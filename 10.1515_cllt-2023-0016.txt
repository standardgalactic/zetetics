Article
Douglas Biber*, Tove Larsson and Gregory R. Hancock
The linguistic organization of grammatical
text complexity: comparing the empirical
adequacy of theory-based models
https://doi.org/10.1515/cllt-2023-0016
Received February 14, 2023; accepted May 3, 2023; published online June 15, 2023
Abstract: Although there is a long tradition of research analyzing the grammatical
complexity of texts (in both linguistics and applied linguistics), there is surprisingly
little consensus on the nature of complexity. Many studies have disregarded syn-
tactic (and structural) distinctions in their analyses of grammatical text
complexity, treating it instead as if it were a single uniﬁed construct. However,
other corpus-based studies indicate that diﬀerent grammatical complexity features
pattern in fundamentally diﬀerent ways. The present study employs methods that
are informed by structural equation modeling to test the goodness-of-ﬁt of four
models that can be motivated from previous research and linguistic theory: a
model treating all complexity features as a single dimension, a model dis-
tinguishing among three major structural types of complexity features, a model
distinguishing among three major syntactic functions of complexity features, and a
model distinguishing among nine combinations of structural type and syntactic
functions. The ﬁndings show that text complexity is clearly a multi-dimensional
construct. Both structural and syntactic distinctions are important. Syntactic dis-
tinctions are actually more important than structural distinctions, although the
combination of the two best accounts for the ways in which complexity features
pattern in texts from diﬀerent registers.
Keywords: grammatical complexity; linguistic co-occurrence; syntactic functions;
text complexity; theory-based models
*Corresponding author: Douglas Biber, Northern Arizona University, Flagstaﬀ, AZ, USA,
E-mail: douglas.biber@nau.edu
Tove Larsson, Northern Arizona University, Flagstaﬀ, AZ, USA. https://orcid.org/0000-0002-0489-2697
Gregory R. Hancock, University of Maryland, College Park, MD, USA
Corpus Linguistics and Ling. Theory 2023; aop

1 Introduction
Although the study of complexity is a major focus of linguistic research, there is
surprisingly little consensus on the nature of the construct itself. One source of
confusion is that the same term has been used to describe characteristics of the
linguistic system as well as the processing diﬃculty associated with particular lin-
guistic features. For example:
[in] linguistics, complexity refers to both the […] internal structuring of linguistic units and to
the psychological diﬃculty in using or learning them. (Crystal 1997: 76)
Bulté and Housen (2012, 2014) make a similar distinction between the complexity of
the linguistic system – what they call “absolute” complexity – as opposed to pro-
cessing diﬃculty, which they call “relative” complexity:
… relative complexity, or cognitive complexity or simply diﬃculty as we will call it, refers to the
mental ease or diﬃculty with which linguistic items are learned, processed or verbalized in the
processes of language acquisition and use […]. The absolute approach deﬁnes language
complexity in objective, quantitative terms as the number of discrete components that a lan-
guage feature or a language system consists of, and as the number of connections between the
diﬀerent components. (Bulté and Housen 2012: 23)
Pallotti (2015: 117ﬀ) also makes a similar distinction, but argues that grammatical
complexity should be conceptualized in strictly linguistic terms (equivalent to the
“absolute”
approach)
as
“the
number
of
linguistic
elements
and
their
interrelationships”.
However, for studies that take a strictly linguistic approach, there is a cross-
cutting distinction that must also be considered: what is the entity that is being
characterized as more or less complex? Research has focused on the complexities of
three diﬀerent kinds of linguistically-relevant entities: 1) phrases/clauses (or sen-
tences), 2) languages (or dialects), and 3) texts. As we show below, this distinction is
crucially important because the conceptualization of complexity diﬀers depending
on the entity that is being characterized.
Descriptive grammars focus on the complexity of phrases/clauses, using the term
complex, as opposed to simple, to describe the ways in which clauses and phrases can
be modiﬁed by the addition of optional structural elements. In this case, each gram-
matical structure is the entity that is being characterized as more-or-less complex. A
simple phrase or clause includes only obligatory elements (e.g., the headword in a
phrase, or the subject, verb, and object in a clause). Optional structural additions to a
simple structure, such as an adjective modifying a head noun, or a prepositional
phrase modifying a verb phrase, result in increasingly complex phrases and clauses.
2
Biber et al.

Traditionally, grammarians have focused on dependent clauses as the most important
manifestation of phrase/clause complexity (see, e.g., Carter and McCarthy 2006: 489;
Huddleston 1984: 378; Purpura 2004: 91; Willis 2003: 192). In most cases, describing the
complexity of phrases/clauses does not entail quantitative analysis. Rather, this is a
purely linguistic description, with a phrase/clause being characterized as complex to
the extent that it includes optional structural elements.
A completely separate conceptualization of grammatical complexity – referred to
as “system complexity” by Szmrecsanyi (2015) – focuses on the nature of the linguistic
system itself, to compare the complexities of diﬀerent languages or dialects. The focus
ofanalysis for this line ofresearch is the number and types ofgrammatical distinctions
found in the linguistic systems ofdiﬀerent languagesor varieties. For example, Nichols
(2013) focused on the number of contrastive elements in the grammatical system, and
McWhorter (2001) focused on the number of rules in the grammatical system. Such
research has been carried out primarily by typologists and functional linguists, who
compare the complexities of varieties to challenge the long-held belief that all lan-
guages and varieties are equally complex (see, e.g., Hawkins 2004; Kortmann and
Szmrecsanyi 2012; Newmeyer and Preston2014; Sampsonetal. 2009). Whenanalysesof
this type are quantitative, the variables measure aspects of the linguistic system, such
as the number of grammatical distinctions made in the system.
Finally, the notion of grammatical complexity can be applied to actual language use,
describing the ways and extent to which complexity features are used in texts. Szmrec-
sanyi (2015: 347–349) refers to this as “usage-based or text complexity” (as opposed to
“system complexity”). The entity being described in this case is the individual text, but
registers, dialects, and even languages can be compared from this perspective, based on
analysis of a corpus of texts from the target language variety. That is, the focus is on the
extent to which texts representing the variety employ diﬀerent types of complexity
features, rather than on the distinctions that exist in the linguistic systems of those
varieties. Analyses from this perspective are almost always quantitative, based on mea-
sures that attempt to capture the extent to which various kinds of complexity features are
used in a text. The present paper adopts this perspective of grammatical text complexity.
Linguists have sometimes compared languages/dialects from a text complexity
perspective,basedonanalysis ofcorporaoftexts fromthetargetvarieties(see,e.g.,Siegel
et al. 2014; Szmrecsanyi 2009). However, the notion of grammatical text complexity has
been applied more commonly to the comparison of registers. For example, Szmrecsanyi
(2009: 334; Figure 2) shows that spoken registers generally exhibit high rates of occur-
rence for analytic function words coupled with low rates of occurrence for synthetically
inﬂected words. In contrast, written registers permit a wider range of variation. For
example, a written register like email messages has low rates of occurrence for both
analytic function words and synthetically inﬂected words; ﬁction has high rates of
occurrence for both analytic function words and synthetically inﬂected words; and
newspaper articles and institutional documents rely heavily on synthetically inﬂected
words, with very low rates of occurrence for analytic function words.
Grammatical text complexity
3

Biber (1992) was an earlier study that undertook a corpus-based investigation of
the grammatical text complexities of spoken and written registers (referred to as
“discourse complexity” in that article). Similar to Szmrecsanyi (2009, 2015) and Biber
(1992) investigated the ways in which grammatical complexity features were used in
texts, rather than cataloging the inventories of grammatical features across diﬀerent
linguistic systems. However, Biber (1992) diﬀered from Szmrecsanyi’s studies by
including a wide range of diﬀerent grammatical complexity features, and focusing
on the ways in which those features co-occur in texts across registers. For example,
that study found that nouns, nominalizations, prepositional phrases, attributive
adjectives, phrasal coordination, and long words all co-occur frequently in texts,
reﬂecting an underlying dimension of complexity (referred to as “integration”).
Numerous subsequent studies carried out within the Register-Functional (RF)
framework have explored the nature of grammatical complexity in English based on
analyses of corpora of texts from diﬀerent registers (see especially the collection of
articles included in Biber et al. 2022). Recent research in this framework has tested
the generalizability of the patterns uncovered in earlier corpus-based studies of
register variation, especially multi-dimensional analyses of spoken and written
registers (e.g., Biber 1988, 2014), and the lexico-grammatical patterns of use across
spoken and written registers documented in the Grammar of Spoken and Written
English (Biber et al. 2021; previously published as Biber et al. 1999). Two especially
surprising research ﬁndings have emerged from these studies:
1)
the grammatical complexity structures regularly employed by speakers in
everyday conversations are long and structurally elaborated, often incorpo-
rating multiple dependent clauses.
2)
the grammatical structures regularly employed by authors in written informa-
tional texts are not elaborated; in fact, they could be better characterized as com-
pressed. Thus, ﬁnite dependent clauses are comparatively rare in informational
written registers, while phrasal complexity features are comparatively frequent.
Biber and Gray (2016) explore these patterns in detail, focusing especially on the
historical development of innovative phrasal complexity features that are especially
prevalent in present-day written academic texts.1
Apart from studies carried out within the register-functional framework, scholars
havegenerallyanalyzedgrammaticaltextcomplexityasasingle,uniﬁedconstruct,even
1 It is worth noting that applied linguistic studies of language proﬁciency/development also usually
employ corpus-based analyses of grammatical text complexity. These studies usually rely on one or
more omnibus measures, i.e., a measure that combines analysis of multiple structural and syntactic
distinctions into a single quantitative variable, generalized across an entire text. Popular examples of
omnibus measures are the mean length of t-units in a text, or the average number of clauses per t-unit
across all sentences of a text (see the surveys in Bulté and Housen 2012; Wolfe-Quintero et al. 1998).
4
Biber et al.

though there is debate over the beneﬁts of diﬀerent measures to represent that
construct. For example, Szmrecsanyi (2015) explores three diﬀerent grammatical text
complexitymeasures: synthetic/analyticgrammaticalmarking,Kolmogorovindices(the
extent to which new text can be predicted from preceding text), and variational
complexity. The important point for our purposes here is that these are proposed as
diﬀerent approaches for assessing the underlying construct of grammatical text
complexity – not as three diﬀerent types or dimensions of grammatical text complexity.
Research in applied linguistics has been dominated by a similar perspective. For
example, scholars like Wolfe-Quintero et al. (1998)and Lu (2011,2017)advocatethe use of
multiple omnibus measures of grammatical text complexity, such as the mean length of
t-units and the average number of dependent clauses per t-unit. However, these are all
considered to be diﬀerent measures of the single underlying construct of grammatical
text complexity, rather than diﬀerent types or dimensions of complexity.2
In contrast, Biber (1992) provided strong empirical evidence showing that gram-
matical text complexity is a multi-dimensional linguistic construct, in the sense that
groupings of phrasal/clausal complexity features co-occur in texts and pattern together
as underlying parameters (or dimensions) of complexity, such that each text has a
speciﬁc characterization in a multi-dimensional space of complexity. These dimensions
are claimed to be quantitative parameters reﬂecting the use of co-occurring complexity
features. That is, a text will have a quantitative dimension score reﬂecting the rate of
occurrence for the group of complexity features.
Subsequent corpus-based studies carried out from an RF perspective provide
strong support for the claim that diﬀerent groupings of phrasal/clausal complexity
features pattern together in texts and vary in systematic ways across registers (see the
chaptersinBiber etal.2022).Grammaticaltext complexity isoneaspectoflanguageuse
more generally, with the use of linguistic features being inﬂuenced by a wide range of
situational and communicative factors. Functional linguists have argued strongly for
the perspective that grammatical distinctions exist for functional reasons (see, e.g.,
Newmeyer 2001; Nichols 1984); for example:
the communicative situation […] the purpose of the speech event, its participants, its discourse
context motivates, constrains, explains, or otherwise determines grammatical structure (Nichols
1984: 97)
2 Applied linguists like Norris and Ortega (2009), Ortega (2015), and Bulté and Housen (2014) have
argued that grammatical text complexity should be approached as a “multi-dimensional” construct.
In practice, though, these studies advocate the use of omnibus measures which fail to distinguish
among the uses of speciﬁc grammatical complexity features. Thus, while these studies are based on
multiple omnibus measures, they present no evidence that those measures represent diﬀerent
linguistic dimensions (see extended discussions in Biber et al. 2020, 2022).
Grammatical text complexity
5

Given this perspective, there is every reason to expect that diﬀerent phrasal/clausal
complexity features will serve unique functions in texts and therefore have their
own distributional patterns.
The grammatical inventory of English includes numerous structural devices,
serving many diﬀerent syntactic functions, which all fall under the general rubric of
phrasal/clausal complexity features. These are all grammatical features that can be
optionally added to a simple phrase/clause to create a more complex phrase/clause. A
functional, language-use perspective requires consideration of how that full in-
ventory of phrasal/clausal complexity features is employed in texts. One hypothesis,
which has been adopted as the analytical basis in many (applied) linguistic studies, is
that all phrasal/clausal complexity features co-occur in texts as a reﬂection of a single
uniﬁed construct of complexity. However, given the ﬁndings of previous research,
there are speciﬁc alternative hypotheses, relating to the ways in which phrasal/
clausal complexity features can be grouped into sets of features that serve similar
discourse functions and thus will co-occur in texts, reﬂecting underlying dimensions
of complexity. These are the general issues that we explore in the present paper,
employing corpus-based analyses to investigate the following research questions:
1)
Should grammatical text complexity be regarded as a single uniﬁed construct or
as a multi-dimensional construct?
2)
If grammatical text complexity is a multi-dimensional construct, what are the
dimensions?
a.
Speciﬁcally, to what extent do observed patterns of linguistic variation
conform to groupings of complexity features that can be hypothesized based
on previous research?
2 Cataloging the inventory of phrasal/clausal
complexity features
Before we can analyze the ways in which grammatical complexity features pattern
together in texts, we need to develop taxonomy of phrasal/clausal complexity fea-
tures in English. That is, the descriptive perspective on phrasal/clausal complexity
provides the foundation for the grammatical text complexity perspective: the former
identiﬁes the set of relevant structural/syntactic features that must be analyzed, and
the latter explores the distributions of those features across texts.
As noted above, we adopt a straightforward deﬁnition of phrasal/clausal
complexity: the addition of optional structural elements to a “simple” phrase or a
“simple” clause. Simple phrases/clauses are deﬁned as structures that include only
obligatory elements plus accompanying function words. For example, a simple noun
phrase includes only a head noun (plus determiners). A simple clause includes only a
main verb (plus auxiliary verbs), a subject noun phrase, and any other obligatory
6
Biber et al.

phrases that are required by the valency of the verb (e.g., a direct object noun phrase
or a subject predicative adjective phrase).3
Applying this general deﬁnition, Table 1 lists the major grammatical complexity
features in English, categorized according to their structural type and syntactic function.
That is, these are the major features (grammatical structures + syntactic functions) that
meet the criteria given in our deﬁnition above. This taxonomy of grammatical-
structures/syntactic-functions is based on a survey of the Grammar of Spoken and
Written English (Biber et al. 2021; the GSWE). However, a survey of any major reference
grammar of English (e.g., Huddleston and Pullum 2002; Quirk et al. 1985) would result in
a similar taxonomy (although the labels for some grammatical features might diﬀer).
Table 1 categorizes complexity features into three general structural types: ﬁnite
dependent clauses, non-ﬁnite dependent clauses, and dependent phrases. Addi-
tionally, as a cross-cutting consideration, each complexity feature is categorized into
three general syntactic functions: clause constituent, noun-phrase constituent, and
other-phrase constituent. Complexity features can be further distinguished accord-
ing to their speciﬁc syntactic functions as modiﬁers versus complements (although
this is not a major organizing principle in the present study).
Table : Phrasal/clausal complexity features in English, by structural type and syntactic function
Complexity feature
Structural
Type
Syntactic Function
Examples
Causative, conditional,
concessive clause
Finite Depen-
dent Clause
Clause constituent:
Adverbial
She won’t narc on me, because she
prides herself on being a gangster.
Well, if I stay here, I’ll have to leave early
in the morning.
Verb + that comple-
ment clause
Finite Depen-
dent Clause
Clause constituent:
Verb complement
I would hope that we can have more
control over them. (with ZERO
complementizer): yeah, I think I prob-
ably could.
Verb + wh comple-
ment clause
Finite Depen-
dent Clause
Clause constituent:
Verb complement
I don’t know how they do it.
Noun + Finite relative
clause (that or WH)
Finite Depen-
dent Clause
Noun phrase constitu-
ent: NP modiﬁer
…the experimental error that could
result from using cloze tests
Noun + that comple-
ment clause
Finite Depen-
dent Clause
Noun phrase constitu-
ent: NP complement
The fact that no tracer particles were
found indicates that these areas are not
a pathway…
3 The one exceptional case is dependent clauses that function syntactically as an obligatory clause
element (e.g., He knew that I was sensitive), which are treated as complexity features in the present study.
Grammatical text complexity
7

Table : (continued)
Complexity feature
Structural
Type
Syntactic Function
Examples
Adjective + that
complement clause
Finite Depen-
dent Clause
Other phrase constit-
uent: Adjective
complement
We’re happy that the hunger strike has
ended.
Extraposed adjective
+ that complement
clause
Finite Depen-
dent Clause
Other phrase constit-
uent: Adjective
complement
It is evident that the virus formation is
related to the cytoplasmic inclusions.
Preposition + wh
complement clause
Finite Depen-
dent Clause
Other phrase constit-
uent: Prepositional
complement
I’ll oﬀer a suggestion for what we should
do.
to-clause as ‘purpose’
adverbial
Non-ﬁnite
Dependent
Clause
Clause constituent:
Adverbial
To verify this hypothesis, sections of
ﬁxed cells were examined.
ing-clause as adverbial Non-ﬁnite
Dependent
Clause
Clause constituent:
Adverbial
Considering mammals’ level of physical
development, the diversity of this spe-
cies is astounding.
ed-clause as adverbial
Non-ﬁnite
Dependent
Clause
Clause constituent:
Adverbial
Based on estimates of the number of
unidentiﬁed species, other studies put
the sum total in the millions.
Verb + to complement
clause
Non-ﬁnite
Dependent
Clause
Clause constituent:
Verb complement
I really want to ﬁx this room up.
Verb + ing
complement clause
Non-ﬁnite
Dependent
Clause
Clause constituent:
Verb complement
I like watching the traﬃc go by.
Noun + -ed (passive)
relative clause
Non-ﬁnite
Dependent
Clause
Noun phrase constitu-
ent: NP modiﬁer
This is a phrase used in the recruitment
industry.
Noun + -ing relative
clause
Non-ﬁnite
Dependent
Clause
Noun phrase constitu-
ent: NP modiﬁer
Elevated levels are treated with a diet
consisting of low cholesterol foods.
Noun + to relative
clause
Non-ﬁnite
Dependent
Clause
Noun phrase constitu-
ent: NP modiﬁer
You’re the best person to ask.
Noun + to
complement clause
Non-ﬁnite
Dependent
Clause
Noun phrase constitu-
ent: NP complement
The project is part of a massive plan to
complete the section of road…
Adjective + to com-
plement clause
Non-ﬁnite
Dependent
Clause
Other phrase constit-
uent: Adjective
complement
I was happy to do it.
8
Biber et al.

The taxonomy of complexity features shown in Table 1 distinguishes among both
structural types and syntactic functions. This aspect of our taxonomy is noteworthy
because it is in marked contrast to most previous complexity studies, which are
based solely on analysis of grammatical structures. However, previous register-
functional studies of complexity have shown that syntactic distinctions are at least as
important as structural distinctions. For example, several previous studies have
found complexity features as clause constituents (e.g., adverbials and verb-
complements) to be especially prevalent in conversation, regardless of structural
Table : (continued)
Complexity feature
Structural
Type
Syntactic Function
Examples
Extraposed adjective
+ to complement
clause
Non-ﬁnite
Dependent
Clause
Other phrase constit-
uent: Adjective
complement
It was important to obtain customer
feedback.
Preposition + ing
complement clause
Non-ﬁnite
Dependent
Clause
Other phrase constit-
uent: Prepositional
complement
The formula for calculating the eﬀective
resistance is ….
Adverb phrase as
adverbial
Dependent
phrase
Clause constituent:
Adverbial
I raved about it afterwards.
Prepositional phrase
as adverbial
Dependent
phrase
Clause constituent:
Adverbial
Alright, we’ll talk to you in the morning.
Attributive adjectives
as noun pre-modiﬁer
Dependent
phrase
Noun phrase constitu-
ent: NP modiﬁer
emotional injury, conventional practices
Nouns as noun pre-
modiﬁer
Dependent
phrase
Noun phrase constitu-
ent: NP modiﬁer
aviation security committee, ﬁghter pilot
training
Of genitive phrases as
noun post-modiﬁer
Dependent
phrase
Noun phrase constitu-
ent: NP modiﬁer
McKenna wrote about the origins of
human language.
Other prepositional
phrases as noun post-
modiﬁer
Dependent
phrase
Noun phrase constitu-
ent: NP modiﬁer
Overall scores were computed by aver-
aging the scores for male and female
students.
Appositive noun
phrases as noun post-
modiﬁer
Dependent
phrase
Noun phrase constitu-
ent: NP modiﬁer
James Klein, president of the American
Beneﬁts Council
Prepositional phrases
as adjective
complement
Dependent
phrase
Other phrase constit-
uent: Adjective
complement
I’d be happy with just one.
Adverb phrase as ad-
jective/adverb
modiﬁer
Dependent
phrase
Other phrase constit-
uent: Adjective/adverb
modiﬁer
That cat was surprisingly fast.
We will see those impacts fairly quickly.
Grammatical text complexity
9

type (see, e.g., Biber et al. 2022). In contrast, complexity features functioning as noun-
phrase modiﬁers are especially prevalent in informational writing, again regardless
of structural type. For these reasons, the analyses below are based on consideration
of both structural type as well as syntactic function.
3 The speciﬁc hypotheses: motivating the models
of text complexity
Previous empirical research coupled with the grammatical distinctions recognized by
linguistic theory enable speciﬁc hypotheses regarding the ways in which complexity
features might pattern together in texts. For this reason, we employ a conﬁrmatory
statistical approach rather than relying on exploratory factor analysis (as in most pre-
vious multi-dimensional studies of register variation). In particular, we employ methods
that are informed by the statistical framework of structural equation modeling (SEM;
Larsson et al. 2021), focusing on the goals of: 1) hypothesizing speciﬁc statistical models
based on previous research ﬁndings or theory; and 2) employing statistical tests to
evaluate the extent to which each model accounts for the characteristics of and relations
among variables that are actually observed in real-world data. In the present study, we
apply building blocks from the SEM framework to test the goodness-of-ﬁt of four models
that can be motivated from previous research and linguistic theory:
–
Model 0: All phrasal/clausal complexity features work together as part of a single
uniﬁed dimension4 of text complexity
–
Model 1: The general construct of text complexity is organized as three di-
mensions reﬂecting the diﬀerent major structural types of complexity features:
–
dependent ﬁnite clauses
–
dependent non-ﬁnite clauses
–
dependent phrases
–
Model 2: The general construct of text complexity is organized as three dimensions
reﬂecting the diﬀerent major syntactic functions of complexity features:
–
clause-level constituents
–
noun-phrase constituents
–
other-phrase constituents
–
Model 3: The general construct of text complexity is organized as nine dimensions
reﬂecting the combinations of major structural types plus syntactic functions (e.g.,
ﬁnite clauses asclause-levelconstituents;phrases asclause-levelconstituents;etc.)
4 We use the term dimension here to refer to a collection of variables that co-vary as a group,
speciﬁcally referring to a group of grammatical complexity features that tend to co-occur in texts.
This use of the term should be distinguished from a “dimension” or “factor” resulting from a
statistical (exploratory or conﬁrmatory) factor analysis.
10
Biber et al.

These models can be visualized from Table 2, which lists the phrasal/clausal
complexity features categorized by structural type and syntactic function. Model
0 tests the hypothesis that all 25 of these complexity features function together in
texts as the realization of a single complexity dimension. Model 1 tests the hypothesis
that complexity features are organized as three structural dimensions, shown as the
three columns in Table 2. Model 2 tests the hypothesis that complexity features are
organized as three syntactic dimensions, shown as the three rows in Table 2. And
ﬁnally, Model 3 tests the hypothesis that complexity features are organized as nine
structural-syntactic dimensions, shown as the individual cells in Table 2.
These four models can be motivated from both linguistic theory and previous
empirical research. Model 0 is the model underlying most previous complexity
research in descriptive and applied linguistics, which generally disregards any
potential importance of diﬀerences in structural type or syntactic function. This is
Table : Phrasal/clausal complexity features included in the analysis, organized according to major
structural type and syntactic function.a
Syntactic function
Structural type
Finite dependent
clauses
Nonﬁnite
dependent clauses
Dependent phrases
Noun phrase
modiﬁers
Finite relative clauses
Noun + that comple-
ment clauses
Passive (-ed)
nonﬁnite relative
clauses
-ing nonﬁnite
relative clauses
To relative clauses
Noun + to
complement clauses
Attributive adjectives
Pre-modifying nouns
Of genitive phrases
Other postnominal
prepositional phrases
Other phrase com-
plements/modiﬁers
Adjective + that
complement clauses
Preposition + WH
complement clauses
Adjective + to
complement clauses
Preposition + -ing
complement clauses
Adjective + prepositional
phrase complement
Adverbs as adjective/adverb
modiﬁers
Clause constituents
Finite adverbial
clauses
Verb + that
complement clauses
Verb + WH
complement clauses
Verb + to complement
clauses
Verb + -ing
complement clauses
To adverbial clauses
-ing adverbial clauses
Clause-level adverbs
Clause-level prepositional
phrases
aAppositive noun phrases were excluded from the analysis because they could not be identiﬁed accurately in a semi-
automatic manner. Some other features (e.g., post nominal prepositional phrases) are analyzed using algorithms that
ensure high precision but lower recall rates (see discussion in Section ).
Grammatical text complexity
11

not to say that all grammatical text complexity studies employ the same measure.
In fact, as noted above, many diﬀerent measures have been proposed (e.g., the
analytic/synthetic ratio, or the average length of t-units). However, these all share
the characteristic that grammatical text complexity is analyzed as a single
construct, rather than being analyzed in terms of the ways in which the structural
and syntactic resources of English are organized as diﬀerent underlying di-
mensions of complexity. In fact, that goal is often made explicit, as in the evaluation
from Wolfe-Quintero et al. (1998) that two measures – clauses per t-unit and
dependent clauses per clause – are the “best […] complexity measures so far” (pp.
118–119; see also the discussion in Pallotti 2009: 590).5
Model 1 reﬂects the basic levels of linguistic structure adopted in grammatical
descriptions of English: dependentphrases versus dependentclauses.This model further
recognizes the intermediate status of non-ﬁnite dependent clauses: non-ﬁnite clauses
behave like ﬁnite clauses in that they include a main verb, but they behave like
dependent phrases in that there is often no subject noun phrase, and they can be
embedded freely in other phrases.6 Model 1 receives implicit support from functional
descriptions in English grammars. For example, descriptive grammars often equate
grammatical complexity with structural elaboration. Thus, ﬁnite dependent clauses
represent greater structural elaboration than non-ﬁnite clauses, which in turn represent
greater structural elaboration than dependent phrases (see e.g., Carter and McCarthy
2006: 489; Huddleston 1984: 378; Purpura 2004: 91; Willis 2003: 192). Similar logic might be
argued to underlie the deﬁnition of some omnibus measures, especially those that are
based on the length of sentences or t-units, because ﬁnite dependent clauses are usually
longerthannon-ﬁniteclauses,whichareinturnusuallylongerthandependentphrases.7
5 As noted above, these are omnibus measures that combine analysis of multiple structural and
syntactic distinctions into a single quantitative variable (see discussion in Biber et al. 2020). Thus,
each omnibus measure attempts to capture the entire system of grammatical text complexity. These
measures are evaluated based on the extent to which they predict diﬀerences among varieties or
groups of speakers. But no study using omnibus measures has evaluated the extent to which the
structural/syntactic characteristics lumped together in the computation of a measure actually
function together as components of a single dimension.
6 For example, a non-ﬁnite clause can be embedded in a prepositional phrase (e.g., the options for
making decisions). However, this kind of embedding is not possible with a ﬁnite dependent clause
(compare *the options for that a person makes decisions).
7 In addition, a few recent researchers in applied linguistics have proposed specialized omnibus
measures that reﬂect certain structural diﬀerences. For example, Norris and Ortega (2009: 561)
discuss diﬀerences between dependent-clause complexity versus phrasal complexity, recommend-
ing omnibus measures like “clauses per t-unit” to capture the former, and measures like “clause
length” as a way to capture the latter. Bulté and Housen (2014) similarly employ a measure of phrasal
complexity (mean length of noun phrase) together with multiple measures of clausal or sentential
complexity (e.g., mean length of sentence, mean length of ﬁnite clause).
12
Biber et al.

Diﬀerences in syntactic function – the basis of Model 2 – are the second major
organizing principle of grammatical description. That is, reference grammars go to
great length to describe the ways in which the same grammatical structure can serve
multiple syntactic functions, and vice versa. For example, a prepositional phrase can
function syntactically as a clause-level adverbial, noun modiﬁer, or adjective com-
plement (see Table 1). Conversely, a clause-level adverbial can be realized struc-
turally as a single adverb, a prepositional phrase, a non-ﬁnite dependent clause, or a
ﬁnite dependent clause (see Table 1). Thus, we have strong motivation from gram-
matical theory for the prediction that syntactic function will be an important orga-
nizing principle for dimensions of grammatical text complexity.
There is also strong support from register studies for the prediction that
syntactic diﬀerences constitute a major organizing principle for grammatical text
complexity. For example, multi-dimensional studies of register variation have
repeatedly found clause-level constituents (adverbials and verb complements) to
be especially prevalent in spoken registers but relatively rare in informational
written registers. In contrast, noun phrase modiﬁers and noun complements are
common in informational written registers but relatively rare in spoken regis-
ters. Numerous detailed studies of complexity features have conﬁrmed these
general diﬀerences in the typical syntactic functions of complexity features in
spoken versus written registers (see, e.g., Biber and Gray 2016; Biber et al. 2022).
However, apart from studies in the register-functional tradition, most previous
analyses of text complexity (including applied studies that employ omnibus
measures) fail to include consideration of syntactic diﬀerences.8
Finally, Model 3 is the logical extension of Models 1 and 2: if structural dis-
tinctions matter, and syntactic diﬀerences matter, then it is likely that systematic
combinations of structural types and syntactic functions will also be important.
And in fact, register studies strongly conﬁrm this logical prediction (see, e.g., Biber
1988, 2014; Biber and Gray 2016; Biber et al. 2022). For example, register studies have
repeatedly found that the combination of ﬁnite dependent clauses functioning as
clause-level constituents is especially prevalent in spoken registers. And in
contrast, the combination of dependent phrases functioning as phrasal modiﬁers is
especially prevalent in informational written registers.
8 One apparent exception is the measure “complex nominals” (see Lu 2010), with a name that
suggests the use of complexity features serving the syntactic function of modifying noun phrases.
However, detailed consideration of this measure shows that it collapses structures serving a wide
range of syntactic functions (including noun modiﬁers, verb complements, and sentential subjects;
see discussion in Biber et al. 2020: 11).
Grammatical text complexity
13

4 Corpus, linguistic analyses, and statistical
methods
We tested the relative descriptive adequacies of the complexity models introduced in
the last section, based on analysis of ten spoken and written registers. Our goal in the
design of the corpus, summarized in Table 3, was to cover a wide range of register
variation within each mode, while at the same time generally matching spoken and
written registers for their communicative purposes, level of assumed expertise, and
interactivity (to avoid confounding the inﬂuence of mode with other situational
factors). Most texts were taken from existing corpora used in previous studies, such
as the T2KSWAL Corpus, the BNC 2014 Spoken Corpus, and the 20th Century Research
Article Corpus. Other texts were downloaded from the web (e.g., university lectures
were obtained from Open Yale Courses; https://oyc.yale.edu).
Rates of occurrence for 25 phrasal/clausal complexity features in each text were
calculated by applying a suite of automated computational tools. In general, our
approach was designed to achieve high precision, with all complexity features being
identiﬁed with >90 % accuracy. However, there was necessarily some reduction in
recall associated with the automatic analysis.
The computational/linguistic analyses began with application of the Biber Tagger,
followed by detailed hand-checking of the annotated texts to identify any pervasive
problems with the tagging. We then developed an additional computer program, using
tagged texts as input, to identify speciﬁc complexity features. To a large extent, that
program relied on a lexico-grammatical approach. For example, features like that clauses
Table : Breakdown of the corpus across texts and registers.
# of
texts
# of words (for all
texts)
Spoken registers
Conversation: opinion discourse units (BNC )

,
Conversation: narrative discourse units (BNC )

,
Classroom teaching (TKSWAL)

,,
Formal university lectures (Open Yale Courses)

,
Written registers
Opinion blogs (CORE)

,
Fiction (Longman)

,,
Newspaper articles (New York Times)

,
University textbooks (TKSWAL)

,
Academic research articles: non-science (th Century Research
Article Corpus)

,,
Academic research articles: science (th Century Research Article
Corpus)

,
TOTAL
,
c. ,,
14
Biber et al.

andtoclausesfunctioningasnouncomplementswereanalyzedwithalgorithmsbasedon
the lexico-grammatical ﬁndings reported in the Grammar of Spoken and Written English.
For the analysis of some other complexity features, we developed additional
databases based on corpus analyses of the lexico-grammatical combinations that
reliably represented the target feature. For example, to accurately identify occur-
rences of prepositional phrases functioning as noun modiﬁers, we began by ﬁrst
creating a database of all noun + preposition combinations that occurred at least 100
timesinthe c. 50-million-word CORECorpus.Then,thatdatabase wasedited byhand to
exclude combinations that might not be functioning as noun post-modiﬁers. For
example, noun + preposition combinations like agreement between and argument for
were retained as reliable instances of a prepositional phrase functioning as a noun
post-modiﬁer, whilecombinationslike money toand way in were excluded because the
prepositional phrasecould be serving othersyntactic functions (e.g., theysentmoney to
someone; they voted the same way in all elections). These resulting edited database of
prepositional phrases functioning as noun modiﬁers includes 1,055 noun+preposition
combinations.
All quantitative-linguistic analyses are based on the normed rates of occurrence
(per 1,000 words) for each feature in each text. The ultimate goal of the study was to
investigate the ways in which complexity features are organized as dimensions of
variation. The statistical analyses are based on the underlying assumption that lin-
guistic features that function in similar ways (and thus constitute a dimension of
variation) will co-occur in texts. These patterns of co-occurrence are captured
through simple Pearson correlations in our case. Thus, the statistical analyses begin
with a correlation matrix of all complexity features.
Each model tests a hypothesized grouping of the complexity features. Specif-
ically, the models test the assumption that features belonging to the same underlying
dimension will systematically co-occur in texts, operationalized by the requirement
that all complexity features in a group (i.e., the features constituting a complexity
dimension) should have correlations >+0.2 with all other features in the group. The
requirement of a positive correlation guarantees that the two features co-occur in
texts. (That is, a large negative correlation would instead show that two features
tended to occur in complementary distribution.) The requirement of >+0.2 might be
considered a relatively weak constraint. However, because this requirement applies
to each of the bivariate correlations in a grouping of features, it represents a rela-
tively strict constraint on the entire grouping.
Each hypothesized model is evaluated for its goodness-of-ﬁt, i.e., the extent to
which the hypothesized grouping of features conforms to the observed correlations.
Our analysis here uses the standard root mean squared residual (SRMR) for this
purpose. The computation of SRMR in our application is relatively straightforward.
We begin with the observed correlations among all features in a group, comparing
those to the correlations predicted by the model (i.e., a correlation >+0.2 for each pair
of features in the group). A residual is computed for each correlation, representing
Grammatical text complexity
15

the diﬀerence between the actual observed correlation and the model-based cor-
relation. If the observed correlation is >+0.2, then the residual is 0.0, because the
actual correlation is in the range predicted by the model. But if the observed cor-
relation is in the range −1.0 to +0.2, then the residual is the diﬀerence between the
model prediction of +0.2 and the observed correlation.
Table 4 illustrates computation of the residuals from three of the groupings in
Model 3. Two cases need to be discussed: when the observed correlation is >+0.2, and
when the observed correlation is <+0.2. If the observed correlation is >+0.2, then the
model-based correlation is exactly the same as the observed correlation, resulting in
a residual of 0.0 (i.e., a perfect ﬁt to the predictions of the model). For example, the
Table : A partial model for three hypothesized groups of complexity features, illustrating computation
of residual correlations.
Observed correlations
ﬁniterel
edrel
torel
ingrel
Adj + N
N + N
N + of
thncomp
.
torel
−.
ingrel
.
.
toncomp
.
.
−.
N + N
.
N + of
.
.
N + prep
.
.
.
Model-based correlations
ﬁniterel
edrel
torel
ingrel
Adj + N
N + N
N + of
thncomp
.
torel
.
–
ingrel
.
.
–
toncomp
.
.
.
N + N
.
–
N + of
.
.
–
N + prep
.
.
.
Residual correlations
ﬁniterel
edrel
torel
ingrel
Adj + N
N + N
N + of
thncomp
−.
torel
−.
ingrel
−.
−.
toncomp
−.
−.
−.
N + N
.
N + of
.
.
N + prep
.
.
.
16
Biber et al.

observed correlation between Adj + N and N + N is 0.686. Because this is greater than
+0.2, the model-based correlation is speciﬁed as being the same as the observed
correlation (i.e., 0.686), and the residual correlation is 0.0. In all other cases, the
model-based correlation is speciﬁed as +0.2, i.e., our a priori cut-oﬀpoint, and the
residual correlation is the diﬀerence between the observed correlation and +0.2. For
example, the observed correlation between ﬁniterel and thncomp is 0.148. Because
this is less than +0.2, the model-based correlation is speciﬁed at +0.2, and the residual
correlation is the diﬀerence: 0.148 −0.2 = −0.052.
Conceptually, the SRMR value represents the average magnitude of the diﬀer-
ences between the observed correlations and the model-based correlations. The
actual value for SRMR is calculated by squaring each residual, averaging all of those
squared-residuals, and then taking the square root of that average. SRMR values in
our study can range from 0.0 to 1.2, with a value of 0.0 representing a perfect ﬁt.
For example, we can compute an SRMR value for each of the three groupings
discussed in Table 4 above:
1. Finiterel, thncomp: SRMR = 0.052
2. edrel, torel, ingrel, toncomp: 0.186
3. Adj + N, N + N, N + of, N + prep: SRMR = 0.0
These SRMR values can be interpreted as a direct reﬂection of the overall magnitude
of residual correlations. For example, all pairwise correlations in Group #3 conform
to the model-based predictions of >+0.2, resulting in the SRMR value of 0.0. In
contrast, none of the pairwise correlations in Group #2 conform to the model-based
predictions, resulting in fairly large residual correlations, reﬂected in the SRMR
value of 0.186.9
5 Overall comparison of the models
Using the methods described above, it is possible to compare the goodness-of-ﬁt
indices for the four models investigated here. Table 5 presents those results. The
1-dimensional model (Model 0), based on the hypothesis that all complexity features
pattern together, has the worst ﬁt (SRMR = 0.289). Model 1, based on the hypothesis
that the structural types of complexity features constitute three separate dimensions,
has a modest improvement in ﬁt (SRMR = 0.267). Model 2, based on the hypothesis
that the syntactic functions of complexity features constitute three separate di-
mensions, has even better ﬁt (SRMR = 0.224). However, Model 3, based on the
9 All models tested in the current study are based on speciﬁcation of only the features that co-vary in
each grouping. That is, we make no predictions about the nature of the correlations among features
across groupings: the oﬀ-diagonal cells in Table 4 above.
Grammatical text complexity
17

hypothesis that each combination of structural type and syntactic function consti-
tutes a separate complexity dimensions, has by far the best ﬁt (SRMR = 0.200).
Table 5 also presents the goodness-of-ﬁt results for each hypothesized dimension
of complexity features (the third column in the table). These correspond to the three
columns of Table 2 for Model 1, the three rows of Table 2 for Model 2, and each cell in
Table 2 for Model 3. For example, the third column of Table 5 shows that dependent
phrases (in Model 1) have a poor ﬁt (SRMR = 0.386), providing little support for the
hypothesis that all phrasal types of complexity co-occur regularly in texts. In
contrast, the more speciﬁc grouping of dependent phrases functioning syntactically
as noun modiﬁers (in Model 3) has a perfect ﬁt (SRMR = 0.0), meaning that those
features all correlate at +0.2 or higher.
Taken together, the ﬁndings shown in Table 5 lead to several major conclusions
that contradict previous expectations. First of all, the results here provide no support
for treating grammatical complexity as a single uniﬁed construct, in contrast to
normal practice in most previous research. Equally surprising is the ﬁnding that
Table : Goodness-of-ﬁt indices for four models of complexity.
Model
Overall model
SRMR
SRMR for each grouping
: single dimension
.
–
: three structural dimensions
.
Finite dependent clauses: .
Non-ﬁnite dependent clauses: .
Dependent phrases: .
: three syntactic dimensions
.
Noun modiﬁers: .
Other phrase complements: .
Clause constituents: .
: nine dimensions = combinations of
syntax + structure
.
1. Noun modiﬁers realized as:
A.
Finite clauses: 0.052
B.
Non-ﬁnite clauses: 0.186
C.
Dependent phrases: 0.000
2. Other phrase complements/modi-
ﬁers realized as:
A.
Finite clauses: 0.236
B.
Non-ﬁnite clauses: 0.264
C.
Dependent phrases: 0.103
3. Clause constituents realized as:
A.
Finite clauses: 0.000
B.
Non-ﬁnite clauses: 0.214
C.
Dependent phrases: 0.643
18
Biber et al.

grouping complexity features by structural type provides only slightly better ﬁt than
a single-dimension model. In contrast, grouping complexity features by syntactic
function provides considerably better ﬁt. These two ﬁndings also contrast sharply
with normal practice: although some previous approaches distinguish among some
structural types of complexity, almost no previous research (apart from studies in
the register-functional framework) distinguishes among the syntactic functions of
complexity features. Finally, the results shown in Table 5 strongly support the
conclusion that grammatical complexity is a multi-dimensional construct, with the
9-dimension model providing the best ﬁt. Both structural type and syntactic function
are important organizing factors, but working together rather than independently.
Two of these groupings receive especially strong support from this analysis:10
–
1C: dependent phrases functioning as noun modiﬁers: attributive adjectives, pre-
modifying nouns, of-genitive phrases, other prepositional phrases post-modifying
a noun
–
3A: ﬁnite dependent clauses functioning as clause-level constituents: ﬁnite
adverbial clauses, verb + that complement clauses, verb + wh complement clauses
These groupings represent the two extreme cells of Table 2, and they can be regarded
as stereotypical phrasal complexity versus stereotypical clausal complexity: the ﬁrst
group of features (1C) is both structurally and syntactically phrasal, while the second
group (3A) is both structurally and syntactically clausal. Previous research indicates
that the features within both groupings are related in terms of their discourse
functions and register distributions. Finite dependent clauses as clause-level con-
stituents are especially frequent in spoken registers, functioning to express personal
stance meanings or to situate discourse relative to particular reasons/conditions/
circumstances (see, e.g., Biber et al. 2021: 654–664; 679–683; 813–815). In contrast,
dependent phrases as noun modiﬁers are especially frequent in informational
written registers, functioning to compress maximal amounts of information into
relatively few words (see discussion in Biber and Gray 2016).
These two complexity dimensions are strongly associated with the “oral” versus
“literate” discourse styles documented in previous multi-dimensional studies (see
survey in Biber 2014). These earlier studies suggest that the stereotypical clausal
(“oral”) complexity dimension and the stereotypical phrasal (“literate”) complexity
dimension have a systematic but complementary relation to each other: when a text
frequently employs oral complexity features, that same text (or register) tends to
rarely use literate complexity features, and vice versa.
10 Additional analyses reported in Biber et al. (2023) show that these patterns are highly robust,
exhibiting very good ﬁt with the requirement that all correlations should occur with a magnitude of
>|0.4|. In fact, Grouping 1C exhibits perfect ﬁt even with the requirement that all correlations are >+0.5.
Grammatical text complexity
19

To test that hypothesis, we analyzed the goodness-of-ﬁt of a specialized model
consisting of only these two dimensions, with the added constraint that each feature
within a grouping should negatively correlate with all other features in the opposing
grouping at <−0.2. Thus, in addition to testing whether the features in each dimen-
sion co-occur in texts, the new model tests the further hypothesis that these two
dimensions have a systematic, complementary relation to one another. Table 6
shows that this specialized model exhibits perfect ﬁt, strongly conﬁrming the hy-
pothesis that these two complexity dimensions represent a fundamental opposition
between the typical linguistic styles of spoken discourse versus written discourse.
6 Complexity proﬁles that do not ﬁt the general
models
The results of even the best-ﬁtting model in Table 5 show that we still have much to
learn about the patterning of complexity features. Two of the structural categories
that function syntactically as noun modiﬁers (i.e., 1A: ﬁnite clauses and 1C: phrases as
noun modiﬁers) exhibit good ﬁt, indicating that they function as two distinct
complexity dimensions. And as mentioned above, ﬁnite dependent clauses func-
tioning syntactically as clause-level constituents (3A) also has excellent ﬁt. But the
other speciﬁc groupings in Table 5 have less good ﬁt, and thus they require further
investigation. The extreme example of this type is the two dependent phrase features
that function as clause-level constituents: adverbs and prepositional phrases. These
two features actually have a strong negative correlation of −0.643, in marked
contrast to the model hypothesized correlation of >+0.2. And more generally, none of
the structural groupings of features that function syntactically as other phrase
complements/modiﬁers have good ﬁt.
In some cases, it seems that individual complexity features have their own
peculiar distributions, apparently motivated by their own speciﬁc communicative
functions. For example, none of the four features of non-ﬁnite clauses as phrase
complements/modiﬁers (to-clauses as adverbials, to-clauses as verb complements,
ing-clauses as adverbials, ing-clauses as verb complements) has a positive correlation
with any of the other non-ﬁnite features.
Table : Testing the hypothesis that dimensions C and A occur as complementary discourse styles.
Overall model
SRMR
SRMR for each component
.
C. Dependent phrases as noun modiﬁers – all positively correlating with one
another
.
A. Finite dependent clauses as clause constituents – all positively correlating
with one another
.
The C phrasal complexity features negatively correlating with the A clausal
complexity features
.
20
Biber et al.

In addition, some complexity features occur infrequently with skewed or
restricted distributions, making it less likely that they will have strong positive
correlations with other features. Table 7 presents descriptive statistics for each of the
25 complexity features included in the present study, organized according to the
groupings used in Model 3. The two groupings that have excellent ﬁt (1C and 3A)
comprise features that have high rates of occurrence and small standard deviations
relative to the size of their mean scores (represented by the Coeﬃcient of Variation;
CoV). Most texts have some occurrences of these features. In contrast, many of the
features in the other groupings have extremely low rates of occurrence (often with
mean scores <1.0 per 1,000 words), and large standard deviations relative to the size
of their mean scores (some with CoV > 2). Even more importantly, many texts have no
occurrences of many of these features.
Table : Descriptive statistics for the rates of occurrence (per ,words) of all complexity features.
Complexity feature
Mean
Standard
deviation
Maximum
rate of
occurrence
Coeﬃcient of
variation
(CoV)
% of texts with
no occurrences
A. Finite clauses functioning as noun modiﬁers (SRMR = .)
Finite relative clauses
.
.
.
.
.%
Noun + that complement
clause
.
.
.
.
.%
B. Non-ﬁnite clauses functioning as noun modiﬁers (SRMR = .)
Non-ﬁnite -ed relative
clauses
.
.
.
.
.%
Non-ﬁnite -ing relative
clauses
.
.
.
.
.%
Non-ﬁnite to relative clauses
.
.
.
.
.%
Noun + to complement
clause
.
.
.
.
.%
C. Phrases functioning as noun modiﬁers (SRMR = .)
Attributive adjectives
.
.
.
.
.%
Pre-modifying nouns
.
.
.
.
.%
Of-genitive phrases
.
.
.
.
.%
Other PPs as noun modiﬁer
.
.
.
.
.%
A. Finite clauses functioning as other phrase complements/modiﬁers (SRMR = .)
Adjective + that complement
clause
.
.
.
.
.%
Preposition + WH-clause
.
.
.
.
.%
B. Non-ﬁnite clauses functioning as other phrase complements/modiﬁers (SRMR = .)
Adjective + to complement
clause
.
.
.
.
.%
Grammatical text complexity
21

In a typical correlational study, data would be pre-screened, and variables would
be omitted if they did not have robust distributions. In the present case, though, we
were governed by the actual structural/syntactic distinctions found in the grammatical
system of English. That is, we could not justify simply disregardingcomplexity features
just because they have sparse or skewed distributions – our goal was rather to account
for the organization of the entire set of complexity features. However, the results
reported in Tables 5 and 7 show that future studies will need to explore complemen-
tary approaches to investigate the patterning of complexity features with sparse
distributions.
Beyond the problems with sparse distributions, more detailed consideration of
our results suggests several additional factors that should be explored in future
research. For example, consideration of the individual pairwise correlations suggests
Table : (continued)
Complexity feature
Mean
Standard
deviation
Maximum
rate of
occurrence
Coeﬃcient of
variation
(CoV)
% of texts with
no occurrences
Preposition + ing-clause
.
.
.
.
.%
C. Phrases functioning as other phrase complements/modiﬁers (SRMR = .)
Adjective + prepositional
phrase complement
.
.
.
.
.%
Adverb as adjective modiﬁer
.
.
.
.
.%
A. Finite clauses functioning as clause-level constituents (SRMR = .)
Finite adverbial clauses
.
.
.
.
.%
Verb + that complement
clause
.
.
.
.
.%
Verb + wh complement
clause
.
.
.
.
.%
B. Non-ﬁnite clauses functioning as clause-level constituents (SRMR = .)
Non-ﬁnite to adverbial
clauses
.
.
.
.
.%
Non-ﬁnite -ing adverbial
clauses
.
.
.
.
.%
Verb + to complement clause
.
.
.
.
.%
Verb + -ing complement
clause
.
.
.
.
.%
C. Phrases functioning as clause-level constituents (SRMR = .)
Adverb as clause constituent
.
.
.
.
.%
Prepositional phrase as
clause constituent
.
.
.
.
.%
22
Biber et al.

that it might be productive to analyze structural distinctions at ﬁner levels of detail.
The clearest example of this type is prepositional phrase features, which all correlate
positively with one another regardless of their syntactic functions (see Table 8).
Similarly, the two adverb features, serving diﬀerent syntactic functions – adverbs
modifying an adjective and adverbs modifying a clause – also correlate positively with
one another (r = 0.287). Results like these suggest that certain speciﬁc complexity
structures are to some extent associated with particular discourse meanings and
functions,and thus they tendto co-occur intextsregardlessoftheir syntacticfunctions.
Considerations like these lead to a more general possibility for future research:
organizing complexity features according to their shared discourse functions
(associated with shared register distributions). The main challenge for such an
approach is that it is more interpretive than grouping features based on grammatical
structure or syntactic function. However, there are good reasons to expect that this
will prove to be a productive approach. The complexity features included in the two
groupings with excellent ﬁt (1C and 3A in Tables 5 and 6) turn out to share discourse
functions and register distributions (see discussion above), in addition to their
shared structural/syntactic characteristics.
In other cases, features with completely diﬀerent structural/syntactic charac-
teristics tend to co-occur in texts, apparently because of shared discourse functions.
For example, to adverbial clauses are one of the most specialized features included in
our study, always being used to express the meaning of “purpose”, as in:
There are heuristics that can be used in machine learning, to attempt an automated construction
of a proof.
Because this discourse function is especially prevalent in written academic
discourse, we ﬁnd to adverbial clauses having positive correlations with phrasal
informational complexity features like attributive adjectives (r = 0.23), nouns as NP
premodiﬁers (r = 0.22), and of-genitives (r = 0.27).
A similar example is prepositional phrases as clause constituents, which are
used to express a wide range of informational meanings. In many instances, the
syntactic function of a prepositional phrase is unclear, as in the following example:
Table : Correlations among prepositional phrase features serving diﬀerent syntactic functions.
PPs as clause
constituents
PPs as adjective
complements
PPs as noun
modiﬁers
PPs as adjective
complements
.
PPs as noun modiﬁers
.
.
OF as noun modiﬁers
.
.
.
Grammatical text complexity
23

They may also apply for protective measures for the purposes of conﬁscating property from the
persons prosecuted.
But regardless of whether these phrases are functioning syntactically as noun
modiﬁers or clause constituents, they all serve the discourse function of compressing
information into relatively few words. Apparently reﬂecting this discourse function,
prepositional phrases as clause constituents have positive correlations with phrasal
informational complexity features like attributive adjectives (r = 0.43) and nouns as
NP premodiﬁers (r = 0.26).
In summary, while we do not have space here for detailed exploration of
groupings based on shared discourse functions, we anticipate that this will be a
complementary perspective for future research.
7 Summary and conclusion
The most important conclusion from the analyses undertaken here is that text
complexity is clearly a multi-dimensional construct. This ﬁnding is in marked
contrast to the standard practice of most previous research, which treats text
complexity as a single, uniﬁed construct. In the context of applied linguistic research
on complexity, the ﬁndings here show that the quest for a single “best measure” of
grammatical complexity is misguided. In addition, these ﬁndings show that the use of
multiple omnibus measures (a practice common in recent applied linguistic studies)
fails to adequately capture the multi-dimensional space of variation among
complexity features.
A second major generalization from the results presented above is that the
structural and syntactic distinctions of standard linguistic theory are important for the
study of text complexity. We have considered here only three general types of struc-
tural distinctions, and three general syntactic distinctions. But these distinctions are
already much more speciﬁc than those assumed by most previous quantitative studies
of text complexity; and the results clearly show that these distinctions matter for any
comprehensive account of text complexity. In the context of applied linguistic research
on complexity in learner discourse, the ﬁndings here show that the application of
omnibus measures of text complexity is misguided. This is the case for both so-called
global complexity measures (e.g., mean length of t-units) as well as so-called speciﬁc
measures of complexity (e.g., mean length of clauses). The reason is that both types of
omnibus measure share the problem that they collapse and confound multiple
structural and syntactic distinctions that pattern in fundamentally diﬀerent ways.
Third, the results here show that syntactic distinctions are actually more
important than structural distinctions. This is a very surprising ﬁnding, in marked
24
Biber et al.

contrast to most previous studies of complexity which completely disregard syntactic
distinctions.11 However, although syntactic distinctions are more important than
structural distinctions, considering both together clearly provides the best account of
textual co-occurrence patterns. The most important take-away from those analyses is
that an adequate analysis of text complexity requires much more attention to
structural/syntactic detail and sophistication than researchers have usually invested
in the past.
Thus, the results of the present study show that some groupings of complexity
features pattern together as underlying dimensions of grammatical text complexity.
Other complexity features have their own peculiar distributions, apparently moti-
vated by specialized discourse functions; future research is required to further
explore those distributions and functions. However, it is clear at this point that
grammatical text complexity must be described in a multi-dimensional space, taking
into account both structural distinctions as well as the syntactic functions of those
structures.
References
Biber, Douglas. 1988. Variation across speech and writing. Cambridge: Cambridge University Press.
Biber, Douglas. 1992. On the complexity of discourse complexity: A multidimensional analysis. Discourse
Processes 15. 133–163.
Biber, Douglas. 2014. Using multi-dimensional analysis to explore cross-linguistic universals of register
variation. Languages in Contrast 14. 7–34.
Biber, Douglas & Bethany Gray. 2016. Grammatical complexity in academic English: Linguistic change in
writing. Cambridge: Cambridge University Press.
Biber, Douglas, Bethany Gray, Shelley Staples & Jesse Egbert. 2020. Investigating grammatical complexity
in L2 English writing research: Linguistic description versus predictive measurement. Journal of
English for Academic Purposes 46. 100869.
Biber, Douglas, Bethany Gray, Shelley Staples & Jesse Egbert. 2022. The register-functional approach to
grammatical complexity. New York: Routledge.
Biber, Douglas, Stig Johansson, Geoﬀrey Leech, Susan Conrad & Edward Finegan. 2021. Grammar of spoken
and written English. Amsterdam: John Benjamins. [Previously published in 1999 by Longman].
Biber, Douglas, Tove Larsson & Gregory R. Hancock. 2023. Dimensions of text complexity in the spoken
and written modes: A comparison of theory-based models. Journal of English Linguistics.
Bulté, Bram & Alex Housen. 2012. Deﬁning and operationalising L2 complexity. In Alex Housen,
Folkert Kuiken & Ineke Vedder (eds.), Dimensions of L2 performance and proﬁciency. Complexity,
accuracy and ﬂuency in SLA, 21–46. Amsterdam: Benjamins.
11 In fact, many applied studies do not recognize the linguistic distinction between grammatical
structure and syntactic function, employing the term syntactic complexity to refer primarily to
structural considerations.
Grammatical text complexity
25

Bulté, Bram & Alex Housen. 2014. Conceptualizing and measuring short-term changes in L2 writing
complexity. Journal of Second Language Writing 26. 42–65.
Carter, Ron & Michael McCarthy. 2006. Cambridge grammar of English. Cambridge: Cambridge University
Press.
Crystal, David. 1997. The Cambridge encyclopedia of language, vol. 2. Cambridge: Cambridge University
Press.
Hawkins, John A. 2004. Eﬃciency and complexity in grammars. Oxford: Oxford University Press.
Huddleston, Rodney. 1984. Introduction to the grammar of English. Cambridge: Cambridge University
Press.
Huddleston, Rodney & Geoﬀrey K. Pullum. 2002. The Cambridge grammar of the English language.
Cambridge: Cambridge University Press.
Kortmann, Bernd & Benedikt Szmrecsanyi (eds.). 2012. Linguistic complexity: Second language acquisition,
indigenization, contact. Berlin: Walter de Gruyter.
Larsson, Tove, Luke Plonsky & Gregory R. Hancock. 2021. On the beneﬁts of structural equation modeling
for corpus linguists. Corpus Linguistics and Linguistic Theory 17. 683–714.
Lu, Xiaofei. 2010. Automatic analysis of syntactic complexity in second language writing. International
Journal of Corpus Linguistics 15. 474–496.
Lu, Xiaofei. 2011. A corpus-based evaluation of syntactic complexity measures as indices of college-level
ESL writer’s language development. TESOL Quarterly 45. 36–61.
Lu, Xiaofei. 2017. Automated measurement of syntactic complexity in corpus-based L2 writing research
and implications for writing assessment. Language Testing 34. 493–511.
McWhorter, John. 2001. The world’s simplest grammars are creole grammars. Linguistic Typology 5.
125–166.
Newmeyer, Frederick J. 2001. The Prague school and North American functionalist approaches to syntax.
Journal of Linguistics 37. 101–126.
Newmeyer, Frederick J. & Laurel B. Preston (eds.). 2014. Measuring grammatical complexity. Oxford: Oxford
University Press.
Nichols, Johanna. 1984. Functional theories of grammar. Annual Review of Anthropology 13. 97–117.
Nichols, Johanna. 2013. The vertical archipelago: Adding the third dimension to linguistic geography. In
Peter Auer, Martin Hilpert, Anja Stukenbrock & Benedikt Szmrecsanyi (eds.), Space in language and
linguistics: Geographical, interactional, and cognitive perspectives. Berlin, New York: Walter de Gruyter.
Norris, John M. & Lourdes Ortega. 2009. Towards an organic approach to investigating CAF in SLA: The
case of complexity. Applied Linguistics 30. 555–578.
Ortega, Lourdes. 2015. Syntactic complexity in L2 writing: Progress and expansion. Journal of Second
Language Writing 29. 404–415.
Pallotti, Gabriele. 2009. CAF: Deﬁning, reﬁning and diﬀerentiating constructs. Applied Linguistics 30.
590–601.
Pallotti, Gabriele. 2015. A simple view of linguistic complexity. Second Language Research 31. 117–134.
Purpura, James E. 2004. Assessing grammar. Cambridge: Cambridge University Press.
Quirk, Randolph, Sidney Greenbaum, Geoﬀrey Leech & Jan Svartvik. 1985. A comprehensive grammar of the
English language. London: Longman.
Sampson, Geoﬀrey, David Gil & Peter Trudgill (eds.). 2009. Language complexity as an evolving variable.
Oxford: Oxford University Press.
Siegel, Jeﬀ, Benedikt Szmrecsanyi & Bernd Kortmann. 2014. Measuring analyticity and syntheticity in
Creoles. Journal of Pidgin and Creole Languages 29. 49–85.
Szmrecsanyi, Benedikt. 2009. Typological parameters of intralingual variability: Grammatical analyticity
versus syntheticity in varieties of English. Language Variation and Change 21. 319–353.
26
Biber et al.

Szmrecsanyi, Benedikt. 2015. Recontextualizing language complexity. In Jocelyne Daems, Eline Zenner,
Kris Heylen, Dirk Speelman & Hubert Cuyckens (eds.), Change of paradigms: New paradoxes:
Recontextualizing language and linguistics. Applications of cognitive linguistics, vol. 31, 347–360. Berlin:
De Gruyter Mouton.
Willis, Dave. 2003. Rules, patterns and words: Grammar and lexis in English language teaching. Cambridge:
Cambridge University Press.
Wolfe-Quintero, Kate, Shunji Inagaki & Hae-Young Kim. 1998. Second language development in writing:
Measures of ﬂuency, accuracy, and complexity. Honolulu: University of Hawaii. Technical Report No. 17.
Supplementary Material: This article contains supplementary material (https://doi.org/10.1515/cllt-
2023-0016).
Grammatical text complexity
27

