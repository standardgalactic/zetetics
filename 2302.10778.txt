The Stochastic-Quantum Correspondence
Jacob A. Barandes1, ∗
1Jeﬀerson Physical Laboratory, Harvard University, Cambridge, MA 02138
(Dated: February 22, 2023)
This paper introduces a precise correspondence between the theory of stochastic processes and
quantum theory. This correspondence provides a new framework for using Hilbert-space methods to
formulate highly generic types of stochastic dynamics, with potential applications throughout the
sciences. This paper also uses the correspondence in the other direction to reconstruct quantum
theory in general from physical models that consist of classical kinematics combined with stochastic
dynamics. This reconstruction approach opens up new ways of understanding quantum-theoretic
phenomena like interference, decoherence, entanglement, noncommutative observables, and wave-
function collapse.
I.
INTRODUCTION
The theory of stochastic processes describes the phe-
nomenological behavior of systems with deﬁnite conﬁg-
urations that evolve in time according to probabilistic
laws. Quantum theory is a comprehensive mathemati-
cal apparatus for making measurement predictions when
taking into account the microscopic constituents of var-
ious kinds of physical systems, from subatomic particles
to superconductors. At an empirical level, both theories
involve probabilities, and at the level of formalism, both
employ vectors and matrices.
There have been a number of previous attempts in
the literature to identify a fundamental relationship con-
necting stochastic-processes theory and quantum the-
ory [1–7]. This paper introduces a new and fully general
correspondence between these two theories in the form
of a simple ‘dictionary’ expressing any time-dependent
stochastic matrix in terms of a suitable combination of
Hilbert-space ingredients.
On the one hand, from a practical standpoint, this
‘stochastic-quantum correspondence’ provides a system-
atic framework for constructing highly generic forms of
stochastic dynamics, much as the classical Lagrangian or
Hamiltonian formulations of classical mechanics provide
systematic frameworks for constructing deterministic dy-
namics. Potential applications range from turbulence to
ﬁnance, to name just two examples. Importantly, this
stochastic-quantum correspondence does not require as-
suming that the stochastic dynamics in question can be
modeled as a Markov chain, nor does it require making
any other frequently deployed approximations.
Taking a more foundational perspective, this pa-
per also uses this stochastic-quantum correspondence
∗barandes@g.harvard.edu
to show that physical models based on classical kine-
matics combined with stochastic dynamics can repli-
cate all the empirical predictions of textbook quantum
theory—including interference, decoherence, entangle-
ment, noncommutative observables, and wave-function
collapse—without relying on the austere and metaphys-
ically opaque Dirac-von Neumann axioms [8, 9]. In this
alternative approach, systems have physical conﬁgura-
tions in classical conﬁguration spaces, and the mathe-
matical objects of the Hilbert-space formulation serve a
functional role akin to gauge-theoretic degrees of free-
dom.
In addition to establishing these new results, this pa-
per identiﬁes several forms of gauge invariance that have
not previously been described in the literature, analyzes
the measurement process in detail, and describes the im-
plications of the stochastic-quantum correspondence for
dynamical symmetries and for formal enlargements or di-
lations of a system’s Hilbert space. Taking advantage of
having a concrete model of stochastic hidden variables in
hand, this paper also revisits and clariﬁes a number of
important questions related to the status of nonlocality
in quantum theory.
Given the mathematical simplicity of this stochastic-
quantum correspondence, it is surprising that it has ap-
parently not shown up in the literature before. To the au-
thor’s knowledge, the only previous example that bears
a suggestive resemblance to the approach taken in this
paper, at least at the level of some of its equations, is the
unpublished draft [6].1 Although that reference argues
that some stochastic processes can be modeled using a
formalism similar to that of quantum theory, it does not
establish that the resulting Hilbert-space representation
is fully general. Nor does it attempt to show that the
correspondence is bidirectional, so that quantum systems
can be modeled by stochastic processes on classical con-
ﬁguration spaces.
1 The author thanks Logan McCarty for ﬁnding this reference.
arXiv:2302.10778v1  [quant-ph]  20 Feb 2023

2
II.
STOCHASTIC PROCESSES
In the theory of stochastic processes [10], one starts
with a conﬁguration space C and a stochastic map Γ(t)
that acts linearly on probability distributions over C at
an initial time t = 0 to yield corresponding probability
distributions over C at other times t ̸= 0. The formalism
is easiest to express in the case in which C has a ﬁnite
number N of conﬁgurations labeled by positive integers
1, . . . , N:
C ≡{1, . . . , N}.
(1)
In that case, the probabilities at t = 0 can be denoted by
pj(0)
[j = 1, . . . , N],
(2)
the probabilities at t ̸= 0 can be denoted by
pi(t)
[i = 1, . . . , N],
(3)
and the stochastic map consists of conditional probabili-
ties
Γij(t) ≡p(i, t|j, 0)
[i, j = 1, . . . , N],
(4)
where p(i, t|j, 0) denotes the conditional probability for
the system to be in its ith conﬁguration at the time t,
given that it is in its jth conﬁguration at the time 0.
(Note that no assumption is made here about whether
t > 0 or t < 0.)
Being probabilities, these quantities
satisfy
pj(0), pi(t) ≥0,
N
X
j=1
pj(0) =
N
X
i=1
pi(t) = 1,
(5)
and
Γij(t) ≥0,
N
X
i=1
Γij(t) = 1.
(6)
Then from marginalization, one has the linear relation-
ship
pi(t) =
N
X
j=1
Γij(t)pj(0),
(7)
where the initial probabilities pj(0) are arbitrary and can
therefore be freely adjusted without altering the condi-
tional probabilities Γij(t).
Letting p(0) denote the N × 1 column vector with en-
tries given by the probabilities pj(0), letting p(t) denote
the analogous N × 1 vector with entries given by pi(t),
and letting Γ(t) denote the time-dependent N × N ma-
trix consisting of the conditional probabilities Γij(t), one
can recast the linear relationship (7) in matrix form as
p(t) = Γ(t)p(0).
(8)
The conditions (6) on Γ(t) identify it as a (left) stochastic
matrix. On physical grounds, Γ(t) will be assumed to
satisfy the continuity condition that in the limit t →0,
it approaches the N × N identity matrix 1:
lim
t→0 Γ(t) = 1 ≡diag(1, . . . , 1).
(9)
Next, consider a random variable A(t) with (not nec-
essarily unique) magnitudes a1(t), . . . , aN(t) determined
by the system’s conﬁguration i = 1, . . . , N, and possibly
also depending explicitly on the time t. Then the expec-
tation value ⟨A(t)⟩is deﬁned as the statistical average
or mean of the magnitudes of A(t) over the probability
distribution at t:
⟨A(t)⟩≡
N
X
i=1
ai(t)pi(t) =
N
X
i=1
N
X
j=1
ai(t)Γij(t)pj(0).
(10)
One can go on to deﬁne the standard deviation and var-
ious statistical moments of A(t) by appropriate general-
izations of this basic deﬁnition.
All these formulas can be extended to systems with
continuous conﬁguration spaces.
For a system with a
continuous conﬁguration space C, one uses probability
densities p(y, 0) at t = 0 and p(x, t) at t ̸= 0, where
x and y each symbolically denotes a set of real-valued
coordinates. The linear relationship (7) then becomes
p(x, t) =
Z
C
dµ(y) Γ(x, y, t)p(y, 0),
(11)
where dµ(y) is a suitable integral measure over C and
where the conditional probability density Γ(x, y, t) natu-
rally serves as an integral kernel. A random variable A(t)
then has magnitudes a(x, t) labeled by x and t, and its
expectation value (10) becomes
⟨A(t)⟩≡
Z
C
dµ(x) a(x, t)p(x, t)
=
Z
C
dµ(x)
Z
C
dµ(y) a(x, t)Γ(x, y, t)p(y, 0).







(12)
For ease of exposition, the discrete case will be assumed
going forward.
Equations like (7), (9), and (11) may appear to single
out t = 0 as a special time. Section IX, however, will
show that for systems in suﬃciently strong contact with
a noisy environment, t = 0 need not actually be a unique
time, but will typically be only one of many times that
play a similar role.
III.
CONVENTIONAL APPROXIMATIONS
In textbook treatments of stochastic processes [10],
one often introduces various approximations or simpli-
ﬁcations of a system’s time-dependent stochastic matrix

3
Γ(t) to make it easier to construct and describe. A typical
such approximation is to assume a discrete-time Markov
chain, meaning that for some small but ﬁnite time scale
∆t, one can express the time-dependent stochastic ma-
trix Γ(t = n ∆t) at any integer number n ≥1 of steps of
duration ∆t as n powers of a constant stochastic matrix
Γ:
Γ(t = n ∆t) = Γn.
(13)
Somewhat more generally, a convenient simpliﬁcation
is to assume that for any two times t and t′ satisfying
t > t′ > 0, one has the composition law
Γ(t) = Γ(t ←t′)Γ(t′),
(14)
which is known as divisibility [11]. Here Γ(t ←t′) is like-
wise required to be a stochastic matrix, in the sense that
its entries are all non-negative and its columns each sum
to 1, as in (6).
An even more special simpliﬁcation is to take Γ(t) to be
a time-dependent permutation matrix, meaning a matrix
whose rows and columns are permutations of the N × N
identity matrix 1. In that case, Γ(t) does not contain
nontrivial probabilities at all, and the system transitions
deterministically from one conﬁguration to another in its
conﬁguration space C. In a suitable continuum limit N →
∞, the time evolution reduces to smooth, deterministic
dynamics.
Absent these sorts of approximations or simpliﬁca-
tions, one is confronted with the task of constructing a
time-dependent, generically ‘indivisible’ N×N stochastic
matrix Γ(t) for a given conﬁguration space C, ideally in a
systematic way. For small conﬁguration spaces, it is easy
to devise smoothly time-dependent, indivisible examples,
like the 2 × 2 stochastic matrix
Γ(t) ≡
 
e−t2/τ 2
1 −e−t2/τ 2
1 −e−t2/τ 2
e−t2/τ 2
!
,
(15)
where τ is a constant with units of time, or
Γ(t) ≡

cos2 ωt sin2 ωt
sin2 ωt cos2 ωt

,
(16)
where ω is a constant with units of inverse-time.
It may not seem obvious how to construct smoothly
time-dependent stochastic matrices Γ(t) systematically,
especially in the case of large (N ≫1) conﬁguration
spaces. A suﬃciently general approach for accomplish-
ing this task could have numerous practical applications
in many scientiﬁc and technical ﬁelds. Ideally, one im-
mediate application would be making it possible to de-
rive a self-contained theoretical justiﬁcation for why the
Markov and divisibility approximations work so well in
many real-world cases.
IV.
THE HILBERT-SPACE FORMULATION
This paper introduces a novel and highly general
framework for formulating time-dependent stochastic
matrices Γ(t), conceptually akin to the Lagrangian or
Hamiltonian frameworks for formulating deterministic
dynamics for mechanical systems.
The starting place is to ‘solve’ the non-negativity con-
dition Γij(t) ≥0 of the individual entries of Γ(t) by ex-
pressing them in the following way:
Γij(t) = |Θij(t)|2.
(17)
This equation is not a postulate—it is a mathematical
identity.
The N × N matrix Θ(t) introduced in (17) is guaran-
teed to exist, although it is not unique. Its entries Θij(t)
could be taken to be the real square roots of the corre-
sponding quantities Γij(t), but they could also include
complex numbers, quaternions, or even the elements of
a more general normed algebra (although associativity is
a very helpful property to require). To keep things sim-
ple, this paper will assume that Θij(t) involves only the
complex numbers.
On account of the general properties of Γ(t) speciﬁed
in (6), note that the matrix Θ(t) must satisfy
N
X
i=1
|Θij(t)|2 = 1.
(18)
For now, no further conditions, such as unitarity, will
be imposed on Θ(t), whose signiﬁcance will soon become
more clear.
There are several helpful ways to re-express the iden-
tity (17). To begin, introduce the Schur-Hadamard prod-
uct ⊙, which is deﬁned for arbitrary N × N matrices X
and Y as entry-wise multiplication [12–14]:
(X ⊙Y )ij ≡XijYij.
(19)
One can then regard (17) as expressing the stochastic
matrix Γ(t) as a Schur-Hadamard factorization of the
complex-conjugated matrix Θ(t) with Θ(t) itself:
Γ(t) = Θ(t) ⊙Θ(t).
(20)
Schur-Hadamard products are not widely used in linear
algebra, in part because they are not basis-independent.
For the purposes of analyzing a given stochastic system,
however, the system’s conﬁguration space C naturally sin-
gles out a speciﬁc basis, to be deﬁned momentarily.
As an alternative approach that will turn out to have
signiﬁcant ramiﬁcations, start by deﬁning an N-member
collection of constant, diagonal N × N projection matri-
ces P1, . . . , PN, which will be called ‘conﬁguration projec-
tors.’ For each i = 1, . . . , N, the conﬁguration projector

4
Pi consists of a single 1 in its ith row, ith column, and
0s in all its other entries. That is, Pi is deﬁned as
Pi ≡diag(0, . . . , 0, 1
↑
ith entry
, 0, . . . , 0),
(21)
with individual entries
Pi,jk = δijδik,
(22)
where δij is the usual Kronecker delta:
δij ≡
(
1
for i = j,
0
for i ̸= j.
(23)
It follows immediately that these conﬁguration projectors
satisfy the conditions of mutual exclusivity,
PiPj = δijPi,
(24)
and completeness,
N
X
i=1
Pi = 1,
(25)
where again 1 is the N × N identity matrix. The con-
ﬁguration projectors P1, . . . , PN therefore constitute a
projection-valued measure (PVM) [15, 16].
Letting tr( ) denote the usual matrix trace, one can
then recast (17) instead as
Γij(t) = tr(Θ†(t)PiΘ(t)Pj).
(26)
This equation is a new result. It will turn out to serve as
an important ‘dictionary’ between the classical theory of
stochastic processes, as symbolized by Γij(t) on the left-
hand side, and an expansive set of mathematical tools
for constructing stochastic dynamics, as embodied by the
right-hand side.2
To understand what these mathematical tools are, in-
troduce a set of N × 1 column vectors e1, . . . , eN, where
ei has a 1 in its ith component and 0s in all its other
components. That is, ei has components
ei,j = δij.
(27)
It follows that the column vectors e1, . . . , eN form an or-
thonormal basis for the vector space of all N × 1 column
vectors, so e1, . . . , eN will be called the system’s ‘conﬁg-
uration basis.’ In particular,
e†
iej = δij,
eie†
i = Pi,
(28)
2 Similar-looking formulas appear in equations (3)–(6) of [17] as
an intermediate step in proving a lemma used for conceptually
diﬀerent purposes.
where Pi is the ith conﬁguration projector, as deﬁned in
(21).
Hence, the right-hand side of the dictionary (26) is a
trace over a Hilbert space H, meaning a complete inner-
product space over the complex numbers.
The dictio-
nary therefore provides a Hilbert-space formulation for
constructing generic forms of stochastic dynamics.
Substituting the right-hand side of the dictionary (26)
into the linear relationship (7) between the probabilities
pj(0) at t = 0 and the probabilities pi(t) at t ̸= 0, one
ﬁnds that
pi(t) = tr(Piρ(t)),
(29)
where ρ(t) is a time-dependent, self-adjoint, unit-trace,
generically non-diagonal N × N matrix deﬁned as
ρ(t) ≡Θ(t)


N
X
j=1
pj(0)Pj

Θ†(t)
= Θ(t)diag(. . . , pj(0), . . . )Θ†(t)
= ρ†(t),
tr(ρ(t)) = 1.



















(30)
Similarly, by substituting the formula (29) for pi(t) into
the deﬁnition (10) of the expectation value of a random
variable A(t), one obtains
⟨A(t)⟩= tr(A(t)ρ(t)),
(31)
where A(t) is now understood to be the diagonal N × N
matrix deﬁned as
A(t) ≡
N
X
i=1
ai(t)Pi = diag(. . . , ai(t), . . . ).
(32)
In the special case in which the system’s probability
distribution at t = 0 is pure, meaning that one of the
system’s conﬁgurations j is occupied with probability 1,
the system’s probability vector at t = 0 is equal to the
jth vector ej in the conﬁguration basis (27):
p(0) = ej
[pure].
(33)
Deﬁning a unit-norm, N × 1 column vector
Ψ(t) ≡Θ(t)ej

Ψ†(t)Ψ(t) = 1

,
(34)
which is ultimately just the jth column of Θ(t), the ith
component Ψi(t) of Ψ(t) is a purely law-like quantity
equal to the speciﬁc matrix entry Θij(t):
Ψi(t) = Θij(t).
(35)
It follows immediately that the self-adjoint matrix ρ(t)
deﬁned in (30) is rank-one and has factorization
ρ(t) = Ψ(t)Ψ†(t)
[pure].
(36)

5
The probability formula (29) then simpliﬁes to
pi(t) = |Ψi(t)|2,
(37)
and the formula (31) for the expectation value of a ran-
dom variable A(t) becomes
⟨A(t)⟩= Ψ†(t)A(t)Ψ(t).
(38)
Looking at all these results, one notices a striking re-
semblance to mathematical objects and formulas that are
familiar from textbook quantum theory.3
Speciﬁcally,
one sees that Θ(t) plays the role of a time-evolution op-
erator, ρ(t) is a density matrix, Ψ(t) is a state vector or
wave function, and A(t) represents an observable. The
probability formulas (29) and (37) have the same form
as the Born rule, and (31) and (38) have the same form
as quantum-theoretic expectation values.
These formulas are all expressed in what would con-
ventionally be called the Schr¨odinger picture. One could
instead work in the Heisenberg picture, with the deﬁni-
tions
ρH ≡ρ(0),
ΨH ≡Ψ(0),
AH(t) ≡Θ†(t)A(t)Θ(t),
)
(39)
where AH(t) now includes both a possible explicit de-
pendence on time through its magnitudes ai(t) as well as
implicit dependence on time through the time-evolution
operator Θ(t). The probability formula (29) would then
become4
pi(t) = tr(P H(t)ρH),
(40)
and the formula (31) for expectation values would be-
come
⟨A(t)⟩= tr(AH(t)ρH).
(41)
Despite the similarity to expressions found in quan-
tum theory, as well as the appearance of non-diagonal
matrices, it is important to keep in mind that the sys-
tem under investigation here is always fundamentally in
a speciﬁc conﬁguration i = 1, . . . , N in its conﬁguration
space C at any given time, and that the system’s dynam-
ics is completely captured by the stochastic matrix Γ(t),
whose entries are conditional probabilities p(i, t|j, 0), in
accordance with (4).
The mathematical objects Θ(t),
ρ(t), Ψ(t), A(t), despite being extremely useful, are not
uniquely deﬁned by C or Γ(t).
3 For pedagogical treatments of quantum theory, see [18–22].
4 Note that for a generic time-evolution operator Θ(t),
the
Heisenberg-picture version P H
i (t) ≡Θ†(t)PiΘ(t) of a projector
Pi will not likewise be a projector.
V.
GAUGE TRANSFORMATIONS
To make this non-uniqueness more manifest, it will be
helpful to introduce an analogy with the Maxwell theory
of classical electromagnetism.5
In classical electromagnetism, the electric and mag-
netic ﬁelds are physically meaningful quantities, but it is
often very convenient to work instead in terms of scalar
and vector potentials, which are not uniquely deﬁned.
All choices for the potentials that yield the same elec-
tric and magnetic ﬁelds are said to be related by gauge
transformations, and any one such choice for the poten-
tials is called a gauge choice. Making a suitable gauge
choice can greatly simplify many calculations, such as us-
ing Lorenz gauge to compute the electric and magnetic
ﬁelds for delayed boundary conditions. Ultimately, how-
ever, all calculations of physical predictions in classical
electromagnetism must conclude with expressions that
are written in terms of gauge-invariant quantities.
To set up the claimed analogy with electromagnetic
gauge transformations, start by observing that the Schur-
Hadamard product of the time-evolution operator Θ(t)
with a matrix of time-dependent phases exp(iθij) is a
transformation of Θ(t) with no physical eﬀects, and
therefore corresponds to a genuine form of gauge invari-
ance:
Θ(t) 7→Θ(t) ⊙



eiθ11(t) eiθ12(t)
eiθ21(t)
...
eiθNN(t)


.
(42)
This gauge transformation can be written equivalently at
the level of individual matrix entries as
Θij(t) 7→Θij(t)eiθij(t).
(43)
To the author’s knowledge, this kind of gauge invariance,
which could be called a ‘Schur-Hadamard gauge transfor-
mation,’ has not yet been described in the literature. It
will turn out to play a key role in the analysis of dynam-
ical symmetries that will be presented in Section XVI,
and will be extended in an interesting way in the context
of Hilbert-space dilations in Section XVII.
The Hilbert-space formulation has another form of
gauge invariance, which appears to have ﬁrst been writ-
ten down in [26] in the context of transformations of the
Schr¨odinger equation between inertial and non-inertial
reference frames. Letting V (t) be a time-dependent uni-
tary matrix, the following transformation is also a gauge
invariance of the Hilbert-space formulation, leaving all
probabilities pi(t), expectation values ⟨A(t)⟩, and the
5 For pedagogical treatments of classical electromagnetism, see
[23–25].

6
stochastic matrix Γ(t) as a whole unchanged:6
ρ(t) 7→ρV (t) ≡V (t)ρ(t)V †(t),
Ψ(t) 7→ΨV (t) ≡V (t)Ψ(t),
A(t) 7→AV (t) ≡V (t)A(t)V †(t),
Θ(t) 7→ΘV (t) ≡V (t)Θ(t)V †(0).











(44)
If the unitary matrix V (t) is time-independent, then
the gauge transformation (44) is merely a change of ba-
sis. However, if V (t) depends nontrivially on time, and if
one regards the system’s Hilbert space at each moment
in time as a ﬁber over a one-dimensional base manifold
parameterized by the time coordinate t, then V (t) rep-
resents a local-in-time, unitary transformation of each
individual Hilbert-space ﬁber. In particular, any given
time-dependent state vector Ψ(t), regarded as a trajec-
tory through the Hilbert space H, can be mapped to any
other trajectory by a suitable choice of time-dependent
unitary matrix V (t), so trajectories in H do not describe
gauge-invariant facts.
VI.
KRAUS DECOMPOSITIONS
In the most general case, a time-evolution operator
Θ(t) may not satisfy any nontrivial constraints apart
from (18). It will turn out to be helpful to ﬁnd alter-
native ways of representing the N × N matrix Θ(t) in
terms of more tightly constrained mathematical objects.
For β = 1, . . . , N, let Kβ(t) be the N × N matrix
deﬁned to share its βth column with Θ(t), but with 0s in
all its other entries:
Kβ(t) ≡



0 · · · 0 Θ1β(t) 0 · · · 0
...
...
...
...
...
...
...
0 · · · 0 ΘNβ(t) 0 · · · 0



[β = 1, . . . , N].
(45)
The entries of Kβ(t) are given explicitly by
Kβ,ij(t) = δβjΘij(t).
(46)
Then the summation condition (18) on Θ(t) becomes the
statement that the matrices K1(t), . . . , KN(t) satisfy the
Kraus identity
N
X
β=1
K†
β(t)Kβ(t) = 1,
(47)
so these matrices are called Kraus operators [27]. One
can then write the dictionary (26) in an alternative form
6 Note the appearance of t = 0 in V †(0) in the transformation rule
for Θ(t).
called a Kraus decomposition:
Γij(t) =
N
X
β=1
tr(K†
β(t)PiKβ(t)Pj).
(48)
Like all the other mathematical objects in the Hilbert-
space formulation, the Kraus operators K1(t), . . . , KN(t)
are not unique. Notice also that any number of N × N
matrices satisfying the Kraus identity (47) are guaran-
teed to yield a valid stochastic matrix Γ(t) via the Kraus
decomposition (48).7
VII.
UNISTOCHASTIC DYNAMICS
In the most minimal case in which the stochastic ma-
trix Γ(t) is determined by just a single Kraus operator
K1(t), that Kraus operator will be denoted instead by
U(t). In that case, the general Schur-Hadamard factor-
ization (20) specializes to
Γ(t) = U(t) ⊙U(t).
(49)
That is,
Γij(t) = |Uij(t)|2,
(50)
or, equivalently, in dictionary form (26),
Γij(t) = tr(U †(t)PiU(t)Pj).
(51)
The Kraus identity (47), meanwhile, reduces to the state-
ment that U(t) is unitary,
U †(t) = U −1(t),
(52)
and Γ(t) is then said to be unistochastic [29, 30].8 It fol-
lows immediately from the dictionary formula (51) that
every unistochastic matrix is doubly stochastic, meaning
that summing over its rows or its columns yields 1:
N
X
i=1
Γij(t) =
N
X
j=1
Γij(t) = 1.
(53)
Note that U(t) will not generically remain unitary un-
der Schur-Hadamard gauge transformations (42), so writ-
ing a unistochastic matrix Γ(t) in terms of a unitary time-
evolution operator U(t) corresponds to making a gauge
7 Kraus operators and Kraus decompositions play an important
role in quantum information theory. They provide (non-unique)
expressions for speciﬁc generalizations of unitary time evolu-
tion known as quantum channels, or completely positive trace-
preserving (CPTP) maps. In particular, conditional probabilities
similar in form to (48) were studied in [28].
8 In Section XVII, it will be shown that all stochastic matrices
can be expressed in terms of a unitary time-evolution operator
on a suitably enlarged or dilated Hilbert space, so assuming unis-
tochastic dynamics is not as special a condition as it might seem.

7
choice—or, somewhat more precisely, to partially ﬁxing
the gauge freedom (42). Notice also that every permu-
tation matrix is unitary, so deterministic dynamics is a
special case of unistochastic dynamics.
Assuming that U(t) is a diﬀerentiable function of the
time t, one can deﬁne a corresponding self-adjoint gen-
erator H(t), called the system’s Hamiltonian, according
to
H(t) ≡iℏ∂U(t)
∂t
U †(t) = H†(t).
(54)
Here the factor of i ensures that H(t) is self-adjoint, and,
for present purposes, ℏis a ﬁxed constant introduced for
purposes of units.
In terms of the Hamiltonian, the system’s density op-
erator ρ(t) then evolves in time according to the von Neu-
mann equation,
iℏ∂ρ(t)
∂t
= [H(t), ρ(t)],
(55)
its state vector Ψ(t) (if it exists) evolves according to the
Schr¨odinger equation,
iℏ∂Ψ(t)
∂t
= H(t)Ψ(t),
(56)
its Heisenberg-picture random variables AH(t) evolve ac-
cording to the Heisenberg equation of motion,
dAH(t)
dt
= i
ℏ[HH(t), AH(t)] +
∂A(t)
∂t
H
,
(57)
and its expectation values ⟨A(t)⟩evolve according to the
Ehrenfest equation,
d⟨A(t)⟩
dt
= i
ℏtr([H(t), A(t)]ρ(t)) +
∂A(t)
∂t

.
(58)
The matrix HH(t) appearing in the Heisenberg equa-
tion of motion (57) is the Hamiltonian in the Heisenberg
picture. Note also that the brackets [X, Y ] that natu-
rally show up in these equations are genuine commutators
XY −Y X, not Poisson brackets, and involve products
of non-diagonal matrices that do not generally commute
with each other under multiplication.
The emergence of these famous equations from a phys-
ical model based on classical kinematics—with a classical
conﬁguration space C—is a surprising new result.
If the system’s time-evolution operator Θ(t) = U(t)
is indeed unitary, then under the unitary gauge trans-
formation deﬁned by (44), the Hamiltonian transforms
precisely as a non-Abelian gauge potential:9
H(t) 7→HV (t)
= V (t)H(t)V †(t) −iℏV (t)∂V †(t)
∂t
.



(59)
9 For pedagogical treatments of non-Abelian gauge theories, see
[31, 32].
This transformation behavior makes clear that a Hamil-
tonian is not a gauge-invariant observable, even though
it may happen to coincide with various observables ac-
cording to particular gauge choices.
Moreover, one can write the Schr¨odinger equation (56)
as
D(t)Ψ(t) = 0.
(60)
Here D(t) is a gauge-covariant derivative deﬁned accord-
ing to
D(t) ≡1 ∂
∂t + i
ℏH(t).
(61)
These formulas make manifest that the Hilbert-space
formulation of a stochastic system is ultimately a col-
lection of gauge-dependent quantities. Hence, although
a Hilbert-space formulation may be extremely useful for
constructing stochastic dynamics or for carrying out cal-
culations, one should be suspicious about trying to assign
direct physical meanings to its mathematical ingredients.
Notice that if one picks
V (t) ≡U †(t),
(62)
then the Hamiltonian precisely vanishes:
HV (t) = 0.
(63)
This choice of gauge is nothing other than the deﬁnition
(39) of the Heisenberg picture.
Unitary gauge trans-
formations (44) can therefore be viewed as generalized
changes of time-evolution picture.10
VIII.
INTERFERENCE
The appearance of the Schr¨odinger equation (56) is an
important signal that the dictionary (26) is more than
just a tool for using Hilbert-space methods to craft highly
general forms of stochastic dynamics.
It also suggests
that stochastic dynamics might have the resources to
replicate the features of quantum theory more broadly.
As another hint pointing in this direction, start by not-
ing that an arbitrary time-dependent stochastic matrix
Γ(t) is generically indivisible, in the sense that it does not
satisfy the divisibility property (14) at arbitrary times.
To see what goes wrong, suppose that at some time t′,
Γ(t′) has a matrix inverse Γ−1(t′), and let
˜Γ(t ←t′) ≡Γ(t)Γ−1(t′).
(64)
10 The fact that one can set HV (t) = 0 for all t is a manifestation of
the fact that the ﬁber bundle in this case, consisting of copies of
the system’s Hilbert space over a one-dimensional base manifold
parameterized by the time t, has vanishing curvature.

8
As an immediate consequence, one then has
Γ(t) = ˜Γ(t ←t′)Γ(t′),
(65)
which resembles the divisibility property (14). However,
it follows from an elementary theorem of linear alge-
bra that the inverse of a stochastic matrix can only be
stochastic if both matrices are permutation matrices, and
therefore do not involve nontrivial probabilities.11 Hence,
the matrix ˜Γ(t ←t′) deﬁned in (64) is not generically
stochastic, so (65) does not express a genuine form of
divisibility.
There is an alternative—and far-reaching—way to un-
derstand the generic indivisibility of a time-dependent
stochastic matrix Γ(t). To this end, suppose that Γ(t)
happens to be unistochastic for simplicity, and let U(t)
be a unitary time-evolution operator for Γ(t). Then for
any two times t and t′, one can deﬁne a relative time-
evolution operator
U(t ←t′) ≡U(t)U †(t′),
(66)
which yields the composition law
U(t) = U(t ←t′)U(t′).
(67)
At the level of the unistochastic matrix Γ(t), one has
from the Schur-Hadamard factorization (49) that
Γ(t) = U(t) ⊙U(t)
= [U(t ←t′)U(t′)] ⊙[U(t ←t′)U(t′)],
)
(68)
which
cannot
generally
be
expressed
in
the
form
Γ(t ←t′)Γ(t′) for any stochastic matrix Γ(t ←t′), due
to the presence of cross terms.
Indeed, examining individual matrix entries, one ﬁnds
more explicitly that
Γij(t) =
N
X
k=1
|Uik(t ←t′)|2|Ukj(t′)|2
+
X
k̸=l
Uik(t ←t′)Ukj(t′)Uil(t ←t′)Ulj(t′).











(69)
11 Proof: Let X and Y be N × N matrices with only non-negative
entries and with Y = X−1, so that XY = 1. Then, in particular,
the ﬁrst row of X must be orthogonal to the second through
Nth columns of Y . Because Y is invertible, the columns of Y
must all be linearly independent, so the ﬁrst row of X must be
orthogonal to the (N −1)-dimensional subspace spanned by the
second through Nth columns of Y . Because the entries of X and
Y are all non-negative by assumption, the only way that this
orthogonality condition can hold is if precisely one of the entries
in the ﬁrst row of X is nonzero, with a 0 in the corresponding
entry in each of the second through Nth columns of Y . Repeating
this argument for the other rows of X, one sees that X can only
have a single nonzero entry in each row.
If X is a stochastic
matrix, then each of these nonzero entries must be the number
1, so X must be a permutation matrix. QED
With Γkj(t′) deﬁned according to (50) as usual,
Γkj(t′) = |Ukj(t′)|2,
(70)
and deﬁning
Γik(t ←t′) ≡|Uik(t ←t′)|2,
(71)
which is manifestly unistochastic, one sees that the
discrepancy between Γ(t) and its would-be division
Γ(t ←t′)Γ(t′) is given by
Γij(t) −[Γ(t ←t′)Γ(t′)]ij
=
X
k̸=l
Uik(t ←t′)Ψk(t′)Uil(t ←t′)Ψl(t′),





(72)
where Ψ(t′) ≡Θ(t′)ej is the system’s state vector at the
time t′, in keeping with the general deﬁnition of state vec-
tors in (34). Remarkably, the right-hand side of (72) has
precisely the mathematical form of quantum-theoretic in-
terference, despite the absence of manifestly quantum-
theoretic assumptions.
One sees from this analysis that interference is a direct
consequence of stochastic dynamics not generally being
divisible.
More precisely, interference is nothing more
than a generic discrepancy between indivisible stochastic
dynamics and divisible stochastic dynamics.
In particular, interference does not imply that mat-
ter is physically wavelike, contrary to frequent claims in
textbook treatments like [33]. Indeed, from the perspec-
tive of the present discussion, the notion that interfer-
ence ever suggested a wavelike quality for matter was
merely an unfortunate accident of history, arising from
the fact that many early empirical examples of interfer-
ence in quantum-theoretic systems happened to resemble
the behavior of interfering waves propagating in three-
dimensional physical space.
These historical examples
were clearly special cases, as is evident from considering
interference in multiparticle systems, whose purported
waves would need to propagate through high-dimensional
conﬁguration spaces (as was noted by Schr¨odinger in his
early work on wave mechanics [34]), or in more abstract
systems, like qubits, that lack continuous conﬁguration
spaces altogether.
Nor does interference mean that, say, a particle in a
double-slit experiment fails to go through one slit or the
other.12 According to the approach laid out in this pa-
per, the particle does go through a speciﬁc slit in each
12 The exposition in [33] ends up at precisely such a conclusion: “It
is not true that the electrons go either through hole 1 or hole
2.” [Emphasis in the original.] This conclusion, however, does
not logically follow from the empirical appearance of interference
eﬀects, but also implicitly depends on the hidden assumption
that the behavior of an electron in a double-slit experiment can
be described by divisible dynamics.

9
run of the experiment. The interference that shows up in
the double-slit experiment may be surprising, but that
is only because indivisible stochastic dynamics can be
highly nonintuitive, and in the historical absence of a
suﬃciently comprehensive framework for describing indi-
visible stochastic dynamics, it was diﬃcult to recognize
just how nonintuitive such dynamics could be.
The fact that interference shows up in a suﬃciently
generic stochastic model means that relative phase fac-
tors in state vectors have clear empirical signatures, even
in the absence of the usual axioms of textbook quan-
tum theory. These empirical manifestations of relative
phases are strong evidence that it should be possible to
carry out measurements on a much wider set of observ-
ables than those that are represented by diagonal ma-
trices (32) in the system’s conﬁguration basis. Indeed,
Section XIII will show that non-diagonal self-adjoint ma-
trices will turn out to be candidate observables as well.
These results also suggest that interference should arise
in a much broader class of contexts than just for quantum
systems. One could imagine experimentally measuring
interference eﬀects for essentially any system that can be
modeled using indivisible stochastic dynamics.
IX.
DIVISION EVENTS
Why do discrete-time Markov chains (13) provide such
a good approximation to so many stochastic processes in
the real world? One intuitively reasonable explanation
is that when a system is not isolated from a noisy envi-
ronment, delicate correlations from one time to another
‘wash out’ over short time scales as those correlations
leak out into the environment. Using the framework pre-
sented in this paper, it is possible to make this intuitive
picture more precise.
To set things up, start by introducing a composite sys-
tem SE consisting of a subject system S together with an
environment E. Label the conﬁgurations of the subject
system’s conﬁguration space CS by i = 1, . . . , N, and la-
bel the conﬁgurations of the environment’s conﬁguration
space CE by e = 1, . . . , M, where M ≥N. The conﬁgura-
tion space of the composite system is then the Cartesian
product
CSE = CS × CE,
(73)
meaning that each element of CSE is a simple ordered
pair of the form (i, e).13 Single out N conﬁgurations of
the environment by labeling them as e(1), . . . , e(N).
13 Note that the right-hand side of (73) is indeed a Cartesian prod-
uct, not a tensor product, because this equation is solely a state-
ment about the composite system’s kinematics, not its dynamics.
For the dynamics, suppose for simplicity that the com-
posite system evolves according to an overall unistochas-
tic matrix
ΓSE(t) = U SE(t) ⊙U SE(t),
(74)
or, in terms of individual entries,
ΓSE
ie,i0e0(t) = |U SE
ie,i0e0(t)|2.
(75)
Furthermore, suppose that the subject system and the
environment interact up to a time t′ > 0 in such a way
that they end up with joint probabilities of the form
pSE
i′e′(t′) = pS
i′(t′)δe′e(i′),
(76)
which describe an idealized correlation between the con-
ﬁguration i′ of the subject system at t′ and the corre-
sponding conﬁguration e(i′) of the environment.
If there is to be any possibility of the two subsystems
evolving independently for times t > t′ after the interac-
tion has concluded, then it should be possible to factorize
the composite system’s relative time-evolution operator
U SE(t ←t′) between the two subsystems for t > t′ as the
following tensor product:
U SE(t ←t′) = U S(t ←t′) ⊗U E(t ←t′)
for t > t′.
)
(77)
In terms of individual entries, one has
U SE
ie,i′e′(t ←t′) = U S
ii′(t ←t′)U E
ee′(t ←t′)
for t > t′,
)
(78)
meaning that each entry U SE
ie,i′e′(t ←t′) of the composite
system’s relative time-evolution operator is the product
of corresponding entries U S
ii′(t ←t′) and U E
ee′(t ←t′) of
the relative time-evolution operators for the two subsys-
tems individually.14
In light of the Born rule (37), the joint probabilities
(76) correspond to a wave function15
ΨSE
i′e′(t′) = ΨS
i′(t′)δe′e(i′),
(79)
so the composite system’s wave function at later times
t > t′ after the interaction is given in terms of the relative
time-evolution operator (78) according to
14 Note the natural appearance of a tensor product in (77) and (78),
which are statements about the composite system’s dynamics.
15 If necessary, one can easily write down idealized examples of
appropriately unitary time-evolution operators for the composite
system. For instance, one could use USE(t′) ≡P
i′ P S
i′ ⊗RE
e(i′),
where P S
i′ is the i′th conﬁguration projector (21) for the subject
system, and where RE
e(i′) is a unitary transformation that takes
the environment’s initial conﬁguration to the conﬁguration e(i′).

10
ΨSE
ie (t) =
X
i′,e′
U SE
ie,i′e′(t ←t′)ΨSE
i′e′(t′)
=
X
i′
U S
ii′(t ←t′)ΨS
i′(t′)U E
ee(i′)(t ←t′).







(80)
From the Born rule (37), one sees that the joint proba-
bilities for t > t′ are given by
pSE
ie (t) =
ΨSE
ie (t)
2.
(81)
Marginalizing over the conﬁguration e of the environment
and invoking the unitarity of the environment’s relative
time-evolution operator U E(t ←t′), one obtains the stan-
dalone probabilities pS
i (t) for the subject system alone for
t > t′:
pS
i (t) =
X
e
pSE
ie (t)
=
X
i′
1,i′
2
U S
ii′
1(t ←t′)ΨS
i′
1(t′)U S
ii′
2(t ←t′)ΨS
i′
2(t′)
×
X
e
U E
ee(i′
1)(t ←t′)U E
ee(i′
2)(t ←t′)
=
X
i′
|U S
ii′(t ←t′)|2|ΨS
i′(t′)|2.



























(82)
Taking the limit t →t′ in (82) and referring back to the
Born rule (37) again, one sees that the subject system’s
standalone probabilities at t′ > 0 are
pS
i′(t′) = |ΨS
i′(t′)|2.
(83)
One also sees from (82) that, as in (71), one can identify
ΓS
ii′(t ←t′) ≡|U S
ii′(t ←t′)|2.
(84)
Hence, (82) simpliﬁes to a genuinely linear relationship
that precisely mirrors the basic marginalization formula
(7) for a stochastic process, with t′ > 0 now serving as
the ‘initial time’:
pS
i (t) =
X
i′
ΓS
ii′(t ←t′)pS
i′(t′).
(85)
Applying the basic marginalization formula (7) to the
stochastic process from t = 0 to t′ > 0, one also has the
equation
pS
i′(t′) =
X
j
ΓS
i′j(t′)pS
j (0).
(86)
Combining (85) with (86) immediately yields
pS
i (t) =
X
j
ΓS
ij(t)pS
j (0),
(87)
where ΓS(t) is a manifestly divisible stochastic matrix:
ΓS(t) ≡ΓS(t ←t′)ΓS(t′).
(88)
Thus, the interaction between the subject system S and
the environment E up to the time t′ > 0 has led to a
stochastic matrix ΓS(t) for the subject system that is
instantaneously divisible at t′.
It is natural to refer to t′ as a ‘division event.’
An
important corollary is that t = 0 is not a unique or special
time, but is instead only one of many division events
inevitably experienced by a system in suﬃciently strong
contact with a noisy environment.
Suppose that these kinds of division events can be ap-
proximated as occurring regularly over a characteristic
time scale ∆t. Suppose, moreover, that the unistochas-
tic dynamics is homogeneous in time, in the sense that
U S(t + ∆t ←t) = U S(∆t) for all times t. Then the sub-
ject system’s stochastic matrix after any integer number
n ≥1 of time steps ∆t is given by
ΓS(t = n∆t) =
 ΓSn,
(89)
where
ΓS
ij ≡|U S
ij(∆t)|2.
(90)
The stochastic dynamics therefore takes the form of a
discrete-time Markov chain (13). This analysis therefore
provides an explanation for the ubiquity of Markovian
stochastic dynamics in so many real-world cases.
X.
DECOHERENCE
Had the environment not interacted with the subject
system, then the subject system’s density matrix ρS(t′)
at t′ > 0 would have generically been non-diagonal, in
accordance with the general deﬁnition (30):
ρS(t′) = U S(t′)

X
j
pj(0)Pj

U S†(t′)
= U S(t′)diag(. . . , pj(0), . . . )U S†(t′).







(91)
By contrast, suppose that the environment indeed in-
teracts with the subject system to produce a division
event (88) at t′. In that case, the standalone probability
pS
i (t) for the subject system to occupy its ith conﬁgu-
ration at t > t′ is given by (82), which can be written
instead as
pS
i (t) = tr(PiρS(t)),
(92)
where
ρS(t) ≡U S(t ←t′)ρS(t′)U S†(t ←t′),
(93)
and where, in turn,
ρS(t′) ≡
X
i′
pS
i′(t′)P S
i′ = diag
 . . . , pS
i′(t′), . . .

,
(94)

11
which is diagonal.
On comparing the two expressions (91) and (94) for the
subject system’s density matrix ρ(t′) at t′, one sees that
the interaction with the environment has eﬀectively elim-
inated the oﬀ-diagonal entries, or coherences, in the sub-
ject system’s density matrix. This phenomenon is called
decoherence, and the foregoing analysis makes clear that
decoherence is nothing more than the unremarkable leak-
age of correlations into the environment when viewed
through the lens of the Hilbert-space formulation.
This analysis also sheds new light on the meaning of co-
herences in density matrices, as well as on superpositions
in state vectors, where superpositions are related to co-
herences in the case of a rank-one density matrix through
the formula ρi1i2(t) = Ψi1(t)Ψi2(t), in accordance with
(36). From the standpoint of this analysis, superpositions
and coherences are merely indications that one is catch-
ing a given system when it is in the midst of an indivisible
stochastic process, between division events, rather than
implying that the system is in ‘multiple states at once.’
These results may also help explain why the precise
connection between quantum theory and stochastic pro-
cesses remained unclear for so long.
If one assumes a
Markov approximation, as is often the case in the litera-
ture on stochastic processes, then coherences and super-
position do not show up, meaning that density matrices
remain diagonal, state vectors remain trivial, and non-
trivial unistochastic dynamics cannot arise.
XI.
ENTANGLEMENT
Consider next a composite system AB consisting of
a pair of subsystems A and B.
Suppose that the two
subsystems do not interact from t = 0 up to some time
t′ > 0, but then begin interacting at t′.
For times t between 0 and t′, the composite system’s
stochastic matrix ΓAB(t) factorizes into the tensor prod-
uct of a stochastic matrix ΓA(t) for A and a stochastic
matrix ΓB(t) for B:
ΓAB(t) = ΓA(t) ⊗ΓB(t)
for 0 ≤t < t′.
(95)
Starting at t = t′, however, the composite system’s
stochastic matrix ΓAB(t), which encodes cumulative sta-
tistical information, will fail to factorize between the two
subsystems, in the sense that
ΓAB(t) ̸= ΓA(t) ⊗ΓB(t)
for t > t′,
(96)
for any possible stochastic matrices ΓA(t) and ΓB(t) that
properly capture the respective dynamics of the two sub-
systems. Even if the two subsystems have a notion of lo-
calizability in space, and are eventually placed at a large
separation distance at some time t > t′, the compos-
ite system’s stochastic matrix will still fail to factorize
between the two subsystems, thereby leading to the ap-
pearance of what looks like nonlocal stochastic dynamics
across that separation distance.16
However, if the composite system exhibits a division
event of the form (88) at some later time t′′ > t′, perhaps
due to interactions with the larger environment, then the
composite system’s stochastic matrix ΓAB(t) will divide
at t′′:
ΓAB(t) = ΓAB(t ←t′′)ΓAB(t′′)
for t > t′′ > t′.
(97)
If the two subsystems A and B do not interact with
each other after t′, then the relative stochastic matrix
ΓAB(t ←t′′) will factorize between them,
ΓAB(t ←t′′) = ΓA(t ←t′′) ⊗ΓB(t ←t′′),
(98)
so the two subsystems will cease exhibiting what had
looked like nonlocal stochastic dynamics.
This analysis precisely captures the quantum-theoretic
notion of entanglement. Systems that interact with each
other start to exhibit what appears to be a nonlocal kind
of stochastic dynamics, even if the systems are moved
far apart in physical space, but decoherence by the envi-
ronment eﬀectively causes a breakdown in that apparent
dynamical nonlocality.
This stochastic picture of entanglement and nonlocal-
ity provides a new way to understand why they occur in
the ﬁrst place. The indivisible nature of generic stochas-
tic dynamics could be viewed as a form of nonlocality in
time, which then leads to an apparent nonlocality across
space. A division event leads to an instantaneous restora-
tion of locality in time, which then leads to a momentary
restoration of manifest locality across space.
XII.
EMERGEABLES
The preceding sections have shown that a model with
kinematics based on a classical conﬁguration space and
dynamics based on a suitable stochastic process is ca-
pable of accounting for signature features of quantum
theory, like interference, decoherence, and entanglement.
In addition, the Hilbert-space side of the dictionary (26)
contains many expressions and equations that are identi-
cal to those found in quantum theory. However, an actual
quantum system also includes observables beyond those
like (32) that are diagonal in a single basis. Indeed, the
existence of noncommuting observables is another hall-
mark feature of quantum theory.
Remarkably, a stochastic system will generically con-
tain such observables as well. Speciﬁcally, Section XIII
16 Questions about nonlocality will be addressed in detail in Sec-
tion XVIII.

12
will establish that these mathematical objects represent
candidate observables that naturally satisfy the usual
probabilistic rules of quantum theory, all without intro-
ducing any new fundamental axioms. In so doing, the
analysis ahead will demonstrate that the dictionary (26)
is not merely a tool for studying stochastic processes,
but deﬁnes a comprehensive stochastic-quantum corre-
spondence.
As motivation, let A be a time-independent (diagonal)
random variable (32), and consider the time derivative of
its Heisenberg-picture counterpart AH(t), as deﬁned for
a generic time-evolution operator Θ(t) by (39):
dAH(t)
dt
= ∂Θ†(t)
∂t
AΘ(t) + Θ†(t)A∂Θ(t)
∂t
.
(99)
Evaluating this matrix in the limit t →0 gives a self-
adjoint, generically non-diagonal N × N matrix ˙A at t =
0:
˙A ≡lim
t→0
dAH(t)
dt
= ˙A†.
(100)
This matrix will not generally commute with the original
random variable A itself:
[A, ˙A] ̸= 0.
(101)
However, the matrix ˙A has physical uses. For example,
tr( ˙Aρ(0)) = lim
t→0
d⟨A(t)⟩
dt
,
(102)
which is a perfectly meaningful physical quantity, even
though the time derivative of an expectation value is not
necessarily the expectation value of something physical.
The matrix ˙A therefore resembles a random variable in
some ways, but incorporates stochastic dynamics directly
into its deﬁnition (100), through the time-evolution oper-
ator Θ(t), and does not have a transparent interpretation
at the level of the system’s underlying conﬁguration space
C. Instead, ˙A is an emergent amalgam of kinematical and
dynamical ingredients, so it will be called an ‘emerge-
able.’17 This terminology is intended to contrast ˙A with
the system’s genuine random variables, which could be
called ‘beables’ or ‘be-ables’, as coined in [35].
XIII.
MEASUREMENTS
Consider now a composite system SDE consisting of
three subsystems that will be called a subject system S,
a measuring device D, and an environment E. One of the
17 There is a sense in which emergeables are not an entirely new
idea, but are closely related to other emergent phenomena like
temperatures or pressures.
goals ahead will be to identify the necessary criteria for a
subsystem like D to be regarded as a genuine measuring
device.
Focusing momentarily on the subject system, consider
a self-adjoint N × N matrix ˜AS = ˜AS†, which may or
may not be one of the subject system’s diagonal ran-
dom variables.18 As a concrete example, ˜AS could be an
emergeable like (100).
By the spectral theorem, ˜AS has a spectral decompo-
sition of the form
˜AS =
X
α
˜aα ˜P S
α ,
(103)
where ˜aα are the eigenvalues of ˜AS and where ˜P S
α are
its eigenprojectors.
These eigenprojectors ˜P S
α are not
generically diagonal, but they satisfy the analogues of
the mutual exclusivity condition (24),
˜P S
α ˜P S
α′ = δαα′ ˜P S
α ,
(104)
and the completeness relation (25),
X
α
˜P S
α = 1S,
(105)
where 1S is the identity matrix for the subject system.
These eigenprojectors therefore constitute a projection-
valued measure (PVM) of their own. Letting ˜eα be the
corresponding orthonormal basis, one has
˜e†
α˜eα′ = δαα′,
˜eα˜e†
α = ˜Pα.
(106)
If ˜AS happens to be one of the subject system’s random
variables (32), then the eigenvalues ˜aα are the random
variable’s magnitudes and the eigenprojectors ˜P S
α are the
conﬁguration projectors (21). More generally, however,
the eigenvalues ˜aα and eigenprojectors ˜Pα do not yet have
an obvious physical meaning.
Suppose that the measuring device D has conﬁgura-
tions d(α) that can be labeled by the index α appearing
in the spectral decomposition (103), and, similarly, that
the environment E has conﬁgurations e(α) that can be
labeled by α. Generalizing (75), suppose, moreover, that
the composite system SDE evolves according to an over-
all unistochastic matrix
ΓSDE
ide,i0d0e0(t) = |U SDE
ide,i0d0e0(t)|2.
(107)
Generalizing (79) and letting ˜eα′,i′ denote the i′th com-
ponent of the basis vector ˜eα′ with respect to the con-
ﬁguration basis ei′, suppose that the three subsystems
18 More generally, one could take ˜
AS to be a normal matrix, mean-
ing a matrix that commutes with its adjoint ˜
AS†.

13
interact up to a time t′ > 0 in such a way that they end
up with overall wave function19
ΨSDE
i′d′e′(t′) =
X
α′
˜ΨS
α′(t′)˜eα′,i′δd′d(α′)δe′e(α′),
(108)
and that, mirroring (77), the composite system’s rela-
tive time-evolution operator factorizes between the three
subsystems for later times t > t′:
U SDE(t ←t′) = U S(t ←t′) ⊗U D(t ←t′)
⊗U E(t ←t′)
for t > t′.





(109)
Then the composite system’s wave function for times t >
t′ after the interaction is
ΨSDE
ide (t) =
X
i′,e′,d′
U SDE
ide,i′d′e′(t ←t′)ΨSDE
i′d′e′(t′)
=
X
i′
X
α′
U S
ii′(t ←t′)˜ΨS
α′(t′)˜eα′,i′
× U D
dd(α′)(t ←t′)U E
ee(α′)(t ←t′).













(110)
Invoking the Born rule (37), it follows that the joint prob-
abilities for t > t′ are given by
pSDE
ide (t) =
ΨSDE
ide (t)
2.
(111)
Marginalizing over the conﬁguration i of the subject sys-
tem as well as the conﬁguration e of the environment, and
invoking the unitarity of both the subject system’s rela-
tive time-evolution operator U S(t ←t′) and the environ-
ment’s relative time-evolution operator U E(t ←t′), one
obtains the standalone probabilities pD
d (t) for the mea-
suring device alone for t > t′:
pD
d (t) =
X
i,e
pSDE
ide (t)
=
X
i′
1,i′
2
X
α′
1,α′
2
U D
dd(α′
1)(t ←t′)˜ΨS
α′
1(t′)˜eα′
1,i′
1
× U D
dd(α′
2)(t ←t′)˜ΨS
α′
2(t′)˜eα′
2,i′
2
×
X
i
U S
ii′
1(t ←t′)U S
ii′
2(t ←t′)
×
X
e
U E
ee(α′
1)(t ←t′)U E
ee(α′
2)(t ←t′)
=
X
α′
|U D
dd(α′)(t ←t′)|2|˜ΨS
α′(t′)|2.











































(112)
19 It is straightforward to write down idealized examples of suitable
unitary time-evolution operators for the composite system. One
choice is USDE(t′) ≡P
α′ ˜P S
α′ ⊗RD
d(α′) ⊗RE
e(α′), where ˜P S
α′ is
the α′th eigenprojector appearing in the spectral decomposition
(103), and where RD
d(α′) and RE
e(α′) are unitary transformations
for the measuring device and the environment that respectively
put them in the conﬁgurations d(α′) and e(α′).
In the limit t →t′, the last line implies that
pD
d(α′)(t′) = |˜ΨS
α′(t′)|2,
(113)
so the measuring device has a probability |˜ΨS
α′(t′)|2 of
ending up in its conﬁguration d(α′), exactly as predicted
by textbook quantum theory.
One can then naturally
deﬁne an expectation value ⟨˜AS(t)⟩for ˜AS as the usual
kind of statistical average:
⟨˜AS(t)⟩≡
X
α
˜aαpD
d(α′)(t′).
(114)
This analysis establishes that as long as there exists a
form of unistochastic time evolution (107) for the com-
posite system SDE that arrives at the wave function
(108), the matrix ˜AS represents a genuine observable,
in the sense that the time evolution (107) leads to the
measuring device ending up in the correct conﬁguration
with the correct Born-rule probability.
For times t > t′ after the interaction, the last line
of (112) implies that t′ > 0 is a division event for the
measuring device:
ΓD(t) = ΓD(t ←t′)ΓD(t′)
for t > t′.
(115)
Here the measuring device’s dynamics for times t > t′ is
given by the relative unistochastic matrix
ΓD
dd(α′)(t ←t′) ≡|U D
dd(α′)(t ←t′)|2.
(116)
By contrast, unless the observable ˜AS happens to be
one of the subject system’s (diagonal) random variables
(32), the subject system does not experience a division
event at t′. Instead, the subject system remains mired
in indivisible time evolution at t′, with some stochasti-
cally evolving underlying conﬁguration. Nonetheless, for
times t > t′, one can compute the standalone probability
pS
i (t) for the subject system to be in its ith conﬁgura-
tion by marginalizing over the measuring device and the
environment:
pS
i (t) =
X
d,e
pSDE
ide (t)
=
X
i′
1,i′
2
X
α′
1,α′
2
U S
ii′
1(t ←t′)˜ΨS
α′
1(t′)˜eα′
1,i′
1
× U S
ii′
2(t ←t′)˜ΨS
α′
2(t′)˜eα′
2,i′
2
×
X
d
U D
dd(α′
1)(t ←t′)U D
dd(α′
2)(t ←t′)
×
X
e
U E
ee(α′
1)(t ←t′)U E
ee(α′
2)(t ←t′)
=
X
α′

X
i′
1,i′
2
U S
ii′
1(t ←t′)U S
ii′
2(t ←t′)˜eα′,i′
2˜eα′,i′
1


× |˜ΨS
α′(t′)|2.





















































(117)

14
Recognizing |˜ΨS
α′(t′)|2 from (113) as the probability
pD
d(α′)(t′) for the measuring device to end up in its con-
ﬁguration d(α′) at t′ > 0, and recalling both the con-
ﬁguration projectors P S
i
deﬁned in (21) as well as the
eigenprojectors ˜P S
α appearing in the spectral decompo-
sition (103) for ˜AS, one can write (117) more succinctly
as
pS
i (t) = tr(P S
i ρS(t)).
(118)
Here the subject system’s density matrix ρS(t) for t > t′
is given by
ρS(t) ≡U S(t ←t′)
"X
α′
pD
d(α′)P S
α′
#
U S†(t ←t′).
(119)
Hence, one can recast the expectation value (114) for ˜AS
as
⟨˜AS(t)⟩= tr( ˜ASρS(t)),
(120)
which precisely mirrors the formula (31) for the expecta-
tion value of a (diagonal) random variable.
Moreover, (117) yields a linear relationship between
the standalone probabilities pD
d(α′)(t′) for the measuring
device at t′ > 0 and the standalone probabilities pS
i (t)
for the subject system at t > t′:
pS
i (t) =
X
α′
ΓSD
i,d(α′)(t ←t′)pD
d(α′)(t′).
(121)
The entries ΓSD
i,d(α′)(t ←t′) of the hybrid relative stochas-
tic matrix appearing here are given explicitly by
ΓSD
i,d(α′)(t ←t′)
≡
X
i′
1,i′
2
U S
ii′
1(t ←t′)U S
ii′
2(t ←t′)˜eα′,i′
2˜eα′,i′
1.





(122)
Because these matrix entries do not depend on the mea-
suring device’s standalone probabilities pD
d(α′)(t′), they
naturally deﬁne conditional probabilities for the subject
system to be in its ith conﬁguration at the time t > t′
given that the measuring device is in its conﬁguration
d(α′) at t′ > 0:
pSD(i, t|d(α′), t′) ≡ΓSD
i,d(α′)(t ←t′).
(123)
XIV.
WAVE-FUNCTION COLLAPSE
Importantly, notice also that one can write the hybrid
stochastic matrix (122) in an overall form that resembles
the dictionary (26):
ΓSD
i,d(α′)(t ←t′)
= tr(U S†(t ←t′)P S
i U(t ←t′) ˜P S
α ).
)
(124)
Rearranging the right-hand side gives the equation
ΓSD
i,d(α′)(t ←t′) = tr(P S
i ρS|α′,t′(t)),
(125)
with a ‘conditional’ density matrix ρS|α′,t′(t) for the sub-
ject system at the time t > t′ naturally deﬁned by time-
evolving the eigenprojector ˜P S
α′ from t′ > 0 to t > t′:
ρS|α′,t′(t) ≡U(t ←t′) ˜P S
α′U S†(t ←t′).
(126)
Thus, the calculation (117) reduces to the statement
that the standalone probabilities pS
i (t) for the subject
system at t > t′ are given by
pS
i (t) = tr(P S
i ρS(t)),
(127)
where the subject system’s density matrix ρS(t), which
was originally deﬁned in (119), can equivalently be ex-
pressed as a probabilistic mixture of the conditional
density matrices ρS|α′,t′(t) deﬁned in (126), statistically
weighted by the measurement probabilities pD
d(α′)(t′):
ρS(t) ≡
X
α′
ρS|α′,t′(t)pD
d(α′)(t′).
(128)
Taking stock of these results, one sees that to make fu-
ture predictions for t > t′ about the subject system, con-
ditioned on the measuring device’s result d(α′) at t′ > 0,
one eﬀectively replaces the subject system’s density ma-
trix with the conditional density matrix ρS|α′,t′(t), cor-
responding to a ‘collapsed’ state vector or wave function
deﬁned as
ΨS|α′,t′(t) ≡U(t ←t′)˜eα.
(129)
By contrast, for an observer who does not know the spe-
ciﬁc measurement result d(α′), the correct density matrix
ρS(t) to use is the one deﬁned in (128), which, again, con-
sists of an appropriate mixture of conditional or collapsed
density matrices probabilistically weighted over the mea-
surement results.
XV.
THE MEASUREMENT PROBLEM
According to the foregoing analysis, measuring devices
are ordinary physical systems that carry out measure-
ments of observables, and then end up in ﬁnal conﬁgu-
rations that reﬂect deﬁnite measurement outcomes, with
the probabilities for those various measurement outcomes
given by the Born rule. Hence, the picture of quantum
theory presented in this paper arguably has the resources
to solve the measurement problem [36].
The stochastic-quantum correspondence is also helpful
for understanding the measurement process in another
important way.
Textbook treatments of quantum the-
ory typically regard measuring devices as metaphysical
primitives or posits, without providing clear principles

15
for deciding which kinds of systems merit being called
measuring devices and which do not. The approach taken
toward the measurement process in this paper not only
gives a candidate resolution of the measurement problem,
but also yields a natural set of criteria for deﬁning what
counts as a good measuring device, without the need to
regard measuring devices as special among all other sys-
tems in any truly fundamental way.
Based on the approach in this paper, a good measuring
device should be a physical system with at least as many
conﬁgurations as possible outcomes for the observable to
be measured (at least up to the desired level of experi-
mental resolution), it should admit an overall form of dy-
namics that results in the correct ﬁnal correlations, and
it should be in suﬃciently strong contact with a noisy
environment to generate a robust division event at the
conclusion of the measurement interaction. It is worth
noting that the ﬁrst two of these three criteria would
be standard requirements for a measuring device even
without worrying about indivisible stochastic dynamics
or quantum theory.
XVI.
SYMMETRIES
The stochastic-quantum correspondence developed in
this paper provides new ways to think about dynamical
symmetries in quantum theory. Going in the other direc-
tion, the stochastic-quantum correspondence also makes
it more straightforward to impose dynamical symmetries
systematically as constraints in the construction of the
dynamics for a given stochastic model.
Classically, any invertible transformation of a system’s
conﬁgurations i = 1, . . . , N is a permutation transforma-
tion of the conﬁguration projectors (21):
Pi 7→Pσ(i),
with {σ(1), . . . , σ(N)} = {1, . . . , N}.
)
(130)
More generally, a transformation between two PVMs
P1, . . . , PN and ˜P1, . . . , ˜PN is always a similarity trans-
formation of the form
Pi 7→˜Pi ≡V †PiV,
(131)
where V is some unitary operator.20
This similarity
transformation reduces to the conﬁgurational transfor-
mation (130) if and only if V is a permutation matrix.
20 Proof:
Let e1, . . . , eN be the orthonormal conﬁguration basis
(28), with e†
i ej = δij and eie†
i = Pi, and let ˜e1, . . . , ˜eN be an or-
thonormal basis related to the new projectors ˜Pi in the analogous
way, with ˜e†
i ˜ej = δij and ˜ei˜e†
i = ˜Pi. Then the N × N matrix
deﬁned by V ≡P
i ei˜e†
i is unitary and satisﬁes V †PiV = ˜Pi.
Going the other way, if V is a unitary N × N matrix, then the
N × N matrices deﬁned for i = 1, . . . , N by ˜Pi ≡V †PiV are
guaranteed to constitute a PVM. QED
The more general transformation (131) leaves the
stochastic dynamics invariant precisely if the right-hand
side of the stochastic-quantum dictionary (26) remains
unchanged:
tr(Θ†(t) ˜PiΘ(t) ˜Pj) = tr(Θ†(t)PiΘ(t)Pj).
(132)
This condition is equivalent to the statement that
tr(˜Θ†(t)Pi ˜Θ(t)Pj) = tr(Θ†(t)PiΘ(t)Pj),
(133)
where
˜Θ(t) ≡V Θ(t)V †.
(134)
Re-expressing both sides of the equivalent condition (133)
in terms of squared absolute values, as in (17), one sees
that (134) is a dynamical symmetry precisely if
|˜Θij(t)|2 = |Θij(t)|2.
(135)
It follows immediately that ˜Θ(t) can diﬀer from Θ(t)
by at most a Schur-Hadamard gauge transformation (42),
meaning that a necessary and suﬃcient condition for a
unitary matrix V to give a dynamical symmetry is that
V Θ(t)V † = Θ(t) ⊙



eiθ11(t) eiθ12(t)
eiθ21(t)
...
eiθNN(t)


.
(136)
As special cases, this condition includes unitary dynam-
ical symmetries,
V Θ(t)V † = Θ(t),
(137)
as well as anti-unitary dynamical symmetries,
V Θ(t)V † = Θ(t).
(138)
Note that if one redeﬁnes V 7→V , which is still uni-
tary, then one can re-express (138) in the somewhat more
conventional form
V KΘ(t)KV † = Θ(t).
(139)
Here K denotes the operation of complex conjugation, so
that K2 = 1 and KXK = X for any N × N matrix X.
The composite operator V K as a whole is then said to be
an anti-unitary operator. Anti-unitary operators play an
important role in describing time-reversal symmetries.21
21 Intriguingly, because K anticommutes with i, meaning that Ki =
−iK, the four mathematical objects 1, i, K, and iK satisfy −i2 =
K2 = (iK)2 = iK(iK) = 1, and therefore deﬁne a Cliﬀord
algebra isomorphic to the pseudo-quaternions [37]. In a sense,
then, the Hilbert spaces of quantum systems are actually deﬁned
not over the complex numbers, but over the pseudo-quaternions.

16
If Θ(t) = U(t) is unitary, then V Θ(t)V † will likewise
be unitary. In that case, if V is continuously connected to
the identity 1 by some smooth parameter, with a corre-
sponding self-adjoint generator G = G†, then Noether’s
theorem then easily follows as the statement that the ex-
pectation value ⟨G(t)⟩of that generator is constant in
time:
⟨G(t)⟩= tr(GU(t)ρ(0)U †(t)) = ⟨G(0)⟩.
(140)
XVII.
DILATIONS
In most textbook treatments of quantum theory, a
quantum system is axiomatically deﬁned as a particular
Hilbert space together with a preferred set of self-adjoint
operators designated as observables with predetermined
physical meanings, along with a particular Hamiltonian
to deﬁne the system’s time evolution.22 From that point
of view, modifying a system’s Hilbert-space formulation
in any nontrivial way would necessarily mean fundamen-
tally modifying the system itself.
From the alternative point of view developed in this
paper, by contrast, a Hilbert-space formulation is merely
a collection of mathematical tools for constructing the
dynamics of a given stochastic system. The system it-
self is ultimately deﬁned by a conﬁguration space and
a dynamical law that stand apart from any arbitrary
choice of Hilbert-space formulation. As a consequence,
one is free to modify a system’s Hilbert-space formula-
tion as needed, much like changing from one gauge choice
to another in a gauge theory, or like adding physically
meaningless variables to the Lagrangian formulation of a
deterministic classical system.
With this motivation in place, recall again the basic
stochastic-quantum dictionary (26):
Γij(t) = tr(Θ†(t)PiΘ(t)Pj).
(141)
The Hilbert-space formulation expressed by the right-
hand side can be manipulated for convenience, provided
that the left-hand side of the dictionary remains un-
changed.
In particular, for an integer D ≥2, one can freely en-
large, or dilate, the Hilbert-space formulation to a larger
dimension ND by the following dilation transformation:
Θ(t) 7→Θ(t) ⊗1I,
Pi(t) 7→Pi(t) ⊗1I,
Pj(t) 7→Pj(t) ⊗P I
γ .





(142)
22 In some circumstances, it may turn out to be more convenient to
deﬁne a quantum system by a formal C*-algebra of observables
alone, without picking a speciﬁc Hilbert-space representation.
Here 1I is the D × D identity matrix on a new ‘internal’
Hilbert space HI, and P I
1 , . . . , P I
D collectively form any
PVM on that internal Hilbert space satisfying the usual
conditions of mutual exclusivity,
P I
γ P I
γ′ = δγγ′P I
γ ,
(143)
and completeness,
D
X
γ=1
P I
γ = 1I.
(144)
It is then a mathematical identity that one can rewrite
the stochastic-quantum dictionary as
Γij(t) = tr
 trI
 
Θ†(t) ⊗1I
Pi ⊗1I
×

Θ(t) ⊗1I
Pj ⊗P I
γ

,
)
(145)
with a second trace over the internal Hilbert space HI.
The choice of value for the label γ here is immaterial, with
diﬀerent choices of γ related by gauge transformations.
One can equivalently write the dilated form of the dic-
tionary in block-matrix form as
Γij(t) = trI

[Θij(t)]I†[Θij(t)]IP I
γ

.
(146)
Here [Θij(t)]I is a diagonal D × D matrix consisting of
repeated copies of the speciﬁc entry Θij(t) (for ﬁxed i, j)
along the diagonal,
[Θij(t)]I ≡Θij(t)1I,
(147)
and the adjoint operation † in (146) acts on this D ×
D block matrix [Θij(t)]I, so it does not transpose the
indices i and j on the N × N matrix Θij(t) itself,
[Θij(t)]I† ≡[Θij(t)]
I.
(148)
In this dilated version of the Hilbert-space formula-
tion, the Schur-Hadamard gauge transformation (42) is
enhanced to the following local-in-time gauge transfor-
mation, which has not yet been described in the litera-
ture:
[Θij(t)]I 7→V I
(ij)(t)[Θij(t)]I.
(149)
Here V I
(ij)(t) are a set of N 2 unitary D × D matrices,
where each such unitary matrix as a whole is labeled by
a speciﬁc pair (ij) of conﬁguration labels:
V I†
(ij)(t) = (V I
(ij)(t))−1.
(150)
The gauge transformations (149) will not generally pre-
serve the factorization Θ(t) ⊗1I appearing in (145), so
they motivate considering more general ND × ND time-
evolution operators ˜Θ(t), in terms of which the dilated
dictionary (145) takes the form
Γij(t) = tr

trI

˜Θ†(t)

Pi ⊗1I˜Θ(t)

Pj ⊗P I
γ

.
(151)

17
Any ND ×ND matrix ˜Θ(t) appearing on the right-hand
side of this dictionary is guaranteed to lead to a valid
stochastic matrix Γij(t) on the left-hand side, so working
with a dilated Hilbert-space formulation essentially pro-
vides a larger ‘canvas’ for designing stochastic matrices.
As a simple example of a dilation for the case D = 2,
one can formally eliminate the complex numbers from a
quantum system’s Hilbert space [38]. Speciﬁcally, by in-
creasing the system’s Hilbert-space dimension from N to
2N, one can replace the imaginary unit i ≡√−1 with
the real-valued 2 × 2 matrix
  0 −1
1
0

, with the enhanced
version (149) of the Schur-Hadamard gauge transforma-
tion now consisting of two-dimensional rotations of the
internal Hilbert space HI. One can then represent the
complex-conjugation operator K appearing in (139) as
the 2 × 2 matrix ( 0 1
1 0 ).
The result is that all unitary
and anti-unitary operators become 2N × 2N orthogonal
matrices.
One cost in using this ‘real’ representation,
however, is that the Hilbert spaces of composite systems
do not factorize as neatly into Hilbert spaces for their
constituent subsystems.23
As a somewhat more signiﬁcant application of dila-
tions, recall that any stochastic matrix Γij(t) has a Kraus
decomposition (48):
Γij(t) =
N
X
β=1
tr(K†
β(t)PiKβ(t)Pj).
(152)
The Stinespring dilation theorem [39] then guarantees
that by an appropriate dilation to a larger Hilbert space
if necessary, one can express Γij(t) in terms of a unitary
time-evolution operator ˜U(t):
Γij(t) = tr

trI

˜U †(t)

Pi ⊗1I ˜U(t)

Pj ⊗P I
γ

.
(153)
This fact makes clear the inevitability of unitary time
evolution in quantum theory.24
23 Without increasing the dimension N of a system’s Hilbert space,
one could instead attempt to limit the appearance of the com-
plex numbers in a system’s Hilbert-space formulation by using
the original Schur-Hadamard gauge transformation (42) to make
all the entries of the system’s time-evolution operator Θ(t) real-
valued.
In this alternative approach, however, a unistochastic
matrix Γ(t) may not be expressible in terms of a unitary or or-
thogonal time-evolution operator, and the complex numbers will
generally still be needed anyway to deﬁne various observables.
24 From the starting assumptions presented here, one can sketch
the following proof: Given N × N Kraus matrices Kβ(t), with
β = 1, . . . , N, deﬁne an N3 × N2 matrix ˜V (t) according to
˜V(iβm)(jl)(t) ≡Kβ,ij(t)δlm, treating (iβm) as the ﬁrst index
of ˜V (t) and treating (jl) as its second index. One can show that
this matrix satisﬁes ˜V †(t) ˜V (t) = 1N2×N2, so it deﬁnes a partial
isometry, which can always be extended to a unitary N3×N3 ma-
trix ˜U(iβm)(jγ)(t) by adding N3−N2 additional columns that are
mutually orthogonal with each other and with the previous N2
As another application, a dilated Hilbert-space formu-
lation can make it possible to introduce new kinds of
emergeables. Some of these emergeables may be observ-
ables that can yield deﬁnite results in measurement pro-
cesses, along the lines of Section XIII, despite not having
a direct meaning at the level of the system’s underlying
conﬁguration space. In this way, a stochastically evolv-
ing system based on a classical conﬁguration space can
easily accommodate emergent observables that model all
kinds of quantum-theoretic phenomena. Indeed, obtain-
ing a unitary time-evolution operator for a given system
may require dilating the Hilbert space in just this way,
as in (153).
An important example of this last application is intrin-
sic spin. To introduce spin as an emergeable, one merely
dilates the Hilbert space to ND dimensions, introduces
a D-dimensional representation of SO(3) for the internal
Hilbert space, and then requires that the dilated time-
evolution operator has the appropriate form of rotation
symmetry.
XVIII.
NONLOCALITY
This paper has shown that systems with classical
conﬁguration spaces and indivisible stochastic dynamics
have Hilbert-space representations and can replicate the
usual mathematical formalism and empirical predictions
of quantum theory.
The classical conﬁgurations in this new picture for
quantum theory essentially play the role of hidden vari-
ables.
The term ‘hidden variables’ immediately raises
questions about the potential invocation of nonlocal dy-
namics, the study of which has motivated famous papers
like [40] and has led to the development of a number of
important theorems [35, 41–43].
Before assessing the implications of these theorems for
the picture described in this paper, it will be important to
note that these theorems do not rule out the possibility of
hidden variables altogether. Nor do these theorems imply
that introducing hidden variables would necessarily make
quantum theory any more dynamically nonlocal than it
already is.
Being mindful of those caveats, there is ample reason to
probe the question of nonlocal dynamics in the approach
to quantum theory taken in this paper. After all, looking
back at the discussion of entanglement in Section XI, a
pair of systems that interact at some time will generically
exhibit what look like nonlocal stochastic dynamics after
that time, at least until the later occurrence of a division
event due to decoherence by an external system.
columns already in ˜V (t), where the new index γ runs through N2
possible values. The last step is to show that ˜U(t) satisﬁes (153),
whose right-hand side reduces to P
β,m | ˜U(iβm)(jγ)(t)|2. QED

18
In what follows, it will be important to be keep in mind
the distinction between deterministic hidden-variables
theories and stochastic hidden-variables theories.
Bell’s original nonlocality theorem, as formulated and
proved in [41], only addressed the case of a deterministic
hidden-variables theory. Speciﬁcally, Bell showed that if
one assumes that a theory’s hidden variables uniquely de-
termine measurement outcomes, and if one also assumes
that local measurement results should not depend on the
settings of faraway measuring devices, then one arrives
at an inequality that is expressly violated by quantum
theory.
There seemed to be just two available options in re-
sponse to this nonlocality theorem. One could either ac-
cept a theory of nonlocal deterministic hidden variables,
or deny the existence of deterministic hidden variables
and thereby avoid having to introduce any dynamical
nonlocality into quantum theory.
However,
for a hidden-variables theory based on
stochastic dynamics rather than deterministic dynamics,
the question of dynamical nonlocality becomes murkier.
The generalization to stochastic dynamics means that
one needs to rely on more abstract, statistical conditions
for establishing whether the theory’s hidden variables be-
have in a dynamically local manner.
The most frequently cited statistical locality criterion
for stochastic hidden-variables theories was formulated
by Bell later on [35, 44, 45].
That statistical locality
criterion is a statement about how rich a theory’s hidden
variables should be in order for the theory to qualify as
dynamically local.
To formulate this statistical locality criterion, start by
considering the case of a measurement outcome x based
on local measurement settings a, and a far-separated
measurement outcome y based on local measurement
settings b.
Then suppose that the joint probabilities
p(x, y|a, b) for the measurement results x and y, con-
ditioned on the measurement settings a and b, show a
statistical correlation. Bell argued that in order for the
theory in question to be considered dynamically local,
the theory should contain enough hidden variables to ac-
count for the statistical correlation in the following pre-
cise sense: if one conditions on all the hidden variables λ
in the past light cone of the two measurements, then the
joint probabilities should factorize according to
p(x, y|a, b, λ) = p(x, a|λ)p(y, b|λ).
(154)
Bell’s statistical locality criterion is precisely the con-
dition that the theory in question should have enough
hidden variables to ensure that the factorization (154) is
always possible. Based on this statistical locality crite-
rion, which should hold even in cases of ‘one-shot’ mea-
surements in which certain measurement outcomes can
be assigned a probability of 1 [43], one can again derive
predictions that are violated by quantum theory, just as
in the case of a deterministic hidden-variables theory.
However, this statistical locality criterion is broader
than the conditions Bell studied in his earlier work on
deterministic hidden-variables theories in [41]. Bell’s sta-
tistical locality condition is so broad, in fact, that Bell
used it to argue that textbook quantum theory is itself
dynamically nonlocal [35, 46].
To understand why, observe that textbook quantum
theory is committed to the existence of measurement set-
tings and deﬁnite measurement outcomes that end up be-
having precisely as a (highly incomplete) set of stochas-
tically evolving hidden variables.
In other words, al-
though textbook quantum theory is not a deterministic
hidden-variables theory, it is, in fact, a stochastic hidden-
variables theory.
The stochastic-quantum correspondence makes these
commitments by textbook quantum theory manifest. In-
deed, one can regard textbook quantum theory as the
insistence that for any measurement set-up consisting of
a subject system S, a measuring device D, and an envi-
ronment E, as laid out in Section XIII, the conﬁgurations
of D are to be treated as hidden variables (that is, as be-
ables), whereas the conﬁgurations of S and E are to be
regarded merely as emergeables.
This seemingly arbitrary division of the world into
measuring devices, which truly have underlying conﬁg-
urations, and all other systems, which do not, leads di-
rectly to all the usual mysteries about the measurement
process according to textbook quantum theory. What, in
the end, determines whether a given system counts as a
measuring device, and therefore merits having underlying
conﬁgurations?
More relevant to the present discussion is that be-
cause textbook quantum theory includes stochastic hid-
den variables for measuring devices, and because those
stochastic hidden variables are insuﬃcient to ensure the
factorization property (154), the nonlocality theorems
that employ Bell’s statistical locality criterion imply that
textbook quantum theory is itself dynamically nonlocal.
Hence, there is no real cost to upgrading the conﬁgura-
tions of S and E to being hidden variables on an equal
footing with the conﬁgurations of D. These additional
hidden variables do not lead to the factorization property
(154) either, but they also do not lead to any trouble for
the no-communication theorem [47, 48], which precludes
using quantum theory to send controllable signals faster
than light.
The main conclusion of this analysis is that if one takes
Bell’s statistical locality criterion seriously, then text-
book quantum theory is already dynamically nonlocal,
so adding some additional hidden variables to the theory
will not ultimately make that dynamical nonlocality any
worse. If one instead disputes Bell’s statistical locality
criterion, then it cannot be used to argue that the picture
of quantum theory presented in this paper is dynamically
nonlocal. Either way, the approach taken toward quan-
tum theory in this paper is no more or less dynamically

19
nonlocal than textbook quantum theory already is.
A number of other important no-go theorems have
been proved over the years, like von Neumann’s early
no-go theorem [9], the Kochen-Specker theorem [49], the
Pusey-Barrett-Rudolph theorem [50], and Myrvold’s no-
go theorem [51]. These theorems either assume that all
observables are true random variables (that is, beables)
that exist at the level of the given system’s conﬁgura-
tion space, or they assume that measurements are pas-
sive operations that merely reveal pre-existing values of
observables without altering the behavior of measured
systems in the process, or they assume the existence of
additional probability formulas. Because the picture of
quantum theory introduced in this paper refrains from
making any of these assumptions, it is consistent with
these theorems.
XIX.
DISCUSSION
This paper has shown that one can reconstruct the
mathematical formalism and predictions of quantum the-
ory using simpler, more physically transparent axioms
than the standard Dirac-von Neumann axioms. Rather
than postulating Hilbert spaces and their ingredients
from the beginning, one instead posits a physical model
based on classical kinematics and generically indivisible
stochastic dynamics.
This new axiomatic approach naturally suggests a new
interpretation of quantum theory grounded in the theory
of stochastic processes. According to this highly adapt-
able interpretation, which one could naturally call the
‘indivisible interpretation’ of quantum theory, systems
have underlying physical conﬁgurations in conﬁguration
spaces at all times, and their dynamics is no more or less
nonlocal than the dynamics of textbook quantum theory.
From this perspective, density matrices, wave func-
tions, and other appurtenances of Hilbert spaces, while
highly useful, are merely gauge variables and should not
be assigned direct physical meanings or treated as though
they directly represent physical objects, any more than
a Lagrangian or a Hamilton’s principal function directly
describe physical objects. Superposition is then not a lit-
eral smearing of physical objects, but is merely a math-
ematical artifact of catching a system in the middle of
an indivisible stochastic process, as represented using a
Hilbert-space formulation and wave functions. Moreover,
from this standpoint, ‘canonical quantization’ need not
be regarded as the promotion of classical observables to
noncommutative operators by ﬁat, but can be imple-
mented (when mathematically feasible) simply by gen-
eralizing a classical system’s dynamics from being deter-
ministic to being stochastic, with all the exotic features
of quantum theory then emerging automatically.
Because the indivisible interpretation invokes hidden
variables in the form of underlying physical conﬁgura-
tions, this approach to quantum theory shares some fea-
tures with the de Broglie-Bohm formulation, or Bohmian
mechanics [52–54]. However, in contrast to the indivis-
ible interpretation, Bohmian mechanics employs deter-
ministic dynamics, and features a guiding equation that
fundamentally breaks Lorentz invariance by singling out
a preferred foliation of spacetime into spacelike hyper-
surfaces. The indivisible interpretation instead takes se-
riously what experiments strongly suggest—that the dy-
namics of quantum theory is indeterministic.
In contrast with the Everett interpretation [55, 56],
the indivisible interpretation assumes that quantum sys-
tems, like classical systems, have deﬁnite conﬁgurations
in conﬁguration spaces, and does not attempt to derive
probability from non-probabilistic assumptions or grap-
ple with fundamental aspects of personal identity in a
universe continuously branching into large numbers of
parallel worlds. The approach in this paper is therefore
more modest, metaphysically speaking, than the Everett
interpretation. Neither the indivisible interpretation nor
the Everett interpretation satisﬁes the statistical local-
ity criterion described in Section XVIII, but the Ev-
erett interpretation arguably exhibits a diﬀerent notion
of dynamical locality at a level of description that tran-
scends its individual world-branches [57]. However, be-
cause each individual world-branch looks no more or less
nonlocal than the world according to textbook quantum
theory or the indivisible interpretation, it is not clear
what concrete beneﬁts the Everett interpretation’s dy-
namical locality truly provide.
Unlike stochastic-collapse theories [58, 59], the indivis-
ible interpretation does not entail any fundamental viola-
tions of unitarity, nor does it require introducing any new
constants of nature to specify dynamical-collapse rates.
The indivisible interpretation shares some features
with the modal interpretations [60–62], including an in-
sistence that systems always have deﬁnite conﬁgurations
of some kind at every moment in time, while assigning
at least some forms of probability a law-like, objective
role. In particular, like the minimal modal interpreta-
tion [63], the indivisible interpretation uses conditional
probabilities in a central way.
One diﬀerence between
the indivisible interpretation and most of the modal in-
terpretations, however, is the insistence by the indivis-
ible interpretation that the deﬁnite conﬁguration of a
given system is an element of a classical-looking conﬁgu-
ration space, rather than corresponding more abstractly
to features of a Hilbert space. The indivisible interpreta-
tion also avoids some of the ontological instabilities that
are a serious challenge for most of the modal interpreta-
tions [64].
Looking forward,
it would be interesting to see
what implications the stochastic-quantum correspon-
dence could have for both phenomenological stochastic
systems, like those in biology or ﬁnance, as well as for fu-
ture work in fundamental physics, like quantum gravity.

20
More broadly, by recasting the Hilbert-space formu-
lation of quantum theory as merely a convenient way
to represent stochastic processes, one opens the door to
searching for totally diﬀerent representations that might
look nothing at all like Hilbert spaces and that could al-
low for the construction of more general kinds of stochas-
tic processes. Perhaps one could even ﬁnd a way to gen-
eralize beyond stochastic processes altogether.
ACKNOWLEDGMENTS
The author would especially like to acknowledge Emily
Adlam, David Albert, Howard Georgi, David Kagan,
and Logan McCarty for extensive discussions during the
writing of this paper.
The author would also like to
thank David Baker, Louis Deslauriers, Melissa Franklin,
Mina Himwich, David Kaiser, Efthimios Kaxiras, Gre-
gory Kestin, Curtis McMullen, and Matthew Reece for
helpful discussions.
[1] E. C. G. Sudarshan, P. M. Mathews, and J. Rau.
“Stochastic
Dynamics
of
Quantum-Mechanical
Sys-
tems”.
Physical
Review,
121:920–924,
February
1961.
URL:
http://link.aps.org/doi/10.1103/
PhysRev.121.920, doi:10.1103/PhysRev.121.920.
[2] G. A. Skorobogatov and S. I. Svertilov. “Quantum Me-
chanics can be Formulated as a Non-Markovian Stochas-
tic Process”.
Physical Review A, 58(5):3426–3432,
November 1998. doi:10.1103/PhysRevA.58.3426.
[3] D. T. Gillespie. “Non-Markovian Stochastic Processes”.
In AIP Conference Proceedings, volume 511, pages 49–
56. American Institute of Physics, July 2000. doi:10.
1063/1.60002.
[4] D. T. Gillespie, W. O. Alltop, and J. M. Martin. “Mod-
eling Quantum Measurement Probability as a Classical
Stochastic Process”. Chaos: An Interdisciplinary Jour-
nal of Nonlinear Science, 11(3):548–562, August 2001.
doi:10.1063/1.1378791.
[5] S. Aaronson. “Quantum Computing and Hidden Vari-
ables”.
Physical Review A, 71(3):032325, March 2005.
doi:10.1103/PhysRevA.71.032325.
[6] C. Wetterich.
“Quantum Representation of Clas-
sical
Statistical
Ensembles”.
Unpublished
draft,
2009. URL: https://www.thphys.uni-heidelberg.de/
~wetterich/Material/quantum_representation.pdf.
[7] M. Frasca. “Quantum Mechanics is the Square Root of a
Stochastic Process”. arXiv, 2012. URL: http://arxiv.
org/abs/1201.5091, arXiv:1201.5091.
[8] P. A. M. Dirac. The Principles of Quantum Mechanics.
Oxford University Press, 1st edition, 1930.
[9] J. von Neumann. Mathematische Grundlagen der Quan-
tenmechanik. Berlin: Springer, 1932.
[10] S. Ross. Stochastic Processes. John Wiley and Sons, 2nd
edition, 1995.
[11] S. Milz and K. Modi. “Quantum Stochastic Processes and
Quantum Non-Markovian Phenomena”. PRX Quantum,
2:030201, May 2021.
URL: https://dx.doi.org/10.
1103/PRXQuantum.2.030201, arXiv:2012.01894v2, doi:
10.1103/PRXQuantum.2.030201.
[12] I. Schur.
“Bemerkungen zur Theorie der beschr¨ank-
ten Bilinearformen mit unendlich vielen Ver¨anderlichen”.
Journal f¨ur die reine und angewandte Mathematik,
140:1–28, 1911. URL: https://eudml.org/doc/149352.
[13] P. R. Halmos. Finite-Dimensional Vector Spaces. Van
Nostrand, 2nd edition, 1958.
[14] R. A. Horn. “The Hadamard Product”. In Matrix Theory
and Applications, volume 40, pages 87–169, 1990. doi:
10.1090/psapm/040/1059485.
[15] G. W. Mackey.
“Induced Representations of Lo-
cally Compact Groups I”.
Annals of Mathematics,
55(1):101–139, 1952.
URL: http://www.jstor.org/
stable/1969423, doi:10.2307/1969423.
[16] G. W. Mackey.
“Quantum Mechanics and Hilbert
Space”. The American Mathematical Monthly, 64(8):45–
57,
1957.
URL:
http://www.jstor.org/stable/
2308516, doi:10.2307/2308516.
[17] A. Auﬀeves and P. Grangier.
“Recovering the Quan-
tum Formalism from Physically Realist Axioms”. Sci-
entiﬁc Reports, 7:43365, Dec. 2017. URL: http://doi.
org/10.1038/srep43365, arXiv:1610.06164v2, doi:10.
1038/srep43365.
[18] D. J. Griﬃths and D. F. Schroeter. Introduction to Quan-
tum Mechanics. Cambridge University Press, 3rd edition,
2018.
[19] J. S. Townsend. A Modern Approach to Quantum Me-
chanics. Cambridge University Press, 2nd edition, 2012.
[20] R. Shankar. Principles of Quantum Mechanics. Plenum
Press, 2nd edition, 1994.
[21] J. J. Sakurai and J. J. Napolitano.
Modern Quantum
Mechanics. Addison-Wesley, 2nd edition, 2010.
[22] B. Schumacher and M. Westmoreland.
Quantum Pro-
cesses, Systems, and Information. Cambridge University
Press, 1st edition, 2010.
[23] D. J. Griﬃths. Introduction to Electrodynamics. Cam-
bridge University Press, 4th edition, 2017.
[24] A. Zangwill. Modern Electrodynamics. Cambridge Uni-
versity Press, 2012.
[25] J. D. Jackson.
Classical Electrodynamics.
Wiley, 3rd
edition, 1998.
[26] H. Brown.
“Aspects of Objectivity in Quantum Me-
chanics”.
In From Physics to Philosophy, pages 45–
70. Cambridge University Press, 1999.
URL: https:
//philpapers.org/rec/BROAOO-2.
[27] K.
Kraus.
“General
State
Changes
in
Quan-
tum
Theory”.
Annals
of
Physics,
64(2):311–335,
June
1971.
URL:
http://www.sciencedirect.
com/science/article/pii/0003491671901084,
doi:10.1016/0003-4916(71)90108-4.
[28] J. A. Barandes and D. Kagan. “Quantum Conditional
Probabilities and New Measures of Quantum Informa-
tion”.
Annals of Physics, 448:169192, January 2023.
arXiv:2109.07447, doi:10.1016/j.aop.2022.169192.
[29] R. C. Thompson.
Lecture notes from a Johns Hop-
kins University lecture series. Unpublished lecture notes,
1989.
[30] P. Nylen, T.-Y. Tam, and F. Uhlig. “On the Eigenval-
ues of Principal Submatrices of Normal, Hermitian and
Symmetric Matrices”.
Linear and Multilinear Algebra,
36(1):69–78, 1993. doi:10.1080/03081089308818276.
[31] M. E. Peskin and D. V. Schroeder. An Introduction to
Quantum Field Theory. Westview Press, 1995.

21
[32] S. Weinberg. The Quantum Theory of Fields, volume 2.
Cambridge University Press, 1996.
[33] R. P. Feynman, R. B. Leighton, and M. Sands. The Feyn-
man Lectures on Physics, Volume 3.
Addison-Wesley,
1965.
URL: https://www.feynmanlectures.caltech.
edu/III_toc.html.
[34] E. Schr¨odinger.
“An Undulatory Theory of the Me-
chanics
of
Atoms
and
Molecules”.
Physical
Re-
view, 28(6):1049–1070, December 1926.
doi:10.1103/
PhysRev.28.1049.
[35] J. S. Bell.
“The Theory of Local Beables”.
CERN,
1975.
URL:
https://cds.cern.ch/record/980036/
files/197508125.pdf.
[36] W. Myrvold.
“Philosophical Issues in Quantum The-
ory”.
In E. N. Zalta and U. Nodelman,
editors,
The Stanford Encyclopedia of Philosophy. Metaphysics
Research Lab, Stanford University, Fall 2022 edition,
2022.
URL: https://plato.stanford.edu/archives/
fall2021/entries/bell-theorem/.
[37] E. C. G. Stueckelberg.
“Quantum Theory in Real
Hilbert Space”.
Helvetica Physica Acta, 33(4):727–
752, 1960. URL: https://www.e-periodica.ch/digbib/
view?pid=hpa-001:1960:33::715#735.
[38] J. Myrheim.
“Quantum Mechanics on a Real Hilbert
Space”. 1999. URL: https://arxiv.org/abs/quant-ph/
9905037, arXiv:quant-ph/9905037.
[39] W. F. Stinespring. “Positive functions on C*-algebras”.
Proceedings
of
the
American
Mathematical
Society,
6(2):211–216, April 1955. doi:10.2307/2032342.
[40] A. Einstein, B. Podolsky, and N. Rosen. “Can Quantum-
Mechanical Description of Physical Reality Be Consid-
ered Complete?”. Physical Review, 47(10):777–780, May
1935. doi:10.1103/PhysRev.47.777.
[41] J. S. Bell. “On the Einstein-Podolsky-Rosen Paradox”.
Physics, 1(3):195–200, 1964.
[42] J. F. Clauser, M. A. Horne, A. E. Shimony, and R. A.
Holt.
“Proposed Experiment to Test Local Hidden-
Variable Theories”. Physical Review Letters, 23(15):880–
884, October 1969. doi:10.1103/PhysRevLett.23.880.
[43] D. M. Greenberger, M. A. Horne, and A. Zeilinger.
“Going Beyond Bell’s Theorem”.
In Bell’s Theo-
rem, Quantum Theory and Conceptions of the Uni-
verse,
Fundamental Theories of Physics,
pages 69–
72. Springer, 1989.
arXiv:0712.0921, doi:10.1007/
978-94-017-0849-4_10.
[44] J. Butterﬁeld. “Bell’s Theorem: What it Takes”. The
British Journal for the Philosophy of Science, 43(1):41–
83, March 1992. URL: https://www.jstor.org/stable/
687884, doi:10.1093/bjps/43.1.41.
[45] W. Myrvold, M. Genovese, and A. Shimony.
“Bell’s
Theorem”.
In
E.
N.
Zalta,
editor,
The
Stan-
ford
Encyclopedia
of
Philosophy.
Metaphysics
Re-
search Lab,
Stanford University,
Fall 2021 edition,
2021.
URL: https://plato.stanford.edu/archives/
fall2021/entries/bell-theorem/.
[46] J. S. Bell. “La Nouvelle Cuisine”. In A. Sarlemijn and
P. Kroes, editors, Between Science and Technology, pages
97–115. Elsevier, 1990.
[47] G. C. Ghirardi, A. Rimini, and T. Weber. “A General
Argument Against Superluminal Transmission Through
the Quantum Mechanical Measurement Process”. Lettere
al Nuovo Cimento, 27(10):293–298, 1980. doi:10.1007/
BF02817189.
[48] T. F. Jordan. “Quantum Correlations do not Transmit
Signals”. Physics Letters A, 94(6):264, 1983. doi:10.
1016/0375-9601(83)90713-2.
[49] S. B. Kochen and E. P. Specker. “The Problem of Hidden
Variables in Quantum Mechanics”. Indiana University
Mathematics Journal, 17(1):59–87, 1967.
[50] M. F. Pusey, J. Barrett, and T. Rudolph. “On the Reality
of the Quantum State”. Nature Physics, 8(6):475–478,
2012. arXiv:1111.3328, doi:10.1038/nphys2309.
[51] W. C. Myrvold. “Modal Interpretations and Relativity”.
Foundations of Physics, 32(11):1773–1784, 2002. URL:
https://doi.org/10.1023/A%3A1021406924313, arXiv:
quant-ph/0209109, doi:10.1023/A:1021406924313.
[52] L. de Broglie.
An Introduction to the Study of Wave
Mechanics. E. P. Dutton and Company, Inc., 1930.
[53] D. J. Bohm. “A Suggested Interpretation of the Quan-
tum Theory in Terms of ‘Hidden’ Variables. I”. Physi-
cal Review, 85(2):166–179, January 1952. doi:10.1103/
PhysRev.85.166.
[54] D. J. Bohm. “A Suggested Interpretation of the Quan-
tum Theory in Terms of ‘Hidden’ Variables. II”. Physi-
cal Review, 85(2):180–193, January 1952. doi:10.1103/
PhysRev.85.180.
[55] H. Everett III. “ ‘Relative State’ Formulation of Quan-
tum Mechanics”. Reviews of Modern Physics, 29(3):454–
462, July 1957. doi:10.1103/RevModPhys.29.454.
[56] H. Everett III. “The Theory of the Universal Wave Func-
tion”. In The Many-Worlds Interpretation of Quantum
Mechanics, volume 1, page 3, 1973.
[57] D. Wallace. The Emergent Multiverse: Quantum Theory
According to the Everett Interpretation. Oxford Univer-
sity Press, 2012.
[58] G. C. Ghirardi, A. Rimini, and T. Weber.
“Uniﬁed
Dynamics for Microscopic and Macroscopic Systems”.
Physical Review D, 34(2):470–491, 1986. doi:10.1103/
PhysRevD.34.470.
[59] A. Bassi and G. C. Ghirardi.
“Dynamical reduction
models”. Physical Reports, 379(5):257–426, 2003. URL:
http://www.sciencedirect.com/science/article/
pii/S0370157303001030,
arXiv:quant-ph/0302164,
doi:10.1016/S0370-1573(03)00103-0.
[60] H. P. Krips. “Two Paradoxes in Quantum Mechanics”.
Philosophy of Science, 36(2):145–152, June 1969. URL:
http://www.jstor.org/stable/186167.
[61] B. C. Van Fraassen. “A Formal Approach to the Philos-
ophy of Science”. In R. Colodny, editor, “Paradigms and
Paradoxes: The Philosophical Challenge of the Quantum
Domain”, pages 303–366. University of Pittsburgh Press,
1972.
[62] P. E. Vermaas and D. G. B. J. Dieks.
“The Modal
Interpretation of Quantum Mechanics and Its General-
ization to Density Operators”. Foundations of Physics,
25(1):145–158, 1995. doi:10.1007/BF02054662.
[63] J. A. Barandes and D. Kagan. “Measurement and Quan-
tum Dynamics in the Minimal Modal Interpretation of
Quantum Theory”. Foundations of Physics, 50(10):1189–
1218, October 2020. arXiv:1807.07136, doi:10.1007/
s10701-020-00374-0.
[64] P. E. Vermaas.
A Philosopher’s Understanding of
Quantum Mechanics:
Possibilities and Impossibilities
of
a
Modal
Interpretation.
Cambridge
University
Press, 1999.
URL: http://books.google.com/books?
id=X2V769s0QIYC.

