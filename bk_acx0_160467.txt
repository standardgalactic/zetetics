CODE LISTINGS AND FIGURES

CHAPTER 1
Figure 1.1. The height of each stickman is the previous two stickmen’s heights added
together.
1 0, 1, 1, 2, 3, 5, 8, 13, 21...
1 fib(n) = fib(n - 1) + fib(n - 2)
Listing 1.1. Øb1.py
1
2
def fib1(n: int) -> int: 
    return fib1(n - 1) + fib1(n - 2)


Figure 1.2. The recursive function fib(n)  calls itself with the arguments n-2  and
n-1 .
Listing 1.2. Øb1.py continued
1
2
if __name__ == "__main__": 
    print(fib1(5))
1 RecursionError: maximum recursion depth exceeded

Listing 1.3. Øb2.py
1
2
3
4
def fib2(n: int) -> int: 
    if n < 2:  # base case 
        return n 
    return fib2(n - 2) + fib2(n - 1)  # recursive case
Listing 1.4. Øb2.py continued
1
2
3
if __name__ == "__main__": 
    print(fib2(5)) 
    print(fib2(10))
1
2
3
fib2(4) -> fib2(3), fib2(2) 
fib2(3) -> fib2(2), fib2(1) 
fib2(2) -> fib2(1), fib2(0) 

Figure 1.3. Every non-base-case call of fib2()  results in two more calls of fib2() .
Figure 1.4. The human memoization machine
4
5
6
7
8
9
fib2(2) -> fib2(1), fib2(0) 
fib2(1) -> 1 
fib2(1) -> 1 
fib2(1) -> 1 
fib2(0) -> 0 
fib2(0) -> 0

Listing 1.5. Øb3.py
1
2
3
4
5
6
7
from typing import Dict 
memo: Dict[int, int] = {0: 0, 1: 1}  # our base cases 
 
def fib3(n: int) -> int: 
    if n not in memo: 
        memo[n] = fib3(n - 1) + fib3(n - 2)  # memoization 
    return memo[n]

Listing 1.6. Øb3.py continued
1
2
3
if __name__ == "__main__": 
    print(fib3(5)) 
    print(fib3(50))
Listing 1.7. Øb4.py
1
2
3
4
5
from functools import lru_cache 
 
@lru_cache(maxsize=None) 
def fib4(n: int) -> int:  # same definition as fib2() 
    if n < 2:  # base case 

Figure 1.5. Compressing a str  representing a gene into a 2-bit-per-nucleotide bit
string
6
7
8
9
10
11
        return n 
    return fib4(n - 2) + fib4(n - 1)  # recursive case 
 
if __name__ == "__main__": 
    print(fib4(5)) 
    print(fib4(50))
Listing 1.8. Øb5.py
1
2
3
4
5
6
7
8
9
10
11
def fib5(n: int) -> int: 
    if n == 0: return n  # special case 
    last: int = 0  # initially set to fib(0) 
    next: int = 1  # initially set to fib(1) 
    for _ in range(1, n): 
        last, next = next, last + next 
    return next 
 
if __name__ == "__main__": 
    print(fib5(5)) 
    print(fib5(50))
Listing 1.9. Øb6.py
1
2
3
4
5
6
7
8
9
10
11
12
13
14
from typing import Generator 
 
def fib6(n: int) -> Generator[int, None, None]: 
    yield 0  # special case 
    if n > 0: yield 1  # special case 
    last: int = 0  # initially set to fib(0) 
    next: int = 1  # initially set to fib(1) 
    for _ in range(1, n): 
        last, next = next, last + next 
        yield next  # main generation step 
 
if __name__ == "__main__": 
    for i in fib6(50): 
        print(i)

Listing 1.10. trivial_compression.py
1
2
3
class CompressedGene: 
    def __init__(self, gene: str) -> None: 
        self._compress(gene)
Listing 1.11. trivial_compression.py continued
1
2
3
4
5
6
7
8
9
10
11
12
def _compress(self, gene: str) -> None: 
    self.bit_string: int = 1  # start with sentinel 
    for nucleotide in gene.upper(): 
        self.bit_string <<= 2  # shift left two bits 
        if nucleotide == "A":  # change last two bits to 00 
            self.bit_string |= 0b00 
        elif nucleotide == "C":  # change last two bits to 01 
            self.bit_string |= 0b01 
        elif nucleotide == "G":  # change last two bits to 10 
            self.bit_string |= 0b10 
        elif nucleotide == "T":  # change last two bits to 11 
            self.bit_string |= 0b11 

13
14
        else: 
            raise ValueError("Invalid Nucleotide:{}".format(nucleotide))
Listing 1.12. trivial_compression.py continued
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
def decompress(self) -> str: 
    gene: str = "" 
    for i in range(0, self.bit_string.bit_length() - 1, 2):  # - 1 to exclude 
     sentinel 
        bits: int = self.bit_string >> i & 0b11  # get just 2 relevant bits 
        if bits == 0b00:  # A 
            gene += "A" 
        elif bits == 0b01:  # C 
            gene += "C" 
        elif bits == 0b10:  # G 
            gene += "G" 
        elif bits == 0b11:  # T 
            gene += "T" 
        else: 
            raise ValueError("Invalid bits:{}".format(bits)) 
    return gene[::-1]  # [::-1] reverses string by slicing backward 
 
def __str__(self) -> str:  # string representation for pretty printing 
    return self.decompress()
Listing 1.13. trivial_compression.py continued
1
2
3
4
5
6
7
8
9
10
11
if __name__ == "__main__": 
    from sys import getsizeof 
    original: str = 
     "TAGGGATTAACCGTTATATATATATAGCCATGGATCGATTATATAGGGATTAACCGTTATATATATATAGC 
     CATGGATCGATTATA" * 100 
    print("original is {} bytes".format(getsizeof(original))) 
    compressed: CompressedGene = CompressedGene(original)  # compress 
    print("compressed is {} bytes".format(getsizeof(compressed.bit_string))) 
    print(compressed)  # decompress 
    print("original and decompressed are the same: {}".format(original == 
     compressed.decompress()))
Listing 1.14. trivial_compression.py output
1
2
3
4
original is 8649 bytes 
compressed is 2320 bytes 
TAGGGATTAACC... 
original and decompressed are the same: True

Figure 1.6. A one-time pad results in two keys that can be separated and then
recombined to re-create the original data.
Listing 1.15. unbreakable_encryption.py
1
2
3
4
5
6
7
8
from secrets import token_bytes 
from typing import Tuple 
 
def random_key(length: int) -> int: 
    # generate length random bytes 
    tb: bytes = token_bytes(length) 
    # convert those bytes into a bit string and return it 
    return int.from_bytes(tb, "big")
1
2
3
A ^ B = C 
C ^ B = A 
C ^ A = B

Listing 1.16. unbreakable_encryption.py continued
1
2
3
4
5
6
def encrypt(original: str) -> Tuple[int, int]: 
    original_bytes: bytes = original.encode() 
    dummy: int = random_key(len(original_bytes)) 
    original_key: int = int.from_bytes(original_bytes, "big") 
    encrypted: int = original_key ^ dummy  # XOR 
    return dummy, encrypted
Listing 1.17. unbreakable_encryption.py continued
1
2
3
4
def decrypt(key1: int, key2: int) -> str: 
    decrypted: int = key1 ^ key2  # XOR 
    temp: bytes = decrypted.to_bytes((decrypted.bit_length()+ 7) // 8, "big") 
    return temp.decode()
Listing 1.18. unbreakable_encryption.py continued
1
2
3
4
if __name__ == "__main__": 
    key1, key2 = encrypt("One Time Pad!") 
    result: str = decrypt(key1, key2) 
    print(result)
1 π = 4/1 - 4/3 + 4/5 - 4/7 + 4/9 - 4/11...
Listing 1.19. calculating_pi.py
1
2
3
4
5
6
7
8
9
def calculate_pi(n_terms: int) -> float: 
    numerator: float = 4.0 
    denominator: float = 1.0 
    operation: float = 1.0 
    pi: float = 0.0 
    for _ in range(n_terms): 
        pi += operation * (numerator / denominator) 
        denominator += 2.0 
        operation *= -1.0 

Figure 1.7. The 
 is to move the three discs, one at a time, from tower A to
tower C. A larger disc may never be on top of a smaller disc.
challenge
10
11
12
13
    return pi 
 
if __name__ == "__main__": 
    print(calculate_pi(1000000))
Listing 1.20. hanoi.py
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
from typing import TypeVar, Generic, List 
T = TypeVar('T') 
 
class Stack(Generic[T]): 
 
    def __init__(self) -> None: 
        self._container: List[T] = [] 
 
    def push(self, item: T) -> None: 
        self._container.append(item) 
 
    def pop(self) -> T: 
        return self._container.pop() 
 

16     def __repr__(self) -> str: 
        return repr(self._container)
Listing 1.21. hanoi.py continued
1
2
3
4
5
6
num_discs: int = 3 
tower_a: Stack[int] = Stack() 
tower_b: Stack[int] = Stack() 
tower_c: Stack[int] = Stack() 
for i in range(1, num_discs + 1): 
    tower_a.push(i)
Listing 1.22. hanoi.py continued
1
2
3
4
5
6
7
8
def hanoi(begin: Stack[int], end: Stack[int], temp: Stack[int], n: int) -> 
     None: 
    if n == 1: 
        end.push(begin.pop()) 
    else: 
        hanoi(begin, temp, end, n - 1) 
        hanoi(begin, end, temp, 1) 
        hanoi(temp, end, begin, n - 1)
Listing 1.23. hanoi.py continued
1
2
3
4
5
if __name__ == "__main__": 
    hanoi(tower_a, tower_c, tower_b, num_discs) 
    print(tower_a) 
    print(tower_b) 
    print(tower_c)

CHAPTER 2
Figure 2.1. A nucleotide is represented by one of the letters A, C, G, and T. A codon is
composed of three nucleotides, and a gene is composed of multiple codons.
Listing 2.1. dna_search.py
1
2
3
4
from enum import IntEnum 
from typing import Tuple, List 
 
Nucleotide: IntEnum = IntEnum('Nucleotide', ('A', 'C', 'G', 'T'))
Listing 2.2. dna_search.py continued
1
2
Codon = Tuple[Nucleotide, Nucleotide, Nucleotide]  # type alias for codons 
Gene = List[Codon]  # type alias for genes
Listing 2.3. dna_search.py continued

Figure 2.2. In the worst case of a linear search, you’ll sequentially look through every
element of the array.
1 gene_str: str = "ACGTGGCTCTCTAACGTACGTACGTACGGGGTTTATATATACCCTAGGACTCCCTTT"
Listing 2.4. dna_search.py continued
1
2
3
4
5
6
7
8
9
def string_to_gene(s: str) -> Gene: 
    gene: Gene = [] 
    for i in range(0, len(s), 3): 
        if (i + 2) >= len(s):  # don't run off end! 
            return gene 
        #  initialize codon out of three nucleotides 
        codon: Codon = (Nucleotide[s[i]], Nucleotide[s[i + 1]], Nucleotide[s[i + 2]])
        gene.append(codon)  # add codon to gene 
    return gene
Listing 2.5. dna_search.py continued
1 my_gene: Gene = string_to_gene(gene_str)
Listing 2.6. dna_search.py continued
1
2
3
4
5
def linear_contains(gene: Gene, key_codon: Codon) -> bool: 
    for codon in gene: 
        if codon == key_codon: 
            return True 
    return False 

Figure 2.3. In the worst case of a binary search, you’ll look through just lg(n) elements of
the list.
6
7
8
9
acg: Codon = (Nucleotide.A, Nucleotide.C, Nucleotide.G) 
gat: Codon = (Nucleotide.G, Nucleotide.A, Nucleotide.T) 
print(linear_contains(my_gene, acg))  # True 
print(linear_contains(my_gene, gat))  # False
Listing 2.7. dna_search.py continued
1
2
3
4
5
6
7
8
9
10
11
12
def binary_contains(gene: Gene, key_codon: Codon) -> bool: 
    low: int = 0 
    high: int = len(gene) - 1 
    while low <= high:  # while there is still a search space 
        mid: int = (low + high) // 2 
        if gene[mid] < key_codon: 
            low = mid + 1 
        elif gene[mid] > key_codon: 
            high = mid - 1 
        else: 
            return True 
    return False
1
2
low: int = 0 
high: int = len(gene) - 1
1 while low <= high:

1 mid: int = (low + high) // 2
1
2
if gene[mid] < key_codon: 
    low = mid + 1
1
2
elif gene[mid] > key_codon: 
    high = mid - 1
1
2
else: 
    return True
Listing 2.8. dna_search.py continued
1
2
3
my_sorted_gene: Gene = sorted(my_gene) 
print(binary_contains(my_sorted_gene, acg))  # True 
print(binary_contains(my_sorted_gene, gat))  # False
Listing 2.9. generic_search.py
1
2
3
4
5
6
7
8
from __future__ import annotations 
from typing import TypeVar, Iterable, Sequence, Generic, List, Callable, Set, 
     Deque, Dict, Any, Optional 
from typing_extensions import Protocol 
from heapq import heappush, heappop 
 
T = TypeVar('T') 
def linear_contains(iterable: Iterable[T], key: T) -> bool: 

9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
    for item in iterable: 
        if item == key: 
            return True 
    return False 
 
C = TypeVar("C", bound="Comparable") 
 
class Comparable(Protocol): 
    def __eq__(self, other: Any) -> bool: 
        ... 
 
    def __lt__(self: C, other: C) -> bool: 
        ... 
 
    def __gt__(self: C, other: C) -> bool: 
        return (not self < other) and self != other 
 
    def __le__(self: C, other: C) -> bool: 
        return self < other or self == other 
 
    def __ge__(self: C, other: C) -> bool: 
        return not self < other 
 
 
def binary_contains(sequence: Sequence[C], key: C) -> bool: 
    low: int = 0 
    high: int = len(sequence) - 1 
    while low <= high:  # while there is still a search space 
        mid: int = (low + high) // 2 
        if sequence[mid] < key: 
            low = mid + 1 
        elif sequence[mid] > key: 
            high = mid - 1 
        else: 
            return True 
    return False 
 
if __name__ == "__main__": 
    print(linear_contains([1, 5, 15, 15, 15, 15, 20], 5))  # True 
    print(binary_contains(["a", "d", "e", "f", "z"], "f"))  # True 
    print(binary_contains(["john", "mark", "ronald", "sarah"], "sheila"))  # 
     False
Listing 2.10. maze.py
1
2
3
4
5
6
7
8
9
10
11
12
from enum import Enum 
from typing import List, NamedTuple, Callable, Optional 
import random 
from math import sqrt 
from generic_search import dfs, bfs, node_to_path, astar, Node 
 
class Cell(str, Enum): 
    EMPTY = " " 
    BLOCKED = "X" 
    START = "S" 
    GOAL = "G" 
    PATH = "*"

Listing 2.11. maze.py continued
1
2
3
class MazeLocation(NamedTuple): 
    row: int 
    column: int
Listing 2.12. maze.py continued
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
class Maze: 
    def __init__(self, rows: int = 10, columns: int = 10, sparseness: float = 
     0.2, start: MazeLocation = MazeLocation(0, 0), goal: MazeLocation = 
     MazeLocation(9, 9)) -> None: 
        # initialize basic instance variables 
        self._rows: int = rows 
        self._columns: int = columns 
        self.start: MazeLocation = start 
        self.goal: MazeLocation = goal 
        # fill the grid with empty cells 
        self._grid: List[List[Cell]] = [[Cell.EMPTY for c in range(columns)] 
     for r in range(rows)] 
        # populate the grid with blocked cells 
        self._randomly_fill(rows, columns, sparseness) 
        # fill the start and goal locations in 
        self._grid[start.row][start.column] = Cell.START 
        self._grid[goal.row][goal.column] = Cell.GOAL 
 
    def _randomly_fill(self, rows: int, columns: int, sparseness: float): 
        for row in range(rows): 
            for column in range(columns): 
                if random.uniform(0, 1.0) < sparseness: 
                    self._grid[row][column] = Cell.BLOCKED
Listing 2.13. maze.py continued
1
2
3
4
5
6
# return a nicely formatted version of the maze for printing 
def __str__(self) -> str: 
    output: str = "" 
    for row in self._grid: 
        output += "".join([c.value for c in row]) + "\n" 
    return output
1
2
maze: Maze = Maze() 
print(maze)

Figure 2.4. In depth-Ørst search, the search proceeds along a continuously deeper path
until it hits a barrier and must backtrack to the last decision point.
Listing 2.14. maze.py continued
1
2
def goal_test(self, ml: MazeLocation) -> bool: 
    return ml == self.goal
Listing 2.15. maze.py continued
1
2
3
4
5
6
7
8
9
10
11
12
13
14
def successors(self, ml: MazeLocation) -> List[MazeLocation]: 
    locations: List[MazeLocation] = [] 
    if ml.row + 1 < self._rows and self._grid[ml.row + 1][ml.column] != 
     Cell.BLOCKED: 
        locations.append(MazeLocation(ml.row + 1, ml.column)) 
    if ml.row - 1 >= 0 and self._grid[ml.row - 1][ml.column] != Cell.BLOCKED: 
        locations.append(MazeLocation(ml.row - 1, ml.column)) 
    if ml.column + 1 < self._columns and self._grid[ml.row][ml.column + 1] != 
     Cell.BLOCKED: 
        locations.append(MazeLocation(ml.row, ml.column + 1)) 
    if ml.column - 1 >= 0 and self._grid[ml.row][ml.column - 1] != 
     Cell.BLOCKED: 
        locations.append(MazeLocation(ml.row, ml.column - 1)) 
    return locations

Listing 2.16. generic_search.py continued
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
class Stack(Generic[T]): 
    def __init__(self) -> None: 
        self._container: List[T] = [] 
 
    @property 
    def empty(self) -> bool: 
        return not self._container  # not is true for empty container 
 
    def push(self, item: T) -> None: 
        self._container.append(item) 
 
    def pop(self) -> T: 
        return self._container.pop()  # LIFO 
 
    def __repr__(self) -> str: 
        return repr(self._container)
Listing 2.17. generic_search.py continued
1
2
3
4
5
class Node(Generic[T]): 
    def __init__(self, state: T, parent: Optional[Node], cost: float = 0.0, 
     heuristic: float = 0.0) -> None: 
        self.state: T = state 
        self.parent: Optional[Node] = parent 

6
7
8
9
10
        self.cost: float = cost 
        self.heuristic: float = heuristic 
 
    def __lt__(self, other: Node) -> bool: 
        return (self.cost + self.heuristic) < (other.cost + other.heuristic)
Listing 2.18. generic_search.py continued
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
def dfs(initial: T, goal_test: Callable[[T], bool], successors: Callable[[T], 
     List[T]]) -> Optional[Node[T]]: 
    # frontier is where we've yet to go 
    frontier: Stack[Node[T]] = Stack() 
    frontier.push(Node(initial, None)) 
    # explored is where we've been 
    explored: Set[T] = {initial} 
 
    # keep going while there is more to explore 
    while not frontier.empty: 
        current_node: Node[T] = frontier.pop() 
        current_state: T = current_node.state 
        # if we found the goal, we're done 
        if goal_test(current_state): 
            return current_node 
        # check where we can go next and haven't explored 
        for child in successors(current_state): 
            if child in explored:  # skip children we already explored 
                continue 
            explored.add(child) 
            frontier.push(Node(child, current_node)) 
    return None  # went through everything and never found goal
Listing 2.19. generic_search.py continued
1
2
3
4
5
6
7
8
def node_to_path(node: Node[T]) -> List[T]: 
    path: List[T] = [node.state] 
    # work backwards from end to front 
    while node.parent is not None: 
        node = node.parent 
        path.append(node.state) 
    path.reverse() 
    return path
Listing 2.20. maze.py continued
1
2
3
def mark(self, path: List[MazeLocation]): 
    for maze_location in path: 
        self._grid[maze_location.row][maze_location.column] = Cell.PATH 

Figure 2.5. In a breadth-Ørst search, the closest elements to the starting location are
searched Ørst.
4
5
6
7
8
9
10
11
    self._grid[self.start.row][self.start.column] = Cell.START 
    self._grid[self.goal.row][self.goal.column] = Cell.GOAL 
 
def clear(self, path: List[MazeLocation]): 
    for maze_location in path: 
        self._grid[maze_location.row][maze_location.column] = Cell.EMPTY 
    self._grid[self.start.row][self.start.column] = Cell.START 
    self._grid[self.goal.row][self.goal.column] = Cell.GOAL
Listing 2.21. maze.py continued
1
2
3
4
5
6
7
8
9
10
11
12
13
if __name__ == "__main__": 
    # Test DFS 
    m: Maze = Maze() 
    print(m) 
    solution1: Optional[Node[MazeLocation]] = dfs(m.start, m.goal_test, 
     m.successors) 
    if solution1 is None: 
        print("No solution found using depth-first search!") 
    else: 
        path1: List[MazeLocation] = node_to_path(solution1) 
        m.mark(path1) 
        print(m) 
        m.clear(path1)
1
2
3
4
5
6
7
8
9
10
S****X X   
 X  *****  
       X*  
 XX******X 
  X*       
  X**X     
 X  *****  
        *  
     X  *X 
        *G

Listing 2.22. generic_search.py continued
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
class Queue(Generic[T]): 
    def __init__(self) -> None: 
        self._container: Deque[T] = Deque() 
 
    @property 
    def empty(self) -> bool: 
        return not self._container  # not is true for empty container 
 
    def push(self, item: T) -> None: 
        self._container.append(item) 
 
    def pop(self) -> T: 
        return self._container.popleft()  # FIFO 
 
    def __repr__(self) -> str: 
        return repr(self._container)
Listing 2.23. generic_search.py continued
1
2
3
4
5
def bfs(initial: T, goal_test: Callable[[T], bool], successors: Callable[[T], 
     List[T]]) -> Optional[Node[T]]: 
    # frontier is where we've yet to go 
    frontier: Queue[Node[T]] = Queue() 
    frontier.push(Node(initial, None)) 

6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
    # explored is where we've been 
    explored: Set[T] = {initial} 
 
    # keep going while there is more to explore 
    while not frontier.empty: 
        current_node: Node[T] = frontier.pop() 
        current_state: T = current_node.state 
        # if we found the goal, we're done 
        if goal_test(current_state): 
            return current_node 
        # check where we can go next and haven't explored 
        for child in successors(current_state): 
            if child in explored:  # skip children we already explored 
                continue 
            explored.add(child) 
            frontier.push(Node(child, current_node)) 
    return None  # went through everything and never found goal
Listing 2.24. maze.py continued
1
2
3
4
5
6
7
8
9
10
# Test BFS 
solution2: Optional[Node[MazeLocation]] = bfs(m.start, m.goal_test, 
     m.successors) 
if solution2 is None: 
    print("No solution found using breadth-first search!") 
else: 
    path2: List[MazeLocation] = node_to_path(solution2) 
    m.mark(path2) 
    print(m) 
    m.clear(path2)
1
2
3
4
5
6
7
8
9
10
S    X X   
*X         
*      X   
*XX      X 
* X        
* X  X     
*X         
*          
*    X   X 
*********G
Listing 2.25. generic_search.py continued
1
2
3
class PriorityQueue(Generic[T]): 
    def __init__(self) -> None: 
        self._container: List[T] = [] 

Figure 2.6. Euclidean distance is the 
 of a straight line from the starting point to
the goal.
length
4
5
6
7
8
9
10
11
12
13
14
15
16
 
    @property 
    def empty(self) -> bool: 
        return not self._container  # not is true for empty container 
 
    def push(self, item: T) -> None: 
        heappush(self._container, item)  # in by priority 
 
    def pop(self) -> T: 
        return heappop(self._container)  # out by priority 
 
    def __repr__(self) -> str: 
        return repr(self._container)
Listing 2.26. maze.py continued
1
2
3
4
5
6
7
def euclidean_distance(goal: MazeLocation) -> Callable[[MazeLocation], 
     float]: 
    def distance(ml: MazeLocation) -> float: 
        xdist: int = ml.column - goal.column 
        ydist: int = ml.row - goal.row 
        return sqrt((xdist * xdist) + (ydist * ydist)) 
    return distance
Listing 2.27. maze.py continued

Figure 2.7. In Manhattan distance, there are no diagonals. The path must be along
parallel or perpendicular lines.
1
2
3
4
5
6
7
def manhattan_distance(goal: MazeLocation) -> Callable[[MazeLocation], 
     float]: 
    def distance(ml: MazeLocation) -> float: 
        xdist: int = abs(ml.column - goal.column) 
        ydist: int = abs(ml.row - goal.row) 
        return (xdist + ydist) 
    return distance
Listing 2.28. generic_search.py
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
def astar(initial: T, goal_test: Callable[[T], bool], successors: 
     Callable[[T], List[T]], heuristic: Callable[[T], float]) -> 
     Optional[Node[T]]: 
    # frontier is where we've yet to go 
    frontier: PriorityQueue[Node[T]] = PriorityQueue() 
    frontier.push(Node(initial, None, 0.0, heuristic(initial))) 
    # explored is where we've been 
    explored: Dict[T, float] = {initial: 0.0} 
 
    # keep going while there is more to explore 
    while not frontier.empty: 
        current_node: Node[T] = frontier.pop() 
        current_state: T = current_node.state 
        # if we found the goal, we're done 
        if goal_test(current_state): 
            return current_node 
        # check where we can go next and haven't explored 
        for child in successors(current_state): 
            new_cost: float = current_node.cost + 1  # 1 assumes a grid, need 
     a cost function for more sophisticated apps 
 
            if child not in explored or explored[child] > new_cost: 
                explored[child] = new_cost 

Figure 2.8. The 
 must use their single canoe to take everyone
across the river from west to east. If the cannibals ever outnumber the missionaries,
they will eat them.
missionaries and cannibals
24
25
26
                frontier.push(Node(child, current_node, new_cost, 
     heuristic(child))) 
    return None  # went through everything and never found goal
Listing 2.29. maze.py continued
1
2
3
4
5
6
7
8
9
10
# Test A* 
distance: Callable[[MazeLocation], float] = manhattan_distance(m.goal) 
solution3: Optional[Node[MazeLocation]] = astar(m.start, m.goal_test, 
     m.successors, distance) 
if solution3 is None: 
    print("No solution found using A*!") 
else: 
    path3: List[MazeLocation] = node_to_path(solution3) 
    m.mark(path3) 
    print(m)
1
2
3
4
5
6
7
8
9
10
S**  X X 
 X**       
   *   X   
 XX*     X 
  X*       
  X**X     
 X  ****   
       *   
     X * X 
       **G

Listing 2.30. missionaries.py
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
from __future__ import annotations 
from typing import List, Optional 
from generic_search import bfs, Node, node_to_path 
 
MAX_NUM: int = 3 
 
 
class MCState: 
    def __init__(self, missionaries: int, cannibals: int, boat: bool) -> 
     None: 
        self.wm: int = missionaries # west bank missionaries 
        self.wc: int = cannibals # west bank cannibals 
        self.em: int = MAX_NUM - self.wm  # east bank missionaries 
        self.ec: int = MAX_NUM - self.wc  # east bank cannibals 
        self.boat: bool = boat 

16
17
18
19
20
21
22
23
24
 
    def __str__(self) -> str: 
        return ("On the west bank there are {} missionaries and {} 
     cannibals.\n" 
                "On the east bank there are {} missionaries and {} 
     cannibals.\n" 
                "The boat is on the {} bank.")\ 
            .format(self.wm, self.wc, self.em, self.ec, ("west" if self.boat 
     else "east"))
Listing 2.31. missionaries.py continued
1
2
def goal_test(self) -> bool: 
    return self.is_legal and self.em == MAX_NUM and self.ec == MAX_NUM
Listing 2.32. missionaries.py continued
1
2
3
4
5
6
7
@property 
def is_legal(self) -> bool: 
    if self.wm < self.wc and self.wm > 0: 
        return False 
    if self.em < self.ec and self.em > 0: 
        return False 
    return True
Listing 2.33. missionaries.py continued
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
def successors(self) -> List[MCState]: 
    sucs: List[MCState] = [] 
    if self.boat: # boat on west bank 
        if self.wm > 1: 
            sucs.append(MCState(self.wm - 2, self.wc, not self.boat)) 
        if self.wm > 0: 
            sucs.append(MCState(self.wm - 1, self.wc, not self.boat)) 
        if self.wc > 1: 
            sucs.append(MCState(self.wm, self.wc - 2, not self.boat)) 
        if self.wc > 0: 
            sucs.append(MCState(self.wm, self.wc - 1, not self.boat)) 
        if (self.wc > 0) and (self.wm > 0): 
            sucs.append(MCState(self.wm - 1, self.wc - 1, not self.boat)) 
    else: # boat on east bank 
        if self.em > 1: 
            sucs.append(MCState(self.wm + 2, self.wc, not self.boat)) 
        if self.em > 0: 
            sucs.append(MCState(self.wm + 1, self.wc, not self.boat)) 
        if self.ec > 1: 
            sucs.append(MCState(self.wm, self.wc + 2, not self.boat)) 

21
22
23
24
25
        if self.ec > 0: 
            sucs.append(MCState(self.wm, self.wc + 1, not self.boat)) 
        if (self.ec > 0) and (self.em > 0): 
            sucs.append(MCState(self.wm + 1, self.wc + 1, not self.boat)) 
    return [x for x in sucs if x.is_legal]
Listing 2.34. missionaries.py continued
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
def display_solution(path: List[MCState]): 
    if len(path) == 0: # sanity check 
        return 
    old_state: MCState = path[0] 
    print(old_state) 
    for current_state in path[1:]: 
        if current_state.boat: 
            print("{} missionaries and {} cannibals moved from the east bank 
     to the west bank.\n" 
                  .format(old_state.em - current_state.em, old_state.ec - 
     current_state.ec)) 
        else: 
            print("{} missionaries and {} cannibals moved from the west bank 
     to the east bank.\n" 
                  .format(old_state.wm - current_state.wm, old_state.wc - 
     current_state.wc)) 
        print(current_state) 
        old_state = current_state
Listing 2.35. missionaries.py continued
1
2
3
4
5
6
7
8
9
if __name__ == "__main__": 
    start: MCState = MCState(MAX_NUM, MAX_NUM, True) 
    solution: Optional[Node[MCState]] = bfs(start, MCState.goal_test, 
     MCState.successors) 
    if solution is None: 
        print("No solution found!") 
    else: 
        path: List[MCState] = node_to_path(solution) 
        display_solution(path)
1
2
3
4
5
6
7
8
On the west bank there are 3 missionaries and 3 cannibals. 
On the east bank there are 0 missionaries and 0 cannibals. 
The boast is on the west bank. 
0 missionaries and 2 cannibals moved from the west bank to the east bank. 
 
On the west bank there are 3 missionaries and 1 cannibals. 
On the east bank there are 0 missionaries and 2 cannibals. 
The boast is on the east bank. 

9
10
11
12
13
14
15
0 missionaries and 1 cannibals moved from the east bank to the west bank. 
 
... 
 
On the west bank there are 0 missionaries and 0 cannibals. 
On the east bank there are 3 missionaries and 3 cannibals. 
The boast is on the east bank.

CHAPTER 3
Figure 3.1. Scheduling problems are a classic application of constraint-satisfaction
.
frameworks

Listing 3.1. csp.py
1
2
3
from typing import Generic, TypeVar, Dict, List, Optional 
from abc import ABC, abstractmethod 
 

4
5
6
7
8
9
10
11
12
13
14
15
16
17
V = TypeVar('V') # variable type 
D = TypeVar('D') # domain type 
 
# Base class for all constraints 
class Constraint(Generic[V, D], ABC): 
    # The variables that the constraint is between 
    def __init__(self, variables: List[V]) -> None: 
        self.variables = variables 
 
 
    # Must be overridden by subclasses 
    @abstractmethod 
    def satisfied(self, assignment: Dict[V, D]) -> bool: 
        ...

Listing 3.2. csp.py continued
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
# A constraint satisfaction problem consists of variables of type V 
# that have ranges of values known as domains of type D and constraints 
# that determine whether a particular variable's domain selection is valid 
class CSP(Generic[V, D]): 
    def __init__(self, variables: List[V], domains: Dict[V, List[D]]) -> 
     None: 
        self.variables: List[V] = variables # variables to be constrained 
        self.domains: Dict[V, List[D]] = domains # domain of each variable 
        self.constraints: Dict[V, List[Constraint[V, D]]] = {} 
        for variable in self.variables: 
            self.constraints[variable] = [] 
            if variable not in self.domains: 
                raise LookupError("Every variable should have a domain 
     assigned to it.") 
 
    def add_constraint(self, constraint: Constraint[V, D]) -> None: 
        for variable in constraint.variables: 
            if variable not in self.variables: 
                raise LookupError("Variable in constraint not in CSP") 
            else: 
                self.constraints[variable].append(constraint)
Listing 3.3. csp.py continued
1
2
3
4
5
6
7
# Check if the value assignment is consistent by checking all constraints 
# for the given variable against it 
def consistent(self, variable: V, assignment: Dict[V, D]) -> bool: 
    for constraint in self.constraints[variable]: 
        if not constraint.satisfied(assignment): 
            return False 
    return True

Listing 3.4. csp.py continued
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
def backtracking_search(self, assignment: Dict[V, D] = {}) -> 
     Optional[Dict[V, D]]: 
    # assignment is complete if every variable is assigned (our base case) 
    if len(assignment) == len(self.variables): 
        return assignment 
 
    # get all variables in the CSP but not in the assignment 
    unassigned: List[V] = [v for v in self.variables if v not in assignment] 
 
    # get the every possible domain value of the first unassigned variable 
    first: V = unassigned[0] 
    for value in self.domains[first]: 
        local_assignment = assignment.copy() 
        local_assignment[first] = value 
        # if we're still consistent, we recurse (continue) 
        if self.consistent(first, local_assignment): 
            result: Optional[Dict[V, D]] = self.backtracking_search(local_ 
     assignment) 
            # if we didn't find the result, we will end up backtracking 
            if result is not None: 
                return result 
    return None
1
2
if len(assignment) == len(self.variables): 
    return assignment
1
2
unassigned: List[V] = [v for v in self.variables if v not in assignment] 
first: V = unassigned[0]
1
2
3
for value in self.domains[first]: 
    local_assignment = assignment.copy() 
    local_assignment[first] = value
1
2
3
4
if self.consistent(first, local_assignment): 
    result: Optional[Dict[V, D]] = self.backtracking_search(local_assignment) 
    if result is not None: 
        return result

Figure 3.2. In a solution to the Australian map-coloring problem, no two adjacent parts
of Australia can be colored with the same color.
1 return None  # no solution
Listing 3.5. map_coloring.py
1
2
3
4
5
from csp import Constraint, CSP 
from typing import Dict, List, Optional 
 
class MapColoringConstraint(Constraint[str, str]): 
    def __init__(self, place1: str, place2: str) -> None: 

6
7
8
9
10
11
12
13
14
15
16
17
        super().__init__([place1, place2]) 
        self.place1: str = place1 
        self.place2: str = place2 
 
    def satisfied(self, assignment: Dict[str, str]) -> bool: 
        # If either place is not in the assignment, then it is not 
        # yet possible for their colors to be conflicting 
        if self.place1 not in assignment or self.place2 not in assignment: 
            return True 
        # check the color assigned to place1 is not the same as the 
        # color assigned to place2 
        return assignment[self.place1] != assignment[self.place2]
Listing 3.6. map_coloring.py continued
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
if __name__ == "__main__": 
    variables: List[str] = ["Western Australia", "Northern Territory", "South 
     Australia", "Queensland", "New South Wales", "Victoria", "Tasmania"] 
    domains: Dict[str, List[str]] = {} 
    for variable in variables: 
        domains[variable] = ["red", "green", "blue"] 
    csp: CSP[str, str] = CSP(variables, domains) 
    csp.add_constraint(MapColoringConstraint("Western Australia", "Northern 
     Territory")) 
    csp.add_constraint(MapColoringConstraint("Western Australia", "South 
     Australia")) 
    csp.add_constraint(MapColoringConstraint("South Australia", "Northern 
     Territory")) 
    csp.add_constraint(MapColoringConstraint("Queensland", "Northern 
     Territory")) 
    csp.add_constraint(MapColoringConstraint("Queensland", "South 
     Australia")) 
    csp.add_constraint(MapColoringConstraint("Queensland", "New South 
     Wales")) 
    csp.add_constraint(MapColoringConstraint("New South Wales", "South 
     Australia")) 
    csp.add_constraint(MapColoringConstraint("Victoria", "South Australia")) 
    csp.add_constraint(MapColoringConstraint("Victoria", "New South Wales")) 
    csp.add_constraint(MapColoringConstraint("Victoria", "Tasmania"))
Listing 3.7. map_coloring.py continued
1
2
3
4
5
solution: Optional[Dict[str, str]] = csp.backtracking_search() 
if solution is None: 
    print("No solution found!") 
else: 
    print(solution)

Figure 3.3. In a solution to the 
 problem (there are many solutions), no two
queens can be threatening each other.
eight queens
1
2
3
{'Western Australia': 'red', 'Northern Territory': 'green', 'South 
      Australia': 'blue', 'Queensland': 'red', 'New South Wales': 'green', 
      'Victoria': 'red', 'Tasmania': 'green'}
Listing 3.8. queens.py
1
2
3
4
5
6
if __name__ == "__main__": 
    columns: List[int] = [1, 2, 3, 4, 5, 6, 7, 8] 
    rows: Dict[int, List[int]] = {} 
    for column in columns: 
        rows[column] = [1, 2, 3, 4, 5, 6, 7, 8] 
    csp: CSP[int, int] = CSP(columns, rows)

Figure 3.4. A classic word search, such as you might Ønd in a children’s puzzle book
Listing 3.9. queens.py continued
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
from csp import Constraint, CSP 
from typing import Dict, List, Optional 
class QueensConstraint(Constraint[int, int]): 
    def __init__(self, columns: List[int]) -> None: 
        super().__init__(columns) 
        self.columns: List[int] = columns 
 
    def satisfied(self, assignment: Dict[int, int]) -> bool: 
       # q1c = queen 1 column, q1r = queen 1 row 
        for q1c, q1r in assignment.items():  
        # q2c = queen 2 column 
            for q2c in range(q1c + 1, len(self.columns) + 1):  
                if q2c in assignment: 
                    q2r: int = assignment[q2c] # q2r = queen 2 row 
                    if q1r == q2r: # same row? 
                        return False 
                    if abs(q1r - q2r) == abs(q1c - q2c): # same diagonal? 
                        return False 
        return True # no conflict
Listing 3.10. queens.py continued
1
2
3
4
5
6
csp.add_constraint(QueensConstraint(columns)) 
solution: Optional[Dict[int, int]] = csp.backtracking_search() 
if solution is None: 
    print("No solution found!") 
else: 
    print(solution)
1 {1: 1, 2: 5, 3: 8, 4: 6, 5: 3, 6: 7, 7: 2, 8: 4}

Listing 3.11. word_search.py
1
2
3
4
5
6
7
8
9
10
11
from typing import NamedTuple, List, Dict, Optional 
from random import choice 
from string import ascii_uppercase 
from csp import CSP, Constraint 
 
Grid = List[List[str]]  # type alias for grids 
 
 
class GridLocation(NamedTuple): 
    row: int 
    column: int
Listing 3.12. word_search.py continued
1
2
3
4
5
6
7
def generate_grid(rows: int, columns: int) -> Grid: 
    # initialize grid with random letters 
    return [[choice(ascii_uppercase) for c in range(columns)] for r in 
     range(rows)] 
 
def display_grid(grid: Grid) -> None: 

8     for row in grid: 
        print("".join(row))
Listing 3.13. word_search.py continued
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
def generate_domain(word: str, grid: Grid) -> List[List[GridLocation]]: 
    domain: List[List[GridLocation]] = [] 
    height: int = len(grid) 
    width: int = len(grid[0]) 
    length: int = len(word) 
    for row in range(height): 
        for col in range(width): 
            columns: range = range(col, col + length + 1) 
            rows: range = range(row, row + length + 1) 
            if col + length <= width: 
                # left to right 
                domain.append([GridLocation(row, c) for c in columns]) 
                # diagonal towards bottom right 
                if row + length <= height: 
                    domain.append([GridLocation(r, col + (r - row)) for r in 
    rows]) 
            if row + length <= height: 
                # top to bottom 
                domain.append([GridLocation(r, col) for r in rows]) 
                # diagonal towards bottom left 
                if col - length >= 0: 
                    domain.append([GridLocation(r, col - (r - row)) for r in 
    rows]) 
   return domain
Listing 3.14. word_search.py continued
1
2
3
4
5
6
7
8
9
10
11
class WordSearchConstraint(Constraint[str, List[GridLocation]]): 
    def __init__(self, words: List[str]) -> None: 
        super().__init__(words) 
        self.words: List[str] = words 
 
    def satisfied(self, assignment: Dict[str, List[GridLocation]]) -> bool: 
        # if there are any duplicates grid locations, then there is an 
     overlap 
        all_locations = [locs for values in assignment.values() for locs in 
     values] 
        return len(set(all_locations)) == len(all_locations)
Listing 3.15. word_search.py continued

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
if __name__ == "__main__": 
    grid: Grid = generate_grid(9, 9) 
    words: List[str] = ["MATTHEW", "JOE", "MARY", "SARAH", "SALLY"] 
    locations: Dict[str, List[List[GridLocation]]] = {} 
    for word in words: 
        locations[word] = generate_domain(word, grid) 
    csp: CSP[str, List[GridLocation]] = CSP(words, locations) 
    csp.add_constraint(WordSearchConstraint(words)) 
    solution: Optional[Dict[str, List[GridLocation]]] = csp.backtracking_ 
     search() 
    if solution is None: 
        print("No solution found!") 
    else: 
        for word, grid_locations in solution.items(): 
            # random reverse half the time 
            if choice([True, False]): 
                grid_locations.reverse() 
            for index, letter in enumerate(word): 
                (row, col) = (grid_locations[index].row, grid_ 
    locations[index].column) 
               grid[row][col] = letter 
       display_grid(grid)
1
2
3
4
5
6
7
8
9
LWEHTTAMJ 
MARYLISGO 
DKOJYHAYE 
IAJYHALAG 
GYZJWRLGM 
LLOTCAYIX 
PEUTUSLKO 
AJZYGIKDU 
HSLZOFNNR
1
2
3
SEND 
 +MORE 
=MONEY
Listing 3.16. send_more_money.py
1
2
3
4
5
6
7
8
9
from csp import Constraint, CSP 
from typing import Dict, List, Optional 
 
class SendMoreMoneyConstraint(Constraint[str, int]): 
    def __init__(self, letters: List[str]) -> None: 
        super().__init__(letters) 
        self.letters: List[str] = letters 
 
    def satisfied(self, assignment: Dict[str, int]) -> bool: 

Figure 3.5. The circuit board layout problem is very similar to the word-search problem,
but the rectangles are of variable width.
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
        # if there are duplicate values, then it's not a solution 
        if len(set(assignment.values())) < len(assignment): 
            return False 
 
        # if all variables have been assigned, check if it adds correctly 
        if len(assignment) == len(self.letters): 
            s: int = assignment["S"] 
            e: int = assignment["E"] 
            n: int = assignment["N"] 
            d: int = assignment["D"] 
            m: int = assignment["M"] 
            o: int = assignment["O"] 
            r: int = assignment["R"] 
            y: int = assignment["Y"] 
            send: int = s * 1000 + e * 100 + n * 10 + d 
            more: int = m * 1000 + o * 100 + r * 10 + e 
            money: int = m * 10000 + o * 1000 + n * 100 + e * 10 + y 
            return send + more == money 
        return True # no conflict
Listing 3.17. send_more_money.py continued
1
2
3
4
5
6
7
8
9
10
11
12
13
if __name__ == "__main__": 
    letters: List[str] = ["S", "E", "N", "D", "M", "O", "R", "Y"] 
    possible_digits: Dict[str, List[int]] = {} 
    for letter in letters: 
        possible_digits[letter] = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] 
    possible_digits["M"] = [1]  # so we don't get answers starting with a 0 
    csp: CSP[str, int] = CSP(letters, possible_digits) 
    csp.add_constraint(SendMoreMoneyConstraint(letters)) 
    solution: Optional[Dict[str, int]] = csp.backtracking_search() 
    if solution is None: 
        print("No solution found!") 
    else: 
        print(solution)
1 {'S': 9, 'E': 5, 'N': 6, 'D': 7, 'M': 1, 'O': 0, 'R': 8, 'Y': 2}


CHAPTER 4
Figure 4.1. A map of the 15 largest MSAs in the United States
Figure 4.2. A graph with vertices representing the 15 largest MSAs in the United States
and edges representing potential Hyperloop routes between them

Figure 4.3. An equivalent graph to that in Øgure 4.2, with the location of Miami moved
Listing 4.1. edge.py
1
2
3
4
5
6
7
8
9
10
11
12
13
14
from __future__ import annotations 
from dataclasses import dataclass 
 
 
@dataclass 
class Edge: 
    u: int # the "from" vertex 
    v: int # the "to" vertex 
 
    def reversed(self) -> Edge: 
        return Edge(self.v, self.u) 
 
    def __str__(self) -> str: 
        return f"{self.u} -> {self.v}"
Listing 4.2. graph.py
1
2
3
4
5
6
7
8
9
10
from typing import TypeVar, Generic, List, Optional 
from edge import Edge 
 
V = TypeVar('V') # type of the vertices in the graph 
 
 
class Graph(Generic[V]): 
    def __init__(self, vertices: List[V] = []) -> None: 
        self._vertices: List[V] = vertices 
        self._edges: List[List[Edge]] = [[] for _ in vertices]

Listing 4.3. graph.py continued
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
@property 
def vertex_count(self) -> int: 
    return len(self._vertices) # Number of vertices 
 
@property 
def edge_count(self) -> int: 
    return sum(map(len, self._edges)) # Number of edges 
 
# Add a vertex to the graph and return its index 
def add_vertex(self, vertex: V) -> int: 
    self._vertices.append(vertex) 
    self._edges.append([]) # Add empty list for containing edges 
    return self.vertex_count - 1 # Return index of added vertex 
 
# This is an undirected graph, 
# so we always add edges in both directions 
def add_edge(self, edge: Edge) -> None: 
    self._edges[edge.u].append(edge) 
    self._edges[edge.v].append(edge.reversed()) 
 
# Add an edge using vertex indices (convenience method) 
def add_edge_by_indices(self, u: int, v: int) -> None: 
    edge: Edge = Edge(u, v) 
    self.add_edge(edge) 
 
# Add an edge by looking up vertex indices (convenience method) 
def add_edge_by_vertices(self, first: V, second: V) -> None: 
    u: int = self._vertices.index(first) 
    v: int = self._vertices.index(second) 
    self.add_edge_by_indices(u, v) 
 
# Find the vertex at a specific index 
def vertex_at(self, index: int) -> V: 
    return self._vertices[index] 
 
# Find the index of a vertex in the graph 
def index_of(self, vertex: V) -> int: 
    return self._vertices.index(vertex) 
 
# Find the vertices that a vertex at some index is connected to 
def neighbors_for_index(self, index: int) -> List[V]: 
    return list(map(self.vertex_at, [e.v for e in self._edges[index]])) 
 
# Look up a vertice's index and find its neighbors (convenience method) 
def neighbors_for_vertex(self, vertex: V) -> List[V]: 
    return self.neighbors_for_index(self.index_of(vertex)) 
 
# Return all of the edges associated with a vertex at some index 
def edges_for_index(self, index: int) -> List[Edge]: 
    return self._edges[index] 
 
# Look up the index of a vertex and return its edges (convenience method) 
def edges_for_vertex(self, vertex: V) -> List[Edge]: 
    return self.edges_for_index(self.index_of(vertex)) 
 
# Make it easy to pretty-print a Graph 
def __str__(self) -> str: 
    desc: str = "" 
    for i in range(self.vertex_count): 

60
61
        desc += f"{self.vertex_at(i)} -> {self.neighbors_for_index(i)}\n" 
    return desc

1
2
def neighbors_for_index(self, index: int) -> List[V]: 
    return list(map(self.vertex_at, [e.v for e in self._edges[index]]))

1
2
3
def add_edge(self, edge: Edge) -> None: 
    self._edges[edge.u].append(edge) 
    self._edges[edge.v].append(edge.reversed())
Listing 4.4. graph.py continued
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
if __name__ == "__main__": 
    # test basic Graph construction 
    city_graph: Graph[str] = Graph(["Seattle", "San Francisco", "Los 
     Angeles", "Riverside", "Phoenix", "Chicago", "Boston", "New York", 
     "Atlanta", "Miami", "Dallas", "Houston", "Detroit", "Philadelphia", 
     "Washington"]) 
    city_graph.add_edge_by_vertices("Seattle", "Chicago") 
    city_graph.add_edge_by_vertices("Seattle", "San Francisco") 
    city_graph.add_edge_by_vertices("San Francisco", "Riverside") 
    city_graph.add_edge_by_vertices("San Francisco", "Los Angeles") 
    city_graph.add_edge_by_vertices("Los Angeles", "Riverside") 
    city_graph.add_edge_by_vertices("Los Angeles", "Phoenix") 
    city_graph.add_edge_by_vertices("Riverside", "Phoenix") 
    city_graph.add_edge_by_vertices("Riverside", "Chicago") 
    city_graph.add_edge_by_vertices("Phoenix", "Dallas") 
    city_graph.add_edge_by_vertices("Phoenix", "Houston") 
    city_graph.add_edge_by_vertices("Dallas", "Chicago") 
    city_graph.add_edge_by_vertices("Dallas", "Atlanta") 
    city_graph.add_edge_by_vertices("Dallas", "Houston") 
    city_graph.add_edge_by_vertices("Houston", "Atlanta") 
    city_graph.add_edge_by_vertices("Houston", "Miami") 
    city_graph.add_edge_by_vertices("Atlanta", "Chicago") 
    city_graph.add_edge_by_vertices("Atlanta", "Washington") 
    city_graph.add_edge_by_vertices("Atlanta", "Miami") 
    city_graph.add_edge_by_vertices("Miami", "Washington") 
    city_graph.add_edge_by_vertices("Chicago", "Detroit") 
    city_graph.add_edge_by_vertices("Detroit", "Boston") 
    city_graph.add_edge_by_vertices("Detroit", "Washington") 
    city_graph.add_edge_by_vertices("Detroit", "New York") 
    city_graph.add_edge_by_vertices("Boston", "New York") 
    city_graph.add_edge_by_vertices("New York", "Philadelphia") 
    city_graph.add_edge_by_vertices("Philadelphia", "Washington") 
    print(city_graph)

Figure 4.4. The shortest route between Boston and Miami, in terms of the number of
edges, is highlighted.
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
Seattle -> ['Chicago', 'San Francisco'] 
San Francisco -> ['Seattle', 'Riverside', 'Los Angeles'] 
Los Angeles -> ['San Francisco', 'Riverside', 'Phoenix'] 
Riverside -> ['San Francisco', 'Los Angeles', 'Phoenix', 'Chicago'] 
Phoenix -> ['Los Angeles', 'Riverside', 'Dallas', 'Houston'] 
Chicago -> ['Seattle', 'Riverside', 'Dallas', 'Atlanta', 'Detroit'] 
Boston -> ['Detroit', 'New York'] 
New York -> ['Detroit', 'Boston', 'Philadelphia'] 
Atlanta -> ['Dallas', 'Houston', 'Chicago', 'Washington', 'Miami'] 
Miami -> ['Houston', 'Atlanta', 'Washington'] 
Dallas -> ['Phoenix', 'Chicago', 'Atlanta', 'Houston'] 
Houston -> ['Phoenix', 'Dallas', 'Atlanta', 'Miami'] 
Detroit -> ['Chicago', 'Boston', 'Washington', 'New York'] 
Philadelphia -> ['New York', 'Washington'] 
Washington -> ['Atlanta', 'Miami', 'Detroit', 'Philadelphia']
Listing 4.5. graph.py continued
1
2
3
4
5
6
7
8
9
10
11
12
13
14
# Reuse BFS from chapter 2 on city_graph 
import sys 
sys.path.insert(0, '..') # so we can access the Chapter2 package in the 
     parent directory 
from Chapter2.generic_search import bfs, Node, node_to_path 
 
bfs_result: Optional[Node[V]] = bfs("Boston", lambda x: x == "Miami", city_ 
     graph.neighbors_for_vertex) 
if bfs_result is None: 
    print("No solution found using breadth-first search!") 
else: 
    path: List[V] = node_to_path(bfs_result) 
    print("Path from Boston to Miami:") 
    print(path)
1
2
Path from Boston to Miami: 
['Boston', 'Detroit', 'Washington', 'Miami']

Figure 4.5. A weighted graph of the 15 largest MSAs in the United States, where each of
the weights represents the distance between two MSAs in miles
Listing 4.6. weighted_edge.py
1
2
3
4
5
6
7
8
from __future__ import annotations 
from dataclasses import dataclass 
from edge import Edge 
 
 
@dataclass 
class WeightedEdge(Edge): 
    weight: float 

9
10
11
12
13
14
15
16
17
18
 
    def reversed(self) -> WeightedEdge: 
        return WeightedEdge(self.v, self.u, self.weight) 
 
    # so that we can order edges by weight to find the minimum weight edge 
    def __lt__(self, other: WeightedEdge) -> bool: 
        return self.weight < other.weight 
 
    def __str__(self) -> str: 
        return f"{self.u} {self.weight}> {self.v}"
Listing 4.7. weighted_graph.py
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
from typing import TypeVar, Generic, List, Tuple 
from graph import Graph 
from weighted_edge import WeightedEdge 
 
V = TypeVar('V') # type of the vertices in the graph 
 
class WeightedGraph(Generic[V], Graph[V]): 
    def __init__(self, vertices: List[V] = []) -> None: 
        self._vertices: List[V] = vertices 
        self._edges: List[List[WeightedEdge]] = [[] for _ in vertices] 
 
    def add_edge_by_indices(self, u: int, v: int, weight: float) -> None: 
        edge: WeightedEdge = WeightedEdge(u, v, weight) 
        self.add_edge(edge) # call superclass version 
 
    def add_edge_by_vertices(self, first: V, second: V, weight: float) -> 
     None: 
        u: int = self._vertices.index(first) 
        v: int = self._vertices.index(second) 
        self.add_edge_by_indices(u, v, weight) 
 
    def neighbors_for_index_with_weights(self, index: int) -> List[Tuple[V, 
     float]]: 
        distance_tuples: List[Tuple[V, float]] = [] 
        for edge in self.edges_for_index(index): 
            distance_tuples.append((self.vertex_at(edge.v), edge.weight)) 
        return distance_tuples 
 
    def __str__(self) -> str: 
        desc: str = "" 
        for i in range(self.vertex_count): 
            desc += f"{self.vertex_at(i)} -> {self.neighbors_for_index_with_ 
    weights(i)}\n" 
        return desc
Listing 4.8. weighted_graph.py continued
1
2
3
4
5
if __name__ == "__main__": 
    city_graph2: WeightedGraph[str] = WeightedGraph(["Seattle", "San 
     Francisco", "Los Angeles", "Riverside", "Phoenix", "Chicago", "Boston", 
     "New York", "Atlanta", "Miami", "Dallas", "Houston", "Detroit", 
     "Philadelphia", "Washington"]) 

6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
    city_graph2.add_edge_by_vertices("Seattle", "Chicago", 1737) 
    city_graph2.add_edge_by_vertices("Seattle", "San Francisco", 678) 
    city_graph2.add_edge_by_vertices("San Francisco", "Riverside", 386) 
    city_graph2.add_edge_by_vertices("San Francisco", "Los Angeles", 348) 
    city_graph2.add_edge_by_vertices("Los Angeles", "Riverside", 50) 
    city_graph2.add_edge_by_vertices("Los Angeles", "Phoenix", 357) 
    city_graph2.add_edge_by_vertices("Riverside", "Phoenix", 307) 
    city_graph2.add_edge_by_vertices("Riverside", "Chicago", 1704) 
    city_graph2.add_edge_by_vertices("Phoenix", "Dallas", 887) 
    city_graph2.add_edge_by_vertices("Phoenix", "Houston", 1015) 
    city_graph2.add_edge_by_vertices("Dallas", "Chicago", 805) 
    city_graph2.add_edge_by_vertices("Dallas", "Atlanta", 721) 
    city_graph2.add_edge_by_vertices("Dallas", "Houston", 225) 
    city_graph2.add_edge_by_vertices("Houston", "Atlanta", 702) 
    city_graph2.add_edge_by_vertices("Houston", "Miami", 968) 
    city_graph2.add_edge_by_vertices("Atlanta", "Chicago", 588) 
    city_graph2.add_edge_by_vertices("Atlanta", "Washington", 543) 
    city_graph2.add_edge_by_vertices("Atlanta", "Miami", 604) 
    city_graph2.add_edge_by_vertices("Miami", "Washington", 923) 
    city_graph2.add_edge_by_vertices("Chicago", "Detroit", 238) 
    city_graph2.add_edge_by_vertices("Detroit", "Boston", 613) 
    city_graph2.add_edge_by_vertices("Detroit", "Washington", 396) 
    city_graph2.add_edge_by_vertices("Detroit", "New York", 482) 
    city_graph2.add_edge_by_vertices("Boston", "New York", 190) 
    city_graph2.add_edge_by_vertices("New York", "Philadelphia", 81) 
    city_graph2.add_edge_by_vertices("Philadelphia", "Washington", 123) 
 
    print(city_graph2)
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
Seattle -> [('Chicago', 1737), ('San Francisco', 678)] 
San Francisco -> [('Seattle', 678), ('Riverside', 386), ('Los Angeles', 348)] 
Los Angeles -> [('San Francisco', 348), ('Riverside', 50), ('Phoenix', 357)] 
Riverside -> [('San Francisco', 386), ('Los Angeles', 50), ('Phoenix', 307), 
     ('Chicago', 1704)] 
Phoenix -> [('Los Angeles', 357), ('Riverside', 307), ('Dallas', 887), 
     ('Houston', 1015)] 
Chicago -> [('Seattle', 1737), ('Riverside', 1704), ('Dallas', 805), 
     ('Atlanta', 588), ('Detroit', 238)] 
Boston -> [('Detroit', 613), ('New York', 190)] 
New York -> [('Detroit', 482), ('Boston', 190), ('Philadelphia', 81)] 
Atlanta -> [('Dallas', 721), ('Houston', 702), ('Chicago', 588), 
     ('Washington', 543), ('Miami', 604)] 
Miami -> [('Houston', 968), ('Atlanta', 604), ('Washington', 923)] 
Dallas -> [('Phoenix', 887), ('Chicago', 805), ('Atlanta', 721), ('Houston', 
     225)] 
Houston -> [('Phoenix', 1015), ('Dallas', 225), ('Atlanta', 702), ('Miami', 
     968)] 
Detroit -> [('Chicago', 238), ('Boston', 613), ('Washington', 396), ('New 
     York', 482)] 
Philadelphia -> [('New York', 81), ('Washington', 123)] 
Washington -> [('Atlanta', 543), ('Miami', 923), ('Detroit', 396), 
     ('Philadelphia', 123)]

Figure 4.6. In the left graph, a cycle exists between vertices B, C, and D, so it is not a
tree. In the right graph, the edge connecting C and D has been pruned, so the graph is a
tree.
Listing 4.9. priority_queue.py
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
from typing import TypeVar, Generic, List 
from heapq import heappush, heappop 
 
T = TypeVar('T') 
 
class PriorityQueue(Generic[T]): 
    def __init__(self) -> None: 
        self._container: List[T] = [] 
 
    @property 
    def empty(self) -> bool: 
        return not self._container  # not is true for empty container 
 
    def push(self, item: T) -> None: 
        heappush(self._container, item)  # in by priority 
 
    def pop(self) -> T: 
        return heappop(self._container)  # out by priority 
 
    def __repr__(self) -> str: 
        return repr(self._container)
Listing 4.10. mst.py
1
2
3
4
5
6
7
8
9
10
from typing import TypeVar, List, Optional 
from weighted_graph import WeightedGraph 
from weighted_edge import WeightedEdge 
from priority_queue import PriorityQueue 
 
V = TypeVar('V') # type of the vertices in the graph 
WeightedPath = List[WeightedEdge] # type alias for paths 
 
def total_weight(wp: WeightedPath) -> float: 
    return sum([e.weight for e in wp])

Listing 4.11. mst.py continued
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
def mst(wg: WeightedGraph[V], start: int = 0) -> Optional[WeightedPath]: 
    if start > (wg.vertex_count - 1) or start < 0: 
        return None 
    result: WeightedPath = [] # holds the final MST 
    pq: PriorityQueue[WeightedEdge] = PriorityQueue() 
    visited: [bool] = [False] * wg.vertex_count # where we've been 
 
    def visit(index: int): 
        visited[index] = True # mark as visited 
        for edge in wg.edges_for_index(index):  
            # add all edges coming from here to pq 
            if not visited[edge.v]: 
                pq.push(edge) 
 
    visit(start) # the first vertex is where everything begins 
 
    while not pq.empty: # keep going while there are edges to process 
        edge = pq.pop() 
        if visited[edge.v]: 
            continue # don't ever revisit 
        # this is the current smallest, so add it to solution 
        result.append(edge)  
        visit(edge.v) # visit where this connects 
 
    return result 
 
def print_weighted_path(wg: WeightedGraph, wp: WeightedPath) -> None: 
    for edge in wp: 
        print(f"{wg.vertex_ 
     at(edge.u)} {edge.weight}> {wg.vertex_at(edge.v)}") 
    print(f"Total Weight: {total_weight(wp)}")
1
2
3
def mst(wg: WeightedGraph[V], start: int = 0) -> Optional[WeightedPath]: 
   if start > (wg.vertex_count - 1) or start < 0: 
        return None
1
2
3
result: WeightedPath = [] # holds the final MST 
pq: PriorityQueue[WeightedEdge] = PriorityQueue() 
visited: [bool] = [False] * wg.vertex_count # where we've been

1
2
3
4
5
6
def visit(index: int): 
    visited[index] = True # mark as visited 
    for edge in wg.edges_for_index(index):  
        # add all edges coming from here 
        if not visited[edge.v]: 
            pq.push(edge)
1 visit(start) # the first vertex is where everything begins
1
2
3
4
5
6
7
8
while not pq.empty: # keep going while there are edges to process 
    edge = pq.pop() 
    if visited[edge.v]: 
        continue # don't ever revisit 
    # this is the current smallest, so add it 
    result.append(edge)  
    visit(edge.v) # visit where this connects 
return result
Listing 4.12. mst.py continued
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
if __name__ == "__main__": 
    city_graph2: WeightedGraph[str] = WeightedGraph(["Seattle", "San 
     Francisco", "Los Angeles", "Riverside", "Phoenix", "Chicago", "Boston", 
     "New York", "Atlanta", "Miami", "Dallas", "Houston", "Detroit", 
     "Philadelphia", "Washington"]) 
 
    city_graph2.add_edge_by_vertices("Seattle", "Chicago", 1737) 
    city_graph2.add_edge_by_vertices("Seattle", "San Francisco", 678) 
    city_graph2.add_edge_by_vertices("San Francisco", "Riverside", 386) 
    city_graph2.add_edge_by_vertices("San Francisco", "Los Angeles", 348) 
    city_graph2.add_edge_by_vertices("Los Angeles", "Riverside", 50) 
    city_graph2.add_edge_by_vertices("Los Angeles", "Phoenix", 357) 
    city_graph2.add_edge_by_vertices("Riverside", "Phoenix", 307) 
    city_graph2.add_edge_by_vertices("Riverside", "Chicago", 1704) 
    city_graph2.add_edge_by_vertices("Phoenix", "Dallas", 887) 
    city_graph2.add_edge_by_vertices("Phoenix", "Houston", 1015) 
    city_graph2.add_edge_by_vertices("Dallas", "Chicago", 805) 
    city_graph2.add_edge_by_vertices("Dallas", "Atlanta", 721) 
    city_graph2.add_edge_by_vertices("Dallas", "Houston", 225) 
    city_graph2.add_edge_by_vertices("Houston", "Atlanta", 702) 
    city_graph2.add_edge_by_vertices("Houston", "Miami", 968) 
    city_graph2.add_edge_by_vertices("Atlanta", "Chicago", 588) 
    city_graph2.add_edge_by_vertices("Atlanta", "Washington", 543) 
    city_graph2.add_edge_by_vertices("Atlanta", "Miami", 604) 
    city_graph2.add_edge_by_vertices("Miami", "Washington", 923) 
    city_graph2.add_edge_by_vertices("Chicago", "Detroit", 238) 
    city_graph2.add_edge_by_vertices("Detroit", "Boston", 613) 

Figure 4.7. The highlighted edges represent a minimum spanning tree that connects all
15 MSAs.
28
29
30
31
32
33
34
35
36
37
38
    city_graph2.add_edge_by_vertices("Detroit", "Washington", 396) 
    city_graph2.add_edge_by_vertices("Detroit", "New York", 482) 
    city_graph2.add_edge_by_vertices("Boston", "New York", 190) 
    city_graph2.add_edge_by_vertices("New York", "Philadelphia", 81) 
    city_graph2.add_edge_by_vertices("Philadelphia", "Washington", 123) 
 
    result: Optional[WeightedPath] = mst(city_graph2) 
    if result is None: 
        print("No solution found!") 
    else: 
        print_weighted_path(city_graph2, result)
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
Seattle 678> San Francisco 
San Francisco 348> Los Angeles 
Los Angeles 50> Riverside 
Riverside 307> Phoenix 
Phoenix 887> Dallas 
Dallas 225> Houston 
Houston 702> Atlanta 
Atlanta 543> Washington 
Washington 123> Philadelphia 
Philadelphia 81> New York 
New York 190> Boston 
Washington 396> Detroit 
Detroit 238> Chicago 
Atlanta 604> Miami 
Total Weight: 5372

Listing 4.13. dijkstra.py
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
from __future__ import annotations 
from typing import TypeVar, List, Optional, Tuple, Dict 
from dataclasses import dataclass 
from mst import WeightedPath, print_weighted_path 
from weighted_graph import WeightedGraph 
from weighted_edge import WeightedEdge 
from priority_queue import PriorityQueue 
 
V = TypeVar('V') # type of the vertices in the graph 
 
 
@dataclass 
class DijkstraNode: 
    vertex: int 
    distance: float 
 
    def __lt__(self, other: DijkstraNode) -> bool: 
        return self.distance < other.distance 
 
    def __eq__(self, other: DijkstraNode) -> bool: 
        return self.distance == other.distance 
 
def dijkstra(wg: WeightedGraph[V], root: V) -> Tuple[List[Optional[float]], 
     Dict[int, WeightedEdge]]: 
    first: int = wg.index_of(root) # find starting index 
    # distances are unknown at first 
    distances: List[Optional[float]] = [None] * wg.vertex_count 
    distances[first] = 0 # the root is 0 away from the root 
    path_dict: Dict[int, WeightedEdge] = {} # how we got to each vertex 
    pq: PriorityQueue[DijkstraNode] = PriorityQueue() 
    pq.push(DijkstraNode(first, 0)) 
 
    while not pq.empty: 
        u: int = pq.pop().vertex # explore the next closest vertex 
        dist_u: float = distances[u] # should already have seen it 
        # look at every edge/vertex from the vertex in question 
        for we in wg.edges_for_index(u):  
            # the old distance to this vertex 
            dist_v: float = distances[we.v]  
            # no old distance or found shorter path 
            if dist_v is None or dist_v > we.weight + dist_u:  
                # update distance to this vertex 
                distances[we.v] = we.weight + dist_u  
                # update the edge on the shortest path to this vertex 
                path_dict[we.v] = we  
                # explore it soon 
                pq.push(DijkstraNode(we.v, we.weight + dist_u))  
 
    return distances, path_dict 
 
# Helper function to get easier access to dijkstra results 
def distance_array_to_vertex_dict(wg: WeightedGraph[V], distances: 
     List[Optional[float]]) -> Dict[V, Optional[float]]: 
    distance_dict: Dict[V, Optional[float]] = {} 
    for i in range(len(distances)): 
        distance_dict[wg.vertex_at(i)] = distances[i] 
    return distance_dict 
 
# Takes a dictionary of edges to reach each node and returns a list of 
# edges that goes from `start` to `end` 
def path_dict_to_path(start: int, end: int, path_dict: Dict[int, 
     WeightedEdge]) -> WeightedPath: 
    if len(path_dict) == 0: 

64
65
66
67
68
69
70
71
        return [] 
    edge_path: WeightedPath = [] 
    e: WeightedEdge = path_dict[end] 
    edge_path.append(e) 
    while e.u != start: 
        e = path_dict[e.u] 
        edge_path.append(e) 
    return list(reversed(edge_path))
1
2
3
4
5
6
7
8
9
def dijkstra(wg: WeightedGraph[V], root: V) -> Tuple[List[Optional[float]], 
     Dict[int, WeightedEdge]]: 
    first: int = wg.index_of(root) # find starting index 
    # distances are unknown at first 
    distances: List[Optional[float]] = [None] * wg.vertex_count 
    distances[first] = 0 # the root is 0 away from the root 
    path_dict: Dict[int, WeightedEdge] = {} # how we got to each vertex 
    pq: PriorityQueue[DijkstraNode] = PriorityQueue() 
    pq.push(DijkstraNode(first, 0))
1
2
3
while not pq.empty: 
    u: int = pq.pop().vertex # explore the next closest vertex 
    dist_u: float = distances[u] # should already have seen it
1
2
3
4
# look at every edge/vertex from here 
for we in wg.edges_for_index(u):  
    # the old distance to this 
    dist_v: float = distances[we.v]
1
2
3
4
5
6
7
8
# no old distance or found shorter path 
if dist_v is None or dist_v > we.weight + dist_u:  
    # update distance to this vertex 
    distances[we.v] = we.weight + dist_u  
    # update the edge on the shortest path 
    path_dict[we.v] = we  
    # explore it soon 
    pq.push(DijkstraNode(we.v, we.weight + dist_u))

1 return distances, path_dict
Listing 4.14. dijkstra.py continued
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
if __name__ == "__main__": 
    city_graph2: WeightedGraph[str] = WeightedGraph(["Seattle", "San 
     Francisco", "Los Angeles", "Riverside", "Phoenix", "Chicago", "Boston", 
     "New York", "Atlanta", "Miami", "Dallas", "Houston", "Detroit", 
     "Philadelphia", "Washington"]) 
 
    city_graph2.add_edge_by_vertices("Seattle", "Chicago", 1737) 
    city_graph2.add_edge_by_vertices("Seattle", "San Francisco", 678) 
    city_graph2.add_edge_by_vertices("San Francisco", "Riverside", 386) 
    city_graph2.add_edge_by_vertices("San Francisco", "Los Angeles", 348) 
    city_graph2.add_edge_by_vertices("Los Angeles", "Riverside", 50) 
    city_graph2.add_edge_by_vertices("Los Angeles", "Phoenix", 357) 
    city_graph2.add_edge_by_vertices("Riverside", "Phoenix", 307) 
    city_graph2.add_edge_by_vertices("Riverside", "Chicago", 1704) 
    city_graph2.add_edge_by_vertices("Phoenix", "Dallas", 887) 
    city_graph2.add_edge_by_vertices("Phoenix", "Houston", 1015) 
    city_graph2.add_edge_by_vertices("Dallas", "Chicago", 805) 
    city_graph2.add_edge_by_vertices("Dallas", "Atlanta", 721) 
    city_graph2.add_edge_by_vertices("Dallas", "Houston", 225) 
    city_graph2.add_edge_by_vertices("Houston", "Atlanta", 702) 
    city_graph2.add_edge_by_vertices("Houston", "Miami", 968) 
    city_graph2.add_edge_by_vertices("Atlanta", "Chicago", 588) 
    city_graph2.add_edge_by_vertices("Atlanta", "Washington", 543) 
    city_graph2.add_edge_by_vertices("Atlanta", "Miami", 604) 
    city_graph2.add_edge_by_vertices("Miami", "Washington", 923) 
    city_graph2.add_edge_by_vertices("Chicago", "Detroit", 238) 
    city_graph2.add_edge_by_vertices("Detroit", "Boston", 613) 
    city_graph2.add_edge_by_vertices("Detroit", "Washington", 396) 
    city_graph2.add_edge_by_vertices("Detroit", "New York", 482) 
    city_graph2.add_edge_by_vertices("Boston", "New York", 190) 
    city_graph2.add_edge_by_vertices("New York", "Philadelphia", 81) 
    city_graph2.add_edge_by_vertices("Philadelphia", "Washington", 123) 
 
    distances, path_dict = dijkstra(city_graph2, "Los Angeles") 
    name_distance: Dict[str, Optional[int]] = distance_array_to_vertex_ 
     dict(city_graph2, distances) 
    print("Distances from Los Angeles:") 
    for key, value in name_distance.items(): 
        print(f"{key} : {value}") 
    print("") # blank line 
 
    print("Shortest path from Los Angeles to Boston:") 
    path: WeightedPath = path_dict_to_path(city_graph2.index_of("Los 
     Angeles"), city_graph2.index_of("Boston"), path_dict) 
    print_weighted_path(city_graph2, path)
1
2
Distances from Los Angeles: 
Seattle : 1026 

3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
San Francisco : 348 
Los Angeles : 0 
Riverside : 50 
Phoenix : 357 
Chicago : 1754 
Boston : 2605 
New York : 2474 
Atlanta : 1965 
Miami : 2340 
Dallas : 1244 
Houston : 1372 
Detroit : 1992 
Philadelphia : 2511 
Washington : 2388 
 
Shortest path from Los Angeles to Boston: 
Los Angeles 50> Riverside 
Riverside 1704> Chicago 
Chicago 238> Detroit 
Detroit 613> Boston 
Total Weight: 2605

CHAPTER 5
Figure 5.1. The general outline of a genetic algorithm
Listing 5.1. chromosome.py
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
from __future__ import annotations 
from typing import TypeVar, Tuple, Type 
from abc import ABC, abstractmethod 
 
T = TypeVar('T', bound='Chromosome') # for returning self 
 
# Base class for all chromosomes; all methods must be overridden 
class Chromosome(ABC): 
    @abstractmethod 
    def fitness(self) -> float: 
        ... 
 
    @classmethod 
    @abstractmethod 
    def random_instance(cls: Type[T]) -> T: 
        ... 
 
    @abstractmethod 
    def crossover(self: T, other: T) -> Tuple[T, T]: 
        ... 
 
    @abstractmethod 
    def mutate(self) -> None: 
        ...

Listing 5.2. genetic_algorithm.py
1
2
3
4
5
6
7
8
9
10
11
12
13
from __future__ import annotations 
from typing import TypeVar, Generic, List, Tuple, Callable 
from enum import Enum 
from random import choices, random 
from heapq import nlargest 
from statistics import mean 
from chromosome import Chromosome 
 
C = TypeVar('C', bound=Chromosome) # type of the chromosomes 
 
 
class GeneticAlgorithm(Generic[C]): 
    SelectionType = Enum("SelectionType", "ROULETTE TOURNAMENT")
Listing 5.3. genetic_algorithm.py continued
1
2
3
4
5
6
7
8
9
def __init__(self, initial_population: List[C], threshold: float, max_ 
     generations: int = 100, mutation_chance: float = 0.01, crossover_chance: 
     float = 0.7, selection_type: SelectionType = SelectionType.TOURNAMENT) - 
     > None: 
    self._population: List[C] = initial_population 
    self._threshold: float = threshold 
    self._max_generations: int = max_generations 
    self._mutation_chance: float = mutation_chance 
    self._crossover_chance: float = crossover_chance 

Figure 5.2. An example of 
 in action
roulette-wheel selection
10
11
    self._selection_type: GeneticAlgorithm.SelectionType = selection_type 
    self._fitness_key: Callable = type(self._population[0]).fitness
Listing 5.4. genetic_algorithm.py continued
1
2
3
4
# Use the probability distribution wheel to pick 2 parents 
# Note: will not work with negative fitness results 
def _pick_roulette(self, wheel: List[float]) -> Tuple[C, C]: 
    return tuple(choices(self._population, weights=wheel, k=2))
Listing 5.5. genetic_algorithm.py continued
1
2
3
4
# Choose num_participants at random and take the best 2 
def _pick_tournament(self, num_participants: int) -> Tuple[C, C]: 
    participants: List[C] = choices(self._population, k=num_participants) 
    return tuple(nlargest(2, participants, key=self._fitness_key))

Listing 5.6. genetic_algorithm.py continued
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
# Replace the population with a new generation of individuals 
def _reproduce_and_replace(self) -> None: 
    new_population: List[C] = [] 
    # keep going until we've filled the new generation 
    while len(new_population) < len(self._population): 
        # pick the 2 parents 
        if self._selection_type == GeneticAlgorithm.SelectionType.ROULETTE: 
            parents: Tuple[C, C] = self._pick_roulette([x.fitness() for x in 
     self._population]) 
        else: 
            parents = self._pick_tournament(len(self._population) // 2) 
        # potentially crossover the 2 parents 
        if random() < self._crossover_chance: 
            new_population.extend(parents[0].crossover(parents[1])) 
        else: 
            new_population.extend(parents) 
    # if we had an odd number, we'll have 1 extra, so we remove it 
    if len(new_population) > len(self._population): 
        new_population.pop() 
    self._population = new_population # replace reference
Listing 5.7. genetic_algorithm.py continued
1
2
3
4
5
# With _mutation_chance probability mutate each individual 
def _mutate(self) -> None: 
    for individual in self._population: 
        if random() < self._mutation_chance: 
            individual.mutate()
Listing 5.8. genetic_algorithm.py continued
1
2
3
4
5
6
7
8
9
10
11
12
13
# Run the genetic algorithm for max_generations iterations 
# and return the best individual found 
def run(self) -> C: 
    best: C = max(self._population, key=self._fitness_key) 
    for generation in range(self._max_generations): 
        # early exit if we beat threshold 
        if best.fitness() >= self._threshold:  
            return best 
        print(f"Generation {generation} Best {best.fitness()} Avg 
     {mean(map(self._fitness_key, self._population))}") 
        self._reproduce_and_replace() 
        self._mutate() 
        highest: C = max(self._population, key=self._fitness_key) 

14
15
16
        if highest.fitness() > best.fitness(): 
            best = highest # found a new best 
    return best # best we found in _max_generations
Listing 5.9. simple_equation.py
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
from __future__ import annotations 
from typing import Tuple, List 
from chromosome import Chromosome 
from genetic_algorithm import GeneticAlgorithm 
from random import randrange, random 
from copy import deepcopy 
 
class SimpleEquation(Chromosome): 
    def __init__(self, x: int, y: int) -> None: 
        self.x: int = x 
        self.y: int = y 
 
    def fitness(self) -> float: # 6x - x^2 + 4y - y^2 
        return 6 * self.x - self.x * self.x + 4 * self.y - self.y * self.y 
    @classmethod 
    def random_instance(cls) -> SimpleEquation: 
        return SimpleEquation(randrange(100), randrange(100)) 
 
    def crossover(self, other: SimpleEquation) -> Tuple[SimpleEquation, 
     SimpleEquation]: 
        child1: SimpleEquation = deepcopy(self) 
        child2: SimpleEquation = deepcopy(other) 
        child1.y = other.y 
        child2.y = self.y 
        return child1, child2 
 
    def mutate(self) -> None: 
        if random() > 0.5: # mutate x 
            if random() > 0.5: 
                self.x += 1 
            else: 
                self.x -= 1 
        else: # otherwise mutate y 
            if random() > 0.5: 
                self.y += 1 
            else: 
                self.y -= 1 
 
    def __str__(self) -> str: 
        return f"X: {self.x} Y: {self.y} Fitness: {self.fitness()}"
Listing 5.10. simple_equation.py continued
1
2
3
4
5
6
if __name__ == "__main__": 
    initial_population: List[SimpleEquation] = [SimpleEquation.random_ 
     instance() for _ in range(20)] 
    ga: GeneticAlgorithm[SimpleEquation] = GeneticAlgorithm(initial_population=initia
     population, threshold=13.0, max_generations = 100, 
     mutation_chance = 0.1, crossover_chance = 0.7) 

7
8
    result: SimpleEquation = ga.run() 
    print(result)
1
2
3
4
5
6
7
8
9
10
Generation 0 Best -349 Avg -6112.3 
Generation 1 Best 4 Avg -1306.7 
Generation 2 Best 9 Avg -288.25 
Generation 3 Best 9 Avg -7.35 
Generation 4 Best 12 Avg 7.25 
Generation 5 Best 12 Avg 8.5 
Generation 6 Best 12 Avg 9.65 
Generation 7 Best 12 Avg 11.7 
Generation 8 Best 12 Avg 11.6 
X: 3 Y: 2 Fitness: 13
Listing 5.11. send_more_money2.py
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
from __future__ import annotations 
from typing import Tuple, List 
from chromosome import Chromosome 
from genetic_algorithm import GeneticAlgorithm 
from random import shuffle, sample 
from copy import deepcopy 
 
class SendMoreMoney2(Chromosome): 
    def __init__(self, letters: List[str]) -> None: 
        self.letters: List[str] = letters 
 
    def fitness(self) -> float: 
        s: int = self.letters.index("S") 
        e: int = self.letters.index("E") 
        n: int = self.letters.index("N") 
        d: int = self.letters.index("D") 
        m: int = self.letters.index("M") 
        o: int = self.letters.index("O") 
        r: int = self.letters.index("R") 
        y: int = self.letters.index("Y") 
        send: int = s * 1000 + e * 100 + n * 10 + d 
        more: int = m * 1000 + o * 100 + r * 10 + e 
        money: int = m * 10000 + o * 1000 + n * 100 + e * 10 + y 
        difference: int = abs(money - (send + more)) 
        return 1 / (difference + 1) 
 
    @classmethod 
    def random_instance(cls) -> SendMoreMoney2: 
        letters = ["S", "E", "N", "D", "M", "O", "R", "Y", " ", " "] 
        shuffle(letters) 
        return SendMoreMoney2(letters) 
 
    def crossover(self, other: SendMoreMoney2) -> Tuple[SendMoreMoney2, 
     SendMoreMoney2]: 
        child1: SendMoreMoney2 = deepcopy(self) 
        child2: SendMoreMoney2 = deepcopy(other) 
        idx1, idx2 = sample(range(len(self.letters)), k=2) 
        l1, l2 = child1.letters[idx1], child2.letters[idx2] 
        child1.letters[child1.letters.index(l2)], child1.letters[idx2] = 

Table 5.1. How the equation 1 / (difference + 1) yields Øtnesses for maximization (view
table Øgure)
di|erence
di|erence + 1
tness (1/(di|erence + 1))
0
1
1
1
2
0.5
2
3
0.25
3
4
0.125
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
     child1.letters[idx2], l2 
        child2.letters[child2.letters.index(l1)], child2.letters[idx1] = 
     child2.letters[idx1], l1 
        return child1, child2 
 
    def mutate(self) -> None: # swap two letters' locations 
        idx1, idx2 = sample(range(len(self.letters)), k=2) 
        self.letters[idx1], self.letters[idx2] = self.letters[idx2], 
     self.letters[idx1] 
 
    def __str__(self) -> str: 
        s: int = self.letters.index("S") 
        e: int = self.letters.index("E") 
        n: int = self.letters.index("N") 
        d: int = self.letters.index("D") 
        m: int = self.letters.index("M") 
        o: int = self.letters.index("O") 
        r: int = self.letters.index("R") 
        y: int = self.letters.index("Y") 
        send: int = s * 1000 + e * 100 + n * 10 + d 
        more: int = m * 1000 + o * 100 + r * 10 + e 
        money: int = m * 10000 + o * 1000 + n * 100 + e * 10 + y 
        difference: int = abs(money - (send + more)) 
        return f"{send} + {more} = {money} Difference: {difference}"
Listing 5.12. send_more_money2.py continued
1
2
3
4
5
6
7
8
9
if __name__ == "__main__": 
    initial_population: List[SendMoreMoney2] = [SendMoreMoney2.random_ 
     instance() for _ in range(1000)] 
    ga: GeneticAlgorithm[SendMoreMoney2] = GeneticAlgorithm(initial_population=initia
     population, threshold=1.0, max_generations = 1000, 
     mutation_chance = 0.2, crossover_chance = 0.7, selection_ 
     type=GeneticAlgorithm.SelectionType.ROULETTE) 
    result: SendMoreMoney2 = ga.run() 
    print(result)

1
2
3
4
Generation 0 Best 0.0040650406504065045 Avg 8.854014252391551e-05 
Generation 1 Best 0.16666666666666666 Avg 0.001277329479413134 
Generation 2 Best 0.5 Avg 0.014920889170684687 
8324 + 913 = 9237 Difference: 0
Listing 5.13. list_compression.py
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
from __future__ import annotations 
from typing import Tuple, List, Any 
from chromosome import Chromosome 
from genetic_algorithm import GeneticAlgorithm 
from random import shuffle, sample 
from copy import deepcopy 
from zlib import compress 
from sys import getsizeof 
from pickle import dumps 
# 165 bytes compressed 
PEOPLE: List[str] = ["Michael", "Sarah", "Joshua", "Narine", "David", 
    "Sajid", "Melanie", "Daniel", "Wei", "Dean", "Brian", "Murat", "Lisa"]  
class ListCompression(Chromosome): 
   def __init__(self, lst: List[Any]) -> None: 
       self.lst: List[Any] = lst 
   @property 
   def bytes_compressed(self) -> int: 
       return getsizeof(compress(dumps(self.lst))) 
   def fitness(self) -> float: 
       return 1 / self.bytes_compressed 
   @classmethod 
   def random_instance(cls) -> ListCompression: 
       mylst: List[str] = deepcopy(PEOPLE) 
       shuffle(mylst) 
       return ListCompression(mylst) 
   def crossover(self, other: ListCompression) -> Tuple[ListCompression, 
    ListCompression]: 
       child1: ListCompression = deepcopy(self) 
       child2: ListCompression = deepcopy(other) 
       idx1, idx2 = sample(range(len(self.lst)), k=2) 
       l1, l2 = child1.lst[idx1], child2.lst[idx2] 
       child1.lst[child1.lst.index(l2)], child1.lst[idx2] = 
    child1.lst[idx2], l2 
       child2.lst[child2.lst.index(l1)], child2.lst[idx1] = 
    child2.lst[idx1], l1 
       return child1, child2 
   def mutate(self) -> None: # swap two locations 
       idx1, idx2 = sample(range(len(self.lst)), k=2) 
       self.lst[idx1], self.lst[idx2] = self.lst[idx2], self.lst[idx1] 
   def __str__(self) -> str: 
       return f"Order: {self.lst} Bytes: {self.bytes_compressed}" 
if __name__ == "__main__": 
   initial_population: List[ListCompression] = [ListCompression.random_ 
    instance() for _ in range(1000)] 

55
56
57
58
59
60
   ga: GeneticAlgorithm[ListCompression] = GeneticAlgorithm(initial_population=init
    population, threshold=1.0, max_generations = 1000, 
    mutation_chance = 0.2, crossover_chance = 0.7, selection_ 
    type=GeneticAlgorithm.SelectionType.TOURNAMENT) 
   result: ListCompression = ga.run() 
   print(result)

CHAPTER 6
Listing 6.1. kmeans.py
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
from __future__ import annotations 
from typing import TypeVar, Generic, List, Sequence 
from copy import deepcopy 
from functools import partial 
from random import uniform 
from statistics import mean, pstdev 
from dataclasses import dataclass 
from data_point import DataPoint 
 
def zscores(original: Sequence[float]) -> List[float]: 
    avg: float = mean(original) 
    std: float = pstdev(original) 
    if std == 0: # return all zeros if there is no variation 
        return [0] * len(original) 
    return [(x - avg) / std for x in original]
Listing 6.2. data_point.py
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
from __future__ import annotations 
from typing import Iterator, Tuple, List, Iterable 
from math import sqrt 
 
class DataPoint: 
    def __init__(self, initial: Iterable[float]) -> None: 
        self._originals: Tuple[float, ...] = tuple(initial) 
        self.dimensions: Tuple[float, ...] = tuple(initial) 
 
    @property 
    def num_dimensions(self) -> int: 
        return len(self.dimensions) 
 
    def distance(self, other: DataPoint) -> float: 
        combined: Iterator[Tuple[float, float]] = zip(self.dimensions, 
      other.dimensions) 
        differences: List[float] = [(x - y) ** 2 for x, y in combined] 
        return sqrt(sum(differences)) 
 
    def __eq__(self, other: object) -> bool: 
        if not isinstance(other, DataPoint): 
            return NotImplemented 
        return self.dimensions == other.dimensions 
 
    def __repr__(self) -> str: 
        return self._originals.__repr__()

Figure 6.1. An example of k-means running through three 
 on an arbitrary
data set. Stars indicate centroids. Colors and shapes represent current cluster
membership (which changes).
generations
Listing 6.3. kmeans.py continued
1
2
3
4
5
6
7
Point = TypeVar('Point', bound=DataPoint) 
 
class KMeans(Generic[Point]): 
    @dataclass 
    class Cluster: 
        points: List[Point] 
        centroid: DataPoint
Listing 6.4. kmeans.py continued
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
def __init__(self, k: int, points: List[Point]) -> None: 
    if k < 1: # k-means can't do negative or zero clusters 
        raise ValueError("k must be >= 1") 
    self._points: List[Point] = points 
    self._zscore_normalize() 
    # initialize empty clusters with random centroids 
    self._clusters: List[KMeans.Cluster] = [] 
    for _ in range(k): 
        rand_point: DataPoint = self._random_point() 
        cluster: KMeans.Cluster = KMeans.Cluster([], rand_point) 
        self._clusters.append(cluster) 
 
@property 
def _centroids(self) -> List[DataPoint]: 
    return [x.centroid for x in self._clusters]

Listing 6.5. kmeans.py continued
1
2
def _dimension_slice(self, dimension: int) -> List[float]: 
    return [x.dimensions[dimension] for x in self._points]
Listing 6.6. kmeans.py continued
1
2
3
4
5
6
7
8
def _zscore_normalize(self) -> None: 
    zscored: List[List[float]] = [[] for _ in range(len(self._points))] 
    for dimension in range(self._points[0].num_dimensions): 
        dimension_slice: List[float] = self._dimension_slice(dimension) 
        for index, zscore in enumerate(zscores(dimension_slice)): 
            zscored[index].append(zscore) 
    for i in range(len(self._points)): 
        self._points[i].dimensions = tuple(zscored[i])
Listing 6.7. kmeans.py continued
1
2
3
4
5
6
7
def _random_point(self) -> DataPoint: 
    rand_dimensions: List[float] = [] 
    for dimension in range(self._points[0].num_dimensions): 
        values: List[float] = self._dimension_slice(dimension) 
        rand_value: float = uniform(min(values), max(values)) 
        rand_dimensions.append(rand_value) 
    return DataPoint(rand_dimensions)
Listing 6.8. kmeans.py continued
1
2
3
4
5
6
7
8
9
# Find the closest cluster centroid to each point and assign the point to 
     that cluster 
def _assign_clusters(self) -> None: 
    for point in self._points: 
        closest: DataPoint = min(self._centroids, 
    key=partial(DataPoint.distance, point)) 
        idx: int = self._centroids.index(closest) 
        cluster: KMeans.Cluster = self._clusters[idx] 
        cluster.points.append(point)

Listing 6.9. kmeans.py continued
1
2
3
4
5
6
7
8
9
10
11
# Find the center of each cluster and move the centroid to there 
def _generate_centroids(self) -> None: 
    for cluster in self._clusters: 
        if len(cluster.points) == 0: # keep the same centroid if no points 
            continue 
        means: List[float] = [] 
        for dimension in range(cluster.points[0].num_dimensions): 
            dimension_slice: List[float] = [p.dimensions[dimension] for p in 
      cluster.points] 
            means.append(mean(dimension_slice)) 
        cluster.centroid = DataPoint(means)
Listing 6.10. kmeans.py continued
1
2
3
4
5
6
7
8
9
10
11
def run(self, max_iterations: int = 100) -> List[KMeans.Cluster]: 
    for iteration in range(max_iterations): 
        for cluster in self._clusters: # clear all clusters 
            cluster.points.clear() 
        self._assign_clusters() # find cluster each point is closest to 
        old_centroids: List[DataPoint] = deepcopy(self._centroids) # record 
        self._generate_centroids() # find new centroids 
        if old_centroids == self._centroids: # have centroids moved? 
            print(f"Converged after {iteration} iterations") 
            return self._clusters 
    return self._clusters
Listing 6.11. kmeans.py continued
1
2
3
4
5
6
7
8
if __name__ == "__main__": 
    point1: DataPoint = DataPoint([2.0, 1.0, 1.0]) 
    point2: DataPoint = DataPoint([2.0, 2.0, 5.0]) 
    point3: DataPoint = DataPoint([3.0, 1.5, 2.5]) 
    kmeans_test: KMeans[DataPoint] = KMeans(2, [point1, point2, point3]) 
    test_clusters: List[KMeans.Cluster] = kmeans_test.run() 
    for index, cluster in enumerate(test_clusters): 
        print(f"Cluster {index}: {cluster.points}")
1
2
3
Converged after 1 iterations 
Cluster 0: [(2.0, 1.0, 1.0), (3.0, 1.5, 2.5)] 
Cluster 1: [(2.0, 2.0, 5.0)]

Figure 6.2. State governors, as of June 2017, plotted by state longitude and governor
age
Listing 6.12. governors.py
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
from __future__ import annotations 
from typing import List 
from data_point import DataPoint 
from kmeans import KMeans 
 
class Governor(DataPoint): 
    def __init__(self, longitude: float, age: float, state: str) -> None: 
        super().__init__([longitude, age]) 
        self.longitude = longitude 
        self.age = age 
        self.state = state 
 
    def __repr__(self) -> str: 
        return f"{self.state}: (longitude: {self.longitude}, age: 
  {self.age})"

Listing 6.13. governors.py continued
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
if __name__ == "__main__": 
    governors: List[Governor] = [Governor(-86.79113, 72, "Alabama"), 
     Governor(-152.404419, 66, "Alaska"), 
                 Governor(-111.431221, 53, "Arizona"), Governor(-92.373123, 
     66, "Arkansas"), 
                 Governor(-119.681564, 79, "California"), Governor(- 
     105.311104, 65, "Colorado"), 
                 Governor(-72.755371, 61, "Connecticut"), Governor(- 
     75.507141, 61, "Delaware"), 
                 Governor(-81.686783, 64, "Florida"), Governor(-83.643074, 
     74, "Georgia"), 
                 Governor(-157.498337, 60, "Hawaii"), Governor(-114.478828, 
     75, "Idaho"), 
                 Governor(-88.986137, 60, "Illinois"), Governor(-86.258278, 
     49, "Indiana"), 
                 Governor(-93.210526, 57, "Iowa"), Governor(-96.726486, 60, 
     "Kansas"), 
                 Governor(-84.670067, 50, "Kentucky"), Governor(-91.867805, 
     50, "Louisiana"), 
                 Governor(-69.381927, 68, "Maine"), Governor(-76.802101, 61, 
     "Maryland"), 
                 Governor(-71.530106, 60, "Massachusetts"), Governor(- 
     84.536095, 58, "Michigan"), 
                 Governor(-93.900192, 70, "Minnesota"), Governor(-89.678696, 
     62, "Mississippi"), 
                 Governor(-92.288368, 43, "Missouri"), Governor(-110.454353, 
     51, "Montana"), 
                 Governor(-98.268082, 52, "Nebraska"), Governor(-117.055374, 
     53, "Nevada"), 
                 Governor(-71.563896, 42, "New Hampshire"), Governor(- 
     74.521011, 54, "New Jersey"), 
                 Governor(-106.248482, 57, "New Mexico"), Governor(- 
     74.948051, 59, "New York"), 
                 Governor(-79.806419, 60, "North Carolina"), Governor(- 
     99.784012, 60, "North Dakota"), 
                 Governor(-82.764915, 65, "Ohio"), Governor(-96.928917, 62, 
     "Oklahoma"), 
                 Governor(-122.070938, 56, "Oregon"), Governor(-77.209755, 
     68, "Pennsylvania"), 
                 Governor(-71.51178, 46, "Rhode Island"), Governor(- 
     80.945007, 70, "South Carolina"), 
                 Governor(-99.438828, 64, "South Dakota"), Governor(- 
     86.692345, 58, "Tennessee"), 
                 Governor(-97.563461, 59, "Texas"), Governor(-111.862434, 70, 
     "Utah"), 
                 Governor(-72.710686, 58, "Vermont"), Governor(-78.169968, 
     60, "Virginia"), 
                 Governor(-121.490494, 66, "Washington"), Governor(- 
     80.954453, 66, "West Virginia"), 
                 Governor(-89.616508, 49, "Wisconsin"), Governor(-107.30249, 
     55, "Wyoming")]
Listing 6.14. governors.py continued
1
2
3
4
kmeans: KMeans[Governor] = KMeans(2, governors) 
gov_clusters: List[KMeans.Cluster] = kmeans.run() 
for index, cluster in enumerate(gov_clusters): 
    print(f"Cluster {index}: {cluster.points}\n")

Figure 6.3. Data points in cluster 0 are designated by circles, and data points in cluster 1
are designated by squares.
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
Converged after 5 iterations 
Cluster 0: [Alabama: (longitude: -86.79113, age: 72), Arizona: (longitude: - 
     111.431221, age: 53), Arkansas: (longitude: -92.373123, age: 66), 
     Colorado: (longitude: -105.311104, age: 65), Connecticut: (longitude: - 
     72.755371, age: 61), Delaware: (longitude: -75.507141, age: 61), 
     Florida: (longitude: -81.686783, age: 64), Georgia: (longitude: - 
     83.643074, age: 74), Illinois: (longitude: -88.986137, age: 60), 
     Indiana: (longitude: -86.258278, age: 49), Iowa: (longitude: -93.210526, 
     age: 57), Kansas: (longitude: -96.726486, age: 60), Kentucky: 
     (longitude: -84.670067, age: 50), Louisiana: (longitude: -91.867805, 
     age: 50), Maine: (longitude: -69.381927, age: 68), Maryland: (longitude: 
     -76.802101, age: 61), Massachusetts: (longitude: -71.530106, age: 60), 
     Michigan: (longitude: -84.536095, age: 58), Minnesota: (longitude: - 
     93.900192, age: 70), Mississippi: (longitude: -89.678696, age: 62), 
     Missouri: (longitude: -92.288368, age: 43), Montana: (longitude: - 
     110.454353, age: 51), Nebraska: (longitude: -98.268082, age: 52), 
     Nevada: (longitude: -117.055374, age: 53), New Hampshire: (longitude: - 
     71.563896, age: 42), New Jersey: (longitude: -74.521011, age: 54), New 
     Mexico: (longitude: -106.248482, age: 57), New York: (longitude: - 
     74.948051, age: 59), North Carolina: (longitude: -79.806419, age: 60), 
     North Dakota: (longitude: -99.784012, age: 60), Ohio: (longitude: - 
     82.764915, age: 65), Oklahoma: (longitude: -96.928917, age: 62), 
     Pennsylvania: (longitude: -77.209755, age: 68), Rhode Island: 
     (longitude: -71.51178, age: 46), South Carolina: (longitude: -80.945007, 
     age: 70), South Dakota: (longitude: -99.438828, age: 64), Tennessee: 
     (longitude: -86.692345, age: 58), Texas: (longitude: -97.563461, age: 
     59), Vermont: (longitude: -72.710686, age: 58), Virginia: (longitude: - 
     78.169968, age: 60), West Virginia: (longitude: -80.954453, age: 66), 
     Wisconsin: (longitude: -89.616508, age: 49), Wyoming: (longitude: - 
     107.30249, age: 55)] 
Cluster 1: [Alaska: (longitude: -152.404419, age: 66), California: 
     (longitude: -119.681564, age: 79), Hawaii: (longitude: -157.498337, age: 
     60), Idaho: (longitude: -114.478828, age: 75), Oregon: (longitude: - 
     122.070938, age: 56), Utah: (longitude: -111.862434, age: 70), 
     Washington: (longitude: -121.490494, age: 66)]

Listing 6.15. mj.py
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
from __future__ import annotations 
from typing import List 
from data_point import DataPoint 
from kmeans import KMeans 
 
class Album(DataPoint): 
    def __init__(self, name: str, year: int, length: float, tracks: float) -> 
     None: 
        super().__init__([length, tracks]) 
        self.name = name 
        self.year = year 
        self.length = length 
        self.tracks = tracks 
 
    def __repr__(self) -> str: 
        return f"{self.name}, {self.year}" 
 
if __name__ == "__main__": 
    albums: List[Album] = [Album("Got to Be There", 1972, 35.45, 10), 
     Album("Ben", 1972, 31.31, 10), 
                           Album("Music & Me", 1973, 32.09, 10), 
     Album("Forever, Michael", 1975, 33.36, 10), 
                           Album("Off the Wall", 1979, 42.28, 10), 
     Album("Thriller", 1982, 42.19, 9), 
                           Album("Bad", 1987, 48.16, 10), Album("Dangerous", 
     1991, 77.03, 14), 
                           Album("HIStory: Past, Present and Future, Book I", 
     1995, 148.58, 30), Album("Invincible", 2001, 77.05, 16)] 
    kmeans: KMeans[Album] = KMeans(2, albums) 
    clusters: List[KMeans.Cluster] = kmeans.run() 
    for index, cluster in enumerate(clusters): 
        print(f"Cluster {index} Avg Length {cluster.centroid.dimensions[0]} 
      Avg Tracks {cluster.centroid.dimensions[1]}: {cluster.points}\n")

1
2
3
4
5
6
7
8
Converged after 1 iterations 
Cluster 0 Avg Length -0.5458820039179509 Avg Tracks -0.5009878988684237: [Got 
     to Be There, 1972, Ben, 1972, Music & Me, 1973, Forever, Michael, 1975, 
     Off the Wall, 1979, Thriller, 1982, Bad, 1987] 
 
Cluster 1 Avg Length 1.2737246758085523 Avg Tracks 1.1689717640263217: 
     [Dangerous, 1991, HIStory: Past, Present and Future, Book I, 1995, 
     Invincible, 2001]

CHAPTER 7
Figure 7.1. A researcher studies fMRI images of the brain. fMRI images do not tell us
much about how individual neurons function or how neural networks are organized.
Figure 7.2. A single neuron combines its weights with input signals to produce an
output signal that is modiØed by an activation function.

Figure 7.3. A simple neural network with one 
 of two neurons, one hidden
layer of four neurons, and one output layer of three neurons. The number of neurons in
each layer in this Øgure is arbitrary.
input layer
Figure 7.4. The mechanism by which an output neuron’s delta is calculated during the
backpropagation phase of training

Figure 7.5. How a delta is calculated for a neuron in a hidden layer
Figure 7.6. The weights of every 
 and output layer neuron are updated
using the deltas calculated in the previous steps, the prior weights, the prior inputs, and
a user-determined learning rate.
hidden layer

Figure 7.7. The sigmoid activation function (S(x)) will always return a value between 0
and 1. Note that its derivative is easy to compute as well (S'(x)).
Listing 7.1. util.py
1
2
3
4
5
6
from typing import List 
from math import exp 
 
# dot product of two vectors 
def dot_product(xs: List[float], ys: List[float]) -> float: 
    return sum(x * y for x, y in zip(xs, ys))
Listing 7.2. util.py continued
1
2
3
4
# the classic sigmoid activation function 
def sigmoid(x: float) -> float: 
    return 1.0 / (1.0 + exp(-x)) 
 

5
6
7
def derivative_sigmoid(x: float) -> float: 
    sig: float = sigmoid(x) 
    return sig * (1 - sig)
Listing 7.3. neuron.py
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
from typing import List, Callable 
from util import dot_product 
 
class Neuron: 
def __init__(self, weights: List[float], learning_rate: float, 
 activation_function: Callable[[float], float], derivative_activation_ 
 function: Callable[[float], float]) -> None: 
    self.weights: List[float] = weights 
    self.activation_function: Callable[[float], float] = activation_ 
 function 
    self.derivative_activation_function: Callable[[float], float] = 
 derivative_activation_function 
    self.learning_rate: float = learning_rate 
    self.output_cache: float = 0.0 
    self.delta: float = 0.0 
 
def output(self, inputs: List[float]) -> float: 
    self.output_cache = dot_product(inputs, self.weights) 
    return self.activation_function(self.output_cache)
Listing 7.4. layer.py
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
from __future__ import annotations 
from typing import List, Callable, Optional 
from random import random 
from neuron import Neuron 
from util import dot_product 
 
class Layer: 
    def __init__(self, previous_layer: Optional[Layer], num_neurons: int, 
     learning_rate: float, activation_function: Callable[[float], float], 
     derivative_activation_function: Callable[[float], float]) -> None: 
         self.previous_layer: Optional[Layer] = previous_layer 
         self.neurons: List[Neuron] = [] 
         # the following could all be one large list comprehension  
         for i in range(num_neurons): 
            if previous_layer is None: 
                random_weights: List[float] = [] 
            else: 
                random_weights = [random() for _ in range(len(previous_ 
     layer.neurons))] 
            neuron: Neuron = Neuron(random_weights, learning_rate, 
     activation_function, derivative_activation_function) 
            self.neurons.append(neuron) 
        self.output_cache: List[float] = [0.0 for _ in range(num_neurons)]

Listing 7.5. layer.py continued
1
2
3
4
5
6
def outputs(self, inputs: List[float]) -> List[float]: 
    if self.previous_layer is None: 
        self.output_cache = inputs 
    else: 
        self.output_cache = [n.output(inputs) for n in self.neurons] 
    return self.output_cache
Listing 7.6. layer.py continued
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
# should only be called on output layer 
def calculate_deltas_for_output_layer(self, expected: List[float]) -> None: 
    for n in range(len(self.neurons)): 
        self.neurons[n].delta = self.neurons[n].derivative_activation_ 
     function(self.neurons[n].output_cache) * (expected[n] - self.output_ 
     cache[n]) 
 
# should not be called on output layer 
def calculate_deltas_for_hidden_layer(self, next_layer: Layer) -> None: 
    for index, neuron in enumerate(self.neurons): 
        next_weights: List[float] = [n.weights[index] for n in next_ 
     layer.neurons] 
        next_deltas: List[float] = [n.delta for n in next_layer.neurons] 
        sum_weights_and_deltas: float = dot_product(next_weights, next_ 
     deltas) 
        neuron.delta = neuron.derivative_activation_function(neuron.output_ 
     cache) * sum_weights_and_deltas
Listing 7.7. network.py
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
from __future__ import annotations 
from typing import List, Callable, TypeVar, Tuple 
from functools import reduce 
from layer import Layer 
from util import sigmoid, derivative_sigmoid 
 
T = TypeVar('T') # output type of interpretation of neural network 
 
 
class Network: 
    def __init__(self, layer_structure: List[int], learning_rate: float, 
     activation_function: Callable[[float], float] = sigmoid, derivative_ 
     activation_function: Callable[[float], float] = derivative_sigmoid) -> 
     None: 
        if len(layer_structure) < 3: 
            raise ValueError("Error: Should be at least 3 layers (1 input, 1 
     hidden, 1 output)") 
        self.layers: List[Layer] = [] 
        # input layer 

20
21
22
23
24
25
26
27
        input_layer: Layer = Layer(None, layer_structure[0], learning_rate, 
     activation_function, derivative_activation_function) 
        self.layers.append(input_layer) 
        # hidden layers and output layer 
        for previous, num_neurons in enumerate(layer_structure[1::]): 
            next_layer = Layer(self.layers[previous], num_neurons, learning_ 
     rate, activation_function, derivative_activation_function) 
            self.layers.append(next_layer)
Listing 7.8. network.py continued
1
2
3
4
5
# Pushes input data to the first layer, then output from the first 
# as input to the second, second to the third, etc. 
def outputs(self, input: List[float]) -> List[float]: 
    return reduce(lambda inputs, layer: layer.outputs(inputs), self.layers, 
     input)
Listing 7.9. network.py continued
1
2
3
4
5
6
7
8
9
# Figure out each neuron's changes based on the errors of the output 
# versus the expected outcome 
def backpropagate(self, expected: List[float]) -> None: 
    # calculate delta for output layer neurons 
    last_layer: int = len(self.layers) - 1 
    self.layers[last_layer].calculate_deltas_for_output_layer(expected) 
    # calculate delta for hidden layers in reverse order 
    for l in range(last_layer - 1, 0, -1): 
        self.layers[l].calculate_deltas_for_hidden_layer(self.layers[l + 1])
Listing 7.10. network.py continued
1
2
3
4
5
6
7
8
9
# backpropagate() doesn't actually change any weights 
# this function uses the deltas calculated in backpropagate() to 
# actually make changes to the weights 
def update_weights(self) -> None: 
    for layer in self.layers[1:]: # skip input layer 
        for neuron in layer.neurons: 
            for w in range(len(neuron.weights)): 
                neuron.weights[w] = neuron.weights[w] + (neuron.learning_rate 
    * (layer.previous_layer.output_cache[w]) * neuron.delta)

Listing 7.11. network.py continued
1
2
3
4
5
6
7
8
9
# train() uses the results of outputs() run over many inputs and compared 
# against expecteds to feed backpropagate() and update_weights() 
def train(self, inputs: List[List[float]], expecteds: List[List[float]]) -> 
     None: 
    for location, xs in enumerate(inputs): 
        ys: List[float] = expecteds[location] 
        outs: List[float] = self.outputs(xs) 
        self.backpropagate(ys) 
        self.update_weights()
Listing 7.12. network.py continued
1
2
3
4
5
6
7
8
9
10
11
12
# for generalized results that require classification 
# this function will return the correct number of trials 
# and the percentage correct out of the total 
def validate(self, inputs: List[List[float]], expecteds: List[T], interpret_ 
     output: Callable[[List[float]], T]) -> Tuple[int, int, float]: 
    correct: int = 0 
    for input, expected in zip(inputs, expecteds): 
        result: T = interpret_output(self.outputs(input)) 
        if result == expected: 
            correct += 1 
    percentage: float = correct / len(inputs) 
    return correct, len(inputs), percentage
Listing 7.13. util.py continued
1
2
3
4
5
6
7
8
9
10
# assume all rows are of equal length 
# and feature scale each column to be in the range 0 - 1 
def normalize_by_feature_scaling(dataset: List[List[float]]) -> None: 
    for col_num in range(len(dataset[0])): 
        column: List[float] = [row[col_num] for row in dataset] 
        maximum = max(column) 
    minimum = min(column) 
    for row_num in range(len(dataset)): 
        dataset[row_num][col_num] = (dataset[row_num][col_num] - 
minimum) / (maximum - minimum)
1
2
3
4
5
5.1,3.5,1.4,0.2,Iris-setosa 
4.9,3.0,1.4,0.2,Iris-setosa 
4.7,3.2,1.3,0.2,Iris-setosa 
4.6,3.1,1.5,0.2,Iris-setosa 
5.0,3.6,1.4,0.2,Iris-setosa

Listing 7.14. iris_test.py
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
import csv 
from typing import List 
from util import normalize_by_feature_scaling 
from network import Network 
from random import shuffle 
 
if __name__ == "__main__": 
    iris_parameters: List[List[float]] = [] 
    iris_classifications: List[List[float]] = [] 
    iris_species: List[str] = [] 
    with open('iris.csv', mode='r') as iris_file: 
        irises: List = list(csv.reader(iris_file)) 
        shuffle(irises) # get our lines of data in random order 
        for iris in irises: 
            parameters: List[float] = [float(n) for n in iris[0:4]] 
            iris_parameters.append(parameters) 
            species: str = iris[4] 
            if species == "Iris-setosa": 
                iris_classifications.append([1.0, 0.0, 0.0]) 
            elif species == "Iris-versicolor": 
                iris_classifications.append([0.0, 1.0, 0.0]) 
            else: 
                iris_classifications.append([0.0, 0.0, 1.0]) 
            iris_species.append(species) 
    normalize_by_feature_scaling(iris_parameters)
Listing 7.15. iris_test.py continued
1 iris_network: Network = Network([4, 6, 3], 0.3)
Listing 7.16. iris_test.py continued
1
2
3
4
5
6
7
def iris_interpret_output(output: List[float]) -> str: 
    if max(output) == output[0]: 
        return "Iris-setosa" 
    elif max(output) == output[1]: 
        return "Iris-versicolor" 
    else: 
        return "Iris-virginica"

Listing 7.17. iris_test.py continued
1
2
3
4
5
# train over the first 140 irises in the data set 50 times 
iris_trainers: List[List[float]] = iris_parameters[0:140] 
iris_trainers_corrects: List[List[float]] = iris_classifications[0:140] 
for _ in range(50): 
    iris_network.train(iris_trainers, iris_trainers_corrects)
Listing 7.18. iris_test.py continued
1
2
3
4
5
6
7
# test over the last 10 of the irises in the data set 
iris_testers: List[List[float]] = iris_parameters[140:150] 
iris_testers_corrects: List[str] = iris_species[140:150] 
iris_results = iris_network.validate(iris_testers, iris_testers_corrects, 
     iris_interpret_output) 
print(f"{iris_results[0]} correct of {iris_results[1]} = {iris_results[2] * 
     100}%")
1 9 correct of 10 = 90.0%
1
2
3
4
5
1,14.23,1.71,2.43,15.6,127,2.8,3.06,.28,2.29,5.64,1.04,3.92,1065 
1,13.2,1.78,2.14,11.2,100,2.65,2.76,.26,1.28,4.38,1.05,3.4,1050 
1,13.16,2.36,2.67,18.6,101,2.8,3.24,.3,2.81,5.68,1.03,3.17,1185 
1,14.37,1.95,2.5,16.8,113,3.85,3.49,.24,2.18,7.8,.86,3.45,1480 
1,13.24,2.59,2.87,21,118,2.8,2.69,.39,1.82,4.32,1.04,2.93,735
Listing 7.19. wine_test.py
1
2
3
4
5
6
7
8
9
10
11
import csv 
from typing import List 
from util import normalize_by_feature_scaling 
from network import Network 
from random import shuffle 
if __name__ == "__main__": 
    wine_parameters: List[List[float]] = [] 
    wine_classifications: List[List[float]] = [] 
    wine_species: List[int] = [] 
    with open('wine.csv', mode='r') as wine_file: 
        wines: List = list(csv.reader(wine_file, quoting=csv.QUOTE_ 

12
13
14
15
16
17
18
19
20
21
22
23
24
25
     NONNUMERIC)) 
        shuffle(wines) # get our lines of data in random order 
        for wine in wines: 
            parameters: List[float] = [float(n) for n in wine[1:14]] 
            wine_parameters.append(parameters) 
            species: int = int(wine[0]) 
            if species == 1: 
                wine_classifications.append([1.0, 0.0, 0.0]) 
            elif species == 2: 
                wine_classifications.append([0.0, 1.0, 0.0]) 
            else: 
                wine_classifications.append([0.0, 0.0, 1.0]) 
            wine_species.append(species) 
    normalize_by_feature_scaling(wine_parameters)
Listing 7.20. wine_test.py continued
1 wine_network: Network = Network([13, 7, 3], 0.9)
Listing 7.21. wine_test.py continued
1
2
3
4
5
6
7
def wine_interpret_output(output: List[float]) -> int: 
    if max(output) == output[0]: 
        return 1 
    elif max(output) == output[1]: 
        return 2 
    else: 
        return 3
Listing 7.22. wine_test.py continued
1
2
3
4
5
# train over the first 150 wines 10 times 
wine_trainers: List[List[float]] = wine_parameters[0:150] 
wine_trainers_corrects: List[List[float]] = wine_classifications[0:150] 
for _ in range(10): 
    wine_network.train(wine_trainers, wine_trainers_corrects)
Listing 7.23. wine_test.py continued

1
2
3
4
5
6
7
# test over the last 28 of the wines in the data set 
wine_testers: List[List[float]] = wine_parameters[150:178] 
wine_testers_corrects: List[int] = wine_species[150:178] 
wine_results = wine_network.validate(wine_testers, wine_testers_corrects, 
     wine_interpret_output) 
print(f"{wine_results[0]} correct of {wine_results[1]} = {wine_results[2] * 
     100}%")
1 27 correct of 28 = 96.42857142857143%

CHAPTER 8
Listing 8.1. board.py
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
from __future__ import annotations 
from typing import NewType, List 
from abc import ABC, abstractmethod 
 
Move = NewType('Move', int) 
 
 
class Piece: 
    @property 
    def opposite(self) -> Piece: 
        raise NotImplementedError("Should be implemented by subclasses.") 
 
 
class Board(ABC): 
    @property 
    @abstractmethod 
    def turn(self) -> Piece: 
        ... 
 
    @abstractmethod 
    def move(self, location: Move) -> Board: 
        ... 
 
    @property 
    @abstractmethod 
    def legal_moves(self) -> List[Move]: 
        ... 
 
    @property 
    @abstractmethod 
    def is_win(self) -> bool: 
        ... 
 
    @property 
    def is_draw(self) -> bool: 
        return (not self.is_win) and (len(self.legal_moves) == 0) 
 
    @abstractmethod 
    def evaluate(self, player: Piece) -> float: 
        ...
Listing 8.2. tictactoe.py
1
2
3
4
5
6
7
from __future__ import annotations 
from typing import List 
from enum import Enum 
from board import Piece, Board, Move 
 
 
class TTTPiece(Piece, Enum): 

Figure 8.1. The one-dimensional list indices that correspond to each square in the tic-
tac-toe board
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
    X = "X" 
    O = "O" 
    E = " " # stand-in for empty 
 
    @property 
    def opposite(self) -> TTTPiece: 
        if self == TTTPiece.X: 
            return TTTPiece.O 
        elif self == TTTPiece.O: 
            return TTTPiece.X 
        else: 
            return TTTPiece.E 
 
def __str__(self) -> str: 
    return self.value
Listing 8.3. tictactoe.py continued
1
2
3
4
5
6
7
8
9
class TTTBoard(Board): 
    def __init__(self, position: List[TTTPiece] = [TTTPiece.E] * 9, turn: 
     TTTPiece = TTTPiece.X) -> None: 
        self.position: List[TTTPiece] = position 
        self._turn: TTTPiece = turn 
 
    @property 
    def turn(self) -> Piece: 
        return self._turn
Listing 8.4. tictactoe.py continued
1
2
3
def move(self, location: Move) -> Board: 
    temp_position: List[TTTPiece] = self.position.copy() 

4     temp_position[location] = self._turn 
    return TTTBoard(temp_position, self._turn.opposite)
Listing 8.5. tictactoe.py continued
1
2
3
4
@property 
def legal_moves(self) -> List[Move]: 
    return [Move(l) for l in range(len(self.position)) if self.position[l] == 
     TTTPiece.E]
Listing 8.6. tictactoe.py continued
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
@property 
def is_win(self) -> bool: 
    # three row, three column, and then two diagonal checks 
    return self.position[0] == self.position[1] and self.position[0] == 
     self.position[2] and self.position[0] != TTTPiece.E or \ 
    self.position[3] == self.position[4] and self.position[3] == 
     self.position[5] and self.position[3] != TTTPiece.E or \ 
    self.position[6] == self.position[7] and self.position[6] == 
     self.position[8] and self.position[6] != TTTPiece.E or \ 
    self.position[0] == self.position[3] and self.position[0] == 
     self.position[6] and self.position[0] != TTTPiece.E or \ 
    self.position[1] == self.position[4] and self.position[1] == 
     self.position[7] and self.position[1] != TTTPiece.E or \ 
    self.position[2] == self.position[5] and self.position[2] == 
     self.position[8] and self.position[2] != TTTPiece.E or \ 
    self.position[0] == self.position[4] and self.position[0] == 
     self.position[8] and self.position[0] != TTTPiece.E or \ 
    self.position[2] == self.position[4] and self.position[2] == 
     self.position[6] and self.position[2] != TTTPiece.E
Listing 8.7. tictactoe.py continued
1
2
3
4
5
6
7
8
9
10
11
12
13
def evaluate(self, player: Piece) -> float: 
        if self.is_win and self.turn == player: 
           return -1 
        elif self.is_win and self.turn != player: 
           return 1 
        else: 
           return 0 
 
    def __repr__(self) -> str: 
        return f"""{self.position[0]}|{self.position[1]}|{self.position[2]} 
----- 
{self.position[3]}|{self.position[4]}|{self.position[5]} 

Figure 8.2. A 
 decision 
 for a tic-tac-toe game with two moves left. To
maximize the likelihood of winning, the initial player, O, will choose to play O in the
bottom center. Arrows indicate the positions from which a decision is made.
minimax
tree
14 ----- 
{self.position[6]}|{self.position[7]}|{self.position[8]}"""
Listing 8.8. minimax.py
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
from __future__ import annotations 
from board import Piece, Board, Move 
 
# Find the best possible outcome for original player 
def minimax(board: Board, maximizing: bool, original_player: Piece, max_ 
     depth: int = 8) -> float: 
    # Base case – terminal position or maximum depth reached 
    if board.is_win or board.is_draw or max_depth == 0: 
        return board.evaluate(original_player) 
 
    # Recursive case - maximize your gains or minimize the opponent's gains 
    if maximizing: 
        best_eval: float = float("-inf") # arbitrarily low starting point 
        for move in board.legal_moves: 
            result: float = minimax(board.move(move), False, original_player, 
    max_depth - 1) 
            best_eval = max(result, best_eval) 
        return best_eval 

19
20
21
22
23
24
25
    else: # minimizing 
        worst_eval: float = float("inf") 
        for move in board.legal_moves: 
            result = minimax(board.move(move), True, original_player, max_ 
    depth - 1) 
            worst_eval = min(result, worst_eval)  
        return worst_eval
Listing 8.9. minimax.py continued
1
2
3
4
5
6
7
8
9
10
11
12
# Find the best possible move in the current position 
# looking up to max_depth ahead 
def find_best_move(board: Board, max_depth: int = 8) -> Move: 
    best_eval: float = float("-inf") 
    best_move: Move = Move(-1) 
    for move in board.legal_moves: 
        result: float = minimax(board.move(move), False, board.turn, max_ 
     depth) 
        if result > best_eval: 
            best_eval = result 
            best_move = move 
    return best_move
Listing 8.10. tictactoe_tests.py
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
import unittest 
from typing import List 
from minimax import find_best_move 
from tictactoe import TTTPiece, TTTBoard 
from board import Move 
 
 
class TTTMinimaxTestCase(unittest.TestCase): 
    def test_easy_position(self): 
        # win in 1 move 
        to_win_easy_position: List[TTTPiece] = [TTTPiece.X, TTTPiece.O, 
     TTTPiece.X, 
                                                TTTPiece.X, TTTPiece.E, 
     TTTPiece.O, 
                                                TTTPiece.E, TTTPiece.E, 
     TTTPiece.O] 
        test_board1: TTTBoard = TTTBoard(to_win_easy_position, TTTPiece.X) 
        answer1: Move = find_best_move(test_board1) 
        self.assertEqual(answer1, 6) 
 
    def test_block_position(self): 
        # must block O's win 
        to_block_position: List[TTTPiece] = [TTTPiece.X, TTTPiece.E, 
     TTTPiece.E, 
                                             TTTPiece.E, TTTPiece.E, 
     TTTPiece.O, 
                                             TTTPiece.E, TTTPiece.X, 
     TTTPiece.O] 
        test_board2: TTTBoard = TTTBoard(to_block_position, TTTPiece.X) 
        answer2: Move = find_best_move(test_board2) 

31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
        self.assertEqual(answer2, 2) 
 
    def test_hard_position(self): 
        # find the best move to win 2 moves 
        to_win_hard_position: List[TTTPiece] = [TTTPiece.X, TTTPiece.E, 
     TTTPiece.E, 
                                                TTTPiece.E, TTTPiece.E, 
     TTTPiece.O, 
                                                TTTPiece.O, TTTPiece.X, 
     TTTPiece.E] 
        test_board3: TTTBoard = TTTBoard(to_win_hard_position, TTTPiece.X) 
        answer3: Move = find_best_move(test_board3) 
        self.assertEqual(answer3, 1) 
 
 
if __name__ == '__main__': 
    unittest.main()
Listing 8.11. tictactoe_ai.py
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
from minimax import find_best_move 
from tictactoe import TTTBoard 
from board import Move, Board 
 
board: Board = TTTBoard() 
 
 
def get_player_move() -> Move: 
    player_move: Move = Move(-1) 
    while player_move not in board.legal_moves: 
        play: int = int(input("Enter a legal square (0-8):")) 
        player_move = Move(play) 
    return player_move 
 
 
if __name__ == "__main__": 
    # main game loop 
    while True: 
        human_move: Move = get_player_move() 
        board = board.move(human_move) 
        if board.is_win: 
            print("Human wins!") 
            break 
        elif board.is_draw: 
            print("Draw!") 
            break 
        computer_move: Move = find_best_move(board) 
        print(f"Computer move is {computer_move}") 
        board = board.move(computer_move) 
        print(board) 
        if board.is_win: 
            print("Computer wins!") 
            break 
        elif board.is_draw: 
            print("Draw!") 
            break

Listing 8.12. connectfour.py
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
from __future__ import annotations 
from typing import List, Optional, Tuple 
from enum import Enum 
from board import Piece, Board, Move 
 
 
class C4Piece(Piece, Enum): 
    B = "B" 
    R = "R" 
    E = " " # stand-in for empty 
 
    @property 
    def opposite(self) -> C4Piece: 
        if self == C4Piece.B: 
            return C4Piece.R 
        elif self == C4Piece.R: 
            return C4Piece.B 
        else: 
            return C4Piece.E 
    def __str__(self) -> str: 
        return self.value
Listing 8.13. connectfour.py continued
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
def generate_segments(num_columns: int, num_rows: int, segment_length: int) - 
     > List[List[Tuple[int, int]]]: 
    segments: List[List[Tuple[int, int]]] = [] 
    # generate the vertical segments 
    for c in range(num_columns): 
        for r in range(num_rows - segment_length + 1): 
            segment: List[Tuple[int, int]] = [] 
            for t in range(segment_length): 
                segment.append((c, r + t)) 
            segments.append(segment) 
 
    # generate the horizontal segments 
    for c in range(num_columns - segment_length + 1): 
        for r in range(num_rows): 
            segment = [] 
            for t in range(segment_length): 
                segment.append((c + t, r)) 
            segments.append(segment) 
 
    # generate the bottom left to top right diagonal segments 
    for c in range(num_columns - segment_length + 1): 
        for r in range(num_rows - segment_length + 1): 
            segment = [] 
            for t in range(segment_length): 
                segment.append((c + t, r + t)) 
            segments.append(segment) 
 
    # generate the top left to bottom right diagonal segments 
    for c in range(num_columns - segment_length + 1): 
        for r in range(segment_length - 1, num_rows): 
            segment = [] 
            for t in range(segment_length): 
                segment.append((c + t, r - t)) 
            segments.append(segment) 
    return segments

Listing 8.14. connectfour.py continued
1
2
3
4
5
6
class C4Board(Board): 
    NUM_ROWS: int = 6 
    NUM_COLUMNS: int = 7 
    SEGMENT_LENGTH: int = 4 
    SEGMENTS: List[List[Tuple[int, int]]] = generate_segments(NUM_COLUMNS, 
     NUM_ROWS, SEGMENT_LENGTH)
Listing 8.15. connectfour.py continued
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
class Column: 
    def __init__(self) -> None: 
        self._container: List[C4Piece] = [] 
 
    @property 
    def full(self) -> bool: 
        return len(self._container) == C4Board.NUM_ROWS 
 
    def push(self, item: C4Piece) -> None: 
        if self.full: 
            raise OverflowError("Trying to push piece to full column") 
        self._container.append(item) 
 
    def __getitem__(self, index: int) -> C4Piece: 
        if index > len(self._container) - 1: 
            return C4Piece.E 
        return self._container[index] 
 
    def __repr__(self) -> str: 
        return repr(self._container) 
 
    def copy(self) -> C4Board.Column: 
        temp: C4Board.Column = C4Board.Column() 
        temp._container = self._container.copy() 
        return temp
Listing 8.16. connectfour.py continued
1
2
3
4
5
6
7
def __init__(self, position: Optional[List[C4Board.Column]] = None, turn: 
     C4Piece = C4Piece.B) -> None: 
    if position is None: 
        self.position: List[C4Board.Column] = [C4Board.Column() for _ in 
     range(C4Board.NUM_COLUMNS)] 
    else: 
        self.position = position 

8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
    self._turn: C4Piece = turn 
 
@property 
def turn(self) -> Piece: 
    return self._turn 
 
def move(self, location: Move) -> Board: 
    temp_position: List[C4Board.Column] = self.position.copy() 
    for c in range(C4Board.NUM_COLUMNS): 
        temp_position[c] = self.position[c].copy() 
    temp_position[location].push(self._turn) 
    return C4Board(temp_position, self._turn.opposite) 
 
@property 
def legal_moves(self) -> List[Move]: 
    return [Move(c) for c in range(C4Board.NUM_COLUMNS) if not 
     self.position[c].full]
Listing 8.17. connectfour.py continued
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
# Returns the count of black and red pieces in a segment 
def _count_segment(self, segment: List[Tuple[int, int]]) -> Tuple[int, int]: 
    black_count: int = 0 
    red_count: int = 0 
    for column, row in segment: 
        if self.position[column][row] == C4Piece.B: 
            black_count += 1 
        elif self.position[column][row] == C4Piece.R: 
            red_count += 1 
    return black_count, red_count 
 
@property 
def is_win(self) -> bool: 
    for segment in C4Board.SEGMENTS: 
        black_count, red_count = self._count_segment(segment) 
        if black_count == 4 or red_count == 4: 
            return True 
    return False
Listing 8.18. connectfour.py continued
1
2
3
4
5
6
7
8
9
10
11
12
13
14
def _evaluate_segment(self, segment: List[Tuple[int, int]], player: Piece) -> 
     float: 
    black_count, red_count = self._count_segment(segment) 
    if red_count > 0 and black_count > 0: 
        return 0 # mixed segments are neutral 
    count: int = max(red_count, black_count) 
    score: float = 0 
    if count == 2: 
        score = 1 
    elif count == 3: 
        score = 100 
    elif count == 4: 
        score = 1000000 
    color: C4Piece = C4Piece.B 

15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
    if red_count > black_count: 
        color = C4Piece.R 
    if color != player: 
        return -score 
    return score 
 
def evaluate(self, player: Piece) -> float: 
    total: float = 0 
    for segment in C4Board.SEGMENTS: 
        total += self._evaluate_segment(segment, player) 
    return total 
 
def __repr__(self) -> str: 
    display: str = "" 
    for r in reversed(range(C4Board.NUM_ROWS)): 
        display += "|" 
        for c in range(C4Board.NUM_COLUMNS): 
            display += f"{self.position[c][r]}" + "|" 
        display += "\n" 
    return display
Listing 8.19. connectfour_ai.py
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
from minimax import find_best_move 
from connectfour import C4Board 
from board import Move, Board 
 
board: Board = C4Board() 
 
def get_player_move() -> Move: 
    player_move: Move = Move(-1) 
    while player_move not in board.legal_moves: 
        play: int = int(input("Enter a legal column (0-6):")) 
        player_move = Move(play) 
    return player_move 
 
 
if __name__ == "__main__": 
    # main game loop 
    while True: 
        human_move: Move = get_player_move() 
        board = board.move(human_move) 
        if board.is_win: 
            print("Human wins!") 
            break 
        elif board.is_draw: 
            print("Draw!") 
            break 
        computer_move: Move = find_best_move(board, 3) 
        print(f"Computer move is {computer_move}") 
        board = board.move(computer_move) 
        print(board) 
        if board.is_win: 
            print("Computer wins!") 
            break 
        elif board.is_draw: 
            print("Draw!") 
            break

Listing 8.20. minimax.py continued
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
def alphabeta(board: Board, maximizing: bool, original_player: Piece, max_ 
     depth: int = 8, alpha: float = float("-inf"), beta: float = 
     float("inf")) -> float: 
    # Base case – terminal position or maximum depth reached 
    if board.is_win or board.is_draw or max_depth == 0: 
        return board.evaluate(original_player) 
 
    # Recursive case - maximize your gains or minimize the opponent's gains 
    if maximizing: 
        for move in board.legal_moves: 
            result: float = alphabeta(board.move(move), False, original_ 
     player, max_depth - 1, alpha, beta) 
            alpha = max(result, alpha) 
            if beta <= alpha: 
                break 
        return alpha 
    else:  # minimizing 
        for move in board.legal_moves: 
            result = alphabeta(board.move(move), True, original_player, max_ 
     depth - 1, alpha, beta) 
            beta = min(result, beta) 
            if beta <= alpha: 
                break 
        return beta

CHAPTER 9
Figure 9.1. The burgler must decide what items to steal because the capacity of the
knapsack is limited.
Listing 9.1. knapsack.py
1
2
3
4
5
6
from typing import NamedTuple, List 
 
class Item(NamedTuple): 
    name: str 
    weight: int 
    value: float
Listing 9.2. knapsack.py continued
1
2
3
4
5
6
7
8
9
10
11
12
def knapsack(items: List[Item], max_capacity: int) -> List[Item]: 
    # build up dynamic programming table 
    table: List[List[float]] = [[0.0 for _ in range(max_capacity + 1)] for _ 
     in range(len(items) + 1)] 
    for i, item in enumerate(items): 
        for capacity in range(1, max_capacity + 1): 
            previous_items_value: float = table[i][capacity] 
            if capacity >= item.weight: # item fits in knapsack 
                value_freeing_weight_for_item: float = table[i][capacity - 
     item.weight] 
                # only take if more valuable than previous item 
                table[i + 1][capacity] = max(value_freeing_weight_for_item + 

13
14
15
16
17
18
19
20
21
22
23
24
25
     item.value, previous_items_value) 
            else: # no room for this item 
                table[i + 1][capacity] = previous_items_value 
    # figure out solution from table 
    solution: List[Item] = [] 
    capacity = max_capacity 
    for i in range(len(items), 0, -1): # work backwards 
        # was this item used? 
        if table[i - 1][capacity] != table[i][capacity]: 
            solution.append(items[i - 1]) 
            # if the item was used, remove its weight 
            capacity -= items[i - 1].weight 
    return solution
Listing 9.3. knapsack.py continued
1
2
3
4
5
6
7
8
9
10
11
12
13
if __name__ == "__main__": 
    items: List[Item] = [Item("television", 50, 500), 
                         Item("candlesticks", 2, 300), 
                         Item("stereo", 35, 400), 
                         Item("laptop", 3, 1000), 
                         Item("food", 15, 50), 
                         Item("clothing", 20, 800), 
                         Item("jewelry", 1, 4000), 
                         Item("books", 100, 300), 
                         Item("printer", 18, 30), 
                         Item("refrigerator", 200, 700), 
                         Item("painting", 10, 1000)] 
    print(knapsack(items, 75))
1
2
3
4
[Item(name='painting', weight=10, value=1000), Item(name='jewelry', weight=1, 
     value=4000), Item(name='clothing', weight=20, value=800), 
     Item(name='laptop', weight=3, value=1000), Item(name='stereo', 
     weight=35, value=400), Item(name='candlesticks', weight=2, value=300)]
1
2
for i, item in enumerate(items): 
    for capacity in range(1, max_capacity + 1):
1
2
previous_items_value: float = table[i][capacity] 
if capacity >= item.weight: # item fits in knapsack

Table 9.1. An example of a knapsack problem of three items (view table Øgure)
0 lb.
1 lb.
2 lb.
3 lb.
Matches (1 lb., $5)
0
5
5
5
Flashlight (2 lbs.,
$10)
0
5
10
15
Book (1 lb., $15)
0
15
20
25
1
2
else: # no room for this item 
    table[i + 1][capacity] = previous_items_value
1
2
3
4
value_freeing_weight_for_item: float = table[i][capacity - item.weight] 
# only take if more valuable than previous item 
table[i + 1][capacity] = max(value_freeing_weight_for_item + item.value, 
     previous_items_value)
1
2
3
for i in range(len(items), 0, -1): # work backwards 
    # was this item used? 
    if table[i - 1][capacity] != table[i][capacity]:
1
2
3
solution.append(items[i - 1]) 
# if the item was used, remove its weight 
capacity -= items[i - 1].weight

Figure 9.2. Five cities in Vermont and the driving distances between them

Table 9.2. Driving distances between cities in Vermont (view table Øgure)
 
Rutland
Burlington
White River
Junction
Bennington
Brattleboro
Rutland
0
67
46
55
75
Burlington
67
0
91
122
153
White River
Junction
46
91
0
98
65
Bennington
55
122
98
0
40
Brattleboro
75
153
65
40
0
Listing 9.4. tsp.py
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
from typing import Dict, List, Iterable, Tuple 
from itertools import permutations 
 
vt_distances: Dict[str, Dict[str, int]] = { 
    "Rutland": 
        {"Burlington": 67, 
         "White River Junction": 46, 
         "Bennington": 55, 
         "Brattleboro": 75}, 
    "Burlington": 
        {"Rutland": 67, 
         "White River Junction": 91, 
         "Bennington": 122, 
         "Brattleboro": 153}, 
    "White River Junction": 
        {"Rutland": 46, 
         "Burlington": 91, 
         "Bennington": 98, 
         "Brattleboro": 65}, 
    "Bennington": 
        {"Rutland": 55, 
         "Burlington": 122, 
         "White River Junction": 98, 
         "Brattleboro": 40}, 
    "Brattleboro": 
        {"Rutland": 75, 
         "Burlington": 153, 
         "White River Junction": 65, 
         "Bennington": 40} 
}
Listing 9.5. tsp.py continued
1
2
vt_cities: Iterable[str] = vt_distances.keys() 
city_permutations: Iterable[Tuple[str, ...]] = permutations(vt_cities)

Figure 9.3. The shortest path for the salesman to visit all Øve cities in Vermont is
illustrated.
Listing 9.6. tsp.py continued
1 tsp_paths: List[Tuple[str, ...]] = [c + (c[0],) for c in city_permutations]
Listing 9.7. tsp.py continued
1
2
3
4
5
6
7
8
9
10
11
12
13
if __name__ == "__main__": 
    best_path: Tuple[str, ...] 
    min_distance: int = 99999999999 # arbitrarily high number 
    for path in tsp_paths: 
        distance: int = 0 
        last: str = path[0] 
        for next in path[1:]: 
            distance += vt_distances[last][next] 
            last = next 
        if distance < min_distance: 
            min_distance = distance 
            best_path = path 
    print(f"The shortest path is {best_path} in {min_distance} miles.")
1
2
The shortest path is ('Rutland', 'Burlington', 'White River Junction', 
     'Brattleboro', 'Bennington', 'Rutland') in 318 miles.


Figure 9.4. The Phone app in iOS retains the letters on keys that its telephone forebears
contained.
Listing 9.8. tsp.py continued
1
2
3
4
5
6
7
8
9
10
11
12
13
from typing import Dict, Tuple, Iterable, List 
from itertools import product 
 
phone_mapping: Dict[str, Tuple[str, ...]] = {"1": ("1",), 
                                             "2": ("a", "b", "c"), 
                                             "3": ("d", "e", "f"), 
                                             "4": ("g", "h", "i"), 
                                             "5": ("j", "k", "l"), 
                                             "6": ("m", "n", "o"), 
                                             "7": ("p", "q", "r", "s"), 
                                             "8": ("t", "u", "v"), 
                                             "9": ("w", "x", "y", "z"), 
                                             "0": ("0",)}

Listing 9.9. tsp.py continued
1
2
3
4
5
def possible_mnemonics(phone_number: str) -> Iterable[Tuple[str, ...]]: 
    letter_tuples: List[Tuple[str, ...]] = [] 
    for digit in phone_number: 
        letter_tuples.append(phone_mapping.get(digit, (digit,))) 
    return product(*letter_tuples)
Listing 9.10. tsp.py continued
1
2
3
4
5
if __name__ == "__main__": 
    phone_number: str = input("Enter a phone number:") 
    print("Here are the potential mnemonics:") 
for mnemonic in possible_mnemonics(phone_number): 
    print("".join(mnemonic))

