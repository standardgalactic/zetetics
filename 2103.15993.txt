Cahier du GERAD G-2021-12
A PROXIMAL QUASI-NEWTON TRUST-REGION METHOD FOR
NONSMOOTH REGULARIZED OPTIMIZATION∗
ALEKSANDR Y. ARAVKIN†, ROBERT BARALDI‡, AND DOMINIQUE ORBAN§
Abstract. We develop a trust-region method for minimizing the sum of a smooth term f and
a nonsmooth term h, both of which can be nonconvex. Each iteration of our method minimizes a
possibly nonconvex model of f + h in a trust region. The model coincides with f + h in value and
subdiﬀerential at the center. We establish global convergence to a ﬁrst-order stationary point when f
satisﬁes a smoothness condition that holds, in particular, when it has Lipschitz-continuous gradient,
and h is proper and lower semi-continuous. The model of h is required to be proper, lower-semi-
continuous and prox-bounded. Under these weak assumptions, we establish a worst-case O(1/ϵ2)
iteration complexity bound that matches the best known complexity bound of standard trust-region
methods for smooth optimization. We detail a special instance in which we use a limited-memory
quasi-Newton model of f and compute a step with the proximal gradient method, resulting in a
practical proximal quasi-Newton method. We establish similar convergence properties and complexity
bound for a quadratic regularization variant, and provide an interpretation as a proximal gradient
method with adaptive step size for nonconvex problems. We describe our Julia implementations
and report numerical results on inverse problems from sparse optimization and signal processing.
Our trust-region algorithm exhibits promising performance and compares favorably with linesearch
proximal quasi-Newton methods based on convex models.
Key words. Nonsmooth optimization, nonconvex optimization, composite optimization, trust-
region methods, quasi-Newton methods, proximal gradient method, proximal quasi-Newton method.
AMS subject classiﬁcations. 49J52, 65K10, 90C53, 90C56
1. Introduction. We consider the problem class
(1.1)
minimize
x
f(x) + h(x),
where f : Rn →R is continuously diﬀerentiable, h : Rn →R ∪{+∞} is proper
and lower semi-continuous, and both may be nonconvex. Smooth and nonsmooth
optimization problems are special cases corresponding to h := 0 and f := 0, respectively.
Certain authors [10, 26] refer to (1.1) as a composite problem. We use instead the term
nonsmooth regularized to diﬀerentiate with problems where f = 0 and h(x) = g(c(x)),
where g is nonsmooth and c is smooth, which is indeed the composition of two functions.
In practice, h is often a regularizer designed to promote desirable properties in solutions,
∗Disclaimer: This report was prepared as an account of work sponsored by an agency of the United
States Government. Neither the United States Government nor any agency thereof, nor any of their
employees, makes any warranty, express or implied, or assumes any legal liability or responsibility for
the accuracy, completeness, or usefulness of any information, apparatus, product, or process disclosed,
or represents that its use would not infringe privately owned rights. Reference herein to any speciﬁc
commercial product, process, or service by trade name, trademark, manufacturer, or otherwise does
not necessarily constitute or imply its endorsement, recommendation, or favoring by the United
States Government or any agency thereof. The views and opinions of authors expressed herein do not
necessarily state or reﬂect those of the United States Government or any agency thereof.
†Department of Applied Mathematics, University of Washington, Seattle WA., USA. E-mail:
saravkin@uw.edu. Research partially supported by the Washington Research Foundation.
‡Department of Applied Mathematics, University of Washington, Seattle WA., USA. E-mail:
rbaraldi@uw.edu.
This material is based upon work supported by the U.S. Department of En-
ergy, Oﬃce of Science, Oﬃce of Advanced Scientiﬁc Computing Research, Department of Energy
Computational Science Graduate Fellowship under Award Number DE-FG02-97ER25308.
§GERAD and Department of Mathematics and Industrial Engineering, Polytechnique Montr´eal,
QC, Canada. E-mail: dominique.orban@gerad.ca. Research partially supported by an NSERC
Discovery Grant.
1
Commit bd54cde by Robert Baraldi on 2021-04-02 10:15:10 -0700
arXiv:2103.15993v2  [math.OC]  2 Apr 2021

2
[toc]
such as sparsity. The class (1.1) captures the natural structure of a wide range of
problems; problems with simple constraints, exact penalty formulations, basis selection
problems with both convex [43, 44] and nonconvex [3, 7, 49] regularization, and more
general inverse and learning problems [1, 8, 11].
We describe a trust-region method for (1.1) in which steps are computed by
approximately minimizing simpler nonsmooth iteration-dependent models inside a
trust region deﬁned by an arbitrary norm. In practice, the norm is chosen based on
the nonsmooth term in the model and the tractability of the step-ﬁnding subproblem,
which is not required to be convex. Our analysis hinges on the observation that
in the nonsmooth context, the ﬁrst step of the proximal gradient method is the
right generalization of the gradient step in smooth optimization. We establish global
convergence in terms of an optimality measure describing the decrease achievable in
the model by a single step of the proximal gradient method inside the trust-region.
We also establish a worst-case complexity bound of O(1/ϵ2) iterations to bring this
optimality measure below a tolerance 0 < ϵ < 1. Others [10, 22] have observed that it
is possible to devise trust-region methods for regularized optimization with complexity
equivalent to that for smooth optimization. However, past research typically assumes
that h is either globally Lipschitz continuous and/or convex.
We also revisit a quadratic regularization method, and establish similar conver-
gence properties and same worst-case compexity under the same assumptions. Our
description highlights the connection between the quadratic regularization method and
the standard proximal gradient method. The former may be seen as an implementation
of the latter with adaptive step size.
We provide implementation details and illustrate the performance of an instance
where the trust-region model is the sum of a limited-memory quasi-Newton, pos-
sibly nonconvex, approximation of f with a nonsmooth model of h and various
choices of the trust-region norm. Our trust-region algorithm exhibits promising per-
formance and compares favorably with linesearch proximal quasi-Newton methods
based on convex models [41, 42]. Our open source implementations are available from
github.com/UW-AMO/TRNC as packages in the emerging Julia programing language [6].
As far as we can tell from the literature, the method described in the present
paper is the ﬁrst trust-region method for the fully nonconvex nonsmooth regularized
problem. Our approach oﬀers ﬂexibility in the choice of the norm used to deﬁne the
trust-region, provided an eﬃcient procedure is known to solve the subproblem. We
show that such procedures are easily obtained in a number of applied scenarios.
Related research. We focus on (1.1) and do not provide an extensive review of
approaches for smooth optimization. Conn et al. [13] cover trust-region methods for
smooth optimization thoroughly, as well as a number of select generalizations, and we
refer the reader to their comprehensive treatment for background.
Yuan [46] formulates conditions for convergence of trust-region methods for convex-
composite objectives, i.e., g(c(x)) where c is continuously diﬀerentiable and g is convex.
In particular, he considers models of the form s 7→g(c(x) + ∇c(x)s), that are relevant
to exact penalty methods for constrained optimization, and that are a special case of
the models we consider.
Dennis et al. [16] develop convergence properties of trust-region methods for
the case where f = 0 and h is Lipschitz continuous. Their analysis is based on a
generalization of the concept of Cauchy point in terms of Clarke directional derivatives,
but they do not provide an approach to solve the typically nonsmooth subproblem.
Kim et al. [25] analyze a trust-region method for (1.1) when f is convex and h is
Commit bd54cde by Robert Baraldi on 2021-04-02 10:15:10 -0700
Cahier du GERAD G-2021-12

[toc]
3
continuous and convex with assumptions based on those of Dennis et al. [16]. Their
model around a current x has the form f(x) + ∇f(x)T s + 1
2α∥s∥2 + h(x + s), where α
is a Barzilai-Borwein step length safeguarded to stay suﬃciently positive and bounded.
By contrast, our approach allows general quadratic models, possibly indeﬁnite, and
explicitly accounts for the trust-region constraint in the subproblem by devising
specialized proximal operators.
Qi and Sun [37] propose a trust-region method inspired by that of Dennis et al.
[16] for the case where f = 0 and h is locally Lipschitz continuous with bounded
level sets. They establish convergence under the further assumption that the models
are [0, 1]-subhomogeneous. Mart´ınez and Moretti [31] employ similar assumptions to
generalize the approach to problems with linear constraints.
Cartis et al. [10] consider (1.1) where h is convex and globally Lipschitz continuous.
They analyze both a trust-region algorithm and a quadratic regularization variant,
develop convergence and iteration complexity results, but do not provide guidance
on how to compute steps in practice. Their analysis revolves around properties of a
stationarity measure that are strongly anchored to the convexity assumption. The
algorithms that we develop below are most similar to theirs but rest upon signiﬁcantly
weaker assumptions and concrete subproblem solvers. Grapiglia et al. [22] detail a
uniﬁed convergence theory for smooth optimization that has trust-region methods as
a special case. They also generalize the results of [10] but focus on objectives of the
form f(x) + g(c(x)) where f and c are smooth and g is convex and globally Lipschitz.
Lee et al. [26] fully explore the global and fast local convergence properties of exact
and inexact proximal Newton and quasi-Newton methods for the case where both f
and h are convex. They show that those methods inherit all the desired properties of
their counterparts in smooth optimization.
Bolte et al. [8] present a proximal alternating method for objectives of the form
g(x) + Q(x, y) + h(y) where g and h are proper and lower semi-continuous and the
coupling function Q is continuously diﬀerentiable. Their setting has (1.1) as a special
case. They establish convergence under the Kurdyka- Lojasiewicz assumption and
provide a general recipe for algorithmic convergence under such an assumption.
Li and Lin [27] consider monotone and non-monotone accelerations of the proximal
gradient method for possibly nonconvex f and h. They establish global convergence
under the assumptions that f has a Lipschitz continuous gradient, h is proper and
lower semi-continuous, and that f + h is coercive. This leads to a sublinear iteration
complexity bound when a Kurdyka- Lojasiewicz condition holds. Bot¸ et al. [9] employ
an inertial acceleration strategy which converges under the assumptions that h is
bounded below and possesses a Kurdyka- Lojasiewicz condition.
Stella et al. [41] initially devised PANOC, a linesearch quasi-Newton method
for (1.1) with limited-memory BFGS Hessian approximations, for model predictive
control. PANOC assumes that the objective has the form f(x)+h1(x)+h2(c(x)), where
f and c are smooth, h1 is nonsmooth and may be nonconvex, and h2 is nonsmooth
and convex. Themelis et al. [42] develop ZeroFPR, a nonmonotone linesearch proximal
quasi-Newton method for (1.1) based on the concept of forward-backward envelope.
ZeroFPR converges under a Kurdyka- Lojasiewicz assumption and enjoys the fast local
convergence properties of quasi-Newton methods for smooth optimization when a
Dennis-Mor´e condition holds.
Notation. Sets are represented by calligraphic letters. The cardinality of set S
is represented by |S|. We use ∥· ∥to denote a generic norm on Rn. The symbols ν,
λ, σ and ∆are scalars. B(0, ∆) is the ball centered at 0 with radius ∆> 0 deﬁned
Cahier du GERAD G-2021-12
Commit bd54cde by Robert Baraldi on 2021-04-02 10:15:10 -0700

4
[toc]
by a norm that should be clear from the context. We use the shorthands B = B(0, 1)
and ∆B = B(0, ∆). When necessary, we write Bp to indicate that the ℓp-norm is
used. Functional symbols f, g, h, as well as φ, ϕ and ψ are used for functions. χ(·; A)
represents the indicator function of A ⊆Rn. In particular, the indicator of B(0, ∆) is
denoted χ(·; ∆B) or just χ(·; ∆) when the norm is clear from the context. We use the
alternative notation χ(·; ∆Bp) to emphasize that the ℓp-norm is used to deﬁne the ball.
If A ⊆Rn is closed and convex, projA(x) denotes the projection of x into A. Finally,
j and k are iteration counters.
Roadmap. The paper proceeds as follows. In section 2, we gather preliminary
concepts for trust-region methods and variational analysis used in the theory. section 3
develops the general trust-region method for (1.1), including the new Algorithm 3.1,
and introduces several innovations that yield the main results.
In section 4, we
explain how to compute a trust-region step based on a proximal quasi-Newton model.
New relevant proximal operators needed to implement the trust-region method are
studied in section 5. A quadratic regularization variant of the trust-region algorithm
together with its convergence analysis are presented in section 6. Numerical results
and experiments are in section 7. We end with a brief discussion in section 8.
2. Preliminaries.
2.1. Smooth context. When f ∈C1 and h = 0 in (1.1), trust-region methods
are known for strong convergence properties and favorable numerical performance on
both small and large-scale problems. At an iterate xk, they compute a step sk as an
approximate solution of
minimize
s
mk(s; xk)
subject to ∥s∥≤∆k,
where mk(·; xk) is a model of f about xk, ∥·∥is a norm and ∆k > 0 is the trust-region
radius. The predicted decrease mk(0; xk) −mk(sk; xk) is compared to the actual
decrease (f + h)(xk) −(f + h)(xk + sk) to decide whether sk should be accepted or
rejected. If sk is accepted, the iteration is successful; otherwise it is unsuccessful.
Typically, mk(·; xk) is a quadratic expansion of f about xk and the Euclidean norm is
used in the trust region. The Euclidean norm is favored because eﬃcient numerical
schemes are known for the quadratic subproblem, which can be solved either exactly
by way of the method of Mor´e and Sorensen [32] or approximately by way of the
truncated conjugate gradient method of Steihaug [40]. See [13] for more information.
2.2. Nonsmooth context. We denote R = R ∪{±∞}. We call h : Rn →R
proper if h(x) > −∞for all x and h(x) < ∞for at least one x, and lower semi-
continuous, or lsc, at ¯x if lim infx→¯x h(x) = h(¯x). We say that h is (lower-)level
bounded if all its level sets are bounded. If h is proper, lsc and level bounded, then
arg min h is nonempty and compact [39, Theorem 1.9].
Definition 2.1. For a proper lsc function h : Rn →R and a parameter ν > 0,
the Moreau envelope eνh and the proximal mapping proxνh are deﬁned by
eνh(x) := inf
w
1
2ν−1∥w −x∥2 + h(w) = ν−1 inf
w
1
2∥w −x∥2 + νh(w),
(2.1a)
prox
νh
(x) := arg min
w
1
2ν−1∥w −x∥2 + h(w) = arg min
w
1
2∥w −x∥2 + νh(w).
(2.1b)
Under certain assumptions, including strong convexity of the objective of (2.1b), the
set proxνh(x) is a singleton. However, in general, the set-valued mapping proxνh may
Commit bd54cde by Robert Baraldi on 2021-04-02 10:15:10 -0700
Cahier du GERAD G-2021-12

[toc]
5
assume empty values or values that contain multiple elements. For a given h, the
range of parameter values for which the Moreau envelope assumes a ﬁnite value is
given by the following deﬁnition.
Definition 2.2. The proper lsc function h : Rn →R is prox-bounded if there
exists ν > 0 and at least one x ∈Rn such that eνh(x) > −∞. The threshold of
prox-boundedness νh of h is the supremum of all such ν > 0.
If h is level bounded, then so is w 7→1
2ν−1∥w −x∥2 + h(w) for all x ∈Rn and
all ν > 0, so eνh(x) > −∞[39, Theorem 1.9] and h is prox-bounded. The following
result summarizes some properties of (2.1a)–(2.1b). Further properties appear in [39,
Theorem 1.25].
Proposition 2.3. Let h : Rn →R be proper lsc and prox-bounded with threshold
νh > 0. For every ν ∈(0, νh) and all x ∈Rn,
1. proxνh(x) is nonempty and compact;
2. eνh(x) depends continuously on (ν, x) and eνh(x) ↗h(x) as ν ↘0.
2.3. Optimality conditions. We use the following notions of subgradient and
subdiﬀerential [39, Deﬁnition 8.3].
Definition 2.4 (Limiting subdiﬀerential). Consider φ : Rn →R and ¯x ∈Rn
with φ(¯x) < ∞. We say that v ∈Rn is a regular subgradient of φ at ¯x, and we write
v ∈ˆ∂φ(¯x) if
lim inf
x→¯x
φ(x) −φ(¯x) −vT (x −¯x)
∥x −¯x∥
≥0.
The set of regular subgradients is also called the Fr´echet subdiﬀerential. We say that
v is a general subgradient of φ at ¯x, and we write v ∈∂φ(¯x), if there are sequences
{xk} and {vk} such that xk →¯x, φ(xk) →φ(¯x), vk ∈ˆ∂φ(xk) and vk →v. The set of
general subgradients is called the limiting subdiﬀerential.
If φ is convex, the Fr´echet and limiting subdiﬀerentials coincide with the subdif-
ferential of convex analysis. If φ is diﬀerentiable at x, ˆ∂φ(x) = ∂φ(x) = {∇φ(x)}.
In the following, we do not make use of the precise deﬁnition of the relevant
subdiﬀerential, but merely rely on the following criticality property.
Proposition 2.5 (39, Theorem 10.1).
If φ : Rn →R is proper and has a local
minimum at ¯x, then 0 ∈ˆ∂φ(¯x) ⊆∂φ(¯x). If φ is convex, the latter condition is also
suﬃcient for ¯x to be a global minimum. If φ = f + h where f is diﬀerentiable on a
neighborhood of ¯x and h is ﬁnite at ¯x, then ∂φ(¯x) = ∇f(¯x) + ∂h(¯x).
2.4. The proximal gradient method. Consider the generic nonsmooth regu-
larized problem
(2.2)
minimize
s
ϕ(s) + ψ(s),
where ϕ is continuously diﬀerentiable and ψ is proper, lower semi-continuous and
prox-bounded. The notation ϕ and ψ is intentionally diﬀerent from (1.1) and will be
reused to denote models of f and h in section 3.
A natural method to solve (2.2) that generalizes the gradient method of smooth
optimization is the proximal gradient method [4, 28]. When initialized from s0 ∈Rn
where ψ is ﬁnite, it generates iterates according to
(2.3)
sj+1 ∈prox
νψ
(sj −ν∇ϕ(sj)),
j ≥0,
Cahier du GERAD G-2021-12
Commit bd54cde by Robert Baraldi on 2021-04-02 10:15:10 -0700

6
[toc]
where ν > 0 is a step size. If ψ is the indicator of a closed convex set, the proximal
gradient method reduces to the projected gradient method.
The ﬁrst-order optimality conditions of (2.3) are
(2.4)
0 ∈sj+1 −sj + ν∇ϕ(sj) + ν∂ψ(sj+1).
The proximal literature primarily focuses on the generalized gradient
(2.5)
Gν(s) := ν−1(s −prox
νψ
(s −ν∇ϕ(s))),
with Gν(0) = ∇ϕ(0) in the case of smooth optimization. The following result gives
conditions under which the proximal gradient method is monotonic.
Proposition 2.6 (8, Lemma 2).
Let ϕ be continuously diﬀerentiable, ∇ϕ be
Lipschitz continuous with constant L > 0 and ψ be proper, lsc and bounded below. For
any 0 < ν < 1/L, any s0 where ψ is ﬁnite, the iteration (2.3) is such that
(ϕ + ψ)(sj+1) ≤(ϕ + ψ)(sj) −1
2(ν−1 −L)∥sj+1 −sj∥2,
j ≥0.
It is possible to remove the assumption that ψ is bounded below from Proposi-
tion 2.6 and replace it with the weaker assumption that ψ is prox-bounded and that ν
is chosen smaller than the threshold of prox-boundedness of ψ.
In the smooth case, where ψ = 0, we have s1 = −ν∇ϕ(s0) and the decrease is
(2.6)
ϕ(s1; x) ≤ϕ(s0) −1
2ν2(ν−1 −L)∥∇ϕ(s0)∥2.
3. Trust-region methods for nonsmooth regularized optimization. In
this section, we develop and analyze a general trust-region method for (1.1). Section 3.1
examines properties of trust-region subproblems. Section 3.2 discusses optimality
measures, and highlights the role of the prox-gradient step in quantifying descent in
the general context of (1.1). Section 2.4 reviews key results for the prox-gradient
method for nonconvex models. In Section 3.3, we present the trust-region approach,
and highlight key innovations that make it possible to obtain the convergence results
and complexity analysis presented in Section 3.4.
3.1. Properties of trust-region subproblems. For ﬁxed x ∈Rn, consider
the parametric problem and its optimal set
p(∆; x) := minimize
s
ϕ(s; x) + ψ(s; x) + χ(s; ∆),
(3.1a)
P(∆; x) := arg min
s
ϕ(s; x) + ψ(s; x) + χ(s; ∆),
(3.1b)
where ϕ(s; x) ≈f(x + s), ψ(s; x) ≈h(x + s), χ(s; ∆) is the indicator function of the
trust region ∆B and ∆> 0. The form of (3.1) is representative of a trust-region
subproblem for (1.1) in which f and h are modeled separately and the trust-region
constraint appears implicitly via an indicator function. By Proposition 2.5,
s ∈P(∆; x)
=⇒
0 ∈∇ϕ(s; x) + ∂(ψ(·; x) + χ(·; ∆))(s).
We make the following additional assumption.
Model Assumption 3.1. For any x ∈Rn, ϕ(·; x) is continuously diﬀerentiable,
ψ(·; x) is proper and lsc.
Commit bd54cde by Robert Baraldi on 2021-04-02 10:15:10 -0700
Cahier du GERAD G-2021-12

[toc]
7
The following result summarizes properties of (3.1).
Proposition 3.1. Let Model Assumption 3.1 be satisﬁed. If we deﬁne p(0; x) :=
ϕ(0; x) + ψ(0; x) and P(0; x) = {0}, the domain of p(·; x) and P(·; x) is {∆| ∆≥0}.
In addition,
1. p(·; x) is proper lsc and for each ∆≥0, P(∆; x) is nonempty and compact;
2. if {∆k} →¯∆≥0 in such a way that {p(∆k; x)} →p( ¯∆; x), and for each k,
sk ∈P(∆k; x), then {sk} is bounded and all its limit points are in P( ¯∆; x);
3. if ϕ(·; x) + ψ(·; x) is strictly convex, P(∆; x) is single-valued;
4. if ¯∆> 0 and there exists ¯s ∈P( ¯∆; x) such that ∥¯s∥< ¯∆, then p(·; x) is
continuous at ¯∆and {p(∆k; x)} →p( ¯∆; x) holds in part 2.
Proof. Model Assumption 3.1 and compactness of the trust region ensure that
the objective of (3.1a) is always level-bounded in s locally uniformly in ∆[39, Deﬁni-
tion 1.16] because for any ¯∆> 0 and ϵ > 0, and for any ∆∈( ¯∆−ϵ, ¯∆+ϵ) with ∆≥0,
the level sets of ϕ(·; x) + ψ(·; x) + χ(·; ∆) are contained in ∆B ⊆( ¯∆+ ϵ)B. Parts 1–2
follow by Rockafellar and Wets [39], Theorems 1.17 and 7.41. Part 3 follows from
Rockafellar and Wets [39, Exercice 7.45]. Part 4 follows by noting that if ∥¯s∥< ¯∆,
then ϕ(¯s; x) + ψ(¯s; x) + χ(¯s; ∆) is continuous in ∆in a neighborhood of ¯∆; the rest
follows from Rockafellar and Wets [39, Theorem 1.17c].
It is not necessary to assume that ψ(·; x) is prox-bounded in Model Assumption 3.1
because under the assumptions stated and compactness of the trust region, the objective
of (3.1a) is necessarily bounded below, and therefore prox-bounded. Proposition 3.1
allows us to think of how approximate solutions “truncated” by a trust-region constraint
approach ¯s as the trust-region radius increases. Indeed, we may choose any ¯∆> ∥¯s∥in
parts 2 and 4. When ψ(·; x) = 0 and ϕ(·; x) is quadratic and strictly convex, the graph
of P(·; x) is known to be a smooth curve such that P(0; x) = {xk}, that is tangential
to −∇f(xk) at ∆= 0 and such that lim∆→∞P(∆; x) contains the Newton step as its
only element. This observation gives rise to several numerical methods to approximate
the solution of (3.1), including the dogleg [36] and double dogleg methods [17].
3.2. Optimality measures. In this section, we seek a convenient way of as-
sessing whether a given x is ﬁrst-order critical for (1.1) based on the trust-region
subproblem (3.1). We begin with the following result.
Proposition 3.2. Let Model Assumption 3.1 be satisﬁed. Assume in addition
that ∇sϕ(0; x) = ∇f(x), ∂ψ(0; x) = ∂h(x), and let ∆> 0. Then, x is ﬁrst-order
stationary for (1.1) if and only if 0 ∈P(∆; x).
Proof. By deﬁnition, x is ﬁrst-order stationary if and only if 0 ∈∇f(x) + ∂h(x) =
∇sϕ(0; x) + ∂ψ(0; x). But ψ(0; x) = ψ(0; x) + χ(0; ∆) and ∂(ψ(·; x) + χ(·; ∆))(0) =
∂ψ(0; x)+∂χ(0; ∆) because ∂χ(0; ∆) = {0}. Thus we obtain 0 ∈∇sϕ(0; x)+∂(ψ(·; x)+
χ(·; ∆))(0).
Proposition 3.2 suggests we may use an element of P(∆; x) as ﬁrst-order optimality
measure for any ∆> 0, such as for example ∥g(∆; x)∥, where g(∆; x) is the least-norm
element of P(∆; x). However, the dependency on ∆is inconvenient. In order to
circumvent this diﬃculty, we focus our attention temporarily on the choice
(3.2)
ϕ(s; x) = f(x) + ∇f(x)T s + 1
2ν−1∥s∥2
= 1
2ν−1∥s + ν∇f(x)∥2 + f(x) −1
2ν∥∇f(x)∥2,
Cahier du GERAD G-2021-12
Commit bd54cde by Robert Baraldi on 2021-04-02 10:15:10 -0700

8
[toc]
where ν > 0 is ﬁxed, so that for any x ∈Rn,
p(∆; x) = eνψ(·;x)+χ(·;∆)(−ν∇f(x)) + f(x) −1
2ν∥∇f(x)∥2,
(3.3a)
P(∆; x) =
prox
νψ(·;x)+χ(·;∆)
(−ν∇f(x)),
(3.3b)
and p only diﬀers from a Moreau envelope by a constant. The above choice of ϕ(·; x)
allows us to derive a convenient, computable optimality measure, and to generalize the
concept of decrease along the steepest descent direction, also known as Cauchy decrease,
which is so fundamental to the convergence analysis of computational methods for
smooth optimization.
In the special case where ψ(·; x) = 0, Proposition 3.1 part 3 indicates that P(∆; x)
is single valued, and its only element is the projection of −ν∇f(x) into the trust
region. On the other hand, p(∆; x) measures the decrease of (3.2) in the direction of
the projected gradient. Cartis et al. [10] study the special case where h(x) = g(c(x))
with g convex and globally Lipschitz continuous, and c smooth. In lieu of (3.3a), they
minimize f(x) + ∇f(x)T s + g(c(x) + ∇c(x)T s) in the trust region, which is analogous.
Crucially, (3.3) describes the ﬁrst step of the proximal gradient method with step
size ν applied to (3.1a) where ϕ(·; x) is as in (3.2) from s = 0 with a trust region of
radius ∆. In the notation of section 2.4, ϕ is ϕ(·; x) and ψ is ψ(·; x)+χ(·; ∆). If ψ(·; x)
is ﬁnite at s0 = 0, the ﬁrst step of the proximal gradient method is
(3.4)
s1 ∈arg min
s
1
2ν−1∥s + ν∇f(x)∥2 + ψ(s; x) + χ(s; ∆)
= arg min
s
f(x) + ∇f(x)T s + 1
2ν−1∥s∥2 + ψ(s; x) + χ(s; ∆),
and yields the decrease
(3.5)
(ϕ + ψ)(s; x) ≤(f + h)(x) −1
2(ν−1 −L)∥s1∥2
Moreover, s1 is also the ﬁrst step of the proximal-gradient method applied to (3.1a)
where ϕ(·; x) is any model of f about x that is diﬀerentiable at s = 0 with ∇sϕ(0; x) =
∇f(x), and, in particular, any quadratic expansion of f about x. In the sequel, we
use s1 as the appropriate generalization to the nonsmooth context of the projected
gradient step, which allows us to derive an adequate optimality measure.
Let
(3.6)
ξ(∆; x) := f(x) + h(x) −p(∆; x),
where p(∆; x) is deﬁned in (3.3a). In view of the above, ξ(∆; x) measures the decrease
predicted by the ﬁrst step of the proximal gradient method applied to (3.1a) from
s = 0 with trust-region radius ∆, where ϕ(·; x) is any model of f about x that is
diﬀerentiable at s = 0 with ∇sϕ(0; x) = ∇f(x).
Assume from now on that ϕ(0; x) = f(x) and ψ(0; x) = h(x). Because p(∆; x) ≤
ϕ(0; x) + ψ(0; x) + χ(0; ∆) = f(x) + h(x), we necessarily have ξ(∆; x) ≥0.
Examples of models of f satisfying the above assumptions include Taylor expansions
of f about x, and in particular quadratic models f(x) + ∇f(x)T s + 1
2sT Bs where
B = BT . The most straightforward example of a model of h satisfying the above
is ψ(s; x) = h(x + s). If h(x) = g(c(x)), where g : Rm →R is proper, lsc and
level-bounded, and c : Rn →Rm is continuously diﬀerentiable, other possible models
include ψ(s; x) = g(c(x) + ∇c(x)T s) and ψ(s; x) = g(c(x) + ∇c(x)T s + Pm
i=1 sT Bis),
where each Bi = BT
i .
Commit bd54cde by Robert Baraldi on 2021-04-02 10:15:10 -0700
Cahier du GERAD G-2021-12

[toc]
9
The following result allows us to rely on the computable values p(∆; x) and ξ(∆; x)
for a well-chosen value of ∆> 0 to assess stationarity.
Proposition 3.3. Let Model Assumption 3.1 be satisﬁed where ϕ(0; x) = f(x) and
∇sϕ(0; x) = ∇f(x). Assume furthermore that ψ(0; x) = h(x) and ∂ψ(0; x) = ∂h(x),
and let ∆> 0. Then x is ﬁrst-order stationary for (1.1) if and only if ξ(∆; x) = 0.
Proof. If x is ﬁrst-order stationary, Proposition 3.2 yields 0 ∈P(∆; x). Substitut-
ing s = 0 in the objective of (3.3a) implies ξ(∆; x) = 0. Conversely, if ξ(∆; x) = 0,
then p(∆; x) = f(x) + h(x), which is the value of ϕ(s; x) + ψ(s; x) at s = 0 and means
that s = 0 ∈P(∆; x).
3.3. A trust-region algorithm. We focus on the solution of (1.1) under Prob-
lem Assumption 3.1.
Problem Assumption 3.1. In (1.1), f ∈C1(Rn), and h is proper and lsc.
At iteration k, we construct a model mk(s; xk) := ϕ(s; xk) + ψ(s; xk) ≈f(xk +
s) + h(xk + s) and we approximately solve
(3.7)
minimize
s
mk(s; xk)
subject to ∥s∥≤∆k
by computing a step sk required to result in at least a fraction of the decrease achieved
with one step of the proximal gradient method. Step Assumption 3.1 formalizes our
requirement.
Step Assumption 3.1. There exists κm > 0 and κmdc ∈(0, 1) such that for all
k, ∥sk∥≤∆k and
|f(xk + sk) + h(xk + sk) −mk(sk; xk)| ≤κm∥sk∥2,
(3.8a)
mk(0; xk) −mk(sk; xk) ≥κmdcξ(∆k; xk).
(3.8b)
Condition (3.8a) is certainly satisﬁed if both f and ϕ are twice continuously
diﬀerentiable with bounded second derivatives, and ψ(s; xk) := h(xk + s). It also
holds when h(x) = g(c(x)) where c : Rn →Rm has Lipschitz-continuous Jacobian
and g : Rm →Rn is Lipschitz continuous. Such a situation arises when (1.1) results
from penalizing infeasibility in the process of solving a smooth constrained problem.
A useful model is then ψ(s; xk) := g(c(xk) + ∇c(xk)T s). If L > 0 is the Lipschitz
constant of g and M > 0 that of the Jacobian of c, we have
|h(xk + s) −ψ(s; xk)| ≤L∥c(xk + s) −c(xk) −∇c(xk)T s∥≤1
2LM∥s∥2,
for all s, and (3.8a) is satisﬁed.
In order to develop a convergence analysis, we further assume that the gradient
of ϕ(·; xk) is Lipschitz continuous with uniformly-bounded Lipschitz constant, which
is satisﬁed, for instance, in the case of a quadratic model with uniformly-bounded
Hessian. We gather the assumptions on the model from sections 3.1 and 3.2 in Model
Assumption 3.2.
Model Assumption 3.2. For any x ∈Rn, ϕ(·; x) is continuously diﬀerentiable
with ϕ(0; x) = f(x) and ∇sϕ(0; x) = ∇f(x). In addition, there exists L > 0 such that
∇sϕ(·; x) is Lipschitz continuous with constant 0 ≤L(x) ≤L for all x ∈Rn. Finally,
ψ(·; x) is proper, lsc, and satisﬁes ψ(0; x) = h(x) and ∂ψ(0; x) = ∂h(x).
The complete process is formalized in Algorithm 3.1, which diﬀers from a traditional
trust-region algorithm in a few respects. First, each iteration begins with the choice of
Cahier du GERAD G-2021-12
Commit bd54cde by Robert Baraldi on 2021-04-02 10:15:10 -0700

10
[toc]
a steplength νk > 0 for the proximal-gradient method. Steplength νk must be below
1/L(xk) to ensure descent; in addition, we connect νk explicitly to ∆k for a reason
that becomes apparent in Theorem 3.4. Second, a step computation occurs in two
phases. In the ﬁrst phase, we compute the ﬁrst step sk,1 of the proximal-gradient
method applied to our model with trust-region radius ∆k. Step sk,1 is an analog
of the scaled projected gradient for nonsmooth regularized problems. In the second
phase, we continue the proximal-gradient iterations from sk,1 but possibly modify the
trust-region radius so it does not exceed β∥sk,1∥for a prescribed β ≥1. This choice is
similar in spirit to the analysis of Curtis et al. [14] for smooth problems, who set the
radius to be proportional to the gradient norm. More precisely, if ∥sk,1∥< ∆k, we
explore a trust region of radius β∥sk,1∥≥∥sk,1∥. Because the constraint ∥s∥≤∆k
is inactive at sk,1, the ﬁrst step of the proximal gradient method computed in the
updated trust region remains sk,1, so that subsequent proximal gradient iterations
will result in further decrease and the ultimate step sk will satisfy (3.8b). If, on the
other hand, ∥sk,1∥= ∆k, the ﬁrst step of the proximal gradient method computed in a
larger trust region might diﬀer from sk,1, which would jeopardize satisfaction of (3.8b).
In order to preserve (3.8b), we leave ∆k unchanged.
Algorithm 3.1 Nonsmooth Regularized Trust-Region Algorithm.
1: Choose a maximum permissible trust-region radius ∆max > 0 and constants
0 < η1 ≤η2 < 1,
0 < γ1 ≤γ2 < 1 < γ3 ≤γ4
and
α > 0, β ≥1.
2: Choose x0 ∈Rn where h is ﬁnite, ∆0 ∈(0, ∆max), compute f(x0) + h(x0).
3: for k = 0, 1, . . . do
4:
Choose 0 < νk ≤α∆k such that νk < 1/L(xk).
5:
Deﬁne mk(s; xk) := ϕ(s; xk) + ψ(s; xk) satisfying Model Assumption 3.2.
6:
Deﬁne mν
k(s; xk) := ϕν(s; xk) + ψ(s; xk) where ϕν(·; xk) is as in (3.2).
7:
Compute sk,1 as the solution of (3.7) with model mν
k(s; xk).
8:
Compute an approximate solution sk of (3.7) with model mk(s; xk) satisfying
Step Assumption 3.1 and such that ∥sk∥≤min(∆k, β∥sk,1∥).
9:
Compute the ratio
ρk := f(xk) + h(xk) −(f(xk + sk) + h(xk + sk))
mk(0; xk) −mk(sk; xk)
.
10:
If ρk ≥η1, set xk+1 = xk + sk. Otherwise, set xk+1 = xk.
11:
Update the trust-region radius according to
∆k+1 ∈





[γ3∆k, γ4∆k]
if ρk ≥η2,
[γ2∆k, ∆k]
if η1 ≤ρk < η2,
[γ1∆k, γ2∆k]
if ρk < η1.
12: end for
3.4. Convergence analysis and iteration complexity. Our ﬁrst result states
that a successful step is guaranteed provided the trust-region radius is small enough.
Theorem 3.4. Let Model Assumption 3.2 and Step Assumption 3.1 be satisﬁed
Commit bd54cde by Robert Baraldi on 2021-04-02 10:15:10 -0700
Cahier du GERAD G-2021-12

[toc]
11
and let
(3.9)
∆succ := α−1
 
L +
2β2κm
κmdc(1 −η2)
!−1
> 0.
If xk is not ﬁrst-order stationary and ∆k ≤∆succ, then iteration k is very successful
and ∆k+1 ≥∆k.
Proof. Because xk is not ﬁrst-order stationary, sk,1 ̸= 0 and sk ̸= 0. Model
Assumption 3.2 and Step Assumption 3.1 together with the bounds ∥sk∥≤β∥sk,1∥
and νk ≤α∆k imply that
|ρk −1| =

f(xk + sk) + h(xk + sk) −mk(sk; xk)
mk(0; xk) −mk(sk; xk)

≤
κm∥sk∥2
κmdcξ(∆k; xk)
≤
κmβ2∥sk,1∥2
1
2κmdc(ν−1
k
−L(xk))∥sk,1∥2
≤
2κmβ2
κmdc(α−1∆−1
k
−L)
.
Therefore, ∆k ≤∆succ implies ρk ≥η2 and iteration k is very successful.
The
trust-region update of Algorithm 3.1 ensures that ∆k+1 ≥∆k.
A careful examination of the proof of Theorem 3.4 reveals that the model adequacy
condition (3.8a) could be replaced with the weaker condition
(3.10)
|f(xk + sk) + h(xk + sk) −mk(sk; xk)| ≤κmβ2∥sk,1∥2,
which encapsulates the step size and the trust-region radius simultaneously, and
suggests that sk,1 is the appropriate generalization of the projected gradient for
nonsmooth regularized optimization.
We are now in position to show that Algorithm 3.1 identiﬁes a ﬁrst-order critical
point. We ﬁrst consider the case where there are ﬁnitely many successful iterations.
Theorem 3.5. Let Model Assumption 3.2 and Step Assumption 3.1 be satisﬁed.
If Algorithm 3.1 only generates ﬁnitely many successful iterations, then xk = x∗for
all suﬃciently large k and x∗is ﬁrst-order critical.
Proof. The proof mirrors that of Conn et al. [13, Theorem 6.4.4]. Under the
assumptions given, there exists k0 ∈N such that all iterations k ≥k0 are unsuccessful
and xk = xk0 = x∗. Assume by contradiction that x∗is not ﬁrst-order critical. The
mechanism of Algorithm 3.1 ensures that ∆k decreases on unsuccessful iterations. Thus,
there must be k1 ≥k0 such that ∆k ≤∆succ, where ∆succ is deﬁned in Theorem 3.4,
which ensures that iteration k1 is successful and contradicts our assumption.
We now turn to the case where there are inﬁnitely many successful iterations and
show that the objective is either unbounded below or a measure of criticality converges
to zero. The mechanism of Algorithm 3.1 and Theorem 3.4 together ensure that
(3.11)
∆k ≥∆min
for all k ∈N where
∆min := min(∆0, γ1∆succ) > 0.
Thus, by deﬁnition of ξ(·; xk) and (3.11), we have
(3.12)
ξ(∆k; xk) ≥ξ(∆min; xk)
for all k ∈N.
Cahier du GERAD G-2021-12
Commit bd54cde by Robert Baraldi on 2021-04-02 10:15:10 -0700

12
[toc]
Following this last observation and in view of Proposition 3.3 and (2.6), we deﬁne
ξ(∆min; xk)
1
2 as our measure of criticality.
Our objective is to establish that lim inf ξ(∆min; xk) = 0 provided f +h is bounded
below. While doing so, we also establish a complexity result.
Let ϵ > 0 be a stopping tolerance set by the user. We are interested in determining
the smallest iteration number k(ϵ) at which we achieve the ﬁrst-order optimality
condition
(3.13)
ξ(∆min; xk)
1
2 ≤ϵ
(0 < ϵ < 1).
We denote
S := {k ∈N | ρk ≥η1},
(3.14a)
S(ϵ) := {k ∈S | k < k(ϵ)},
(3.14b)
U(ϵ) := {k ∈N | k ̸∈S and k < k(ϵ)},
(3.14c)
respectively the set of all successful iterations, the set of successful iterations for
which (3.13) has not yet been attained, and the set of unsuccessful iterations be-
fore (3.13) is ﬁrst attained. The following two results parallel the now-classic complexity
analysis of Cartis et al. [10] and references therein.
Lemma 3.6. Let Model Assumption 3.2 and Step Assumption 3.1 be satisﬁed.
Assume there are inﬁnitely many successful iterations and that f(xk) + h(xk) ≥
(f + h)low for all k ∈N. Then, for all ϵ ∈(0, 1),
(3.15)
|S(ϵ)| ≤(f + h)(x0) −(f + h)low
η1κmdcϵ2
= O(ϵ−2).
Proof. If k ∈S(ϵ), Step Assumption 3.1 and (3.12) imply
f(xk) + h(xk) −f(xk + sk) −h(xk + sk) ≥η1(mk(0; xk) −mk(sk; xk))
≥η1κmdcξ(∆k; xk)
≥η1κmdcξ(∆min; xk)
≥η1κmdcϵ2.
Because f + h is bounded below by (f + h)low, summing the above inequalities over
all k ∈S(ϵ) yields
(f + h)(x0) −(f + h)low ≥
X
k∈S(ϵ)
(f + h)(xk) −(f + h)(xk+1) ≥|S(ϵ)|η1κmdcϵ2,
which establishes (3.15).
In order to derive a similar bound on the total number of iterations before (3.13)
is ﬁrst attained, we need to bound the number of unsuccessful iterations.
Lemma 3.7. Under the assumptions of Lemma 3.6,
(3.16)
|U(ϵ)| ≤logγ2(∆min/∆0) + |S(ϵ)|| logγ2(γ4)| = O(ϵ−2).
Proof. Each unsuccessful iteration reduces the trust-region radius by a factor at
least γ2, while at each successful iteration, ∆k ≤γ4∆k. Thus if k(ϵ)−1 is the iteration
index just before (3.13) occurs for the ﬁrst time,
∆min ≤∆k(ϵ)−1 ≤∆0γ|U(ϵ)|
2
γ|S(ϵ)|
4
.
Commit bd54cde by Robert Baraldi on 2021-04-02 10:15:10 -0700
Cahier du GERAD G-2021-12

[toc]
13
Taking logarithms on both sides and remembering that 0 < γ2 < 1 gives
|U(ϵ)| log(γ2) + |S(ϵ)| log(γ4) ≥log(∆min/∆0),
and establishes (3.16).
Finally, the total number of iteration until (3.13) is attained is given in the next
result, which simply combines Lemma 3.6 and Lemma 3.7.
Theorem 3.8. Under the assumptions of Lemma 3.6,
(3.17)
|S(ϵ)| + |U(ϵ)| = O(ϵ−2).
We use the update ∆k+1 ∈[γ3∆k, γ4∆k] on very successful iterations but other
possibilities exist.
For instance, it is common to set ∆k+1 = max(γ3∥sk∥, ∆k)
instead.
Lemma 3.7 continues to hold because on successful iterations, ∆k+1 ≤
max(γ3∆k, ∆k) = γ3∆k.
Curtis et al. [14] establish a complexity bound of O(ϵ−2) by making ∆k proportional
to an optimality measure—in their context of smooth optimization, they choose the
gradient norm. Grapiglia et al. [22] study the convergence and complexity of a generic
algorithm that has trust-region methods as a special case and obtain the O(ϵ−2)
complexity bound under stronger smoothness assumptions than ours. Among others,
they establish a bound for regularized optimization but also require h to be convex and
globally Lipschitz continuous. Curtis et al. [15] describe a nonstandard trust-region
algorithm with a stronger O(ϵ−3/2) complexity bound.
A straightforward consequence of Theorem 3.8 is that if f + h is bounded below,
a subsequence of the criticality measure converges to zero.
Corollary 3.9. Let Model Assumption 3.2 and Step Assumption 3.1 be satisﬁed.
If there are iniﬁnitely many successful iterations, then, either
lim
k→∞f(xk) + h(xk) →−∞
or
lim inf
k→∞ξ(∆min; xk) = 0.
Proof. Follows directly from Theorem 3.8.
In order to give an interpretation of Corollary 3.9, consider (3.1) with ∆= ∆min >
0 along with its value function p(∆min; x), optimal set P(∆min; x) and the optimality
measure ξ(∆min; x), where x now plays the role of the parameter.
Similarly to
Proposition 3.1, though with slightly stronger assumptions than Model Assumption 3.1,
we have the following result.
Proposition 3.10. Let Problem Assumption 3.1 be satisﬁed and consider (3.1)
with ϕ as in (3.2). Assume ψ is proper and lsc in the joint variables (s, x) and
ψ(s; x) + χ(s; ∆min) is level-bounded in s locally uniformly in x. Then, the domain of
p(∆min; ·) and P(∆min; ·) is Rn. In addition,
1. p(∆min; ·) is proper lsc and for all x ∈Rn, P(∆min; x) is nonempty and
compact. In addition, ξ(∆min; ·) is proper;
2. if {xk} →¯x in such a way that p(∆min; xk) →p(∆min; ¯x), and for each
k, sk ∈P(∆min; xk), then {sk} is bounded and all its limit points are in
P(∆min; ¯x).
3. if there exists ¯s ∈P(∆min; ¯x) such that ψ(¯s; ·) is continuous at ¯x, then
p(∆min; ·) is continuous at ¯x, and {p(∆min; xk)} →p(∆min; ¯x) in part 2. In
addition, ξ(∆min; ·) is lsc at ¯x.
Cahier du GERAD G-2021-12
Commit bd54cde by Robert Baraldi on 2021-04-02 10:15:10 -0700

14
[toc]
Proof. Because h is proper lsc, (3.6) implies that ξ(∆min; ·) is proper whenever
p(∆min; ·) is proper and is lsc whenever p(∆min; ·) is continuous. The rest follows by
[39, Theorems 1.17 and 7.41].
By Corollary 3.9, if f + h is bounded below, there is an index set K such that
{ξ(∆min; xk)}K →0. Assume that {xk}K possesses a limit point and, without loss
of generality, that {xk}K →¯x. Under the assumptions of Proposition 3.10 part 3,
ξ(∆min; ·) is lsc, which means exactly that
0 = lim inf
k∈K ξ(∆min; xk) = ξ(∆min; ¯x),
so that ¯x is ﬁrst-order critical.
If ξ(∆min; ·) is continuous, as when h itself is continuous, a stronger conclusion
holds with the following result, which implies similarly that every limit point of {xk}
is ﬁrst-order critical.
Theorem 3.11. Let Model Assumption 3.2 and Step Assumption 3.1 be satisﬁed.
Assume also that h is continuous. If there are iniﬁnitely many successful iterations,
lim
k→∞f(xk) + h(xk) →−∞
or
lim
k→∞ξ(∆min; xk) = 0.
Proof. The proof follows Conn et al. [13, Theorem 6.4.6]. Continuity of h implies
continuity of ξ(∆min; ·), which is required, just as continuity of the objective gradient
is used at the bottom of page 138 of [13] in the concluding argument.
4. Proximal-quasi-Newton trust-region method. In this section, we con-
sider the computation of a trust-region step and develop a special case of Proposition 2.6
in which
(4.1)
ϕ(s; x) := f(x) + ∇f(x)T s + 1
2sT Bs,
where B = BT . We assume that ∆> 0 is ﬁxed. For conciseness, we use the notation
ϕ(s) := ϕ(s; x) and ψ(s) := ψ(s; x) + χ(s; ∆). We work under Model Assumption 3.2,
i.e., we assume that ψ is proper and lsc with prox-boundedness coming from χ(·; ∆).
4.1. Computing a trust-region step. The following result states a fundamen-
tal relationship between Gν and ∂ψ.
Lemma 4.1.
Let sj+1be given by (2.3) and Gν(sj)be deﬁned by (2.5). Then,
Gν(sj) −∇ϕ(sj) ∈∂ψ(sj+1).
(4.2a)
(B −ν−1I)(sj+1 −sj) ∈∇ϕ(sj+1) + ∂ψ(sj+1).
(4.2b)
Proof. (4.2a) is a simple restatement of (2.4) and (4.2b) results from adding
∇ϕ(sj+1)to both sides of (2.4) and substituting the gradient of ϕ using (4.1).
The next result shows that (2.3) is a descent method when ϕ is a quadratic.
Lemma 4.2. Let {sj} be generated according to (2.3). For all j ≥0,
ψ(sj+1) + ∇ϕ(sj)T (sj+1 −sj) ≤ψ(sj) −1
2ν−1∥sj+1 −sj∥2,
(4.3a)
(ϕ + ψ)(sj+1) ≤(ϕ + ψ)(sj) + 1
2(sj+1 −sj)T (B −ν−1I)(sj+1 −sj).
(4.3b)
Commit bd54cde by Robert Baraldi on 2021-04-02 10:15:10 -0700
Cahier du GERAD G-2021-12

[toc]
15
Proof. Because sj+1 solves (2.3), we have
1
2ν−1∥s −(sj −ν∇ϕ(sj))∥2 + ψ(s) ≤1
2ν−1∥ν∇ϕ(sj)∥2.
By expanding the squared norm in the left-hand-side of the above and cancelling the
common term ∥ν∇ϕ(sj)∥2, we obtain (4.3a). Because ϕ is quadratic,
ϕ(sj+1) = ϕ(sj) + ∇ϕ(sj)T (sj+1 −sj) + 1
2(sj+1 −sj)T B(sj+1 −sj).
We now add ψ(sj+1) to both sides and use (4.3a) and obtain
(ϕ + ψ)(sj+1) ≤ϕ(sj) + ψ(sj) −1
2ν−1∥sj+1 −sj∥2 + 1
2(sj+1 −sj)T B(sj+1 −sj)
= (ϕ + ψ)(sj) + 1
2(sj+1 −sj)T (B −ν−1I)(sj+1 −sj).
We now examine two choices of ν > 0 that result in two decrease behaviors.
Corollary 4.3. Under the assumptions of Lemma 4.2, assume 0 < ν ≤(1 −
θ)/∥B∥for some θ ∈(0, 1), or simply that ν > 0 if B = 0, in which case θ = 1. Then,
(4.4)
(ϕ + ψ)(sj+1) ≤(ϕ + ψ)(sj) −1
2θν−1 ∥sj −sj+1∥2,
(j ≥0).
Proof. If B = 0, (4.4) with θ = 1 follows directly from (4.3a). If B ̸= 0, we have by
assumption (1 −θ)ν−1 ≥∥B∥, so that λmax(B −ν−1I) ≤−θν−1 < 0, and therefore,
(sj+1 −sj)T (B −ν−1I)(sj+1 −sj) ≤−θν−1 ∥sj+1 −sj∥2,
which combines with (4.3b) to complete the proof.
Corollary 4.4. Under the assumptions of Lemma 4.2, assume B ̸= 0, let 0 <
θ < 1/(4∥B∥) and νmin ≤ν ≤νmax, where
νmin := 1 −
p
1 −4θ∥B∥
2∥B∥
,
νmax := 1 +
p
1 −4θ∥B∥
2∥B∥
.
Then, for all j ≥0,
(4.5) (ϕ+ψ)(sj+1) ≤(ϕ+ψ)(sj)−1
2θν−2 ∥sj −sj+1∥2 = (ϕ+ψ)(sj)−1
2θ∥Gν(sj)∥2.
Proof. Under our assumptions, the quadratic p(ν) := ∥B∥ν2 −ν + θ has the two
positive real roots νmin and νmax. Moreover, for all ν ∈[νmin, νmax], p(ν) ≤0, which
can also be written ∥B∥−ν−1 ≤−θν−2. Therefore, if ν ∈[νmin, νmax], then for all j,
(sj+1 −sj)T (B −ν−1I)(sj+1 −sj) ≤−θν−2 ∥sj+1 −sj∥2 = −θ∥Gν(sj)∥2,
which combines with (4.3b) to complete the proof.
Because (ϕ+ψ)(s0) = f(x)+h(x) < +∞, Lemma 4.2 indicates that (2.3) generates
iterates {sj} such that {(ϕ + ψ)(sj)} is monotonically decreasing and all its terms are
ﬁnite. Finiteness implies that ∥sj∥≤∆for all j ≥0, i.e., all iterates lie in the trust
region. If ν is chosen as in Corollary 4.3 or Corollary 4.4, then for any j ≥1
(4.6)
mk(sj+1; xk) ≤mk(sj; xk) ≤mk(s1; xk) ≤mν
k(s1; xk),
where mν
k(s1; xk) = 1
2ν−1∥s1 + ν∇f(xk)∥2
2 + (ψ + χ)(s1) and hence sj satisﬁes the
suﬃcient decrease condition (3.8b).
Cahier du GERAD G-2021-12
Commit bd54cde by Robert Baraldi on 2021-04-02 10:15:10 -0700

16
[toc]
With regards to proximal gradient convergence, two situations may occur. In the
ﬁrst, (2.3) results in sj0+1 = sj0 for a smallest index j0 > 0. In that case, (2.4) yields
0 ∈∂(ϕ + ψ)(sj0),
i.e., we have identiﬁed a stationary point of (3.7) in a ﬁnite number of iterations, while
decreasing the value of mk at each iteration. Otherwise, sj+1 ̸= sj for all j ≥0, and the
next result establishes sub-linear convergence of the proximal gradient method (2.3).
Theorem 4.5. Let {sj} be generated according to (2.3) with ν as in Corollary 4.3.
Denote (ϕ + ψ)low := inf(ϕ + ψ) > −∞. Let vj+1 denote the left-hand side of (4.2b).
For any N ≥1,
min
j=0,...,N−1 ∥vj+1∥≤
r
2
Nθ(ν−1 −λmin(B)) ((ϕ + ψ)(s0) −(ϕ + ψ)low),
and {sj} converges sublinearly to a stationary point of ϕ + ψ.
Proof. We rearrange (4.4) and sum from iteration j = 0 to iteration j = N −1:
N−1
X
j=0
∥sj −sj+1∥2 ≤2ν
θ ((ϕ + ψ)(s0) −(ϕ + ψ)(sN)) ≤2ν
θ ((ϕ + ψ)(s0) −(ϕ + ψ)low).
For any positive sequence {cj},
min
0≤j≤N−1 cj =
r
min
0≤j≤N−1 c2
j ≤
v
u
u
t 1
N
N−1
X
j=0
c2
j.
Therefore,
min
0≤j≤N−1 ∥sj −sj+1∥≤
r
2ν
Nθ ((ϕ + ψ)(s0) −(ϕ + ψ)low).
Because ∥vj+1∥≤∥B −ν−1I∥∥sj −sj+1∥= (ν−1 −λmin(B)) ∥sj −sj+1∥≤ν−1∥sj −
sj+1∥, we obtain the desired result.
When solving (3.7), a reasonable stopping condition would be ∥vj+1∥≤ϵ for a
user-chosen tolerance ϵ > 0. Theorem 4.5 indicates that such stopping condition is
attained after N(ϵ) iterations, where
N(ϵ) =
 2
ϵ2θ
(ν−1 −λmin(B)) ((ϕ + ψ)(s0) −(ϕ + ψ)low)

.
A result similar to Theorem 4.5 can be established under the step size rule of
Corollary 4.4, with nearly identical proof.
Theorem 4.6. Let {sj} be generated according to (2.3) with ν as in Corollary 4.4
with 0 < θ < 1/(4∥B∥). Assume ψ, and therefore ϕ + ψ, is bounded below and denote
(ϕ + ψ)low := inf(ϕ + ψ) > −∞. For any N ≥1,
min
j=0,...,N−1 ∥Gν(sj+1)∥≤
r
2
Nθ ((ϕ + ψ)(s0) −(ϕ + ψ)low),
and {sj} converges sublinearly to a stationary point of ϕ + ψ.
Commit bd54cde by Robert Baraldi on 2021-04-02 10:15:10 -0700
Cahier du GERAD G-2021-12

[toc]
17
4.2. Ensuring boundedness of Hessian approximations. Limited-memory
quasi-Newton Hessian approximations are popular due to their eﬀectiveness in practice
and modest storage requirements. Among them, the limited-memory symmetric rank-1
(LSR1) holds a special place for its ability to capture negative curvature, a highly
desirable feature in the context of trust-region methods [12, 30]. Unfortunately, there is
no guarantee that such approximations yield a model ϕ(·; x) with a uniformly bounded
Hessian, as required by Model Assumption 3.2. In this section, we outline a simple
strategy to safeguard LSR1 approximations while ensuring that they remain uniformly
bounded.
In the course of the iterations of a descent method applied to a generic smooth
objective f, LSR1 updates a current Bk = BT
k ≈∇2f(xk) according to
Bk+1 = Bk + zkzT
k
sT
k zk
,
where sk = xk+1 −xk is the most recent step, zk = yk −Bksk and yk = ∇f(xk+1) −
∇f(xk). The limited-memory aspect resides in the fact that only the m ≥0 most
recent vectors sj and zj are stored, j = max(k−m+1, 0), . . . , k, and the approximation
Bk−m+1 is replaced with a well-chosen Bk,0 = BT
k,0. Typically, Bk,0 is a multiple of
the identity. In order to avoid a (near) division by zero, one possibility is to perform
the update if
|sT
k zk| ≥ω ∥zk∥2,
ω > 0,
and leave Bk unchanged otherwise. Other choices are possible but we focus on the
above simple strategy in the following.
The eigenvalues of the rank-1 update term zkzT
k /sT
k zk are λ1 = 0 with multiplicity
n −1 and λ2 = ∥zk∥2/sT
k zk with multiplicty one. Moreover, 0 < |λ2| ≤1/ω. Thus, if
λmin,0 and λmax,0 are the smallest and largest eigenvalues of Bk,0, respectively, and if
Sk,+ = {j = max(k −m + 1, 0), . . . , k | sT
j zj > 0},
Sk,−= {j = max(k −m + 1, 0), . . . , k | sT
j zj < 0},
we obtain the bounds
λmin(Bk) ≥λmin,0 +
X
j∈Sk,−
∥zj∥2
sT
j zj
≥λmin,0 −min(m, k)/ω,
(4.7a)
λmax(Bk) ≤λmax,0 +
X
j∈Sk,+
∥zj∥2
sT
j zj
≤λmax,0 + min(m, k)/ω.
(4.7b)
It is now possible to esure that Bk remains uniformly bounded as follows:
1. select a constant M > 0;
2. at each iteration k, select Bk,0 such that −M ≤λmin,0 ≤λmax,0 ≤M;
3. if either of the bounds (4.7) lies outside [−M, M], prune the sets {sj} and
{zj} or reset the approximation Bk.
This simple procedure ensures that ∥Bk∥≤M at all times. Lotﬁet al. [29] use a
similar strategy successfully with the limited-memory BFGS update in deep learning.
5. Proximal Operators for Trust-Region Subproblems. In this section, we
develop techniques for computing (2.3) for use in Steps 7 and 8 of Algorithm 3.1.
Many standard proximal operators for both convex and nonconvex prox-bounded
Cahier du GERAD G-2021-12
Commit bd54cde by Robert Baraldi on 2021-04-02 10:15:10 -0700

18
[toc]
functions ψ have been worked out [5, 11], and new examples for nonconvex problems
continuously appear. Well-known examples include the ﬁrm-thresholding penalty [21],
the SCAD penalty [19], MCP penalty [47], lower C2 functions [23], any ℓp
p-seminorm
for 0 < p < 1 [49, Appendix A], and other exotic operators, see e.g. [48, Table 1]. We
refer to such functions ψ as prox-friendly. However, Algorithm 3.1 requires evaluating
proximal operators for modiﬁed functions that combine a shift and a summation
with an indicator function. By Model Assumption 3.2, our model ψ(s; x) ≈h(x + s)
must coincide with h in value and subdiﬀerential at s = 0. In particular, the choice
ψ(s; x) = h(x + s) seems natural when h itself is prox-friendly. Here we consider
(5.1)
ψ(s; x) := h(x + s) + χ(s; ∆Bp),
where h is prox-friendly, x is a shift, and p ∈{1, 2, ∞}. Below, we provide closed form
solutions and/or eﬃcient routines for (5.1) with focus on the following cases:
1. for an arbitrary separable prox-friendly h, we evaluate proxνψ(·;x) by leveraging
proxνh, but we restrict our attention to p = ∞. This allows us to consider (5.1)
with h(x) = λ∥x∥1 and h(x) = λ∥x∥0;
2. we consider h(x) = λ∥x∥1 in (5.1) for p = 2. Our computations can be
generalized to other convex h.
5.1. p = ∞, h separable. For the special case of B∞, (2.1b) and (5.1) yield
(5.2)
prox
νψ
(q) := arg min
s
1
2ν−1∥s −q∥2 + h(x + s) + χ(s; ∆B∞).
If h is separable, i.e., h(x) = P
i hi(xi), (5.2) decouples in each coordinate:
prox
νψ
(q)i = arg min
si
1
2ν−1(si −qi)2 + hi(xi + si) + χ(si; [−∆, ∆]).
Using the change of variable vi = xi + si, we may rewrite
prox
νψ
(q)i = arg min
vi
( 1
2ν−1(vi −xi −qi)2 + hi(vi) + χ(vi −xi; [−∆, ∆])) −xi.
We now work backwards from the form of the solution. For any pi ∈proxνψ (q)i, either
1. |pi| < ∆, in which case pi ∈proxνhi (q + x)i −xi;
2. otherwise, |pi| = ∆by construction.
Putting both cases together, we obtain
prox
νψ
(q)i = proj
[−∆,∆]
(prox
νhi
(q + x)i −xi).
For example, let h(x) = λ∥x∥1. Then,
prox
νψ
(q)i = proj
[−∆,∆]
(prox
νλ|·|
(q + x)i −xi) = proj
[−∆,∆]








qi −νλ
xi + qi > νλ
−xi
|xi + qi| ≤νλ
qi + νλ
xi + qi < −νλ



= proj
[−∆,∆]
 
proj
[qi−νλ,qi+νλ]
(−xi)
!
.
With h(x) = λ∥x∥0, we obtain
prox
νψ
(q)i = proj
[−∆,∆]
(prox
νλ|·|0
(q + x)i −xi) = proj
[−∆,∆]








−xi
1
2(q + x)2
i < νλ
qi
1
2(q + x)2
i > νλ
{−xi, qi}
1
2(q + x)2
i = νλ.


.
Commit bd54cde by Robert Baraldi on 2021-04-02 10:15:10 -0700
Cahier du GERAD G-2021-12

[toc]
19
5.2. p = 2, h(x) = λ∥x∥1. When using other norms to deﬁne the trust region,
additional computations are required.
The key idea is to dualize h.
We begin
with generalities using Bp but specialize our results to p = 2 below. We focus on
h(x) = λ∥x∥1 throughout because we use it in section 7.1.
First, we rewrite the scaled ℓ1-norm using its conjugate:
λ∥x + s∥1 =
sup
w∈λB∞
wT (x + s).
The minimization problem in (2.1b) and (5.1) can now be written
min
s
sup
w∈λB∞
1
2ν−1∥s −q∥2 + wT (x + s) + χ(s; ∆Bp).
Strong duality holds in this case since the objective is piecewise linear-quadratic
and the primal solution is attained. We interchange the order of minimization and
maximization and complete squares in s and in w to obtain
sup
w∈λB∞
min
s
1
2ν−1∥s −q + νw∥2 + χ(s; ∆Bp) −1
2ν−1 ∥x + q −νw∥2 + 1
2ν−1∥x + q∥2.
The solution of the inner problem given the dual variable w is
(5.3)
s(w) = prox
νψ
(q) = proj
∆Bp
(q −νw).
To obtain an explicit problem in w, we plug s(w) into the dual objective:
sup
w∈λB∞
1
2ν−1 dist (q −νw; ∆Bp)2 −1
2ν−1 ∥x + q −νw∥2 + 1
2ν−1∥x + q∥2,
where dist(x; A) is the Euclidean distance from x ∈Rn to A ⊆Rn. With the change
of variable y = q −νw, the problem is equivalent to
(5.4)
min
q−νλ1≤y≤q+νλ1
1
2ν−1 
∥y + x∥2 −dist (y; ∆Bp)2
,
or
min
y
1
2ν−1 
dist (−x; [q −νλ1, q + νλ1])2 −dist (y; ∆Bp)2
,
where 1 is a vector of all ones. The explicit solution of (5.4) depends on the shape of
the trust-region. Once we have the optimal solution in y+, from (5.3) we obtain
prox
νψ
(q) = proj
∆Bp
(y+).
The squared distance to a closed convex set is smooth, and, in particular, we have
d
dy

1
2 dist (y; ∆Bp)2
= y −proj
∆Bp
(y).
To further characterize y+, we consider two cases:
1. if y+ ∈∆Bp, dist(y+; ∆Bp) = 0 and so we have
(5.5)
prox
νψ
(q) = y+ =
proj
[q−νλ1,q+νλ1]
(−x);
Cahier du GERAD G-2021-12
Commit bd54cde by Robert Baraldi on 2021-04-02 10:15:10 -0700

20
[toc]
2. if y+ ̸∈∆Bp, we have the optimality condition
(5.6)
0 ∈x + proj
∆Bp
(y+) + ν∂χ(y+; [q −νλ1, q + νλ1]).
Using now the fact that p = 2, (5.6) becomes
(5.7)
0 ∈x +
∆
∥y+∥
y+ + ν∂χ(y+; [q −νλ1, q + νλ1]),
which we can rewrite as
0 ∈y+ + ∥y+∥
∆x + ν∥y+∥
∆
∂χ(y+; [q −νλ1, q + νλ1]).
Given the ℓ2-norm of the answer, we know that
y+ =
proj
[q−νλ1,q+νλ1]
 
−∥y+∥
∆x
!
This sets up a scalar root ﬁnding problem, where we seek η such that
η =

proj
[q−νλ1,q+νλ1]

−η
∆x
 .
A good starting point for η is η = ∆. Once η has been found, there remains to project
y+ into the ℓ2-norm trust region:
prox
νψ
(q) = proj
∆B2
 
proj
[q−νλ1,q+νλ1]

−η
∆x
!
.
6. A quadratic regularization variant. We now describe a variant of the
trust-region algorithm of the previous sections inspired by the modiﬁed Gauss-Newton
scheme proposed by Nesterov [34] in the context of nonlinear least-squares problems.
Here again, Cartis et al. [10] establish a complexity of O(ϵ−2) iterations to attain a
near-optimality condition under the assumption that h is convex and globally Lipschitz
continuous. In the sequel, we obtain the same complexity bound under Problem
Assumption 3.1. The quadratic regularization method decribed below is closely related
to the standard proximal gradient method with the exception that it employs an
adaptive steplength. It may be used as an alternative to a linesearch-based proximal
gradient method such as those of Li and Lin [27] and Bot¸ et al. [9].
In the quadratic regularization method, we use the linear model
(6.1)
ϕ(s; x) = f(x) + ∇f(x)T s ≈f(x + s)
together with a model of ψ(s; x) that satisﬁes Model Assumption 3.2.
The ﬁrst
diﬀerence is that in the present setting, the Lipschitz constant of ∇ϕ(·; x) is L(x) = 0
for all x ∈Rn. The second diﬀerence is that we must now assume that ψ(·; x) is
prox-bounded. At x, we deﬁne
p(σ; x) := minimize
s
m(s; x, σ),
(6.2a)
P(σ; x) := arg min
s
m(s; x, σ),
(6.2b)
Commit bd54cde by Robert Baraldi on 2021-04-02 10:15:10 -0700
Cahier du GERAD G-2021-12

[toc]
21
where
(6.3)
m(s; x, σ) := ϕ(s; x) + ψ(s; x) + 1
2σ∥s∥2,
and σ > 0 is a regularization parameter.
From x, the method computes a step
s ∈P(σ; x). As earlier, let us also deﬁne
(6.4)
ξ(σ; x) := f(x) + h(x) −p(σ; x) ≥0.
If we combine (6.1) with (6.3), we may write
(6.5)
m(s; x, σ) = 1
2σ∥s + σ−1∇f(x)∥2 + ψ(s; x) + f(x) −1
2σ−1∥∇f(x)∥2,
where the last two terms are independent of s. In (6.5), we recognize a model of
the form (3.4), so that minimizing (6.3) amounts to performing a single step of the
proximal gradient method with step size 1/σ and Lipschitz constant L = 0. The
decrease guaranteed by the proximal gradient method is given by (3.5), i.e.,
(6.6)
ξ(x; σ) = f(x) + h(x) −m(s; x, σ) ≥1
2σ∥s∥2,
so that
(6.7)
f(x) + h(x) −(ϕ(s; x) + ψ(s; x)) ≥σ∥s∥2.
In view of (6.5), Proposition 2.3 applies to (6.2). In particular, p(σ; x) is continuous
in (σ, x), and P(σ; x) is nonempty and compact for all σ > 0.
By Proposition 2.5, for any σ > 0, if s ∈P(σ; x), then 0 ∈∇f(x) + ∂ψ(s; x) + σs.
Thus, we have the following optimality result.
Lemma 6.1. Let Model Assumption 3.2 be satisﬁed, ψ(·; x) be prox-bounded, and
let σ > 0. Then x is ﬁrst-order stationary for (1.1) if and only if 0 ∈P(σ; x), which
occurs if and only if ξ(σ; x) = 0.
As in the trust-region context, we require that the diﬀerence between the model
and the actual objective be bounded by a multiple of ∥sk∥2:
Step Assumption 6.1. There exists κm > 0 such that for all k,
(6.8)
|f(xk + sk) + h(xk + sk) −ϕk(sk; xk) −ψ(sk; xk)| ≤κm∥sk∥2.
Once a step s has been computed, its quality is assessed by comparing the decrease
in ϕ(·; x) + ψ(·; x) with that in the objective f + h, similarly to Algorithm 3.1. If both
are in strong agreement, σ decreases. Otherwise, σ increases. We state the overall
algorithm as Algorithm 6.1.
We now combine (6.7) with Step Assumption 6.1 into the following result.
Theorem 6.2. Let Model Assumption 3.2 and Step Assumption 6.1 be satisﬁed,
ψ(·; xk) be prox-bounded for each k ∈N, and let
(6.9)
σsucc := κm/(1 −η2) > 0.
If xk is not ﬁrst-order stationary and σk ≥σsucc, then iteration k is very successful
and σk+1 ≤σk.
Cahier du GERAD G-2021-12
Commit bd54cde by Robert Baraldi on 2021-04-02 10:15:10 -0700

22
[toc]
Algorithm 6.1 Nonsmooth quadratic regularization algorithm.
1: Choose constants 0 < η1 ≤η2 < 1 and 0 < γ3 ≤1 < γ1 ≤γ2.
2: Choose x0 ∈Rn where h is ﬁnite, σ0 > 0, compute f(x0) + h(x0).
3: for k = 0, 1, . . . do
4:
Deﬁne m(s; xk, σk) as in (6.3) satisfying Model Assumption 3.2 with L = 0.
5:
Compute a solution sk of (6.2) such that Step Assumption 6.1 holds.
6:
Compute the ratio
ρk := f(xk) + h(xk) −(f(xk + sk) + h(xk + sk))
ϕ(0; xk) + ψ(0; xk) −(ϕ(sk; xk) + ψ(sk; xk)).
7:
If ρk ≥η1, set xk+1 = xk + sk. Otherwise, set xk+1 = xk.
8:
Update the regularization parameter according to
σk+1 ∈





[γ3σk, σk]
if ρk ≥η2,
[σk, γ1σk]
if η1 ≤ρk < η2,
[γ1σk, γ2σk]
if ρk < η1.
9: end for
Proof. Let sk be the step computed at iteration k of Algorithm 6.1. Because xk
is not ﬁrst-order stationary, sk ̸= 0. Step Assumption 6.1 and (6.7) combine to yield
|ρk −1| = |f(xk + sk) + h(xk + sk) −(ϕ(sk; xk) + ψ(sk; xk))|
ϕ(0; xk) + ψ(0; xk) −(ϕ(sk; xk) + ψ(sk; xk))
≤κm∥sk∥2
σk∥sk∥2 .
After simplifying by ∥sk∥2, we obtain σk ≥σsucc =⇒ρk ≥η2.
Theorem 6.2 ensures existence of a constant σmax > 0 such that
(6.10)
σk ≤σmax := min(σ0, γ2σsucc) > 0
for all k ∈N.
A result analogous to Theorem 3.5 holds for Algorithm 6.1. We omit the proof, as
it is nearly identical.
Theorem 6.3. Let Model Assumption 3.2 and Step Assumption 6.1 be satisﬁed,
and ψ(·; xk) be prox-bounded for each k ∈N. If Algorithm 6.1 only generates ﬁnitely
many successful iterations, xk = x∗for suﬃciently large k and x∗is ﬁrst-order critical.
According to Proposition 2.3 part 2, and the identiﬁcation ν = σ−1, p(σ; x)
increases as σ increases, so that ξ(σ; x) decreases as σ increases, and (6.10) yields
(6.11)
ξ(σk; xk) ≥ξ(σmax; xk)
for all k ∈N.
Lemma 6.1, (6.7) and (6.11) suggest using ξ(σmax; xk)
1
2 as stationarity measure.
Let ϵ > 0 be a tolerance set by the user and consider the sets (3.14). We are now in
position to establish complexity results analogous to those obtained for Algorithm 3.1.
The proof is nearly identical and is omitted.
Theorem 6.4. Let Model Assumption 3.2 and Step Assumption 6.1 be satisﬁed,
and ψ(·; xk) be prox-bounded for each k ∈N.
Assume there are inﬁnitely many
successful iterations and that f(xk) + h(xk) ≥(f + h)low for all k ∈N. Then, for all
ϵ ∈(0, 1),
(6.12)
|S(ϵ)| = O(ϵ−2),
|U(ϵ)| = O(ϵ−2),
|S(ϵ)| + |U(ϵ)| = O(ϵ−2).
Commit bd54cde by Robert Baraldi on 2021-04-02 10:15:10 -0700
Cahier du GERAD G-2021-12

[toc]
23
7. Implementation and numerical results. Algorithms 3.1 and 6.1 are im-
plemented in Julia [6] and are available from github.com/UW-AMO/TRNC, along with
scripts to reproduce our experiments. Our design allows the user to choose a method
to compute a step, an important feature given the nonstandard ψk + χk operator.
We compare the performance of Algorithm 3.1 to other proximal quasi-Newton
routines: PANOC [41] and ZeroFPR [42]. PANOC can be viewed as a proximal
gradient descent scheme accelerated by limited-memory BFGS steps. It performs
proximal gradient iterations with a backtracking linesearch, and then 20 quasi-Newton
steps computed using the proximal gradient method. ZeroFPR is similar, but takes a
ﬁxed number of quasi-Newton steps between each proximal gradient step; it defaults to
proximal gradient descent if no progress is made during the inner quasi-Newton steps.
To compare, we count gradient evaluations as well as proximal operator evaluations,
but note that in our example problems, proximal evaluations are far cheaper.
In the following experiments, we set ψ(s; xk) := h(xk + s). Our stopping criteria
for Algorithm 3.1 is the ﬁrst-order error measure ξ(∆; xk) deﬁned in (3.6). We set
∆0 := 1.0. We compute trust-region steps using the proximal-gradient method with
step length chosen as in Corollary 4.3, but the user can choose accelerated variants
for the subproblem. We use proximal operators that include both ψ(·; xk) and the
indicator of the trust region as described in section 5. The criticality measure used in
the inner iterations is set to be the squared-norm of the subgradient (4.2b), which is
standard in the literature [2], and we set the inner tolerance to
min(0.01, ∥ν−1sk,1∥
1
2 ) ∥ν−1sk,1∥,
which is inspired from inexact Newton methods to encourage fast local convergence.
We use automatic diﬀerentiation as implemented in the Zygote package [24] to
obtain ∇f(x) and construct limited-memory quasi-Newton approximations by way of
the LinearOperators package [35]. Below, we use LSR1 approximations with memory 5.
7.1. LASSO/BPDN. The ﬁrst set of experiments concerns LASSO/basis pur-
suit de-noise (BPDN) problems, which arise in statistical [43] and compressed sensing
[18] applications. We seek to recover a sparse signal xtrue ∈Rn given observed noisy
data b ∈Rm. We set m = 200, n = 512, b := Axtrue + ε where ε ∼N(0, .01) and A
to have orthonormal rows—AT is generated by taking the Q factor in the thin QR
decomposition of a random n×m matrix. To recover x, we solve
(7.1)
minimize
x
1
2∥Ax −b∥2
2 + h(x).
We ﬁrst consider h(x) = λ∥x∥p for p ∈{0, 1} with λ = 0.1∥AT b∥∞in the vein of
van den Berg and Friedlander [44], and employ both the ℓ2 and ℓ∞norms to deﬁne
the trust region. We also consider h(x) = χ(x; λB0) with λ = 10 and an ℓ∞-norm
trust region. We set the maximum inner iterations to 1000, although this limit is never
reached, and ϵ = 10−6. The quasi-Newton model is deﬁned by a limited-memory SR1
approximation with memory 5. All algorithms are initialized at the origin.
Table 7.1 and Figure 7.1 summarize our results. Table 7.1 shows that Algorithm 3.1
performs comparably to PANOC and ZeroFPR in terms of parameter ﬁt, it performs
signiﬁcantly fewer gradient evaluations and signiﬁcantly more proximal operator
evaluations. Thus there is an advantage when proximal evaluations are cheap relative
to gradient evaluations, especially in situations where the proximal operator of ψ
is simpler or cheaper than that of h. All algorithms yield nearly identical solution
quality. The objective value history in Figure 7.1 shows a steeper initial decrease for
Algorithm 3.1 with shorter tails in all cases.
Cahier du GERAD G-2021-12
Commit bd54cde by Robert Baraldi on 2021-04-02 10:15:10 -0700

24
[toc]
0
100
200
300
400
500
−1.0
−0.5
0.0
0.5
1.0
x - index
True
TR
PANOC
ZFP
(a) Basis: h = ∥· ∥1, ∆B2
0
25
50
75
100
10−1.2
10−1.0
10−0.8
10−0.6
10−0.4
10−0.2
100.0
100.2
kth ∇f call
Objective Value
TR
PANOC
ZFP
(b) History: h = ∥· ∥1, ∆B2
0
100
200
300
400
500
−1.0
−0.5
0.0
0.5
1.0
x - index
True
TR
PANOC
ZFP
(c) Basis: h = ∥· ∥0, ∆B∞
0
10
20
30
40
50
60
10−1.2
10−1.0
10−0.8
10−0.6
10−0.4
10−0.2
100.0
100.2
kth ∇f call
Objective Value
TR
PANOC
ZFP
(d) History: h = ∥· ∥0, ∆B∞
0
100
200
300
400
500
−1.0
−0.5
0.0
0.5
1.0
x - index
True
TR
PANOC
ZFP
(e) Basis: h = χ(·; λB0), ∆B∞
5
10
15
20
10−2.0
10−1.5
10−1.0
10−0.5
100.0
kth ∇f call
Objective Value
TR
PANOC
ZFP
(f) History: h = χ(·; λB0), ∆B∞
Fig. 7.1. BPDN results (7.1) with Algorithm 3.1 (TR), PANOC and ZeroFPR (ZFP): basis
plots (left) and objective value history (right). ∆Bp indicates the norm used to deﬁne the trust region.
Table 7.1
BPDN results (7.1) with Algorithm 3.1 (TR), PANOC and ZeroFPR (ZFP). ∆Bp indicates the
norm used in the trust region. The true value of h is 10 for ∥· ∥1 and ∥· ∥0, but 0 for χ(·; λB0).
h = ∥· ∥1, ∆B2
h = ∥· ∥0, ∆B∞
h = χ(·; λB0), ∆B∞
True
TR
PANOC
ZFP
TR
PANOC
ZFP
TR
PANOC
ZFP
f(x)
0.011
0.002
0.002
0.002
0.010
0.010
0.010 0.010
0.010
0.010
h(x)
10/0
10.891
10.892
10.892
10
10
10
0
0
0
∥x −x0∥2/∥A∥
0
0.145
0.146
0.146
0.053
0.053
0.053 0.053
0.053
0.053
∇f evals
23
121
66
17
61
31
6
20
14
proxνψ calls
793
61
64
162
32
29
74
10
12
Commit bd54cde by Robert Baraldi on 2021-04-02 10:15:10 -0700
Cahier du GERAD G-2021-12

[toc]
25
7.2. A nonlinear inverse problem. We next consider an inverse problem
consisting in recovering the regularized solution to a system of nonlinear ODEs.
We seek parameters xtrue ∈Rn given observed noisy data b = F(xtrue) + ε where
F : Rn →Rm and ε ∼N(0, 0.1). The data generating mechanism F is given by the
FitzHugh [20] and Nagumo et al. [33] model for neuron activation
(7.2)
dV
dt = (V −V 3/3 −W + x1)x−1
2 ,
dW
dt = x2(x3V −x4W + x5),
which, if x1 = x4 = x5 = 0, becomes the Van der Pol [45] oscillator
(7.3)
dV
dt = (V −V 3/3 −W)x−1
2 ,
dW
dt = x2(x3V ).
Both models are highly nonlinear and ill-conditioned.
We use initial conditions (V, W) = (2, 0) and discretize the time interval [0, 20]
at 0.2 second increments. For given x, let V (t; x) and W(t; x) be solutions of (7.2).
Deﬁne variables vi(x) ≈V (ti; x), wi(x) ≈W(ti; x), i = 1, . . . , n + 1 where n =
20/0.2 = 100. We set F(x) := (v(x), w(x)), where v(x) := (v1(x), . . . , vn+1(x)) and
w(x) := (w1(x), . . . , wn+1(x)). We generate b using xtrue = (0, 0.2, 1, 0, 0), which
corresponds to a solve of the Van der Pol oscillator. To recover x, we solve
(7.4)
minimize
x
1
2∥F(x) −b∥2
2 + h(x),
with h(x) = ∥x∥0. ODE solves are performed with the DiﬀerentialEquations.jl package
[38], which features an mechanism for choosing the solver, and provides ∇v(x) and
∇w(x) by way of automatic diﬀerentiation. We set ϵ = 10−3 in all methods.
Table 7.2 summarizes our results and Figure 7.2 shows overall data ﬁt and objective
function traces. Both Algorithm 3.1 and ZeroFPR correctly identiﬁed the nonzero
pattern of x with reasonable error in the nonzero elements. PANOC performs well
initially, but its linesearch routine terminates prematurely as it generates a step length
that is below a preset tolerance of 10−7. At that point, PANOC terminates. ZeroFPR
performs well, but needs many iterations to decrease the objective value to the same
level as Algorithm 3.1. As in section 7.1, Algorithm 3.1 converges with signiﬁcantly
fewer gradient evaluations than ZeroFPR, though with a signiﬁcant number of proximal
operator evaluations. However, gradient evaluations in (7.2) are far more expensive
and time consuming that proximal evaluations. Figure 7.2 also reveals that the ﬁnal
iterate generated by Algorithm 3.1 and ZeroFPR results in trajectories that are visually
indistinguishable from those associated with the exact solution.
We also compare Algorithm 6.1 to our own implementation of a standard proximal
gradient with linesearch (PG) on (7.4). We set the stopping tolerance for both to 10−6.
Table 7.3 summarizes our results and Figure 7.3 shows overall data ﬁt and objective
function traces. Both Algorithm 6.1 and PG converge much slower than Algorithm 3.1,
where we use curvature information. Neither algorithm correctly identiﬁed the nonzero
pattern of x within 5000 iterations, although Algorithm 6.1 descends considerably faster
than PG. Gradient evaluations in (7.2) are far more expensive and time consuming
that proximal evaluations. Whereas Algorithm 6.1 requires exactly as many proximal
evaluations as gradient calls, PG requires more proxνψ calls during its linesearch.
Figure 7.3 reveals that the ﬁnal iterate generated by Algorithm 6.1 is closer to the
solution than that of PG, though both terminated far from the correct answer.
Cahier du GERAD G-2021-12
Commit bd54cde by Robert Baraldi on 2021-04-02 10:15:10 -0700

26
[toc]
Table 7.2
Results for Algorithm 3.1 applied to (7.2) with h = ∥· ∥0, ∆B∞and LSR1 approximation.
Parameters
True
TR
PANOC
ZFP
Function
True
TR
PANOC
ZFP
0
0
0.728
0
f(x)
1.090
1.112
57.947
1.084
0.2
0.211
0.586
0.191
h(x)
2
2
5
2
1.0
0.959
0.938
1.036
||x −x0||2
0
0.042
1.526
0.037
0
0
0.953
0
∇f evals
116
47
292
0
0
0.859
0
proxνψ calls
34650
47
291
0
5
10
15
20
−2
−1
0
1
2
Time
Voltage
Data-V
Data-W
True-V
True-W
TR-V
TR-W
PANOC-V
PANOC-W
ZFP-V
ZFP-W
(a) Solution with data
0
100
200
300
100.5
101.0
101.5
102.0
kth ∇f call
Objective Value
TR
PANOC
ZFP
(b) Objective Function (7.4) history
Fig. 7.2. Solution of (7.2) with h(x) = λ∥x∥0 in (7.4), ∆B∞and LSR1 approximation.
Table 7.3
Results for Algorithm 6.1 applied to (7.2) with h = ∥· ∥0.
Parameters
True
QR
PG
Function
True
QR
PG
0
0
0.238
f(x)
1.090
4.143
27.249
0.2
0.149
0.263
h(x)
2
4
5
1.0
1.343
1.051
||x −x0||2
0
0.692
1.062
0
0.599
0.928
∇f evals
5000
5000
0
0.019
0.450
proxνψ calls
5000
5026
0
5
10
15
20
−2
−1
0
1
2
Time
Voltage
Data-V
Data-W
True-V
True-W
QR-V
QR-W
PG-V
PG-W
(a) Solution with data
0
1000
2000
3000
4000
5000
101.0
101.2
101.4
101.6
101.8
102.0
102.2
kth ∇f call
Objective Value
QR
PG
(b) Objective Function (7.4) history
Fig. 7.3. Solution of (7.2) for h = λ∥· ∥0 in (7.4) with Algorithm 6.1.
Commit bd54cde by Robert Baraldi on 2021-04-02 10:15:10 -0700
Cahier du GERAD G-2021-12

[toc]
27
8. Discussion and perspectives. We demonstrated the performance of trust-
region methods using nonconvex LSR1 quasi-Newton models against two linesearch
methods using LBFGS models, and observed faster convergence curves with fewer
gradient evaluations. Many regularizers in (1.1) have a closed-form or eﬃciently-
computable proximal operator, whose cost is often dominated by that of a function or
gradient evaluation in a large inverse problem.
The worst-case iteration complexity bound of Algorithm 3.1 matches the best
known bound for trust-region methods in smooth optimization. Algorithm 6.1, a
ﬁrst-order method that is related to the proximal gradient method with adaptive
steplength, does not require prior knowledge or estimation of a Lipschitz constant, and
has a straightforward complexity analysis similar to that of Algorithm 3.1. In practice,
using curvature information in Algorithm 3.1 proved useful for eﬃciently estimating
highly nonlinear nonsmooth models. Convergence of trust-region methods for smooth
optimization can be established even if Hessian approximations are unbounded, pro-
vided they do not deteriorate too fast. It may be possible to generalize our analysis
along similar lines.
Interesting directions left to future work include implementation and analysis
for inexact function, gradient, and proximal operator evaluations, and extensions of
our results to cubic regularization, and more general nonlinear stepsize control-type
methods, such as those of [22].
References.
[1] A. Aravkin and D. Davis. Trimmed statistical estimation via variance reduction. Math. Oper.
Res., 45(1):292–322, 2020.
[2] H. Attouch, J. Bolte, and B. F. Svaiter. Convergence of descent methods for semi-algebraic and
tame problems: proximal algorithms, forward–backward splitting, and regularized Gauss-Seidel
methods. Math. Program., 137(1-2):91–129, 2013.
[3] R. Baraldi, R. Kumar, and A. Aravkin. Basis pursuit denoise with nonsmooth constraints. IEEE
T. Signal Proces., 67(22):5811–5823, 2019.
[4] H. H. Bauschke and P. L. Combettes. Convex Analysis and Monotone Operator Theory in
Hilbert Spaces. Springer Science, 2011.
[5] A. Beck. First Order Methods in Optimization. SIAM, Philadelphia, USA, 2017.
[6] J. Bezanson, A. Edelman, S. Karpinski, and V. B. Shah. Julia: A fresh approach to numerical
computing. SIAM Rev., 59(1):65–98, 2017.
[7] T. Blumensath and M. E. Davies. Iterative hard thresholding for compressed sensing. Appl.
Comput. Harmon. A., 27(3):265–274, 2009.
[8] J. Bolte, S. Sabach, and M. Teboulle. Proximal alternating linearized minimization for nonconvex
and nonsmooth problems. Math. Program., (146):459—-494, 2014.
[9] R. I. Bot¸, E. R. Csetnek, and S. L´aszl´o.
An inertial forward–backward algorithm for the
minimization of the sum of two nonconvex functions. EURO J. Comput. Optim., (4):3–25, 2016.
[10] C. Cartis, N. I. M. Gould, and Ph. L. Toint. On the evaluation complexity of composite function
minimization with applications to nonconvex nonlinear programming. SIAM J. Optim., 21(4):
1721–1739, 2011.
[11] P. L. Combettes and J.-C. Pesquet. Proximal splitting methods in signal processing. In Fixed-
point algorithms for inverse problems in science and engineering, pages 185–212. Springer,
2011.
[12] A. R. Conn, N. I. M. Gould, and Ph. L. Toint. Convergence of quasi-Newton matrices generated
by the symmetric rank one update. Math. Program., 50(1):177–195, Mar 1991.
[13] A. R. Conn, N. I. M. Gould, and Ph. L. Toint. Trust-Region Methods. Number 1 in MOS-SIAM
Series on Optimization. SIAM, Philadelphia, USA, 2000.
[14] F. Curtis, Z. Lubberts, and D. Robinson. Concise complexity analyses for trust region methods.
Optim. Lett., (12):1713—-1724, 2018.
[15] F. E. Curtis, D. P. Robinson, and M. Samadi. A trust region algorithm with a worst-case
iteration complexity of O(ϵ−3/2) for nonconvex optimization. Math. Program., Series A, (162):
1–32, 2017.
[16] J. Dennis, S. Li, and R. Tapia. A uniﬁed approach to global convergence of trust region methods
for nonsmooth optimization. Math. Program., (68):319—-346, 1995.
[17] J. E. Dennis Jr. and H. H. W. Mei. Two new unconstrained optimization algorithms which use
Cahier du GERAD G-2021-12
Commit bd54cde by Robert Baraldi on 2021-04-02 10:15:10 -0700

28
[toc]
function and gradient values. J. Optim. Theory and Applics., 28:453—-482, 1979.
[18] D. L. Donoho. Compressed sensing. IEEE T. Inform. Theory, 52(4):1289–1306, 2006.
[19] J. Fan and R. Li. Variable selection via nonconcave penalized likelihood and its oracle properties.
J. Am. Stat. Assoc., 96(456):1348–1360, 2001.
[20] R. FitzHugh. Mathematical models of threshold phenomena in the nerve membrane. B. Math.
Biophys., 17(4):257–278, 1955.
[21] H.-Y. Gao and A. G. Bruce. Waveshrink with ﬁrm shrinkage. Stat. Sinica, 7:855–874, 1997.
[22] G. Grapiglia, J. Yuan, and Y. Yuan. Nonlinear stepsize control algorithms: Complexity bounds
for ﬁrst- and second-order optimality. J. Optim. Theory and Applics., (171):980––997, 2016.
[23] W. Hare and C. Sagastiz´abal.
Computing proximal points of nonconvex functions.
Math.
Program., 116(1):221–258, Jan 2009.
[24] M. Innes.
Don’t unroll adjoint:
Diﬀerentiating SSA-form programs.
Technical Report
abs/1810.07951, CoRR, 2018. http://arxiv.org/abs/1810.07951.
[25] D. Kim, S. Sra, and I. S. Dhillon.
A scalable trust-region algorithm with application to
mixed-norm regression. In ICML, pages 519–526, 2010.
[26] J. D. Lee, Y. Sun, and M. A. Saunders. Proximal Newton-type methods for minimizing composite
functions. SIAM J. Optim., 24(3):1420–1443, 2014.
[27] H. Li and Z. Lin. Accelerated proximal gradient methods for nonconvex programming. In
Proceedings of the 28th International Conference on Neural Information Processing Systems -
Volume 1, NIPS’15, pages 379–387, Cambridge, MA, USA, 2015. MIT Press.
[28] P. Lions and B. Mercier. Splitting algorithms for the sum of two nonlinear operators. SIAM J.
Numer. Anal., 16(6):964—-979, 1979.
[29] S. Lotﬁ, T. Bonniot de Ruisselet, D. Orban, and A. Lodi. Stochastic damped L-BFGS with
controlled norm of the Hessian approximation. 2020. OPT2020 Conference on Optimization for
Machine Learning.
[30] X. Lu. A Study of the Limited-Memory SR1 Method in Practice. Phd thesis, University of
Colorado, 1996.
[31] J. M. Mart´ınez and A. C. Moretti. A trust region method for minimization of nonsmooth
functions with linear constraints. Math. Program., (76):431–449, 1997.
[32] J. J. Mor´e and D. C. Sorensen. Computing a trust region step. SIAM J. Sci. and Statist.
Comput., 4(3):553–572, 1983.
[33] J. Nagumo, S. Arimoto, and S. Yoshizawa. An active pulse transmission line simulating nerve
axon. Proceedings of the IRE, 50(10):2061–2070, 1962.
[34] Y. Nesterov. Modiﬁed Gauss–Newton scheme with worst case guarantees for global performance.
Optim. Method Softw., 22(3):469–483, 2007.
[35] D. Orban and A. S. Siqueira. Linearoperators.jl., February 2019.
[36] M. J. D. Powell. A new algorithm for unconstrained optimization. In J. Rosen, O. Mangasarian,
and K. Ritter, editors, Nonlinear Programming, pages 31–65. Academic Press, 1970.
[37] L. Qi and J. Sun. A trust region algorithm for minimization of locally Lipschitzian functions.
Math. Program., (66):25—-43, 1994.
[38] C. Rackauckas and Q. Nie. Diﬀerentialequations.jl–a performant and feature-rich ecosystem for
solving diﬀerential equations in Julia. J. Open Res. Softw., 5(1), 2017.
[39] R. Rockafellar and R. Wets. Variational Analysis, volume 317. Springer Verlag, 1998.
[40] T. Steihaug. The conjugate gradient method and trust regions in large scale optimization. SIAM
J. Numer. Anal., 20(3):626–637, 1983.
[41] L. Stella, A. Themelis, P. Sopasakis, and P. Patrinos. A simple and eﬃcient algorithm for
nonlinear model predictive control. In 2017 IEEE 56th Annual Conference on Decision and
Control (CDC), pages 1939–1944, 2017.
[42] A. Themelis, L. Stella, and P. Patrinos. Forward-backward envelope for the sum of two nonconvex
functions: Further properties and nonmonotone linesearch algorithms. SIAM J. Optim., 28(3):
2274–2303, 2018.
[43] R. Tibshirani. Regression shrinkage and selection via the lasso. J. Roy. Statist. Soc. Ser. B, 58
(1):267–288, 1996.
[44] E. van den Berg and M. P. Friedlander. Probing the pareto frontier for basis pursuit solutions.
SIAM J. Sci. Comput., 31(2):890–912, Nov. 2008. ISSN 1064-8275.
[45] B. Van der Pol. Lxxxviii. On “relaxation-oscillations”. The London, Edinburgh, and Dublin
Philosophical Magazine and Journal of Science, 2(11):978–992, 1926.
[46] Y.-X. Yuan. Conditions for convergence of trust region algorithms for nonsmooth optimization.
Math. Program., (31):220––228, 1985.
[47] C.-H. Zhang et al. Nearly unbiased variable selection under minimax concave penalty. Ann.
Stat., 38(2):894–942, 2010.
[48] P. Zheng and A. Aravkin. Relax-and-split method for nonconvex inverse problems. Inverse
Commit bd54cde by Robert Baraldi on 2021-04-02 10:15:10 -0700
Cahier du GERAD G-2021-12

[toc]
29
Problems, 36(9):095013, 2020.
[49] P. Zheng, T. Askham, S. L. Brunton, J. N. Kutz, and A. Y. Aravkin. A uniﬁed framework for
sparse relaxed regularized regression: SR3. IEEE Access, 7:1404–1423, 2018.
Contents.
1
Introduction
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
2
Preliminaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4
2.1
Smooth context
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4
2.2
Nonsmooth context
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4
2.3
Optimality conditions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5
2.4
The proximal gradient method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5
3
Trust-region methods for nonsmooth regularized optimization . . . . . . . . . . . . . .
6
3.1
Properties of trust-region subproblems . . . . . . . . . . . . . . . . . . . . . . . . . .
6
3.2
Optimality measures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
7
3.3
A trust-region algorithm
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
9
3.4
Convergence analysis and iteration complexity . . . . . . . . . . . . . . . . . . . . .
10
4
Proximal-quasi-Newton trust-region method . . . . . . . . . . . . . . . . . . . . . . . .
14
4.1
Computing a trust-region step
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
14
4.2
Ensuring boundedness of Hessian approximations
. . . . . . . . . . . . . . . . . . .
17
5
Proximal Operators for Trust-Region Subproblems . . . . . . . . . . . . . . . . . . . .
17
5.1
p = ∞, h separable . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
18
5.2
p = 2, h(x) = λ∥x∥1
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
19
6
A quadratic regularization variant
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
20
7
Implementation and numerical results . . . . . . . . . . . . . . . . . . . . . . . . . . .
23
7.1
LASSO/BPDN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
23
7.2
A nonlinear inverse problem
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
25
8
Discussion and perspectives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
27
Cahier du GERAD G-2021-12
Commit bd54cde by Robert Baraldi on 2021-04-02 10:15:10 -0700

