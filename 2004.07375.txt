A Practical Introduction to Bayesian Estimation of Causal Eﬀects:
Parametric and Nonparametric Approaches
Arman Oganisian*1 | Jason A. Roy2
1Department of Biostatistics, Epidemiology,
and Informatics, University of
Pennsylvania, Pennsylvania, USA
2Department of Biostatistics and
Epidemiology, Rutgers University, New
Jersey, USA
Correspondence
*Email: aoganisi@upenn.edu
Present Address
Room 108, Blockley Hall, 423 Guardian
Drive, Philadelphia, PA, USA 19104.
Summary
Substantial advances in Bayesian methods for causal inference have been made in
recent years. We provide an introduction to Bayesian inference for causal eﬀects
for practicing statisticians who have some familiarity with Bayesian models and
would like an overview of what it can add to causal estimation in practical set-
tings. In the paper, we demonstrate how priors can induce shrinkage and sparsity in
parametric models and be used to perform probabilistic sensitivity analyses around
causal assumptions. We provide an overview of nonparametric Bayesian estima-
tion and survey their applications in the causal inference literature. Inference in the
point-treatment and time-varying treatment settings are considered. For the latter, we
explore both static and dynamic treatment regimes. Throughout, we illustrate imple-
mentation using oﬀ-the-shelf open source software. We hope to leave the reader with
implementation-level knowledge of Bayesian causal inference using both parametric
and nonparametric models. All synthetic examples and code used in the paper are
publicly available on a companion GitHub repository.
KEYWORDS:
Bayesian, causal inference, g-computation, confounding, bayesian nonparametric, Dirichlet process,
BART, Gaussian process
1
INTRODUCTION
Causal inference is broadly concerned with estimating parameters governing the causal mechanisms between an intervention or
treatment of interest and an outcome. These causal parameters can diﬀer substantially from associational ones. Causal inference
provides a framework for 1) constructing diﬀerent estimands that have explicitly causal, rather than associational, interpretations
2) formulating the assumptions under which we can estimate these using observed data, 3) devising sensitivity analyses around
violations of these assumptions, and 4) making inferences about these causal estimands via statistical modeling. These are just
some of the many contributions of the causal inference literature, which we will touch on throughout this paper.
Bayesian modeling in causal inference has been growing in popularity. There are perhaps several reasons for this phenomenon.
First, Bayesian modeling yields full posterior inference for any function of model parameters. For instance, point and interval
estimates can be easily constructed for causal risk ratios, odds ratios, and risk diﬀerences by post-processing a single set of
posterior draws from logistic regression model. Another advantage is the use of priors to induce shrinkage and sparsity in
causal models - yielding more regularized causal eﬀect estimates. We show that these can be more satisfying than the ad-hoc
alternatives often employed. Priors can also be used to conduct probabilistic sensitivity analyses around violations of key causal
identiﬁcation assumptions. Finally, the Bayesian literature consists of a large suite of nonparametric models that can be readily
arXiv:2004.07375v2  [stat.ME]  21 Aug 2020

2
Oganisian ET AL
applied to causal modeling. These nonparametric approaches are appealing because, unlike many classical machine learning
algorithms, they allow for posterior uncertainty estimation as well as robust point estimates.
We begin with an overview of the causal identiﬁcation and the Bayesian linear model before moving to confounder adjust-
ment via standardization in the point-treatment setting. Here we highlight how priors can be used to induce shrinkage in a causal
dose eﬀect curve and partially pool conditional average treatment eﬀect estimates across sparsely populated subgroups. Par-
tial pooling shrinks the heterogeneous eﬀects across subgroups towards an overall homogenous eﬀect in the absence of data.
We introduce the Bayesian bootstrap as a method for performing standardization. Next, we move to the time-varying treatment
and confounding setting where we discuss Bayesian 푔-computation with priors that promote sparsity. Causal inference in these
settings requires estimation of a large number of nuisance parameters. Priors that regularize these estimates by encouraging
sparsity can be an attractive alternative to common modeling assumptions, which can be quite strict. Estimation for both static
and dynamic treatment regimes are discussed. We then turn to using priors for causal sensitivity analyses. These follow from
expressing violations of causal assumptions in terms of non-identiﬁable parameters, then conveying uncertainty about the mag-
nitude/direction of the violation via priors on these parameters. We end with a discussion of Bayesian nonparametric causal
estimation. We discuss Dirichlet process priors, Bayesian Additive Regression Trees, Gaussian processes and survey their appli-
cations to causal problems. Throughout, we present several pedagogical examples using publicly available synthetic data. We
hope to demonstrate how readily these models can be implemented using existing software. A companion GitHub3 repository
contains all relevant implementation code that reproduce the results in this paper.
2
INGREDIENTS OF BAYESIAN CAUSAL INFERENCE
2.1
Causal Estimands and Identiﬁcation Assumptions
In order to make causal inferences, we ﬁrst need to deﬁne and identify the causal estimand. After doing so, we will turn to
the statistical problem of actually making inferences about this estimand. Consider estimation of the causal eﬀect of a binary
treatment assignment 퐴∈{0, 1} on some observed scalar outcome 푌. In this paper, we formulate estimands in terms of
potential outcome 푌푎1. This represents the outcome that would have been observed had a subject received treatment 퐴= 푎.
For subjects receiving treatment 퐴= 푎, we never observe their counterfactual outcome, 푌1−푎. If we did observe both potential
outcomes, we could estimate each subject’s individual-level eﬀects by taking the diﬀerence 푌1 −푌0. This is the diﬀerence in
outcome had the subject taken treatment 1 versus 0. We could also estimate a population-level average treatment eﬀect (ATE),
Ψ = 퐸[푌1] −퐸[푌0], directly by simply taking the sample average of the diﬀerence, 푌1 −푌0, across all subjects. The ATE is
interpreted as the average diﬀerence in the outcome had everyone in the target population received treatment 퐴= 1 rather than
퐴= 0. In absence of the counterfactual, we cannot estimate the individual-level eﬀects and can only estimate Ψ under certain
identiﬁcation assumptions (퐼퐴s).
To understand the role of these assumptions, it is helpful to consider the data we actually observe. Along with 푌(note the
lack of superscript) and 퐴, we observe a vector of confounders 퐿- these are variables, measured pre-treatment, that impact
both treatment assignment and outcome. Thus, we could estimate the conditional outcome mean, or regression, 퐸[푌∣퐴, 퐿]
directly from observed data. The aforementioned identiﬁcation assumptions are required to express Ψ - the diﬀerence in average
unobserved potential outcomes - in terms of 퐸[푌∣퐴= 1, 퐿]−퐸[푌∣퐴= 0, 퐿] - the average diﬀerence in conditional outcome
means between the two treatment groups. Identiﬁcation refers precisely to this process of expressing (“identifying”) estimands
such as Ψ in terms of observed data. In this setting with a single baseline treatment, the standard 퐼퐴s2 are
퐼퐴.1: Conditional ignorability: 푌푎⟂퐴∣퐿.
퐼퐴.2: Consistency: 푃(푌푎= 푌∣퐴= 푎) = 1, ∀푎.
퐼퐴.3: No interference: 푌푎1∶푛
푖
= 푌푎푖
푖.
퐼퐴.4: Positivity: 0 < 푃(퐴= 1 ∣퐿) < 1, ∀퐿∈.
Above, 푎1∶푛= (푎1, 푎2, … , 푎푖, … , 푎푛) is a vector of treatment interventions for each of 푛observed subjects and 푌푎1∶푛
푖
represents
subject 푖’s potential outcome had each subject received their corresponding treatments in 푎1∶푛. 퐼퐴.1 requires that pre-treatment
3https://github.com/stablemarkets/intro_bayesian_causal

Oganisian ET AL
3
variables 퐿fully capture the confounding between treatment and outcome. That is, conditioning on 퐿renders the potential
outcome under a particular treatment, 푌푎, independent of the observed treatment assignment, 퐴. This can be violated if, for
instance, we fail to condition on some confounder, such as age, when in fact older subjects tend to be treated with treatment
퐴= 1 and are likely to have worse outcomes under this treatment, 푌1. It is important to note that conditioning on inappropriate
variables (e.g. colliders or post-treatment variables) may also lead to ignorability violations3. In this paper, we will discuss ways
to perform sensitivity analyses around violations of this assumption.
Consistency, 퐼퐴.2, requires that the treatment be well-deﬁned in terms of a clear intervention4. For example, suppose 퐴is
high/low blood pressure and 푌is myocardial infarction. The outcome that occurs in a world where we intervene directly to lower
blood pressure is likely not the outcome that would have occurred had everyone in the population had low blood pressure. This is
because the mechanism by which we set blood pressure likely itself aﬀects the outcome. Whether blood pressured was lowered
via changes in lifestyle (exercise, better eating habits, etc) versus medication probably impacts the outcome. For this reason,
consistency is often described as requiring that there is only “one version” of the treatment. A more well-deﬁned intervention
may be blood pressure medication use (versus no use). Other canonical examples of ill-deﬁned exposures include race and BMI5.
퐼퐴.3 states that no subject’s treatment assignment should aﬀect another’s potential outcome. Formally, the 푖푡ℎsubject’s poten-
tial outcome under intervention 퐴푖= 푎, 푌푎푖
푖, need not be indexed by the other 푛−1 subjects’ interventions in the superscript.
Hence, we can simplify 푌푎1∶푛
푖
to just 푌푎푖
푖. This assumption is often violated if subjects are not independent. For example, a study
of the eﬀect of prophylactic antivirals on infection using data from patients in the same hospital may suﬀer from interference:
the antiviral treatment of subjects roomed together aﬀect each other’s infection probability. For concreteness, consider two such
patients, 푖and 푗, with potential infection status, 푌
푎푖,푎푗
푖
and 푌
푎푖,푎푗
푗
, respectively. Here, intervention 푎= 1 indicates antiviral ther-
apy and 푎= 0 indicates control. If the infection is contagious, it may be the case that 푃(푌0,1
푖
) < 푃(푌0,0
푖
). Even if subject 푖is
untreated, their infection probability would likely be lower had their neighbor, subject 푗, been treated. Since we cannot speak of
subject 푖’s outcome separately from subject 푗’s treatment, we cannot drop 푎푗from the superscript in 푌
푎푖,푎푗
푖
. Causal inference in
these settings is more complicated and an active area of research6.
Finally, 퐼퐴.4 requires that the treatment probability be bounded so that there is no subset of the population in terms of 퐿
for whom treatment is deterministic. Intuitively, if treatment assignment was deterministic for a subpopulation of individuals,
we would have no data about that group’s outcome under the other treatment condition. Positivity violations can occur at the
population level (e.g. protocols forbidding treatment 푎for subjects over a certain age) or at the sample level due to small sample
size (e.g. we observe no male diabetics with treatment 푎). The former are sometimes called structural violations and the latter
are called random violations of positivity in the literature.
Using these assumptions we can identify both expectations in Ψ. First, under 퐼퐴.3, 퐸[푌푎1∶푛
푖
] = 퐸[푌푎푖
푖]. Omitting subscripts
for compactness,
퐸[푌푎] = ∫

퐸[푌푎∣퐿] 푑푃(퐿)
= ∫

퐸[푌푎∣퐴= 푎, 퐿] 푑푃(퐿)
= ∫

퐸[푌∣퐴= 푎, 퐿] 푑푃(퐿)
(1)
The ﬁrst equality follows from iterated expectation over 퐿. We use to denote the space of 퐿. From 퐼퐴.1, we know that the
potential outcome is independent of assignment conditional on 퐿, which allows us to condition on 퐴= 푎in the second equality.
퐼퐴.4 ensures that we are not conditioning on a zero-probability event. Lastly, 퐼퐴.2 allows us to drop the superscript. Intuitively,
(1) identiﬁes the average potential outcome as a regression model (under intervention 퐴= 푎) that is averaged over the marginal
confounder distribution. Computing marginal causal eﬀect using this expression is called standardization. In this way, we have
identiﬁed each term of Ψ in terms a regression that is estimable from observed data.

4
Oganisian ET AL
2.2
Statistical Assumptions
Equation (1) usually requires statistical/modeling assumptions about the regression, 퐸[푌∣퐴, 퐿]. As an example, consider
substituting a linear regression model 퐸[푌∣퐴, 퐿] = 휃퐴+ 퐿′훽(where an intercept is included in 퐿). Then, under the 퐼퐴s,
standardization yields
Ψ = ∫

퐸[푌∣퐴= 1, 퐿, 휔] −퐸[푌∣퐴= 0, 퐿, 휔]푑푃(퐿)
= ∫

{(휃+ 퐿′
푖훽) −(퐿′
푖훽)}푑푃(퐿) = 휃.
(2)
In this special case, the ATE, Ψ, is equal to the treatment indicator coeﬃcient, 휃. Thus, an estimate of this coeﬃcient is an
estimate of the ATE. In the non-linear examples discussed later, 퐿′
푖훽will not cancel out as it did above and a probability model
for 푝(퐿) will be necessary to evaluate the integral.
2.3
Bayesian Modeling
Bayesian causal inference combines Bayesian modeling with the 퐼퐴s discussed to compute a posterior distribution over causal
estimands. In this section we introduce these key ideas, which will be expanded in future sections. Throughout much of the
paper, we assume that 퐼퐴s hold to keep focus on the added beneﬁt of Bayesian modeling.
Suppose we observe data 퐷= {푌푖, 퐴푖, 퐿푖}푖=1∶푛on 푛independent subjects, where 퐴푖∈{0, 1} is a binary treatment indicator, 퐿푖
is a vector of confounders (including an intercept), and 푌푖is the scalar outcome of interest, as deﬁned earlier. Bayesian inference
requires both a probability model for the conditional distribution of the outcome, 푌, (a likelihood) as well as a probability
distribution over the unknown parameter vector, 휔, governing this conditional distribution (i.e. a prior). Inference then follows
from making probability statements about 휔having conditioned on 퐷(via the posterior). From Bayes’ rule we have that the
posterior is proportional to the likelihood times the prior, 푝(휔∣퐷) ∝푝(휔) ∏
푖푝(푌푖∣퐴푖, 퐿푖, 휔).
For instance, if 푌푖is real-valued, we could specify a Gaussian outcome model with conditional mean 휃퐴푖+ 퐿′
푖훽and variance
휙: 푝(푌푖∣퐴푖, 퐿푖, 휔) = 푁(푌푖∣휃퐴푖+ 퐿′
푖훽, 휙). We could also set a Normal-Inverse-Gamma prior on the parameter vector
휔= (휃, 훽, 휙), e.g. 푝(휔) = 푁(휃∣0, 1)푁(훽∣휇0, Σ0)퐼퐺(휙∣푎0, 푏0). This probability model induces a linear regression 퐸[푌∣
퐴푖, 퐿푖] = 휃퐴푖+퐿′
푖훽, where we drop explicit conditioning on the parameters. Now it remains to ﬁnd the posterior over the model
parameters, 푝(휔∣퐷) - which includes 휃. As we showed with the linear model in the previous section, the coeﬃcient 휃is the
ATE, Ψ. So a posterior over 휃is a posterior over Ψ. This simple example demonstrates a general Bayesian approach to causal
inference. First, identify the causal parameter of interest as a transformation of the model parameters. The 퐼퐴s required to achieve
this will vary by problem and strategy. Mediation7 and time-varying treatment8 settings will require extensions of the 퐼퐴s
discussed. Instrumental variables9, diﬀerence-in-diﬀerences10, and regression discontinuity11 strategies all involve their own
unique 퐼퐴s. Second, obtain the posterior distribution (or draws from it) of these model parameters which, after transformation,
yields a posterior over the causal estimand.
In practical settings, the posterior distribution, 푝(휔∣퐷) does not have known form - so that we cannot analytically ﬁnd the
posterior after specifying the likelihood and prior. As a result, inference is instead typically conducted using draws from the
posterior obtained via Markov Chain Monte Carlo (MCMC). Though a crucial topic and active area of research in itself, we omit
discussion of MCMC methods and keep focus on Bayesian estimation of causal eﬀects. We refer the reader to Andrieu et al.12
for an introduction to MCMC. For our purposes, it is enough to know that MCMC yields a set of 푀draws, {휔(푚)}1∶푀, from the
posterior 푝(휔∣퐷) given a speciﬁed likelihood and prior. Throughout, we assume we have suﬃciently many draws to closely
approximate the posterior. The mean or median of these samples can be used as a Bayesian point estimate of 휔. Percentiles of
these draws can be used for credible interval estimation (e.g. .025 and .975 percentiles for a 95% interval).
This paper relies mainly on Stan for MCMC sampling throughout. Stan is an open-source programming language for spec-
ifying Bayesian models using intuitive syntax. It back-ends to C++ to eﬃciently obtain posterior draws after a likelihood and
prior are speciﬁed. Stan programs are often called in R via the package rstan. For those unfamiliar with Stan and R, we provide
some guidance with SAS version 9.4 - a popular commercial statistical analysis software. Some of the nonparametric models to
be discussed cannot be handled in either Stan or SAS. For these models, we will rely on specialized R packages.

Oganisian ET AL
5
(a) Posterior estimates from (3) with prior (4) with 퐾= 10,
휇1 = 0, 휏1 = 10, and 휏푘= 1 for all 푘. The AR1 prior smooths
erratic MLEs by inducing correlation between neighboring
points on the curve.
(b) Posterior estimates of Ψ(푣) from (6) with partial pooling
prior of Section 3.2 with 푞= 5, a single confounder 푊, an
improper uniform prior on 휇, and 휏= .5. Posterior mean odds
ratio for each stratum are shrunk towards the overall causal
odds ratio (dotted line).
FIGURE 1 Estimates of dose eﬀect curve (Section 3.1) and partially pooled conditional causal odds ratios (Section 3.2) using
synthetic data.
2.4
Prior Information
As mentioned earlier, Bayesian inference requires speciﬁcation of a prior over the parameters, 푝(휔). Throughout this paper we
hope to illustrate that, rather than anchoring estimates to particular hard-coded values, priors can induce intricate correlation
structures between parameters. These correlation structures stabilize causal eﬀect estimates when data are sparse (as it often is in
scientiﬁc applications). This is often referred to as “shrinkage”. Priors can also be used to induce “sparsity” on whole parameter
vectors. Speciﬁcally, for high-dimensional vectors, we can place priors that express the belief that some portion of the vectors
are nearly zero. Priors can also be used to conduct probabilistic sensitivity analyses around causal identiﬁcation assumptions.
All of these are pragmatic motivations for taking a Bayesian approach to causal estimation, even if one is not a Bayesian “at
heart”. We will emphasize that, perhaps contrary to intuition, common frequentist approaches can often be seen as special cases
of these Bayesian estimators with very rigid priors.
3
PARAMETRIC MODELS IN POINT-TREATMENT SETTINGS
In the following sections, we outline two examples where a Bayesian approach to causal inference oﬀers unique beneﬁts in the
form of prior shrinkage. Although these examples use relatively simple parametric models, they reﬂect the general approach
and intuition of Bayesian causal inference and help motivate key tools such as the Bayesian bootstrap.
3.1
Causal Dose Eﬀects with AR1 Prior
Consider a setting where treatment consists of 퐾dose levels 퐴푖∈{0, 1, … , 퐾}, with 퐴푖= 0 indicating no treatment. Let
퐴푖푘= I(퐴푖= 푘) be an indicator that subject 푖was assigned to dose 푘∈{1, … , 퐾}. Here, we assume the dose values are ordered

6
Oganisian ET AL
so that they are increasing with 푘. That is, dose 푘+ 1 is higher than dose 푘. Consider a linear outcome model,
퐸[푌푖∣퐴, 퐿푖] = 휃0 + 퐿′
푖훽+
퐾
∑
푘=1
휃푘퐴푖푘.
(3)
Suppose our estimand of interest is a causal incremental dose eﬀect curve on Ψ(푘) = 퐸[푌퐴=푘] −퐸[푌퐴=푘−1]. This is a curve
as a function of dose, 푘. Each point on the curve is the causal eﬀect of increasing dose from level 푘−1 to level 푘. Under mild
extensions of 퐼퐴.1-퐼퐴.4 from the binary treatment setting to the multi-treatment setting we can again identify this estimand as
Ψ(푘) = 휃푘−휃푘−1 푘∈{2, … , 퐾}
Where the ﬁrst point is Ψ(1) = 휃1. We consider several prior choices for 휃1∶퐾and the induced prior on Ψ(푘). Throughout,
푢푎∶푏for intergers 푎< 푏denotes the vector 푢= (푢푎, … , 푢푏). A ﬁrst-pass approach may be to express prior independence and
factorize the joint prior as 푝(휃1∶퐾) = ∏퐾
푘=1 푝(휃푘). We could specify each term to be Gaussian centered at some prior mean, 휇푘,
and standard deviation, 휏푘. However, we can formulate more useful priors in this setting. The increasing dose levels may give
us prior reason to believe that the eﬀect of neighboring doses are actually correlated, not fully independent. This motivates an
alternative (dependent) prior factorization: 푝(휃1∶퐾) = 푝(휃1)푝(휃2 ∣휃1) ∏퐾
푘=3 푝(휃푘∣휃퐾−1, 휃퐾−2). Each term is speciﬁed as
휃1 ∼푁(휇1, 휏1)
휃2 ∣휃1 ∼푁(2휃1, 휏2)
휃푘∣휃푘−1, 휃푘−2 ∼푁(2휃푘−1 −휃푘−2, 휏푘),
푘> 2,
where 휇1, 휏1∶퐾are all hyperparameters that we can specify. Alternatively, we could specify hyperpriors for these parameters.
The above induces the following ﬁrst-order autoregressive (AR1) prior on the causal curve, Ψ(푘). For instance, the last line for
푘> 2 above implies that 휃푘−휃푘−1 ∣휃푘−1, 휃푘−2 ∼푁(휃푘−1 −휃푘−2, 휏푘). This follows from simply subtracting 휃푘−1 from 휃푘and its
mean. Using the deﬁnition of Ψ(푘), we see that this statement is equivalent to Ψ(푘) ∣휃푘−1, 휃푘−2 ∼푁(Ψ(푘−1), 휏푘). Extending
this logic, the hierarchical prior on 휃s induces the following prior on the Ψs
Ψ(1) ∼푁(휇1, 휏1)
Ψ(푘) ∣Ψ(푘−1) ∼푁(Ψ(푘−1), 휏푘), 푘> 1
(4)
This expresses the prior belief that the response from increasing dose to the next level should not be too diﬀerent from the
response due to the previous dose level. That is, neighboring points on the curve are related. Of course, if we have data suggesting
otherwise, the data will drive our posterior inference away from this prior. However, in the absence of data, this provides valuable
shrinkage back towards a sensible prior belief. An example using synthetic data is presented in Figure 1a with posterior sampling
done in Stan13. Implementation details along with a more thorough walkthrough using this synthetic data set are available in
Appendix A. Implementation via PROC MCMC in SAS is also discussed. Notice in the ﬁgure that small sample sizes at each
dose level lead to erratic MLE estimates. In contrast, the Bayesian estimate with the AR1 prior produces a smoother curve. In
dose level 8, we only have three observations. Thus, the Bayes estimate is aggresively shrunk towards the estimate at dose 7.
A common heuristic solution to this issue of decreasing sample size with increasing dose is to fully pool patients at, say,
dose 퐾and 퐾−1 and estimate a single eﬀect for both rather than allowing separate eﬀects. The prior in (4) is a compromise
between these two extremes. Recall from (4) that Ψ(퐾) ∣Ψ(퐾−1) ∼푁(Ψ(퐾−1), 휏퐾) for 퐾> 1. Now notice that the heuristic
alternative of combining groups 퐾and 퐾−1 corresponds to the strong prior belief that 휏퐾≈0. That is, the causal eﬀect at
dose 퐾is a point-mass distribution at Ψ(퐾−1): Ψ(퐾) ∣Ψ(퐾−1) ∼훿Ψ(퐾−1).
3.2
Partial Pooling of Conditional Causal Eﬀects
Here we consider a more involved model for causal estimation using a logistic regression with binary outcome and treatment.
Here, the mean function 퐸[푌∣퐴, 퐿] is related to the covariates 퐿through a (non-linear) logit link with inverse logit denoted
by 휎{⋅}. Thus, the integration over 퐿in (1) must be evaluated explicitly. Consider some 푞−dimensional subset of pre-treatment
covariates, 푉⊂퐿. Let 푊= 퐿⧵푉be the set diﬀerence so that 퐿= {푊, 푉}. One target estimand of interest in this setting is
a causal odds ratio at each level of 푉
Ψ(푣) = 퐸[푌1 ∣푉= 푣]∕(1 −퐸[푌1 ∣푉= 푣])
퐸[푌0 ∣푉= 푣]∕(1 −퐸[푌0 ∣푉= 푣])
(5)

Oganisian ET AL
7
Causally, this is contrasting the odds of the outcome had everyone in stratum 푉= 푣taken treatment 1 versus treatment 0.
Since we allow for diﬀerent treatment eﬀects for each level of 푣, sometimes the set of Ψ(푣) is referred to as a heterogenous
treatment eﬀects or conditional treatment eﬀects (i.e. conditional on 푉= 푣). Under extensions of 퐼퐴.1−퐼퐴.4, each conditional
expectation in Ψ(푣) is identiﬁed as 퐸[푌푎∣푉= 푣] = ∫퐸[푌∣푎, 푉= 푣, 푊]푑푃푣(푊). Where 푃푣(푊) = 푃(푊∣푉= 푣) is the
confounder distribution within stratum 푣. Note that this is just (1) conditional on 푉= 푣. The regression model is
퐸[푌∣퐴= 푎, 푉, 푊] = 휎{훽′
푤푊+ 훽′
푣푉+ (휃0 + 휃′
1∶푞푉)퐴}
(6)
Above, we include an intercept in 푊. Note that the treatment eﬀect, 휃0+휃′
1∶푞푉, varies with levels of 푉. We defer discussion of
the integration over 푊to Section 3.3. For concreteness, suppose 푉is a vector of indicators for 푞= 4 race/ethnicity categories:
Black, Asian, Hispanic, Native American, and White as reference. Often some categories (e.g. Hispanic, Asian, Native Amer-
ican) are sparse. In these settings, it is common to combine these categories into “Other” and estimate a single odds ratio for
these subjects. It is also common to simply exclude these subjects and not compute causal eﬀects for these strata at all. Neither
of these may be desirable and, again, carefully formulated priors can help us strike a balance when estimating conditional causal
eﬀects. For instance, consider the prior assumption that all of these conditional (we have not marginalized over 푊yet) eﬀects
within race category (휃0, 휃0 + 휃1, ..., 휃0 + 휃4) are normally distributed around some “overal” treatment eﬀect 휇with standard
deviation 휏. We can achieve this by specifying a Gaussian prior for the conditional eﬀect in the reference stratum 휃0 ∼푁(휇, 휏).
For the conditional eﬀect in stratum 푉= 1, we specify 휃0 + 휃1 ∼푁(휇, 휏). This is the same as saying 휃1 ∼푁(휇−휃0, 휏).
Following this logic for the other strata, the joint prior over all parameters is
푝(휃0∶4 ∣휇, 휏) = 푁(휃0 ∣휇, 휏)
4
∏
푗=1
푁(휃푗∣휇−휃0, 휏)
(7)
For categories with many observations, the posterior of the conditional eﬀects with race category will be driven mostly by data.
However, for small categories, each conditional eﬀect shrinks to the overall average across race values, 휇. The hyperparameter
휏controls how aggressively we shrink these conditional eﬀects to the overall average. This allows us to estimate regularized
race-speciﬁc causal eﬀects rather than abandoning the task altogether or resorting to ad-hoc groupings of categories. Priors for
휇, 휏, and the other regression coeﬃcients must be speciﬁed. Standard guidance14 can be followed when specifying priors on
these nuisance parameters. Similar to the dose eﬀect example, the heuristic approach of fully pooling sparsely populated race
clusters corresponds to a rigid prior. In this case, a prior belief that the conditional eﬀect in all the pooled strata are the same.
3.3
Standardization via Bayesian Bootstrap
To compute conditional causal eﬀects in (5), we must integrate the logistic regression in the previous example over 푃푣(푊).
As shown earlier, factors involving 푊would cancel out in a linear model - obviating the need for explicit integration. Here,
due to the non-collapsability of the logit link, 푊does not cancel. To compute this integral, we need an estimate of 푃푣(푊)
over which to integrate. Let 푆푣= {푖∶푉푖= 푣} be the set of indices of subjects in stratum 푉= 푣. There are 푛푣subjects in
stratum 푣, so that the size of 푆푣is 푛푣. A frequentist nonparametric approach would be to estimate the distribution empirically as
̂푃푣(푤) =
1
푛푣
∑
푗∈푆푣훿푊푗(푤), where 훿푊푗(⋅) is the degenerate distribution at 푊푗. This places probability mass 1∕푛푣on each of the
푛푣subjects in stratum 푣. This yields average potential outcome estimate
퐸[푌푎∣푉= 푣] ≈1
푛푣
∑
푗∈푆푣
퐸[푌∣퐴= 푎, 푉= 푣, 푊= 푊푗]
in stratum 푣. This is ideal in the sense that we impose no parametric model on the conditional distribution of 푊, but is unsatis-
factory from a Bayesian point of view because it ignores the uncertainty in the empirical estimate. This motivates the Bayesian
bootstrap (BB)15. The BB begins with a model for 푊, 푃푣(푤) = ∑
푗∈푆푣푝푣푗⋅훿푊푗(푤). We store all the weights in this stratum in an
푛푣−dimensional vector 푝푣= {푝푣푗∶푗∈푆푣}. This weight vector 푝푣live in a simplex 푝푣∈{ℝ푛푣∶푝푣푗> 0 ∀푗and ∑
푗∈푆푣푝푣푗= 1}.
Rather than ﬁxing 푝푣푗= 1∕푛푣, the BB treats the weights as unknown with a ﬂat Dirichlet prior 푝푣∼퐷푖푟(0푛푣), where 0푛푣is
the 푛푣−dimensional vector of zeros. This yields the (conjugate) posterior 푝푣∣푊∼퐷푖푟(1푛푣), where 1푛푣is the 푛푣−dimensional
vector of ones. The BB makes minimal assumptions about the confounder distribution within each stratum: note the posterior
mean of each weight is also 1∕푛푣(same as the frequentist approach), but allows uncertainty around this mean to ﬂow through
to the causal eﬀect in that stratum.
The BB was applied to marginal ATE estimation using generalized linear models (GLMs) for the outcome by Wang et al.16.
When computing a marginal ATE, the BB is used as a model for the marginal 푝(퐿) not the conditional 푝푣(푊). In the outcome

8
Oganisian ET AL
model, we no longer set 푉= 푣since 푉is included in 퐿= {푊, 푉}, which we integrate over. The BB model is now 푃(푙∣푝1∶푛) =
∑푛
푖=1 푝푖훿퐿푖(푙). Now we place a Dirichlet prior on the 푛-dimensional vector 푝1∶푛rather than the 푛푣-dimensional vectors 푝푣. This
marginal estimate will play a key role in the nonparametric estimation of Section 6.
Full posterior inference for the causal odds ratio (5) requires just a few additional steps after sampling. Suppose we obtain the
푚푡ℎdraw of the parameters in (6), {훽(푚)
푤, 훽(푚)
푣, 휃(푚), 휃(푚)
1∶푞}. Then, for each stratum 푣, we draw BB weights 푝(푚)
푣
∣푊∼퐷푖푟(1푛푣).
Note that here 푝(푚)
푣
denotes the collection {푝(푚)
푣푗∶푗∈푆푣}. Then, we do the following
1. Integrate under both interventions 퐴∈{1, 0}:
휇(푚)(푎, 푣) =
∑
푗∈푆푣
푝(푚)
푣푗휎{훽
′(푚)
푤푊푗+ 훽
′(푚)
푣
푣+ (휃(푚) + 휃
′(푚)
1∶푞푣)푎}
2. Compute Causal Eﬀects for each 푣
Ψ(푚)(푣) = 휇(푚)(1, 푣)∕(1 −휇(푚)(1, 푣))
휇(푚)(0, 푣)∕(1 −휇(푚)(0, 푣))
Doing this for 푚= 1, … , 푀posterior parameter draws yields 푀draws from the posterior of the causal estimand:
{Ψ(푚)(푣)}1∶푀for each 푣. These draws can be used for posterior inference. Figure 1b shows posterior estimates of Ψ(푣) with the
partial pooling prior in (7) using synthetic data. MCMC-based posterior inference was done using Stan. Notice that for strata
푉∈{4, 5}, we have relatively few observations. In these strata, the maximum likelihood estimate (MLE) is much higher than
the others due to small sample variability. Thus, the Bayesian prior aggressively shrinks the posterior mean estimate away from
MLE towards the overall eﬀect. From a causal perspective, we can view this as shrinking the heterogenous treatment eﬀects
towards an overall treatment eﬀect. Details of this synthetic data generation and implementation in both Stan and SAS are given
in Appendix B. The latter relies on PROC MCMC for posterior sampling and PROC IML for the BB post-processing step.
4
TIME-VARYING TREATMENT AND CONFOUNDING
The previous sections focused on the point-treatment setting: estimating the causal eﬀect of a single treatment administered
at baseline while adjusting for a single set of pre-treatment parameters. In many applications, treatment decisions are made
sequentially over time as a function of covariates measured after baseline. For example, consider a binary treatment setting where
treatment at time 푡= 0, 퐴0, is assigned conditional on confounders, 퐿0, measured before 퐴0. The subsequent treatment, 퐴1,
is assigned conditional on 퐿0, 퐴0, and 퐿1, where 퐿1 is measured between 퐴0 and 퐴1, temporally. After treatment, we observe
a single outcome 푌. Suppose we wish to estimate the causal ATE 퐸[푌(1,1) −푌(0,0)] - the diﬀerence had everyone in the target
population been always treated versus never treated. Note the potential outcomes here are indexed by a treatment vector, not
scalar. In the literature this vector is often referred to as a “treatment regime” or “treatment policy”. In this section, we ﬁrst
discuss causal contrasts comparing outcomes that would have been realized under two diﬀerent static treatment regimes while
controlling for time-varying confounding. Static regimes are treatment vectors that are pre-set to ﬁxed values in advance (e.g.
always treated, never treated, alternating treatments). Afterwards, we discuss an extension to dynamic treatment regimes, where
the treatment regime is set sequentially over time according to a pre-speciﬁed rule (e.g. treat at time point 푡if blood pressure at
time 푡is lower than some threshold). We refer the reader to Daniel8 for a thorough tutorial on time-dependent confounding and
modeling.
4.1
Comparing Static Treatment Regimes
Standard regression methods fail to properly adjust for the time-varying confounder in these settings. For instance, if we condition
on 퐿1, then we adjust away 퐴0’s impact on 푌that runs through 퐿1. However, 퐿1 is a confounder of 퐴1 and 푌- so failing to adjust
for it will also lead to bias. Now, generalizing to 푡= 0, … , 푇time points, under extensions of 퐼퐴.1 −퐼퐴.4 to this sequential
setting2 we can identify each term of the causal contrast Ψ = 퐸[푌푎0∶푇−푌푎′
0∶푇] as
퐸[푌푎0∶푇] = ∫

퐸[푌∣푎0∶푇, 퐿0∶푇] ×
푇
∏
푡=0
푝(퐿푡∣퐿0∶푡−1, 푎0∶푡−1)푑퐿0∶푇
(8)

Oganisian ET AL
9
(a)
(b)
FIGURE 2 A directed acyclic graph (DAG) showing a time-varying treatment, 퐴푡, time-varying confounder 퐿푡, and outcome,
푌, for three time points. In the ﬁrst panel, treatment and confounding at each time point aﬀects treatment and confounding in
every future time point. The second panel depicts the Markov assumption described in Section 4.1 - confounders and treatment
only impact variables in the next period so that 푝(퐿2 ∣퐿0∶1, 퐴0∶1) = 푝(퐿2 ∣퐿1, 퐴1). This is visually depicted by the deletion of
the gray arrows in the ﬁrst panel. Bayesian methods can help us strike a balance between these two extremes.
Where for 푡= 0, we deﬁne 푝(퐿0 ∣퐿0∶−1, 푎0∶−1) = 푝(퐿0). The expression above is known as the 푔-formula and the computation
of the integral is referred to as 푔-computation - it is the multi-time point generalization of standardization in (1). Here we ignore
the details of identiﬁcation to focus on Bayesian modeling and computation.
In particular, note that the above requires integrating an outcome regression over the joint distribution of confounders, con-
ditional on treatment regime 푎0∶푇. The outcome regression here can be high-dimensional even in common data applications.
If we have just two time-varying confounders and twelve (e.g. monthly) time points, the outcome model must condition on 36
variables. Similarly, each conditional confounder distribution must (usually) be modeled conditional on all previous values of
퐿푡and 퐴푡- another high-dimensional modeling task.
The sequential nature of treatment and confounder measurement can be visually depicted using a directed acyclic graph
(DAG) in Figure 2a for 푇= 3 timepoints (for compactness). Notice 퐿2 is impacted by all previous confounder values (퐿0 and
퐿1) and treatment values (퐴0 and 퐴1). This is shown by arrows going into 퐿2. Similarly, the outcome is impacted by all past 퐿
and 퐴values. To simplify this complexity, a Markovian assumption is commonly invoked. This assumes that each confounder
distribution only depends on the previous confounder and treatment values, 푝(퐿푡∣퐿0∶푡−1, 퐴0∶푡−1) = 푝(퐿푡∣퐿푡−1, 퐴푡−1). A similar
assumption may be used in the outcome model. This Markov-type assumption is depicted in Figure 2b, which is simply the DAG
in 2a with all the gray arrows removed. After removing gray arrows, each variable is directly impacted only by variables in the
preceding time point. In Figure 2b, for instance, once we know 퐿1 and 퐴1, we know the distribution of 퐿2. The history (퐴0 and
퐿0) need not be considered since it only aﬀects 퐿2 through 퐿1 and 퐴1. Thus, 푝(퐿2 ∣퐿0∶1, 퐴0∶1) = 푝(퐿2 ∣퐿1, 퐴1).
Neither of these extremes - conditioning on full history or invoking Markov - are completely desirable. Suppose 퐿푡is an
indicator of poor kidney function at day 푡. The Markov assumption presumes that two treated subjects with, say, poor kidney
function on the previous day, 퐿푡−1, have the same 퐿푡distribution - even if one patient had poor function everyday since 푡= 0
and the other had good function until day 푡−1. This seems unrealistic. On the other hand, it may also be unrealistic to say that
kidney function on day 1, 퐿1, would directly impact function on, say, day 100, 퐿100. In the Bayesian paradigm, we can devise
priors that balance these two extremes of either conditioning only on previous time period’s values versus conditioning on the
entire past history. The general idea is to condition on the full history, but express a prior belief that values closer in time to the
present have relatively more direct impact on the present. Conversely, values further back in time have small, if any, direct eﬀect.
To continue this example, consider a simple setting where 퐿푡is a continuous measure of kidney function and the outcome
is viral load, with the treatment, 퐴푡∈{0, 1} being anti-viral therapy at time 푡. Lower viral load is desirable, but comes at the
expense of nephrotoxicity. So, depending on previous treatment, if the patient shows poor kidney function as measured by 퐿,
the physician may alter their treatment. To evaluate (8), we will need an outcome regression and a sequence of conditional
confounder models. Consider a linear outcome regression 퐸[푌∣퐴0∶푇, 퐿0 ∶푇] = 훾+ 퐿′
0∶푇훽푌+ 퐴′
0∶푇휃푌and a Gaussian

10
Oganisian ET AL
(a) Plot of coeﬃcient estimates from (9) with t=9. Each coef-
ﬁcient on the x-axis is the eﬀect of 퐿푡on 퐿9 for time points
푡= 0, … , 8. Note aggressive shrinkage of 훽0 but ability to
detect signal in the past at 훽1.
(b) Sensitivity analysis of Section 5. Posterior Distribution of
Ψ푠= Ψ −Δ under various priors for for Δ. Red line indicates
true value.
FIGURE 3 Example of 푔-computation on synthetic data with 10 time points, single time-varying treatment and confounder.
The ridge prior in (10) was used along with Gaussian outcome and conditional confounder models.
conditional model for 퐿푡with conditional mean
휇퐿푡(퐿0∶푡−1, 퐴0∶푡−1) = 훽+ 퐿′
0∶푡−1훽퐿+ 퐴′
0∶푡−1휃,
(9)
where 훽퐿= (훽0, 훽1, 훽2, … , 훽푡−1) and 휃are length 푡parameter vectors. We note that these parameters should be indexed by 푡(e.g.
훽푡
퐿) as each conditional distribution should be allowed to have their own eﬀects, but we omit this indexing for compactness. We
consider the following prior on each element of 훽퐿
훽푡−푘∼푁(0, 휏푘휙), 푘∈{1, … , 푡}.
(10)
An identical prior can be used for 휃. Consider the speciﬁcation 휏푘= (1∕휆푘) for some 휆> 1. This corresponds to what is often
referred to as a ridge penalty in the machine learning literature. However, it diﬀers from the standard ridge regression in that we
do not apply the same penalty to all coeﬃcients. Rather, the penalty gets increasingly aggressive for coeﬃcients going farther
back in time. For instance, for 휆= 2, the prior standard deviation around 0 is halved every step backward in time, providing
increasingly aggressive prior shrinkage towards 0. This implies a strong prior belief that recent confounder values are more
likely to inﬂuence the present than values farther in the past. Note that the Markov assumption follows from a special (strongly
informative) case of this prior, where 훽푡−푘∼훿0 for 푘> 1: all coeﬃcients but 훽푡−1 follow a point-mass distribution at 0. An
example of the prior in (10) is provided in Figure 3a with 푇= 9. The plot shows the coeﬃcients of 훽퐿in the model 휇퐿9 getting
increasingly penalized. Note that the posterior estimate of 훽1 is able to break away from this prior to detect a signal (a truly non-
zero coeﬃcient value), even though it is farther in the past. However, at time point 0 the posterior estimate 훽0 is strongly shrunk
to zero (relative to the MLE).
The Bayesian literature has explored several such “sparsity” priors, including the horseshoe17, LASSO, and spike-and-slab
priors18 - all of which could be applied to 푔-computation. These priors can all be characterized by their ability to both shrink
noise, while being able to break away from the prior to detect signals17. For instance, a horseshoe type prior on the components

Oganisian ET AL
11
of 훽퐿can be speciﬁed by placing half-Cauchy hyper-priors on 휏푘and 휙in (10):
휏푘∼퐶+(0, 1∕2푘)
휙∼퐶+(0, 휈)
where 휈is a speciﬁed scale parameter that controls overall shrinkage across time. Similar to the ridge-type prior, the scale on
the distribution of 휏푘is halved every step backward in time.
The integration in (8) can be done via Monte Carlo after obtaining MCMC draws from the posterior of all the parameters
governing the conditional confounder and outcome distributions. Conditional on these draws, we can simulate confounder values
from these distributions and take the average of our regression model over these simulated values. Let 휔(푚)
푦
denote the 푚푡ℎ
draw of the parameter vector governing the regression in (8). Similarly, denote the parameter vector governing each conditional
confounder distribution 푝(퐿푡∣퐿0∶푡−1, 푎0∶푡−1) by 휔(푚)
퐿푡. For instance, these would include draws of the regression parameters
훽, 훽퐿, 휃in (9) along with the Gaussian variance parameter. In the viral load example discussed earlier, 휔(푚)
푦
would consist of
휔(푚)
푦
= (훾(푚), 훽(푚)
푌, 휃(푚)
푌)
To compute the causal ATE Ψ = 퐸[푌푎0∶푇−푌푎′
0∶푇] of regime 푎0∶푇versus 푎′
0∶푇, with each posterior draw of 휔(푚)
푌
and 휔(푚)
퐿푡we:
1. Draw confounders, for 푡∈0 … 푇sequentially
̃퐿푡∼푝(퐿푡∣̃퐿0∶푡−1, 푎0∶푡−1, 휔(푚)
퐿푡)
Denote these draws ̃퐿0∶푇= ( ̃퐿0, ̃퐿1 … , ̃퐿푇). Repeat this a total of 퐵times to obtain { ̃퐿(푏)
0∶푇}1∶퐵= { ̃퐿(1)
0∶푇, ̃퐿(2)
0∶푇, … ̃퐿(퐵)
0∶푇}
2. Integrate the outcome model 퐸[푌∣푎0∶푇, 퐿0∶푇] over { ̃퐿(푏)
0∶푇}1∶퐵conditional on current set of draws 휔(푚)
푦, under both
interventions. In the viral load example, this would be
휇(푚)(푎0∶푇) = 1
퐵
퐵
∑
푏=1
퐸[푌∣푎0∶푇, ̃퐿(푏)
0∶푇, 휔(푚)
푦]
= 1
퐵
퐵
∑
푏=1
(훾(푚) + ̃퐿
′(푏)
0∶푇훽(푚)
푌
+ (푎0∶푇)′휃(푚)
푌)
Similarly, repeat Step 1 and 2 under 푎′
0∶푇.
3. Compute Causal Contrast
Ψ(푚) = 휇(푚)(푎0∶푇) −휇(푚)(푎′
0∶푇)
This procedure yields 푀posterior draws of Ψ, which can be used to form posterior mean and credible intervals. This can also
be implemented in Stan using the “generated quantities” block as demonstrated in the our code on GitHub. The number of
draws 퐵should be large so that the Monte Carlo error of the integration of (8) is suﬃciently low. In general, analyses with more
time points and time-varying confounders will require larger 퐵. In practice, we can try running steps 1-3 for a single posterior
draw (say, draw 푚), over successively larger 퐵. Keeping track of each repetition, we can check at which point increasing 퐵
only marginally increases precision in the estimate of Ψ(푚). We can then set 퐵to this value across all posterior draws. A nice
feature of this Bayesian approach is that uncertainty about the confounder and outcome models at all time points naturally ﬂows
through to the posterior of Ψ or any other causal contrast. For instance, we could have computed posterior draws of causal ratio
contrast 퐸[푌푎0∶푇]∕퐸[푌푎′
0∶푇] in Step 3 as 휇(푚)(푎0∶푇)∕휇(푚)(푎′
0∶푇). In contrast, the frequentist approach would require many bootstrap
estimates of the parameter vectors. Then, we would repeat Steps 1-3 using these bootstrap draws in place of the posterior draws.
In the Bayesian framework, we need not re-estimate the model. We simply post-process the same set of draws diﬀerently.
4.2
Dynamic Treatment Regimes
In the previous section we compared static treatment vectors 푎0∶푇= (푎0, 푎1, … , 푎푇), where each element is ﬁxed at baseline.
A dynamic treatment regime is a treatment regime where the elements are determined dynamically post-baseline via a pre-
speciﬁed decision rule. A decision rule is a function that, at each time point 푡, maps the confounder history and treatment history
(퐿0∶푇, 퐴0∶푇) to a treatment value 푎푡∈{0, 1}. For simplicity, here we discuss treatment rules that determine assignment based
on current confounder values only. That is, rules 푟푡(⋅) ∶→{0, 1} maps from the space of confounders to a treatment decision.
Expanding on the viral load/kidney function example from earlier, consider a treatment rule that administers treatment at time 푡

12
Oganisian ET AL
only if kidney function at time 푡is higher than some threshold 휅: 푟푡(퐿푡) = 푟(퐿푡) = 퐼(퐿푡> 휅). We denote the average potential
outcome under the dynamic treatment regime 푎푟
0∶푇= (푟(퐿1), 푟(퐿2), … , 푟(퐿푇)) as 퐸[푌푎푟
0∶푇]. Of interest may be to compare the
average diﬀerence in outcome had everyone been treated according to rule 푟versus rule 푑: Ψ = 퐸[푌푎푟
0∶푇−푌푎푑
0∶푇]
We note that these rules can be quite complex. For example, treatment at time 푡may only be assigned if kidney function has
been above 휅for the previous two periods as well as the current time period:
푟푡(퐿(푡−2)∶푡) = 퐼(퐿푡> 휅푡) ⋅퐼(퐿푡−1 > 휅푡−1) ⋅퐼(퐿푡−2 > 휅푡−2)
Here, 푟푡(⋅) ∶3 →{0, 1}. In general, the rule may include previous treatment history as well as confounder history. In this
section we consider the simple rule 푟(퐿푡) = 퐼(퐿푡> 휅), but the procedure is the same for more complicated rules.
As shown in all previous examples, Bayesian causal inference can be done quite easily provided we have posterior draws of
the model parameters. Once these are obtained, computing causal contrasts is just a matter of post-processing. In this case, we
only need to modify the 푔-computation post-processing steps from the previous section to sequentially set each element of the
treatment vector as confounders are simulated, rather than use a pre-set treatment vector 푎0∶푇.
Consider the same scenario as in the static treatment setting, with posterior draw of 휔(푚)
푌
and 휔(푚)
퐿푡, but this time with a speciﬁed
dynamic treatment rule 푟(퐿푡) = 퐼(퐿푡> 휅). We compute a draw, 휇(푚)(푟), from the posterior of the average potential outcome
under rule 푟, 퐸[푌푎푟
0∶푇], as follows
1. Starting from 푡= 1, perform the following two sub-steps sequentially until 푡= 푇
(a) Simulate Confounder
̃퐿푡∼푝(퐿푡∣̃퐿0∶푡−1, ̃푎0∶푡−1, 휔(푚)
퐿푡)
(b) Determine Treatment according to rule
̃푎푡= 푟( ̃퐿푡) = 퐼( ̃퐿푡> 휅)
Denote these draws ̃퐿0∶푇= ( ̃퐿0, ̃퐿1 … , ̃퐿푇) and ̃퐴0∶푇= ( ̃푎0, ̃푎1, … , ̃푎푇). Repeat this a total of 퐵times to obtain { ̃퐿(푏)
0∶푇}1∶퐵
and { ̃퐴(푏)
0∶푇}1∶퐵
2. Integrate the outcome model 휇(푚)(푟) = 퐸[푌∣푎푟
0∶푇, 퐿0∶푇] over { ̃퐿(푏)
0∶푇}0∶푇and { ̃퐴(푏)
0∶푇}1∶퐵conditional on current set of
draws 휔(푚)
푦, under both interventions. In the viral load example, this would be
휇(푚)(푟) = 1
퐵
퐵
∑
푏=1
퐸[푌∣̃퐴(푏)
0∶푇, ̃퐿(푏)
0∶푇, 휔(푚)
푦]
Similarly, we can draw from the posterior of average potential outcome under an alternative rule 푑, 퐸[푌푎푑
0∶푇]. Denote this by
휇(푚)(푑). Taking the diﬀerence yields a posterior draw of Ψ, Ψ(푚) = 휇(푚)(푟) −휇(푚)(푑). The sum over 퐵is a Monte Carlo estimate
of the integral in (8). This highlights the advantage of full posterior inference. A posterior over the model parameters induces a
posterior over functions of those parameters - in this case, ATEs that contrast dynamic treatment regimes.
5
PRIORS OVER SENSITIVITY PARAMETERS
So far we have demonstrated how priors can be used to induce various correlation structures between model parameters. In
Section 3.1, we were able to estimate a smoothed causal curve by inducing correlation between neighboring points. In section
3.2, we were able to estimate conditional causal contrasts for sparsely populated subgroups by shrinking their estimates towards
the overall average. Lastly, in the previous section we explored ridge-like and horseshoe priors for inducing principled sparsity
on a high-dimensional covariate vector. In this section, we present a diﬀerent use of priors focused explicitly on causality rather
than modeling - outlining how they can be used to express uncertainty about causal identiﬁcation assumptions.
We consider a binary point-treatment setting with a continuous real-valued outcome. Suppose that conditional ignorability
(퐼퐴.1) does not hold, so that 푌푎̸⟂퐴∣퐿, for 푎∈{0, 1}. This implies that 퐸[푌푎∣퐴= 1, 퐿] ≠[푌푎∣퐴= 0, 퐿]. That is,
the mean of each potential outcome diﬀers between those actually treated and untreated, even after conditioning on 퐿. Suppose
they diﬀer by
Δ푎(퐿) = 퐸[푌푎∣퐴= 1, 퐿] −퐸[푌푎∣퐴= 0, 퐿]

Oganisian ET AL
13
This could be a result of selection bias. For instance, if higher outcome values are beneﬁcial then 퐸[푌0 ∣퐴= 1, 퐿] < 퐸[푌0 ∣
퐴= 0, 퐿] implies those assigned to treatment would have had worse outcomes even if they had not been treated, relative to those
not assigned treatment. This could be caused by “confounding by indication” where patients worse-oﬀto begin with are more
likely to be treated with more advanced drugs. Not accounting for this selection bias may make these drugs look ineﬀective and,
perhaps, even harmful.
In this setting, if we were to incorrectly assume 퐼퐴.1, then standardization in (1) would yield a biased estimated of the causal
eﬀect Ψ = 퐸[푌1 −푌0]:
∫

{휇(1, 퐿) −휇(0, 퐿)}푑푃(퐿) = Ψ + 휉
where the bias term, 휉, is a function of Δ푎(퐿) and the propensity score 푒(퐿) = 푃(퐴= 1 ∣퐿)
휉= ∫

{Δ0(퐿)푒(퐿) + Δ1(퐿)[1 −푒(퐿)]}푑푃(퐿).
(11)
Above, 휉fully characterizes the implication of an ignorability violation on our estimate, but has a complicated form: it is a func-
tion of the treatment probability and two unknown functions, Δ1(퐿) and Δ0(퐿). Since ignorability is an untestable assumption,
it is inherently impossible to learn about Δ1(퐿) and Δ0(퐿) through the observed data. To proceed, we must make assumptions
about the form of the ignorability violation. The art of sensitivity analysis lies in making assumptions that balance the trade-
oﬀbetween the range of violations that can be explored against the interpretability of the sensitivity parameters. If they are
not interpretable, we cannot form sensible prior beliefs about them. But if they are too simple, we will fail to explore realistic
violations.
As an example, suppose that Δ1(퐿) = Δ0(퐿) = Δ so that both potential outcomes diﬀer by some constant amount between
those assigned and unassigned treatments. That is, there is some constant boost that one treatment group is getting under both
hypothetical treatment interventions. We also assume this bias is constant with respect to measured covariates, so that we learn
nothing about the bias by conditioning on 퐿(a worse-case scenario). In this setting, the bias reduces to 휉= Δ ∫푑푃(퐿) = Δ.
These assumptions reduce (11) to be a function of a single parameter which, as mentioned earlier, can be viewed as the amount
of selection bias: Δ = 퐸[푌0 ∣퐴= 1, 퐿] −퐸[푌0 ∣퐴= 0, 퐿]. If higher 푌values are beneﬁcial, then Δ < 0 implies treated
subjects would have had outcome values Δ units lower than those not assigned treatment, even had they not been treated. This
could be because of a lurking unmeasured confounder (e.g. baseline disease severity) that impacts both treatment assignment
and outcome. Interpretation of magnitude will depend on the units of 푌. If 푌were standardized, we could interpret Δ as a
standard deviation diﬀerence in average potential outcomes between the two treatment groups. Suppose we believe that there is
strong possibility of a selection bias in the Δ < 0 direction and no chance of bias in the other direction, we can set Δ = −Δ∗.
We could then specify a prior Δ∗∼퐺푎푚(푎, 푏), which has prior mean 퐸[Δ∗] = 푎∕푏and variance 푉푎푟[Δ∗] = 푎∕푏2. For instance,
if we have a prior belief of a one standard deviation bias, we can set (푎∕푏) = 1 and set 푏to, say, 푏= 3. This is a fairly tight prior
around Δ∗= 1 with standard deviation 3−1∕2.
To illustrate, we generate some synthetic data with a single binary treatment, single continuous observed confounder, a single
continuous unobserved confounder, and a Gaussian outcome with mean being a function of treatment and both confounders.
We then ﬁt the Bayesian linear regression in Equation (2), excluding the unmeasured confounder. Appendix C describes this
synthetic data generation and implementation in more detail. If we had included it, standardization would yield an accurate
estimate of the ATE, Ψ = 퐸[푌1 −푌0], which equals Ψ = 1 in this simulation. However, because we mistakenly exclude the
unmeasured confounder, our estimate will be biased by some Δ. Conducting a sensitive analysis involves specifying diﬀerent
priors for Δ. Because we have no data about Δ, the posterior is the same as the prior and so the usual standardization algorithm
can be modiﬁed as follows:
1. Perform standardization as usual to obtain Ψ(푚). Because we are using a linear model in this simulated example, Ψ(푚)
is simply the 푚푡ℎposterior draw of the coeﬃcient on the treatment dummy in our regression - as shown in Equation (2).
2. Draw sensitivity parameter from some speciﬁed prior, e.g. Δ∗(푚) ∼퐺푎푚(1, 3), transform to get Δ(푚) = −Δ∗(푚), and
compute
Ψ(푚)
푠
= Ψ(푚) −Δ(푚).
In this case, our sensitivity analysis produces the usual posterior draws Ψ(푚) that are perturbed by draws of Δ(푚). We can also
view it as “subtracting oﬀ” the bias in (11) from the standardization estimate, Ψ(푚). This perturbation incorporates our prior
uncertainty regarding the magnitude of the bias due to a pre-speciﬁed form and direction of an ignorability violation. Figure 3b

14
Oganisian ET AL
presents perturbed posteriors under three diﬀerent priors for this synthetic example: Δ ∼푁(0, 푠푑= 3−1∕2), Δ ∼퐺푎푚(1, 3),
and Δ∗∼퐺푎푚(1, 3). Note that ignorability (i.e. no unmeasured confounding) can be expressed as a strong prior belief that Δ
follows a point-mass distribution at 0, Δ ∼훿0. As shown in Figure 3b, this yields a posterior estimate centered far from Ψ = 1.
The ﬁrst prior expresses symmetric belief about the direction of the bias, and so increases uncertainty in the posterior, without
shifting its mean. Consequently, in Figure 3b we see the wider posterior interval that now has more mass around Ψ = 1. The
second prior expresses prior belief that Δ > 0 and the third expresses the belief that Δ < 0. Thus, the former shifts our posterior
lower to correct for the upward bias and the latter shifts our posterior up to correct for the downward bias.
While sensitivity analyses around 퐼퐴s are unique and application-speciﬁc, they follow the general procedure we outlined
above:
1. Find the bias induced by an 퐼퐴violation, 휉.
2. Make assumptions about the nature of the violation so that 휉is expressed in terms of interpretable sensitivity parameters.
3. Express your belief about the direction and degree of the violation via priors on these sensitivity parameters.
4. Use draws from these priors to perturb the causal eﬀect.
5. Assess the perturbed posterior.
We contrast this approach with the usual frequentist approach that computes point and interval estimates for Ψ under a pre-
speciﬁed range of Δ. Usually this range is wide enough so that we can see where perturbation “reverses” some statistically
signiﬁcant eﬀect, as measured by a change in p-value from signiﬁcant to non-signiﬁcant. In the Bayesian approach, we see
how perturbation impacts the entire posterior distribution of the estimand - telling us how posterior mean, median, quantiles,
variance, etc are all aﬀected by the uncertainty in our sensitivity parameters.
The literature on Bayesian sensitivity analysis is large and growing. For instance, McCandless et al.19 develop a sensitiv-
ity analysis for unmeasured confounding of the eﬀect of a binary exposure on an outcome and assess the quality of posterior
inference via extensive simulations. Gustafson et al.20 develop a Bayesian sensitivity analysis framework for unmeasured con-
founding where it is assumed measured confounders are measured with error. This highlights a strength of Bayesian approach:
sensitivities around multiple violations (in this case, measurement error and ignorability) can be done at once with suitable priors.
Mediation analyses require more complex ignorability assumptions to estimate natural direct and indirect eﬀects. Bayesian sen-
sitivity analyses have been developed for such problems within the context of hazard models for survival outcomes21. Bayesian
sensitivity analysis for mediators have also been explored with nonparametric Bayesian models22. Other work by Gustafson et
al. focus on Bayesian sensitivity for partially identiﬁed bias parameters23. They discuss an application to average causal eﬀect
estimation in a randomized trial with non-compliance (i.e. not all patients randomized to treatment 퐴= 푎take treatment 푎).
6
FLEXIBLE MODELS VIA NONPARAMETRIC BAYES
In previous examples, we considered parametric regression models 휇(퐴, 퐿) = 퐸[푌∣퐴, 퐿] that were indexed by ﬁnitely many
parameters. In the Gaussian example of Section 2, the regression was determined completely by (휃, 훽). In Section 3.2, the
logistic regression was a function of (훽푤, 훽푣, 휃0, 휃1∶푞). In our discussion of time-varying confounding, models for the confounder
distribution were required at every time point, in addition to an outcome model. These models impose restrictive functional
forms of the covariate and treatment eﬀect. For instance, they assume that the treatment eﬀects are linear and additive on
some transformation of the conditional outcome mean. However, it is possible that the treatment eﬀect is a complex, nonlinear
function of 퐿. Suppose all relevant confounders suﬃcient for 퐼퐴.1 to hold are measured and included in the model. Even in this
scenario, msisspeciﬁcation of the functional form of that model will, in general, yield inaccurate posterior causal eﬀect estimates.
In this section we will provide a brief overview of causal eﬀect estimation using Bayesian nonparametric (BNP) models - a
class of ﬂexible models that make minimal functional form assumptions. We focus here on the point-treatment setting, with
the understanding that these methods can be applied to other settings, including conditional mean modeling in 푔-computation,
mediation, marginal structural models, and so on. Throughout, 퐷= {푌푖, 퐴푖, 퐿푖}1∶푛will denote the observed data consisting of
outcome, treatment, and confounder vector for 푛independent subjects. We will deﬁne a covariate vector 푋푖= (1, 퐴푖, 퐿푖) for
compactness.

Oganisian ET AL
15
6.1
Dirichlet Process Mixture Models
We return to the linear model of Section 2 and specify a more ﬂexible alternative. First, deﬁne conditional regression 휇푖(푋) =
푋′훽푖. We specify the following model for the joint data distribution
푌푖∣푋푖, 훽푖, 휙푖∼푁(휇푖(푋푖), 휙푖)
푋푖∣휃푖∼푝(푋푖∣휃푖)
휔푖∣퐺∼퐺
퐺∣훼, 퐺0 ∼퐷푃(훼퐺0)
(12)
휔푖= (휃푖, 훽푖, 휙푖) denotes the full parameter vector. There are two key additions in this model. First, we have saturated the model
with more parameters than there are observations in the data. This is nonparametric in the sense that the number of parameters is
growing with the sample size. Second, this is a generative rather than conditional model. That is, we model the joint distribution
푝(푌푖, 푋푖∣휔푖) = 푝(푌푖∣푋푖, 휔푖)푝(푋푖∣휔푖) rather than just the conditional distribution of the outcome.
The parameters of the joint distribution follow an unknown prior, 퐺. Above, we specify a Dirichlet process (DP) prior on
G. Realizations of this stochastic process are discrete random probability distributions centered around a base distribution,
퐺0(휔푖), with dispersion controlled by 훼. This discreteness induces ties among the 휔푖which, in turn, induces posterior clustering
of data points. Speciﬁcally, subjects are partitioned into groups with similar joint data distributions and each group’s joint is
modeled using a separate 휔푖. In this way, the posterior conditional regression is a mixture of many cluster-speciﬁc regressions.
In the machine learning literature24 these are often called “mixture of experts” learners, since each component regression in
the mixture (referred to as an “expert”) has “expertise” in a particular region of the data. Predictions are formed by averaging
over the component experts’ predictions. These are distinct from ensemble models, which model the entire data using separate
candidate models - rather than assigning diﬀerent data regions to diﬀerent models.
Induced Posterior Regression
Such DP mixture models have been discussed in the BNP literature for some time. Shahbaba and Neal (2007) ﬁrst described a DP
mixture of regressions25. Blei et al. (2011) later extended this to a DP mixture of GLMs, which generalizes (12) to any conditional
outcome and covariate distribution in the exponential family26. There is extensive literature on posterior sampling strategies for
this model, though the most common approach in causal inference tends to be Neal’s Algorithm 827. We will use software to
conduct the sampling, but it is instructive to show that the posterior regression can be expressed as a mixture of regressions at
each iteration in the sampler. Let 휔(푚)
1∶푛be a draw of all the subject-level parameters and let 휇(푚)
푖
(푋) = 퐸[푌∣푋, 휔(푚)
푖] denote the
posterior regression at each iteration, given by
휇(푚)
푖
(푋) = 푤(푚)
0 휇(푚)
0 (푋) +
푛
∑
푖=1
푤(푚)
푖휇(푚)
푖
(푋)
(13)
Note that this is a mixture with 푛+ 1 components and mixture weights {푤(푚)
0 , 푤(푚)
1∶푛}. Above, 휇(푚)
0 (퐴, 퐿) is the regression under
a prior draw 훽(푚)
0
∼퐺0 - we will call this a “prior regression”. The weights 푤(푚)
푖
have the form
푤(푚)
푖
=
푝(푋∣휃(푚)
푖
)
훼푝(푋∣휃(푚)
0 ) + ∑푛
푖=1 푝(푋∣휃(푚)
푖
)
,
(14)
where 휃(푚)
0
∼퐺0 is a prior draw. The weight on the prior regression is
푤(푚)
0
=
훼푝(푋∣휃(푚)
0 )
훼푝(푋∣휃(푚)
0 ) + ∑푛
푖=1 푝(푋∣휃(푚)
푖
)
(15)
The induced posterior regression is a complex mixture of a prior regression and several subject speciﬁc regressions. Importantly,
the mixture weights are covariate-dependent, allowing us to capture non-linear and non-additive eﬀects of 푋on the outcome. We
refer to the speciﬁed distributions in (12) as “local” distributions as they are local to a particular mixture component. Even though
the local model is parametric, we can approximate arbitrarily complicated distributions using a mixture of locally simple models.
This is similar conceptually to approximating a complicated non-linear regression function using piecewise linear splines.

16
Oganisian ET AL
(a) BART
(b) Dirichlet Process
(c) Gaussian Process
(d) ATE Estimates
FIGURE 4 Training and test set predictions from three BNP models, along with ATE estimates from each. Red points indicate
held-out test data. Gray points are training data. Notice for the DP and GP models, the increased uncertainty in the test region.
BART, by contrast, has less uncertainty in this region. Relative to DP and GP, BART’s interpolation is more rigid due to its
inherent tree structure.
Local Model Choice and Hyperparameters
Speciﬁcation of the model requires specifying the local distributions. In general, model ﬁt will not be too sensitive to these
choices as the resulting regression takes a complex non-linear mixtures of these local models to ﬁt the regression. However,
desired support can be a guiding concern in making this choice. For instance, it may be desirable to choose 푝(푋푖∣휃푖) such that it
respects the support of the elements of 푋푖. Consider a vector 푋= (푋1, 푋2, 푋3) that consists of a binary, continuous/real-valued,

Oganisian ET AL
17
and count confounders respectively. Assuming prior independence, we can set 푝(푋푖∣휃푖) to be the product of the Bernoulli,
Gaussian, and Poisson distributions, with 휃푖being the vector of parameters governing all three distributions. Similarly, if the
outcome must be non-negative (e.g. blood pressure, cost, etc) then we could use a log-normal conditional outcome distribution
instead of a Gaussian.
Just as with the local models, 퐺0 should also be set to place non-zero prior measure on the support of 휔푖. In model (12) with
a single count covariate 퐿푖, we could set
퐺(휔푖) = 푁2(훽푖; 훽∗, Σ∗)퐼퐺(휙푖; 푎∗, 푏∗)퐵푒푟(푝푖; 푝∗)퐼퐺(휆푖; 휆∗)
Where, 휃푖= (휆푖, 푝푖) are the parameters governing the local covariate distribution 푝(푋푖∣휃푖) = 푃표푖푠(퐿푖; 휆푖)퐵푒푟(퐴푖; 푝푖).
In the causal literature, the parameters of 퐺0 (superscripted with asterisks above) are often set using empirical Bayes principles
while a relatively ﬂat 퐺푎푚푚푎(1, 1) hyperprior is set on 훼. Speciﬁcally, 훽∗might be set to the ordinary least squares estimates,
and Σ∗may be set using the MLE covariance estimate. Empirical Bayes is a practical method of setting priors here as cross-
validation would be too computationally intensive. Moreover, we typically have no substantive knowledge that could guide these
choices. Centering the priors around empirical estimates also helps constrain the parameter draws to a reasonable range of the
observed data. Simulation studies in a variety of scenarios show that this tends to yield adequate frequentist properties (i.e.
credible intervals and point estimates with close to nominal coverage and bias, respectively, in repeated samples)28,29,30. This
approach is similar to Zellner’s g-prior - an empirical Bayes prior popular in the Bayesian model selection literature31.
Relationship to Kernel Regression
In this section, we discuss how the DP regression can be viewed as a Bayesian compromise between a fully empirical kernel
regression and a parametric regression.
A kernel regression estimate for a point with covariate vector 푋is simply a weighted average of all the observed outcome
values, each weighted by how “close” the vector 푋is to each observed covariate. Speciﬁcally, denote the centered Gaussian
kernel as 퐾ℎ(푢) (i.e. this is the density of a Gaussian with zero mean and variance ℎ). The Gaussian kernel regression32 is
deﬁned as
̂퐸[푌∣푋] =
푛
∑
푖=1
푤푘
푖(푋) ∫푌⋅퐾ℎ(푌−푌푖)푑푌.
(16)
Note that ∫푌⋅퐾ℎ(푌−푌푖)푑푌= 푌푖is just the Gaussian mean. The weights 푤푘
푖(푋) are given by
푤푘
푖(푋) =
퐾푔(푋−푋푖)
∑
푖퐾푔(푋−푋푖).
(17)
Now taking 훼→0 (corresponding to an improper, ﬂat prior) in the DP regression (13) yields
퐸[푌∣푋, 휔(푚)
1∶푛, 퐷] =
푛
∑
푖=1
푤(푚)
푖휇(푚)
푖
(푋),
(18)
with limiting weights
푤(푚)
푖
=
푝(푋∣휃(푚)
푖
)
∑
푖푝(푋∣휃(푚)
푖
)
.
(19)
Comparing these equations, it is clear that the improper extreme of the DP regression becomes a type of kernel regression. In
particular, if we set 푝(푋∣휃푖) to be Gaussian with mean 푋푖and variance 푔and set 휇(푚)
푖
(푋) = 푌푖, then the DP regression reduces
to a kernel regression estimate. Both models are covariate-weighted mixtures of subject level conditional mean models, though
the DP model is more satisfying from a statistical point of view. It outputs full posterior distribution over the regression. The
kernel regression typically produces a point estimate, with uncertainty estimation being more complicated. Moreover, with the
DP we can specify a covariate model, 푝(푋∣휃푖), that respects the support of the various covariates. This is in contrast to the
kernel regression, which uses a single kernel for the whole vector.
On the other extreme, take 훼>> 푛. Then, the DP regression becomes 퐸[푌∣푋, 휔(푚)
1∶푛, 퐷] ≈푤(푚)
0 휇(푚)
0 (푋). Recall here that 휇0
is the regression with parameters drawn from the prior 훽0 ∼퐺0. The weights 푤0 are also based on covariate parameters drawn
from the prior 휃0 ∼퐺0. In other words, this extreme results in a completely parametric model with parameters drawn from the
prior base disstribution. So we can view the DP regression as a type of posterior compromise between the kernel regression on
one extreme and a parametric regression on the other. It would also be fair to say that the DP regression is a regularized version of
the kernel regression. This perspective oﬀers more insight into the role the hyperparameters of the local outcome and covariate

18
Oganisian ET AL
distributions. Speciﬁcally, if 푝(푋∣휃푖) and 푝(푌푖∣푋푖, 훽푖, 휙푖) are Guassian, then the variance parameters of these distribution
play the same role as ℎin the Kernel regression. Here, ℎcontrols the bias-variance tradeoﬀ. Large values of ℎlead to a less
ﬂexible (more penalized) ﬁt, while small values of ℎlead to more ﬂexible (less penalized) ﬁt. Similarly, prior distributions on
the variance parameters of these distributions that favor small values will yield a more ﬂexible ﬁt with less shrinkage.
Computing Causal Eﬀects
The MCMC scheme involves obtaining posterior draws of {휔(푚)
1∶푛}1∶푀, which we can use to construct the mean regression
휇(푚)
푖
(퐴, 퐿) at each iteration. Under 퐼퐴.1 −퐼퐴.4, we can estimate causal contrasts such as Ψ = 퐸[푌1 −푌0] by integrating
this regression over the confounder distribution, just as in the parameter setting. Here, integration is done over a BB draw as in
Section 3.3,
1. Sample from the DP posterior to get
휇(푚)
푖
(퐴, 퐿)
2. Draw BB weights
푝(푚)
1∶푛∣푊∼퐷푖푟(11∶푛)
3. Integrate to get posterior draw of Causal Eﬀect:
Ψ(푚) ≈
푛
∑
푖=1
푝(푚)
푖
{
휇(푚)
푖
(1, 퐿푖) −휇(푚)
푖
(0, 퐿푖)
}
The computationally demanding portion of the above is Step 1 and can be done using oﬀ-the-shelf R packages such as ChiRP30.
This package runs the DP model in (12) and, by default, speciﬁes local Gaussian distributions for non-binary and local Bernoulli
distributions for binary covariates. Figure 4 visualizes predictions trained using ChiRP, where the conditional outcome distri-
bution is simulated from a mixture of two damped harmonic oscillators. It also plots the ATE posterior from the DP model,
computed as described above. The ATEs are computed using a synthetic data set with a binary treatment and single Gaussian
confounder. In this example, the true treatment eﬀect is a quadratic function of 퐿. The ﬁgure also displays ATEs from a frequen-
tist linear additive model, 퐸[푌∣퐴, 퐿] = 훽0+훽1퐴+훽2퐿, estimated using OLS. These results are biased in this scenario. Detailed
descriptions of the synthetic example used for ATE computations in Appendix E. This appendix also contains implementation
of the ATE computation using ChiRP.
Survey of Recent DP Applications
The DP and related priors over random probability distributions such as the enriched DP33,34, dependent DP35,36, and centered
DP37 have also been applied to causal inference. For instance, Kim et al. (2017) employ a Dirichlet Process mixture to estimate
direct and indirect eﬀects in a mediation analysis22. They specify a joint Gaussian model for the outcome, mediator, and con-
founders, and place a DP prior on the mean vector and covariance matrix. Later work applied DPs to latent mediators38. Roy et
al. (2018) use an enriched DP to model the joint distribution of the outcome and confounders, and estimate ATEs via posterior
standardization over the estimated distribution of the confounders29. They also describe posterior imputation of missing-at-
random covariates within their model. Roy et al. (2018) use a dependent DP to estimate a marginal structural model and apply it
to causal estimation with a survival outcome29. Xu et al. (2016) applied a similar dependent DP model to estimate causal eﬀects
of dynamic treatment regimes39. Xu et al. (2018) propose an approach for estimating quantile causal eﬀects (e.g. diﬀerence in
median outcome under one intervention versus another)40. A Bayesian Additive Regression Tree (BART) probit model is used
to to model the propensity score as a function of covariates, while a Gaussian outcome model is speciﬁed conditional on the
propensity score. The parameters of the joint outcome-propensity score model are given a DP mixture prior. We will describe
BART models in the next section. Oganisian et al. (2018) specify a generative model for the joint outcome, propensity score,
and confounder distribution, where the conditional outcome model is a two-part zero-inﬂated model41. The parameters of this
joint are given a DP mixture prior. Posterior standardization was conducted and a method for posterior predictive checks of pos-
itivity (퐼퐴.4) are proposed. Others42 have applied DP models to adjust for post-treatment variables via principal stratiﬁcation43.
Centered DPs have also been used to estimate heterogeneous treatment eﬀects44. Here, the centered DP was used as a prior for
an unspeciﬁed error term distribution of an accelerated failure time model.

Oganisian ET AL
19
6.2
Bayesian Additive Regression Trees
The original BART approach of Chipman et al.45 models the conditional outcome distribution as a Gaussian with mean function
휇(푋) =
퐽∑
푗=1
푔(푋; 푇푗, 푀푗)
(20)
Above, the conditional mean is modeled as a sum of predictions from 퐽regression trees, 푇푗. In this sense BART can be viewed
as an ensemble learner. Speciﬁcally, 푇푗consists of a set of nodes and splitting rules with an associated vector of terminal node
parameters 푀푗. The function 푔maps covariates 푋푖to one of the terminal node parameters in 푀푗. The mean is then the sum of
the terminal node predictions from each of the trees. The BART prior, consisting of priors on the splitting rules and terminal
node parameters, is formulated to induce shrinkage towards shallow trees. This helps prevent over-ﬁtting. This serves as a
probabilistically principled alternative to pruning heuristics often used with random forests. Predictions for a toy examples are
given in Figure 4. Notice that BART produces a step function as a result of the the assumed tree structure of 휇(푋). This holds
even as BART interpolates across the covariate space with no training data (the red points in the plot indicate held out test data).
The MCMC inference engine behind BART relies on the “backﬁtting”46 approach, which takes posterior draws of each tree
structure and their terminal node parameters sequentially. Each tree is ﬁt using the residual from the previously ﬁt trees as the
outcome. At every iteration 푚, one such cycle through the 퐽trees yields 푇(푚)
푗
and 푀(푚)
푗
, which we can then use to construct a
regression
휇(푚)(퐴, 퐿) =
퐽∑
푗=1
푔(퐴, 퐿; 푇(푚)
푗
, 푀(푚)
푗
)
We can use existing software in R such as BayesTree to obtain the posterior draws for 휇(푚)(퐴, 퐿) under both interventions.
We ﬁrst stack two test data sets 퐷푎
푡푒푠푡= (퐴= 푎, 퐿푖)1∶푛for 푎∈{0, 1} into a single test set {퐷1
푡푒푠푡, 퐷0
푡푒푠푡}. The training data
simply consists of the observed data set 퐷푡푟푎푖푛= (푌푖, 퐴푖, 퐿푖)1∶푛. The package will then output BART estimates of 휇(푋) under
both interventions in the stacked test set {휇(푚)(1, 퐿푖), 휇(푚)(0, 퐿푖)}1∶푛for 푚= 1, … 푀. To compute the integral in (1), we can
post-process the draws in R as follows. For each iteration, take a BB draw 푝(푚)
1∶푛and compute
Ψ(푚) =
푛
∑
푖=1
푝(푚)
푖
(휇(푚)(1, 퐿푖) −휇(푚)(0, 퐿푖)
)
In this way we obtain draws from the posterior of the ATE. Our review of BART was cursory, with a focus on causal estimation.
We refer the reader to Tan et al. (2019) for a thorough tutorial on BART and its various extensions47.
Survey of Recent BART Applications
We now provide a brief (but by no-means exhaustive) survey of BART in interesting causal inference applications. Hill (2011)
ﬁrst applied BART to ATE estimation48. BART has since enjoyed wide popularity in causal estimation. For instance, it has
been used to formulate fully Bayesian semi-parametric estimation of structural mean models49, fully nonparametric estimation
of optimal dynamic treatment regimes50, and estimation of causal eﬀects in the presence of positivity violations51. The latter
augments BART with splines to extrapolate to regions of the data with deterministic treatment (i.e. non-overlap regions). Work
by Hahn et al. (2017) has focused on improving the use of BART for causal inference52. They separate out the the treatment and
confounder eﬀects in the outcome regression, which aims to improve bias due to what the authors term “regularization-induced
confounding”. We also note that the original BART model presented here has been extended for outcomes with diﬀerent support.
For instance, the mean function modeled using BART can be run through a probit link when the outcome is binary. Sparapani
et al. proposed using BART for survival outcomes53. They use a discrete-time failure model where the probability of death at
each time point is modeled with a BART probit.
6.3
Gaussian Process (GP) Models
Here we review another BNP approach using Gaussian process (GP) priors for regression modeling54,55. Although less widely
used in the causal literature relative to DP and BART models, GPs are popular in the BNP literature. They can be implemented
in Stan and so may be a practical choice for applied researchers. We consider the same problem of modeling, 휇(푋), the mean
function of a Gaussian outcome, 푌∣푋∼푁(휇(푋), 휙). The GP can be motivated as a prior over the space of regression functions,

20
Oganisian ET AL
휇(푋). We say that 휇(푋) follows a GP with prior mean function 휃0(푋) and covariance 푪(푋; 휂, 휌). Together with the full model,
this is denoted as
푌∣휇(푋) ∼푁
(
휇(푋), 휙
)
휇(푋) ∼(휃0, 푪).
(21)
Above we have suppressed dependence of 휃0 and 푪on 푋and hyperparameters (휂, 휌) for compactness. Our prior belief is that
the regression function 휇(푋) is randomly distributed around some mean regression function 휃0, with linearity and smoothness
of 휇(푋) relative to 휃0 being controlled by the hyperparameters. For example, a common prior mean function choice is 휃0(푋) = 0
- a hyperplane through the origin. Another, approach is to set 휃0(푋) = 푋′훽. The latter speciﬁcation centers our prior around
a linear/additive prior mean regression function, while 휂and 휌allow for deviations from this prior if the data are inconsistent.
The covariance can have many speciﬁed forms, but we focus on the exponential-quadratic form popular in the causal literature,
푪푖푗= 휂exp{−휌||푋푖−푋푗||2} + .01훿푖푗,
(22)
where ||푣|| =
√
푣′푣denotes the 퐿2 vector norm. 푪is the 푛× 푛matrix with elements given by 푪푖푗. Intuitively, this describes
the prior belief that the regression function evaluations should be similar for two subjects with similar covariate vectors. The
evaluations should diﬀer more for two subjects who have very diﬀerent covariates. The parameter 휌controls how similar these
function evaluations are for subjects with similar covariates. Larger 휌favors more similar regression evaluations. The parameter
휂controls the linearity of the regression function - with smaller 휂penalizing non-linearity and a priori favoring linear regression
functions.
Stan can be used to sample from the posterior distribution of the regression function 휇(푋). Speciﬁcally, it outputs 푀draws
from the posterior of the regression function {휇(푚)(푋)}1∶푚. These posterior draws are visualized in Figure 4 for both training
and held-out test points. Causal ATE estimation can be done by feeding Stan two held-out test data sets, 퐷푎
푡푒푠푡= (푎, 퐿푖)1∶푛
for 푎∈{0, 1}. This returns posterior draws the regression function under both interventions {휇(푚)(1, 퐿푖), 휇(푚)(0, 퐿푖)}1∶푛for
푚= 1, … 푀. Within Stan, standardization can be done using BB as described before. For each iteration, take a BB draw 푝(푚)
1∶푛
and compute
Ψ(푚) =
푛
∑
푖=1
푝(푚)
푖
{
휇(푚)(1, 퐿푖) −휇(푚)(0, 퐿푖)
}
Posterior inference for the ATE using this GP model is shown in Figure 4. Implementation details for this synthetic example
are given in Appendix E. Finally, we note that GPs can easily accommodate outcomes with non-continuous/real support. For
instance, with count outcomes we could specify 푌∣푋∼푃표푖푠
(
exp(휇(푥))
)
. Here, we model log(퐸[푌∣푋]) = 휇(푋) and place
a GP prior on 휇(푋) as in the Gaussian case.
Recent Applications in Causal Inference
Gaussian process priors have seen some usage in the causal literature. For instance, the dependent DP, used for posterior inference
about marginal structural models29 and dynamic treatment regimes39 is essentially a combination of the DP and GP. Speciﬁcally,
each cluster-speciﬁc regression function in the DP is assigned a GP prior. Just as the Guassian local model in (12) induced
a posterior regression that is a mixture of linear regression functions, the dependent DP induces a posterior regression that
is a mixture of GP regression functions. Other uses of GPs included modeling pollution outcomes in the presence of spatial
interference (i.e. violations of 퐼퐴.3 that exhibit spatial structure)56 and estimation of propensity scores57.
7
DISCUSSION
In this paper we reviewed causal eﬀect estimation from a Bayesian perspective in point-treatment and time-varying treatment
settings. For the latter, we outlined how to estimate causal eﬀects of both static and dynamic treatment regimes. Both parameteric
and nonparametric settings were discussed. Along the way, we discussed the utility of priors both for providing interpretable
shrinkage and also for conducting causal sensitivity analyses. Throughout, we emphasize that the ad-hoc procedures we often use
correspond to strongly informative priors. Throughout, we have highlighted various BNP techniques used for causal estimation
in the literature. We hope that these surveys will be useful literature overviews that can serve as a starting point for those who
want to delve further into these methods.

Oganisian ET AL
21
We note that our treatment of Bayesian causal estimation diﬀers from that of Rubin58 - which is fundamentally a ﬁnite-
sample approach. In this approach, each subject’s counterfactual is treated as a missing data point and the target is the posterior
distribution over these missing variables, 푝({푌1−퐴푖
푖
}1∶푛, ∣퐷). Here, 퐷= {푌퐴푖
푖, 퐴푖, 퐿푖}1∶푛consists of the observed potential
outcomes, treatment assignment, and confounder vector. Denote the parameters governing the observed data distribution as 휔.
By Bayes’ rule we can express the desired posterior as
푝({푌1−퐴푖
푖
}1∶푛, ∣퐷) = ∫푝({푌1−퐴푖
푖
}1∶푛, ∣휔)푝(휔∣퐷)푑휔
∝∫푝({푌1−퐴푖
푖
}1∶푛, ∣휔)푝(퐷∣휔)푝(휔)푑휔
Suppose that 푛1 of the 푛subjects are treated. Then the likelihood is
푝(퐷∣휔) = 푝(푌1
푖, … , 푌1
푛1, 푌0
푛1+1, … 푌0
푛∣퐿1∶푛, 휔)
Thus this approach requires a model for the joint distribution of 푝(푌1, 푌0 ∣퐿, 휔), which is not identiﬁable in the data: we
never observe both potential outcomes for any subject. By non-identiﬁable, we mean that the posterior (even if it is proper)
over this joint distribution will be completely driven by the prior. This issue is not unique to Bayesian inference. For instance,
the variance of the sample average treatment eﬀect is not identiﬁable from a frequentist perspective either59. It is a function
of the covariance of the two potential outcomes, which we cannot learn. Ding et al. (2018) provide an excellent review of
Bayesian causal inference from this missing data perspective60. This missing data approach is the central idea behind the more
recent PENCOMP method61, which uses a penalized splines to impute the missing counterfactuals. The approach described in
our paper is what Ding et al. (2018) term the “super-population” approach, rather than the ﬁnite-sample approach. This super-
population approach focuses on estimands that are a function of the parameters governing the data generation process. Once we
have a good model of the process, these estimands are simply transformations of these parameters.
ACKNOWLEDGMENTS
Jason Roy was supported by the National Center for Advancing Translational Sciences (NCATS), a component of the National
Institute of Health (NIH) under Award Number UL1TR0030117. We thank Dr. Nandita Mitra (University of Pennsylvania) and
Shira Mitchell (Civis Analytics) for very helpful comments and suggestions that improved the manuscript.
SUPPORTING INFORMATION
All code supporting synthetic examples in this paper can be found in the accompanying GitHub repository at https://github.
com/stablemarkets/intro_bayesian_causal
References
1. Rubin DB. Estimating causal eﬀects of treatments in randomized and nonrandomized studies.. Journal of educational
Psychology 1974; 66(5): 688-701.
2. Robins J. A new approach to causal inference in mortality studies with a sustained exposure period - application to control
of the healthy worker survivor eﬀect. Mathematical Modelling 1986; 7(9): 1393 - 1512. doi: https://doi.org/10.1016/0270-
0255(86)90088-6
3. Greenland S, Pearl J, Robins JM. Causal diagrams for epidemiologic research. Epidemiology 1999: 37–48.
4. Cole S, Frangakis C. The consistency statement in causal inference: a deﬁnition or an assumption?. Epidemiology 2009;
20: 1–5.
5. Hernán MA, Taubman SL. Does obesity shorten life? The importance of well-deﬁned interventions to answer causal
questions. International Journal of Obesity 2008; 32(3): S8–S14. doi: 10.1038/ijo.2008.82

22
Oganisian ET AL
6. Hudgens MG, Halloran ME. Toward Causal Inference With Interference. Journal of the American Statistical Association
2008; 103(482): 832-842. doi: 10.1198/016214508000000292
7. Imai K, Keele L, Yamamoto T. Identiﬁcation, Inference and Sensitivity Analysis for Causal Mediation Eﬀects. Statist. Sci.
2010; 25(1): 51–71. doi: 10.1214/10-STS321
8. Daniel R, Cousens S, De Stavola B, Kenward MG, Sterne JAC. Methods for dealing with time-dependent confounding.
Statistics in Medicine 2013; 32(9): 1584-1618. doi: 10.1002/sim.5686
9. Baiocchi M, Cheng J, Small DS. Instrumental variable methods for causal inference. Statistics in Medicine 2014; 33(13):
2297-2340. doi: 10.1002/sim.6128
10. Lechner M. The Estimation of Causal Eﬀects by Diﬀerence-in-Diﬀerence Methods. University of St. Gallen Department
of Economics working paper series 2010 2010-28, Department of Economics, University of St. Gallen; 2010.
11. Imbens G, Lemieux T. Regression Discontinuity Designs: A Guide to Practice. Working Paper 13039, National Bureau of
Economic Research; 2007
12. Andrieu C, De Freitas N, Doucet A, Jordan MI. An introduction to MCMC for machine learning. Machine learning 2003;
50(1-2): 5–43.
13. Carpenter B, Gelman A, Hoﬀman M, et al. Stan: A Probabilistic Programming Language. Journal of Statistical Software,
Articles 2017; 76(1): 1–32. doi: 10.18637/jss.v076.i01
14. Gelman A, Carlin JB, Stern HS, Rubin DB. Bayesian Data Analysis. Chapman and Hall/CRC. 2nd ed. ed. 2004.
15. Rubin DB. The Bayesian Bootstrap. Ann. Statist. 1981; 9(1): 130–134. doi: 10.1214/aos/1176345338
16. Wang C, Dominici F, Parmigiani G, Zigler CM. Accounting for uncertainty in confounder and eﬀect modiﬁer selection when
estimating average causal eﬀects in generalized linear models. Biometrics 2015; 71(3): 654-665. doi: 10.1111/biom.12315
17. Carvalho CM, Polson NG, Scott JG. The horseshoe estimator for sparse signals. Biometrika 2010; 97(2): 465–480.
18. George EI, McCulloch RE. APPROACHES FOR Bayesian VARIABLE SELECTION. Statistica Sinica 1997; 7(2): 339–
373.
19. McCandless LC, Gustafson P, Levy A. Bayesian sensitivity analysis for unmeasured confounding in observational studies.
Statistics in Medicine 2007; 26(11): 2331-2347. doi: 10.1002/sim.2711
20. Gustafson P, McCandless LC, Levy AR, Richardson S. Simpliﬁed Bayesian Sensitivity Analysis for Mismeasured and
Unobserved Confounders. Biometrics 2010; 66(4): 1129-1137. doi: 10.1111/j.1541-0420.2009.01377.x
21. McCandless LC, Somers JM. Bayesian sensitivity analysis for unmeasured confounding in causal mediation analysis.
Statistical Methods in Medical Research 2019; 28(2): 515-531. PMID: 28882092doi: 10.1177/0962280217729844
22. Kim C, Daniels MJ, Marcus BH, Roy JA. A framework for Bayesian nonparametric inference for causal eﬀects of mediation.
Biometrics 2017; 73(2): 401-409. doi: 10.1111/biom.12575
23. Gustafson P. Bayesian inference in partially identiﬁed models: Is the shape of the posterior distribution useful?. Electron.
J. Statist. 2014; 8(1): 476–496. doi: 10.1214/14-EJS891
24. Bishop CM. Pattern Recognition and Machine Learning (Information Science and Statistics). Berlin, Heidelberg: Springer-
Verlag . 2006.
25. Shahbaba B, Neal RM. Nonlinear Models Using Dirichlet Process Mixtures. 2007.
26. Hannah LA, Blei DM, Powell WB. Dirichlet process mixtures of generalized linear models. Journal of Machine Learning
Research 2011; 12(Jun): 1923–1953.

Oganisian ET AL
23
27. Neal RM. Markov Chain Sampling Methods for Dirichlet Process Mixture Models. Journal of Computational and Graphical
Statistics 2000; 9(2): 249-265. doi: 10.1080/10618600.2000.10474879
28. Roy J, Lum KJ, Daniels MJ. A Bayesian nonparametric approach to marginal structural models for point treatments and a
continuous or survival outcome. Biostatistics 2017; 18(1): 32-47. doi: 10.1093/biostatistics/kxw029
29. Roy J, Lum KJ, Zeldow B, Dworkin JD, Re VL, Daniels MJ. Bayesian nonparametric generative models for causal inference
with missing at random covariates. Biometrics 2018; 74(4): 1193–1202. doi: 10.1111/biom.12875
30. Oganisian A. ChiRP: Chinese Restaurant Process Mixtures for Regression and Clustering. Journal of Open Source Software
2019; 4(35): 1287. doi: 10.21105/joss.01287
31. Zellner A. On assessing prior distributions and Bayesian regression analysis with g-prior distributions. Bayesian Inference
and Decision techniques 1986.
32. Nadaraya EA. On Estimating Regression. Theory of Probability & Its Applications 1964; 9(1): 141-142.
doi:
10.1137/1109020
33. Wade S, Mongelluzzo S, Petrone S, others . An enriched conjugate prior for Bayesian nonparametric inference. Bayesian
Analysis 2011; 6(3): 359–385.
34. Wade S, Dunson DB, Petrone S, Trippa L. Improving prediction from Dirichlet process mixtures via enrichment. The
Journal of Machine Learning Research 2014; 15(1): 1041–1071.
35. MacEachern SN. Dependent nonparametric processes. ASA 1999 Proceedings of the Section on Bayesian Statistics 1999.
36. MacEachern SN. Dependent Dirichlet Process. 2000.
37. Yang M, Dunson DB, Baird D. Semiparametric Bayes hierarchical models with mean and variance constraints. Computa-
tional Statistics & Data Analysis 2010; 54(9): 2172 - 2186. doi: https://doi.org/10.1016/j.csda.2010.03.025
38. Kim C, Daniels M, Li Y, Milbury K, Cohen L. A Bayesian semiparametric latent variable approach to causal mediation.
Statistics in Medicine 2018; 37(7): 1149-1161. doi: 10.1002/sim.7572
39. Xu Y, Müller P, Wahed AS, Thall PF. Bayesian Nonparametric Estimation for Dynamic Treatment Regimes With Sequen-
tial Transition Times. Journal of the American Statistical Association 2016; 111(515): 921-950. PMID: 28018015doi:
10.1080/01621459.2015.1086353
40. Xu D, Daniels MJ, Winterstein AG. A Bayesian nonparametric approach to causal inference on quantiles. Biometrics 2018;
74(3): 986-996. doi: 10.1111/biom.12863
41. Oganisian A, Mitra N, Roy JA. A Bayesian nonparametric model for zero-inﬂated outcomes: Prediction, clustering, and
causal estimation. Biometrics; n/a(n/a). doi: 10.1111/biom.13244
42. Schwartz SL, Li F, Mealli F. A Bayesian semiparametric approach to intermediate variables in causal inference. Journal of
the American Statistical Association 2011; 106(496): 1331–1344.
43. Frangakis CE, Rubin DB. Principal Stratiﬁcation in Causal Inference. Biometrics 2002; 58(1): 21-29. doi: 10.1111/j.0006-
341X.2002.00021.x
44. Henderson NC, Louis TA, Rosner GL, Varadhan R. Individualized Treatment Eﬀects with Censored Data via Fully
Nonparametric Bayesian Accelerated Failure Time Models. 2017.
45. Chipman HA, George EI, McCulloch RE. BART: Bayesian additive regression trees. Ann. Appl. Stat. 2010; 4(1): 266–298.
doi: 10.1214/09-AOAS285
46. Breiman L, Friedman JH. Estimating Optimal Transformations for Multiple Regression and Correlation. Journal of the
American Statistical Association 1985; 80(391): 580-598. doi: 10.1080/01621459.1985.10478157

24
Oganisian ET AL
47. Tan YV, Roy J. Bayesian additive regression trees and the General BART model. Statistics in Medicine 2019; 38(25):
5048-5069. doi: 10.1002/sim.8347
48. Hill JL. Bayesian Nonparametric Modeling for Causal Inference. Journal of Computational and Graphical Statistics 2011;
20(1): 217-240. doi: 10.1198/jcgs.2010.08162
49. Zeldow B, Lo Re III V, Roy J. A semiparametric modeling approach using Bayesian Additive Regression Trees with an
application to evaluate heterogeneous treatment eﬀects. The annals of applied statistics. 2019-09; 13(3): 1989,2010.
50. Murray TA, Yuan Y, Thall PF. A Bayesian Machine Learning Approach for Optimizing Dynamic Treatment Regimes.
Journal of the American Statistical Association 2018; 113(523): 1255-1267. doi: 10.1080/01621459.2017.1340887
51. Nethery RC, Mealli F, Dominici F. Estimating population average causal eﬀects in the presence of non-overlap: The eﬀect
of natural gas compressor station exposure on cancer mortality. Ann. Appl. Stat. 2019; 13(2): 1242–1267. doi: 10.1214/18-
AOAS1231
52. Hahn PR, Murray JS, Carvalho C. Bayesian regression tree models for causal inference: regularization, confounding, and
heterogeneous eﬀects. 2017.
53. Sparapani RA, Logan BR, McCulloch RE, Laud PW. Nonparametric survival analysis using Bayesian Additive Regression
Trees (BART). Statistics in Medicine 2016; 35(16): 2741-2753. doi: 10.1002/sim.6893
54. Neal RM. Monte Carlo implementation of Gaussian process models for Bayesian regression and classiﬁcation. arXiv
preprint physics/9701026 1997.
55. Rasmussen CE, Williams CKI. Gaussian Processes for Machine Learning. MIT Press . 2006.
56. Zigler CM, Dominici F, Wang Y. Estimating causal eﬀects of air quality regulations using principal stratiﬁcation for spatially
correlated multivariate intermediate outcomes. Biostatistics 2012; 13(2): 289-302. doi: 10.1093/biostatistics/kxr052
57. Vegetabile BG, Gillen DL, Stern HS. Optimally balanced Gaussian process propensity scores for estimating treat-
ment eﬀects. Journal of the Royal Statistical Society: Series A (Statistics in Society) 2020; 183(1): 355-377.
doi:
10.1111/rssa.12502
58. Rubin DB. Bayesian Inference for Causal Eﬀects: The Role of Randomization. Ann. Statist. 1978; 6(1): 34–58.
doi:
10.1214/aos/1176344064
59. Imbens GW. Nonparametric Estimation of Average Treatment Eﬀects under Exogeneity: A Review. Working Paper 294,
National Bureau of Economic Research; 2003
60. Ding P, Li F. Causal Inference: A Missing Data Perspective. Statist. Sci. 2018; 33(2): 214–237. doi: 10.1214/18-STS645
61. Zhou T, Elliott MR, Little RJA. Penalized Spline of Propensity Methods for Treatment Comparison. Journal of the American
Statistical Association 2019; 114(525): 1-19. doi: 10.1080/01621459.2018.1518234
APPENDIX
A CAUSAL DOSE EFFECT EXAMPLE
A.1 Data generation and implementation in Stan
This appendix provides a more detailed walkthrough of the synthetic example and model discussed in Section 3.1. We refer the
reader to the Stan manual online for details about the language, syntax, and best practices. The toy example was simulated as
follows. For 퐾= 10 doese levels 푘∈{0, … , 9}, and 푛= 100 subjects, indexed by 푖we simulate:
1. single continuous confounder:
퐿푖∼푁(0, 1)

Oganisian ET AL
25
2. treatment assignment:
퐴푖∣퐿푖∼푃(퐴푖= 푘) ∝expit(1 −(2∕9) ⋅푘+ 퐿푖−.5푘퐿푖)
3. outcome:
푌푖∣퐴푖, 퐿푖∼푁(5 ⋅Φ(퐴푖−5) −5 ⋅퐿푖, 2)
Above, Φ(⋅) is the standard normal CDF. Notice that the baseline probability of treatment decreases with dose level. Reﬂecting
a realistic scenario where fewer patients are likely to be assigned to higher doses. The confounder 퐿푖impacts both treatment and
the outcome. Higher values of 퐿푖make higher dose assignments more likely (note the −.5푘퐿푖term). At the same time, higher
퐿푖lead to lower outcomes. This simulation takes place in the ﬁrst several lines of dose_response.R in the GitHub repository.
The logic behind using Φ is purely to have an interesting/realistic toy example. 퐴= 5 is about the middle dose level. Using
Φ we are ensuring that doses much higher than the middle have diminishing returns on the outcome. Each dose increase aﬀects
the outcome less and less. Thus the true dose eﬀect curve is 5 ⋅Φ(퐴−5), which is plotted in red in Figure 1a. We need to adjust
for 퐿푖because patients with higher 퐿are more likely to be treated at all levels and less likely to have higher outcomes.
The full probability model is
푌푖∣퐴푖, 퐿푖∼푁(휇(퐴푖, 퐿푖), 휙)
Where, 휇(퐴푖, 퐿푖) is the conditional expectation in (3) - a function of 휃0∶퐾and 훽. In the paper we discussed the priors on 휃1∶퐾.
These took the form of a sequence of dependent Gaussian priors, as a function of 휇and 휏푘. This likelihood is specifying in the
”model” block of the Stan code DR_model.stan:
model {
// specify priors
theta[1] ~ normal( 0, 10 );
theta[2] ~ normal( 2*theta[1], 1);
for(j in 3:num_A_levels){
theta[j] ~ normal( 2*theta[j-1] - theta[j-2], 1 );
}
beta ~ normal(0, 10);
phi ~ cauchy(0,10);
// specify likelihood
Y ~ normal(L*beta + A*theta , phi);
}
Note that in the above, an intercept is included in 퐿. Notice here we have set 휇= 0, 휏1 = 10, and 휏1∶퐾= 1. We specify a
Gaussian prior with standard deviation (SD) 10. This is a relatively ﬂat prior since this SD is larger than the sampling model
SD= 2. On 휙we place a half-Cauchy prior with scale 10 - again, fairly ﬂat. If we wanted to place priors on, say, 휇instead of
setting it at 휇= 0, we could have instead speciﬁed
model {
// specify priors
mu ~ normal(0, 10);
theta[1] ~ normal( mu, 10 );
...
}
We would also need to declare 휇in the “parameters” block of DR_model.stan. The same idea holds for 휏0∶퐾. We could also
specify hyper-prior distributions for these variables. We ﬁx these to constant values for simplicity of the illustrated examples
and to maintain focus on the AR1 prior construction. Another important portion of DR_model.stan worth highlighting is the
“generated quantities” block. In this block, we can perform post-processing of posterior draws of parameters. For instance, we
can post-process draws of 휃1∶퐾to compute the curve Ψ(푘):
generated quantities {
vector[num_A_levels] Psi;
Psi[1] = theta[1];
for(k in 2:num_A_levels){
Psi[k] = theta[k] - theta[k-1];
}
}

26
Oganisian ET AL
Above, we declare a vector of length num_A_levels (which is 퐾= 10 in this example). And compute Ψ(푘) = 휃푘−휃푘−1 as
deﬁned in the main text. In dose_response.R we call the Stan model using the rstan package - which allows us to call Stan
programs from R. Using the R function stan_model(), we compile the Bayesian model speciﬁed in DR_model.stan. Using the R
function sampling() we take 500 posterior draws after a 500 draw burn-in period. Only one chain is run. In practice, more chains
should be used with more posterior draws and a longer burnin period. We should check that the chains for Ψ in the generated
quantities block has converged. Posterior predictive checks should also be done to evaluate model ﬁt. Guidance for convergence
and posterior predictive checks is no diﬀerent in this causal setting than in the general Bayesian modeling framework, so we
leave details to standard Bayesian texts such as Bayesian Data Analysis14.
A.2 Implementation in SAS
The ﬁle dose_analysis.sas in our companion GitHub repository repeats the analysis above using PROC MCMC in SAS. Within
PROC MCMC, we use the “parms” statement to declare the parameters of our model. In this case, we declare the dispersion
parameter “phi”, the nine conditional dose eﬀects ( t1, t2, ..., t9), the confounder eﬀect ( “bL” ), and the intercept (“b0” ):
parms phi t1-t9 bL b0;
The AR1 prior can be speciﬁed using the “prior” statement:
prior t1 ~ normal(0, sd=10);
prior t2 ~ normal(2*t1, sd=1);
prior t3 ~ normal(2*t2 - t1, sd=1);
prior t4 ~ normal(2*t3 - t2, sd=1);
prior t5 ~ normal(2*t4 - t3, sd=1);
prior t6 ~ normal(2*t5 - t4, sd=1);
prior t7 ~ normal(2*t6 - t5, sd=1);
prior t8 ~ normal(2*t7 - t6, sd=1);
prior t9 ~ normal(2*t8 - t7, sd=1);
The Gaussian likelihood is speciﬁed using the “model” statement:
muA = t1*A1 + t2*A2 + t3*A3 + t4*A4 + t5*A5 + t6*A6 + t7*A7 + t8*A8 + t9*A9;
model Y ~ normal( b0 + muA + bL*L
, sd=phi);
Finally, for computational eﬃciency, we can compute the causal eﬀects of interest directly within PROC MCMC as simple
transformations of t1, t2, ...t9 after specifying the likelihood. Note this is completely analogous to the generated quantities block
in Stan.
Psi[1] = t1 ;
Psi[2] = t2 - t1;
Psi[3] = t3 - t2;
Psi[4] = t4 - t3;
Psi[5] = t5 - t4;
Psi[6] = t6 - t5;
Psi[7] = t7 - t6;
Psi[8] = t8 - t7;
Psi[9] = t9 - t8;
Overall, the results from SAS are quite similar to results in Stan.
B CONDITIONAL CAUSAL EFFECTS
B.1 Data generation and implementation in Stan
This appendix walks through simulation and analysis of the synthetic example discussed in Section 3.2, including imple-
mentation of the Bayesian bootstrap in Stan. The synthetic data was simulated for 푛= 500 subjects (indexed here by 푖) as
follows:
1. Confounder 푊푖∼푁(0, 1).
2. Stratum membership, 푉푖, with probability 푃(푉푖= 푣) = 푝푣for 푣∈{1, 2, … , 5}. Where we set
푝1∶푣= ( 3
10, 3
10, 2
10, 1
10, 1
10)

Oganisian ET AL
27
3. Treatment assignment as Bernoulli with probability
푃(퐴푖∣푊푖, 푉푖= 푣) = expit(1 ⋅푊푖+ 훾푣)
Where 훾1∶5 = (0, −.5, .5, .5, −.5)
4. Scalar Bernoulli outcome with probability
푃(푌푖∣퐴푖, 푊푖, 푉푖) = expit[−1 + 푊푖+ (1 +
5
∑
푣=2
휂푣퐼(푉푖= 푣))퐴푖]
Where 휂2∶5 = (−.5, 0, .5, .6) (푉= 1 is the reference).
Again note that 푊푖and 푉푖both impact treatment probability and the outcome probability. The strata membership simulation
mirrors practical examples where some strata are more populated (i.e. with probability 3∕10) than other strata (i.e. with proba-
bility 1∕10). In the outcome model, notice that the conditional treatment eﬀect varies with stratum membership. Motivating the
need for causal eﬀect estimates conditional on each stratum. This simulation is done in the top portion of partial_pool.R.
The full probability model we specify for the outcome is that
푌푖∣퐴푖, 푊푖, 푉푖∼퐵푒푟(휇(퐴푖, 퐿푖))
where 휇(퐴푖, 퐿푖) is the conditional expectation in (6), reproduced here with notation speciﬁc to this example
퐸[푌푖∣퐴푖, 퐿푖] = 휎
{
훾+ 훽푤푊푖+
5
∑
푣=2
훽푣퐼(푉푖= 푣) + [휃1 +
5
∑
푣=2
휃푣퐼(푉푖= 푣)]퐴푖
}
Recall here that 휎{⋅} is the inverse logit link. Note here that 휃1 is the conditional (on 푊) treatment eﬀect in stratum 1 - which,
in this parameterization, is the reference stratum. Similarly, 휃1 + 휃푣is the treatment eﬀect in stratum 푣for 푣∈2, … , 5.
The Bayesian model is speciﬁed in partial_pool.stan. Below, is the “model” block where we specify the prior in (7) and
likelihood. In the code, “W” is an 푛× 1 matrix containing each subject’s confounder value and “V” is an 푛× 5 matrix with 푖푡ℎ
row (1, 퐼(푉푖= 2), 퐼(푉푖= 3), 퐼(푉푖= 4), 퐼(푉푖= 5)). Thus, 퐼(푉푖= 1) is the reference. The variable “theta” is a 5 × 1 vector, 휃1∶5.
The variable 훽푣is a 5 × 1 vector of 푉-speciﬁc main eﬀects, 훽2∶5 including a constant ( 훾in the model above ).
The prior for “theta” is speciﬁed to induce partial pooling as discussed. We set the standard deviation of the Gaussian priors
on 휃1∶5 to be 휏= .5. A Gaussian hyper-prior is placed on 휇. Note that on a logit scale this is quite ﬂat. A Gaussian prior is also
used on the coeﬃcient of the confounder and intercept
model {
// specify priors
beta_w ~ normal(0, 1);
beta_v ~ normal(0, 1);
mu ~ normal(0, 1);
theta[1] ~ normal( mu, .5 );
theta[2:Pv] ~ normal( mu - theta[1], .5);
// specify likelihood
for(i in 1:N){
Y[i] ~ bernoulli_logit( W[i]*beta_w + V[i]*beta_v + ( V[i]*theta )*A[i] ) ;
}
}
As before in Appendix A, we can use the generated quantities block for post-processing. As discussed in the main manuscript,
this involves integrating the estimated model over a Bayesian bootstrap (BB) estimate of the conditional distribution of 푊∣푉,
푃푣(푊). Below, we include an excerpt from partial_pool.stan that loops through each stratum of 푉and computes a causal odds
ratio for that stratum. Below, we compute the conditional mean outcome under intervention 퐴= 1 and 퐴= 0 for each subject:
cond_mean_y1 and cond_mean_y0, respectively. Then we take a weighted average of these conditional means, with bootstrap
weights coded as bb_weights. Here, the Stan function dirichlet_rng takes a draw from 퐷푖푟(1푛푣), which is the BB posterior
estimate of 푃푣(푊). This weighted average is an estimate of the marginal mean under each intervention, coded as marg_mean_y1
and marg_mean_y0. Computing the odds ratio is done as usual using these marginal means.
generated quantities {

28
Oganisian ET AL
real marg_mean_y1;
real marg_mean_y0;
real odds_1;
real odds_0;
...
// cycle through strata of interest and compute causal Odds Ratio for each.
vector[Pv] odds_ratio;
for( v in 1:Pv ){
// n_v = number of subjects in that stratum
// v_start:v_end are the row indices of subjects in stratum V
int nv = n_v[v];
int v_start = ind[v]+1;
int v_end = ind[v+1];
vector[nv] cond_mean_y1;
vector[nv] cond_mean_y0;
vector[nv] bb_weights;
// subset to stratum v
matrix[nv, Pw] Wv = W[ v_start:v_end,
];
matrix[nv, Pv] Vv = V[ v_start:v_end,];
// compute conditional means.
cond_mean_y1 = inv_logit( Wv*beta_w +Vv*beta_v + Vv*theta );
cond_mean_y0 = inv_logit( Wv*beta_w + Vv*beta_v );
// Bayesian bootstrap weights for P_v(W)
bb_weights = dirichlet_rng( rep_vector(1, nv) ) ;
// taking average over bayesian bootstrap weights under both treatments
marg_mean_y1 = bb_weights’ * cond_mean_y1;
marg_mean_y0 = bb_weights’ * cond_mean_y0;
// compute odds ratio
odds_1 = (marg_mean_y1/(1 - marg_mean_y1));
odds_0 = (marg_mean_y0/(1 - marg_mean_y0));
odds_ratio[v] = odds_1/odds_0;
}
...
}
In the sampling statement in partial_pool.R, we run a single sampling chain consisting of 1000 posterior draws after 1000
burnin draws. The results of this computation is shown in Figure 1b, which is potted in partial_pool.R.
B.2 Implementation in SAS
The code partial_pool.sas in our companion GitHub repository repeats the analysis in SAS. The main procedures involved are
PROC MCMC (as in the dose eﬀect example) and PROC IML. Here, PROC IML (Integrated Matrix Language) is used to
manipulate the posterior draws obtained from PROC MCMC and conduct the Bayesian Bootstrap. Since the PROC MCMC step
is very similar to the dose eﬀect example, here we focus on the PROC IML post-processing step.
The ﬁrst statements in PROC IML load in two datasets as matrices. First, dataset “posterior_draws” is loaded and stored as
matrix “pm”. This is a matrix with each column corresponding to a parameter and each row corresponding to a posterior draw.
This was an output from PROC MCMC. Second, dataset “mcmc_data” is loaded and stored as matrix “X”. This is the model
matrix with 푛rows (for each of the 푛subjects) and covariates along the columns. Here is the relevant excerpt:
/* Read in matrix of posterior draws from SAS to IML */
use posterior_draws; read all var _ALL_ into pm; close posterior_draws;
/* Read in model matrix from SAS to IML */
use mcmc_data; read all var _ALL_ into X; close mcmc_data;
n = nrow(X);
n_iter = nrow(pm);
/* shell to store posterior draws of Causal OR for each of the 5 strata */
OR_mat = j(n_iter, 5, 0);

Oganisian ET AL
29
Next, we loop through each posterior draw, indexed by “i” in the code. For each draw, we loop through the strata of 푉, take a BB
draw of the conditional confounder distribution 푃푣(푊), and integrate the logistic model over this BB draw of the conditional
confounder distribution to attain the marginal means under each treatment. The odds ratio is computed in terms of these means.
Here is the relevant excerpt:
do v = 1 to 5;
/*X[,6] is the column containing V_i. */
nv = sum(X[,6] = v); /* Find how many subjects in stratum v */
idx = loc(X[,6] = v) ; /* find which obs are in stratum v */
/* Draw from Dirichlet(1_{nv}) distribution
to do bayesian bootstrap estimate of P_v(W) */
alpha= J(nv , 1 , 1);
bb_w = RandDirichlet(1, alpha);
bb_w = bb_w || 1-sum(bb_w);
/* for each strata, compute logit of event
under treatment 1 and 0: lp1, lp0*/
/* compute reference group v=1 separately */
if v=1 then do;
lp1 = pm[i,2] + pm[i, 3]*X[ idx , 8] + pm[i, 8] ;
lp0 = pm[i,2] + pm[i, 3]*X[ idx , 8] ;
end;
if v>1 then do;
lp1 = pm[i,2] + pm[i, 3]*X[ idx , 8] + pm[i,2+v]
+ (pm[i, 8] + pm[i,7+v] ) ;
lp0 = pm[i,2] + pm[i, 3]*X[ idx , 8] + pm[i,2+v] ;
end;
/* inverse logit transform to convert to probability */
p1 = exp(lp1)/(1+exp(lp1));
p0 = exp(lp0)/(1+exp(lp0));
/* bayesian bootstrap average of probability*/
/* dot-product: bb_w is 1-X-n vector and p1, p0 are n-X-1
*/
mu1 = bb_w*p1;
mu0 = bb_w*p0;
/* compute Odds Ratio for stratum v */
OR_mat[i,v] = ( mu1/(1-mu1) ) / ( mu0/(1-mu0 ) )
;
end;
Note that indexing of “pm” and “X” is so that we grab the appropriate columns of the model matrix and posterior parameters
when forming the log odds ratio as a linear combination of these parameters. This is completely analogous to the “generated
quantities” block in the Stan implementation. The SAS results are quite similar to results in Stan. Since we run relatively few
MCMC iterations with diﬀerent seeds across statistical software, some small diﬀerences are expected.
C PRIORS ON SENSITIVITY PARAMETERS
C.1 Implementation in Stan
Here, we brieﬂy describe using the generated quantities block in Stan to conduct the sensitivity analysis described in Section
5. The synthetic example underlying Figure 3b was simulated as follows in the program sensitivity.R. For 푖= 1, … , 푛= 100
subjects,
1. Simulate two confounders 퐿푖∼푁(0, 1) and 푈푖∼푁(0, 1).
2. Simulate treatment assignment 퐴푖from a Bernoulli with probability
푃(퐴푖= 1 ∣퐿푖, 푈푖) = expit(퐿푖+ 푈푖)
3. Simulate outcome 푌푖from
푌푖∣퐴푖, 퐿푖, 푈푖∼푁(퐴푖−퐿푖−2푈푖, 1)

30
Oganisian ET AL
Notice here that subjects with higher 푈푖are more likely to be treated and have lower outcome values. Failing to adjust for 푈푖
may lead us to conclude that the treatment eﬀect is negative, while in reality is is positive (speciﬁcally, treatment has coeﬃcient
+1 in the conditional outcome model).
We specify the following misspeciﬁed Bayesian model where 푈푖is excluded:
푌푖∣퐿푖, 퐴푖∼푁(휃퐴푖+ 훽퐿푖, 휙)
As described in the introduction, the ATE produced by standardization from this linear conditional mean model is simply 휃.
However, Posterior estimates of 휃will be biased since we did not adjust for some unmeasured confounder 푈푖(i.e. 퐼퐴.1 is
violated). Here, we perform the sensitivity analysis described in Section 5. In the model block of sensitivity.stan, we specify the
model as shown in the following excerpt
model {
// set priors
theta ~ normal(0, 3);
beta ~ normal(0, 3);
delta1 ~ normal(0,1/sqrt(3));
// specify likelihood
Y ~ normal(A*theta + beta*L, phi);
}
Notice that the sensitivity parameter here is coded as delta1 and given a standard Gaussian distribution. Now, in the generated
quantities block, we compute the perturbed estimate of the ATE, coded as psi3.
generated quantities {
...
real psi3;
...
psi3 = theta + delta1;
}
This produces the posterior estimates for Δ ∼푁(0, 3−1∕2) in Figure 3b. Note ellipses here denote ommitted code. The full code
is available in the companion GitHub repository.
C.2 Derivation of Bias
Here we detail the derivation of the bias, 휉. Deﬁne the amount of bias in potential outcome 푌푎as
Δ푎(퐿) = 퐸[푌푎∣퐴= 1, 퐿] −퐸[푌푎∣퐴= 0, 퐿]
Now, take 퐸[푌푎]. Iterate expectation over 퐿and then iterate once more over 퐴, conditional on 퐿. We get
퐸[푌푎] = ∫퐸[푌푎∣퐴= 0, 퐿] + Δ푎(퐿)푒(퐿) 푑푃(퐿)
Noting that 퐸[푌1 ∣퐴= 0, 퐿] = 퐸[푌1 ∣퐴= 1, 퐿] −Δ1(퐿) (by deﬁnition of Δ1(퐿)), we have the following expressions for each
expected potential outcome
퐸[푌0] = ∫퐸[푌0 ∣퐴= 0, 퐿] + Δ0(퐿)푒(퐿) 푑푃(퐿)
and
퐸[푌1] = ∫퐸[푌1 ∣퐴= 1, 퐿] −Δ1(퐿)(1 −푒(퐿)) 푑푃(퐿)
Note that consistency allows us to drop the superscripts 푎when conditioning on 퐴= 푎so that 퐸[푌푎∣퐴= 푎, 퐿] = 휇(푎, 퐿) .
Then subtracting yields,
퐸[푌1 −푌0] = ∫휇(1, 퐿) −휇(0, 퐿)푑푃(퐿) −
{
∫Δ1(퐿)(1 −푒(퐿)) + Δ0(퐿)푒(퐿) 푑푃(퐿)
}
Thus, under this ignorability violation, the target is equal to the usual standardization (ﬁrst term on the right of the equal sign)
having subtracted oﬀthe bias (the second term, which we deﬁne as 휉in the main text).

Oganisian ET AL
31
D TIME-VARYING TREATMENTS
In the companion GitHub repository, the programs g_comp.R and gcomp.stan simulate the synthetic example and produce the
posterior inference behind Figure 3a. Simulating and coding the analyses in this multi-time point setting is a little more tedious
- involving more Stan syntax. We leave the details to the code comments. Brieﬂy, the synthetic example contains a single binary
treatment, time-varying confounder, and outcome for 10 time points. The confounder at each time point is simulated from a
Gaussian with a conditional mean being a function of all previous confounder values. Treatment at each time point is simulated
from a Bernoulli with probability being a function of all previous confounder and treatment values. Lastly, a single outcome at
the end is simulated from a Gaussian with conditional mean being a function of all previous treatment and confounder values.
The generated quantities block demonstrates how we can simulate confounders sequentially conditional on “always treated”
and “never treated” regimes. This is the type of simulation requires to compute ATEs of both static and dynamic treatment
regimes outlined in the main text.
E NONPARAMETRIC MODELS
This Appendix will focus on implementation details behind Section 6 - speciﬁcally the computation of ATEs in panel d of Figure
4. We will cover implementation of DP mixtures and BART in R packages ChiRP and BayesTree, respectively, as well as GP
models in Stan that are contained in the program npbayes_ATE.R available in the companion GitHub repository. The synthetic
data behind this example was simulated as follows. For 푖= 1, 2, … , 푛= 500 subjects,
1. Simulate confounder 퐿푖∼푁(0, 1).
2. Simulate treatment assignment, 퐴푖, from Bernoulli with probability
푃(퐴푖∣퐿푖) = expit(1 −1
2퐿푖)
3. Simulate outcome, 푌푖, as
푌푖∣퐴푖, 퐿푖∼푁
(
(퐿푖+ 1
2퐿2
푖)퐴푖, 1
5
)
Note above that the conditional treatment eﬀect is a parabolic function of 퐿푖. This is a complex function form. Note that the true
causal eﬀect via standardization is:
Ψ = 퐸퐿[퐸[푌|퐴= 1, 퐿] −퐸[푌|퐴= 0, 퐿]]
= 퐸퐿[퐿푖+ 1
2퐿2
푖]
= 퐸퐿[퐿푖] + 1
2퐸퐿[퐿2
푖]
= 1
2
The last line follows from the fact that 퐿has a standard normal distribution. A parametric model will only recover this eﬀect
if it correctly speciﬁed - a tall order for such a complex functional form. Instead, Section 6 illustrates several nonparametric
approaches.
Implementation of the model in (12) can be done via the fDPMix() funciton in ChiRP. We refer the reader to the companion
web site1 and R help documentation for detailed information on defaults. The simulated data set is stored in an R object called
d_train in npbayes_ATE.R. Recall that we want posterior draws of the conditional outcome mean, for each subject, under both
interventions. To that end, we construct the dataset d_test as follows:
d_a1 = data.frame(A=1, L=d_train$L)
d_a0 = data.frame(A=0, L=d_train$L)
d_test = rbind(d_a1, d_a0)
Note that d_test is the observed data set stacked twice: once with treatment set to 1 for all subjects, another with treatment
set to 0 for all subjects. This will allow us to obtain predictive draws for each subject under both interventions. We now feed
1https://stablemarkets.github.io/ChiRPsite/index.html

32
Oganisian ET AL
these data sets into fDPMix() function and specify that the conditional mean outcome model to be a function of 퐿and 퐴. We
take 500 posterior draws after a 500 draw burnin. Initial number of clusters is set to 10. In practice, several chains with various
initializations should be run and checked for mixing.
set.seed(2)
res=fDPMix(d_train = d_train, formula = Y ~ L + A,
d_test = d_test,
iter=1000, burnin=500, init_k = 10)
The object res is a list containing a 2푛× iter-burnin matrix where the ﬁrst 푛rows are posterior predictions for each subject
under treatment 퐴= 1 and the next 푛rows, from 푛+ 1 to 2푛, are posterior predictions under treatment 퐴= 0. The program
npbayes_ATE.R has a short function called bayes_boot() that performs BB standardization using these draws, as described in the
test. The result is a length iter-burnin vector of posterior draws for the ATE. Additional confounders can be handled accordingly.
The other nonparametric models are implemented very similarly. In the same R program, we have implemented BART using
the BayesTree package as:
bart_res = bart(x.train = d_train[, c(’L’,’A’) ],
y.train = d_train$Y, x.test = d_test,
ndpost = 500, , nskip = 500)
Here, we take 500 posterior draws after a 500 period burn-in. Again, we stress that in practical examples, longer burnin will
likely be required. By default, this implementation runs BART using a sum of 200 trees. The function can accomodate other
prior settings. We refer the reader to the R documentation.
The implementation of the GP regression was taken directly from the Stan manual section on Gaussian Processes2 with some
minor modiﬁcations. We leave implementation details to our code and the online manual. It is quite similar to the parametric
Stan implementations discussed in earlier appendices. Stan uses the following parameterization of the exponential-quadratic
covariance function:
푪푖푗= 훼2 exp
(
−1
2휖2 ||푋푖−푋푗||2)
The parameter 휂in the main manuscript corresponds to 훼2, while the parameter 휌in the manuscript corresponds to
1
2휖2 above. In Stan, we can conduct posterior inference on the hyperparameter by assigning them priors. In the program
gaussian_process_with_HPs_multi.stan this is done in the model block. Here is the relevant excerpt:
model {
...
rho ~ inv_gamma(5, 5);
alpha ~ std_normal();
...
}
Here since 훼is declared to be be a non-negative parameter, the speciﬁed standard normal prior defaults to a half-normal prior.
2https://mc-stan.org/docs/2_22/stan-users-guide/ﬁt-gp-section.html

