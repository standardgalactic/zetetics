A Brief 
History of 
Computing
Gerard O’Regan
Third Edition

A Brief History of Computing

Gerard O’Regan
A Brief History  
of Computing
3rd Edition

ISBN 978-3-030-66598-2        ISBN 978-3-030-66599-9  (eBook)
https://doi.org/10.1007/978-3-030-66599-9
© The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature  
Switzerland AG, 2008, 2012, 2021
This work is subject to copyright. All rights are solely and exclusively licensed by the Publisher, whether 
the whole or part of the material is concerned, specifically the rights of translation, reprinting, reuse of 
illustrations, recitation, broadcasting, reproduction on microfilms or in any other physical way, and 
transmission or information storage and retrieval, electronic adaptation, computer software, or by similar 
or dissimilar methodology now known or hereafter developed.
The use of general descriptive names, registered names, trademarks, service marks, etc. in this publication 
does not imply, even in the absence of a specific statement, that such names are exempt from the relevant 
protective laws and regulations and therefore free for general use.
The publisher, the authors, and the editors are safe to assume that the advice and information in this book 
are believed to be true and accurate at the date of publication. Neither the publisher nor the authors or the 
editors give a warranty, expressed or implied, with respect to the material contained herein or for any 
errors or omissions that may have been made. The publisher remains neutral with regard to jurisdictional 
claims in published maps and institutional affiliations.
This Springer imprint is published by the registered company Springer Nature Switzerland AG
The registered company address is: Gewerbestrasse 11, 6330 Cham, Switzerland
Gerard O’Regan
Mallow, Co. Cork, Ireland

To
My wonderful goddaughter
Jane Crowley

vii
Preface
Overview
The objective of this book is to provide a brief introduction to the history of comput-
ing. The computing field is a vast area, and a comprehensive account of its history 
would require several volumes. The goals of this book are more modest, and it aims 
to give the reader a flavour of some of the important events in the history of comput-
ing and to stimulate the reader to study the more advanced articles and books that 
are available.
Organisation and Features
The first chapter provides an introduction to analogue and digital computers as well 
as the von Neumann architecture which is the fundamental architecture underlying 
a digital computer. Chapter 2 considers the contributions of early civilisations to the 
computing field, and we discuss the achievements of the Babylonians, Egyptians, 
Greeks, and Romans as well as the Islamic civilisation.
Chapter 3 provides an introduction to the foundations of computing, and we 
discuss the binary number system and the step reckoner calculating machine, which 
were invented by Leibniz. Babbage designed the difference engine as a machine to 
evaluate polynomials, and his analytic engine provided the vision of a modern com-
puter. Boole’s symbolic logic provided the foundation for digital computing.
Chapter 4 discusses the first digital computers including the Atanasoff-Berry 
computer developed in the United States; the ENIAC and EDVAC computers devel-
oped in the United States; the Colossus computer developed in England; Zuse’s 
computers developed in Germany; and the Manchester Mark I computer developed 
in England.

viii
Chapter 5 discusses the first commercial computers including UNIVAC devel-
oped by EMCC/Sperry in the United States; the LEO I computer developed by 
J. Lyons and Co. in England; the Z4 computer developed by Zuse KG in Germany; 
and the Ferranti Mark I computer developed by Ferranti in England.
Chapter 6 discusses early commercial computers including the IBM 701 and 704 
computers. We discuss the SAGE air defence system, which used the AN/FSQ-7 
computer, which was developed by IBM. We discuss the invention of the transistor 
by William Shockley and others at Bell Labs and early transistor computers.
Chapter 7 discusses the invention of the integrated circuit by Jack Kirby at Texas 
Instruments and subsequent work by Robert Noyce at Fairchild Semiconductors on 
silicon-based integrated circuits. Moore’s Law on the exponential growth of transis-
tor density on an integrated circuit is discussed, as well as its relevance to the com-
puting power of electronic devices.
Chapter 8 is concerned with the development of the IBM System/360 and its 
influence on later computer development. The System/360 was a family of main-
frame computers, and the user could start with a low specification member of the 
family and upgrade over time to a more powerful member of the family. It was the 
start of an era of computer compatibility, and it set IBM on the road to dominate the 
computer field for the next 20 years.
Chapter 9 discusses later mainframes and minicomputers, including DEC’s 
PDP-1, PDP-11 and VAX 11/780 minicomputers, which were popular with the 
engineering and scientific communities. We discuss Amdahl’s mainframe comput-
ers, such as the Amdahl 470V/6, and the intense competition between IBM 
and Amdahl.
Chapter 10 is concerned with the revolutionary invention of the microprocessor, 
which led to the development of home and personal computers. We discuss early 
microprocessors such as the Intel 4004, the 8-bit Intel 8080 and the 8-bit Motorola 
6800. The 16-bit Intel 8086 was introduced in 1978 and the 8-bit Intel 8088 (the 
cheaper 8-bit variant of the Intel 8086) was introduced in 1979, and it was chosen 
as the microprocessor for the IBM personal computer.
Chapter 11 discusses home computers such as the Apple I and II home comput-
ers, which were released in 1976 and 1977 respectively. We discuss the Commodore 
PET computer, which was introduced in 1977, and the Atari 400 and 800 comput-
ers, which were released in 1979. The Commodore 64 computer became very popu-
lar after its introduction in 1982. The Sinclair ZX 81 and ZX spectrum computers 
were released in 1980 and 1981, respectively, and the Apple Macintosh was released 
in 1984.
Chapter 12 discusses the introduction of the IBM personal computer, which was 
a major milestone in the computing field. IBM’s goal was to get into the home com-
puter market as quickly as possible, and this led IBM to build the machine from 
off-the-shelf parts from a number of equipment manufacturers. IBM outsourced the 
development of the operating system to a small company called Microsoft, and a 
company called Intel was chosen to supply the microprocessor for the IBM PC.
Preface

ix
Chapter 13 presents a short history of operating systems including the IBM 
OS/360, which was the operating system for the IBM System/360 family of com-
puters. We discuss the MVS and VM operating systems, which were used on the 
IBM System/370 mainframe computer. Ken Thompson and Dennis Ritchie devel-
oped the popular UNIX operating system in the early 1970s. DEC developed the 
VAX/VMS operating system in the late 1970s for its VAX family of minicomputers. 
Microsoft developed MS/DOS for the IBM personal computer in 1981, and it intro-
duced Windows as a response to the GUI driven operating system of the Apple 
Macintosh.
Chapter 14 discusses the birth of the software industry and the evolution of 
human-computer interaction. We discuss IBM’s decision to unbundle its software in 
the late 1960s, which changed the computer industry forever with software chang-
ing from being a giveaway item to becoming a commercial product and industry in 
its own right. The IBM unbundling decision led to the software and services indus-
try that we see today, and the quality of software and its usability became increas-
ingly important.
Chapter 15 presents a short history of programming languages, starting with 
machine languages; to assembly languages; to early high-level procedural lan-
guages such as Fortran and COBOL; to later high-level languages such as Pascal 
and C; and to object-oriented languages such as C++ and Java. Functional program-
ming languages and logic programming languages are discussed, and there is a 
short discussion on the important area of syntax and semantics.
Chapter 16 presents a short history of software engineering from its birth at the 
Garmisch conference in Germany, and it is emphasised that software engineering is 
a lot more than just programming. We discuss the key challenges in software engi-
neering, as well a number of the high profile software failures. The waterfall and 
spiral lifecycles are discussed, as well a brief discussion on the Rational unified 
process and the popular Agile methodology. We discuss the key activities in the 
traditional waterfall model such as requirements, design, implementation, unit, sys-
tem and acceptance testing.
Chapter 17 presents a short history of telecommunications, and it focuses on the 
development of mobile phone technology. The development of the AXE system by 
Ericsson is discussed, and this was the first fully automated digital switching sys-
tem. We discuss the concept of a cellular system, which was introduced by Bell 
Labs, as well as the introduction of the first mobile phone, the DynaTAC, by 
Motorola.
Chapter 18 describes the Internet revolution starting from ARPANET, which was 
a packet switched network; to TCP/IP, which is a set of network standards for inter-
connecting networks and computers. These developments led to the birth of the 
Internet, and Tim Berners-Lee’s work at CERN led to the birth of the World Wide 
Web. The dot com bubble and subsequent burst of the late 1990s/early 2000 are 
discussed, and we discuss some more recent developments including the Internet of 
Things and the Internet of Money.
Preface

x
Chapter 19 discusses the invention of the smart phone and the rise of social 
media. It describes the evolution of the smart phone from PDAs and mobile phone 
technology, and a smart phone is essentially a touch-based computer on a phone. 
The impact of Facebook and Twitter in social networking is discussed. Facebook is 
the leading social media site in the world, and it has become a way for young people 
to discuss their hopes and aspirations as well as a tool for social protest and revolu-
tion. Twitter has become a popular tool in political communication, and it is also an 
effective way for businesses to advertise its brand to its target audience.
Chapter 20 presents a miscellany of innovations in the computer field, including 
distributed systems, service-oriented architecture (SOA), software as a service 
(SaaS), cloud computing and embedded systems. We discuss GPS, Wikipedia, 
quantum computing and nanotechnology.
Chapter 21 presents a short history of databases including a discussion of the 
hierarchical and network models. We discuss the relational model as developed by 
Codd at IBM in more detail, as most databases used today are relational. There is a 
short discussion on the SQL query language and on the Oracle database.
Chapter 22 presents a short history of artificial intelligence, and we discuss the 
Turing test, which is a test of machine intelligence, that is, strong and weak AI, 
where strong AI considers an AI programmed computer to be essentially a mind, 
whereas weak AI considers a programmed computer as simulating thought without 
real understanding. We discuss Searle’s Chinese room argument, which is a rebuttal 
of strong AI. We discuss Weizenbaum’s views on the ethics of AI, and philosophical 
issues in AI.
Chapter 23 discusses ethics and professional responsibility in the computing 
field. Ethics is a branch of philosophy that deals with moral questions such as what 
is right or wrong, and computer ethics are a set of principles that guide the behav-
iour of individuals when using computer resources. Professional ethics are a code of 
conduct that governs how members of a profession deal with each other and with 
third parties, and we discuss Parnas’s contributions to professional responsibility 
and the ACM and BCS code of ethics.
Chapter 24 discusses legal aspects of computing and is concerned with the over-
lap of the law and the computing field. We discuss intellectual property, such as 
patents, copyright and trademarks, and the licensing of software. We examine the 
area of hacking and computer crime, and explore the nature of privacy, free speech 
and censorship. We consider the legal issues of bespoke software development and 
the legal aspects of the Internet.
Audience
The main audience of this book are computer science students who are interested in 
learning about the history of computing field. The book will also be of interest to the 
general reader who is curious about the history of computing.
Preface

xi
Acknowledgements
I am deeply indebted to friends and family who supported my efforts in this endeav-
our. This book is dedicated to my goddaughter, Jane Crowley, who is always so 
entertaining, and she and her sisters (Eve, Grace and Tara) have shown so much 
resilience in dealing with the loss of their father, Kevin, and in supporting their 
mother, Maura. I would like to express my thanks to the team at Springer for their 
consistent professional work.
Cork, Ireland
Gerard O’Regan  
Preface

xiii
Contents
	1	
What Is a Computer?������������������������������������������������������������������������������      1
	1.1	 Introduction��������������������������������������������������������������������������������������      1
	1.2	 Analog Computers����������������������������������������������������������������������������      2
	1.3	 Digital Computers����������������������������������������������������������������������������      3
	1.3.1	 Vacuum Tubes����������������������������������������������������������������������      4
	1.3.2	 Transistors����������������������������������������������������������������������������      4
	1.3.3	 Integrated Circuits����������������������������������������������������������������      6
	1.3.4	 Microprocessors��������������������������������������������������������������������      7
	1.4	 von Neumann Architecture ��������������������������������������������������������������      8
	1.5	 Hardware and Software��������������������������������������������������������������������      9
	1.6	 Review Questions.�����������������������������������������������������������������������������    10
	1.7	 Summary������������������������������������������������������������������������������������������    10
	2	
Computing in Early Civilizations����������������������������������������������������������    11
	2.1	 Introduction��������������������������������������������������������������������������������������    11
	2.2	 The Babylonians ������������������������������������������������������������������������������    13
	2.3	 The Egyptians ����������������������������������������������������������������������������������    15
	2.4	 The Greek and Hellenistic Contribution������������������������������������������    18
	2.5	 The Romans��������������������������������������������������������������������������������������    26
	2.6	 Islamic Influence������������������������������������������������������������������������������    28
	2.7	 Chinese and Indian Mathematics������������������������������������������������������    31
	2.8	 Review Questions.�����������������������������������������������������������������������������    33
	2.9	 Summary������������������������������������������������������������������������������������������    33
	3	
Foundations of Computing����������������������������������������������������������������������    35
	3.1	 Introduction��������������������������������������������������������������������������������������    35
	3.2	 Step Reckoner Calculating Machine������������������������������������������������    36
	3.3	 Binary Numbers��������������������������������������������������������������������������������    38
	3.4	 The Difference Engine����������������������������������������������������������������������    40
	3.5	 The Analytic Engine – Vision of a Computer����������������������������������    42
	3.5.1	 Applications of Analytic Engine������������������������������������������    43

xiv
	3.6	 Boole’s Symbolic Logic��������������������������������������������������������������������    44
	3.6.1	 Switching Circuits and Boolean Algebra������������������������������    47
	3.7	 Application of Boole’s Logic to Digital Computing������������������������    49
	3.8	 Review Questions.�����������������������������������������������������������������������������    50
	3.9	 Summary������������������������������������������������������������������������������������������    50
	4	
The First Digital Computers������������������������������������������������������������������    53
	4.1	 Introduction��������������������������������������������������������������������������������������    53
	4.2	 Harvard Mark I����������������������������������������������������������������������������������    54
	4.3	 Atanasoff-Berry Computer ��������������������������������������������������������������    55
	4.4	 ENIAC and EDVAC��������������������������������������������������������������������������    57
	4.4.1	 EDVAC����������������������������������������������������������������������������������    60
	4.4.2	 Controversy Between the ABC and ENIAC������������������������    60
	4.5	 Bletchley Park and Colossus������������������������������������������������������������    61
	4.5.1	 Colossus��������������������������������������������������������������������������������    62
	4.6	 Zuse’s Machines��������������������������������������������������������������������������������    64
	4.6.1	 Z1, Z2, and Z3 Machines������������������������������������������������������    65
	4.7	 University of Manchester������������������������������������������������������������������    66
	4.7.1	 Manchester Mark I����������������������������������������������������������������    68
	4.8	 Review Questions.�����������������������������������������������������������������������������    69
	4.9	 Summary������������������������������������������������������������������������������������������    69
	5	
The First Commercial Computers.���������������������������������������������������������    71
	5.1	 Introduction��������������������������������������������������������������������������������������    71
	5.2	 UNIVAC��������������������������������������������������������������������������������������������    72
	5.3	 LEO I Computer ������������������������������������������������������������������������������    73
	5.4	 The Z4 Computer������������������������������������������������������������������������������    75
	5.5	 Ferranti Mark I����������������������������������������������������������������������������������    76
	5.6	 CSIRAC Computer ��������������������������������������������������������������������������    77
	5.7	 Review Questions.�����������������������������������������������������������������������������    78
	5.8	 Summary������������������������������������������������������������������������������������������    78
	6	
Early Commercial Computers and the Invention  
of the Transistor ��������������������������������������������������������������������������������������    81
	6.1	 Introduction��������������������������������������������������������������������������������������    81
	6.2	 Early IBM Computers����������������������������������������������������������������������    82
	6.3	 The SAGE System����������������������������������������������������������������������������    84
	6.4	 Invention of the Transistor����������������������������������������������������������������    86
	6.5	 Early Transistor Computers��������������������������������������������������������������    87
	6.6	 Review Questions.�����������������������������������������������������������������������������    88
	6.7	 Summary������������������������������������������������������������������������������������������    88
	7	
Integrated Circuit and Silicon Valley����������������������������������������������������    89
	7.1	 Introduction��������������������������������������������������������������������������������������    89
	7.2	 Invention of Integrated Circuit����������������������������������������������������������    90
	7.2.1	 Moore’s Law������������������������������������������������������������������������    92
Contents

xv
	7.3	
Early Integrated Circuit Computers������������������������������������������������    93
	7.4	
Birth of Silicon Valley��������������������������������������������������������������������    93
	7.5	
Review Questions.���������������������������������������������������������������������������    96
	7.6	
Summary����������������������������������������������������������������������������������������    96
	8	
The IBM System/360��������������������������������������������������������������������������������    97
	8.1	
Introduction������������������������������������������������������������������������������������    97
	8.2	
Background to the Development of System/360����������������������������    98
	8.3	
The IBM System 360����������������������������������������������������������������������    99
	8.4	
Review Questions.���������������������������������������������������������������������������  102
	8.5	
Summary����������������������������������������������������������������������������������������  102
	9	
Minicomputers and Later Mainframes ������������������������������������������������  103
	9.1	
Introduction������������������������������������������������������������������������������������  103
	9.2	
DEC’s Minicomputers��������������������������������������������������������������������  104
	  9.2.1	 PDP-11����������������������������������������������������������������������������������  105
	  9.2.2	 The VAX 11/780 ������������������������������������������������������������������  106
	9.3	
The War Between IBM and Amdahl����������������������������������������������  107
	9.4	
Review Questions.���������������������������������������������������������������������������  110
	9.5	
Summary����������������������������������������������������������������������������������������  110
	10	 The Microprocessor Revolution��������������������������������������������������������������  113
	10.1	 Introduction������������������������������������������������������������������������������������  113
	10.2	 Invention of the Microprocessor����������������������������������������������������  114
	10.3	 Early Microprocessors��������������������������������������������������������������������  115
	10.4	 A Selection of Semiconductor Companies ������������������������������������  117
	10.5	 Review Questions.���������������������������������������������������������������������������  118
	10.6	 Summary����������������������������������������������������������������������������������������  118
	11	 Home Computers ������������������������������������������������������������������������������������  119
	11.1	 Introduction������������������������������������������������������������������������������������  119
	11.2	 Xerox Alto Personal Computer������������������������������������������������������  120
	11.3	 MITS Altair 8800����������������������������������������������������������������������������  121
	11.4	 Apple I and II Home Computers����������������������������������������������������  122
	11.5	 Commodore PET����������������������������������������������������������������������������  123
	11.6	 Atari 400 and 800����������������������������������������������������������������������������  125
	11.7	 Commodore 64��������������������������������������������������������������������������������  126
	11.8	 Sinclair ZX 81 and ZX Spectrum ��������������������������������������������������  127
	11.9	 Apple Macintosh����������������������������������������������������������������������������  129
	11.10	 Later Commodore and Atari Machines������������������������������������������  130
	11.11	 Atari Video Machines ��������������������������������������������������������������������  132
	11.12	 Review Questions.���������������������������������������������������������������������������  136
	11.13	 Summary����������������������������������������������������������������������������������������  136
Contents

xvi
	12	 The IBM Personal Computer.�����������������������������������������������������������������  137
	12.1	 Introduction������������������������������������������������������������������������������������  137
	12.2	 The IBM Personal Computer����������������������������������������������������������  138
	12.3	 Operating System for IBM PC��������������������������������������������������������  140
	12.4	 Review Questions.���������������������������������������������������������������������������  142
	12.5	 Summary����������������������������������������������������������������������������������������  142
	13	 History of Operating Systems����������������������������������������������������������������  143
	13.1	 Introduction������������������������������������������������������������������������������������  143
	13.2	 Fundamentals of Operating Systems����������������������������������������������  145
	13.3	 OS/360 and MVS����������������������������������������������������������������������������  147
	13.4	 VM��������������������������������������������������������������������������������������������������  148
	13.5	 VMS������������������������������������������������������������������������������������������������  149
	13.6	 UNIX����������������������������������������������������������������������������������������������  150
	13.7	 MS/DOS������������������������������������������������������������������������������������������  151
	13.8	 Microsoft Windows������������������������������������������������������������������������  151
	13.9	 Mobile Operating Systems��������������������������������������������������������������  152
	13.10	 Review Questions.���������������������������������������������������������������������������  153
	13.11	 Summary����������������������������������������������������������������������������������������  154
	14	 Birth of Software Industry and Human  
Computer Interaction������������������������������������������������������������������������������  155
	14.1	 Introduction������������������������������������������������������������������������������������  155
	14.2	 Birth of Software Industry��������������������������������������������������������������  156
	 14.2.1	 Software Contractors Industry������������������������������������������  157
	 14.2.2	 Corporate Software Products��������������������������������������������  158
	 14.2.3	 Personal Computer Software Industry������������������������������  158
	 14.2.4	 Software as a Service��������������������������������������������������������  159
	 14.2.5	 Open-Source Software������������������������������������������������������  160
	 14.2.6	 App Stores������������������������������������������������������������������������  162
	14.3	 Microsoft Office Software��������������������������������������������������������������  162
	 14.3.1	 Microsoft Excel����������������������������������������������������������������  163
	 14.3.2	 Microsoft PowerPoint������������������������������������������������������  164
	 14.3.3	 Microsoft Word����������������������������������������������������������������  164
	 14.3.4	 Microsoft Access and Outlook������������������������������������������  164
	14.4	 Human–Computer Interaction��������������������������������������������������������  166
	 14.4.1	 HCI Principles������������������������������������������������������������������  168
	 14.4.2	 Software Usability������������������������������������������������������������  170
	 14.4.3	 User-Centered Design������������������������������������������������������  171
	14.5	 The Mouse��������������������������������������������������������������������������������������  172
	14.6	 Review Questions.���������������������������������������������������������������������������  174
	14.7	 Summary����������������������������������������������������������������������������������������  174
	15	 History of Programming Languages������������������������������������������������������  177
	15.1	 Introduction������������������������������������������������������������������������������������  177
	15.2	 Plankalkül ��������������������������������������������������������������������������������������  179
Contents

xvii
	15.3	 Imperative Programming Languages����������������������������������������������  180
	 15.3.1	 FORTRAN and COBOL��������������������������������������������������  181
	 15.3.2	 ALGOL����������������������������������������������������������������������������  183
	 15.3.3	 Pascal and C����������������������������������������������������������������������  184
	15.4	 Object-Oriented Languages������������������������������������������������������������  187
	 15.4.1	 C++ and Java��������������������������������������������������������������������  188
	15.5	 Functional Programming Languages����������������������������������������������  190
	 15.5.1	 Miranda����������������������������������������������������������������������������  192
	 15.5.2	 Lambda Calculus��������������������������������������������������������������  193
	15.6	 Logic Programming Languages������������������������������������������������������  195
	15.7	 Syntax and Semantics ��������������������������������������������������������������������  197
	 15.7.1	 Programming Language Semantics����������������������������������  198
	15.8	 Review Questions.���������������������������������������������������������������������������  199
	15.9	 Summary����������������������������������������������������������������������������������������  199
	16	 History of Software Engineering������������������������������������������������������������  201
	16.1	 Introduction������������������������������������������������������������������������������������  201
	16.2	 What is Software Engineering?������������������������������������������������������  204
	16.3	 Challenges in Software Engineering����������������������������������������������  206
	16.4	 Software Processes and Lifecycles ������������������������������������������������  208
	 16.4.1	 Waterfall Lifecycle������������������������������������������������������������  209
	 16.4.2	 Spiral Lifecycles ��������������������������������������������������������������  210
	 16.4.3	 Rational Unified Process��������������������������������������������������  211
	 16.4.4	 Agile Development����������������������������������������������������������  212
	16.5	 Activities in Waterfall Lifecycle ����������������������������������������������������  214
	 16.5.1	 Business Requirements Definition������������������������������������  214
	 16.5.2	 Specification of System Requirements����������������������������  215
	 16.5.3	 Design������������������������������������������������������������������������������  215
	 16.5.4	 Implementation����������������������������������������������������������������  216
	 16.5.5	 Software Testing ��������������������������������������������������������������  217
	 16.5.6	 Maintenance����������������������������������������������������������������������  218
	16.6	 Software Inspections����������������������������������������������������������������������  219
	16.7	 Software Project Management��������������������������������������������������������  220
	16.8	 CMMI Maturity Model������������������������������������������������������������������  221
	16.9	 Formal Methods������������������������������������������������������������������������������  222
	16.10	 Open-Source Software��������������������������������������������������������������������  223
	16.11	 Review Questions.���������������������������������������������������������������������������  224
	16.12	 Summary����������������������������������������������������������������������������������������  224
	17	 A Short History of Telecommunications������������������������������������������������  227
	17.1	 Introduction������������������������������������������������������������������������������������  227
	17.2	 AXE System������������������������������������������������������������������������������������  229
	17.3	 Development of Mobile Phone Standards��������������������������������������  230
	17.4	 Development of Mobile Phone Technology.�����������������������������������  232
	17.5	 The Iridium Satellite System����������������������������������������������������������  234
	17.6	 Review Questions.���������������������������������������������������������������������������  236
	17.7	 Summary����������������������������������������������������������������������������������������  236
Contents

xviii
	18	 The Internet Revolution��������������������������������������������������������������������������  237
	18.1	 Introduction������������������������������������������������������������������������������������  237
	18.2	 The ARPANET ������������������������������������������������������������������������������  238
	 18.2.1	 Email��������������������������������������������������������������������������������  240
	 18.2.2	 Gmail��������������������������������������������������������������������������������  241
	18.3	 TCP/IP��������������������������������������������������������������������������������������������  241
	18.4	 Birth of the Internet������������������������������������������������������������������������  243
	18.5	 Birth of the World Wide Web����������������������������������������������������������  243
	 18.5.1	 Applications of the World Wide Web ������������������������������  245
	18.6	 Dot Com Companies����������������������������������������������������������������������  246
	 18.6.1	 Dot Com Failures��������������������������������������������������������������  248
	 18.6.2	 Business Models��������������������������������������������������������������  249
	 18.6.3	 Bubble and Burst��������������������������������������������������������������  250
	 18.6.4	 E-Commerce Security������������������������������������������������������  252
	18.7	 Internet of Things����������������������������������������������������������������������������  253
	18.8	 Internet of Money and Bitcoin��������������������������������������������������������  254
	18.9	 Review Questions.���������������������������������������������������������������������������  255
	18.10	 Summary����������������������������������������������������������������������������������������  255
	19	 The Smartphone and Social Media��������������������������������������������������������  257
	19.1	 Introduction������������������������������������������������������������������������������������  257
	19.2	 Evolution of the Smartphone����������������������������������������������������������  258
	19.3	 The Facebook Revolution ��������������������������������������������������������������  259
	19.4	 The Tweet����������������������������������������������������������������������������������������  261
	19.5	 Social Media and Fake News����������������������������������������������������������  263
	19.6	 Review Questions.���������������������������������������������������������������������������  264
	19.7	 Summary����������������������������������������������������������������������������������������  265
	20	 A Miscellany of Innovation ��������������������������������������������������������������������  267
	20.1	 Introduction������������������������������������������������������������������������������������  267
	20.2	 Distributed Systems������������������������������������������������������������������������  268
	20.3	 Service-Oriented Architecture��������������������������������������������������������  270
	20.4	 Software as a Service����������������������������������������������������������������������  270
	20.5	 Cloud Computing����������������������������������������������������������������������������  271
	20.6	 Embedded Systems������������������������������������������������������������������������  272
	20.7	 WiFi������������������������������������������������������������������������������������������������  273
	 20.7.1	 WiFi Security��������������������������������������������������������������������  275
	20.8	 Quantum Computing����������������������������������������������������������������������  276
	20.9	 GPS Technology ����������������������������������������������������������������������������  277
	 20.9.1	 Applications of GPS ��������������������������������������������������������  279
	20.10	 Wikipedia����������������������������������������������������������������������������������������  279
	 20.10.1	 Wikipedia Quality Controls����������������������������������������������  282
	20.11	 Nanotechnology������������������������������������������������������������������������������  283
	20.12	 Review Questions.���������������������������������������������������������������������������  284
	20.13	 Summary����������������������������������������������������������������������������������������  284
Contents

xix
	21	 History of Databases��������������������������������������������������������������������������������  285
	21.1	 Introduction������������������������������������������������������������������������������������  285
	21.2	 Hierarchical and Network Models��������������������������������������������������  286
	21.3	 The Relational Model ��������������������������������������������������������������������  287
	21.4	 Structured Query Language (SQL)������������������������������������������������  291
	21.5	 Oracle Database������������������������������������������������������������������������������  292
	21.6	 Review Questions.���������������������������������������������������������������������������  293
	21.7	 Summary����������������������������������������������������������������������������������������  293
	22	 History of Artificial Intelligence ������������������������������������������������������������  295
	22.1	 Introduction������������������������������������������������������������������������������������  295
	22.2	 Descartes����������������������������������������������������������������������������������������  296
	22.3	 The Field of Artificial Intelligence��������������������������������������������������  299
	 22.3.1	 Turing Test and Strong AI������������������������������������������������  301
	 22.3.2	 Ethics and AI��������������������������������������������������������������������  304
	22.4	 Philosophy and AI��������������������������������������������������������������������������  305
	22.5	 Cognitive Psychology ��������������������������������������������������������������������  307
	22.6	 Computational Linguistics��������������������������������������������������������������  309
	22.7	 Cybernetics ������������������������������������������������������������������������������������  310
	22.8	 Logic and AI ����������������������������������������������������������������������������������  311
	22.9	 Computability, Incompleteness, and Decidability��������������������������  312
	22.10	 Robots ��������������������������������������������������������������������������������������������  313
	22.11	 Neural Networks ����������������������������������������������������������������������������  314
	22.12	 Expert Systems��������������������������������������������������������������������������������  315
	22.13	 Driverless Car ��������������������������������������������������������������������������������  317
	22.14	 Review Questions.���������������������������������������������������������������������������  318
	22.15	 Summary����������������������������������������������������������������������������������������  319
	23	 Ethics and Professional Responsibility��������������������������������������������������  321
	23.1	 Introduction������������������������������������������������������������������������������������  321
	23.2	 Business Ethics ������������������������������������������������������������������������������  322
	23.3	 What Is Computer Ethics?��������������������������������������������������������������  323
	 23.3.1	 Ethics and Artificial Intelligence��������������������������������������  325
	 23.3.2	 Robots and Ethics ������������������������������������������������������������  325
	23.4	 Parnas on Professional Responsibility��������������������������������������������  326
	23.5	 ACM Code of Ethics and Professional Conduct����������������������������  327
	23.6	 British Computer Society Code of Conduct ����������������������������������  327
	23.7	 Review Questions.���������������������������������������������������������������������������  329
	23.8	 Summary����������������������������������������������������������������������������������������  329
	24	 Legal Aspects of Computing ������������������������������������������������������������������  331
	24.1	 Introduction������������������������������������������������������������������������������������  331
	24.2	 Intellectual Property������������������������������������������������������������������������  332
	 24.2.1	 Patent Law������������������������������������������������������������������������  332
	 24.2.2	 Copyright Law������������������������������������������������������������������  333
	 24.2.3	 Trademarks ����������������������������������������������������������������������  334
Contents

xx
	24.3	 Software Licensing ������������������������������������������������������������������������  334
	 24.3.1	 Software Licensing and Failure����������������������������������������  335
	24.4	 Bespoke Software Development����������������������������������������������������  336
	24.5	 E-commerce and the Law ��������������������������������������������������������������  337
	24.6	 Free Speech and Censorship����������������������������������������������������������  338
	24.7	 Computer Privacy in the Workplace ����������������������������������������������  338
	24.8	 Computer Crime������������������������������������������������������������������������������  339
	 24.8.1	 Dark Side of the Internet��������������������������������������������������  340
	24.9	 Hacking and Computer Security����������������������������������������������������  341
	24.10	 Review Questions.���������������������������������������������������������������������������  342
	24.11	 Summary����������������������������������������������������������������������������������������  343
Glossary������������������������������������������������������������������������������������������������������������  345
References��������������������������������������������������������������������������������������������������������  351
Index������������������������������������������������������������������������������������������������������������������  355
Contents

xxi
Fig. 1.1	
Vannevar Bush with the differential analyzer��������������������������������      3
Fig. 1.2	
William Shockley. Creative Commons������������������������������������������      5
Fig. 1.3	
Replica of transistor. Public domain����������������������������������������������      5
Fig. 1.4	
Intel 4004 microprocessor�������������������������������������������������������������      7
Fig. 1.5	
von Neumann architecture�������������������������������������������������������������      8
Fig. 1.6	
Fetch/execute cycle������������������������������������������������������������������������      9
Fig. 2.1	
The Plimpton 322 tablet����������������������������������������������������������������    15
Fig. 2.2	
Geometric representation of (a + b)2 = (a2 + 2ab + b2)�����������������    16
Fig. 2.3	
Egyptian numerals�������������������������������������������������������������������������    17
Fig. 2.4	
Egyptian representation of a number���������������������������������������������    17
Fig. 2.5	
Egyptian representation of a fraction��������������������������������������������    18
Fig. 2.6	
Eratosthenes measurement of the circumference  
of the earth�������������������������������������������������������������������������������������    21
Fig. 2.7	
Plato and Aristotle�������������������������������������������������������������������������    24
Fig. 2.8	
Roman numbers�����������������������������������������������������������������������������    26
Fig. 2.9	
Julius Caesar����������������������������������������������������������������������������������    27
Fig. 2.10	
Caesar Cipher��������������������������������������������������������������������������������    28
Fig. 2.11	
Mohammed Al Khwarizmi������������������������������������������������������������    29
Fig. 2.12	
Al Azhar University, Cairo������������������������������������������������������������    30
Fig. 3.1	
Wilhelm Gottfried Leibniz������������������������������������������������������������    36
Fig. 3.2	
Replica of Step Reckoner at Technische  
Sammlungen Museum, Dresden����������������������������������������������������    37
Fig. 3.3	
Decimal to binary conversion��������������������������������������������������������    39
Fig. 3.4	
Charles Babbage����������������������������������������������������������������������������    40
Fig. 3.5	
Difference engine No. 2. Photo public domain�����������������������������    41
Fig. 3.6	
Lady Ada Lovelace������������������������������������������������������������������������    44
Fig. 3.7	
George Boole���������������������������������������������������������������������������������    45
Fig. 3.8	
Binary AND operation�������������������������������������������������������������������    48
Fig. 3.9	
Binary OR operation����������������������������������������������������������������������    48
List of Figures

xxii
Fig. 3.10	
NOT operation�������������������������������������������������������������������������������    48
Fig. 3.11	
Half-adder��������������������������������������������������������������������������������������    48
Fig. 3.12	
Claude Shannon�����������������������������������������������������������������������������    49
Fig. 4.1	
Howard Aiken��������������������������������������������������������������������������������    54
Fig. 4.2	
Harvard Mark I (IBM ASCC).  
(Courtesy of IBM Archives)����������������������������������������������������������    55
Fig. 4.3	
John Atanasoff with components of ABC�������������������������������������    56
Fig. 4.4	
Replica of ABC Computer: Creative Commons.���������������������������    57
Fig. 4.5	
Setting the switches on ENIAC’s  
function tables. Public domain������������������������������������������������������    58
Fig. 4.6	
Replacing a valve on ENIAC. Public domain�������������������������������    59
Fig. 4.7	
The EDVAC computer. Public domain������������������������������������������    60
Fig. 4.8	
Tommy Flowers�����������������������������������������������������������������������������    61
Fig. 4.9	
Colossus Mark 2. Public domain���������������������������������������������������    63
Fig. 4.10	
Konrad Zuse. Courtesy of Horst Zuse, Berlin�������������������������������    64
Fig. 4.11	
Zuse and the Reconstructed Z3.  
(Courtesy of Horst Zuse, Berlin)���������������������������������������������������    66
Fig. 4.12	
Replica of the Manchester Baby.  
(Courtesy of Tommy Thomas)�������������������������������������������������������    67
Fig. 4.13	
The Manchester Mark 1 computer������������������������������������������������    68
Fig. 5.1	
UNIVAC I computer����������������������������������������������������������������������    72
Fig. 5.2	
LEO I computer. (Courtesy of LEO Computer Society)���������������    74
Fig. 5.3	
The Z4 computer. (Creative Commons)����������������������������������������    75
Fig. 5.4	
Ferranti Mark I������������������������������������������������������������������������������    77
Fig. 5.5	
CSIRAC computer. (Creative Commons)�������������������������������������    78
Fig. 6.1	
IBM 701. (Courtesy of IBM Archives).�����������������������������������������    83
Fig. 6.2	
IBM 704. (Courtesy of IBM Archives).�����������������������������������������    83
Fig. 6.3	
SAGE IBM AN/FSQ-7 Console. (Creative Commons)����������������    85
Fig. 7.1	
Jack Kilby c. 1958. (Courtesy of Texas Instruments)��������������������    90
Fig. 7.2	
First integrated circuit. (Courtesy of Texas Instruments)��������������    91
Fig. 7.3	
The DEC PDP-8/e�������������������������������������������������������������������������    94
Fig. 7.4	
HP Palo Alto Garage. Birthplace of Silicon Valley.  
(Courtesy of HP)����������������������������������������������������������������������������    95
Fig. 8.1	
IBM System/360. (Courtesy of IBM Archives)�����������������������������  100
Fig. 8.2	
Gene Amdahl. (Creative Commons).���������������������������������������������  101
Fig. 8.3	
Fred Brooks. (Photo courtesy of Dan Sears)���������������������������������  101
Fig. 9.1	
The PDP-1 computer���������������������������������������������������������������������  105
Fig. 9.2	
PDP-11������������������������������������������������������������������������������������������  106
Fig. 9.3	
VAX-11/780�����������������������������������������������������������������������������������  107
Fig. 9.4	
Amdahl 5860. (Courtesy of Robert Broughton,  
University of Newcastle)���������������������������������������������������������������  109
List of Figures

xxiii
Fig. 10.1	
Intel 4004 microprocessor�������������������������������������������������������������  115
Fig. 10.2	
Motorola 6800 microprocessor������������������������������������������������������  116
Fig. 11.1	
Xerox Alto�������������������������������������������������������������������������������������  120
Fig. 11.2	
MITS Altair computer. (Photo public domain)������������������������������  122
Fig. 11.3	
Apple II computer. (Photo public domain)������������������������������������  123
Fig. 11.4	
Commodore PET 2001 home computer����������������������������������������  124
Fig. 11.5	
The Atari 800 home computer�������������������������������������������������������  125
Fig. 11.6	
Commodore 64 home computer����������������������������������������������������  126
Fig. 11.7	
ZX spectrum����������������������������������������������������������������������������������  128
Fig. 11.8	
Apple Macintosh computer. (Photo public domain)����������������������  129
Fig. 11.9	
Amiga 500 home computer (1987)������������������������������������������������  131
Fig. 11.10	 Atari 1040 ST home computer������������������������������������������������������  132
Fig. 11.11	 Nolan Bushnell������������������������������������������������������������������������������  132
Fig. 11.12	 Original Atari Pong video game console���������������������������������������  134
Fig. 11.13	 Atari video computer system (VCS)���������������������������������������������  134
Fig. 12.1	
Don Estridge. (Courtesy of IBM archives)������������������������������������  138
Fig. 12.2	
IBM personal computer. (Courtesy of IBM archives)�������������������  139
Fig. 13.1	
Process state transitions�����������������������������������������������������������������  146
Fig. 13.2	
A simple deadlock�������������������������������������������������������������������������  147
Fig. 13.3	
Virtual machine operating system�������������������������������������������������  149
Fig. 13.4	
Android operating system��������������������������������������������������������������  153
Fig. 14.1	
Richard Stallman. (Creative Commons)����������������������������������������  161
Fig. 14.2	
Microsoft Excel�����������������������������������������������������������������������������  163
Fig. 14.3	
Microsoft PowerPoint��������������������������������������������������������������������  165
Fig. 14.4	
Microsoft Word������������������������������������������������������������������������������  165
Fig. 14.5	
FreeDOS text editing���������������������������������������������������������������������  167
Fig. 14.6	
Microsoft Windows 3.11 (1993).  
(Used with permission from Microsoft)����������������������������������������  168
Fig. 14.7	
SRI First Mouse�����������������������������������������������������������������������������  172
Fig. 14.8	
Two Macintosh Plus Mice. 1984���������������������������������������������������  173
Fig. 14.9	
A. Computer mouse with two buttons  
and a scroll wheel��������������������������������������������������������������������������  174
Fig. 15.1	
Grace Murray and UNIVAC����������������������������������������������������������  182
Fig. 16.1	
Standish report–results of 1995 and 2009 survey��������������������������  203
Fig. 16.2	
Standish 1998 report – Estimation accuracy���������������������������������  207
Fig. 16.3	
Waterfall V lifecycle model�����������������������������������������������������������  210
Fig. 16.4	
SPIRAL lifecycle model. Public domain��������������������������������������  211
Fig. 17.1	
AXE system. Creative Commons��������������������������������������������������  229
Fig. 17.2	
Frequency reuse in cellular networks��������������������������������������������  231
Fig. 17.3	
Martin Cooper re-enacts DynaTAC call����������������������������������������  232
List of Figures

xxiv
Fig. 18.1	
Vannevar Bush�������������������������������������������������������������������������������  238
Fig. 18.2	
Dow Jones (1995–2002)����������������������������������������������������������������  251
Fig. 18.3	
NASDAQ (1995–2002)�����������������������������������������������������������������  251
Fig. 19.1	
Apple iPhone 4������������������������������������������������������������������������������  259
Fig. 19.2	
Mark Zuckerberg���������������������������������������������������������������������������  260
Fig. 19.3	
Jack Dorsey at the 2012 Time 100 Gala����������������������������������������  262
Fig. 20.1	
A distributed system����������������������������������������������������������������������  269
Fig. 20.2	
Service-oriented architecture���������������������������������������������������������  270
Fig. 20.3	
Cloud computing. Creative Commons������������������������������������������  272
Fig. 20.4	
Example of an embedded system��������������������������������������������������  273
Fig. 20.5	
WiFi range diagram. Public domain����������������������������������������������  274
Fig. 20.6	
GPS satellite system (24 satellites). Creative Commons���������������  277
Fig. 20.7	
GPS in operation����������������������������������������������������������������������������  278
Fig. 20.8	
Wikipedia logo. Creative Commons����������������������������������������������  281
Fig. 21.1	
Simple part/supplier–network model.��������������������������������������������  287
Fig. 21.2	
Simple part/supplier–hierarchical model���������������������������������������  287
Fig. 21.3	
Edgar Codd������������������������������������������������������������������������������������  288
Fig. 21.4	
PART relation��������������������������������������������������������������������������������  290
Fig. 21.5	
Domains vs. attributes�������������������������������������������������������������������  290
Fig. 22.1	
Rene Descartes������������������������������������������������������������������������������  296
Fig. 22.2	
Brain in a VAT thought experiment�����������������������������������������������  297
Fig. 22.3	
John McCarthy������������������������������������������������������������������������������  301
Fig. 22.4	
Searle’s Chinese room�������������������������������������������������������������������  303
List of Figures

xxv
Table 1.1	
von Neumann architecture�������������������������������������������������������������      9
Table 2.1	
Syllogisms: relationship between terms����������������������������������������    25
Table 3.1	
Binary number system�������������������������������������������������������������������    38
Table 3.2	
Analytic engine������������������������������������������������������������������������������    42
Table 14.1	 Eight golden rules of interface design�������������������������������������������  169
Table 14.2	 Software development lifecycle (including usability)�������������������  170
Table 14.3	 UCD principles������������������������������������������������������������������������������  171
Table 15.1	 Object-oriented paradigm��������������������������������������������������������������  189
Table 15.2	 Programming language semantics�������������������������������������������������  198
Table 18.1	 TCP layers�������������������������������������������������������������������������������������  242
Table 18.2	 Features of world Wide Web���������������������������������������������������������  244
Table 18.3	 Characteristics of e-commerce������������������������������������������������������  246
Table 18.4	 Characteristics of business models������������������������������������������������  249
Table 20.1	 Methods for intercepting data��������������������������������������������������������  276
Table 20.2	 Applications of GPS����������������������������������������������������������������������  280
Table 22.1	 Laws of robotics����������������������������������������������������������������������������  313
Table 22.2	 Expert systems�������������������������������������������������������������������������������  316
Table 22.3	 Challenges with driverless vehicles�����������������������������������������������  318
Table 23.1	 Ten commandments on computer ethics���������������������������������������  324
Table 23.2	 Professional responsibilities of software engineers�����������������������  327
Table 23.3	 ACM code of conduct (general obligations)���������������������������������  328
Table 23.4	 BCS Code of conduct��������������������������������������������������������������������  328
List of Tables

1
© The Author(s), under exclusive license to Springer Nature 
Switzerland AG 2021
G. O’Regan, A Brief History of Computing, 
https://doi.org/10.1007/978-3-030-66599-9_1
Chapter 1
What Is a Computer?
1.1  Introduction
Computers are an integral part of modern society, and new technology has trans-
formed the modern world into a global village. Communication today may be con-
ducted using text messaging, WhatsApp, Skype, mobile phones, video calls over the 
Internet, e-mail, and social media sites such as Facebook, Twitter, and Instagram. 
New technology allows people to keep in touch with friends and family around the 
world, and the World Wide Web allows businesses to compete in a global market.
A computer is a programmable electronic device that can process, store, and 
retrieve data. It processes data according to a set of instructions or program. All 
computers consist of two basic parts, namely hardware and software. The hardware 
is the physical part of the machine, and the components of a digital computer include 
memory for short-term storage of data or instructions, an arithmetic/logic unit for 
carrying out arithmetic and logical operations, a control unit responsible for the 
execution of computer instructions in memory, and peripherals that handle the input 
and output operations. Software is a set of instructions that tells the computer 
what to do.
The original meaning of the word “computer” referred to someone who carried 
out calculations rather than an actual machine. The early digital computers built in 
the 1940s and 1950s were enormous machines consisting of thousands of vacuum 
tubes. They typically filled a large room, but their computational power was a frac-
tion of the personal computers used today.
Key Topics
Analog computers
Digital computers
Vacuum tubes
Transistors
Integrated circuits
von Neumann architecture
Generation of computers
Hardware
Software

2
There are two distinct families of computing devices namely digital computers 
and the historical analog computer. The earliest computers were analog not digital, 
and these two types of computer operate on quite different principles.
The computation in a digital computer is based on binary digits, that is, “0” and 
“1”. Electronic circuits are used to represent binary numbers, with the state of an 
electrical switch (i.e., “on” or “off”) representing a binary digit internally within a 
computer.
A digital computer is a sequential device that generally operates on data one step 
at a time. The data are represented in binary format, and a single transistor is used 
to represent a binary digit in a digital computer. Several transistors are required to 
store larger numbers. The earliest digital computers were developed in the 1940s.
An analog computer operates in a completely different way to a digital computer. 
The representation of data in an analog computer reflects the properties of the data 
that are being modeled. For example, data and numbers may be represented by 
physical quantities such as electric voltage in an analog computer, whereas a stream 
of binary digits represents them in a digital computer.
1.2  Analog Computers
James Thompson (who was the brother of the physicist Lord Kelvin) did early foun-
dational work on analog computation in the nineteenth century. He invented a wheel 
and disc integrator, which was used in mechanical analog devices, and he worked 
with Kelvin to construct a device to perform the integration of a product of two 
functions. Kelvin later described a general-purpose analog machine (he did not 
build it) for integrating linear differential equations of any order. He built a tide-­
predicting analog computer that remained in use at the Port of Liverpool up to 
the 1960s.1
The operations in an analog computer are performed in parallel, and they are 
useful in simulating dynamic systems. They have been applied to flight simulation, 
nuclear power plants, and industrial chemical processes.
Vannevar Bush at the Massachusetts Institute of Technology developed the first 
large-scale general-purpose mechanical analog computer. This machine was Bush’s 
differential analyzer (Fig. 1.1), and it was a mechanical analog computer designed 
to solve sixth-order differential equations by integration, using wheel-and-disc 
mechanisms to perform the integration. This mechanization allowed integration and 
differential equations problems to be solved more rapidly. The machine took up the 
space of a large table in a room and weighed 100 tons.
It contained wheels, discs, shafts, and gears to perform the calculations. It 
required a considerable set up time by technicians to solve a particular equation. It 
contained 150 motors and miles of wires connecting relays and vacuum tubes.
1 Tide-predicting machines are special-purpose mechanical analog computers that predict the ebb 
and flow of sea tides and the irregular variation in their heights.
1  What Is a Computer?

3
Data representation in an analog computer is compact, but it may be subject to 
corruption with noise. A single capacitor can represent one continuous variable in 
an analog computer, whereas several transistors are required in a digital computer. 
Analog computers were replaced by digital computers shortly after the Second 
World War.
1.3  Digital Computers
Early digital computers used vacuum tubes to store binary information, and a vac-
uum tube could represent the binary value “0” or “1”. These tubes were large and 
bulky and generated a significant amount of heat. Air-conditioning was required to 
cool the machine, and there were problems with the reliability of the tubes.
Shockley and others invented the transistor in the later 1940s, and transistors 
replaced vacuum tubes from the late 1950s. Transistors are small and consume very 
little power, and the resulting machines were smaller, faster, and more reliable.
Integrated circuits were introduced in the early 1960s, and a massive amount of 
computational power could now be placed on a very small chip. Integrated circuits 
are small and consume very little power, and may be mass produced to very high-­
quality standard. However, integrated circuits are difficult to modify or repair and 
nearly always need to be replaced.
The fundamental architecture of a computer has remained basically the same 
since von Neumann and others proposed it in the mid-1940s. It includes a central 
processing unit which includes the control unit and the arithmetic unit, an input and 
output unit, and memory.
Fig. 1.1  Vannevar Bush with the differential analyzer
1.3  Digital Computers

4
1.3.1  Vacuum Tubes
A vacuum tube is a device that relies on the flow of an electric current through a 
vacuum. Vacuum tubes (thermionic valves) were widely used in electronic devices 
such as televisions, radios, and computers until the invention of the transistor.
The basic idea of a vacuum tube is that a current passes through the filament, 
which then heats it up so that it gives off electrons. The electrons are negatively 
charged and are attracted to the small positive plate (or anode) within the tube. A 
unidirectional flow is thus established between the filament and the plate. Thomas 
Edison had observed this while investigating the reason for breakage of lamp fila-
ments. He noted an uneven blackening (darkest near one terminal of the filament) of 
the bulbs in his incandescent lamps, and noted that current flows from the lamp’s 
filament and a plate within the vacuum.
The first generation of computers used several thousand bulky vacuum tubes, 
with several racks of vacuum tubes taking up the space of a large room. The vacuum 
tube used in the early computers was a three-terminal device, and it consisted of a 
cathode, a grid, and a plate. The vacuum tube was used to represent one of two 
binary states, that is, the binary value “0” or “1”.
The filament of a vacuum tube becomes unstable over time. Further, if air leaked 
into the tube, then oxygen would react with the hot filament and damage it. The size 
and unreliability of vacuum tubes motivated research into more compact and reli-
able technologies, which led to the invention of the transistor in the late 1940s.
The first generation of digital computers all used vacuum tubes: for example, the 
Atanasoff-Berry computer (ABC) developed at the University of Iowa in 1942; 
Colossus developed at Bletchley Park, England, in 1944; ENIAC developed in the 
United States in the mid-1940s; UNIVAC I developed in 1951; Whirlwind devel-
oped in 1951; and the IBM 701 developed in 1953.
1.3.2  Transistors
The transistor is a fundamental building block in modern electronic systems, and its 
invention revolutionized the field of electronics. It was smaller, cheaper, and more 
reliable than the existing vacuum tubes.
The transistor is a three-terminal, solid-state electronic device. It can control 
electric current or voltage between two of the terminals by applying an electric cur-
rent or voltage to the third terminal. The three-terminal transistor enables an electric 
switch to be made which can be controlled by another electrical switch. Complicated 
logic circuits may be built up by cascading these switches (switches that control 
switches that control switches, and so on).
These logic circuits may be built very compactly on a silicon chip (e.g., a density 
of millions or billions of transistors per square centimeter). The switches may be 
turned on and off very rapidly (e.g., every 0.000000001 second). These electronic 
chips are at the heart of modern electron devices.
1  What Is a Computer?

5
The transistor (Fig. 1.3) was developed at Bell Labs after the Second World War. 
The goal of the research was to find a solid-state alternative to vacuum tubes, as this 
technology was too bulky and unreliable. Three inventors at Bell Labs (Shockley, 
Bardeen, and Brattain) were awarded the Nobel Prize in physics in 1956 in recogni-
tion of their invention of the transistor.
William Shockley (Fig. 1.2) was involved in radar research and antisubmarine 
operations research during the Second World War, and after the war, he led a 
research group including Bardeen and Brattain to find a solid-state alternative to the 
glass-based vacuum tubes.
Bardeen and Brattain succeeded in creating a point contact transistor in 1947 
independently of Shockley who was working on a junction-based transistor. 
Shockley believed that the points contact transistor would not be commercially 
viable, and his junction point transistor was announced in 1951 (Fig. 1.3).
Fig. 1.3  Replica of 
transistor. Public domain
Fig. 1.2  William Shockley. 
Creative Commons
1.3  Digital Computers

6
Shockley was not an easy person to work with and relations between him and the 
others deteriorated. He formed Shockley Semiconductor Inc. (part of Beckman 
Instruments) in 1955.
The second generation of computers used transistors instead of vacuum tubes. 
The University of Manchester’s experimental Transistor Computer was one of the 
earliest transistor computers. The prototype machine appeared in 1953, and the full-­
size version was commissioned in 1955. The invention of the transistor is discussed 
in more detail in Chap. 6.
1.3.3  Integrated Circuits
Jack Kilby of Texas Instruments invented the integrated circuit in 1958. His inven-
tion used a wafer of germanium, and Robert Noyce of Fairchild Semiconductors did 
subsequent work on silicon-based integrated circuits. The integrated circuit was a 
solution to the problem of building a circuit with a large number of components, and 
the Nobel Prize in Physics was awarded to Kilby in 2000 for his contribution to its 
invention.
The idea was that instead of making transistors one-by-one that several transis-
tors could be made at the same time on the same piece of semiconductor. This 
allowed transistors and other electric components such as resistors, capacitors, and 
diodes to be made by the same process with the same materials.
An integrated circuit consists of a set of electronic circuits on a small chip of 
semiconductor material, and it is much smaller than a circuit made out of indepen-
dent components. Integrated circuits today are extremely compact, and may contain 
billions of transistors and other electronic components in a tiny area. The width of 
each conducting line has got smaller and smaller due to advances in technology over 
the years, and it is now measured in tens of nanometers
The number of transistors per unit area has been doubling (roughly) every 
1–2 years over the last 30 years. This amazing progress in circuit fabrication is 
known as Moore’s law after Gordon Moore (one of the founders of Intel), who for-
mulated the law in the mid-1960s (see Chap. 7).
Kilby was designing micro modules for the military, and this involved connect-
ing many germanium2 wafers of discrete components together by stacking each 
wafer on top of one another. The connections were made by running wires up the 
sides of the wafers.
Kilby saw this process as unnecessarily complicated and realized that if a piece 
of germanium was engineered properly that it could act as many components simul-
taneously. This was the idea that led to the birth of the first integrated circuit and its 
development involved miniaturizing transistors and placing them on silicon chips 
called semiconductors. The use of semiconductors led to third-generation comput-
ers, with a major increase in speed and efficiency.
2 Germanium is an important semiconductor material used in transistors and other electronic 
devices, although silicon is more common.
1  What Is a Computer?

7
Users interacted with third-generation computers through keyboards and moni-
tors and interfaced with an operating systems, which allowed the device to run many 
different applications at one time with a central program that monitored the mem-
ory. Computers became accessible to a wider audience, as they were smaller and 
cheaper than their predecessors. The invention of the integrated circuit is discussed 
in more detail in Chap. 7.
1.3.4  Microprocessors
The Intel P4004 microprocessor (Fig. 1.4) was the world’s first microprocessor, and 
it was released in 1969. It was the first semiconductor device that provided, at the 
chip level, the functions of a computer.
The invention of the microprocessor happened by accident rather than design. 
Busicom, a Japanese company, requested Intel to design a set of integrated circuits 
for its new family of high-performance programmable calculators. Ted Hoff, an 
Intel engineer, studied Busicom’s design and rejected it as unwieldy. He proposed a 
more elegant solution requiring just four integrated circuits (Busicom’s original 
design required 12 integrated circuits), and his design included a chip that was a 
general-purpose logic device that derived its application instructions from the semi-
conductor memory. This was the Intel 4004 microprocessor.
It provided the basic building blocks that are used in today’s microcomputers, 
including the arithmetic and logic unit and the control unit. The 4-bit Intel 4004 ran 
at a clock speed of 108 kHz and contained 2300 transistors. It processed data in 4 
bits, but its instructions were 8 bits long. It could address up to 1 Kb of program 
memory and up to 4 Kb of data memory.
Gary Kildall of Digital Research was one of the early people to recognize the 
potential of a microprocessor as a computer in its own right. He worked as a consul-
tant with Intel, and he began writing experimental programs for the Intel 4004 
microprocessor. He later developed the CP/M operating system for the Intel 8080 
chip, and he set up Digital Research to market and sell the operating system.
The development of the microprocessor led to the fourth generation of comput-
ers with thousands of integrated circuits placed onto a single silicon chip. A single 
chip could now contain all of the components of a computer from the CPU and 
Fig 1.4  Intel 4004 
microprocessor
1.3  Digital Computers

8
memory to input and output controls. It could fit in the palm of the hand whereas 
first generation of computers filled an entire room. The invention of the micropro-
cessor is discussed in more detail in Chap. 10, and it led to the home and personal 
computer industry.
1.4  von Neumann Architecture
The earliest computers were fixed programs machines that were designed to do a 
specific task. This proved to be a major limitation as it meant that a complex manual 
rewiring process was required to enable the machine to solve a different problem.
The computers used today are general-purpose machines designed to allow a 
variety of programs to be run on the machine. von Neumann and others [VN:45] 
described the fundamental architecture underlying the computers used today in the 
late 1940s. It is known as von Neumann architecture (Fig. 1.5).
von Neumann architecture arose on work done by von Neumann, Eckert, 
Mauchly, and others on the design of the EDVAC computer, which was the succes-
sor to ENIAC computer. von Neumann’s draft report on EDVAC described the new 
architecture.
von Neumann architecture led to the birth of stored program computers, where a 
single store is used for both machine instructions and data. The key components of 
von Neumann architecture are described in Table 1.1.
The key approach to building a general-purpose device according to von 
Neumann was in its ability to store not only its data and the intermediate results of 
computation but also the instructions or commands for the computation. The com-
puter instructions can be part of the hardware for specialized machines, but for 
general-purpose machines, the computer instructions must be as changeable as the 
data that is acted upon by the instructions. His insight was to recognize that both the 
machine instructions and data could be stored in the same memory.
The key advantage of the von Neumann architecture over the existing approach 
was that it was much simpler to reconfigure a computer to perform a different task. 
Memory
Control 
Unit
Input
Output
Arithmetic 
Logic Unit
Accumulator
Fig. 1.5  von Neumann 
architecture
1  What Is a Computer?

9
Table 1.1  von Neumann architecture
Component
Description
Arithmetic 
unit
The arithmetic unit is capable of performing basic arithmetic operations.
Control unit
The program counter contains the address of the next instruction to be executed. 
This instruction is fetched from memory and executed. This is the basic Fetch 
and Execute cycle (Fig. 1.6).
The control unit contains a built in set of machine instructions.
Input–Output 
unit
The input and output unit allows the computer to interact with the outside world.
Memory
The one-dimensional memory stores all of the program instructions and data. 
These are usually kept in different areas of memory.
The memory may be written to or read from, that is, it is random access memory 
(RAM).
The program instructions are binary values, and the control unit decodes the 
binary value to determine the particular instruction to execute.
Memory
CPU       
Accumulator
Fetch
Execute
Decode (Instructions / Data)
Fig. 1.6  Fetch/
execute cycle
All that was required was to enter new machine instructions in computer memory 
rather than physically rewiring a machine as was required with ENIAC. The limita-
tions of von Neumann architecture include that it is limited to sequential processing 
and not very suitable for parallel processing.
1.5  Hardware and Software
Hardware is the physical part of the machine. It is tangible and may be seen or 
touched. It includes punched cards, vacuum tubes, transistors and circuit boards, 
integrated circuits, and microprocessors. The hardware of a personal computer 
includes a keyboard, network cards, a mouse, a DVD drive, hard disk drive, printers 
and scanners, and so on.	
Software is intangible and consists of a set of instruc-
tions that tells the computer what to do. It is an intellectual creation of a program-
mer or a team of programmers. Operating system software manages the computer 
hardware and resources, and it acts as an intermediary between the application pro-
grams and the computer hardware. Examples of operating systems include the 
OS/360 for the IBM System 360 mainframe; the UNIX operating system; the vari-
ous Microsoft Windows operating system for the personal computer; and the Mac 
operating system for the Macintosh computer.
1.5  Hardware and Software

10
1.6  Review Questions
1.7  Summary
A computer is a programmable electronic device that can process, store, and retrieve 
data. It processes data according to a set of instructions or program. All computers 
consist of hardware and software, where the hardware is the physical part of the 
machine, whereas software is intangible and consists of the set of instructions that 
tells the computer what to do.
There are two distinct families of computing devices namely digital computers 
and analog computers, and these operate on quite different principles. A digital 
computer is a sequential device that generally operates on data one step at a time 
with the data represented in binary format. A single transistor can store only two 
states, that is, on and off. Several transistors are required to store larger numbers.
The representation of data in an analog computer reflects the properties of the 
data that is being modeled. For example, data and numbers may be represented by 
physical quantities such as electric voltage in an analog computer. However, a 
stream of binary digits represents the data in a digital computer.
	1.	 Explain the difference between analog and digital computers.
	2.	 Explain the difference between hardware and software.
	3.	 What is a microprocessor?
	4.	 Explain the difference between vacuum tubes, transistors, and integrated 
circuits.
	5.	 Explain von Neumann architecture.
	6.	 What are the advantages and limitations of the von Neumann architecture?
	7.	 Explain the difference between a fixed program machine and a stored pro-
gram machine.
1  What Is a Computer?

11
© The Author(s), under exclusive license to Springer Nature 
Switzerland AG 2021
G. O’Regan, A Brief History of Computing, 
https://doi.org/10.1007/978-3-030-66599-9_2
Chapter 2
Computing in Early Civilizations
2.1  Introduction
The pace of change and innovation in western society over the last 20–30 years has 
been phenomenal. There is a proliferation of sophisticated technology such as 
computers, smart phones, the Internet, the World Wide Web, social media, and so 
on. Software is pervasive and is an integral part of automobiles, airplanes, televisions, 
and mobile communication. The pace of change is relentless, and communication 
today is instantaneous with video calls, text messaging, mobile phones, and e-mail. 
Today people may book flights over the World Wide Web as well as keeping in 
contact with family members in any part of the world. In previous generations, 
communication often involved writing letters that took months to reach the recipient. 
Communication improved with the telegraph and the telephone in the late nineteenth 
century, but today it is instantaneous.
The new technologies have led to major benefits1 to society and to improvements 
in the standard of living for many citizens in the western world. It has also reduced 
the necessity for humans to perform some of the more tedious or dangerous manual 
tasks, as computers may now automate many of these. The increase in productivity 
due to the more advanced computerized technologies has allowed humans, at least 
in theory, the freedom to engage in more creative and rewarding tasks.
1 The new technologies are of major benefit to society, but it is essential to move toward more 
sustainable development to ensure the long-term survival of the planet. This involves finding tech-
nological and other solutions to reduce greenhouse gas emissions as well as moving to a carbon 
neutral way of life. The environmental crisis is a major challenge for the twenty-first century.
Key Topics
Babylonian mathematics
Egyptian civilization
Greek and Roman civilization
Counting and numbers
Solving practical problems
Syllogistic logic
Algorithms
Early ciphers

12
Societies have evolved over millennia and some early societies had a limited 
vocabulary for counting: for example, “one, two, three, many” is associated with a 
number of primitive societies, and indicates limited numerate and scientific abilities. 
It suggests that the problems dealt with in this culture were elementary. These 
primitive societies generally employed their fingers for counting, and as humans 
have five fingers on each hand and five toes on each foot, then the obvious bases 
would have been 5, 10, and 20. Traces of the earlier use of the base 20 system are 
still apparent in modern languages such as English and French. This includes 
phrases such as “three score” in English and “quatre vingt” in French.
The decimal system (base 10) is used today in western society, but the base 60 
was common in early computation circa 1500 BC. One example of the use of base 
60 today is still evident in the subdivision of hours into 60  minutes, and the 
subdivision of minutes into 60 seconds. The base 60 system (i.e., the sexagesimal 
system) is inherited from the Babylonians [Res:84], and the Babylonians were able 
to represent arbitrarily large numbers or fractions with just two symbols.
The achievements of some of these early civilizations are impressive. The arche-
ological remains of ancient Egypt such as the pyramids at Giza and the temples 
along the Nile such as at Karnak and Abu Simbel are inspiring. These monuments 
provide an indication of the engineering sophistication of the ancient Egyptian 
civilization. The objects found in the tomb of Tutankhamun2 are now displayed in 
the Egyptian museum in Cairo and demonstrate the artistic skill of the Egyptians.
The Greeks made major contributions to western civilization including contribu-
tions to Mathematics, Philosophy, Logic, Drama, Architecture, Biology, and 
Democracy.3 The Greek philosophers considered fundamental questions such as 
ethics, the nature of being, how to live a good life, and the nature of justice and poli-
tics. The Greek philosophers include Parmenides, Heraclitus, Socrates, Plato, and 
Aristotle. The Greeks invented democracy, and their democracy was radically dif-
ferent from today’s representative democracy.4 The sophistication of Greek 
2 Tutankhamun was a minor Egyptian pharaoh who reigned after the controversial rule of 
Akhenaten. Howard Carter discovered Tutankhamun’s intact tomb in the Valley of the Kings. The 
quality of the workmanship of the artifacts found in the tomb was extraordinary, and a visit to the 
Egyptian museum in Cairo is memorable.
3 The origin of the word “democracy” is from demos (δημος) meaning people and kratos (κρατος) 
meaning rule. That is, it means rule by the people. It was introduced into Athens following the 
reforms introduced by Cleisthenes. He divided the Athenian city-state into thirty areas. Twenty of 
these areas were inland or along the coast and ten were in Attica itself. Fishermen lived mainly in 
the ten coastal areas; farmers in the ten inland areas; and various tradesmen in Attica. Cleisthenes 
introduced ten new clans where the members of each clan came from one coastal area, one inland 
area on one area in Attica. He then introduced a Boule (or assembly) which consisted of 500 mem-
bers (50 from each clan). Each clan ruled for 1/10 th of the year.
4 The Athenian democracy involved the full participations of the citizens (i.e., the male adult mem-
bers of the city-state who were not slaves), whereas in representative democracy, the citizens elect 
representatives to rule and represent their interests. The Athenian democracy was chaotic and 
could also be easily influenced by individuals who were skilled in rhetoric. There were teachers 
(known as the Sophists) who taught wealthy citizens rhetoric in return for a fee. The origin of the 
word “sophist” is the Greek word σοφος meaning wisdom. One of the most well-known of the 
2  Computing in Early Civilizations

13
architecture and sculpture is evident from the Parthenon on the Acropolis and the 
Elgin marbles5 that are housed today in the British Museum, London.
The Hellenistic6 period commenced with Alexander the Great, and led to the 
spread of Greek culture throughout most of the known world. The city of Alexandria 
became a center of learning during the Hellenistic period. Its scholars included 
Euclid who provided a systematic foundation for geometry, and his famous work 
“The Elements” consists of thirteen books.
There are many words of Greek origin that are part of the English language. 
These include words such as psychology which is derived from two Greek words: 
psyche (ψυχη) and logos (λογος). The Greek word “psyche” means mind or soul, 
and the word “logos” means an account or discourse. Other examples are 
anthropology derived from “anthropos” (ανθροπος) and “logos” (λογος).
The Romans were influenced by Greeks culture, and following Rome’s defeat of 
the Greek city-states, many Greeks became tutors in Rome, as the Roman’s 
recognized the value of Greek culture and knowledge. The Romans built aqueducts, 
viaducts, and amphitheatres; they developed the Julian calendar; formulated laws 
(lex); and maintained peace throughout the Roman Empire (pax Romano). The 
ruins of Pompeii and Herculaneum demonstrate their engineering excellence. The 
Roman numbering system is still employed in clocks and for page numbering in 
documents, but it is cumbersome for serious computation. The collapse of the 
Roman Empire in Western Europe led to a decline in knowledge and learning in 
Europe. However, the eastern part of the Roman Empire continued at Constantinople 
until the Ottomans conquered it in 1453 AD.
2.2  The Babylonians
The Babylonian7 civilization flourished in Mesopotamia (in modern Iraq) from 
about 2000  BC until about 500  BC.  Various clay cuneiform tablets containing 
mathematical texts were discovered and deciphered in the nineteenth century 
[Smi:23]. These included tables for multiplication, division, squares, cubes, and 
square roots; measurement of area and length; and the solution of linear and 
quadratic equations. The late Babylonian period (c. 500  BC) includes work on 
astronomy.
The Babylonians recorded their mathematics on soft clay using a wedge-shaped 
instrument to form impressions of the cuneiform numbers. The clay tablets were 
sophists was Protagoras. The problems with Athenian democracy led philosophers such as Plato to 
consider alternate solutions such as rule by philosopher kings. This is described in Plato’s Republic.
5 The Elgin marbles are named after Lord Elgin who moved them from the Parthenon in Athens to 
London in 1806. The marbles show the Pan-Athenaic festival that was held in Athens in honor of 
the goddess Athena after whom Athens is named.
6 The origin of the word Hellenistic is from Hellene (‘Ελλην) meaning Greek.
7 The hanging gardens of Babylon were one of the seven wonders of the ancient world.
2.2  The Babylonians

14
then baked in an oven or by the heat of the sun. They employed just two symbols (1 
and 10) to represent numbers, and these symbols were then combined to form all 
other numbers. They employed a positional number system8 and used the base 60 
system. The symbol representing 1 could also (depending on the context) represent 
60, 602, 603, etc. It could also mean 1/60, 1/3600, and so on. There was no zero employed 
in the system, and there was no decimal point (no “sexagesimal point”), and 
therefore, the context was essential.
 
The example above illustrates the cuneiform notation and represents the number 
60 + 10 + 1 = 71. They used the base 60 system for computation, and one possible 
explanation for this is the ease of dividing 60 into parts as it is divisible by 2, 3, 4, 
5, 6, 10, 12, 15, 20, and 30. They were able to represent large and small numbers and 
had no difficulty in working with fractions (in base 60) and in multiplying fractions. 
They maintained tables of reciprocals (i.e., 1/n, n = 1, ... 59 apart from numbers like 
7, 11, etc., which are not of the form 2α3β5γ and cannot be written as a finite 
sexagesimal expansion).
Babylonian numbers may be represented in a more modern sexagesimal notation 
[Res:84]. For example, 1;24, 51, 10 represents the number 1 + 24/60 + 51/3600 + 10/216000 
= 1 + 0.4 + 0.0141666 + 0.0000462 = 1.4142129 and is the Babylonian represen-
tation of the square root of 2. The Babylonians performed multiplication as the 
following calculation of (20) × (1;24, 51, 10), that is, 20 × sqrt(2) illustrates:
	
20 1
20
20
24
20 2460
8
20 513600
51180
1760
17
20 10216000
 









;
;



33600
20216000
0 3 20
; , ,
	
Hence, 20 × sqrt (2) = 20; + 8; + ;17 + ;0, 3, 20 = 28;17, 3, 20
The Babylonians appear to have been aware of Pythagoras’s theorem about 
1000 years before the time of Pythagoras. The Plimpton 322 tablet (Fig. 2.1) records 
various Pythagorean triples, that is, triples of numbers (a, b, c) where a2 + b2 = c2. It 
dates from approximately 1700 BC.
They developed an algebra to assist with problem solving, which allowed prob-
lems involving length, breadth, and area to be discussed and solved. They did not 
employ notation for representation of unknown values (e.g., let x be the length and 
y be the breadth), and instead, they used words like “length” and “breadth.” They 
8 A positional numbering system is a number system where each position is related to the next by 
a constant multiplier. The decimal system is an example: for example, 546 = 5 × 102 + 4 × 101 + 6.
2  Computing in Early Civilizations

15
were familiar with and used square roots in their calculations, as well as techniques 
to solve quadratic equations.
They 
were 
familiar 
with 
various 
mathematical 
identities 
such 
as 
(a + b)2 = (a2 + 2ab + b2) as illustrated geometrically in Fig. 2.2. They also worked 
on astronomical problems, and they had mathematical theories of the cosmos to 
predict when eclipses and other astronomical events would occur. They were also 
interested in astrology, and they associated various deities with the heavenly bodies 
such as the planets, as well as the sun and moon. Various clusters of stars were 
associated with familiar creatures such as lions, goats, and so on.
The Babylonians used counting boards to assist with counting and simple calcu-
lations. A counting board is an early version of the abacus, and it was usually made 
of wood or stone. The counting board contained grooves, which allowed beads or 
stones to be moved along the groove. The abacus differed from counting boards in 
that the beads in abaci contained holes that enabled them to be placed in a particular 
rod of the abacus.
2.3  The Egyptians
The Egyptian civilization developed along the Nile from about 4000 BC, and the 
pyramids at Giza were built during the Fourth Dynasty around 3000    BC.  The 
Egyptians used mathematics to solve practical problems such as measuring time, 
measuring the annual Nile flooding, calculating the area of land, book keeping and 
accounting, and calculating taxes. They developed a calendar circa 4000 BC, which 
Fig. 2.1  The Plimpton 322 tablet
2.3  The Egyptians

16
consisted of 12 months with each month having 30 days. There were five extra feast 
days to give 365 days in a year. Egyptians writing commenced around 3000 BC, and 
it is recorded on the walls of temples and tombs.9 A reed-like parchment termed 
“papyrus” was also used for writing, and there are three Egyptian writing scripts 
namely hieroglyphics, the hieratic script, and the demotic script.
Hieroglyphs are little pictures and are used to represent words, alphabetic char-
acters as well as syllables or sounds, and there were also special indeterminate signs 
to indicate the type of reading to be used. Champollion deciphered hieroglyphics 
with his work on the Rosetta stone, which was discovered during the Napoleonic 
campaign in Egypt, and it is now in the British Museum in London. It contains three 
scripts: Hieroglyphics, Demotic script, and Greek. A key part of the decipherment 
was that the Rosetta stone contained just one name “Ptolemy” in the Greek text, and 
this was identified with the hieroglyphic characters in the cartouche10 of the hiero-
glyphics. There was just one cartouche on the Rosetta stone, and Champollion 
inferred that the cartouche represented the name “Ptolemy.” He was familiar with 
another multilingual object, which contained two names in the cartouche. One he 
recognized as Ptolemy and the other he deduced from the Greek text as “Cleopatra.” 
This led to the breakthrough in translation of the hieroglyphics [Res:84], and 
Champollion’s knowledge of Coptic (where Egyptian is written in Greek letters) 
was essential in the deciphering
The Rhind Papyrus is a famous Egyptian papyrus on mathematics. The Scottish 
Egyptologist Henry Rhind purchased it in 1858, and it is a copy created by an 
Egyptian scribe called Ahmose.11 It is believed to date to 1832  BC.  It contains 
9 The decorations of the tombs in the Valley of the Kings record the life of the pharaoh including 
his exploits and successes in battle.
10 The cartouche surrounded a group of hieroglyphic symbols enclosed by an oval shape. 
Champollion’s insight was that the group of hieroglyphic symbols represented the name of the 
Ptolemaic pharaoh “Ptolemy.”
11 The Rhind papyrus is sometimes referred to as the Ahmose papyrus in honor of the scribe who 
wrote it in 1832 BC.
a
2
b
2
a
b
ab
ab
a+b
Fig. 2.2  Geometric 
representation of 
(a + b)2 = (a2 + 2ab + b2)
2  Computing in Early Civilizations

17
examples of all kinds of arithmetic and geometric problems, and students may have 
used it as a textbook to develop their mathematical knowledge. This would allow 
them to participate in the pharaoh’s building program.
The Egyptians were familiar with geometry, arithmetic, and elementary algebra. 
They had formulae to find solutions to problems with one or two unknowns. A base 
10 number system was employed with separate symbols for one, ten, a hundred, a 
thousand, a ten thousand, a hundred thousand, and so on. These hieroglyphic sym-
bols are represented in Fig. 2.3.
For example, the representation of the number 276 in Egyptian Hieroglyphics is 
given in Fig. 2.4.
The addition of two numerals is straightforward and involves adding the indi-
vidual symbols, and where there are ten copies of a symbol it is then replaced by a 
single symbol of the next higher value. The Egyptian employed unit fractions (e.g., 
1/n where n is an integer). These were represented in hieroglyphs by placing the 
symbol representing a “mouth” above the number. The symbol “mouth” represents 
part of. For example, the representation of the number 1/276 is given Fig. 2.5.
The papyrus included problems to determine the angle of the slope of the pyra-
mid’s face. The Egyptians were familiar with trigonometry including sine, cosine, 
tangent, and cotangent, and they knew how to build right angles into their structures 
by using the ratio 3:4:5. The papyrus also considered problems such as the calcula-
tion of the number of bricks required for part of a building project. They were famil-
iar with addition, subtraction, multiplication, and division. However, their 
multiplication and division was cumbersome as they could only multiply and 
divide by two.
Suppose they wished to multiply a number n by 7. Then, n × 7 is determined by 
n × 2 + n × 2 + n × 2 + n. Similarly, if they wished to divide 27 by 7 they would note 
that 7 × 2 + 7 = 21 and that 27 – 21 = 6 and that therefore the answer was 3 6/7. 
Egyptian mathematics was cumbersome and the writing of it was long and repetitive. 
For example, they wrote a number such as 22 by 10 + 10 + 1 + 1.
The Egyptians calculated the approximate area of a circle by calculating the area 
of a square 8/9 of the diameter of a circle. That is, instead of calculating the area in 
terms of our familiar πr2 their approximate calculation yielded (8/9 × 2r)2 = 256/81 r2 
Fig. 2.3  Egyptian numerals
Fig. 2.4  Egyptian representation  
of a number
2.3  The Egyptians

18
or 3.16 r2. Their approximation of π was 256/81 or 3.16. They were able to calculate 
the area of a triangle and volumes.
The Moscow papyrus is a well-known Egyptian papyrus, and it includes a prob-
lem to calculate the volume of the frustum. The formula for the volume of a frustum 
of a square pyramid12 was given by V = 1/3 h(b1
2 + b1b2 + b2
2), and when b2 is 0, then 
the well-known formula for the volume of a pyramid is given: that is, 1/3 hb1
2.
2.4  The Greek and Hellenistic Contribution
The Greeks made major contributions to western civilization including mathemat-
ics, logic, astronomy, philosophy, politics, drama, and architecture. The Greek 
world of 500 BC consisted of several independent city-states, such as Athens and 
Sparta, and various city-states in Asia Minor. The Greek polis (πολις) or city-state 
tended to be quite small, and it consisted of the Greek city and a certain amount of 
territory outside the city. Each city-state had its own unique political structure for its 
citizens: some were oligarchs where political power was maintained in the hands of 
a few individuals or aristocratic families; others were ruled by tyrants (or sole rul-
ers) who sometimes took power by force, but who often had a lot of support from 
the public. These included people such as Solon, Peisistratus, and Cleisthenes 
in Athens.
The reforms by Cleisthenes led to the introduction of the Athenian democracy. 
Power was placed in the hands of the citizens who were male (women or slaves did 
not participate). It was an extremely liberal democracy where citizens voted on all 
of the important issues. Often, this led to disastrous results as speakers who were 
skilled in rhetoric could exert significant influence (e.g., the disastrous Sicilian 
expedition during the Peloponnesian war). This led Plato to advocate austere rule by 
philosopher kings rather than democracy, and Plato’s republic was influenced by the 
ideals of Sparta.
Early Greek mathematics commenced approximately 500–600 BC with work 
done by Pythagoras and Thales. Pythagoras was a philosopher and mathematician 
who had spent time in Egypt becoming familiar with Egyptian mathematics. He was 
born on the island of Samos (off the coast of Turkey), and he later moved to Croton 
in the south of Italy. He formed a secret society known as the Pythagoreans, and 
they included men and women who believed in the transmigration of souls and that 
12 The length of a side of the bottom base of the pyramid is b1and the length of a side of the top 
base is b2
Fig. 2.5  Egyptian representation of a fraction
2  Computing in Early Civilizations

19
number was the essence of all things. They discovered the mathematics for harmony 
in music, with the relationship between musical notes being expressed in numerical 
ratios of small whole numbers. Pythagoras is credited with the discovery of 
Pythagoras’s theorem, although the Babylonians probably knew this theorem about 
1000 years before Pythagoras. The Pythagorean society was dealt a major blow13 by 
the discovery of the incommensurability of the square root of 2, that is, there are no 
numbers p, q such that √2 = p/q.
Thales was a sixth century (BC) philosopher from Miletus in Asia Minor (Turkey) 
who made contributions to philosophy, geometry, and astronomy. His contributions 
to philosophy are mainly in the area of metaphysics, and he was concerned with 
questions on the nature of the world. His objective was to give a natural or scientific 
explanation of the cosmos, rather than relying on the traditional supernatural 
explanation of creation in Greek mythology. He believed that there was single 
substance that was the underlying constituent of the world, and he believed that this 
substance was water. He also contributed to mathematics [AnL:95], and Thales’s 
theorem in Euclidean geometry states that if A, B and C are points on a circle, where 
the line AC is a diameter of the circle, then the angle <ABC is a right angle.
The rise of Macedonia led to the Greek city-states being conquered by Philip of 
Macedonia in the fourth century BC. His son, Alexander the Great, defeated the 
Persian Empire, and he extended his empire to include most of the known world. 
This led to the Hellenistic Age where Greek language and culture spread to the 
known world. Alexander founded the city of Alexandra, and it became a major 
center of learning in Ptolemaic Egypt.14 However, Alexander’s reign was very short 
as he died at the young age of 33 in 323 BC.
Euclid lived in Alexandria during the early Hellenistic period. He is considered 
the father of geometry and the deductive method in mathematics. His systematic 
treatment of geometry and number theory is published in the thirteen books of the 
Elements [Hea:56]. It starts from five axioms, five postulates, and twenty-three 
definitions to logically derive a comprehensive set of theorems. His method of proof 
was generally constructive, in that as well as demonstrating the truth of a theorem 
the proof would often include the construction of the required entity. He was also 
used indirect proof (a nonconstructive proof) to show that there are an infinite 
number of primes:
	1.	 Suppose there is a finite number of primes (say n primes).
	2.	 Multiply all n primes together and add 1 to form N.
	
N 

 



p
p
pn
1
2
1
.
	
13 The Pythagoreans were a secret society and its members took a vow of silence with respect to this 
discovery. However, one member of the society is said to have shared the secret result with others 
outside the sect, and the apocryphal account is that he was thrown into a lake for his betrayal and 
drowned. They obviously took Mathematics seriously back then!
14 The ancient library in Alexandria was once the largest library in the world. It was built during the 
Hellenistic period in the third century BC and destroyed by fire in 391 A.D.
2.4  The Greek and Hellenistic Contribution

20
	3.	 N is not divisible by p1, p2, ….., pn as dividing by any of these gives a remain-
der of one.
	4.	 Therefore, N must either be prime or divisible by some other prime that was not 
included in the list.
	5.	 Therefore, there must be at least n + 1 primes.
	6.	 This is a contradiction (it was assumed that there are n primes).
	7.	 Therefore, the assumption that there is a finite number of primes is false.
	8.	 Therefore, there is an infinite number of primes.
Euclidean geometry included the parallel postulate (the fifth postulate). This pos-
tulate generated interest, as many mathematicians believed that it was unnecessary 
and could be proved as a theorem. It states that:
Definition 2.1 (Parallel Postulate)
If a line segment intersects two straight lines forming two interior angles on the 
same side that sum to less than two right angles, then the two lines, if extended 
indefinitely, meet on that side on which the angles sum to less than two right angles.
This postulate was later proved to be independent of the other postulates with the 
development of non-Euclidean geometries in the nineteenth century. These include 
the hyperbolic geometry discovered independently by Bolyai and Lobachevsky and 
elliptic geometry as developed by Riemann. The standard model of Riemannian 
geometry is the sphere where lines are great circles.
The material in the Euclid’s Elements is a systematic development of geometry 
starting from the small set of axioms, postulates, and definitions, leading to theorems 
derived logically from the axioms and postulates. There are some jumps in reasoning, 
and the German mathematician, David Hilbert, later added extra axioms to address 
this. Euclidean geometry contains many well-known mathematical results such as 
Pythagoras’s theorem, Thales’s theorem, Sum of Angles in a Triangle, Prime 
Numbers, Greatest Common Divisor and Least Common Multiple, Euclidean 
Algorithm, Areas and Volumes, Tangents to a point, and Algebra.
The Euclidean algorithm is one of the oldest known algorithms, and it is used to 
determine the greatest common divisor of two numbers a and b. It is presented in 
the Elements, but it was known well before Euclid. The formulation of the gcd 
algorithm for two natural numbers a and b is as follows:
	1.	 Check if b is zero. If so, then a is the gcd.
	2.	 Otherwise, the gcd (a, b) is given by gcd (b, a mod b).
It is also possible to determine integers p and q such that ap + bq = gcd (a, b).
The proof of the Euclidean algorithm is as follows. Suppose a and b are two posi-
tive numbers whose gcd is to be determined, and let r be the remainder when a is 
divided by b.
	1.	 Clearly a = qb + r where q is the quotient of the division.
	2.	 Any common divisor of a and b is also a divider or r (since r = a – qb).
	3.	 Similarly, any common divisor of b and r will also divide a.
2  Computing in Early Civilizations

21
	4.	 Therefore, the greatest common divisor of a and b is the same as the greatest 
common divisor of b and r.
	5.	 The number r is smaller than b and we will reach r = 0 in finitely many steps.
	6.	 The process continues until r = 0.
Comment 2.1
Algorithms are fundamental in computing as they define the procedure by which a 
problem is solved. A computer program implements the algorithm in some program-
ming language.
Eratosthenes was a third century BC Hellenistic mathematician and scientist 
who worked as librarian in the famous library in Alexandria. He was the first person 
to estimate of the size of the circumference of the earth. His approach to the calcula-
tion was as follows (Fig. 2.6):
	1.	 Eratosthenes believed that the earth was a sphere.
	2.	 On the summer solstice at noon in the town of Syene (ancient name of Aswan15) 
on the Tropic of Cancer in Egypt the sun appears directly overhead.
	3.	 He assumed that rays of light came from the sun in parallel beams and reached 
the earth at the same time.
	4.	 At the same time, in Alexandria, he had measured that the sun would be 7.2° 
south of the zenith.
	5.	 He assumed that Alexandria was directly north of Aswan.
	6.	 He concluded that the distance from Alexandria to Aswan was 7.2/360 of the cir-
cumference of the earth.
	7.	 The distance between Alexandria and Aswan was 5000 stadia (approximately 
800 km).
	8.	 He established a value of 252,000 stadia or approximately 39,6000  km (the 
actual circumference at equator is 40,075 km).
Eratosthenes’s calculation was an impressive result for 200 BC. The errors in his 
calculation were due to:
15 The town of Aswan is famous today for the Aswan high dam, which was built in the 1960s. There 
was an older Aswan dam built by the British in the late nineteenth century. The new dam led to a 
rise in the water level of Lake Nasser and flooding of archaeological sites along the Nile. Several 
sites such as Abu Simbel and the island of Philae were relocated to higher ground.
Aswan
Alexandria
7.2°
Sun
Fig. 2.6  Eratosthenes measurement of the circumference of the earth
2.4  The Greek and Hellenistic Contribution

22
	1.	 Aswan is not exactly on the Tropic of Cancer (it is actually 55 km north of it).
	2.	 Alexandria is not exactly north of Aswan (there is a difference of 3° longitude).
	3.	 The distance between Aswan and Alexandria is 729 km not 800 km.
	4.	 Angles in antiquity could not be measured with absolute precision.
	5.	 The angular distance is actually 7.08° and not 7.2°.
The first century BC Stoic philosopher and polymath, Posidonius, also calcu-
lated the circumference of the earth using the star Canopus, and he arrived at a simi-
lar figure (240,000 stadia or 39,0000  km). Eratosthenes also calculated the 
approximate distance to the moon and sun, and he also produced maps of the known 
world. He developed a useful algorithm for determining all of the prime numbers up 
to a specified integer, and this is known as the Sieve of Eratosthenes. The steps in 
the algorithm are as follows:
	1.	 Write a list of the numbers from 2 to the largest number to be tested. This first 
list is called A.
	2.	 A second List B is created to list the primes. It is initially empty.
	3.	 The number 2 is the first prime number, and it is added to List B.
	4.	 Strike off (or remove) all multiples of 2 from List A.
	5.	 The first remaining number in List A is a prime number, and this prime number 
is added to List B.
	6.	 Strike off (or remove) this number and all multiples of it from List A.
	7.	 Repeat steps 5 through 7 until no more numbers are left in List A.
Comment 2.2
The Sieve of Eratosthenes method is a well-known algorithm for determining prime 
numbers.
Archimedes was a mathematician and astronomer who lived in Syracuse, Sicily. 
He discovered the law of buoyancy known as Archimedes’s principle:
The buoyancy force is equal to the weight of the displaced fluid.
He is believed to have discovered the principle while sitting in his bath, and he 
was so overwhelmed with his discovery that he rushed out onto the streets of 
Syracuse shouting “Eureka,” forgetting to put on his clothes.
The weight of the displaced liquid is proportional to the volume of the displaced 
liquid. Therefore, if two objects have the same mass, the one with greater volume 
(or smaller density) has greater buoyancy. An object will float if its buoyancy force 
(i.e., the weight of liquid displaced) exceeds the downward force of gravity (i.e., its 
weight). If the object has exactly the same density as the liquid, then it will stay still, 
neither sinking nor floating upwards.
For example, a rock is generally a very dense material, and so it usually does not 
displace its own weight. Therefore, a rock will sink to the bottom as the downward 
weight exceeds the buoyancy weight. However, the weight of a buoyancy device is 
significantly less than the liquid that it would displace, and so it floats at a level 
where it displaces the same weight of liquid as the weight of the object.
Archimedes also made good contributions to mathematics including an approxi-
mation to π, contributions to the positional numbering system, geometric series, and 
2  Computing in Early Civilizations

23
to maths physics. He also solved several interesting problems: for example, the 
calculation of the composition of cattle in the herd of the Sun god by solving a num-
ber of simultaneous Diophantine equations (named after Diophantus). The herd 
consisted of bulls and cows, with one part of the herd consisting of white, second 
part black, third spotted, and the fourth brown. Various constraints were then 
expressed in Diophantine equations, and the problem was to determine the precise 
composition of the herd.
He calculated the number of grains of sands in the known universe, and chal-
lenged the prevailing view this was too large to be determined. He developed a 
naming system for large numbers, as the largest number in use at the time was a 
myriad myriad (100 million), where a myriad is 10,000. He developed the laws of 
exponents: that is, 10a10b = 10a+ b, and his calculation of the upper bound includes 
not only the grains of sand on each beach but on the earth filled with sand and the 
known universe filled with sand. His final estimate of the upper bound of the num-
ber of grains of sand in a filled universe was 1064.
It is possible that he may have developed the odometer,16 which could calculate 
the total distance traveled on a journey. An odometer is described by the Roman 
engineer Vitruvius around 25 BC. It employed a wheel with a diameter of 4 feet, and 
the wheel turned 400 times in every mile.17 The device included gears and pebbles 
and a 400-tooth cogwheel that turned once every mile, and caused one pebble to 
drop into a box. The total distance traveled was determined by counting the number 
of pebbles in the box.
Aristotle was born in Macedonia and he became a student of Plato at Plato’s 
academy in Athens in the fourth century BC. (Fig. 2.7). Aristotle later founded his 
own school (known as the Lyceum) in Athens, and he was also the tutor of Alexander 
the Great. He made contributions to biology, logic, politics, ethics, and metaphysics.
His starting point to knowledge acquisition was the senses, as he believed that 
these were essential to acquire knowledge. His position is the opposite of Plato who 
argued that the senses deceive and should not be relied upon. Plato’s writings are 
mainly in dialogs involving his former mentor Socrates.18
Aristotle made important contributions to formal reasoning with his develop-
ment of syllogistic logic. Syllogistic logic (also known as term logic) consists of 
16 The origin of the word “odometer” is from the Greek words οδος (meaning journey) and μετρον 
meaning (measure).
17 The figures given here are for the distance of one Roman mile. This is given by 
π4 × 400 = 12.56 × 400 = 5024 (which is less than 5280 feet for a standard mile in the Imperial 
system).
18 Socrates was a moral philosopher who deeply influenced Plato. His method of enquiry into 
philosophical problems and ethics was by questioning. Socrates himself maintained that he knew 
nothing (Socratic ignorance). However, from his questioning, it became apparent that those who 
thought they were clever were not really that clever after all. His approach obviously would not 
have made him very popular with the citizens of Athens. Socrates had consulted the oracle at 
Delphi to find out who was the wisest of all men, and he was informed that there was no one wiser 
than him. Socrates was sentenced to death for allegedly corrupting the youth of Athens, and he was 
forced drink the juice of the hemlock plant (a type of poison).
2.4  The Greek and Hellenistic Contribution

24
reasoning with two premises and one conclusion. Each premise consists of two 
terms and there is a common middle term. The conclusion links the two unrelated 
terms from the premises. For example:
	
Premise 
All Greeks are Mortal
Premise 
Socrates is a Greek
1
2
.
_______________
Conclusion
Socrates is Mortal
	
The common middle term is “Greek,” which appears in the two premises. The 
two unrelated terms from the premises are “Socrates” and “Mortal.” The relation-
ship between the terms in the first premise is that of the universal, that is, any-
thing or any person that is a Greek is mortal. The relationship between the terms 
in the second premise is that of the particular, that is, Socrates is a person that is 
a Greek. The conclusion from the two premises is that Socrates is mortal, that is, 
Fig. 2.7  Plato and 
Aristotle
2  Computing in Early Civilizations

25
a particular relationship between the two unrelated terms “Socrates” and 
“Mortal.”
The example above is an example of a valid syllogistic argument. Aristotle stud-
ied the various possible syllogistic arguments and determined those that were valid 
and those that were invalid. There are several candidate relationships that may 
potentially exist between the terms in a premise. These are listed in Table 2.1.
In general, a syllogistic argument will be of the form:
	
S M
M P
S P
x
y
z
	
where x, y, and z may be universal affirmation, universal negation, particular 
affirmation, and particular negation. Syllogistic logic is described in more detail in 
[ORg:20]. Aristotle’s work was highly regarded in classical and medieval times, and 
Kant believed that there was nothing else to invent in Logic.
An early form of propositional logic that was developed by Chrysippus19 in the 
third century BC. Aristotelian logic is of historical interest today, and it has been 
replaced by propositional and predicate logic.
Ptolemy was a second century AD Hellenistic mathematician and cartographer, 
and he created a table of chords (essentially equivalent to a table of values of the 
sine function). He also produced maps of the inhabited world and a geocentric 
model of the universe.
19 Chrysippus was the head of the Stoics in the third century BC.
Table 2.1  Syllogisms: relationship between terms
Relationship
Abbr.
Universal affirmation
Universal negation
Particular affirmation
Particular negation
A
E
I
O
2.4  The Greek and Hellenistic Contribution

26
2.5  The Romans
Rome is said to have been founded20 by Romulus and Remus about 750 BC. Early 
Rome covered a small part of Italy, but it gradually expanded in size and impor-
tance. It destroyed Carthage21 in 146  BC to become the major power in the 
Mediterranean. The Romans colonized the Hellenistic world, and they were influ-
enced by Greek culture and mathematics. Julius Caesar (Fig. 2.9) conquered the 
Gauls in 58 BC.
The Gauls consisted of several disunited Celtic22 tribes. Vercingetorix succeeded 
in uniting them, but he was defeated by at the siege of Alesia in 52 BC.
The Roman number system uses letters to represent numbers (Fig. 2.8) and a 
number consists of a sequence of letters. The evaluation rules specify that if a large 
number follows a smaller number, then the smaller number is subtracted from the 
large: for example, IX represents 9 and XL represents 40. Similarly, if a smaller 
number followed a larger number, they were generally added: for example, MCC 
represents 1200. They had no zero in their system.
The use of Roman numerals was cumbersome, and an abacus was often employed 
for calculation. An abacus consists of several columns in which pebbles are placed. 
Each column represented powers of 10, that is, 100, 101, 102, 103, etc. The column to 
the far right represents one; the column to the left 10; next column to the left 100; 
and so on. Pebbles (calculi) were placed in the columns to represent different 
20 The Aeneid by Virgil suggests that the Romans were descended from survivors of the Trojan War, 
and that Aeneas brought surviving Trojans to Rome after the fall of Troy.
21 Carthage was located in Tunisia, and the wars between Rome and Carthage are known as the 
Punic wars. Hannibal was one of the great Carthaginian military commanders, and during the 
second Punic war, he brought his army to Spain, marched through Spain and crossed the Pyrenees. 
He then marched along southern France and crossed the Alps into Northern Italy. His army also 
consisted of war elephants. Rome finally defeated Carthage and leveled the city.
22 The Celtic period commenced around 1000 BC in Hallstatt (near Salzburg in Austria). The Celts 
were skilled in working with iron and bronze, and they gradually expanded into Europe. They 
eventually reached Britain and Ireland around 600 BC. The early Celtic period was known as the 
“Hallstatt period,” and the later Celtic period is known as the “La Téne” period. The La Téne period 
is characterized by the quality of ornamentation produced. The Celtic museum in Hallein in Austria 
provides valuable information and artifacts on the Celtic period. The Celtic language has similari-
ties to the Irish language. However, the Celts did not employ writing, and the Ogham writing 
developed in Ireland was developed in the early Christian period.
Fig. 2.8  Roman numbers
2  Computing in Early Civilizations

27
numbers: for example, the number represented by an abacus with 4 pebbles on the 
far right; 2 pebbles in the column to the left; and 3 pebbles in the next column to the 
left is 324. The calculations were performed by moving pebbles from column 
to column.
Merchants introduced a set of weights and measures (including the libra for 
weights and the pes for lengths). They developed an early banking system to provide 
loans for business, and commenced minting coins around 290 BC. The Romans also 
made contributions to calendars, and Julius Caesar introduced the Julian calendar in 
45 BC. It has a regular year of 365 days divided into 12 months, and a leap day is 
added to February every 4 years. However, too many leap years are added over time, 
and this led to the introduction of the Gregorian calendar in 1582.
Caesar employed a substitution cipher (Fig. 2.10) on his military campaigns to 
ensure that important messages were communicated safely. This involves the 
substitution of each letter in the plaintext (i.e., the original message) by a letter a 
fixed number of positions down in the alphabet. For example, a shift of 3 positions 
causes the letter B to be replaced by E, the letter C by F, and so on. The Caesar 
cipher is easily broken, as the frequency distribution of letters may be employed to 
determine the mapping. The cipher is defined as follows:
The process of enciphering a message (i.e., plaintext) involves mapping each let-
ter in the plaintext to the corresponding cipher letter. For example, the encryption of 
“summer solstice” involves:
	
Plaintext
Summer Solstice
Cipher Text
vxpphu vrovwleh
:
	
Fig. 2.9  Julius Caesar
2.5  The Romans

28
The decryption involves the reverse operation: that is, for each cipher letter, the 
corresponding plaintext letter is identified from the table.
	
Cipher Text
vxpphu vrovwleh
Plaintext
Summer Solstice
:
	
The encryption may also be done using modular arithmetic. The numbers 0–25 
represent the alphabet letters, and addition (modula 26) is used to perform the 
encryption. The encoding of the plaintext letter x is given by:
	
c
x

 

3
26
mod
	
Similarly, the decoding of a cipher letter represented by the number c is given by:
	
x
c

 

3
26
mod
	
The emperor Augustus23 employed a similar substitution cipher (with a shift key 
of 1). The Caesar cipher remained in use up to the early twentieth century. However, 
by then, frequency analysis techniques were available to break the cipher. The 
Vigenère cipher uses a Caesar cipher with a different shift at each position in the 
text. The value of the shift to be employed with each plaintext letter is defined using 
a repeating keyword.
2.6  Islamic Influence
Islamic mathematics refers to mathematics developed in the Islamic world from the 
birth of Islam in the early seventh century up until the seventeenth century. The 
Islamic world commenced with the prophet Mohammed in Mecca and spread 
throughout the Middle East, North Africa, and Spain. The Golden Age of Islamic 
civilization was from 750  AD to 1250  AD, and during this period, enlightened 
caliphs recognized the value of knowledge and sponsored scholars to come to 
Baghdad to gather and translate the existing world knowledge into Arabic.
23 Augustus was the first Roman emperor and his reign ushered in a period of peace and stability 
following the bitter civil wars. He was the adopted son of Julius Caesar and was called Octavian 
before he became emperor. The earlier civil wars were between Caesar and Pompey, and following 
Caesar’s assassination, civil war broke out between Mark Anthony and Octavian. Octavian 
defeated Anthony and Cleopatra at the battle of Actium in 31 BC.
Fig. 2.10  Caesar Cipher
2  Computing in Early Civilizations

29
This led to the preservation of the Greek texts during the Dark ages in Europe. 
Further, the Islamic cities of Baghdad, Cordoba, and Cairo became key intellectual 
centers, and scholars added to existing knowledge (e.g., in mathematics, astronomy, 
medicine, and philosophy), as well as translating the known knowledge into Arabic.
The Islamic mathematicians and scholars were based in several countries in the 
Middle East, North Africa, and Spain. Early work commenced in Baghdad, and the 
mathematicians were also influenced by the work of Hindu mathematicians, who 
had introduced the decimal system and decimal numerals. Among the well-known 
Islamic scholars are Ibn Al Haytham, a tenth century Iraqi scientist; Mohammed Al 
Khwarizmi (Fig. 2.11), a ninth Persian mathematician; Abd Al Rahman al Sufi, a 
Persian astronomer who discovered the Andromeda galaxy; Ibn Al Nazis, a Syrian 
who did work on circulation in medicine; Averroes, who was an Aristotelian 
philosopher from Cordoba in Spain; Avicenna, who was a Persian philosopher; and 
Omar Khayman, who was a Persian Mathematician and poet.
Many caliphs (Muslim rulers) were enlightened and encouraged scholarship in 
mathematics and science. They set up a center for translation and research in 
Baghdad, and existing Greek texts such as the works of Euclid, Archimedes, 
Apollonius, and Diophantus were translated into Arabic. The Islamic scholar, 
Al-Khwarizmi, made contributions to early classical algebra, and the word algebra 
comes from the Arabic word “al jabr” that appears in a textbook by Al Khwarizmi. 
The origin of the word algorithm is from “Al Khwarizmi.”
Education was important during the Golden Age, and the Al Azhar University in 
Cairo (Fig. 2.12) was established in 970 AD, and the Al-Qarawiyyin University in 
Fez, Morocco, was established in 859 AD. The Islamic World has created beautiful 
architecture and art, including the ninth century Great Mosque of Samarra in Iraq; 
the tenth century Great Mosque of Cordoba; and the eleventh century Alhambra 
palace and fortress complex in Grenada.
Fig. 2.11  Mohammed Al 
Khwarizmi
2.6  Islamic Influence

30
The Moors24 invaded Spain in the eighth century AD, and they ruled large parts 
of the Peninsula for several centuries. Moorish Spain became a center of learning, 
and this led to Islamic and other scholars coming to study at the universities in 
Spain. Many texts on Islamic mathematics were translated from Arabic into Latin, 
and these were invaluable in the renaissance in European learning and mathematics 
from the thirteenth century. The Moorish influence25 in Spain continued until the 
time of the Catholic Monarchs26 in the fifteenth century. Ferdinand and Isabella 
united Spain, defeated the Moors in Andalusia, and expelled them from Spain.
24 The origin of the word “Moor” is from the Greek work μυοροζ meaning very dark. It referred to 
the fact that many of the original Moors who came to Spain were from Egypt, Tunisia, and other 
parts of North Africa.
25 The Moorish influence includes the construction of various castles (alcazar), fortresses (alcaz-
aba), and mosques. One of the most striking Islamic sites in Spain is the palace of Alhambra in 
Granada, and it represents the zenith of Islamic art.
26 The Catholic Monarchs refer to Ferdinand of Aragon and Isabella of Castile who married in 
1469. They captured Granada (the last remaining part of Spain controlled by the Moors) in 1492.
Fig. 2.12  Al Azhar University, Cairo
2  Computing in Early Civilizations

31
The Islamic contribution to algebra was an advance on the achievements of the 
Greeks. They developed a broader theory that treated rational and irrational num-
bers as algebraic objects, and moved away from the Greek concept of mathematics 
as being essentially Geometry. Later, Islamic scholars applied algebra to arithmetic 
and geometry and studied curves using equations. This included contributions to 
reduce geometric problems such as duplicating the cube to algebraic problems. 
Eventually, this led to the use of symbols in the fifteenth century such as:
	
x x
x
n
m
m n
.
.

 	
The poet Omar Khayman was also a mathematician who did work on the clas-
sification of cubic equations with geometric solutions. Other scholars made contri-
butions to the theory of numbers: for example, a theorem that allows pairs of 
amicable numbers to be found. Amicable numbers are two numbers such that each 
is the sum of the proper divisors of the other. They were aware of Wilson’s theory in 
number theory: that is, for p prime then p divides (p – 1)! +1.
The Islamic world was tolerant of other religious belief systems during the 
Golden Age, and there was freedom of expression provided that it did not infringe 
on the rights of others. It began to come to an end following the Mongol invasion 
and sack of Baghdad in the late 1250s and the Crusades. It continued to some extent 
until the conquest by Ferdinand and Isabella of Andalusia in the late fifteenth 
century.
2.7  Chinese and Indian Mathematics
The development of mathematics commenced in China about 1000 BC, and it was 
independent of developments in other countries. The emphasis was on problem 
solving rather than on conducting formal proofs. It was concerned with finding the 
solution to practical problems such as the calendar, the prediction of the positions of 
the heavenly bodies, land measurement, conducting trade, and the calculation 
of taxes.
The Chinese employed counting boards as mechanical aids for calculation from 
the fourth century BC. Counting boards are similar to abaci and are usually made of 
wood or metal, and contained carved grooves between which beads, pebbles, or 
metal discs were moved. The abacus is a device, usually of wood having a frame 
that holds rods with freely sliding beads mounted on them. It is used as a tool to 
assist calculation, and it is useful for keeping track of the sums, the carry, and so on 
of calculations.
2.7  Chinese and Indian Mathematics

32
Early Chinese mathematics was written on bamboo strips and included work 
on arithmetic and astronomy. The Chinese method of learning and calculation in 
mathematics was learning by analogy. This involves a person acquiring knowl-
edge from observation of how a problem is solved, and then applying this knowl-
edge for problem solving to similar kinds of problems.
They had their version of Pythagoras’s theorem and applied it to practical prob-
lems. They were familiar with the Chinese remainder theorem, the formula for find-
ing the area of a triangle, as well as showing how polynomial equations (up to degree 
ten) could be solved. Other Chinese mathematicians showed how geometric prob-
lems could be solved by algebra, how roots of polynomials could be solved, how 
quadratic and simultaneous equations could be solved, and how the area of various 
geometric shapes such as rectangles, trapezia, and circles could be computed. 
Chinese mathematicians were familiar with the formula to calculate the volume of a 
sphere. The best approximation that the Chinese had of π was 3.14159, and this was 
obtained by approximations from inscribing regular polygons with 3 × 2n sides in 
a circle.
The Chinese made contributions to number theory including the summation 
of arithmetic series and solving simultaneous congruences. The Chinese remain-
der theorem deals with finding the solutions to a set of simultaneous congru-
ences in modular arithmetic. Chinese astronomers made accurate observations, 
which were used to produce a new calendar in the sixth century. This was known 
as the Taming Calendar and it was based on a cycle of 391 years.
Indian mathematicians have made important contributions such as the develop-
ment of the decimal notation for numbers that is now used throughout the world. 
This was developed in India sometime between 400 BC and 400 AD. Indian math-
ematicians also invented zero and negative numbers, and also did early work on the 
trigonometric functions of sine and cosine. The knowledge of the decimal numerals 
reached Europe through Arabic mathematicians, and the resulting system is known 
as the Hindu-Arabic numeral system.
The Shulba Sutras is a Hindu text that documents Indian mathematics, and it 
dates from about 400 BC. It includes a summary of early Hindu trigonometry and 
their rules. The Indians were familiar with the statement and proof of Pythagoras’s 
theorem, rational numbers, quadratic equations, as well as the calculation of the 
square root of 2 to five decimal places.
2  Computing in Early Civilizations

33
2.8  Review Questions
2.9  Summary
The last decades of the twentieth century have witnessed a proliferation of high-tech 
computers, mobile phones, and information technology. Software is now pervasive 
and technology has become an integral part of the western world, with the pace of 
change and innovation quite extraordinary. It has led to increases in industrial pro-
ductivity and potentially allows humans the freedom to engage in more creative and 
rewarding tasks.
This chapter considered the contributions of early civilizations to computing, 
including contributions of the Babylonians, the Egyptians, the Greeks, and the 
Romans and Islamic scholars.
The Babylonian civilization flourished from about 2000 BC, and they produced 
clay cuneiform tablets containing mathematical texts. These included tables for 
multiplication, division, squares, and square roots, as well as the calculation of area 
and the solution of linear and quadratic equations.
The Egyptian civilization developed along the Nile from about 4000 BC, and 
they used mathematics for practical problem solving. The Greeks made major 
contributions to western civilization, with Euclid developing a systematic treatment 
of geometry. Aristotle’s syllogistic logic remained in use until the development of 
propositional and predicate logic in the late nineteenth century.
The Islamic contribution helped to preserve western knowledge during the dark 
ages in Europe. Islamic scholars in Baghdad, Cairo, and Cordoba translated Greek 
texts into Arabic. They also added to existing knowledge in mathematics, science, 
astronomy, and medicine.
	1.	
Discuss the strengths and weaknesses of the various number systems.
	2.	
Describe ciphers used during the Roman civilization and write a pro-
gram to implement one of these.
	3.	
Discuss the nature of an algorithm and its importance in computing.
	4.	
Discuss the working of an abacus and its application to calculation.
	5.	
What are the differences between syllogistic logic and propositional 
and predicate logic??
2.9  Summary

35
© The Author(s), under exclusive license to Springer Nature 
Switzerland AG 2021
G. O’Regan, A Brief History of Computing, 
https://doi.org/10.1007/978-3-030-66599-9_3
Chapter 3
Foundations of Computing
3.1  Introduction
This chapter considers important foundational work done by Willhelm Leibniz, 
Charles Babbage, George Boole, Lady Ada Lovelace, and Claude Shannon. Leibniz 
was a seventeenth-century German mathematician, philosopher, and inventor, and 
he is recognized (with Issac Newton) as the inventor of Calculus, He developed the 
Step Reckoner calculating machine that could perform all four basic arithmetic 
operations (i.e., addition, subtraction, multiplication, and division), and he also 
invented the binary number system (which is used extensively in the computer field).
Boole and Babbage are considered grandfathers of the computing field, with 
Babbage’s Analytic Engine providing a vision of a mechanical computer, and 
Boole’s logic providing the foundation for modern digital computers.
Babbage was a nineteenth-century scientist and inventor who did pioneering 
work on calculating machines. He invented the Difference Engine (a sophisticated 
calculator that could be used to produce mathematical tables), and he also designed 
the Analytic Engine (the design of the world’s first mechanical computer). The 
design of the Analytic Engine included a processor, memory, and a way to input 
information and output results.
Lady Ada Lovelace was introduced into Babbage’s ideas on the analytic engine 
at a dinner party. She was fascinated and predicted that such a machine could be 
used to compose music, produce graphics, as well as solving mathematical and 
scientific problems. She explained how the Analytic Engine could be programmed, 
and she wrote what is considered the first computer program.
Key Topics
Leibniz
Binary numbers
Step Reckoner
Babbage
Difference engine
Analytic engine
Lovelace
Boole
Shannon
Switching circuits

36
Boole was a nineteenth-century English mathematician who made important 
contributions to mathematics, probability theory, and logic. Boole’s logic provides 
the foundation for digital computers.
Shannon was the first person to apply Boole’s logic to switching theory, and he 
showed that Boole’s logic could simplify the design of circuits and telephone 
routing switches. It provides the perfect mathematical model for switching theory 
and for the subsequent design of digital circuits and computers.
3.2  Step Reckoner Calculating Machine
Leibniz (Fig. 3.1) was a German philosopher, mathematician, and inventor in the 
field of mechanical calculators. He developed the binary number system used in 
digital computers, and he invented the Calculus independently of Sir Issac Newton. 
He became familiar with Pascal’s calculating machine, the Pascaline, while in Paris 
in the early 1670s. He recognized its limitations as the machine could perform 
addition and subtraction operations only.
He designed and developed a calculating machine that could perform addition, 
subtraction, multiplication, division, and the extraction of roots. He commenced 
work on the machine in 1672, and the machine was completed in 1694. It was the 
first calculator that could perform all four arithmetic operations, and Leibniz’s 
machine was called the Step Reckoner (Fig. 3.2). It allowed the common arithmetic 
operations to be carried out mechanically.
Fig. 3.1  Wilhelm 
Gottfried Leibniz
3  Foundations of Computing

37
The operating mechanism used in his calculating machine was based on a counting 
device called the stepped cylinder or “Leibniz wheel.” This mechanism allowed a 
gear to represent a single decimal digit from zero to nine in just one revolution, and 
this remained the dominant approach to the design of calculating machines for the 
next 200 years. It was essentially a counting device consisting of a set of wheels that 
were used in the calculation. The Step Reckoner consisted of an accumulator that 
could hold 16 decimal digits and an 8-digit input section. The eight dials at the front 
of the machine set the operand number, which was then employed in the calculation.
The machine performed multiplication by repeated addition and division by repeated 
subtraction. The basic operation is to add or subtract the operand from the accumulator 
as many times as desired. The machine could add or subtract an 8-digit number to the 
16-digit accumulator to form a 16-digit result. It could multiply two 8-digit numbers to 
give a 16-digit result, and it could divide a 16-bit number by an 8-digit number. Addition 
and subtraction are performed in a single step, with the operating crank turned in the 
opposite direction for subtraction. The result is stored in the accumulator.
Fig. 3.2  Replica of Step Reckoner at Technische Sammlungen Museum, Dresden
3.2  Step Reckoner Calculating Machine

38
3.3  Binary Numbers
Arithmetic has traditionally been done using the decimal notation,1 and Leibniz was 
one of the first to recognize the potential of the binary number system. This system 
uses just two digits namely “0” and “1,” with the number two represented by 10; the 
number four by 100; and so on. Leibniz described the binary system in Explication 
de l'Arithmétique Binaire, which was published in 1703 [Lei:03]. A table of values 
for the first fifteen binary numbers is given in Table 3.1.
Leibniz’s 1703 paper describes how binary numbers may be added, subtracted, 
multiplied, and divided, and he was an advocate of their use. The key advantage of 
the use of binary notation is in digital computers, where a binary digit may be 
implemented by an on/off switch, with the digit 1 representing that the switch is on, 
and the digit 0 representing that the switch is off.
The use of binary arithmetic allows more complex mathematical operations to be 
performed by relay circuits, and Boole’s logic (described in Sect. 3.6) is the perfect 
model for simplifying such circuits, and is the foundation underlying digital 
computing.
The binary number system (base 2) is a positional number system, which uses 
two binary digits 0 and 1, and an example binary number is 1001.012 which 
represents 1 × 23 + 0 × 22 + 0 × 21 + 1 × 20 + 0 × 2−1 + 1 × 2−2 = 1 × 23 + 1 × 20 + 
1 × 2−2 = 8 + 1 + 0.25 = 9.25.
The decimal system (base 10) is familiar from daily use, and there are algorithms 
to convert numbers from decimal to binary and vice versa. For example, to convert 
the decimal number 25 to its binary representation 110012 we proceed as in Fig. 3.3.
The base 2 is written on the left and the number to be converted to binary is 
placed in the first column. At each stage in the conversion, the number in the first 
column is divided by 2 to form the quotient and remainder, which are then placed 
on the next row. For the first step, the quotient when 25 is divided by 2 is 12 and the 
remainder is 1. The process continues until the quotient is 0, and the binary repre-
sentation result is then obtained by reading the second column from the bottom up. 
Thus, we see that the binary representation of 25 is 110012.
Similarly, there are algorithms to convert decimal fractions to binary representa-
tion (to a defined number of binary digits as the representation may not terminate), 
1 The segadecimal (or base-60) system was employed by the Babylonians c. 2000 BC. Indian and 
Arabic mathematicians developed the decimal system between 800 and 900 AD.
Table 3.1  Binary number system
Binary
Dec.
Binary
Dec.
Binary
Dec.
Binary
Dec.
0000
0
0100
4
1000
8
1100
12
0001
1
0101
5
1001
9
1101
13
0010
2
0110
6
1010
10
1110
14
0011
3
0111
7
1011
11
1111
15
3  Foundations of Computing

39
and the conversion of a number that contains an integer part and a fractional part 
involves converting each part separately and then combining them.
The octal (base 8) and hexadecimal (base 16) are often used in computing, as the 
bases 2, 8, and 16 are related bases and are easy to convert between. For example, 
to convert between binary and octal involves grouping the binary bits into groups of 
three on either side of the point. Each set of 3 bits corresponds to one digit in the 
octal representation. Similarly, the conversion between binary and hexadecimal 
involves grouping into sets of 4 binary digits on either side of the point. The 
conversion from octal to binary or hexadecimal to binary is equally simple, and 
involves replacing the octal (or hexadecimal) digit with the 3-bit (or 4-bit) binary 
representation.
Numbers are represented in a digital computer as sequences of bits of fixed 
length (e.g., 16 bits, 32 bits). There is a difference in the way in which integers and 
real numbers are represented, with the representation of real numbers being more 
complicated.
An integer number is represented by a sequence (usually 2 or 4) bytes where 
each byte is 8 bits. For example, a 2-byte integer has 16 bits with the first bit used 
as the sign bit (the sign is 1 for negative numbers and 0 for positive integers), and 
the remaining 15 bits represent the number. This means that two bytes may be used 
to represent all integer numbers between -32768 and 32767. A positive number is 
represented by the normal binary representation discussed earlier, whereas a 
negative number is represented using 2’s complement of the original number (i.e., 0 
changes to 1 and 1 changes to 0 and the sign bit is 1). All the standard arithmetic 
operations may then be carried out (using modulo 2 arithmetic).
The representation of floating-point real numbers is more complicated, and a real 
number is represented to a fixed number of significant digits (the significand) and 
scaled using an exponent in some base (usually 2). That is, the number is represented 
(approximated as):
	
significand
baseexponent
´
	
The significand (also called mantissa) and exponent have a sign bit. For example, 
in simple floating-point representation (4 bytes) the mantissa is generally 24 bits 
and the exponent 8 bits, whereas for double precision (8 bytes) the mantissa is 
2
2 5
1 2
6
3
1
0
0
0
1
1
1
Fig 3.3  Decimal to binary conversion
3.3  Binary Numbers

40
generally 53 bits and the exponent 11 bits. There is an IEEE standard for floating-­
point numbers (IEEE 754).
3.4  The Difference Engine
Babbage is considered (along with Boole) to be one of the grandfathers of the com-
puting field. He made contributions to several areas including mathematics, statis-
tics, astronomy, calculating machines, philosophy, railways, and lighthouses. He 
founded the British Statistical Society and the Royal Astronomical Society 
(Fig. 3.4).
Babbage was interested in accurate mathematical tables for scientific work. He 
was aware of the high error rate in the existing tables due to the human error intro-
duced during calculation, and he became interested in finding a mechanical method 
to perform calculation to eliminate these errors. He planned to develop a more 
advanced machine than the existing Pascaline and the Step Reckoner (developed by 
Pascal and Leibniz, respectively), and his goal was to develop a machine that could 
compute polynomial functions.
He designed the Difference Engine (No. 1) in 1821 for the production of math-
ematical tables. This was essentially a mechanical calculator (analogous to modern 
electronic calculators), and it was designed to compute polynomial functions of 
degree 4 on 15-digit numbers. It could also compute logarithmic and trigonometric 
functions such as sine or cosine (as these may be approximated by polynomials).2
2 The power series expansion of the sine function is given by Sin(x) = x − x3/3! + x5/5! − x7/7! + ... 
The power series expansion for the cosine function is given by Cos(x) = 1 − x2/2! + x4/4! − x6/6! + 
... Functions may be approximated by interpolation and the approximation of a function by a poly-
nomial of degree n requires n + 1 points on the curve for the interpolation. That is, the curve formed 
by the polynomial of degree n that passes through the n + 1 points of the function to be approxi-
mated is an approximation to the function. The error function also needs to be considered.
Fig 3.4  Charles Babbage
3  Foundations of Computing

41
The accurate approximation of trigonometric, exponential, and logarithmic func-
tions by polynomials depends on the degree of the polynomials, the number of deci-
mal digits that it is being approximated to, and on the error function. A higher 
degree polynomial is generally able to approximate the function more accurately.
Babbage produced prototypes for parts of the Difference Engine, but he never 
actually completed the machine. The Swedish engineers, George and Edward 
Schuetz, built the first working Difference Engine (based on Babbage’s design) in 
1853 with funding from the Swedish government. The Schuetz machine could 
compute polynomials of degree 4 on 15-digit numbers, and the 3rd Scheutz 
Difference Engine is on display at the Science Museum in London.
It was the first machine to compute and print mathematical tables mechanically. 
The machine was accurate, and it showed the potential of mechanical machines as a 
tool for scientists and engineers.
The machine is unable to perform multiplication or division directly. Once the 
initial value of the polynomial and its derivative are calculated for some value of x, 
the difference engine may calculate any number of nearby values using the numeri-
cal method of finite differences. This method replaces computational intensive tasks 
involving multiplication or division, by an equivalent computation that just involves 
addition or subtraction.
The British government canceled Babbage’s project in 1842. He designed an 
improved difference engine No.2 (Fig. 3.5) in 1849. It could operate on 7th order 
differences (i.e., polynomials of order 7) and 31-digit numbers. The machine con-
sisted of eight columns with each column consisting of 31 wheels. However, it was 
over 150 years later before it was built (in 1991) to mark the 200th anniversary of 
his birth. The Science Museum in London also built the printer that Babbage 
Fig. 3.5  Difference engine No. 2. Photo public domain
3.4  The Difference Engine

42
designed, and both the machine and the printer worked correctly according to 
Babbage’s design (after a little debugging).
3.5  The Analytic Engine – Vision of a Computer
The Difference Engine was designed to produce mathematical tables, but it required 
human intervention to perform the calculations. Babbage proposed a revolutionary 
solution to its limitations in the 1830s with his vision of a mechanical computer. His 
plan was to construct a new machine that would be capable of executing all tasks 
that may be expressed in algebraic notation. The Analytic Engine was designed in 
1834 as the world’s first mechanical computer [Lov:42]. The machine included a 
processor, memory, and a way to input information and output results. Babbage’s 
vision consisted of two parts (Table 3.2):
Babbage intended that the operation of the Analytic Engine would be analogous 
to the operation of the Jacquard loom.3 The latter is capable of weaving (i.e., execut-
ing on the loom) a design pattern that has been prepared by a team of skilled artists. 
The design pattern is represented by a set of cards with punched holes, where each 
card represents a row in the design. The cards are then ordered; placed in the loom; 
and the loom produces the exact pattern.
The use of the punched cards in the Analytic Engine allowed the formulae to be 
manipulated in a manner dictated by the programmer. The cards commanded the 
analytic engine to perform various operations and to return a result. Babbage distin-
guished between two types of punched cards:
–– Operation cards
–– Variable cards
Operation cards are used to define the operations to be performed, whereas the 
variable cards define the variables or data that the operations are performed upon. 
His planned use of punched cards to store programs in the Analytic Engine is 
3 The Jacquard loom was invented by Joseph Jacquard in 1801. It is a mechanical loom which used 
the holes in punch cards to control the weaving of patterns in a fabric. The use of punched cards 
allowed complex designs to be woven from the pattern defined on the punched cards. Each punched 
card corresponds to one row of the design and the cards were appropriately ordered. It was very 
easy to change the pattern of the fabric being weaved on the loom, as this simply involved chang-
ing cards.
Table 3.2  Analytic engine
Part
Function
Store This contains the variables to be operated upon as well as all those quantities, which have 
arisen from the result of intermediate operations
Mill
The mill is essentially the processor of the machine into which the quantities about to be 
operated upon are brought
3  Foundations of Computing

43
similar to the idea of a stored computer program in von Neumann architecture. 
However, Babbage’s idea of using punched cards to represent machine instructions 
and data was over 100 years before digital computers. Babbage’s Analytic Engine is 
therefore an important milestone in the history of computing.
Babbage intended that the program be stored on read-only memory using punch 
cards, and that the input and output would be carried out using punch cards. He 
intended that the machine would be able to store numbers and intermediate results 
in memory that could then be processed. There would be several punch card readers 
in the machine for programs and data. He envisioned that the machine would be able 
to perform conditional jumps as well as parallel processing where several calcula-
tions could be performed at once.
Babbage wrote several sample programs for the analytic engine including pro-
grams for polynomials, Gaussian elimination, and Bernouilli numbers. However, 
the machine was never built, as Babbage was unable to secure funding from the 
British Government. Babbage did build a small part of it before his death in 1871, 
and his son later constructed a part of the mill and the printing apparatus c.1910. 
There is a campaign (Plan 28) to raise funds with a view to constructing a physical 
analytic machine in time for the 200th anniversary of the design of the machine.
3.5.1  Applications of Analytic Engine
Lady Augusta Ada Lovelace (nee Byron)4 (Fig. 3.6) was a mathematician who col-
laborated with Babbage on applications for the analytic engine. She is considered 
the world’s first programmer, and the Ada programming language is named in 
her honor.
She was introduced to Babbage at a dinner party in 1833, and she visited 
Babbage’s studio in London, where the prototype Difference Engine was on display. 
She recognized the beauty of its invention, and she was fascinated by the idea of the 
analytic engine. She communicated regularly with Babbage with ideas on its 
applications.
Lovelace produced an annotated translation of Menabrea’s “Notions sur la 
machine analytique de Charles Babbage” [Lov:42]. She added copious notes to the 
translation,5 which were about three times the length of the original memoir, and 
considered many of the difficult and abstract questions connected with the subject. 
These notes are regarded as a description of a computer and software.
She explained in the notes how the Analytic Engine could be programmed, and 
wrote what is considered to be the first computer program. This was a detailed plan 
for how the analytic engine would calculate Bernoulli numbers. Lady Ada Lovelace 
4 Lady Ada Lovelace was the daughter of the poet Lord Byron.
5 There is some controversy as to whether this was entirely her own work or a joint effort by 
Lovelace and Babbage.
3.5  The Analytic Engine – Vision of a Computer

44
is therefore considered to be the first computer programmer, and Babbage called her 
the “enchantress of numbers.”
She saw the potential of the analytic engine to fields other than mathematics. She 
predicted that the machine could be used to compose music, produce graphics, as 
well as solving mathematical and scientific problems. She speculated that the 
machine might act on other things apart from numbers, and be able to manipulate 
symbols according to rules. In this way, a number could represent an entity other 
than a quantity.
3.6  Boole’s Symbolic Logic
George Boole (Fig. 3.7) was born in Lincoln, England in 1815. His father (a cobbler 
who was interested in mathematics and optical instruments) taught him mathematics, 
and showed him how to make optical instruments. Boole inherited his father’s 
interest in knowledge, and he was self-taught in mathematics and Greek. He taught 
at various schools near Lincoln, and he developed his mathematical knowledge by 
working his way through Newton’s Principia, as well as applying himself to the 
work of mathematicians such as Laplace and Lagrange.
He published regular papers from his early twenties, and these included contribu-
tions to probability theory, differential equations, and finite differences. He devel-
oped Boolean algebra, which is the foundation for modern computing, and he is 
considered (along with Babbage) to be one of the grandfathers of computing. His 
work was theoretical, and he never actually built a computer or calculating machine. 
Fig. 3.6  Lady Ada 
Lovelace
3  Foundations of Computing

45
However, Boole’s symbolic logic was the perfect mathematical model for switching 
theory and for the design of digital circuits.
Boole became interested in formulating a calculus of reasoning, and he pub-
lished “Mathematical Analysis of Logic” in 1847 [Boo:48]. This work developed 
novel ideas on a logical method, and he argued that logic should be considered as a 
separate branch of mathematics, rather than as a part of philosophy. He argued that 
there are mathematical laws to express the operation of reasoning in the human 
mind, and he showed how Aristotle’s syllogistic logic could be reduced to a set of 
algebraic equations. He corresponded regularly on logic with Augustus De Morgan.6
His paper on logic introduced two quantities “0” and “1.” He used the quantity 1 
to represent the universe of thinkable objects (i.e., the universal set), and the quan-
tity 0 represents the absence of any objects (i.e., the empty set). He then employed 
symbols such as x, y, z, etc., to represent collections or classes of objects given by 
the meaning attached to adjectives and nouns. Next, he introduced three operators 
(+, −, and ×) that combined classes of objects.
The expression xy (i.e., x multiplied by y or x × y) combines the two classes x, y 
to form the new class xy (i.e., the class whose objects satisfy the two meanings rep-
resented by class x and class y). Similarly, the expression x + y combines the two 
classes x, y to form the new class x + y (that satisfies either the meaning represented 
by class x or class y). The expression x - y combines the two classes x, y to form the 
new class x − y. This represents the class (that satisfies the meaning represented by 
class x but not class y. The expression (1 – x) represents objects that do not have the 
attribute that represents class x.
Thus, if x = black and y = sheep, then xy represents the class of black sheep. 
Similarly, (1 − x) would represent the class obtained by the operation of selecting 
all things in the world except black things; x (1 − y) represents the class of all things 
6 De-Morgan was a nineteenth-century British mathematician based at University College London. 
De-Morgan’s laws in Set Theory and Logic state that: (A ∪ B)c = Ac ∩ Bc and ¬ (A ∨ B) ≡ ¬A ∧ ¬B.
Fig. 3.7  George Boole
3.6  Boole’s Symbolic Logic

46
that are black but not sheep; and (1 − x) (1 − y) would give us all things that are 
neither sheep nor black.
He showed that these symbols obeyed a rich collection of algebraic laws and 
could be added, multiplied, etc., in a manner that is like real numbers. These symbols 
may be used to reduce propositions to equations, and algebraic rules may be 
employed to solve the equations. The rules include:
1.
x + 0 = x
(Additive identity)
2.
x + (y + z) = (x + y) + z
(Associative)
3.
x + y = y + x
(Commutative)
4.
x + (1 − x) = 1
5.
x 1 = x
(Multiplicative identity)
6.
x 0 = 0
7.
x + 1 = 1
8.
xy = yx
(Commutative)
9.
x(yz) = (xy)z
(Associative)
10.
x(y + z) = xy + xz
(Distributive)
11.
x(y − z) = xy − xz
(Distributive)
12.
x2 = x
(Idempotent)
These operations are similar to the modern laws of set theory with the set union 
operation represented by “+,” and the set intersection operation is represented by 
multiplication. The universal set is represented by “1” and the empty by “0.” The 
associative and distributive laws hold. Finally, the set complement operation is 
given by (1 − x).
He applied the symbols to encode Aristotle’s Syllogistic Logic, and he showed 
how the syllogisms could be reduced to equations. For example, the syllogism “All 
X’s are Y’s” may be expressed algebraically as x(1 − y) = 0. This allowed conclusions 
to be derived from premises by eliminating the middle term in the syllogism. He 
refined his ideas on logic further in “An Investigation of the Laws of Thought” which 
was published in 1854 [Boo:58]. This book aimed to identify the fundamental laws 
underlying reasoning in the human mind and to give expression to these laws in the 
symbolic language of a calculus.
He considered the equation x2 = x to be a fundamental law of thought. It allows 
the principle of contradiction to be expressed (i.e., for an entity to possess an attri-
bute and at the same time not to possess it):
For example, if x represents the class of horses then (1 – x) represents the class 
of “not-horses.” The product of two classes represents a class whose members are 
common to both classes. Hence, x (1 – x) represents the class whose members are at 
once both horses and “not-horses,” and the equation x (1 – x) = 0 expresses that fact 
that there is no such class. That is, it is the empty set.
3  Foundations of Computing

47
Boole contributed to other areas in mathematics including differential equations, 
finite differences,7 and to the development of probability theory. The Irish 
mathematician, Des McHale, has written an interesting and authoritative biography 
of Boole [McH:85]. Boole’s logic appeared to have no practical use, but this changed 
with Claude Shannon’s 1937 Master’s Thesis, which showed its applicability to 
switching theory and to the design of digital circuits.
3.6.1  Switching Circuits and Boolean Algebra
Claude Shannon’s Master’s Thesis showed that Boole’s algebra provided the perfect 
mathematical model for switching theory and for the design of digital circuits. It 
may be used to optimize the design of systems of electromechanical relays, and 
circuits with relays solve Boolean algebra problems. The use of switches to represent 
binary values is the foundation of modern computing, and using the properties of 
electrical switches to process logic is the basic concept that underlies all modern 
electronic digital computers. Boolean logical operations may be implemented by 
electronic AND, OR, and NOT gates, and more complex circuits (e.g., arithmetic) 
may be designed from these fundamental building blocks.
Modern electronic computers use billions of transistors that act as switches and 
can change state rapidly. A high voltage represents the binary value 1 with a low 
voltage representing the binary value 0. A silicon chip may contain billions of tiny 
electronic switches arranged into logical gates. The basic logic gates are AND, OR, 
and NOT. These gates may be combined in various ways to allow the computer to 
perform more complex tasks such as binary arithmetic. Each gate has binary inputs 
and outputs.
The example in Fig. 3.8 is that of an “AND” gate which produces the binary 
value 1 as output only if both inputs are 1. Otherwise, the result will be the binary 
value 0. Figure 3.9 shows an “OR” gate which produces the binary value 1 as output 
if any of its inputs is 1. Otherwise, it will produce the binary value 0.
Finally, a NOT gate (Fig. 3.10) accepts only a single input which it inverts. That 
is if the input is “1” the value “0” is produced and vice versa.
The logic gates may be combined to form more complex circuits. The example 
in Fig. 3.11 is that of a half adder of 1 + 0. The inputs to the top OR gate are 1 and 
0 which yields the result of 1. The inputs to the bottom AND gate are 1 and 0 which 
yields the result 0, which is then inverted through the NOT gate to yield binary 1. 
Finally, the last AND gate receives two 1’s as input and the binary value 1 is the 
result of the addition. The half-adder computes the addition of two arbitrary binary 
digits, but it does not calculate the carry. It may be extended to a full adder that 
provides a carry for addition.
7 Finite Differences are a numerical method used in solving differential equations.
3.6  Boole’s Symbolic Logic

48
1
1
1
O R
1
0
1
O R
0
0
0
O R
Fig. 3.9  Binary OR 
operation
1
0
1
0
Fig 3.10  NOT operation
A N D
O R
1
0
A N D
1
Fig 3.11  Half-adder
1
0
1
0
0
1
1
0
0
Fig. 3.8  Binary AND 
operation
3  Foundations of Computing

49
3.7  Application of Boole’s Logic to Digital Computing
Claude Shannon (Fig. 3.12) was the first person8 to see the applicability of Boole’s 
algebra to simplify the design of circuits and telephone routing switches. He showed 
that Boole’s symbolic logic was the perfect mathematical model for switching the-
ory and for the subsequent design of digital circuits and computers.
His influential Master’s Thesis is a key milestone in computing, and it shows how 
to lay out circuits according to Boolean principles. It provides the theoretical foun-
dation of switching circuits, and his insight of using the properties of electrical 
switches to do Boolean logic is the basic concept that underlies all electronic digital 
computers.
Shannon realized that you could combine switches in circuits in such a manner 
as to carry out symbolic logic operations. This allowed binary arithmetic and more 
complex mathematical operations to be performed by relay circuits. He designed a 
circuit, which could add binary numbers, and he later designed circuits that could 
make comparisons and thus capable of performing a conditional statement. This 
was the birth of digital logic and the digital computing age.
Vannevar Bush [ORg:13] was Shannon’s supervisor at MIT, and Shannon’s ini-
tial work was to improve Bush’s Differential Analyzer. This machine had a compli-
cated control circuit that was composed of one hundred switches that could be 
automatically opened and closed by an electromagnet. Shannon’s insight was his 
realization that an electronic circuit is similar to Boolean algebra, and he showed 
8 Victor Shestakov at Moscow State University also proposed a theory of electric switches based on 
Boolean algebra (published in Russian in 1941 whereas Shannon’s were published in 1937).
Fig 3.12  Claude Shannon
3.7  Application of Boole’s Logic to Digital Computing

50
how Boolean algebra could be employed to optimize the design of systems of elec-
tromechanical relays used in the analog computer. He also realized that circuits with 
relays could solve Boolean algebra problems.
His Master’s thesis “A Symbolic Analysis of Relay and Switching Circuits” 
[Sha:37] showed that the binary digits can be represented by electrical switches. 
This allowed binary arithmetic and more complex mathematical operations to be 
performed by relay circuits, and provided electronics engineers with the mathemati-
cal tool to design digital electronic circuits.
The design of circuits and telephone routing switches may be simplified with 
Boole’s symbolic algebra. Shannon’s Master’s thesis became the foundation for the 
practical design of digital circuits. These circuits are fundamental to the operation 
of modern computers and telecommunication systems, and Shannon’s insight of 
using the properties of electrical switches to do Boolean logic is the basic concept 
that underlies all electronic digital computers.
3.8  Review Questions
3.9  Summary
This chapter considered foundational work done by Leibniz, Babbage, Boole, Ada 
Lovelace, and Shannon. Leibniz developed the Step Reckoner calculating machine 
and the binary number system.
Babbage did pioneering work on calculating machines including the Difference 
Engine (a calculator to produce mathematical tables), and he also designed the 
Analytic Engine (the world’s first mechanical computer). Lady Ada Lovelace 
predicted that such a machine could be used to compose music, produce graphics, 
as well as solving mathematical and scientific problems.
	1.	 Explain the significance of binary numbers in the computing field.
	2.	 Explain the importance of Shannon’s Master Thesis.
	3.	 Explain the significance of the Analytic Engine.
	4.	 Explain why Ada Lovelace is considered the world’s first programmer.
	5.	 Explain the significance of Boole to the computing field.
	6.	 Explain the significance of Babbage to the computing field.
	7.	 Explain the significance of Leibniz to the computing field.
3  Foundations of Computing

51
Boole was a nineteenth-century English mathematician who made important 
contributions to mathematics, and his symbolic logic provided the foundation for 
digital computers. Shannon was a twentieth-century American mathematician and 
engineer, and he showed that Boole’s symbolic logic provided the perfect mathe-
matical model for switching theory, and for the subsequent design of digital circuits 
and computer.
3.9  Summary

53
© The Author(s), under exclusive license to Springer Nature 
Switzerland AG 2021
G. O’Regan, A Brief History of Computing, 
https://doi.org/10.1007/978-3-030-66599-9_4
Chapter 4
The First Digital Computers
4.1  Introduction
This chapter considers some of the early computers developed in the United States, 
Britain, and Germany. The Second World War motivated researchers to investigate 
faster ways to perform calculation to solve practical problems. This led to research 
into the development of digital computers to determine if they could provide faster 
methods of computation.
The early computers were mainly large bulky machines consisting of several 
thousand vacuum tubes. A computer often took up the space of a large room, and it 
was slow and unreliable.
The early computers considered in this chapter include the Harvard Mark I 
designed and developed by Howard Aiken and IBM. This was a large electrome-
chanical calculator that could perform mathematical calculations quickly. John 
Atanasoff and Clifford Berry designed and developed the Atanasoff-Berry (ABC) 
computer, and this machine was designed to solve a set of linear equations using 
Gaussian elimination. John Mauchly and Presper Eckert designed the ENIAC and 
EDVAC computers. ENIAC was a fixed-program computer that needed to be physi-
cally rewired to solve different problems, but the EDVAC computer implemented 
the concept of a stored program. This meant that the program instructions could be 
stored in memory, and that all that was required to carry out a new task was to load 
a new program into memory.
The team at Bletchley Park in England designed and developed the COLOSSUS 
computer as part of their code-breaking work during the Second World War. This 
allowed them to crack the German Lorenz codes, and to provide important military 
intelligence for the D-Day landings of 1944.
Key Topics
Harvard mark I
ABC computer
ENIAC
EDVAC
Colossus
Zuse’s machines
Manchester mark I

54
Konrad Zuse designed and developed the Z1, Z2, and Z3 machines in Germany. 
The Z3 was operational in 1941, and it was the world’s first programmable computer.
4.2  Harvard Mark I
Howard Aiken (Fig. 4.1) made several important contributions to the early comput-
ing field. He showed that a large calculating machine could be built that would 
provide speedy solutions to mathematical problems.
His idea was to construct an electromechanical machine that could perform 
mathematical operations quickly and efficiently, and the machine would need to be 
able to handle positive and negative numbers, scientific functions such as loga-
rithms, and be able to work with minimal human intervention.
He discussed the idea with colleagues and IBM, and he was successful in obtain-
ing IBM funding to build the machine. The machine was built at the IBM laborato-
ries at Endicott with several IBM engineers involved in its construction. The 
construction took 7 years, and it was completed in 1943.
The machine became known as the Harvard Mark I (also known as the IBM 
Automatic Sequence Controlled Calculator (ASCC)). Aiken was influenced by 
Babbage’s ideas on the design of the Difference Engine and the Analytic Engine.
IBM presented the machine to Harvard University in 1944, and the ASCC was 
essentially an electromechanical calculator that could perform large computations 
automatically. It could perform addition, subtraction, multiplication, and division, 
and it could refer to previous results.
The Harvard Mark I (Fig. 4.2) was designed to assist in the numerical computa-
tion of differential equations, and it was 50 feet long, 8 feet high, and weighed 5 
tons. It performed additions in less than a second, multiplications in 6 seconds, and 
division in about 12 seconds. It used electromechanical relays to perform the calcu-
lations, and it could execute long computations automatically.
It was constructed out of switches, relays, rotating shafts, and clutches, and it 
used 500 miles of wiring and over 750,000 components. It was the industry’s largest 
electromechanical calculator, and it had 60 sets of 24 switches for manual data 
Fig. 4.1  Howard Aiken
4  The First Digital Computers

55
entry. It could store 72 numbers, each 23 decimal digits long. The instructions were 
read on paper tape, and punched cards were used to input the data and the results 
were either on punched cards or an electric typewriter.
The US Navy used the Harvard Mark I for ballistic calculations, and the machine 
remained in use until 1959. It cost approximately half a million dollars, but it was 
never mass-produced by IBM. It differed from most of the early digital computers 
in that it used relays instead of vacuum tubes.
The announcement of the Harvard Mark I led to tension between Aiken and 
IBM, as Aiken announced himself as the sole inventor without acknowledging the 
important role played by IBM.
4.3  Atanasoff-Berry Computer
John Atanasoff (Fig. 4.3) was born in New York in 1903, and he studied electrical 
engineering at the University of Florida, and did a Masters in Mathematics at Iowa 
State College. He earned a PhD in theoretical physics from the University of 
Wisconsin in 1930, and became an assistant professor at Iowa State College, where 
he taught mathematics and physics.
He became interested in developing faster methods of computation while doing 
his PhD research, so as to ease the time-consuming burden of calculation. He did 
some work on an analog calculator in 1936, but he concluded that these devices 
Fig. 4.2  Harvard Mark I (IBM ASCC). (Courtesy of IBM Archives)
4.3  Atanasoff-Berry Computer

56
were too restrictive and unable to provide the desired accuracy. His goal was to 
mechanize calculation to enable accurate computation to be carried out faster.
The existing computing devices were mechanical, electromechanical, or analog. 
Atanasoff developed the concept of digital machine in the late 1930s, and he pub-
lished his design for a machine to solve linear equations using his own version of 
Gaussian elimination in the summer of 1939. He then used his research grant of 
$650 to build the Atanasoff-Berry computer (ABC), with the assistance of his grad-
uate student, Clifford Berry, from 1939 to 1942.
The ABC (Fig. 4.4) was approximately the size of a large desk and had approxi-
mately 270 vacuum tubes. Two hundred and ten tubes controlled the arithmetic unit; 
30 tubes controlled the card reader and card punch; and the remaining tubes helped 
maintain charges in the condensers. It employed rotating drum memory, with each 
of the two drum memory units able to hold thirty 50-bit numbers.
The ABC was a digital machine that was designed for a specific purpose (i.e., 
solving linear equations) rather than as a general-purpose computer. The working 
prototype was one of the earliest electronic digital computers.1 However, the ABC 
was slow, and it required constant operator monitoring.
It used binary mathematics and Boolean logic to solve simultaneous linear equa-
tions. It employed over 270 vacuum tubes for digital computation, but it had no 
central processing unit (CPU), and it was not programmable.
It weighed over 300 kg and it used 1.6 km of wiring. It used 50-bit numbers, and 
it could perform 30 additions or subtractions per second. The memory and arithme-
tic units could operate and store 60 such numbers at a time (60 × 50 = 3000 bits). 
The arithmetic logic unit was fully electronic, and it was implemented with vac-
uum tubes.
1 The ABC was ruled to be the first electronic digital computer in the Sperry Rand vs. Honeywell 
patent case in 1973 (see Sect. 4.4.2). However, Zuse’s Z3 computer preceded it (it was completed 
in 1941).
Fig. 4.3  John Atanasoff 
with components of ABC
4  The First Digital Computers

57
The input was in decimal format with standard IBM 80 column punch cards, and 
the output was in decimal format via a front panel display. A paper card reader was 
used as an intermediate storage device to store the results of operations too large to 
be handled entirely within electronic memory. The ABC pioneered important ele-
ments in modern computing including:
–– Binary arithmetic and Boolean logic
–– All calculations were performed using electronics rather than mechanical 
switches
–– Computation and memory were separated
The ABC was tested and operational by 1942, and its historical significance is 
that it demonstrated the feasibility of electronic computing. Several of its concepts 
were later used in the ENIAC computer developed by Mauchly and Eckert.
4.4  ENIAC and EDVAC
The Electronic Numerical Integrator and Computer (ENIAC) was one of the first 
large general-purpose digital computers. It was used to integrate ballistic equations, 
and to calculate the trajectories of naval shells. It was completed in 1946, and it 
Fig. 4.4  Replica of ABC 
Computer: Creative 
Commons.
4.4  ENIAC and EDVAC

58
remained in use until 1955. The original cost of the machine was approximately 
$500,000.
ENIAC (Fig. 4.5) was a large bulky machine and it was over 100 feet long, 
10 feet high, 3 feet deep, and weighed about 30 tons. Its development commenced 
in 1943 at the University of Pennsylvania, and it was built for the US Army’s 
Ballistics Research Laboratory. The project team included Presper Eckert as chief 
engineer, John Mauchly as a consultant, and several others. ENIAC had over 18,000 
vacuum tubes, and so the machine generated a vast quantity of heat, as each vacuum 
tube generated heat like a light bulb. The machine used 150 kW of power and air-­
conditioning was used to cool it.
It employed decimal numerals and it could add five thousand numbers; do over 
three hundred and fifty 10-digit multiplications; or thirty-five 10-digit divisions in 
one second. It could be programmed to perform complex sequences of operations, 
and this included loops, branches, and subroutines. However, the task of taking a 
problem and mapping it onto the machine was complex, and it usually took weeks 
to perform. The first step was to determine what the program was to do on paper; the 
second step was the process of manipulating the switches and cables to enter the 
program into ENIAC, and this usually took several days. The final step was verifica-
tion and debugging, and this often involved single-step execution of the machine.
There were problems initially with the reliability of ENIAC, as several vacuum 
tubes burned out most days (Fig. 4.6). This meant that the machine was often non-­
functional, as high-reliability vacuum tubes only became available in the late 1940s. 
However, most of the problems with the tubes occurred during the warm-up and 
cool-down periods, and it was therefore decided not to turn the machine off. This led 
Fig. 4.5  Setting the switches on ENIAC’s function tables. Public domain
4  The First Digital Computers

59
to improvements in its reliability to the acceptable level of one tube every 2 days. 
The longest continuous period of operation without a failure was 5 days.
The very first program run on ENIAC took just 20 seconds, and the answer was 
manually verified to be correct after forty hours of work with a mechanical calcula-
tor. One of the earliest problems solved was related to the feasibility of the hydrogen 
bomb, and this program involved the input of 500,000 punch cards, and it ran for 
6 weeks, and gave an affirmative reply.
ENIAC was a fixed-program computer, and the machine had to be physically 
rewired in order to perform different tasks. It was clear that there was a need for an 
architecture that would allow a machine to perform different tasks without physical 
rewiring each time. This led to the concept of the stored program, which was imple-
mented on EDVAC (the successor to ENIAC).
The idea of a stored program is that the program is stored in memory, and when-
ever there is a need to change the task that is to be computed, then all that is required 
is to place a new program in the memory of the computer, rather than rewiring the 
machine. EDVAC implemented the concept of a stored program in 1949, just after 
its implementation on the Manchester Baby prototype machine in England. The 
concept of a stored program and von Neumann architecture is detailed in Von 
Neumann’s report on EDVAC [VN:45].
ENIAC was preceded in development by Zuse’s Z3 machine in Germany; the 
Atanasoff Berry Computer (ABC) in the United States; and the Colossus computer 
developed in the UK. ENIAC was a major milestone in the history of computing.
Fig. 4.6  Replacing a valve on ENIAC. Public domain
4.4  ENIAC and EDVAC

60
4.4.1  EDVAC
The EDVAC (Electronic Discrete Variable Automatic Computer) was the successor 
to the ENIAC computer. It was a stored-program computer and it cost $500,000. 
Eckert and Mauchly proposed it in 1944, and design work commenced prior to the 
completion of ENIAC.
It was delivered to the Ballistics Research Laboratory in 1949, and it commenced 
operations in 1951. It remained in operations until 1961. It employed 6000 vacuum 
tubes and its power consumption was 56,000 watts. It had 5.5 Kb of memory.
EDVAC (Fig 4.7) was one of the earliest stored-program computers, and the 
program instructions were stored in memory, rather than rewiring the machine 
each time.
4.4.2  Controversy Between the ABC and ENIAC
The ABC computer was ruled to be the first electronic digital computer in the 1973 
Honeywell vs. Sperry Rand patent court case in the United States. The court case 
arose from a patent dispute between Sperry and Honeywell, where Sperry was 
Fig. 4.7  The EDVAC 
computer. Public domain
4  The First Digital Computers

61
charging Honeywell with patent infringement and demanding compensation and 
royalties. Honeywell countersued and charged Sperry with monopoly and fraud and 
demanded that the Sperry patent be declared invalid. The ENIAC patent had been 
lodged in 1947 and was issued in 1964, and the legal proceedings relating to the 
patent dispute commenced in 1967 and lasted for 6 years.
It is fundamental in patent law that an invention is a novel, and that there is no 
existing prior art at the time of the patent application. Further, the invention must 
not be in the public domain at the time of the application, as can happen through a 
publication or presentation on the invention.
The application for the ENIAC patent was filed in 1947, but there had been a 
public disclosure of ENIAC in 1946, as well as Von Neumann’s draft report on 
EDVAC in 1945, which legally constituted a publication that disclosed both ENIAC 
and EDVAC, and in effect placed ENIAC in the public domain. Further, John 
Atanasoff was called as an expert witness in the case, and the court also ruled that 
Eckert and Mauchly did not invent the first electronic computer, since the ABC 
existed as prior art at the time of their patent application for ENIAC. This meant 
that the Mauchly and Eckert patent application for ENIAC was invalid, and John 
Atanasoff was named as the inventor of the first digital computer.
Mauchly had visited Atanasoff on several occasions prior to the development of 
ENIAC, and they had discussed the implementation of the ABC computer. Mauchly 
subsequently designed the ENIAC, EDVAC, and UNIVAC computers. The court 
ruled that the ABC was the first digital computer, and that the inventors of ENIAC 
had derived the subject matter of the electronic digital computer from Atanasoff.
4.5  Bletchley Park and Colossus
Tommy Flowers (Fig. 4.8) was a British engineer who made important contribu-
tions to breaking the Lorenz codes during the Second World War. He led the team 
that designed and built Colossus, which was one of the earliest electronic 
Fig. 4.8  Tommy Flowers
4.5  Bletchley Park and Colossus

62
computers. The machine was designed to decode the top-level encrypted German 
military communication sent by German High Command to its commanders in the 
field. This provided British and American Intelligence with important information 
on German military plans around the D-Day invasion and later battles, and it helped 
to ensure the success of the Normandy landings and the ultimate defeat of Nazi 
Germany.
Flowers was born in East London in 1905, and he obtained a position with the 
telecommunications branch of the General Post Office in 1926. He moved to the 
research station at Dollis Hill in 1930, and he investigated the use of electronics for 
telephone exchanges. He was convinced at an early stage that an all-electronic sys-
tem was possible.
He became involved with the code-breaking work taking place at Bletchley Park 
(located near Milton Keynes north-west of London) during the Second World War. 
Alan Turing and others had cracked the German Enigma codes by building a 
machine known as the Bombe. This machine employed a crib to deduce the settings 
of the Enigma machine for that day. Turing introduced Flowers to Max Newman 
who was leading British efforts to break a German cipher generated by the Lorenz 
SZ42 machine.
Their existing approach to deciphering the Lorenz codes was with the Heath 
Robinson2 machine (a slow and unreliable prototype machine containing a small 
number of vacuum tubes) that was designed by Max Newman and build by the Post 
Office Research Station at Dollis Hills. Flowers proposed an alternate electronic 
machine in 1943, and this machine was called Colossus and it employed 1800 
thermionic valves. The management at Bletchley Park was skeptical, but they 
encouraged him to continue with his work.
Flowers and others at the Post Office Research Centre built the machine in 
11 months, and its successor, the Mark 2 Colossus, contained 2400 valves and it 
commenced operations on June 1, 1944. It was a large bulky machine and took up 
the space of a small room and weighed a ton.
It provided vital information for the Normandy landings, and it confirmed that 
Hitler had been successfully misled by Allied disinformation into believing that the 
Normandy landings were to be a diversionary tactic. Further, it confirmed that no 
additional German troops were to be moved there. The Colossus Mark 2 machine 
played a key role in helping the British to monitor the German reaction to their 
deception tactics.
4.5.1  Colossus
Flowers and others designed and built the original Colossus machine at the Post 
Office Research Station at Dollis Hill in London. The machine was used to find pos-
sible key combinations for the Lorenz machines rather than decrypting an 
2 William Heath Robinson was an English cartoonist who was well known for drawing elaborate 
machines to solve simple problems.
4  The First Digital Computers

63
intercepted message in its entirety. The Lorenz machine was based on the 
Vernam cipher.
Colossus compared two data streams to identify possible key settings for the 
Lorenz machine. The first data stream was the encrypted message, and it was read 
at high speed from a paper tape. The second stream was generated internally, and 
was an electronic simulation of the Lorenz machine at various trial settings. If the 
match count for a setting was above a certain threshold, it would be sent as output 
to an electric typewriter.
The Lorenz codes were a more complex cipher than the Enigma codes, and they 
were used in the transmission of important messages between the German High 
Command in Berlin and the military commanders in the field. The Lorenz SZ 40/42 
machine performed the encryption. The Bletchley Park code breakers called the 
typewriter-coding machine “Tunny” and the coded messages “Fish.” The code-­
breaking work involved carrying out complex statistical analyses on the intercepted 
messages.
The Colossus Mark 1 machine was specifically designed for code breaking rather 
than as a general-purpose computer. It was semi-programmable and helped in deci-
phering messages encrypted using the Lorenz machine. A prototype was available 
in 1943 and a working version was available in early 1944 at Bletchley Park. The 
Colossus Mark 2 (Fig. 4.9) was introduced just prior to the Normandy landings in 
June 1944.
The Colossus Mark 1 used 15 kW of power and it could process 5000 characters 
of paper tape per second. It enabled a large amount of mathematical work to be done 
in hours rather than in weeks. There were ten Colossi machines working at Bletchley 
Park by the end of the war. A replica of the Colossus was re-built by a team of vol-
unteers led by Tony Sale from 1993 to 1996, and it is at Bletchley Park museum.
The contribution of Bletchley Park to the cracking of the German Enigma and 
Lorenz codes, and to the development of computing remained clouded in secrecy 
Fig. 4.9  Colossus Mark 2. Public domain
4.5  Bletchley Park and Colossus

64
until recent times.3 The museum at Bletchley Park provides insight to the important 
contribution made by this organization to code breaking and to early computing 
during the Second World War.
4.6  Zuse’s Machines
Konrad Zuse is considered “the father of the computer” in Germany, as he built the 
world’s first programmable machine (the Z3) in 1941 (Fig. 4.10).
He was born in Berlin in 1910, and he studied civil engineering at the Technical 
University of Berlin. He commenced working for Henschel (an airline manufac-
turer) after his graduation in 1935. He resigned after 1 year with the intention of 
forming his own company to build automatic calculating machines.
His parents provided financial support, and he commenced work on what would 
become the Z1 machine in 1936. Zuse employed the binary system for the calcula-
tor and metallic shafts that could shift from position 0 to 1 and vice versa. The Z1 
was operational by 1938.
3 Gordan Welchman was the head of Hut 6 at Bletchey Park and he published his book “The Hut 
Six Story” in 1982 (in the United States and United Kingdom). However, the security services 
disapproved of its publication and his security clearance was revoked. He was forbidden to speak 
of his book and wartime work.
Fig. 4.10  Konrad Zuse. 
Courtesy of Horst 
Zuse, Berlin
4  The First Digital Computers

65
He served in the German Army on the Eastern Front for 6 months in 1939 at the 
start of the Second World War. Henschel helped Zuse to obtain a deferment from the 
army, and they made the case that he was needed as an engineer and not as a soldier. 
Zuse re-commenced working at Henschel in 1940, and he remained affiliated with 
Henschel for the duration of the war. He built the Z2 and Z3 machines during this 
period, and the Z3 was operational in 1941, and it was the world’s first program-
mable computer.
He started his own company in 1941, and this was the first company founded 
with the sole purpose of developing computers. The Z4 was almost complete as the 
Red Army advanced on Berlin in 1945, and Zuse left Berlin for Bavaria with the Z4 
prior to the Russian advance. His other machines were destroyed in the Allied 
bombing of Germany.
He designed the world’s first high-level programming language between 1943 
and 1945, and this language was called Plankalkül. He later re-started his company 
(Zuse KG), and he completed the Z4 in 1950. This was the first commercial com-
puter, as it was completed ahead of the Ferranti Mark 1, Univac, and LEO comput-
ers (discussed in Chap. 5). Its first customer was the Technical University of 
Zurich (ETH).
Zuse’s results are all the more impressive given that he was working alone in 
Germany, and he was unaware of the developments taking place in other countries. 
There is more detailed information on Zuse in [ORg:13].
4.6.1  Z1, Z2, and Z3 Machines
Zuse was unaware of computer-related developments in Germany or in other coun-
tries, and he independently implemented the principles of modern digital computers 
in isolation.
He commenced work on his first machine called the Z1 in 1936, and the machine 
was operational by 1938. It was demonstrated to a small number of people who saw 
it rattle and compute the determinant of a three by three matrix. It was essentially a 
binary electrically driven mechanical calculator with limited programmability. It 
was capable of executing instructions read from the program punch cards, but the 
program itself was never loaded into the memory.
It employed the binary system and metallic shafts that could slide from position 
0 to position 1 and vice versa. The machine was essentially a 22-bit floating-point 
value adder and subtracter. A decimal keyboard was used for input, and the output 
was decimal digits. The machine included some control logic, which allowed it to 
perform more complex operations such as multiplications and division. These oper-
ations were performed by repeated additions for multiplication, and repeated sub-
tractions for division. The multiplication took approximately 5  seconds. The 
computer memory contained 64 22-bit words. Each word of memory could be read 
from and written to by the program punch cards and the control unit. It had a clock 
speed of 1 Hz, and two floating-point registers of 22 bits each. The machine was 
unreliable, and a reconstruction of it is in the Deutsches Technikmuseum in Berlin.
4.6  Zuse’s Machines

66
His Z2 machine aimed to improve on the Z1, and this mechanical and relay com-
puter was created in 1939. It used a similar mechanical memory, but it replaced the 
arithmetic and control logic with 600 electrical relay circuits. It used 16-bit fixed-­
point arithmetic instead of the 22-bit used in the Z1. It had a 16-bit word size and 
the size of its memory was 64 words. It had a clock speed of 3 Hz.
The Z3 machine (Fig.  4.11) was the first functional tape-stored-program-­
controlled computer, and it was created in 1941. It used 2600 telephone relays; the 
binary number system; and it could perform floating-point arithmetic. It had a clock 
speed of 5Hz, and multiplication and division took 3 seconds. The input to the 
machine was with a decimal keyboard, and the output was on lamps that could dis-
play decimal numbers. The word length was 22 bits, and the size of the memory was 
64 words.
It used a punched film for storing the sequence of program instructions. It could 
convert decimal to binary and back again. It was the first digital computer since it 
pre-dates the Atanasoff-Berry Computer by 1 year. It was proven to be Turing com-
plete in 1998. There is a reconstruction of the Z3 computer in the Deutsches Museum 
in Munich.
4.7  University of Manchester
The Manchester Small Scale Experimental Computer (better known by its nick-
name “Baby”) was developed at the University of Manchester. It was the first 
stored-program computer, and it was designed and built at Manchester University 
in England by Frederic Williams, Tom Kilburn, Geoff Tootill, and others.
Fig. 4.11  Zuse and the Reconstructed Z3. (Courtesy of Horst Zuse, Berlin)
4  The First Digital Computers

67
The machine demonstrated the reliability of the Williams Tube, which was a 
form of electronic memory based on the cathode ray tube (CRT). The data in the 
tube could be read and written to, where each memory location contained either a 
positive charge to represent the binary value 1, with a negative charge representing 
the binary value 0.
It was the first stored-program computer: Another words the task to be com-
puted is defined by the computer instructions that are placed in memory, and in 
order to change the task to be computed, all that is required is to load a different 
program into the computer memory. Kilburn wrote and executed the first stored 
program, and it was a short 17-instruction program written to determine the high-
est proper divisor of 218. The program was successfully executed in 1948 and it 
ran for 52 minutes.
The prototype “Baby” (Fig. 4.12) demonstrated the feasibility and potential of 
a stored-program computer. Its memory consisted of 32  ×  32-bit words 
(1024  bits), and it took 1.2  milliseconds to execute one instruction, that is, 
0.00083 MIPS (million instructions per second). Today’s computers are rated at 
speeds of thousands of MIPS or billons of instruction per second (GIPS). The 
team in Manchester developed the machine further, and in 1949, the Manchester 
Mark 1 was available.
Fig. 4.12  Replica of the Manchester Baby. (Courtesy of Tommy Thomas)
4.7  University of Manchester

68
4.7.1  Manchester Mark I
The Manchester Automatic Digital Computer (MADC), also known as the 
Manchester Mark 1, was developed at the University of Manchester. It was one of 
the earliest stored-program computers, and it was the successor to the Manchester 
“Baby” computer. It was designed and built by Williams, Kilburn, and others.
Each word could hold one 40-bit number or two 20-bit instructions. The main 
memory consisted of two pages (i.e., two Williams tubes with each holding 
32 × 40-bit words or 1280 bits). The secondary backup storage was a magnetic 
drum consisting of 32 pages (this was updated to 128 pages in the final specifica-
tion). Each track consisted of two pages (2560 bits). One revolution of the drum 
took 30  milliseconds, and this allowed the 2560 bits to be transferred to the 
main memory.
The Manchester Mark I (Fig. 4.13) contained 4050 vacuum tubes, and it had a 
power consumption of 25,000 watts. The standard instruction cycle was 1.8 milli-
seconds but multiplication was much slower. The machine had 26 defined instruc-
tions, and the programs were entered into the machine in binary format, as assembly 
languages and assemblers were not yet available.
Fig. 4.13  The Manchester Mark 1 computer
4  The First Digital Computers

69
It had no operating system and its only systems software were some basic rou-
tines for input and output. Its peripheral devices included a teleprinter and a 5-hole 
paper tape reader and punch.
A display terminal used with the Manchester Mark 1 computer mirrored what 
was happening within the Williams Tube. A metal detector plate placed close to the 
surface of the tube detected changes in electrical charges. The metal plate obscured 
a clear view of the tube, but the technicians could monitor the tubes used with a 
video screen. Each dot on the screen represented a dot on the tube’s surface, and the 
dots on the tube’s surface worked as capacitors that were either charged and bright 
or uncharged and dark. The information translated into binary code (0 for dark, 1 for 
bright) became a way to program the computer.
The Manchester Mark I influenced later computer development such as Ferranti’s 
Mark I general-purpose computer which was released in 1951, as well as early IBM 
computers such as the IBM 701.
4.8  Review Questions
4.9  Summary
This chapter discussed some of the early computers developed in the United States, 
Britain, and Germany. These were mainly large bulky machines consisting of sev-
eral thousand vacuum tubes. A computer often took up the space of a large room, 
and it was slow and unreliable.
We discussed the Harvard Mark I which was a large electromechanical calculator 
that was designed by Howard Aiken. Atanasoff and Berry designed and developed 
the ABC computer, and this machine was designed to solve a set of linear equations. 
Mauchly and Eckert designed the ENIAC and EDVAC computers, and the EDVAC 
computer implemented the concept of a stored program.
The team at Bletchley Park in England designed and developed the COLOSSUS 
computer as part of their code-breaking work. This allowed them to crack the 
	1.	 Explain the significance of the ABC computer.
	2.	 Explain what is meant by a “stored program” computer, and its advantages 
over a fixed-program machine such as ENIAC.
	3.	 Explain why Konrad Zuse is considered the father of the computer in 
Germany.
	4.	 Explain the significance of the Manchester Baby computer.
	5.	 Explain the significance of the work done at Bletchley Park during the 
Second World War.
	6.	 Explain the significance of the Harvard Mark I?
4.9  Summary

70
German Lorenz codes, and to provide important military information during the 
D-Day landings of 1944.
Konrad Zuse designed and developed the Z1, Z2, and Z3 machines in Germany. 
The Z3 was operational in 1941 and it was the world’s first programmable com-
puter. Williams, Kilburn, and others implemented the first stored-program com-
puter. This machine was popularly known as the Manchester Baby.
4  The First Digital Computers

71
© The Author(s), under exclusive license to Springer Nature 
Switzerland AG 2021
G. O’Regan, A Brief History of Computing, 
https://doi.org/10.1007/978-3-030-66599-9_5
Chapter 5
The First Commercial Computers
5.1  Introduction
This chapter considers a selection of the first commercial computers designed and 
developed in the United States, Great Britain, Germany, and Australia. These 
machines built on the work of the first computers developed during the Second 
World War.
We discuss the UNIVAC I computer developed by EMCC (later called Sperry 
and Unisys) in the United States, the LEO I computer developed by J. Lyons and 
Co. in England, the Z4 computer developed by Zuse KG in Germany, the Ferranti 
Mark I developed by Ferranti in England, and the CSIRAC developed by CSIR in 
Australia.
The UNIVAC I computer was designed by John Mauchly and Presper Eckert of 
EMCC for the US Census Bureau, and it was designed for business and 
administrative use.
The LEO I computer was developed by J. Lyons and Co. in partnership with 
Cambridge University in England. It was based on the EDSAC computer designed 
by Maurice Wilkes at Cambridge University, and it was designed for business use.
The Z4 was designed and developed by Konrad Zuse in Germany. Zuse had 
already designed and developed a number of machines, and the Z4 computer was 
almost complete at the end of the Second World War. Zuse formed Zuse ZG to 
complete the machine after the war.
The University of Manchester implemented the first stored program computer 
(discussed in previous chapter), and the British government encouraged Ferranti to 
commercialize the Manchester Mark I.
Key Topics
UNIVAC I
LEO I computer
Ferranti Mark I
Z4
CSIRAC

72
5.2  UNIVAC
The Eckert-Mauchly Computer Corporation (EMCC) was founded by Presper 
Eckert and John Mauchly in 1947 after their resignations from the University of 
Pennsylvania. It was one of the earliest computer companies in the world, and it 
pioneered a number of fundamental computer concepts such as “stored program,” 
“subroutines,” “programming languages,” and “compilers.”
EMCC was awarded a contract from the US Census Bureau in 1948 to develop 
the Universal Automatic Computer (UNIVAC) for the 1950 census. This was one of 
the first commercially available computers when it was delivered in 1951 (too late 
for the 1950 census), and it was designed for business and administrative use, rather 
than for complex scientific calculations. The UNIVAC machine was later used to 
accurately predict the result of the 1952 presidential election in the United States 
(Dwight Eisenhower’s landslide victory) from a sample of 1% of the population.
The UNIVAC I (Fig. 5.1) was initially priced at $159,000, and the price gradu-
ally increased over the years to reach between $1.2 and $1.5 million. Over 46 of 
these computers were built and delivered.
It employed magnetic tape for high-speed storage, and it used 5,200 vacuum 
tubes. It consumed 125 kW of electricity, and it could carry out over 1000 operations 
per second. It took up 400 square foot of space, and its main memory consisted of 
1000 words of 12 characters. The input/output was via the operator’s console; 
several tape drives; and an electric typewriter.
UNIVAC is the name of a series of digital computers produced by EMCC and its 
successors (i.e., Remington Rand, Sperry, and Unisys). The original model was the 
UNIVAC I (Universal Automatic Computer I). The successor models in the original 
Fig 5.1  UNIVAC I computer
5  The First Commercial Computers

73
UNIVAC series included the UNIVAC II, which was released in 1958, and the 
UNIVAC III, which was released by Sperry Rand in 1962.
EMCC set up a department to develop software applications for the UNIVAC 
computer, and it hired Grace Murray Hopper in 1949 as one of its first programmers. 
Hopper played an important role in the development of programming languages, 
and she made important contributions to the early development of compilers, 
programming language constructs, data processing, and the COBOL programming 
language. She had previously worked with Howard Aiken on the Harvard Mark I 
computer, which was discussed in Chap. 4. For more information on Grace Murray 
Hopper, see [ORg:13].
EMCC was taken over by Remington Rand in 1950. Remington had a back-
ground in the production of typewriters, and the Remington Typewriter was the first 
to use the QWERTY keyboard. Remington’s acquisition of EMCC allowed it to 
enter the electronics market, and EMCC became the UNIVAC division of Remington 
Rand. Sperry took over Remington Rand in 1955, and it became known as Sperry 
Rand (and later just Sperry).
5.3  LEO I Computer
J. Lyons and Co. was an innovative and forward thinking British company, and it 
was committed to finding ways to continuously improve to serve its customers 
better. It sent two of its executives to the United States shortly after the Second 
World War to evaluate new methods to improve its business processes. These two 
executives came across the early computers that had been developed in the United 
States, including the ENIAC computer that had been developed by John Mauchly 
and others. They recognized the potential of these early machines for business data 
processing.
They also became aware during their visit that Maurice Wilkes and others at 
Cambridge University in England were working on the design of a computer based 
on the ideas detailed in Von Neumann’s report. On their return to England, they 
visited Wilkes at Cambridge University, who was working on the design of the 
EDSAC computer. They were impressed by his ideas and technical knowledge, and 
the potential of the planned EDSAC computer. They prepared a report for Lyon’s 
board recommending that a computer designed for data processing should be the 
next step in improving business processes, and that Lyons should develop or acquire 
a computer to meet its business needs.
Lyons and Cambridge entered a collaboration arrangement where Lyons agreed 
to help fund the completion of EDSAC, and Cambridge agreed to help Lyons to 
develop its own computer, which was called the Lyons Electronic Office or LEO 
Computer (Fig. 5.2). This machine was based on EDSAC but adapted to business 
data processing. Lyons set up a project team led by John Pinkerton to develop its 
computer, and Wilkes provided training for Lyon’s engineers. The LEO computer 
ran its first program in late 1951.
5.3  LEO I Computer

74
The Electronic Delay Storage Automatic Calculator (EDSAC) was completed 
and ran its first program in 1949, and the LEO I computer was completed and ran its 
first program in late 1951. Lyons developed several applications for LEO, and the 
computer was used to process business applications (e.g., payroll) for other 
companies. Lyons recognized that more and more companies would require 
computing power, and they saw a business opportunity. They decided to set up a 
subsidiary company to focus on computers for commercial applications
Leo Computers Ltd. was set up in 1954 and it was based in London. It designed 
and developed a new computer, the LEO II, which was purchased by several British 
companies. The LEO III was released in 1961, and it was sold to customers in the 
United Kingdom and overseas.
LEO I’s clock speed was 500 kHz with most instructions taking 1.5 milliseconds 
to complete. The machine was linked to fast paper tape readers and fast punched 
card readers and punches. It had 8.75Kb of memory holding 2048 35-bit words
The LEO I was initially used for valuation jobs, but this was later extended to 
payroll, inventory, and other applications. One of the early applications developed 
by Lyons was an early version of an integrated management information system to 
manage its business. Lyons was also one of the pioneers of IT outsourcing in that it 
performed payroll calculations for a number of companies in the United Kingdom.
The UK Met Office used the LEO I computer in an early attempt at using a com-
puter for weather forecasting in the early 1950s. The weather prediction model was 
solved on the LEO I computer, and the first predictions were made in 1954. The Met 
Office later used the Ferranti Mark I and more powerful computers for weather 
forecasting. For a more detailed account of LEO, see [ORg:15, Fer:03].
Fig. 5.2  LEO I computer. (Courtesy of LEO Computer Society)
5  The First Commercial Computers

75
5.4  The Z4 Computer
Zuse KG was founded by Konrad Zuse at Neukirchen (north of Frankfurt) in 1949. 
It was the first computer company in Germany and it initially had five employees. 
The early focus of the company was to restore and improve Zuse’s Z4 machine, 
which had survived the Allied bombing of Berlin, and Zuse’s subsequent move to 
Bavaria.
.
The Z4 machine (Fig.  5.3) consisted of 2200 relays (electrically operated 
switches), a mechanical memory of sixty-four 32-bit words, and a processor. The 
speed of the machine was approximately 1000 instructions per hour (and so it was 
very slow compared to the other early digital computers). The Henschel Aircraft 
Company had ordered the Z4 machine in 1942, but as the production of the machine 
was time consuming, it was never actually delivered to Henschel. The machine was 
almost completed by the end of the Second World War in 1945.
The Z4 was restored for the Institute of Applied Mathematics at the Eidgenössische 
Technische Hochschule Zürich (ETH) in Zurich. The restoration was complete in 
1950, and it was delivered to the ETH later that year. It was one of the first operational 
computers in Europe at that time.
It was transferred to the French-German Research Institute of Saint-Louis in 
France in 1955, and it remained operational there until 1959. Today, the Z4 machine 
is on display at the Deutsche Museum in Munich.
Fig. 5.3  The Z4 computer. (Creative Commons)
5.4  The Z4 Computer

76
Zuse ZG commenced work on the Z5 in the early 1950s, and this was an extended 
version of the Z4. The Z5 was one of the first commercial computers in Europe, and 
it was produced for the Leitz company in Germany. The Z5 followed similar 
construction principles as the Z4, but it was over six times faster.
Zuse KG produced over two hundred and fifty computers from 1949 to 1969, and 
by 1964 it had over 1200 employees. The company ran into financial difficulties in 
the early 1960s, and it was taken over by Rheinstahl in 1964. Rheinstahl was taken 
over by Siemens in 1967, and Konrad Zuse left the company in 1969.	
For a more 
detailed account of Zuse, see [ORg:15].
5.5  Ferranti Mark I
Ferranti Ltd. (a British company) and Manchester University collaborated to build 
one of the earliest general-purpose electronic computers. The machine was called 
the Ferranti Mark 1 (it was also known as the Manchester Electronic Computer), 
and it was basically an improved version of the Manchester Mark 1.
The first machine off the production line was delivered to the University of 
Manchester in 1951 and shortly before the release of the UNIVAC I electronic 
computer in the United States.
The main improvements of the Ferranti Mark 1 over the Manchester Mark I 
computer were in the size of primary and secondary storage, a faster multiplier, and 
additional instructions. The Ferranti Mark I (Fig. 5.4) had 8 pages of random access 
memory (i.e., 8 Williams tubes each with a storage capacity of sixty-four 20-bit 
words or 1280 bits). A 512-page magnetic drum, which stored two pages per track, 
provided the secondary storage, and its revolution time was 30 milliseconds.
It used a 20-bit word stored as a single line of dots on the Williams tube display, 
with each tube storing a total of 64 lines of dots (or 64 words). Instructions were 
stored in a single word, while numbers were stored in two words.
The accumulator was 80 bits and it could also be addressed as two 40-bit words. 
There were about 50 instructions and the standard instruction time was 1.2 
milliseconds. Multiplication could be completed in 2.16 milliseconds. There were 
4050 vacuum tubes employed.
The Ferranti Mark 1’s instruction set included a “hoot command,” which allowed 
auditory sounds to be produced. It also allowed variations in pitch. Christopher 
Strachey (who later did important work in the semantics of programming languages) 
programmed the Ferranti Mark 1 to play tunes such as “God save the King,” and the 
Ferranti Mark 1 was one of the earliest computers to play music.
Dr. Dietrich Prinz wrote one of the earliest computer games (a chess-playing 
program) for the Ferranti Mark I in 1951. The parents of Tim Berners-Lee (the 
inventor of the world-wide web) both worked on the Ferranti Mark 1.
5  The First Commercial Computers

77
5.6  CSIRAC Computer
The CSIRAC (Council for Scientific and Industrial Research Automatic Computer) 
was Australia’s first digital computer. It was one of the earliest stored program 
computers, and it became operational in November 1949. It is on permanent display 
at the Melbourne Museum.
It was constructed by a team led by Trevor Pearcey and Maston Beard at the 
CSIR in Sydney. The machine had 2,000 vacuum valves and used 30kW of power 
during operation. The input to the machine was done with a punched paper tape, and 
output was to a teleprinter or to punched tape. The machine was controlled through 
a console, which allowed programs to be stepped through one at a time.
The CSIRAC (Fig. 5.5) was the first digital computer to play music and this took 
place in 1950. The machine was moved to the University of Melbourne in the 
mid-1950s, and today the machine is on permanent display at the Melbourne Museum.
Fig. 5.4  Ferranti Mark I
5.6  CSIRAC Computer

78
5.7  Review Questions
5.8  Summary
This chapter considered a selection of the first commercial computers designed and 
developed in the United States, Britain, Germany, and Australia. These machines 
built upon the work done on the first digital computers developed during the Second 
World War.
We discussed the UNIVAC I computer developed by EMCC in the United States; 
the LEO I computer developed by J. Lyons and Co. in England; the Z4 computer 
developed by Zuse KG in Germany; the Ferranti Mark I developed by Ferranti in 
England; and CSIRAC developed by CSIR in Australia.
Mauchly and Eckert wished to commercialize their work on the ENIAC/EDVAC 
computers and to protect their intellectual property. The University of Pennsylvania 
	1.	
What are the key contributions made by EMCC/Unisys to the com-
puting field?
	2.	
Describe the contributions of J, Lyons and Co. to the early comput-
ing field?
	3.	
What is the significance of Zuse’s Z4 machine?
	4.	
Discuss the progress made in the production of music on early 
computers.
	5.	
Describe the contribution of the University of Manchester to early 
computing. What were the key improvements in the Ferranti Mark I 
over the Manchester Mark I?
	6.	
Describe the contributions of Grace Murray Hopper to the comput-
ing field.
Fig. 5.5  CSIRAC computer. (Creative Commons)
5  The First Commercial Computers

79
had introduced new policies that required them to sign over the intellectual property 
rights to their invention, and so they set up EMCC to commercialize their inventions.
The LEO I computer arose as a result of forward thinking by J. Lyons and Co. 
who wished to improve their businesses processes, and they collaborated with 
Maurice Wilkes at Cambridge University to produce the LEO I computer.
The UK government encouraged Ferranti to commercialize the Manchester 
Mark I computer, and the Ferranti Mark I was an improved version, which was 
commercialized in the UK.
5.8  Summary

81
© The Author(s), under exclusive license to Springer Nature 
Switzerland AG 2021
G. O’Regan, A Brief History of Computing, 
https://doi.org/10.1007/978-3-030-66599-9_6
Chapter 6
Early Commercial Computers 
and the Invention of the Transistor
6.1  Introduction
This chapter considers a selection of computers developed during the 1950s, and it 
includes a selection of vacuum-tube-based computers as well as transistor comput-
ers. One of the drivers for the design and development of more powerful computers 
was the perceived threat of the Soviet Union. This led to an arms race between the 
two superpowers, and it was clear that computing technology would play an impor-
tant role in developing more sophisticated weapon and defense systems. The devel-
opment of the SAGE air defense system in the United States and Canada was an 
early example of the use of computer technology for the military.
The other key driver for the development of more powerful computers was to 
support business, universities, and government. The machines developed during this 
period were mainly large proprietary mainframes designed for business, scientific, 
and government use. They were expensive, and this eventually led vendors such as 
IBM and DEC to introduce families of computers in the 1960s, where a customer 
could choose a small cheaper member of the family to meet their needs, and then to 
upgrade over time to a larger computer in the family as their computing needs 
increased.
The origins of IBM are in the work done by Hermann Hollerith in developing a 
tabulating machine to process the 1890 census of the population of the United 
States. IBM became a very successful international company selling punched cards 
tabulating machines. Thomas Watson Sr. led the company from 1912 to 1952, and 
Thomas Watson Jr. became CEO in 1952. He believed that the future of IBM was in 
computers, and not tabulators, and he transformed IBM to become a world leader in 
the computer sector.
Key Topics
IBM 701
SAGE
Transistor
IBM 608
IBM 704

82
6.2  Early IBM Computers
IBM commenced work on computers during the Second World War, with its joint 
venture with Howard Aiken on the Harvard Mark I (also known as the IBM 
Automatic Sequence Controlled Calculator (ASCC)). This machine was essentially 
an electromechanical calculator that could perform large computations automati-
cally (see Chap. 4), and it was delivered to Harvard University in 1941.
IBM introduced the vacuum tube multiplier in 1943, which was an important 
move from electromechanical to electronic machines (the Harvard Mark I used 
electromechanical relays to perform the calculations). It was one of the first com-
plete machines to perform arithmetic electronically by substituting vacuum tubes 
for electric relays. The key advantages of the vacuum tubes were that they were 
faster, smaller, and easier to replace than the electromechanical switches used on the 
Harvard Mark I.  This allowed engineers to process information thousands of 
times faster.
IBM introduced its first large computer based on vacuum tubes in 1952. The 
machine was called the IBM 701 (Fig. 6.1), and it executed 17,000 instructions per 
second. It was used mainly for government work and for business applications.
IBM introduced the IBM 650 (Magnetic Drum Calculator) in 1954. This was an 
intermediate-sized electronic computer designed to handle accounting and scientific 
computations. It was one of the first mass-produced computers, and it was used by 
universities and businesses. It was a very successful product for IBM, with over 
2000 machines built and sold between its product launch in 1954, and its retirement 
in 1962. The machine included a central processing unit, a power unit, and a 
card reader.
The IBM 704 data processing system was a large computer introduced in 1954. 
It included core memory and floating-point arithmetic, and it was used for scientific 
and commercial applications. It included high-speed memory, which was faster and 
much more reliable than the cathode-ray-tube memory storage mechanism used in 
earlier machines. It also had a magnetic drum storage unit, which could store parts 
of the program and intermediate results (Fig. 6.2).
The interaction with the system was either by magnetic tape or punched cards 
entered through the card reader. The program instructions or data were initially 
produced on punched cards. They were then either converted to magnetic tape or 
read directly into the system, and the data processing was then performed. The out-
put from the data processing was then sent to a line printer, magnetic tape, or 
punched cards. Multiplication and division was performed in 240 microseconds.
The designers of the IBM 704 included John Backus and Gene Amdahl. Backus 
was one of the key designers of the FORTRAN programming language, which was 
introduced by IBM in 1957. This was the first scientific programming language, and 
it is still popular with engineers and scientists. Gene Amdahl later founded Amdahl 
Corporation after his resignation from IBM, and Amdahl Corporation later became 
a major competitor to IBM in the mainframe market. For more detailed information 
on Backus and Amdahl, see [ORg:13].
6  Early Commercial Computers and the Invention of the Transistor

83
Fig. 6.1  IBM 701. (Courtesy of IBM Archives)
Fig. 6.2  IBM 704. (Courtesy of IBM Archives)
6.2  Early IBM Computers

84
6.3  The SAGE System
The Semi-Automatic Ground Environment (SAGE) was an automated system for 
tracking and intercepting enemy aircraft in North America. It was used by the North 
American Aerospace Defense Command (NORAD), which is located in an earth-
quake and nuclear blast proof structure deep inside Cheyenne Mountain in Colorado 
in the United States. The SAGE system was used from the late 1950s until the 1980s.
The interception of enemy aircraft was extremely difficult prior to the invention 
of radar during the Second World War. Its introduction allowed fighter aircraft to be 
scrambled just in time to meet the enemy threat. The radar stations were ground 
based, and they therefore needed to communicate with and send interception 
instructions to fighter aircraft to deal with hostile aircraft.
However, after the war the speed of aircraft increased considerably, thereby 
reducing the time available to scramble fighter aircraft. This necessitated a more 
efficient and automatic way to transmit interception instructions, and new approaches 
to provide security of airspace for the United States. The SAGE system was designed 
to solve this problem, and it analyzed the real-time information that it received from 
the various radar stations around the country, and it then automated the transmis-
sion of interception messages to fighter aircraft (Fig. 6.3).
IBM and MIT played an important role in the design and development of 
SAGE.  Some initial work on real-time computer systems had been done at 
Massachusetts Institute of Technology on a project for the United States Navy. This 
project was concerned with building an aircraft flight simulator computer for train-
ing bombing crews, and it led to the development of the Whirlwind digital com-
puter. This computer was originally intended to be an analog machine, but instead it 
became the Whirlwind digital computer, and it was used for experimental develop-
ment of military combat information systems.
Whirlwind was the first real-time computer and Jay Forrester and his team at 
MIT created it. The US military saw Whirlwind as a potentially useful starting point 
for an air defense system, and so George Valley and Jay Forrester wrote a proposal 
to employ Whirlwind for air defense. This led to the Cape Cod system, which dem-
onstrated the feasibility of an air defense system covering New England. The design 
and development of SAGE commenced in 1953, and a detailed account of the devel-
opment of SAGE from the initial work done on Whirlwind is in [ReS:00].
IBM was responsible for the design and manufacture of the AN/FSQ-7 vacuum 
tube computer used in SAGE. Its design was based on the Whirlwind II computer, 
which was intended to be the successor to Whirlwind. However, the Whirlwind II 
was never built, and the AN/FSQ-7 computer weighed 275 tons and included 
500,000 lines of assembly code. It used magnetic core memory, which was much 
faster than the Williams tube discussed in Section 4.7.
6  Early Commercial Computers and the Invention of the Transistor

85
The AN/FSQ holds the current world record for the largest computer ever built. 
It employed 55,000 vacuum tubes, covered an area over 18,000 square feet, and it 
used about three megawatts of power.
There were twenty-four SAGE Direction Centers and three SAGE Combat 
Centers located in the United Sates. Each SAGE site included two computers for 
redundancy, and long-distance telephone lines linked each center. Burroughs pro-
vided the communications equipment to enable the centers to communicate with 
one another, and this was one of the earliest computer networks.
Each site was connected to multiple radar stations with tracking data transmitted 
by modem over a standard telephone wire. The SAGE computers then collected the 
tracking data for display on a cathode ray tube (CRT). The console operators at the 
center could select any of the targets on the display to obtain information on the 
tracking data. This enabled aircraft to be tracked and identified, and the electronic 
information was presented to operators on a display device.
The engineering effort in the SAGE project was immense, and the total cost is 
believed to have been several billion US dollars. It was a massive construction proj-
ect, which involved erecting buildings and building power lines, and communica-
tion links between the various centers and radar stations.
SAGE influenced the design and development of the Federal Aviation Authority 
(FAA) automated air traffic control system.
Fig. 6.3  SAGE IBM AN/FSQ-7 Console. (Creative Commons)
6.3  The SAGE System

86
6.4  Invention of the Transistor
The early computers were large bulky machines taking up the size of a large room. 
They contained thousands of vacuum tubes,1 and these tubes consumed large 
amounts of power and generated a vast quantity of heat. This led to problems with 
the reliability of the early computers, as several tubes burned out each day. This 
meant that machines were often nonfunctional for parts of the day, until the defec-
tive tube was identified and replaced (see Fig. 4.6).
There was therefore a need to find a better solution to vacuum tubes, and Shockley 
(Fig. 1.2) set up the solid physics research group at Bell Labs after the Second 
World War. His goal was to find a solid-state alternative to the existing glass-based 
vacuum tubes.
Shockley was born in England in 1910 to American parents, and he grew up at 
Palo Alto in California. He earned his PhD from Massachusetts Institute of 
Technology in 1936, and he joined Bell Labs shortly afterward. His solid physics 
research team included John Bardeen and Walter Brattain, who would later share 
the 1956 Nobel Prize in Physics with him for their invention of the transistor 
(Fig. 1.3).
Their early research was unsuccessful, but by late 1947 Bardeen and Brattan suc-
ceeded in creating a point-contact transistor independently of Shockley, who was 
working on a junction-based transistor. Shockley believed that the point-contact 
transistor would not be commercially viable, and his junction point transistor was 
announced in mid-1951, with a patent granted later that year. The junction point 
transistor soon eclipsed the point-contact transistor, and it became dominant in the 
market place.
Shockley published a book on semiconductors in 1950 [Sho:50], and he resigned 
from Bell Labs in 1955. He formed Shockley Laboratory for Semiconductors (part 
of Beckman Instruments) at Mountain View in California. This company played an 
important role in the development of transistors and semiconductors, and several of 
its staff later formed semiconductor companies in the Silicon Valley area.
Shockley was the director of the company, but his management style alienated 
several of his employees. This led to the resignation of eight key researchers in 1957 
following his decision not to continue research into silicon-based semiconductors. 
This gang of eight went on to form Fairchild Semiconductors and other companies 
in the Silicon Valley area in the following years.
1 ENIAC contained over 18,000 vacuum tubes and the AN/FSQ-7 computer used in SAGE con-
tained 55,000 vacuum tubes.
6  Early Commercial Computers and the Invention of the Transistor

87
For more detailed information on Shockley and Bell Labs, see [ORg:13, ORg:15].
6.5  Early Transistor Computers
The University of Manchester Experimental Transistor Computer was one of the 
first transistor computers.2 The prototype machine used 92 point-contact transistors 
and had a 48-bit word size, whereas the full-scale version used 200 point-contact 
transistors. There were problems with the reliability of the point-contact transistors, 
which meant that there were reliability problems with the machine. Metropolitan-
Vickers (a Manchester company) adapted the design and changed the circuits to use 
the more reliable junction-based transistors and created a full-scale version called 
the Metrovick 950 in 1956.
Other early transistor computers include the TRADIC designed and developed 
by Bell Labs in early 1954. This machine also used some vacuum tubes. The Harwell 
CADET was an early fully transistorized machine when it appeared in early 1955. 
The IBM 608 was the first IBM product to use transistor circuits instead of vacuum 
tubes. The prototype of this product appeared in 1955, and the fully transistorized 
calculator was introduced in late 1957. It contained 3000 germanium transistors. 
The Burroughs SM-65-Atlas ICBM was an early-transistorized computer, which 
appeared in 1957.
The IBM 7090 was one of the earliest commercial computers with transistor 
logic, and it was introduced in 1958. It was designed for large-scale scientific 
applications, and it was over thirteen times faster than the older vacuum tube 
IBM 701. It used 36-bit words, had an address-space of 32,768 words, and could 
perform 229,000 calculations per second. It was used by the U.S. Air Force to 
provide an early warning system for missiles, and also by NASA to control space 
flights. It cost approximately $3 million but it could be rented for over $60K 
per month.
2 It was not a fully transistorized computer, in that it employed a small number of vacuum tubes in 
its clock generator.
6.5  Early Transistor Computers

88
6.6  Review Questions
6.7  Summary
This chapter considered a selection of computers developed during the 1950s, 
including a selection of vacuum tube-based computers, as well as early transistor 
computers.
Among the early vacuum tube computers considered were the IBM 701 and IBM 
704. The IBM 701 was introduced in 1952; it was used mainly for government work 
and for business applications. The IBM 704 data processing system was a large 
computer that was introduced in 1954. It was used for scientific and commercial 
applications, with Gene Amdahl and John Backus involved in its design.
The SAGE air defense system was developed for the United States and Canada, 
and it was an early example of the use of computer technology for the military. It 
was an automated system for tracking and intercepting enemy aircraft in North 
America, and it automated the transmission of interception messages to fighter 
aircraft.
The invention of the transistor by Shockley and others at Bell Labs was a revolu-
tion in computing, and it led to smaller, faster, and more reliable computers. The 
University of Manchester experimental transistor computer was one of the earliest 
transistor computers.
	1.	
Explain the significance of the transistor in the computing field.
	2.	
Explain the significance of the SAGE system to the computing field.
	3.	
Describe the contributions made by the University of Manchester to 
the computing field.
	4.	
Describe the early transistor computers.
	5.	
Describe the contributions of John Backus and Gene Amdahl to the 
computing field.
	6.	
Describe the contributions of Bell Labs to the computing field.
	7.	
Describe the contributions of IBM to the computing field.
6  Early Commercial Computers and the Invention of the Transistor

89
© The Author(s), under exclusive license to Springer Nature 
Switzerland AG 2021
G. O’Regan, A Brief History of Computing, 
https://doi.org/10.1007/978-3-030-66599-9_7
Chapter 7
Integrated Circuit and Silicon Valley
7.1  Introduction
The invention of the transistor was a revolution in computing, and it led to smaller, 
faster, and more reliable computers. However, it was still a challenge for engineers 
to design complex circuits, as they had to wire hundreds (thousands) of separate 
components together.
It is essential when building a circuit that all of the connections are intact, as 
otherwise the electric current will be stopped on its way through the circuit, and the 
circuit will fail. Prior to the invention of the integrated circuit, engineers had to 
construct circuits by hand, which involved soldering each component in place, and 
connecting them with wires. However, the manual assembly of the large number of 
components required in a computer often resulted in faulty connections, and 
advanced computers required so many connections that they were almost impossi-
ble to build. Clearly, there was a need for a better solution.
The invention of the integrated circuit allowed many transistors to be combined 
on a single chip, and it was a revolution in computing. The integrated circuit placed 
the previously separated transistors, resistors, capacitors, and wiring circuitry on to 
a single chip made of silicon or germanium. The integrated circuit shrunk the size 
and cost of making electronics, and it had a major influence on the design of later 
computers and electronics. It led to faster and more powerful computers.
Key Topics
Integrated circuit
Silicon
Germanium
Texas Instruments
Fairchild
Silicon Valley
Moore’s Law

90
7.2  Invention of Integrated Circuit
The electronics industry was dominated by vacuum tube technology up to the 
mid-­1950s. However, vacuum tubes had inherent limitations as they were bulky, 
unreliable, produced considerable heat, and consumed a lot of power. Bell Labs 
invented the transistor in the late 1940s, and transistors were tiny in comparison to 
vacuum tubes, consumed very little power, and they were faster, more reliable, and 
lasted longer. The transistor stimulated engineers to design ever more complex elec-
tronic circuits and equipment containing hundreds or thousands of discrete compo-
nents such as transistors, diodes, rectifiers, and capacitors.
The motivation for the invention of the integrated circuit was to find a solution to 
the problems that engineers faced as the number of components in their design 
increased so as to enhance its performance. Each component needed to be wired to 
many other components, and the wiring and soldering was done manually. Clearly, 
more components would be required to improve performance, and therefore it 
seemed that future designs would consist almost entirely of wiring.
These components needed to be interconnected to form electronic circuits, and 
this involved hand soldering of thousands of components to thousands of bits of 
wire. This was expensive and time-consuming, and it was also unreliable since 
every soldered joint was a potential source of trouble. The challenge for the industry 
was to find a cost-effective and reliable way of producing these components and 
interconnecting them.
Jack Kilby (Fig. 7.1) joined Texas Instruments in 1958, and he began investigating 
how to solve this problem. He realized that semiconductors were all that were really 
required, as resistors and capacitors could be made from the same material as the 
transistors. He realized that since all of the components could be made of a single 
material that they could also be made in situ interconnected to form a complete circuit.
Kilby succeeded in building an integrated circuit made of germanium that con-
tained several transistors in 1958. Robert Noyce of Fairchild Semiconductors built 
an integrated circuit on a single wafer of silicon in 1960, and Kirby and Noyce are 
Fig. 7.1  Jack Kilby c. 
1958. (Courtesy of Texas 
Instruments)
7  Integrated Circuit and Silicon Valley

91
considered coinventors of the integrated circuit. Kilby was awarded the Nobel Prize 
in Physics in 2000 for his role in its invention.
Kilby’s integrated circuit consisted of a transistor and other components on a 
slice of germanium (Fig. 7.2). His invention revolutionized the electronics industry, 
and the integrated circuit is the foundation of almost every electronic device in use 
today. His invention used germanium, and the size of the integrated circuit was 7/16 
by 1/16-inches.
Robert Noyce at Fairchild Semiconductors later invented an integrated circuit 
based on a single wafer of silicon in 1960, and today silicon is the material of choice 
for semiconductors. Noyce made an important improvement on Kilby’s design in 
that he added a thin layer of metal to the chip to better connect the various compo-
nents in the circuit. Noyce’s solution made the integrated circuit more suitable for 
mass production, and Fairchild Semiconductors pioneered the use of the planar 
process for making transistors, and the existing semiconductor companies soon 
employed this process. Noyce was one of the cofounders of Intel, which is one of 
the largest manufacturers of integrated circuits in the world.
An integrated circuit (IC) consists of a set of electronic circuits on a small chip 
of semiconductor material, and it is much smaller than a circuit made out of inde-
pendent components. The IC is made on a small plate of semiconductor material 
that is usually made of silicon. An integrated circuit is extremely compact, and it 
may contain billions of transistors and other electronic components in a tiny area. 
The width of each conducting line has got smaller and smaller due to advances in 
technology over the years, and it is now measured is in tens of nanometers.1 The 
1 1 nanometer (nm) is equal to 10−9 m.
Fig. 7.2  First integrated circuit. (Courtesy of Texas Instruments)
7.2  Invention of Integrated Circuit

92
invention of the integrated circuit led to major reductions in the size and cost of 
making electronics, and it impacted the design future computers and electronics.
The size of the components in a modern fabrication plant is extremely small, 
with thousands of transistors fitting inside the cross section of a strand of hair. The 
production of a chip requires precision at the atomic level, with tiny particles such 
as those in tobacco smoke large enough to ruin a chip. For this reason, chip produc-
tion takes place in a clean room, which is a special room designed with furniture 
made of special materials that do not give off particles, and very effective air filters 
and air circulation systems.
There has been a massive reduction in the production costs of integrated circuits, 
with the initial production cost of integrated circuits at $1000 in 1960. However, as 
demand increased and production techniques improved, the cost of production was 
reduced down to $25 by 1963.
There are several generations of integrated circuits from the small-scale integra-
tion (SSI) of the early 1960s, which typically had less than 30 transistors on the 
chip, to medium-scale integration (MSI) of the late 1960s with less than 300 transis-
tors on the chip; to large-scale integration (LSI) of the mid-70s with less than 3000 
transistors on the chip; to very large scale (VLSI) of the 1980s, which have over a 
million transistors on the chip to and ultra-large-scale integration (ULSI), which 
have over a million transistors on the chip.
There are several large companies that design and make semiconductors. These 
include companies such as Texas Instruments (TI), which is an American electron-
ics company that is one of the largest manufacturers of semiconductors in the world. 
Intel and AMD (Advanced Micro Devices) are among the largest makers of semi-
conductors in the world. For more detailed information on Jack Kilby and Texas 
Instruments, see [ORg:13-b, ORg:15-d].
7.2.1  Moore’s Law
Gordon Moore observed that over a period of time (from 1958 up to 1965) that the 
number of transistors on an integrated circuit doubled approximately every year. 
This led him to formulate what became known as Moore’s Law in 1965 [Mor:65], 
which predicted that this trend would continue for at least another 10 years. He 
refined the law in 1975 and predicted that a doubling in transistor density would 
occur every 2 years for the following 10 years.
His prediction of exponential growth in transistor density has proved to be accu-
rate over the last 50 years, and the capabilities of many digital electronic devices are 
linked to Moore’s Law.
The exponential growth in the capability of processor speed, memory capacity, 
and so on is all related to this law. It is likely that the growth in transistor density 
will slow in the coming years.
7  Integrated Circuit and Silicon Valley

93
The phenomenal growth in productivity is due to continuous innovation and 
improvement in manufacturing processes. It has led to more and more powerful 
computers running more and more sophisticated applications.
7.3  Early Integrated Circuit Computers
It took some time for integrated circuits to take off, as they were an unproven tech-
nology, and they remained expensive until mass production. Kilby and others at 
Texas Instruments successfully commercialized the integrated circuit by designing 
a hand-held calculator that was as powerful as the existing large, electromechanical 
desktop models. The resulting electronic hand-held calculator was small enough to 
fit in a coat pocket. This battery-powered device could perform the four basic arith-
metic operations on six digit numbers, and it was completed in 1967.
The earliest computers that used integrated circuits appeared in the 1960s, and 
their early use was mainly in embedded systems. The use of integrated circuits 
played an important role in early aerospace projects such as the Apollo Guidance 
Computer and Minuteman missile. The Apollo flight computer was one of the earli-
est computers to use integrated circuits, and it was developed by MIT/Raytheon and 
introduced in 1966. It provided capabilities for the guidance, navigation, and con-
trol of the Apollo spacecraft. The Minuteman II program used a computer built from 
integrated circuits, and the guidance system of the Minuteman II intercontinental 
ballistic missile was much smaller due to the use of the integrated circuits.
DEC’s first minicomputer to use integrated circuits was the popular PDP-8 
(Fig. 7.3), which was designed by Edson de Castro, and introduced in 1965. Hewlett-­
Packard introduced the 2116A minicomputer in 1966, and this minicomputer used 
Fairchild Semiconductors integrated circuits.
The Honeywell ALERT airborne computer was designed to handle complex air-
borne data in a real-time environment, and it was introduced in 1966. The Central 
Air Data Computer, was designed in the late 1960s, and it was used for flight control 
in the US Navy’s F-14A Tomcat Fighter. These were among the early computers to 
use integrated circuits.
7.4  Birth of Silicon Valley
Silicon Valley is the nickname for the southern portion of the San Francisco Bay 
area. It is home to many of the world’s largest high-tech companies, as well as thou-
sands of startup companies.
The term “Silicon Valley” first appeared in the printed media in 1971, in a series 
by Don Hoefler titled “Silicon Valley in the USA,” which was published in the 
weekly newspaper Electronics News. The term was used widely from the early 
1980s following the introduction of the IBM personal computer and given the high 
7.4  Birth of Silicon Valley

94
concentration of semiconductor technology companies in the area. The word “sili-
con” originally referred to the large number of silicon chip manufacturers in the 
area, as most semiconductors are made from silicon. The word “valley” refers to the 
Santa Clara Valley.
Bill Hewlett and Dave Packard started their two-person company (Hewlett-­
Packard) in a Palo Alto garage (Fig.  7.4) on 367 Addison Street in 1938. Fruit 
orchards covered the surrounding area, as Silicon Valley as it is known today did not 
exist. This 12 by 18 feet garage is now a historical landmark, and it has been offi-
cially declared the “birthplace of Silicon Valley.” HP purchased the property in 2000 
to preserve it for future generations.
William Shockley (one of the inventors of the transistor) moved from New Jersey 
to Mountain View in California to start Shockley Semiconductors in 1956. 
Shockley’s work served as the foundation for many electronics developments. 
However, Shockley was a difficult person to work with and his management style 
soon alienated several of his employees. This led to the resignation of eight key 
Fig. 7.3  The 
DEC PDP-8/e
7  Integrated Circuit and Silicon Valley

95
researchers in 1957, following his decision not to continue research into silicon-­
based semiconductors. Shockley described them as the “traitorous eight.”
This gang of eight went on to form Fairchild Semiconductors and other compa-
nies in the Silicon Valley area in the following years. They included Gordon Moore 
and Robert Noyce, who founded Intel in 1968. Other employees from Fairchild 
Semiconductors formed companies such as National Semiconductors and Advanced 
Micro Devices in the Silicon Valley area in later years. Shockley Semiconductors 
and these new companies formed the nucleus of what became Silicon Valley.
Stanford University played an important role in the development of Silicon 
Valley, and Frederick Terman, the Dean of Engineering and provost of Stanford 
University in the 1950s, encouraged graduates to form companies in the Silicon 
Valley area. Stanford University set up an industrial park (Stanford Research Park) 
for high-technology companies. Terman has been described as the father of 
Silicon Valley.
Fig. 7.4  HP Palo Alto Garage. Birthplace of Silicon Valley. (Courtesy of HP)
7.4  Birth of Silicon Valley

96
7.5  Review Questions
7.6  Summary
An integrated circuit consists of a set of electronic circuits on a small chip of semi-
conductor material, and it is much smaller than a circuit made out of independent 
components. The integrated circuit was a revolution in computing, and it shrunk the 
size and cost of making electronics. Its invention placed the previously separated 
transistors, resistors, capacitors, and wiring circuitry onto a single chip made of sili-
con or germanium.
There are several generations of integrated circuits that have evolved from the 
small-scale integration of the early 1960s with less than 30 transistors on a chip to 
the ultra-large-scale integration with over a billion transistors on the chip. Gordon 
Moore formulated Moore’s Law in 1965, in which he predicted exponential growth 
in transistor density. His prediction has proved to be accurate over the last 50 years, 
and the capabilities of modern digital electronic devices are linked to Moore’s Law.
The earliest computers to use integrated circuits appeared in the 1960s, and their 
use was mainly in embedded systems. They played an important role in early aero-
space projects such as the Apollo Guidance Computer and Minuteman missile. 
DEC’s popular PDP-8 was one of the early computers to use integrated circuits, and 
it was introduced in 1965.
The garage where HP was formed is considered the birthplace of Silicon Valley, 
and it is home to the world’s largest high-tech companies and thousands of start-ups.
	1.	
What is an integrated circuit?
	2.	
Explain the significance of Moore’s Law and its relevance to the 
computing power of electronic devices.
	3.	
Explain the importance of the integrated circuit?
	4.	
Describe the early computers that were based on the integrated 
circuit.
	5.	
Describe how Silicon Valley was formed.
	6.	
Describe the role played by Stanford University in the success of 
Silicon Valley.
7  Integrated Circuit and Silicon Valley

97
© The Author(s), under exclusive license to Springer Nature 
Switzerland AG 2021
G. O’Regan, A Brief History of Computing, 
https://doi.org/10.1007/978-3-030-66599-9_8
Chapter 8
The IBM System/360
8.1  Introduction
The IBM System/3601 was a family of mainframe computers designed and devel-
oped by IBM. It set IBM on the road to dominate the computing field for the next 
20 years, up to the introduction of personal computers in the 1980s. It was the 
beginning of an era of computer compatibility, where machines across a product 
line could work with each other. It meant that IBM customers could start off with a 
low specification member of the family, and upgrade over time to a more powerful 
member as their computing needs increased.
This allowed the customer to choose the appropriate model to meet its current 
needs, and it could upgrade to a more powerful member of the family as its needs 
evolved. It was a massive $5 billion investment (bet the business gamble) by Thomas 
Watson Jr., and it moved IBM from its traditional business and product lines into the 
unknown with the gamble that the future would be the System/360.
Thomas Watson Jr.2 announced the System/360 in 1964, and it fundamentally 
changed business and the world of computing. The System 360 replaced all five of 
IBM’s existing computer product lines with one strictly compatible family. It used 
a new computer architecture that employed hybrid integrated circuit technology, 
and it pioneered the 8-bit byte, which remains in use on every computer today.
The System/360 included a multiprogramming disk-based operating system, 
which was called OS/360. It included free software packages such as compilers for 
several programming languages, as well as packages for communication network 
capabilities [Pug:09].
1 The number “360” (the number of degrees in a circle) was chosen to represent the ability of each 
computer to handle all types of applications.
2 Thomas Watson Jr. later stated, “The System/360 was the biggest, riskiest decision that I ever 
made, and I agonised about it for weeks, but deep down I believed that there was nothing that IBM 
couldn’t do.”
Key Topics
System/360
Family of computers
Gene Amdahl
Fred Brooks
The Mythical Man Month

98
The System/360 was an extremely successful product line for IBM, with orders 
rapidly exceeding forecasts. Its success vastly exceeded IBM’s expectations, with 
over a thousand orders placed in the first four weeks after the announcement. The 
popularity of the System/360 made it difficult for IBM competitors (such as 
Burroughs, Honeywell and Sperry-Rand) to compete against IBM in the general-­
purpose computer market.
Monthly rental prices ranged from under $3,000 per month for the most basic 
system to over $100,000 per month for a large multisystem. The purchase cost 
ranged from $130,000 for a basic system to over $5 million for a large system. In 
1989, 25 years after the announcement of the System/360, products based on the 
System/360 architecture and its extensions still accounted for over 50% of IBM 
revenue.
8.2  Background to the Development of System/360
Thomas Watson Jr., the son of Thomas Watson Sr. (the first president of IBM), 
became president of IBM in 1952. He recognized that computers would play a key 
role for business in the years ahead, and he realized that the future of IBM was in 
the computer business, and not in tabulators. It was clear to him that IBM needed to 
change, and he played a key role in transforming the company to become the world 
leader in the computer industry.
IBM was already a successful computer company in the 1950s. It introduced its 
first large computer (the IBM 701) based on vacuum tubes in 1952; the IBM 650 
(Magnetic Drum Calculator) in 1954; and the IBM 704 data processing system 
computer in 1954 (see Chap. 6). It had also played a key role in the development of 
the computers for the SAGE air defense system in the United States. IBM was the 
dominant player and market leader, and it employed over 100,000 people around the 
world. That is, IBM was the “Snow White” of the computer industry, and Burroughs, 
Sperry, NCR, Control Data Corporation, Honeywell, General Electric, and RCA 
were the seven dwarfs of the computer sector.
However, within IBM there were concerns that the company had reached a pla-
teau, and competitors were launching alternative products to IBM. The origins of 
the System/360 go back to the late 1950s, and Watson’s determination to transform 
IBM to position it for future success. IBM was supporting five different product 
lines by 1959, and it was becoming a major challenge to train staff to service and 
maintain software to support so many different computer products.
Further, there were major problems with incompatibility between different hard-
ware and software among the different computer vendors, as well as incompatibility 
among IBM’s own products. IBM had an existing product line of several computers, 
each excellent in its own right, but all with incompatible architectures. It meant that 
customers who wished to move up from their existing small system to a larger sys-
tem had to invest in a new system, new printers, new storage devices, and new 
software (often totally rewritten for the new machine).
8  The IBM System/360

99
It was clear to Watson and other senior IBM executives that there was a need to 
develop a totally cohesive product line so that computers produced at different IBM 
facilities would be compatible with one another. IBM set up a corporate wide task 
group to establish an overall IBM plan for its future products. The task group had 
the acronym SPREAD (System Programming, Research, Engineering, and Design), 
and it completed its final report in late 1961. It made a series of recommendations 
such as that there would be five processors spanning a 200-fold range in perfor-
mance. IBM made the brave decision in 1962 to replace the company’s entire prod-
uct line of computers and to build a new family of compatible machines.
It would mean that code written for the smallest member of the family would be 
upwardly compatible with each of the processors in the family. Further, the various 
peripherals such as printers and storage devices would be compatible across the 
family. It was an incredibly brave decision, and Fortune Magazine later described it 
as IBM’s five billion dollar gamble.
8.3  The IBM System 360
Thomas Watson announced the new System 360 to the world at a press confer-
ence in 1964 and said:
“The System/360 represents a sharp departure from concepts of the past in designing and 
building computers. It is the product of an international effort in IBM’s laboratories and 
plants, and is the first time IBM has redesigned the basic internal architecture of its comput-
ers in a decade. The result will be more computer productivity at lower cost than ever 
before. This is the beginning of a new generation - - not only of computers - - but of their 
application in business, science and government.”
The IBM System/360 (Fig. 8.1) was a family of small to large computers, and the 
concept of a “family of computers” was a paradigm shift away from the traditional 
“one size fits all” philosophy of the computer industry, as up until then, every com-
puter model was designed independently.
The family of computers ranged from minicomputers with 24 KB of memory to 
supercomputers for US missile defense systems. However, all these computers 
employed the same user instruction set, and the main difference was that for the 
larger computers the more complex machine instructions were implemented with 
hardware, whereas the smaller machines used micro code.
The System/360 architecture allowed customers to commence with a lower cost 
computer model and to then upgrade over time to a larger system to meet their 
evolving needs. The fact that the same instruction set was employed meant that the 
time and expense of rewriting software was avoided.
8.3  The IBM System 360

100
Gene Amdahl (Fig. 8.2) was the chief architect for the System/360, and Fred 
Brooks3 was the project manager (Fig. 8.3). The IBM 360 family was introduced in 
1964, and the IBM chairman, Thomas Watson Jr., called it the most important prod-
uct announcement in the company’s history.
The IBM 360 family of small to large computers offered a choice of 5 processors 
and 19 combinations of power, speed, and memory. There were 14 models in the 
family. It was successful in achieving strict compatibility in the family of comput-
ers, and the project introduced a number of new industry standards including 
8-bit bytes.
A customer could start with a small member of the System/360 family and 
upgrade over time in to a larger computer in the family. This helped to make com-
puters more affordable for businesses, and it stimulated growth in computer use.
It was used extensively in the Apollo program to place man on the moon. The 
contribution by IBM computers and personnel were essential to the success of the 
project. IBM invested over $5 billion in the design and development of the S/360. 
However, the gamble paid off, and it was a very successful product line for IBM.
Gene Amdahl was appointed an IBM fellow in 1965 in recognition of his contri-
bution to IBM, and he was appointed director of IBM’s Advanced Computing 
Systems (ACS) Laboratory in California and given freedom to pursue his own 
research projects. He later left IBM following disagreements on future computer 
3 Fred Brooks wrote an influential paper “The Mythical Man Month” based on his experience as 
project manager for the System 360 project.
Fig. 8.1  IBM System/360. (Courtesy of IBM Archives)
8  The IBM System/360

101
development and he formed Amdahl Corporation, which later became a major com-
petitor to IBM in the mainframe market.
Fred Brooks was the project manager for the System 360 project, which involved 
5000 man-years of effort at IBM. Brooks recorded his experience as project man-
ager in a famous project management book titled The Mythical Man Month [Brk:75]. 
This book which appeared in 1975 considered the challenge of delivering a major 
project (of which software is a key constituent) on time, on budget, and with the 
right quality. Brooks described it as “my belated answer to Tom Watson’s probing 
question as to why programming is hard to manage.”
For a more detailed account of the System/360 revolution, see the excellent IBM 
article “The 360 Revolution” by Chuck Boyer [Boy:04]. For more detailed informa-
tion on Brooks and Amdahl, see [ORg:13, ORg:15].
Fig. 8.2  Gene Amdahl. 
(Creative Commons)
Fig. 8.3  Fred Brooks. 
(Photo courtesy of 
Dan Sears)
8.3  The IBM System 360

102
8.4  Review Questions
8.5  Summary
The IBM System/360 was a family of small to large computers, and it was a para-
digm shift away from the traditional “one size fits all” philosophy of the computer 
industry, as up until then, every computer model was designed independently.
The family ranged from minicomputers with 24 KB of memory to supercomput-
ers for U.S. missile defense systems. However, all these computers employed the 
same user instruction set, and the main difference was that for the larger computers 
the more complex machine instructions were implemented with hardware, whereas 
the smaller machines used micro code.
The System/360 architecture allowed customers to commence with a lower cost 
computer model and to upgrade over time to a larger system to meet their evolving 
needs. The fact that the same instruction set was employed meant that the time and 
expense of rewriting software was avoided.
Gene Amdahl was the chief architect for the System/360 and Fred Brooks was 
the project manager. Fred Brooks later wrote an influential project management 
book, which was concerned with the challenge of delivering a major project (of 
which software is a key part) on time, on budget, and with the right quality.
	1.	
Why did IBM decide to retire its existing product line and develop 
the System/360?
	2.	
What were the main risks in developing the System/360?
	3.	
What were the advantages of developing the System/360?
	4.	
What new industry standards followed from the System/360?
	5.	
What is a family of computers?
	6.	
Describe the contributions of Gene Amdahl to the computing field.
	7.	
Describe the contributions of Fred Brooks to the computing field.
8  The IBM System/360

103
© The Author(s), under exclusive license to Springer Nature 
Switzerland AG 2021
G. O’Regan, A Brief History of Computing, 
https://doi.org/10.1007/978-3-030-66599-9_9
Chapter 9
Minicomputers and Later Mainframes
9.1  Introduction
The minicomputer was a new class of low-cost computers that arose during the 
1960s. The development of minicomputers was facilitated by the introduction of 
integrated circuits, and their improved performance and declining cost. 
Minicomputers were distinguished from the large mainframe computers by price 
and size, and they formed a class of the smallest general-purpose computers.
Mainframes were large expensive machines (typically costing over $1 million), 
and they required separate rooms for technicians and operation, whereas minicom-
puters cost well under $100,000, and they were designed for direct, personal inter-
action with the programmer.
Digital Equipment Corporation (DEC) and Control Data Corporation (CDC) 
introduced small or minicomputers in the early 1960s. These included DEC’s 
PDP-1, which was released in 1961, and the CDC-160A, which was released in 
1960. These machines cost $110,000 and $60,000, respectively, which was a frac-
tion of the cost of a mainframe computer.
The DEC PDP series of minicomputers became popular in the 1960s. The PDP-8 
minicomputer was released in 1965, and it was a 12-bit machine with a small instruc-
tion set. The PDP-11 was a highly successful series of 16-bit minicomputers, and it 
remained a popular product for over 20 years from its release in 1970 to the early 1990s.
Gene Amdahl was the chief architect for the IBM System/360, and he resigned 
from IBM to set up Amdahl Corporation in 1970. His goals were to develop a main-
frame that would provide better performance than the existing IBM machines and 
do so a lower cost, as well as being compatible with IBM hardware and software.
Amdahl Corporation launched its first product, the Amdahl 470V/6, in 1975. 
This was an IBM S/370 compatible mainframe that could run IBM software, and so 
it was an alternative to a full IBM proprietary solution. It meant that companies 
Key Topics
DEC
Minicomputers
PDP-11
VAX-11/780
Amdahl 470
IBM System/370

104
around the world now had the choice of continuing to run their software on IBM 
machines or purchasing the cheaper and more powerful IBM compatibles produced 
by Amdahl. Amdahl Corporation became a major competitor to IBM in large-scale 
computer placements.
Amdahl Corporation’s success led to a price war with IBM, with the latter offer-
ing discounts to its customers to protect its market share.
9.2  DEC’s Minicomputers
Ken Olsen and Harlan Anderson founded Digital Equipment Corporation (DEC) in 
1957. It was a spin off from MIT’s Lincoln computer laboratory, and it was an inno-
vative and forward-thinking company. It became the second largest computer com-
pany in the world in the late 1980s, with revenues of over $14 billion and over 
100,000 employees. It dominated the minicomputer era from the 1960s to the 1980s, 
with its PDP and VAX series of computers, which were very popular with the engi-
neering and scientific communities.
DEC’s first computer, the “Programmed Data Processor” (PDP-1), was released 
in 1961 (Fig. 9.1). This 18-bit machine was a relatively inexpensive computer for 
the time, and it cost $110,000. The existing IBM mainframes were substantially 
more expensive, and so DEC’s minicomputers were relatively affordable to busi-
nesses. It was a simple and reasonably easy to use computer with 4000 words 
of memory.
The PDP series of minicomputers were elegant and reasonably priced and domi-
nated the new minicomputer market segment. They were an alternative to the mul-
timillion dollar mainframe computers offered by IBM to large corporate customers. 
Research laboratories, engineering companies, and other organizations with large 
computing needs all used DEC’s minicomputers.
The PDP-8 minicomputer (Fig. 7.3) was released in 1965, and it was a 12-bit 
machine with a small instruction set. It was a major commercial success for DEC 
with many sold to schools and universities. The PDP-11 was a highly successful 
series of 16-bit minicomputer, and it remained a popular product for over 20 years 
from the 1970s to the 1990s.
Gordon Bell was one of the earliest employees of the company, and he played an 
important role in the development of the PDP family of minicomputers. He designed 
the multiplier/divider unit and the interrupt system for the PDP-1 computer, which 
built upon work done at the MIT Lincoln Laboratory. He later became vice presi-
dent of research and development at DEC, and he was the architect of several PDP 
computers. He later led the development of the 32-bit VAX series of computers, and 
he was involved in the design of around 30 microprocessors.
The VAX series of minicomputers were derived from the best-selling PDP-11, 
and the VAX was the first widely used 32-bit minicomputer. The VAX-11/780 was 
released in 1978, and it was a major success for the company. The VAX product line 
9  Minicomputers and Later Mainframes

105
was a competitor to the IBM System/370 series of mainframe computers. The VAX 
minicomputers used the Virtual Memory System (VMS) operating system.
The rise of the microprocessor and microcomputer led to the availability of low 
cost personal computers, and this later challenged DEC’s product line. DEC was 
slow in recognizing the importance of these developments, and Olsen’s statement 
from the mid-1970s “There is no need for any individual to have a computer in his 
home” suggests that DEC were totally unprepared for the revolution in home and 
personal computing and its threat to DEC’s business. DEC was too late in respond-
ing to the paradigm shift in the industry, and this proved to be fatal. Compaq 
acquired DEC in 1998 for $9.8 billion, and HP later acquired Compaq.
9.2.1  PDP-11
The PDP-11 (Fig. 9.2) was a family of 16-bit minicomputers produced by DEC 
from 1970 up to the early 1990s. It was designed by Harold McFarland, with the 
prototype ready in 1969, and the PDP-11 released in 1970. There were several mod-
els in the PDP-11 family.
It was one of DEC’s most successful computers, with over 600,000 machines 
sold. It was the only 16-bit computer made by the company, as its successor was the 
32-bit VAX:11 series. It started its life as a minicomputer and ended its life as micro/
super-microcomputer. The release price of the PDP-11 in 1970 was a very afford-
able $20,000.
Fig 9.1  The PDP-1 computer
9.2  DEC’s Minicomputers

106
Its central processing unit had eight 16-bit registers, six general-purpose regis-
ters, the stack pointer, and a program counter. It included software such as an editor, 
debugger, and utilities. The size of its memory was 128 KB.
The PDP-11 was very useful for multiuser and multitask applications, and one of 
the earliest versions of the UNIX operating system ran on a PDP-11/20 in 1973 (the 
first version was written in assembly language and ran on a PDP-7). The VAX line 
at Digital began as an enhancement to the PDP-11 architecture.
9.2.2  The VAX 11/780
The Virtual Address eXtension (VAX) was a family of minicomputers produced by 
DEC from the mid-1970s up to the late 1980s. This family used processors imple-
menting the VAX instruction set architecture, and its members included minicom-
puters such as the VAX-11/780, /782, /784, /785, /787, /788, /750, /725, and /730. 
The VAX product line was a competitor to the IBM System/370 series of computers.
The VAX series was derived from the PDP-11 minicomputer and the VAX-11/780 
(Fig. 9.3) was the first member of the family. It was the first widely used 32-bit 
Fig. 9.2  PDP-11
9  Minicomputers and Later Mainframes

107
minicomputer, and it was released in 1978. It was the first one MIPS (Million 
Instructions per Second) machine, and it was a major success for the company.
Several programming languages including Fortran-77, BASIC, COBOL, and 
Pascal were available for the machine. The VAX-11/780 used the DEC VMS operat-
ing system, which was a multiuser, multitasking, and virtual memory operating sys-
tem. The VAX-11/780 remained the base system that every computer benchmarked 
its speed against for many years.
It supported 128KB to 8MB of memory through one or two memory controllers, 
and the memory was protected with error correcting codes. Each memory controller 
could support 128KB to 4MB of memory. For more detailed information on DEC, 
see [Sch:04].
9.3  The War Between IBM and Amdahl
Gene Amdahl (Fig. 8.2) resigned from IBM to set up Amdahl Corporation in 1970, 
and his goals were to develop a mainframe that would be compatible with the IBM 
System/360. Further, he intended that it would provide a superior performance at a 
Fig. 9.3  VAX-11/780
9.3  The War Between IBM and Amdahl

108
lower cost than the existing IBM machine. Amdahl revised his plans to launch an 
IBM compatible System/370 mainframe following IBM’s introduction of its IBM 
System/370 mainframe.
Amdahl Corporation launched its first product, the Amdahl 470V/6, in 1975. 
This was an IBM System/370 compatible mainframe that could run IBM software, 
and so it was an alternative to a full IBM proprietary solution. It meant that compa-
nies around the world now had the choice of continuing to run their software on 
IBM machines or purchasing the cheaper and more powerful IBM compatibles pro-
duced by Amdahl.
Amdahl’s first customer was the NASA Goddard Institute for Space Studies, 
which was based in New York. The Institute needed a powerful computer to track 
data from its Nimbus weather satellite, and it had a choice between a well-­established 
company such as IBM and an unknown company such as Amdahl. It seemed likely 
that IBM would be the chosen supplier. However, the institute was highly impressed 
with the performance of the Amdahl 470 V/6, and its cost was significantly less than 
the IBM machine.
The Amdahl 470 competed directly against the IBM System 370 family of main-
frames. It was compatible with IBM hardware and software but cheaper than the 
IBM product: that is, the Amdahl machines provided better performance for less 
money. Further, the machine was much smaller than the IBM machine due to the use 
of large-scale integration (LSI) with many integrated circuits on each chip. This 
meant that the Amdahl 470 was one-third of the size of IBM’s 370. It was over twice 
as fast and sold for about 10% less than the IBM 370.
IBM’s machines were water-cooled, while Amdahl’s were air-cooled, which 
decreased installation costs significantly. Machine sales were slow initially due to 
concerns over Amdahl Corporation’s long-term survival, and the risks of dealing 
with a new player. IBM had a long established reputation as the leader in the com-
puter field. The University of Michigan was Amdahl’s second customer, and it used 
the 470 in its education center. Texas A&M was Amdahl’s third customer, and they 
used the 470 for educational and administrative purposes. Amdahl Corporation was 
well on its way to success, and by 1977 it had over fifty 470 V/6 machines installed 
at various customer sites.
IBM launched a new product, the IBM 3033, in 1977 to compete with the Amdahl 
470. However, Amdahl Corporation responded with a new machine, the 470 V/7, 
which was one and a half times faster than the 3033, and only slightly more expen-
sive. Customers voted with their feet and chose Amdahl as their supplier, and by late 
1978, it had sold over a hundred of the 470 V/7 machines.
IBM introduced a medium-sized computer, the 4300 series, in early 1979, and in 
late 1980, it announced plans for the 3081 processor which would have twice the 
performance of the existing 3033 on its completion in late 1981. In response, 
Amdahl announced the 580 series (Fig. 9.4), which would have twice the perfor-
mance of the existing 470 series. The 580 series was released in mid-1982, but their 
early processors had some reliability problems and lacked some of the features of 
the new IBM product.
9  Minicomputers and Later Mainframes

109
Amdahl moved into large system multiprocessor design from the mid-1980s. It 
introduced its 5890 model in late 1985, and its superior performance allowed 
Amdahl to gain market share and increase its sales to approximately $1 billion in 
1986. It now had over 1300 customers in around 20 countries around the world. It 
launched a new product line, the 5990 processor, in 1988, and this processor outper-
formed IBM by 50%. Customers voted with their feet and chose Amdahl as their 
supplier.
It was clear that Amdahl was now a major threat to IBM in the high-end main-
frame market. Amdahl had a 24% market share and annual revenues of $2 billion at 
the end of 1988. This led to a price war with IBM, with the latter offering discounts 
to its customers to protect its market share. Amdahl responded with its own dis-
counts, and this led to a reduction in profitability for the company.
The IBM personal computer was introduced in the early 1980s, and by the early 
1990s, it was clear that the major threat to Amdahl was the declining mainframe 
market. Revenue and profitability fell, and Amdahl shut factory lines and cut staff 
numbers. By the late 1990s, Amdahl was making major losses, and there were con-
cerns about the future viability of the company.
It was clear by 2001 that Amdahl could no longer effectively compete against 
IBM following IBM’s introduction of its 64-bit zSeries architecture. Amdahl had 
invested a significant amount in research on a 64-bit architecture to compete against 
the zSeries, but the company estimated that it would take a further $1 billion and 
two more years to create an IBM-compatible 64-bit system. Further, it would be 
Fig. 9.4  Amdahl 5860. (Courtesy of Robert Broughton, University of Newcastle)
9.3  The War Between IBM and Amdahl

110
several years before they would gain any benefit from this investment as there were 
declining sales in the mainframe market due to the popularity of personal computers.
By late 2001, the sales of mainframes accounted for just 10% of Amdahl’s rev-
enue, with the company gaining significant revenue from the sale of Sun servers. 
Amdahl became a wholly owned subsidiary of Fujitsu in 1997, and it exited the 
mainframe business in 2002. Today, it focuses on the server and storage side, as well 
as on services and consulting.
For more detailed information on Gene Amdahl, Amdahl Corporation, IBM, and 
Digital Equipment Corporation, see [ORg:13, ORg:15].
9.4  Review Questions
9.5  Summary
The minicomputer was a new class of low-cost computers that arose during the 
1960s. The development of minicomputers was facilitated by the introduction of 
integrated circuits, as this helped to reduce cost and size of computers. Minicomputers 
were distinguished from the large mainframe computers by price and size, and they 
formed a class of the smallest general-purpose computers.
DEC introduced minicomputers from the early 1960s and the PDP-11 was a 
highly successful series of 16-bit minicomputers, and remained popular from the 
1970s to the 1990s. The VAX series of minicomputers were derived from the 
PDP-11, and it was the first widely used 32-bit minicomputer.
The rise of the microprocessor and microcomputer led to the availability of low-­
cost home and personal computers, and this paradigm shift later challenged the 
mainframe and minicomputer market. DEC was too late in responding to the para-
digm shift in the industry.
Gene Amdahl set up Amdahl Corporation in 1970, and his goals were to develop 
a mainframe that would be compatible with the IBM System/360. Amdahl’s main-
frames were compatible with IBM computers but delivered superior performance, 
and this gave companies the choice of continuing to run their software on IBM 
	1.	
What is a minicomputer?
	2.	
What factors led to the introduction of the minicomputer?
	3.	
Describe the achievements of Gene Amdahl.
	4.	
Describe the competition between Amdahl Corporation and IBM in 
the mainframe market.
	5.	
What factors led to the demise of DEC and Amdahl?
	6.	
What could DEC and Amdahl done differently?
	7.	
Describe the achievements of Gordon Bell.
9  Minicomputers and Later Mainframes

111
machines or purchasing the cheaper and more powerful IBM compatibles produced 
by Amdahl.
Amdahl became a major threat to IBM in the high-end mainframe market, as 
customers placed orders with Amdahl at IBM’s expense. However, as the main-
frame market declined in the 1990s, Amdahl failed to adapt to the rise of the per-
sonal computer, and it went through major financial difficulties and it was taken 
over by Fujitsu.
9.5  Summary

113
© The Author(s), under exclusive license to Springer Nature 
Switzerland AG 2021
G. O’Regan, A Brief History of Computing, 
https://doi.org/10.1007/978-3-030-66599-9_10
Chapter 10
The Microprocessor Revolution
10.1  Introduction
A microprocessor is a central part of a modern personal computer (or computer 
device). It integrates the functions of a central processing unit (the part of a com-
puter that processes the program instructions) onto a single integrated circuit and 
places a vast amount of processing power on a tiny chip.
Intel’s invention of the microprocessor in 1971 was a revolution in computing, 
and it placed the power of a computer on a tiny chip. It was initially developed as an 
enhancement to allow users to add more memory to their units. However, it soon 
became clear that the microprocessor had great potential for everything from calcu-
lators to cash registers and traffic lights. Its invention made personal computers, 
tablets, and mobile phones possible.
Computers in the 1960s were large and expensive and were available only to a 
small number of individuals and government laboratories. The invention of the tran-
sistor by Shockley and others at Bell Labs and the later invention of the integrated 
circuit by Jack Kirby of Texas Instruments helped to reduce the size and cost of a 
computer. However, large-scale integration where a large number of transistors 
could be placed onto a silicon chip was still a long way away.
Several employees left Fairchild Semiconductors in the late 1960s to form their 
own semiconductor companies in the Silicon Valley area. They formed companies 
such as Intel, National Semiconductors, and Advanced Micro Devices (AMD). Intel 
began operations making memory chips and it delivered its first product, the 64-bit 
SRAM chip (the 3101), to Honeywell in 1969. It introduced a DRAM chip (the 
1103) in 1970, and in 1971, it introduced the microprocessor, an invention that 
transformed the computing field.
Key Topics
Microprocessor
Intel 4004
Intel 8008
Intel 8080
Intel 8088
Motorola 68000

114
10.2  Invention of the Microprocessor
The invention of the microprocessor (initially called microcomputer) in 1971 was a 
revolution in computing, with the power of a computer now available on a tiny 
microprocessor chip.
The microprocessor is essentially a computer on a chip, and its invention made 
hand-held calculators and personal computers (PCs) possible. Intel’s microproces-
sors are used on the majority of personal computers and laptops around the world.
The invention of the microprocessor happened by accident rather than design. 
The Nippon Calculating Machine Corporation (later known as Busicom), a Japanese 
company, requested Intel to design a set of integrated circuits for its new family of 
high-performance programmable calculators. At that time, it was standard practice 
to custom design all logic chips for each customer’s product, and this clearly limited 
the applicability of a logic chip to a specialized domain.
The design proposed by Busicom required 12 integrated circuits. Tedd Hoff, an 
Intel engineer, studied Busicom’s design and he rejected it as unwieldy. He pro-
posed a more elegant solution requiring just four integrated circuits, and his design 
included a chip that was a general-purpose logic device (microprocessor) that 
derived its application instructions from the semiconductor memory. Busicom 
accepted his proposed design, and Intel engineers then implemented it.
Hoff’s 4004-microprocessor design included a central processing unit (CPU) on 
one chip. It contained 2300 transistors on a one-eighth by one-sixth-inch chip sur-
rounded by three ICs containing ROM, shift registers, input/output ports, and RAM.
Busicom had exclusive rights to the design and components, but following dis-
cussion and negotiations, Busicom agreed to give up its exclusive rights to the chips. 
Intel shortly afterward announced the availability of the first microprocessor, the 
Intel 4004 (Fig. 10.1).
This was the world’s first microprocessor, and although it was initially developed 
as an enhancement to allow users to add more memory to their units, it soon became 
clear that the microprocessor could be applied to many other areas.
This small Intel 4004 microprocessor chip was launched in late 1971, and it 
could execute 60,000 operations per second. The tiny chip had an equivalent com-
puting power as the large ENIAC computer that used 18,000 vacuum tubes and took 
up the space of an entire room.
The Intel 4004 sold for $200 and for the first time affordable computing power 
was available to designers of all types of products. The introduction of the micro-
processor was a revolution in computing, and its invention had applications to 
everything from traffic lights to medical instruments and to the development of 
home and personal computers.
Gary Kildall was one of the early people to recognize the potential of the micro-
processor as a computer in its own right, and he began writing experimental pro-
grams for the Intel 4004 microprocessor in the early 1970s. Kildall worked as a 
consultant with Intel on the later 8008 and 8080 microprocessors.
10  The Microprocessor Revolution

115
He developed the first high-level programming language for a microprocessor 
(PL/M) in 1973, which enabled programmers to write applications for microproces-
sors. He developed the CP/M operating system (Control Program for 
Microcomputers) in the same year. CP/M allowed the Intel 8080 microprocessor to 
control a floppy disk drive allowing files to be read and written to and from an eight-­
inch floppy disk. CP/M made it possible for computer hobbyists and companies to 
build the first home computers.
Kildall made CP/M hardware independent by creating a separate module called 
the BIOS (Basic Input/Output System). He added several utilities such as an editor, 
debugger, and assembler, and by 1977 several manufactures were including CP/M 
with their systems. He set up Digital Research Inc. (DRI) in 1976 to develop, mar-
ket, and sell the CP/M operating system.
10.3  Early Microprocessors
Intel has developed more and more powerful microprocessors since its introduction 
of the Intel 4004. The Intel 8008 was launched in 1972, and this was a reasonably 
successful product. It led to the 8-bit Intel 8080 microprocessor, which was released 
in 1974. The Intel 8080 was the first general-purpose microprocessor, and it was 
sold for $360: that is, a whole computer on one chip was sold for $360, while con-
ventional computers sold for thousands of dollars. The Intel 8080 soon became the 
industry standard, and Intel became the industry leader in the 8-bit market. The 
8080 played an important role in starting home computer development, as it attracted 
the interest of computer developers and engineers.
Motorola introduced its first microprocessor, the 8-bit 6800 microprocessors 
(Fig. 10.2) in 1974, and this microprocessor was used in automotive, computing, 
Fig. 10.1  Intel 4004 
microprocessor
10.3  Early Microprocessors

116
and video games. It contained over 4000 transistors. It competed against the Intel 
8080 microprocessor, and it was used in some early home computer kits.
National Semiconductors introduced its 16-bit IMP-16 in 1973, and an 8-bit ver-
sion, the IMP-8, in 1974. Texas Instruments introduced the first single chip micro-
processor, the PACE, in 1974, and it introduced its first 16-bit microprocessor, the 
TMS 9900, in 1976. MOS Technology introduced its 8-bit 6502 in 1975, and Zilog 
introduced its Z80 in 1976.
The 16-bit Intel 8086 was introduced in 1978, but it soon faced competition from 
Motorola, which introduced its 16/32-bit 68000 microprocessor in 1979. The Intel 
8088 is an 8-bit variant of the 8086, and it was introduced in 1979. The Motorola 
68000 was a hybrid 16/32-bit microprocessor that had a 16-bit data bus, but it could 
perform 32-bit calculations internally. It was used on various Apple Macintosh 
computers, the Atari ST, and the Commodore Amiga.
The first single chip 32-bit microprocessor was AT&T Bell Labs BELLMAC-32A, 
which was introduced in 1982. Motorola introduced its 32-bit 68020 microproces-
sor in 1984, and this microprocessor contained 200,000 transistors on a three-­
eighths-­inch square chip.
IBM considered several microprocessors for its IBM PC, including the IBM 801 
processor, the Motorola 68000 microprocessor, and the Intel 8088 microprocessor. 
IBM chose the Intel 8088 chip (which was cheaper than the 16-bit Intel 8086), and 
it took a 20% stake in Intel leading to strong ties between both companies.
Today, Intel’s microprocessors are used on most personal computers around the 
world, and the contract to supply the Intel 8088 microprocessor was a major turning 
point for the company. Intel had been focused more on the sale of dynamic random 
access memory chips, with sales of microprocessors in thousands or in tens of thou-
sands. However, sales of microprocessors rocketed following the introduction of the 
IBM PC, and soon sales were in tens of millions of units.
The introduction of the IBM PC was a revolution in computing, and there are 
hundreds of millions of computers in use around the world today. It placed comput-
ing power in the hands of ordinary users, and today’s personal computers are more 
powerful than the mainframes that were used to send man to the moon. The cost of 
computing processing power has fallen exponentially since the introduction of the 
first microprocessor, and Intel has played a key role in squeezing more and more 
transistors onto a chip leading to more and more powerful microprocessors and 
personal computers.
Fig. 10.2  Motorola 6800 
microprocessor
10  The Microprocessor Revolution

117
10.4  A Selection of Semiconductor Companies
Robert Noyce and Gordon Moore founded Intel (Integrated Electronics) in 1968. 
Today, it is an American semiconductor giant with headquarters at Santa Clara in 
California. It is one of the largest semiconductor manufacturers in the world, with 
plants in the United States, Europe, and Asia. It has played an important role in 
shaping the computing field with its invention of the microprocessor in 1971. It is 
the inventor of the x86 series of microprocessors that are used in most personal 
computers, and the company is renowned for its leadership in the microprocessor 
industry, and for its excellence and innovation in microprocessor design and 
manufacturing.
Noyce and Moore left Fairchild Semiconductors to set up Intel, and the initial 
focus of the company was on semiconductor memory products, and to make semi-
conductor memory practical. Its goal was to create large-scale integrated (LSI) 
semiconductor memory, and it introduced a number of products including the Intel 
1103, which was a one-kilobit (KB) dynamic random-access memory (DRAM) 
integrated circuit.
Motorola set up a research lab in 1952 to take advantage of the potential of semi-
conductors, and by 1961 it was mass-producing semiconductors at a low cost. It 
introduced a transistorized walkie-talkie in 1962, as well as transistors for its Quasar 
televisions. Its microprocessors have played an important role in the computing 
field. These include the influential 68000 and Power PC architecture, which were 
used in the Apple Macintosh and Power Macintosh personal computers. Motorola’s 
semiconductor business was spun off to become a separate company called Freescale 
Semiconductor Inc. in 2004.
Advanced Micro Devices (AMD) was formed by Jerry Sanders and several of his 
colleagues from Fairchild Semiconductors in 1969. It initially acted as a second 
source supplier of microchips designed by Fairchild and National Semiconductors, 
and it later acted as second supplier for the x86 chips produced by Intel. AMD pro-
duces microprocessors, motherboards, chipsets, and it is the second largest supplier 
of x86-based microprocessors.
National Semiconductors was founded in Connecticut by Bernard Rothlein and 
several of his colleagues from Sperry-Rand Corporation. It introduced the 16-bit 
IMP-16 microprocessor in 1973, and the 8-bit version, the IMP-8, in 1974. National 
Semiconductors was taken over by Texas Instruments in 2011.
Texas Instruments (TI) is an American electronics company that was formed in 
1951, and its headquarters are in Dallas. It is one of the largest manufacturers of 
semiconductors in the world, and it produces a wide range of semiconductor prod-
ucts, including chips for mobile phones, calculators, micro controllers, digital signal 
processors, analog semiconductors, and multicore processors.
It commenced research on transistors in the early 1950s, and it introduced one of 
the first transistor radios in 1954. It invented the integrated circuit in 1958; PACE, 
the first single chip microprocessor, was introduced in 1974; and the TMS 9900, its 
first 16-bit microprocessor, was released in 1976.
10.4  A Selection of Semiconductor Companies

118
MOS Technologies was formed in 1969 initially as a second supplier of calcula-
tor chips for Texas Instruments. Several Motorola designers of the Motorola 6800 
microprocessor joined the company in 1975, and their knowledge allowed MOS to 
develop the 6501 and 6502 microprocessors. MOS Technologies was taken over by 
Commodore in 1976.
Philips Semiconductors was founded in the Netherlands in the early 1950s, and 
it was spun off by Philips to become NXP Semiconductors in 2006. NXP merged 
with Freescale Semiconductors (formerly Motorola Semiconductors) in 2015, and 
the merged company continues operations as NXP Semiconductors.
10.5  Review Questions
10.6  Summary
A microprocessor is a central part of a modern personal computer (or computer 
device), and it places a vast amount of processing power on a tiny chip. Intel’s 
invention of the microprocessor in 1971 changed computing forever.
The microprocessor was initially developed as an enhancement to allow users to 
add more memory to their units. However, it soon became clear that the micropro-
cessor had applications to many other areas. Its invention led to personal computers, 
tablets, and mobile phones.
The invention of the microprocessor happened by accident rather than design, 
and it was initially developed as part of the design to allow users to add more mem-
ory to their units. The design solution included a general-purpose chip that derived 
its application instructions from the semiconductor memory. This was the Intel 
4004-microprocessor, which was the first microprocessor.
	1.	 What is a microprocessor?
	2.	 What is the significance of the Intel 4004?
	3.	 Why is the invention of the microprocessor considered a revolution in 
computing?
	4.	 What are the main contributions made by Motorola to the semiconduc-
tor field?
	5.	 Why did so many employees leave Fairchild Semiconductors to set up 
companies in Silicon Valley? What companies did they form?
	6.	 What are the main contributions made by Intel to the semiconductor field?
	7.	 Explain the significance of PL/M and CP/M.
10  The Microprocessor Revolution

119
© The Author(s), under exclusive license to Springer Nature 
Switzerland AG 2021
G. O’Regan, A Brief History of Computing, 
https://doi.org/10.1007/978-3-030-66599-9_11
Chapter 11
Home Computers
11.1  Introduction
The invention of the microprocessor was a revolution in computing, and it led to the 
development of home and personal computers. We consider a selection of home and 
personal computers in this chapter, including early home computers such as the 
MITS Altair 8800; the Apple I and II computers; the Commodore PET computer; 
the Atari 400 and 800 computers; and the Commodore 64 computer. We discuss 
later Atari and Amiga computers; and the Apple Macintosh computer, which was a 
major milestone in computing. We will discuss the introduction of the IBM personal 
computer in Chap. 12.
Many of the early home computers discussed in this chapter were based on the 
8-bit MOS 6502 microprocessor. The MITS Altair 8800 was based on the Intel 8080 
microprocessor, and it was one of the earliest home computers when it was intro-
duced in late 1974.
Later, home and personal computers used a variety of microprocessors. The ZX 
spectrum home computer was based on the 8-bit Zilog Z80 microprocessor; the 
Apple Macintosh was based on the Motorola 68000 microprocessor, as was the 
Amiga 1000. The Atari personal computer was based on the Intel 8088 
microprocessor.
We start with a discussion of the Xerox Alto computer, which was developed at 
Xerox PARC. This computer pioneered several key concepts in personal comput-
ing, and it had a major impact on the design of the Apple Macintosh.
Key Topics
Xerox Alto
MITS Altair 8800
Apple I and II computers
Atari 400 and 800
Commodore PET
Amiga
Commodore 64
Sinclair ZX Spectrum
Apple Macintosh

120
11.2  Xerox Alto Personal Computer
The Xerox Alto (Fig. 11.1) was one of the earliest personal computers, and it was 
introduced in early 1973. Chuck Thacker and others at Xerox designed it, and it was 
one of the first computers to use a mouse driven graphical user interface. It was 
designed for individual rather than home use, and a single person sitting at a desk 
used it. It was essentially a small minicomputer rather than a personal computer, and 
it was unlike modern personal computers, in that it was not based on the micropro-
cessor. The significance of the Xerox Alto is that it had a major impact on the design 
of early personal computers, and especially on the design of the Apple Macintosh 
computer.
Butler Lampson wrote a famous memo to the management in Xerox in 1972 
[Lam:72], in which he requested funds to construct a number of Alto workstations. 
He made the case for the development of the Alto, and he outlined his vision of 
personal computing in the memo. His vision described a broad range of applications 
to which the Xerox Alto could be applied.
He outlined his vision of distributed computing, where several Xerox Altos 
workstations would form a network of computers, with computer users having their 
own files, and communicating with other users to interchange or share information. 
Lampson argued that the development of the Alto would allow the theory that cheap 
Fig. 11.1  Xerox Alto
11  Home Computers

121
personal computers would be extremely useful to be tested, and demonstrated com-
prehensively to be the case.
This memo led to the development of a network of Altos in the mid-1970s, the 
development of Ethernet technology for connecting computers in a network, the 
development of a mouse-driven graphical user interface, the development of a 
WYSIWYG editor, laser printing and the development of the Smalltalk object-­
oriented programming language.
The cost of the Alto machine was approximately $10,000, and this was signifi-
cantly less than the existing mainframes and minicomputers. The machine was 
capable of performing almost any computation that a DEC PDP-10 machine could 
perform. For a more detailed account of the contributions of Xerox PARC to the 
computing field, see [Hil:00].
11.3  MITS Altair 8800
Micro Instrumentation and Telemetry Systems (MITS) was founded by Ed Roberts 
and others in 1969. Roberts had a background in electronics from the US military, 
and the company began in Robert’s garage in New Mexico. Its initial focus was to 
design and sell electronic kits to model rocket enthusiasts, which had become a 
popular hobby in the 1960s, due to manned space flights and the race to the moon.
The next product that the company introduced was the MITS 816 calculator kit, 
which included six LSI integrated circuits designed to make a calculator with the 
four basic arithmetic functions. The calculator kit featured on the November 1971 
cover of Popular Electronics, which was a popular American electronics magazine 
that appeared from the mid-1950s to the late 1990s.
MITS began working on the Altair 8800 home computer (Fig. 11.2) in 1974, and 
the prototype was available in October of that year. The cover page of the January 
1975 edition of Popular Electronics featured an early design of the Altair 8800, and 
this publicity helped in generating sales that vastly exceeded expectations. Over 
5000 machines were delivered by August 1975, and the home computer kit version 
(which was assembled by the customer) cost $439, whereas the fully assembled 
version cost $621.
The home kit included assembly instructions, a metal case, a front panel with 
switches, a power supply, a motherboard with expansion slots, and various cards to 
plug into the expansion slots, as well as any other components required to build the 
computer. The actual assembly was quite a challenge as it involved careful soldering 
and assembly. There was no actual keyboard or monitor, which meant that the task 
of programming the machine was non trivial, and required the user to program in 
machine language and watch the LEDs on the front panel to get the results. Several 
expansion cards (e.g., for keyboard, monitor and data storage) were soon released, 
and made it easier to use. The Altair 8800 used the 8-bit Intel 8080 microprocessor, 
which was introduced in 1974.
11.3  MITS Altair 8800

122
Bill Gates and Paul Allen developed a BASIC interpreter for the Altair 8800, and 
the 4k/8k versions of BASIC were released in July 1975. It cost the customer an 
additional $60/$75 when purchasing an Altair 8800. Gates and Allen formed 
Microsoft later in 1975, and Altair BASIC was their first product.
11.4  Apple I and II Home Computers
Steve Jobs and Steve Wozniak formed Apple Computers in 1976, and the company 
commenced operations in Job’s family garage. Their goal was to develop a user-­
friendly alternative to the existing mainframe and minicomputers produced by IBM 
and Digital. Wozniak was responsible for product development and Jobs for market-
ing. Jobs and Wozniak were both college dropouts, and both attended the Homebrew 
Computer Club of computer enthusiasts in Silicon Valley during the mid-1970s.
The Apple I computer was released in 1976, and it retailed for $666.66. It gener-
ated over $700,000 in revenue for the company, but it was mainly of interest to 
computer hobbyists and engineers. This was due to the fact that it was not a fully 
assembled personal computer as such, and it was essentially an assembled mother-
board that lacked features such as a keyboard, monitor, and case. It used a television 
as the display system, and it had a cassette interface to allow programs to be loaded 
and saved. It used the inexpensive MOS Technologies 6502 microprocessor chip, 
which had been released earlier that year, and Wozniak had already written a BASIC 
interpreter for this chip.
The Apple II computer (Fig. 11.3) was released in 1977, and it was a significant 
advance on its predecessor. It was a personal computer with a monitor, keyboard 
and case, and it was one of the earliest computers to come preassembled. It used the 
Fig. 11.2  MITS Altair 
computer. (Photo 
public domain)
11  Home Computers

123
MOS 6502 microprocessor chip, and it was one of the earliest computers to have a 
color display with color graphics.
The BASIC programming language was built in, and it contained 4K of RAM 
(which was could be expanded to 48K). The VisiCalc spreadsheet program was 
released on the Apple II, and this helped to transform the computer into a credible 
business machine. The Apple II retailed for $1299, and it was a major commercial 
success for Apple generating over $139 million in revenue for the company. For 
more detailed information on Apple, see [ORg:15].
11.5  Commodore PET
Commodore Business Machines was a leading North American home computer and 
electronics manufacturing company. It played an important role in the development 
of the home computer industry in the 1970s and 1980s, and it is especially famous 
for its development of the Commodore PET computer, which was very popular in 
the education field. It also developed the VIC-20 and Commodore 64 home comput-
ers, which were popular machines.
Commodore initially manufactured typewriters for the North American market, 
and it diversified into the manufacture of mechanical calculators from the early 
1960s. It introduced both consumer and scientific calculators in the late 1960s, and 
by the early 1970s, it was one of the most popular brands for calculators. The calcu-
lators used Texas Instruments chips but when Texas Instruments entered the calcula-
tor market in the mid-1970s, Commodore was unable to compete with the prices 
offered by Texas.
Commodore purchased the semiconductor company, MOS technologies, with 
the intention of using MOS chips in its calculators. However, Chuck Peddle, one of 
Fig. 11.3  Apple II 
computer. (Photo 
public domain)
11.5  Commodore PET

124
MOS’s employees convinced Commodore that the future was in computers and not 
calculators. Commodore used one of MOS’s Technologies chips, the 8-bit 6502, to 
enter the home computer market in 1977 with the launch of its Commodore Personal 
Electronic Transactor (PET) computer.
This Commodore PET was very popular in the education market and one of its 
models was called the “Teachers PET.” It used the MOS 8-bit 6502 microprocessor, 
which was designed by Check Peddle and others at MOS Technology. The 6502 
controlled the screen, keyboard, the cassette recorder, and any peripherals con-
nected to the expansion ports. The machine used the Commodore BASIC operating 
system. There were several models of the Commodore PET introduced during its 
lifetime including the PET 2001 series, the PET 4000 series, and the Super PET 
8000 series.
The first model introduced was the PET 2001 (Fig. 11.4), which had either 4Kb 
or 8Kb of RAM. It had a built in monochrome monitor with 40 × 25 character 
graphics enclosed in a metal case. It included a magnetic data storage device known 
as a datasette (data + cassette) in the front of the machine as well as a small key-
board. There were complaints with respect to the small keyboard, which soon led to 
the appearance of external replacement keyboards.
The PET 4000-series was launched in 1980, and the 4032 model was very suc-
cessful at schools as its all-metal construction and all-in-one design made it ideal for 
the challenges in the classroom. The 4000-series used a larger 12” monitor and an 
enhanced BASIC 4.0 operating system. Commodore manufactured a successful 
variant called the “Teachers” PET.
Commodore introduced the 8000-series and the last in the series was the 
SuperPET or SP9000. It used the Motorola 6809 microprocessor, and it provided 
support for several programming languages such as BASIC, Pascal, COBOL, and 
FORTRAN. For more detailed information on Commodore, see [ORg:15].
Fig. 11.4  Commodore 
PET 2001 home computer
11  Home Computers

125
11.6  Atari 400 and 800
Atari designed and produced four lines of home and personal computers from the 
late 1970s up to the early 1990s. These were the 8-bit Atari 400 and 800 line; the 
16-bit ST line; the IBM PC compatible series; and the 32-bit series.
The Atari 8-bit series began as a next-generation follow-up to its successful Atari 
2600 Video Game Console. Atari’s management noted the success of Apple in the 
early personal computer market, and they tasked their engineers to transform the 
hardware into a personal computer system. The net result was the Atari 400 and the 
Atari 800 home computers, which were introduced in 1979.
The Atari 800 (Fig. 11.5) came with 8KB of RAM and it retailed for $1000, and 
the Atari 400 was a lower specification version, which retailed for $550. Both 
machines were based on the MOS 6502 microprocessor. The architecture of the 
Atari 400 and 800 machines provided sound and graphics capabilities that were 
superior to competitor products such as the Apple II or the Commodore PET.
The Atari 400 and 800 made an impact on the home computing field, and both 
machines included joystick ports for playing games. Atari BASIC was provided on 
an external cartridge for each machine.
The Atari 400 was Atari’s entry-level computer, and it was designed for younger 
children. It had a membrane keyboard designed to prevent damage from food or 
small objects, and the keys could not be removed or swallowed by children. It was 
initially designed for 4K of memory but as memory costs declined it was shipped 
with 8K (and later 16K). This meant that it could run most cartridge and cassette 
based software. It was connected to a standard television.
The Atari 800 was based on the MOS 6502 microprocessor, and this 8-bit 
machine came with a graphics/audio chipset that allowed it to produce the most 
advanced graphics and sound on an existing home computer system. It could pro-
duce 128 colors (later upgraded to 256 colors using a later chip), and the graphics 
were 320 × 192, which was very advanced for its time. It looked like a standard 
typewriter machine.
Fig. 11.5  The Atari 800 
home computer
11.6  Atari 400 and 800

126
The Atari 400 and 800 were replaced in 1982, initially with the Atari 1200XL 
and then with the Atari 600/800XL line of computers. For more detailed informa-
tion on Atari, see [ORg:15].
11.7  Commodore 64
The Commodore 64 (C64) was a very successful 8-bit home computer introduced 
by Commodore in 1982. Its main competitors at the time were the Atari 400 and 
800, and the Apple II computer. The cost of the C64 machine was $595, which was 
significantly less than its rivals, and Commodore cleverly exploited the price differ-
ence to rapidly gain market share. Approximately fifteen million of the Commodore 
64 machines were sold (Fig. 11.6).
The C64 used the MOS 6501 microprocessor and it came with 64 kilobytes of 
RAM. It had 320 × 200 color graphics with 16 colors using the VIC-II graphics 
chip, and the MOS Sound Interface Device (SID) chip. The SID chip was one of the 
first sound chips to be included in a home computer. The C64 dominated the low-­
end home computer market for most of the 1980s.
It came with the Commodore BASIC, but support for other languages such as 
Pascal and FORTRAN were also available. Programmers also wrote programs in 
assembly language to maximize speed and memory use. The Commodore 64’s 
graphics and sound capabilities were quite advanced for the time, and it was popular 
for computer games.
Commodore published detailed technical documentation to assist programmers 
and enthusiastic users to design and develop applications for the Commodore 64. 
This led to the development of over 10,000 commercial software applications such 
as development tools, games, and office productivity applications for the machine. 
Atari was Commodore’s main competitor, but it kept its technical information secret.
The C64 included a ROM-based version of the BASIC 2.0 programming lan-
guage. There was no operating system as such, and instead the kernel was accessed 
via BASIC commands. BASIC did not allow commands for sound or graphics 
manipulation, and instead the user had to use the ‘POKE’ command to access these 
chips directly.
Fig. 11.6  Commodore 64 
home computer
11  Home Computers

127
The Commodore 64 remained highly popular throughout the 1980s, and it was 
still being sold up to the early 1990s. For a more detailed account of Commodore, 
see [Bag:12].
11.8  Sinclair ZX 81 and ZX Spectrum
Sir Clive Sinclair founded Sinclair Research in 1973 as a consumer electronics 
company. It entered the home computer market in 1980 with the Sinclair ZX 80. 
This home computer retailed for £99.95, and it was the cheapest and smallest home 
computer in the United Kingdom at the time.
The ZX 80 was a stepping-stone for the Sinclair ZX 81 home computer, which 
was introduced in 1981. The ZX 81 was designed by Rick Dickinson to be a small, 
simple, and low-cost home computer for the general public, and it retailed for an 
affordable £69.95. It offered tremendous value for money, and it opened the world 
of computing to those who had been denied access by cost. It was bought mainly for 
educational purposes
The ZX 81 was a very successful product with sales of over 1.5 million units. It 
came with 1KB of memory, which could be extended, to 16KB of memory. It had a 
monochrome black and white display on a UHF television. It was one of the first 
home computers to be used widely by the general public, and it led to a large com-
munity of enthusiastic users. It came with a BASIC interpreter, which enabled users 
to learn about computing, and allowed them to write their first BASIC programs. It 
came with a standard QWERTY keyboard, which had some extra keys, and each 
key had several functions.
Sinclair entered an agreement with Timex, an American company, which allowed 
Timex to produce clones of Sinclair machines for the American market. These 
included the Timex Sinclair 1000 and the Timex Sinclair 1500 which were variants 
of the ZX 81. These were initially successful but soon faced intense completion 
from other American vendors.
The ZX spectrum home computer (Fig. 11.7) was introduced in 1982, and it 
became the best-selling computer in the United Kingdom at that time. Its main com-
petitor was the BBC microcomputer produced by Acorn Computers. However, the 
BBC micro was more expensive and retailed for £299, whereas the ZX spectrum 
was about half its price. The basic model of the ZX Spectrum had 16KB of RAM 
and retailed for £125, whereas the more advanced model had 48KB of RAM and 
retailed for £175. This made the ZX Spectrum significantly cheaper than the exist-
ing Commodore 64 home computer and the newly introduced BBC 
microcomputer.
The ZX spectrum introduced color graphics and sound, and it included an 
extended version of Sinclair’s existing BASIC interpreter. It was an 8-bit home 
computer, and it used an 8-bit Zilog Z80 microprocessor. It initially came in two 
models, and was eventually released in eight different models.
11.8  Sinclair ZX 81 and ZX Spectrum

128
Rick Dickinson and Richard Altwasser designed the ZX Spectrum with Dickinson 
creating the sleek outward design, and the internal hardware was designed by 
Altwasser. Clive Sinclair had emphasized the importance creating a home computer 
substantially cheaper than the rival BBC microcomputer, and so cost was a key fac-
tor in the design of the ZX spectrum.
Cost forced the designers to find new ways of doing things, and they minimized 
the number of components in the keyboard from a few hundred to a handful of mov-
ing parts using a new technology. They used the cost effective 3.5 MHz Z80 proces-
sor, a sound beeper, a BASIC interpreter, and an audio tape as a storage device.
The demand for the ZX Spectrum was phenomenal, as the machine caught the 
imagination of the British public. It was initially targeted as an educational tool to 
help students to become familiar with programming, but it soon became popular for 
playing home video games.
It was a very successful home computer with over five million units sold. It led 
to a massive interest in learning about computing, programming and video games 
among the general public.
The users were supplied with a book from which they could type in a computer 
program into the computer, or they could load a program from a cassette. This 
allowed users to modify and experiment with programs as well as playing com-
puter games.
Its simplicity, versatility, and good design led to companies writing various soft-
ware programs for it, and soon computer magazines and books dedicated to the ZX 
Spectrum were launched with the goal of teaching users how to program the 
machine.
The ZX Spectrum spawned various clones around the world. Countries such as 
the United States, to Russia and India created their own version of the Spectrum.
The ZX Spectrum remained popular throughout the 1980s, and it was officially 
retired in 1988. The Spectrum+ was released in 1984, and this was essentially the 
48K version of the Spectrum with an enhanced keyboard. The Spectrum +128 was 
released in 1986, and it was similar in appearance to the Spectrum + but it had 128K 
of memory.
Fig. 11.7  ZX spectrum
11  Home Computers

129
Sinclair was sold to Amstrad in 1986, and Amstrad created its own models 
including the ZX Spectrum +2, the ZX Spectrum +2A, the ZX Spectrum +3, the ZX 
Spectrum +3A and the ZX Spectrum +3B.
There is a large archive of ZX Spectrum-related material available on line (http://
www.worldofspectrum.org), and it includes software, utilities, games, and tools. 
Today, there are emulators available that allow Spectrum games to be downloaded 
and played on personal computers.
11.9  Apple Macintosh
The Apple Macintosh (Fig. 11.8) was announced during a famous television com-
mercial aired during the third quarter of the Super Bowl in 1984. This was a very 
creative advertisement, and it ran just once on television. It generated more excite-
ment than any other advertisement up to then, and it immediately positioned Apple 
as a creative and innovative company, while implying that its competition (i.e., 
IBM) was stale and robotic.
It presented Orwell’s totalitarian world of 1984, with a lady runner wearing 
orange shorts and a white tee shirt with a picture of the Apple Macintosh running 
towards a big screen, and hurling a hammer at the big brother character on the 
screen. The audience is stunned at the broken screen and the voice over states “On 
January 24th Apple will introduce the Apple Macintosh and you will see why 1984 
Fig. 11.8  Apple 
Macintosh computer. 
(Photo public domain)
11.9  Apple Macintosh

130
will not be like ‘1984’.” Ridley Scott who has directed well-known films, such as 
Alien, Blade Runner, Robin Hood, and Gladiator directed the short film.
The Macintosh project began in Apple in 1979 with the goal of creating an easy-­
to-­use low-cost computer for the average consumer. Jef Raskin initially led it, and 
the project team included Bill Atkinson, Burrell Smith, and others. It was influenced 
by the design of the Apple Lisa, and it employed the Motorola 68000 processor. 
Steve Jobs became involved in the project in 1981 and Raskin left the project. Jobs 
negotiated a deal with Xerox that allowed him and other Apple employees to visit 
the Xerox PARC research center at Palo Alto in California to see their pioneering 
work on the Xerox Alto computer, and their work on a graphical user interface. 
PARC’s research work had a major influence on the design and development of the 
Macintosh, as Jobs was convinced that future computers would use a graphical user 
interface. The design of the Macintosh included a friendly and intuitive graphical 
user interface (GUI), and the release of the Macintosh was a major milestone in 
computing.
The Macintosh was a much easier machine to use than the existing IBM PC. Its 
friendly and intuitive graphical user interface was a revolutionary change from the 
command-driven operating system of the IBM PC, which required the users to be 
familiar with its operating system commands. The introduction of the Mac GUI is 
an important milestone in the computing field, and it was 1990 before Microsoft 
introduced its Windows 3.0 GUI driven operating system.
Apple intended that the Macintosh would be an inexpensive and user-friendly 
personal computer that would rival the IBM PC and compatibles. However, it was 
more expensive, and retailed for $2495, which was significantly more expensive 
than the IBM PC. Further, initially it had a limited number of applications available, 
whereas the IBM PC had spreadsheets, word processors, and databases applica-
tions, and so it was more attractive to customers. The technically superior Apple 
Macintosh was unable to break the IBM dominance of the market. However, the 
machine became very popular in the desktop publishing market, due to its advanced 
graphics capabilities.
11.10  Later Commodore and Atari Machines
Commodore purchased the start-up company called Amiga Corporation in 1984, 
and it became a subsidiary called Commodore-Amiga. The Amiga family of per-
sonal computers was sold by Commodore in the 1980s and 1990s. The first model, 
the Amiga 1000 (or A1000), was released in 1985, and it became popular for its 
graphical, audio, and multitasking capabilities. The A1000 had a powerful CPU and 
advanced graphics and sound hardware. It was based on the Motorola 68000 series 
of microprocessor, and it had 256 kilobytes of RAM, which could be upgraded with 
a further 256Kb of RAM. It retailed for $1295.
The Amiga 500 (Fig. 11.9) was the best-selling model in the Amiga family, and 
it was released in 1987. It was a highly popular home computer with over six 
11  Home Computers

131
million machines sold. Several other models of the Amiga machines were intro-
duced including the A3000, the A500+, and A600; and the A1200 and A4000 
machines.
The August 1994 edition of the Byte magazine [By:94] spoke highly of the early 
Amiga machines. It called the A1000 machine the first multimedia computer, as it 
was so far ahead of its time with advanced graphics and sound.
Jack Tramiel (the founder and former CEO of Commodore) acquired Atari’s 
home computing division in 1984, and he renamed the company to Atari Corporation. 
Atari designed the 16-bit GUI-based home computer, the Atari ST, in 1985. This 
machine was priced at an affordable $799, and it included a 360KB floppy disk 
drive, a mouse, and a monochrome monitor. A color monitor was provided for an 
extra $200, and the machine came with 512KB of RAM. It used a color graphical 
windowing system called GEM. The Atari ST included two Musical Instrument 
Digital Interface (MIDI) ports, which made it very popular with musicians.
The Atari 1040 ST (Fig. 11.10) was introduced in 1986 and this 16-bit machine 
differed from the Atari ST in that it integrated the external power supply and floppy 
disk drive into one case. It contained 1MB of RAM and retailed for $999. It came 
as a complete system with a base unit, a monochrome monitor, and a mouse. Atari 
released advanced versions of these models, called the Atari 520STE and the Atari 
1040 STE, in 1989. The Atari ST line had an impressive life span starting in 1986, 
and ending with the Atari Mega STE, which was released in 1990.
Atari released its first personal computer, the Atari PC, in 1987. This IBM-­
compatible machine was an 8  MHz 8088 machine with 512KB of RAM and a 
360KB 5.25 inch floppy disk drive in a metal case. It released the Atari PC2 and 
PC3 later that year, and the PC3 included an internal hard disk. The Atari PC4 
included a faster 16MHz 80286 CPU and 1MB of RAM, and it was released the 
same year. The PC5 was released in 1988 and it had a 20MHz 80386 CPU and 
2MB of RAM.
The Atari ABC (Atari Business Computer) was released in 1990. The Atari ABC 
286 version shipped with a range of CPU and storage choices ranging from an 
Fig. 11.9  Amiga 500 
home computer (1987)
11.10  Later Commodore and Atari Machines

132
8MHz to a 20MHz CPU, and a 30 MB to 60 MB hard disk. The Atari ABC 386 ver-
sion included a 20MHz or 40 MHz CPU, and a 40 MB or 80 MB hard disk. The 
ABC 386 shipped with Microsoft Windows 3.0. For more detailed information on 
Atari, see [Edw:11, IGN:14].
There was intense rivalry between the Amiga and Atari families of personal com-
puters. However, players such as IBM, Dell, HP, and Apple now dominate the per-
sonal computer market.
11.11  Atari Video Machines
Atari Inc. laid the foundation for the modern video game industry. It developed 
video games such as Pong, Asteroids, Tempest, Centipede, and Star Wars. It was 
founded by Nolan Bushnell (Fig. 11.11) and Ted Dabney in 1972. Atari designed 
and developed the first arcade video game, Computer Space, later that year. This 
Fig. 11.10  Atari 1040 ST 
home computer
Fig. 11.11  Nolan 
Bushnell
11  Home Computers

133
computer game was functionally quite like an early computer game called Spacewar1, 
and it was not entirely successful, as it was perceived as being a little complicated 
to use. The name “atari” is used in Japanese when a prediction comes through or 
when someone wins the lottery it comes from the Japanese verb “ataru” which 
means “to hit a target” and it is associated with good fortune.
Bushnell developed a fascination for one of the earliest video games, Spacewar, 
while he was a student at the University of Utah. Steve Russell and others developed 
this game on a Digital PDP-1 computer at MIT in the early 1960s.
The field of computer graphics emerged with the development of computer 
graphics hardware, and Ivan Sutherland of MIT (and later the University of Utah) 
played an important role. He developed sketchpad software in the late 1950s that 
allowed a user to draw simple shapes on the computer screen, and he invented the 
first computer-controlled head-mounted display (HMD) in the mid-1960s. The 
University of Utah became the leading research center in computer graphics in the 
late-1960s, and so Bushnell received a solid foundation in the computer graph-
ics field.
Bushnell had worked in an amusement arcade during his school holidays, and it 
occurred to him that a video game could potentially operate as a coin-operated 
machine. Bushnell’s vision was that of an arcade that would contain coin-operated 
video games, which would inspire and challenge teenagers.
Atari Inc. hired Al Alcorn as its first design engineer, and he had previously 
worked with Bushnell and Dabney. Alcom designed and developed Pong 
(Fig.  11.12), which was an arcade version of an existing tennis game2 for the 
Magnavox Odyssey home video game console. Bushnell had attended the demon-
stration of this first-ever home video game console, and Alcom made significant 
improvements to Magnovox’s existing game. The new game was called “Pong,” and 
it was a sports game that simulated table tennis. The player could compete against a 
computer or against another player. Alcom’s improvements included speeding up 
the ball the longer the game went on and adding sound. Pong became popular very 
quickly, and digital table tennis became addictive.
Pong was a commercial success with a single unit earning approximately $40 per 
day, and Atari was soon receiving orders faster than it could deliver them. Pong 
showed that a coin-operated video game could be both popular and profitable, and 
over 8,000 machines were delivered to bars, amusement arcades, and other places 
around the world by 1974. The home version of Pong was released in 1975, and it 
sold 200,000 units in its first year.
Atari did not have any patents protecting Pong, and soon other vendors were 
offering imitation products. Atari continued to innovate and released successful 
Atari cabinets including Space Race, Tank, Gotcha, and Breakout in the mid-to-­
late 1970s.
1 The Spacewar game was developed by Steve Russell and others at MIT in the early 1960s.
2 Atari later settled a court case brought against it by Magnavox over alleged patent infringement 
of Magnovox’s Odyssey tennis game. Magnavox won millions in various patent disputes, and Atari 
became a licensee of Magnovox.
11.11  Atari Video Machines

134
Atari had been looking for a way to bring all its existing arcade game to the home 
market. It designed the Atari Video Computer System (VCS) in 1977, which was 
later marketed as the Atari 2600 (Fig. 11.13). This was a home games console, 
which used the MOS 6052 microprocessor, and it provided an affordable way for 
high-quality video games to be played at home. There were significant financial 
costs associated with the development and manufacture of the VCS, and Bushnell 
made a strategic decision to sell Atari to Warner Communications for $26 million to 
secure the required funding. The Atari VCS was introduced in 1977, and it was 
Fig. 11.12  Original Atari 
Pong video game console
Fig. 11.13  Atari video 
computer system (VCS)
11  Home Computers

135
priced at $199. It would eventually become one of the most successful video games 
consoles, but its initial sales were quite low.
Bushnell left the company in 1978 following disagreements over the direction of 
the company and Ray Kassar took over. By 1979 over a million units of the Atari 
2600 were sold, and over 10 million units were sold in 1982. Atari entered the home 
computer market in 1979 with its release of the Atari 400 and 800 8-bit home com-
puters (discussed earlier in the chapter).
However, despite the success of the Atari 2600, there were deep problems at 
Atari. Warner Communications did not fundamentally understand a technology 
business, and management alienated many of the creative software development 
staff. Several of Atari’s key engineers left the company to form Activision, a new 
company that made third party games for the VCS. Activision’s games were better 
than Atari’s, and third-party software developers were also creating games specifi-
cally for the Atari 2600. This helped sales of the Atari 2600 to soar, but the quality 
of the games being produced by Atari began to deteriorate.
Atari now had three areas of business: its arcade business; its home video game 
business; and its home computer business. However, these three business areas were 
not working closely together, and Warner did not invest sufficiently in new technol-
ogy and product development for future success. This was to prove fatal for the 
company.
The market reaction to Atari’s release of Pac-Man and E. T., The Extra Terrestrial 
in 1982 was very negative, and Atari was left with a large quantity of unsold inven-
tory that depressed prices. Atari’s problems were compounded with the Video game 
crash of 1983, and it lost over $300 million in the second quarter of that year. It was 
also facing major challenges in the home computing market with users moving from 
game machines to home computers. Arcades had become less important as video 
games were now being played at home, and Atari was failing to innovate with new 
products.
Warner sold the home computing part of the Atari business to Jack Tramiel3 in 
1984, and Tramiel later renamed it to Atari Corporation. Atari Corporation devel-
oped and sold video game consoles, video games developed for home use, as well 
as home and personal computers.
Warner held on to its arcade business until 1985 when it sold it to Namco. Atari’s 
arcade business faded into obscurity, but Atari Corporation continued in business as 
a designer of home and personal computers until the early 1990s.
3 Jack Tramiel was the founder of Commodore Business Machines.
11.11  Atari Video Machines

136
11.12  Review Questions
11.13  Summary
The invention of the microprocessor led to the development of home and personal 
computers. Many of the early home computers were based on the 8-bit MOS 6502 
microprocessor, with the MITS Altair 8800 based on the Intel 8080 microprocessor. 
Later, home and personal computers used a variety of microprocessors such as the 
8-bit Zilog Z80 microprocessor; the Motorola 68000 microprocessor, the Intel 8088 
microprocessor; and later Intel microprocessors.
We discussed the Xerox Alto computer, which was developed at Xerox 
PARC. This computer pioneered several key concepts in personal computing, and it 
had a major impact on the design of the Apple Macintosh.
We discussed several early home computers such as the Apple I and II comput-
ers, which were developed by Apple; the Commodore PET, which was introduced 
by Commodore Business Machines; the Atari 400 and 800 computers, which were 
introduced by Atari; the Commodore 64 computer; the Apple Macintosh computer; 
the ZX Spectrum introduced by Sinclair Research; and later Atari and Amiga 
computers.
	1.	
What is the significance of the Xerox Alto in the history of 
computing?
	2.	
Discuss the relevance of Atari to game development and the comput-
ing field.
	3.	
Discuss the accuracy of the message conveyed by Apple in the 1984 
Super bowl commercial that launched the Apple Macintosh.
	4.	
Discuss whether Apple should have received all of the credit for its 
GUI-based operating system on the Macintosh given the pioneering 
work done at Xerox PARC?
	5.	
Describe the relevance of the Apple I and II computers to the com-
puting field.
	6.	
Describe the significance of Sinclair Research to the computing field.
	7.	
Explain the relevance of the MITS Altair 8800 to the computing field.
11  Home Computers

137
© The Author(s), under exclusive license to Springer Nature 
Switzerland AG 2021
G. O’Regan, A Brief History of Computing, 
https://doi.org/10.1007/978-3-030-66599-9_12
Chapter 12
The IBM Personal Computer
12.1  Introduction
The introduction of the IBM Personal Computer in 1981 was a major milestone in 
the computing field. IBM’s traditional approach up to then in product development 
was to develop a full proprietary solution. However, due to the aggressive times-
cales associated with the introduction of the IBM PC, it decided instead to out-
source the development of the microprocessor to a small company called Intel, and 
to outsource the development of the operating system to a small company called 
Microsoft. These decisions would later prove costly to IBM, as Microsoft and Intel 
later became technology giants (at IBM’s expense).
The introduction of the IBM personal computer was a paradigm shift in comput-
ing in that it placed computing power in the hands of millions of people. The previ-
ous paradigm was that an individual user had limited control over a computer, with 
the system administrators controlling the access privileges of the individual users.
The awarding of the contract to develop the operating system to Microsoft later 
proved controversial. IBM had intended awarding the contract to Digital Research 
a company that had developed the CP/M operating system for several microproces-
sors. However, IBM and Digital Research were unable to agree terms (there may 
have been problems with meeting the IBM delivery timescales or the royalties 
demanded by Digital Research may have been excessive), and IBM instead awarded 
the contract to Microsoft (a small company that specialized in providing BASIC 
interpreters). Microsoft hired a consultant to port an existing CP/M operating sys-
tem to the 8088 microprocessor, and it later became clear to Digital Research that 
their software had been used to develop the operating system for the IBM personal 
computer.
Key Topics
Intel 8088
Intel 8086
PC/DOS
MS/DOS
IBM compatible
CP/M
Digital research

138
12.2  The IBM Personal Computer
IBM introduced the IBM Personal Computer (PC) in 1981 as a machine to be used 
by small businesses and users in the home. The IBM goal at the time was to get 
quickly into the home computer market, which was then dominated by Commodore, 
Atari and Apple.
IBM assembled a small team of 12 people led by Don Estridge (Fig. 12.1), and 
their objective was to rapidly get the personal computer to the market. They designed 
and developed the IBM PC within one year, and as time to market was the key driver 
they built the machine with “off-the-shelf” parts from a number of equipment manu-
facturers. The normal IBM approach to the design and development of a computer 
was to develop a full proprietary solution.
The team had intended using the IBM 801 processor, which was being developed 
at the IBM Research Centre in Yorktown Heights. However, they decided instead to 
use the existing Intel 8088 microprocessor, which was inferior to the IBM 801. 
They chose the PC/DOS operating system from Microsoft rather than developing 
their own operating system.
The unique IBM elements in the personal computer were limited to the system 
unit and keyboard. The team decided on an open architecture so that other manufac-
turers could produce and sell peripheral components and software without purchas-
ing a license. They published the IBM PC Technical Reference Manual, which 
included the complete circuit schematics; the IBM ROM BIOS source code; and 
other engineering and programming information.
The IBM PC (Fig. 12.2) was the cheapest IBM computer produced up to then, 
and it was priced at an affordable $1,565. It offered 16 kilobytes of memory (expand-
able to 256 kilobytes); a floppy disk, a keyboard, and a monitor. The IBM personal 
computer became an immediate success, and it became the industry standard.
Fig. 12.1  Don Estridge. 
(Courtesy of IBM archives)
12  The IBM Personal Computer

139
The open architecture led to a new industry of “IBM-compatible” computers, 
which had all of the essential features of the IBM PC, except that they were cheaper. 
The terms of the licensing of PC/DOS operating system gave Microsoft the rights to 
the MS/DOS operating system on the IBM compatible computers, and this led inex-
orably to the rise of the Microsoft Corporation. The IBM Personal Computer XT 
was introduced in 1983. This model had more memory, a dual-sided diskette drive, 
and a high-performance fixed-disk drive. The Personal Computer/AT was intro-
duced in 1984.
The development of the IBM PC meant that computers were now affordable to 
ordinary users, and this led to a huge consumer market for personal computers and 
software. It led to the development of business software such as spreadsheets and 
accountancy packages, banking packages, programmer developer tools such as 
compilers for various programming languages, specialized editors, and com-
puter games.
The introduction of the personal computer was a paradigm shift in computing, 
and it led to a fundamental change in the way in which people worked. It placed 
computing power directly in the hands of millions of people, with individual users 
having complete control over the machine. The previous paradigm was that the 
system administrators strictly controlled the access privileges of the individual 
users, and so individual users had limited control over the computer. The introduc-
tion of the client-server architecture led to the linking of the personal computers 
Fig. 12.2  IBM personal 
computer. (Courtesy of 
IBM archives)
12.2  The IBM Personal Computer

140
(clients) to larger computers (servers). These servers contained large amounts of 
data that could be shared with the individual client computers.
The IBM strategy in developing the IBM personal computer was deeply flawed, 
and it cost the company dearly. IBM had traditionally produced all of the compo-
nents for its machines, but with its open architecture model, any manufacturer could 
now produce an IBM-compatible machine. IBM had outsourced the development of 
the microprocessor chip to Intel, and Intel later became the dominant player in the 
microprocessor industry.
The development of the operating system, PC/DOS (PC Disk Operating System) 
was outsourced to a small company called Microsoft1. This proved to be a major 
mistake by IBM, as the terms of the deal with Microsoft were favorable to the latter, 
and it allowed Microsoft to sell its own version of the operating system (i.e., MS/
DOS) to other manufacturers as the operating system for the many IBM compati-
bles. Intel and Microsoft became technology giants.
12.3  Operating System for IBM PC
Digital Research lost out on the opportunity of a lifetime to supply the operating for 
the IBM personal computer to IBM, and instead it was Microsoft that reaped the 
benefits.
Bloomberg Business Week published an article in 2004 describing the back-
ground to the development of the operating system for the IBM PC, and the failed 
negotiations between Digital Research and IBM on the licensing of the CP/M oper-
ating system. The article was titled “The Man who could have been Bill Gates” 
[Blo:04].
The project was subject to an aggressive delivery schedule, and while tradition-
ally IBM developed a full proprietary solution, it decided instead to outsource the 
development of the microprocessor and the operating system.
The IBM team initially asked Bill Gates and Microsoft in Seattle to supply them 
with an operating system. Microsoft had already signed a contract with IBM to sup-
ply a BASIC interpreter for the IBM PC, but they lacked the expertise in operating 
system development. Gates referred IBM to Gary Kildall at DRI, and the IBM team 
approached Digital Research with a view to licensing its CP/M operating system.
Digital Research was working on a new version of CP/M for the 16-bit Intel 8086 
microprocessor, which had been introduced in 1978. IBM decided to use the lower 
cost Intel 8088 microprocessor (a slower version of the 8086) for its new personal 
computer.
IBM and Digital Research failed to reach an agreement on the licensing of CP/M 
for the IBM PC. The precise reasons for failure are unclear, but some immediate 
problems seem to have arisen with respect to the signing of an IBM non-disclosure 
1 Microsoft was founded by Bill Gates and Paul Allen in 1975.
12  The IBM Personal Computer

141
agreement during the visit. It is unclear whether Kildall actually met with IBM and 
whether there was an informal handshake agreement between both parties. However, 
there was certainly no documented legal agreement between IBM and DRI.
There may also have been difficulties in relation to the amount of royalty pay-
ment being demanded by Digital Research, as well as practical difficulties in achiev-
ing the required IBM delivery schedule (due to Digital Research’s existing 
commitments to Intel). Kildall was superb at technical innovation, but he may have 
lacked the appropriate business acumen to secure a good deal, or he may have over-
sold his hand.
Gates offered to provide an operating system (later called PC/DOS) and BASIC 
to IBM on favorable terms. IBM accepted the offer, and the contract allowed 
Microsoft to market and sell its version (MS/DOS) of the operating systems on IBM 
compatibles.
Gates was aware of the work done by Tim Patterson on a simple quick and dirty 
version of CP/M (called QDOS) for the 8086 microprocessor for Seattle Computer 
Products (SCP). Gates licensed QDOS for $50,000, and he hired Patterson to mod-
ify it to run on the IBM PC for the Intel 8088 microprocessor. Gates then licensed 
the operating system to IBM for a low per-copy royalty fee.
IBM called the new operating system PC/DOS, and Microsoft retained the rights 
to MS/DOS, which was used on IBM-compatible computers produced by other 
hardware manufacturers. In time, MS/DOS would later become the dominant oper-
ating system (eclipsing PC/DOS due to the open architecture of the IBM PC and the 
rapid growth of clones) leading to the growth of Microsoft into a major 
corporation.
DRI released CP/M-86 shortly after IBM released PC DOS. Kildall examined 
PC/DOS, and it was clear to him that it had been derived from CP/M. He was furi-
ous and met separately with IBM and Microsoft, but nothing was resolved. Digital 
Research considered suing Microsoft for copying all of the CP/M system calls in 
DOS 1.0, as it was evident to Kildall that Patterson’s QDOS was a copy of CP/M.
He considered his legal options but his legal advice suggested that as intellectual 
copyright law with regard to software had only been recently introduced in the 
United States, that it was not clear what constituted infringement of copyright. 
There was no guarantee of success in any legal action against IBM, and consider-
able expense would be involved. Kildall threatened IBM with legal action, and IBM 
agreed to offer both CP/M-86 and PC-DOS. However, as CP/M was priced at $240 
and DOS at $60, few personal computer owners were willing to pay the extra cost. 
CP/M was to fade into obscurity.
Perhaps, if Kildall had played his hand differently, he could have been in the 
position that Bill Gates is in today, and Digital Research could well have been, the 
“Microsoft” of the PC industry. Kildall’s delay in developing the operating system 
gave Patterson the opportunity to create his own version. IBM was under serious 
time pressures with the development of the IBM PC, and Kildall may have been 
unable to meet the IBM deadline. This may have resulted in IBM dealing with Gates 
instead of DRI.
12.3  Operating System for IBM PC

142
Further, the size of the royalty fee demanded by Kildall for CP/M was not very 
sensible, as the excessive fee resulted in very low sales for the DRI product, whereas 
if a more realistic price had been proposed, then DRI may have made some reason-
able revenue. Nevertheless, Kildall could justly feel hard done by, and he may have 
viewed Microsoft’s actions as the theft of his intellectual ideas and technical 
inventions.
12.4  Review Questions
12.5  Summary
The introduction of the IBM Personal Computer in 1981 was a major milestone in 
the computing field. IBM’s approach up to then was to develop a full proprietary 
solution. However, due to the timescales associated with the development of the 
IBM PC, it decided instead to outsource the development of the microprocessor to 
a small company called Intel, and to outsource the development of the operating 
system to a small company called Microsoft.
Don Estridge led the IBM team responsible for the introduction of the IBM PC, 
and their goal was to design and develop the IBM PC within one year. They built the 
machine with “off-the-shelf” parts from a number of equipment manufacturers, 
rather than the usual IBM approach developing a full proprietary solution.
The awarding of the contract to develop the operating system to Microsoft later 
proved controversial. IBM had intended awarding the contract to Digital Research 
who had introduced the CP/M operating system for several microprocessors. 
However, negotiations between DR and IBM failed and IBM awarded the contract 
to Microsoft.
	1.	
Why did IBM launch the personal computer?
	2.	
What mistakes did IBM make with its introduction of the IBM PC?
	3.	
Why has Gary Kildall has been described as “the man who could 
have been Bill Gates?”
	4.	
Describe the controversy over the operating system for the IBM PC.
	5.	
Describe IBM’s contributions to the computing field.
	6.	
Describe Intel’s contributions to the computing field.
	7.	
Describe Microsoft’s contributions to the computing field.
12  The IBM Personal Computer

143
© The Author(s), under exclusive license to Springer Nature 
Switzerland AG 2021
G. O’Regan, A Brief History of Computing, 
https://doi.org/10.1007/978-3-030-66599-9_13
Chapter 13
History of Operating Systems
13.1  Introduction
An operating system is a collection of software programs that control the hardware 
of a computer and makes it usable. It makes the computing power of the hardware 
available to the users of the computer, and it manages the hardware to achieve good 
system performance. An operating system manages system hardware such as the 
processors, storage, input/output devices, communication devices, and data, and it 
provides functionality such as sharing hardware among users, scheduling resources 
among users, preventing users from interfering with each other, facilitating input/
output, recovering from errors, and handling network communication.
The earliest computers did not have an operating system, and the user had exclu-
sive control over a large computer for a specified period of time. The user entered 
the program one bit at a time in machine code (initially using mechanical switches 
and later with a stack of punched cards), and waited for the results. People began to 
develop libraries to share code for common activities, and these are in a sense the 
precursor of today’s operating systems.
The earliest operating systems were designed in the 1950s with the goal of mak-
ing more efficient use of expensive computer resources. These batch-processing 
systems ran one job at a time, and programs and data were submitted in groups (or 
batches), where each batch consisted of several jobs (or programs) that were sub-
mitted for processing.
These evolved during the early 1960s into multibatch systems that were designed 
to improve utilization of the expensive computer resources. They could handle sev-
eral diverse jobs at once, and running several jobs offered a way to optimize computer 
utilization. One job could be using the processor while another job could be using the 
Key Topics
MVS
VM
OS/360
UNIX
MS/DOS
Windows
Android
iOS

144
various I/O devices. These later batch-processing systems contained many peripheral 
devices such as card readers, card punches, printers, tape drives, and disk drives.
Jobs were normally submitted on punched cards and computer tape, and often a 
user’s job could sit for hours (days) on an input table until it was processed. However, 
even a very slight error in a program would cause the program to fail, and it would 
require resubmission. This meant that software development in this environment 
was very slow. This led operating system designers to develop the concept of multi-
programming where several jobs are in main memory at once, and the concept of 
interrupts, where an interrupt allows one unit to gain the attention of another, and 
the state of the interrupted unit is saved prior to the processing of the interrupt, and 
restored once processing is complete.
MIT developed the CTSS timesharing system in the early 1960s, and this operat-
ing system ran a conventional batch stream (to ensure high utilization of expensive 
computer resources), but it was also able to give fast responses to users who were 
editing or debugging programs. It was a highly interactive environment where the 
computer provided rapid responses to user requests. IBM began work on the CP/
CMS operating system in 1964, and this would eventually evolve into IBM’s VM 
operating system.
IBM announced the System/360 family of computers in 1964, and the computers 
in the family were designed to use the IBM System/360 operating system (OS/360). 
OS/360 was a batch-oriented operating system, and IBM supported three variants of 
OS/360, which allowed multiprogramming for mid-range and top-range members 
of the family. The other major operating system used in the System/360 was the 
Disk Operating System (DOS/360).1 The IBM System/360 evolved over time into 
the System/370 series.
MIT’s successor to the CTSS operating system was a general timesharing operat-
ing system called “Multics,” and Bell Labs was initially involved in its develop-
ment. UNIX arose out of work on the development of Multics, and it was developed 
at Bell Labs in the early 1970s. It is a multitasking and multiuser operating system.
The IBM PC was introduced in 1981, and IBM outsourced the development of 
the operating system to a small company called Microsoft (discussed in previous 
chapter). The terms of the deal with IBM allowed Microsoft the right to license its 
operating system, MS/DOS, on IBM compatibles, with PC/DOS (or simply DOS) 
reserved for IBM personal computers only. MS/DOS managed floppy disks and 
files, input and output, memory, and it contained an external command processor 
that interpreted user commands and allowed the user to interact with the system.
The Macintosh was a paradigm shift for the computer industry when it was intro-
duced in 1984. Its MAC operating system was GUI based, friendly, intuitive, and 
easy to use, and it was clear that the future of operating systems was in GUI driven 
systems, rather than primitive command-driven operating systems such as MS/DOS.
Microsoft Windows is a family of graphical operating systems developed by 
Microsoft, and it has evolved to become the dominant operating system on laptops 
1 Not to be confused with DOS used on IBM personal computers.
13  History of Operating Systems

145
and personal computers, but it has failed to make an impact on the smartphone oper-
ating system market, which is dominated by Apple’s iOS and Google’s Android 
operating systems.
The Android operating system was designed mainly for touchscreen smartphones 
and tablets, and it was developed by Google and the Open Handset Alliance. 
Android is built on the Linux kernel, and its first version was released in late 2007.
The iOS operating system is a mobile operating system employed on Apple’s 
mobile devices such as smartphones and tablets. It was introduced in 2007. For 
more detailed information on operating systems, see [Dei:90, AnDa:14].
13.2  Fundamentals of Operating Systems
An operating system is a collection of software programs that control the hardware 
of a computer and makes it usable. The operating system may be dealing with a 
single processor or multiprocessor system. The concept of a process (a program in 
execution) is central to understanding modern operating systems, and a process 
goes through a series of discrete process states with an event leading to a change of 
state. A process is said to be running if it currently has the CPU, and a process is 
said to be ready if it could use a CPU (should one be available). A process is said to 
be blocked if it is waiting for some event to happen (e.g., an i/o event) before it can 
continue (Fig. 13.1).
A process is created in response to the submission of a job to the system, and it 
is generally added to the end of the ready list. The process then gradually moves to 
the head of the ready queue, and when the CPU becomes available, the process 
makes a transition from the ready state to the running space. The assignment of the 
CPU to the first process on the ready list is termed dispatching, and the operating 
system sets a hardware interrupting clock to allow the process to run for a fixed 
period (or quantum), and the operating system interrupts (where appropriate) to 
ensure that the next ready process is dispatched to running before (or at) the end of 
the time quantum.
The process control block (PCB) is a data structure containing key information 
about the process including its current state, priority, and pointers to parent and 
child processes (i.e., the process that created it and any processes that it created). It 
defines the process to the operating system. Processes may be created or destroyed, 
suspended or resumed, blocked or woken up, and dispatched. A suspended process 
cannot continue until another process resumes it, and the suspension may be initi-
ated by the process itself or another process.
An interrupt is an event that alters the sequence in which a processor executes 
instructions, and it is generated by the hardware of the computer system. It results 
in the operating system gaining control, and the state of the interrupted process is 
saved. The operating system then analyses the interrupt and passes control to the 
interrupt handler for processing the interrupt. Finally, the interrupted process is 
resumed.
13.2  Fundamentals of Operating Systems

146
Concurrency is a form of computing in which multiple computations (processes) 
are executed during the same time period. Parallel computing allows execution to 
occur in the same time instant (on separate processors of a multiprocessor machine), 
whereas concurrent computing consists of process lifetimes overlapping and where 
execution need not happen at the same time instant.
Concurrency employs interleaving where the execution steps of each process 
employs time sharing slices so that only one process runs at a time, and if it does not 
complete within its time slice it is paused, another process begins or resumes, and 
then later, the original process is resumed. That is, only one process is running at a 
given time instant, whereas multiple processes are part of the way through execution.
It is important to identify and deal with concurrency-specific errors such as dead-
lock and livelock. A deadlock is a situation in which the system has reached a state 
in which no further progress can be made, and at least one process needs to com-
plete its tasks. Figure 13.2 illustrates a deadlock situation where both processes are 
waiting for the other to free a resource that it will not free until the other frees its 
resource (circular wait). Livelock refers to a situation where the processes in a sys-
tem are stuck in a repetitive task and are making no progress toward their func-
tional goals.
It is essential that properties such as mutual exclusion (at most one process is in 
its critical section at any given time) should not be violated. The critical section 
refers to shared modifiable data, and so it must be ensured that when one process is 
in a critical section, then all other processes that access the same shared modifiable 
data are excluded from their critical sections. One common implementation of 
mutual exclusion is by semaphores (a protected variable whose values may be 
accessed and modified only by the P and V operations).
It is essential that something bad (e.g., a deadlock situation) never happens and 
that liveness properties (a desired event or something good eventually happens). It 
is essential that invariants (properties that are true all the time) are not be violated.
Running
Ready
Blocked
Dispatch
Block
Wakeup
Timeout
Fig. 13.1  Process state 
transitions
13  History of Operating Systems

147
13.3  OS/360 and MVS
The System/360 family of computers was designed to use the IBM System/360 
operating system (OS/360). OS/360 was a batch-oriented operating system, and 
IBM supported three variants of it. These were OS/360 PCP (Principal Control 
Program), OS/360 MFT (Multiple Programming with a Fixed number of Tasks), 
and OS/360 MVT (Multiple Programming with a Variable number of Tasks).
OS/360 PCP was the simplest version, and it could run only one program at a 
time. The smaller members of the System/360 family used it. OS/360 MFT could 
run several programs at once, but only after partitioning the memory required to run 
each. It was subject to the limitation that if a program was idle, its allocated memory 
was unavailable to other programs. It was developed as an interim solution pending 
the delayed introduction of OS/360 MVT. However, the simpler MFT continued in 
use for many years due to problems with MVT.
OS/360 MVT was the most sophisticated version of OS/360, and it was intended 
for the largest members in the System/family. It allowed memory divisions to be 
recreated as needed, and it was able to allocate all of a computer’s memory (if 
required) to a single large job. Further, whenever memory was available, OS/MVT 
searched a queue of jobs to see if any could be run on the available memory. OS/
MVT was introduced in 1967.
All three versions of OS/360 provided similar features from the point of view of 
application programs. This included the same application-programming interface 
(API); the same job control language (JCL) for initiating batch jobs; the same access 
methods for reading and writing files and data communication; the same spooling 
facility, and multitasking.
The Multiple Virtual Storage (MVS) operating system was introduced in 1974 as 
an enhancement of the MVT version of the OS/360 operating system that supported 
virtual memory. It was the most commonly used operating system on the IBM 
System/370 and System/390 mainframe computers.
Resource 1
Resource 1 allocated 
to process A
Process A
Process B
Resource 2
Resource 2 allocated 
to process B
Process B requests 
Resource 1
Process A requests 
Resource 2
Fig. 13.2  A simple deadlock
13.3  OS/360 and MVS

148
The System/370 was an enhancement of the System/360 architecture in that it 
provided virtual storage capabilities, where virtual storage allows a much larger 
storage space to be addressed than is available in the primary memory of the com-
puter. The concept of virtual storage dates back to the design of the Atlas Computer 
at the University of Manchester in 1960, and the two most common methods of 
implementing virtual storage are paging and segmentation.
The 24-bit addressing of the System/370 meant that each user (or job) had a 
16-megabyte (224) virtual address space (i.e., 256 segments, with each segment con-
taining 16 pages, and each page contained 4096 bytes).
MVS provides multiprogramming and multiprocessing capabilities, and it is a 
large operating system designed with performance, reliability, and availability in 
mind. The operating system has recovery routines that gain control in the event of 
an operating system failure, and it attempts recovery from hardware errors.
MVS includes a master scheduler that initializes the system and responds to 
commands issued by the system operator. It contains a job entry subsystem that 
allows jobs to be entered into the system. Its system management facility collects 
information to account for system use and to analyze system performance. Its time-
sharing option (TSO) provides users with interactive editing, testing, and debugging 
capabilities. Its data management functionality handles all input/output and file 
management activities. Its telecommunication functionality allows remote terminal 
users to access MVS.
13.4  VM
The virtual machine operating system (VM) makes a single machine appear as sev-
eral real machines (Fig. 13.3). The user at a VM virtual machine sees the equivalent 
of a complete real machine, even though it is an illusion and just appears to be a real 
machine to the user. A virtual machine runs programs in a similar way to a real 
machine, and the user communicates with the virtual machine through a terminal. 
The most widely used virtual machine operating system is IBM’s VM, and it was 
used on an IBM System/370 mainframe. It created the illusion that each user operat-
ing at a terminal had access to a complete IBM 370, including the input/output 
devices.
VM can run several different operating systems at once, each of them on its own 
virtual machine. This is a very attractive feature as running multiple operating sys-
tems offers a form of backup in the event of failure. The operating systems running 
on virtual machines perform their normal functions such as storage management, 
control of input/output, processor scheduling, and multiprogramming. Virtual 
machines create virtual processors, virtual storage, and virtual I/O devices. The VM 
user may run operating systems such as MVS, VM/370, AIX/370, or VM itself.
The main components of VM are the Control Program (CP), the Conversational 
Monitor System (CMS), the Remote Spooling Communications Subsystem (RSCS), 
the Interactive Problem Control System (IPCS), and the CMS Batch.
13  History of Operating Systems

149
CP creates the environment in which virtual machines may execute, and it pro-
vides support for the various operating systems that may be used to control the 
IBM/370. It manages the real machine underlying the virtual machine environment 
and gives each user access to the facilities of the real machine. CMS is an applica-
tions system with editors, debugging tools, and various application packages. RSCS 
provides the ability to transmit and receive files, and IPCS is used for on-line analy-
sis and for fixing VM software problems. The CMS Batch facility allows the user to 
submit longer jobs for batch processing.
13.5  VMS
The VAX Virtual Memory System (VMS) was designed as the operating system for 
the VAX family of minicomputers. Digital Equipment Corporation (DEC) intro-
duced it in the late 1970s, and the models in the VAX family of computers all had 
the same architecture, and they could all run the VMS operating system.
David Cutler and others at DEC designed VMS as a high-end, secure, scalable, 
multi-user, multitasking, and virtual memory operating system that supported a 
broad class of applications and systems. DEC developed VAX and VMS together, 
and the designers balanced the tradeoffs between the work done by the hardware 
and the work done by the operating system.
VAXes may operate together in a peer-to-peer relationship, where any VAX may 
be a client or a server. This allows flexibility when several computers perform tasks 
in cooperation. Several VAXes may be connected together so that they work as a 
cooperating unit called a VAXcluster.
VMS expanded the memory of the machine by disk or other peripheral storage 
to act as extra memory. The VAX-11 provided a 32-bit virtual address space per 
process, divided into 512 byte pages. VMS used paging and segmentation, with the 
first 23 bits used as the virtual page number (VPN), and a 9-bit offset within the page.
VMS was a popular and easy to use operating system. Its commands are easy to 
remember English like words, and it had an extensive on-line help system. It 
included utilities such as a mail program and a text editor. Open VMS is the latest 
version of the operating system and is sold by HP.
Virtual Machine
Multiprogramming
Operating System
Virtual
Machine
1
Virtual
Machine
2
Virtual
Machine
3
....
Virtual
Machine
n
Fig. 13.3  Virtual machine 
operating system
13.5  VMS

150
13.6  UNIX
Ken Thompson, Dennis Ritchie, and others designed and developed the UNIX oper-
ating system at Bell Labs in the early 1970s. It is a multitasking and multiuser 
operating system that was written almost entirely in the C programming language, 
which was designed by Denis Ritchie at Bell Labs. UNIX arose out of work by 
Massachusetts Institute of Technology, General Electric, and Bell Labs on the 
development of a general timesharing operating system called “Multics.”
Bell Labs decided in 1969 to withdraw from the Multics project (as they believed 
that it would be a large and expensive system) and to use General Electric’s GECOS 
operating system. However, several of the Bell Lab researchers (led by Ken 
Thompson) decided to continue the work on a smaller scale operating system, and 
the name “UNIX” was coined by Brian Kernighan. The first version of UNIX was 
written on a Digital PDP-7 minicomputer in assembly language, and Dennis Ritchie 
joined the project. He helped in rewriting UNIX in the C programming language for 
the recently introduced PDP-11 computer in 1973. Thompson and Ritchie later 
received the Turing Award for their design and development of the UNIX operating 
system. Microsoft introduced XENIX, a commercial version of UNIX, in 1980.
The use of C helped to make UNIX more portable, and it became a widely used 
operating system. It was initially used by universities and the US government, but it 
later became popular in industry. It is a powerful and flexible operating system, and 
it is used on a variety of machines from micros to supercomputers. It is designed to 
allow several programmers to access the computer at the same time and to share its 
resources, and it offers powerful real time sharing of resources.
It includes features such as multitasking which allows the computer to do several 
things at once; multiuser capability which allows several users to use the computer 
at the same time; and portability of the operating system which allows it to be used 
on several computer platforms with minimal changes to the code. It includes a col-
lection of tools and applications. There are three levels of the UNIX system: kernel, 
shell, and tools and applications.
The kernel is the central part of the UNIX operating system, and it provides sys-
tems services to applications programs. This includes services for process manage-
ment, memory management, and input/output management. UNIX manages many 
concurrent processes.
The UNIX shell is a command interpreter that acts as the interface between the 
user and the operating system. There are a number of popular shells for UNIX, 
including the Bourne shell and Korn shell. UNIX uses a hierarchical file system 
with the root node at its origin, with each directory entry containing files and other 
directories. For a more detailed account of UNIX, see [Rob:05].
13  History of Operating Systems

151
13.7  MS/DOS
We discussed the introduction of the IBM personal computer in the previous chap-
ter, as well as the controversy with respect to the development of the PC/DOS oper-
ating system for the IBM PC. The terms of the deal with IBM allowed Microsoft the 
right to license its operating system, MS/DOS, on IBM compatibles, whereas PC/
DOS (or simply DOS) was reserved for IBM personal computers only.
The IBM PC was introduced in 1981, and the first version of the operating sys-
tem was compatible with Digital Research’s CP/M operating system (as it essen-
tially was CP/M). It managed floppy disks and files, input and output, memory, and 
it contained an external command processor that interpreted user commands and 
allowed the user to interact with the system.
MS/DOS version 2.0 was introduced in 1983 and it was designed to support the 
10  MB hard disk on the IBM PC/XT and provide support for device drivers. 
Microsoft had previously licensed XENIX (their commercial version of UNIX) 
from AT&T, and MS/DOS 2.0 was a move toward XENIX. It employed a hierarchi-
cal file system, and a unique path name identified each file (similar to XENIX). It 
provided limited multitasking for background print spooling. The hard disk on the 
XT helped to establish the IBM PC in the business market place.
The open architecture of the IBM PC led to the development of cheaper IBM 
compatible personal computers, and they rapidly gained market share, as it was dif-
ficult for IBM to compete on price. This led to massive international demand for 
MS/DOS (which was the operating system for IBM compatibles and clones).
MS/DOS 3.0 was released in 1984, and it provided support for the IBM PC/AT, 
which had a 20 MB hard disk. Several versions of MS/DOS followed through the 
1980s and 1990s. Today, Microsoft Windows is the operating system used on per-
sonal computers, and MS/DOS is of historical interest.
13.8  Microsoft Windows
Microsoft Windows is a family of graphical operating systems developed by 
Microsoft. The original Windows 1.0 operating environment was introduced in late 
1985 as a graphical operating system shell for its command-driven MS/DOS operat-
ing system. It was Microsoft’s initial response to Apple’s GUI operating system.
The Apple Macintosh was released in 1984, and its MAC operating system was 
GUI based and a paradigm shift for the computer industry. It was friendly, intuitive, 
and easy to use, and it was clear that the future of operating systems was in GUI-­
driven systems, rather than primitive command-driven operating systems such 
as MS/DOS.
The early versions of Windows were not complete operating systems as such, 
and they were graphical shells that ran on top of MS/DOS and extended the operat-
ing system. Windows 1.0 used MS/DOS for file system services, and it also included 
13.8  Microsoft Windows

152
applications such as a calculator, calendar, and clock. However, Windows differed 
from MS/DOS in that it allowed multiple graphical applications to be run at the 
same time, and this was done through cooperative multitasking.
Windows 2.0 was introduced in 1987 and it was more popular than its predeces-
sor. It included improvements to the user interface and to memory management. 
Windows 3.0 improved the design of the operating system, and it used virtual mem-
ory and virtual device drivers that allowed arbitrary devices to be shared between 
multitasked DOS applications. It was introduced in 1990, and it was the first 
Windows operating system to achieve commercial success.
Windows 3.1 was introduced in 1992; Windows 95 in 1995; Windows 98 in 
1998; and Windows Millennium (ME) in 2000. Windows ME provided expanded 
multimedia capabilities including the Windows Media Player, and it was the last 
DOS-based version of Windows. Windows ME was criticized for its speed and 
instability.
Windows XP was introduced in 2001, and it was marketed into a “Home” edition 
for personal users and a “Professional” edition for business users. Windows Vista 
was released in 2006, Windows 7 in 2009, Windows 8 in 2012, and Windows 10 was 
released in 2015.
Microsoft Windows dominates the personal computer and laptop market with 
over 90% market share. However, Windows has not been as successful on mobile 
computing platforms such as mobile phones and tablets, where Google’s Android 
operating system is the dominant platform.
13.9  Mobile Operating Systems
Android (Fig. 13.4) is a mobile operating system that was developed by Google and 
the Open Handset Alliance, and it was designed mainly for touchscreen smart-
phones and tablets. It is built on the Linux kernel, and the first version of the operat-
ing system was released in late 2007. The first Android smartphone was released in 
late 2008, and Android is currently the most widely used operating system.
The source code for Android is released under an open-source license, and its 
open-source philosophy has led to a large community of developers who maintain 
and develop new versions of it. Manufacturers may modify Android as they see fit, 
and this allows them to customize their devices and differentiate them from com-
petitor products.
There are over a million applications (apps) for Android, and developers are 
challenged to ensure that the apps are compatible with the many mobile devices 
using different hardware and running various (possibly customized) versions of 
Android.
The iOS operating system is a mobile operating system employed on Apple’s 
mobile devices such as smartphones and tablets. It was created from the MAC OS/X 
operating system and introduced in 2007. Multitasking for iOS was introduced in 
2010 with the release of iOS version 4.0.
13  History of Operating Systems

153
13.10  Review Questions
	1.	
What is an operating system?
	2.	
What are the main functions of an operating system?
	3.	
Explain the following operating system concepts: Processor sched-
uling, multiprogramming, paging/segmentation, and multitasking.
	4.	
Describe IBM’s contributions to operating system development.
	5.	
Describe the similarities and differences between VM and MVS.
	6.	
Describe the influence of the UNIX operating system.
	7.	
Describe the features of DEC’s VMS operating system.
Fig. 13.4  Android 
operating system
13.10  Review Questions

154
13.11  Summary
An operating system is a collection of software programs that control the hardware 
of a computer and makes it usable. It makes the computing power of the hardware 
available to the users of the computer, and it manages the hardware to achieve good 
system performance.
The earliest computers did not have an operating system, and the user had exclu-
sive control over a large computer for a specified period of time. The earliest operat-
ing systems were designed in the 1950s with the goal to make more efficient use of 
the computer (as computers were expensive). These batch-processing systems ran 
one job at a time, and programs and data were submitted in groups (or batches).
These evolved during the early 1960s into batch multiprogramming systems that 
were designed to get better utilization of expensive computer resources. They could 
handle several diverse jobs at once. However, software development in this environ-
ment was very slow. This led operating system designers to develop the concept of 
multiprogramming in which several jobs are in main memory at once.
The computers in the System/360 family were designed to use the IBM 
System/360 operating system (OS/360), and there were three variants of this operat-
ing system.
UNIX was developed at Bell Labs in the early 1970s, and it is a multitasking and 
multiuser operating system. Microsoft developed the MS/DOS operating system on 
IBM compatibles, with PC/DOS (or simply DOS) reserved for IBM personal com-
puters only. The Apple Macintosh was a paradigm shift for the computer industry 
when it was introduced in 1984. Its MAC operating system was GUI based, friendly, 
intuitive, and easy to use.
Microsoft Windows is a family of graphical operating systems developed by 
Microsoft, and it has evolved to become the dominant operating system on laptops 
and personal computers.
The Android operating system was designed mainly for touchscreen smartphones 
and tablets, and the iOS operating system is a mobile operating system employed on 
Apple’s mobile devices.
13  History of Operating Systems

155
© The Author(s), under exclusive license to Springer Nature 
Switzerland AG 2021
G. O’Regan, A Brief History of Computing, 
https://doi.org/10.1007/978-3-030-66599-9_14
Chapter 14
Birth of Software Industry and Human 
Computer Interaction
14.1  Introduction
The market participants in the early days of computing consisted of a small number 
of computer companies such as IBM, which was a giant corporation and smaller 
companies such as Burroughs, Sperry, NCR, and so on. IBM was the dominant 
player in the market, and the computer industry at that time was described as Snow 
white (i.e., IBM) and the seven dwarfs (i.e., the competitors to IBM in the market).
The software produced in the early days of computing was proprietary and devel-
oped by commercial vendors such as IBM and its competitors. Once a customer 
made a decision to purchase a particular computer from a computer company, it was 
dependent on that company providing it with proprietary software to meet its needs.
The hardware of the various computers of the different vendors were incompat-
ible, and this meant that if a customer changed vendor, then there was a need to 
rewrite software for the new computer architecture.
The early computers were not user friendly and users needed to be skilled to 
operate them. Human–computer interaction is a branch of computer science that is 
concerned with the design, evaluation, and implementation of interactive computing 
systems for human use. It is focused on the interfaces between people and comput-
ers and has grown over the decades to include text-based interaction systems, graph-
ical user interfaces, and voice user interfaces.
The development of home computers from the mid-1970s meant that everyone in the 
world was now a potential computer user, and it was clear that there was a need to 
Key Topics
Software industry
Software contractors industry
Corporate software products
Mass market for software
Software as a service
Text-based interface
Graphical user interface
Usability standards
Mouse
Microsoft Office

156
improve the usability of machines. Humans interact with computers in many ways, and 
so it is important to understand the interface between them to facilitate the interaction.
14.2  Birth of Software Industry
The vast majority of software produced in the early days of computing was propri-
etary and developed by commercial vendors such as IBM and UNIVAC. The com-
puter companies provided a total solution to their clients including both hardware 
and software, and there was a very limited independent software sector that devel-
oped application software for specific clients. Computer companies were essentially 
in the hardware business, and so they bundled software with their machines, that is, 
the software was essentially given away free and provided with the mainframe com-
puter. Another words, operating systems, system software, and application pro-
grams were provided with the mainframe computer, and software was not priced 
separately from the computer hardware.
IBM was the dominant player in the computer field in the 1960s. The company 
had approximately a 70% market share of the computer industry in the 1960s and 
1970s, and this led it being regarded as a monopoly with excessive powers. The US 
Department of Justice (DOJ) launched a major antitrust case against IBM in 1969, 
as it viewed the company as a dominant monopoly. Its goal was to eliminate IBM’s 
excessive power over the industry by breaking it into smaller business units that 
would compete against one another. The antitrust case continued for 13 years (with 
over 30 million pages of documents produced as part of the case) up to the introduc-
tion of the IBM personal computer in the early 1980s. The eventual ruling in 1982 
was that the case was “without merit.”
IBM decided in 1968 to unbundle many of its software programs, and it intro-
duced a new pricing strategy for its software programs and support and training 
services. IBM had several motivations for unbundling its software and services 
including:
–– Anticipation of upcoming DOJ antitrust case.
–– The cost of software development and support (especially its experience with the 
development of the System 360).
–– The growth of independent software vendors meant that IBM was no longer 
obliged to provide all software solutions to its customers.
–– The introduction of the System 360 meant that vendors could now provide a 
software product to a whole family of architecturally compatible machines.
The IBM decision meant that the computer industry changed forever, with soft-
ware changing from being a giveaway item to becoming a commercial product and 
industry in its own right. The IBM unbundling decision led in time to the software 
and services industry that we see today, and the quality of software and its usability 
became increasingly important. Chapter 16 discusses the important field of software 
engineering, which emerged in the late 1960s as a response to the crisis in software 
14  Birth of Software Industry and Human Computer Interaction

157
development, and Sect. 14.4 is concerned with human–computer interaction and 
software usability.
Today, the software and services industry is immense, and the largest companies 
in the industry are IBM, Microsoft, Oracle, and SAP. Cambell–Kelly [CK:04] pro-
posed a division of the software industry into three sectors: software contractors 
(from the mid-1950s); producers of corporate software products (from the 
mid-­1960s), and mass market of software products (from the late 1970s). We expand 
on this classification a little to include more recent developments.
14.2.1  Software Contractors Industry
The software contractors industry consists of the first programming companies, 
with the earliest contractors dating from the mid-1950s. Their role was to develop 
complete systems or application programs for their clients. Their early customers 
included the US military, government organizations, and large corporations, and 
their role was to provide the appropriate expertise in designing, developing, and 
testing of the software. The selection of a software contractor was generally based 
on its project management capability, as well as the scope and cost of the proposed 
solution.
The selection process aimed to identify the most capable contractor that pro-
posed the most appropriate and cost-effective solution. The software was produced 
for one customer only, as a mass market for software did not exist at that time, and 
so the solution was tailored to meet the needs of the customer.
Systems Development Corporation (SDC) was founded in 1955 as the systems 
engineering group for the SAGE project at the RAND Corporation. SDC developed 
the software for the SAGE system (IBM did not do the software part of the project), 
and SDC later developed the timesharing system for ARPA’s mainframe computer 
in the 1960s, and it also developed the JOVIAL programming language for real-­
time applications. RAND spun off SDC in 1957 as a not-for-profit organization that 
provided expertise in software development to the US military, and SDC later 
became a for-profit organization offering its services to all types of organizations 
from the late 1960s.
Computer Sciences Corporation (CSC) was founded in 1959, and it initially pro-
vided software development services to companies such as IBM and Honeywell and 
later with publicly funded organizations such as NASA. It became a global provider 
of information technology services with operations in the United States, Europe, 
and Asia. It merged with HP Enterprise (formerly EDS) in 2017 to form DXC 
Technology.
Today, there are many international consulting companies in the United States, 
Europe, and Asia, such as Infosys, Wipro, and Tata in India; Accenture and Cap 
Gemini in Europe; and Cognizant and IBM in the United States.
14.2  Birth of Software Industry

158
14.2.2  Corporate Software Products
The IBM System/360 (see Chap. 8) was a family of small to large computers, and it 
was a paradigm shift from the traditional “one size fits all” philosophy of the com-
puter industry. The computers employed the same user instruction set, and there 
were 14 models in the family. There was strict compatibility within the family, and 
so a program written for one model would work on another model. This led to a 
market for software products for the System/360, and several software companies 
were formed to develop software products.
This includes Informatics General, which was founded by Walter F. Bauer in 
California in 1962. The company was initially involved in the software contracting 
business, but it later built its own software products. These include the Mark IV, 
which was a file management system/report generator for the IBM System/360. 
There were over 1000 installations of this product. Informatics also developed other 
software products.
Applied Data Research was founded in New Jersey in 1959, and it was initially 
in the software contracting business. It later developed several of its own software 
products, and the most widely used of these include Autoflow for automatic flow-
charting; Meta COBOL which is a macro processor for COBOL, and Librarian for 
source code control management.
Advanced Computer Techniques (ACT) was founded by Charles Lecht in 
New York in 1962, and the company was active in creating compiler related tools in 
its early years. It developed compilers for Fortran and COBOL in the 1960s, and it 
developed a compiler for Pascal and Ada in the 1970s and 1980s. It became a public 
company in 1968, and it diversified into other areas such as education and training, 
service bureaus to handle data processing needs of clients, and packaged software 
business of compilers and related tools.
Today, there are many companies providing corporate software products. For 
example, SAP is a German software corporation that makes enterprise software to 
manage business operations and customer relations.
14.2.3  Personal Computer Software Industry
The invention of the microprocessor led to the development of home and personal 
computers, and led to a massive demand for software for home and personal use. 
This included software such as editors, compilers, spreadsheets, and games, and it 
led to a mass market for software. The number of units sold for a software product 
for mainframes and minicomputers was in the hundreds (or thousands), but in the 
brave new world of personal computing, the number of units sold was in the mil-
lions of units.
MITS developed the prototype of the Altair 8800 home computer in late 1974, 
and the released product came as a home computer kit version (which was 
14  Birth of Software Industry and Human Computer Interaction

159
assembled by the customer) or a more expensive fully assembled version. One of 
the earliest products for the home/personal computing market was Altair Basic, 
which was produced in 1975 by a small company called Microsoft. It was Microsoft’s 
first product, and computer hobbyists began producing software to run on the Altair 
and the emerging home computers.
Early software programs for home computers were often provided in a book or 
magazine, and the user would type in the entire program to the computer. However, 
this was a slow process and could only deal with small programs. Further, if the user 
mistyped, then the program either did not work as intended or was inoperable. The 
cassette tape was another popular means of distributing early software programs for 
home computers.
The emergence of the IBM personal computer in the early 1980s fundamentally 
changed the computing field, and it rapidly took market share in the home/personal 
computer market. It led to a massive demand (in millions of units) for these comput-
ers, as well as a massive demand for application software to run on the machines. 
Floppy disks became available for distributing software for personal computers in 
the 1980s.
The demand for software led to the growth of several large software companies 
in the 1980s that were providing application software for the IBM PC. These include 
Lotus Software (later part of IBM) that developed the popular 1-2-3-spreadsheet 
program (spreadsheet calculations, database functionality and graphical charts). 
This was the dominant spreadsheet software in the 1980s, but it was eclipsed by 
Microsoft Excel in the 1990s. WordPerfect Corporation (now part of the Corel 
Corporation) was the dominant player in the word-processor market in the 1980s. It 
created the popular WordPerfect (WP) word processor in the late 1970s/early 1980s, 
which remained the dominant word processor until it was eclipsed by Microsoft 
Word in the 1990s.
Microsoft has dominated the personal computer software industry since the 
1990s, and Microsoft Office is a suite of office applications for the Microsoft 
Windows operating system. It consists of well-known programs such as Microsoft 
Word, which is a word processor; Microsoft Excel, which is a spreadsheet program; 
Microsoft PowerPoint, which is used to create slideshows for presentations; 
Microsoft Access, which is a database management system for Windows; and 
Microsoft Outlook, which is a personal information manager. We discuss Microsoft 
Office in more detail in Sect. 14.3.
14.2.4  Software as a Service
The idea of software as a service (SaaS) is that the software may be hosted remotely 
on a server (or servers), and access provided to it over the Internet through a web 
browser. The functionality is provided at the remote server with client access pro-
vided through the web browser. The cost of hosting and management of the service 
14.2  Birth of Software Industry

160
is transferred to the service provider, with the initial set up costs for users signifi-
cantly less than for traditional software.
The software is licensed to the user on a subscription basis. Occasionally, the 
software is free to use with funding for the service provided through advertisements, 
or there may be a free basic service provided with charges applied for the more 
advanced version.
14.2.5  Open-Source Software
Open-source development is an approach to software development in which the 
source code is published, and thousands of volunteer software developers from 
around the world participate in developing and improving the software. The idea is 
that the source code is not proprietary, and that it is freely available for software 
developers to use and modify as they wish. One useful benefit is that it may poten-
tially speed up development time, thereby shortening time to market.
The roots of open source development are in the Free Software Foundation 
(FSF). This is a nonprofit organization founded by Richard Stallman [ORg:13-b] to 
promote the free software movement, and it has developed a legal framework for the 
free software movement.
The Linux operating system is a well-known open-source product, and other 
products include mySQL, Firefox, and Apache HTTP server. The quality of soft-
ware produced by the open-source movement is good, and defects are generally 
identified and fixed faster than with proprietary software development.
14.2.5.1  Free Software Foundation
Richard Stallman (Fig. 14.1) is the prophet of the free software movement, and he 
launched the Free Software Foundation (FSF) in 1985. Stallman joined the Artificial 
Intelligence Laboratory at MIT as a programmer, and he later became a critic of 
restricted computer access at the lab. He believed that software users should have 
the freedom to share software with others and to be able to study and make changes 
to the software that they use. He left his position at MIT to launch the free software 
movement, and he explains his concept of free software as:
Free software is a matter of liberty, not price. To understand the concept, you should think 
of free as in free speech, not as in free beer.
He launched the GNU project in 1984, which is a free software movement, and 
involves the participation of volunteer software programmers from around the 
world. He formed the Free Software Foundation (FSF) to promote the free software 
movement, and he is the nonsalaried president of the organization. FSF has devel-
oped a legal framework for the free software movement, which provides a legal 
means to protect the modification and distribution rights of free software. The 
14  Birth of Software Industry and Human Computer Interaction

161
meaning of the term “free software” is defined in the GNU manifesto, and he lists 
four key freedoms essential to software development [Sta:02], and a program is 
termed “free” if it satisfies these properties. These are:
	1.	 Freedom to run the program for any purpose
	2.	 Freedom to access, study and to improve the code, and to modify it to suit 
your needs
	3.	 Freedom to make copies of the program and to redistribute them to others
	4.	 Freedom to distribute copies of the modified program so that others can benefit 
from your improvements
The GNU project uses software that is free for users to copy, edit, and distribute. 
It is free in the sense that users can change the software to fit individual needs. 
Stallman has written many essays on software freedom and is a key campaigner for 
the free software movement. The legal framework for the free software movement 
provides protection to the modification and distribution rights of free software. 
Stallman introduced the concept of “copyleft,” which is a form of licensing of free 
software. It makes a program or product free and requires that all modified or 
extended versions of the program are also free.
Stallman has argued against intellectual property such as patent law and copy-
right law. He has argued against patenting software ideas, stating that a patent is an 
absolute monopoly on the use of an idea. He states that while 20 years may not seem 
like a long period of time, that in the software field it is essentially a generation, due 
to the pace at which technology changes in the world. Further, patents act a barrier 
to competition and lead to monopolies. They make it difficult for new companies to 
enter a market place, due to the restrictions and costs associated with the licensing 
of patents. In recent times, we have seen large companies acquire others for their 
intellectual property (e.g., the Google acquisition of Motorola Mobility was due to 
the latter’s valuable collection of patents), and today there are major intellectual 
property wars in the corporate world.
Stallman argues that copyright law places Draconian restrictions on the public 
and takes away freedoms that they would otherwise have. They protect the busi-
nesses of the copyright owner, and he suggests that alternative approaches should be 
considered in the digital age.
Fig. 14.1  Richard 
Stallman. (Creative 
Commons)
14.2  Birth of Software Industry

162
14.2.6  App Stores
Applications for mobile phones and tablets are termed “apps,” and sales of apps are 
made through an App store, which vets the app and may take a percentage of every 
app that is sold. Apple’s App store is used for apps that run on Apple’s iOS operating 
system for iPhones, and Google Play is a popular App store for Android phones 
(there are multiple App stores available for the Android platform).
The Apps may be created by companies, by organizations or by individuals, and 
some are free to the user while others are subject to a payment.
14.3  Microsoft Office Software
Microsoft Office is a suite of office applications for the Microsoft Windows operat-
ing system. It consists of well-known programs such as Microsoft Word, which is a 
word processor; Microsoft Excel, which is a spreadsheet program; Microsoft 
PowerPoint, which is used to create slideshows for presentations; Microsoft Access, 
which is a database management system for Windows; and Microsoft Outlook, 
which is a personal information manager.
Microsoft’s first Office application was a spreadsheet program initially called 
Multiplan when it was released in 1982. It was developed as a competitor to VisiCalc 
(Apple’s spreadsheet program), and it renamed to Excel when it was released on the 
Macintosh in 1985. Excel is a spreadsheet program consisting of a grid of cells in 
rows and columns that may be used for data manipulation and arithmetic opera-
tions. It includes functionality for statistical, engineering, and financial applica-
tions, and it can display lines, histograms, and charts. It also provides support for 
user-defined macros.
Microsoft Word is the leading word processor, and the first version of the pro-
gram was released on the MS/DOS operating system in 1983. It was designed for 
use with a mouse, and it provides “What you see is what you get” functionality. The 
first version of Word for Windows was released in 1989, and Microsoft Word began 
to dominate the market from the early 1990s.
Microsoft PowerPoint is a popular presentation program, and it enables the user 
to create a presentation consisting of several slides. Each slide may contain text, 
graphics, audio, movies, and so on. PowerPoint has made it easier to create presen-
tations. It was originally developed for the Macintosh computer in 1987, and it was 
released for Windows in 1990.
The first version of Microsoft Access was released in 1992, and this database 
management system enables users to create tables, queries, forms, and reports. It 
includes a graphical user interface that allows users to build queries without knowl-
edge of the query language. Microsoft Outlook is a personal information manager, 
and it is used mainly as an email application, but it also includes a calendar, task 
manager, note taking, and web browsing.
14  Birth of Software Industry and Human Computer Interaction

163
The various Microsoft application programs such as Word, Excel, and PowerPoint 
were all available individually, until they were bundled together into the Microsoft 
Office suite in 1989.
14.3.1  Microsoft Excel
Microsoft Excel is a spreadsheet program, and it consists of a grid of cells in rows 
and columns that may be used for data manipulation and arithmetic operations. It 
includes functionality for statistical, engineering, and financial applications, and it 
has graphical functionality to display lines, histograms, and charts (Fig. 14.2).
This spreadsheet program was initially called Multiplan when it was released in 
1982, and it was Microsoft’s first Office application. It was developed as a competi-
tor to Apple’s VisiCalc, and it was initially released on computers running the CP/M 
operating system. It was renamed to Excel when it was released on the Macintosh in 
1985, and the first version of Excel for the IBM PC was released in 1987.
It provides support for user-defined macros, and it also allows the user to employ 
Visual Basic for Applications (VBA) to perform numeric computation and report 
the results back to the Excel spreadsheet. Lotus 1-2-3 was the leading Spreadsheet 
tool of the 1980s, but Excel overtook it from the early 1990s.
Fig. 14.2  Microsoft Excel
14.3  Microsoft Office Software

164
14.3.2  Microsoft PowerPoint
Microsoft PowerPoint is a popular presentation program that allows the user to cre-
ate a presentation consisting of several slides. Each slide may contain text, graphics, 
audio, movies, and so on, and PowerPoint has made it easier to create and deliver 
presentations. The user may customize slideshows and show the slides in a different 
order from the original order. It has advanced features for animating text and graph-
ics, video editing, and even broadcasting the presentation.
Microsoft PowerPoint was initially called Presenter, and Forethought Inc. origi-
nally developed it in 1987 for the Macintosh computer. Microsoft acquired 
Forethought for $14 million in 1987, and the first Windows version of PowerPoint 
was released in 1990. PowerPoint has many features to enable professional presen-
tations to be made (Fig. 14.3).
14.3.3  Microsoft Word
Microsoft Word is used for word processing tasks such as creating and editing docu-
ments. Charles Simonyi and Richard Brodie developed it for the MS/DOS operating 
system in the early 1980s. Simonyi and Brodie were former Xerox PARC employ-
ees who had worked on the Xerox Bravo WYSIWYG GUI word processor (the first 
such word processor), and they joined Microsoft in 1981. The first version of 
Microsoft Word was released in 1983.
Wordstar and WordPerfect were the leading word processors at the time, and it 
took some time for Microsoft Word to gain popularity. Word was designed for use 
with a mouse, and it provided “What you see is what you get” (WYSIWYG) func-
tionality. Microsoft continued to improve the product, and it was ported to the MAC 
operating system in 1985. The first version for Windows was released in 1989, and 
Word began to dominate the word processing market shortly after the release of 
Windows 3.0 (Fig. 14.4).
14.3.4  Microsoft Access and Outlook
Microsoft Access is a database management system that allows users to create 
tables, queries, forms and reports, and connects them together with macros. It 
includes a graphical user interface that allows users to build queries without knowl-
edge of the query language, or the user can create the query using the SQL database 
query language.
Microsoft Outlook is a powerful e-mail program and a personal information 
manager. It allows user to schedule meetings and to book meeting rooms and other 
resources, and the main Outlook sections include Mail, Calendar, Contacts, Tasks, 
14  Birth of Software Industry and Human Computer Interaction

165
Notes, and Journal. Users may create and send e-mail messages, and manage their 
e-mails by creating e-mail rules; they may create e-mail auto-reply messages to 
automatically reply when they are out of the office; manage meetings, events, and 
appointments; maintain and manage contacts; and to define tasks that the user needs 
to perform (including their priority).
Fig. 14.3  Microsoft PowerPoint
Fig. 14.4  Microsoft Word
14.3  Microsoft Office Software

166
14.4  Human–Computer Interaction
The interaction between humans and machines was mainly limited to information 
technology professionals from the early days of computing up to the mid/late 1970s. 
This changed after the invention of the microprocessor in the early 1970s, which led 
to an explosion of interest from computer hobbyists, and the subsequent develop-
ment of home computers from the mid-1970s. The introduction of the IBM personal 
computer in the early 1980s meant that everyone in the world was now was a poten-
tial computer user, and it led to a new market of personal applications and tools to 
support the user. However, it was clear that there were serious deficiencies with 
respect to the usability of computers in carrying out the tasks that users wished to 
perform.
Humans interact with computers in many ways, and so it is important to under-
stand the interface between human and machines to facilitate an effective interac-
tion. The early computer systems were batch processing (running programs in 
batches without human intervention) on a large expensive mainframe computer. The 
interaction between the human (operator) and computer was limited, and it con-
sisted of placing the punched cards (encoded instructions to the computer) on the 
card reader, and the computer would then process the cards overnight. These com-
puters were slow and expensive, and it was important that they be used efficiently 
24 h a day. The computer could run only one program at a time, and programmers 
were unable to interact with the computer while it was running. This made it diffi-
cult and time consuming to identify and correct errors.
Licklider wrote an influential paper “Man-Computer Symbiosis” in 1960 
[Lic:60], in which he outlined the need for a simple interaction system between 
users and computers. This paper mentioned ideas such as sharing computers among 
many users; interactive information processing and programming; large-scale stor-
age and retrieval; and speech and handwriting recognition.
Doug Engelbart was one of the main developers of NLS (On Line System) in the 
late 1960s, and this online word processor system had revolutionary features such 
as the first computer mouse; time-sharing; and a command line interface. User trials 
and testing was employed in its development as part of a philosophy toward a sys-
tem adapting to people rather than people adapting to a system.
Human–computer interaction (HCI) is a branch of computer science that is con-
cerned with the design, evaluation, and implementation of interactive computing 
systems for human use. It is focused on the interfaces between people and comput-
ers and involves several different fields including computer science, cognitive psy-
chology, design, and communication. The human–computer interaction field has 
evolved over the decades to text-based interaction systems, to graphical user inter-
faces (GUI), and voice user interfaces (VUI) for speech recognition and speech 
synthesis.
A text-based interface (also known as a command line interface) is where the 
system interaction (input and output) and navigation is text based. These interfaces 
14  Birth of Software Industry and Human Computer Interaction

167
are easier to use than punched card programming, but they require skilled users. 
This is due to the difficulty in remembering long lists of system commands.
One of the most well-known text-based operating system was Microsoft’s MS/
DOS operating system for IBM compatible personal computers, which was intro-
duced in 1981 (Fig. 14.5). Text-based interfaces are effective for expert users but are 
more difficult for users with an average level of knowledge. They have a steep learn-
ing curve, as it is difficult to remember long system commands. The fact that they 
are not very intuitive or user-friendly motivated research into alternative approaches 
to human–computer interaction.
The graphical user interface (GUI) is an interface that uses graphical icons, 
menus, and windows to represent information and action to the user. It was a revolu-
tion in human and computer interaction, and the GUI was intuitive and user friendly. 
They have made computers and electronic devices attractive to nontechnical users, 
and the usability of the GUI has allowed a large range of users with varying ability 
and expertise to successfully interact with computers.
Early work on graphical user interfaces took place at Xerox PARC in the 1970s 
with their work on the Xerox Alto personal workstation (Fig. 11.1). This was the 
first computer to use a mouse-driven graphical user interface, and it was essentially 
a small minicomputer rather than a personal computer (it was not based on the 
microprocessor). Its significance is that it had a major impact on the user interface 
design, and especially on the design of the Apple Macintosh computer.
The Xerox Star was introduced in the early 1980s, and it followed sound usabil-
ity principles (prototyping and analysis, iterative development, and testing with 
users) in its development. Steve Jobs visited Xerox PARC in late 1979, and he real-
ized that the future of personal computing was with computers that employed a 
graphical user interface (such as in the Xerox Alto). Jobs was amazed that Xerox 
had not commercialized the technology, as he saw its graphical user interface as a 
revolution in computing and a potential goldmine in the future of computing. The 
Fig. 14.5  FreeDOS text editing
14.4  Human–Computer Interaction

168
design of the Apple Macintosh was heavily influenced by the design of the 
Xerox Alto.
The Macintosh was a much easier machine to use than the existing IBM personal 
computer. Its friendly and intuitive graphical user interface was a revolutionary 
change from the command driven operating system of the IBM PC, which required 
the users to be familiar with its operating system commands. It was 1990 before 
Microsoft introduced its Windows 3.0 GUI-driven operating system (Fig. 14.6).
Today, the prevalent paradigm in human computer interaction is the WIMP (win-
dows, icons, menus, and pointers) paradigm, which is comprised of a graphic and 
text interface navigated by a mouse and keyboard. The future of HCI is predicted to 
be the SILK (Speech, Image, Language, Knowledge) paradigm, where communica-
tion between humans and machine will be more natural and intuitive.
14.4.1  HCI Principles
The success of computer systems is critically influenced by the design of the 
human–computer interaction, and in the achievement of end-user computing satis-
faction. Human–computer interaction is concerned with the study of humans and 
machines, and so it needs knowledge of both to be effective. The study of machines 
Fig. 14.6  Microsoft Windows 3.11 (1993). (Used with permission from Microsoft)
14  Birth of Software Industry and Human Computer Interaction

169
requires knowledge of computer graphics, programming languages, capabilities of 
current technology, and so on, whereas on the human side, it requires knowledge of 
cognitive psychology, ergonomics, and other human factors such as usability and 
end-user satisfaction. Table 14.1 summarizes Shneiderman’s “Eight Golden Rules 
of Interface Design” [Shn:05]:
There are several fundamental principles and models underlying HCI. It is essen-
tial to understand the user and their characteristics, as well as their diversity in age, 
experience, physical and intellectual abilities, and so on. It is customary to distin-
guish between two types of user knowledge (IT and domain knowledge), and the 
user’s proficiency in each type of knowledge yields several user categories that 
range between novice and expert.
–– Interface knowledge (knowledge of the IT technology)
–– Domain/task knowledge of the real-world system
The software will generally support multiple user categories, where novices get 
opportunities to learn about the system and have fewer opportunities for error. It is 
important to understand the domain in which the software will be used and to iden-
tify the tasks to be performed, as well as the frequency in which they will be 
performed.
Table 14.1  Eight golden rules of interface design
Principle
Description
Strive for consistency Consistent terminology, sequences of action, and commands throughout 
the system
Enable frequent users 
to use shortcuts
The user will naturally desire to reduce the number of interactions as the 
frequency of use increases
Provide informative 
feedback
There should be appropriate system feedback
Design dialog to 
yield closure
Sequences of actions should be organized into groups with a beginning, 
middle and end
Offer simple error 
handling
Design the system (as far as possible) to prevent the user from making a 
serious error. The system should be able to detect an error and provide a 
handling mechanism
Permit easy reversal 
of actions
This is important to the user as it means that errors can be easily undone
Support internal 
locus of control
The system should be designed to make the users initiators of actions 
rather than responders to actions
Reduce short-term 
memory load
There are limitations to human processing in short-term memory, and so 
displays should be kept simple
14.4  Human–Computer Interaction

170
14.4.2  Software Usability
Usability has become an important area in software engineering, and especially 
since the emergence of the World Wide Web in the early 1990s. The usability of the 
software is the perception that a user or group of users has of its quality and ease of 
use (i.e., is the software easy to use and easy to learn?), and its efficiency and effec-
tiveness. Usability is a multidisciplinary field, and psychological testing may be 
employed to evaluate the perception that users have of the computer system. 
Usability is defined in the ISO 9241 standard as:
Usability is the degree to which software can be used by specified consumers to achieve 
quantified objectives with effectiveness, efficiency, and satisfaction in a quantified con-
text of use.
There are several standards for usability including the ISO 9241 and ISO 16982 
standards, and the IEC 62366-1 standard (Applications of Usability Engineering to 
Medical Devices) from the International Electrotechnical Commission (IEC).
Usability, like quality, needs to be built into the software product rather than add-
ing it later, and it needs to be considered from the earliest stages of the software 
development process. It requires an analysis of the user population and the tasks that 
they perform, as well as their knowledge and experience. The specification of the 
user and system requirements needs to include the usability requirements, as these 
are an integral part of the system.
There will often be a variety of different viewpoints to be considered, and this 
leads to multiple design solutions and an evaluation of these against the require-
ments. An iterative software development lifecycle is often employed, with active 
user involvement during the development process. Prototyping is employed to give 
the users a flavor of the proposed system and to get early user feedback on its usabil-
ity. User acceptance testing (including usability testing) provides confidence that 
the software satisfies the usability, accessibility, and quality expectations of the 
users (Table 14.2).
Table 14.2  Software development lifecycle (including usability)
Phase
Description
Requirements
Interviews with the different categories of users
Prototype
Initial prototype developed and structured feedback given by users 
(usually via questionnaire)
Spiral design/
development
Design a little; code a little; test a little; formal review & user feedback 
prior to new spiral
Acceptance
Final acceptance testing by users
14  Birth of Software Industry and Human Computer Interaction

171
14.4.3  User-Centered Design
User-centered design (UCD) is a design process that is focused on the usability of 
and accessibility of the system to be developed, and it places the users at the center 
of the software development process. The users are actively involved from the 
beginning of the project, and regular feedback is obtained from them at each stage 
of the process. UCD follows well-established techniques for analysis and design, 
and it is focused on understanding the characteristics of users and their needs 
(Table 14.3).
The UCD design activities focus on the user, including understanding the tasks 
that they perform, their needs, and their experience. The users clarify what they 
want from the product, and the environment in which the software will be used. The 
designers then determine how the users are currently performing their tasks, and 
what they like and dislike about the ways in which the tasks are currently done. This 
helps the designer to design a product that will be fit for purpose that will satisfy the 
usability expectations of users, as well as being competitive in the market.
The software development team produces an initial version (or prototype) of the 
product, and the prototype has sufficient functionality to test some parts of the 
design. The design and development proceeds in cycles of modification, testing, and 
a user review of the current version, until the software satisfies functional, usability, 
and accessibility requirements. The approach is to design a little; code a little; test a 
little; evaluate and decide on whether to proceed with subsequent cycles.
A prerelease of the software may be created and sent to a restricted set of users 
for their evaluation, and the user feedback is then used to finalize the product prior 
to its actual release.
Table 14.3  UCD principles
Principle
Description
User 
understanding
The design is based on an explicit understanding of users, tasks, and 
environments (i.e., Who are the users? What are their tasks and needs? 
What is their experience?).
User involvement
The users are involved throughout the design and development (and user 
feedback shapes the design and development).
User evaluation
The design is driven and refined by user evaluation (and the user acceptance 
testing confirms that the usability and functional requirements are properly 
implemented).
Iterative 
development
The software development process is iterative, and the approach is to design 
and develop a little, get feedback from the user evaluation, modify 
accordingly and proceed to the next cycle in the iteration.
Design
The design addresses the whole user experience.
Multidisciplinary
The design team includes multidisciplinary skills.
14.4  Human–Computer Interaction

172
14.5  The Mouse
The computer mouse was invented by Douglas Engelbart of the Augmentation 
Research Center (ARC) at the Stanford Research Institute (SRI) in the mid-1960s. 
It consisted of a wooden shell, a circuit board, and two metal wheels that came into 
contact with the surface that it was being used on (Fig. 14.7). Engelbart had been 
investigating ways for individuals to improve their capability in solving complex 
problems, and the mouse was part of ARC’s oNline System (NLS).
Engelbart envisaged problem-solvers using computer-aided work stations using 
some sort of device to move a cursor around a screen. Engelbart and Bill English 
developed the first prototype of the mouse in 1964, and it worked on an early win-
dows graphical user interface. They christened the device “mouse” as the early pro-
totypes had a cord attached to the rear part of the device that looked like a tail and 
resembled an actual mouse.
The 1967 patent application described the mouse as an X-Y position indicator 
for a display system. It was publicly demonstrated at a famous computer conference 
in 1968, where Engelbart and a group of 17 other researchers of the ARC group 
gave a public demonstration of their NLS System.
The public demonstration took place at the Fall Joint Computer Conference held 
in San Francisco, and the mouse was just one of several innovations presented by 
Engelbart on that day. The goal of the NLS system was to act as an instrument to 
help humans operate within the domain of complex information structures.
The demonstration included the mouse, hypertext,1 a precursor to today’s graphi-
cal user interfaces; networked computers with shared screen collaboration involving 
two people at different sites communicating over a network with audio and video 
interface. The public demonstration introduced several fundamental computing 
concepts taken for granted today, and it later became known as “The Mother of 
all Demos.”
The mouse operates on the principle that the computer determines the distance 
and speed that the mouse has traveled and converts that information into coordinates 
that it can plot on a display screen. The original mouse was used by Engelbart to 
navigate the NLS system, and this was also the first system to use hypertext.
1 Ted Nelson coined the term hypertext in the early 1960s.
Fig. 14.7  SRI First Mouse
14  Birth of Software Industry and Human Computer Interaction

173
Bill English moved to Xerox PARC in 1971, and the “Ball Mouse” was devel-
oped by English at PARC in 1972. It replaced the external wheels with a single ball 
that could rotate in any direction. The ball mouse became an important part of the 
graphical user interface of the Xerox Alto computer system, which was developed 
in Xerox and used at several universities. Xerox eventually commercialized a ver-
sion of the Alto (the Xerox Star 8010) in 1981, and this was one of the earliest 
computers to be sold with a mouse.
The term “mouse” became an accepted term of the modern computer lexicon 
when it was introduced as a standard part of the Apple Macintosh in 1984 (Fig. 14.8). 
Steve Jobs had visited PARC to see the Xerox Alto, and he licensed the technology 
from Xerox. The Apple Lisa and Macintosh both used a graphical user interface and 
a mouse, and Microsoft made the MS/DOS Microsoft Word program mouse com-
patible, and the first Microsoft mouse for the PC appeared in 1983. The mouse 
became pervasive after the release of the Apple Macintosh and later Atari and Amiga 
personal computers in the mid-1980s, and the release of Microsoft Windows 3.0 in 
the early 1990s.
A mouse is a pointing device that detects two-dimensional motion relative to a 
surface, and it generally involves the motion of a pointer on a display. It is held in 
the user’s hand and generally has one or more buttons and a scroll wheel (Fig. 14.9).
An optical mouse was invented in 1980, which eliminated the need for the use of 
the rolling ball. The latter often became dirty from rolling around leading to a nega-
tive impact on its performance. It was several years before optical mice became 
commercially viable, but today they have replaced ball-based mice and are supplied 
as a standard part of new computers.
An optical mouse is an advanced computer-pointing device that uses a light-­
emitting diode (LED), an optical sensor, and digital signal processing (DSP) instead 
of the traditional ball mouse technology. Movement is detected by sensing changes 
in reflected light rather than the interpretation of a rolling sphere. Steve Kirsch of 
MIT and Mouse Corporation and Richard Lyon of Xerox invented the first optical 
mouse independently of each other in 1980.
Fig. 14.8  Two Macintosh 
Plus Mice. 1984
14.5  The Mouse

174
14.6  Review Questions
14.7  Summary
IBM decided in 1968 to unbundle many of its software programs, and this decision 
changed the computer industry forever, with software changing from being a give-
away item to becoming a commercial product and industry in its own right. This 
decision led in time to the software and services industry that we see today, and the 
quality of software and its usability became increasingly important.
Human–computer interaction is a branch of computer science that is concerned 
with the design, evaluation, and implementation of interactive computing systems 
for human use. It is focused on the interfaces between people and computers and has 
grown over the decades to include text-based interaction systems, graphical user 
interfaces, and voice user interfaces.
Humans interact with computers in many ways, and so it is important to under-
stand the interface between them to facilitate the interaction. The early interaction 
between humans and computers was via batch processing with limited interaction 
between the operator and computer. These were followed by text-based interfaces 
(also known as a command line interface), where the system interaction (input and 
output) and navigation is text based.
	1.	
Describe the evolution of the software industry.
	2.	
Describe the suite of applications in Microsoft Office.
	3.	
What is a text-based interface?
	4.	
What is a graphical user interface?
	5.	
Explain the importance of software usability.
	6.	
Investigate the various usability standards such as ISO 9241 and 
ISO 16982.
	7.	
Explain user-centered design.
	8.	
Describe the evolution of human computer interfaces.
Fig. 14.9  A. Computer 
mouse with two buttons 
and a scroll wheel
14  Birth of Software Industry and Human Computer Interaction

175
The graphical user interface is a human computer interface that uses graphical 
icons, menus, and windows to represent information and action to the user. They are 
intuitive and user friendly and have made computers and electronic devices attrac-
tive to nontechnical users.
The success of modern software systems is related to the usability of the soft-
ware, and user-centered design has become a key paradigm in building usability in 
the software. It places the user at the center of the software development process 
with active user involvement and evaluation employed.
14.7  Summary

177
© The Author(s), under exclusive license to Springer Nature 
Switzerland AG 2021
G. O’Regan, A Brief History of Computing, 
https://doi.org/10.1007/978-3-030-66599-9_15
Chapter 15
History of Programming Languages
15.1  Introduction
Hardware is physical and may be seen and touched, whereas software is intangible 
and is an intellectual undertaking by a team of programmers. Software is written in 
a programming language, and hundreds of languages have been developed since the 
development of the early computers. Programming languages have evolved with the 
earliest languages using machine code to instruct the computer. The next develop-
ment was the use of assembly languages to represent machine language instruc-
tions. These were then translated into machine code by an assembler. The next step 
was to develop high-level programming languages such as FORTRAN and 
COBOL. These were easier to use than assembly languages and machine code, and 
helped to improve quality and productivity.
A first-generation programming language (or 1GL) is a machine-level program-
ming language that consists of 1 s and 0 s. The main advantage of these languages 
is execution speed as they may be directly executed on the computer, and they do 
not require a compiler or assembler to convert from a high-level language or assem-
bly language into the machine code.
However, writing a program in machine code is difficult and error prone, as it 
involves writing a stream of binary numbers. This made the programming language 
difficult to learn and difficult to correct should any errors occur. The programming 
instructions were entered through the front panel switches of the computer system, 
and adding new code was difficult. Further, the machine code was not portable, as 
the machine language for one computer could differ significantly from that of 
Key Topics
Generations of programming languages
Imperative languages
ALGOL
Fortran and Cobol
Pascal and C
Object-oriented languages
Java and C++
Functional programming languages
Logic programming languages
Syntax and semantics

178
another computer. Often, the program needed to be totally re-written for the new 
computer. First-generation languages were used mainly on the early computers.
Second-generation languages, or 2GL, are low-level assembly languages that are 
specific to a computer and processor. However, assembly languages are easier to 
read than the first-generation machine code, and the assembler converts the assem-
bly code into the actual machine code to run on the computer. The assembly lan-
guage is specific to a processor family and environment, and it is therefore not 
portable. They require considerably more programming effort than high-level pro-
gramming languages, and are more difficult to use for larger applications.
A program written in assembly language often needs to be rewritten for a differ-
ent platform. However, since the assembly language is in the native language of the 
processor, it has significant speed advantages over high-level languages. Second-­
generation languages are still used today, but high-level programming languages 
have generally replaced them.
The third-generation languages, or 3GL, include high-level programming lan-
guages such as Pascal, C or FORTRAN. These are general-purpose languages and 
have been applied to business, scientific, and general applications. A program written 
in a high-level programming language is generally translated by the compiler1 into the 
machine language of the target computer for execution. They are designed to be easier 
for a human to understand, and include features such as named variables, conditional 
statements, iterative statements, assignment statements, and data structures. Early 
examples of third-generation languages are FORTRAN, ALGOL and COBOL, and 
later examples are C, C++ and Java. The advantages of these high-level languages are:
–– Ease of readability
–– Clearly defined syntax (and semantics2)
–– Suitable for business or scientific applications
–– Machine independent
–– Portability to other platforms
–– Ease of debugging
–– Execution speed.
1 This is true of code generated by native compilers. Other compilers may compile the source code 
to the object code of a Virtual Machine, and the translator module of the Virtual Machine translates 
the byte code of the Virtual Machine to the corresponding native machine instruction. That is, the 
Virtual Machine translates each generalized machine instruction into a specific machine instruc-
tion (or instructions) that may then be executed by the processor on the target computer. A com-
puter language such as C requires a separate compiler for each computer platform (i.e., computer 
and operating system). However, a language such as Java comes with a virtual machine for each 
platform. This allows the source code statements in these programs to be compiled just once, and 
they may then be executed on any platform.
2 The study of programming language semantics commenced in the 1960s. It includes work done 
by Hoare on Axiomatic Semantics; work done by Gordon Plotkin on Operational Semantics; and 
work done by Scott and Strachey on Denotational Semantics.
15  History of Programming Languages

179
These languages are machine independent and may be compiled for different 
platforms. The early 3GLs were procedural in that they focused on how something 
is done rather than on what needs to be done. The later 3GLs were object-oriented3 
and the programming tasks were divided into objects. Objects may be employed to 
build larger programs, in a manner that is analogous to building a prefabricated 
building from its constituent parts. Java, C++ and Smalltalk are examples of object-­
oriented languages.
High-level programming languages allow programmers to focus on problem-­
solving rather than on the low-level details associated with assembly languages. 
They are easier to debug and to maintain than assembly languages.
Fourth-generation languages specify what needs to be done rather than how it 
should be done. They are designed to reduce programming effort and include report 
generators and form generators. Report generators take a description of the data 
format and the report that is to be created, and then automatically generate a pro-
gram to produce the report. Form generators are used to generate programs to man-
age online interactions with the application system users. However, a disadvantage 
of 4GLs is that they are slow compared to compiled languages.
A fifth-generation programming language, or 5GL, is a programming language 
that is based around solving problems using constraints applied to the program, 
rather than using an algorithm written by the programmer. Fifth-generation lan-
guages are designed to make the computer (rather than the programmer) solve the 
problem. The programmer specifies the problem and the constraints to be satisfied, 
and is not concerned with the algorithm or implementation details. These languages 
are mainly used for research purposes, especially in the field of artificial intelli-
gence. Prolog is one of the best known fifth-generation languages, and it is a logic 
programming language.
The task of deriving an efficient algorithm from a set of constraints for a problem 
is non-trivial, and to date this step has not been successfully automated. Fifth-­
generation languages are used mainly in academia.
15.2  Plankalkül
Plankalkül was developed by Konrad Zuse in 1946 and it is the earliest high-level 
programming language. It means “Plan” and “Kalkül,” that is, a calculus of pro-
grams. It is a relatively modern language for such an old language, and there was no 
compiler available at the time of its creation. It was over 50 years before the first 
Plankalkül program was run, and this happened when the Free University of Berlin 
designed and developed the first compiler for the language in 2000.
3 Norwegian Research originally developed object-oriented programming with their work on 
Simula-67 in the late 1960s.
15.2  Plankalkül

180
The language employs data structures and Boolean algebra, and includes a 
mechanism to define more powerful data structures. Zuse demonstrated that the 
Plankalkül language could be used to solve scientific and engineering problems, and 
he wrote several example programs including programs for sorting lists and search-
ing a list for an entry. The main features of Plankalkül are:
–– A high-level language.
–– Fundamental data types are arrays and tuples of arrays.
–– While construct for iteration.
–– Conditionals are addressed using guarded commands.
–– There is no GOTO statement.
–– Programs are non-recursive functions.
–– Type of a variable is specified when it is used.
The main constructs of the language are variable assignment, arithmetical and 
logical operations, guarded commands, and while loops. There are also some list 
and set processing functions.
15.3  Imperative Programming Languages
Imperative programming is a programming style that describes computation in 
terms of a program state, and statements that change the state. The term “impera-
tive” is a command to carry out a specific instruction or action, and imperative 
programming consists of a set of commands to be executed on the computer, and is 
therefore concerned with how the program will be executed. The execution of an 
imperative command generally results in a change of state.
Imperative programming languages are quite distinct from functional and logic 
programming languages. Functional programming languages, like Miranda, have 
no global state, and programs consist of mathematical functions that have no side 
effects. In other words, there is no change of state, and the variable x will have the 
same value later in the program as it does earlier. Logic programming languages, 
like Prolog, define “what” is to be computed, rather than “how” the computation is 
to take place.
Most high-level programming languages are imperative languages, and assem-
bly languages and machine code are also imperative languages. Imperative pro-
grams tend to be more difficult to reason about due to the change of state, as the 
variable x may have a different value later in the program.
High-level imperative languages use program variables and employ commands 
such as assignment statements, conditional statements, iterative commands, and calls 
to procedures. An assignment statement performs an operation on information located 
in memory, and stores the results in memory. Its effect is a change of the program 
state. A conditional statement allows a statement to be executed only if a specified 
condition is satisfied, whereas an iterative statement allows a statement (or a group of 
statements) to be executed multiple times while a specified condition is satisfied.
15  History of Programming Languages

181
High-level imperative languages allow the evaluation of complex expressions 
such as arithmetic operations and function evaluations, and the resulting value of 
the expression is assigned to memory.
FORTRAN was developed in the mid-1950s, and it was one of the earliest pro-
gramming languages. ALGOL was developed in the late 1950s and 1960s, and it 
became a popular language for the expression of algorithms. COBOL was designed 
in the late 1950s as a programming language for business use. George Kemeny and 
Thomas Kurtz designed the BASIC (Beginner’s All Purpose Symbolic Instruction 
Code) programming language in the 1960s. Niklaus Wirth developed Pascal in the 
early 1970s. Denis Ritchie developed the C programming language at Bell Labs in 
the early 1970s.
Object-oriented languages include features to support objects, and Norwegian 
Research developed Simula 67 in the late 1960s. Xerox PARC was influenced by 
Simula, and they developed the Smalltalk language in the late 1970s. Bjorne 
Stroustrup designed C++ in 1985 as an object-oriented extension of the C language. 
Sun Microsystems released Java in 1996. The Ada programming language was 
developed for the US military in the early 1980s.
15.3.1  FORTRAN and COBOL
FORTRAN (FORmula TRANslator) was the first high-level programming language 
to be implemented. John Backus developed it at IBM in the mid-1950s, and the first 
compiler was available in 1957. The language includes named variables, complex 
expressions, and subprograms. It was designed for scientific and engineering appli-
cations, and remains the most important programming language for these domains. 
The main statements of the language include:
–– Assignment Statements (using the = symbol)
–– IF Statements
–– Goto Statements
–– DO Loops
Fortran II was developed in 1958, and it introduced subprograms and functions 
to support procedural (or imperative) programming. Each procedure (or subroutine) 
contains computational steps to be carried out when it is called (at any point) during 
program execution. This could include calls by other procedures or by itself. 
However, recursion was not allowed until Fortran 90. Fortran 2003 provides support 
for object-oriented programming.
The basic types supported in FORTRAN include Boolean, Integer, and Real. 
Support for double precision and complex numbers was added later. The language 
includes relational operators for equality (.EQ.), less than (.LT.), and so on. 
FORTRAN is good at handling numbers and computation, and this made it espe-
cially suitable for mathematical and engineering problems. The following code 
(written in Fortran 77) gives a flavor of the language.
15.3  Imperative Programming Languages

182
    PROGRAM HELLOWORLD
C     FORTRAN 77 SOURCE CODE COMMENTS FOR HELLOWORLD
        PRINT ‘(A)’, ‘HELLO WORLD’
        STOP
        END
FORTRAN remains a popular language for application such as climate model-
ing; simulations of the solar system; modeling the trajectories of artificial satellites; 
and simulation of automobile crash dynamics.
It was initially weak at handling input and output, which was important to busi-
ness computing. This led to the development of the COBOL programming language 
in the late 1950s.
The Common Business Oriented Language (COBOL) was the first business pro-
gramming language, and it was introduced in 1959. Grace Murray Hopper4 
(Fig. 15.1) and a group of computer professionals called the Conference on Data 
Systems Languages (CODASYL) designed it with the objective of improving the 
readability of software source code. It has an English-like syntax designed to make 
it easy to learn the language, and its only data types are numbers and strings of text, 
that may be grouped into arrays and records. The language is verbose:
4 Mary Hopper was a programmer on the Mark 1, Mark II, and Mark III and UNIVAC 1 computers. 
She was the technical advisor to the CODASYL committee.
Fig. 15.1  Grace Murray and UNIVAC
15  History of Programming Languages

183
     “DIVIDE A BY B GIVING C REMAINDER D.”
COBOL was the first computer language whose use was mandated by the US 
Department of Defense. The language remains in use today, and there is an object-­
oriented version of the language.
15.3.2  ALGOL
ALGOL (ALGOrithmic Language) is a family of imperative programming lan-
guages that was originally developed in the mid-1950s. It was later revised in 
ALGOL 60, and ALGOL 68, and the language was designed to address some of the 
problems in FORTRAN. ALGOL was not a widely used language, and this may 
have been due to the refusal of IBM to support ALGOL, and the dominance of IBM 
in the computing field.
A committee of American and European computer scientists designed the lan-
guage, and ALGOL had a significant influence on later language design. ALGOL 60 
[Nau:60] was the most popular member of the family, and Edsger Dijkstra devel-
oped an early ALGOL 60 compiler. John Backus and Peter Naur developed a 
method for describing the syntax of the ALGOL 58 programming language, which 
is known as Backus Naur form (or BNF).
ALGOL includes data structures and block structures. Block structures were 
designed to allow blocks of statements to be created (e.g., for procedures or func-
tions). A variable defined within a block may be used within the block but is out of 
scope outside of the block.
ALGOL 60 introduced two ways of passing parameters to subprograms, and 
these are “call by value” and “call by name.” The call by value parameter passing 
technique involves the evaluation of the arguments of a function or procedure before 
the function or procedure is entered. The values of the arguments are passed to the 
function or procedure, and any changes to the arguments within the called function 
or procedure have no effect on the actual arguments. The call by name parameter 
passing technique is the default parameter passing technique in ALGOL 60. It 
involves re-evaluating the actual parameter expression each time the formal param-
eter is read. Call by name is used today in C/C++ macro expansion.
ALGOL 60 includes conditional statements and iterative statements. It supports 
recursions: that is, it allows a function or procedure to call itself. It includes:
•	 Dynamic Arrays: These are arrays in which the subscript range is specified by 
variables.
•	 Reserved Words: These are keywords that are not allowed to be used as identifi-
ers by the programmer.
•	 User defined data types: These allow the user to design their own data types.
•	 ALGOL uses bracketed statement blocks and it was the first language to use 
begin end pairs for delimiting blocks.
15.3  Imperative Programming Languages

184
ALGOL was used mainly by researchers in the United States and Europe. There 
was a lack of interest to its adoption by commercial companies, due to the absence 
of standard input and output facilities in its description. ALGOL 60 became the 
standard for the publication of algorithms, and it had a major influence on later 
language development.
ALGOL evolved during the 1960s, but not in the right direction. The ALGOL 68 
committee decided on a very complex design rather than the simple and elegant 
ALGOL 60 specification. Tony Hoare remarked that:
ALGOL 60 was a great improvement on its successors.
15.3.3  Pascal and C
Niklaus Wirth designed the Pascal programming language in the early 1970s. It is 
named after Blaise Pascal (a seventeenth-century French mathematician), and it was 
based on the ALGOL programming language. It was intended as a language to teach 
students structured programming.
Structured programming is concerned with rigorous techniques to design and 
develop programs, and there was intense debate on correct approaches to software 
development in the late 1960s. Dijkstra argued against the use of the GOTO state-
ment “GOTO Statement considered harmful” [Dij:68-a], and this influenced lan-
guage design, and led to several languages that did not include the construct.
The Pascal language includes the conditional if statement; the iterative while, 
repeat and for statements; the assignment statement; and the case statement (which 
is a generalized if statement). The statement in the body of the repeat statement is 
executed at least once, whereas the statement within the body of a while statement 
may never be executed.
The language has several reserved words (known as keywords) that have a spe-
cial meaning, and these may not be used as program identifiers. The Pascal program 
that displays “Hello World” is given by:
program HELLOWORLD (OUTPUT);
begin
       WRITELN ('Hello, World!')
end.
Pascal includes several simple data types such as Boolean, Integer, Character and 
Reals, and it also has more advanced data types such as arrays, enumeration types, 
ordinal types, and pointer data types. It allows complex data types to be constructed 
from existing data types using records, and types are introduced with the reserved 
word “type”.
15  History of Programming Languages

185
  type
           c = record
                  a: integer;
                  b: char
            end;
Pascal includes a “pointer” data type, and this data type allows linked lists to be 
created by including a pointer type field in the record. The variable linklist is a 
pointer to the data type B in the example below where B is a record.
type
  BPTR = ^B;
  B = record
        A: integer;
        C: BPTR
      end;
var
  linklist : BPTR;
Pascal is a block-structured language with programs structured into procedures 
and function blocks. These can be nested and recursion is allowed. Each block has 
its own constants, types, variables, and other procedures and functions, which are 
defined, within the scope of the block.
Pascal was criticized as being unsuitable for serious programming by Brian 
Kernighan and others [Ker:81-b]. Many of these deficiencies were addressed in later 
versions of the language. However, by then, Denis Richie at Bell Labs had devel-
oped the C programming language, which became popular in industry. C is a gen-
eral purpose and a systems programming language.
It was originally designed as a language to write the kernel for the UNIX operat-
ing system, which was novel, as operating systems were traditionally written in 
assembly languages. The success of C in writing the UNIX kernel led to its use on 
several other operating systems such as Windows and Linux. It also influenced later 
language development such as C++, and the language is described in detail in 
[KeR:78-a].
C provides high-level and low-level capabilities, and a C program that is written 
in ANSI C with portability in mind may be compiled for a very wide variety of 
computer platforms and operating systems (with minimal changes to the source 
code). The C language is now available on a wide range of platforms.
C is a procedural programming language and includes conditional statements 
such as the “if statement”; the “switch statement”; iterative statements such as the 
“while” statement or “do” statement; and the assignment statement.
15.3  Imperative Programming Languages

186
    • If Statement
        if (A == B)
                A = A + 1;
        else
                A = A – 1;5
    • Assignment Statement
        i  = i + 1;
One of the first programs that people write in C is the Hello world program. This 
is given by:
    main()
    {
             printf("Hello, World\n");
    }
It includes several predefined data types including integers and floating-point 
numbers.
       - int       (integer)
       - long    (long integer)
       - float    (floating point real)
       - double (double precision real)
It allows more complex data types to be created using “structs,” which are similar 
to records in Pascal. It allows the use of pointers to access memory locations, which 
allows the memory locations to be directly referenced and modified. For example, 
the result of the following program fragment is that the value 5 is assigned to the 
variable x.
        int    x;
         int   *ptr_x;
         x = 4;
          ptr_x = &x;
          *ptr_x =5;
C is a block-structured language, and a program is structured into functions (or 
blocks). Each function block contains variables and functions, and a function may 
call itself (i.e., recursion is allowed).
5 The semi-colon in Pascal is used as a statement separator, whereas it is used as a statement termi-
nator in C.
15  History of Programming Languages

187
One key criticism of C is that it is very easy to make errors in C programs, and to 
thereby produce undesirable results. For example, one of the easiest mistakes to 
make is to accidentally write the assignment operator (=) for the equality operator 
(==). This totally changes the meaning of the original statement as can be seen below:
     if (a == b)
             a++;                …. Program fragment A
      else
             a--
     if (a = b)
             a++;                …. Program fragment B
      else
             a--
Both program fragments are syntactically correct and the intended meaning of a 
program is easily changed. The philosophy of C is to allow statements to be written 
as concisely as possible, and this is potentially dangerous.6 The use of pointers may 
lead to problems as uninitialized pointers may point anywhere in memory, and may 
therefore overwrite anywhere in memory. Therefore, the effective use of C requires 
experienced programmers, well-documented source code, and formal peer reviews 
of the source code by other developers.
15.4  Object-Oriented Languages
The traditional view of programming is that a program is a collection of functions, 
or a list of instructions to be performed on the computer. Object-oriented program-
ming is a paradigm shift in programming, where a computer program is viewed as a 
collection of objects that act on each other. Each object may send and receive mes-
sages and process data. That is, each object may be viewed as an independent entity 
or actor with a distinct role or responsibility.
An object is a “black box” which sends and receives messages. A black box 
consists of code (computer instructions) and data (information which these instruc-
tions operate on). The traditional way of programming kept code and data separate. 
For example, functions and data structures in the C programming language are not 
connected. However, in the object-oriented world, code and data are merged into a 
single indivisible thing called an object.
The reason that an object is called a black box is that the user of an object never 
needs to look inside the box, since all communication to it is done via messages. 
6 It is very easy to write incomprehensible code in C and even a 1-line of C code can be incompre-
hensible. The maintenance of poorly written code is a challenge unless programmers follow good 
programming practice. This discipline needs to be enforced by formal reviews of the source code.
15.4  Object-Oriented Languages

188
Messages define the interface to the object. Everything an object can do is repre-
sented by its message interface. Therefore, there is no need to know anything about 
what is in the black box (or object) to use it. The access to an object is only through 
its messages, while keeping the internal details private. This is called information 
hiding7 and is due to work by Parnas in the early 1970s.
The origins of object-oriented programming go back to the invention of Simula 
67 at the Norwegian Computing Research Center8 in the late 1960s. Simula 67 
introduced the notion of a class and instances of a class,9 and it influenced later 
languages such as Smalltalk developed at Xerox PARC in the mid-1970s. Xerox 
introduced the term “Object-oriented programming” for the use of objects and mes-
sages as the basis for computation. Most modern programming languages support 
object-oriented programming (e.g., Java and C++), and object-oriented features 
have been added to many existing languages such as BASIC, FORTRAN, and Ada. 
The main features of object-oriented languages are described in Table 15.1.
Object-oriented programming has become popular in large-scale software devel-
opment, and it became the dominant programming paradigm from the early 1990s. 
Its proponents argue that it is easier to learn, and simpler to develop and maintain 
such programs. Its growth in popularity was helped by the rise in popularity of 
Graphical User Interfaces (GUI), which is well suited to object-oriented program-
ming. C++ and Java are popular object-oriented programming languages.
15.4.1  C++ and Java
Bjarne Stroustroup developed C++ in 1983 as an object-oriented extension of the C 
programming language. It was designed to use the power of object-oriented pro-
gramming, and to maintain the speed and portability of C. It provides a significant 
extension of C’s capabilities, but it does not force the programmer to use the object-­
oriented features of the language.
A key difference between C++ and C is the concept of a class. A class is an 
extension to the C concept of a structure, where the main difference is that while a 
C data structure can hold only data, a C++ class may hold both data and functions. 
An object is an instantiation of a class, that is the class is essentially the type, 
whereas the object is essentially a variable of that type. Classes are defined in C++ 
by using the keyword class:
7 Information hiding is a key contribution by Parnas to computer science. He has also done work 
on mathematical approaches to software quality using tabular expressions [ORg:16b].
8 The inventors of Simula-67 were Ole-Johan Dahl and Kristen Nygaard.
9 Dahl and Nygaard were working on ship simulations and were attempting to address the huge 
number of combinations of different attributes from different types of ships. Their insight was to 
group the different types of ships into different classes of objects, with each class of objects being 
responsible for defining its own data and behavior.
15  History of Programming Languages

189
  class class_name
  {
       access_specifier_1:
                 member1;
        access_specifier_2:
                 member2;
        ...
  }
The members may be either data or function declarations, and an access specifier 
is included to specify the access rights for each member (e.g., private, public, or 
protected). Private members of a class are accessible only by other members of the 
same class; public members are accessible from anywhere where the object is visi-
ble; protected are accessible by other members of same class and from members of 
their derived classes. An example of a class in C++ is the definition of the class 
rectangle:
Table 15.1  Object-oriented paradigm
Feature
Description
Class
A class defines the abstract characteristics of a thing, including its attributes 
(or properties), and its behaviors (or methods). The members of a class are 
termed objects.
Object
An object is an instance of a class with its own set of attributes. The set of 
values of the attributes of an object is called its state.
Method
The methods associated with a class represent the behaviors of the objects 
in the class.
Message passing
Message passing is the process by which an object sends data to another 
object, or asks the other object to invoke a method.
Inheritance
A class may have sub-classes (or children classes) that are more specialized 
versions of the class. A subclass inherits the attributes and methods of the 
parent class. This allows the programmer to create new classes from 
existing classes. The derived classes inherit the methods and data structures 
of the parent class.
Encapsulation 
(information 
hiding)
A fundamental principle of the object-oriented world is encapsulation (or 
information hiding). The internals of an object are kept private to the object, 
and may not be accessed from outside the object. That is, encapsulation 
hides the details of how the class is implemented, and it requires a clearly 
specified interface around the services provided.
Abstraction
Abstraction simplifies complexity by modelling classes and removing all 
un-necessary detail. All essential detail is represented, and non-essential 
information is ignored.
Polymorphism
Polymorphism is behavior that varies depending on the class in which the 
behavior is invoked. Two or more classes may react differently to the same 
message. The same name is given to methods in different subclasse, that is 
one interface, and multiple methods.
15.4  Object-Oriented Languages

190
  class CRectangle
  {
      int x, y;
        public:
             void set_values (int,int);
             int area (void);
  } rect;
Java is an object-oriented programming language that was developed by James 
Gosling and others at Sun Microsystems in the early 1990s. C and C++ influenced 
the syntax of the language, and Java was designed with portability in mind. The 
objective is for a program to be written once and executed anywhere. Platform inde-
pendence is achieved by compiling the Java code into Java bytecode, which are 
simplified machine instructions specific to the Java platform.
This code is then run on a Java Virtual Machine (JVM) that interprets and exe-
cutes the Java bytecode. The JVM is specific to the native code on the host hard-
ware. The problem with interpreting bytecode is that it is slow compared to 
traditional compilation. However, Java has several techniques to address this includ-
ing just in time compilation and dynamic recompilation. Java also provides auto-
matic garbage collection. This is a very useful feature, as it protects programmers 
who forget to deallocate memory (thereby causing memory leaks).
Java is a proprietary standard that is controlled through the Java Community 
Process. Sun Microsystems makes most of its Java implementations available with-
out charge. The following is an example of the Hello World program written in Java.
  class HelloWorld
  {
        public static void main (String args[])
     {
                  System.out.println ("Hello World!");
        }
  }
15.5  Functional Programming Languages
Functional programming is quite distinct from imperative programming, in that it 
involves the evaluation of mathematical functions. Imperative programming 
involves the execution of sequential (or iterative) commands that change the state, 
and so, the value of a variable x may change during program execution.
There is no change of state in functional programs, and the fact that the value of 
x will always be the same makes it easier to reason about functional programs than 
imperative programs. Functional programming languages provide referential 
15  History of Programming Languages

191
transparency, that is, equals may be substituted for equals, and if two expressions 
have equal values, then one can be substituted for the other in any larger expression 
without affecting the result of the computation.
Functional programming languages use higher order functions,10 recursion, lazy 
and eager evaluation, monads,11 and Hindley–Milner type inference systems.12 
These languages are mainly used in academia, but there has been some industrial 
use, including the use of Erlang for concurrent applications in industry. Alonzo 
Church developed Lambda calculus in the 1930s, and it provides an abstract frame-
work for describing mathematical functions and their evaluation. It provides the 
foundation for functional programming languages, and Church employed lambda 
calculus to prove that there is no solution to the decision problem for first order 
arithmetic in 1936.
Lambda calculus uses transformation rules, and one of these rules is variable 
substitution. The original calculus developed by Church was untyped, but typed 
lambda calculi have since been developed. Any computable function can be 
expressed and evaluated using lambda calculus, but there is no general algorithm to 
determine whether two arbitrary lambda calculus expressions are equivalent. 
Lambda calculus influenced functional programming languages such as Lisp, ML, 
and Haskell.
Functional programming uses the notion of higher order functions. Higher order 
functions take other functions as arguments, and may return functions as results. 
The derivative function d/dx f(x) = f’(x) is a higher order function that takes a function 
as an argument and returns a function as a result. Higher order functions allow cur-
rying which is a technique developed by Schönfinkel. It allows a function with 
several arguments to be applied to each of its arguments one at a time, with each 
application returning a new (higher order) function that accepts the next argument. 
This allows a function of n-arguments to be treated as n applications of a function 
with 1-argument.
John McCarthy developed LISP at MIT in the late 1950s, which includes many 
of the features found in modern functional programming languages.13 Scheme built 
upon the ideas in LISP, and Kenneth Iverson developed APL14 in the early 1960s. 
APL influenced Backus’s FP programming language, and Robin Milner designed 
the ML programming language in the early 1970s. David Turner developed Miranda 
10 Higher order functions are functions that take functions as arguments or return a function as a 
result. They are known as operators (or functionals) in mathematics.
11 Monads are used in functional programming to express input and output operations without 
introducing side effects. The Haskell functional programming language makes use of uses this 
feature.
12 This is the most common algorithm used to perform type inference, which is concerned with 
determining the type of the value derived from the eventual evaluation of an expression.
13 Lisp is a multi-paradigm language rather than a pure functional programming language.
14 Iverson received the Turing Award in 1979 for his contributions to programming language and 
mathematical notation. The title of his Turing award paper was “Notation as a tool of thought.”
15.5  Functional Programming Languages

192
in the mid-1980s, and it influenced the Haskell programming language developed 
by Philip Wadler and others in the early 1990s.
15.5.1  Miranda
Miranda was developed by David Turner at the University of Kent in the mid-1980s 
[Turn:85]. It is a non-strict functional programming language: that is, the arguments 
to a function are not evaluated until they are required within the function being 
called. This is also known as lazy evaluation, and one of its key advantages is that it 
allows a potentially infinite data structure to be passed as an argument to a function. 
Miranda is a pure functional language, in that there are no side effect features in the 
language. The language has been used for:
–– Rapid prototyping
–– Specification language
–– Teaching language
A Miranda program is a collection of equations that define various functions and 
data structures. It is a strongly typed language with a terse notation.
          z = sqr p / sqr q
                      sqr k = k * k
               p = a + b
                      q = a - b
                      a = 10
                      b = 5
The scope of a formal parameter (e.g., the parameter k above in the function sqr) 
is limited to the definition of the function in which it occurs.
One of the most common data structures used in Miranda is the list. The empty 
list is denoted by [ ], and an example of a list of integers is given by [1, 3, 4]. Lists 
may be appended using the “++” operator. For example:
      [1, 3, 5] ++ [2, 4] is [1, 3, 5, 2, 4].
The length of a list is given by the “#” operator:
      # [1, 3] = 2
The infix operator “:” is employed to prefix an element to the front of a list. For 
example:
15  History of Programming Languages

193
      5 : [2, 4, 6]  is equal to [5, 2, 4, 6]
The subscript operator “!” is employed for subscripting: For example:
      Nums = [5,2,4,6]        then  Nums!0 is 5.
The elements of a list are required to be of the same type. A sequence of elements 
that contains mixed types is called a tuple. A tuple is written as follows:
              Employee = (“Holmes”, “221B Baker St. London”, 50, 
“Detective”)
A tuple is similar to a record in Pascal whereas lists are similar to arrays. Tuples 
cannot be subscripted, but their elements may be extracted by pattern matching. 
Pattern matching is illustrated by the well-known example of the factorial function:
  fac 0 = 1
  fac (n+1) = (n+1) * fac n
The definition of the factorial function uses two equations, distinguished by 
using different patterns in the formal parameters. Another example of pattern match-
ing is the reverse function on lists:
              reverse [] = []
             reverse (a:x) = x : reverse [a]
Miranda is a higher-order language, and it allows functions to be passed as 
parameters and returned as results. Currying is allowed and this allows a function of 
n-arguments to be treated as n applications of a function with 1-argument. Function 
application is left associative, that is, f x y means (f x) y. That is, the result of apply-
ing the function f to x is a function, and this function is then applied to y. Every 
function with two or more arguments in Miranda is a higher order function.
15.5.2  Lambda Calculus
Lambda Calculus (λ-calculus) was designed by Alonzo Church in the 1930s to 
study computability. It is a formal system that may be used to study function defini-
tion, function application, parameter passing and recursion. Any computable func-
tion may be expressed and evaluated using lambda calculus.
Lambda calculus is equivalent to the abstract Turing machine formalism, in that 
they compute the same set of functions. However, lambda calculus emphasizes the 
use of transformation rules, whereas Turing machines are concerned with 
15.5  Functional Programming Languages

194
computability on primitive mathematical machines. Lambda calculus consists of a 
small set of rules:
Alpha-conversion rule (α-conversion)15
Beta-reduction rule (β-reduction)16
Eta-conversion (η-conversion)17
Every expression in the λ-calculus stands for a function with a single argument. 
The argument of the function is itself a function with a single argument, and so on. 
The definition of a function is anonymous in the calculus. For example, the function 
that adds one to its argument is usually defined as f(x) = x + 1. However, in λ-calculus, 
the function is defined as:
                  λ x. x + 1
The name of the formal argument x is irrelevant and an equivalent definition of 
the function is λ z. z + 1. The evaluation of a function f with respect to an argument 
(e.g. 3) is usually expressed by f(3). In λ-calculus, this would be written as (λ x. 
x + 1) 3, and this evaluates to 3 + 1 = 4. Function application is left associative, that 
is f x y = (f x) y. A function of two variables is expressed in lambda calculus as a 
function of one argument, which returns a function of one argument. This is known 
as currying, and the function f(x, y) = x + y is written as λ x. λ y. x + y. This is often 
abbreviated to λ x y. x + y.
λ-calculus is a simple mathematical system and its syntax is defined as follows:
   <exp> ::= <identifier>         |
             λ <identifier>.<exp>  |  --abstraction
             <exp> <exp>              |  --application
             ( <exp> )
        -- Syntax of Lambda Calculus --
λ-Calculus’s four lines of syntax plus conversion rules, are sufficient to define 
Booleans, integers, data structures, and computations on them. It inspired Lisp and 
modern functional programming languages.
15 This essentially expresses that the names of bound variables are unimportant.
16 This essentially expresses the idea of function application.
17 This essentially expresses the idea that two functions are equal if and only if they give the same 
results for all arguments.
15  History of Programming Languages

195
15.6  Logic Programming Languages
Logic programming languages describe what is to be done, rather than how it should 
be done. These languages are concerned with the statement of the problem to be 
solved, rather than how the problem will be solved.
These languages use mathematical logic as a tool in the statement of the problem 
definition. Logic is a useful tool in developing a body of knowledge (or theory), and 
it allows further truths to be rigorously derived from the existing set of truths. The 
theory is built up from a small set of axioms or postulates, and the rules of inference 
allow further truths to be deduced.
The objective of logic programming is to employ mathematical logic to assist 
with computer programming. Many problems are naturally expressed as a theory, 
and the statement of a problem to be solved is often equivalent to determining if a 
new hypothesis is consistent with the existing theory. Logic provides a rigorous way 
to do this, as it includes a rigorous process for conducting proof.
Computation in logic programming is essentially logical deduction, and logic-­
programming languages use first-order18 predicate calculus. It employs theorem 
proving to derive a desired truth from an initial set of axioms. These proofs are 
constructive19 in the sense that an actual object that satisfies the constraints is pro-
duced, rather than a reliance on a theoretical existence theorem. Logic program-
ming specifies the objects, the relationships between them and the constraints that 
must be satisfied for the problem. It involves:
–– The set of objects involved in the computation
–– The relationships that hold between the objects
–– The constraints that must be satisfied for the problem.
The language interpreter then decides how to satisfy the constraints. Artificial 
Intelligence influenced the development of logic programming, and John McCarthy20 
demonstrated that mathematical logic could be used for expressing knowledge. The 
first logic programming language was Planner developed by Carl Hewitt at MIT in 
1969. It used a procedural approach for knowledge representation rather than 
McCarthy’s declarative approach.
The best-known logic programming languages is Prolog, which was developed 
in the early 1970s by Alain Colmerauer and Robert Kowalski. It stands for program-
ming in logic. It is a goal-oriented language that is based on predicate logic. Prolog 
became an ISO standard in 1995. The language attempts to solve a goal by tackling 
the sub-goals that the goal consists of:
18 First-order logic allows quantification over objects but not functions or relations. Higher order 
logics allow quantification of functions and relations.
19 For example, the constructive proof of the statement ∃x such that x = √4 (i.e., there is an x such 
that x is the square root of 4) provides more than a proof of existence, and an actual object satisfy-
ing the existence criteria is explicitly produced (i.e., it produces x = 2 or x – -2).
20 John McCarthy received the Turing Award in 1971 for his contributions to Artificial Intelligence.
15.6  Logic Programming Languages

196
             goal :-  subgoal1 , ..., subgoaln.
That is, to prove a particular goal, it is sufficient to prove subgoal1 through sub-
goaln. Each line of a Prolog program consists of a rule or a fact, and the language 
specifies what exists rather than how. The following program fragment has one rule 
and two facts:
       grandmother(G,S) :-  parent(P,S), mother(G,P).
       mother(sarah, issac).
       parent(issac, jacob).
The first line in the program fragment is a rule that states that G is the grand-
mother of S, if there is a parent P of S such that G is the mother of P. The next two 
statements are facts stating that issac is a parent of jacob, and that sarah is the 
mother of issac. A goal clause is true if all of its sub clauses are true:
          goalclause(Vg) :- clause1(V1),..,clausem(Vm)
A Horn clause consists of a goal clause and a set of clauses that must be proven 
separately. Prolog finds solutions by unification, that is, by binding a variable to a 
value. For an implication to succeed, all goal variables Vg on the left side of: - must 
find a solution by binding variables from the clauses which are activated on the right 
side. When all clauses are examined and all variables in Vg are bound, the goal suc-
ceeds. But if a variable cannot be bound for a given clause, then that clause fails. 
Following the failure, Prolog backtracks, and this involves going back to the left to 
previous clauses to continue trying to unify with alternative bindings. Backtracking 
gives Prolog the ability to find multiple solutions to a given query or goal.
Most logic programming languages use a simple searching strategy to consider 
alternatives:
If a goal succeeds and there are more goals to achieve, then remember any untried 
alternatives and go on to the next goal.
If a goal is achieved and there are no more goals to achieve then stop with success.
If a goal fails and there are alternative ways to solve it then try the next one.
If a goal fails and there are no alternate ways to solve it, and there is a previous goal, 
then go back to the previous goal.
If a goal fails and there are no alternate ways to solve it, and no previous goal, then 
stop with failure.
Constraint programming is a programming paradigm where relations between 
variables can be stated in the form of constraints. Constraints specify the properties 
of the solution, and it differs from imperative programming, in that the sequence of 
steps to execute to establish the solution is not specified.
15  History of Programming Languages

197
15.7  Syntax and Semantics
There are two key parts to any programming language, namely, its syntax and 
semantics. The syntax is the grammar of the language, and a program needs to be 
syntactically correct with respect to its grammar. The semantics of the language is 
deeper, and determines the meaning of what has been written by the programmer. 
The semantics of a language determines what a syntactically valid program will 
compute. A programming language is therefore given by:
          Programming Language = Syntax + Semantics
The theory of the syntax of programming languages is well established, and 
Chomsky21 defined a hierarchy of grammars (regular, context free, context sensi-
tive). Backus Naur Form22 (BNF) is often employed to specify the grammar of 
context-­free languages, which may be input into a parser to determine whether the 
program is syntactically correct. A BNF specification consists of a set of rules 
such as:
          <symbol> ::= <expression with symbols>
where <symbol> is a nonterminal and the expression consists of sequences of 
symbols and/or sequences separated by the vertical bar “|” which indicates a choice. 
Symbols that never appear on a left side are called terminals. The partial definition 
of the syntax of various statements in a programming language is given below:
  <loop statement> ::= <while loop> | <for loop>
  <while loop> ::= while ( <condition> ) <statement>
  <for loop> ::= for ( <expression> ) <statement>
  <statement> ::= <assignment statement>  | <loop statement>
  <assignment statement> ::= <variable> := <expression>
The example above includes various non-terminals (<loop statement>, <while 
loop>, <for loop>, <condition>, <expression>, <statement>, <assignment state-
ment>, and <variable>). The terminals include “while,” “for,” “:=,” “(“and”).” The 
production rules for <condition> and <expression> are not included.
There are various types of grammars such as regular grammars, context-free 
grammars, and context-sensitive grammars. A parser translates the grammar of a 
language into a parse table, and each type of grammar has its own parsing algorithm 
21 Chomsky made important contributions to linguistics and the theory of grammars. He is more 
widely known today as a critic of United States foreign policy.
22 Backus Naur Form is named after John Backus and Peter Naur. It was created as part of the 
design of Algol 60, and used to define the syntax rules of the language.
15.7  Syntax and Semantics

198
to determine whether a particular program is syntactically correct with respect to its 
grammar.
15.7.1  Programming Language Semantics
The formal semantics of a programming language is concerned with the meaning of 
programs. A program is written according to the rules of its grammar (syntax), and 
the compiler then checks that it is syntactically correct, and if so, it generates the 
equivalent machine code.23
The compiler must preserve the semantics of the language, and the syntax of the 
language gives no information as to the meaning of a program. It is possible to write 
syntactically correct programs that behave in quite a different way from the inten-
tions of the programmer.
The formal semantics of a language is given by a mathematical model, which 
describes the possible computations described by the language. The three main 
approaches to programming language semantic are axiomatic semantics, opera-
tional semantics, and denotational semantics. A short summary of each approach is 
described in Table 15.2.
23 Of course, what the programmer has written may not be what the programmer had intended.
Table 15.2  Programming language semantics
Approach
Description
Axiomatic 
semantics
Axiomatic semantics involves giving meaning to phrases of the language with 
logical axioms. This approach was developed by C.A.R Hoare, and is based on 
mathematical logic. It employs pre- and post-condition assertions to specify 
what happens when the statement executes. The relationship between the initial 
assertion and the final assertion essentially gives the semantics of the code.
Operational 
semantics
The operational semantics for a programming language was developed by 
Gordon Plotkin. It describes how a valid program is interpreted by a sequence 
of computational steps.
An abstract machine (SECD machine) may be defined to give meaning to 
phrases, by describing the transitions they induce on states of the machine.
A precise mathematical interpreter (such as the lambda calculus) may also give 
the semantics.
Denotational 
semantics
Denotational semantics (originally called mathematical semantics) provides 
meaning to programs in terms of mathematical objects such as integers, tuples, 
and functions.
Each phrase in the language is translated into a mathematical object that is the 
denotation of the phrase. Christopher Strachey and Dana Scott developed this 
approach in the mid-1960s.
15  History of Programming Languages

199
15.8  Review Questions
15.9  Summary
This chapter considered the evolution of programming languages from machine 
languages, to low-level assembly languages, to high-level programming languages 
and object-oriented languages, and to functional and logic programming languages.
The advantages of machine languages are execution speed and efficiency. 
However, it is difficult to write programs in these languages, as the program involves 
a stream of binary numbers. Further, these languages are not portable, as the machine 
language for one computer may differ significantly from the machine language of 
another.
The second-generation languages are low-level assembly languages that are spe-
cific to a computer and processor. These are easier to write and understand, but they 
must be converted into the actual machine code to run on the computer. They are 
specific to a processor family and environment and are not portable. However, their 
advantages are execution speed, as the assembly language is the native language of 
the processor.
The third-generation languages are high-level programming languages, and have 
been applied to business, scientific, and general applications. They are designed to 
be easier to understand, and to allow the programmer to focus on problem-solving. 
Their advantages include ease of readability, portability, and ease of debugging and 
maintenance. The early 3GLs were procedure-oriented and the later 3GLs were 
object-oriented.
Fourth-generation languages consist of statements similar to human language, 
and are often used in database programming. They specify what needs to be done 
rather than how it should be done, and they have been used as report generators and 
form generators.
	1.	 Describe the five generations of programming languages.
	2.	 Explain the difference between machine code and assembly languages.
	3.	 What are the key features of Fortran and Cobol?
	4.	 Describe the key features of Pascal and C.
	5.	 What are the key features of object-oriented languages?
	6.	 Explain the differences between imperative programming languages and 
functional programming languages.
	7.	 What are the key features of logic programming languages?
	8.	 What is the difference between syntax and semantics?
	9.	 Explain the main approaches to programming language semantics.
15.9  Summary

200
Fifth-generation programming languages or 5GLs are programming languages 
that are based around solving problems using logic programming or applying con-
straints to the program. They are designed to make the computer (rather than the 
programmer) solve the problem. The programmer only needs to be concerned with 
the specification of the problem and the constraints to be satisfied, and does not need 
to be concerned with the algorithm or implementation details.
15  History of Programming Languages

201
© The Author(s), under exclusive license to Springer Nature 
Switzerland AG 2021
G. O’Regan, A Brief History of Computing, 
https://doi.org/10.1007/978-3-030-66599-9_16
Chapter 16
History of Software Engineering
16.1  Introduction
The approach to software development in the 1950s and 1960s has been described 
as the “Mongolian Hordes Approach” by Fred Brooks [Brk:75]1. The “method” or 
lack of method was applied to projects that were running late, and it involved adding 
a large number of programmers to the project, with the expectation that this would 
allow the project schedule to be recovered. However, this approach was deeply 
flawed, as it led to inexperienced programmers with inadequate knowledge of the 
project joining the team and attempting to solve problems, and they inevitably 
required significant time from the other project team members.
This resulted in the project being delivered even later, as well as subsequent 
problems with quality (i.e., the approach of throwing people at a problem does not 
work). The philosophy of software development back in the 1950/1960s was char-
acterized by the beliefs that:
The completed code will always be full of defects.
The coding should be finished quickly to correct these defects.
Design as you code approach.
This philosophy accepted defeat in software development and suggested that 
irrespective of a solid engineering approach, the completed software would always 
1 The “Mongolian Hordes” management myth is the belief that adding more programmers to a 
software project that is running late will allow catch-up. In fact, as Brooks says adding people to a 
late software project actually makes it later.
Key Topics
Standish chaos report
Software lifecycles
Waterfall model
Spiral model
Rational unified process
Agile development
Software inspections
Software testing
Project management
CMMI

202
contain lots of defects, and that it therefore made sense to code as quickly as pos-
sible, and to then identify the defects that would be present, so as to correct them as 
soon as possible.
It was clear in the late 1960s that the existing approaches to software develop-
ment were deeply flawed, and that there was an urgent need for change. The NATO 
Science Committee organized two famous conferences to discuss critical issues in 
software development [Bux:75], with the first conference held at Garmisch, 
Germany, in 1968, and it was followed by a second conference in Rome in 1969.
Over fifty people from eleven countries attended the Garmisch conference, 
including Edsger Djkstra, who did important theoretical work on formal specifica-
tion and verification. The NATO conferences highlighted problems that existed in 
the software sector in the late 1960s, and the term “software crisis” was coined to 
refer to these problems. These included budget and schedule overruns, as well as 
problems with the quality and reliability of the delivered software.
The conference led to the birth of software engineering as a discipline in its own 
right, and the realization that programming is quite distinct from science and math-
ematics. Programmers are like engineers, in that they build software products, and 
they therefore need education in traditional engineering as well as in the latest tech-
nologies. The education of a classical engineer includes product design and mathe-
matics. However, often, computer science education places an emphasis on the 
latest technologies rather than the important engineering foundations of designing 
and building high-quality products that are safe for the public to use.
Programmers therefore need to learn the key engineering skills to enable them to 
build products that are safe for the public to use. This includes a solid foundation on 
design and the mathematics required for building safe software products. 
Mathematics plays a key role in engineering and may assist software engineers in 
the delivery of high-quality software products. Several mathematical approaches to 
assist software engineers are described in [ORg:17b].
There are parallels between the software crisis in the late 1960s, and serious 
problems with bridge construction in the nineteenth century. Several bridges col-
lapsed or were delivered late or over-budget due to the fact that people involved in 
their design and construction did not have the required engineering knowledge. This 
led to bridges that were inadequately designed and constructed, which led to their 
collapse resulting in injury and loss of life.
This led to legislation requiring engineers to be licensed by the Professional 
Engineering Association prior to practicing as engineers. This organization identi-
fied a core body of knowledge that the engineer is required to possess, and the 
licensing body verifies that the engineer has the required qualifications and experi-
ence. This helps to ensure that only personnel competent to design and build prod-
ucts actually do so. Engineers have a professional responsibility to ensure that the 
products are properly built and are safe for the public to use.
The Standish group has conducted research (Fig. 16.1) on the extent of problems 
with IT projects since the mid-1990s. These studies were conducted in the United 
States, but there is no reason to believe that European or Asian companies perform 
any better. The results indicate serious problems with on-time delivery of projects 
16  History of Software Engineering

203
or projects being cancelled prior to completion.2 However, the comparison between 
1995 and 2009 suggests that there have been some improvements with a greater 
percentage of projects being delivered successfully, and a reduction in the percent-
age of projects being cancelled.
Fred Brooks (the project manager for the IBM System 360 project in the 1960s 
[ORg:13]) argues that software is inherently complex, and that there is no silver 
bullet that will resolve all of the problems associated with software development 
such as schedule or budget overruns [Brk:75, Brk:86]. Poor software quality can 
lead to defects in the software that may adversely impact the customer, and even 
lead to loss of life (e.g., the defective Therac-25 radiation machine gave massive 
overdoses of radiation that killed four patients and left two others with lifelong 
injuries in the mid-1980s [LeT:93]). It is therefore essential that software develop-
ment organizations place sufficient emphasis on quality throughout the software 
development lifecycle.
The Y2K problem was caused by a two-digit representation of dates, and it 
required major rework of legacy software for the new millennium. Clearly, well-­
designed programs would have hidden the representation of the date, and would 
have required minimal changes for year 2000 compliance. Instead, companies spent 
vast sums of money to rectify the problem.
The quality of software produced by some companies is impressive.3 These com-
panies employ mature software processes, and are committed to continuous 
improvement. Today, there is a lot of industrial interest in software process maturity 
models for software organizations, and various approaches to assess and mature 
2 These are IT projects covering diverse sectors including banking, telecommunications, etc., rather 
than pure software companies. Software companies following maturity frameworks such as the 
CMMI generally achieve more consistent project results, and the CMMI focuses on the manage-
ment side of software engineering.
3 I recall projects at Motorola that regularly achieved 5.6σ-quality in a L4 CMM environment (i.e., 
approx. 20 defects per million lines of code. This represents very high quality).
Fig. 16.1  Standish report–results of 1995 and 2009 survey
16.1  Introduction

204
software companies are described in [ORg:10, ORg:14].4 These models focus on 
improving the effectiveness of the management, engineering, and organization 
practices related to software engineering and in introducing best practice in soft-
ware engineering. The disciplined use of the mature software processes by the soft-
ware engineers enables high-quality software to be consistently produced.
16.2  What is Software Engineering?
Software engineering involves the multiperson construction of multiversion pro-
grams. The IEEE 610.12 definition of Software Engineering is:
“Software engineering is the application of a systematic, disciplined, quantifiable approach 
to the development, operation, and maintenance of software; that is, the application of 
engineering to software, and the study of such approaches.”
Software engineering includes:
	1.	 Methodologies to design, develop, and test software to meet customers’ needs.
	2.	 Software is engineered. That is, the software products are properly designed, 
developed, and tested in accordance with engineering principles.
	3.	 Quality and safety are properly addressed.
	4.	 Mathematics may be employed to assist with the design and verification of soft-
ware products. The level of mathematics employed will depend on the safety 
critical nature of the product. Systematic peer reviews and rigorous testing will 
often be sufficient to build quality into the software, with heavy mathematical 
techniques reserved for safety and security critical software.
	5.	 Sound project management and quality management practices are employed.
	6.	 Support and maintenance of the software are properly addressed.
Software engineering is not just programming. It requires the engineer to state 
precisely the requirements that the software product is to satisfy, and then to pro-
duce designs that will meet these requirements. The project needs to be planned and 
delivered on time and budget. The requirements must provide a precise description 
of the problem to be solved, that is, it should be evident from the requirements what 
is and what is not required. The requirements need to be rigorously reviewed to 
ensure that they are stated clearly and unambiguously and are exactly what the cus-
tomer wants. The next step is then to create the design that will solve the problem, 
and it is essential to validate the correctness of the design. Next, the software to 
4 Approaches such as the CMM or SPICE (ISO 15504) focus mainly on the management and orga-
nizational practices required in software engineering. The process maturity models provide useful 
information on practices to consider in the implementation, and they focus on what needs to be 
done rather how it should be done. This gives the organization the freedom to choose the appropri-
ate implementation to meet its needs. The emphasis is on defining software processes that are fit 
for purpose and to consistently follow them.
16  History of Software Engineering

205
implement the design is written, and peer reviews and software testing are employed 
to verify and validate the correctness of the software.
The verification and validation of the design is rigorously performed for safety 
critical systems, and it is sometimes appropriate to employ mathematical techniques 
for this. However, it will often be sufficient to employ peer reviews or software 
inspections, as these methodologies provide a high degree of rigor. This may include 
approaches such as Fagan inspections [Fag:76], Gilb inspections [Glb:94], or Prince 
2’s approach to quality reviews [OGC:04].
The term “engineer” is a title that is awarded on merit in classical engineering. It 
is generally applied only to people who have attained the necessary education and 
competence to be called engineers, and who base their practice on classical engi-
neering principles. The title places responsibilities on its holder such as to behave 
professionally and ethically. Often in computer science the term “software engi-
neer” is employed loosely to refer to anyone who builds things, rather than to an 
individual with a core set of knowledge, experience, and competence.
Several computer scientists (such as Parnas5) have argued that computer scien-
tists should be educated as engineers to enable them to apply appropriate scientific 
principles to their work. They argue that computer scientists should receive a solid 
foundation in mathematics and design, to enable them to have the professional com-
petence to perform as engineers in building high-quality products that are safe for 
the public to use. The use of mathematics is an integral part of the engineer’s work 
in other engineering disciplines, and so the software engineer should be able to use 
the appropriate mathematics to assist in the modeling or understanding of the behav-
ior or properties of a proposed software system.
Software engineers need education6 on specification, design, turning designs into 
programs, software inspections, and testing. The education should enable the soft-
ware engineer to produce well-structured programs that are fit for purpose.
Parnas has argued that software engineers have responsibilities as professional 
engineers. They are responsible for designing and implementing high-quality and 
reliable software that is safe to use7. They are also accountable for their decisions 
and actions,8 and have a responsibility to object to decisions that violate ­professional 
5 Parnas has made important contributions to computer science. He advocates a solid engineering 
approach with the extensive use of classical mathematical techniques in software development. He 
also introduced information hiding in the 1970s, which is now a part of object-oriented development.
6 Software Companies that are following approaches such as the CMM or ISO 9001 consider the 
education and qualification of staff prior to assigning staff to performing specific tasks. The appro-
priate qualifications and experience for the specific role are considered prior to appointing a person 
to carry out the role. Many companies are committed to the education and continuous development 
of their staff, and on introducing best practice in software engineering into their organization..
7 The ancient Babylonians used the concept of accountability, and they employed a code of laws 
(known as the Hammurabi Code) c. 1750 B.C. It included a law that stated that if a house collapsed 
and killed the owner, then the builder of the house would be executed.
8 However, it is unlikely that an individual programmer would be subject to litigation in the case of 
a flaw in a program causing damage or loss of life. A comprehensive disclaimer of responsibility 
for problems rather than a guarantee of quality accompany most software products. Software engi-
16.2  What is Software Engineering?

206
standards. Engineers are required to behave professionally and ethically with their 
clients. The membership of the professional engineering body requires the member 
to adhere to the code of ethics9 of the profession. Engineers in other professions are 
licensed, and therefore, Parnas argues that a similar licensing approach be adopted 
for professional software engineers10 to provide confidence that they are competent 
for the particular assignment. Professional software engineers are required to follow 
best practice in software engineering and the defined software processes.11
Many software companies invest heavily in training, as the education and knowl-
edge of its staff are essential to delivering high-quality products and services. 
Employees need to receive professional training related to the roles that they are 
performing, such as project management, service management, and software test-
ing. The fact that the employees are professionally qualified increases confidence in 
the ability of the company to deliver high-quality products and services. A company 
that pays little attention to the competence and continuous development of its staff 
will underperform its peers, and suffer a loss of reputation and market share.
16.3  Challenges in Software Engineering
The challenge in software engineering is to deliver high-quality software on time 
and on budget to customers. The research done by the Standish Group was dis-
cussed earlier in this chapter, and the results of their 1998 research (Fig. 16.2) on 
project cost overruns in the United States indicated that 33% of projects are between 
21% and 50% over estimate, 18% are between 51% and 100% over estimate, and 
11% of projects are between 101% and 200% overestimate.
neering is a team-based activity involving many engineers in various parts of the project, and it 
would be potentially difficult for an outside party to prove that the cause of a particular problem is 
due to the professional negligence of a particular software engineer, as there are many others 
involved in the process such as reviewers of documentation and code and the various test groups. 
Companies are more likely to be subject to litigation, as a company is legally responsible for the 
actions of their employees in the workplace, and a company is a wealthier entity than one of its 
employees. The legal aspects of licensing software may protect software companies from litiga-
tion. However, greater legal protection for the customer can be built into the contract between the 
supplier and the customer for bespoke-software development.
9 Many software companies have a defined code of ethics that employees are expected to adhere. 
Larger companies will wish to project a good corporate image and to be respected worldwide.
10 The British Computer Scientist (BCS) has introduced a qualification system for computer sci-
ence professionals that it used to show that professionals are properly qualified. This includes the 
BCS Information Systems Examination Board (ISEB) that allows IT professionals to be qualified 
in service management, project management, software testing, and so on.
11 Software companies that are following the CMMI or ISO 9000 standards will employ audits to 
verify that the processes and procedures have been followed. Auditors report their findings to 
management and the findings are addressed appropriately by the project team and affected 
individuals.
16  History of Software Engineering

207
The accurate estimation of project cost, effort, and schedule is a challenge in 
software engineering. Therefore, project managers need to determine how good 
their estimation process actually is and to make appropriate improvements. The use 
of software metrics is an objective way to do this, and improvements in estimation 
will be evident from a reduced variance between estimated and actual effort. The 
project manager will determine and report the actual versus estimated effort and 
schedule for the project.
Risk management is an important part of project management, and the objective 
is to identify potential risks early and throughout the project, and to manage them 
appropriately. The probability of each risk occurring and its impact is determined 
and the risks are managed during project execution.
Software quality needs to be properly planned to enable the project to deliver a 
quality product. Flaws with poor-quality software lead to a negative perception of 
the company, and may damage the customer relationship and lead to a loss of mar-
ket share.
There is a strong economic case to building quality into the software, as less time 
is spent in reworking defective software. The cost of poor quality (COPQ) should be 
measured and targets set for its reductions. It is important that lessons are learned 
during the project and are acted upon appropriately. This helps to promote a culture 
of continuous improvement.
There have been a number of high-profile software failures [ORg:14]. These 
included the defective Therac-25 radiation machine, the millennium bug (Y2K) 
problem, the floating point bug in the Intel microprocessor, the European Space 
Agency Ariane-5 disaster, and so on. These have caused embarrassment to the orga-
nizations as well as the cost of replacement and correction.
The defective Therac-25 radiation machine was discussed earlier. The millen-
nium bug was due to the use of two digits to represent dates rather than four digits. 
The solution involved finding and analyzing all code that that had a Y2K impact; 
Fig. 16.2  Standish 1998 report – Estimation accuracy
16.3  Challenges in Software Engineering

208
planning and making the necessary changes; and verifying the correctness of the 
changes. The worldwide cost of correcting the millennium bug is estimated to have 
been in billions of dollars.
The Intel Corporation was slow to acknowledge the floating-point problem in its 
Pentium microprocessor, and in providing adequate information on its impact to its 
customers. This led to a large financial cost in replacing microprocessors for its 
customers. The Ariane-5 failure caused major embarrassment and damage to the 
credibility of the European Space Agency (ESA). Its maiden flight ended in failure 
on June 4, 1996, after a flight time of just 40 s.
These failures indicate that quality needs to be carefully considered when design-
ing and developing software. The effect of software failure may be large costs to 
correct the software, loss of credibility of the company, or even loss of life.
16.4  Software Processes and Lifecycles
Organizations vary by size and complexity, and the processes employed will reflect 
the nature of their business. The development of software involves many processes 
such as those for defining requirements; processes for project management and esti-
mation; processes for design, implementation, testing, and so on.
It is important that the processes employed are fit for purpose, and a key premise 
in the software quality field is that the quality of the resulting software is influenced 
by the quality and maturity of the underlying processes, and compliance to them. 
Therefore, it is necessary to focus on the quality of the processes, as well as the 
quality of the resulting software.
There is, of course, little point in having high-quality processes unless their use 
is institutionalized in the organization. That is, all employees need to follow the 
processes consistently. This requires that people are trained on the new processes 
and that process discipline is instilled by an appropriate audit strategy.
Employees need to be trained on the processes, and audits are conducted to 
ensure process compliance. Data will be collected to improve the process. The soft-
ware process assets in an organization generally consist of:
–– A software development policy for the organization
–– Process maps that describe the flow of activities
–– Procedures and guidelines that describe the processes in more detail
–– Checklists to assist with the performance of the process
–– Templates for the performance of specific activities (e.g., design, testing)
–– Training materials
The processes employed to develop high-quality software generally include:
–– Project management process
–– Requirements process
–– Design process
16  History of Software Engineering

209
–– Coding Process
–– Peer review process
–– Testing process
–– Supplier selection processes
–– Configuration management process
–– Audit process
–– Measurement process
–– Improvement process
–– Customer support and maintenance processes
The software development process has an associated lifecycle that consists of 
various phases. There are several well-known lifecycles employed, such as the 
waterfall model [Roy:70], the spiral model [Boe:88], the Rational Unified Process 
[Jac:99], and the Agile methodology [Bec:00], which has become popular in recent 
years. The choice of a particular software development lifecycle is determined from 
the particular needs of the specific project. The various lifecycles are described in 
more detail in the following sections.
16.4.1  Waterfall Lifecycle
The origins of the waterfall model12 (Fig. 16.3) are in the manufacturing and con-
struction industry, and Winston Royce defined it formally for software development 
in 1970 [Roy:70]. It starts with requirements gathering and definition. It is followed 
by the functional specification, the design and implementation of the software, and 
comprehensive testing. The testing generally includes unit, system and user accep-
tance testing.
It is employed for projects where the requirements can be identified early in the 
project lifecycle or are known in advance. It is often called the “V” life cycle model, 
with the left-hand side of the “V” detailing requirements, specification, design, and 
coding and the right-hand side detailing unit tests, integration tests, system tests and 
acceptance testing. Each phase has entry and exit criteria that must be satisfied 
before the next phase commences. There are several variations to the water-
fall model.
Many companies employ a set of templates to enable the activities in the various 
phases to be consistently performed. Templates may be employed for project plan-
ning and reporting, requirements definition, design, testing, and so on. These tem-
plates may be based on the IEEE standards or on industrial best practice.
12 We treat the waterfall model as identical to the V model in this text.
16.4  Software Processes and Lifecycles

210
16.4.2  Spiral Lifecycles
The spiral model (Fig. 16.4) was developed by Barry Boehm in the mid-1980s, and 
is useful for a project in which the requirements are not fully known at project initia-
tion, or where the requirements evolve as a part of the development lifecycle. The 
development proceeds in a number of spirals, where each spiral typically involves 
objectives and an analysis of the risks, updates to the requirements, design, code, 
testing, and a user review of the particular iteration or spiral. The early spirals are 
concerned with prototyping with the later spirals concerned with the full implemen-
tation of the system.
The spiral is, in effect, a reusable prototype with the business analysts and the 
customer reviewing the current iteration, and providing feedback to the develop-
ment team. The feedback is analyzed and used to plan the next iteration. This 
approach is often used in joint application development, where the usability and 
look and feel of the application are a key concern. This is important in web-based 
development and in the development of a graphical user interface (GUI). The imple-
mentation of part of the system helps in gaining a better understanding of the 
requirements of the system, and this feeds into subsequent development cycle. The 
process repeats until the requirements and the software product are fully complete.
There are several variations in the spiral model, including Rapid Application 
Development (RAD), Joint Application Development (JAD) models, and the 
Dynamic Systems Development Method (DSDM) model. Agile methods have 
become popular in recent years and these generally employ sprints (or iterations) of 
two weeks’ duration to implement a number of user stories.
There are other life cycle models, for example, the iterative development process 
that combines the waterfall and spiral lifecycle model. The Cleanroom approach 
developed by Harlan Mills at IBM includes a phase for formal specification, and its 
approach to software testing is based on the predicted usage of the software product. 
The Rational Unified Process is discussed in the next section.
Fig. 16.3  Waterfall V lifecycle model
16  History of Software Engineering

211
16.4.3  Rational Unified Process
The Rational Unified Process [Jac:99] was developed at the Rational Corporation 
(now part of IBM) in the late 1990s. It uses the Unified Modelling Language (UML) 
as a tool for specification and design, and UML is a visual modeling language for 
software systems, which provides a means of specifying, constructing, and docu-
menting the object-oriented system. UML was developed by James Rumbaugh, 
Grady Booch, and Ivar Jacobson, and it facilitates the understanding of the architec-
ture and complexity of the system.
RUP is use case-driven, architecture-centric, iterative and incremental, and 
includes cycles, phases, workflows, risk mitigation, quality control, project manage-
ment, and configuration control. Software projects may be very complex, and there 
are risks that requirements may be incomplete, or that the interpretation of a require-
ment may differ between the customer and the project team.
Requirements are gathered as use cases, and the use cases describe the func-
tional requirements from the point of view of the user of the system. They describe 
what the system will do at a high level, and ensure that there is an appropriate focus 
on the user when defining the scope of the project. Use cases also drive the 
Fig. 16.4  SPIRAL lifecycle model. Public domain
16.4  Software Processes and Lifecycles

212
development process, as the developers create a series of design and implementation 
models that realize the use cases. The developers review each successive model for 
conformance to the use-case model, and the test team verifies that the implementa-
tion correctly implements the use cases.
The software architecture concept embodies the most significant static and 
dynamic aspects of the system. The architecture grows out of the use cases and fac-
tors such as the platform that the software is to run on, deployment considerations, 
legacy systems, and nonfunctional requirements.
RUP decomposes the work of a large project into smaller slices or mini projects, 
and each mini project is an iteration that results in an increment to the product. The 
iteration consists of one or more steps in the workflow, and generally leads to the 
growth of the product. If there is a need to repeat an iteration, then all that is lost is 
the misdirected effort of one iteration, rather than the entire product. In other words, 
RUP is a way to mitigate risk in software engineering.
16.4.4  Agile Development
There has been a growth of popularity among software developers in lightweight 
methodologies such as Agile. This is a software development methodology that 
claims to be more responsive to customer needs than traditional methods such as the 
waterfall model. The waterfall development model is similar to a wide and slow 
moving value stream, and halfway through the project, 100% if the requirements are 
typically 50% done. However, for agile development, 50% of requirements are typi-
cally 100% done halfway through the project.
An early version of the methodology was originally introduced in the early 
1990s, and the Agile Manifesto was introduced in early 2001 [Bec:00]. Agile has a 
strong collaborative style of working and its approach includes the following:
–– Aim is to achieve a narrow fast flowing value stream.
–– Feedback and adaptation employed in decision making.
–– User Stories and sprints are employed.
–– Stories are either done are not done.
–– Iterative and Incremental development is employed.
–– A project is divided into iterations.
–– An iteration has a fixed length (i.e., time boxing is employed).
–– Entire software development lifecycle is used for the implementation of 
each story.
–– Change is accepted as a normal part of life in the Agile world.
–– Delivery is made as early as possible.
–– Maintenance is seen as part of the development process.
–– Refactoring and evolutionary design employed.
–– Continuous integration is employed.
–– Short cycle times.
16  History of Software Engineering

213
–– Emphasis on quality.
–– Stand up meetings.
–– Plan regularly.
–– Direct interaction preferred over documentation.
–– Rapid conversion of requirements into working functionality.
–– Demonstrate value early.
–– Early decision-making.
Ongoing changes to requirements are considered normal in the Agile world, and 
it is believed to be more realistic to change requirements regularly throughout the 
project rather than attempting to define all of the requirements at the start of the 
project. The methodology includes controls to manage changes to the requirements, 
and good communication and early regular feedback are essential parts of the 
process.
A story may be a new feature or a modification to an existing feature. It is reduced 
to the minimum scope that can deliver business value, and a feature may give rise to 
several stories. Stories often build upon other stories and the entire software devel-
opment life cycle is employed for the implementation of each story. Stories are 
either done or not done, that is, there is such thing as a story being 80% done. The 
story is complete only when it passes its acceptance tests. Stories are prioritized 
based on a number of factors, including the following:
–– Business value of story
–– Mitigation of risk
–– Dependencies on other stories
Sprint planning is performed before the start of the iteration, and stories are 
assigned to the iteration to fill the available time. The estimates for each story and 
their priority are determined, and the prioritized stories are assigned to the iteration. 
A short morning stand-up meeting is held daily during the iteration, and attended by 
the project manager and the project team. It discusses the progress made the previ-
ous day, problem reporting and tracking, and the work planned for the day ahead. A 
separate meeting is held for issues that require more detailed discussion.
Once the iteration is complete, the latest product increment is demonstrated to an 
audience including the product owner. This is to receive feedback and to identify 
new requirements. The team also conducts a retrospective meeting to identify what 
went well and what went poorly during the iteration. This is for continuous improve-
ment for future iterations.
Agile employs pair programming and a collaborative style of working with the 
philosophy that two heads are better than one. This allows multiple perspectives in 
decision-making and a broader understanding of the issues.
Software testing is very important and Agile generally employs automated test-
ing for unit, acceptance, performance, and integration testing. Tests are run fre-
quently with the goal of catching programming errors early. They are generally run 
on a separate build server to ensure that all dependencies are checked. Tests are re-­
run before making a release. Agile employs test-driven development with tests 
16.4  Software Processes and Lifecycles

214
written before the code. The developers write code to make a test pass with ideally 
developers only coding against failing tests. This approach forces the developer to 
write testable code.
Refactoring is employed in Agile as a design and coding practice. The objective 
is to change how the software is written without changing what it does. Refactoring 
is a tool for evolutionary design where the design is regularly evaluated, and 
improvements are implemented as they are identified. The automated test suite is 
essential in showing that the integrity of the software is maintained following 
refactoring.
Continuous integration allows the system to be built with every change. Early 
and regular integration allows early feedback to be provided. It also allows all of the 
automated tests to be run thereby identifying problems earlier.
16.5  Activities in Waterfall Lifecycle
This section describes the various activities in the waterfall software development 
lifecycle in more detail. The activities discussed include:
•	 Business requirements definition
•	 Specification of system requirements
•	 Design
•	 Implementation
•	 Unit testing
•	 System testing
•	 UAT testing
•	 Support and maintenance
16.5.1  Business Requirements Definition
The business requirements specify what the customer wants, and define what the 
software system is required to do (as distinct from how this is to be done). The 
requirements are the foundation for the system, and if they are incorrect, then the 
implemented system will be incorrect. Prototyping may be employed to assist in the 
definition and validation of the requirements.
The specification of the requirements needs to be unambiguous to ensure that all 
parties involved in the development of the system share a common understanding of 
what is to be developed and tested.
Requirements gathering involve meetings with the stakeholders to gather all rel-
evant information for the proposed product. The stakeholders are interviewed, and 
requirement workshops conducted to elicit the requirements from them. An early 
working system (prototype) is often used to identify gaps and misunderstandings 
16  History of Software Engineering

215
between developers and users. The prototype may serve as a basis for writing the 
specification.
The requirements workshops with the stakeholders are used to discuss and pri-
oritize the requirements, as well as identifying and resolving any conflicting require-
ments. The collected information is consolidated into a coherent set of requirements.
The requirements are validated by the stakeholders to ensure that they are actu-
ally those desired, and to establish their feasibility. This may involve several reviews 
of the requirements until all stakeholders are ready to approve the requirements 
document. Changes to the requirements may occur during the project, and these 
need to be controlled. It is essential to understand the impacts of a change prior to 
its approval.
The requirements for a system are generally documented in a natural language 
such as “English.” Other notations that may be employed to express the require-
ments include the visual modeling language UML [Jac:05], and formal specifica-
tion languages such as VDM or Z for the safety critical field.
16.5.2  Specification of System Requirements
The specification of the system requirements of the product is essentially a state-
ment of what the software development organization will provide to meet the busi-
ness requirements. That is, the detailed business requirements are a statement of 
what the customer wants, whereas the specification of the system requirements is a 
statement of what will be delivered by the software development organization.
It is essential that the system requirements are valid with respect to the business 
requirements, and the stakeholders review them to ensure their validity. Traceability 
may be employed to show how the business requirements are addressed by the sys-
tem requirements
There are two categories of system requirements, namely functional and non-
functional requirements. The functional requirements define the functionality that is 
required of the system, and it may include screen shots, report layouts, or the desired 
functionality specified in natural language, use cases, etc. The nonfunctional 
requirements will generally include security, reliability, performance and portability 
requirements, as well as usability and maintainability requirements.
16.5.3  Design
The design of the system consists of engineering activities to describe the architec-
ture or structure of the system, as well as activities to describe the algorithms and 
functions required to implement the system requirements. It is a creative process 
concerned with how the system will be implemented, and it includes architecture 
design, interface design, and data structure design. There are often several possible 
16.5  Activities in Waterfall Lifecycle

216
design solutions for a particular system, and the designer will need to decide on the 
most appropriate solution.
The design may be specified in various ways such as graphical notations that 
display the relationships between the components making up the design. The nota-
tion may include flowcharts, or various UML diagrams such as sequence diagrams 
and state charts. Program description languages or pseudo code may be employed 
to define the algorithms and data structures that are the basis for implementation.
Functional design involves starting with a high-level view of the system and 
refining it into a more detailed design. The system state is centralized and shared 
between the functions operating on that state.
Object-oriented design is based on the concept of information hiding [Par:72]. 
The system is viewed as a collection of objects rather than functions, with each 
object managing its own state information. The system state is decentralized and an 
object is a member of a class. The definition of a class includes attributes and opera-
tions on class members, and these may be inherited from super classes. Objects 
communicate by exchanging messages.
It is essential to verify and validate the design with respect to the system require-
ments, and this will be done by design reviews, and traceability of the design to the 
system requirements
16.5.4  Implementation
This phase is concerned with implementing the design in the target language and 
environment (e.g., C++ or Java), and it involves writing or generating the actual 
code. The development team divides up the work to be done, with each programmer 
responsible for one or more modules. The coding activities generally include code 
reviews or walkthroughs to ensure that quality code is produced, and to verify its 
correctness. They also verify that the source code adheres to the coding standards, 
that maintainability issues are addressed, and that the code produced is a valid 
implementation of the software design.
Software reuse has become more important in recent times, as it provides a way 
to speed up the development process. Components or objects that may be reused 
need to be identified and handled accordingly. The implemented code may use soft-
ware components that are either being developed internally or purchased off the 
shelf. Open-source software allows software developed by others to be used (under 
an open-source license) in the development of applications.
The benefits of software reuse include increased productivity and a faster time to 
market. There are inherent risks with customized-off-the shelf (COTS) software, as 
the supplier may decide to no longer support the software, or there is no guarantee 
that software that has worked successfully in one domain will work correctly in a 
different domain. It is therefore important to consider the risks as well as the bene-
fits of software reuse and open source software.
16  History of Software Engineering

217
16.5.5  Software Testing
Software testing is employed to verify that the requirements have been correctly 
implemented, and that the software is fit for purpose, as well as identifying defects 
present in the software. There are various types of testing that may be conducted 
including unit testing, integration testing, system testing, performance testing and 
user acceptance testing. These are described below:
Unit Testing
Unit testing is performed by the programmer on the completed unit (or module), 
and prior to its integration with other modules. The programmer writes these tests, 
and the objective is to show that the code satisfies the design. Each unit test should 
include a test objective and the expected result.
Code coverage and branch coverage metrics are often recorded to give an indica-
tion of how comprehensive the unit testing has been. These metrics provide visibil-
ity into the number of lines of code executed as well as the branches covered during 
unit testing.
The developer executes the unit tests; records the results; corrects any identified 
defects and re-tests the software. Test-driven development has become popular in 
recent years (e.g., in the Agile world), and this involves writing the unit test case 
before the code, and the code is written to pass the unit test cases.
Integration Test
The development team performs this type of testing on the integrated system, once 
all of the individual units work correctly in isolation. The objective is to verify that 
all of the modules and their interfaces work correctly together, and to identify and 
resolve any issues. Modules that work correctly in isolation may fail when inte-
grated with other modules.
System Test
The purpose of system testing is to verify that the implementation is valid with 
respect to the system requirements. It involves the specification of system test cases, 
and the execution of the test cases will verify that the system requirements have 
been correctly implemented. An independent test group generally conducts this type 
of testing, and the system tests are traceable to the system requirements.
Any system requirements that have been incorrectly implemented will be identi-
fied, and defects logged and reported to the developers. The test group will verify 
that the new version of the software is correct, and regression testing is conducted 
to verify system integrity. System testing may include security testing, usability 
testing and performance testing.
The preparation of the test environment requires detailed planning, and it may 
involve ordering special hardware and tools. It is important that the test environment 
is set up as early as possible to allow the timely execution of the test cases.
16.5  Activities in Waterfall Lifecycle

218
Performance Test
The purpose of performance testing is to ensure that the performance of the system 
is within the bounds specified in the non-functional requirements, and to determine 
if the system is scalable to support future growth. It may include load performance 
testing, where the system is subjected to heavy loads over a long period of time, and 
stress testing, where the system is subjected to heavy loads during a short time 
interval.
Performance testing often involves the simulation of many users using the sys-
tem, and measuring the response times for various activities. Test tools are often 
employed to simulate a large number of users and heavy loads.
User Acceptance Test
UAT is usually performed under controlled conditions at the customer site, and its 
operation will closely resemble the real-life behavior of the system. The customer 
will see the product in operation, and is able to judge whether or not the system is 
fit for purpose.
The objective is to demonstrate that the product satisfies the business require-
ments and meets the customer expectations. Upon its successful completion, the 
customer is happy to accept the product. Software testing is described in more detail 
in [ORg:19].
16.5.6  Maintenance
This phase continues after the release of the software product to the customer. Any 
problems that the customer notes with the software are reported as per the customer 
support and maintenance agreement. The support issues will require investigation, 
and the issue may be a defect in the software, an enhancement to the software, or 
due to a misunderstanding. The support and maintenance team will identify the 
causes of any identified defects, and will implement the appropriate solution. 
Testing is conducted to verify that the solution is correct, and that the changes made 
have not adversely affected other parts of the system. Mature organizations will 
conduct post mortems to learn lessons from the defect13, and will take corrective 
action to prevent a reoccurrence.
The presence of a maintenance phase suggests an acceptance of the reality that 
problems with the software will be identified post release. The goal of building a 
correct and reliable software product the first time is very difficult to achieve, and 
the customer is always likely to find some issues with the released software product. 
It is accepted today that quality needs to be built into each step in the development 
13 This is essential for serious defects that have caused significant inconvenience to customers (e.g., 
a major telecom outage). The software development organization will wish to learn lessons to 
determine what went wrong in its processes that prevented the defect from being identified during 
peer reviews and testing. Actions to prevent a reoccurrence will be identified and implemented.
16  History of Software Engineering

219
process, with the role of software inspections and testing to identify as many defects 
as possible prior to release, and minimize the risk that that serious defects will be 
found post-release.
The more effective the in-phase inspections of deliverables, the higher the qual-
ity of the resulting implementation, with a corresponding reduction in the number 
of defects detected by the test groups. The testing group plays a key role in verifying 
that the system is correct, and in providing confidence that the software is fit for 
purpose. Dijkstra [Dij:72] noted that:
“Testing a program demonstrates that it contains errors, never that it is correct.”
That is, irrespective of the amount of time spent testing, it can never be said with 
absolute confidence that the program is correct, and, at best, statistical techniques 
may be employed to give a measure of the confidence in its correctness. That is, 
there is no guarantee that all defects have been found in the software.
Many software companies may consider one defect per thousand lines of code 
(KLOC) to be reasonable quality. However, if the system contains one million lines 
of code this is equivalent to a thousand post-release defects, which is 
unacceptable.
Some mature organizations have a quality objective of three defects per million 
lines of code. This goal is known as six-sigma (6σ), and Motorola developed it ini-
tially for its manufacturing businesses and later applied to its software organization. 
The goal is to reduce variability in manufacturing processes and to ensure that the 
processes performed within strict process control limits. Motorola was awarded the 
first Malcom Baldridge Quality award for its six-sigma initiative and its commit-
ment to quality.
16.6  Software Inspections
Software inspections are used to build quality into software products, and there are 
several well-known approaches such as the Fagan Methodology [Fag:76], Gilb’s 
approach [Glb:94], and Prince 2’s approach.
Fagan inspections were developed by Michael Fagan of IBM. It is a seven-step 
process that identifies and removes errors in work products. The process mandates 
that requirement documents, design documents, source code, and test plans are all 
formally inspected by experts independent of the author of the deliverable to ensure 
quality.
There are various roles defined in the process including the moderator who 
chairs the inspection. The reader’s responsibility is to read or paraphrase the par-
ticular deliverable, and the author is the creator of the deliverable and has a special 
interest in ensuring that it is correct. The tester role is concerned with the test 
viewpoint.
The inspection process will consider whether the design is correct with respect 
to the requirements, and whether the source code is correct with respect to the 
16.6  Software Inspections

220
design. Software inspections play an important role in building quality into the soft-
ware, and in reducing the cost of poor quality in the organization. For more detailed 
information, see [ORg:14].
16.7  Software Project Management
The timely delivery of quality software requires good management and engineering 
processes. Software projects have a history of being delivered late or over budget, 
and project planning involves:
–– Defining the business case for the project
–– Defining the scope of the project and what it is to achieve
–– Defining the key success factors for the project.
–– Determining the approach to be taken for the project
–– Determining the key stakeholders
–– Determining the project lifecycle and phases of the project
–– Determining the resources required
–– Staffing the project and assigning resources to the tasks and activities
–– Determining the knowledge, skills and training required.
–– Estimation of the cost, effort and schedule
–– Determining the start and end dates for the project
–– Determining the key project milestones
–– Preparation of financial budget
–– Preparing the project plan
–– Preparing the initial project schedule
–– Identifying initial project risks
–– Preparing quality plan
–– Preparing test plan
–– Preparing configuration management plan
–– Preparing deployment plan
–– Obtaining approval for the project plan and schedule
The project planning activities take place during the project start-up and initia-
tion phase, and re-planning activities take place during project execution. The proj-
ect plan will contain or reference several other plans such as the project quality plan, 
the communication plan, the configuration management plan, and the test plan.
Project estimation and scheduling are difficult, as often software projects are 
breaking new ground and differ from previous projects. That is, previous estimates 
may often not be a good basis for estimation for the current project. Often, unantici-
pated problems can arise for technically advanced projects, and the estimates may 
be optimistic. Gantt charts are generally employed for project scheduling, and these 
show the work breakdown for the project, as well as task dependencies, and the 
allocation of staff to the various tasks.
16  History of Software Engineering

221
The effective management of risk during a project is essential to project success. 
Risks arise due to uncertainty and the risk management cycle involves14 risk identi-
fication; risk analysis and evaluation; identifying responses to risks; selecting and 
planning a response to the risk; and risk monitoring. The risks are logged, and the 
likelihood of each risk arising and its impact is then determined. The risk is assigned 
an owner and an appropriate response to the risk determined. For more detailed 
information on project management, see [ORg:17a].
16.8  CMMI Maturity Model
The CMMI is a framework to assist an organization in the implementation of best 
practice in software and systems engineering [CKS:11]. It is an internationally rec-
ognized model for process improvement and assessment, and is used worldwide by 
thousands of organizations. It provides a framework for an organization to introduce 
a solid engineering approach to the development of software, and it helps in the defi-
nition of high-quality processes for the various software engineering and manage-
ment activities.
It was developed by the Software Engineering Institute (SEI) who adapted the 
process improvement principles used in the manufacturing field to the software 
field. They developed the original CMM model in the early 1990s, and its successor 
the CMMI. The CMMI states what the organization needs to do to mature its pro-
cesses rather than how this should be done.
The CMMI consists of five maturity levels with each maturity level consisting of 
several process areas. Each process area consists of a set of goals, and these goals 
are implemented by practices related to that process area. Level two is focused on 
management practices; level three is focused on engineering and organization prac-
tices; level four is concerned with ensuring that key processes are performing within 
strict quantitative limits; level five is concerned with continuous process improve-
ment. Maturity levels may not be skipped in the staged implementation of the 
CMMI, as each maturity level is the foundation for the next level.
The CMMI allows organizations to benchmark themselves against other organi-
zations. This is done by a formal appraisal conducted by an authorized lead appraiser 
[SCA:06]. The results of the appraisal are generally reported back to the SEI, and 
there is a strict qualification process to become an authorized lead appraiser. An 
appraisal is useful in verifying that an organization has improved, and it enables the 
organization to prioritize improvements for the next improvement cycle. The CMMI 
is discussed in more detail in [ORg:14].
14 These are the risk management activities in the Prince2 methodology.
16.8  CMMI Maturity Model

222
16.9  Formal Methods
Dijkstra and Hoare have argued that the appropriate way to develop correct software 
is to derive the program from its formal mathematical specification, and to employ 
mathematical proof to demonstrate the correctness of the software with respect to 
the specification. This offers a rigorous framework to develop programs adhering to 
the highest quality constraints. However, in practice, mathematical techniques have 
proved to be cumbersome to use, and their widespread deployment in industry is 
unlikely at this time.
The safety-critical area is one domain to which mathematical techniques have 
been successfully applied: for example, demonstrating the presence or absence of 
safety critical properties such as “when a train is in a level crossing, then the gate is 
closed.” There is a need for extra rigor in the software development process used in 
the safety critical field, and mathematical techniques can demonstrate the presence 
or absence of certain desirable or undesirable properties.
Spivey [Spi:92] defines a “formal specification” as the use of mathematical nota-
tion to describe in a precise way the properties which an information system must 
have, without unduly constraining the way in which these properties are achieved. 
It describes what the system must do, as distinct from how it is to be done. This 
abstraction away from implementation enables questions about what the system 
does to be answered, independently of the detailed code. Furthermore, the unam-
biguous nature of mathematical notation avoids the problem of speculation about 
the meaning of phrases in an imprecisely worded natural language description of 
a system.
The formal specification thus becomes the key reference point for the different 
parties concerned with the construction of the system, and is a useful way of pro-
moting a common understanding for all those concerned with the system.
The term “formal methods” is used to describe a formal specification language 
and a method for the design and implementation of computer systems. The specifi-
cation is written in a mathematical language, and its precision helps to avoid the 
problem of ambiguity inherent in a natural language specification. The derivation of 
an implementation from the specification may be achieved via step-wise refinement. 
Each refinement step makes the specification more concrete and closer to the actual 
implementation. There is an associated proof obligation that the refinement be valid, 
and that the concrete state preserves the properties of the more abstract state. Thus, 
assuming the original specification is correct and the proofs of correctness of each 
refinement step are valid, then there is a very high degree of confidence in the cor-
rectness of the implemented software.
Formal methods have been applied to a diverse range of applications, including 
circuit design, artificial intelligence, specification of standards, specification and 
verification of programs, etc. They are described in more detail in [ORg:17b].
16  History of Software Engineering

223
16.10  Open-Source Software
Open-source software (OSS) is software that is freely available under an open-­
source license to study, change, and distribute to anyone for any purpose. Free and 
open-source licenses are often divided into two categories depending on the rights 
to be granted in distribution of the modified software. The first category aims to give 
users unlimited freedom to use, study, and modify the software, and if the user 
adheres to the terms of an open-source license such as GNU General Public License 
(GPL), the freedom to distribute the software and any changes made to it. The sec-
ond category of open-source licenses gives the user permission to use, study, and 
modify the software, but not the right to distribute it freely under an open-source 
license (it could be distributed as part of a proprietary software license).
Open source software allows software developed by others to be used (under an 
open-source license) in the development of applications. The source code to be 
published, and thousands of volunteer software developers from around the world 
participate in developing and improving the software code. The idea is that the 
source code is not proprietary, and that it is freely available for software developers 
to use and modify as they wish. One useful benefit is that it may potentially speed 
up development time, thereby shortening time to market.
The roots of open-source development are in the Free Software Foundation 
(FSF). This is a nonprofit organization founded by Richard Stallman [ORg:13] to 
promote free software, and it has developed a legal framework for open-source soft-
ware development.
The Linux operating system is a well-known open source product, and other 
products include mySQL, Firefox, and Apache HTTP server. Google introduced its 
open source Android operating system in late 2007, which is the dominant operating 
system for smartphones and tablets. The quality of software produced by the open 
source movement is good, and defects are generally identified and fixed faster than 
with proprietary software.
16.10  Open-Source Software

224
16.11  Review Questions
16.12  Summary
The birth of software engineering was at the NATO conference held in 1968 in 
Germany. This conference highlighted the problems that existed in the software sec-
tor in the late 1960s, and the term “software crisis” was coined to refer to these. This 
led to the realization that programming is quite distinct from science and mathemat-
ics, and that software engineers need to be properly trained to enable them to build 
high-quality products that are safe to use.
The Standish group conducts research on the extent of problems with the deliv-
ery of projects on time and budget. Their research indicates that it remains a chal-
lenge to deliver projects on time, on budget, and with the right quality.
Programmers are like engineers in the sense that they build products. Therefore, 
programmers need to receive an appropriate education in engineering as part of 
their education. Classical engineers receive training on product design, and an 
appropriate level of mathematics.
Software engineering involves multiperson construction of multiversion pro-
grams. It is a systematic approach to the development and maintenance of the soft-
ware, and it requires a precise statement of the requirements of the software product, 
and then the design and development of a solution to meet these requirements. It 
includes methodologies to design, develop, implement, and test software, as well as 
sound project management, quality management, and configuration management 
practices. Support and maintenance of the software are properly addressed.
Software process maturity models such as the CMMI place an emphasis on 
understanding and improving the software processes in an organization. It is a 
	1.	 Discuss the research results of the Standish Group on the current state of 
IT project delivery.
	2.	 What are the main challenges in software engineering?
	3.	 Describe various software lifecycles such as the waterfall model and the 
spiral model.
	4.	 Discuss the benefits of Agile over conventional approaches. What are the 
advantages and disadvantages?
	5.	 Describe the purpose of software inspections? What are the benefits?
	6.	 Describe the main activities in software testing.
	7.	 Describe the advantages and disadvantages of formal methods.
	8.	 Describe the main activities in project management.
	9.	 Explain the significance of the CMMI as a framework to improve the soft-
ware engineering capability of an organization.
16  History of Software Engineering

225
principle in the software quality field that high-quality processes play a key role in 
delivering a high-quality product, and the CMMI is a framework that allows high-­
quality processes to be successfully introduced in the organization. The CMMI 
allows organizations to benchmark themselves against other similar organizations, 
and this is done by a formal SCAMPI appraisal conducted by qualified assessors.
Formal methods involve the use of mathematical techniques to provide extra 
confidence in the correctness of the software. They are used mainly in the safety and 
security critical fields.
16.12  Summary

227
© The Author(s), under exclusive license to Springer Nature 
Switzerland AG 2021
G. O’Regan, A Brief History of Computing, 
https://doi.org/10.1007/978-3-030-66599-9_17
Chapter 17
A Short History of Telecommunications
17.1  Introduction
Telecommunications is a branch of technology concerned with the transmission of 
information over a distance, where the transmitter sends the information to a 
receiver. Early societies used fire and smoke signals for visual communication, with 
drums used for auditory communication. This allowed simple messages (e.g., “dan-
ger”) to be communicated to other groups.
The Persian Empire established an early postal system in the sixth century BC, 
and the Egyptians and Romans later established their own postal systems. A pigeon 
messaging system, where the homing characteristics of pigeons were employed to 
send messages, was later introduced.
The Greeks introduced an early semaphore system in the fourth century BC, 
which allowed very simple messages to be exchanged between groups on two dif-
ferent hills (similar in a sense to smoke signals). A ship semaphore system was 
introduced in the fifteenth century, which allowed two ships to communicate with 
each other. This system used flags where the position and motion of a flag repre-
sented a letter.
The Chappe brothers in France introduced an early optical telegraph system in 
Europe in the late eighteenth century. It used similar principles to the ship-based 
semaphore system, and it allowed messages to be sent from one high tower to 
another. It was used by the French military.
Early electrical telegraph systems were introduced in the early nineteenth cen-
tury, and Samuel Morse devised a system (the Morse code) that allowed letters to be 
represented by a series of on-off tones in the late 1830s. This was the foundation for 
electrical telegraphs and later telephone systems. The first Atlantic telegraph cable 
Key Topics
Telegraph
Telephone
AMPS
AXE
Telephone
Telegraph
Mobile phone system
Iridium

228
was laid between Britain and America (via Valencia Island in Ireland) in 1858, and 
this allowed messages to be sent and responded to the same day rather than the usual 
delivery time of ten days for letters sent by ships.
The telephone was invented by Alexander Graham Bell in 18761, and early tele-
phones were hardwired to and communicated with a single other telephone (e.g., 
from a person’s business to his home), as initially there were no telephone exchanges. 
A telephone exchange provides switching or interconnection between two sub-
scriber lines, and the earliest manual commercial telephone exchanges were intro-
duced in the late 1870s. The first mechanical automated exchanges were introduced 
in the early 1890s. The first North American transcontinental phone call from the 
east coast to the west coast was made by Bell in 1915, and it made long-distance 
communication a reality.
The invention of the telephone was a paradigm shift from face-to-face communi-
cation, where people met to exchange ideas and share information, or where indi-
viduals wrote letters to each other to exchange information. The telephone was a 
new medium that provided direct and instantaneous communication between two 
people. It allowed two individuals to establish and maintain two-way communica-
tion irrespective of being at two different physical locations. Initially the business 
community and the affluent members of society used the telephone, but this changed 
rapidly in the years that followed.
Marconi, an Italian engineer, introduced a system for the wireless transmission 
of sounds in 1896, and the British Marconi Company was established in 1897. It 
began communication between ships at sea and coastal radio stations, and the first 
radio messages were sent across the Atlantic in 1902. The value of radio communi-
cation was highlighted in the sinking of the Titanic in 1912. Marconi established an 
early radio factory in England in 1912.
The first prototype electronic television was developed and demonstrated by 
Philip Farnsworth in the late 1920s. It was the result of research on ways to transmit 
images, and it had been determined that radio waves could be encoded with an 
image, and then transmitted back to the screen. Farnsworth’s prototype is consid-
ered the first electronic television.
The foundations of the mobile cellular industry go back to the introduction of a 
limited-capacity mobile phone system that was introduced for automobiles in 1946. 
Martin Cooper of Motorola made the first mobile phone call to Joe Engels at Bell 
Labs in 1973, and a prototype mobile phone network was operational in the late 
1970s with commercial mobile phone networks introduced in the early 1980s. The 
first global mobile phone system (Iridium) was operational in 1998, and the Iridium 
system consisted of 66 satellites, with the customers using hand-held satel-
lite phones.
The ARPANET packet switching network was introduced in the late 1960s, and 
it remained operational until 1990, when the Internet became operational. The 
1 He was the first person to patent the telephone as an “apparatus for transmitting vocal or other 
sounds telegraphically.” There are several other claimants for inventing the telephone.
17  A Short History of Telecommunications

229
Internet has led to almost instantaneous communication, and it has led to electronic 
mail; the World Wide Web, which was developed by Tim Berners Lee at CERN; 
social networking; electronic commerce; and telephone calls over the Internet with 
the VOIP protocol.
This chapter considers a small number of events in the history of telecommuni-
cations including the development of the AXE system, which was the first fully 
automated digital switching system; the development of mobile phone technology; 
and the development of the Iridium satellite mobile phone system.
17.2  AXE System
Ericsson introduced the AXE (Automatic Exchange Electric) switching system in 
1977 (Fig. 17.1). This was the first fully automated digital switching system, and it 
converted speech into digital (i.e., the binary language used by computers). 
Ericsson’s competitors were still using the slower and less reliable analog system.
The analog system uses an electric current to convey the vibrations of the human 
voice, whereas a digital system uses a stream of binary digits to represent sound. 
The AXE system was an immediate success with telecom companies, and it was 
Fig 17.1  AXE system. 
Creative Commons
17.2  AXE System

230
sold in many countries around the world. AXE was originally a digital exchange for 
landline telephony, but it was later extended for use with mobile telephony systems.
Ellemtel was established in 1970 as a pure research and development company, 
and it was a joint venture between Televerket (Sweden’s state-owned PTT) and 
Ericsson. Its primary task was to develop an electronic and automated switching 
system for telephone stations that would become the AXE system.
Ericsson had been working to develop a commercial electronic switching system 
called AKE, while Televerket was working on its own electronic switch. Ericsson 
realized that its AKE system was not suitable for large switching stations, and that 
it needed to develop a new generation of switching systems. It decided to combine 
its resources with Televerket, and to jointly develop an electronic telephone switch-
ing system.
Bengt-Gunnar Magnusson was the project manager for the AXE project, and 
AXE had a modular system design which made the system flexible. New functional-
ity could be added, and existing modules updated or replaced. The modular design 
allowed the system to be easily adapted to different markets.
The development of AXE also involved the development of hardware and soft-
ware such as programs and processors to control the AXE stations. The first proto-
type AXE system was installed at a Televerket station in 1976, and Ellemtel’s work 
in developing the AXE system was complete in 1978.
The AXE system was then commercialized and many of Ellemtel’s employees 
moved to Ericsson. AXE was an immediate success and Ericsson soon had custom-
ers in Sweden, Finland, France, Australia and Saudi Arabia. The Saudi order was 
the largest that Ericsson had ever received, and it involved increasing the capacity 
of the Saudi network by 200% and installing the AXE system.
The introduction of AXE meant that by the early 1980s Ericsson had the mar-
ket’s most advanced and flexible switching system, and this made it ideally placed 
for the transition from fixed line to mobile telephony. It meant that Ericsson had 
moved from being a minor player in the telecoms business to a major-league player. 
It was now the leader in fixed line phone technology, and it had the right foundations 
in place for success in mobile telephony. It became the leader in mobile technology 
in the late 1980s, and today the AXE system has been installed in over 130 countries.
17.3  Development of Mobile Phone Standards
Bell Labs played an important role (with Motorola) in the development of the ana-
log mobile phone system in the United States. It developed a system in the mid-­1940s 
that allowed mobile users to place and receive calls from automobiles, and Motorola 
developed mobile phones for automobiles. However, these phones were large and 
bulky and they consumed a lot of power. A user needed to keep the automobile’s 
engine running to make or receive a call.
Bell Labs first proposed the idea of a cellular system back in the late 1940s, when 
they proposed hexagonal rings for mobile communication. Large geographical 
17  A Short History of Telecommunications

231
areas were divided into cells, where each cell had its own base station and channels. 
The available frequencies could be used in parallel in different cells without disturb-
ing each other (Fig. 17.2). Mobile telephone could now, in theory, handle many 
subscribers. However, it was not until the late 1960s that Bell Labs prepared a 
detailed plan for implementing the cellular system.
Bell Labs developed the Advanced Mobile Phone System (AMPS) standard from 
1968 to 1983. Motorola and other telecommunication companies designed and built 
phones for this cellular system. The AMPS system uses separate frequencies (or 
channels) for each conversation, and requires considerable bandwidth for many users.
The signals from a transmitter cover an area called a cell. As a user moves from 
one cell into a new cell, a handover to the new cell takes place without any notice-
able difference to the user. The signals in the adjacent cell are sent and received on 
different channels to the existing cell’s signals, and so there is no interference.
The Total Access Communication (TACS) and Extended TACS (ETACS) system 
were variants of AMPS that were employed in the United Kingdom and Europe. 
These analog standards employed separate frequencies (or channels) for each con-
versation using frequency division multiple access (FDMA). However, the analog 
system suffered from static and noise, and there was no protection from eavesdrop-
ping using a scanner.
Ericsson became the leader in the first generation of mobile with Motorola, and 
the extent of its leadership was clear when its proposed design for digital mobile 
radio transmission was selected as the US Standard for Cellular Communications 
over entries from Motorola and AT&T in 1989.
The AMPS system represents the first generation of cellular technology, and it 
has several weaknesses when compared to today’s cellular systems. Mobile technol-
ogy evolved to the second-generation digital Global System for Mobile 
Communication (GSM) and Code Division Multiple Access (CDMA) technologies; 
to General Packet Radio Service (GPRS); to third-generation mobile, including 3G 
and WCDMA; and to fourth- and fifth-generation mobile (4G and 5G).
F1
F2
F1
F3
F4
F1
F2
F3
Fig 17.2  Frequency reuse 
in cellular networks
17.3  Development of Mobile Phone Standards

232
17.4  Development of Mobile Phone Technology
The invention of the telephone by Graham Bell in the late nineteenth century was a 
revolution in human communication, as it allowed people in different geographic 
locations to communicate instantaneously rather than meeting face to face. However, 
the key restriction of the telephone was that the actual physical location of the per-
son to be contacted was required prior to communication, as otherwise communica-
tion could not take place, that is communication was between places rather 
than people.
The origins of the mobile phone revolution dates to work done on radio technol-
ogy in the 1940s. Bell Labs had proposed the idea of a cellular communication 
system back in 1947, and it was eventually brought to fruition by researchers at Bell 
Labs and Motorola. Bell Labs constructed and operated a prototype cellular system 
in Chicago in the late 1970s, and performed public trials in 1979. Motorola com-
menced a second US cellular system test in the Washington/Baltimore area. The 
first commercial systems commenced operation in the United States in 1983.
The DynaTAC (Dynamic adoptive Total Area Coverage) used cellular radio tech-
nology to link people and not places. Motorola was the first company to incorporate 
the technology into a portable device designed for use outside of an automobile, and 
it spent $100 million on the development of cellular technology. Martin Cooper 
(Fig. 17.3) led the team at Motorola that developed the DynaTAC8000X, and he 
Fig. 17.3  Martin Cooper 
re-enacts DynaTAC call
17  A Short History of Telecommunications

233
made the first mobile phone call on a prototype DynaTAC phone to Joel Engels, the 
head of research at Bell Labs, in April 1973.
Commercial cellular services commenced in North America in 1983, and the 
world’s first commercial mobile phone went on sale the same year. This was the 
Motorola DynaTAC 8000X, and it was popularly known as the “brick” due to its 
size and shape. It weighed 28 ounces (almost 2 lbs); it was 13.5” (over a foot) in 
length; and 3.5” in width. It had an LED display and could store 30 numbers. It had 
a talk time of 30 min, 8 h of standby, and it took over ten hours to recharge.
The cost of the Motorola DynacTAC 8000X was $3995, and it was too expensive 
for most people apart from wealthy consumers. Today, mobile phones are ubiqui-
tous, and there are more mobile phone users than fixed line users. The cost of a 
mobile phone today is often less than $100, and a mobile phone typically weighs as 
little as 3 ounces.
The first-generation mobile phone system introduced into North America in the 
early 1980s used the 800 MHz cellular band. It had a frequency range between 800 
and 900 MHz. Each service provider could use half of the 824–849 MHz range for 
receiving signals from cellular phones and half the 869–894 MHz range for trans-
mitting to cellular phones. The bands were divided into 30 kHz sub-bands called 
channels and a separate frequency (or channel) was used for each conversation. The 
division of the spectrum into sub-band channels is achieved by using frequency 
division multiple access (FDMA).
This first-generation system allowed voice communication only, and it was sus-
ceptible to static and noise. Further, it had no protection from eavesdropping using 
a scanner.
The AXE system provided the foundation for Ericsson’s growth in mobile tele-
phony, as its flexible modular design allowed new functionality to be added, and by 
changing a module, AXE could be reconfigured to handle mobile telephone calls. 
This allowed Ericsson to design the first mobile telephone exchange (MTX) by 
replacing the subsystem for fixed subscribers with a new subsystem for mobile sub-
scribers. The MTX switch was developed in the late 1970s/early 1980s and was a 
key part of the Nordic Mobile Telephone system (NMT) which would be used in all 
Nordic countries.
Ericsson was awarded a large Saudi Arabian contract to deliver a fixed line and 
mobile system, and it was agreed that the NMT standard would be used and that 
Ericsson would supply the entire system. The Saudi mobile phone network became 
operational from 1981, and Ericsson provided base stations, radio towers, and 
switches. Ericsson had now acquired cell-planning experience, and it was awarded 
the contract to develop the entire mobile telephone network in the Netherlands. 
Ericsson was now a total systems supplier in mobile telephony, and it provided the 
entire infrastructure such as switches and base stations. Today, its base stations 
range from small picocells to large macrocells.
The second generation (2G) of mobile technology was a significant improvement 
on the existing analog technology. This digital, cellular technology encrypted tele-
phone conversations, and provided data services such as text and picture messages. 
The second-generation technologies included the GSM standard developed by the 
17.4  Development of Mobile Phone Technology

234
European Telecommunications Standards Institute (ETSI), and CDMA developed 
in the United States. The first GSM call was made by the Finnish prime minister in 
Finland in 1991, and the first short message service (SMS) or text message was sent 
in 1992.
The Subscriber Identity Module (SIM) card was a new feature in GSM, and a 
SIM card is a detachable smart card that contains the user’s subscription informa-
tion and phone book. The SIM card may be used in other GSM phones, and this is 
useful when the user purchases a replacement phone. GSM provides an increased 
level of security, with communication between the subscriber and base station 
encrypted.
GSM networks evolved into GPRS (2.5 G), which became available in 2000. 
Third- and fourth-generation mobile (3G and 4G) provide mobile broadband multi-
media communication. Mobile phone technology has transformed the earlier para-
digm of communication between places to that of communication between people.
Motorola dominated the analogue mobile phone market. However, it was slow to 
adapt to the GSM standard, and it paid a heavy price with a loss of market share to 
Nokia and Ericsson. It was very slow to see the potential of a mobile phone as a 
fashion device2, and it was too slow in adapting to smart phones.
17.5  The Iridium Satellite System
Iridium was a global satellite phone company that was backed by Motorola. In 
many ways, it was an engineering triumph over common sense, and over $5 billion 
was spent in building an infrastructure of low earth orbit (LEO) satellites to provide 
global coverage. It was launched in late 1998 to provide worldwide wireless cover-
age to its customers, including the oceans, airways and polar regions. The existing 
telecom systems had limited coverage in remote areas, and so the concept of global 
coverage as provided by Iridium was potentially very useful.
Iridium was implemented by a constellation of 66 satellites. The original design 
required 77 satellites, and so the name “Iridium” was chosen (since its atomic num-
ber in the periodic table is 77). However, the later design required just 66 satellites, 
and so “Dysprosium” may have been a more appropriate choice. The satellites are in 
low Earth orbit at a height of approximately 485 miles, and communication between 
the satellites is via inter-satellite links. Each satellite contains seven Motorola Power 
PC 603E processors running at 200MHz, which are used for satellite communica-
tion and control.
Iridium routes phone calls through space and there are several Earth stations. As 
satellites leave the area of an Earth base station the routing tables change, and 
2 The attitude of Motorola at the time seemed to be like that of Henry Ford, that is, they can have 
whatever color they like as long as it is black.
17  A Short History of Telecommunications

235
frames are forwarded to the next satellite just coming into view of the Earth base 
station.
The Iridium constellation is a large commercial satellite constellation, and it is 
especially suited for industries such as maritime, aviation, government and the mili-
tary. Motorola was the prime contractor for Iridium, and it played a key role in its 
design and development. The satellites were produced at a cost of $5 million each 
($40 million each including launch costs), and Motorola engineers could make a 
satellite in the phenomenal time of 2–3 weeks.
The first Iridium call was made by Al Gore in late 1998. However, despite being 
an engineering triumph, Iridium was a commercial failure, and it went bankrupt in 
late 1999 due to insufficient demand for its services. It had needed a million sub-
scribers to break even, and as the cost of an Iridium call was very expensive com-
pared to the existing cellular providers, and as the cost of its handsets were much 
higher and more cumbersome to use than existing mobile phones, there was very 
little demand for its services. The reasons for failure included:
–– Insufficient demand for its services (10,000 subscribers)
–– High cost of its service ($5 per minute for a call)
–– Cost of its mobile handsets ($3000 per handset)
–– Bulky mobile handsets
–– Competition from existing mobile phone networks
–– Management failures
However, the Iridium satellites remained in orbit, and the service was re-­
established in 2001 by the newly founded Iridium Satellite LLC. The new business 
model required just 60,000 subscribers to break even. Today, it has over half a mil-
lion customers, and it is used extensively by the US Department of Defense.
Iridium was designed in the late 1980s and so it is designed primarily for voice 
rather than data. It lacks the sophistication of modern mobile phone networks, and 
so it is not as attractive to users. However, it provides service in remote parts of the 
world, which is very useful. Iridium has developed and launched a second genera-
tion of satellites (Iridium Next) that includes new features such as data transmission. 
The network became operational in 2018. For a more detailed account of the contri-
butions of Bell Labs, Ericsson, and Motorola, see [Ger:13, MeJ:01, Mot:99, 
ORg:15].
17.5  The Iridium Satellite System

236
17.6  Review Questions
17.7  Summary
The invention of the telephone by Graham Bell in the late nineteenth century was a 
revolution in human communication, as it allowed people in different geographic 
locations to communicate instantaneously rather than meeting face to face. The 
early phones had major limitations, but the development of automated telephone 
exchanges helped to deal with these.
However, the key limitation of the telephone was that the actual physical location 
of the person to be contacted was needed prior to communication, that is, commu-
nication was between places rather than people.
This led to research by Bell Labs and others into ways in which communication 
could take place between people (and not places). Bell Labs developed a system in 
the mid-1940s that allowed mobile users to place and receive calls from automo-
biles, with Motorola developing the phones for automobiles. However, these phones 
were large and bulky, and the automobile’s engine needed to be running to make or 
receive a call.
Bell Labs proposed the idea of a cellular system back in the late 1940s, and it 
prepared a detailed plan for its implementation in the late 1960s. A cellular system 
is divided into cells, where each cell has its own base station and channels. The 
available frequencies may be used in parallel in different cells without interference 
with each other.
Motorola developed the first mobile phone, the DynaTAC, and it made the first 
mobile phone call in 1973. The first mobile phone systems were analog, and based 
on the AMPS standard. The later generations of mobile technology are digital, and 
are a significant advance on the older cellular technology.
Iridium provides global wireless coverage to its customers including coverage in 
the oceans, airways and polar regions. It was implemented by a constellation of 66 
satellites.
	1.	 Describe the contributions of Bell Labs to mobile technology.
	2.	 What are the advantages of mobile technology over fixed line technology?
	3.	 Describe the various generations of mobile technology.
	4.	 Describe Motorola’s contributions to mobile technology.
	5.	 What factors led to Ericsson’s success and leadership in mobile technology?
	6.	 What factors led to the (initial) commercial failure of the Iridium System?
17  A Short History of Telecommunications

237
© The Author(s), under exclusive license to Springer Nature 
Switzerland AG 2021
G. O’Regan, A Brief History of Computing, 
https://doi.org/10.1007/978-3-030-66599-9_18
Chapter 18
The Internet Revolution
18.1  Introduction
The vision of the Internet and World Wide Web goes back to an article by Vannevar 
Bush in the 1940s. Bush was an American scientist who had done work on subma-
rine detection for the US Navy. He designed and developed the differential analyzer 
(Fig. 1.1), which was a mechanical computer whose function was to evaluate and 
solve first-order differential equations. Bush supervised Claude Shannon at MIT 
(see Chap. 3) and Shannon’s initial work was to improve the differential analyzer.
Bush (Fig. 18.1) became director of the office of Scientific Research and Development 
and he developed a win–win relationship between the US military and universities. He 
arranged generous research funding for the universities to carry out applied research to 
assist the military. This allowed the military to benefit from the early exploitation of 
research results, and it also led to better facilities and laboratories at the universities. It 
led to close links and cooperation between universities such as Harvard and Berkeley, 
and this would eventually lead to the development of ARPANET by DARPA.
Bush outlined his vision of an information management system called the 
“memex” (memory extender) in a famous essay “As We May Think” [Bus:45]. He 
envisaged the memex as a device electronically linked to a library that would be 
able to display books and films. It describes a proto-hypertext computer system that 
later influenced the development of hypertext systems.
“A memex is a device in which an individual stores all his books, records, and communica-
tions, and which is mechanized so that it may be consulted with exceeding speed and flexi-
bility. It is an enlarged intimate supplement to his memory.
Key Topics
ARPANET
TCP/IP
The Internet
Internet of things
Internet of money
The world-wide web
Dot com bubble
Facebook
The Twitter revolution

238
It consists of a desk, and while it can presumably be operated from a distance, it is pri-
marily the piece of furniture at which he works. On the top are slanting translucent screens 
on which material can be projected for convenient reading. There is a keyboard, and sets of 
buttons and levers. Otherwise it looks like an ordinary desk.”
Bush predicted that:
“Wholly new forms of encylopedias will appear, ready made with a mesh of associative 
trails running through them, ready to be dropped into the memex and there amplified.”
This description motivated Ted Nelson and Douglas Engelbart to independently 
formulate ideas that would become hypertext. Tim Berners-Lee would later use 
hypertext as part of the development of the World Wide Web.
18.2  The ARPANET
There were approximately 10,000 computers in the world in the 1960s. These were 
expensive machines (often over $1 million) with limited processing power. They 
contained only a few thousand words of magnetic memory, and programming and 
debugging was difficult. Further, communication between computers was virtually 
nonexistent.
However, several computer scientists had dreams of worldwide networks of 
computers, where every computer around the globe is interconnected to all other 
Fig. 18.1  Vannevar Bush
18  The Internet Revolution

239
computers in the world. Licklider1 wrote memos in the early 1960s on his concept 
of an intergalactic network, which envisaged that everyone around the globe would 
be interconnected, and able to access programs and data at any site from anywhere.
The US Department of Defense founded the Advance Research Projects Agency 
(ARPA) in the late 1950s. ARPA embraced high-risk, high-return research, and 
Licklider became the head of its computer research program. He developed close 
links with MIT, UCLA, and BBN Technologies.2 The concept of packet switching3 
was invented in the 1960s, and several organizations including the National Physical 
Laboratory (NPL), the RAND Corporation, and MIT commenced work on its 
implementation.
The early computers had different standards for data representation, and so it was 
essential to know the standard employed by each computer prior to communication. 
This led to recognition of the need for common standards in data representation, and 
a US government committee developed the American Standard Code for Information 
Interchange (ASCII) in 1963. This was the first universal standard for data and it 
allowed machines from different manufacturers to exchange data. The standard 
allowed a 7-bit binary number to stand for a letter in the English alphabet, an Arabic 
numeral, or a punctuation symbol. The use of 7 bits allowed 128 distinct characters 
to be represented. The development of the IBM System/360 mainframe (discussed 
in Chap. 8) standardized the use of 8 bits for a word, and 12-bit or 36-bit words 
became obsolete.
The SAGE system did early work done on wide-area networks for military use in 
the late 1950s (see Chap. 6). The first civilian wide-area network connection was 
created in 1965, and it involved the connection of a computer at MIT to a computer 
in Santa Monica. This was done via a dedicated telephone line and it showed that a 
telephone line could be used for data transfer. ARPA recognized the need to build a 
network of computers and this led to the ARPANET project in 1966 which aimed to 
implement a packet-switched network with a network speed of 56 Kbps. ARPANET 
was to become the world’s first packet-switched network.
BBN Technologies was awarded the contract to implement the network with 
plans for a total of 19 nodes. The first two nodes were based at UCLA and Stanford 
Research Institute (SRI). The network management was performed by intercon-
nected Interface Message Processors (IMPs), which were in front of the main 
computers. The IMPs eventually evolved to become the network routers that are 
used today
1 Licklider was an early pioneer of AI and wrote an influential paper “Man-Computer Symbiosis” 
in 1960 [Lic:60], which outlined the need for simple interaction between users and computers.
2 BBN Technologies (originally Bolt Beranek and Newman) is a research and development tech-
nology company. It played an important role in the development of packet switching and in the 
implementation and operation of ARPANET. The “@” sign used in an email address was a BBN 
innovation.
3 Packet switching is a message communication system between computers. Long messages are 
split into packets, which are then sent separately to minimize the risk of congestion.
18.2  The ARPANET

240
The team at UCLA called itself the Network Working Group, and it saw its role 
as developing a set of rules that specified how the computers on the network should 
communicate. These rules were called the Network Control Protocol (NCP). The 
first host-to-host connection was made between a computer in UCLA and a com-
puter at SRI in late 1969. Several other nodes were added to the network until it 
reached its target of 19 nodes in 1971.
The Network Working Group developed the telnet protocol and the file transfer 
protocol (FTP) in 1971. The telnet program allowed the user of one computer to 
remotely log in to the computer of another computer. The file transfer protocol 
allows the user of one computer to send (or receive) files to (from) another com-
puter. A highly successful public demonstration of ARPANET was made in 1972 
and one of the earliest demos was that of Weizenbaum’s Eliza program (see Chap. 
22). This famous Artificial Intelligence (AI) program allowed a user to conduct a 
typed conversation with an artificially intelligent machine (Rogerian psychothera-
pist) at MIT.
The viability of packet switching as a standard for network communication had 
been clearly demonstrated. Ray Tomlinson of BBN Technologies developed a pro-
gram that allowed electronic mail to be sent over the ARPANET. Over 30 institu-
tions were connected to the ARPANET by the early 1970s.
18.2.1  Email
Ray Tomlinson of BBN Technologies is recognized as the inventor of modern email 
as he developed an email program at BBN that allowed a user to send electronic 
mail to another user who was connected to a different host machine on 
ARPANET. Tomlinson sent the first text letter between two ARPANET connected 
computers in 1971.
The users of existing email systems could only send messages to others that used 
the same mainframe computer, and Tomlinson introduced the @ sign to specify the 
machine name of the user where the message should be sent to (e.g., bob@mit). The 
addresses were initially of the form username@host, but this was later revised to 
username@host.domain with the development of the domain name system (DNS).
Tomlinson’s email system was a major advance on existing email systems used 
in organizations, and it led to a revolution in the way that people communicate. 
Email systems are based on a store-and-forward model where the email server 
accepts, stores, forwards and delivers messages, and neither the users nor their com-
puters are required to be on line. There are several protocols used with Email sys-
tems including Simple Mail Transfer Protocol (SMTP), the Post Office Protocol 
(POP3), and the Internet Message Application Protocol (IMAP).
Messages are exchanged between hosts using the SMTP protocol, and the desti-
nation address consists of the username and the domain name. The system then 
attempts to deliver the message, and where it cannot be delivered, the message 
18  The Internet Revolution

241
bounces back to the sender indicating a problem. Users may retrieve their messages 
from the server using POP or IMAP protocols.
It is important to use email appropriately and care is often required before reply-
ing to an email, especially as it is easy to appear as abrupt or harsh in correspon-
dence. Further, emails leave a trail and may be forwarded by the recipient, and so it 
is essential that whatever is written does not cause injury to others. Therefore, an 
email should be courteous and should be written professionally in the work place. 
For example, it should include a subject line, and address the person (or audience) 
appropriately. It needs to be sensitive to cultural differences, and care may be 
required with humor. Finally, the spelling should be checked, and it should be re-­
read prior to it being sent to ensure that the right tone is set in the communication.
18.2.2  Gmail
Google Mail is the most widely use web-based email service (yahoo, hotmail, and 
outlook are other web-based email systems) with over a billion users around the 
world. The user logs into the web-based email account using a web browser to send 
and receive mail. Google provides over 15  GB of free storage between Gmail, 
Google drive, and Google+, and users can purchase additional storage as required 
up to a maximum of 300 TB. Gmail is available on personal computers as well as 
on tablets and mobile devices, and over 50 languages are supported.
Gmail includes a search bar for searching emails, and it also allows web searches 
to be performed. It automatically scans all incoming and outgoing mail for viruses 
in email attachments, and it will prevent the message from being sent if a virus is 
found in the outgoing attachment. Further, it will attempt to remove any viruses 
found in an incoming email attachment.
Gmail automatically scans the contents of emails to filter spam and to add 
context-­sensitive advertisements to the emails. This has raised privacy concerns as 
it means that all emails sent or received are scanned and read by some computer, and 
Google has stated in court filings that no “reasonable expectation exists among 
Gmail users with respect to the confidentiality of their emails.” Further, Google 
argues that the automated scanning of emails is done for the benefits of the user, as 
it allows Google to provide customized search results, tailored advertisements, and 
the prevention of spam and viruses.
18.3  TCP/IP
ARPA was renamed as the Defence Advanced Research Projects Agency (DARPA) 
in 1973. It commenced a project to connect seven computers on four islands using 
a radio-based network and a project to establish a satellite connection between a site 
in Norway and in the United Kingdom. This led to a need for the interconnection of 
18.3  TCP/IP

242
the ARPANET with other networks. The key problems were to investigate ways of 
achieving convergence between ARPANET, radio-based networks, and the satellite 
networks, as these all had different interfaces, packet sizes, and transmission rates. 
Therefore, there was a need for a network-to-network connection protocol.
An International Network Working Group (INWG) was formed in 1973. The 
concept of the transmission control protocol (TCP) was developed at DARPA by 
Bob Kahn and Vint Cerf, and they presented their ideas at an INWG meeting at the 
University of Sussex in England in 1974 [KaC:74]. TCP allowed cross-network 
connections and it began to replace the original NCP protocol that was used in 
ARPANET.
TCP is a set of network standards that specify the details of how computers com-
municate as well as the standards for interconnecting networks and computers. It 
was designed to be flexible and provides a transmission standard that deals with 
physical differences in host computers, routers, and networks. It is designed to 
transfer data over networks which support different packet sizes, and which may 
sometimes lose packets. It allows the inter-networking of very different networks, 
which then act as one network.
The new protocol standards were the transport control protocol (TCP) and the 
Internet protocol (IP). TCP details how information is broken into packets and re-­
assembled on delivery, whereas IP is focused on sending the packet across the net-
work. These standards allow users to send electronic mail or to transfer files 
electronically without needing to concern themselves with the physical differences 
in the networks. TCP/IP consists of four layers (Table 18.1):
The Internet protocol (IP) is a connectionless protocol that is responsible for 
addressing and routing packets. It breaks large packets down into smaller packets 
when they are traveling through a network that supports smaller packets. A connec-
tionless protocol means that a session is not established before data are exchanged 
and packet delivery with IP is not guaranteed as packets may be lost or delivered out 
of sequence.
An acknowledgment is not sent when data are received and the sender or receiver 
is not informed when a packet is lost or delivered out of sequence. The router for-
wards a packet only if it knows a route to the destination, and otherwise, the packet 
Table 18.1  TCP layers
Layer
Description
Network interface 
layer
This layer is responsible for formatting packets and placing them on to the 
underlying network.
Internet layer
This layer is responsible for network addressing. It includes the internet 
protocol and the address resolution protocol.
Transport layer
This layer is concerned with data transport, and is implemented by TCP and 
the user datagram protocol (UDP).
Application layer
This layer is responsible for liaising between user applications and the 
transport layer
It includes the file transfer protocol (FTP), telnet, domain naming system 
(DNS), and simple mail transfer program (SMTP).
18  The Internet Revolution

243
is dropped. Packets are dropped if their checksum is invalid or if their time to live is 
zero. The acknowledgment of packets is the responsibility of the TCP protocol. The 
ARPANET employed the TCP/IP protocols as a standard from 1983.
18.4  Birth of the Internet
The use of ARPANET was initially limited to academia and to the United States 
military, and in the early years, there was little interest from industrial companies. It 
allowed messages to be sent between the universities that were part of 
ARPANET. There were over 2000 hosts on the TCP/IP-enabled network by the 
mid-1980s.
It was decided to shut down the network by the late-1980s, and the National 
Science Foundation (NSF) commenced work on its successor, the NSFNET, in the 
mid-1980s. This network consisted of multiple regional networks connected to a 
major backbone. The original links in NSFNET were 56Kbps, but these were 
updated to 1.544Mbps T1 links in 1988. The NSFNET T1 backbone initially con-
nected 13 sites, but this increased as there was growing academic and industrial 
interest from around the world. The NSF quickly realized that the Internet had com-
mercial potential.
The Internet began to become more international with nodes in Canada and sev-
eral European countries. DARPA formed the Computer Emergency Response Team 
(CERT) to deal with any emergency incidents arising from the operation of the 
network.
The independent not-for-profit company, Advanced Network Services (ANS), 
was founded in 1991. It installed a new network (ANSNET) that replaced the 
NSFNET T1 network, and it operated over T3 (45Mbps) links. It was owned and 
operated by a private company rather than the U.S. government with the NSF focus-
ing on the research aspects of networks rather than on the operational side.
The ANSNET network was a distributive network architecture operated by com-
mercial providers such as Sprint, MCI, and BBN. The various parts of the network 
were connected by major network exchange points. These were termed Network 
Access Points (NAPs) and there were over 160,000 hosts connected to the Internet 
by the late 1980s.
18.5  Birth of the World Wide Web
Tim Berners-Lee invented the World Wide Web at CERN in 1990 [BL:00]. CERN 
is an important European center for research in the nuclear field, and it is based in 
Switzerland. It employs several thousand physicists and scientists from around the 
world and has many visiting scientists.
18.5  Birth of the World Wide Web

244
One of the problems that scientists at CERN faced in the late 1980s was in keep-
ing track of people, computers, documents, and databases. The center had many 
visiting scientists who spent several months there as well as a large pool of perma-
nent staff. There was no efficient way in CERN at that time to share information 
among scientists.
A visiting scientist might need to obtain information or data from a CERN com-
puter or to make the results of their research available to researchers at 
CERN. Berners-Lee came to CERN in the early 1980s, and he developed a program 
called “Enquire” to assist with information sharing and in keeping track of the work 
of visiting scientists. He returned to CERN in the mid-1980s to work on other proj-
ects and he devoted part of his free time to consider solutions to the information-­
sharing problem.
He built on several existing inventions such as the Internet, hypertext, and the 
mouse. Ted Nelson invented hypertext in the 1960s and it allowed links to be pres-
ent in text. For example, a document such as a book contains a table of contents, an 
index, and a bibliography. These are all links to material that is either within the 
book itself or external to the book. The reader of a book may follow the link to 
obtain the internal or external information. Doug Engelbart invented the mouse in 
the 1960s and it allowed the cursor to be steered around the screen.
The major leap that Berners-Lee made was essentially a marriage of the Internet, 
hypertext, and the mouse into what has become the World Wide Web. His vision and 
its subsequent realization benefited CERN and the wider world.
He created a system that gives every web page a standard address called the uni-
versal resource locator (URL). Each page is accessible via the hypertext transfer 
protocol (HTTP) and the page is formatted with the hypertext mark-up language 
(HTML). Each page is visible using a web browser. The key features of Berners-Lee 
invention are listed in Table 18.2.
Berners-Lee invented the well-known terms such as URL, HTML, and World 
Wide Web, and he wrote the first browser program that allowed users to access web 
pages throughout the world. Browsers are used to connect to remote computers over 
the Internet and to request, retrieve, and display the web pages on the local machine.
The early browsers included Gopher developed at the University of Minnesota, 
and Mosaic developed at the University of Illinois. These were replaced in later 
years by Netscape, which dominated the browser market until Microsoft developed 
Table 18.2  Features of world Wide Web
Feature
Description
URL
Universal Resource Identifier (later renamed to Universal Resource Locator (URL) 
provides a unique address code for each web page.
HTML
Hypertext mark-up language (HTML) is used for designing the layout of web pages.
HTTP
The Hypertext Transport Protocol (HTTP) allows a new web page to be accessed from 
the current page.
Browser A browser is a client program that allows a user to interact with the pages and 
information on the World Wide Web.
18  The Internet Revolution

245
its Internet Explorer (IE). The development of the graphical browsers led to the 
commercialization of the World Wide Web.
The World Wide Web creates a space in which users can access information eas-
ily from any part of the world. This is done using only a web browser and simple 
web addresses. The user can then click on hyperlinks on web pages to access further 
relevant information that may be on an entirely different continent. Berners-Lee 
later became the director of the World Wide Web Consortium and this MIT-based 
organization sets the software standards for the Web.
The invention of the World Wide Web was a revolutionary milestone in the his-
tory of computing. It transformed the use of the Internet from mainly academic use 
to where it is now an integral part of peoples’ lives. Users may now surf the web, 
that is, hyperlink among the millions of computers in the world and obtain informa-
tion easily. It is revolutionary in that:
•	 No single organization is controlling the web.
•	 No single computer is controlling the web.
•	 Millions of computers are interconnected.
•	 It is an enormous market place of billions of users.
•	 The web is not located in one physical location.
•	 The web is a space and not a physical thing.
18.5.1  Applications of the World Wide Web
Berners-Lee realized that the World Wide Web offered the potential to conduct 
business in cyberspace rather than the traditional way where buyers and sellers 
come together to do business in the market place.
“Anyone can trade with anyone else except that they do not have to go to the market square 
to do so”
The growth of the World Wide Web has been phenomenal with exponential 
growth rate curves, a feature of newly formed Internet companies and their business 
plans. It has been applied to many areas, including the following:
•	 Travel industry (booking flights, train tickets, and hotels)
•	 E-marketing
•	 Online shopping
•	 Portal sites
•	 Recruitment services
•	 Internet banking
•	 Online casinos
•	 Online auction sites
•	 Newspapers and news channels
•	 Social media
18.5  Birth of the World Wide Web

246
The prediction in the early days was that the new web-based economy would 
replace traditional bricks and mortar companies. It was expected that most business 
would be conducted over the web with traditional enterprises losing market share 
and going out of business. Exponential growth of e-commerce companies was pre-
dicted, and the size of the new web economy was estimated to be in trillions of 
U.S. dollars.
New companies were formed to exploit the opportunities of the web, and exist-
ing companies developed e-business and e-commerce strategies to adapt to the 
brave new world. Companies providing full e-commerce solutions were concerned 
with the selling of products or services over the web to either businesses or consum-
ers. These business models are referred to as Business-to-Business (B2B) or 
Business-to-consumer (B2C). E-commerce websites have the following character-
istics (Table 18.3):
18.6  Dot Com Companies
The success of the World Wide Web was phenomenal and it led to a boom in the 
formation of “new economy” businesses. These businesses were conducted over the 
web and included the Internet portal company (Yahoo), the online bookstore 
(Amazon), and the online auction site (eBay). Yahoo provides news and a range of 
services and most of its revenue comes from advertisements. Amazon initially sold 
books, but it now sells a collection of consumer and electronic goods and also sup-
ports cloud computing. eBay brings buyers and sellers together in an online auc-
tion space.
Some of these new technology companies were successful and remain in busi-
ness. Others were financial disasters due to poor business models, poor manage-
ment, and poor implementation of the new technology. Some of these technology 
companies offered an Internet version of a traditional bricks and mortar company, 
Table 18.3  Characteristics of e-commerce
Feature
Description
Catalogue of 
products
The catalogue of products details the products available for sale and their 
prices.
Well-designed and 
easy to use.
This is essential as otherwise the website will not be used.
Shopping carts
This is analogous to shopping carts in a supermarket.
Security
Security of credit card information is a key concern for users of the web, as 
users need to have confidence that their credit card details will not be 
compromised.
Payments
Once the user has completed the selection of purchases, there is a checkout 
facility to arrange for the purchase of the goods.
Order fulfillment/
Order enquiry
Once payment has been received, the products must be delivered to the 
customer.
18  The Internet Revolution

247
with others providing a unique business offering. For example, eBay offers an auc-
tioneering Internet site to consumers worldwide which was a totally new service 
and quite distinct from traditional auctioneering.
David Filo and Jerry Yang founded Yahoo, and they used it to keep track of their 
personal interests and the corresponding websites on the Internet. Filo and Yang 
were students at Stanford in California, and their list of interests grew over time and 
became too long and unwieldy. Therefore, they broke their interests into a set of 
categories and then subcategories, and this is the core concept of the website.
There was a lot of interest in the site from other students, family and friends, and 
a growing community of users. The founders realized that the site had commercial 
potential and they incorporated it as a business in 1995. The company launched its 
initial public offering (IPO) 1 year later in April 1996, and it was valued at $850 
million. Yahoo is a portal site and it offers free email accounts to users, a search 
engine, news, shopping, entertainment, health, and so on. The company earns most 
of its revenue from advertisement (including the click through advertisements that 
appear on a yahoo web page).
Jeff Bezos founded Amazon in 1995 as an online bookstore, and its product port-
folio has expanded to include just about everything. Its initial focus was to build up 
the “Amazon” brand throughout the world, and to become the world’s largest book-
store. It initially sold books at a loss by giving discounts to buyers to build market 
share. It was very effective in building its brand through advertisements, marketing, 
and discounts.
It became the largest online bookstore in the world and has a solid business 
model with a very large product catalogue, a well-designed website with good 
searching facilities, good check out facilities and good order fulfillment. It also 
developed an associate model, which allows its associates to receive a commission 
for purchases of Amazon products made through the associate site.
Pierre Omidyar founded eBay in 1995, and the site brings buyers and sellers 
together. Millions of items are listed, bought, and sold on eBay every day. The sell-
ers are individuals or international companies. Any legal product that does not vio-
late the company’s terms of service may be bought or sold on the site. A buyer 
makes a bid for a product or service and competes against several other bidders. The 
highest bid is successful, and payment and delivery is then arranged. The revenue 
earned by eBay includes fees to list a product and commission fees that are applied 
whenever a product is sold.
Any product listed that violates eBay’s terms of service is removed from the site 
as soon as the company is aware of them. The company also has a fraud prevention 
mechanism, which allows buyers and sellers to provide feedback on each other and 
to rate each other following the transaction. The feedback may be positive, negative, 
or neutral, and relevant comments included. This offers a way to help to reduce 
fraud as unscrupulous sellers or buyers will receive negative ratings and comments.
18.6  Dot Com Companies

248
18.6.1  Dot Com Failures
Several of the companies formed during the dot com era were successful and remain 
in business today. Others had inappropriate business models or poor management 
and failed in a spectacular fashion. This section considers some of the dot com fail-
ures and highlights the reasons for failure.
Webvan.com was an online grocery business based in California. It delivered 
products to a customer’s home within a 30-min period of their choosing. The com-
pany expanded to several other cities before it went bankrupt in 2001. Many of its 
failings were due to management as the business model was reasonable, and today, 
there are several successful online fresh food delivery businesses. The management 
was inexperienced in the supermarket or grocery business, and the company spent 
excessively on infrastructure. It had been advised to build up an infrastructure to 
deliver groceries as quickly as possible rather than developing partnerships with 
existing supermarkets. It built warehouses, purchased a fleet of delivery vehicles, 
and top of the range computer infrastructure before running out of money.
Ernst Malmsten and others founded Boo.com in 1998 as an online fashion 
retailer that was based in the United Kingdom. The company spent over $135 mil-
lion of shareholder funds in less than 3 years before it went bankrupt in 2000. Its 
website was poorly designed for its target audience, and it went against many of the 
accepted usability conventions of the time. The website was designed in the days 
before broadband with 56K modems used by most customers. However, its design 
included the latest Java and Flash technologies and it took most users several min-
utes to load the first page of the website. Further, the navigation of the website was 
inconsistent and changed as the user moved around the site.
Other reasons for failure included poor management and leadership, lack of 
direction, lack of communication between departments, spirally costs left unchecked, 
and crippling pay roll costs. Further, purchasers returned many products, and there 
was no postage charge applied for this service. The company went bankrupt in 
2000, and an account of its formation and collapse is in the book Boo Hoo, [MaP:02]. 
This book is a software development horror story, and the maturity of the software 
development practices employed may be judged from the fact that the developers 
were working without any source code control mechanism in place (a basic soft-
ware engineering practice). The net effect was that despite extensive advertising by 
the company, users were not inclined to use the site.
Pets.com was an online pet supply company founded in 1998 by Greg McLemore. 
It sold pet accessories and supplies, and it had a well-known advertisement as to 
“why one should shop at an online pet store?” The answer to this question was: 
“Because Pets Can't Drive!” Its famous mascot (the Pets.com dog sock puppet) was 
used in its marketing campaign. It launched its IPO in February 2000 just before the 
dot com collapse.
Pets.com made investments in infrastructure such as warehousing and vehicles. 
It needed a critical mass of customers to break even, and its management believed 
18  The Internet Revolution

249
that it needed $300 million of revenue to achieve this. They expected that this would 
take a minimum of 4–5 years, and therefore, there was a need to raise further capital. 
However, following the dot com collapse of 2000, there was negative sentiment 
toward technology companies, and it was apparent that it would be unable to raise 
further capital. The management tried to sell the company without success, and it 
went into liquidation 9 months after its IPO.
Joseph Park and Yong Kang founded Kozmo.com in New York in 1998 as an 
online company that promised free 1-h delivery of small consumer goods. It pro-
vided point-to-point delivery (usually on a bicycle) and did not charge a delivery 
fee. Its business model was deeply flawed, as it is expensive to offer point-to-point 
delivery of small goods within a 1-h period without charging a fee. The company 
argued that they could make savings to offset the delivery costs, as they did not 
require retail space. It expanded into several cities in the United States and raised 
about $280 million from investors. The company ceased trading in 2001.
18.6.2  Business Models
A business model converts a business or technology idea into a commercial reality, 
and it needs to be appropriate for the company and its intended operating market. A 
company with an excellent business idea but with a weak business model may fail, 
whereas a company with an average business idea but an excellent business model 
may be quite successful. Several of the business models in the dot com era were 
deeply flawed, and the eventual collapse of many of these companies was predict-
able. Chesbrough and Rosenbroom [ChR:02] have identified six key components in 
a business model (Table 18.4):
Table 18.4  Characteristics of business models
Constituent
Description
Value proposition
This describes how the product or service is a solution to a customer 
problem.
Market segment
This describes the customers that will be targeted (including market 
segments).
Value chain structure
This describes where the company fits into the value chain [Por:98].
Revenue generation and 
margins
This describes how revenue will be generated, including revenue 
streams from sales, support, etc.
Position in value 
network
This involves identifying competitors and other players that can assist 
in delivering added value to the customer.
Competitive strategy
This describes how it will develop a competitive advantage to be 
successful.
18.6  Dot Com Companies

250
18.6.3  Bubble and Burst
The initial public offering of Netscape in 1995 demonstrated the incredible value of 
the new Internet companies. Netscape had planned to issue the share price at $14, 
but it decided at the last minute to issue it at $28. The share price reached $75 later 
that day. This was followed by what became the dot com bubble where there were 
many public offerings of internet stock, and the value of these stocks reached astro-
nomical levels. Reality returned to the stock market when it crashed in April 2000, 
and share values returned to more realistic levels.
Most of these Internet companies were losing substantial sums of money, and 
few expected to deliver profits in the short term. Financial instruments such as the 
balance sheet, profit and loss account, and price to earnings ratio are usually 
employed to estimate the value of a company. However, investment bankers argued 
that there was a new paradigm in stock market valuation for Internet companies. 
This paradigm suggested that the potential future earnings of technology companies 
be considered in determining their value, and this was used to justify the high prices 
of shares, as frenzied investors rushed to buy these over-priced and over-hyped 
stocks. Common sense seemed to play no role in decision-making. The dot com 
bubble was characterized by the following:
•	 Irrational exuberance on the part of investors.
•	 Insatiable appetite for Internet Stocks.
•	 Incredible greed from all parties involved.
•	 Following herd mentality.
•	 A lack of rationality and common sense by all concerned.
•	 Traditional method of company valuation not employed.
•	 Interest in making money rather than in building the business first.
•	 Questionable decisions by Federal Reserve Chairman (Alan Greenspan).
•	 Questionable analysis by investment firms.
•	 Investment banks had conflicts of interest and did not question the boom too 
closely.
•	 Market had left reality behind.
There were winners and losers in the boom and collapse. Some investors made a 
lot of money from the bubble, with others including pension funds and life assur-
ance funds making significant losses. The investment banks typically earned 5–7% 
commission on each successful IPO, and it was not in their interest to question the 
boom too closely. Those who bought and disposed early obtained a good return, 
whereas those who kept their shares for too long suffered losses. The full extent of 
the boom can be seen in the rise and fall of the value of the Dow Jones and NASDAQ 
from 1995 through 2002.
The extraordinary rise of the Dow Jones (Fig. 18.2) from a level of 3800 in 1995 
to 11900 in 2000 represented a 200% increase over 5 years or approximately 26% 
annual growth (compound) during this period. The rise of the NASDAQ (Fig. 18.3) 
over this period is even more dramatic. It rose from a level of 751 in 1995 to 5000 in 
2000 representing a 566% increase during the period. This is equivalent to a 46% 
compounded annual growth rate of the index.
18  The Internet Revolution

251
The fall of the indices was equally as dramatic especially in the case of the 
NASDAQ (Fig. 18.3). It peaked at 5000 in March 2000, and fell to 1200 (a 76% 
drop) by September 2002. It had become clear that Internet companies were rapidly 
going through the cash raised at the IPOs, and analysts noted that a significant num-
ber would be out of cash by the end of 2000. Therefore, these companies would 
either go out of business or would need to go back to the market for further funding. 
This led to questioning of the hitherto relatively unquestioned business models of 
these Internet firms. Funding is easy to obtain when stock prices are rising at a rapid 
rate. However, when prices are static or falling, with negligible or negative business 
return to the investor, then funding dries up. The actions of the Federal Reserve in 
rising interest rates to prevent inflationary pressures also helped to correct the irra-
tional exuberance of investors.
Some independent commentators had recognized the bubble but their comments 
and analysis had been largely ignored. These included “The Financial Times” and 
the “Economist” as well as some commentators in the investment banks. Investors 
rarely queried the upbeat analysis coming from Wall Street, and seemed to believe 
that rising stock prices would be a permanent feature of the US stock markets. 
Greenspan had argued that it is difficult to predict a bubble until after the event, and 
that even if the bubble had been identified it could not have been corrected without 
causing a contraction. Instead, the responsibility of the Fed (according to Greenspan) 
was to mitigate the fallout when it occurs.
Dow Jones Trend
0
2000
4000
6000
8000
10000
12000
14000
1995
1996
1997
1998
1999
2000
2001
2002
Dow Jones Trend
Fig. 18.2  Dow Jones (1995–2002)
Nasdaq Trend
0
1000
2000
3000
4000
5000
6000
1995
1996
1997
1998
1999
2000
2001
2002
Nasdaq Trend
Fig. 18.3  NASDAQ (1995–2002)
18.6  Dot Com Companies

252
There have, of course, been other stock market bubbles throughout history. For 
example, in the 1800s, there was a rush on railway stock in England leading to a 
bubble and eventual burst of railway stock prices in the 1840s. There was a devastat-
ing property bubble and collapse (2002–2009) in the Republic of Ireland. The fail-
ure of the Irish political class, the Irish Central bank and financial regulators, the 
Irish Banking sector in their irresponsible lending policies, and failures of the media 
in questioning the bubble are deeply disturbing. Its legacy remains and while the 
country has made a remarkable recovery, the failures of so many at senior level in 
the state remains deeply disturbing.
18.6.4  E-Commerce Security
The World Wide Web consists of unknown users and suppliers with un-predictable 
behavior operating in unknown countries around the world. These users and web-
sites may be friendly or hostile and the issue of trust arises:
•	 Is the other person who they claim to be?
•	 Can the other person be relied upon to deliver the goods on-payment?
•	 What legal remedies are there if the goods are not delivered?
•	 Can the other person be trusted not to inflict malicious damage?
•	 Is financial information kept confidential on the server?
Hostility may manifest itself in various acts of destruction. For example, mali-
cious software may attempt to format the hard disk of the local machine, and if 
successful, all local data will be deleted. Other malicious software may attempt to 
steal confidential data from the local machine including bank account or credit card 
details. The denial of service attack is when a website is overloaded by a malicious 
attack, and where users are unable to access the website for an extended period.
The display of web pages on the local client machine may involve the download-
ing of programs from the server, and running the program on the client machine. 
Standard HTML allows the static presentation of a web page, whereas many web 
pages include active content (e.g., Java Applets or Active X). There is a danger that 
a Trojan horse4 may be activated during the execution of active content.
Security threats may be from anywhere (e.g., client side, server side, transmis-
sion) in an e-commerce environment, and therefore, a holistic approach is required 
4 The origin of the term “Trojan Horse” is from Homer’s Illiad and concerns the Greek victory in 
the Trojan war. The Greek hero Odysseus and others hid in a wooden horse while the other Greeks 
sailed away from Troy. This led the Trojans to believe that the Greeks had abandoned their attack 
and were returning to their homeland leading behind a farewell gift for the citizens of Troy. The 
Trojans brought the wooden horse into the city, and later that night Odysseus and his companions 
opened the gates of Troy to the returning Greeks, leading to the mass slaughter of its citizens. 
Hence the phrase “Beware of Greeks bearing gifts.” Troy was located at the mouth of the 
Dardanelles in Turkey.
18  The Internet Revolution

253
to protect the user. Internal and external security measures need to be considered, 
with internal security generally implemented with good processes and procedures 
and assigning appropriate access privileges.
It is essential that users have confidence in the security provided as otherwise 
they will be reluctant to pass credit card details over the web for purchases. 
Technologies such as secure-socket layer (SSL) and secure HTTP (S-HTTP) help to 
ensure security.
18.7  Internet of Things
The Internet of Things refers to interconnected technology that is now an integral 
part of modern society, where computation and data communication are embedded 
in our environment. The Internet of Things is not a single technology as such, and 
instead, it is a collection of devices, sensors, and services that capture data to moni-
tor and control the world around them. It means that information processing is now 
an integral part of people’s lives.
The Internet of Things has been applied to several areas including our bodies 
(quantified self), our homes (smart homes) and public spaces (smart city). Wearable 
biometric sensors may be used to determine the calories burned during a period of 
exercise as well as monitoring heart rate, breathing, skin temperature, and perspira-
tion. In theory, this helps individuals to control key parameters associated with 
their health.
The rise of the smart home is intended to deliver convenience to home occupiers, 
and these consist of connected devices that provide useful functionality. The various 
digital controls in a modern home may be used to control lighting, entertainment, 
security as well as cooling and ventilation systems. The devices gather data about 
the environment as well as passing data back to the service provider. However, there 
are dangers with giving all this data about your life to a service provider, as it is 
essential that the privacy of an individual be protected.
The rise of the smart city is where the modern city collects data about its inhabit-
ants, and uses it to make more efficient use of energy, space, and other resources. 
The data may be gathered through CCTV and other devices, and in the future, the 
smart city will have knowledge of the habits and energy use of the citizens, allowing 
it to control resources more effectively.
There are several implicit assumptions with respect to smart cities, and it seems 
to be assumed that it is possible to know all aspects of the world perfectly with data, 
and that the data will always be accurate, and that the data will be easy to interpret. 
These assumptions are questionable.
That is, while the Internet of Things presents new possibilities, it is important to 
proceed cautiously and to use it as an extra tool that may support decision-making 
rather than assuming that it provides all the answers. For further information on the 
Internet of Things, see the thought-provoking Guardian article [Gre:17].
18.7  Internet of Things

254
18.8  Internet of Money and Bitcoin
The idea of the Internet of Money is to build a financial environment that is suitable 
for the Internet world, and it moves away from the traditional centralized model of 
banking where banks record and manage all financial transactions. The new para-
digm is a decentralized model (via the Internet) where buyers and sellers interact 
directly through digital currencies and decentralized ledgers. This decentralized 
model is termed the “Internet of Money,” and Bitcoin aims to satisfy this model.
Digital currency is a type of currency that is available only in digital form, and it 
exhibits properties like the traditional physical currencies in that they may be used 
to buy goods and services. These include virtual currencies and cryptocurrencies.
The concept of digital cash was proposed by David Chaum in the early 1980s, 
and he formed DigiCash (an electronics cash company) in the early 1990s to com-
mercialize his research [Ch:82]. The goal of electronic cash (ecash) is to allow the 
user to be anonymous, and it allows users to spend in a manner that is untraceable 
to a bank or any other third party.
Chaum introduced the idea of blind signatures in his 1982 paper, which blinds 
the content of a message before it is signed. This means that the signer cannot deter-
mine the content of the message, but the resulting blind signature can be verified 
against the original unblinded message.
There are several types of digital currency including centralized systems (e.g., 
PayPal, eCash) which sell digital currency directly to the end user, mobile digital 
wallets for contactless payment transfer to facilitate easy payment (e.g., Google 
Wallet and Apple Pay make it easy to carry all your debit and credit cards on your 
smartphone), and decentralized system which employ cryptocurrencies and rely on 
cryptography (Bitcoin is the most well known of these). Finally, there are virtual 
currencies which are issued and controlled by its developers, and accepted by the 
members of a virtual community.
One of the earliest digital currencies was e-Gold (it was backed by Gold), and 
this centralized service appeared in the mid-1990s. The US government later shut it 
down due to concerns over money laundering. Bitcoin appeared in 2008, and it is 
the most widely used and accepted digital currency.
Bitcoin is based on cryptographic algorithms, and it is the first decentralized 
digital currency. It was created by an unknown inventor(s) with the pseudonym 
Satoshi Nakamoto in 2008 [Nak:08], and it works without a central repository or 
single administrator. It is peer-to-peer with transactions taking place directly 
between users without the need for third-party intermediaries, and the transactions 
are verified by network nodes and recorded in a public distributed ledger termed a 
blockchain. The open-source software for Bitcoin was released by Nakamoto in 
early 2009, and the domain name bitcoin.org was registered in 2008.
The unit of account in the Bitcoin system is the bitcoin (BTC) with smaller 
amounts represented by millibitcoins (0.001 BTC), and the smallest amount is the 
satoshi (0.00000001 BTC).
18  The Internet Revolution

255
18.9  Review Questions
18.10  Summary
This chapter considered the evolution of the Internet from the early work on packet 
switching and ARPANET to the subsequent development of the TCP/IP network 
protocol, which is a transmission standard that deals with physical differences in 
host computers, routers, and networks.
TCP/IP is designed to transfer data over networks which support different packet 
sizes and which may sometimes lose packets. TCP details how information is bro-
ken into packets and re-assembled on delivery, whereas IP is focused on sending the 
packet across the network.
The invention of the World Wide Web by Tim Berners-Lee was a revolutionary 
milestone in computing. It transformed the Internet from mainly academic use to 
commercial use, and it led to a global market of consumers and suppliers. Today, the 
World Wide Web is an integral part of peoples’ lives.
The growth of the World Wide Web was exponential, and it led to the formation 
of many “new economy” businesses. These new companies conducted business 
over the web as distinct from the traditional bricks and mortar companies. Some of 
these new companies were very successful (e.g., Amazon) and remain in business. 
Others were financial disasters due to poor business models, poor management, and 
poor implementation of the new technology.
The dot com bubble was characterized by many public offerings of internet 
stock, and where the value of these stocks reached astronomical levels. Reality 
returned to the stock market when the bubble burst and the market crashed in 2000.
	 1.	 Describe the development of the internet.
	 2.	 Describe the development of the World Wide Web and its key 
constituents.
	 3.	 Describe the applications of the World Wide Web.
	 4.	 Describe the key constituents of an electronic commerce site.
	 5.	 Describe a successful dot com company that you are familiar with. What 
has made the company successful?
	 6.	 Describe a dot com failure that you are familiar with. What caused the 
company to fail?
	 7.	 Discuss the key components of a business model.
	 8.	 Discuss security in an e-commerce environment.
	 9.	 What is the Internet of Things?
	10.	 What is bitcoin?
18.10  Summary

257
© The Author(s), under exclusive license to Springer Nature 
Switzerland AG 2021
G. O’Regan, A Brief History of Computing, 
https://doi.org/10.1007/978-3-030-66599-9_19
Chapter 19
The Smartphone and Social Media
19.1  Introduction
Smartphones arose as the outcome of the marriage of the existing mobile phone 
technology and Personal Digital Assistant (PDA) technology, and they contain 
advanced computing capabilities that are attractive to users. Today, the smartphone 
is ubiquitous, with most people in advanced countries owning one.
The introduction of the PDA by Apple and Palm played a role in the development 
of the smartphone, and its introduction facilitated a major growth of social network-
ing. Users are now able to communicate news events, or update their personal infor-
mation in real time. Social networking sites such as Facebook and Twitter have 
transformed human communication.
Social media involves the use of computer technology for the creation and 
exchange of user-generated content. These web-based technologies allow users to 
discuss and modify the created content, and it has led to major changes in commu-
nication between individuals, communities, and organizations.
Facebook helps users to keep in touch with friends and family, and it allows them 
to share their opinions on what is happening around the world. Users may upload 
photos and videos; express opinions and ideas; and exchange messages. Facebook 
allows the user’s community of friends to be actively kept up to date on important 
events that the user wishes to share.
Facebook has become an important communication channel for young people to 
discuss their aspirations for the future, as well as their grievances with society and 
the state. It has become an effective tool for protest and social revolution.
Twitter has become an effective way to communicate the latest news, and its 
effectiveness as a communication tool increases as the number of a person’s follow-
ers grows. It allows a person or organization to determine what people are saying 
about it, including their positive or negative experiences. This allows direct interac-
tion with the followers, and so it is a powerful way to engage the audience and to 
make people feel heard.
Key Topics
PDA
Smartphone
Facebook
Tweets
Twitter

258
19.2  Evolution of the Smartphone
A smartphone is more than a mobile device for making and receiving calls, and it is 
essentially a touch-based computer on a phone, which comes with its own touch-
screen keyboard, operating system, Internet access, and third-party applications. It 
provides many other features such as a camera, maps, browser, email, calendar, 
alarm clock and games.
IBM (in a joint venture with BellSouth) introduced one of the earliest precursors 
of today’s smartphones in 1993. This was the IBM Simon, and it included voice and 
data services. It acted as a mobile phone, a PDA, and a fax machine, and it also 
included a touchscreen that could be used to dial numbers. It could send faxes and 
emails as well as making or receiving calls, and it included applications such as an 
address book, calendar, and calculator. However, it was a large and expensive bulky 
device, and it was priced at $900.
A PDA allows a large amount of data to be stored on a small handheld device. 
John Sculley, the CEO of Apple, coined the term “Personal Digital Assistant,” and 
Apple introduced the first PDA, the Newton, in 1993. The Apple Newton included 
some nice features including limited handwriting recognition abilities. Xerox PARC 
had created a prototype PDA, the Dynabook, in the 1970s, but they did not com-
mercialize it.
Palm introduced an early PDA device, the Palm Pilot 1000, in 1996, and this was 
used for mobile data. It played an important role in popularizing the use of mobile 
data by business users. The Palm Pilot started the PDA industry, and it included 
128Kb of memory and 16 MHz of processing power. It had better handwriting rec-
ognition capabilities than the Newton, and a graphical user interface.
The Nokia 9000 Communicator was released in 1996, and this phone combined 
the features of a PDA and a mobile phone. It included a physical QWERTY key-
board, and it provided features such as email, calendar, address book, and calcula-
tor. However, it did not provide the ability to browse the web, and a color display 
was introduced in the Nokia 9120 in 1998.
Qualcomm introduced its pdQ smartphone in 1999, and this phone combined a 
Palm PDA with Internet connectivity capabilities. Research In Motion (RIM) 
released its first Blackberry devices in 1999, and these provided secure email com-
munication into a single inbox. Samsung’s first smartphone was the Samsung SPH-­
I300, which was released in 2001, and this Palm-powered smartphone is a distant 
ancestor of today’s smartphones. Samsung introduced its SGH i607 smartphone in 
2006, and this Window’s powered phone was inspired by Research in Motion’s 
Blackberry phone.
Smartphone technology continued to evolve through the early 2000s, and Apple 
introduced its revolutionary iPhone in 2007. This Internet-based multimedia smart-
phone included a touch screen, and features such as a video camera, email, web 
browsing, text messaging, and voice. The iPhone had a 3.5 inch 480 × 320 touch-
screen, a QWERTY touchscreen keyboard, and 4GB of storage. Apple developed its 
own operating system, iOS, for the iPhone.
19  The Smartphone and Social Media

259
Google introduced its open source Android operating system in late 2007, and 
the first Android phone was introduced in late 2008. Android is now the dominant 
operating system for smartphones and tablets, with iOS used on Apple’s products. 
The Samsung Instinct was released in 2008, but it was based on an operating system 
developed by Samsung from various Java components. Although, its touch screen 
operating system was not in the same league as Apple’s iOS, it became a competitor 
to Apple’s iPhone.
Apple’s iPhone 4 (Fig.  19.1) was introduced in 2010, and this powerful 
smartphone has a 3.5  inch 960  ×  640 screen and a 5-mega pixel camera. The 
Samsung Galaxy S smartphone was launched in 2010, and this touchscreen enabled 
Android smartphone became extremely popular. The Samsung Galaxy S series of 
smartphones have been very successful, and have become a major competitor to 
Apple’s iPhone.
Apple released the iPad in 2010, which is a large screen tablet like device that 
uses a touch screen operating system. Samsung is a major competitor to Apple in 
the tablet market.
19.3  The Facebook Revolution
Facebook is the leading social networking site (SNS) and its mission is to make the 
world more open and connected. It helps users to keep in touch with friends and 
family, and it allows them to share their opinions on what is happening around the 
world. Users may upload photos and videos, express opinions and ideas, and 
exchange messages. Facebook is very popular with advertisers as it allows them to 
easily reach a large target audience.
Mark Zuckerberg (Fig.  19.2) founded the company in 2004 while he was a 
student studying psychology at Harvard University. Zuckerberg was interested in 
programming, and he had already developed several social networking websites for 
Fig 19.1  Apple iPhone 4
19.3  The Facebook Revolution

260
his fellow students, including Facemash, which could be used to rate the 
attractiveness of a person, and Coursematch, which allowed students to view people 
taking their degree.
Zuckerberg launched “The Facebook” (thefacebook.com) at Harvard in February 
2004, and over a thousand Harvard students had registered on the site within the first 
24 hours. Over half of the Harvard student population had a profile on Facebook 
within the first month. The membership of the site was initially restricted to students 
at Harvard, then to students at the other universities in Boston, and then to students 
at the other universities in the United States. Its membership was extended to inter-
national universities from 2005.
The use of Facebook was extended beyond universities to anyone with an email 
address from 2006, and the number of registered users began to increase exponen-
tially. The number of registered users reached 100 million in 2008, 500 million in 
2010, it exceeded 1 billion in 2012 and reached 2.7 billion in 2020. It is now one of 
the most popular websites in the world.
Facebook’s business model is quite distinct from that of a traditional business, in 
that it does not manufacture or sell any products. Instead, it earns its revenue mainly 
from advertisements, and its business model is based on advertisement revenue, 
with advertisements targeted to its over 2 billion users based on their specific 
Fig 19.2  Mark 
Zuckerberg
19  The Smartphone and Social Media

261
interests. That is, Facebook is essentially selling its users to advertisers (i.e., the 
users are the product), where the users really do all the work, and Facebook collects 
data about them (e.g., age, gender, location, education, work history, and interests), 
and classifies and categories them, so that it may target advertisements that will 
potentially be of interest to them. This ensures that the advertisements are targeted 
to the right audience.
Social media have become important communication channels for young people 
to discuss their aspirations for the future, as well as their grievances with society and 
the state. The effectiveness of Facebook as a tool for protests and revolution is evi-
dent in the relatively short protests that culminated in the resignation of President 
Hosni Mubarak of Egypt in 2011.
Egypt has a young population with roughly 60% of the population under the age 
of 30, and the country has faced many challenges since independence such as 
improving education and literacy for its young population, as well as finding jobs 
for its citizens.
Facebook provided a platform for Egyptian youth to discuss issues such as 
unemployment, low wages, police brutality, and corruption. Young Egyptians set up 
groups on Facebook to discuss specific issues (e.g., a group that aimed to provide 
solidarity with striking workers was set up). Further momentum for revolution fol-
lowed the beating and killing of Khalid Mohammed Said, as photos of his disfigured 
body were posted over the Internet and went viral. An influential Facebook group 
called “We are All Khalid Said” was set up, and the killing provided a tangible focus 
for solidarity among young Egyptians.
Protests began and lasted for eighteen days and it led to hundreds of thousands 
of young Egyptians taking to the streets and gathering in Tahrir Square in Cairo. 
They demanded an end to police brutality as well as the end of the 30-year reign of 
President Hosni Mubarak. The authorities reacted swiftly in closing the Internet in 
Egypt, but this act of censorship failed to stop the demonstrations and protests. 
Social media played an important role in mobilizing protests, and in influencing the 
outcome of the revolution.
19.4  The Tweet
Twitter is a social communication tool that allows people to broadcast short 
messages. It is often described as the “SMS of the Internet,” and Twitter is an online 
social media and micro blogging site that allows its users to send and receive short 
character messages called “tweets.” The restriction of the message length was origi-
nally to 140 characters to allow Twitter to be used on non-smartphone mobile 
devices. However, Twitter increased the character limit to 280 characters in 2017 
although the average length of a tweet is 34 characters. Twitter has over 300 million 
active users, and it is one of the most visited websites in the world. Users may 
access Twitter through its website interface, a mobile device app or SMS.
19.4  The Tweet

262
Jack Dorsey (Fig.  19.3) and others founded the company in 2006. Dorsey 
introduced the idea of an individual using an SMS service to communicate with a 
small group while he was still an undergraduate student at New York University. 
The word “twitter” was the chosen name for this new service, and its definition as 
“a short burst of information” and “chirps from birds” was highly appropriate.
Twitter messages are often about friends telling one another about their day, what 
they are doing, where they are, whey they are thinking and doing, and Twitter has 
transformed the world of media, politics, and business. It is possible to include links 
to web pages and other media as a tweet. News such as natural disasters, sports 
results and so on are often reported first by Twitter. The site has impacted political 
communication in a major way, as it allows politicians and their followers to debate 
and exchange political opinions. It allows celebrities to engage and stay in contact 
with their fans, and it provides a new way for businesses to advertise its brands to its 
target audience.
A Twitter user may select which other people that they wish to follow, and when 
you follow someone their tweets show up in a list known as your Twitter stream. 
Similarly, anyone who chooses to follow you will see your tweets in their stream.
A hashtag is an easy way to find all the tweets about a topic of interest, and it 
may be used even if you are not following the people who are tweeting. It also 
allows you to contribute to the topic that is of interest, and a hashtag consists of a 
short word or acronym preceded by the hash sign (#). Conferences, hot topics, and 
so on often have a hashtag.
A word or topic that is tagged at a greater rate than other hashtags is said to be a 
trending topic, and a trending topic is often the result of an event that prompts 
people to discuss the topic. Trending may also result from the deliberate action of 
certain groups (e.g., in the entertainment industry) to raise the profile of a musician 
or celebrity and to market their work.
Twitter has evolved to become an effective way to communicate the latest news, 
and its effectiveness as a communication tool for an organization increases as the 
number of its followers grows. An organization may determine what people are 
Fig 19.3  Jack Dorsey at 
the 2012 Time 100 Gala
19  The Smartphone and Social Media

263
saying about it, as well as their positive or negative experience in interacting with it. 
This allows the organization to directly interact with its followers, which is a power-
ful way to engage with its audience and to make people feel heard. It allows the 
organization to respond to any negative feedback, and to deal with such feedback 
sensitively and appropriately.
The first version of Twitter was introduced in mid-2006, and it took the company 
some time to determine exactly what type of entity it was. There was nothing quite 
like it in existence, and initially it was considered a micro-blogging and social 
media site. Today, it is viewed as an information network rather than just a social 
media site.
Twitter has experienced rapid growth from 400,000 tweets posted per quarter in 
2007, to 100 million per quarter in 2008, to 65 million tweets per day from 2010, to 
140 million tweets per day in 2011 and to 500 million tweets per day in 2016. 
Twitter’s usage spikes during important events such as major sporting events, natu-
ral disasters, the death of a celebrity, and so on. For such events, there may be over 
100,000 tweets per second.
Twitter’s main source of revenue is advertisements through “promoted tweets” 
that appear in a user’s timeline (Twitter stream). The first promoted tweets appeared 
from late 2011, and the use of a tweet for advertisement was ingenious. It helped to 
make the advertisement feel like part of Twitter, and it meant that an advertisement 
could go anywhere that a tweet could go. Advertisers are only charged when the 
user follows the links or re-tweets the original advertisements. Further, the use of 
tweets for advertisement meant that the transition to mobile was easy, and today 
about 80% of Twitter use is on mobile devices.
Twitter has embarked on a strategy that goes beyond these advertisements to sell 
products directly (including to people who don’t use Twitter). Twitter also earns 
revenue from a data licensing arrangement where it sells its information to compa-
nies who use this information to analyze consumer trends. Twitter analyses what 
users tweet to understand their intent. For more detailed information on Twitter, see 
[Sch:14].
19.5  Social Media and Fake News
Fake news is the systematic spreading of misleading or false information in 
traditional print or online social media, with the intention of misleading or damaging 
another person or institution. It can negatively affect individuals in a country and 
lead to violence or hate against minority ethnic groups. The popularity of social 
media sites such as Facebook has contributed to the spread of fake news, and this 
new phenomenon poses threats to twenty-first-century democracy. Fake news may 
be spread by individuals, organizations, and hostile states, and it consists of news 
that has no basis in fact, but which is presented as being factually correct.
Fake news in the form of propaganda has been around for centuries, where such 
news is generally published for political reasons. Military leaders have often 
19.5  Social Media and Fake News

264
embellished their bravery and results in battle throughout history (e.g., Ramses II’s 
description of the Battle of Kadesh in the thirteenth century B.C. paints a very posi-
tive but factually inaccurate account of the battle).
Following the invention of the printing press in the fifteenth century, news 
publications became popular, and over time fake news stories appeared in the print 
media. Fake news played an important role in propaganda during the First and 
Second World Wars, with radio broadcasts and printed material used to persuade the 
public at home as well as discouraging enemy troops. Today, modern society is 
highly dependent on accurate information in the print, radio, television, and online 
media. The effectiveness of fake news increases when the stories spread widely (as 
often occurs in social media), and where users interact with and rely on these stories 
rather than on traditional news media.
Fake news played a role in the 2016 presidential election in the United States, 
which led to the election of Donald Trump. Most of the fake election news in the last 
3 months of the campaign was anti-Clinton, but it is difficult to determine the extent 
to which this influenced the outcome of the election. Trump and his supporters seem 
to use the word “fake news” to refer to the mainstream media that is opposed to him 
and his policies.
It is important when considering the accuracy of an article to consider the source 
of the news (e.g., is it written by a reputable news organization such as the BBC or 
Reuters), as well as considering the authenticity of its authors and the supporting 
sources. Fake news is a deeply disturbing Internet trend that needs to be resolved if 
technology is to serve humanity. Modern technology has provided many benefits to 
modern society, but it needs to be regulated and managed effectively.
Fake news is a dangerous trend in society, as false news can spread easily due to 
the speed and accessibility of modern technology. It allows individuals to be misled 
and negatively influenced. Online social media sites such as Facebook and Twitter 
have a responsibility to develop appropriate solutions to address this serious 
problem.
19.6  Review Questions
	1.	 What is a PDA?
	2.	 What is a smartphone?
	3.	 What is social media? Explain how sites such as Facebook and Twitter 
have transformed human communication.
	4.	 Explain how a company may use social media to market new products to 
its customers.
	5.	 Explain how social media has been used as a tool for protest and revolution.
	6.	 Why has Twitter been described as the SMS of the Internet?
	7.	 Explain how Social media has facilitated the spread of Fake news.
19  The Smartphone and Social Media

265
19.7  Summary
A smartphone is essentially touch-based computer on a phone, which comes with its 
own keyboard, operating system, Internet access, and third-party applications. It 
provides many other attractive features such as a camera, maps, calendar, alarm 
clock, and games. It arose from the marriage of mobile phone technology and PDA 
technology.
The smartphone has facilitated a major growth of social networking, as users are 
now able to communicate news or update their personal information in real time. 
Social media involves the use of computer technology that allows the creation and 
exchange of user-generated content. It has led to major changes in communication 
between individuals, communities, and organizations. Social networking sites such 
as Facebook and Twitter have transformed human communication.
Facebook helps users to keep in touch with friends and family, and it allows them 
to share their opinions on what is happening around the world. Users may upload 
photos and videos; express opinions and ideas; and exchange messages. Facebook 
has become an important communication channel, and it has also become an effec-
tive tool for mobilizing protests and social revolution.
Twitter has become an effective way to communicate the latest news, and its 
effectiveness as a communication tool increases as the number of its followers 
grows. It allows a person or organization to determine what people are saying about 
it, as well as their positive or negative experiences.
19.7  Summary

267
© The Author(s), under exclusive license to Springer Nature 
Switzerland AG 2021
G. O’Regan, A Brief History of Computing, 
https://doi.org/10.1007/978-3-030-66599-9_20
Chapter 20
A Miscellany of Innovation
20.1  Introduction
The process of translating a business idea or invention into a product or service that adds 
value and that people will pay for is termed innovation. A business idea is innovative if 
it is commercially viable at an economic cost that people will be willing to pay, and it 
must satisfy a specific customer need (as otherwise, there will be no demand for it).
There are two broad categories of innovations, namely evolutionary and revolu-
tionary innovations. An evolutionary innovation is generally brought about by 
incremental advances in technology, whereas a revolutionary innovation is often 
totally new and completely different from the existing products in the market place 
(e.g., the development of the Apple Macintosh or iPhone were paradigm shifts from 
the existing state of the art). There is generally greater risk with a revolutionary 
innovation, as it is creating an entirely new product or technology, and so it is essen-
tial that there will be a need and demand for the product (e.g., the introduction of the 
IBM System/360 discussed in Chap. 8 was a revolutionary innovation), whereas 
evolutionary innovations generally involve less risk.
The success of hi-tech companies relies on the creativity and innovation of its 
staff, and therefore, it is important to foster innovation in the workplace. An innova-
tive work environment generally has a low power distance between management 
and staff, with an emphasis on open communication and inter-department collabora-
tion. Brainstorming sessions to come up with innovative ideas or solutions to prob-
lems are encouraged, as well as the use of a suggestion box where employees can 
submit ideas or improvement suggestions as well as making them to their supervisor.
The software field is highly innovative and is continually evolving, and this has 
led to the development of many new technologies and systems. This includes 
Key Topics
Distributed system
Service-oriented architecture
Software as a service
Cloud computing
Aspect-oriented software engineering
Embedded systems
WIFI
Quantum computing
GPS

268
distributed systems; service-oriented architecture (SOA); software as a service 
(SaaS); cloud computing; embedded systems; quantum computing; GPS; WiFi; and 
many more.
A distributed system is a collection of computers that appears to be a single sys-
tem, and many large computer systems used today are distributed systems. A dis-
tributed system allows hardware and software resources to be shared, and it supports 
concurrency with multiple processors running on different computers on the 
network.
Service-oriented architecture (SOA) is a way of developing a distributed system 
consisting of stand-alone web services that may be executing on distributed com-
puters in different geographic regions. Software as a service (SaaS) allows software 
to be hosted remotely on a server (or servers), and the user can access the software 
over the Internet through a web browser. Cloud computing is a type of internet-­
based computing that provides computing resources and various other services 
on demand.
An embedded system is a computer system within a larger electrical or mechani-
cal system, and it is embedded as part of a complete system that includes hardware 
and mechanical parts. An embedded system is usually designed to do a specific task 
rather than as a general-purpose device, and it may be subject to real-time perfor-
mance constraints.
Quantum computing is totally different from classical computing, and it has the 
potential to enable problems to be solved substantially faster than with classical 
computer technology. The origins of quantum computing date back to the early 
1980s, when a quantum mechanical model of the Turing machine was proposed. 
There are several technical challenges in the construction of quantum computers.
Nanotechnology is the manipulation of matter at the atomic, molecular and 
supramolecular scale, with the size of matter ranging from 1 to 100 nanometers
20.2  Distributed Systems
A distributed system (Fig. 20.1) is a collection of computers, interconnected via a 
network, which is capable of collaborating on a task. It appears to be a single inte-
grated computing system to the user, and most large computer systems today are 
distributed systems. The components (or nodes) of a distributed system are located 
on networked computers, and interact to achieve a common goal.
The communication and coordination of action is via message passing. A distrib-
uted system is not centrally controlled, and as a result, the individual computers 
may behave differently at different times, and each computer has a limited and 
incomplete view of the system.
A distributed system allows hardware and software resources (e.g., printers and 
files) to be shared, and information may be shared between people and processes 
located in distant geographical regions. It supports concurrency with multiple pro-
cessors running on different computers on the network. The processors in a 
20  A Miscellany of Innovation

269
distributed system run concurrently in parallel, and each computer is running on its 
own local operating system.
A distributed system is designed to tolerate failures on individual computers, and 
the system is designed to be reliable and to continue service when a node fails. That 
is, a distributed system needs to be designed to be fault tolerant, and it must remain 
available if there are hardware, software, or network failures. This requires building 
in redundancy and recovery features (e.g., duplicating information on several com-
puters). The fault-tolerant design allows continuity of service (possibly a degraded 
service) when failures occur.
The design of distributed systems is more complex than a centralized system, as 
there may be complex interactions between its components and the system infra-
structure. The performance of the distributed system is dependent on the network 
bandwidth and load, as well on the speed of the computers that are on the network. 
This differs from a centralized system, which is dependent on the speed of a single 
processor. The performance and response time of a distributed system may vary 
(and be unpredictable), depending on the network load and network bandwidth, and 
so the response time may vary from user to user.
The nodes in a distributed system are often independent systems with no central 
control, and the network connecting the nodes is a complex system, which is not 
controlled by the systems using the network. There are many applications of distrib-
uted system in the telecommunication domain, such as fixed line, mobile and wire-
less networks, company intranets, the Internet and the World Wide Web. Next, we 
describe how service-oriented architecture is used in distributed systems.
Fig. 20.1  A distributed system
20.2  Distributed Systems

270
20.3  Service-Oriented Architecture
Service-oriented architecture (SOA) is a way of developing a distributed system 
using stand-alone web services executing on distributed computers in different geo-
graphic regions. It is an approach to creating an architecture based upon the use of 
services, where a service may carry out some small function such as producing data 
or validating a customer.
A web service is a computational or information resource that may be used by 
another program, and it allows a service provider to provide a service to an applica-
tion (service requestor) that wishes to use the service. The web service may be 
accessed remotely, and is acted upon independently. The service provider is respon-
sible for designing and implementing the service, and specifying the interface to the 
service.
The service is platform and implementation language independent, and it is 
designed and implemented by the service provider with the interface to the service 
specified. Information about the service is published in an accessible service regis-
try, and service clients (requestors) can locate the service provider and link their 
application with the specific service and communicate with it. The idea of a SOA is 
illustrated in Fig. 20.2.
There are several standards that support communication between services, as 
well as standards for service interface definition [Som:10].
20.4  Software as a Service
The idea of software as a service (SaaS) is that the software may be hosted remotely 
on a server (or servers), and access provided to it over the Internet through a web 
browser. The functionality is provided at the remote server with client access pro-
vided through the web browser.
Service
Registry
Service
Requestor
Service
Provider
service
find
publish
bind
Fig. 20.2  Service-oriented 
architecture
20  A Miscellany of Innovation

271
The cost model for traditional software is made up of an up-front cost for a per-
petual license and optional on-going support fees. SaaS is a software licensing and 
delivery model where the software is licensed to the user on a subscription basis. 
The software provider owns and provides the service, whereas the software organi-
zation that is using the service will pay a subscription for its use. Occasionally, the 
software is free to use with funding for the service provided through advertisements, 
or there may be a free basic service provided with charges applied for the more 
advanced version.
A key benefit of SaaS is that the cost of hosting and management of the service 
is transferred to the service provider, with the provider responsible for resolving 
defects and installing upgrades of the software. Consequently, the initial setup costs 
for users is significantly less than for traditional software.
The disadvantages to the user are that data must be transferred at the speed of the 
network, and the transfer of a large amount of data may take a lot of time. The sub-
scription charges may be monthly or annual, with extra charges possibly due 
depending on the amount of data transferred.
20.5  Cloud Computing
Cloud computing is a type of Internet-based computing that provides computing 
processing resources on demand. It provides access to a shared pool of configurable 
computing resources such as networks, servers, and applications on-demand, and 
such resources may be provided and released with minimal effort. It provides users 
and organizations with capabilities to store and process their data at third-party data 
centers that may be in distant geographical locations (Fig. 20.3).
A key advantage of cloud computing is that it allows companies to avoid large 
up-front infrastructure costs such as purchasing hardware and servers, and it allows 
organizations to focus on their core business. Further, it allows companies to get 
their applications operational in a shorter space of time, as well as providing an 
efficient way for companies to adjust resources to deal with fluctuating demand. 
Companies can scale up as computing needs increase and scale down as demand 
decreases. Cloud providers generally use a “pay as you go” model.
Among the well-known cloud computing platforms are Amazon’s Elastic 
Compute Cloud, Microsoft’s Azure, and Oracle’s cloud. The main enabling technol-
ogy for cloud computing is virtualization, which separates a physical computing 
device into one or more virtual devices. Each of the virtual devices may be easily 
used and managed to perform computing tasks, and this leads to the creation of a 
scalable system of multiple independent computing devices that allows the idle 
physical resources to be allocated and used more effectively.
Cloud computing providers offer their services according to different models. 
These include infrastructure as a service (IaaS) where computing infrastructure, 
such as virtual machines and other resources, is provided as a service to subscribers. 
Platform as a service (PaaS) provides capability to the consumer to provide a 
20.5  Cloud Computing

272
development platform (e.g., deploying relevant infrastructure and applications) to 
develop, manage, or run business applications. That is, the client is not required to 
build and maintain the infrastructure that the software development process would 
generally require as the service provider offers a cloud solution. PaaS vendors pro-
vides a development platform to application developers. Software as a service 
(SaaS) provides capability to the consumer to use the provider’s applications run-
ning on a cloud infrastructure through a web browser or a program interface. Cloud 
providers manage the infrastructure and platforms that run the applications.
20.6  Embedded Systems
An embedded system is a computer system within a larger electrical or mechanical 
system that is usually subject to real-time constraints. The computer system is 
embedded as part of a complete system that includes hardware and mechanical 
parts. Embedded systems vary from personal devices such as MP3 players and 
mobile phones, to household devices such as dishwashers and cookers, to the auto-
motive sector, and to traffic lights. An embedded system is usually designed to do a 
Fig. 20.3  Cloud computing. Creative Commons
20  A Miscellany of Innovation

273
specific task rather than acting as a general-purpose device, and it may be subject to 
real-time performance constraints (Fig. 20.4).
Some embedded systems are termed reactive systems, as they react to events that 
occur in their environment, and so their design is often based on a stimulus–response 
model. An event (or condition) that occurs in the system environment that causes 
the system to respond in some way is termed a stimulus, and the response is the 
signal sent by the software to its environment. For example, in the automotive sec-
tor, there are sensors in a car that detect when the temperature in the engine goes too 
high, and the response may be an audio alarm and visual warning to the driver.
One of the earliest embedded systems was the guidance computer developed for 
the Minuteman II missile in the mid-1960s (see Chap. 7). Embedded systems are 
ubiquitous today, and they control many devices that are in common use such as 
microwave ovens, washing machines, coffee makers, clocks, DVD players, mobile 
phones, and televisions.
Embedded systems became more popular following the introduction of the 
microprocessor in the early 1970s, and many microprocessors produced today are 
used as the components of embedded systems.
20.7  WiFi
WiFi is a popular short-range wireless broadband technology based on the IEEE 
802.11 standard, and it is the wireless equivalent of Ethernet. It uses 2.4–5 gigahertz 
(GHz) radio frequencies, and it can transfer data at rates of up to a maximum of 
600 Mbps (802.11n). The term “WiFi” is a trademark of the WiFi Alliance, and the 
name was coined by a brand consulting company (WiFi sounds a little like hi-fi). 
The technology is used for most home networks, business local area networks, and 
pubic hotspot networks (Fig. 20.5).
WiFi technology allows local area networks (LANs) to operate without cable or 
physical connections, and it eliminates the need for complex cabling and network 
Fig. 20.4  Example of an 
embedded system
20.7  WiFi

274
switches and connectors. It may be used to connect computers and WiFi compatible 
devices to each other, to the Internet, and to the wired network. WiFi-enabled 
devices can connect to the Internet when they are near areas that have WiFi access 
called “hotspots.”
WiFi grew out of a technology called WaveLAN designed by AT&T and NCR 
for wireless cash registers in the late 1980s, and the technology was developed fur-
ther in the 1990s. It was published as the 802.11 standard in 1997, and it initially 
provided 2 Mb/s link speeds. The standard evolved over time (e.g., 802.11 g with 
link speeds of 54 Mb/s) to provide increased performance and features. WiFi began 
to take off from the early 2000s, especially with high-speed broadband in the home, 
as it provided an easy way for several computers to share the same broadband link.
A WiFi compatible device (e.g., personal computer, tablet, smartphone and 
printer) can connect to and communicate to a wireless access point within range. 
The access point (AP) is a wireless LAN transceiver or base station that can connect 
one or more wireless devices simultaneously. Home computer networks often use a 
wireless broadband router as a WiFi access point, whereas public hotspots often use 
one or more access points inside the coverage area.
A WiFi hotspot is a physical location where a person may obtain Internet access 
via WiFi technology, and the wireless local area network (WLAN) is connected to 
an Internet Service Provider via a router. It is a place to bring a laptop or other 
Fig. 20.5  WiFi range diagram. Public domain
20  A Miscellany of Innovation

275
mobile device to connect to the Internet, and these include libraries, coffee shops, 
and schools. Many towns and cities have implemented free WiFi networks, and 
there are several million hotspots in use around the world. Most are free to users, but 
some operate on a pay-per-service model or on a subscription basis. Many hotspot 
access points use software for managing user subscriptions and limiting 
Internet access.
Electronic devices may easily determine if there are wireless networks in range, 
and the user may then initiate a connection to the hotspot’s wireless network. Small 
WiFi radios and antennas are embedded inside electronic devices allowing them to 
function as network clients, and the access points are configured with network 
names that the user can identify. The range of a WiFi network varies depending on 
obstructions that the radio signals encounter between network endpoints. A range of 
30 m indoors is typical (and up to 95 m outdoors), but if there are significant obstruc-
tions in the radio signal’s path, then the range could be much smaller. It is possible 
to improve the range with specialized antennae.
WiFi networks are more vulnerable to eavesdropping attacks than wired net-
works such as Ethernet, but security technology has been developed to help to 
address this (e.g., the WiFi Protected Access (WPA2) encryption).
Many broadband networks are beginning to offer unlimited mobile data plans, 
and so many consumers may no longer need to sign into a WiFi network to avoid 
expensive network charges. However, if the user is on holiday in another country, 
there is a possibility of roaming charges being applied by the network operator, and 
WiFi will remain important in these situations. WiFi is likely to continue to be 
important in homes and office buildings.
20.7.1  WiFi Security
WiFi hotspots are widely used around the world, with hotels, airports and cafes 
offering free WiFi to their customers. This provides convenience to travelers, but 
there are dangers associated with WiFi including risks of hostile attack and informa-
tion being stolen or compromised. It is therefore important to understand how these 
attacks work so that the associated risks may be managed, and to ensure that data 
are kept secure and that sensitive information is protected.
Once a user connects to a public WiFi network, information is sent out into the 
world, and there are several ways in which this information may be compromised. 
These may include sniffing attacks, rogue access points, and evil twin attacks 
(Table 20.1).
20.7  WiFi

276
20.8  Quantum Computing
Quantum computing is totally different from classical computing, and it has the 
potential to enable problems to be solved substantially faster than with classical 
computer technology. Anything that may be computed by a classical computer may 
be computed by a quantum computer and vice versa. That is, quantum computing 
has no additional advantages over classical computers in terms of computability. 
However, quantum computers have quantum supremacy in that they are believed to 
be capable of solving certain problems quickly that a classical computer is unable 
to solve in a feasible amount of time.
The origins of quantum computing date back to the early 1980s, with a quantum 
mechanical model of the Turing machine proposed by Paul Benioff. His work on 
quantum information theory and the quantum mechanical model demonstrated the 
theoretical possibility of quantum computers. Richard Feynman and Yuri Manin 
later suggested that a quantum computer had the potential to simulate things that a 
classical computer is unable to.
There are several models of quantum computing including the quantum circuit 
model, the quantum Turing Machine (QTM) as well as others. Quantum circuits are 
based on the quantum bit (“qubit”), which is somewhat comparable to the standard 
bit in classical computing. Qubits may be in a 1 or 0 quantum state or a superposi-
tion of the 1 or 0 states, and computation is performed by manipulating qubits with 
quantum logic gates (that are somewhat comparable to classical logic gates). Digital 
quantum computers use quantum logic gates to do computation.
The security of public key cryptographic systems on classical computers is due 
to the infeasibility of the integer factorization problem for large integers, where the 
large integer is the product of two 300-digit prime numbers. However, this problem 
may be solved efficiently on a quantum computer using Shor’s algorithm, which is 
a polynomial time quantum computer algorithm for integer factorization.
Table 20.1  Methods for intercepting data
Method
Description
Sniffing
A sniffing attack does not require sophisticated technical expertise, as a sniffing 
device examines information passed over the network and captures information such 
as passwords. Encryption helps to eliminate these attacks but some older protocols 
(e.g., WEP) are easy to crack and provide limited protection against hostile attack.
Rogue 
access 
points
This is a simple form of the “man-in-the-middle” attack where the problem is that 
you cannot be sure of what you are directly connecting to with a public hotspot. The 
attacker’s laptop is configured to act as an access point (with an innocent name), and 
everything looks fine to the victim with access provided to the Internet.  However, 
the attacker captures all information, with unencrypted information immediately 
compromised, and encrypted information may be decoded (depending on the 
complexity of the encryption method employed).
Evil twin 
attacks
This is a variant of the rogue access point where the attacker sets up an identical 
network name to an existing public hotspot, and tricks the victim’s device into 
connecting to the evil twin rather than the legitimate hotspot.
20  A Miscellany of Innovation

277
There are several technical challenges in the construction of quantum computers, 
especially in controlling and removing quantum decoherence, and sourcing parts is 
quite difficult. For more information on quantum computing, see [Ber:19].
20.9  GPS Technology
The Global positioning system (GPS) is a global network of satellites that orbit the 
earth (Fig. 20.6). It is owned by the US government and operated by the US Air 
Force, and it is used for civilian, commercial, and military purposes. It provides 
real-world geographic information including location (three-dimensional position), 
timing, velocity, and navigation information to users who are equipped with a GPS 
receiver (e.g., a mobile phone).
It may be used anywhere in the world irrespective of weather conditions, where 
there is an unobstructed line of sight of at least four GPS satellites. This free and 
dependable service operates independently of Internet or telephone reception, and 
the user is not required to transmit any data.
GPS consists of three segments, namely. the space segment, the control segment, 
and the user segment. The space segment consists of a constellation of satellites 
orbiting in 6 planes and transmitting radio signals to users. The GPS satellites fly in 
a medium earth orbit (MEO) at an altitude slightly over 20,000 km, and each satel-
lite circles the earth twice a day.
The GPS control segment consists of a global network of ground facilities that 
track the GPS satellites, monitors their transmissions, and performs appropriate 
analysis and management of the constellation. It includes a master control station, 
an alternate master control station, command and control antennae, and monitor-
ing sites.
Fig 20.6  GPS satellite 
system (24 satellites). 
Creative Commons
20.9  GPS Technology

278
The GPS user segment consists of the GPS receiver equipment, which uses the 
signals and transmitted information from the GPS satellites to determine the user’s 
3-dimensional position and time. These devices contain small computers that mea-
sure the time that it takes for the radio signal to travel from a GPS satellite until it 
arrives at the GPS antenna. The GPS receiver software calculates its position 
through a process of triangulation (Fig. 20.7).
The importance of being able to locate one’s position on the surface of the earth 
has been recognized for hundreds of years, and early navigation systems used celes-
tial observation, spherical trigonometry, and hand computation. Electronic naviga-
tion commenced in the 1940s with fixed land-based radio transmitters.
The first satellite navigation system (the TRANSIT system) was successfully 
tested in the United States in 1960, and it used a constellation of five satellites that 
could provide a navigation fix roughly once per hour. The GPS project commenced 
in the late-1970s, and it was designed to overcome the limitations of earlier naviga-
tion systems.
The GPS system was developed for the US Department of Defense, and its 
inventors are Roger Easton of the Naval Research Laboratory, Ivan Getting of The 
Aerospace Corporation, and Bradford Parkinson of the Applied Physical Laboratory. 
It used a constellation of 24 satellites with four satellites in each of six orbits. The 
GPS system became operational in 1995, and the orbits are evenly spaced every 60o 
GPS Receiver
Distance
Distance
Distance
Distance
1.
Each satellite broadcasts 
location, time and status
2. GPS radio signal is at speed
of light
3. GPS receiver calculates 
distance to each visible satellite
4. GPS receiver calculates exact 
location from 4 satellites
Fig 20.7  GPS in operation
20  A Miscellany of Innovation

279
around the earth, and at an altitude of 20,200 km. Several of the satellites are visible 
from any point on the surface of the Earth at any given time.
There are also several other satellite navigation systems under development or in 
use. These include the Russian Global Navigation Satellite System (GLONASS), 
the Chinese BeiDou Navigation Satellite System (BDS), and the European Galileo 
Global Navigation Satellite System (GNSS). Galileo was designed purely for civil-
ian use and it became fully operational in 2019. The complete Galileo system 
includes 30 satellites (24 operational and 6 spares). It is accurate to within 1 m.
The typical handheld GPS receivers are accurate to about 5 m, and there are more 
sophisticated GPS receivers that provide position accuracy to within a centimeter. 
The world (including the military and citizens) has become very dependent on GPS, 
and there is a need to manage the threat of the complete system being rendered 
inoperable due to hostile or natural events. This is leading to research into alterna-
tive backup systems that can still provide the accuracy of GPS to manage this risk.
20.9.1  Applications of GPS
GPS was originally developed for US military use during the cold war, with devel-
opment commencing in the late 1970s. It was released for civilian and commercial 
use from the late 1990s. The free and dependable nature of GPS has led to the devel-
opment of many applications of the technology from mobile phones, to wrist-
watches, to the transport sector including vehicles and aviation, to outdoor pursuits, 
and to surveying and mapping.
A GPS receiver allows the user to accurately pinpoint their position and velocity 
in vehicles, aircraft, and ships. Drivers can use in-vehicle navigation systems to fol-
low a route and to avoid traffic problems. GPS can be used by hikers to check that 
they are following their chosen route, and GPS is invaluable to the emergency ser-
vices in enabling them to find their way to an incident faster, as well as pinpointing 
the location of accidents for the search and rescue teams. GPS also supports the 
creation of accurate maps. Table 20.2 lists a small number of applications of GPS.
There are many texts available (e.g., see [MEn:10]) that provide more detailed 
information on GPS.
20.10  Wikipedia
The idea of compiling the world’s knowledge into a single location dates back to the 
ancient library of Alexandria. Ptolemy I, who was a Macedonian general, founded 
this famous library in the third century BC. He became the ruler of the Egyptian part 
of Alexander the Great’s empire after Alexander’s death in 323  BC, and the 
Ptolemaic dynasty ruled Egypt up to the death of Cleopatra in 30 BC. The library in 
Alexandria was one of the largest and most important of the ancient world, with 
20.10  Wikipedia

280
most of the books in the library kept as papyrus scrolls. The estimates of the number 
of books in the collection vary between 40,000 and 400,000 scrolls.
An encyclopedia is a compendium of knowledge, and it consists of an extensive 
summary of many branches of knowledge. It consists of articles organized alpha-
betically by article name, and a concise description is provided for each article. The 
earliest encyclopedia (Naturalis Historia) dates to the Roman period, and it was 
written (in Latin) by Pliny the Elder circa 79 AD. Archbishop Isidore of Seville 
wrote an encyclopedia (the Etymologiae) in the middle ages (c. seventh century 
AD), and this was a compilation of the known learning in the world. Johannes 
Gutenberg invented the printing press in the fifteenth century during the Renaissance 
period, and it meant that books no longer needed to be copied by hand (a slow and 
expensive process). Books could now be mass-produced leading to wider circula-
tion and reading of encyclopedias.
Modern encyclopedias evolved out of dictionaries from the eighteenth century, 
with Diderot’s Encyclopédie published in 1751, and the Encyclopedia Britannia 
first published in 1771. These provided a comprehensive set of topics that were 
discussed in depth, and the 2010-printed version of the Encyclopedia Britannia con-
tained 32 volumes and 32,000 pages. The twentieth century saw the appearance of 
the Children’s Encyclopedia and specialized encyclopedias in specific fields.
Wikipedia is a free open-source Internet encyclopedia that anyone can edit, and 
Jimmy Wales and Larry Sanger founded this multilingual collaborative encyclope-
dia in 2001. It is written and edited by a worldwide community of unpaid volun-
teers, and there is no central organization controlling the editing. This contrasts with 
Table 20.2  Applications of GPS
Area
Description
Military
GPS was originally developed for the US military, but it has since been 
adopted by the armed forces of several countries around the world. It is 
used to map the location of vehicles and other assets on battlefields in 
real time. GPS is also fitted to missiles for tracking and guidance.
Road transport
GPS is used for commercial fleet management and taxi services. The 
emergency services and private motorists use in-car navigation systems, 
and GPS plays a key role in the navigation of driverless cars.
Aviation
Almost all modern aircrafts are equipped with several GPS receivers that 
provide real-time aircraft position and a map of flight progress. 
Unmanned aerial vehicles also use it for navigation.
Maritime
High accuracy GPS receivers allows the captain to navigate safely 
through unfamiliar channels or waterways.
Surveying and 
mapping
Surveyors are responsible for accurate mapping and measuring features 
of the Earth’s surface (e.g., land boundaries, mapping sea floor). Accurate 
GPS receivers make this easier and the data can be transferred into 
mapping software to create quick and detailed maps.
Telecommunications
GPS provides the facility for the synchronization of coordinated 
universal time (UTC).
Social
GPS is used for various social activities such as hiking, sailing, and 
geotagging photographs.
20  A Miscellany of Innovation

281
other encyclopedias such as Encyclopedia Britannica. Wikipedia is a useful educa-
tional resource where a user can go to learn about a topic (Fig. 20.8).
It is owned by the non-profit Wikimedia foundation, and there are over 200 
Wikipedia encyclopedias in various languages. The English Wikipedia is the largest 
of these with over 5 million articles, and there is a total of 40 million articles in vari-
ous languages. Wikipedia is in the top 10 of the most popular websites, and the 
Wikipedia foundation handles the servers and legal issues.
Wikipedia grew out of the Nupedia project, which was a free on-line encyclope-
dia with articles written by experts and subject to a strict formal review process 
prior to publication. The Nupedia articles were written by highly qualified volun-
teers who were experts in their field, and the authors usually had a PhD in their 
discipline. The articles were subjected to a rigorous peer review to ensure their 
quality.
However, despite its full-time editor-in-chief (Larry Sanger) and a mailing list of 
editors, the production of content for Nupedia was extremely slow. There were 
about twelve articles published the first year, and approximately 150 articles were 
still in draft format. This meant that Nupedia was useless as an encyclopedia, and it 
was clear that there was a need for a radically new approach so that content could 
be created much faster.
Wikipedia was initially intended to complement Nupedia by providing addi-
tional draft articles and ideas for it, and the goal was to create content faster for 
Nupedia rather than creating a separate online encyclopedia. It was developed as a 
wiki-style web site, and the project was given the name Wikipedia (which came 
from wiki and encyclopedia), and it was launched on its own domain “wikipe-
dia.com.”
The wiki took off and Wikipedia quickly overtook Nupedia and became a global 
project. It generated Web content in a similar way to GNU and the free open-source 
software movement, with content created and maintained by a worldwide commu-
nity of volunteers. The site is not elitist, and anyone may edit a page and the results 
Fig 20.8  Wikipedia logo. 
Creative Commons
20.10  Wikipedia

282
show up instantly. This may lead to inaccurate content, and if a bad edit appears, 
then the community of volunteers may get rid of it by clicking on a revert link.
Wikipedia articles aim to maintain a neutral point of view on controversial top-
ics. However, consensus can be quite difficult to achieve on sensitive topics, as it 
may be a challenge to find common ground.
Wikipedia has led to the demise of the printed versions of commercial encyclo-
pedias, as these are unable to compete with a product that is essentially free. 
Traditional printed encyclopedias (e.g., Encyclopedia Britannia) are now historical 
and are available on line only, with Wikipedia being the largest web-based encyclo-
pedia in the world. Wikipedia is owned by the nonprofit organization called the 
Wikimedia Foundation, and it is funded by donations from its users. The funds are 
used to pay for the technology to run the organization and to cover the salaries of 
its staff.
Academics, historians, and journalists have criticized Wikipedia as being an 
unreliable source of information. They argue that its content is a mixture of truth, 
half-truths, and incorrect information, and that it is especially unreliable when deal-
ing with controversial topics. However, Wikipedia is often a good starting point to 
learn about a topic, and the accuracy of its articles is constantly improving, as its 
worldwide community includes experts in many fields. Jimmy Wales’ inspiring 
mission for Wikipedia is:
Imagine a world in which every single person on the planet is given free access to the sum 
of all human knowledge. That’s what we’re doing.
20.10.1  Wikipedia Quality Controls
Wikipedia has processes and structures in place to control the editing of articles (as 
part of its editorial control), and it uses several approaches to ensure that its content 
is as accurate and unbiased as possible.
There are thousands of regular editors who vary in knowledge from experts in 
their field to more casual readers. Anyone who is not a blocked user may visit 
Wikipedia and edit an article on the site. There are mechanisms for the Wikipedia 
community to spot poor edits, and a few hundred administrators have the authority 
to enforce good behavior. There is an arbitration committee that considers situations 
that remain unresolved, and this committee has the authority to impose sanctions 
(including a restriction of editing privileges).
The Wikipedia community is largely self-organizing, and while poor information 
may be added to the site, over time, other editors will amend the article until con-
sensus is reached. That is, the approach is in a way like group learning, which leads 
to quality improvement of the article through successive edits.
Anyone may build a reputation as a competent editor over time, and they may 
choose to become involved in more specialized roles such as reviewing articles at 
20  A Miscellany of Innovation

283
the request of others, or watching newly created articles or existing articles for 
accuracy.
There are software controls that make it easy for editors to check for acts of van-
dalism (malicious edits), and to monitor recent changes, and to check activity in 
articles in personal watchlists. Automated software controls (e.g., the program 
VandalProof) allow bad edits to be removed at the click of a button, and allows 
problematic editors to be blocked. These software controls generally allow vandal-
ism to be identified and corrected within minutes.
Wikipedia also has systems in place for article review and improvement, includ-
ing quality-based peer reviews where editors are invited to comment on an article 
that they were not involved in writing. The review will consider the readability, 
quality, and balance of the article, as well as its compliance with Wikipedia policies.
20.11  Nanotechnology
Nanotechnology is the manipulation of matter at the atomic, molecular, and supra-
molecular scale, and it involves the manipulation of matter sized from 1 to 100 nano-
meters (1 nanometer = 1 nm = 1 × 10−9 m). The concepts that led to nanotechnology 
were first discussed by Richard Feynman in the late 1950s, and the term “nanotech-
nology” was coined and popularized by Eric Dresler in his book, Engines of Creation 
[Dre:86]1. Drexler co-founded “The Foresight Institute” to increase public aware-
ness and understanding of the concepts and implication of nanotechnology. 
Nanotechnology emerged as a field in the 1980s.
Nanotechnology is a broad field with applications in surface science, semicon-
ductor physics, energy storage, engineering, and many more. It involves the engi-
neering of functional systems at the molecular scale using a bottom-up or top-down 
approach. For the former, materials and devices are built from molecular compo-
nents that assemble themselves chemically, whereas with the top-down approach 
nano-objects are created from larger entities without atomic-level control.
1 The term had been used by Norio Taniguchi independently of Drexler in 1974.
20.11  Nanotechnology

284
20.12  Review Questions
20.13  Summary
The success of a business depends on the creativity and innovation of its staff, and 
it is important to foster innovation in the workplace. This chapter gave a short intro-
duction to several innovations in computing field including distributed systems, 
service-oriented architecture, software as a service, cloud computing, embedded 
systems, GPS, WiFi, and quantum computing.
A distributed system is a collection of interconnected computers that appears to 
be a single system. Service-oriented architecture is a way of developing a distrib-
uted system consisting of stand-alone web service executing on distributed comput-
ers in different geographic regions. Software as a service allows software to be 
hosted remotely on a server (or servers), and access is provided to it over the Internet 
through a web browser. Cloud computing is a type of internet-based computing that 
provides computing resources and various other services on demand.
An embedded system is a computer system within a larger electrical or mechani-
cal system, and it is usually designed to do a specific task rather than as a general-­
purpose device, and it may be subject to real-time performance constraints. For a 
more detailed account on innovations in the computing field, see [ORg:18b].
	1.	 What is a distributed system?
	2.	 What is service-oriented architecture?
	3.	 What is software as a service?
	4.	 What is cloud computing?
	5.	 What is embedded software engineering?
	6.	 Explain WiFi and GPS.
	7.	 Discuss the potential of quantum computing.
20  A Miscellany of Innovation

285
© The Author(s), under exclusive license to Springer Nature 
Switzerland AG 2021
G. O’Regan, A Brief History of Computing, 
https://doi.org/10.1007/978-3-030-66599-9_21
Chapter 21
History of Databases
21.1  Introduction
A database (DB) is essentially an organized collection of data, and consists of sche-
mas, tables, queries, reports, and views. It is organized in such a way that a computer 
program (termed the database management system) may easily select and analyze 
the desired pieces of data. A database holds information about many different types 
of entities, as well as information about the relationships between the entities.
A database management system (DBMS) is a collection of software programs 
that allows a user to store, modify, and extract data from a database. The interaction 
between the users and the database is through the DBMS, and it enables the 
definition, creation, query, update and administration of databases. Historically, 
there are three main categories of database management systems, and these are 
hierarchical, network, and relational models. These differ in how the DBMS 
organizes data internally, and this determines the speed and efficiency of data 
retrieval from the database.
A network model database is perceived by the user to be a collection of records, 
and relationships between the records are organized as a network. The network 
model defines the relationships explicitly as part of the structure of the network. A 
hierarchical model is perceived by a user to be a collection of hierarchies or trees, 
and it is a more restricted structure than the network model as only one arrow may 
enter each box on the network. A relational model is perceived by the user to be a 
collection of tables (or relations), and it has been the most popular category of 
databases since the 1980s.
Early work on database management systems began in the 1960s as part of the 
Apollo mission to land man on the moon. It was clear that the existing systems were 
not capable of handling the coordination of the vast amounts of data required for the 
Key Topics
Hierarchical model
Network model
Relational model
Key
Index
SQL
Oracle database

286
project. IBM developed the Generalized Update Access Method (GUAM) product 
in 1964, and this product evolved into Data Language/1 (DL/1). DL/1 is the data 
management component of the Information Management System (IMS) database, 
which was one of the earliest database management systems when it was introduced 
in 1968. IMS used the hierarchical model.
The CODASYL committee1 set up a database task group and devised a standard, 
which became known as the “CODASYL approach.” This became the network 
standard and it was defined in the late 1960s. The standard was introduced in 1971.
Codd proposed the Relational Model, a radically new approach to the manage-
ment of data in 1970, and IBM developed the prototype system called System R in 
the 1970s. Commercial relational database systems were introduced from the early 
1980s, and today, relational databases are much more widely used than network or 
hierarchical databases. Among the popular relational databases used today are 
Oracle, Microsoft SQL Server and Informix.
21.2  Hierarchical and Network Models
A database management system uses the network model if the data relationships are 
defined in terms of a graph. The relationships are defined in terms of records (a 
record is a collection of fields, with each field containing one value), which are 
connected together via links. Any given record may have several parent records and 
several dependent records. Cycles are permitted in the model. Charles Bachman and 
others on the CODASYL Committee defined the network model in the late 1960s, 
and General Electric’s Integrated Data Store (IDS) and the Integrated Database 
Management System (IDMS) were based on the model. These mainframe databases 
were introduced in the early 1970s.
For a possible network view of suppliers and parts, the data would be presented 
in a simple graph-like structure (Fig. 21.1), which allows many-to-many relationships 
to be expressed. For more detailed information, see [Dat:81].
A database management system uses the hierarchical model if the data relation-
ships are defined in terms of hierarchies (i.e., in a tree-like structure). The relation-
ships are simple but inflexible (as they are one to many). The data are defined as 
records, which are connected to each other through links. Each child record may 
have only one parent, whereas each parent record may have several children records. 
The whole tree (starting from the root) needs to be traversed in order to retrieve data 
from a hierarchical database. Another words, the hierarchical model is a more 
restricted version of the network model, where no box can have more than one 
arrow entering the box although several arrows can leave a box.
1 The CODASYL committee is the group that defined and standardised the COBOL programming 
language. It was also involved in work in standardising database interfaces.
21  History of Databases

287
For a possible hierarchical view of suppliers and parts, the data would be pre-
sented in a simple tree-like structure (Fig. 21.2). Each tree consists of one part 
record together with a set of supplier record occurrences, one for each supplier of 
the part. For more detailed information, see [Dat:81].
The database access and manipulation component of the hierarchical model is 
termed Data Language/1, and it includes a data definition language and a data 
manipulation language. The IBM Information Management System (IMS) is one of 
the most widely used hierarchical databases, and it was created in the late 1960s.
21.3  The Relational Model
A Relational Database Management System (RDBMS) is a system that manages 
data using the relational model, and examples include RDMS developed at MIT in 
the early 1970s; Ingres developed at the University of California, Berkeley in the 
mid-1970s; System R developed at IBM in the mid-1970s; Oracle developed in the 
late 1970s; DB2 (IBM’s first commercial relational database management system) 
was released in 1982; the Informix relational DBMS was created by Roger Sippl 
(the founder of Informix Corporation) in 1980, and Informix later became part of 
IBM; Microsoft SQL Server was initially created by Microsoft and Sybase in 1988, 
with Microsoft taking sole responsibility for its development from the mid-1990s; 
and Microsoft Access is part of Microsoft Office and was introduced in the 
early 1990s.
A relation is defined as a set of tuples, and is usually represented by a table. A 
table is data organized in rows and columns, with the data in each column of the 
table of the same data type. Constraints may be employed to provide restrictions on 
London
12
Red
Nut
P1
London
12
Red
Nut
P1
London
20
Smith
S1
London
20
Smith
S1
Paris
10
Jones
S2
Paris
10
Jones
S2
300
Paris
17
Green
Bolt
P2
Paris
17
Green
Bolt
P2
300
400
Fig. 21.1  Simple part/supplier–network model
P1
Nut
Red
12
London
S1
Smith
20
London
300
S2
Jones
10
Paris
300
Fig. 21.2  Simple part/
supplier–
hierarchical model
21.3  The Relational Model

288
the kinds of data that may be stored in the relations. These are the conditions to be 
satisfied for data integrity, and are a way of implementing business rules in the 
database.
Relations have one or more keys associated with them, and the key uniquely 
identifies the row of the table. An index is a way of providing fast access to the data 
in a relational database, as it allows the tuple in a relation to be looked up directly 
(using the index) rather than checking all of the tuples in the relation.
The Structured Query Language (SQL) is a computer language that tells the 
relational database what to retrieve and how to display it. A stored procedure is 
executable code that is associated with the database, and it is used to perform 
common operations on the database.
The concept of a relational database was first described in a paper “A Relational 
Model of Data for Large Shared Data Banks” by Codd [Cod:70]. A relational 
database is a database that conforms to the relational model, and it may be defined 
as a set of relations (or tables). Codd was a British mathematician, computer 
scientist, and IBM researcher, who initially worked on the SSEC (Selective 
Sequence Electronic Computer) project in New York, and then on the IBM 701 and 
702 computers. He later worked on the IBM 7030 STRETCH computer (IBM’s first 
transistorized computer). He was the creator of STEM (statistical database expert 
manager).
He developed the relational data base model in the late 1960s, and he published 
an internal IBM paper on the Relational Model in 1969. This is the standard way 
that information is organized and retrieved from computers, and relational databases 
are at the heart of systems from hospitals’ patient records to airline flight and 
schedule information (Fig. 21.3).
Fig. 21.3  Edgar Codd
21  History of Databases

289
IBM was promoting its IMS hierarchical database in the 1970s, and it showed 
little interest or enthusiasm for Codd’s new relational database model. It made busi-
ness sense for IBM to preserve revenue for the IMS/DB model, rather than embark-
ing on a new technology. However, IBM agreed to implement Codd’s ideas on the 
relational model for the System R research project in the 1970s, and this project 
demonstrated the power of the model, as well as demonstrating good transaction 
processing performance. The project introduced a data query language that was 
initially called SEQUEL (later renamed to SQL), and this language was designed to 
retrieve and manipulate data in the IBM database.
Codd continued to develop and extend his relational model, and several theorems 
are named after him. In later years, he proposed a three-valued logic to deal with 
missing or undefined information, and even proposed a four-valued logic in the 
1990s. These proposals were never implemented and were controversial at the time. 
The relational model became popular from the early 1980s, and Codd received the 
ACM Turing Award in 1981 for his development of the relational database model.
A binary relation R(A, B) where A and B are sets is a subset of the Cartesian 
product (A × B) of A and B. The domain of the relation is A, and the co-domain of 
the relation is B. The notation aRb signifies that there is a relation between a and b 
and that (a, b) ∈R. An n-ary relation R (A1, A2, … An) is a subset of the Cartesian 
product of the n sets: that is, a subset of (A1 × A2 × … × An). However, an n-ary 
relation may also be regarded as a binary relation R(A, B) with A = A1 × A2 × … × An−1 
and B = An.
The data in the relational model are represented as a mathematical n-ary relation. 
In other words, a relation is defined as a set of n-tuples, and a table is a visual 
representation of the relation, and the data are organized in rows and columns. The 
data stored in each column of the table are of the same data type.
The basic relational building block is the domain or data type (often called just 
type). Each row of the table represents one n-tuple (one tuple) of the relation, and 
the number of tuples in the relation is the cardinality of the relation. Consider the 
PART relation taken from [Dat:81], where this relation consists of a heading and the 
body. There are five data types representing part numbers, part names, part colors, 
part weights, and locations in which the parts are stored. The body consists of a set 
of n-tuples. The cardinality of the PART relation is six (Fig. 21.4).
Strictly speaking, there is no ordering defined among the tuples of a relation, 
since a relation is a set, and sets are not ordered. However, in practice, relations are 
often considered to have an ordering.
There is a distinction between a domain and the columns (or attributes) that are 
drawn from that domain. An attribute represents the use of a domain within a 
relation, and the distinction is often emphasized by giving attributes names that are 
distinct from the underlying domain. The difference between domains and attributes 
can be seen in the PART relation (Fig. 21.5) from [Dat:81].
A normalized relation satisfies the property that at every row and column posi-
tion in the table there is exactly one value (i.e., never a set of values). All relations 
in a relational database are required to satisfy this condition, and an un-normalized 
relation may be converted into an equivalent normalized form.
21.3  The Relational Model

290
It is often the case that within a given relation that there is one attribute with 
values that is unique within the relation, and can thus be used to identify the tuples 
of the relation. For example, the attribute P# of the PART relation has this property 
since each PART tuple contains a distinct P# value, which may be used to distinguish 
that tuple from all other tuples in the relation. P# is termed the primary key for the 
PART relation. A candidate key that is not the primary key is termed the alternate key.
An index is a way of providing quicker access to the data in a relational database, 
as it allows the tuple in a relation to be looked up directly (using the index) rather 
than checking all of the tuples in the relation.
The consistency of a relational database is enforced by a set of constraints that 
provide restrictions on the kinds of data that may be stored in the relations. The 
constraints are declared as part of the logical schema and are enforced by the 
database management system. They are used to implement the business rules for the 
database.
P#
PName
Colour
Weight
City
P1
P2
P3
P4
P5
P6
Nut
Bolt
Screw
Screw
Cam
Cog
Red
Green
Blue
Red
Blue
Red
12
17
17
14
12
19
London
Paris
Rome
London
Paris
London
Fig. 21.4  PART relation
DOMAIN
PART_NUMBER
CHARACTER(6)
DOMAIN
PART_NAME 
CHARACTER(20)
DOMAIN
COLOUR 
CHARACTER(6)
DOMAIN
WEIGHT 
NUMERIC(4)
DOMAIN
LOCATION 
CHARACTER(15)
RELATION PART
(P#
: DOMAIN  PART_NUMBER
PNAME
: DOMAIN  PART_NAME
COLOUR
: DOMAIN  COLOUR
WEIGHT
: DOMAIN  WEIGHT
CITY
:  DOMAIN  LOCATION)
Fig. 21.5  Domains vs. attributes
21  History of Databases

291
21.4  Structured Query Language (SQL)
Codd proposed the Alpha language as the database language for his relational 
model. However, IBM’s implementation of his relational model in the System-R 
project introduced a data query language that was initially called SEQUEL (later 
renamed to SQL). This language did not adhere to Codd’s relational model but 
became the most popular and widely used database language. It was designed to 
retrieve and manipulate data in the IBM database, and its operations included insert, 
delete, update, query, schema creation and modification, and data access control.
Structured Query Language (SQL) is a computer language that tells the rela-
tional database what to retrieve and how to display it. It was designed and developed 
at IBM by Donald Chamberlin and Raymond Boyce, and it became an ISO standard 
in 1987.
The most common operation in SQL is the query command, which is performed 
with the SELECT statement. The SELECT statement retrieves data from one or 
more tables, and the query specifies one or more columns to be included in the 
result. Consider the example of a query that returns a list of expensive books (defined 
as books that cost more than 100.00).
SELECT *2
FROM Book
WHERE Price > 100.00
ORDER by title;
The Data Manipulation Language (DML) is the subset of SQL used to add, 
update and delete data. It includes the INSERT, UPDATE, and DELETE commands. 
The Data Definition Language (DDL) manages table and index structure, and 
includes the CREATE, ALTER, RENAME, and DROP statements.
There are extensions to standard SQL that add programming language function-
ality. A stored procedure is executable code that is associated with the database. It is 
usually written in an imperative programming language, and it is used to perform 
common operations on the database.
Oracle is recognized as a world leader in relational database technology and its 
products play a key role in business computing. An Oracle database consists of a 
collection of data managed by an Oracle Database Management System. Today, 
Oracle is the main standard for database technology.
2 The asterisk (*) indicates that all columns of the Book table should be included in the result.
21.4  Structured Query Language (SQL)

292
21.5  Oracle Database
An Oracle database is a collection of data treated as a unit, and the database is used 
to store and retrieve related information. The database server manages a large 
amount of data in a multi-user environment. It allows concurrent access to the data, 
and the database management system prevents unauthorized access to the database. 
It also provides a smooth recovery of database information in the case of an outage 
or any other disruptive event.
Every Oracle database consists of one or more physical data files, which contain 
all of the database data, and a control file that contains entries that specify the 
physical structure of the database.
An Oracle database includes logical storage structures that enable the database to 
have control of disk space use. The database schema refers to the organization of 
data, and the schema objects are the logical structures that directly refer to the 
database’s data. They include structures such as tables, views, indexes, and 
constraints, and a database generally stores its schema in the data dictionary.
Tables are the basic unit of data storage in an Oracle database, and each table has 
several rows and columns. An index is an optional structure associated with a table, 
and it is used to enhance the performance of data retrieval. The index provides an 
access path to the table data. A view is the customized presentation of data from one 
or more tables. It does not contain actual data and derives the data from the actual 
tables on which it is based.
Each Oracle database has a data dictionary, which stores information about the 
logical and physical structure of the database. The data dictionary is created when 
the database is created, and is updated automatically by the Oracle database to 
ensure that it accurately reflects the status of the database at all times.
An Oracle database uses memory structures and various processes to manage 
and access the database. These include server processes, background processes, and 
user processes.
A database administrator (DBA) is responsible for setting up the Oracle database 
server and application tools. This role is concerned with allocating system storage 
and planning future storage requirements for the database management system. The 
DBA will create appropriate storage structures to meet the needs of application 
developers who are designing a new application. The access to the database will be 
monitored and controlled, and the performance of the database monitored and 
optimized. The DBA will plan backups and recovery of database information.
21  History of Databases

293
21.6  Review Questions
21.7  Summary
A database management system (DBMS) is a collection of software programs that 
allow a user to store, modify, and extract data from a database. A database is 
essentially a collection of data organized in such a way that a computer program 
may easily select the desired pieces of data.
There are three main categories of database management systems, and these are 
hierarchical, network, and relational models. A network model database is perceived 
by the user to be a collection of records and the relationships between them are 
organized as a network. A hierarchical model is perceived by a user to be a collection 
of hierarchies or trees, and it is a more restricted structure than the network model. 
A relational model is perceived by the user to be a collection of tables (or relations).
Codd proposed the relational model as a new approach to the management of 
data in 1970, and IBM developed the prototype System R relational database in the 
1970s. Relational databases are now dominant with the hierarchical and network 
model mainly of historical interest.
	1.	 What is a database?
	2.	 What is a database management system?
	3.	 Explain the differences between Relational, Hierarchical and Network 
databases.
	4.	 Explain the difference between a key and an index.
	5.	 What is a stored procedure?
	6.	 What is the role of the Oracle DBA?
	7.	 Explain the differences between tables, views, and schemas.
	8.	 What is SQL?
	9.	 What is an Oracle database?
21.7  Summary

295
© The Author(s), under exclusive license to Springer Nature 
Switzerland AG 2021
G. O’Regan, A Brief History of Computing, 
https://doi.org/10.1007/978-3-030-66599-9_22
Chapter 22
History of Artificial Intelligence
22.1  Introduction
The long-term1 goal of artificial intelligence (AI) is to create a thinking machine that is 
intelligent, has consciousness, has the ability to learn, has free will, and is ethical. The 
field involves several disciplines such as philosophy, psychology, linguistics, machine 
vision, cognitive science, mathematics, logic, and ethics. Artificial intelligence is a 
young field and John McCarthy and others coined the term in 1956. Alan Turing had 
earlier devised the Turing Test as a way to test the intelligent behavior of a machine. 
There are deep philosophical problems in artificial intelligence, and some researchers 
(including Hubert Dreyfus and John Searle) believe that its goals are impossible or 
incoherent. Even if artificial intelligence is possible there are moral issues to consider 
such as the exploitation of artificial machines by humans, and whether it is ethical to 
do this. Weizembaum2 has argued that artificial intelligence is unethical.
One of the earliest references to creating life by artificial means is that of the 
classical myth of Pygmalion. Pygmalion was a sculptor who carved a woman out of 
ivory. The sculpture was so realistic that he fell in love with it, and offered the statue 
presents and prayed to Aphrodite the goddess of love. Aphrodite took pity on him 
and brought the statue (Galathea) to life.
1 This long-term goal may be hundreds of years as there is unlikely to be an early breakthrough in 
machine intelligence as there are deep philosophical problems to be solved.
2 Weizenbaum was a psychologist who invented the ELIZA program, which simulated a psycholo-
gist in dialogue with a patient. He was initially an advocate of artificial intelligence but later 
became a critic.
Key Topics
Turing Test
Searle’s Chinese room
Philosophical problems in AI
Cognitive psychology
Linguistics
Logic and AI
Robots
Cybernetics
Neural networks
Expert systems

296
There are several stories of attempts by man to create life from inanimate objects, 
for example, the creation of the monster in Mary Shelly’s Frankenstein. The mon-
ster is created by an overambitious scientist who is punished for his blasphemy of 
creation (in that creation is for God alone). The monster feels rejected following 
creation, and inflicts a horrible revenge on its creator.
The Czech play Rossum’s Universal Robots” is a science fiction play by Capek, 
and it was performed in Prague in 1921. It was translated into English and appeared 
in London in 1923. It contains the first reference to the term “robot,” and the play 
considers the exploitation of artificial workers in a factory. The robots (or androids) 
are initially happy to serve humans, but become unhappy with their existence over 
a period of time. The fundamental question that the play is considering is whether 
the robots are being exploited, and if so, whether it is ethical, and what should the 
response of the robots be to their exploitation. It eventually leads to a revolt by the 
robots and the extermination of the human race.
22.2  Descartes
René Descartes (Fig. 22.1) was an influential French mathematician, scientist, and 
philosopher. He was born in a village in the Loire valley in France in 1596 and stud-
ied law at the University of Poitiers. He never practiced as a lawyer and instead 
served Prince Maurice of Nassau in the Netherlands. He invented the Cartesian 
coordinate system used in plane geometry, where each point on the plane is identi-
fied with a pair of numbers (x, y): the x-coordinate and the y-coordinate.
He made important contributions to philosophy and attempted to derive a funda-
mental set of principles that can be known to be true. His approach was to renounce 
Fig. 22.1  Rene Descartes
22  History of Artificial Intelligence

297
any idea that could be doubted. He rejected the senses since they can deceive, and are 
not a sound source of knowledge. For example, during a dream the subject perceives 
stimuli that appear to be real, but these have no existence outside the subject’s mind. 
Therefore, it is inappropriate to rely on one’s senses as the foundation of knowledge.
He argued that a powerful “evil demon or mad-scientist” could exist who sets out 
to manipulate and deceive subjects, thereby preventing them from knowing the true 
nature of reality. The evil demon could bring the subject into existence including an 
implanted memory. The question is how one can know for certain what is true given 
the limitations of the senses. The “brain in the vat thought experiment” is a more 
modern formulation of the idea of an evil spirit or mad scientist. A mad scientist 
could remove a person’s brain from their body and place it in a vat and connects its 
neurons by wires to a supercomputer. The computer then provides the disembodied 
brain with the electrical impulses that the brain would normally receive. The com-
puter could then simulate reality, and the disembodied brain would have conscious 
experiences and would receive the same impulses as if it were inside a person’s 
skull. There is no way to tell whether the brain is inside the vat or inside a person.
That is, at any moment an individual could potentially be a brain connected to a 
sophisticated computer program or inside a person’s skull. Therefore, if you cannot 
be sure that you are not a brain in a vat, then you cannot rule out the possibility that 
all of your beliefs about the external world are false. This skeptical argument is dif-
ficult to refute.
The perception of a “cat” (Fig. 22.2) in the case where the brain is in the vat is 
false, and does not correspond to reality. It is impossible to know whether your brain 
is in a vat or inside your skull, it is therefore impossible to know whether your belief 
is valid or not.
Fig. 22.2  Brain in a VAT 
thought experiment
22.2  Descartes

298
Descartes deduced that there was one single principle that must be true. He 
argued that even if he is being deceived, then clearly he is thinking and must exist. 
This principle of existence or being is more famously known as “cogito, ergo sum” 
(I think, therefore I am). Descartes argued that this existence can be applied to the 
present only, as memory may be manipulated and therefore doubted. Further, the 
only existence that he sure of is that he is a “thinking thing.” He cannot be sure of 
the existence of his body, as his body is perceived by his senses, which he has 
proven to be unreliable. Therefore, his mind or thinking thing is the only thing about 
him that cannot be doubted. His mind is used to make judgments, and to deal with 
unreliable perceptions received via the senses.
Descartes constructed a system of knowledge (Rationalism) from this one prin-
ciple using the deductive method. He deduced the existence of a benevolent God 
using the ontological argument. He argues [Des:99] that we have an innate idea of a 
supremely perfect being (God), and that God’s existence may be inferred immedi-
ately from the innate idea of a supremely perfect being.
	1.	 I have an innate idea of a supremely perfect being (i.e., God).
	2.	 Necessarily, existence is a perfection.3
	3.	 Therefore, God exists.
He then argued that since God is benevolent that he can have some trust in the 
reality that his senses provide. God has provided him with a thinking mind and does 
not wish to deceive him. He argued that knowledge of the external world can be 
obtained by both perception and deduction, and that reason (or rationalism) is the 
only reliable method of obtaining knowledge.
Descartes was a dualist and he makes a clear mind–body distinction. He states 
that there are two substances in the universe: mental substances and bodily sub-
stances. The mind–body distinction is very relevant in AI and the analogy of the 
human mind and brain is software running on a computer.
This thinking thing (res cogitans or mind/soul) is distinct from the rest of nature 
(res extensa), and interacts with the world through the senses to gain knowledge. 
Knowledge is gained by mental operations using the deductive method, where start-
ing from the premises that are known to be true, further truths may be logically 
deduced. Descartes founded what would become known as the Rationalist school of 
philosophy where knowledge was derived solely by human reasoning. The analogy 
of the mind in AI would be an AI program running on a computer with knowledge 
gained by sense perception with sensors and logical deduction.
Descartes believed that the bodies of animals are complex living machines with-
out feelings. He dissected (including vivisection) many animals for experiments. 
His experiments led him to believe that the actions and behavior of nonhuman ani-
mals can be fully accounted for by mechanistic means, and without reference to the 
operations of the mind. He realized from his experiments that a lot of human 
3 Descartes’ ontological argument is similar to St. Amselm’s argument on the existence of God, and 
implicitly assumes existence as a predicate (which was refuted by Kant).
22  History of Artificial Intelligence

299
behavior (e.g., physiological functions and blinking) is like that of animals in that it 
has a mechanistic explanation.
Descartes was of the view that well-designed automata4 could mimic many parts 
of human behavior. He argued that the key differentiators between human and ani-
mal behavior were that humans could adapt to widely varying situations, and also 
had the ability to use language. The use of language illustrates the power of the use 
of thought, and it clearly differentiates humans from animals. Animals do not pos-
sess the ability to use language for communication or reason. This, he argues, pro-
vides evidence for the presence of a soul associated with the human body. In essence, 
animals are pure machines, whereas humans are machines with minds (or souls).
The significance of Descartes in the field of artificial intelligence is that the 
Cartesian dualism that humans seem to possess would need to be reflected among 
artificial machines. Humans seem to have a distinct sense of “I” as distinct from the 
body, and the “I” seems to represent some core sense or essence of being that is 
unchanged throughout the person’s life. It somehow represents personhood, as dis-
tinct from the physical characteristics of a person that are inherited genetically. The 
long-term challenge for the AI community is to construct a machine that (in a sense) 
possesses Cartesian dualism: that is, a machine that has awareness of itself as well 
as its environment.
22.3  The Field of Artificial Intelligence
The origin of the term “Artificial Intelligence” is in work done on the proposal for 
Dartmouth Summer Research Project on Artificial Intelligence. John McCarthy and 
others wrote this proposal in 1955, and the research project took place in the sum-
mer of 1956.
The success of early AI went to its practitioners’ heads and they believed that 
they would soon develop machines that would emulate human intelligence. They 
convinced many of the funding agencies and the military to provide research grants, 
as they believed that real artificial intelligence would soon be achieved. They had 
some initial (limited) success with machine translation, pattern recognition, and 
automated reasoning. However, it is now clear that AI is a long-term project. 
Artificial intelligence is a multidisciplinary field and includes disciplines such as:
•	 Computing
•	 Logic and philosophy
•	 Psychology
•	 Linguistics
•	 Neuroscience and neural networks
•	 Machine vision
4 An automaton is a self-operating machine or mechanism that behaves and responds in a mechan-
ical way.
22.3  The Field of Artificial Intelligence

300
•	 Robotics
•	 Expert systems
•	 Machine translation
•	 Epistemology and knowledge representation
The British mathematician, Alan Turing, contributed to the debate concerning 
thinking machines, consciousness, and intelligence in the early 1950s [Tur:50]. He 
devised the famous “Turing Test” to judge whether a machine was conscious and 
intelligent. Turing’s paper was very influential as it raised the idea of the possibility 
of programming a computer to behave intelligently.
Shannon considered the problem of writing a chess program in the late 1940s, 
and he distinguished between a brute force strategy where the program could look 
at every combination of moves, or a strategy where knowledge of chess could be 
used to select and examine a subset of available moves. The ability of a program to 
play chess is a skill that is considered intelligent, even though the machine itself is 
not conscious that it is playing chess.
Modern chess programs have been quite successful, and have advantages over 
humans in terms of computational speed in considering combinations of moves. 
The IBM chess program “Deep Blue” defeated Kasparov in 1997.
Herbert Simon and Alan Newell developed the first theorem prover with their 
work on a program called “Logic Theorist” or “LT” [NeS:56]. This program could 
provide proofs of various theorems in Russell’s and Whitehead’s Principia 
Mathematica5 [RuW:10]. LT was demonstrated at the Dartmouth conference, and it 
showed that computers had the ability to encode knowledge and could perform 
intelligent operations such as solving theorems in mathematics.
John McCarthy (Fig. 22.3) proposed a program called the Advice Taker in his 
influential paper “Programs with Common Sense” [Mc:59]. The idea was that this 
program would be able to draw conclusions from a set of premises, and McCarthy 
states that a program has common sense if it is capable of automatically deducing 
for itself “a sufficiently wide class of immediate consequences of anything it is told 
and what it already knows.”
The Advice Taker uses logic to represent knowledge (i.e., premises that are taken 
to be true), and it then applies the deductive method to deduce further truths from 
the relevant premises.6 That is, the program manipulates the formal language (e.g., 
predicate logic), and provides a conclusion that may be a statement or an impera-
tive. McCarthy envisaged that the Advice Taker would be a program that would be 
able to learn and improve. This would involve making statements to the program, 
5 Russell is said to have remarked that he was delighted to see that the Principia Mathematica could 
be done by machine, and that if he and Whitehead had known this in advance that they would not 
have wasted 10 years doing this work by hand in the early twentieth century. The LT program suc-
ceeded in proving 38 of the 52 theorems in chapter 2 of Principia Mathematica. Its approach was 
to start with the theorem to be proved and to then search for relevant axioms and operators to prove 
the theorem.
6 The machine would somehow need to know what premises are relevant and should be selected in 
applying the deductive method from the many premises that are already encoded. This is nontrivial.
22  History of Artificial Intelligence

301
and telling it about its symbolic environment. The program will have available to it 
all the logical consequences of what it has already been told and previous knowl-
edge. McCarthy’s desire was to create programs to learn from their experience as 
effectively as humans do.
The McCarthy philosophy is that common sense7 knowledge, reasoning, and 
problem-solving can be formalized with logic. A particular system is described by 
a set of sentences in logic. These logic sentences represent all that is known about 
the world in general, and what is known about the particular situation and the goals 
of the systems. The program then performs actions that it infers are appropriate for 
achieving its goals.
22.3.1  Turing Test and Strong AI
Alan Turing contributed to the debate concerning artificial intelligence in his 1950 
paper on Computing, machinery, and intelligence [Tur:50]. Turing’s paper consid-
ered whether it could be possible for a machine to be conscious and to think. He 
predicted that it would be possible to speak of thinking machines, and he devised a 
famous experiment that would determine if a computer had these attributes. This is 
known as the “Turing Test,” and it is an adaptation of a well-known party game, 
which involves three participants. One of them, the judge, is placed in a separate 
room from the other two: one is a male and the other is a female. Questions and 
responses are typed and passed under the door. The objective of the game is for the 
judge to determine which participant is male and which is female. The male is 
allowed to deceive the judge, whereas the female is supposed to assist.
7 Common sense includes basic facts about events, beliefs, actions, knowledge, and desires. It also 
includes basic facts about objects and their properties.
Fig. 22.3  John McCarthy
22.3  The Field of Artificial Intelligence

302
Turing adapted this game by allowing the role of the male to be played by a com-
puter. The test involves a judge who is engaged in a natural language conversation 
with two other parties, one party is a human and the other is a machine. If the judge 
cannot determine which is machine and which is human, then the machine is said to 
have passed the “Turing Test.” That is, a machine that passes the Turing Test must 
be considered intelligent, as it is indistinguishable from a human. The test is applied 
to test the linguistic capability of the machine rather than the audio capability, and 
the conversation is limited to a text-only channel.
Turing’s work on “thinking machines” led to a debate concerning the nature of 
intelligence, and it caused a great deal of public controversy as defenders of tradi-
tional values attacked the idea of machine intelligence.
Turing strongly believed that machines would eventually be developed that 
would stand a good chance of passing the “Turing Test.” He considered the opera-
tion of “thought” to be equivalent to the operation of a discrete state machine. A 
program that runs on a single, universal machine, that is, a computer, may simulate 
such a machine.
Turing viewpoint that a machine will one day pass the Turing Test and be consid-
ered intelligent is known as “strong artificial intelligence.” It states that a computer 
with the right program would have the mental properties of humans. There are a 
number of objections to strong AI, and one well-known rebuttal is that of Searle’s 
Chinese room argument.
Searle’s Chinese room thought experiment is a famous paper written by John 
Searle on machine understanding [Sea:80]. This classic paper presents a compelling 
argument against the feasibility of the strong AI project. It rejects the claim that a 
machine will someday in the future have the same cognitive qualities as humans. 
Searle argues that brains cause minds, and that syntax does not suffice for seman-
tics. He defines the terms “strong” and “weak AI” as follows.
Strong AI
The computer is not merely a tool in the study of the mind, rather the appropri-
ately programmed computer really is a mind in the sense that computers given the 
right programs can be literally said to understand and have other cognitive states.
Weak AI
Computers just simulate thought, their seeming understanding is not real under-
standing (just as-if), their seeming calculation is only as-if calculation, etc. 
Nevertheless, computer simulation is useful for studying the mind (as for studying 
the weather and other things).
Searle’s Chinese Room Thought Experiment
A man is placed into a closed room into which Chinese writing symbols are input to 
him (Fig. 22.4). He is given a rulebook that shows him how to manipulate the sym-
bols to produce Chinese output. He has no idea as to what each symbol means but 
with the rulebook he is able to produce the Chinese output. This allows him to com-
municate with the other person and appear to understand Chinese. The rulebook 
22  History of Artificial Intelligence

303
allows him to answer any questions posed, without the slightest understanding of 
what he is doing or what the symbols mean.
	1.	 Chinese characters are entered through slot 1.
	2.	 The rulebook is employed to construct new Chinese characters.
	3.	 Chinese characters are outputted to slot 2.
The question “Do you understand Chinese?” could potentially be asked, and the 
rulebook would be consulted to produce the answer “Yes, of course” despite the fact 
that the person inside the room has not the faintest idea of what is going on. It will 
appear to the person outside the room that the person inside is knowledgeable on 
Chinese. The person inside is just following rules without understanding.
The process is essentially that of a computer program that takes an input; per-
forms a computation based on the input; and then finally produces an output. Searle 
has essentially constructed a machine that can never be mental. Changing the pro-
gram essentially means changing the rulebook, and this does not increase under-
standing. The strong artificial intelligence thesis states that given the right program, 
any machine running it would be mental. However, Searle argues that the program 
for this Chinese room would not understand anything, and that therefore the strong 
AI thesis must be false. In other words, Searle’s Chinese room argument is a rebuttal 
of strong AI by showing that a program running on a machine that appears to be 
intelligent has no understanding whatsoever of the symbols that it is manipulating. 
That is, given any rulebook (i.e., program), the person would never understand the 
meanings of those characters that are manipulated.
That is, just because the machine acts like it knows what is going on, it actually 
only knows what it is programmed to know. It differs from humans in that it is not 
aware of the situation like humans are. It suggests that machines may not have intel-
ligence or consciousness, and the Chinese room argument applies to any Turing 
equivalent computer simulation.
There are several rebuttals of Searle’s position and one well-known rebuttal 
attempt is the “System Reply” argument. This reply argues that if a result associated 
with intelligence is produced, then intelligence must be found somewhere in the 
system. The proponents of this argument draw an analogy between the human brain 
and its constituents. None of its constituents have intelligence but the system as a 
whole (i.e., the brain) exhibits intelligence. Similarly, the parts of the Chinese room 
may lack intelligence, but the system as a whole is intelligence.
Fig. 22.4  Searle’s 
Chinese room
22.3  The Field of Artificial Intelligence

304
22.3.2  Ethics and AI
Weizenbaum created the famous Eliza program at MIT in 1966, and the program 
interacted with a user sitting at an electric typewriter, in English, in the manner of a 
Rogerian psychotherapist.8
The name “Eliza”9 was chosen because it could be taught to speak increasingly 
well, as in Shaw’s Pygmalion. It was one of the earliest natural language processing 
programs, and Weizenbaum gave an example of a conversation between Eliza and a 
young woman in [Wei:66]. Many users believed that Eliza had real understanding, 
and they began to unburden themselves in long computer sessions.
The program operated by decomposing the user’s input into its constituent parts 
of speech, and then typing them back at the user in a manner to continue with the 
dialogue. The program provided very convincing human-like interaction, as may be 
seen in the sample dialogue below:
User/Patient:	
Men are all alike.
Eliza	
	
In what way?
User/Patient:	
They are always bugging us about something or other.
Eliza	
	
an you think of a specific example?
User/Patient:	
Well, my boyfriend made me come here.
Eliza	
	
Your boyfriend made you come here?
User/Patient	
He says I’m depressed much of the time.
Eliza	
	
I am sorry to hear that you are depressed.
User/Patient	
It’s true, I am unhappy.
Eliza	
	
Do you think that coming here will help you not to be unhappy?
User/Patient	
I need some help, that much seems certain.
Eliza	
	
What would it mean to you if you got some help?
User/Patient	
Perhaps, I could learn to get along with my mother.
Eliza	
	
Tell me more about your family.
Weizenbaum was shocked to discover that so many users were convinced that the 
program had real understanding, and users spent hours sharing their personal prob-
lems with the program. It led Weizenbaum to think about the ethics and implications 
of the artificial intelligence field, and the ability of a relatively trivial program to 
deceive a naïve user to reveal personal information. He became a leading critic of 
the AI field, and an advocate for professional and social responsibility.
His views on the ethics of AI are discussed in his book “Computer Power and 
Human Reason” [Wei:76]. He displays ambivalence toward computer technology, 
and he argues that AI is a threat to human dignity, and that AI should not replace 
humans in positions that require respect and care. He states that machines lack 
8 Rogerian psychotherapy (person-centered therapy) was developed by Carl Rodgers in the 1940s.
9 Eliza Doolittle was a working-class character in Shaw’s play Pygmalion. She is taught to speak 
with an upper-class English accent.
22  History of Artificial Intelligence

305
empathy, and that if they replace humans in positions such as police officers or 
judges, this would lead to alienation and a devaluation of the human condition.
His Eliza program demonstrated the threat that AI poses to privacy. It is con-
ceivable that an AI program may be developed in the future that is capable of under-
standing speech and natural languages. Such a program could theoretically 
eavesdrop on every phone conversation and email, and gather private information 
on what is said, and who is saying it. Such a program could be used by a state to 
suppress dissent, and to eliminate those who pose a threat.
As more and more sophisticated machines and robots are created, it is, of course, 
essential that intelligent machines behave ethically, and have a moral compass to 
distinguish right from wrong. It remains an open question as to how to teach a robot 
or machine right from wrong.
22.4  Philosophy and AI
Artificial intelligence includes the study of knowledge and the mind, and there are 
deep philosophical problems (e.g., the nature of mind, consciousness, and knowl-
edge) to be solved.
The Greeks did important early work on philosophy as they attempted to under-
stand the world and the nature of being and reality. Thales and the Miletians10 
attempted to find an underlying principle that would explain the nature of the world. 
Pythagoras believed that mathematics was this basic principle, and that everything 
(e.g., music) could be explained in terms of number. Plato distinguished between 
the world of appearances and the world of reality. He argued that the world of 
appearances resembles the flickering shadows on a cave wall, whereas reality is in 
the world of ideas11 or forms, in which objects of this world somehow participate. 
Aristotle divides the world into two categories: substances and accidents, where 
substance is the most fundamental category. It includes form plus matter, for exam-
ple, the matter of a wooden chair is the wood that it is composed of, and its form is 
the general form of a chair.
Descartes’ rationalist position had a significant influence on the philosophy of 
mind and AI.  Knowledge is gained by mental operations using the deductive 
method. This involves starting from premises that are known to be true and deriving 
further truths. He distinguished between the mind and the body (Cartesian dualism), 
and the analogy of the mind is an AI program running on a computer with sensors 
and logical deduction used to gain knowledge.
10 The term “Miletians” refers to inhabitants of the Greek city state Miletus, which is located in 
modern Turkey. Anaximander and Anaximenes were two other Miletians who made contributions 
to early Greek philosophy in approx. 600 B.C.
11 Plato was an Idealist, i.e., that reality is in the world of ideas rather than the external world. 
Realists (in contrast) believe that the external world corresponds to our mental ideas.
22.4  Philosophy and AI

306
British Empiricism rejected the Rationalist position, and stressed the importance 
of empirical data in gaining knowledge about the world. It argued that all knowl-
edge is derived from sense experience. It included philosophers such as Locke, 
Berkeley,12 and Hume. Locke argued that a child’s mind is a blank slate (tabula 
rasa) at birth, and that all knowledge is gained by sense experience. Berkeley argued 
that the ideas in a man’s mind have no existence outside his mind [Ber:99], and this 
philosophical position is known as Idealism.13 David Hume formulated the standard 
empiricist philosophical position in “An Enquiry concerning Human Understanding” 
[Hum:06].
Hume argued that all objects of human knowledge may be divided into two 
kinds: matters of fact propositions that are based entirely on experience, or relation 
of ideas propositions that may be demonstrated via deduction reasoning in the oper-
ations of the mind. He argued that any subject14 proclaiming knowledge that does 
not adhere to these empiricist principles should be committed to the flames15 as such 
knowledge contains nothing but sophistry and illusion.
Kant’s Critique of Pure Reason [Kan:03] was published in 1781 and is a response 
to Hume’s theory of empiricism. Kant argued that there is a third force in human 
knowledge that provides concepts that cannot be inferred from experience. Such 
concepts include the laws of logic (e.g., modus ponens), causality, and so on, and 
Kant argued that the third force was the manner in which the human mind structures 
its experiences. He called these structures categories.
The continental school of philosophy included thinkers such as Heidegger and 
Merleau-Ponty who argued that the world and the human body are mutually inter-
twined. Merleau-Ponty emphasized the concept of a body-subject that actively par-
ticipates both as the perceiver of knowledge and as an object of perception. 
12 Berkeley was an Irish philosopher and he was born in Dysart castle in Kilkenny, Ireland. He was 
educated at Trinity College, Dublin, and served as bishop of Cloyne in Co. Cork. He planned to 
establish an education seminary in Bermuda for the sons of colonists in America, but the project 
failed due to the lack of funding from the British government. Berkeley University in San Francisco 
is named after him.
13 Berkeley’s theory of Ontology is that for an entity to exist it must be perceived, i.e., “Esse est 
percipi.” He argues that “It is an opinion strangely prevailing amongst men, that houses, moun-
tains, rivers, and in a world all sensible objects have an existence natural or real, distinct from 
being perceived.” This led to a famous Limerick that poked fun at Berkeley’s theory. “There once 
was a man who said God; Must think it exceedingly odd; To find that this tree, continues to be; 
When there is no one around in the Quad.” The reply to this Limerick was appropriately: “Dear sir, 
your astonishments odd; I am always around in the Quad; And that’s why this tree will continue to 
be; Since observed by, yours faithfully, God.”
14 Hume argues that these principles apply to subjects such as Theology as its foundations are in 
faith and divine revelation, which are neither matters of fact nor relations of ideas.
15 “When we run over libraries, persuaded of these principles, what havoc must we make? If we 
take in our hand any volume; of divinity or school metaphysics, for instance; let us ask, Does it 
contain any abstract reasoning concerning quantity or number? No. Does it contain any experi-
mental reasoning concerning matter of fact and existence? No. Commit it then to the flames: for it 
can contain nothing but sophistry and illusion.”
22  History of Artificial Intelligence

307
Heidegger emphasized that existence can only be considered with respect to a 
changing world.
Philosophy has been studied for over two millennia but to date very little prog-
ress has been made in solving its fundamental questions. However, it is important 
that it be considered as any implementation of AI will make philosophical assump-
tions, and it is important that these be understood.
22.5  Cognitive Psychology
Psychology arose out of the field of psychophysics in the late nineteenth century 
with work by German pioneers in attempting to quantify perception and sensation. 
Fechner’s formulation of the relationship between stimulus and sensation is:
	
S
 


k
I
c
log
	
The symbol S refers to the intensity of the sensation, the symbols k and c are 
constants, and the symbol I refers to the physical intensity of the stimulus. William 
James defined psychology as the science of mental life.
One of the early behavioralist psychologists was Pavlov who showed that it was 
possible to develop a conditional reflex in a dog. He showed that it is possible to 
make a dog salivate in response to the ringing of a bell. This is done by ringing a bell 
each time before meat is provided to the dog, and the dog therefore associates the 
presentation of meat with the ringing of the bell after a training period.
Skinner developed the concept of conditioning further using rewards to reinforce 
desired behavior, and punishment to discourage undesired behavior. Positive rein-
forcement helps to motivate the individual to behave in the desired way, with punish-
ment used to deter the individual from performing undesired behavior. The behavioral 
theory of psychology explains many behavioral aspects of the world. However, it 
does not really explain complex learning tasks such as language development.
Merleau-Ponty16 considered the problem of what the structure of the human 
mind must be for the objects of the external world to exist in our minds in the form 
that they do. He built upon the theory of phenomenology as developed by Hegel and 
Husserl. Phenomenology involves a focus and exploration of phenomena with the 
goal of establishing the essential features of experience. Merleau-Ponty introduced 
the concept of the body-subject, which is distinct from the Cartesian view that the 
world is just an extension of our own mind. He argued that the world and the human 
body are mutually intertwined. The Cartesian view is that the self must first be 
aware of and know its own existence, prior to being aware of and recognizing the 
existence of anything else.
16 Merleau-Ponty was a French philosopher who was strongly influenced by the phenomenology of 
Husserl. He was also closely associated with the French existentialist philosophers such as Jean-
Paul Sartre and Simone de Beauvoir.
22.5  Cognitive Psychology

308
The body has the ability to perceive the world, and it plays a double role in that 
it is both the subject (i.e., the perceiver) and the object (i.e., the entity being per-
ceived) of experience. Human understanding and perception is dependent on the 
body’s capacity to perceive via the senses, and its ability to interrogate its environ-
ment. Merleau-Ponty argued that there is a symbiotic relationship between the per-
ceiver and what is being perceived, and he argues that as our consciousness develops 
the self imposes richer and richer meanings on objects. He provides a detailed anal-
ysis of the flow of information between the body-subject and the world.
Cognitive psychology is a branch of psychology that is concerned with learning, 
language, memory, and internal mental processes. Its roots lie in Piaget’s child 
development psychology, and in Wertheimer’s Gestalt psychology. The latter argues 
that the operations of the mind are holistic, and that the mind contains a self-­
organizing mechanism. Holism argues that the sum of the parts is less than the 
whole, and it is the opposite of logical Atomism17 developed by Bertrand Russell. 
Russell (and also the early Wittgenstein) attempted to identify the atoms of thought: 
that is, the elements of thought that cannot be divided into smaller pieces. Logical 
Atomism argues that all truths are ultimately dependent on a layer of atomic facts. It 
had an associated methodology whereby a process of analysis is attempted to con-
struct more complex notions in terms of simpler ones.
Cognitive psychology was developed in the late 1950s and is concerned with how 
people understand, diagnose, and solve problems, as well as the mental processes 
that take place during a stimulus and its corresponding response. It argues that solu-
tions to problems take the form of rules, heuristics, and sudden insight, and it con-
siders the mind as having a certain conceptual structure. The dominant paradigm in 
the field has been the information processing model, which considers the mental 
processes of thinking and reasoning as being equivalent to software running on the 
computer: that is, the brain. It has associated theories of input, representation of 
knowledge, processing of knowledge, and output.
Cognitive psychology has been applied to artificial intelligence from the 1960s, 
and some of the research areas include:
•	 Perception
•	 Concept formation
•	 Memory
•	 Knowledge representation
•	 Learning
•	 Language
•	 Grammar and linguistics
•	 Thinking
•	 Logic and problem-solving
17 Atomism actually goes back to the work of the ancient Greeks and was originally developed by 
Democritus and his teacher Leucippus in the fifth century BC Atomism was rejected by Plato in 
the dialogue of the Timaeus.
22  History of Artificial Intelligence

309
It is clear that for a machine to behave with intelligence it will need to be able to 
perceive objects in the physical world. It must be able to form concepts and to 
remember knowledge that it has already been provided with. It will need an under-
standing of temporal events. Knowledge must be efficiently represented to allow 
easy retrieval for analysis and decision-making. An intelligent machine will need 
the ability to produce and understand written or spoken language. A thinking 
machine must be capable of thought, learning, analysis, and problem-solving.
22.6  Computational Linguistics
Linguistics is the theoretical and applied study of language, and human language is 
highly complex. It includes the study of phonology, morphology, syntax, semantics, 
and pragmatics. Syntax is concerned with the study of the rules of grammar, and the 
application of the rules forms the syntactically valid sentences and phrases of the 
language. Morphology is concerned with the formation and alteration of words, and 
phonetics is concerned with the study of sounds, and how sounds are produced and 
perceived as speech (or nonspeech).
Noam Chomsky is considered the father of linguistics, and he has been highly 
influential in the linguistics field. He defined the Chomsky Hierarchy of grammars 
[ORg:13], which classifies grammars into a number of classes with increasing 
expressive power. These consist of four levels including regular grammars; context-­
free grammars; context-sensitive grammars; and unrestricted grammars. Each suc-
cessive class can generate a broader set of formal languages than the previous. The 
grammars are distinguished by their production rules, which determine the type of 
language that is generated.
Computational linguistics is an interdisciplinary study of the design and analysis 
of natural language processing systems. It includes linguists, computer scientists, 
cognitive psychologists, mathematicians, and experts in artificial intelligence.
Early work on computational linguistics commenced with machine translation 
work in the United States in the 1950s. The objective was to develop an automated 
mechanism by which Russian language texts could be translated directly into 
English without human intervention. It was naively believed that it was only a mat-
ter of time before automated machine translation would be done.
However, the initial results were not very successful, and it was realized that the 
automated processing of human languages was considerably more complex. This 
led to the birth of a new field called computational linguistics, and the objective of 
this field is to investigate and develop algorithms and software for processing natu-
ral languages. It is a sub-field of artificial intelligence, and deals with the compre-
hension and production of natural languages.
The task of translating one language into another involves decoding the meaning 
of the source text, and encoding this meaning into the target language. The task of 
translating one language into another requires an understanding of the grammar of 
both languages. This includes an understanding of the syntax, the morphology, 
22.6  Computational Linguistics

310
semantics and pragmatics of the language, as well as the cultural aspects of the 
translation.
Machine translation has improved in recent years with programs such as Google 
Translate providing useful output (it has many limitations). However, an automated 
high-quality translation of unrestricted text remains a long-term project. For artifi-
cial intelligence to become a reality it will need to make major breakthroughs in 
computational linguistics.
22.7  Cybernetics
The interdisciplinary field of cybernetics18 began in the late 1940s when concepts 
such as information, feedback, and regulation were generalized from engineering to 
other systems. These include systems such as living organisms, machines, robots, 
and language. Norbert Wiener coined the term “cybernetics,” and it was taken from 
the Greek word “κυβeρνητη” (meaning steersman or governor). It is the study of 
communications and control and feedback in living organisms and machines to 
ensure efficient action.
The name is well chosen, as a steersman needs to respond to different conditions 
and feedback while steering a boat to travel to a particular destination. Similarly, the 
field of cybernetics is concerned with the interaction of goals, predictions, actions, 
feedback, and responses in all kinds of systems. It uses models of organizations, 
feedback, and goals to understand the capacity and limits of any system.
It is concerned with knowledge acquisition through control and feedback. Its 
principles are similar to human knowledge acquisition, where learning is achieved 
through a continuous process of feedback from parents and peers, which leads to 
adaptation and transformation of knowledge, rather than its explicit encoding.
The conventional belief in AI is that knowledge may be stored inside a machine, 
and that the application of stored knowledge to the real world in this way constitutes 
intelligence. External objects are mapped to internal states on the machine, and 
machine intelligence is manifested by the manipulation of the internal states. This 
approach has been reasonably successful with rule-based expert systems, but it has 
made limited progress in creating intelligent machines. Therefore, alternative 
approaches such as cybernetics warrant further research. Cybernetics views infor-
mation (or intelligence) as an attribute of an interaction, rather than something that 
is stored in a computer.
18 Cybernetics was defined by Couffignal (one of its pioneers) as the art of ensuring the efficacy 
of action.
22  History of Artificial Intelligence

311
22.8  Logic and AI
Mathematical logic is used in the AI field to formalize knowledge and reasoning. 
Common-sense reasoning is required for solving problems in the real world, and 
McCarthy [Mc:59] argues that it is reasonable for logic to play a key role in the 
formalization of common-sense knowledge. This includes the formalization of 
basic facts about actions and their effects; facts about beliefs and desires; and facts 
about knowledge and how it is obtained. His approach allows common-sense prob-
lems to be solved by logical reasoning.
Its formalization requires sufficient understanding of the common-sense world, 
and often the relevant facts to solve a particular problem are unknown. It may be 
that knowledge thought relevant may be irrelevant and vice versa. A computer may 
have millions of facts stored in its memory, and the problem is how to determine 
which of these should be chosen from its memory to serve as premises in logical 
deduction.
McCarthy’s influential 1959 paper discusses various common-sense problems 
such as getting home from the airport. Mathematical logic is the standard approach 
to express premises, and it includes rules of inferences that are used to deduce valid 
conclusions from a set of premises. Its rigorous deductive reasoning shows how new 
formulae may be logically deduced from a set or premises.
McCarthy’s approach to programs with common sense has been criticized by 
Bar-Hillel and others on the grounds that common sense is fairly elusive, and the 
difficulty that a machine would have in determining which facts are relevant to a 
particular deduction from its known set of facts.
Propositional calculus associates a truth-value with each proposition, and 
includes logical connectives to produce formulae such as A → B, A ∧ B, and A ∨ 
B. The truth-values of the propositions are normally the binary values of true and 
false. There are other logics, such as 3-valued logic or fuzzy logics that allow more 
than two truth-values for a proposition. Predicate logic is more expressive than 
propositional logic and includes quantifiers and variables. It can formalize the syl-
logism “All Greeks are mortal; Socrates is a Greek; Therefore, Socrates is mortal.” 
The predicate calculus consists of:
•	 Axioms
•	 Rules for defining well-formed formulae
•	 Inference rules for deriving theorems from premises
A formula in predicate calculus is built up from the basic symbols of the lan-
guage. These include variables, predicate symbols such as equality, function sym-
bols, constants, logical symbols such as ∃, ∧, ∨, ¬, and punctuation symbols such as 
brackets and commas. The formulae of predicate calculus are built from terms, 
where a term is defined recursively as a variable or individual constant, or as some 
function containing terms as arguments. A formula may be an atomic formula, or 
built from other formulae via the logical symbols.
22.8  Logic and AI

312
There are several rules of inference associated with predicate calculus, and the 
most important of these are modus ponens and generalization. The rule of modus 
ponens states that given two formulae p, and p → q, then we may deduce q. The rule 
of generalization states that given a formula p that we may deduce ∀(x)p.
22.9  Computability, Incompleteness, and Decidability
An algorithm (or procedure) is a finite set of unambiguous instructions to perform a 
specific task. The term “algorithm” is named after the Persian mathematician 
Al-Khwarizmi. Church defined the concept of an algorithm formally in 1936, and 
he defined computability in terms of the lambda calculus. Turing defined comput-
ability in terms of the theoretical Turing machine. These formulations are equivalent.
Hilbert proposed formalism as a foundation for mathematics in the early twenti-
eth century. A formal system consists of a formal language, a set of axioms, and 
rules of inference. Hilbert’s program was concerned with the formalization of math-
ematics (i.e., the axiomatization of mathematics) together with a proof that the axi-
omatization was consistent. Its goals were to:
–– Develop a formal system where the truth or falsity of any mathematical state-
ment may be determined
–– A proof that the system is consistent (i.e., that no contradictions may be derived)
A proof in a formal system consists of a sequence of formulae, where each for-
mula is either an axiom or derived from one or more preceding formulae in the 
sequence by one of the rules of inference. Hilbert believed that every mathematical 
problem could be solved, and he therefore expected that the formal system of math-
ematics would be complete (i.e., all truths could be proved within the system) and 
decidable: that is, that the truth or falsity of any mathematical proposition could be 
determined by an algorithm. However, Church and Turing independently showed 
this to be impossible in 1936, and the only way to determine whether a statement is 
true or false is to try to solve it.
Russell and Whitehead published Principia Mathematica in 1910, and this three-­
volume work on the foundations of mathematics attempted to derive all mathemati-
cal truths in arithmetic from a well-defined set of axioms and rules of inference. The 
questions remained whether the Principia was complete and consistent. That is, is it 
possible to derive all the truths of arithmetic in the system and is it possible to derive 
a contradiction from the Principia’s axioms?
Gödel’s second incompleteness theorem [Goe:31] showed that first-order arith-
metic is incomplete, and that the consistency of first-order arithmetic cannot be 
proved within the system. Therefore, if first-order arithmetic cannot prove its own 
consistency, then it cannot prove the consistency of any system that contains first-­
order arithmetic. These results dealt a fatal blow to Hilbert’s program.
22  History of Artificial Intelligence

313
22.10  Robots
The first use of the term “robot” was by the Czech playwright Karel Capek in his 
play Rossum’s Universal Robots, performed in Prague in 1921. The word “robot” is 
from the Czech word for forced labor. The theme explored is whether it is ethical to 
exploit artificial workers in a factory, and how the robots should respond to their 
exploitation. Capek’s robots were not mechanical or metal in nature and were 
instead created through chemical means.
Asimov wrote several stories about robots in the 1940s including the story of a 
robotherapist. He predicted the rise of a major robot industry, and he also introduced 
a set of rules (or laws) for good robot behavior. These are known as the three Laws 
of Robotics (Table 22.1), and Asimov later added a fourth law.
The term “robot” is defined by the Robot Institute of America as:
Definition 22.1 (Robots)
A reprogrammable, multifunctional manipulator designed to move material, parts, 
tools, or specialized devices through various programmed motions for the perfor-
mance of a variety of tasks.
Joseph Engelberger and George Devol are considered the fathers of robotics, and 
they set up the first manufacturing company “Unimation” to make robots. Their first 
robot was called the “Unimate.” These robots were very successful and reliable, and 
saved their customer (General Motors) money by replacing staff with machines.
Robots are very effective at doing clearly defined repetitive tasks, and there are 
many sophisticated robots in the workplace today. The robot industry plays a major 
role in the automobile sector, and these are mainly industrial manipulators that are 
essentially computer-controlled “arms and hands.” However, fully functioning 
androids are many years away.
Robots may also improve the quality of life for workers, as they can free human 
workers from performing dangerous or repetitive tasks. They consistently produce 
(24 × 7 × 365) high-quality products at a low cost to consumers. They will, of 
course, from time to time require servicing by engineers or technicians. However, 
there are impacts on workers whose jobs are displaced by robots.
Table 22.1  Laws of robotics
Law
Description
Law 
zero
A robot may not injure humanity or, through inaction, allow humanity to come to 
harm.
Law 
one
A robot may not injure a human being or, through inaction, allow a human being to 
come to harm, unless this would violate a higher order law.
Law 
two
A robot must obey orders given it by human beings, except where such orders would 
conflict with a higher order law.
Law 
three
A robot must protect its own existence as long as such protection does not conflict with 
a higher order law.
22.10  Robots

314
22.11  Neural Networks
The term “neural network” refers to an interconnected group of processing elements 
called nodes or neurons. These neurons cooperate and work together to produce an 
output function. Neural networks may be artificial or biological. A biological net-
work is part of the human brain, whereas an artificial neural network is designed to 
mimic some properties of a biological neural network. The processing of informa-
tion by a neural network is done in parallel rather than in series.
A unique property of a neural network is fault tolerance: that is, it can still per-
form (within certain tolerance levels) its overall function even if some of its neurons 
are not functioning. Neural network may be trained to learn to solve complex prob-
lems from a set of examples. These systems may also use the acquired knowledge 
to generalize and solve unforeseen problems.
A biological neural network is composed of billions of neurons (or nerve cells). 
A single neuron may be physically connected to thousands of other neurons, and the 
total number of neurons and connections in a network may be enormous. The human 
brain consists of many billions of neurons, and these are organized into a complex 
intercommunicating network. The connections are formed through axons19 to 
dendrites,20 and the neurons can pass electrical signals to each other. These connec-
tions are not just the binary digital signals of on or off, and instead the connections 
have varying strength, which allows the influence of a given neuron on one of its 
neighbors to vary from very weak to very strong.
That is, each connection has an individual weight (or number) associated with it 
that indicates its strength. Each neuron sends its output value to all other neurons to 
which it has an outgoing connection. The output of one neuron can influence the 
activations of other neurons causing them to fire. The neuron receiving the connec-
tions calculates its activation by taking a weighted sum of the input signals. 
Networks learn by changing the weights of the connections. Many aspects of brain 
function, especially the learning process, are closely associated with the adjustment 
of these connection strengths. Brain activity is represented by particular patterns of 
firing activity among the network of neurons. This simultaneous cooperative behav-
ior of a huge number of simple processing units is at the heart of the computational 
power of the human brain.21
Artificial neural networks aim to simulate various properties of biological neural 
networks. They consist of many hundreds of simple processing units, which are 
wired together in a complex communication network. Each unit or node is a 
19 These are essentially the transmission lines of the nervous system. They are microscopic in diam-
eter and conduct electrical impulses. The axon is the output from the neuron and the dendrites 
are input.
20 Dendrites extend like the branches of a tree. The origin of the word dendrite is from the Greek 
word (δενδρον) for tree.
21 The brain works through massive parallel processing.
22  History of Artificial Intelligence

315
simplified model of a real neuron which fires22 if it receives a sufficiently strong 
input signal from the other nodes to which it is connected. The strength of these 
connections may be varied in order for the network to perform different tasks cor-
responding to different patterns of node firing activity. The objective is to solve a 
particular problem, and artificial neural networks have been applied to speech rec-
ognition problems, image analysis, and so on.
The human brain employs massive parallel processing whereas artificial neural 
networks provide simplified models of the neural processing that takes place in the 
brain. The largest artificial neural networks are tiny compared to biological neural 
networks. The challenge for the field is to determine what properties individual 
neural elements should have to produce something useful representing intelligence.
Neural networks differ from the traditional von Neumann architecture, which is 
based on the sequential execution of machine instructions. The origins of neural 
networks lie in the attempts to model information processing in biological systems. 
This relies more on parallel processing as well as on implicit instructions based on 
pattern recognition from sense perceptions of the external world.
The nodes in an artificial neural network are composed of many simple process-
ing units, which are connected into a network. Their computational power depends 
on working together (parallel processing) on any task, and computation is related to 
the dynamic process of node firings rather than sequential execution of instructions. 
This structure is much closer to the operation of the human brain, and leads to a 
computer that may be applied to a number of complex tasks.
22.12  Expert Systems
An expert system is a computer system that contains domain knowledge of one or 
more human experts in a narrow specialized domain. It consists of a set of rules (or 
knowledge) supplied by the domain experts about a specific class of problems, and 
allows knowledge to be stored and intelligently retrieved. The effectiveness of the 
expert system is largely dependent on the accuracy of the rules provided, as incor-
rect inferences will be drawn with incorrect rules. Several commercial expert sys-
tems have been developed since the 1960s.
Expert systems have been a success story in the AI field. They have been applied 
to the medical field, equipment repair, and investment analysis. They employ a logi-
cal reasoning capability to draw conclusions from known facts, as well as recom-
mending an appropriate course of action to the user. An expert system consists of 
the following components (Table 22.2).
Human knowledge of a specialty is of two types: namely public knowledge and 
private knowledge. The former includes the facts and theories documented in text-
books and publications, whereas the latter refers to knowledge that the expert 
22 The firing of a neuron means that it sends off a new signal with a particular strength (or weight).
22.12  Expert Systems

316
possesses that has not found its way into the public domain. The latter often consists 
of rules of thumb or heuristics that allow the expert to make an educated guess 
where required, as well as allowing the expert to deal effectively with incomplete or 
erroneous data. It is essential that the expert system encodes both public and private 
knowledge to enable it to draw valid inferences.
The inference engine is made up of many inference rules that are used by the 
engine to draw conclusions. Rules may be added or deleted without affecting other 
rules, and this reflects the normal updating of human knowledge. Out of date facts 
may be deleted, as they are no longer used in reasoning, while new knowledge may 
be added and applied in reasoning. The inference rules use reasoning that is closer 
to human reasoning, and the two main types of reasoning are backward chaining 
and forward chaining. Forward chaining starts with the data available, and uses the 
inference rules to draw intermediate conclusions until a desired goal is reached. 
Backward chaining starts with a set of goals and works backward to determine if 
one of the goals can be met with the data that are available.
The expert system makes its expertise available to decision-makers who need 
answers quickly. This is extremely useful as often there is a shortage of experts, and 
the availability of an expert computer with in-depth knowledge of specific subjects 
is therefore very attractive. Expert systems may also assist managers with long-term 
planning. There are many small expert systems available that are quite effective in a 
narrow domain.
Several expert systems (e.g., Dendral, Mycin, and Colossus) have been devel-
oped. Dendral (Dendritic Algorithm) was developed at Stanford University in the 
mid-1960s, and its objectives were to assist the organic chemist with the problem of 
identifying unknown organic compounds and molecules by computerized spec-
trometry. This involved the analysis of information from mass spectrometry graphs 
and knowledge of chemistry. Dendral automated the decision-making and problem-­
solving process used by organic chemists to identify complex unknown organic 
molecules. It was written in LISP and it showed how an expert system could employ 
rules, heuristics, and judgment to guide scientists in their work.
Mycin was developed at Stanford University in the 1970s. It was written in LISP 
and was designed to diagnose infectious blood diseases, and to recommend appro-
priate antibiotics and dosage amounts corresponding to the patient’s body weight. It 
had a knowledge base of approximately 500 rules and a fairly simple inference 
Table 22.2  Expert systems
Component
Description
Knowledge base
The knowledge base is represented as a set of rules of the form (IF condition 
THEN action).
Inference engine
Carries out reasoning by which Expert System reaches conclusion.
Explanatory 
facility
Explains how a particular conclusion was reached.
User interface
Interface between user and expert system.
Database/memory Set of facts used to match against IF conditions in knowledge base.
22  History of Artificial Intelligence

317
engine. Its approach was to query the physician running the program with a long list 
of yes/no questions. Its output consisted of various possible bacteria that could cor-
respond to the blood disease, along with an associated probability that indicated the 
confidence in the diagnosis. It also included the rationale for the diagnosis, and a 
course of treatment appropriate to the diagnosis.
Mycin had a correct diagnosis rate of 65%. This was better than the diagnosis of 
most physicians who did not specialize in bacterial infections. However, its diagno-
sis rate was less than that of experts in bacterial infections who had a success rate of 
80%. Mycin was never actually used in practice due to legal and ethical reasons on 
the use of expert systems in medicine. For example, if the machine makes the wrong 
diagnosis who is to be held responsible?
Colossus is an expert system used by several Australian insurance companies to 
help insurance adjusters assess personal injury claims. It helps to improve consis-
tency, objectivity, and fairness in the claims process. It guides the adjuster through 
an evaluation of medical treatment options, the degree of pain, and suffering of the 
claimant, and the extent that there is permanent impairment to the claimant, as well 
as the impact of the injury on the claimant’s lifestyle. It was developed in Australia 
in the late 1980s, and the product was acquired by the Computer Sciences 
Corporation (CSC) in the mid-1990s.
22.13  Driverless Car
A driverless car (autonomous vehicle) is a vehicle that can sense its environment 
and navigate its way without human intervention. It uses techniques such as AI, 
GPS, radar, and computer vision to detect its environment, and it has advanced con-
trol systems to determine an appropriate navigation path to its destination. Its navi-
gation needs to be sophisticated to enable it to avoid obstacles, and to observe road 
signage and traffic lights during the journey, as well as dealing with diverse weather/
light conditions.
The control systems include sensing and navigation systems, and the analysis of 
the sensory data must be able to distinguish between different vehicles on the road. 
The control system must make the correct decisions from the analysis of the images, 
and this is especially important when dealing with unexpected situations.
Driverless cars will need to be encoded with a moral compass to deal with situa-
tions where ethical decisions need to be made. For example, suppose a self-driving 
vehicle is traveling on a road and two children roll off a grassy bank on to the road. 
Further, there is no time for the vehicle to brake and the question is what should the 
vehicle do where if the vehicle swerves to the left to avoid the children it will hit an 
oncoming motorbike. Which decision should the car make and how should it make 
such a decision? Further, who should be held accountable when incorrect or unethi-
cal decisions are made?
Several technology companies such as Google, Apple, Uber, and Amazon are 
working on driverless cars, and autonomous vehicles may potentially lead to a 
22.13  Driverless Car

318
significant reduction in road accidents and fatalities. They offer greater mobility for 
people who cannot operate a vehicle, but there are many challenges and safety/
security issues to be solved before the public will have sufficient confidence in their 
use (Table 22.3).
22.14  Review Questions
Table 22.3  Challenges with driverless vehicles
Area
Description
Sensing the 
surroundings
A motorway looks totally different on a clear day than on a foggy day or at 
dusk. Driverless cars must be able to detect road features in all conditions, and 
the sensors need to be reliable.
Unexpected 
encounters
Driverless cars struggle with unexpected situations (e.g., traffic police waving 
vehicles through a red light), as rule-based programming is unlikely to cover 
every scenario.
Human vehicle 
interaction
Most self-driving cars will be semi-autonomous for the foreseeable future, and 
determining the responsibilities of human and machine and when one or the 
other should be in control is a challenge.
Ethical
Should the car prioritize the protection of the pedestrian or the passenger? 
Moral judgments may be required.
Security/
hacking
Conventional vehicles have vulnerabilities that may be exploited by hackers 
(e.g., the braking and steering system of a vehicle was hacked through its 
entertainment system in 2015). Self-driving cars have more vulnerabilities and 
are at greater risk of a malicious attack.
Legal 
framework/
Liability
Self-driving vehicles will be subject to strict safety regulations, and 
appropriate legislation needs to be developed.
	1.	 Discuss Descartes and his rationalist philosophy and his relevance to arti-
ficial intelligence.
	2.	 Discuss the Turing Test and its relevance on strong AI.
	3.	 Discuss Searle’s Chinese room rebuttal arguments. What are your views on 
Searle’s argument?
	4.	 Discuss the philosophical problems underlying artificial intelligence.
	5.	 Discuss the applicability of logic to artificial intelligence.
	6.	 Discuss neural networks and their applicability to artificial intelligence.
	7.	 Discuss expert systems and their applications to the AI field.
	8.	 Discuss the applications of cybernetics to the AI field.
	9.	 Discuss the applications of phenomenology to the AI field.
22  History of Artificial Intelligence

319
22.15  Summary
Artificial intelligence is a multidisciplinary field, and its branches include logic; 
philosophy; psychology; linguistics; machine vision; neural networks; and expert 
systems. Turing believed that machine intelligence was achievable, and he devised 
the “Turing Test” to judge if a machine was intelligent. Searle’s Chinese room argu-
ment is a rebuttal of strong AI, and it aims to demonstrate that a machine will never 
have the same cognitive qualities as a human even if it passes the Turing Test.
McCarthy argued that human-level intelligence could be achieved with a logic-­
based system. Cognitive psychology is concerned with cognition and some of its 
research areas include perception, memory, learning, thinking, and logic and 
problem-­solving. Linguistics is the scientific study of language and includes the 
study of syntax and semantics.
Artificial neural networks aim to simulate various properties of biological neural 
networks. They consist of many hundreds of simple processing units that are wired 
together in a complex communication network. Each unit or node is a simplified 
model of a real neuron which fires if it receives a sufficiently strong input signal 
from the other nodes to which it is connected. The strength of these connections 
may be varied in order for the network to perform different tasks corresponding to 
different patterns of node firing activity.
An expert system is a computer system that allows knowledge to be stored and 
intelligently retrieved. It is a program that is made up of a set of rules (or knowl-
edge). The domain experts generally supply the rules about a specific class of prob-
lems. Expert systems include a problem-solving component that allows an analysis 
of the problem, as well as recommending an appropriate course of action to solve 
the problem.
22.15  Summary

321
© The Author(s), under exclusive license to Springer Nature 
Switzerland AG 2021
G. O’Regan, A Brief History of Computing, 
https://doi.org/10.1007/978-3-030-66599-9_23
Chapter 23
Ethics and Professional Responsibility
23.1  Introduction
Ethics is a practical branch of philosophy that deals with moral questions such as 
what is right or wrong, and how a person should behave in a given situation in a 
complex world. Ethics explores what actions are right or wrong within a specific 
context or within a certain society, and seeks to find satisfactory answers to moral 
questions. The origin of the word “ethics” is from the Greek word ἠθικός, which 
means habit or custom.
There are various schools of ethics such as the relativist position (as defined by 
Protagoras), which argues that each person decides on what is right or wrong for 
them; cultural relativism argues that the particular society determines what is right 
or wrong based upon its cultural values; deontological ethics (as defined by Kant) 
argues that there are moral laws to guide people in deciding what is right or wrong; 
and utilitarianism which argues that an action is right if its overall effect is to pro-
duce more happiness than unhappiness in society.
Professional ethics are a code of conduct that governs how members of a profes-
sion deal with each other and with third parties. A professional code of ethics expresses 
ideals of human behavior, and it defines the fundamental principles of the organiza-
tion, and is an indication of its professionalism. Several organizations such as the 
Association Computing Machinery (ACM) and British Computer Society (BCS) have 
developed a code of conduct for their members, and violations of the code by mem-
bers are taken seriously and are subject to investigations and disciplinary procedures.
Business ethics define the core values of the business, and are used to guide 
employee behavior. Should an employee accept gifts from a supplier to a company, 
as this could lead to a conflict of interest? A company may face ethical questions on 
the use of technology. For example, should the use of a new technology be restricted 
because people can use it for illegal or harmful actions as well as beneficial ones?
Key Topics
Ethics
Parnas on professional responsibility
ACM code of ethics and professional practice
BCS code of conduct
Licensing of software engineers
Professional conduct

322
Consider mobile phone technology, which has transformed communication 
between people, and thus is highly beneficial to society. What about mobile phones 
with cameras? On the one hand, they provide useful functionality in combining a 
phone and a camera. On the other hand, they may be employed to take indiscreet 
photos without permission of others, which may then be placed on inappropriate 
sites. In other words, how can citizens be protected from inappropriate use of such 
technology?
23.2  Business Ethics
Business ethics (also called corporate ethics) is concerned with ethical principles 
and moral problems that arise in a business environment. They refer to the core 
principles and values of the organization, and apply throughout the organization. 
They guide individual employees in carrying out their roles, and ethical issues 
include the rights and duties between a company and its employees, customers and 
suppliers.
Many corporations and professional organizations have a written “code of eth-
ics” that defines the professional standards expected of all employees in the com-
pany. All employees are expected to adhere to these values whenever they represent 
the company. The human resource function in a company plays an important role in 
promoting ethics and the core values of the organization, and in putting internal HR 
policies in place relating to the ethical conduct of its employees. The HR depart-
ment is also responsible for ensuring that discrimination, sexual harassment are 
addressed, and that employees are treated appropriately (including cultural sensi-
tivities in a multicultural business environment).
Companies are expected to behave ethically and not to exploit its workers. There 
was a case of employee exploitation at the Foxconn plant (an Apple supplier of the 
iPhone) in Shenzhen in China in 2006, where conditions at the plant were so dread-
ful (long hours, low pay, unreasonable workload, and crammed accommodation) 
that several employees committed suicide. The scandal raised questions on the 
extent to which a large corporation such as Apple should protect the safety and well-­
being of the factory workers of its suppliers. Further, given the profits that Apple 
makes from the iPhone, is it ethical for Apple to allow such workers to be exploited?
Today, the area of corporate social responsibility (CSR) has become applicable 
to the corporate world, and it requires the corporation to be an ethical and respon-
sible citizen in the communities in which it operates (even at a cost to its profits). It 
is therefore reasonable to expect a responsible corporation to pay its fair share of 
tax, and to refrain from using tax loopholes to avoid paying billions in taxes on 
international sales. Today, environmental ethics has become topical, and it places 
responsibilities on business to protect the environment in which it operates. It is 
reasonable to expect a responsible corporation to make the protection of the envi-
ronment and sustainability part of its business practices.
23  Ethics and Professional Responsibility

323
Unethical business practices refer to those business actions that do not meet the 
standard of acceptable business operations, and they give the company a bad reputa-
tion. It may be that the entire business culture is corrupt or it may be result of the 
unethical actions of an employee. It is important that such practices be exposed, and 
this may place an employee in an ethical dilemma (i.e., the loyalty of an employee 
to the employer versus what is the right thing to do such as exposing the unethical 
practices).
Some accepted practices in the workplace might cause ethical concerns. For 
example, in many companies, it is normal for the employer to monitor email and 
Internet use to ensure that employees do not abuse it, and so, there may be grounds 
for privacy concerns. On the one hand, the employer is paying the employee’s salary 
and has a reasonable expectation that the employee does not abuse email and the 
Internet. On the other hand, the employee has reasonable rights of privacy provided 
computer resources are not abused.
The nature of privacy is relevant in the business models of several technology 
companies. For example, Google specializes in Internet-based services and prod-
ucts, and its many products include Google Search (the world’s largest search 
engine); Gmail for email; and Google Maps (a web mapping application that offers 
satellite images and street views). Google’s products gather a lot of personal data, 
and create revealing profiles of everyone, which can then be used for commercial 
purposes.
A Google search leaves traces on both the computer and in records kept by 
Google, which has raised privacy concerns, as such information may be obtained by 
a forensic examination of the computer, or in records obtained from Google or the 
Internet Service Providers (ISP). Gmail automatically scans the contents of emails 
to add context sensitive advertisements to them and to filter spam, which raises 
privacy concerns, as it means that all emails sent or received are scanned and read 
by some computer. Google has argued that the automated scanning of emails is done 
to enhance the user experience, as it provides customized search results, tailored 
advertisements, and the prevention of spam and viruses. Google’ maps provides 
location information which may be used for targeted advertisements.
23.3  What Is Computer Ethics?
Computer ethics is a set of principles that guide the behavior of individuals when 
using computer resources. Several ethical issues that may arise include intellectual 
property rights, privacy concerns, as well as the impacts of computer technology on 
wider society.
The Computer Ethics Institute (CEI) is an American organization that examines 
ethical issues that arise in the information technology field. It published the well-­
known ten commandments on computer ethics (Table  23.1) in the early 1990s 
[Bar:92], which attempted to outline principles and standards of behavior to guide 
people in the ethical use of computers.
23.3  What Is Computer Ethics?

324
The first commandment says that it is unethical to use a computer to harm another 
user (e.g., destroy their files or steal their personal data), or to write a program that 
on execution does so. That is, activities such as spamming, phishing and cyberbul-
lying are unethical. The second commandment is related and may be interpreted 
that malicious software and viruses that disrupt the functioning of computer sys-
tems are unethical. The third commandment says that it is unethical (with some 
exceptions such as dealing with cybercrime and international terrorism) to read 
another person’s emails, files and personal data, as this is an invasion of their 
privacy.
The fourth commandment states that the theft or leaking of confidential elec-
tronic personal information is unethical (computer technology has made it easier to 
steal personal information). The fifth commandment states that it is unethical to 
spread false or incorrect information (e.g., fake news or misinformation spread via 
email or social media). The sixth commandment states that it is unethical to obtain 
illegal copies of copyrighted software, as software is considered an artistic or liter-
ary work that is subject to copyright. All copies should be obtained legally.
The seventh commandment states that it is unethical to break in to a computer 
system with another user’s id and password (without their permission), or to gain 
unauthorized access to the data on another computer by hacking into the computer 
system. The eight commandment states that it is unethical to claim ownership of a 
work that is not yours (e.g., of a program written by another).
The ninth commandment states that it is important for companies and individuals 
to think about the social impacts of the software that is being created, and to create 
software only if it is beneficial to society (i.e., it is unethical to create malicious 
software). The tenth commandment states that communication over computers and 
the Internet should be courteous, as well as showing respect for others (e.g., no 
abusive language or spreading false statements).
Table 23.1  Ten commandments on computer ethics
No. Description
1.
Thou shalt not use a computer to harm other people.
2.
Thou shalt not interfere with other people’s computer work.
3.
Thou shalt not snoop around other people’s computer files.
4.
Thou shalt not use a computer to steal.
5.
Thou shalt not use a computer to bear false witness.
6.
Thou shalt not copy or use proprietary software for which you have not paid.
7.
Thou shalt not use other people’s computer resources without authorization or proper 
compensation.
8.
Thou shalt not appropriate other people’s intellectual output.
9.
Thou shalt think about the social consequences of the programs that you are writing or 
designing.
10.
Thou shalt always use a computer in ways that ensure consideration and respect for your 
fellow humans.
23  Ethics and Professional Responsibility

325
23.3.1  Ethics and Artificial Intelligence
We discussed Weizenbaum’s Eliza program in Chap. 22, and the program inter-
acted with a user sitting at an electric typewriter, in English, in the manner of a 
Rogerian psychotherapist. This was one of the earliest natural language processing 
programs, and many users believed that Eliza had real understanding, and they 
began to unburden themselves in long computer sessions.
The program provided very convincing human-like interaction and Weizenbaum 
was shocked to discover that so many users were convinced that the program had 
real understanding, and users spent hours sharing their personal problems with the 
program. It led Weizenbaum to think about the ethics and implications of the artifi-
cial intelligence field, and the ability of a relatively trivial program to deceive a 
naïve user to reveal personal information. He became a leading critic of the AI field, 
and an advocate for professional and social responsibility.
His Eliza program demonstrated the threat that AI poses to privacy. It is con-
ceivable that an AI program may be developed in the future that is capable of under-
standing speech and natural languages. Such a program could theoretically 
eavesdrop on every phone conversation and email, and gather private information 
on what is said, and who is saying it. Such a program could be used by a state to 
suppress dissent, and to eliminate those who pose a threat.
23.3.2  Robots and Ethics
It is, of course, essential that intelligent machines behave ethically, and have a moral 
compass to distinguish right from wrong. It remains an open question as to how to 
teach a robot right from wrong, and in view of the recent progress that has been 
made in the AI field, the time is approaching where machines will routinely make 
ethical decisions.
For example, it is reasonable to expect that driverless cars (self-driving vehicles) 
will be common on the road in the next 10–20 years. A driverless car is a vehicle 
that can sense its environment, and navigate a route without human intervention 
(see Chap. 22). Suppose, a self-driving vehicle is travelling on a road and two chil-
dren roll off a grassy bank on to the road and there is no time for the vehicle to 
brake. However, if the vehicle swerves to the left it can avoid the children but hit an 
oncoming motorbike. Which decision should the car make and how should it make 
such a decision?
This is a variant of the trolley problem, which is a famous thought experiment in 
ethics. A train is rushing down a track out of control as its brakes have failed. 
Disaster lies ahead as five people are tied to the track and will perish in the absence 
of action. There is sufficient time to flick the points and divert the train down a side 
track where there is one man tied to the track. Is it ethical to divert the train to do 
23.3  What Is Computer Ethics?

326
this? Most people would be inclined to take the view that this is the best (least 
worst) possible outcome.
There is a controversial variant of the problem where the train is rushing toward 
five people and you are standing on top of a footbridge overlooking the track next 
to a man with a very bulky rucksack. The only way to save the five people is to push 
the man to his doom, as his rugsack will block the train and save the five. Is it ethical 
to deliberately kill or sacrifice another human being to save five others? Most people 
would say no to this deliberate killing, but it would be valid in the utilitarian school 
of ethics, which seeks to maximize happiness in the world.
Even though the trolley problem is a thought experiment, it is conceivable that a 
driverless car will face situations where a moral choice must be made (e.g., who to 
harm or injure such as pedestrians, passengers or driver). Clearly, this raises the 
importance of the type of ethics that are programmed into the car, and who is to 
decide what ethics are programmed into a car?
Teaching ethics may involve programming in certain principles, and then the 
machine learns from scenarios on how to apply the principles to new situations. 
There is a need for care with machine learning as the machine may learn the wrong 
lessons, or as its learning evolves, it may not be possible to predict its behavior in 
the future. Further questions arise as to who is to be held accountable in the event of 
a machine making incorrect or unethical decisions. For further information on the 
feasibility of teaching ethics to robots, see the interesting BBC article “Can we 
teach robots ethics?” [BBC:17].
23.4  Parnas on Professional Responsibility
We discussed Parnas’s views on software engineering and professional responsibil-
ity of software engineers in Chap. 16. Software engineering involves multiperson 
construction of multiversion programs. It requires the engineer to state precisely the 
requirements that the software product is to satisfy, and to produce designs that will 
meet these requirements.
Parnas is a strong advocate of a classical engineering approach, and he argues 
that computer scientists need the right education to apply scientific and mathemati-
cal principles in their work. Software engineers need education on specification, 
design, turning designs into programs, software inspections and testing. The educa-
tion should enable the software engineer to produce well-structured programs using 
module decomposition and information hiding.
He argues that software engineers have individual responsibilities as profession-
als. They are responsible for designing and implementing high-quality and reliable 
software that is safe to use. They are also accountable for their own decisions and 
actions, and have a responsibility to object to decisions that violate professional 
standards. They have a duty to their clients to ensure that they are solving the real 
problem of the client, and need to be honest about current capabilities when asked 
23  Ethics and Professional Responsibility

327
to work on problems that have no appropriate technical solution, rather than accept-
ing a contract for something that cannot be done.1
The licensing of a professional engineer provides confidence that the engineer 
has the right education, experience to build safe and reliable products. The licensing 
of an engineer requires that the engineer completes an accepted engineering course, 
and understands the professional responsibility of an engineer. The professional 
body is responsible for enforcing standards and certification. The term “engineer” 
is a title that is awarded on merit, but it also places responsibilities on its holder.
The membership of the professional engineering body requires the member to 
adhere to the code of ethics of the profession. The code of ethics will detail the ethi-
cal behavior and responsibilities, including those given in Table 23.2.
23.5  ACM Code of Ethics and Professional Conduct
The Association of Computing Machinery (ACM) has defined a code of ethics and 
professional conduct for its members. The general obligations are detailed in 
Table 23.3.
23.6  British Computer Society Code of Conduct
The British Computer Society (BCS) has a code of conduct that defines the stan-
dards expected of BCS members, and it applies to all grades of members during 
their professional work. Any known breaches of the BCS codes by a member are 
investigated by the BCS, and appropriate disciplinary procedures followed. The 
main parts of the BCS code of conduct are listed in Table 23.4.
1 Parnas applied this professional responsibility faithfully when he argued against the Strategic 
Defence Initiative (SDI), as he believed that the public (i.e., taxpayers) were being misled and that 
the goals of the project were not achievable.
Table 23.2  Professional responsibilities of software engineers
No.
Responsibility
1.
Honesty and fairness in dealings with clients
2.
Responsibility for actions
3.
Continuous learning to ensure appropriate knowledge to 
serve the client effectively
23.6  British Computer Society Code of Conduct

328
Table 23.3  ACM code of conduct (general obligations)
No. Area
Description
1.
Contribute to society 
and human 
well-being.
Computer professionals must strive to develop computer systems 
that will be used in socially responsible ways and have minimal 
negative consequences.
2.
Avoid harm to 
others.
Computer professionals must follow best practice to ensure that 
they develop high-quality systems that are safe for the public. The 
professional has a responsibility to report any signs of danger in the 
workplace that could result in serious damage or injury.
3.
Be honest and 
trustworthy.
The computer professional will give an honest account of their 
qualifications and any conflicts of interest. The professional will 
make accurate statement on the system and the system design, and 
will exercise care in representing ACM.
4.
Be fair and act not to 
discriminate.
Computer professionals are required to ensure that there is no 
discrimination in the use of computer resources, and that equality, 
tolerance, and respect for others are respected.
5.
Respect property 
rights.
The professional must not violate copyright or patent law, and only 
authorized copies of software should be made.
6.
Respect intellectual 
property.
Computer professionals are required to protect the integrity of 
intellectual property and must not take credit for another person’s 
ideas or work.
7.
Respect the privacy 
of others.
The professional must ensure that any personal information 
gathered for a specific purpose is not used for another purpose 
without the consent of the individuals. User data observed during 
normal system operation must be treated with the strictest 
confidentiality.
8.
Respect 
confidentiality.
The professional will respect all confidentiality obligations to 
employers, clients, and users.
Table 23.4  BCS Code of conduct
Area
Description
Public interest
Due regards to rights of third parties.
Conduct professional activities without discrimination
Promote equal access to IT.
Professional competence and 
integrity
Only do work within professional competence.
Do not claim competence that you do not possess.
Ongoing development of knowledge/skills.
Avoid injuring others.
Reject bribery and unethical behavior.
Duty to relevant authority
Carry out professional responsibilities with due care and 
diligence.
Exercise professional judgment.
Accept professional responsibility for work.
Duty to the profession
Uphold reputation of profession and BCS.
Seek to improve professional standards.
Act with integrity.
Support other members in their professional development.
23  Ethics and Professional Responsibility

329
23.7  Review Questions
23.8  Summary
Ethics is a branch of philosophy that deals with moral questions such as what is 
right or wrong, and what is the right behavior for an individual in a given situation? 
There are various schools of ethics such as the relativist position; cultural relativ-
ism; deontological ethics; and utilitarianism.
Business ethics (also called corporate ethics) is concerned with ethical principles 
and moral problems that arise in a business environment. They refer to the core 
principles and values of the organization, and apply throughout the organization. 
The ethical issues include the rights and duties between a company and its employ-
ees, customers, and suppliers.
Professional ethics are a code of conduct that governs how members of a profes-
sion deal with each other and with third parties. It defines its fundamental principles 
and is an indication of its professionalism.
Several organizations such as the Association Computing Machinery (ACM) and 
British Computer Society (BCS) have developed a code of conduct for their mem-
bers, and violations of the code by members are subject to investigations and disci-
plinary procedures.
	1.	 What is ethics?
	2.	 Describe the main schools of ethics.
	3.	 What is business ethics?
	4.	 Give examples of unethical behavior.
	5.	 Discuss the relevance of the Eliza program to computer ethics.
	6.	 Describe Parnas’s contributions to the debate concerning the professional 
responsibility of software engineers.
	7.	 Describe the ACM Code of Ethics and professional conduct.
	8.	 Describe the BCS Code of conduct.
23.8  Summary

331
© The Author(s), under exclusive license to Springer Nature 
Switzerland AG 2021
G. O’Regan, A Brief History of Computing, 
https://doi.org/10.1007/978-3-030-66599-9_24
Chapter 24
Legal Aspects of Computing
24.1  Introduction
Legal aspects of computing are concerned with the application of the legal system 
to the computing field. This chapter explores several legal aspects of digital infor-
mation and software, as well as legal aspects of the Internet.
We discuss intellectual property law including patents, copyright, trademarks, 
and trade secrets. Patents provide legal protection for intellectual ideas; copyright 
law protects the expression of an idea; and trademarks provide legal protection of 
names or symbols.
A software license is a legal agreement between the copyright owner and the 
licensee, which governs the use or distribution of software to the user. The two most 
common categories of software licenses that may be granted under copyright law 
are those for proprietary software and those for free open-source software.
We discuss the legal aspects of bespoke software development, where a legal 
contract is prepared between the supplier and the customer. This will generally 
include a statement of work that stipulates the deliverables to be produced, and it 
may also include a service level agreement and an Escrow agreement.
We discuss the nature of electronic commerce including transactions to place an 
order, the acknowledgment of the order, the acceptance of the order, and order 
fulfillment.
We discuss the problem of hacking where a hacker is a person who uses his 
computer skills to gain unauthorized access to a computer system. We distinguish 
between ethical white hat hackers and malicious black hat hackers. We discuss com-
puter crime including the unauthorized access of computer resources, the theft of 
personal information, cyberextortion, and denial of service attacks.
Key Topics
Intellectual property
Patents, copyright, and trademarks
Software licenses
Bespoke software
E-commerce law
Computer crime
Hackers and privacy
Freedom of speech and censorship
Cyberextortion

332
24.2  Intellectual Property
Intellectual property law deals with the rules that apply in protecting inventions, 
designs, and artistic work, and in enforcing such rights. Intangible assets such as 
software designs or inventions may be protected in a similar way to the protection 
of private property, and the inventor is generally granted exclusive rights to the 
invention for a defined period. This provides the inventor the incentive to develop 
creative works that may benefit society, as it allows the owner of the invention to 
profit from their work without fear of misappropriation by others.
The main forms of intellectual property are patents, copyright, and trademarks. 
Patents give inventors exclusive rights to their invention for a specified period (pos-
sibly up to 20 years), or to profit from the invention by transferring the right to 
another party. A patent protects innovative ideas and concepts, and the invention 
itself must be novel and more than an obvious next step from existing technology. 
The patent needs to be filed at the Patent Office, and the patent gives the inventor 
protection against patent infringement in a specific country or region of the world.
A copyright applies to original writing, music, motion pictures, and other original 
intellectual and artistic expressions. It does not protect the underlying idea as such, 
and what is protected is the expression of the idea. Copyrights are exclusive rights 
to make copies of the expression, where the ways of expressing ideas are 
copyrightable. Computer software source code is protected by copyright law. The 
term “fair use” refers to the permitted limited use of copyrightable material without 
requiring permission from the copyright owner.
A trademark protects names or symbols that are used to identify goods or 
services, and their purpose is to avoid confusion and to help customers to distinguish 
one brand from another.
A trade secret is information that provides a competitive advantage over others, 
and it is of value only if it is kept secret. It applies in the computer sector where 
programs may use algorithms that are unknown to others1.
24.2.1  Patent Law
Patents protect innovative ideas and concepts and give the inventor protection 
against infringement, and allow the inventor to profit from their work. The invention 
needs to be precisely described including how it is unique from existing technology, 
the invention needs to be filed at the Patent Office. A successful patent must be 
novel (more than an obvious next step from existing technology) and there must be 
no existing prior art. There needs to be a good business case for the patent (i.e., the 
idea must be such that competitors will need to use the invention and are unable to 
bypass the invention), and once the patent has been described at the right level of 
1 It is not illegal to use reverse engineering to try to discover the trade secret.
24  Legal Aspects of Computing

333
detail by the inventor, there needs to be a business decision on whether to file the 
patent at the Patent Office or not (it may be that the revenue return from the patent 
may be insufficient to justify a filing at the patent office).2
The prosecution of the patent at the Patent Office will be done by a patent 
attorney, and it will require a detailed search to ensure that there is no existing prior 
art that would invalidate the patent application. Finally, the Patent Office grants (or 
rejects) the patent, and the inventor may then earn a royalty fee from the invention 
for a defined period (based upon its use).
A patent should have an informative title as well as a concise summary of the 
invention. It needs to provide a description of the current state of the art as well as a 
technical description of the invention. It needs to highlight the applications and 
advantages of invention, and drawings should be included. It needs to employ clear 
wording and a glossary may be required. It is essential that the invention is novel 
and more than an obvious next step, and more than a transpose of existing technol-
ogy. It needs a good business case, and it is desirable that competitors are unable to 
bypass the invention (as otherwise competitors will be able to avoid the payment of 
a license fee for its use).
The status of a patent application may be unassessed (if it has not been subject to 
a business review), dropped (the business review decides that it should not proceed 
any further), filed (an application has been made to the patent office), prosecuted 
and granted (the patent office has awarded the patent), defensive publication (it has 
been decided not to file an application at the patent office, but to publish an article 
on the invention placing the invention in the public domain, and thereby preventing 
a competitor from lodging a patent application).
24.2.2  Copyright Law
Copyrights apply to original writing and to original intellectual and artistic 
expressions, and it protects the expression of the idea rather than facts or the idea 
itself. Copyright law protects literary, musical, and artistic works such as poetry, 
songs, movies, and computer software. It provides exclusive rights to make copies 
of the expression (subject to copyright law and fair use), where the ways of 
expressing ideas are copyrightable.
A copyright gives the copyright owner rights to exclude others from using or 
copying the finished work, and most copyrights are generally valid for the creator’s 
lifetime plus 70 years (the exact period depends on the jurisdiction as copyright 
laws vary between countries).
2 The decision may be to put the invention in the public domain with a defensive publication 
thereby preventing competitors from filing a patent for the invention. We discussed how the ENIAC 
patent was ruled to be invalid (see Chap. 4) due to the existence of the ABC computer as prior art 
and Von Neumann’s draft report on EDVAC.
24.2  Intellectual Property

334
The term “fair use” refers to the permitted limited use of copyrighted material 
without requiring permission from the copyright owner. There are several factors 
that need to be considered before deciding whether fair use may be applied such as 
the purpose of use (e.g., non-profit educational use), the amount used (e.g., it is 
generally valid to use a small portion of the work for criticism or for education pur-
poses), the amount used as a proportion of the whole of the copyrighted work, and 
the effect of use on the market or value of the copyrighted work. The defendant 
bears the burden of proving fair use in any litigation on copyright infringement.
Computer software source code was granted protection by copyright law from 
the mid-1970s, which means that the reproduction of the computer software created 
by software developers and software companies is protected. The copyright grants 
the author the right to exclude others from making copies, and the owners of the 
copies have the right to make additional copies (for archival purposes) without the 
authorization of the copyright owner. Further, owners of copies have the right to sell 
their copies.
This has led the software sector to move toward licensing their software rather 
than selling it. There is some software code that is freely available, and this includes 
software created by the free software movement (which began in the mid-1980s), 
the open-source initiative (which began in the late 1990s as a move that wished to 
highlight the benefits of freely available source code), or software that is in the pub-
lic domain and that is therefore not subject to copyright. Open-source software 
(OSS) is software that is freely available under an open-source license to study, 
change, and distribute to anyone for any purpose.
24.2.3  Trademarks
Trademarks protect names or symbols that are used to identify goods or services, 
and help customers to distinguish one brand from another. Trademark rights come 
from actual use, and a trademark does not expire after a fixed period provided it 
continues to be used. Brand names, slogans, and logos are examples.
The registration of a trademark is not mandatory as rights to a mark may be 
granted based on its use. A registered trademark is indicated by ®, whereas an 
unregistered trademark is indicated by TM for goods and SM for services.
24.3  Software Licensing
A software license is a legal agreement between the copyright owner and the 
licensee, which governs the use or distribution of software to the user (licensee). 
Computer software code is protected under copyright law in most countries, and a 
typical software license grants the user permission to make one or more copies of 
24  Legal Aspects of Computing

335
the software, where the copyright owner retains exclusive rights to the software 
under copyright law.
The two most common categories of software licenses that may be granted under 
copyright law are those for proprietary software, and those for free open-source 
software (FOSS). The rights granted to the licensee are quite different for each of 
these categories, where the user has the right to copy, modify and distribute (under 
the same license) software that has been supplied under an open-source license, 
whereas proprietary software typically does not grant these rights to the user.
The licensing of proprietary software typically gives the owner of a copy of the 
software the right to use it (including the rights to make copies for archival pur-
poses). The software may be accompanied by an end-user license agreement 
(EULA) that may place further restrictions on the rights of the user. There may be 
restrictions on the ownership of the copies made, and on the number of installations 
allowed under the term of the distribution. The ownership of the copy of the soft-
ware often remains with the copyright owner, and the end user must accept the 
license agreement to use the software.
The most common licensing model is per single user, and the customer may 
purchase a certain number of licenses over a fixed period. Another model employed 
is the license per server model (for a site license), or a license per dongle model, 
which allows the owner of the dongle to use the software on any computer. A license 
may be perpetual (it lasts forever), or it may be for a fixed period (typically one year).
The software license may include maintenance for a period (typically one year), 
and the maintenance agreement generally includes updates to the software during 
that time and it may also cover a limited amount of technical support. The two par-
ties may sign a service level agreement (SLA), which stipulates the service that will 
be provided by the service provider. This will generally include timelines for the 
resolution of serious problems, as well as financial penalties that will be applicable 
where the customer service performance does not meet the levels defined in the SLA.
Free and open-source licenses are often divided into two categories depending 
on the rights to be granted in the distribution of the modified software. The first 
category aims to give users unlimited freedom to use, study, and modify the soft-
ware, and if the user adheres to the terms of an open-source license such as GNU or 
General Public License (GPL), the freedom to distribute the software and any 
changes made to it. The second category of open-source licenses gives the user 
permission to use, study, and modify the software, but not the right to distribute it 
freely under an open-source license (it could be distributed as part of a proprietary 
software license).
24.3.1  Software Licensing and Failure
Software license agreements generally include limited warranties on the quality of 
the licensed software, and they often provide limited remedies to the customer when 
the software is defective. The software vendor typically promises that the software 
24.3  Software Licensing

336
will conform to the software documentation for a specified period (the warranty 
period), and the software warranty generally excludes problems that are not caused 
by the software or are beyond the software vendor’s control.
The customers are generally provided with limited remedies in the case of 
defective software (e.g., the replacement of the software with a corrected version, or 
termination of the user’s right to use the defective software and a refund of the 
license fee). The payment of compensation for loss or damage is generally excluded 
in the software licensing agreement.
Software licensing agreements are generally accompanied by a comprehensive 
disclaimer that protects the software vendor from any liability (however remote) 
that might result from the use of the software. It may include statements such as “the 
software is provided ‘as is’, and that the customers use the software at their 
own risk.”
A limited warranty and disclaimer limit the customer’s rights and remedies if the 
licensed software is defective, and so the customer may need to consider how best 
to manage the associated risks.
24.4  Bespoke Software Development
Bespoke software (or custom software) is software that is developed for a specific 
customer or organization, and it needs to satisfy the defined customer requirements. 
The selection of the supplier needs to be rigorous to ensure that the selected supplier 
has the capability to deliver a high-quality and reliable solution on time and on bud-
get. A legal agreement is drawn up between the organization and the selected sup-
plier, which states the terms and conditions of the contract, as well as the statement 
of work.
The statement of work (SOW) details the work to be carried out, the deliverables 
to be produced, when they will be produced, the personnel involved their roles and 
responsibilities, any training to be provided, and the standards to be followed. The 
agreement will need to be signed by both parties, and may (depending on the type 
of agreement) include:
–– Legal contract
–– Statement of work
–– Implementation plan
–– Training plan
–– User guides and manuals
–– Customer support to be provided
–– Service level agreement
–– Escrow agreement
–– Warranty period
24  Legal Aspects of Computing

337
A service level agreement (SLA) is an agreement between the customer and 
service provider which specifies the service that the customer will receive as well as 
the response time to customer issues and problems.
An Escrow agreement is an agreement made between two parties where an 
independent trusted third-party acts as an intermediary between both parties. The 
intermediary receives money from one party and sends it to the other party when 
contractual obligations are satisfied.
The law of tort refers to a civil wrong where one party (the defendant) is held 
accountable for their actions (by the plaintiff). There are several actions that the 
defendant could be held accountable, for example, negligence, trespass, misstate-
ment, product liability, defamation, and so on. For example, the defendant may be 
accused of negligence and a breach of his duty of care, where damage that was 
reasonably foreseeable was caused by negligence.
24.5  E-commerce and the Law
The invention of the World Wide Web led to a revolution in business with commerce 
conducted over the web, e-commerce sites are ubiquitous with business marketing 
and selling their products to customers around the world. The website needs to be 
carefully designed so that users can easily navigate its catalog of products, and 
make an informed decision on which products to purchase. It needs to provide infor-
mation about the business, its address and contact details, its products and their 
prices, the shipping costs, and so on.
The user may select several products/services to purchase and may place an 
electronic order (the website will include an order/buy button). An acknowledgment 
email is sent shortly after placing the order (this is confirming that an order has been 
received but it is not confirming acceptance of the order). A separate email is sent 
confirming acceptance of the order, and this is confirmation of the electronic trans-
action between both parties (a contract now exists between both parties). The terms 
and conditions of purchase are specified either on the website or included in the 
email confirming the acceptance of the order. This will include information on the 
delivery period as well as the consumer’s cancellation rights (during the cooling-off 
period). Further, the terms of purchase must be fair and reasonable and written 
clearly, with unfair terms legally unenforceable.
The Internet is global with business conducted internationally over the World 
Wide Web. However, a business is subject to the e-commerce laws of the country in 
which it is doing business: that is, the law is national, and so a business needs to be 
familiar with and follow the specifics of the e-commerce law in the particular juris-
diction in which it is doing business. E-commerce law is not radically different from 
standard commerce law, and in general, it follows the same basic principles. For 
example, false advertising and copyright infringement are not allowed, and if an 
item cannot be sold in a physical shop in a given country then it cannot legally be 
sold online in that country.
24.5  E-commerce and the Law

338
Privacy is one area where e-commerce law differs from commerce law, since an 
online business collects a lot of information about the customer (financial and non-­
financial). It is essential that the online business has an appropriate privacy policy 
and that it protects the privacy of the customer’s information. Data protection laws 
refer to laws that define the ways in which information about living people may be 
legally used, with the goal of protecting people from its misuse.
24.6  Free Speech and Censorship
Free speech and censorship are the opposites of one another, with censorship 
concerned with suppressing or removing anything deemed objectionable (e.g., 
obscene or indecent material). For example, TV networks often bleep out swear 
words that are potentially offensive to their audience. State censorship is concerned 
with controlling its population, and preventing information and free expression that 
could lead to protests or revolution, and so states may restrict access to specific 
websites to limit the information that their citizens may receive. For example, the 
Great Firewall of China (GFW) regulates the use of the Internet in China, and it 
blocks access to selected foreign websites (e.g., Google and Facebook).
Freedom of speech (or expression) is concerned with the right to express one’s 
opinions and ideas without fear of censorship or government sanction. It is recog-
nized as a right under Article 19 of the UN Declaration of Human rights, but it is a 
right that is subject to special duties and responsibilities (i.e., freedom of speech is 
not an absolute right, and is subject to limitations such as libel, slander, obscenity, 
defamation, hate speech, public order, and incitement to violence). Freedom of 
speech is a key tenet of western democracies, but it places responsibilities on the 
citizens.
Social media sites are testing the legal boundaries of free speech, and the question 
is how far a person’s public speech may inflame its audience before it may be 
restrained. The use of Facebook as a tool for social protest and revolution was dis-
cussed in Chap. 19.
24.7  Computer Privacy in the Workplace
The right of an employee to privacy in the workplace has become more controversial 
in the digital age. Employers now have technology to monitor the use of computer 
resources in the workplace, and may monitor communications such as the Internet 
and electronic mail. Employees may naturally feel that such monitoring is a violation 
of their privacy, but employee activities when using an employer’s computer systems 
are generally not protected by privacy laws.
That is, emails are company property, and employers generally have the right to 
monitor and view such emails to check for productivity, inappropriate use, and so 
24  Legal Aspects of Computing

339
on. Further, emails may be used as evidence in cases of proof of employee miscon-
duct or wrongdoing.
Further, employers have the right to track websites visited by their employees to 
ensure that an employee is not spending an excessive amount of time at a specific 
site. Employers have the right to block or limit the time that an employee may 
spend online.
Employees have rights to privacy in the workplace but these need to be balanced 
against the employers’ right to monitor its business operations. That is, while it is 
reasonable for an employer to monitor email and Internet use to ensure that employ-
ees do not abuse it and that the business is operating effectively, an employee has 
reasonable rights of privacy if computer resources are used appropriately. And so, it 
is about balancing rights given that on the one hand, the employer is paying the 
employee’s salary and has a reasonable expectation that the employee does not 
abuse email and the Internet, and on the other hand, the employee has reasonable 
expectations of privacy provided that the computer resources are used appropriately 
and not abused.
24.8  Computer Crime
It is common in the major urban areas to encounter dangers in some streets or 
neighborhoods. Similarly, the Internet has dangers with hackers, scammers, and 
web predators lurking in the shadows. A hacker may be accessing a computer 
resource without authorization with the intention of committing an unlawful act. 
The hacker’s activities may be limited to eavesdropping (listening to a conversation), 
or it may be an active man-in-the-middle attack, where the hacker may possibly 
alter the conversation between two parties.
One of the earliest Internet attacks was back in 1988 when a graduate student 
from Carnegie Mellon University released a program on the Internet (an Internet 
Worm) that exploited security vulnerability in the mail software to automatically 
replicate itself locally and on remote machines. It affected lots of machines and 
effectively shut down the Internet for 1–2 days.
Today, more and more individuals and companies are online, and networking 
systems and computers have become quite complex. There has been a major growth 
in attacks on businesses and individuals, and so it is essential to consider computer 
and network security. The Internet was developed based on trust with security fea-
tures added as a response to different types of attacks.
There are several threats associated with network connectivity such as 
unauthorized access (a break-in by an unauthorized person); disclosure of sensitive 
information to people who should not have access to the information; and denial of 
service (DoS), where there is a degradation of service that makes it impossible to 
access the website and perform productive work.
There may be attacks that lead to defacement of the websites, bank fraud, stealing 
of credit card numbers, hoax (scam) letters, phishing emails that appear to come 
24.8  Computer Crime

340
from legitimate parties but contain links to a site that is different from the one that 
the user expects to go to, intercepting of packets, and password sniffing. Phishing is 
an attempt to obtain sensitive information such as usernames, passwords, and credit 
card details with the intention of committing fraud.
A computer virus is a self-replicating computer program that is installed on the 
user’s computer without consent. It is a malicious program that replicates itself on 
execution and infects other computer programs by modifying them. A virus often 
performs a harmful activity on infected computers such as accessing private infor-
mation, spamming email contacts, or corrupting data. It is not a crime per se to write 
a computer virus or malicious software. However, if that software or other malware 
spreads to other computers, then it could be considered a crime.
Cyberextortion is a crime that involves an attack, or threat of an attack, 
accompanied by a demand for money to stop the attack. They are often initiated 
through malware in an email attachment. These may include denial of service 
attacks or ransomware attacks that encrypts the victim’s data. The victim is then 
offered the private key to resolve the encryption in return for payment. Companies 
need to manage the risks associated with cyberextortion, and to ensure that end 
users are properly educated on malware and phishing.
Another form of computer crime is Internet fraud where one party is intent on 
deceiving another. Among these are hoax email scams, which are designed to 
deceive, and fraud the email recipient. These may include the Nigeria 419 scams, 
where the email recipient is offered a share of a large amount of money trapped in 
their country, if the recipient will help in getting the money out of the country. The 
recipient may be asked for their bank account details to help them to transfer the 
money (this information will later be used by them to steal funds), or the request 
may be to pay fees or taxes to release payment with further fees requested. Of 
course, the money will never arrive (if an email looks like it really is too good to be 
true then it has a high probability of being a scam).
24.8.1  Dark Side of the Internet
The Internet has a dark and secret side where harmless or sinister activities may be 
conducted. These include online services such as online pornography and adult chat 
rooms, escort sites, and so on. There are more sinister sites where a consenting adult 
unintentionally downloads malicious software from an adult chat room which 
infects the computer, and allows someone to hack into the machine’s camera, and 
the adult is captured on camera performing compromising acts, and is then con-
tacted by the gang or fraudster with demands for a payout (sextortion) to prevent the 
images and video being made public.
Other unsavory activities include revenge porn where one of the parties to the 
relationship releases private intimate images/videos of their former partner as an act 
of revenge at the end of the relationship. Sexting is where the sender sends privates 
24  Legal Aspects of Computing

341
images (of himself or herself) to the recipient, and the recipient makes the images 
available publicly (betrayal of trust and the naivety of the sender).
Other distasteful activities include cyberbullying where a child or young adult is 
bullied online by his or her peers, and sometimes there are devastating conse-
quences. The Internet is a great resource but care is required to avoid being a victim 
of its dark side, and this requires education on its dangers as well as on its many 
positive aspects.
24.9  Hacking and Computer Security
A hacker is a person who uses his (or her) computer skills to gain unauthorized 
access to computer files or networks. A hacker may enjoy experimenting with com-
puter technology (the original meaning of the term), but some hackers enjoy break-
ing into systems and causing damage (the modern meaning of the word). Ethical 
(white hat) hackers are former hackers who play an important role in the security 
industry in testing network security, and in helping to create secure products and 
services. Malicious (black hat) hackers (also called crackers) are generally moti-
vated by personal gain, and they exploit security and system vulnerabilities to steal, 
exploit, or sell data.
Many computer systems have vulnerabilities that may be exploited by a 
determined hacker to gain unauthorized entry to the system, and access to 
unauthorized information. It is vital that best practice in software and system 
engineering is employed to develop safe and secure systems, and that known 
vulnerabilities in system security are addressed promptly by updates to the system 
software. Further, it is essential to educate staff on security, and to define (and 
follow) the appropriate procedures to prevent security breaches.
The early hackers were mainly young students (without malicious intent) who 
were exploring the university computer systems (such as the students at 
Massachusetts Institute of Technology in the late 1950s who were interested in 
exploring the IBM 704 computer), and they would enter areas of the system without 
authorization and gain access to privileged resources. They were motivated by 
knowledge, and wished to have a deeper understanding of the systems that they had 
access to. The idea of a hacker ethic was formulated in a book by Steven Levy in the 
mid-1980s [Lev:84], and he outlined several key ethical principles including free 
access to computers and information and improvement to quality of life.
Today, ethical hackers need to obtain permission prior to acting, as their actions 
may potentially cause major disruption to an organization. Responsible (white hat) 
hackers can provide useful information on security vulnerabilities, and in improving 
computer security.
The security of the system refers to its ability to protect itself from accidental or 
deliberate external attacks. There are various security threats in any networked sys-
tem including threats to the confidentiality and integrity of the system and its data, 
and threats to its availability.
24.9  Hacking and Computer Security

342
Therefore, controls are required to enhance security and to ensure that attacks are 
unsuccessful. Encryption is one way to reduce system vulnerability, as encrypted 
data are unreadable to the attacker. There may be controls that detect and repel 
attacks, and these controls are used to monitor the system and to take appropriate 
action to shut down parts of the system or restrict access in the event of an attack. 
There may be controls that limit exposure (e.g., insurance policies and automated 
backup strategies) that allow recovery from the problems introduced.
Security engineering is concerned with the development of systems that can 
prevent malicious attacks and recover from them. It has become an important part 
of software and system engineering, and software developers need to be aware of 
the threats facing a system, and develop solutions to manage them. A risk assessment 
of the security threats facing a system is conducted early in the software development 
process, and this will lead to several security requirements for the system.
The system needs to be designed for security, as it is difficult to add security after 
the system has been implemented. Security loopholes may be introduced in the 
development of the system, and so care needs to be taken to prevent these as well as 
preventing hackers from exploiting security vulnerabilities.
The choice of architecture and how the system is organized is fundamental to the 
security of the system, and different types of systems will require different technical 
solutions to provide an acceptable level of security to its users. The following guide-
lines for designing secure systems are described in [Som:10]:
–– Security decisions should be based on the security policy.
–– A security critical system should fail securely.
–– A secure system should be designed for recoverability.
–– A balance is needed between security and usability.
–– A single point of failure should be avoided.
–– A log of user actions should be maintained.
–– Redundancy and diversity should be employed.
–– Organization of information in system into compartments.
The unauthorized access to the system and the theft of confidential data and 
disruption of its services is unlawful, and subject to the rigors of the law.
24.10  Review Questions
	1.	 What is intellectual property law?
	2.	 Explain the difference between a patent, copyright, and trademark.
	3.	 What is computer crime?
	4.	 Explain how software is licensed to users.
	5.	 What is cyberextortion?
	6.	 Explain the legal aspects of bespoke software development.
	7.	 Explain the difference between ethical and malicious hackers.
	8.	 Discuss e-commerce law and standard commerce law.
24  Legal Aspects of Computing

343
24.11  Summary
Legal aspects of computing are concerned with the legal aspects of digital 
information and software, as well as the legal aspects of the Internet. It deals with 
Intellectual property law including patents, copyright, and trademarks.
A software license is a legal agreement between the copyright owner and the 
licensee, which governs the use or distribution of software to the user (licensee). 
Software license agreements include limited warranties on the quality of the soft-
ware and provide limited remedies to the customer if the software is defective.
Bespoke software (or custom software) is software that is developed for a specific 
customer or organization, and needs to satisfy specific customer requirements. An 
appropriate supplier is selected, and a legal agreement is drawn up, which states the 
terms and conditions of the contract, as well as the statement of work. E-commerce 
law is concerned with laws to regulate online electronic transactions and to protect 
the rights of consumers.
Computer crime includes the unauthorized access to computer resources, the 
theft of personal information, and denial of service attacks. A hacker uses his com-
puter skills to gain unauthorized access to a computer system. Computer crime also 
includes Internet fraud, cyberextortion, and viruses.
24.11  Summary

345
© The Editor(s) (if applicable) and The Author(s), under exclusive license to 
Springer Nature Switzerland AG 2021 
G. O’Regan, A Brief History of Computing, 
https://doi.org/10.1007/978-3-030-66599-9
Glossary
ABC	
Altanasoff-Berry Computer
ACM	
Association for Computing Machinery
ACS	
Advanced Computing Systems
AI	
Artificial Intelligence
ALGOL	
Algorithmic language
AMD	
Advanced Micro Devices
AMPS	
Advanced Mobile Phone System
ANS 	
Advanced Network Services
ANSI	
American National Standards Institute
AP	
Access Point
API	
Application Programmer Interface
ARC	
Augmentation Research Centre
ARPA	
Advanced Research Projects Agency
ASCC	
Automatic Sequence Controlled Calculator
ASCII	
American Standard Code for Information Interchange
AXE	
Automatic Exchange Electric switching system
B2B	
Business to Business
B2C	
Business to Consumer
BASIC	
Beginners All-purpose Symbolic Instruction Code
BBN	
Bolt, Beranek and Newman
BCS	
British Computer Society
BDS	
BeiDou Navigation Satellite System
BIOS	
Basic Input Output System
BNF	
Backus-Naur Form
C-64	
Commodore 64
CDC	
Control Data Corporation
CDMA	
Code Division Multiple Access
CEI	
Computer Ethics Institute
CEO	
Chief Executive Officer

346
CERN	
Conseil European Recherche Nucleaire
CERT	
Certified Emergency Response Team
CMM®	
Capability Maturity Model
CMMI®	
Capability Maturity Model Integration
CMS	
Conversational Management System
COBOL	
Common Business Oriented Language
CODASYL	
Conference on Data Systems Languages
COPQ	
Cost of Poor Quality
COTS	
Customised Off the Shelf
CP	
Control Program
CP/M	
Control Program for Microcomputers
CPU	
Central Processing Unit
CSIRAC 	
Council for Scientific and Industrial Research Automatic Computer
CRT	
Cathode Ray Tube
CSC	
Computer Sciences Corporation
CSR	
Corporate Social Responsibility
CTSS	
Compatible Time-Sharing System
DARPA	
Defence Advanced Research Project Agency
DB	
Database
DBA	
Database Administrator
DBMS	
Database Management System
DDL	
Data Definition Language
DEC	
Digital Equipment Corporation
DL/1	
Data Language 1
DML	
Data Manipulation Language
DNS	
Domain Naming System
DOJ	
Department of Justice
DoS	
Denial of Service
DOS	
Disk Operating System
DRAM	
Dynamic Random Access Memory
DRI	
Digital Research Incorporated
DSDM	
Dynamic Systems Development Method
DSP	
Digital Signal Processing
DVD	
Digital Versatile Disc
EDSAC 	
Electronic Delay Storage Automatic Calculator
EDVAC	
Electronic Discrete Variable Automatic Computer
EMCC	
Eckert-Mauchly Computer Corporation
ENIAC	
Electronic Numerical Integrator and Computer
ESA	
European Space Agency
ETH	
Eidgenössische Technische Hochschule
ETACS	
Extended TACs
ETSI	
European Telecommunications Standards Institute
EULA	
End User License Agreement
FAA	
Federal Aviation Authority
FDMA	
Frequency Division Multiple Access
Glossary

347
FTP	
File Transfer Protocol
FOSS	
Free Open Source Software
GB	
Giga Byte
GECOS	
General Electric Comprehensive Operating System
GFW	
Great Firewall of China
GHz	
Giga-Hertz
GIPS	
Giga Instructions Per Second
GL	
Generation Language
GLONASS	
Global Navigation Satellite System
GNSS	
Global Navigation Satellite System
GNU	
GNU’s Not Unix
GPL	
General Public License
GPS	
Global Positioning System
GPRS	
General Packet Radio Service
GSM	
Global System Mobile
GUAM 	
Generalised Update Access Method
GUI	
Graphical User Interface
HCI	
Human Computer Interaction
HMD	
Head Mounted Display
HP	
Hewlett Packard
HR	
Human Resources
HTML	
Hypertext Markup Language
HTTP	
Hyper Text Transport Protocol
IaaS	
Infrastructure as a Service
IBM	
International Business Machines
IC	
Integrated Circuit
ICBM	
Intercontinental Ballistic Missile
IDMS	
Integrated Database Management System
IDS	
Integrated Data Store
IE	
Internet Explorer
IEC	
International Electrotechnical Commission
IEEE	
Institute of Electrical and Electronic Engineers
IMAP 	
Internet Message Application Protocol
IMP	
Interface Message Processor
IMS	
Information Management System
INWG 	
International Network-Working Group
iOS	
Internetwork operating system
IP	
Internet Protocol
IPCS	
Interactive Problem Control System
IPO	
Initial Public Offering
ISEB	
Information Systems Examination Board
ISO	
International Standards Organization
ISP	
Internet Service Provider
IT	
Information Technology
JAD	
Joint Application Development
Glossary

348
JCL 	
Job Control Language
JVM	
Java Virtual Machine
KB	
Kilo Byte
KLOC	
Thousand Lines of Code
LAN	
Local Area Network
LED	
Light Emitting Diode
LEO	
Lyons Electronic Office
LEO	
Low Earth Orbit
LSI	
Large Scale Integration
MADC 	
Manchester Automatic Digital Computer
MB	
Mega Byte
ME	
Millennium
MEO	
Medium Earth Orbit
MFT 	
Multiple Programming with a Fixed number of Tasks
MIDI	
Musical Instrument Digital Interface
MIPS	
Million Instructions Per Second
MIT	
Massachusetts Institute of Technology
MITS	
Micro Instrumentation and Telemetry System
MOS	
Metal Oxide Semiconductor
MSI	
Medium Scale Integration
MS/DOS	
Microsoft Disk Operating System
MTX	
Mobile Telephone Exchange
MVS	
Multiple Virtual Storage
MVT	
Multiple Programming with a Variable number of Tasks
NAP	
Network Access Point
NASA	
National Aeronautics and Space Administration
NATO	
North Atlantic Treaty Organisation
NCP	
Network Control Protocol
NLS	
oN Line System
NMT	
Nordic Mobile Telephony system
NORAD	
North American Aerospace Defence
NPL	
National Physical Laboratory
NSF	
National Science Foundation
OS	
Operating System
OSS	
Open Source Software
PaaS	
Platform as a Service
PARC	
Palo Alto Research Centre
PC	
Personal Computer
PC/DOS	
Personal Computer Disk Operating System
PDA	
Personal Digital Assistant
PDP	
Programmed Data Processor
PL/M	
Programming Language for Microcomputers
POP	
Post Office Protocol
PTT	
Postal Telephone and Telegraph
RAD	
Rapid Application Development
Glossary

349
RAM	
Random Access Memory
RDBMS	
Relational Database Management System
RIM	
Research in Motion
ROM	
Read Only Memory
RSCS	
Remote Spooling Communications Subsystem
RUP	
Rational Unified Process
SaaS	
Software as a Service
SAGE	
Semi-Automatic Ground Environment
SCP	
Seattle Computer Products
SDC	
Systems Development Corporation
SDI	
Strategic Defence Initiative
SECD	
Stack, Environment, Control, Dump
SEI	
Software Engineering Institute
SID	
Sound Interface Device
SILK	
Speech, Images, Language and Knowledge
SIM	
Subscriber Identity Module
SLA	
Service Level Agreement
SM	
Service Mark
SMS	
Short Message Service
SMTP 	
Simple Mail Transfer Program
SNS	
Social Networking Site
SOA	
Service Oriented Architecture
SOW	
Statement of Work
SPREAD 	
System Programming, Research, Engineering and Design
SQL	
Structured Query Language
SRI	
Stanford Research Institute
SSI	
Small Scale Integration
SSL	
Secure Socket Layer
TACS	
Total Access Communication
TCP	
Transport Control Protocol
TI	
Texas Instrument
TM	
Trade Mark
TSO	
Time Sharing Option
UAT	
User Acceptance Testing
UCD	
User Cantered Design
UCLA	
University of California (Los Angeles)
UDP	
User Datagram Protocol
ULSI	
Ultra Large Scale Integration
UML	
Unified Modelling Language
UNIVAC	
Universal Automatic Computer
URL	
Universal Resource Locator
UTC	
Universal Time Coordinated
VAX	
Virtual Address extension
VBA	
Visual Basic for Applications
VCS	
Video Control System
Glossary

350
VDM	
Vienna Development Method
VLSI	
Very Large Scale Integration
VM	
Virtual Memory
VMS	
Virtual Memory System
VUI	
Voice User Interface
WCDMA	
Wideband CDMA
WIMP	
Windows, Icons, Menus and Pointers
WLAN	
Wireless LAN
WP	
WordPerfect
WPA	
Wi-Fi Protected Access
Glossary

351
© The Editor(s) (if applicable) and The Author(s), under exclusive license to 
Springer Nature Switzerland AG 2021 
G. O’Regan, A Brief History of Computing, 
https://doi.org/10.1007/978-3-030-66599-9
References
	AnDa:14	 Operating Systems: Principles and Practice. Thomas Anderson and Michael Dahlin. 
Recursive Books. 2014.
	AnL:95	
The Heritage of Thales. W.S. Anglin and J. Lambek. Springer Verlag. New York. 1995.
	Bag:12	
Commodore: A Company on the Edge. Second Edition. Brian Bagnall. Variant 
Press. 2012.
	Bar:92	
In Pursuit of a ‘Ten Commandments’ for Computer Ethics. Ramon C.  Barquin. 
Computer Ethics Institute. 1992.
	BBC:17	 Can we teach Robots Ethics. BBC Magazine. October 17th. 2017.
	Bec:00	
Extreme Programming Explained. Embrace Change. Kent Beck. Addison Wesley. 2000.
	Ber:19	
Quantum Computing for Everyone. Chris Bernhardt. MIT Press. 2019.
	Ber:99	
Principles of Human Knowledge. George Berkeley. Oxford University Press. 1999. 
(Originally published in 1710).
	BL:00	
Weaving the Web. Tim Berners-Lee. Collins Book. 2000.
	Blo:04	
The Man Who Could Have Been Bill Gates. Bloomberg Business Week Magazine. 
October 2004.
	Boe:88	
A Spiral Model for software development and enhancement. Barry Boehm. Computer. 
May 1988.
	Boo:48	
The Calculus of Logic. George Boole. Cambridge and Dublin Mathematical Journal. 
Vol. III (1848), pp. 183–98.
	Boo:58	
An Investigation into the Laws of Thought. George Boole. Dover Publications. 1958. 
(First published in 1854)
	Boy:04	
The 360 Revolution. Chuck Boyer. IBM. 2004.
	Brk:75	
The Mythical Man Month. Fred Brooks. Addison Wesley. 1975.
	Brk:86	
No Silver Bullet. Essence and Accidents of Software Engineering. Fred Brooks. 
Information Processing. Elsevier. Amsterdam, 1986.
	Bus:45	
As We May Think. Vannevar Bush. The Atlantic Monthly. Vol. 176, No. 1. July, 1945
	Bux:75	
Software Engineering. Petrocelli. 1975. IN. Buxton, P. Naur and B. Randell. Report 
on two NATO Conferences held in Garmisch, Germany (October1968) and Rome, Italy 
(October 1969).
	By:94	
R.I.P.  Commodore. 1954  – 1994. A look at an innovative industry pioneer, whose 
achievements have been largely forgotten. Tom Halfhill. Byte Magazine. August 1994.
	Ch:82	
Blind Signatures for Untraceable Payments. David Chaum. Advances in Cryptology 
Proceedings of Crypto. 82(3). 199–203. 1982.

352
	ChR:02	
The Role of the Business Model in Capturing Value from Innovation: Evidence from 
Xerox Corporation’s Technology Spin-off Companies. Henry Chesbrough and Richard 
Rosenbloom. Industrial and Corporate Change, vol. 11 (3): 529–555. 2002.
	CK:04	
From Airline Reservation to Sonic the Hedgehog. A History of the Software Industry. 
Martin Campbell-Kerry. MIT Press. 2004.
	CKS:11	 CMMI. Guidelines for Process Integration and Product Improvement. Third Edition. 
Mary Beth Chrissis, Mike Conrad and Sandy Shrum. SEI Series in Software Engineering. 
Addison Wesley. 2011.
	Cod:70	
A Relational Model of Data for Large Shared Data Banks. E.F. Codd. Communications 
of the ACM 13 (6): 377–387. 1970.
	Dat:81	
An Introduction to Database Systems. 3rd Edition. C.J. Date. The Systems Programming 
Series. 1981.
	Dei:90	
Operating Systems. Second Edition, H.M. Deitel. Addison Wesley.1990.
	Des:99	
Discourse on Method and Meditations on First Philosophy, 4th Edition. Rene Descartes. 
Translated by Donald Cress. Hackett Publishing Company. 1999.
	Dij:68	
Go To Statement Considered Harmful. E.W.  Dijkstra. Communications of the 
ACM. March, 1968
	Dij:72	
Structured Programming. E.W. Dijkstra. Academic Press. 1972.
	Dre:86	
Engines of Creation. The Coming Era of Nanotechnology. Eric Drexler Anchor Library 
of Science.1986.
	Edw:11	
The History of Atari Computers. Benj Edwards. PC World. April 21st 2011.
	Fag:76	
Design and Code Inspections to Reduce Errors in Software Development. Michael 
Fagan. IBM Systems Journal 15(3). 1976.
	Fer:03	
A Computer Called LEO: Lyons Tea Shops and the World’s First Office Computer. 
Georgina Ferry. Fourth Estate Ltd. 2003.
	Ger:13	
The Idea Factory: Bell Labs and the Great Age of American Innovation. Jon Gertner. 
Penguin Books. 2013.
	Glb:94	
Software Inspections. Tom Gilb and Dorothy Graham. Addison Wesley. 1994.
	Goe:31	
Kurt Goedel. Undecidable Propositions in Arithmetic. Über formal unentscheidbare 
Sätze der Principia Mathematica und verwandter Systeme, I. Monatshefte für Mathematik und 
Physik 38: 173–98. 1931.
	Gre:17	
Rise of the Machines. Who is the Internet of Things Good For? Adam Greenfield. 
Guardian Article. https://www.theguardian.com/technology/2017/jun/06/internet-of-things-­
smart-home-smart-city. June 6th 2017.
	Hea:56	
Euclid. The Thirteen Books of the Elements. Vol.1. Translated by Sir Thomas Heath. 
Dover Publications, 1956. (First published in 1925)
	Hil:00	
Dealers of Lightning. Xerox PARC and the Dawn of the Computer Age. Michael 
A. Hilzik. Harper Business. 2000.
	Hum:06	 An Enquiry concerning Human Understanding. Digireads.com. David Hume. 2006. 
(Originally published in 1748).
	IGN:14	
IGN Presents: The history of Atari. March 2014. http://www.ign.com/articles/2014/03/20/
ign-presents-the-history-of-atari
	InA:91	
Practical Formal Methods with VDM.  D. Ince and D.  Andrews. McGraw Hill 
International Series in Software Engineering. 1991.
	Jac:99	
The Unified Software Development Process. Ivar Jacobson, Grady Booch and James 
Rumbaugh. Addison Wesley. 1999.
	Jac:05	
The Unified Modelling Language, User Guide. 2nd Edition. Ivar Jacaobson et  al. 
Addison Wesley Professional. 2005.
	KaC:74	
Protocol for Packet Network Interconnections. Bob Kahn and Vinton Cerf. IEEE 
Transactions on Communications Technology. 1974.
	Kan:03	
Critique of Pure Reason. Immanuel Kant. Dover Publications. 2003. Originally pub-
lished in 1781.
References

353
	Ker:81	
Why Pascal is not my favourite language. Brian Kernighan. AT&T Bell 
Laboratories. 1981.
	KeR:78	
The C Programming Language. 1st Edition. Brian Kernighan and Dennis Ritchie.
	Lam:72	
Why Alto? Xerox Inter-Office Memorandum. Butler Lampson. December 1972.
	Lei:03	
Explication de l’Arithmétique Binaire Wilhelm Gottfried Leibniz. Memoires de 
l’Academie Royale des Sciences. 1703.
	LeT:93	
An Investigation of the Therac-25 accidents. Nancy Leveson and Clark Turner. IEEE 
Computer. 26(7): 18–41. 1993.
	Lev:84	
Hackers: Heroes of the Computer Revolution. Steven Levy. O’Reilly Media. 1984.
	Lic:60	
Man-Computer Symbiosis. J.C.R Licklider. IRE Transactions on Human Factors in 
Electronics. Vo. HFE 1, Pages 4–11, March 1960.
	Lov:42	
Sketch of the Analytic Engine invented by Charles Babbage. L.F.  Menabrea, 
Bibliothèque Universelle de Genève, October, 1842, No. 82 Translated by Ada, Augusta, 
Countess of Lovelace.
	MaP:02	
Boo Hoo. Ernst Malmsten and Erik Portanger. $135 Million, 18 Months. . . A Dot.Com 
Story from Concept to Catastrophe. Arrow. 2002.
	Mc:59	
Programs with Common Sense. John McCarthy. Proceedings of the Teddington 
Conference on the Mechanization of Thought Processes. 1959.
	McH:85	 Boole. Des McHale. Cork University Press. 1985.
	MeJ:01	
The Ericsson Chronicle: 125 Years in Telecommunications. John Meurling and Richard 
Jeans. Informations for laget. 2001.
	MEn:10	 Global Positioning System. 2nd Edition. Prater Misra and Per Enge. Ganga-Jamuna 
Press. 2010.
	Mor:65	
Cramming more components onto integrated circuits. Gordon Moore. Electronics 
Magazine. 1965.
	Mot:99	
Motorola (CB)  - A Journey Through Time and Technology. Motorola Museum of 
Electrics and Motorola. Purdue University Press. 1999.
	Nak:08	
Bitcoin: A Peer-to-Peer Electronic Cash System. Satoshi Nakamoto. 2008.
	Nau:60	
Report on the algorithmic language: ALGOL 60. Edited by Peter Naur. Communication 
of the ACM. 3(5), 299–314. 1960.
	Nes:56	
A. Newell and H. Simon. The Logic Theory Machine. IRE Transactions on Information 
Theory, 2, 61–79. 1956.
	OGC:04	 Managing Successful Projects with PRINCE2. Office of Government Commerce. 2004.
	ORg:10	
Introduction to Software Process Improvement. Gerard O’ Regan. Springer Verlag. 2010.
	ORg:13	
Giants of Computing. Gerard O’ Regan. Springer Verlag. 2013.
	ORg:14	
Introduction to Software Quality. Gerard O’ Regan. Springer Verlag. 2014.
	ORg:15	
Pillars of Computing. Gerard O’ Regan. Springer Verlag. 2015.
	ORg:16	
Guide to Discrete Mathematics. Gerard O’Regan. Springer. 2016.
	ORg:17a	 Concise Guide to Software Engineering. Gerard O’ Regan. Springer Verlag. 2017.
	ORg:17b	 Concise Guide to Formal Methods. Gerard O’ Regan. Springer Verlag. 2017.
	ORg:18b	 The Innovation in Computing Companion. Gerard O’ Regan. Springer. 2018.
	ORg:19	
Concise Guide to Software Testing. Gerard O’ Regan. Springer Verlag. 2019.
	ORg:20	
Mathematics in Computing. 2nd Edition. Gerard O’ Regan. Springer Verlag. 2020.
	Par:72	
On the Criteria to be used in Decomposing Systems into Modules. David Parnas. 
Communications of the ACM, 15(12). 1972.
	Por:98	
Competitive Advantage. Creating and Sustaining Superior Performance. Michael 
E. Porter. Free Pres. 1998.
	Pug:09	
Building IBM: Shaping an Industry and its Technology. Emerson W.  Pugh. MIT 
Press. 2009.
	ReS:00	
From Whirlwind to Mitre. K. Redmond and T. Smith. The MIT Press. 2000.
	Res:84	
Mathematics in Civilization. H.L. Resnikoff and R.O. Wells. Dover Publications. 1984.
	Rob:05	
Unix in a Nutshell. 4th Edition. Arnold Robbins. O’Reilly Media. 2005.
References

354
	Roy:70	
The Software Lifecycle Model (Waterfall Model). W.  Royce. In Proc. WESTCON, 
August, 1970.
	RuW:10	 Principia Mathematica. B. Russell and A.N. Whitehead. Cambridge University Press. 
Cambridge. 1910.
	SCA:06	 Standard CMMI Appraisal Method for Process Improvement. CMU/SEI-2006-HB-002. 
V1.2. August 2006.
	Sch:04	
DEC is Dead, Long Live DEC. The Lasting Legacy of Digital Equipment Corporation. 
Edgar Schein. Barrett-Koehler Publishers. 2004.
	Sch:14	
The Tao of Twitter. Changing your Life and Business 140 Characters at a Time. Second 
Edition. Mark W. Schaefer. McGraw-Hill. 2014.
	Sea:80	
Minds, Brains, and Programs. John Searle. The Behavioral and Brain Sciences (3), 
417–457. 1980.
	Sha:37	
A Symbolic Analysis of Relay and Switching Circuits. Claude Shannon. Masters 
Thesis. Massachusetts Institute of Technology. 1937.
	Shn:05	
Designing the User Interface. Bob Snheiderman and Catherine Plaisant. Pearson 
Education. 2005.
	Sho:50	
Electrons and Holes in Semiconductors with applications to Transistor Electronics. 
William Shockley. Van Nostrand. New York. 1950.
	Smi:23	
History of mathematics. D.E. Smith. Volume 1. Dover Publications, New York. 1923.
	Som:10	
Software Engineering. 9th Edition. Ian Sommerville. Pearson. 2011.
	Spi:92	
The Z Notation. A Reference Manual. J.M. Spivey. Prentice Hall International Series in 
Computer Science. 1992.
	Sta:02	
Free Software, free society. Richard Stallman. Free Software Foundation, Inc., 
Boston. 2002.
	Tur:50	
Computing, Machinery and Intelligence. Alan Turing. Mind (49). Pages 433–460. 1950.
	Turn:85	 Miranda. David Turner. Proceedings IFIP Conference, Nancy France, Springer LNCS 
(201). September 1985
	VN:45	
First Draft of a Report on the EDVAC.  John von Neumann. University of 
Pennsylvania. 1945.
	Wei:66	
Eliza. A Computer Program for the study of Natural Language Communication between 
Man and Machine. Joseph Weizenbaum. Communications of the ACM. 9(1) 36–45. 1966.
	Wei:76	
Computer Power and Human Reason: From Judgments to Calculation. Joseph 
Weizenbaum. W.H. Freeman & Co Ltd. 1976.
References

355
© The Editor(s) (if applicable) and The Author(s), under exclusive license to 
Springer Nature Switzerland AG 2021 
G. O’Regan, A Brief History of Computing, 
https://doi.org/10.1007/978-3-030-66599-9
A
Abu Simbal, 12
Ada Lovelace, 43–44
Advanced Micro Devices (AMD), 117
Advanced mobile phone system, 230, 231
Advice Taker, 300
Agile development, 212–214
Aiken, H., 54
Alexander the Great, 19
Alexandria, 19
ALGOrithmic Language (ALGOL), 183
Al-Khwarizmi, 29
Amdahl 470V/6, 103, 108
Amdahl Corporation, 103
Analog computers, 2, 3
Analytic engine, 42
Anderson, H., 104
Android, 152
Apple I, 122
Apple II, 122
Apple Macintosh, 129
App stores, 162
Archimedes, 23
Ariane 5 disaster, 207
ARPANET, 237–241
Artificial Intelligence (AI), 295, 299
Atanasoff-Berry computer, 55–57
Atari 400, 125, 126
Atari 800, 125
Atari 1040, 131
Atari ABC, 131
Atari Inc., 132
Atari Video Computer System (VCS), 134
Athenian democracy, 18
AXE System, 229, 230
Axiomatic approach, 153
Axiomatic semantics, 198
B
Babbage, C., 40
Babylonians, 13–15
Ball Mouse, 173
BBN Technologies, 239
BCS code of conduct, 327, 328
Bell, G., 104, 232, 236
Berners-Lee, T., 243
Bespoke software, 336
Binary numbers, 38–40
Binary relation, 289
Birth of Silicon Valley, 93–95
Birth of software industry, 156–162
Bitcoin, 254
Bletchley Park, 61–64
Boo.com, 248
Boole, G., 44
British Empiricism, 306
Bubble and burst, 250–252
Bush, V., 49, 237
Bushnell, N., 132
Business ethics, 322, 323
Business model, 249
Business-to-Business (B2B), 246
Business-to-consumer (B2C), 246
C
C++, 188–190
Capability maturity model integration 
(CMMI®), 203, 206, 221, 224, 225
Index

356
Capek, K., 313
Champollion, 16
Chinese remainder theorem, 32
Cloud computing, 271, 272
CMMI maturity model, 221
Codd, E., 288
Cognitive psychology, 307–309
Colossus, 62–64
Colossus Mark 1, 63
Commodore 64, 126, 127
Commodore-Amiga, 130
Commodore Business Machines, 123
Commodore PET, 123, 124
Common Business Oriented Language 
(COBOL), 181, 182
Computable function, 191
Computational linguistics, 309, 310
Computer crime, 339–341
Computer ethics, 323
Computer privacy, 338, 339
Computer security, 341–342
Concurrency, 146
Conference on Data Systems Languages 
(CODASYL), 182
Cooper, M., 232
Copyright law, 333, 334
Corporate social responsibility (CSR), 322
Corporate software products, 158
C programming language, 185
Cybernetics, 310
D
Dark side of the internet, 340, 341
Database (DB), 285
Database management system (DBMS), 285
Deadlock, 146
DEC’s Minicomputers, 104–107
Defence Advanced Research Projects Agency 
(DARPA), 237, 241
Denotational semantics, 198
Descartes, 296
Deutsches Technikmuseum, 65
Difference engine (No. 1), 40–42
Differential analyser, 2
Digital computers, 3–8
Digital currency, 254
Digital Equipment Corporation (DEC), 104
Digital Research, 7
Distributed systems, 268, 269
Dorsey, J., 262
Dot Com, 246–253
Dot com bubble, 250, 255
Dot com failures, 248, 249
Driverless car, 317, 318
DynaTAC, 233
E
Early IBM Computers, 82
eBay, 247
Eckert-Mauchly Computer Corporation 
(EMCC), 72
E-Commerce Security, 252, 253
EDSAC computer, 73
Egyptians, 15–18
Electronic Discrete Variable Automatic 
Computer (EDVAC), 60
Electronic Numerical Integrator and Computer 
(ENIAC), 57–61
Eliza program, 304, 325
Embedded systems, 272, 273
Engelbart, D., 166
Eratosthenes, 21
Ericsson, 230
Escrow agreement, 337
Estridge, D., 138, 142
Ethics, 321
Ethics and AI, 304–305, 325
Euclid, 19
Euclidean algorithm, 20
European Space Agency (ESA), 208
Expert system, 315
F
Facebook, 259
Facebook revolution, 259–261
Fagan inspections, 205, 219
Fake news, 263
Ferranti Mark I, 76
Flowers, T., 61
Formalism, 312
Formal methods, 222, 223
FORmula TRANslator (FORTRAN),  
181–183
Free Software Foundation (FSF), 223
Free speech and censorship, 338
Functional programming, 190
G
Global positioning system (GPS), 277
Gmail, 240, 241
GNU project, 160
Greek, 18
Index

357
H
Hacker, 341
Harvard Mark 1, 54–55
HCI principles, 156–162, 166–171
Heidegger, 306
Hellenistic age, 19
Hewlett, B., 94
Hierarchical model, 286
Home computers, 119–136
Human-computer interaction (HCI), 166
Hume, D., 306
Hypertext, 172
I
IBM 360, 102
IBM 701, 82
IBM 704, 82
IBM 7090, 87
IBM Personal Computer, 137–142
IBM System/360, 97–102, 158
IEEE standards, 209
Imperative programming, 180
Integrated circuits, 6–7, 90–93
Intel 4004, 114
Intellectual property, 332–334
Internet, 243
Internet of Money, 254
Internet of Things, 253
Internet protocol (IP), 242
Interrupt, 145
iOS, 152
iPad, 259
Iridium, 234
Islamic mathematics, 28
J
Java, 190
K
Karnak, 12
Kernighan, B., 185
Kilby, J., 90
Kozmo.com, 249
L
Lambda Calculus, 193
Leibniz, 36
LEO I Computer, 73–74
Livelock, 146
Logic and AI, 311, 312
Logic programming languages, 195
Logic Theorist, 300
Lorenz codes, 63
M
Maintenance, 218
Malcom Baldridge, 219
Manchester Mark I, 65–66, 68–69
Mauchly, J., 72
McCarthy, J., 300
Merleau-Ponty, 307
Microprocessor, 7, 8, 113–118
Microsoft Access, 164
Microsoft Excel, 163
Microsoft Office, 159, 162
Microsoft Outlook, 164
Microsoft PowerPoint, 164
Microsoft Windows, 151, 152
Microsoft Word, 164
Miranda, 192
MIT, 239
MITS Altair 8800, 121, 122
Mobile operating systems, 152
Mobile phone, 232
Model, 209
Mongolian Hordes Approach, 201
Moore, G., 117
Moore’s Law, 92, 93
Mosaic, 244
Motorola, 115, 232
Mouse, 172
MS/DOS, 139, 151
N
Nanotechnology, 283
NASDAQ, 250
National Semiconductors, 116
Nelson, T., 244
Network model, 286
Neural network, 314
Noyce, R., 117
O
Object-oriented programming, 187
Olsen, K., 104
Omidyar, P., 247
Open source license, 223
Open source software, 160–161
Operating Systems, 143–152
Index

358
Operational semantics, 198
Oracle database, 292
OS/360, 147, 148
P
Packard, D., 94
Parnas, D., 205, 326
Pascal, 184
Patent law, 332, 333
PC/DOS, 139
PDP-11, 103–106, 110
Performance testing, 218
Personal computer software industry,  
158, 159
Pets.com, 248
Philosophy and AI, 305–307
Plaintext, 28
Plankalkül, 179, 180
Plimpton 322 tablet, 15
Pong, 133
Predicate calculus, 311
Prince 2, 205, 219
Process, 145
Process control block (PCB), 145
Professional Engineering Association, 202
Professional engineers, 206
Project management, 220–221
Prolog, 195
Proof, 312
Propositional calculus, 311
Prototyping, 214
Pygmalion, 295
Q
Quantum computing, 276, 277
R
RAND Corporation, 239
Rational Unified Process, 209–212
Relational model, 286–290
Remington Rand, 73
Rhind Papyrus, 16
Ritchie, D., 150
Robots, 313
Robots and ethics, 325, 326
Rossums Universal Robots, 296
S
Searle’s Chinese room, 302
Security, 341
Semantics, 197
Semi-Automated Ground Environment 
(SAGE), 84–85
Service-oriented architecture (SOA), 270
Shannon, C., 47
Shockley, W., 5, 86
Simula 67, 188
Sinclair ZX 81, 127
Six sigma (6σ), 219
Smartphone, 257–265
Software as a service (SaaS), 159, 160, 
270, 271
Software contractors industry, 157
Software crisis, 202, 224
Software engineering, 202, 204, 206
Software failures, 207
Software inspections, 219, 220
Software licensing, 334–336
Software quality assurance, 103–111
Software reuse, 216
Software testing, 217
Sperry, 73
Spiral model, 210
Sprint planning, 213
Stallman, R., 160
Standish group, 202, 224
Step Reckoner, 36–37
Story, 213
Strong AI, 302
Structured query language (SQL), 291
Syllogistic logic, 24
Syntax, 197
System testing, 217
T
TCP, 242
TCP/IP, 241–243
Test driven development, 217
Tomlinson, R., 240
Traceability, 215
Trademarks, 334
Transistor, 4–6, 86–87
Trojan horse, 252
Tunny, 63
Turing Test, 300, 301
Tweet, 261–263
U
UAT testing, 218
Unit testing, 217
Universal Automatic Computer 
(UNIVAC), 72–73
Index

359
UNIX, 150
Usability, 170
User-centered design (UCD), 171
V
Vacuum tubes, 4
VAX 11 series, 104, 110
VAX 11/780, 106, 107
Virtual machine operating system (VM), 
148, 149
Virtual Memory System (VMS), 149
von Neumann architecture, 8–9
W
Waterfall model, 209
Weak AI, 302
Webvan, 248
Weizenbaum, 304, 325
Whirlwind, 84
WiFi, 273
WiFi security, 275, 276
Wikipedia, 281
Wikipedia controls, 273–276, 279–283
World-Wide Web, 243–246
X
Xerox alto personal computer, 120, 121
Y
Y2K, 203, 207
Y2K bug, 207
Yahoo, 247
Z
Z3, 66
Z4 Computer, 75–76
Zuse, K., 64
Zuse’s Machines, 65–66
ZX spectrum, 127
Index

