
Modern Classical Physics


Modern Classical Physics
Optics, Fluids, Plasmas, Elasticity, Relativity, and Statistical Physics
KIP S. THORNE and ROGER D. BLANDFORD
PRINCETON UNIVERSITY PRESS
Princeton and Oxford

Copyright © 2017 by Princeton University Press
Published by Princeton University Press, 41 William Street, Princeton, New Jersey 08540
In the United Kingdom: Princeton University Press, 6 Oxford Street, Woodstock, Oxfordshire OX20 1TR
press.princeton.edu
All Rights Reserved
Library of Congress Cataloging-in-Publication Data
Names: Thorne, Kip S., author. | Blandford, Roger D., author.
Title: Modern classical physics : optics, ﬂuids, plasmas, elasticity,
relativity, and statistical physics / Kip S. Thorne and Roger D. Blandford.
Description: Princeton : Princeton University Press, 2017. | Includes
bibliographical references and index.
Identiﬁers: LCCN 2014028150 | ISBN 9780691159027 (hardcover : alk. paper) |
ISBN 0691159025 (hardcover : alk. paper)
Subjects: LCSH: Physics.
Classiﬁcation: LCC QC21.3 .T46 2015 | DDC 530—dc23
LC record available at https://lccn.loc.gov/2014028150
British Library Cataloging-in-Publication Data is available
This book has been composed in MinionPro, Whitney, and Ratio Modern using ZzTEX by Windfall
Software, Carlisle, Massachusetts
Printed on acid-free paper.
Printed in China
10 9 8 7 6 5 4 3 2 1

To Carolee and Liz


CONTENTS
List of Boxes xxvii
Preface xxxi
Acknowledgments xxxix
PART I FOUNDATIONS 1
1
Newtonian Physics: Geometric Viewpoint 5
1.1
Introduction 5
1.1.1 The Geometric Viewpoint on the Laws of Physics 5
1.1.2 Purposes of This Chapter 7
1.1.3 Overview of This Chapter 7
1.2
Foundational Concepts 8
1.3
Tensor Algebra without a Coordinate System 10
1.4
Particle Kinetics and Lorentz Force in Geometric Language 13
1.5
Component Representation of Tensor Algebra 16
1.5.1 Slot-Naming Index Notation 17
1.5.2 Particle Kinetics in Index Notation 19
1.6
Orthogonal Transformations of Bases 20
1.7
Differentiation of Scalars, Vectors, and Tensors; Cross Product and Curl 22
1.8
Volumes, Integration, and Integral Conservation Laws 26
1.8.1 Gauss’s and Stokes’ Theorems 27
1.9
The Stress Tensor and Momentum Conservation 29
1.9.1 Examples: Electromagnetic Field and Perfect Fluid 30
1.9.2 Conservation of Momentum 31
1.10
Geometrized Units and Relativistic Particles for Newtonian Readers 33
1.10.1 Geometrized Units 33
1.10.2 Energy and Momentum of a Moving Particle 34
Bibliographic Note 35
Track Two; see page xxxiv
Nonrelativistic (Newtonian) kinetic theory; see page 96
Relativistic theory; see page 96
vii

2
Special Relativity: Geometric Viewpoint
37
2.1
Overview 37
2.2
Foundational Concepts 38
2.2.1 Inertial Frames, Inertial Coordinates, Events, Vectors, and Spacetime Diagrams 38
2.2.2 The Principle of Relativity and Constancy of Light Speed 42
2.2.3 The Interval and Its Invariance 45
2.3
Tensor Algebra without a Coordinate System 48
2.4
Particle Kinetics and Lorentz Force without a Reference Frame 49
2.4.1 Relativistic Particle Kinetics: World Lines, 4-Velocity, 4-Momentum and
Its Conservation, 4-Force 49
2.4.2 Geometric Derivation of the Lorentz Force Law 52
2.5
Component Representation of Tensor Algebra 54
2.5.1 Lorentz Coordinates 54
2.5.2 Index Gymnastics 54
2.5.3 Slot-Naming Notation 56
2.6
Particle Kinetics in Index Notation and in a Lorentz Frame 57
2.7
Lorentz Transformations 63
2.8
Spacetime Diagrams for Boosts 65
2.9
Time Travel 67
2.9.1 Measurement of Time; Twins Paradox 67
2.9.2 Wormholes 68
2.9.3 Wormhole as Time Machine 69
2.10
Directional Derivatives, Gradients, and the Levi-Civita Tensor 70
2.11
Nature of Electric and Magnetic Fields; Maxwell’s Equations 71
2.12
Volumes, Integration, and Conservation Laws 75
2.12.1 Spacetime Volumes and Integration 75
2.12.2 Conservation of Charge in Spacetime 78
2.12.3 Conservation of Particles, Baryon Number, and Rest Mass 79
2.13
Stress-Energy Tensor and Conservation of 4-Momentum 82
2.13.1 Stress-Energy Tensor 82
2.13.2 4-Momentum Conservation 84
2.13.3 Stress-Energy Tensors for Perfect Fluids and Electromagnetic Fields 85
Bibliographic Note 88
PART II STATISTICAL PHYSICS 91
3
Kinetic Theory 95
3.1
Overview 95
3.2
Phase Space and Distribution Function 97
3.2.1 Newtonian Number Density in Phase Space, N
97
3.2.2 Relativistic Number Density in Phase Space, N
99
viii
Contents

3.2.3 Distribution Function f (x, v, t) for Particles in a Plasma 105
3.2.4 Distribution Function Iν/ν3 for Photons 106
3.2.5 Mean Occupation Number η 108
3.3
Thermal-Equilibrium Distribution Functions 111
3.4
Macroscopic Properties of Matter as Integrals over Momentum Space 117
3.4.1 Particle Density n, Flux S, and Stress Tensor T 117
3.4.2 Relativistic Number-Flux 4-Vector ⃗S and Stress-Energy Tensor TTT
118
3.5
Isotropic Distribution Functions and Equations of State 120
3.5.1 Newtonian Density, Pressure, Energy Density, and Equation of State 120
3.5.2 Equations of State for a Nonrelativistic Hydrogen Gas 122
3.5.3 Relativistic Density, Pressure, Energy Density, and Equation of State 125
3.5.4 Equation of State for a Relativistic Degenerate Hydrogen Gas 126
3.5.5 Equation of State for Radiation 128
3.6
Evolution of the Distribution Function: Liouville’s Theorem, the Collisionless
Boltzmann Equation, and the Boltzmann Transport Equation 132
3.7
Transport Coefﬁcients 139
3.7.1 Diffusive Heat Conduction inside a Star 142
3.7.2 Order-of-Magnitude Analysis 143
3.7.3 Analysis Using the Boltzmann Transport Equation 144
Bibliographic Note 153
4
Statistical Mechanics 155
4.1
Overview 155
4.2
Systems, Ensembles, and Distribution Functions 157
4.2.1 Systems 157
4.2.2 Ensembles 160
4.2.3 Distribution Function 161
4.3
Liouville’s Theorem and the Evolution of the Distribution Function 166
4.4
Statistical Equilibrium 168
4.4.1 Canonical Ensemble and Distribution 169
4.4.2 General Equilibrium Ensemble and Distribution; Gibbs Ensemble;
Grand Canonical Ensemble 172
4.4.3 Fermi-Dirac and Bose-Einstein Distributions 174
4.4.4 Equipartition Theorem for Quadratic, Classical Degrees of Freedom 177
4.5
The Microcanonical Ensemble 178
4.6
The Ergodic Hypothesis 180
4.7
Entropy and Evolution toward Statistical Equilibrium 181
4.7.1 Entropy and the Second Law of Thermodynamics 181
4.7.2 What Causes the Entropy to Increase? 183
4.8
Entropy per Particle 191
4.9
Bose-Einstein Condensate 193
Contents
ix

4.10
Statistical Mechanics in the Presence of Gravity 201
4.10.1 Galaxies 201
4.10.2 Black Holes 204
4.10.3 The Universe 209
4.10.4 Structure Formation in the Expanding Universe: Violent Relaxation
and Phase Mixing 210
4.11
Entropy and Information 211
4.11.1 Information Gained When Measuring the State of a System
in a Microcanonical Ensemble 211
4.11.2 Information in Communication Theory 212
4.11.3 Examples of Information Content 214
4.11.4 Some Properties of Information 216
4.11.5 Capacity of Communication Channels; Erasing Information
from Computer Memories 216
Bibliographic Note 218
5
Statistical Thermodynamics 219
5.1
Overview 219
5.2
Microcanonical Ensemble and the Energy Representation of Thermodynamics 221
5.2.1 Extensive and Intensive Variables; Fundamental Potential 221
5.2.2 Energy as a Fundamental Potential 222
5.2.3 Intensive Variables Identiﬁed Using Measuring Devices;
First Law of Thermodynamics 223
5.2.4 Euler’s Equation and Form of the Fundamental Potential 226
5.2.5 Everything Deducible from First Law; Maxwell Relations 227
5.2.6 Representations of Thermodynamics 228
5.3
Grand Canonical Ensemble and the Grand-Potential Representation
of Thermodynamics 229
5.3.1 The Grand-Potential Representation, and Computation of Thermodynamic
Properties as a Grand Canonical Sum 229
5.3.2 Nonrelativistic van der Waals Gas 232
5.4
Canonical Ensemble and the Physical-Free-Energy Representation
of Thermodynamics 239
5.4.1 Experimental Meaning of Physical Free Energy 241
5.4.2 Ideal Gas with Internal Degrees of Freedom 242
5.5
Gibbs Ensemble and Representation of Thermodynamics; Phase Transitions
and Chemical Reactions 246
5.5.1 Out-of-Equilibrium Ensembles and Their Fundamental Thermodynamic Potentials
and Minimum Principles 248
5.5.2 Phase Transitions 251
5.5.3 Chemical Reactions 256
5.6
Fluctuations away from Statistical Equilibrium 260
x
Contents

5.7
Van der Waals Gas: Volume Fluctuations and Gas-to-Liquid Phase Transition 266
5.8
Magnetic Materials 270
5.8.1 Paramagnetism; The Curie Law 271
5.8.2 Ferromagnetism: The Ising Model 272
5.8.3 Renormalization Group Methods for the Ising Model 273
5.8.4 Monte Carlo Methods for the Ising Model 279
Bibliographic Note 282
6
Random Processes 283
6.1
Overview 283
6.2
Fundamental Concepts 285
6.2.1 Random Variables and Random Processes 285
6.2.2 Probability Distributions 286
6.2.3 Ergodic Hypothesis 288
6.3
Markov Processes and Gaussian Processes 289
6.3.1 Markov Processes; Random Walk 289
6.3.2 Gaussian Processes and the Central Limit Theorem; Random Walk 292
6.3.3 Doob’s Theorem for Gaussian-Markov Processes, and Brownian Motion 295
6.4
Correlation Functions and Spectral Densities 297
6.4.1 Correlation Functions; Proof of Doob’s Theorem 297
6.4.2 Spectral Densities 299
6.4.3 Physical Meaning of Spectral Density, Light Spectra, and Noise
in a Gravitational Wave Detector 301
6.4.4 The Wiener-Khintchine Theorem; Cosmological Density Fluctuations 303
6.5
2-Dimensional Random Processes 306
6.5.1 Cross Correlation and Correlation Matrix 306
6.5.2 Spectral Densities and the Wiener-Khintchine Theorem 307
6.6
Noise and Its Types of Spectra 308
6.6.1 Shot Noise, Flicker Noise, and Random-Walk Noise; Cesium Atomic Clock 308
6.6.2 Information Missing from Spectral Density 310
6.7
Filtering Random Processes 311
6.7.1 Filters, Their Kernels, and the Filtered Spectral Density 311
6.7.2 Brownian Motion and Random Walks 313
6.7.3 Extracting a Weak Signal from Noise: Band-Pass Filter, Wiener’s Optimal Filter,
Signal-to-Noise Ratio, and Allan Variance of Clock Noise 315
6.7.4 Shot Noise 321
6.8
Fluctuation-Dissipation Theorem 323
6.8.1 Elementary Version of the Fluctuation-Dissipation Theorem; Langevin Equation,
Johnson Noise in a Resistor, and Relaxation Time for Brownian Motion 323
6.8.2 Generalized Fluctuation-Dissipation Theorem; Thermal Noise in a
Laser Beam’s Measurement of Mirror Motions; Standard Quantum Limit
for Measurement Accuracy and How to Evade It 331
Contents
xi

6.9
Fokker-Planck Equation 335
6.9.1 Fokker-Planck for a 1-Dimensional Markov Process 336
6.9.2 Optical Molasses: Doppler Cooling of Atoms 340
6.9.3 Fokker-Planck for a Multidimensional Markov Process; Thermal Noise
in an Oscillator 343
Bibliographic Note 345
PART III OPTICS 347
7
Geometric Optics 351
7.1
Overview 351
7.2
Waves in a Homogeneous Medium 352
7.2.1 Monochromatic Plane Waves; Dispersion Relation 352
7.2.2 Wave Packets 354
7.3
Waves in an Inhomogeneous, Time-Varying Medium: The Eikonal Approximation and
Geometric Optics 357
7.3.1 Geometric Optics for a Prototypical Wave Equation 358
7.3.2 Connection of Geometric Optics to Quantum Theory 362
7.3.3 Geometric Optics for a General Wave 366
7.3.4 Examples of Geometric-Optics Wave Propagation 368
7.3.5 Relation to Wave Packets; Limitations of the Eikonal Approximation
and Geometric Optics 369
7.3.6 Fermat’s Principle 371
7.4
Paraxial Optics 375
7.4.1 Axisymmetric, Paraxial Systems: Lenses, Mirrors, Telescopes, Microscopes,
and Optical Cavities 377
7.4.2 Converging Magnetic Lens for Charged Particle Beam 381
7.5
Catastrophe Optics 384
7.5.1 Image Formation 384
7.5.2 Aberrations of Optical Instruments 395
7.6
Gravitational Lenses 396
7.6.1 Gravitational Deﬂection of Light 396
7.6.2 Optical Conﬁguration 397
7.6.3 Microlensing 398
7.6.4 Lensing by Galaxies 401
7.7
Polarization 405
7.7.1 Polarization Vector and Its Geometric-Optics Propagation Law 405
7.7.2 Geometric Phase 406
Bibliographic Note 409
xii
Contents

8
Diffraction 411
8.1
Overview 411
8.2
Helmholtz-Kirchhoff Integral 413
8.2.1 Diffraction by an Aperture 414
8.2.2 Spreading of the Wavefront: Fresnel and Fraunhofer Regions 417
8.3
Fraunhofer Diffraction 420
8.3.1 Diffraction Grating 422
8.3.2 Airy Pattern of a Circular Aperture: Hubble Space Telescope 425
8.3.3 Babinet’s Principle 428
8.4
Fresnel Diffraction 429
8.4.1 Rectangular Aperture, Fresnel Integrals, and the Cornu Spiral 430
8.4.2 Unobscured Plane Wave 432
8.4.3 Fresnel Diffraction by a Straight Edge: Lunar Occultation of a Radio Source 432
8.4.4 Circular Apertures: Fresnel Zones and Zone Plates 434
8.5
Paraxial Fourier Optics 436
8.5.1 Coherent Illumination 437
8.5.2 Point-Spread Functions 438
8.5.3 Abb´e’s Description of Image Formation by a Thin Lens 439
8.5.4 Image Processing by a Spatial Filter in the Focal Plane of a Lens: High-Pass,
Low-Pass, and Notch Filters; Phase-Contrast Microscopy 441
8.5.5 Gaussian Beams: Optical Cavities and Interferometric Gravitational-Wave
Detectors 445
8.6
Diffraction at a Caustic 451
Bibliographic Note 454
9
Interference and Coherence 455
9.1
Overview 455
9.2
Coherence 456
9.2.1 Young’s Slits 456
9.2.2 Interference with an Extended Source: Van Cittert-Zernike Theorem 459
9.2.3 More General Formulation of Spatial Coherence; Lateral Coherence Length 462
9.2.4 Generalization to 2 Dimensions 463
9.2.5 Michelson Stellar Interferometer; Astronomical Seeing 464
9.2.6 Temporal Coherence 472
9.2.7 Michelson Interferometer and Fourier-Transform Spectroscopy 474
9.2.8 Degree of Coherence; Relation to Theory of Random Processes 477
9.3
Radio Telescopes 479
9.3.1 Two-Element Radio Interferometer 479
9.3.2 Multiple-Element Radio Interferometers 480
9.3.3 Closure Phase 481
9.3.4 Angular Resolution 482
Contents
xiii

9.4
Etalons and Fabry-Perot Interferometers 483
9.4.1 Multiple-Beam Interferometry; Etalons 483
9.4.2 Fabry-Perot Interferometer and Modes of a Fabry-Perot Cavity
with Spherical Mirrors 490
9.4.3 Fabry-Perot Applications: Spectrometer, Laser, Mode-Cleaning Cavity,
Beam-Shaping Cavity, PDH Laser Stabilization, Optical Frequency Comb 496
9.5
Laser Interferometer Gravitational-Wave Detectors 502
9.6
Power Correlations and Photon Statistics: Hanbury Brown and Twiss Intensity
Interferometer 509
Bibliographic Note 512
10
Nonlinear Optics 513
10.1
Overview 513
10.2
Lasers 515
10.2.1 Basic Principles of the Laser 515
10.2.2 Types of Lasers and Their Performances and Applications 519
10.2.3 Ti:Sapphire Mode-Locked Laser 520
10.2.4 Free Electron Laser 521
10.3
Holography 521
10.3.1 Recording a Hologram 522
10.3.2 Reconstructing the 3-Dimensional Image from a Hologram 525
10.3.3 Other Types of Holography; Applications 527
10.4
Phase-Conjugate Optics 531
10.5
Maxwell’s Equations in a Nonlinear Medium; Nonlinear Dielectric Susceptibilities;
Electro-Optic Effects 536
10.6
Three-Wave Mixing in Nonlinear Crystals 540
10.6.1 Resonance Conditions for Three-Wave Mixing 540
10.6.2 Three-Wave-Mixing Evolution Equations in a Medium That Is Dispersion-Free
and Isotropic at Linear Order 544
10.6.3 Three-Wave Mixing in a Birefringent Crystal: Phase Matching and
Evolution Equations 546
10.7
Applications of Three-Wave Mixing: Frequency Doubling, Optical Parametric
Ampliﬁcation, and Squeezed Light 553
10.7.1 Frequency Doubling 553
10.7.2 Optical Parametric Ampliﬁcation 555
10.7.3 Degenerate Optical Parametric Ampliﬁcation: Squeezed Light 556
10.8
Four-Wave Mixing in Isotropic Media 558
10.8.1 Third-Order Susceptibilities and Field Strengths 558
10.8.2 Phase Conjugation via Four-Wave Mixing in CS2 Fluid 559
10.8.3 Optical Kerr Effect and Four-Wave Mixing in an Optical Fiber 562
Bibliographic Note 564
xiv
Contents

PART IV ELASTICITY 565
11
Elastostatics 567
11.1
Overview 567
11.2
Displacement and Strain 570
11.2.1 Displacement Vector and Its Gradient 570
11.2.2 Expansion, Rotation, Shear, and Strain 571
11.3
Stress, Elastic Moduli, and Elastostatic Equilibrium 577
11.3.1 Stress Tensor 577
11.3.2 Realm of Validity for Hooke’s Law 580
11.3.3 Elastic Moduli and Elastostatic Stress Tensor 580
11.3.4 Energy of Deformation 582
11.3.5 Thermoelasticity 584
11.3.6 Molecular Origin of Elastic Stress; Estimate of Moduli 585
11.3.7 Elastostatic Equilibrium: Navier-Cauchy Equation 587
11.4
Young’s Modulus and Poisson’s Ratio for an Isotropic Material: A Simple
Elastostatics Problem 589
11.5
Reducing the Elastostatic Equations to 1 Dimension for a Bent Beam: Cantilever Bridge,
Foucault Pendulum, DNA Molecule, Elastica 592
11.6
Buckling and Bifurcation of Equilibria 602
11.6.1 Elementary Theory of Buckling and Bifurcation 602
11.6.2 Collapse of the World Trade Center Buildings 605
11.6.3 Buckling with Lateral Force; Connection to Catastrophe Theory 606
11.6.4 Other Bifurcations: Venus Fly Trap, Whirling Shaft, Triaxial Stars, and
Onset of Turbulence 607
11.7
Reducing the Elastostatic Equations to 2 Dimensions for a Deformed Thin Plate:
Stress Polishing a Telescope Mirror 609
11.8
Cylindrical and Spherical Coordinates: Connection Coefﬁcients and Components
of the Gradient of the Displacement Vector 614
11.9
Solving the 3-Dimensional Navier-Cauchy Equation in Cylindrical Coordinates 619
11.9.1 Simple Methods: Pipe Fracture and Torsion Pendulum 619
11.9.2 Separation of Variables and Green’s Functions: Thermoelastic Noise
in Mirrors 622
Bibliographic Note 627
12
Elastodynamics 629
12.1
Overview 629
12.2
Basic Equations of Elastodynamics; Waves in a Homogeneous Medium 630
12.2.1 Equation of Motion for a Strained Elastic Medium 630
12.2.2 Elastodynamic Waves 636
12.2.3 Longitudinal Sound Waves 637
Contents
xv

12.2.4 Transverse Shear Waves 638
12.2.5 Energy of Elastodynamic Waves 640
12.3
Waves in Rods, Strings, and Beams 642
12.3.1 Compression Waves in a Rod 643
12.3.2 Torsion Waves in a Rod 643
12.3.3 Waves on Strings 644
12.3.4 Flexural Waves on a Beam 645
12.3.5 Bifurcation of Equilibria and Buckling (Once More) 647
12.4
Body Waves and Surface Waves—Seismology and Ultrasound 648
12.4.1 Body Waves 650
12.4.2 Edge Waves 654
12.4.3 Green’s Function for a Homogeneous Half-Space 658
12.4.4 Free Oscillations of Solid Bodies 661
12.4.5 Seismic Tomography 663
12.4.6 Ultrasound; Shock Waves in Solids 663
12.5
The Relationship of Classical Waves to Quantum Mechanical Excitations 667
Bibliographic Note 670
PART V FLUID DYNAMICS 671
13
Foundations of Fluid Dynamics 675
13.1
Overview 675
13.2
The Macroscopic Nature of a Fluid: Density, Pressure, Flow Velocity;
Liquids versus Gases 677
13.3
Hydrostatics 681
13.3.1 Archimedes’ Law 684
13.3.2 Nonrotating Stars and Planets 686
13.3.3 Rotating Fluids 689
13.4
Conservation Laws 691
13.5
The Dynamics of an Ideal Fluid 695
13.5.1 Mass Conservation 696
13.5.2 Momentum Conservation 696
13.5.3 Euler Equation 697
13.5.4 Bernoulli’s Theorem 697
13.5.5 Conservation of Energy 704
13.6
Incompressible Flows 709
13.7
Viscous Flows with Heat Conduction 710
13.7.1 Decomposition of the Velocity Gradient into Expansion, Vorticity, and Shear 710
13.7.2 Navier-Stokes Equation 711
13.7.3 Molecular Origin of Viscosity 713
13.7.4 Energy Conservation and Entropy Production 714
xvi
Contents

13.7.5 Reynolds Number 716
13.7.6 Pipe Flow 716
13.8
Relativistic Dynamics of a Perfect Fluid 719
13.8.1 Stress-Energy Tensor and Equations of Relativistic Fluid Mechanics 719
13.8.2 Relativistic Bernoulli Equation and Ultrarelativistic Astrophysical Jets 721
13.8.3 Nonrelativistic Limit of the Stress-Energy Tensor 723
Bibliographic Note 726
14
Vorticity 729
14.1
Overview 729
14.2
Vorticity, Circulation, and Their Evolution 731
14.2.1 Vorticity Evolution 734
14.2.2 Barotropic, Inviscid, Compressible Flows: Vortex Lines Frozen into Fluid 736
14.2.3 Tornados 738
14.2.4 Circulation and Kelvin’s Theorem 739
14.2.5 Diffusion of Vortex Lines 741
14.2.6 Sources of Vorticity 744
14.3
Low-Reynolds-Number Flow—Stokes Flow and Sedimentation 746
14.3.1 Motivation: Climate Change 748
14.3.2 Stokes Flow 749
14.3.3 Sedimentation Rate 754
14.4
High-Reynolds-Number Flow—Laminar Boundary Layers 757
14.4.1 Blasius Velocity Proﬁle Near a Flat Plate: Stream Function and
Similarity Solution 758
14.4.2 Blasius Vorticity Proﬁle 763
14.4.3 Viscous Drag Force on a Flat Plate 763
14.4.4 Boundary Layer Near a Curved Surface: Separation 764
14.5
Nearly Rigidly Rotating Flows—Earth’s Atmosphere and Oceans 766
14.5.1 Equations of Fluid Dynamics in a Rotating Reference Frame 767
14.5.2 Geostrophic Flows 770
14.5.3 Taylor-Proudman Theorem 771
14.5.4 Ekman Boundary Layers 772
14.6
Instabilities of Shear Flows—Billow Clouds and Turbulence in the Stratosphere 778
14.6.1 Discontinuous Flow: Kelvin-Helmholtz Instability 778
14.6.2 Discontinuous Flow with Gravity 782
14.6.3 Smoothly Stratiﬁed Flows: Rayleigh and Richardson Criteria
for Instability 784
Bibliographic Note 786
15
Turbulence 787
15.1
Overview 787
15.2
The Transition to Turbulence—Flow Past a Cylinder 789
Contents
xvii

15.3
Empirical Description of Turbulence 798
15.3.1 The Role of Vorticity in Turbulence 799
15.4
Semiquantitative Analysis of Turbulence 800
15.4.1 Weak-Turbulence Formalism 800
15.4.2 Turbulent Viscosity 804
15.4.3 Turbulent Wakes and Jets; Entrainment; the Coanda Effect 805
15.4.4 Kolmogorov Spectrum for Fully Developed, Homogeneous,
Isotropic Turbulence 810
15.5
Turbulent Boundary Layers 817
15.5.1 Proﬁle of a Turbulent Boundary Layer 818
15.5.2 Coanda Effect and Separation in a Turbulent Boundary Layer 820
15.5.3 Instability of a Laminar Boundary Layer 822
15.5.4 Flight of a Ball 823
15.6
The Route to Turbulence—Onset of Chaos 825
15.6.1 Rotating Couette Flow 825
15.6.2 Feigenbaum Sequence, Poincar´e Maps, and the Period-Doubling Route to
Turbulence in Convection 828
15.6.3 Other Routes to Turbulent Convection 831
15.6.4 Extreme Sensitivity to Initial Conditions 832
Bibliographic Note 834
16
Waves 835
16.1
Overview 835
16.2
Gravity Waves on and beneath the Surface of a Fluid 837
16.2.1 Deep-Water Waves and Their Excitation and Damping 840
16.2.2 Shallow-Water Waves 840
16.2.3 Capillary Waves and Surface Tension 844
16.2.4 Helioseismology 848
16.3
Nonlinear Shallow-Water Waves and Solitons 850
16.3.1 Korteweg–de Vries (KdV) Equation 850
16.3.2 Physical Effects in the KdV Equation 853
16.3.3 Single-Soliton Solution 854
16.3.4 Two-Soliton Solution 855
16.3.5 Solitons in Contemporary Physics 856
16.4
Rossby Waves in a Rotating Fluid 858
16.5
Sound Waves 862
16.5.1 Wave Energy 863
16.5.2 Sound Generation 865
16.5.3 Radiation Reaction, Runaway Solutions, and Matched Asymptotic
Expansions 869
Bibliographic Note 874
xviii
Contents

17
Compressible and Supersonic Flow 875
17.1
Overview 875
17.2
Equations of Compressible Flow 877
17.3
Stationary, Irrotational, Quasi-1-Dimensional Flow 880
17.3.1 Basic Equations; Transition from Subsonic to Supersonic Flow 880
17.3.2 Setting up a Stationary, Transonic Flow 883
17.3.3 Rocket Engines 887
17.4
1-Dimensional, Time-Dependent Flow 891
17.4.1 Riemann Invariants 891
17.4.2 Shock Tube 895
17.5
Shock Fronts 897
17.5.1 Junction Conditions across a Shock; Rankine-Hugoniot Relations 898
17.5.2 Junction Conditions for Ideal Gas with Constant γ
904
17.5.3 Internal Structure of a Shock 906
17.5.4 Mach Cone 907
17.6
Self-Similar Solutions—Sedov-Taylor Blast Wave 908
17.6.1 The Sedov-Taylor Solution 909
17.6.2 Atomic Bomb 912
17.6.3 Supernovae 914
Bibliographic Note 916
18
Convection 917
18.1
Overview 917
18.2
Diffusive Heat Conduction—Cooling a Nuclear Reactor; Thermal Boundary
Layers 918
18.3
Boussinesq Approximation 923
18.4
Rayleigh-B´enard Convection 925
18.5
Convection in Stars 933
18.6
Double Diffusion—Salt Fingers 937
Bibliographic Note 941
19
Magnetohydrodynamics 943
19.1
Overview 943
19.2
Basic Equations of MHD 944
19.2.1 Maxwell’s Equations in the MHD Approximation 946
19.2.2 Momentum and Energy Conservation 950
19.2.3 Boundary Conditions 953
19.2.4 Magnetic Field and Vorticity 957
19.3
Magnetostatic Equilibria 958
19.3.1 Controlled Thermonuclear Fusion 958
19.3.2 Z-Pinch 960
Contents
xix

19.3.3 -Pinch 962
19.3.4 Tokamak 963
19.4
Hydromagnetic Flows 965
19.5
Stability of Magnetostatic Equilibria 971
19.5.1 Linear Perturbation Theory 971
19.5.2 Z-Pinch: Sausage and Kink Instabilities 975
19.5.3 The -Pinch and Its Toroidal Analog; Flute Instability; Motivation
for Tokamak 978
19.5.4 Energy Principle and Virial Theorems 980
19.6
Dynamos and Reconnection of Magnetic Field Lines 984
19.6.1 Cowling’s Theorem 984
19.6.2 Kinematic Dynamos 985
19.6.3 Magnetic Reconnection 986
19.7
Magnetosonic Waves and the Scattering of Cosmic Rays 988
19.7.1 Cosmic Rays 988
19.7.2 Magnetosonic Dispersion Relation 989
19.7.3 Scattering of Cosmic Rays by Alfv´en Waves 992
Bibliographic Note 993
PART VI PLASMA PHYSICS 995
20
The Particle Kinetics of Plasma 997
20.1
Overview 997
20.2
Examples of Plasmas and Their Density-Temperature Regimes 998
20.2.1 Ionization Boundary 998
20.2.2 Degeneracy Boundary 1000
20.2.3 Relativistic Boundary 1000
20.2.4 Pair-Production Boundary 1001
20.2.5 Examples of Natural and Human-Made Plasmas 1001
20.3
Collective Effects in Plasmas—Debye Shielding and Plasma Oscillations 1003
20.3.1 Debye Shielding 1003
20.3.2 Collective Behavior 1004
20.3.3 Plasma Oscillations and Plasma Frequency 1005
20.4
Coulomb Collisions 1006
20.4.1 Collision Frequency 1006
20.4.2 The Coulomb Logarithm 1008
20.4.3 Thermal Equilibration Rates in a Plasma 1010
20.4.4 Discussion 1012
20.5
Transport Coefﬁcients 1015
20.5.1 Coulomb Collisions 1015
20.5.2 Anomalous Resistivity and Anomalous Equilibration 1016
xx
Contents

20.6
Magnetic Field 1019
20.6.1 Cyclotron Frequency and Larmor Radius 1019
20.6.2 Validity of the Fluid Approximation 1020
20.6.3 Conductivity Tensor 1022
20.7
Particle Motion and Adiabatic Invariants 1024
20.7.1 Homogeneous, Time-Independent Magnetic Field and No Electric Field 1025
20.7.2 Homogeneous, Time-Independent Electric and Magnetic Fields 1025
20.7.3 Inhomogeneous, Time-Independent Magnetic Field 1026
20.7.4 A Slowly Time-Varying Magnetic Field 1029
20.7.5 Failure of Adiabatic Invariants; Chaotic Orbits 1030
Bibliographic Note 1032
21
Waves in Cold Plasmas: Two-Fluid Formalism 1033
21.1
Overview 1033
21.2
Dielectric Tensor, Wave Equation, and General Dispersion Relation 1035
21.3
Two-Fluid Formalism 1037
21.4
Wave Modes in an Unmagnetized Plasma 1040
21.4.1 Dielectric Tensor and Dispersion Relation for a Cold, Unmagnetized Plasma 1040
21.4.2 Plasma Electromagnetic Modes 1042
21.4.3 Langmuir Waves and Ion-Acoustic Waves in Warm Plasmas 1044
21.4.4 Cutoffs and Resonances 1049
21.5
Wave Modes in a Cold, Magnetized Plasma 1050
21.5.1 Dielectric Tensor and Dispersion Relation 1050
21.5.2 Parallel Propagation 1052
21.5.3 Perpendicular Propagation 1057
21.5.4 Propagation of Radio Waves in the Ionosphere; Magnetoionic Theory 1058
21.5.5 CMA Diagram for Wave Modes in a Cold, Magnetized Plasma 1062
21.6
Two-Stream Instability 1065
Bibliographic Note 1068
22
Kinetic Theory of Warm Plasmas 1069
22.1
Overview 1069
22.2
Basic Concepts of Kinetic Theory and Its Relationship to Two-Fluid Theory 1070
22.2.1 Distribution Function and Vlasov Equation 1070
22.2.2 Relation of Kinetic Theory to Two-Fluid Theory 1073
22.2.3 Jeans’ Theorem 1074
22.3
Electrostatic Waves in an Unmagnetized Plasma: Landau Damping 1077
22.3.1 Formal Dispersion Relation 1077
22.3.2 Two-Stream Instability 1079
22.3.3 The Landau Contour 1080
22.3.4 Dispersion Relation for Weakly Damped or Growing Waves 1085
Contents
xxi

22.3.5 Langmuir Waves and Their Landau Damping 1086
22.3.6 Ion-Acoustic Waves and Conditions for Their Landau Damping to Be Weak 1088
22.4
Stability of Electrostatic Waves in Unmagnetized Plasmas 1090
22.4.1 Nyquist’s Method 1091
22.4.2 Penrose’s Instability Criterion 1091
22.5
Particle Trapping 1098
22.6
N-Particle Distribution Function 1102
22.6.1 BBGKY Hierarchy 1103
22.6.2 Two-Point Correlation Function 1104
22.6.3 Coulomb Correction to Plasma Pressure 1107
Bibliographic Note 1108
23
Nonlinear Dynamics of Plasmas 1111
23.1
Overview 1111
23.2
Quasilinear Theory in Classical Language 1113
23.2.1 Classical Derivation of the Theory 1113
23.2.2 Summary of Quasilinear Theory 1120
23.2.3 Conservation Laws 1121
23.2.4 Generalization to 3 Dimensions 1122
23.3
Quasilinear Theory in Quantum Mechanical Language 1123
23.3.1 Plasmon Occupation Number η 1123
23.3.2 Evolution of η for Plasmons via Interaction with Electrons 1124
23.3.3 Evolution of f for Electrons via Interaction with Plasmons 1129
23.3.4 Emission of Plasmons by Particles in the Presence of a Magnetic Field 1131
23.3.5 Relationship between Classical and Quantum Mechanical Formalisms 1131
23.3.6 Evolution of η via Three-Wave Mixing 1132
23.4
Quasilinear Evolution of Unstable Distribution Functions—A Bump in the Tail 1136
23.4.1 Instability of Streaming Cosmic Rays 1138
23.5
Parametric Instabilities; Laser Fusion 1140
23.6
Solitons and Collisionless Shock Waves 1142
Bibliographic Note 1149
PART VII GENERAL RELATIVITY 1151
24
From Special to General Relativity 1153
24.1
Overview 1153
24.2
Special Relativity Once Again 1153
24.2.1 Geometric, Frame-Independent Formulation 1154
24.2.2 Inertial Frames and Components of Vectors, Tensors, and Physical Laws 1156
24.2.3 Light Speed, the Interval, and Spacetime Diagrams 1159
24.3
Differential Geometry in General Bases and in Curved Manifolds 1160
24.3.1 Nonorthonormal Bases 1161
xxii
Contents

24.3.2 Vectors as Directional Derivatives; Tangent Space; Commutators 1165
24.3.3 Differentiation of Vectors and Tensors; Connection Coefﬁcients 1169
24.3.4 Integration 1174
24.4
The Stress-Energy Tensor Revisited 1176
24.5
The Proper Reference Frame of an Accelerated Observer 1180
24.5.1 Relation to Inertial Coordinates; Metric in Proper Reference Frame; Transport Law
for Rotating Vectors 1183
24.5.2 Geodesic Equation for a Freely Falling Particle 1184
24.5.3 Uniformly Accelerated Observer 1186
24.5.4 Rindler Coordinates for Minkowski Spacetime 1187
Bibliographic Note 1190
25
Fundamental Concepts of General Relativity 1191
25.1
History and Overview 1191
25.2
Local Lorentz Frames, the Principle of Relativity, and Einstein’s Equivalence Principle 1195
25.3
The Spacetime Metric, and Gravity as a Curvature of Spacetime 1196
25.4
Free-Fall Motion and Geodesics of Spacetime 1200
25.5
Relative Acceleration, Tidal Gravity, and Spacetime Curvature 1206
25.5.1 Newtonian Description of Tidal Gravity 1207
25.5.2 Relativistic Description of Tidal Gravity 1208
25.5.3 Comparison of Newtonian and Relativistic Descriptions 1210
25.6
Properties of the Riemann Curvature Tensor 1213
25.7
Delicacies in the Equivalence Principle, and Some Nongravitational Laws of Physics in
Curved Spacetime 1217
25.7.1 Curvature Coupling in the Nongravitational Laws 1218
25.8
The Einstein Field Equation 1221
25.8.1 Geometrized Units 1224
25.9
Weak Gravitational Fields 1224
25.9.1 Newtonian Limit of General Relativity 1225
25.9.2 Linearized Theory 1227
25.9.3 Gravitational Field outside a Stationary, Linearized Source of Gravity 1231
25.9.4 Conservation Laws for Mass, Momentum, and Angular Momentum in
Linearized Theory 1237
25.9.5 Conservation Laws for a Strong-Gravity Source 1238
Bibliographic Note 1239
26
Relativistic Stars and Black Holes 1241
26.1
Overview 1241
26.2
Schwarzschild’s Spacetime Geometry 1242
26.2.1 The Schwarzschild Metric, Its Connection Coefﬁcients, and Its Curvature
Tensors 1242
Contents
xxiii

26.2.2 The Nature of Schwarzschild’s Coordinate System, and Symmetries of the
Schwarzschild Spacetime 1244
26.2.3 Schwarzschild Spacetime at Radii r ≫M: The Asymptotically Flat Region 1245
26.2.4 Schwarzschild Spacetime at r ∼M 1248
26.3
Static Stars 1250
26.3.1 Birkhoff’s Theorem 1250
26.3.2 Stellar Interior 1252
26.3.3 Local Conservation of Energy and Momentum 1255
26.3.4 The Einstein Field Equation 1257
26.3.5 Stellar Models and Their Properties 1259
26.3.6 Embedding Diagrams 1261
26.4
Gravitational Implosion of a Star to Form a Black Hole 1264
26.4.1 The Implosion Analyzed in Schwarzschild Coordinates 1264
26.4.2 Tidal Forces at the Gravitational Radius 1266
26.4.3 Stellar Implosion in Eddington-Finkelstein Coordinates 1267
26.4.4 Tidal Forces at r = 0—The Central Singularity 1271
26.4.5 Schwarzschild Black Hole 1272
26.5
Spinning Black Holes: The Kerr Spacetime 1277
26.5.1 The Kerr Metric for a Spinning Black Hole 1277
26.5.2 Dragging of Inertial Frames 1279
26.5.3 The Light-Cone Structure, and the Horizon 1279
26.5.4 Evolution of Black Holes—Rotational Energy and Its Extraction 1282
26.6
The Many-Fingered Nature of Time 1293
Bibliographic Note 1297
27
Gravitational Waves and Experimental Tests of General Relativity 1299
27.1
Overview 1299
27.2
Experimental Tests of General Relativity 1300
27.2.1 Equivalence Principle, Gravitational Redshift, and Global Positioning
System 1300
27.2.2 Perihelion Advance of Mercury 1302
27.2.3 Gravitational Deﬂection of Light, Fermat’s Principle, and Gravitational
Lenses 1305
27.2.4 Shapiro Time Delay 1308
27.2.5 Geodetic and Lense-Thirring Precession 1309
27.2.6 Gravitational Radiation Reaction 1310
27.3
Gravitational Waves Propagating through Flat Spacetime 1311
27.3.1 Weak, Plane Waves in Linearized Theory 1311
27.3.2 Measuring a Gravitational Wave by Its Tidal Forces 1315
27.3.3 Gravitons and Their Spin and Rest Mass 1319
xxiv
Contents

27.4
Gravitational Waves Propagating through Curved Spacetime 1320
27.4.1 Gravitational Wave Equation in Curved Spacetime 1321
27.4.2 Geometric-Optics Propagation of Gravitational Waves 1322
27.4.3 Energy and Momentum in Gravitational Waves 1324
27.5
The Generation of Gravitational Waves 1327
27.5.1 Multipole-Moment Expansion 1328
27.5.2 Quadrupole-Moment Formalism 1330
27.5.3 Quadrupolar Wave Strength, Energy, Angular Momentum, and Radiation
Reaction 1332
27.5.4 Gravitational Waves from a Binary Star System 1335
27.5.5 Gravitational Waves from Binaries Made of Black Holes, Neutron Stars,
or Both: Numerical Relativity 1341
27.6
The Detection of Gravitational Waves 1345
27.6.1 Frequency Bands and Detection Techniques 1345
27.6.2 Gravitational-Wave Interferometers: Overview and Elementary
Treatment 1347
27.6.3 Interferometer Analyzed in TT Gauge 1349
27.6.4 Interferometer Analyzed in the Proper Reference Frame of the
Beam Splitter 1352
27.6.5 Realistic Interferometers 1355
27.6.6 Pulsar Timing Arrays 1355
Bibliographic Note 1358
28
Cosmology 1361
28.1
Overview 1361
28.2
General Relativistic Cosmology 1364
28.2.1 Isotropy and Homogeneity 1364
28.2.2 Geometry 1366
28.2.3 Kinematics 1373
28.2.4 Dynamics 1376
28.3
The Universe Today 1379
28.3.1 Baryons 1379
28.3.2 Dark Matter 1380
28.3.3 Photons 1381
28.3.4 Neutrinos 1382
28.3.5 Cosmological Constant 1382
28.3.6 Standard Cosmology 1383
28.4
Seven Ages of the Universe 1383
28.4.1 Particle Age 1384
28.4.2 Nuclear Age 1387
28.4.3 Photon Age 1392
Contents
xxv

28.4.4 Plasma Age 1393
28.4.5 Atomic Age 1397
28.4.6 Gravitational Age 1397
28.4.7 Cosmological Age 1400
28.5
Galaxy Formation 1401
28.5.1 Linear Perturbations 1401
28.5.2 Individual Constituents 1406
28.5.3 Solution of the Perturbation Equations 1410
28.5.4 Galaxies 1412
28.6
Cosmological Optics 1415
28.6.1 Cosmic Microwave Background 1415
28.6.2 Weak Gravitational Lensing 1422
28.6.3 Sunyaev-Zel’dovich Effect 1428
28.7
Three Mysteries 1431
28.7.1 Inﬂation and the Origin of the Universe 1431
28.7.2 Dark Matter and the Growth of Structure 1440
28.7.3 The Cosmological Constant and the Fate of the Universe 1444
Bibliographic Note 1447
References 1449
Name Index 1473
Subject Index 1477
xxvi
Contents

BOXES
1.1
Readers’ Guide 6
1.2
Vectors and Tensors in Quantum Theory
18
2.1
Readers’ Guide 38
2.2
Measuring the Speed of Light Without Light 43
2.3
Propagation Speeds of Other Waves 44
2.4
Proof of Invariance of the Interval for a Timelike Separation 46
3.1
Readers’ Guide 96
3.2
Sophisticated Derivation of Relativistic Collisionless Boltzmann Equation
136
3.3
Two-Lengthscale Expansions 146
4.1
Readers’ Guide 156
4.2
Density Operator and Quantum Statistical Mechanics
165
4.3
Entropy Increase Due to Discarding Quantum Correlations 186
5.1
Readers’ Guide 220
5.2
Two Useful Relations between Partial Derivatives 225
5.3
Derivation of van der Waals Grand Potential
235
6.1
Readers’ Guide 284
7.1
Readers’ Guide 352
7.2
Bookkeeping Parameter in Two-Lengthscale Expansions 360
8.1
Readers’ Guide 412
9.1
Readers’ Guide 456
9.2
Astronomical Seeing, Speckle Image Processing, and Adaptive Optics
466
9.3
Modes of a Fabry-Perot Cavity with Spherical Mirrors 491
xxvii

10.1
Readers’ Guide 514
10.2
Properties of Some Anisotropic, Nonlinear Crystals 541
11.1
Readers’ Guide 568
11.2
Irreducible Tensorial Parts of a Second-Rank Tensor in 3-Dimensional
Euclidean Space 572
11.3
Methods of Solving the Navier-Cauchy Equation 590
11.4
Shear Tensor in Spherical and Cylindrical Coordinates
618
12.1
Readers’ Guide 630
12.2
Wave Equations in Continuum Mechanics 633
13.1
Readers’ Guide 676
13.2
Thermodynamic Considerations 679
13.3
Flow Visualization 699
13.4
Self-Gravity
705
13.5
Terminology Used in Chapter 13 724
14.1
Readers’ Guide 730
14.2
Movies Relevant to this Chapter 731
14.3
Swimming at Low and High Reynolds Number: Fish versus Bacteria 747
14.4
Stream Function for a General, Two-Dimensional, Incompressible Flow
760
14.5
Arbitrariness of Rotation Axis;  for Atmospheric and Oceanic Flows 769
15.1
Readers’ Guide 788
15.2
Movies and Photographs on Turbulence 790
15.3
Consequences of the Kelvin-Helmholtz Instability 801
16.1
Readers’ Guide 836
16.2
Movies Relevant to this Chapter 837
16.3
Nonlinear Shallow-Water Waves with Variable Depth 841
16.4
Surface Tension 844
17.1
Readers’ Guide 876
17.2
Movies Relevant to this Chapter 877
17.3
Velocity Proﬁles for 1-Dimensional Flow Between Chambers 885
17.4
Space Shuttle 889
18.1
Readers’ Guide 918
18.2
Mantle Convection and Continental Drift 932
19.1
Readers’ Guide 944
20.1
Readers’ Guide 998
21.1
Readers’ Guide 1034
xxviii
Boxes

22.1
Readers’ Guide 1070
22.2
Stability of a Feedback-Control System: Analysis by Nyquist’s Method
1093
23.1
Readers’ Guide 1112
23.2
Laser Fusion 1141
24.1
Readers’ Guide 1154
24.2
Stress-Energy Tensor for a Point Particle
1178
24.3
Inertial Guidance Systems 1182
25.1
Readers’ Guide 1192
25.2
Decomposition of Riemann: Tidal and Frame-Drag Fields
1235
26.1
Readers’ Guide 1242
26.2
Connection Coefﬁcients and Curvature Tensors for Schwarzschild Solution 1243
26.3
Tendex and Vortex Lines Outside a Black Hole
1295
27.1
Readers’ Guide 1300
27.2
Projecting Out the Gravitational-Wave Field hTT
ij
1314
27.3
Tendex and Vortex Lines for a Gravitational Wave
1318
27.4
Geometrodynamics
1344
28.1
Readers’ Guide 1362
Boxes
xxix


PREFACE
The study of physics (including astronomy) is one of the oldest academic enterprises.
Remarkable surges in inquiry occurred in equally remarkable societies—in Greece
and Egypt, in Mesopotamia, India and China—and especially in Western Europe
from the late sixteenth century onward. Independent, rational inquiry ﬂourished at
the expense of ignorance, superstition, and obeisance to authority.
Physics is a constructive and progressive discipline, so these surges left behind
layers of understanding derived from careful observation and experiment, organized
by fundamental principles and laws that provide the foundation of the discipline
today. Meanwhile the detritus of bad data and wrong ideas has washed away. The
laws themselves were so general and reliable that they provided foundations for
investigation far beyond the traditional frontiers of physics, and for the growth of
technology.
The start of the twentieth century marked a watershed in the history of physics,
when attention turned to the small and the fast. Although rightly associated with
the names of Planck and Einstein, this turning point was only reached through the
curiosity and industry of their many forerunners. The resulting quantum mechanics
and relativity occupied physicists for much of the succeeding century and today
are viewed very differently from each other. Quantum mechanics is perceived as an
abrupt departure from the tacit assumptions of the past, while relativity—though no
less radical conceptually—is seen as a logical continuation of the physics of Galileo,
Newton, and Maxwell. There is no better illustration of this than Einstein’s growing
special relativity into the general theory and his famous resistance to the quantum
mechanics of the 1920s, which others were developing.
This is a book about classical physics—a name intended to capture the pre-
quantum scientiﬁc ideas, augmented by general relativity. Operationally, it is physics
in the limit that Planck’s constant h →0. Classical physics is sometimes used, pejora-
tively, to suggest that “classical” ideas were discarded and replaced by new principles
and laws. Nothing could be further from the truth. The majority of applications of
xxxi

physics today are still essentially classical. This does not imply that physicists or others
working in these areas are ignorant or dismissive of quantum physics. It is simply that
the issues with which they are confronted are mostly addressed classically. Further-
more, classicalphysicshasnotstoodstillwhilethequantumworldwasbeingexplored.
In scope and in practice, it has exploded on many fronts and would now be quite un-
recognizable to a Helmholtz, a Rayleigh, or a Gibbs. In this book, we have tried to
emphasize these contemporary developments and applications at the expense of his-
torical choices, and this is the reason for our seemingly oxymoronic title, Modern
Classical Physics.
This book is ambitious in scope, but to make it bindable and portable (and so
the authors could spend some time with their families), we do not develop classi-
cal mechanics, electromagnetic theory, or elementary thermodynamics. We assume
the reader has already learned these topics elsewhere, perhaps as part of an under-
graduate curriculum. We also assume a normal undergraduate facility with applied
mathematics. This allows us to focus on those topics that are less frequently taught in
undergraduate and graduate courses.
Another important exclusion is numerical methods and simulation. High-
performancecomputinghastransformedmodernresearchandenabledinvestigations
that were formerly hamstrung by the limitations of special functions and artiﬁcially
imposed symmetries. To do justice to the range of numerical techniques that have
been developed—partial differential equation solvers, ﬁnite element methods, Monte
Carlo approaches, graphics, and so on—would have more than doubled the scope and
size of the book. Nonetheless, because numerical evaluations are crucial for physical
insight, the book includes many applications and exercises in which user-friendly nu-
merical packages (such as Maple, Mathematica, and Matlab) can be used to produce
interesting numerical results without too much effort. We hope that, via this pathway
from fundamental principle to computable outcome, our book will bring readers not
only physical insight but also enthusiasm for computational physics.
Classical physics as we develop it emphasizes physical phenomena on macro-
scopic scales: scales where the particulate natures of matter and radiation are sec-
ondary to their behavior in bulk; scales where particles’ statistical—as opposed to
individual—properties are important, and where matter’s inherent graininess can be
smoothed over.
In this book, we take a journey through spacetime and phase space; through
statistical and continuum mechanics (including solids, ﬂuids, and plasmas); and
through optics and relativity, both special and general. In our journey, we seek to
comprehend the fundamental laws of classical physics in their own terms, and also in
relation to quantum physics. And, using carefully chosen examples, we show how the
classical laws are applied to important, contemporary, twenty-ﬁrst-century problems
and to everyday phenomena; and we also uncover some deep relationships among the
various fundamental laws and connections among the practical techniques that are
used in different subﬁelds of physics.
xxxii
Preface

Geometry is a deep theme throughout this book and a very important connector.
We shall see how a few geometrical considerations dictate or strongly limit the basic
principles of classical physics. Geometry illuminates the character of the classical
principles and also helps relate them to the corresponding principles of quantum
physics.Geometricalmethodscanalsoobviatelengthyanalyticalcalculations.Despite
this, long, routine algebraic manipulations are sometimes unavoidable; in such cases,
we occasionally save space by invoking modern computational symbol manipulation
programs, such as Maple, Mathematica, and Matlab.
This book is the outgrowth of courses that the authors have taught at Caltech and
Stanford beginning 37 years ago. Our goal was then and remains now to ﬁll what we
saw as a large hole in the traditional physics curriculum, at least in the United States:
.
We believe that every masters-level or PhD physicist should be familiar with
the basic concepts of all the major branches of classical physics and should
have had some experience in applying them to real-world phenomena; this
book is designed to facilitate this goal.
.
Many physics, astronomy, and engineering graduate students in the United
States and around the world use classical physics extensively in their re-
search, and even more of them go on to careers in which classical physics
is an essential component; this book is designed to expedite their efforts.
.
Many professional physicists and engineers discover, in mid-career, that
they need an understanding of areas of classical physics that they had not
previously mastered. This book is designed to help them ﬁll in the gaps and
see the relationship to already familiar topics.
In pursuit of this goal, we seek, in this book, to give the reader a clear understanding
ofthebasicconceptsandprinciplesofclassicalphysics.Wepresenttheseprinciplesinthe
language of modern physics (not nineteenth-century applied mathematics), and we
present them primarily for physicists—though we have tried hard to make the content
interesting, useful, and accessible to a much larger community including engineers,
mathematicians, chemists, biologists, and so on. As far as possible, we emphasize
theory that involves general principles which extend well beyond the particular topics
we use to illustrate them.
In this book, we also seek to teach the reader how to apply the ideas of classical
physics. We do so by presenting contemporary applications from a variety of ﬁelds,
such as
.
fundamental physics, experimental physics, and applied physics;
.
astrophysics and cosmology;
.
geophysics, oceanography, and meteorology;
.
biophysics and chemical physics; and
Preface
xxxiii

.
engineering, optical science and technology, radio science and technology,
and information science and technology.
Why is the range of applications so wide? Because we believe that physicists should
have enough understanding of general principles to attack problems that arise in
unfamiliar environments. In the modern era, a large fraction of physics students will
go on to careers outside the core of fundamental physics. For such students, a broad
exposure to non-core applications can be of great value. For those who wind up in the
core, such an exposure is of value culturally, and also because ideas from other ﬁelds
often turn out to have impact back in the core of physics. Our examples illustrate
how basic concepts and problem-solving techniques are freely interchanged across
disciplines.
We strongly believe that classical physics should not be studied in isolation from
quantum mechanics and its modern applications. Our reasons are simple:
.
Quantum mechanics has primacy over classical physics. Classical phys-
ics is an approximation—often excellent, sometimes poor—to quantum
mechanics.
.
In recent decades, many concepts and mathematical techniques developed
for quantum mechanics have been imported into classical physics and there
used to enlarge our classical understanding and enhance our computational
capability. An example that we shall study is nonlinearly interacting plasma
waves, which are best treated as quanta (“plasmons”), despite their being
solutions of classical ﬁeld equations.
.
Ideas developed initially for classical problems are frequently adapted for
application to avowedly quantum mechanical subjects; examples (not dis-
cussed in this book) are found in supersymmetric string theory and in the
liquid drop model of the atomic nucleus.
Because of these intimate connections between quantum and classical physics, quan-
tum physics appears frequently in this book.
The amount and variety of material covered in this book may seem overwhelming.
If so, keep in mind the key goals of the book: to teach the fundamental concepts, which
are not so extensive that they should overwhelm, and to illustrate those concepts.
Our goal is not to provide a mastery of the many illustrative applications contained
in the book, but rather to convey the spirit of how to apply the basic concepts of
classical physics. To help students and readers who feel overwhelmed, we have labeled
as “Track Two” sections that can be skipped on a ﬁrst reading, or skipped entirely—
but are sufﬁciently interesting that many readers may choose to browse or study them.
Track-Two sections are labeled by the symbol
. To keep Track One manageable for
a one-year course, the Track-One portion of each chapter is rarely longer than 40
pages (including many pages of exercises) and is often somewhat shorter. Track One
is designed for a full-year course at the ﬁrst-year graduate level; that is how we have
xxxiv
Preface

mostly used it. (Many ﬁnal-year undergraduates have taken our course successfully,
but rarely easily.)
The book is divided into seven parts:
I. Foundations—which introduces our book’s powerful geometric point of
viewonthelawsofphysicsandbringsreadersuptospeedonsomeconcepts
and mathematical tools that we shall need. Many readers will already have
mastered most or all of the material in Part I and might ﬁnd that they can
understand most of the rest of the book without adopting our avowedly
geometric viewpoint. Nevertheless, we encourage such readers to browse
Part I, at least brieﬂy, before moving on, so as to become familiar with
this viewpoint. We believe the investment will be repaid. Part I is split
into two chapters, Chap. 1 on Newtonian physics and Chap. 2 on special
relativity. Since nearly all of Parts II–VI is Newtonian, readers may choose
to skip Chap. 2 and the occasional special relativity sections of subsequent
chapters, until they are ready to launch into Part VII, General Relativity.
Accordingly, Chap. 2 is labeled Track Two, though it becomes Track One
when readers embark on Part VII.
II. Statistical Physics—including kinetic theory, statistical mechanics, statis-
tical thermodynamics, and the theory of random processes. These subjects
underlie some portions of the rest of the book, especially plasma physics
and ﬂuid mechanics.
III. Optics—by which we mean classical waves of all sorts: light waves, radio
waves, sound waves, water waves, waves in plasmas, and gravitational
waves. The major concepts we develop for dealing with all these waves
include geometric optics, diffraction, interference, and nonlinear wave-
wave mixing.
IV. Elasticity—elastic deformations, both static and dynamic, of solids. Here
we develop the use of tensors to describe continuum mechanics.
V. Fluid Dynamics—with ﬂows ranging from the traditional ones of air and
water to more modern cosmic and biological environments. We intro-
ducevorticity, viscosity, turbulence, boundarylayers, heattransport, sound
waves, shock waves, magnetohydrodynamics, and more.
VI. Plasma Physics—including plasmas in Earth-bound laboratories and in
technological (e.g., controlled-fusion) devices, Earth’s ionosphere, and cos-
mic environments. In addition to magnetohydrodynamics (treated in Part
V), we develop two-ﬂuid and kinetic approaches, and techniques of non-
linear plasma physics.
VII. General Relativity—the physics of curved spacetime. Here we show how
the physical laws that we have discussed in ﬂat spacetime are modiﬁed
to account for curvature. We also explain how energy and momentum
Preface
xxxv

generate this curvature. These ideas are developed for their principal clas-
sical applications to neutron stars, black holes, gravitational radiation, and
cosmology.
It should be possible to read and teach these parts independently, provided one
is prepared to use the cross-references to access some concepts, tools, and results
developed in earlier parts.
Five of the seven parts (II, III, V, VI, and VII) conclude with chapters that focus
on applications where there is much current research activity and, consequently, there
are many opportunities for physicists.
Exercises are a major component of this book. There are ﬁve types of exercises:
1. Practice.Exercises that provide practice at mathematical manipulations (e.g.,
of tensors).
2. Derivation.Exercises that ﬁll in details of arguments skipped over in the text.
3. Example. Exercises that lead the reader step by step through the details of
some important extension or application of the material in the text.
4. Problem. Exercises with few, if any, hints, in which the task of ﬁguring out
how to set up the calculation and get started on it often is as difﬁcult as doing
the calculation itself.
5. Challenge. Especially difﬁcult exercises whose solution may require reading
other books or articles as a foundation for getting started.
We urge readers to try working many of the exercises, especially the examples, which
should be regarded as continuations of the text and which contain many of the
most illuminating applications. Exercises that we regard as especially important are
designated with **.
A few words on units and conventions. In this book we deal with practical matters
and frequently need to have a quantitative understanding of the magnitudes of vari-
ous physical quantities. This requires us to adopt a particular unit system. Physicists
use both Gaussian and SI units; units that lie outside both formal systems are also
commonly used in many subdisciplines. Both Gaussian and SI units provide a com-
plete and internally consistent set for all of physics, and it is an often-debated issue
as to which system is more convenient or aesthetically appealing. We will not enter
this debate! One’s choice of units should not matter, and a mature physicist should
be able to change from one system to another with little thought. However, when
learning new concepts, having to ﬁgure out “where the 2πs and 4πs go” is a genuine
impediment to progress. Our solution to this problem is as follows. For each physics
subﬁeld that we study, we consistently use the set of units that seem most natural or
that, we judge, constitute the majority usage by researchers in that subﬁeld. We do not
pedantically convert cm to m or vice versa at every juncture; we trust that the reader
xxxvi
Preface

can easily make whatever translation is necessary. However, where the equations are
actually different—primarily in electromagnetic theory—we occasionally provide, in
brackets or footnotes, the equivalent equations in the other unit system and enough
information for the reader to proceed in his or her preferred scheme.
We encourage readers to consult this book’s website, http://press.princeton.edu/
titles/MCP.html, for information, errata, and various resources relevant to the book.
A large number of people have inﬂuenced this book and our viewpoint on the
material in it. We list many of them and express our thanks in the Acknowledgments.
Many misconceptions and errors have been caught and corrected. However, in a book
of this size and scope, others will remain, and for these we take full responsibility.
We would be delighted to learn of these from readers and will post corrections and
explanations on this book’s website when we judge them to be especially important
and helpful.
Above all, we are grateful for the support of our wives, Carolee and Liz—and
especially for their forbearance in epochs when our enterprise seemed like a mad
and vain pursuit of an unreachable goal, a pursuit that we juggled with huge numbers
of other obligations, while Liz and Carolee, in the midst of their own careers, gave us
the love and encouragement that were crucial in keeping us going.
Preface
xxxvii


ACKNOWLEDGMENTS
This book evolved gradually from notes written in 1980–81, through improved notes,
then sparse prose, and on into text that ultimately morphed into what you see today.
Over these three decades and more, courses based on our evolving notes and text were
taught by us and by many of our colleagues at Caltech, Stanford, and elsewhere. From
those teachers and their students, and from readers who found our evolving text on
the web and dove into it, we have received an extraordinary volume of feedback,1 and
also patient correction of errors and misconceptions as well as help with translating
passages that were correct but impenetrable into more lucid and accessible treatments.
For all this feedback and to all who gave it, we are extremely grateful. We wish that we
hadkeptbetterrecords; theheartfeltthanksthatweofferallthesecolleagues, students,
and readers, named and unnamed, are deeply sincere.
Teachers who taught courses based on our evolving notes and text, and gave
invaluable feedback, include Professors Richard Blade, Yanbei Chen, Michael Cross,
Steven Frautschi, Peter Goldreich, Steve Koonin, Christian Ott, Sterl Phinney, David
Politzer, John Preskill, John Schwarz, and David Stevenson at Caltech; Professors Tom
Abel, Seb Doniach, Bob Wagoner, and Shoucheng Zhang at Stanford; and Professor
Sandor Kovacs at Washington University in St. Louis.
Our teaching assistants, who gave us invaluable feedback on the text, improve-
ments of exercises, and insights into the difﬁculty of the material for the students,
include Jeffrey Atwell, Nate Bode, Yu Cao, Yi-Yuh Chen, Jane Dai, Alexei Dvoret-
sky, Fernando Echeverria, Jiyu Feng, Eanna Flanagan, Marc Goroff, Dan Grin, Arun
Gupta, Alexandr Ikriannikov, Anton Kapustin, Kihong Kim, Hee-Won Lee, Geoffrey
Lovelace, Miloje Makivic, Draza Markovic, Keith Matthews, Eric Moranson, Mike
Morris, Chung-Yi Mou, Rob Owen, Yi Pan, Jaemo Park, Apoorva Patel, Alexander
Putilin, Shuyan Qi, Soo Jong Rey, Fintan Ryan, Bonnie Shoemaker, Paul Simeon,
1.
Speciﬁc applications that were originated by others, to the best of our memory, are acknowledged in the
text.
xxxix

Hidenori Sinoda, Matthew Stevenson, Wai Mo Suen, Marcus Teague, Guodang Wang,
Xinkai Wu, Huan Yang, Jimmy Yee, Piljin Yi, Chen Zheng, and perhaps others of
whom we have lost track!
Among the students and readers of our notes and text, who have corresponded
with us, sending important suggestions and errata, are Bram Achterberg, Mustafa
Amin, Richard Anantua, Alborz Bejnood, Edward Blandford, Jonathan Blandford,
Dick Bond, Phil Bucksbaum, James Camparo, Conrado Cano, U Lei Chan, Vernon
Chaplin, Mina Cho, Ann Marie Cody, Sandro Command`e, Kevin Fiedler, Krzysztof
Findeisen, Jeff Graham, Casey Handmer, Ted Jacobson, Matt Kellner, Deepak Kumar,
Andrew McClung, Yuki Moon, Evan O’Connor, Jeffrey Oishi, Keith Olive, Zhen Pan,
Eric Peterson, Laurence Perreault Levasseur, Vahbod Pourahmad, Andreas Reiseneg-
ger, David Reiss, Pavlin Savov, Janet Scheel, Yuki Takahashi, Fun Lim Yee, Yajie Yuan,
and Aaron Zimmerman.
For computational advice or assistance, we thank Edward Campbell, Mark Scheel,
Chris Mach, and Elizabeth Wood.
Academic support staff who were crucial to our work on this book include Chris-
tine Aguilar, JoAnn Boyd, Jennifer Formicelli, and Shirley Hampton.
The editorial and production professionals at Princeton University Press (Peter
Dougherty, Karen Fortgang, Ingrid Gnerlich, Eric Henney, and Arthur Werneck) and
at Princeton Editorial Associates (Peter Strupp and his freelance associates Paul Anag-
nostopoulos, Laurel Muller, MaryEllen Oliver, Joe Snowden, and Cyd Westmoreland)
have been magniﬁcent, helping us plan and design this book, and transforming our
raw prose and primitive ﬁgures into a visually appealing volume, with sustained at-
tention to detail, courtesy, and patience as we missed deadline after deadline.
Of course, we the authors take full responsibility for all the errors of judgment,
bad choices, and mistakes that remain.
Roger Blandford thanks his many supportive colleagues at Caltech, Stanford Uni-
versity, and the Kavli Institute for Particle Astrophysics and Cosmology. He also
acknowledges the Humboldt Foundation, the Miller Institute, the National Science
Foundation, and the Simons Foundation for generous support during the completion
of this book. And he also thanks the Berkeley Astronomy Department; Caltech; the
Institute of Astronomy, Cambridge; and the Max Planck Institute for Astrophysics,
Garching, for hospitality.
Kip Thorne is grateful to Caltech—the administration, faculty, students, and
staff—for the supportive environment that made possible his work on this book, work
that occupied a signiﬁcant portion of his academic career.
xl
Acknowledgments

I
PART I
FOUNDATIONS
In this book, a central theme will be a Geometric Principle: The laws of physics must all
be expressible as geometric (coordinate-independent and reference-frame-independent)
relationships between geometric objects (scalars, vectors, tensors, . . . ) that represent
physical entities.
There are three different conceptual frameworks for the classical laws of physics,
and correspondingly, three different geometric arenas for the laws; see Fig. 1. General
relativity is the most accurate classical framework; it formulates the laws as geometric
relationships among geometric objects in the arena of curved 4-dimensional space-
time. Special relativity is the limit of general relativity in the complete absence of
gravity; its arena is ﬂat, 4-dimensional Minkowski spacetime.1 Newtonian physics
is the limit of general relativity when
.
gravity is weak but not necessarily absent,
.
relative speeds of particles and materials are small compared to the speed of
light c, and
.
all stresses (pressures) are small compared to the total density of mass-
energy.
Its arena is ﬂat, 3-dimensional Euclidean space with time separated off and made
universal (by contrast with relativity’s reference-frame-dependent time).
In Parts II–VI of this book (covering statistical physics, optics, elasticity, ﬂuid
mechanics, and plasma physics), we conﬁne ourselves to the Newtonian formulations
of the laws (plus special relativistic formulations in portions of Track Two), and
accordingly, our arena will be ﬂat Euclidean space (plus ﬂat Minkowski spacetime
in portions of Track Two). In Part VII, we extend many of the laws we have studied
into the domain of strong gravity (general relativity)—the arena of curved spacetime.
1.
This is so-called because Hermann Minkowski (1908) identiﬁed the special relativistic invariant interval
as deﬁning a metric in spacetime and elucidated the resulting geometry of ﬂat spacetime.
1

General relativity
• Most accurate framework for classical physics
• Arena: Curved spacetime
Special relativity
• Classical physics in the absence 
 of gravity
• Arena: Flat, Minkowski spacetime
low speeds
small stresses
add weak gravity
weak gravity
low speeds
small stresses
vanishing
gravity
Newtonian physics
• Approximation to relativistic physics
• Arena: Flat, Euclidean 3-space plus 
 universal time
FIGURE 1 The three frameworks and arenas for the classical laws of physics and their relationship to
one another.
In Parts II and III (on statistical physics and optics), in addition to conﬁning
ourselves to ﬂat space (plus ﬂat spacetime in Track Two), we avoid any sophisticated
use of curvilinear coordinates. Correspondingly, when using coordinates in nontrivial
ways, we conﬁne ourselves to Cartesian coordinates in Euclidean space (and Lorentz
coordinates in Minkowski spacetime).
Part I of this book contains just two chapters. Chapter 1 is an introduction to
our geometric viewpoint on Newtonian physics and to all the geometric mathemat-
ical tools that we shall need in Parts II and III for Newtonian physics in its arena,
3-dimensional Euclidean space. Chapter 2 introduces our geometric viewpoint on
special relativistic physics and extends our geometric tools into special relativity’s
arena, ﬂat Minkowski spacetime. Readers whose focus is Newtonian physics will have
no need for Chap. 2; and if they are already familiar with the material in Chap. 1 but
not from our geometric viewpoint, they can successfully study Parts II–VI without
reading Chap. 1. However, in doing so, they will miss some deep insights; so we rec-
ommend they at least browse Chap. 1 to get some sense of our viewpoint, then return
to the chapter occasionally, as needed, when encountering an unfamiliar geometric
argument.
In Parts IV, V, and VI, when studying elasticity, ﬂuid dynamics, and plasma phys-
ics, we use curvilinear coordinates in nontrivial ways. As a foundation for this, at the
beginning of Part IV, we extend our ﬂat-space geometric tools to curvilinear coordi-
nate systems (e.g., cylindrical and spherical coordinates). Finally, at the beginning of
Part VII, we extend our geometric tools to the arena of curved spacetime.
Throughout this book, we pay close attention to the relationship between classical
physics and quantum physics. Indeed, we often ﬁnd it powerful to use quantum me-
chanical language or formalism when discussing and analyzing classical phenomena.
2
Part I

classical limit
classical limit
classical limit
classical limit
low speeds,
small stresses,
add weak
gravity
no gravity
low speeds,
particles not
created or
destroyed
Quantum gravity
(string theory?)
no gravity
classical
 gravity
Quantum field theory
in curved spacetime
General relativity
Special relativity
Newtonian physics
Quantum field theory
in flat spacetime
Nonrelativistic
quantum mechanics
FIGURE 2 The relationship of the three frameworks for classical physics (on right)
to four frameworks for quantum physics (on left). Each arrow indicates an
approximation. All other frameworks are approximations to the ultimate laws of
quantum gravity (whatever they may be—perhaps a variant of string theory).
This quantum power in classical domains arises because quantum physics is primary
and classical physics is secondary. Today we see classical physics as arising from quan-
tum physics, though historically the linkage was inverted. The relationship between
quantum frameworks and arenas for the laws of physics, and classical frameworks, is
sketched in Fig. 2.
Foundations
3


1
CHAPTER ONE
Newtonian Physics: Geometric Viewpoint
Geometry postulates the solution of these problems from mechanics and teaches the use of the
problems thus solved. And geometry can boast that with so few principles obtained from other ﬁelds,
it can do so much.
ISAAC NEWTON, 1687
1.1
1.1 Introduction
1.1.1
1.1.1 The Geometric Viewpoint on the Laws of Physics
In this book, we adopt a different viewpoint on the laws of physics than that in many
elementary and intermediate texts. In most textbooks, physical laws are expressed in
termsofquantities(locationsinspace, momentaofparticles, etc.)thataremeasuredin
somecoordinatesystem.Forexample, Newtonianvectorialquantitiesareexpressedas
tripletsofnumbers[e.g., p = (px, py, pz) = (1, 9, −4)], representingthecomponents
of a particle’s momentum on the axes of a Cartesian coordinate system; and tensors
are expressed as arrays of numbers (e.g.,
I =
⎡
⎢⎣
Ixx
Ixy
Ixz
Iyx
Iyy
Iyz
Izx
Izy
Izz
⎤
⎥⎦
(1.1)
for the moment of inertia tensor).
By contrast, in this book we express all physical quantities and laws in geometric
forms, i.e., in forms that are independent of any coordinate system or basis vectors.
For example, a particle’s velocity v and the electric and magnetic ﬁelds E and B that
it encounters will be vectors described as arrows that live in the 3-dimensional, ﬂat
Euclidean space of everyday experience.1 They require no coordinate system or basis
vectors for their existence or description—though often coordinates will be useful. In
other words, v represents the vector itself and is not just shorthand for an ordered list
of numbers.
1.
This interpretation of a vector is close to the ideas of Newton and Faraday. Lagrange, Hamilton, Maxwell,
and many others saw vectors in terms of Cartesian components. The vector notation was streamlined by
Gibbs, Heaviside, and others, but the underlying coordinate system was still implicit, and v was usually
regarded as shorthand for (vx, vy, vz).
5

BOX 1.1.
READERS’ GUIDE
.
This chapter is a foundation for almost all of this book.
.
Many readers already know the material in this chapter, but from
a viewpoint different from our geometric one. Such readers will be
able to understand almost all of Parts II–VI of this book without
learning our viewpoint. Nevertheless, that geometric viewpoint has
such power that we encourage them to learn it by browsing this
chapter and focusing especially on Secs. 1.1.1, 1.2, 1.3, 1.5, 1.7, and
1.8.
.
The stress tensor, introduced and discussed in Sec. 1.9, plays an
important role in kinetic theory (Chap. 3) and a crucial role in
elasticity (Part IV), ﬂuid dynamics (Part V), and plasma physics
(Part VI).
.
The integral and differential conservation laws derived and discussed
in Secs. 1.8 and 1.9 play major roles throughout this book.
.
The Box labeled
is advanced material (Track Two) that can be
skipped in a time-limited course or on a ﬁrst reading of this book.
WeinsistthattheNewtonianlawsofphysicsallobeyaGeometricPrinciple:theyare
all geometric relationships among geometric objects (primarily scalars, vectors, and
tensors), expressible without the aid of any coordinates or bases. An example is the
Lorentz force law mdv/dt = q(E + v × B)—a (coordinate-free) relationship between
the geometric (coordinate-independent) vectors v, E, and B and the particle’s scalar
mass m and charge q. As another example, a body’s moment of inertia tensor I can
be viewed as a vector-valued linear function of vectors (a coordinate-independent,
basis-independent geometric object). Insert into the tensor I the body’s angular ve-
locity vector , and you get out the body’s angular momentum vector: J = I(). No
coordinates or basis vectors are needed for this law of physics, nor is any description
of I as a matrix-like entity with components Iij required. Components are secondary;
they only exist after one has chosen a set of basis vectors. Components (we claim)
are an impediment to a clear and deep understanding of the laws of classical physics.
The coordinate-free, component-free description is deeper, and—once one becomes
accustomed to it—much more clear and understandable.2
2.
This philosophy is also appropriate for quantum mechanics (see Box 1.2) and, especially, quantum ﬁeld
theory, where it is the invariance of the description under gauge and other symmetry operations that
is the powerful principle. However, its implementation there is less direct, simply because the spaces in
which these symmetries lie are more abstract and harder to conceptualize.
6
Chapter 1. Newtonian Physics: Geometric Viewpoint

By adopting this geometric viewpoint, we gain great conceptual power and often
also computational power. For example, when we ignore experiment and simply ask
what forms the laws of physics can possibly take (what forms are allowed by the
requirement that the laws be geometric), we shall ﬁnd that there is remarkably little
freedom. Coordinate independence and basis independence strongly constrain the
laws of physics.3
This power, together with the elegance of the geometric formulation, suggests that
in some deep sense, Nature’s physical laws are geometric and have nothing whatsoever
to do with coordinates or components or vector bases.
1.1.2
1.1.2 Purposes of This Chapter
The principal purpose of this foundational chapter is to teach the reader this geometric
viewpoint.
The mathematical foundation for our geometric viewpoint is differential geometry
(also called “tensor analysis” by physicists). Differential geometry can be thought of as
an extension of the vector analysis with which all readers should be familiar. A second
purpose of this chapter is to develop key parts of differential geometry in a simple form
well adapted to Newtonian physics.
1.1.3
1.1.3 Overview of This Chapter
In this chapter, we lay the geometric foundations for the Newtonian laws of physics in
ﬂatEuclideanspace.WebegininSec.1.2 byintroducingsomefoundationalgeometric
concepts: points, scalars, vectors, inner products of vectors, and the distance between
points. Then in Sec. 1.3, we introduce the concept of a tensor as a linear function
of vectors, and we develop a number of geometric tools: the tools of coordinate-free
tensor algebra. In Sec. 1.4, we illustrate our tensor-algebra tools by using them to
describe—without any coordinate system—the kinematics of a charged point particle
that moves through Euclidean space, driven by electric and magnetic forces.
In Sec. 1.5, we introduce, for the ﬁrst time, Cartesian coordinate systems and their
basis vectors, and also the components of vectors and tensors on those basis vectors;
and we explore how to express geometric relationships in the language of components.
In Sec. 1.6, we deduce how the components of vectors and tensors transform when
one rotates the chosen Cartesian coordinate axes. (These are the transformation laws
that most physics textbooks use to deﬁne vectors and tensors.)
In Sec. 1.7, we introduce directional derivatives and gradients of vectors and ten-
sors, thereby moving from tensor algebra to true differential geometry (in Euclidean
space). We also introduce the Levi-Civita tensor and use it to deﬁne curls and cross
3.
Examples are the equation of elastodynamics (12.4b) and the Navier-Stokes equation of ﬂuid mechanics
(13.69), which are both dictated by momentum conservation plus the form of the stress tensor [Eqs.
(11.18), (13.43), and (13.68)]—forms that are dictated by the irreducible tensorial parts (Box 11.2) of
the strain and rate of strain.
1.1 Introduction
7

products, and we learn how to use index gymnastics to derive, quickly, formulas for
multiple cross products. In Sec. 1.8, we use the Levi-Civita tensor to deﬁne vectorial
areas, scalar volumes, and integration over surfaces. These concepts then enable us to
formulate, in geometric, coordinate-free ways, integral and differential conservation
laws. In Sec. 1.9, we discuss, in particular, the law of momentum conservation, formu-
lating it in a geometric way with the aid of a geometric object called the stress tensor.
As important examples, we use this geometric conservation law to derive and discuss
the equations of Newtonian ﬂuid dynamics, and the interaction between a charged
medium and an electromagnetic ﬁeld. We conclude in Sec. 1.10 with some concepts
from special relativity that we shall need in our discussions of Newtonian physics.
1.2
1.2 Foundational Concepts
In this section, we sketch the foundational concepts of Newtonian physics without
using any coordinate system or basis vectors. This is the geometric viewpoint that we
advocate.
space and time
The arena for the Newtonian laws of physics is a spacetime composed of the
familiar 3-dimensional Euclidean space of everyday experience (which we call 3-
space) and a universal time t. We denote points (locations) in 3-space by capital script
letters, such as P and Q. These points and the 3-space in which they live require no
coordinates for their deﬁnition.
scalar
A scalar is a single number. We are most interested in scalars that directly represent
physical quantities (e.g., temperature T ). As such, they are real numbers, and when
they are functions of location P in space [e.g., T (P)], we call them scalar ﬁelds.
However, sometimes we will work with complex numbers—most importantly in
quantum mechanics, but also in various Fourier representations of classical physics.
vector
A vector in Euclidean 3-space can be thought of as a straight arrow (or more
formally a directed line segment) that reaches from one point, P, to another, Q (e.g.,
the arrow x in Fig. 1.1a). Equivalently, x can be thought of as a direction at P and
a number, the vector’s length. Sometimes we shall select one point O in 3-space as an
“origin” and identify all other points, say, Q and P, by their vectorial separations xQ
and xP from that origin.
The Euclidean distance σ between two points P and Q in 3-space can be mea-
distance and length
sured with a ruler and so, of course, requires no coordinate system for its deﬁnition.
(If one does have a Cartesian coordinate system, then σ can be computed by the Py-
thagorean formula, a precursor to the invariant interval of ﬂat spacetime; Sec. 2.2.3.)
This distance σ is also the length |x| of the vector x that reaches from P to Q,
and the square of that length is denoted
|x|2 ≡(x)2 ≡(σ)2.
(1.2)
Of particular importance is the case when P and Q are neighboring points and
x is a differential (inﬁnitesimal) quantity dx. This inﬁnitesimal displacement is a
more fundamental physical quantity than the ﬁnite x. To create a ﬁnite vector out
8
Chapter 1. Newtonian Physics: Geometric Viewpoint

O
C
Q
xQ
x
xP
P
(a)
(b)
FIGURE 1.1 (a) A Euclidean 3-space diagram depicting two points P and Q,
their respective vectorial separations xP and xQ from the (arbitrarily chosen)
origin O, and the vector x = xQ −xP connecting them. (b) A curve P(λ)
generated by laying out a sequence of inﬁnitesimal vectors, tail-to-tip.
of inﬁnitesimal vectors, one has to add several inﬁnitesimal vectors head to tail, head
to tail, and so on, and then take a limit. This involves translating a vector from one
point to the next. There is no ambiguity about doing this in ﬂat Euclidean space using
the geometric notion of parallelism.4 This simple property of Euclidean space enables
us to add (and subtract) vectors at a point. We attach the tail of a second vector to the
head of the ﬁrst vector and then construct the sum as the vector from the tail of the
ﬁrst to the head of the second, or vice versa, as should be quite familiar. The point is
that we do not need to add the Cartesian components to sum vectors.
We can also rotate vectors about their tails by pointing them along a different
direction in space. Such a rotation can be speciﬁed by two angles. The space that is
deﬁned by all possible changes of length and direction at a point is called that point’s
tangent space. Again, we generally view the rotation as being that of a physical vector
tangent space
in space, and not, as it is often useful to imagine, the rotation of some coordinate
system’s basis vectors, with the chosen vector itself kept ﬁxed.
We can also construct a path through space by laying down a sequence of inﬁnites-
curve
imal dxs, tail to head, one after another. The resulting path is a curve to which these
dxs are tangent (Fig. 1.1b). The curve can be denoted P(λ), with λ a parameter along
the curve and P(λ) the point on the curve whose parameter value is λ, or x(λ) where
x is the vector separation of P from the arbitrary origin O. The inﬁnitesimal vectors
that map the curve out are dx = (dP/dλ) dλ = (dx/dλ) dλ, and dP/dλ = dx/dλ
is the tangent vector to the curve.
tangent vector
If the curve followed is that of a particle, and the parameter λ is time t, then we
have deﬁned the velocity v ≡dx/dt. In effect we are multiplying the vector dx by the
scalar 1/dt and taking the limit. Performing this operation at every point P in the
space occupied by a ﬂuid deﬁnes the ﬂuid’s velocity ﬁeld v(x). Multiplying a particle’s
velocity v by its scalar mass gives its momentum p = mv. Similarly, the difference dv
4.
The statement that there is just one choice of line parallel to a given line, through a point not lying on
the line, is the famous ﬁfth axiom of Euclid.
1.2 Foundational Concepts
9

of two velocity measurements during a time interval dt, multiplied by 1/dt, generates
the particle’s acceleration a = dv/dt. Multiplying by the particle’s mass gives the force
F = ma that produced the acceleration; dividing an electrically produced force by the
particle’s charge q gives the electric ﬁeld E = F/q. And so on.
We can deﬁne inner products [see Eq. (1.4a) below] and cross products [Eq.
(1.22a)] of pairs of vectors at the same point geometrically; then using those vectors
we can deﬁne, for example, the rate that work is done by a force and a particle’s angular
momentum about a point.
These two products can be expressed geometrically as follows. If we allow the two
vectors to deﬁne a parallelogram, then their cross product is the vector orthogonal
to the parallelogram with length equal to the parallelogram’s area. If we ﬁrst rotate
one vector through a right angle in a plane containing the other, and then deﬁne the
parallelogram, its area is the vectors’ inner product.
derivatives of scalars and
vectors
We can also deﬁne spatial derivatives. We associate the difference of a scalar
between two points separated by dx at the same time with a gradient and, likewise,
go on to deﬁne the scalar divergence and the vector curl. The freedom to translate
vectors from one point to the next also underlies the association of a single vector
(e.g., momentum) with a group of particles or an extended body. One simply adds all
the individual momenta, taking a limit when necessary.
In this fashion (which should be familiar to the reader and will be elucidated,
formalized, and generalized below), we can construct all the standard scalars and
vectors of Newtonian physics. What is important is that these physical quantities
require no coordinate system for their deﬁnition. They are geometric (coordinate-
independent) objects residing in Euclidean 3-space at a particular time.
Geometric Principle
It is a fundamental (though often ignored) principle of physics that the Newtonian
physicallawsareallexpressibleasgeometricrelationshipsamongthesetypesofgeometric
objects, and these relationships do not depend on any coordinate system or orientation
of axes, nor on any reference frame (i.e., on any purported velocity of the Euclidean
space in which the measurements are made).5 We call this the Geometric Principle for
the laws of physics, and we use it throughout this book. It is the Newtonian analog of
Einstein’s Principle of Relativity (Sec. 2.2.2).
1.3
1.3 Tensor Algebra without a Coordinate System
In preparation for developing our geometric view of physical laws, we now intro-
duce, in a coordinate-free way, some fundamental concepts of differential geometry:
tensors, the inner product, the metric tensor, the tensor product, and contraction of
tensors.
WehavealreadydeﬁnedavectorA asastraightarrowfromonepoint, sayP, inour
space to another, say Q. Because our space is ﬂat, there is a unique and obvious way to
5.
By changing the velocity of Euclidean space, one adds a constant velocity to all particles, but this leaves
the laws (e.g., Newton’s F = ma) unchanged.
10
Chapter 1. Newtonian Physics: Geometric Viewpoint

T 
7.95 
FIGURE 1.2 A rank-3 tensor T.
transport such an arrow from one location to another, keeping its length and direction
unchanged.6 Accordingly, we shall regard vectors as unchanged by such transport.
This enables us to ignore the issue of where in space a vector actually resides; it is
completely determined by its direction and its length.
tensor
A rank-n tensor T is, by deﬁnition, a real-valued linear function of n vectors.7
Pictorially we regard T as a box (Fig. 1.2) with n slots in its top, into which are inserted
n vectors, and one slot in its end, which prints out a single real number: the value that
the tensor T has when evaluated as a function of the n inserted vectors. Notationally
we denote the tensor by a boldfaced sans-serif character T:
T(
,
,
,

	
)
↖n slots in which to put the vectors.
(1.3a)
This deﬁnition of a tensor is very different (and far simpler) than the one found in
most standard physics textbooks (e.g., Marion and Thornton, 1995; Jackson, 1999;
Grifﬁths, 1999). There, a tensor is an array of numbers that transform in a particular
way under rotations. We shall learn the connection between these deﬁnitions in
Sec. 1.6 below.
To illustrate this approach, if T is a rank-3 tensor (has 3 slots) as in Fig. 1.2, then
its value on the vectors A, B, C is denoted T(A, B, C). Linearity of this function can
be expressed as
T(eE + f F, B, C) = eT(E, B, C) + f T(F, B, C),
(1.3b)
where e and f are real numbers, and similarly for the second and third slots.
inner product
We have already deﬁned the squared length (A)2 ≡A2 of a vector A as the squared
distance between the points at its tail and its tip. The inner product (also called the
dot product) A . B of two vectors is deﬁned in terms of this squared length by
A . B ≡1
4

(A + B)2 −(A −B)2
.
(1.4a)
In Euclidean space, this is the standard inner product, familiar from elementary
geometry and discussed above in terms of the area of a parallelogram.
6.
This is not so in curved spaces, as we shall see in Sec. 24.3.4.
7.
Thisisadifferentuseofthewordrank thanforamatrix, whoserankisitsnumberoflinearlyindependent
rows or columns.
1.3 Tensor Algebra without a Coordinate System
11

One can show that the inner product (1.4a) is a real-valued linear function of each
of its vectors. Therefore, we can regard it as a tensor of rank 2. When so regarded, the
inner product is denoted g(
,
) and is called the metric tensor. In other words, the
metric tensor
metric tensor g is that linear function of two vectors whose value is given by
g(A, B) ≡A . B.
(1.4b)
Notice that, because A . B = B . A, the metric tensor is symmetric in its two slots—
one gets the same real number independently of the order in which one inserts the
two vectors into the slots:
g(A, B) = g(B, A).
(1.4c)
With the aid of the inner product, we can regard any vector A as a tensor of rank
one: the real number that is produced when an arbitrary vector C is inserted into A’s
single slot is
A(C) ≡A . C.
(1.4d)
In Newtonian physics, we rarely meet tensors of rank higher than two. However,
second-rank tensors appear frequently—often in roles where one sticks a single vector
into the second slot and leaves the ﬁrst slot empty, thereby producing a single-slotted
entity, a vector. An example that we met in Sec. 1.1.1 is a rigid body’s moment-of-
inertia tensor I(
,
), which gives us the body’s angular momentum J(
) = I(
, )
when its angular velocity  is inserted into its second slot.8 Another example is the
stress tensor of a solid, a ﬂuid, a plasma, or a ﬁeld (Sec. 1.9 below).
tensor product
From three vectors A, B, C, we can construct a tensor, their tensor product (also
called outer product in contradistinction to the inner product A . B), deﬁned as
follows:
A ⊗B ⊗C(E, F, G) ≡A(E)B(F)C(G) = (A . E)(B . F)(C . G).
(1.5a)
Here the ﬁrst expression is the notation for the value of the new tensor, A ⊗B ⊗C
evaluated on the three vectors E, F, G; the middle expression is the ordinary product
of three real numbers, the value of A on E, the value of B on F, and the value of C
on G; and the third expression is that same product with the three numbers rewritten
as scalar products. Similar deﬁnitions can be given (and should be obvious) for the
tensor product of any number of vectors, and of any two or more tensors of any rank;
for example, if T has rank 2 and S has rank 3, then
T ⊗S(E, F, G, H, J) ≡T(E, F)S(G, H, J).
(1.5b)
One last geometric (i.e., frame-independent) concept we shall need is contraction.
contraction
We illustrate this concept ﬁrst by a simple example, then give the general deﬁnition.
8.
Actually, it doesn’t matter which slot, since I is symmetric.
12
Chapter 1. Newtonian Physics: Geometric Viewpoint

From two vectors A and B we can construct the tensor product A ⊗B (a second-
rank tensor), and we can also construct the scalar product A . B (a real number, i.e., a
scalar, also known as a rank-0 tensor). The process of contraction is the construction
of A . B from A ⊗B:
contraction(A ⊗B) ≡A . B.
(1.6a)
One can show fairly easily using component techniques (Sec. 1.5 below) that any
second-rank tensor T can be expressed as a sum of tensor products of vectors, T =
A ⊗B + C ⊗D + . . . . Correspondingly, it is natural to deﬁne the contraction of T
to be contraction(T) = A . B + C . D + . . . . Note that this contraction process lowers
the rank of the tensor by two, from 2 to 0. Similarly, for a tensor of rank n one can
construct a tensor of rank n −2 by contraction, but in this case one must specify
which slots are to be contracted. For example, if T is a third-rank tensor, expressible
as T = A ⊗B ⊗C + E ⊗F ⊗G + . . ., then the contraction of T on its ﬁrst and third
slots is the rank-1 tensor (vector)
1&3contraction(A ⊗B ⊗C + E ⊗F ⊗G + . . .) ≡(A . C)B + (E . G)F + . . . .
(1.6b)
Unfortunately, there is no simple index-free notation for contraction in common use.
All the concepts developed in this section (vector, tensor, metric tensor, inner
product, tensor product, and contraction of a tensor) can be carried over, with no
change whatsoever, into any vector space9 that is endowed with a concept of squared
length—for example, to the 4-dimensional spacetime of special relativity (next
chapter).
1.4
1.4 Particle Kinetics and Lorentz Force in Geometric Language
In this section, we illustrate our geometric viewpoint by formulating Newton’s laws
of motion for particles.
In Newtonian physics, a classical particle moves through Euclidean 3-space as
universal time t passes. At time t it is located at some point x(t) (its position). The
trajectory, velocity,
momentum, acceleration,
and energy
function x(t) represents a curve in 3-space, the particle’s trajectory. The particle’s
velocity v(t) is the time derivative of its position, its momentum p(t) is the product of
its mass m and velocity, its acceleration a(t) is the time derivative of its velocity, and
its kinetic energy E(t) is half its mass times velocity squared:
v(t) = dx
dt ,
p(t) = mv(t),
a(t) = dv
dt = d2x
dt2 ,
E(t) = 1
2mv2.
(1.7a)
9.
Or, more precisely, any vector space over the real numbers. If the vector space’s scalars are complex
numbers, as in quantum mechanics, then slight changes are needed.
1.4 Particle Kinetics and Lorentz Force in Geometric Language
13

Since points in 3-space are geometric objects (deﬁned independently of any coordi-
nate system), so also are the trajectory x(t), the velocity, the momentum, the acceler-
ation, and the energy. (Physically, of course, the velocity has an ambiguity; it depends
on one’s standard of rest.)
Newton’s second law of motion states that the particle’s momentum can change
only if a force F acts on it, and that its change is given by
dp/dt = ma = F.
(1.7b)
If the force is produced by an electric ﬁeld E and magnetic ﬁeld B, then this law of
motion in SI units takes the familiar Lorentz-force form
dp/dt = q(E + v × B).
(1.7c)
(Here we have used the vector cross product, with which the reader should be familiar,
and which will be discussed formally in Sec. 1.7.)
laws of motion
The laws of motion (1.7) are geometric relationships among geometric objects.
Let us illustrate this using something very familiar, planetary motion. Consider a
light planet orbiting a heavy star. If there were no gravitational force, the planet
would continue in a straight line with constant velocity v and speed v = |v|, sweeping
out area A at a rate dA/dt = rvt/2, where r is the radius, and vt is the tangential
speed. Elementary geometry equates this to the constant vb/2, where b is the impact
parameter—the smallest separation from the star. Now add a gravitational force F and
let it cause a small radial impulse. A second application of geometry showed Newton
that the product rvt/2 is unchanged to ﬁrst order in the impulse, and he recovered
Kepler’s second law (dA/dt = const) without introducing coordinates.10
Contrast this approach with one relying on coordinates. For example, one in-
troduces an (r, φ) coordinate system, constructs a lagrangian and observes that the
coordinate φ is ignorable; then the Euler-Lagrange equations immediately imply the
conservation of angular momentum, which is equivalent to Kepler’s second law. So,
which of these two approaches is preferable? The answer is surely “both!” Newton
wrote the Principia in the language of geometry at least partly for a reason that remains
valid today: it brought him a quick understanding of fundamental laws of physics.
Lagrange followed his coordinate-based path to the function that bears his name,
because he wanted to solve problems in celestial mechanics that would not yield to
10. Continuing in this vein, when the force is inverse square, as it is for gravity and electrostatics, we can
use Kepler’s second law to argue that when the orbit turns through a succession of equal angles dθ,
its successive changes in velocity dv = adt (with a the gravitational acceleration) all have the same
magnitude |dv| and have the same angles dθ from one to another. So, if we trace the head of the velocity
vector in velocity space, it follows a circle. The circle is not centered on zero velocity when the eccentricity
is nonzero but there exists a reference frame in which the speed of the planet is constant. This graphical
representation is known as a hodograph,and similar geometrical approaches are used in ﬂuid mechanics.
For Richard Feynman’s masterful presentation of these ideas to ﬁrst-year undergraduates, see Goodstein
and Goodstein (1996).
14
Chapter 1. Newtonian Physics: Geometric Viewpoint

Newton’s approach. So it is today. Geometry and analysis are both indispensible. In the
domain of classical physics, the geometry is of greater importance in deriving and un-
derstanding fundamental laws and has arguably been underappreciated; coordinates
hold sway when we apply these laws to solve real problems. Today, both old and new
laws of physics are commonly expressed geometrically, using lagrangians, hamiltoni-
ans, and actions, for example Hamilton’s action principle δ

Ldt = 0 where L is the
coordinate-independentlagrangian.Indeed, beingabletodothiswithoutintroducing
coordinates is a powerful guide to deriving these laws and a tool for comprehending
their implications.
symmetry and
conservation laws
A comment is needed on the famous connection between symmetry and conserva-
tion laws.In our example above, angular momentum conservation followed from axial
symmetry which was embodied in the lagrangian’s independence of the angle φ; but
we also deduced it geometrically. This is usually the case in classical physics; typically,
we do not need to introduce a speciﬁc coordinate system to understand symmetry
and to express the associated conservation laws. However, symmetries are sometimes
well hidden, for example with a nutating top, and coordinate transformations are then
usually the best approach to uncover them.
Often in classical physics, real-world factors invalidate or complicate Lagrange’s
and Hamilton’s coordinate-based analytical dynamics, and so one is driven to geo-
metric considerations. As an example, consider a spherical marble rolling on a ﬂat
horizontal table. The analytical dynamics approach is to express the height of the
marble’s center of mass and the angle of its rotation as constraints and align the basis
vectors so there is a single horizontal coordinate deﬁned by the initial condition. It is
then deduced that linear and angular momenta are conserved. Of course that result
is trivial and just as easily gotten without this formalism. However, this model is also
used for many idealized problems where the outcome is far from obvious and the ap-
proach is brilliantly effective. But consider the real world in which tables are warped
and bumpy, marbles are ellipsoidal and scratched, air imposes a resistance, and wood
and glass comprise polymers that attract one another. And so on. When one includes
these factors, it is to geometry that one quickly turns to understand the real marble’s
actual dynamics. Even ignoring these effects and just asking what happens when the
marble rolls off the edge of a table introduces a nonholonomic constraint, and ﬁguring
out where it lands and how fast it is spinning are best addressed not by the methods of
Lagrange and Hamilton, but instead by considering the geometry of the gravitational
and reaction forces. In the following chapters, we shall encounter many examples
where we have to deal with messy complications like these.
EXERCISES
Exercise 1.1 Practice: Energy Change for Charged Particle
Without introducing any coordinates or basis vectors, show that when a particle with
charge q interacts with electric and magnetic ﬁelds, its kinetic energy changes at a rate
dE/dt = q v . E.
(1.8)
1.4 Particle Kinetics and Lorentz Force in Geometric Language
15

Exercise 1.2 Practice: Particle Moving in a Circular Orbit
Consider a particle moving in a circle with uniform speed v = |v| and uniform
magnitude a = |a| of acceleration. Without introducing any coordinates or basis
vectors, do the following.
(a) At any moment of time, let n = v/v be the unit vector pointing along the velocity,
and let s denote distance that the particle travels in its orbit. By drawing a picture,
show that dn/ds is a unit vector that points to the center of the particle’s circular
orbit, divided by the radius of the orbit.
(b) Show that the vector (not unit vector) pointing from the particle’s location to the
center of its orbit is (v/a)2a.
1.5
1.5 Component Representation of Tensor Algebra
Cartesian coordinates and
orthonormal basis vectors
In the Euclidean 3-space of Newtonian physics, there is a unique set of orthonormal
basis vectors {ex, ey, ez} ≡{e1, e2, e3} associated with any Cartesian coordinate system
{x, y, z} ≡{x1, x2, x3} ≡{x1, x2, x3}. (In Cartesian coordinates in Euclidean space,
we usually place indices down, but occasionally we place them up. It doesn’t matter.
By deﬁnition, in Cartesian coordinates a quantity is the same whether its index is
down or up.) The basis vector ej points along the xj coordinate direction, which is
orthogonal to all the other coordinate directions, and it has unit length (Fig. 1.3), so
ej . ek = δjk,
(1.9a)
where δjk is the Kronecker delta.
Any vector A in 3-space can be expanded in terms of this basis:
A = Ajej.
(1.9b)
Hereandthroughoutthisbook, weadopttheEinsteinsummationconvention:repeated
Einstein summation
convention
indices (in this case j) are to be summed (in this 3-space case over j = 1, 2, 3), unless
Cartesian components of a
vector
otherwise instructed. By virtue of the orthonormality of the basis, the components
Aj of A can be computed as the scalar product
Aj = A . ej.
(1.9c)
[The proof of this is straightforward: A . ej = (Akek) . ej = Ak(ek . ej) = Akδkj =
Aj.]
Any tensor, say, the third-rank tensor T(
,
,
), can be expanded in terms of
tensor products of the basis vectors:
T = Tijkei ⊗ej ⊗ek.
(1.9d)
16
Chapter 1. Newtonian Physics: Geometric Viewpoint

x
y
z
e3
e2
e1
FIGURE 1.3 The orthonormal basis vectors
ej associated with a Euclidean coordi-
nate system in Euclidean 3-space.
The components Tijk of T can be computed from T and the basis vectors by the
Cartesian components of a
tensor
generalization of Eq. (1.9c):
Tijk = T(ei, ej, ek).
(1.9e)
[This equation can be derived using the orthonormality of the basis in the same way
as Eq. (1.9c) was derived.] As an important example, the components of the metric
tensor are gjk = g(ej, ek) = ej . ek = δjk [where the ﬁrst equality is the method (1.9e)
of computing tensor components, the second is the deﬁnition (1.4b) of the metric, and
the third is the orthonormality relation (1.9a)]:
gjk = δjk.
(1.9f)
The components of a tensor product [e.g., T(
,
,
) ⊗S(
,
)] are easily de-
duced by inserting the basis vectors into the slots [Eq. (1.9e)]; they are T(ei, ej, ek) ⊗
S(el, em) = TijkSlm [cf. Eq. (1.5a)]. In words, the components of a tensor product are
equal to the ordinary arithmetic product of the components of the individual tensors.
In component notation, the inner product of two vectors and the value of a tensor
when vectors are inserted into its slots are given by
A . B = AjBj,
T(A, B, C) = TijkAiBjCk,
(1.9g)
as one can easily show using previous equations. Finally, the contraction of a tensor
[say, the fourth-rank tensor R(
,
,
,
)] on two of its slots (say, the ﬁrst and
third) has components that are easily computed from the tensor’s own components:
components of [1&3contraction of R] = Rijik.
(1.9h)
Note that Rijik is summed on the i index, so it has only two free indices, j and k, and
thus is the component of a second-rank tensor, as it must be if it is to represent the
contraction of a fourth-rank tensor.
1.5.1
1.5.1 Slot-Naming Index Notation
We now pause in our development of the component version of tensor algebra to
introduce a very important new viewpoint.
1.5 Component Representation of Tensor Algebra
17

BOX 1.2.
VECTORS AND TENSORS IN QUANTUM THEORY
The laws of quantum theory, like all other laws of Nature, can be expressed as
geometric relationships among geometric objects. Most of quantum theory’s
geometric objects, like those of classical theory, are vectors and tensors: the
quantum state |ψ⟩of a physical system (e.g., a particle in a harmonic-oscillator
potential) is a Hilbert-space vector—a generalization of a Euclidean-space
vector A. There is an inner product, denoted ⟨φ|ψ⟩, between any two states
|φ⟩and |ψ⟩, analogous to B . A; but B . A is a real number, whereas ⟨φ|ψ⟩is
a complex number (and we add and subtract quantum states with complex-
number coefﬁcients). The Hermitian operators that represent observables
(e.g., the hamiltonian ˆH for the particle in the potential) are two-slotted
(second-rank), complex-valued functions of vectors; ⟨φ| ˆH|ψ⟩is the complex
number that one gets when one inserts φ and ψ into the ﬁrst and second
slots of ˆH. Just as, in Euclidean space, we get a new vector (ﬁrst-rank tensor)
T(
, A) when we insert the vector A into the second slot of T, so in quantum
theory we get a new vector (physical state) ˆH|ψ⟩(the result of letting ˆH “act
on” |ψ⟩) when we insert |ψ⟩into the second slot of ˆH. In these senses, we can
regard T as a linear map of Euclidean vectors into Euclidean vectors and ˆH as
a linear map of states (Hilbert-space vectors) into states.
For the electron in the hydrogen atom, we can introduce a set of
orthonormal basis vectors {|1⟩, |2⟩, |3⟩, . . .}, that is, the atom’s energy
eigenstates, with ⟨m|n⟩= δmn. But by contrast with Newtonian physics,
where we only need three basis vectors (because our Euclidean space is 3-
dimensional), for the particle in a harmonic-oscillator potential, we need an
inﬁnite number of basis vectors (since the Hilbert space of all states is inﬁnite-
dimensional). In the particle’s quantum-state basis, any observable (e.g., the
particle’s position ˆx or momentum ˆp) has components computed by inserting
the basis vectors into its two slots: xmn = ⟨m|ˆx|n⟩, and pmn = ⟨m| ˆp|n⟩. In this
basis, the operator ˆx ˆp (which maps states into states) has components xjkpkm
(a matrix product), and the noncommutation of position and momentum
[ˆx, ˆp]= iℏ(an important physical law) is expressible in terms of components
as xjkpkm −pjkxkm = iℏδjm.
Consider the rank-2 tensor F(
,
). We can deﬁne a new tensor G(
,
) to be
the same as F, but with the slots interchanged: i.e., for any two vectors A and B, it is
true that G(A, B) = F(B, A). We need a simple, compact way to indicate that F and
G are equal except for an interchange of slots. The best way is to give the slots names,
say a and b—i.e., to rewrite F(
,
) as F(
a,
b) or more conveniently as Fab, and
then to write the relationship between G and F as Gab = Fba. “NO!” some readers
18
Chapter 1. Newtonian Physics: Geometric Viewpoint

might object. This notation is indistinguishable from our notation for components on
a particular basis. “GOOD!” a more astute reader will exclaim. The relation Gab = Fba
in a particular basis is a true statement if and only if “G = F with slots interchanged”
is true, so why not use the same notation to symbolize both? In fact, we shall do
this. We ask our readers to look at any “index equation,” such as Gab = Fba, like they
would look at an Escher drawing: momentarily think of it as a relationship between
components of tensors in a speciﬁc basis; then do a quick mind-ﬂip and regard it quite
differently, as a relationship between geometric, basis-independent tensors with the
indices playing the roles of slot names. This mind-ﬂip approach to tensor algebra will
pay substantial dividends.
slot-naming index notation
As an example of the power of this slot-naming index notation, consider the con-
tractionoftheﬁrstandthirdslotsofathird-ranktensor T.Inanybasisthecomponents
of 1&3contraction(T) are Taba; cf. Eq. (1.9h). Correspondingly, in slot-naming index
notation we denote 1&3contraction(T) by the simple expression Taba. We can think
of the ﬁrst and third slots as annihilating each other by the contraction, leaving free
only the second slot (named b) and therefore producing a rank-1 tensor (a vector).
Weshouldcautionthatthephrase“slot-namingindexnotation”isunconventional.
You are unlikely to ﬁnd it in any other textbooks. However, we like it. It says precisely
what we want it to say.
1.5.2
1.5.2 Particle Kinetics in Index Notation
As an example of slot-naming index notation, we can rewrite the equations of particle
kinetics (1.7) as follows:
vi = dxi
dt ,
pi = mvi,
ai = dvi
dt = d2xi
dt2 ,
E = 1
2mvjvj,
dpi
dt = q(Ei + ϵijkvjBk).
(1.10)
(In the last equation ϵijk is the so-called Levi-Civita tensor, which is used to produce
the cross product; we shall learn about it in Sec. 1.7. And note that the scalar energy
E must not be confused with the electric ﬁeld vector Ei.)
Equations (1.10) can be viewed in either of two ways: (i) as the basis-independent
geometric laws v = dx/dt, p = mv, a = dv/dt = d2x/dt2, E = 1
2mv2, and dp/dt =
q(E + v × B) written in slot-naming index notation; or (ii) as equations for the
components of v, p, a, E, and B in some particular Cartesian coordinate system.
EXERCISES
Exercise 1.3 Derivation: Component Manipulation Rules
Derive the component manipulation rules (1.9g) and (1.9h).
Exercise 1.4 Example and Practice: Numerics of Component Manipulations
The third-rank tensor S(
,
,
) and vectors A and B have as their only nonzero
components S123 = S231 = S312 = +1, A1 = 3, B1 = 4, B2 = 5. What are the
1.5 Component Representation of Tensor Algebra
19

components of the vector C = S(A, B,
), the vector D = S(A,
, B), and the tensor
W = A ⊗B?
[Partial solution: In component notation, Ck = SijkAiBj, where (of course) we
sum over the repeated indices i and j. This tells us that C1 = S231A2B3, because
S231 is the only component of S whose last index is a 1; this in turn implies that
C1 = 0, since A2 = 0. Similarly, C2 = S312A3B1 = 0 (because A3 = 0). Finally, C3 =
S123A1B2 = +1 × 3 × 5 = 15. Also, in component notation Wij = AiBj, so W11 =
A1 × B1 = 3 × 4 = 12, and W12 = A1 × B2 = 3 × 5 = 15. Here the × stands for
numerical multiplication, not the vector cross product.]
Exercise 1.5 Practice: Meaning of Slot-Naming Index Notation
(a) The following expressions and equations are written in slot-naming index nota-
tion. Convert them to geometric, index-free notation: AiBjk, AiBji, Sijk = Skji,
AiBi = AiBjgij.
(b) The following expressions are written in geometric, index-free notation. Convert
them to slot-naming index notation: T(
,
, A), T(
, S(B,
),
).
1.6
1.6 Orthogonal Transformations of Bases
Consider two different Cartesian coordinate systems {x, y, z} ≡{x1, x2, x3}, and
{¯x, ¯y, ¯z} ≡{x¯1, x¯2, x¯3}. Denote by {ei} and {e ¯p} the corresponding bases. It is possible
to expand the basis vectors of one basis in terms of those of the other. We denote the
expansion coefﬁcients by the letter R and write
ei = e ¯pR ¯pi,
e ¯p = eiRi¯p.
(1.11)
The quantities R ¯pi and Ri¯p are not the components of a tensor; rather, they are the
elements of transformation matrices
[R ¯pi]=
⎡
⎢⎣
R¯11
R¯12
R¯13
R¯21
R¯22
R¯23
R¯31
R¯32
R¯33
⎤
⎥⎦,
[Ri¯p]=
⎡
⎢⎣
R1¯1
R1¯2
R1¯3
R2¯1
R2¯2
R2¯3
R3¯1
R3¯2
R3¯3
⎤
⎥⎦.
(1.12a)
(Here and throughout this book we use square brackets to denote matrices.) These
twomatricesmustbetheinverseofeachother, sinceonetakesusfromthebarredbasis
to the unbarred, and the other in the reverse direction, from unbarred to barred:
R ¯piRi¯q = δ ¯p ¯q,
Ri¯pR¯pj = δij.
(1.12b)
The orthonormality requirement for the two bases implies that δij = ei . ej =
(e ¯pR ¯pi) . (e¯qR¯qj) = R ¯piR¯qj(e ¯p . e¯q) = R ¯piR¯qjδ ¯p ¯q = R ¯piR¯pj. This says that the
transpose of [R ¯pi]is its inverse—which we have already denoted by [Ri¯p]:
[Ri¯p]≡inverse

[R ¯pi]

= transpose

[R ¯pi]

.
(1.12c)
20
Chapter 1. Newtonian Physics: Geometric Viewpoint

This property implies that the transformation matrix is orthogonal, so the transfor-
orthogonal transformation
and rotation
mation is a reﬂection or a rotation (see, e.g., Goldstein, Poole, and Safko, 2002). Thus
(as should be obvious and familiar), the bases associated with any two Euclidean co-
ordinate systems are related by a reﬂection or rotation, and the matrices (1.12a) are
called rotation matrices. Note that Eq. (1.12c) does not say that [Ri¯p] is a symmetric
matrix. In fact, most rotation matrices are not symmetric [see, e.g., Eq. (1.14)].
The fact that a vector A is a geometric, basis-independent object implies that
A = Aiei = Ai(e ¯pR ¯pi) = (R ¯piAi)e ¯p = A ¯pe ¯p:
A ¯p = R ¯piAi,
and similarly,
Ai = Ri¯pA ¯p;
(1.13a)
and correspondingly for the components of a tensor:
T ¯p ¯q ¯r = R ¯piR¯qjR¯rkTijk,
Tijk = Ri¯pRj ¯qRk¯rT ¯p ¯q ¯r.
(1.13b)
It is instructive to compare the transformation law (1.13a) for the components of
a vector with Eqs. (1.11) for the bases. To make these laws look natural, we have
placed the transformation matrix on the left in the former and on the right in the
latter. In Minkowski spacetime (Chap. 2), the placement of indices, up or down, will
automatically tell us the order.
If we choose the origins of our two coordinate systems to coincide, then the vector
x reachingfromthecommonorigintosomepointP, whosecoordinatesarexj andx ¯p,
hascomponentsequaltothosecoordinates; andasaresult, thecoordinatesthemselves
obey the same transformation law as any other vector:
x ¯p = R ¯pixi,
xi = Ri¯px ¯p.
(1.13c)
The product of two rotation matrices [Ri¯pR ¯p¯¯s] is another rotation matrix [Ri¯¯s],
which transforms the Cartesian bases e¯¯s to ei. Under this product rule, the rotation
rotation group
matrices form a mathematical group: the rotation group, whose group representations
play an important role in quantum theory.
EXERCISES
Exercise 1.6 **Example and Practice: Rotation in x-y Plane
Consider two Cartesian coordinate systems rotated with respect to each other in the
x-y plane as shown in Fig. 1.4.
(a) Show that the rotation matrix that takes the barred basis vectors to the unbarred
basis vectors is
[R ¯pi]=
⎡
⎢⎣
cos φ
sin φ
0
−sin φ
cos φ
0
0
0
1
⎤
⎥⎦,
(1.14)
and show that the inverse of this rotation matrix is, indeed, its transpose, as it
must be if this is to represent a rotation.
(b) Verify that the two coordinate systems are related by Eq. (1.13c).
1.6 Orthogonal Transformations of Bases
21

x
y
yˉ
xˉ
eyˉ
exˉ
φ
ex
ey
FIGURE 1.4 Two Cartesian coordinate systems {x, y, z} and
{¯x, ¯y, ¯z} and their basis vectors in Euclidean space, rotated
by an angle φ relative to each other in the x-y plane. The z- and
¯z-axes point out of the paper or screen and are not shown.
(c) Let Aj be the components of the electromagnetic vector potential that lies in
the x-y plane, so that Az = 0. The two nonzero components Ax and Ay can be
regarded as describing the two polarizations of an electromagnetic wave propa-
gating in the z direction. Show that A¯x + iA ¯y = (Ax + iAy)e−iφ. One can show
(cf. Sec. 27.3.3) that the factor e−iφ implies that the quantum particle associ-
ated with the wave—the photon—has spin one [i.e., spin angular momentum
ℏ= (Planck’s constant)/2π].
(d) Let hjk be the components of a symmetric tensor that is trace-free (its contraction
hjj vanishes) and is conﬁned to the x-y plane (so hzk = hkz = 0 for all k). Then
the only nonzero components of this tensor are hxx = −hyy and hxy = hyx.
As we shall see in Sec. 27.3.1, this tensor can be regarded as describing the
two polarizations of a gravitational wave propagating in the z direction. Show
that h¯x ¯x + ih¯x ¯y = (hxx + ihxy)e−2iφ. The factor e−2iφ implies that the quantum
particle associated with the gravitational wave (the graviton) has spin two (spin
angular momentum 2ℏ); cf. Eq. (27.31) and Sec. 27.3.3.
1.7
1.7 Differentiation of Scalars, Vectors, and Tensors; Cross Product and Curl
Consider a tensor ﬁeld T(P) in Euclidean 3-space and a vector A. We deﬁne the
directional derivative
directional derivative of T along A by the obvious limiting procedure
∇AT ≡lim
ϵ→0
1
ϵ [T(xP + ϵA) −T(xP)]
(1.15a)
and similarly for the directional derivative of a vector ﬁeld B(P) and a scalar ﬁeld
ψ(P). [Here we have denoted points, e.g., P, by the vector xP that reaches from some
22
Chapter 1. Newtonian Physics: Geometric Viewpoint

arbitrary origin to the point, and T(xP) denotes the ﬁeld’s dependence on location in
space; T’s slots and dependence on what goes into the slots are suppressed; and the
units of ϵ are chosen to ensure that ϵA has the same units as xP. There is no other
appearance of vectors in this chapter.] In deﬁnition (1.15a), the quantity in square
brackets is simply the difference between two linear functions of vectors (two tensors),
so the quantity on the left-hand side is also a tensor with the same rank as T.
It should not be hard to convince oneself that this directional derivative ∇AT of any
tensor ﬁeld T is linear in the vector A along which one differentiates. Correspondingly,
if T hasrankn(nslots), thenthereisanothertensorﬁeld, denoted∇T, withrankn + 1,
such that
∇AT = ∇T(
,
,
, A).
(1.15b)
Here on the right-hand side the ﬁrst n slots (3 in the case shown) are left empty, and
gradient
A is put into the last slot (the “differentiation slot”). The quantity ∇T is called the
gradient of T. In slot-naming index notation, it is conventional to denote this gradient
by Tabc;d, where in general the number of indices preceding the semicolon is the rank
of T. Using this notation, the directional derivative of T along A reads [cf. Eq. (1.15b)]
Tabc;jAj.
It is not hard to show that in any Cartesian coordinate system, the components of
the gradient are nothing but the partial derivatives of the components of the original
tensor, which we denote by a comma:
Tabc;j = ∂Tabc
∂xj
≡Tabc,j.
(1.15c)
In a non-Cartesian basis (e.g., the spherical and cylindrical bases often used in electro-
magnetic theory), the components of the gradient typically are not obtained by simple
partial differentiation [Eq. (1.15c) fails] because of turning and/or length changes of
the basis vectors as we go from one location to another. In Sec. 11.8, we shall learn
how to deal with this by using objects called connection coefﬁcients. Until then, we
conﬁne ourselves to Cartesian bases, so subscript semicolons and subscript commas
(partial derivatives) can be used interchangeably.
Because the gradient and the directional derivative are deﬁned by the same stan-
dard limiting process as one uses when deﬁning elementary derivatives, they obey the
standard (Leibniz) rule for differentiating products:
∇A(S ⊗T = (∇AS) ⊗T + S ⊗∇AT,
or
(SabTcde);jAj = (Sab;jAj)Tcde + Sab(Tcde;jAj);
(1.16a)
and
∇A(f T) = (∇Af )T + f ∇AT,
or
(f Tabc);jAj = (f;jAj)Tabc + f Tabc;jAj.
(1.16b)
1.7 Differentiation of Scalars, Vectors, and Tensors; Cross Product and Curl
23

In an orthonormal basis these relations should be obvious: they follow from the
Leibniz rule for partial derivatives.
Because the components gab of the metric tensor are constant in any Cartesian
coordinate system, Eq. (1.15c) (which is valid in such coordinates) guarantees that
gab;j = 0; i.e., the metric has vanishing gradient:
∇g = 0,
or
gab;j = 0.
(1.17)
From the gradient of any vector or tensor we can construct several other important
derivatives by contracting on slots:
1. Since the gradient ∇A of a vector ﬁeld A has two slots, ∇A(
,
), we can
contract its slots on each other to obtain a scalar ﬁeld. That scalar ﬁeld is the
divergence
divergence of A and is denoted
∇. A ≡(contraction of ∇A) = Aa;a.
(1.18)
2. Similarly, if T is a tensor ﬁeld of rank 3, then Tabc;c is its divergence on its
third slot, and Tabc;b is its divergence on its second slot.
3. By taking the double gradient and then contracting on the two gradient slots
we obtain, from any tensor ﬁeld T, a new tensor ﬁeld with the same rank,
laplacian
∇2T ≡(∇. ∇)T ,
or Tabc;jj.
(1.19)
Hereandhenceforth, allindicesfollowingasemicolon(orcomma)represent
gradients(orpartialderivatives):Tabc;jj ≡Tabc;j;j, Tabc,jk ≡∂2Tabc/∂xj∂xk.
The operator ∇2 is called the laplacian.
The metric tensor is a fundamental property of the space in which it lives; it
embodies the inner product and hence the space’s notion of distance. In addition to
the metric, there is one (and only one) other fundamental tensor that describes a piece
of Euclidean space’s geometry: the Levi-Civita tensor ϵ, which embodies the space’s
Levi-Civita tensor
notion of volume.
In a Euclidean space with dimension n, the Levi-Civita tensor ϵ is a completely
antisymmetric tensor with rank n (with n slots). A parallelepiped whose edges are the
n vectors A, B, . . . , F is said to have the volume
volume
volume = ϵ(A, B, . . . , F).
(1.20)
(We justify this deﬁnition in Sec. 1.8.) Notice that this volume can be positive or
negative, and if we exchange the order of the parallelepiped’s legs, the volume’s sign
changes: ϵ(B, A, . . . , F) = −ϵ(A, B, . . . , F) by antisymmetry of ϵ.
It is easy to see (Ex. 1.7) that (i) the volume vanishes unless the legs are all linearly
independent, (ii) once the volume has been speciﬁed for one parallelepiped (one
set of linearly independent legs), it is thereby determined for all parallelepipeds,
and therefore, (iii) we require only one number plus antisymmetry to determine ϵ
24
Chapter 1. Newtonian Physics: Geometric Viewpoint

fully. If the chosen parallelepiped has legs that are orthonormal (all are orthogonal
to one another and all have unit length—properties determined by the metric g),
then it must have unit volume, or more precisely volume ±1. This is a compatibility
relation between g and ϵ. It is easy to see (Ex. 1.7) that (iv) ϵ is fully determined by its
antisymmetry, compatibility with the metric, and a single sign: the choice of which
parallelepipeds have positive volume and which have negative. It is conventional
in Euclidean 3-space to give right-handed parallelepipeds positive volume and left-
handed ones negative volume:ϵ(A, B, C) is positive if, when we place our right thumb
along C and the ﬁngers of our right hand along A, then bend our ﬁngers, they sweep
toward B and not −B.
These considerations dictate that in a right-handed orthonormal basis of Eu-
clidean 3-space, the only nonzero components of ϵ are
ϵ123 = +1,
ϵabc =
⎧
⎪⎨
⎪⎩
+1
if a, b, c is an even permutation of 1, 2, 3
−1
if a, b, c is an odd permutation of 1, 2, 3
0
if a, b, c are not all different;
(1.21)
and in a left-handed orthonormal basis, the signs of these components are reversed.
cross product and curl
The Levi-Civita tensor is used to deﬁne the cross product and the curl:
A × B ≡ϵ(
, A, B);
in slot-naming index notation, ϵijkAjBk;
(1.22a)
∇× A ≡(the vector ﬁeld whose slot-naming index form is ϵijkAk;j).
(1.22b)
[Equation (1.22b) is an example of an expression that is complicated if stated in index-
free notation; it says that ∇× A is the double contraction of the rank-5 tensor ϵ ⊗∇A
on its second and ﬁfth slots, and on its third and fourth slots.]
AlthoughEqs.(1.22a)and(1.22b)looklikecomplicatedwaystodealwithconcepts
that most readers regard as familiar and elementary, they have great power. The power
comes from the following property of the Levi-Civita tensor in Euclidean 3-space
[readily derivable from its components (1.21)]:
ϵijmϵklm = δij
kl ≡δi
kδj
l −δi
lδj
k.
(1.23)
Here δi
k is the Kronecker delta. Examine the 4-index delta function δij
kl carefully; it says
that either the indices above and below each other must be the same (i = k and j = l)
with a + sign, or the diagonally related indices must be the same (i = l and j = k) with
a −sign. [We have put the indices ij of δij
kl up solely to facilitate remembering this rule.
Recall (ﬁrst paragraph of Sec. 1.5) that in Euclidean space and Cartesian coordinates,
it does not matter whether indices are up or down.] With the aid of Eq. (1.23) and the
index-notation expressions for the cross product and curl, one can quickly and easily
derive a wide variety of useful vector identities; see the very important Ex. 1.8.
1.7 Differentiation of Scalars, Vectors, and Tensors; Cross Product and Curl
25

EXERCISES
Exercise 1.7 Derivation: Properties of the Levi-Civita Tensor
From its complete antisymmetry, derive the four properties of the Levi-Civita tensor,
in n-dimensional Euclidean space, that are claimed in the text following Eq. (1.20).
Exercise 1.8 **Example and Practice: Vectorial Identities for the Cross Product
and Curl
Here is an example of how to use index notation to derive a vector identity for the dou-
ble cross product A × (B × C): in index notation this quantity is ϵijkAj(ϵklmBlCm).
By permuting the indices on the second ϵ and then invoking Eq. (1.23), we can write
this as ϵijkϵlmkAjBlCm = δlm
ij AjBlCm. By then invoking the meaning of the 4-index
delta function [Eq. (1.23)], we bring this into the form AjBiCj −AjBjCi, which
is the slot-naming index-notation form of (A . C)B −(A . B)C. Thus, it must be that
A × (B × C) = (A . C)B −(A . B)C. Use similar techniques to evaluate the following
quantities.
(a) ∇× (∇× A).
(b) (A × B) . (C × D).
(c) (A × B) × (C × D).
Exercise 1.9 **Example and Practice: Levi-Civita Tensor in 2-Dimensional
Euclidean Space
In Euclidean 2-space, let {e1, e2} be an orthonormal basis with positive volume.
(a) Show that the components of ϵ in this basis are
ϵ12 = +1,
ϵ21 = −1,
ϵ11 = ϵ22 = 0.
(1.24a)
(b) Show that
ϵikϵjk = δij.
(1.24b)
1.8
1.8 Volumes, Integration, and Integral Conservation Laws
In Cartesian coordinates of 2-dimensional Euclidean space, the basis vectors are
orthonormal, so (with a conventional choice of sign) the components of the Levi-
Civita tensor are given by Eqs. (1.24a). Correspondingly, the area (i.e., 2-dimensional
volume) of a parallelogram whose sides are A and B is
2-volume = ϵ(A, B) = ϵabAaBb = A1B2 −A2B1 = det
 A1
B1
A2
B2

,
(1.25)
a relation that should be familiar from elementary geometry. Equally familiar should
be the following expression for the 3-dimensional volume of a parallelepiped with legs
26
Chapter 1. Newtonian Physics: Geometric Viewpoint

A, B, and C [which follows from the components (1.21) of the Levi-Civita tensor]:
3-volume
3-volume = ϵ(A, B, C) = ϵijkAiBjCk = A . (B × C) = det
⎡
⎢⎣
A1
B1
C1
A2
B2
C2
A3
B3
C3
⎤
⎥⎦.
(1.26)
Our formal deﬁnition (1.20) of volume is justiﬁed because it gives rise to these familiar
equations.
Equations (1.25) and (1.26) are foundations from which one can derive the usual
formulas dA = dx dy and dV = dx dy dz for the area and volume of elementary
surface and volume elements with Cartesian side lengths dx, dy, and dz (Ex. 1.10).
In Euclidean 3-space, we deﬁne the vectorial surface area of a 2-dimensional
parallelogram with legs A and B to be
 = A × B = ϵ(
, A, B).
(1.27)
This vectorial surface area has a magnitude equal to the area of the parallelogram
vectorial surface area
and a direction perpendicular to it. Notice that this surface area ϵ(
, A, B) can be
thought of as an object that is waiting for us to insert a third leg, C, so as to compute
a 3-volume ϵ(C, A, B)—the volume of the parallelepiped with legs C, A, and B.
A parallelogram’s surface has two faces (two sides), called the positive face and the
negative face.If the vector C sticks out of the positive face, then (C) = ϵ(C, A, B) is
positive; if C sticks out of the negative face, then (C) is negative.
1.8.1
1.8.1 Gauss’s and Stokes’ Theorems
Such vectorial surface areas are the foundation for surface integrals in 3-dimensional
Gauss’s and Stokes’
theorems
space and for the familiar Gauss’s theorem,

V3
(∇. A)dV =

∂V3
A . d
(1.28a)
(where V3 is a compact 3-dimensional region, and ∂V3 is its closed 2-dimensional
boundary) and Stokes’ theorem,

V2
∇× A . d =

∂V2
A . dl
(1.28b)
(where V2 is a compact 2-dimensional region, ∂V2 is the 1-dimensional closed curve
that bounds it, and the last integral is a line integral around that curve); see, e.g.,
Arfken, Weber, and Harris (2013).
This mathematics is illustrated by the integral and differential conservation laws
for electric charge and for particles: The total charge and the total number of particles
inside a 3-dimensional region of space V3 are

V3 ρe dV and

V3 ndV , where ρe is
the charge density and n the number density of particles. The rates that charge and
particles ﬂow out of V3 are the integrals of the current density j and the particle ﬂux
1.8 Volumes, Integration, and Integral Conservation Laws
27

vector S over its boundary ∂V3. Therefore, the integral laws of charge conservation and
integral conservation laws
particle conservation are
d
dt

V3
ρe dV +

∂V3
j . d = 0,
d
dt

V3
ndV +

∂V3
S . d = 0.
(1.29)
Pull the time derivative inside each volume integral (where it becomes a partial
derivative), and apply Gauss’s law to each surface integral; the results are

V3(∂ρe/∂t +
∇. j)dV = 0 and similarly for particles. The only way these equations can be true for
all choices of V3 is for the integrands to vanish:
∂ρe/∂t + ∇. j = 0,
∂n/∂t + ∇. S = 0.
(1.30)
These are the differential conservation laws for charge and for particles. They have a
differential conservation
laws
standard, universal form: the time derivative of the density of a quantity plus the
divergence of its ﬂux vanishes.
Note that the integral conservation laws (1.29) and the differential conservation
laws (1.30) require no coordinate system or basis for their description, and no coordi-
nate system or basis was used in deriving the differential laws from the integral laws.
This is an example of the fundamental principle that the Newtonian physical laws are
all expressible as geometric relationships among geometric objects.
EXERCISES
Exercise 1.10 Derivation and Practice: Volume Elements in Cartesian Coordinates
Use Eqs. (1.25) and (1.26) to derive the usual formulas dA = dxdy and dV = dxdydz
for the 2-dimensional and 3-dimensional integration elements, respectively, in right-
handed Cartesian coordinates. [Hint: Use as the edges of the integration volumes
dx ex, dy ey, and dz ez.]
Exercise 1.11 Example and Practice: Integral of a Vector Field over a Sphere
Integrate the vector ﬁeld A = zez over a sphere with radius a, centered at the origin
of the Cartesian coordinate system (i.e., compute

A . d). Hints:
(a) Introduce spherical polar coordinates on the sphere, and construct the vectorial
integration element d from the two legs adθ e ˆθ and a sin θdφ e ˆφ. Here e ˆθ and
e ˆφ are unit-length vectors along the θ and φ directions. (Here as in Sec. 1.6 and
throughout this book, we use accents on indices to indicate which basis the index
is associated with: hats here for the spherical orthonormal basis, bars in Sec. 1.6
for the barred Cartesian basis.) Explain the factors adθ and a sin θdφ in the
deﬁnitions of the legs. Show that
d = ϵ(
, e ˆθ, e ˆφ)a2 sin θdθdφ.
(1.31)
(b) Using z = a cos θ and ez = cos θeˆr −sin θe ˆθ on the sphere (where eˆr is the unit
vector pointing in the radial direction), show that
A . d = a cos2 θ ϵ(eˆr, e ˆθ, e ˆφ) a2 sin θdθdφ.
28
Chapter 1. Newtonian Physics: Geometric Viewpoint

(c) Explain why ϵ(eˆr, e ˆθ, e ˆφ) = 1.
(d) Perform the integral

A . dover the sphere’s surface to obtain your ﬁnal answer
(4π/3)a3. This, of course, is the volume of the sphere. Explain pictorially why this
had to be the answer.
Exercise 1.12 Example: Faraday’s Law of Induction
One of Maxwell’s equations says that ∇× E = −∂B/∂t (in SI units), where E and
B are the electric and magnetic ﬁelds. This is a geometric relationship between ge-
ometric objects; it requires no coordinates or basis for its statement. By integrating
this equation over a 2-dimensional surface V2 with boundary curve ∂V2 and applying
Stokes’ theorem, derive Faraday’s law of induction—again, a geometric relationship
between geometric objects.
1.9
1.9 The Stress Tensor and Momentum Conservation
Press your hands together in the y-z plane and feel the force that one hand exerts
on the other across a tiny area A—say, one square millimeter of your hands’ palms
force vector
(Fig. 1.5). That force, of course, is a vector F. It has a normal component (along the
x direction). It also has a tangential component: if you try to slide your hands past
each other, you feel a component of force along their surface, a “shear” force in the
y and z directions. Not only is the force F vectorial; so is the 2-surface across which
it acts,  = A ex. (Here ex is the unit vector orthogonal to the tiny area A, and we
have chosen the negative side of the surface to be the −x side and the positive side to
be +x. With this choice, the force F is that which the negative hand, on the −x side,
exerts on the positive hand.)
Now, it should be obvious that the force F is a linear function of our chosen surface
stress tensor
. Therefore, there must be a tensor, the stress tensor,that reports the force to us when
we insert the surface into its second slot:
F(
) = T(
, ),
or
Fi = Tijj.
(1.32)
x
y
z
FIGURE 1.5 Hands, pressed
together, exert a force on
each other.
1.9 The Stress Tensor and Momentum Conservation
29

Newton’s law of action and reaction tells us that the force that the positive hand
exerts on the negative hand must be equal and opposite to that which the negative
hand exerts on the positive. This shows up trivially in Eq. (1.32): by changing the sign
of , one reverses which hand is regarded as negative and which positive, and since
T is linear in , one also reverses the sign of the force.
The deﬁnition (1.32) of the stress tensor gives rise to the following physical mean-
ing of its components:
meaning of components of
stress tensor
Tjk =
 j component of force per unit area
across a surface perpendicular to ek

=
⎛
⎝
j component of momentum that crosses a unit
area that is perpendicular to ek, per unit time,
with the crossing being from −xk to +xk
⎞
⎠.
(1.33)
The stresses inside a table with a heavy weight on it are described by the stress
tensor T, as are the stresses in a ﬂowing ﬂuid or plasma, in the electromagnetic ﬁeld,
and in any other physical medium. Accordingly, we shall use the stress tensor as an
important mathematical tool in our study of force balance in kinetic theory (Chap.
3), elasticity (Part IV), ﬂuid dynamics (Part V), and plasma physics (Part VI).
symmetry of stress tensor
Itisnotobviousfromitsdeﬁnition, butthestresstensor T isalwayssymmetricinits
two slots. To see this, consider a small cube with side L in any medium (or ﬁeld) (Fig.
1.6). The medium outside the cube exerts forces, and hence also torques, on the cube’s
faces. The z-component of the torque is produced by the shear forces on the front and
backfacesandontheleftandright.Asshownintheﬁgure, theshearforcesonthefront
and back faces have magnitudes TxyL2 and point in opposite directions, so they exert
identical torques on the cube, Nz = TxyL2(L/2) (where L/2 is the distance of each
face from the cube’s center). Similarly, the shear forces on the left and right faces have
magnitudes TyxL2 and point in opposite directions, thereby exerting identical torques
on the cube, Nz = −TyxL2(L/2). Adding the torques from all four faces and equating
them to the rate of change of angular momentum, 1
6ρL5dz/dt (where ρ is the mass
density, 1
6ρL5 is the cube’s moment of inertia, and z is the z component of its angular
velocity), we obtain (Txy −Tyx)L3 = 1
6ρL5dz/dt. Now, let the cube’s edge length
become arbitrarily small, L →0. If Txy −Tyx does not vanish, then the cube will be
set into rotation with an inﬁnitely large angular acceleration, dz/dt ∝1/L2 →∞—
an obviously unphysical behavior. Therefore, Tyx = Txy, and similarly for all other
components: the stress tensor is always symmetric under interchange of its two slots.
1.9.1
1.9.1 Examples: Electromagnetic Field and Perfect Fluid
Two examples will make the concept of the stress tensor more concrete.
.
Electromagnetic ﬁeld: See Ex. 1.14.
perfect ﬂuid
.
Perfect ﬂuid: A perfect ﬂuid is a medium that can exert an isotropic pressure
P but no shear stresses, so the only nonzero components of its stress tensor
30
Chapter 1. Newtonian Physics: Geometric Viewpoint

z
y
x
L
L
L
TxyL2
TxyL2
TyxL2
TyxL2
FIGURE 1.6 The shear forces exerted on the left, right, front, and
back faces of a vanishingly small cube of side length L. The
resulting torque about the z direction will set the cube into
rotation with an arbitrarily large angular acceleration unless the
stress tensor is symmetric.
in a Cartesian basis are Txx = Tyy = Tzz = P. (Examples of nearly perfect
ﬂuids are air and water, but not molasses.) We can summarize this property
by Tij = Pδij or equivalently, since δij are the components of the Euclidean
metric, Tij = P gij. The frame-independent version of this is
T = P g
or, in slot-naming index notation,
Tij = P gij.
(1.34)
Note that, as always, the formula in slot-naming index notation looks iden-
tical to the formula Tij = P gij for the components in our chosen Cartesian
coordinate system. To check Eq. (1.34), consider a 2-surface  = An with
area A oriented perpendicular to some arbitrary unit vector n. The vecto-
rial force that the ﬂuid exerts across  is, in index notation, Fj = Tjkk =
P gjkAnk = PAnj (i.e., it is a normal force with magnitude equal to the ﬂuid
pressure P times the surface area A). This is what it should be.
1.9.2
1.9.2 Conservation of Momentum
ThestresstensorplaysacentralroleintheNewtonianlawofmomentumconservation
because(bydeﬁnition)theforceactingacrossasurfaceisthesameastherateofﬂowof
momentum, per unit area, across the surface: the stress tensor is the ﬂux of momentum.
Consider the 3-dimensional region of space V3 used above in formulating the
integral laws of charge and particle conservation (1.29). The total momentum in V3
is

V3 GdV , where G is the momentum density. This quantity changes as a result
of momentum ﬂowing into and out of V3. The net rate at which momentum ﬂows
outward is the integral of the stress tensor over the surface ∂V3 of V3. Therefore, by
1.9 The Stress Tensor and Momentum Conservation
31

analogy with charge and particle conservation (1.29), the integral law of momentum
conservation says
integral conservation of
momentum
d
dt

V3
GdV +

∂V3
T . d = 0.
(1.35)
By pulling the time derivative inside the volume integral (where it becomes a
partial derivative) and applying the vectorial version of Gauss’s law to the surface
integral, we obtain

V3(∂G/∂t + ∇. T) dV = 0. This can be true for all choices of
V3 only if the integrand vanishes:
∂G
∂t + ∇. T = 0,
or
∂Gj
∂t
+ Tjk; k = 0.
(1.36)
(Because T is symmetric, it does not matter which of its slots the divergence acts on.)
This is the differential law of momentum conservation. It has the standard form for
differential conservation
of momentum
any local conservation law: the time derivative of the density of some quantity (here
momentum), plus the divergence of the ﬂux of that quantity (here the momentum
ﬂux is the stress tensor), is zero. We shall make extensive use of this Newtonian law
of momentum conservation in Part IV (elasticity), Part V (ﬂuid dynamics), and Part
VI (plasma physics).
EXERCISES
Exercise 1.13 **Example: Equations of Motion for a Perfect Fluid
(a) Consider a perfect ﬂuid with density ρ, pressure P , and velocity v that vary in
time and space. Explain why the ﬂuid’s momentum density is G = ρv, and explain
why its momentum ﬂux (stress tensor) is
T = P g + ρv ⊗v,
or, in slot-naming index notation,
Tij = P gij + ρvivj.
(1.37a)
(b) Explain why the law of mass conservation for this ﬂuid is
∂ρ
∂t + ∇. (ρv) = 0.
(1.37b)
(c) Explain why the derivative operator
d
dt ≡∂
∂t + v . ∇
(1.37c)
describes the rate of change as measured by somebody who moves locally with
the ﬂuid (i.e., with velocity v). This is sometimes called the ﬂuid’s advective time
derivative or convective time derivative or material derivative.
32
Chapter 1. Newtonian Physics: Geometric Viewpoint

(d) Show that the ﬂuid’s law of mass conservation (1.37b) can be rewritten as
1
ρ
dρ
dt = −∇. v,
(1.37d)
which says that the divergence of the ﬂuid’s velocity ﬁeld is minus the fractional
rate of change of its density, as measured in the ﬂuid’s local rest frame.
(e) Show that the differential law of momentum conservation (1.36) for the ﬂuid can
be written as
dv
dt = −∇P
ρ .
(1.37e)
This is called the ﬂuid’s Euler equation. Explain why this Euler equation is New-
ton’s second law of motion, F = ma, written on a per unit mass basis.
In Part V of this book, we use Eqs. (1.37) to study the dynamical behaviors of ﬂuids.
For many applications, the Euler equation will need to be augmented by the force per
unit mass exerted by the ﬂuid’s internal viscosity.
Exercise 1.14 **Problem: Electromagnetic Stress Tensor
(a) An electric ﬁeld E exerts (in SI units) a pressure ϵoE2/2 orthogonal to itself and
a tension of this same magnitude along itself. Similarly, a magnetic ﬁeld B exerts
a pressure B2/2μo = ϵoc2B2/2 orthogonal to itself and a tension of this same
magnitude along itself. Verify that the following stress tensor embodies these
stresses:
T = ϵo
2

(E2 + c2B2)g −2(E ⊗E + c2B ⊗B)

.
(1.38)
(b) Consider an electromagnetic ﬁeld interacting with a material that has a
charge density ρe and a current density j. Compute the divergence of the electro-
magnetic stress tensor (1.38) and evaluate the derivatives using Maxwell’s
equations. Show that the result is the negative of the force density that the
electromagnetic ﬁeld exerts on the material. Use momentum conservation to
explain why this has to be so.
1.10
1.10 Geometrized Units and Relativistic Particles for Newtonian Readers
Readers who are skipping the relativistic parts of this book will need to know two
important pieces of relativity: (i) geometrized units and (ii) the relativistic energy and
momentum of a moving particle.
1.10.1
1.10.1 Geometrized Units
The speed of light is independent of one’s reference frame (i.e., independent of how
fast one moves). This is a fundamental tenet of special relativity, and in the era before
1983, when the meter and the second were deﬁned independently, it was tested and
1.10 Geometrized Units and Relativistic Particles for Newtonian Readers
33

conﬁrmed experimentally with very high precision. By 1983, this constancy had
become so universally accepted that it was used to redeﬁne the meter (which is hard
to measure precisely) in terms of the second (which is much easier to measure with
modern technology).11 The meter is now related to the second in such a way that the
speed of light is precisely c = 299,792,458 m s−1 (i.e., 1 meter is the distance traveled
by light in 1/299,792,458 seconds). Because of this constancy of the light speed, it is
permissible when studying special relativity to set c to unity. Doing so is equivalent
to the relationship
c = 2.99792458 × 108 m s−1 = 1
(1.39a)
between seconds and centimeters; i.e., equivalent to
1 s = 2.99792458 × 108 m.
(1.39b)
geometrized units
We refer to units in which c = 1as geometrized units,and we adopt them through-
out this book when dealing with relativistic physics, since they make equations look
much simpler. Occasionally it will be useful to restore the factors of c to an equation,
thereby converting it to ordinary (SI or cgs) units. This restoration is achieved easily
using dimensional considerations. For example, the equivalence of mass m and rela-
tivistic energy E is written in geometrized units as E = m. In SI units E has dimensions
of joule = kg m2 s−2, while m has dimensions of kg, so to make E = m dimensionally
correct we must multiply the right side by a power of c that has dimensions m2 s−2
(i.e., by c2); thereby we obtain E = mc2.
1.10.2
1.10.2 Energy and Momentum of a Moving Particle
A particle with rest mass m, moving with velocity v = dx/dt and speed v = |v|, has a
relativistic energy and
momentum
relativistic energy E (including its rest mass), relativistic kinetic energy E (excluding
its rest mass), and relativistic momentum p given by
E =
m
√
1 −v2 ≡
m

1 −v2/c2 ≡E + m,
p = Ev =
mv
√
1 −v2;
so E =

m2 + p2.
(1.40)
In the low-velocity (Newtonian) limit, the energy E with rest mass removed (kinetic
energy) and the momentum p take their familiar Newtonian forms:
When v ≪c ≡1,
E →1
2mv2
and p →mv.
(1.41)
11. The second is deﬁned as the duration of 9,192,631,770 periods of the radiation produced by a certain
hyperﬁne transition in the ground state of a 133Cs atom that is at rest in empty space. Today (2016)
all fundamental physical units except mass units (e.g., the kilogram) are deﬁned similarly in terms of
fundamental constants of Nature.
34
Chapter 1. Newtonian Physics: Geometric Viewpoint

A particle with zero rest mass (a photon or a graviton)12 always moves with the speed
of light v = c = 1, and like other particles it has momentum p = Ev, so the magnitude
of its momentum is equal to its energy: |p| = Ev = Ec = E.
When particles interact (e.g., in chemical reactions, nuclear reactions, and
elementary-particle collisions) the sum of the particle energies E is conserved, as
is the sum of the particle momenta p.
For further details and explanations, see Chap. 2.
EXERCISES
Exercise 1.15 Practice: Geometrized Units
Convert the following equations from the geometrized units in which they are written
to SI units.
(a) The “Planck time” tP expressed in terms of Newton’s gravitation constant G and
Planck’s reduced constant ℏ, tP =
√
Gℏ. What is the numerical value of tP in
seconds? in meters?
(b) The energy E = 2m obtained from the annihilation of an electron and a positron,
each with rest mass m.
(c) The Lorentz force law mdv/dt = e(E + v × B).
(d) The expression p = ℏωn for the momentum p of a photon in terms of its angular
frequency ω and direction n of propagation.
How tall are you, in seconds? How old are you, in meters?
Bibliographic Note
Most of the concepts developed in this chapter are treated, though from rather dif-
ferent viewpoints, in intermediate and advanced textbooks on classical mechanics
or electrodynamics, such as Marion and Thornton (1995); Jackson (1999); Grifﬁths
(1999); Goldstein, Poole, and Safko (2002).
Landau and Lifshitz’s (1976) advanced text Mechanics is famous for its concise
and precise formulations; it lays heavy emphasis on symmetry principles and their
implications. A similar approach is followed in the next volume in their Course of
Theoretical Physics series, The Classical Theory of Fields (Landau and Lifshitz, 1975),
which is rooted in special relativity and goes on to cover general relativity. We refer
to other volumes in this remarkable series in subsequent chapters.
The three-volume Feynman Lectures on Physics (Feynman, Leighton, and Sands,
2013) had a big inﬂuence on several generations of physicists, and even more so on
their teachers. Both of us (Blandford and Thorne) are immensely indebted to Richard
Feynman for shaping our own approaches to physics. His insights on the foundations
12. We do not know for sure that photons and gravitons are massless, but the laws of physics as currently
understood require them to be massless, and there are tight experimental limits on their rest masses.
Bibliographic Note
35

of classical physics and its relationship to quantum mechanics, and on calculational
techniques, are as relevant today as in 1963, when his course was ﬁrst delivered.
The geometric viewpoint on the laws of physics, which we present and advocate
in this chapter, is not common (but it should be because of its great power). For ex-
ample, the vast majority of mechanics and electrodynamics textbooks, including all
those listed above, deﬁne a tensor as a matrix-like entity whose components trans-
form under rotations in the manner described by Eq. (1.13b). This is a complicated
deﬁnition that hides the great simplicity of a tensor as nothing more than a linear
function of vectors; it obscures thinking about tensors geometrically, without the aid
of any coordinate system or basis.
The geometric viewpoint comes to the physics community from mathematicians,
largely by way of relativity theory. By now, most relativity textbooks espouse it. See the
Bibliographic Note to Chap. 2. Fortunately, this viewpoint is gradually seeping into
the nonrelativistic physics curriculum (e.g., Kleppner and Kolenkow, 2013). We hope
this chapter will accelerate that seepage.
36
Chapter 1. Newtonian Physics: Geometric Viewpoint

2
CHAPTER TWO
Special Relativity: Geometric Viewpoint
Henceforth space by itself, and time by itself, are doomed to fade away into mere shadows,
and only a kind of union of the two will preserve an independent reality.
HERMANN MINKOWSKI, 1908
2.1
2.1 Overview
This chapter is a fairly complete introduction to special relativity at an intermediate
level. We extend the geometric viewpoint, developed in Chap. 1 for Newtonian phys-
ics, tothedomainofspecialrelativity; andweextendthetoolsofdifferentialgeometry,
developed in Chap. 1 for the arena of Newtonian physics (3-dimensional Euclidean
space) to that of special relativity (4-dimensional Minkowski spacetime).
We begin in Sec. 2.2 by deﬁning inertial (Lorentz) reference frames and then in-
troducing fundamental, geometric, reference-frame-independent concepts: events,
4-vectors, and the invariant interval between events. Then in Sec. 2.3, we develop
the basic concepts of tensor algebra in Minkowski spacetime (tensors, the metric
tensor, the inner product and tensor product, and contraction), patterning our devel-
opment on the corresponding concepts in Euclidean space. In Sec. 2.4, we illustrate
our tensor-algebra tools by using them to describe—without any coordinate system or
reference frame—the kinematics (world lines, 4-velocities, 4-momenta) of point par-
ticles that move through Minkowski spacetime. The particles are allowed to collide
with one another and be accelerated by an electromagnetic ﬁeld. In Sec. 2.5, we in-
troduce components of vectors and tensors in an inertial reference frame and rewrite
our frame-independent equations in slot-naming index notation; then in Sec. 2.6,
we use these extended tensorial tools to restudy the motions, collisions, and electro-
magnetic accelerations of particles. In Sec. 2.7, we discuss Lorentz transformations in
Minkowski spacetime, and in Sec. 2.8, we develop spacetime diagrams and use them
to study length contraction, time dilation, and simultaneity breakdown. In Sec. 2.9,
we illustrate the tools we have developed by asking whether the laws of physics permit
a highly advanced civilization to build time machines for traveling backward in time
as well as forward. In Sec. 2.10, we introduce directional derivatives, gradients, and
the Levi-Civita tensor in Minkowski spacetime, and in Sec. 2.11, we use these tools to
discuss Maxwell’s equations and the geometric nature of electric and magnetic ﬁelds.
37

BOX 2.1.
READERS’ GUIDE
.
Parts II (Statistical Physics), III (Optics), IV (Elasticity), V (Fluid
Dynamics), and VI (Plasma Physics) of this book deal almost
entirely with Newtonian physics; only a few sections and exercises
are relativistic. Readers who are inclined to skip those relativistic
items (which are all labeled Track Two) can skip this chapter and then
return to it just before embarking on Part VII (General Relativity).
Accordingly, this chapter is Track Two for readers of Parts II–VI and
Track One for readers of Part VII—and in this spirit we label it Track
Two.
.
More speciﬁcally, this chapter is a prerequisite for the following:
sections on relativistic kinetic theory in Chap. 3, Sec. 13.8 on
relativistic ﬂuid dynamics, Ex. 17.9 on relativistic shocks in
ﬂuids, many comments in Parts II–VI about relativistic effects
and connections between Newtonian physics and relativistic physics,
and all of Part VII (General Relativity).
.
We recommend that those readers for whom relativity is relevant—
and who already have a strong understanding of special relativity—
not skip this chapter entirely. Instead, we suggest they browse
it, especially Secs. 2.2–2.4, 2.8, and 2.11–2.13, to make sure they
understand this book’s geometric viewpoint and to ensure their
familiarity with such concepts as the stress-energy tensor that they
might not have met previously.
In Sec. 2.12, we develop our ﬁnal set of geometric tools: volume elements and the in-
tegration of tensors over spacetime; ﬁnally, in Sec. 2.13, we use these tools to deﬁne
the stress-energy tensor and to formulate very general versions of the conservation of
4-momentum.
2.2
2.2 Foundational Concepts
2.2.1
2.2.1 Inertial Frames, Inertial Coordinates, Events, Vectors, and Spacetime Diagrams
Because the nature and geometry of Minkowski spacetime are far less obvious intu-
itively than those of Euclidean 3-space, we need a crutch in our development of the
geometric viewpoint for physics in spacetime. That crutch will be inertial reference
frames.
38
Chapter 2. Special Relativity: Geometric Viewpoint

FIGURE 2.1 An inertial reference frame. From Taylor
and Wheeler (1966). Used with permission of E. F.
Taylor and the estate of J. A. Wheeler.
inertial reference frame
An inertial reference frame is a 3-dimensional latticework of measuring rods and
clocks (Fig. 2.1) with the following properties:
.
The latticework is purely conceptual and has arbitrarily small mass, so it does
not gravitate.
.
The latticework moves freely through spacetime (i.e., no forces act on it) and
is attached to gyroscopes, so it is inertially nonrotating.
.
The measuring rods form an orthogonal lattice, and the length intervals
marked on them are uniform when compared to, for example, the wave-
lengthoflightemittedbysomestandardtypeofatomormolecule.Therefore,
the rods form an orthonormal Cartesian coordinate system with the coor-
dinate x measured along one axis, y along another, and z along the third.
.
The clocks are densely packed throughout the latticework so that, ideally,
there is a separate clock at every lattice point.
.
The clocks tick uniformly when compared to the period of the light emitted
by some standard type of atom or molecule (i.e., they are ideal clocks).
ideal clocks and their
synchronization
.
The clocks are synchronized by the Einstein synchronization process: if a
pulse of light, emitted by one of the clocks, bounces off a mirror attached to
another and then returns, the time of bounce tb, as measured by the clock
that does the bouncing, is the average of the times of emission and reception,
as measured by the emitting and receiving clock: tb = 1
2(te + tr).1
1.
For a deeper discussion of the nature of ideal clocks and ideal measuring rods see, for example, Misner,
Thorne, and Wheeler (1973, pp. 23–29 and 395–399).
2.2 Foundational Concepts
39

(That inertial frames with these properties can exist, when gravity is unimportant,
is an empirical fact; it tells us that, in the absence of gravity, spacetime is truly
Minkowski.)
event
Our ﬁrst fundamental, frame-independent relativistic concept is the event. An
event is a precise location in space at a precise moment of time—a precise location
(or point) in 4-dimensional spacetime. We sometimes denote events by capital script
letters, such as P and Q—the same notation used for points in Euclidean 3-space.
4-vector
A 4-vector (also often referred to as a vector in spacetime or just a vector) is a
straight2 arrow ⃗x reaching from one event P to another, Q. We often deal with
4-vectors and ordinary (3-space) vectors simultaneously, so we shall use different
notations for them: boldface Roman font for 3-vectors, x, and arrowed italic font
for 4-vectors, ⃗x. Sometimes we identify an event P in spacetime by its vectorial
separation ⃗xP from some arbitrarily chosen event in spacetime, the origin O.
An inertial reference frame provides us with a coordinate system for spacetime.
The coordinates (x0, x1, x2, x3) = (t, x, y, z) that it associates with an event P are
P’s location (x, y, z) in the frame’s latticework of measuring rods and the time t of P
as measured by the clock that sits in the lattice at the event’s location. (Many apparent
paradoxes in special relativity result from failing to remember that the time t of an
event is always measured by a clock that resides at the event—never by clocks that
reside elsewhere in spacetime.)
spacetime diagrams
It is useful to depict events on spacetime diagrams, in which the time coordinate
t = x0 of some inertial frame is plotted upward; two of the frame’s three spatial
coordinates, x = x1 and y = x2, are plotted horizontally; and the third coordinate
z = x3 is omitted. Figure 2.2 is an example. Two events P and Q are shown there,
along with their vectorial separations ⃗xP and ⃗xQ from the origin and the vector
⃗x = ⃗xQ −⃗xP that separates them from each other. The coordinates of P and Q,
which are the same as the components of ⃗xP and ⃗xQ in this coordinate system, are
(tP, xP, yP, zP) and (tQ, xQ, yQ, zQ). Correspondingly, the components of ⃗x are
x0 = t = tQ −tP,
x1 = x = xQ −xP,
x2 = y = yQ −yP,
x3 = z = zQ −zP.
(2.1)
We denote these components of ⃗x more compactly by xα, where the index α and
all other lowercased Greek indices range from 0 (for t) to 3 (for z).
When the physics or geometry of a situation being studied suggests some preferred
inertial frame (e.g., the frame in which some piece of experimental apparatus is at
rest), then we typically use as axes for our spacetime diagrams the coordinates of
that preferred frame. By contrast, when our situation provides no preferred inertial
frame, or when we wish to emphasize a frame-independent viewpoint, we use as axes
2.
By “straight” we mean that in any inertial reference frame, the coordinates along ⃗x are linear functions
of one another.
40
Chapter 2. Special Relativity: Geometric Viewpoint

t
y
→xQ
→xP
→x
x
O
P
Q
FIGURE 2.2 A spacetime diagram depicting two events P and
Q, their vectorial separations ⃗xP and ⃗xQ from an (arbitrarily
chosen) origin O, and the vector ⃗x = ⃗xQ −⃗xP connecting
them. The laws of physics cannot involve the arbitrary
origin; we introduce it only as a conceptual aid.
the coordinates of a completely arbitrary inertial frame and think of the diagram as
depicting spacetime in a coordinate-independent, frame-independent way.
inertial coordinates
(Lorentz coordinates)
We use the terms inertial coordinate system and Lorentz coordinate system inter-
changeably3 to mean the coordinate system (t, x, y, z) provided by an inertial frame;
we also use the term Lorentz frame interchangeably with inertial frame. A physicist
or other intelligent being who resides in a Lorentz frame and makes measurements
using its latticework of rods and clocks will be called an observer.
observer
Although events are often described by their coordinates in a Lorentz reference
frame, and 4-vectors by their components (coordinate differences), it should be ob-
vious that the concepts of an event and a 4-vector need not rely on any coordinate
system whatsoever for their deﬁnitions. For example, the event P of the birth of Isaac
Newton and the event Q of the birth of Albert Einstein are readily identiﬁed without
coordinates. They can be regarded as points in spacetime, and their separation vector
is the straight arrow reaching through spacetime from P to Q. Different observers in
different inertial frames will attribute different coordinates to each birth and different
components to the births’ vectorial separation, but all observers can agree that they
are talking about the same events P and Q in spacetime and the same separation vec-
tor ⃗x. In this sense, P, Q, and ⃗x are frame-independent, geometric objects (points
and arrows) that reside in spacetime.
3.
It was Lorentz (1904) who ﬁrst wrote down the relationship of one such coordinate system to another:
the Lorentz transformation.
2.2 Foundational Concepts
41

2.2.2
2.2.2 The Principle of Relativity and Constancy of Light Speed
Principle of Relativity
Einstein’s Principle of Relativity, stated in modern form, says that Every (special rel-
ativistic) law of physics must be expressible as a geometric, frame-independent rela-
tionship among geometric, frame-independent objects (i.e., such objects as points in
spacetime and 4-vectors and tensors, which represent physical quantities, such as
events, particle momenta, and the electromagnetic ﬁeld). This is nothing but our Ge-
ometric Principle for physical laws (Chap. 1), lifted from the Euclidean-space arena
of Newtonian physics to the Minkowski-spacetime arena of special relativity.
Sincethelawsareallgeometric(i.e., unrelatedtoanyreferenceframeorcoordinate
system), they can’t distinguish one inertial reference frame from any other. This leads
to an alternative form of the Principle of Relativity (one commonly used in elementary
textbooks and equivalent to the above): All the (special relativistic) laws of physics are
the same in every inertial reference frame everywhere in spacetime. This, in fact, is
Einstein’s own version of his Principle of Relativity; only in the sixty years since his
death have we physicists reexpressed it in geometric language.
Because inertial reference frames are related to one another by Lorentz transfor-
mations (Sec. 2.7), we can restate Einstein’s version of this Principle as All the (special
relativistic) laws of physics are Lorentz invariant.
A more operational version of this Principle is: Give identical instructions for a
speciﬁc physics experiment to two different observers in two different inertial ref-
erence frames at the same or different locations in Minkowski (i.e., gravity-free)
spacetime. The experiment must be self-contained; that is, it must not involve ob-
servations of the external universe’s properties (the “environment”). For example, an
unacceptable experiment would be a measurement of the anisotropy of the universe’s
cosmic microwave radiation and a computation therefrom of the observer’s velocity
relative to the radiation’s mean rest frame; such an experiment studies the universal
environment, not the fundamental laws of physics. An acceptable experiment would
be a measurement of the speed of light using the rods and clocks of the observer’s own
frame, or a measurement of cross sections for elementary particle reactions using par-
ticles moving in the reference frame’s laboratory. The Principle of Relativity says that
in these or any other similarly self-contained experiments, the two observers in their
two different inertial frames must obtain identical experimental results—to within
the accuracy of their experimental techniques. Since the experimental results are gov-
erned by the (nongravitational) laws of physics, this is equivalent to the statement that
all physical laws are the same in the two inertial frames.
constancy of light speed
Perhaps the most central of special relativistic laws is the one stating that The speed
of light c in vacuum is frame independent; that is, it is a constant, independent of the
inertial reference frame in which it is measured. In other words, there is no “aether”
that supports light’s vibrations and in the process inﬂuences its speed—a remarkable
factthatcameasagreatexperimentalsurprisetophysicistsattheendofthenineteenth
century.
42
Chapter 2. Special Relativity: Geometric Viewpoint

The constancy of the speed of light, in fact, is built into Maxwell’s equations. For
these equations to be frame independent, the speed of light, which appears in them,
must be frame independent. In this sense, the constancy of the speed of light follows
from the Principle of Relativity; it is not an independent postulate. This is illustrated
in Box 2.2.
BOX 2.2.
MEASURING THE SPEED OF LIGHT WITHOUT LIGHT
r
r
(a)
(b)
Q
Q
ae
am
q,μ
q,μ
v
In some inertial reference frame, we perform two thought experiments using
two particles, one with a large charge Q; the other, a test particle, with a much
smaller charge q and mass μ. In the ﬁrst experiment, we place the two particles
at rest, separated by a distance |x| ≡r, and measure the electrical repulsive
acceleration ae of q (panel a in the diagram). In Gaussian units (where the
speed of light shows up explicitly instead of via ϵoμo = 1/c2), the acceleration
is ae = qQ/r2μ. In the second experiment, we connect Q to ground by a long
wire, and we place q at the distance |x| = r from the wire and set it moving
at speed v parallel to the wire. The charge Q ﬂows down the wire with an e-
folding time τ, so the current is I = dQ/dτ = (Q/τ)e−t/τ. At early times
0 < t ≪τ, this current I = Q/τ produces a solenoidal magnetic ﬁeld at q
with ﬁeld strength B = (2/cr)(Q/τ), and this ﬁeld exerts a magnetic force on
q, giving it an acceleration am = q(v/c)B/μ = 2vqQ/c2τrμ. The ratio of the
electric acceleration in the ﬁrst experiment to the magnetic acceleration in the
second experiment is ae/am = c2τ/2rv. Therefore, we can measure the speed
of light c in our chosen inertial frame by performing this pair of experiments;
carefully measuring the separation r, speed v, current Q/τ, and accelerations;
and then simply computing c =

(2rv/τ)(ae/am). The Principle of Relativity
insists that the result of this pair of experiments should be independent of the
inertial frame in which they are performed. Therefore, the speed of light c
that appears in Maxwell’s equations must be frame independent. In this sense,
the constancy of the speed of light follows from the Principle of Relativity as
applied to Maxwell’s equations.
2.2 Foundational Concepts
43

What makes light so special? What about the propagation speeds of other types of
waves? Are they or should they be the same as light’s speed? For a digression on this
topic, see Box 2.3.
The constancy of the speed of light underlies our ability to use the geometrized
units introduced in Sec. 1.10. Any reader who has not studied that section should do
so now. We use geometrized units throughout this chapter (and also throughout this
book) when working with relativistic physics.
BOX 2.3.
PROPAGATION SPEEDS OF OTHER WAVES
Electromagnetic radiation is not the only type of wave in Nature. In this book,
we encounter dispersive media, such as optical ﬁbers and plasmas, where
electromagnetic signals travel slower than c. We also analyze sound waves
and seismic waves, whose governing laws do not involve electromagnetism
at all. How do these ﬁt into our special relativistic framework? The answer is
simple. Each of these waves involves an underlying medium that is at rest in
one particular frame (not necessarily inertial), and the velocity at which the
wave’s information propagates (the group velocity) is most simply calculated
in this frame from the wave’s and medium’s fundamental laws. We can then
use the kinematic rules of Lorentz transformations to compute the velocity
in another frame. However, if we had chosen to compute the wave speed in
the second frame directly, using the same fundamental laws, we would have
gotten the same answer, albeit perhaps with greater effort. All waves are in
full compliance with the Principle of Relativity. What is special about vacuum
electromagnetic waves and, by extension, photons, is that no medium (or
“aether,” as it used to be called) is needed for them to propagate. Their speed
is therefore the same in all frames. (Although some physicists regard the
cosmological constant, discussed in Chap. 28, as a modern aether, we must
emphaisze that, unlike its nineteenth-century antecedent, its presence does
not alter the propagation of photons through Lorentz frames.)
This raises an interesting question. What about other waves that do not
require an underlying medium? What about electron de Broglie waves? Here
the fundamental wave equation, Schr¨odinger’s or Dirac’s, is mathematically
different from Maxwell’s and contains an important parameter, the electron
rest mass. This rest mass allows the fundamental laws of relativistic quantum
mechanics to be written in a form that is the same in all inertial reference
frames and at the same time allows an electron, considered as either a wave
or a particle, to travel at a different speed when measured in a different
frame.
(continued)
44
Chapter 2. Special Relativity: Geometric Viewpoint

BOX 2.3.
(continued)
Some particles that have been postulated (such as gravitons, the quanta of
gravitational waves; Chap. 27) are believed to exist without a rest mass (or an
aether!), just like photons. Must these travel at the same speed as photons?
The answer, according to the Principle of Relativity, is “yes.” Why? Suppose
there were two such waves or particles whose governing laws led to different
speeds, c and c′ < c, with each speed claimed to be the same in all reference
frames. Such a claim produces insurmountable conundrums. For example,
if we move with speed c′ in the direction of propagation of the second wave,
we will bring it to rest, in conﬂict with our hypothesis that its speed is frame
independent. Therefore, all signals whose governing laws require them to
travel with a speed that has no governing parameters (no rest mass and
no underlying physical medium) must travel with a unique speed, which
we call c. The speed of light is more fundamental to relativity than light
itself!
2.2.3
2.2.3 The Interval and Its Invariance
the interval
Next we turn to another fundamental concept, the interval (s)2 between the two
events P and Q whose separation vector is ⃗x. In a speciﬁc but arbitrary inertial
reference frame and in geometrized units, (s)2 is given by
(s)2 ≡−(t)2 + (x)2 + (y)2 + (z)2 = −(t)2 +
 
i,j
δijxixj;
(2.2a)
cf. Eq. (2.1). If (s)2 > 0, the events P and Q are said to have a spacelike separation;
spacelike, timelike, and
null
if (s)2 = 0, their separation is null or lightlike; and if (s)2 < 0, their separation is
timelike. For timelike separations, (s)2 < 0 implies that s is imaginary; to avoid
dealing with imaginary numbers, we describe timelike intervals by
(τ)2 ≡−(s)2,
(2.2b)
whose square root τ is real.
The coordinate separation between P and Q depends on one’s reference frame: if
xα′ and xα are the coordinate separations in two different frames, then xα′ ̸=
2.2 Foundational Concepts
45

xα. Despite this frame dependence, the Principle of Relativity forces the interval
(s)2 to be the same in all frames:
(s)2 = −(t)2 + (x)2 + (y)2 + (z)2
= −(t′)2 + (x′)2 + (y′)2 + (z′)2.
(2.3)
In Box 2.4, we sketch a proof for the case of two events P and Q whose separation is
timelike.
Because of its frame invariance, the interval (s)2 can be regarded as a geometric
property of the vector ⃗x that reaches from P to Q; we call it the squared length (⃗x)2
of ⃗x:
(⃗x)2 ≡(s)2.
(2.4)
BOX 2.4.
PROOF OF INVARIANCE OF THE INTERVAL FOR A
TIMELIKE SEPARATION
A simple demonstration that the interval is invariant is provided by a thought
experiment in which a photon is emitted at event P, reﬂects off a mirror, and
is then detected at event Q. We consider the interval between these events
in two reference frames, primed and unprimed, that move with respect to
each other. Choose the spatial coordinate systems of the two frames in such
a way that (i) their relative motion (with speed β, which will not enter into
our analysis) is along the x and x′ directions, (ii) event P lies on the x and
x′ axes, and (iii) event Q lies in the x-y and x′-y′ planes, as depicted below.
Then evaluate the interval between P and Q in the unprimed frame by the
following construction: Place the mirror parallel to the x-z plane at precisely
the height h that permits a photon, emitted from P, to travel along the dashed
line to the mirror, then reﬂect off the mirror and continue along the dashed
path, arriving at event Q. If the mirror were placed lower, the photon would
arrive at the spatial location of Q sooner than the time of Q; if placed higher,
it would arrive later. Then the distance the photon travels (the length of the
two-segment dashed line) is equal to ct = t, where t is the time between
events P and Q as measured in the unprimed frame. If the mirror had not
been present, the photon would have arrived at event R after time t, so ct
is the distance between P and R. From the diagram, it is easy to see that the
height of R above the x-axis is 2h −y, and the Pythagorean theorem then
implies that
(s)2 = −(t)2 + (x)2 + (y)2 = −(2h −y)2 + (y)2.
(1a)
The same construction in the primed frame must give the same formula, but
with primes:
(s′)2 = −(t′)2 + (x′)2 + (y′)2 = −(2h′ −y′)2 + (y′)2. (1b)
(continued)
46
Chapter 2. Special Relativity: Geometric Viewpoint

BOX 2.4.
(continued)
The proof that (s′)2 = (s)2 then reduces to showing that the Principle of
Relativity requires that distances perpendicular to the direction of relative
motion of two frames be the same as measured in the two frames: h′ = h,
y′ = y. We leave it to the reader to develop a careful argument for this
(Ex. 2.2).
y
y
ct
2h – y
x
y′
x
h
mirror
x′
β
P
R
Q
Note that this squared length, despite its name, can be negative (for timelike ⃗x) or
zero (for null ⃗x) as well as positive (for spacelike ⃗x).
The invariant interval (s)2 between two events is as fundamental to Minkowski
spacetime as the Euclidean distance between two points is to ﬂat 3-space. Just as
the Euclidean distance gives rise to the geometry of 3-space (as embodied, e.g., in
Euclid’s axioms), so the interval gives rise to the geometry of spacetime, which we
shall be exploring. If this spacetime geometry were as intuitively obvious to humans
as is Euclidean geometry, we would not need the crutch of inertial reference frames
to arrive at it. Nature (presumably) has no need for such a crutch. To Nature (it seems
evident), thegeometryofMinkowskispacetime, asembodiedintheinvariantinterval,
is among the most fundamental aspects of physical law.
EXERCISES
Exercise 2.1 Practice: Geometrized Units
Do Ex. 1.15 in Chap. 1.
Exercise 2.2 Derivation and Example: Invariance of the Interval
Complete the derivation of the invariance of the interval given in Box 2.4, using the
2.2 Foundational Concepts
47

Principle of Relativity in the form that the laws of physics must be the same in the
primed and unprimed frames. Hints (if you need them):
(a) Having carried out the construction in the unprimed frame, depicted at the
bottom left of Box 2.4, use the same mirror and photons for the analogous
construction in the primed frame. Argue that, independently of the frame in
whichthemirrorisatrest(unprimedorprimed), thefactthatthereﬂectedphoton
has (angle of reﬂection) = (angle of incidence) in its rest frame implies that this
is also true for the same photon in the other frame. Thereby conclude that the
construction leads to Eq. (1b) in Box 2.4, as well as to Eq. (1a).
(b) Then argue that the perpendicular distance of an event from the common x- and
x′-axes must be the same in the two reference frames, so h′ = h and y′ = y;
whence Eqs. (1b) and (1a) in Box 2.4 imply the invariance of the interval. [Note:
For a leisurely version of this argument, see Taylor and Wheeler (1992, Secs. 3.6
and 3.7).]
2.3
2.3 Tensor Algebra without a Coordinate System
Having introduced points in spacetime (interpreted physically as events), the invari-
ant interval (s)2 between two events, 4-vectors (as arrows between two events),
and the squared length of a vector (as the invariant interval between the vector’s tail
and tip), we can now introduce the remaining tools of tensor algebra for Minkowski
spacetime in precisely the same way as we did for the Euclidean 3-space of Newtonian
physics (Sec. 1.3), with the invariant interval between events playing the same role as
the squared length between Euclidean points.
tensor
In particular: a tensor TTT(
,
,
) is a real-valued linear function of vectors
in Minkowski spacetime. (We use slanted letters TTT for tensors in spacetime and
unslanted letters T in Euclidean space.) A tensor’s rank is equal to its number of slots.
The inner product (also called the dot product) of two 4-vectors is
inner product
⃗A . ⃗B ≡1
4

( ⃗A + ⃗B)2 −( ⃗A −⃗B)2
,
(2.5)
where( ⃗A + ⃗B)2 isthesquaredlengthofthisvector(i.e., theinvariantintervalbetween
metric tensor
its tail and its tip). The metric tensor of spacetime is that linear function of 4-vectors
whose value is the inner product of the vectors:
ggg( ⃗A, ⃗B) ≡⃗A . ⃗B.
(2.6)
Using the inner product, we can regard any vector ⃗A as a rank-1 tensor: ⃗A( ⃗C) ≡⃗A . ⃗C.
tensor product
Similarly, the tensor product ⊗is deﬁned precisely as in the Euclidean domain,
Eqs. (1.5), as is the contraction of two slots of a tensor against each other, Eqs. (1.6),
contraction
which lowers the tensor’s rank by two.
48
Chapter 2. Special Relativity: Geometric Viewpoint

2.4
2.4 Particle Kinetics and Lorentz Force without a Reference Frame
2.4.1
2.4.1 Relativistic Particle Kinetics: World Lines, 4-Velocity, 4-Momentum and
Its Conservation, 4-Force
In this section, we illustrate our geometric viewpoint by formulating the special
relativistic laws of motion for particles.
ideal clock
An accelerated particle moving through spacetime carries an ideal clock.By “ideal”
we mean that the clock is unaffected by accelerations: it ticks at a uniform rate when
compared to unaccelerated atomic oscillators that are momentarily at rest beside
the clock and are well protected from their environments. The builders of inertial
guidance systems for airplanes and missiles try to make their clocks as ideal as possible
proper time
in just this sense. We denote by τ the time ticked by the particle’s ideal clock, and we
call it the particle’s proper time.
world line
The particle moves through spacetime along a curve, called its world line, which
we can denote equally well by P(τ) (the particle’s spacetime location P at proper time
τ), or by ⃗x(τ) (the particle’s vector separation from some arbitrarily chosen origin at
proper time τ).4
momentary rest frame
We refer to the inertial frame in which the particle is momentarily at rest as its
momentarily comoving inertial frame or momentary rest frame. Now, the particle’s
clock(whichmeasuresτ)isideal, andsoaretheinertialframe’sclocks(whichmeasure
coordinate time t). Therefore, a tiny interval τ of the particle’s proper time is equal
to the lapse of coordinate time in the particle’s momentary rest frame τ = t.
Moreover, since the two events ⃗x(τ) and ⃗x(τ + τ) on the clock’s world line occur
at the same spatial location in its momentary rest frame (xi = 0, where i = 1, 2, 3)
to ﬁrst order in τ, the invariant interval between those events is (s)2 = −(t)2 +
!
i,j xixjδij = −(t)2 = −(τ)2. Thus, the particle’s proper time τ is equal to
the square root of the negative of the invariant interval, τ =
√
−s2, along its world line.
Figure 2.3 shows the world line of the accelerated particle in a spacetime diagram
where the axes are coordinates of an arbitrary Lorentz frame. This diagram is intended
to emphasize the world line as a frame-independent, geometric object. Also shown in
the ﬁgure is the particle’s 4-velocity ⃗u, which (by analogy with velocity in 3-space) is
the time derivative of its position
4-velocity
⃗u ≡dP/dτ = d ⃗x/dτ
(2.7)
and is the tangent vector to the world line. The derivative is deﬁned by the usual
limiting process
dP
dτ = d ⃗x
dτ ≡lim
τ→0
P(τ + τ) −P(τ)
τ
= lim
τ→0
⃗x(τ + τ) −⃗x(τ)
τ
.
(2.8)
4.
One of the basic ideas in string theory is that an elementary particle is described as a 1-dimensional
loop in space rather than a 0-dimensional point. This means that it becomes a cylinder-like surface in
spacetime—a world tube.
2.4 Particle Kinetics and Lorentz Force without a Reference Frame
49

t
y
→u
→u
τ = 0
1
2
3
4
5
6
7
x
FIGURE 2.3 Spacetime diagram showing the world
line ⃗x(τ) and 4-velocity ⃗u of an accelerated
particle. Note that the 4-velocity is tangent to
the world line.
Here P(τ + τ) −P(τ) and ⃗x(τ + τ) −⃗x(τ) are just two different ways to denote
the same vector that reaches from one point on the world line to another.
The squared length of the particle’s 4-velocity is easily seen to be −1:
⃗u2 ≡ggg(⃗u, ⃗u) = d ⃗x
dτ
. d ⃗x
dτ = d ⃗x . d ⃗x
(dτ)2 = −1.
(2.9)
The last equality follows from the fact that d ⃗x . d ⃗x is the squared length of d ⃗x, which
equals the invariant interval (s)2 along it, and (dτ)2 is the negative of that invariant
interval.
4-momentum
The particle’s 4-momentum is the product of its 4-velocity and rest mass:
⃗p ≡m⃗u = md ⃗x/dτ ≡d ⃗x/dζ .
(2.10)
Here the parameter ζ is a renormalized version of proper time,
ζ ≡τ/m.
(2.11)
This ζ and any other renormalized version of proper time with a position-
afﬁne parameter
independent renormalization factor are called afﬁne parameters for the particle’s
world line. Expression (2.10), together with ⃗u2 = −1, implies that the squared length
of the 4-momentum is
⃗p2 = −m2.
(2.12)
In quantum theory, a particle is described by a relativistic wave function, which, in
the geometric optics limit (Chap. 7), has a wave vector ⃗k that is related to the classical
particle’s 4-momentum by
⃗k = ⃗p/ℏ.
(2.13)
50
Chapter 2. Special Relativity: Geometric Viewpoint

The above formalism is valid only for particles with nonzero rest mass, m ̸= 0.
The corresponding formalism for a particle with zero rest mass (e.g., a photon or a
graviton) can be obtained from the above by taking the limit as m →0 and dτ →0
with the quotient dζ = dτ/m held ﬁnite. More speciﬁcally, the 4-momentum of a
zero-rest-mass particle is well deﬁned (and participates in the conservation law to
be discussed below), and it is expressible in terms of the particle’s afﬁne parameter ζ
by Eq. (2.10):
⃗p = d ⃗x/dζ .
(2.14)
By contrast, the particle’s 4-velocity ⃗u = ⃗p/m is inﬁnite and thus undeﬁned, and
propertimeτ = mζ ticksvanishinglyslowlyalongitsworldlineandthusisundeﬁned.
Because proper time is the square root of the invariant interval along the world line,
the interval between two neighboring points on the world line vanishes. Therefore, the
world line of a zero-rest-mass particle is null. (By contrast, since dτ 2 > 0 and ds2 < 0
alongtheworldlineofaparticlewithﬁniterestmass, theworldlineofaﬁnite-rest-mass
particle is timelike.)
conservation of
4-momentum
The 4-momenta of particles are important because of the law of conservation of
4-momentum (which, as we shall see in Sec. 2.6, is equivalent to the conservation
laws for energy and ordinary momentum): If a number of “initial” particles, named
A = 1, 2, 3, . . . , enter a restricted region of spacetime V and there interact strongly
to produce a new set of “ﬁnal” particles, named ¯A = ¯1, ¯2, ¯3, . . . (Fig. 2.4), then the
total 4-momentum of the ﬁnal particles must be the same as the total 4-momentum
of the initial ones:
 
¯A
⃗p ¯A =
 
A
⃗pA.
(2.15)
Note that this law of 4-momentum conservation is expressed in frame-independent,
geometric language—in accord with Einstein’s insistence that all the laws of physics
should be so expressible. As we shall see in Part VII, 4-momentum conservation
is a consequence of the translation symmetry of ﬂat, 4-dimensional spacetime. In
general relativity’s curved spacetime, where that translation symmetry is lost, we lose
4-momentum conservation except under special circumstances; see Eq. (25.56) and
associated discussion.
If a particle moves freely (no external forces and no collisions with other particles),
then its 4-momentum ⃗p will be conserved along its world line, d ⃗p/dζ = 0. Since
⃗p is tangent to the world line, this conservation means that the direction of the
world line in spacetime never changes: the free particle moves along a straight line
through spacetime. To change the particle’s 4-momentum, one must act on it with a
4-force ⃗F,
4-force
d ⃗p/dτ = ⃗F .
(2.16)
2.4 Particle Kinetics and Lorentz Force without a Reference Frame
51

t
y
→p1
→p2–
→p1–
→p2
x
V
FIGURE 2.4 Spacetime diagram depicting the law of 4-momentum conser-
vation for a situation where two particles, numbered 1 and 2, enter an
interaction region V in spacetime, and there interact strongly and produce
two new particles, numbered ¯1 and ¯2. The sum of the ﬁnal 4-momenta,
⃗p¯1 + ⃗p¯2, must be equal to the sum of the initial 4-momenta, ⃗p1 + ⃗p2.
If the particle is a fundamental one (e.g., photon, electron, proton), then the 4-force
must leave its rest mass unchanged,
0 = dm2/dτ = −d ⃗p2/dτ = −2 ⃗p . d ⃗p/dτ = −2 ⃗p . ⃗F;
(2.17)
thatis, the4-forcemustbeorthogonaltothe4-momentuminthe4-dimensionalsense
that their inner product vanishes.
2.4.2
2.4.2 Geometric Derivation of the Lorentz Force Law
As an illustration of these physical concepts and mathematical tools, we use them to
deduce the relativistic version of the Lorentz force law. From the outset, in accord with
the Principle of Relativity, we insist that the law we seek be expressible in geometric,
frame-independent language, that is, in terms of vectors and tensors.
electromagnetic ﬁeld
tensor
Consider a particle with charge q and rest mass m ̸= 0 interacting with an electro-
magnetic ﬁeld. It experiences an electromagnetic 4-force whose mathematical form
we seek. The Newtonian version of the electromagnetic force F = q(E + v × B) is
proportional to q and contains one piece (electric) that is independent of velocity v
and a second piece (magnetic) that is linear in v. It is reasonable to expect that, to
produce this Newtonian limit, the relativistic 4-force ⃗F will be proportional to q and
will be linear in the 4-velocity ⃗u. Linearity means there must exist some second-rank
tensor FFF(
,
), the electromagnetic ﬁeld tensor, such that
d ⃗p/dτ = ⃗F(
) = qFFF(
, ⃗u).
(2.18)
52
Chapter 2. Special Relativity: Geometric Viewpoint

Because the 4-force ⃗F must be orthogonal to the particle’s 4-momentum and thence
also to its 4-velocity, ⃗F . ⃗u ≡⃗F(⃗u) = 0, expression (2.18) must vanish when ⃗u is
inserted into its empty slot. In other words, for all timelike unit-length vectors ⃗u,
FFF(⃗u, ⃗u) = 0.
(2.19)
It is an instructive exercise (Ex. 2.3) to show that this is possible only if FFF is anti-
symmetric, so the electromagnetic 4-force is
electromagnetic 4-force
d ⃗p/dτ = qFFF(
, ⃗u),
where
FFF( ⃗A, ⃗B) = −FFF( ⃗B, ⃗A)
for all ⃗A and ⃗B.
(2.20)
Equation (2.20) must be the relativistic form of the Lorentz force law. In Sec. 2.11
we deduce the relationship of the electromagnetic ﬁeld tensor FFF to the more familiar
electric and magnetic ﬁelds, and the relationship of this relativistic Lorentz force to
its Newtonian form (1.7c).
The discussion of particle kinematics and the electromagnetic force in this Sec. 2.4
is elegant but perhaps unfamiliar. In Secs. 2.6 and 2.11, we shall see that it is equivalent
to the more elementary (but more complex) formalism based on components of
vectors in Euclidean 3-space.
EXERCISES
Exercise 2.3 Derivation and Example: Antisymmetry of Electromagnetic Field Tensor
Show that Eq. (2.19) can be true for all timelike, unit-length vectors ⃗u if and only if FFF
is antisymmetric. [Hints: (i) Show that the most general second-rank tensor FFF can be
written as the sum of a symmetric tensor SSS and an antisymmetric tensor AAA, and that
the antisymmetric piece contributes nothing to Eq. (2.19), so SSS(⃗u, ⃗u) must vanish for
every timelike ⃗u. (ii) Let ⃗a be a timelike vector, let ⃗b be an artibrary vector (timelike,
null, or spacelike), and let ϵ be a number small enough that ⃗A± ≡⃗a ± ϵ⃗b are both
timelike. From the fact that SSS( ⃗A+, ⃗A+), SSS( ⃗A−, ⃗A−), and SSS(⃗a, ⃗a) all vanish, deduce
that SSS(⃗b, ⃗b) = 0 for the arbitrary vector ⃗b. (iii) From this, deduce that SSS vanishes (i.e.,
it gives zero when any two vectors are inserted into its slots).]
Exercise 2.4 Problem: Relativistic Gravitational Force Law
In Newtonian theory, the gravitational potential  exerts a force F = dp/dt =
−m∇ on a particle with mass m and momentum p. Before Einstein formulated
general relativity, some physicists constructed relativistic theories of gravity in which
a Newtonian-like scalar gravitational ﬁeld  exerted a 4-force ⃗F = d ⃗p/dτ on any
particle with rest mass m, 4-velocity ⃗u, and 4-momentum ⃗p = m⃗u. What must that
force law have been for it to (i) obey the Principle of Relativity, (ii) reduce to New-
ton’s law in the nonrelativistic limit, and (iii) preserve the particle’s rest mass as time
passes?
2.4 Particle Kinetics and Lorentz Force without a Reference Frame
53

2.5
2.5 Component Representation of Tensor Algebra
2.5.1
2.5.1 Lorentz Coordinates
Lorentz (orthonormal)
basis
In Minkowski spacetime, associated with any inertial reference frame (Fig. 2.1 and
Sec. 2.2.1), there is a Lorentz coordinate system {t, x, y, z} = {x0, x1, x2, x3} gener-
ated by the frame’s rods and clocks. (Note the use of superscripts.) And associated
with these coordinates is a set of Lorentz basis vectors {⃗et, ⃗ex, ⃗ey, ⃗ez} = {⃗e0, ⃗e1, ⃗e2, ⃗e3}.
(Note the use of subscripts. The reason for this convention will become clear below.)
The basis vector ⃗eα points along the xα coordinate direction, which is orthogonal to
all the other coordinate directions, and it has squared length −1 for α = 0 (vector
pointing in a timelike direction) and +1 for α = 1, 2, 3 (spacelike):
⃗eα . ⃗eβ = ηαβ.
(2.21)
Here ηαβ (a spacetime analog of the Kronecker delta) are deﬁned by
η00 ≡−1,
η11 ≡η22 ≡η33 ≡1,
ηαβ ≡0 if α ̸= β.
(2.22)
Any basis in which ⃗eα . ⃗eβ = ηαβ is said to be orthonormal (by analogy with the
Euclidean notion of orthonormality, ej . ek = δjk).
Because ⃗eα . ⃗eβ ̸= δαβ, manyoftheEuclidean-spacecomponent-manipulationfor-
mulas (1.9b)–(1.9h) do not hold in Minkowski spacetime. There are two approaches
to recovering these formulas. One approach, used in many older textbooks (including
the ﬁrst and second editions of Goldstein’s Classical Mechanics and Jackson’s Classi-
cal Electrodynamics), is to set x0 = it, where i = √−1and correspondingly make the
time basis vector be imaginary, so that ⃗eα . ⃗eβ = δαβ. When this approach is adopted,
the resulting formalism does not depend on whether indices are placed up or down;
onecanplacethemwhereverone’sstomachorliverdictateswithoutaskingone’sbrain.
However, this x0 = it approach has severe disadvantages: (i) it hides the true phys-
ical geometry of Minkowski spacetime, (ii) it cannot be extended in any reasonable
manner to nonorthonormal bases in ﬂat spacetime, and (iii) it cannot be extended
in any reasonable manner to the curvilinear coordinates that must be used in gen-
eral relativity. For these reasons, most modern texts (including the third editions of
Goldstein and Jackson) take an alternative approach, one always used in general rela-
tivity. This alternative, which we shall adopt, requires introducing two different types
of components for vectors (and analogously for tensors): contravariant components
denoted by superscripts (e.g., T αβγ) and covariant components denoted by subscripts
(e.g., Tαβγ). In Parts I–VI of this book, we introduce these components only for or-
thonormal bases; in Part VII, we develop a more sophisticated version of them, valid
for nonorthonormal bases.
2.5.2
2.5.2 Index Gymnastics
contravariant components
A vector’s or tensor’s contravariant components are deﬁned as its expansion coefﬁ-
cients in the chosen basis [analogs of Eqs. (1.9b) and (1.9d) in Euclidean 3-space]:
54
Chapter 2. Special Relativity: Geometric Viewpoint

⃗A ≡Aα⃗eα,
TTT ≡T αβγ ⃗eα ⊗⃗eβ ⊗⃗eγ .
(2.23a)
Here and throughout this book, Greek (spacetime) indices are to be summed when they
are repeated with one up and the other down; this is called the Einstein summation
convention.
covariant components
The covariant components are deﬁned as the numbers produced by evaluating the
vector or tensor on its basis vectors [analog of Eq. (1.9e) in Euclidean 3-space]:
Aα ≡⃗A(⃗eα) = ⃗A . ⃗eα,
Tαβγ ≡TTT(⃗eα, ⃗eβ, ⃗eγ).
(2.23b)
(Just as there are contravariant and covariant components Aα and Aα, so also there is
a second set of basis vectors ⃗eα dual to the set ⃗eα. However, for economy of notation
we delay introducing them until Part VII.)
These deﬁnitions have a number of important consequences. We derive them one
after another and then summarize them succinctly with equation numbers:
(i) The covariant components of the metric tensor are gαβ = ggg(⃗eα, ⃗eβ) =
⃗eα . ⃗eβ = ηαβ. Here the ﬁrst equality is the deﬁnition (2.23b) of the covari-
ant components, the second equality is the deﬁnition (2.6) of the metric
tensor, and the third equality is the orthonormality relation (2.21) for the
basis vectors.
(ii) The covariant components of any tensor can be computed from the contra-
variant components by
Tλμν = TTT(⃗eλ, ⃗eμ, ⃗eν) = T αβγ ⃗eα ⊗⃗eβ ⊗⃗eγ(⃗eλ, ⃗eμ, ⃗eν)
= T αβγ(⃗eα . ⃗eλ)(⃗eβ . ⃗eμ)(⃗eγ . ⃗eν) = T αβγ gαλgβμgγ ν.
The ﬁrst equality is the deﬁnition (2.23b) of the covariant components, the
second is the expansion (2.23a) of TTT on the chosen basis, the third is the
deﬁnition (1.5a) of the tensor product, and the fourth is one version of our
result (i) for the covariant components of the metric.
raising and lowering
indices:signﬂipiftemporal
(iii) This result, Tλμν = T αβγ gαλgβμgγ ν, together with the numerical values (i)
of gαβ, implies that when one lowers a spatial index there is no change in the
numerical value of a component, and when one lowers a temporal index,
the sign changes: Tijk = T ijk, T0jk = −T 0jk, T0j0 = +T 0j0, T000 = −T 000.
We call this the “sign-ﬂip-if-temporal” rule. As a special case, −1 = g00 =
components of metric
tensor
g00, 0 = g0j = −g0j, δjk = gjk = gjk—that is, the metric’s covariant and
contravariant components are numerically identical; they are both equal to
the orthonormality values ηαβ.
(iv) It is easy to see that this sign-ﬂip-if-temporal rule for lowering indices
implies the same sign-ﬂip-if-temporal rule for raising them, which in turn
can be written in terms of metric components as T αβγ = Tλμνgλαgμβgνγ.
mixed components
(v) It is convenient to deﬁne mixed components of a tensor, components with
some indices up and others down, as having numerical values obtained
2.5 Component Representation of Tensor Algebra
55

by raising or lowering some but not all of its indices using the metric,
for example, T αμν = T αβγ gβμgγ ν = Tλμνgλα. Numerically, this continues
to follow the sign-ﬂip-if-temporal rule: T 00k = −T 00k, T 0jk = T 0jk, and
it implies, in particular, that the mixed components of the metric are
gαβ = δαβ (the Kronecker-delta values; +1 if α = β and 0 otherwise).
summary of index
gymnastics
These important results can be summarized as follows. The numerical values of the
components of the metric in Minkowski spacetime are expressed in terms of the matrices
[δαβ]and [ηαβ]as
gαβ = ηαβ,
gα
β = δαβ,
gα
β = δαβ,
gαβ = ηαβ;
(2.23c)
indices on all vectors and tensors can be raised and lowered using these components of
the metric:
Aα = gαβAβ,
Aα = gαβAβ,
T α
μν ≡gμβgνγT αβγ ,
T αβγ ≡gβμgγ νT α
μν,
(2.23d)
which is equivalent to the sign-ﬂip-if-temporal rule.
This index notation gives rise to formulas for tensor products, inner products,
values of tensors on vectors, and tensor contractions that are obvious analogs of those
in Euclidean space:
[Contravariant components of TTT(
,
,
) ⊗SSS(
,
)]= T αβγSδϵ,
(2.23e)
⃗A . ⃗B = AαBα = AαBα,
TTT(A, B, C) = TαβγAαBβCγ = T αβγAαBβCγ ,
(2.23f)
Covariant components of [1&3contraction of RRR] = Rμ
αμβ,
Contravariant components of [1&3contraction of RRR] = Rμα
μ
β.
(2.23g)
Notice the very simple pattern in Eqs. (2.23b) and (2.23d), which universally
permeates the rules of index gymnastics, a pattern that permits one to reconstruct the
rules without any memorization: Free indices (indices not summed over) must agree
in position (up versus down) on the two sides of each equation. In keeping with this
pattern, one can regard the two indices in a pair that is summed as “annihilating each
other by contraction,” and one speaks of “lining up the indices” on the two sides of an
equation to get them to agree. These rules provide helpful checks when performing
calculations.
In Part VII, when we use nonorthonormal bases, all these index-notation equa-
tions (2.23) will remain valid except for the numerical values [Eq. (2.23c)] of the
metric components and the sign-ﬂip-if-temporal rule.
2.5.3
2.5.3 Slot-Naming Notation
InMinkowskispacetime, asinEuclideanspace, wecan(andoftendo)useslot-naming
index notation to represent frame-independent geometric objects and equations and
56
Chapter 2. Special Relativity: Geometric Viewpoint

physical laws. (Readers who have not studied Sec. 1.5.1 on slot-naming index notation
should do so now.)
For example, we often write the frame-independent Lorentz force law d ⃗p/dτ =
qFFF(
, ⃗u) [Eq. (2.20)] as dpμ/dτ = qFμνuν.
Notice that, because the components of the metric in any Lorentz basis are gαβ =
ηαβ, we can write the invariant interval between two events xα and xα + dxα as
ds2 = gαβdxαdxβ = −dt2 + dx2 + dy2 + dz2.
(2.24)
This is called the special relativistic line element.
line element
EXERCISES
Exercise 2.5 Derivation: Component Manipulation Rules
Derive the relativistic component manipulation rules (2.23e)–(2.23g).
Exercise 2.6 Practice: Numerics of Component Manipulations
In some inertial reference frame, the vector ⃗A and second-rank tensor TTT have as
their only nonzero components A0 = 1, A1 = 2; T 00 = 3, T 01 = T 10 = 2, T 11 = −1.
Evaluate TTT( ⃗A, ⃗A) and the components of TTT( ⃗A,
) and ⃗A ⊗TTT.
Exercise 2.7 Practice: Meaning of Slot-Naming Index Notation
(a) Convert the following expressions and equations into geometric, index-free no-
tation: AαBγ δ; AαBγ
δ; Sα
βγ = Sγβα; AαBα = AαBβgαβ.
(b) Convert TTT(
, SSS(RRR( ⃗C,
),
),
) into slot-naming index notation.
Exercise 2.8 Practice: Index Gymnastics
(a) Simplify the following expression so the metric does not appear in it:
Aαβγ gβρSγ λgρδgλ
α.
(b) The quantity gαβgαβ is a scalar since it has no free indices. What is its numerical
value?
(c) What is wrong with the following expression and equation?
Aα
βγSαγ;
Aα
βγSβTγ = RαβδSβ.
2.6
2.6 Particle Kinetics in Index Notation and in a Lorentz Frame
As an illustration of the component representation of tensor algebra, let us return
to the relativistic, accelerated particle of Fig. 2.3 and, from the frame-independent
equations for the particle’s 4-velocity ⃗u and 4-momentum ⃗p (Sec. 2.4), derive the
component description given in elementary textbooks.
We introduce a speciﬁc inertial reference frame and associated Lorentz co-
ordinates xα and basis vectors {⃗eα}. In this Lorentz frame, the particle’s world line
2.6 Particle Kinetics in Index Notation and in a Lorentz Frame
57

⃗x(τ) is represented by its coordinate location xα(τ) as a function of its proper time
τ. The contravariant components of the separation vector d ⃗x between two neigh-
boring events along the particle’s world line are the events’ coordinate separations
dxα [Eq. (2.1)]; and correspondingly, the components of the particle’s 4-velocity
⃗u = d ⃗x/dτ are
uα = dxα/dτ
(2.25a)
(the time derivatives of the particle’s spacetime coordinates). Note that Eq. (2.25a)
implies
vj ≡dxj
dt = dxj/dτ
dt/dτ = uj
u0 .
(2.25b)
This relation, together with −1 = ⃗u2 = gαβuαuβ = −(u0)2 + δijuiuj = −(u0)2(1 −
δijvivj), implies that the components of the 4-velocity have the forms familiar from
elementary textbooks:
u0 = γ ,
uj = γ vj,
where
γ =
1
(1 −δijvivj)
1
2
.
(2.25c)
ordinary velocity
It is useful to think of vj as the components of a 3-dimensional vector v, the
ordinary velocity, that lives in the 3-dimensional Euclidean space t = const of the
chosen Lorentz frame (the green plane in Fig. 2.5). This 3-space is sometimes called
slice of simultaneity
the frame’s slice of simultaneity or 3-space of simultaneity, because all events lying in
it are simultaneous, as measured by the frame’s observers. This 3-space is not well
deﬁned until a Lorentz frame has been chosen, and correspondingly, v relies for its
existence on a speciﬁc choice of frame. However, once the frame has been chosen,
v can be regarded as a coordinate-independent, basis-independent 3-vector lying in
the frame’s slice of simultaneity. Similarly, the spatial part of the 4-velocity ⃗u (the part
with components uj in our chosen frame) can be regarded as a 3-vector u lying in the
frame’s 3-space; and Eqs. (2.25c) become the component versions of the coordinate-
independent, basis-independent 3-space relations
u = γ v ,
γ =
1
√
1 −v2 ,
(2.25d)
where v2 = v . v. This γ is called the “Lorentz factor.”
The components of the particle’s 4-momentum ⃗p in our chosen Lorentz frame
have special names and special physical signiﬁcances: The time component of the
4-momentum is the particle’s (relativistic) energy E as measured in that frame:
relativistic energy
E ≡p0 = mu0 = mγ =
m
√
1 −v2 = (the particle’s energy)
≃m + 1
2mv2
for |v| ≪1.
(2.26a)
58
Chapter 2. Special Relativity: Geometric Viewpoint

t
u
v = u/γ
world line
y
→u
x
FIGURE 2.5 Spacetime diagram in a speciﬁc Lorentz frame, showing the frame’s
3-space t = 0 (green region), the world line of a particle, the 4-velocity ⃗u of
the particle as it passes through the 3-space, and two 3-dimensional vectors
that lie in the 3-space: the spatial part u of the particle’s 4-velocity and the
particle’s ordinary velocity v.
Note that this energy is the sum of the particle’s rest mass-energy m = mc2 and its
kinetic energy
rest mass-energy
kinetic energy
E ≡E −m = m

1
√
1 −v2 −1

≃1
2mv2
for |v| ≪1.
(2.26b)
The spatial components of the 4-momentum, when regarded from the viewpoint of
momentum
3-dimensional physics, are the same as the components of the momentum, a 3-vector
residing in the chosen Lorentz frame’s 3-space:
pj = muj = mγ vj =
mvj
√
1 −v2 = Evj
= (j component of particle’s momentum);
(2.26c)
or, in basis-independent, 3-dimensional vector notation,
p = mu = mγ v =
mv
√
1 −v2 = Ev = (particle’s momentum).
(2.26d)
For a zero-rest-mass particle, as for one with ﬁnite rest mass, we identify the time
component of the 4-momentum, in a chosen Lorentz frame, as the particle’s energy,
2.6 Particle Kinetics in Index Notation and in a Lorentz Frame
59

and the spatial part as its momentum. Moreover, if—appealing to quantum theory—
we regard a zero-rest-mass particle as a quantum associated with a monochromatic
wave, then quantum theory tells us that the wave’s angular frequency ω as measured
in a chosen Lorentz frame is related to its energy by
E ≡p0 = ℏω = (particle’s energy);
(2.27a)
and, since the particle has ⃗p2 = −(p0)2 + p2 = −m2 = 0 (in accord with the lightlike
nature of its world line), its momentum as measured in the chosen Lorentz frame is
p = En = ℏωn.
(2.27b)
Here n is the unit 3-vector that points in the direction of the particle’s travel, as
measured in the chosen frame; that is (since the particle moves at the speed of light
v = 1), n is the particle’s ordinary velocity. Eqs. (2.27a) and (2.27b) are respectively
the temporal and spatial components of the geometric, frame-independent relation
⃗p = ℏ⃗k [Eq. (2.13), which is valid for zero-rest-mass particles as well as ﬁnite-mass
ones].
3+1 split of spacetime into
space plus time
The introduction of a speciﬁc Lorentz frame into spacetime can be said to produce
a 3+1 split of every 4-vector into a 3-dimensional vector plus a scalar (a real number).
The 3+1 split of a particle’s 4-momentum ⃗p produces its momentum p plus its energy
E = p0. Correspondingly, the 3+1 split of the law of 4-momentum conservation (2.15)
produces a law of conservation of momentum plus a law of conservation of energy:
 
¯A
p ¯A =
 
A
pA,
 
¯A
E ¯A =
 
A
EA.
(2.28)
The unbarred quantities in Eqs. (2.28) are momenta and energies of the particles
entering the interaction region, and the barred quantities are those of the particles
leaving (see Fig. 2.4).
Because the concept of energy does not even exist until one has chosen a Lorentz
frame—and neither does that of momentum—the laws of energy conservation and
momentum conservation separately are frame-dependent laws. In this sense, they
are far less fundamental than their combination, the frame-independent law of 4-
momentum conservation.
By learning to think about the 3+1 split in a geometric, frame-independent way,
one can gain conceptual and computational power. As an example, consider a particle
with4-momentum ⃗p, beingstudiedbyanobserverwith4-velocity ⃗U.Intheobserver’s
own Lorentz reference frame, her 4-velocity has components U0 = 1 and Uj = 0,
and therefore, her 4-velocity is ⃗U = Uα⃗eα = ⃗e0; that is, it is identically equal to the
time basis vector of her Lorentz frame. Thus the particle energy that she measures is
E = p0 = −p0 = −⃗p . ⃗e0 = −⃗p . ⃗U. This equation, derived in the observer’s Lorentz
frame, is actually a geometric, frame-independent relation: the inner product of two
4-vectors. It says that when an observer with 4-velocity ⃗U measures the energy of a
60
Chapter 2. Special Relativity: Geometric Viewpoint

particle with 4-momentum ⃗p, the result she gets (the time part of the 3+1 split of ⃗p as
seen by her) is
E = −⃗p . ⃗U.
(2.29)
We shall use this equation in later chapters. In Exs. 2.9 and 2.10, the reader can
gain experience deriving and interpreting other frame-independent equations for 3+1
splits. Exercise 2.11 exhibits the power of this geometric way of thinking by using it
to derive the Doppler shift of a photon.
EXERCISES
Exercise 2.9 **Practice: Frame-Independent Expressions for Energy, Momentum,
and Velocity
Anobserverwith4-velocity ⃗U measuresthepropertiesofaparticlewith4-momentum
⃗p. The energy she measures is E = −⃗p . ⃗U [Eq. (2.29)].
(a) Show that the particle’s rest mass can be expressed in terms of ⃗p as
m2 = −⃗p2.
(2.30a)
(b) Show that the momentum the observer measures has the magnitude
|p| = [( ⃗p . ⃗U)2 + ⃗p . ⃗p]
1
2 .
(2.30b)
(c) Show that the ordinary velocity the observer measures has the magnitude
|v| = |p|
E ,
(2.30c)
where |p| and E are given by the above frame-independent expressions.
(d) Show that the ordinary velocity v, thought of as a 4-vector that happens to lie in
the observer’s slice of simultaneity, is given by
⃗v = ⃗p + ( ⃗p . ⃗U) ⃗U
−⃗p . ⃗U
.
(2.30d)
Exercise 2.10 **Example: 3-Metric as a Projection Tensor
Consider, as in Ex. 2.9, an observer with 4-velocity ⃗U who measures the properties of
a particle with 4-momentum ⃗p.
(a) Show that the Euclidean metric of the observer’s 3-space, when thought of as a
tensor in 4-dimensional spacetime, has the form
PPP ≡ggg + ⃗U ⊗⃗U.
(2.31a)
Show, further, that if ⃗A is an arbitrary vector in spacetime, then −⃗A . ⃗U is the
component of ⃗A along the observer’s 4-velocity ⃗U, and
PPP(
, ⃗A) = ⃗A + ( ⃗A . ⃗U) ⃗U
(2.31b)
2.6 Particle Kinetics in Index Notation and in a Lorentz Frame
61

is the projection of ⃗A into the observer’s 3-space (i.e., it is the spatial part of
⃗A as seen by the observer). For this reason, PPP is called a projection tensor. In
quantum mechanics, the concept of a projection operator ˆP is introduced as
one that satisﬁes the equation ˆP 2 = ˆP. Show that the projection tensor PPP is a
projection operator in the same sense:
PαμP μ
β = Pαβ.
(2.31c)
(b) Show that Eq. (2.30d) for the particle’s ordinary velocity, thought of as a 4-vector,
can be rewritten as
⃗v = PPP(
, ⃗p)
−⃗p . ⃗U
.
(2.32)
Exercise 2.11 **Example: Doppler Shift Derived without Lorentz Transformations
(a) An observer at rest in some inertial frame receives a photon that was emitted in
direction n by an atom moving with ordinary velocity v (Fig. 2.6). The photon
frequency and energy as measured by the emitting atom are νem and Eem; those
measured by the receiving observer are νrec and Erec. By a calculation carried out
solely in the receiver’s inertial frame (the frame of Fig. 2.6), and without the aid of
any Lorentz transformation, derive the standard formula for the photon’s Doppler
shift:
νrec
νem
=
√
1 −v2
1 −v . n .
(2.33)
[Hint: Use Eq. (2.29) to evaluate Eem using receiver-frame expressions for the
emitting atom’s 4-velocity ⃗U and the photon’s 4-momentum ⃗p.]
(b) Suppose that instead of emitting a photon, the emitter produces a particle with
ﬁnite rest mass m. Using the same method as in part (a), derive an expression
for the ratio of received energy to emitted energy, Erec/Eem, expressed in terms
of the emitter’s ordinary velocity v and the particle’s ordinary velocity V (both as
measured in the receiver’s frame).
v
n
receiver
emitter
FIGURE 2.6 Geometry for Doppler shift, drawn in a slice
of simultaneity of the receiver’s inertial frame.
62
Chapter 2. Special Relativity: Geometric Viewpoint

2.7
2.7 Lorentz Transformations
Consider two different inertial reference frames in Minkowski spacetime. Denote
their Lorentz coordinates by {xα} and {x ¯μ} and their bases by {eα} and {e ¯μ}, respec-
tively, and write the transformation from one basis to the other as
⃗eα = ⃗e ¯μL ¯μ
α,
⃗e ¯μ = ⃗eαLα
¯μ.
(2.34)
As in Euclidean 3-space (the rotation matrices of Sec 1.6), L ¯μα and Lα ¯μ are elements
transformation matrix
of two different transformation matrices, and since these matrices operate in opposite
directions, they must be the inverse of each other:
L ¯μ
αLα
¯ν = δ ¯μ
¯ν,
Lα
¯μL ¯μ
β = δα
β.
(2.35a)
Notice the up/down placement of indices on the elements of the transformation
matrices: the ﬁrst index is always up, and the second is always down. This is just a
convenient convention, which helps systematize the index shufﬂing rules in a way that
can easily be remembered. Our rules about summing on the same index when up and
down, and matching unsummed indices on the two sides of an equation automatically
dictate the matrix to use in each of the transformations (2.34); and similarly for all
other equations in this section.
In Euclidean 3-space the orthonormality of the two bases dictates that the trans-
formations must be orthogonal (i.e., must be reﬂections or rotations). In Minkowski
spacetime, orthonormality implies gαβ = ⃗eα . ⃗eβ = (⃗e ¯μL ¯μα) . (⃗e¯νL¯νβ) = L ¯μαL¯νβg ¯μ¯ν;
that is,
g ¯μ¯νL ¯μ
αL¯ν
β = gαβ,
and similarly,
gαβLα
¯μLβ
¯ν = g ¯μ¯ν.
(2.35b)
Any matrix whose elements satisfy these equations is a Lorentz transformation.
Lorentz transformation
From the fact that vectors and tensors are geometric, frame-independent objects,
one can derive the Minkowski-space analogs of the Euclidean transformation laws for
components (1.13a) and (1.13b):
A ¯μ = L ¯μ
αAα,
T ¯μ¯ν ¯ρ = L ¯μ
αL¯ν
βL ¯ρ
γT αβγ ,
(2.36a)
and similarly in the opposite direction. Notice that here, as elsewhere, these equations
can be constructed by lining up indices in accord with our standard rules.
If (as is conventional) we choose the spacetime origins of the two Lorentz coordi-
nate systems to coincide, then the vector ⃗x extending from the origin to some event
P, whose coordinates are xα and x ¯α, has components equal to those coordinates. As
a result, the transformation law for the coordinates takes the same form as Eq. (2.36a)
for the components of a vector:
xα = Lα
¯μx ¯μ,
x ¯μ = L ¯μ
αxα.
(2.36b)
2.7 Lorentz Transformations
63

The product Lα ¯μL ¯μ ¯¯ρ of two Lorentz transformation matrices is a Lorentz trans-
formation matrix. Under this product rule, the Lorentz transformations form a math-
Lorentz group
ematical group, the Lorentz group, whose representations play an important role in
quantum ﬁeld theory (cf. the rotation group in Sec. 1.6).
An important speciﬁc example of a Lorentz transformation is:

Lα
¯μ

=
⎡
⎢⎢⎢⎢⎣
γ
βγ
0
0
βγ
γ
0
0
0
0
1
0
0
0
0
1
⎤
⎥⎥⎥⎥⎦
,

L ¯μ
α

=
⎡
⎢⎢⎢⎢⎣
γ
−βγ
0
0
−βγ
γ
0
0
0
0
1
0
0
0
0
1
⎤
⎥⎥⎥⎥⎦
,
(2.37a)
where β and γ are related by
|β| < 1 ,
γ ≡(1 −β2)−1
2 .
(2.37b)
[Notice that γ is the Lorentz factor associated with β; cf. Eq. (2.25d).]
Lorentz boost
One can readily verify (Ex. 2.12) that these matrices are the inverses of each other
and that they satisfy the Lorentz-transformation relation (2.35b). These transforma-
tion matrices produce the following change of coordinates [Eq. (2.36b)]:
t = γ (¯t + β ¯x) ,
x = γ (¯x + β¯t) ,
y = ¯y ,
z = ¯z,
¯t = γ (t −βx) ,
¯x = γ (x −βt) ,
¯y = y ,
¯z = z.
(2.37c)
These expressions reveal that any particle at rest in the unbarred frame (a particle
with ﬁxed, time-independent x, y, z) is seen in the barred frame to move along the
world line ¯x = const −β¯t, ¯y = const, ¯z = const. In other words, the unbarred frame is
seen by observers at rest in the barred frame to move with uniform velocity v = −βe¯x,
and correspondingly the barred frame is seen by observers at rest in the unbarred
frame to move with the opposite uniform velocity v = +βex. This special Lorentz
transformation is called a pure boost along the x direction.
EXERCISES
Exercise 2.12 Derivation: Lorentz Boosts
Show that the matrices (2.37a), with β and γ satisfying Eq. (2.37b), are the inverses
of each other, and that they obey the condition (2.35b) for a Lorentz transformation.
Exercise 2.13 Example: General Boosts and Rotations
(a) Show that, if nj is a 3-dimensional unit vector and β and γ are deﬁned as
in Eq. (2.37b), then the following is a Lorentz transformation [i.e., it satisﬁes
Eq. (2.35b)]:
L0¯0 = γ ,
L0 ¯j = Lj ¯0 = βγ nj ,
Lj ¯k = Lk ¯j = (γ −1)njnk + δjk. (2.38)
Show, further, that this transformation is a pure boost along the direction n with
speed β, and show that the inverse matrix L ¯μα for this boost is the same as Lα ¯μ,
but with β changed to −β.
64
Chapter 2. Special Relativity: Geometric Viewpoint

(b) Show that the following is also a Lorentz transformation:
"
Lα
¯μ
#
=
⎡
⎢⎢⎢⎢⎣
1
0
0
0
0
0
[Ri ¯j]
0
⎤
⎥⎥⎥⎥⎦
,
(2.39)
where [Ri ¯j] is a 3-dimensional rotation matrix for Euclidean 3-space. Show,
further, that this Lorentz transformation rotates the inertial frame’s spatial axes
(its latticework of measuring rods) while leaving the frame’s velocity unchanged
(i.e., the new frame is at rest with respect to the old).
One can show (not surprisingly) that the general Lorentz transformation [i.e., the
general solution of Eqs. (2.35b)] can be expressed as a sequence of pure boosts, pure
rotations, and pure inversions (in which one or more of the coordinate axes are
reﬂected through the origin, so xα = −x ¯α).
2.8
2.8 Spacetime Diagrams for Boosts
Figure 2.7 illustrates the pure boost (2.37c). Panel a in that ﬁgure is a 2-dimensional
spacetime diagram, with the y- and z-coordinates suppressed, showing the ¯t- and
¯x-axes of the boosted Lorentz frame F in the t, x Lorentz coordinate system of the
unboosted frame F. That the barred axes make angles tan−1 β with the unbarred
axes, as shown, can be inferred from the Lorentz transformation (2.37c). Note that
the orthogonality of the ¯t- and ¯x-axes to each other (⃗e¯t . ⃗e¯x = 0) shows up as the two
axes making the same angle π/2 −β with the null line x = t. The invariance of the
interval guarantees that, as shown for a = 1 or 2 in Fig. 2.7a, the event ¯x = a on the
¯x-axis lies at the intersection of that axis with the dashed hyperbola x2 −t2 = a2; and
similarly, the event ¯t = a on the ¯t-axis lies at the intersection of that axis with the
dashed hyperbola t2 −x2 = a2.
→u–
→u
x–
t–
t
simultaneous
3-space in F
simultaneous
3-space in F–
tan–1β
tan–1β
1
2
2
1
1
2
2
1
(a)
(b)
(c)
x
x–
x–
t–
t
P
x
x
t–
t
FIGURE 2.7 Spacetime diagrams illustrating the pure boost (2.37c) from one Lorentz reference frame
to another.
2.8 Spacetime Diagrams for Boosts
65

As shown in Fig. 2.7b, the barred coordinates {¯t, ¯x} of an event P can be inferred
by projecting from P onto the ¯t- and ¯x-axes, with the projection parallel to the ¯x-
and ¯t-axes, respectively. Figure 2.7c shows the 4-velocity ⃗u of an observer at rest in
frame F and that, ¯⃗u, of an observer at rest in frame F. The events that observer F
regards as all simultaneous, with time t = 0, lie in a 3-space that is orthogonal to ⃗u and
includes the x-axis. This is a slice of simultaneity of reference frame F. Similarly, the
events that observer F regards as all simultaneous, with ¯t = 0, live in the 3-space that
is orthogonal to ¯⃗u and includes the ¯x-axis (i.e., in a slice of simultaneity of frame F).
length contraction, time
dilation, and breakdown of
simultaneity
Exercise 2.14 uses spacetime diagrams similar to those in Fig. 2.7 to deduce a num-
ber of important relativistic phenomena, including the contraction of the length of a
moving object (length contraction), the breakdown of simultaneity as a universally
agreed-on concept, and the dilation of the ticking rate of a moving clock (time dila-
tion). This exercise is extremely important; every reader who is not already familiar
with it should study it.
EXERCISES
Exercise 2.14 **Example: Spacetime Diagrams
Use spacetime diagrams to prove the following:
(a) Two events that are simultaneous in one inertial frame are not necessarily simul-
taneous in another. More speciﬁcally, if frame F moves with velocity ⃗v = β⃗ex as
seen in frame F, where β > 0, then of two events that are simultaneous in F the
one farther “back” (with the more negative value of ¯x) will occur in F before the
one farther “forward.”
(b) Two events that occur at the same spatial location in one inertial frame do not
necessarily occur at the same spatial location in another.
(c) If P1and P2 are two events with a timelike separation, then there exists an inertial
reference frame in which they occur at the same spatial location, and in that frame
the time lapse between them is equal to the square root of the negative of their
invariant interval, t = τ ≡

−(s)2.
(d) IfP1andP2 aretwoeventswithaspacelikeseparation, thenthereexistsaninertial
reference frame in which they are simultaneous, and in that frame the spatial
distance between them is equal to the square root of their invariant interval,

gijxixj = s ≡

(s)2.
(e) If the inertial frame F moves with speed β relative to the frame F, then a clock
at rest in F ticks more slowly as viewed from F than as viewed from F—more
slowly by a factor γ −1 = (1 −β2)
1
2. This is called relativistic time dilation. As
one consequence, the lifetimes of unstable particles moving with speed β are
increased by the Lorentz factor γ .
(f) If the inertial frame F moves with velocity ⃗v = β⃗ex relative to the frame F,
then an object at rest in F as studied in F appears shortened by a factor γ −1 =
(1 −β2)
1
2 along the x direction, but its length along the y and z directions
66
Chapter 2. Special Relativity: Geometric Viewpoint

is unchanged. This is called Lorentz contraction. As one consequence, heavy
ions moving at high speeds in a particle accelerator appear to act like pancakes,
squashed along their directions of motion.
Exercise 2.15 Problem: Allowed and Forbidden Electron-Photon Reactions
Show, using spacetime diagrams and also using frame-independent calculations, that
the law of conservation of 4-momentum forbids a photon to be absorbed by an
electron, e + γ →e, and also forbids an electron and a positron to annihilate and
produceasinglephoton, e+ + e−→γ (intheabsenceofanyotherparticlestotakeup
some of the 4-momentum); but the annihilation to form two photons, e+ + e−→2γ ,
is permitted.
2.9
2.9 Time Travel
2.9.1
2.9.1 Measurement of Time; Twins Paradox
Time dilation is one facet of a more general phenomenon: time, as measured by
ideal clocks, is a personal thing, different for different observers who move through
twins paradox
spacetime on different world lines. This is well illustrated by the infamous “twins
paradox,” in which one twin, Methuselah, remains forever at rest in an inertial frame
and the other, Florence, makes a spacecraft journey at high speed and then returns to
rest beside Methuselah.
The twins’ world lines are depicted in Fig. 2.8a, a spacetime diagram whose axes
are those of Methuselah’s inertial frame. The time measured by an ideal clock that
Methuselah carries is the coordinate time t of his inertial frame; and its total time
lapse, from Florence’s departure to her return, is treturn −tdeparture ≡TMethuselah. By
contrast, the time measured by an ideal clock that Florence carries is her proper time
τ (i.e., the square root of the invariant interval (2.4) along her world line). Thus her
total time lapse from departure to return is
TFlorence =

dτ =
 
dt2 −δijdxidxj =
 TMethuselah
0

1 −v2 dt.
(2.40)
Here (t, xi) are the time and space coordinates of Methuselah’s inertial frame, and v is
Florence’s ordinary speed, v =

δij(dxi/dt)(dxj/dt), as measured in Methuselah’s
frame. Obviously, Eq. (2.40) predicts that TFlorence is less than TMethuselah. In fact
(Ex. 2.16), even if Florence’s acceleration is kept no larger than one Earth gravity
throughout her trip, and her trip lasts only TFlorence = (a few tens of years), TMethuselah
can be hundreds or thousands or millions or billions of years.
Does this mean that Methuselah actually “experiences” a far longer time lapse,
and actually ages far more than Florence? Yes! The time experienced by humans and
the aging of the human body are governed by chemical processes, which in turn are
governed by the natural oscillation rates of molecules, rates that are constant to high
accuracy when measured in terms of ideal time (or, equivalently, proper time τ).
2.9 Time Travel
67

t
τ = 1
τ = 1
11
10
9
8
7
6
5
4
3
2
0
τc = 1
11
10
9
8
7
6
5
4
3
2
0
0
2
3
4
5
6
7
τc = 1
0
2
3
4
5
6
7
(a)
Florence
Methuselah
(b)
x
t
x
FIGURE2.8 (a) Spacetime diagram depicting the so-called “twins paradox.” Marked along the two world
lines are intervals of proper time as measured by the two twins. (b) Spacetime diagram depicting the
motions of the two mouths of a wormhole. Marked along the mouths’ world tubes are intervals of
proper time τc as measured by the single clock that sits in the common mouths.
Therefore, a human’s experiential time and aging time are the same as the human’s
proper time—so long as the human is not subjected to such high accelerations as to
damage her body.
In effect, then, Florence’s spacecraft has functioned as a time machine to carry
her far into Methuselah’s future, with only a modest lapse of her own proper time
(i.e., ideal, experiential, or aging time). This may be a “paradox” in the sense that it
is surprising. However, it is in no sense a contradiction. This type of time dilation is
routinely measured in high-energy physics storage rings.
2.9.2
2.9.2 Wormholes
Is it also possible, at least in principle, for Florence to construct a time machine that
carries her into Methuselah’s past—and also her own past? At ﬁrst sight, the answer
would seem to be “yes.” Figure 2.8b shows one possible method, using a wormhole.
[See Frolov and Novikov (1990), Friedman and Higuchi (2006), Everett and Roman
(2011) for other approaches.]
wormhole
Wormholes are hypothetical handles in the topology of space. A simple model of a
wormhole can be obtained by taking a ﬂat 3-dimensional space, removing from it the
interiors of two identical spheres, and identifying the spheres’ surfaces so that if one
enters the surface of one of the spheres, one immediately ﬁnds oneself exiting through
the surface of the other. When this is done, there is a bit of strongly localized spatial
curvature at the spheres’ common surface, so to analyze such a wormhole properly,
one must use general relativity rather than special relativity. In particular, it is the
laws of general relativity, combined with the laws of quantum ﬁeld theory, that tell
68
Chapter 2. Special Relativity: Geometric Viewpoint

one how to construct such a wormhole and what kinds of materials are required to
hold it open, so things can pass through it. Unfortunately, despite considerable effort,
theoretical physicists have not yet deduced deﬁnitively whether those laws permit
such wormholes to exist and stay open, though indications are pessimistic (Everett
andRoman, 2011; FriedmanandHiguchi, 2006).However, assumingsuchwormholes
can exist, the following special relativistic analysis (Morris et al., 1988) shows how one
might be used to construct a machine for backward time travel.
2.9.3
2.9.3 Wormhole as Time Machine
The two identiﬁed spherical surfaces are called the wormhole’s mouths. Ask Methuse-
world tube
lah to keep one mouth with him, forever at rest in his inertial frame, and ask Florence
to take the other mouth with her on her high-speed journey. The two mouths’ world
tubes (analogs of world lines for a 3-dimensional object) then have the forms shown
in Fig. 2.8b. Suppose that a single ideal clock sits in the wormhole’s identiﬁed mouths,
so that from the external universe one sees it both in Methuselah’s wormhole mouth
and in Florence’s. As seen in Methuselah’s mouth, the clock measures his proper time,
which is equal to the coordinate time t (see tick marks along the left world tube in
Fig. 2.8b). As seen in Florence’s mouth, the clock measures her proper time, Eq. (2.40)
(see tick marks along the right world tube in Fig. 2.8b). The result should be obvious,
if surprising: When Florence returns to rest beside Methuselah, the wormhole has
become a time machine. If she travels through the wormhole when the clock reads
τc = 7, she goes backward in time as seen in Methuselah’s (or anyone else’s) inertial
frame; and then, in fact, traveling along the everywhere timelike world line (dashed
in Fig. 2.8b), she is able to meet her younger self before she entered the wormhole.
This scenario is profoundly disturbing to most physicists because of the dangers
of science-ﬁction-type paradoxes (e.g., the older Florence might kill her younger self,
thereby preventing herself from making the trip through the wormhole and killing
herself). Fortunately perhaps, it seems likely (though far from certain) that vacuum
ﬂuctuations of quantum ﬁelds will destroy the wormhole at the moment its mouths’
motion ﬁrst makes backward time travel possible. It may be that this mechanism will
always prevent the construction of backward-travel time machines, no matter what
chronology protection
tools one uses for their construction (Kay et al., 1997; Kim and Thorne, 1991); but
see also contrary indications in research reviewed by Everett and Roman (2011) and
Friedman and Higuchi (2006). Whether this is so we likely will not know until the
laws of quantum gravity have been mastered.
EXERCISES
Exercise 2.16 Example: Twins Paradox
(a) The 4-acceleration of a particle or other object is deﬁned by ⃗a ≡d ⃗u/dτ, where ⃗u
is its 4-velocity and τ is proper time along its world line. Show that, if an observer
carries an accelerometer, the magnitude |a| of the 3-dimensional acceleration
a measured by the accelerometer will always be equal to the magnitude of the
observer’s 4-acceleration, |a| = |⃗a| ≡
√
⃗a . ⃗a.
2.9 Time Travel
69

(b) In the twins paradox of Fig. 2.8a, suppose that Florence begins at rest beside
Methuselah, then accelerates in Methuselah’s x-direction with an acceleration
a equal to one Earth gravity, g, for a time TFlorence/4 as measured by her, then
accelerates in the −x-direction at g for a time TFlorence/2, thereby reversing her
motion; thensheacceleratesinthe+x-directionatg foratimeTFlorence/4, thereby
returning to rest beside Methuselah. (This is the type of motion shown in the
ﬁgure.) Show that the total time lapse as measured by Methuselah is
TMethuselah = 4
g sinh
gTFlorence
4

.
(2.41)
(c) Show that in the geometrized units used here, Florence’s acceleration (equal to
acceleration of gravity at the surface of Earth) is g = 1.033/yr. Plot TMethuselah as a
function of TFlorence, and from your plot estimate TFlorence if TMethuselah is the age
of the Universe, 14 billion years.
Exercise 2.17 Challenge: Around the World on TWA
In a long-ago era when an airline named Trans World Airlines (TWA) ﬂew around
the world, Josef Hafele and Richard Keating (1972a) carried out a real live twins para-
dox experiment: They synchronized two atomic clocks and then ﬂew one around the
world eastward on TWA, and on a separate trip, around the world westward, while
the other clock remained at home at the Naval Research Laboratory near Washington,
D.C. When the clocks were compared after each trip, they were found to have aged
differently. Making reasonable estimates for the airplane routing and speeds, compute
the difference in aging, and compare your result with the experimental data in Hafele
and Keating (1972b). [Note: The rotation of Earth is important, as is the general rela-
tivistic gravitational redshift associated with the clocks’ altitudes; but the gravitational
redshift drops out of the difference in aging, if the time spent at high altitude is the
same eastward as westward.]
2.10
2.10 Directional Derivatives, Gradients, and the Levi-Civita Tensor
Derivatives of vectors and tensors in Minkowski spacetime are deﬁned in precisely
the same way as in Euclidean space; see Sec. 1.7. Any reader who has not studied that
section should do so now. In particular (in extreme brevity, as the explanations and
justiﬁcations are the same as in Euclidean space):
directional derivative
The directional derivative of a tensor
TTT
along a vector
⃗A is ∇⃗ATTT ≡
limϵ→0(1/ϵ)[TTT(⃗xP + ϵ ⃗A) −TTT(⃗xP)]; the gradient ⃗∇TTT is the tensor that produces the
gradient
directional derivative when one inserts ⃗A into its last slot: ∇⃗ATTT = ⃗∇TTT(
,
,
, ⃗A).
In slot-naming index notation (or in components on a basis), the gradient is de-
noted Tαβγ ;μ. In a Lorentz basis (the basis vectors associated with an inertial reference
frame), the components of the gradient are simply the partial derivatives of the tensor,
70
Chapter 2. Special Relativity: Geometric Viewpoint

Tαβγ ;μ = ∂Tαβγ/∂xμ ≡Tαβγ ,μ. (The comma means partial derivative in a Lorentz
basis, as in a Cartesian basis.)
The gradient and the directional derivative obey all the familiar rules for differen-
tiation of products, for example, ∇⃗A(SSS ⊗TTT) = (∇⃗ASSS) ⊗TTT + SSS ⊗∇⃗ATTT. The gradient
of the metric vanishes, gαβ;μ = 0. The divergence of a vector is the contraction of its
gradient, ⃗∇. ⃗A = Aα;βgαβ = Aα;α.
Recall that the divergence of the gradient of a tensor in Euclidean space is the
Laplacian:Tabc;jkgjk = Tabc,jkδjk = ∂2Tabc∂xj∂xj.Bycontrast, inMinkowskispace-
time, because g00 = −1 and gjk = δjk in a Lorentz frame, the divergence of the
d’Alembertian
gradient is the wave operator (also called the d’Alembertian):
Tαβγ ;μνgμν = Tαβγ ,μνgμν = −
∂2Tαβγ
∂t2
+
∂2Tαβγ
∂xj∂xk δjk =
Tαβγ .
(2.42)
When one sets this to zero, one gets the wave equation.
Levi-Civita tensor
As in Euclidean space, so also in Minkowski spacetime, there are two tensors
that embody the space’s geometry: the metric tensor ggg and the Levi-Civita tensor
ϵ. The Levi-Civita tensor in Minkowski spacetime is the tensor that is completely
antisymmetric in all its slots and has value ϵ( ⃗A, ⃗B, ⃗C, ⃗D) = +1 when evaluated
on any right-handed set of orthonormal 4-vectors—that is, by deﬁnition, any ortho-
normal set for which ⃗A is timelike and future directed, and { ⃗B, ⃗C, ⃗D} are spatial and
right-handed. This means that in any right-handed Lorentz basis, the only nonzero
components of ϵ are
ϵαβγ δ = +1 if α, β, γ , δ is an even permutation of 0, 1, 2, 3;
−1 if α, β, γ , δ is an odd permutation of 0, 1, 2, 3;
0 if α, β, γ , δ are not all different.
(2.43)
By the sign-ﬂip-if-temporal rule, ϵ0123 = +1 implies that ϵ0123 = −1.
2.11
2.11 Nature of Electric and Magnetic Fields; Maxwell’s Equations
Now that we have introduced the gradient and the Levi-Civita tensor, we can study
the relationship of the relativistic version of electrodynamics to the nonrelativistic
(Newtonian) version. In doing so, we use Gaussian units (with the speed of light set
to 1), as is conventional among relativity theorists, and as does Jackson (1998) in his
classic textbook, switching from SI to Gaussian when he moves into the relativistic
domain.
Consider a particle with charge q, rest mass m, and 4-velocity ⃗u interacting with an
electromagnetic ﬁeld FFF(
,
). In index notation, the electromagnetic 4-force acting
on the particle [Eq. (2.20)] is
dpα/dτ = qF αβuβ.
(2.44)
2.11 Nature of Electric and Magnetic Fields; Maxwell’s Equations
71

Let us examine this 4-force in some arbitrary inertial reference frame in which the
particle’s ordinary-velocity components are vj = vj and its 4-velocity components are
u0 = γ , uj = γ vj [Eqs. (2.25c)]. Anticipating the connection with the nonrelativistic
viewpoint, we introduce the following notation for the contravariant components of
the antisymmetric electromagnetic ﬁeld tensor:
F 0j = −F j0 = +Fj0 = −F0j = Ej,
F ij = Fij = ϵijkBk.
(2.45)
Inserting these components of FFF and ⃗u into Eq. (2.44) and using the relationship
dt/dτ = u0 = γ between t and τ derivatives, we obtain for the components of the
4-force dpj/dτ = γ dpj/dt = q(Fj0u0 + Fjkuk) = qu0(Fj0 + Fjkvk) = qγ (Ej +
ϵjkivkBi) and dp0/dτ = γ dp0/dt = qF 0juj = qγ Ejvj. Dividing by γ , converting
into 3-space index notation, and denoting the particle’s energy by E = p0, we bring
these into the familiar Lorentz-force form
Lorentz force
dp/dt = q(E + v × B),
dE/dt = qv . E.
(2.46)
Evidently, E is the electric ﬁeld and B the magnetic ﬁeld as measured in our chosen
Lorentz frame.
This may be familiar from standard electrodynamics textbooks (e.g., Jackson,
1999). Not so familiar, but very important, is the following geometric interpretation
of E and B.
The electric and magnetic ﬁelds E and B are spatial vectors as measured in the
chosen inertial frame. We can also regard them as 4-vectors that lie in a 3-surface of
simultaneity t = const of the chosen frame, i.e., that are orthogonal to the 4-velocity
(denote it ⃗w) of the frame’s observers (cf. Figs. 2.5 and 2.9). We shall denote this 4-
vectorversionofE andBby ⃗E ⃗w and ⃗B ⃗w, wherethesubscript ⃗w identiﬁesthe4-velocity
of the observer who measures these ﬁelds. These ﬁelds are depicted in Fig. 2.9.
In the rest frame of the observer ⃗w, the components of ⃗E ⃗w are E0
⃗w = 0, Ej
⃗w = Ej =
Fj0 [the Ej appearing in Eqs. (2.45)], and similarly for ⃗B ⃗w; the components of ⃗w are
w0 = 1, wj = 0. Therefore, in this frame Eqs. (2.45) can be rewritten as
electric and magnetic
ﬁelds measured by an
observer
Eα
⃗w = F αβwβ,
Bβ
⃗w = 1
2ϵαβγ δFγ δwα.
(2.47a)
[To verify this, insert the above components of FFF and ⃗w into these equations and,
after some algebra, recover Eqs. (2.45) along with E0
⃗w = B0
⃗w = 0.] Equations (2.47a)
saythatinonespecialreferenceframe, thatoftheobserver ⃗w, thecomponentsofthe4-
vectors on the left and on the right are equal. This implies that in every Lorentz frame
the components of these 4-vectors will be equal; that is, Eqs. (2.47a) are true when
one regards them as geometric, frame-independent equations written in slot-naming
index notation. These equations enable one to compute the electric and magnetic ﬁelds
measured by an observer (viewed as 4-vectors in the observer’s 3-surface of simultaneity)
72
Chapter 2. Special Relativity: Geometric Viewpoint

y
t
w
→
w
→
B
→
w
→
E
→
x
FIGURE 2.9 The electric and magnetic ﬁelds measured by an observer with
4-velocity ⃗w, shown as 4-vectors ⃗E ⃗w and ⃗B ⃗w that lie in the observer’s
3-surface of simultaneity (green 3-surface orthogonal to ⃗w).
from the observer’s 4-velocity and the electromagnetic ﬁeld tensor, without the aid of any
basis or reference frame.
Equations (2.47a) embody explicitly the following important fact. Although the
electromagneticﬁeldtensor FFF isageometric, frame-independentquantity, theelectric
and magnetic ﬁelds ⃗E ⃗w and ⃗B ⃗w individually depend for their existence on a speciﬁc
choice of observer (with 4-velocity ⃗w), that is, a speciﬁc choice of inertial reference
frame, orinotherwords, aspeciﬁcchoiceofthesplitofspacetimeintoa3-space(the3-
surface of simultaneity orthogonal to the observer’s 4-velocity ⃗w) and corresponding
time (the Lorentz time of the observer’s reference frame). Only after making such an
observer-dependent3+1splitofspacetimeintospaceplustimedotheelectricﬁeldandthe
magneticﬁeldcomeintoexistenceasseparateentities.Differentobserverswithdifferent
4-velocities ⃗w make this spacetime split in different ways, thereby resolving the frame-
independent FFF into different electric and magnetic ﬁelds ⃗E ⃗w and ⃗B ⃗w.
By the same procedure as we used to derive Eqs. (2.47a), one can derive the inverse
relationship, the following expression for the electromagnetic ﬁeld tensor in terms of
the (4-vector) electric and magnetic ﬁelds measured by some observer:
F αβ = wαEβ
⃗w −Eα
⃗wwβ + ϵαβ
γ δwγBδ
⃗w.
(2.47b)
Maxwell’s equations
Maxwell’s equations in geometric, frame-independent form are (in Gaussian
units)5
F αβ
;β = 4πJ α,
ϵαβγ δFγ δ;β = 0;
i.e.,
Fαβ;γ + Fβγ ;α + Fγ α;β = 0.
(2.48)
5.
In SI units the 4π gets replaced by μ0 = 1/ϵ0, corresponding to the different units for the charge-current
4-vector.
2.11 Nature of Electric and Magnetic Fields; Maxwell’s Equations
73

Here ⃗J is the charge-current 4-vector, which in any inertial frame has components
J 0 = ρe = (charge density),
J i = ji = (current density).
(2.49)
Exercise 2.19 describes how to think about this charge density and current density as
geometric objects determined by the observer’s 4-velocity or 3+1 split of spacetime
into space plus time. Exercise 2.20 shows how the frame-independent Maxwell’s
equations (2.48) reduce to the more familiar ones in terms of E and B. Exercise 2.21
explores potentials for the electromagnetic ﬁeld in geometric, frame-independent
language and the 3+1 split.
EXERCISES
Exercise 2.18 Derivation and Practice: Reconstruction of FFF
Derive Eq. (2.47b) by the same method as was used to derive Eq. (2.47a). Then show,
by a geometric, frame-independent calculation, that Eq. (2.47b) implies Eq. (2.47a).
Exercise 2.19 Problem: 3+1 Split of Charge-Current 4-Vector
Just as the electric and magnetic ﬁelds measured by some observer can be regarded
as 4-vectors ⃗E ⃗w and ⃗B ⃗w that live in the observer’s 3-space of simultaneity, so also the
charge density and current density that the observer measures can be regarded as a
scalar ρ ⃗w and 4-vector ⃗j ⃗w that live in the 3-space of simultaneity. Derive geometric,
frame-independent equations for ρ ⃗w and ⃗j ⃗w in terms of the charge-current 4-vector
⃗J and the observer’s 4-velocity ⃗w, and derive a geometric expression for ⃗J in terms
of ρ ⃗w, ⃗j ⃗w, and ⃗w.
Exercise 2.20 Problem: Frame-Dependent Version of Maxwell’s Equations
By performing a 3+1 split on the geometric version of Maxwell’s equations (2.48),
derive the elementary, frame-dependent version
3+1 split of Maxwell’s
equations
∇. E = 4πρe,
∇× B −∂E
∂t = 4πj,
∇. B = 0,
∇× E + ∂B
∂t = 0.
(2.50)
Exercise 2.21 Problem: Potentials for the Electromagnetic Field
(a) Express the electromagnetic ﬁeld tensor as an antisymmetrized gradient of a 4-
vector potential: in slot-naming index notation
Fαβ = Aβ;α −Aα;β.
(2.51a)
Show that, whatever may be the 4-vector potential ⃗A, the second of Maxwell’s
equations (2.48) is automatically satisﬁed. Show further that the electromagnetic
ﬁeld tensor is unaffected by a gauge change of the form
⃗Anew = ⃗Aold + ⃗∇ψ,
(2.51b)
74
Chapter 2. Special Relativity: Geometric Viewpoint

where ψ is a scalar ﬁeld (the generator of the gauge change). Show, ﬁnally, that it
is possible to ﬁnd a gauge-change generator that enforces Lorenz gauge
⃗∇. ⃗A = 0
(2.51c)
on the new 4-vector potential, and show that in this gauge, the ﬁrst of Maxwell’s
equations (2.48) becomes (in Gaussian units)
⃗A = −4π ⃗J;
i.e.,
Aα;μ
μ = −4πJ α.
(2.51d)
(b) Introduce an inertial reference frame, and in that frame split FFF into the electric
and magnetic ﬁelds E and B, split ⃗J into the charge and current densities ρe and
j, and split the vector potential into a scalar potential and a 3-vector potential
φ ≡A0,
A = spatial part of ⃗A.
(2.51e)
Deduce the 3+1 splits of Eqs. (2.51a)–(2.51d), and show that they take the form
given in standard textbooks on electromagnetism.
2.12
2.12 Volumes, Integration, and Conservation Laws
2.12.1
2.12.1 Spacetime Volumes and Integration
In Minkowski spacetime as in Euclidean 3-space (Sec. 1.8), the Levi-Civita tensor is
the tool by which one constructs volumes. The 4-dimensional parallelepiped whose
legs are the four vectors ⃗A, ⃗B, ⃗C, ⃗D has a 4-dimensional volume given by the analog
of Eqs. (1.25) and (1.26):
4-volume
4-volume = ϵαβγ δAαBβCγDδ = ϵ( ⃗A, ⃗B, ⃗C, ⃗D) = det
⎡
⎢⎢⎢⎢⎣
A0
B0
C0
D0
A1
B1
C1
D1
A2
B2
C2
D2
A3
B3
C3
D3
⎤
⎥⎥⎥⎥⎦
.
(2.52)
Note that this 4-volume is positive if the set of vectors { ⃗A, ⃗B, ⃗C, ⃗D} is right-handed
and negative if left-handed [cf. Eq. (2.43)].
Equation (2.52) provides us a way to perform volume integrals over 4-dimensional
Minkowski spacetime. To integrate a smooth tensor ﬁeld TTT over some 4-dimensional
region V of spacetime, we need only divide V up into tiny parallelepipeds, multiply
the 4-volume d of each parallelepiped by the value of TTT at its center, add, and
take the limit. In any right-handed Lorentz coordinate system, the 4-volume of a
tiny parallelepiped whose edges are dxα along the four orthogonal coordinate axes is
d = ϵ(dt ⃗e0, dx ⃗ex, dy ⃗ey, dz ⃗ez) = ϵ0123 dt dx dy dz = dt dx dy dz (the analog of
dV = dx dy dz). Correspondingly, the integral of TTT over V can be expressed as

V
T αβγd =

V
T αβγdt dx dy dz.
(2.53)
2.12 Volumes, Integration, and Conservation Laws
75

vectorial 3-volume
By analogy with the vectorial area (1.27) of a parallelogram in 3-space, any 3-
dimensional parallelepiped in spacetime with legs ⃗A, ⃗B, ⃗C has a vectorial 3-volume
⃗ (not to be confused with the scalar 4-volume ) deﬁned by
⃗(
) = ϵ(
, ⃗A, ⃗B, ⃗C);
μ = ϵμαβγAαBβCγ .
(2.54)
Here we have written the 3-volume vector both in abstract notation and in slot-
naming index notation. This 3-volume vector has one empty slot, ready and waiting
for a fourth vector (“leg”) to be inserted, so as to compute the 4-volume  of a 4-
dimensional parallelepiped.
Notice that the 3-volume vector ⃗ is orthogonal to each of its three legs (because
of the antisymmetry of ϵ), and thus (unless it is null) it can be written as ⃗ = V ⃗n,
where V is the magnitude of the 3-volume, and ⃗n is the unit normal to the three legs.
Interchanging any two legs of the parallelepiped reverses the 3-volume’s sign.
Consequently, the 3-volume is characterized not only by its legs but also by the order
of its legs, or equally well, in two other ways: (i) by the direction of the vector ⃗
(reverse the order of the legs, and the direction of ⃗ will reverse); and (ii) by the sense
of the 3-volume, deﬁned as follows. Just as a 2-volume (i.e., a segment of a plane) in 3-
dimensional space has two sides, so a 3-volume in 4-dimensional spacetime has two
positive and negative
sides, and sense of
3-volume
sides (Fig. 2.10). Every vector ⃗D for which ⃗ . ⃗D > 0 points out the positive side of the
3-volume ⃗. Vectors ⃗D with ⃗ . ⃗D < 0 point out its negative side. When something
moves through, reaches through, or points through the 3-volume from its negative
side to its positive side, we say that this thing is moving or reaching or pointing in
the “positive sense;” similarly for “negative sense.” The examples shown in Fig. 2.10
should make this more clear.
Figure 2.10a shows two of the three legs of the volume vector ⃗ = ϵ(
, x⃗ex,
y⃗ey, z⃗ez), where {t, x, y, z} are the coordinates, and {⃗eα} is the corresponding
right-handed basis of a speciﬁc Lorentz frame. It is easy to show that this ⃗ can also
be written as ⃗ = −V ⃗e0, where V is the ordinary volume of the parallelepiped
as measured by an observer in the chosen Lorentz frame, V = xyz. Thus, the
direction of the vector ⃗ is toward the past (direction of decreasing Lorentz time t).
From this, and the fact that timelike vectors have negative squared length, it is easy
to infer that ⃗ . ⃗D > 0 if and only if the vector ⃗D points out of the “future” side of
the 3-volume (the side of increasing Lorentz time t); therefore, the positive side of ⃗
is the future side. It follows that the vector ⃗ points in the negative sense of its own
3-volume.
Figure 2.10b shows two of the three legs of the volume vector ⃗ = ϵ(
, t⃗et,
y⃗ey, z⃗ez) = −tA⃗ex (with A = yz). In this case, ⃗ points in its own
positive sense.
This peculiar behavior is completely general. When the normal to a 3-volume is
timelike, its volume vector ⃗ points in the negative sense; when the normal is space-
like, ⃗ points in the positive sense. And as it turns out, when the normal is null, ⃗
76
Chapter 2. Special Relativity: Geometric Viewpoint

y
t
positive
sense
(a)
(b)
positive
sense
x
y
t
x
x →ex
t →e0
y →ey
y →ey

→

→
FIGURE 2.10 Spacetime diagrams depicting 3-volumes in 4-dimensional spacetime, with one spatial
dimension (that along the z direction) suppressed.
lies in the 3-volume (parallel to its one null leg) and thus points neither in the positive
sense nor the negative.6
Note the physical interpretations of the 3-volumes of Fig. 2.10. Figure 2.10a shows
an instantaneous snapshot of an ordinary, spatial parallelepiped, whereas Fig. 2.10b
shows the 3-dimensional region in spacetime swept out during time t by the
parallelogram with legs y⃗ey, z⃗ez and with area A = yz.
Vectorial3-volumeelementscanbeusedtoconstructintegralsover3-dimensional
volumes (also called 3-dimensional surfaces) in spacetime, for example,

V3 ⃗A . d ⃗.
More speciﬁcally, let (a, b, c) be (possibly curvilinear) coordinates in the 3-surface
(3-volume) V3, and denote by ⃗x(a, b, c) the spacetime point P on V3 whose coor-
dinate values are (a, b, c). Then (∂⃗x/∂a)da, (∂⃗x/∂b)db, (∂⃗x/∂c)dc are the vec-
torial legs of the elementary parallelepiped whose corners are at (a, b, c), (a +
da, b, c), (a, b + db, c), and so forth; and the spacetime components of these vecto-
rial legs are (∂xα/∂a)da, (∂xα/∂b)db, (∂xα/∂c)dc. The 3-volume of this elementary
parallelepiped is d ⃗ = ϵ

, (∂⃗x/∂a)da, (∂⃗x/∂b)db, (∂⃗x/∂c)dc

, which has space-
time components
dμ = ϵμαβγ
∂xα
∂a
∂xβ
∂b
∂xγ
∂c dadbdc.
(2.55)
This is the integration element to be used when evaluating

V3
⃗A . d ⃗ =

V3
Aμdμ.
(2.56)
See Ex. 2.22 for an example.
6.
This peculiar behavior gets replaced by a simpler description if one uses one-forms rather than vectors
to describe 3-volumes; see, for example, Misner, Thorne, and Wheeler (1973, Box 5.2).
2.12 Volumes, Integration, and Conservation Laws
77

Just as there are Gauss’s and Stokes’ theorems (1.28a) and (1.28b) for integrals in
Gauss’s theorem
Euclidean 3-space, so also there are Gauss’s and Stokes’ theorems in spacetime. Gauss’s
theorem has the obvious form

V4
( ⃗∇. ⃗A)d =

∂V4
⃗A . d ⃗,
(2.57)
where the ﬁrst integral is over a 4-dimensional region V4 in spacetime, and the second
is over the 3-dimensional boundary ∂V4 of V4, with the boundary’s positive sense
pointing outward, away from V4 (just as in the 3-dimensional case). We shall not write
down the 4-dimensional Stokes’ theorem, because it is complicated to formulate with
the tools we have developed thus far; easy formulation requires differential forms (e.g.,
Flanders, 1989), which we shall not introduce in this book.
2.12.2
2.12.2 Conservation of Charge in Spacetime
In this section, we use integration over a 3-dimensional region in 4-dimensional
spacetime to construct an elegant, frame-independent formulation of the law of
conservation of electric charge.
We begin by examining the geometric meaning of the charge-current 4-vector
⃗J. We deﬁned ⃗J in Eq. (2.49) in terms of its components. The spatial component
J x = Jx = J(⃗ex) is equal to the x component of current density jx: it is the amount Q
of charge that ﬂows across a unit surface area lying in the y-z plane in a unit time (i.e.,
the charge that ﬂows across the unit 3-surface ⃗ = ⃗ex). In other words, ⃗J( ⃗) = ⃗J(⃗ex)
is the total charge Q that ﬂows across ⃗ = ⃗ex in ⃗’s positive sense and similarly for the
other spatial directions. The temporal component J 0 = −J0 = ⃗J(−⃗e0) is the charge
density ρe: it is the total charge Q in a unit spatial volume. This charge is carried by
particles that are traveling through spacetime from past to future and pass through
the unit 3-surface (3-volume) ⃗ = −⃗e0. Therefore, ⃗J( ⃗) = ⃗J(−⃗e0) is the total charge
Q that ﬂows through ⃗ = −⃗e0 in its positive sense.This interpretation is the same one
we deduced for the spatial components of ⃗J.
This makes it plausible, and indeed one can show, that for any small 3-surface ⃗,
⃗J( ⃗) ≡J αα is the total charge Q that ﬂows across ⃗ in its positive sense.
charge-current 4-vector
This property of the charge-current 4-vector is the foundation for our frame-
independent formulation of the law of charge conservation. Let V be a compact 4-
dimensional region of spacetime and denote by ∂V its boundary, a closed 3-surface
in 4-dimensional spacetime (Fig. 2.11). The charged media (ﬂuids, solids, particles,
etc.) present in spacetime carry electric charge through V, from the past toward the
future. The law of charge conservation says that all the charge that enters V through
the past part of its boundary ∂V must exit through the future part of its boundary. If
we choose the positive sense of the boundary’s 3-volume element d ⃗ to point out of
V (toward the past on the bottom boundary and toward the future on the top), then
this global law of charge conservation can be expressed as
78
Chapter 2. Special Relativity: Geometric Viewpoint

y
t
V
∂V
x
FIGURE 2.11 The 4-dimensional region V in spacetime and its
closed 3-boundary ∂V (green surface), used in formulating
the law of charge conservation. The dashed lines symbolize,
heuristically, the ﬂow of charge from the past toward the future.

∂V
J αdα = 0.
(2.58)
global law of charge
conservation
When each tiny charge q enters V through its past boundary, it contributes nega-
tively to the integral, since it travels through ∂V in the negative sense (from positive
side of ∂V toward negative side); and when that same charge exits V through its fu-
ture boundary, it contributes positively. Therefore, its net contribution is zero, and
similarly for all other charges.
In Ex. 2.23 you will show that, when this global law of charge conservation (2.58) is
subjectedtoa3+1splitofspacetimeintospaceplustime, itbecomesthenonrelativistic
integral law of charge conservation (1.29).
This global conservation law can be converted into a local conservation law with
the help of the 4-dimensional Gauss’s theorem (2.57),

∂V J αdα =

V J α;αd. Since
the left-hand side vanishes, so must the right-hand side; and for this 4-volume integral
to vanish for every choice of V, it is necessary that the integrand vanish everywhere
in spacetime:
J α
;α = 0 ;
that is,
⃗∇. ⃗J = 0.
(2.59)
In a speciﬁc but arbitrary Lorentz frame (i.e., in a 3+1 split of spacetime into space
local law of charge
conservation
plus time), Eq. (2.59) becomes the standard differential law of charge conservation
(1.30).
2.12.3
2.12.3 Conservation of Particles, Baryon Number, and Rest Mass
Any conserved scalar quantity obeys conservation laws of the same form as those for
electric charge. For example, if the number of particles of some species (e.g., electrons,
protons, or photons) is conserved, then we can introduce for that species a number-
number-ﬂux 4-vector
ﬂux 4-vector ⃗S (analog of charge-current 4-vector ⃗J): in any Lorentz frame, S0 is the
numberdensityofparticles, alsodesignatedn, andSj istheparticleﬂux.If ⃗ isasmall
2.12 Volumes, Integration, and Conservation Laws
79

3-volume (3-surface) in spacetime, then ⃗S( ⃗) = Sαα is the number of particles that
pass through  from its negative side to its positive side. The frame-invariant global
laws of particle
conservation
and local conservation laws for these particles take the same form as those for electric
charge:

∂V
Sαdα = 0,
where ∂V is any closed 3-surface in spacetime,
(2.60a)
Sα
;α = 0;
that is,
⃗∇. ⃗S = 0.
(2.60b)
When fundamental particles (e.g., protons and antiprotons) are created and de-
stroyed by quantum processes, the total baryon number (number of baryons minus
number of antibaryons) is still conserved—or at least this is so to the accuracy of
all experiments performed thus far. We shall assume it so in this book. This law of
baryon-number conservation takes the forms of Eqs. (2.60), with ⃗S the number-ﬂux
4-vector for baryons (with antibaryons counted negatively).
It is useful to express this baryon-number conservation law in Newtonian-like
language by introducing a universally agreed-on mean rest mass per baryon ¯mB. This
¯mB is often taken to be 1/56 the mass of an 56Fe (iron-56) atomic nucleus, since 56Fe
is the nucleus with the tightest nuclear binding (i.e., the endpoint of thermonuclear
evolution in stars). We multiply the baryon number-ﬂux 4-vector ⃗S by this mean rest
mass per baryon to obtain a rest-mass-ﬂux 4-vector
rest-mass-ﬂux 4-vector
⃗Srm = ¯mB ⃗S,
(2.61)
which (since ¯mB is, by deﬁnition, a constant) satisﬁes the same conservation laws
(2.60) as baryon number.
For such media as ﬂuids and solids, in which the particles travel only short dis-
tances between collisions or strong interactions, it is often useful to resolve the particle
number-ﬂux 4-vector and the rest-mass-ﬂux 4-vector into a 4-velocity of the medium
⃗u (i.e., the 4-velocity of the frame in which there is a vanishing net spatial ﬂux of par-
ticles), and the particle number density no or rest mass density ρo as measured in the
medium’s rest frame:
⃗S = no⃗u,
⃗Srm = ρo⃗u.
(2.62)
See Ex. 2.24.
We make use of the conservation laws ⃗∇. ⃗S = 0 and ⃗∇. ⃗Srm = 0 for particles and
rest-mass conservation
rest mass later in this book (e.g., when studying relativistic ﬂuids); and we shall ﬁnd
the expressions (2.62) for the number-ﬂux 4-vector and rest-mass-ﬂux 4-vector quite
useful. See, for example, the discussion of relativistic shock waves in Ex. 17.9.
EXERCISES
Exercise 2.22 Practice and Example: Evaluation of 3-Surface Integral in Spacetime
In Minkowski spacetime, the set of all events separated from the origin by a timelike
interval a2 is a 3-surface, the hyperboloid t2 −x2 −y2 −z2 = a2, where {t, x, y, z}
80
Chapter 2. Special Relativity: Geometric Viewpoint

are Lorentz coordinates of some inertial reference frame. On this hyperboloid, intro-
duce coordinates {χ, θ, φ} such that
t = a cosh χ,
x = a sinh χ sin θ cos φ,
y = a sinh χ sin θ sin φ,
z = a sinh χ cos θ.
(2.63)
Note that χ is a radial coordinate and (θ, φ) are spherical polar coordinates. Denote
by V3 the portion of the hyperboloid with radius χ ≤b.
(a) Verify that for all values of (χ, θ, φ), the points deﬁned by Eqs. (2.63) do lie on
the hyperboloid.
(b) On a spacetime diagram, draw a picture of V3, the {χ, θ, φ} coordinates, and the
elementary volume element (vector ﬁeld) d ⃗ [Eq. (2.55)].
(c) Set ⃗A ≡⃗e0 (the temporal basis vector), and express

V3 ⃗A . d ⃗ as an integral over
{χ, θ, φ}. Evaluate the integral.
(d) Consider a closed 3-surface consisting of the segment V3 of the hyperboloid as its
top, the hypercylinder {x2 + y2 + z2 = a2 sinh2 b, 0 < t < a cosh b} as its sides,
and the sphere {x2 + y2 + z2 ≤a2 sinh2 b, t = 0} as its bottom. Draw a picture
of this closed 3-surface on a spacetime diagram. Use Gauss’s theorem, applied to
this 3-surface, to show that

V3 ⃗A . d ⃗ is equal to the 3-volume of its spherical
base.
Exercise 2.23 Derivation and Example: Global Law of Charge Conservation
in an Inertial Frame
Consider the global law of charge conservation

∂V J αdα = 0 for a special choice
of the closed 3-surface ∂V: The bottom of ∂V is the ball {t = 0, x2 + y2 + z2 ≤a2},
where {t, x, y, z} are the Lorentz coordinates of some inertial frame. The sides are
the spherical world tube {0 ≤t ≤T , x2 + y2 + z2 = a2}. The top is the ball {t =
T , x2 + y2 + z2 ≤a2}.
(a) Draw this 3-surface in a spacetime diagram.
(b) Show that for this ∂V,

∂V J αdα = 0 is a time integral of the nonrelativistic
integral conservation law (1.29) for charge.
Exercise 2.24 Example: Rest-Mass-Flux 4-Vector, Lorentz Contraction of
Rest-Mass Density, and Rest-Mass Conservation for a Fluid
Consider a ﬂuid with 4-velocity ⃗u and rest-mass density ρo as measured in the ﬂuid’s
rest frame.
(a) From the physical meanings of ⃗u, ρo, and the rest-mass-ﬂux 4-vector ⃗Srm, deduce
Eqs. (2.62).
(b) Examine the components of ⃗Srm in a reference frame where the ﬂuid moves
with ordinary velocity v. Show that S0 = ρoγ , and Sj = ρoγ vj, where γ =
1/
√
1 −v2. Explain the physical interpretation of these formulas in terms of
Lorentz contraction.
2.12 Volumes, Integration, and Conservation Laws
81

(c) Show that the law of conservation of rest mass ⃗∇. ⃗Srm = 0 takes the form
dρo
dτ = −ρo ⃗∇. ⃗u,
(2.64)
where d/dτ is derivative with respect to proper time moving with the ﬂuid.
(d) Consider a small 3-dimensional volume V of the ﬂuid, whose walls move with
the ﬂuid (so if the ﬂuid expands, V increases). Explain why the law of rest-mass
conservation must take the form d(ρoV )/dτ = 0. Thereby deduce that
⃗∇. ⃗u = (1/V )(dV/dτ).
(2.65)
2.13
2.13 Stress-Energy Tensor and Conservation of 4-Momentum
2.13.1
2.13.1 Stress-Energy Tensor
GEOMETRIC DEFINITION
We conclude this chapter by formulating the law of 4-momentum conservation in
ways analogous to our laws of conservation of charge, particles, baryon number,
and rest mass. This task is not trivial, since 4-momentum is a vector in spacetime,
while charge, particle number, baryon number, and rest mass are scalar quantities.
Correspondingly, the density-ﬂux of 4-momentum must have one more slot than the
density-ﬂuxes of charge, baryon number, and rest mass, ⃗J, ⃗S and ⃗Srm, respectively;
it must be a second-rank tensor. We call it the stress-energy tensor and denote it
TTT(
,
). It is a generalization of the Newtonian stress tensor to 4-dimensional
spacetime.
stress-energy tensor
Consider a medium or ﬁeld ﬂowing through 4-dimensional spacetime. As it
crosses a tiny 3-surface ⃗, it transports a net electric charge ⃗J( ⃗) from the nega-
tive side of ⃗ to the positive side, and net baryon number ⃗S( ⃗) and net rest mass
⃗Srm( ⃗). Similarly, it transports a net 4-momentum TTT(
, ⃗) from the negative side
to the positive side:
TTT(
, ⃗) ≡(total 4-momentum ⃗P that ﬂows through ⃗);
or T αββ = P α. (2.66)
COMPONENTS
From this deﬁnition of the stress-energy tensor we can read off the physical meanings
of its components on a speciﬁc, but arbitrary, Lorentz-coordinate basis: Making use of
method (2.23b) for computing the components of a vector or tensor, we see that in a
speciﬁc, but arbitrary, Lorentz frame (where ⃗ = −⃗e0 is a volume vector representing
a parallelepiped with unit volume V = 1, at rest in that frame, with its positive sense
toward the future):
−Tα0 = TTT(⃗eα, −⃗e0) = ⃗P (⃗eα) =
⎛
⎝
α component of 4-momentum that
ﬂows from past to future across a unit
volume V = 1 in the 3-space t = const
⎞
⎠
= (α component of density of 4-momentum).
(2.67a)
82
Chapter 2. Special Relativity: Geometric Viewpoint

Specializing α to be a time or space component and raising indices, we obtain the
specialized versions of (2.67a):
T 00 = (energy density as measured in the chosen Lorentz frame),
T j0 = (density of j component of momentum in that frame).
(2.67b)
Similarly, the αx component of the stress-energy tensor (also called the α1 compo-
nent, since x = x1 and ⃗ex = ⃗e1) has the meaning
Tα1 ≡Tαx ≡TTT(⃗eα, ⃗ex) =
⎛
⎜⎜⎝
α component of 4-momentum that crosses
a unit area yz = 1 lying in a surface of
constant x, during unit time t, crossing
from the −x side toward the +x side
⎞
⎟⎟⎠
=

α component of ﬂux of 4-momentum
across a surface lying perpendicular to ⃗ex

.
(2.67c)
The speciﬁc forms of this for temporal and spatial α are (after raising indices)
T 0x =
 energy ﬂux across a surface perpendicular to ⃗ex,
from the −x side to the +x side

,
(2.67d)
T jx =
 ﬂux of j component of momentum across a surface
perpendicular to ⃗ex, from the −x side to the +x side

=
 jx component
of stress

.
(2.67e)
The αy and αz components have the obvious, analogous interpretations.
components of stress-
energy tensor
These interpretations, restated much more brieﬂy, are:
T 00 = (energy density),
T j0 = (momentum density),
T 0j = (energy ﬂux),
T jk = (stress).
(2.67f)
SYMMETRY
Although it might not be obvious at ﬁrst sight, the 4-dimensional stress-energy tensor is
symmetry of stress-energy
tensor
always symmetric: in index notation (where indices can be thought of as representing
the names of slots, or equally well, components on an arbitrary basis)
T αβ = T βα.
(2.68)
This symmetry can be deduced by physical arguments in a speciﬁc, but arbitrary,
Lorentz frame: Consider, ﬁrst, the x0 and 0x components, that is, the x components
of momentum density and energy ﬂux. A little thought, symbolized by the following
heuristic equation, reveals that they must be equal:
T x0 =
 momentum
density

= (E)dx/dt
xyz =
E
yzt =
 energy
ﬂux

,
(2.69)
2.13 Stress-Energy Tensor and Conservation of 4-Momentum
83

and similarly for the other space-time and time-space components: T j0 = T 0j.
[In the ﬁrst expression of Eq. (2.69) E is the total energy (or equivalently mass)
in the volume xyz, (E)dx/dt is the total momentum, and when divided by
the volume we get the momentum density. The third equality is just elementary al-
gebra, and the resulting expression is obviously the energy ﬂux.] The space-space
components, being equal to the stress tensor, are also symmetric, T jk = T kj, by the
argument embodied in Fig. 1.6. Since T 0j = T j0 and T jk = T kj, all components in
our chosen Lorentz frame are symmetric, T αβ = T βα. Therefore, if we insert arbitrary
vectors into the slots of TTT and evaluate the resulting number in our chosen Lorentz
frame, we ﬁnd
TTT( ⃗A, ⃗B) = T αβAαBβ = T βαAαBβ = TTT( ⃗B, ⃗A);
(2.70)
that is, TTT is symmetric under interchange of its slots.
Let us return to the physical meanings (2.67f) of the components of the stress-
energy tensor. With the aid of TTT’s symmetry, we can restate those meanings in the
language of a 3+1 split of spacetime into space plus time: When one chooses a speciﬁc
reference frame, that choice splits the stress-energy tensor up into three parts. Its time-
time part is the energy density T 00, its time-space part T 0j = T j0 is the energy ﬂux or
equivalently the momentum density, and its space-space part T jk is the stress tensor.
2.13.2
2.13.2 4-Momentum Conservation
Our interpretation of ⃗J( ⃗) ≡J αα as the net charge that ﬂows through a small 3-
surface ⃗ from its negative side to its positive side gave rise to the global conservation
lawforcharge,

∂V J αdα = 0[Eq.(2.58)andFig.2.11].Similarlytheroleof TTT(
, ⃗)
[T αββ in slot-naming index notation] as the net 4-momentum that ﬂows through ⃗
from its negative side to positive gives rise to the following equation for conservation
of 4-momentum:
global law of 4-momentum
conservation

∂V
T αβdβ = 0.
(2.71)
(The time component of this equation is energy conservation; the spatial part is
momentum conservation.) This equation says that all the 4-momentum that ﬂows
into the 4-volume V of Fig. 2.11 through its 3-surface ∂V must also leave V through
∂V; it gets counted negatively when it enters (since it is traveling from the positive
side of ∂V to the negative), and it gets counted positively when it leaves, so its net
contribution to the integral (2.71) is zero.
This global law of 4-momentum conservation can be converted into a local law
(analogous to ⃗∇. ⃗J = 0 for charge) with the help of the 4-dimensional Gauss’s theo-
rem(2.57).Gauss’stheorem, generalizedintheobviouswayfromavectorialintegrand
to a tensorial one, is:

V
T αβ
;β d =

∂V
T αβdβ.
(2.72)
84
Chapter 2. Special Relativity: Geometric Viewpoint

Since the right-hand side vanishes, so must the left-hand side; and for this 4-volume
integral to vanish for every choice of V, the integrand must vanish everywhere in
spacetime:
local law of 4-momentum
conservation
T αβ
;β = 0;
or
⃗∇. TTT = 0.
(2.73a)
In the second, index-free version of this local conservation law, the ambiguity about
which slot the divergence is taken on is unimportant, since TTT is symmetric in its two
slots: T αβ;β = T βα;β.
In a speciﬁc but arbitrary Lorentz frame, the local conservation law (2.73a) for
4-momentum has as its temporal part
∂T 00
∂t
+ ∂T 0k
∂xk = 0,
(2.73b)
that is, the time derivative of the energy density plus the 3-divergence of the energy
ﬂux vanishes; and as its spatial part
∂T j0
∂t
+ ∂T jk
∂xk = 0,
(2.73c)
that is, the time derivative of the momentum density plus the 3-divergence of the
stress (i.e., of momentum ﬂux) vanishes. Thus, as one should expect, the geometric,
frame-independent law of 4-momentum conservation includes as special cases both
the conservation of energy and the conservation of momentum; and their differential
conservation laws have the standard form that one expects both in Newtonian physics
and in special relativity: time derivative of density plus divergence of ﬂux vanishes; cf.
Eq. (1.36) and associated discussion.
2.13.3
2.13.3 Stress-Energy Tensors for Perfect Fluids and Electromagnetic Fields
perfect-ﬂuid stress-energy
tensor
As an important example that illustrates the stress-energy tensor, consider a per-
fect ﬂuid—a medium whose stress-energy tensor, evaluated in its local rest frame (a
Lorentz frame where T j0 = T 0j = 0), has the form
T 00 = ρ,
T jk = P δjk
(2.74a)
[Eq. (1.34) and associated discussion]. Here ρ is a short-hand notation for the energy
densityT 00 (densityoftotalmass-energy, includingrestmass)asmeasuredinthelocal
rest frame, and the stress tensor T jk in that frame is an isotropic pressure P . From this
special form of T αβ in the local rest frame, one can derive the following geometric,
frame-independent expression for the stress-energy tensor in terms of the 4-velocity
⃗u of the local rest frame (i.e., of the ﬂuid itself), the metric tensor of spacetime ggg, and
the rest-frame energy density ρ and pressure P:
T αβ = (ρ + P)uαuβ + Pgαβ;
i.e., TTT = (ρ + P )⃗u ⊗⃗u + P ggg.
(2.74b)
See Ex. 2.26.
2.13 Stress-Energy Tensor and Conservation of 4-Momentum
85

In Sec. 13.8, we develop and explore the laws of relativistic ﬂuid dynamics that
follow from energy-momentum conservation ⃗∇. TTT = 0 for this stress-energy tensor
and from rest-mass conservation ⃗∇. ⃗Srm = 0. By constructing the Newtonian limit
of the relativistic laws, we shall deduce the nonrelativistic laws of ﬂuid mechanics,
which are the central theme of Part V. Notice, in particular, that the Newtonian limit
(P ≪ρ, u0 ≃1, uj ≃vj) of the stress part of the stress-energy tensor (2.74b) is
T jk = ρvjvk + Pδjk, which we met in Ex. 1.13.
electromagnetic stress-
energy tensor
Another example of a stress-energy tensor is that for the electromagnetic ﬁeld,
which takes the following form in Gaussian units (with 4π →μ0 = 1/ϵ0 in SI units):
T αβ = 1
4π

F αμF β
μ −1
4
gαβF μνFμν

.
(2.75)
We explore this stress-energy tensor in Ex. 2.28.
EXERCISES
Exercise 2.25 Example: Global Conservation of Energy in an Inertial Frame
Consider the 4-dimensional parallelepiped V whose legs are t⃗et, x⃗ex, y⃗ey,
z⃗ez, where (t, x, y, z) = (x0, x1, x2, x3) are the coordinates of some inertial frame.
The boundary ∂V of this V has eight 3-dimensional “faces.” Identify these faces,
and write the integral

∂V T 0βdβ as the sum of contributions from each of them.
According to the law of energy conservation, this sum must vanish. Explain the
physical interpretation of each of the eight contributions to this energy conservation
law. (See Ex. 2.23 for an analogous interpretation of charge conservation.)
Exercise 2.26 **Derivation and Example: Stress-Energy Tensor and
Energy-Momentum Conservation for a Perfect Fluid
(a) Derive the frame-independent expression (2.74b) for the perfect ﬂuid stress-
energy tensor from its rest-frame components (2.74a).
(b) Explain why the projection of ⃗∇. TTT = 0 along the ﬂuid 4-velocity, ⃗u . ( ⃗∇. TTT) = 0,
should represent energy conservation as viewed by the ﬂuid itself. Show that this
equation reduces to
dρ
dτ = −(ρ + P ) ⃗∇. ⃗u.
(2.76a)
With the aid of Eq. (2.65), bring this into the form
d(ρV )
dτ
= −P dV
dτ ,
(2.76b)
where V is the 3-volume of some small ﬂuid element as measured in the ﬂuid’s
local rest frame. What are the physical interpretations of the left- and right-hand
sides of this equation, and how is it related to the ﬁrst law of thermodynamics?
(c) Read the discussion in Ex. 2.10 about the tensor PPP = ggg + ⃗u ⊗⃗u that projects into
the 3-space of the ﬂuid’s rest frame. Explain why PμαT αβ;β = 0 should represent
86
Chapter 2. Special Relativity: Geometric Viewpoint

the law of force balance (momentum conservation) as seen by the ﬂuid. Show that
this equation reduces to
(ρ + P )⃗a = −PPP . ⃗∇P ,
(2.76c)
where ⃗a = d ⃗u/dτ is the ﬂuid’s 4-acceleration. This equation is a relativistic ver-
sion of Newton’s F = ma. Explain the physical meanings of the left- and right-
hand sides. Infer that ρ + P must be the ﬂuid’s inertial mass per unit volume. It
is also the enthalpy per unit volume, including the contribution of rest mass; see
Ex. 5.5 and Box 13.2.
Exercise 2.27 **Example: Inertial Mass per Unit Volume
Supposethatsomemediumhasarestframe(unprimedframe)inwhichitsenergyﬂux
and momentum density vanish, T 0j = T j0 = 0. Suppose that the medium moves in
the x direction with speed very small compared to light, v ≪1, as seen in a (primed)
laboratoryframe, andignorefactorsoforderv2.Theratioofthemedium’smomentum
density Gj′ = T j′0′ (as measured in the laboratory frame) to its velocity vi = vδix is
called its total inertial mass per unit volume and is denoted ρinert
ji
:
T j′0′ = ρinert
ji
vi.
(2.77)
In other words, ρinert
ji
is the 3-dimensional tensor that gives the momentum density
Gj′ when the medium’s small velocity is put into its second slot.
(a) Using a Lorentz transformation from the medium’s (unprimed) rest frame to the
(primed) laboratory frame, show that
ρinert
ji
= T 00δji + Tji.
(2.78)
(b) Give a physical explanation of the contribution Tjivi to the momentum density.
(c) Show that for a perfect ﬂuid [Eq. (2.74b)] the inertial mass per unit volume is
isotropic and has magnitude ρ + P, where ρ is the mass-energy density, and P
is the pressure measured in the ﬂuid’s rest frame:
ρinert
ji
= (ρ + P )δji.
(2.79)
See Ex. 2.26 for this inertial-mass role of ρ + P in the law of force balance.
Exercise 2.28 **Example: Stress-Energy Tensor, and Energy-Momentum
Conservation for the Electromagnetic Field
(a) From Eqs. (2.75) and (2.45) compute the components of the electromagnetic
stress-energy tensor in an inertial reference frame (in Gaussian units). Your
2.13 Stress-Energy Tensor and Conservation of 4-Momentum
87

answer should be the expressions given in electrodynamics textbooks:
T 00 = E2 + B2
8π
,
G = T 0jej = T j0ej = E × B
4π
,
T jk = 1
8π

(E2 + B2)δjk −2(EjEk + BjBk)

.
(2.80)
(In SI units, 4π →μ0 = 1/ϵ0.) See also Ex. 1.14 for an alternative derivation of
the stress tensor Tjk.
(b) Show that the divergence of the stress-energy tensor (2.75) is given by
T μν
;ν = 1
4π (F μα
;νF ν
α + F μαF ν
α;ν −1
2Fαβ
;μF αβ).
(2.81a)
(c) Combine this with Maxwell’s equations (2.48) to show that
∇. TTT = −FFF(
, ⃗J);
i.e., T αβ
;β = −F αβJβ.
(2.81b)
(d) The matter that carries the electric charge and current can exchange energy and
momentum with the electromagnetic ﬁeld. Explain why Eq. (2.81b) is the rate per
unit volume at which that matter feeds 4-momentum into the electromagnetic
ﬁeld, and conversely, +F αμJμ is the rate per unit volume at which the electro-
magnetic ﬁeld feeds 4-momentum into the matter. Show, further, that (as viewed
in any reference frame) the time and space components of this quantity are
dEmatter
dtdV
= F 0jJj = E . j,
dpmatter
dtdV
= ρeE + j × B,
(2.81c)
where ρe is charge density, and j is current density [Eq. (2.49)]. The ﬁrst of these
equations describes ohmic heating of the matter by the electric ﬁeld, and the
second gives the Lorentz force per unit volume on the matter (cf. Ex. 1.14b).
Bibliographic Note
For an inspiring taste of the history of special relativity, see the original papers by
Einstein, Lorentz, and Minkowski, translated into English and archived in Lorentz
et al. (1923).
Early relativity textbooks [see the bibliography in Jackson (1999, pp. 566–567)]
emphasized the transformation properties of physical quantities, in going from one
inertial frame to another, rather than their roles as frame-invariant geometric objects.
Minkowski (1908) introduced geometric thinking, but only in recent decades—in
large measure due to the inﬂuence of John Wheeler—has the geometric viewpoint
gained ascendancy.
In our opinion, the best elementary introduction to special relativity is the ﬁrst
edition of Taylor and Wheeler (1966); the more ponderous second edition (Taylor
88
Chapter 2. Special Relativity: Geometric Viewpoint

and Wheeler, 1992) is also good. At an intermediate level we strongly recommend
the special relativity portions of Hartle (2003).
At a more advanced level, comparable to this chapter, we recommend Goldstein,
Poole, and Safko (2002) and the special relativity sections of Misner, Thorne, and
Wheeler (1973), Carroll (2004), and Schutz (2009).
These all adopt the geometric viewpoint that we espouse. In this chapter, so far
as possible, we have minimized the proliferation of mathematical concepts (avoiding,
e.g., differential forms and dual bases). By contrast, the other advanced treatments
cited above embrace the richer mathematics.
Much less geometric than these references but still good, in our view, are the
special relativity sections of popular electrodynamics texts: Grifﬁths (1999) at an
intermediate level and Jackson (1999) at a more advanced level. We recommend
avoiding special relativity treatments that use imaginary time and thereby obfuscate
(e.g., earlier editions of Goldstein and of Jackson, and also the more modern and
otherwise excellent Zangwill (2013)).
Bibliographic Note
89


II
PART II
STATISTICAL PHYSICS
In this second part of the book, we study aspects of classical statistical physics that
every physicist should know but that are not usually treated in elementary thermo-
dynamics courses. Our study lays the microphysical (particle-scale) foundations for
the continuum physics of Parts III–VII, and it elucidates the intimate connections be-
tween relativistic statistical physics and the Newtonian theory, and between quantum
statistical physics and the classical theory. Our treatment is both Newtonian and rel-
ativistic. Readers who prefer a solely Newtonian treatment can skip the (rather few)
relativistic sections. Throughout, we presume that readers are familiar with elemen-
tary thermodynamics but not with other aspects of statistical physics.
In Chap. 3, we study kinetic theory—the simplest of all formalisms for analyz-
ing systems of huge numbers of particles (e.g., molecules of air, neutrons diffusing
throughanuclearreactor, orphotonsproducedinthebig-bangoriginoftheuniverse).
In kinetic theory, the key concept is the distribution function, or number density of
particles in phase space, N , that is, the number of particles of some species (e.g., elec-
trons) per unit of physical space and of momentum space. In special relativity, despite
ﬁrst appearances, this N turns out to be a geometric, reference-frame-independent
entity (a scalar ﬁeld in phase space). This N and the frame-independent laws it obeys
provide us with a means for computing, from microphysics, the macroscopic quanti-
ties of continuum physics: mass density, thermal energy density, pressure, equations
of state, thermal and electrical conductivities, viscosities, diffusion coefﬁcients, . . . .
In Chap. 4, we develop the foundations of statistical mechanics. Here our sta-
tistical study is more sophisticated than in kinetic theory: we deal with ensembles
of physical systems. Each ensemble is a (conceptual) collection of a huge number of
physical systems that are identical in the sense that they all have the same degrees
of freedom, but different in that their degrees of freedom may be in different physical
states. For example, the systems in an ensemble might be balloons that are each ﬁlled
with 1023 air molecules so each is describable by 3 × 1023 spatial coordinates (the
{x, y, z} of all the molecules) and 3 × 1023 momentum coordinates (the {px, py, pz}
of all the molecules). The state of one of the balloons is fully described, then,
91

by 6 × 1023 numbers. We introduce a distribution function N that is a function
of these 6 × 1023 different coordinates (i.e., it is deﬁned in a phase space with 6 × 1023
dimensions). This distribution function tells us how many systems (balloons) in our
ensemble lie in a unit volume of that phase space. Using this distribution function,
we study such issues as the statistical meaning of entropy, the relationship between
entropy and information, the statistical origin of the second law of thermodynam-
ics, the statistical meaning of “thermal equilibrium,” and the evolution of ensembles
into thermal equilibrium. Our applications include derivations of the Fermi-Dirac
distribution for fermions in thermal equilibrium and the Bose-Einstein distribution
for bosons, a study of Bose-Einstein condensation in a dilute gas, and explorations
of the meaning and role of entropy in gases, black holes, and the universe as a
whole.
In Chap. 5, we use the tools of statistical mechanics to study statistical thermo-
dynamics: ensembles of systems that are in or near thermal equilibrium (also called
statistical equilibrium). Using statistical mechanics, we derive the laws of thermo-
dynamics, and we learn how to use thermodynamic and statistical mechanical tools,
hand in hand, to study not only equilibria but also the probabilities for random, spon-
taneous ﬂuctuations away from equilibrium. Among the applications we study are:
(i) chemical and particle reactions, such as ionization equilibrium in a hot gas, and
electron-positron pair formation in a still hotter gas and (ii) phase transitions, such
as the freezing, melting, vaporization, and condensation of water. We focus special
attention on a ferromagnetic phase transition, in which the magnetic moments of
atoms spontaneously align with one another as iron is cooled, using it to illustrate
two elegant and powerful techniques of statistical physics: the renormalization group
and Monte Carlo methods.
In Chap. 6, we develop the theory of random processes (a modern, mathematical
component of which is the theory of stochastic differential equations). Here we study
the dynamical evolution of processes that are inﬂuenced by a huge number of factors
over which we have little control and little knowledge, except of their statistical
properties. One example is the Brownian motion of a dust particle being buffeted
by air molecules; another is the motion of a pendulum used, say, in a gravitational-
wave interferometer, where one monitors that motion so accurately that one can see
the inﬂuences of seismic vibrations and of ﬂuctuating thermal (Nyquist) forces in
the pendulum’s suspension wire. The position of such a dust particle or pendulum
cannot be predicted as a function of time, but one can compute the probability that
it will evolve in a given manner. The theory of random processes is a theory of the
evolution of the position’s probability distribution (and the probability distribution
for any other entity driven by random, ﬂuctuating inﬂuences). Among the random-
process concepts we study are spectral densities, correlation functions, the Fokker-
Planck equation (which governs the evolution of probability distributions), and the
ﬂuctuation-dissipation theorem (which says that, associated with any kind of friction,
92
Part II

there must be ﬂuctuating forces whose statistical properties are determined by the
strength of the friction and the temperature of the entities that produce the friction).
The theory of random processes, as treated in Chap. 6, also includes the theory
of signals and noise. At ﬁrst sight this undeniably important topic, which lies at the
heart of experimental and observational science, might seem outside the scope of
this book. However, we shall discover that it is intimately connected to statistical
physicsandthatsimilarprinciplestothoseusedtodescribe, say, Brownianmotion, are
appropriate when thinking about, for example, how to detect the electronic signal of
a rare particle event against a strong and random background. We study, for example,
techniques for extracting weak signals from noisy data by ﬁltering the data, and the
limits that noise places on the accuracies of physics experiments and on the reliability
of communications channels.
Statistical Physics
93


3
CHAPTER THREE
Kinetic Theory
The gaseous condition is exempliﬁed in the soir´ee, where the members rush about confusedly, and the
only communication is during a collision, which in some instances may be prolonged by button-holing.
JAMES CLERK MAXWELL (1873)
3.1
3.1 Overview
In this chapter, we study kinetic theory, the simplest of all branches of statistical
physics. Kinetic theory deals with the statistical distribution of a “gas” made from
a huge number of “particles” that travel freely, without collisions, for distances (mean
free paths) long compared to their sizes.
Examples of particles (italicized) and phenomena that can be studied via kinetic
theory are:
.
Whether neutrons in a nuclear reactor can survive long enough to maintain
a nuclear chain reaction and keep the reactor hot.
.
How galaxies, formed in the early universe, congregate into clusters as the
universe expands.
.
How spiral structure develops in the distribution of a galaxy’s stars.
.
How, deep inside a white-dwarf star, relativistic degeneracy inﬂuences the
equation of state of the star’s electrons and protons.
.
How a supernova explosion affects the evolution of the density and temper-
ature of interstellar molecules.
.
How anisotropies in the expansion of the universe affect the temperature
distribution of the cosmic microwave photons—the remnants of the big bang.
.
How changes of a metal’s temperature affect its thermal and electrical con-
ductivity (with the heat and current carried by electrons).
Most of these applications involve particle speeds small compared to that of light
and so can be studied with Newtonian theory, but some involve speeds near or at
the speed of light and require relativity. Accordingly, we develop both versions of the
theory, Newtonian and relativistic, and demonstrate that the Newtonian theory is
the low-speed limit of the relativistic theory. As is discussed in the Readers’ Guide
95

BOX 3.1.
READERS’ GUIDE
.
This chapter develops nonrelativistic (Newtonian) kinetic theory
and also the relativistic theory. Sections and exercises labeled
are
Newtonian, and those labeled
are relativistic. The
material
can be read without the
material, but the
material requires
the
material as a foundation. The
material is all Track Two.
.
This chapter relies on the geometric viewpoint about physics
developed in Chap. 1 for Newtonian physics and in Chap. 2 for
relativistic physics. It especially relies on
– Secs. 1.4 and 1.5.2 on Newtonian particle kinetics,
– Secs. 2.4.1 and 2.6 on relativistic particle kinetics,
– Sec. 1.8 for the Newtonian conservation laws for particles,
– Sec. 2.12.3 for the relativistic number-ﬂux 4-vector and its
conservation law,
– Sec. 1.9 on the Newtonian stress tensor and its role in
conservation laws for momentum,
– Sec. 2.13 on the relativistic stress-energy tensor and its role
in conservation laws for 4-momentum, and
– Sec. 1.10 on aspects of relativity theory that Newtonian
readers will need.
.
The Newtonian parts of this chapter are a crucial foundation for
the remainder of Part II (Statistical Physics) of this book, for small
portions of Part V (Fluid Dynamics; especially equations of state, the
origin of viscosity, and the diffusion of heat in ﬂuids), and for half of
Part VI (Plasma Physics; Chaps. 22 and 23).
(Box 3.1), the relativistic material is all Track Two and can be skipped by readers who
are focusing on the (nonrelativistic) Newtonian theory.
We begin in Sec. 3.2 by introducing the concepts of momentum space, phase space
(the union of physical space and momentum space), and the distribution function
(number density of particles in phase space). We meet several different versions of
the distribution function, all equivalent, but each designed to optimize conceptual
thinking or computations in a particular arena (e.g., photons, plasma physics, and
the interface with quantum theory). In Sec. 3.3, we study the distribution functions
that characterize systems of particles in thermal equilibrium. There are three such
equilibrium distributions: one for quantum mechanical particles with half-integral
spin (fermions), another for quantum particles with integral spin (bosons), and a
96
Chapter 3. Kinetic Theory

third for classical particles. As special applications, we derive the Maxwell velocity
distribution for low-speed, classical particles (Ex. 3.4) and its high-speed relativistic
analog (Ex. 3.5 and Fig. 3.6 below), and we compute the effects of observers’ motions
on their measurements of the cosmic microwave radiation created in our universe’s
big-bang origin (Ex. 3.7). In Sec. 3.4, we learn how to compute macroscopic, physical-
space quantities (particle density and ﬂux, energy density, stress tensor, stress-energy
tensor, . . . ) by integrating over the momentum portion of phase space. In Sec. 3.5,
we show that, if the distribution function is isotropic in momentum space, in some
reference frame, then on macroscopic scales the particles constitute a perfect ﬂuid.
We use our momentum-space integrals to evaluate the equations of state of various
kinds of perfect ﬂuids: a nonrelativistic hydrogen gas in both the classical, nonde-
generate regime and the regime of electron degeneracy (Sec. 3.5.2), a relativistically
degenerate gas (Sec. 3.5.4), and a photon gas (Sec. 3.5.5). We use our results to dis-
cuss the physical nature of matter as a function of density and temperature (see
Fig. 3.7).
In Sec. 3.6, we study the evolution of the distribution function, as described by
Liouville’s theorem and by the associated collisionless Boltzmann equation when col-
lisions between particles are unimportant, and by the Boltzmann transport equation
when collisions are signiﬁcant. We use a simple variant of these evolution laws to
study the heating of Earth by the Sun, and the key role played by the greenhouse
effect (Ex. 3.15). Finally, in Sec. 3.7, we learn how to use the Boltzmann transport
equation to compute the transport coefﬁcients (diffusion coefﬁcient, electrical con-
ductivity, thermal conductivity, and viscosity) that describe the diffusive transport of
particles, charge, energy, and momentum through a gas of particles that collide fre-
quently. We then use the Boltzmann transport equation to study a chain reaction in
a nuclear reactor (Ex. 3.21).
Readers who feel overwhelmed by the enormous amount and variety of applica-
tions in this chapter (and throughout this book) should remember the authors’ goals:
We want readers to learn the fundamental concepts of kinetic theory (and other topics
in this book), and we want them to meet a variety of applications, so they will under-
stand how the fundamental concepts are used. However, we do not expect readers to
become expert in or even remember all these applications. To do so would require
much more time and effort than most readers can afford or should expend.
3.2
3.2 Phase Space and Distribution Function
3.2.1
3.2.1 Newtonian Number Density in Phase Space, N
physical space
In Newtonian, 3-dimensional space (physical space), consider a particle with rest mass
m that moves along a path x(t) as universal time t passes (Fig. 3.1a). The particle’s
time-varying velocity and momentum are v(t) = dx/dt and p(t) = mv. The path x(t)
is a curve in the physical space, and the momentum p(t) is a time-varying, coordinate-
independent vector in the physical space.
3.2 Phase Space and Distribution Function
97

z
(a)
(b)
x(0)
x(2)
p(0)
p(0)
p(2)
p(2)
y
t = 0
t = 0
2
2
3
3
4
4
5
5
t = 1
t = 1
x
pz
px
py
FIGURE 3.1 (a) Euclidean physical space, in which a particle moves along a curve x(t) that is
parameterized by universal time t. In this space, the particle’s momentum p(t) is a vector tangent to
the curve. (b) Momentum space, in which the particle’s momentum vector p is placed, unchanged,
with its tail at the origin. As time passes, the momentum’s tip sweeps out the indicated curve p(t).
It is useful to introduce an auxiliary 3-dimensional space, called momentum space,
momentum space
in which we place the tail of p(t) at the origin. As time passes, the tip of p(t) sweeps
out a curve in momentum space (Fig. 3.1b). This momentum space is “secondary”
in the sense that it relies for its existence on the physical space of Fig. 3.1a. Any
Cartesian coordinate system of physical space, in which the location x(t) of the
particle has coordinates {x, y, z}, induces in momentum space a corresponding co-
ordinate system {px, py, pz}. The 3-dimensional physical space and 3-dimensional
phase space
momentum space together constitute a 6-dimensional phase space, with coordinates
{x, y, z, px, py, pz}.
In this chapter, we study a collection of a very large number of identical particles
(all with the same rest mass m).1 As tools for this study, consider a tiny 3-dimensional
volume dVx centered on some location x in physical space and a tiny 3-dimensional
volume dVp centered on location p in momentum space. Together these make up a
tiny 6-dimensional volume
d2V ≡dVxdVp.
(3.1)
In any Cartesian coordinate system, we can think of dVx as being a tiny cube located
at (x, y, z) and having edge lengths dx, dy, dz, and similarly for dVp. Then, as
computed in this coordinate system, these tiny volumes are
dVx = dx dy dz,
dVp = dpx dpy dpz,
d2V = dx dy dz dpx dpy dpz. (3.2)
1.
In Ex. 3.2 and Box 3.2, we extend kinetic theory to particles with a range of rest masses.
98
Chapter 3. Kinetic Theory

Denote by dN the number of particles (all with rest mass m) that reside inside
d2V in phase space (at some moment of time t). Stated more fully: dN is the number
of particles that, at time t, are located in the 3-volume dVx centered on the location x
in physical space and that also have momentum vectors whose tips at time t lie in the
3-volume dVp centered on location p in momentum space. Denote by
distribution function
N (x, p, t) ≡dN
d2V =
dN
dVx dVp
(3.3)
the number density of particles at location (x, p) in phase space at time t. This is also
called the distribution function.
This distribution function is kinetic theory’s principal tool for describing any
collection of a large number of identical particles.
In Newtonian theory, the volumes dVx and dVp occupied by our collection of dN
particles are independent of the reference frame that we use to view them. Not so
in relativity theory: dVx undergoes a Lorentz contraction when one views it from a
moving frame, and dVp also changes; but (as we shall see in Sec. 3.2.2) their product
d2V = dVxdVp is the same in all frames. Therefore, in both Newtonian theory and
relativity theory, the distribution function N = dN/d2V is independent of reference
frame, and also, of course, independent of any choice of coordinates. It is a coordinate-
independent scalar in phase space.
3.2.2
3.2.2 Relativistic Number Density in Phase Space, N
SPACETIME
We deﬁne the special relativistic distribution function in precisely the same way
as the nonrelativistic one, N (x, p, t) ≡dN/d2V = dN/dVxdVp, except that now
p is the relativistic momentum (p = mv/
√
1 −v2 if the particle has nonzero rest
mass m). This deﬁnition of N appears, at ﬁrst sight, to be frame dependent, since
the physical 3-volume dVx and momentum 3-volume dVp do not even exist until
we have selected a speciﬁc reference frame. In other words, this deﬁnition appears
to violate our insistence that relativistic physical quantities be described by frame-
independent geometric objects that live in 4-dimensional spacetime. In fact, the
distribution function deﬁned in this way is frame independent, though it does not
look so. To elucidate this, we shall develop carefully and somewhat slowly the 4-
dimensional spacetime ideas that underlie this relativistic distribution function.
Consider, as shown in Fig. 3.2a, a classical particle with rest mass m moving
through spacetime along a world line P(ζ), or equivalently ⃗x(ζ), where ζ is an afﬁne
parameter related to the particle’s 4-momentum by
⃗p = d ⃗x/dζ
(3.4a)
3.2 Phase Space and Distribution Function
99

t
(a)
(b)
y
py
px
ζ = 0
ζ = 1
ζ = 2
ζ = 3
ζ = 4
x
p→ = d→x
—
dζ
p→(ζ = 2)
p0 = E
ζ = 0
1
2
3
4
FIGURE3.2 (a)Theworldline ⃗x(ζ)ofaparticleinspacetime(withonespatialcoordinate, z, suppressed),
parameterized by a parameter ζ that is related to the particle’s 4-momentum by ⃗p = d ⃗x/dζ. (b) The
trajectory of the particle in momentum space. The particle’s 4-momentum is conﬁned to the mass
hyperboloid, ⃗p2 = −m2 (also known as the mass shell).
[as discussed following Eq. (2.10)]. If the particle has nonzero rest mass, then its 4-
velocity ⃗u and proper time τ are related to its 4-momentum and afﬁne parameter by
⃗p = m⃗u,
ζ = τ/m
(3.4b)
[Eqs. (2.10) and (2.11)], and we can parameterize the world line by either τ or ζ. If
the particle has zero rest mass, then its world line is null, and τ does not change along
it, so we have no choice but to use ζ as the world line’s parameter.
MOMENTUM SPACE AND MASS HYPERBOLOID
4-dimensional momentum
space
The particle can be thought of not only as living in 4-dimensional spacetime
(Fig. 3.2a), but also as living in a 4-dimensional momentum space (Fig. 3.2b). Mo-
mentum space, like spacetime, is a geometric, coordinate-independent concept: each
point in momentum space corresponds to a speciﬁc 4-momentum ⃗p. The tail of the
vector ⃗p sits at the origin of momentum space, and its tip sits at the point representing
⃗p. The momentum-space diagram drawn in Fig. 3.2b has as its coordinate axes the
components (p0, p1 = p1 ≡px, p2 = p2 ≡py, p3 = p3 ≡pz) of the 4-momentum
as measured in some arbitrary inertial frame. Because the squared length of the 4-
momentum is always −m2,
⃗p . ⃗p = −(p0)2 + (px)2 + (py)2 + (pz)2 = −m2,
(3.4c)
the particle’s 4-momentum (the tip of the 4-vector ⃗p) is conﬁned to a hyperboloid in
mass hyperboloid
momentum space. This mass hyperboloid requires no coordinates for its existence; it
is the frame-independent set of points in momentum space for which ⃗p . ⃗p = −m2. If
100
Chapter 3. Kinetic Theory

the particle has zero rest mass, then ⃗p is null, and the mass hyperboloid is a cone with
vertex at the origin of momentum space. As in Chap. 2, we often denote the particle’s
energy p0 by
E ≡p0
(3.4d)
(with the E in script font to distinguish it from the energy E = E −m with rest mass
removed and its nonrelativistic limit E = 1
2mv2), and we embody the particle’s spatial
momentum in the 3-vector p = pxex + pyey + pzez. Therefore, we rewrite the mass-
hyperboloid relation (3.4c) as
E2 = m2 + |p|2.
(3.4e)
If no forces act on the particle, then its momentum is conserved, and its location
in momentum space remains ﬁxed. A force (e.g., due to an electromagnetic ﬁeld)
pushes the particle’s 4-momentum along some curve in momentum space that lies
on the mass hyperboloid. If we parameterize that curve by the same parameter ζ as
we use in spacetime, then the particle’s trajectory in momentum space can be written
abstractly as ⃗p(ζ). Such a trajectory is shown in Fig. 3.2b.
Because the mass hyperboloid is 3-dimensional, we can characterize the particle’s
location on it by just three coordinates rather than four. We typically use as those
coordinates the spatial components of the particle’s 4-momentum, (px, py, pz), or
the spatial momentum vector p as measured in some speciﬁc (but usually arbitrary)
inertial frame.
PHASE SPACE
phase space
Momentum space and spacetime, taken together, constitute the relativistic phase
space. We can regard phase space as 8-dimensional (four spacetime dimensions plus
four momentum space dimensions). Alternatively, if we think of the 4-momentum
as conﬁned to the 3-dimensional mass hyperboloid, then we can regard phase space
as 7-dimensional. This 7- or 8-dimensional phase space, by contrast with the non-
relativistic 6-dimensional phase space, is frame independent. No coordinates or ref-
erence frame are actually needed to deﬁne spacetime and explore its properties, and
none are needed to deﬁne and explore 4-momentum space or the mass hyperboloid—
though inertial (Lorentz) coordinates are often helpful in practical situations.
VOLUMES IN PHASE SPACE AND DISTRIBUTION FUNCTION
Now turn attention from an individual particle to a collection of a huge number of
identical particles, each with the same rest mass m, and allow m to be ﬁnite or zero
(it does not matter which). Examine those particles that pass close to a speciﬁc event
P (also denoted ⃗x) in spacetime; and examine them from the viewpoint of a speciﬁc
observer, who lives in a speciﬁc inertial reference frame. Figure 3.3a is a spacetime
diagram drawn in that observer’s frame. As seen in that frame, the event P occurs
at time t and spatial location (x, y, z).
3.2 Phase Space and Distribution Function
101

t
dVx
dVp
d
→
p
dpx
dpy
(a)
(b)
y
py
p
px
x
p0
dy
P
dx
→p
FIGURE 3.3 Deﬁnition of the distribution function from the viewpoint of a speciﬁc observer in a speciﬁc
inertial reference frame, whose coordinate axes are used in these drawings. (a) At the event P, the
observer selects a 3-volume dVx and focuses on the set S of particles that lie in dVx. (b) These particles
have momenta lying in a region of the mass hyperboloid that is centered on ⃗p and has 3-momentum
volume dVp. If dN is the number of particles in that set S, then N (P, ⃗p) ≡dN/dVxdVp.
We ask the observer, at the time t of the chosen event, to deﬁne the distribution
function N in identically the same way as in Newtonian theory, except that p is the
relativistic spatial momentum p = mv/
√
1 −v2 instead of the nonrelativistic p = mv.
Speciﬁcally, the observer, in her inertial frame, chooses a tiny 3-volume
dVx = dx dy dz
(3.5a)
centered on location P (little horizontal rectangle shown in Fig. 3.3a) and a tiny 3-
volume
dVp = dpx dpy dpz
(3.5b)
centered on p in momentum space (little rectangle in the px-py plane in Fig. 3.3b).
Ask the observer to focus on the set S of particles that lie in dVx and have spatial
momenta in dVp (Fig. 3.3). If there are dN particles in this set S, then the observer
will identify
relativistic distribution
function
N ≡
dN
dVxdVp
≡dN
d2V
(3.6)
as the number density of particles in phase space or distribution function.
Notice in Fig. 3.3b that the 4-momenta of the particles in S have their tails at
the origin of momentum space (as by deﬁnition do all 4-momenta) and have their
tips in a tiny rectangular box on the mass hyperboloid—a box centered on the 4-
momentum ⃗p whose spatial part is p and temporal part is p0 = E =

m2 + p2.
102
Chapter 3. Kinetic Theory

The momentum volume element dVp is the projection of that mass-hyperboloid box
onto the horizontal (px, py, pz) plane in momentum space. [The mass-hyperboloid
box itself can be thought of as a (frame-independent) vectorial 3-volume d ⃗p—the
momentum-space version of the vectorial 3-volume introduced in Sec. 2.12.1; see
below.]
The number density N depends on the location P in spacetime of the 3-volume
dVx and on the 4-momentum ⃗p about which the momentum volume on the mass
hyperboloid is centered: N = N (P, ⃗p). From the chosen observer’s viewpoint, it can
be regarded as a function of time t and spatial location x (the coordinates of P) and
of spatial momentum p.
At ﬁrst sight, one might expect N to depend also on the inertial reference frame
used in its deﬁnition (i.e., on the 4-velocity of the observer). If this were the case (i.e.,
if N at ﬁxed P and ⃗p were different when computed by the above prescription using
different inertial frames), then we would feel compelled to seek some other object—
one that is frame-independent—to serve as our foundation for kinetic theory. This is
because the principle of relativity insists that all fundamental physical laws should be
expressible in frame-independent language.
Fortunately, the distribution function (3.6) is frame independent by itself: it is a
frame-independent scalar ﬁeld in phase space, so we need seek no further.
PROOF OF FRAME INDEPENDENCE OF N = dN/d2V
To prove the frame independence of N , we shall consider the frame dependence of
the spatial 3-volume dVx, then the frame dependence of the momentum 3-volume
dVp, and ﬁnally the frame dependence of their product d2V = dVxdVp and thence
of the distribution function N = dN/d2V.
The thing that identiﬁes the 3-volume dVx and 3-momentum dVp is the set of
particles S. We select that set once and for all and hold it ﬁxed, and correspondingly,
the number of particles dN in the set is ﬁxed. Moreover, we assume that the particles’
rest mass m is nonzero and shall deal with the zero-rest-mass case at the end by taking
the limit m →0. Then there is a preferred frame in which to observe the particles S:
their own rest frame, which we identify by a prime.
In their rest frame and at a chosen event P, the particles S occupy the interior of
some box with imaginary walls that has some 3-volume dVx′. As seen in some other
“laboratory” frame, their box has a Lorentz-contracted volume dVx =
√
1 −v2 dVx′.
Here v is their speed as seen in the laboratory frame. The Lorentz-contraction factor
is related to the particles’ energy, as measured in the laboratory frame, by
√
1 −v2 =
m/E, and therefore EdVx = mdVx′. The right-hand side is a frame-independent
constant m times a well-deﬁned number that everyone can agree on: the particles’
rest-frame volume dVx′, i.e.,
EdVx = (a frame-independent quantity).
(3.7a)
3.2 Phase Space and Distribution Function
103

Thus, the spatial volume dVx occupied by the particles is frame dependent, and their
energy E is frame dependent, but the product of the two is independent of reference
frame.
Turn now to the frame dependence of the particles’ 3-volume dVp. As one sees
from Fig. 3.3b, dVp is the projection of the frame-independent mass-hyperboloid
region d ⃗p onto the laboratory’s xyz 3-space. Equivalently, it is the time component
d0
p of d ⃗p. Now, the 4-vector d ⃗p, like the 4-momentum ⃗p, is orthogonal to the
mass hyperboloid at the common point where they intersect it, and therefore d ⃗p is
parallel to ⃗p. This means that, when one goes from one reference frame to another,
the time components of these two vectors will grow or shrink in the same manner:
d ⃗0
p = dVp is proportional to p0 = E, so their ratio must be frame independent:
dVp
E
= (a frame-independent quantity).
(3.7b)
(If this sophisticated argument seems too slippery to you, then you can develop an
alternative, more elementary proof using simpler 2-dimensional spacetime diagrams:
Ex. 3.1.)
By taking the product of Eqs. (3.7a) and (3.7b) we see that for our chosen set of
particles S,
dVxdVp = d2V = (a frame-independent quantity);
(3.7c)
and since the number of particles in the set, dN, is obviously frame-independent, we
conclude that
frame independence of
relativistic distribution
function
N =
dN
dVxdVp
≡dN
d2V = (a frame-independent quantity).
(3.8)
Although we assumed nonzero rest mass (m ̸= 0) in our derivation, the conclu-
sions that EdVx and dVp/E are frame independent continue to hold if we take the
limit as m →0 and the 4-momenta become null. Correspondingly, Eqs. (3.7a)–(3.8)
are valid for particles with zero as well as nonzero rest mass.
EXERCISES
Exercise 3.1 Derivation and Practice: Frame Dependences of dVx and dVp
Use the 2-dimensional spacetime diagrams of Fig. 3.4 to show that EdVx and dVp/E
are frame independent [Eqs. (3.7a) and (3.7b)].
Exercise 3.2 **Example: Distribution Function for Particles with a Range of
Rest Masses
A galaxy such as our Milky Way contains ∼1012 stars—easily enough to permit a
kinetic-theory description of their distribution; each star contains so many atoms
(∼1056) that the masses of the stars can be regarded as continuously distributed, not
104
Chapter 3. Kinetic Theory

t
S
dpx′
dpx
px′
p0′
p0
px
mass
hyperboloid
dx′
dx
x′
x
t′
(a)
(b)
FIGURE 3.4 (a) Spacetime diagram drawn from the viewpoint of the (primed) rest frame of the particles
S for the special case where the laboratory frame moves in the −x′ direction with respect to them.
(b) Momentum-space diagram drawn from viewpoint of the unprimed observer.
discrete. Almost everywhere in a galaxy, the stars move with speeds small compared
to light, but deep in the cores of most galaxies there resides a massive black hole
near which the stars move with relativistic speeds. In this exercise we explore the
foundations for treating such a system: “particles” with continuously distributed rest
masses and relativistic speeds.
(a) For a subset S of particles like that of Fig. 3.3 and associated discussion, but with
a range of rest masses dm centered on some value m, introduce the phase-space
volume d2V ≡dVxdVpdm that the particles S occupy. Explain why this occupied
volume is frame invariant.
(b) Show that this invariant occupied volume can be rewritten as d2V =
(dVx E/m)(dVpdE) = (dVx E/m)(dp0dpxdpydpz). Explain the physical mean-
ing of each term in parentheses, and show that each is frame invariant.
If the number of particles in the set S is dN, then we deﬁne the frame-invariant
distribution function by
N ≡dN
d2V =
dN
dVxdVpdm.
(3.9)
This is a function of location P in 4-dimensional spacetime and location ⃗p in 4-
dimensional momentum space (not conﬁned to the mass hyperboloid), and thus a
function of location in 8-dimensional phase space. We explore the evolution of this
distribution function in Box 3.2 (near the end of Sec. 3.6).
3.2.3
3.2.3 Distribution Function f (x, v, t) for Particles in a Plasma
The normalization that one uses for the distribution function is arbitrary: renormalize
N by multiplying with any constant, and N will still be a geometric, coordinate-
independent, and frame-independent quantity and will still contain the same infor-
mation as before. In this book, we use several renormalized versions of N , depending
3.2 Phase Space and Distribution Function
105

on the situation. We now introduce them, beginning with the version used in plasma
physics.
In Part VI, when dealing with nonrelativistic plasmas (collections of electrons and
ions that have speeds small compared to light), we regard the distribution function
as depending on time t, location x in Euclidean space, and velocity v (instead of
momentum p = mv), and we denote it by2
plasma distribution
function
f (t, x, v) ≡
dN
dVx dVv
=
dN
dxdydz dvx dvy dvz
= m3N .
(3.10)
(This change of viewpoint and notation when transitioning to plasma physics is
typical of this textbook. When presenting any subﬁeld of physics, we usually adopt
the conventions, notation, and also the system of units that are generally used in that
subﬁeld.)
3.2.4
3.2.4 Distribution Function Iν/ν3 for Photons
[For readers restricting themselves to the Newtonian portions of this book: Please
read Sec. 1.10, which lists a few items of special relativity that you need for the
discussion here. As described there, you can deal with photons fairly easily by simply
remembering that a photon has zero rest mass, energy E = hν, and momentum
p = (hν/c)n, where ν is its frequency and n is a unit vector tangent to the photon’s
spatial trajectory.]
When dealing with photons or other zero-rest-mass particles, one often expresses
N in terms of the speciﬁc intensity Iν. This quantity is deﬁned as follows (see Fig. 3.5).
An observer places a CCD (or other measuring device) perpendicular to the photons’
propagation direction n—perpendicular as measured in her reference frame. The
region of the CCD that the photons hit has surface area dA as measured by her, and
because the photons move at the speed of light c, the product of that surface area with
c times the time dt that they take to all go through the CCD is equal to the volume
they occupy at a speciﬁc moment of time:
dVx = dA cdt.
(3.11a)
Focus attention on a set S of photons in this volume that all have nearly the same
frequency ν and propagation direction n as measured by the observer. Their energies
E and momenta p are related to ν and n by
E = hν,
p = (hν/c)n,
(3.11b)
where h is Planck’s constant. Their frequencies lie in a range dν centered on ν, and
they come from a small solid angle d centered on −n; the volume they occupy in
momentum space is related to these quantities by
dVp = |p|2dd|p| = (hν/c)2d(hdν/c) = (h/c)3ν2ddν.
(3.11c)
2.
The generalization to relativistic plasmas is straightforward; see, e.g., Ex. 23.12.
106
Chapter 3. Kinetic Theory

dA
dVx
dt
n
d
FIGURE 3.5 Geometric construction used in
deﬁning the speciﬁc intensity Iν.
The photons’ speciﬁc intensity, as measured by the observer, is deﬁned to be the total
energy
dE = hνdN
(3.11d)
(where dN is the number of photons) that crosses the CCD per unit area dA, per unit
time dt, per unit frequency dν, and per unit solid angle d (i.e., per unit everything):
speciﬁc intensity
Iν ≡
dE
dAdtdνd.
(3.12)
(This Iν is sometimes denoted Iν.) From Eqs. (3.8), (3.11), and (3.12) we readily
deduce the following relationship between this speciﬁc intensity and the distribution
function:
N = c2
h4
Iν
ν3.
(3.13)
This relation shows that, with an appropriate renormalization, Iν/ν3 is the photons’
photon distribution
function
distribution function.
Astronomers and opticians regard the speciﬁc intensity (or equally well, Iν/ν3)
as a function of the photon propagation direction n, photon frequency ν, location
x in space, and time t. By contrast, nonrelativistic physicists regard the distribution
function N as a function of the photon momentum p, location in space, and time;
relativistic physicists regard it as a function of the photon 4-momentum ⃗p (on the
photons’ mass hyperboloid, which is the light cone) and of location P in spacetime.
Clearly, the information contained in these three sets of variables, the astronomers’
set and the two physicists’ sets, is the same.
If two different physicists in two different reference frames at the same event
in spacetime examine the same set of photons, they will measure the photons to
have different frequencies ν (because of the Doppler shift between their two frames).
They will also measure different speciﬁc intensities Iν (because of Doppler shifts of
frequencies, Doppler shifts of energies, dilation of times, Lorentz contraction of areas
of CCDs, and aberrations of photon propagation directions and thence distortions of
3.2 Phase Space and Distribution Function
107

solid angles). However, if each physicist computes the ratio of the speciﬁc intensity
that she measures to the cube of the frequency she measures, that ratio, according to
Eq. (3.13), will be the same as computed by the other astronomer: the distribution
function Iν/ν3 will be frame independent.
3.2.5
3.2.5 Mean Occupation Number η
Although this book is about classical physics, we cannot avoid making frequent
contact with quantum theory. The reason is that modern classical physics rests on
a quantum mechanical foundation. Classical physics is an approximation to quantum
physics, not conversely. Classical physics is derivable from quantum physics, not
conversely.
In statistical physics, the classical theory cannot fully shake itself free from its
quantum roots; it must rely on them in crucial ways that we shall meet in this chapter
and the next. Therefore, rather than try to free it from its roots, we expose these roots
and proﬁt from them by introducing a quantum mechanics-based normalization for
the distribution function: the mean occupation number η.
As an aid in deﬁning the mean occupation number, we introduce the concept of
density of states
the density of states: Consider a particle of mass m, described quantum mechanically.
Suppose that the particle is known to be located in a volume dVx (as observed in
a speciﬁc inertial reference frame) and to have a spatial momentum in the region
dVp centered on p. Suppose, further, that the particle does not interact with any other
particles or ﬁelds; for example, ignore Coulomb interactions. (In portions of Chaps. 4
and 5, we include interactions.) Then how many single-particle quantum mechanical
states3 are available to the free particle? This question is answered most easily by
constructing (in some arbitrary inertial frame) a complete set of wave functions
for the particle’s spatial degrees of freedom, with the wave functions (i) conﬁned
to be eigenfunctions of the momentum operator and (ii) conﬁned to satisfy the
standard periodic boundary conditions on the walls of a box with volume dVx. For
simplicity, let the box have edge length L along each of the three spatial axes of the
Cartesian spatial coordinates, so dVx = L3. (This L is arbitrary and will drop out of
our analysis shortly.) Then a complete set of wave functions satisfying (i) and (ii) is
the set {ψj ,k,l} with
ψj ,k,l(x, y, z) =
1
L3/2ei(2π/L)(jx+ky+lz)e−iωt
(3.14a)
[cf., e.g., Cohen-Tannoudji, Diu, and Lalo¨e (1977, pp. 1440–1442), especially the
Comment at the end of this page range]. Here the demand that the wave function take
3.
A quantum mechanical state for a single particle is called an “orbital” in the chemistry literature (where
the particle is an election) and in the classic thermal physics textbook by Kittel and Kroemer (1980);
we shall use physicists’ more conventional but cumbersome phrase “single-particle quantum state,” and
also, sometimes, “mode.”
108
Chapter 3. Kinetic Theory

on the same values at the left and right faces of the box (x = −L/2 and x = +L/2),
at the front and back faces, and at the top and bottom faces (the demand for periodic
boundary conditions) dictates that the quantum numbers j, k, and l be integers.
The basis states (3.14a) are eigenfunctions of the momentum operator (ℏ/i)∇with
momentum eigenvalues
px = 2πℏ
L j ,
py = 2πℏ
L k ,
pz = 2πℏ
L l;
(3.14b)
correspondingly, the wave function’s frequency ω has the following values in Newto-
nian theory
and relativity
:
ℏω = E = p2
2m = 1
2m
2πℏ
L
2
(j2 + k2 + l2);
(3.14c)
ℏω = E =

m2 + p2 →m + E in the Newtonian limit.
(3.14d)
Equations (3.14b) tell us that the allowed values of the momentum are conﬁned
to lattice sites in 3-momentum space with one site in each cube of side 2πℏ/L.
Correspondingly, the total number of states in the region dVxdVp of phase space is
the number of cubes of side 2πℏ/L in the region dVp of momentum space:
dNstates =
dVp
(2πℏ/L)3 =
L3dVp
(2πℏ)3 =
dVxdVp
h3
.
(3.15)
This is true no matter how relativistic or nonrelativistic the particle may be.
Thus far we have considered only the particle’s spatial degrees of freedom. Particles
can also have an internal degree of freedom called “spin.” For a particle with spin s,
the number of independent spin states is
gs =
⎧
⎪⎨
⎪⎩
2s + 1
if m ̸= 0 (e.g., an electron, proton, or atomic nucleus)
2
if m = 0 and s > 0 [e.g., a photon (s = 1) or graviton (s = 2)]
1
if m = 0 and s = 0 (i.e., a hypothetical massless scalar particle)
(3.16)
A notable exception is each species of neutrino or antineutrino, which has nonzero
rest mass and spin 1/2, but gs = 1 rather than gs = 2s + 1 = 2.4 We call this number
of internal spin states gs the particle’s multiplicity.[It will turn out to play a crucial role
particle’s multiplicity
in computing the entropy of a system of particles (Chap. 4); thus, it places the imprint
of quantum theory on the entropy of even a highly classical system.]
Taking account of both the particle’s spatial degrees of freedom and its spin de-
gree of freedom, we conclude that the total number of independent quantum states
4.
The reason for the exception is the particle’s ﬁxed chirality: −1 for neutrinos and +1 for antineutrinos;
to have gs = 2, a spin-1/2 particle must admit both chiralities.
3.2 Phase Space and Distribution Function
109

available in the region dVxdVp ≡d2V of phase space is dNstates = (gs/h3)d2V, and
correspondingly the number density of states in phase space is
density of states in phase
space
Nstates ≡dNstates
d2V
= gs
h3.
(3.17)
[Relativistic remark: Note that, although we derived this number density of states
using a speciﬁc inertial frame, it is a frame-independent quantity, with a numerical
value depending only on Planck’s constant and (through gs) the particle’s rest mass m
and spin s.]
The ratio of the number density of particles to the number density of quantum
states is obviously the number of particles in each state (the state’s occupation number)
averaged over many neighboring states—but few enough that the averaging region is
small by macroscopic standards. In other words, this ratio is the quantum states’ mean
occupation number η:
mean occupation number
η =
N
Nstates
= h3
gs
N ;
i.e.,
N = Nstatesη = gs
h3η.
(3.18)
The mean occupation number η plays an important role in quantum statistical
mechanics, and its quantum roots have a profound impact on classical statistical
physics.
fermions and bosons
From quantum theory we learn that the allowed values of the occupation number
for a quantum state depend on whether the state is that of a fermion (a particle with
spin 1/2, 3/2, 5/2, . . .) or that of a boson (a particle with spin 0, 1, 2, . . .). For fermions,
no two particles can occupy the same quantum state, so the occupation number can
only take on the eigenvalues 0 and 1. For bosons, one can shove any number of
particles one wishes into the same quantum state, so the occupation number can take
on the eigenvalues 0, 1, 2, 3, . . . . Correspondingly, the mean occupation numbers
must lie in the ranges
0 ≤η ≤1 for fermions,
0 ≤η < ∞for bosons.
(3.19)
Quantum theory also teaches us that, when η ≪1, the particles, whether fermions
classical distinguishable
particles and classical
waves
or bosons, behave like classical, discrete, distinguishable particles; and when η ≫1
(possible only for bosons), the particles behave like a classical wave—if the particles
are photons (s = 1), like a classical electromagnetic wave; and if they are gravitons
(s = 2), like a classical gravitational wave. This role of η in revealing the particles’
physical behavior will motivate us frequently to use η as our distribution function
instead of N .
Of course η, like N , is a function of location in phase space, η(P, ⃗p) in relativity
with no inertial frame chosen; or η(t, x, p) in both relativity and Newtonian theory
when an inertial frame is in use.
110
Chapter 3. Kinetic Theory

EXERCISES
Exercise 3.3 **Practice and Example: Regimes of Particulate and Wave-Like
Behavior
(a) CygnusX-1isasourceofX-raysthathasbeenstudiedextensivelybyastronomers.
The observations (X-ray, optical, and radio) show that it is a distance r ∼6,000
light-years from Earth. It consists of a very hot disk of X-ray-emitting gas that
surrounds a black hole with mass 15M⊙, and the hole in turn is in a binary orbit
with a heavy companion star. Most of the X-ray photons have energies E ∼2
keV, their energy ﬂux arriving at Earth is F ∼10−10 W m−2, and the portion of
the disk that emits most of them has radius roughly 7 times that of the black
hole (i.e., R ∼300 km).5 Make a rough estimate of the mean occupation number
of the X-rays’ photon states. Your answer should be in the region η ≪1, so
the photons behave like classical, distinguishable particles. Will the occupation
number change as the photons propagate from the source to Earth?
(b) A highly nonspherical supernova in the Virgo cluster of galaxies (40 million light-
years from Earth) emits a burst of gravitational radiation with frequencies spread
over the band 0.5–2.0 kHz, as measured at Earth. The burst comes out in a time
of about 10 ms, so it lasts only a few cycles, and it carries a total energy of roughly
10−3M⊙c2, where M⊙= 2 × 1030 kg is the mass of the Sun. The emitting region
is about the size of the newly forming neutron-star core (10 km), which is small
comparedtothewavelengthofthewaves; soifoneweretotrytoresolvethesource
spatially by imaging the gravitational waves with a gravitational lens, one would
see only a blur of spatial size one wavelength rather than seeing the neutron star.
What is the mean occupation number of the burst’s graviton states? Your answer
should be in the region η ≫1, so the gravitons behave like a classical gravitational
wave.
3.3
3.3 Thermal-Equilibrium Distribution Functions
In Chap. 4, we introduce with care and explore in detail the concept of statistical
equilibrium—also called “thermal equilibrium.” That exploration will lead to a set of
distribution functions for particles that are in statistical equilibrium. In this section,
we summarize those equilibrium distribution functions, so as to be able to use them
for examples and applications of kinetic theory.
Ifacollectionofmanyidenticalparticlesisinthermalequilibriumintheneighbor-
hood of an event P, then, as we shall see in Chap. 4, there is a special inertial reference
frame (the mean rest frame of the particles near P) in which the distibution function
is isotropic, so the mean occupation number η is a function only of the magnitude |p|
5.
These numbers refer to what astronomers call Cygnus X-1’s soft (red) state. It also, sometimes, is seen
in a hard (blue) state.
3.3 Thermal-Equilibrium Distribution Functions
111

of the particle momentum and does not depend on the momentum’s direction. Equiv-
alently, η is a function of the particle’s energy. In the relativistic regime, we use two
different energies, one denoted E that includes the contribution of the particle’s rest
mass and the other denoted E that omits the rest mass and thus represents kinetic
energy (cf. Sec. 1.10):
E ≡E −m =

m2 + p2 −m →p2
2m in the low-velocity, Newtonian limit.
(3.20)
In the nonrelativistic, Newtonian regime we use only E = p2/(2m).
Most readers already know that the details of the thermal equilibrium are ﬁxed
by two quantities: the mean density of particles and the mean energy per particle,
or equivalently (as we shall see) by the chemical potential μ and the temperature T .
By analogy with our treatment of relativistic energy, we use two different chemical
potentials: one, ˜μ, that includes rest mass and the other,
μ ≡˜μ −m,
(3.21)
that does not. In the Newtonian regime we use only μ.
As we prove by an elegant argument in Chap. 4, in thermal equilibrium the
mean occupation number has the following form at all energies, relativistic or
nonrelativistic:
Fermi-Dirac and Bose-
Einstein distributions
η =
1
e(E−μ)/(kBT ) + 1
for fermions,
(3.22a)
η =
1
e(E−μ)/(kBT ) −1
for bosons.
(3.22b)
Here kB = 1.381 × 10−16 erg K−1 = 1.381 × 10−23 J K−1 is Boltzmann’s constant.
Equation (3.22a) for fermions is the Fermi-Dirac distribution; Eq. (3.22b) for bosons
is the Bose-Einstein distribution. In the relativistic regime, we can also write these
distribution functions in terms of the energy E that includes the rest mass as
η =
1
e(E−μ)/(kBT ) ± 1 =
1
e(E−˜μ)/(kBT ) ± 1.
(3.22c)
Notice that the equilibrium mean occupation number (3.22a) for fermions lies in
the range 0–1 as required, while that (3.22b) for bosons lies in the range 0 to ∞. In
the regime μ ≪−kBT , the mean occupation number is small compared to unity for
all particle energies E (since E is never negative; i.e., E is never less than m). This is
the domain of distinguishable, classical particles, and in it both the Fermi-Dirac and
Bose-Einstein distributions become
112
Chapter 3. Kinetic Theory

η ≃e−(E−μ)/(kBT ) = e−(E−˜μ)/(kBT )
when μ ≡˜μ −m ≪−kBT
(classical particles).
(3.22d)
This limiting distribution is the Boltzmann distribution.6
Boltzmann distribution
By scrutinizing the distribution functions (3.22), one can deduce that the larger
the temperature T at ﬁxed μ, the larger will be the typical energies of the particles;
the larger the chemical potential μ at ﬁxed T , the larger will be the total density of
particles [see Ex. 3.4 and Eqs. (3.39)]. For bosons, μ must always be negative or zero,
that is, ˜μ cannot exceed the particle rest mass m; otherwise, η would be negative at low
energies, which is physically impossible. For bosons with μ extremely close to zero,
thereexisthugenumbersofvery-low-energyparticles, leadingquantummechanically
to a Bose-Einstein condensate; we study such condensates in Sec. 4.9.
In the special case that the particles of interest can be created and destroyed
completely freely, with creation and destruction constrained only by the laws of
4-momentum conservation, the particles quickly achieve a thermal equilibrium in
which the relativistic chemical potential vanishes, ˜μ = 0 (as we shall see in Sec. 5.5).
For example, inside a box whose walls are perfectly emitting and absorbing and have
temperature T , the photons acquire the mean occupation number (3.22b) with zero
chemical potential, leading to the standard blackbody (Planck) form
Planck distribution
η =
1
ehν/(kBT ) −1,
N = 2
h3
1
ehν/(kBT ) −1,
Iν =
(2h/c2)ν3
ehν/(kBT ) −1.
(3.23)
(Here we have set E = hν, where ν is the photon frequency as measured in the box’s
rest frame, and in the third expression we have inserted the factor c−2, so that Iν will
be in ordinary units.)
By contrast, if one places a ﬁxed number of photons inside a box whose walls
cannot emit or absorb them but can scatter them, exchanging energy with them in
the process, then the photons will acquire the Bose-Einstein distribution (3.22b) with
temperature T equal to that of the walls and with nonzero chemical potential μ ﬁxed
by the number of photons present; the more photons there are, the larger will be the
chemical potential.
EXERCISES
Exercise 3.4 **Example: Maxwell Velocity Distribution
Consider a collection of thermalized, classical particles with nonzero rest mass, so
they have the Boltzmann distribution (3.22d). Assume that the temperature is low
enough (kBT ≪mc2) that they are nonrelativistic.
(a) Explain why the total number density of particles n in physical space (as measured
in the particles’ mean rest frame) is given by the integral n =

N dVp. Show
6.
Lynden-Bell (1967) identiﬁes a fourth type of thermal distribution that occurs in the theory of violent
relaxation of star clusters. It corresponds to individually distinguishable, classical particles (in his case
stars with a range of masses) that obey the same kind of exclusion principle as fermions.
3.3 Thermal-Equilibrium Distribution Functions
113

that n ∝eμ/kBT , and derive the proportionality constant. [Hint: Use spherical
coordinates in momentum space, so dVp = 4πp2dp with p ≡|p|.] Your answer
should be Eq. (3.39a) below.
(b) Explain why the mean energy per particle is given by ¯E = n−1 
(p2/2m)N dVp.
Show that ¯E = 3
2kBT .
(c) ShowthatP(v)dv ≡(probability thatarandomlychosenparticlewillhavespeed
v ≡|v| in the range dv) is given by
P(v) =
4
√π
v2
v3
o
e−v2/v2
o,
where
vo =
&
2kBT
m
.
(3.24)
This is called the Maxwell velocity distribution; it is graphed in Fig. 3.6a. Notice
that the peak of the distribution is at speed vo.
[Side remark: In the normalization of probability distributions such as this one,
you will often encounter integrals of the form
 ∞
0
x2ne−x2dx. You can evaluate
this quickly via integration by parts, if you have memorized that
 ∞
0
e−x2dx =
√π/2.]
(d) Consider particles conﬁned to move in a plane or in one dimension (on a line).
What is their speed distribution P (v) and at what speed does it peak?
Exercise 3.5 Problem: Maxwell-J¨utner Velocity Distribution for Thermalized,
Classical, Relativistic Particles
Show that for thermalized, classical relativistic particles the probability distribution
for the speed [relativistic version of the Maxwell distribution (3.24)] is
1.0
0.8
0.6
0.4
0.2
0.0
0.6
0.5
0.4
0.3
0.2
0.1
0.0
0.0
0.0
0.2
0.4
0.6
0.8
1.0
0.5
1.0
1.5
(a)
(b)
2.0
2.5
3.0
v/vo
P(v)
—
Pmax
v
vo = 0.1
vo = 0.5
vo = 1
vo = 2
voP(v)
FIGURE 3.6 (a) Maxwell velocity distribution for thermalized, classical, nonrelativistic particles.
(b) Extension of the Maxwell velocity distribution into the relativistic domain. In both plots
vo =

2kBT/m.
114
Chapter 3. Kinetic Theory

P (v) =
2/v2
0
K2(2/v2
0)
v2
(1 −v2)5/2 exp
'
−
2/v2
o
√
1 −v2
(
,
where
vo =
&
2kBT
m
.
(3.25)
Where K2 is the modiﬁed Bessel function of the second kind and order 2. This is
sometimes called the Maxwell-J¨utner distribution, and it is plotted in Fig. 3.6b for
a sequence of four temperatures ranging from the nonrelativistic regime kBT ≪
m toward the ultrarelativistic regime kBT ≫m. In the ultrarelativistic regime the
particles are (almost) all moving at very close to the speed of light, v = 1.
Exercise 3.6 Example and Challenge: Radiative Processes
We have described distribution functions for particles and photons and the forms
that they have in thermodynamic equilibrium. An extension of these principles can
be used to constrain the manner in which particles and photons interact, speciﬁcally,
to relate the emission and absorption of radiation.
(a) Consider a two-level (two-state) electron system with energy separation E = hν0.
Suppose that an electron can transition with a probability per unit time, A, from
the upper level (u) to the lower level (l), creating a photon in a speciﬁc state. Use
the Boltzmann distribution, ignoring degeneracy, Eq. (3.22d), and the expression
for the mean photon occupation number, Eq. (3.23), to show that, when the elec-
trons and photons are in thermal equilibrium at the same temperature T , then:
Anu + Anuηγ = Anlηγ ,
(3.26)
where nl,u are the number densities of the electrons in the two states, and ηγ is
the photon mean occupation number.
(b) The three terms in Eq. (3.26) are often called the rates per unit volume for spon-
taneous emission, stimulated emission, and (stimulated) absorption, respectively.
(The second and third terms are sometimes expressed using Einstein B coefﬁ-
cients.) The expressions Anu, Anuηγ, and Anlηγ for the rates of these three types
of transition are commonly (and usually correctly) assumed to apply out of ther-
modynamic equilibrium as well as in equilibrium. Discuss brieﬂy two conditions
that need to be satisﬁed for this to be so: that all three types of transition proceed
in a manner that is independent of anything else present, and that the stimulated
transitions are time reversible.7 What additional condition needs to be satisﬁed if
the electron system is more complex than a two-level system? (We return to these
issues in the context of cosmology, in Secs. 28.4.4 and 28.6.3.)
(c) Typical transitions have some duration τ, which implies that the photons will be
emitted with a distribution of frequencies with width ν ∼τ −1 about ν0. They
may also not be emitted isotropically and can carry polarization. Denote the state
of a photon by its frequency ν, direction of travel ), and polarization i = 1 or 2,
7.
These principles are quite classical in origin but the full justiﬁcation of the heuristic argument presented
here requires quantum electrodynamics.
3.3 Thermal-Equilibrium Distribution Functions
115

and denote by P i
ν)
 the photons’ probability distribution, normalized such that
i

dν dP i
ν)
 = 1, with d an element of solid angle around ). Now deﬁne a
classical emissivity and a classical absorption coefﬁcient by
ji
ν)
 ≡nuhνAP i
ν)
,
κi ≡nlA(1 −e−hν0/(kBTe))P i
ν)
 c2/ν2,
(3.27)
respectively, where Te is the electron temperature. Interpret these two quantities
and prove Kirchhoff’s law,namely, that ji
ν)
/κi is the blackbody radiation intensity
for one polarization mode. What happens when hν0 ≪kBTe?
(d) Further generalize the results in part c by assuming that, instead of occupying
just two states, the electrons have a continuous distribution of momenta and ra-
diate throughout this distribution. Express the classical emissivity and absorption
coefﬁcient as integrals over electron momentum space.
(e) Finally, consider the weak nuclear transformation ν + n →e + p, where the
neutron n and the proton p can be considered as stationary. (This is important
in the early universe, as we discuss further in Sec. 28.4.2.) Explain carefully why
the rate at which this transformation occurs can be expressed as
dnp
dt = nn
 dVpν
h3 ην
 *
h6W
m5
e
δ(Eν + mn −Ee −mp)
+ 
2
dVpe
h3 (1 −ηe)

(3.28)
for some W. It turns out that W is a constant (Weinberg, 2008). What is the
corresponding rate for the inverse reaction?
Exercise 3.7 **Example: Observations of Cosmic Microwave Radiation
from Earth
The universe is ﬁlled with cosmic microwave radiation left over from the big bang. At
eacheventinspacetimethemicrowaveradiationhasameanrestframe.Asseeninthat
mean rest frame the radiation’s distribution function η is almost precisely isotropic
and thermal with zero chemical potential:
η =
1
ehν/(kBTo) −1,
with
To = 2.725 K.
(3.29)
Here ν is the frequency of a photon as measured in the mean rest frame.
(a) Show that the speciﬁc intensity of the radiation as measured in its mean rest frame
has the Planck spectrum, Eq. (3.23). Plot this speciﬁc intensity as a function of
frequency, and from your plot determine the frequency of the intensity peak.
(b) Show that η can be rewritten in the frame-independent form
η =
1
e−⃗p.⃗uo/(kBTo) −1 ,
(3.30)
where ⃗p is the photon 4-momentum, and ⃗uo is the 4-velocity of the mean rest
frame. [Hint: See Sec. 2.6 and especially Eq. (2.29).]
116
Chapter 3. Kinetic Theory

(c) In actuality, Earth moves relative to the mean rest frame of the microwave back-
ground with a speed v of roughly 400 km s−1toward the Hydra-Centaurus region
of the sky. An observer on Earth points his microwave receiver in a direction that
makes an angle θ with the direction of that motion, as measured in Earth’s frame.
Show that the speciﬁc intensity of the radiation received is precisely Planckian in
form [Eqs. (3.23)], but with a direction-dependent Doppler-shifted temperature
T = To
* √
1 −v2
1 −v cos θ
+
.
(3.31)
Note that this Doppler shift of T is precisely the same as the Doppler shift of the
frequency of any speciﬁc photon [Eq. (2.33)]. Note also that the θ dependence
corresponds to an anisotropy of the microwave radiation as seen from Earth.
Show that because Earth’s velocity is small compared to the speed of light, the
anisotropy is very nearly dipolar in form. Measurements by the WMAP satellite
give To = 2.725 K and (averaged over a year) an amplitude of 3.346 × 10−3 K for
the dipolar temperature variations (Bennett et al., 2003). What, precisely, is the
value of Earth’s year-averaged speed v?
3.4
3.4 Macroscopic Properties of Matter as Integrals over Momentum Space
3.4.1
3.4.1 Particle Density n, Flux S, and Stress Tensor T
If one knows the Newtonian distribution function N = (gs/h3)η as a function of
momentum p at some location (x, t) in space and time, one can use it to compute
various macroscopic properties of the particles.
From the deﬁnition N ≡dN/dVxdVp of the distribution function, it is clear that
the number density of particles n(x, t) in physical space is given by the integral
Newtonian particle density
n = dN
dVx
=

dN
dVxdVp
dVp =

N dVp.
(3.32a)
Similarly, the number of particles crossing a unit surface in the y-z plane per unit time
(i.e., the x component of the ﬂux of particles) is
Sx =
dN
dydzdt =

dN
dxdydzdVp
dx
dt dVp =

N px
m dVp,
where dx/dt = px/m is the x component of the particle velocity. This and the anal-
ogous equations for Sy and Sz can be combined into a single geometric, coordinate-
independent integral for the vectorial particle ﬂux:
Newtonian particle ﬂux
S =

N p
dVp
m .
(3.32b)
3.4 Macroscopic Properties of Matter as Integrals over Momentum Space
117

Notice that, if we multiply this S by the particles’ mass m, the integral becomes the
momentum density:
Newtonian momentum
density
G = mS =

N p dVp.
(3.32c)
Finally, since the stress tensor T is the ﬂux of momentum [Eq. (1.33)], its j-x compo-
nent (j component of momentum crossing a unit area in the y-z plane per unit time)
must be
Tjx =

dN
dydzdtdVp
pj dVp =

dN
dxdydzdVp
dx
dt pjdVp =

N pj
px
m dVp.
This and the corresponding equations for Tjy and Tjz can be collected together into
a single geometric, coordinate-independent integral:
Newtonian stress tensor
Tjk =

N pjpk
dVp
m ,
i.e.,
T =

N p ⊗p
dVp
m .
(3.32d)
Notice that the number density n is the zeroth moment of the distribution function
in momentum space [Eq. (3.32a)], and aside from factors 1/m, the particle ﬂux vector is
the ﬁrst moment [Eq. (3.32b)], and the stress tensor is the second moment [Eq. (3.32d)].
All three moments are geometric, coordinate-independent quantities, and they are
the simplest such quantities that one can construct by integrating the distribution
function over momentum space.
3.4.2
3.4.2 Relativistic Number-Flux 4-Vector ⃗S and Stress-Energy Tensor TTT
When we switch from Newtonian theory to special relativity’s 4-dimensional space-
time viewpoint, we require that all physical quantities be described by geometric,
frame-independent objects (scalars,
vectors,
tensors, . . .) in 4-dimensional
spacetime. We can construct such objects as momentum-space integrals over the
frame-independent, relativistic distribution function N (P, ⃗p) = (gs/h3)η. The
frame-independent quantities that can appear in these integrals are (i) N itself,
(ii) the particle 4-momentum ⃗p, and (iii) the frame-independent integration ele-
ment dVp/E [Eq. (3.7b)], which takes the form dpxdpydpz/

m2 + p2 in any inertial
reference frame. By analogy with the Newtonian regime, the most interesting such
integrals are the lowest three moments of the distribution function:
R ≡

N
dVp
E ;
(3.33a)
⃗S ≡

N ⃗p
dVp
E ,
i.e., Sμ ≡

N pμ dVp
E ;
(3.33b)
TTT ≡

N ⃗p ⊗⃗p
dVp
E ,
i.e., T μν ≡

N pμpν dVp
E .
(3.33c)
118
Chapter 3. Kinetic Theory

Here and throughout this chapter, relativistic momentum-space integrals are taken
over the entire mass hyperboloid unless otherwise speciﬁed.
We can learn the physical meanings of each of the momentum-space integrals
(3.33) by introducing a speciﬁc but arbitrary inertial reference frame and using it to
perform a 3+1 split of spacetime into space plus time [cf. the paragraph containing
Eq. (2.28)]. When we do this and rewrite N as dN/dVxdVp, the scalar ﬁeld R
of Eq. (3.33a) takes the form
R =

dN
dVxdVp
1
E dVp
(3.34)
(where of course dVx = dxdydz and dVp = dpxdpydpz). This is the sum, over all
particles in a unit 3-volume, of the inverse energy. Although it is intriguing that
this quantity is a frame-independent scalar, it is not a quantity that appears in any
important way in the laws of physics.
By contrast, the 4-vector ﬁeld ⃗S of Eq. (3.33b) plays a very important role in
physics. Its time component in our chosen frame is
S0 =

dN
dVxdVp
p0
E dVp =

dN
dVxdVp
dVp
(3.35a)
(since p0 and E are just different notations for the same thing—the relativistic energy

m2 + p2 of a particle). Obviously, this S0 is the number of particles per unit spatial
volume as measured in our chosen inertial frame:
S0 = n = (number density of particles).
(3.35b)
The x component of ⃗S is
Sx =

dN
dVxdVp
px
E dVp =

dN
dxdydz dVp
dx
dt dVp =

dN
dtdydz dVp
dVp,
(3.35c)
which is the number of particles crossing a unit area in the y-z plane per unit time
(i.e., the x component of the particle ﬂux); similarly for other directions j:
Sj = (j component of the particle ﬂux vector S).
(3.35d)
[In Eq. (3.35c), the second equality follows from
pj
E = pj
p0 = dxj/dζ
dt/dζ = dxj
dt = (j component of velocity),
(3.35e)
where ζ is the afﬁne parameter such that ⃗p = d ⃗x/dζ.] Since S0 is the particle number
number-ﬂux 4-vector
density and Sj is the particle ﬂux, ⃗S [Eq. (3.33b)] must be the number-ﬂux 4-vector
introduced and studied in Sec. 2.12.3. Notice that in the Newtonian limit, where p0 =
E →m, the temporal and spatial parts of the formula ⃗S =

N ⃗p (dVp/E) reduce
3.4 Macroscopic Properties of Matter as Integrals over Momentum Space
119

to S0 =

N dVp and S =

N p(dVp/m), respectively, which are the coordinate-
independent expressions (3.32a) and (3.32b) for the Newtonian number density of
particles and ﬂux of particles, respectively.
Turn to the quantity TTT deﬁned by the integral (3.33c). When we perform a 3+1
split of it in our chosen inertial frame, we ﬁnd the following for its various parts:
T μ0 =

dN
dVxdVp
pμp0dVp
p0 =

dN
dVxdVp
pμdVp
(3.36a)
is the μ component of 4-momentum per unit volume (i.e., T 00 is the energy density,
and T j0 is the momentum density). Also,
T μx =

dN
dVxdVp
pμpx dVp
p0 =

dN
dxdydzdVp
dx
dt pμdVp =

dN
dtdydzdVp
pμdVp
(3.36b)
istheamountofμcomponentof4-momentumthatcrossesaunitareainthey-z plane
per unit time (i.e., it is the x component of ﬂux of μ component of 4-momentum).
More speciﬁcally, T 0x is the x component of energy ﬂux (which is the same as the
momentum density T x0), and T jx is the x component of spatial-momentum ﬂux—
or, equivalently, the jx component of the stress tensor. These and the analogous
expressions and interpretations of T μy and T μz can be summarized by
T 00 = (energy density),
T j0 = (momentum density) = T 0j = (energy ﬂux),
T jk = (stress tensor).
(3.36c)
Therefore [cf. Eq. (2.67f)], the TTT of Eq. (3.33c) must be the stress-energy tensor
stress-energy tensor
introduced and studied in Sec. 2.13. Notice that in the Newtonian limit, where E →m,
the coordinate-independent Eq. (3.33c) for the spatial part of the stress-energy tensor
(the stress) becomes

N p ⊗p dVp/m, which is the same as our coordinate-
independent Eq. (3.32d) for the stress tensor.
3.5
3.5 Isotropic Distribution Functions and Equations of State
3.5.1
3.5.1 Newtonian Density, Pressure, Energy Density, and Equation of State
Let us return to Newtonian theory.
If the Newtonian distribution function is isotropic in momentum space (i.e., is
a function only of the magnitude p ≡|p]=

p2
x + p2
y + p2
z of the momentum, as
is the case, e.g., when the particle distribution is thermalized), then the particle ﬂux
S vanishes (equal numbers of particles travel in all directions), and the stress tensor
is isotropic: T = P g, or Tjk = P δjk. Thus, it is the stress tensor of a perfect ﬂuid.
[Here P is the isotropic pressure, and g is the metric tensor of Euclidian 3-space, with
Cartesian components equal to the Kronecker delta; Eq. (1.9f).] In this isotropic case,
the pressure can be computed most easily as 1/3 the trace of the stress tensor (3.32d):
120
Chapter 3. Kinetic Theory

P = 1
3Tjj = 1
3

N (p2
x + p2
y + p2
z)
dVp
m
= 1
3
 ∞
0
N p24πp2dp
m
= 4π
3m
 ∞
0
N p4 dp.
(3.37a)
Here in the third step we have written the momentum-volume element in spherical
Newtonian pressure
polar coordinates as dVp = p2 sin θdθdφdp and have integrated over angles to get
4πp2dp. Similarly, we can reexpress the number density of particles (3.32a) and the
corresponding mass density as
Newtonian particle and
mass density
n = 4π
 ∞
0
N p2dp,
ρ ≡mn = 4πm
 ∞
0
N p2 dp.
(3.37b)
Finally, because each particle carries an energy E = p2/(2m), the energy density in
this isotropic case (which we shall denote by U) is 3/2 the pressure:
Newtonian energy density
U =

p2
2mN dVp = 4π
2m
 ∞
0
N p4dp = 3
2P
(3.37c)
[cf. Eq. (3.37a)].
If we know the distribution function for an isotropic collection of particles,
Eqs. (3.37) give us a straightforward way of computing the collection’s number density
of particles n, mass density ρ = nm, perfect-ﬂuid energy density U, and perfect-ﬂuid
pressure P as measured in the particles’ mean rest frame. For a thermalized gas, the
distribution functions (3.22a), (3.22b), and (3.22d) [with N = (gs/h3)η] depend on
two parameters: the temperature T and chemical potential μ, so this calculation gives
n, U, and P in terms of μ and T . One can then invert n(μ, T ) to get μ(n, T ) and
insert the result into the expressions for U and P to obtain equations of state for
thermalized, nonrelativistic particles:
equations of state
U = U(ρ, T ) ,
P = P (ρ, T ) .
(3.38)
For a gas of nonrelativistic, classical particles, the distribution function is Boltz-
mann [Eq. (3.22d)], N = (gs/h3)e(μ−E)/(kBT ), with E = p2/(2m), and this proce-
thermalized, classical,
nonrelativistic gas
dure gives, quite easily (Ex. 3.8):
n = gseμ/(kBT )
λ3
T dB
= gs
h3(2πmkBT )3/2eμ/(kBT ),
(3.39a)
U = 3
2nkBT ,
P = nkBT .
(3.39b)
Notice that the mean energy per particle is (cf. Ex. 3.4b)
¯E = 3
2kBT .
(3.39c)
3.5 Isotropic Distribution Functions and Equations of State
121

In Eq. (3.39a), λT dB ≡h/

2πmkBT is the particles’ thermal de Broglie wavelength:
the wavelength of Schr¨odinger wave-function oscillations for a particle with thermal
kinetic energy E = πkBT . Note that the classical regime η ≪1(i.e., μ/(kBT ) ≪−1),
in which our computation is being performed, corresponds to a mean number of
particles in a thermal de Broglie wavelength small compared to 1, nλ3
T dB ≪1, which
should not be surprising.
3.5.2
3.5.2 Equations of State for a Nonrelativistic Hydrogen Gas
As an application, consider ordinary matter. Figure 3.7 shows its physical nature as a
function of density and temperature, near and above room temperature (300 K). We
study solids (lower right) in Part IV, ﬂuids (lower middle) in Part V, and plasmas
(middle) in Part VI.
Our kinetic-theory tools are well suited to any situation where the particles have
mean free paths large compared to their sizes. This is generally true in plasmas and
sometimes in ﬂuids (e.g., air and other gases, but not water and other liquids), and
even sometimes in solids (e.g., electrons in a metal). Here we focus on a nonrelativistic
10
9
8
7
6
5
4
3
2
–28
–24
–20
–16
–12
–8
–4
0
4
8
relativistic
log10T (K)
log10ρ (g cm–3)
nonrelativistic
nonrelativistic
relativistic
ionized
neutral
classical
quantum
Plasma
Fluid
Solid
electron
degenerate
FIGURE3.7 Physicalnatureofhydrogenatvariousdensitiesandtemperatures.Theplasmaregime
is discussed in great detail in Part VI, and the equation of state in this regime is Eq. (3.40). The
region of relativistic electron degeneracy (to the right of the vertical dotted line) is analyzed in
Sec. 3.5.4, and that for the nonrelativistic regime (between slanted solid line and vertical dotted
line) in the second half of Sec. 3.5.2. The boundary between the plasma regime and the electron-
degenerate regime (slanted solid line) is Eq. (3.41); that between nonrelativistic degeneracy and
relativistic degeneracy (vertical dotted line) is Eq. (3.46). The upper relativistic/nonrelativistic
boundary is governed by electron-positron pair production (Ex. 5.9 and Fig. 5.7) and is only
crudely approximated by the upper dashed line. The ionized-neutral boundary is governed by
the Saha equation (Ex. 5.10 and Fig. 20.1) and is crudely approximated by the lower dashed
line. For a more accurate and detailed version of this ﬁgure, including greater detail on the
plasma regime and its boundaries, see Fig. 20.1.
122
Chapter 3. Kinetic Theory

plasma (i.e., the region of Fig. 3.7 that is bounded by the two dashed lines and the
slanted solid line). For concreteness and simplicity, we regard the plasma as made
solely of hydrogen.8
A nonrelativistic hydrogen plasma consists of a mixture of two ﬂuids (gases): free
nondegenerate hydrogen
gas
electrons and free protons, in equal numbers. Each ﬂuid has a particle number density
n = ρ/mp, where ρ is the total mass density and mp is the proton mass. (The electrons
are so light that they do not contribute signiﬁcantly to ρ.) Correspondingly, the energy
density and pressure include equal contributions from the electrons and protons and
are given by [cf. Eqs. (3.39b)]
U = 3(kB/mp)ρT ,
P = 2(kB/mp)ρT .
(3.40)
In zeroth approximation, the high-temperature boundary of validity for this equa-
tion of state is the temperature Trel = mec2/kB = 6 × 109 K, at which the electrons
become highly relativistic (top dashed line in Fig. 3.7). In Ex. 5.9, we compute the
thermal production of electron-positron pairs in the hot plasma and thereby discover
that the upper boundary is actually somewhat lower than this (Figs. 5.7 and 20.1).
The bottom dashed line in Fig. 3.7 is the temperature Tion ∼(ionization energy of
hydrogen)/(a few kB) ∼104 K, at which electrons and protons begin to recombine
and form neutral hydrogen. In Ex. 5.10 on the Saha equation, we analyze the con-
ditions for ionization-recombination equilibrium and thereby reﬁne this boundary
(Fig. 20.1). The solid right boundary is the point at which the electrons cease to be-
have like classical particles, because their mean occupation number ηe ceases to be
≪1. As one can see from the Fermi-Dirac distribution (3.22a), for typical electrons
(which have energies E ∼kBT ), the regime of classical behavior (ηe ≪1; to the left
of the solid line) is μe ≪−kBT and the regime of strong quantum behavior (ηe ≃1;
electron degeneracy; to the right of the solid line) is μe ≫+kBT . The slanted solid
boundary in Fig. 3.7 is thus the location μe = 0, which translates via Eq. (3.39a) to
ρ = ρdeg ≡2mp/λ3
TdB = (2mp/h3)(2πmekBT )3/2 = 0.00808(T /104 K)3/2 g cm−3.
(3.41)
Although the hydrogen gas is degenerate to the right of this boundary, we can still
degenerate hydrogen gas
compute its equation of state using our kinetic-theory equations (3.37), so long as we
use the quantum mechanically correct distribution function for the electrons—the
Fermi-Dirac distribution (3.22a).9 In this electron-degenerate region, μe ≫kBT , the
electron mean occupation number ηe = 1/(e(E−μe)/(kBT ) + 1) has the form shown
8.
For both astrophysical and laboratory applications, the non-hydrogen elemental composition often
matters, and involves straightforward corrections to purely hydrogen formulae given here.
9.
Our kinetic-theory analysis and the Fermi-Dirac distribution ignore Coulomb interactions between the
electrons, and between the electrons and the ions. They thereby miss so-called Coulomb corrections to
the equation of state (Sec. 22.6.3) and other phenomena that are often important in condensed matter
physics, but rarely important in astrophysics.
3.5 Isotropic Distribution Functions and Equations of State
123

1.0
0.8
0.6
0.4
0.2
0.00.0
0.2
0.4
0.6
0.8
1.0
1.2
E/μe
4kBT/μe
ηe
FIGURE 3.8 The Fermi-Dirac distribution function for electrons in the
nonrelativistic, degenerate regime kBT ≪μe ≪me, with temperature such
that kBT/μe = 0.03. Note that ηe drops from near 1 to near 0 over the range
μe −2kBT <∼E <∼μe + 2kBT . See Ex. 3.11b.
in Fig. 3.8 and thus can be well approximated by ηe = 1 for E = p2/(2me) < μe and
ηe = 0 for E > μe; or equivalently by
ηe = 1 for p < pF ≡

2meμe,
ηe = 0 for p > pF .
(3.42)
Here pF is called the Fermi momentum.(The word “degenerate” refers to the fact that
Fermi momentum
almost all the quantum states are fully occupied or are empty; i.e., ηe is everywhere
nearly 1 or 0.) By inserting this degenerate distribution function [or, more precisely,
Ne = (2/h3)ηe] into Eqs. (3.37) and integrating, we obtain ne ∝pF 3 and Pe ∝pF 5.
By then setting ne = np = ρ/mp and solving for pF ∝n1/3
e
∝ρ1/3 and inserting into
the expression for Pe and evaluating the constants, we obtain (Ex. 3.9) the following
equation of state for the electron pressure:
Pe = 1
20
 3
π
2/3 mec2
λ3
c
*
ρ
mp/λ3
c
+5/3
.
(3.43)
Here
λc = h/(mec) = 2.426 × 10−10 cm
(3.44)
is the electron Compton wavelength.
The rapid growth Pe ∝ρ5/3 of the electron pressure with increasing density is due
to the degenerate electrons’ being conﬁned by the Pauli Exclusion Principle to regions
of ever-shrinking size, causing their zero-point motions and associated pressure to
grow. By contrast, the protons, with their far larger rest masses, remain nondegenerate
[until their density becomes (mp/me)3/2 ∼105 times higher than Eq. (3.41)], and so
124
Chapter 3. Kinetic Theory

their pressure is negligible compared to that of the electrons: the total pressure is
P = Pe = Eq. (3.43)
(3.45)
in the regime of nonrelativistic electron degeneracy. This is the equation of state for
the interior of a low-mass white-dwarf star and for the outer layers of a high-mass
white dwarf—aside from tiny corrections due to Coulomb interactions. In Sec. 13.3.2
we shall see how it can be used to explore the structures of white dwarfs. It is also the
equation of state for a neutron star, with me replaced by the rest mass of a neutron mn
(since neutron degeneracy pressure dominates over that due to the star’s tiny number
of electrons and protons) and ρ/mp replaced by the number density of neutrons—
except that for neutron stars there are large corrections due to the strong nuclear force
(see, e.g., Shapiro and Teukolsky, 1983).
When the density of hydrogen in this degenerate regime is pushed on upward to
ρrel deg =
8πmp
3λ3
c
≃9.8 × 105 g cm−3
(3.46)
(dotted vertical line in Fig. 3.7), the electrons’ zero-point motions become relativis-
tically fast (the electron chemical potential μe becomes of order mec2 and the Fermi
momentum pF of order mec), so the nonrelativistic, Newtonian analysis fails, and the
matter enters a domain of relativistic degeneracy (Sec. 3.5.4). Both domains, nonrel-
ativistic degeneracy (μe ≪mec2) and relativistic degeneracy (μe >∼mec2), occur for
matter inside a massive white-dwarf star—the type of star that the Sun will become
when it dies (see Shapiro and Teukolsky, 1983). In Sec. 26.3.5, we shall see how general
relativity (spacetime curvature) modiﬁes a star’s structure. It also helps force sufﬁ-
ciently massive white dwarfs to collapse (Sec. 6.10 of Shapiro and Teukolsky, 1983).
The (almost) degenerate Fermi-Dirac distribution function shown in Fig. 3.8 has
a thermal tail whose energy width is 4kBT /μe. As the temperature T is increased,
the number of electrons in this tail increases, thereby increasing the electrons’ total
energy Etot. This increase is responsible for the electrons’ speciﬁc heat (Ex. 3.11)—
a quantity of importance for both the electrons in a metal (e.g., a copper wire) and
the electrons in a white-dwarf star. The electrons dominate the speciﬁc heat when
the temperature is sufﬁciently low; but at higher temperatures it is dominated by the
energies of sound waves (see Ex. 3.12, where we use the kinetic theory of phonons to
compute the sound waves’ speciﬁc heat).
3.5.3
3.5.3 Relativistic Density, Pressure, Energy Density, and Equation of State
Now we turn to the relativistic domain of kinetic theory, initially for a single species
of particle with rest mass m and then (in the next subsection) for matter composed of
electrons and protons.
The relativistic mean rest frame of the particles, at some event P in spacetime, is
that frame in which the particle ﬂux S vanishes. We denote by ⃗urf the 4-velocity of
this mean rest frame. As in Newtonian theory (Sec. 3.5.2), we are especially interested
3.5 Isotropic Distribution Functions and Equations of State
125

in distribution functions N that are isotropic in the mean rest frame: distribution
functions that depend on the magnitude |p| ≡p of the spatial momentum of a particle
but not on its direction—or equivalently, that depend solely on the particles’ energy
E = −⃗urf . ⃗p
expressed in frame-independent form [Eq. (2.29)],
E = p0 =

m2 + p2
in mean rest frame.
(3.47)
Such isotropy is readily produced by particle collisions (Sec. 3.7).
Notice that isotropy in the mean rest frame [i.e., N = N (P, E)] does not imply
isotropy in any other inertial frame. As seen in some other (primed) frame, ⃗urf will
have a time component u0′
rf = γ and a space component u′rf = γ V [where V is the
mean rest frame’s velocity relative to the primed frame, and γ = (1 −V2)−1/2]; and
correspondingly, in the primed frame, N will be a function of
E = −⃗urf . ⃗p = γ [(m2 + p′2)
1
2 −V . p′],
(3.48)
which is anisotropic: it depends on the direction of the spatial momentum p′ relative
tothevelocityV oftheparticle’smeanrestframe.Anexampleisthecosmicmicrowave
radiation as viewed from Earth (Ex. 3.7).
AsinNewtoniantheory, isotropygreatlysimpliﬁesthemomentum-spaceintegrals
(3.33) that we use to compute macroscopic properties of the particles: (i) The inte-
grands of the expressions Sj =

N pj(dVp/E) and T j0 = T 0j =

N pjp0(dVp/E)
for the particle ﬂux, energy ﬂux, and momentum density are all odd in the
momentum-space coordinate pj and therefore give vanishing integrals: Sj = T j0 =
T 0j = 0. (ii) The integral T jk =

N pjpkdVp/E produces an isotropic stress ten-
sor, T jk = Pgjk = Pδjk, whose pressure is most easily computed from its trace,
P = 1
3T jj. Using these results and the relations |p| ≡p for the magnitude of the mo-
mentum, dVp = 4πp2dp for the momentum-space volume element, and E = p0 =

m2 + p2 for the particle energy, we can easily evaluate Eqs. (3.33) for the particle
number density n = S0, the total density of mass-energy T 00 (which we denote ρ—
the same notation as we use for mass density in Newtonian theory), and the pressure
P. The results are
relativistic particle density,
mass-energy density, and
pressure
n ≡S0 =

N dVp = 4π
 ∞
0
N p2dp,
(3.49a)
ρ ≡T 00 =

N EdVp = 4π
 ∞
0
N Ep2dp,
(3.49b)
P = 1
3

N p2dVp
E
= 4π
3
 ∞
0
N
p4dp

m2 + p2 .
(3.49c)
3.5.4
3.5.4 Equation of State for a Relativistic Degenerate Hydrogen Gas
Return to the hydrogen gas whose nonrelativistic equations of state were computed in
Sec. 3.5.1. As we deduced there, at densities ρ >∼105 g cm−3 (near and to the right of
126
Chapter 3. Kinetic Theory

the vertical dotted line in Fig. 3.7) the electrons are squeezed into such tiny volumes
that their zero-point energies are >∼mec2, forcing us to treat them relativistically.
We can do so with the aid of the following approximation for the relativistic Fermi-
relativistically degenerate
electrons
Dirac mean occupation number ηe = 1/[e(E−˜μe/(kBT )) + 1]:
ηe ≃1 for E < ˜μe ≡EF; i.e., for p < pF =

E2
F −m2,
(3.50)
ηe ≃0 for E > EF; i.e., for p > pF .
(3.51)
Here EF is called the relativisticFermi energy and pF the relativistic Fermi momentum.
By inserting this ηe along with Ne = (2/h3)ηe into the integrals (3.49) for the electron
number density ne, total density of mass-energy ρe, and pressure Pe, and performing
the integrals (Ex. 3.10), we obtain results that are expressed most simply in terms of
a parameter t (not to be confused with time) deﬁned by
EF ≡˜μe ≡me cosh(t/4),
pF ≡

E2
F −m2
e ≡me sinh(t/4).
(3.52a)
The results are
ne = 8π
3λ3
c
pF
me
3
= 8π
3λ3
c
sinh3(t/4),
(3.52b)
ρe = 8πme
λ3
c
 pF/me
0
x2
1 + x2 dx = πme
4λ3
c
[sinh(t) −t],
(3.52c)
Pe = 8πme
λ3
c
 pF/me
0
x4
√
1 + x2 dx = πme
12λ3
c
[sinh(t) −8 sinh(t/2) + 3t].
(3.52d)
These parametric relationships for ρe and Pe as functions of the electron number
density ne are sometimes called the Anderson-Stoner equation of state, because they
were ﬁrst derived by Wilhelm Anderson and Edmund Stoner in 1930 (see Thorne,
1994, pp. 153–154). They are valid throughout the full range of electron degeneracy,
from nonrelativistic up to ultrarelativistic.
In a white-dwarf star, the protons, with their high rest mass, are nondegenerate,
relativistically degenerate
hydrogen gas
the total density of mass-energy is dominated by the proton rest-mass density, and
since there is one proton for each electron in the hydrogen gas, that total is
ρ ≃mpne =
8πmp
3λ3
c
sinh3(t/4).
(3.53a)
By contrast (as in the nonrelativistic regime), the pressure is dominated by the elec-
trons (because of their huge zero-point motions), not the protons; and so the total
pressure is
P = Pe = π me
12λ3
c
[sinh(t) −8 sinh(t/2) + 3t].
(3.53b)
3.5 Isotropic Distribution Functions and Equations of State
127

In the low-density limit, where t ≪1 so pF ≪me = mec, we can solve the rela-
tivistic equation (3.52b) for t as a function of ne = ρ/mp and insert the result into the
relativistic expression (3.53b); the result is the nonrelativistic equation of state (3.43).
The dividing line ρ = ρrel deg = 8πmp/(3λ3
c) ≃1.0 × 106 g cm−3 [Eq. (3.46)] be-
tween nonrelativistic and relativistic degeneracy is the point where the electron Fermi
momentumisequaltotheelectronrestmass[i.e., sinh(t/4) = 1].Theequationofstate
(3.53a) and (3.53b) implies
Pe ∝ρ5/3
in the nonrelativistic regime, ρ ≪ρrel deg,
Pe ∝ρ4/3
in the relativistic regime, ρ ≫ρrel deg.
(3.53c)
These asymptotic equations of state turn out to play a crucial role in the structure and
stability of white dwarf stars (Secs. 13.3.2 and 26.3.5; Shapiro and Teukolsky, 1983;
Thorne, 1994, Chap. 4).
3.5.5
3.5.5 Equation of State for Radiation
thermalized radiation
As was discussed at the end of Sec. 3.3, for a gas of thermalized photons in an en-
vironment where photons are readily created and absorbed, the distribution func-
tion has the blackbody (Planck) form η = 1/(eE/(kBT ) −1), which we can rewrite as
1/(ep/(kBT ) −1), since the energy E of a photon is the same as the magnitude p of its
momentum. In this case, the relativistic integrals (3.49) give (see Ex. 3.13)
n = bT 3,
ρ = aT 4,
P = 1
3ρ,
(3.54a)
where
b = 16πζ(3) k3
B
h3c3 = 20.28 cm−3 K−3,
(3.54b)
a = 8π5
15
k4
B
h3c3 = 7.566 × 10−15 erg cm−3 K−4 = 7.566 × 10−16 J m−3 K−4
(3.54c)
are radiation constants. Here ζ(3) = !∞
n=1 n−3 = 1.2020569 . . . is the Riemann zeta
function.
As we shall see in Sec. 28.4, when the universe was younger than about 100,000
years, its energy density and pressure were predominantly due to thermalized photons
plus neutrinos (which contributed approximately the same as the photons), so its
equation of state was given by Eq. (3.54a) with the coefﬁcient changed by a factor
of order unity. Einstein’s general relativistic ﬁeld equations (Sec. 25.8 and Chap. 28)
relate the energy density ρ of these photons and neutrinos to the age of the universe
t as measured in the photons’ and neutrinos’ mean rest frame:
3
32πGt2 = ρ ≃aT 4.
(3.55a)
128
Chapter 3. Kinetic Theory

Here G is Newton’s gravitation constant. Putting in numbers, we ﬁnd that
ρ = 4.5 × 10−10 g cm−3
(τ/1 yr)2
,
T ≃2.7 × 106 K
(τ/1 yr)1/2 .
(3.55b)
This implies that, when the universe was 1 minute old, its radiation density and
temperature were about 100 g cm−3 and 2 × 109 K, respectively. These conditions and
the proton density were well suited for burning hydrogen to helium; and, indeed,
about 1/4 of all the mass of the universe did get burned to helium at this early epoch.
We shall examine this in further detail in Sec. 28.4.2.
EXERCISES
Exercise 3.8 Derivation and Practice: Equation of State for Nonrelativistic,
Classical Gas
Consider a collection of identical, classical (i.e., with η ≪1) particles with a dis-
tribution function N that is thermalized at a temperature T such that kBT ≪mc2
(nonrelativistic temperature).
(a) Show that the distribution function, expressed in terms of the particles’ momenta
or velocities in their mean rest frame, is
N = gs
h3eμ/(kBT )e−p2/(2mkBT ),
where p = |p| = mv,
(3.56)
with v being the speed of a particle.
(b) Show that the number density of particles in the mean rest frame is given by Eq.
(3.39a).
(c) Show that this gas satisﬁes the equations of state (3.39b).
Note: The following integrals, for nonnegative integral values of q, will be useful:
 ∞
0
x2qe−x2dx = (2q −1)!!
2q+1
√π ,
(3.57)
where n!! ≡n(n −2)(n −4) . . . (2 or 1); and
 ∞
0
x2q+1e−x2dx = 1
2q! .
(3.58)
Exercise 3.9 Derivation and Practice: Equation of State for Nonrelativistic,
Electron-Degenerate Hydrogen
Derive Eq. (3.43) for the electron pressure in a nonrelativistic, electron-degenerate
hydrogen gas.
Exercise 3.10 Derivation and Practice: Equation of State for Relativistic,
Electron-Degenerate Hydrogen
Derive the equations of state (3.52) for an electron-degenerate hydrogen gas. (Note:
It might be easiest to compute the integrals with the help of symbolic manipulation
software, such as Mathematica, Matlab, or Maple.)
3.5 Isotropic Distribution Functions and Equations of State
129

Exercise 3.11 Example: Speciﬁc Heat for Nonrelativistic, Degenerate Electrons
in White Dwarfs and in Metals
Consider a nonrelativistically degenerate electron gas at ﬁnite but small temperature.
(a) Show that the inequalities kBT ≪μe ≪me are equivalent to the words “nonrel-
ativistically degenerate.”
(b) Show that the electron mean occupation number ηe(E) has the form depicted
in Fig. 3.8: It is near unity out to (nonrelativistic) energy E ≃μe −2kBT , and it
then drops to nearly zero over a range of energies E ∼4kBT .
(c) If the electrons were nonrelativistic but nondegenerate, their thermal energy
density would be U = 3
2nkBT , so the total electron energy (excluding rest mass)
in a volume V containing N = nV electrons would be Etot = 3
2NkBT , and the
electron speciﬁc heat, at ﬁxed volume, would be
CV ≡
∂Etot
∂T

V
= 3
2NkB
(nondegenerate, nonrelativistic).
(3.59)
Using the semiquantitative form of ηe depicted in Fig. 3.8, show that to within a
factor of order unity the speciﬁc heat of degenerate electrons is smaller than in
the nondegenerate case by a factor ∼kBT /μe:
CV ≡
∂Etot
∂T

V
∼
kBT
μe

NkB
(degenerate, nonrelativistic).
(3.60)
(d) Compute the multiplicative factor in Eq. (3.60) for CV . More speciﬁcally, show
that, to ﬁrst order in kBT /μe,
CV = π2
2
kBT
μe

NkB.
(3.61)
(e) As an application, consider hydrogen inside a white dwarf with density ρ = 105
g cm−3 and temperature T = 106 K. (These are typical values for a white-dwarf
interior). What are the numerical values of μe/me and kBT /μe for the electrons?
What is the numerical value of the dimensionless factor (π2/2)(kBT /μe) by
which degeneracy reduces the electron speciﬁc heat?
(f) Asasecondapplication, considertheelectronsinsideacopperwireinalaboratory
on Earth at room temperature. Each copper atom donates about one electron to a
“gas” of freely traveling (conducting) electrons and keeps the rest of its electrons
bound to itself. (We neglect interaction of this electron gas with the ions, thereby
missing important condensed matter complexities, such as conduction bands and
what distinguishes conducting materials from insulators.)
What are the numerical values of μe/me and kBT /μe for the conducting
electron gas? Verify that these are in the range corresponding to nonrelativistic
degeneracy. What is the value of the factor (π2/2)(kBT /μe) by which degeneracy
reduces the electron speciﬁc heat? At room temperature, this electron contribu-
130
Chapter 3. Kinetic Theory

tion to the speciﬁc heat is far smaller than the contribution from thermal vibra-
tions of the copper atoms (i.e., thermal sound waves, i.e., thermal phonons), but
at very low temperatures the electron contribution dominates, as we shall see in
the next exercise.
Exercise 3.12 Example: Speciﬁc Heat for Phonons in an Isotropic Solid
In Sec. 12.2 we will study classical sound waves propagating through an isotropic,
elastic solid. As we shall see, there are two types of sound waves: longitudinal with
frequency-independentspeedCL, andtransverse withasomewhatsmallerfrequency-
independent speed CT . For each type of wave, s = L or T , the material of the solid
undergoes an elastic displacement ξ = Afs exp(ik . x −ωt), where A is the wave
amplitude, fs is a unit vector (polarization vector) pointing in the direction of the
displacement, k is the wave vector, and ω is the wave frequency. The wave speed is
Cs = ω/|k| (= CL or CT ). Associated with these waves are quanta called phonons. As
for any wave, each phonon has a momentum related to its wave vector by p = ℏk, and
an energy related to its frequency by E = ℏω. Combining these relations we learn
that the relationship between a phonon’s energy and the magnitude p = |p| of its
momentum is E = Csp. This is the same relationship as for photons, but with the
speed of light replaced by the speed of sound! For longitudinal waves fL is in the
propagation direction k, so there is just one polarization, gL = 1. For transverse waves
fT is orthogonal to k, so there are two orthogonal polarizations (e.g., fT = ex and
fT = ey when k points in the ez direction), gT = 2.
(a) Phonons of both types, longitudinal and transverse, are bosons. Why? [Hint: Each
normal mode of an elastic body can be described mathematically as a harmonic
oscillator.]
(b) Phonons are fairly easily created, absorbed, scattered, and thermalized. A general
argument that we will give for chemical reactions in Sec. 5.5 can be applied to
phononcreationandabsorptiontodeducethat, oncetheyreachcompletethermal
equilibrium with their environment, the phonons will have vanishing chemical
potential μ = 0. What, then, will be their distribution functions η and N ?
(c) Ignoring the fact that the sound waves’ wavelengths λ = 2π/|k| cannot be smaller
than about twice the spacing between the atoms of the solid, show that the total
phonon energy (wave energy) in a volume V of the solid is identical to that for
blackbody photons in a volume V , but with the speed of light c replaced by
the speed of sound Cs, and with the photon number of spin states, 2, replaced
by gs = 3 (2 for transverse waves plus 1 for longitudinal): Etot = asT 4V , with
as = gs(4π5/15)(k4
B/(h3C3
s)) [cf. Eqs. (3.54)].
(d) Show that the speciﬁc heat of the phonon gas (the sound waves) is CV = 4asT 3V .
This scales as T 3, whereas in a metal the speciﬁc heat of the degenerate electrons
scales as T (previous exercise), so at sufﬁciently low temperatures the electron
speciﬁc heat will dominate over that of the phonons.
3.5 Isotropic Distribution Functions and Equations of State
131

(e) Show that in the phonon gas, only phonon modes with wavelengths longer than
∼λT = Csh/(kBT ) are excited; that is, for λ ≪λT the mean occupation num-
ber is η ≪1; for λ ∼λT , η ∼1; and for λ ≫λT , η ≫1. As T is increased, λT
gets reduced. Ultimately it becomes of order the interatomic spacing, and our
computation fails, because most of the modes that our calculation assumes are
thermalized actually don’t exist. What is the critical temperature (Debye temper-
ature) at which our computation fails and the T 3 law for CV changes? Show by a
roughly one-line argument that above the Debye temperature, CV is independent
of temperature.
Exercise 3.13 Derivation and Practice: Equation of State for a Photon Gas
(a) Consider a collection of photons with a distribution function N that, in the mean
rest frame of the photons, is isotropic. Show, using Eqs. (3.49b) and (3.49c), that
this photon gas obeys the equation of state P = 1
3ρ.
(b) Suppose the photons are thermalized with zero chemical potential (i.e., they are
isotropicwithablackbodyspectrum).Showthatρ = aT 4, wherea istheradiation
constant of Eq. (3.54c). [Note: Do not hesitate to use Mathematica, Matlab, or
Maple, or other computer programs to evaluate integrals!]
(c) Show that for this isotropic, blackbody photon gas the number density of photons
is n = bT 3, where b is given by Eq. (3.54b), and that the mean energy of a photon
in the gas is
¯Eγ =
π4
30ζ(3) kBT ≃2.701 kBT .
(3.62)
3.6
3.6 Evolution of the Distribution Function:
Liouville’s Theorem, the Collisionless Boltzmann Equation,
and the Boltzmann Transport Equation
We now turn to the issue of how the distribution function η(P, ⃗p), or equivalently,
N = (gs/h3)η, evolves from point to point in phase space. We explore the evolution
under the simple assumption that between their very brief collisions, the particles
all move freely, uninﬂuenced by any forces. It is straightforward to generalize to a
situation where the particles interact with electromagnetic, gravitational, or other
ﬁelds as they move, and we do so in Box 3.2, and Sec. 4.3. However, in the body
of this chapter, we restrict attention to the common situation of free motion between
collisions.
Initially we even rule out collisions; only at the end of this section do we restore
them by inserting them as an additional term in our collision-free evolution equation
for η.
The foundation for the collision-free evolution law will be Liouville’s theorem.
Consider a set S of particles that are initially all near some location in phase space
132
Chapter 3. Kinetic Theory

and initially occupy an inﬁnitesimal (frame-independent) phase-space volume d2V =
dVxdVp. Pick a particle at the center of the set S and call it the “ﬁducial particle.”
Since all the particles in S have nearly the same initial position and velocity, they
subsequently all move along nearly the same trajectory (world line): they all remain
congregated around the ﬁducial particle. Liouville’s theorem says that the phase-space
volume occupied by the set of particles S is conserved along the trajectory of the
ﬁducial particle:
Liouville’s theorem
d
dℓ(dVxdVp) = 0.
(3.63)
Here ℓis an arbitrary parameter along the trajectory. For example, in Newtonian
theory ℓcould be universal time t or distance l traveled, and in relativity it could be
proper time τ as measured by the ﬁducial particle (if its rest mass is nonzero) or the
afﬁne parameter ζ that is related to the ﬁducial particle’s 4-momentum by ⃗p = d ⃗x/dζ.
We shall prove Liouville’s theorem with the aid of the diagrams in Fig. 3.9. Assume,
for simplicity, that the particles have nonzero rest mass. Consider the region in phase
space occupied by the particles, as seen in the inertial reference frame (rest frame)
of the ﬁducial particle, and choose for ℓthe time t of that inertial frame (or in
Newtonian theory the universal time t). Choose the particles’ region dVxdVp at
t = 0 to be a rectangular box centered on the ﬁducial particle (i.e., on the origin
xj = 0 of its inertial frame; Fig. 3.9a). Examine the evolution with time t of the 2-
dimensional slice y = py = z = pz = 0 through the occupied region. The evolution
of other slices will be similar. Then, as t passes, the particle at location (x, px) moves
with velocity dx/dt = px/m (where the nonrelativistic approximation to the velocity
is used, because all the particles are very nearly at rest in the ﬁducial particle’s inertial
frame). Because the particles move freely, each has a conserved px, and their motion
dx/dt = px/m (larger speeds are higher in the diagram) deforms the particles’ phase
space region into a skewed parallelogram as shown in Fig. 3.9b. Obviously, the area
of the occupied region, xpx, is conserved.
px
px
x
x
(a)
(b)
x
px
px
x
FIGURE 3.9 The phase-space region (x-px part) occupied by a set S of
particles with ﬁnite rest mass, as seen in the inertial frame of the central,
ﬁducial particle. (a) The initial region. (b) The region after a short time.
3.6 Evolution of the Distribution Function
133

This same argument shows that the x-px area is conserved at all values of
y, z, py, pz; similarly for the areas in the y-py planes and those in the z-pz planes. As
a consequence, the total volume in phase space, dVxdVp = xpxypyzpz,
is conserved.
Although this proof of Liouville’s theorem relies on the assumption that the par-
ticles have nonzero rest mass, the theorem is also true for particles with zero rest
mass—as one can deduce by taking the relativistic limit as the rest mass goes to zero
and the particles’ 4-momenta become null.
Since, in the absence of collisions or other nongravitational interactions, the
number dN of particles in the set S is conserved, Liouville’s theorem immediately
implies the conservation of the number density in phase space, N = dN/(dVxdVp):
collisionless Boltzmann
equation
dN
dℓ= 0
along the trajectory of a ﬁducial particle.
(3.64)
This conservation law is called the collisionless Boltzmann equation; in the context of
plasma physics (Part VI) it is sometimes called the Vlasov equation. Note that it says
that not only is the distribution function N frame independent; N also is constant along
the phase-space trajectory of any freely moving particle.
ThecollisionlessBoltzmannequationisactuallyfarmoregeneralthanissuggested
by the above derivation; see Box 3.2, which is best read after ﬁnishing this section.
The collisionless Boltzmann equation is most nicely expressed in the frame-
independent form Eq. (3.64). For some purposes, however, it is helpful to express
the equation in a form that relies on a speciﬁc but arbitrary choice of inertial ref-
erence frame. Then N can be regarded as a function of the reference frame’s seven
phase-space coordinates, N = N (t, xj, pk), and the collisionless Boltzmann equa-
tion (3.64) takes the coordinate-dependent form
dN
dℓ= dt
dℓ
∂N
∂t +
dxj
dℓ
∂N
∂xj
+
dpj
dℓ
∂N
∂pj
= dt
dℓ
*
∂N
∂t + vj
∂N
∂xj
+
= 0.
(3.65)
Here we have used the equation of straight-line motion dpj/dt = 0 for the particles
and have set dxj/dt equal to the particle velocity vj.
Since our derivation of the collisionless Boltzmann equation relies on the as-
sumption that no particles are created or destroyed as time passes, the collisionless
Boltzmann equation in turn should guarantee conservation of the number of parti-
cles, ∂n/∂t + ∇. S = 0 in Newtonian theory (Sec. 1.8), and ⃗∇. ⃗S = 0 relativistically
(Sec. 2.12.3). Indeed, this is so; see Ex. 3.14. Similarly, since the collisionless Boltz-
mann equation is based on the law of momentum (or 4-momentum) conservation
for all the individual particles, it is reasonable to expect that the collisionless Boltz-
mann equation will guarantee the conservation of their total Newtonian momen-
tum [∂G/∂t + ∇. T = 0, Eq. (1.36)] and their relativistic 4-momentum [ ⃗∇. TTT = 0,
134
Chapter 3. Kinetic Theory

Eq. (2.73a)]. And indeed, these conservation laws do follow from the collisionless
Boltzmann equation; see Ex. 3.14.
Thus far we have assumed that the particles move freely through phase space with
no collisions. If collisions occur, they will produce some nonconservation of N along
the trajectory of a freely moving, noncolliding ﬁducial particle, and correspondingly,
the collisionless Boltzmann equation will be modiﬁed to read
Boltzmann transport
equation
dN
dℓ=
dN
dℓ

collisions
,
(3.66)
where the right-hand side represents the effects of collisions. This equation, with
collision terms present, is called the Boltzmann transport equation.The actual form of
the collision terms depends, of course, on the details of the collisions. We meet some
speciﬁc examples in the next section [Eqs. (3.79), (3.86a), (3.87), and Ex. 3.21] and in
our study of plasmas (Chaps. 22 and 23).
When one applies the collisionless Boltzmann equation or Boltzmann transport
equation to a given situation, it is helpful to simplify one’s thinking in two ways:
(i) Adjust the normalization of the distribution function so it is naturally tuned to
the situation. For example, when dealing with photons, Iν/ν3 is typically best, and
if—as is usually the case—the photons do not change their frequencies as they move
and only a single reference frame is of any importance, then Iν alone may do; see
Ex. 3.15. (ii) Adjust the differentiation parameter ℓso it is also naturally tuned to the
situation.
EXERCISES
Exercise 3.14 Derivation and Problem: Collisionless Boltzmann Equation Implies
Conservation of Particles and of 4-Momentum
Consider a collection of freely moving, noncolliding particles that satisfy the
collisionless Boltzmann equation dN /dℓ= 0.
(a) Show that this equation guarantees that the Newtonian particle conservation
law ∂n/∂t + ∇. S = 0 and momentum conservation law ∂G/∂t + ∇. T = 0 are
satisﬁed, where n, S, G, and T are expressed in terms of the distribution function
N by the Newtonian momentum-space integrals (3.32).
(b) Show that the relativistic Boltzmann equation guarantees the relativistic conser-
vation laws ⃗∇. ⃗S = 0 and ⃗∇. TTT = 0, where the number-ﬂux 4-vector ⃗S and the
stress-energy tensor TTT are expressed in terms of N by the momentum-space in-
tegrals (3.33).
Exercise 3.15 **Example: Solar Heating of Earth: The Greenhouse Effect
In this example we study the heating of Earth by the Sun. Along the way, we derive
some important relations for blackbody radiation.
3.6 Evolution of the Distribution Function
135

BOX 3.2.
SOPHISTICATED DERIVATION OF RELATIVISTIC
COLLISIONLESS BOLTZMANN EQUATION
Denote by ⃗X ≡{P, ⃗p} a point in 8-dimensional phase space. In an inertial
frame the coordinates of ⃗X are {x0, x1, x2, x3, p0, p1, p2, p3}. [We use up
(contravariant) indices on x and down (covariant) indices on p, because this
is the form required in Hamilton’s equations below; i.e., it is pα and not pα
that is canonically conjugate to xα.] Regard N as a function of location ⃗X in
8-dimensional phase space. Our particles all have the same rest mass, so N is
nonzero only on the mass hyperboloid, which means that as a function of ⃗X,
N entails a delta function. For the following derivation, that delta function
is irrelevant; the derivation is valid also for distributions of nonidentical
particles, as treated in Ex. 3.2.
A particle in our distribution N at location ⃗X moves through phase
space along a world line with tangent vector d ⃗X/dζ, where ζ is its afﬁne
parameter. The product N d ⃗X/dζ represents the number-ﬂux 8-vector of
particles through spacetime, as one can see by an argument analogous to Eq.
(3.35c). We presume that, as the particles move through phase space, none
are created or destroyed. The law of particle conservation in phase space, by
analogy with ⃗∇. ⃗S = 0 in spacetime, takes the form ⃗∇. (N d ⃗X/dζ) = 0. In
terms of coordinates in an inertial frame, this conservation law says
∂
∂xα

N dxα
dζ

+
∂
∂pα

N dpα
dζ

= 0.
(1)
The motions of individual particles in phase space are governed by Hamilton’s
equations
dxα
dζ = ∂H
∂pα
, dpα
dζ = −∂H
∂xα .
(2)
For the freely moving particles of this chapter, a convenient form for the
relativistic hamiltonian is [cf. Goldstein, Poole, and Safko (2002, Sec. 8.4) or
Misner, Thorne, and Wheeler (1973, p. 489), who call it the super-hamiltonian]
H = 1
2(pαpβgαβ + m2).
(3)
Our derivation of the collisionless Boltzmann equation does not depend on
this speciﬁc form of the hamiltonian; it is valid for any hamiltonian and thus,
for example, for particles interacting with an electromagnetic ﬁeld or even
a relativistic gravitational ﬁeld (spacetime curvature; Part VII). By inserting
Hamilton’s equations (2) into the 8-dimensional law of particle conservation
(1), we obtain
(continued)
136
Chapter 3. Kinetic Theory

BOX 3.2.
(continued)
∂
∂xα

N ∂H
∂pα

−
∂
∂pα

N ∂H
∂xα

= 0.
(4)
Using the rule for differentiating products and noting that the terms involving
two derivatives of H cancel, we bring this into the form
0 = ∂N
∂xα
∂H
∂pα
−∂N
∂pα
∂H
∂xα = ∂N
∂xα
dxα
dζ −∂N
∂pα
dpα
dζ = dN
dζ ,
(5)
which is the collisionless Boltzmann equation. (To get the second expression
we have used Hamilton’s equations, and the third follows directly from the
formulas of differential calculus.) Thus, the collisionless Boltzmann equation is
a consequence of just two assumptions: conservation of particles and Hamilton’s
equations for the motion of each particle. This implies that the Boltzmann
equation has very great generality.We extend and explore this generality in the
next chapter.
Since we will study photon propagation from the Sun to Earth with Doppler shifts
playing a negligible role, there is a preferred inertial reference frame: that of the Sun
andEarthwiththeirrelativemotionneglected.Wecarryoutouranalysisinthatframe.
Since we are dealing with thermalized photons, the natural choice for the distribution
function is Iν/ν3; and since we use just one unique reference frame, each photon has
a ﬁxed frequency ν, so we can forget about the ν3 and use Iν.
(a) Assume, asisverynearlytrue, thateachspotontheSunemitsblackbodyradiation
in all outward directions with a common temperature T⊙= 5,800 K. Show, by
integrating over the blackbody Iν, that the total energy ﬂux (i.e., power per unit
surface area) F emitted by the Sun is
F ≡
dE
dtdA = σT 4
⊙,
where
σ = ac
4 = 2π5
15
k4
B
h3c2 = 5.67 × 10−5
erg
cm2 s K4 .
(3.67)
(b) Since the distribution function Iν is conserved along each photon’s trajectory,
observers on Earth, looking at the Sun, see the same blackbody speciﬁc intensity
Iν as they would if they were on the Sun’s surface, and similarly for any other
star. By integrating over Iν at Earth [and not by the simpler method of using
Eq. (3.67) for the ﬂux leaving the Sun], show that the energy ﬂux arriving at
Earth is F = σT 4
⊙(R⊙/r)2, where R⊙= 696,000 km is the Sun’s radius and
r = 1.496 × 108 km is the mean distance from the Sun to Earth.
3.6 Evolution of the Distribution Function
137

(c) Our goal is to compute the temperature T⊕of Earth’s surface. As a ﬁrst attempt,
assume that all the Sun’s ﬂux arriving at Earth is absorbed by Earth’s surface,
heating it to the temperature T⊕, and then is reradiated into space as blackbody
radiation at temperature T⊕. Show that this leads to a surface temperature of
T⊕= T⊙
R⊙
2r
1/2
= 280 K = 7 ◦C.
(3.68)
This is a bit cooler than the correct mean surface temperature (287 K = 14 °C).
(d) Actually, Earth has an albedo of A ≃0.30, which means that 30% of the sunlight
that falls onto it gets reﬂected back into space with an essentially unchanged spec-
trum, rather than being absorbed. Show that with only a fraction 1 −A = 0.70
of the solar radiation being absorbed, the above estimate of Earth’s temperature
becomes
T⊕= T⊙
*√
1 −A R⊙
2r
+1/2
= 256 K = −17 ◦C.
(3.69)
This is even farther from the correct answer.
(e) The missing piece of physics, which raises the temperature from −17 ◦C to
something much nearer the correct 14 ◦C, is the greenhouse effect: The absorbed
solarradiationhasmostofitsenergyatwavelengths∼0.5 μm(inthevisualband),
which pass rather easily through Earth’s atmosphere. By contrast, the blackbody
radiationthatEarth’ssurfacewantstoradiatebackintospace, withitstemperature
∼300 K, is concentrated in the infrared range from ∼8 μm to ∼30 μm. Water
molecules, carbon dioxide and methane in Earth’s atmosphere absorb about 40%
of the energy that Earth tries to reradiate at these energies (Cox, 2000, Sec. 11.22),
causing the reradiated energy to be about 60% that of a blackbody at Earth’s
surface temperature. Show that with this (oversimpliﬁed!) greenhouse correction,
T⊕becomes about 290 K = +17 ◦C, which is within a few degrees of the true
meantemperature.Thereisoverwhelmingevidencethatthemeasuredincreasein
the average Earth temperature in recent decades is mostly caused by the measured
increase in carbon dioxide and methane, which, in turn, is mostly due to human
activity. Although the atmospheric chemistry is not well enough understood to
make accurate predictions, mankind is performing a very dangerous experiment.
Exercise 3.16 **Challenge: Olbers’ Paradox and Solar Furnace
Consider a universe (not ours!) in which spacetime is ﬂat and inﬁnite in size and is
populated throughout by stars that cluster into galaxies like our own and our neigh-
bors, with interstellar and intergalactic distances similar to those in our neighbor-
hood.Assumethatthegalaxiesarenot movingapart—thereisnouniversalexpansion.
Using the collisionless Boltzmann equation for photons, show that Earth’s temper-
ature in this universe would be about the same as the surface temperatures of the
universe’s hotter stars, ∼10,000 K, so we would all be fried. This is Olbers’ Paradox.
What features of our universe protect us from this fate?
138
Chapter 3. Kinetic Theory

Motivated by this model universe, describe a design for a furnace that relies on
sunlightforitsheatandachievesatemperaturenearlyequaltothatoftheSun’ssurface,
5,800 K.
3.7
3.7 Transport Coefﬁcients
In this section we turn to a practical application of kinetic theory: the computation of
transport coefﬁcients. Our primary objective is to illustrate the use of kinetic theory,
but the transport coefﬁcients themselves are also of interest: they play important roles
in Parts V and VI (Fluid Dynamics and Plasma Physics) of this book.
electrical conductivity
What are transport coefﬁcients? An example is electrical conductivity κe. When
an electric ﬁeld E is imposed on a sample of matter, Ohm’s law tells us that the matter
responds by developing a current density
j = κeE.
(3.70a)
The electrical conductivity is high if electrons can move through the material with
ease; itislowifelectronshavedifﬁcultymoving.Theimpedimenttoelectronmotionis
scattering off other particles—off ions, other electrons, phonons (sound waves), plas-
mons (plasma waves), . . . . Ohm’s law is valid when (as almost always) the electrons
scatter many times, so they diffuse (random-walk their way) through the material. To
compute the electrical conductivity, one must analyze, statistically, the effects of the
many scatterings on the electrons’ motions. The foundation for an accurate analysis
is the Boltzmann transport equation (3.66).
thermal conductivity
Another example of a transport coefﬁcient is thermal conductivity κ, which ap-
pears in the law of heat conduction
F = −κ∇T .
(3.70b)
Here F is the diffusive energy ﬂux from regions of high temperature T to low. The im-
pediment to heat ﬂow is scattering of the conducting particles; and, correspondingly,
the foundation for accurately computing κ is the Boltzmann transport equation.
coefﬁcient of shear
viscosity
Other examples of transport coefﬁcients are (i) the coefﬁcient of shear viscosity
ηshear, which determines the stress Tij (diffusive ﬂux of momentum) that arises in a
shearing ﬂuid [Eq. (13.68)]
Tij = −2ηshearσij,
(3.70c)
where σij is the ﬂuid’s rate of shear (Ex. 3.19), and (ii) the diffusion coefﬁcient D,
diffusion coefﬁcient
which determines the diffusive ﬂux of particles S from regions of high particle density
n to low (Fick’s law):
S = −D∇n.
(3.70d)
3.7 Transport Coefﬁcients
139

There is a diffusion equation associated with each of these transport coefﬁ-
diffusion equation
cients. For example, the differential law of particle conservation ∂n/∂t + ∇. S = 0
[Eq. (1.30)], when applied to material in which the particles scatter many times so
S = −D∇n, gives the following diffusion equation for the particle number density:
∂n
∂t = D∇2n,
(3.71)
where we have assumed that D is spatially constant. In Ex. 3.17, by exploring solutions
to this equation, we shall see that the root mean square (rms) distance ¯l the particles
travel is proportional to the square root of their travel time, ¯l =
√
4Dt, a behavior
characteristic of diffusive random walks.10 See Sec. 6.3 for deeper insights into this.
Similarly, the law of energy conservation, when applied to diffusive heat ﬂow
F = −κ∇T , leads to a diffusion equation for the thermal energy density U and
thence for temperature [Ex. 3.18 and Eq. (18.4)]. Maxwell’s equations in a magnetized
ﬂuid, when combined with Ohm’s law j = κeE, lead to diffusion equation (19.6) for
magneticﬁeldlines.Andthelawofangularmomentumconservation, whenappliedto
a shearing ﬂuid with Tij = −2ηshearσij, leads to diffusion equation (14.6) for vorticity.
These diffusion equations, and all other physical laws involving transport coef-
ﬁcients, are approximations to the real world—approximations that are valid if and
only if (i) many particles are involved in the transport of the quantity of interest (e.g.,
charge, heat, momentum, particles) and (ii) on average each particle undergoes many
scatterings in moving over the length scale of the macroscopic inhomogeneities that
drive the transport. This second requirement can be expressed quantitatively in terms
of the mean free path λ between scatterings (i.e., the mean distance a particle trav-
mean free path
els between scatterings, as measured in the mean rest frame of the matter) and the
macroscopic inhomogeneity scale L for the quantity that drives the transport (e.g., in
heat transport that scale is L ∼T /|∇T |; i.e., it is the scale on which the temperature
changesbyanamountoforderitself).Intermsofthesequantities, thesecondcriterion
of validity is λ ≪L. These two criteria (many particles and λ ≪L) together are called
diffusion criteria
diffusion criteria, since they guarantee that the quantity being transported (charge,
heat, momentum, particles) will diffuse through the matter. If either of the two dif-
fusion criteria fails, then the standard transport law (Ohm’s law, the law of heat con-
duction, the Navier-Stokes equation, or the particle diffusion equation) breaks down
and the corresponding transport coefﬁcient becomes irrelevant and meaningless.
The accuracy with which one can compute a transport coefﬁcient using the Boltz-
mann transport equation depends on the accuracy of one’s description of the scat-
tering. If one uses a high-accuracy collision term (dN /dℓ)collisions in the Boltzmann
10. Einstein derived this diffusion law ¯l =
√
4Dt, and he used it and his formula for the diffusion coefﬁcient
D, along with observational data about the diffusion of sugar molecules in water, to demonstrate the
physical reality of molecules, determine their sizes, and deduce the numerical value of Avogadro’s
number; see the historical discussion in Pais (1982, Chap. 5).
140
Chapter 3. Kinetic Theory

equation, one can derive a highly accurate transport coefﬁcient. If one uses a very
crude approximation for the collision term, the resulting transport coefﬁcient might
be accurate only to within an order of magnitude—in which case, it was probably not
worth the effort to use the Boltzmann equation; a simple order-of-magnitude argu-
ment would have done just as well. If the interaction between the diffusing particles
and the scatterers is electrostatic or gravitational (long-range 1/r2 interaction forces),
then the particles cannot be idealized as moving freely between collisions, and an ac-
curate computation of transport coefﬁcients requires a more sophisticated analysis:
the Fokker-Planck equation developed in Sec. 6.9 and discussed, for plasmas, in Secs.
20.4.3 and 20.5.
In the following three subsections, we compute the coefﬁcient of thermal con-
ductivity κ for hot gas inside a star (where short-range collisions hold sway and the
Boltzmann transport equation is highly accurate). We do so ﬁrst by an order-of-
magnitude argument and then by the Boltzmann equation with an accurate collision
term. In Exs. 3.19 and 3.20, readers have the opportunity to compute the coefﬁcient of
viscosity and the diffusion coefﬁcient for particles using moderately accurate collision
terms, and in Ex. 3.21 (neutron diffusion in a nuclear reactor), we will meet diffusion
in momentum space, by contrast with diffusion in physical space.
EXERCISES
Exercise 3.17 **Example: Solution of Diffusion Equation in an Inﬁnite
Homogeneous Medium
(a) Show that the following is a solution to the diffusion equation (3.71) for particles
in a homogeneous inﬁnite medium:
n =
N
(4πDt)3/2e−r2/(4Dt),
(3.72)
(where r ≡

x2 + y2 + z2 is radius), and that it satisﬁes

n dVx = N, so N is
the total number of particles. Note that this is a Gaussian distribution with width
σ =
√
4Dt. Plot this solution for several values of σ. In the limit as t →0, the
particles are all localized at the origin. As time passes, they random-walk (diffuse)
away from the origin, traveling a mean distance ασ = α
√
4Dt after time t, where
α is a coefﬁcient of order one. We will meet this square-root-of-time evolution in
other random-walk situations elsewhere in this book; see especially Exs. 6.3 and
6.4, and Sec. 6.7.2.
(b) Suppose that the particles have an arbitrary initial distributionno(x) at time t = 0.
Show that their distribution at a later time t is given by the following Green’s-
function integral:
n(x, t) =

no(x′)
(4πDt)3/2e−|x−x′|2/(4Dt)dVx′.
(3.73)
(c) What form does the solution take in one dimension? And in two dimensions?
3.7 Transport Coefﬁcients
141

Exercise 3.18 **Problem: Diffusion Equation for Temperature
Use the law of energy conservation to show that, when heat diffuses through a homo-
geneous medium whose pressure is being kept ﬁxed, the evolution of the temperature
perturbation δT ≡T −(average temperature) is governed by the diffusion equation
∂T
∂t = χ∇2T ,
where
χ = κ/(ρcP)
(3.74)
is called the thermal diffusivity. Here cP is the speciﬁc heat per unit mass at ﬁxed
pressure, and ρcP is that speciﬁc heat per unit volume. For the extension of this to
heat ﬂow in a moving ﬂuid, see Eq. (18.4).
3.7.1
3.7.1 Diffusive Heat Conduction inside a Star
The speciﬁc transport-coefﬁcient problem we treat here is for heat transport through
hot gas deep inside a young, massive star. We conﬁne attention to that portion of
the star in which the temperature is 107 K <∼T <∼109 K, the mass density is ρ <∼
10 g cm−3(T /107 K)2, and heat is carried primarily by diffusing photons rather than
photon diffusion through
scattering electrons
by diffusing electrons or ions or by convection. (We study convection in Chap. 18.) In
this regime the primary impediment to the photons’ ﬂow is collisions with electrons.
The lower limit on temperature, 107 K, guarantees that the gas is almost fully ionized,
so there is a plethora of electrons to do the scattering. The upper limit on density,
ρ ∼10 g cm−3(T /107 K)2, guarantees that (i) the inelastic scattering, absorption,
and emission of photons by electrons accelerating in the Coulomb ﬁelds of ions
(bremsstrahlung processes) are unimportant as impediments to heat ﬂow compared
to scattering off free electrons and (ii) the scattering electrons are nondegenerate (i.e.,
they have mean occupation numbers η small compared to unity) and thus behave
like classical, free, charged particles. The upper limit on temperature, T ∼109 K,
guarantees that (i) the electrons doing the scattering are moving thermally at much
less than the speed of light (the mean thermal energy 3
2kBT of an electron is much less
than its rest mass-energy mec2) and (ii) the scattering is nearly elastic, with negligible
energy exchange between photon and electron, and is describable with good accuracy
by the Thomson scattering cross section.
In the rest frame of the electron (which to good accuracy will be the same as
the mean rest frame of the gas, since the electron’s speed relative to the mean rest
frame is ≪c), the differential cross section dσ for a photon to scatter from its initial
propagation direction n′ into a unit solid angle d centered on a new propagation
direction n is
Thomson cross section
dσ(n′ →n)
d
=
3
16π σT[1 + (n . n′)2] .
(3.75a)
HereσT isthetotalThomsoncrosssection[theintegralofthedifferentialcrosssection
(3.75a) over solid angle]:
σT =
 dσ(n′ →n)
d
d = 8π
3 r2
o = 0.665 × 10−24 cm2 ,
(3.75b)
142
Chapter 3. Kinetic Theory

where ro = e2/(mec2) is the classical electron radius. [For a derivation and discussion
of the Thomson cross sections (3.75), see, e.g., Jackson (1999, Sec. 14.8).]
3.7.2
3.7.2 Order-of-Magnitude Analysis
Before embarking on any complicated calculation, it is always helpful to do a rough,
order-of-magnitude analysis, thereby identifying the key physics and the approximate
answer. The ﬁrst step of a rough analysis of our heat transport problem is to identify
the magnitudes of the relevant lengthscales. The inhomogeneity scale L for the tem-
perature, which drives the heat ﬂow, is the size of the hot stellar core, a moderate
fraction of the Sun’s radius: L ∼105 km. The mean free path of a photon can be es-
timated by noting that, since each electron presents a cross section σT to the photon
and there are ne electrons per unit volume, the probability of a photon being scattered
when it travels a distance l through the gas is of order neσTl. Therefore, to build up
to unit probability for scattering, the photon must travel a distance
photon mean free path
λ ∼
1
neσT
∼
mp
ρσT
∼3 cm
*
1 g cm−3
ρ
+
∼3 cm.
(3.76)
Here mp is the proton rest mass, ρ ∼1 g cm−3 is the mass density in the core of a
young, massive star, and we have used the fact that stellar gas is mostly hydrogen
to infer that there is approximately one nucleon per electron in the gas and hence
that ne ∼ρ/mp. Note that L ∼105 km is 3 × 109 times larger than λ ∼3 cm, and the
number of electrons and photons inside a cube of side L is enormous, so the diffusion
description of heat transport is highly accurate.
In the diffusion description, the heat ﬂux F as measured in the gas’s rest frame
is related to the temperature gradient ∇T by the law of diffusive heat conduction
F = −κ∇T . To estimate the thermal conductivity κ, orient the coordinates so the
temperature gradient is in the z direction, and consider the rate of heat exchange
between a gas layer located near z = 0 and a layer one photon mean free path away,
at z = λ (Fig. 3.10). The heat exchange is carried by photons that are emitted from
one layer, propagate nearly unimpeded to the other, and then scatter. Although the
individual scatterings are nearly elastic (and we thus are ignoring changes of photon
z = 0
αcaT0
4
αcaTλ
4
z = λ
FIGURE3.10 Heatexchangebetweentwolayersofgasseparated
by a distance of one photon mean free path in the direction
of the gas’s temperature gradient.
3.7 Transport Coefﬁcients
143

frequency in the Boltzmann equation), tiny changes of photon energy add up over
many scatterings to keep the photons nearly in local thermal equilibrium with the gas.
Thus, we approximate the photons and gas in the layer at z = 0 to have a common
temperature T0 and those in the layer at z = λ to have a common temperature Tλ =
T0 + λdT /dz. Then the photons propagating from the layer at z = 0 to that at z = λ
carry an energy ﬂux
F0→λ = αca(T0)4 ,
(3.77a)
where a is the radiation constant of Eq. (3.54c); a(T0)4 is the photon energy density at
z = 0; and α is a dimensionless constant of order 1/4 that accounts for what fraction
of the photons at z = 0 are moving rightward rather than leftward, and at what mean
angle to the z direction. (Throughout this section, by contrast with early sections of
this chapter, we use nongeometrized units, with the speed of light c present explicitly.)
Similarly, the ﬂux of energy from the layer at z = λ to the layer at z = 0 is
Fλ→0 = −αca(Tλ)4 ;
(3.77b)
and the net rightward ﬂux, the sum of Eqs. (3.77a) and (3.77b), is
F = αca[(T0)4 −(Tλ)4]= −4αcaT 3λdT
dz .
(3.77c)
Noting that 4α is approximately 1, inserting expression (3.76) for the photon mean
free path, and comparing with the law of diffusive heat ﬂow F = −κ∇T , we conclude
that the thermal conductivity is
thermal conductivity:
order of magnitude
estimate
κ ∼aT 3cλ = acT 3
σTne
.
(3.78)
3.7.3
3.7.3 Analysis Using the Boltzmann Transport Equation
With these physical insights and rough answer in hand, we turn to a Boltzmann
transport analysis of the heat transfer. Our ﬁrst step is to formulate the Boltzmann
transport equation for the photons (including effects of Thomson scattering off the
electrons) in the rest frame of the gas. Our second step will be to solve that equation
to determine the inﬂuence of the heat ﬂow on the distribution function N , and our
third step will be to compute the thermal conductivity κ by an integral over that N .
To simplify the analysis we use, as the parameter ℓin the Boltzmann transport
equation dN /dℓ= (dN /dℓ)collisions, the distance l that a ﬁducial photon travels, and
we regard the distribution function N as a function of location x in space, the pho-
ton propagation direction (unit vector) n, and the photon frequency ν: N (x, n, ν).
Because the photon frequency does not change during free propagation or Thomson
scattering, it can be treated as a constant when solving the Boltzmann equation.
Along the trajectory of a ﬁducial photon, N (x, n, ν) will change as a result of two
things: (i) the scattering of photons out of the n direction and into other directions
and (ii) the scattering of photons from other directions n′ into the n direction. These
144
Chapter 3. Kinetic Theory

effects produce the following two collision terms in the Boltzmann transport equation
(3.66):
Boltzmann transport
equation for diffusing
photons
dN (x, n, ν)
dl
= −σTne N (x, n, ν) +
 dσ(n′ →n)
d
ne N (x, n′, ν)d′ .
(3.79)
(The second scattering term would be more obvious if we were to use Iν (which is per
unit solid angle) as our distribution function rather than N ; but they just differ by a
constant.) Because the mean free path λ = 1/(σT ne) ∼3 cm is so short compared to
the length scale L ∼105 km of the temperature gradient, the heat ﬂow will show up
as a tiny correction to an otherwise isotropic, perfectly thermal distribution function.
Thus, we can write the photon distribution function as the sum of an unperturbed,
perfectly isotropic and thermalized piece N0 and a tiny, anisotropic perturbation N1:
expand N
N
N in powers of
λ/L
λ/L
λ/L
N = N0 + N1,
where N0 = 2
h3
1
ehν/(kBT ) −1.
(3.80a)
Here the perfectly thermal piece N0(x, n, ν) has the standard blackbody form (3.23);
it is independent of n, and it depends on x only through the temperature T = T (x).
If the photon mean free path were vanishingly small, there would be no way for
photons at different locations x to discover that the temperature is inhomogeneous;
correspondingly, N1 would be vanishingly small. The ﬁniteness of the mean free path
permits N1 to be ﬁnite, and so it is reasonable to expect (and turns out to be true) that
the magnitude of N1 is
N1 ∼λ
LN0 .
(3.80b)
Thus, N0 is the leading-order term, and N1 is the ﬁrst-order correction in an expan-
sion of the distribution function N in powers of λ/L. This is called a two-lengthscale
expansion; see Box 3.3.
Inserting N = N0 + N1 into our Boltzmann transport equation (3.79) and using
d/dl = n . ∇for the derivative with respect to distance along the ﬁducial photon
trajectory, we obtain
perturbative Boltzmann
equation for N1
N1
N1
nj
∂N0
∂xj
+ nj
∂N1
∂xj
=

−σTneN0 +
 dσ(n′ →n)
d
necN0d′

+

−σTnecN1(n, ν) +
 dσ(n′ →n)
d
necN1(n′, ν)d′

.
(3.80c)
Because N0 is isotropic (i.e., is independent of photon direction n′), it can be pulled
out of the integral over n′ in the ﬁrst square bracket on the right-hand side. When
this is done, the ﬁrst and second terms in that square bracket cancel each other. Thus,
the unperturbed part of the distribution, N0, completely drops out of the right-hand
side of Eq. (3.80c). On the left-hand side the term involving the perturbation N1 is
tiny compared to that involving the unperturbed distribution N0, so we shall drop it.
3.7 Transport Coefﬁcients
145

BOX 3.3.
TWO-LENGTHSCALE EXPANSIONS
Equation (3.80b) is indicative of the mathematical technique that underlies
Boltzmann-transport computations: a perturbative expansion in the
dimensionless ratio of two lengthscales, the tiny mean free path λ of
the transporter particles and the far larger macroscopic scale L of the
inhomogeneities that drive the transport. Expansions in lengthscale ratios
λ/L are called two-lengthscale expansions and are widely used in physics and
engineering. Most readers will previously have met such an expansion in
quantum mechanics: the WKB approximation, where λ is the lengthscale on
which the wave function changes, and L is the scale of changes in the potential
V (x) that drives the wave function. Kinetic theory itself is the result of a
two-lengthscale expansion: it follows from the more sophisticated statistical-
mechanics formalism of Chap. 4, in the limit where the particle sizes are
small compared to their mean free paths. In this book we use two-lengthscale
expansions frequently—for instance, in the geometric optics approximation to
wave propagation (Chap. 7), in the study of boundary layers in ﬂuid mechanics
(Secs. 14.4, 14.5.4, and 15.5), in the quasi-linear formalism for plasma physics
(Chap. 23), and in the deﬁnition of a gravitational wave (Sec. 27.4).
Because the spatial dependence of N0 is entirely due to the temperature gradient, we
can bring the ﬁrst term and the whole transport equation into the form
nj
∂T
∂xj
∂N0
∂T = −σTneN1(n, ν) +
 dσ(n′ →n)
d
neN1(n′, ν)d′.
(3.80d)
The left-hand side of this equation is the amount by which the temperature gradient
causes N0 to fail to satisfy the Boltzmann equation, and the right-hand side is the
mannerinwhichtheperturbationN1stepsintothebreachandenablestheBoltzmann
equation to be satisﬁed.
Because the left-hand side is linear in the photon propagation direction nj (i.e.,
it has a cos θ dependence in coordinates where ∇T is in the z-direction; i.e., it has
a dipolar, l = 1, angular dependence), N1 must also be linear in nj (i.e., dipolar), in
order to fulﬁll Eq. (3.80d). Thus, we write N1 in the dipolar form
N1 = Kj(x, ν)nj,
(3.80e)
and we shall solve the transport equation (3.80d) for the function Kj.
[Side remark: This is a special case of a general situation. When solving the
multipolar expansion of N
N
N
Boltzmann transport equation in diffusion situations, one is performing a power
series expansion in λ/L; see Box 3.3. The lowest-order term in the expansion, N0,
is isotropic (i.e., it is monopolar in its dependence on the direction of motion of the
146
Chapter 3. Kinetic Theory

diffusing particles). The ﬁrst-order correction, N1, is down in magnitude by λ/L from
N0 and is dipolar (or sometimes quadrupolar; see Ex. 3.19) in its dependence on the
particles’directionofmotion.Thesecond-ordercorrection, N2, isdowninmagnitude
by (λ/L)2 from N0 and its multipolar order is one higher than N1 (quadrupolar here;
octupolar in Ex. 3.19). And so it continues to higher and higher orders.11]
When we insert the dipolar expression (3.80e) into the angular integral on the
right-hand side of the transport equation (3.80d) and notice that the differential
scattering cross section (3.75a) is unchanged under n′ →−n′, but Kjn′j changes
sign, we ﬁnd that the integral vanishes. As a result the transport equation (3.80d)
takes the simpliﬁed form
nj
∂T
∂xj
∂N0
∂T = −σTneKjnj,
(3.80f)
from which we can read off the function Kj and thence N1 = Kjnj:
solution for N1
N1
N1
N1 = −∂N0/∂T
σTne
∂T
∂xj
nj.
(3.80g)
Notice that, as claimed in Eq. (3.80b), the perturbation has a magnitude
N1
N0
∼
1
σT ne
1
T |∇T | ∼λ
L.
(3.80h)
Having solved the Boltzmann transport equation to obtain N1, we can now eval-
uate the energy ﬂux Fi carried by the diffusing photons. Relativity physicists will
recognize that ﬂux as the T 0i part of the stress-energy tensor and will therefore eval-
uate it as
Fi = T 0i = c2

N p0pi dVp
p0 = c2

N pidVp
(3.81)
[cf. Eq. (3.33c) with the factors of c restored]. Newtonian physicists can deduce this
formula by noticing that photons with momentum p in dVp carry energy E = |p|c
and move with velocity v = cp/|p|, so their energy ﬂux is N Ev dVp = c2N p dVp;
integrating this over momentum space gives Eq. (3.81). Inserting N = N0 + N1 into
this equation and noting that the integral over N0 vanishes, and inserting Eq. (3.80g)
for N1, we obtain
energy ﬂux from N1
N1
N1
Fi = c2

N1pidVp = −
c
σTne
∂T
∂xj
∂
∂T

N0cnjpidVp.
(3.82a)
The relativity physicist will identify this integral as Eq. (3.33c) for the photons’ stress
tensor Tij (since nj = pj/p0 = pj/E). The Newtonian physicist, with a little thought,
will recognize the integral in Eq. (3.82a) as the j component of the ﬂux of i component
11. For full details of this “method-of-moments” analysis in nonrelativistic situations, see, e.g., Grad (1958);
and for full relativistic details, see, e.g., Thorne (1981).
3.7 Transport Coefﬁcients
147

of momentum, which is precisely the stress tensor. Since this stress tensor is being
computed with the isotropic, thermalized part of N , it is isotropic, Tji = P δji, and
its pressure has the standard blackbody-radiation form P = 1
3aT 4 [Eqs. (3.54a)].
Replacing the integral in Eq. (3.82a) by this blackbody stress tensor, we obtain our
ﬁnal answer for the photons’ energy ﬂux:
Fi = −
c
σTne
∂T
∂xj
d
dT
1
3aT 4δji

= −
c
σTne
4
3aT 3∂T
∂xi
.
(3.82b)
Thus, from the Boltzmann transport equation we have simultaneously derived the
law of diffusive heat conduction q = −κ∇T and evaluated the coefﬁcient of thermal
conductivity
thermal conductivity
from Boltzmann transport
equation
κ = 4
3
acT 3
σTne
.
(3.83)
Notice that this heat conductivity is 4/3 times our crude, order-of-magnitude estimate
(3.78).
The above calculation, while somewhat complicated in its details, is conceptually
fairly simple. The reader is encouraged to go back through the calculation and identify
the main conceptual steps [expansion of distribution function in powers of λ/L,
insertion of zero-order plus ﬁrst-order parts into the Boltzmann equation, multipolar
decomposition of the zero- and ﬁrst-order parts (with zero-order being monopolar
and ﬁrst-order being dipolar), neglect of terms in the Boltzmann equation that are
smaller than the leading ones by factors λ/L, solution for the coefﬁcient of the
multipolar decomposition of the ﬁrst-order part, reconstruction of the ﬁrst-order part
from that coefﬁcient, and insertion into a momentum-space integral to get the ﬂux
of the quantity being transported]. Precisely these same steps are used to evaluate all
other transport coefﬁcients that are governed by classical physics. [For examples of
other such calculations, see, e.g., Shkarofsky, Johnston, and Bachynski (1966).]
As an application of the thermal conductivity (3.83), consider a young (main-
sequence) 7-solar-mass (7 M⊙) star as modeled, for example, on pages 480 and 481
of Clayton (1968). Just outside the star’s convective core, at radius r ≃0.7R⊙≃
5 × 105 km (where R⊙is the Sun’s radius), the density and temperature are ρ ≃
5.5 g cm−3 and T ≃1.9 × 107 K, so the number density of electrons is ne ≃
ρ/(1.4mp) ≃2.3 × 1024 cm−3 where the 1.4 accounts for the star’s chemical composi-
tion. For these parameters,
Eq. (3.83) gives a thermal conductivity κ ≃
1.3 × 1018 erg s−1 cm−2 K−1. The lengthscale L on which the temperature is chang-
ing is approximately the same as the radius, so the temperature gradient is |∇T | ∼
T/r ∼4 × 10−4 K cm−1. The law of diffusive heat transfer then predicts a heat ﬂux
F = κ|∇T | ∼5 × 1014 erg s−1 cm−2, and thus a total luminosity L = 4πr2F ∼
1.5 × 1037 erg s−1 ≃4000L⊙(4,000 solar luminosities). (This estimate is a little high.
The correct value is about 3,600L⊙.) What a difference the mass makes! The heavier
a star, the hotter its core, the faster it burns, and the higher its luminosity will be.
Increasing the mass by a factor of 7 drives the luminosity up by 4,000.
148
Chapter 3. Kinetic Theory

EXERCISES
Exercise 3.19 **Example: Viscosity of a Monatomic Gas
Consider a nonrelativistic ﬂuid that, in the neighborhood of the origin, has ﬂuid
velocity
vi = σijxj,
(3.84)
with σij symmetric and trace-free. As we shall see in Sec. 13.7.1, this represents a
purely shearing ﬂow, with no rotation or volume changes of ﬂuid elements; σij is
called the ﬂuid’s rate of shear. Just as a gradient of temperature produces a diffusive
ﬂow of heat, so the gradient of velocity embodied in σij produces a diffusive ﬂow of
momentum (i.e., a stress). In this exercise we use kinetic theory to show that, for a
monatomic gas with isotropic scattering of atoms off one another, this stress is
Tij = −2ηshearσij,
(3.85a)
with the coefﬁcient of shear viscosity
ηshear ≃1
3ρλvth,
(3.85b)
where ρ is the gas density, λ is the atoms’ mean free path between collisions, and
vth =

3kBT/m is the atoms’ rms speed. Our analysis follows the same route as the
analysis of heat conduction in Secs. 3.7.2 and 3.7.3.
(a) Derive Eq. (3.85b) for the shear viscosity, to within a factor of order unity, by an
order-of-magnitude analysis like that in Sec. 3.7.2.
(b) Regard the atoms’ distribution function N as being a function of the magnitude
p and direction n of an atom’s momentum, and of location x in space. Show that,
if the scattering is isotropic with cross section σs and the number density of atoms
is n, then the Boltzmann transport equation can be written as
dN
dl = n . ∇N = −1
λN +

1
4πλN (p, n′, x)d′,
(3.86a)
where λ = 1/nσs is the atomic mean free path (mean distance traveled between
scatterings) and l is distance traveled by a ﬁducial atom.
(c) Explain why, in the limit of vanishingly small mean free path, the distribution
function has the following form:
N0 =
n
(2πmkBT )3/2 exp[−(p −mσ . x)2/(2mkBT )].
(3.86b)
(d) Solve the Boltzmann transport equation (3.86a) to obtain the leading-order cor-
rection N1 to the distribution function at x = 0.
[Answer:
N1 = −(λ p/(kBT ))σabnanb N0.]
3.7 Transport Coefﬁcients
149

(e) Compute the stress at x = 0 via a momentum-space integral. Your answer should
be Eq. (3.85a) with ηshear given by Eq. (3.85b) to within a few tens of percent
accuracy. [Hint: Along the way you will need the following angular integral:

nanbninjd = 4π
15 (δabδij + δaiδbj + δajδbi).
(3.86c)
Derive this by arguing that the integral must have the above delta-function struc-
ture, and then computing the multiplicative constant by performing the integral
for a = b = i = j = z.]
Exercise 3.20 Example: Diffusion Coefﬁcient in the Collision-Time
Approximation
Consider a collection of identical test particles with rest mass m ̸= 0 that diffuse
through a collection of thermalized scattering centers. (The test particles might be
molecules of one species, and the scattering centers might be molecules of a much
more numerous species.) The scattering centers have a temperature T such that
kBT ≪mc2, so if the test particles acquire this temperature, they will have thermal
speeds small compared to the speed of light as measured in the mean rest frame of
the scattering centers. We study the effects of scattering on the test particles using
the following collision-time approximation for the collision terms in the Boltzmann
equation, which we write in the mean rest frame of the scattering centers:
dN
dt

collision
= 1
τ (N0 −N ),
where
N0 ≡e−p2/(2mkBT )
(2πmkBT )3/2n.
(3.87)
Here the time derivative d/dt is taken moving with a ﬁducial test particle along its
unscattered trajectory, p = |p| is the magnitude of the test particles’ spatial momen-
tum, n =

N dVp is the number density of test particles, and τ is a constant to be
discussed below.
(a) Show that this collision term preserves test particles in the sense that
dn
dt

collision
≡
 dN
dt

collision
dpxdpydpz = 0.
(3.88)
(b) Explain why this collision term corresponds to the following physical picture:
Each test particle has a probability 1/τ per unit time of scattering; when it scat-
ters, its direction of motion is randomized and its energy is thermalized at the
scattering centers’ temperature.
(c) Suppose that the temperature T is homogeneous (spatially constant), but the
test particles are distributed inhomogeneously, n = n(x) ̸= const. Let L be the
lengthscale on which their number density n varies. What condition must L, τ, T ,
and m satisfy for the diffusion approximation to be reasonably accurate? Assume
that this condition is satisﬁed.
150
Chapter 3. Kinetic Theory

(d) Compute, in order of magnitude, the particle ﬂux S = −D∇n produced by the
gradientofthenumberdensityn, andtherebyevaluatethediffusioncoefﬁcientD.
(e) Show that the Boltzmann transport equation takes the form (sometimes known
as the BKG or Crook model)
∂N
∂t +
pj
m
∂N
∂xj
= 1
τ (N0 −N ).
(3.89a)
(f) Show that to ﬁrst order in a small diffusion-approximation parameter, the so-
lution of this equation is N = N0 + N1, where N0 is as deﬁned in Eq. (3.87),
and
N1 = −
pjτ
m
∂n
∂xj
e−p2/(2mkBT )
(2πmkBT )3/2 .
(3.89b)
Note that N0 is monopolar (independent of the direction of p), while N1is dipolar
(linear in p).
(g) Show that the perturbation N1 gives rise to a particle ﬂux given by Eq. (3.70d),
with the diffusion coefﬁcient
D = kBT
m τ.
(3.90)
How does this compare with your order-of-magnitude estimate in part (d)?
Exercise 3.21 **Example: Neutron Diffusion in a Nuclear Reactor
A simpliﬁed version of a commercial nuclear reactor involves ﬁssile material such as
enriched uranium12 and a moderator such as graphite, both of which will be assumed
in this exercise. Slow (thermalized) neutrons, with kinetic energies ∼0.1 eV, are cap-
tured by the 235U nuclei and cause them to undergo ﬁssion, releasing ∼170 MeV of
kinetic energy per ﬁssion which appears as heat. Some of this energy is then converted
into electric power. The ﬁssion releases an average of two or three (assume two) fast
neutrons with kinetic energies ∼1 MeV. (This is an underestimate.) The fast neu-
trons must be slowed to thermal speeds where they can be captured by 235U atoms
and induce further ﬁssions. The slowing is achieved by scattering off the moderator
atoms—a scattering in which the crucial effect, energy loss, occurs in momentum
space. The momentum-space scattering is elastic and isotropic in the center-of-mass
frame, with total cross section (to scatter off one of the moderator’s carbon atoms)
σs ≃4.8 × 10−24 cm2 ≡4.8 barns. Using the fact that in the moderator’s rest frame,
the incoming neutron has a much higher kinetic energy than the moderator carbon
atoms, and using energy and momentum conservation and the isotropy of the scat-
tering, one can show that in the moderator’s rest frame, the logarithm of the neutron’s
12. Natural uranium contains ∼0.007 of the ﬁssile isotope 235U; the fraction is increased to ∼0.01–0.05 in
enriched uranium.
3.7 Transport Coefﬁcients
151

energy is reduced in each scattering by an average amount ξ that is independent of
energy and is given by
ξ ≡− ln E = 1 + (A −1)2
2A
ln
A −1
A + 1

≃0.16,
(3.91)
a quantity sometimes known as lethargy. Here A ≃12 is the ratio of the mass of the
scattering atom to that of the scattered neutron.
There is a dangerous hurdle that the diffusing neutrons must overcome during
their slowdown: as the neutrons pass through a critical energy region of about ∼7
to ∼6 eV, the 238U atoms can absorb them. The absorption cross section has a huge
resonance there, with width ∼1 eV and resonance integral

σad ln E ≃240 barns.
For simplicity, we approximate the cross section in this absorption resonance by
σa ≃1600 barns at 6 eV < E < 7 eV, and zero outside this range. To achieve a viable
ﬁssion chain reaction and keep the reactor hot requires about half of the neutrons (one
per original 235U ﬁssion) to slow down through this resonant energy without getting
absorbed. Those that make it through will thermalize and trigger new 235U ﬁssions
(about one per original ﬁssion), maintaining the chain reaction.
We idealize the uranium and moderator atoms as homogeneously mixed on
lengthscales small compared to the neutron mean free path, λs = 1/(σsns) ≃2 cm,
where ns is the number density of moderator (carbon) atoms. Then the neutrons’ dis-
tribution function N , as they slow down, is isotropic in direction and independent
of position; and in our steady-state situation, it is independent of time. It therefore
depends only on the magnitude p of the neutron momentum or equivalently, on the
neutron kinetic energy E = p2/(2m): N = N (E).
Use the Boltzmann transport equation or other considerations to develop the
theory of the slowing of the neutrons in momentum space and of their struggle to
pass through the 238U resonance region without getting absorbed. More speciﬁcally,
do the following.
(a) Use as the distribution function not N (E) but rather nE(E) ≡dN/dVxdE
= (number of neutrons per unit volume and per unit kinetic energy), and de-
note by q(E) the number of neutrons per unit volume that slow down through
energy E per unit time. Show that outside the resonant absorption region these
two quantities are related by
q = σsnsξE nEv,
where v =
√
2mE
(3.92)
is the neutron speed, so q contains the same information as the distribution
function nE. Explain why the steady-state operation of the nuclear reactor re-
quires q to be independent of energy in this nonabsorption region, and infer that
nE ∝E−3/2.
(b) Show further that inside the resonant absorption region, 6 eV < E < 7 eV, the
relationship between q and E is modiﬁed:
q = (σsns + σana)ξE nEv.
(3.93)
152
Chapter 3. Kinetic Theory

Here ns is the number density of scattering (carbon) atoms, and na is the number
density of absorbing (238U) atoms. [Hint: Require that the rate at which neutrons
scatter into a tiny interval of energy δE ≪ξE is equal to the rate at which they
leave that tiny interval.] Then show that the absorption causes q to vary with
energy according to the following differential equation:
d ln q
d ln E =
σana
(σsns + σana)ξ .
(3.94)
(c) By solving this differential equation in our idealization of constant σa over the
range 7 to 6 eV, show that the condition to maintain the chain reaction is
ns
na
≃σa
σs
ln(7/6)
ξ ln 2 −1

≃0.41σa
σs
≃140.
(3.95)
Thus, to maintain the reaction in the presence of the huge 238U absorption
resonance for neutrons, it is necessary that approximately 99% of the reactor
volume be taken up by moderator atoms and 1% by uranium atoms.
This is a rather idealized version of what happens inside a nuclear reactor, but it pro-
vides insight into some of the important processes and the magnitudes of various
relevant quantities. For a graphic example of an additional complexity, see the descrip-
tion of “xenon poisoning” of the chain reaction in the ﬁrst production-scale nuclear
reactor (built during World War II to make plutonium for the ﬁrst American atomic
bombs) in John Archibald Wheeler’s autobiography (Wheeler, 2000).
Bibliographic Note
Newtonian kinetic theory is treated in many textbooks on statistical physics. At an
elementary level, Kittel and Kroemer (1980, Chap. 14) is rather good. Texts at a
more advanced level include Kardar (2007, Chap. 3), Reif (2008, Secs. 7.9–7.13 and
Chaps. 12–14), and Reichl (2009, Chap. 11). For a very advanced treatment with
extensive applications to electrons and ions in plasmas, and electrons, phonons, and
quasi-particles in liquids and solids, see Lifshitz and Pitaevskii (1981).
Relativistic kinetic theory is rarely touched on in statistical-physics textbooks but
should be. It is well known to astrophysicists. The treatment in this chapter is easily
lifted into general relativity theory (see, e.g., Misner, Thorne, and Wheeler, 1973,
Sec. 22.6).
Bibliographic Note
153


4
CHAPTER FOUR
Statistical Mechanics
Willard Gibbs did for statistical mechanics and for thermodynamics what Laplace did for celestial
mechanics and Maxwell did for electrodynamics, namely, made his ﬁeld a well-nigh ﬁnished theoretical
structure.
ROBERT A. MILLIKAN (1938)
4.1
4.1 Overview
While kinetic theory (Chap. 3) gives a powerful description of some statistical features
of matter, other features are outside its realm and must be treated using the more
sophisticated tools of statistical mechanics. Examples include:
.
Correlations: Kinetic theory’s distribution function N tells us, on average,
how many particles will occupy a given phase-space volume, but it says noth-
ing about whether the particles like to clump or prefer to avoid one another.
It is therefore inadequate to describe, for example, the distributions of galax-
ies and stars, which cluster under their mutual gravitational attraction (Sec.
4.10.1), or that of electrons in a plasma, which are mutually repulsive and
thus are spatially anticorrelated (Sec. 22.6).
.
Fluctuations: In experiments to measure a very weak mechanical force (e.g.,
tests of the equivalence principle and searches for gravitational waves), one
typically monitors the motion of a pendulum’s test mass, on which the
force acts. Molecules of gas hitting the test mass also make it move. Kinetic
theory predicts how many molecules will hit in 1 ms, on average, and how
strong is the resulting pressure acting in all directions; but kinetic theory’s
distribution function N cannot tell us the probability that in 1 ms more
molecules will hit one side of the test mass than the other, mimicking the
force one is trying to measure. The probability distribution for ﬂuctuations
is an essential tool for analyzing the noise in this and any other physical
experiment, and it falls in the domain of statistical mechanics, not kinetic
theory (Sec. 5.6).
.
Strongly interacting particles: As should be familiar, the thermal motions of
an ionic crystal are best described not in terms of individual atoms (as in
the Einstein theory), but instead by decomposing the atoms’ motion into
155

BOX 4.1.
READERS’ GUIDE
.
Relativity enters into portions of this chapter solely via the relativistic
energies and momenta of high-speed particles (Sec. 1.10). We
presume that all readers are familiar with at least this much relativity
and accordingly, we do not provide a Newtonian track through this
chapter. We make occasional additional side remarks for the beneﬁt
of relativistic readers, but a Newtonian reader’s failure to understand
them will not compromise mastering all of this chapter’s material.
.
This chapter relies in crucial ways on Secs. 3.2, 3.3, 3.5.1, 3.5.2, 3.5.5,
and 3.6, and Box 3.3.
.
Chapter 5 is an extension of this chapter. To understand it and
portions of Chap. 6, one must master the fundamental concepts of
statistical mechanics in this chapter (Secs. 4.2–4.8).
.
Other chapters do not depend strongly on this one.
normal modes (phonons; Debye theory). The thermal excitation of phonons
is governed by statistical mechanics [Eq. (4.26)].
.
Microscopic origin of thermodynamic laws: The laws of classical thermo-
dynamics can be (and often are) derived from a few elementary, macroscopic
postulates without any reference to the microscopic, atomic nature of mat-
ter. Kinetic theory provides a microscopic foundation for some of thermo-
dynamics’ abstract macroscopic ideas (e.g., the ﬁrst law of thermodynamics)
and permits the computation of equations of state. However, a full appreci-
ation of entropy and the second law of thermodynamics (Sec. 4.7), and of
behavior at phase transitions (Secs. 4.9, 5.5.2, 5.8.2, and 5.8.4) requires the
machinery of statistical mechanics.
In this chapter, we develop the conceptual foundations for classical statistical me-
chanics and its interface with quantum physics, and we also delve deeply enough into
the quantum world to be able to treat a few simple quantum problems. More specif-
ically, in Sec. 4.2, we introduce the concepts of systems, ensembles of systems, and
the distribution function for an ensemble. In Sec. 4.3, we use Hamiltonian dynamics
to study the evolution of an ensemble’s distribution function and derive the statistical
mechanical version of Liouville’s theorem. In Sec. 4.4, we develop the concept of statis-
tical equilibrium and derive the general form of distribution functions for ensembles
of systems that have reached statistical equilibrium (Sec. 4.4.2) and speciﬁc forms
that depend on what additive macroscopic quantities the systems can exchange with
their thermalized environment: energy exchange (canonical distribution, Sec. 4.4.1),
156
Chapter 4. Statistical Mechanics

energy and volume exchange (Gibbs distribution, Sec. 4.4.2), energy and particle
exchange (grand canonical distribution, Sec. 4.4.2), and nothing exchanged (micro-
canonical distribution, Sec. 4.5).
In Chap. 5, we study these equilibrium distributions in considerable detail, espe-
cially their relationship to the laws of thermodynamics. Here in Chap. 4, we use them
to explore some fundamental statistical mechanics issues:
1. aderivationoftheBose-EinsteinandFermi-Diracdistributionsforthemean
occupation number of a single-particle quantum state, which we studied in
depth in Chap. 3 (Sec. 4.4.3);
2. a discussion and proof of the equipartition theorem for classical, quadratic
degrees of freedom (Sec. 4.4.4);
3. the relationship between the microcanonical ensemble and ergodicity (the
ergodic evolution of a single, isolated system; Sec. 4.6);
4. the concept of the entropy of an arbitrary ensemble of systems, and the
increase of entropy (second law of thermodynamics) as an ensemble of
isolated (“closed”) systems evolves into its equilibrium, microcanonical form
via phase mixing,coarse graining,and (quantum mechanically) via discarding
quantum correlations—it’s the physicist’s fault!—(Sec. 4.7);
5. the entropy increase when two gases are mixed, and how quantum mechan-
ics resolved the highly classical Gibbs Paradox (Ex. 4.8);
6. the power of entropy per particle as a tool for studying the evolution of
physical systems (Sec. 4.8 and Ex. 4.10); and
7. Bose-Einstein condensation of a dilute gas of bosonic atoms (Sec. 4.9).
We conclude with a discussion of statistical mechanics in the presence of gravity
(applications to galaxies, black holes, and the universe as a whole; Sec. 4.10) and a brief
introduction to the concept of information and its connection to entropy (Sec. 4.11).
4.2
4.2 Systems, Ensembles, and Distribution Functions
4.2.1
4.2.1 Systems
systems
Systems play the same role in statistical mechanics as is played by particles in kinetic
theory. A system is any physical entity. (Obviously, this is an exceedingly general
concept!) Examples are a galaxy, the Sun, a sapphire crystal, the fundamental mode
of vibration of that crystal, an aluminum atom in that crystal, an electron from that
aluminum atom, a quantum state in which that electron could reside, . . . .
SEMICLOSED SYSTEMS
Statistical mechanics focuses special attention on systems that couple only weakly to
the rest of the universe. Stated more precisely, we are interested in systems whose
internal and external
timescales
relevant internal evolution timescales, τint, are short compared with the external
timescales, τext, on which they exchange energy, entropy, particles, and so forth,
4.2 Systems, Ensembles, and Distribution Functions
157

with their surroundings. Such systems are said to be semiclosed, and in the idealized
semiclosed systems
limit where one completely ignores their external interactions, they are said to be
closed systems
closed. The statistical mechanics formalism for dealing with them relies on the as-
sumption τint/τext ≪1; in this sense, it is a variant of a two-lengthscale expansion
(Box 3.3).
Some examples will elucidate these concepts. For a galaxy of, say, 1011 stars, τint
is the time it takes a star to cross the galaxy, so τint ∼108 yr. The external timescale
is the time since the galaxy’s last collison with a neighboring galaxy or the time since
it was born by separating from the material that formed neighboring galaxies; both
these times are τext ∼1010 yr, so τint/τext ∼1/100, and the galaxy is semiclosed. For
a small volume of gas inside the Sun (say, 1 m on a side), τint is the timescale for the
constituent electrons, ions, and photons to interact through collisions, τint <∼10−10 s;
this is much smaller than the time for external heat or particles to diffuse from the
cube’s surface to its center, τext >∼10−5 s, so the cube is semiclosed. An individual
atom in a crystal is so strongly coupled to its neighboring atoms by electrostatic
forces that τint ∼τext, which means the atom is not semiclosed. By contrast, for a
vibrational mode of the crystal, τint is the mode’s vibration period, and τext is the
time to exchange energy with other modes and thereby damp the chosen mode’s
vibrations; quite generally, the damping time is far longer than the period, so the
mode is semiclosed. (For a highly polished, cold sapphire crystal weighing several
kilograms, τext can be ∼109 τint.) Therefore, it is the crystal’s vibrational normal
modes and not its atoms that are amenable to the statistical mechanical tools we shall
develop.
CLOSED SYSTEMS AND THEIR HAMILTONIANS
When a semiclosed classical system is idealized as closed, so its interactions with the
external universe are ignored, then its evolution can be described using Hamilto-
nian dynamics (see, e.g., Marion and Thornton, 1995; Landau and Lifshitz, 1976;
Goldstein, Poole, and Safko, 2002). The system’s classical state is described by gen-
eralized coordinates q ≡{qj} and generalized momenta p ≡{pj}, where the index j
runs from 1 to W = (the system’s number of degrees of freedom). The evolution of
Hamilton’s equations for a
closed system
q, p is governed by Hamilton’s equations
dqj
dt = ∂H
∂pj
,
dpj
dt = −∂H
∂qj
,
(4.1)
where H(q, p) is the hamiltonian, and each equation is really W separate equations.
Note that, because the system is idealized as closed, there is no explicit time depen-
dence in the hamiltonian. Of course, not all physical systems (e.g., not those with
strong internal dissipation) are describable by Hamiltonian dynamics, though in prin-
158
Chapter 4. Statistical Mechanics

ciple this restriction can usually be circumvented by increasing the number of degrees
of freedom to include the cause of the dissipation.1
EXAMPLES
Let us return to our examples. For an individual star inside a galaxy, there are three
degrees of freedom (W = 3), which we might choose to be the motion along three
mutually orthogonal Cartesian directions, so q1 = x, q2 = y, q3 = z. Because the star’s
speed is small compared to that of light, its hamiltonian has the standard form for a
nonrelativistic particle:
H(q, p) = 1
2m(p1
2 + p2
2 + p3
2) + m(q1, q2, q3).
(4.2)
Here m is the stellar mass, and (q1, q2, q3) is the galaxy’s Newtonian gravitational
potential (whose sign we take to be negative). Now, consider not just one star, but
K ∼1011 of them in a galaxy. There are now W = 3K degrees of freedom, and the
hamiltonian is simply the sum of the hamiltonians for each individual star, so long as
we ignore interactions between pairs of stars. The great power of the principles that
we will develop is that they do not depend on whether W = 1 or W = 3 × 1011.
If our system is the fundamental mode of a sapphire crystal, then the number of
degrees of freedom is only W = 1, and we can take the single generalized coordinate
q to be the displacement of one end of the crystal from equilibrium. There will be an
effective mass M for the mode (approximately equal to the actual mass of the crystal)
such that the mode’s generalized momentum is p = Mdq/dt. The hamiltonian will
be the standard one for a harmonic oscillator:
H(p, q) = p2
2M + 1
2Mω2q2,
(4.3a)
where ω is the mode’s angular frequency of oscillation.
If we want to describe a whole crystal weighing several kilograms and having K ∼
1026 atoms, then we obtain H by summing over W = 3K oscillator hamiltonians for
the crystal’s W normal modes and adding an interaction potential Hint that accounts
for the very weak interactions among modes:
H =
W
 
j=1
, p2
j
2Mj
+ 1
2Mjωj
2qj
2
-
+ Hint(q1, . . . , qW , p1, . . . , pW).
(4.3b)
Here Mj is the effective mass of mode j, and ωj is the mode’s angular frequency.
This description of the crystal is preferable to one in which we use, as our generalized
coordinates and momenta, the coordinate locations and momentum components of
each of the 1026 atoms. Why? Because the normal modes are so weakly coupled to one
1.
For example, if we add damping to a simple harmonic oscillator, we can either treat the system as (in
principle) hamiltonian by allowing for all the internal degrees of freedom associated with the damping,
for example friction, or as (in practice) non-hamiltonian with an external heat sink.
4.2 Systems, Ensembles, and Distribution Functions
159

another that they are semiclosed subsystems of the crystal, whereas the atoms are so
strongly coupled that they are not, individually, semiclosed. As we shall see, there is
great power in decomposing a complicated system into semiclosed subsystems.
4.2.2
4.2.2 Ensembles
ensemble of systems
In kinetic theory, we study statistically a collection of a huge number of particles.
Similarly, in statistical mechanics, we study statistically a collection or ensemble of
a huge number of systems. This ensemble is actually only a conceptual device, a
foundation for statistical arguments that take the form of thought experiments. As we
shall see, there are many different ways that one can imagine forming an ensemble,
and this freedom can be used to solve many different types of problems.
In some applications, we require that all the systems in the ensemble be closed and
be identical in the sense that they all have the same number of degrees of freedom, W;
are governed by hamiltonians with the same functional forms H(q, p); and have the
samevolumeV andtotalinternalenergyE (orE, includingrestmasses).However, the
values of the generalized coordinates and momenta at a speciﬁc time t, {q(t), p(t)},
need not be the same (i.e., the systems need not be in the same state at time t). If such a
conceptual ensemble of identical closed systems (ﬁrst studied by Boltzmann) evolves
until it reaches statistical equilibrium (Sec. 4.5), it then is called microcanonical; see
microcanonical ensemble
Table 4.1.
Sometimes we deal with an ensemble of systems that can exchange energy (heat)
with their identical surroundings, so the internal energy of each system can ﬂuctuate.
If the surroundings (sometimes called heat baths) have far greater heat capacity than
heat baths
the individual systems, and if statistical equilibrium has been reached, then we call
canonical ensemble
this sort of ensemble (introduced by Gibbs) canonical.
At the next level of generality, the systems can also expand (i.e., they can exchange
volume as well as energy with their identical surroundings). This case was also studied
by Gibbs—his text (Gibbs, 1902) still repays reading—and in equilibrium it is known
Gibbs ensemble
as the Gibbs ensemble; its environment is a heat and volume bath. A fourth ensemble in
common use is Pauli’s grand canonical ensemble, in which each system can exchange
Pauli’s grand canonical
ensemble
TABLE 4.1: Statistical-equilibrium ensembles used in this chapter
Ensemble
Quantities exchanged with surroundings
Microcanonical
Nothing
Canonical
Energy E
Gibbs
Energy E and volume V
Grand canonical
Energy E and number of particles NI of various species I
Note: For relativistic systems we usually include the rest masses of all particles in the energy, so E is replaced
by E in the above formulas.
160
Chapter 4. Statistical Mechanics

energy and particles (but not volume) with its surroundings; see Table 4.1. We study
these equilibrium ensembles and their baths in Secs. 4.4 and 4.5.
4.2.3
4.2.3 Distribution Function
DISTRIBUTION FUNCTION AS A PROBABILITY
In kinetic theory (Chap. 3), we described the statistical properties of a collection
of identical particles by a distribution function, and we found it useful to tie that
distribution function’s normalization to quantum theory: η(t; x, p) = (mean number
of particles that occupy a quantum state at location {x, p} in 6-dimensional phase
space at time t). In statistical mechanics, we use the obvious generalization of this:
η = (mean number of systems that occupy a quantum state at location {q, p} in
an ensemble’s 2W-dimensional phase space, at time t)—except that we need two
modiﬁcations:
1. This generalized η is proportional to the number of systems Nsys in our
ensemble. (If we double Nsys, then η will double.) Because our ensemble is
only a conceptual device, we don’t really care how many systems it contains,
so we divide η by Nsys to get a renormalized, Nsys-independent distribution
function, ρ = η/Nsys, whose physical interpretation is
probabilistic distribution
function
ρ(t; q, p) =
⎛
⎝
probability that a system, drawn randomly
from our ensemble, will be in a quantum state
at location (q, p) in phase space at time t
⎞
⎠. (4.4)
2. If the systems of our ensemble can exchange particles with the external
universe (as is the case, for example, in the grand canonical ensemble of
Table 4.1), then their number of degrees of freedom, W, can change, so ρ
may depend on W as well as on location in the 2W-dimensional phase space:
ρ(t; W , q, p).
In the sector of the system’s phase space with W degrees of freedom, denote the
number density of quantum states by
density of states
Nstates(W , q, p) = dNstates
dWqdWp ≡dNstates
dW
.
(4.5)
Here we have used
dWq ≡dq1dq2 . . . dqW ,
dWp ≡dp1dp2 . . . dpW ,
dW ≡dWq dWp.
(4.6)
Then the sum of the occupation probability ρ over all quantum states, which must
(by the meaning of probability) be unity, takes the form
normalization of
distribution function
 
n
ρn =
 
W

ρNstatesdW = 1.
(4.7)
On the left-hand side n is a formal index that labels the various quantum states
|n⟩available to the ensemble’s systems; on the right-hand side the sum is over all
4.2 Systems, Ensembles, and Distribution Functions
161

possible values of the system’s dimensionality W, and the integral is over all of the
2W-dimensional phase space, with dW a short-hand notation for the phase-space
integration element dWqdWp.
GEOMETRICAL VIEWPOINT
Equations (4.4)–(4.7) require some discussion. Just as the events and 4-momenta
in relativistic kinetic theory are geometric, frame-independent objects, similarly lo-
cation in phase space in statistical mechanics is a geometric, coordinate-independent
concept (though our notation does not emphasize it). The quantities {q, p} ≡
{q1, q2, . . . , qW , p1, p2, . . . , pW} are the coordinates of that phase-space location.
When one makes a canonical transformation from one set of generalized coordinates
and momenta to another (Ex. 4.1), the qs and ps change, but the geometric location
in phase space does not. Moreover, just as the individual spatial and momentum vol-
umes dVx and dVp occupied by a set of relativistic particles in kinetic theory are frame
dependent, but their product dVxdVp is frame-independent [cf. Eqs. (3.7a)–(3.7c)],
so also in statistical mechanics the volumes dWq and dWp occupied by some chosen
set of systems are dependent on the choice of canonical coordinates (they change un-
der a canonical transformation), but the product dWqdWp ≡dW (the systems’ total
volume in phase space) is independent of the choice of canonical coordinates and is
unchanged by a canonical transformation. Correspondingly, the number density of
states in phase space Nstates = dNstates/dW and the statistical mechanical distribution
ρρρ and Nstates
Nstates
Nstates as geometric
objects
function ρ(t; W , q, p), like their kinetic-theory counterparts, are geometric, coordinate-
independent quantities: they are unchanged by a canonical transformation. See Ex. 4.1
and references cited there.
DENSITY OF STATES
Classical thermodynamics was one of the crowning achievements of nineteenth-
century science. However, thermodynamics was inevitably incomplete and had to
remain so until the development of quantum theory. A major difﬁculty, one that we
have already confronted in Chap. 3, was how to count the number of states available to
a system. As we saw in Chap. 3, the number density of quantum mechanical states in
the 6-dimensional, single-particle phase space of kinetic theory is (ignoring particle
spin)Nstates = 1/h3, wherehisPlanck’sconstant.Generalizingtothe2W-dimensional
phase space of statistical mechanics, the number density of states turns out to be 1/hW
[one factor of 1/h for each of the canonical pairs (q1, p1), (q2, p2), . . . , (qW , pW)].
Formally, this follows from the canonical quantization procedure of elementary quan-
tum mechanics.
DISTINGUISHABILITY AND MULTIPLICITY
distinguishability of
particles
There was a second problem in nineteenth-century classical thermodynamics, that
of distinguishability: If we swap two similar atoms in phase space, do we have a new
state or not? If we mix two containers of the same gas at the same temperature and
pressure, does the entropy increase (Ex. 4.8)? This problem was recognized classically
162
Chapter 4. Statistical Mechanics

but was not resolved in a completely satisfactory classical manner. When the laws of
quantum mechanics were developed, it became clear that all identical particles are
indistinguishable, so having particle 1 at location A in phase space and an identical
particle 2 at location B must be counted as the same state as particle 1 at B and particle
2 at A. Correspondingly, if we attribute half the quantum state to the classical phase-
space location {1 at A, 2 at B} and the other half to {1 at B, 2 at A}, then the classical
number density of states per unit volume of phase space must be reduced by a factor
multiplicity
of 2—and more generally by some multiplicity factor M. In general, therefore, we can
write the actual number density of states in phase space as
density of states
Nstates = dNstates
dW
=
1
MhW ,
(4.8a)
and correspondingly, we can rewrite the normalization condition (4.7) for our prob-
abilistic distribution function as
 
n
ρn ≡
 
W

ρNstatesdW =
 
W

ρ dW
MhW = 1.
(4.8b)
This equation can be regarded, in the classical domain, as deﬁning the meaning of the
sum over states n. We shall make extensive use of such sums over states.
For N identical and indistinguishable particles with zero spin, it is not hard to see
that M= N!. If we include the effects of quantum mechanical spin (and the spin states
can be regarded as degenerate), then there are gs [Eq. (3.16)] more states present in
the phase space of each particle than we thought, so an individual state’s multiplicity
M (the number of different phase-space locations to be attributed to the state) is
reduced to
M = N!
gsN
for a system of N identical particles with spin s.
(4.8c)
This is thequantitythatappearsinthedenominator ofthe sumover states[Eq. (4.8b)].
Occasionally, for conceptual purposes it is useful to introduce a renormalized
distribution function Nsys, analogous to kinetic theory’s number density of particles
in phase space:
number density of systems
in phase space
Nsys = Nsys Nstates ρ =
d(number of systems)
d(volume in 2W-dimensional phase space).
(4.9)
However, this version of the distribution function will rarely if ever be useful
computationally.
ENSEMBLE AVERAGE
Each system in an ensemble is endowed with a total energy that is equal to its hamilto-
nian, E = H(q, p) [or relativistically, E = H(q, p)]. Because different systems reside
at different locations (q, p) in phase space, they typically will have different energies.
4.2 Systems, Ensembles, and Distribution Functions
163

A quantity of much interest is the ensemble-averaged energy,which is the average value
of E over all systems in the ensemble:
⟨E⟩=
 
n
ρn En =
 
W

ρ ENstatesdW =
 
W

ρ E dW
MhW .
(4.10a)
For any other function A(q, p) deﬁned on the phase space of a system (e.g., the linear
momentum or the angular momentum), one can compute an ensemble average by
the obvious analog of Eq. (4.10a):
ensemble average
⟨A⟩=
 
n
ρnAn.
(4.10b)
Ourprobabilisticdistributionfunctionρn = ρ(t; W , q, p)hasdeeperconnections
to quantum theory than the above discussion reveals. In the quantum domain, even
if we start with a system whose wave function ψ is in a pure state (ordinary, everyday
type of quantum state), the system may evolve into a mixed state as a result of (i) inter-
action with the rest of the universe and (ii) our choice not to keep track of correlations
between the universe and the system (Box 4.2 and Sec. 4.7.2). The system’s initial, pure
state can be described in geometric, basis-independent quantum language by a state
vector (“ket”) |ψ⟩; but its ﬁnal, mixed state requires a different kind of quantum de-
scription: a density operator ˆρ. In the classical limit, the quantum mechanical density
operator ˆρ becomes our classical probabilistic distribution functionρ(t, W , q, p); see
Box 4.2 for some details.
EXERCISES
Exercise 4.1 Example: Canonical Transformation
Canonical transformations are treated in advanced textbooks on mechanics, such as
Goldstein, Poole, and Safko (2002, Chap. 9) or, more concisely, Landau and Lifshitz
(1976). This exercise gives a brief introduction. For simplicity we assume the hamil-
tionian is time independent.
Let (qj, pk) be one set of generalized coordinates and momenta for a given system.
We can transform to another set (Qj, Pk), which may be more convenient, using
a generating function that connects the old and new sets. One type of generating
function is F(qj, Pk), which depends on the old coordinates {qj} and new momenta
{Pk}, such that
pj = ∂F
∂qj
,
Qj = ∂F
∂Pj
.
(4.11)
(a) As an example, what are the new coordinates and momenta in terms of the old
that result from
F =
W
 
i=1
fi(q1, q2, . . . , qW)Pi,
(4.12)
where fi are arbitrary functions of the old coordinates?
164
Chapter 4. Statistical Mechanics

BOX 4.2.
DENSITY OPERATOR AND QUANTUM
STATISTICAL MECHANICS
Here we describe brieﬂy the connection of our probabilistic distribution
function ρ to the full quantum statistical theory as laid out, for example,
in Sethna (2006, Sec. 7.1.1) and Cohen-Tannoudji, Diu, and Lalo¨e (1977,
complement EIII), or in much greater detail in Pathria and Beale (2011,
Chap. 5) and Feynman (1972).
Consider a single quantum mechanical system that is in a pure state |ψ⟩.
One can formulate the theory of such a pure state equally well in terms of
|ψ⟩or the density operator ˆϱ ≡|ψ⟩⟨ψ|. For example, the expectation value
of some observable, described by a Hermitian operator ˆA, can be expressed
equally well as ⟨A⟩= ⟨ψ| ˆA|ψ⟩or as ⟨A⟩= Trace(ˆϱ ˆA).2
If our chosen system interacts with the external universe and we have no
knowledge of the correlations that the interaction creates between the system
and the universe, then the interaction drives the system into a mixed state,
which is describable by a density operator ˆϱ but not by a ket vector |ψ⟩. This
ˆϱ can be regarded as a classical-type average of |ψ⟩⟨ψ| over an ensemble of
systems, each of which has interacted with the external universe and then
has been driven into a pure state |ψ⟩by a measurement of the universe.
Equivalently, ˆϱ can be constructed from the pure state of universe plus system
by “tracing over the universe’s degrees of freedom.”
If the systems in the ensemble behave nearly classically, then it turns
out that in the basis |φn⟩, whose states are labeled by the classical variables
n = {W , q, p}, the density matrix ϱnm ≡⟨φn|ˆϱ|φm⟩is very nearly diagonal.
The classical probability ρn of classical statistical mechanics (and of this book
when dealing with classical or quantum systems) is then equal to the diagonal
value of this density matrix: ρn = ϱnn.
It can be demonstrated that the equation of motion for the density operator
ˆϱ, when the systems in the quantum mechanical ensemble are all evolving
freely (no signiﬁcant interactions with the external universe), is
∂ˆϱ
∂t + 1
iℏ[ˆϱ, ˆH]= 0.
(1)
This is the quantum statistical analog of the Liouville equation (4.15), and
the quantum mechanical commutator [ˆϱ, ˆH] appearing here is the quantum
2. In any basis |φi⟩, “Trace” is just the trace of the matrix product !
j ϱijAjk, where
Ajk ≡⟨φj| ˆA|φk⟩, and ϱij ≡⟨φi|ˆϱ|φj⟩is called the density matrix in that basis. Sometimes ˆρ itself
is called the density matrix, even though it is an operator.
(continued)
4.2 Systems, Ensembles, and Distribution Functions
165

BOX 4.2.
(continued)
mechanical analog of the Poisson bracket [ρ, H]q,p, which appears in the
Liouville equation. If the ensemble’s quantum systems are in eigenstates of
their hamiltonians, then ˆϱ commutes with ˆH, so the density matrix is constant
in time and there will be no transitions. This is the quantum analog of the
classical ρ being constant in time and thus a constant of the motion (Sec. 4.4).
(b) The
canonical
transformation
generated
by
Eq.
(4.11)
for
arbitrary
F(qj, Pk) leaves unchanged the value, but not the functional form, of the hamil-
tonian at each point in phase space. In other words, H is a geometric, coordinate-
independent function (scalar ﬁeld) of location in phase space. Show, for the
special case of a system with one degree of freedom (one q, one p, one Q, and
one P ), that if Hamilton’s equations (4.1) are satisﬁed in the old variables (q, p),
then they will be satisﬁed in the new variables (Q, P).
(c) Show, for a system with one degree of freedom, that although dq ̸= dQ and dp ̸=
dP , the volume in phase space is unaffected by the canonical transformation:
dpdq = dP dQ.
(d) Hence show that for any closed path in phase space,
.
pdq =
.
P dQ. These
results are readily generalized to more than one degree of freedom.
4.3
4.3 Liouville’s Theorem and the Evolution of the Distribution Function
In kinetic theory, the distribution function N is not only a frame-independent en-
tity, it is also a constant along the trajectory of any freely moving particle, so long
as collisions between particles are negligible. Similarly, in statistical mechanics, the
probability ρ is not only coordinate-independent (unaffected by canonical transfor-
Liouville’s theorem
mations); ρ is also a constant along the phase-space trajectory of any freely evolving
system, so long as the systems in the ensemble are not interacting signiﬁcantly with
the external universe (i.e., so long as they can be idealized as closed). This is the sta-
tistical mechanical version of Liouville’s theorem, and its proof is a simple exercise
in Hamiltonian mechanics, analogous to the “sophisticated” proof of the collisionless
Boltzmann equation in Box 3.2.
Since the ensemble’s systems are closed, no system changes its dimensionality W
during its evolution. This permits us to ﬁx W in the proof. Since no systems are
created or destroyed during their evolution, the number density of systems in phase
space, Nsys = Nsys Nstates ρ [Eq. (4.9)], must obey the same kind of conservation law
as we encountered in Eq. (1.30) for electric charge and particle number in Newtonian
166
Chapter 4. Statistical Mechanics

physics. For particle number in a ﬂuid, the conservation law is ∂n/∂t + ∇. (nv) = 0,
wherenisthenumberdensityofparticlesinphysicalspace, v istheircommonvelocity
(theﬂuid’svelocity)inphysicalspace, andnv istheirﬂux.Ourensemble’ssystemshave
velocity dqj/dt = ∂H/∂pj in physical space and “velocity” dpj/dt = −∂H/∂qj in
momentum space, so by analogy with particle number in a ﬂuid, the conservation law
(valid for ρ as well as for Nsys, since they are proportional to each other) is
conservation law for
systems
∂ρ
∂t + ∂
∂qj

ρ
dqj
dt

+
∂
∂pj

ρ
dpj
dt

= 0.
(4.13)
Equation (4.13) has an implicit sum, from 1 to W, over the repeated index j (recall
the Einstein summation convention, Sec. 1.5). Using Hamilton’s equations, we can
rewrite this as
0 = ∂ρ
∂t + ∂
∂qj
*
ρ ∂H
∂pj
+
−
∂
∂pj
*
ρ ∂H
∂qj
+
= ∂ρ
∂t + ∂ρ
∂qj
∂H
∂pj
−∂ρ
∂pj
∂H
∂qj
= ∂ρ
∂t + [ρ, H]q,p,
(4.14)
where [ρ, H]q,p is the Poisson bracket (e.g., Landau and Lifshitz, 1976; Marion and
Thornton, 1995; Goldstein, Poole, and Safko, 2002). By using Hamilton’s equations
once again in the second expression, we discover that this is the time derivative of ρ
moving with a ﬁducial system through the 2W-dimensional phase space:
Liouville equation
(collisionless Boltzmann
equation)
dρ
dt

moving with a
ﬁducial system
≡∂ρ
∂t +
dqj
dt
∂ρ
∂qj
+
dpj
dt
∂ρ
∂pj
= ∂ρ
∂t + [ρ, H]q,p = 0.
(4.15)
Therefore, the probability ρ is constant along the system’s phase space trajectory, as
was to be proved.
We call Eq. (4.15), which embodies this Liouville theorem, the statistical mechan-
ical Liouville equation or collisionless Boltzmann equation.
Asasimple, qualitativeexample, considerasystemconsistingofhotgasexpanding
adiabatically, so its large random kinetic energy is converted into ordered radial
motion. If we examine a set S of such systems very close to one another in phase
space, then it is apparent that, as the expansion proceeds, the size of S’s physical-space
volume dWq increases and the size of its momentum-space volume dWp diminishes,
so that the product dWq dWp remains constant (Fig. 4.1), and correspondingly ρ ∝
Nsys = dNsys/dWq dWp is constant.
What happens if the systems being studied interact weakly with their surround-
ings? We must then include an interaction term on the right-hand side of Eq. (4.15),
4.3 Liouville’s Theorem and the Evolution of the Distribution Function
167

(a)
(b)
pi
pi
qi
qi
FIGURE 4.1 Liouville’s theorem. (a) The region in the qi-pi part of phase space
(with i ﬁxed) occupied by a set S of identical, closed systems at time t = 0.
(b) The region occupied by the same set of systems a short time later, t > 0.
The hamiltonian-generated evolution of the individual systems has moved
them in such a manner as to skew the region they occupy, but the volume

dpidqi is unchanged.
thereby converting it into the statistical mechanical version of the Boltzmann trans-
port equation:
Boltzmann transport
equation
dρ
dt

moving with a
ﬁducial system
=
dρ
dt

interactions
.
(4.16)
Thetimederivativeontheleftisnowtakenmovingthroughphasespacewithaﬁducial
system that does not interact with the external universe.
4.4
4.4 Statistical Equilibrium
In this section’s discussion of statistical equilibrium, we begin by writing formulas in
the relativistic form, where rest masses are included in the energy E; afterward we
take the Newtonian limit.
the meaning of
temperature
Before we start, we should clarify what we mean by the temperature of a system.
The ﬁrst point to make is that a rigorous deﬁnition presumes thermodynamic equilib-
rium for the system in question, which can be anything from a two-level atom to the
early universe. We can then say that two systems that are in equilibrium and whose
average properties do not change when they are brought into contact (so they can
exchange heat) have the same temperature and that this attribute is transitive. (This
is known as the zeroth law of thermodynamics.) This allows us to deﬁne the temper-
ature of a reference system as a monotonic function that increases as heat is added to
it. This reference system can then be used to assign a temperature to every other body
with which it can be brought into equilibrium; cf. Sec. 5.2.3. There are several ways
to specify this function. The one that we shall follow [Eqs. (4.19) and following text]
is surprisingly general and depends on simple ideas from probability.3
3.
Other approaches to the deﬁnition of temperature involve the engineering-inspired Carnot cycle, the
mathematical Carath´eodory approach, and the ﬂuctuation-dissipation theorem expressed, for example,
168
Chapter 4. Statistical Mechanics

4.4.1
4.4.1 Canonical Ensemble and Distribution
STATISTICAL EQUILIBRIUM AND JEANS’ THEOREM
Consider an ensemble of identical systems, all of which have the same huge number of
degrees of freedom (dimensionality W ≫1). Put all the systems initially in the same
state, and then let them exchange heat (but not particles, volume, or anything else)
with an external thermal bath that has a huge heat capacity and is in thermodynamic
equilibrium at some temperature T . (For example, the systems might be impermeable
cubes of gas 1 km on a side near the center of the Sun, and the thermal bath might
be all the surrounding gas near the Sun’s center; or the systems might be identical
sapphire crystals inside a huge cryostat, and the thermal bath might be the cryostat’s
huge store of liquid helium.) After a sufﬁciently long time, t ≫τext, the ensemble
will settle down into equilibrium with the bath (i.e., it will become the canonical
ensemble mentioned in Table 4.1 above). In this ﬁnal, canonical equilibrium state,
the probability ρ(t, q, p) is independent of time t, and it no longer is affected by
interactions with the external environment. In other words, the interaction terms in
the evolution equation (4.16) have ceased to have any net effect: on average, for each
interaction event that feeds energy into a system, there is an interaction event that
takes away an equal amount of energy. The distribution function, therefore, satisﬁes
the interaction-free, collisionless Boltzmann equation (4.15) with the time derivative
∂ρ/∂t removed:
statistical equilibrium
[ρ, H]q,p ≡∂ρ
∂qj
∂H
∂pj
−∂ρ
∂pj
∂H
∂qj
= 0.
(4.17)
We use the phrase statistical equilibrium to refer to any ensemble whose distribution
function has attained such a state and thus satisﬁes Eq. (4.17).
Equation (4.17) is a well-known equation in Hamiltonian mechanics. It says that ρ
is a function solely of constants of the individual systems’ hamiltonian-induced mo-
tions (e.g., Landau and Lifshitz, 1976; Marion and Thornton, 1995; Goldstein, Poole,
and Safko, 2002); in other words, ρ can depend on location (q, p) in phase space
only through those constants of the motion. Sometimes this goes by the name Jeans’
Jeans’ theorem
theorem. Among the constants of motion in typical situations (for typical hamiltoni-
ans) are the system’s energy E, its linear momentum P, its angular momentum J, its
number NI of conserved particles of various types I (e.g., electrons, protons), and its
volume V. Notice that these constants of motion E, P, J, NI, and V are all additive: if
we double the size of a system, they each double. We call such additive constants of
the hamiltonian-induced motion extensive variables (a term borrowed from thermo-
dynamics) and denote them by an enumerated list K1, K2, . . . .
extensive variables
Now, thesystemswearestudyinghaveexchangedenergyE withtheirenvironment
(the thermal bath) and thereby have acquired some range of E values; therefore, ρ
as Johnson noise (Sec. 6.8.1). These are covered in many thermodynamics texts (e.g., Reif, 2008) and
lead to the same temperature scale.
4.4 Statistical Equilibrium
169

can depend on E. However, the systems have not exchanged anything else with their
environment, and they all thus have retained their original (identical) values of the
other extensive variables KA; therefore, ρ must be a delta function in these other
variables. We write
ρ = ρ(E)
(4.18a)
and do not write down the delta functions explicitly.
As an aid in discovering the form of the function ρ(E), let us decompose each
system in the ensemble into a huge number of subsystems. For example, each system
might be a cube 1 km on a side inside the Sun, and its subsystems might be the 109
1-m cubes into which the system can be divided, or the systems might be identical
sapphire crystals each containing 1026 atoms, and the subsystems might be the crys-
tals’ 3 × 1026 normal modes of vibration. We label the subsystems of each system by
an integer a in such a way that subsystem a in one system has the same hamiltonian as
subsystem a in any other system. (For the sapphire crystals, a = 1could be the funda-
mental mode of vibration, a = 2 the ﬁrst harmonic, a = 3 the second harmonic, etc.)
The subsystems with ﬁxed a make up a subensemble because of their relationship to
subensembles
the original ensemble.
Because the full ensemble is in statistical equilibrium, the subensembles will also
be in statistical equilibrium; therefore, their probabilities must be functions of those
extensive variables E, KA that they can exchange with one another:
ρa = ρa(Ea, K1 a, K2 a, . . .).
(4.18b)
(Although each system can exchange only energy E with its heat bath, the subsystems
may be able to exchange other quantities with one another; for example, if subsystem
a is a 1-m cube inside the Sun with permeable walls, then it can exchange energy Ea
and particles of all species I, so KIa = NIa.)
Since there is such a huge number of subsystems in each system, it is reasonable
to expect that in statistical equilibrium there will be no signiﬁcant correlations at
any given time between the actual state of subsystem a and the state of any other
subsystem. In other words, the probability ρa(Wa,qa, pa) that subsystem a is in a
quantum state with Wa degrees of freedom and with its generalized coordinates and
momenta near the values (qa, pa) is independent of the state of any other subsystem.
This lack of correlations, which can be written as
statistical independence
ρ(E) =
/
a
ρa,
(4.18c)
is called statistical independence.4
4.
Statistical independence is actually a consequence of a two-lengthscale approximation [Box 3.3]. The
size of each subsystem is far smaller than that of the full system, and precise statistical independence
arises in the limit as the ratio of these sizes goes to zero.
170
Chapter 4. Statistical Mechanics

Statistical independence places a severe constraint on the functional forms of ρ
and ρa, as the following argument shows. By taking the logarithm of Eq. (4.18c), we
obtain
ln ρ(E) =
 
a
ln ρa(Ea, K1 a, . . .).
(4.18d)
We also know, since energy is a linearly additive quantity, that
E =
 
a
Ea.
(4.18e)
Now, we have not stipulated the way in which the systems are decomposed into
subsystems. For our solar example, the subsystems might have been 2-m or 7-m cubes
rather than 1-m cubes. Exploiting this freedom, one can deduce that Eqs. (4.18d) and
(4.18e) can be satisﬁed simultaneously if and only if ln ρ and ln ρa depend linearly
on the energies E and Ea, with the same proportionality constant −β:
ln ρa = −βEa + (some function of K1 a, K2 a, . . .),
(4.19a)
ln ρ = −βE + constant.
(4.19b)
The reader presumably will identify β with 1/(kBT ), where T is the temperature of
the thermal bath, as we have implicitly done in Chap. 3. However, what does this
temperature actually mean and how do we deﬁne it? One approach is to choose as our
deﬁnition of temperature
subsystem a single identiﬁed atom in a classical monatomic perfect gas, with atomic
rest mass high enough that the gas is nonrelativistic. The energy E is then just the
atom’s kinetic energy (plus rest mass) and the pressure is nkBT . We then repeat this for
every other atom. Measuring the pressure—mechanically—in this simple system then
deﬁnes kBT . The choice of kB is a mere convention; it is most commonly chosen to set
the temperature of the triple point of water as 273.16 K. Much more complex systems
canthenbeassignedthesametemperatureastheperfectgaswithwhichtheywouldbe
in equilibrium as outlined above. If the reader protests that gases are not perfect at low
or high temperature, then we can substitute free electrons or photons and adopt their
distribution functions as we have described in Sec. 3.3 and will derive in Sec. 4.4.3.
To summarize, an ensemble of identical systems with many degrees of freedom
W ≫1, which have reached statistical equilibrium by exchanging energy but nothing
else with a huge thermal bath, has the following canonical distribution function:
canonical distribution
ρcanonical = C exp(−E/kBT ),
ρcanonical = C′ exp(−E/kBT ) nonrelativistically.
(4.20)
Here E(q, p) is the energy of a system at location {q, p} in phase space, kB is Boltz-
mann’s constant, T is the temperature of the heat bath, and C is whatever normaliza-
tion constant is required to guarantee that !
n ρn = 1. The nonrelativistic expression
is obtained by removing all the particle rest masses from the total energy E and then
taking the low-temperature, low-thermal-velocities limit.
4.4 Statistical Equilibrium
171

Actually, we have proved more than Eq. (4.20). Not only must the ensemble of
huge systems (W ≫1) have the energy dependence ρ ∝exp(−E/(kBT )), so must
each subensemble of smaller systems, ρa ∝exp(−Ea/(kBT )), even if (for example)
the subensemble’s identical subsystems have only one degree of freedom, Wa = 1.
Thus, if the subsystems exchanged only heat with their parent systems, then they
must have the same canonical distribution (4.20) as the parents. This shows that the
canonical distribution is the equilibrium state independently of the number of degrees of
freedom W.
4.4.2
4.4.2 General Equilibrium Ensemble and Distribution;
Gibbs Ensemble; Grand Canonical Ensemble
GENERAL EQUILIBRIUM ENSEMBLE
We can easily generalize the canonical distribution to an ensemble of systems that
exchange other additive conserved quantities (extensive variables) K1, K2, . . . , in
addition to energy E, with a huge, thermalized bath. By an obvious generalization of
the argument in Sec. 4.4.1, the resulting statistical equilibrium distribution function
must have the form
general equilibrium
distribution
ρ = C exp
*
−βE −
 
A
βAKA
+
.
(4.21)
When the extensive variables KA that are exchanged with the bath (and thus appear
extensive variables:
energy, volume, particle
numbers, momentum,
angular momentum
explicitly in the distribution function ρ) are energy E, momentum P, angular mo-
mentum J, the number NI of the species I of conserved particles, volume V , or any
combination of these quantities, it is conventional to rename the multiplicative factors
β and βA so that ρ takes on the form
ρ = C exp
−E + U . P +  . J + !
I ˜μINI −P V
kBT

.
(4.22)
Here T , U, , ˜μI, and P are constants (called intensive variables) that are the same
for all systems and subsystems (i.e., that characterize the full ensemble and all its
bath’s intensive variables:
temperature, pressure,
chemical potentials,
velocity, angular velocity
subensembles and therefore must have been acquired from the bath); any extensive
variable that is not exchanged with the bath must be omitted from the exponential and
be replaced by an implicit delta function.
As we have seen in Sec. 3.3, T is the temperature that the ensemble and subensem-
bles acquired from the bath (i.e., it is the bath temperature). From the Lorentz trans-
formation law for energy and momentum [E′ = γ (E −U . P); Eqs. (2.37) and Ex.
2.13] we see that, if we were to transform to a reference frame that moves with veloc-
ity U with respect to our original frame, then the exp(U . P/(kBT )) term in ρ would
disappear, and the distribution function would be isotropic in P. Thus U is the ve-
locity of the bath with respect to our chosen reference frame. By a similar argument,
 is the bath’s angular velocity with respect to an inertial frame. By comparison with
172
Chapter 4. Statistical Mechanics

Eq. (3.22d), we see that ˜μI is the chemical potential of the conserved species I. Fi-
nally, experience with elementary thermodynamics suggests (and it turns out to be
true) that P is the bath’s pressure.5 Note that, by contrast with the corresponding ex-
tensive variables E, P, J, NI, and V , the intensive variables T , U, , ˜μI, and P do not
double when the size of a system is doubled (i.e., they are not additive); rather, they
are properties of the ensemble as a whole and thus are independent of the systems’
sizes.
By removing the rest masses mI of all particles from each system’s energy and
similarly removing the particle rest mass from each chemical potential,
nonrelativistic energy
and chemical potentials
obtained by removing rest
masses
E ≡E −
 
I
NImI ,
μI ≡˜μI −mI
(4.23)
[Eqs. (3.20) and (3.21)], we bring the distribution function into a form that is identical
to Eq. (4.22) but with E →E and ˜μI →μI:
general equilibrium
distribution
ρ = C exp
−E + U . P +  . J + !
I μINI −P V
kBT

.
(4.24)
This is the form used in Newtonian theory, but it is also valid relativistically.
SPECIAL EQUILIBRIUM ENSEMBLES
Henceforth (except in Sec. 4.10.2, when discussing black-hole atmospheres), we re-
strictourbathsalwaystobeatrestinourchosenreferenceframeandtobenonrotating
with respect to inertial frames, so that U =  = 0. The distribution function ρ can
then either be a delta function in the system momentum P and angular momentum
J (if momentum and angular momentum are not exchanged with the bath), or it can
involve no explicit dependence on P and J (if momentum and angular momentum
are exchanged with the bath; cf. Eq. (4.22) with U =  = 0). In either case, if energy
is the only other quantity exchanged with the bath, then the distribution function is
the canonical one [Eq. (4.20)]:
ρcanonical = C exp
 −E
kBT

= C′ exp
 −E
kBT

,
(4.25a)
where (obviously) the constants C and C′ are related by
C′ = C exp
'
−
 
I
NImI/kBT
(
.
If, in addition to energy, volume can also be exchanged with the bath (e.g., if the
systems are ﬂoppy bags of gas whose volumes can change and through which heat can
5.
One can also identify these physical interpretations of T , ˜μI, and P by analyzing idealized measuring
devices; cf. Sec. 5.2.2.
4.4 Statistical Equilibrium
173

ﬂow),6 then the equilibrium is the Gibbs ensemble,which has the distribution function
Gibbs distribution
ρGibbs = C exp
−(E + P V )
kBT

= C′ exp
−(E + P V )
kBT

(4.25b)
(with an implicit delta function in NI and possibly in J and P). The combination
E + PV is known as the enthalpy H. If the exchanged quantities are energy and
enthalpy
particles but not volume (e.g., if the systems are 1-m cubes inside the Sun with totally
imaginary walls through which particles and heat can ﬂow), then the equilibrium is
the grand canonical ensemble, with
grand canonical
distribution
ρgrand canonical = C exp
−E + !
I ˜μINI
kBT

= C exp
−E + !
I μINI
kBT

(4.25c)
(with an implicit delta function in V and perhaps in J and P).
We mention, as a preview of an issue to be addressed in Chap. 5, that an individual
system, picked randomly from the ensemble and then viewed as a bath for its own
tiny subsystems, will not have the same temperature T , and/or chemical potential ˜μI,
and/or pressure P as the huge bath with which the ensemble has equilibrated; rather,
the individual system’s T , ˜μI, and/or P can ﬂuctuate a tiny bit around the huge bath’s
values (around the values that appear in the above probabilities), just as its E, NI,
and/or V ﬂuctuate. We study these ﬂuctuations in Sec. 5.6.
4.4.3
4.4.3 Fermi-Dirac and Bose-Einstein Distributions
The concepts and results developed in this chapter have enormous generality. They
are valid (when handled with sufﬁcient care) for quantum systems as well as classical
ones, andtheyarevalidforsemiclosedorclosedsystemsofanytype.Thesystemsneed
not resemble the examples we have met in the text. They can be radically different,
but so long as they are closed or semiclosed, our concepts and results will apply.
SINGLE-PARTICLE QUANTUM STATES (MODES)
As an important example, let each system be a single-particle quantum state of
some ﬁeld. These quantum states can exchange particles (quanta) with one an-
other. As we shall see, in this case the above considerations imply that, in sta-
tistical equilibrium at temperature T , the mean number of particles in a state,
whose individual particle energies are E, is given by the Fermi-Dirac formula (for
fermions) η = 1/(e(E−˜μ)/(kBT ) + 1) and Bose-Einstein formula (for bosons) η =
1/(e(E−˜μ)/(kBT ) −1), which we used in our kinetic-theory studies in the last chap-
ter [Eqs. (3.22a), (3.22b)]. Our derivation of these mean occupation numbers will
6.
For example, the huge helium-ﬁlled balloons made of thin plastic that are used to lift scientiﬁc payloads
into Earth’s upper atmosphere.
174
Chapter 4. Statistical Mechanics

illustrate the closeness of classical statistical mechanics and quantum statistical me-
chanics: the proof is fundamentally quantum mechanical, because the regime η ∼1
is quantum mechanical (it violates the classical condition η ≪1); nevertheless, the
proof makes use of precisely the same concepts and techniques as we have developed
for our classical studies.
As a conceptual aid in the derivation, consider an ensemble of complex systems
in statistical equilibrium. Each system can be regarded as made up of a large number
of fermions (electrons, protons, neutrons, neutrinos, . . .) and/or bosons (photons,
gravitons, alpha particles, phonons, . . .). We analyze each system by identifying a
complete set of single-particle quantum states (which we call modes) that the particles
modes
can occupy7 (see, e.g., Chandler, 1987, chap. 4). A complete enumeration of modes
is the starting point for the second quantization formulation of quantum ﬁeld theory
second quantization
and is also the starting point for our far simpler analysis.
Choose one speciﬁc mode S [e.g., a nonrelativistic electron plane-wave mode in
a box of side L with spin up and momentum p = (5, 3, 17)h/L]. There is one such
mode S in each of the systems in our ensemble, and these modes (all identical in their
properties) form a subensemble of our original ensemble. Our derivation focuses on
this subensemble of identical modes S. Because each of these modes can exchange
energy and particles with all the other modes in its system, the subensemble is grand
canonically distributed.
many-particle quantum
states
The (many-particle) quantum states allowed for mode S are states in which S
contains a ﬁnite number n of particles (quanta). Denote by ES the energy of one
particle residing in mode S. Then the mode’s total energy when it is in the state |n⟩
(when it contains n quanta) is En = nES. [For a freely traveling, relativistic electron
mode, ES =

m2 + p2, Eq. (1.40), where p is the mode’s momentum, px = jh/L
for some integer j and similarly for py and pz; for a phonon mode with angular
eigenfrequency of vibration ω, ES = ℏω.] Since the distribution of the ensemble’s
modes among the allowed quantum states is grand canonical, the probability ρn of
being in state |n⟩is [Eq. (4.25c)]
ρn = C exp
−En + ˜μn
kBT

= C exp
n( ˜μ −ES)
kBT

,
(4.26)
where ˜μ and T are the chemical potential and temperature of the bath of other modes,
with which the mode S interacts.8
7.
For photons, these modes are the normal modes of the classical electromagnetic ﬁeld; for phonons in
a crystal, they are the normal modes of the crystal’s vibrations; for nonrelativistic electrons or protons
or alpha particles, they are energy eigenstates of the nonrelativistic Schr¨odinger equation; for relativistic
electrons, they are energy eigenstates of the Dirac equation.
8.
Here and throughout Chaps. 4 and 5 we ignore quantum zero point energies, since they are unobservable
in this context (though they are observed in the ﬂuctuational forces discussed in Sec. 6.8). Equally well
we could include the zero point energies in En, Es, and ˜μ, and they would cancel out in the combinations
that appear, e.g., in Eq. (4.26): ˜μ −Es, and so forth.
4.4 Statistical Equilibrium
175

FERMION MODES: FERMI-DIRAC DISTRIBUTION
Suppose that S is a fermion mode (i.e., its particles have half-integral spin). Then
the Pauli exclusion principle dictates that S cannot contain more than one particle:
n can take on only the values 0 and 1. In this case, the normalization constant in the
distribution function (4.26) is determined by ρ0 + ρ1 = 1, which implies that
Fermi-Dirac distribution
ρ0 =
1
1 + exp[( ˜μ −ES)/(kBT )],
ρ1 =
exp[( ˜μ −ES)/(kBT )]
1 + exp[( ˜μ −ES)/(kBT )] .
(4.27a)
This is the explicit form of the grand canonical distribution for a fermion mode. For
many purposes (including all those in Chap. 3), this full probability distribution is
more than one needs. Quite sufﬁcient instead is the mode’s mean occupation number
Fermi-Dirac mean
occupation number
ηS ≡⟨n⟩=
1
 
n=0
nρn =
1
exp[(ES −˜μ)/(kBT )]+ 1 =
1
exp[(ES −μ)/(kBT )]+ 1.
(4.27b)
Here ES = ES −m is the energy of a particle in the mode with rest mass removed, and
μ = ˜μ −m is the chemical potential with rest mass removed—the quantities used in
the nonrelativistic (Newtonian) regime.
Equation (4.27b) is the Fermi-Dirac mean occupation number asserted in Chap. 3
[Eq. (3.22a)] and studied there for the special case of a gas of freely moving, non-
interacting fermions. Because our derivation is completely general, we conclude
that this mean occupation number and the underlying grand canonical distribu-
tion (4.27a) are valid for any mode of a fermion ﬁeld—for example, the modes for an
electron trapped in an external potential well or a magnetic bottle, and the (single-
particle) quantum states of an electron in a hydrogen atom.
BOSON MODES: BOSE-EINSTEIN DISTRIBUTION
Suppose that S is a boson mode (i.e., its particles have integral spin), so it can contain
anynonnegativenumberofquanta; thatis, ncanassumethevalues0, 1, 2, 3, . . . .Then
the normalization condition !∞
n=0 ρn = 1 ﬁxes the constant in the grand canonical
distribution (4.26), resulting in
Bose-Einstein distribution
ρn =

1 −exp
 ˜μ −ES
kBT

exp
n( ˜μ −ES)
kBT

.
(4.28a)
From this grand canonical distribution we can deduce the mean number of bosons
in mode S:
Bose-Einstein mean
occupation number
ηS ≡⟨n⟩=
∞
 
n=1
nρn =
1
exp[(ES −˜μ)/(kBT )]−1 =
1
exp[(ES −μ)/(kBT )]−1,
(4.28b)
176
Chapter 4. Statistical Mechanics

in accord with Eq. (3.22b). As for fermions, this Bose-Einstein mean occupation num-
ber and underlying grand canonical distribution (4.28a) are valid generally, and not
solely for the freely moving bosons of Chap. 3.
When the mean occupation number is small, ηS ≪1, both the bosonic and the
fermionic distribution functions are well approximated by the classical Boltzmann
mean occupation number
Boltzmann mean
occupation number
ηS = exp[−(ES −˜μ)/(kBT )].
(4.29)
In Sec. 4.9 we explore an important modern application of the Bose-Einstein
mean occupation number (4.28b): Bose-Einstein condensation of bosonic atoms in
a magnetic trap.
4.4.4
4.4.4 Equipartition Theorem for Quadratic, Classical Degrees of Freedom
As a second example of statistical equilibrium distribution functions, we derive the
classical equipartition theorem using statistical methods.
To motivate this theorem, consider a diatomic molecule of nitrogen, N2. To a good
approximation, its energy (its hamiltonian) can be written as
E = p2
x
2M +
p2
y
2M + p2
z
2M + P 2
ℓ
2Mℓ
+ 1
2Mℓω2
v ℓ2 + J 2
x
2I +
J 2
y
2I .
(4.30)
Here M is the molecule’s mass; px, py, and pz are the components of its translational
momentum; and the ﬁrst three terms are the molecule’s kinetic energy of translation.
The next two terms are the molecule’s longitudinal vibration energy, with ℓthe
change of the molecule’s length (change of the separation of its two nuclei) from
equilibrium, Pℓthe generalized momentum conjugate to that length change, ωv the
vibration frequency, and Mℓthe generalized mass associated with that vibration. The
last two terms are the molecule’s energy of end-over-end rotation, with Jx and Jy the
components of angular momentum associated with this two-dimensional rotator and
I its moment of inertia.
Notice that every term in this hamiltonian is quadratic in a generalized coordi-
nate or generalized momentum! Moreover, each of these coordinates and momenta
appears only in its single quadratic term and nowhere else, and the density of states
is independent of the value of that coordinate or momentum. We refer to such a co-
quadratic degree of
freedom
ordinate or momentum as a quadratic degree of freedom.
In some cases (e.g., the vibrations and rotations but not the translations), the en-
ergy Eξ = αξ2 of a quadratic degree of freedom ξ is quantized, with some energy
separation ε0 between the ground state and ﬁrst excited state (and with energy sep-
arations to higher states that are <∼ε0). If (and only if) the thermal energy kBT is
signiﬁcantly larger than ε0, then the quadratic degree of freedom ξ will be excited far
above its ground state and will behave classically. The equipartition theorem applies
only at these high temperatures. For diatomic nitrogen, the rotational degrees of free-
dom Jx and Jy have ε0 ∼10−4 eV and ε0/kB ∼1 K, so temperatures big compared
4.4 Statistical Equilibrium
177

to 1 K are required for Jx and Jy to behave classically. By contrast, the vibrational
degrees of freedom ℓand Pℓhave ε0 ∼0.1 eV and ε0/kB ∼1,000 K, so temperatures
of a few thousand Kelvins are required for them to behave classically. Above ∼104 K,
the hamiltonian (4.30) fails: electrons around the nuclei are driven into excited states,
and the molecule breaks apart (dissociates into two free atoms of nitrogen).
The equipartition theorem holds for any classical, quadratic degree of freedom
[i.e., at temperatures somewhat higher than To = εo/(kBT )]. We derive this theorem
using the canonical distribution (4.25a). We write the molecule’s total energy as
E = αξ2 + E′, whereE′ doesnotinvolveξ.Thenthemeanenergyassociatedwithξ is
⟨Eξ⟩=

αξ2 e−β(αξ2+E′)dξ d(other degrees of freedom)

e−β(αξ2+E′)dξ d(other degrees of freedom)
.
(4.31)
Here the exponential is that of the canonical distribution function (4.25a), the de-
nominator is the normalizing factor, and we have set β ≡1/(kBT ). Because ξ does
not appear in the portion E′ of the energy, its integral separates out from the others
in both numerator and denominator, and the integrals over E′ in numerator and de-
nominator cancel. Rewriting

αξ2 exp(−βαξ2) dξ as −d/dβ[

exp(−βαξ2) dξ],
Eq. (4.31) becomes
⟨Eξ⟩= −d
dβ ln

exp(−βαξ2) dξ

= −d
dβ ln

1
√βα

due−u2du

= 1
2β = 1
2kBT .
(4.32)
Therefore, in statistical equilibrium, the mean energy associated with any classical,
equipartition theorem
quadratic degree of freedom is 1
2kBT . This is the equipartition theorem. Note that the
factor 1
2 follows from the quadratic nature of the degrees of freedom.
For our diatomic molecule, at room temperature there are three translational and
two rotational classical, quadratic degrees of freedom (px, py, pz, Jx, Jy), so the
mean total energy of the molecule is 5
2kBT . At a temperature of several thousand
Kelvins, the two vibrational degrees of freedom, ℓand Pℓ, become classical and the
molecule’s mean total energy is 7
2kBT . Above ∼104 K the molecule dissociates, and
its two parts (the two nitrogen atoms) have only translational quadratic degrees of
freedom, so the mean energy per atom is 3
2kBT .
The equipartition theorem is valid for any classical, quadratic degree of freedom,
whether it is part of a molecule or not. For example, it applies to the generalized coor-
dinate and momentum of any harmonic-oscillator mode of any system: a vibrational
mode of Earth or of a crystal, or a mode of an electromagnetic ﬁeld.
4.5
4.5 The Microcanonical Ensemble
Let us now turn from ensembles of systems that interact with an external, thermal
bath (as discussed in Sec. 4.4.1) to an ensemble of identical, precisely closed systems
(i.e., systems that have no interactions with the external universe). By “identical” we
178
Chapter 4. Statistical Mechanics

mean that every system in the ensemble has (i) the same set of degrees of freedom, and
thus (ii) the same number of degrees of freedom W, (iii) the same hamiltonian, and
(iv) the same values for all the additive constants of motion (E, K1, K2, . . .) except
perhaps total momentum P and total angular momentum J.9
Suppose that these systems begin with values of (q, p) that are spread out in some
(arbitrary) manner over a hypersurface in phase space that has H(q, p) equal to the
common value of energy E. Of course, we cannot choose systems whose energy is
precisely equal to E. For most E this would be a set of measure zero (see Ex. 4.7).
Instead we let the systems occupy a tiny range of energy between E and E + δE and
then discover (in Ex. 4.7) that our results are highly insensitive to δE as long as it is
extremely small compared with E.
It seems reasonable to expect that this ensemble, after evolving for a time much
longer than its longest internal dynamical time scale t ≫τint, will achieve statistical
equilibrium (i.e., will evolve into a state with ∂ρ/∂t = 0). (In the next section we
justify this expectation.) The distribution function ρ then satisﬁes the collisionless
Boltzmann equation (4.15) with vanishing time derivative, and therefore is a function
only of the hamiltonian’s additive constants of the motion E and KA. However, we
already know that ρ is a delta function in KA and almost a delta function with a tiny
but ﬁnite spread in E; and the fact that it cannot depend on any other phase-space
microcanonical
distribution
quantities then implies ρ is a constant over the hypersurface in phase space that has
the prescribed values of KA and E, and it is zero everywhere else in phase space. This
equilibrium ensemble is called “microcanonical.”
There is a subtle aspect of this microcanonical ensemble that deserves discussion.
Suppose we split each system in the ensemble up into a huge number of subsystems
that can exchange energy (but for concreteness, nothing else) with one another.
We thereby obtain a huge number of subensembles, in the manner of Sec. 4.4.1.
The original systems can be regarded as a thermal bath for the subsystems, and
correspondingly, the subensembles will have canonical distribution functions, ρa =
Ce−Ea/(kBT ). One might also expect the subensembles to be statistically independent,
so that ρ = 0
a ρa. However, such independence is not possible, since together with
additivity of energy E = !
a Ea, it would imply that ρ = Ce−E/(kBT ) (i.e., that the full
ensemble is canonically distributed rather than microcanonical). What is wrong here?
correlations in the
microcanonical ensemble
The answer is that there is a tiny correlation between the subensembles: if, at
some moment of time, subsystem a = 1 happens to have an unusually large energy,
then the other subsystems must correspondingly have a little less energy than usual.
This very slightly invalidates the statistical-independence relation ρ = 0
a ρa, thereby
9.
Exercise 4.7 below is an example of a microcanonical ensemble where P and J are not precisely ﬁxed,
though we do not discuss this in the exercise. The gas atoms in that example are contained inside an
impermeable box whose walls cannot exchange energy or atoms with the gas, but obviously can and do
exchange momentum and angular momentum when atoms collide with the walls. Because the walls are
at rest in our chosen reference frame, the distribution function has U =  = 0 and so is independent of
P and J [Eq. (4.24)] rather than having precisely deﬁned values of them.
4.5 The Microcanonical Ensemble
179

enabling the full ensemble to be microcanonical, even though all its subensembles are
canonical. In the language of two-lengthscale expansions, where one expands in the
dimensionlessratio(sizeofsubsystems)/(sizeoffullsystem)[Box3.3], thiscorrelation
is a higher-order correction to statistical independence.
We are now in a position to understand more deeply the nature of the thermalized
bath that we have invoked to drive ensembles into statistical equilibrium. That bath
can be any huge system that contains the systems we are studying as subsystems; the
bath’s thermal equilibrium can be either a microcanonical statistical equilibrium or a
statistical equilibrium involving exponentials of its extensive variables.
Exercise 4.7 gives a concrete illustration of the microcanonical ensemble, but we
delay presenting it until we have developed some additional concepts that it also
illustrates.
4.6
4.6 The Ergodic Hypothesis
The ensembles we have been studying are almost always just conceptual ones that do
not exist in the real universe. We have introduced them and paid so much attention
to them not for their own sakes, but because, in the case of statistical-equilibrium en-
sembles, they can be powerful tools for studying the properties of a single, individual
system that really does exist in the universe or in our laboratory.
This power comes about because a sequence of snapshots of the single system,
taken at times separated by sufﬁciently large intervals t, has a probability distri-
bution ρ (for the snapshots’ instantaneous locations {q, p} in phase space) that is
the same as the distribution function ρ of some conceptual, statistical-equilibrium
ensemble. If the single system is closed, so its evolution is driven solely by its own
hamiltonian, then the time between snapshots should be t ≫τint, and its snapshots
will be (very nearly) microcanonically distributed. If the single system exchanges en-
ergy, and only energy, with a thermal bath on a timescale τext, then the time between
snapshots should be t ≫τext, and its snapshots will be canonically distributed; sim-
ilarly for the other types of bath interactions. This property of snapshots is equivalent
to the statement that for the individual system, the long-term time average10 of any
ergodicity: equality of time
average and ensemble
average
function of the system’s location in phase space is equal to the statistical-equilibrium
ensemble average:
¯A ≡lim
T →∞
1
T
 +T/2
−T/2
A(q(t), p(t)) = ⟨A⟩≡
 
n
Anρn.
(4.33)
This property comes about because of ergodicity: the individual system, as it evolves,
ergodicity
visits each accessible quantum state n for a fraction of the time that is equal to the
equilibrium ensemble’s probability ρn. Or, stated more carefully, the system comes
10. Physicists often study a system’s evolution for too short a time to perform this average, and therefore the
system does not reveal itself to be ergodic.
180
Chapter 4. Statistical Mechanics

sufﬁciently close to each state n for a sufﬁcient length of time that, for practical
purposes, we can approximate it as spending a fraction ρn of its time at n.
At ﬁrst sight, ergodicity may seem trivially obvious. However, it is not a universal
propertyofallsystems.Onecaneasilydeviseidealizedexamplesofnonergodicbehav-
ior (e.g., a perfectly elastic billiard ball bouncing around a square billiard table), and
some few-body systems that occur in Nature are nonergodic (e.g., fortunately, plane-
tary systems, such as the Sun’s). Moreover, one can devise realistic, nonergodic models
of some many-body systems. For examples and a clear discussion see Sethna (2006,
Chap. 4). On the other hand, generic closed and semiclosed systems in Nature, whose
propertiesandparametersarenotcarefullyﬁnetuned, dotypicallybehaveergodically,
though to prove so is one of the most difﬁcult problems in statistical mechanics.11
We assume throughout this book’s discussion of statistical physics that all the systems
we study are indeed ergodic; this is called the ergodic hypothesis. Correspondingly,
ergodic hypothesis
sometimes (for ease of notation) we denote the ensemble average with a bar.
One must be cautious in practical applications of the ergodic hypothesis: it can
sometimes require much longer than one might naively expect for a system to wander
sufﬁciently close to accessible states that ¯A = ⟨A⟩for observables A of interest.
4.7
4.7 Entropy and Evolution toward Statistical Equilibrium
4.7.1
4.7.1 Entropy and the Second Law of Thermodynamics
For any ensemble of systems, whether it is in statistical equilibrium or not, and also
whether it is quantum mechanical or not, the ensemble’s entropy S is deﬁned, in
words, by the following awful sentence: S is the mean value (ensemble average) of the
natural logarithm of the probability that a random system in the ensemble occupies
a given quantum state, summed over states and multiplied by −kB. More speciﬁcally,
denoting the probability that a system is in state n by ρn, the ensemble’s entropy S is
the following sum over quantum states (or the equivalent integral over phase space):
entropy of an ensemble
S ≡−kB
 
n
ρn ln ρn.
(4.34)
If all the systems are in the same quantum state, for example, in the state n = 17,
then ρn = δn,17 so we know precisely the state of any system pulled at random from
the ensemble, and Eq. (4.34) dictates that the entropy vanish. Vanishing entropy thus
corresponds to perfect knowledge of the system’s quantum state; it corresponds to the
quantum state being pure.
Entropy is a measure of our lack of information about the state of any system
chosen at random from an ensemble (see Sec. 4.11). In this sense, the entropy can be
11. The ergodic hypothesis was introduced in 1871 by Boltzmann. For detailed analyses of it from physics
viewpoints, see, e.g., ter Haar (1955) and Farquhar (1964). Attempts to understand it rigorously, and
the types of systems that do or do not satisfy it, have spawned a branch of mathematical physics called
“ergodic theory.”
4.7 Entropy and Evolution toward Statistical Equilibrium
181

regarded as a property of a random individual system in the ensemble, as well as of the
ensemble itself.
By contrast, consider a system in microcanonical statistical equilibrium. In this
case, all states are equally likely (ρ is constant), so if there are Nstates states available
to the system, then ρn = 1/Nstates, and the entropy (4.34) takes the form12
entropy for microcanonical
ensemble
S = kB ln Nstates.
(4.35)
The entropy, so deﬁned, has some important properties. One is that when the
ensemble can be broken up into statistically independent subensembles of subsystems
(as is generally the case for big systems in statistical equilibrium), so that ρ = 0
a ρa,
then the entropy is additive: S = !
a Sa (see Ex. 4.3). This permits us to regard the
entropy, like the systems’ additive constants of motion, as an extensive variable.
second law of
thermodynamics
A second very important property is that, as an ensemble of systems evolves,
its entropy cannot decrease, and it generally tends to increase. This is the statistical
mechanical version of the second law of thermodynamics.
As an example of this second law, consider two different gases (e.g., nitrogen and
oxygen) in a container, separated by a thin membrane. One set of gas molecules is
constrained to lie on one side of the membrane; the other set lies on the opposite side.
The total number of available states Nstates is less than if the membrane is ruptured
and the two gases are allowed to mix. The mixed state is readily accessible from the
partitioned state and not vice versa. When the membrane is removed, the entropy
begins to increase in accord with the second law of thermodynamics (cf. Ex. 4.8).
Sinceanyensembleofidentical, closedsystemswillultimately, afteratimet ≫τint,
evolve into microcanonical statistical equilibrium, it must be that the microcanonical
distribution function ρ = constant has a larger entropy than any other distribution
function that the ensemble could acquire. That this is indeed so can be demonstrated
formally as follows.
Consider the class of all distribution functions ρ that: (i) vanish unless the con-
stants of motion have the prescribed values E (in the tiny range δE) and KA; (ii) can be
nonzeroanywhereintheregionofphasespace, whichwecall Yo, wheretheprescribed
values E, KA are taken; and (iii) are correctly normalized so that
 
n
ρn ≡

Yo
ρNstatesd = 1
(4.36a)
[Eq. (4.8b)]. We ask which ρ in this class gives the largest entropy
S = −kB
 
n
ρn ln ρn.
The requirement that the entropy be extremal (stationary) under variations δρ of ρ
that preserve the normalization (4.36a) is embodied in the variational principle (see,
e.g., Boas, 2006, Chap. 9):
12. This formula, with slightly different notation, can be found on Boltzmann’s tomb.
182
Chapter 4. Statistical Mechanics

δS = δ

Yo
(−kBρ ln ρ − ρ)Nstatesd = 0.
(4.36b)
Here  is a Lagrange multiplier that enforces the normalization (4.36a). Performing
the variation, we ﬁnd that

Yo
(−kB ln ρ −kB − )δρNstatesd = 0,
(4.36c)
which is satisﬁed if and only if ρ is a constant, ρ = e−1− /kB, independent of lo-
cation in the allowed region Yo of phase space (i.e., if and only if ρ is that of the
microcanonical ensemble). This calculation actually only shows that the microcanon-
ical ensemble has stationary entropy. To show it is a maximum, one must perform
the second variation (i.e., compute the second-order contribution of δρ to δS =
δ

(−kBρ ln ρ)Nstatesd). That second-order contribution is easily seen to be
entropy maximized
when ρρρ is constant
(microcanonical
distribution)
δ2S =

Yo

−kB
(δρ)2
2ρ

Nstatesd < 0.
(4.36d)
Thus, the microcanonical distribution does maximize the entropy, as claimed.
4.7.2
4.7.2 What Causes the Entropy to Increase?
There is an apparent paradox at the heart of statistical mechanics, and, at various
stages in the development of the subject it has led to confusion and even despair.
It still creates controversy (see, e.g., Hawking and Penrose, 2010; Penrose, 1999). Its
simplestandmostdirectexpressionistoask:howcanthetime-reversible, microscopic
laws, encoded in a time-independent hamiltonian, lead to the remorseless increase of
entropy?
COARSE-GRAINING
For insight, ﬁrst consider a classical, microcanonical ensemble of precisely closed
systems (no interaction at all with the external universe). Assume, for simplicity, that
at time t = 0 all the systems are concentrated in a small but ﬁnite region of phase space
with volume , as shown in Fig. 4.2a, withρ = 1/(Nstates) in the occupied region
and ρ = 0 everywhere else. As time passes each system evolves under the action of
the systems’ common hamiltonian. As depicted in Fig. 4.2b, this evolution distorts
the occupied region of phase space; but Liouville’s theorem dictates that the occupied
region’s volume  remain unchanged and, correspondingly, that the ensemble’s
entropy
S = −kB

(ρ ln ρ)Nstatesd = kB ln(Nstates)
(4.37)
remain unchanged.
How can this be so? The ensemble is supposed to evolve into statistical equilib-
rium, with its distribution function uniformly spread out over that entire portion of
4.7 Entropy and Evolution toward Statistical Equilibrium
183

(a)
(c)
(b)
pk

qk
pk
qk
pk
qk
FIGURE 4.2 Evolution of a classical ensemble at t = 0 (a) toward statistical equilibrium by means of
phase mixing (b) (cf. Fig. 4.1) followed by coarse-graining of one’s viewpoint (c).
phase space allowed by the hamiltonian’s constants of motion—a portion of phase
space far, far larger than —and in the process the entropy is supposed to increase.
Figure 4.2b,c resolves the paradox. As time passes, the occupied region becomes
more and more distorted. It retains its phase-space volume, but gets strung out into
a winding, contorted surface (Fig. 4.2b), which (by virtue of the ergodic hypothe-
sis) ultimately passes arbitrarily close to any given point in the region allowed by the
phase mixing
constants of motion. This ergodic wandering is called phase mixing. Ultimately, the
physicist gets tired of keeping track (or ceases to be able to keep track) of all these con-
tortions of the occupied region and chooses instead to take a coarse-grained viewpoint
that averages over scales larger than the distance between adjacent portions of the oc-
cupied surface, and thereby regards the ensemble as having become spread over the
entire allowed region (Fig. 4.2c). More typically, the physicist will perform a coarse-
grained smearing out on some given, constant scale at all times. Once the transverse
scale of the ensemble’s lengthening and narrowing phase-space region drops below
the smearing scale, its smeared volume and its entropy start to increase. Thus, for an
coarse graining causes
entropy increase
ensemble of closed systems it is the physicist’s choice (though often a practical necessity) to
perform coarse-grain averaging that causes entropy to increase and causes the ensemble
to evolve into statistical equilibrium.
The situation is a bit more subtle for an ensemble of systems interacting with
a thermal bath. The evolution toward statistical equilibrium is driven by the inter-
actions. Thus, it might appear at ﬁrst sight that the physicist is not, this time, to blame
for the entropy increase and the achievement of statistical equilibrium. However, a
deeper examination reveals the physicist’s ultimate culpability. If the physicist were
willing to keep track of all those dynamical degrees of freedom of the bath that are
inﬂuenced by and inﬂuence the systems in the ensemble, then the physicist could
incorporate those degrees of freedom into the description of the systems and deﬁne a
phase-space volume that obeys Liouville’s theorem and thus does not increase, and an
entropy that correspondingly remains constant. However, physicists instead generally
choose to ignore the microscopic details of the bath, and that choice forces them to
184
Chapter 4. Statistical Mechanics

attribute a growing entropy to the ensemble of systems bathed by the bath and regard
the ensemble as approaching statistical equilibrium.
DISCARDING CORRELATIONS
When one reexamines these issues in quantum mechanical language, one discovers
that the entropy increase is caused by the physicist’s discarding the quantum mechan-
ical correlations (the off-diagonal terms in the density matrix of Box 4.2) that get built
up through the systems’ interaction with the rest of the universe. This discarding of
correlations is accomplished through a trace over the external universe’s basis states
(Box 4.2), and if the state of system plus universe was originally pure, this tracing
(discarding of correlations) makes it mixed. From this viewpoint, then, it is the physi-
discarding quantum cor-
relations (decoherence)
causes entropy increase
cist’s choice to discard correlations with the external universe that causes the entropy
increase and the evolution toward statistical equilibrium.Heuristically, we can say that
the entropy does not increase until the physicist actually (or ﬁguratively) chooses to
let it increase by ignoring the rest of the universe. For a simple example, see Box 4.3
and Ex. 4.9.
This viewpoint then raises a most intriguing question. What if we regard the
universe as the ultimate microcanonical system? In this case, we might expect that
the entropy of the universe will remain identically zero for all time, unless physicists
(orotherintelligentbeings)performsomesortofcoarse-grainingordiscardsomesort
of correlations. However, such coarse-graining or discarding are made deeply subtle
by the fact that the physicists (or other intelligent beings) are themselves part of the
system being studied. Further discussion of these questions introduces fascinating,
though ill-understood, quantum mechanical and cosmological considerations, which
will reappear in a different context in Sec. 28.7.
EXERCISES
Exercise 4.2 Practice: Estimating Entropy
Make rough estimates of the entropy of the following systems, assuming they are in
statistical equilibrium.
(a) An electron in a hydrogen atom at room temperature.
(b) A glass of wine.
(c) The Paciﬁc ocean.
(d) An ice cube.
(e) The observable universe. [Its entropy is mostly contained in the 3-K microwave
background radiation and in black holes (Sec. 4.10). Why?]
Exercise 4.3 Derivation and Practice: Additivity of Entropy for Statistically
Independent Systems
Consideranensembleofclassicalsystemswitheachsystemmadeupofalargenumber
of statistically independent subsystems, so ρ = 0
a ρa. Show that the entropy of the
full ensemble is equal to the sum of the entropies of the subensembles a: S = !
a Sa.
4.7 Entropy and Evolution toward Statistical Equilibrium
185

BOX 4.3.
ENTROPY INCREASE DUE TO DISCARDING
QUANTUM CORRELATIONS
As an idealized, pedagogical example of entropy increase due to physicists’
discarding quantum correlations, consider an electron that interacts with a
photon. The electron’s initial quantum state is |ψe⟩= α| ↑⟩+ β| ↓⟩, where
| ↑⟩is the state with spin up, | ↓⟩is that with spin down, and α and β are
complex probability amplitudes with |α|2 + |β|2 = 1. The interaction is so
arranged that if the electron spin is up, then the photon is put into a positive
helicity state |+⟩, and if down, the photon is put into a negative helicity state
|−⟩. Therefore, after the interaction the combined system of electron plus
photon is in the state |!⟩= α| ↑⟩⊗|+⟩+ β| ↓⟩⊗|−⟩, where ⊗is the tensor
product [Eq. (1.5a) generalized to the vector space of quantum states].
The photon ﬂies off into the universe leaving the electron isolated. Suppose
that we measure some electron observable ˆAe. The expectation values for the
measurement before and after the interaction with the photon are
Before:
⟨ψe| ˆAe|ψe⟩= |α|2⟨↑| ˆAe| ↑⟩+ |β|2⟨↓| ˆAe| ↓⟩
+ α∗β⟨↑| ˆAe| ↓⟩+ β∗α⟨↓| ˆAe| ↑⟩;
(1)
After:
⟨!| ˆAe|!⟩= |α|2⟨↑| ˆAe| ↑⟩⟨+|+⟩
 	
 
1
+|β|2⟨↓| ˆAe| ↓⟩⟨−|−⟩
 	
 
1
+ α∗β⟨↑| ˆAe| ↓⟩⟨+|−⟩
 	
 
0
+β∗α⟨↓| ˆAe| ↑⟩⟨−|+⟩
 	
 
0
= |α|2⟨↑| ˆAe| ↑⟩+ |β|2⟨↓| ˆAe| ↓⟩.
(2)
Comparing Eqs. (1) and (2), we see that the correlations with the photon
have removed the α∗β and β∗α quantum interference terms from the expectation
value. The two pieces α| ↑⟩and β| ↓⟩of the electron’s original quantum state
|ψe⟩are said to have decohered. Since the outcomes of all measurements
can be expressed in terms of expectation values, this quantum decoherence
is complete in the sense that no quantum interference between the α| ↑⟩
and β| ↓⟩pieces of the electron state |ψe⟩will ever be seen again in any
measurement on the electron, unless the photon returns, interacts with the
electron, and thereby removes its correlations with the electron state.
If physicists are conﬁdent the photon will never return and the correla-
tions will never be removed, then they are free to change their mathematical
description of the electron state. Instead of describing the postinterac-
tion state as |!⟩= α| ↑⟩⊗|+⟩+ β| ↓⟩⊗|−⟩, the physicists can discard the
(continued)
186
Chapter 4. Statistical Mechanics

BOX 4.3.
(continued)
correlations with the photon and regard the electron as having classical
probabilities ρ↑= |α|2 for spin up and ρ↓= |β|2 for spin down (i.e., as
being in a mixed state). This new, mixed-state viewpoint leads to the same
expectation value (2) for all physical measurements as the old, correlated,
pure-state viewpoint |!⟩.
The important point for us is that, when discarding the quantum
correlations with the photon (with the external universe), the physicist
changes the entropy from zero (the value for any pure state including |!⟩) to
S = −kB(p↑ln p↑+ p↓ln p↓) = −kB(|α|2 ln |α|2 + |β|2 ln |β|2) > 0. The
physicist’s change of viewpoint has increased the entropy.
In Ex. 4.9, this pedagogical example is reexpressed in terms of the density
operator discussed in Box 4.2.
Exercise 4.4 **Example: Entropy of a Thermalized Mode of a Field
Consider a mode S of a fermionic or bosonic ﬁeld, as discussed in Sec. 4.4.3. Suppose
that an ensemble of identical such modes is in statistical equilibrium with a heat and
particle bath and thus is grand canonically distributed.
(a) Show that if S is fermionic, then the ensemble’s entropy is
SS = −kB[η ln η + (1 −η) ln(1 −η)]
≃−kBη(ln η −1)
in the classical regime η ≪1,
(4.38a)
where η is the mode’s fermionic mean occupation number (4.27b).
(b) Show that if the mode is bosonic, then the entropy is
SS = kB[(η + 1) ln(η + 1) −η ln η]
≃−kBη(ln η −1)
in the classical regime η ≪1,
(4.38b)
where η is the bosonic mean occupation number (4.28b). Note that in the classical
regime, η ≃e−(E−˜μ)/(kBT ) ≪1, the entropy is insensitive to whether the mode is
bosonic or fermionic.
(c) Explain why the entropy per particle in units of Boltzmann’s constant is σ =
SS/(ηkB). Plot σ as a function of η for fermions and for bosons. Show analytically
that for degenerate fermions (η ≃1) and for the bosons’ classical-wave regime
(η ≫1) the entropy per particle is small compared to unity. See Sec. 4.8 for the
importance of the entropy per particle.
4.7 Entropy and Evolution toward Statistical Equilibrium
187

Exercise 4.5 Example: Entropy of Thermalized Radiation Deduced from Entropy
per Mode
Consider fully thermalized electromagnetic radiation at temperature T , for which the
mean occupation number has the standard Planck (blackbody) form η = 1/(ex −1)
with x = hν/(kBT ).
(a) Show that the entropy per mode of this radiation is
SS = kB[x/(ex −1) −ln(1 −e−x)].
(b) Show that the radiation’s entropy per unit volume can be written as the following
integral over the magnitude of the photon momentum:
S/V = (8π/h3)
 ∞
0
SS p2dp.
(c) By performing the integral (e.g., using Mathematica), show that
S
V = 4
3
U
T = 4
3aT 3,
(4.39)
where U = aT 4 is the radiation energy density, and a = (8π5k4
B/15)/(ch)3 is the
radiation constant [Eqs. (3.54)].
(d) Verify Eq. (4.39) for the entropy density by using the ﬁrst law of thermodynamics
dE = T dS −PdV (which you are presumed to know before reading this book,
and which we discuss below and study in the next chapter).
Exercise 4.6 Problem: Entropy of a Classical, Nonrelativistic, Perfect Gas, Deduced
from Entropy per Mode
Consider a classical, nonrelativistic gas whose particles do not interact and have no
excited internal degrees of freedom (a perfect gas—not to be confused with perfect
ﬂuid). Let the gas be contained in a volume V and be thermalized at temperature T
and chemical potential μ. Using the gas’s entropy per mode, Ex. 4.4, show that the
total entropy in the volume V is
S =
5
2 −
μ
kBT

kBN,
(4.40)
where N = gs(2πmkBT /h2)3/2eμ/(kBT )V is the number of particles in the volume V
[Eq. (3.39a), derived in Chap. 3 using kinetic theory], and gs is each particle’s number
of spin states.
Exercise 4.7 Example: Entropy of a Classical, Nonrelativistic, Perfect Gas in a
Microcanonical Ensemble
Consider a microcanonical ensemble of closed cubical cells with volume V . Let each
cell contain precisely N particles of a classical, nonrelativistic, perfect gas and contain
a nonrelativistic total energy E ≡E −Nmc2. For the moment (by contrast with the
188
Chapter 4. Statistical Mechanics

text’s discussion of the microcanonical ensemble), assume that E is precisely ﬁxed
instead of being spread over some tiny but ﬁnite range.
(a) Explain why the region Yo of phase space accessible to each system is
|xA| < L/2 ,
|yA| < L/2 ,
|zA| < L/2 ,
N
 
A=1
1
2m|pA|2 = E,
(4.41a)
where A labels the particles, and L ≡V 1/3 is the side of the cell.
(b) To compute the entropy of the microcanonical ensemble, we compute the volume
 in phase space that it occupies, multiply by the number density of states in
phase space (which is independent of location in phase space), and then take the
logarithm. Explain why
 ≡
N
/
A=1

Yo
dxAdyAdzAdpx
Adpy
Adpz
A
(4.41b)
vanishes. This illustrates the “set of measure zero” statement in the text (second
paragraph of Sec. 4.5), which we used to assert that we must allow the systems’
energies to be spread over some tiny but ﬁnite range.
(c) Now permit the energies of our ensemble’s cells to lie in the tiny but ﬁnite range
Eo −δEo < E < Eo. Show that
 = V N[Vν(a) −Vν(a −δa)] ,
(4.41c)
where Vν(a) is the volume of a sphere of radius a in a Euclidean space with ν ≫1
dimensions, and where
a ≡

2mEo ,
δa
a ≡1
2
δEo
Eo
,
ν ≡3N.
(4.41d)
It can be shown (and you might want to try to show it) that
Vν(a) = πν/2
(ν/2)!aν
for ν ≫1.
(4.41e)
(d) Show that, so long as 1≫δEo/Eo ≫1/N (where N in practice is an exceedingly
huge number),
Vν(a) −Vν(a −δa) ≃Vν(a)[1 −e−νδa/a] ≃Vν(a),
(4.41f)
which is independent of δEo and thus will produce a value for  and thence
Nstates and S independent of δEo, as desired. From this and with the aid of
Stirling’s approximation (Reif, 2008, Appendix A.6) n!≃(2πn)1/2(n/e)n for large
n, and taking account of the multiplicity M = N!, show that the entropy of the
microcanonically distributed cells is given by
S(V , E, N) = NkB ln
'
V
N
 E
N
3/2
gs
4πm
3h2
3/2
e5/2
(
.
(4.42)
This is known as the Sackur-Tetrode equation.
4.7 Entropy and Evolution toward Statistical Equilibrium
189

(e) Using Eqs. (3.39), show that this is equivalent to Eq. (4.40) for the entropy, which
we derived by a very different method.
Exercise 4.8 **Example: Entropy of Mixing, Indistinguishability of Atoms, and
the Gibbs Paradox
(a) Consider two identical chambers, each with volume V , separated by an im-
permeable membrane. Into one chamber put energy E and N atoms of he-
lium, and into the other, energy E and N atoms of xenon, with E/N and
N/V small enough that the gases are nonrelativistic and nondegenerate. The
membrane is ruptured, and the gases mix. Show that this mixing drives the
entropy up by an amount S = 2NkB ln 2. [Hint: Use the Sackur-Tetrode equa-
tion (4.42).]
(b) Suppose that energy E and N atoms of helium are put into both chambers (no
xenon). Show that, when the membrane is ruptured and the gases mix, there
is no increase of entropy. Explain why this result is reasonable, and explain its
relationship to entropy being an extensive variable.
(c) Suppose that the N helium atoms were distinguishable instead of indistin-
guishable. Show this would mean that, in the microcanonical ensemble, they
have N!more states available to themselves, and their entropy would be larger by
kB ln N! ≃kB(N ln N −N); and as a result, the Sackur-Tetrode formula (4.42)
would be
Distinguishable particles:
S(V , E, N) = NkB ln
'
V
 E
N
3/2 4πm
3h2
3/2
e3/2
(
.
(4.43)
Before the advent of quantum theory, physicists thought that atoms were distin-
guishable, and up to an additive multiple of N (which they could not compute),
they deduced this entropy.
(d) Show that if, as prequantum physicists believed, atoms were distinguishable, then
when the membrane between two identical helium-ﬁlled chambers is ruptured,
there would be an entropy increase identical to that when the membrane between
helium and xenon is ruptured: S = 2NkB ln 2 [cf. parts (a) and (b)]. This result,
which made prequantum physicists rather uncomfortable, is called the Gibbs
paradox.
Exercise 4.9 Problem: Quantum Decoherence and Entropy Increase in Terms of the
Density Operator
Reexpress Box 4.3’s pedagogical example of quantum decoherence and entropy in-
crease in the language of the quantum mechanical density operator ˆρ (Box 4.2). Use
190
Chapter 4. Statistical Mechanics

this example to explain the meaning of the various statements made in the next-to-last
paragraph of Sec. 4.7.2.
4.8
4.8 Entropy per Particle
entropy per particle
The entropy per particle in units of Boltzmann’s constant,
σ ≡S/(NkB),
(4.44)
is a very useful concept in both quantitative and order-of-magnitude analyses. (See,
e.g., Exs. 4.10, 4.11, and 4.4c, and the discussion of entropy in the expanding universe
in Sec. 4.10.3.) One reason is the second law of thermodynamics. Another is that in
the real universe σ generally lies somewhere between 0 and 100 and thus is a natural
quantity in terms of which to think about and remember the magnitudes of various
quantities.
For example, for ionized hydrogen gas in the nonrelativistic, classical domain,
the Sackur-Tetrode equation (4.42) for the entropy (derived from the microcanonical
ensemble in Ex. 4.7), when specialized either to the gas’s protons or to its electrons
(both of which, with their spin 1/2, have gs = 2), gives
entropy of ionized
hydrogen
σp = 5
2 + ln
'
2mp
ρ
2πmkBT
h2
3/2(
.
(4.45)
Here we have set the number density of particles N/V (either protons or electrons)
to ρ/mp, since almost all the mass density ρ is in the protons, and we have set the
thermal energy per particle E/N to 3
2kBT [see Eq. (3.39b) derived in Chap. 3 using
kinetic theory]. The only way this formula depends on which particle species we are
considering, the gas’s protons or its electrons, is through the particle mass m; and this
factor in Eq. (4.45) tells us that the protons’ entropy per proton is a factor ≃10 higher
than the electrons’: σp −σe = 3
2 ln(mp/me) = 11.27 ≃10. Therefore, for an ionized
hydrogen gas most of the entropy is in the protons.
The protons’ entropy per proton is plotted as a function of density and temperature
inFig.4.3.Itgrowslogarithmicallyasthedensityρ decreases, anditrangesfromσ ≪1
in the regime of extreme proton degeneracy (lower right of Fig. 4.3; see Ex. 4.4) to σ ∼
1near the onset of proton degeneracy (the boundary of the classical approximation),
to σ ∼100 at the lowest density that occurs in the universe, ρ ∼10−29 g cm−3. This
rangeisanexampleofthefactthatthelogarithmsofalmostalldimensionlessnumbers
that occur in Nature lie between approximately −100 and +100.
4.8 Entropy per Particle
191

10
9
8
7
6
5
4
90
–32
–28
–24
–20
–16
–12
–8
–4
0
4
8
80
70
60
50
40
30
20
10
0
protons nondegenerate
degenerate
log10 T (K)
log10ρ (g cm–3)
σp =
FIGURE 4.3 Proton entropy per proton σp for an ionized hydrogen gas. Each line is
labeled with its value of σρ. The electron entropy per electron σe is a factor ≃10
smaller; the electrons are degenerate when σe ≃σp −10 <∼1. The protons are
degenerate when σp <∼1.
EXERCISES
Exercise 4.10 **Problem: Primordial Element Formation
(a) As we shall see in Sec. 28.4.1, when the early universe was ∼200 s old, its prin-
cipal constituents were photons, protons, neutrons, electrons, positrons, and
(thermodynamically isolated) neutrinos and gravitons. The photon temperature
was ∼9 × 108 K, and the baryon density was ∼0.02 kg m−3. The photons, pro-
tons, electrons, and positrons were undergoing rapid electromagnetic interac-
tions that kept them in thermodynamic equilibrium. Use the neutron-proton
mass difference of 1.3 MeV to argue that, if the neutrons had also been in ther-
modynamic equilibrium, then their density would have been negligible at this
time.
(b) However, the universe expanded too rapidly for weak interactions to keep the
neutronsinequilibriumwiththeotherparticles, andsothefractionofthebaryons
at 200 s, in the form of neutrons that did not subsequently decay, was ∼0.14. At
this time (Sec. 28.4.2) the neutrons began rapidly combining with protons to form
alpha particles through a short chain of reactions, of which the ﬁrst step—the one
that was hardest to make go—was n + p →d + 2.22 MeV, with the 2.22 MeV
going into heat. Only about 10−5 of the baryons needed to go into deuterium in
order to start and then maintain the full reaction chain. Show, using entropy per
particle and the ﬁrst law of thermodynamics, that at time t ∼200 s after the big
bang, this reaction was just barely entropically favorable.
(c) During this epoch, roughly how do you expect the baryon density to have de-
creased as a function of decreasing photon temperature? (For this you can neglect
the heat being released by the nuclear burning and the role of positrons.) Show
that before t ∼200 s, the deuterium-formation reaction could not take place, and
after t ∼200 s, it rapidly became strongly entropically favorable.
192
Chapter 4. Statistical Mechanics

(d) The nuclear reactions shut down when the neutrons had all cycled through
deuterium and almost all had been incoroporated into α particles, leaving only
∼10−5 of them in deuterium. About what fraction of all the baryons wound up
in α particles (Helium 4)? (See Fig. 28.7 for details from a more complete analysis
sketched in Sec. 28.4.2.)
Exercise 4.11 Problem: Reionization of the Universe
Following the epoch of primordial element formation (Ex. 4.10), the universe con-
tinued to expand and cool. Eventually when the temperature of the photons was
∼3,000 K, the free electrons and protons combined to form atomic hydrogen; this was
the epoch of recombinaton. Later, when the photon temperature had fallen to ∼30 K,
some hot stars and quasars formed and their ultraviolet radiation dissociated the hy-
drogen; this was the epoch of reionization. The details are poorly understood. (For
more discussion, see Ex. 28.19.) Making the simplifying assumption that reioniza-
tion happened rapidly and homogeneously, show that the increase in the entropy per
baryon was ∼60kB, depending weakly on the temperature of the atomic hydrogen,
which you can assume to be ∼100 K.
4.9
4.9 Bose-Einstein Condensate
In this section, we explore an important modern application of the Bose-Einstein
mean occupation number for bosons in statistical equilibrium. Our objectives are
(i) to exhibit, in action, the tools developed in this chapter and (ii) to give a nice
example of the connections between quantum statistical mechanics (which we use
in the ﬁrst 3/4 of this section) and classical statistical mechanics (which we use in
the last 1/4).
Bose-Einstein
condensation
For bosons in statistical equilibrium, the mean occupation number η =
1/[e(E−μ)/(kBT ) −1] diverges as E →0, if the chemical potential μ vanishes. This
divergence is intimately connected to Bose-Einstein condensation.
Consider a dilute atomic gas in the form of a large number N of bosonic atoms,
spatially conﬁned by a magnetic trap. When the gas is cooled below some critical
temperature Tc, μ is negative but gets very close to zero [see Eq. (4.47d)], causing η to
become huge near zero energy. This huge η manifests physically as a large number N0
of atoms collecting into the trap’s mode of lowest (vanishing) energy, the Schr¨odinger
equation’s ground state [see Eq. (4.49a) and Fig. 4.4a later in this section].
This condensation was predicted by Einstein (1925), but an experimental demon-
stration was not technologically feasible until 1995, when two research groups in-
dependently exhibited it: one at JILA (University of Colorado) led by Eric Cornell
and Carl Wieman; the other at MIT led by Wolfgang Ketterle. For these experiments,
Cornell, Ketterle, and Wieman were awarded the 2001 Nobel Prize. Bose-Einstein
condensates have great promise as tools for precision-measurement technology and
nanotechnology.
4.9 Bose-Einstein Condensate
193

As a concrete example of Bose-Einstein condensation, we analyze an idealized
version of one of the early experiments by the JILA group (Ensher et al., 1996): a gas
of 40,000 87Rb atoms placed in a magnetic trap that we approximate as a spherically
symmetric, harmonic oscillator potential:13
V (r) = 1
2mω2
or2 = 1
2mω2
o(x2 + y2 + z2).
(4.46a)
Here x, y, z are Cartesian coordinates, and r is radius. The harmonic-oscillator
frequency ωo and associated temperature ℏωo/kB, the number N of rubidium atoms
trapped in the potential, and the atoms’ rest mass m are
ωo/(2π) = 181 Hz,
ℏωo/kB = 8.7 nK,
N = 40,000,
m = 1.444 × 10−25 kg.
(4.46b)
Our analysis is adapted, in part, from a review article by Dalfovo et al. (1999).
Each 87Rb atom is made from an even number of fermions [Z = 37 electrons, Z =
37 protons, and (A −Z) = 50 neutrons], and the many-particle wave function ! for
the system of N = 40,000 atoms is antisymmetric (changes sign) under interchange
of each pair of electrons, each pair of protons, and each pair of neutrons. Therefore,
when any pair of atoms is interchanged (entailing interchange of an even number of
fermion pairs), there is an even number of sign ﬂips in !. Thus ! is symmetric (no
sign change) under interchange of atoms (i.e., the atoms behave like bosons and must
obey Bose-Einstein statistics).
Repulsive forces between the atoms have a moderate inﬂuence on the experiment,
but only a tiny inﬂuence on the quantities that we compute (see, e.g., Dalfovo et al.,
1999). We ignore those forces and treat the atoms as noninteracting.
To make contact with our derivation, in Sec. 4.4.3, of the Bose-Einstein distribu-
modes: single-atom
quantum states
tion, we must identify the modes (single-atom quantum states) S available to the
atoms. Those modes are the energy eigenstates of the Schr¨odinger equation for a 87Rb
atom in the harmonic-oscillator potential V (r). Solution of the Schr¨odinger equa-
tion (e.g., Cohen-Tannoudji, Diu, and Lalo¨e, 1977, complement BVII) reveals that
the energy eigenstates can be labeled by the number of quanta of energy {nx, ny, nz}
associated with an atom’s motion along the x, y, and z directions; the energy of
the mode {nx, ny, nz} is Enx,ny,nz = ℏωo[(nx + 1/2) + (ny + 1/2) + (nz + 1/2)]. We
simplify subsequent formulas by subtracting 3
2ℏωo from all energies and all chem-
ical potentials. This is merely a change in what energy we regard as zero (renor-
malization), a change under which our statistical formalism is invariant (cf. foot-
13. In the actual experiment, the potential was harmonic but prolate spheroidal rather than spherical, i.e.,
in Cartesian coordinates V (x, y, z) = 1
2m[ω2
ϖ(x2 + y2) + ω2
zz2], with ωz somewhat smaller than ωϖ.
For pedagogical simplicity we treat the potential as spherical, with ωo set to the geometric mean of
the actual frequencies along the three Cartesian axes, ωo = (ω2
ϖωz)1/3. This choice of ωo gives good
agreement between our model’s predictions and the prolate-spheroidal predictions for the quantities
that we compute.
194
Chapter 4. Statistical Mechanics

note 8 on page 175). Correspondingly, we attribute to the mode {nx, ny, nz} the
energy Enx,ny,nz = ℏωo(nx + ny + nz). Our calculations will be simpliﬁed by lump-
ing together all modes that have the same energy, so we switch from {nx, ny, nz} to
q ≡nx + ny + nz = (the mode’s total number of quanta) as our fundamental quan-
tum number, and we write the mode’s energy as
Eq = qℏωo.
(4.47a)
It is straightforward to verify that the number of independent modes with q quanta
(the number of independent ways to choose {nx, ny, nz} such that their sum is q) is
1
2(q + 1)(q + 2). (Of course, one can also derive this same formula in spherical polar
coordinates.)
ground-state mode
Of special interest is the ground-state mode of the potential, {nx, ny, nz} =
{0, 0, 0}. This mode has q = 0, and it is unique: (q + 1)(q + 2)/2 = 1. Its energy
is E0 = 0, and its Schr¨odinger wave function is ψo = (πσ 2
o)−3/4 exp(−r2/(2σ 2
o)), so
foranyatomthathappenstobeinthisground-statemode, theprobabilitydistribution
for its location is the Gaussian
|ψo(r)|2 =
*
1
πσ 2
o
+3/2
exp
*
−r2
σ 2
o
+
,
where
σo =
1
ℏ
mωo
= 0.800 μm. (4.47b)
The entire collection of N atoms in the magnetic trap is a system; it interacts
with its environoment, which is at temperature T , exchanging energy but nothing
else, so a conceptual ensemble consisting of this N-atom system and a huge number
of identical systems has the canonical distribution ρ = C exp(−Etot/(kBT )), where
Etot is the total energy of all the atoms. Each mode (labeled by {nx, ny, nz} or by
q and two degeneracy parameters that we have not speciﬁed) is a subsystem of
this system. Because the modes can exchange atoms as well as energy with one
another, a conceptual ensemble consisting of any chosen mode and its clones is grand-
canonically distributed [Eq. (4.28a)], so its mean occupation number is given by the
Bose-Einstein formula (4.28b) with ES = qℏωo:
ηq =
1
exp[(qℏωo −μ)/(kBT )]−1.
(4.47c)
The temperature T is inherited from the environment (heat bath) in which the atoms
live. The chemical potential μ is common to all the modes and takes on whatever
value is required to guarantee that the total number of atoms in the trap is N—or,
equivalently, that the sum of the mean occupation number (4.47c) over all the modes
is N.
For the temperatures of interest to us:
1. The number N0 ≡η0 of atoms in the ground-state mode q = 0 will be large,
N0 ≫1, whichpermitsustoexpandtheexponentialinEq.(4.47c)withq = 0
to obtain N0 = 1/[e−μ/(kBT ) −1]≃−kBT /μ, that is,
μ/(kBT ) = −1/N0.
(4.47d)
4.9 Bose-Einstein Condensate
195

2. The atoms in excited modes will be spread out smoothly over many values
of q, so we can approximate the total number of excited-mode atoms by an
integral:
N −N0 =
∞
 
q=1
(q + 1)(q + 2)
2
ηq ≃
 ∞
0
1
2(q2 + 3q + 2)dq
exp[(qℏωo/(kBT ) + 1/N0)]−1.
(4.48a)
The integral is dominated by large qs, so it is a rather good approximation to keep
only the q2 term in the numerator and to neglect the 1/N0 in the exponential:
N −N0 ≃
 ∞
0
q2/2
exp(qℏωo/(kBT )) −1dq = ζ(3)
kBT
ℏωo
3
.
(4.48b)
Here ζ(3) ≃1.202 is the Riemann zeta function [which also appeared in our study of
the equation of state of thermalized radiation, Eq. (3.54b)]. It is useful to rewrite Eq.
(4.48b) as
ground-state occupation
number
N0 = N
⎡
⎣1 −
*
T
T 0
c
+3⎤
⎦,
(4.49a)
where
critical temperature
T 0
c = ℏωo
kB
 N
ζ(3)
1/3
= 280 nK ≫ℏωo/kB = 8.7 nK
(4.49b)
is our leading-order approximation to the critical temperature Tc. Obviously, we
cannot have a negative number of atoms in the ground-state mode, so Eq. (4.49a)
must fail for T > T 0
c . Presumably, N0 becomes so small there that our approximation
(4.47d) fails.
Figure 4.4a, adapted from the review article by Dalfovo et al. (1999), compares our
simple prediction (4.49a) for N0(T ) (dashed curve) with the experimental measure-
ments by the JILA group (Ensher et al., 1996). Both theory and experiment show that,
when one lowers the temperature T through a critical temperature Tc, the atoms sud-
denly begin to accumulate in large numbers in the ground-state mode. At T ≃0.8Tc,
half the atoms have condensed into the ground state (Bose-Einstein condensation);
Bose-Einstein
condensation
at T ≃0.2Tc almost all are in the ground state. The simple formula (4.49a) is remark-
ably good at 0 < T < Tc; evidently, T 0
c [Eq. (4.49b)] is a rather good leading-order
approximation to the critical temperature Tc at which the Bose-Einstein condensate
begins to form.
Exercise 4.12 and Fig. 4.4b use more accurate approximations to Eq. (4.48a) to
explore the onset of condensation as T is gradually lowered through the critical
temperature. The onset is actually continuous when viewed on a sufﬁciently ﬁne
temperature scale; but on scales 0.01Tc or greater, it appears to be discontinuous.
phase transition
The onset of Bose-Einstein condensation is an example of a phase transition:a sud-
den (nearly) discontinuous change in the properties of a thermalized system. Among
196
Chapter 4. Statistical Mechanics

1.0
0.8
0.6
0.4
0.2
0.0
600
500
400
300
200
100
0
0.0
0.980
0.985
0.990
0.995
1.000
0.2
0.4
0.6
0.8
1.0
1.2
1.4
1.6
1.8
N0 /N
T0 /Tc
0
 
T0 /Tc
0
 
N0 
(a)
(b)
FIGURE 4.4 The number N0 of atoms in the Bose-Einstein condensate at the center of a magnetic trap
as a function of temperature T . (a) Low resolution; (b) High resolution. The dashed curve in each
panel is the prediction (4.49a) of the simple theory presented in the text, using the parameters shown
in Eq. (4.46b). The dotted curve in panel b is the prediction derived in Ex. 4.12c. The solid curves
are our most accurate prediction (4.54) [Ex. 4.12d], including details of the condensation turning on.
The large dots are experimental data from Ensher et al. (1996). Panel a is adapted from Dalfovo et al.
(1999).
the sudden changes accompanying this phase transition is a (nearly) discontinuous
change of the atoms’ speciﬁc heat (Ex. 4.13). We study some other phase transitions
in Chap. 5.
Notice that the critical temperature T 0
c is larger, by a factor ∼N1/3 = 34, than
the temperature ℏωo/kB = 8.7 nK associated with the harmonic-oscillator potential.
Correspondingly, at the critical temperature there are signiﬁcant numbers of atoms
in modes with q as large as ∼34—which means that nearly all of the atoms are
actually behaving rather classically at T ≃T 0
c , despite our use of quantum mechanical
concepts to analyze them!
It is illuminating to compute the spatial distribution of these atoms at the criti-
cal temperature using classical techniques. (This distribution could equally well be
deduced using the above quantum techniques.) In the near classical, outer region
of the trapping potential, the atoms’ number density in phase space N = (gs/h3)η
must have the classical, Boltzmann-distribution form (4.29): dN/dVxdVp ∝
exp[−E/(kBT )]= exp{−[V (r) + p2/(2m)]/(kBTc)}, where V (r) is the harmonic-
oscillator potential (4.46a). Integrating over momentum space, dVp = 4πp2dp, we
obtain for the number density of atoms n = dN/dVx
n(r) ∝exp
−V (r)
kBTc

= exp
*
−r2
a2
o
+
,
(4.50a)
4.9 Bose-Einstein Condensate
197

where [using Eqs. (4.49b) for Tc and (4.47b) for ωo]
ao =
1
2kBTc
mω2
o
=
√
2
[ζ(3)]1/6N1/6σo = 1.371N1/6σo = 8.02σo = 6.4 μm.
(4.50b)
Thus, at the critical temperature, the atoms have an approximately Gaussian spatial
distribution with radius ao eight times larger than the trap’s 0.80 μm ground-state
Gaussian distribution. This size of the distribution gives insight into the origin of the
Bose-Einstein condensation: The mean inter-atom spacing at the critical temperature
T 0
c is ao/N1/3. It is easy to verify that this is approximately equal to the typical atom’s
deBrogliewavelengthλT dB = h/

2πmkBT = h/(typicalmomentum)—whichisthe
size of the region that we can think of each atom as occupying. The atomic separation
is smaller than this in the core of the atomic cloud, so the atoms there are beginning to
overlap and feel one another’s presence, and thereby want to accumulate into the same
quantum state (i.e., want to begin condensing). By contrast, the mean separation is
larger than λdB in the outer portion of the cloud, so the atoms there continue to behave
classically.
At temperatures below Tc, the N0 condensed, ground-state-mode atoms have a
spatial Gaussian distribution with radius σo ∼ao/8 (i.e., eight times smaller than the
region occupied by the classical, excited-state atoms). Therefore, the condensation
is visually manifest by the growth of a sharply peaked core of atoms at the center of
the larger, classical, thermalized cloud. In momentum space, the condensed atoms
and classical cloud also have Gaussian distributions, with rms momenta pcloud ∼
8pcondensate (Ex. 4.14) or equivalently, rms speeds vcloud ∼8vcondensate. In early ex-
periments, the existence of the condensate was observed by suddenly shutting off the
trap and letting the condensate and cloud expand ballistically to sizes vcondensatet and
vcloudt, and then observing them visually. The condensate was revealed as a sharp
Gaussian peak, sticking out of the roughly eight times larger, classical cloud (Fig. 4.5).
EXERCISES
Exercise 4.12 **Example: Onset of Bose-Einstein Condensation
By using more accurate approximations to Eq. (4.48a), explore the onset of the con-
densation near T = T 0
c . More speciﬁcally, do the following.
(a) Approximate the numerator in Eq. (4.48a) by q2 + 3q, and keep the 1/N0 term
in the exponential. Thereby obtain
N −N0 =
kBT
ℏωo
3
Li3(e−1/N0) + 3
2
kBT
ℏωo
2
Li2(e−1/N0).
(4.51)
Here
Lin(u) =
∞
 
p=1
up
pn
(4.52a)
is a special function called the polylogarithm (Lewin, 1981), which is known to
Mathematica and other symbolic manipulation software and has the properties
198
Chapter 4. Statistical Mechanics

FIGURE4.5 Velocity distribution of rubidium atoms in a Bose-Einstein
condensate experiment by Anderson et al. (1995), as observed by the
ballistic expansion method described in the text. In the left frame T
is slightly higher than Tc, and there is only the classical cloud. In the
center frame T is a bit below Tc, and the condensate sticks up sharply
above the cloud. The right frame, at still lower T , shows almost pure
condensate. Figure from Cornell (1996).
Lin(1) = ζ(n),
dLin(u)
du
= Lin−1(u)
u
,
(4.52b)
where ζ(n) is the Riemann zeta function.
(b) Show that by setting e−1/N0 = 1 and ignoring the second polylogarithm in Eq.
(4.51), one obtains the leading-order description of the condensation discussed
in the text: Eqs. (4.48b) and (4.49).
(c) By continuing to set e−1/N0 = 1but keeping the second polylogarithm, obtain an
improved equation for N0(T ). Your answer should continue to show a discontin-
uous turn on of the condensation, but at a more accurate, slightly lower critical
temperature
T 1
c = T 0
c

1 −
ζ(2)
2ζ(3)2/3
1
N1/3

= 0.979T 0
c .
(4.53)
This equation illustrates the fact that our approximations are a large-N expansion
(i.e., an expansion in powers of 1/N).
(d) By keeping all details of Eq. (4.51) but rewriting it in terms of T 0
c , show that
N0 = N
⎡
⎣1 −
*
T
T 0
c
+3
Li3(e−1/N0)
ζ(3)
−
3
2ζ(3)2/3
1
N1/3
*
T
T 0
c
+2
Li2(e−1/N0)
⎤
⎦.
(4.54)
4.9 Bose-Einstein Condensate
199

Solve this numerically to obtain N0(T /T 0
c ) for N = 40,000, and plot your result
graphically. It should take the form of the solid curves in Fig. 4.4: a continuous
turn on of the condensation over the narrow temperature range 0.98T 0
c <∼T <∼
0.99T 0
c (i.e., a range T ∼T 0
c /N1/3). In the limit of an arbitrarily large number of
atoms, theturnonisinstantaneous, asdescribedbyEq.(4.49a)—aninstantaneous
phase transition.
Exercise 4.13 **Problem: Discontinuous Change of Speciﬁc Heat
Analyze the behavior of the atoms’ total energy near the onset of condensation, in the
limitofarbitrarilylargeN (i.e., keepingonlytheleadingorderinour1/N1/3expansion
and approximating the condensation as turning on discontinuously at T = T 0
c ). More
speciﬁcally, do the following.
(a) Show that the total energy of the atoms in the magnetic trap is
Etotal = 3ζ(4)
ζ(3) NkBT 0
c
*
T
T 0
c
+4
when T < T 0
c ,
Etotal = 3Li4(eμ/(kBT ))
ζ(3)
NkBT 0
c
 T
Tc
4
when T > T 0
c ,
(4.55a)
where (at T > Tc) eμ/(kBT ) is a function of N and T determined by N =

kBT/(ℏωo)
3 Li3(eμ/(kBT )), so μ = 0 at T = T 0
c (see Ex. 4.12). Because Lin(1) =
ζ(n), this energy is continuous across the critical temperature Tc.
(b) Show that the speciﬁc heat C = (∂Etotal/∂T )N is discontinuous across the critical
temperature T 0
c :
C = 12ζ(4)
ζ(3) NkB = 10.80NkB
as T →Tc from below,
C =
12ζ(4)
ζ(3)
−9ζ(3)
ζ(2)

NkB = 4.228NkB
as T →Tc from above.
(4.55b)
Note that for gas contained within the walls of a box, there are two speciﬁc heats:
CV = (∂E/∂T )N ,V when the box volume is held ﬁxed, and CP = (∂E/∂T )N ,P
when the pressure exerted by the box walls is held ﬁxed. For our trapped atoms,
there are no physical walls; the quantity held ﬁxed in place of V or P is the
trapping potential V (r).
Exercise 4.14 Derivation: Momentum Distributions in Condensate Experiments
Show that in the Bose-Einstein condensate discussed in the text, the momentum
distribution for the ground-state-mode atoms is Gaussian with rms momentum
pcondensate = √3/2ℏ/σo =

3ℏmωo/2 and that for the classical cloud it is Gaussian
with rms momentum pcloud =

3mkBTc ≃

3

N/ζ(3)
1/3ℏmωo ≃8pcondensate.
200
Chapter 4. Statistical Mechanics

Exercise 4.15 Problem: Bose-Einstein Condensation in a Cubical Box
Analyze Bose-Einstein condensation in a cubical box with edge lengths L [i.e., for a
potentialV (x, y, z)thatiszeroinsidetheboxandinﬁniteoutsideit].Inparticular, us-
ing the analog of the text’s simplest approximation, show that the critical temperature
at which condensation begins is
T 0
c =
1
8πmkB
'
2πℏ
L

N
ζ(3/2)
1/3(2
,
(4.56a)
and the number of atoms in the ground-state condensate, when T < T 0
c , is
N0 = N
⎡
⎣1 −
*
T
T 0
c
+3/2⎤
⎦.
(4.56b)
4.10
4.10 Statistical Mechanics in the Presence of Gravity
Systems with signiﬁcant gravity behave quite differently in terms of their statistical
mechanics than do systems without gravity. This has led to much controversy as to
whether statistical mechanics can really be applied to gravitating systems. Despite
that controversy, statistical mechanics has been applied in the presence of gravity in a
variety of ways, with great success, resulting in important, fundamental conclusions.
In this section, we sketch some of those applications: to galaxies, black holes, the
universe as a whole, and the formation of structure in the universe. Our discussion is
intended to give just the ﬂavor of these subjects and not full details, so we state some
things without derivation. This is necessary in part because many of the phenomena
we describe rely for their justiﬁcation on general relativity (Part VII) and/or quantum
ﬁeld theory in curved spacetime (see, e.g., Parker and Toms, 2009).
4.10.1
4.10.1 Galaxies
A galaxy is dominated by a roughly spherical distribution of dark matter (believed
to comprise elementary particles with negligible collision cross section) with radius
RD ∼3 × 1021 m and mass MD ∼1042 kg. The dark matter and roughly N ∼1011
stars, each with ﬁducial mass m ∼1030 kg, move in a common gravitational potential
well. (As we discuss in Chap. 28, the ratio of regular, or baryonic, matter to dark matter
is roughly 1:5 by mass.) The baryons (stars plus gas) are mostly contained within a
radius R ∼3 × 1020 m. The characteristic speed of the dark matter and the stars and
gas is v ∼(GMD/RD)1/2 ∼(GNm/R)1/2 ∼200 km s−1. For the moment, focus on
the stars, with total mass M = Nm, ignoring the dark matter and gas, whose presence
does not change our conclusions.
The time it takes stars moving in the dark matter’s gravitational potential to cross
the baryonic galaxy is τint ∼2R/v ∼108 yr.14 This time is short compared with the
14. 1 yr ≃π × 107 s.
4.10 Statistical Mechanics in the Presence of Gravity
201

age of a galaxy, ∼1010 yr. Galaxies have distant encounters with their neighbors on
timescales that can be smaller than their ages but still much longer than τint; in this
sense, they can be thought of as semiclosed systems weakly coupled to their environ-
ments. In this subsection, we idealize our chosen galaxy as fully closed (no interaction
with its environment). Direct collisions between stars are exceedingly rare, and strong
two-star gravitational encounters, which happen when the impact parameter15 is
smaller than ∼Gm/v2 ∼R/N, are also negligibly rare except, sometimes, near the
center of a galaxy (which we ignore until the last paragraph of this subsection). We
can therefore regard each of the galaxy’s stars as moving in a gravitational potential
determined by the smoothed-out mass of the dark matter and all the other stars, and
can use Hamiltonian dynamics to describe their motions.
Imagine that we have an ensemble of such galaxies, all with the same number of
stars N, the same mass M, and the same energy E (in a tiny range δE). We begin our
study of that ensemble by making an order-of-magnitude estimate of the probability
ρ of ﬁnding a chosen galaxy from the ensemble in some chosen quantum state. We
compute that probability from the corresponding probabilities for its subsystems,
individual stars. The phase-space volume available to each star in the galaxy is ∼
R3(mv)3, the density of single-particle quantum states (modes) in each star’s phase
space is 1/h3, the number of available modes is the product of these, ∼(Rmv/h)3,
and the probability of the star occupying the chosen mode, or any other mode, is
the reciprocal of this product, ∼[h/(Rmv)]3. The probability of the galaxy occupying
a state in its phase space is the product of the probabilities for each of its N stars
[Eq. (4.18c)]:
ρ ∼

h
Rmv
3N
∼10−2.7×1013.
(4.57)
This very small number suggests that it is somewhat silly of us to use quantum
distribution function for
stars in a galaxy
mechanics to normalize the distribution function (i.e., silly to use the probabilistic
distribution function ρ) when dealing with a system as classical as a whole galaxy.
Silly, perhaps; but dangerous, no. The key point is that, so far as classical statistical
mechanics is concerned, the only important feature of ρ is that it is proportional
to the classical distribution function Nsys; its absolute normalization is usually not
important, classically. It was this fact that permitted so much progress to be made in
statistical mechanics prior to the advent of quantum mechanics.
Are real galaxies in statistical equilibrium? To gain insight into this question, we
estimate the entropy of a galaxy in our ensemble and then ask whether that entropy
has any chance of being the maximum value allowed to the galaxy’s stars (as it must
be if the galaxy is in statistical equilibrium).
Obviously, the stars (by contrast with electrons) are distinguishable, so we can
assume multiplicity M = 1 when estimating the galaxy’s entropy. Ignoring the (neg-
15. The impact parameter is the closest distance between the two stars along their undeﬂected trajectories.
202
Chapter 4. Statistical Mechanics

ligible) correlations among stars, the entropy computed by integating ρ ln ρ over
the galaxy’s full 6N-dimensional phase space is just N times the entropy asso-
ciated with a single star, which is S ∼NkB ln(/h3) [Eqs. (4.37) and (4.8a)],
where  is the phase-space volume over which the star wanders in its ergodic,
hamiltonian-induced motion (i.e., the phase space volume available to the star).
We express this entropy in terms of the galaxy’s total mass M and its total nonrel-
ativistic energy E ∼−GM2/(2R) as follows. Since the characteristic stellar speed is
v ∼(GM/R)1/2, the volume of phase space over which the star wanders is  ∼
(mv)3R3 ∼(GMm2R)3/2 ∼(−G2M3m2/(2E))3/2, and the entropy is therefore
SGalaxy ∼(M/m)kB ln(/h3) ∼(3M/(2m))kB ln(−G2M3m2/(2Eh2)).
(4.58)
Is this the maximum possible entropy available to the galaxy, given the constraints
that its mass be M and its nonrelativistic energy be E? No. Its entropy can be made
larger by removing a single star from the galaxy to radius r ≫R, where the star’s
energy is negligible. The entropy of the remaining stars will decrease slightly, since
the mass M diminishes by m at constant E. However, the entropy associated with the
removed star, ∼(3/2) ln(GMm2r/h2), can be made arbitrarily large by making its
orbital radius r arbitrarily large. By this thought experiment, we discover that galaxies
cannot be in a state of maximum entropy at ﬁxed E and M; they therefore cannot be
galaxy never in statistical
equilibrium
in a true state of statistical equilibrium.16 (One might wonder whether there is entropy
associated with the galaxy’s gravitational ﬁeld, some of which is due to the stars, and
whether that entropy invalidates our analysis. The answer is no. The gravitational
ﬁeld has no randomness, beyond that of the stars themselves, and thus no entropy;
its structure is uniquely determined, via Newton’s gravitational ﬁeld equation, by the
stars’ spatial distribution.)
In a real galaxy or other star cluster, rare near-encounters between stars in the
cluster core (ignored in the above discussion) cause individual stars to be ejected
from the core into distant orbits or to be ejected from the cluster altogether. These
ejections increase the entropy of the cluster plus ejected stars in just the manner of
to increase entropy, galaxy
core shrinks and halo
grows
our thought experiment. The core of the galaxy shrinks, a diffuse halo grows, and the
total number of stars in the galaxy gradually decreases. This evolution to ever-larger
entropy is demanded by the laws of statistical mechanics, but by contrast with systems
without gravity, it does not bring the cluster to statistical equilibrium. The long-range
gravity as key to galaxy’s
behavior
inﬂuence of gravity prevents a true equilibrium from being reached. Ultimately, the
cluster’s or galaxy’s core may collapse to form a black hole—and, indeed, most large
galaxies are observed to have massive black holes in their cores. Despite this somewhat
negative conclusion, the techniques of statistical mechanics can be used to understand
16. A true equilibrium can be achieved if the galaxy is enclosed in an idealized spherical box whose walls
prevent stars from escaping, or if the galaxy lives in an inﬁnite thermalized bath of stars so that, on
average, when one star is ejected into a distant orbit in the bath, another gets injected into the galaxy (see,
e.g., Ogorodnikov, 1965; Lynden-Bell, 1967). However, in the real universe galaxies are not surrounded
by walls or by thermalized star baths.
4.10 Statistical Mechanics in the Presence of Gravity
203

galactic dynamics over the comparatively short timescales of interest to astronomers
(e.g., Binney and Tremaine, 2003). For a complementary description of a dark matter
galaxy in which the stars are ignored, see Ex. 28.7. Further discussion of stellar and
dark matter distributions in galaxies is presented in Chap. 28.
4.10.2
4.10.2 Black Holes
Quantum ﬁeld theory predicts that, near the horizon of a black hole, the vacuum ﬂuc-
tuations of quantized ﬁelds behave thermally, as seen by stationary (non-infalling)
thermal atmosphere of a
black hole
observers. More speciﬁcally, such observers see the horizon surrounded by an atmo-
sphere that is in statistical equilibrium (a thermalized atmosphere) and that rotates
with the same angular velocity H as the hole’s horizon. This remarkable conclusion,
due to Stephen Hawking (1976), William Unruh (1976), and Paul Davies (1977), is
discussedpedagogicallyinbooksbyThorne, Price, andMacDonald(1986)andFrolov
and Zelnikov (2011), and more rigorously in a book by Wald (1994). The atmosphere
contains all types of particles that can exist in Nature. Very few of the particles man-
age to escape from the hole’s gravitational pull; most emerge from the horizon, ﬂy up
to some maximum height, then fall back down to the horizon. Only if they start out
moving almost vertically upward (i.e., with nearly zero angular momentum) do they
have any hope of escaping. The few that do escape make up a tiny trickle of Hawking
Hawking radiation
radiation (Hawking, 1975) that will ultimately cause the black hole to evaporate, un-
less it grows more rapidly due to infall of material from the external universe (which
it will unless the black hole is far less massive than the Sun).
In discussing the distribution function for the hole’s thermalized, rotating atmo-
sphere, one must take account of the fact that the locally measured energy of a particle
decreases as it climbs out of the hole’s gravitational ﬁeld (Ex. 26.4). One does so by
attributing to the particle the energy that it would ultimately have if it were to escape
from the hole’s gravitational grip. This is called the particle’s “redshifted energy” and
is denoted by E∞. This E∞is conserved along the particle’s world line, as is the pro-
jection j . ˆH of the particle’s orbital angular momentum j along the hole’s spin axis
(unit direction ˆH).
The hole’s horizon behaves like the wall of a blackbody cavity. Into each up-
going mode (single-particle quantum state) a of any and every quantum ﬁeld that
can exist in Nature, it deposits particles that are thermalized with (redshifted) tem-
perature TH, vanishing chemical potential, and angular velocity H. As a result,
the mode’s distribution function—which is the probability of ﬁnding Na particles
in it with net redshifted energy Ea ∞= Na × (redshifted energy of one quantum
in the mode) and with net axial component of angular momentum ja . ˆH = Na ×
(angular momentum of one quantum in the mode)—is
ρa = C exp
−Ea ∞+ H . ja
kBTH

(4.59)
[see Eq. (4.22) and note that H = H ˆH]. The distribution function for the entire
atmosphere’s distribution
function
thermalized atmosphere (made of all modes that emerge from the horizon) is, of
204
Chapter 4. Statistical Mechanics

course, ρ = 0
a ρa. (Ingoing modes, which originate at inﬁnity—i.e., far from the
black hole—are not thermalized; they contain whatever the universe chooses to send
toward the hole.) Because Ea ∞is the redshifted energy in mode a, TH is similarly
a redshifted temperature: it is the temperature that the Hawking radiation exhibits
when it has escaped from the hole’s gravitational grip. Near the horizon, the locally
measured atmospheric temperature is gravitationally blue-shifted to much higher
values than TH.
The temperature TH and angular velocity H, like all properties of a black hole,
are determined completely by the hole’s spin angular momentum JH and its mass MH.
To within factors of order unity, they have magnitudes [Ex. 26.16 and Eq. (26.77)]
black hole temperature
and angular velocity
TH ∼
ℏ
8πkBGMH/c3 ∼6 × 10−8 K
MH/M⊙
,
H ∼
JH
MH(2GMH/c2)2 .
(4.60)
For a very slowly rotating hole the “∼” becomes an “=” in both equations. Notice how
small the hole’s temperature is, if its mass is greater than or of orderM⊙. For such holes
the thermal atmosphere is of no practical interest, though it has deep implications for
fundamental physics. Only for tiny black holes (that might conceivably have been
formed in the big bang) is TH high enough to be physically interesting.
Suppose that the black hole evolves much more rapidly by accreting matter than
by emitting Hawking radiation. Then the evolution of its entropy can be deduced
from the ﬁrst law of thermodynamics for its atmosphere. By techniques analogous to
some developed in the next chapter, one can argue that the atmosphere’s equilibrium
distribution (4.59) implies the following form for the ﬁrst law (where we set c = 1):
ﬁrst law of
thermodynamics
for black hole
dMH = THdSH + H . dJH
(4.61)
[cf. Eq. (26.92)]. Here dMH is the change of the hole’s mass due to the accretion (with
each infalling particle contributing its E∞to dMH), dJH is the change of the hole’s spin
angular momentum due to the accretion (with each infalling particle contributing its
j), and dSH is the increase of the black hole’s entropy.
Because this ﬁrst law can be deduced using the techniques of statistical mechanics
(Chap. 5), it can be argued (e.g., Zurek and Thorne, 1985) that the hole’s entropy
increase has the standard statistical mechanical origin and interpretation: if Nstates
is the total number of quantum states that the infalling material could have been in
(subject only to the requirement that the total infalling mass-energy be dMH and total
infalling angular momentum be dJH), then dSH = kB log Nstates [cf. Eq. (4.35)]. In
other words, the hole’s entropy increases by kB times the logarithm of the number
of quantum mechanically different ways that we could have produced its changes of
mass and angular momentum, dMH and dJH. Correspondingly, we can regard the
hole’s total entropy as kB times the logarithm of the number of ways in which it could
have been made. That number of ways is enormous, and correspondingly, the hole’s
4.10 Statistical Mechanics in the Presence of Gravity
205

entropy is enormous. This analysis, when carried out in full detail (Zurek and Thorne,
1985), reveals that the entropy is [Eq. (26.93)]
black hole’s entropy
SH = kB
AH
4LP
2 ∼1 × 1077kB
*
MH
M⊙
+2
,
(4.62)
where AH ∼4π(2GMH/c2) is the surface area of the hole’s horizon, and LP =

Gℏ/c3 = 1.616 × 10−33 cm is the Planck length—a result ﬁrst proposed by Beken-
stein (1972) and ﬁrst proved by Hawking (1975).
What is it about a black hole that leads to this peculiar thermal behavior and enor-
horizon as key to hole’s
thermal behavior
mous entropy? Why is a hole so different from a star or galaxy? The answer lies in the
black-hole horizon and the fact that things that fall inward through the horizon can-
not get back out. From the perspective of quantum ﬁeld theory, the horizon produces
the thermal behavior. From that of statistical mechanics, the horizon produces the
loss of information about how the black hole was made and the corresponding en-
tropy increase. In this sense, the horizon for a black hole plays a role analogous to
coarse-graining in conventional classical statistical mechanics.17
The above statistical mechanical description of a black hole’s atmosphere and
thermal behavior is based on the laws of quantum ﬁeld theory in curved spacetime—
laws in which the atmosphere’s ﬁelds (electromagnetic, neutrino, etc.) are quantized,
but the hole itself is not governed by the laws of quantum mechanics. For detailed
but fairly brief analyses along the lines of this section, see Zurek and Thorne (1985);
Frolov and Page (1993). For a review of the literature on black-hole thermodynamics
and of conundrums swept under the rug in our simple-minded discussion, see Wald
(2001).18
EXERCISES
Exercise 4.16 Example: Thermal Equilibria for a Black Hole inside a Box
This problem was posed and partially solved by Hawking (1976), and fully solved
by Page et al. (1977). Place a nonrotating black hole with mass M at the center of a
spherical box with volume V that is far larger than the black hole: V 1/3 ≫2GM/c2.
Put into the box, and outside the black hole, thermalized radiation with energy
E −Mc2 (so the total energy in the box is E). The black hole will emit Hawking
17. Itseemslikely, asof2017, thattheinformationaboutwhatfellintotheholegetsretained, insomemanner,
in the black hole’s atmosphere, and we have coarse-grained it away by our faulty understanding of the
relevant black-hole quantum mechanics.
18. A much deeper understanding involves string theory—the most promising approach to quantum gravity
and to quantization of black holes. Indeed, the thermal properties of black holes, and most especially
their entropy, are a powerful testing ground for candidate theories of quantum gravity. A recent, lively
debate around the possibility that a classical event horizon might be accompanied by a ﬁrewall (Almheiri
et al., 2013) is a testament to the challenge of these questions, and to the relevance that they have to the
relationship between gravity and the other fundamental interactions.
206
Chapter 4. Statistical Mechanics

radiation and will accrete thermal radiation very slowly, causing the hole’s mass
M and the radiation energy E −Mc2 to evolve. Assume that the radiation always
thermalizes during the evolution, so its temperature T is always such that aT 4V =
E −Mc2, where a is the radiation constant. (For simplicity assume that the only form
ofradiationthattheblackholeemitsandthatresidesintheboxisphotons; theanalysis
is easily extended to the more complicated case where other kinds of particles are
present and are emitted.) Discuss the evolution of this system using the second law of
thermodynamics. More speciﬁcally, do the following.
(a) To simplify your calculations, use so-called natural units in which not only is
c set equal to unity (geometrized units), but also G = ℏ= kB = 1. If you have
never used natural units before, verify that no dimensionless quantities can be
constructed from G, c, ℏ, and kB; from this, show that you can always return to
cgs or SI units by inserting the appropriate factors of G, c, ℏ, and kB to get the
desired units. Show that in natural units the radiation constant is a = π2/15.
(b) ShowthatinnaturalunitsthetotalentropyinsidetheboxisS = 4
3aV T 3 + 4πM2.
The mass M and radiation temperature T will evolve so as to increase this S
subject to the constraint that E = M + aV T 4, with ﬁxed E and V .
(c) Find a rescaling of variables that enables E to drop out of the problem. [Answer:
Setm = M/E,  = S/(4πE2), andν = V a/[(3π)4E5], som, , andν arerescaled
black-hole mass, entropy in the box, and box volume.] Show that the rescaled
entropy is given by
 = m2 + ν1/4(1 −m)3/4.
(4.63)
This entropy is plotted as a function of the black hole mass m in Fig. 4.6 for various
ν [i.e., for various V = (3π)4(E5/a)ν].
(d) Show that
d
dm =
3ν1/4
4(1 −m)1/4(τ −1),
(4.64)
where τ = T/TH = 8πMT is the ratio of the radiation temperature to the black
hole’s Hawking temperature. Thereby show that (i) when τ > 1, the black hole
accretes more energy than it emits, and its mass M grows, thereby increasing the
entropy in the box and (ii) when τ < 1, the black hole emits more energy than it
accretes, thereby decreasing its mass and again increasing the total entropy.
(e) From the shapes of the curves in Fig. 4.6, it is evident that there are two critical
values of the box’s volume V (or equivalently, of the rescaled volume ν): Vh and
Vg. For V > Vh, the only state of maximum entropy is m = 0: no black hole.
For these large volumes, the black hole will gradually evaporate and disappear.
For V < Vh, there are two local maxima: one with a black hole whose mass is
somewhere between m = M/E = 4/5 and 1; the other with no black hole, m = 0.
4.10 Statistical Mechanics in the Presence of Gravity
207

1.6
1.4
1.2
1.0
0.8
0.0
0.2
0.4
0.6
0.8
0.90
0.92
0.94
0.96
0.98
1.00
1.0
1.02
1.00
0.98
 = S
—
4πE 2
m = M/E
V > Vh
V = Vh
Vg < V  < Vh
Vg < V  < Vh
V  = Vg
V  = Vg
V  < Vg
V  < Vg
FIGURE 4.6 Total entropy S inside a box of volume V that contains a black hole with mass M and
thermalized radiation with energy E −Mc2 and temperature T = [(E −Mc2)/(aV )]1/4. For V < Vh
there is a statistical equilibrium that contains a black hole, at the local maximum of entropy (large
ﬁlled circles). At that equilibrium, the radiation temperature T is equal to the black hole’s Hawking
temperature TH. See Exercise 4.16e for the deﬁnitions of Vg and Vh.
If V = Vg, the two states have the same entropy; if V < Vg, the state with a black
hole has the larger entropy; if Vg < V < Vh, the state without a black hole has the
larger entropy. Show that
Vh = 220π4
55a E5 = 4.97 × 104

E
MPc2
2 GE
c4
3
,
Vg = 0.256Vh,
(4.65)
where the ﬁrst expression is in natural units. Here MP = √ℏc/G = 2.177 ×
10−5 g is the Planck mass, and GE/c4 is half the radius of a black hole with mass
E/c2. Show that, if Vg < V < Vh, and if the box’s volume V is made as large as
possible—the size of the universe—then the mass of the equilibrium black hole
will be roughly 1/100 the mass of the Sun.
When there are two entropy maxima, that is, two states of statistical equilibrium
(i.e., for V < Vh), an entropy barrier exists between the two equilibria. In principle,
quantum ﬂuctuations should be able to carry the system through that barrier, from
the equilibrium of lower entropy to that of higher entropy, though the rate will be
extremely small for E ≫MPc2. Those ﬂuctuations will be governed by the laws of
208
Chapter 4. Statistical Mechanics

quantum gravity, so studying them is a useful thought experiment in the quest to
understand quantum gravity.
4.10.3
4.10.3 The Universe
Observations and theory agree that the universe, when far younger than 1 s old,
settled into a very hot, highly thermalized state. All particles except gravitons were
in statistical equilibrium at a common, declining temperature, until the dark matter
andtheneutrinosdroppedoutofequilibriumand(likethegravitons)becamethermo-
dynamically isolated.
During this early relativistic era, the equations of relativistic cosmology imply
(as discussed in Sec. 28.4.1) that the temperature T of the universe at age t satisﬁed
T/TP ∼(t/tP)−1/2. Here TP ≡[ℏc5/(Gk2
B)]1/2 ∼1032 K is the Planck temperature,
and tP ≡(ℏG/c5)1/2 ∼10−43 s is the Planck time. (This approximate T /TP relation-
ship can be justiﬁed on dimensional grounds.) Now the region that was in causal
contact at time t (i.e., that was contained within a mutual cosmological horizon) had
a volume ∼(ct)3, and thermodynamic considerations imply that the number of rela-
number of particles
and entropy inside
cosmological horizon
tivistic particles that were in causal contact at time t was N ∼(kBT t/ℏ)3 ∼(t/tP)3/2.
(This remains roughly true today when N has grown to ∼1091, essentially all in
microwave background photons.) The associated entropy was then S ∼NkB (cf.
Sec. 4.8).
Although this seems like an enormous entropy, gravity can do even better. The
most efﬁcient way to create entropy, as described in Sec. 4.10.2, is to form mas-
sive black holes. Suppose that out of all the relativistic particle mass within the
horizon, M ∼NkBT/c2, a fraction f has collapsed into black holes of mass MH.
Then, with the aid of Sec. 4.10.2, we estimate that the associated entropy is SH ∼
entropy in black holes
f (MH/M)(t/tP)1/2S. If we use the observation that every galaxy has a central
black hole with mass in the ∼106–109 solar mass range, we ﬁnd that f ∼10−4 and
SH ∼1011S today!
Now it might be claimed that massive black holes are thermodynamically isolated
from the rest of the universe because they will take so long to evaporate. That may be
so as a practical matter, but more modest gravitational condensations that create stars
and starlight can produce large local departures from thermodynamic equilibrium,
accompanied by (indeed, driven by) a net increase of entropy and can produce the
conditions necessary for life to develop.
Given these considerations, it should not come as a surprise to learn that the
behavior of entropy in the expanding universe has provided a foundation for the
standard model of cosmology, which we outline in Chap. 28. It has also provided
a stimulus for many imaginative proposals addressing fascinating questions that lie
4.10 Statistical Mechanics in the Presence of Gravity
209

beyond the standard model, some of which connect with the nature of life in the
universe.19
4.10.4
4.10.4 Structure Formation in the Expanding Universe:
Violent Relaxation and Phase Mixing
The formation of stars and galaxies (“structure”) by gravitational condensation pro-
vides a nice illustration of the phase mixing and coarse-graining that underlie the
second law of thermodynamics (Sec. 4.7.2).
It is believed that galaxies formed when slight overdensities in the dark matter
and gas (presumably irregular in shape) stopped expanding and began to contract
under their mutual gravitational attraction. Much of the gas was quickly converted
into stars. The dark-matter particles and the stars had very little random motion at
this stage relative to their random motions today, v ∼200 km s−1. Correspondingly,
although their physical volume Vx was initially only moderately larger than today,
their momentum-space volume Vp was far smaller than it is today. Translated into
the language of an ensemble of N such galaxies, the initial coordinate-space volume

d3Nx ∼Vx
N occupied by each of the ensemble’s galaxies was moderately larger than
it is today, while its momentum-space volume

d3Np ∼Vp
N was far smaller. The
phase-space volume VN
x VN
p must therefore have increased considerably during the
galaxy formation—with the increase due to a big increase in the relative momenta of
neighboring stars. For this to occur, it was necessary that the stars changed their rel-
ative energies during the contraction, which requires a time-dependent hamiltonian.
In other words, the gravitational potential  felt by the stars must have varied rapidly,
so that the individual stellar energies would vary according to
dE
dt = ∂H
∂t = m∂
∂t .
(4.66)
The largest changes of energy occurred when the galaxy was contracting dynami-
cally (collapsing), so the potential changed signiﬁcantly on the timescale it took stars
violent relaxation of star
distribution
to cross the galaxy, τint ∼2R/v. Numerical simulations show that this energy trans-
fer was highly efﬁcient. This process is known as violent relaxation. Although violent
relaxation could create the observed stellar distribution functions, it was not by itself
a means of diluting the phase-space density, since Liouville’s theorem still applied.
phase mixing and coarse-
grainingofstardistribution
The mechanism that changed the phase-space density was phase mixing and
coarse-graining (Sec. 4.7.2 above). During the initial collapse, the particles and newly
formed stars could be thought of as following highly perturbed radial orbits. The
orbits of nearby stars were somewhat similar, though not identical. Therefore small
elements of occupied phase space became highly contorted as the particles and stars
moved along their phase-space paths.
19. For an early and highly inﬂuential analysis, see Schr¨odinger (1944), and for a more recent discussion,
see Penrose (2016).
210
Chapter 4. Statistical Mechanics

Let us make a simple model of this process by assuming the individual particles
and stars initially populate a fraction f ≪1of the ﬁnal occupied phase-space volume
Vﬁnal. After one dynamical timescale τint ∼R/v, this small volume f Vﬁnal is (pre-
sumably) deformed into a convoluted surface that folds back on itself once or twice
like dough being kneaded by a baker, while still occupying the same volume f Vﬁnal.
After n dynamical timescales, there are ∼2n such folds (cf. Fig. 4.2b above). After
n ∼−log2 f dynamical timescales, the spacing between folds becomes comparable
with the characteristic thickness of this convoluted surface, and it is no longer prac-
tical to distinguish the original distribution function. We expect that coarse-graining
has been accomplished for all practical purposes; only a pathological physicist would
resist it and insist on trying to continue keeping track of which contorted phase-space
regions have the original high density and which do not. For a galaxy we might expect
that f ∼10−3 and so this natural coarse-graining can occur in a time approximately
equal to −log2 10−3τint ∼10 τint ∼109 yr, which is 10 times shorter than the present
age of galaxies. Therefore it need not be a surprise that the galaxy we know best, our
own Milky Way, exhibits little obvious vestigial trace of its initial high-density (low
phase-space-volume) distribution function.20
4.11
4.11 Entropy and Information
4.11.1
4.11.1 Information Gained When Measuring the State of a System
in a Microcanonical Ensemble
In Sec. 4.7, we said that entropy is a measure of our lack of information about the
state of any system chosen at random from an ensemble. In this section we make this
heuristic statement useful by introducing a precise deﬁnition of information.
Consider a microcanonical ensemble of identical systems. Each system can reside
in any one of a ﬁnite number, Nstates, of quantum states, which we label by integers
n = 1, 2, 3, . . . , Nstates. Because the ensemble is microcanonical, all Nstates states are
equally probable; they have probabilities ρn = 1/Nstates. Therefore the entropy of any
system chosen at random from this ensemble is S = −kB
!
n ρn ln ρn = kB ln Nstates
[Eqs. (4.34) and (4.35)].
Now suppose that we measure the state of our chosen system and ﬁnd it to be
(for example) state number 238 out of the Nstates equally probable states. How much
information have we gained? For this thought experiment, and more generally (see
Sec. 4.11.2 below), the amount of information gained, expressed in bits, is deﬁned to be
amount of information
gained in a measurement
for microcanonical
ensemble
the minimum number of binary digits required to distinguish the measured state from all
the other Nstates states that the system could have been in. To evaluate this information
gain, we label each state n by the number n −1 written in binary code (state n = 1
is labeled by {000}, state n = 2 is labeled by {001}, 3 is {010}, 4 is {011}, 5 is {100},
20. However, the dark-matter particles may very well not be fully coarse-grained at the present time, and
this inﬂuences strategies for detecting it.
4.11 Entropy and Information
211

6 is {101}, 7 is {110}, 8 is {111}, etc.). If Nstates = 4, then the number of binary digits
needed is 2 (the leading 0 in the enumeration above can be dropped), so in measuring
the system’s state we gain 2 bits of information. If Nstates = 8, the number of binary
digits needed is 3, so our measurement gives us 3 bits of information. In general,
we need log2 Nstates binary digits to distinguish the states from one another, so the
amount of information gained in measuring the system’s state is the base-2 logarithm of
the number of states the system could have been in:
I = log2 Nstates = (1/ ln 2) ln Nstates = 1.4427 ln Nstates.
(4.67a)
information gain related to
entropy decrease
Notice that this information gain is proportional to the entropy S = kB ln Nstates
of the system before the measurement was made:
I = S/(kB ln 2).
(4.67b)
The measurement reduces the system’s entropy from S = −kB ln Nstates to zero
(and increases the entropy of the rest of the universe by at least this amount), and
it gives us I = S/(kB ln 2) bits of information about the system. We shall discover
below that this entropy/information relationship is true of measurements made on a
system drawn from any ensemble, not just a microcanonical ensemble. But ﬁrst we
must develop a more complete understanding of information.
4.11.2
4.11.2 Information in Communication Theory
communication theory
The deﬁnition of “the amount of information I gained in a measurement” was for-
mulated by Claude Shannon (1948) in the context of his laying the foundations of
communication theory. Communication theory deals (among other things) with the
problem of how to encode most efﬁciently a message as a binary string (a string of 0s
and 1s) in order to transmit it across a communication channel that transports binary
signals. Shannon deﬁned the information in a message as the number of bits required,
general deﬁnition of
information
inthemostcompressedsuchencoding, todistinguishthismessagefromallothermessages
that might be transmitted.
symbols and messages
Shannon focused on messages that, before encoding, consist of a sequence of sym-
bols. For an English-language message, each symbol might be a single character (a
letter A, B, C, . . . , Z or a space; N = 27 distinct symbols in all), and a speciﬁc message
might be the following sequence of length L = 19 characters: “I DO NOT UNDER-
STAND”. Suppose, for simplicity, that in the possible messages, all N distinct symbols
appear with equal frequency (this, of course, is not the case for English-language mes-
sages), and suppose that the length of some speciﬁc message (its number of symbols)
is L. Then the number of bits needed to encode this message and distinguish it from
all other possible messages of length L is
I = log2 NL = L log2 N.
(4.68a)
In other words, the average number of bits per symbol (the average amount of infor-
mation per symbol) is
¯I = log2 N.
(4.68b)
212
Chapter 4. Statistical Mechanics

If there are only two possible symbols, we have one bit per symbol in our message. If
there are four possible (equally likely) symbols, we have two bits per symbol, and so
forth.
It is usually the case that not all symbols occur with the same frequency in the
allowed messages. For example, in English messages the letter “A” occurs with a
frequency pA ≃0.07, while the letter “Z” occurs with the much smaller frequency
pZ ≃0.001. All English messages, of character length L ≫N = 27, constructed by
a typical English speaker, will have these frequencies of occurrence for “A” and “Z”.
Any purported message with frequencies for “A” and “Z” differing substantially from
0.07 and 0.001 will not be real English messages, and thus need not be included
in the binary encoding of messages. As a result, it turns out that the most efﬁcient
binary encoding of English messages (the most compressed encoding) will use an
average number of bits per character somewhat less than log2 N = log2 27 = 4.755.
In other words, the average information per character in English language messages
is somewhat less than log2 27.
To deduce the average information per character when the characters do not
all occur with the same frequency, we begin with a simple example: the number of
distinct characters to be used in the message is just N = 2 (the characters “B” and
“E”), and their frequencies of occurrence in very long allowed messages are pB = 3/5
and pE = 2/5. For example, in the case of messages with length L = 100, the message
EBBEEBBBBEBBBBBBBBBEBEBBBEEEEBBBEB
BEEEEEBEEBEEEEEEBBEBBBBBEBBBBBEBBE
BBBEBBBEEBBBEBBBBBBBEBBBEBBEEBEB
(4.69a)
contains 63 Bs and 37 Es, and thus (to within statistical variations) has the correct
frequencies pB ≃0.6, pE ≃0.4 to be an allowed message. By contrast, the message
BBBBBBBBBBBBBBEBBBBBBBBBBBBBBBBBBB
BBBBBBBBBBBEBBBBBBBBBBBBBBBBBBBBBB
BBBBBBBBBBBBBBBEBBBBBBBBBBBBBBBB
(4.69b)
contains 97 Bs and 3 Es and thus is not an allowed message. To deduce the number of
allowed messages and thence the number of bits required to encode them distinguish-
ably, we map this problem of 60% probable Bs and 40% probable Es onto the problem
of messages with ﬁve equally probable symbols as follows. Let the set of distinct sym-
bols be the letters “a”, “b”, “c”, “y”, and “z”, all occurring in allowed messages equally
frequently: pa = pb = pc = py = pz = 1/5. An example of an allowed message is
zcczzcaabzccbabcccczaybacyzyzcbbyc
ayyyyyayzcyzzzzzcczacbabybbbcczabz
bbbybaazybccybaccabazacbzbayycyc
(4.69c)
We map each such message from our new message set into one from the previous
message set by identifying “a”, “b”, and “c” as from the beginning of the alphabet
(and thus converting them to “B”), and identifying “y” and “z” as from the end of
4.11 Entropy and Information
213

the alphabet (and thus converting them to “E”). Our message (4.69c) from the new
messagesetthenmapsintothemessage(4.69a)fromtheoldset.Thismappingenables
us to deduce the number of bits required to encode the old messages, with their
unequal frequencies pB = 3/5 and pE = 2/5, from the number required for the new
messages, with their equal frequencies pa = pb = . . . = pz = 1/5.
The number of bits needed to encode the new messages, with length L ≫Nnew =
5, is I = L log2 5. The characters “a,” “b,” and “c” from the beginning of the alphabet
occur 3
5L times in each new message (in the limit that L is arbitrarily large). When
converting the new message to an old one, we no longer need to distinguish between
“a”, “b”, and “c”, so we no longer need the 3
5L log2 3 bits that were being used to make
those distinctions. Similarly, the number of bits we no longer need when we drop the
distinction between our two end-of-alphabet characters “y” and “z” is 2
5L log2 2. As a
result, the number of bits still needed to distinguish between old messages (messages
with “B” occurring 3/5 of the time and “E” occurring 2/5 of the time) is
I = L log2 5 −3
5L log2 3 −2
5 log2 2 = L

−3
5 log2
3
5 −2
5 log2
2
5

= L(−pB log2 pB −pE log2 pE).
(4.69d)
A straightforward generalization of this argument (Ex. 4.17) shows that, when one
constructs messages with very large length L ≫N from a pool of N symbols that occur
with frequencies p1, p2, . . . , pN, the minimum number of bits required to distinguish
all the allowed messages from one another (i.e., the amount of information in each
message) is
I = L
N
 
n=1
−pn log2 pn;
(4.70)
so the average information per symbol in the message is
information per symbol in
a message
¯I =
N
 
n=1
−pn log2 pn = (1/ ln 2)
N
 
n=1
−pn ln pn.
(4.71)
4.11.3
4.11.3 Examples of Information Content
Notice the similarity of the general information formula (4.70) to the general for-
mula (4.34) for the entropy of an arbitrary ensemble. This similarity has a deep
consequence.
INFORMATION FROM MEASURING THE STATE OF ONE SYSTEM IN AN ENSEMBLE
Consider an arbitrary ensemble of systems in statistical mechanics. As usual, label the
quantumstatesavailabletoeachsystembytheintegern = 1, 2, . . . , Nstates, anddenote
by pn the probability that any chosen system in the ensemble will turn out to be in
state n. Now select one system out of the ensemble and measure its quantum state n1;
214
Chapter 4. Statistical Mechanics

select a second system and measure its state, n2. Continue this process until some large
number L ≫Nstates of systems have been measured. The sequence of measurement
results {n1, n2, . . . , nL} can be regarded as a message. The minimum number of bits
needed to distinguish this message from all other possible such messages is given by
the general information formula (4.70). This is the total information in the L system
information from
measurement for a
general ensemble
measurements.Correspondingly, theamountofinformationwegetfrommeasuringthe
state of one system (the average information per measurement) is given by Eq. (4.71).
This acquired information is related to the entropy of the system before measurement
[Eq. (4.34)] by the same standard formula (4.67b) as we obtained earlier for the special
case of the microcanonical ensemble:
¯I = S/(kB ln 2).
(4.72)
INFORMATION IN AN ENGLISH-LANGUAGE MESSAGE
For another example of information content, we return to English-language messages
(Shannon, 1948). Evaluating the information content of a long English message is a
very difﬁcult task, since it requires ﬁguring out how to compress the message most
compactly. We shall make a series of estimates.
information per character
in English message
A crude initial estimate of the information per character is that obtained by
idealizing all the characters as occurring equally frequently: ¯I = log2 27 ≃4.76 bits
per character [Eq. (4.68b)]. This is an overestimate, because the 27 characters actually
occur with very different frequencies. We could get a better estimate by evaluating
¯I = !27
n=1 −pn log2 pn, taking account of the characters’ varying frequencies pn (the
result is about ¯I = 4.1), but we can do even better by converting from characters as
our symbols to words. The average number of characters in an English word is about
4.5 letters plus 1 space, or 5.5 characters per word. We can use this number to convert
from characters as our symbols to words. The number of words in a typical English
speaker’s vocabulary is roughly 12,000. If we idealize these 12,000 words as occurring
with the same frequencies, then the information per word is log2 12,000 ≃13.6, so
the information per character is ¯I = (1/5.5) log2 12,000 ≃2.46. This is much smaller
than our previous estimates. A still better estimate is obtained by using Zipf’s (1935)
approximation pn = 0.1/n of the frequencies of occurrence of the words in English
messages.21 To ensure that !N
n=1 pn = 1 for Zipf’s approximation, we require that
the number of words be N = 12,367. We then obtain, as our improved estimate of
the information per word, !12,367
n=1 (−0.1/n) log2(0.1/n) = 9.72, corresponding to a
value of information per character ¯I ≃9.72/5.5 = 1.77. This is substantially smaller
than our initial, crudest estimate of 4.76 and is close to more careful estimates ¯I ≃1.0
to 1.5 (Schneier, 1997, Sec. 11.1).
21. The most frequently occurring word is “THE”, and its frequency is about 0.1 (1 in 10 words is “THE” in
a long message). The next most frequent words are “OF”, “AND”, and “TO”; their frequencies are about
0.1/2, 0.1/3, and 0.1/4, respectively; and so forth.
4.11 Entropy and Information
215

4.11.4
4.11.4 Some Properties of Information
Because of the similarity of the general formulas for information and entropy (both
proportional to !
n −pn ln pn), information has very similar properties to entropy.
In particular (Ex. 4.18):
1. Information is additive (just as entropy is additive). The information in two
successive, independent messages is the sum of the information in each
message.
2. If the frequencies of occurrence of the symbols in a message are pn = 0 for
all symbols except one, which has pn = 1, then the message contains zero
information. This is analogous to the vanishing entropy when all states have
zero probability except for one, which has unit probability.
3. For a message L symbols long, whose symbols are drawn from a pool of N
distinct symbols, the information content is maximized if the probabilities
of the symbols are all equal (pn = 1/N), and the maximal value of the infor-
mation is I = L log2 N. This is analogous to the microcanonical ensemble
having maximal entropy.
4.11.5
4.11.5 Capacity of Communication Channels; Erasing Information
from Computer Memories
NOISELESS COMMUNICATION
A noiseless communication channel has a maximum rate (number of bits per second)
channel capacity of
noiseless communication
at which it can transmit information. This rate is called the channel capacity and is
denoted C. When one subscribes to a cable internet connection in the United States,
one typically pays a monthly fee that depends on the connection’s channel capacity;
for example, in Pasadena, California, in summer 2011 the fee was $29.99 per month
for a connection with capacity C = 12 megabytes/s = 96 megabits/s, and $39.99 for
C = 144 megabits/s. (This was a 30-fold increase in capacity per dollar since 2003!)
It should be obvious from the way we have deﬁned the information I in a message
that the maximum rate at which we can transmit optimally encoded messages, each
with information content I, is C/I messages per second.
NOISY COMMUNICATION
When a communication channel is noisy (as all channels actually are), for high-
conﬁdence transmission of messages one must put some specially designed redun-
dancyintoone’sencoding.Withcleverness, onecantherebyidentifyandcorrecterrors
in a received message, caused by the noise (error-correcting code); see, for example,
Shannon, (1948), Raisbeck (1963), and Pierce (2012).22 The redundancy needed for
such error identiﬁcation and correction reduces the channel’s capacity. As an exam-
ple, consider a symmetric binary channel: one that carries messages made of 0s and
22. A common form of error-correcting code is based on parity checks.
216
Chapter 4. Statistical Mechanics

1s, with equal frequency p0 = p1 = 0.5, and whose noise randomly converts a 0 into
a 1 with some small error probability pe, and randomly converts a 1 into 0 with that
same probability pe. Then one can show (e.g., Pierce, 2012; Raisbeck, 1963) that the
reduction of channel
capacity due to error
correction
channel capacity is reduced—by the need to ﬁnd and correct for these errors—by a
factor
C = Cnoiseless[1 −¯I(pe)],
where ¯I(pe) = −pe log2 pe −(1 −pe) log2(1 −pe).
(4.73)
Note that the fractional reduction of capacity is by the amount of information per
symbol in messages made from symbols with frequencies equal to the probabilities
pe of making an error and 1−pe of not making an error—a remarkable and nontrivial
conclusion! This is one of many important results in communication theory.
MEMORY AND ENTROPY
Information is also a key concept in the theory of computation. As an important
example of the relationship of information to entropy, we cite Landauer’s (1961, 1991)
Landauer’s theorem:
entropy increase due to
erasure
theorem: In a computer, when one erases L bits of information from memory, one
necessarily increases the entropy of the memory and its environment by at least
S = LkB ln 2 and correspondingly, one increases the thermal energy (heat) of the
memory and environment by at least Q = T S = LkBT ln 2 (Ex. 4.21).
EXERCISES
Exercise 4.17 Derivation: Information per Symbol When Symbols Are
Not Equally Probable
Derive Eq. (4.70) for the average number of bits per symbol in a long message con-
structed from N distinct symbols, where the frequency of occurrence of symbol n is
pn. [Hint: Generalize the text’s derivation of Eq. (4.69d).]
Exercise 4.18 Derivation: Properties of Information
Prove the properties of entropy enumerated in Sec. 4.11.4.
Exercise 4.19 Problem: Information per Symbol for Messages Built from
Two Symbols
ConsidermessagesoflengthL ≫2constructedfromjusttwosymbols(N = 2), which
occur with frequencies p and (1 −p). Plot the average information per symbol ¯I(p)
in such messages, as a function of p. Explain why your plot has a maximum ¯I = 1
when p = 1/2, and has ¯I = 0 when p = 0 and when p = 1. (Relate these properties
to the general properties of information.)
Exercise 4.20 Problem: Information in a Sequence of Dice Throws
Two dice are thrown randomly, and the sum of the dots showing on the upper faces
is computed. This sum (an integer n in the range 2 ≤n ≤12) constitutes a symbol,
4.11 Entropy and Information
217

and the sequence of results of L ≫12 throws is a message. Show that the amount of
information per symbol in this message is ¯I ≃3.2744.
Exercise 4.21 Derivation: Landauer’s Theorem
Derive, or at least give a plausibility argument for, Landauer’s theorem (stated at the
end of Sec. 4.11.5).
Bibliographic Note
Statistical mechanics has inspired a variety of readable and innovative texts. The clas-
sic treatment is Tolman (1938). Classic elementary texts are Kittel (2004) and Kittel
and Kroemer (1980). Among more modern approaches that deal in much greater
depth with the topics covered in this chapter are Lifshitz and Pitaevskii (1980), Chan-
dler (1987), Sethna (2006), Kardar (2007), Reif (2008), Reichl (2009), and Pathria
and Beale (2011). The Landau-Lifshitz textbooks (including Lifshitz and Pitaevskii,
1980) are generally excellent after one has already learned the subject at a more el-
ementary level. A highly individual and advanced treatment, emphasizing quantum
statistical mechanics, is Feynman (1972). A particularly readable account in which
statistical mechanics is used heavily to describe the properties of solids, liquids, and
gases is Goodstein (2002). Readable, elementary introductions to information theory
are Raisbeck (1963) and Pierce (2012); an advanced text is McEliece (2002).
218
Chapter 4. Statistical Mechanics

5
CHAPTER FIVE
Statistical Thermodynamics
One of the principal objects of theoretical research is to ﬁnd the point of view from which the subject
appears in the greatest simplicty.
J. WILLARD GIBBS (1881)
5.1
5.1 Overview
In Chap. 4, we introduced the concept of statistical equilibrium and brieﬂy studied
some properties of equilibrated systems. In this chapter, we develop the theory of
statistical equilibrium in a more thorough way.
The title of this chapter, “Statistical Thermodynamics,” emphasizes two aspects of
the theory of statistical equilibrium. The term thermodynamics is an ancient one that
predates statistical mechanics. It refers to a study of the macroscopic properties of sys-
tems that are in or near equilibrium, such as their energy and entropy. Despite paying
no attention to the microphysics, classical thermodynamics is a very powerful the-
ory for deriving general relationships among macroscopic properties. Microphysics
inﬂuences the macroscopic world in a statistical manner, so in the late nineteenth
century, Willard Gibbs and others developed statistical mechanics and showed that it
provides a powerful conceptual underpinning for classical thermodynamics. The re-
sulting synthesis, statistical thermodynamics, adds greater power to thermodynamics
by augmenting it with the statistical tools of ensembles and distribution functions.
In our study of statistical thermodynamics, we restrict attention to an ensemble
of large systems that are in statistical equilibrium. By “large” is meant a system that
can be broken into a large number Nss of subsystems that are all macroscopically
identical to the full system except for having 1/Nss as many particles, 1/Nss as much
volume, 1/Nss as much energy, 1/Nss as much entropy, and so forth. (Note that
this deﬁnition constrains the energy of interaction between the subsystems to be
negligible.) Examples are 1 kg of plasma in the center of the Sun and a 1-kg sapphire
crystal.
The equilibrium thermodynamic properties of any type of large system (e.g., an
ideal gas)1 can be derived using any one of the statistical equilibrium ensembles of
the last chapter (microcanonical, canonical, grand canonical, or Gibbs). For example,
1.
An ideal gas is one with negligible interactions among its particles.
219

BOX 5.1.
READERS’ GUIDE
.
Relativity enters into portions of this chapter solely via the relativistic
energies and momenta of high-speed particles (Sec. 1.10).
.
This chapter relies in crucial ways on Secs. 3.2 and 3.3 of Chap. 3 and
on Secs. 4.2–4.8 of Chap. 4.
.
Portions of Chap. 6 rely on Sec. 5.6 of this chapter. Portions of Part V
(Fluid Dynamics) rely on thermodynamic concepts and equations of
state treated in this chapter, but most readers will already have met
these in a course on elementary thermodynamics.
.
Other chapters do not depend strongly on this one.
each of these ensembles will predict the same equation of state P = (N/V )kBT for an
idealgas, eventhoughinoneensembleeachsystem’snumberofparticlesN isprecisely
ﬁxed, while in another ensemble N can ﬂuctuate so that strictly speaking, one should
write the equation of state as P = (N/V )kBT , with N the ensemble average of N.
(Here and throughout this chapter, for compactness we use bars rather than brackets
to denote ensemble averages, i.e., N rather than ⟨N⟩.) The equations of state are the
same to very high accuracy because the fractional ﬂuctuations of N are so extremely
small: N/N ∼1/

N (cf. Ex. 5.11).
Although the thermodynamic properties are independent of the equilibrium en-
semble, speciﬁcpropertiesareoftenderivedmostquickly, andthemostinsightusually
accrues, from the ensemble that most closely matches the physical situation being
studied. In Secs. 5.2–5.5, we use the microcanonical, grand canonical, canonical, and
Gibbs ensembles to derive many useful results from statistical thermodynamics: fun-
damental potentials expressed as statistical sums over quantum states, variants of the
ﬁrst law of thermodynamics, equations of state, Maxwell relations, Euler’s equation,
and others. Table 5.1 summarizes the most important of those statistical-equilibrium
results and some generalizations of them. Readers are advised to delay studying this
table until they have read further into the chapter.
As we saw in Chap. 4, when systems are out of statistical equilibrium, their evolu-
tion toward equilibrium is driven by the law of entropy increase—the second law of
thermodynamics. In Sec. 5.5, we formulate the fundamental potential (Gibbs poten-
tial) for an out-of-equilibrium ensemble that interacts with a heat and volume bath,
and we discover a simple relationship between that fundamental potential and the en-
tropy of system plus bath. From that relationship, we learn that in this case the second
law is equivalent to a law of decrease of the Gibbs potential. As applications, we learn
how chemical potentials drive chemical reactions and phase transitions. In Sec. 5.6,
we discover how the Gibbs potential can be used to study spontaneous ﬂuctuations
of a system away from equilibrium, when it is coupled to a heat and particle bath.
220
Chapter 5. Statistical Thermodynamics

TABLE 5.1: Representations and ensembles for systems in statistical equilibrium, in relativistic notation
Representation
Quantities exchanged
Distribution
and ensemble
First law
with bath
function ρ
Energy and microcanonical
dE = T dS + ˜μdN −PdV
None
const = e−S/kB
(Secs. 4.5 and 5.2)
E const in δE
Enthalpy
dH = T dS + ˜μdN + V dP
V and E
const = e−S/kB
(Exs. 5.5 and 5.13)
dE = −PdV
H const
Physical free energy and
dF = −SdT + ˜μdN −PdV
E
e(F−E)/(kBT )
canonical (Secs. 4.4.1 and 5.4)
Gibbs (Secs. 4.4.2 and 5.5)
dG = −SdT + ˜μdN + V dP
E and V
e(G−E−PV )/(kBT )
Grand canonical
d = −SdT −Nd ˜μ −PdV
E and N
e(−E+ ˜μN)/(kBT )
(Secs. 4.4.2 and 5.3)
Notes: The nonrelativistic formulas are the same but with the rest masses of particles removed from the chemical potentials ( ˜μ →μ)
and from all fundamental potentials except  (E →E, but no change of notation for H, F, and G). This table will be hard to understand
until after reading the sections referenced in column one.
In Sec. 5.7, we employ these tools to explore ﬂuctuations and the gas-to-liquid phase
transition for a model of a real gas due to the Dutch physicist Johannes van der Waals.
Out-of-equilibrium aspects of statistical mechanics (evolution toward equilibrium
and ﬂuctuations away from equilibrium) are summarized in Table 5.2 and discussed
in Secs. 5.5.1 and 5.6, not just for heat and volume baths, but for a variety of baths.
Deriving the macroscopic properties of real materials by statistical sums over their
quantum states can be formidably difﬁcult. Fortunately, in recent years some powerful
approximation techniques have been devised for performing the statistical sums. In
Secs. 5.8.3 and 5.8.4, we give the reader the ﬂavor of two of these techniques: the
renormalization group and Monte Carlo methods. We illustrate and compare these
techniques by using them to study a phase transition in a simple model for ferro-
magnetism called the Ising model.
5.2
5.2 Microcanonical Ensemble and the Energy Representation
of Thermodynamics
5.2.1
5.2.1 Extensive and Intensive Variables; Fundamental Potential
Consider a microcanonical ensemble of large, closed systems that have attained sta-
tistical equilibrium. We can describe the ensemble macroscopically using a set of
thermodynamic variables. These variables can be divided into two classes: extensive
extensive and intensive
variables
variables (Sec. 4.4.1), which double if one doubles the system’s size, and intensive vari-
ables (Sec. 4.4.2), whose magnitudes are independent of the system’s size. Familiar
examples of extensive variables are a system’s total energy E, entropy S, volume V ,
and number of conserved particles of various species NI. Corresponding examples of
5.2 Microcanonical Ensemble and the Energy Representation of Thermodynamics
221

intensive variables are temperature T , pressure P , and the chemical potentials ˜μI for
various species of particles.
complete set of extensive
variables
For a large, closed system, there is a complete set of extensive variables that we can
specify independently—usually its volume V , total energy E or entropy S, and number
NI of particles of each species I. The values of the other extensive variables and all
the intensive variables are determined in terms of this complete set by methods that
we shall derive.
The particle species I in the complete set must only include those species whose
particles are conserved on the timescales of interest. For example, if photons can
be emitted and absorbed, then one must not specify Nγ, the number of photons;
rather, Nγ will come to an equilibrium value that is governed by the values of the
other extensive variables. Also, one must omit from the set {I} any conserved particle
species whose numbers are automatically determined by the numbers of other, in-
cluded species. For example, gas inside the Sun is always charge neutral to very high
precision, and therefore (neglecting all elements except hydrogen and helium), the
number of electrons Ne in a sample of gas is determined by the number of protons
Np and the number of helium nuclei (alpha particles) Nα: Ne = Np + 2Nα. Therefore,
if one includes Np and Nα in the complete set of extensive variables being used, one
must omit Ne.
As in Chap. 4, we formulate the theory relativistically correctly but formulate it
solely in the mean rest frames of the systems and baths being studied. Correspond-
ingly, in our formulation we generally include the particle rest masses mI in the total
energy E and in the chemical potentials ˜μI. For very nonrelativistic systems, however,
we usually replace E by the nonrelativistic energy E ≡E −!
I NImIc2 and ˜μI by the
nonrelativistic chemical potential μI ≡˜μI −mIc2 (though, as we shall see in Sec. 5.5
when studying chemical reactions, the identiﬁcation of the appropriate rest mass mI
to subtract is a delicate issue).
5.2.2
5.2.2 Energy as a Fundamental Potential
For simplicity, we temporarily specialize to a microcanonical ensemble of one-species
systems, which all have the same values of a complete set of three extensive variables:
the energy E,2 number of particles N, and volume V . Suppose that the microscopic
nature of the ensemble’s systems is known. Then, at least in principle and often
in practice, one can identify from that microscopic nature the quantum states that
are available to the system (given its constrained values of E, N, and V ), one can
count those quantum states, and from their total number Nstates one can compute the
ensemble’s total entropy S = kB ln Nstates [Eq. (4.35)]. The resulting entropy can be
regarded as a function of the complete set of extensive variables,
S = S(E, N, V ),
(5.1)
2.
In practice, as illustrated in Ex. 4.7, one must allow E to fall in some tiny but ﬁnite range δE rather
than constraining it precisely, and one must then check to be sure that the results of the analysis are
independent of δE.
222
Chapter 5. Statistical Thermodynamics

and this equation can then be inverted to give the total energy in terms of the entropy
and the other extensive variables:
E = E(S, N, V ).
(5.2)
We call the energy E, viewed as a function of S, N, and V , the fundamental thermo-
energy as fundamental
thermodynamic potential
for microcanonical
ensemble
dynamic potential for the microcanonical ensemble. When using this fundamental
potential, we regard S, N, and V as our complete set of extensive variables rather
than E, N, and V . From the fundamental potential, as we shall see, one can deduce
all other thermodynamic properties of the system.
5.2.3
5.2.3 Intensive Variables Identiﬁed Using Measuring Devices;
First Law of Thermodynamics
TEMPERATURE
In Sec. 4.4.1, we used kinetic-theory considerations to identify the thermodynamic
temperature T of the canonical ensemble [Eq. (4.20)]. It is instructive to discuss
how this temperature arises in the microcanonical ensemble. Our discussion makes
idealized thermometer
use of an idealized thermometer consisting of an idealized atom that has only two
quantum states, |0⟩and |1⟩, with energies E0 and E1 = E0 + E. The atom, initially
in its ground state, is brought into thermal contact with one of the large systems of
our microcanonical ensemble and then monitored over time as it is stochastically
excited and deexcited. The ergodic hypothesis (Sec. 4.6) guarantees that the atom
traces out a history of excitation and deexcitation that is governed statistically by the
canonical ensemble for a collection of such atoms exchanging energy (heat) with our
large system (the heat bath). More speciﬁcally, if T is the (unknown) temperature of
our system, then the fraction of time the atom spends in its excited state, divided by
thefractionspentinitsgroundstate, isequaltothecanonicaldistribution’sprobability
ratio:
ρ1
ρ0
= e−E1/(kBT )
e−E0/(kBT ) = e−E/(kBT )
(5.3a)
[cf. Eq. (4.20)].
This ratio can also be computed from the properties of the full system augmented
by the two-state atom. This augmented system is microcanonical with a total energy
E + E0, sincetheatomwasinthegroundstatewhenﬁrstattachedtothefullsystem.Of
all the quantum states available to this augmented system, the ones in which the atom
is in the ground state constitute a total number N0 = eS(E,N ,V )/kB; and those with
the atom in the excited state constitute a total number N1 = eS(E−E,N ,V )/kB. Here
we have used the fact that the number of states available to the augmented system is
equal to that of the original, huge system with energy E or E −E (since the atom,
in each of the two cases, is forced to be in a unique state), and we have expressed
that number of states of the original system, for each of the two cases, in terms of the
original system’s entropy function [Eq. (5.1)]. The ratio of the number of states N1/N0
is (by the ergodic hypothesis) the ratio of the time that the augmented system spends
5.2 Microcanonical Ensemble and the Energy Representation of Thermodynamics
223

with the atom excited to the time spent with the atom in its ground state (i.e., it is
equal to ρ1/ρ0):
ρ1
ρ0
= N1
N0
= eS(E−E,N ,V )/kB
eS(E,N ,V )/kB
= exp

−E
kB
∂S
∂E

N ,V

.
(5.3b)
By equating Eqs. (5.3a) and (5.3b), we obtain an expression for the original system’s
temperature T in terms of the partial derivative (∂E/∂S)N ,V of its fundamental
potential E(S, N, V ):
temperature from energy
potential E(S, N, V )
E(S, N, V )
E(S, N, V )
T =
1
(∂S/∂E)N ,V
=
∂E
∂S

N ,V
,
(5.3c)
where we have used Eq. (3) of Box 5.2.
CHEMICAL POTENTIAL AND PRESSURE
A similar thought experiment—using a highly idealized measuring device that can
exchange one particle (N = 1) with the system but cannot exchange any energy with
it—gives for the fraction of the time spent with the extra particle in the measuring
device (“state 1”) and in the system (“state 0”):
ρ1
ρ0
= e ˜μN/kBT
= eS(E,N−N ,V )/kB
eS(E,N ,V )/kB
= exp

−N
kB
 ∂S
∂N

E,V

.
(5.4a)
Here the ﬁrst expression is computed from the viewpoint of the measuring device’s
equilibrium ensemble,3 and the second from the viewpoint of the combined system’s
microcanonical ensemble. Equating these two expressions, we obtain
chemical potential from
energy potential
˜μ = −T
 ∂S
∂N

E,V
=
 ∂E
∂N

S,V
.
(5.4b)
In the last step we use Eq. (5.3c) and Eq. (4) of Box 5.2. The reader should be able
to construct a similar thought experiment involving an idealized pressure transducer
(Ex. 5.1), which yields the following expression for the system’s pressure:
pressure from energy
potential
P = −
 ∂E
∂V

S,N
.
(5.5)
FIRST LAW OF THERMODYNAMICS
Having identifed the three intensive variables T , ˜μ, and P as partial derivatives
[Eqs. (5.3c), (5.4b), and (5.5)], we now see that the fundamental potential’s differential
relation
dE(S, N, V ) =
∂E
∂S

N ,V
dS +
 ∂E
∂N

S,V
dN +
 ∂E
∂V

S,N
dV
(5.6)
3.
This ensemble has ρ = constant e−˜μN/(kBT ), since only particles can be exchanged with the device’s heat
bath (our system).
224
Chapter 5. Statistical Thermodynamics

BOX 5.2.
TWO USEFUL RELATIONS BETWEEN PARTIAL DERIVATIVES
Expand a differential increment in the energy E(S, N, V ) in terms of
differentials of its arguments S, N, and V :
dE(S, N, V ) =
∂E
∂S

N ,V
dS +
 ∂E
∂N

S,V
dN +
 ∂E
∂V

S,N
dV . (1)
Next expand the entropy S(E, N, V ) similarly, and substitute the resulting
expression for dS into the above equation to obtain
dE =
∂E
∂S

N ,V
∂S
∂E

N ,V
dE
+
'∂E
∂S

N ,V
 ∂S
∂N

E,V
+
 ∂E
∂N

S,V
(
dN
+
'∂E
∂S

N ,V
 ∂S
∂V

N ,E
+
 ∂E
∂V

S,N
(
dV .
(2)
Noting that this relation must be satisﬁed for all values of dE, dN, and dV ,
we conclude that
∂E
∂S

N ,V
=
1
(∂S/∂E)N ,V
,
(3)
 ∂E
∂N

S,V
= −
∂E
∂S

N ,V
 ∂S
∂N

E,V
,
(4)
and so forth; similarly for other pairs and triples of partial derivatives.
These equations, and their generalization to other variables, are useful in
manipulations of thermodynamic equations.
is nothing more nor less than the ordinary ﬁrst law of thermodynamics
ﬁrst law of thermo-
dynamics from energy
potential
dE = T dS + ˜μdN −P dV
(5.7)
(cf. Table 5.1 above).
Notice the pairing of intensive and extensive variables in this ﬁrst law: temperature
T is paired with entropy S; chemical potential ˜μ is paired with number of particles
N; and pressure P is paired with volume V . We can think of each intensive variable
as a “generalized force” acting on its corresponding extensive variable to change the
energy of the system. We can add additional pairs of intensive and extensive variables
if appropriate, calling them XA, YA (e.g., an externally imposed magnetic ﬁeld B and
a material’s magnetization M; Sec. 5.8). We can also generalize to a multicomponent
5.2 Microcanonical Ensemble and the Energy Representation of Thermodynamics
225

system (i.e., one that has several types of conserved particles with numbers NI and
associated chemical potentials ˜μI). We can convert to nonrelativistic language by
subtracting off the rest-mass contributions (switching from E to E ≡E −! NImIc2
and from ˜μI to μI = ˜μI −mIc2). The result is the nonrelativistic, extended ﬁrst law:
extended ﬁrst law
dE = T dS +
 
I
μIdNI −P dV +
 
A
XAdYA.
(5.8)
EXERCISES
Exercise 5.1 Problem: Pressure-Measuring Device
For the microcanonical ensemble considered in this section, derive Eq. (5.5) for the
pressure using a thought experiment involving a pressure-measuring device.
5.2.4
5.2.4 Euler’s Equation and Form of the Fundamental Potential
We can integrate the differential form of the ﬁrst law to obtain a remarkable—though
essentially trivial—relation known as Euler’s equation. We discuss this for the one-
species system whose ﬁrst law is dE = T dS + ˜μdN −P dV . The generalization to
other systems should be obvious.
We decompose our system into a large number of subsystems in equilibrium with
one another. As they are in equilibrium, they will all have the same values of the
intensive variables T , ˜μ, and P ; therefore, if we add up all their energies dE to obtain
E, their entropies dS to obtain S, and so forth, we obtain from the ﬁrst law (5.7)4
E = T S + ˜μN −P V .
(5.9a)
Since the energy E is itself extensive, Euler’s equation (5.9a) must be expressible as
Euler’s equation for energy
E = Nf (V/N, S/N)
(5.9b)
for some function f . This is a useful functional form for the fundamental potential
E(N, V , S). For example, for a nonrelativistic, classical, monatomic perfect gas,5 the
4.
There are a few (but very few!) systems for which some of the thermodynamic laws, including Euler’s
equation, take on forms different from those presented in this chapter. A black hole is an example
(cf. Sec. 4.10.2). A black hole cannot be divided up into subsystems, so the above derivation of Euler’s
equation fails. Instead of increasing linearly with the mass MH = E/c2 of the hole, the hole’s extensive
variables SH = (entropy) and JH = (spin angular momentum) increase quadratically with MH. And
instead of being independent of the hole’s mass, the intensive variables TH = (temperature) and H =
(angular velocity) scale as 1/MH. See, e.g., Tranah and Landsberg (1980) and see Sec. 4.10.2 for some
other aspects of black-hole thermodynamics.
5.
Recall (Ex. 4.6) that a perfect gas is one that is ideal (i.e., has negligible interactions among its particles)
and whose particles have no excited internal degrees of freedom. The phrase “perfect gas” must not be
confused with “perfect ﬂuid” (a ﬂuid whose viscosity is negligible so its stress tensor, in its rest frame,
consists solely of an isotropic pressure).
226
Chapter 5. Statistical Thermodynamics

Sackur-Tetrode equation (4.42) can be solved for E = E −Nmc2 to get the following
form of the fundamental potential:
energy potential for
nonrelativistic, classical,
perfect gas
E(V , S, N) = N
*
3h2
4πmg2/3
s
+ V
N
−2/3
exp
 2
3kB
S
N −5
3

.
(5.9c)
Here m is the mass of each of the gas’s particles, and h is Planck’s constant.
5.2.5
5.2.5 Everything Deducible from First Law; Maxwell Relations
There is no need to memorize a lot of thermodynamic relations; nearly all relations can
be deduced almost trivially from the functional form of the ﬁrst law of thermodynamics,
the main formula shown on the ﬁrst line of Table 5.1.
For example, in the case of our simple one-species system, the ﬁrst law dE =
T dS + ˜μdN −PdV tellsusthatthesystemenergyE shouldberegardedasafunction
of the things that appear as differentials on the right-hand side: S, N, and V ; that is,
the fundamental potential must have the form E = E(S, N, V ). By thinking about
building up our system from smaller systems by adding entropy dS, particles dN,
and volume dV at ﬁxed values of the intensive variables, we immediately deduce, from
the ﬁrst law, the Euler equation E = T S + ˜μN −P V . By writing out the differential
relation (5.6)—which is just elementary calculus—and comparing with the ﬁrst law,
we immediately read off the intensive variables in terms of partial derivatives of the
fundamental potential:
T =
∂E
∂S

V ,N
,
˜μ =
 ∂E
∂N

V ,S
,
P = −
 ∂E
∂V

S,N
.
(5.10a)
We can then go on to notice that the resulting P (V , S, N), T (V , S, N), and
˜μ(V , S, N) are not all independent. The equality of mixed partial derivatives (e.g.,
∂2E/∂V ∂S = ∂2E/∂S∂V ) together with Eqs. (5.10a) implies that they must satisfy
the following Maxwell relations:
 ∂T
∂N

S,V
=
∂˜μ
∂S

N ,V
,
−
∂P
∂S

V ,N
=
∂T
∂V

S,N
,
 ∂˜μ
∂V

N ,S
= −
∂P
∂N

V ,S
.
(5.10b)
Additional relations can be generated using the types of identities proved in Box 5.2—
Maxwell relations from
energy potential
or they can be generated more easily by applying the above procedure to the funda-
mental potentials associated with other ensembles; see Secs. 5.3–5.5. All equations
of state [i.e., all such relations as Eqs. (5.11) between intensive and extensive vari-
ables] must satisfy the Maxwell relations. For our simple example of a nonrelativistic,
5.2 Microcanonical Ensemble and the Energy Representation of Thermodynamics
227

classical, perfect gas, we can substitute the fundamental potential E [Eq. (5.9c)] into
Eqs. (5.10a) to obtain
T (V , S, N) =
*
h2
2πmkBg2/3
s
+ N
V
2/3
exp
 2S
3kBN −5
3

,
μ(V , S, N) =
*
h2
4πmg2/3
s
+ N
V
2/3 
5 −2 S
kBN

exp
 2S
3kBN −5
3

P(V , S, N) =
*
h2
2πmg2/3
s
+ N
V
5/3
exp
 2S
3kBN −5
3

,
(5.11)
(Ex. 5.2). These clearly do satisfy the Maxwell relations.
EXERCISES
Exercise 5.2 Derivation: Energy Representation for a Nonrelativistic,
Classical, Perfect Gas
(a) Use the fundamental potential E(V , S, N) for the nonrelativistic, classical, per-
fect gas [Eq. (5.9c)] to derive Eqs. (5.11) for the gas pressure, temperature, and
chemical potential.
(b) Show that these equations of state satisfy Maxwell relations (5.10b).
(c) Combine these equations of state to obtain the ideal-gas equation of state
P = N
V kBT ,
(5.12)
which we derived in Ex. 3.8 using kinetic theory.
5.2.6
5.2.6 Representations of Thermodynamics
The treatment of thermodynamics given in this section is called the energy representa-
tion,because it is based on the fundamental potential E(S, V , N) in which the energy
is expressed as a function of the complete set of extensive variables {S, V , N}. As we
have seen, this energy representation is intimately related to the microcanonical en-
semble. In Sec. 5.3, we meet the grand-potential representation for thermodynamics,
whichisintimatelyrelatedtothegrandcanonicalensembleforsystemsofvolumeV in
equilibrium with a heat and particle bath that has temperature T and chemical poten-
tial ˜μ. Then in Secs. 5.4 and 5.5, we meet the two representations of thermodynamics
that are intimately related to the canonical and Gibbs ensembles, and discover their
power to handle certain special issues. And in Ex. 5.5, we consider a representation
and ensemble based on enthalpy. These ﬁve representations and their ensembles are
summarized in Table 5.1 above.
228
Chapter 5. Statistical Thermodynamics

5.3
5.3 Grand Canonical Ensemble and the Grand-Potential
Representation of Thermodynamics
We now turn to the grand canonical ensemble, and its grand-potential representation
of thermodynamics, for a semiclosed system that exchanges heat and particles with
a thermalized bath. For simplicity, we assume that all particles are identical (just one
particle species), but we allow them to be relativistic (speeds comparable to the speed
of light) or not and allow them to have nontrivial internal degrees of freedom (e.g.,
vibrations and rotations; Sec. 5.4.2), and allow them to exert forces on one another
via an interaction potential that appears in their hamiltonian (e.g., van der Waals
forces; Secs. 5.3.2 and 5.7). We refer to these particles as a gas, though our analysis is
more general than gases. The nonrelativistic limit of all our fundamental equations is
trivially obtained by removing particle rest masses from the energy (E gets replaced
by E = E −mc2) and from the chemical potential ( ˜μ gets replaced by μ = ˜μ −mc2),
but not from the grand potential, as it never has rest masses in it [see, e.g., Eq. (5.18)
below].
We begin in Sec. 5.3.1 by deducing the grand potential representation of thermo-
dynamics from the grand canonical ensemble, and by deducing a method for com-
puting the thermodynamic properties of our gas from a grand canonical sum over
the quantum states available to the system. In Ex. 5.3, the reader will apply this grand
canonical formalism to a relativistic perfect gas. In Sec. 5.3.2, we apply the formal-
ism to a nonrelativistic gas of particles that interact via van der Waals forces, thereby
deriving the van der Waals equation of state, which is surprisingly accurate for many
nonionized gases.
5.3.1
5.3.1 The Grand-Potential Representation, and Computation
of Thermodynamic Properties as a Grand Canonical Sum
Figure 5.1 illustrates the ensemble of systems that we are studying and its bath. Each
system is a cell of ﬁxed volume V , with imaginary walls, inside a huge thermal bath of
identical particles. Since the cells’ walls are imaginary, the cells can and do exchange
energy and particles with the bath. The bath is characterized by chemical potential ˜μ
for these particles and by temperature T . Since we allow the particles to be relativistic,
we include the rest mass in the chemical potential ˜μ.
We presume that our ensemble of cells has reached statistical equilibrium with the
bath, so its probabilistic distribution function has the grand canonical form (4.25c):
grand canonical
distribution function
ρn = 1
Z exp
−En + ˜μNn
kBT

= exp
 −En + ˜μNn
kBT

.
(5.13)
Here the index n labels the quantum state |n⟩of a cell, Nn is the number of particles in
that quantum state, En is the total energy of that quantum state (including each parti-
cle’s rest mass; its energy of translational motion; its internal energy if it has internal
vibrations, rotations, or other internal excitations; and its energy of interaction with
5.3 Grand Canonical Ensemble and the Grand-Potential Representation of Thermodynamics
229

FIGURE 5.1 An ensemble of cells, each with volume V and imaginary walls, inside a heat and particle
bath.
other particles), and 1/Z ≡e/(kBT ) is the normalization constant that guarantees
!
n ρn = 1:
grand partition function
and grand potential
Z ≡exp
 −
kBT

≡
 
n
exp
−En + ˜μNn
kBT

.
(5.14)
This normalization constant, whether embodied in Z or in , is a function of the
bath’s temperature T and chemical potential ˜μ, and also of the cells’ common volume
V (which inﬂuences the set of available states |n⟩). When regarded as a function of
T , ˜μ, and V , the quantity Z(V , ˜μ, T ) is called the gas’s grand partition function, and
(T , ˜μ, V ) is called its grand potential. The following general argument shows that
once one has computed the explicit functional form for the grand potential
(V , ˜μ, T )
(5.15)
[or for the grand partition function Z(V , ˜μ, T )], one can then derive from it all the
thermodynamic properties of the thermally equilibrated system. The argument is so
general that it applies to every grand canonical ensemble of systems, not just to our
chosen gas of identical particles.
As key quantities in the argument, we introduce the mean energy and mean
number of particles in the ensemble’s systems (i.e., cells of Fig. 5.1):
E ≡
 
n
ρnEn,
N ≡
 
n
ρnNn.
(5.16)
(We denote these quantities with bars E rather than brackets ⟨E⟩for ease of notation.)
Inserting expression (5.13) for ρn into the log term in the deﬁnition of entropy
S = −kB
!
n ρn ln ρn and using Eqs. (5.16), we obtain
S = −kB
 
n
ρn ln ρn = −kB
 
n
ρn
 −En + ˜μNn
kBT

= − −E + ˜μN
T
;
(5.17)
or, equivalently,
Legendre transformation
between thermodynamic
representations
 = E −T S −˜μN.
(5.18)
230
Chapter 5. Statistical Thermodynamics

This can be regarded as a Legendre transformation that leads from the energy rep-
resentation of thermodynamics to the grand-potential representation. Legendre
transformations are a common tool, for example, in classical mechanics (e.g., Landau
and Lifshitz, 1976; Marion and Thornton, 1995; Goldstein, Poole, and Safko, 2002),
for switching from one set of independent variables to another. Note that remov-
ing rest masses from E = ¯E + Nmc2 and from ˜μ = μ + mc2 to get a nonrelativistic
formula leaves  unchanged.
Wenowaskhowthegrandpotentialwillchangeifthetemperature T andchemical
potential ˜μ of the bath (and therefore of the ensemble) are slowly altered, and the
volumes V of all the ensemble’s boxes are slowly altered. Differentiating Eq. (5.18),
we obtain d = dE −T dS −SdT −˜μdN −Nd ˜μ. Expressing dE in terms of the
energy representation’s ﬁrst law of thermodynamics (5.7) (with E replaced by E and
N replaced by N), we bring this expression into the form
ﬁrst law in grand potential
representation
d = −PdV −Nd ˜μ −SdT .
(5.19)
This is the grand-potential representation of the ﬁrst law of thermodynamics.
The quantities P, N, and S paired with the independent variables V , ˜μ, and T ,
respectively, can be thought of as generalized forces that push on the independent
generalized forces
variables as they change, to produce changes in the grand potential.
From this version of the ﬁrst law (the key grand canonical equation listed in the
last line of Table 5.1), we can easily deduce almost all other equations of the grand-
potential representation of thermodynamics. We just follow the same procedure as
we used for the energy representation (Sec. 5.2.5).
The grand-potential representation’s complete set of independent variables con-
sists of those that appear as differentials on the right-hand side of the ﬁrst law (5.19):
V , ˜μ, and T . From the form (5.19) of the ﬁrst law we see that  is being regarded as
a function of these three independent variables:  = (V , ˜μ, T ). This is the funda-
mental potential.
Euler equation for grand
potential
The Euler equation of this representation is deduced by building up a system from
small pieces that all have the same values of the intensive variables ˜μ, T , and P . The
ﬁrst law (5.19) tells us that this buildup will produce
 = −P V .
(5.20)
Thus, if we happen to know P as a function of this representation’s independent
intensive variables—P( ˜μ, T ) (it must be independent of the extensive variable V )—
then we can simply multiply by V to get the functional form of the grand potential:
(V , ˜μ, T ) = P( ˜μ, T )V ; see Eqs. (5.24a) and (5.25) as a concrete example.
By comparing the grand-potential version of the ﬁrst law (5.19) with the elemen-
tary calculus equation d = (∂/∂V )dV + (∂/∂˜μ)d ˜μ + (∂/∂T )dT , we infer
5.3 Grand Canonical Ensemble and the Grand-Potential Representation of Thermodynamics
231

equations for the system’s “generalized forces,” the pressure P , mean number of par-
ticles N, and entropy S:
N = −
∂
∂˜μ

V ,T
,
S = −
∂
∂T

V , ˜μ
,
P = −
∂
∂V

˜μ,T
.
(5.21)
Bydifferentiatingtheserelationsandequatingmixedpartialderivatives, wecanderive
Maxwell relations from
grand potential
Maxwell relations analogous to those [Eqs. (5.10b)] of the energy representation; for
example, (∂N/∂T )V , ˜μ = (∂S/∂˜μ)V ,T . Equations of state are constrained by these
Maxwell relations.
If we had begun with a speciﬁc functional form of the grand potential as a func-
tion of this representation’s complete set of independent variables (V , T , ˜μ) [e.g.,
Eq. (5.24a) below], then Eqs. (5.21) would give us the functional forms of almost
all the other dependent thermodynamic variables. The only one we are missing is
the mean energy E(V , ˜μ, T ) in a cell. If we have forgotten Eq. (5.18) (the Legendre
transformation) for that quantity, we can easily rederive it from the grand canon-
ical distribution function ρ = exp[( −E + ˜μN)/(kBT )] (the other key equation,
besides the ﬁrst law, on the last line of Table 5.1), via the deﬁnition of entropy as
S = −kB
!
n ρn ln ρn = −kBln ρ, as we did in Eq. (5.17).
This illustrates the power of the sparse information in Table 5.1. From it and
little else we can deduce all the thermodynamic equations for each representation
of thermodynamics.
It should be easy to convince oneself that the nonrelativistic versions of all the above
equations in this section can be obtained by the simple replacements E →E (removal
of rest masses from total energy) and ˜μ →μ (removal of rest mass from chemical
potential).
5.3.2
5.3.2 Nonrelativistic van der Waals Gas
computing the grand
potential from a statistical
sum
The statistical sum Z ≡e−/(kBT ) = !
n e(−En+ ˜μNn)/(kBT ) [Eq. (5.14)] is a powerful
method for computing the grand potential (V , ˜μ, T ), a method often used in
condensed matter physics. Here we present a nontrivial example: a nonrelativistic,
monatomic gas made of atoms or molecules (we call them “particles”) that interact
with so-called “van der Waals forces.” In Ex. 5.3, the reader will explore a simpler
example: a relativistic, perfect gas.
We assume that the heat and particle bath that bathes the cells of Fig. 5.1 has
(i) sufﬁciently low temperature that the gas’s particles are not ionized (therefore they
are also nonrelativistic, kBT ≪mc2) and (ii) sufﬁciently low chemical potential that
the mean occupation number η of the particles’ quantum states is small compared to
unity, so they behave classically, μ ≡˜μ −mc2 ≪−kBT [Eq. (3.22d)].
The orbital electron clouds attached to each particle repel one another when the
distance r between the particles’ centers of mass is smaller than about the diameter
ro of the particles. At larger separations, the particles’ electric dipoles (intrinsic or
induced) attract one another weakly. The interaction energy (potential energy) u(r)
232
Chapter 5. Statistical Thermodynamics

associated with these forces has a form well approximated by the Lennard-Jones
potential
u(r) = εo
'ro
r
12
−
ro
r
6(
,
(5.22a)
where εo is a constant energy. When a gradient is taken, the ﬁrst term gives rise to the
small-r repulsive force and the second to the larger-r attractive force. For simplicity
of analytic calculations, we use the cruder approximation
approximate interaction
energy for van der Waals
gas
u(r) = ∞for r < ro,
u(r) = −εo(ro/r)6 for r > ro,
(5.22b)
which has an inﬁnitely sharp repulsion at r = ro (a hard wall). For simplicity, we
assumethatthemeaninterparticleseparationismuchlargerthanro (dilutegas), soitis
highly unlikely that three or more particles are close enough together simultaneously,
r ∼ro, to interact (i.e., we conﬁne ourselves to two-particle interactions).6
We compute the grand potential (V , μ, T ) for an ensemble of cells embedded
in a bath of these particles (Fig. 5.1), and from (V , μ, T ) we compute how the
particles’ interaction energy u(r) alters the gas’s equation of state from the form
P = (N/V )kBT for an ideal gas [Eqs. (3.39b,c)]. Since this is our objective, any
internal and spin degrees of freedom that the particles might have are irrelevant, and
we ignore them.
For
this
ensemble,
the
nonrelativistic
grand
partition
function
Z =
!
n exp[(−En + μNn)/(kBT )]is
Z = e−/(kBT )
=
∞
 
N=0
eμN/(kBT )
N!
 d3Nxd3Np
h3N
exp
⎡
⎣−
N
 
i=1
p2
i
2mkBT −
N
 
i=1
N
 
j=i+1
uij
kBT
⎤
⎦.
(5.23a)
Here we have used Eq. (4.8b) for the sum over states !
n [with M = N! (the multi-
plicity factor of Eqs. (4.8)), W = 3N, and dW = d3Nxd3Np; cf. Ex. 5.3], and we have
written En as the sum over the kinetic energies of the N particles in the cell and the
interaction energies
uij ≡u(rij),
rij ≡|xi −xj|
(5.23b)
of the 1
2N(N −1) pairs of particles.
Evaluation of the integrals and sum in Eq. (5.23a), with the particles’ interaction
energies given by Eqs. (5.23b) and (5.22b), is a rather complex task, which we relegate
totheTrack-TwoBox5.3.Theresultforthegrandpotential,  = −kBT ln Z, accurate
6.
Finding effective ways to tackle many-body problems is a major challenge in many areas of modern
theoretical physics.
5.3 Grand Canonical Ensemble and the Grand-Potential Representation of Thermodynamics
233

to ﬁrst order in the particles’ interactions (in the parameters a and b below), is
van der Waals grand
potential
 = −kBT V (2πmkBT )3/2
h3
eμ/(kBT )

1 + (2πmkBT )3/2
h3
eμ/(kBT )
 a
kBT −b

.
(5.24a)
Here b is four times the volume of each hard-sphere particle, and a is that volume
times the interaction energy εo of two hard-sphere particles when they are touching:
b = 16π
3
ro
2
3
,
a = bεo.
(5.24b)
By differentiating this grand potential, we obtain the following expressions for the
pressure P and mean number of particles N in a volume-V cell:
P = −
∂
∂V

μ,T
= kBT (2πmkBT )3/2
h3
eμ/(kBT )

1 + (2πmkBT )3/2
h3
eμ/(kBT )
 a
kBT −b

,
N = −
∂
∂μ

V ,T
= V (2πmkBT )3/2
h3
eμ/(kBT )

1 + 2(2πmkBT )3/2
h3
eμ/(kBT )
 a
kBT −b

.
(5.25)
Notice that, when the interaction energy is turned off so a = b = 0, the second equa-
van der Waals equation of
state
tiongivesthestandardideal-gasparticledensity N/V = (2πmkBT )3/2eμ/(kBT )/h3 =
ζ/λT dB3 where ζ and λT dB are deﬁned in Eq. (2) of Box 5.3. Inserting this into the
square bracketed expression in Eqs. (5.25), taking the ratio of expressions (5.25) and
multiplying by V and expanding to ﬁrst order in a/(kBT ) −b, we obtain P V/N =
kBT [1 + (N/V )(b −a/(kBT ))]—accurate to ﬁrst order in (b −a/(kBT )). Bring-
ing the a term to the left-hand side, multiplying both sides by [1 −(N/V )b], and
linearizing in b, we obtain the standard van der Waals equation of state:
*
P +
a
(V/N)2
+
(V/N −b) = kBT .
(5.26)
The quantity V/N is the speciﬁc volume (volume per particle).
A few comments are in order.
1. The factor (V/N −b) in the equation of state corresponds to an excluded
volume b = (16π/3)(ro/2)3 that is four times larger than the actual volume
of each hard-sphere particle (whose radius is ro/2).
2. The term linear in a, P = −aN/V = −bεoN/V, is a pressure reduction due
to the attractive force between particles.
234
Chapter 5. Statistical Thermodynamics

BOX 5.3.
DERIVATION OF VAN DER WAALS GRAND
POTENTIAL
In Eq. (5.23a) the momentum integrals and the space integrals separate, and
the N momentum integrals are identical, so Z takes the form
Z =
∞
 
N=0
eμN/(kBT )
N! h3N
 ∞
0
4πp2dp exp
 −p2
2mkBT
N
JN
=
∞
 
N=0
(ζ/λT dB3)N
N!
JN,
(1)
where
ζ ≡eμ/(kBT ),
λT dB ≡
h
(2πmkBT )1/2 ,
JN =

d3Nx exp
⎡
⎣−
N
 
i=1
N
 
j=i+1
uij
kBT
⎤
⎦.
(2)
Note that λ is the particles’ thermal deBroglie wavelength. The Boltzmann
factor e−uij/(kBT ) is unity for large interparticle separations rij ≫ro, so we
write
e−uij/(kBT ) ≡1 + fij,
(3)
where fij is zero except when rij <∼ro. Using this deﬁnition and rewriting the
exponential of a sum as the products of exponentials, we bring JN into the
form
JN =

d3Nx
N
/
i=1
N
/
j=i+1
(1 + fij).
(4)
The product contains (i) terms linear in fij that represent the inﬂuence of
pairs of particles that are close enough (rij <∼ro) to interact, plus (ii) quadratic
terms, such as f14f27, that are nonzero only if particles 1 and 4 are near
each other and 2 and 7 are near each other (there are so many of these terms
that we cannot neglect them!), plus (iii) quadratic terms such as f14f47 that
are nonzero only if particles 1, 4, and 7 are all within a distance ∼ro of one
another (because our gas is dilute, it turns out these three-particle terms
can be neglected), plus (iv) cubic and higher-order terms. At all orders ℓ
(linear, quadratic, cubic, quartic, etc.) for our dilute gas, we can ignore terms
that require three or more particles to be near one another, so we focus
only on terms fijfmn . . . fpq where all indices are different. Eq. (4) then
becomes
(continued)
5.3 Grand Canonical Ensemble and the Grand-Potential Representation of Thermodynamics
235

BOX 5.3.
(continued)
JN =

d3Nx[1 + (f12 + f13 + . . .)

	

n1 terms
+ (f12f34 + f13f24 + . . .)

	

n2 terms
+ (f12f34f56 + f13f24f56 + . . .)

	

n3 terms
. . .],
(5)
where nℓis the number of terms of order ℓwith all 2ℓparticles different.
Denoting
Vo ≡

f (r)4πr2dr,
(6)
and performing the integrals, we bring Eq. (5) into the form
JN =
∞
 
ℓ=0
nℓV N−ℓV ℓ
o .
(7)
At order ℓthe number of unordered sets of 2ℓparticles that are all different
is N(N −1) . . . (N −2ℓ+ 1)/ℓ!. The number of ways that these 2ℓparticles
can be assembled into unordered pairs is (2ℓ−1)(2ℓ−3)(2ℓ−5) . . . 1 ≡
(2ℓ−1)!!. Therefore, the number of terms of order ℓthat appear in Eq. (7) is
nℓ= N(N −1) . . . (N −2ℓ+ 1)
ℓ!
(2ℓ−1)!!
= N(N −1) . . . (N −2ℓ+ 1)
2ℓℓ!
.
(8)
Inserting Eqs. (7) and (8) into Eq. (1) for the partition function, we obtain
Z =
∞
 
N=0
(ζ/λ3)N
N!
[N/2]
 
ℓ=0
N(N −1) . . . (N −2ℓ+ 1)
2ℓℓ!
V N−ℓV ℓ
o ,
(9)
where [N/2]means the largest integer less than or equal to N/2. Performing
a little algebra and then reversing the order of the summations, we obtain
Z =
∞
 
ℓ=0
∞
 
N=2ℓ
1
(N −2ℓ)!
ζV
λ3
N−2ℓ1
ℓ!
ζV
λ3
ζVo
2λ3
ℓ
.
(10)
By changing the summation index from N to N′ = N −2ℓ, we decouple the
two summations. Each of the sums is equal to an exponential, giving
(continued)
236
Chapter 5. Statistical Thermodynamics

BOX 5.3.
(continued)
Z = e−/(kBT ) = exp
ζV
λ3

exp
ζV
λ3
ζVo
2λ3

= exp
ζV
λ3

1 + ζVo
2λ3

.
(11)
Therefore, the grand potential for our van der Waals gas is
 = −kBT ζV
λ3

1 + ζVo
2λ3

.
(12)
From kinetic theory [Eq. (3.39a)], we know that for an ideal gas, the mean
number density is N/V = ζ/λ3; this is also a good ﬁrst approximation for
our van der Waals gas, which differs from an ideal gas only by the weakly
perturbative interaction energy u(r). Thus ζVo/(2λ3) is equal to 1
2Vo/(mean
volume per particle), which is ≪1 by our dilute-gas assumption. If we had
kept three-particle interaction terms, such as f14f47, they would have given
rise to fractional corrections of order (ζVo/λ3)2, which are much smaller than
the leading-order fractional correction ζVo/(2λ3) that we have computed
[Eq. (12)]. The higher-order corrections are derived in statistical mechanics
textbooks, such as Pathria and Beale (2011, Chap. 10) and Kardar (2007,
Chap. 5) using a technique called the “cluster expansion.”
For the hard-wall potential (5.22b), f is −1 at r < ro, and assuming that
the temperature is high enough that εo/(kBT ) ≪1, then at r > ro, f is very
nearly −u/(kBT ) =

εo/(kBT )

(ro/r)6; therefore we have
Vo
2 ≡1
2

f (r)4πr2dr =
a
kBT −b,
where b = 2πr3
o
3
, a = bεo.
(13)
Inserting this expression for Vo/2 and Eqs. (2) for ζ and λ into Eq. (12), we
obtain Eqs. (5.24) for the grand potential of a van der Waals gas.
3. Our derivation is actually only accurate to ﬁrst order in a and b, so it does
not justify the quadratic term P = ab(N/V )2 in the equation of state (5.26).
However, that quadratic term does correspond to the behavior of real gases:
a sharp rise in pressure at high densities due to the short-distance repulsion
between particles.
We study this van der Waals equation of state in Sec. 5.7, focusing on the gas-
to-liquid phase transition that it predicts and on ﬂuctuations of thermodynamic
quantities associated with that phase transition.
5.3 Grand Canonical Ensemble and the Grand-Potential Representation of Thermodynamics
237

In this section we have presented the grand canonical analysis for a van der Waals
gas not because such a gas is important (though it is), but rather as a concrete example
of how one uses the formalism of statistical mechanics and introduces ingenious ap-
proximations to explore the behavior of realistic systems made of interacting particles.
EXERCISES
Exercise 5.3 Derivation and Example: Grand Canonical Ensemble
for a Classical, Relativistic, Perfect Gas
Consider cells that reside in a heat and particle bath of a classical, relativistic, perfect
gas (Fig. 5.1). Each cell has the same volume V and imaginary walls. Assume that the
bath’s temperature T has an arbitrary magnitude relative to the rest mass-energy mc2
of the particles (so the thermalized particles might have relativistic velocities), but
require kBT ≪−μ (so all the particles behave classically). Ignore the particles’ spin
degrees of freedom, if any. For ease of notation use geometrized units (Sec. 1.10) with
c = 1.
(a) The number of particles in a chosen cell can be anything from N = 0 to N = ∞.
Restrict attention, for the moment, to a situation in which the cell contains a
precise number of particles, N. Explain why the multiplicity is M = N! even
though the density is so low that the particles’ wave functions do not overlap,
and they are behaving classically (cf. Ex. 4.8).
(b) Still holding ﬁxed the number of particles in the cell, show that the number of
degrees of freedom W, the number density of states in phase space Nstates, and
the energy EN in the cell are
W = 3N ,
Nstates =
1
N!h3N ,
EN =
N
 
j=1
(pj
2 + m2)
1
2 ,
(5.27a)
where pj is the momentum of classical particle number j.
(c) Using Eq. (4.8b) to translate from the formal sum over states !
n to a sum over
W = 3N and an integral over phase space, show that the sum over states (5.14)
for the grand partition function becomes
Z = e−/(kBT ) =
∞
 
N=0
V N
N! h3N e ˜μN/(kBT )
' ∞
0
exp
*
−(p2 + m2)
1
2
kBT
+
4πp2dp
(N
.
(5.27b)
(d) Evaluate the momentum integral in the nonrelativistic limit kBT ≪m, and
thereby show that
(T , μ, V ) = −kBT V (2πmkBT )3/2
h3
eμ/(kBT ),
(5.28a)
whereμ = ˜μ −misthenonrelativisticchemicalpotential.Thisistheinteraction-
free limit Vo = a = b = 0 of our grand potential (5.24a) for a van der Waals gas.
238
Chapter 5. Statistical Thermodynamics

(e) Show that in the extreme relativistic limit kBT ≫m, Eq. (5.27b) gives
(T , ˜μ, V ) = −8πV (kBT )4
h3
e ˜μ/(kBT ).
(5.29)
(f) For the extreme relativistic limit use your result (5.29) for the grand potential
(V , T , ˜μ)toderivethemeannumberofparticlesN, thepressureP , theentropy
S, and the mean energy E as functions of V , ˜μ, and T . Note that for a photon gas,
because of the spin degree of freedom, the correct values of N, E, and S will be
twice as large as what you obtain in this calculation. Show that the energy density
is E/V = 3P (a relation valid for any ultrarelativistic gas); and that E/N = 3kBT
(which is higher than the 2.7011780 . . . kBT for blackbody radiation, as derived
in Ex. 3.13, because in the classical regime of η ≪1, photons don’t cluster in the
same states at low frequency; that clustering lowers the mean photon energy for
blackbody radiation).
5.4
5.4 Canonical Ensemble and the Physical-Free-Energy
Representation of Thermodynamics
In this section, we turn to an ensemble of single-species systems that can exchange
energy but nothing else with a heat bath at temperature T . The systems thus have
variable total energy E, but they all have the same, ﬁxed values of the two remaining
extensive variables N and V . We presume that the ensemble has reached statistical
equilibrium, so it is canonical with a distribution function (probability of occupying
any quantum state of energy E) given by Eq. (4.20):
canonical distribution
function
ρn = 1
ze−En/(kBT ) ≡e(F−En)/(kBT ).
(5.30)
Here, as in the grand canonical ensemble [Eq. (5.13)], we have introduced special no-
tationsforthenormalizationconstant:1/z = eF/(kBT ), wherez (thepartitionfunction)
and F (the physical free energy or Helmholtz free energy) are functions of the systems’
ﬁxed N and V and the bath temperature T . Once the systems’ quantum states |n⟩
(with ﬁxed N and V but variable E) have been identiﬁed, the functions z(T , N, V )
and F(T , N, V ) can be computed from the normalization relation !
n ρn = 1:
partition function and
physical free energy
e−F/(kBT ) ≡z(T , N, V ) =
 
n
e−En/(kBT ).
(5.31)
This canonical sum over states, like the grand canonical sum (5.14) that we used
for the van der Waals gas, is a powerful tool in statistical mechanics. As an example,
in Secs. 5.8.2 and 5.8.3 we use the canonical sum to evaluate the physical free energy
F for a model of ferromagnetism and use the resulting F to explore a ferromagnetic
phase transition.
5.4 Canonical Ensemble and the Physical-Free-Energy Representation of Thermodynamics
239

Having evaluated z(T , N, V ) [or equivalently, F(T , N, V )], one can then
proceed as follows to determine other thermodynamic properties of the ensemble’s
systems. The entropy S
can be computed from the standard expression
S = −kB
!
n ρn ln ρn = −kBln ρ, which, with Eq. (5.30) for ρn, implies S = (E −
F)/T . It is helpful to rewrite this as an equation for the physical free energy F:
Legendre transformation
F = E −T S.
(5.32)
This is the Legendre transformation that leads from the energy representation of
thermodynamics to the physical-free-energy representation.
Suppose that the canonical ensemble’s parameters T , N, and V are changed
slightly. By how much will the physical free energy change? Equation (5.32) tells us
that dF = dE −T dS −SdT .Because macroscopic thermodynamics is independent
of the statistical ensemble being studied, we can evaluate dE using the ﬁrst law
of thermodynamics (5.7) with the microcanonical exact energy E replaced by the
canonical mean energy E. The result is
ﬁrst law in physical-free-
energy representation
dF = −SdT + ˜μdN −P dV .
(5.33)
Equation (5.33) contains the same information as the ﬁrst law of thermodynamics
and can be thought of as the ﬁrst law rewritten in the physical-free-energy repre-
sentation. From this form of the ﬁrst law, we can deduce the other equations of the
physical-free-energy representation by the same procedure we used for the energy
representation in Sec. 5.2.5 and the grand-potential representation in Sec. 5.3.1.
If we have forgotten our representation’s independent variables, we read them off
the ﬁrst law (5.33); they appear as differentials on the right-hand side: T , N, and V .
The fundamental potential is the quantity that appears on the left-hand side of the
ﬁrst law: F(T , N, V ). By building up a full system from small subsystems that all
have the same intensive variables T , ˜μ, and P , we deduce from the ﬁrst law the Euler
relation for this representation:
Euler relation for physical
free energy
F = ˜μN −P V .
(5.34)
From the ﬁrst law (5.33) we read off equations of state for this representation’s gen-
eralized forces [e.g., −S = (∂F/∂T )N ,V ]. Maxwell relations can be derived from the
equality of mixed partial derivatives.
Thus, as for the energy and grand-potential representations, all the equations
of the physical-free-energy representation are easily deducible from the minimal
information in Table 5.1.
And as for those representations, the Newtonian version of this representation’s
fundamental equations (5.30)–(5.34) is obtained by simply removing rest masses from
˜μ (which becomes μ), E (which becomes E), and F (whose notation does not change).
240
Chapter 5. Statistical Thermodynamics

heat
bath
piston
gas
FIGURE 5.2 Origin of the name “physical free
energy” for F(V , T , N).
5.4.1
5.4.1 Experimental Meaning of Physical Free Energy
The name “physical free energy” for F can be understood using the idealized exper-
iment shown in Fig. 5.2. Gas is placed in a chamber, one wall of which is a piston,
and the chamber comes into thermal equilibrium with a heat bath, with which it can
exchange heat but not particles. The volume of the chamber has some initial value Vi;
and correspondingly, the gas has some initial physical free energy F(Vi, T , N). The
gas is then allowed to push the piston to the right sufﬁciently slowly for the gas to
remain always in thermal equilibrium with the heat bath, at the bath’s temperature T .
When the chamber has reached its ﬁnal volume Vf, the total work done on the piston
by the gas (i.e., the total energy extracted by the piston from this “engine”) is
Eextracted =
 Vf
Vi
−P dV .
(5.35a)
Using the ﬁrst law dF = −SdT + ˜μdN −P dV and remembering that T and N are
physical free energy
extracted in isothermal
expansion
kept constant, Eq. (5.35a) becomes
Eextracted = F(Vf , T , N) −F(Vi, T , N) ≡ F .
(5.35b)
Thus, F is the energy that is free to be extracted in an isothermal, physical expansion of
the gas.7
If the expansion had been done in a chamber that was perfectly thermally insu-
lated, so no heat could ﬂow in or out of it, then there would have been no entropy
change. Correspondingly, with S and N held ﬁxed but V changing during the expan-
sion, the natural way to analyze the expansion would have been in the energy rep-
resentation; that representation’s ﬁrst law dE = −P dV + T dS + ˜μdN would have
told us that the total energy extracted,

−P dV , was the change E of the gas’s total
energy. Such a process, which occurs without any heat ﬂow or entropy increase, is
called adiabatic. Thus, the energy E (or in the nonrelativistic regime, E) measures the
amount of energy that can be extracted from an adiabatic engine, by contrast with F,
which measures the energy extracted from an isothermal engine.
7.
More generally, the phrase “free energy” means the energy that can be extracted in a process that occurs
in contact with some sort of environment. The nature of the free energy depends on the nature of the
contact. We will meet chemical free energy in Sec. 5.5, and the free energy of a body on which a steady
force is acting in Sec. 11.6.1.
5.4 Canonical Ensemble and the Physical-Free-Energy Representation of Thermodynamics
241

5.4.2
5.4.2 Ideal Gas with Internal Degrees of Freedom
As an example of the canonical distribution, we explore the inﬂuence of internal
molecular degrees of freedom on the properties of a nonrelativistic, ideal gas.8 This
exampleiscomplementarytothevanderWaalsgasthatweanalyzedinSec.5.3.2using
the grand canonical distribution. There we assumed no internal degrees of freedom,
but we allowed each pair of particles to interact via an interaction potential u(r) that
depended on the particles’ separation r. Here, because the gas is ideal, there are no
interactions, but we allow for internal degrees of freedom—rotational, vibrational,
and electron excitations.
(We have previously studied internal degrees of freedom in Sec. 4.4.4, where we
proved the equipartition theorem for those whose generalized coordinates and/or
momenta are quadratic in the hamiltonian and are classically excited, such as the
vibrations and rotations of a diatomic molecule. Here we allow the internal degrees
of freedom to have any form whatsoever and to be arbitrarily excited or nonexcited.)
Our gas is conﬁned to a ﬁxed volume V , it has a ﬁxed number of molecules N,
it is in contact with a heat bath with temperature T , and its equilibrium distribu-
tion is therefore canonical, ρn = e(F−En)/(kBT ). The quantum states |n⟩available to
the gas can be characterized by the locations {xi, pi} in phase space of each of the
molecules i = 1, . . . , N, and by the state |Ki⟩of each molecule’s internal degrees
of freedom. Correspondingly, the partition function and physical free energy are
given by [Eq. (5.31)]
z = e−F/(kBT ) = gsN
N!
 d3Nxd3Np
h3N
 
K1,K2, ...,KN
exp
'
−
N
 
i=1
*
p2
i
2mkBT +
EKi
kBT
+(
.
(5.36a)
It is instructive to compare this with Eq. (5.23a) for the grand partition function of the
van der Waals gas. In Eq. (5.36a) there is no interaction energy uij between molecules,
no sum over N, and no eμN/(kBT ) (because N is ﬁxed and there is no particle bath).
However, we now have sums over the internal states Ki of each of the molecules
and a factor gs in the multiplicity to allow for the molecules’ gs different spin states
[cf. Eq. (4.8c)].
Because there are no interactions between molecules, the partition function can
be split up into products of independent contributions from each of the molecules.
Because there are no interactions between a molecule’s internal and translational
degrees of freedom, the partition function can be split into a product of translational
and internal terms; and because the molecules are all identical, their contributions
are all identical, leading to
z = e−F/(kBT ) = 1
N!

gs
 d3xd3p
h3
e−p2/(kBT )
N ' 
K
e−EK/(kBT )
(N
. (5.36b)
8.
See footnote 5 of this chapter on p. 226 for the meaning of “ideal gas.”
242
Chapter 5. Statistical Thermodynamics

The

d3xd3p h−3e−p2/(kBT ) integral is the same as we encountered in the grand
canonical analysis; it gives V/λ3, where λ = h/(2πmkBT )1/2 [cf. Eq. (1) in Box 5.3].
contribution of internal
states to physical free
energy of an ideal gas
The sum over internal states gives a contribution that is some function of temperature:
f (T ) ≡
 
K
e−EK/(kBT ).
(5.37)
Correspondingly [using Stirling’s approximation, N! ≃(N/e)N, to the accuracy
needed here], the physical free energy becomes
F(N, V , T ) = NkBT ln
N
e
h3/gs
(2πmkBT )3/2V

−NkBT ln[f (T )].
(5.38)
Note that because the molecules’ translational and internal degrees of freedom are de-
coupled, their contributions to the free energy are additive. We could have computed
them separately and then simply added their free energies.
Because the contribution of the internal degrees of freedom depends only on
temperature and not on volume, the ideal gas’s pressure
P = −(∂F/∂V )N ,T = (N/V )kBT
(5.39)
is unaffected by the internal degrees of freedom. By contrast, the entropy and the total
energy in the box do have internal contributions, which depend on temperature but
not on the gas’s volume and thence not on its density N/V :
S = −(∂F/∂T )N ,V = Stranslational + NkB(ln f + d ln f/d ln T ),
(5.40)
where the entropy Stranslational can straightforwardly be shown to be equivalent to the
Sackur-Tetrode formula (4.42) and
¯E = F + T S = NkBT
3
2 + d ln f
d ln T

.
(5.41)
For degrees of freedom that are classical and quadratic, the internal contribution
NkBT d ln f/d ln T gives 1
2kBT for each quadratic term in the hamiltonian, in accord
with the equipartition theorem (Sec. 4.4.4).
If there is more than one particle species present (e.g., electrons and protons at
high temperatures, so hydrogen is ionized), then the contributions of the species to
F, P , S, and E simply add, just as the contributions of internal and translational
degrees of freedom added in Eq. (5.38).
EXERCISES
Exercise 5.4 Example and Derivation: Adiabatic Index for Ideal Gas
In Part V, when studying ﬂuid dynamics, we shall encounter an adiabatic index
 ≡−
∂ln P
∂ln V

S
(5.42)
[Eq. (13.2)] that describes how the pressure P of a ﬂuid changes when it is compressed
adiabatically (i.e., compressed at ﬁxed entropy, with no heat being added or removed).
5.4 Canonical Ensemble and the Physical-Free-Energy Representation of Thermodynamics
243

Derive an expression for  for an ideal gas that may have internal degrees of freedom
(e.g., Earth’s atmosphere). More speciﬁcally, do the following.
(a) Consider a ﬂuid element (a small sample of the ﬂuid) that contains N molecules.
These molecules can be of various species; all species contribute equally to the
idealgas’spressureP = (N/V )kBT andcontributeadditivelytoitsenergy.Deﬁne
the ﬂuid element’s speciﬁc heat at ﬁxed volume to be the amount of heat T dS that
must be inserted to raise its temperature by an amount dT while the volume V
is held ﬁxed:
CV ≡T (∂S/∂T )V ,N = (∂E/∂T )V ,N.
(5.43)
Deduce the second equality from the ﬁrst law of thermodynamics. Show that in an
adiabatic expansion the temperature T drops at a rate given by CV dT = −P dV .
[Hint: Use the ﬁrst law of thermodynamics and the fact that for an ideal gas the
energy of a ﬂuid element depends only on its temperature and not on its volume
(or density); Eq. (5.41).]
(b) Combine the temperature change dT = (−P/CV )dV for an adiabatic expansion
with the equation of state P V = NkBT to obtain  = (CV + NkB)/CV .
(c) To interpret the numerator CV + NkB, imagine adding heat to a ﬂuid element
while holding its pressure ﬁxed (which requires a simultaneous volume change).
Show that in this case the ratio of heat added to temperature change is
CP ≡T (∂S/∂T )P ,N = CV + NkB.
(5.44)
Combining with part (b), conclude that the adiabatic index for an ideal gas is
given by
 = γ ≡CP/CV ,
(5.45)
a standard result in elementary thermodynamics.
Exercise 5.5 Example: The Enthalpy Representation of Thermodynamics
(a) Enthalpy H is a macroscopic thermodynamic variable deﬁned by
H ≡E + P V .
(5.46)
Show that this deﬁnition can be regarded as a Legendre transformation that
converts from the energy representation of thermodynamics with E(V , S, N)
as the fundamental potential, to an enthalpy representation with H(P , S, N) as
the fundamental potential. More speciﬁcally, show that the ﬁrst law, reexpressed
in terms of H, takes the form
dH = V dP + T dS + ˜μdN;
(5.47)
and then explain why this ﬁrst law dictates that H(P , S, N) be taken as the
fundamental potential.
244
Chapter 5. Statistical Thermodynamics

(b) For a nonrelativistic system, it is conventional to remove the particle rest masses
from the enthalpy just as one does from the energy, but by contrast with energy,
we do not change notation for the enthalpy:
Hnonrelativistic ≡Hrelativistic −Nm = E + P V .
(5.48)
What is the form of the ﬁrst law (5.47) for the nonrelativistic H?
(c) There is an equilibrium statistical mechanics ensemble associated with the en-
thalpy representation. Show that each system of this ensemble (ﬂuctuationally)
exchanges volume and energy with a surrounding pressure bath but does not ex-
change heat or particles, so the exchanged energy is solely that associated with the
exchanged volume, dE = −PdV , and the enthalpy H does not ﬂuctuate. Note
that P is the common pressure of the bath and the system.
(d) Show that this ensemble’s distribution function is ρ = e−S/kB = constant for
those states in phase space that have a speciﬁed number of particles N and a
speciﬁed enthalpy H. Why do we not need to allow for a small range δH of H,
by analogy with the small range E for the microcanonical ensemble (Sec. 4.5 and
Ex. 4.7)?
(e) What equations of state can be read off from the enthalpy ﬁrst law? What are the
Maxwell relations between these equations of state?
(f) What is the Euler equation for H in terms of a sum of products of extensive and
intensive variables?
(g) Show that the system’s enthalpy is equal to its total (relativistic) inertial mass
(multiplied by the speed of light squared); cf. Exs. 2.26 and 2.27.
(h) As another interpretation of the enthalpy, think of the system as enclosed in
an impermeable box of volume V . Inject into the box a “sample” of additional
material of the same sort as is already there. (It may be helpful to think of the
material as a gas.) The sample is to be put into the same thermodynamic state
(i.e., macrostate) as that of the box’s material (i.e., it is to be given the same val-
ues of temperature T , pressure P, and chemical potential ˜μ). Thus, the sample’s
material is indistinguishable in its thermodynamic properties from the mate-
rial already in the box, except that its extensive variables (denoted by ) are
far smaller: V/V = E/E = S/S ≪1. Perform the injection by opening
up a hole in one of the box’s walls, pushing aside the box’s material to make
a little cavity of volume V equal to that of the sample, inserting the sam-
ple into the cavity, and then closing the hole in the wall. The box now has
the same volume V as before, but its energy has changed. Show that the en-
ergy change (i.e., the energy required to create the sample and perform the
injection) is equal to the enthalpy H of the sample. Thus, enthalpy has the
physical interpretation of energy of injection at ﬁxed volume V . Equivalently, if a
sample of material is ejected from the system, the total energy that will come
5.4 Canonical Ensemble and the Physical-Free-Energy Representation of Thermodynamics
245

out (including the work done on the sample by the system during the ejec-
tion) is the sample’s enthalpy H. From this viewpoint, enthalpy is the system’s
free energy.
5.5
5.5 Gibbs Ensemble and Representation of Thermodynamics;
Phase Transitions and Chemical Reactions
Next consider systems in which the temperature T and pressure P are both being
controlled by an external environment (bath) and thus are treated as independent
variables in the fundamental potential. This is the situation in most laboratory exper-
iments and geophysical situations and is common in elementary chemistry but not
chemical engineering.
In this case each of the systems has a ﬁxed number of particles NI for the various
independent species I, and it can exchange heat and volume with its surroundings.
(We explicitly allow for more than one particle species, because a major application of
the Gibbs representation will be to chemical reactions.) There might be a membrane
separating each system from its bath—a membrane impermeable to particles but
through which heat can pass, and with negligible surface tension so the system and
the bath can buffet each other freely, causing ﬂuctuations in the system’s volume. For
example, this is the case for a so-called “constant-pressure balloon” of the type used
to lift scientiﬁc payloads into the upper atmosphere. Usually, however, there is no
membrane between system and bath. Instead, gravity might hold the system together
because it has higher density than the bath (e.g., a liquid in a container); or solid-state
forces might hold the system together (e.g., a crystal); or we might just introduce a
conceptual, imaginary boundary around the system of interest—one that comoves
with some set of particles.
The equilibrium ensemble for this type of system is that of Gibbs, with distribution
function
ρn = eG/(kBT )e−(En+PVn)/(kBT )
(5.49)
[Eq. (4.25b), to which we have added the normalization constant eG/(kBT )]. As for
the canonical and grand canonical distributions, the quantity G in the normalization
constant becomes the fundamental potential for the Gibbs representation of thermo-
dynamics. It is called the Gibbs potential, and also, sometimes, the Gibbs free energy
or chemical free energy (see Ex. 5.6). It is a function of the systems’ ﬁxed numbers
of particles NI and of the bath’s temperature T and pressure P, which appear in the
Gibbs distribution function: G = G(NI , T , P ).
Gibbs potential as sum
over states
The Gibbs potential can be evaluated by a sum over quantum states that follows
from !
n ρn = 1:
e−G/(kBT ) =
 
n
e−(En+PVn)/(kBT ).
(5.50)
246
Chapter 5. Statistical Thermodynamics

See Ex. 5.7 for an example. This sum has proved to be less useful than the canonical
and grand canonical sums, so in most statistical mechanics textbooks there is little or
no discussion of the Gibbs ensemble. By contrast, the Gibbs representation of thermo-
dynamics is extremely useful, as we shall see, so textbooks pay a lot of attention to it.
We can deduce the equations of the Gibbs representation by the same method as
we used for the canonical and grand canonical representations. We begin by writ-
ing down a Legendre transformation that takes us from the energy representation
to the Gibbs representation. As for the canonical and grand canonical cases, that
Legendre transformation can be inferred from the equilibrium ensemble’s entropy,
S = −kBln ρ = −(G −E −P ¯V )/T [cf. Eq. (5.49) for ρ]. Solving for G, we get
Legendre transformation
G = E + P ¯V −T S.
(5.51)
Once we are in the thermodynamic domain (as opposed to statistical mechanics),
we can abandon the distinction between expectation values of quantities and ﬁxed
values; that is, we can remove the bars and write this Legendre transformation as
G = E + PV −T S.
Differentiating this Legendre transformation and combining with the energy rep-
resentation’s ﬁrst law (5.8), we obtain the ﬁrst law in the Gibbs representation:
ﬁrst law in Gibbs
representation
dG = V dP −SdT +
 
I
˜μIdNI.
(5.52)
From this ﬁrst law we read out the independent variables of the Gibbs representation,
namely {P , T , NI} (in case we have forgotten them!), and the values of its generalized
forces [equations of state; e.g., V = (∂G/∂P )T ,NI]. From the equality of mixed partial
derivatives, we read off the Maxwell relations. By imagining building up a large system
from many tiny subsystems (all with the same, ﬁxed, intensive variables P , T , and ˜μI)
and applying the ﬁrst law (5.52) to this buildup, we obtain the Euler relation
Euler relation for Gibbs
potential
G =
 
I
˜μINI.
(5.53)
This Euler relation will be very useful in Sec. 5.5.3, when we discuss chemical
reactions.
As with previous representations of thermodynamics, to obtain the Newtonian
version of all of this section’s equations, we simply remove the particle rest masses
from ˜μI (which then becomes μI), from E (which then becomes E), and from G
(which does not change notation).
EXERCISES
Exercise 5.6 Problem: Gibbs Potential Interpreted as Chemical Free Energy
In Sec. 5.4.1, we explained the experimental meaning of the free energy F for a system
5.5 Gibbs Ensemble and Representation of Thermodynamics
247

in contact with a heat bath so its temperature is held constant, and in Ex. 5.5h we did
the same for contact with a pressure bath. By combining these, give an experimental
interpretation of the Gibbs potential G as the free energy for a system in contact with
a heat and pressure bath—the “chemical free energy.”
Exercise 5.7 Problem and Practice: Ideal Gas Equation of State from Gibbs Ensemble
For a nonrelativistic, classical, ideal gas (no interactions between particles), evaluate
the statistical sum (5.50) to obtain G(P , T , N), and from it deduce the standard
formula for the ideal-gas equation of state P ¯V = NkBT .
5.5.1
5.5.1 Out-of-Equilibrium Ensembles and Their Fundamental
Thermodynamic Potentials and Minimum Principles
Despite its lack of usefulness in practical computations of the Gibbs potential G, the
Gibbs ensemble plays an important conceptual role in a minimum principle for G,
which we now derive.
Consider an ensemble of systems, each of which is immersed in an identical
heat and volume bath, and assume that the ensemble begins with some arbitrary
distribution function ρn, one that is not in equilibrium with the baths. As time passes,
each system will interact with its bath and will evolve in response to that interaction.
Correspondingly, the ensemble’s distribution function ρ will evolve. At any moment
of time the ensemble’s systems will have some mean (ensemble-averaged) energy
E ≡!
n ρnEn and volume ¯V ≡!
n ρnVn, and the ensemble will have some entropy
S = −kB
!
n ρn ln ρn. From these quantities (which are well deﬁned even though
the ensemble may be very far from statistical equilibrium), we can compute a Gibbs
potential G for the ensemble. This out-of-equilibrium G is deﬁned by the analog of
the equilibrium deﬁnition (5.51),
out-of-equilibrium Gibbs
potential
G ≡E + Pb ¯V −TbS,
(5.54)
wherePb andTb arethepressureandtemperatureoftheidenticalbathswithwhichthe
ensemble’s systems are interacting.9 As the evolution proceeds, the total entropy of the
baths’ensembleplusthesystems’ensemblewillcontinuallyincrease, untilequilibrium
is reached. Suppose that during a short stretch of evolution the systems’ mean energy
changes by E, their mean volume changes by  ¯V , and the entropy of the ensemble
9.
Notice that, because the number N of particles in the system is ﬁxed (as is the bath temperature Tb), the
evolving Gibbs potential is proportional to
G
NkBTb
=
¯E
NkBTb
+
Pb ¯V
NkBTb
−
S
NkB
.
This quantity is dimensionless and generally of order unity. Note that the last term is the dimensionless
entropy per particle [Eq. (4.44) and associated discussion].
248
Chapter 5. Statistical Thermodynamics

changes by S. Then, by conservation of energy and volume, the baths’ mean energy
and volume must change by
Eb = −E,
 ¯Vb = − ¯V .
(5.55a)
Because the baths (by contrast with the systems) are in statistical equilibrium, we can
apply to them the ﬁrst law of thermodynamics for equilibrated systems:
Eb = −Pb ¯Vb + TbSb +
 
I
˜μIbNIb.
(5.55b)
SincetheNIb arenotchanging(thesystemscannotexchangeparticleswiththeirbaths)
and since the changes of bath energy and volume are given by Eqs. (5.55a), Eq. (5.55b)
tells us that the baths’ entropy changes by
Sb = −E −Pb ¯V
Tb
.
(5.55c)
Correspondingly, the sum of the baths’ entropy and the systems’ entropy changes by
the following amount, which cannot be negative:
Sb + S = −E −Pb ¯V + TbS
Tb
≥0.
(5.55d)
Becausethebaths’pressurePb andtemperatureTb arenotchanging(thesystemsareso
tiny compared to the baths that the energy and volume they exchange with the baths
cannot have any signiﬁcant effect on the baths’ intensive variables), the numerator
of expression (5.55d) is equal to the evolutionary change in the ensemble’s out-of-
equilibrium Gibbs potential (5.54):
Sb + S = −G
Tb
≥0.
(5.56)
Thus, the second law of thermodynamics for an ensemble of arbitrary systems in
minimum principle for
Gibbs potential
contact with identical heat and volume baths is equivalent to the law that the systems’
out-of-equilibrium Gibbs potential can never increase. As the evolution proceeds and
the entropy of baths plus systems continually increases, the Gibbs potential G will
be driven smaller and smaller, until ultimately, when statistical equilibrium with the
baths is reached, G will stop at its ﬁnal, minimum value.
The ergodic hypothesis implies that this minimum principle applies not only to
an ensemble of systems but also to a single, individual system when that system
is averaged over times long compared to its internal timescales τint (but times that
might be short compared to the timescale for interaction with the heat and volume
bath). The system’s time-averaged energy E and volume ¯V , and its entropy S (as
computed, e.g., by examining the temporal wandering of its state on timescales ∼τint),
combine with the bath’s temperature Tb and pressure Pb to give an out-of-equilibrium
5.5 Gibbs Ensemble and Representation of Thermodynamics
249

Gibbs potential G = E + Pb ¯V −TbS. This G evolves on times long compared to
the averaging time used to deﬁne it, and that evolution must be one of continually
decreasing G. Ultimately, when the system reaches equilibrium with the bath, G
achieves its minimum value.
extremum principles for
other thermodynamic
potentials
At this point we might ask about the other thermodynamic potentials. Not surpris-
ingly, associated with each of them is an extremum principle analogous to “minimum
G”:
1. Fortheenergypotential E(V , S, N)(Sec.5.2), onefocusesonclosedsystems
and switches to S(V , E, N). The extremum principle is then the standard
second law of thermodynamics: an ensemble of closed systems of ﬁxed E, V ,
and N always must evolve toward increasing entropy S; when it ultimately
reaches equilibrium, the ensemble will be microcanonical and will have
maximum entropy.
2. For the physical free energy (Helmholtz free energy) F(Tb, V , N) (Sec. 5.4),
one can derive, in a manner perfectly analogous to the Gibbs derivation, the
following minimum principle. For an ensemble of systems interacting with a
heatbath, theout-of-equilibriumphysicalfreeenergyF = E −TbS willalways
decrease, ultimately reaching a minimum when the ensemble reaches its ﬁnal,
equilibrium, canonical distribution.
3. The grand potential (V , Tb, ˜μb) (Sec. 5.3) satisﬁes the analogous mini-
mum principle. For an ensemble of systems interacting with a heat and particle
bath, the out-of-equilibrium grand potential  = E −˜μbN −TbS will always
decrease, ultimately reaching a minimum when the ensemble reaches its ﬁnal,
equilibrium, grand canonical distribution.
4. For the enthalpy H(Pb, S, N) (Ex. 5.5) the analogous extremum principle
is a bit more tricky (see Ex. 5.13). For an ensemble of systems interacting with
a volume bath, as for an ensemble of closed systems, the bath’s entropy remains
constant, so the systems’ entropy S will always increase, ultimately reaching a
maximum when the ensemble reaches its ﬁnal equilibrium distribution.
Table 5.2 summarizes these extremum principles. The ﬁrst column lists the quan-
tities that a system exchanges with its bath. The second column shows the out-
of-equilibrium fundamental potential for the system, which depends on the bath
variables and the system’s out-of-equilibrium distribution function ρ (shown explic-
itly) and also on whatever quantities are ﬁxed for the system (e.g., its volume V and/or
number of particles N; not shown explicitly). The third column expresses the total
entropy of system plus bath in terms of the bath’s out-of-equilibrium fundamental
potential. The fourth column expresses the second law of thermodynamics for bath
plus system in terms of the fundamental potential. We shall discuss the ﬁfth column
in Sec. 5.6, when we study ﬂuctuations away from equilibrium.
250
Chapter 5. Statistical Thermodynamics

TABLE 5.2: Descriptions of out-of-equilibrium ensembles with distribution function ρ
Quantities exchanged
Fundamental
Total entropy
Second
Fluctuational
with bath
potential
S + Sb
law
probability
None
S(ρ) with E constant
S + const
dS ≥0
∝eS/kB
Volume and energy
S(ρ) with
S + const
dS ≥0
∝eS/kB
with dE = −PbdV
H = E + PbV constant
(see Ex. 5.13)
Heat
F(Tb; ρ) = E −TbS
−F/Tb + const
dF ≤0
∝e−F/(kBTb)
Heat and volume
G(Tb, Pb; ρ) = E + Pb ¯V −TbS
−G/Tb + const
dG ≤0
∝e−G/(kBTb)
Heat and particle
(Tb, ˜μb, ρ) = E −˜μbN −TbS
−/Tb + const
d ≤0
∝e−/(kBTb)
Notes: From the distribution function ρ, one computes S = −kB
!
n ρn ln ρn, E = !
n ρnEn, ¯V = !
n ρnVn, and Nn = !
n ρnNn. The
systems of each ensemble are in contact with the bath shown in column one, and Tb, Pb, and ˜μb are the bath’s temperature, pressure,
and chemical potential, respectively. For ensembles in statistical equilibrium, see Table 5.1. As in that table, the nonrelativistic formulas
are the same as above but with the rest masses of particles removed from the chemical potentials ( ˜μ →μ) and from all fundamental
potentials except  (E →E, but no change of notation for H, F, and G).
5.5.2
5.5.2 Phase Transitions
phase transitions
The minimum principle for the Gibbs potential G is a powerful tool in understanding
phase transitions. “Phase” here refers to a speciﬁc pattern into which the atoms or
molecules of a substance organize themselves. The substance H2O has three familiar
phases: water vapor, liquid water, and solid ice. Over one range of pressure P and
temperature T , the H2Omolecules prefer to organize themselves into the vapor phase;
over another, the liquid phase; and over another, the solid ice phase. It is the Gibbs
potential that governs their preferences.
To understand this role of the Gibbs potential, consider a cup of water in a
refrigerator (and because the water molecules are highly nonrelativistic, adopt the
nonrelativistic viewpoint with the molecules’ rest masses removed from their energy
E, chemical potential μH2O, and Gibbs potential). The refrigerator’s air forms a heat
and volume bath for the water in the cup (the system). There is no membrane between
the air and the water, but none is needed. Gravity, together with the density difference
between water and air, serves to keep the water molecules in the cup and the air above
the water’s surface, for all relevant purposes.
Allow the water to reach thermal and pressure equilibrium with the refrigerator’s
air, then turn down the refrigerator’s temperature slightly and wait for the water to
reach equilibrium again, and then repeat the process. Suppose that you are clever
enough to compute from ﬁrst principles the Gibbs potentialG for the H2Oat each step
of the cooling, using two alternative assumptions: that the H2O molecules organize
themselvesintotheliquidwaterphase, andthattheyorganizethemselvesintothesolid
ice phase. Your calculations will produce curves for G as a function of the common
5.5 Gibbs Ensemble and Representation of Thermodynamics
251

G
liquid
liquid
solid
solid
Gc
Tc
T
FIGURE 5.3 The Gibbs potential G(T , P , N) for H2O as a function of temperature
T , with ﬁxed P and N, near the freezing point T = Tc = 273 K. The solid curves
correspond to the actual path traversed by the H2O if the phase transition is
allowed to proceed. The dotted curves correspond to superheated solid ice and
supercooled liquid water that are unstable against the phase transition because
their Gibbs potentials are higher than those of the other phase. Note that G tends
to decrease with increasing temperature. This is caused by the −T S term in
G = E + P V −T S.
bath and H2O temperature Tb = T at ﬁxed (atmospheric) pressure, with the shapes
shown in Fig. 5.3. At temperatures T > Tc = 273 K the liquid phase has the lower
Gibbs potential G, and at T < Tc the solid phase has the lower G. Correspondingly,
when the cup’s temperature sinks slightly below 273 K, the H2O molecules have a
statistical preference for reorganizing themselves into the solid phase. The water
freezes, forming ice.
It is a familiar fact that ice ﬂoats on water (i.e., ice is less dense than water), even
when they are both precisely at the phase-transition temperature of 273 K. Corre-
spondingly, when our sample of water freezes, its volume increases discontinuously
by some amount V ; that is, when viewed as a function of the Gibbs potential G, the
volume V of the statistically preferred phase is discontinuous at the phase-transition
point (see Fig. 5.4a). It is also a familiar fact that when water freezes, it releases heat
into its surroundings. This is why the freezing requires a moderately long time: the
solidifying water can remain at or below its freezing point and continue to solidify
only if the surroundings carry away the released heat, and the surroundings typically
cannot carry it away quickly. It takes time to conduct heat through the ice and convect
it through the water. The heat Q released during the freezing (the latent heat) and
the volume change V are related to each other in a simple way (see Ex. 5.8, which
focuses on the latent heat per unit mass q and the density change ρ instead of on
Q and V ).
ﬁrst-order phase
transitions
Phase transitions like this one, with ﬁnite volume jumps V ̸= 0 and ﬁnite latent
heat Q ̸= 0, are called ﬁrst-order. The van der Waals gas (Sec. 5.3.2) provides an
analytic model for another ﬁrst-order phase transition: that from water vapor to
liquid water; but we delay studying this model (Sec. 5.7) until we have learned about
ﬂuctuations of systems in statistical equilibrium (Sec. 5.6), which the van der Waals
gas also illustrates.
252
Chapter 5. Statistical Thermodynamics

G
liquid
solid
Gc
V
G
Gc
V
first-
order
(a)
(b)
second-
order
V
FIGURE 5.4 The changes of volume (plotted rightward) with increasing Gibbs function
(plotted upward) at ﬁxed P and N for (a) a ﬁrst-order phase transition and (b) a
second-order phase transition. The critical value of the Gibbs potential at which the
transition occurs is Gc.
Less familiar, but also important, are second-order phase transitions. In such tran-
sitions, the volumes V of the two phases are the same at the transition point, but their
second-order phase
transitions
rates of change dV/dG are different (and this is so whether one holds P ﬁxed as G
decreases, holds T ﬁxed, or holds some combination of P and T ﬁxed); see Fig. 5.4b.
Crystals provide examples of both ﬁrst-order and second-order phase transitions.
A crystal can be characterized as a 3-dimensional repetition of a unit cell, in which
ions are distributed in some ﬁxed way. For example, Fig. 5.5a shows the unit cell for
a BaTiO3 (barium titanate) crystal at relatively high temperatures. This unit cell
has a cubic symmetry. The full crystal can be regarded as made up of such cells
stacked side by side and one on another. A ﬁrst-order phase transition occurs when,
with decreasing temperature, the Gibbs potential G of some other ionic arrangement,
barium
oxygen
titanium
(a)
(b)
FIGURE 5.5 (a) The unit cell for a BaTiO3 crystal at relatively high temperatures. (b) The
displacements of the titanium and oxygen ions relative to the corners of the unit cell that occur
in this crystal with falling temperature when it undergoes its second-order phase transition.
The magnitudes of the displacements are proportional to the amount Tc −T by which the
temperature T drops below the critical temperature Tc, for small Tc −T .
5.5 Gibbs Ensemble and Representation of Thermodynamics
253

with a distinctly different unit cell, drops below the G of the original arrangement.
Then the crystal can spontaneously rearrange itself, converting from the old unit cell
to the new one with some accompanying release of heat and some discontinuous
change in volume.
BaTiO3 does not behave in this way. Rather, as the temperature falls a bit below
a critical value, the unit cell begins to elongate parallel to one of its edges (i.e., the
cell’s atoms get displaced as indicated in Fig. 5.5b). If the temperature is only a tiny
bit below critical, they are displaced by only a tiny amount. When the temperature
falls further, their displacements increase. If the temperature is raised back up above
critical, the ions return to the standard, rigidly ﬁxed positions shown in Fig. 5.5a. The
result is a discontinuity, at the critical temperature, in the rate of change of volume
dV/dG (Fig. 5.4b), but there is no discontinuous jump of volume and no latent heat.
This BaTiO3 example illustrates a frequent feature of phase transitions: when the
transition occurs (i.e., when the atoms start to move), the unit cell’s cubic symme-
try gets broken. The crystal switches discontinuously to a lower type of symmetry,
a tetragonal one in this case. Such spontaneous symmetry breaking is a common
occurrence in phase transitions not only in condensed matter physics but also in fun-
damental particle physics.
Bose-Einstein condensation of a bosonic atomic gas in a magnetic trap (Sec. 4.9)
is another example of a phase transition. As we saw in Ex. 4.13, for Bose-Einstein
condensation the speciﬁc heat of the atoms changes discontinuously (in the limit of
an arbitrarily large number of atoms) at the critical temperature; this, or often a mild
divergence of the speciﬁc heat, is characteristic of second-order phase transitions.
Ferromagnetism also exhibits a second-order phase transition, which we explore in
Secs. 5.8.3 and 5.8.4 using two powerful computational techniques: the renormaliza-
tion group and Monte Carlo methods.
EXERCISES
Exercise 5.8 Example: The Clausius-Clapeyron Equation
for Two Phases in Equilibrium with Each Other
(a) Consider H2O in contact with a heat and volume bath with temperature T and
pressure P. For certain values of T and P the H2O will be liquid water; for others,
ice; for others, water vapor—and for certain values it may be a two- or three-phase
mixture of water, ice, and/or vapor. Show, using the Gibbs potential and its Euler
equation, that, if two phases a and b are present and in equilibrium with each
other, then their chemical potentials must be equal: μa = μb. Explain why, for
any phase a, μa is a unique function of T and P . Explain why the condition
μa = μb for two phases to be present implies that the two-phase regions of the
T -P plane are lines and the three-phase regions are points (see Fig. 5.6). The
three-phase region is called the “triple point.” The volume V of the two- or three-
phase system will vary, depending on how much of each phase is present, since
the density of each phase (at ﬁxed T and P ) is different.
254
Chapter 5. Statistical Thermodynamics

P
melt
evaporate
sublimate
T
ice
vapor
water
second-
order
FIGURE 5.6 Phase diagram for H2O. The temperature of the
triple point (where the three phases meet) is 273.16 K and
has been used to deﬁne the absolute scale of temperature.
(b) Show that the slope of the ice-water interface curve in Fig. 5.6 (the “melting
curve”) is given by the Clausius-Clapeyron equation
dPmelt
dT
= qmelt
T
 ρice ρwater
ρice −ρwater

,
(5.57a)
where ρ is density (mass per unit volume), and qmelt is the latent heat per unit
mass for melting (or freezing)—the amount of heat required to melt a unit mass of
ice, or the amount released when a unit mass of water freezes. Notice that, because
ice is less dense than water, the slope of the melting curve is negative. [Hint:
Compute dP/dT by differentiating μa = μb, and then use the thermodynamic
properties of Ga = μaNa and Gb = μbNb.]
(c) Suppose that a small amount of water is put into a closed container of much
larger volume than the water. Initially there is vacuum above the water’s surface,
but as time passes some of the liquid water evaporates to establish vapor-water
equilibrium. The vapor pressure will vary with temperature in accord with the
Clausius-Clapeyron equation
dPvapor
dT
=
qevaporate
T
 ρwater ρvapor
ρwater −ρvapor

.
(5.57b)
Now suppose that a foreign gas (not water vapor) is slowly injected into the
container. Assume that this gas does not dissolve in the liquid water. Show that, as
the pressure Pgas of the foreign gas gradually increases, it does not squeeze water
vapor into the water, but rather it induces more water to vaporize:
dPvapor
dPtotal

T ﬁxed
=
ρvapor
ρwater
> 0,
(5.57c)
where Ptotal = Pvapor + Pgas.
5.5 Gibbs Ensemble and Representation of Thermodynamics
255

5.5.3
5.5.3 Chemical Reactions
A second important application of the Gibbs potential is to the study of chemical
chemical reactions
reactions. Here we generalize the term “chemical reactions,” to include any change
in the constituent particles of the material being studied, including for example the
joining of atoms to make molecules, the liberation of electrons from atoms in an
ionization process, the joining of two atomic nuclei to make a third kind of nucleus,
and the decay of a free neutron to produce an electron and a proton. In other words,
the “chemical” of chemical reactions encompasses the reactions studied by nuclear
physicists and elementary-particle physicists as well as those studied by chemists. The
Gibbs representation is the appropriate one for discussing chemical reactions, because
such reactions generally occur in an environment (“bath”) of ﬁxed temperature and
pressure, with energy and volume being supplied and removed as needed.
As a speciﬁc example, in Earth’s atmosphere, consider the breakup of two mole-
cules of water vapor to form two hydrogen molecules and one oxygen molecule:
2H2O →2H2 + O2. The inverse reaction 2H2 + O2 →2H2O also occurs in the
atmosphere,10 and it is conventional to write down the two reactions simultaneously
in the form
2H2O ↔2H2 + O2.
(5.58)
A chosen (but arbitrary) portion of the atmosphere, with idealized walls to keep all
its molecules in, can be regarded as a system. (The walls are unimportant in practice,
but are pedagogically useful.) The kinetic motions of this system’s molecules reach
and maintain statistical equilibrium, at ﬁxed temperature T and pressure P , far more
rapidly than chemical reactions can occur. Accordingly, if we view this system on
timescales short compared to that τreact for the reactions (5.58) but long compared
to the kinetic relaxation time, then we can regard the system as in partial statistical
partial statistical
equilibrium
equilibrium, with ﬁxed numbers of water molecules NH2O, hydrogen molecules NH2,
and oxygen molecules NO2, and with a Gibbs potential whose value is given by the
Euler relation (5.53):
G = ˜μH2ONH2O + ˜μH2NH2 + ˜μO2NO2.
(5.59)
(Here, even though Earth’s atmosphere is highly nonrelativistic, we include rest
masses in the chemical potentials and in the Gibbs potential; the reason will become
evident at the end of this section.)
When one views the sample over a longer timescale, t ∼τreact, one discovers
that these molecules are not inviolate; they can change into one another via the
reactions (5.58), thereby changing the value of the Gibbs potential (5.59). The changes
of G are more readily computed from the Gibbs representation of the ﬁrst law, dG =
10. In the real world these two reactions are made complicated by the need for free-electron intermediaries,
whose availability is inﬂuenced by external factors, such as ultraviolet radiation. This, however, does not
change the issues of principle discussed here.
256
Chapter 5. Statistical Thermodynamics

V dP −SdT + !
I ˜μIdNI, than from the Euler relation (5.59). Taking account of the
constancy of P and T and the fact that the reactions entail transforming two water
molecules into two hydrogen molecules and one oxygen molecule (or conversely),
so that
dNH2 = −dNH2O ,
dNO2 = −1
2dNH2O,
(5.60a)
the ﬁrst law says
dG = (2 ˜μH2O −2 ˜μH2 −˜μO2)1
2dNH2O.
(5.60b)
The reactions (5.58) proceed in both directions, but statistically there is a preference
for one direction over the other. The preferred direction, of course, is the one that
reduces the Gibbs potential (i.e., increases the entropy of the molecules and their
bath). Thus, if 2 ˜μH2O is larger than 2 ˜μH2 + ˜μO2, then water molecules preferentially
break up to form hydrogen plus oxygen; but if 2 ˜μH2O is less than 2 ˜μH2 + ˜μO2, then
oxygen and hydrogen preferentially combine to form water. As the reactions proceed,
the changing NI values produce changes in the chemical potentials ˜μI. [Recall the
intimate connection
NI = gs
(2πmIkBT )3/2
h3
eμI/(kBT )V
(5.61)
between μI = ˜μI −mIc2 and NI for a gas in the nonrelativistic regime; Eq. (3.39a).]
These changes in the NI and ˜μI values lead ultimately to a macrostate (thermody-
namic state) of minimum Gibbs potential G—a state in which the reactions (5.58)
can no longer reduce G. In this ﬁnal state of full statistical equilibrium, the dG of
expression (5.60b) must be zero. Correspondingly, the chemical potentials associated
with the reactants must balance:
2 ˜μH2O = 2 ˜μH2 + ˜μO2.
(5.62)
The above analysis shows that the “driving force” for the chemical reactions is the
combination of chemical potentials in the dG of Eq. (5.60b). Notice that this combi-
nation has coefﬁcients in front of the ˜μI terms that are identical to the coefﬁcients in
the reactions (5.58) themselves, and the equilibrium relation (5.62) also has the same
coefﬁcients as the reactions (5.60b). It is easy to convince oneself that this is true in
general. Consider any chemical reaction. Write the reaction in the form
 
j
νL
j AL
j ↔
 
j
νR
j AR
j .
(5.63)
Here the superscripts L and R denote the “left” and “right” sides of the reaction, the
Ajs are the names of the species of particle or atomic nucleus or atom or molecule
involved in the reaction, and the νjs are the number of such particles (or nuclei or
atoms or molecules) involved. Suppose that this reaction is occurring in an environ-
ment of ﬁxed temperature and pressure. Then to determine the direction in which the
5.5 Gibbs Ensemble and Representation of Thermodynamics
257

reaction preferentially goes, examine the chemical-potential sums for the two sides
of the reaction,
direction of a chemical
reaction governed by
chemical-potential sums
 
j
νL
j ˜μL
j ,
 
j
νR
j ˜μR
j .
(5.64)
The reaction will proceed from the side with the larger chemical-potential sum to
the side with the smaller; and ultimately, the reaction will bring the two sides into
equality. That ﬁnal equality is the state of full statistical equilibrium. Exercises 5.9
and 5.10 illustrate this behavior.
rationale for including
rest masses in chemical
potentials
When dealing with chemical reactions between extremely nonrelativistic mol-
ecules and atoms (e.g., water formation and destruction in Earth’s atmosphere), one
might wish to omit rest masses from the chemical potentials. If one does so, and if
one wishes to preserve the criterion that the reaction goes in the direction of decreas-
ing dG = (2μH2O −2μH2 −μO2) 1
2dNH2O [Eq. (5.60b) with tildes removed], then
one must choose as the “rest masses” to be subtracted values that do not include
chemical binding energies; that is, the rest masses must be deﬁned in such a way that
2mH2O = 2mH2 + mO2. This delicacy can be avoided by simply using the relativistic
chemical potentials. The derivation of the Saha equation (Ex. 5.10) is an example.
EXERCISES
Exercise 5.9 **Example: Electron-Positron Equilibrium at “Low” Temperatures
Consider hydrogen gas in statistical equilibrium at a temperature T ≪mec2/kB ≃
6 × 109 K. Electrons at the high-energy end of the Boltzmann energy distribution
can produce electron-positron pairs by scattering off protons:
e−+ p →e−+ p + e−+ e+.
(5.65)
(Therearemanyotherwaysofproducingpairs, butinanalyzingstatisticalequilibrium
we get all the information we need—a relation among the chemical potentials—by
considering just one way.)
(a) In statistical equilibrium, the reaction (5.65) and its inverse must proceed on
average at the same rate. What does this imply about the relative magnitudes
of the electron and positron chemical potentials ˜μ−and ˜μ+ (with rest masses
included)?
(b) Although these reactions require an e−that is relativistic in energy, almost all
the electrons and positrons will have kinetic energies of magnitude E ≡E −
mec2 ∼kBT ≪mec2, and thus they will have E ≃mec2 + p2/(2me). What are
the densities in phase space N± = dN±/(d3xd3p) for the positrons and electrons
in terms of p, ˜μ±, and T ? Explain why for a hydrogen gas we must have ˜μ−> 0
and ˜μ+ < 0.
(c) Assume that the gas is very dilute, so that η ≪1for both electrons and positrons.
Then integrate over momenta to obtain the following formula for the number
258
Chapter 5. Statistical Thermodynamics

10–30
10–25
10–20
10–15
ρ (g cm–3)
T (K)
10–10
10–5
100
105
1010
109
108
FIGURE 5.7 The temperature Tp at which electron-positron pairs form in a dilute hydrogen plasma,
plotted as a function of density ρ. This is the correct upper limit (upper dashed line in Fig. 3.7) on
the region where the plasma can be considered fully nonrelativistic. Above this curve, although T
may be ≪mec2/kB ≃6 × 109 K, a proliferation of electron-positron pairs radically changes the
properties of the plasma.
densities in physical space of electrons and positrons:
n± = 2
h3(2πmekBT )3/2 exp
 ˜μ± −mec2
kBT

.
(5.66)
In cgs units, what does the dilute-gas assumption η ≪1correspond to in terms of
n±? What region of hydrogen mass density ρ and temperature T is the dilute-gas
region?
(d) Let n be the number density of protons. Then by charge neutrality, n = n−−n+
will also be the number density of “ionization electrons” (i.e., of electrons that
have been ionized off of hydrogen). Show that the ratio of positrons (and hence
of pairs) to ionization electrons is given by
n+
n =
1
2y[y + (1 + y2)
1
2]
,
(5.67a)
where
y ≡1
4nλ3emec2/(kBT ) ,
and
λ ≡
h

2πmekBT
(5.67b)
is the thermal deBroglie wavelength of the electrons. Figure 5.7 shows the tem-
perature Tp at which, according to this formula, n+ = n (and y = 0.354), as a
function of mass density ρ ≃mprotonn. This Tp can be thought of as the tempera-
ture at which pairs form in a dilute plasma. Somewhat below Tp there are hardly
any pairs; somewhat above, the pairs are profuse.
(e) Note
that
at
low
densities
pairs
form
at
temperatures
T ∼108 K ≃
0.02mec2/kB. Explain qualitatively in terms of available phase space why the
formation temperature is so low.
Exercise 5.10 **Example: Saha Equation for Ionization Equilibrium
Consider an optically thick hydrogen gas in statistical equilibrium at temperature T .
(“Optically thick” means that photons can travel only a small distance compared to
5.5 Gibbs Ensemble and Representation of Thermodynamics
259

the size of the system before being absorbed, so they are conﬁned by the hydrogen
and kept in statistical equilibrium with it.) Among the reactions that are in statistical
equilibrium are H + γ ↔e + p (ionization and recombination of H, with the H
in its ground state) and e + p ↔e + p + γ (emission and absorption of photons
by “bremsstrahlung,” i.e., by the Coulomb-force-induced acceleration of electrons as
they ﬂy past protons). Let ˜μγ, ˜μH, ˜μe, and ˜μp be the chemical potentials including rest
masses; let mH, me, and mp be the rest masses; denote by I(≡13.6 eV) the ionization
energy of H, so that mHc2 = mec2 + mpc2 −I; denote μj ≡˜μj −mjc2; and assume
that T ≪mec2/kB ≃6 × 109 K and that the density is low enough that the electrons,
protons, and H atoms can be regarded as nondegenerate (i.e., as distinguishable,
classical particles).
(a) What relationships hold between the chemical potentials ˜μγ, ˜μH, ˜μe, and ˜μp?
(b) What are the number densities nH, ne, and np expressed in terms of T , ˜μH, ˜μe,
and ˜μp—taking account of the fact that the electron and proton both have spin
1
2, and including for H all possible electron and nuclear spin states?
(c) Derive the Saha equation for ionization equilibrium:
nenp
nH
= (2πmekBT )3/2
h3
e−I/(kBT ).
(5.68)
This equation is widely used in astrophysics and elsewhere.
5.6
5.6 Fluctuations away from Statistical Equilibrium
As we saw in Chap. 4, statistical mechanics is built on a distribution function ρ that is
equal to the probability of ﬁnding a chosen system in a quantum state at some chosen
location in the system’s phase space. For systems in statistical equilibrium, this prob-
ability is given by the microcanonical, canonical, grand canonical, Gibbs, or other
distribution, depending on the nature of the system’s interactions with its surround-
ings. Classical thermodynamics makes use of only a tiny portion of the information
in this probability distribution: the mean values of a few macroscopic parameters (en-
ergy, entropy, volume, pressure, etc.). Also contained in the distribution function, but
ignored by classical thermodynamics, is detailed information about ﬂuctuations of a
system away from its mean values.
As an example, consider a microcanonical ensemble of boxes, each with volume V
and each containing precisely N identical, nonrelativistic, classical gas particles and
containing energy (excluding rest mass) between E and E + δE, where δE ≪E.
(Remember the kludge that was necessary in Ex. 4.7). Consider a quantity y that is
not ﬁxed by the set {E, V , N}. That quantity might be discrete (e.g., the total number
260
Chapter 5. Statistical Thermodynamics

NR of particles in the right half of the box). Alternatively, it might be continuous (e.g.,
the total energy ER in the right half).
In the discrete case, the total number of quantum states that correspond to spe-
ciﬁc values of y is related to the entropy S by the standard microcanonical relation
Nstates(E, V , N; y) = exp[S(E, V , N; y)/kB]; and correspondingly, since all states
are equally probable in the microcanonical ensemble, the probability of ﬁnding a sys-
tem of the ensemble to have the speciﬁc value y is
probabilities for
ﬂuctuations in closed
systems
p(E, V , N; y) =
Nstates(E, V , N; y)
!
y Nstates(E, V , N; y) = const × exp
S(E, V , N; y)
kB

.
(5.69a)
Here the entropy S is to be computed via statistical mechanics (or, when possible, via
thermodynamics) not for the original ensemble of boxes in which y was allowed to
vary, but for an ensemble in which y is ﬁxed at a chosen value.
The continuous case (e.g., y = ER) can be converted into the discrete case by di-
viding the range of y into intervals that all have the same inﬁnitesimal width δy. Then
the probability of ﬁnding y in one of these intervals is [dp(E, V , N; y in δy)/dy]δy =
const × exp[S(E, V , N; y in δy)]. Dividing both sides by δy and absorbing δy on the
right-hand side into the constant, we obtain
dp(E, V , N; y)
dy
= const × exp
S(E, V , N; y in δy)
kB

.
(5.69b)
Obviously, if we are interested in the joint probability for a set of ys, some discrete
(e.g., y1 = NR) and some continuous (e.g., y2 = ER), that probability will be given by
dp(E, V , N; y1, y2, . . . , yr)
dyq . . . dyr
= const × exp
S(E, V , N; yj)
kB

,
(5.69c)
where we keep in mind (but now omit from our notation) the fact that continuous
variables are to be given values yj in some arbitrary but ﬁxed inﬁnitesimal range δyj.
The probability distribution (5.69c), though exact, is not terribly instructive. To
get better insight we expand S in powers of the deviations of the yj from the values ¯yj
thatmaximizetheentropy(thesewillturnoutalsotobethemeansofthedistribution).
Then for small |yj −¯yj|, Eq. (5.69c) becomes
Gaussian approximation to
ﬂuctuation probabilities
dp(E, V , N; yj)
dyq . . . dyr
= const × exp
 1
2kB
 ∂2S
∂yj∂yk

(yj −¯yj)(yk −¯yk)

.
(5.69d)
Here the second partial derivative of the entropy is to be evaluated at the maximum-
entropy location, where yj = ¯yj for all j. Expression (5.69d) is a (multidimensional)
Gaussian probability distribution for which the means are obviously ¯yj, as predicted.
(That this had to be Gaussian follows from the central limit theorem, Sec. 6.3.2.)
The last entry in the ﬁrst line of Table 5.2 summarizes the above equations: for a
closed system, the probability of some ﬂuctuation away from equilibrium is proportional
5.6 Fluctuations away from Statistical Equilibrium
261

to eS/kB, where S is the total entropy for the out-of-equilibrium ﬂuctuational macrostate
(e.g., the macrostate with NR particles in the right half of the box).
For the speciﬁc example where y1 ≡NR = (number of perfect-gas particles in
right half of box) and y2 ≡ER = (amount of energy in right half of box), we can
infer S(E, V , N; NR, ER) from the Sackur-Tetrode equation (4.42) as applied to the
two halves of the box and then added:11
S(E, V , N; ER, NR) = kBNR ln
4πm
3h2
3/2
e5/2V
2
E3/2
R
N5/2
R

+ kB(N −NR) ln
4πm
3h2
3/2
e5/2V
2
(E −ER)3/2
(N −NR)5/2

.
(5.70a)
It is straightforward to compute the values ¯ER and NR that maximize this entropy:
¯ER = E
2 ,
NR = N
2 .
(5.70b)
Thus, in agreement with intuition, the mean values of the energy and particle number
in the right half-box are equal to half of the box’s total energy and particle number. It is
alsostraightforwardtocomputefromexpression(5.70a)thesecondpartialderivatives
of the entropy with respect to ER and NR, evaluate them at ER = ¯ER and NR = NR,
and plug them into the probability distribution (5.69d) to obtain
dpNR
dER
= const × exp
−(NR −N/2)2
2(N/4)
+ −[(ER −E/2) −(E/N)(NR −N/2)]2
2(N/6)(E/N)2

.
(5.70c)
This Gaussian distribution has the following interpretation. (i) There is a correla-
tion between the energy ER and the particle number NR in the right half of the box,
as one might have expected: if there is an excess of particles in the right half, then
we must expect an excess of energy there as well. (ii) The quantity that is not corre-
lated with NR is ER −(E/N)NR, again as one might have expected. (iii) For ﬁxed
NR, dpNR/dER is Gaussian with mean ¯ER = E/2 + (E/N)(NR −N/2) and with
rms ﬂuctuation (standard deviation; square root of variance) σER = (E/N)√N/6.
(iv) After integrating over ER, we obtain
pNR = const × exp
−(NR −N/2)2
2N/4

.
(5.70d)
ThisisGaussianwithmeanNR = N/2andrmsﬂuctuationσNR = √N/4.Bycontrast,
if the right half of the box had been in equilibrium with a bath far larger than itself, NR
would have had an rms ﬂuctuation equal to the square root of its mean, σNR = √N/2
11. Note that the derivation of Eq. (4.42), as specialized to the right half of the box, requires the same kind
of inﬁnitesimal range δy2 = δER as we used to derive our ﬂuctuational probability equation (5.69d).
262
Chapter 5. Statistical Thermodynamics

(see Ex. 5.11). The fact that the companion of the right half has only the same size
as the right half, rather than being far larger, has reduced the rms ﬂuctuation of the
number of particles in the right half from √N/2 to √N/4.
Notice that the probability distributions (5.70c) and (5.70d) are exceedingly
sharply peaked about their means. Their standard deviations divided by their means
(i.e., the magnitude of their fractional ﬂuctuations) are all of order 1/

N, where
N is the mean number of particles in a system; and in realistic situations N is very
large. (For example, N is of order 1026 for a cubic meter of Earth’s atmosphere, and
thus the fractional ﬂuctuations of thermodynamic quantities are of order 10−13.) It is
this extremely sharp peaking that makes classical thermodynamics insensitive to the
choice of type of equilibrium ensemble—that is, sensitive only to means and not to
ﬂuctuations about the means.
The generalization of this example to other situations should be fairly obvious;
see Table 5.2. When a system is in some out-of-equilibrium macrostate, the total
entropy S + Sb of the system and any bath with which it may be in contact is, up
to an additive constant, either the system’s entropy S or the negative of its out-of-
equilibrium potential divided by the bath’s temperature (−F/Tb + const, −G/Tb +
const, or−/Tb + const; seecolumn3ofTable5.2).Correspondingly, theprobability
of a ﬂuctuation from statistical equilibrium to this out-of-equilibrium macrostate
probabilities for
ﬂuctuations in systems
interacting with baths
is proportional to the exponential of this quantity in units of Boltzmann’s constant
(e−S/kB, e−F/(kBTb), e−G/(kBTb), or e−/(kBTb); column 5 of Table 5.2). By expanding
the quantity in the exponential around the equilibrium state to second order in the
ﬂuctuations, one obtains a Gaussian probability distribution for the ﬂuctuations, like
Eq. (5.69d).
As examples, in Ex. 5.11 we study ﬂuctuations in the number of particles in a
cell that is immersed in a heat and particle bath, so the starting point is the out-of-
equilibrium grand potential . And in Ex. 5.12, we study temperature and volume
ﬂuctuations for a system in contact with a heat and volume bath; so the starting point
is the out-of-equilibrium Gibbs function G.
EXERCISES
Exercise 5.11 Example: Probability Distribution for the Number of Particles in a Cell
Consider a cell with volume V , like those of Fig. 5.1, that has imaginary walls and
is immersed in a bath of identical, nonrelativistic, classical perfect-gas particles with
temperature Tb and chemical potential μb. Suppose that we make a large number of
measurementsofthenumberofparticlesinthecellandthatfromthosemeasurements
we compute the probability pN for that cell to contain N particles.
(a) How widely spaced in time must the measurements be to guarantee that the mea-
sured probability distribution is the same as that computed, using the methods
of this section, from an ensemble of cells (Fig. 5.1) at a speciﬁc moment of time?
5.6 Fluctuations away from Statistical Equilibrium
263

(b) Assume that the measurements are widely enough separated for this criterion to
be satisﬁed. Show that pN is given by
pN ∝exp
−(V , Tb, μb; N)
kBTb

≡1
N!
 d3Nxd3Np
h3N
exp
−En + μbNn
kBTb

(5.71)
= 1
N!
 d3Nxd3Np
h3N
exp
⎡
⎢⎣
−
2!N
i=1 p2
i/(2m)
3
+ μbN
kBTb
⎤
⎥⎦,
where (V , Tb, μb; N) is the grand potential for the ensemble of cells, with each
cell constrained to have precisely N particles in it (cf. the last entry in Table 5.2).
(c) By evaluating Eq. (5.71) exactly and then computing the normalization constant,
show that the probability pN for the cell to contain N particles is given by the
Poisson distribution
pN = e−N(N
N/N!),
(5.72a)
where N is the mean number of particles in a cell,
N = (

2πmkBTb/h)3eμb/(kBTb)V
[Eq. (3.39a)].
(d) Show that for the Poisson distribution (5.72a), the expectation value is ⟨N⟩= N,
and the rms deviation from this is
σN ≡
4
N −N
25 1
2 = N
1
2 .
(5.72b)
(e) Show that for N −N <∼σN, this Poisson distribution is exceedingly well approx-
imated by a Gaussian with mean N and variance σN.
Exercise 5.12 Example: Fluctuations of Temperature and Volume in an Ideal Gas
Consider a gigantic container of gas made of identical particles that might or might
not interact. Regard this gas as a bath, with temperature Tb and pressure Pb. Pick out
at random a sample of the bath’s gas containing precisely N particles, with N ≫1.
Measure the volume V of the sample and the temperature T inside the sample. Then
pick another sample of N particles, and measure its V and T , and repeat over and
over again. Thereby map out a probability distribution dp/dT dV for V and T of
N-particle samples inside the bath.
264
Chapter 5. Statistical Thermodynamics

(a) Explain in detail why
dp
dT dV = const × exp

−
1
2kBTb
∂2G
∂V 2(V −¯V )2 + ∂2G
∂T 2 (T −Tb)2
+ 2 ∂2G
∂T ∂V (V −¯V )(T −Tb)

,
(5.73a)
where G(N, Tb, Pb; T , V ) = E(T , V , N) + PbV −TbS(T , V , N) is the out-of-
equilibrium Gibbs function for a sample of N particles interacting with this bath
(next-to-last line of Table 5.2), ¯V is the equilibrium volume of the sample when
its temperature and pressure are those of the bath, and the double derivatives in
Eq. (5.73a) are evaluated at the equilibrium temperature Tb and pressure Pb.
(b) Show that the derivatives, evaluated at T = Tb and V = ¯V , are given by
∂2G
∂T 2

V ,N
= CV
Tb
,
∂2G
∂V 2

T ,N
= 1
κ ,
and
 ∂2G
∂T ∂V

N
= 0,
(5.73b)
where CV is the gas sample’s speciﬁc heat at ﬁxed volume and κ is its compress-
ibility at ﬁxed temperature β, multiplied by V/P:
CV ≡
∂E
∂T

V ,N
= T
 ∂S
∂T

V ,N
,
κ ≡βV/P = −
∂V
∂P

T ,N
,
(5.73c)
both evaluated at temperature Tb and pressure Pb. [Hint: Write G = Geq + (Pb −
P )V −(Tb −T )S, where Geq is the equilibrium Gibbs function for the gas
samples.] Thereby conclude that
dp
dT dV = const × exp

−(V −¯V )2
2kBTbκ
−CV (T −Tb)2
2kBT 2
b

.
(5.73d)
(c) This probability distribution says that the temperature and volume ﬂuctuations
are uncorrelated. Is this physically reasonable? Why?
(d) What are the rms ﬂuctuations of the samples’ temperature and volume, σT and
σV ? Show that σT scales as 1/
√
N and σV as
√
N, where N is the number of
particles in the samples. Are these physically reasonable? Why?
Exercise 5.13 Example and Derivation: Evolution and Fluctuations
of a System in Contact with a Volume Bath
Exercise 5.5 explored the enthalpy representation of thermodynamics for an equilib-
rium ensemble of systems in contact with a volume bath. Here we extend that analysis
to an ensemble out of equilibrium. We denote by Pb the bath pressure.
(a) The systems exchange volume but not heat or particles with the bath. Explain
why, even though the ensemble may be far from equilibrium, any system’s volume
5.6 Fluctuations away from Statistical Equilibrium
265

changedV mustbeaccompaniedbyanenergychangedE = −PbdV .Thisimplies
thatthesystem’senthalpyH = E + PbV isconserved.Allsystemsintheensemble
are assumed to have the same enthalpy H and the same number of particles N.
(b) Usingequilibriumconsiderationsforthebath, showthatinteractionwithasystem
cannot change the bath’s entropy.
(c) Show that the ensemble will always evolve toward increasing entropy S, and
that when the ensemble ﬁnally reaches statistical equilibrium with the bath,
its distribution function will be that of the enthalpy ensemble (Table 5.1): ρ =
e−S/kB = const for all regions of phase space that have the speciﬁed particle
number N and enthalpy H.
(d) Show that ﬂuctuations away from equilibrium are described by the probability
distributions (5.69a) and (5.69c), but with the system energy E replaced by the
system enthalpy H and the system volume V replaced by the bath pressure Pb
(cf. Table 5.2).
5.7
5.7 Van der Waals Gas: Volume Fluctuations and
Gas-to-Liquid Phase Transition
The van der Waals gas studied in Sec. 5.3.2 provides a moderately realistic model
for real gases such as H2O and their condensation (phase transition) into liquids,
such as water.
The equation of state for a van der Waals gas is

P + a
v2

(v −b) = kBT
(5.74)
[Eq. (5.26)]. Here a and b are constants, and v ≡V/N is the speciﬁc volume (the
inverse of the number density of gas particles). In Fig. 5.8a we depict this equation of
state as curves (isotherms) of pressure P versus speciﬁc volume v at ﬁxed temperature
T . Note [as one can easily show from Eq. (5.74)] that there is a critical temperature
Tc = 8a/(27bkB) such that for T > Tc the isotherms are monotonic decreasing; for
T = Tc they have an inﬂection point [at v = vc ≡3b and P = Pc = a/(27b2)]; and
for T < Tc they have a maximum and a minimum.
probability for volume
ﬂuctuations in van der
Waals gas
From Eq. (5.73d), derived in Ex. 5.12, we can infer that the probability dp/dv for
ﬂuctuations of the speciﬁc volume of a portion of this gas containing N particles is
dp
dv = const × exp
N(∂P/∂v)T
2kBT
(v −¯v)2

.
(5.75)
Thisprobabilityiscontrolledbytheslope(∂P/∂v)T oftheisotherms.Wheretheslope
is negative, the volume ﬂuctuations are small; where it is positive, the ﬂuid is unstable:
itsvolumeﬂuctuationsgrow.Therefore, forT < Tc, theregionofanisothermbetween
its minimum M and its maximum X (Fig. 5.8b) is unphysical; the ﬂuid cannot exist
stably there. Evidently, at T < Tc there are two phases: one with low density (v > vX)
266
Chapter 5. Statistical Thermodynamics

P
(a)
(b)
v
P
A
b
M
X
B
C
T > Tc
T < Tc
T = Tc
v
FIGURE 5.8 (a) The van der Waals equation of state P(N, V , T ) plotted as pressure P versus speciﬁc
volume v ≡V/N at ﬁxed temperature T , for various values of T . (b) The route of a phase transition
in the van der Waals gas. The transition is a discontinuous jump from point A to point B.
is gaseous; the other with high density (v < vM < vc = 3b) is liquid. [Recall, from
comment (i) at the end of Sec. 5.3.2, that b/4 is the volume of each of the material’s
particles, so in the high-density phase the particles’ separations are not much larger
than their diameter; this is characteristic of a ﬂuid.]
Hold the temperature T ﬁxed at T < Tc, and gradually increase the density from
zero (decrease the speciﬁc volume v from inﬁnity). At low densities, the material will
be gaseous, and at high densities, it will be liquid. The phase transition from gas to
liquid involves a discontinuous jump from some point B in Fig. 5.8b to another point
A. The Gibbs potential controls the location of those points.
Since the two phases are in equilibrium with each other at A and B, their Gibbs
potential G = μN must be the same, which means their chemical potentials must
be the same, μA = μB—as, of course, must be their temperatures TA = TB (they
lie on the same isotherm). This in turn implies their pressures must be the same,
PA = P (μA, T ) = P(μB, T ) = PB. Therefore, the points A and B in Fig 5.8b are
connected by a horizontal line (the dashed line in the ﬁgure). Let us use the ﬁrst
law of thermodynamics in the Gibbs representation to compute the change in the
chemical potential μ as one moves along the isotherm from point A to point B. The
ﬁrst law says dG = −SdT + V dP + μdN. Focusing on a sample of the material
containing N particles, and noting that along the isotherm the sample has G = μN,
dN = 0, dT = 0, and V = vN, we obtain dμ = vdP . Integrating this relation along
the isotherm from A to B, we obtain
0 = μB −μA =
 B
A
dμ =
 B
A
vdP .
(5.76)
This integral is the area of the right green region in Fig. 5.8b minus the area of the left
green region. Therefore, these two areas must be equal, which tells us the location of
the points A and B that identify the two phases (liquid and gaseous) when the phase
transition occurs.
5.7 Van der Waals Gas: Volume Fluctuations and Gas-to-Liquid Phase Transition
267

Consider again volume ﬂuctuations. Where an isotherm is ﬂat, (∂P/∂v)T = 0,
large volume ﬂuctuations occur [Eq. (5.75)]. For T < Tc, the isotherm is ﬂat at the
minimumM andthemaximumX, butthesedonotoccurinNature—unlessthephase
transition is somehow delayed as one compresses or expands the material. However,
for T = Tc, the isotherm is ﬂat at its inﬂection point v = vc, P = Pc (the material’s
critical point C in Fig. 5.8a); so the volume ﬂuctuations will be very large there.
At some temperatures T and pressures P , it is possible for two phases, liquid
and gas, to exist; at other T and P , only one phase exists. The dividing line in the
T -P plane between these two regions is called a catastrophe—a term that comes from
catastrophe theory. We explore this in Ex. 7.16, after ﬁrst introducing some ideas of
catastrophe theory in the context of optics.
EXERCISES
Exercise 5.14 **Example: Out-of-Equilibrium Gibbs Potential for Water;
Surface Tension and Nucleation12
Water and its vapor (liquid and gaseous H2O) can be described moderately well
by the van der Waals model, with the parameters a = 1.52 × 10−48 J m3 and b =
5.05 × 10−29 m3 determined by ﬁtting to the measured pressure and temperature
at the critical point (inﬂection point C in Fig. 5.8a: Pc = a/(27b2) = 22.09 MPa,
Tc = 8a/(27bkB) = 647.3 K). [Note: 1 MPa is 106 Pascal; and 1 Pascal is the SI unit
of pressure, 1 kg m s−2.]
(a) For an out-of-equilibrium sample of N atoms of H2O at temperature T and
pressure P that has ﬂuctuated to a speciﬁc volume v, the van-der-Waals-modeled
Gibbs potential is
G(N, T , P; v) = N

−kBT + P v −a/v + kBT ln
2
λT dB
3/(v −b)
3
,
λT dB ≡h/

2πmkBT .
(5.77)
Verify that this Gibbs potential is minimized when v satisﬁes the van der Waals
equation of state (5.74).
(b) Plot the chemical potential μ = G/N as a function of v at room temperature,
T = 300 K, for various pressures in the vicinity of 1 atmosphere = 0.1013 MPa.
Adjust the pressure so that the two phases, liquid and gaseous, are in equilibrium
(i.e., so the two minima of the curve have the same height). [Answer: The required
pressure is about 3.6 atmospheres, and the chemical-potential curve is shown in
Fig. 5.9. If the gas is a mixture of air and H2O rather than pure H2O, then the
required pressure will be lower.]
(c) Compare the actual densities of liquid water and gaseous H2O with the predic-
tions of Fig. 5.9. They agree moderately well but not very well.
12. Exercise adapted from Sethna (2006, Ex. 11.3 and Sec. 11.3).
268
Chapter 5. Statistical Thermodynamics

–5.0
–5.1
–5.2
–5.3
–5.4
–5.5
–5.6
–28.0
–27.5
–27.0
–26.5
log10ν (m3)
liquid’s
surface layer
liquid
gas
μ (10–20 J)
–26.0
–25.5
FIGURE 5.9 The out-of-equilibrium chemical potential for a van der Waals gas, with
its parameters ﬁtted to the properties of H2O and with temperature T = 300 K and
pressure P = 3.6 atmospheres at the liquid-gas interface.
(d) Attheliquid’ssurfacethereisasurfacelayerafewmoleculesthick, inwhichtheat-
tractiveforcebetweenthewatermolecules, F = −6εor6
o/r7 = −[27/(2π2)]ab/r7
[Eqs. (5.22b) and (5.24b)], produces surface tension. This surface tension is a
force per unit length, γ , that the surface molecules on one side of any line lying
in the surface exert on the molecules on the other side (Box 16.4). Explain by a
simple physical argument why there is an energy γ A associated with this surface
tension, stored in any area A of the surface. This is a free energy at ﬁxed T , P (a
Gibbs free energy) in excess of the free energy that the surface’s water molecules
would have if they were in the bulk liquid or the bulk gas. This excess free energy
shows up in the chemical potential of Fig. 5.9, and the numbers in that ﬁgure can
be used to estimate the water’s surface tension γ . Show that γ ∼μh/v, where
h and v are the thickness and speciﬁc volume, respectively, of the surface layer,
and μ is the difference between the chemical potential in the surface layer and
in the bulk water and gas. Estimate γ using numbers from Fig. 5.9 and compare
with the measured surface tension, γ ≃0.0723 N/m at T = 300 K.
(e) In a cloud or fog, when water vapor is cooled below its equilibrium temperature
with liquid water Te, water drops try to form, that is, nucleate. However, there is
a potential barrier against nucleation due to the surface tension of an incipient
drop. If R is the drop’s radius, show that the Gibbs free energy of a droplet (the
sum of contributions from its surface layer and its interior) minus the free energy
that the droplet’s molecules will have if they remain gaseous, is
G = 4πR2γ −
4π
3 R3
 qT
vℓTe
.
(5.78)
5.7 Van der Waals Gas: Volume Fluctuations and Gas-to-Liquid Phase Transition
269

Here q is the latent heat per molecule that is released when the vapor liquiﬁes, vℓ
is the liquid’s speciﬁc volume, and T is the amount by which the temperature
has dropped below the equilibrium point Te for the two phases. Plot this G(R),
and explain why (i) there is a minimum droplet radius Rmin for nucleation to
succeed, and (ii) for the droplet to form with this minimum size, thermal ﬂuc-
tuations must put into it some excess energy, B, above statistical equilibrium.
Derive these formulas:
Rmin = 2γ Tevℓ
qT ,
B = 16πγ 3T 2
e v2
ℓ
3q2T 2
.
(5.79)
Explain why the rate at which nucleation occurs must scale as exp[−B/(kBT )],
which is generally an exceedingly small number. Show that, if the nucleation oc-
curs on a leaf or blade of grass or on the surface of a dust grain, so the drop’s
interface with the vapor is a hemisphere rather than a sphere, then the energy bar-
rier B is reduced by a factor 8, and the rate of nucleation is enormously increased.
That is why nucleation of water droplets almost always occurs on solid surfaces.
5.8
5.8 Magnetic Materials
The methods we have developed in this chapter can be applied to systems very differ-
ent from the gases and liquids studied thus far. In this section, we focus on magnetic
materials as an example, and we use this example to illustrate two powerful, modern
computational techniques: the renormalization group and Monte Carlo methods.
model for magnetic
material
We consider, for concreteness, the simplest type of magnetic material: one consist-
ing of a cubic lattice of N identical atoms, each with spin 1/2 and magnetic moment
mo. The material is immersed in a uniform external magnetic ﬁeld B, so each atom
(labeled by an index i) has two possible quantum states: one with its spin parallel to B
quantum number sisisi for
spin orientation
(quantumnumbersi = +1), theotherantiparalleltoB(si = −1).Theenergiesofthese
states are Esi = −moBsi. The atoms interact with one another’s magnetic ﬁelds with
a pairwise interaction energy Esisj that we shall make more concrete in Sec. 5.8.2 be-
low. The material’s total energy, when the atoms are in the state |n⟩= |s1, s1, . . . , sn⟩,
internal energy and
magnetization
is En −MnB, where
En =
N
 
i>j
N
 
j=1
Esisj ,
Mn = mo
N
 
j=1
sj
(5.80a)
are the material’s self-interaction energy (internal energy) and magnetization.
The atoms interact with a heat bath that has temperature T and with the external
magnetic ﬁeld B, which can be thought of as part of the bath.13 When they reach sta-
13. Arranging the electromagnetic environment to keep B ﬁxed is a choice similar to arranging the thermal
environment to keep T ﬁxed. Other choices are possible.
270
Chapter 5. Statistical Thermodynamics

tistical equilibrium with this heat and magnetic bath, the probability for the material
(all N atoms) to be in state |n⟩= |s1, s1, . . . , sn⟩is, of course,
pn = eG(N ,B,T )/(kBT )e−(En−BMn)/(kBT ).
(5.80b)
Here the ﬁrst term is the normalization constant, which depends on the number N
of atoms in the sample and the bath’s B and T , and G(N, B, T ) is the fundamental
thermodynamic potential for this system, which acts as the normalizing factor for the
probability:
Gibbs potential for
magnetic material
e−G(N ,B,T )/(kBT ) =
 
n
e−(En−BMn)/(kBT ).
(5.80c)
We have denoted this potential by G, because it is analogous to the Gibbs potential
for a gas, but with the gas’s volume Vn replaced by minus the magnetization −Mn and
the gas bath’s pressure P replaced by the material bath’s magnetic ﬁeld strength B.
Not surprisingly, the Gibbs thermodynamic formalism for this magnetic material is
essentially the same as for a gas, but with V →−M and P →B.
5.8.1
5.8.1 Paramagnetism; The Curie Law
paramagnetic material
Paramagnetic materials have sufﬁciently weak self-interaction that we can set En = 0
and focus solely on the atoms’ interaction with the external B ﬁeld. The magnetic
interaction tries to align each atom’s spin with B, while thermal ﬂuctuations try to
randomizethespins.Asaresult, thestrongerisB (atﬁxedtemperature), thelargerwill
be the mean magnetization ¯M. From Eq. (5.80b) for the spins’ probability distribution
we can compute the mean magnetization:
¯M =
 
n
pnMn = eG/(kBT )  
n
MneBMn/(kBT )
= eG/(kBT )kBT
 ∂
∂B

N ,T
 
n
eBMn/(kBT ).
(5.81a)
The last sum is equal to e−G/(kBT ) [Eq. (5.80c) with En = 0], so Eq. (5.81a) becomes
¯M = −
∂G
∂B

N ,T
.
(5.81b)
This is obviously our material’s analog of ¯V = (∂G/∂P )N ,T for a gas [which follows
from the Gibbs representation of the ﬁrst law, Eq. (5.52)].
To evaluate ¯M explicitly in terms of B, we must ﬁrst compute the Gibbs function
from the statistical sum (5.80c) with En = 0. Because the magnetization Mn in state
|n⟩= |s1, s2, . . . , sN⟩is the sum of contributions from individual atoms [Eq. (5.80a)],
this sum can be rewritten as the product of identical contributions from each of the
N atoms:
e−G/(kBT ) =
2
e−Bmo/kBT + e+Bmo/kBT 3N
=
2
2 cosh[Bmo/(kBT )]
3N
.
(5.81c)
5.8 Magnetic Materials
271

(In the second expression, the ﬁrst term is from state si = −1 and the second from
si = +1.) Taking the logarithm of both sides, we obtain
Gibbs function for
paramagnetic material
G(B, T , N) = −NkBT ln
2
2 cosh[Bmo/(kBT )]
3
.
(5.82)
Differentiating with respect to B [Eq. (5.81b)], we obtain for the mean magnetization
¯M = Nmo tanh
"
Bmo/(kBT )
#
.
(5.83)
At high temperatures, kBT ≫Bmo, the magnetization increases linearly with the
applied magnetic ﬁeld (the atoms begin to align with B), so the magnetic susceptibility
is independent of B:
χM ≡
*
∂¯M
∂B
+
T ,N
≃Nm2
o/(kBT ).
(5.84)
The proportionality χM ∝1/T for a paramagnetic material at high temperature is
Curie’s law for magnetic
susceptibility
called Curie’s law. At low temperatures (kBT ≪Bmo), the atoms are essentially all
aligned with B, and the magnetization saturates at ¯M = Nmo.
5.8.2
5.8.2 Ferromagnetism: The Ising Model
Turn now to a magnetic material for which the spins’ interactions are strong, and there
is no external B ﬁeld. In such a material, at high temperatures the spin directions are
random, while at low enough temperatures the interactions drive neighboring spins to
align with one another, producing a net magnetization. This is called ferromagnetism,
ferromagnetic material
because it occurs rather strongly in iron. The transition between the two regimes is
sharp (i.e., it is a phase transition).
In this section, we introduce a simple model for the spins’ interaction: the Ising
model.14 For simplicity, we idealize to two spatial dimensions. The corresponding 3-
dimensional model is far more difﬁcult to analyze. Studying the 2-dimensional model
carefully brings out many general features of phase transitions, and the intuition it
cultivates is very helpful in thinking about experiments and simulations.
Ising model and its
pairwise interaction
energy
In this model, the atoms are conﬁned to a square lattice that lies in the x-y
plane, and their spins can point up (along the +z direction) or down. The pairwise
interaction energy is nonzero only for nearest neighbor atoms:
Esi,sj = −Jsisj
for nearest neighbors;
(5.85)
it vanishes for all other pairs. Here J is a positive constant (which depends on the
lattice’s speciﬁc volume v = V/N, but that will not be important for us). Note that the
interaction energy −Jsisj is negative if the spins are aligned (si = sj) and positive if
they are opposite (si = −sj), so like spins attract and opposite spins repel. Although
the Ising model does not explicitly include more distant interactions, they are present
indirectly: the “knock-on” effect from one spin to the next, as we shall see, introduces
14. Named for Ernst Ising, who ﬁrst investigated it, in 1925.
272
Chapter 5. Statistical Thermodynamics

long-range organization that propagates across the lattice when the temperature is
reduced below a critical value Tc, inducing a second-order phase transition. We use
the dimensionless parameter
K ≡J/(kBT )
(5.86)
to characterize the phase transition. For K ≪1 (i.e., kBT ≫J), the spins will be
almost randomly aligned, and the total interaction energy will be close to zero. When
K ≫1 (i.e., kBT ≪J), the strong coupling will drive the spins to align over large
critical temperature Tc
Tc
Tc and
critical parameter Kc
Kc
Kc
(2-dimensional) volumes. At some critical intermediate temperature Kc ∼1 [and
corresponding temperature Tc = J/(kBKc)], the phase transition will occur.
We compute this critical Kc, and macroscopic properties of the material near it,
using two modern, sophisticated computational techniques: renormalization meth-
ods in Sec. 5.8.3 and Monte Carlo methods in Sec. 5.8.4. We examine the accuracy of
these methods by comparing our results with an exact solution for the 2-dimensional
Ising model, derived in a celebrated paper by Lars Onsager (1944).
5.8.3
5.8.3 Renormalization Group Methods for the Ising Model
The key idea behind the renormalization group approach to the Ising model is to try to
idea behind
renormalization group
replace the full lattice by a sparser lattice that has similar thermodynamic properties,
and then to iterate, making the lattice more and more sparse; see Fig. 5.10.15
We implement this procedure using the statistical sum (5.80c) for the Gibbs
potential, except that here the external magnetic ﬁeld B vanishes, so the bath is purely
thermal and its potential is F(N, V , T )—the physical free energy, not G—and the
statistical sum (5.80c) reads e−F/(kBT ) ≡z = !
n e−En/(kBT ). For our Ising model,
with its nearest-neighbor interaction energies (5.85), this becomes
e−F(N ,V ,T )/(kBT ) ≡z =
 
{s1=±1,s2=±1, ...}
eK1sisj.
(5.87a)
Here in the exponential 1 means a sum over all pairs of nearest neighbor sites {i, j}.
The dependence on the material’s number of atoms N appears in the number of terms
in the big sum; the dependence on V/N is via the parameter J, and on T is via the
parameter K = J/(kBT ).
The ﬁrst step in the renormalization group method is to rewrite Eq. (5.87a) so
that each of the open-circle spins of Fig. 5.10 (e.g., s5) appears in only one term in the
exponential. Then we explicitly sum each of those spins over ±1, so they no longer
appear in the summations:
z =
 
{...,s4=±1,s5=±1,s6=±1, ...}
. . . eK(s1+s2+s3+s4)s5 . . .
=
 
{...,s4=±1,s6=±1, ...}
. . .

eK(s1+s2+s3+s4) + e−K(s1+s2+s3+s4)
. . . .
(5.87b)
15. This section is based in part on Maris and Kadanoff (1978) and Chandler (1987, Sec. 5.7).
5.8 Magnetic Materials
273

1
5
4
2
3
FIGURE 5.10 Partition of a square lattice into two interlaced square lattices (solid circles
and open circles). In the renormalization group approach, the open-circle spins
are removed from the lattice, and all their interactions are replaced by modiﬁed
interactions between the remaining solid-circle spins. The new lattice is rotated by π/4
with respect to the original lattice, and the lattice spacing increases by a factor
√
2.
(This rewriting of z is possible because each open-circle spin interacts only with solid-
circle spins.) The partition function z is now a product of terms like those in the square
brackets, one for each open-circle lattice site that we have “removed.” We would like
to rewrite each square-bracketed term in a form involving solely nearest-neighbor
interactions of the solid-circle spins, so that we can then iterate our procedure. Such a
rewrite, however, is not possible; after some experimentation, one can verify that the
rewrite also requires next-nearest-neighbor interactions and four-site interactions:

eK(s1+s2+s3+s4) + e−K(s1+s2+s3+s4)
= f (K)e[ 1
2K1(s1s2+s2s3+s3s4+s4s1)+K2(s1s3+s2s4)+K3s1s2s3s4].
(5.87c)
We can determine the four functions K1(K), K2(K), K3(K), f (K) by substituting
each of the four possible distinct combinations of {s1, s2, s3, s4} into Eq. (5.87c).
Those four combinations, arranged in the pattern of the solid circles of Fig. 5.10, are
+ +
++, −+
+ −, ++
−−, and ++
+−. [Rotating the pattern or changing all signs leaves both
sides of Eq. (5.87c) unchanged.] By inserting these combinations into Eq. (5.87c) and
performing some algebra, we obtain
K1 = 1
4 ln cosh(4K),
K2 = 1
8 ln cosh(4K),
K3 = 1
8 ln cosh(4K) −1
2 ln cosh(2K), and
f (K) = 2[cosh(2K)]1/2[cosh(4K)]1/8.
(5.87d)
By inserting expression (5.87c) and the analogous expressions for the other terms
into Eq. (5.87b), we obtain the partition function for our original N-spin lattice of
open and closed circles, expressed as a sum over the (N/2)-spin lattice of closed
circles:
z(N, K) = [f (K)]N/2  
e[K11sisj+K22sisj+K33sisjsksl].
(5.87e)
274
Chapter 5. Statistical Thermodynamics

Here the symbol 1 still represents a sum over all nearest neighbors but now in the
N/2 lattice, 2 is a sum over the four next nearest neighbors, and 3 is a sum over
spins located at the vertices of a unit cell. [The reason we deﬁned K1 with the 1/2
in Eq. (5.87c) was because each nearest neighbor interaction appears in two adjacent
squares of the solid-circle lattice, thereby converting the 1/2 to a 1 in Eq. (5.87e).]
So far, what we have done is exact. We now make two drastic approximations
that Onsager did not make in his exact treatment, but are designed to simplify the
remainderofthecalculationandtherebyelucidatetherenormalizationgroupmethod.
First, in evaluating the partition function (5.87e), we drop completely the quadruple
interaction (i.e., we set K3 = 0). This is likely to be decreasingly accurate as we lower
the temperature and the spins become more aligned. Second, we assume that near the
criticalpoint, insomeaveragesense, thedegreeofalignmentofnextnearestneighbors
(of which there are as many as nearest neighbors) is “similar” to that of the nearest
neighbors, so that we can set K2 = 0 but increase K1 to
K′ = K1 + K2 = 3
8 ln cosh(4K).
(5.88)
(If we simply ignored K2 we would not get a phase transition.) This substitution
ensures that the energy of a lattice with N/2 aligned spins—and therefore N near-
est neighbor and N next nearest neighbor bonds, namely, −(K1 + K2)NkBT —is
the same as that of a lattice in which we just include the nearest neighbor bonds
but strengthen the interaction from K1 to K′. Clearly this will be unsatisfactory at
high temperature, but we only need it to be true near the phase transition’s critical
temperature.
These approximations bring the partition function (5.87e) into the form
z(N, K) = [f (K)]N/2z(N/2, K′),
(5.89a)
which relates the partition function (5.87a) for our original Ising lattice of N spins
and interaction constant K to that of a similar lattice with N/2 spins and interaction
constant K′.
As the next key step in the renormalization procedure, we note that because the
free energy, F = −kBT ln z, is an extensive variable, ln z must increase in direct
proportion to the number of spins, so that it must have the form
−F/(kBT ) ≡ln z(N, K) = Ng(K),
(5.89b)
for some function g(K). By combining Eqs. (5.89a) and (5.89b), we obtain a rela-
tion for the function g(K) (the free energy, aside from constants) in terms of the
function f (K):
g(K′) = 2g(K) −ln f (K),
where f (K) = 2[cosh(2K)]1/2[cosh(4K)]1/8
(5.90)
[cf. Eq. (5.87d)].
Equations (5.88) and (5.90) are the fundamental equations that allow us to calcu-
late thermodynamic properties. They are called the renormalization group equations,
renormalization group
equations
because their transformations form a mathematical group, and they are a scheme
5.8 Magnetic Materials
275

for determining how the effective coupling parameter K changes (gets renormal-
ized) when one views the lattice on larger and larger distance scales. Renormalization
group equations like these have been widely applied in elementary-particle theory,
condensed-matter theory, and elsewhere. Let us examine these in detail.
The iterative map (5.88) expresses the coupling constant K′ for a lattice of enlarged
physical size and reduced number of particles N/2in terms of K for the smaller lattice
with N particles. [And the associated map (5.90) expresses the free energy when the
lattice is viewed on the larger scale in terms of that for a smaller scale.] The map (5.88)
has a ﬁxed point that is obtained by setting K′ = K [i.e., Kc = 3
8 ln cosh(4Kc)], which
implies
Kc = 0.507.
(5.91)
This ﬁxed point corresponds to the critical point for the phase transition, with critical
temperature Tc such that Kc = J/(kBTc).
We can infer that this is the critical point by the following physical argument.
Suppose that T is slightly larger than Tc, so K is slightly smaller than Kc. Then,
when we make successive iterations, because dK′/dK > 1 at K = Kc, K decreases
with each step, moving farther from Kc; the ﬁxed point is unstable. What this means
is that, when T > Tc, as we look on larger and larger scales, the effective coupling
constant K becomes weaker and weaker, so the lattice becomes more disordered.
Conversely, below the critical temperature (T < Tc and K > Kc), the lattice becomes
more ordered with increasing scale. Only when K = Kc does the lattice appear to
be comparably disordered on all scales. It is here that the increase of order with
lengthscale changes from greater order at smaller scales (for high temperatures) to
greater order at larger scales (for low temperatures).
To demonstrate more explicitly that K = Kc is the location of a phase transition,
we compute the lattice’s speciﬁc heat in the vicinity of Kc. The ﬁrst step is to com-
pute the lattice’s entropy, S = −(∂F/∂T )V ,N. Recalling that K ∝1/T at ﬁxed V , N
[Eq. (5.86)] and using expression (5.89b) for F, we see that
S = −
∂F
∂T

V ,N
= NkB

g −K
 dg
dK

.
(5.92a)
The speciﬁc heat at constant volume is then, in turn, given by
CV = T
 ∂S
∂T

V ,N
= NkBK2 d2g
dK2 .
(5.92b)
Nextwenotethat, becausetheiteration(5.88)isunstablenear Kc, theinverseiteration
K = 1
4 cosh−1[exp(8K′/3)]
(5.92c)
is stable. The corresponding inverse transformation for the function g(K) is obtained
from Eq. (5.90), with K in the function f converted to K′ using Eq. (5.92c):
g(K) = 1
2g(K′) + 1
2 ln{2 exp(2K′/3)[cosh(4K′/3)]1/4}.
(5.92d)
276
Chapter 5. Statistical Thermodynamics

0.510
0.508
0.506
0.504
0.502
0.00
−0.02
−0.04
−0.06
−0.08
K
S/NkB
−2.136
−2.138
−2.140
−2.142
−2.144
100
80
60
40
20
0.510
0.508
0.506
0.504
0.502
0.510
0.508
0.506
0.504
0.502
0.510
0.508
0.506
0.504
0.502
0.510
0.508
0.506
(a)
(b)
(c)
(d)
0.504
0.502
F/NJ
CV /NkB
J/kBT
J/kBT
J/kBT
K′
FIGURE 5.11 (a) Iteration map K(K′) in the vicinity of the critical point. (b) Free energy per spin.
(c) Entropy per spin. (d) Speciﬁc heat per spin. Recall that J/(kBT ) = K.
Now, we know that at low temperature, T ≪Tc and K ≫Kc, all the spins are aligned;
correspondingly, in the statistical sum (5.87a) the two terms with all s’s identical
dominate, giving z = e−F/(kBT ) = eNg = 2e2NK, whence g(K) ≃2K. Conversely, at
high temperature, there is complete disorder, and K →0. This means that every
one of the 2N terms in the statistical sum (5.87a) is unity, giving z = eNg = 2N,
whence g(K) ≃ln 2. We can therefore use the iterative map, Eqs. (5.92c) and (5.92d),
to approach K = Kc from either side, starting with the high-temperature and low-
temperature limits of g(K) and evaluating thermodynamic quantities at each step.
More speciﬁcally, at each step, we evaluate g(K), dg/dK, and d2g/dK2 numerically,
and from them we compute F, S, and CV using Eqs. (5.89b), (5.92a), and (5.92b).
The iterated values of these quantities are plotted as points in Fig. 5.11. Note
that the entropy S is continuous at Kc (panel c), but its derivative, the speciﬁc heat
(panel d), diverges at Kc, as K →Kc from either side. This is characteristic of a
second-order phase transition.
To calculate the explicit form of this divergence, suppose that g(K) is a sum of
an analytic (inﬁnitely differentiable) function and a nonanalytic part. Suppose that
5.8 Magnetic Materials
277

near the critical point, the nonanalytic part behaves as g(K) ∼|K −Kc|2−α for some
“critical exponent” α. This implies that CV diverges ∝|K −Kc|−α ∝|T −Tc|−α.
Now, from Eq. (5.92d), we have that
|K′ −Kc|2−α = 2|K −Kc|2−α,
(5.93a)
or equivalently,
dK′
dK = 21/(2−α).
(5.93b)
Evaluating the derivative at K = Kc from Eq. (5.92c), we obtain
α = 2 −
ln 2
ln(dK′/dK)c
= 0.131,
(5.93c)
which is consistent with the numerical calculation.
The exact Onsager (1944) analysis of the Ising model gives Kc = 0.441compared
exact analysis of Ising
model compared to our
approximate analysis
to our Kc = 0.507, and CV ∝−ln |T −Tc| compared to our CV ∝|T −Tc|−0.131.
Evidently, our renormalization group approach (formulated by Maris and Kadanoff,
1978) gives a fair approximation to the correct answers but not a good one.
Our approach appears to have a serious problem in that it predicts a negative value
fortheentropyinthevicinityofthecriticalpoint(Fig.5.11c).Thisissurelyunphysical.
(The entropy becomes positive farther away, on either side of the critical point.) This
is an artiﬁciality associated with our approach’s ansatz [i.e., associated with our setting
K2 = K3 = 0 and K′ = K1 + K2 in Eq. (5.88)]. It does not seem easy to cure this in a
simple renormalization-group approach.
Nonetheless, our calculations exhibit the conceptual and physical essentials of the
renormalization-group approach to phase transitions.
Why did we bother to go through this cumbersome procedure when Onsager has
given us an exact analytical solution to the Ising model? The answer is that it is not
possible to generalize the Onsager solution to more complex and realistic problems.
In particular, it has not even been possible to ﬁnd an Onsager-like solution to the 3-
dimensional Ising model. However, once the machinery of the renormalization group
has been mastered, it can produce approximate answers, with an accuracy that can
be estimated, for a variety of problems. In the following section we look at a quite
different approach to the same 2-dimensional Ising problem with exactly the same
motivation in mind.
EXERCISES
Exercise 5.15 Example: One-Dimensional Ising Lattice
(a) Write down the partition function for a 1-dimensional Ising lattice as a sum over
terms describing all possible spin organizations.
278
Chapter 5. Statistical Thermodynamics

(b) Show that by separating into even and odd numbered spins, it is possible to factor
thepartitionfunctionandrelatez(N, K)exactlytoz(N/2, K′).Speciﬁcally, show
that
z(N, K) = f (K)N/2z(N/2, K′)
(5.94)
where K′ = ln[cosh(2K)]/2, and f (K) = 2[cosh(2K)]1/2.
(c) Use these relations to demonstrate that the 1-dimensional Ising lattice does not
exhibit a second-order phase transition.
5.8.4
5.8.4 Monte Carlo Methods for the Ising Model
In this section, we explore the phase transition of the 2-dimensional Ising model
using our second general method: the Monte Carlo approach.16 This method, like
the renormalization group, is a powerful tool for a much larger class of problems than
just phase transitions.17
Monte Carlo method for
Ising model
The Monte Carlo approach is much more straightforward in principle than the
renormalization group. We set up a square lattice of atoms and initialize their spins
randomly.18 We imagine that our lattice is in contact with a heat bath with a ﬁxed
temperature T (it is one member of a canonical ensemble of systems), and we drive it
to approach statistical equilibrium and then wander onward through an equilibrium
sequence of states |n1⟩, |n2⟩, . . . in a prescribed, ergodic manner. Our goals are to
visualize typical equilibrium states (see Fig. 5.12 later in this section) and to compute
thermodynamic quantities using ¯X = z−1 !
n e−En/(kBT )Xn, where the sum is over
the sequence of states |n1⟩, |n2⟩, . . . . For example, we can compute the speciﬁc heat
(at constant volume) from
CV = d ¯E
dT = ∂
∂T
*!
n e−En/(kBT )En
!
n e−En/(kBT )
+
= E2 −¯E2
kBT 2
.
(5.95)
[Note that a singularity in the speciﬁc heat at a phase transition will be associated
with large ﬂuctuations in the energy, just as it is associated with large ﬂuctuations of
temperature; Eq. (5.73d).]
In constructing our sequence of lattice states |n1⟩, |n2⟩, . . . , we obviously cannot
visit all 2N states even just once, so we must sample them fairly. How can we prescribe
the rule for changing the spins when going from one state in our sample to the next, so
as to produce a fair sampling? There are many answers to this question; we describe
16. The name “Monte Carlo” is a sardonic reference to the casino whose patrons believe they will proﬁt by
exploiting random processes.
17. We shall meet it again in Sec. 28.6.1.
18. This and other random steps that follow are performed numerically and require a (pseudo) random
number generator. Most programming languages supply this utility, which is mostly used uncritically,
occasionally with unintended consequences. Deﬁning and testing “randomness” is an important topic
which, unfortunately, we shall not address. See, for example, Press et al. (2007).
5.8 Magnetic Materials
279

and use one of the simplest, due to Metropolis et al. (1953). To understand this, we
must appreciate that we don’t need to comprehend the detailed dynamics by which a
spin in a lattice actually ﬂips. All that is required is that the rule we adopt, for going
from one state to the next, should produce a sequence that is in statistical equilibrium.
Let us denote by pnn′ the conditional probability that, if the lattice is in state |n⟩,
then the next step will take it to state |n′⟩. For statistical equlilibrium, it must be that
the probability that any randomly observed step takes us out of state |n⟩is equal to
the probability that it takes us into that state:
ρn
 
n′
pnn′ =
 
n′
ρn′pn′n.
(5.96)
(Here ρn is the probability that the lattice was in state |n⟩just before the transition.)
We know that in equilibrium, ρn′ = ρn e(En−En′)/(kBT ), so our conditional transition
probabilities must satisfy
 
n′
pnn′ =
 
n′
pn′ne(En−En′)/(kBT ).
(5.97)
The Metropolis rule is simple:
Metropolis rule for
transition probabilities
if En > Em, then pnm = 1;
and if En < Em, then pnm = exp[(En −Em)/(kBT )]
(5.98)
up to some normalization constant. It is easy to show that this satisﬁes the statistical
equilibrium condition (5.97) and that it drives an initial out-of-equilibrium system
toward equilibrium.
The numerical implementation of the Metropolis rule (5.98) is as follows: Start
with the lattice in an initial, random state, and then choose one spin at random
to make a trial ﬂip. If the new conﬁguration has a lower energy, we always accept
the change. If it has a higher energy, we only accept the change with a probability
given by exp[−E/(kBT )], where E > 0 is the energy change.19 In this way, we
produce a sequence of states that will ultimately have the equilibrium distribution
function, and we can perform our thermodynamic averages using this sequence in an
unweighted fashion. This is a particularly convenient procedure for the Ising problem,
because, by changing just one spin at a time, E can only take one of ﬁve values
(−4, −2, 0, +2, +4 in units of J), and it is possible to change from one state to the
next very quickly. (It also helps to store the two acceptance probabilities e−2J/(kBT )
and e−4J/(kBT ) for making an energy-gaining transition, so as to avoid evaluating
exponentials at every step.)
19. There is a small subtlety here. The probability of making a given transition is actually the product of the
probability of making the trial ﬂip and of accepting the trial. However, the probability of making a trial
ﬂip is the same for all the spins that we might ﬂip (1/N), and these trial probabilities cancel, so it is only
the ratio of the probabilities of acceptance that matters.
280
Chapter 5. Statistical Thermodynamics

T = 1
T = 2
T = 3
FIGURE 5.12 Typical equilibrium Ising lattices for temperatures T = 1, 2, 3 in units of J/kB. The black
regions have spins s = +1; the white, s = −1.
How big a lattice do we need, and how many states should we consider? The
lattice size can be surprisingly small to get qualitatively correct results, if we adopt
periodic boundary conditions. That is to say, we imagine a ﬁnite tiling of our ac-
tual ﬁnite lattice, and every time we need to know the spin at a site beyond the
tiling’s last column (or row), we use the corresponding spin an equal distance be-
yond the ﬁrst column (or row). This device minimizes the effects of the boundary
on the ﬁnal answer. Lattices as small as 32 × 32 can be useful. The length of the
computation depends on the required accuracy. (In practice, this is usually imple-
mented the other way around. The time available on a computer of given speed
determines the accuracy.) One thing should be clear. It is necessary that we ex-
plore a reasonable volume of state space to be able to sample it fairly and com-
pute meaningful estimates of thermodynamic quantities. The ﬁnal lattice should
exhibit no vestigial patterns from the state when the computation was half com-
plete. In practice, it is this consideration that limits the size of the lattice, and it is
one drawback of the Metropolis algorithm that the step sizes are necessarily small.
There is a large bag of tricks for Monte Carlo simulations that can be used for vari-
ance reduction and estimation, but we only concern ourselves here with the general
method.
Monte Carlo results for
Ising model
Returning to the Ising model, we show in Fig. 5.12 typical equilibrium states
(snapshots) for three temperatures, measured in units of J/kB. Recall that the critical
temperature is Tc = J/(kBKc) = J/(0.441kB) = 2.268J/kB. Note the increasingly
long-range order as the temperature is reduced below Tc.
We have concluded this chapter with an examination of a very simple system that
can approach equilibrium according to speciﬁed rules and that can exhibit strong
ﬂuctuations. In the following chapter, we examine ﬂuctuations more systematically.
EXERCISES
Exercise 5.16 Practice: Direct Computation of Thermodynamic Integrals
Estimate how long it would take a personal computer to calculate the partition func-
tion for a 32 × 32 Ising lattice by evaluating every possible state.
5.8 Magnetic Materials
281

Exercise 5.17 Example: Monte Carlo Approach to Phase Transition
Write a simple computer program to compute the energy and the speciﬁc heat of
a 2-dimensional Ising lattice as described in the text. Examine the accuracy of your
answers by varying the size of the lattice and the number of states sampled. (You might
also try to compute a formal variance estimate.)
Exercise 5.18 Problem: Ising Lattice with an Applied Magnetic Field
Modify your computer program from Ex. 5.17 to deal with the 2-dimensional Ising
model augmented by an externally imposed, uniform magnetic ﬁeld [Eqs. (5.80)].
Compute the magnetization and the magnetic susceptibility for wisely selected values
of moB/J and K = J/(kBT ).
Bibliographic Note
Most statistical mechanics textbooks include much detail on statistical thermo-
dynamics. Among those we have found useful at an elementary level are Kittel
and Kroemer (1980), and at more advanced levels, Chandler (1987), Sethna (2006),
Kardar (2007), Reif (2008), and Pathria and Beale (2011). Chandler (1987) and Sethna
(2006) are particularly good for phase transitions. Our treatment of the renormaliza-
tion group in Sec. 5.8.3 is adapted in part from Chandler, who also covers Monte
Carlo methods.
282
Chapter 5. Statistical Thermodynamics

6
CHAPTER SIX
Random Processes
These motions were such as to satisfy me, after frequently repeated observation, that they arose
neither from currents in the ﬂuid, nor from its gradual evaporation, but belonged to the particle itself.
ROBERT BROWN (1828)
6.1
6.1 Overview
In this chapter we analyze, among others, the following issues:
.
What is the time evolution of the distribution function for an ensemble of
systems that begins out of statistical equilibrium and is brought to equilib-
rium through contact with a heat bath?
.
How can one characterize the noise introduced into experiments or obser-
vations by noisy devices, such as resistors and ampliﬁers?
.
What is the inﬂuence of such noise on one’s ability to detect weak signals?
.
What ﬁltering strategies will improve one’s ability to extract weak signals
from strong noise?
.
Frictional damping of a dynamical system generally arises from coupling to
many other degrees of freedom (a bath) that can sap the system’s energy.
What is the connection between the ﬂuctuating (noise) forces that the bath
exerts on the system and its damping inﬂuence?
The mathematical foundation for analyzing such issues is the theory of random
processes (i.e., of functions that are random and unpredictable but have predictable
probabilities for their behavior). A portion of the theory of random processes is the
theory of stochastic differential equations (equations whose solutions are probability
distributions rather than ordinary functions). This chapter is an overview of these
topics, sprinkled throughout with applications.
In Sec. 6.2, we introduce the concept of random processes and the various proba-
bility distributions that describe them. We introduce restrictions that we shall adhere
to—the random processes that we study are stationary and ergodic—and we intro-
duce an example that we return to time and again: a random-walk process, of which
Brownian motion is an example. In Sec. 6.3, we discuss two special classes of random
processes: Markov processes and Gaussian processes; we also present two important
theorems: the central limit theorem, which explains why random processes so often
283

BOX 6.1.
READERS’ GUIDE
.
Relativity does not enter into this chapter.
.
This chapter does not rely in any major way on previous chapters,
but it does make occasional reference to results from Chaps. 4 and
5 about statistical equilibrium and ﬂuctuations in and away from
statistical equilibrium.
.
No subsequent chapter relies in any major way on this chapter.
However:
– The concepts of spectral density and correlation function,
developed in Sec. 6.4, will be used in Ex. 9.8 when treating
coherence properties of radiation, in Sec. 11.9.2 when
studying thermal noise in solids, in Sec. 15.4 when studying
turbulence in ﬂuids, in Sec. 23.2.1 in treating the quasilinear
formalism for weak plasma turbulence, and in Sec. 28.6.1
when discussing observations of the anisotropy of the
cosmic microwave background radiation.
– The ﬂuctuation-dissipation theorem, developed in Sec. 6.8,
will be used in Sec. 11.9.2 for thermoelastic noise in solids,
and in Sec. 12.5 for normal modes of an elastic body.
– The Fokker-Planck equation, developed in Sec. 6.9, will be
referred to or used in Secs. 20.4.3, 20.5.1, and 28.6.3 and
Exs. 20.8 and 20.10 when discussing thermal equilibration
in a plasma and thermoelectric transport coefﬁcients, and
it will be used in Sec. 23.3.3 in developing the quasilinear
theory of wave-particle interactions in a plasma.
have Gaussian probability distributions, and Doob’s theorem, which says that all the
statistical properties of a Markov, Gaussian process are determined by just three pa-
rameters. In Sec. 6.4, we introduce two powerful mathematical tools for the analysis
of random processes: the correlation function and spectral density, and prove the
Wiener-Khintchinetheorem, whichrelatesthem.Asapplicationsofthesetools, weuse
them to prove Doob’s theorem and to discuss optical spectra, noise in interferomet-
ric gravitational wave detectors, and ﬂuctuations of cosmological mass density and of
the distribution of galaxies in the universe. In Secs. 6.6 and 6.7, we introduce another
powerful tool, the ﬁltering of a random process, and we use these tools to develop
the theory of noise and techniques for extracting weak signals from large noise. As
applications we study shot noise (which is important, e.g., in measurements with laser
light), frequency ﬂuctuations of atomic clocks, and also the Brownian motion of a dust
284
Chapter 6. Random Processes

particle buffeted by air molecules and its connection to random walks. In Sec. 6.8, we
develop another powerful tool, the ﬂuctuation-dissipation theorem, which quantiﬁes
the relationship between the ﬂuctuations and the dissipation (friction) produced by
one and the same heat bath. As examples, we explore Brownian motion (once again),
Johnson noise in a resistor and the voltage ﬂuctuations it produces in electric circuits,
thermal noise in high-precision optical measurements, and quantum limits on the ac-
curacy of high-precision measurements and how to circumvent them. Finally, in Sec.
6.9 we derive and discuss the Fokker-Planck equation, which governs the evolution
of Markov random processes, and we illustrate it with the random motion of an atom
that is being cooled by interaction with laser beams (so-called optical molasses) and
with thermal noise in a harmonic oscillator.
6.2
6.2 Fundamental Concepts
In this section we introduce a number of fundamental concepts about random
processes.
6.2.1
6.2.1 Random Variables and Random Processes
RANDOM VARIABLE
random variable
A (1-dimensional) random variable is a (scalar) function y(t), where t is usually time,
for which the future evolution is not determined uniquely by any set of initial data—
or at least by any set that is knowable to you and me. In other words, random variable
is just a fancy phrase that means “unpredictable function.” Throughout this chapter,
we insist for simplicity that our random variables y take on a continuum of real values
ranging over some interval, often but not always −∞to +∞. The generalizations to
y with complex or discrete (e.g., integer) values, and to independent variables other
than time, are straightforward.
Examples of random variables are: (i) the total energy E(t) in a cell of gas that is
in contact with a heat bath; (ii) the temperature T (t) at the corner of Main Street and
Center Street in Logan, Utah; (iii) the price per share of Google stock P (t); (iv) the
mass-ﬂow rate ˙M(t) from the Amazon River into the Atlantic Ocean. One can also
deal with random variables that are vector or tensor functions of time; in Track-Two
portions of this chapter we do so.
RANDOM PROCESS
random process
A (1-dimensional) random process (also called “stochastic process”) is an ensemble E
of real random variables y(t) that, in a physics context, all represent the same kind of
physical entity. For example, each y(t) could be the longitude of a particular oxygen
molecule undergoing a random walk in Earth’s atmosphere. The individual random
variables y(t) in the ensemble E are often called realizations of the random process.
As an example, Fig. 6.1 shows three realizations y(t) of a random process that
represents the random walk of a particle in one dimension. For details, see Ex. 6.4,
which shows how to generate realizations like these on a computer.
6.2 Fundamental Concepts
285

100
50
0
–50
–100
–150
0
2,000
4,000
t
y
6,000
8,000
10,000
FIGURE 6.1 Three different realizations y(t) of a random process that describes
the location y of a particle at time t, when it is undergoing a random walk in
1 dimension (e.g., an atmospheric oxygen molecule’s east-west motion).
6.2.2
6.2.2 Probability Distributions
PROBABILITY DISTRIBUTIONS FOR A RANDOM PROCESS
Since the precise time evolution of a random variable y(t) is not predictable, if one
wishes to make predictions, one can do so only probabilistically. The foundation for
probabilistic predictions is a set of probability functions for the random process (i.e.,
for the ensemble E of its realizations).
More speciﬁcally, the most general (1-dimensional) random process is fully char-
acterized by the set of probability distributions p1, p2, p3, . . . deﬁned as
probability distributions
for a random process
pn(yn, tn; . . . ; y2, t2; y1, t1)dyn . . . dy2dy1.
(6.1)
Equation (6.1) tells us the probability that a realization y(t), drawn at random from
the process (the ensemble E), (i) will take on a value between y1 and y1 + dy1 at time
t1, (ii) also will take on a value between y2 and y2 + dy2 at a later time t2, . . . , and
(iii) also will take on a value between yn and yn + dyn at a later time tn. (Note that the
subscript n on pn tells us how many independent values of y appear in pn, and that
earlier times are placed to the right—a practice common for physicists, particularly
when dealing with propagators.) If we knew the values of all the process’s probability
distributions (an inﬁnite number of pns!), then we would have full information about
its statistical properties. Not surprisingly, it will turn out that, if the process in some
sense is in statistical equilibrium, then we can compute all its probability distributions
from a very small amount of information. But that comes later; ﬁrst we must develop
more formalism.
286
Chapter 6. Random Processes

ENSEMBLE AVERAGES
From the probability distributions, we can compute ensemble averages (denoted by
ensemble average and
variance
brackets). For example, the quantities
⟨y(t1)⟩≡

y1p1(y1, t1)dy1
and
σ 2
y(t1) ≡
6
[y(t1) −⟨y(t1)⟩]27
(6.2a)
are the ensemble-averaged value of y and the variance of y at time t1. Similarly,
⟨y(t2)y(t1)⟩≡

y2y1p2(y2, t2; y1, t1)dy2dy1
(6.2b)
is the average value of the product y(t2)y(t1).
CONDITIONAL PROBABILITIES
Besidesthe(absolute)probabilitydistributionspn, wealsoﬁndusefulaninﬁniteseries
of conditional probability distributions P2, P3, . . . , deﬁned as
conditional probability
distributions
Pn(yn, tn|yn−1, tn−1; . . . ; y1, t1)dyn.
(6.3)
This distribution is the probability that, if y(t) took on the values y1, y2, . . . , yn−1 at
times t1, t2, . . . , tn−1, then it will take on a value between yn and yn + dyn at a later
time tn.
It should be obvious from the deﬁnitions of the probability distributions that
pn(yn, tn; . . . ; y1, t1)
= Pn(yn, tn|yn−1, tn−1; . . . ; y1, t1)pn−1(yn−1, tn−1; . . . ; y1, t1).
(6.4)
Using this relation, one can compute all the conditional probability distributions Pn
from the absolute distributions p1, p2, . . . . Conversely, using this relation recursively,
one can build up all the absolute probability distributions pn from p1(y1, t1) and all
the conditional distributions P2, P3, . . . .
STATIONARY RANDOM PROCESSES
stationary random process
A random process is said to be stationary if and only if its probability distributions pn
depend just on time differences and not on absolute time:
pn(yn, tn + τ; . . . ; y2, t2 + τ; y1, t1 + τ) = pn(yn, tn; . . . ; y2, t2; y1, t1).
(6.5)
If this property holds for the absolute probabilities pn, then Eq. (6.4) guarantees it also
will hold for the conditional probabilities Pn.
Nonstationary random processes arise when one is studying a system whose evo-
lution is inﬂuenced by some sort of clock that registers absolute time, not just time
differences. For example, the speeds v(t) of all oxygen molecules in downtown St. An-
thony, Idaho, makeuprandomprocessesregulatedinpartbytheatmospherictemper-
ature and therefore by the rotation of Earth and its orbital motion around the Sun. The
6.2 Fundamental Concepts
287

extremely small t2 − t1
small t2 − t1
large t2 − t1, Maxwellian
P2
v2
FIGURE 6.2 The probability P2(v2, t2|0, t1) that a molecule with
vanishing speed at time t1 will have speed v2 (in a unit interval dv2)
at time t2. Although the molecular speed is a stationary random
process, this probability evolves in time.
inﬂuence of these clocks makes v(t) a nonstationary random process. Stationary ran-
dom processes, by contrast, arise in the absence of any regulating clocks. An example
is the speeds v(t) of all oxygen molecules in a room kept at constant temperature.
Stationarity does not mean “no time evolution of probability distributions.” For
example, suppose one knows that the speed of a speciﬁc oxygen molecule vanishes
at time t1, and one is interested in the probability that the molecule will have speed
v2 at time t2. That probability, P2(v2, t2|0, t1), is sharply peaked around v2 = 0 for
extremely small time differences t2 −t1 and is Maxwellian for large time differences
t2 −t1 (Fig. 6.2). Despite this evolution, the process is stationary (assuming constant
temperature) in the sense that it does not depend on the speciﬁc time t1 at which v
happened to vanish, only on the time difference t2 −t1: P2(v2, t2|0, t1) = P2(v2, t2 −
t1|0, 0).
Henceforth, throughout this chapter, we restrict attention to random processes that
are stationary (at least on the timescales of interest to us); and, accordingly, we use
p1(y) ≡p1(y, t1)
(6.6a)
for the probability, since it does not depend on the time t1. We also denote by
P2(y2, t|y1) ≡P2(y2, t|y1, 0)
(6.6b)
the probability that, if a (realization of a) random process begins with the value y1,
then after the lapse of time t it has the value y2.
6.2.3
6.2.3 Ergodic Hypothesis
ergodic hypothesis
A (stationary) random process (ensemble E of random variables) is said to satisfy the
ergodic hypothesis (or, for brevity, it will be called ergodic) if and only if it has the
following property.
288
Chapter 6. Random Processes

Let y(t) be a random variable in the ensemble E (i.e., let y(t) be any realization of
the process). Construct from y(t) a new ensemble E′ whose members are
Y K(t) ≡y(t + KT ),
(6.7)
where K runs over all integers, negative and positive, and where T is some very
large time interval. Then E′ has the same probability distributions pn as E; that is,
pn(Yn, tn; . . . ; Y1, t1) has the same functional form as pn(yn, tn; . . . ; y1, t1) for all
times such that |ti −tj| < T .
This is essentially the same ergodic hypothesis as we met in Sec. 4.6.
Henceforth we restrict attention to random processes that satisfy the ergodic hypoth-
esis (i.e., that are ergodic). This, in principle, is a severe restriction. In practice, for a
physicist, it is not severe at all. In physics one’s objective, when deﬁning random vari-
ables that last forever (−∞< t < +∞) and when introducing ensembles, is usually
to acquire computational techniques for dealing with a single, or a small number of,
random variables y(t), studied over ﬁnite lengths of time. One acquires those tech-
niques by deﬁning conceptual inﬁnite-duration random variables and ensembles in
such a way that they satisfy the ergodic hypothesis.
As in Sec. 4.6, because of the ergodic hypothesis, time averages deﬁned using any
realization y(t) of a random process are equal to ensemble averages:
¯F ≡lim
T →∞
1
T
 T /2
−T /2
F

y(t)

dt = ⟨F(y)⟩≡

F(y)p1(y)dy,
(6.8)
for any function F = F(y). In this sense, each realization of the random process is
representative, when viewed over sufﬁciently long times, of the statistical properties
of the process’s entire ensemble—and conversely. Correspondingly, we can blur the
distinction between the random process and speciﬁc realizations of it—and we often
do so.
6.3
6.3 Markov Processes and Gaussian Processes
6.3.1
6.3.1 Markov Processes; Random Walk
Markov random process
A random process y(t) is said to be Markov (also sometimes called “Markovian”) if
and only if all of its future probabilities are determined by its most recently known
value:
Pn(yn, tn|yn−1, tn−1; . . . ; y1, t1) = P2(yn, tn|yn−1, tn−1)
for all tn ≥. . . ≥t2 ≥t1.
(6.9)
This relation guarantees that any Markov process (which, of course, we require to be
stationary without saying so) is completely characterized by the probabilities
p1(y) and P2(y2, t|y1) ≡p2(y2, t; y1, 0)
p1(y1)
.
(6.10)
6.3 Markov Processes and Gaussian Processes
289

From p1(y) and P2(y2, t|y1) one can reconstruct, using the Markov relation (6.9)
and the general relation (6.4) between conditional and absolute probabilities, all
distribution functions of the process.
Actually, for any random process that satisﬁes the ergodic hypothesis (which
means all random processes considered in this chapter), p1(y) is determined by the
conditionalprobabilityP2(y2, t|y1)[Ex.6.1], soforanyMarkov(andergodic)process,
all the probability distributions follow from P2(y2, t|y1) alone!
An example of a Markov process is the x component of velocity vx(t) of a dust
particle in an arbitrarily large room,1 ﬁlled with constant-temperature air. Why?
Because the molecule’s equation of motion is2 mdvx/dt = F ′
x(t), and the force F ′
x(t)
is due to random buffeting by other molecules that are uncorrelated (the kick now is
unrelated to earlier kicks); thus, there is no way for the value of vx in the future to be
inﬂuenced by any earlier values of vx except the most recent one.
By contrast, the position x(t) of the particle is not Markov, because the probabili-
ties of future values of x depend not just on the initial value of x, but also on the initial
velocity vx—or, equivalently, the probabilities depend on the values of x at two initial,
closely spaced times. The pair {x(t), vx(t)} is a 2-dimensional Markov process (see
Ex. 6.23).
THE SMOLUCHOWSKI EQUATION
Choose three (arbitrary) times t1, t2, and t3 that are ordered, so t1 < t2 < t3. Consider
a (realization of an) arbitrary random process that begins with a known value y1 at
t1, and ask for the probability P2(y3, t3|y1) (per unit y3) that it will be at y3 at time
t3. Since the realization must go through some value y2 at the intermediate time t2
(though we don’t care what that value is), it must be possible to write the probability
to reach y3 as
P2(y3, t3|y1, t1) =

P3(y3, t3|y2, t2; y1, t1)P2(y2, t2|y1, t1)dy2,
where the integration is over all allowed values of y2. This is not a terribly interesting
relation. Much more interesting is its specialization to the case of a Markov process.
In that case P3(y3, t3|y2, t2; y1, t1) can be replaced by P2(y3, t3|y2, t2) = P2(y3, t3 −
t2|y2, 0) ≡P2(y3, t3 −t2|y2), and the result is an integral equation involving only P2.
Because of stationarity, it is adequate to write that equation for the case t1 = 0:
P2(y3, t3|y1) =

P2(y3, t3 −t2|y2)P2(y2, t2|y1)dy2.
(6.11)
This is the Smoluchowski equation (also called Chapman-Kolmogorov equation). It is
Smoluchowski equation
valid for any Markov random process and for times 0 < t2 < t3. We shall discover its
power in our derivation of the Fokker-Planck equation in Sec. 6.9.1.
1.
The room must be arbitrarily large so the effects of the ﬂoor, walls, and ceiling can be ignored.
2.
By convention, primes are used to identify stochastic forces (i.e., forces that are random processes).
290
Chapter 6. Random Processes

EXERCISES
Exercise 6.1 **Example: Limits of P2
Explain why, for any (stationary) random process,
lim
t→0 P2(y2, t|y1) = δ(y2 −y1).
(6.12a)
Use the ergodic hypothesis to argue that
lim
t→∞P2(y2, t|y1) = p1(y2).
(6.12b)
Thereby conclude that, for a Markov process, all the probability distributions are
determined by the conditional probability P2(y2, t|y1). Give an algorithm for com-
puting them.
Exercise 6.2 Practice: Markov Processes for an Oscillator
Consider a harmonic oscillator (e.g., a pendulum), driven by bombardment with air
molecules. Explain why the oscillator’s position x(t) and velocity v(t) = dx/dt are
randomprocesses.Isx(t)Markov?Why?Isv(t)Markov?Why?Isthepair{x(t), v(t)}
a 2-dimensional Markov process? Why? We study this 2-dimensional random process
in Ex. 6.23.
Exercise 6.3 **Example: Diffusion of a Particle; Random Walk
In Ex. 3.17, we studied the diffusion of particles through an inﬁnite 3-dimensional
medium. By solving the diffusion equation, we found that, if the particles’ number
density at time t = 0 was no(x), then at time t it has become
n(x, t) = [1/(4πDt)]3/2

no(x′)e−(x−x′)2/(4Dt)d3x′,
where D is the diffusion coefﬁcient [Eq. (3.73)].
(a) For any one of the diffusing particles, the location y(t) in the y direction (one of
three Cartesian directions) is a 1-dimensional random process. From the above
n(x, t), infer that the conditional probability distribution for y is
P2(y2, t|y1) =
1
√
4πDt
e−(y2−y1)2/(4Dt).
(6.13)
(b) Verify that the conditional probability (6.13) satisﬁes the Smoluchowski equa-
tion (6.11). [Hint: Consider using symbol-manipulation computer software that
quickly can do straightforward calculations like this.]
At ﬁrst this may seem surprising, since a particle’s position y is not Markov.
However (as we explore explicitly in Sec. 6.7.2), the diffusion equation from
which we derived this P2 treats as negligibly small the timescale τr on which
the velocity dy/dt thermalizes. It thereby wipes out all information about what
the particle’s actual velocity is, making y effectively Markov, and forcing its P2 to
6.3 Markov Processes and Gaussian Processes
291

satisfy the Smoluchowski equation. See Ex. 6.10, where we shall also discover that
this diffusion is an example of a random walk.
6.3.2
6.3.2 Gaussian Processes and the Central Limit Theorem; Random Walk
GAUSSIAN PROCESSES
A random process is said to be Gaussian if and only if all of its (absolute) probability
Gaussian random process
distributions are Gaussian (i.e., have the following form):
pn(yn, tn; . . . ; y2, t2; y1, t1) = A exp

−
n
 
j=1
n
 
k=1
αjk(yj −¯y)(yk −¯y)

, (6.14a)
where (i) A and αjk depend only on the time differences t2 −t1, t3 −t1, . . . , tn −t1;
(ii) A is a positive normalization constant; (iii)
"
αjk
#
is a positive-deﬁnite, symmetric
matrix (otherwise pn would not be normalizable); and (iv) ¯y is a constant, which one
readily can show is equal to the ensemble average of y,
¯y ≡⟨y⟩=

yp1(y) dy.
(6.14b)
Since the conditional probabilities are all computable as ratios of absolute proba-
bilities [Eq. (6.4)], the conditional probabilities of a Gaussian process will be Gaussian.
Gaussian random processes are very common in physics. For example, the total
number of particles N(t) in a gas cell that is in statistical equilibrium with a heat bath
is a Gaussian random process (Ex. 5.11d); and the primordial ﬂuctuations that gave
rise to structure in our universe appear to have been Gaussian (Sec. 28.5.3). In fact, as
we saw in Sec. 5.6, macroscopic variables that characterize huge systems in statistical
equilibrium always have Gaussian probability distributions. The underlying reason is
that, when a random process is driven by a large number of statistically independent,
random inﬂuences, its probability distributions become Gaussian. This general fact is a
consequence of the central limit theorem of probability. We state and prove a simple
variant of this theorem.
CENTRAL LIMIT THEOREM (A SIMPLE VERSION)
Let y be a random quantity [not necessarily a random variable y(t); there need not be
central limit theorem
any times involved; however, our applications will be to random variables]. Suppose
that y is characterized by an arbitrary probability distribution p(y) (e.g., that of
Fig. 6.3a), so the probability of the quantity taking on a value between y and y + dy
is p(y)dy. Denote by ¯y the mean value of y, and by σy its standard deviation (also
called its rms ﬂuctuation and the square root of its variance):
¯y ≡⟨y⟩=

yp(y)dy,
(σy)2 ≡⟨(y −¯y)2⟩= ⟨y2⟩−¯y2.
(6.15a)
Randomly draw from this distribution a large number N of values {y1, y2, . . . ,
yN}, and average them to get a number
292
Chapter 6. Random Processes

small N
medium N
large N
(a)
(b)
p( y)
y
p(Y)
Y
FIGURE 6.3 Example of the central limit theorem. (a) The random variable y with the probability
distribution p(y). (b) This variable produces, for various values of N, the variable Y = (y1 + . . . +
yN)/N with the probability distributions p(Y). In the limit of very large N, p(Y) is a Gaussian.
Y ≡1
N
N
 
i=1
yi.
(6.15b)
Repeatthisprocessmanytimes, andexaminetheresultingprobabilitydistribution
for Y. In the limit of arbitrarily large N, that distribution will be Gaussian with mean
and standard deviation
¯Y = ¯y
and
σY =
σy
√
N
,
(6.15c)
that is, it will have the form
p(Y) =
1

2πσY 2 exp

−(Y −¯Y)2
2σY 2

,
(6.15d)
with ¯Y and σY given by Eq. (6.15c). See Fig. 6.3b.
Proof of Central Limit Theorem.
The key to proving this theorem is the Fourier
transform of the probability distribution. (That Fourier transform is called the distri-
bution’s characteristic function, but in this chapter we do not delve into the details of
characteristic functions.) Denote the Fourier transform of p(y) by3
˜py(f ) ≡
 +∞
−∞
ei2πfyp(y)dy =
∞
 
n=0
(i2πf )n
n!
⟨yn⟩.
(6.16a)
The second expression follows from a power series expansion of ei2πfy in the ﬁrst.
Similarly, sinceapowerseriesexpansionanalogoustoEq.(6.16a)mustholdfor ˜pY(f )
and since ⟨Y n⟩can be computed from
⟨Y n⟩= ⟨N−n(y1 + y2 + . . . + yN)n⟩
=

N−n(y1 + . . . + yN)np(y1) . . . p(yN)dy1 . . . dyN,
(6.16b)
3.
See the beginning of Sec. 6.4.2 for the conventions we use for Fourier transforms.
6.3 Markov Processes and Gaussian Processes
293

it must be that
˜pY(f ) =
∞
 
n=0
(i2πf )n
n!
⟨Y n⟩
=

exp[i2πf N−1(y1 + . . . + yN)]p(y1) . . . p(yN)dy1 . . . dyn
=

ei2πfy/Np(y)dy
N
=

1 + i2πf ¯y
N
−(2πf )2⟨y2⟩
2N2
+ O
 1
N3
N
= exp

i2πf ¯y −(2πf )2(⟨y2⟩−¯y2)
2N
+ O
 1
N2

.
(6.16c)
Here the last equality can be obtained by taking the logarithm of the preceding
quantity, expanding in powers of 1/N, and then exponentiating. By inverting the
Fourier transform (6.16c) and using (σy)2 = ⟨y2⟩−¯y2, we obtain for p(Y) the Gaus-
sian (6.15d).
This proof is a good example of the power of Fourier transforms, a power that we
exploit extensively in this chapter. As an important example to which we shall return
later, Ex. 6.4 analyzes the simplest version of a random walk.
EXERCISES
Exercise 6.4 **Example: Random Walk with Discrete Steps of Identical Length
This exercise is designed to make the concept of random processes more familiar and
also to illustrate the central limit theorem.
A particle travels in 1 dimension, along the y axis, making a sequence of steps
yj (labeled by the integer j), each of which is yj = +1 with probability 1/2, or
yj = −1 with probability 1/2.
(a) After N ≫1 steps, the particle has reached location y(N) = y(0) + !N
j=1 yj.
What does the central limit theorem predict for the probability distribution of
y(N)? What are its mean and its standard deviation?
(b) Viewed on lengthscales ≫1, y(N) looks like a continuous random process, so
we shall rename N ≡t. Using the (pseudo)random number generator from your
favorite computer software language, compute a few concrete realizations of y(t)
for 0 < t < 104 and plot them.4 Figure 6.1 above shows one realization of this
random process.
(c) Explain why this random process is Markov.
4.
If you use Mathematica, the command RandomInteger[] generates a pseudorandom number that is
0 with probability 1/2 or 1 with probability 1/2. Therefore, the following simple script will carry out the
desired computation: y = Table[0, {10000}]; For[t = 1, t < 10000, t++, y[[t + 1]] =
y[[t]] + 2 RandomInteger[] - 1]; ListPlot[y, Joined -> True]. This was used to gener-
ate Fig. 6.1.
294
Chapter 6. Random Processes

(d) Use the central limit theorem to infer that the conditional probability P2 for this
random process is
P2(y2, t|y1) =
1
√
2πt
exp

−(y2 −y1)2
2t

.
(6.17)
(e) Notice that this is the same probability distribution as we encountered in the
diffusion exercise (Ex. 6.3) but with D = 1/2. Why did this have to be the
case?
(f) Using an extension of the computer program you wrote in part (b), evaluate
y(t = 104) for 1,000 realizations of this random process, each with y(0) = 0, then
bin the results in bins of width δy = 10, and plot the number of realizations y(104)
that wind up in each bin. Repeat for 10,000 realizations. Compare your plots with
the probability distribution (6.17).
6.3.3
6.3.3 Doob’s Theorem for Gaussian-Markov Processes, and Brownian Motion
Doob’s theorem
A large fraction of the random processes that one meets in physics are Gaussian, and
many are Markov. Therefore, the following remarkable theorem is very important.
Any 1-dimensional random process y(t) that is both Gaussian and Markov has the
following form for its conditional probability distribution P2:
P2(y2, t|y1) =
1
[2πσyt
2]
1
2
exp
'
−(y2 −¯yt)2
2σyt
2
(
,
(6.18a)
where the mean ¯yt and variance σ 2
yt at time t are given by
¯yt = ¯y + e−t/τr(y1 −¯y),
σ 2
yt = (1 −e−2t/τr)σy
2.
(6.18b)
Here ¯y and σy2 are respectively the process’s equilibrium mean and variance (the
values at t →∞), and τr is its relaxation time.This result is Doob’s theorem.5 We shall
prove it in Ex. 6.5, after we have developed some necessary tools.
Note the great power of Doob’s theorem: Because y(t) is Markov, all of its probabil-
ity distributions are computable from this P2 (Ex. 6.1), which in turn is determined by
¯y, σy, and τr. Correspondingly, all statistical properties of a Gaussian-Markov process
are determined by just three parameters: its (equilibrium) mean ¯y and variance σy2,
5.
It is so named because it was ﬁrst formulated and proved by J. L. Doob (1942).
6.3 Markov Processes and Gaussian Processes
295

t = 0
t = 1
σy
t = 0.2τr
t = 0.02τr
t = τr
y2
y1
y—
FIGURE 6.4 Evolution of the conditional probability P2(y2, t|y1) for a Gaussian-Markov
random process [Eq. (6.18a)], as predicted by Doob’s theorem. The correlation function
and spectral density for this process are shown later in the chapter in Fig. 6.8.
and its relaxation time τr. As an example, the ﬁrst absolute probability distribution is
p1(y) = lim
t→∞P2(y, t|y1) =
1

2πσy2
exp
'
−(y −¯y)2
2σy2
(
.
(6.18c)
The time evolution of P2 [Eqs. (6.18a,b)] is plotted in Fig. 6.4. At t = 0 it is a
delta function at y1, in accord with Eq. (6.12a). As t increases, its peak (its mean)
moves toward ¯y, and it spreads out. Ultimately, at t = ∞, its peak asymptotes to ¯y,
and its standard deviation (half-width) asymptotes to σy, so P2 →p1—in accord with
Eqs. (6.12b) and (6.18c).
Brownian motion
An example that we explore in Sec. 6.7.2 is a dust particle being buffeted by air
moleculesinalarge, constant-temperatureroom(Brownianmotion).Aswediscussed
near the beginning of Sec. 6.3.1, any Cartesian component v of the dust particle’s
velocity is a Markov process. It is also Gaussian (because its evolution is inﬂuenced
solely by the independent forces of collisions with a huge number of independent air
molecules), so P2(v, t|v1) is given by Doob’s theorem. In equilibrium, positive and
negative values of the Cartesian velocity component v are equally probable, so ¯v = 0,
which means that 1
2mσv2 = 1
2mv2, which is the equilibrium mean kinetic energy—
a quantity we know to be 1
2kBT from the equipartition theorem (Sec. 4.4.4); thus,
¯v = 0, and σv =

kBT/m. The relaxation time τr is the time required for the particle
to change its velocity substantially, due to collisions with air molecules; we compute
it in Sec. 6.8.1 using the ﬂuctuation-dissipation theorem; see Eq. (6.78).
296
Chapter 6. Random Processes

6.4
6.4 Correlation Functions and Spectral Densities
6.4.1
6.4.1 Correlation Functions; Proof of Doob’s Theorem
Let y(t) be a (realization of a) random process with time average ¯y. Then the corre-
lation function of y(t) is deﬁned by
correlation function
Cy(τ) ≡[y(t) −¯y][y(t + τ) −¯y]≡lim
T →∞
1
T
 +T/2
−T/2
[y(t) −¯y][y(t + τ) −¯y]dt.
(6.19)
This quantity, as its name suggests, is a measure of the extent to which the values of y
at times t and t + τ tend to be correlated. The quantity τ is sometimes called the delay
time, and by convention it is taken to be positive. [One can easily see that, if one also
deﬁnes Cy(τ) for negative delay times τ by Eq. (6.19), then Cy(−τ) = Cy(τ). Thus
nothing is lost by restricting attention to positive delay times.]
As an example, for a Gaussian-Markov process with P2 given by Doob’s formula
(6.18a)(Fig.6.4), wecancomputeC(τ)byreplacingthetimeaverageinEq.(6.19)with
an ensemble average: Cy(τ) =

y2 y1 p2(y2, τ; y1) dy1 dy2. If we use p2(y2, τ; y1) =
P2(y2, τ; y1) p1(y1) [Eq. (6.10)], insert P2 and p1 from Eqs. (6.18), and perform the
integrals, we obtain
Cy(τ) = σy
2e−τ/τr.
(6.20)
This correlation function has two properties that are quite general:
1. The following is true for all (ergodic and stationary) random processes:
properties of correlation
function
Cy(0) = σy
2,
(6.21a)
as one can see by replacing time averages with ensemble averages in deﬁni-
tion (6.19); in particular, Cy(0) ≡(y −¯y)2 = ⟨(y −¯y)2⟩, which by deﬁni-
tion is the variance σy2 of y.
2. In addition, we have that
Cy(τ) asymptotes to zero for τ ≫τr,
(6.21b)
where τr is the process’s relaxation time or correlation time (see Fig. 6.5). This
relaxation time
is true for all ergodic, stationary random processes, since our deﬁnition of
ergodicity in Sec. 6.2.3 relies on each realization y(t) losing its memory of
earlier values after some sufﬁciently long time T . Otherwise, it would not be
possible to construct the ensemble E′ of random variables Y K(t) [Eq. (6.7)]
and have them behave like independent random variables.
6.4 Correlation Functions and Spectral Densities
297

Cy(τ)
τ
τr
σy
2
FIGURE 6.5 Properties (6.21) of correlation functions.
As an example of how one can use correlation functions, in Ex. 6.5 we use them
to prove Doob’s theorem.
EXERCISES
Exercise 6.5 Derivation: Proof of Doob’s Theorem
Prove Doob’s theorem. More speciﬁcally, for any Gaussian-Markov random process,
show that P2(y2, t|y1) is given by Eqs. (6.18a,b).
[Hint: For ease of notation, set ynew = (yold −¯yold)/σyold, so ¯ynew = 0 and
σynew = 1. If the theorem is true for ynew, then by the rescalings inherent in the deﬁ-
nition of P2(y2, t|y1), it will also be true for yold.]
(a) Show that the Gaussian process ynew has probability distributions
p1(y) =
1
√
2π
e−y2/2,
(6.22a)
p2(y2, t2; y1, t1) =
1

(2π)2(1 −C21
2)
exp

−y12 + y22 −2C21y1y2
2(1 −C21
2)

;
(6.22b)
and show that the constant C21 that appears here is the correlation function
C21 = Cy(t2 −t1).
(b) From the relationship between absolute and conditional probabilities [Eq. (6.4)],
show that
P2(y2, t2|y1, t1) =
1

2π(1 −C21
2)
exp

−(y2 −C21y1)2
2(1 −C21
2)

.
(6.22c)
(c) Show that for any three times t3 > t2 > t1,
C31 = C32C21;
i.e.,
Cy(t3 −t1) = Cy(t3 −t2)Cy(t2 −t1).
(6.22d)
To show this, you could (i) use the relationship between absolute and conditional
probabilities and the Markov nature of the random process to infer that
p3(y3, t3; y2, t2; y1, t1) = P3(y3, t3|y2, t2; y1, t1)p2(y2, t2; y1, t1)
= P2(y3, t3|y2, t2)p2(y2, t2; y1, t1);
298
Chapter 6. Random Processes

then (ii) compute the last expression explicitly, getting
1

2π(1 −C32
2)
exp

−(y3 −C32y2)2
2(1 −C32
2)

×
1

(2π)2(1 −C21
2)
exp

−(y12 + y22 −2C21y1y2)
2(1 −C21
2)

;
(iii) then using this expression, evaluate
Cy(t3 −t1) ≡C31 ≡⟨y(t3)y(t1)⟩=

p3(y3, t3; y2, t2; y1, t1)y3y1dy3dy2dy1.
(6.22e)
The result should be C31 = C32C21.
(d) Argue that the unique solution to this equation, with the “initial condition” that
Cy(0) = σy2 = 1, is Cy(τ) = e−τ/τr, where τr is a constant (which we identify as
the relaxation time). Correspondingly, C21 = e−(t2−t1)/τr.
(e) By inserting this expression into Eq. (6.22c), complete the proof for ynew(t), and
thence conclude that Doob’s theorem is also true for our original, unrescaled
yold(t).
6.4.2
6.4.2 Spectral Densities
There are several different normalization conventions for Fourier transforms. In this
chapter, we adopt a normalization that is commonly (though not always) used in the
theoryofrandomprocessesandthatdiffersfromtheonecommoninquantumtheory.
Speciﬁcally, instead of using the angular frequency ω, we use the ordinary frequency
f ≡ω/(2π). We deﬁne the Fourier transform of a function y(t) and its inverse by
Fourier transform
˜y(f ) ≡
 +∞
−∞
y(t)ei2πf tdt,
y(t) ≡
 +∞
−∞
˜y(f )e−i2πf tdf .
(6.23)
Notice that with this set of conventions, there are no factors of 1/(2π) or 1/
√
2π
multiplying the integrals. Those factors have been absorbed into the df of Eq. (6.23),
since df = dω/(2π).
TheintegralsinEq.(6.23)arenotwelldeﬁnedaswrittenbecausearandomprocess
y(t) is generally presumed to go on forever so its Fourier transform ˜y(f ) is divergent.
One gets around this problem by crude trickery. From y(t) construct, by truncation,
the function
yT (t) ≡
, y(t)
if −T /2 < t < +T /2,
0
otherwise.
(6.24a)
6.4 Correlation Functions and Spectral Densities
299

Then the Fourier transform ˜yT (f ) is ﬁnite, and by Parseval’s theorem (e.g., Arfken,
Weber, and Harris, 2013) it satisﬁes
 +T /2
−T /2
[y(t)]2dt =
 +∞
−∞
[yT (t)]2dt =
 +∞
−∞
| ˜yT (f )|2df = 2
 ∞
0
| ˜yT (f )|2 df .
(6.24b)
In the last equality we have used the fact that because yT (t) is real, ˜y∗
T (f ) = ˜yT (−f ),
where * denotes complex conjugation. Consequently, the integral from −∞to 0 of
| ˜yT (f )|2 is the same as the integral from 0 to +∞. Now, the quantities on the two
sides of (6.24b) diverge in the limit as T →∞, and it is obvious from the left-hand
side that they diverge linearly as T . Correspondingly, the limit
lim
T →∞
1
T
 +T/2
−T/2
[y(t)]2dt = lim
T →∞
2
T
 ∞
0
| ˜yT (f )|2df
(6.24c)
is convergent.
These considerations motivate the following deﬁnition of the spectral density (also
sometimes called the power spectrum) Sy(f ) of the random process y(t):
spectral density
Sy(f ) ≡lim
T →∞
2
T
8888
 +T/2
−T/2
[y(t) −¯y]ei2πf tdt
8888
2
.
(6.25)
Notice that the quantity inside the absolute value sign is just ˜yT (f ), but with the mean
of y removed before computation of the Fourier transform. (The mean is removed to
avoid an uninteresting delta function in Sy(f ) at zero frequency.) Correspondingly,
by virtue of our motivating result (6.24c), the spectral density satisﬁes
 ∞
0
Sy(f )df =
limT →∞
1
T
 +T /2
−T /2 [y(t) −¯y]2dt = (y −¯y)2 = σy2, or
integral of spectral density
 ∞
0
Sy(f )df = Cy(0) = σ 2
y .
(6.26)
Thus the integral of the spectral density of y over all positive frequencies is equal to
the variance of y.
By convention, our spectral density is deﬁned only for nonnegative frequencies f .
This is because, were we to deﬁne it also for negative frequencies, the fact that y(t) is
real would imply that Sy(f ) = Sy(−f ), so the negative frequencies contain no new
information. Our insistence that f be positive goes hand in hand with the factor 2 in
the 2/T of deﬁnition (6.25): that factor 2 folds the negative-frequency part onto the
positive-frequency part. This choice of convention is called the single-sided spectral
density. Sometimes one encounters a double-sided spectral density,
Sdouble-sided
y
(f ) = 1
2Sy(|f |),
(6.27)
in which f is regarded as both positive and negative, and frequency integrals generally
run from −∞to +∞instead of 0 to ∞(see, e.g., Ex. 6.7).
300
Chapter 6. Random Processes

Hδ
frequency f
Hγ
Hβ
Hα
FIGURE 6.6 A spectrum obtained by sending light through a diffraction grating. The intensity of the
image is proportional to dE/dtdf , which, in turn, is proportional to the spectral density SE(f ) of
the electric ﬁeld E(t) of the light that entered the diffraction grating.
Notice that the spectral density has units of y2 per unit frequency; or, more
colloquially (since frequency f is usually measured in Hertz, i.e., cycles per second),
its units are y2/Hz.
6.4.3
6.4.3 Physical Meaning of Spectral Density, Light Spectra,
and Noise in a Gravitational Wave Detector
We can infer the physical meaning of the spectral density from previous experience
with light spectra. Speciﬁcally, consider the scalar electric ﬁeld6 E(t) of a plane-
polarized light wave entering a telescope from a distant star, galaxy, or nebula. (We
must multiply this E(t) by the polarization vector to get the vectorial electric ﬁeld.)
This E(t) is a superposition of emission from an enormous number of atoms, mol-
ecules, and high-energy particles in the source, so it is a Gaussian random process.
It is not hard to convince oneself that E(t)’s spectral density SE(f ) is proportional
to the light power per unit frequency dE/dtdf (the light’s power spectrum) en-
tering the telescope. When we send the light through a diffraction grating, we get
this power spectrum spread out as a function of frequency f in the form of spec-
tral lines superposed on a continuum, as in Fig. 6.6. The amount of light power in
this spectrum, in some narrow bandwidth f centered on some frequency f , is
(dE/dtdf )f ∝SE(f )f (assuming SE is nearly constant over that band).
Another way to understand this role of the spectral density SE(f ) is by examining
the equation for the variance of the oscillating electric ﬁeld E as an integral over
frequency, σE2 =
 ∞
0
SE(f )df . If we ﬁlter the light so only that portion at frequency
f , in a very narrow bandwidth f , gets through the ﬁlter, then the variance of the
ﬁltered, oscillating electric ﬁeld will obviously be the portion of the integral coming
from this frequency band. The rms value of the ﬁltered electric ﬁeld will be the square
root of this—and similarly for any other random process y(t):
rms oscillation
*
rms value of y’s oscillations
at frequency f in a very narrow bandwidth f
+
≃

Sy(f )f .
(6.28)
6.
In this section, and only here, E represents the electric ﬁeld rather than (nonrelativistic) energy.
6.4 Correlation Functions and Spectral Densities
301

Frequency (Hz)
10
100
1,000
10,000
[Sξ( f )]1/2 (m/Hz1/2)
laser
10–15
10–16
10–17
10–18
10–19
10–20
L2
L1
photo-
detector
FIGURE 6.7 The square root of the spectral density of the time-varying arm-length difference
ξ(t) = L1 −L2 (see inset), in the Laser Interferometer Gravitational-wave Observatory (LIGO)
interferometer at Hanford, Washington, as measured on February 22, 2010. See Sec. 9.5 and Fig. 9.13.
The dark blue curve is the noise that was speciﬁed as this instrument’s goal. The narrow spectral lines
(sharp spikes in the spectrum produced by internal resonances in the instrument) contain negligible
power, and so can be ignored for our purposes. At high frequencies, f >∼150 Hz, the noise is due
to randomness in arrival times of photons used to measure the mirror motions (photon shot noise,
Sec. 6.7.4). At intermediate frequencies, 40 Hz <∼f <∼150 Hz, it is primarily thermal noise (end of
Sec. 6.8.2). At low frequencies, f <∼40 Hz, it is primarily mechanical vibrations that sneak through a
vibration isolation system (“seismic” noise).
(In Sec. 6.7.1, we develop a mathematical formalism to describe this type of
ﬁltering).
As a practical example, consider the output of an interferometric gravitational
wave detector (to be further discussed in Secs. 9.5 and 27.6). The gravitational waves
from some distant source (e.g., two colliding black holes) push two mirrors (hanging
by wires) back and forth with respect to each other. Laser interferometry is used to
monitor the difference ξ(t) = L1 −L2 between the two arm lengths. (Here L1 is the
separation between the mirrors in one arm of the interferometer, and L2 is that in
the other arm; see inset in Fig. 6.7.) The measured ξ(t) is inﬂuenced by noise in the
instrument as well as by gravitational waves. Figure 6.7 shows the square root of the
spectral density of the noise-induced ﬂuctuations in ξ(t). Note that this Sξ(f ) has
units of meters/
√
Hertz (since ξ has units of meters).
The minimum of the noise power spectrum is at f ≃150 Hz. If one is searching
amidst this noise for a broadband gravitational-wave signal, then one might ﬁlter the
interferometer output so one’s data analysis sees only a frequency band of order the
frequency of interest: f ≃f . Then the rms noise in this band will be Sξ(f ) × f ≃
10−19 m/
√
Hz ×
√
150 Hz ≃10−18 m, which is ∼1/1,000 the diameter of a proton.
If a gravitational wave with frequency ∼150 Hz changes the mirrors’ separations by
much more than this miniscule amount, it should be detectable!
302
Chapter 6. Random Processes

6.4.4
6.4.4 The Wiener-Khintchine Theorem; Cosmological Density Fluctuations
Wiener-Khintchine
theorem
The Wiener-Khintchine theorem says that, for any random process y(t), the correlation
function Cy(τ) and the spectral density Sy(f ) are the cosine transforms of each other
and thus contain precisely the same information:
Cy(τ) =
 ∞
0
Sy(f ) cos(2πf τ)df ,
Sy(f ) = 4
 ∞
0
Cy(τ) cos(2πf τ)dτ.
(6.29)
The factor 4 results from our folding negative frequencies into positive in our deﬁni-
tion of the spectral density.
Proof of Wiener-Khintchine Theorem.
This theorem is readily proved as a con-
sequence of Parseval’s theorem: Assume, from the outset, that the mean has been
subtracted from y(t), so ¯y = 0. (This is not really a restriction on the proof, since Cy
and Sy are insensitive to the mean of y.) Denote by yT (t) the truncated y of Eq. (6.24a)
and by ˜yT (f ) its Fourier transform. Then the generalization of Parseval’s theorem7
 +∞
−∞
(gh∗+ hg∗)dt =
 +∞
−∞
( ˜g ˜h∗+ ˜h ˜g∗)df
(6.30a)
[withg = yT (t)andh = yT (t + τ)bothrealandwith ˜g = ˜yT (f ), ˜h = ˜yT (f )e−i2πf τ],
states
 +∞
−∞
yT (t)yT (t + τ)dt =
 +∞
−∞
˜y∗
T (f ) ˜yT (f )e−i2πf τ df .
(6.30b)
By dividing by T , taking the limit as T →∞, and using Eqs. (6.19) and (6.25), we
obtain the ﬁrst equality of Eqs. (6.29). The second follows from the ﬁrst by Fourier
inversion.
spectral density as mean
squareofrandomprocess’s
Fourier transform
The Wiener-Khintchine theorem implies (Ex. 6.6) the following formula for the
ensemble averaged self-product of the Fourier transform of the random process y(t):
2⟨˜y(f ) ˜y∗(f ′)⟩= Sy(f )δ(f −f ′).
(6.31)
This equation quantiﬁes the strength of the inﬁnite value of | ˜y(f )|2, which motivated
our deﬁnition (6.25) of the spectral density.
As an application of the Wiener-Khintchine theorem, we can deduce the spectral
density Sy(f ) for any Gaussian-Markov process by performing the cosine transform
of its correlation function Cy(τ) = σy2e−τ/τr [Eq. (6.20)]. The result is
Sy(f ) =
(4/τr)σy2
(2πf )2 + (1/τr)2;
(6.32)
see Fig. 6.8.
7.
This follows by subtracting Parseval’s theorem for g and for h from Parseval’s theorem for g + h.
6.4 Correlation Functions and Spectral Densities
303

Cy
τ
τr
Sy
f
1/(πτr)
(b)
(a)
σy
2
4σy
2τr
Sy ' σy
2/τr
—
π2f 2
FIGURE6.8 (a) The correlation function (6.20) and (b) the spectral density (6.32) for a Gaussian-
Markov process. The conditional probability P2(y2, τ|y1) for this process is shown in Fig. 6.4.
As a second application, in Ex. 6.7 we explore ﬂuctuations in the density of galaxies
in the universe, caused by gravity pulling them into clusters.
EXERCISES
Exercise 6.6 Derivation: Spectral Density as the Mean Square
of Random Process’s Fourier Transform
Derive Eq. (6.31).
[Hint: Write ⟨˜y(f ) ˜y∗(f ′)⟩=
 +∞
−∞
 +∞
−∞⟨y(t)y(t′)⟩ei2πf te−i2πf ′t′dtdt′. Then set
t′ = t + τ, and express the expectation value as Cy(τ), and use an expression for the
Dirac delta function in terms of Fourier transforms.]
Exercise 6.7 **Example: Cosmological Density Fluctuations8
Random processes can be stochastic functions of some variable or variables other than
time. For example, it is conventional to describe fractional ﬂuctuations in the large-
scale distribution of mass in the universe, or the distribution of galaxies, using the
quantity
δ(x) ≡ρ(x) −⟨ρ⟩
⟨ρ⟩
,
or
δ(x) ≡n(x) −⟨n⟩
⟨n⟩
(6.33)
(not to be confused with the Dirac delta function). Here ρ(x) is mass density and n(x)
is the number density of galaxies, which we assume, for didactic purposes, to have
equal mass and to be distributed in the same fashion as the dark matter (Sec. 28.3.2).
This δ(x) is a function of 3-dimensional position rather than 1-dimensional time,
and ⟨.⟩is to be interpreted conceptually as an ensemble average and practically as a
volume average (ergodic hypothesis!).
(a) Deﬁne the Fourier transform of δ over some large averaging volume V as
˜δV (k) =

V
eik.xδ(x)d3x,
(6.34a)
8.
Discussed further in Sec. 28.5.4.
304
Chapter 6. Random Processes

and deﬁne its spectral density (Sec. 28.5.4) by
Pδ(k) ≡lim
V →∞
1
V |˜δV (k)|2.
(6.34b)
(Note that we here use cosmologists’ “double-sided” normalization for Pδ, which
is different from our normalization for a random process in time; we do not fold
negative values of the Cartesian components kj of k onto positive values.) Show
that the two-point correlation function for cosmological density ﬂuctuations,
deﬁned by
ξδ(r) ≡⟨δ(x)δ(x + r)⟩,
(6.34c)
is related to Pδ(k) by the following version of the Wiener-Khintchine theorem:
ξδ(r) =

Pδ(k)e−ik.r d3k
(2π)3 =
 ∞
0
Pδ(k) sinc(kr)k2dk
2π2 ,
(6.35a)
Pδ(k) =

ξδ(r)eik.rd3x =
 ∞
0
ξδ(r) sinc(kr)4πr2dr,
(6.35b)
where sinc x ≡sin x/x. In deriving these expressions, use the fact that the uni-
verse is isotropic to infer that ξδ can depend only on the distance r between points
and not on direction, and Pδ can depend only on the magnitude k of the wave
number and not on its direction.
(b) Figure 6.9 shows observational data for the galaxy correlation function ξδ(r).
These data are rather well approximated at r < 20 Mpc by
ξδ(r) = (ro/r)γ ,
ro ≃7 Mpc,
γ ≃1.8.
(6.36)
(Here 1 Mpc means 1 × 106 parsecs or about 3 × 106 light-years.) Explain why
this implies that galaxies are strongly correlated (they cluster together strongly)
on lengthscales r <∼ro ≃7 Mpc. (Recall that the distance between our Milky Way
galaxy and the nearest other large galaxy, Andromeda, is about 0.8 Mpc.) Use
the Wiener-Khintchine theorem to compute the spectral density Pδ(k) and then
the rms fractional density ﬂuctuations at wave number k in bandwidth k = k.
Fromyouranswer, inferthatthedensityﬂuctuationsareverylargeonlengthscales
-λ = 1/k < ro.
(c) As a more precise measure of these density ﬂuctuations, show that the variance
of the total number N(R) of galaxies inside a sphere of radius R is
σ 2
N = ⟨n⟩2
 ∞
0
dk
2π2k2Pδ(k) W 2(kR),
(6.37a)
where
W(x) = 3(sinc x −cos x)
x2
.
(6.37b)
Evaluate this for the spectral density Pδ(r) that you computed in part (b). [Hint:
Although it is straightforward to calculate this directly, it is faster to regard the
6.4 Correlation Functions and Spectral Densities
305

Comoving separation r (1.5 Mpc)
ξδ(r)
0
100
50
150
1.00
0.30
0.10
0.04
0.02
0.00
−0.02
FIGURE 6.9 The galaxy correlation function ξδ(r) [deﬁned in Eq. (6.34c)], as measured in the
Sloan Digital Sky Survey. Notice that the vertical scale is linear for ξδ <∼0.04 and logarithmic
for larger ξδ. Adapted from Eisenstein et al. (2005).
distribution of galaxies inside the sphere as an inﬁnite distribution multiplied by
a step function in radius and to invoke the convolution theorem.]
6.5
6.5 2-Dimensional Random Processes
Sometimestwo(ormore)randomprocessesarecloselyrelated, andonewantstostudy
their connections. An example is the position x(t) and momentum p(t) of a harmonic
oscillator (Ex. 6.23), and we will encounter other examples in Secs. 28.5 and 28.6. Such
pairs can be regarded as a 2-dimensional random process. In this Track-Two section,
we generalize the concepts of correlation function and spectral density to such related
processes.
6.5.1
6.5.1 Cross Correlation and Correlation Matrix
If x(t) and y(t) are two random processes, then by analogy with the correlation
function Cy(τ) we deﬁne their cross correlation as
cross correlation
Cxy(τ) ≡x(t)y(t + τ).
(6.38a)
306
Chapter 6. Random Processes

When x = y, the cross correlation function becomes the autocorrelation function,
Cyy(τ) interchangeable here with Cy(τ). The matrix
correlation matrix
 Cxx(τ)
Cxy(τ)
Cyx(τ)
Cyy(τ)

≡
 Cx(τ)
Cxy(τ)
Cyx(τ)
Cy(τ)

(6.38b)
can be regarded as a correlation matrix for the 2-dimensional random process
{x(t), y(t)}. Notice that the elements of this matrix satisfy
Cab(−τ) = Cba(τ).
(6.39)
6.5.2
6.5.2 Spectral Densities and the Wiener-Khintchine Theorem
If x(t) and y(t) are two random processes, then by analogy with the spectral density
Sy(f ) we deﬁne their cross spectral density as
cross spectral density
Sxy(f ) = lim
T →∞
2
T
 +T /2
−T /2
[x(t) −¯x]e−2πif tdt
 +T/2
−T/2
[y(t′) −¯y]e+2πif t′dt′.
(6.40a)
Notice that the cross spectral density of a random process with itself is equal to its
spectral density, Syy(f ) = Sy(f ), and is real, but if x(t) and y(t) are different random
processes, then Sxy(f ) is generally complex, with
S∗
xy(f ) = Sxy(−f ) = Syx(f ).
(6.40b)
This relation allows us to conﬁne attention to positive f without any loss of informa-
tion. The Hermitian matrix
spectral density matrix
 Sxx(f )
Sxy(f )
Syx(f )
Syy(f )

=
 Sx(f )
Sxy(f )
Syx(f )
Sy(f )

(6.40c)
can be regarded as a spectral density matrix that describes how the power in the 2-
dimensional random process {x(t), y(t)} is distributed over frequency.
Wiener-Khintchine
theorem for cross spectral
density
A generalization of the 1-dimensional Wiener-Khintchine Theorem (6.29) states
that for any two random processes x(t) and y(t), the cross correlation function Cxy(τ)
and the cross spectral density Sxy(f ) are Fourier transforms of each other and thus
contain precisely the same information:
Cxy(τ) = 1
2
 +∞
−∞
Sxy(f )e−i2πf τdf = 1
2
 ∞
0

Sxy(f )e−i2πf τ + Syx(f )e+i2πf τ
df ,
Sxy(f ) = 2
 ∞
−∞
Cxy(τ)ei2πf τdτ = 2
 ∞
0

Cxy(f )e+i2πf τ + Cyx(f )e−i2πf τ
df .
(6.41)
The factors 1/2 and 2 in these formulas result from folding negative frequencies into
positive in our deﬁnitions of the spectral density. Equations (6.41) can be proved by
thesameParseval-theorem-basedargumentasweusedforthe1-dimensionalWiener-
Khintchine theorem (Sec. 6.4.4).
6.5 2-Dimensional Random Processes
307

The Wiener-Khintchine theorem implies the following formula for the ensemble
averaged product of the Fourier transform of the random processes x(t) and y(t):
cross spectral density
as mean product of
random processes’ Fourier
transforms
2⟨˜x(f ) ˜y∗(f ′)⟩= Sxy(f )δ(f −f ′).
(6.42)
This can be proved by the same argument as we used in Ex. 6.6 to prove its single-
process analog, 2⟨˜y(f ) ˜y∗(f ′)⟩= Sy(f )δ(f −f ′) [Eq. (6.31)].
EXERCISES
Exercise 6.8 Practice: Spectral Density of the Sum of Two Random Processes
Let u and v be two random processes. Show that
Su+v(f ) = Su(f ) + Sv(f ) + Suv(f ) + Svu(f ) = Su(f ) + Sv(f ) + 2ℜSuv(f ),
(6.43)
where ℜdenotes the real part of the argument.
6.6
6.6 Noise and Its Types of Spectra
Experimental physicists and engineers encounter random processes in the form of
noise that is superposed on signals they are trying to measure. Examples include:
1. In radio communication, static on the radio is noise.
2. When modulated laser light is used for optical communication, random
ﬂuctuations in the arrival times of photons always contaminate the signal;
the effects of such ﬂuctuations are called “shot noise” and will be studied in
Sec. 6.6.1.
3. Even the best of atomic clocks fail to tick with absolutely constant angular
frequencies ω. Their frequencies ﬂuctuate ever so slightly relative to an ideal
clock, and those ﬂuctuations can be regarded as noise.
Sometimes the signal that one studies amidst noise is actually itself some very
special noise. (One person’s noise is another person’s signal.) An example is the light
passing through an optical telescope and diffraction grating, discussed in Sec. 6.4.3.
There the electric ﬁeld E(t) of the light from a star is a random process whose
spectral density the astronomer measures as a function of frequency, studying with
great interest features in the spectral lines and continuum. When the source is dim,
the astronomer must try to separate its spectral density from those of noise in the
photodetector and noise of other sources in the sky.
6.6.1
6.6.1 Shot Noise, Flicker Noise, and Random-Walk Noise; Cesium Atomic Clock
Physicists, astronomers, and engineers give names to certain shapes of noise spectra:
white, ﬂicker, and random-
walk spectra
Sy(f ) independent of f —white noise spectrum,
(6.44a)
Sy(f ) ∝1/f —ﬂicker noise spectrum,
(6.44b)
308
Chapter 6. Random Processes

t
(a)
t
(b)
FIGURE 6.10 Examples of two random processes that have ﬂicker noise spectra, Sy(f ) ∝1/f . Adapted
from Press (1978).
Sy(f ) ∝1/f 2—random-walk spectrum.
(6.44c)
white noise
White noise, Sy independent of f , is called “white” because it has equal amounts
of power per unit frequency Sy at all frequencies, just as white light has roughly equal
powers at all light frequencies. Put differently, if y(t) has a white-noise spectrum,
then its rms ﬂuctuations in ﬁxed bandwidth f are independent of frequency f (i.e.,
Sy(f )f is independent of f ).
ﬂicker noise
Flicker noise,Sy ∝1/f , gets its name from the fact that, when one looks at the time
evolutiony(t)ofarandomprocesswithaﬂicker-noisespectrum, oneseesﬂuctuations
(“ﬂickering”) on all timescales, and the rms amplitude of ﬂickering is independent
of the timescale one chooses. Stated more precisely, choose any timescale t and
then choose a frequency f ∼3/t, so one can ﬁt roughly three periods of oscillation
into the chosen timescale. Then the rms amplitude of the ﬂuctuations observed will
be Sy(f )f/3, which is a constant independent of f when the spectrum is that of
ﬂicker noise, Sy ∝1/f . In other words, ﬂicker noise has the same amount of power
in each octave of frequency. Figure 6.10 is an illustration: both graphs shown there
depict random processes with ﬂicker-noise spectra. (The differences between the two
graphs will be explained in Sec. 6.6.2.) No matter what time interval one chooses,
these processes look roughly periodic with one, two, or three oscillations in that time
interval; and the amplitudes of those oscillations are independent of the chosen time
interval. Flicker noise occurs widely in the real world, at low frequencies, for instance,
in many electronic devices, in some atomic clocks, in geophysics (the ﬂow rates of
rivers, ocean currents, etc.), in astrophysics (the light curves of quasars, sunspot
numbers, etc.); even in classical music. For an interesting discussion, see Press (1978).
random-walk noise
Random-walk noise, Sy ∝1/f 2, arises when a random process y(t) undergoes a
random walk. In Sec. 6.7.2, we explore an example: the time evolving position x(t) of
a dust particle buffeted by air molecules—the phenomenon of Brownian motion.
6.6 Noise and Its Types of Spectra
309

1 × 10–19
5 × 10–20
1 × 10–21
1 × 10–20
5 × 10–21
2 × 10–21
10–7
10–6
10–5
f (Hz)
(a)
white
Sω = const
random walk
Sω ~ 1/f 2
(b)
τ (s)
στ
ω–2Sω (Hz–1)
10–4
10–3
10–2
102
103
104
105
106
107 
2 × 10–20
5 × 10–12
1 × 10–13
5 × 10–14
1 × 10–12
5 × 10–13
2 × 10–13
2 × 10–12
FIGURE 6.11 (a) Spectral density of the ﬂuctuations in angular frequency ω of a typical cesium atomic
clock. (b) Square root of the Allan variance for the same clock; see Ex. 6.13. Adapted from Galleani
(2012). The best cesium clocks in 2016 (e.g., the U.S. primary time and frequency standard) have
amplitude noise,

Sω and στ, 1000 times lower than this.
Notice that for a Gaussian-Markov process, the spectrum [Eq. (6.32) and Fig. 6.8b]
iswhiteatfrequenciesf ≪1/(2πτr), whereτr istherelaxationtime, anditisrandom-
walk at frequencies f ≫1/(2πτr). This is typical: random processes encountered in
the real world tend to have one type of spectrum over one large frequency interval and
then switch to another type over another large interval. The angular frequency ω of
ticking of a cesium atomic clock is another example.9 It ﬂuctuates slightly with time,
ω = ω(t), with the ﬂuctuation spectral density shown in Fig. 6.11. At low frequencies,
f <∼10−6 Hz (over long timescales t >∼2 weeks), ω exhibits random-walk noise. At
higher frequencies, f >∼10−6 Hz (timescales t <∼2 weeks), it exhibits white noise—
which is just the opposite of a Gaussian-Markov process (see, e.g., Galleani, 2012).
6.6.2
6.6.2 Information Missing from Spectral Density
In experimental studies of noise, attention focuses heavily on the spectral density
Sy(f ) and on quantities that can be computed from it. In the special case of a
Gaussian-Markov process, the spectrum Sy(f ) and the mean ¯y together contain full
information about all statistical properties of the random process. However, most
random processes that one encounters are not Markov (though most are Gaussian).
(When the spectrum deviates from the special form shown in Fig. 6.8, one can be sure
the process is not Gaussian-Markov.) Correspondingly, for most processes the spec-
trum contains only a tiny part of the statistical information required to characterize
9.
The U.S. national primary time and frequency standard is currently (2016) a cesium atomic clock; but
it might be replaced, in a few years, by an atomic clock that oscillates at optical frequencies rather than
the cesium clock’s microwave frequencies. In their current (2016) experimental form, such clocks have
achieved frequency stabilities and accuracies as good as a few ×10−18, nearly 100 times better than the
current U.S. standard. Optical-frequency combs (Sec. 9.4.3) can be used to lock microwave-frequency
oscillators to such optical-frequency clocks.
310
Chapter 6. Random Processes

the process. The two random processes shown in Fig. 6.10 are good examples. They
were constructed on a computer as superpositions of pulses F(t −to) with random
arrival times to and with identical forms
F(t) = 0 for t < 0,
F(t) = K/
√
t for t > 0
(6.45)
(cf. Sec. 6.7.4). The two y(t)s look very different, because the ﬁrst (Fig. 6.10a) in-
volves frequent small pulses, while the second (Fig. 6.10b) involves less frequent,
larger pulses. These differences are obvious to the eye in the time evolutions y(t).
However, they do not show up at all in the spectra Sy(f ), which are identical: both
are ﬂicker spectra (Ex. 6.15). Moreover, the differences do not show up in p1(y1) or
in p2(y2, t2; y1, t1), because the two processes are both superpositions of many in-
dependent pulses and thus are Gaussian, and for Gaussian processes p1 and p2 are
determined fully by the mean and the correlation function, or equivalently by the
mean and spectral density, which are the same for the two processes. Thus, the differ-
ences between the two processes show up only in the probabilities pn of third order
and higher, n ≥3 [as deﬁned in Eq. (6.1)].
6.7
6.7 Filtering Random Processes
6.7.1
6.7.1 Filters, Their Kernels, and the Filtered Spectral Density
In experimental physics and engineering, one often takes a signal y(t) or a random
process y(t) and ﬁlters it to produce a new function w(t) that is a linear functional
of y(t):
w(t) =
 +∞
−∞
K(t −t′)y(t′)dt′.
(6.46)
The quantity y(t) is called the ﬁlter’s input; K(t −t′) is the ﬁlter’s kernel, and w(t) is
a ﬁlter and its input,
output, and kernel
its output. We presume throughout this chapter that the kernel depends only on the
time difference t −t′ and not on absolute time. When this is so, the ﬁlter is said to be
stationary; and when it is violated so K = K(t, t′) depends on absolute time, the ﬁlter
issaidtobenonstationary.Ourrestrictiontostationaryﬁltersgoeshand-in-handwith
our restriction to stationary random processes, since if y(t) is stationary and the ﬁlter
is stationary (as we require), then the ﬁltered process w(t) =
 +∞
−∞K(t −t′)y(t′)dt′
is also stationary.
Some examples of kernels and their ﬁltered outputs are
K(τ) = δ(τ) :
w(t) = y(t),
K(τ) = δ′(τ) :
w(t) = dy/dt,
K(τ) = 0 for τ < 0 and 1 for τ > 0 :
w(t) =
 t
−∞
y(t′)dt′.
(6.47)
Here δ′(τ) denotes the derivative of the Dirac δ-function.
6.7 Filtering Random Processes
311

As with any function, a knowledge of the kernel K(τ) is equivalent to a knowledge
of its Fourier transform:
Fourier transform of ﬁlter’s
kernel
˜K(f ) ≡
 +∞
−∞
K(τ)ei2πf τdτ.
(6.48)
This Fourier transform plays a central role in the theory of ﬁltering (also called the
theory of linear signal processing): the convolution theorem of Fourier transform the-
ory states that, if y(t) is a function whose Fourier transform ˜y(f ) exists (converges),
then the Fourier transform of the ﬁlter’s output w(t) [Eq. (6.46)] is given by
˜w(f ) = ˜K(f ) ˜y(f ).
(6.49)
Similarly, by virtue of the deﬁnition (6.25) of spectral density in terms of Fourier
transforms, if y(t) is a random process with spectral density Sy(f ), then the ﬁlter’s
output w(t) will be a random process with spectral density
spectral density of ﬁlter’s
output
Sw(f ) = | ˜K(f )|2Sy(f ).
(6.50)
[Note that, although ˜K(f ), like all Fourier transforms, is deﬁned for both positive and
negative frequencies, when its modulus is used in Eq. (6.50) to compute the effect of
the ﬁlter on a spectral density, only positive frequencies are relevant; spectral densities
are strictly positive-frequency quantities.]
easy way to compute
kernel’s squared Fourier
transform
The quantity | ˜K(f )|2 that appears in the very important relation (6.50) is most
easily computed not by evaluating directly the Fourier transform (6.48) and then
squaring, but rather by sending the function ei2πf t through the ﬁlter (i.e., by com-
puting the output w that results from the special input y = ei2πf t), and then squaring
the output: | ˜K(f )|2 = |w|2. To see that this works, notice that the result of sending
y = ei2πf t through the ﬁlter is
w =
 +∞
−∞
K(t −t′)ei2πf t′dt′ = ˜K∗(f )ei2πf t,
(6.51)
which differs from ˜K(f ) by complex conjugation and a change of phase, and which
thus has absolute value squared of |w|2 = | ˜K(f )|2.
For example, if w(t) = dny/dtn, then when we set y = ei2πf t, we get w =
dn(ei2πf t)/dtn = (i2πf )nei2πf t;
and,
accordingly,
| ˜K(f )|2 = |w|2 = (2πf )2n,
whence, for any random processy(t), the quantity w(t) = dny/dtn will haveSw(f ) =
(2πf )2nSy(f ).
how differentiation
and integration change
spectral density
This example also shows that by differentiating a random process once, one
changes its spectral density by a multiplicative factor (2πf )2; for example, one can
thereby convert random-walk noise into white noise. Similarly, by integrating a ran-
dom process once in time (the inverse of differentiating), one multiplies its spectral
density by (2πf )−2. If instead one wants to multiply by f −1, one can achieve that
using the ﬁlter whose kernel is
K(τ) = 0 for τ < 0,
K(τ) =
&
2
τ for τ > 0;
(6.52a)
312
Chapter 6. Random Processes

K(τ)
τ
FIGURE 6.12 The kernel (6.52a), whose ﬁlter multi-
plies the spectral density by a factor 1/f , thereby
converts white noise into ﬂicker noise and ﬂicker
noise into random-walk noise.
see Fig. 6.12. Speciﬁcally, it is easy to show, by sending a sinusoid through this ﬁlter,
that
w(t) ≡
 t
−∞
&
2
t −t′y(t′)dt′
(6.52b)
has spectral density
Sw(f ) = 1
f Sy(f ).
(6.52c)
Thus by ﬁltering in this way, one can convert white noise into ﬂicker noise and ﬂicker
noise into random-walk noise.
EXERCISES
Exercise 6.9 Derivations and Practice: Examples of Filters
(a) Show that the kernels K(τ) in Eq. (6.47) produce the indicated outputs w(t). De-
duce the ratio Sw(f )/Sy(f ) = | ˜K(f )|2 in two ways: (i) by Fourier transforming
each K(τ); (ii) by setting y = ei2πf t, deducing the corresponding ﬁltered out-
put w directly from the expression for w in terms of y, and then squaring to get
| ˜K(f )|2.
(b) Derive Eqs. (6.52b) and (6.52c) for the kernel (6.52a).
6.7.2
6.7.2 Brownian Motion and Random Walks
Brownian motion
Asanexampleoftheusesofﬁltering, considerthemotionofanorganellederivedfrom
pollen (henceforth “dust particle”) being buffeted by thermalized air molecules—the
phenomenon of Brownian motion, named for the Scottish botanist Robert Brown
(1828), one of the ﬁrst to observe it in careful experiments. As we discussed in Sec.
6.3.1 and in greater detail at the end of Sec. 6.3.3, any Cartesian component v(t) of
the particle’s velocity is a Gaussian-Markov process, whose statistical properties are
all determined by its equilibrium mean ¯v = 0 and standard deviation σv =

kBT /m,
and its relaxation time τr (which we compute in Sec. 6.8.1). Here m is the particle’s
6.7 Filtering Random Processes
313

mass, and T is the temperature of the air molecules that buffet it. The conditional
probability distribution P2 for v is given by Doob’s theorem:
P2(v2, t|v1) = e−(v2−¯vt)2/(2σvt
2)
[2πσvt
2]
1
2
,
¯vt = v1e−t/τr,
σvt
2 = (1 −e−2t/τr)σ 2
v ,
σv =
&
kBT
m
(6.53a)
[Eqs. (6.18)], and its corresponding correlation function and spectral density have the
standard forms (6.20) and (6.32) for a Gaussian-Markov process:
correlation function and
spectral densities for
Brownian motion
Cv(τ) = σ 2
ve−τ/τr,
Sv(f ) =
4σ 2
v/τr
(2πf )2 + (1/τr)2 .
(6.53b)
The Cartesian coordinate (position) of the dust particle, x(t) =

vdt, is of spe-
cial interest. Its spectral density can be deduced by applying the time-integral ﬁlter
| ˜K(f )|2 = 1/(2πf )2 to Sv(f ). The result, using Eq. (6.53b), is
Sx(f ) =
4τrσ 2
v
(2πf )2[1 + (2πf τr)2].
(6.53c)
Notice that at frequencies f ≪1/τr (corresponding to times long compared to the
relaxation time), our result (6.53c) reduces to the random-walk spectrum Sx =
4σ 2
vτr/(2πf )2. From this spectrum, we can compute the rms distance σx in the
x direction that the dust particle travels in a time interval τ ≫τr. That σx is the
standard deviation of the random process x(t) ≡x(t + τ) −x(t). The ﬁlter that
takes x(t) into x(t) has
| ˜K(f )|2 = |ei2πf (t+τ) −ei2πf t|2 = 4 sin2(πf τ).
(6.54a)
Correspondingly, x(t) has spectral density
Sx(f ) = | ˜K(f )|2Sx(f ) = 4σ 2
vτr(τ)2 sinc2(πf τ)
(6.54b)
(where, again, sinc u ≡sin u/u), so the variance of x (i.e., the square of the rms
distance traveled) is
(σx)2 =
 ∞
0
Sx(f )df = 2(σvτr)2τ
τr
.
(6.54c)
This equation has a simple physical interpretation. The damping time τr is the
time required for collisions to change substantially the dust particle’s momentum, so
we can think of it as the duration of a single step in the particle’s random walk. The
particle’s mean speed is roughly
√
2σv, so the distance traveled during each step (the
particle’s mean free path) is roughly
√
2σvτr. (The
√
2 comes from our analysis; this
physical argument could not have predicted it.) Therefore, during a time interval τ
long compared to a single step τr, the rms distance traveled in the x direction by the
314
Chapter 6. Random Processes

random-walking dust particle is about one mean-free path
√
2σvτr, multiplied by the
square root of the mean number of steps taken, √τ/τr:
rms distance traveled in
Brownian motion
σx =
√
2σvτr

τ/τr.
(6.55)
This “square root of the number of steps taken” behavior is a universal rule of
thumb for random walks; one meets it time and again in science, engineering, and
mathematics. We have met it previously in our studies of diffusion (Exs. 3.17 and 6.3)
and of the elementary “unit step” random walk problem that we studied using the
central limit theorem in Ex. 6.4. We could have guessed Eq. (6.55) from this rule of
thumb, up to an unknown multiplicative factor of order unity. Our analysis has told
us that factor:
√
2.
EXERCISES
Exercise 6.10 Example: Position, Viewed on Timescales τ ≫τr, as a Markov Process
(a) Explain why, physically, when the Brownian motion of a particle (which starts at
x = 0 at time t = 0) is observed only on timescales τ ≫τr corresponding to
frequencies f ≪1/τr, its position x(t) must be a Gaussian-Markov process with
¯x = 0. What are the spectral density of x(t) and its relaxation time in this case?
(b) Use Doob’s theorem to compute the conditional probabilityP2(x2, τ|x1). Your an-
swer should agree with the result deduced in Ex. 6.3 from the diffusion equation,
and in Ex. 6.4 from the central limit theorem for a random walk.
6.7.3
6.7.3 Extracting a Weak Signal from Noise: Band-Pass Filter, Wiener’s Optimal Filter,
Signal-to-Noise Ratio, and Allan Variance of Clock Noise
In experimental physics and engineering, one often meets a random process Y(t) that
consists of a sinusoidal signal on which is superposed noise y(t):
Y(t) =
√
2Ys cos(2πfot + δo) + y(t).
(6.56a)
[The factor
√
2 is included in Eq. (6.56a) because the time average of the square of
the cosine is 1/2; correspondingly, with the factor
√
2 present, Ys is the rms signal
amplitude.]Weassumethatthefrequencyfo andphaseδo ofthesignalareknown, and
we want to determine the signal’s rms amplitude Ys. The noise y(t) is an impediment
band-pass ﬁlter
to the determination of Ys. To reduce that impediment, we can send Y(t) through a
band-pass ﬁlter centered on the signal frequency fo (i.e., a ﬁlter with a shape like that
of Fig. 6.13).
bandwidth
For such a ﬁlter, with central frequency fo and with bandwidth f ≪fo, the
bandwidth is deﬁned by
f ≡
 ∞
0
| ˜K(f )|2df
| ˜K(fo)|2
.
(6.56b)
6.7 Filtering Random Processes
315

|K˜( f )|2
|K˜( fo)|2
f
f
fo
FIGURE 6.13 A band-pass ﬁlter centered on
frequency fo with bandwidth f .
The output W(t) of such a ﬁlter, when the input is Y(t), has the form
W(t) = | ˜K(fo)|
√
2Ys cos(2πfot + δ1) + w(t),
(6.56c)
where the ﬁrst term is the ﬁltered signal and the second is the ﬁltered noise. The
output signal’s phase δ1 may be different from the input signal’s phase δo, but that
difference can be evaluated in advance for one’s ﬁlter and can be taken into account in
the measurement of Ys; thus it is of no interest to us. Assuming (as we shall) that the
input noise y(t) has spectral density Sy that varies negligibly over the small bandwidth
of the ﬁlter, the ﬁltered noise w(t) will have spectral density
spectral density of
band-pass ﬁlter’s output
Sw(f ) = | ˜K(f )|2Sy(fo).
(6.56d)
This means that w(t) consists of a random superposition of sinusoids all with nearly—
but not quite—the same frequency fo; their frequency spread is f . Now, when
one superposes two sinusoids with frequencies that differ by f ≪fo, the two beat
against each other, producing a modulation with period 1/f . Correspondingly, with
its random superposition of many such sinusoids, the noise w(t) will have the form
w(t) = wo(t) cos[2πfot + φ(t)],
(6.56e)
with amplitude wo(t) and phase φ(t) that ﬂuctuate randomly on timescales
t ∼1/f ,
(6.56f)
but that are nearly constant on timescales t ≪1/f .
band-pass ﬁlter’s output in
time domain
The ﬁlter’s net output W(t) thus consists of a precisely sinusoidal signal at fre-
quency fo, with known phase δ1 and with an amplitude that we wish to determine,
plus noise w(t) that is also sinusoidal at frequency fo but with amplitude and phase
that wander randomly on timescales t ∼1/f . The rms output signal is
S ≡| ˜K(fo)|Ys
(6.56g)
316
Chapter 6. Random Processes

[Eq. (6.56c)], while the rms output noise is
N ≡σw =
 ∞
0
Sw(f )df
 1
2
=

Sy(fo)
 ∞
0
| ˜K(f )|2df
 1
2
= | ˜K(fo)|

Sy(fo)f ,
(6.56h)
where the ﬁrst integral follows from Eq. (6.26), the second from Eq. (6.56d), and
the third from the deﬁnition (6.56b) of the bandwidth f . The ratio of the rms
signal (6.56g) to the rms noise (6.56h) after ﬁltering is
signal-to-noise ratio for
band-pass ﬁlter
S
N =
Ys
Sy(fo)f .
(6.57)
Thus, the rms output S + N of the ﬁlter is the signal amplitude to within an rms
fractional error N/S given by the reciprocal of (6.57). Notice that the narrower the
ﬁlter’sbandwidth, themoreaccuratewillbethemeasurementofthesignal.Inpractice,
of course, one does not know the signal frequency with complete precision in advance;
correspondingly, onedoesnotwanttomakeone’sﬁltersonarrowthatthesignalmight
be lost from it.
A simple example of a band-pass ﬁlter is the following ﬁnite Fourier transform
ﬁlter:
w(t) =
 t
t−t
cos[2πfo(t −t′)]y(t′)dt′,
where t ≫1/fo.
(6.58a)
In Ex. 6.11 it is shown that this is indeed a band-pass ﬁlter, and that the integration
time t used in the Fourier transform is related to the ﬁlter’s bandwidth by
f = 1/t.
(6.58b)
Oftenthesignaloneseeksamidstnoiseisnotsinusoidalbuthassomeotherknown
form s(t). In this case, the optimal way to search for it is with a so-called Wiener ﬁlter
(an alternative to the band-pass ﬁlter); see the very important Ex. 6.12.
EXERCISES
Exercise 6.11 Derivation and Example: Bandwidths
of a Finite-Fourier-Transform Filter and an Averaging Filter
(a) If y is a random process with spectral density Sy(f ), and w(t) is the output of the
ﬁnite-Fourier-transform ﬁlter (6.58a), what is Sw(f )?
(b) Sketchtheﬁlterfunction| ˜K(f )|2 forthisﬁnite-Fourier-transformﬁlter, andshow
that its bandwidth is given by Eq. (6.58b).
(c) An“averagingﬁlter”isonethataveragesitsinputoversomeﬁxedtimeintervalt:
w(t) ≡1
t
 t
t−t
y(t′)dt′.
(6.59a)
What is | ˜K(f )|2 for this ﬁlter? Draw a sketch of this | ˜K(f )|2.
6.7 Filtering Random Processes
317

(d) Suppose that y(t) has a spectral density that is very nearly constant at all frequen-
cies, f <∼1/t, and that this y is put through the averaging ﬁlter (6.59a). Show
that the rms ﬂuctuations in the averaged output w(t) are
σw =

Sy(0)f ,
(6.59b)
where f , interpretable as the bandwidth of the averaging ﬁlter, is
f =
1
2t .
(6.59c)
(Recall that in our formalism we insist that f be nonnegative.) Why is there a
factor 1/2 here and not one in the equation for an averaging ﬁlter [Eq. (6.58b)]?
Because here, with f restricted to positive frequencies and the ﬁlter centered on
zero frequency, we see only the right half of the ﬁlter: f ≥fo = 0 in Fig. 6.13.
Exercise 6.12 **Example: Wiener’s Optimal Filter
Suppose that you have a noisy receiver of weak signals (e.g., a communications
receiver). You are expecting a signal s(t) with ﬁnite duration and known form to
come in, beginning at a predetermined time t = 0, but you are not sure whether it is
present. If it is present, then your receiver’s output will be
Y(t) = s(t) + y(t),
(6.60a)
where y(t) is the receiver’s noise, a random process with spectral density Sy(f ) and
with zero mean, ¯y = 0. If it is absent, then Y(t) = y(t). A powerful way to ﬁnd out
whether the signal is present is by passing Y(t) through a ﬁlter with a carefully chosen
kernel K(t). More speciﬁcally, compute the quantity
W ≡
 +∞
−∞
K(t)Y(t)dt.
(6.60b)
If K(t) is chosen optimally, then W will be maximally sensitive to the signal s(t) in
the presence of the noise y(t). Correspondingly, if W is large, you infer that the signal
was present; if it is small, you infer that the signal was either absent or so weak as
not to be detectable. This exercise derives the form of the optimal ﬁlter, K(t) (i.e., the
ﬁlter that will most effectively discern whether the signal is present). As tools in the
derivation, we use the quantities S and N deﬁned by
S ≡
 +∞
−∞
K(t)s(t)dt,
N ≡
 +∞
−∞
K(t)y(t)dt.
(6.60c)
Note that S is the ﬁltered signal, N is the ﬁltered noise, and W = S + N. Since K(t)
and s(t) are precisely deﬁned functions, S is a number. But since y(t) is a random
process, the value of N is not predictable, and instead is given by some probability
distribution p1(N). We shall also need the Fourier transform ˜K(f ) of the kernel K(t).
(a) In the measurement being done one is not ﬁltering a function of time to get
a new function of time; rather, one is just computing a number, W = S + N.
318
Chapter 6. Random Processes

Nevertheless, as an aid in deriving the optimal ﬁlter it is helpful to consider the
time-dependent output of the ﬁlter that results when noise y(t) is fed continu-
ously into it:
N(t) ≡
 +∞
−∞
K(t −t′)y(t′)dt′.
(6.61a)
Show that this random process has a mean squared value
N2 =
 ∞
0
| ˜K(f )|2Sy(f )df .
(6.61b)
Explain why this quantity is equal to the average of the number N2 computed
using (6.60c) in an ensemble of many experiments:
N2 = ⟨N2⟩≡

p1(N)N2dN =
 ∞
0
| ˜K(f )|2Sy(f )df .
(6.61c)
(b) ShowthatofallchoicesofthekernelK(t), theonethatwillgivethelargestvalueof
S
⟨N2⟩
1
2
(6.61d)
is Norbert Wiener’s (1949) optimal ﬁlter,whose kernel has the Fourier transform
Wiener’s optimal ﬁlter
˜K(f ) = const × ˜s(f )
Sy(f ) ,
(6.62a)
where ˜s(f ) is the Fourier transform of the signal s(t), and Sy(f ) is the spectral
density of the noise. Note that when the noise is white, so Sy(f ) is independent of
f , this optimal kernel is just K(t) = const × s(t) (i.e., one should simply multiply
the known signal form into the receiver’s output and integrate). By contrast, when
the noise is not white, the optimal kernel (6.62a) is a distortion of const × s(t)
in which frequency components at which the noise is large are suppressed, while
frequency components at which the noise is small are enhanced.
(c) Show that when the optimal kernel (6.62a) is used, the square of the signal-to-
noise ratio is
signal-to-noise ratio for
Wiener’s optimal ﬁlter
S2
⟨N2⟩= 4
 ∞
0
|˜s(f )|2
Sy(f ) df .
(6.62b)
(d) As an example, suppose the signal consists of n cycles of some complicated
waveform with frequencies spread out over the range fo/2 to 2fo with amplitude
∼A for its entire duration. Also suppose that Sy is approximately constant (near
white noise) over this frequency band. Show that S/⟨N2⟩1/2 ∼2nA/foSy(fo),
so the amplitude signal to noise increases linearly with the number of cycles in
the signal.
6.7 Filtering Random Processes
319

(e) Suppose(asanidealizationofsearchesforgravitationalwavesinnoisyLIGOdata)
that (i) we do not know the signal s(t) in advance, but we do know that it is from a
set of N distinct signals, all of which have frequency content concentrated around
some fo; (ii) we do not know when the signal will arrive, but we search for it for a
long time τs (say, a year); and (iii) the noise superposed on the signal is Gaussian.
Show that, in order to have 99% conﬁdence that any signal found is real, it
must have amplitude signal-to-noise ratio of S/⟨N2⟩1/2 >∼[2 ln(H/
√
2 ln H)]1/2,
whereH = 100Nfoτs.ForN ∼104, fo ∼100 Hz, τs ∼1 yr, thissaysS/⟨N2⟩1/2 >∼
8.2. This is so small because the Gaussian probability distribution falls off so
rapidly. If the noise is non-Gaussian, then the minimum detectable signal will
be larger than this, possibly much larger.
Exercise 6.13 **Example: Allan Variance of Clocks
Highly stable clocks (e.g., cesium clocks, hydrogen maser clocks, or quartz crystal
oscillators) have angular frequencies ω of ticking that tend to wander so much over
very long timescales that their variances diverge. For example, a cesium clock has
random-walk noise on very long timescales (low frequencies)
Sω(f ) ∝1/f 2
at low f ;
(6.63a)
and correspondingly,
σω
2 =
 ∞
0
Sω(f )df = ∞
(6.63b)
(cf.Fig.6.11andassociateddiscussion).Forthisreason, clockmakershaveintroduced
a special technique for quantifying the frequency ﬂuctuations of their clocks. Using
the phase
φ(t) =
 t
0
ω(t′)dt′,
(6.64a)
they deﬁne the quantity
τ(t) = [φ(t + 2τ) −φ(t + τ)]−[φ(t + τ) −φ(t)]
√
2 ¯ωτ
,
(6.64b)
where ¯ω is the mean frequency. Aside from the
√
2, this τ(t) is the fractional
difference of clock readings for two successive intervals of duration τ. (In practice
the measurement of t is made by a clock more accurate than the one being studied;
or, if a more accurate clock is not available, by a clock or ensemble of clocks of the
same type as is being studied.)
(a) Show that the spectral density of τ(t) is related to that of ω(t) by
Sτ(f ) = 2
¯ω2
cos 2πf τ −1
2πf τ
2
Sω(f )
∝f 2Sω(f ) at f ≪1/(2πτ)
(6.65)
∝f −2Sω(f ) at f ≫1/(2πτ).
320
Chapter 6. Random Processes

Note that Sτ(f ) is much better behaved (more strongly convergent when inte-
grated) than Sω(f ) is, both at low frequencies and at high.
(b) The Allan variance of the clock is deﬁned as
στ
2 ≡[ variance of τ(t)]=
 ∞
0
Sτ(f )df .
(6.66)
Show that
στ =
'
α Sω

1/(2τ)

¯ω2
1
2τ
( 1
2
,
(6.67)
where α is a constant of order unity that depends on the spectral shape of Sω(f )
near f = 1/(2τ). Explain why, aside from the factor α, the right-hand side of Eq.
(6.67) is the rms fractional ﬂuctuation of ω at frequency 1/(2τ) in bandwidth
1/(2τ).
(c) Show that, if ω has a white-noise spectrum, then the clock stability is better for
long averaging times than for short; if ω has a ﬂicker-noise spectrum, then the
clock stability is independent of averaging time; and if ω has a random-walk
spectrum, then the clock stability is better for short averaging times than for long.
(See Fig. 6.11.)
6.7.4
6.7.4 Shot Noise
shot noise
A speciﬁc kind of noise that one frequently meets and frequently wants to ﬁlter is
shot noise. A random process y(t) is said to consist of shot noise if it is a random
superposition of a large number of ﬁnite-duration pulses. In this chapter, we restrict
attention to a simple version of shot noise in which the pulses all have the same shape,
F(τ) (e.g., Fig. 6.14a), but their arrival times ti are random
y(t) =
 
i
F(t −ti),
(6.68a)
as may be the case for individual photons arriving at a photodetector. We denote
by R the mean rate of pulse arrivals (the mean number per second). From the
deﬁnition(6.25)ofspectraldensity, itisstraightforwardtoseethatthespectraldensity
of y is
spectral density of shot
noise
Sy(f ) = 2R| ˜F(f )|2,
(6.68b)
where ˜F(f ) is the Fourier transform of F(τ) (Fig. 6.14). See Ex. 6.14 for proof. If the
pulses are broadband bursts without much substructure in them (as in Fig. 6.14a),
then the duration τp of the pulse is related to the frequency fmax at which the spectral
density starts to cut off by fmax ∼1/τp. Since the correlation function is the cosine
transform of the spectral density, the correlation’s relaxation time is τr ∼1/fmax ∼τp
(Ex. 6.14).
6.7 Filtering Random Processes
321

(b)
(a)
F(τ)
f
τp
τ
1/τp
Sy
FIGURE 6.14 (a) A broadband pulse that produces shot noise by arriving at random
times. (b) The spectral density of the shot noise produced by that pulse.
In the common (but not universal) case that many pulses are on at once on average
(Rτp ≫1), then at any moment of time y(t) is the sum of many random processes.
Correspondingly, the central limit theorem guarantees that y is a Gaussian random
process. Over time intervals smaller than τp ∼τr the process will not generally be
Markov, because a knowledge of both y(t1) and y(t2) gives some rough indication of
how many pulses happen to be on and how many new ones have turned on during
the time interval between t1 and t2 and thus are still in their early stages at time t3; this
knowledge helps one predict y(t3) with greater conﬁdence than if one knew onlyy(t2).
In other words, P3(y3, t3|y2, t2; y1, t1) is not equal to P2(y3, t3|y2, t2), which implies
non-Markov behavior.
By contrast, if many pulses are on at once, and if one takes a coarse-grained view
of time, never examining time intervals as short as τp or shorter, then a knowledge
of y(t1) is of no help in predicting y(t2). All correlations between different times are
lost, so the process is Markov, and (because it is a random superposition of many
independent inﬂuences) it is also Gaussian—an example of the central limit theorem
at work. Thus it must have the standard Gaussian-Markov spectral density (6.32) with
vanishing correlation time τr (i.e., it must be white). Indeed, it is: For f ≪1/τp, the
limit of Eq. (6.68b) for Sy and the corresponding correlation function are
Sy(f ) = 2R| ˜F(0)|2,
Cy(τ) = R| ˜F(0)|2δ(τ).
(6.68c)
This formula remains true if the pulses have different shapes, so long as their Fourier
transforms at zero frequency, ˜Fj(0) =
 ∞
−∞Fjdt, are all the same; see Ex. 6.14b.
As an important example, consider a (nearly) monochromatic beam of light with
angular frequency ωo ∼1015 s−1 and with power (energy per unit time) W(t) that is
being measured by a photodetector. The arriving light consists of discrete photons,
each with its own pulse shape Wj(t −tj),10 which lasts for a time τp long compared
to the light’s period (∼3 × 10−15 s) but short compared to the inverse frequency f −1
at which we measure the photon shot noise. The Fourier transform of Wj at zero
10. For a single photon, Wj(t) is the probability per unit time for the photon’s arrival, times the photon’s
energy ℏωo.
322
Chapter 6. Random Processes

frequency is just ˜Wj(0) =
 ∞
0
Wjdt = ℏω (the total energy carried by the photon),
whichisthesameforallpulses; therateofarrivalofphotonsisR = W/ℏωo.Therefore
the spectral density of the intensity measured by the photodetector is
SW(f ) = 2W ℏω.
(6.69)
In the LIGO interferometer, whose noise power spectrum is shown in Fig. 6.7, this
photon shot noise dominates in the frequency band f >∼200 Hz. (Although SW for
the laser light has white noise, when passed through the interferometer as a ﬁlter, it
produces Sx ∝f 2.)
EXERCISES
Exercise 6.14 Derivation: Shot Noise
(a) Show that for shot noise, y(t) = !
i F(t −ti), the spectral density Sy(f ) is given
byEq.(6.68b).Showthattherelaxationtimeappearinginthecorrelationfunction
is approximately the duration τp of F(t).
(b) Suppose the shapes of Fj(t −tj) are all different instead of being identical but
all last for times <∼τp, and all have the same Fourier transform at zero frequency,
˜Fj(0) =
 ∞
−∞Fjdt = ˜F(0). Show that the shot noise at frequencies f ≪1/τp is
still given by Eq. (6.68c).
Exercise 6.15 Example: Shot Noise with Flicker Spectrum
(a) Show that for shot noise with identical pulses that have the inﬁnitely sharply
peaked shape of Eq. (6.45), the power spectrum has the ﬂicker form Sy ∝1/f
for all f .
(b) Construct realizations of shot noise with ﬂicker spectrum [Eq. (6.68a) with pulse
shape (6.45)] that range from a few large pulses in the time interval observed
to many small pulses, and describe the visual differences; cf. Fig. 6.10 and the
discussion in Sec. 6.6.2.
6.8
6.8 Fluctuation-Dissipation Theorem
6.8.1
6.8.1 Elementary Version of the Fluctuation-Dissipation Theorem; Langevin Equation,
Johnson Noise in a Resistor, and Relaxation Time for Brownian Motion
Frictionisgenerallycausedbyinteractionwiththehugenumberofdegreesoffreedom
of some sort of bath (e.g., the molecules of air against which a moving ball or dust
particle pushes). Those degrees of freedom also produce ﬂuctuating forces. In this
section, we study the relationship between the friction and the ﬂuctuating forces when
the bath is thermalized at some temperature T (so it is a heat bath).
For simplicity, we restrict ourselves to a speciﬁc generalized coordinate q of the
system that will interact with a bath (e.g., the x coordinate of the ball or dust particle).
6.8 Fluctuation-Dissipation Theorem
323

We require just one special property for q: its time derivative ˙q = dq/dt must appear
in the system’s lagrangian as a kinetic energy,
Ekinetic = 1
2m˙q2,
(6.70)
and in no other way. Here m is a (generalized) mass associated with q. Then the
equation of motion for q will have the simple form of Newton’s second law, m¨q = F,
where F includes contributions F from the system itself (e.g., a restoring force in the
case of a normal mode), plus a force Fbath due to the heat bath (i.e., due to all the
degrees of freedom in the bath). This Fbath is a random process whose time average
is a frictional (damping) force proportional to ˙q:
¯Fbath = −R ˙q,
Fbath ≡¯Fbath + F ′.
(6.71)
Here R is the coefﬁcient of friction. The ﬂuctuating part F ′ of Fbath is responsible for
driving q toward statistical equilibrium.
examples:
Three speciﬁc examples, to which we shall return below, are as follows.
dust particle
1. The system might be a dust particle with q its x coordinate and m its mass.
The heat bath might be air molecules at temperature T , which buffet the dust
particle, producing Brownian motion.
electric circuit
2. The system might be an L-C-R circuit (i.e., an electric circuit containing an
inductance L, a capacitance C, and a resistance R) with q the total electric
charge on the top plate of the capacitor. The bath in this case would be the
many mechanical degrees of freedom in the resistor. For such a circuit, the
“equation of motion” is
L¨q + C−1q = Fbath(t) = −R ˙q + F ′,
(6.72)
so the effective mass is the inductance L; the coefﬁcient of friction is the re-
sistance (both denoted R); −R ˙q + F ′ is the total voltage across the resistor;
and F ′ is the ﬂuctuating voltage produced by the resistor’s internal degrees
of freedom (the bath) and so might better be denoted V ′.
normal mode of crystal
3. The system might be the fundamental mode of a 10-kg sapphire crystal with
q its generalized coordinate (cf. Sec. 4.2.1). The heat bath might be all the
other normal modes of vibration of the crystal, with which the fundamental
mode interacts weakly.
LANGEVIN EQUATION
In general, the equation of motion for the generalized coordinate q(t) under the joint
action of (i) the bath’s damping force −R ˙q, (ii) the bath’s ﬂuctuating forces F ′, and
(iii) the system’s internal force F will take the form [cf. Eq. (6.71)]
m¨q + R ˙q = F + F ′(t).
(6.73)
324
Chapter 6. Random Processes

The internal force F is derived from the system’s hamiltonian or lagrangian in the
absence of the heat bath. For the L-C-R circuit of Eq. (6.72) that force is F = −C−1q;
for the dust particle, if the particle were endowed with a charge Q and were in an
external electric ﬁeld with potential (t, x, y, z), it would be F = −Q∂/∂x;for the
normal mode of a crystal, it is F = −mω2q, where ω is the mode’s eigenfrequency.
Because the equation of motion (6.73) involves a driving force F ′(t) that is a ran-
domprocess, onecannotsolveittoobtainq(t).Instead, onemustsolveitinastatistical
way to obtain the evolution of q’s probability distributions pn(q1, t1; . . . ; qn, tn). This
and other evolution equations involving random-process driving terms are called by
stochastic differential
equation
modern mathematicians stochastic differential equations, and there is an extensive
body of mathematical formalism for solving them. In statistical physics the speciﬁc
Langevin equation
stochastic differential equation (6.73) is known as the Langevin equation.
ELEMENTARY FLUCTUATION-DISSIPATION THEOREM
Because the damping force −R ˙q and the ﬂuctuating force F ′ both arise from inter-
action with the same heat bath, there is an intimate connection between them. For
example, the stronger the coupling to the bath, the stronger will be the coefﬁcient of
friction R and the stronger will be F ′. The precise relationship between the dissipa-
tion embodied in R and the ﬂuctuations embodied in F ′ is given by the following
ﬂuctuation-dissipation theorem: At frequencies
elementary ﬂuctuation-
dissipation theorem
f ≪1/τr,
(6.74a)
where τr is the (very short) relaxation time for the ﬂuctuating force F ′, the ﬂuctuating
force has the spectral density
SF ′(f ) = 4R
1
2hf +
hf
ehf/(kBT ) −1

in general,
(6.74b)
SF ′(f ) = 4RkBT
in the classical domain, kBT ≫hf .
(6.74c)
Here T is the temperature of the bath, and h is Planck’s constant.
classical ﬂuctuations
accompanying −R ˙q
−R ˙q
−R ˙q
damping are Gaussian,
Markov, white-noise
processes
Notice that in the classical domain, kBT ≫hf , the spectral density has a white-
noise spectrum. In fact, since we are restricting attention to frequencies at which
F ′ has no self-correlations (f −1 ≫τr), F ′ is Markov; and since it is produced by
interaction with the huge number of degrees of freedom of the bath, F ′ is also
Gaussian. Thus, in the classical domain F ′ is a Gaussian-Markov, white-noise process.
At frequencies f ≫kBT/h (quantum domain), in Eq. (6.74b) the term SF ′ =
4R 1
2hf is associated with vacuum ﬂuctuations of the degrees of freedom that make
up the heat bath (one-half quantum of ﬂuctuations per mode as for any quantum
mechanical simple harmonic oscillator). In addition, the second term, SF ′(f ) =
4Rhf e−hf/(kBT ), associated with thermal excitations of the bath’s degrees of freedom,
is exponentially suppressed because at these high frequencies, the bath’s modes have
exponentiallysmallprobabilitiesofcontaininganyquantaatall.Sinceinthisquantum
6.8 Fluctuation-Dissipation Theorem
325

domain SF ′(f ) does not have the standard Gaussian-Markov frequency dependence
(6.32), in the quantum domain F ′ is not a Gaussian-Markov process.
Proof of the Fluctuation-Dissipation Theorem.
proof of elementary
ﬂuctuation-dissipation
theorem
In principle, we can alter the system’s internal restoring force F without altering its
interactions with the heat bath [i.e., without altering R or SF′(f )]. For simplicity, we
set F to zero so q becomes the coordinate of a free mass. The basic idea of our proof
is to choose a frequency fo at which to evaluate the spectral density of F ′, and then,
in an idealized thought experiment, very weakly couple a harmonic oscillator with
eigenfrequency fo to q. Through that coupling, the oscillator is indirectly damped
by the resistance R of q and is indirectly driven by R’s associated ﬂuctating force
F ′, which arises from a bath with temperature T . After a long time, the oscillator will
reach thermal equilibrium with that bath and will then have the standard thermalized
mean kinetic energy ( ¯E = kBT in the classical regime). We shall compute that mean
energy in terms of SF ′(fo) and thereby deduce SF ′(fo).
The Langevin equation (6.73) and equation of motion for the coupled free mass
and harmonic oscillator are
m¨q + R ˙q = −κQ + F ′(t),
M ¨Q + Mω2
oQ = −κq.
(6.75a)
Here M, Q, and ωo = 2πfo are the oscillator’s mass, coordinate, and angular eigen-
frequency, and κ is the arbitrarily small coupling constant. (The form of the coupling
terms −κQ and −κq in the two equations can be deduced from the coupling’s in-
teraction hamiltonian HI = κqQ.) Equations (6.75a) can be regarded as a ﬁlter to
produce from the ﬂuctuating-force input F ′(t) a resulting motion of the oscillator,
Q(t) =
 +∞
−∞K(t −t′)F ′(t′)dt′. The squared Fourier transform | ˜K(f )|2 of this ﬁl-
ter’s kernel K(t −t′) is readily computed by the standard method [Eq. (6.51) and
associated discussion] of inserting a sinusoid e−iωt (with ω = 2πf ) into the ﬁlter
[i.e., into the differential equations (6.75a)] in place of F ′, then solving for the sinu-
soidal output Q, and then setting | ˜K|2 = |Q|2. The resulting | ˜K|2 is the ratio of the
spectral densities of input and output. We carefully manipulate the resulting | ˜K|2 so
as to bring it into the following standard resonant form:
Sq(f ) = | ˜K(f )|2SF ′(f ) =
|B|2
(ω −ω′
o)2 + (2Mω2
oR|B|2)2]SF ′(f ).
(6.75b)
Here B = κ/[2Mωo(mω2
o + iRωo)]is arbitrarily small because κ is arbitrarily small;
and ω′
o
2 = ω2
o + 4mMω4
o|B|2 is the oscillator’s squared angular eigenfrequency after
coupling to q, and is arbitrarily close to ω2
o because |B|2 is arbitrarily small. In
these equations we have replaced ω by ωo everywhere except in the resonance term
(ω −ω′
o)2 because | ˜K|2 is negligibly small everywhere except near resonance, ω ∼= ωo.
The mean energy of the oscillator, averaged over an arbitrarily long timescale, can
be computed in either of two ways.
326
Chapter 6. Random Processes

1. Because the oscillator is a mode of some boson ﬁeld and is in statistical
equilibrium with a heat bath, its mean occupation number must have the
standard Bose-Einstein value η = 1/[eℏωo/(kBT ) −1], and since each quan-
tum carries an energy ℏωo, the mean energy is
¯E =
ℏωo
eℏωo/(kBT ) −1 + 1
2ℏωo.
(6.75c)
Here we have included the half-quantum of energy associated with the
mode’s vacuum ﬂuctuations.
2. Because on average the energy is half potential and half kinetic, and the
mean potential energy is 1
2mω2
oQ2, and because the ergodic hypothesis tells
us that time averages are the same as ensemble averages, it must be that
¯E = 21
2Mω2
oω2⟨Q2⟩= Mω2
o
 ∞
0
SQ(f ) df .
(6.75d)
By inserting the spectral density (6.75b) and performing the frequency integral with
the help of the narrowness of the resonance, we obtain
¯E = SF ′(fo)
4R
.
(6.75e)
Equating this to our statistical-equilibrium expression (6.75c) for the mean energy,
we see that at the frequency fo = ωo/(2π) the spectral density SF ′(fo) has the
form (6.74b) claimed in the ﬂuctuation-dissipation theorem. Moreover, since fo can
be chosen to be any frequency in the range (6.74a), the spectral density SF ′(f ) has
the claimed form anywhere in this range.
Let us discuss two examples of the elementary ﬂuctuation-dissipation theorem
(6.74):
JOHNSON NOISE IN A RESISTOR
FortheL-C-R circuitofEq.(6.72), R ˙q isthedissipativevoltageacrosstheresistor, and
F ′(t) is the ﬂuctuating voltage [more normally denoted V ′(t)] across the resistor. The
ﬂuctuating voltage is called Johnson noise,and the ﬂuctuation-dissipation relationship
Nyquist’s theorem for
Johnson noise
SV (f ) = 4RkBT (classical regime) is called Nyquist’s theorem, because John Johnson
(1928) discovered the voltage ﬂuctuations V ′(t) experimentally, and Harry Nyquist
(1928) derived the ﬂuctuation-dissipation relationship for a resistor to explain them.
Theﬂuctuation-dissipationtheoremasformulatedhereisageneralizationofNyquist’s
originaltheoremtoanysystemwithkineticenergy 1
2m˙q2 associatedwithageneralized
coordinate q and with frictional dissipation produced by a heat bath.
BROWNIAN MOTION
In Secs. 6.3.3 and 6.7.2, we have studied the Brownian motion of a dust particle being
buffetedbyairmolecules, butuntilnowweomittedanyattempttodeducethemotion’s
relaxation time τr. We now apply the ﬂuctuation-dissipation theorem to deduce τr,
6.8 Fluctuation-Dissipation Theorem
327

using a model in which the particle is idealized as a sphere with mass m and radius a
that, of course, is far larger than the air molecules.
The equation of motion for the dust particle, when we ignore the molecules’ ﬂuc-
tuating forces, is mdv/dt = −Rv. Here the resistance (friction) R due to interaction
with the molecules has a form that depends on whether the molecules’ mean free
path λ is small or large compared to the particle. From the kinetic-theory formula
λ = 1/(nσmol), where n is the number density of molecules and σmol is their cross
section to scatter off each other (roughly their cross sectional area), we can deduce
that for air λ ∼0.1 μm. This is tiny compared to a dust particle’s radius a ∼10 to
1,000 μm. This means that, when interacting with the dust particle, the air molecules
will behave like a ﬂuid. As we shall learn in Chap. 15, the friction for a ﬂuid de-
pends on whether a quantity called the Reynolds number, Re = va/ν, is small or large
compared to unity; here ν ∼10−5 m2 s−1 is the kinematic viscosity of air. Inserting
numbers, we see that Re ∼(v/0.1 m s−1)(a/100 μm). The speeds v of dust particles
being buffeted by air are far smaller than 0.1 m s−1 as anyone who has watched them
in a sunbeam knows, or as you can estimate from Eq. (6.53a). Therefore, the Reynolds
number is small. From an analysis carried out in Sec. 14.3.2, we learn that in this low-
Re ﬂuid regime, the resistance (friction) on our spherical particle with radius a is
[Eq. (14.34)]
R = 6πρνa,
(6.76)
where ρ ∼1 kg m−3 is the density of air. (Notice that this resistance is proportional to
the sphere’s radius a or circumference; if λ were ≫a, then R would be proportional
to the sphere’s cross sectional area, i.e., to a2.)
When we turn on the molecules’ ﬂuctuating force F ′, the particle’s equation of
motion becomes mdv/dt + Rv = F ′. Feeding ei2πf t through this equation in place
of F ′, we get the output v = 1/(R + i2πf m), whose modulus squared then is the ratio
of Sv to SF ′. In this obviously classical regime, the ﬂuctuation-dissipation theorem
states that SF ′ = 4RkBT . Therefore, we have
Sv =
SF ′
R2 + (2πf m)2 =
4RkBT
R2 + (2πf m)2 =
4RkBT /m2
(2πf )2 + (R/m)2 .
(6.77)
By comparing with the Sv that we derived from Doob’s theorem, Eq. (6.53b), we can
relaxation time for
Brownian motion
read off the particle’s rms velocity (in one dimension, x or y or z), σv =

kBT /m—
which agrees with Eq. (6.53a) as it must—and we can also read off the particle’s
relaxation time (not to be confused with the bath’s relaxation time),
τr = m/R = m/(6πρνa).
(6.78)
If we had tried to derive this relaxation time by analyzing the buffeting of the particle
directly, we would have had great difﬁculty. The ﬂuctuation-dissipation theorem,
328
Chapter 6. Random Processes

C
L
R
γ
α
β
FIGURE 6.15 An L-C-R
circuit. See Ex. 6.16.
Doob’s theorem, and the ﬂuid-mechanics analysis of friction on a sphere have made
the task straightforward.
EXERCISES
Exercise 6.16 Practice: Noise in an L-C-R Circuit
Consider an L-C-R circuit as shown in Fig. 6.15. This circuit is governed by the
differential equation (6.72), where F ′ is the ﬂuctuating voltage produced by the
resistor’s microscopic degrees of freedom (so we shall rename it V ′), and F ≡V
vanishes, since there is no driving voltage in the circuit. Assume that the resistor
has temperature T ≫ℏωo/k, where ωo = (LC)−1/2 is the circuit’s resonant angular
frequency, ωo = 2πfo, and also assume that the circuit has a large quality factor (weak
damping) so R ≪1/(ωoC) ≃ωoL.
(a) Initially consider the resistor R decoupled from the rest of the circuit, so current
cannot ﬂow across it. What is the spectral density Vαβ of the voltage across this
resistor?
(b) Now place the resistor into the circuit as shown in Fig. 6.15. The ﬂuctuating
voltage V ′ will produce a ﬂuctuating current I = ˙q in the circuit (where q is the
charge on the capacitor). What is the spectral density of I? And what, now, is the
spectral density Vαβ across the resistor?
(c) What is the spectral density of the voltage Vαγ between points α and γ ? and of
Vβγ?
(d) The voltage Vαβ is averaged from time t = t0 to t = t0 + τ (with τ ≫1/fo), giving
some average value U0. The average is measured once again from t1 to t1 + τ,
giving U1. A long sequence of such measurements gives an ensemble of numbers
{U0, U1, . . . , Un}. What are the mean ¯U and rms deviation U ≡⟨(U −¯U)2⟩
1
2
of this ensemble?
Exercise 6.17 **Example: Detectability of a Sinusoidal Force
that Acts on an Oscillator with Thermal Noise
To measure a very weak sinusoidal force, let the force act on a simple harmonic oscil-
lator with eigenfrequency at or near the force’s frequency, and measure the oscillator’s
6.8 Fluctuation-Dissipation Theorem
329

response. Examples range in physical scale from nanomechanical oscillators (∼1 μm
in size) with eigenfrequency ∼1 GHz that might play a role in future quantum infor-
mation technology (e.g., Chan et al., 2011), to the fundamental mode of a ∼10-kg
sapphire crystal, to a ∼40-kg LIGO mirror on which light pressure produces a restor-
ing force, so its center of mass oscillates mechanically at frequency ∼100 Hz (e.g.,
Abbott et al., 2009a). The oscillator need not be mechanical; for example, it could be
an L-C-R circuit, or a mode of an optical (Fabry-Perot) cavity.
The displacement x(t) of any such oscillator is governed by the driven-harmonic-
oscillator equation
m(¨x + 2
τ∗
˙x + ω2x) = F(t) + F ′(t).
(6.79)
Herem, ω, andτ∗arerespectivelytheeffectivemass, angularfrequency, andamplitude
damping time associated with the oscillator; F(t) is an external driving force; and
F ′(t) is the ﬂuctuating force associated with the dissipation that gives rise to τ∗.
Assume that ωτ∗≫1 (weak damping).
(a) Weak coupling to other modes is responsible for the damping. If the other modes
are thermalized at temperature T , what is the spectral density SF ′(f ) of the
ﬂuctuating force F ′? What is the spectral density Sx(f ) of x?
(b) A very weak sinusoidal force drives the fundamental mode precisely on reso-
nance:
F =
√
2Fs cos ω t.
(6.80)
Here Fs is the rms signal. What is the x(t) produced by this signal force?
(c) A sensor with negligible noise monitors this x(t) and feeds it through a narrow-
band ﬁlter with central frequency f = ω/(2π) and bandwidth f = 1/ˆτ (where
ˆτ is the averaging time used by the ﬁlter). Assume that ˆτ ≫τ∗. What is the rms
thermal noise σx after ﬁltering? Show that the strength Fs of the signal force that
produces a signal x(t) =
√
2xs cos(ωt + δ) with rms amplitude xs equal to σx
and phase δ is
Fs =
1
8mkBT
ˆττ∗
.
(6.81)
This is the minimum detectable force at the “one-σ level.”
(d) Suppose that the force acts at a frequency ωo that differs from the oscillator’s
eigenfrequency ω by an amount |ω −ωo| <∼1/τ∗. What, then, is the minimum
detectable force strength Fs? What might be the advantages and disadvantages of
operating off resonance in this way, versus on resonance?
330
Chapter 6. Random Processes

6.8.2
6.8.2 Generalized Fluctuation-Dissipation Theorem; Thermal Noise
in a Laser Beam’s Measurement of Mirror Motions; Standard Quantum
Limit for Measurement Accuracy and How to Evade It
Not all generalized coordinates q have kinetic energy 1
2m˙q2. An important example
(Levin, 1998) arises when one measures the location of the front of a mirror by
bouncing a laser beam perpendicularly off of it—a common and powerful tool in
modern technology. If the mirror moves along the beam’s optic axis by z, the
distance of the bouncing light’s travel changes by 2z, and the light acquires a phase
shift (2π/λ)2z (with λ the light’s wavelength) that can be read out via interferometry
(Chap. 9). Because the front of the mirror can deform, z is actually the change in
a spatial average of the mirror front’s location z(r, φ; t), an average weighted by the
number of photons that hit a given region. In other words, the (time varying) mirror
position monitored by the light is
q(t) =

z(r, φ; t)e−(r/ro)2
πr2
o
rdφ dr.
(6.82)
Here (r, φ) are cylindrical coordinates centered on the laser beam’s optic axis, and
e−(r/ro)2 is the Gaussian distribution of the beam’s energy ﬂux, so

e−(r/ro)2/(πr2
o)

rdφdr
is the probability that a photon of laser light will hit the mirror at (r, φ) in the range
(dr, dφ).
Because the mirror front’s deformations z(r, φ; t) can be expanded in normal
modes, this q is a linear superposition of the generalized coordinates qj(t) of the mir-
ror’s normal modes of oscillation and its center-of-mass displacement q0(t): q(t) =
q0(t) + !
j Qj(r, φ)qj(t), where Qj(r, φ) is mode j’s displacement eigenfunction
evaluated at the mirror’s face. Each of the generalized coordinates q0 and qj has a ki-
netic energy proportional to ˙q2
j, but this q does not. Therefore, the elementary version
of the ﬂuctuation-dissipation theorem, treated in the previous section, is not valid for
this q.
Fortunately, there is a remarkably powerful generalized ﬂuctuation-dissipation
theorem due to Callen and Welton (1951) that works for this q and all other gen-
eralized coordinates that are coupled to a heat bath. To formulate this theorem, we
must ﬁrst introduce the complex impedance Z(ω) for a generalized coordinate.
Let a sinusoidal external force F = Foe−iωt act on the generalized coordinate q
[soq’scanonicallyconjugatemomentump isbeingdrivenas(dp/dt)drive = Foe−iωt].
Then the velocity of the resulting sinuosoidal motion will be
˙q ≡dq
dt = −iωq =
1
Z(ω)Foe−iωt,
(6.83a)
6.8 Fluctuation-Dissipation Theorem
331

where the real part of each expression is to be taken. This equation can be regarded
as the deﬁnition of q’s complex impedance Z(ω) (ratio of force to velocity); it is
complex impedance for a
generalized coordinate
determined by the system’s details. If the system were completely conservative, then
the impedance would be perfectly imaginary, Z = iI, where I is real. For example, for
a freely moving dust particle in vacuum, driven by a sinusoidal force, the momentum
is p = m˙q (where m is the particle’s mass), the equation of motion is Foe−iωt =
dp/dt = m(d/dt)˙q = m(−iω)˙q, andsotheimpedanceisZ = −imω, whichispurely
imaginary.
The bath prevents the system from being conservative—energy can be fed back
and forth between the generalized coordinate q and the bath’s many degrees of free-
dom. This energy coupling inﬂuences the generalized coordinate q in two important
ways. First, it changes the impedance Z(ω) from purely imaginary to complex,
real and imaginary parts
of complex impedance;
resistance R(ω)
R(ω)
R(ω)
Z(ω) = iI(ω) + R(ω),
(6.83b)
where R is the resistance experienced by q. Correspondingly, when the sinusoidal
force F = Foe−iωt is applied, the resulting motions of q feed energy into the bath,
dissipating power at a rate Wdiss = ⟨ℜ(F)ℜ(˙q)⟩=
4
ℜ(Foe−iωt)ℜ(Foe−iωt/Z)
5
=
4
Fo cos ωt ℜ(1/Z) Fo cos ωt)
5
; that is,
power dissipation rate
Wdiss = 1
2
R
|Z|2F 2
o .
(6.84)
Second, the thermal motions of the bath exert a randomly ﬂuctuating force F ′(t) on
q, driving its generalized momentum as (dp/dt)drive = F ′.
As an example, consider the L-C-R circuit of Eq. (6.72). We can identify the gen-
eralized momentum by shutting off the bath (the resistor and its ﬂuctuating voltage);
writing down the lagrangian for the resulting L-C circuit, L = 1
2L˙q2 −1
2q2/C; and
computing p = ∂L/∂˙q = L˙q. [Equally well, we can identify p from one of Hamilton’s
equations for the hamiltonian H = p2/(2L) + q2/(2C).] We evaluate the impedance
Z(ω) from the equation of motion for this lagrangian with the bath’s resistance re-
stored (but not its ﬂuctuating voltage) and with a sinusoidal voltage V = Voe−iωt
imposed:
Ld ˙q
dt −q
C + R ˙q =

−iωL +
1
−iωC + R

˙q = Voe−iωt.
(6.85a)
Evidently, V = Voe−iωt is the external force F that drives the generalized momentum
p = L˙q, and the complex impedance (ratio of force to velocity) is
Z(ω) = V
˙q = −iωL +
1
−iωC + R.
(6.85b)
This is identical to the impedance as deﬁned in the standard theory of electrical
circuits (which is what motivates our Z = F/˙q deﬁnition of impedance), and as
expected, the real part of this impedance is the circuit’s resistance R.
332
Chapter 6. Random Processes

Returning to our general q, the ﬂuctuating force F ′ (equal to ﬂuctuating voltage
V ′ in the case of the circuit) and the resistance R to an external force both arise from
interaction with the same heat bath. Therefore, it should not be surprising that they
are connected by the generalized ﬂuctuation-dissipation theorem:
generalized ﬂuctuation-
dissipation theorem
SF ′(f ) = 4R(f )
1
2hf +
hf
ehf/(kBT ) −1

in general,
(6.86a)
SF ′(f ) = 4R(f )kBT
in the classical domain, kBT ≫hf ,
(6.86b)
which is valid at all frequencies
f ≪1/τr,
(6.87)
where τr is the (very short) relaxation time for the bath’s ﬂuctuating forces F ′. Here T
isthetemperatureofthebath, hisPlanck’sconstant, andwehavewrittentheresistance
as R(f ) to emphasize that it can depend on frequency f = ω/(2π).
A derivation of this generalized ﬂuctuation-dissipation theorem is sketched in
Ex. 6.18.
spectral density for
generalized coordinate
One is usually less interested in the spectral density of the bath’s force F ′ than in
that of the generalized coordinate q. The deﬁnition (6.83a) of impedance implies
−iω ˜q = ˜F ′/Z(ω) for Fourier transforms, whence Sq = SF ′/[(2πf )2|Z|2]. When
combined with Eqs. (6.86) and (6.84), this implies
Sq(f ) =
8Wdiss
(2πf )2F 2
o
1
2hf +
hf
ehf/(kBT ) −1

in general,
(6.88a)
Sq(f ) = 8WdisskBT
(2πf )2F 2
o
in the classical domain, kBT ≫hf .
(6.88b)
Therefore, to evaluate Sq(f ), one does not need to know the complex impedance
Z(ω). Rather, one only needs the power dissipation Wdiss that results when a sinu-
soidal force Fo is applied to the generalized momentum p that is conjugate to the
coordinate q of interest.
Thelightbeambouncingoffamirror(beginningofthissection)isagoodexample.
To couple the sinusoidal force F(t) = Foe−iωt to the mirror’s generalized coordi-
nate q, we add an interaction term HI = −F(t)q to the mirror’s hamiltonian Hmirror.
Hamilton’s equation for the evolution of the momentum conjugate to q then becomes
dp/dt = −∂[Hmirror −F(t)q]/∂q = ∂Hmirror/∂t + F(t). Thus, F(t) drives p as de-
sired. The form of the interaction term is, by Eq. (6.82) for q,
HI = −F(t)q = −

z(r, φ)F(t)e−(r/ro)2
πr2
o
rdφ dr.
(6.89)
6.8 Fluctuation-Dissipation Theorem
333

This is the mathematical description of a time varying pressure
P = Foe−iωte−(r/ro)2/(πr2
o)
applied to the mirror face, which has coordinate location z(r, φ). Therefore, to com-
pute the spectral density of the mirror’s light-beam-averaged displacement q, at fre-
quency f = ω/(2π), we can
Levin’s method for
computingspectraldensity
of mirror’s light-averaged
displacement
1. apply to the mirror’s front face a pressure with spatial shape the same as that
of the light beam’s energy ﬂux (a Gaussian in our example) and with total
force Foe−iωt;
2. evaluate the power dissipationWdiss produced by this sinusoidally oscillating
pressure; and then
3. insert the ratio Wdiss/F 2
o into Eq. (6.88a) or Eq. (6.88b). This is called Levin’s
(1998) method.
In practice, in this thought experiment the power can be dissipated at many loca-
tions: in the mirror coating (which makes the mirror reﬂective), in the substrate on
which the coating is placed (usually glass, i.e., fused silica), in the attachment of the
mirror to whatever supports it (usually a wire or glass ﬁber), and in the supporting
structure (the wire or ﬁber and the solid object to which it is attached). The dissipa-
tions Wdiss at each of these locations add together, and therefore the ﬂuctuating noises
from the various dissipation locations are additive. Correspondingly, one speaks of
“coating thermal noise,” “substrate thermal noise,” and so forth; physicists making
delicate optical measurements deduce each through a careful computation of its cor-
responding dissipation Wdiss.
In the LIGO interferometer, whose noise power spectrum is shown in Fig. 6.7,
these thermal noises dominate in the intermediate frequency band 40 Hz <∼f <∼
150 Hz.
EXERCISES
Exercise 6.18 Derivation: Generalized Fluctuation-Dissipation Theorem
By a method analogous to that used for the elementary ﬂuctuation-dissipation theo-
rem (Sec. 6.8.1), derive the generalized ﬂuctuation-dissipation theorem [Eqs. (6.86)].
Hints: Consider a thought experiment in which the system’s generalized coordi-
nate q is very weakly coupled to an external oscillator that has a mass M and an
angular eigenfrequency ωo, near which we wish to derive the ﬂuctuation-dissipation
formulas (6.86). Denote by Q and P the external oscillator’s generalized coordinate
and momentum and by κ the arbitrarily weak coupling constant between the oscilla-
tor and q, so the hamiltonian of system plus oscillator plus ﬂuctuating force F ′ acting
on q is
H = Hsystem(q, p, . . .) + P 2
2M + 1
2Mω2
oQ2 + κQq −F ′(t) q.
(6.90)
334
Chapter 6. Random Processes

Here the “. . .” refers to the other degrees of freedom of the system, some of which
might be strongly coupled to q and p (as is the case, e.g., for the laser-measured mirror
discussed in the text).
(a) By combining Hamilton’s equations for q and its conjugate momentum p [which
give Eq. (6.83a) with the appropriate driving force] with those for the external
oscillator (Q, P), derive an equation that shows quantitatively how the force F ′,
acting through q, inﬂuences the oscillator’s coordinate Q:

M(−ω2 + ω′
o
2) −iκ2R
ω|Z|2

˜Q =
κ
iωZ
˜F ′.
(6.91)
Here the tildes denote Fourier transforms; ω = 2πf is the angular frequency at
which the Fourier transforms are evaluated; and ω′
o
2 = ω2
o −κ2I/(ω|Z|2), with
Z = R + iI, is the impedance of q at angular frequency ω.
(b) Show that
SQ =
(κ/ω|Z|)2SF ′
M2(−ω2 + ω′
o
2)2 + κ4R2/(ω|Z|2)2 .
(6.92)
(c) Make the resonance in this equation arbitrarily sharp by choosing the coupling
constant κ arbitrarily small. Then show that the mean energy in the oscillator is
¯E = Mω2
o
 ∞
0
SQ(f )df = SF ′(f = ωo/(2π))
4R
.
(6.93)
(d) By equating this to expression (6.75c) for the mean energy of any oscillator
coupled to a heat bath, deduce the desired generalized ﬂuctuation-dissipation
equations (6.86).
6.9
6.9 Fokker-Planck Equation
In statistical physics, we often want to know the collective inﬂuence of many degrees
of freedom (a bath) on a single (possibly vectorial) degree of freedom q. The bath
might or might not be thermalized. The forces it exerts on q might have short range
(as in molecular collisions buffeting an air molecule or dust particle) or long range
(as in Coulomb forces from many charged particles in a plasma pushing stochastically
on an electron that interests us, or gravitational forces from many stars pulling on a
single star of interest). There might also be long-range, macroscopic forces that pro-
duce anisotropies and/or inhomogeneities (e.g., applied electric or magnetic ﬁelds).
We might want to compute how the bath’s many degrees of freedom inﬂuence, for
example, the diffusion of a particle as embodied in its degree of freedom q. Or we
might want to compute the statistical properties of q for a representative electron in
a plasma and from them deduce the plasma’s transport coefﬁcients (diffusivity, heat
6.9 Fokker-Planck Equation
335

conductivity, and thermal conductivity). Or we might want to know how the gravita-
tional pulls of many stars in the vicinity of a black hole drive the collective evolution
of the stars’ distribution function.
The Fokker-Planck equation is a powerful tool in such situations. To apply it, we
crucial assumption of a
Markov Process
must identify a (possibly vectorial) degree of freedom q to analyze that is Markov. For
the types of problems described here, this is typically the velocity (or a component
of velocity) of a representative particle or star. The Fokker-Planck equation is then a
differential equation for the evolution of the conditional probability distribution P2
[Eq. (6.6b)], or other distribution function, for that Markov degree of freedom. In
Sec. 6.9.1, we present the simplest, 1-dimensional example. Then in Sec. 6.9.3, we
generalize to several dimensions.
6.9.1
6.9.1 Fokker-Planck for a 1-Dimensional Markov Process
For a 1-dimensional Markov process y(t) (e.g., the x component of the velocity of a
particle) being driven by a bath (not necessarily thermalized!) with many degrees of
freedom, the Fokker-Planck equation11 states
1-dimensional Fokker-
Planck equation
∂
∂t P2 = −∂
∂y [A(y)P2]+ 1
2
∂2
∂y2[B(y)P2].
(6.94)
Here P2 = P2(y, t|yo) is to be regarded as a function of the variables y and t with yo
ﬁxed; that is, Eq. (6.94) is to be solved subject to the initial condition
P2(y, 0|yo) = δ(y −yo).
(6.95)
As we shall see later, this Fokker-Planck equation is a generalized diffusion equation
for the probability P2: as time passes, the probability diffuses away from its initial
location, y = yo, spreading gradually out over a wide range of values of y.
In the Fokker-Planck equation (6.94) the function A(y) produces a motion of the
mean away from its initial location, while the function B(y) produces a diffusion of
the probability. If one can deduce the evolution of P2 for very short times by some
other method [e.g., in the case of a dust particle being buffeted by air molecules, by
solving statistically the Langevin equation mdv/dt + Rv = F ′(t)], then from that
short-time evolution one can compute the functions A(y) and B(y):
A(y) = lim
t→0
1
t
 +∞
−∞
(y′ −y)P2(y′, t|y)dy′,
(6.96a)
B(y) = lim
t→0
1
t
 +∞
−∞
(y′ −y)2P2(y′, t|y)dy′.
(6.96b)
11. A very important generalization of this equation is to replace the probability P2 by a particle distribution
function and the Markov process y(t) by the 3-dimensional velocity or momentum of the particles. The
foundations for this generalization are laid in the Track-Two Sec. 6.9.3, and an application is in Ex. 20.8.
336
Chapter 6. Random Processes

(These equations can be deduced by reexpressing the limit as an integral of the time
derivative ∂P2/∂t and then inserting the Fokker-Planck equation and integrating by
parts; Ex. 6.19.) Note that the integral (6.96a) for A(y) is the mean change y in the
value of y that occurs in time t, if at the beginning of t (at t = 0) the value of the
process is precisely y; moreover (since the integral of yP2 is just equal to y, which is
a constant), A(y) is also the rate of change of the mean, d ¯y/dt. Correspondingly we
can write Eq. (6.96a) in the more suggestive form
A(y) = lim
t→0
*
y
t
+
=
d ¯y
dt

t=0
.
(6.97a)
Similarly, the integral (6.96b) for B(y) is the mean-squared change in y, (y)2, if at
the beginning of t the value of the process is precisely y; and (as one can fairly easily
show; Ex. 6.19) it is also the rate of change of the variance σ 2
y =

(y′ −¯y)2P2dy′.
Correspondingly, Eq. (6.96b) can be written as
B(y) = lim
t→0
*
(y)2
t
+
=
*dσ 2
y
dt
+
t=0
.
(6.97b)
It may seem surprising that y and (y)2 can both increase linearly in time for
small times [cf. the t in the denominators of both Eq. (6.97a) and Eq. (6.97b)],
thereby both giving rise to ﬁnite functions A(y) and B(y). In fact, this is so: the linear
evolution of y at small t corresponds to the motion of the mean (i.e., of the peak of
the probability distribution), while the linear evolution of (y)2 corresponds to the
diffusive broadening of the probability distribution.
DERIVATION OF THE FOKKER-PLANCK EQUATION (6.94)
Because y is Markov, it satisﬁes the Smoluchowski equation (6.11), which we rewrite
here with a slight change of notation:
P2(y, t + τ|yo) =
 +∞
−∞
P2(y −ξ , t|yo)P2(y −ξ + ξ , τ|y −ξ)dξ.
(6.98a)
Takeτ tobesmallsoonlysmallξ willcontributetotheintegral, andexpandinaTaylor
series in τ on the left-hand side of (6.98a) and in the ξ of y −ξ on the right-hand side:
P2(y, t|yo) +
∞
 
n=1
1
n!
 ∂n
∂tnP2(y, t|yo)

τ n
=
 +∞
−∞
P2(y, t|yo)P2(y + ξ , τ|y)dξ
+
∞
 
n=1
1
n!
 +∞
−∞
(−ξ)n ∂n
∂yn[P2(y, t|yo)P2(y + ξ , τ|y)]dξ.
(6.98b)
6.9 Fokker-Planck Equation
337

In the ﬁrst integral on the right-hand side the ﬁrst term is independent of ξ and can
be pulled out from under the integral, and the second term then integrates to one;
thereby the ﬁrst integral on the right reduces to P2(y, t|yo), which cancels the ﬁrst
term on the left. The result is then
∞
 
n=1
1
n!
 ∂n
∂tnP2(y, t|yo)

τ n
=
∞
 
n=1
(−1)n
n!
∂n
∂yn

P2(y, t|yo)
 +∞
−∞
ξnP2(y + ξ , τ|y) dξ

.
(6.98c)
Divide by τ, take the limit τ →0, and set ξ ≡y′ −y to obtain
∂
∂t P2(y, t|yo) =
∞
 
n=1
(−1)n
n!
∂n
∂yn[Mn(y)P2(y, t|yo)],
(6.99a)
where
Mn(y) ≡lim
t→0
1
t
 +∞
−∞
(y′ −y)nP2(y′, t|y) dy′
(6.99b)
is the nth moment of the probability distribution P2 after time t. This is a form
of the Fokker-Planck equation that has slightly wider validity than Eq. (6.94). Almost
always, however, theonlynonvanishingfunctionsMn(y)areM1 ≡A, whichdescribes
the linear motion of the mean, and M2 ≡B, which describes the linear growth of the
variance. Other moments of P2 grow as higher powers of t than the ﬁrst power, and
correspondingly, their Mns vanish. Thus, almost always12 (and always, so far as we
are concerned), Eq. (6.99a) reduces to the simpler version (6.94) of the Fokker-Planck
equation.
TIME-INDEPENDENT FOKKER-PLANCK EQUATION
If, as we assume in this chapter, y is ergodic, then p1(y) can be deduced as the limit
of P2(y, t|yo) for arbitrarily large times t. Then (and in general) p1 can be deduced
from the time-independent Fokker-Planck equation:
time-independent Fokker-
Planck equation
−∂
∂y [A(y)p1(y)]+ 1
2
∂2
∂y2[B(y)p1(y)]= 0.
(6.100)
GAUSSIAN-MARKOV PROCESS
For a Gaussian-Markov process, the mathematical form of P2(y2, t|y1) is known from
Doob’s theorem: Eqs. (6.18). In the notation of those equations, the Fokker-Planck
functions A and B are
A(y1) = (d ¯yt/dt)t=0 = −(y1 −¯y)/τr,
and
B(y1) = (dσ 2
yt/dt)t=0 = 2σ 2
y/τr.
12. In practice, when there are important effects not captured by A and B (e.g., in the mathematical theory of
ﬁnance; Hull, 2014), they are usually handled by adding other terms to Eq. (6.94), including sometimes
integrals.
338
Chapter 6. Random Processes

Translating back to the notation of this section, we have
A(y) = −(y −¯y)/τr,
B(y) = 2σ 2
y/τr.
(6.101)
Thus, if we can compute A(y) and B(y) explicitly for a Gaussian-Markov process,
then from them we can read off the process’s relaxation time τr, long-time mean ¯y,
and long-time variance σ 2
y. As examples, in Ex. 6.22 we revisit Brownian motion of a
dust particle in air and in the next section, we analyze laser cooling of atoms. A rather
different example is the evolution of a photon distribution function under Compton
scattering (Sec. 28.6.3).
EXERCISES
Exercise 6.19 Derivation: Equations for A and B
Derive Eqs. (6.96) for A and B from the Fokker-Planck equation (6.94), and then
from Eqs. (6.96) derive Eqs. (6.97).
Exercise 6.20 Problem: Fokker-Planck Equation as Conservation Law for Probability
Show that the Fokker-Planck equation can be interpreted as a conservation law for
probability. What is the probability ﬂux in this conservation law? What is the inter-
pretation of each of its two terms?
Exercise 6.21 Example: Fokker-Planck Coefﬁcients When There Is Direct
Detailed Balance
Consider an electron that can transition between two levels by emitting or absorbing
a photon; and recall (as discussed in Ex. 3.6) that we have argued that the stimu-
lated transitions should be microscopically reversible. This is an example of a general
principle introduced by Boltzmann called detailed balance. In the context of classical
physics, it is usually considered in the context of the time reversibility of the underly-
ing physical equations. For example, if two molecules collide elastically and exchange
energy, the time-reversed process happens with the same probability per unit time
when the colliding particles are in the time-reversed initial states. However, this does
not necessarily imply that the probability of a single molecule changing its velocity
from v to v′ is the same as that of the reverse change. (A high-energy molecule is
more likely to lose energy when one averages over all collisions.)
An important simpliﬁcation happens when the probability of a change in y is
equal to the probability of the opposite change. An example might be a light particle
colliding with a heavy particle for which the recoil can be ignored. Under this more
restrictive condition, we can write that P2(y′, t|y) = P2(y, t|y′). Show that the
Fokker-Planck equation then simpliﬁes (under the usual assumptions) to a standard
diffusion equation:
∂
∂t P2 = 1
2
∂
∂y B(y) ∂
∂y P2.
(6.102)
6.9 Fokker-Planck Equation
339

Of course, there can be other contributions to the total Fokker-Planck coefﬁcients
that do not satisfy this condition, but this simpliﬁcation can be very instructive. An
example described in Sec. 23.3.3 is the quasilinear interaction between waves and
particles in a plasma.
Exercise 6.22 Example: Solution of Fokker-Planck Equation for Brownian
Motion of a Dust Particle
(a) Write down the explicit form of the Langevin equation for the x component of
velocity v(t) of a dust particle interacting with thermalized air molecules.
(b) Suppose that the dust particle has velocity v at time t. By integrating the Langevin
equation, show that its velocity at time t + t is v + v, where
mv + Rvt + O[(t)2]=
 t+t
t
F ′(t′)dt′,
(6.103a)
with R the frictional resistance and m the particle’s mass. Take an ensemble
average of this and use F ′ = 0 to conclude that the function A(v) appearing in
the Fokker-Planck equation (6.94) has the form
A(v) ≡lim
t→0
v
t = −Rv
m .
(6.103b)
Compare this expression with the ﬁrst of Eqs. (6.101) to conclude that the mean
and relaxation time are ¯v = 0 and τr = m/R, respectively, in agreement with the
second of Eqs. (6.53a) in the limit τ →∞and with Eq. (6.78).
(c) From Eq. (6.103a) show that
(v)2 =

−v
τr
t + O[(t)2]+ 1
m
 t+t
t
F ′(t′)dt′
2
.
(6.103c)
Take an ensemble average of this expression,
and use F ′(t1)F ′(t2) =
CF ′(t2 −t1)—together with the Wiener-Khintchine theorem—to evaluate the
terms involving F ′ in terms of SF ′, which in turn is known from the ﬂuctuation-
dissipation theorem. Thereby obtain
B(v) = lim
t→0
(v)2
t
= 2RkBT
m2
.
(6.103d)
Combine with Eq. (6.101) and τr = m/R [from part (b)], to conclude that σ 2
v =
kBT/m, in accord with the last of Eqs. (6.53a).
6.9.2
6.9.2 Optical Molasses: Doppler Cooling of Atoms
The 1997 Nobel Prize was awarded to Steven Chu, Claude Cohen-Tannoudji, and
William D. Phillips for the “development of methods to cool and trap atoms with laser
light” (Chu et al., 1998). In this section, we use the Fokker-Planck equation to analyze
340
Chapter 6. Random Processes

mirror
mirror
0
(a)
(b)
atom
σ′

ω
FIGURE 6.16 Doppler cooling of an atom in a Fabry-Perot cavity. (a) The cavity formed by two mirrors
with laser light bouncing back and forth between them, and the sodium atom at the center. (b) The
cross section σ ′ = dσ/dω for the atom in its ground state to absorb a photon of laser light. The laser
angular frequency ω is tuned to the off-resonance inﬂection point (steepest slope) of σ ′, indicated by
the dot.
one of the most important methods they developed: Doppler cooling, also called laser
cooling or optical molasses.
A neutral sodium atom is placed near the center (waist) of a Fabry-Perot optical
cavity (Sec. 9.4.2), so it is bathed by laser light traveling in both the +z and −z
directions (Fig. 6.16a). The atom absorbs and reemits photons and their momenta,
resulting in a stochastic evolution of its z component of velocity, v. Using the Fokker-
Planck equation to analyze this evolution, we shall discover that, if the light frequency
and power are tuned appropriately, there is a strong resisting force (“optical molasses”)
on the atom as well as a randomizing force. The net effect, after the atom relaxes into
equilibrium with the photon ﬁeld, is a very low effective temperature (∼100 μK) for
the atom’s motion in the z direction.
The atom has a large cross section σ ′ ≡dσ/dω to absorb a photon with angular
frequency ω ≃3.20 × 1015 s−1 (yellow light), thereby getting excited into a state with
energy ℏω ≃2.11 eV. The absorption cross section σ ′(ω) has a narrow resonance
(Lorentzian line shape ∝[1 + (ω −ωo)2/ 2]−1; Fig. 6.16b) with half-width  ≃
10 MHz; and, correspondingly, the excited atom has a half-life 1/  to reemit a photon
and return to its ground state. The laser power is adjusted to make the excitation rate
R equal to ,
R =  ≃107 s−1,
(6.104a)
thereby maximizing the rate of excitations. (At a higher power, the excitation rate
will saturate at 1/ , because the atom spends most of its time excited and waiting to
reemit.)
The laser frequency is tuned to the resonance’s inﬂection point (point of greatest
slope dσ ′/dω on one side of the line), so that, when an atom is moving rightward with
velocity v, the Doppler shift δω/ω = v/c produces a maximal fractional increase in
the cross section and rate for absorbing leftward-moving photons and decrease in
those for rightward-moving photons:
δR
R = δσ ′
σ ′ = 1
σ ′
dσ ′
dω

ωv
c

∼ω

v
c .
(6.104b)
6.9 Fokker-Planck Equation
341

(Here and henceforth “∼” means accurate to within a factor of order unity.) This
results in a net resisting force F ∼δR ℏk on the atom, due to the imbalance in
absorption rates for leftward and rightward photons; here k = ω/c = 10.7 μm−1 is
the photons’ wave number, and ℏk is the momentum absorbed from each photon.
This slow-down force produces a rate of change of the atom’s mean velocity
A = d ¯v
dt ∼−δR ℏk
m
∼−ℏk2
m v.
(6.104c)
Here we have used Eqs. (6.104b) and (6.104a), and ω/c = k; and we have set the slow-
down rate equal to the coefﬁcient A in the Fokker-Planck equation for v [Eq. (6.97a)].
There are two sources of randomness in the atom’s velocity, both of the same
magnitude: statistical randomness (
√
N) in the number of photons absorbed from
the two directions, and randomness in the direction of reemission of photons and
thence in the recoil direction. During a short time interval t, the mean number
of absorptions and reemissions is ∼Rt, so the rms ﬂuctuation in the momentum
transfer to the atom (along the z direction) is ∼ℏk
√
Rt, whence the change of
the variance of the velocity is (v)2 ∼(ℏk)2Rt/m2. (Here m ≃3.82 × 10−26 kg is
the sodium atom’s mass.) Correspondingly, the B coefﬁcient (6.103d) in the Fokker-
Planck equation for v is
B = (v)2
t
∼
ℏk
m
2
R =
ℏk
m
2
.
(6.104d)
From the A and B coefﬁcients [Eqs. (6.104c) and (6.104d)] we infer, with the aid
of Eqs. (6.101), the relaxation time, long-term mean, and long-term variance of the
atom’s velocity along the z direction, and also an effective temperature associated with
the variance:13
τr ∼
m
(ℏk2) = 3 μs,
¯v = 0,
σ 2
v ∼ℏ
m = (0.17 ms−1)2,
Teff = mσ 2
v
kB
∼ℏ
kB
∼8 μK.
(6.105)
It is remarkable how effective this optical molasses can be!
If one wants to cool all components of velocity, one can either impose counter-
propagating laser beams along all three Cartesian axes, or put the atom into a potential
well (inside the Fabry Perot cavity) that deﬂects its direction of motion on a timescale
much less than τr.
This optical molasses technique is widely used today in atomic physics, for ex-
ample, when cooling ensembles of atoms to produce Bose-Einstein condensates
13. The atom’s long-term,
ergodically wandering velocity distribution is Gaussian rather than
Maxwellian, so it is not truly thermalized. However, it has the same velocity variance as a thermal
distribution with temperature ∼ℏ/kB, so we call this its “effective temperature.”
342
Chapter 6. Random Processes

(Sec. 4.9), and for cooling atoms to be used as the ticking mechanisms of atomic
clocks (Fig. 6.11, footnote 9 in Sec. 6.6.1, Ex. 6.13, and associated discussions).
6.9.3
6.9.3 Fokker-Planck for a Multidimensional Markov Process;
Thermal Noise in an Oscillator
Few 1-dimensional random processes are Markov, so only a few can be treated using
the 1-dimensional Fokker-Planck equation. However, it is frequently the case that, if
one augments additional variables into the random process, it becomes Markov. An
important example is a harmonic oscillator driven by a Gaussian random force (Ex.
6.23). Neither the oscillator’s position x(t) nor its velocity v(t) is Markov, but the pair
{x, v} is a 2-dimensional Markov process.
For such a process, and more generally for any n-dimensional Gaussian-Markov
process {y1(t), y2(t), . . . , yn(t)} ≡{y(t)}, the conditional probability distribution
P2(y, t|yo) satisﬁes the following Fokker-Planck equation [the obvious generalization
of Eq. (6.94)]:
multidimensional Fokker-
Planck equation
∂
∂t P2 = −∂
∂yj
[Aj(y)P2]+ 1
2
∂2
∂yj∂yk
[Bjk(y)P2].
(6.106a)
Here the functions Aj and Bjk, by analogy with Eqs. (6.96) and (6.97), are
Aj(y) = lim
t→0
1
t

(y′
j −yj)P2(y′, t|y)dny′ = lim
t→0
yj
t

,
(6.106b)
Bjk(y) = lim
t→0
1
t

(y′
j −yj)(y′
k −yk)P2(y′, t|y)dny′ = lim
t→0
yjyk
t

.
(6.106c)
In Ex. 6.23 we use this Fokker-Planck equation to explore how a harmonic oscillator
settles into equilibrium with a dissipative heat bath. In Ex. 20.8 we apply it to Coulomb
collisions in an ionized plasma.
The multidimensional Fokker-Planck equation can be used to solve the Boltz-
mann transport equation (3.66) for the kinetic-theory distribution function N (p, t)
or (in the conventions of plasma physics) for the velocity distribution f (v, t) (Chap.
20). The reasons are (i) N (p, t) and f (v, t) are the same kind of probability distri-
bution as P2—probabilities for a Markov momentum or velocity—with the exception
that N (p, t) and f (v, t) usually have different initial conditions at time t = 0 than
P2’s delta function [in fact, P2 can be regarded as a Green’s function for N (p, t) and
f (v, t)] and (ii) the initial conditions played no role in our derivation of the Fokker-
Planck equation. In Sec. 20.4.3, we discuss the use of the Fokker-Planck equation to
deduce how long-range Coulomb interactions drive the equilibration of the distri-
bution functions f (v, t) for the velocities of electrons and ions in a plasma. In Sec.
23.3.3, we use the Fokker-Planck equation to study the interaction of electrons and
ions with plasma waves (plasmons).
6.9 Fokker-Planck Equation
343

EXERCISES
Exercise 6.23 **Example: Solution of Fokker-Planck Equation
for Thermal Noise in an Oscillator
Consider a classical simple harmonic oscillator (e.g., the nanomechanical oscillator,
LIGO mass on an optical spring, L-C-R circuit, or optical resonator brieﬂy discussed
in Ex. 6.17). Let the oscillator be coupled weakly to a dissipative heat bath with
temperature T . The Langevin equation for the oscillator’s generalized coordinate x is
Eq. (6.79). The oscillator’s coordinate x(t) and momentum p(t) ≡m˙x together form
a 2-dimensional Gaussian-Markov process and thus obey the 2-dimensional Fokker-
Planck equation (6.106a). As an aid to solving this Fokker-Planck equation, change
variables from {x, p} to the real and imaginary parts X1 and X2 of the oscillator’s
complex amplitude:
x = ℜ[(X1 + iX2)e−iωt]= X1(t) cos ωt + X2(t) sin ωt.
(6.107)
Then {X1, X2} is a Gaussian-Markov process that evolves on a timescale ∼τr.
(a) Show that X1 and X2 obey the Langevin equation
−2ω( ˙X1 + X1/τr) sin ωt + 2ω( ˙X2 + X2/τr) cos ωt = F ′/m.
(6.108a)
(b) To compute the functions Aj(X) and Bjk(X) that appear in the Fokker-Planck
equation(6.106a), choosethetimescalet tobeshortcomparedtotheoscillator’s
damping time τr but long compared to its period 2π/ω. By multiplying the
Langevin equation successively by sin ωt and cos ωt and integrating from t = 0
to t = t, derive equations for the changes X1 and X2 produced during t
by the ﬂuctuating force F ′(t) and its associated dissipation. [Neglect fractional
corrections of order 1/(ωt) and of order t/τr]. Your equations should be
analogous to Eq. (6.103a).
(c) By the same technique as was used in Ex. 6.22, obtain from the equations derived
in part (b) the following forms of the Fokker-Planck functions:
Aj =
−Xj
τr
,
Bjk = 2kBT
mω2τr
δjk.
(6.108b)
(d) Show that the Fokker-Planck equation, obtained by inserting functions (6.108b)
into Eq. (6.106a), has the following Gaussian solution:
P2(X1, X2, t|X(o)
1 , X(o)
2 ) =
1
2πσ 2 exp
'
−(X1 −¯X1)2 + (X2 −¯X2)2
2σ 2
(
, (6.109a)
where the means and variance of the distribution are
¯Xj = X(o)
j e−t/τr,
σ 2 = kBT
mω2
2
1 −e−2t/τr
3
≃
⎧
⎨
⎩
kBT
mω2
2t
τr
for t ≪τr
kBT
mω2
for t ≫τr.
(6.109b)
344
Chapter 6. Random Processes

(e) Discuss the physical meaning of the conditional probability (6.109a).
Discuss its implications for the physics experiment described in Ex. 6.17, when
the signal force acts for a time short compared to τr rather than long.
Bibliographic Note
Random processes are treated in many standard textbooks on statistical physics,
typicallyundertherubricofﬂuctuationsornonequilibriumstatisticalmechanics(and
sometimes not even using the phrase “random process”). We like Kittel (2004), Sethna
(2006), Reif (2008), and Pathria and Beale (2011). A treatise on signal processing that
we recommend, despite its age, is Wainstein and Zubakov (1962). There are a number
of textbooks on random processes (also called “stochastic processes” in book titles),
usually aimed at mathematicians, engineers, or ﬁnance folks (who use the theory of
random processes to try to make lots of money, and often succeed). But we do not like
any of those books as well as the relevant sections in the above statistical mechanics
texts. Nevertheless, you might want to peruse Lax et al. (2006), Van Kampen (2007),
and Paul and Baschnagel (2010).
Bibliographic Note
345


III
PART III
OPTICS
Prior to the twentieth century’s quantum mechanics and opening of the electro-
magnetic spectrum observationally, the study of optics was concerned solely with
visible light.
Reﬂection and refraction of light were ﬁrst described by the Greeks and Arabs and
furtherstudiedbysuchmedievalscholasticsasRogerBacon(thirteenthcentury), who
explained the rainbow and used refraction in the design of crude magnifying lenses
and spectacles. However, it was not until the seventeenth century that there arose a
strong commercial interest in manipulating light, particularly via the telescope and
compound microscope, improved and famously used by Galileo and Newton.
The discovery of Snell’s law in 1621 and observations of diffractive phenomena
by Grimaldi in 1665 stimulated serious speculation about the physical nature of
light. The wave and corpuscular theories were propounded by Huygens in 1678
and Newton in 1704, respectively. The corpuscular theory initially held sway, for
100 years. However, observational studies of interference by Young in 1803 and the
derivation of a wave equation for electromagnetic disturbances by Maxwell in 1865
then seemed to settle the matter in favor of the undulatory theory, only for the debate
to be resurrected in 1887 with the discovery of the photoelectric effect by Hertz. After
quantum mechanics was developed in the 1920s, the dispute was abandoned, the wave
and particle descriptions of light became “complementary,” and Hamilton’s optics-
inspired formulation of classical mechanics was modiﬁed to produce the Schr¨odinger
equation.
Many physics students are all too familiar with this potted history and may con-
sequently regard optics as an ancient precursor to modern physics, one that has been
completely subsumed by quantum mechanics. Not so! Optics has developed dramat-
ically and independently from quantum mechanics in recent decades and is now a
major branch of classical physics. And it is no longer concerned primarily with light.
The principles of optics are routinely applied to all types of wave propagation: for ex-
ample, all parts of the electromagnetic spectrum, quantum mechanical waves (e.g., of
347

electrons and neutrinos), waves in elastic solids (Part IV of this book), ﬂuids (Part V),
plasmas (Part VI), and the geometry of spacetime (Part VII). There is a commonality,
for instance, to seismology, oceanography, and radio physics that allows ideas to be
freely interchanged among these different disciplines. Even the study of visible light
has seen major developments: the invention of the laser has led to the modern theory
of coherence and has begotten the new ﬁeld of nonlinear optics.
An even greater revolution has occurred in optical technology. From the credit
card and white-light hologram to the laser scanner at a supermarket checkout, from
laser printers to CDs, DVDs, and BDs, from radio telescopes capable of nanoradian
angular resolution to Fabry-Perot systems that detect displacements smaller than the
size of an elementary particle, we are surrounded by sophisticated optical devices
in our everyday and scientiﬁc lives. Many of these devices turn out to be clever and
direct applications of the fundamental optical principles that we discuss in this part
of the book.
Our treatment of optics in this part differs from that found in traditional texts,
in that we assume familiarity with basic classical mechanics and quantum mechanics
and, consequently, ﬂuency in the language of Fourier transforms. This inversion of the
historical development reﬂects contemporary priorities and allows us to emphasize
those aspects of the subject that involve fresh concepts and modern applications.
In Chap. 7, we discuss optical (wave-propagation) phenomena in the geometric
optics approximation. This approximation is accurate when the wavelength and the
wave period are short compared with the lengthscales and timescales on which the
wave amplitude and the waves’ environment vary. We show how a wave equation
can be solved approximately, with optical rays becoming the classical trajectories of
quantum particles (photons, phonons, plasmons, and gravitons) and the wave ﬁeld
propagating along these trajectories. We also show how, in general, these trajectories
develop singularities or caustics where the geometric optics approximation breaks
down, and we must revert to the wave description.
In Chap. 8, we develop the theory of diffraction that arises when the geometric
optics approximation fails, and the waves’ energy spreads in a non-particle-like way.
We analyze diffraction in two limiting regimes, called “Fresnel” and “Fraunhofer”
(after the physicists who discovered them), in which the wavefronts are approximately
planar or spherical, respectively. As we are working with a linear theory of wave
propagation, we make heavy use of Fourier methods and show how elementary
applications of Fourier transforms can be used to design powerful optics instruments.
Most elementary diffractive phenomena involve the superposition of an inﬁnite
number of waves. However, in many optical applications, only a small number of
waves from a common source are combined. This is known as interference and is the
subject of Chap. 9. In this chapter, we also introduce the notion of coherence, which is
a quantitative measure of the distributions of the combining waves and their capacity
to interfere constructively.
348
Part III

The ﬁnal chapter on optics, Chap. 10, is concerned with nonlinear phenomena
that arise when waves, propagating through a medium, become sufﬁciently strong to
couple to one another. These nonlinear phenomena can occur for all types of waves
(wemeetthemforﬂuidwavesinSec.16.3andplasmawavesinChap.23).Forlight(the
focus of Chap. 10), nonlinearities have become especially important in recent years;
the nonlinear effects that arise when laser light is shone through certain crystals are
having a strong impact on technology and on fundamental scientiﬁc research. We
explore several examples.
Optics
349


7
CHAPTER SEVEN
Geometric Optics
Solar rays parallel to OB and passing through this solid are refracted at the hyperbolic surface,
and the refracted rays converge at A.
IBN SAHL (984)
7.1
7.1 Overview
Geometric optics, the study of “rays,” is the oldest approach to optics. It is an accurate
description of wave propagation when the wavelengths and periods of the waves are
far smaller than the lengthscales and timescales on which the wave amplitude and the
medium supporting the waves vary.
After reviewing wave propagation in a homogeneous medium (Sec. 7.2), we begin
our study of geometric optics in Sec. 7.3. There we derive the geometric-optics prop-
agation equations with the aid of the eikonal approximation, and we elucidate the
connection to Hamilton-Jacobi theory (which we assume the reader has already en-
countered). This connection is made more explicit by demonstrating that a classical,
geometric-optics wave can be interpreted as a ﬂux of quanta. In Sec. 7.4, we special-
ize the geometric-optics formalism to any situation where a bundle of nearly parallel
rays is being guided and manipulated by some sort of apparatus. This is the parax-
ial approximation, and we illustrate it with a magnetically focused beam of charged
particles and show how matrix methods can be used to describe the particle (i.e., ray)
trajectories. In Sec. 7.5, we explore how imperfect optics can produce multiple images
of a distant source, and that as one moves from one location to another, the images
appear and disappear in pairs. Locations where this happens are called “caustics” and
are governed by catastrophe theory, a topic we explore brieﬂy. In Sec. 7.6, we describe
gravitational lenses, remarkable astronomical phenomena that illustrate the forma-
tion of multiple images and caustics. Finally, in Sec. 7.7, we turn from scalar waves to
the vector waves of electromagnetic radiation. We deduce the geometric-optics prop-
agation law for the waves’ polarization vector and explore the classical version of a
phenomenon called geometric phase.
351

BOX 7.1.
READERS’ GUIDE
.
This chapter does not depend substantially on any previous chapter,
but it does assume familiarity with classical mechanics, quantum
mechanics, and classical electromagnetism.
.
Secs. 7.1–7.4 are foundations for the remaining optics chapters, 8, 9,
and 10.
.
The discussion of caustics in Sec. 7.5 is a foundation for Sec. 8.6 on
diffraction at a caustic.
.
Secs. 7.2 and 7.3 (monochromatic plane waves and wave packets
in a homogeneous, time-independent medium; the dispersion
relation; and the geometric-optics equations) are used extensively in
subsequent parts of this book, including
– Chap. 12 for elastodynamic waves,
– Chap. 16 for waves in ﬂuids,
– Sec. 19.7 and Chaps. 21–23 for waves in plasmas, and
– Chap. 27 for gravitational waves.
– Sec. 28.6.2 for weak gravitational lensing.
7.2
7.2 Waves in a Homogeneous Medium
7.2.1
7.2.1 Monochromatic Plane Waves; Dispersion Relation
Consider a monochromatic plane wave propagating through a homogeneous me-
dium. Independently of the physical nature of the wave, it can be described math-
ematically by
ψ = Aei(k.x−ωt) ≡Aeiϕ,
(7.1)
where ψ is any oscillatory physical quantity associated with the wave, for example,
plane wave: complex
amplitude, phase,
angular frequency, wave
vector, wavelength, and
propagation direction
the y component of the magnetic ﬁeld associated with an electromagnetic wave. If, as
is usually the case, the physical quantity is real (not complex), then we must take the
real part of Eq. (7.1). In Eq. (7.1), A is the wave’s complex amplitude; ϕ = k . x −ωt
is the wave’s phase; t and x are time and location in space; ω = 2πf is the wave’s
angular frequency; and k is its wave vector (with k ≡|k| its wave number,λ = 2π/k its
wavelength, -λ = λ/(2π)itsreducedwavelength,and ˆk ≡k/k itspropagationdirection).
Surfaces of constant phase ϕ are orthogonal to the propagation direction ˆk and move
phase velocity
in the ˆk direction with the phase velocity
Vph ≡
∂x
∂t

ϕ
= ω
k
ˆk
(7.2)
(cf. Fig. 7.1). The frequency ω is determined by the wave vector k in a manner that
depends on the wave’s physical nature; the functional relationship
352
Chapter 7. Geometric Optics

y
x
ϕ = const
Vph = (ω/k)kˆ
FIGURE 7.1 A monochromatic plane
wave in a homogeneous medium.
ω = (k)
(7.3)
is called the wave’s dispersion relation, because (as we shall see in Ex. 7.2) it governs
dispersion relation
the dispersion (spreading) of a wave packet that is constructed by superposing plane
waves.
Some examples of plane waves that we study in this book are:
examples:
1. Electromagnetic waves propagating through an isotropic dielectric medium
electromagnetic waves
with index of refraction n [Eq. 10.20)], for which ψ could be any Cartesian
component of the electric or magnetic ﬁeld or vector potential and the
dispersion relation is
ω = (k) = Ck ≡C|k|,
(7.4)
with C = c/n the phase speed and c the speed of light in vacuum.
2. Sound waves propagating through a solid (Sec. 12.2.3) or ﬂuid (liquid or
sound waves
vapor; Secs. 7.3.1 and 16.5), for which ψ could be the pressure or density
perturbation produced by the sound wave (or it could be a potential whose
gradient is the velocity perturbation), and the dispersion relation is the same
as for electromagnetic waves, Eq. (7.4), but with C now the sound speed.
3. Waves on the surface of a deep body of water (depth ≫-λ; Sec. 16.2.1),
water waves
for which ψ could be the height of the water above equilibrium, and the
dispersion relation is [Eq. (16.9)]:
ω = (k) =

gk =

g|k|,
(7.5)
with g the acceleration of gravity.
4. Flexural waves on a stiff beam or rod (Sec. 12.3.4), for which ψ could be the
ﬂexural waves
transverse displacement of the beam from equilibrium, and the dispersion
relation is
ω = (k) =
&
D
 k2 =
&
D
 k . k,
(7.6)
7.2 Waves in a Homogeneous Medium
353

with  the rod’s mass per unit length and D its “ﬂexural rigidity” [Eq.
(12.33)].
5. Alfv´en waves in a magnetized, nonrelativistic plasma (bending waves of the
Alfv´en waves
plasma-laden magnetic ﬁeld lines; Sec. 19.7.2), for which ψ could be the
transverse displacement of the ﬁeld and plasma, and the dispersion relation
is [Eq. (19.75)]
ω = (k) = a . k,
(7.7)
with a = B/√μoρ, [= B/√4πρ]1 the Alfv´en speed, B the (homogeneous)
magneticﬁeld, μo themagneticpermittivityofthevacuum, andρ theplasma
mass density.
6. Gravitational waves propagating across the universe, for which ψ can be
gravitational waves
a component of the waves’ metric perturbation which describes the waves’
stretching and squeezing of space; these waves propagate nondispersively at
the speed of light, so their dispersion relation is Eq. (7.4) with C replaced by
the vacuum light speed c.
In general, one can derive the dispersion relation ω = (k) by inserting the plane-
wave ansatz (7.1) into the dynamical equations that govern one’s physical system [e.g.,
Maxwell’s equations, the equations of elastodynamics (Chap. 12), or the equations for
a magnetized plasma (Part VI)]. We shall do so time and again in this book.
7.2.2
7.2.2 Wave Packets
wave packet
Waves in the real world are not precisely monochromatic and planar. Instead, they
occupywavepacketsthataresomewhatlocalizedinspaceandtime.Suchwavepackets
can be constructed as superpositions of plane waves:
ψ(x, t) =

A(k)eiα(k)ei(k.x−ωt) d3k
(2π)3 ,
where A(k) is concentrated around some k = ko.
(7.8a)
Here A and α (both real) are the modulus and phase of the complex amplitude Aeiα,
and the integration element is d3k ≡dVk ≡dkxdkydkz in terms of components of k
along Cartesian axes x, y, and z. In the integral (7.8a), the contributions from adjacent
ks will tend to cancel each other except in that region of space and time where the
oscillatory phase factor changes little with changing k (when k is near ko). This is the
spacetime region in which the wave packet is concentrated, and its center is where
∇k(phase factor) = 0:
*
∂α
∂kj
+ ∂
∂kj
(k . x −ωt)
+
k=ko
= 0.
(7.8b)
1.
Gaussian unit equivalents will be given with square brackets.
354
Chapter 7. Geometric Optics

ϕ = const
ϕ = const
ϕ = const
Vph
Vph
Vph
B
Vg
Vg
Vg
kˆ
(a) Water waves
(b) Flexural waves
(c) Alfvén waves
FIGURE 7.2 (a) A wave packet of waves on a deep body of water. The packet is localized in the spatial
region bounded by the ellipse. The packet’s (ellipse’s) center moves with the group velocity Vg. The
ellipse expands slowly due to wave-packet dispersion (spreading; Ex. 7.2). The surfaces of constant
phase (the wave’s oscillations) move twice as fast as the ellipse and in the same direction, Vph = 2Vg
[Eq. (7.11)]. This means that the wave’s oscillations arise at the back of the packet and move forward
throughthepacket, disappearingatthefront.Thewavelengthoftheseoscillationsisλ = 2π/ko, where
ko = |ko| is the wave number about which the wave packet is concentrated [Eq. (7.8a) and associated
discussion]. (b) A ﬂexural wave packet on a beam, for which Vph = 1
2Vg [Eq. (7.12)], so the wave’s
oscillations arise at the packet’s front and, traveling more slowly than the packet, disappear at its back.
(c) An Alfv´en wave packet. Its center moves with a group velocity Vg that points along the direction of
the background magnetic ﬁeld [Eq. (7.13)], and its surfaces of constant phase (the wave’s oscillations)
move with a phase velocity Vph that can be in any direction ˆk. The phase speed is the projection of
the group velocity onto the phase propagation direction, |Vph| = Vg . ˆk [Eq. (7.13)], which implies
that the wave’s oscillations remain ﬁxed inside the packet as the packet moves; their pattern inside the
ellipse does not change. (An even more striking example is provided by the Rossby wave, discussed
in Sec. 16.4, in which the group velocity is equal and oppositely directed to the phase velocity.)
Evaluating the derivative with the aid of the wave’s dispersion relation ω = (k), we
obtain for the location of the wave packet’s center
xj −
*
∂
∂kj
+
k=ko
t = −
*
∂α
∂kj
+
k=ko
= const.
(7.8c)
group velocity
This tells us that the wave packet moves with the group velocity
Vg = ∇k,
i.e.,
Vg j =
*
∂
∂kj
+
k=ko
.
(7.9)
When, as for electromagnetic waves in a dielectric medium or sound waves in a
solid or ﬂuid, the dispersion relation has the simple form of Eq. (7.4), ω = (k) = Ck
with k ≡|k|, then the group and phase velocities are the same,
Vg = Vph = C ˆk,
(7.10)
and the waves are said to be dispersionless. If the dispersion relation has any other
form, then the group and phase velocities are different, and the wave is said to exhibit
7.2 Waves in a Homogeneous Medium
355

dispersion; cf. Ex. 7.2. Examples are (see Fig. 7.2 and the list in Sec. 7.2.1, from which
our numbering is taken):
3. Wavesonadeepbodyofwater[dispersionrelation(7.5); Fig.7.2a], forwhich
Vg = 1
2Vph = 1
2
&g
k
ˆk;
(7.11)
4. Flexural waves on a stiff beam or rod [dispersion relation (7.6); Fig. 7.2b],
for which
Vg = 2Vph = 2
&
D
 k ˆk;
(7.12)
5. Alfv´enwavesinamagnetizedandnonrelativisticplasma[dispersionrelation
(7.7); Fig. 7.2c], for which
Vg = a,
Vph = (a . ˆk)ˆk.
(7.13)
Notice that, depending on the dispersion relation, the group speed |Vg| can be less
than or greater than the phase speed, and if the homogeneous medium is anisotropic
(e.g., for a magnetized plasma), the group velocity can point in a different direction
than the phase velocity.
Physically, it should be obvious that the energy contained in a wave packet must
remain always with the packet and cannot move into the region outside the packet
where the wave amplitude vanishes. Correspondingly, the wave packet’s energy must
propagate with the group velocity Vg and not with the phase velocity Vph. When one
examines the wave packet from a quantum mechanical viewpoint, its quanta must
move with the group velocity Vg. Since we have required that the wave packet have
its wave vectors concentrated around ko, the energy and momentum of each of the
packet’s quanta are given by the standard quantum mechanical relations:
E = ℏ(ko),
and
p = ℏko.
(7.14)
EXERCISES
Exercise 7.1 Practice: Group and Phase Velocities
Derive the group and phase velocities (7.10)–(7.13) from the dispersion relations
(7.4)–(7.7).
Exercise 7.2 **Example: Gaussian Wave Packet and Its Dispersion
Considera1-dimensionalwavepacket, ψ(x, t) =

A(k)eiα(k)ei(kx−ωt)dk/(2π), with
dispersion relation ω = (k). For concreteness, let A(k) be a narrow Gaussian peaked
around ko: A ∝exp[−κ2/(2(k)2)], where κ = k −ko.
(a) Expand α as α(k) = αo −xoκ with xo a constant, and assume for simplicity that
higher order terms are negligible. Similarly, expand ω ≡(k) to quadratic order,
356
Chapter 7. Geometric Optics

and explain why the coefﬁcients are related to the group velocity Vg at k = ko by
 = ωo + Vgκ + (dVg/dk)κ2/2.
(b) Show that the wave packet is given by
ψ ∝exp[i(αo + kox −ωot)]
 +∞
−∞
exp[iκ(x −xo −Vgt)]
(7.15a)
× exp

−κ2
2

1
(k)2 + i
dVg
dk t

dκ.
The term in front of the integral describes the phase evolution of the waves inside
the packet; cf. Fig. 7.2.
(c) Evaluate the integral analytically (with the help of a computer, if you wish). From
your answer, show that the modulus of ψ satisﬁes
|ψ| ∝
1
L1/2 exp
'
−
(x −xo −Vgt)2
2L2
(
, where L = 1
k
1
1 +
dVg
dk (k)2 t
2
(7.15b)
is the packet’s half-width.
(d) Discuss the relationship of this result at time t = 0 to the uncertainty principle
for the localization of the packet’s quanta.
(e) Equation (7.15b) shows that the wave packet spreads (i.e., disperses) due to its
containing a range of group velocities [Eq. (7.11)]. How long does it take for the
packet to enlarge by a factor 2? For what range of initial half-widths can a water
wave on the ocean spread by less than a factor 2 while traveling from Hawaii to
California?
7.3
7.3 Waves in an Inhomogeneous, Time-Varying Medium:
The Eikonal Approximation and Geometric Optics
Suppose that the medium in which the waves propagate is spatially inhomogeneous
and varies with time. If the lengthscale L and timescale T for substantial variations
are long compared to the waves’ reduced wavelength and period,
L ≫-λ = 1/k,
T ≫1/ω,
(7.16)
then the waves can be regarded locally as planar and monochromatic. The medium’s
inhomogeneities and time variations may produce variations in the wave vector k and
frequency ω, but those variations should be substantial only on scales >∼L ≫1/k
two-lengthscale expansion
and >∼T ≫1/ω. This intuitively obvious fact can be proved rigorously using a two-
lengthscale expansion (i.e., an expansion of the wave equation in powers of -λ/L =
1/kL and 1/ωT ). Such an expansion, in this context of wave propagation, is called
7.3 Waves in an Inhomogeneous, Time-Varying Medium
357

the geometric-optics approximation or the eikonal approximation (after the Greek
eikonal approximation
word ϵικων, meaning image). When the waves are those of elementary quantum
mechanics, it is called the WKB approximation.2 The eikonal approximation converts
WKB approximation
the laws of wave propagation into a remarkably simple form, in which the waves’
amplitude is transported along trajectories in spacetime called rays. In the language
of quantum mechanics, these rays are the world lines of the wave’s quanta (photons for
light, phonons for sound, plasmons for Alfv´en waves, and gravitons for gravitational
waves), and the law by which the wave amplitude is transported along the rays is
one that conserves quanta. These ray-based propagation laws are called the laws of
geometric optics.
In this section we develop and study the eikonal approximation and its resulting
laws of geometric optics. We begin in Sec. 7.3.1 with a full development of the eikonal
approximation and its geometric-optics consequences for a prototypical dispersion-
free wave equation that represents, for example, sound waves in a weakly inhomoge-
neous ﬂuid. In Sec. 7.3.3, we extend our analysis to cover all other types of waves. In
Sec. 7.3.4 and a number of exercises we explore examples of geometric-optics waves,
and in Sec. 7.3.5 we discuss conditions under which the eikonal approximation breaks
down and some non-geometric-optics phenomena that result from the breakdown.
Finally, in Sec. 7.3.6 we return to nondispersive light and sound waves, deduce Fer-
mat’s principle, and explore some of its consequences.
7.3.1
7.3.1 Geometric Optics for a Prototypical Wave Equation
Our prototypical wave equation is
prototypicalwaveequation
in a slowly varying medium
∂
∂t

W ∂ψ
∂t

−∇. (WC2∇ψ) = 0.
(7.17)
Here ψ(x, t) is the quantity that oscillates (the wave ﬁeld), C(x, t) will turn out
to be the wave’s slowly varying propagation speed, and W(x, t) is a slowly varying
weighting function that depends on the properties of the medium through which the
wave propagates. As we shall see, W has no inﬂuence on the wave’s dispersion relation
or on its geometric-optics rays, but it does inﬂuence the law of transport for the waves’
amplitude.
The wave equation (7.17) describes sound waves propagating through a static,
isentropic, inhomogeneous ﬂuid (Ex. 16.13), in which case ψ is the wave’s pressure
perturbation δP , C(x) =

(∂P/∂ρ)s is the adabiatic sound speed, and the weight-
ing function is W(x) = 1/(ρC2), with ρ the ﬂuid’s unperturbed density. This wave
equation also describes waves on the surface of a lake or pond or the ocean, in the
limit that the slowly varying depth of the undisturbed water ho(x) is small compared
2.
Sometimes called “JWKB,” adding Jeffreys to the attribution, though Carlini, Liouville, and Green used
it a century earlier.
358
Chapter 7. Geometric Optics

to the wavelength (shallow-water waves; e.g., tsunamis); see Ex. 16.3. In this case ψ is
the perturbation of the water’s depth, W = 1, and C =

gho with g the acceleration
of gravity. In both cases—sound waves in a ﬂuid and shallow-water waves—if we turn
on a slow time dependence in the unperturbed ﬂuid, then additional terms enter the
wave equation (7.17). For pedagogical simplicity we leave those terms out, but in the
analysis below we do allow W and C to be slowly varying in time, as well as in space:
W = W(x, t) and C = C(x, t).
energy density and ﬂux
Associated with the wave equation (7.17) are an energy density U(x, t) and energy
ﬂux F(x, t) given by
U = W
'
1
2
∂ψ
∂t
2
+ 1
2C2(∇ψ)2
(
,
F = −WC2∂ψ
∂t ∇ψ;
(7.18)
see Ex. 7.4. It is straightforward to verify that, if C and W are independent of time t,
then the scalar wave equation (7.17) guarantees that the U and F of Eq. (7.18) satisfy
the law of energy conservation:
∂U
∂t + ∇. F = 0;
(7.19)
cf. Ex. 7.4.3
eikonal approximated
wave: amplitude, phase,
wave vector, and angular
frequency
We now specialize to a weakly inhomogeneous and slowly time-varying ﬂuid and
to nearly plane waves, and we seek a solution of the wave equation (7.17) that locally
has approximately the plane-wave form ψ ≃Aeik.x−ωt. Motivated by this plane-wave
form, (i) we express the waves in the eikonal approximation as the product of a real
amplitude A(x, t) that varies slowly on the length- and timescales L and T , and the
exponential of a complex phase ϕ(x, t) that varies rapidly on the timescale 1/ω and
lengthscale -λ:
ψ(x, t) = A(x, t)eiϕ(x,t);
(7.20)
and (ii) we deﬁne the wave vector (ﬁeld) and angular frequency (ﬁeld) by
k(x, t) ≡∇ϕ,
ω(x, t) ≡−∂ϕ/∂t.
(7.21)
In addition to our two-lengthscale requirement, L ≫1/k and T ≫1/ω, we also
require that A, k, and ω vary slowly (i.e., vary on lengthscales R and timescales T ′
long compared to -λ = 1/k and 1/ω).4 This requirement guarantees that the waves are
locally planar, ϕ ≃k . x −ωt + constant.
3.
Alternatively, one can observe that a stationary medium will not perform work.
4.
Note that these variations can arise both (i) from the inﬂuence of the medium’s inhomogeneity (which
puts limits R <∼L and T ′ <∼T on the wave’s variations) and (ii) from the chosen form of the wave. For
example, the wave might be traveling outward from a source and so have nearly spherical phase fronts
with radii of curvature r ≃(distance from source); then R = min(r, L).
7.3 Waves in an Inhomogeneous, Time-Varying Medium
359

BOX 7.2.
BOOKKEEPING PARAMETER IN
TWO-LENGTHSCALE EXPANSIONS
When developing a two-lengthscale expansion, it is sometimes helpful to
introduce a bookkeeping parameter σ and rewrite the ansatz (7.20) in a
ﬂeshed-out form:
ψ = (A + σB + . . .)eiϕ/σ.
(1)
The numerical value of σ is unity, so it can be dropped when the analysis is
ﬁnished. We use σ to tell us how various terms scale when -λ is reduced at
ﬁxed L and R. The amplitude A has no attached σ and so scales as -λ0, B is
multiplied by σ and so scales proportional to -λ, and ϕ is multiplied by σ −1
and so scales as -λ−1. When one uses these factors of σ in the evaluation of
the wave equation, the ﬁrst term on the right-hand side of Eq. (7.22) gets
multiplied by σ −2, the second term by σ −1, and the omitted terms by σ 0.
These factors of σ help us to quickly group together all terms that scale in a
similar manner and to identify which of the groupings is leading order, and
which subleading, in the two-lengthscale expansion. In Eq. (7.22) the omitted
σ 0 terms are the ﬁrst ones in which B appears; they produce a propagation
law for B, which can be regarded as a post-geometric-optics correction.
Occasionally the wave equation itself will contain terms that scale with -λ
differently from one another (e.g., Ex. 7.9). One should always look out for
this possibility.
We now insert the eikonal-approximated wave ﬁeld (7.20) into the wave equation
(7.17), perform the differentiations with the aid of Eqs. (7.21), and collect terms in a
manner dictated by a two-lengthscale expansion (see Box 7.2):
0 = ∂
∂t

W ∂ψ
∂t

−∇. (WC2∇ψ)
(7.22)
=
2
−ω2 + C2k23
Wψ
+ i

−2
2
ω∂A
∂t + C2kjA,j
3
W −∂(Wω)
∂t
A −(WC2kj),jA

eiϕ + . . . .
The ﬁrst term on the right-hand side, (−ω2 + C2k2)Wψ, scales as -λ−2 when we
make the reduced wavelength -λ shorter and shorter while holding the macroscopic
lengthscales L and R ﬁxed; the second term (in square brackets) scales as -λ−1; and
the omitted terms scale as -λ0. This is what we mean by “collecting terms in a manner
dictated by a two-lengthscale expansion.” Because of their different scaling, the ﬁrst,
360
Chapter 7. Geometric Optics

second, and omitted terms must vanish separately; they cannot possibly cancel one
another.
dispersion relation
The vanishing of the ﬁrst term in the eikonal-approximated wave equation (7.22)
implies that the waves’ frequency ﬁeld ω(x, t) ≡−∂ϕ/∂t and wave-vector ﬁeld k ≡
∇ϕ satisfy the dispersionless dispersion relation,
ω = (k, x, t) ≡C(x, t)k,
(7.23)
where (as throughout this chapter) k ≡|k|. Notice that, as promised, this dispersion
relation is independent of the weighting function W in the wave equation. Notice
further that this dispersion relation is identical to that for a precisely plane wave in a
homogeneous medium, Eq. (7.4), except that the propagation speed C is now a slowly
varying function of space and time. This will always be so.
One can always deduce the geometric-optics dispersion relation by (i) considering
a precisely plane, monochromatic wave in a precisely homogeneous, time-independent
medium and deducing ω = (k) in a functional form that involves the medium’s prop-
erties (e.g., density) and then (ii) allowing the properties to be slowly varying functions
of x and t. The resulting dispersion relation [e.g., Eq. (7.23)] then acquires its x and t
dependence from the properties of the medium.
The vanishing of the second term in the eikonal-approximated wave equation
(7.22) dictates that the wave’s real amplitude A is transported with the group velocity
Vg = C ˆk in the following manner:
propagation law for
amplitude
dA
dt ≡
 ∂
∂t + Vg . ∇

A = −
1
2Wω
∂(Wω)
∂t
+ ∇. (WC2k)

A.
(7.24)
This propagation law, by contrast with the dispersion relation, does depend on the
weighting function W. We return to this propagation law shortly and shall understand
more deeply its dependence on W, but ﬁrst we must investigate in detail the directions
along which A is transported.
rays
The time derivative d/dt = ∂/∂t + Vg . ∇appearing in the propagation law (7.24)
is similar to the derivative with respect to proper time along a world line in special
relativity, d/dτ = u0∂/∂t + u . ∇(with uα the world line’s 4-velocity). This analogy
tells us that the waves’ amplitude A is being propagated along some sort of world lines
(trajectories). Those world lines (the waves’ rays), in fact, are governed by Hamilton’s
Hamilton’s equations for
rays
equations of particle mechanics with the dispersion relation (x, t, k) playing the
role of the hamiltonian and k playing the role of momentum:
dxj
dt =
*
∂
∂kj
+
x,t
≡Vg j,
dkj
dt = −
*
∂
∂xj
+
k,t
,
dω
dt =
∂
∂t

x,k
.
(7.25)
The ﬁrst of these Hamilton equations is just our deﬁnition of the group velocity, with
which [according to Eq. (7.24)] the amplitude is transported. The second tells us how
7.3 Waves in an Inhomogeneous, Time-Varying Medium
361

the wave vector k changes along a ray, and together with our knowledge of C(x, t), it
tells us how the group velocity Vg = C ˆk for our dispersionless waves changes along
a ray, and thence deﬁnes the ray itself. The third tells us how the waves’ frequency
changes along a ray.
To deduce the second and third of these Hamilton equations, we begin by inserting
the deﬁnitions ω = −∂ϕ/∂t and k = ∇ϕ [Eqs. (7.21)] into the dispersion relation
ω = (x, t; k) for an arbitrary wave, thereby obtaining
∂ϕ
∂t + (x, t; ∇ϕ) = 0.
(7.26a)
This equation is known in optics as the eikonal equation. It is formally the same as
eikonal equation and
Hamilton-Jacobi equation
the Hamilton-Jacobi equation of classical mechanics (see, e.g., Goldstein, Poole, and
Safko, 2002), if we identify  with the hamiltonian and ϕ with Hamilton’s principal
function (cf. Ex. 7.9). This suggests that, to derive the second and third of Eqs. (7.25),
we can follow the same procedure as is used to derive Hamilton’s equations of motion.
We take the gradient of Eq. (7.26a) to obtain
∂2ϕ
∂t∂xj
+ ∂
∂kl
∂2ϕ
∂xl∂xj
+ ∂
∂xj
= 0,
(7.26b)
where the partial derivatives of  are with respect to its arguments (x, t; k); we then
use ∂ϕ/∂xj = kj and ∂/∂kl = Vg l to write Eq. (7.26b) as dkj/dt = −∂/∂xj. This
isthesecondofHamilton’sequations(7.25), andittellsushowthewavevectorchanges
along a ray. The third Hamilton equation, dω/dt = ∂/∂t [Eq. (7.25)], is obtained
by taking the time derivative of the eikonal equation (7.26a).
propagation equation for
phase
Not only is the waves’ amplitude A propagated along the rays, so also is their phase:
dϕ
dt = ∂ϕ
∂t + Vg . ∇ϕ = −ω + Vg . k.
(7.27)
Since our dispersionless waves have ω = Ck and Vg = C ˆk, this vanishes. Therefore,
for the special case of dispersionless waves (e.g., sound waves in a ﬂuid and electro-
magnetic waves in an isotropic dielectric medium), the phase is constant along each
ray:
dϕ/dt = 0.
(7.28)
7.3.2
7.3.2 Connection of Geometric Optics to Quantum Theory
Although the waves ψ = Aeiϕ are classical and our analysis is classical, their propa-
gation laws in the eikonal approximation can be described most nicely in quantum
mechanical language.5 Quantum mechanics insists that, associated with any wave in
5.
This is intimately related to the fact that quantum mechanics underlies classical mechanics; the classical
world is an approximation to the quantum world, often a very good approximation.
362
Chapter 7. Geometric Optics

the geometric-optics regime, there are real quanta: the wave’s quantum mechanical
quanta
particles. If the wave is electromagnetic, the quanta are photons; if it is gravitational,
they are gravitons; if it is sound, they are phonons; if it is a plasma wave (e.g., Alfv´en),
they are plasmons. When we multiply the wave’s k and ω by ℏ, we obtain the particles’
momentum and energy:
momentum and energy of
quanta
p = ℏk,
E = ℏω.
(7.29)
Although the originators of the nineteenth-century theory of classical waves were
unaware of these quanta, once quantum mechanics had been formulated, the quanta
became a powerful conceptual tool for thinking about classical waves.
In particular, we can regard the rays as the world lines of the quanta, and by
multiplyingthedispersionrelationbyℏ, wecanobtainthehamiltonianforthequanta’s
world lines:
hamiltonian for quanta
H(x, t; p) = ℏ(x, t; k = p/ℏ).
(7.30)
Hamilton’s equations (7.25) for the rays then immediately become Hamilton’s equa-
tions for the quanta: dxj/dt = ∂H/∂pj, dpj/dt = −∂H/∂xj, and dE/dt = ∂H/∂t.
Returnnowtothepropagationlaw(7.24)forthewaves’amplitude, andexamineits
consequences for the waves’ energy. By inserting the ansatz ψ = ℜ(Aeiϕ) = A cos(ϕ)
into Eqs. (7.18) for the energy density U and energy ﬂux F and averaging over a
wavelength and wave period (so cos2 ϕ = sin2 ϕ = 1/2), we ﬁnd that
U = 1
2WC2k2A2 = 1
2Wω2A2,
F = U(C ˆk) = UVg.
(7.31)
Inserting these into the expression ∂U/∂t + ∇. F for the rate at which energy (per
unit volume) fails to be conserved and using the propagation law (7.24) for A, we
obtain
∂U
∂t + ∇. F = U ∂ln C
∂t
.
(7.32)
Thus, as the propagation speed C slowly changes at a ﬁxed location in space due to
a slow change in the medium’s properties, the medium slowly pumps energy into the
waves or removes it from them at a rate per unit volume of U∂ln C/∂t.
This slow energy change can be understood more deeply using quantum concepts.
The number density and number ﬂux of quanta are
number density and ﬂux
for quanta
n = U
ℏω ,
S = F
ℏω = nVg.
(7.33)
By combining these equations with the energy (non)conservation equation (7.32), we
obtain
∂n
∂t + ∇. S = n
∂ln C
∂t
−d ln ω
dt

.
(7.34)
7.3 Waves in an Inhomogeneous, Time-Varying Medium
363

The third Hamilton equation (7.25) tells us that
dω/dt = (∂/∂t)x,k = [∂(Ck)/∂t]x,k = k∂C/∂t,
whence d ln ω/dt = ∂ln C/∂t, which, when inserted into Eq. (7.34), implies that the
quanta are conserved:
conservation of quanta
∂n
∂t + ∇. S = 0.
(7.35a)
Since S = nVg and d/dt = ∂/∂t + Vg . ∇, we can rewrite this conservation law as a
propagation law for the number density of quanta:
dn
dt + n∇. Vg = 0.
(7.35b)
The propagation law for the waves’ amplitude, Eq. (7.24), can now be understood
much more deeply: The amplitude propagation law is nothing but the law of conserva-
tion of quanta in a slowly varying medium, rewritten in terms of the amplitude. This
is true quite generally, for any kind of wave (Sec. 7.3.3); and the quickest route to the
amplitude propagation law is often to express the wave’s energy density U in terms of
the amplitude and then invoke conservation of quanta, Eq. (7.35b).
In Ex. 7.3 we show that the conservation law (7.35b) is equivalent to
d(nCA)
dt
= 0,
i.e., nCA is a constant along each ray.
(7.35c)
Here A is the cross sectional area of a bundle of rays surrounding the ray along
which the wave is propagating. Equivalently, by virtue of Eqs. (7.33) and (7.31) for
the number density of quanta in terms of the wave amplitude A, we have
d
dt A
√
CWωA = 0,
i.e., A
√
CWωA is a constant along each ray.
(7.35d)
In Eqs. (7.33) and (7.35), we have boxed those equations that are completely general
(because they embody conservation of quanta) and have not boxed those that are
specialized to our prototypical wave equation.
EXERCISES
Exercise 7.3 ** Derivation and Example: Amplitude Propagation for Dispersionless
Waves Expressed as Constancy of Something along a Ray
(a) In connection with Eq. (7.35b), explain why ∇. Vg = d ln V/dt, where V is the
tiny volume occupied by a collection of the wave’s quanta.
(b) Choose for the collection of quanta those that occupy a cross sectional area
A orthogonal to a chosen ray, and a longitudinal length s along the ray, so
V = As. Show that d ln s/dt = d ln C/dt and correspondingly, d ln V/dt =
d ln(CA)/dt.
364
Chapter 7. Geometric Optics

(c) Given part (b), show that the conservation law (7.35b) is equivalent to the con-
stancy of nCA along a ray, Eq. (7.35c).
(d) Fromtheresultsofpart(c), derivetheconstancyofA
√
CWωA alongaray(where
A is the wave’s amplitude), Eq. (7.35d).
Exercise 7.4 **Example: Energy Density and Flux, and Adiabatic Invariant,
for a Dispersionless Wave
(a) Show that the prototypical scalar wave equation (7.17) follows from the varia-
tional principle
δ

Ldtd3x = 0,
(7.36a)
where L is the lagrangian density
L = W
'
1
2
∂ψ
∂t
2
−1
2C2 (∇ψ)2
(
(7.36b)
(not to be confused with the lengthscale L of inhomogeneities in the medium).
(b) For any scalar-ﬁeld lagrangian density L(ψ, ∂ψ/∂t, ∇ψ, x, t), the energy den-
sity and energy ﬂux can be expressed in terms of the lagrangian, in Cartesian
coordinates, as
U(x, t) = ∂ψ
∂t
∂L
∂ψ/∂t −L,
Fj = ∂ψ
∂t
∂L
∂ψ/∂xj
(7.36c)
(Goldstein, Poole, and Safko, 2002, Sec. 13.3). Show, from the Euler-Lagrange
equations for L, that these expressions satisfy energy conservation, ∂U/∂t
+ ∇. F = 0, if L has no explicit time dependence [e.g., for the lagrangian (7.36b)
if C = C(x) and W = W(x) do not depend on time t].
(c) Show that expression (7.36c) for the ﬁeld’s energy density U and its energy ﬂux
Fj agree with Eqs. (7.18).
(d) Now, regard the wave amplitude ψ as a generalized (ﬁeld) coordinate. Use the
lagrangian L =

Ld3x to deﬁne a ﬁeld momentum % conjugate to this ψ, and
then compute a wave action,
J ≡
 2π/ω
0

%(∂ψ/∂t)d3x dt,
(7.36d)
which is the continuum analog of Eq. (7.43) in Sec. 7.3.6. The temporal integral is
over one wave period. Show that this J is proportional to the wave energy divided
by the frequency and thence to the number of quanta in the wave.
It is shown in standard texts on classical mechanics that, for approximately
periodic oscillations, the particle action (7.43), with the integral limited to one
period of oscillation of q, is an adiabatic invariant.By the extension of that proof
to continuum physics, the wave action (7.36d) is also an adiabatic invariant. This
7.3 Waves in an Inhomogeneous, Time-Varying Medium
365

means that the wave action and hence the number of quanta in the waves are con-
served when the medium [in our case the index of refraction n(x)] changes very
slowly in time—a result asserted in the text, and one that also follows from quan-
tum mechanics. We study the particle version (7.43) of this adiabatic invariant
in detail when we analyze charged-particle motion in a slowly varying magnetic
ﬁeld in Sec. 20.7.4.
Exercise 7.5 Problem: Propagation of Sound Waves in a Wind
Consider sound waves propagating in an atmosphere with a horizontal wind. Assume
that the sound speed C, as measured in the air’s local rest frame, is constant. Let the
wind velocity u = uxex increase linearly with height z above the ground: ux = Sz,
where S is the constant shearing rate. Consider only rays in the x-z plane.
(a) Give an expression for the dispersion relation ω = (x, t; k). [Hint: In the local
rest frame of the air,  should have its standard sound-wave form.]
(b) Show that kx is constant along a ray path, and then demonstrate that sound waves
will not propagate when
8888
ω
kx
−ux(z)
8888 < C.
(7.37)
(c) Consider sound rays generated on the ground that make an angle θ to the hori-
zontal initially. Derive the equations describing the rays, and use them to sketch
the rays, distinguishing values of θ both less than and greater than π/2. (You
might like to perform this exercise numerically.)
7.3.3
7.3.3 Geometric Optics for a General Wave
With the simple case of nondispersive sound waves (Secs. 7.3.1 and 7.3.2) as our
model, we now study an arbitrary kind of wave in a weakly inhomogeneous and
slowly time varying medium (e.g., any of the examples in Sec. 7.2.1: light waves in a
dielectric medium, deep water waves, ﬂexural waves on a stiff beam, or Alfv´en waves).
Whatever the wave may be, we seek a solution to its wave equation using the eikonal
approximation ψ = Aeiϕ with slowly varying amplitude A and rapidly varying phase
ϕ. Depending on the nature of the wave, ψ and A might be a scalar (e.g., sound waves),
a vector (e.g., light waves), or a tensor (e.g., gravitational waves).
When we insert the ansatz ψ = Aeiϕ into the wave equation and collect terms in
the manner dictated by our two-lengthscale expansion [as in Eq. (7.22) and Box 7.2],
the leading-order term will arise from letting every temporal or spatial derivative act
on the eiϕ. This is precisely where the derivatives would operate in the case of a plane
wave in a homogeneous medium, and here, as there, the result of each differentiation
is ∂eiϕ/∂t = −iωeiϕ or ∂eiϕ/∂xj = ikjeiϕ. Correspondingly, the leading-order terms
in the wave equation here will be identical to those in the homogeneous plane wave
366
Chapter 7. Geometric Optics

case: they will be the dispersion relation multiplied by something times the wave,
dispersion relation for
general wave
[−ω2 + 2(x, t; k)]× (something)Aeiϕ = 0,
(7.38a)
with the spatial and temporal dependence of 2 entering through the medium’s
properties. This guarantees that (as we claimed in Sec. 7.3.1) the dispersion relation
can be obtained by analyzing a plane, monochromatic wave in a homogeneous, time-
independent medium and then letting the medium’s properties, in the dispersion
relation, vary slowly with x and t.
Each next-order (“subleading”) term in the wave equation will entail just one of
the wave operator’s derivatives acting on a slowly varying quantity (A, a medium
property, ω, or k) and all the other derivatives acting on eiϕ. The subleading terms
that interest us, for the moment, are those in which the one derivative acts on A,
thereby propagating it. Therefore, the subleading terms can be deduced from the
leading-order terms (7.38a) by replacing just one iωAeiϕ = −A(eiϕ),t by −A,teiϕ,
and replacing just one ikjAeiϕ = A(eiϕ),j by A,jeiϕ (where the subscript commas
denote partial derivatives in Cartesian coordinates). A little thought then reveals that
the equation for the vanishing of the subleading terms must take the form [deducible
from the leading terms (7.38a)]:
−2iω∂A
∂t −2i(k, x, t)∂(k, x, t)
∂kj
∂A
∂xj
= terms proportional to A.
(7.38b)
Using the dispersion relation ω = (x, t; k) and the group velocity (ﬁrst Hamilton
equation) ∂/∂kj = Vg j, we bring this into the “propagate A along a ray” form:
dA
dt ≡∂A
∂t + Vg . ∇A = terms proportional to A.
(7.38c)
Let us return to the leading-order terms (7.38a) in the wave equation [i.e., to
the dispersion relation ω = (x, t; k)]. For our general wave, as for the prototypical
dispersionless wave of the previous two sections, the argument embodied in Eqs.
(7.26) shows that the rays are determined by Hamilton’s equations (7.25),
Hamilton’s equations for
general wave
dxj
dt =
*
∂
∂kj
+
x,t
≡Vg j,
dkj
dt = −
*
∂
∂xj
+
k,t
,
dω
dt =
∂
∂t

x,k
,
(7.39)
but using the general wave’s dispersion relation (k, x, t) rather than  = C(x, t)k.
These Hamilton equations include propagation laws for ω = −∂ϕ/∂t and kj =
∂ϕ/∂xj, from which we can deduce the propagation law (7.27) for ϕ along the rays:
propagation law for phase
of general wave
dϕ
dt = −ω + Vg . k.
(7.40)
For waves with dispersion, by contrast with sound in a ﬂuid and other waves that have
 = Ck, ϕ will not be constant along a ray.
7.3 Waves in an Inhomogeneous, Time-Varying Medium
367

For our general wave, as for dispersionless waves, the Hamilton equations for the
rays can be reinterpreted as Hamilton’s equations for the world lines of the waves’
quanta [Eq. (7.30) and associated discussion]. And for our general wave, as for dis-
persionlesswaves, themedium’sslowvariationsareincapableofcreatingordestroying
wave quanta.6 Correspondingly, if one knows the relationship between the waves’ en-
ergy density U and their amplitude A, and thence the relationship between the waves’
quantum number density n = U/ℏω and A, then from the quantum conservation law
[boxed Eqs. (7.35)]
conservation of quanta and
propagation of amplitude
for general wave
∂n
∂t + ∇. (nVg) = 0,
dn
dt + n∇. Vg = 0,
or
d(nCA)
dt
= 0,
(7.41)
one can deduce the propagation law for A—and the result must be the same propagation
law as one obtains from the subleading terms in the eikonal approximation.
7.3.4
7.3.4 Examples of Geometric-Optics Wave Propagation
SPHERICAL SOUND WAVES
As a simple example of these geometric-optics propagation laws, consider a sound
wave propagating radially outward through a homogeneous ﬂuid from a spherical
source (e.g., a radially oscillating ball; cf. Sec. 16.5.3). The dispersion relation is
Eq. (7.4):  = Ck. It is straightforward (Ex. 7.6) to integrate Hamilton’s equations
and learn that the rays have the simple form {r = Ct + constant, θ = constant, φ =
constant, k = (ω/C)er} in spherical polar coordinates, with er the unit radial vector.
Because the wave is dispersionless, its phase ϕ must be conserved along a ray [Eq.
(7.28)], soϕ mustbeafunctionofCt −r, θ, andφ.Forthewavestopropagateradially,
it is essential that k = ∇ϕ point very nearly radially, which implies that ϕ must be a
rapidly varying function of Ct −r and a slowly varying one of θ and φ. The law
of conservation of quanta in this case reduces to the propagation law d(rA)/dt = 0
(Ex. 7.6), so rA is also a constant along the ray; we call it B. Putting this all together,
we conclude that the sound waves’ pressure perturbation ψ = δP has the form
ψ = B(Ct −r, θ, φ)
r
eiϕ(Ct−r,θ ,φ),
(7.42)
where the phase ϕ is rapidly varying in Ct −r and slowly varying in the angles, and
the amplitude B is slowly varying in Ct −r and the angles.
FLEXURAL WAVES
As another example of the geometric-optics propagation laws, consider ﬂexural waves
onaspacecraft’staperingantenna.Thedispersionrelationis = k2√D/ [Eq.(7.6)]
with D/ ∝h2, where h is the antenna’s thickness in its direction of bend (or the
6.
This is a general feature of quantum theory; creation and destruction of quanta require imposed
oscillations at the high frequency and short wavelength of the waves themselves, or at some submultiple
of them (in the case of nonlinear creation and annihilation processes; Chap. 10).
368
Chapter 7. Geometric Optics

antenna’s diameter, if it has a circular cross section); cf. Eq. (12.33). Since  is in-
dependent of t, as the waves propagate from the spacecraft to the antenna’s tip, their
frequency ω is conserved [third of Eqs. (7.39)], which implies by the dispersion re-
lation that k = (D/ )−1/4ω1/2 ∝h−1/2; hence the wavelength decreases as h1/2. The
group velocity is Vg = 2(D/ )1/4ω1/2 ∝h1/2. Since the energy per quantum ℏω is
constant, particle conservation implies that the waves’ energy must be conserved,
which in this 1-dimensional problem means that the energy ﬂowing through a seg-
ment of the antenna per unit time must be constant along the antenna. On physical
grounds this constant energy ﬂow rate must be proportional to A2Vgh2, which means
that the amplitude A must increase ∝h−5/4 as the ﬂexural waves approach the an-
tenna’s end. A qualitatively similar phenomenon is seen in the cracking of a bullwhip
(where the speed of the end can become supersonic).
LIGHT THROUGH A LENS AND ALFV´EN WAVES
Figure 7.3 sketches two other examples: light propagating through a lens and Alfv´en
waves propagating in the magnetosphere of a planet. In Sec. 7.3.6 and the exercises we
explore a variety of other applications, but ﬁrst we describe how the geometric-optics
propagation laws can fail (Sec. 7.3.5).
EXERCISES
Exercise 7.6 Derivation and Practice: Quasi-Spherical Solution
to Vacuum Scalar Wave Equation
Derive the quasi-spherical solution (7.42) of the vacuum scalar wave equation
−∂2ψ/∂t2 + ∇2ψ = 0 from the geometric-optics laws by the procedure sketched
in the text.
7.3.5
7.3.5 Relation to Wave Packets; Limitations of the Eikonal Approximation
and Geometric Optics
The form ψ = Aeiϕ of the waves in the eikonal approximation is remarkably general.
At some initial moment of time, A and ϕ can have any form whatsoever, so long as the
two-lengthscaleconstraintsaresatisﬁed[A, ω ≡−∂ϕ/∂t, k ≡∇ϕ, anddispersionre-
lation (k; x, t) all vary on lengthscales long compared to -λ = 1/k and on timescales
long compared to 1/ω]. For example, ψ could be as nearly planar as is allowed by the
inhomogeneities of the dispersion relation. At the other extreme, ψ could be a mod-
erately narrow wave packet, conﬁned initially to a small region of space (though not
too small; its size must be large compared to its mean reduced wavelength). In either
case, the evolution will be governed by the above propagation laws.
Of course, the eikonal approximation is an approximation. Its propagation laws
phenomena missed by
geometric optics
make errors, though when the two-lengthscale constraints are well satisﬁed, the
errors will be small for sufﬁciently short propagation times. Wave packets provide an
important example. Dispersion (different group velocities for different wave vectors)
causes wave packets to spread (disperse) as they propagate; see Ex. 7.2. This spreading
7.3 Waves in an Inhomogeneous, Time-Varying Medium
369

k
Vg
(a)
ϕ = const
ϕ = const
ϕ = const
ray
ray
ray
ray
ray
source
lens
k
k
k
Vg
(b)
ϕ = const
ϕ = const
ϕ = const
planet
FIGURE 7.3 (a) The rays and the surfaces of constant phase ϕ at a ﬁxed time for light passing through a
converging lens [dispersion relation  = ck/n(x), where n is the index of refraction]. In this case the
rays (which always point along Vg) are parallel to the wave vector k = ∇ϕ and thus are also parallel
to the phase velocity Vph, and the waves propagate along the rays with a speed Vg = Vph = c/n that is
independentofwavelength.Thestrangeself-intersectingshapeofthelastphasefrontisduetocaustics;
see Sec. 7.5. (b) The rays and surfaces of constant phase for Alfv´en waves in the magnetosphere of a
planet [dispersion relation  = a(x) . k]. In this case, because Vg = a ≡B/√μ0ρ, the rays are parallel
to the magnetic ﬁeld lines and are not parallel to the wave vector, and the waves propagate along
the ﬁeld lines with speeds Vg that are independent of wavelength; cf. Fig. 7.2c. As a consequence, if
some electric discharge excites Alfv´en waves on the planetary surface, then they will be observable
by a spacecraft when it passes magnetic ﬁeld lines on which the discharge occurred. As the waves
propagate, because B and ρ are time independent and hence ∂/∂t = 0, the frequency ω and energy
ℏω of each quantum is conserved, and conservation of quanta implies conservation of wave energy.
Because the Alfv´en speed generally diminishes with increasing distance from the planet, conservation
of wave energy typically requires the waves’ energy density and amplitude to increase as they climb
upward.
is not included in the geometric-optics propagation laws; it is a fundamentally wave-
based phenomenon and is lost when one goes to the particle-motion regime. In the
limit that the wave packet becomes very large compared to its wavelength or that the
packet propagates for only a short time, the spreading is small (Ex. 7.2). This is the
geometric-optics regime, and geometric optics ignores the spreading.
Many other wave phenomena are missed by geometric optics. Examples are
diffraction (e.g., at a geometric-optics caustic; Secs. 7.5 and 8.6), nonlinear wave-wave
coupling (Chaps. 10 and 23, and Sec. 16.3), and parametric ampliﬁcation of waves by
370
Chapter 7. Geometric Optics

rapid time variations of the medium (Sec. 10.7.3)—which shows up in quantum me-
chanics as particle production (i.e., a breakdown of the law of conservation of quanta).
In Sec. 28.7.1 , we will encounter such particle production in inﬂationary models of
the early universe.
7.3.6
7.3.6 Fermat’s Principle
principle of least action
Hamilton’s equations of optics allow us to solve for the paths of rays in media that
vary both spatially and temporally. When the medium is time independent, the rays
x(t) can be computed from a variational principle due to Fermat. This is the optical
analog of the classical dynamics principle of least action,7 which states that, when a
particle moves from one point to another through a time-independent potential (so
its energy, the hamiltonian, is conserved), then the path q(t) that it follows is one that
extremizes the action
J =

p . dq
(7.43)
(where q and p are the particle’s generalized coordinates and momentum), subject
to the constraint that the paths have a ﬁxed starting point, a ﬁxed endpoint, and
constant energy. The proof (e.g., Goldstein, Poole, and Safko, 2002, Sec. 8.6) carries
over directly to optics when we replace the hamiltonian by , q by x, and p by k. The
resulting Fermat principle, stated with some care, has the following form.
Fermat’s principle
Consider waves whose hamiltonian (k, x) is independent of time. Choose an
initial location xinitial and a ﬁnal location xﬁnal in space, and consider the rays x(t)
that connect these two points. The rays (usually only one) are those paths that satisfy
the variational principle
δ

k . dx = 0.
(7.44)
In this variational principle, k must be expressed in terms of the trial path x(t) using
Hamilton’s equation dxj/dt = −∂/∂kj; the rate that the trial path is traversed (i.e.,
the magnitude of the group velocity) must be adjusted to keep  constant along the
trial path (which means that the total time taken to go from xinitial to xﬁnal can differ
from one trial path to another). And of course, the trial paths must all begin at xinitial
and end at xﬁnal.
PATH INTEGRALS
Notice that, once a ray has been identiﬁed by this action principle, it has k = ∇ϕ, and
therefore the extremal value of the action

k . dx along the ray is equal to the waves’
7.
This is commonly attributed to Maupertuis, though others, including Leibniz and Euler, understood it
earlier or better. This “action” and the rules for its variation are different from those in play in Hamilton’s
principle.
7.3 Waves in an Inhomogeneous, Time-Varying Medium
371

phase difference ϕ between xinitial and xﬁnal. Correspondingly, for any trial path, we
can think of the action as a phase difference along that path,
ϕ =

k . dx,
(7.45a)
and we can think of Fermat’s principle as saying that the particle travels along a path
of extremal phase difference ϕ. This can be reexpressed in a form closely related to
Feynman’s path-integral formulation of quantum mechanics (Feynman, 1966). We can
regard all the trial paths as being followed with equal probability. For each path, we
are to construct a probability amplitude eiϕ, and we must then add together these
amplitudes,
 
all paths
eiϕ,
(7.45b)
to get the net complex amplitude for quanta associated with the waves to travel from
xinitial to xﬁnal. The contributions from almost all neighboring paths will interfere
destructively. The only exceptions are those paths whose neighbors have the same
values of ϕ, to ﬁrst order in the path difference. These are the paths that extremize
the action (7.44): they are the wave’s rays, the actual paths of the quanta.
SPECIALIZATION TO  = C(x)k
Fermat’s principle takes on an especially simple form when not only is the hamil-
tonian (k, x) time independent, but it also has the simple dispersion-free form
 = C(x)k—a form valid for the propagation of light through a time-independent
dielectric, and sound waves through a time-independent, inhomogeneous ﬂuid, and
electromagneticorgravitationalwavesthroughatime-independent, Newtoniangrav-
itational ﬁeld (Sec. 7.6). In this  = C(x)k case, the hamiltonian dictates that for each
trial path, k is parallel to dx, and therefore k . dx = kds, where s is distance along the
path. Using the dispersion relation k = /C and noting that Hamilton’s equation
dxj/dt = ∂/∂kj implies ds/dt = C for the rate of traversal of the trial path, we see
that k . dx = kds = dt. Since the trial paths are constrained to have  constant, Fer-
mat’s principle (7.44) becomes a principle of extremal time: The rays between xinitial
and xﬁnal are those paths along which
principle of extreme time
for dispersionless wave

dt =

ds
C(x) =
 n(x)
c ds
(7.46)
is extremal. In the last expression we have adopted the convention used for light in a
index of refraction
dielectric medium, that C(x) = c/n(x), where c is the speed of light in vacuum, and n
is the medium’s index of refraction. Since c is constant, the rays are paths of extremal
optical path length

n(x)ds.
We can use Fermat’s principle to demonstrate that, if the medium contains
no opaque objects, then there will always be at least one ray connecting any two
372
Chapter 7. Geometric Optics

points. This is because there is a lower bound on the optical path between any
two points, given by nminL, where nmin is the lowest value of the refractive index
anywhere in the medium, and L is the distance between the two points. This means
that for some path the optical path length must be a minimum, and that path is then
a ray connecting the two points.
From the principle of extremal time, we can derive the Euler-Lagrange differential
equation for the ray. For ease of derivation, we write the action principle in the form
δ

n(x)
&
dx
ds
. dx
ds ds,
(7.47)
where the quantity in the square root is identically one. Performing a variation in the
usual manner then gives
ray equation for
dispersionless wave
d
ds

ndx
ds

= ∇n,
i.e.,
d
ds
 1
C
dx
ds

= ∇
 1
C

.
(7.48)
This is equivalent to Hamilton’s equations for the ray, as one can readily verify using
the hamiltonian  = kc/n (Ex. 7.7).
Equation (7.48) is a second-order differential equation requiring two boundary
conditions to deﬁne a solution. We can either choose these to be the location of the
start of the ray and its starting direction, or the start and end of the ray. A simple case
arises when the medium is stratiﬁed [i.e., when n = n(z), where (x, y, z) are Cartesian
coordinates]. Projecting Eq. (7.48) perpendicular to ez, we discover that ndy/ds and
ndx/ds are constant, which implies
Snell’s law
n sin θ = constant,
(7.49)
where θ is the angle between the ray and ez. This is a variant of Snell’s law of refraction.
Snell’s law is just a mathematical statement that the rays are normal to surfaces
(wavefronts) on which the eikonal (phase) ϕ is constant (cf. Fig. 7.4).8 Snell’s law is
valid not only when n(x) varies slowly but also when it jumps discontinuously, despite
the assumptions underlying geometric optics failing at a discontinuity.
EXERCISES
Exercise 7.7 Derivation: Hamilton’s Equations for Dispersionless Waves;
Fermat’s Principle
Show that Hamilton’s equations for the standard dispersionless dispersion rela-
tion (7.4) imply the same ray equation (7.48) as we derived using Fermat’s
principle.
8.
Another important application of this general principle is to the design of optical instruments, where it
is known as the Abb´e condition. See, e.g., Born and Wolf (1999).
7.3 Waves in an Inhomogeneous, Time-Varying Medium
373

2
ϕ = const
k
k
ez
θ1
θ2
n2
n1
θ1
θ2
λ1
λ2
1
FIGURE 7.4 Illustration of Snell’s law of refraction at the interface between two
media, for which the refractive indices are n1 and n2 (assumed less than n1). As
the wavefronts must be continuous across the interface, simple geometry tells us
that λ1/ sin θ1 = λ2/ sin θ2. This and the fact that the wavelengths are inversely
proportional to the refractive index, λj ∝1/nj, imply that n1 sin θ1 = n2 sin θ2, in
agreement with Eq. (7.49).
Exercise 7.8 Example: Self-Focusing Optical Fibers
Optical ﬁbers in which the refractive index varies with radius are commonly used to
transport optical signals. When the diameter of the ﬁber is many wavelengths, we can
use geometric optics. Let the refractive index be
n = n0(1 −α2r2)1/2,
(7.50a)
where n0 and α are constants, and r is radial distance from the ﬁber’s axis.
(a) Consideraraythatleavestheaxisoftheﬁberalongadirectionthatmakesanangle
β to the axis. Solve the ray-transport equation (7.48) to show that the radius of
the ray is given by
r = sin β
α
8888sin
 αz
cos β
8888 ,
(7.50b)
where z measures distance along the ﬁber.
(b) Next consider the propagation time T for a light pulse propagating along the ray
with β ≪1, down a long length L of ﬁber. Show that
T = n0L
C [1 + O(β4)],
(7.50c)
and comment on the implications of this result for the use of ﬁber optics for
communication.
374
Chapter 7. Geometric Optics

Exercise 7.9 **Example: Geometric Optics for the Schr¨odinger Equation
Consider the nonrelativistic Schr¨odinger equation for a particle moving in a time-
dependent, 3-dimensional potential well:
−ℏ
i
∂ψ
∂t =
'
1
2m
ℏ
i ∇
2
+ V (x, t)
(
ψ.
(7.51)
(a) Seek a geometric-optics solution to this equation with the form ψ = AeiS/ℏ,
where A and V are assumed to vary on a lengthscale L and timescale T long
compared to those, 1/k and 1/ω, on which S varies. Show that the leading-
order terms in the two-lengthscale expansion of the Schr¨odinger equation give
the Hamilton-Jacobi equation
∂S
∂t + 1
2m(∇S)2 + V = 0.
(7.52a)
Our notation ϕ ≡S/ℏfor the phase ϕ of the wave function ψ is motivated by the
fact that the geometric-optics limit of quantum mechanics is classical mechanics,
and the function S = ℏϕ becomes, in that limit, “Hamilton’s principal function,”
which obeys the Hamilton-Jacobi equation (see, e.g., Goldstein, Poole, and Safko,
2002, Chap. 10). [Hint: Use a formal parameter σ to keep track of orders (Box 7.2),
and argue that terms proportional to ℏn are of order σ n. This means there must
be factors of σ in the Schr¨odinger equation (7.51) itself.]
(b) From Eq. (7.52a) derive the equation of motion for the rays (which of course is
identical to the equation of motion for a wave packet and therefore is also the
equation of motion for a classical particle):
dx
dt = p
m ,
dp
dt = −∇V ,
(7.52b)
where p = ∇S.
(c) Derive the propagation equation for the wave amplitude A and show that it
implies
d|A|2
dt
+ |A|2∇. p
m
= 0.
(7.52c)
Interpret this equation quantum mechanically.
7.4
7.4 Paraxial Optics
It is quite common in optics to be concerned with a bundle of rays that are almost
parallel (i.e., for which the angle the rays make with some reference ray can be
treated as small). This approximation is called paraxial optics, and it permits one
to linearize the geometric-optics equations and use matrix methods to trace their
7.4 Paraxial Optics
375

ex
ez
ray
reference ray (optic axis)
FIGURE 7.5 A reference ray (the z-axis) and an adjacent ray identiﬁed by
its transverse distances x(z) and y(z), from the reference ray.
rays. The resulting matrix formalism underlies the ﬁrst-order theory of simple optical
instruments (e.g., the telescope and the microscope).
We develop the paraxial optics formalism for waves whose dispersion relation
has the simple, time-independent, nondispersive form  = kc/n(x). This applies to
light in a dielectric medium—the usual application. As we shall see, it also applies
to charged particles in a storage ring or electron microscope (Sec. 7.4.2) and to light
being lensed by a weak gravitational ﬁeld (Sec. 7.6).
We restrict ourselves to a situation where there exists a ray that is a straight line,
except when it reﬂects off a mirror or other surface. We choose this as a reference
ray (also called the optic axis) for our formalism, and we orient the z-axis of a
Cartesian coordinate system along it (Fig. 7.5). Let the 2-dimensional vector x(z) be
the transverse displacement of some other ray from this reference ray, and denote by
(x, y) = (x1, x2) the Cartesian components of x.
Under paraxial conditions, |x| is small compared to the z lengthscales of the
propagation, so we can Taylor expand the refractive index n(x, z) in (x1, x2):
n(x, z) = n(0, z) + xin,i(0, z) + 1
2xixjn,ij(0, z) + . . . .
(7.53a)
Here the subscript commas denote partial derivatives with respect to the transverse
coordinates, n,i ≡∂n/∂xi.Thelinearizedformoftheray-propagationequation(7.48)
is then given by
d
dz

n(0, z)dxi
dz

= n,i(0, z) + xjn,ij(0, z).
(7.53b)
In order for the reference ray xi = 0 to satisfy this equation, n,i(0, z) must vanish,
so Eq. (7.53b) becomes a linear, homogeneous, second-order equation for the path of
a nearby ray, x(z):
paraxial ray equation
 d
dz
 ndxi
dz

= xjn,ij.
(7.54)
Here n and n,ij are evaluated on the reference ray. It is helpful to regard z as “time”
and think of Eq. (7.54) as an equation for the 2-dimensional motion of a particle (the
376
Chapter 7. Geometric Optics

ray) in a quadratic potential well. We can solve Eq. (7.54) given starting values x(z′)
and ˙x(z′), where the dot denotes differentiation with respect to z, and z′ is the starting
location. The solution at some later point z is linearly related to the starting values.
We can capitalize on this linearity by treating {x(z), ˙x(z)} as a 4-dimensional vector
Vi(z), with
V1 = x,
V2 = ˙x,
V3 = y,
and
V4 = ˙y,
(7.55a)
and embodying the linear transformation [linear solution of Eq. (7.54)] from location
z′ to location z in a transfer matrix Jab(z, z′):
paraxial transfer matrix
Va(z) = Jab(z, z′) . Vb(z′),
(7.55b)
where there is an implied sum over the repeated index b. The transfer matrix contains
full information about the change of position and direction of all rays that propagate
fromz′ toz.Asisalwaysthecaseforlinearsystems, thetransfermatrixforpropagation
over a large interval, from z′ to z, can be written as the product of the matrices for two
subintervals, from z′ to z′′ and from z′′ to z:
Jac(z, z′) = Jab(z, z′′)Jbc(z′′, z′).
(7.55c)
7.4.1
7.4.1 Axisymmetric, Paraxial Systems: Lenses, Mirrors, Telescopes, Microscopes,
and Optical Cavities
If the index of refraction is everywhere axisymmetric, so n = n(

x2 + y2, z), then
there is no coupling between the motions of rays along the x and y directions, and
the equations of motion along x are identical to those along y. In other words,
J11 = J33, J12 = J34, J21 = J43, and J22 = J44 are the only nonzero components of the
transfer matrix. This reduces the dimensionality of the propagation problem from 4
dimensions to 2: Va can be regarded as either {x(z), ˙x(z)} or {y(z), ˙y(z)}, and in both
cases the 2 × 2 transfer matrix Jab is the same.
axisymmetric transfer
matrices
Let us illustrate the paraxial formalism by deriving the transfer matrices of a few
simple, axisymmetric optical elements. In our derivations it is helpful conceptually
to focus on rays that move in the x-z plane (i.e., that have y = ˙y = 0). We write the
2-dimensional Vi as a column vector:
Va =
 x
˙x

.
(7.56a)
The simplest case is a straight section of length d extending from z′ to z = z′ + d. The
components of V will change according to
x = x′ + ˙x′d,
˙x = ˙x′,
7.4 Paraxial Optics
377

so
for straight section
Jab =
 1
d
0
1

for a straight section of length d,
(7.56b)
where x′ = x(z′), and so forth. Next, consider a thin lens with focal length f . The
usual convention in optics is to give f a positive sign when the lens is converging
and a negative sign when diverging. A thin lens gives a deﬂection to the ray that is
linearly proportional to its displacement from the optic axis, but does not change
its transverse location. Correspondingly, the transfer matrix in crossing the lens
(ignoring its thickness) is
for thin lens
Jab =

1
0
−f −1
1

for a thin lens with focal length f .
(7.56c)
Similarly, a spherical mirror with radius of curvature R (again adopting a positive
sign for a converging mirror and a negative sign for a diverging mirror) has a transfer
matrix
for spherical mirror
Jab =

1
0
−2R−1
1

for a spherical mirror with radius of curvature R.
(7.56d)
(Recall our convention that z always increases along a ray, even when the ray reﬂects
off a mirror.)
As a simple illustration, we consider rays that leave a point source located a
distance u in front of a converging lens of focal length f , and we solve for the ray
positionsadistancev behindthelens(Fig.7.6).Thetotaltransfermatrixisthetransfer
matrix (7.56b) for a straight section, multiplied by the product of the lens transfer
matrix (7.56c) and a second straight-section transfer matrix:
Jab =
 1
v
0
1
 
1
0
−f −1
1
  1
u
0
1

=
 1 −vf −1
u + v −uvf −1
−f −1
1 −uf −1

.
(7.57)
Whenthe1-2element(upperrightentry)ofthistransfermatrixvanishes, theposition
conjugate planes
of the ray after traversing the optical system is independent of the starting direction.
In other words, rays from the point source form a point image. When this happens,
the planes containing the source and the image are said to be conjugate. The condition
for this to occur is
thin-lens equations
1
u + 1
v = 1
f .
(7.58)
378
Chapter 7. Geometric Optics

u
v
source
lens
FIGURE7.6 Simpleconverginglensusedtoillustratetheuseoftransfer
matrices. The total transfer matrix is formed by taking the product
of the straight-section transfer matrix with the lens matrix and
another straight-section matrix.
θ
Mθ
objective
ray
ray
ray
ray
optic axis
eye piece
FIGURE 7.7 Simple refracting telescope. By convention θ > 0 and Mθ < 0,
so the image is inverted.
This is the standard thin-lens equation. The linear magniﬁcation of the image is given
by M = J11 = 1 −v/f , that is,
M = −v
u ,
(7.59)
where the negative sign means that the image is inverted. Note that, if a ray is reversed
in direction, it remains a ray, but with the source and image planes interchanged; u
and v are exchanged, Eq. (7.58) is unaffected, and the magniﬁcation (7.59) is inverted:
M →1/M.
EXERCISES
Exercise 7.10 Problem: Matrix Optics for a Simple Refracting Telescope
Consider a simple refracting telescope (Fig. 7.7) that comprises two converging lenses,
the objective and the eyepiece. This telescope takes parallel rays of light from distant
stars, which make an angle θ ≪1with the optic axis, and converts them into parallel
rays making a much larger angle Mθ. Here Mis the magniﬁcation with Mnegative,
7.4 Paraxial Optics
379

objective
ray
ray
ray
optic axis
eye piece
FIGURE 7.8 Simple microscope.
|M| ≫1, and |Mθ| ≪1. (The parallel output rays are then focused by the lens of a
human’s eye, to a point on the eye’s retina.)
(a) Use matrix methods to investigate how the output rays depend on the separation
of the two lenses, and hence ﬁnd the condition that the output rays are parallel
when the input rays are parallel.
(b) How does the magniﬁcation M depend on the ratio of the focal lengths of the
two lenses?
(c) If, instead of looking through the telescope with one’s eye, one wants to record the
stars’ image on a photographic plate or CCD, how should the optics be changed?
Exercise 7.11 Problem: Matrix Optics for a Simple Microscope
A microscope takes light rays from a point on a microscopic object, very near the optic
axis, and transforms them into parallel light rays that will be focused by a human eye’s
lens onto the eye’s retina (Fig. 7.8). Use matrix methods to explore the operation of
such a microscope. A single lens (magnifying glass) could do the same job (rays from
a point converted to parallel rays). Why does a microscope need two lenses? What
focal lengths and lens separations are appropriate for the eye to resolve a bacterium
100 μm in size?
Exercise 7.12 Example: Optical Cavity—Rays Bouncing between Two Mirrors
Considertwosphericalmirrors, eachwithradiusofcurvatureR, separatedbydistance
d so as to form an optical cavity (Fig. 7.9). A laser beam bounces back and forth
between the two mirrors. The center of the beam travels along a geometric-optics ray.
(We study such beams, including their diffractive behavior, in Sec. 8.5.5.)
(a) Show, using matrix methods, that the central ray hits one of the mirrors (either
one) at successive locations x1, x2, x3, . . . (where x ≡(x, y) is a 2-dimensional
vector in the plane perpendicular to the optic axis), which satisfy the difference
equation
xk+2 −2bxk+1 + xk = 0,
(7.60a)
380
Chapter 7. Geometric Optics

x3
x2
x1
FIGURE 7.9 An optical cavity formed by two mirrors,
and a light beam bouncing back and forth inside it.
where
b = 1 −4d
R + 2d2
R2 .
(7.60b)
Explain why this is a difference-equation analog of the simple-harmonic-
oscillator equation.
(b) Show that this difference equation has the general solution
xk = A cos(k cos−1 b) + B sin(k cos−1 b).
(7.60c)
Obviously, A is the transverse position x0 of the ray at its 0th bounce. The ray’s
0th position x0 and its 0th direction of motion ˙x0 together determine B.
(c) Show that if 0 ≤d ≤2R, the mirror system is stable. In other words, all rays
oscillate about the optic axis. Similarly, show that if d > 2R, the mirror system is
unstable and the rays diverge from the optic axis.
(d) For an appropriate choice of initial conditions x0 and ˙x0, the laser beam’s succes-
sive spots on the mirror lie on a circle centered on the optic axis. When operated
in this manner, the cavity is called a Harriet delay line. How must d/R be chosen
so that the spots have an angular step size θ? (There are two possible choices.)
7.4.2
7.4.2 Converging Magnetic Lens for Charged Particle Beam
Since geometric optics is the same as particle dynamics, matrix equations can be used
to describe paraxial motions of electrons or ions in a storage ring. (Note, however,
that the hamiltonian for such particles is dispersive, since it does not depend linearly
on the particle momentum, and so for our simple matrix formalism to be valid, we
must conﬁne attention to a monoenergetic beam of particles.)
The simplest practical lens for charged particles is a quadrupolar magnet.
Quadrupolar magnetic ﬁelds are used to guide particles around storage rings. If we
orient our axes appropriately, the magnet’s magnetic ﬁeld can be expressed in the form
quadrupolar magnetic
ﬁeld
B = B0
r0
(yex + xey)
independent of z within the lens
(7.61)
7.4 Paraxial Optics
381

ey
ex
N
N
S
S
FIGURE 7.10 Quadrupolar magnetic lens. The magnetic ﬁeld lines lie in
a plane perpendicular to the optic axis. Positively charged particles
moving along ez converge when y = 0 and diverge when x = 0.
(Fig. 7.10). Particles traversing this magnetic ﬁeld will be subjected to a Lorentz force
that curves their trajectories. In the paraxial approximation, a particle’s coordinates
satisfy the two differential equations
¨x = −x
λ2 ,
¨y = y
λ2 ,
(7.62a)
where the dots (as above) mean d/dz = v−1d/dt, and
λ =
 pr0
qB0
1/2
(7.62b)
[cf. Eq. (7.61)], with q the particle’s charge (assumed positive) and p its momentum.
The motions in the x and y directions are decoupled. It is convenient in this case to
work with two 2-dimensional vectors, {Vx1, Vx2} ≡{x, ˙x} and {Vy1, Vy2} = {y, ˙y}.
From the elementary solutions to the equations of motion (7.62a), we infer that the
transfer matrices from the magnet’s entrance to its exit are Jx ab, Jy ab, where
transfer matrices for
quadrupolar magnetic lens
Jx ab =

cos φ
λ sin φ
−λ−1 sin φ
cos φ

,
(7.63a)
Jy ab =

cosh φ
λ sinh φ
λ−1 sinh φ
cosh φ

,
(7.63b)
and
φ = L/λ,
(7.63c)
with L the distance from entrance to exit (i.e., the lens thickness).
382
Chapter 7. Geometric Optics

The matrices Jx ab and Jy ab can be decomposed as follows:
Jx ab =
 1
λ tan φ/2
0
1
 
1
0
−λ−1 sin φ
1
  1
λ tan φ/2
0
1

(7.63d)
Jy ab =
 1
λ tanh φ/2
0
1
 
1
0
λ−1 sinh φ
1
  1
λ tanh φ/2
0
1

(7.63e)
Comparing with Eqs. (7.56b) and (7.56c), we see that the action of a single magnet
is equivalent to the action of a straight section, followed by a thin lens, followed by
another straight section. Unfortunately, if the lens is focusing in the x direction, it
must be defocusing in the y direction and vice versa. However, we can construct a lens
that is focusing along both directions by combining two magnets that have opposite
polarity but the same focusing strength φ = L/λ.
combining two magnets to
make a converging lens
Consider ﬁrst the particles’ motion in the x direction. Let
f+ = λ/ sin φ
and
f−= −λ/ sinh φ
(7.64)
be the equivalent focal lengths of the ﬁrst converging lens and the second diverging
lens. If we separate the magnets by a distance s, this must be added to the two effective
lengths of the two magnets to give an equivalent separation of d = λ tan(φ/2) + s +
λ tanh(φ/2) for the two equivalent thin lenses. The combined transfer matrix for the
two thin lenses separated by this distance d is then
transfer matrix for
converging magnetic
lens

1
0
−f −1
−
1
  1
d
0
1
 
1
0
−f −1
+
1

=
 1 −df −1
+
d
−f −1
∗
1 −df −1
−

,
(7.65a)
where
1
f∗
= 1
f−
+ 1
f+
−
d
f−f+
= sin φ
λ
−sinh φ
λ
+ d sin φ sinh φ
λ2
.
(7.65b)
If we assume that φ ≪1 and s ≪L, then we can expand as a Taylor series in φ to
obtain
f∗≃3λ
2φ3 = 3λ4
2L3.
(7.66)
The effective focal length f∗of the combined magnets is positive, and so the lens has
a net focusing effect. From the symmetry of Eq. (7.65b) under interchange of f+ and
f−, it should be clear that f∗is independent of the order in which the magnets are
encountered. Therefore, if we were to repeat the calculation for the motion in the
y direction, we would get the same focusing effect. (The diagonal elements of the
transfer matrix are interchanged, but as they are both close to unity, this difference is
rather small.)
The combination of two quadrupole lenses of opposite polarity can therefore
imitate the action of a converging lens. Combinations of magnets like this are
used to collimate particle beams in storage rings, particle accelerators, and electron
microscopes.
7.4 Paraxial Optics
383

7.5
7.5 Catastrophe Optics
7.5.1
7.5.1 Image Formation
CAUSTICS
Many simple optical instruments are carefully made to form point images from point
sources. However, naturally occurring optical systems, and indeed precision optical
instruments when examined in ﬁne detail, bring light to a focus not at a point, but
instead on a 2-dimensional surface—an envelope formed by the rays—called a caustic.
caustic
Caustics are often seen in everyday life. For example, when bright sunlight is reﬂected
by the inside of an empty coffee mug some of the rays are reﬂected specularly (angle
of incidence equals angle of reﬂection) and some of the rays are reﬂected diffusely
(in all directions due to surface irregularity and multiple reﬂections and refractions
beneath the surface). The specular reﬂection by the walls—a cylindrical mirror—
forms a caustic surface. The intersection of this surface with the bottom forms caustic
lines that can be seen in diffuse reﬂection.9 These caustic lines are observed to meet
in a point. When the optical surfaces are quite irregular (e.g., the water surface in
a swimming pool10 or the type of glass used in bathrooms), then a caustic network
forms. Caustic lines and points are seen, just the same as with the mug (Fig. 7.11).
What may be surprising is that caustics like these, formed under quite general
catastrophes
conditions, can be classiﬁed into a rather small number of types, called catastrophes,
possessing generic properties and scaling laws (Thom, 1994). The scaling laws are
reminiscent of the renormalization group discussed in Sec. 5.8.3. Although we focus
on catastrophes in the context of optics (e.g., Berry and Upstill, 1980), where they are
caustics, the phenomenon is quite general and crops up in other subﬁelds of physics,
especially dynamics (e.g., Arnol’d, 1992) and thermodynamics (e.g., Ex. 7.16). It has
also been invoked, often quite controversially, in ﬁelds outside physics (e.g., Poston
and Stewart, 2012). Catastrophes can be found whenever we have a physical system
whose states are determined by extremizing a function, such as energy. Our treatment
will be quite heuristic, but the subject does have a formal mathematical foundation
that connects it to bifurcations and Morse theory (see Sec. 11.6; see also, e.g., Petters
et al., 2001).
STATE VARIABLES AND CONTROL PARAMETERS
Let us start with a speciﬁc, simple example. Suppose that there is a distant source
S and a detector D separated by free space. If we consider all the paths from S to
9.
The curve that is formed is called a “nephroid.”
10. The optics is quite complicated. Some rays from the Sun are reﬂected specularly by the surface of the
water, creating multiple images of the Sun. As the Sun is half a degree in diameter, these produce
thickened caustic lines. Some rays are refracted by the water, forming caustic surfaces that are intersected
by the bottom of the pool to form a caustic pattern. Some light from this pattern is reﬂected diffusely
before being refracted a second time on the surface of the water and ultimately detected by a retina or a
CCD. Other rays are reﬂected multiple times.
384
Chapter 7. Geometric Optics

(b)
(a)
FIGURE 7.11 Photographs of caustics. (a) Simple caustic pattern formed by a coffee mug. (b) Caustic
network formed in a swimming pool. The generic structure of these patterns comprises fold lines
meeting at cusp points.
P1
P2
P3
S
b
a
y
x
D
D
axis
(a)
(b)
z
FIGURE 7.12 (a) Alternative paths make up a sequence of straight segments from a source S to a
detector D. The path S-P1-P2-P3-D can be simpliﬁed to a shorter path S-P1-P3-D, and this process
can be continued until we have the minimum number of segments needed to exhibit the catastrophe.
The (true) ray, with the smallest phase difference, is the axis S-D. (b) A single path from a distant
source intersecting a screen at {a, b} and ending at detector D with coordinates {x, y, z}.
D there is a single extremum—a minimum—in the phase difference, ϕ = ωt =

k . dx. By Fermat’s principle, this is the (true) ray—the axis—connecting the two
points. There are an inﬁnite number of alternative paths that could be deﬁned by an
inﬁnite set of parameters, but wherever else the rays go, the phase difference is larger.
Take one of these alternative paths connecting S and D and break it down into a
sequenceofconnectedsegments(Fig.7.12a).Wecanimaginereplacingtwosuccessive
segments with a single segment connecting their endpoints. This will reduce the phase
difference. The operation can be repeated until we are left with the minimum number
of segments, speciﬁed by the minimum number of necessary variables that we need to
exhibit the catastrophe. The order in which we do this does not matter, and the ﬁnal
variables characterizing the path can be chosen for convenience. These variables are
known as state variables.
state variables
7.5 Catastrophe Optics
385

Next, introduce a screen perpendicular to the S–D axis and close to D (Fig. 7.12b).
Consider a path from S, nearly parallel to the axis and intersecting the screen at
a point with Cartesian coordinates {a, b} measured from the axis. There let it be
deﬂected toward D. In this section and the next, introduce the delay t ≡ϕ/ω,
subtracting off the constant travel time along the axis in the absence of the screen,
to measure the phase. The additional geometric delay associated with this ray is given
approximately by
tgeo = a2 + b2
2zc
,
(7.67)
where z ≫{a, b} measures the distance from the screen to D, parallel to the axis, and
control parameters
c is the speed of light. The coordinates {a, b} act as state variables, and the true ray is
determined by differentiating with respect to them. Next, move D off the axis and give
it Cartesian coordinates {x, y, z} with the x-y plane parallel to the a-b plane, and the
transverse coordinates measured from the original axis. As these coordinates specify
one of the endpoints, they do not enter into the variation that determines the true ray,
but they do change tgeo to [(a −x)2 + (b −y)2]/(2zc). These {x, y, z} parameters are
examples of control parameters.In general, the number of control parameters that we
use is also the minimum needed to exhibit the catastrophe, and the choice is usually
determined by algebraic convenience.
FOLD CATASTROPHE
Now replace the screen with a thin lens of refractive index n and thickness w(a, b).
This introduces an additional contribution to the delay, tlens = (n −1)w/c. The true
ray will be ﬁxed by the variation of the sum of the geometric and lens delays with
respect to a and b plus any additional state variables that are needed. Suppose that
the lens is cylindrical so rays are bent only in the x direction and one state vari-
able, a, sufﬁces. Let us use an analytically tractable example, tlens = s2(1 −2a2/s2 +
a4/s4)/(4f c), for |a| < s, where f ≫s is the focal length (Fig. 7.13). Place the de-
tector D on the axis with z < f . The delay along a path is:
t ≡tgeo + tlens =
a2
2f zc

f −z + a2z
2s2

,
(7.68)
dropping a constant. This leaves the single minimum and the true ray at a = 0.
Now displace D perpendicular to the axis a distance x with z ﬁxed. tgeo becomes
(a −x)2/(2zc), and the true ray will be parameterized by the single real value of a
that minimizes t and therefore solves
x = a
f

f −z + za2
s2

.
(7.69)
The ﬁrst two terms, f −z, represent a perfect thin lens [cf. J11in Eq. (7.57)]; the third
represents an imperfection.
A human eye at D [coordinates (x, y, z)]focuses the ray through D and adjacent
rays onto its retina, producing there a point image of the point source at S. The
386
Chapter 7. Geometric Optics

z
C
B
A
t
a
a
t
a
t
a
f
screen
FIGURE 7.13 Light from a distant source is normally incident on a thin, phase-changing lens. The phase
change depends solely on the distance a from the axis. The delay t along paths encountering a detector
D located at (x, z) can be calculated using an equation such as Eq. (7.68). The true rays are located
where t is extremized. The envelope created by these rays comprises two fold caustic curves (red) that
meet at a cusp point. When D lies outside the caustic, for example at A, there is only one true ray
(cyan) where t has its single minimum. When D lies inside the caustic, for example at point B, there
are three true rays associated with two minima (orange, cyan) and one maximum (purple) of t. When
D lies on the caustic, for example at C, there is one minimum (cyan) and a point of inﬂection (green).
The magniﬁcation is formally inﬁnite on the caustic. The cusp at the end of the caustic is the focus, a
distance f from the screen.
power P = dE/dt in that image is the energy ﬂux at D times the area inside the eye’s
iris, so the image power is proportional to the energy ﬂux. Since the energy ﬂux is
proportional to the square of the ﬁeld amplitude A2 and A ∝1/
√
A, where A is the
area of a bundle of rays [Eq. (7.35d)], the image power is P ∝1/A.
Consider a rectangular ray bundle that passes through {a, b} on the screen with
edges da and db, and area Ascreen = dadb. The bundle’s area when it arrives at D
is AD = dxdy. Because the lens is cylindrical, dy = db, so the ratio of power seen
by an eye at D to that seen by an eye at the screen (i.e., the lens’s magniﬁcation) is
M = dPD/dPscreen = Ascreen/AD = da/dx. Using Eq. (7.69), we ﬁnd
H ≡M−1 = dx
da = zc
 d2t
da2

=
f −z
f
+ 3 a2z
s2f

.
(7.70)
If the curvature H of the delay in the vicinity of a true ray is decreased, the mag-
niﬁcation is increased. When z < f , the curvature is positive. When z > f the cur-
vature for a = x = 0 is negative, and the magniﬁcation is M = −f/(z −f ), corre-
sponding to an inverted image. However, there are now two additional images with
a = ±z−1/2(z −f )1/2s atminimawithassociatedmagniﬁcations M= 1
2f (z −f )−1.
NextmovethedetectorD fartherawayfromtheaxis.Amaximumandaminimum
in t will become a point of inﬂection and, equivalently, two of the images will merge
when a = af = ±3−1/2z−1/2(z −f )1/2s or
x = xf ≡∓2f −1z−1/2(z −f )3/2s.
(7.71)
7.5 Catastrophe Optics
387

This is the location of the caustic; in 3-dimensional space it is the surface shown in
the ﬁrst panel of Fig. 7.15 below.
fold catastrophe
The magniﬁcation of the two images will diverge at the caustic and, expanding H
to linear order about zero, we ﬁnd that M= ±2−13−1/4f 1/2s1/2z−1/4(z −f )−1/4|x −
xf|−1/2 for each image. However, when |x| > xf, the two images vanish. This abrupt
change in the optics—two point images becoming inﬁnitely magniﬁed and then
vanishing as the detector is moved—is an example of a fold catastrophe occurring at
a caustic. (Note that the algebraic sum of the two magniﬁcations is zero in the limit.)
It should be pointed out that the divergence of the magniﬁcation does not happen
in practice for two reasons. The ﬁrst is that a point source is only an idealization, and
if we allow the source to have ﬁnite size, different parts will produce caustics at slightly
differentlocations.Thesecondisthatgeometricoptics, onwhichouranalysisisbased,
pretends that the wavelength of light is vanishingly small. In actuality, the wavelength
is always nonzero, and near a caustic its ﬁniteness leads to diffraction effects, which
also limit the magniﬁcation to a ﬁnite value (Sec. 8.6).
standard form for
catastrophes
Although we have examined one speciﬁc and stylized example, the algebraic de-
tails can be worked out for any conﬁguration governed by geometric optics. However,
they are less important than the scaling laws—for example, M ∝|x −xf|−1/2—that
become increasingly accurate as the catastrophe (caustic) is approached. For this rea-
son, catastrophes are commonly given a standard formchosen to exhibit these features
and only valid very close to the catastrophe. We discuss this here just in the context
of geometrical optics, but the basic scalings are useful in other physics applications
(see, e.g., Ex. 7.16).
First we measure the state variables a, b, . . . in units of some appropriate scale.
Next we do likewise for the control parameters, x, y, . . . . We call the new state
variables and control parameters ˜a, ˜b, . . . and ˜x, ˜y . . . , respectively. We then Taylor
expand the delay about the catastrophe. In the case of the fold, we want to be able to
ﬁnd up to two extrema. This requires a cubic equation in ˜a. The constant is clearly
irrelevant, and an overall multiplying factor will not change the scalings. We are also
free to change the origin of ˜a, allowing us to drop either the linear or the quadratic
term (we choose the latter, so that the coefﬁcient is linearly related to x). If we adjust
the scaled delay in the vicinity of a fold catastrophe, Eq. (7.68) can be written in the
standard form:
for fold catastrophe
˜tfold = 1
3 ˜a3 −˜x ˜a,
(7.72)
where the coefﬁcients are chosen for algebraic convenience. The maximum number of
rays involved in the catastrophe is two, and the number of control parameters required
is one, which we can think of as being used to adjust the difference in ˜t between two
stationary points. The scaled magniﬁcations are now given by 9
M ≡(d ˜x/d ˜a)−1 =
± 1
2 ˜x−1/2, and the combined, scaled magniﬁcation is 9
M = ˜x−1/2 for ˜x > 0.
388
Chapter 7. Geometric Optics

CUSP CATASTROPHE
So far, we have only allowed D to move perpendicular to the axis along x. Now move
it along the axis toward the screen. We ﬁnd that xf decreases with decreasing z until it
vanishes at z = f . At this point, the central maximum in t merges simultaneously with
both minima, leaving a single image. This is an example of a cusp catastrophe.Working
in 1-dimensional state-variable space with two control parameters and applying the
same arguments as we just used with the fold, the standard form for the cusp can be
written as
for cusp catastrophe
˜tcusp = 1
4 ˜a4 −1
2 ˜z˜a2 −˜x ˜a.
(7.73)
The parameter ˜x is still associated with a transverse displacement of D, and we
can quickly persuade ourselves that ˜z ∝z −f by inspecting the quadratic term in
Eq. (7.68).
The cusp then describes a transition between one and three images, one of which
must be inverted with respect to the other two. The location of the image for a given
˜a and ˜z is
˜x = ˜a3 −˜z˜a.
(7.74)
Conversely, for a given ˜x and ˜z, there are one or three real solutions for ˜a(˜x, ˜z) and one
or three images. The equation satisﬁed by the fold lines where the transition occurs is
˜x = ± 2
33/2 ˜z3/2.
(7.75)
These are the two branches of a semi-cubical parabola (the caustic surface in 3 di-
mensions depicted in the second panel of Fig. 7.15 below), and they meet at the cusp
catastrophe where ˜x = ˜z = 0.
The scaled magniﬁcation at the cusp is
9
M (˜x, ˜z) =
∂˜x
∂˜a
−1
˜z
= [3˜a(˜x, ˜z)2 −z]−1.
(7.76)
SWALLOWTAIL CATASTROPHE
Now let the rays propagate in 3 dimensions, so that there are three control variables,
x, y, and z, where the y-axis is perpendicular to the x- and z-axes. The fold, which
was a point in 1 dimension and a line in 2, becomes a surface in 3 dimensions, and the
point cusp in 2 dimensions becomes a line in 3 (see Fig. 7.15 below). If there is still
only one state variable, then ˜t should be a quintic with up to four extrema. (In general,
a catastrophe involving as many as N images requires N −1control parameters for its
full description. These parameters can be thought of as independently changing the
relative values of ˜t at the extrema.) The resulting, four-image catastrophe is called a
swallowtail.(Inpractice, thiscatastropheonlyariseswhentherearetwostatevariables,
and additional images are always present. However, these are not involved in the
7.5 Catastrophe Optics
389

catastrophe.) Again following our procedure, we can write the standard form of the
swallowtail catastrophe as
forswallowtailcatastrophe
˜tswallowtail = 1
5 ˜a5 −1
3 ˜z˜a3 −1
2 ˜y ˜a2 −˜x ˜a.
(7.77)
There are two cusp lines in the half-space ˜z > 0, and these meet at the catastrophe
where ˜x = ˜y = ˜z = 0 (see Fig. 7.15 below). The relationship between ˜x, ˜y, and ˜z and
x, y, and z in this or any other example is not simple, and so the variation of the
magniﬁcation in the vicinity of the swallowtail catastrophe depends on the details.
HYPERBOLIC UMBILIC CATASTROPHE
Next increase the number of essential state variables to two. We can choose these to
be ˜a and ˜b. To see what is possible, sketch contours of t in the ˜a-˜b plane for ﬁxed
values of the control variables. The true rays will be associated with maxima, minima,
or saddle points, and each distinct catastrophe corresponds to a different way to nest
thecontours(Fig.7.14).Thepropertiesofthefold, cusp, andswallowtailareessentially
unchanged by the extra dimension. We say that they are structurally stable. However,
a little geometric experimentation uncovers a genuinely 2-dimensional nesting. The
hyperbolic umbilic catastrophe has two saddles, one maximum and one minimum.
Further algebraic experiment produces a standard form:
for hyperbolic umbilic
catastrophe
˜t = 1
3(˜a3 + ˜b3) −˜z˜a ˜b −˜x ˜a −˜y ˜b.
(7.78)
This catastrophe can be exhibited by a simple generalization of our example. We
replace the cylindrical lens described by Eq. (7.68) with a nearly circular lens where
the focal length fa for rays in the a-z plane differs from the focal length fb for rays in
the b-z plane.
t =
a2
2fazc
*
fa −z + a2z
2s2
a
+
+
b2
2fbzc
*
fb −z + b2z
2s2
b
+
.
(7.79)
This is an example of astigmatism. A pair of fold surfaces is associated with each of
astigmatism
these foci. These surfaces can cross, and when this happens a cusp line associated
with one fold surface can transfer onto the other fold surface. The point where this
happens is the hyperbolic umbilic catastrophe.
This example also allows us to illustrate a simple feature of magniﬁcation. When
the source and the detector are both treated as 2-dimensional, then we generalize the
curvature to the Hessian matrix
magniﬁcation matrix
:
H = 9
M
−1 =
 ∂˜x
∂˜a
∂˜y
∂˜a
∂˜x
∂˜b
∂˜y
∂˜b

.
(7.80)
The magniﬁcation matrix 9
M , which describes the mapping from the source plane to
the image plane, is simply the inverse of :
H . The four matrix elements also describe the
deformation of the image. As we describe in more detail when discussing elastostatics
(Sec. 11.2.2), the antisymmetric part of 9
M describes the rotation of the image, and
390
Chapter 7. Geometric Optics

b
b
b
b
a
max
(a)
(b)
(c)
(d)
1.0
0.5
0.0
–0.5
–10.0
–1.0
–0.5
0.0
0.5
1.0
a
min
min
min
1.0
0.5
0.0
–0.5
–10.0
–1.0
–0.5
0.0
0.5
1.0
a
max
max
1.0
0.5
0.0
–0.5
–10.0
–1.0
–0.5
0.0
0.5
1.0
a
max
1.0
0.5
0.0
–0.5
–10.0
–1.0
–0.5
0.0
0.5
1.0
FIGURE 7.14 Distinct nestings of contours of ˜t in state-variable space. (a) A 1-dimensional arrangement
of two saddle points and a maximum in the vicinity of a cusp. The locations of the extrema and their
curvatures change as the control parameters change. (b) A cusp formed by two minima and a saddle.
Although the nestings look different in 2 dimensions, this is essentially the same catastrophe when
considered in 1 dimension, which is all that is necessary to determine its salient properties. These are
the only contour nestings possible with two state variables and three extrema (or rays). (c) When we
increase the number of extrema to four, two more nestings are possible. The swallowtail catastrophe is
essentially a cusp with an additional extremum added to the end, requiring three control parameters
to express. It, too, is essentially 1-dimensional. (d) The hyperbolic umbilic catastrophe is essentially
2-dimensional and is associated with a maximum, a minimum, and two saddles. A distinct nesting
of contours with three saddle points and one extremum occurs in the elliptic umbilic catastrophe
(Ex. 7.13).
7.5 Catastrophe Optics
391

the symmetric part its magniﬁcation and stretching or shear. Both eigenvalues of 9
M
are positive at a minimum, and the image is a distorted version of the source. At a
saddle, one eigenvalue is positive, the other negative, and the image is inverted; at a
maximum, they are both negative, and the image is doubly inverted so that it appears
to have been rotated through a half-turn.
ELLIPTIC UMBILIC CATASTROPHE
There is a second standard form that can describe the nesting of contours just
discussed—a distinct catastrophe called the elliptic umbilic catastrophe (Ex. 7.13b):
standard form for elliptic
umbilic catastrophe
˜t = 1
3 ˜a3 −˜a ˜b2 −˜z(˜a2 + ˜b2) −˜x ˜a −˜y ˜b.
(7.81)
The caustic surfaces in three dimensions (˜x, ˜y, ˜z) for the ﬁve elementary catastro-
phes discussed here are shown in Fig. 7.15. Additional types of catastrophe are found
with more control parameters, for example, time (e.g., Poston and Stewart, 2012). This
is relevant, for example, to the twinkling of starlight in the geometric-optics limit.
EXERCISES
Exercise 7.13 Derivation and Problem: Cusps and Elliptic Umbilics
(a) Work through the derivation of Eq. (7.73) for the scaled time delay in the vicinity
of the cusp caustic for our simple example [Eq. (7.68)], with the aid of a suitable
change of variables (Goodman, Romani, Blandford, and Narayan, 1987, Appen-
dix B).
(b) Sketch the nesting of the contours for the elliptic umbilic catastrophe as shown
for the other four catastrophes in Fig. 7.14. Verify that Eq. (7.81) describes this
catastrophe.
Exercise 7.14 Problem: Cusp Scaling Relations
Consider a cusp catastrophe created by a screen as in the example and described by a
standard cusp potential, Eq. (7.73). Suppose that a detector lies between the folds, so
that there are three images of a single point source with state variables ˜ai.
(a) Explain how, in principle, it is possible to determine ˜a for a single image by
measurements at D.
(b) Make a 3-dimensional plot of the location of the image(s) in ˜a-˜x- ˜y space and
explain why the names “fold” and “cusp” were chosen.
(c) Prove as many as you can of the following scaling relations, valid in the limit as
the cusp catastrophe is approached:
3
 
i=1
˜ai = 0,
3
 
i=1
1
˜ai
= −˜z
˜x ,
3
 
i=1
9
M i = 0,
3
 
i=1
˜ai 9
M i = 0,
3
 
i=1
˜a2
i 9
M i = 1,
3
 
i=1
˜a3
i 9
M i = 0
and
3
 
i=1
˜a4
i 9
M = ˜z.
(7.82)
392
Chapter 7. Geometric Optics

fold
t = 1−4a4 − 1−2z a2 − x a
t = 1−3a3 − x a
x
y
z
cusp
hyperbolic umbilic
elliptic umbilic
t = 1−5a5 − 1−3z a3 − 1−2y a2 − x a
t = 1−3a3 − a b2 − z (a2 + b2) − x a − y b
t = 1−3(a3 + b3) − z a b − x a − y b
x
y
z
x
x
y
y
z
z
x
y
z
x
y
z
swallowtail
FIGURE 7.15 The ﬁve elementary catastrophes (caustic structures) that are possible for a
set of light rays speciﬁed by one or two state varables {˜a, ˜b} in 3-dimensional space with
coordinates (control parameters) {˜x, ˜y, ˜z}. The surfaces represent the loci of points of
inﬁnite magniﬁcation assuming a point source and geometric optics. The actual caustic
surfaces will be deformed versions of these basic shapes. The hyperbolic umbilic surfaces
are shown from two different viewpoints.
7.5 Catastrophe Optics
393

[Hint: You must retain the sign of the magniﬁcation.] Of course, not all of these are
useful. However, relations like these exist for all catastrophes and are increasingly
accurate as the separation of the images becomes much smaller than the scale of
variation of ˜t.
Exercise 7.15 Problem: Wavefronts
As we have emphasized, representing light using wavefronts is complementary to
treating it in terms of rays. Sketch the evolution of the wavefronts after they prop-
agate through a phase-changing screen and eventually form caustics. Do this for a
2-dimensional cusp, and then consider the formation of a hyperbolic umbilic catas-
trophe by an astigmatic lens.
Exercise 7.16 **Example: Van der Waals Catastrophe
The van der Waals equation of state (P + a/v2)(v −b) = kBT for H2O relates the
pressure P and speciﬁc volume (volume per molecule) v to the temperature T ; see
Sec. 5.7. Figure 5.8 makes it clear that, at some temperatures T and pressures P, there
are three allowed volumes v(T , P ), one describing liquid water, one water vapor, and
the third an unstable phase that cannot exist in Nature. At other values of T and P,
there is only one allowed v. The transition between three allowed v values and one
occurs along some curve in the T -P plane—a catastrophe curve.
(a) This curve must correspond to one of the elementary catastrophes explored in
the previous exercise. Based on the number of solutions for v(T , P ), which
catastrophe must it be?
(b) Change variables in the van der Waals equation of state to p = P/Pc −1, τ =
T/Tc −1, and ρ = vc/v −1, where Tc = 8a/(27bkB), Pc = a/(27b2), and vc =
3b are the temperature, pressure, and speciﬁc volume at the critical point C of
Fig. 5.8. Show that this change of variables brings the van der Waals equation of
state into the form
ρ3 −zρ −x = 0,
(7.83)
where z = −(p/3 + 8τ/3) and x = 2p/3 −8τ/3.
(c) This equation ρ3 −zρ −x is the equilibrium surface associated with the catas-
trophe-theory potential t(ρ; x, z) = 1
4ρ4 −1
2zρ2 −xρ [Eq. (7.73)]. Correspond-
ingly, the catastrophe [the boundary between three solutions v(T , P ) and one]
has the universal cusp form x = ±2(z/3)2/3 [Eq. (7.75)]. Plot this curve in the
temperature-pressure plane.
Note that we were guaranteed by catastrophe theory that the catastrophe curve would
have this form near its cusp point. However, it is a surprise and quite unusual that, for
394
Chapter 7. Geometric Optics

the van der Waals case, the cusp shape x = ±2(z/3)2/3 is not conﬁned to the vicinity
of the cusp point but remains accurate far from that point.
7.5.2
7.5.2 Aberrations of Optical Instruments
Much computational effort is expended in the design of expensive optical instruments
prior to prototyping and fabrication. This is conventionally discussed in terms of
aberrations, which provide a perturbative description of rays that complements the
singularity-based approach of catastrophe theory. While it is possible to design in-
struments that take all the rays from a point source S and focus them geometrically
onto a point detector D,11 this is not what is demanded of them in practice. Typically,
they have to map an extended image onto an extended surface, for example, a CCD
detector. Sometimes the source is large, and the instrument must achieve a large ﬁeld
of view; sometimes it is small, and image ﬁdelity close to the axis matters. Sometimes
light levels are low, and transmission losses must be minimized. Sometimes the band-
width of the light is large, and the variation of the imaging with frequency must be
minimized. Sometimes diffractive effects are important. The residual imperfections
aberrations
of an instrument are known as aberrations.
As we have shown, any (geometric-optics) instrument will map, one to many,
source points onto detector points. This mapping is usually expanded in terms of a
set of basis functions, and several choices are in use, for example, those due to Seidel
and Zernike (e.g., Born and Wolf, 1999, Secs. 5.3, 9.2). If we set aside effects caused by
chromatic aberration
the variation of the refractive index with wavelength, known as chromatic aberration,
there are ﬁve common types of geometrical aberration. Spherical aberration is the
spherical aberration
failure to bring a point on the optic axis to a single focus. Instead, an axisymmetric
cusp/fold caustic is created. We have already exhibited astigmatism in our discussion
of the hyperbolic umbilic catastrophe with a non-axisymmetric lens and an axial
source (Sec. 7.5.1). It is not hard to make axisymmetric lenses and mirrors, so this
does not happen much in practice. However, as soon as we consider off-axis surfaces,
we break the symmetry, and astigmatism is unavoidable. Curvature arises when the
curvature
surface on which the rays from point sources are best brought to a focus lies on a
curved surface, not on a plane. It is sometimes advantageous to accept this aberration
and to curve the detector surface.12 To understand coma, consider a small pencil of
coma
rays from an off-axis source that passes through the center of an instrument and is
brought to a focus. Now consider a cone of rays about this pencil that passes through
the periphery of the lens. When there is coma, these rays will on average be displaced
11. A simple example is to make the interior of a prolate ellipsoidal detector perfectly reﬂecting and to place
S and D at the two foci, as crudely implemented in whispering galleries.
12. For example, in a traditional Schmidt telescope.
7.5 Catastrophe Optics
395

radially. Coma can be ameliorated by reducing the aperture. Finally, there isdistortion,
distortion
in which the sides of a square in the source plane are pushed in (pin cushion) or out
(barrel) in the image plane.
7.6
7.6 Gravitational Lenses
7.6.1
7.6.1 Gravitational Deﬂection of Light
Albert Einstein’s general relativity theory predicts that light rays should be deﬂected
bythegravitationalﬁeldoftheSun(Ex.27.3; Sec.27.2.3).Newton’slawofgravitycom-
bined with his corpuscular theory of light also predicts this deﬂection, but through an
angle half as great as relativity predicts. A famous measurement, during a 1919 solar
eclipse, conﬁrmed the relativistic prediction, thereby making Einstein world famous.
The deﬂection of light by gravitational ﬁelds allows a cosmologically distant galaxy
to behave like a crude lens and, in particular, to produce multiple images of a more
distant quasar. Many examples of this phenomenon have been observed. The optics
of these gravitational lenses provides an excellent illustration of the use of Fermat’s
principle (e.g., Blandford and Narayan, 1992; Schneider, Ehlers, and Falco, 1992). We
explore these issues in this section.
The action of a gravitational lens can only be understood properly using general
relativity. However, when the gravitational ﬁeld is weak, there exists an equivalent
Newtonian model, due to Eddington (1919), that is adequate for our purposes. In
this model, curved spacetime behaves as if it were spatially ﬂat and endowed with a
refractive index given by
refractive index model for
gravitational lensing
n = 1 −2
c2 ,
(7.84)
where  is the Newtonian gravitational potential, normalized to vanish far from the
source of the gravitational ﬁeld and chosen to have a negative sign (so, e.g., the ﬁeld at
a distance r from a point mass M is  = −GM/r). Time is treated in the Newtonian
manner in this model. In Sec. 27.2.3, we use a general relativistic version of Fermat’s
principle to show that for static gravitational ﬁelds this index-of-refraction model
gives the same predictions as general relativity, up to fractional corrections of order
||/c2, which are <∼10−5 for the lensing examples in this chapter.
second refractive index
model
A second Newtonian model gives the same predictions as this index-of-refraction
model to within its errors, ∼||/c2. We deduce it by rewriting the ray equation
(7.48) in terms of Newtonian time t using ds/dt = C = c/n. The resulting equation is
(n3/c2)d2x/dt2 = ∇n −2(n/c)2(dn/dt)dx/dt. The second term changes the length
of the velocity vector dx/dt by a fractional amount of order ||/c2 <∼10−5 (so as to
keep the length of dx/ds unity). This is of no signiﬁcance for our Newtonian model,
so we drop this term. The factor n3 ≃1 −6/c2 produces a fractional correction to
d2x/dt2 thatisofthesamemagnitudeasthefractionalerrorsinourindexofrefraction
396
Chapter 7. Geometric Optics

model, so we replace this factor by one. The resulting equation of motion for the ray is
d2x
dt2 = c2∇n = −2∇.
(7.85)
Equation (7.85) says that the photons that travel along rays feel a Newtonian gravita-
tional potential that is twice as large as the potential felt by low-speed particles; the
photons, moving at speed c (aside from fractional changes of order ||/c2), respond
to that doubled Newtonian ﬁeld in the same way as any Newtonian particle would.
The extra deﬂection is attributable to the geometry of the spatial part of the metric
being non-Euclidean (Sec. 27.2.3).
7.6.2
7.6.2 Optical Conﬁguration
To understand how gravitational lenses work, we adopt some key features from our
discussion of optical catastrophes formed by an intervening screen. However, there
are some essential differences.
.
The source is not assumed to be distant from the screen (which we now call
a lens, L).
.
Instead of tracing rays emanating from a point source S, we consider a
congruence of rays emanating from the observer O (i.e., us) and propagating
backward in time past the lens to the sources. This is because there are many
stars and galaxies whose images will be distorted by the lens. The caustics
envelop the sources.
.
Theuniverseisexpanding, whichmakestheopticsformallytime-dependent.
However, as we discuss in Sec. 28.6.2, we can work in comoving coordinates
and still use Fermat’s principle. For the moment, we introduce three dis-
tances: dOL for distance from the observer to the lens, dOS for the distance
from the observer to the source, and dLS for the distance from the lens to
the source. We evaluate these quantities cosmologically in Sec. 28.6.2.
.
Instead of treating a and b as the state variables that describe rays (Sec. 7.5.1),
we use a 2-dimensional (small) angular vector θ measuring the image po-
sition on the sky. We also replace the control parameters x and y with the
2-dimensional angle β, which measures the location that the image of the
source would have in the absence of the lens. We can also treat the distance
dOS as a third control parameter replacing z.
The Hessian matrix, replacing Eq. (7.80), is now the Jacobian of the vectorial angles
that a small, ﬁnite source would subtend in the absence and in the presence of the lens:
H = M−1 = ∂β
∂θ .
(7.86)
7.6 Gravitational Lenses
397

As the speciﬁc intensity Iν = dE/dAdtdνd is conserved along a ray (see Sec. 3.6),
the determinant of H is just the ratio of the ﬂux of energy per unit frequency without
the lens to the ﬂux with the lens, and correspondingly the determinant of M (the
scalar magniﬁcation) is the ratio of ﬂux with the lens to that without the lens.
7.6.3
7.6.3 Microlensing
Our ﬁrst example of a gravitational lens is a point mass—speciﬁcally, a star. This
phenomenon is known as microlensing, because the angles of deﬂection are typically
microarcseconds.13 The source is also usually another star, which we also treat as a
point.
We ﬁrst compute the deﬂection of a Newtonian particle with speed v passing by
a mass M with impact parameter b. By computing the perpendicular impulse, it is
straightforward to show that the deﬂection angle is 2GM/v2. Replacing v by c and
doubling the answer gives the small deﬂection angle for light:
microlensing deﬂection
angle
α = 4GM
bc2
= 1.75
*
M
M⊙
+ *
b
R⊙
+−1
ˆb arcsec,
(7.87)
where ˆb is a unit vector along the impact parameter, which allows us to treat the
deﬂection as a 2-dimensional vector like θ and β. M⊙and R⊙are the solar mass and
radius, respectively.
microlensing lens equation
The imaging geometry can be expressed as a simple vector equation called the lens
equation (Fig. 7.16):
θ = β + dLS
dOS
α.
(7.88)
A point mass exhibits circular symmetry, so we can treat this equation as a scalar
equation and rewrite it in the form
θ = β + θ2
E
θ ,
(7.89)
where
θE =
4GM
deffc2
1/2
= 903
*
M
M⊙
+1/2  deff
10 kpc
−1/2
μ arcsec
(7.90)
is the Einstein radius, and
deff = dOLdOS
dLS
(7.91)
is the effective distance. (Here 10 kpc means 10 kiloparsecs, about 30,000 light years.)
13. Interestingly, Newton speculated that light rays could be deﬂected by gravity, and the underlying theory
of microlensing was worked out correctly by Einstein in 1912, before he realized that the deﬂection was
twice the Newtonian value.
398
Chapter 7. Geometric Optics

ray
ray
S
O
L
α
β
θ
dLS
dOL
dOS
b
FIGURE 7.16 Geometry for microlensing of a stellar source S by a stellar lens L observed at O.
The solutions to this quadratic equation are
image locations
θ± = β
2 ±
1
θE
2 +
β
2
2
.
(7.92)
The magniﬁcation of the two images can be computed directly by evaluating the
reciprocalofthedeterminantofH fromEq.(7.86).However, itisquickertoexploitthe
circular symmetry and note that the element of source solid angle in polar coordinates
is βdβdφ, while the element of image solid angle is θdθdφ, so that
image magniﬁcations
M = θ
β
dθ
dβ =
1
1 −(θE/θ)4 .
(7.93)
The eigenvalues of the magniﬁcation matrix are [1+ (θE/θ)2]−1 and [1−(θE/θ)2]−1.
The former describes the radial magniﬁcation, the latter the tangential magniﬁcation.
As β →0, θ →θE for both images. If we consider a source of ﬁnite angular size, when
β approaches this size then the tangential stretching is pronounced and two nearly
circular arcs are formed on opposite sides of the lens, one with θ > θE; the other,
inverted, with θ < θE. When β is reduced even more, the arcs join up to form an
Einstein ring (Fig. 7.17).
Einstein ring
Astronomers routinely observe microlensing events when stellar sources pass
behind stellar lenses. They are unable to distinguish the two images and so measure a
combined magniﬁcation M = |M+| + |M−|. If we substitute β for θ, then we have
M =
(θ2
E + 1
2β2)
(θ2
E + 1
4β2)1/2β
.
(7.94)
Note that in the limit of large magniﬁcations, M ∼θE/β, and the probability that
the magniﬁcation exceeds M is proportional to the cross sectional area πβ2 ∝M−2
(cf. Fig. 7.16).
If the speed of the source relative to the continuation of the O-L line is v,
and the closest approach to this line is h, which happens at time t = 0, then β =
(h2 + v2t2)1/2/dOS, and then there is a one-parameter family of magniﬁcation curves
(shown in Fig. 7.18). The characteristic variation of the magniﬁcation can be used to
distinguish this phenomenon from intrinsic stellar variation. This behavior is very
7.6 Gravitational Lenses
399

FIGURE 7.17 The source LRG 3-757, as imaged by the Hubble Space
Telescope. The blue Einstein ring is the image of two background
galaxies formed by the gravitational ﬁeld associated with the
intervening central (yellow) lens galaxy. The accurate alignment
of the lens and source galaxies is quite unusual. (ESA/Hubble and
NASA.)
6
5
4
3
2
1
0
–2
–1
0
vt/θE dOS
0.2
M
0.4
0.6
0.8
1.0
1
2
FIGURE 7.18 Variation of the combined magniﬁcations of a stellar source as it passes
behind a lens star. The time t is measured in units of dOSθE/v, and the parameter
that labels the curves is h/(dOSθE).
different from that at a generic caustic (Sec. 7.5.1) and is not structurally stable: if the
axisymmetry is broken, then the behavior will change signiﬁcantly. Nevertheless, for
ﬁnite-sized sources of light and stars or nearly circular galaxies, stable Einstein rings
are commonly formed.
400
Chapter 7. Geometric Optics

EXERCISES
Exercise 7.17 Example: Microlensing Time Delay
An alternative derivation of the lens equation for a point-mass lens, Eq. (7.88), eval-
uates the time delay along a path from the source to the observer and ﬁnds the true
ray by extremizing it with respect to variations of θ [cf. Eq. (7.68)].
(a) Show that the geometric time delay is given by
tgeo = 1
2cdeff(θ −β)2.
(7.95)
(b) Next show that the lens time delay can be expressed as
tlens = −(4GM/c3) ln b + const,
where b is the impact parameter. (It will be helpful to evaluate the difference in
delays between two rays with differing impact parameters.) This is known as the
Shapiro delay and is discussed further in Sec. 27.2.4.
(c) Show that the lens delay can also be written as
tlens = −2
c3

dz = −2
c32,
(7.96)
where 2 is the surface gravitational potential obtained by integrating the 3-
dimensional potential  along the path. The surface potential is only determined
up to an unimportant, divergent constant, which is acceptable because we are only
interested in dtlens/db which is ﬁnite.
(d) By minimizing tgeo + tlens, derive the lens equation (7.88).
Exercise 7.18 Derivation: Microlensing Variation
Derive Eq. (7.94).
Exercise 7.19 Problem: Magniﬁcation by a Massive Black Hole
Suppose that a large black hole forms two images of a background source separated
by an angle θ. Let the ﬂuxes of the two images be F+ and F−< F+. Show that the
ﬂux from the source would be F+ −F−if there were no lens and that the black hole
should be located an angular distance [1 + (F−/F+)−1/2]−1θ along the line from the
brighter image to the fainter one. (Only consider small angle deﬂections.)
7.6.4
7.6.4 Lensing by Galaxies
Most observed gravitational lenses are galaxies. Observing these systems brings out
new features of the optics and proves useful for learning about galaxies and the
universe. Galaxies comprise dark matter and stars, and the dispersion ⟨v2
||⟩in the
7.6 Gravitational Lenses
401

stars’ velocities along the line of sight can be measured using spectroscopy. The virial
theorem (Goldstein, Poole, and Safko, 2002) tells us that the kinetic energy of the
matter in the galaxy is half the magnitude of its gravitational potential energy . We
can therefore make an order of magnitude estimate of the ray deﬂection angle caused
by a galaxy by using Eq. (7.87):
α ∼4GM
bc2
∼4||
c2
∼4 × 2 × 3
2 ×
⟨v2
||⟩
c2 ∼
12⟨v2
||⟩
c2
.
(7.97)
This evaluates to α ∼2 arcsec for a typical galaxy velocity dispersion of ∼300 km
s−1. The images can typically be resolved using radio and optical telescopes, but their
separations are much less than the full angular sizes of distant galaxies and so the
imaging is sensitive to the lens galaxy’s structure. As the lens is typically far more
complicated than a point mass, it is now convenient to measure the angle θ relative to
the reference ray that connects us to the source.
We can describe the optics of a galaxy gravitational lens by adapting the formal-
ism that we developed for a point-mass lens in Ex. 7.17. We assume that there is a
point source at β and consider paths designated by θ. The geometrical time delay is
unchanged. In Ex. 7.17, we showed that the lens time delay for a point mass was pro-
portional to the surface gravitational potential 2. A distributed lens is handled by
adding the potentials associated with all the point masses out of which it can be con-
sidered as being composed. In other words, we simply use the surface potential for
the distributed mass in the galaxy,
t = tgeo + tlens = deff
2c (θ −β)2 −2
c32 = deff ˜t
c
,
(7.98)
where the scaled time delay t is deﬁned by ˜t(θ; β) = 1
2(θ −β)2 −!(θ), and ! =
22/(c2deff). The quantity ! satisﬁes the 2-dimensional Poisson equation:
scaled time delay for
lensing by galaxies
∇2
2,θ! = 8πG
deffc2 ,
(7.99)
where  is the density of matter per unit solid angle, and the 2-dimensional laplacian
describes differentiation with respect to the components of θ.14
As written, Eq. (7.98) describes all paths for a given source position, only a small
number of which correspond to true rays. However, if, instead, we set β = 0 and
choose any convenient origin for θ so that
14. The minimum surface density (expressed as mass per area) of a cosmologically distant lens needed to
produce multiple images of a background source turns out to be ∼1 g cm−2. It is remarkable that such a
seemingly small surface density operating on these scales can make such a large difference to our view
of the universe. It is tempting to call this a “rule of thumb,” because it is roughly the column density
associated with one’s thumb!
402
Chapter 7. Geometric Optics

˜t(θ) = 1
2θ2 −!(θ),
(7.100)
then three useful features of ˜t emerge:
uses of scaled time delay
.
if there is an image at θ, then the source position is simply β = ∇θ ˜t
[cf. Eq. (7.88)];
.
the magniﬁcation tensor associated with this image can be calculated by
taking the inverse of the Hessian matrix H = ∇θ∇θ ˜t [cf. Eq. (7.86)]; and
.
the measured differences in the times of variation observed in multiple
images of the same source are just the differences in deff ˜t/c evaluated at the
image positions.15
Computing ˜t for a model of a putative lens galaxy allows one to assess whether
background sources are being multiply imaged and, if so, to learn about the lens as
well as the source.
EXERCISES
Exercise 7.20 Problem: Catastrophe Optics of an Elliptical Gravitational Lens
Consider an elliptical gravitational lens where the potential ! is modeled by
!(θ) = (1 + Aθ2
x + 2Bθxθy + Cθ2
y)q;
0 < q < 1/2.
(7.101)
Determine the generic form of the caustic surfaces, the types of catastrophe encoun-
tered, and the change in the number of images formed when a point source crosses
these surfaces. Note that it is in the spirit of catastrophe theory not to compute exact
expressions but to determine scaling laws and to understand the qualitative features
of the images.
Exercise 7.21 Challenge: Microlensing in a Galaxy
Our discussion of microlensing assumed a single star and a circularly symmetric po-
tential about it. This is usually a good approximation for stars in our galaxy. However,
when the star is in another galaxy and the source is a background quasar (Figs. 7.19,
7.20), it is necessary to include the gravitational effects of the galaxy’s other stars and
its dark matter. Recast the microlensing analysis (Sec. 7.6.3) in the potential formula-
tion of Eq. (7.98) and add external magniﬁcation and external shear contributions to
15. These differences can be used to measure the size and age of the universe. To order of magnitude, the
relative delays are the times it takes light to cross the universe (or equivalently, the age of the universe,
roughly 10 Gyr) times the square of the scattering angle (roughly 2 arcsec or ∼10−5 radians), which is
roughly 1 year. This is very convenient for astronomers (see Fig. 7.20).
7.6 Gravitational Lenses
403

virtual ray
virtual ray
S
O
L
α
θ
(dOL/dLS)θ
dLS
dOL
reference ray
FIGURE 7.19 Geometry for gravitational lensing of a quasar source S by a galaxy lens L
observed at O.
lensing
galaxy
galaxy core
A
B
C
D
FIGURE 7.20 Gravitational lens in which a distant quasar, Q2237+0305, is quadruply imaged by
an intervening galaxy. The four quasar images are denoted A, B, C, and D. The galaxy is much
larger than the separation of the images (1–1.5 arcsec) but its bright central core is labeled. There
is also a ﬁfth, faint image coincident with this core. There are many examples of gravitational
lenses like this, where the source region is very compact and variable so that the delay in the
variation seen in the individual images can be used to measure the distance of the source and the
size and age of the universe. In addition, microlensing-like variations in the images are induced
by individual stars in the lens galaxy moving in front of the quasar. Analyzing these changes can
be used to measure the proportion of stars and dark matter in galaxies. Adapted from image by
Hubble Space Telescope. (NASA, ESA, STScI.)
! that are proportional to θ2
x + θ2
y and θ2
x −θ2
y, respectively. The latter will break the
circular symmetry, and structurally stable caustics will be formed. Explore the behav-
ior of these caustics as you vary the strength and sign of the magniﬁcation and shear
contributions. Plot a few ﬂux variations that might be observed.
404
Chapter 7. Geometric Optics

7.7
7.7 Polarization
In our geometric-optics analyses thus far, we have either dealt with a scalar wave (e.g.,
a sound wave) or simply supposed that individual components of vector or tensor
waves can be treated as scalars. For most purposes, this is indeed the case, and we
continue to use this simpliﬁcation in the following chapters. However, there are some
important wave properties that are unique to vector (or tensor) waves. Most of these
come under the heading of polarization effects. In Secs. 27.3, 27.4, and 27.5, we study
polarization effects for (tensorial) gravitational waves. Here and in Secs. 10.5 and
28.6.1, we examine them for electromagnetic waves.
An electromagnetic wave’s two polarizations are powerful tools for technology,
engineering, and experimental physics. However, we forgo any discussion of this in
the present chapter. Instead we focus solely on the geometric-optics propagation law
for polarization (Sec. 7.7.1) and an intriguing aspect of it—the geometric phase (Sec.
7.7.2).
7.7.1
7.7.1 Polarization Vector and Its Geometric-Optics Propagation Law
A plane electromagnetic wave in a vacuum has its electric and magnetic ﬁelds E and
B perpendicular to its propagation direction ˆk and perpendicular to each other. In
a medium, E and B may or may not remain perpendicular to ˆk, depending on the
medium’s properties. For example, an Alfv´en wave has its vibrating magnetic ﬁeld
perpendicular to the background magnetic ﬁeld, which can make an arbitrary angle
with respect to ˆk. By contrast, in the simplest case of an isotropic dielectric medium,
where the dispersion relation has our standard dispersion-free form  = (c/n)k, the
group and phase velocities are parallel to ˆk, and E and B turn out to be perpendicular
to ˆk and to each other—as in a vacuum. In this section, we conﬁne attention to this
simple situation and to linearly polarized waves, for which E oscillates linearly along
polarization vector
a unit polarization vector ˆf that is perpendicular to ˆk:
E = Aeiϕ ˆf,
ˆf . ˆk ≡ˆf . ∇ϕ = 0.
(7.102)
In the eikonal approximation, Aeiϕ ≡ψ satisﬁes the geometric-optics propaga-
tion laws of Sec. 7.3, and the polarization vector ˆf, like the amplitude A, will propagate
along the rays. The propagation law for ˆf can be derived by applying the eikonal ap-
proximation to Maxwell’s equations, but it is easier to infer that law by simple physical
reasoning:
1. Since ˆf is orthogonal to ˆk for a plane wave, it must also be orthogonal to ˆk
in the eikonal approximation (which, after all, treats the wave as planar on
lengthscales long compared to the wavelength).
2. If the ray is straight, then the medium, being isotropic, is unable to distin-
guish a slow right-handed rotation of ˆf from a slow left-handed rotation, so
there will be no rotation at all: ˆf will continue always to point in the same
direction (i.e., ˆf will be kept parallel to itself during transport along the ray).
7.7 Polarization
405

3. If the ray bends, so d ˆk/ds ̸= 0 (where s is distance along the ray), then ˆf
will have to change as well, so as always to remain perpendicular to ˆk. The
direction of ˆf’s change must be ˆk, since the medium, being isotropic, cannot
provide any other preferred direction for the change. The magnitude of the
change is determined by the requirement that ˆf . ˆk remain zero all along the
ray and that ˆk . ˆk = 1. This immediately implies that the propagation law for
ˆf is
propagation law for
polarization vector
dˆf
ds = −ˆk
*
ˆf . d ˆk
ds
+
.
(7.103)
This equation states that the vector ˆf is parallel-transported along the ray
(cf. Fig. 7.5 in Sec. 24.3.3). Here “parallel transport” means: (i) Carry ˆf a short dis-
tance along the ray, keeping it parallel to itself in 3-dimensional space. Because of
the bending of the ray and its tangent vector ˆk, this will cause ˆf to no longer be per-
pendicular to ˆk. (ii) Project ˆf perpendicular to ˆk by adding onto it the appropriate
multiple of ˆk. (The techniques of differential geometry for curved lines and surfaces,
which we develop in Chaps. 24 and 25 in preparation for studying general relativity,
give powerful mathematical tools for analyzing this parallel transport.)
7.7.2
7.7.2 Geometric Phase
We use the polarization propagation law (7.103) to illustrate a quite general phe-
nomenon known as the geometric phase, or sometimes as the Berry phase, after
Michael Berry who elucidated it. For further details and some history of this concept,
see Berry (1990).
As a simple context for the geometric phase, consider a linearly polarized, mono-
chromatic light beam that propagates in an optical ﬁber. Focus on the evolution of the
polarization vector along the ﬁber’s optic axis. We can imagine bending the ﬁber into
any desired shape, thereby controlling the shape of the ray. The ray’s shape in turn will
control the propagation of the polarization via Eq. (7.103).
If the ﬁber and ray are straight, then the propagation law (7.103) keeps ˆf constant.
If the ﬁber and ray are circular, then Eq. (7.103) causes ˆf to rotate in such a way as to
always point along the generator of a cone, as shown in Fig. 7.21a. This polarization
behavior, and that for any other ray shape, can be deduced with the aid of a unit sphere
on which we plot the ray direction ˆk (Fig. 7.21b). For example, the ray directions at
ray locations C and H of panel a are as shown in panel b of the ﬁgure. Notice that the
trajectory of ˆk around the unit sphere is a great circle.
On the unit sphere we also plot the polarization vector ˆf—one vector at each point
corresponding to a ray direction. Because ˆf . ˆk = 0, the polarization vectors are always
tangent to the unit sphere. Notice that each ˆf on the unit sphere is identical in length
and direction to the corresponding one in the physical space of Fig. 7.21a.
The parallel-transport law (7.103) keeps constant the angle α between ˆf and the
trajectory of ˆk (i.e., the great circle in panel b of the ﬁgure). Translated back to
406
Chapter 7. Geometric Optics

(b)
ray
fˆ
fˆ
fˆ
fˆ
fˆ
kˆ
kˆ
(a)
A
A
B
B
C
C
D
D
E
E
F
F
G
G
H
H
α
α
α
α
FIGURE 7.21 (a) The ray along the optic axis of a circular loop of optical ﬁber, and the
polarization vector ˆf that is transported along the ray by the geometric-optics transport
law dˆf/ds = −ˆk(ˆf . d ˆk/ds). (b) The polarization vector ˆf drawn on the unit sphere.
The vector from the center of the sphere to each of the points A, B, . . . , H is the ray’s
propagation direction ˆk, and the polarization vector (which is orthogonal to ˆk and thus
tangent to the sphere) is identical to that in the physical space of the ray (panel a).
panel a, this constancy of α implies that the polarization vector points always along
the generators of the cone, whose opening angle is π/2 −α, as shown.
Next let the ﬁber and its central axis (the ray) be helical as shown in Fig. 7.22a.
In this case, the propagation direction ˆk rotates, always maintaining the same angle
θ to the vertical direction, and correspondingly its trajectory on the unit sphere of
Fig. 7.22b is a circle of constant polar angle θ. Therefore (as one can see, e.g., with
the aid of a large globe of Earth and a pencil transported around a circle of latitude
90◦−θ), the parallel-transport law dictates that the angle α between ˆf and the circle
not remain constant, but instead rotate at the rate
dα/dφ = cos θ.
(7.104)
Here φ is the angle (longitude on the globe) around the circle. This is the same prop-
agation law as for the direction of swing of a Foucault pendulum as Earth turns
(cf. Box 14.5), and for the same reason: the gyroscopic action of the Foucault pen-
dulum is described by parallel transport of its plane along Earth’s spherical surface.
In the case where θ is arbitrarily small (a nearly straight ray), Eq. (7.104) says
dα/dφ = 1. This is easily understood: although ˆf remains arbitrarily close to constant,
the trajectory of ˆk turns rapidly around a tiny circle about the pole of the unit
sphere, so α changes rapidly—by a total amount α = 2π after one trip around the
pole, φ = 2π; whence dα/dφ = α/φ = 1. For any other helical pitch angle θ,
Eq. (7.104) says that during one round trip, α will change by an amount 2π cos θ
that lags behind its change for a tiny circle (nearly straight ray) by the lag angle
αlag = 2π(1 −cos θ), which is also the solid angle  enclosed by the path of ˆk on
the unit sphere:
αlag = .
(7.105)
7.7 Polarization
407

(b)
(a)
A
A
A
B
B
C
D
D
α
α
α
α
αlag
θ
θ
C
fˆ
fˆ
fˆ
fˆ
FIGURE 7.22 (a) The ray along the optic axis of a helical loop of optical ﬁber, and the
polarization vector ˆf that is transported along this ray by the geometric-optics transport
law dˆf/ds = −ˆk(ˆf . d ˆk/ds). The ray’s propagation direction ˆk makes an angle θ = 73◦to
the vertical direction. (b) The trajectory of ˆk on the unit sphere (a circle with polar angle
θ = 73◦), and the polarization vector ˆf that is parallel transported along that trajectory. The
polarization vectors in panel a are deduced from the parallel-transport law demonstrated
in panel b. The lag angle αlag = 2π(1 −cos θ) = 1.42π is equal to the solid angle contained
inside the trajectory of ˆk (the θ = 73◦circle).
(For the circular ray of Fig. 7.21, the enclosed solid angle is  = 2π steradians, so
the lag angle is 2π radians, which means that ˆf returns to its original value after one
trip around the optical ﬁber, in accord with the drawings in the ﬁgure.)
lag angle for polarization
vector in an optical ﬁber
Remarkably, Eq. (7.105) is true for light propagation along an optical ﬁber of any
shape: if the light travels from one point on the ﬁber to another at which the tangent
vector ˆk has returned to its original value, then the lag angle is given by the enclosed
solid angle on the unit sphere, Eq. (7.105).
By itself, the relationship αlag =  is merely a cute phenomenon. However, it
turns out to be just one example of a very general property of both classical and
quantum mechanical systems when they are forced to make slow, adiabatic changes
described by circuits in the space of parameters that characterize them. In the more
general case, one focuses on a phase lag rather than a direction-angle lag. We can
easily translate our example into such a phase lag.
The apparent rotation of ˆf by the lag angle αlag =  can be regarded as an
advance of the phase of one circularly polarized component of the wave by  and
geometric phase change
a phase retardation of the other circular polarization by the same amount. Thus the
phase of a circularly polarized wave will change, after one circuit around the ﬁber’s
helix, by an amount equal to the usual phase advance ϕ =

k . dx (where dx is
displacement along the ﬁber) plus an extra geometric phase change ±, where the
sign is given by the sense of circular polarization. This type of geometric phase change
is found quite generally, when classical vector or tensor waves propagate through
408
Chapter 7. Geometric Optics

backgrounds that change slowly, either temporally or spatially. The phases of the wave
functions of quantum mechanical particles with spin behave similarly.
EXERCISES
Exercise 7.22 Derivation: Parallel Transport
Use the parallel-transport law (7.103) to derive the relation (7.104).
Exercise 7.23 Problem: Martian Rover
A Martian Rover is equipped with a single gyroscope that is free to pivot about the
direction perpendicular to the plane containing its wheels. To climb a steep hill on
Mars without straining its motor, it must circle the summit in a decreasing spiral
trajectory. Explain why there will be an error in its measurement of North after it has
reached the summit. Could it be programmed to navigate correctly? Will a stochastic
error build up as it traverses a rocky terrain?
Bibliographic Note
Modern textbooks on optics deal with the geometric-optics approximation only for
electromagnetic waves propagating through a dispersion-free medium. Accordingly,
they typically begin with Fermat’s principle and then treat in considerable detail
the paraxial approximation, applications to optical instruments, and sometimes the
human eye. There is rarely any mention of the eikonal approximation or of multiple
images and caustics. Examples of texts of this sort that we like are Bennett (2008),
Ghatak(2010), andHecht(2017).Forafarmorethoroughtreatiseongeometricoptics
of scalar and electromagnetic waves in isotropic and anisotropic dielectric media,
see Kravtsov (2005). A good engineering-oriented text with many contemporary
applications is Iizuka (1987).
We do not know of textbooks that treat the eikonal approximation to the degree
of generality used in this chapter, though some should, since it has applications to
all types of waves (many of which are explored later in this book). For the eikonal
approximation specialized to Maxwell’s equations, see Kravtsov (2005) and the classic
treatise on optics by Born and Wolf (1999), which in this new edition has modern
updates by a number of other authors. For the eikonal approximation specialized to
the Schr¨odinger equation and its connection to Hamilton-Jacobi theory, see most any
quantum mechanics textbook (e.g., Grifﬁths, 2004).
Multiple-image formation and caustics are omitted from most standard optics
textbooks, except for a nice but out-of-date treatment in Born and Wolf (1999). Much
better are the beautiful review by Berry and Upstill (1980) and the much more thor-
ough treatments in Kravtsov (2005) and Nye (1999). For an elementary mathematical
treatment of catastrophe theory, we like Saunders (1980). For a pedagogical treatise on
gravitational lenses, see Schneider, Ehlers, and Falco (1992). Finally, for some history
and details of the geometric phase, see Berry (1990).
Bibliographic Note
409


8
CHAPTER EIGHT
Diffraction
I have seen—without any illusion—three broad stripes in the spectrum of Sirius,
which seem to have no similarity to those of sunlight.
JOSEPH VON FRAUNHOFER (1814–1815)
8.1
8.1 Overview
The previous chapter was devoted to the classical mechanics of wave propagation. We
showed how a classical wave equation can be solved in the short-wavelength (eikonal)
approximationtoyieldHamilton’sdynamicalequationsforitsrays.Whenthemedium
is time independent (as we require in this chapter), we showed that the frequency of
a wave packet is constant, and we imported a result from classical mechanics—the
principle of stationary action—to show that the true geometric-optics rays coincide
withpathsalongwhichtheaction(thephase)isstationary[Eqs.(7.44)and(7.45a)and
associated discussion]. Our physical interpretation of this result was that the waves
do indeed travel along every path, from some source to a point of observation, where
they are added together, but they only give a signiﬁcant net contribution when they
can add coherently in phase—along the true rays [Eq. (7.45b)]. Essentially, this is
Huygens’ model of wave propagation, or, in modern language, a path integral.
Huygens’ principle asserts that every point on a wavefront acts as a source of
secondary waves that combine so their envelope constitutes the advancing wavefront.
This principle must be supplemented by two ancillary conditions: that the secondary
waves are only formed in the forward direction, not backward, and that a π/2 phase
shift be introduced into the secondary wave. The reason for the former condition
is obvious, that for the latter, less so. We discuss both together with the formal
justiﬁcation of Huygens’ construction in Sec. 8.2.
We begin our exploration of the “wave mechanics” of optics in this chapter and
continue it in Chaps. 9 and 10. Wave mechanics differs increasingly from geometric
optics as the reduced wavelength -λ increases relative to the lengthscales R of the phase
fronts and L of the medium’s inhomogeneities. The number of paths that can combine
constructively increases, and the rays that connect two points become blurred. In
quantum mechanics, we recognize this phenomenon as the uncertainty principle, and
it is just as applicable to photons as to electrons.
411

BOX 8.1.
READERS’ GUIDE
.
This chapter depends substantially on Secs. 7.1–7.4 (geometric
optics).
.
In addition, Sec. 8.6 of this chapter (on diffraction at a caustic)
depends on Sec. 7.5.
.
Chapters 9 and 10 depend substantially on Secs. 8.1–8.5 of this
chapter.
.
Nothing else in this book relies on this chapter.
Solving the wave equation exactly is very hard, except in simple circumstances.
Geometric optics is one approximate method of solving it—a method that works well
in the short-wavelength limit. In this chapter and the next two, we develop approxi-
mate techniques that work when the wavelength becomes longer and geometric optics
fails.
In this book, we make a somewhat artiﬁcial distinction between phenomena that
arise when an effectively inﬁnite number of propagation paths are involved (which
we call diffraction and describe in this chapter) and those when a few paths, or, more
correctly, a few tight bundles of rays are combined (which we term interference, and
whose discussion we defer to the next chapter).
In Sec. 8.2, we present the Fresnel-Helmholtz-Kirchhoff theory that underlies
most elementary discussions of diffraction. We then distinguish between Fraunhofer
diffraction (the limiting case when spreading of the wavefront mandated by the un-
certainty principle is important) and Fresnel diffraction (where wavefront spreading
is a modest effect, and geometric optics is beginning to work, at least roughly). In
Sec. 8.3, we illustrate Fraunhofer diffraction by computing the angular resolution
of the Hubble Space Telescope, and in Sec. 8.4, we analyze Fresnel diffraction and
illustrate it using zone plates and lunar occultation of radio waves.
Many contemporary optical devices can be regarded as linear systems that take
an input wave signal and transform it into a linearly related output. Their operation,
particularly as image-processing devices, can be considerably enhanced by processing
the signal in the spatial Fourier domain, a procedure known as spatial ﬁltering. In
Sec. 8.5 we introduce a tool for analyzing such devices: paraxial Fourier optics—
a close analog of the paraxial geometric optics of Sec. 7.4. Using paraxial Fourier
optics, we develop the theory of image processing by spatial ﬁlters and use it to discuss
various types of ﬁlters and the phase-contrast microscope. We also use Fourier optics
to develop the theory of Gaussian beams—the kind of light beam produced by lasers
when (as is usual) their optically resonating cavities have spherical mirrors. Finally, in
Sec. 8.6 we analyze diffraction near a caustic of a wave’s phase ﬁeld, a location where
412
Chapter 8. Diffraction

geometric optics predicts a divergent magniﬁcation of the wave (Sec. 7.5). As we shall
see, diffraction keeps the magniﬁcation ﬁnite and produces an oscillating energy-ﬂux
pattern (interference fringes).
8.2
8.2 Helmholtz-Kirchhoff Integral
In this section, we derive a formalism for describing diffraction. We restrict attention
tothesimplest(and, fortunately, themostwidelyuseful)case:amonochromaticscalar
wave,
! = ψ(x)e−iωt,
(8.1a)
with ﬁeld variable ψ that satisﬁes the Helmholtz equation
Helmholtz equation
∇2ψ + k2ψ = 0,
with k = ω/c,
(8.1b)
except at boundaries. Generally, ! will represent a real-valued physical quantity, but
for mathematical convenience we give it a complex representation and take the real
part of ! when making contact with physical measurements. This is in contrast to
a quantum mechanical wave function satisfying the Schr¨odinger equation, which is
an intrinsically complex function. We assume that the wave in Eqs. (8.1) is mono-
chromatic (constant ω) and nondispersive, and that the medium is isotropic and
homogeneous (phase speed equal to group speed, and both with a constant value
C, so k is also constant). Each of these assumptions can be relaxed, but with some
technical penalty.
applications of scalar
diffraction formalism
The scalar formalism that we develop based on Eq. (8.1b) is fully valid for weak
sound waves in a homogeneous ﬂuid or solid (e.g., air; Secs. 12.2 and 16.5). It is also
quite accurate, but not precisely so, for the most widely used application of diffraction
theory: electromagnetic waves in a vacuum or in a medium with a homogeneous
dielectric constant. In this case ψ can be regarded as one of the Cartesian components
of the electric ﬁeld vector, such as Ex (or equally well, a Cartesian component of
the vector potential or the magnetic ﬁeld vector). In a vacuum or in a homogeneous
dielectric medium, Maxwell’s equations imply that this ψ = Ex satisﬁes the scalar
wave equation exactly and hence, for ﬁxed frequency, the Helmholtz equation (8.1b).
However, when the wave hits a boundary of the medium (e.g., the edge of an aperture,
or the surface of a mirror or lens), its interaction with the boundary can couple the
various components of E, thereby invalidating the simple scalar theory we develop in
this chapter. Fortunately, this polarizational coupling is usually weak in the paraxial
(small angle) limit, and also under a variety of other circumstances, thereby making
our simple scalar formalism quite accurate.1
1.
For a formulation of diffraction that takes account of these polarization effects, see, e.g., Born and Wolf
(1999, Chap. 11).
8.2 Helmholtz-Kirchhoff Integral
413

The Helmholtz equation (8.1b) is an elliptic, linear, partial differential equation,
and we can thus express the value ψP of ψ at any point P inside some closed surface
S as an integral over S of some linear combination of ψ and its normal derivative;
see Fig. 8.1. To derive such an expression, we proceed as follows. First, we introduce
in the interior of S a second solution of the Helmholtz equation:
spherical wave
ψ0 = eikr
r .
(8.2)
This is a spherical wave originating from the point P, and r is the distance from P
to the point where ψ0 is evaluated. Next we apply Gauss’s theorem, Eq. (1.28a), to the
vector ﬁeld ψ∇ψ0 −ψ0∇ψ and invoke Eq. (8.1b), thereby obtaining

S∪So
(ψ∇ψ0 −ψ0∇ψ) . d = −

V
(ψ∇2ψ0 −ψ0∇2ψ)dV
= 0.
(8.3)
Here we have introduced a small sphere So of radius ro surrounding P (Fig. 8.1); V
is the volume between the two surfaces So and S (so S ∪So is the boundary ∂V of
V). For future convenience we have made an unconventional choice of direction for
the integration element d: it points into V instead of outward, thereby producing
the minus sign in the second expression in Eq. (8.3). As we let the radius ro decrease
to zero, we ﬁnd that ψ∇ψ0 −ψ0∇ψ →−ψP/r2
o er + O(1/ro), and so the integral
over So becomes −4πψP (where ψP is the value of ψ at P). Rearranging, we obtain
Helmholtz-Kirchhoff
integral
ψP = 1
4π

S

ψ∇eikr
r
−eikr
r ∇ψ

. d.
(8.4)
Equation (8.4), known as the Helmholtz-Kirchhoff integral, is the promised ex-
pression for the ﬁeld ψ at some point P in terms of a linear combination of its value
and normal derivative on a surrounding surface. The speciﬁc combination of ψ and
d . ∇ψ that appears in this formula is perfectly immune to contributions from any
wave that might originate at P and pass outward through S (any outgoing wave). The
integral thus is inﬂuenced only by waves that enter V through S, propagate through
V, and then leave through S. (There cannot be sources inside S, except conceivably
at P, because we assumed ψ satisﬁes the source-free Helmholtz equation throughout
V.) If P is many wavelengths away from the boundary S, then to high accuracy, the
integral is inﬂuenced by the waves ψ only when they are entering through S (when
they are incoming) and not when they are leaving (outgoing). This fact is important
for applications, as we shall see.
8.2.1
8.2.1 Diffraction by an Aperture
Now let us suppose that some aperture Q, with size much larger than a wavelength but
much smaller than the distance to P, is illuminated by a distant wave source (left side
414
Chapter 8. Diffraction

P′
n′
n
ψ′
Q
V
S
So
P
r
d
FIGURE 8.1 Geometry for the Helmholtz-Kirchhoff integral (8.4), which expresses the ﬁeld
ψP at the point P in terms of an integral of the ﬁeld and its normal derivative over the
surrounding surface S. The small sphere So is centered on the observation point P, and V
is the volume bounded by S and So. (The aperture Q, the vectors n and n′ at the aperture,
the incoming wave ψ′, and the point P′ are irrelevant to the formulation of the Helmholtz-
Kirchhoff integral, but appear in applications later in this chapter—initially in Sec. 8.2.1.)
of Fig. 8.1).2 Let the surface S pass through the aperture Q, and denote by ψ′ the wave
incident on Q. We assume that the diffracting aperture has a local and linear effect
on ψ′. More speciﬁcally, we suppose that the wave transmitted through the aperture
is given by
ψQ = t ψ′,
(8.5)
where t is a complex transmission function that varies over the aperture. In practice,
complex transmission
function ttt
t is usually zero (completely opaque region) or unity (completely transparent region).
However, t can also represent a variable phase factor when, for example, the aperture
consists of a medium (lens) of variable thickness and of different refractive index from
that of the homogeneous medium outside the aperture—as is the case in microscopes,
telescopes, eyes, and other optical devices.
limitations of this scalar
diffraction formalism
What this formalism does not allow is that ψQ at any point on the aperture
be inﬂuenced by the wave’s interaction with other parts of the aperture. For this
reason, not only the aperture, but also any structure that it contains must be many
wavelengths across. To give a speciﬁc example of what might go wrong, suppose that
electromagnetic radiation is normally incident on a wire grid. A surface current will
2.
If the aperture were comparable to a wavelength in size, or if part of it were only a few wavelengths
from P, then polarizational coupling effects at the aperture would be large (Born and Wolf, 1999). Our
assumption avoids this complication.
8.2 Helmholtz-Kirchhoff Integral
415

P
Q
R
r
S
FIGURE 8.2 Geometry for deriving Eq.
(8.6) for diffraction by an aperture.
be induced in each wire by the wave’s electric ﬁeld, and that current will produce a
secondary wave that cancels the primary wave immediately behind the wire, thereby
“eclipsing” the wave. If the wire separation is not large compared to a wavelength,
then the secondary wave from the current ﬂowing in one wire will drive currents in
adjacent wires, thereby modifying their secondary waves and disturbing the eclipse in
a complex, polarization-dependent manner. Such modiﬁcations are negligible if the
wires are many wavelengths apart.
Let us now use the Helmholtz-Kirchhoff integral (8.4) to compute the ﬁeld at P
due to the wave ψQ = t ψ′ transmitted through the aperture. Let the (imaginary)
surface S in Fig. 8.1 comprise the aperture Q, a sphere of radius R ≫r centered
on P, and an extension of the aperture to meet the sphere as sketched in Fig. 8.2.
Assume that the only incoming waves are those passing through the aperture. Then,
for the reason discussed in the paragraph following Eq. (8.4), when the incoming
waves subsequently pass on outward through the spherical part of S, they contribute
negligibly to the integral (8.4). Also, with the extension from aperture to sphere
swinging back as drawn (Fig. 8.2), the contribution from the extension will also be
negligible. Therefore, the only contribution is from the aperture itself.3
Because kr ≫1, we can write ∇(eikr/r) ≃−ikneikr/r on the aperture. Here n is a
unit vector pointing toward P (Fig. 8.1). Similarly, we write ∇ψ ≃ikt n′ψ′, where n′
is a unit vector along the direction of propagation of the incident wave (and where our
assumption that anything in the aperture varies on scales long compared to -λ = 1/k
permits us to ignore the gradient of t). Inserting these gradients into the Helmholtz-
Kirchhoff integral, we obtain
3.
Actually, the incoming waves will diffract around the edge of the aperture onto the back side of the
screen that bounds the aperture (i.e., the side facing P), and this diffracted wave will contribute to
the Helmholtz-Kirchhoff integral in a polarization-dependent way (see Born and Wolf, 1999, Chap.
11). However, because the diffracted wave decays along the screen with an e-folding length of order a
wavelength, its contribution will be negligible if the aperture is many wavelengths across and P is many
wavelengths away from the edge of the aperture, as we have assumed.
416
Chapter 8. Diffraction

ψP = −ik
2π

Q
d .
n + n′
2
 eikr
r t ψ′.
(8.6)
wave ﬁeld behind an
aperture
Equation (8.6) can be used to compute the wave from a small aperture Q at any
point P in the far ﬁeld. It has the form of an integral transform of the incident ﬁeld
variable ψ′, where the integral is over the area of the aperture. The kernel of the
transform is the product of several factors. The factor 1/r guarantees that the wave’s
energy ﬂux falls off as the inverse square of the distance to the aperture, as we might
have expected. The phase factor −ieikr advances the phase of the wave by an amount
equal to the optical path length between the element dof the aperture and P, minus
π/2 (the phase of −i). The amplitude and phase of the wave ψ′ can also be changed
by the transmission function t. Finally there is the geometric factor d ˆ . (n + n′)/2
(with d ˆ the unit vector normal to the aperture). This is known as the obliquity
obliquity factor
factor, and it ensures that the waves from the aperture propagate only forward with
respect to the original wave and not backward (i.e., not in the direction n = −n′).
More speciﬁcally, this factor prevents the backward-propagating secondary wavelets
in a Huygens construction from reinforcing one another to produce a back-scattered
wave. When dealing with paraxial Fourier optics (Sec. 8.5), we can usually set the
obliquity factor to unity.
It is instructive to specialize to a point source seen through a small diffracting
aperture. If we suppose that the source has unit strength and is located at P′, a distance
r′ before Q (Fig. 8.1), then ψ′ = −eikr′/(4πr′) (our deﬁnition of unit strength), and
ψP can be written in the symmetric form
propagator through an
aperture
ψP =

Q
 eikr
4πr

it (k + k′) . d
*
eikr′
4πr′
+
.
(8.7)
We can think of this expression as the Green’s function response at P to a delta
function source at P′. Alternatively, we can regard it as a propagator from P′ to P by
way of the aperture (co-opting a concept that was ﬁrst utilized in quantum mechanics
but is also useful in classical optics).
8.2.2
8.2.2 Spreading of the Wavefront: Fresnel and Fraunhofer Regions
Equation (8.6) [or Eq. (8.7)] gives a general prescription for computing the diffraction
pattern from an illuminated aperture. It is commonly used in two complementary
limits, called “Fraunhofer” and “Fresnel.”
Supposethattheaperturehaslinearsizea (asinFig.8.3)andisroughlycenteredon
thegeometricrayfromthesourcepointP′ totheﬁeldpointP, son . d ˆ = n′ . d ˆ ≃1.
Consider the variations of the phase ϕ of the contributions to ψP that come from
various places in the aperture. Using elementary trigonometry, we can estimate that
locations on the aperture’s opposite edges produce phases at P that differ by ϕ =
8.2 Helmholtz-Kirchhoff Integral
417

ρ
ρ
~λ/a
screen
Fresnel region
Fraunhofer region
rF = λρ ¿ a
rF = λρ À a
a
x
FIGURE 8.3 Fraunhofer and Fresnel diffraction. The dashed line is an approximation to the edge of
the aperture’s shadow.
k(ρ2 −ρ1) ∼ka2/2ρ, where ρ1and ρ2 are the distances of P from the two edges of the
aperture, and ρ is the distance from the center of the aperture. There are two limiting
regions for ρ, depending on whether P’s so-called Fresnel length,
Fresnel length
rF ≡
2πρ
k
1/2
= (λρ)1/2
(8.8)
(a surrogate for the distance ρ), is large or small compared to the aperture. Notice
regions of Fraunhofer and
Fresnel diffraction
that (a/rF)2 = ka2/(2πρ) ∼ϕ/π. Therefore, when rF ≫a (ﬁeld point far from
the aperture), the phase variation ϕ across the aperture is ≪π and can be ignored,
so the contributions at P from different parts of the aperture are essentially in phase
with one another. This is the Fraunhofer region. When rF ≪a (near the aperture),
the phase variation is ϕ ≫π and therefore is of utmost importance in determining
the observed energy-ﬂux pattern F ∝|ψP|2. This is the Fresnel region; see Fig. 8.3.
We can use an argument familiar, perhaps, from quantum mechanics to de-
duce the qualitative form of the ﬂux patterns in these two regions. For simplicity,
let the incoming wave be planar [r′ huge in Eq. (8.7)]; let it propagate perpendicular
to the aperture (as shown in Fig. 8.3); and let the aperture be empty, so t = 1 inside
the aperture. Then geometric optics (photons treated like classical particles) would
predict that the aperture’s edge will cast a sharp shadow; the wave leaves the plane of
the aperture as a beam with a sharp edge. However, wave optics insists that the trans-
verse localization of the wave into a region of size x ∼a must produce a spread in
its transverse wave vector, kx ∼1/a (a momentum uncertainty px = ℏkx ∼ℏ/a
in the language of the Heisenberg uncertainty principle). This uncertain transverse
418
Chapter 8. Diffraction

wave vector produces, after propagating a distance ρ, a corresponding uncertainty
(kx/k)ρ ∼r2
F/a in the beam’s transverse size. This uncertainty superposes in-
coherently on the aperture-induced size a of the beam to produce a net transverse
beam size of
x ∼

a2 + (r2
F/a)2
∼
; a
if rF ≪a (i.e., ρ ≪a2/λ; Fresnel region),
2
λ
a
3
ρ
if rF ≫a (i.e., ρ ≫a2/λ; Fraunhofer region).
(8.9)
Therefore, in the nearby, Fresnel region, the aperture creates a beam whose edges
have the same shape and size as the aperture itself, and are reasonably sharp (but
Fresnel and Fraunhofer
diffraction regions and
patterns
with some oscillatory blurring, associated with wavepacket spreading, that we analyze
below); see Fig. 8.4. Thus, in the Fresnel region the ﬁeld behaves approximately as one
would predict using geometric optics. By contrast, in the more distant, Fraunhofer
region, wavefront spreading causes the transverse size of the entire beam to grow
linearly with distance; as illustrated in Fig. 8.4, the ﬂux pattern differs markedly from
the aperture’s shape. We analyze the distant (Fraunhofer) region in Sec. 8.3 and the
near (Fresnel) region in Sec. 8.4.
–a/2
0
x
a/2
–a/2
0
x
a/2
–a/2
0
x
a/2
–a/2
0
x
a/2
rF/a = 0.05
Fresnel region
rF/a = 0.5
rF/a = 1
rF/a = 2
Fraunhofer
region
FIGURE 8.4 The 1-dimensional energy-ﬂux diffraction pattern |ψ|2 produced on a screen a distance
z from a slit with t(x) = 1 for |x| < a/2 and t(x) = 0 for |x| > a/2. Four patterns are shown, each
for a different value of rF/a =
√
λz/a. For rF/a = 0.05 (very near the slit; extreme Fresnel region),
the ﬂux distribution resembles the slit itself: sharp edges at x = ±a/2, but with damped oscillations
(interference fringes) near the edges. For rF/a = 1(beginning of Fraunhofer region) there is a bright
central peak and low-brightness, oscillatory side bands. As rF/a increases from 0.05 to 2, the pattern
transitions (quite rapidly between 0.5 and 2) from the Fresnel to the Fraunhofer pattern. These ﬂux
distributions are derived in Ex. 8.8.
8.2 Helmholtz-Kirchhoff Integral
419

8.3
8.3 Fraunhofer Diffraction
Consider the Fraunhofer region of strong wavefront spreading, rF ≫a, and for sim-
plicity specialize to the case of an incident plane wave with wave vector k orthogonal
to the aperture plane; see Fig. 8.5. Regard the line along k through the center of the
aperture Q as the optic axis and identify points in the aperture by their transverse 2-
dimensional vectorial separation x from that axis. Identify P by its distance ρ from
the aperture center and its 2-dimensional transverse separation ρθ from the optic
axis, and restrict attention to small-angle diffraction |θ| ≪1. Then the geometric
path length between P and a point x on Q [the length denoted r in Eq. (8.6)] can
be expanded as
Path length = r = (ρ2 −2ρx . θ + x2)1/2 ≃ρ −x . θ + x2
2ρ + . . . ;
(8.10)
cf. Fig. 8.5. The ﬁrst term in this expression, ρ, just contributes an x-independent
phaseeikρ totheψP ofEq.(8.6).Thethirdterm, x2/(2ρ), contributesaphasevariation
that is ≪1in the Fraunhofer region (but that will be important in the Fresnel region;
Sec. 8.4). Therefore, in the Fraunhofer region we can retain just the second term,
−x . θ, and write Eq. (8.6) in the form
Fraunhofer diffraction of a
plane wave
ψP(θ) ∝

e−ikx.θt (x) d ≡˜t(θ),
(8.11a)
where d is the surface-area element in the aperture plane, and we have dropped a
constant phase factor and constant multiplicative factors. Thus, ψP(θ) in the Fraun-
hofer region is given by the 2-dimensional Fourier transform, denoted ˜t(θ), of the
transmission function t(x), with x made dimensionless in the transform by multiply-
ing by k = 2π/λ. [Note that with this optics convention for the Fourier transform, the
inverse transform is
optics convention for
Fourier transform
t(x) =
 k
2π
2 
eikx.θ ˜t(θ) d,
(8.11b)
where d = dθxdθy is the solid angle.]
The ﬂux distribution of the diffracted wave [Eq. (8.11a)] is
Fraunhofer diffracted ﬂux
F(θ) =

ℜ[ψP(θ)e−iωt]
2 = 1
2|ψP(θ)|2 ∝|˜t(θ)|2,
(8.12)
where ℜmeans take the real part, and the bar means average over time.
As an example, the bottom curve in Fig. 8.4 (the curve rF = 2a) shows the ﬂux
distribution F(θ) from a slit
t(x) = H1(x) ≡
, 1
|x| < a/2
0
|x| > a/2,
(8.13a)
420
Chapter 8. Diffraction

ρθ
k
x
x′
optic axis
path length r
Q
P
z
ρ
FIGURE 8.5 Geometry for computing the path length between a point Q in the aperture and the
point of observation P. The transverse vector x is used to identify Q in our Fraunhofer analysis
(Sec. 8.3), and x′ is used in the Fresnel analysis (Sec. 8.4).
for which
Fraunhofer diffraction
from a slit with width aaa
ψP(θ) ∝˜H1 ∝
 a/2
−a/2
eikxθdx ∝sinc
 1
2kaθ

,
(8.13b)
F(θ) ∝sinc2  1
2kaθ

.
(8.13c)
Here sinc(ξ) ≡sin(ξ)/ξ. The bottom ﬂux curve in Fig. 8.4 is almost—but not quite—
described by Eq. (8.13c); the differences (e.g., the not-quite-zero value of the mini-
mum between the central peak and the ﬁrst side lobe) are due to the ﬁeld point not
being fully in the Fraunhofer region, rF/a = 2 rather than rF/a ≫1.
It is usually uninteresting to normalize a Fraunhofer diffraction pattern. On those
rare occasions when the absolute value of the observed ﬂux is needed, rather than just
the pattern’s angular shape, it typically can be derived most easily from conservation
of the total wave energy. This is why we have ignored the proportionality factors in
the diffraction patterns.
All techniques for handling Fourier transforms (which should be familiar from
quantum mechanics and elsewhere, though with different normalizations) can be ap-
plied to derive Fraunhofer diffraction patterns. In particular, the convolution theorem
turns out to be very useful. It says that the Fourier transform of the convolution
convolution
f2 ⊗f1 ≡
 +∞
−∞
f2(x −x′)f1(x′)d′
(8.14)
of two functions f1 and f2 is equal to the product ˜f2(θ) ˜f1(θ) of their Fourier trans-
forms, and conversely, the Fourier transform of a product is equal to the convolution.
[Here and throughout this chapter, we use the optics version of a Fourier transform,
in which 2-dimensional transverse position x is made dimensionless via the wave
number k; Eq. (8.11a).]
8.3 Fraunhofer Diffraction
421

As an example of the convolution theorem’s power, we now compute the diffrac-
tion pattern produced by a diffraction grating.
8.3.1
8.3.1 Diffraction Grating
A diffraction grating4 can be modeled as a ﬁnite series of alternating transparent
and opaque, long, parallel strips. Let there be N transparent and opaque strips each
of width a ≫λ (Fig. 8.6a), and idealize them as inﬁnitely long, so their diffraction
pattern is 1-dimensional. We outline how to use the convolution theorem to derive
the grating’s Fraunhofer diffraction pattern. The details are left as an exercise for the
reader (Ex. 8.2).
using convolution to build
transmission function
Our idealized N-slit grating can be regarded as an inﬁnite series of delta functions
with separation 2a, convolved with the transmission function H1 [Eq. (8.13a)] for a
single slit of width a,
 ∞
−∞
' +∞
 
n=−∞
δ(ξ −2an)
(
H1(x −ξ)dξ ,
(8.15a)
and then multiplied by an aperture function with width 2Na:
H2N(x) ≡
, 1
|x| < Na
0
|x| > Na.
(8.15b)
More explicitly, we have
t(x) =
* ∞
−∞
' +∞
 
n=−∞
δ(ξ −2an)
(
H1(x −ξ)dξ
+
H2N(x),
(8.16)
which is shown graphically in Fig. 8.6b.
using the convolution
theorem to compute
Fraunhofer diffraction
Let us use the convolution theorem to evaluate the Fourier transform ˜t(θ) of
expression (8.16), thereby obtaining the diffraction pattern ψP(θ) ∝˜t(θ) for our
transmission grating. The Fourier transform of the inﬁnite series of delta functions
with spacing 2a is itself an inﬁnite series of delta functions with reciprocal spacing
2π/(2ka) = λ/(2a) (see the hint in Ex. 8.2). This must be multiplied by the Fourier
transform ˜H1(θ) ∝sinc( 1
2kaθ) of the single narrow slit and then convolved with the
Fourier transform ˜H2N(θ) ∝sinc(Nkaθ) of the aperture (wide slit). The result is
shown schematically in Fig. 8.6c. (Each of the transforms is real, so the 1-dimensional
functions shown in the ﬁgure fully embody them.)
The resulting diffracted energy ﬂux, F ∝|t(θ)|2 (as computed in Ex. 8.2), is shown
in Fig. 8.6d. The grating has channeled the incident radiation into a few equally spaced
beams with directions θ = πp/(ka) = pλ/(2a), where p is an integer known as the
order of the beam. Each of these beams has a shape given by | ˜H2N(θ)|2: a sharp central
peak with half-width (distance from center of peak to ﬁrst null of the ﬂux) λ/(2Na),
followed by a set of side lobes whose intensities are ∝N−1.
4.
Diffraction gratings were ﬁrst fabricated by David Rittenhouse in 1785 by winding hair around a pair of
screws.
422
Chapter 8. Diffraction

0
(a)
(b)
(c)
(d)
transparent
opaque
t
a
a a a
N
H1(x)
H˜ 1(θ)
H2N(x)
1
a
2a
π/(ka) = λ/(2a)
λ/(2a)
2π/(Nka) = λ/(Na)
4π/(ka) = 2λ/a
λ/(Na)
λ/(Na)
2Na
a
a
a
x
+Na
–Na
=
−
−
...
...
...
...
×
×
FIGURE 8.6 (a) Diffraction grating t(x) formed by N alternating transparent and opaque strips each
of width a. (b) Decomposition of this ﬁnite grating into an inﬁnite series of equally spaced delta
functions that are convolved (the symbol ⊗) with the shape of an individual transparent strip (i.e., a
slit) and then multiplied (the symbol ×) by a large aperture function covering N such slits; Eq. (8.16).
(c) The resulting Fraunhofer diffraction pattern ˜t(θ) is shown schematically as the Fourier transform
of a series of delta functions multiplied by the Fourier transform of a single slit and then convolved
with the Fourier transform of the aperture. (d) The energy ﬂux F ∝|˜t(θ)|2 of this diffraction pattern.
8.3 Fraunhofer Diffraction
423

The deﬂection angles θ = pλ/(2a) of these beams are proportional to λ; this
underpins the use of diffraction gratings for spectroscopy (different wavelengths
deﬂected into beams at different angles). It is of interest to ask what the wavelength
resolution of such an idealized grating might be. If one focuses attention on the pth-
order beams at two wavelengths λ and λ + δλ [which are located at θ = pλ/(2a) and
p(λ + δλ)/(2a)], then one can distinguish the beams from each other when their
separation δθ = pδλ/(2a) is at least as large as the angular distance λ/(2Na) between
the maximum of each beam’s diffraction pattern and its ﬁrst minimum, that is, when
diffraction grating’s
chromatic resolving power
λ
δλ
<∼R ≡Np.
(8.17)
(Recall that N is the total number of slits in the grating, and p is the order of the
diffracted beam.) This R is called the grating’s chromatic resolving power.
Real gratings are not this simple. First, they usually work not by modulating the
amplitude of the incident radiation in this simple manner, but instead by modulating
the phase. Second, the manner in which the phase is modulated is such as to channel
most of the incident power into a particular order, a technique known as blazing.
Third, gratings are often used in reﬂection rather than transmission. Despite these
complications, the principles of a real grating’s operation are essentially the same
as our idealized grating. Manufactured gratings typically have N >∼10,000, giving
a wavelength resolution for visual light that can be as small as λ/105 ∼10 pm (i.e.,
10−11 m).
EXERCISES
Exercise 8.1 Practice: Convolutions and Fourier Transforms
(a) Calculate the 1-dimensional Fourier transforms [Eq. (8.11a) reduced to 1 dimen-
sion] of the functions f1(x) ≡e−x2/2σ 2, and f2 ≡0 for x < 0, f2 ≡e−x/h for
x ≥0.
(b) Take the inverse transforms of your answers to part (a) and recover the original
functions.
(c) Convolve the exponential function f2 with the Gaussian function f1, and then
compute the Fourier transform of their convolution. Verify that the result is the
same as the product of the Fourier transforms of f1 and f2.
Exercise 8.2 Derivation: Diffraction Grating
Use the convolution theorem to carry out the calculation of the Fraunhofer diffraction
pattern from the grating shown in Fig. 8.6. [Hint: To show that the Fourier transform
of the inﬁnite sequence of equally spaced delta functions is a similar sequence of delta
functions, perform the Fourier transform to get !+∞
n=−∞ei2kanθ (aside from a multi-
plicative factor); then use the formulas for a Fourier series expansion, and its inverse,
for any function that is periodic with period π/(ka) to show that !+∞
n=−∞ei2kanθ is
a sequence of delta functions.]
424
Chapter 8. Diffraction

FIGURE8.7 Diffractiongratingformed
from three groups of parallel lines.
Exercise 8.3 Problem: Triangular Diffraction Grating
Sketch the Fraunhofer diffraction pattern you would expect to see from a diffraction
grating made from three groups of parallel lines aligned at angles of 120◦to one
another (Fig. 8.7).
8.3.2
8.3.2 Airy Pattern of a Circular Aperture: Hubble Space Telescope
The Hubble Space Telescope was launched in April 1990 to observe planets, stars,
and galaxies above Earth’s atmosphere. One reason for going into space is to avoid
the irregular refractive-index variations in Earth’s atmosphere, known, generically, as
seeing, which degrade the quality of the images. (Another reason is to observe the
ultraviolet part of the spectrum, which is absorbed in Earth’s atmosphere.) Seeing
typically limits the angular resolution of Earth-bound telescopes to ∼0.5′′ at visual
wavelengths (see Box 9.2). We wish to compute how much the angular resolution
improvesbygoingintospace.Asweshallsee, thecomputationisessentiallyanexercise
in Fraunhofer diffraction theory.
The essence of the computation is to idealize the telescope as a circular aperture
with diameter equal to that of the primary mirror. Light from this mirror is actually
reﬂected onto a secondary mirror and then follows a complex optical path before
being focused on a variety of detectors. However, this path is irrelevant to the angular
resolution. The purposes of the optics are merely (i) to bring the Fraunhofer-region
light to a focus close to the mirror [Eq. (8.31) and subsequent discussion], in order to
produce an instrument that is compact enough to be launched, and (ii) to match the
sizes of stars’ images to the pixel size on the detector. In doing so, however, the optics
leaves the angular resolution unchanged; the resolution is the same as if we were to
observe the light, which passes through the primary mirror’s circular aperture, far
beyond the mirror, in the Fraunhofer region.
If the telescope aperture were very small, for example, a pin hole, then the light
from a point source (a very distant star) would create a broad diffraction pattern,
and the telescope’s angular resolution would be correspondingly poor. As we increase
the diameter of the aperture, we still see a diffraction pattern, but its angular width
diminishes.
8.3 Fraunhofer Diffraction
425

0
1.22
Dθ/λ
FIGURE 8.8 Airy diffraction pattern produced by
a circular aperture.
Usingtheseconsiderations, wecancomputehowwellthetelescopecandistinguish
neighboring stars. We do not expect it to resolve them fully if they are closer together
on the sky than the angular width of the diffraction patttern. Of course, optical
imperfections and pointing errors in a real telescope may degrade the image quality
even further, but this is the best that can be done, limited only by the uncertainty
principle.
The calculation of the Fraunhofer amplitude far from the aperture, via the Fourier
transform (8.11a), is straightforward (Ex. 8.4):
Airy diffraction pattern
from circular aperture
ψ(θ) ∝

Disk with diameter D
e−ikx.θd
∝jinc
kDθ
2

,
(8.18)
where D is the diameter of the aperture (i.e., of the telescope’s primary mirror), θ ≡|θ|
is the angle from the optic axis, and jinc(x) ≡J1(x)/x, with J1 the Bessel function of
the ﬁrst kind and of order one. The ﬂux from the star observed at angle θ is therefore
∝jinc2(kDθ/2). This energy-ﬂux pattern, known as the Airy pattern, is shown in
Fig. 8.8. The image appears as a central “Airy disk” surrounded by a circle where the
ﬂux vanishes, and then further surrounded by a series of concentric rings whose ﬂux
diminishes with radius. Only 16% of the total light falls outside the central Airy disk.
The angular radius θA of the Airy disk (i.e., the radius of the dark circle surrounding
it) is determined by the ﬁrst zero of J1(kDθ/2) = J1(θ πD/λ):
θA = 1.22λ/D.
(8.19)
A conventional, though essentially arbitrary, criterion for angular resolution is
to say that two point sources can be distinguished if they are separated in angle by
more than θA. For the Hubble Space Telescope, D = 2.4 m and θA ∼0.05′′ at visual
wavelengths, which is more than 10 times better than is achievable on the ground with
conventional (nonadaptive) optics.
Initially, there was a serious problem with Hubble’s telescope optics. The hyper-
boloidal primary mirror was ground to the wrong shape, so rays parallel to the optic
426
Chapter 8. Diffraction

axis did not pass through a common focus after reﬂection off a convex hyperboloidal
spherical aberration in the
Hubble Space Telescope
secondary mirror. This defect, known as spherical aberration (Sec. 7.5.2), created
blurred images. However, it was possible to correct this error in subsequent instru-
mentsintheopticaltrain, andtheHubbleSpaceTelescopebecamethemostsuccessful
optical telescope of all time, transforming our view of the universe.
TheHubbleSpaceTelescopeshouldbesucceededin2018bytheJamesWebbSpace
Telescope. Webb will have a diameter D ≃6.5 m (2.7 times larger than Hubble) but its
wavelengths of observation are somewhat longer (0.6 μm to 28.5 μm), so its angular
resolution will be, on average, roughly the same as Hubble’s.
EXERCISES
Exercise 8.4 Derivation: Airy Pattern
Derive and plot the Airy diffraction pattern [Eq. (8.18)] and show that 84% of the
light is contained within the Airy disk.
Exercise 8.5 Problem: Pointillist Painting
The neoimpressionist painter Georges Seurat was a member of the pointillist school.
Hispaintingsconsistedofanenormousnumberofcloselyspaceddotsofpurepigment
(of size ranging from ∼0.4 mm in his smaller paintings to ∼4 mm in his largest
paintings, such as Gray Weather, Grande Jatte, Fig. 8.9). The illusion of color mixing
was produced only in the eye of the observer. How far from the painting should one
stand to obtain the desired blending of color?
(a)
(b)
FIGURE 8.9 (a) Georges Seurat’s painting Gray Weather, Grande Jatte. When viewed from a sufﬁcient
distance, adjacent dots of paint with different colors blend together in the eye to form another
color. (b) Enlargement of the boat near the center of the painting. In this enlargement, one sees
clearly the individual dots of paint. Gray Weather, Grande Jatte by Georges Seurat (ca. 1886–88);
The Metropolitan Museum of Art (www.metmuseum.org); The Walter H. and Leonore Annenberg
Collection, Gift of Walter H. and Leonore Annenberg, 2002, Bequest of Walter H. Annenberg, 2002.
8.3 Fraunhofer Diffraction
427

~λ/a
~λ/D
screen
object, size a
D
FIGURE 8.10 Geometry for Babinet’s principle. The beam produced by the large aperture D is conﬁned
between the long-dashed lines. Outside this beam, the energy-ﬂux pattern F(θ) ∝|t(θ)|2 produced
by a small object (size a) and its complement are the same, Eqs. (8.20). This diffracted ﬂux pattern
is conﬁned between the dotted lines.
8.3.3
8.3.3 Babinet’s Principle
Suppose that monochromatic light falls normally onto a large circular aperture with
diameter D. At distances z <∼D2/λ (i.e., rF <∼D), the transmitted light will be col-
limated into a beam with diameter D, and at larger distances, the beam will become
conical with opening angle λ/D (Fig. 8.3) and ﬂux distribution given by the Airy
diffraction pattern of Fig. 8.8.
Now place into this aperture a signiﬁcantly smaller object (size a ≪D; Fig. 8.10)
with transmissivity t1(x)—for example, an opaque star-shaped object. This object will
produceaFraunhoferdiffractionpatternwithopeningangleλ/a ≫λ/D thatextends
well beyond the large aperture’s beam. Outside that beam, the diffraction pattern will
be insensitive to the shape and size of the large aperture, because only the small object
can diffract light to these large angles; so the diffracted ﬂux will be F1(θ) ∝|˜t1(θ)|2.
Next, suppose that we replace the small object by one with a complementary
transmissivity t2, complementary in the sense that
t1(x) + t2(x) = 1.
(8.20a)
For example, we replace a small, opaque star-shaped object by an opaque screen that
Babinet’s principle
ﬁlls the original, large aperture except for a star-shaped hole. This complementary
object will produce a diffraction pattern F2(θ) ∝|˜t2(θ)|2. Outside the large aperture’s
beam, thispatternagainisinsensitivetothesizeandshapeofthelargeaperture, thatis,
itisinsensitivetothe1int2 = 1−t1(whichsendslightsolelyinsidethelargeaperture’s
428
Chapter 8. Diffraction

beam); so at these large angles, ˜t2(θ) = −˜t1(θ), which implies that the energy-ﬂux
diffraction pattern of the original object and the new, complementary object will be
the same outside the large aperture’s beam:
F2(θ) ∝|˜t2(θ)|2 = |˜t1(θ)|2 ∝F1(θ).
(8.20b)
This is called Babinet’s principle.
EXERCISES
Exercise 8.6 Problem: Light Scattering by a Large, Opaque Particle
Consider the scattering of light by an opaque particle with size a ≫1/k. Neglect any
scattering via excitation of electrons in the particle. Then the scattering is solely due
to diffraction of light around the particle. With the aid of Babinet’s principle, do the
following.
(a) Explain why the scattered light is conﬁned to a cone with opening angle θ ∼
π/(ka) ≪1.
(b) Show that the total power in the scattered light, at very large distances from the
particle, is PS = FA, where F is the incident energy ﬂux, and A is the cross
sectional area of the particle perpendicular to the incident wave.
(c) Explain why the total “extinction” (absorption plus scattering) cross section is
equal to 2A independent of the shape of the opaque particle.
Exercise 8.7 Problem: Thickness of a Human Hair
Conceive and carry out an experiment using light diffraction to measure the thickness
of a hair from your head, accurate to within a factor of ∼2. [Hint: Make sure the source
of light that you use is small enough—e.g., a very narrow laser beam—that its ﬁnite
size has negligible inﬂuence on your result.]
8.4
8.4 Fresnel Diffraction
We next turn to the Fresnel region of observation points P with rF = √λρ much
smaller than the aperture. In this region, the ﬁeld at P arriving from different parts of
theaperturehassigniﬁcantlydifferentphase ϕ ≫1.Weagainspecializetoincoming
wave vectors that are approximately orthogonal to the aperture plane and to small
diffraction angles, so we can ignore the obliquity factor d ˆ . (n + n′)/2 in Eq. (8.6).
By contrast with the Fraunhofer case, we now identify P by its distance z from the
aperture plane instead of its distance ρ from the aperture center, and we use as
our integration variable in the aperture x′ ≡x −ρθ (Fig. 8.5), thereby writing the
dependence of the phase at P on x in the form
ϕ ≡k × [(path length from x to P) −z]= kx′2
2z + O
*
kx′4
z3
+
.
(8.21)
8.4 Fresnel Diffraction
429

In the Fraunhofer region (Sec. 8.3) only the linear term −kx . θ in kx′2/(2z) ≃k(x −
rθ)2/r was signiﬁcant. In the Fresnel region the term quadratic in x is also signiﬁcant
(and we have changed variables to x′ so as to simplify it), but the O(x′4) term is
negligible. Therefore, in the Fresnel region the diffraction pattern (8.6) is
ψP = −ikeikz
2πz

eiϕtψ′d′ = −ikeikz
2πz

eikx′2/(2z)t(x′)ψ′(x′)d′,
(8.22)
where in the denominator we have replaced r by z to excellent approximation.
Let us consider the Fresnel diffraction pattern formed by an empty (t = 1) simple
aperture of arbitrary shape, illuminated by a normally incident plane wave. It is
convenient to introduce transverse Cartesian coordinates x′ = (x′, y′) and deﬁne
σ =
 k
πz
1/2
x′,
τ =
 k
πz
1/2
y′.
(8.23a)
[Notice that (k/[πz])1/2 is
√
2/rF; cf. Eq. (8.8).] We can thereby rewrite Eq. (8.22) in
the form
Fresnel diffraction pattern
from arbitrary empty
aperture Q
Q
Q
ψP = −i
2
 
Q
eiπσ 2/2eiπτ2/2ψQeikzdσdτ.
(8.23b)
Here we have changed notation for the ﬁeld ψ′ impinging on the aperture Q to ψQ.
Equations (8.23) depend on the transverse location of the observation point P
through the origin used to deﬁne x′ = (x′, y′); see Fig. 8.5. We use these rather
general expressions in Sec. 8.5, when discussing paraxial Fourier optics, as well as
in Secs. 8.4.1–8.4.4 on Fresnel diffraction.
8.4.1
8.4.1 Rectangular Aperture, Fresnel Integrals, and the Cornu Spiral
Inthisandthefollowingthreesections, weexplorethedetailsoftheFresneldiffraction
pattern for an incoming plane wave that falls perpendicularly on the aperture, so ψQ
is constant over the aperture.
Fresnel diffraction by
rectangular aperture
For simplicity, we initially conﬁne attention to a rectangular aperture with edges
along the x′ and y′ directions. Then the two integrals have limits that are independent
of each other, and the integrals can be expressed in the form E(σmax) −E(σmin) and
E(τmax) −E(τmin), so
ψP = −i
2 [E(σmax) −E(σmin)][E(τmax) −E(τmin)]ψQeikz ≡−i
2 EσEτψQeikz,
(8.24a)
where the arguments are the limits of integration (the two edges of the aperture), and
where
E(ξ) ≡
 ξ
0
eiπσ 2/2dσ ≡C(ξ) + iS(ξ).
(8.24b)
430
Chapter 8. Diffraction

S
0.6
0.4
0.2
0.25
ξ = σmin
ξ
ξ
ξ = σmax
–0.25
–0.50
0.75
1.0
1.5
2.5
0.5
–0.5
–1.0
–1.5
–2.5
–2.0
2.0
–0.75
0.50
–0.2
–0.4
–0.6
C
FIGURE 8.11 Cornu spiral in the complex plane; the real part of E(ξ) = C(ξ) + iS(ξ) is
plotted horizontally, and the imaginary part vertically; the point ξ = 0 is at the origin,
positive ξ is in the upper right quadrant, and negative ξ is in the lower left quadrant.
The diffracted energy ﬂux is proportional to the squared length of the arrow reaching
from ξ = σmin to ξ = σmax.
Here
Fresnel integrals
C(ξ) ≡
 ξ
0
dσ cos(πσ 2/2),
S(ξ) ≡
 ξ
0
dσ sin(πσ 2/2)
(8.24c)
are known as Fresnel integrals and are standard functions tabulated in many books
and can be found in Mathematica, Matlab, and Maple. Notice that the energy-ﬂux
distribution is
F ∝|ψP|2 ∝|Eσ|2|Eτ|2.
(8.24d)
Cornu spiral
It is convenient to exhibit the Fresnel integrals graphically using a Cornu spiral
(Fig. 8.11). This is a graph of the parametric equation [C(ξ), S(ξ)], or equivalently,
a graph of E(ξ) = C(ξ) + iS(ξ) in the complex plane. The two terms Eσ and Eτ
in Eq. (8.24a) can be represented in amplitude and phase by arrows in the C-S plane
reaching from ξ = σmin on the Cornu spiral to ξ = σmax (Fig. 8.11), and from ξ = τmin
to ξ = τmax. Correspondingly, the ﬂux F [Eq. (8.24d)] is proportional to the product
of the squared lengths of these two vectors.
As the observation point P moves around in the observation plane (Fig. 8.5),
x′
min and x′
max change, and hence σmin = [k/(πz)]1/2x′
min and σmax = [k/(πz)]1/2x′
max
change [i.e., the tail and tip of the arrow in Fig. 8.11 move along the Cornu spiral,
thereby changing the diffracted ﬂux, which is ∝(length of arrow)2].
8.4 Fresnel Diffraction
431

8.4.2
8.4.2 Unobscured Plane Wave
The simplest illustration of Fresnel integrals is the totally unobscured plane wave.
In this case, the limits of both integrations extend from −∞to +∞, which, as we
see in Fig. 8.11, is an arrow of length 21/2 and phase π/4. Therefore, ψP is equal to
(21/2eiπ/4)2(−i/2)ψQeikz = ψQeikz, as we could have deduced simply by solving the
Helmholtz equation (8.1b) for a plane wave.
This unobscured-wavefront calculation elucidates three issues that we have al-
ready met. First, it illustrates our interpretation of Fermat’s principle in geometric
optics. In the limit of short wavelengths, the paths that contribute to the wave ﬁeld are
just those along which the phase is stationary to small variations. Our present calcu-
for Fresnel diffraction
dominant paths are near
geometric optics path
lation shows that, because of the tightening of the Cornu spiral as one moves toward
a large argument, the paths that contribute signiﬁcantly to ψP are those that are sep-
arated from the geometric-optics path by less than a few Fresnel lengths at Q. (For a
laboratory experiment with light and z ∼2 m, the Fresnel length is
√
λz ∼1 mm.)
A second, and related, point is that, when computing the Fresnel diffraction
pattern from a more complicated aperture, we need only perform the integral (8.6)
in the immediate vicinity of the geometric-optics ray. We can ignore the contribution
from the extension of the aperture Q to meet the “sphere at inﬁnity” (the surface S in
Fig. 8.2), even when the wave is unobstructed there. The rapid phase variation makes
the contribution from that extension and from S sum to zero.
Third, when integrating over the whole area of the wavefront at Q, we have
summed contributions with increasingly large phase differences that add in such
a way that the total has a net extra phase of π/2 relative to the geometric-optics
ray. This phase factor cancels exactly the prefactor −i in the Helmholtz-Kirchhoff
formula (8.6). (This phase factor is unimportant in the limit of geometric optics.)
8.4.3
8.4.3 Fresnel Diffraction by a Straight Edge: Lunar Occultation of a Radio Source
The next-simplest case of Fresnel diffraction is the pattern formed by a straight edge.
As a speciﬁc example, consider a cosmologically distant source of radio waves that
is occulted by the Moon. If we treat the lunar limb as a straight edge, then the radio
source will create a changing diffraction pattern as it passes behind the Moon, and
the diffraction pattern can be measured by a radio telescope on Earth. We orient
our coordinates so the Moon’s edge is along the y′ direction (τ direction). Then
in Eq. (8.24a) Eτ ≡E(τmax) −E(τmin) =
√
2i is constant, and Eσ ≡E(σmax) −
E(σmin) is described by the Cornu spiral of Fig. 8.12b.
Long before the occultation, we can approximate σmin = −∞and σmax = +∞
(Fig.8.12a), soEσ isgivenbythearrowfrom(−1/2, −1/2)to(1/2, 1/2)inFig.8.12b
(i.e., Eσ =
√
2i). The observed wave amplitude, Eq. (8.24a), is therefore ψQeikz.
When the Moon approaches occultation of the radio source, the upper bound on
the Fresnel integral begins to diminish from σmax = +∞, and the complex vector
on the Cornu spiral begins to oscillate in length (e.g., from A to B in Fig. 8.12b,c)
and in phase. The observed ﬂux also oscillates, more and more strongly as geometric
432
Chapter 8. Diffraction

P
xmax
x0
max = (rF/ 2)σmax 
(a)
(b)
(c)
x0
min = σmin = –1
σmin = –1
|ψ|2
A
A
B
B
C
C
σmax = 1.27
1/4
1
0
σmax = 1.83
σmax = 0
FIGURE 8.12 Diffraction from a straight edge. (a) The straight edge, onto which a plane wave impinges
orthogonally, the observation point P, and the vectors that reach to the lower and upper limits of
integration, x′
min = −∞and x′
max for computation of the diffraction integral (8.23b). (b) The Cornu
spiral, showing the arrows that represent the contribution Eσ to the diffracted ﬁeld ψP. (c) The
energy-ﬂux diffraction pattern formed by the straight edge. The ﬂux |ψ|2 ∝|Eσ|2 is proportional
to the squared length of the arrow on the Cornu spiral in panel b.
occultation is approached. At the point of geometric occultation (point C in Fig.
8.12b,c), the complex vector extends from (−1/2, −1/2) to (0, 0), and so the observed
waveamplitudeisone-halftheunoccultedvalue, andtheﬂuxisreducedtoone-fourth.
As the occultation proceeds, the length of the complex vector and the observed ﬂux
decrease monotonically to zero, while the phase continues to oscillate.
Historically, diffraction of a radio source’s waves by the Moon led to the discovery
discovery of quasars
of quasars—the hyperactive nuclei of distant galaxies. In the early 1960s, a team
of Australian and British radio observers led by Cyril Hazard knew that the Moon
would occult the powerful radio source 3C273, so they set up their telescope to
observe the development of the diffraction pattern as the occultation proceeded.
From the pattern’s observed times of ingress (passage into the Moon’s shadow) and
egress (emergence from the Moon’s shadow), Hazard determined the coordinates of
3C273 on the sky and did so with remarkable accuracy, thanks to the oscillatory
features in the diffraction pattern. These coordinates enabled Maarten Schmidt at the
200-inch telescope on Palomar Mountain to identify 3C273 optically and discover
(from its optical redshift) that it was surprisingly distant and consequently had an
unprecedentedluminosity.Itwastheﬁrstexampleofaquasar—apreviouslyunknown
astrophysical object.
In Hazard’s occultation measurements, the observing wavelength was λ ∼0.2 m.
Since the Moon is roughly z ∼400,000 km distant, the Fresnel length was about
rF =
√
λz ∼10 km. The Moon’s orbital speed is v ∼200 m s−1, so the diffraction
pattern took a time ∼5rF/v ∼4 min to pass through the telescope.
The straight-edge diffraction pattern of Fig. 8.12c occurs universally along the
edge of the shadow of any object, so long as the source of light is sufﬁciently small
8.4 Fresnel Diffraction
433

FIGURE 8.13 Fresnel diffraction pattern in the shadow
of Mary’s Hand Holding a Dime—a photograph by
Eugene Hecht, from the ﬁrst ﬁgure in Hecht (2017,
Chap. 10).
and the shadow’s edge bends on lengthscales long compared to the Fresnel length
rF =
√
λz. Examples are the diffraction patterns on the two edges of a slit’s shadow in
the upper-left curve in Fig. 8.4 (cf. Ex. 8.8) and the diffraction pattern along the edge
of a shadow cast by a person’s hand in Fig. 8.13.
EXERCISES
Exercise 8.8 Example: Diffraction Pattern from a Slit
Derive a formula for the energy-ﬂux diffraction pattern F(x) of a slit with width a,
as a function of distance x from the center of the slit, in terms of Fresnel integrals.
Plot your formula for various distances z from the slit’s plane (i.e., for various values
of rF/a =

λz/a2), and compare with Fig. 8.4.
8.4.4
8.4.4 Circular Apertures: Fresnel Zones and Zone Plates
We have seen how the Fresnel diffraction pattern for a plane wave can be thought of
as formed by waves that derive from a patch in the diffracting object’s plane a few
Fresnel lengths in size. This notion can be made quantitatively useful by reanalyzing
an unobstructed wavefront in circular polar coordinates. More speciﬁcally, consider
a plane wave incident on an aperture Q that is inﬁnitely large (no obstruction),
and deﬁne ϖ ≡|x′|/rF =

1
2(σ 2 + τ 2). Then the phase factor in Eq. (8.23b) is
ϕ = πϖ 2, so the observed wave coming from the region inside a circle of radius
|x′| = rFϖ will be given by
ψP = −i
 ϖ
0
2πϖ ′dϖ ′eiπϖ ′2ψQeikz
= (1 −eiπϖ 2)ψQeikz.
(8.25)
Now, this integral does not appear to converge as ϖ →∞. We can see what is
happening if we sketch an amplitude-and-phase diagram (Fig. 8.14).
434
Chapter 8. Diffraction

Fresnel zones
=ψ
<ψ
ϖ2 = 1, 3, 5, . . .
ϖ2 = 0, 2, 4, . . .
ϖ
FIGURE 8.14 Amplitude-and-phase diagram for an unobstructed plane wavefront,
decomposed into Fresnel zones; Eq. (8.25).
As we integrate outward from ϖ = 0, the complex vector has the initial phase
retardation of π/2 but then moves on a semi-circle, so that by the time we have
integrated out to a radius of |x′| = rF (ϖ = 1), the contribution to the observed
wave is ψP = 2ψQ in phase with the incident wave. When the integration has been
extended to
√
2 rF, (ϖ =
√
2), the circle has been completed, and ψP = 0! The
integral continues on around the same circle over and over again, as the upper-bound
radius is further increased; see Fig. 8.14.
Of course, the ﬁeld must actually have a well-deﬁned value asϖ →∞, despite this
apparent failure of the integral to converge. To understand how the ﬁeld becomes well
deﬁned, imagine splitting the aperture Q up into concentric annular rings, known as
Fresnel half-period zones, with outer radii √n rF, where n = 1, 2, 3 . . . . The integral
half-period zones
fails to converge because the contribution from each odd-numbered ring cancels that
fromanadjacenteven-numberedring.However, thethicknessoftheseringsdecreases
as 1/√n, and eventually we must allow for the fact that the incoming wave is not
exactly planar; or, equivalently and more usefully, we must allow for the fact that
the wave’s distant source has some ﬁnite angular size. The ﬁnite size causes different
pieces of the source to have their Fresnel rings centered at slightly different points
in the aperture plane, which causes our computation of ψP to begin averaging over
rings. This averaging forces the tip of the complex vector (ℜψ, ℑψ), where ℜand ℑ
correspond to the real and imaginary parts, to asymptote to the center of the circle in
Fig. 8.14. Correspondingly, due to the averaging, the observed energy ﬂux asymptotes
to |ψQ|2 [Eq. (8.25) with the exponential eiπϖ 2 going to zero].
Although this may not seem to be a particularly wise way to decompose a plane
zone plate
wavefront, it does allow a striking experimental veriﬁcation of our theory of diffrac-
tion. Suppose that we fabricate an aperture (called a zone plate) in which, for a
chosen wavelength and observation point P on the optic axis, alternate half-period
8.4 Fresnel Diffraction
435

zones are obscured. Then the wave observed at P will be the linear sum of several
diameters of the circle in Fig. 8.14 and therefore will be far larger than ψQ. This
strong ampliﬁcation is conﬁned to our chosen spot on the optic axis; most every-
where else the ﬁeld’s energy ﬂux is reduced, thereby conserving energy. Thus the
zone plate behaves like a lens. Because the common area of the half-period zones
is A = nπr2
F −(n −1)πr2
F = πr2
F = πλz, if we construct a zone plate with ﬁxed
area A for the zones, its focal length will be f = z = A/(πλ). For A = (a few square
millimeters)—the typical choice—and λ ∼500 nm (optical wavelengths), we have
f ∼a few meters.
Zone plates are only good lenses when the radiation is monochromatic, since the
focal length is wavelength dependent, f ∝λ−1. They have the further interesting
property that they possess secondary foci, where the ﬁelds from 3 contiguous zones,
secondary foci
or 5 or 7 or so forth, add up coherently (Ex. 8.9).
EXERCISES
Exercise 8.9 Problem: Zone Plate
(a) Use an amplitude-and-phase diagram to explain why a zone plate has secondary
foci at distances of f/3, f/5, f/7 . . . .
(b) An opaque, perfectly circular disk of diameter D is placed perpendicular to an
incoming plane wave. Show that, at distances r such that rF ≪D, the disk casts
a rather sharp shadow, but at the precise center of the shadow there must be a
bright spot.5 How bright?
Exercise 8.10 Problem: Spy Satellites
Telescopes can also look down through the same atmospheric irregularities as those
mentioned in Sec. 8.3.2 (see also Box 9.2). In what important respects will the optics
differ from those for ground-based telescopes looking upward?
8.5
8.5 Paraxial Fourier Optics
We have developed a linear theory of wave optics that has allowed us to calculate
diffraction patterns in the Fraunhofer and Fresnel limiting regions. That these calcu-
lations agree with laboratory measurements provides some vindication of the theory
and the assumptions implicit in it. We now turn to practical applications of these
ideas, speciﬁcally, to the acquisition and processing of images by instruments operat-
ing throughout the electromagnetic spectrum. As we shall see, these instruments rely
5.
Sim´eon Poisson predicted the existence of this spot as a consequence of Fresnel’s wave theory of light,
in order to demonstrate that Fresnel’s theory was wrong. However, Fran¸cois Arago (who was brieﬂy, in
1848, premier of France) quickly demonstrated experimentally that the bright spot existed. It is now
called the Poisson spot (despite Poisson’s skepticism) or the Arago spot.
436
Chapter 8. Diffraction

on an extension of paraxial geometric optics (Sec. 7.4) to situations where diffrac-
tion effects are important. Because of the central role played by Fourier transforms
in diffraction [e.g., Eq. (8.11a)], the theory underlying these instruments is called
paraxial Fourier optics, or just Fourier optics.
Although the conceptual framework and mathematical machinery for image pro-
cessing by Fourier optics were developed in the nineteenth century, Fourier optics
was not widely exploited until the second half of the twentieth century. Its matura-
tion was driven in part by a growing recognition of similarities between optics and
communication theory—for example, the realization that a microscope is simply an
image-processing system. The development of electronic computation has also trig-
image processing with
mirrors, lenses, etc. plus
computing
gered enormous strides; computers are now seen as extensions of optical devices, and
vice versa. It is a matter of convenience, accuracy, economics, and practicality to de-
cide which parts of the image processing are carried out with mirrors, lenses, and the
like, and which parts are performed numerically.
One conceptually simple example of optical image processing is an improvement
in one’s ability to identify a faint star in the Fraunhofer diffraction rings (“fringes”)
of a much brighter star. As we shall see [Eq. (8.31) and subsequent discussion], the
bright image of a source in a telescope’s or microscope’s focal plane has the same
Airy diffraction pattern as we met in Eq. (8.18) and Fig. 8.8. If the shape of that
image could be changed from the ring-endowed Airy pattern to a Gaussian, then
it would be far easier to identify a nearby feature or faint star. One way to achieve this
would be to attenuate the incident radiation at the telescope aperture in such a way
Gaussian aperture
that, immediately after passing through the aperture, it has a Gaussian proﬁle instead
of a sharp-edged proﬁle. Its Fourier transform (the diffraction pattern in the focal
plane) would then also be Gaussian. Such a Gaussian-shaped attenuation is difﬁcult
to achieve in practice, but it turns out—as we shall see—that there are easier options.
Before exploring these options, we must lay some foundations, beginning with the
concept of coherent illumination in Sec. 8.5.1, and then moving on to point-spread
functions in Sec. 8.5.2.
8.5.1
8.5.1 Coherent Illumination
If the radiation arriving at the input of an optical system derives from a single source
(e.g., a point source that has been collimated into a parallel beam by a converging
lens), then the radiation is best described by its complex amplitude ψ (as we are do-
ing in this chapter). An example might be a biological specimen on a microscope
slide, illuminated by an external point source, for which the phases of the waves leav-
ing different parts of the slide are strongly correlated with one another. This is called
coherent illumination.If, by contrast, the source is self-luminous and of nonnegligible
size, with the atoms or molecules in its different parts radiating independently—for
example, a cluster of stars—then the phases of the radiation from different parts are
uncorrelated, and it may be the radiation’s energy ﬂux, not its complex amplitude,
that obeys well-deﬁned (nonprobabilistic) evolution laws. This is called incoherent
8.5 Paraxial Fourier Optics
437

illumination. In this chapter we develop Fourier optics for a coherently illuminating
source (the kind of illumination tacitly assumed in previous sections of the chapter).
A parallel theory with a similar vocabulary can be developed for incoherent illumina-
tion, and some of the foundations for it are laid in Chap. 9. In Chap. 9, we also develop
a more precise formulation of the concept of coherence.
8.5.2
8.5.2 Point-Spread Functions
In our treatment of paraxial geometric optics (Sec. 7.4), we showed how it is possible
to regard a group of optical elements as a sequence of linear devices and relate the
output rays to the input by linear operators (i.e., matrices). This chapter’s theory of
diffraction is also linear, and so a similar approach can be followed. As in Sec. 7.4, we
restrict attention to small angles relative to some optic axis (“paraxial Fourier optics”).
We describe the wave ﬁeld at some distance zj along the optic axis by the function
ψj(x), wherex isa2-dimensionalvectorperpendiculartotheopticaxis(asinFig.8.5).
If we consider a single linear optical device, then we can relate the output ﬁeld ψ2 at
z2 to the input ψ1 at z1 using a Green’s function denoted P21(x2, x1):6
Green’s function,
point-spread function,
propagator
ψ2(x2) =

P21(x2, x1)d1ψ1.
(8.26)
If ψ1were a delta function, then the output would be simply given by the function P21,
up to normalization. For this reason, P21is usually known as the point-spread function.
Alternatively, we can think of it as a propagator.If we now combine two optical devices
sequentially, so the output ψ2 of the ﬁrst device is the input to the second, then the
point-spread functions combine in the natural manner of any linear propagator to
give a total point-spread function
combining point-spread
functions
P31(x3, x1) =

P32(x3, x2)d2P21(x2, x1).
(8.27)
Just as the simplest matrix for paraxial, geometric-optics propagation is that for
free propagation through some distance d, so also the simplest point-spread function
is that for free propagation. From Eq. (8.22) we see that it is given by
free-propagation point-
spread function
P21 = −ik
2πd eikd exp
ik(x2 −x1)2
2d

for free propagation through a distance d = z2 −z1.
(8.28)
6.
The approach followed here has an interesting history. It originated in the treatment of Markov processes
by Norbert Wiener and others (see Sec 6.3). It was then cleverly adopted for use in quantum mechanics
and quantum ﬁeld theory by Paul Dirac, Richard Feynman, and others, where it constitutes the path
integral formulation. This, in turn, suggested the simpler adaptation to problems in classical optics laid
out here.
438
Chapter 8. Diffraction

source plane
lens plane
xS
xF
xI
xL
xL′
focal plane
image plane
u
f
v
FIGURE 8.15 Wave theory of a single converging lens. The focal plane is a distancef (lens focal length)
from the lens plane; and the image plane is a distance v = f u/(u −f ) from the lens plane.
NotethatthisP21dependsonlyonx2 −x1asitshould, andnotonx2 orx1individually,
because there is joint translational invariance in the transverse x1, x2 planes.
A thin lens adds or subtracts an extra phase ϕ to the wave, and ϕ depends
quadratically on distance |x| from the optic axis, so the angle of deﬂection, which
is proportional to the gradient of the extra phase, will depend linearly on x. Corre-
spondingly, the point-spread function for a thin lens with focal lengthf is
thin-lens point-spread
function
P21 = exp
−ik|x1|2
2f

δ(x2 −x1).
(8.29)
For a converging lens, f is positive; for a diverging one, it is negative.
8.5.3
8.5.3 Abb´e’s Description of Image Formation by a Thin Lens
We can use the two point-spread functions (8.28) and (8.29) to give a wave description
of the production of images by a single converging lens, in parallel to the geometric-
optics description of Fig. 7.6. This description was formulated by Ernst Abb´e in 1873.
We develop Abb´e’s description in two stages. First, we propagate the wave from the
source plane S a distance u in front of the lens, through the lens L, and to its focal
plane F a distance f behind the lens (Fig. 8.15). Then we propagate the wave a further
distance v −f from the focal plane to the image plane. We know from geometric
opticsthatv = f u/(u −f )[Eq.(7.58)].Werestrictourselvestou > f , sov ispositive
and the lens forms a real, inverted image.
8.5 Paraxial Fourier Optics
439

Using Eqs. (8.27)–(8.29), we obtain the following expression for the propagator
from the source plane S through the lens plane L to the focal plane F:
PFS =

PFL′dL′PL′LdLPLS
=

−ik
2πf eikf exp
*
ik(xF −x′
L)2
2f
+
dL′δ(xL′ −xL) exp
−ik|xL|2
2f

× dL
−ik
2πueiku exp
ik(xL −xS)2
2u

= −ik
2πf eik(f +u) exp
*
−ikx2
F
2(v −f )
+
exp
−ikxF . xS
f

.
(8.30)
Here we have extended all integrations to ±∞and have used the values of the Fresnel
integrals at inﬁnity, E(±∞) = ±(1 + i)/2, to get the expression on the last line. The
wave in the focal plane is given by ψF(xF) =

PFSdSψS(xS), which integrates to
wave ﬁeld in focal plane of
a thin lens
ψF(xF) = −ik
2πf eik(f +u) exp
*
−ikx2
F
2(v −f )
+
˜ψS(xF/f ).
(8.31)
Here
˜ψS(θ) =

dSψS(xS)e−ikθ.xS.
(8.32)
Equation (8.31) states that the ﬁeld in the focal plane is, apart from a phase factor,
proportional to the Fourier transform of the ﬁeld in the source plane [recall our optics
convention Eq. (8.11a) for the Fourier transform]. In other words, the focal-plane ﬁeld
Fraunhofer diffraction in
focal plane
is the Fraunhofer diffraction pattern of the input wave. That this has to be the case can
be understood from Fig. 8.15. The focal plane F is where the converging lens brings
parallel rays from the source plane to a focus. By doing so, the lens in effect brings
in from “inﬁnity” the Fraunhofer diffraction pattern of the source [Eq. (8.11a)]7 and
places it into the focal plane.
It now remains to propagate the ﬁnal distance from the focal plane to the im-
age plane. We do so with the free-propagation point-spread function (8.28): ψI =

PIFdFψF, which integrates to
wave ﬁeld in image plane
of a thin lens
ψI(xI) = −
u
v

eik(u+v) exp
*
ikx2
I
2(v −f )
+
ψS

xS = −xIu/v

.
(8.33)
7.
In Eq. (8.11a), the input wave at the system’s entrance aperture is ψS = ψ′ t(x) ∝t(x) [Eq. (8.6) and
Fig. 8.2], the Fraunhofer diffraction pattern is ψP ∝˜t(θ), and the lens produces the focal-plane ﬁeld
˜ψF ∝˜t(xF/f ).
440
Chapter 8. Diffraction

Thus (again ignoring a phase factor) the wave in the image plane is just a magniﬁed
and inverted version of the wave in the source plane, as we might have expected from
geometric optics. In words, the lens acts by taking the Fourier transform of the source
and then takes the Fourier transform again to recover the source structure.
8.5.4
8.5.4 Image Processing by a Spatial Filter in the Focal Plane of a Lens:
High-Pass, Low-Pass, and Notch Filters; Phase-Contrast Microscopy
ThefocalplaneofalensisaconvenientplacetoprocessanimagebyalteringitsFourier
spatial ﬁltering
transform. This process, known as spatial ﬁltering, is a powerful technique. We shall
gain insight into its power via several examples.
Ineachoftheseexamples, weassumeforsimplicitytheone-lenssystemofFig.8.15,
for which we worked out Abb´e’s description in the previous section. If the source
wave has planar phase fronts parallel to the source plane so ψS is real, then the output
wave in the image plane has spherical phase fronts, embodied in the phase factor
exp[ikx2
I/(2(v −f ))]. If, instead, one wants the output wave to have the same planar
phase fronts as the input wave, one can achieve that by using a two-lens system with
the lenses separated by the sum of the lenses’ focal lengths and altering the Fourier
transform occurring in the common focal plane between them (Ex. 8.11).
LOW-PASS FILTER: CLEANING A LASER BEAM
aperture stop to remove
high spatial-frequency
noise
In low-pass ﬁltering, a small circular aperture or “stop” is introduced into the
focal plane, thereby allowing only the low-order spatial Fourier components (long-
wavelength components) to be transmitted to the image plane. This produces a
considerable smoothing of the wave. An application is to the output beam from a
laser (Chap. 10), which ought to be smooth but in practice has high spatial frequency
structure (high transverse wave numbers, short wavelengths) on account of noise and
imperfections in the optics. A low-pass ﬁlter can be used to clean the beam. In the
language of Fourier transforms, if we multiply the transform of the source, in the focal
plane, by a small-diameter circular aperture function, we will thereby convolve the
image with a broad Airy-disk smoothing function.
HIGH-PASS FILTER: ACCENTUATING AN IMAGE’S FEATURES
high-pass ﬁlter to
accentuate edges
Conversely, we can exclude the low spatial frequencies with a high-pass ﬁlter (e.g., by
placing an opaque circular disk in the focal plane, centered on the optic axis). This
accentuates boundaries and discontinuities in the source’s image and can be used to
highlight features where the gradient of the brightness is large.
NOTCH FILTER: REMOVING PIXELATION FROM AN IMAGE
Another type of ﬁlter is used when the image is pixelated and thus has unwanted
structure with wavelength equal to pixel size. A narrow range of frequencies centered
around this spatial frequency is removed by putting an appropriate ﬁlter in the focal
notch ﬁlter to remove
pixelations
plane; this is sometimes called a “notch ﬁlter.”
8.5 Paraxial Fourier Optics
441

aperture edge
aperture edge
specimen
focal plane
image plane
Airy disk
ϕ˜
ϕ˜
1/4-wave phase plate
and attenuator
FIGURE 8.16 Schematic phase-contrast microscope.
PHASE-CONTRAST MICROSCOPY
Phase-contrast microscopy (Fig. 8.16) is a useful technique for studying small objects,
such as transparent biological specimens, that modify the phase of coherent illumi-
nating light but not its amplitude. Suppose that the differential phase change in the
object is small, |ϕ| ≪1, as often is the case for biological specimens. We can then write
the ﬁeld just after it passes through the specimen as
ψS(x) = H(x)eiϕ(x) ≃H(x) + iϕ(x)H(x).
(8.34)
Here H is the microscope’s aperture function, unity for |x| < D/2 and zero for
|x| > D/2, with D the aperture diameter. The energy ﬂux is not modulated, and
therefore the effect of the specimen on the wave is hard to observe unless one is clever.
Equation (8.34) and the linearity of the Fourier transform imply that the wave
in the focal plane is the sum of (i) the Fourier transform of the aperture function
[Eq. (8.18) and Ex. 8.4] and (ii) the transform of the phase function convolved with
that of the aperture [in which the ﬁne-scale variations of the phase function dominate
and push ˜ϕ to large radii in the focal plane (Fig. 8.16), where the aperture has little
inﬂuence]:
ψF ∼jinc
kD|xF|
2f

+ i ˜ϕ
xF
f

,
where
jinc(x) = J1(x)/x.
(8.35)
If a high-pass ﬁlter is used to remove the Airy disk completely, then the remaining
wave ﬁeld in the image plane will be essentially ϕ magniﬁed by v/u. However, the
energy ﬂux F ∝(ϕv/u)2 will be quadratic in the phase, and so the contrast in the
converting phase changes
to amplitude changes
image will still be small. A better technique is to phase shift the Airy disk in the focal
plane by π/2 so that the two terms in Eq. (8.35) are in phase. The ﬂux variations,
F ∼(1± ϕ)2 ≃1± 2ϕ, will now be linear in the phase ϕ. An even better procedure is
442
Chapter 8. Diffraction

source plane
xS
xF
xI
filter plane
image plane
f
f
f
f
FIGURE 8.17 Two-lens system for spatial ﬁltering.
to attenuate the Airy disk until its amplitude is comparable with the rms value of ϕ and
also phase shift it by π/2 (as indicated by the “1/4-wave phase plate and attenuator” in
Fig.8.16).Thiswillmaximizethecontrastintheﬁnalimage.Analogoustechniquesare
used in communications to interconvert amplitude-modulated and phase-modulated
signals.
EXERCISES
Exercise 8.11 **Example: Two-Lens Spatial Filter
Figure 8.17 depicts a two-lens system for spatial ﬁltering (also sometimes called a
“4f system,” since it involves ﬁve special planes separated by four intervals with
lengths equal to the common focal length f of the two lenses). Develop a description,
patterned after Abb´e’s, of image formation with this system. Most importantly, do the
following.
(a) Show that the ﬁeld at the ﬁlter plane is
ψF(xF) = −ik
2πf e2ikf ˜ψS(xF/f ).
(8.36a)
This is like Eq. (8.31) for the one-lens system but with the spatially dependent
phase factor exp[−ikx2
F/(2(v −f ))] gone, so aside from a multiplicative con-
stant, the ﬁlter-plane ﬁeld is precisely the Fourier transform of the source-plane
ﬁeld.
(b) In the ﬁlter plane we place a ﬁlter whose transmissivity we denote ˜K(−xF/f ),
so it is (proportional to) the ﬁlter-plane ﬁeld that would be obtained from some
source-plane ﬁeld K(−xS). Using the optics conventions (8.11) for the Fourier
transformanditsinverse, showthattheimage-planeﬁeld, withtheﬁlterpresent,is
ψI(xI) = −e4ikf!S(xS = −xI).
(8.36b)
8.5 Paraxial Fourier Optics
443

Here !S is the convolution of the source ﬁeld and the ﬁlter function
!S(xS) =

K(xS −x′)ψS(x′)d′.
(8.36c)
In the absence of the ﬁlter, !S is equal to ψS, so Eq. (8.36b) is like the image-
planeﬁeld(8.33)forthesingle-lenssystem, butwiththespatiallydependentphase
factor exp[−ikx2
F/(2(v −f ))]gone. Thus ψI is precisely the same as the inverted
ψS, aside from an overall phase.
Exercise 8.12 Problem: Convolution via Fourier Optics
(a) Suppose that you have two thin sheets with transmission functions t = g(x, y)
and t = h(x, y), and you wish to compute via Fourier optics the convolution
g ⊗h(xo, yo) ≡
 
g(x, y)h(xo −x, yo −y) dx dy.
(8.37)
Devise a method for doing so using Fourier optics. [Hint: Use several lenses and
a projection screen with a pinhole through which passes light whose energy ﬂux
is proportional to the convolution; place the two sheets at strategically chosen
locations along the optic axis, and displace one of the two sheets transversely
with respect to the other.]
(b) Suppose you wish to convolve a large number of different pairs of 1-dimensional
functions {g1h1}, {g2h2}, . . . simultaneously; that is, you want to compute
gj ⊗hj(xo) ≡

gj(x)hj(xo −x)dx
(8.38)
for j = 1, 2, . . . . Devise a way to do this via Fourier optics using appropriately
constructed transmissive sheets and cylindrical lenses.
Exercise 8.13 **Example: Transmission Electron Microscope
In a transmission electron microscope, electrons, behaving as waves, are prepared in
near-plane-wave quantum wave-packet states with transverse sizes large compared to
theobject(“sample”)beingimaged.Thesample, placedinthesourceplaneofFig.8.15,
is sufﬁciently thin—with a transmission function t(x)—that the electron waves can
passthroughit, beingdiffractedintheprocess.Thediffractedwavestravelthroughthe
lens shown in Fig. 8.15 (the objective lens), then onward to and through a second lens,
called the projector lens,which focuses them onto a ﬂuorescent screen that shines with
anenergyﬂuxproportionaltothearrivingelectronﬂux.Atleasttwolensesareneeded,
as in the simplest of optical microscopes and telescopes (Figs. 7.7 and 7.8), and for
the same reason: to make images far larger than could be achieved with a single lens.
(a) The electrons all have the same kinetic energy E ∼200 keV, to within an energy
spread E ∼1 eV. What is the wavelength λ of their nearly plane-wave quan-
tum wave functions, and what is their fractional wavelength spread λ/λ? Your
444
Chapter 8. Diffraction

answer for λ (∼a few picometers) is so small that electron microscopy can be
used to study atoms and molecules. Contrast this with light’s million-fold longer
wavelength ∼1 μm, which constrains it to imaging objects a million times larger
than atoms.
(b) Explain why the paraxial Fourier-optics formalism that we developed in Sec. 8.5
can be used without change to analyze this electron microscope. This is true
even though the photons of an ordinary microscope are in states with mean
occupation numbers η huge compared to unity while the electrons have η ≪1,
and the photons have zero rest mass while the electrons have ﬁnite rest mass m
with roughly the same magnitude as their kinetic energies, E ∼mc2.
(c) Suppose that each magnetic lens in the electron microscope is made of two
transverse magnetic quadrupoles, as described in Sec. 7.4.2. Show that, although
these quadrupoles are far from axisymmetric, their combined inﬂuence on each
electron’s wave function is given by the axisymmetric thin-lens point-spread
function (8.29) with focal length (7.66), to within the accuracy of the analysis
of Sec. 7.4.2. [In practice, higher-order corrections make the combined lens
sufﬁciently nonaxisymmetric that electron microscopes do not use this type of
magnetic lens. Instead they use a truly axisymmetric lens in which the magnetic
ﬁeld lines lie in planes of constant azimuthal angle φ, and the ﬁeld lines ﬁrst bend
the electron trajectories into helices (give them motion in the φ direction), then
bend them radially, and then undo the helical motion.]
(d) By appropriate placement of the projector lens, the microscope can produce, in
the ﬂuorescing plane, either a vastly enlarged image of the source-plane sample,
|t(x)|2, or a large image of the modulus of that object’s Fourier transform (the
object’s diffraction pattern), |˜t(k)|2. Explain how each of these is achieved.
8.5.5
8.5.5 Gaussian Beams: Optical Cavities and Interferometric
Gravitational-Wave Detectors
The mathematical techniques of Fourier optics enable us to analyze the structure and
propagation of light beams that have Gaussian proﬁles. Such Gaussian beams are the
natural output of ideal lasers; they are the real output of spatially ﬁltered lasers; and
they are widely used for optical communication, interferometry, and other practical
applications. Moreover, they are the closest one can come in the real world of wave
optics to the idealization of a geometric-optics pencil beam.
Considerabeamthatispreciselyplane-fronted, withaGaussianproﬁle, atlocation
z = 0 on the optic axis:
ψ0 = exp
*
−ϖ 2
σ 2
0
+
;
(8.39)
8.5 Paraxial Fourier Optics
445

here ϖ = |x| is radial distance from the optic axis. The form of this same wave at a
distance z farther down the optic axis can be computed by propagating this ψ0 using
the point-spread function (8.28) (with the distance d replaced by z). The result is
freely propagating
Gaussian beam
ψz = σ0
σz
exp
*
−ϖ 2
σ 2
z
+
exp

i
kϖ 2
2Rz
+ kz −arctan z
z0

,
(8.40a)
where
z0 = kσ 2
0
2
= πσ 2
0
λ ,
σz = σ0(1 + z2/z2
0)1/2,
Rz = z(1 + z2
0/z2),
(8.40b)
and a subscript z indicates that this quantity is a function of z. These equations for
the freely propagating Gaussian beam are valid for negative z as well as positive.
From these equations we learn the following properties of the beam:
.
The beam’s cross sectional energy-ﬂux distribution
F ∝|ψz|2 ∝exp(−ϖ 2/σ 2
z )
remains a Gaussian as the wave propagates, with a beam radius
beam radius
σz = σ0

1 + z2/z2
0
that is a minimum at z = 0 (the beam’s waist) and grows away from the
waist, both forward and backward, in just the manner to be expected from
our uncertainty-principle discussion of wavefront spreading [Eq. (8.9)]. At
distances |z| ≪z0 from the waist location (corresponding to a Fresnel length
rF = √λ|z| ≪√πσ0), the beam radius is nearly constant; this is the Fresnel
region. At distances z ≫z0 (rF ≫√πσ0), the beam radius increases linearly
[i.e., the beam spreads with an opening angle θ = σ0/z0 = λ/(πσ0)]; this is
the Fraunhofer region.
.
The beam’s wavefronts (surfaces of constant phase) have phase
ϕ = kϖ 2/(2Rz) + kz −arctan(z/z0) = constant.
The arctan term (called the wave’s Gouy phase) varies far far more slowly
Gouy phase
with changing z than does the kz term, so the wavefronts are almost precisely
z = −ϖ 2/2Rz + const, whichisasegmentofasphereofradiusRz.Thus, the
wavefronts are spherical, with radii of curvature Rz = z(1+ z2
0/z2), which is
inﬁnite (ﬂat phase fronts) at the waist z = 0, decreases to a minimum of 2z0 at
z = z0 (boundary between Fresnel and Fraunhofer regions and beginning of
substantial wavefront spreading), and then increases as z (gradual ﬂattening
of spreading wavefronts) when one moves deep into the Fraunhofer region.
446
Chapter 8. Diffraction

.
The Gaussian beam’s form [Eqs. (8.40)] at some arbitrary location is fully
characterized by three parameters: the wavelength λ = 2π/k, the distance
z to the waist, and the beam radius σ0 at the waist [from which one can
compute the local beam radius σz and the local wavefront radius of curvature
Rz via Eqs. (8.40b)].
One can easily compute the effects of a thin lens on a Gaussian beam by folding
the ψz at the lens’s location into the lens point-spread function (8.29). The result is
a phase change that preserves the general Gaussian form of the wave but alters the
distance z to the waist and the radius σ0 at the waist. Thus, by judicious placement of
lenses or mirrors and with judicious choices of the lenses’ and mirrors’ focal lengths,
tailoring the beam
parameters
one can tailor the parameters of a Gaussian beam to ﬁt whatever optical device one is
working with. For example, if one wants to send a Gaussian beam into a self-focusing
optical ﬁber (Exs. 7.8 and 8.14), one should place its waist at the entrance to the
ﬁber and adjust its waist size there to coincide with that of the ﬁber’s Gaussian mode
of propagation (the mode analyzed in Ex. 8.14). The beam will then enter the ﬁber
smoothlyandwillpropagatesteadilyalongtheﬁber, withtheeffectsofthetransversely
varying index of refraction continually compensating for the effects of diffraction so
as to keep the phase fronts ﬂat and the waist size constant.
use of Gaussian beams in
LIGO
Gaussian beams are used (among many other places) in interferometric
gravitational-wave detectors, such as LIGO (the Laser Interferometer Gravitational-
Wave Observatory). We shall learn how these GW interferometers work in Sec. 9.5.
For the present, all we need to know is that a GW interferometer entails an optical
cavity formed by mirrors facing each other, as in Fig. 7.9. A Gaussian beam travels
back and forth between the two mirrors, its light superposing on itself coherently
after each round trip—the light resonates in the cavity formed by the two mirrors.
Each mirror hangs from an overhead support, and when a gravitational wave passes,
it pushes the hanging mirrors back and forth with respect to each other, causing the
cavity to lengthen and shorten by a tiny fraction of a light wavelength. This puts a
minuscule phase shift on the resonating light, which is measured by allowing some of
the light to leak out of the cavity and interfere with light from another, similar cavity
(see Sec. 9.5).
For the light to resonate in the cavity, the mirrors’ surfaces must coincide with the
Gaussian beam’s wavefronts. Suppose that the mirrors are identical, with radii of cur-
vature R, and are separated by a distance L = 4 km, as in LIGO. Then the beam must
be symmetric around the center of the cavity, so its waist must be halfway between
the mirrors. What is the smallest that the beam radius can be at the mirrors’ locations
z = ±L/2 = ±2 km? From σz = σ0(1 + z2/z2
0)1/2 together with z0 = πσ 2
0/λ, we see
that σL/2 is minimized when z0 = L/2 = 2 km. If the wavelength is λ = 1.064 μm
(Nd:YAG—neodymium-doped yttrium aluminum garnet—laser light, as in LIGO),
then the beam radii at the waist and at the mirrors are σ0 =

λz0/π = √λL/2π =
2.6 cm, and σL/2 =
√
2σ0 = 3.7 cm, respectively, and the mirrors’ radii of curvature
are RL/2 = L = 4 km. This was approximately the regime of parameters used for
8.5 Paraxial Fourier Optics
447

LIGO’s initial GW interferometers, which carried out a 2-year-long search for grav-
itational waves from autumn 2005 to autumn 2007 and then, after some sensitivity
improvements, a second long search in 2009 and 2010.
advanced LIGO
A new generation of GW interferometers, called “Advanced LIGO” (LIGO Sci-
entiﬁc Collaboration, 2015), began operating in summer 2015 and shortly thereafter
discoveredgravitationalwaves.IntheseGWinterferometers, thespotsizesonthemir-
rors are enlarged, so as to reduce thermal noise by averaging over a much larger spatial
sampling of thermal ﬂuctuations of the mirror surfaces (cf. Secs. 6.8.2 and 11.9.2).
How were the spot sizes enlarged? From Eqs. (8.40b) we see that, in the limit z0 =
πσ 2
0/λ →0, the mirrors’ radii of curvature approach the cavity half-length, RL/2 →
L/2, and the beam radii on the mirrors diverge as σL/2 →Lλ/(2πσ0) →∞. This
is the same instability as we discovered in the geometric-optics limit (Ex. 7.12). Ad-
vanced LIGO takes advantage of this instability by moving toward the near-unstable
regime, causing the beams on the mirrors to enlarge. In Advanced LIGO’s semiﬁnal
design, the mirrors’ radii of curvature were set at RL/2 = 2.076 km, just 4% above
the unstable point R = L/2 = 2 km; and Eqs. (8.40b) then tell us that σ0 = 1.15 cm,
z0 = 0.389 km ≪L/2 = 2 km, and σz was pushed up by nearly a factor of two, to
σz = 6.01cm. The mirrors are deep into the Fraunhofer, wavefront-spreading region.
In the ﬁnal design the optical cavity was made slightly asymmetric with mirror radii
of curvature a bit below and a bit above 2.076 km (Table 1 of LIGO Scientiﬁc Collab-
oration, 2015).
EXERCISES
Exercise 8.14 Problem: Guided Gaussian Beams
Consider a self-focusing optical ﬁber discussed in Ex. 7.8, in which the refractive
index is
n(x) = no(1 −α2r2)1/2,
(8.41)
where r = |x|.
(a) Write down the Helmholtz equation in cylindrical polar coordinates and seek an
axisymmetric mode for which ψ = R(r)Z(z), where R and Z are functions to
be determined, and z measures distance along the ﬁber. In particular, show that
there exist modes with a Gaussian radial proﬁle that propagate along the ﬁber
without spreading.
(b) Compute the group and phase velocities along the ﬁber for this mode.
Exercise 8.15 Example: Noise Due to Scattered Light in LIGO
In LIGO and other GW interferometers, one potential source of noise is scattered
light. When the Gaussian beam in one of LIGO’s cavities reﬂects off a mirror, a small
portion of the light gets scattered toward the walls of the cavity’s vacuum tube. Some of
thisscatteredlightcanreﬂectorscatteroffthetubewallandthenpropagatetowardthe
distant mirror, where it scatters back into the Gaussian beam; see Fig. 8.18a (without
448
Chapter 8. Diffraction

mirror
mirror
vacuum tube wall
vacuum tube wall
Gaussian beam
(b)
(a)
baffles
baffles
FIGURE 8.18 (a) Scattered light in LIGO’s beam tube. (b) Cross section of a bafﬂe used
to reduce the noise due to scattered light.
the bafﬂes, which are shown dashed). This is troublesome because the tube wall
vibrates from sound-wave excitations and seismic excitations, and those vibrations
put a phase shift on the scattered light. Although the fraction of all the light that
scatters in this way is tiny, the phase shift is huge compared to that produced in the
Gaussian beam by gravitational waves. When the tiny amount of scattered light with
its huge oscillating phase shift recombines into the Gaussian beam, it produces a net
Gaussian-beam phase shift that can be large enough to mask a gravitational wave.
This exercise explores some aspects of this scattered-light noise and its control.
(a) The scattering of Gaussian-beam light off the mirror is caused by bumps in the
mirror surface (imperfections). Denote by h(x) the height of the mirror surface
relative to the desired shape (a segment of a sphere with radius of curvature that
matches the Gaussian beam’s wavefronts). Show that, if the Gaussian-beam ﬁeld
emerging from a perfect mirror is ψG(x) [Eq. (8.40a)] at the mirror plane, then
the beam emerging from the actual mirror is ψ′(x) = ψG(x) exp[−i2kh(x)]. The
magnitude of the mirror irregularities is very small compared to a wavelength, so
|2kh| ≪1, and the wave ﬁeld emerging from the mirror is ψ′(x) = ψG(x)[1 −
i2kh(x)]. Explain why the factor 1 does not contribute at all to the scattered light
(where does its light go?), so the scattered light ﬁeld emerging from the mirror is
ψS(x) = −iψG(x)2kh(x).
(8.42)
8.5 Paraxial Fourier Optics
449

(b) Assume that, when arriving at the vacuum-tube wall, the scattered light is in the
Fraunhofer region. (You will justify this later in this example.) Then at the tube
wall, the scattered light ﬁeld is given by the Fraunhofer formula
ψS(θ) ∝

ψG(x)kh(x)eikx.θd.
(8.43)
Show that the light that hits the tube wall at an angle θ = |θ| to the optic axis arises
from irregularities in the mirror that have spatial wavelengths λmirror ∼λ/θ. The
radiusofthebeamtubeisR = 60 cminLIGO, andthelengthofthetube(distance
between cavity mirrors) is L = 4 km. What is the spatial wavelength of the mirror
irregularities that scatter light to the tube wall at distances z ∼L/2 (which can
then reﬂect or scatter off the wall toward the distant mirror and there scatter back
into the Gaussian beam)? Show that for these irregularities, the tube wall is indeed
in the Fraunhofer region. [Hint: The irregularities have a coherence length of only
a few wavelengths λmirror.]
(c) In the initial LIGO interferometers, the mirrors’ scattered light consisted of two
components: one peaked strongly toward small angles so it hit the distant tube
wall (e.g., at z ∼L/2), and the other roughly isotropically distributed. What is
the size of the irregularities that produced the isotropic component?
(d) To reduce substantially the amount of scattered light reaching the distant mirror
via reﬂection or scattering from the tube wall, a set of bafﬂes was installed in the
tube, in such a way as to hide the wall from scattered light (dashed lines in Fig.
8.18). The bafﬂes have an angle of 35◦to the tube wall, so when light hits a bafﬂe,
it reﬂects at a steep angle, ∼70◦toward the opposite tube wall, and after a few
bounces gets absorbed. However, a small portion of the scattered light can now
diffract off the top of each bafﬂe and then propagate to the distant mirror and
scatter back into the main beam. Especially troublesome is the case of a mirror in
the center of the beam tube’s cross section, because light that scatters off such a
mirror travels nearly the same total distance from the mirror to the top of some
bafﬂe and then to the distant mirror, independent of the azimuthal angle φ on the
bafﬂe at which it diffracts. There is then a danger of coherent superposition of all
scattered light that diffracts off all angular locations around any given bafﬂe—and
coherent superposition means a much enlarged net noise (a variant of the Poisson
or Arago spot discussed in the footnote to Ex. 8.9). To protect against any such
coherence, the bafﬂes in the LIGO beam tubes are serrated (i.e., they have saw-
tooth edges), and the heights of the teeth are drawn from a random (Gaussian)
probability distribution (Fig. 8.18b). The typical tooth heights are large enough
to extend through about six Fresnel zones. How wide is each Fresnel zone at the
bafﬂe location, and correspondingly, how high must be the typical bafﬂe tooth?
By approximately how much do the random serrations reduce the light-scattering
noise, relative to what it would be with no serrations and with coherent scattering?
[Hint: See part e. There are two ways that the noise is reduced: (i) The breaking
450
Chapter 8. Diffraction

of coherence of scattered light by the randomness of serrated tooth height, which
causesthephaseofthescatteredlightdiffractingoffdifferentteethtoberandomly
different. (ii) The reduction in energy ﬂux of the scattered light due to the teeth
reaching through six Fresnel zones, on average.]
(e) To aid you in answering part d, show that the propagator (point-spread function)
for light that begins at the center of one mirror, travels to the edge of a bafﬂe, and
then propagates to the center of the distant mirror is
P ∝
 2π
o
exp
ikR2(φ)
2ℓred

dφ,
where
1
ℓred
= 1
ℓ+
1
L −ℓ.
(8.44)
Here R(φ) is the radial distance of the bafﬂe edge from the beam tube axis at
azimuthal angle φ around the beam tube, and at distance ℓdown the tube from
the scattering mirror. Note that ℓred is the “reduced bafﬂe distance” analogous
to the reduced mass in a binary system. One can show that the time-varying part
of the scattered-light amplitude (i.e., the part whose time dependence is produced
by bafﬂe vibrations) is proportional to this propagator. Explain why this is plau-
sible. Then explain how the bafﬂe serrations, embodied in the φ dependence of
R(φ), producethereductionofscattered-lightamplitudeinthemannerdescribed
in part c.
8.6
8.6 Diffraction at a Caustic
InSec.7.5, wedescribedhowcausticscanbeformedingeneralinthegeometric-optics
limit (e.g., on the bottom of a swimming pool when the water’s surface is randomly
rippled, or behind a gravitational lens). We chose as an example an imperfect lens
illuminated by a point source (Fig. 7.13) and showed how a pair of images would
merge as the transverse distance x of the observer from the caustic decreases to zero.
That merging was controlled by maxima and minima of the scaled time delay ˜t or
equivalently, the phase ϕ of the light that originates at transverse location a just before
the lens and arrives at transverse location x in the observation plane. We argued that
for a fold caustic, this phase, when expressed as a Taylor series in a, has the standard
form ϕ(˜a, ˜x) = ˜a3/3 −˜x ˜a, where ˜a and ˜x are rescaled a and x [Eq. (7.72)]. Using
this ϕ, we showed that the magniﬁcation M of the images diverged ∝˜x−1/2 as the
geometric optics
divergence at a fold
caustic
caustic was approached (˜x →0), and then Mcrashed to zero just past the caustic (the
two images disappeared). This singular behavior raised the question of what happens
when we take into account the ﬁnite wavelength of the wave while still assuming the
source has negligible size.
We are now in a position to answer this question. We simply use the Helmholtz-
Kirchhoff formula (8.6) to write the expression for the amplitude measured at position
˜x in the form (Ex. 8.17)
8.6 Diffraction at a Caustic
451

Ai(ξ)
ξ
5
–5
0.4
0.2
–0.2
–0.4
–15
–10
FIGURE 8.19 The Airy function Ai(ξ) describing diffraction at a fold caustic.
The argument is ξ = −˜x, where ˜x is rescaled distance from the caustic.
ψ(˜x) ∝

d ˜aeiϕ(˜a, ˜x) =

d ˜a(cos ϕ + i sin ϕ),
where
ϕ = ˜a3
3 −˜x ˜a.
(8.45)
The phase ϕ varies rapidly with location ˜a in the lens at large |˜a|, so we can treat the
limits of integration as ±∞. Because ϕ(˜a, ˜x) is odd in ˜a, the sine term integrates to
zero, and the cosine integral turns out to be the Airy function
diffraction at a caustic:
Airy function
ψ ∝
 ∞
−∞
d ˜a cos(˜a3/3 −˜x ˜a) = 2πAi(−˜x).
(8.46)
The Airy function Ai(ξ) is displayed in Fig. 8.19.
The asymptotic behavior of Ai(ξ) is
Ai(ξ) ∼π−1/2|ξ|−1/4 sin(2|ξ|3/2/3 + π/4),
for ξ →−∞
∼e−2ξ3/2/3
2π1/2ξ1/4 ,
for ξ →∞.
(8.47)
We see that the amplitude ψ remains ﬁnite as the caustic is approached (as ˜x = −ξ →
diffractive ﬁeld structure
at a fold caustic
0) instead of diverging as in the geometric-optics limit, and it decreases smoothly
toward zero when the caustic is passed, instead of crashing instantaneously to zero.
For ˜x > 0 (ξ = −˜x < 0; left part of Fig. 8.19), where an observer sees two geometric-
optics images, the envelope of ψ diminishes ∝˜x−1/4, so the energy ﬂux |ψ|2 decreases
∝˜x−1/2 just as in the geometric-optics limit. What is actually seen is a series of bands
of alternating dark and light with their spacing calculated by using (2˜x3/2/3) = π
or ˜x ∝˜x−1/2. At sufﬁcient distance from the caustic, it is not possible to resolve
these bands, and a uniform illumination of average ﬂux is observed, so we recover the
geometric-optics limit.
452
Chapter 8. Diffraction

These near-caustic scalings and others in Ex. 8.16, like the geometric-optics scal-
ings (Sec. 7.5), are a universal property of this type of caustic (the simplest caustic of
all, the “fold”).
There is a helpful analogy, familiar from quantum mechanics. Consider a particle
analogy with quantum
wave function in harmonic
oscillator potential
in a harmonic potential well in a highly excited state. Its wave function is given in the
usual way using Hermite polynomials of large order. Close to the classical turning
point, these functions change from being oscillatory to having exponential decay,
just like the Airy function (and if we were to expand about the turning point, we
would recover Airy functions). Of course, what is happening is that the probability
densityofﬁndingtheparticleclosetoitsturningpointdivergesclassically, becauseitis
movingvanishinglyslowlyattheturningpoint; theoscillationsstemfrominterference
between waves associated with the particle moving in opposite directions at the
turning point.
For light near a caustic, if we consider the transverse component of the photon
motion, then we have essentially the same problem. The ﬁeld’s oscillations stem
from interference of the waves associated with the motions of the photons in two
geometric-optics beams coming from slightly different directions and thus having
slightly different transverse photon speeds.
This is our ﬁrst illustration of the formation of large-contrast interference fringes
when only a few beams are combined. We shall meet other examples of such interfer-
ence in the next chapter.
EXERCISES
Exercise 8.16 Problem: Wavelength Scaling at a Fold Caustic
For the fold caustic discussed in the text, assume that the phase change introduced by
the imperfect lens is nondispersive, so that the ϕ(˜a, ˜x) in Eq. (8.45) satisﬁes ϕ ∝λ−1.
Show that the peak magniﬁcation of the interference fringes at the caustic scales
with wavelength, ∝λ−4/3. Also show that the spacing x of the fringes near a ﬁxed
observing position x is ∝λ2/3. Discuss qualitatively how the fringes will be affected
if the source has a ﬁnite size.
Exercise 8.17 Problem: Diffraction at Generic Caustics
In Sec. 7.5, we explored ﬁve elementary (generic) caustics that can occur in geometric
optics. Each is described by its phase ϕ(˜a, ˜b; ˜x, ˜y, ˜z) for light arriving at an observa-
tion point with Cartesian coordinates {˜x, ˜y, ˜z} along paths labeled by (˜a, ˜b).
(a) Suppose the (monochromatic) wave ﬁeld ψ(˜x, ˜y, ˜z) that exhibits one of these
caustics is produced by plane-wave light that impinges orthogonally on a phase-
shifting surface on which are laid out Cartesian coordinates (˜a, ˜b). Using the
Helmholtz-Kirchhoff diffraction integral (8.6), show that the ﬁeld near a caustic
is given by
ψ(˜x, ˜y, ˜z) ∝
 
d ˜a d ˜b eiϕ(˜a, ˜b;˜x, ˜y, ˜z).
(8.48)
8.6 Diffraction at a Caustic
453

(b) In the text we evaluated this near-caustic diffraction integral for a fold caustic, ob-
taining the Airy function. For the higher-order elementary caustics, the integral
cannot be evaluated analytically in terms of standard functions. To get insight into
the inﬂuence of ﬁnite wavelength, evaluate the integral numerically for the case
of a cusp caustic, ϕ = 1
4 ˜a4 −1
2 ˜z˜a2 −˜x ˜a, and plot the real and imaginary parts
of ψ (ℜψ and ℑψ). Before doing so, though, guess what these parts will look
like. As foundations for this guess, (i) pay attention to the shape ˜x = ±2(˜z/3)3/2
of the caustic in the geometric-optics approximation, (ii) notice that away from
the cusp point, each branch of the caustic is a fold, whose ψ is the Airy function
(Fig. 8.19), and (iii) note that the oscillating ψ associated with each branch in-
terferes with that associated with the other branch. The numerical computation
may take awhile, so make a wise decision from the outset as to the range of ˜z and
˜x to include in your computations and plots. If your computer is really slow, you
may want to prove that the integral is symmetric in ˜x and so restrict yourself to
positive ˜x, and argue that the qualitative behaviors of ℜψ and ℑψ must be the
same, and so restrict yourself to ℜψ.
Bibliographic Note
Hecht (2017) gives a pedagogically excellent treatment of diffraction at roughly the
same level as this chapter, but in much more detail, with many illustrations and
intuitive explanations. Other nice treatments at about our level will be found in stan-
dard optics textbooks, including Jenkins and White (1976), Brooker (2003), Sharma
(2006), Bennett (2008), Ghatak (2010), and, from an earlier era, Longhurst (1973)
and Welford (1988). The deﬁnitive treatment of diffraction at an advanced and thor-
ough level is that of Born and Wolf (1999). For an excellent and thorough treatment
of paraxial Fourier optics and spatial ﬁltering, see Goodman (2005). The standard
textbooks say little or nothing about diffraction at caustics, though they should; for
this, we recommend the brief treatment by Berry and Upstill (1980) and the thorough
treatment by Nye (1999).
454
Chapter 8. Diffraction

9
CHAPTER NINE
Interference and Coherence
When two Undulations, from different Origins, coincide either perfectly or very nearly in Direction,
their joint effect is a Combination of the Motions belonging to each.
THOMAS YOUNG (1802)
9.1
9.1 Overview
In the last chapter, we considered superpositions of waves that pass through a (typ-
ically large) aperture. The foundation for our analysis was the Helmholtz-Kirchhoff
expression (8.4) for the ﬁeld at a chosen point P as a sum of contributions from all
points on a closed surface surrounding P. The spatially varying ﬁeld pattern resulting
from this superposition of many different contributions is known as diffraction.
In this chapter, we continue our study of superposition, but for the special case
where only two (or at most, several) discrete beams are being superposed. For this
special case one uses the term interference rather than diffraction. Interference is
important in a wide variety of practical instruments designed to measure or use the
spatial and temporal structures of electromagnetic radiation. However, interference is
not just of practical importance. Attempting to understand it forces us to devise ways
of describing the radiation ﬁeld that are independent of the ﬁeld’s origin and of the
means by which it is probed. Such descriptions lead us naturally to the fundamental
concept of coherence (Sec. 9.2).
The light from a distant, monochromatic point source is effectively a plane wave;
we call it “perfectly coherent” radiation. In fact, there are two different types of co-
herence present: lateral or spatial coherence (coherence in the angular structure of the
radiationﬁeld), andtemporalorlongitudinalcoherence (coherenceintheﬁeld’stempo-
ral structure, which clearly must imply something also about its frequency structure).
We shall see in Sec. 9.2 that for both types of coherence there is a measurable quan-
tity, called the degree of coherence, that is the Fourier transform of either the radiation’s
angular intensity distribution I(α) (energy ﬂux per unit angle or solid angle, as a func-
tion of direction α) or its spectral energy ﬂux Fω(ω) (energy ﬂux per unit angular
frequency ω, as a function of angular frequency).
Interspersed with our development of the theory of coherence are two historical
devices with modern applications: (i) the stellar interferometer (Sec. 9.2.5), by which
Michelson measured the diameters of Jupiter’s moons and several bright stars using
455

BOX 9.1.
READERS’ GUIDE
.
This chapter depends substantially on
– Secs. 8.2, 8.3, and 8.5.5 and
– correlation functions, spectral densities, and the Wiener-
Khintchine theorem for random processes (Sec. 6.4).
.
The concept of coherence length or coherence time, as developed in
this chapter, is used in Chaps. 10, 15, 16, and 23.
.
Interferometry as developed in this chapter, especially in Sec. 9.5, is
a foundation for the discussion of gravitational-wave detection in
Sec. 27.6.
.
Nothing else in this book relies substantially on this chapter.
spatial coherence; and (ii) the Michelson interferometer and its practical implementa-
tion in a Fourier-transform spectrometer (Sec. 9.2.7), which use temporal coherence
to measure electromagnetic spectra (e.g., the spectral energy ﬂux of the cosmic mi-
crowave background radiation). After developing our full formalism for coherence,
we go on in Sec. 9.3 to apply it to the operation of radio telescope arrays, which func-
tion by measuring the spatial coherence of the radiation ﬁeld.
InSec.9.4, weturntomultiple-beaminterferometry, inwhichincidentradiationis
split many times into several different paths and then recombined. A simple example
is an etalon, made from two parallel, reﬂecting surfaces. A Fabry-Perot cavity inter-
ferometer, in which light is trapped between two highly reﬂecting mirrors (e.g., in a
laser), is essentially a large-scale etalon. In Secs. 9.4.3 and 9.5, we discuss a number
of applications of Fabry-Perot interferometers, including lasers, their stabilization,
manipulations of laser light, the optical frequency comb, and laser interferometer
gravitational-wave detectors.
Finally, in Sec. 9.6, we turn to the intensity interferometer. This has not proved
especially powerful in application but does illustrate some quite subtle issues of phys-
ics and, in particular, highlights the relationship between the classical and quantum
theories of light.
9.2
9.2 Coherence
9.2.1
9.2.1 Young’s Slits
Young’s slits
ThemostelementaryexampleofinterferenceisprovidedbyYoung’sslits.Supposetwo
long, narrow, parallel slits are illuminated coherently by monochromatic light from a
distant source that lies on the perpendicular bisector of the line joining the slits (the
456
Chapter 9. Interference and Coherence

(a)
(b)
(c)
(d)
θ
θ
θ
θ
FP
r
a
P
FP
Fmax
Fmin
Fmax – Fmin
—
Fmax + Fmin
|γ?| = 
θ
θ
α
α
r
a
P
arg (γ?)
FIGURE 9.1 (a) Young’s slits. (b) Interference fringes observed in a transverse plane [Eq. (9.1b)].
(c) The propagation direction of the incoming waves is rotated to make an angle α to the optic axis; as
a result, the angular positions of the interference fringes in panel b are shifted by θ = α [Eq. (9.3);
not shown]. (d) Interference fringes observed from an extended source [Eq. (9.8)].
optic axis), so an incident wavefront reaches the slits simultaneously (Fig. 9.1a). This
situation can be regarded as having only one lateral dimension because of translation
invariance in the other. The waves from the slits (effectively, two 1-dimensional
beams) fall onto a screen in the distant, Fraunhofer region, and there they interfere.
The Fraunhofer interference pattern observed at a point P, whose position is speciﬁed
using the polar coordinates {r, θ} shown in Fig. 9.1, is proportional to the spatial
Fourier transform of the transmission function [Eq. (8.11a)]. If the slits are very
narrow, we can regard the transmission function as two delta functions, separated
by the slit spacing a, and its Fourier transform will be
ψ(θ) ∝e−ikaθ/2 + eikaθ/2 ∝cos
kaθ
2

,
(9.1a)
where k = 2π/λ is the light’s wave number, and a is the slit’s separation. (That we
can sum the wave ﬁelds from the two slits in this manner is a direct consequence of
9.2 Coherence
457

the linearity of the underlying wave equation.) The energy ﬂux (energy per unit time
crossing a unit area) at P (at angle θ to the optic axis) will be
F(θ) ∝|ψ|2 ∝cos2(kaθ/2);
(9.1b)
cf. Fig. 9.1b. The alternating regions of dark and bright illumination in this ﬂux
interference fringes from
Young’s slits
distribution are known as interference fringes. Notice that the ﬂux falls to zero
between the bright fringes. This will be very nearly so even if (as is always the case in
practice) the ﬁeld is slightly nonmonochromatic, that is, even if the ﬁeld hitting the
slits has the form ei[ωot+δϕ(t)], where ωo = c/k is the light’s average angular frequency,
and δϕ(t) is a phase [not to be confused with the light’s full phase ϕ = ωot + δϕ(t)],
which varies randomly on a timescale extremely long compared to 1/ωo.1 Notice also
that there are many fringes, symmetrically disposed with respect to the optic axis. [If
we were to take account of the ﬁnite width w ≪a of the two slits, then we would ﬁnd,
by contrast with Eq. (9.1b), that the actual number of fringes is ﬁnite, in fact of order
a/w; cf. Fig. 8.6 and associated discussion.] This type of interferometry is sometimes
interference by division of
the wavefront
known as interference by division of the wavefront.
Of course, this Young’s slits experiment is familiar from quantum mechanics,
where it is often used as a striking example of the nonparticulate behavior of electrons
Young’s slits in quantum
mechanics
(e.g., Feynman, Leighton, and Sands, 2013, Vol. III, Chap. 1). Just as for electrons,
so also for photons it is possible to produce interference fringes even if only one
photon is in the apparatus at any time, as was demonstrated in a famous experiment
performed by G. I. Taylor in 1909. However, our concerns in this chapter are with
the classical limit, where many photons are present simultaneously and their ﬁelds
can be described by Maxwell’s equations. In the next subsection we depart from the
usual quantum mechanical treatment by asking what happens to the fringes when the
source of radiation is spatially extended.
EXERCISES
Exercise 9.1 Problem: Single-Mirror Interference
X-rayswithwavelength8.33 ˚A(0.833 nm)comingfromapointsourcecanbereﬂected
at shallow angles of incidence from a plane mirror. The direct ray from a point source
1.
More precisely, if δϕ(t) wanders by ∼π on a timescale τc ≫2π/ωo (the waves’ coherence time), then the
waves are contained in a bandwidth ωo ∼2π/τc ≪ωo centered on ωo, k is in a band k ∼kω/ωo,
and the resulting superposition of precisely monochromatic waves has fringe minima with ﬂuxes Fmin
that are smaller than the maxima by Fmin/Fmax ∼(πω/ωo)2 ≪1. [One can see this in order of
magnitude by superposing the ﬂux (9.1b) with wave number k and the same ﬂux with wave number
k + k.] Throughout this section, until Eq. (9.15), we presume that the waves have such a small
bandwidth (such a long coherence time) that this Fmin/Fmax is completely negligible; for example,
1 −Fmin/Fmax is far closer to unity than any fringe visibility V [Eq. (9.8)] that is of interest to us. This
can be achieved in practice by either controlling the waves’ source or by band-pass ﬁltering the measured
signals just before detecting them.
458
Chapter 9. Interference and Coherence

to a detector 3 m away interferes with the reﬂected ray to produce fringes with spacing
25 μm. Calculate the distance of the X-ray source from the mirror plane.
9.2.2
9.2.2 Interference with an Extended Source: Van Cittert-Zernike Theorem
We approach the topic of extended sources in steps. Our ﬁrst step was taken in the
last subsection, where we dealt with an idealized, single, incident plane wave, such
as might be produced by an ideal, distant laser. We have called this type of radiation
perfect coherence
“perfectly coherent,” which we have implicitly taken to mean that the ﬁeld oscillates
with a ﬁxed angular frequency ωo and a randomly but very slowly varying phase δϕ(t)
(seefootnote1), andthus, forallpracticalpurposes, thereisatime-independentphase
difference between any two points in the region under consideration.
As our second step, we keep the incoming waves perfectly coherent and perfectly
planar, but change their incoming direction in Fig. 9.1 so it makes a small angle α to
the optic axis (and correspondingly, its wavefronts make an angle α to the plane of
the slits) as shown in Fig. 9.1c. Then the distribution of energy ﬂux in the Fraunhofer
diffraction pattern on the screen will be modiﬁed to
interference fringes for
perfectly coherent waves
from angle ααα
F(θ) ∝|e−ika(θ−α)/2 + e+ika(θ−α)/2|2 ∝cos2
ka(θ −α)
2

∝{1 + cos[ka(θ −α)]}.
(9.2)
Notice that, as the direction α of the incoming waves is varied, the locations of the
bright and dark fringes change by θ = α, but the fringes remain fully sharp (their
minima remain essentially zero; cf. footnote 1). Thus, the positions of the fringes carry
information about the direction to the source.
Now, in our third and ﬁnal step, we deal with an extended source (i.e., one whose
radiation comes from a ﬁnite range of angles α), with (for simplicity) |α| ≪1. We
assume that the source is monochromatic (and in practice we can make it very nearly
monochromatic by band-pass ﬁltering the waves just before detection). However, in
keeping with how all realistic monochromatic sources (including band-pass ﬁltered
sources) behave, we give it a randomly ﬂuctuating phase δϕ(t) [and amplitude A(t)],
and require that the timescale on which the phase and amplitude wander (the waves’
coherence time) be long compared to the waves’ period 2π/ωo; cf. footnote 1.
We shall also assume that the sources of the light propagating in different direc-
tions are independent and uncorrelated. Typically, they are separate electrons, ions,
atoms, or molecules. To make this precise, we write the ﬁeld in the form2
wave ﬁeld from extended
source
!(x, z, t) = ei(kz−ωot)

ψ(α, t)eikαxdα,
(9.3)
2.
As in Chap. 8, we denote the full ﬁeld by ! and reserve ψ to denote the portion of the ﬁeld from which
a monochromatic part e−iωot or ei(kz−ωot) has been factored out.
9.2 Coherence
459

whereψ(α, t) = Ae−iδϕ istheslowlywanderingcomplexamplitudeofthewavesfrom
direction α. When we consider the total ﬂux arriving at a given point (x, z) from two
different directions α1 and α2 and average it over times long compared to the waves’
coherence time, then we lose all interference between the two contributions:
incoherent superposition
of radiation
|ψ(α1, t) + ψ(α2, t)|2 = |ψ(α1, t)|2 + |ψ(α2, t)|2.
(9.4)
Such radiation is said to be incoherent in the incoming angle α, and we say that the
contributions from different directions superpose incoherently.This is just a fancy way
of saying that their intensities (averaged over time) add linearly.
The angularly incoherent light from our extended source is sent through two
Young’s slits and produces fringes on a screen in the distant Fraunhofer region. We
assume that the coherence time for the light from each source point is very long
compared to the difference in light travel time to the screen via the two different
slits. Then the light from each source point in the extended source forms the sharp
interference fringes described by Eq. (9.2). However, because contributions from
different source directions add incoherently, the ﬂux distribution on the screen is
a linear sum of the ﬂuxes from source points:
F(θ) ∝

dαI(α){1 + cos[ka(θ −α)]}.
(9.5)
Here I(α)dα ∝|ψ(α, t)|2dα is the ﬂux incident on the plane of the slits from the
inﬁnitesimal range dα of directions, so I(α) is the radiation’s intensity (its energy per
unit time falling on a unit area and coming from a unit angle). The remainder of the
integrand, 1 + cos[ka(θ −α)], is the Fraunhofer diffraction pattern [Eq. (9.2)] for
coherent radiation from direction α.
We presume that the range of angles present in the waves, α, is large compared to
their fractional bandwidth α ≫ω/ωo; so, whereas the ﬁnite but tiny bandwidth
produced negligible smearing out of the interference fringes (see footnote 1 in this
chapter), the ﬁnite but small range of directions may produce signiﬁcant smearing
[i.e., the minima of F(θ) might not be very sharp]. We quantify the fringes’ non-
sharpness and their locations by writing the slit-produced ﬂux distribution (9.5) in
the form
interference fringes from
extended source
F(θ) = FS[1 + ℜ{γ⊥(ka)e−ikaθ}],
(9.6a)
where
FS ≡

dαI(α)
(9.6b)
(subscript S for “source”) is the total ﬂux arriving at the slits from the source, and
degree of lateral coherence
γ⊥(ka) ≡

dαI(α)eikaα
FS
(9.7a)
460
Chapter 9. Interference and Coherence

is deﬁned as the radiation’s degree of spatial (or lateral) coherence.3 The phase of γ⊥
determines the angular locations of the fringes; its modulus determines their depth
(the amount of their smearing due to the source’s ﬁnite angular size).
The nonzero value of γ⊥(ka) reﬂects the existence of some degree of relative
coherence between the waves arriving at the two slits, whose separation is a. The
radiation can have this ﬁnite spatial coherence, despite its complete lack of angular
coherence, because each angle contributes coherently to the ﬁeld at the two slits. The
lack of coherence for different angles reduces the net spatial coherence (smears the
fringes), but it does not drive the coherence all the way to zero (does not completely
destroy the fringes).
Equation (9.7a) states that the degree of lateral coherence of the radiation from an
extended, angularly incoherent source is the Fourier transform of the source’s angular
intensity pattern. Correspondingly, if one knows the degree of lateral coherence as a
function of the (dimensionless) distance ka, from it one can reconstruct the source’s
angular intensity pattern by Fourier inversion:
I(α) = FS
 d(ka)
2π
γ⊥(ka)e−ikaα.
(9.7b)
The two Fourier relations (9.7a) and (9.7b) make up the van Cittert-Zernike theorem.
van Cittert-Zernike
theorem for lateral
coherence
In Ex. 9.8, we shall see that this theorem is a complex-variable version of Chap. 6’s
Wiener-Khintchine theorem for random processes.
Because of its Fourier-transform relationship to the source’s angular intensity
pattern I(α), the degree of spatial coherence γ⊥(ka) is of great practical importance.
For a given choice of ka (a given distance between the slits), γ⊥is a complex number
that one can read off the interference fringes of Eq. (9.6a) and Fig. 9.1d as follows. Its
modulus is
|γ⊥| ≡V = Fmax −Fmin
Fmax + Fmin
,
(9.8)
where Fmax and Fmin are the maximum and minimum values of the ﬂux F on the
screen; and its phase arg(γ⊥) is ka times the displacement θ of the centers of the
fringe visibility, or visibility
bright fringes from the optic axis. The modulus (9.8) is called the fringe visibility,
or simply the visibility, because it measures the fractional contrast in the fringes
[Eq. (9.8)], and this name is the reason for the symbol V . Analogously, the complex
complex fringe visibility
quantity γ⊥(or a close relative) is sometimes known as the complex fringe visibility.
Notice that V can lie anywhere in the range from zero (no contrast; fringes completely
undetectable) to unity (monochromatic plane wave; contrast as large as possible).
3.
In Sec. 9.2.6, we introduce the degree of temporal coherence (also known as longitudinal coherence)
to describe the correlation along the direction of propagation. The correlation in a general, lateral and
longitudinal, direction is called the degree of coherence (Sec. 9.2.8).
9.2 Coherence
461

When the phase arg(γ⊥) of the complex visibility (degree of coherence) is zero, there
phase of γ⊥
γ⊥
γ⊥
is a bright fringe precisely on the optic axis. This will be the case for a source that
is symmetric about the optic axis, for example. If the symmetry point of such a
source is gradually moved off the optic axis by an angle δα, the fringe pattern will
shift correspondingly by δθ = δα, which will show up as a corresponding shift in the
argument of the fringe visibility, arg(γ⊥) = kaδα.
The above analysis shows that Young’s slits, even when used virtually, are nicely
suited to measuring both the modulus and the phase of the complex fringe visibility
(the degree of spatial coherence) of the radiation from an extended source.
9.2.3
9.2.3 More General Formulation of Spatial Coherence; Lateral Coherence Length
It is not necessary to project the light onto a screen to determine the contrast and
angular positions of the fringes. For example, if we had measured the ﬁeld at the
locations of the two slits, we could have combined the signals electronically and cross
correlated them numerically to determine what the fringe pattern would be with slits.
AllwearedoingwiththeYoung’sslitsissamplingthewaveﬁeldattwodifferentpoints,
which we now label 1 and 2. Observing the fringes corresponds to adding a phase ϕ
(= kaθ) to the ﬁeld at one of the points and then adding the ﬁelds and measuring the
ﬂux ∝|ψ1 + ψ2eiϕ|2 averaged over many periods. Now, since the source is far away,
the rms value of the wave ﬁeld will be the same at the two slits: |ψ1|2 = |ψ2|2 ≡|ψ|2.
We can therefore express this time-averaged ﬂux in the symmetric-looking form
F(ϕ) ∝(ψ1 + ψ2eiϕ)(ψ∗
1 + ψ∗
2e−iϕ)
∝1 + ℜ
*
ψ1ψ∗
2
|ψ|2 e−iϕ
+
.
(9.9)
Here a bar denotes an average over times long compared to the coherence times for
degree of spatial
coherence
ψ1 and ψ2. Comparing with Eq. (9.6a) and using ϕ = kaθ, we identify
γ⊥12 = ψ1ψ∗
2
|ψ|2
(9.10)
as the degree of spatial coherence in the radiation ﬁeld between the two points 1 and 2.
Equation(9.10)isthegeneraldeﬁnitionofdegreeofspatialcoherence.Equation(9.6a)
is the special case for points separated by a lateral distance a.
If the radiation ﬁeld is strongly correlated between the two points, we describe it
as having strong spatial or lateral coherence. Correspondingly, we shall deﬁne a ﬁeld’s
spatial or lateral coherence
length
lateral coherence length l⊥as the linear size of a region over which the ﬁeld is strongly
correlated (has V = |γ⊥| ∼1). If the angle subtended by the source is ∼δα, then by
virtue of the van Cittert-Zernike theorem [Eqs. (9.7)] and the usual reciprocal relation
for Fourier transforms, the radiation ﬁeld’s lateral coherence length will be
462
Chapter 9. Interference and Coherence

l⊥∼2π
k δα = λ
δα .
(9.11)
This relation has a simple physical interpretation. Consider two beams of radiation
coming from opposite sides of the brightest portion of the source. These beams are
separated by the incoming angle δα. As one moves laterally in the plane of the Young’s
slits, one sees a varying relative phase delay between these two beams. The coherence
length l⊥is the distance over which the variations in that relative phase delay are of
order 2π: k δα l⊥∼2π.
9.2.4
9.2.4 Generalization to 2 Dimensions
We have so far just considered a 1-dimensional intensity distribution I(α) observed
through the familiar Young’s slits. However, most sources will be 2-dimensional, so
to investigate the full radiation pattern, we should allow the waves to come from 2-
dimensional angular directions α:
! = ei(kz−ωot)

ψ(α, t)eikα.xd2α ≡ei(kz−ωot)ψ(x, t)
(9.12a)
[where ψ(α, t) is slowly varying in time], and we should use several pairs of slits
aligned along different directions. Stated more generally, we should sample the wave
ﬁeld (9.12a) at a variety of points separated by a variety of 2-dimensional vectors a
transverse to the direction of wave propagation. The complex visibility (degree of
spatial coherence) will then be a function of ka,
complex visibility,
or degree of spatial
coherence
γ⊥(ka) = ψ(x, t)ψ∗(x + a, t)
|ψ|2
,
(9.12b)
and the van Cittert-Zernike theorem (9.7) will take the 2-dimensional form
γ⊥(ka) =

dαI(α)eika.α
FS
,
(9.13a)
2-dimensional van Cittert-
Zernike theorem
I(α) = FS
 d2(ka)
(2π)2 γ⊥(ka)e−ika.α.
(9.13b)
Here I(α) ∝|ψ(α, t)|2 is the source’s intensity (energy per unit time crossing a unit
area from a unit solid angle dα); FS =

dαI(α) is the source’s total energy ﬂux;
and d2(ka) = k2da is a (dimensionless) surface area element in the lateral plane.
EXERCISES
Exercise 9.2 Problem: Lateral Coherence of Solar Radiation
How closely separated must a pair of Young’s slits be to see strong fringes from the
Sun (angular diameter ∼0.5◦) at visual wavelengths? Suppose that this condition is
9.2 Coherence
463

just satisﬁed, and the slits are 10 μm in width. Roughly how many fringes would you
expect to see?
Exercise 9.3 Problem: Degree of Coherence for a Source
with Gaussian Intensity Distribution
A circularly symmetric light source has an intensity distribution I(α) =
I0 exp[−α2/(2α2
0)], where α is the angular radius measured from the optic axis. Com-
pute the degree of spatial coherence. What is the lateral coherence length? What
happens to the degree of spatial coherence and the interference fringe pattern if the
source is displaced from the optic axis?
9.2.5
9.2.5 Michelson Stellar Interferometer; Astronomical Seeing
The classic implementation of Young’s slits for measuring spatial coherence is Michel-
son’s stellar interferometer, which Albert Michelson and Francis Pease (1921) used
for measuring the angular diameters of Betelgeuse and several other bright stars in
1920.4 The starlight was sampled at two small mirrors separated by a variable distance
a ≤6 m and was then reﬂected into the 100-inch (2.5-m) telescope on Mount Wil-
son, California, to form interference fringes (Fig. 9.2). (As we have emphasized, the
way in which the fringes are formed is unimportant; all that matters is the two loca-
tions where the light is sampled, i.e., the ﬁrst two mirrors in Fig. 9.2.) As Michelson
and Pease increased the separation a between the mirrors, the fringe visibility V de-
creased. Michelson and Pease modeled Betelgeuse (rather badly, in fact) as a circular
disk of uniform brightness, I(α) = 1 for |α| < αr and 0 for |α| > αr, so its visibility
was given, according to Eq. (9.13a), as
V = γ⊥= 2 jinc(kaαr)
(9.14)
where αr is the star’s true angular radius, and jinc(ξ) = J1(ξ)/ξ. They identiﬁed the
separation a ≃3 m, where the fringes disappeared, with the ﬁrst zero of the function
jinc(kaαr). From this and the mean wavelength λ = 575 nm of the starlight, they
inferred that the angular radius of Betelgeuse is αr ∼0.02 arcsec, which at Betelgeuse’s
then-estimated distance of 60 pc (180 light-years) corresponds to a physical radius
∼300 times larger than that of the Sun. The modern parallax-measured distance is
200 pc, so Betelgeuse’s physical radius is actually ∼1,000 times larger than the Sun.
This technique only works for big, bright stars and is very difﬁcult to use, because
turbulence in Earth’s atmosphere causes the fringes to keep moving around; see
Box 9.2 and Ex. 9.4 for details.
4.
Similar principles are relevant to imaging by Earth-observing satellites where one looks down, not up.
In this case, there is the important distinction that most of the diffraction happens relatively close to the
source, not the detector.
464
Chapter 9. Interference and Coherence

fringes
a
FIGURE 9.2 Schematic illustration of a Michelson stellar interferometer.
EXERCISES
Exercise 9.4 Example and Derivation: Time-Averaged Visibility and Image
for a Distant Star Seen through Earth’s Turbulent Atmosphere
Fill in the details of the analysis of time-averaged seeing in Box 9.2. More speciﬁcally,
do the following. If you have difﬁculty, Roddier (1981) may be helpful.
(a) Give an order-of-magnitude derivation of Eq. (4a) in Box 9.2 for the mean-square
phase ﬂuctuation of light induced by propagation through a thin, turbulent layer
of atmosphere. [Hint: Consider turbulent cells of size a, each of which produces
some δϕ, and argue that the contributions add up as a random walk.]
(b) Deduce the factor 2.91 in Eq. (4a) in Box 9.2 by evaluating
Dδϕ = k2
<; z+δh
z
[δn(x + a, z, t) −δn(x, z, t)]dz
=2>
.
(c) Derive Eq. (4b) in Box 9.2 for the time-averaged complex visibility after propagat-
ingthroughthethinlayer.[Hint:Becauseζ ≡δϕ(x, t) −δϕ(x + a, t)istheresult
of contributions from a huge number of independent turbulent cells, the central
limit theorem (Sec. 6.3.2) suggests it is a Gaussian random variable though, in
fact intermittency (Sec. 15.3) can make it rather non-Gaussian. Idealizing it as
Gaussian, evaluate γ⊥= ⟨eiζ⟩= ⟨
 ∞
−∞p(ζ)eiζ dζ⟩with p(ζ) the Gaussian dis-
tribution.]
(d) Use the point-spread function (8.28) for free propagation of the light ﬁeld ψ
to show that, under free propagation, the complex visibility γ⊥(a, z, t) =
⟨ψ(x + a, z, t)ψ∗(x, z, t)⟩(with averaging over x and t) is constant (i.e., in-
dependent of height z).
(e) By combining parts c and d, deduce Eqs. (5) in Box 9.2 for the mean-square phase
ﬂuctuations and spacetime-averaged visibility on the ground.
(f) Perform a numerical Fourier transform of ¯γ⊥(a) [Eq. (5b) in Box 9.2] to get
the time-averaged intensity distribution I(α). Construct a log-log plot of it, and
compare with panel b of the ﬁrst ﬁgure in Box 9.2. What is ro for the observational
data shown in that ﬁgure?
9.2 Coherence
465

BOX 9.2.
ASTRONOMICAL SEEING, SPECKLE IMAGE
PROCESSING, AND ADAPTIVE OPTICS
When light from a star passes through turbulent layers of Earth’s atmosphere,
the turbulently varying index of refraction n(x, t) diffracts the light in a
random, time varying way. One result is “twinkling” (ﬂuctuations in the ﬂux
observed by eye on the ground, with ﬂuctuational frequencies fo ∼100 Hz).
Another is astronomical seeing: the production of many images of the star
(i.e., speckles) as seen through a large optical telescope (panel a of the box
ﬁgure), with the image pattern ﬂuctuating at ∼100 Hz.
Here and in Ex. 9.4 we quantify astronomical seeing using the theory of
2-dimensional lateral coherence. We do this not because seeing is important
(though it is), but rather because our analysis provides an excellent illustration
of three fundamental concepts working together: (i) turbulence in ﬂuids and
its Kolmogorov spectrum (Chap. 15), (ii) random processes (Chap. 6), and
(iii) coherence of light (this chapter).
We begin by deriving, for a star with arbitrarily small angular diameter,
the time-averaged complex visibility γ⊥observed on the ground and the
visibility’s Fourier transform [the observed intensity distribution averaged
0
5
10
15
0
–2
–4
–6
1/3
1/100
1/10
1
1
3
α (arcsec)
α (arcmin)
(b)
(a)
log I
magnitude  arcsec–2
10
30
1"
(a) Picture of a bright star with a dimmer companion star, as seen through the Russian
6-m telescope in the Caucasus Mountains, in an exposure shorter than 10 ms. Atmospheric
turbulence creates a large number of images of each star (speckles) spread over a region with
angular diameter of order 2 arcsec. (b) The theory discussed in the text and in Ex. 9.4 predicts
the solid curve for the time-averaged intensity distribution for a single bright star. Notice the
logarithmic axes. The dotted curve is an estimate of the inﬂuence of the small-scale cutoff of
the turbulence, and the dashed curve is a Gaussian. The circles are observational data. Panel
(a), Gerd Weigelt; panel (b), adapted from Roddier (1981).
(continued)
466
Chapter 9. Interference and Coherence

BOX 9.2.
(continued)
over the speckles, ¯I(α)]. Then we brieﬂy discuss the temporally ﬂuctuating
speckle pattern and techniques for extracting information from it.
TIME-AVERAGED VISIBILITY AND ANGULAR DISTRIBUTION OF INTENSITY
When analyzing light propagation through a turbulent atmosphere, it is
convenient to describe the turbulent ﬂuctuations of the index of refraction by
their spatial correlation function Cn(ξ) ≡⟨δn(X, t)δn(X + ξ, t)⟩(discussed
in Sec. 6.4.1); or, better yet, by n’s mean-square ﬂuctuation on the lengthscale ξ,
Dn(ξ) ≡⟨[δn(X + ξ, t) −δn(X, t)]2⟩= 2[σ 2n −Cn(ξ)],
(1)
which is called n’s structure function. Here δn is the perturbation of the index
of refraction, X is location in 3-dimensional space, t is time, ⟨.⟩denotes a
spacetime average, and σ 2n ≡⟨δn2⟩= Cn(0) is the variance of the ﬂuctuations.
In Sec. 15.4.4, we show that, for strong and isotropic turbulence, Dn
has the functional form Dn ∝ξ2/3 (where ξ ≡|ξ|), with a multiplicative
coefﬁcient d2n that characterizes the strength of the perturbations:
Dn(ξ) = d2nξ2/3
(2)
[Eq. (15.29)]. The 2/3 power is called the Kolmogorov spectrum for the
turbulence.
When light from a very distant star (a point source), directly overhead
for simplicity, reaches Earth’s atmosphere, its phase fronts lie in horizontal
planes, so the frequency ω component of the electric ﬁeld is ψ = eikz, where z
increases downward. (Here we have factored out the ﬁeld’s overall amplitude.)
When propagating through a thin layer of turbulent atmosphere of thickness
δh, the light acquires the phase ﬂuctuation
δϕ(x, t) = k
 z+δh
z
δn(x, z, t)dz.
(3)
Here x is the transverse (i.e., horizontal) location, and Eq. (3) follows from
dϕ = kdz, with k = (n/c)ω and n ≃1.
In Ex. 9.4, we derive some spacetime-averaged consequences of the phase
ﬂuctuations (3):
1. When the light emerges from the thin, turbulent layer, it has acquired
a mean-square phase ﬂuctuation on transverse lengthscale a given by
Dδϕ(a) ≡⟨[δϕ(x + a, t) −δϕ(x, t)]2⟩= 2.91 d2n δh k2a5/3 (4a)
(continued)
9.2 Coherence
467

BOX 9.2.
(continued)
[Eq. (2)], and a spacetime-averaged complex visibility given by
¯γ⊥(a) = ⟨ψ(x, t)ψ∗(x + a, t)⟩= ⟨exp {i [δϕ(x, t) −δϕ(x + a, t)]}⟩
= exp

−1
2Dδϕ(a)

= exp

−1.455 d2n δhk2a5/3
.
(4b)
2. Free propagation (including free-propagator diffraction effects,
which are important for long-distance propagation) preserves the
spacetime-averaged complex visibility: d ¯γ⊥/dz = 0.
3. Therefore, not surprisingly, when the turbulence is spread out
vertically in some arbitrary manner, the net mean-square phase shift
and time-averaged complex visibility observed on the ground are
Dϕ(a) = 2.91
"
d2n(z)dz
#
k2a5/3, and ¯γ⊥(a) = exp
"
−1
2Dϕ(a)
#
.
It is conventional to introduce a transverse lengthscale
ro ≡

0.423k2

d2n(z)dz
−3/5
called the Fried parameter, in terms of which Dϕ and ¯γ⊥are
Dϕ(a) = 6.88(a/ro)5/3,
(5a)
¯γ⊥(a) = exp

−1
2Dϕ(a)

= exp

−3.44(a/ro)5/3
.
(5b)
This remarkably simple result provides opportunities to test the
Kolmogorov power law. For light from a distant star, one can use a large
telescope to measure ¯γ⊥(a) and then plot ln ¯γ⊥as a function of a. Equation
(5b)predictsaslope5/3forthisplot, andobservationsconﬁrmthatprediction.
Notice that the Fried parameter ro is the lengthscale on which the rms
phase ﬂuctuation ϕrms = Dϕ(a = ro) is
√
6.88 = 2.62 radians: ro is the
transverse lengthscale beyond which the turbulence-induced phase ﬂuctu-
ations are large compared to unity. These large random phase ﬂuctuations
drive ¯γ⊥rapidly toward zero with increasing distance a [Eq. (5b)], that is, they
cause the light ﬁeld to become spatially decorrelated with itself for distances
a >∼ro. Therefore, ro is (approximately) the time-averaged light ﬁeld’s spatial
correlation length on the ground. Moreover, since ¯γ⊥is preserved under
free propagation from the turbulent region to the ground, ro must be the
transverse correlation length of the light as it exits the turbulent region that
(continued)
468
Chapter 9. Interference and Coherence

BOX 9.2.
(continued)
produces the seeing. A correlated region with transverse size ro is called an
isoplanatic patch.
The observed time-averaged intensity ¯I(α) from the point-source star
is the Fourier transform of the complex visibility (5b); see Eq. (9.13b). This
transform cannot be performed analytically, but a numerical computation
gives the solid curve in panel b of the ﬁgure above, which agrees remarkably
well with observations out to ∼10−4 of the central intensity, where the
Kolmogorov power law is expected to break down. Notice that the intensity
distribution has a large-radius tail with far larger intensity than a Gaussian
distribution (the dashed curve). This large-radius light is produced by large-
angle diffraction, which is caused by very small-spatial-scale ﬂuctuations
(eddies) in the index of refraction.
Astronomers attribute to this time-averaged I(α) a full width at half
maximum (FWHM) angular diameter αFWHM
Kol
= 0.98λ/ro (Ex. 9.4). For blue
light in very good seeing conditions, ro is about 20 cm and αFWHM
Kol
is about
0.5 arcsec. Much more common is ro ∼10 cm and αFWHM
Kol
∼1 arcsec.
SPECKLE PATTERN AND ITS INFORMATION
The speckle pattern seen on short timescales, <∼1/fo ∼0.01 s, can be un-
derstood in terms of the turbulence’s isoplanatic patches (see the drawing
below). When the light ﬁeld exits the turbulent region, at a height h <∼1 km,
the isoplanatic patches on its wavefronts, with transverse size ro, are planar
to within roughly a reduced wavelength -λ = 1/k = λ/(2π) (since the rms
phase variation across a patch is just 2.62 radians). Each patch carries an
image of the star, or whatever other object the astronomer is observing. The
patch’s light rays make an angle θ <∼αFWHM
Kol
= 0.98λ/ro to the vertical. The
patch’s Fresnel length from the ground is rF =
√
λh <∼2 cm (since λ ∼0.5 μm
and h <∼1km). This is signiﬁcantly smaller than the patch size ro ∼10 to 20
cm; so there is little diffraction in the trip to ground. When these patches reach
patch
patch
patch
patch
ground
h
wavefront
θ
ro
(continued)
9.2 Coherence
469

BOX 9.2.
(continued)
a large telescope (one with diameter D ≫ro), each is focused to produce an
image of the object centered on the angular position θ of its rays (dotted lines
in the drawing). These images are the speckles seen in panel a of the ﬁrst box
ﬁgure.
The speckle pattern varies rapidly, because winds at high altitude sweep the
isoplanatic patches through the star’s light rays. For a wind speed u ∼20 m s−1,
the frequency of the pattern’s ﬂuctuations is fo ∼u/ro ∼100 Hz, in agreement
with observations.
To study the speckles and extract information about the object’s above-
atmosphere intensity distribution Io(α), one must observe them on timescales
<∼1/fo ∼10 ms. The ﬁrst observations of this sort were the measurements
of a few stellar diameters by Michelson and Pease, using the Michelson
stellar interferometer (Sec. 9.2.7). The fringes they saw were produced by the
speckles, and because the phase of each speckle’s fringes was random, the
many speckles contributed incoherently to produce a far smaller net fringe
visibility V than in the absence of atmospheric turbulence. Moreover, because
the speckle pattern varied at fo ∼100 Hz, the net visibility and its phase also
varied at fo ∼100 Hz. Fortunately, the human eye can discern things that
vary this fast, so Michelson and Pease were able to see the fringes.
In the modern era of CCDs, fast electronics, and powerful computers, a
variety of more sophisticated techniques have been devised and implemented
for observing these speckles and extracting their information. Two common
techniques are speckle-image processing and adaptive optics.
In speckle image processing, which is really only usable for bright sources,
one makes optical measurements of the speckle pattern (sometimes with
multi-pinhole masks) on timescales <∼0.01 s for which the speckles are
unchanging. One then uses optical or computational techniques to construct
fourth-order or sixth-order correlations of the light ﬁeld, for example,

γ⊥(a −a′)γ ∗
⊥(a′)d2a′ (which is fourth-order in the ﬁeld), from which a
good approximation to the source’s above-atmosphere intensity distribution
Io(α) can be computed.
In adaptive optics, one focuses not on the speckles themselves, but on
the turbulence-induced distortions of the wavefronts arriving at the large
telescope’s mirror. The simplest implementation uses natural guide stars to act
as point sources. Unfortunately the incidence of sufﬁciently bright stars only
allows a small fraction of the sky to be examined using this technique.
(continued)
470
Chapter 9. Interference and Coherence

BOX 9.2.
(continued)
Therefore, laser guide stars are created by shining collimated laser light
close to the direction of the astronomical sources under study. The laser light
generates the guide star via either Rayleigh scattering by molecules at modest
altitude (∼20 km) or resonant scattering from a layer of sodium atoms at
high altitude (∼90 km).
The guide star must be within an angular distance <∼ro/h ∼3 arcsec of
the astronomical object one is observing (where h ∼10 km is the height of
the highest turbulent layers that contribute signiﬁcantly to the seeing). This
<∼3 arcsec separation guarantees that light rays arriving at the same spot on
the telescope mirror from the object and from the artiﬁcial star will have
traversed the same isoplanatic patches of turbulent atmosphere and thus
have experienced the same phase delay and acquired the same wavefront
distortions. One measures the wavefront distortions of the artiﬁcial star’s light
and dynamically reshapes the telescope mirror so as to compensate for them.
This removes the distortions not only from the artiﬁcial star’s wavefronts
but also from the astronomical object’s wavefronts. Thereby one converts the
speckle pattern into the object’s true intensity distribution Io(α).
Two recent successes of adaptive optics are to observe the stars orbiting the
massive black hole in our galactic center and thereby measure its mass (Ghez
et al., 2008; Genzel, Eisenhauer, and Gillessen, 2010); and to image exoplanets
directly by masking out the light—typically millions of times brighter than
the planet—from the stars that they orbit (Macintosh et al., 2014).
The techniques described here also ﬁnd application to the propagation
of radio waves through the turbulent interplanetary and interstellar media.
The refractive index is due to the presence of free electrons in a plasma (see
Sec. 21.4.1). Interestingly, this turbulence is commonly characterized by a
Kolmogorov spectrum, though the presence of a magnetic ﬁeld makes it
anisotropic.
These techniques are also starting to ﬁnd application in ophthalmology
and industry.
(g) Reexpress the turbulence-broadened image’s FWHM as αFWHM
Kol
= 0.98λ/ro.
Show that the Airy intensity distribution for light for a circular aperture of diam-
eter D [Eq. (8.18)] has FWHM αFWHM
Airy
= 1.03λ/D.
(h) The fact that the coefﬁcients in these two expressions for αFWHM are both close to
unity implies that when the diameter D <∼ro, the seeing is determined by the tele-
scope. Conversely, when D >∼ro (which is true for essentially all ground-based
9.2 Coherence
471

research optical telescopes), it is the atmosphere that determines the image qual-
ity. Large telescopes act only as “light buckets,” unless some additional correctives
are applied, such as speckle image processing or adaptive optics (Box 9.2). A com-
mon measure of the performance of a telescope with or without this correction is
the Strehl ratio, S, which is the ratio of the peak intensity in the actual image of a
point source on the telescope’s optic axis to the peak intensity in the Airy disk for
the telescope’s aperture. Show that without correction, S = 1.00(ro/D)2. Modern
adaptive optics systems on large telescopes can achieve S ∼0.5.
9.2.6
9.2.6 Temporal Coherence
In addition to the degree of spatial (or lateral) coherence, which measures the correla-
tion of the ﬁeld transverse to the direction of wave propagation, we can also measure
the degree of temporal coherence, also called the degree of longitudinal coherence. This
describes the correlation at a given time at two points separated by a distance s along
the direction of propagation. Equivalently, it measures the ﬁeld sampled at a ﬁxed
position at two times differing by τ = s/c. When (as in our discussion of spatial co-
herence) the waves are nearly monochromatic so the ﬁeld arriving at the ﬁxed position
has the form ! = ψ(t)e−iωot, then the degree of temporal coherence is complex and
has a form completely analogous to the transverse case [Eq. (9.12b)]:
degree of temporal or
longitudinal coherence
for nearly monochromatic
radiation
γ∥(τ) = ψ(t)ψ∗(t + τ)
|ψ|2
for nearly monochromatic radiation.
(9.15)
Here the average is over sufﬁciently long times t for the averaged value to settle down
to an unchanging value.
When studying temporal coherence, one often wishes to deal with waves that
contain a wide range of frequencies—such as the nearly Planckian (blackbody) cosmic
microwave radiation emerging from the very early universe (Ex. 9.6). In this case, one
should not factor any e−iωot out of the ﬁeld !, and one gains nothing by regarding
!(t) as complex, so the temporal coherence
degree of temporal
coherence for broadband
radiation
γ∥(τ) = !(t)!(t + τ)
!2
for real ! and broadband radiation
(9.16)
is also real. We use this real γ∥throughout this subsection and the next. It obviously
is the correlation function of ! [Eq. (6.19)] renormalized so γ∥(0) = 1.
As τ is increased, γ∥typically remains near unity until some critical value τc is
reached, and then it begins to fall off toward zero. The critical value τc, the longest
time over which the ﬁeld is strongly coherent, is the coherence time, of which we have
already spoken: If the wave is roughly monochromatic, so !(t) ∝cos[ωot + δϕ(t)],
with ωo ﬁxed and the phase δϕ randomly varying in time, then it should be clear that
472
Chapter 9. Interference and Coherence

the mean time for δϕ to change by an amount of order unity is the coherence time τc
at which γ∥begins to fall signiﬁcantly.
Theuncertaintyprincipledictatesthataﬁeldwithcoherencetimeτc, whenFourier
analyzed in time, must contain signiﬁcant power over a bandwidth f = ω/(2π) ∼
1/τc. Correspondingly, if we deﬁne the ﬁeld’s longitudinal coherence length by
longitudinal coherence
length
l∥≡cτc,
(9.17)
then l∥for broadband radiation will be only a few times the peak wavelength, but for
a narrow spectral line of width λ, it will be λ2/λ.
These relations between the coherence time or longitudinal coherence length
and the ﬁeld’s spectral energy ﬂux are order-of-magnitude consequences not only
of the uncertainty relation, but also of the temporal analog of the van Cittert-Zernike
theorem. That analog is just the Wiener-Khintchine theorem in disguise, and it can
be derived by the same methods as we used in the transverse spatial domain. In that
theorem the degree of lateral coherence γ⊥is replaced by the degree of temporal
coherence γ∥, and the angular intensity distribution I(α) (distribution of energy over
spectrum or spectral
energy ﬂux Fω(ω)
Fω(ω)
Fω(ω)
angle) is replaced by the ﬁeld’s spectral energy ﬂux Fω(ω) (the energy crossing a
unit area per unit time and per unit angular frequency ω)—which is also called its
spectrum.5 The theorem takes the explicit form
temporal analog of van
Cittert-Zernike theorem
γ∥(τ) =
 ∞
−∞dωFω(ω)eiωτ
FS
= 2
 ∞
0
dωFω(ω) cos ωτ
FS
for real !(t), valid for broadband radiation
(9.18a)
and
Fω(ω) = FS
 ∞
−∞
dτ
2π γ∥(τ)e−iωτ = 2FS
 ∞
0
dτ
2π γ∥(τ) cos ωτ.
(9.18b)
[Here the normalization of our Fourier transform and the sign of its exponential
are those conventionally used in optics, and differ from those used in the theory of
random processes (Chap. 6). Also, because we have chosen ! to be real, Fω(−ω) =
Fω(+ω) and γ∥(−τ) = γ∥(+τ).] One can measure γ∥by combining the radiation
from two points displaced longitudinally to produce interference fringes just as we
did when measuring spatial coherence. This type of interference is sometimes called
interference by division of
the amplitude
interference by division of the amplitude, in contrast with “interference by division of
the wavefront” for a Young’s-slit-type measurement of lateral spatial coherence (next-
to-last paragraph of Sec. 9.2.1).
5.
Note that the spectral energy ﬂux (spectrum) is simply related to the spectral density of the ﬁeld:
if the ﬁeld ! is so normalized that the energy density is U = β !,t!,t with β some constant, then
Fω(ω) = βcω2/(2π)S!(f ), with f = ω/(2π).
9.2 Coherence
473

EXERCISES
Exercise 9.5 Problem: Longitudinal Coherence of Radio Waves
An FM radio station has a carrier frequency of 91.3 MHz and transmits heavy metal
rock music in frequency-modulated side bands of the carrier. Estimate the coherence
length of the radiation.
9.2.7
9.2.7 Michelson Interferometer and Fourier-Transform Spectroscopy
Michelson interferometer
The classic instrument for measuring the degree of longitudinal coherence is the
Michelson interferometer of Fig. 9.3 (not to be confused with the Michelson stellar
interferometer). In the simplest version, incident light (e.g., in the form of a Gaussian
beam; Sec. 8.5.5) is split by a beam splitter into two beams, which are reﬂected off
different plane mirrors and then recombined. The relative positions of the mirrors
are adjustable so that the two light paths can have slightly different lengths. (An early
version of this instrument was used in the famous Michelson-Morley experiment.)
There are two ways to view the fringes. One way is to tilt one of the reﬂecting
mirrors slightly so there is a range of path lengths in one of the arms. Light and
dark interference bands (fringes) can then be seen across the circular cross section of
the recombined beam. The second method is conceptually more direct but requires
aligning the mirrors sufﬁciently accurately so the phase fronts of the two beams
are parallel after recombination and the recombined beam has no banded structure.
The end mirror in one arm of the interferometer is then slowly moved backward or
forward, and as it moves, the recombined light slowly changes from dark to light to
dark and so on.
It is interesting to interpret this second method in terms of the Doppler shift. One
beam of light undergoes a Doppler shift on reﬂection off the moving mirror. There is
then a beat wave produced when it is recombined with the unshifted radiation of the
other beam.
Whichever method is used (tilted mirror or longitudinal motion of mirror), the
visibility γ|| of the interference fringes measures the beam’s degree of longitudinal
coherence, which is related to the spectral energy ﬂux (spectrum) Fω by Eqs. (9.18).
Let us give an example. Suppose we observe a spectral line with rest angular
frequency ω0 that is broadened by random thermal motions of the emitting atoms.
Then the line proﬁle is
Fω ∝exp

−(ω0 −ω)2
2(ω)2

.
(9.19a)
The width of the line is given by the formula for the Doppler shift,
ω ∼ω0[kBT /(mc2)]1/2,
where T is the temperature of the emitting atoms, and m is their mass. (We ignore
other sources of line broadening, e.g., natural broadening and pressure broadening,
474
Chapter 9. Interference and Coherence

light source
interference
fringes
beam splitter
FIGURE 9.3 Michelson interferometer.
which actually dominate under normal conditions.) For example, for hydrogen at
T = 103 K, the Doppler-broadened line width is ω ∼10−5ω0.
By Fourier transforming this line proﬁle, using the well-known result that the
Fourier transform of a Gaussian is another Gaussian and invoking the fundamental
relations (9.18) between the spectrum and temporal coherence, we obtain
γ∥(τ) = exp

−τ 2(ω)2
2

cos ω0τ.
(9.19b)
If we had used the nearly monochromatic formalism with the ﬁeld written as
! = ψ(t)e−iω0t, then we would have obtained
γ∥(τ) = exp

−τ 2(ω)2
2

eiω0τ ,
(9.19c)
the real part of which is our broadband formalism’s γ∥. In either case, γ∥oscillates with
angular frequency ω0, and the amplitude of this oscillation is the fringe visibility V :
fringe visibility
V = exp

−τ 2(ω)2
2

.
(9.19d)
The variation V (τ) of this visibility with lag time τ is sometimes called an interfero-
interferogram
gram. For time lags τ ≪(ω)−1, the line appears to be monochromatic, and fringes
with unit visibility should be seen. However, for lags τ >∼(ω)−1, the fringe visibility
will decrease exponentially with increasing τ 2. In our Doppler-broadened hydrogen-
line example with ω ∼10−5ω0, the rest angular frequency is ω0 ∼3 × 1015 rad s−1,
so the longitudinal coherence length is l∥= cτc ∼10 mm. No fringes will be seen
when the radiation is combined from points separated by much more than this dis-
tance.
This procedure is an example of Fourier transform spectroscopy, in which, by
measuring the degree of temporal coherence γ∥(τ) and then Fourier transforming
Fourier transform
spectroscopy
9.2 Coherence
475

it [Eq. (9.18)], one infers the shape of the radiation’s spectrum, or in this case, the
width of a speciﬁc spectral line.
When (as in Ex. 9.6) the waves are very broad band, the degree of longitudinal
coherence γ∥(τ) will not have the form of a sinusoidal oscillation (regular fringes)
with slowly varying amplitude (visibility). Nevertheless, the broadband van Cittert-
Zernike theorem [Eqs. (9.18)] still guarantees that the spectrum (spectral energy ﬂux)
will be the Fourier transform of the coherence γ∥(τ), which can be measured by a
Michelson interferometer.
EXERCISES
Exercise 9.6 Problem: COBE Measurement of the Cosmic Microwave
Background Radiation
An example of a Michelson interferometer is the Far Infrared Absolute Spectro-
photometer (FIRAS) carried by the Cosmic Background Explorer satellite (COBE).
COBE studied the spectrum and anisotropies of the cosmic microwave background
radiation (CMB) that emerged from the very early, hot phase of our universe’s ex-
pansion (Sec. 28.3.3). One of the goals of the COBE mission was to see whether the
CMB spectrum really has the shape of 2.7 K blackbody (Planckian) radiation, or if
it is highly distorted, as some measurements made on rocket ﬂights had suggested.
COBE’s spectrophotometer used Fourier transform spectroscopy to meet this goal:
it compared accurately the degree of longitudinal coherence γ∥of the CMB radia-
tion with that of a calibrated source on board the spacecraft, which was known to
be a blackbody at about 2.7 K. The comparison was made by alternately feeding ra-
diation from the microwave background and radiation from the calibrated source
into the same Michelson interferometer and comparing their fringe spacings. The
result (Mather et al., 1994) was that the background radiation has a spectrum that is
Planckian with temperature 2.726 ± 0.010 K over the wavelength range 0.5–5.0 mm,
in agreement with simple cosmological theory that we shall explore in the last chapter
of this book.
(a) Suppose that the CMB had had a Wien spectrum
Fω ∝ω3 exp[−ℏω/(kBT )].
Show that the visibility of the fringes would have been
V = |γ∥| ∝|s4 −6s2
0s2 + s4
0|
(s2 + s2
0)4
(9.20)
where s = cτ is longitudinal distance, and calculate a numerical value for s0.
(b) Compute the interferogram V (τ) for a Planck function either analytically (per-
haps with the help of a computer) or numerically using a fast Fourier transform.
Compare graphically the interferogram for the Wien and Planck spectra.
476
Chapter 9. Interference and Coherence

9.2.8
9.2.8 Degree of Coherence; Relation to Theory of Random Processes
full (3-dimensional)
degree of coherence
Having separately discussed spatial and temporal coherence, we now can easily per-
form a ﬁnal generalization and deﬁne the full degree of coherence of the radiation
ﬁeld between two points separated both laterally by a vector a and longitudinally by
a distance s (or equivalently, by a time τ = s/c). If we restrict ourselves to nearly
monochromatic waves and use the complex formalism so the waves are written as
! = ei(kz−ωot)ψ(x, t) [Eq. (9.12a)], then we have
γ12(ka, τ) ≡
ψ(x1, t)ψ∗(x1 + a, t + τ)

|ψ(x1, t)|2 |ψ(x1 + a, t)|2
1/2 = ψ(x1, t)ψ∗(x1 + a, t + τ)
|ψ|2
.
(9.21)
In the denominator of the second expression we have used the fact that, because the
volume of coherence
source is far away, |ψ|2 is independent of the spatial location at which it is evaluated,
in the region of interest. Consistent with the deﬁnition (9.21), we can deﬁne a volume
of coherence Vc as the product of the longitudinal coherence length l∥= cτc and the
square of the transverse coherence length l2
⊥: Vc = l2
⊥cτc.
The 3-dimensional version of the van Cittert-Zernike theorem relates the complex
speciﬁc intensity
degree of coherence (9.21) to the radiation’s speciﬁc intensity, Iω(α, ω), also called its
spectral intensity (i.e., the energy crossing a unit area per unit time per unit solid angle
and per unit angular frequency, or energy “per unit everything”). (Since the frequency
ν and the angular frequency ω are related by ω = 2πν, the speciﬁc intensity Iω of
this chapter and that Iν of Chap. 3 are related by Iν = 2πIω.) The 3-dimensional van
Cittert-Zernike theorem states that
3-dimensional van Cittert-
Zernike theorem
γ12(ka, τ) =

dαdωIω(α, ω)ei(ka.α+ωτ)
FS
,
(9.22a)
and
Iω(α, ω) = FS
 dτd2ka
(2π)3 γ12(ka, τ)e−i(ka.α+ωτ).
(9.22b)
There obviously must be an intimate relationship between the theory of random
processes, as developed in Chap. 6, and the theory of a wave’s coherence, as we have
developed it in Sec. 9.2. That relationship is explained in Ex. 9.8.
EXERCISES
Exercise 9.7 Problem: Decomposition of Degree of Coherence
We have deﬁned the degree of coherence γ12(a, τ) for two points in the radiation
ﬁeld separated laterally by a distance a and longitudinally by a time τ. Under what
conditions will this be given by the product of the spatial and temporal degrees of
coherence?
γ12(a, τ) = γ⊥(a)γ∥(τ).
(9.23)
9.2 Coherence
477

Exercise 9.8 **Example: Complex Random Processes and the van Cittert-Zernike
Theorem
In Chap. 6 we developed the theory of real-valued random processes that vary ran-
domly with time t (i.e., that are deﬁned on a 1-dimensional space in which t is a
coordinate). Here we generalize a few elements of that theory to a complex-valued
random process (x) deﬁned on a (Euclidean) space with n dimensions. We assume
the process to be stationary and to have vanishing mean (cf. Chap. 6 for deﬁnitions).
For (x) we deﬁne a complex-valued correlation function by
C(ξ) ≡(x)∗(x + ξ)
(9.24a)
(where ∗denotes complex conjugation) and a real-valued spectral density by
S(k) = lim
L→∞
1
Ln| ˜L(k)|2.
(9.24b)
Here L is  conﬁned to a box of side L (i.e., set to zero outside that box), and the
tilde denotes a Fourier transform deﬁned using the conventions of Chap. 6:
˜L(k) =

L(x)e−ik.xdnx,
L(x) =

˜L(k)e+ik.x dnk
(2π)n .
(9.25)
Because  is complex rather than real, C(ξ) is complex; and as we shall see below, its
complexity implies that [although S(k) is real], S(−k) ̸= S(k). This fact prevents
us from folding negative k into positive k and thereby making S(k) into a “single-
sided” spectral density as we did for real random processes in Chap. 6. In this complex
case we must distinguish −k from +k and similarly −ξ from +ξ.
(a) The complex Wiener-Khintchine theorem [analog of Eq. (6.29)] states that
S(k) =

C(ξ)e+ik.ξdnξ ,
(9.26a)
C(ξ) =

S(k)e−ik.ξ dnk
(2π)n .
(9.26b)
Derivetheserelations.[Hint:UseParseval’stheoremintheform

A(x)B∗(x)dnx
=
 ˜A(k) ˜B∗(k)dnk/(2π)n with A(x) = L(x) and B(x) = L(x + ξ), and then
take the limit as L →∞.] Because S(k) is real, this Wiener-Khintchine theo-
rem implies that C(−ξ) = C∗
(ξ). Show that this is so directly from the deﬁni-
tion (9.24a) of C(ξ). Because C(ξ) is complex, the Wiener-Khintchine theorem
implies that S(k) ̸= S(−k).
(b) Let ψ(x, t) be the complex-valued wave ﬁeld deﬁned in Eq. (9.12a), and re-
strict x to range only over the two transverse dimensions so ψ is deﬁned on a
3-dimensional space. Deﬁne (x, t) ≡ψ(x, t)/

|ψ(x, t)|2
1/2
. Show that
C(a, τ) = γ12(ka, τ),
S(−αk, −ω) = const × Iω(α, ω)
FS
,
(9.27)
478
Chapter 9. Interference and Coherence

and that the complex Wiener-Khintchine theorem (9.26) is the van Cittert-
Zernike theorem (9.22). (Note: The minus signs in S result from the differ-
ence in Fourier transform conventions between the theory of random processes
[Eq. (9.25) and Chap. 6] and the theory of optical coherence [this chapter].) Eval-
uate the constant in Eq. (9.27).
9.3
9.3 Radio Telescopes
TheinterferometrytechniquepioneeredbyMichelsonformeasuringtheangularsizes
of stars at visual wavelengths has been applied to great effect in radio astronomy.
A modern radio telescope is a large surface that reﬂects radio waves onto a “feed,”
where the waves’ ﬂuctuating electric ﬁeld creates a tiny electric voltage that subse-
quently can be ampliﬁed and measured electronically. Modern radio telescopes have
diameters D that range from ∼10 m to the ∼300 m of the Arecibo telescope in Puerto
Rico. A typical observing wavelength might be λ ∼6 cm. This implies an angular
resolution θA ∼λ/D ∼2 arcmin(λ/6 cm)(D/100 m)−1 [Eq. (8.18) and subsequent
discussion]. However, many of the most interesting cosmic sources are much smaller
than this. To achieve much better angular resolution, the technique of radio interfer-
radio telescope
interferometry
ometry was pioneered in the 1950s and has been steadily developing since then.6
9.3.1
9.3.1 Two-Element Radio Interferometer
If we have two radio telescopes, then we can think of them as two Young’s slits, and
we can link them using a combination of waveguides and electric cables, as shown in
Fig. 9.4. When they are both pointed at a source, they both measure the electric ﬁeld
in radio waves from that source. We combine their signals by narrowband ﬁltering
their voltages to make them nearly monochromatic and then either adding the ﬁltered
voltages and measuring the power, or multiplying the two voltages directly. In either
case a measurement of the degree of coherence [Eq. (9.10)] can be achieved. [If
the source is not vertically above the two telescopes, one obtains some nonlateral
component of the full degree of coherence γ12(a, τ). However, by introducing a time
delay into one of the signals, as in Fig. 9.4, one can measure the degree of lateral
coherence γ⊥(a), which is what the astronomer usually needs.]
The objective is usually to produce an image of the radio waves’ source. This is
achieved by Fourier inverting the lateral degree of coherence γ⊥(a) [Eq. (9.13b)],
which therefore must be measured for a variety of values of the relative separation
vector a of the telescopes perpendicular to the source’s direction. As Earth rotates,
the separation vector will trace out half an ellipse in the 2-dimensional a plane every
12 hours. [The source intensity is a real quantity, so we can use Eq. (9.13a) to deduce
6.
This type of interferometry is also developing fast at optical wavelengths. This was not possible until
optical technology became good enough to monitor the phase of light as well as its amplitude, at separate
locations, and then produce interference.
9.3 Radio Telescopes
479

delay
a
correlator
telescope and
amplifier
γ?(a)
FIGURE 9.4 Two-element radio interferometer.
that γ⊥(−a) = γ ∗
⊥(a), which gives the other half of the ellipse.] By changing the
spacing between the two telescopes daily and collecting data for a number of days,
the degree of coherence can be well sampled. This technique7 is known as Earth-
aperture synthesis
rotation aperture synthesis, because the telescopes are being made to have the angular
resolution of a giant telescope as big as their maximum separation, with the aid of
Earth’s rotation. They do not, of course, have the sensitivity of this giant telescope.
9.3.2
9.3.2 Multiple-Element Radio Interferometers
In practice, a modern radio interferometer has many more than two telescopes. For
JVLA
example, the Karl G. Jansky Very Large Array (JVLA) in New Mexico (USA) has
27 individual telescopes arranged in a Y pattern and operating simultaneously, with
a maximum baseline of 36 km and a minimum observing wavelength of 7 mm.
The degree of coherence can thus be measured simultaneously over 27 × 26/2 =
351 different relative separations. The results of these measurements can then be
interpolated to give values of γ⊥(a) on a regular grid of points (usually 2N × 2N
for some integer N). This is then suitable for applying the fast Fourier transform
algorithm to infer the source structure I(α).
ALMA
The Atacama Large Millimeter Array (ALMA) being constructed in Chile is al-
ready (2016) operational. It comprises 66 telescopes observing with wavelengths be-
tween 0.3 and 9.6 mm and baselines as long as 16 km. Future ambitions at longer
radio wavelengths are centered on the proposed Square Kilometer Array (SKA) to be
built in South Africa and Australia comprising thousands of dishes with a combined
collecting area of a square kilometer.
7.
For which Martin Ryle was awarded the Nobel Prize.
480
Chapter 9. Interference and Coherence

9.3.3
9.3.3 Closure Phase
Among the many technical complications of interferometry is one that brings out
an interesting point about Fourier methods. It is usually much easier to measure the
modulus than the phase of the complex degree of coherence. This is partly because
phase errors
it is hard to introduce the necessary delays in the electronics accurately enough to
know where the zero of the fringe pattern should be located and partly because
unknown, ﬂuctuating phase delays are introduced into the phase of the ﬁeld as the
wave propagates through the upper atmosphere and ionosphere. [This is a radio
variantoftheproblemof“seeing”foropticaltelescopes(cf.Box9.2), anditalsoplagues
the Michelson stellar interferometer.] It might therefore be thought that we would
have to make do with just the modulus of the degree of coherence (i.e., the fringe
visibility) to perform the Fourier inversion for the source structure. This is not so.
Consider a three-element interferometer measuring ﬁelds ψ1, ψ2, and ψ3, and
suppose that at each telescope there are unknown phase errors, δϕ1, δϕ2, and δϕ3
(Fig. 9.5). For baseline a12, we measure the degree of coherence γ⊥12 ∝ψ1ψ∗
2, a
complex number with phase 12 = ϕ12 + δϕ1 −δϕ2, where ϕ12 is the phase of γ⊥12
in the absence of phase errors. If we also measure the degrees of coherence for the
other two pairs of telescopes in the triangle and derive their phases 23 and 31, we
can then calculate the quantity
C123 = 12 + 23 + 31
= ϕ12 + ϕ23 + ϕ31,
(9.28)
from which the phase errors cancel out.
closure phase
The quantity C123, known as the closure phase, can be measured with high accu-
racy. In the JVLA, there are 27 × 26 × 25/6 = 2,925 such closure phases, and they
can all be measured with considerable redundancy. Although absolute phase infor-
mation cannot be recovered, 93% of the telescopes’ relative phases can be inferred in
this manner and used to construct an image far superior to what could be achieved
without any phase information.
a12
a23
a31
2
3
1δϕ1
δϕ2
δϕ3
FIGURE 9.5 Closure-phase measurement
using a triangle of telescopes.
9.3 Radio Telescopes
481

9.3.4
9.3.4 Angular Resolution
When the telescope spacings are well sampled and the source is bright enough to carry
out these image-processing techniques, an interferometer can have an angular resolv-
ing power approaching that of an equivalent ﬁlled aperture as large as the maximum
telescope spacing. For the JVLA the best angular resolution is 50 milliarcsec and at
ALMA it will be as ﬁne as 4 milliarcsec, thousands of times better than single dishes.
Even greater angular resolution is achieved with a technique known as very long
baseline interferometry (VLBI). Here the telescopes can be located on different con-
tinents and instead of linking them directly, the oscillating ﬁeld amplitudes ψ(t) are
stored electronically. Then they are combined digitally long after the observation to
compute the complex degree of coherence and thence the source structure I(α). In
this way angular resolutions more than 300 times better than those achievable by the
JVLAhavebeenobtained.Structuresmallerthanamilliarcsec, correspondingtoafew
light-years at cosmological distances, can be measured in this manner. A most excit-
ing prospect is to use submillimeter VLBI to resolve marginally the event horizons
of massive black holes, speciﬁcally, the four-million-solar-mass hole at the center of
our galaxy and the six-billion-solar-mass hole at the center of the nearby galaxy M87.
Existing observations by a collaboration called the “event horizon telescope” have al-
ready (2016) measured interference fringes on angular scales ∼5 times larger than
these black holes’ gravitational radii, i.e. ∼10 GM/c2.
EXERCISES
Exercise 9.9 Example: Radio Interferometry from Space
The longest radio-telescope separation available in 2016 is that between telescopes
on Earth’s surface and a 10-m diameter radio telescope in the Russian RadioAstron
satellite, which was launched into a highly elliptical orbit around Earth in summer
2011, with perigee ∼10,000 km (1.6 Earth radii) and apogee ∼350,000 km (55 Earth
radii).
(a) Radio astronomers conventionally describe the speciﬁc intensity Iω(α, ω) of a
source in terms of its brightness temperature. This is the temperature Tb(ω) that
a blackbody would have to emit, in the Rayleigh-Jeans (low-frequency) end of its
spectrum, to produce the same speciﬁc intensity as the source. Show that for a
single (linear or circular) polarization, if the solid angle subtended by a source is
 and the spectral energy ﬂux measured from the source is Fω ≡

Iωd =
Iω, then the brightness temperature is
Tb = (2π)3c2Iω
kBω2
= (2π)3c2Fω
kBω2 ,
(9.29)
where kB is Boltzmann’s constant.
(b) The
brightest
quasars
emit
radio
spectral
ﬂuxes
of
about
Fω =
10−25 W m−2 Hz−1, independent of frequency. The smaller such a quasar is, the
larger will be its brightness temperature. Thus, one can characterize the small-
482
Chapter 9. Interference and Coherence

est sources that a radio-telescope system can resolve by the highest brightness
temperatures it can measure. Show that the maximum brightness temperature
measurable by the Earth-to-orbit RadioAstron interferometer is independent of
the frequency at which the observation is made, and estimate its numerical value.
9.4
9.4 Etalons and Fabry-Perot Interferometers
We have shown how a Michelson interferometer (Fig. 9.3) can be used as a Fourier-
transform spectrometer: one measures the complex fringe visibility as a function of
the two arms’ optical path difference and then takes the visibility’s Fourier transform
to obtain the spectrum of the radiation. The inverse process is also powerful. One
can drive a Michelson interferometer with radiation with a known, steady spectrum
(usually close to monochromatic), and look for time variations of the positions of its
fringes caused by changes in the relative optical path lengths of the interferometer’s
two arms. This was the philosophy of the famous Michelson-Morley experiment to
search for ether drift, and it is also the underlying principle of a laser interferometer
(“interferometric”) gravitational-wave detector.
To reach the sensitivity required for gravitational-wave detection, one must mod-
ify the Michelson interferometer by making the light travel back and forth in each arm
many times, thereby amplifying the phase shift caused by changes in the arm lengths.
This is achieved by converting each arm into a Fabry-Perot interferometer. In this
section, we study Fabry-Perot interferometers and some of their other applications,
and in Sec. 9.5, we explore their use in gravitational-wave detection.
9.4.1
9.4.1 Multiple-Beam Interferometry; Etalons
etalon
Fabry-Perot interferometry is based on trapping monochromatic light between two
highly reﬂecting surfaces. To understand such trapping, let us consider the concrete
situation where the reﬂecting surfaces are ﬂat and parallel to each other, and the trans-
parent medium between the surfaces has one index of refraction n, while the medium
outside the surfaces has another index n′ (Fig. 9.6). Such a device is sometimes called
an etalon. One example is a glass slab in air (n ≃1.5, n′ ≃1); another is a vacuum
maintained between two glass mirrors (n = 1, n′ ≃1.5). For concreteness, we discuss
the slab case, though all our formulas are equally valid for a vacuum between mirrors
or for any other etalon.
Suppose that a monochromatic plane wave (i.e., with parallel rays) with angular
frequency ω is incident on one of the slab’s reﬂecting surfaces, where it is partially re-
ﬂected and partially transmitted with refraction. The transmitted wave will propagate
through to the second surface, where it will be partially reﬂected and partially trans-
mitted. The reﬂected portion will return to the ﬁrst surface, where it too will be split,
and so on (Fig. 9.6a). The resulting total ﬁelds in and outside the slab can be com-
puted by summing the series of sequential reﬂections and transmissions (Ex. 9.12).
Alternatively, they can be computed as follows.
9.4 Etalons and Fabry-Perot Interferometers
483

(a)
(b)
θ
ψr
ψi
ψt
ψb
ψa
n′
n′
n
n′
n′
n
d
FIGURE 9.6 Multiple-beam interferometry using a type of Fabry-Perot etalon.
Assume, for pedagogical simplicity, that there is translational invariance along
the slab (i.e., the slab and incoming wave are perﬂectly planar). Then the series, if
summed, would lead to the ﬁve waves shown in Fig. 9.6b: an incident wave (ψi), a
reﬂected wave (ψr), a transmitted wave (ψt), and two internal waves (ψa and ψb).
amplitude reﬂection and
transmission coefﬁcients
We introduce amplitude reﬂection and transmission coefﬁcients, denoted r and
t, for waves incident on the slab surface from outside. Likewise, we introduce coefﬁ-
cients r′, t′ for waves incident on the slab from inside. These coefﬁcients are functions
of the angles of incidence and the light’s polarization. They can be computed using
electromagnetic theory (e.g., Hecht, 2017, Sec. 4.6.2), but this will not concern us here.
Armed with these deﬁnitions, we can express the reﬂected and transmitted waves
at the ﬁrst surface (location A in Fig. 9.7) in the form
ψr = rψi + t′ψb,
ψa = tψi + r′ψb,
(9.30a)
where ψi, ψa, ψb, and ψr are the values of ψ at A for waves impinging on or leaving
the surface along the paths i, a, b, and r, respectively, depicted in Fig. 9.7. Simple
geometry shows that the waves at the second surface are as depicted in Fig. 9.7.
Correspondingly, the relationships between the ingoing and outgoing waves there are
ψbe−iks1 = r′ψaeik(s1−s2),
ψt = t′ψaeiks1,
(9.30b)
where k = nω/c is the wave number in the slab, and (as is shown in the ﬁgure) s1 and
s2 are deﬁned as
s1 = d sec θ,
s2 = 2d tan θ sin θ,
(9.30c)
with d the thickness of the slab, and θ the angle that the wavefronts inside the slab
make to the slab’s faces.
In solving Eqs. (9.30) for the net transmitted and reﬂected waves ψt and ψr in
terms of the incident wave ψi, we need reciprocity relations between the reﬂection
484
Chapter 9. Interference and Coherence

ψr
ψi
ψt
ψb
ψb e–iks1
ψa eik(s1 – s2)
ψa
i
A
r
s2 = 2d tan θ sin θ
θ
a
a
b
t
d
2d tan θ
s1 = d sec θ
FIGURE 9.7 Construction for calculating the phase differences across
the slab for the two internal waves in an etalon.
and transmission coefﬁcients r and t for waves that hit the reﬂecting surfaces from
one side, and those between r′ and t′ for waves from the other side. These reciprocity
relations are analyzed quite generally in Ex. 9.10. To derive the reciprocity relations
in our case of sharp boundaries between homogeneous media, consider the limit in
which the slab thickness d →0. This is allowed because the wave equation is linear,
and the solution for one surface can be superposed on that for the other surface. In
this limit s1 = s2 = 0 and the slab must become transparent, so
ψr = 0,
ψt = ψi.
(9.31)
Equations (9.30a), (9.30b), and (9.31) are then six homogeneous equations in the ﬁve
wave amplitudes ψi, ψr, ψt, ψa, and ψb, from which we can extract the two desired
reciprocity relations:
reciprocity relations
r′ = −r,
tt′ −rr′ = 1.
(9.32)
Since there is no mechanism to produce a phase shift as the waves propagate across
a perfectly sharp boundary, it is reasonable to expect r, r′, t, and t′ all to be real, as
indeed they are (Ex. 9.10). [If the interface has a ﬁnite thickness, it is possible to adjust
the spatial origins on the two sides of the interface so as to make r, r′, t, and t′ all be
real, leading to the reciprocity relations (9.32), but a price will be paid; see Ex. 9.10.]
Now return to the case of ﬁnite slab thickness. By solving Eqs. (9.30) for the
reﬂectedandtransmittedﬁeldsandinvokingthereciprocityrelations(9.32), weobtain
ψr
ψi
≡re = r(1 −eiϕ)
1 −r2eiϕ ,
ψt
ψi
≡te = (1 −r2)eiϕ/(2 cos2 θ)
1 −r2eiϕ
.
(9.33a)
9.4 Etalons and Fabry-Perot Interferometers
485

Here re and te are the etalon’s reﬂection and transmission coefﬁcients, and ϕ =
k(2s1 −s2), which reduces to
ϕ = 2nωd cos θ/c,
(9.33b)
is the light’s round-trip phase shift (along path a and then b) inside the etalon, relative
to the phase of the incoming light that it meets at location A. If ϕ is a multiple of 2π,
the round-trip light will superpose coherently on the new, incoming light.
We are particularly interested in the reﬂectivity and transmissivity for the energy
ﬂux—the coefﬁcients that tell us what fraction of the total ﬂux (and therefore also the
total power) incident on the etalon is reﬂected by it and what fraction emerges from
its other side:
etalon’s reﬂectivity and
transmissivity
R = |re|2 = |ψr|2
|ψi|2 =
2r2(1 −cos ϕ)
1 −2r2 cos ϕ + r4 ,
T = |te|2 = |ψt|2
|ψi|2 =
(1 −r2)2
1 −2r2 cos ϕ + r4 .
(9.33c)
From these expressions, we see that
energy conservation
R + T = 1,
(9.33d)
which says that the energy ﬂux reﬂected from the slab plus that transmitted is equal
to that impinging on the slab (energy conservation). It is actually the reciprocity
relations (9.32) for the amplitude reﬂection and transmission coefﬁcients that enforce
thisenergyconservation.Iftheyhadcontainedaprovisionforabsorptionorscattering
of light in the interfaces, R + T would have been less than one.
We discuss the etalon’s reﬂectivity and transmissivity, Eq. (9.33c), at length in
Sec. 9.4.2. But ﬁrst, in a set of example exercises, we clarify some important issues
related to the above analysis.
EXERCISES
Exercise 9.10 Example: Reciprocity Relations for a Locally Planar Optical Device
Modern mirrors, etalons, beam splitters, and other optical devices are generally made
of glass or fused silica (quartz) and have dielectric coatings on their surfaces. The
coatings consist of alternating layers of materials with different dielectric constants, so
the index of refraction n varies periodically. If, for example, the period of n’s variations
is half a wavelength of the radiation, then waves reﬂected from successive dielectric
layers build up coherently, producing a large net reﬂection coefﬁcient; the result is a
highly reﬂecting mirror.
Inthisexercise, weuseamethodduetoStokestoderivethereciprocityrelationsfor
devices with dielectric coatings, and in fact for much more general devices. Specif-
ically, our derivation will be valid for locally plane-fronted, monochromatic waves
486
Chapter 9. Interference and Coherence

ψi eiki¢x
z
(a)
(b)
r ψi eikr¢x
t ψi eikt¢x′
ψi* e–iki¢x
r* ψi* e–ikr¢x
t* ψi* e–ikt¢x′
FIGURE 9.8 Construction for deriving reciprocity relations for amplitude transmission and
reﬂection coefﬁcients.
impinging on an arbitrary, locally planar, lossless optical device.8 The device could be
a mirror, a surface with an antireﬂection coating (Ex. 9.13 below), an etalon, or any
sequence of such objects with locally parallel surfaces.
Letaplane, monochromaticwaveψieiki.xe−iωt impingeontheopticaldevicefrom
above, and orient the device so its normal is in the z direction and it is translation
invariant in the x and y directions; see Fig. 9.8a. Then the reﬂected and transmitted
waves are as shown in the ﬁgure. Because the medium below the device can have a
different index of refraction from that above, the waves’ propagation direction below
may be different from that above, as shown. For reasons explained in part (e), we
denote position below the device by x′ and position above the device by x. Some
arbitrary choice has been made for the locations of the vertical origins z = 0and z′ = 0
on the two sides of the device.
(a) Consider a thought experiment in which the waves of Fig. 9.8a are time-reversed,
so they impinge on the device from the original reﬂection and transmission di-
rections and emerge toward the original input direction, as shown in Fig. 9.8b.
If the device had been lossy, the time-reversed waves would not satisfy the ﬁeld’s
wave equation; the absence of losses guarantees they do. Show that mathemati-
cally, the time reversal can be achieved by complex conjugating the spatial part
of the waves while leaving the temporal part e−iωt unchanged. (Such phase con-
jugation can be achieved in practice using techniques of nonlinear optics, as we
8.
By “locally” plane-fronted and planar, we mean that transverse variations are on scales sufﬁciently long
compared to the wavelength of light that we can use the plane-wave analysis sketched here; for example,
the spherical mirrors and Gaussian beams of an interferometric gravitational-wave detector (see Fig. 9.13
in Sec. 9.5) easily satisfy this requirement. By lossless we mean that there is no absorption or scattering
of the light.
9.4 Etalons and Fabry-Perot Interferometers
487

shall see in the next chapter.) Show, correspondingly, that the spatial part of the
time-reversed waves is described by the formulas shown in Fig. 9.8b.
(b) Use the reﬂection and transmission coefﬁcients to compute the waves produced
by the inputs of Fig. 9.8b. From the requirement that the wave emerging from the
device’s upward side must have the form shown in the ﬁgure, conclude that
1 = rr∗+ t′t∗.
(9.34a)
Similarly, from the requirement that no wave emerge from the device’s downward
side, conclude that
0 = tr∗+ t∗r′.
(9.34b)
Eqs. (9.34) are the most general form of the reciprocity relations for lossless,
planar devices.
(c) For a sharp interface between two homogeneous media, combine these general
reciprocity relations with the ones derived in the text [Eqs. (9.32)] to show that t,
t′, r, and r′ are all real (as was asserted in the text).
(d) For the etalon of Figs. 9.6 and 9.7, re and te are given by Eqs. (9.33a). What do
the reciprocity relations tell us about the coefﬁcients for light propagating in the
opposite direction, r′
e and t′
e?
(e) Show that for a general optical device, the reﬂection and transmission coefﬁcients
can all be made real by appropriate, independent adjustments of the origins of
the vertical coordinates z (for points above the device) and z′ (for points below
the device). More speciﬁcally, show that by setting znew = zold + δz and z′
new =
z′
old + δz′ and choosing δz and δz′ appropriately, one can make t and r real.
Show further that the reciprocity relations (9.34a) and (9.34b) then imply that
t′ and r′ are also real. Finally, show that this adjustment of origins brings the real
reciprocity relations into the same form (9.32) as for a sharp interface between
two homogeneous media.
As attractive as it may be to have these coefﬁcients real, one must keep in mind
some disadvantages: (i) the displaced origins for z and z′ in general will depend
on frequency, and correspondingly, (ii) frequency-dependent information (most
importantly, frequency-dependent phase shifts of the light) is lost by making the
coefﬁcients real. If the phase shifts depend only weakly on frequency over the
band of interest (as is typically the case for the dielectric coating of a mirror face),
then these disadvantages are unimportant and it is conventional to choose the
coefﬁcients real. If the phase shifts depend strongly on frequency over the band
of interest [e.g., for the etalon of Eqs. (9.33a), when its two faces are highly re-
ﬂecting and its round-trip phase ϕ is near a multiple of 2π], the disadvantages
are severe. One then should leave the origins frequency independent, and corre-
spondingly leave the device’s r, r′, t, and t′ complex [as we have for the etalon in
Eqs. (9.33a)].
488
Chapter 9. Interference and Coherence

Exercise 9.11 **Example: Transmission and Reﬂection Coefﬁcients for an Interface
between Dielectric Media
Consider monochromatic electromagnetic waves that propagate from a medium with
index of refraction n1 into a medium with index of refraction n2. Let z be a Cartesian
coordinate perpendicular to the planar interface between the media.
(a) From the Helmholtz equation [−ω2 + (c2/n2)∇2]ψ = 0, show that both ψ and
ψ,z must be continuous across the interface.
(b) Using these continuity requirements, show that for light propagating orthogonal
to the interface (z direction), the reﬂection and transmission coefﬁcients, in going
from medium 1 to medium 2, are
r = n1 −n2
n1 + n2
,
t =
2n1
n1 + n2
.
(9.35)
Notice that these r and t are both real.
(c) Use the reciprocity relations (9.34) to deduce the reﬂection and transmission
coefﬁcients r′ and t′ for a wave propagating in the opposite direction, from
medium 2 to medium 1.
Exercise 9.12 **Example: Etalon’s Light Fields Computed by Summing
the Contributions from a Sequence of Round Trips
Study the step-by-step buildup of the ﬁeld inside an etalon and the etalon’s transmitted
ﬁeld, when the input ﬁeld is suddenly turned on. More speciﬁcally, carry out the
following steps.
(a) When the wave ﬁrst turns on, the transmitted ﬁeld inside the etalon, at point
A of Fig. 9.7, is ψa = tψi, which is very small if the reﬂectivity is high so that
|t| ≪1. Show (with the aid of Fig. 9.7) that, after one round-trip-travel time in
the etalon, the transmitted ﬁeld at A is ψa = tψi + (r′)2eiϕtψi. Show that for high
reﬂectivity and on resonance, the tiny transmitted ﬁeld has doubled in amplitude
and its energy ﬂux has quadrupled.
(b) Compute the transmitted ﬁeld ψa at A after more and more round trips, and
watch it build up. Sum the series to obtain the steady-state ﬁeld ψa. Explain the
ﬁnal, steady-state amplitude: why is it not inﬁnite, and why, physically, does it
have the value you have derived?
(c) Show that, at any time during this buildup, the ﬁeld transmitted out the far
side of the etalon is ψt = t′ψaeiks1 [Eq. (9.30b)]. What is the ﬁnal, steady-state
transmitted ﬁeld? Your answer should be Eqs. (9.33a).
Exercise 9.13 **Example: Anti-Reﬂection Coating
A common technique used to reduce the reﬂection at the surface of a lens is to coat
it with a quarter wavelength of material with refractive index equal to the geometric
mean of the refractive indices of air and glass.
9.4 Etalons and Fabry-Perot Interferometers
489

(a) Show that this does indeed lead to perfect transmission of normally incident
light.
(b) Roughly how thick must the layer be to avoid reﬂection of blue light? Estimate
the energy-ﬂux reﬂection coefﬁcient for red light in this case.
[Hint: The amplitude reﬂection coefﬁcients at an interface are given by Eqs. (9.35).]
Exercise 9.14 Problem: Oil Slick
When a thin layer of oil lies on top of water, one sometimes sees beautiful, multi-
colored, irregular bands of light reﬂecting off the oil layer. Explain qualitatively what
causes this.
9.4.2
9.4.2 Fabry-Perot Interferometer and Modes of a Fabry-Perot Cavity with Spherical
Mirrors
When an etalon’s two faces are highly reﬂecting (reﬂection coefﬁcient r near unity),
we can think of them as mirrors, between which the light resonates. The etalon is then
Fabry-Perot interferometer
a special case of a Fabry-Perot interferometer. The general case is any device in which
light resonates between two high-reﬂectivity mirrors. The mirrors need not be planar
and need not have the same reﬂectivities, and the resonating light need not be plane
fronted.
A common example is the optical cavity of Fig. 7.9, formed by two mirrors that
are segments of spheres, which we studied using geometric optics in Ex. 7.12. Because
the phase fronts of a Gaussian beam (Sec. 8.5.5) are also spherical, such a beam can
resonate in the optical cavity if (i) the beam’s waist location and waist radius are
adjusted so its phase-front radii of curvature, at the mirrors, are the same as the
mirrors’ radii of curvature, and (ii) the light’s frequency is adjusted so a half-integral
number of wavelengths ﬁt perfectly inside the cavity. Box 9.3 gives details for the case
where the two mirrors have identical radii of curvature. In that box we also learn
that the Gaussian beams are not the only eigenmodes that can resonate inside such
a cavity. Other, “higher-order” modes can also resonate. They have more complex
transverse distributions of the light. There are two families of such modes: one with
rectangular transverse light distributions, and the other with wedge-shaped, spoke-
like light distributions.
For any Fabry-Perot interferometer with identical mirrors, driven by light with
a transverse cross section that matches one of the interferometer’s modes, one can
study the interferometer’s response to the driving light by the same kind of analysis
as we used for an etalon in the previous section. And the result will be the same: the
interferometer’s reﬂected and transmitted light, at a given transverse location {x, y},
will be given by
ψr
ψi
≡rFP = r(1 −eiϕ)
1 −r2eiϕ ,
ψt
ψi
≡tFP = (1 −r2)eiϕ/2
1 −r2eiϕ
(9.36)
490
Chapter 9. Interference and Coherence

BOX 9.3.
MODES OF A FABRY-PEROT CAVITY WITH
SPHERICAL MIRRORS
Consider a Fabry-Perot cavity whose spherical mirrors have the same radius
of curvature R and are separated by a distance L. Introduce (i) Cartesian
coordinates with z = 0 at the cavity’s center, and (ii) the same functions we
used for Gaussian beams [Eqs. (8.40b)]:
z0 = kσ 2
0
2
= πσ 2
0
λ ,
σz = σ0(1 + z2/z2
0)1/2,
Rz = z(1 + z2
0/z2), (1)
with k the wave number and σ0 a measure of the transverse size of the beam
at the cavity’s center. Then it is straightforward to verify that the following
functions (i) satisfy the Helmholtz equation, (ii) are orthonormal when
integrated over their transverse Cartesian coordinates x and y, and (iii) have
phase fronts (surfaces of constant phase) that are spheres with radius of
curvature Rz:
ψmn(x, y, z) =
e−(x2+y2)/σ 2
z
√
2m+n−1π m!n! σz
Hm
*√
2 x
σz
+
Hn
*√
2 y
σz
+
× exp
,
i
k(x2 + y2)
2Rz
+ kz −(n + m + 1) tan−1 z
z0
-
. (2)
Here Hn(ξ) = (−1)neξ2dne−ξ2/dξn is the Hermite polynomial of index n,
and m and n range over nonnegative integers. By adjusting σ0, we can make
the phase-front radius of curvature Rz match that, R, of the mirrors at the
mirror locations, z = ±L/2. Then the umn are a transversely orthonormal set
of modes for the light ﬁeld inside the cavity. Their ﬂux distribution |umn|2 on
each mirror consists of an m + 1by n + 1matrix of discrete spots; see panel b
in the box ﬁgure. The mode with m = n = 0 (panel a) is the Gaussian beam
explored in the previous chapter: Eqs. (8.40). A given mode, speciﬁed by
{m, n, k}, cannot resonate inside the cavity unless its wave number matches
the cavity length, in the sense that the total phase shift in traveling from the
cavity center z = 0 to the cavity end (z = ±L/2) is an integral multiple of π/2;
that is, kL/2 −(n + m + 1) tan−1[L/(2z0)]= Nπ/2 for some integer N.
There is a second family of modes that can resonate in the cavity, one
whose eigenfunctions separate in circular polar coordinates:
ψpm(ϖ , φ, z) =
2p!e−ϖ 2/σ 2
z

1 + δm0 π(p + m)! σz
*√
2ϖ
σz
+m
Lm
p
*
2ϖ 2
σ 2
z
+ cos mφ or
sin mφ

× exp
,
i
kϖ 2
2Rz
+ kz −(2p + m + 1) tan−1 z
z0
-
,
(3)
(continued)
9.4 Etalons and Fabry-Perot Interferometers
491

BOX 9.3.
(continued)
3
2
1
0
–1
–2
–3
–3
–2
–1
0
x/σz
y/σz
1
2
3
3
2
1
0
–1
–2
–3
–3
–2
(a)
(b)
(c)
–1
0
x/σz
y/σz
1
2
3
3
2
1
0
–1
–2
–3
–3
–2
–1
0
x/σz
y/σz
1
2
3
Energy ﬂux distributions for (a) the Gaussian mode, (b) the Hermite mode of order
3,2, (c) the associated Laguerre mode of order 2,3. The contours are at 90%, 80%,
. . . , 10% of maximum.
where Lm
p(ξ) = (1/p!) eξ ξ−m dp/dξp(e−ξ ξp+m) is the associated Laguerre
polynomial, and the indices p and m range over nonnegative integers. These
modes make spots on the mirrors shaped like azimuthal wedges cut radially
by circles; see panel c in the box ﬁgure. Again, they can resonate only if the
phase change from the center of the cavity to an end mirror at z = ±L/2 is an
integral multiple of π/2: kL/2 −(2p + m + 1) tan−1[L/(2z0)]= Nπ/2.
As one goes to larger mode numbers m, n (Hermite modes) or p, m
(associated Laguerre modes), the region with substantial light power gets
larger (see the box ﬁgure). As a result, more light gets lost off the edges of the
cavity’s mirrors. So unless the mirrors are made very large, high-order modes
have large losses and do not resonate well.
For further details on these modes, see, for example, Yariv and Yeh (2007,
Secs. 2.5–2.8 and 4.3).
492
Chapter 9. Interference and Coherence

[Eqs. (9.33a) with θ = 0 so the light rays are orthogonal to the mirrors]. Here r is the
mirrors’ reﬂection coefﬁcient, and the round-trip phase is now
ϕ = 2πω/ωf + ϕG,
where ωf = 2π/τrt.
(9.37)
Here τrt is the time required for a high-frequency photon to travel round-trip in the
free spectral range
interferometer along the optic axis, from one mirror to the other; ωf (called the
free spectral range) is, as we shall see, the angular-frequency separation between the
interferometer’s resonances; and ϕG is an additive contribution (the Gouy phase),
Gouy phase
caused by the curvature of the phase fronts [e.g., the tan−1(z/zo) term in Eq. (8.40a)
for a Gaussian beam and in Eqs. (2) and (3) of Box 9.3 for higher-order modes].
Because ϕG is of order one while 2πω/ωf is huge compared to one, and because
ϕG changes very slowly with changing light frequency, it is unimportant in principle
(and we henceforth shall ignore it). However, it is important in practice: it causes
modes with different transverse light distributions (e.g., the Gaussian and higher-
order modes in Box 9.3), which have different Gouy phases, to resonate at different
frequencies.
The Fabry-Perot interferometer’s power transmissivity T and reﬂectivity R are
given by Eqs. (9.33c), which we can rewrite in the following simpliﬁed form:
T = 1 −R =
1
1 + (2F/π)2 sin2 1
2ϕ
.
(9.38)
Here F, called the interferometer’s ﬁnesse, is deﬁned by
ﬁnesse
F ≡πr/(1 −r2).
(9.39)
[This ﬁnesse should not be confused with the coefﬁcient of ﬁnesse F = (2F/π)2,
which is sometimes used in optics, but which we eschew to avoid confusion.]
In Fig. 9.9 we plot, as functions of the round-trip phase ϕ = 2πω/ωf (ignoring
ϕG), the interferometer’s power reﬂectivity and transmissivity T and R, and the phase
changes arg(tFP) and arg(rFP) of the light that is transmitted and reﬂected by the
interferometer.
Notice in Fig. 9.9a that, when the ﬁnesse F is large compared to unity, the interfer-
ometer exhibits sharp resonances at frequencies separated by the free spectral range
ωf. On resonance, the interferometer is perfectly transmitting (T = 1); away from
resonance, it is nearly perfectly reﬂecting (R ≃1). The full width at half maximum
(FWHM) of each sharp transmission resonance is given by
resonance FWHM
δϕ1/2 = 2π
F ,
δω1/2 =
ωf
F .
(9.40a)
In other words, if the frequency ω of the light is swept slowly through resonance, the
transmission will be within 50% of its peak value (unity) over a bandwidth δω1/2 =
ωf/F. Notice also, in Fig. 9.9b, that for large ﬁnesse, the phase of the reﬂected and
9.4 Etalons and Fabry-Perot Interferometers
493

1.0
0.8
0.6
0.4
0.2
0.0
5π/2
2π
3π/2
π
π/2
0
–π/2
0
π
2π
ϕ = 2πω/ωfsr
r = 0.2
F = 0.65
r = 0.4
F = 1.5
r = 0.4
F = 1.5
r = 0.4
F = 1.5
r = 0.9
F = 15
r = 0.9
F = 15
r = 0.9
F = 15
T = 1 – R
3π
4π
5π
0
π
2π
ϕ = 2πω/ωfsr
3π
arg(tFP)
arg(rFP)
4π
5π
(b)
(a)
FIGURE 9.9 (a) Power transmissivity and reﬂectivity [Eq. (9.38)] for a Fabry-Perot
interferometer with identical mirrors that have reﬂection coefﬁcients r, as a
function of the round-trip phase shift ϕ inside the interferometer. (b) The phase
of the light transmitted (red) or reﬂected (blue) from the interferometer, relative
to the input phase [Eqs. (9.36)]. The interferometer’s ﬁnesse F is related to the
mirrors’ reﬂectivity by Eq. (9.39).
transmitted light near resonance changes very rapidly with a change in frequency of
the driving light. Precisely on resonance, that rate of change is
resonance rate of change
of phase
d arg(tFP)
dω

on resonance
=
d arg(rFP)
dω

on resonance
= 2F
ωf
=
2
δω1/2
.
(9.40b)
The large transmissivity at resonance for large ﬁnesse can be understood by con-
sidering what happens when one ﬁrst turns on the incident wave. Since the reﬂectivity
494
Chapter 9. Interference and Coherence

of the ﬁrst (input) mirror is near unity, the incoming wave has a large amplitude for re-
ﬂection, and correspondingly, only a tiny amplitude for transmission into the optical
cavity. The tiny bit that gets transmitted travels through the ﬁrst mirror, gets strongly
reﬂected from the second mirror, and returns to the ﬁrst precisely in phase with the
superposition of internal
waves on resonance
incoming wave (because ϕ is an integer multiple of 2π). Correspondingly, it super-
poses coherently on the tiny ﬁeld being transmitted by the incoming wave, and so the
net wave inside the cavity is doubled. After one more round trip inside the slab, this
wave returns to the ﬁrst face again in phase with the tiny ﬁeld being transmitted by
the incoming wave; again they superpose coherently, and the internal wave now has a
three-times-larger amplitude than it began with. This process continues until a very
strong ﬁeld has built up inside the cavity (Ex. 9.12). As it builds up, that ﬁeld begins to
leak out of the cavity’s ﬁrst mirror with just such a phase as to destructively interfere
with the wave being reﬂected there. The net reﬂected wave is thereby driven close to
zero. The ﬁeld leaking out of the second mirror has no other wave to interfere with.
It remains strong, so the interferometer settles down into a steady state with strong
net transmission. Heuristically, one can say that, because the wave inside the cavity
Bose-Einstein behavior on
resonance
is continually constructively superposing on itself, the cavity sucks almost all the in-
coming wave into itself, and then ejects it out the other side. Quantum mechanically,
this sucking is due to the photons’ Bose-Einstein statistics: the photons “want” to be in
the same quantum state. We shall study this phenomenon in the context of plasmons
that obey Bose-Einstein statistics in Sec. 23.3.2.
This discussion makes it clear that, when the properties of the input light are
changed, a high-ﬁnesse Fabry-Perot interferometer will change its response rather
slowly—on a timescale approximately equal to the inverse of the resonance FWHM
(i.e., the ﬁnesse times the round-trip travel time):
τresponse ∼
2π
δω1/2
= F τrt.
(9.40c)
These properties of a high-ﬁnesse Fabry-Perot interferometer are similar to those
similarity between Fabry-
Perot interferometer and
an oscillator
of a high-Q mechanical or electrical oscillator. The similarity arises because, in both
cases, energy is being stored in a resonant, sinusoidal manner inside the device (the
oscillator or the interferometer). For the interferometer, the light’s round-trip travel
time τrt is analogous to the oscillator’s period, the interferometer’s free spectral range
ωf is analogous to the oscillator’s resonant angular frequency, and the interferometer’s
ﬁnesse F is analogous to the oscillator’s quality factor Q. However, there are some
major differences between an ordinary oscillator and a Fabry-Perot interferometer.
Perhaps the most important is that the interferometer has several large families of
resonant modes (families characterized by the number of longitudinal nodes between
the mirrors and by the 2-dimensional transverse distributions of the light), whereas
an oscillator has just one mode. This gives an interferometer much greater versatility
than a simple oscillator possesses.
9.4 Etalons and Fabry-Perot Interferometers
495

9.4.3
9.4.3 Fabry-Perot Applications: Spectrometer, Laser, Mode-Cleaning Cavity,
Beam-Shaping Cavity, PDH Laser Stabilization, Optical Frequency Comb
Just as mechanical and electrical oscillators have a wide variety of important appli-
cations in science and technology, so also do Fabry-Perot interferometers. In this
section, we sketch a few of them.
SPECTROMETER
In the case of a Fabry-Perot etalon (highly reﬂecting parallel mirrors; plane-parallel
light beam), the resonant transmission enables the etalon to be used as a spectrometer.
The round-trip phase change ϕ = 2nωd cos θ/c inside the etalon varies linearly with
thewave’sangularfrequencyω, butonlywaveswithround-tripphaseϕ nearaninteger
multiple of 2π will be transmitted efﬁciently. The etalon can be tuned to a particular
frequency by varying either the slab width d or the angle of incidence of the radiation
(and thence the angle θ inside the etalon). Either way, impressively good chromatic
resolving power can be achieved. We say that waves with two nearby frequencies can
just be resolved by an etalon when the half-power point of the transmission coefﬁcient
of one wave coincides with the half-power point of the transmission coefﬁcient of the
other. Using Eq. (9.38) we ﬁnd that the phases for the two frequencies must differ
by δϕ ≃2π/F. Correspondingly, since ϕ = 2nωd cos θ/c, the chromatic resolving
power is
R = ω
δω = 4πnd cos θ
λvacδϕ
= 2nd cos θF
λvac
.
(9.41)
Here λvac = 2πc/ω is the wavelength in vacuum (i.e., outside the etalon).
chromatic resolving power
of a spectrometer
LASER
Fabry-Perot interferometers are exploited in the construction of many types of lasers.
For example, in a gas-phase laser, the atoms are excited to emit a spectral line. This
radiation is spontaneously emitted isotropically over a wide range of frequencies.
Placing the gas between the mirrors of a Fabry-Perot interferometer allows one or
more highly collimated and narrowband modes to be trapped and, while trapped, to
be ampliﬁed by stimulated emission (i.e., to lase). See Sec. 10.2.1.
MODE CLEANER FOR A MESSY LASER BEAM
The output beam from a laser often has a rather messy cross sectional proﬁle, for
example because it contains multiple modes of excitation of the Fabry-Perot interfer-
ometer in which the lasing material resides (see the discussion of possible modes in
Box 9.3). For many applications, one needs a much cleaner laser beam (e.g., one with
cleaning a light beam
a Gaussian proﬁle). To clean the beam, one can send it into a high-ﬁnesse Fabry-Perot
cavity with identical spherical mirrors, whose mirror curvatures and cavity length are
adjusted so that, among the modes present in the beam, only the desired Gaussian
mode will resonate and thereby be transmitted (see the sharp transmission peaks in
Fig. 9.9a). The beam’s unwanted modes will not resonate in the cavity, and therefore
will be reﬂected backward off its input mirror, leaving the transmitted beam clean.
496
Chapter 9. Interference and Coherence

BEAM-SHAPING CAVITY
In some applications one wants a light beam whose cross sectional distribution of
ﬂux F(x, y) is different from any of the modes that resonate in a spherical-mirror
cavity—for example, one might want a circular, ﬂat-topped ﬂux distribution F(ϖ)
with steeply dropping edges, like the shape of a circular mesa in a North American
reshaping a light beam
desert. One can achieve the desired light distribution (or something approximating
it) as follows. Build a Fabry-Perot cavity with identical mirrors that are shaped in such
a way that there is a cavity mode with the desired distribution. Then drive the cavity
with a Gaussian beam. That portion of the beam with the desired ﬂux distribution will
resonate in the interferometer and leak out of the other mirror as the desired beam;
the rest of the input beam will be rejected by the cavity.
LASER STABILIZATION
There are two main ways to stabilize the frequency of a laser. One is to lock it onto the
frequency of some fundamental atomic or molecular transition. The other is to lock
it onto a resonant frequency of a mechanically stable Fabry-Perot cavity—a technique
PDH locking
called Pound-Drever-Hall (PDH) locking.
InPDHlockingtoacavitywithidenticalmirrors, onepassesthelaser’soutputlight
(with frequency ω) through a device that modulates its frequency,9 so ω becomes
ω + δω with δω = σ cos(t) and σ ≪δω1/2, the cavity resonance’s FWHM. One
then sends the modulated light into the cavity and monitors the reﬂected light power.
Assume, for simplicity, that the modulation is slow compared to the cavity response
time,  ≪1/τresponse. Then the cavity’s response at any moment will be that for steady
light, that is, the reﬂected power will be PiR(ω + δω), where R is the reﬂectivity at
frequency ω + δω. Using Eq. (9.38) for the reﬂectivity, specialized to frequencies very
near resonance so the denominator is close to one, and using Eqs. (9.37) and (9.40a),
we bring the reﬂected power into the form
Pr = PiR(ω + δω) = Pi ×

R(ω) + dR
dω δω(t)

= Pi
'
R(ω) + 8σ(ω −ωo)
(δω1/2)2
cos t
(
,
(9.42)
where ωo is the cavity’s resonant frequency (at which ϕ is an integral multiple of 2π).
The modulated part of the reﬂected power has an amplitude directly proportional
to the laser’s frequency error, ω −ωo. In the PDH technique, one monitors this modu-
lated power with a photodetector, followed by a band-pass ﬁlter on the photodetector’s
output electric current to get rid of the unmodulated part of the signal [arising from
PiR(ω)]. The amplitude of the resulting, modulated output current is proportional
9.
Actually, one sends it through a phase modulator called a Pockels cell, consisting of a crystal whose
index of refraction is modulated by applying an oscillating voltage to it. The resulting phase modulation,
δφ ∝sin t, is equivalent to a frequency modulation, δω = dδφ/dt ∝cos t.
9.4 Etalons and Fabry-Perot Interferometers
497

to ω −ωo and is used to control a feedback circuit that drives the laser back toward
the desired, cavity-resonant frequency ωo. (See, e.g., Black, 2001, for details.)
In Ex. 9.15 it is shown that, if one needs a faster feedback and therefore requires a
modulation frequency  >∼1/τresponse, this PDH locking technique still works.
This technique was invented by Ronald Drever for use in interferometric
gravitational-wave detectors, relying on earlier ideas of Robert Pound, and it was
ﬁrst demonstrated experimentally by Drever and John Hall. It is now used widely in
many areas of science and technology.
OPTICAL FREQUENCY COMB
JohnHallandTheodorH¨anschwereawardedthe2005NobelPrizefordevelopmentof
the optical frequency comb. This powerful tool is based on an optical cavity of length
L, ﬁlled with a lasing medium that creates and maintains a sharply pulsed internal
light ﬁeld with the following form (Fig. 9.10):
ψ = ψo(z −Vgt) exp[ikp(z −Vpt)].
(9.43)
Here
1. we use a z coordinate that increases monotonically along the optic axis as
one moves rightward from mirror 1 to mirror 2, then leftward from 2 to 1,
then rightward from 1 to 2, and so forth;
2. exp[ikp(z −Vpt)]is the pth longitudinal monochromatic mode of the cav-
ity, with wave number kp ≡pπ/L, phase velocity Vp, and angular frequency
kpVp lying in the optical range ∼1015 Hz;
3. ψo(z −Vgt) is the envelope of a wave packet so narrow that only about one
wavelength of the mode p can ﬁt inside it;
4. the envelope travels with group velocity Vg and does not spread.
For the wave packet not to spread, Vg must have the same (constant) value over all
frequencies contained in the packet, which means that the dispersion relation must
have 0 = (∂Vg/∂k) = ∂2ω/∂k2; ω must be linear in k:
ω = Vg(k + κ)
(9.44)
for some constant κ, which is typically considerably smaller than the wave numbers
k contained in the packet.
It was a huge technical challenge to build a lasing cavity that creates and sustains
a very narrow wave packet of this sort. Two of the keys to this achievement were
(i) using a nonlinear lasing medium that ampliﬁes light more strongly at high energy
ﬂuxes |ψ|2 than at low ones and thereby tends to produce intense, short pulses rather
than long, monochromatic waves and (ii) using some trickery to ensure that the lasing
mediumandanythingelseinthecavityjointlygiverisetothelineardispersionrelation
(9.44) over a sufﬁciently wide frequency band. For some of the details, see Sec. 10.2.3.
Because the sharp wave packet (9.43) has ﬁxed relationships between the phases of the
498
Chapter 9. Interference and Coherence

Vg
Vp
z
FIGURE 9.10 The sharply pulsed electric ﬁeld [Eq. (9.43)]
inside a Fabry-Perot cavity. The envelope is shown dotted;
the red curve is the full ﬁeld ψ.
various monochromatic modes that make it up, the lasing optical cavity that creates
mode-locked laser
it is called a mode-locked laser.
As the internal ﬁeld’s pulse hits mirror 2 time and again, it transmits through
the mirror a sequence of outgoing pulses separated by the wave packet’s round-trip
travel time in the cavity, τrt = 2L/Vg. Assuming, for pedagogical clarity, a Gaussian
shape for each pulse, the oscillating internal ﬁeld (9.43) produces the outgoing ﬁeld
ψ ∝!
n exp[−σ 2(t −z/c −nτrt)2/2]exp[−ikpVp(t −z/c)]. Here 1/σ is the pulse
length in time, and we have assumed vacuum-light-speed propagation outside the
cavity. It is helpful to rewrite the frequency kpVp of the oscillatory piece of this ﬁeld
as the sum of its nearest multiple of the cavity’s free spectral range, ωf = 2π/τrt, plus
a frequency shift ωs: kpVp = qωf + ωs. The integer q = (largest integer contained in
kpVp/ωf) will typically be quite close to p, and ωs is guaranteed to lie in the interval
0 ≤ωs < ωf. The emerging electric ﬁeld is then
pulsed electric ﬁeld from
mode-locked laser
ψ ∝
 
n
exp[−σ 2(t −z/c −nτrt)2/2]exp[−i(qωf + ωs)(t −z/c)]
(9.45a)
(Fig. 9.11a).
This entire emerging ﬁeld is periodic in t −z/c with period τrt = 2π/ωf, except
for the frequency-shift term exp[−iωs(t −z/c)]. The periodic piece can be expanded
as a sum over discrete frequencies that are multiples of ωf = 2π/τrt. Since the Fourier
transform of a Gaussian is a Gaussian, this sum, augmented by the frequency shift
term, turns out to be
ψ ∝
+∞
 
m=−∞
exp
'
−(m −q)2ωf 2
2σ 2
(
exp[−i(mωf + ωs)(t −z/c)].
(9.45b)
The set of discrete frequencies (spectral lines) appearing in this outgoing ﬁeld is the
electric ﬁeld’s optical
frequency comb
frequency comb displayed in Fig. 9.11b.
9.4 Etalons and Fabry-Perot Interferometers
499

0
0.5q
q
(b)
(a)
mo
2mo
1.5q
τrt
τrt
τrt/q
t – z/c
m
2π/σ
FIGURE 9.11 Optical frequency comb. (a) The pulsed electric ﬁeld (9.45a) emerging from the cavity.
(b) The ﬁeld’s comb spectrum. Each line, labeled by m, has angular frequency mωf , and is shown
with height proportional to its power, ∝exp
"
−(m −q)2ωf 2/σ 2#
[cf. Eq. (9.45b)].
Some concrete numbers make clear how very remarkable this pulsed electric ﬁeld
(9.45a) and its frequency comb (9.45b) are:
1. The Fabry-Perot cavity typically has a length L somewhere between ∼3 cm
and∼3 m, so(withthegroupvelocityVg oforderthevacuumlightspeed)the
round-trip travel time and free spectral range are τrt = 2L/Vg ∼0.3to 30 ns;
and ωf/2π ∼1/τrt ∼30 MHz to 3 GHz, which are radio and microwave
frequencies, respectively. Since the shift frequency is ωs < ωf, it is also in
the radio or microwave band.
2. The comb’s central frequency is in the optical, qωf/2π ∼3 × 1014 Hz, so
the harmonic number of the central frequency is q ∼105 to 107, roughly a
million.
3. The pulse width ∼2/σ contains roughly one period (2π/qωf) of the central
frequency, so σ ∼qωf/3, which means that most of the comb’s power is
contained in the range m ∼2q/3 to m ∼4q/3 (i.e., there are roughly a
million strong teeth in the comb).
It is possible to lock the comb’s free spectral range ωf to a very good cesium atomic
clock, whose oscillation frequency ∼9 GHz is stable to δω/ω ∼10−13 (Fig. 6.11), so
ωf has that same phenomenal stability. One can then measure the shift frequency ωs
500
Chapter 9. Interference and Coherence

and calibrate the comb (identify the precise mode number m of each frequency in the
calibrating the optical
frequency comb
comb) as follows.
1. Arbitrarily choose a tooth at the low-frequency end of the comb, mo ≃2q/3
(Fig. 9.11b); it has frequency ωo = moωf + ωs.
2. Separate the light in that tooth from light in the other teeth, and send a beam
of that tooth’s light through a frequency doubler (to be discussed in Sec.
10.7.1), thereby getting a beam with frequency 2ωo = 2(moωf + ωs).
3. By beating this beam against the light in teeth at m ∼4q/3, identify the
tooth that most closely matches this beam’s frequency. It will have frequency
2moωf + ωs, and the frequency difference (beat frequency) will be ωs.
This reveals ωs to very high accuracy, and one can count the number of teeth (mo −1)
between this tooth 2mo and its undoubled parent mo, thereby learning the precise
numerical value of mo. From this, by tooth counting, one learns the precise mode
numbers m of all the optical-band teeth in the comb, and also their frequencies
mωf + ωs.
With the comb now calibrated, it can be used to measure the frequency of any
some applications
other beam of light in the optical band in terms of the ticking frequency of the cesium
clock, to which the entire comb has been locked. The optical frequency accuracies
thereby achieved are orders of magnitude better than were possible before this optical
frequency comb was developed. And in the near future, as optical-frequency atomic
clocks become much more accurate and stable than the microwave-frequency cesium
clock (see the footnote in Sec. 6.6.1), this comb will be used to calibrate microwave
and radio frequencies in terms of the ticking rates of optical frequency clocks.
For further details about optical frequency combs, see the review articles by Cun-
diff (2002) and Cundiff and Ye (2003).
EXERCISES
Exercise 9.15 Problem: PDH Laser Stabilization
Show that the PDH method for locking a laser’s frequency to an optical cavity works
for modulations faster than the cavity’s response time,  >∼1/τresponse, and even works
for  ≫1/τresponse. More speciﬁcally, show that the reﬂected power still contains the
information needed for feedback to the laser. [For a quite general analysis and some
experimental details, see Black (2001).]
Exercise 9.16 Derivation: Optical Frequency Comb
Fill in the details of the derivation of all the equations in the section describing the
optical frequency comb.
Exercise 9.17 **Problem: Sagnac Interferometer
A Sagnac interferometer is a rudimentary version of a laser gyroscope for measuring
rotation with respect to an inertial frame. The optical conﬁguration is shown in
9.4 Etalons and Fabry-Perot Interferometers
501

L
B
T

FIGURE 9.12 Sagnac interferometer used as a
type of laser gyro.
Fig. 9.12. Light from a laser L is split by a beam splitter B and travels both clockwise
and counterclockwise around the optical circuit, reﬂecting off three plane mirrors.
The light is then recombined at B, and interference fringes are viewed through
the telescope T . The whole assembly rotates with angular velocity . Calculate the
difference in the time it takes light to traverse the circuit in the two directions,
and show that the consequent fringe shift (total number of fringes that enter the
telescope during one round trip of the light in the interferometer) can be expressed
as N = 4A/(cλ), where λ is the wavelength, and A is the area bounded by the
beams. Show further that, for a square Sagnac interferometer with side length L, the
rate at which fringes enter the telescope is L/λ.
9.5
9.5 Laser Interferometer Gravitational-Wave Detectors
As we discuss in Chap. 27, gravitational waves are predicted to exist by general
relativity theory, and their emission by the binary neutron-star system PSR B1913+16
has been monitored since 1974, via their back-action on the binary’s orbital motion.
As orbital energy is lost to gravitational waves, the binary gradually spirals inward, so
its orbital angular velocity gradually increases. The measured rate of increase agrees
with general relativity’s predictions to within the experimental accuracy of a fraction
of a percent (for which Russell Hulse and Joseph Taylor received the 1993 Nobel
Prize in physics). Unfortunately, the gravitational analog of Hertz’s famous laboratory
emission and detection of electromagnetic waves has not yet been performed, and
cannot be in the authors’ lifetime because of the waves’ extreme weakness. For waves
strongenoughtobedetectableonEarth, onemustturntoviolentastrophysicalevents,
such as the collision and coalescence of two neutron stars or black holes.
When the gravitational waves from such an event reach Earth and pass through a
laboratory, general relativity predicts that they will produce tiny relative accelerations
of free test masses. The resulting oscillatory variation of the distance between two
such masses can be measured optically using a Michelson interferometer, in which
(to increase the signal strength) each of the two arms is operated as a Fabry-Perot
502
Chapter 9. Interference and Coherence

laser
recycling
mirror
input
mirror
end
mirror
beam splitter
cavity 1
cavity 2
photo-
detector
L + δL1
L + δL2
FIGURE 9.13 Schematic design of an initial gravitational-wave
interferometer operated in LIGO (at Livingston, Louisiana,
and Hanford, Washington, USA) during 2005–2010.
cavity. Two such instruments, called interferometric gravitational wave detectors [for
interferometric
gravitational wave
detector
which Rainer Weiss (1972) was the primary inventor, with important contributions
from Ronald Drever and many others] made the ﬁrst discovery of gravitational waves
arriving at Earth on September 14, 2015 (Abbott et al., 2016a). The waves came from
the last few orbits of inspiral and the collision of two black holes with masses 29M⊙
and 36M⊙, where M⊙is the Sun’s mass.
The observatory that discovered these waves is called LIGO, the Laser Interferom-
eter Gravitational Wave Observatory, and its interferometric detectors were second
generation instruments, called advanced LIGO. These advanced LIGO detectors are
advanced LIGO
more complex than is appropriate to analyze in this chapter, so we shall forcus instead
on the ﬁrst generation detectors called initial LIGO (Abbott et al., 2009b), and then
initial LIGO
near the end of this section we shall brieﬂy describe how advanced LIGO differs from
initial LIGO.
In each of the initial LIGO gravitational-wave detectors, the two cavities are
aligned along perpendicular directions, as shown in Fig. 9.13. A Gaussian beam of
light (Sec. 8.5.5) from a laser passes through a beam splitter, creating two beams
with correlated phases. The beams excite the two cavities near resonance. Each cavity
has an end mirror with extremely high reﬂectivity,10 1 −r2
e < 10−4, and a corner
mirror reﬂectivity
mirror (“input mirror”) with a lower reﬂectivity, 1 −r2
i ∼0.03. Because of this lower
reﬂectivity, by contrast with the etalons discussed in previous sections, the resonant
light leaks out through the input mirror instead of through the end mirror. This
reﬂectivity of the input mirror is so adjusted that the typical photon is stored in
10. Because LIGO operates with monochromatic light, it is convenient to adjust the phases of the mirrors’
reﬂection and transmission coefﬁcients so r and t are both real; cf. Ex. 9.10e. We do so here.
9.5 Laser Interferometer Gravitational-Wave Detectors
503

the cavity for roughly half the period of the expected gravitational waves (a few
milliseconds), which means that the input mirror’s reﬂectivity r2
i, the arm length L,
and the gravitational-wave angular frequency ωgw are related by
4L
c(1 −r2
i) ∼
1
ωgw
.
(9.46)
The light emerging from the cavity, like that transmitted by an etalon, has a phase
that is highly sensitive to the separation between the mirrors: a tiny change δL in their
separation produces a change in the outcoming phase
δϕo ≃8ωδL
c
1
(1 −r2
i) ∼2ω
ωgw
δL
L
(9.47)
in the limit 1−ri ≪1; see Ex. 9.18. The outcoming light beams from the two cavities
return to the beam splitter and are recombined there. The relative distances from the
beam splitter to the cavities are adjusted so that, in the absence of any perturbations
of the cavity lengths, almost all the interfered light goes back toward the laser, and
only a tiny (but nonzero) amount goes toward the photodetector of Fig. 9.13, which
monitors the output. Perturbations δL1 and δL2 in the cavity lengths then produce a
change
phase shift induced by
mirror motions
δϕo1 −δϕo2 ∼2ω
ωgw
(δL1 −δL2)
L
(9.48)
intherelativephasesatthebeamsplitter, andthisinturnproducesachangeofthelight
power entering the photodetector. By using two cavities in this way and keeping their
light-storage times (and hence response times) the same, one makes the light power
entering the photodetector be insensitive to ﬂuctuations in the laser frequency. This is
crucial for obtaining the high sensitivities that gravitational-wave detection requires.
The mirrors at the ends of each cavity are suspended as pendula, and when a
gravitational wave with dimensionless amplitude h (discussed in Chap. 27) passes,
it moves the mirrors back and forth, producing changes
mirror motions produced
by gravitational wave
δL1 −δL2 = hL
(9.49)
in the arm-length difference. The resulting change in the relative phases of the two
beams returning to the beam splitter,
δϕo1 −δϕo2 ∼2ω
ωgw
h,
(9.50)
is monitored via the changes in power that it produces for the light going into the
photodetector. If one builds the entire detector optimally and uses the best possible
photodetector, thesephasechangescanbemeasuredwithaphotonshot-noise-limited
detectable phase shift
precision of ∼1/
√
N. Here N ∼[Wℓ/(ℏω)](π/ωgw) is the number of photons put into
504
Chapter 9. Interference and Coherence

the detector by the laser (with power Wℓ) during half a gravitational-wave period.11
By combining this with Eq. (9.50), we see that the weakest wave that can be detected
(at signal-to-noise ratio 1) is
estimate of weakest
detectable gravitational
wave
h ∼
* ℏω3
gw
4πωWℓ
+1/2
.
(9.51)
For a laser power Wℓ∼5 W, and ωgw ∼103 s−1, ω ∼2 × 1015 s−1, this gravitational-
wave sensitivity (noise level) is h ∼1 × 10−21.
When operated in this manner, about 97% of the light returns toward the laser
from the beam splitter and the other 3% goes out the end mirror, goes into the
photodetector, gets absorbed, or is scattered due to imperfections in the optics. In
LIGO’s initial detectors, the 97% returning toward the laser was recycled back into the
interferometer, inphasewithnewlaserlight, byplacingamirrorbetweenthelaserand
the beam splitter. This “power recycling mirror” (shown dashed in Fig. 9.13) made the
power recycling
entire optical system into a big optical resonator with two subresonators (the arms’
Fabry-Perot cavities), and the practical result was a 50-fold increase in the input light
power, from 5 W to 250 W—and an optical power in each arm of about 1
2 × 250 W ×
4/(1 −r2
i) ∼15 kW; see Abbott et al. (2009b, Fig. 3). When operated in this manner,
the interferometer achieved a noise level h ∼1× 10−21/
√
50 ∼1× 10−22. For a more
accurate analysis of the sensitivity, see Exs. 9.18 and 9.19.
This estimate of sensitivity is actually the rms noise in a bandwidth equal to
frequency at the minimum of LIGO’s noise curve. Figure 6.7 shows the noise curve
as the square root of the spectral density of the measured arm-length difference
measured noise in initial
LIGO
ξ ≡L1 −L2, Sξ(f ). Since the waves produce a change of ξ given by δξ = hL
[Eq. (9.49)], the corresponding noise-induced ﬂuctuations in the measured h have
Sh = Sξ/L2, and the rms noise ﬂuctuations in a bandwidth equal to frequency f are
hrms =

Shf = (1/L)

Sℓf . Inserting Sξ ≃10−19 m Hz−1/2 and f ≃100 Hz from
Fig.6.7, andL = 4 kmfortheLIGOarmlength, weobtainhrms ≃2.5 × 10−22, afactor
2.5 larger than our 1 × 10−22 estimate—in part because thermal noise is roughly as
large as photon shot noise at 100 Hz.
experimental challenges
Thereareenormousobstaclestoachievingsuchhighsensitivity.Herewenamejust
a few. Imperfections in the optics will absorb some of the high light power, heating the
mirrors and beam splitter and causing them to deform. Even without such heating,
the mirrors and beam splitter must be exceedingly smooth and near perfectly shaped
to minimize the scattering of light from them (which causes noise; Ex. 8.15). Thermal
noise in the mirrors and their suspensions (described by the ﬂuctuation-dissipation
11. This measurement accuracy is related to the Poisson distribution of the photons entering the interfer-
ometer’s two arms: if N is the mean number of photons during a half gravitational-wave period, then
the variance is
√
N, and the fractional ﬂuctuation is 1/
√
N. The interferometer’s shot noise is actually
caused by a beating of quantum electrodynamical vacuum ﬂuctuations against the laser’s light; for details
see Caves (1980).
9.5 Laser Interferometer Gravitational-Wave Detectors
505

theorem) will cause the mirrors to move in manners that simulate the effects of
a gravitational wave (Secs. 6.8.2 and 11.9.2), as will seismic- and acoustic-induced
vibrations of the mirror suspensions. LIGO’s arms must be long (4 km) to minimize
the effects of these noise sources. While photon shot noise dominates above the noise
curve’s minimum, f >∼100 Hz, these and other noises dominate at lower frequencies.
The initial LIGO detectors operated from 2005 to 2010, carrying out gravitational-
wave searches, much of the time in collaboration with international partners (the
French-Italian VIRGO and British/German GEO600 detectors). From 2010 to 2015,
the second generation advanced LIGO detectors were installed in the LIGO vacuum
advanced LIGO noise and
discovery of gravitational
waves
system, with amplitude design sensitivity 10-fold higher than the initial detectors.
These advanced detectors discovered gravitational waves in September 2015, just
before their ﬁrst search ofﬁcially began, and when their sensitivity at the noise-curve
minimum was about 3 times worse than their design but 3 times better than initial
LIGO.
One of several major changes, in going from initial LIGO to advanced LIGO, was
the insertion of a “signal recycling mirror” between the beam splitter and the pho-
advanced LIGO’s signal
recycling mirror
todetector ( Abbott et al., 2016b). The output signal light, in the cavity bounded by
this new mirror and the two input mirrors, “sucks” signal light out of the interferom-
eter arms due to Bose-Einstein statistics. This permits laser light to be stored in the
arm cavities far longer than half a gravitational wave period (and thereby build up to
higher intensity), while the signal light gets extracted in roughly a half period. This
added complication is why we chose not to analyze the advanced detectors.
EXERCISES
Exercise 9.18 Derivation and Problem: Phase Shift in LIGO Arm Cavity
Inthisexerciseandthenext, simplifytheanalysisbytreatingeachGaussianlightbeam
as though it were a plane wave. The answers for the phase shifts will be the same as
for a true Gaussian beam, because on the optic axis, the Gaussian beam’s phase [Eq.
(8.40a) with ϖ = 0] is the same as that of a plane wave, except for the Gouy phase
tan−1(z/z0), which is very slowly changing and thus is irrelevant.
(a) For the interferometric gravitational-wave detector depicted in Fig. 9.13 (with the
arms’ input mirrors having amplitude reﬂectivities ri close to unity and the end
mirrors idealized as perfectly reﬂecting), analyze the light propagation in cavity 1
by the same techniques as used for an etalon in Sec. 9.4.1. Show that, if ψi1 is the
light ﬁeld impinging on the input mirror, then the total reﬂected light ﬁeld ψr1 is
ψr1 = eiϕ11 −rie−iϕ1
1 −rieiϕ1 ψi1,
where ϕ1 = 2kL1.
(9.52a)
(b) From this, infer that the reﬂected ﬂux |ψr1|2 is identical to the cavity’s input ﬂux
|ψi1|2, as it must be, since no light can emerge through the perfectly reﬂecting
end mirror.
506
Chapter 9. Interference and Coherence

(c) The arm cavity is operated on resonance, so ϕ1 is an integer multiple of 2π. From
Eq. (9.52a) infer that (up to fractional errors of order 1 −ri) a change δL1 in the
length of cavity 1 produces a change
δϕr1 = 8kδL1
1 −r2
i
.
(9.52b)
With slightly different notation, this is Eq. (9.47), which we used in the text’s
order-of-magnitude analysis of LIGO’s sensitivity. In this exercise and the next,
we carry out a more precise analysis.
Exercise 9.19 Example: Photon Shot Noise in LIGO
This exercise continues the preceding one. We continue to treat the light beams as
plane waves.
(a) Denote by ψℓthe light ﬁeld from the laser that impinges on the beam splitter and
gets split in two, with half going into each arm (Fig. 9.13). Using the equations
from Ex. 9.18 and Sec. 9.5, infer that the light ﬁeld returning to the beam splitter
from arm 1 is ψs1 =
1
√
2ψℓeiϕ1(1 + iδϕr1), where ϕ1 is some net accumulated
phase that depends on the separation between the beam splitter and the input
mirror of arm 1.
(b) Using the same formula for the ﬁeld ψs2 from arm 2, and assuming that the phase
changes between beam splitter and input mirror are almost the same in the two
arms, so ϕo ≡ϕ1 −ϕ2 is small compared to unity (mod 2π), show that the light
ﬁeld that emerges from the beam splitter, traveling toward the photodetector, is
ψpd = 1
√
2
(ψs1 −ψs2) = i
2(ϕo + δϕr1 −δϕr2)ψℓ
(9.53a)
to ﬁrst order in the small phases. Show that the condition |ϕo| ≪1 corresponds
to the experimenters’ having adjusted the positions of the input mirrors in such
a way that almost all the light returns toward the laser, and only a small fraction
goes toward the photodetector.
(c) For simplicity, let the gravitational wave travel through the interferometer from
directly overhead and have an optimally oriented polarization. Then, as we
shall see in Chap. 27 [Eq. (27.81)], the dimensionless gravitational-wave ﬁeld
h(t) produces the arm-length changes δL1 = −δL2 = 1
2h(t)L, where L is the
unperturbed arm length. Show, then, that the ﬁeld traveling toward the photode-
tector is
ψpd = i
2(ϕo + δϕgw)ψℓ,
where
δϕgw = 8kL
1 −r2
i
h(t) = 16πL/λ
1 −r2
i
h(t).
(9.53b)
The experimenter adjusts ϕo so it is large compared to the tiny δϕgw.
(d) Actually, this equation has been derived assuming, when analyzing the arm cavi-
ties [Eq. (9.52a)], that the arm lengths are static. Explain why it should still be
nearly valid when the gravitational waves are moving the mirrors, so long as
9.5 Laser Interferometer Gravitational-Wave Detectors
507

the gravitational-wave half-period 1/(2f ) = π/ωgw is somewhat longer than the
mean time that a photon is stored inside an arm cavity, or so long as f ≪fo,
where
fo ≡1 −r2
i
4π
c
2L.
(9.54)
Assume that this is so. For the initial LIGO detectors, 1−r2
i ∼0.03and L = 4 km,
so fo ∼90 Hz.
(e) Showthat, ifWℓisthelaserpowerimpingingonthebeamsplitter(proportionalto
|ψℓ|2), then the steady-state light power going toward the photodetector is Wpd =
(ϕo/2)2Wℓ, andthetimevariationinthatlightpowerduetothegravitationalwave
(the gravitational-wave signal) is
Wgw(t) =

WℓWpd
16πL/λ
1 −r2
i
h(t).
(9.55a)
The photodetector monitors these changes Wgw(t) in the light power Wpd and
from them infers the gravitational-wave ﬁeld h(t). This is called a “DC” or
“homodyne” readout system; it works by beating the gravitational-wave signal
ﬁeld (∝δϕgw) against the steady light ﬁeld (“local oscillator,” ∝ϕo) to produce
the signal light power Wgw(t) ∝h(t).
(f) Shot noise in the interferometer’s output light power Wpd gives rise to noise in the
measured gravitational-wave ﬁeld h(t). From Eq. (9.55a) show that the spectral
density of the noise in the measured h(t) is
Sh(f ) =
*
(1 −r2
i)λ
16πL
+2
SWpd
WℓWpd
.
(9.55b)
In Sec. 6.7.4, we derived the formula SWpd = 2R(ℏω)2 = 2Wpdℏω [Eq. (6.69)] for
the (frequency-independent) spectral density of a steady, monochromatic light
beam’s power ﬂuctuations due to shot noise; here R = Wpd/(ℏω) is the average
rate of arrival of photons. Combining with Eq. (9.55b), deduce your ﬁnal formula
for the spectral density of the noise in the inferred gravitational-wave signal:
Sh(f ) =
*
(1 −r2
i)λ
16πL
+2
2
Wℓ/(ℏω).
(9.56a)
From this deduce the rms noise in a bandwidth equal to frequency
hrms =

f Sh =
*
(1 −r2
i)λ
16πL
√
N
+
,
where
N = Wℓ
ℏω
1
2f
(9.56b)
508
Chapter 9. Interference and Coherence

is the number of photons that impinge on the beam splitter, from the laser, in half
a gravitational-wave period.
(g) In Ex. 9.20 we shall derive (as a challenge) the modiﬁcation to the spectral
density that arises at frequencies f >∼fo. The signal strength that gets through the
interferometer is reduced because the arm length is increasing, then decreasing,
then increasing again (and so forth) while the typical photon is in an arm cavity.
The result of the analysis is an increase of Sh(f ) by 1 + (f/fo)2, so we have
Sh(f ) =
*
(1 −r2
i)λ
16πL
+2
2
Wℓ/ℏω
*
1 + f 2
f 2
o
+
.
(9.57)
Compare this with the measured noise, at frequencies above fo ∼90 Hz in the
initial LIGO detectors (Fig. 6.7 with ξ = hL), using the initial LIGO parameters:
λ = 1.06 μm, ω = 2πc/λ ≃2 × 1015 s−1, L = 4 km, Wℓ= 250 W, 1 −r2
i = 0.03.
It should agree fairly well with the measured noise at frequencies f >∼fo, where
most of the noise is due to photon shot noise. Also compare the noise (9.57) in a
bandwidth equal to frequency

f Sh and evaluated at frequency f = fo with the
estimate (9.51) worked out in the text.
Exercise 9.20 Challenge: LIGO Shot Noise at f >∼fo
Derive the factor 1 + (f/fo)2 by which the spectral density of the shot noise is in-
creased at frequencies f >∼fo. [Hint: Redo the analysis of the arm cavity ﬁelds, part
(a) of Ex. 9.19, using an arm length that varies sinusoidally at frequency f due to
a sinusoidal gravitational wave, and then use the techniques of Ex. 9.19 to deduce
Sh(f ).]
9.6
9.6 Power Correlations and Photon Statistics:
Hanbury Brown and Twiss Intensity Interferometer
A type of interferometer that is rather different from those studied earlier in this chap-
ter was proposed and constructed by Robert Hanbury Brown and Richard Q. Twiss
in 1956. In this interferometer, light powers, rather than amplitudes, are combined to
measure the degree of coherence of the radiation ﬁeld. This is often called an intensity
intensity interferometer
interferometer,because the optics community often uses the word “intensity” to mean
energy ﬂux (power per unit area).
In their original experiment, Hanbury Brown and Twiss divided light from an
incandescent mercury lamp and sent it along two paths of variable length before
detecting photons in each beam separately using a photodetector (see Fig. 9.14). The
electrical output from each photodetector measures the rate of arrival of its beam’s
photons, or equivalently, its beam’s power W(t), which we can write as K(ℜ!)2,
9.6 Power Correlations and Photon Statistics
509

beam splitter
Hg line
current / I
current / I
correlator
intensity
fringes
photodetector
photodetector
FIGURE 9.14 Hanbury Brown and Twiss intensity interferometer.
where K is a constant. This W exhibits ﬂuctuations δW about its mean value W,
ﬂuctuations of power W in
each beam
and it was found that the ﬂuctuations in the two beams were correlated. How can
this be?
The light that was detected originated from many random and independent emit-
ters and therefore obeys Gaussian statistics, according to the central limit theorem
(Sec. 6.3.2). This turns out to mean that the fourth-order correlations of the wave
ﬁeld ! with itself can be expressed in terms of the second-order correlations (i.e., in
terms of the degree of coherence γ||).
More speciﬁcally, continuing to treat the wave ﬁeld ! as a scalar, we (i) write each
beam’s power as the sum over a set of Fourier components !j with precise frequencies
ωj and slowly wandering, complex amplitudes W(t) = (!
j ℜ!j)2; (ii) form the
product W(t)W(t + τ); (iii) keep only terms that will have nonzero averages by virtue
of containing products of the form ∝e+iωjte−iωjte+iωkte−iωkt (where j and k are
generally not the same); and (iv) average over time. Thereby we obtain
W(t)W(t + τ) = K2!(t)!∗(t) × !(t + τ)!∗(t + τ)
+ K2!(t)!∗(t + τ) × !∗(t)!(t + τ)
= W
2[1 + |γ∥(τ)|2]
(9.58)
[cf. Eq. (9.16) with ! allowed to be complex]. If we now measure the relative ﬂuctu-
ations, we ﬁnd that
longitudinal correlation of
beam power
δW(t)δW(t + τ)
W(t)
2
= W(t)W(t + τ) −W(t)
2
W(t)
2
= |γ∥(τ)|2.
(9.59)
[Note: This analysis is only correct if the radiation comes from many uncorrelated
sources—the many independently emitting mercury atoms in Fig. 9.14—and there-
fore has Gaussian statistics.]
Equation (9.59) tells us that the power as well as the amplitude of coherent radia-
tion must exhibit a positive longitudinal correlation, and the degree of coherence for
the ﬂuxes is equal to the squared modulus of the degree of coherence for the ampli-
tudes. Although this result was rather controversial at the time the experiments were
510
Chapter 9. Interference and Coherence

ﬁrst performed, it is easy to interpret qualitatively if we think in terms of photons
rather than classical waves. Photons are bosons and are therefore positively corre-
explanation of power
correlation by Bose-
Einstein statistics: photon
bunching
lated even in thermal equilibrium; cf. Chaps. 3 and 4. When they arrive at the beam
splitter of Fig. 9.14, they clump more than would be expected for a random distribu-
tion of classical particles, a phenomenon called photon bunching.12 In fact, treating
the problem from the point of view of photon statistics gives an answer equivalent to
Eq. (9.59).
Some practical considerations should be mentioned. The ﬁrst is that Eq. (9.59),
derived for a scalar wave, is really only valid for electromagnetic waves if they are
completely polarized. If the incident waves are unpolarized, then the intensity ﬂuctu-
ations are reduced by a factor of two. The second point is that, in the Hanbury Brown
and Twiss experiments, the photon counts were actually averaged over longer times
than the correlation time of the incident radiation. This reduced the magnitude of the
measured effect further.
Nevertheless, after successfully measuring temporal power correlations, Hanbury
Brown and Twiss constructed a stellar intensity interferometer, with which they were
stellar intensity
interferometer
able to measure the angular diameters of bright stars. This method had the advan-
tage that it did not depend on the phase of the incident radiation, so the results
were insensitive to atmospheric ﬂuctuations (seeing), one of the drawbacks of the
Michelson stellar interferometer (Sec. 9.2.5). Indeed, it is not even necessary to use
accurately ground mirrors to measure the effect. The method has the disadvantage
that it can only measure the modulus of the degree of coherence; the phase is lost.
It was the ﬁrst example of using fourth-order correlations of the light ﬁeld to extract
image information from light that has passed through Earth’s turbulent atmosphere
(Box 9.2).
EXERCISES
Exercise 9.21 Derivation: Power Correlations
By expressing the ﬁeld as either a Fourier sum or a Fourier integral complete the
argument that leads to Eq. (9.58).
Exercise 9.22 Problem: Electron Intensity Interferometry
Is it possible to construct an intensity interferometer (i.e., a number-ﬂux interfer-
ometer) to measure the coherence properties of a beam of electrons? What qualitative
differences do you expect there to be from a photon-intensity interferometer? What
do you expect Eq. (9.59) to become?
12. Pions emerging from high-energy, heavy ion collisions exhibit similar bunching because pions, like
photons, are bosons.
9.6 Power Correlations and Photon Statistics
511

Bibliographic Note
For pedagogical introductions to interference and coherence at an elementary level
in greater detail than this chapter, see Klein and Furtak (1986) and Hecht (2017). For
more advanced treatments, we like Pedrotti, Pedrotti, and Pedrotti (2007), Saleh and
Teich (2007), Ghatak (2010), and especially Brooker (2003). For a particularly deep
andthoroughdiscussionofcoherence, seeGoodman(1985).Formodernapplications
of interferometry (including the optical frequency comb), see Yariv and Yeh (2007),
and at a more elementary level, Francon and Willmans (1966) and Hariharan (2007).
512
Chapter 9. Interference and Coherence

10
CHAPTER TEN
Nonlinear Optics
The development of the maser and laser . . . followed no script except to hew to
the nature of humans groping to understand, to explore, and to create . . .
CHARLES H. TOWNES (2002)
10.1
10.1 Overview
Communication technology is undergoing a revolution, and computer technology
may do so soon—a revolution in which the key devices used (e.g., switches and com-
munication lines) are changing from radio and microwave frequencies to optical fre-
quencies. This revolution has been made possible by the invention and development
of lasers (especially semiconductor diode lasers) and other technology developments,
such as nonlinear media whose polarization Pi is a nonlinear function of the applied
electric ﬁeld, Pi = ϵ0(χijEj + 2dijkEjEk + 4χijklEjEkEl + . . .). In this chapter we
study lasers, nonlinear media, and various nonlinear optics applications that are based
on them.
Most courses in elementary physics idealize the world as linear. From the simple
harmonicoscillatortoMaxwell’sequationstotheSchr¨odingerequation, mostelemen-
tary physical laws one studies are linear, and most of the applications studied make
use of this linearity. In the real world, however, nonlinearities abound, creating such
phenomena as avalanches, breaking ocean waves, holograms, optical switches, and
neural networks; and in the past three decades nonlinearities and their applications
have become major themes in physics research, both basic and applied. This chapter,
with its exploration of nonlinear effects in optics, serves as a ﬁrst introduction to some
fundamental nonlinear phenomena and their present and future applications. In later
chapters, we revisit some of these phenomena and meet others, in the context of ﬂuids
(Chaps. 16 and 17), plasmas (Chap. 23), and spacetime curvature (Chaps. 25–28).
Since highly coherent and monochromatic laser light is one of the key foundations
on which modern nonlinear optics has been built, we begin in Sec. 10.2 with a review
ofthebasicphysicsprinciplesthatunderliethelaser:thepumpingofanactivemedium
to produce a molecular population inversion and the stimulated emission of radiation
from the inverted population. Then we brieﬂy describe the wide variety of lasers now
available, how a few of them are pumped, and the characteristics of their light. As
513

BOX 10.1.
READERS’ GUIDE
.
This chapter depends substantially on Secs. 7.2, 7.3, and 7.7.1
(geometric optics).
.
Sec. 10.6, on wave-wave mixing, is an important foundation for
Chap. 23 on the nonlinear dynamics of plasmas, and (to a lesser
extent) for the discussions of solitary waves (solitons) in Secs. 16.3
and 23.6. Nothing else in this book relies substantially on this chapter.
an important example (crucial for the optical frequency combs of Sec. 9.4.3), we give
details about mode-locked lasers.
In Sec. 10.3, we meet our ﬁrst example of an application of nonlinear optics:
holography. In the simplest variant of holography, a 3-dimensional, monochromatic
image of an object is produced by a two-step process: recording a hologram of
the image, and then passing coherent light through the hologram to reconstruct the
image. We analyze this recording and reconstruction and then describe a few of the
many variants of holography now available and some of their practical applications.
Holography differs from more modern nonlinear optics applications in not be-
ing a real-time process. Real-time processes have been made possible by nonlinear
media and other new technologies. In Sec. 10.4, we study an example of a real-time,
nonlinear-optics process: phase conjugation of light by a phase-conjugating mirror
(though we delay a detailed discussion of how such mirrors work until Sec. 10.8.2). In
Sec. 10.4, we also see how phase conjugation can be used to counteract the distortion
of images and signals by media through which they travel.
In Sec. 10.5, we introduce nonlinear media and formulate Maxwell’s equations for
waves propagating through such media. As an example, we brieﬂy discuss electro-
optic effects, where a slowly changing electric ﬁeld modulates the optical properties
of a nonlinear crystal, thereby modulating light waves that propagate through it. Then
in Sec. 10.6, we develop a detailed description of how such a nonlinear crystal couples
two optical waves to produce a new, third wave—so-called “three-wave mixing.”
Three-wave mixing has many important applications in modern technology. In Sec.
10.7, we describe and analyze several: frequency doubling (e.g., in a green laser
pointer), optical parametric ampliﬁcation of signals, and driving light into a squeezed
state (e.g., the squeezed vacuum of quantum electrodynamics).
In an isotropic medium, three-wave mixing is suppressed, but a new, fourth wave
can be produced by three incoming waves. In Sec. 10.8, we describe and analyze this
four-wave mixing and how it is used in phase-conjugate mirrors and produces prob-
lems in the optical ﬁbers widely used to transmit internet, television, and telephone
signals.
514
Chapter 10. Nonlinear Optics

These topics just scratch the surface of the exciting ﬁeld of nonlinear optics, but
they will give the reader an overview and some major insights into this ﬁeld, and into
nonlinear phenomena in the physical world.
10.2
10.2 Lasers
10.2.1
10.2.1 Basic Principles of the Laser
In quantum mechanics one identiﬁes three different types of interaction of light with
material systems (atoms, molecules, atomic nuclei, electrons, etc.): (i) spontaneous
spontaneous emission,
absorption, and stimulated
emission
emission, in which a material system in an excited state spontaneously drops into a
state of lesser excitation and emits a photon in the process; (ii) absorption, in which
an incoming photon is absorbed by a material system, exciting it; and (iii) stimulated
emission, in which a material system, initially in some excited state, is “tickled” by
passing photons, and this tickling stimulates it to emit a photon of the same sort (in
the same state) as the photons that tickled it.
As peculiar as stimulated emission may seem at ﬁrst sight, in fact it is easily
understood and analyzed classically. It is nothing but “negative absorption”: In classi-
cal physics, when a light beam with electric ﬁeld E = ℜ[Aei(kz−ωt+ϕ)]travels through
an absorbing medium, its real amplitude A decays exponentially with the distance
propagated, A ∝e−μz/2 (corresponding to an energy-ﬂux decay F ∝e−μz), while its
frequency ω, wave number k, and phase ϕ remain nearly constant. For normal materi-
als, the absorption rate μ = F −1dF/dz is positive, and the energy lost goes ultimately
into heat. However, one can imagine a material with an internally stored energy that
ampliﬁes a passing light beam. Such a material would have a negative absorption rate,
μ < 0, and correspondingly, the amplitude of the passing light would grow with the
distance traveled, A ∝e+|μ|z/2, while its frequency, wave number, and phase would
remain nearly constant. Such materials do exist; they are called “active media,” and
active medium
their ampliﬁcation of passing waves is stimulated emission.
This elementary, classical description of stimulated emission is equivalent to the
quantum mechanical description in the domain where the stimulated emission is
strong: the domain of large photon-occupation numbers η ≫1(which, as we learned
in Sec. 3.2.5, is the domain of classical waves).
The classical description of stimulated emission takes for granted the existence
of an active medium. To understand the nature of such a medium, we must turn to
quantum mechanics.
As a ﬁrst step toward such understanding, consider a beam of monochromatic
light with frequencyω that impinges on a collection of molecules (or atoms or charged
particles) that are all in the same quantum mechanical state|1⟩. Suppose the molecules
haveasecondstate|2⟩withenergyE2 = E1 + ℏω.Thenthelightwillresonantlyexcite
the molecules from their initial state |1⟩to the higher state |2⟩, and in the process
photons will be absorbed (Fig. 10.1a). The strength of the interaction is proportional
to the beam’s energy ﬂux F. Stated more precisely, the rate of absorption of photons
10.2 Lasers
515

E2
ħω = E2 – E1
ħω = E2 – E1
E1
E2
E1
j2i
j1i
j2i
j1i
(a)
(b)
FIGURE 10.1 (a) Photon absorption. A photon with energy ℏω = E2 −E1 excites a
molecule from its ground state, with energy E1 to an excited state with energy E2
(as depicted by an energy-level diagram). (b) Stimulated emission. The molecule is
initially in its excited state, and the incoming photon stimulates it to deexcite into its
ground state, emitting a photon identical to the incoming one.
is proportional to the number ﬂux of photons in the beam, dn/dAdt = F/(ℏω), and
thence is proportional to F, in accord with the classical description of absorption.
Next suppose that when the light beam ﬁrst arrives, the atoms are all in the higher
state |2⟩rather than the lower state |1⟩. There will still be a resonant interaction, but
this time the interaction will deexcite the atoms, with an accompanying emission
of photons (Fig. 10.1b). As in the absorption case, the strength of the interaction is
proportionaltotheﬂuxoftheincomingbeam(i.e., therateofemissionofnewphotons
is proportional to the number ﬂux of photons that the beam already has), and thence
it is also proportional to the beam’s energy ﬂux F. A quantum mechanical analysis
shows that the photons from this stimulated emission come out in the same quantum
state as is occupied by the photons of the incoming beam (Bose-Einstein statistics:
photons, being bosons, tend to congregate in the same state). Correspondingly, when
viewed classically, the beam’s ﬂux will be ampliﬁed at a rate proportional to its initial
ﬂux, with no change of its frequency, wave number, or phase.
In Nature, molecules usually have their energy levels populated in accord with
the laws of statistical (thermodynamic) equilibrium. Such thermalized populations,
as we saw at the end of Sec. 4.4.1, entail a ratio N2/N1 = exp[−(E2 −E1)/(kBT )]< 1
for the number N2 of molecules in state |2⟩to the number N1 in state |1⟩. Here T is
the molecular temperature, and for simplicity it is assumed that the states are nonde-
generate. Since there are more molecules in the lower state |1⟩than the higher one |2⟩,
an incoming light beam will experience more absorption than stimulated emission.
By contrast, occasionally in Nature and often in the laboratory a collection of
molecules develops a “population inversion” in which N2 > N1. The two states can
population inversion
then be thought of as having a negative temperature with respect to each other. Light
propagating through population-inverted molecules will experience more stimulated
emission than absorption (i.e., it will be ampliﬁed). The result is “light ampliﬁcation
by stimulated emission,” or “laser” action.
laser
This basic principle underlying the laser has been known since the early years
of quantum mechanics, but only in the 1950s did physicists succeed in designing,
constructing, and operating real lasers. The ﬁrst proposals for practical devices were
516
Chapter 10. Nonlinear Optics

j2i, metastable
j1i
absorption states
fast decay
fast decay
ground state
fast pump
transition
laser
transition
FIGURE 10.2 The mechanism for creating the population inversion that
underlies laser action. The horizontal lines and band represent energy
levels of a molecule, and the arrows represent transitions in which the
molecules are excited by pumping or decay by emission of photons.
made, independently, in the United States by Weber (1953) and Gordon, Zeiger, and
Townes (1954), and in the Soviet Union by Basov and Prokhorov (1954, 1955). The
ﬁrst successful construction and operation of a laser was by Gordon, Zeiger, and
Townes (1954, 1955), and soon thereafter by Basov and Prokhorov—though these
ﬁrst lasers actually used radiation not at optical frequencies but rather at microwave
frequencies and were based on a population inversion of ammonia molecules (see
Feynman, Leighton, and Sands, 2013, Chap. 9), and thus were called masers.The ﬁrst
optical frequency laser, one based on a population inversion of chromium ions in a
ruby crystal, was constructed and operated by Maiman (1960).
The key to laser action is the population inversion. Population inversions are
incompatible with thermodynamic equilibrium; thus, to achieve them, one must
manipulate the molecules in a nonequilibrium way. This is usually done by some con-
crete variant of the process shown in the energy-level diagram of Fig. 10.2. Some sort
of pump mechanism (to be discussed in the next section) rapidly excites molecules
pump mechanism
from the ground state into some group of absorption states. The molecules then de-
cay rapidly from the absorption states into the state |2⟩, which is metastable (i.e., has
a long lifetime against spontaneous decay), so the molecules linger there. The laser
transition is from state |2⟩to state |1⟩. Once a molecule has decayed into state |1⟩, it
quickly decays on down to the ground state and then may be quickly pumped back
up into the absorption states. This is called “four-level pumping.” It is instead called
“three-level pumping” if state |1⟩is the ground state.
If the pump acts suddenly and brieﬂy, this process produces a temporary popu-
lation inversion of states |2⟩and |1⟩, with which an incoming, weak burst of “seed”
light can interact to produce a burst of ampliﬁcation. The result is a pulsed laser. If
pulsed lasers and
continuous-wave lasers
the pump acts continuously, the result may be a permanently maintained population
inversion with which continuous seed light can interact to produce continuous-wave
laser light.
10.2 Lasers
517

escaping
laser light
active
medium
FIGURE 10.3 The use of a Fabry-Perot cavity to enhance the
interaction of the light in a laser with its active medium.
As the laser beam travels through the active medium (the population-inverted
molecules), its ﬂux F builds up with distance z as dF/dz = F/ℓo, so F(z) = Foez/ℓo.
Here Fo is the initial ﬂux, and ℓo ≡1/|μ| (the e-folding length) depends on the
strength of the population inversion and the strength of the coupling between the
light and the active medium. Typically, ℓo is so long that strong lasing action cannot
be achieved by a single pass through the active medium. In this case, the lasing action
is enhanced by placing the active medium inside a Fabry-Perot cavity (Fig. 10.3 and
Sec. 9.4.3). The length L of the cavity is adjusted to maximize the output power, which
occurs when the lasing transition frequency ω = (E2 −E1)/ℏis an eigenfrequency
of the cavity. The lasing action then excites a standing wave mode of the cavity, from
which the light leaks out through one or both cavity mirrors. If F is the cavity’s ﬁnesse
[approximately the average number of times a photon bounces back and forth inside
the cavity before escaping through a mirror; cf. Eq. (9.39)], then the cavity increases
the distance that typical photons travel through the active medium by a factor ∼F,
thereby increasing the energy ﬂux of the light output by a factor ∼eFL/ℓo.
Typically, many modes of the Fabry-Perot cavity are excited, so the laser’s output
is multimodal and contains a mixture of polarizations. When a single mode and
polarization are desired, the polarization is made pure by oblique optical elements
at the ends of the laser that transmit only the desired polarization, and all the modes
except one are removed from the output light by a variety of techniques (e.g., ﬁltering
with a second Fabry-Perot cavity; Sec. 9.4.3).
For an ideal laser (one, e.g., with a perfectly steady pump maintaining a perfectly
steady population inversion that in turn maintains perfectly steady lasing), the light
comes out in the most perfectly classical state that quantum mechanics allows. This
coherent-state laser light
state, called a quantum mechanical coherent state,has a perfectly sinusoidally oscillat-
ing electric ﬁeld on which is superimposed the smallest amount of noise (the smallest
wandering of phase and amplitude) allowed by quantum mechanics: the noise of
quantum electrodynamical vacuum ﬂuctuations. The value of the oscillations’ well-
deﬁned phase is determined by the phase of the seed ﬁeld from which the coherent
state was built up by lasing. Real lasers have additional noise due to a variety of prac-
tical factors, but nevertheless, their outputs are usually highly coherent, with long
coherence times.
518
Chapter 10. Nonlinear Optics

10.2.2
10.2.2 Types of Lasers and Their Performances and Applications
Lasers can have continuous, nearly monochromatic output, or they can be pulsed.
Their active media can be liquids, gases (ionized or neutral), or solids (semi-
conductors, glasses, orcrystals; usuallycarefullydopedwithimpurities).Laserscanbe
laser pump mechanisms
pumped by radiation (e.g., from a ﬂash tube), by atomic collisions that drive the lasing
atoms into their excited states, by nonequilibrium chemical reactions, or by electric
ﬁelds associated with electric currents (e.g., in semiconductor diode lasers that can be
powered by ordinary batteries and are easily modulated for optical communication).
pulsed lasers
Lasers can be made to pulse by turning the pump on and off, by mode-locked
operation (Sec. 10.2.3), or by Q-switching (turning off the lasing, e.g., by inserting
into the Fabry-Perot cavity an electro-optic material that absorbs light until the pump
has produced a huge population inversion, and then suddenly applying an electric
ﬁeld to the absorber, which makes it transparent and restores the lasing).
Laser pulses can be as short as a few femtoseconds (thus enabling experimental
investigations of fast chemical reactions) and they can carry as much as 20,000 J with
duration of a few picoseconds and pulse power ∼1015 W (at the U.S. National Ignition
Facility in Livermore, California, for controlled fusion).
continuous lasers
The most powerful continuous laser in the United States is the Mid-Infrared
Advanced Chemical Laser (MIRACL), developed by the Navy to shoot down missiles
and satellites, with ∼1MW power in a 14 × 14 cm2 beam lasting ∼70 s. Continuous
CO2 lasers with powers ∼3 kW are used industrially for cutting and welding metal.
The beam from a Q-switched CO2 laser with ∼1GW power can be concentrated
intoaregionwithtransversedimensionsassmallasonewavelength(∼1 μm), yielding
a local energy ﬂux of 1021 W m−2, an rms magnetic ﬁeld strength of ∼3 kT, an electric
ﬁeld of ∼1 TV m−1, and an electrical potential difference across a wavelength of
∼1 MeV. It then should not be surprising that high-power lasers can create electron-
positron-pair plasmas!
For many applications, large power is irrelevant or undesirable, but high fre-
quency stability (a long coherence time) is often crucial. By locking the laser
locking a laser’s frequency
frequency to an optical frequency atomic transition (e.g., in the Al+ atomic clock;
see footnote in Sec. 6.6.1), one can achieve a frequency stability f/f ∼10−17, so
f ∼3 mHz, for hours or longer, corresponding to coherence times of ∼100 s and
coherence lengths of ∼3 × 107 km. By locking the frequency to a mode of a physi-
cally highly stable Fabry-Perot cavity (e.g., PDH locking; Sec. 9.4.3), stabilities have
been achieved as high as f/f ∼10−16 for times of ∼1hr in a physically solid cavity
(the superconducting cavity stabilized oscillator), and f/f ∼10−22 for a few ms
in LIGO’s 4-km-long cavity with freely hanging mirrors and sophisticated seismic
isolation (Sec. 9.5).
When ﬁrst invented, lasers were called “a solution looking for a problem.” Now
they permeate everyday life and high technology. Examples are supermarket bar-code
readers, laser pointers, DVD players, eye surgery, laser printers, laser cutting and
10.2 Lasers
519

welding, laser gyroscopes (which are standard on commercial aircraft), laser-based
surveying, Raman spectroscopy, laser fusion, optical communication, optically based
computers, holography, maser ampliﬁers, and atomic clocks.
10.2.3
10.2.3 Ti:Sapphire Mode-Locked Laser
As a concrete example of a modern, specialized laser, consider the titanium-sapphire
(Ti:sapphire) mode-locked laser (Cundiff, 2002) that is used to generate the optical
frequency comb described in Sec. 9.4.3. Recall that this laser’s light must be con-
centrated in a very short pulse that travels unchanged back and forth between its
Fabry-Perot mirrors. The pulse is made from phase-locked (Gaussian) modes of the
optical cavity that extend over a huge frequency band, ω ∼ω. Among other things,
this mode-locked laser illustrates the use of an optical nonlinearity called the “Kerr
effect,” whose underlying physics we describe later in this chapter (Sec. 10.8.3).
As we discussed in Sec. 9.4.3, this mode-locked laser must (i) more strongly
amplify modes with high energy ﬂux than with low (this pushes the light into the
short, high-ﬂux pulse), and (ii) its (Gaussian) modes must have a group velocity Vg
that is independent of frequency over the frequency band ω ∼ω (this enables the
pulse to stay short rather than disperse).
Figure 10.4 illustrates the Ti:sapphire laser that achieves this. The active medium is
a sapphire crystal doped with titanium ions. This medium exhibits the optical Kerr ef-
fect, which means that its index of refraction n is a sum of two terms, one independent
of the light’s energy ﬂux; the other proportional to the ﬂux [Eq. (10.69)]. The ﬂux-
dependent term slows the light’s speed near the beam’s center and thereby focuses the
beam, makingitscrosssectionsmaller.Acircularapertureattenuateslargelightbeams
but not small. As a result, the lasing is stronger the smaller the beam (which means
the higher its ﬂux). This drives the lasing light into the desired short, high-ﬂux pulse.
The Ti:sapphire crystal has a group velocity that increases with frequency. The two
prisms and mirror (Fig. 10.4) compensate this. The ﬁrst prism bends low-frequency
light more than high, so the high-frequency light traverses more glass in the second
prism and is slowed. By adjusting the mirror tilt, one adjusts the amount of slowing
to keep the round-trip-averaged phase velocity the same at high frequencies as at low.
mode-locked laser
produces frequency
comb
output
output
mirror
tiltable mirror
cavity
length
adjustment
group delay 
adjustment
aperture
prisms
pump
laser
Ti:sapphire
crystal
FIGURE 10.4 The Ti:sapphire mode-locked laser. Adapted from Cundiff (2002).
520
Chapter 10. Nonlinear Optics

The laser then generates multimode, high-intensity, pulsed light (with pulse durations
that can be as short as attoseconds, when augmented by a technique called chirped
pulse ampliﬁcation), resulting in the optical frequency comb of Sec. 9.4.3.
10.2.4
10.2.4 Free Electron Laser
The free electron laser is quite different from the lasers we have been discussing. A
collimated beam of essentially monoenergetic electrons (the population inversion)
passes through an undulator comprising an alternating transverse magnetic ﬁeld,
which causes the electrons to radiate X-rays along the direction of the beam. From a
classical perspective, this X-ray-frequency electromagnetic wave induces correlated
electron motions, which emit coherently, enhancing the X-ray wave. In other words,
the undulating electron beam lases.
As an example, the LINAC Coherent Light Source (LCLS) at SLAC National
Accelerator Laboratory can produce femtosecond pulses of keV X-rays with pulse
frequency 120 Hz and peak intensity ∼109 times higher than that achievable from a
conventional synchrotron. An upgrade, LCLS-II, is planned to start operating in 2020
with a pulse frequency ∼100 kHz and an increase in average brightness of ∼103.
EXERCISES
Exercise 10.1 Challenge: Nuclear Powered X-Ray Laser
A device much ballyhooed in the United States during the presidency of Ronald
Reagan, but thankfully never fully deployed, was a futuristic, superpowerful X-ray
laser pumped by a nuclear explosion. As part of Reagan’s Strategic Defense Initiative
(“Star Wars”), this laser was supposed to shoot down Soviet missiles.
How would you design a nuclear powered X-ray laser? The energy for the pump
comes from a nuclear explosion that you set off in space above Earth. You want to use
that energy to create a population inversion in an active medium that will lase at X-ray
wavelengths, and you want to focus the resulting X-ray beam onto an intercontinental
ballistic missile that is rising out of Earth’s atmosphere. What would you use for the
active medium? How would you guarantee that a population inversion is created in
the active medium? How would you focus the resulting X-ray beam? (Note: This is a
highly nontrivial exercise, intended more as a stimulus for thought than as a test of
one’s understanding of things taught in this book.)
10.3
10.3 Holography
Holography is an old1 and well-explored example of nonlinear optics—an example
in which the nonlinear interaction of light with itself is produced not in real time,
but rather by means of a recording followed by a later readout (e.g., Cathey, 1974;
Iizuka, 1987).
1.
Holography was invented by Dennis Gabor (1948) for use in electron microscopy. The ﬁrst practical
optical holograms were made in 1962, soon after lasers became available.
10.3 Holography
521

object
lens
illuminating
white light
photographic
plate
FIGURE 10.5 Ordinary photography.
By contrast with ordinary photography (Fig. 10.5), which produces a colored,
2-dimensional image of 3-dimensional objects, holography (Figs. 10.6 and 10.8)
normally produces a monochromatic 3-dimensional image of 3- dimensional ob-
jects. Roughly speaking, the two processes contain the same amount of information,
two items at each location in the image. For ordinary photography, they are the energy
ﬂux and color; for holography, the energy ﬂux and phase of monochromatic light.
It is the phase, lost from an ordinary photograph but preserved in holography, that
carries the information about the third dimension. Our brain deduces the distance to
a point on an object from the difference in the directions of propagation of the point’s
light as it arrives at our two eyes. Those propagation directions are encoded in the
light as variations of the phase with transverse location [see, e.g., the point-spread
function for a thin lens, Eq. (8.29)].
ordinary photography
In an ordinary photograph (Fig. 10.5), white light scatters off an object, with
different colors scattering at different strengths. The resulting colored light is focused
through a lens to form a colored image on a photographic plate or a CCD. The plate
or CCD records the color and energy ﬂux at each point or pixel in the focal plane,
thereby producing the ordinary photograph.
hologram
In holography, one records a hologram with ﬂux and phase information (see
Fig. 10.6), and one then uses the hologram to reconstruct the 3-dimensional, mono-
chromatic, holographic image (see Fig. 10.8).
10.3.1
10.3.1 Recording a Hologram
Consider, ﬁrst, the recording of the hologram. Monochromatic, linearly polarized
plane-wave light with electric ﬁeld
E = ℜ[ψ(x, y, z)e−iωt],
(10.1)
angular frequency ω, and wave number k = ω/c illuminates the object and also a
mirror, as shown in Fig. 10.6. The light must be spatially coherent over the entire
522
Chapter 10. Nonlinear Optics

object
object wave: O(x, y, z)eikz
mirror wave: Meik(z cos θo – y sin θo)
mirror
θo
illuminating
monochromatic
light
photographic
plate
y
z
FIGURE 10.6 Recording a hologram.
region of mirror plus object. The propagation vector k of the illuminating light lies in
the y-z plane at some angle θo to the z-axis, and the mirror lies in the x-y plane. The
mirror reﬂects the illuminating light, producing a so-called “reference beam,” which
reference beam or mirror
wave
we call the mirror wave:
ψmirror = Meik(z cos θo−y sin θo),
(10.2)
where M is a real constant. The object (shown in Fig. 10.6) scatters the illuminating
light, producing a wave that propagates in the z direction toward the recording
medium (a photographic plate, for concreteness). We call this the object wave and
object wave
denote it
ψobject = O(x, y, z)eikz.
(10.3)
It is the slowly varying complex amplitude O(x, y, z) of this object wave that carries
the 3-dimensional, but monochromatic, information about the object’s appearance.
Thus it is this O(x, y, z) that will be reconstructed in the second step of holography.
In the ﬁrst step (Fig. 10.6), the object wave propagates along the z direction to
the photographic plate (or, more commonly today, a photoresist) at z = 0, where it
interferes with the mirror wave to produce the transverse pattern of energy ﬂux
F(x, y) ∝|O + Me−iky sin θo|2
= M2 + |O(x, y, z = 0)|2 + O(x, y, z = 0)Meiky sin θo
+ O∗(x, y, z = 0)Me−iky sin θo.
(10.4)
(Here and throughout this chapter, * denotes complex conjugation.) The plate is
blackened at each point in proportion to this ﬂux. The plate is then developed, and
a positive or negative print (it doesn’t matter which because of Babinet’s principle,
10.3 Holography
523

(a)
(b)
(c)
y
x
y
x
FIGURE 10.7 (a) Ordinary photograph of an object. (b) Hologram of the same object. (c) Magniﬁcation
of the hologram. Photos courtesy Jason Sapan, Holographic Studios, New York City.
Sec. 8.3.3) is made on a transparent sheet of plastic or glass. This print, the hologram,
has a transmissivity as a function of x and y that is proportional to the ﬂux distribu-
tion (10.4):
hologram’s transmissivity
t(x, y) ∝M2 + |O(x, y, z = 0)|2 + O(x, y, z = 0)Meiky sin θo
+ O∗(x, y, z = 0)Me−iky sin θo.
(10.5)
In this transmissivity we meet our ﬁrst example of nonlinearity: t(x, y) contains a
hologram’s nonlinearity
nonlinear superposition of the mirror wave and the object wave. Stated more pre-
cisely, the superposition is not a linear sum of wave ﬁelds, but instead is a sum
of products of one wave ﬁeld with the complex conjugate of another wave ﬁeld.
A further nonlinearity will arise in the reconstruction of the holographic image
[Eq. (10.7)].
Figure 10.7 shows an example. Figure 10.7a is an ordinary photograph of an object,
Fig. 10.7b is a hologram of the same object, and Fig. 10.7c is a blow-up of a portion
of that hologram. The object is not at all recognizable in the hologram, because the
object wave O was not focused to form an image at the plane of the photographic
plate. Rather, light from each region of the object was scattered to and recorded by all
regions of the photographic plate. Nevertheless, the plate contains the full details of
hologram’s information
encoding
the scattered light O(x, y, z = 0), including its phase. That information is recorded
in the piece M(Oeiky sin θo + O∗e−iky sin θo) = 2M ℜ(Oeiky sin θo) of the hologram’s
transmissivity. This piece oscillates sinusoidally in the y direction with wavelength
2π/(k sin θo); and the amplitude and phase of its oscillations are modulated by the
object wave O(x, y, z = 0). Those modulated oscillations show up clearly when one
magniﬁes the hologram (Fig. 10.7c); they turn the hologram into a sort of diffraction
grating, with the object wave O(x, y, z = 0) encoded as variations of the darkness
and spacings of the grating lines.
524
Chapter 10. Nonlinear Optics

virtual
image
secondary
real image
reference wave:
Re–ik sin θo y eik cos θo z
reconstructed object wave:
const × MRO(x, y, z)eikz
phase conjugated object wave:
const × MRO*e–ik sin θs y eik cos θs z
hologram: T(x, y) = M2 + |O(x, y, z = 0)|2 + O(x, y, z = 0)Me+ik y sin θo
+ O*(x, y, z = 0)Me–ik y sin θo
modulated mirror wave:
const × R(|O|2 + M2)e–ik sin θo y eik cos θo z
θo
θo
θs
y
z
FIGURE 10.8 Reconstructing the holographic image from the hologram. Note that sin θs = 2 sin θo.
What about the other pieces of the transmissivity (10.5), which superpose linearly
on the diffraction grating? One piece, t ∝M2, is spatially uniform and thus has no
effectexcepttomakethelightestpartsofthehologramslightlygrayratherthanleaving
it absolutely transparent (since this hologram is a negative rather than a positive). The
other piece, t ∝|O|2, is the ﬂux of the object’s unfocused, scattered light. It produces
a graying and whitening of the hologram (Fig. 10.7b) that varies on lengthscales long
compared to the grating’s wavelength 2π/(k sin θo) and thus blots out the diffraction
grating a bit here and there, but it does not change the amplitude or phase of the
grating’s modulation.
10.3.2
10.3.2 Reconstructing the 3-Dimensional Image from a Hologram
To reconstruct the object’s 3-dimensional wave, O(x, y, z)eikz, one sends through
the hologram monochromatic, plane-wave light identical to the mirror light used in
reference beam for
reconstructing
3-dimensional image
making the hologram (Fig. 10.8). If, for pedagogical simplicity, we place the hologram
at the same location z = 0 as was previously occupied by the photographic plate, then
the incoming light has the same form (10.2) as the original mirror wave, but with an
amplitude that we denote as R, corresponding to the phrase reference beam that is
used to describe this incoming light:
ψreference = Reik(z cos θo−y sin θo).
(10.6)
In passing through the hologram at z = 0, this reference beam is partially absorbed
and partially transmitted. The result, immediately on exiting from the hologram,
10.3 Holography
525

is a reconstructed light-wave ﬁeld whose value and normal derivative are given by
[cf. Eq. (10.5)]
reconstructed wave
ψreconstructed
888
z=0 ≡R(x, y, z = 0) = t(x, y)Re−iky sin θo
=

M2 + |O(x, y, z = 0)|2
Re−iky sin θo
+ MRO(x, y, z = 0)
+ MRO∗(x, y, z = 0)e−i2ky sin θo;
ψreconstructed,z
888
z=0 ≡Z(x, y, z = 0) = ik cos θoR(x, y, z = 0).
(10.7)
This ﬁeld and normal derivative act as initial data for the subsequent evolution of the
reconstructed wave. Note that the ﬁeld and derivative, and thus also the reconstructed
wave, are triply nonlinear: each term in Eq. (10.7) is a product of (i) the original
mirror wave M used to construct the hologram or the original object wave O, (ii) O∗
or M∗= M, and (iii) the reference wave R that is being used in the holographic
reconstruction.
The evolution of the reconstructed wave beyond the hologram (at z > 0) can be
computedbycombiningtheinitialdata[Eq.(10.7)]forψreconstructed andψreconstructed,z
at z = 0 with the Helmholtz-Kirchhoff formula (8.4); see Exs. 10.2 and 10.6. From
the four terms in Eq. (10.7) [which arise from the four terms in the hologram’s
transmissivity t(x, y), Eq. (10.5)], the reconstruction produces four wave ﬁelds; see
Fig. 10.8. The direction of propagation of each of these waves can easily be inferred
from the vertical spacing of its phase fronts along the outgoing face of the hologram,
or equivalently, from the relation ∂ψreconstructed/∂y = ikyψreconstructed = −ik sin θψ,
where θ is the angle of propagation relative to the horizontal z direction. Since,
immediately in front of the hologram, ψreconstructed = R, the propagation angle is
sin θ = ∂R/∂y
−ikR .
(10.8)
Comparing with Eqs. (10.5) and (10.7), we see that the ﬁrst two, slowly spatially
varying, terms in the transmissivity, t ∝M2 and T ∝|O|2, both produce waves that
propagate in the same direction as the reference wave, θ = θo. This combined wave
has an uninteresting, smoothly and slowly varying energy-ﬂux pattern.
The two diffraction-grating terms in the hologram’s transmissivity produce two
interesting waves. One, arising from t ∝O(x, y, z = 0)Meiky sin θo [and produced
by the MRO term of the initial conditions (10.7)], is precisely the same object wave
object wave and its
3-dimensional image
ψobject = O(x, y, z)eikz (aside from overall amplitude) as one would have seen while
making the hologram if one had replaced the photographic plate by a window and looked
through it. This object wave, carrying [encoded in O(x, y, z)] the holographic image
with full 3-dimensionality, propagates in the z direction, θ = 0.
526
Chapter 10. Nonlinear Optics

The transmissivity’s second diffraction-grating term,
secondary (phase
conjugate) wave
t ∝O∗(x, y, z = 0)Me−iky sin θo,
acting via the MRO∗term of the initial conditions (10.7), gives rise to a sec-
ondary wave, which [according to Eq. (10.8)] propagates at an angle θs to the z-axis,
where
sin θs = 2 sin θo.
(10.9)
(If θo > 30◦, then 2 sin θo > 1, which means θs cannot be a real angle, and there will be
no secondary wave.) This secondary wave, if it exists, carries an image that is encoded
in the complex conjugate O∗(x, y, z = 0) of the transverse (i.e., x, y) part of the original
object wave.Since complex conjugation of an oscillatory wave just reverses the sign of
the wave’s phase, this wave in some sense is a “phase conjugate” of the original object
wave.
When one recalls that the electric and magnetic ﬁelds that make up an electro-
magnetic wave are actually real rather than complex, and that we are using com-
plex wave ﬁelds to describe electromagnetic waves only for mathematical conve-
nience, one then realizes that this phase conjugation of the object wave is actually
a highly nonlinear process. There is no way, by linear manipulations of the real elec-
tric and magnetic ﬁelds, to produce the phase-conjugated wave from the original
object wave.
In Sec. 10.4 we develop in detail the theory of phase-conjugated waves, and in
Ex. 10.6, we relate our holographically constructed secondary wave to that theory.
As we shall see, our secondary wave is not quite the same as the phase-conjugated
object wave, but it is the same aside from some distortion along the y direction and
a change in propagation direction. More speciﬁcally, if one looks into the object wave
object wave’s image is
virtual
with one’s eyes (i.e., if one focuses it onto one’s retinas), one sees the original object
in all its 3-dimensional glory, though single colored, sitting behind the hologram at the
object’s original position (shown in Fig. 10.8). Because the image one sees is behind the
hologram, it is called a virtual image.If, instead, one looks into the secondary wave with
secondary wave’s image is
real
one’s eyes,one sees the original 3-dimensional object, sitting in front of the hologram but
turned inside out and distorted (also shown in the ﬁgure). For example, if the object
is a human face, the secondary image looks like the interior of a mask made from
that human face, with distortion along the y direction. Because this secondary image
appears to be in front of the hologram, it is called a real image—even though one can
pass one’s hands through it and feel nothing but thin air.
10.3.3
10.3.3 Other Types of Holography; Applications
There are many variants on the basic holographic technique depicted in Figs. 10.6–
10.8. These include the following.
10.3 Holography
527

PHASE HOLOGRAPHY
Instead of darkening the high-ﬂux regions of the hologram as in photography, one
produces a phase-shifting screen, whose phase shift (due to thickening of the holo-
gram’s material) is proportional to the incoming ﬂux. Such a phase hologram trans-
mits more of the reference-wave light than a standard, darkened hologram, thus
making a brighter reconstructed image.
VOLUME HOLOGRAPHY
The hologram is a number of wavelengths deep rather than being just 2-dimensional.
For example, it could be made from a thick photographic emulsion, in which the
absorption length for light is longer than the thickness. Such a hologram has a 3-
3-dimensional gratings
dimensionalgratingstructure(grating“surfaces”ratherthangrating“lines”), withtwo
consequences. When one reconstructs the holographic image from it in the manner
of Fig. 10.8, (i) the third dimension of the grating suppresses the secondary wave
while enhancing the (desired) object wave, so more power goes into it; and (ii) the
referencewave’sincomingangleθo mustbecontrolledmuchmoreprecisely, asmodest
errors suppress the reconstructed object wave. This second consequence enables one
to record multiple images in a volume hologram, each using its own angle θo for the
illuminating light and reference wave.
REFLECTION HOLOGRAPHY
One reads out the hologram by reﬂecting light off of it rather than transmitting
light through it, and the hologram’s diffraction grating produces a 3-dimensional
holographic image by the same process as in transmission; see Ex. 10.3.
WHITE-LIGHT HOLOGRAPHY
The hologram is recorded with monochromatic light as usual, but it is optimized for
reading out with white light. Even for the simple 2-dimensional hologram of Fig. 10.8,
if one sends in white light at the angle θo, one will get a 3-dimensional object wave:
the hologram’s grating will diffract various wavelengths in various directions. In the
colored holograms
direction of the original object wave (the horizontal direction in Fig. 10.8), one gets a
3-dimensional reconstructed image of the same color as was used when constructing
the hologram. When one moves away from that direction (vertically in Fig. 10.8), one
sees the color of the 3-dimensional image continuously change (Ex. 10.2b). White-
light reﬂection holograms are used on credit cards and money as impediments to
counterfeiting; they have even been used on postage stamps.
COMPUTATIONAL HOLOGRAMS
Just as one can draw 2-dimensional pictures numerically, pixel-by-pixel, so one can
also create and modify holograms numerically, then read them out optically.
FULL-COLOR HOLOGRAPHY
A full-color holographic image of an object can be constructed by superposing three
monochromatic holographic images with the three primary colors—red, green, and
528
Chapter 10. Nonlinear Optics

FIGURE 10.9 In-and-out vibrations of a guitar body visualized via holographic interferometry with
green light. The dark and bright curves are a contour map, in units of the green light’s wavelength, of
the amplitude of vibration. Image courtesy Bernard Richardson, Cardiff University.
blue. One way to achieve this is to construct a single volume hologram using illu-
combining red, green, and
blue holograms
minating light from red, green, and blue laser beams, each arriving from a different
2-dimensional direction θo. Each beam produces a diffraction grating in the holo-
gram with a different orientation and with spatial wave number corresponding to the
beam’s color. The 3-dimensional image can then be reconstructed using three white-
light reference waves, one from each of the original three directions θo. The hologram
will pick out of each beam the appropriate primary color, and produce the desired
three overlapping images, which the eye will interpret as having approximately the
true colors of the original object.
HOLOGRAPHIC INTERFEROMETRY
One can observe changes in the shape of a surface at about the micrometer level by
constructing two holograms, one of the original surface and the other of the changed
surface, and then interfering the reconstructed light from the two holograms. Among
other things, this holographic interferometry is used to observe small strains and
vibrations of solid bodies—for example, sonic vibrations of a guitar in Fig. 10.9.
HOLOGRAPHIC LENSES
Instead of designing a hologram to reconstruct a 3-dimensional image, one can
design it to manipulate light beams in most any way one wishes. As a simple example
(Ex. 10.4c) of such a holographic lens, one can construct a holographic lens that
10.3 Holography
529

splits one beam into two and focuses each of the two beams on a different spot.
Holographic lenses are widely used in everyday technology, for example, to read bar
codes in supermarket checkouts and to read the information off CDs, DVDs, and BDs
(Ex. 10.5).
FUTURE APPLICATIONS
Major applications of holography that are under development include (i) dynamically
changing volume holograms for 3-dimensional movies (which, of course, will require
no eye glasses), and (ii) volume holograms for storage of large amounts of data—up
to terabytes cm−3.
EXERCISES
Exercise 10.2 Derivation and Problem: Holographically Reconstructed Wave
(a) Use the Helmholtz-Kirchhoff integral (8.4) or (8.6) to compute all four pieces of
the holographically reconstructed wave ﬁeld. Show that the piece generated by
t ∝O(x, y, z = 0)Meiky sin θo
is the same (aside from overall amplitude) as the ﬁeld ψobject = O(x, y, z)e−iωt
that would have resulted if when making the hologram (Fig. 10.6), the mir-
ror wave had been absent and the photographic plate replaced by a window.
Show that the other pieces have the forms and propagation directions indicated
heuristically in Fig. 10.8. We shall examine the secondary wave, generated by
t ∝MO∗e−iky sin θo, in Ex. 10.6.
(b) Suppose that plane-parallel white light is used in the holographic reconstruction
of Fig. 10.8. Derive an expression for the direction in which one sees the object’s
3-dimensional image have a given color (or equivalently, wave number). Assume
that the original hologram was made with green light and θo = 45◦. What are the
angles at which one sees the image as violet, green, yellow, and red?
Exercise 10.3 Problem: Recording a Reﬂection Hologram
How would you record a hologram if you want to read it out via reﬂection? Draw
diagrams illustrating this, similar to Figs. 10.6 and 10.8. [Hint: The mirror wave
and object wave can impinge on the photographic plate from either side; it’s your
choice.]
Exercise 10.4 Example: Holographic Lens to Split and Focus a Light Beam
A holographic lens, like any other hologram, can be described by its transmissivity
t(x, y).
(a) What t(x, y) will take a reference wave, impinging from the θo direction (as in
Fig. 10.8) and produce from it a primary object wave that converges on the spot
530
Chapter 10. Nonlinear Optics

(x, y, z) = (0, 0, d)? [Hint: Consider, at the hologram’s plane, a superposition of
the incoming mirror wave and the point-spread function (8.28), which represents
a beam that diverges from a point source. Then phase conjugate the point-spread
function, so it converges to a point instead of diverging.]
(b) Draw a contour plot of the transmissivity t(x, y) of the lens in part (a). Notice
the resemblance to the Fresnel zone plate of Sec. 8.4.4. Explain the connection of
the two, paying attention to how the holographic lens changes when one alters
the chosen angle θo of the reference wave.
(c) What t(x, y) will take a reference wave, impinging from the θo direction, and pro-
duce from it a primary wave that splits in two, with equal light powers converging
on the spots (x, y, z) = (−a, 0, d) and (x, y, z) = (+a, 0, d)?
Exercise 10.5 **Problem: CDs, DVDs, and BDs
Information on CDs, DVDs, and BDs (compact, digital video, and blu-ray disks) is
recorded and read out using holographic lenses, but it is not stored holographically.
Rather, it is stored in a linear binary code consisting of pits and no-pits (for 0 and 1)
along a narrow spiraling track. In each successive generation of storage device, the
laser light has been pushed to a shorter wavelength (λ = 780 nm for CDs, 650 nm for
DVDs, and 405 nm for BDs), and in each generation, the efﬁciency of the information
storage has been improved. In CDs, the information is stored in a single holographic
layer on the surface of the disk; in DVDs and BDs, it is usually stored in a single layer
but can also be stored in as many as four layers, one above the other, though with a
modest price in access time.
(a) Explain why one can expect to record in a disk’s recording layer, at the very most,
(close to) four bits of information per square wavelength of the recording light.
(b) The actual storage capacities are up to 900 MB for CDs, 4.7 GB for DVDs, and
25 GB for BDs. How efﬁcient are each of these technologies relative to the maxi-
mum given in part (a)?
(c) Estimate the number of volumes of the Encyclopedia Britannica that can be
recorded on a CD, on a DVD, and on a BD.
10.4
10.4 Phase-Conjugate Optics
Nonlinear optical techniques make it possible to phase conjugate an optical wave
in real time, by contrast with holography, where the phase conjugation requires
recording a hologram and then reconstructing the wave later. In this section, we
explore the properties of phase-conjugated waves of any sort (light, sound, plasma
waves, etc.), and in the next section, we discuss technology by which real-time phase
conjugation is achieved for light.
10.4 Phase-Conjugate Optics
531

The basic ideas and foundations for phase conjugation of waves were laid in
Moscow by Boris Yakovovich Zel’dovich2 and his colleagues (1972) and at Caltech
by Amnon Yariv (1978).
phase conjugation
Phase conjugation is the process of taking a monochromatic wave
!O = ℜ[ψ(x, y, z)e−iωt]= 1
2(ψe−iωt + ψ∗e+iωt),
(10.10a)
and from it constructing the wave
!PC = ℜ[ψ∗(x, y, z)e−iωt]= 1
2(ψ∗e−iωt + ψe+iωt).
(10.10b)
Notice that the phase-conjugated wave !PC is obtainable from the original wave !O
phase-conjugating mirror
by time reversal, t →−t. This has a number of important consequences. One is that
!PC propagates in the opposite direction to !O. Others are explained most clearly
with the help of a phase-conjugating mirror.
Consider a wave !O with spatial modulation (i.e., a wave that carries a picture or a
signalofsomesort).Letthewavepropagateinthez direction(rightwardinFig.10.10),
so that
incoming wave
ψ = A(x, y, z)ei(kz−ωt),
(10.11)
where A = Aeiϕ is a complex amplitude whose modulus A and phase ϕ change
slowly in x, y, and z (slowly compared to the wave’s wavelength λ = 2π/k). Suppose
that this wave propagates through a time-independent medium with slowly varying
physical properties [e.g., a dielectric medium with slowly varying index of refraction
n(x, y, z)]. These slow variations will distort the wave’s complex amplitude as it
propagates. The wave equation for the real, classical ﬁeld ! = ℜ[ψe−iωt]will have the
form L! −∂2!/∂t2 = 0, where L is a real spatial differential operator that depends
on the medium’s slowly varying physical properties. This wave equation implies that
the complex ﬁeld ψ satisﬁes
Lψ + ω2ψ = 0
(10.12)
[which is the Helmholtz equation (8.1b) if L is the vacuum wave operator]. Equation
(10.12) is the evolution equation for the wave’s complex amplitude.
Let the distorted, rightward propagating wave !O reﬂect off a mirror located at
z = 0. If the mirror is a phase-conjugating one, then very near it (at z near zero) the
reﬂected wave will have the form
phase conjugating mirror
and its phase conjugated
wave !PC
!PC
!PC
!PC = ℜ[A∗(x, y, z = 0)ei(−kz−ωt)],
(10.13)
2.
Zel’dovich is the famous son of a famous Russian/Jewish physicist, Yakov Borisovich Zel’dovich, who
with Andrei Dmitrievich Sakharov fathered the Soviet hydrogen bomb and then went on to become a
dominant ﬁgure internationally in astrophysics and cosmology.
532
Chapter 10. Nonlinear Optics

phase-conjugating
mirror
ordinary mirror
incoming wave O
incoming wave O
incoming wave O
incoming wave O
reflected wave PC
reflected wave PC
reflected wave R
reflected wave R
medium
(a)
(b)
medium
FIGURE 10.10 A rightward propagating wave and the reﬂected wave produced by (a) an
ordinary mirror and (b) a phase-conjugating mirror. In both cases the waves propagate
through a medium with spatially variable properties, which distorts their phase fronts. In
case (a) the distortion is reinforced by the second passage through the variable medium;
in case (b) the distortion is removed by the second passage.
while if it is an ordinary mirror, then the reﬂected wave will be
ordinary mirror and its
reﬂected wave !R
!R
!R
!R = ℜ[±A(x, y, z = 0)ei(−kz−ωt)].
(10.14)
(Here the sign depends on the physics of the wave. For example, if ! is the transverse
electric ﬁeld of an electromagnetic wave and the mirror is a perfect conductor, the sign
will be minus to guarantee that the total electric ﬁeld, original plus reﬂected, vanishes
at the mirror’s surface.)
These two waves, the phase-conjugated one !PC and the ordinary reﬂected one
!R, have very different surfaces of constant phase (phase fronts). The phase of the
phase fronts of
!PC
!PC
!PC and !R
!R
!R
incoming wave !O [Eqs. (10.10a) and (10.11)] as it nears the mirror (z = 0) is ϕ + kz,
so (taking account of the fact that ϕ is slowly varying) the surfaces of constant phase
are z = −ϕ(x, y, z = 0)/k. Similarly, the phase of the wave !R [Eq. (10.14)] reﬂected
from the ordinary mirror is ϕ −kz, so its surfaces of constant phase near the mirror
are z = +ϕ(x, y, z = 0)/k, which are reversed from those of the incoming wave, as
shown in the upper right of Fig. 10.10. Finally, the phase of the wave !PC [Eq. (10.13)]
reﬂected from the phase-conjugating mirror is −ϕ −kz, so its surfaces of constant
phase near the mirror are z = −ϕ(x, y, z = 0)/k, which are the same as those of the
10.4 Phase-Conjugate Optics
533

first fiber segment
second fiber segment
identical to first
beam
splitter
ordinary
mirror
phase-
conjugating
mirror
FIGURE 10.11 The use of a phase-conjugating mirror in an optical transmission line to prevent the ﬁber
from distorting an optical image. The distortions put onto the image as it propagates through the ﬁrst
segment of ﬁber are removed during propagation through the second segment.
incoming wave (lower right of Fig. 10.10), even though the two waves are propagating
in opposite directions.
The phase fronts of the original incoming wave and the phase-conjugated wave are
the same not only near the phase-conjugating mirror; they are the same everywhere.
More speciﬁcally, as the phase-conjugated wave !PC propagates away from the mirror
[near which it is described by Eq. (10.13)], the propagation equation (10.12) forces
it to evolve in such a way as to remain always the phase conjugate of the incoming
wave:
!PC = ℜ[A∗(x, y, z)e−ikze−iωt].
(10.15)
This should be obvious: because the differential operator L in the propagation equa-
tion (10.12) for ψ(x, y, z) = Aeikz is real, ψ∗(x, y, z) = A∗e−ikz will satisfy this
propagation equation when ψ(x, y, z) does.
That the reﬂected wave !PC always remains the phase conjugate of the incoming
wave !O means that the distortions put onto the incoming wave, as it propagates
distortion removal in !PC
!PC
!PC
rightward through the inhomogeneous medium, get removed from the phase-conjugated
wave as it propagates back leftward (Fig. 10.10).
This removal of distortions has a number of important applications. One is for
image transmission in optical ﬁbers. Normally when an optical ﬁber is used to trans-
mit an optical image, the transverse spatial variations n(x, y) of the ﬁber’s index of
refraction (which are required to hold the light in the ﬁber; Ex. 7.8) distort the image
somewhat. The distortions can be eliminated by using a sequence of identical seg-
ments of optical ﬁbers separated by phase-conjugating mirrors (Fig. 10.11). A few
other applications include (i) real-time holography; (ii) removal of phase distortions
in Fabry-Perot cavities by making one of the mirrors a phase-conjugating one, with a
resulting improvement in the shape of the beam that emerges from the cavity; (iii) de-
vices that can memorize an optical image and compare it to other images; (iv) the
production of squeezed light (Ex. 10.16); and (v) improved focusing of laser light for
laser fusion.
534
Chapter 10. Nonlinear Optics

As we shall see in the next section, phase-conjugating mirrors rely crucially on
the sinusoidal time evolution of the wave ﬁeld; they integrate that sinusoidal evolu-
tion coherently over some timescale ˆτ (typically microseconds to nanoseconds) to
produce the phase-conjugated wave. Correspondingly, if an incoming wave varies on
timescales τ long compared to this ˆτ (e.g., if it carries a temporal modulation with
bandwidth ω ∼1/τ small compared to 1/ˆτ), then the wave’s temporal modulations
will not be time reversed by the phase-conjugating mirror. For example, if the wave
impinging on a phase-conjugating mirror has a frequency that is ωa initially, and then
gradually, over a time τ, increases to ωb = ωa + 2π/τ, then the phase-conjugated
wave will not emerge from the mirror with frequency ωb ﬁrst and ωa later. Rather,
it will emerge with ωa ﬁrst and ωb later (same order as for the original wave). When
the incoming wave’s temporal variations are fast compared to the mirror’s integration
time, τ ≪ˆτ, the mirror encounters a variety of frequencies during its integration time
and ceases to function properly. Thus, even though phase conjugation is equivalent to
phase conjugation and
time reversal
time reversal in a formal sense, a phase-conjugating mirror cannot time reverse a tem-
poral signal. It only time reverses monochromatic waves (which might carry a spatial
signal).
EXERCISES
Exercise 10.6 Derivation and Example: Secondary Wave in Holography
Consider the secondary wave generated by t ∝MO∗e−iky sin θo in the holographic
reconstruction process of Fig. 10.8, Eq. (10.7), and Ex. 10.2.
(a) Assume, for simplicity, that the mirror and reference waves propagate nearly
perpendicular to the hologram, so θo ≪90◦and θs ≃2θo ≪90◦; but assume
that θs is still large enough that fairly far from the hologram the object wave and
secondary waves separate cleanly from each other. Then, taking account of the
factthattheobjectwaveﬁeldhastheformO(x, y, z)eikz, showthatthesecondary
wave is the phase-conjugated object wave deﬁned in this section, except that it is
propagating in the +z direction rather than −z (i.e., it has been reﬂected through
the z = 0 plane). Then use this and the discussion of phase conjugation in the
text to show that the secondary wave carries an image that resides in front of the
hologram and is turned inside out, as discussed near the end of Sec. 10.3. Show,
further, that if θo is not ≪90◦(but is < 30◦, so θs is a real angle, and the secondary
image actually exists), then the secondary image is changed by a distortion along
the y direction. What is the nature of the distortion, a squashing or a stretch?
(b) Suppose that a hologram has been made with θo < 30◦. Show that it is possible
to perform image reconstruction with a modiﬁed reference wave (different from
Fig. 10.8) in such a manner that the secondary, phase-conjugated wave emerges
precisely perpendicular to the hologram and undistorted.
10.4 Phase-Conjugate Optics
535

10.5
10.5 Maxwell’s Equations in a Nonlinear Medium;
Nonlinear Dielectric Susceptibilities; Electro-Optic Effects
In nonlinear optics, one is often concerned with media that are electrically polarized
with polarization (electric dipole moment per unit volume) P but have no free charges
or currents and are unmagnetized. In such a medium the charge and current densities
associated with the polarization are
ρP = −∇. P,
jP = ∂P
∂t ,
(10.16a)
and Maxwell’s equations in SI units take the form
∇. E = ρP
ϵ0
,
∇. B = 0,
∇× E = −∂B
∂t ,
∇× B = μ0

jP + ϵ0
∂E
∂t

, (10.16b)
which should be familiar. When rewritten in terms of the electric displacement vector
D ≡ϵ0E + P,
(10.17)
these Maxwell equations take the alternative form
∇. D = 0,
∇. B = 0,
∇× E = −∂B
∂t ,
∇× B = μ0
∂D
∂t ,
(10.18)
which should also be familiar. By taking the curl of the third equation (10.16b), using
the relation ∇× ∇× E = −∇2E + ∇(∇. E), and combining with the time derivative
of the fourth equation (10.16b) and with ϵ0μ0 = 1/c2 and jP = ∂P/∂t, we obtain the
following wave equation for the electric ﬁeld, sourced by the medium’s polarization:
wave equation for light in a
polarizable medium
∇2E −∇(∇. E) = 1
c2
∂2(E + P/ϵ0)
∂t2
.
(10.19)
If the electric ﬁeld is sufﬁciently weak and the medium is homogeneous and
isotropic (the case treated in most textbooks on electromagnetic theory), the polariza-
tion P is proportional to the electric ﬁeld: P = ϵ0χ0E, where χ0 is the medium’s electri-
cal susceptibility. In this case the medium does not introduce any nonlinearities into
Maxwell’sequations, theright-handsideofEq.(10.19)becomes[(1+ χ0)/c2]∂2E/∂t2,
the divergence of Eq. (10.19) implies that the divergence of E vanishes, and therefore
Eq. (10.19) becomes the standard dispersionless wave equation:
∇2E −n2
c2
∂2E
∂t2 = 0,
with
n2 = 1 + χ0.
(10.20)
In many dielectric media, however, a strong electric ﬁeld can produce a polariza-
tion that is nonlinear in the ﬁeld. In such nonlinear media, the general expression for
the (real) polarization in terms of the (real) electric ﬁeld is
polarization in a nonlinear
medium
Pi = ϵ0(χijEj + 2dijkEjEk + 4χijklEjEkEl + . . .),
(10.21)
536
Chapter 10. Nonlinear Optics

where we sum over repeated indices. Here χij, the linear susceptibility, is proportional
to the 3-dimensional metric, χij = χ0gij = χ0δij, if the medium is isotropic (i.e., if
all directions in it are equivalent), but otherwise it is tensorial; and the dijk and χijkl
are nonlinear susceptibilities, referred to as second-order and third-order,respectively,
second-order and
third-order nonlinear
susceptibilities
because of the two and three E terms that multiply them in Eq. (10.21). The nor-
malizations used for these second- and third-order susceptibilities differ from one
researcher to another: sometimes the factor ϵ0 is omitted in Eq. (10.21); occasionally
the factors of 2 and 4 are omitted. A compressed 2-index notation is sometimes used
for the components of dijk; see Box 10.2 in Sec. 10.6.
With P given by Eq. (10.21), the wave equation (10.19) becomes
dielectric tensor ϵij
ϵij
ϵij
∇2E −∇(∇. E) −1
c2ϵ . ∂2E
∂t2 =
1
c2ϵ0
∂2 PNL
∂t2
,
where
ϵij = δij + χij
(10.22a)
is the “dielectric tensor,” and PNL is the nonlinear part of the polarization:
P NL
i
= ϵ0(2dijkEjEk + 4χijklEjEkEl + . . .).
(10.22b)
When PNL is strong enough to be important and a monochromatic wave at fre-
quency ω enters the medium, the nonlinearities lead to harmonic generation—the
harmonic generation by
nonlinearities
production of secondary waves with frequencies 2ω, 3ω, . . . ; see Secs. 10.7.1 and
10.8.1.Asaresult, anelectricﬁeldinthemediumcannotoscillateatjustonefrequency,
and each of the electric ﬁelds in expression (10.22b) for the nonlinear polarization
must be a sum of pieces with different frequencies. Because the susceptibilities can de-
pend on frequency, this means that, when using expression (10.21), one sometimes
must break up Pi and each Ei into its frequency components and use different values
of the susceptibility to couple the different frequencies together. For example, one of
the terms in Eq. (10.22b) will become
P (4)
i
= 4ϵ0χijkl E(1)
j
E(2)
k
E(3)
l
,
(10.23)
where E(n)
j
oscillates at frequency ωn, P (4)
i
oscillates at frequency ω4, and χijkl de-
pends on the four frequencies ω1, . . . , ω4. Although this is complicated in the gen-
eral case, in most practical applications, resonant coupling (or equivalently, energy
and momentum conservation for photons) guarantees that only a single set of fre-
quencies is important, and the resulting analysis simpliﬁes substantially (see, e.g.,
Sec. 10.6.1).
Because all the tensor indices on the susceptibilities except the ﬁrst index get con-
tracted into the electric ﬁeld in expression (10.21), we are free (and it is conventional)
to deﬁne the susceptibilities as symmetric under interchange of any pair of indices
that does not include the ﬁrst. When [as has been tacitly assumed in Eq. (10.21)]
10.5 Maxwell’s Equations in a Nonlinear Medium
537

there is no hysteresis in the medium’s response to the electric ﬁeld, the energy density
of interaction between the polarization and the electric ﬁeld is
polarizational energy
density
U = ϵ0
χijEiEj
2
+
2dijkEiEjEk
3
+
4χijklEiEjEkEl
4
+ . . .

,
(10.24a)
and the polarization is related to this energy of interaction, in Cartesian coordi-
nates, by
Pi = ∂U
∂Ei
,
(10.24b)
which agrees with Eq. (10.21) providing the susceptibilities are symmetric under inter-
change of all pairs of indices, including the ﬁrst. We shall assume such symmetry.3 If
the crystal is isotropic (as will be the case if it has cubic symmetry and reﬂection
symmetry), then each of its tensorial susceptibilities is constructable from the metric
gij = δij and a single scalar susceptibility (see Ex. 10.7):4
susceptibilities for
isotropic crystal
χij = χ0gij,
dijk = 0,
χijkl = 1
3χ4(gijgkl + gikgjl + gilgjk),
χijklm = 0, . . . .
(10.25)
A simple model of a crystal that explains how nonlinear susceptibilities can arise
is the following. Imagine each ion in the crystal as having a valence electron that can
oscillateinresponsetoasinusoidalelectricﬁeld.Theelectroncanberegardedasresid-
ing in a potential well, which, for low-amplitude oscillations, is very nearly harmonic
(potential energy quadratic in displacement; restoring force proportional to displace-
ment; “spring constant” independent of displacement). However, if the electron’s dis-
placement from equilibrium becomes a signiﬁcant fraction of the interionic distance,
it will begin to feel the electrostatic attraction of the neighboring ions, and its spring
constant will weaken. So the potential the electron sees is really not that of a harmonic
oscillator, butratherthatofananharmonicoscillator,V (x) = αx2 −βx3 + . . . , where
x is the electron’s displacement from equilibrium. The nonlinearities in this potential
cause the electron’s amplitude of oscillation, when driven by a sinusoidal electric ﬁeld,
3.
For further details see, e.g., Sharma (2006, Sec. 14.3) or Yariv (1989, Secs. 16.2 and 16.3). In a lossy
medium, symmetry on the ﬁrst index is lost; see Yariv and Yeh (2007, Sec. 8.1).
4.
There is a caveat to these symmetry arguments. When the nonlinear susceptibilities depend signiﬁcantly
on the frequencies of the three or four waves, then these simple symmetries can be broken. For example,
the third-order susceptibility χijkl for an isotropic medium depends on which of the three input waves
is paired with the output wave in Eq. (10.25); so when one orders the input waves with wave 1 on the j
index, 2 on the k index, and 3 on the l index (and output 4 on the i index), the three terms in χijkl [Eq.
(10.25)] have different scalar coefﬁcients. We ignore this subtlety in the remainder of this chapter. (For
details, see, e.g., Sharma, 2006, Sec. 14.3.)
538
Chapter 10. Nonlinear Optics

to be nonlinear in the ﬁeld strength, and that nonlinear displacement causes the crys-
tal’s polarization to be nonlinear (e.g., Yariv, 1989, Sec. 16.3). For most crystals, the
spatial arrangement of the ions causes the electron’s potential energy V to be different
for displacements in different directions, which causes the nonlinear susceptibilities
to be anisotropic.
Because the total energy required to liberate the electron from its lattice site
is roughly 1 eV and the separation between lattice sites is ∼10−10 m, the charac-
teristic electric ﬁeld for strong instantaneous nonlinearities is ∼1 V(10−10 m)−1 =
1010 V m−1 = 1 V (100 pm)−1.
Correspondingly,
since
dijk
has
dimensions
1/(electric ﬁeld) and χijkl has dimensions 1/(electric ﬁeld)2, rough upper limits on
their Cartesian components are
magnitudes of nonlinear
susceptibilities
dijk <∼100 pm V−1,
χ4 ∼χijkl <∼
2
100 pm V−132
.
(10.26)
For comparison, because stronger ﬁelds will pull electrons out of solids, the strongest
continuous-wave electric ﬁelds that occur in practical applications are E ∼
106 V m−1, corresponding to maximum intensities F ∼1 kW mm−2 = 1 GW m−2.
These numbers dictate that, unless the second-order dijk are suppressed by isotropy,
they will produce much larger effects than the third-order χijkl, which in turn will
dominate over all higher orders.
In the next few sections, we explore how the nonlinear susceptibilities produce
nonlinear couplings of optical waves. There is, however, another application that
we must mention in passing. When a slowly changing, non-wave electric ﬁeld Ek
is applied to a nonlinear medium, it can be thought of as producing a change in
the linear dielectric tensor for waves χij = 2(dijk + dikj)Ek+ quadratic terms [cf.
Eq. (10.22b)]. This is an example (Boyd, 2008) of an electro-optic effect: the modi-
electro-optic effects
ﬁcation of optical properties of a medium by an applied electric ﬁeld. Electro-optic
effects are important in modern optical technology. For example, Pockels cells (used
to modulate Gaussian light beams), optical switches (used in Q-switched lasers), and
liquid-crystal displays (used for computer screens and television screens) are based
on electro-optic effects. For some details of several important electro-optic effects and
their applications, see, for example, Yariv and Yeh (2007, Chap. 9).
EXERCISES
Exercise 10.7 Derivation and Example: Nonlinear Susceptibilities
for an Isotropic Medium
Explain why the nonlinear susceptibilities for an isotropic medium have the forms
given in Eq. (10.25). [Hint: Use the facts that the χs must be symmetric in all their in-
dices, and that, because the medium is isotropic, they must be constructable from
10.5 Maxwell’s Equations in a Nonlinear Medium
539

the only isotropic tensors available to us, the (symmetric) metric tensor gij and
the (antisymmetric) Levi-Civita tensor ϵijk.] What are the corresponding forms, in
an isotropic medium, of χijklmn and χijklmnp? [Note: We will encounter an argu-
ment similar to this, in Ex. 28.1, for the form of the Riemann tensor in an isotropic
universe.]
10.6
10.6 Three-Wave Mixing in Nonlinear Crystals
10.6.1
10.6.1 Resonance Conditions for Three-Wave Mixing
When a beam of light is sent through a nonlinear crystal, the nonlinear suscepti-
bilities produce wave-wave mixing. The mixing due to the second-order suscep-
tibility dijk is called three-wave mixing, because three electric ﬁelds appear in the
three-wave and four-wave
mixing
polarization-induced interaction energy, Eq. (10.24a). The mixing produced by the
third-order χijkl is similarly called four-wave mixing. Three-wave mixing dominates
in an anisotropic medium, but it is suppressed when the medium is isotropic, leaving
four-wave mixing as the leading-order nonlinearity.
For use in our analyses of three-wave mixing, in Box 10.2 we list the second-order
susceptibilities and some other properties of several speciﬁc nonlinear crystals.
Let us examine three-wave mixing in a general anisotropic crystal. Because the
nonlinear susceptibilities are so small [i.e., because the input wave will generally be
far weaker than 1010 V m−1 = 1 V(100 pm)−1], the nonlinearities can be regarded
as small perturbations. Suppose that two waves, labeled n = 1 and n = 2, are in-
jected into the anisotropic crystal, and let their wave vectors be kn when one ignores
the (perturbative) nonlinear susceptibilities but keeps the large linear χij. Because
χij is an anisotropic function of frequency, the dispersion relation (k) for these
waves (ignoring the nonlinearities) will typically be anisotropic. The frequencies
of the two input waves satisfy the dispersion relation, ωn = (kn), and the waves’
forms are
E(n)
j
= ℜ
2
A(n)
j ei(kn.x−ωnt)3
= 1
2
2
A(n)
j ei(kn.x−ωnt) + A(n)∗
j
ei(−kn.x+ωnt)3
,
(10.27)
where we have denoted their vectorial complex amplitudes by A(n)
j . We adopt the
convention that wave 1 is the wave with the larger frequency, so ω1 −ω2 ≥0.
These two input waves couple, via the second-order nonlinear susceptibility dijk,
to produce the following contribution to the medium’s nonlinear polarization vector:
polarization for 3-wave
mixing
P (3)
i
= 2ϵ0dijk 2E(1)
j E(2)
k
= ϵ0dijk
2
A(1)
j A(2)
k ei(k1+k2).xei(ω1+ω2)t + A(1)
j A(2)∗
k
ei(k1−k2).xei(ω1−ω2)t + cc
3
,
(10.28)
540
Chapter 10. Nonlinear Optics

BOX 10.2.
PROPERTIES OF SOME ANISOTROPIC, NONLINEAR CRYSTALS
NOTATION FOR SECOND-ORDER SUSCEPTIBILITIES
In tabulations of the second-order nonlinear susceptibilities dijk, a compressed
two-index notation dab is often used, with the indices running over
a: 1 = x, 2 = y, 3 = z,
b: 1 = xx, 2 = yy, 3 = zz, 4 = yz = zy, 5 = xz = zx, 6 = xy = yx.
(1)
CRYSTALS WITH LARGE SECOND-ORDER SUSCEPTIBILITIES
The following crystals have especially large second-order susceptibilities:
Te: tellurium
d11 = dxxx = 650 pm V−1
CdGeAs2
d36 = dzyx = 450 pm V−1
Se: selenium
d11 = dxxx = 160 pm V−1.
(2)
However, they are not widely used in nonlinear optics, because some of their
other properties are unfavorable. By contrast, glasses containing tellurium or
selenium have moderately large nonlinearities and are useful.
KH2PO4
Potassium dihydrogen phosphate (KDP) is among the most widely used
nonlinear crystals in 2016, not because of its nonlinear susceptibilities (which
are quite modest) but because (i) it can sustain large electric ﬁelds without
sufferingdamage, (ii)itishighlybirefringent(differentlightspeedsindifferent
directions and for different polarizations, which as we shall see in Sec. 10.6.3
is useful for phase matching), and (iii) it has large electro-optic coefﬁcients
(end of Sec. 10.5). At linear order, it is axisymmetric around the z-axis, and
its indices of refraction and susceptibilities have the following dependence
on wavelength λ (measured in microns), which we use in Sec. 10.6.3 and
Fig. 10.12a:
(no)2 = 1 + χxx = 1 + χyy = 2.259276 +
0.01008956
λ2 −0.012942625 + 13.005522λ2
λ2 −400
,
(ne)2 = 1 + χzz = 2.132668 +
0.008637494
λ2 −0.012281043 + 3.2279924λ2
λ2 −400
.
(3)
The second-order nonlinearities break the axisymmetry of KDP, giving rise to
d36 = dzyx = 0.44 pm V−1.
(4)
Although this is three orders of magnitude smaller than the largest
nonlinearities available, its smallness is compensated for by its ability to
sustain large electric ﬁelds.
(continued)
10.6 Three-Wave Mixing in Nonlinear Crystals
541

BOX 10.2.
(continued)
KTiOPO4
Potassium titanyl phosphate (KTP) is quite widely used in 2016 (e.g., in green
laser pointers; Ex. 10.13). At linear order it is nonaxisymmetric, but with only
modest birefringence: its indices of refraction along its three principal axes, at
the indicated wavelengths, are
1,064 nm: nx =

1 + χxx = 1.740,
ny =

1 + χyy = 1.747,
nz =

1 + χzz = 1.830;
532 nm: nx =

1 + χxx = 1.779,
ny =

1 + χyy = 1.790,
nz =

1 + χzz = 1.887.
(5)
Its third-order nonlinearities are moderately large. In units of pm V−1, they are
d31 = dzxx = 6.5,
d32 = dzyy = 5.0,
d33 = dzzz = 13.7,
d24 = dxyz = dxzy = 7.6,
d15 = dxxz = dxzx = 6.1.
(6)
Notice that symmetry on the ﬁrst index is modestly broken: dzxx = 6.5 ̸=
dxxz = 7.6. This symmetry breaking is caused by the crystal’s dissipating a
small portion of the light power that drives it.
EVOLUTION OF MATERIALS
Over the past three decades materials scientists have found and developed
nonlinear crystals with ever-improving properties. By the time you read this
book, the most widely used crystals are likely to have changed.
where “cc” means complex conjugate.5 This sinusoidally oscillating polarization pro-
duces source terms in Maxwell’s equations (10.16b) and the wave equation (10.19):
an oscillating, polarization-induced charge density ρP = −∇. P(3) and current den-
sity jP = ∂P(3)/∂t. This polarization charge and current, like P(3) itself [Eq. (10.28)],
consist of two traveling waves, one with frequency and wave vector
resonance conditions and
dispersion relation for
new, third wave
ω3 = ω1 + ω2,
k3 = k1 + k2;
(10.29a)
the other with frequency and wave vector
ω3 = ω1 −ω2,
k3 = k1 −k2.
(10.29b)
5.
The reason for the factor 2 in the deﬁnition Pi = 2ϵ0dijkEjEk is to guarantee a factor unity in Eq. (10.28)
and in the resulting coupling constant κ of Eq. (10.38).
542
Chapter 10. Nonlinear Optics

If either of these (ω3, k3) satisﬁes the medium’s dispersion relation ω = (k), then
the polarization will generate an electromagnetic wave E(3)
j
that propagates along in
resonance with its polarization-vector source in the wave equation
∇2E(3) −∇(∇. E(3)) + ω2
3
c2 ϵ . E(3) =
1
c2ϵ0
∂2P(3)
∂t2
(10.30)
[the frequency-ω3 part of Eq. (10.22a)]. Therefore, this new electromagnetic wave,
with frequency ω3 and wave vector k3, will grow as it propagates.
For most choices of the input waves—most choices of {k1, ω1 = (k1), k2, ω2 =
(k2)}—neither of the polarizations P(3) will have a frequency ω3 = ω1 ± ω2 and
wave vector k3 = k1 ± k2 that satisfy the medium’s dispersion relation, and thus
neither will be able to create a third electromagnetic wave resonantly; the wave-wave
mixing is ineffective. However, for certain special choices of the input waves, resonant
coupling will be achieved, and a strong third wave will be produced. See Sec. 10.6.3
for details.
In nonlinear optics, enforcing the resonance conditions (10.29), with all three
waves satisfying their dispersion relations, is called phase matching, because it guar-
phase matching
antees that the new wave propagates along in phase with the polarization produced
by the two old waves.
The
resonance
conditions
(10.29)
have
simple
quantum
mechanical
interpretations—a fact that is not at all accidental: quantum mechanics underlies the
classical theory that we are developing. Each classical wave is carried by photons that
have discrete energies En = ℏωn and discrete momenta pn = ℏkn. The input waves are
able to produce resonantly waves with ω3 = ω1 ± ω2 and k3 = k1 ± k2, if those waves
quantum description of
resonance conditions
satisfy the dispersion relation. Restated in quantum mechanical terms, the condition
of resonance with the “+” sign rather than the “−” is
one photon created from
two
E3 = E1 + E2,
p3 = p1 + p2.
(10.31a)
This has the quantum mechanical meaning that one photon of energy E1 and mo-
mentum p1, and another of energy E2 and momentum p2 combine together, via the
medium’s nonlinearities, and are annihilated (in the language of quantum ﬁeld the-
ory). By their annihilation they create a new photon with energy E3 = E1 + E2 and
momentum p3 = p1 + p2. Thus the classical condition of resonance is the quantum
mechanical condition of energy-momentum conservation for the sets of photons in-
volved in a process of quantum annihilation and creation. For this process to proceed,
not only must energy-momentum conservation be satisﬁed, but also all three photons
must have energies and momenta that obey the photons’ semiclassical hamiltonian re-
lation E = H(p) (i.e., the dispersion relation ω = (k) with H = ℏ, E = ℏω, and
p = ℏk).
10.6 Three-Wave Mixing in Nonlinear Crystals
543

Similarly, the classical conditions of resonance with the “−” sign rather than the
“+” can be written (after bringing photon 2 to the left-hand side) as
two photons created from
one
E3 + E2 = E1,
p3 + p2 = p1.
(10.31b)
This has the quantum mechanical meaning that one photon of energy E1 and mo-
mentum p1 is annihilated, via the medium’s nonlinearities, and from its energy and
momentum two photons are created, with energies E2, E3 and momenta p2, p3 that
satisfy energy-momentum conservation.
Resonance conditions play a major role in other areas of physics, whenever one
deals with nonlinear wave-wave coupling or wave-particle coupling. In this book we
meet them again in both classical language and quantum language when studying
excitations of plasmas (Chap. 23).
10.6.2
10.6.2 Three-Wave-Mixing Evolution Equations
in a Medium That Is Dispersion-Free and Isotropic at Linear Order
Consider the simple, idealized case where the linear part of the susceptibility χjk
is isotropic and frequency independent, χjk = χ0gjk; correspondingly, Maxwell’s
equations imply ∇. E = 0. The Track-One part of this chapter will be conﬁned to
this idealized case. In Sec. 10.6.3 (Track Two), we treat the more realistic case, which
has dispersion and anisotropy at linear order.
In our idealized case the dispersion relation, ignoring the nonlinearities, takes the
simple, nondispersive form [which follows from Eq. (10.20)]:
ω = c
nk,
where
k = |k|, n =

1 + χ0.
(10.32)
Consider three-wave mixing for waves 1, 2, and 3 that all propagate in the same
z direction with wave numbers that satisfy the resonance condition k3 = k1 + k2.
The dispersion-free dispersion relation (10.32) guarantees that the frequencies will
also resonate: ω3 = ω1 + ω2. If we write the new wave as E(3)
i
= ℜ(A(3)
i ei(k3z−ω3t)) =
1
2A(3)
i ei(k3z−ω3t) + cc, then its evolution equation (10.30), when combined with Eqs.
(10.27) and (10.28), takes the form
∇2 2
A(3)
i ei(k3z−ω3t)3
+ n2ω2
3
c2 A(3)
i ei(k3z−ω3t) = −2ω2
3
c2 dijkA(1)
j A(2)
k ei(k3z−ω3t).
(10.33)
Using the dispersion relation (10.32) and the fact that the lengthscale on which wave
3 changes is long compared to its wavelength (which is always the case, because
the ﬁelds are always much weaker than 1010 V m−1), the left-hand side becomes
2ik3dA(3)
i /dz, and Eq. (10.33) then becomes (with the aid of the dispersion relation)
dA(3)
i /dz = i(k3/n2)dijkA(1)
j A(2)
k . This and similar computations for evolution of the
other two waves (Ex. 10.8) give the following equations for the rates of change of the
three waves’ complex amplitudes:
544
Chapter 10. Nonlinear Optics

dA(3)
i
dz
= i k3
n2dijkA(1)
j A(2)
k
at ω3 = ω1 + ω2, k3 = k1 + k2;
(10.34a)
dA(1)
i
dz
= i k1
n2dijkA(3)
j A(2)∗
k
at ω1 = ω3 −ω2, k1 = k3 −k2;
(10.34b)
dA(2)
i
dz
= i k2
n2dijkA(3)
j A(1)∗
k
at ω2 = ω3 −ω1, k2 = k3 −k1.
(10.34c)
Therefore, each wave’s amplitude changes with distance z traveled at a rate propor-
tional to the product of the ﬁeld strengths of the other two waves.
It is instructive to rewrite the evolution equations (10.34) in terms of renormalized
scalar amplitudes An and unit-normed polarization vectors f (n)
j
for the three waves
n = 1, 2, 3:
renormalized wave
amplitudes
A(n)
j
=
1
2kn
ϵ0n2 An f (n)
j
=
1
2ωn
ϵ0c n An f (n)
j
.
(10.35)
This renormalization is motivated by the fact that |An|2 is proportional to the ﬂux of
quanta dNn/dAdt associated with wave n. Speciﬁcally, the energy density in wave n is
(neglecting nonlinearities) U = ϵo(1 + χo)E2 = 1
2ϵon2|A(n)|2 (where the bar means
time average); the energy ﬂux is this U times the wave speed c/n:
Fn = 1
2ϵonc|A(n)|2 = ωn|An|2;
(10.36)
and the ﬂux of quanta is this Fn divided by the energy En = ℏωn of each quantum:
dNn/dAdt = |An|2/ℏ, where dA is a unit area orthogonal to kn.
The three-wave-mixing evolution equations (10.34), rewritten in terms of the
renormalized amplitudes, take the simple form
three-wave mixing
evolution equations in an
isotropic, dispersion-free
medium
dA3
dz = iκ A1A2,
dA1
dz = iκ A3A∗
2,
dA2
dz = iκ A3A∗
1;
κ =
1
2ω1ω2ω3
ϵ0c3n3
dijk f (1)
i
f (2)
j f (3)
k .
(10.37)
It is straightforward to verify that these evolution equations guarantee energy conser-
vation d(F1 + F2 + F3)/dz = 0, with Fn given by Eq. (10.36). Therefore, at least one
wave will grow and at least one wave will decay due to three-wave mixing.
frequency doubling
When waves 1 and 2 are the same wave, the three-wave mixing leads to frequency
doubling: ω3 = 2ω1. In this case, the nonlinear polarization that produces the third
wave is Pi = ϵ0dijkE(1)
j E(1)
k , by contrast with that when waves 1 and 2 are different,
Pi = 2ϵ0dijkE(1)
j E(2)
j
[Eq. (10.28)]. [In the latter case the factor 2 arises because we
are dealing with cross terms in (E(1)
j
+ E(2)
j )(E(1)
k
+ E(2)
k ).] Losing the factor 2 and
10.6 Three-Wave Mixing in Nonlinear Crystals
545

making wave 2 the same as wave 1 leads to an obvious modiﬁcation of the evolution
equations (10.37):
evolution equations for
frequency doubling
dA3
dz = iκ
2 (A1)2,
dA1
dz = iκA3A∗
1;
κ =
1
2ω2
1ω3
ϵ0c3n3 dijk f (1)
i
f (1)
j f (3)
k .
(10.38)
Once again, it is easy to verify energy conservation, d(F1 + F3)/dz = 0. We discuss
frequency doubling in Sec. 10.7.1.
EXERCISES
Exercise 10.8 Derivation: Evolution Equations in Idealized Three-Wave Mixing
Derive Eqs. (10.34b) and (10.34c) for the amplitudes of waves 1 and 2 produced by
three-wave mixing.
10.6.3
10.6.3 Three-Wave Mixing in a Birefringent Crystal:
Phase Matching and Evolution Equations
ORDINARY WAVES, EXTRAORDINARY WAVES, AND DISPERSION RELATIONS
In reality, all nonlinear media have frequency-dependent dispersion relations and
most are anisotropic at linear order and therefore birefringent (different wave speeds
birefringent crystal
in different directions). An example is the crystal KDP (Box 10.2), which is symmetric
around the z-axis and has indices of refraction6
no =

1 + χxx =

1 + χyy,
ne =

1 + χzz
(10.39)
that depend on the light’s wave number k = 2π/λ in the manner shown in Fig. 10.12a
and in Eq. (3) of Box 10.2. The subscript o stands for ordinary; e, for extraordinary;
see the next paragraph.
Maxwell’s equations imply that, in this crystal, for plane, monochromatic waves
propagating in the x-z plane at an angle θ to the symmetry axis [k = k(sin θex +
cos θez)], there are two dispersion relations corresponding to the two polarizations
of the electric ﬁeld:
1. If E is orthogonal to the symmetry axis, then (as is shown in Ex. 10.9), it
must also be orthogonal to the propagation direction (i.e., must point in the
ey direction), and the dispersion relation is
ω/k
c
= (phase speed in units of speed of light) = 1
no
,
(10.40a)
6.
For each wave, the index of refraction is the ratio of light’s vacuum speed c to the wave’s phase speed
Vph = ω/k.
546
Chapter 10. Nonlinear Optics

0
2
4
(b)
(a)
6
8
k1 (μm–1)
k (μm–1)
A
A
B
n–1
no
–1
ne
–1
θ (°)
10
12
0
5
10
15
20
25
30
ordinary
(any θ)
extraordinary
θ = π/2
14
80
60
40
20
0
0.68
0.66
0.64
0.62
FIGURE 10.12 (a) The inverse of the index of refraction n−1 (equal to the phase speed in units of the
speed of light) for electromagnetic waves propagating at an angle θ to the symmetry axis of a KDP
crystal, as a function of wave number k in reciprocal microns. See Eq. (10.40a) for the lower curve and
Eq. (10.40b) with θ = π/2 for the upper curve. For extraordinary waves propagating at an arbitrary
angle θ to the crystal’s symmetry axis, n−1 is a mean [Eq. (10.40b)] of the two plotted curves. The
plotted curves are ﬁt by the analytical formulas (3) of Box 10.2. (b) The angle θ to the symmetry axis
at which ordinary waves with wave number k1 (e.g., point A) must propagate for three-wave mixing
to be able to produce frequency-doubled or phase-conjugated extraordinary waves (e.g., point B).
independent of the angle θ. These waves are called ordinary,and their phase
ordinary waves
speed (10.40a) is the lower curve in Fig. 10.12a; at k = 10 μm−1 (point A),
the phase speed is 0.663c, while at k = 20 μm−1, it is 0.649c.
2. If E is not orthogonal to the symmetry axis, then (Ex. 10.9) it must lie in the
plane formed by k and the symmetry axis (the x-z) plane, with Ex/Ez =
−(ne/no)2 cot θ (which means that E is not orthogonal to the propagation
direction unless the crystal is isotropic, ne = no, which it is not); and the
dispersion relation is
ω/k
c
= 1
n =
1
cos2 θ
n2
o
+ sin2 θ
n2
e
.
(10.40b)
In this case the waves are called extraordinary.7 As the propagation direc-
extraordinary waves
tion varies from parallel to the symmetry axis (cos θ = 1) to perpendicular
(sin θ = 1), this extraordinary phase speed varies from c/no (the lower curve
in Fig. 10.12; 0.663c at k = 10 μm−1), to c/ne (the upper curve; 0.681c at
k = 10 μm−1).
7.
When studying perturbations of a cold, magnetized plasma (Sec. 21.5.3) we will meet two wave modes
that have these same names: ordinary and extraordinary. However, because of the physical differences
between an axially symmetric magnetized plasma and an axially symmetric birefringent crystal, the
physics of those plasma modes (e.g., the direction of their oscillating electric ﬁeld) is rather different
from that of the crystal modes studied here.
10.6 Three-Wave Mixing in Nonlinear Crystals
547

PHASE MATCHING FOR FREQUENCY DOUBLING IN A KDP CRYSTAL
This birefringence enables one to achieve phase matching (satisfy the resonance
frequency doubling
example
conditions) in three-wave mixing. As an example, consider the resonance conditions
forafrequency-doublingdevice (discussedinfurtherdetailinSec.10.7.1):oneinwhich
the two input waves are identical, so k1 = k2 and k3 = 2k1 point in the same direction.
Let this common propagation direction be at an angle θ to the symmetry axis. Then
the resonance conditions reduce to the demands that the output wave number be
twice the input wave number, k3 = 2k1, and the output phase speed be the same as the
input phase speed, ω3/k3 = ω1/k1. Now, for waves of the same type (both ordinary
or both extraordinary), the phase speed is a monotonic decreasing function of wave
number [Fig. 10.12a and Eqs. (10.40)], so there is no choice of propagation angle θ
that enables these resonance conditions to be satisﬁed. The only way to satisfy them
is by using ordinary input waves and extraordinary output waves, and then only for
a special, frequency-dependent propagation direction. This technique is called type I
type I phase matching in a
birefringent crystal
phase matching; “type I” because there are other techniques for phase matching (i.e.,
for arranging that the resonance conditions be satisﬁed; see, e.g., Table 8.4 of Yariv
and Yeh, 2007).
As an example, if the input waves are ordinary, with k1 = 10 μm−1(approximately
the value for light from a ruby laser; point A in Fig. 10.12a), then the output waves
must be extraordinary and must have the same phase speed as the input waves (same
height in Fig. 10.12a) and have k3 = 2k1 = 20 μm−1 (i.e., point B). This phase speed
is between c/ne(2k1) and c/no(2k1), and thus can be achieved for a special choice of
propagation angle: θ = 56.7◦(point A in Fig. 10.12b). In general, Eqs. (10.40) imply
that the unique propagation direction θ at which the resonance conditions can be
satisﬁed is the following function of the input wave number k1:
sin2 θ = 1/n2
o(k1) −1/n2
o(2k1)
1/n2
e(2k1) −1/n2
o(2k1).
(10.41)
This resonance angle is plotted as a function of wave number for KDP in
Fig. 10.12b.
discreteness of possible
propagation directions
for 3-wave mixing in
birefringent crystal
Thisspecialcaseofidenticalinputwavesillustratesageneralphenomenon:atﬁxed
inputfrequencies, theresonanceconditionscanbesatisﬁedonlyforspecial, discreteinput
and output directions.
For our frequency-doubling example, the extraordinary dispersion relation
(10.40b) for the output wave can be rewritten as
ω = ck
n = e(k) = c
1
k2
z
no(k)2 +
k2
x
ne(k)2 ,
where
k =

k2
x + k2
z.
(10.42)
548
Chapter 10. Nonlinear Optics

Correspondingly, the group velocity8 V j
g = ∂/∂kj for the output wave has
components
V x
g = Vph sin θ
*
n2
n2
e
−n2 cos2 θ
n2
o
d ln no
d ln k −n2 sin2 θ
n2
e
d ln ne
d ln k
+
,
V z
g = Vph cos θ
*
n2
n2
o
−n2 cos2 θ
n2
o
d ln no
d ln k −n2 sin2 θ
n2
e
d ln ne
d ln k
+
,
(10.43)
where Vph = ω/k = c/n is the phase velocity. For an ordinary input wave with k1 =
10 μm−1(point A in Fig. 10.12) and an extraordinary output wave with k3 = 20 μm−1
(point B), these formulas give for the direction of the output group velocity (direction
along which the output waves grow) θg = arctan(V x
g /V z
g ) = 58.4o, compared to the
direction of the common input-output phase velocity θ = 56.7o. They give for the
magnitudeofthegroupvelocityVg = 0.628c, comparedtothecommonphasevelocity
vph = 0.663c. Thus, the differences between the group velocity and the phase velocity
are small, but they do differ.
EVOLUTION EQUATIONS
Once one has found wave vectors and frequencies that satisfy the resonance condi-
tions, the evolution equations for the two (or three) coupled waves have the same form
as in the idealized dispersion-free, isotropic case [Eqs. (10.38) or (10.37)], but with
the following minor modiﬁcations.
Let planar input waves impinge on a homogeneous, nonlinear crystal at some
plane z = 0 and therefore (by symmetry) have energy ﬂuxes inside the crystal that
evolve as functions of z only: Fn = Fn(z) for waves n = 1and 3 in the case of frequency
doubling (or 1, 2, and 3 in the case of three different waves). Then energy conservation
dictates that
d
dz
 
n
Fn z = 0,
(10.44)
where Fn z(z) is the z component of the energy ﬂux for wave n. It is convenient to
deﬁne a complex amplitude An for wave n that is related to the wave’s complex electric
ﬁeld amplitude by an analog of Eq. (10.35):
renormalized amplitude in
birefringent crystal
A(n)
j
= ζn
1
2ωn
ϵ0c nn
Anf (n)
j
.
(10.45)
Here f (n)
j
is the wave’s polarization vector [Eq. (10.35)], nn is its index of refraction
(deﬁned by ωn/kn = c/nn), and ζn is some positive real constant that depends on the
8.
Since a wave’s energy travels with the group velocity, it must be that Vg = E × H/U, where U is the wave’s
energy density, E × H is its Poynting vector (energy ﬂux), and H = B/μ0 (in our dielectric medium). It
can be shown explicitly that, indeed, this is the case.
10.6 Three-Wave Mixing in Nonlinear Crystals
549

relative directions of kn, f(n), and ez and has a value ensuring that
Fn z = ωn|An|2
(10.46)
[same as Eq. (10.36) but with Fn replaced by Fn z]. Since the energy ﬂux is ℏωn times
the photon-number ﬂux, this equation tells us that |An|2/ℏis the photon-number ﬂux
(just like the idealized case).
Because the evolution equations involve the same photon creation and annihila-
tion processes as in the idealized case, they must have the same mathematical form as
in that case [Eqs. (10.38) or (10.37)], except for the magnitude of the coupling con-
stant. (For a proof, see Ex. 10.10.) Speciﬁcally, for frequency doubling of a wave 1
to produce wave 3 (ω3 = 2ω1), the resonant evolution equations and coupling con-
stant are
three-wave mixing
evolution equations in
a birefringent crystal
dA3
dz = iκ
2 (A1)2,
dA1
dz = iκ A3A∗
1;
κ = β
1
2ω2
1ω3
ϵ0c3n2
1n3
dijk f (1)
i
f (1)
j f (3)
k
(10.47)
[cf. Eqs. (10.38) for the idealized case]. For resonant mixing of three different waves
(ω3 = ω1 + ω2), they are
dA3
dz = iκ A1A2,
dA1
dz = iκ A3A∗
2,
dA2
dz = iκ A3A∗
1;
κ = β′
1
2ω1ω2ω3
ϵ0c3n1n2n3
dijk f (1)
i
f (2)
j f (3)
k
(10.48)
[cf. Eqs. (10.37) for the idealized case]. Here β and β′ are constants of order unity
that depend on the relative directions of ez and the wave vectors kn and polarization
vectors f(n); see Ex. 10.10.
It is useful to keep in mind the following magnitudes of the quantities that appear
in these three-wave-mixing equations (Ex. 10.11):
Fn <∼1 GW m−2,
|An| <∼10−3 J1/2 m−1,
κ <∼105 J−1/2,
|κ An| <∼1 cm−1.
(10.49)
We use the evolution equations (10.47) and (10.48) in Sec. 10.7 to explore several
applications of three-wave mixing.
One can reformulate the equations of three-wave mixing in fully quantum me-
chanical language, with a focus on the mean occupation numbers of the wave modes.
This is commonly done in plasma physics; in Sec. 23.3.6 we discuss the example of
coupled electrostatic waves in a plasma.
550
Chapter 10. Nonlinear Optics

EXERCISES
Exercise 10.9 **Example: Dispersion Relation for an Anisotropic Medium
Consider a wave propagating through a dielectric medium that is anisotropic, but not
necessarily—for the moment—axisymmetric. Let the wave be sufﬁciently weak that
nonlinear effects are unimportant. Then the nonlinear wave equation (10.22a) takes
the linear form
−∇2E + ∇(∇. E) = −1
c2ϵ . ∂2E
∂t2 .
(10.50)
(a) Specialize to a monochromatic plane wave with angular frequency ω and wave
vector k. Show that the wave equation (10.50) reduces to
LijEj = 0,
where Lij = kikj −k2δij + ω2
c2 ϵij.
(10.51a)
This equation says that Ej is an eigenvector of Lij with vanishing eigenvalue,
which is possible if and only if
det ||Lij|| = 0.
(10.51b)
This vanishing determinant is the waves’ dispersion relation. We use it in Chap. 21
to study waves in plasmas.
(b) Next specialize to an axisymmetric medium, and orient the symmetry axis along
the z direction, so the only nonvanishing components of the dielectric tensor
ϵij are ϵ11 = ϵ22 and ϵ33. Let the wave propagate in a direction ˆk that makes an
angle θ to the symmetry axis. Show that in this case Lij has the form
||Lij|| = k2
8888888
8888888
(no/n)2 −cos2 θ
0
sin θ cos θ
0
(no/n)2 −1
0
sin θ cos θ
0
(ne/n)2 −sin2 θ
8888888
8888888
,
(10.52a)
and the dispersion relation (10.51b) reduces to
*
1
n2 −1
n2
o
+ *
1
n2 −cos2 θ
n2
o
−sin2 θ
n2
e
+
= 0,
(10.52b)
where 1/n = ω/kc, no = √ϵ11 = √ϵ22, and ne = √ϵ33, in accord with Eq. (10.39).
(c) Show that this dispersion relation has the two solutions (ordinary and extraordi-
nary) discussed in the text, Eqs. (10.40a) and (10.40b), and show that the electric
ﬁelds associated with these two solutions point in the directions described in the
text.
Exercise 10.10 **Derivation and Example: Evolution Equations for Realistic
Wave-Wave Mixing
Derive the evolution equations (10.48) for three-wave mixing. [The derivation of
those (10.47) for frequency doubling is similar.] You could proceed as follows.
10.6 Three-Wave Mixing in Nonlinear Crystals
551

(a) Insert expressions (10.27) and (10.28) into the general wave equation (10.30)
and extract the portions with frequency ω3 = ω1 + ω2, thereby obtaining the
generalization of Eq. (10.33):
∇2 2
A(3)
i ei(k3z−ω3t)3
−
∂2
∂xi∂xj
2
A(3)
j ei(k3z−ω3t)3
+ ω2
3
c2 ϵijA(3)
j ei(k3z−ω3t)
= −2ω2
3
c2 dijkA(1)
j A(2)
k eik3z−ω3t.
(10.53)
(b) Explain why ei(k3 . x−ω3t)f(3) satisﬁes the homogeneous wave equation (10.50).
Then, splitting each wave into its scalar ﬁeld and polarization vector, A(n)
i
≡
A(n)f (n)
i
, and letting each A(n) be a function of z (because of the boundary
condition that the three-wave mixing begins at the crystal face z = 0), show that
Eq. (10.53) reduces to
α3dA(3)/dz = i(k3/n2
3)dijkf (1)
j f (2)
k A(1)A(2),
where α3 is a constant of order unity that depends on the relative orientations of
the unit vectors ez, f(3), and ˆk3. Note that, aside from α3, this is the same evolution
equation as for our idealized isotropic, dispersion-free medium, Eq. (10.34a).
Show that, similarly, A(1)(z) and A(2)(z) satisfy the same equations (10.34b) and
(10.34c) as in the idealized case, aside from multiplicative constants α1 and α2.
(c) Adopting the renormalizations A(n) = ζn

2ωn/(ϵ0c nn) An [Eq. (10.45)] with ζn
so chosen that the photon-number ﬂux for wave n is proportional to |An|2, show
that your evolution equations for An become Eqs. (10.48), except that the factor
β′ and thence the value of κ might be different for each equation.
(d) Since the evolution entails one photon with frequency ω1 and one with fre-
quency ω2 annihilating to produce a photon with frequency ω3, it must be
that d|A1|3/dz = d|A2|3/dz = −d|A3|2/dz. (These are called Manley-Rowe re-
lations.) By imposing this on your evolution equations in part (c), deduce that
all three coupling constants κ must be the same, and thence also that all three β′
must be the same; therefore the evolution equations take precisely the claimed
form, Eqs. (10.48).
Exercise 10.11 **Derivation: Magnitudes of Three-Wave-Mixing Quantities
Derive Eqs. (10.49). [Hint: The maximum energy ﬂux in a wave arises from the limit
E <∼106 V m−1on the wave’s electric ﬁeld to ensure that it not pull electrons out of the
surface of the nonlinear medium. The maximum coupling constant κ arises from the
largest values |dijk| <∼10 pm V−1 for materials typically used in three-wave mixing
(Box 10.2).]
552
Chapter 10. Nonlinear Optics

10.7
10.7 Applications of Three-Wave Mixing: Frequency Doubling,
Optical Parametric Ampliﬁcation, and Squeezed Light
10.7.1
10.7.1 Frequency Doubling
second harmonic
generation (frequency
doubling)
Frequency doubling (also called second harmonic generation) is one of the most
important applications of wave-wave mixing. As we have already discussed brieﬂy in
Secs. 10.6.2 (Track One) and 10.6.3 (Track Two), it can be achieved by passing a single
wave (which plays the role of both wave n = 1 and wave n = 2) through a nonlinear
crystal, with the propagation direction chosen to satisfy the resonance conditions.
As we have also seen in the previous section (Track Two), the crystal’s birefringence
and dispersion have little inﬂuence on the growth of the output wave, n = 3 with
ω3 = 2ω1; it grows with distance inside the crystal at a rate given by Eqs. (10.47),
which is the same as in the Track-One case of a medium that is isotropic at linear
order, Eqs.(10.38), asidefromthefactorβ oforderunityinthecouplingconstantκ.By
doing a sufﬁciently good job of phase matching (satisfying the resonance conditions)
efﬁciency of frequency
doubling
and choosing the thickness of the crystal appropriately, one can achieve close to
100% conversion of the input-wave energy into frequency-doubled energy. More
speciﬁcally, if wave 1 enters the crystal at z = 0 with A1(0) = A1o, which we choose
(without loss of generality) to be real, and if there is no incoming wave 3 so A3(0) = 0,
then the solution to the evolution equations (10.47) or (10.38) is
wave amplitude evolution
A3 =
i√
2
A1o tanh
 κ
√
2
A1o z

,
A1 = A1o sech
 κ
√
2
A1o z

.
(10.54)
It is easy to see that this solution has the following properties. (i) It satisﬁes energy
conservation, 2|A3|2 + |A1|2 = |A1o|2. (ii) At a depth z = 1.246/(κA1o) in the crystal,
half the initial energy has been frequency doubled. (iii) As z increases beyond this
half-doubling depth, the light asymptotes to fully frequency doubled.
One might expect the frequency doubling to proceed onward to 4ω1, and so forth.
However, it typically does not, because these higher-frequency waves typically fail to
satisfy the crystal’s dispersion relation.
Nd: YAG laser
As an example, the neodymium:YAG (Nd3+:YAG) laser, which is based on an
yttrium-aluminum-garnet crystal with trivalent neodymium impurities, is among the
most attractive of all lasers for a combination of high frequency stability, moderately
high power, and high efﬁciency. However, this laser operates in the infrared, at a
wavelength of 1.064 microns. For many purposes, one wants optical light. This can
be achieved by frequency doubling the laser’s output, thereby obtaining 0.532-micron
(green) light. This is how green laser pointers, used in lecturing, work (though in 2016
they are typically driven not by Nd:YAG but rather a relative; see Ex. 10.13).
Frequencydoublingalsoplaysakeyroleinlaserfusion, whereintense, pulsedlaser
beams, focused on a pellet of fusion fuel, compress and heat the pellet to high densities
and temperatures. Because the beam’s energy ﬂux is inversely proportional to the area
10.7 Applications of Three-Wave Mixing
553

ofitsfocusedcrosssection—andbecausethelargerthewavelength, themoreseriously
diffraction impedes making the cross section small—in order to achieve efﬁcient
compression of the pellet, it is important to give the beam a very short wavelength.
This is achieved by multiple frequency doublings, which can and do occur in the
experimental setup of laser fusion.
EXERCISES
Exercise 10.12 Derivation: Saturation in Frequency Doubling
Derive the solution (10.54) to the evolution equations (10.47) for frequency doubling,
and verify that it has the claimed properties.
Exercise 10.13 **Example: Frequency Doubling in a Green Laser Pointer
Green laser pointers, popular in 2016, have the structure shown in Fig. 10.13. A
battery-driven infrared diode laser puts out 808-nm light that pumps a Nd:YVO4 laser
crystal (neodymium-doped yttrium vanadate; a relative of Nd:YAG). The 1,064-nm
light beam from this Nd:YVO4 laser is frequency doubled by a KTP crystal, resulting
in 532-nm green light. An infrared ﬁlter removes all the 880-nm and 1,064-nm light
from the output, leaving only the green.
(a) To make the frequency doubling as efﬁcient as possible, the light is focused to as
small a beam radius ϖo as diffraction allows as it travels through the KTP crystal.
Assuming that the crystal length is L ≃3 mm, show that ϖo ≃

λL/(4πn1) ≃
808 nm
pump
diode
LD+
KTP
Nd:YVO4
MCA
battery
+    AAA alkaline    –
+    AAA alkaline    –
DPSS
laser module
pump LD
driver
LD–
pump
focusing
lens
beam paths: 808 nm
1,064 + 532 nm
532 nm
expanding
lens
collimating
lens
IR
filter
FIGURE10.13 Structureofagreenlaserpointer, circa2012.Adaptedwithminorchangesfromadraw-
ing copyright by Samuel M. Goldwasser (Sam’s Laser FAQ at http://www.repairfaq.org/lasersam
.htm), and printed here with his permission.
554
Chapter 10. Nonlinear Optics

12 μm (about 12 times larger than the 1,064-nm wavelength). [Hint: Use the
properties of Gaussian beams; Sec. 8.5.5 adjusted for propagation in a medium
with index of refraction n1.]
(b) The 1,064-nm beam has an input power W1o ≃100 mW as it enters the KTP crys-
tal. Show that its energy ﬂux and its electric ﬁeld strength are F ≃230 MW m−2
and A(1) ≃400 kV m−1.
(c) Assuming that phase matching has been carried out successfully (i.e., photon
energy and momentum conservation have been enforced), explain why it is rea-
sonable to expect the quantity βdijkf (1)
i
f (1)
j f (3)
k
in the coupling constant κ to
be roughly 4 pm/V [cf. Eq. (6) of Box 10.2]. Then show that the green output
beam at the end of the KTP crystal has |A3|2 ∼0.7 × 10−4 A2
1o, corresponding to
an output power W3 ∼1.5 × 10−4 W1o ≃0.015 mW. This is far below the output
power, 5 mW, of typical green laser pointers. How do you think the output power
is boosted by a factor ∼5/0.015 ≃300?
(d) The answer is (i) to put reﬂective coatings on the two ends of the KTP crystal so it
becomes a Fabry-Perot resonator for the 1.064 μm input ﬁeld; and also (ii) make
the input face (but not the output face) reﬂective for the 0.532 μm green light.
Show that, if the 1.064 μm resonator has a ﬁnesse F ≃30, then the green-light
output power will be increased to ≃5 mW.
(e) Explain why this strategy makes the output power sensitive to the temperature
of the KTP crystal. To minimize this sensitivity, the crystal is oriented so that its
input and output faces are orthogonal to its (approximate) symmetry axis—the
z-axis—for which the thermal expansion coefﬁcient is very small (0.6 × 10−6/C,
by contrast with ≃10 × 10−6/C along other axes. Show that, in this case, a
temperature increase or reduction of 6 C from the pointer’s optimal 22 C (room
temperature) will reduce the output power from 5 mW to much less than 1 mW.
Astronomers complain that green laser pointers stop working outdoors on cool
evenings.
10.7.2
10.7.2 Optical Parametric Ampliﬁcation
optical parametric
ampliﬁcation; pump
wave, signal wave, idler
wave
In optical parametric ampliﬁcation, the energy of a pump wave is used to amplify an
initially weak signal wave and also amplify an uninteresting idler wave. The waves
satisfy the resonance conditions with ωp = ωs + ωi. The pump wave and signal wave
are fed into an anisotropic nonlinear crystal, propagating in (nearly) the same direc-
tion, with nonzero renormalized amplitudes Apo and Aso at z = 0. The idler wave
has Aio = 0 at the entry plane. Because the pump wave is so strong, it is negligibly
inﬂuenced by the three-wave mixing (i.e., Ap remains constant inside the crystal).
The evolution equations for the (renormalized) signal and idler amplitudes are
dAs
dz = iκApA∗
i ,
dAi
dz = iκApA∗
s
(10.55)
10.7 Applications of Three-Wave Mixing
555

[Eqs. (10.48) or (10.37)]. For the initial conditions of weak signal wave and no idler
wave, the solution to these equations is
wave amplitude evolution
As = Aso cosh(|γ |z),
Ai = γ
|γ |A∗
so sinh(|γ |z);
γ ≡iκAp.
(10.56)
Thus the signal ﬁeld grows exponentially, after an initial pause, with an e-folding
length 1/|γ |, which for strong three-wave nonlinearities is of order 1 cm [Ex. (10.14)].
EXERCISES
Exercise 10.14 Derivation: e-Folding Length for an Optical Parametric Ampliﬁer
Estimate the magnitude of the e-folding length for an optical parametric ampliﬁer
that is based on a strong three-wave nonlinearity.
10.7.3
10.7.3 Degenerate Optical Parametric Ampliﬁcation: Squeezed Light
Consider optical parametric ampliﬁcation with the signal and idler frequencies
identical, so the idler ﬁeld is the same as the signal ﬁeld, and the pump frequency
degenerate optical
parametric ampliﬁcation
is twice the signal frequency: ωp = 2ωs. This condition is called degenerate. Adjust
the phase of the pump ﬁeld so that γ = iκAp is real and positive. Then the equa-
tion of evolution for the signal ﬁeld is the same as appears in frequency doubling
[Eqs. (10.47) or (10.38)]:
dAs/dz = γ A∗
s .
(10.57)
The resulting evolution is most clearly understood by decomposing As into its
real and imaginary parts (as we did in Ex. 6.23 when studying thermal noise in an
oscillator): As = X1 + iX2. Then the time-evolving electric ﬁeld is
E ∝ℜ(Asei(ksz−ωst)) = X1 cos(ksz −ωst) + X2 sin(ksz −ωst).
(10.58)
Therefore, X1is the amplitude of the ﬁeld’s cosine quadrature, and X2 is the amplitude
of its sine quadrature. Equation (10.57) then says that dX1/dz = γ X1, dX2/dz =
−γ X2, so we have
X1 = X1oeγ z,
X2 = X2oe−γ z.
(10.59)
Therefore, the wave’s cosine quadrature gets ampliﬁed as the wave propagates, and
its sine quadrature is attenuated. This is called squeezing, because X2 is reduced
squeezing
(squeezed) while X1 is increased. It is a phenomenon known to children who swing;
see Ex. 10.15.
Squeezing is especially interesting when it is applied to noise. Typically, a wave has
equal amounts of noise in its two quadratures (i.e., the standard deviations X1 and
X2 of the two quadratures are equal, as was the case in Ex. 6.23). When such a wave
is squeezed, its two standard deviations get altered in such a way that their product is
unchanged:
X1 = X1o eγ z;
X2 = X2o e−γ z,
X1X2 = const
(10.60)
556
Chapter 10. Nonlinear Optics

(a)
(b)
(c)
(d)
(e)
X2
X1
2σ
(Xˉ1, Xˉ2)
X2
X1
X2
X1
X2
X1
X2
X1
FIGURE 10.14 Error boxes in the complex amplitude plane for several different electromagnetic
waves: (a) Classical light. (b) Phase-squeezed light. (c) Amplitude-squeezed light. (d) The quantum
electrodynamical vacuum. (e) The squeezed vacuum.
(see Fig. 10.14). When, as here, the standard deviations of two quadratures differ, the
squeezed state of light
light is said to be in a squeezed state.
In quantum theory, X1and X2 are complementary observables; they are described
by Hermitian operators that do not commute. The uncertainty principle associated
with their noncommutation implies that their product X1X2 has some minimum
possible value. This minimum is achieved by the wave’s vacuum state, which has
X1 = X2 with values corresponding to a half quantum of energy (vacuum ﬂuctu-
ations) in the ﬁeld mode that we are studying. When this “quantum electrodynamic
vacuum” is fed into a degenerate optical parametric ampliﬁer, the vacuum noise gets
squeezed in the same manner [Eq. (10.59)] as any other noise.
squeezed vacuum
Squeezed states of light, including this squeezed vacuum, have great value for
fundamental physics experiments and technology. Most importantly, they can be used
to reduce the photon shot noise of an interferometer below the standard quantum
limit of N =
√
N (Poisson statistics), thereby improving the signal-to-noise ratio
in certain communications devices and in laser interferometer gravitational-wave
detectors such as LIGO (Caves, 1981; McClelland et al., 2011; Oelker et al., 2016).
We explore some properties of squeezed light in Ex. 10.16.
EXERCISES
Exercise 10.15 **Example: Squeezing by Children Who Swing
A child, standing in a swing, bends her knees and then straightens them twice
per swing period, making the distance ℓfrom the swing’s support to her center of
mass oscillate as ℓ= ℓ0 + ℓ1 sin 2ω0t. Here ω0 =

gℓ0 is the swing’s mean angular
frequency.
(a) Show that the swing’s angular displacement from vertical, θ, obeys the equation
of motion
d2θ
dt2 + ω2
0θ = −ω2
1 sin(2ω0t)θ,
(10.61)
where ω1 =

gℓ1, and θ is assumed to be small, θ ≪1.
10.7 Applications of Three-Wave Mixing
557

E
t
FIGURE 10.15 The error band for the electric ﬁeld E(t), as measured
at a ﬁxed location in space, when phase-squeezed light passes by.
(b) Write θ = X1 cos ω0t + X2 sin ω0t. Assuming that ℓ1 ≪ℓ0 so ω1 ≪ω0, show that
the child’s knee bending (her “pumping” the swing) squeezes X1and ampliﬁes X2
(parametric ampliﬁcation):
X1(t) = X1(0)e−[ω2
1/(2ωo)]t,
X2(t) = X2(0)e+[ω2
1/(2ωo)]t
(10.62)
(c) Explain how this squeezing is related to the child’s conscious manipulation of the
swing (i.e., to her strategy for increasing the swing’s amplitude when she starts up,
and her strategy for reducing the amplitude when she wants to quit swinging).
Exercise 10.16 **Example: Squeezed States of Light
Consider a plane, monochromatic electromagnetic wave with angular frequency
ω, whose electric ﬁeld is expressed in terms of its complex amplitude X1 + iX by
Eq. (10.58). Because the ﬁeld (inevitably) is noisy, its quadrature amplitudes X1 and
X2 are random processes with means ¯X1, ¯X2 and variances X1, X2.
(a) Normal, classical light has equal amounts of noise in its two quadratures. Explain
why it can be represented by Fig. 10.14a.
(b) Explain why Fig. 10.14b represents phase-squeezed light,and show that its electric
ﬁeld as a function of time has the form shown in Fig. 10.15.
(c) Explain why Fig. 10.14c represents amplitude-squeezed light, and construct a
diagram of its electric ﬁeld as a function of time analogous to Fig. 10.15.
(d) Figure 10.14d represents the vacuum state of light’s frequency-ω plane-wave
mode. Give a formula for the diameter of the mode’s circular error box. Construct
a diagram of the electric ﬁeld as a function of time analogous to Fig. 10.15.
(e) Figure 10.14e represents the squeezed vacuum. Construct a diagram of its electric
ﬁeld as a function of time analogous to Fig. 10.15.
10.8
10.8 Four-Wave Mixing in Isotropic Media
10.8.1
10.8.1 Third-Order Susceptibilities and Field Strengths
The
nonlinear
polarization
for
four-wave
mixing,
P (4)
i
= 4ϵ0χijklEjEkEl
[Eq. (10.21)], is typically smaller than that, P (3)
i
= 2ϵ0dijkEjEk, for three-wave mix-
558
Chapter 10. Nonlinear Optics

TABLE 10.1: Materials used in four-wave mixing
Wavelength
Material
(μm)
n
χ1111 (pm2 V−2)
n2 (10−20 m2 W−1)
Fused silica
0.694
1.455
56
3
SF6 glass
1.06
1.77
590
21
CS2 liquid
1.06
1.594
6,400
290
2-methyl-4-nitroaniline
(MNA) organic crystala
1.8
1.7 × 105
5,800
PTS polydiacetylene
polymeric crystala
1.88
5.5 × 105
1.8 × 104
a. Also has large dijk.
Notes: At the indicated light wavelength, n is the index of refraction, χ1111 is the third-order nonlinear
susceptibility, and n2 is the Kerr coefﬁcient of Eq. (10.69). Adapted from Yariv and Yeh (2007, Table 8.8),
whose χ1111 is 1/ϵ0 times ours.
ing by ∼E|χ/d| ∼(106 V m−1)(100 pm V−1) ∼10−4. (Here we have used the largest
electric ﬁeld that solids typically can support.) Therefore (as we have already dis-
cussed), only when dijk is greatly suppressed by isotropy of the nonlinear material
does χijkl and four-wave mixing become the dominant nonlinearity. And in that
order of magnitude
estimate for strength of
four-wave mixing
case, we expect the propagation lengthscale for strong, cumulative four-wave mix-
ing to be ∼104 larger than that (∼1cm) for the strongest three-wave mixing (i.e.,
ℓ4w >∼100 m).
In reality, as we shall see in Sec. 10.8.2, this estimate is overly pessimistic. In special
materials, ℓ4w can be less than a meter (though still much bigger than the three-wave
mixing’s centimeter). Two factors enable this. (i) If the nonlinear material is a ﬂuid
(e.g., CS2) conﬁned by solid walls, then it can support somewhat larger electric ﬁeld
strengths than a nonlinear crystal’s maximum, 106 V m−1. (ii) If the nonlinear mate-
rial is made of molecules signiﬁcantly larger than 10−10 m (e.g., organic molecules),
then the molecular electric dipoles induced by an electric ﬁeld can be signiﬁcantly
larger than our estimates (10.26); correspondingly, |χijkl| can signiﬁcantly exceed
(100 pm V−1)2; see Table 10.1.
In Secs. 10.8.2 and 10.8.3, we give (i) an example with strong four-wave mix-
ing: phase conjugation by a half-meter-long cell containing CS2 liquid and then
(ii) an example with weak but important four-wave mixing: light propagation in a
multikilometer-long fused-silica optical ﬁber.
10.8.2
10.8.2 Phase Conjugation via Four-Wave Mixing in CS2 Fluid
phase conjugation by
four-wave mixing
As an example of four-wave mixing, we discuss phase conjugation in a rectangular cell
that contains carbon disulﬁde (CS2) liquid (Fig. 10.16a). The ﬂuid is pumped by two
10.8 Four-Wave Mixing in Isotropic Media
559

pump wave
pump wave
phase-
conjugated
wave
(b)
(a)
phase-conjugated wave 4
incoming wave
incoming wave 3
z = 0
0
0
z
L
y
z = L
k1
k2
k3
k4
energy flux F
FIGURE 10.16 (a) A phase-conjugating mirror based on four-wave mixing. (b) The evolution of the
incoming wave’s ﬂux and the phase-conjugated wave’s ﬂux inside the mirror (the nonlinear medium).
strong waves, 1 and 2, propagating in opposite directions with the same frequency
as the incoming wave 3 that is to be phase conjugated. The pump waves are planar
without modulation, but wave 3 has a spatial modulation (slow compared to the
wave number) that carries, for example, a picture; A3 = A3(x, y; z). As we shall
see, nonlinear interaction of the two pump waves 1 and 2 and the incoming wave
3 produces outgoing wave 4, which is the phase conjugate of wave 3. All four waves
propagate in planes of constant x and have their electric ﬁelds in the x direction, so
the relevant component of the third-order nonlinearity is χxxxx = χ1111.
The resonance conditions (photon energy and momentum conservation) for this
resonance conditions for
four-wave mixing
four-wave mixing process are ω4 = ω1 + ω2 −ω3 and k4 = k1 + k2 −k3. Since the
three input waves all have the same frequency, ω1 = ω2 = ω3 = ω, the output wave 4
will also have ω4 = ω, so this is fully degenerate four-wave mixing. The pump waves
propagate in opposite directions, so they satisfy k1 = −k2, whence the output wave
has k4 = −k3. That is, it propagates in the opposite direction to the input wave 3 and
has the same frequency, as it must, if it is to be (as we claim) the phase conjugate of 3.
The nonlinear polarization that generates wave 4 is
P (4)
x
= 4ϵ0χ1111(E(1)
x E(2)
x E(3)
x
+ E(2)
x E(3)
x E(1)
x + . . .).
There are six terms in the sum (six ways to order the three waves), so
P (4)
x
= 24ϵ0χ1111E(1)
x E(2)
x E(3)
x .
Inserting
E(n)
x
= 1
2(A(n)ei(kn.x−ωnt) + A(n)∗ei(−kn+ωnt))
560
Chapter 10. Nonlinear Optics

into this P (4)
x
and plucking out the relevant term for our phase-conjugation process
(with the signal wave 3 phase conjugated and the pump waves not), we obtain
P (4)
x
= 3ϵ0χ1111A(1)A(2)A(3)∗ei(k4.x−ω4t).
(10.63)
Inserting this expression into the wave equation for wave 4 in an isotropic medium,
(∇2 + n2ω2
4/c2) (A(4)ei(k4.x−ω4t)) = −(ω2
4/c2)P (4)
x
[analog of the isotropic-medium
wave equation (10.33) for three-wave mixing] and making use of the fact that the
lengthscale on which wave 4 changes is long compared to its wavelength, we obtain
the following evolution equation for wave 4, which we augment with that for wave 3,
obtained in the same way:
dA(4)
dz
= −3ik
n2 χ1111A(1)A(2)A(3)∗,
dA(3)
dz
= −3ik
n2 χ1111A(1)A(2)A(4)∗.
(10.64)
Here we have dropped subscripts from k, since all waves have the same scalar wave
number, and we have used the dispersion relation ω/k = c/n common to all four
waves (since they all have the same frequency). We have not written down the evolu-
tion equations for the pump waves, because in practice they are very much stronger
than the incoming and phase-conjugated waves, so they change hardly at all during
the evolution.
It is convenient to change normalizations of the wave ﬁelds, as in three-wave
mixing, from A(n) (the electric ﬁeld) to An (the square root of energy ﬂux divided
by frequency, An =

Fn/ωn):
renormalized wave
amplitudes
A(n) =
1
2k
ϵ0n2An =
1
2ωn
ϵ0cnAn
(10.65)
[Eq. (10.35)]. Inserting these into the evolution equations (10.64) and absorbing the
constant pump-wave amplitudes into a coupling constant, we obtain
evolution equations for
fully degenerate four-
wave mixing in an isotropic
medium
dA4
dz = −iκA∗
3,
dA3
dz = iκA∗
4;
κ =
6ω2
c2n2ϵ0
χ1111A1A2.
(10.66)
Equations (10.66) are our ﬁnal, simple equations for the evolution of the input and
phase-conjugate waves in our isotropic, nonlinear medium (CS2 liquid). Inserting the
index of refraction n = 1.594 and nonlinear susceptibility χ1111 = 6,400 (pm/V)2 for
CS2 (Table 10.1), the angular frequency corresponding to 1.064 μm wavelength light
from, say, a Nd:YAG laser, and letting both pump waves n = 1 and 2 have energy
ﬂuxes Fn = ω|An|2 = 5 × 1010 W m−2 (corresponding to electric ﬁeld amplitudes
6.1 × 106 V m−1, six times larger than good nonlinear crystals can support), we
obtain for the magnitude of the coupling constant |κ| = 1/0.59 m−1. Thus, the CS2
cell of Fig. 10.16a need only be a half meter thick to produce strong phase conjugation.
10.8 Four-Wave Mixing in Isotropic Media
561

For an input wave A3o(x, y) at the cell’s front face z = 0 and no input wave 4 at
z = L, the solution to the evolution equations (10.66) is easily found to be, in the
interior of the cell:
A4(x, y, z) = −iκ
|κ|
sin[|κ|(z −L)]
cos[|κ|L]

A∗
3o(x, y),
A3(x, y, z) =
cos[|κ|(z −L)]
cos[|κ|L]

A3o(x, y).
(10.67)
The corresponding energy ﬂuxes, Fn = ω|An|2 are plotted in Fig. 10.16b, for a crystal
thickness L = 1/|κ| = 0.59 m. Notice that the pump waves amplify the rightward
propagating input wave, so it grows from the crystal front to the crystal back. At
the same time, the interaction of the input wave with the pump waves generates the
leftward propagating phase-conjugated wave, which begins with zero strength at the
back of the crystal and grows (when L ∼1/|κ|) to be stronger than the input wave at
the crystal front.
EXERCISES
Exercise 10.17 **Problem: Photon Creation and Annihilation
in a Phase-Conjugating Mirror
Describe the creation and annihilation of photons that underlies a phase-
conjugating mirror’s four-wave mixing. Speciﬁcally, how many photons of each wave
are created or annihilated? [Hint: See the discussion of photon creation and annihi-
lation for three-wave mixing at the end of Sec. 10.6.1.]
Exercise 10.18 **Problem: Spontaneous Oscillation in Four-Wave Mixing
Suppose the thickness of the nonlinear medium of the text’s four-wave mixing analysis
is L = π/(2κ), so the denominators in Eqs. (10.67) are zero. Explain the physical
nature of the resulting evolution of waves 3 and 4.
Exercise 10.19 Problem: Squeezed Light Produced by Phase Conjugation
Suppose a light beam is split in two by a beam splitter. One beam is reﬂected off an
ordinary mirror and the other off a phase-conjugating mirror. The beams are then
recombined at the beam splitter. Suppose that the powers returning to the beam
splitter are nearly the same; they differ by a fractional amount P/P = ϵ ≪1. Show
that the recombined light is in a strongly squeezed state, and discuss how one can
guarantee it is phase squeezed, or (if one prefers) amplitude squeezed.
10.8.3
10.8.3 Optical Kerr Effect and Four-Wave Mixing in an Optical Fiber
Suppose that an isotropic, nonlinear medium is driven by a single input plane wave
polarized in the x direction, Ex = ℜ[Ae−(kz−ωt)]. This input wave produces the
following polarization that propagates along with itself in resonance (Ex. 10.20):
Px = ϵ0χ0Ex + 6ϵ0χ1111E2Ex.
(10.68)
562
Chapter 10. Nonlinear Optics

Here the second term is due to four-wave mixing, and E2 is the time average of the
square of the electric ﬁeld, which can be expressed in terms of the energy ﬂux as E2 =
F/(ϵ0nc).Thefour-wave-mixingtermcanberegardedasanonlinearcorrectiontoχ0:
χ0 = 6χ1111E2 = [6χ1111/(nc ϵ0)]F. Since the index of refraction is n = √1 + χ0,
this corresponds to a fractional change of index of refraction given by
n = n2F ,
where n2 = 3χ1111
n2c ϵ0
.
(10.69)
This nonlinear change of n is called the optical Kerr effect,and the coefﬁcient n2 is the
optical Kerr effect; Kerr
coefﬁcient
Kerr coefﬁcient and has dimensions of 1/(energy ﬂux), or m2 W−1. Values for n2 for
several materials are listed in Table 10.1.
We have already brieﬂy discussed an important application of the optical Kerr
effect: the self-focusing of a laser beam, which plays a key role in mode locked lasers
(Sec. 10.2.3) and also in laser fusion.
The optical Kerr effect is also important in the optical ﬁbers used in modern com-
munication (e.g., to carry telephone, television, and internet signals to your home).
Such ﬁbers are generally designed to support just one spatial mode of propagation: the
fundamental Gaussian mode of Sec. 8.5.5 or some analog of it. Their light-carrying
cores are typically made from fused silica doped with particular impurities, so their
Kerr coefﬁcients are n2 ≃3 × 10−20 m2 W−1 (Table 10.1). Although the ﬁbers are
not spatially homogeneous and the wave is not planar, one can show (and it should
not be surprising) that the ﬁbers nonetheless exhibit the optical Kerr effect, with
n = n2Feff. Here Feff, the effective energy ﬂux, is the light beam’s power P divided
by an effective cross sectional area, πσ 2
0, with σ0 the Gaussian beam’s radius, deﬁned
in Eq. (8.39): Feff = P/πσ 2
0; see Yariv and Yeh (2007, Sec. 14.1).
As a realistic indication of the importance of the optical Kerr effect in communi-
cation ﬁbers, consider a signal beam with mean power P = 10 mW and a beam radius
σ0 = 5 μm and thence an effective energy ﬂux Feff = 127 MW m−2. If the wavelength
is 2π/k = 0.694 μm, then Table 10.1 gives n = 1.455 and n2 = 3 × 10−20 m2 W−1.
When this beam travels a distance L = 50 km along the ﬁber, its light experiences a
phase shift
φ = n
n kL = n2
n FkL ≃1.2 rad.
(10.70)
A phase shift of this size or larger can cause signiﬁcant problems for optical commu-
nication. For example:
1. Variations of the ﬂux, when pulsed signals are being transmitted, cause time-
varying phase shifts that modify the signals’ phase evolution (self-phase mod-
ulation). One consequence of this is the broadening of each pulse; another
is a nonlinearly induced chirping of each pulse (slightly lower frequency at
beginning and higher at end).
10.8 Four-Wave Mixing in Isotropic Media
563

2. Fibers generally carry many channels of communication with slightly differ-
ent carrier frequencies, and the time-varying ﬂux of one channel can modify
the phase evolution of another (cross-phase modulation).
Various techniques have been developed to deal with these issues (see, e.g., Yariv and
Yeh, 2007, Chap. 14).
In long optical ﬁbers, pulse broadening due to the nonlinear optical Kerr effect can
be counterbalanced by a narrowing of a pulse due to linear dispersion (dependence
of group velocity on frequency). The result is an optical soliton: a pulse of light with a
optical soliton
special shape that travels down the ﬁber without any broadening or narrowing (see,
e.g., Yariv and Yeh, 2007, Sec. 14.5). In Sec. 16.3, we study in full mathematical detail
this soliton phenomenon for nonlinear waves on the surface of water; in Sec. 23.6, we
study it for nonlinear waves in plasmas.
EXERCISES
Exercise 10.20 Derivation: Optical Kerr Effect
(a) Derive Eq. (10.68) for the polarization induced in an isotropic medium by a
linearly polarized electromagnetic wave.
(b) Fill in the remaining details of the derivation of Eq. (10.69) for the optical Kerr
effect.
Bibliographic Note
For a lucid and detailed discussion of lasers and their applications, see Saleh and Teich
(2007), and at a more advanced level, Yariv and Yeh (2007). For less detailed but clear
discussions, see standard optics textbooks, such as Jenkins and White (1976), Ghatak
(2010), and Hecht (2017).
For a lucid and detailed discussion of holography and its applications, see
Goodman (2005). Most optics textbooks contain less detailed but clear discussions.
We like Jenkins and White (1976), Brooker (2003), Sharma (2006), Ghatak (2010),
and Hecht (2017).
Wave-wave mixing in nonlinear media is discussed in great detail and with many
applications by Yariv and Yeh (2007). Some readers might ﬁnd an earlier book by
Yariv (1989) pedagogically easier; it was written when the subject was less rich, but
the foundations were already in place, and it has more of a quantum mechanical focus.
The fundamental concepts of wave-wave mixing and its underlying physical processes
are treated especially nicely by Boyd (2008). A more elementary treatment with focus
on applications is given by Saleh and Teich (2007). Among treatments in standard
optics texts, we like Sharma (2006).
564
Chapter 10. Nonlinear Optics

IV
PART IV
ELASTICITY
Although ancient civilizations built magniﬁcent pyramids, palaces, and cathedrals
and presumably developed insights into how to avoid their collapse, mathematical
models for this (the theory of elasticity) were not developed until the seventeenth
century and later.
The seventeenth-century focus was on a beam (e.g., a vertical building support)
under compression or tension. Galileo initiated this study in 1632, followed most
notably by Robert Hooke1 in 1660. Bent beams became the focus with the work of
Edme Mariotte in 1680. Bending and compression came together with Leonhard
Euler’s 1744 theory of the buckling of a compressed beam and his derivation of
the complex shapes of very thin wires, whose ends are pushed toward each other
(elastica). These ideas were extended to 2-dimensional thin plates by Marie-Sophie
Germain and Joseph-Louis Lagrange in 1811–1816 in a study that was brought to full
fruition by Augustus Edward Hugh Love in 1888. The full theory of 3-dimensional,
stressed, elastic objects was developed by Claude-Louis Navier and by Augustin-Louis
Cauchy in 1821–1822. A number of great mathematicians and natural philosophers
then developed techniques for solving the Navier-Cauchy equations, particularly
for phenomena relevant to railroads and construction. In 1956, with the advent of
modern digital computers, M. J. Turner, R. W. Clough, H. C. Martin, and L. J. Topp
pioneered ﬁnite-element methods for numerically modeling stressed bodies. Finite-
element numerical simulations are now a standard tool for designing mechanical
structures and devices, and, more generally, for solving difﬁcult elasticity problems.
These historical highlights cannot begin to do justice to the history of elasticity
research. For much more detail see, for example, the (out-of-date) long introduction
in Love (1927); and for far more detail than most anyone wants, see the (even more
out-of-date) two-volume work by Todhunter and Pearson (1886).
1.
One of whose many occupations was architect.
565

Despite its centuries-old foundations, elasticity remains of great importance today,
and its modern applications include some truly interesting phenomena. Among those
applications, most of which we shall touch on in this book, are
1. the design of bridges, skyscrapers, automobiles, and other structures and
mechanical devices and the study of their structural failure;
2. the development and applications of new materials, such as carbon nano-
tubes, which are so light and strong that one could aspire to use them to
build a tether connecting a geostationary satellite to Earth’s surface;
3. the design of high-precision physics experiments with torsion pendula and
microcantilevers, including brane-worlds-motivated searches for gravita-
tional evidence of macroscopic higher dimensions of space;
4. the creation of nano-scale cantilever probes in atomic-force microscopes;
5. the study of biophysical systems, such as DNA molecules, cell walls, and the
Venus ﬂy trap plant; and
6. the study of plate tectonics, quakes, seismic waves, and seismic tomography
in Earth and other planets. Much of the modern, geophysical description
of mountain building involves buckling and fracture within the lithosphere
through viscoelastic processes that combine the principles of elasticity with
those of ﬂuid dynamics discussed in Part V.
Indeed, elastic solids are so central to everyday life and to modern science that
a basic understanding of their behavior should be part of the repertoire of every
physicist. That is the goal of Part IV of the book.
We devote just two chapters to elasticity. The ﬁrst (Chap. 11) will focus on elasto-
statics: the properties of materials and solid objects that are in static equilibrium,
with all forces and torques balancing out. The second (Chap. 12) will focus on elasto-
dynamics: the dynamical behavior of materials and solid objects that are perturbed
away from equilibrium.
566
Part IV

11
CHAPTER ELEVEN
Elastostatics
Ut tensio, sic vis
ROBERT HOOKE (1678)
11.1
11.1 Overview
From the viewpoint of continuum mechanics, a solid is a substance that recovers
its original shape after the application and removal of any small stress. Note the
requirement that this be true for any small stress. Many ﬂuids (e.g., water) satisfy our
deﬁnition as long as the applied stress is isotropic, but they will deform permanently
under a shear stress. Other materials (e.g., Earth’s crust) are only solid for limited
times but undergo plastic ﬂow when a small stress is applied for a long time.
Hooke’s law
We focus our attention in this chapter on solids whose deformation (quantiﬁed by
a tensorial strain) is linearly proportional to the applied, small, tensorial stress. This
linear, 3-dimensional stress-strain relationship, which we develop and explore in this
chapter, generalizes Hooke’s famous 1-dimensional law, which states that if an elastic
wire or rod is stretched by an applied force F (Fig. 11.1a), its fractional change of
length (its strain) is proportional to the force, ℓ/ℓ∝F.
Hooke’s law turns out to be one component of a 3-dimensional stress-strain rela-
tion, but to understand it deeply in that language, we must ﬁrst deﬁne and understand
the strain tensor and the stress tensor. Our approach to these tensors follows the ge-
ometric, frame-independent philosophy introduced in Chap. 1. Some readers may
wish to review that philosophy and mathematics by rereading or browsing Chap. 1.
We begin our development of elasticity theory in Sec. 11.2 by introducing, in a
frame-independent way, the vectorial displacement ﬁeld ξ(x) inside a stressed body
(Fig. 11.1b), and its gradient ∇ξ, whose symmetric part is the strain tensor S. We then
express the strain tensor as the sum of an expansion  that represents volume changes
and a shear  that represents shape changes.
In Sec. 11.3.1, we introduce the stress tensor, and in Sec. 11.3.2, we discuss the
realms in which there is a linear relationship between stress and strain, and ways
in which linearity can fail. In Sec. 11.3.3, assuming linearity, we discuss how the
material resists volume change by developing an opposing isotropic stress, with a
stress/strainratiothatisequaltothebulkmodulus K.Wediscusshowthematerialalso
567

BOX 11.1.
READERS’ GUIDE
.
This chapter relies heavily on the geometric view of Newtonian
physics (including vector and tensor analysis) laid out in Chap. 1.
.
Chapter 12 (Elastodynamics) is an extension of this chapter; to
understand it, this chapter must be mastered.
.
The idea of the irreducible tensorial parts of a tensor, and its most
important example, decomposition of the gradient of a displacement
vector into expansion, rotation, and shear (Sec. 11.2.2 and Box
11.2) will be encountered again in Part V (Fluid Dynamics), Part VI
(Plasma Physics), and Part VII (General Relativity).
.
Differentiation of vectors and tensors with the help of connection
coefﬁcients (Sec. 11.8; Track Two) will be used occasionally in
Part V (Fluid Dynamics) and Part VI (Plasma Physics), and will be
generalizedtononorthonormalbasesinPartVII(GeneralRelativity),
where it will become Track One and will be used extensively.
.
No other portions of this chapter are important for subsequent parts
of this book.
(b)
(a)
z
F
ξ
ℓ + ℓ
FIGURE 11.1 (a) Hooke’s 1-dimensional law for a rod
stretched by a force F: ℓ/ℓ∝F. (b) The 3-dimensional
displacement vector ξ(x) inside the stretched rod.
resists a shear-type strain by developing an opposing shear stress with a stress/strain
ratio equal to twice the shear modulus 2μ. In Sec. 11.3.4, we evaluate the energy
density stored in elastostatic strains; in Sec. 11.3.5, we explore the inﬂuence of thermal
expansion on the stress-strain relationship; and in Sec. 11.3.6, we discuss the atomic-
force origin of the elastostatic stresses and use atomic considerations to estimate
568
Chapter 11. Elastostatics

the magnitudes of the bulk and shear moduli. Then in Sec. 11.3.7, we compute the
elastic force density inside a linear material as the divergence of the sum of its elastic
stresses, and we formulate the law of elastostatic stress balance (the Navier-Cauchy
equation) as the vanishing sum of the material’s internal elastic force density and
any other force densities that may act (usually a gravitational force density due to
the weight of the elastic material). We discuss the analogy between this elastostatic
stress-balance equation and Maxwell’s electrostatic and magnetostatic equations. We
describe how mathematical techniques common in electrostatics can also be applied
to solve the Navier-Cauchy equation, subject to boundary conditions that describe
external forces.
In Sec. 11.4, as a simple example, we use our 3-dimensional formulas to deduce
Hooke’s law for the 1-dimensional longitudinal stress and strain in a stretched wire.
When the elastic body that one studies is very thin in two dimensions compared to
the third (e.g., a wire or rod), we can reduce the 3-dimensional elastostatic equations
to a set of coupled 1-dimensional equations by taking moments of the elastostatic
equations. We illustrate this technique in Sec. 11.5, where we treat the bending of
beams and other examples.
Elasticity theory, as developed in this chapter, is an example of a common (some
would complain far too common) approach to physics problems, namely, to linearize
them. Linearization may be acceptable when the distortions are small. However, when
deformed by sufﬁciently strong forces, elastic media may become unstable to small
displacements, which can then grow to large amplitude, causing rupture. We study an
example of this in Sec. 11.6: the buckling of a beam when subjected to a sufﬁciently
large longitudinal stress. Buckling is associated with bifurcation of equilibria, a phe-
nomenon that is common to many physical systems, not just elastostatic ones. We
illustrate bifurcation in Sec. 11.6 using our beam under a compressive load, and we
explore its connection to catastrophe theory.
In Sec. 11.7, we discuss dimensional reduction by the method of moments for
bodies that are thin in only 1 dimension, not two, such as plates and thin mirrors. In
suchbodies, the3-dimensionalelastostaticequationsarereducedto2dimensions.We
illustrate our 2-dimensional formalism by the stress polishing of telescope mirrors.
Because elasticity theory entails computing gradients of vectors and tensors, and
practical calculations are often best performed in cylindrical or spherical coordinate
systems, we present a mathematical digression in Track-Two Sec. 11.8—an introduc-
tion to how one can perform practical calculations of gradients of vectors and tensors
in the orthonormal bases associated with curvilinear coordinate systems, using the
concept of a connection coefﬁcient.
As illustrative examples of both connection coefﬁcients and elastostatic force
balance, in Track-Two Sec. 11.9 and various exercises, we give practical examples of
solutions of the elastostatic force-balance equation in cylindrical coordinates using
two common techniques of elastostatics and electrostatics: separation of variables
(text of Sec. 11.9.2) and Green’s functions (Ex. 11.27).
11.1 Overview
569

11.2
11.2 Displacement and Strain
We begin our study of elastostatics by introducing the elastic displacement vector, its
gradient, and the irreducible tensorial parts of its gradient. We then identify the strain
as the symmetric part of the displacement’s gradient.
11.2.1
11.2.1 Displacement Vector and Its Gradient
displacement vector
Elasticity provides a major application of the tensorial techniques we developed in
Chap. 1. Label the position of a point (a tiny bit of solid) in an unstressed body,
relative to some convenient origin in the body, by its position vector x. Let a force
be applied, so the body deforms and the point moves from x to x + ξ(x); we call ξ
the point’s displacement vector (Fig. 11.1b). If ξ were constant (i.e., if its components
in a Cartesian coordinate system were independent of location in the body), then the
body would simply be translated and would undergo no deformation. To produce a
deformation, we must make the displacement ξ change from one location to another.
The most simple, coordinate-independent way to quantify those changes is by the
gradient of ξ, ∇ξ. This gradient is a second-rank tensor ﬁeld, which we denote by W:
W ≡∇ξ.
(11.1a)
This tensor is a geometric object, deﬁned independently of any coordinate system
in the manner described in Sec. 1.7. In slot-naming index notation (Sec. 1.5), it is
denoted
Wij = ξi;j,
(11.1b)
where the index j after the semicolon is the name of the gradient slot.
In a Cartesian coordinate system the components of the gradient are always just
partial derivatives [Eq. (1.15c)], and therefore the Cartesian components of W are
Wij = ∂ξi
∂xj
= ξi,j.
(11.1c)
(Recall that indices following a comma represent partial derivatives.) In Sec. 11.8, we
learn how to compute the components of the gradient in cylindrical and spherical
coordinates.
In any small neighborhood of any point xo in a deformed body, we can reconstruct
the displacement vector ξ from its gradient W up to an additive constant. Speciﬁcally,
in Cartesian coordinates, by virtue of a Taylor-series expansion, ξ is given by
ξi(x) = ξi(xo) + (xj −xoj)(∂ξi/∂xj) + . . .
= ξi(xo) + (xj −xoj)Wij + . . . .
(11.2)
If we place the origin of Cartesian coordinates at xo and let the origin move with the
point there as the body deforms [so ξ(xo) = 0], then Eq. (11.2) becomes
ξi = Wijxj
when |x| is sufﬁciently small.
(11.3)
570
Chapter 11. Elastostatics

We have derived this as a relationship between components of ξ, x, and W in a
Cartesian coordinate system. However, the indices can also be thought of as the names
of slots (Sec. 1.5) and correspondingly, Eq. (11.3) can be regarded as a geometric,
coordinate-independent relationship among the vectors and tensor ξ, x, and W.
In Ex. 11.2, we use Eq. (11.3) to gain insight into the displacements associated with
various parts of the gradient W.
11.2.2
11.2.2 Expansion, Rotation, Shear, and Strain
irreducible tensorial parts
of a tensor
In Box 11.2, we introduce the concept of the irreducible tensorial parts of a tensor, and
we state that in physics, when one encounters an unfamiliar tensor, it is often useful
to identify the tensor’s irreducible parts. The gradient of the displacement vector,
W = ∇ξ, is an important example. It is a second-rank tensor. Therefore, as discussed
expansion, shear, and
rotation
in Box 11.2, its irreducible tensorial parts are its trace  ≡Tr(W) = Wii = ∇. ξ,
which is called the deformed body’s expansion (for reasons we shall explore below); its
symmetric, trace-free part Σ, which is called the body’s shear; and its antisymmetric
part R, which is called the body’s rotation:
 = Wii = ∇. ξ,
(11.4a)
Σij = 1
2(Wij + Wji) −1
3gij = 1
2(ξi;j + ξj;i) −1
3ξk;k gij,
(11.4b)
Rij = 1
2(Wij −Wji) = 1
2(ξi;j −ξj;i).
(11.4c)
Here gij is the metric, which has components gij = δij (Kronecker delta) in Cartesian
coordinates, and repeated indices [the ii in Eq. (11.4a)] are to be summed [Eq. (1.9b)
and subsequent discussion].
We can reconstruct W = ∇ξ from these irreducible tensorial parts in the following
manner [Eq. (4) of Box 11.2, rewritten in abstract notation]:
∇ξ = W = 1
3g + Σ + R.
(11.5)
Let us explore the physical effects of the three separate parts of W in turn. To
understand expansion, consider a small 3-dimensional piece V of a deformed body (a
volume element). When the deformation x →x + ξ occurs, a much smaller element
of area1 d on the surface ∂V of V gets displaced through the vectorial distance ξ
and in the process sweeps out a volume ξ . d. Therefore, the change in the volume
element’s volume, produced by ξ, is
δV =

∂V
d . ξ =

V
dV ∇. ξ = ∇. ξ

V
dV = (∇. ξ) V .
(11.6)
1.
Note that we use  for a vectorial area and Σ for the shear tensor. There should be no confusion.
11.2 Displacement and Strain
571

BOX 11.2.
IRREDUCIBLE TENSORIAL PARTS OF A SECOND-
RANK TENSOR IN 3-DIMENSIONAL EUCLIDEAN SPACE
In quantum mechanics, an important role is played by the rotation group: the
set of all rotation matrices, viewed as a mathematical entity called a group
(e.g., Mathews and Walker, 1970, Chap. 16). Each tensor in 3-dimensional
Euclidean space, when rotated, is said to generate a speciﬁc representation
of the rotation group. Tensors that are “big” (in a sense to be discussed later
in this box) can be broken down into a sum of several tensors that are “as
small as possible.” These smallest tensors are said to generate irreducible
representations of the rotation group. All this mumbo-jumbo is really simple,
when one thinks about tensors as geometric, frame-independent objects.
As an example, consider an arbitrary second-rank tensor Wij in 3-
dimensional, Euclidean space. In the text Wij is the gradient of the
displacement vector. From this tensor we can construct the following “smaller”
tensors by linear operations that involve only Wij and the metric gij. (As these
smaller tensors are enumerated, the reader should think of the notation used
as the basis-independent, frame-independent, slot-naming index notation of
Sec. 1.5.1.) The smaller tensors are the contraction (i.e., trace) of Wij,
 ≡Wijgij = Wii;
(1)
the antisymmetric part of Wij,
Rij ≡1
2(Wij −Wji);
(2)
and the symmetric, trace-free part of Wij,
Σij ≡1
2(Wij + Wji) −1
3
gijWkk.
(3)
It is straightforward to verify that the original tensor Wij can be reconstructed
from these three smaller tensors plus the metric gij as follows:
Wij = 1
3gij + Rij + Σij.
(4)
One way to see the sense in which , Rij, and Σij are smaller than
Wij is by counting the number of independent real numbers required
to specify their components in an arbitrary basis. (Think of the index
notation as components on a chosen basis.) The original tensor Wij has
three × three = nine components (W11, W12, W13, W21, . . . W33), all of which
are independent. By contrast, the scalar  has just one. The antisymmetric
(continued)
572
Chapter 11. Elastostatics

BOX 11.2.
(continued)
tensor Rij has just three independent components, R12, R23, and R31. Finally,
the nine components of Σij are not independent; symmetry requires that
Σij ≡Σji, which reduces the number of independent components from nine
to six; being trace-free, Σii = 0, reduces it further from six to ﬁve. Therefore,
(ﬁve independent components in Σij) + (three independent components in
Rij) + (one independent component in ) = 9 = (number of independent
components in Wij).
The number of independent components (one for , three for Rij, and ﬁve
for Σij) is a geometric, basis-independent concept: It is the same, regardless
of the basis used to count the components; and for each of the smaller tensors
that make up Wij, it is easily deduced without introducing a basis at all (think
here in slot-naming index notation): The scalar  is clearly speciﬁed by just
one real number. The antisymmetric tensor Rij contains precisely the same
amount of information as the vector
φi ≡−1
2ϵijkRjk,
(5)
as can be seen from the fact that Eq. (5) can be inverted to give
Rij = −ϵijkφk;
(6)
and the vector φi can be characterized by its direction in space (two numbers)
plus its length (a third). The symmetric, trace-free tensor Σij can be
characterized geometrically by the ellipsoid (gij + εΣij)ζiζj = 1, where
ε is an arbitrary number ≪1, and ζi is a vector whose tail sits at the center of
the ellipsoid and whose head moves around on the ellipsoid’s surface. Because
Σij is trace-free, this ellipsoid has unit volume. Therefore, it is speciﬁed fully
by the direction of its longest principal axis (two numbers) plus the direction
of a second principal axis (a third number) plus the ratio of the length of the
second axis to the ﬁrst (a fourth number) plus the ratio of the length of the
third axis to the ﬁrst (a ﬁfth number).
Each of the tensors , Rij (or equivalently, φi), and Σij is irreducible
in the sense that one cannot construct any smaller tensors from it, by any
linear operation that involves only it, the metric, and the Levi-Civita tensor.
Irreducible tensors in 3-dimensional Euclidean space always have an odd
number of components. It is conventional to denote this number by 2l + 1,
where the integer l is called the “order of the irreducible representation of the
(continued)
11.2 Displacement and Strain
573

BOX 11.2.
(continued)
rotation group” that the tensor generates. For , Rij (or equivalently,
φi), and Σjk, l is 0, 1, and 2, respectively. These three tensors can be
mapped into the spherical harmonics of order l = 0, 1, 2; and their
2l + 1 components correspond to the 2l + 1 values of the quantum number
m = −l, −l + 1 . . . , l −1, l. (For details see, e.g., Thorne, 1980, Sec. II.C.)
In physics, when one encounters a new tensor, it is often useful to identify
the tensor’s irreducible parts. They almost always play important, independent
roles in the physical situation one is studying. We meet one example in this
chapter, another when we study ﬂuid dynamics (Chap. 13), and a third in
general relativity (Box 25.2).
Here we have invoked Gauss’s theorem in the second equality, and in the third we
have used the smallness of V to infer that ∇. ξ is essentially constant throughout V
and so can be pulled out of the integral. Therefore, the fractional change in volume is
equal to the trace of the stress tensor (i.e., the expansion):
expansion as fractional
volume change
δV
V = ∇. ξ = .
(11.7)
See Fig. 11.2 for a simple example.
shearing displacements
The shear tensor Σ produces the shearing displacements illustrated in Figs. 11.2
and 11.3. As the tensor has zero trace, there is no volume change when a body under-
goes a pure shear deformation. The shear tensor has ﬁve independent components
(Box 11.2). However, by rotating our Cartesian coordinates appropriately, we can
transform away all the off-diagonal elements, leaving only the three diagonal elements
shear’s stretch and
squeeze along principal
axes
Σxx, Σyy, and Σzz, which must sum to zero. This is known as a principal-axis trans-
formation. Each element produces a stretch (Σ.. > 0) or squeeze (Σ.. < 0) along its
S
g
Σ
R
+
+
=
FIGURE 11.2 A simple example of the decomposition of a 2-dimensional distortion
S of a square body into an expansion , a shear Σ, and a rotation R.
574
Chapter 11. Elastostatics

x2
x1
FIGURE 11.3 Shear in 2 dimensions. The displacement of points in a solid
undergoing pure shear is the vector ﬁeld ξ(x) given by Eq. (11.3) with Wji
replaced by Σji: ξj = Σjixi = Σj1x1 + Σj2x2. The integral curves of this vector
ﬁeld are plotted in this ﬁgure. The ﬁgure is drawn using principal axes, which are
Cartesian, so Σ12 = Σ21 = 0 and Σ11 = −Σ22, which means that ξ1 = Σ11x1 and
ξ2 = −Σ11x2; or, equivalently, ξx = Σxxx and ξy = −Σxxy. The integral curves
of this simple vector ﬁeld are the hyperbolas shown. Note that the displacement
increases linearly with distance from the origin. The shear shown in Fig. 11.2 is
the same as this, but with the axes rotated counterclockwise by 45°.
axis,2 and their vanishing sum (the vanishing trace of Σ) means that there is no net
volume change. The components of the shear tensor in any Cartesian coordinate sys-
tem can be written down immediately from Eq. (11.4b) by substituting the Kronecker
delta δij for the components of the metric tensor gij and treating all derivatives as
partial derivatives:
Σxx = 2
3
∂ξx
∂x −1
3
∂ξy
∂y + ∂ξz
∂z

,
Σxy = 1
2
∂ξx
∂y +
∂ξy
∂x

,
(11.8)
and similarly for the other components. The analogous equations in spherical and
cylindrical coordinates are given in Sec. 11.8.
rotation vector
The third term Rin Eq. (11.5) describes a pure rotation, which does not deform the
solid. To verify this, write ξ = φ × x, where φ is a small rotation of magnitude φ about
an axis parallel to the direction of φ. Using Cartesian coordinates in 3-dimensional
Euclidean space, we can demonstrate by direct calculation that the symmetric part of
W = ∇ξ vanishes (i.e.,  = Σ = 0) and that
Rij = −ϵijkφk,
φi = −1
2ϵijkRjk.
(11.9a)
2.
More explicitly, Σxx > 0produces a stretch along the x-axis, Σyy < 0produces a squeeze along the y-axis,
etc.
11.2 Displacement and Strain
575

Therefore, the elements of the tensor R in a Cartesian coordinate system just involve
the vectorial rotation angle φ. Note that expression (11.9a) for φ and expression
(11.4c) for Rij imply that φ is half the curl of the displacement vector:
φ = 1
2∇× ξ.
(11.9b)
A simple example of rotation is shown in the last picture in Fig. 11.2.
Elastic materials resist expansion  and shear Σ, but they don’t mind at all having
their orientation in space changed (i.e., they do not resist rotations R). Correspond-
ingly, in elasticity theory a central focus is on expansion and shear. For this reason the
symmetric part of the gradient of ξ,
strain tensor
Sij ≡1
2(ξi;j + ξj;i) = Σij + 1
3gij,
(11.10)
which includes the expansion and shear but omits the rotation, is given a special
name—the strain—and is paid great attention.
Let us consider some examples of strains that arise in physical systems.
1. Understanding how materials deform under various loads (externally ap-
plied forces) is central to mechanical, civil, and structural engineering. As
we learn in Sec. 11.3.2, all Hookean materials (materials with strain propor-
tional to stress when the stress is small) crack or break when the load is so
great that any component of their strain exceeds ∼0.1, and almost all crack
or break at strains ∼0.001. For this reason, in our treatment of elasticity the-
ory (this chapter and the next), we focus on strains that are small compared
to unity.
2. Continental drift can be measured on the surface of Earth using very long
baseline interferometry, a technique in which two or more radio telescopes
are used to detect interferometric fringes using radio waves from an astro-
nomical point source. (A similar technique uses the Global Positioning Sys-
tem to achieve comparable accuracy.) By observing the fringes, it is possible
to detect changes in the spacing between the telescopes as small as a fraction
of a wavelength (∼1cm). As the telescopes are typically 1,000 km apart, this
means that dimensionless strains ∼10−8 can be measured. The continents
drift apart on a timescale <∼108 yr, so it takes roughly a year for these changes
to grow large enough to be measured. Such techniques are also useful for
monitoring earthquake faults.
3. The smallest time-varying strains that have been measured so far involve
laser interferometer gravitational-wave detectors, such as LIGO. In each
arm of a LIGO interferometer, two mirrors hang freely, separated by 4 km.
In 2015 their separations were monitored (at frequencies of ∼100 Hz) to
∼4 × 10−19 m, four ten-thousandths the radius of a nucleon. The associated
strain is 1× 10−22. Although this strain is not associated with an elastic solid,
it does indicate the high accuracy of optical measurement techniques.
576
Chapter 11. Elastostatics

EXERCISES
Exercise 11.1 Derivation and Practice: Reconstruction of a Tensor from Its Irreducible
Tensorial Parts
Using Eqs. (1), (2), and (3) of Box 11.2, show that 1
3gij + Σij + Rij is equal to Wij.
Exercise 11.2 Example: Displacement Vectors Associated with Expansion, Rotation,
and Shear
(a) Consider a W = ∇ξ that is pure expansion: Wij = 1
3gij. Using Eq. (11.3) show
that, in the vicinity of a chosen point, the displacement vector is ξi = 1
3xi. Draw
this displacement vector ﬁeld.
(b) Similarly, draw ξ(x) for a W that is pure rotation. [Hint: Express ξ in terms of the
vectorial angle φ with the aid of Eq. (11.9b).]
(c) Draw ξ(x) for a W that is pure shear. To simplify the drawing, assume that the
shear is conﬁned to the x-y plane, and make your drawing for a shear whose only
nonzero components are Σxx = −Σyy. Compare your drawing with Fig. 11.3.
11.3
11.3 Stress, Elastic Moduli, and Elastostatic Equilibrium
11.3.1
11.3.1 Stress Tensor
The forces acting in an elastic solid are measured by a second-rank tensor, the stress
tensor introduced in Sec. 1.9. Let us recall the deﬁnition of this stress tensor.
Consider two small, contiguous regions in a solid. If we take a small element of
area d in the contact surface with its positive sense3 (same as the direction of d
viewed as a vector) pointing from the ﬁrst region toward the second, then the ﬁrst
region exerts a force dF (not necessarily normal to the surface) on the second through
this area. The force the second region exerts on the ﬁrst (through the area −d) will,
by Newton’s third law, be equal and opposite to that force. The force and the area
of contact are both vectors, and there is a linear relationship between them. (If we
double the area, we double the force.) The two vectors therefore will be related by a
second-rank tensor, the stress tensor T:
stress tensor
dF = T . d = T(. . . , d);
dFi = Tijdj.
(11.11)
Thus the tensor T is the net (vectorial) force per unit (vectorial) area that a body
exerts on its surroundings. Be aware that many books on elasticity (e.g., Landau and
Lifshitz, 1986) deﬁne the stress tensor with the opposite sign to that in Eq. (11.11).
Also be careful not to confuse the shear tensor Σjk with the vectorial inﬁnitesimal
surface area dj.
3.
For a discussion of area elements including their positive sense, see Sec. 1.8.
11.3 Stress, Elastic Moduli, and Elastostatic Equilibrium
577

We often need to compute the total elastic force acting on some ﬁnite volume V.
To aid in this, we make an important assumption, discussed in Sec. 11.3.6: the stress
is determined by local conditions and can be computed from the local arrangement
of atoms. If this assumption is valid, then (as we shall see in Sec. 11.3.6), we can
compute the total force acting on the volume element by integrating the stress over
its surface ∂V:
F = −

∂V
T . d = −

V
∇. TdV,
(11.12)
where we have invoked Gauss’s theorem, and the minus sign is included because by
convention, for a closed surface ∂V, d points out of V instead of into it.
Equation (11.12) must be true for arbitrary volumes, so we can identify the elastic
force density f acting on an elastic solid as
elastic force density
f = −∇. T.
(11.13)
In elastostatic equilibrium, this force density must balance all other volume forces
acting on the material, most commonly the gravitational force density, so
force balance equation
f + ρg = 0,
(11.14)
where g is the gravitational acceleration. (Again, there should be no confusion be-
tween the vector g and the metric tensor g.) There are other possible external forces,
someofwhichweshallencounterlaterinthecontextofﬂuids(e.g., anelectromagnetic
force density). These can be added to Eq. (11.14).
Just as for the strain, the stress tensor T can be decomposed into its irreducible
tensorial parts, a pure trace (the pressure P ) plus a symmetric trace-free part (the
shear stress):
pressure and shear stress
T = P g + Tshear;
P = 1
3 Tr(T) = 1
3Tii.
(11.15)
There is no antisymmetric part, because the stress tensor is symmetric, as we saw in
Sec. 1.9. Fluids at rest exert isotropic stresses: T = P g. They cannot exert shear stress
when at rest, though when moving and shearing, they can exert a viscous shear stress,
as we discuss extensively in Part V (initially in Sec. 13.7.2).
Pascal
In SI units, stress is measured in units of Pascals, denoted Pa:
1 Pa = 1 N m−2 = 1 kg m s−2
m2
,
(11.16)
or sometimes in GPa = 109 Pa. In cgs units, stress is measured in dyne cm−2. Note
that 1 Pa = 10 dyne cm−2.
Now let us consider some examples of stresses.
1. Atmospheric pressure is equal to the weight of the air in a column of unit
area extending above the surface of Earth, and thus is roughly P ∼ρgH ∼
578
Chapter 11. Elastostatics

105 Pa, where ρ ≃1 kg m−3 is the density of air, g ≃10 m s−2 is the ac-
celeration of gravity at Earth’s surface, and H ≃10 km is the atmospheric
scale height [H ≡(d ln P/dz)−1, with z the vertical distance]. Thus 1 atmo-
sphere is ∼105 Pa (or, more precisely, 1.01325 × 105 Pa). The stress tensor is
isotropic.
2. Suppose we hammer a nail into a block of wood. The hammer might weigh
m ∼0.3 kg and be brought to rest from a speed of v ∼10 m s−1 in a distance
of, say, d ∼3 mm. Then the average force exerted on the wood by the nail,
as it is driven, is F ∼mv2/d ∼104 N. If this is applied over an effective
area A ∼1 mm2, then the magnitude of the typical stress in the wood is
∼F/A ∼1010 Pa ∼105 atmosphere. There is a large shear component to the
stress tensor, which is responsible for separating the ﬁbers in the wood as the
nail is hammered.
3. Neutron stars are as massive as the Sun, M ∼2 × 1030 kg, but have far
smaller radii, R ∼10 km. Their surface gravities are therefore g ∼GM/
R2 ∼1012 m s−2, 10 billion times that encountered on Earth. They have
solid crusts of density ρ ∼1016 kg m−3 that are about 1 km thick. In the
crusts, the main contribution to the pressure is from the degeneracy of
relativistic electrons (see Sec. 3.5.3). The magnitude of the stress at the base
of a neutron-star crust is P ∼ρgH ∼1031 Pa! The crusts are solid, because
the free electrons are neutralized by a lattice of ions. However, a crust’s shear
modulus is only a few percent of its bulk modulus.
4. As we discuss in Sec. 28.7.1, a popular cosmological theory called inﬂa-
tion postulates that the universe underwent a period of rapid, exponen-
tial expansion during its earliest epochs. This expansion was driven by
the stress associated with a false vacuum. The action of this stress on the
universe can be described quite adequately using a classical stress tensor.
If the interaction energy is E ∼1015 GeV, the supposed scale of grand
uniﬁcation, and the associated lengthscale is the Compton wavelength as-
sociated with that energy, l ∼ℏc/E, then the magnitude of the stress is
∼E/l3 ∼1097(E/1015 GeV)4 Pa.
5. Elementary particles interact through forces. Although it makes no
sense to describe this interaction using classical elasticity, it is reasonable
to make order-of-magnitude estimates of the associated stress. One promis-
ing model of these interactions involves strings with mass per unit length
μ = g2
sc2/(8πG) ∼1Megaton/fermi (where Megaton is not the TNT equiv-
alent!), and cross section of order the Planck length squared, LP
2 =
ℏG/c3 ∼10−70 m2, and tension (negative pressure) Tzz ∼μc2/LP
2 ∼
10110 Pa. Here ℏ, G, and c are Planck’s reduced constant, Newton’s gravi-
tation constant, and the speed of light, and g2
s ∼0.025 is the string coupling
constant.
11.3 Stress, Elastic Moduli, and Elastostatic Equilibrium
579

6. The highest possible stress is presumably associated with spacetime singu-
larities, for example at the birth of the universe or inside a black hole. Here
the characteristic energy is the Planck energy EP = (ℏc5/G)1/2 ∼1019 GeV,
the lengthscale is the Planck length LP = (ℏG/c3)1/2 ∼10−35 m, and the
associated ultimate stress is ∼EP/L3
P ∼10114 Pa.
11.3.2
11.3.2 Realm of Validity for Hooke’s Law
In elasticity theory, motivated by Hooke’s Law (Fig. 11.1), we assume a linear rela-
tionship between a material’s stress and strain tensors. Before doing so, however, we
discuss the realm in which this linearity is true and some ways in which it can fail.
For this purpose, consider again the stretching of a rod by an applied force
(Fig. 11.1a, shown again in Fig. 11.4a). For a sufﬁciently small stress Tzz = F/A
(with A the cross sectional area of the rod), the strain Szz = ℓ/ℓfollows Hooke’s
law (straight red line in Fig. 11.4b). However, at some point, called the proportionality
proportionality limit
limit (ﬁrst big dot in Fig. 11.4b), the strain begins to depart from Hooke’s law. De-
spite this deviation, if the stress is removed, the rod returns to its original length.
At a somewhat larger stress, called the elastic limit, that ceases to be true; the rod
elastic limit
is permanently stretched. At a still larger stress, called the yield limit or yield point,
yield point
little or no increase in stress causes a large increase in strain, usually because the
material begins to ﬂow plasticly. At an even larger stress, the rupture point, the rod
rupture point
cracks or breaks. For a ductile substance like polycrystalline copper, the proportional-
ity limit and elastic limit both occur at about the same rather low strain ℓ/ℓ∼10−4,
but yield and rupture do not occur until ℓ/ℓ∼10−3. For a more resilient mate-
rial like cemented tungsten carbide, strains can be proportional and elastic up to
∼3 × 10−3. Rubber is non-Hookean (stress is not proportional to strain) at essen-
tially all strains; its proportionality limit is exceedingly small, but it returns to its
original shape from essentially all nonrupturing deformations, which can be as large
as ℓ/ℓ∼8 (the yield and rupture points).4 Especially signiﬁcant is that in almost all
solids except rubber, the proportionality, elastic, and yield limits are all small com-
pared to unity.
11.3.3
11.3.3 Elastic Moduli and Elastostatic Stress Tensor
In realms where Hooke’s law is valid, there is a corresponding linear relationship
between the material’s stress tensor and its strain tensor. The most general linear
equation relating two second-rank tensors involves a fourth-rank tensor known as
the elastic modulus tensor Y. In slot-naming index notation,
elastic modulus tensor
Tij = −YijklSkl.
(11.17)
4.
Rubber is made of long, polymeric molecules, and its elasticity arises from uncoiling of the molecules
when a force is applied, which is a different mechanism than is found in crystalline materials (Xing,
Goldbart, and Radzihovsky, 2007).
580
Chapter 11. Elastostatics

(b)
rupture point
yield limit
elastic limit
proportionality limit
Hooke’s law
(a)
F
Szz = ℓ/ℓ
ℓ + ℓ
Tzz = F/A
FIGURE11.4 Thestress-strainrelationforarod, showingspecialpoints
at which the behavior of the rod’s material changes.
Now, a general fourth-rank tensor in 3 dimensions has 34 = 81independent com-
ponents. Elasticity can get complicated! However, the situation need not be so dire.
There are several symmetries that we can exploit. Let us look ﬁrst at the general case.
As the stress and strain tensors are both symmetric, Y is symmetric in its ﬁrst pair of
slots, and we are free to choose it symmetric in its second pair: Yijkl = Yjikl = Yijlk.
There are therefore 6 independent components Yijkl for variable i, j and ﬁxed k, l,
and vice versa. In addition, as we will show, Y is symmetric under an interchange of its
ﬁrst and second pairs of slots: Yijkl = Yklij. There are therefore (6 × 7)/2 = 21 inde-
pendent components in Y. This is an improvement over 81. Many substances, notably
crystals, exhibit additional symmetries, which can reduce the number of independent
components considerably.
The simplest, and in fact most common, case arises when the medium is isotropic.
In other words, there are no preferred directions in the material. This occurs when
the solid is polycrystalline or amorphous and completely disordered on a scale large
compared with the atomic spacing, but small compared with the solid’s inhomo-
geneity scale.
If a medium is isotropic, then its elastic properties must be describable by scalars
that relate the irreducible parts P and Tshear of the stress tensor T to those,  and Σ, of
the strain tensor S. The only mathematically possible, linear, coordinate-independent
relationship between {P , Tshear} and {, Σ} involving solely scalars is P = −K,
Tshear = −2μΣ, corresponding to a total stress tensor
bulk modulus, shear
modulus, and stress
tensor for isotropic elastic
medium
T = −Kg −2μΣ.
(11.18)
Here K is called the bulk modulus and μ the shear modulus, and the factor 2 is
included for purely historical reasons. The ﬁrst minus sign (with K > 0) ensures that
the isotropic part of the stress, −Kg, resists volume changes; the second minus sign
(with μ > 0) ensures that the symmetric, trace-free part, −2μΣ, resists shape changes
(resists shearing).
11.3 Stress, Elastic Moduli, and Elastostatic Equilibrium
581

Hooke’slaw(Figs.11.1and11.4)canbeexpressedinthissamestress-proportional-
to-strain form. The stress, when the rod is stretched, is the force F that does the
stretching divided by the rod’s cross sectional area A, the strain is the rod’s fractional
change of length ℓ/ℓ, and so Hooke’s law takes the form
F/A = −Eℓ/ℓ,
(11.19)
with E an elastic coefﬁcient called Young’s modulus. In Sec. 11.4, we show that E is a
combination of the bulk and shear moduli: E = 9μK/(3K + μ).
Lam´e coefﬁcients
In many treatments and applications of elasticity, the shear tensor Σ is paid little
attention. The focus instead is on the strain Sij and its trace Skk = , and the elastic
stress tensor (11.18) is written as T = −λg −2μS, where λ ≡K −2
3μ. In these
treatments μ and λ are called the ﬁrst and second Lam´e coefﬁcients and are used in
place of μ and K. We shall not adopt this viewpoint.
11.3.4
11.3.4 Energy of Deformation
Take a wire of length ℓand cross sectional area A, and stretch it (e.g., via the “Hooke’s-
law experiment” of Figs. 11.1 and 11.4) by an amount ζ ′ that grows gradually from
0 to ℓ. When the stretch is ζ ′, the force that does the stretching is [by Eq. (11.19)]
F ′ = EA(ζ ′/ℓ) = (EV/ℓ2)ζ ′; here V = Aℓis the wire’s volume, and E is its Young’s
modulus. As the wire is gradually lengthened, the stretching force F ′ does work
W =
 ℓ
0
F ′dζ ′ =
 ℓ
0
(EV/ℓ2)ζ ′dζ ′
= 1
2EV (ℓ/ℓ)2.
This tells us that the stored elastic energy per unit volume is
U = 1
2E(ℓ/ℓ)2.
(11.20)
To generalize this formula to a strained, isotropic, 3-dimensional medium, con-
sider an arbitrary but small region V inside a body that has already been strained
by a displacement vector ﬁeld ξi and is thus already experiencing an elastic stress
Tij = −Kδij −2μΣij [Eq. (11.18)]. Imagine building up this displacement grad-
ually from zero at the same rate everywhere in and around V, so at some moment
during the buildup the displacement ﬁeld is ξ′
i = ξiϵ (with the parameter ϵ gradually
growing from 0 to 1). At that moment, the stress tensor (by virtue of the linearity of the
stress-strain relation) is T ′
ij = Tijϵ. On the boundary ∂V of the region V, this stress
exerts a force F ′
i = −T ′
ijj across any surface element j, from the exterior
of ∂V to its interior. As the displacement grows, this surface force does the following
amount of work on V:
Wsurf =

F ′
idξ′
i =

(−T ′
ijj)dξ′
i = −
 1
0
Tijϵjξ′
idϵ = −1
2Tijjξi.
(11.21)
582
Chapter 11. Elastostatics

The total amount of work done can be computed by adding up the contributions from
all the surface elements of ∂V:
Wsurf = −1
2

∂V
Tijξidj = −1
2

V
(Tijξi);jdV = −1
2(Tijξi);j V .
(11.22)
In the second step we have used Gauss’s theorem, and in the third step we have used
the smallness of the region V to infer that the integrand is very nearly constant and
the integral is the integrand times the total volume V of V.
Does Wsurf equal the elastic energy stored in V? The answer is “no,” because
we must also take account of the work done in the interior of V by gravity or any
other nonelastic force that may be acting. Although it is not easy in practice to turn
gravity off and then on, we must do so in the following thought experiment. In the
volume’s ﬁnal deformed state, the divergence of its elastic stress tensor is equal to the
gravitational force density, ∇. T = ρg [Eqs. (11.13) and (11.14)]; and in the initial,
undeformed and unstressed state, ∇. T must be zero, whence so must g. Therefore, we
must imagine growing the gravitational force proportional to ϵ just like we grow the
displacement, strain, and stress. During this growth, with g′ = ϵg, the gravitational
force ρg′V does the following amount of work on our tiny region V:
Wgrav =

ρV g′ . dξ′ =
 1
0
ρV gϵ . ξdϵ = 1
2ρV g . ξ = 1
2(∇. T) . ξV = 1
2Tij;jξi V .
(11.23)
The total work done to deform V is the sum of the work done by the elastic
force (11.22) on its surface and the gravitational force (11.23) in its interior, Wsurf +
Wgrav = −1
2(ξiTij);jV + 1
2Tij;jξiV = −1
2Tijξi;jV . This work gets stored in V as
elastic energy, so the energy density is U = −1
2Tijξi;j. Inserting (for an isotropic
material) Tij = −Kgij −2μΣij and ξi;j = 1
3gij + Σij + Rij in this equation for
U and performing some simple algebra that relies on the symmetry properties of the
expansion, shear, and rotation (Ex. 11.3), we obtain
elastic energy density at
ﬁxed temperature
U = 1
2K2 + μΣijΣij.
(11.24)
Note that this elastic energy density is always positive if the elastic moduli are positive,
as they must be for matter to be stable against small perturbations, and note that it is
independent of the rotation Rij, as it should be on physical grounds.
For the more general, anisotropic case, expression (11.24) becomes [by virtue of
the stress-strain relation Tij = −Yijklξk;l, Eq. (11.17)]
U = 1
2ξi;jYijklξk;l.
(11.25)
ThevolumeintegraloftheelasticenergydensitygivenbyEq.(11.24)or(11.25)can
be used as an action from which to compute the stress, by varying the displacement
(Ex. 11.4). Since only the part of Y that is symmetric under interchange of the ﬁrst
11.3 Stress, Elastic Moduli, and Elastostatic Equilibrium
583

and second pairs of slots contributes to U, only that part can affect the action-
principle-derived stress. Therefore, it must be that Yijkl = Yklij. This is the symmetry
we asserted earlier.
EXERCISES
Exercise 11.3 Derivation and Practice: Elastic Energy
Beginning with U = −1
2Tijξi;j [text following Eq. (11.23)], derive Eq. (11.24) for the
elastic energy density inside a body.
Exercise 11.4 Derivation and Practice: Action Principle for Elastic Stress
For an anisotropic, elastic medium with elastic energy density U = 1
2ξi;jYijklξk;l,
integrate this energy density over a 3-dimensional region V (not necessarily small) to
get the total elastic energy E. Now consider a small variation δξi in the displacement
ﬁeld. Evaluate the resulting change δE in the elastic energy without using the relation
Tij = −Yijklξk;l. Convert to a surface integral over ∂V, and thence infer the stress-
strain relation Tij = −Yijklξk;l.
11.3.5
11.3.5 Thermoelasticity
coefﬁcient of linear
thermal expansion
In our discussion of deformation energy, we tacitly assumed that the temperature
of the elastic medium was held ﬁxed during the deformation (i.e., we ignored the
possibility of any thermal expansion). Correspondingly, the energy density U that
we computed is actually the physical free energy per unit volume F, at some chosen
temperature T0 of a heat bath. If we increase the bath’s and material’s temperature
from T0 to T = T0 + δT , then the material wants to expand by  = δV/V = 3αδT
(i.e., it will have vanishing expansional elastic energy if  has this value). Here α is
its coefﬁcient of linear thermal expansion. (The factor 3 is because there are three
directions into which it can expand: x, y, and z.) Correspondingly, the physical-free-
energy density at temperature T = T0 + δT is
elastic physical free energy
F = F0(T ) + 1
2K( −3αδT )2 + μΣijΣij.
(11.26)
The stress tensor in this heated and strained state can be computed from Tij =
−∂F/∂Sij [a formula most easily inferred from Eq. (11.25) with U reinterpreted as
F and ξi;j replaced by its symmetrization, Sij]. Reexpressing Eq. (11.26) in terms of
Sij and computing the derivative, we obtain (not surprisingly!)
Tij = −∂F
∂Sij
= −K( −3αδT )δij −2μΣij.
(11.27)
What happens if we allow our material to expand adiabatically rather than at ﬁxed
temperature? Adiabatic expansion means expansion at ﬁxed entropy S. Consider a
small sample of material that contains mass M and has volume V = M/ρ. Its entropy
584
Chapter 11. Elastostatics

is S = −[∂(FV )/∂T ]V [cf. Eq. (5.33)], which, using Eq. (11.26), becomes
S = S0(T ) + 3αK V .
(11.28)
Here we have neglected the term −9α2KδT , which can be shown to be negligible
compared to the temperature dependence of the elasticity-independent term S0(T ).
If our sample expands adiabatically by an amount V = V , then its temperature
must go down by the amount T < 0 that keeps S ﬁxed (i.e., that makes S0 =
−3αKV ). Noting that T S0 is the change of the sample’s thermal energy, which
is ρcV T (cV is the speciﬁc heat per unit mass), we see that the temperature change is
temperature change in
adiabatic expansion
T
T
= −3αK
ρcV
for adiabatic expansion.
(11.29)
This temperature change, accompanying an adiabatic expansion, alters slightly the
elastic stress [Eq. (11.27)] and thence the bulk modulus K (i.e., it gives rise to an
adiabatic bulk modulus that differs slightly from the isothermal bulk modulus K
introduced in previous sections). However, the differences are so small that they are
generally ignored. For further details, see Landau and Lifshitz (1986, Sec. 6).
11.3.6
11.3.6 Molecular Origin of Elastic Stress; Estimate of Moduli
It is important to understand the microscopic origin of the elastic stress. Consider an
ionic solid in which singly ionized ions (e.g., positively charged sodium and negatively
charged chlorine) attract their nearest (opposite-species) neighbors through their
mutual Coulomb attraction and repel their next nearest (same-species) neighbors,
and so on. Overall, there is a net electrostatic attraction on each ion, which is balanced
by the short-range repulsion of its bound electrons against its neighbors’ bound
electrons. Now consider a thin slice of material of thickness intermediate between
the inter-atomic spacing and the solid’s inhomogeneity scale (Fig. 11.5).
Although the electrostatic force between individual pairs of ions is long range, the
material is electrically neutral on the scale of several ions; as a result, when averaged
FIGURE 11.5 A thin slice of an ionic solid (between the dark lines) that
interacts electromagnetically with ions outside it. The electrostatic
force on the slice is dominated by interactions between ions lying
in the two thin shaded areas, a few atomic layers thick, one on each
side of the slice. The force is effectively a surface force rather than a
volume force. In elastostatic equilibrium, the forces on the two sides
are equal and opposite, if the slice is sufﬁciently thin.
11.3 Stress, Elastic Moduli, and Elastostatic Equilibrium
585

TABLE 11.1: Density ρ; bulk, shear, and Young’s moduli K, μ, and E, respectively; Poisson’s
ratio ν; and yield strain SY under tension, for various materials
ρ
K
μ
E
cL
cT
Substance
(kg m−3)
(GPa)
(GPa)
(GPa)
ν
SY
(km s−1)
(km s−1)
Carbon nanotube 1,300
∼1,000
0.05
Steel
7,800
170
81
210
0.29
0.003
5.9
3.2
Copper
8,960
130
45
120
0.34
0.0006
4.6
2.2
Rock
3,000
70
40
100
0.25 0.001
6.0
3.5
Glass
2,500
47
28
70
0.25
0.0005
5.8
3.3
Rubber
1,200
10
0.0007
0.002
0.50
∼8
1.0
0.03
DNA molecule
0.3
∼0.1
Notes: The ﬁnal two columns are the longitudinal and transverse sound speeds cL, cT , deﬁned in Chap. 12.
The DNA molecule is discussed in Ex. 11.12.
over many ions, the net electric force is short range (Fig. 11.5). We can therefore treat
the net force acting on the thin slice as a surface force, governed by local conditions
in the material. This is essential if we are to be able to write down a localized linear
stress-strain relation Tij = −YijklSkl or Tij = −Kδij −2μΣij. This need not have
been the case; there are other circumstances where the net electrostatic force is long
range, not short. One example occurs in certain types of crystal (e.g., tourmaline),
which develop internal, long-range piezoelectric ﬁelds when strained.
Our treatment so far has implicitly assumed that matter is continuous on all scales
and that derivatives are mathematically well deﬁned. Of course, this is not the case. In
fact, we not only need to acknowledge the existence of atoms, we must also use them
to compute the elastic moduli.
magnitudes of elastic
moduli
We can estimate the elastic moduli in ionic or metallic materials by observing
that, if a crystal lattice were to be given a dimensionless strain of order unity, then the
elastic stress would be of order the electrostatic force between adjacent ions divided
by the area associated with each ion. If the lattice spacing is a ∼2 ˚A = 0.2 nm and
the ions are singly charged, then K and μ ∼e2/4πϵ0a4 ∼100 GPa. This is about a
million atmospheres. Covalently bonded compounds are less tightly bound and have
somewhat smaller elastic moduli; exotic carbon nanotubes have larger moduli. See
Table 11.1.
On the basis of this argument, it might be thought that crystals can be subjected
to strains of order unity before they attain their elastic limits. However, as discussed
in Sec. 11.3.2, most materials are only elastic for strains <∼10−3. The reason for this
difference is that crystals are generally imperfect and are laced with dislocations.
Relatively small stresses sufﬁce for the dislocations to move through the solid and
for the crystal thereby to undergo permanent deformation (Fig. 11.6).
586
Chapter 11. Elastostatics

(a)
(b)
FIGURE 11.6 The ions in one layer of a crystal. In subsequent layers, going into
each picture, the ion distribution is the same. (a) This perfect crystal, in which
the atoms are organized in a perfectly repeating lattice, can develop very large
shear strains without yielding. (b) Real materials contain dislocations that greatly
reduce their rigidity. The simplest type of dislocation, shown here, is the edge
dislocation (with the central vertical atomic layer having a terminating edge that
extends into the picture). The dislocation will move transversely, and the crystal
thereby will undergo inelastic deformation when the strain is typically greater
than ∼10−3, which is ∼1% of the yield shear strain for a perfect crystal.
EXERCISES
Exercise 11.5 Problem: Order-of-Magnitude Estimates
(a) What is the maximum size of a nonspherical asteroid? [Hint: If the asteroid is too
large, its gravity will deform it into a spherical shape.]
(b) What length of steel wire can hang vertically without breaking? What length of
carbonnanotube?WhataretheprospectsforcreatingatetherthathangstoEarth’s
surface from a geostationary satellite?
(c) Canaheliumballoonliftthetankusedtotransportitsheliumgas?(Purcell, 1983).
Exercise 11.6 Problem: Jumping Heights
Explain why all animals, from ﬂeas to humans to elephants, can jump to roughly the
same height. The ﬁeld of science that deals with topics like this is called allometry
(Ex. 11.18).
11.3.7
11.3.7 Elastostatic Equilibrium: Navier-Cauchy Equation
elastic force density
It is commonly the case that the elastic moduli K and μ are constant (i.e., independent
of location in the medium), even though the medium is stressed in an inhomogeneous
way. (This is because the strains are small and thus perturb the material properties
by only small amounts.) If so, then from the elastic stress tensor T = −Kg −2μ
and expressions (11.4a) and (11.4b) for the expansion and shear in terms of the
displacement vector, we can deduce the following expression for the elastic force
density f [Eq. (11.13)] inside the body:
f = −∇. T = K∇ + 2μ∇. Σ =

K + 1
3μ

∇(∇. ξ) + μ∇2ξ;
(11.30)
11.3 Stress, Elastic Moduli, and Elastostatic Equilibrium
587

boundary
pill box
n
FIGURE 11.7 Pill box used to derive boundary conditions in electrostatics and elastostatics.
see Ex. 11.7. Here ∇. Σ in index notation is Σij;j = Σji;j. Extra terms must be added
if we are dealing with anisotropic materials. However, in this book Eq. (11.30) will be
sufﬁcient for our needs.
If no other countervailing forces act in the interior of the material (e.g., if there is
no gravitational force), and if, as in this chapter, the material is in a static, equilibrium
state rather than vibrating dynamically, then this force density will have to vanish
throughout the material’s interior. This vanishing of f ≡−∇. T is just a fancy version
of Newton’s law for static situations, F = ma = 0. If the material has density ρ and is
pulled on by a gravitational acceleration g, then the sum of the elastostatic force per
unit volume and gravitational force per unit volume must vanish, f + ρg = 0:
Navier-Cauchy equation
for elastostatic equilibrium
f + ρg =

K + 1
3μ

∇(∇. ξ) + μ∇2ξ + ρg = 0.
(11.31)
This is often called the Navier-Cauchy equation.5
When external forces are applied to the surface of an elastic body (e.g., when one
pushes on the face of a cylinder) and gravity acts on the interior, the distribution of the
strain ξ(x) inside the body can be computed by solving the Navier-Cauchy equation
(11.31) subject to boundary conditions provided by the applied forces.
In electrostatics, one can derive boundary conditions by integrating Maxwell’s
equations over the interior of a thin box (a “pill box”) with parallel faces that snuggle
up to the boundary (Fig. 11.7). For example, by integrating ∇. E = ρe/ϵo over the
interior of the pill box and then applying Gauss’s law to convert the left-hand side to a
surface integral, we obtain the junction condition that the discontinuity in the normal
component of the electric ﬁeld is equal 1/ϵo times the surface charge density. Similarly,
in elastostatics one can derive boundary conditions by integrating the elastostatic
equation ∇. T = 0 over the pill box of Fig. 11.7 and then applying Gauss’s law:
0 =

V
∇. T dV =

∂V
T . d =

∂V
T . n dA = [(T . n)upper face −(T . n)lower face]A.
(11.32)
Here in the next-to-last expression we have used d = n dA, where dA is the scalar
area element, and n is the unit normal to the pill-box face. In the last term we have
5.
It was ﬁrst written down by Claude-Louis Navier (in 1821) and in a more general form by Augustin-Louis
Cauchy (in 1822).
588
Chapter 11. Elastostatics

assumed the pill box has a small face, so T . n can be treated as constant and be pulled
outside the integral. The result is the boundary condition that
boundary conditions for
Navier-Cauchy equation
T . n
must be continuous across any boundary;
(11.33)
in index notation, Tijnj is continuous.
Physically, this is nothing but the law of force balance across the boundary: the
force per unit area acting from the lower side to the upper side must be equal and
opposite to that acting from upper to lower. As an example, if the upper face is
bounded by vacuum, then the solid’s stress tensor must satisfy Tijnj = 0at the surface.
If a normal pressure P is applied by some external agent at the upper face, then the
solid must respond with a normal force equal to P : niTijnj = P . If a vectorial force
per unit area Fi is applied at the upper face by some external agent, then it must be
balanced: Tijnj = −Fi.
Solving the Navier-Cauchy equation (11.32) for the displacement ﬁeld ξ(x), sub-
jecttospeciﬁedboundaryconditions, isaprobleminelastostaticsanalogoustosolving
Maxwell’s equations for an electric ﬁeld subject to boundary conditions in electro-
statics, or for a magnetic ﬁeld subject to boundary conditions in magnetostatics. The
types of solution techniques used in electrostatics and magnetostatics can also be used
here. See Box 11.3.
EXERCISES
Exercise 11.7 Derivation and Practice: Elastic Force Density
From Eq. (11.18) derive expression (11.30) for the elastostatic force density inside an
elastic body.
Exercise 11.8 **Practice: Biharmonic Equation
A homogeneous, isotropic, elastic solid is in equilibrium under (uniform) gravity and
applied surface stresses. Use Eq. (11.30) to show that the displacement inside it, ξ(x),
is biharmonic, i.e., it satisﬁes the differential equation
∇2∇2ξ = 0.
(11.34a)
Show also that the expansion  satisﬁes the Laplace equation
∇2 = 0.
(11.34b)
11.4
11.4 Young’s Modulus and Poisson’s Ratio for an Isotropic Material:
A Simple Elastostatics Problem
As a simple example of an elastostatics problem, we explore the connection between
our 3-dimensional theory of stress and strain and the 1-dimensional Hooke’s law
(Fig. 11.1).
11.4 Young’s Modulus and Poisson’s Ratio
589

BOX 11.3.
METHODS OF SOLVING THE NAVIER-CAUCHY EQUATION
Many techniques have been devised to solve the Navier-Cauchy equation
(11.31), or other equations equivalent to it, subject to appropriate boundary
conditions. Among them are:
.
Separation of variables. See Sec. 11.9.2.
.
Green’s functions. See Ex. 11.27 and Johnson (1985).
.
Variational principles. See Marsden and Hughes (1986, Chap. 5) and
Slaughter (2002, Chap. 10).
.
Saint-Venant’s principle. One changes the boundary conditions
to something simpler, for which the Navier-Cauchy equation can
be solved analytically, and then one uses linearity of the Navier-
Cauchy equation to compute an approximate, additive correction
that accounts for the difference in boundary conditions.1
.
Dimensional reduction. This method reduces the theory to
2 dimensions in the case of thin plates (Sec. 11.7), and to 1 dimension
for rods and for translation-invariant plates (Sec. 11.5).
.
Complex variable methods. These are particularly useful in
solving the 2-dimensional equations (Boresi and Chong, 1999,
Appendix 5B).
.
Numerical simulations on computers. These are usually carried
out by the method of ﬁnite elements, in which one approximates
stressed objects by a ﬁnite set of elementary, interconnected physical
elements, such as rods; thin, triangular plates; and tetrahedra (Ugural
and Fenster, 2012, Chap. 7).
.
Replace Navier-Cauchy by equivalent equations. For example, and
widely used in the engineering literature, write force balance Tij;j = 0
in terms of the strain tensor Sij, supplement this with an equation
that guarantees Sij can be written as the symmetrized gradient of
a vector ﬁeld (the displacement vector), and develop techniques
to solve these coupled equations plus boundary conditions for Sij
[Ugural and Fenster (2012, Sec. 2.4); also large parts of Boresi and
Chong (1999) and Slaughter (2002)].
.
Mathematica or other computer software. These software packages
can be used to perform complicated analytical analyses. One can
then explore their predictions numerically (Constantinescu and
Korsunsky, 2007).
1. In 1855 Barr´e de Saint-Venant had the insight to realize that, under suitable
conditions, the correction will be signiﬁcant only locally (near the altered boundary)
and not globally. (See Boresi and Chong, 1999, pp. 288ff; Ugural and Fenster, 2012,
Sec. 2.16, and references therein.)
590
Chapter 11. Elastostatics

Consider a thin rod of square cross section hanging along the ez direction of a
Cartesian coordinate system (Fig. 11.1). Subject the rod to a stretching force applied
normallyanduniformlyatitsends.(Itcouldjustaseasilybearodundercompression.)
Its sides are free to expand or contract transversely, since no force acts on them:
dFi = Tijdj = 0. As the rod is slender, vanishing of dFi at its x and y sides implies
to high accuracy that the stress components Tix and Tiy will vanish throughout the
interior; otherwise there would be a very large force density Tij;j inside the rod. Using
Tij = −Kgij −2μΣij, we then obtain
Txx = −K −2μΣxx = 0,
(11.35a)
Tyy = −K −2μΣyy = 0,
(11.35b)
Tyz = −2μΣyz = 0,
(11.35c)
Txz = −2μΣxz = 0,
(11.35d)
Txy = −2μΣxy = 0,
(11.35e)
Tzz = −K −2μΣzz.
(11.35f)
From the ﬁrst two of these equations and Σxx + Σyy + Σzz = 0, we obtain a relation-
ship between the expansion and the nonzero components of the shear,
K = μΣzz = −2μΣxx = −2μΣyy;
(11.36)
and from this and Eq. (11.35f), we obtain Tzz = −3K. The decomposition of Sij
into its irreducible tensorial parts tells us that Szz = ξz;z = Σzz + 1
3, which becomes,
on using Eq. (11.36), ξz;z = [(3K + μ)/(3μ)]. Combining with Tzz = −3K, we
obtain Hooke’s law and an expression for Young’s modulus E in terms of the bulk and
shear moduli:
Hooke’s law and Young’s
modulus
−Tzz
ξz;z
=
9μK
3K + μ = E.
(11.37)
It is conventional to introduce Poisson’s ratio ν, which is minus the ratio of the
lateral strain to the longitudinal strain during a deformation of this type, where the
transverse motion is unconstrained. It can be expressed as a ratio of elastic moduli as
follows:
Poisson’s ratio
ν ≡−ξx;x
ξz;z
= −
ξy;y
ξz;z
= −
Σxx + 1
3
Σzz + 1
3
= 3K −2μ
2(3K + μ) ,
(11.38)
where we have used Eq. (11.36). We tabulate these relations and their inverses for
future use:
E =
9μK
3K + μ ,
ν = 3K −2μ
2(3K + μ);
K =
E
3(1 −2ν) ,
μ =
E
2(1 + ν).
(11.39)
11.4 Young’s Modulus and Poisson’s Ratio
591

We have already remarked that mechanical stability of a solid requires that K, μ >
0. Using Eq. (11.39), we observe that this imposes a restriction on Poisson’s ratio,
namely that −1 < ν < 1/2. For metals, Poisson’s ratio is typically about 1/3, and the
shear modulus is roughly half the bulk modulus. For a substance that is easily sheared
but not easily compressed, like rubber (or neutron star crusts; Sec. 11.3.6), the bulk
modulus is relatively high and ν ≃1/2 (cf. Table 11.1). For some exotic materials,
Poisson’s ratio can be negative (cf. Yeganeh-Haeri, Weidner, and Parise, 1992).
Although we derived them for a square strut under extension, our expressions for
Young’s modulus and Poisson’s ratio are quite general. To see this, observe that the
derivation would be unaffected if we combined many parallel, square ﬁbers together.
All that is necessary is that the transverse motion be free, so that the only applied force
is uniform and normal to a pair of parallel faces.
11.5
11.5 Reducing the Elastostatic Equations to 1 Dimension for a Bent Beam:
Cantilever Bridge, Foucault Pendulum, DNA Molecule, Elastica
When dealing with bodies that are much thinner in 2 dimensions than the third
(e.g., rods, wires, and beams), one can use the method of moments to reduce the 3-
dimensionalelastostaticequationstoordinarydifferentialequationsin1dimension(a
process called dimensional reduction). We have already met an almost trivial example
dimensional reduction
of this in our discussion of Hooke’s law and Young’s modulus (Sec. 11.4 and Fig.
11.1). In this section, we discuss a more complicated example, the bending of a beam
through a small displacement angle. In Ex. 11.13, we shall analyze a more complicated
example: the bending of a long, elastic wire into a complicated shape called an elastica.
Our beam-bending example is motivated by a common method of bridge con-
struction, which uses cantilevers. (A famous historical example is the old bridge over
the Firth of Forth in Scotland that was completed in 1890 with a main span of half a
kilometer.)
The principle is to attach two independent beams to the two shores as cantilevers,
and allow them to meet in the middle. (In practice the beams are usually supported
at the shores on piers and strengthened along their lengths with trusses.) Similar
cantilevers, with lengths of order a micron or less, are used in atomic force micro-
scopes and other nanotechnology applications, including quantum-information ex-
periments.
Let us make a simple model of a cantilever (Fig. 11.8). Consider a beam clamped
rigidly at one end, with length ℓ, horizontal width w, and vertical thickness h. In-
troduce local Cartesian coordinates with ex pointing along the beam and ez pointing
vertically upward. Imagine the beam extending horizontally in the absence of gravity.
Now let it sag under its own weight, so that each element is displaced through a small
distance ξ(x). The upper part of the beam is stretched, while the lower part is com-
pressed, so there must be a neutral surface where the horizontal strain ξx,x vanishes.
neutral surface
592
Chapter 11. Elastostatics

neu
tral
 sur
face
dx
S
S
h
x
(a)
(b)
(c)
(d)
h
z
w
y
z
S
S + dS
Wdx
–M
M + dM
dx
θ
η
ℓ
FIGURE 11.8 Bending of a cantilever. (a) A beam is held rigidly at one end and extends horizontally
with the other end free. We introduce an orthonormal coordinate system(x, y, z) with ex extending
along the beam. We only consider small departures from equilibrium. The bottom of the beam will
be compressed, the upper portion extended. There is therefore a neutral surface z = 0 on which
the strain ξx,x vanishes. (b) The beam has a rectangular cross section with horizontal width w
and vertical thickness h; its length is ℓ. (c) The bending torque M must be balanced by the torque
exerted by the vertical shear force S. (d) The shear force S must vary along the beam so as to
support the beam’s weight per unit length, W.
This neutral surface must itself be curved downward. Let its downward displacement
from the horizontal plane that it occupied before sagging be η(x) (> 0), let a plane
tangent to the neutral surface make an angle θ(x) (also > 0) with the horizontal, and
adjust the x and z coordinates so x runs along the slightly curved neutral plane and
z is orthogonal to it (Fig. 11.8). The longitudinal strain is then given to ﬁrst order in
small quantities by
longitudinal strain
ξx,x = z
R = zdθ
dx ≃zd2η
dx2 ,
(11.40a)
where R = dx/dθ > 0 is the radius of curvature of the beam’s bend, and we have
chosen z = 0 at the neutral surface. The 1-dimensional displacement η(x) will be the
focus for dimensional reduction of the elastostatic equations.
As in our discussion of Hooke’s law for a stretched rod (Sec. 11.4), we can regard
the beam as composed of a bundle of long, parallel ﬁbers, stretched or squeezed along
their length and free to contract transversely. The longitudinal stress is therefore
Txx = −Eξx,x = −Ezd2η
dx2 .
(11.40b)
11.5 Cantilever Bridge, Foucault Pendulum, DNA Molecule, Elastica
593

We can now compute the horizontal force density, which must vanish in elasto-
static equilibrium:6
fx = −Txx,x −Txz,z = Ezd3η
dx3 −Txz,z = 0.
(11.40c)
This is a partial differential equation. We convert it into a 1-dimensional ordinary
differential equation by the method of moments: We multiply it by z and integrate
method of moments
over z (i.e., we compute its “ﬁrst moment”). Integrating the second term,

zTxz,zdz,
by parts and using the boundary condition Txz = 0 on the upper and lower surfaces
of the beam, we obtain
Eh3
12
d3η
dx3 = −
 h/2
−h/2
Txz dz.
(11.40d)
Using Txz = Tzx, notice that the integral, when multiplied by the beam’s width w in
the y direction, is the vertical shear force S(x) in the beam:
shear force, SSS
S =

Tzxdydz = w
 h/2
−h/2
Tzxdz = −D d3η
dx3.
(11.41a)
Here
ﬂexural rigidity or bending
modulus of an elastic
beam, DDD
D ≡E

z2dydz ≡EA r2
g = Ewh3/12
(11.41b)
is called the beam’sﬂexural rigidity,or its bending modulus.Notice that, quite generally,
D is the beam’s Young’s modulus E times the second moment of the beam’s cross
sectional area A along the direction of bend. Engineers call that second moment A r2
g
and call rg the radius of gyration. For our rectangular beam, this D is Ewh3/12.
As an aside, we can gain some insight into Eq. (11.41a) by examining the torques
that act on a segment of the beam with length dx. As shown in Fig. 11.8c, the shear
forces on the two ends of the segment exert a clockwise torque 2S(dx/2) = Sdx. This
is balanced by a counterclockwise torque due to the stretching of the upper half of the
segment and compression of the lower half (i.e., due to the bending of the beam). This
bending torque is
bending torque, M
M
M
M ≡

Txxzdydz = −D d2η
dx2
(11.41c)
6.
Because the coordinates are slightly curvilinear rather than precisely Cartesian, our Cartesian-based
analysis makes small errors. Track-Two readers who have studied Sec. 11.8 can evaluate those errors
using connection-coefﬁcient terms that were omitted from this equation: −xjkTjk −jkjTxk. Each 
has magnitude 1/R, so these terms are of order Tjk/R, whereas the terms kept in Eq. (11.40c) are of
order Txx/ℓand Txz/h. Since the thickness h and length ℓof the beam are small compared to the beam’s
radius of curvature R, the connection-coefﬁcient terms are negligible.
594
Chapter 11. Elastostatics

on the right end of the segment and minus this on the left, so torque balance says
(dM/dx)dx = Sdx:
S = dM/dx;
(11.42)
see Fig. 11.8c. This is precisely Eq. (11.41a).
Equation (11.41a) [or equivalently, Eq. (11.42)] embodies half of the elastostatic
equations. It is the x component of force balance fx = 0, converted to an ordinary
differential equation by evaluating its lowest nonvanishing moment: its ﬁrst moment,

zfxdydz = 0 [Eq. (11.40d)]. The other half is the z component of stress balance,
which we can write as
Tzx,x + Tzz,z + ρg = 0
(11.43)
(vertical elastic force balanced by gravitational pull on the beam). We can convert this
to a 1-dimensional ordinary differential equation by taking its lowest nonvanishing
moment, its zeroth moment (i.e., by integrating over y and z). The result is
dS
dx = −W ,
(11.44)
where W = gρwh is the beam’s weight per unit length (Fig. 11.8d).
weight per unit length, W
W
W
Combining our two dimensionally reduced components of force balance,
Eqs. (11.41a) and (11.44), we obtain a fourth-order differential equation for our
1-dimensional displacement η(x):
elastostatic force balance
equation for bent beam
d4η
dx4 = W
D .
(11.45)
(Fourth-order differential equations are characteristic of elasticity.)
Equation (11.45) can be solved subject to four appropriate boundary conditions.
However, before we solve it, notice that for a beam of a ﬁxed length ℓ, the deﬂection
η is inversely proportional to the ﬂexural rigidity. Let us give a simple example of this
scaling. Floors in U.S. homes are conventionally supported by wooden joists of 2" by
6" lumber with the 6" side vertical. Suppose an inept carpenter installed the joists with
the 6" side horizontal. The ﬂexural rigidity of the joist would be reduced by a factor
9, and the center of the ﬂoor would be expected to sag 9 times as much as if the joists
had been properly installed—a potentially catastrophic error.
Also, before solving Eq. (11.45), let us examine the approximations that we have
made. First, we have assumed that the sag is small compared with the length of the
beam, when making the small-angle approximation in Eq. (11.40a); we have also
assumed the beam’s radius of curvature is large compared to its length, when treating
11.5 Cantilever Bridge, Foucault Pendulum, DNA Molecule, Elastica
595

our slightly curved coordinates as Cartesian.7 These assumptions will usually be valid,
but are not so for the elastica studied in Ex. 11.13. Second, by using the method of
moments rather than solving for the complete local stress tensor ﬁeld, we have ignored
the effects of some components of the stress tensor. In particular, when evaluating the
bending torque [Eq. (11.41c)] we have ignored the effect of the Tzx component of the
stress tensor. This is O(h/ℓ)Txx, and so our equations can only be accurate for fairly
slender beams. Third, the extension above the neutral surface and the compression
below the neutral surface lead to changes in the cross sectional shape of the beam.
The fractional error here is of order the longitudinal shear, which is small for real
materials.
The solution to Eq. (11.45) is a fourth-order polynomial with four unknown
constants, to be set by boundary conditions. In this problem, the beam is held hor-
izontal at the ﬁxed end, so that η(0) = η′(0) = 0, where the prime denotes d/dx.
At the free end, Tzx and Txx must vanish, so the shear force S must vanish, whence
η′′′(ℓ) = 0 [Eq. (11.41a)]; the bending torque M [Eq. (11.41c)] must also vanish,
whence [by Eq. (11.42)]

Sdx ∝η′′(ℓ) = 0. By imposing these four boundary con-
ditions η(0) = η′(0) = η′′(ℓ) = η′′′(ℓ) = 0 on the solution of Eq. (11.45), we obtain
for the beam shape
displacement of a clamped
cantilever
η(x) = W
D
1
4ℓ2x2 −1
6ℓx3 + 1
24x4

.
(11.46a)
Therefore, the end of the beam sags by
η(ℓ) = Wℓ4
8D .
(11.46b)
Problemsinwhichthebeamrestsonsupportsratherthanbeingclampedcanbesolved
in a similar manner. The boundary conditions will be altered, but the differential
equation (11.45) will be unchanged.
Now suppose that we have a cantilever bridge of constant vertical thickness h and
total span 2ℓ∼100 m made of material with density ρ ∼8 × 103 kg m−3 (e.g., steel)
and Young’s modulus E ∼100 GPa. Suppose further that we want the center of the
bridge to sag by no more than η ∼1 m. According to Eq. (11.46b), the thickness of
the beam must satisfy
h >∼
3ρgℓ4
2Eη
1/2
∼2.8 m.
(11.47)
This estimate makes no allowance for all the extra strengthening and support present
in real structures (e.g., via trusses and cables), and so it is an overestimate.
7.
In more technical language, when neglecting the connection-coefﬁcient terms discussed in the previous
footnote.
596
Chapter 11. Elastostatics

EXERCISES
Exercise 11.9 Derivation: Sag in a Cantilever
(a) Verify Eqs. (11.46) for the sag in a horizontal beam clamped at one end and
allowed to hang freely at the other end.
(b) Nowconsiderasimilarbeamwithconstantcrosssectionandloadedwithweights,
so that the total weight per unit length is W(x). What is the sag of the free end,
expressed as an integral over W(x), weighted by an appropriate Green’s function?
Exercise 11.10 Example: Microcantilever
A microcantilever, fabricated from a single crystal of silicon, is being used to test
the inverse square law of gravity on micron scales (Weld et al., 2008). It is clamped
horizontally at one end, and its horizontal length is ℓ= 300 μm, its horizontal width
is w = 12 μm, and its vertical height is h = 1 μm. (The density and Young’s modulus
for silicon are ρ = 2,000 kg m−3 and E = 100 GPa, respectively.) The cantilever is
loaded at its free end with a m = 10 μg gold mass.
(a) Show that the static deﬂection of the end of the cantilever is η(ℓ) = mgℓ3/(3D) =
9 μm, where g = 10 m s−2 is the acceleration due to gravity. Explain why it is
permissible to ignore the weight of the cantilever.
(b) Next
suppose
the
mass
is
displaced
slightly
vertically
and
then
re-
leased. Show that the natural frequency of oscillation of the cantilever is
f = 1/(2π)

g/η(ℓ) ≃170 Hz.
(c) A second, similar gold mass is placed 100 μm away from the ﬁrst. Estimate
roughly the Newtonian gravitational attraction between these two masses, and
compare with the attraction of Earth. Suggest a method that exploits the natural
oscillation of the cantilever to measure the tiny gravitational attraction between
the two gold masses.
The motivation for developing this technique was to seek departures from Newton’s
inverse-square law of gravitation on ∼micron scales, which had been predicted if our
universe is a membrane (“brane”) in a higher-dimensional space (“bulk”) with at least
one macroscopic extra dimension. No such departures have been found as of 2016.
Exercise 11.11 Example: Foucault Pendulum
In any high-precision Foucault pendulum, it is important that the pendular restoring
forcebeisotropic, sinceanisotropywillmaketheswingingperioddifferentindifferent
planes and thereby cause precession of the plane of swing.
(a) Consider a pendulum of mass m and length ℓsuspended (as shown in Fig. 11.9)
by a rectangular wire with thickness h in the plane of the bend (X-Z plane)
and thickness w orthogonal to that plane (Y direction). Explain why the force
that the wire exerts on the mass is approximately −F = −(mg cos θo + mℓ˙θ2
o)ex,
where g is the acceleration of gravity, θo is deﬁned in the ﬁgure, and ˙θo is the time
derivative of θo due to the swinging of the pendulum. In the second term we have
11.5 Cantilever Bridge, Foucault Pendulum, DNA Molecule, Elastica
597

F
Z
X
x
θo
ℓ
FIGURE 11.9 Foucault pendulum.
assumed that the wire is long compared to its region of bend. Express the second
term in terms of the amplitude of swing θmax
o
, and show that for small amplitudes
θmax
o
≪1, F ≃−mgex. Use this approximation in the subsequent parts.
(b) Assuming that all along the wire, its angle θ(x) to the vertical is small, θ ≪1,
show that
θ(x) = θo

1 −e−x/λ
,
(11.48a)
where λ (not to be confused with the second Lam´e coefﬁcient) is
λ =
h
(12ϵ)1/2 ,
(11.48b)
ϵ = ξx,x is the longitudinal strain in the wire, and h is the wire’s thickness in the
plane of its bend. [Hint: The solution to Ex. 11.9 might be helpful.] Note that the
bending of the wire is concentrated near the support, so this is where dissipation
will be most important and where most of the suspension’s thermal noise will
arise (cf. Sec. 6.8 for discussion of thermal noise).
(c) HenceshowthattheshapeofthewireisgivenintermsofCartesiancoordinatesby
Z = [X −λ(1 −e−X/λ)]θo
(11.48c)
to leading order in λ, and that the pendulum period is
P = 2π
ℓ−λ
g
1/2
.
(11.48d)
(d) Finally, show that the pendulum periods when swinging along ex and ey differ by
δP
P =
h −w
ℓ
  1
48ϵ
1/2
.
(11.48e)
From Eq. (11.48e) one can determine how accurately the two thicknesses h
and w must be equal to achieve a desired degree of isotropy in the period. A
similar analysis can be carried out for the more realistic case of a slightly elliptical
wire.
598
Chapter 11. Elastostatics

Exercise 11.12 Example: DNA Molecule—Bending, Stretching,
Young’s Modulus, and Yield Point
A DNA molecule consists of two long strands wound around each other as a helix,
forming a cylinder with radius a ≃1nm. In this exercise, we explore three ways of
measuring the molecule’s Young’s modulus E. For background and further details,
see Marko and Cocco (2003) and Nelson (2008, Chap. 9).
(a) Show that if a segment of DNA with length ℓis bent into a segment of a circle
with radius R, its elastic energy is Eel = Dℓ/(2R2), where D = (π/4)a4E is the
molecule’s ﬂexural rigidity.
(b) Biophysicists deﬁne the DNA’s persistence length ℓp as that length which, when
bent through an angle of 90◦, has elastic energy Eel = kBT , where kB is Boltz-
mann’s constant and T is the temperature of the molecule’s environment. Show
that ℓp ≃D/(kBT ). Explain why, in a thermalized environment, segments much
shorter than ℓp will be more or less straight, and segments with length ∼ℓp will
be randomly bent through angles of order 90◦.
(c) Explain why a DNA molecule with total length L will usually be found in a
random coil with diameter d ≃ℓp
L/ℓp = Lℓp. Observations at room tem-
perature with L ≃17 μm reveal that d ≃1 μm. From this show that the persis-
tence length is ℓp ≃50 nm at room temperature, and thence evaluate the mol-
ecule’s ﬂexural rigidity and from it, show that the molecule’s Young’s modulus is
E ≃0.3 GPa; cf. Table 11.1.
(d) When the ends of a DNA molecule are attached to glass beads and the beads are
pulled apart with a gradually increasing force F, the molecule begins to uncoil,
just like rubber. To understand this semiquantitatively, think of the molecule as
likeachainmadeofN links, eachwithlengthℓp, whoseinterfacescanbendfreely.
If the force acts along the z direction, explain why the probability that any chosen
link will make an angle θ to the z axis is dP/d cos θ ∝exp[+Fℓp cos θ/(kBT )].
[Hint: This is analogous to the probability dP/dV ∝exp[−P V/(kBT )] for the
volume V of a system in contact with a bath that has pressure P and temperature
T [Eq. (5.49)]; see also the discussion preceding Eq. (11.56).] Infer that when
the force is F, the molecule’s length along the force’s direction is ¯L ≃L(coth α −
1/α), where α = Fℓp/(kBT ) and L = Nℓp is the length of the uncoiled molecule.
Infer, further, that for α ≪1 (i.e., F ≪kBT /ℓp ∼0.1 pN), our model predicts
¯L ≃αL/3, i.e. a linear force-length relation F = (3kBT /ℓp) ¯L/L, with a strongly
temperature dependent spring constant, 3kBT /ℓp ∝T 2. The measured value of
this spring constant, at room temperature, is about 0.13 pN (Fig. 9.5 of Nelson,
2008). From this infer a value 0.5 GPa for the molecule’s Young’s modulus. This
agrees surprisingly well with the 0.3 GPa deduced in part (c), given the crudeness
of the jointed chain model.
(e) Show that when F ≫kBT/ℓp ∼0.1pN, our crude model predicts (correctly)
that the molecule is stretched to its full length L = Nℓp. At this point, its true
11.5 Cantilever Bridge, Foucault Pendulum, DNA Molecule, Elastica
599

elasticity should take over and allow genuine stretching. That true elasticity turns
out to dominate only for forces >∼10 pN. [For details of what happens between 0.1
and 10 pN, see, e.g., Nelson (2008), Secs. 9.1–9.4.] For a force between ∼10 and
∼80 pN, the molecule is measured to obey Hooke’s law, with a Young’s modulus
E ≃0.3 GPa that agrees with the value inferred in part (c) from its random-coil
diameter. When the applied force reaches ≃65 pN, the molecule’s double helix
suddenly stretches greatly with small increases of force, changing its structure,
so this is the molecule’s yield point. Show that the strain at this yield point is
ℓ/ℓ∼0.1; cf. Table 11.1.
Exercise 11.13 **Example: Elastica
Consider a slender wire of rectangular cross section with horizontal thickness h and
vertical thickness w that is resting on a horizontal surface, so gravity is unimportant.
Let the wire be bent in the horizontal plane as a result of equal and opposite forces
F that act at its ends; Fig. 11.10. The various shapes the wire can assume are called
elastica; they were ﬁrst computed by Euler in 1744 and are discussed in Love (1927,
elastica
pp. 401–404). The differential equation that governs the wire’s shape is similar to that
for the cantilever [Eq. (11.45)], with the simpliﬁcation that the wire’s weight does
not enter the problem and the complication that the wire is long enough to deform
through large angles.
It is convenient (as in the cantilever problem, Fig. 11.8) to introduce curvi-
linear coordinates with coordinate x measuring distance along the neutral surface,
z measuring distance orthogonal to x in the plane of the bend (horizontal plane),
and y measured perpendicular to the bending plane (vertically). The unit vectors
along the x, y, and z directions are ex, ey, ez (Fig. 11.10). Let θ(x) be the angle be-
tween ex and the applied force F; θ(x) is determined, of course, by force and torque
balance.
(a) Show that force balance along the x and z directions implies
F cos θ =

Txxdydz,
F sin θ =

Tzxdydz ≡S.
(11.49a)
(b) Show that torque balance for a short segment of wire implies
S = dM
dx ,
(11.49b)
where M(x) ≡

zTxxdydz is the bending torque.
(c) Show that the stress-strain relation in the wire implies
M = −D dθ
dx ,
(11.49c)
where D = Ewh3/12 is the ﬂexural rigidity [Eq. (11.41b)].
600
Chapter 11. Elastostatics

(a)
(b)
(c)
(d)
h
w
z
x
ez
ex
F
F
θ
FIGURE 11.10 Elastica. (a) A bent wire is in elastostatic equilibrium under
the action of equal and opposite forces applied at its two ends. x measures
distance along the neutral surface; z measures distance orthogonal to the
wire in the plane of the bend. (b)–(d) Examples of the resulting shapes.
(d) From the relations in parts (a)–(c), derive the following differential equation for
the shape of the wire:
d2θ
dx2 = −F sin θ
D
.
(11.49d)
This is the same equation as describes the motion of a simple pendulum!
(e) For Track-Two readers who have studied Sec. 11.8: Go back through your analysis
andidentifyanyplacethatconnectioncoefﬁcientswouldenterintoamorecareful
computation, and explain why the connection-coefﬁcient terms are negligible.
(f) Find one nontrivial solution of the elastica equation (11.49d) either analytically
using elliptic integrals or numerically. (The general solution can be expressed in
terms of elliptic integrals.)
(g) Solve analytically or numerically for the shape adopted by the wire corresponding
to your solution in part (f), in terms of precisely Cartesian coordinates (X, Z) in
the bending (horizontal) plane. Hint: Express the curvature of the wire, 1/R =
dθ/dx, as
dθ
dx = −d2X
dZ2
'
1 +
dX
dZ
2(−3/2
.
(11.49e)
(h) Obtain a uniform piece of wire and adjust the force F to compare your answer
with experiment.
11.5 Cantilever Bridge, Foucault Pendulum, DNA Molecule, Elastica
601

11.6
11.6 Buckling and Bifurcation of Equilibria
So far, we have considered stable elastostatic equilibria and have implicitly assumed
that the only reason for failure of a material is exceeding the yield limit. However,
anyone who has built a house of cards knows that mechanical equilibria can be
unstable, with startling consequences. In this section, we explore a speciﬁc, important
example of a mechanical instability: buckling—the theory of which was developed
long ago, in 1744 by Leonard Euler.
A tragic example of buckling was the collapse of the World Trade Center’s Twin
Towers on September 11, 2001. We discuss it near the end of this section, after ﬁrst
developing the theory in the context of a much simpler and cleaner example.
11.6.1
11.6.1 Elementary Theory of Buckling and Bifurcation
buckling
Take a new playing card and squeeze it between your ﬁnger and thumb (Fig. 11.11).
When you squeeze gently, the card remains ﬂat. But when you gradually increase the
compressive force F past a critical value Fcrit, the card suddenly buckles (i.e., bends),
and the curvature of the bend then increases rather rapidly with increasing applied
force.
To understand quantitatively the sudden onset of buckling, we derive an eigen-
equation for the transverse displacement η as a function of distance x from one end of
the card. (Although the card is effectively 2-dimensional, it has translation symmetry
along its transverse dimension, so we can use the 1-dimensional equations of Sec.
11.5.) We suppose that the ends are free to pivot but not move transversely, so
η(0) = η(ℓ) = 0.
(11.50)
For small displacements, the bending torque of our dimensionally reduced
1-dimensional theory is [Eq. (11.41c)]
x
η(x)
η0
F
F
w
ℓ
FIGURE 11.11 A playing card of length ℓ,
width w, and thickness h is subjected to
a compressive force F applied at both ends.
The ends of the card are free to pivot.
602
Chapter 11. Elastostatics

M(x) = −D d2η
dx2 ,
(11.51)
where D = wh3E/12 is the ﬂexural rigidity [Eq. (11.41b)]. As the card is very light
(negligible gravity), the total torque around location x, acting on a section of the card
from x to one end, is the bending torque M(x) acting at x plus the torque −Fη(x)
associated with the applied force. This sum must vanish:
D d2η
dx2 + Fη = 0.
(11.52)
The eigensolutions of Eq. (11.52) satisfying boundary conditions (11.50) are
η = η0 sin kx,
(11.53a)
with eigenvalues
k =
F
D
1/2
= nπ
ℓ
for nonnegative integers n.
(11.53b)
Therefore, there is a critical force (ﬁrst derived by Leonhard Euler in 1744), given by
critical force for buckling
Fcrit = π2D
ℓ2
= π2wh3E
12ℓ2
.
(11.54)
When F < Fcrit, there is no solution except η = 0 (an unbent card). When F = Fcrit,
the unbent card is still a solution, and there suddenly is the additional, arched solution
(11.53) with n = 1, depicted in Fig. 11.11.
The linear approximation we have used cannot tell us the height η0 of the arch as
a function of F for F ≥Fcrit; it reports, incorrectly, that for F = Fcrit all arch heights
are allowed, and that for F > Fcrit there is no solution with n = 1. However, when
nonlinearities are taken into account (Ex. 11.14), the n = 1solution continues to exist
for F > Fcrit, and the arch height η0 is related to F by
F = Fcrit
;
1 + 1
2
πη0
2ℓ
2
+ O
'πη0
2ℓ
4(=
.
(11.55)
The sudden appearance of the arched equilibrium state as F is increased through
Fcrit is called a bifurcation of equilibria. This bifurcation also shows up in the elasto-
dynamics of the playing card, as we deduce in Sec. 12.3.5. When F < Fcrit, small
perturbations of the card’s unbent shape oscillate stably. When F = Fcrit, the unbent
card is neutrally stable, and its zero-frequency motion leads the card from its unbent
equilibrium state to its n = 1, arched equilibrium. When F > Fcrit, the straight card is
an unstable equilibrium: its n = 1perturbations grow in time, driving the card toward
the n = 1 arched equilibrium state.
A nice way of looking at this bifurcation is in terms of free energy. Consider
candidate equilibrium states labeled by the height η0 of their arch. For each value of η0,
givethecard(forconcreteness)then = 1sine-waveshapeη = η0 sin(πx/ℓ).Compute
the total elastic energy E(η0) associated with the card’s bending, and subtract off the
11.6 Buckling and Bifurcation of Equilibria
603

η0
F = 0
F = Fcrit
F = 1.1Fcrit
F = 1.2Fcrit
V
FIGURE 11.12 Representation of bifurcation by a potential energy function
V(η0). When the applied force is small (F ≤Fcrit), there is only one
stable equilibrium. As the applied force F is increased, the bottom of
the potential well ﬂattens, and eventually (for F > Fcrit) the number of
equilibria increases from one to three, of which only two are stable.
work FδX done on the card by the applied force F when the card arches from η0 = 0
to height η0. [Here δX(η0) is the arch-induced decrease in straight-line separation
between the card’s ends.] The resulting quantity, V(η0) = E −FδX, is the card’s free
energy—analogous to the physical free energy F = E −T S for a system in contact
withaheatbath(Secs.5.4.1and11.3.5), theenthalpicfreeenergywhenincontactwith
a pressure bath (Ex. 5.5h), and the Gibbs (chemical) free energy G = E −T S + P V
when in contact with a heat and pressure bath (Sec. 5.5). It is the relevant energy for
analyzing the card’s equilibrium and dynamics when the force F is continually being
applied at the two ends. In Ex. 11.15 we deduce that this free energy is
free energy of a bent card
or beam
V =
πη0
2ℓ
2
ℓ
'
(Fcrit −F) + 1
4Fcrit
πη0
2ℓ
2(
+ O
'
Fcritℓ
πη0
2ℓ
6(
,
(11.56)
which we depict in Fig. 11.12.
At small values of the compressive force F < Fcrit, the free energy has only one
minimum η0 = 0 corresponding to a single stable equilibrium, the straight card.
However, as the force is increased through Fcrit, the potential minimum ﬂattens out
and then becomes a maximum ﬂanked by two new minima (e.g., the curve F =
1.2Fcrit). The maximum for F > Fcrit is the unstable, zero-displacement (straight-
card) equilibrium, and the two minima are the stable, ﬁnite-amplitude equilibria with
positive and negative η0 given by Eq. (11.55).
This procedure of representing a continuous system with an inﬁnite number of
degrees of freedom by just one or a few coordinates and ﬁnding the equilibrium by
minimizing a free energy is quite common and powerful.
Thus far, we have discussed only two of the card’s equilibrium shapes (11.53):
the straight shape n = 0 and the single-arch shape n = 1. If the card were con-
strained, by gentle, lateral stabilizing forces, to remain straight beyond F = Fcrit,
higher order equilibria
then at F = n2Fcrit for each n = 2, 3, 4, . . . , the nth-order perturbative mode, with
604
Chapter 11. Elastostatics

η = η0 sin(nπx/ℓ), would become unstable, and a new, stable equilibrium with this
shape would bifurcate from the straight equilibrium. You can easily explore this for
n = 2 using a new playing card.
These higher-order modes are rarely of practical importance. In the case of a beam
with no lateral constraints, as F increases above Fcrit, it will buckle into its single-
arched shape. For beam dimensions commonly used in construction, a fairly modest
further increase of F will bend it enough that its yield point and then rupture point
are reached. To experience this yourself, take a thin meter stick, compress its ends
between your two hands, and see what happens.
11.6.2
11.6.2 Collapse of the World Trade Center Buildings
Now we return to the example with which we began this section. On September 11,
2001, al-Qaeda operatives hijacked two Boeing 767 passenger airplanes and crashed
them into the 110-story Twin Towers of the World Trade Center in New York City,
triggering the towers’ collapse a few hours later, with horrendous loss of life.
The weight of a tall building such as the towers is supported by vertical steel
beams, called “columns.” The longer the column is, the lower the weight it can support
without buckling, since Fcrit = π2D/ℓ2 = π2EA(rg/ℓ)2, with A the beam’s cross
sectional area, rg its radius of gyration along its bending direction, and ℓits length
[Eqs. (11.54) and (11.41b)].8 The column lengths are typically chosen such that the
critical stress for buckling, Fcrit/A = E(πrg/ℓ)2, is roughly the same as the yield
stress, Fyield ≃0.003E (cf. Table 11.1), which means that the columns’ slenderness
ratio is ℓ/rg ∼50. The columns are physically far longer than 50rg, but they are
anchored to each other laterally every ∼50rg by beams and girders in the ﬂoors,
so their effective length for buckling is ℓ∼50rg. The columns’ radii of gyration
rg are generally made large, without using more steel than needed to support the
overhead weight, by making the columns hollow, or giving them H-shaped cross
sections. In the Twin Towers, the thinnest beams had rg ∼13 cm, and they were
anchored in every ﬂoor, with ﬂoor separations ℓ≃3.8 m, so their slenderness ratio
was actually ℓ/rg ≃30.
description of failure
modes
According to a detailed investigation (NIST, 2005, especially Secs. 6.14.2 and
6.14.3), the crashing airplanes ignited ﬁres in and near ﬂoors 93–99 of the North
Tower and 78–83 of the South Tower, where the airplanes hit. The ﬁres were most
intense in the ﬂoors and around uninsulated central steel columns. The heated cen-
tral columns lost their rigidity and began to sag, and trusses then transferred some of
the weight above to the outer columns. In parallel, the heated ﬂoor structures began
8.
As noted in the discussion, after Eq. (11.41b), Ar2
g is really the second moment of the column’s cross
sectional area, along its direction of bend. If the column is supported at its ends against movement in
both transverse directions, then the relevant second moment is the transverse tensor

xixjdxdy, and
the direction of buckling (if it occurs) will be the eigendirection of this tensor that has the smallest
eigenvalue (the column’s narrowest direction).
11.6 Buckling and Bifurcation of Equilibria
605

Fl 14
Fl 14
(a)
(b)
view from west
Col
81
Col
80
Col
79
Fl 13
Fl 12
Fl 11
Fl 10
Fl 9
Fl 8
Fl 7
Fl 7
Fl 6
Fl 5
FIGURE 11.13 (a) The buckling of column 79 in building WTC7 at the World Trade Center, based on a
ﬁnite-element simulation informed by all available observational data. (b) The subsequent buckling
of the building’s core. From NIST (2008).
to sag, pulling inward on the buildings’ exterior steel columns, which bowed inward
and then buckled, initiating the buildings’ collapse. [This is a somewhat oversimpli-
ﬁed description of a complex situation; for full complexities, see the report, NIST
(2005).]
This column buckling was somewhat different from the buckling of a playing card
because of the inward pull of the sagging ﬂoors. Much more like our playing-card
buckle was the fate of an adjacent, 47-story building called WTC7. When the towers
collapsed, they injected burning debris onto and into WTC7. About 7 hours later, ﬁre-
induced thermal expansion triggered a cascade of failures in ﬂoors 13–16, which left
column 79 with little stabilizing lateral support, so its effective length ℓwas increased
far beyond 50rg. It then quickly buckled (Fig. 11.13a) in much the same manner as
our playing card, followed by column 80, then 81, and subsequently columns 77, 78,
and 76 (NIST, 2008, especially Sec. 2.4). Within seconds, the building’s entire core
was buckling (Fig. 11.13b).
11.6.3
11.6.3 Buckling with Lateral Force; Connection to Catastrophe Theory
Returning to the taller Twin Towers, we can crudely augment the inward pull of the
sagging ﬂoors into our free-energy description of buckling, by adding a term −Flatη0,
which represents the energy inserted into a bent column by a lateral force Flat when
its center has been displaced laterally through the distance η0. Then the free energy
606
Chapter 11. Elastostatics

(11.56), made dimensionless and with its terms rearranged, takes the form
ϕ ≡
V
Fcritℓ= 1
4
πη0
2ℓ
4
−1
2
2(F −Fcrit)
Fcrit
 πη0
2ℓ
2
−
 2Flat
πFcrit
 πη0
2ℓ

.
(11.57)
Notice that this equation has the canonical form ϕ = 1
4a4 −1
2za2 −xa for the poten-
tial that governs a cusp catastrophe, whose state variable is a = πη0/(2ℓ) and control
variables are z = 2(F −Fcrit)/Fcrit and x = (2/π)Flat/Fcrit; see Eq. (7.72).9 From the
interpretation in terms of
catastrophe theory
elementary mathematics of this catastrophe, as worked out in Sec. 7.5.1, we learn
that although the lateral force Flat will make the column bend, it will not induce a
bifurcation of equilibria until the control-space cusp x = ±2(z/3)3/2 is reached:
Flat
Fcrit
= ±π
2(F −Fcrit)
3Fcrit
3/2
.
(11.58)
Notice that the lateral force Flat actually delays the bifurcation to a higher vertical
force, F > Fcrit. However, this is not signiﬁcant for the physical buckling, since the
column in this case is bent from the outset, and as Flat increases, it stops carrying its
share of the building’s weight and moves smoothly toward its yield point and rupture;
Ex. 11.16.
11.6.4
11.6.4 Other Bifurcations: Venus Fly Trap, Whirling Shaft,
Triaxial Stars, and Onset of Turbulence
This bifurcation of equilibria, associated with the buckling of a column, is just one
of many bifurcations that occur in physical systems. Another is a buckling type bi-
furcation that occurs in the 2-dimensional leaves of the Venus ﬂy trap plant; the plant
uses the associated instability to snap together a pair of leaves in a small fraction of
a second, thereby capturing insects for it to devour; see Fortere et al. (2005). Yet an-
other is the onset of a lateral bend in a shaft (rod) that spins around its longitudinal
axis (see Love, 1927, Sec. 286). This is called whirling; it is an issue in drive shafts for
whirling shaft
automobiles and propellers, and a variant of it occurs in spinning DNA molecules
during replication—see Wolgemuth, Powers, and Goldstein (2000). One more exam-
ple is the development of triaxiality in self-gravitating ﬂuid masses (i.e., stars) when
their rotational kinetic energy reaches a critical value, about 1/4 of their gravitational
energy; see Chandrasekhar (1962). Bifurcations also play a major role in the onset of
turbulence in ﬂuids and in the route to chaos in other dynamical systems; we study
turbulence and chaos in Sec. 15.6.
9.
The lateral force Flat makes the bifurcation structurally stable, in the language of catastrophe theory
(discussed near the end of Sec. 7.5) and thereby makes it describable by one of the generic catastrophes.
Without Flat, the bifurcation is not structurally stable.
11.6 Buckling and Bifurcation of Equilibria
607

For further details on the mathematics of bifurcations with emphasis on elasto-
statics and elastodynamics, see, for example, Marsden and Hughes (1986, Chap. 7).
For details on buckling from an engineering viewpoint, see Ugural and Fenster (2012,
Chap. 11).
EXERCISES
Exercise 11.14 Derivation and Example: Bend as a Function of Applied Force
Derive Eq. (11.55) relating the angle θo = (dη/dx)x=0 = kηo = πηo/ℓto the applied
force F when the card has an n = 1, arched shape. [Hint: Consider the card as com-
prising many thin parallel wires and use the elastica differential equation d2θ/dx2 =
−(F/D) sin θ [Eq. (11.49d)] for the angle between the card and the applied force at
distance x from the card’s end. The sin θ becomes θ in the linear approximation used
inthetext; thenonlinearitiesembodiedinthesinegiverisetothedesiredrelation.The
following steps along the way toward a solution are mathematically the same as used
when computing the period of a pendulum as a function of its amplitude of swing.]
(a) Derive the ﬁrst integral of the elastica equation
(dθ/dx)2 = 2(F/D)(cos θ −cos θo),
(11.59)
where θo is an integration constant. Show that the boundary condition of no
bending torque (no inﬂection of the card’s shape) at the card ends implies θ = θo
at x = 0 and x = ℓ; whence θ = 0 at the card’s center, x = ℓ/2.
(b) Integrate the differential equation (11.59) to obtain
ℓ
2 =
&
D
2F
 θo
0
dθ

cos θ −cos θo
.
(11.60)
(c) Perform the change of variable sin(θ/2) = sin(θo/2) sin φ and thereby bring Eq.
(11.60) into the form
ℓ= 2
&
D
F
 π/2
0
dφ

1 −sin2(θo/2) sin2 φ
= 2
&
D
F K[sin2(θo/2)].
(11.61)
Here K(y) is the complete elliptic integral of the ﬁrst type, with the parameteri-
zation used by Mathematica (which differs from that of many books).
(d) Expand Eq. (11.61) in powers of θo/2 to obtain
F = Fcrit
4
π2K2[sin2(θo/2)]= Fcrit
'
1 + 1
2
θo/2
2
2
+ . . .
(
,
(11.62)
from which deduce our desired result, Eq. (11.55).
Exercise 11.15 Problem: Free Energy of a Bent, Compressed Beam
Derive Eq. (11.56) for the free energy V of a beam that is compressed with a force F
and has a critical compression Fcrit = π2D/ℓ2, where D is its ﬂexural rigidity. [Hint: It
608
Chapter 11. Elastostatics

must be that ∂V/∂η0 = 0 gives Eq. (11.55) for the beam’s equilibrium bend amplitude
η0 as a function of F −Fcrit. Use this to reduce the number of terms in V(η0) in Eq.
(11.56) that you need to derive.]
Exercise 11.16 Problem: Bent Beam with Lateral Force
Explore numerically the free energy (11.57) of a bent beam with a compressive force
F and lateral force Flat. Examine how the extrema (equilibrium states) evolve as F
and Flat change, and deduce the physical consequences.
Exercise 11.17 **Problem: Applications of Buckling—Mountains and Pipes
Buckling plays a role in many natural and human-caused phenomena. Explore the
following examples.
(a) Mountain building. When two continental plates are in (very slow) collision,
the compressional force near their interface drives their crustal rock to buckle
upward, producing mountains. Estimate how high such mountains can be on
Earth and on Mars, and compare your estimates with their actual heights. Read
about such mountain building in books or on the web.
(b) Thermal expansion of pipes. When a segment of pipe is heated (e.g., by the rising
sun in the morning), it will expand. If its ends are held ﬁxed, this can easily
producealongitudinalstresslargeenoughtobucklethepipe.Howwouldyoudeal
with this in an oil pipeline on Earth’s surface? In a long vacuum tube? Compare
your answers with standard engineering solutions, which you can ﬁnd in books
or on the web.
Exercise 11.18 Example: Allometry
Allometry is the study of biological scaling laws that relate various features of an
animal to its size or mass. One example concerns the ratio of the width to the length
of leg bones. Explain why the width to the length of a thigh bone in a quadruped
might scale as the square root of the stress that it has to support. Compare elephants
with cats in this regard. (The density of bone is roughly 1.5 times that of water, and
its Young’s modulus is ∼20 GPa.)
11.7
11.7 Reducing the Elastostatic Equations to 2 Dimensions
for a Deformed Thin Plate: Stress Polishing a Telescope Mirror
The world’s largest optical telescopes (as of 2016) are the Gran Telescopio Canarias in
the Canary Islands and the two Keck telescopes on Mauna Kea in Hawaii, which are all
about 10 m in diameter. It is very difﬁcult to support traditional, monolithic mirrors
so that the mirror surfaces maintain their shape (their “ﬁgure”) as the telescope slews,
because they are so heavy, so for Keck a new method of fabrication was sought. The
solution devised by Jerry Nelson and his colleagues was to construct the telescope out
11.7 Stress Polishing a Telescope Mirror
609

of 36 separate hexagons, each 0.9 m on a side. However, this posed a second problem:
howtogrindeachhexagon’sreﬂectingsurfacetotherequiredhyperboloidalshape.For
this, a novel technique called stressed mirror polishing was developed. This technique
stressed mirror polishing
relies on the fact that it is relatively easy to grind a surface to a spherical shape,
but technically highly challenging to create a nonaxisymmetric shape. So during the
grinding, stresses are applied around the boundary of the mirror to deform it, and a
spherical surface is produced. The stresses are then removed, and the mirror springs
into the desired nonspherical shape. Computing the necessary stresses is a problem
in classical elasticity theory and, in fact, is a good example of a large number of
applications where the elastic body can be approximated as a thin plate and its shape
analyzed using elasticity equations that are reduced from 3 dimensions to 2 by the
method of moments.
For stress polishing of mirrors, the applied stresses are so large that we can ig-
nore gravitational forces (at least in our simpliﬁed treatment). We suppose that the
hexagonal mirror has a uniform thickness h and idealize it as a circle of radius R, and
we introduce Cartesian coordinates with (x, y) in the horizontal plane (the plane of
the mirror before deformation and polishing begin), and z vertical. The mirror is de-
formed as a result of a net vertical force per unit area (pressure) P (x, y). This pressure
is applied at the lower surface when upward (positive) and the upper surface when
downward (negative). In addition, there are shear forces and bending torques applied
around the rim of the mirror.
As in our analysis of a cantilever in Sec. 11.5, we assume the existence of a neutral
surface in the deformed mirror, where the horizontal strain vanishes, Tab = 0. (Here
and below we use letters from the early part of the Latin alphabet for horizontal
components x = x1 and y = x2.) We denote the vertical displacement of the neutral
surface by η(x, y). By applying the method of moments to the 3-dimensional stress-
balance equation Tjk,k = 0 in a manner similar to our cantilever analysis, we obtain
the following 2-dimensional equation for the mirror’s shape (Ex. 11.19):
elastostatic force balance
for a bent plate on which
a pressure PPP acts: shape
equation
∇2(∇2η) = P (x, y)/D.
(11.63a)
Here ∇2 is the horizontal Laplacian: ∇2η ≡η,aa = η,xx + η,yy. Equation (11.63a)
is the 2-dimensional analog of the equation d4η/dx4 = W(x)/D for the shape of a
cantilever on which a downward force per unit length W(x) acts [Eq. (11.45)]. The
2-dimensional ﬂexural rigidity that appears in Eq. (11.63a) is
2-dimensional ﬂexural
rigidity
D =
Eh3
12(1 −ν2) ,
(11.63b)
where E is the mirror’s Young’s modulus, h is its thickness, and ν is its Poisson’s ratio.
The operator ∇2∇2 acting on η in the shape equation (11.63a) is called the biharmonic
biharmonic operator
operator; it also appears in 3-dimensional form in the biharmonic equation (11.34a)
610
Chapter 11. Elastostatics

mirror
glass
block
radial arm
10 cm
F1
F2
P
r1
r2
FIGURE 11.14 Schematic showing the mirror rim, a radial arm attached to it via a block,
and a lever assembly used to apply shear forces and bending torques to the rim during
stress polishing. (F1 need not equal F2, as there is a pressure P applied to the back
surface of the mirror and forces applied at 23 other points around its rim.) The shear
force on the mirror rim is S = F2 −F1, and the bending torque is M = r2F2 −r1F1.
for the displacement inside a homogeneous, isotropic body to which surface stresses
are applied.
The shape equation (11.63a) must be solved subject to boundary conditions
around the mirror’s rim: the applied shear forces and bending torques.
The individual Keck mirror segments were constructed out of a ceramic material
with Young’s modulus E = 89 GPa and Poisson’s ratio ν = 0.24 (similar to glass; cf.
Table 11.1). A mechanical jig was constructed to apply the shear forces and bending
torques at 24 uniformly spaced points around the rim of the mirror (Fig. 11.14). The
maximum stress was applied for the six outermost mirrors and was 2.4 × 106 N m−2,
12% of the material’s breaking tensile strength (2 × 107 N m−2).
This stress polishing worked beautifully, and the Keck telescopes have become
highly successful tools for astronomical research.
EXERCISES
Exercise 11.19 **Derivation and Example: Dimensionally Reduced Shape Equation
for a Stressed Plate
Use the method of moments (Sec. 11.5) to derive the 2-dimensional shape equation
(11.63a) for the stress-induced deformation of a thin plate, and expression (11.63b)
for the 2-dimensional ﬂexural rigidity. Here is a step-by-step guide, in case you want
or need it.
(a) Show on geometrical grounds that the in-plane strain is related to the vertical
displacement by [cf. Eq. (11.40a)]
ξa,b = −zη,ab.
(11.64a)
(b) Derive an expression for the horizontal components of the stress, Tab, in terms
of double derivatives of the displacement function η(x, y) [analog of Txx =
−Ezd2η/dx2, Eq. (11.40b), for a stressed rod]. This can be done (i) by arguing
on physical grounds that the vertical component of stress, Tzz, is much smaller
than the horizontal components and therefore can be approximated as zero [an
11.7 Stress Polishing a Telescope Mirror
611

approximation to be checked in part (f)]; (ii) by expressing Tzz = 0 in terms of
the strain and thence displacement and using Eqs. (11.39) to obtain
 = −
1 −2ν
1 −ν

z∇2η,
(11.64b)
where ∇2 is the horizontal Laplacian; and (iii) by then writing Tab in terms of
 and ξa,b and combining with Eqs. (11.64a) and (11.64b) to get the desired
equation:
Tab = Ez

ν
(1 −ν2)∇2η δab +
η,ab
(1 + ν)

.
(11.64c)
(c) With the aid of Eq. (11.64c), write the horizontal force density in the form
fa = −Tab,b −Taz,z = −Ez
1 −ν2∇2η,a −Taz,z = 0.
(11.64d)
Then, asinthecantileveranalysis[Eq.(11.40d)], reducethedimensionalityofthis
force equation by the method of moments. The zeroth moment (integral over z)
vanishes. Why? Therefore, the lowest nonvanishing moment is the ﬁrst (multiply
fa by z and integrate). Show that this gives
Sa ≡

Tzadz = D∇2η,a,
(11.64e)
where D is the 2-dimensional ﬂexural rigidity (11.63b). The quantity Sa is the
vertical shear force per unit length acting perpendicular to a line in the mirror
whose normal is in the direction a; it is the 2-dimensional analog of a stressed
rod’s shear force S [Eq. (11.41a)].
(d) For physical insight into Eq. (11.64e), deﬁne the bending torque per unit length
(bending torque density) as
Mab ≡

zTabdz,
(11.64f)
andshowwiththeaidofEq.(11.64c)that(11.64e)isthelawoftorquebalance Sa =
Mab,b—the 2-dimensional analog of a stressed rod’s S = dM/dx [Eq. (11.42)].
(e) Compute the total vertical shear force acting on a small area of the plate as the
line integral of Sa around its boundary, and by applying Gauss’s theorem, deduce
that the vertical shear force per unit area is Sa,a. Argue that this must be balanced
by the net pressure P applied to the face of the plate, and thereby deduce the law
of vertical force balance:
Sa,a = P .
(11.64g)
By combining this equation with the law of torque balance (11.64e), obtain the
plate’s bending equation ∇2(∇2η) = P/D [Eq. (11.63a)—the ﬁnal result we were
seeking].
612
Chapter 11. Elastostatics

(f) Use this bending equation to verify the approximation made in part (b) that Tzz
is small compared to the horizontal stresses. Speciﬁcally, show that Tzz ≃P is
O(h/R)2Tab, where h is the plate thickness, and R is the plate radius.
Exercise 11.20 Example: Paraboloidal Mirror
Show how to construct a paraboloidal mirror of radius R and focal length f by stress
polishing.
(a) Adopt a strategy of polishing the stressed mirror into a segment of a sphere with
radius of curvature equal to that of the desired paraboloid at its center, r = 0. By
comparing the shape of the desired paraboloid to that of the sphere, show that
the required vertical displacement of the stressed mirror during polishing is
η(r) =
r4
64f 3 ,
(11.64h)
where r is the radial coordinate, and we only retain terms of leading order.
(b) Hence use Eq. (11.63a) to show that a uniform force per unit area
P = D
f 3 ,
(11.64i)
where D is the ﬂexural rigidity, must be applied to the bottom of the mirror.
(Ignore the weight of the mirror.)
(c) Based on the results of part (b), show that if there are N equally spaced levers
attached at the rim, the vertical force applied at each of them must be
Fz = πDR2
Nf 3 ,
(11.64j)
and the applied bending torque must be
M = πDR3
2Nf 3 .
(11.64k)
(d) Show that the radial displacement inside the mirror is
ξr = −r3z
16f 3 ,
(11.64l)
where z is the vertical distance from the neutral surface, halfway through the
mirror.
(e) Hence evaluate the expansion  and the components of the shear tensor , and
show that the maximum stress in the mirror is
Tmax =
(3 −2ν)R2hE
32(1 −2ν)(1 + ν)f 3 ,
(11.64m)
where h is the mirror thickness. Comment on the limitations of this technique
for making a thick, “fast” (i.e., 2R/f large) mirror.
11.7 Stress Polishing a Telescope Mirror
613

11.8
11.8 Cylindrical and Spherical Coordinates: Connection Coefﬁcients
and Components of the Gradient of the Displacement Vector
Thus far in our discussion of elasticity, we have restricted ourselves to Cartesian
coordinates. However, many problems in elasticity are most efﬁciently solved using
cylindrical or spherical coordinates, so in this section, we develop some mathematical
tools for those coordinate systems. In doing so, we follow the vectorial conventions
of standard texts on electrodynamics and quantum mechanics (e.g., Jackson, 1999;
Cohen-Tannoudji, Diu, and Lalo¨e, 1977). We introduce an orthonormal set of basis
orthonormal basis vectors
of cylindrical or spherical
coordinates
vectors associated with each of our curvilinear coordinate systems; the coordinate
lines are orthogonal to one another, and the basis vectors have unit lengths and point
along the coordinate lines. In our study of continuum mechanics (Part IV, Elasticity;
Part V, Fluid Dynamics; and Part VI, Plasma Physics), we follow this practice. When
studying General Relativity (Part VII), we introduce and use basis vectors that are not
orthonormal.
cylindrical coordinates
Our notation for cylindrical coordinates is (ϖ , φ, z); ϖ (pronounced “pomega”)
is distance from the z-axis, and φ is the angle around the z-axis:
ϖ =

x2 + y2,
φ = arctan(y/x).
(11.65a)
The unit basis vectors that point along the coordinate axes are denoted eϖ, eφ, and
ez, and are related to the Cartesian basis vectors by
eϖ = (x/ϖ)ex + (y/ϖ)ey,
eφ = −(y/ϖ)ex + (x/ϖ)ey,
ez = Cartesian ez.
(11.65b)
Our notation for spherical coordinates is (r, θ, φ), with (as should be very
spherical coordinates
familiar)
r =

x2 + y2 + z2,
θ = arccos(z/r),
φ = arctan(y/x).
(11.66a)
The unit basis vectors associated with these coordinates are
er = x
r ex + y
r ey + z
r ez,
eθ = z
r eϖ −ϖ
r ez,
eφ = −y
ϖ ex + x
ϖ ey.
(11.66b)
Because our bases are orthonormal,
the components of the metric of
3-dimensional space retain the Kronecker-delta values
gjk ≡ej . ek = δjk,
(11.67)
which permits us to keep all vector and tensor indices down, by contrast with space-
time, where we must distinguish between up and down; cf. Sec. 2.5.10
10. Occasionally—e.g., in the useful equation ϵijmϵklm = δij
kl ≡δi
kδj
l −δi
lδj
k [Eq. (1.23)]—it is convenient to
put some indices up. In our orthonormal basis, any component with an index up is equal to that same
component with an index down: e.g., δi
k ≡δik.
614
Chapter 11. Elastostatics

In Jackson (1999), Cohen-Tannoudji, Diu, and Lalo¨e (1977), and other standard
texts, formulas are written down for the gradient and Laplacian of a scalar ﬁeld, and
the divergence and curl of a vector ﬁeld, in cylindrical and spherical coordinates;
one uses these formulas over and over again. In elasticity theory, we deal largely with
second-rank tensors and will need formulas for their various derivatives in cylindrical
and spherical coordinates. In this book we introduce a mathematical tool, connection
connection coefﬁcients
coefﬁcients ijk, by which those formulas can be derived when needed.
The connection coefﬁcients quantify the turning of the orthonormal basis vectors
as one moves from point to point in Euclidean 3-space: they tell us how the basis
vectors at one point in space are connected to (related to) those at another point. More
speciﬁcally, we deﬁne ijk by the two equivalent relations
∇kej = ijkei;
ijk = ei . (∇kej).
(11.68)
Here ∇k ≡∇ek is the directional derivative along the orthonormal basis vector ek; cf.
Eq. (1.15a). Notice that (as is true quite generally; cf. Sec. 1.7) the differentiation index
comes last on ; and notice that the middle index of  names the basis vector that
is differentiated. Because our basis is orthonormal, it must be that ∇k(ei . ej) = 0.
Expanding this expression out using the standard rule for differentiating products,
we obtain ej . (∇kei) + ei . (∇kej) = 0. Then invoking the deﬁnition (11.68) of the
connection coefﬁcients, we see that ijk is antisymmetric on its ﬁrst two indices:
ijk = −jik.
(11.69)
In Part VII, when we use nonorthonormal bases, this antisymmetry will break
down.
It is straightforward to compute the connection coefﬁcients for cylindrical and
spherical coordinates from (i) the deﬁnition (11.68); (ii) expressions (11.65b) and
(11.66b) for the cylindrical and spherical basis vectors in terms of the Cartesian basis
vectors; and (iii) the fact that in Cartesian coordinates the connection coefﬁcients vanish
(ex, ey, and ez do not rotate as one moves through Euclidean 3-space). One can also
deducethecylindricalandsphericalconnectioncoefﬁcientsbydrawingpicturesofthe
basis vectors and observing how they change from point to point. As an example, for
cylindrical coordinates we see from Fig. 11.15 that ∇φeϖ = eφ/ϖ. A similar pictorial
calculation (which the reader is encouraged to do) reveals that ∇φeφ = −eϖ/ϖ. All
other derivatives vanish. By comparing with Eq. (11.68), we see that the only nonzero
connection coefﬁcients
for orthonormal bases of
cylindrical and spherical
coordinates
connection coefﬁcients in cylindrical coordinates are
ϖφφ = −1
ϖ ,
φϖφ = 1
ϖ ,
(11.70)
11.8 Cylindrical and Spherical Coordinates
615

eϖ
eϖ
rφeϖ
eφ
FIGURE 11.15 Pictorial evaluation of φϖφ. In the rightmost assemblage of
vectors we compute ∇φeϖ as follows. We draw the vector to be differentiated,
eϖ, at the tail of eφ (the vector along which we differentiate) and also at its
head. We then subtract eϖ at the head from that at the tail; this difference
is ∇φeϖ. It obviously points in the eφ direction. When we perform the same
calculation at a radius ϖ that is smaller by a factor 2 (left assemblage of
vectors), we obtain a result, ∇φeϖ, that is twice as large. Therefore, the length
of this vector must scale as 1/ϖ. By looking quantitatively at the length at
some chosen radius ϖ, one can see that the multiplicative coefﬁcient is unity:
∇φeϖ = eφ/ϖ. Comparing with Eq. (11.68), we deduce that φϖφ = 1/ϖ.
which have the required antisymmetry [Eq. (11.69)]. Likewise, for spherical coordi-
nates (Ex. 11.22), we have
θrθ = φrφ = −rθθ = −rφφ = 1
r ,
φθφ = −θφφ = cot θ
r
.
(11.71)
These connection coefﬁcients are the keys to differentiating vectors and tensors.
Consider the gradient of the displacement, W = ∇ξ. Applying the product rule for
differentiation, we obtain
∇k(ξjej) = (∇kξj)ej + ξj(∇kej) = ξj ,kej + ξjljkel.
(11.72)
Here the comma denotes the directional derivative, along a basis vector, of the com-
directional derivative
along basis vector
ponents treated as scalar ﬁelds. For example, in cylindrical coordinates we have
ξi,ϖ = ∂ξi
∂ϖ ,
ξi,φ = 1
ϖ
∂ξi
∂φ ,
ξi,z = ∂ξi
∂z ;
(11.73)
and in spherical coordinates we have
ξi,r = ∂ξi
∂r ,
ξi,θ = 1
r
∂ξi
∂θ ,
ξi,φ =
1
r sin θ
∂ξi
∂φ .
(11.74)
616
Chapter 11. Elastostatics

Taking the ith component of Eq. (11.72) we obtain
Wik = ξi;k = ξi,k + ijkξj.
(11.75)
Here ξi;k are the nine components of the gradient of the vector ﬁeld ξ(x).
We can use Eq. (11.75) to evaluate the expansion  = Tr W = ∇. ξ. Using Eqs.
(11.70) and (11.71), we obtain
 = ∇. ξ = ∂ξϖ
∂ϖ + 1
ϖ
∂ξφ
∂φ + ∂ξz
∂z + ξϖ
ϖ
= 1
ϖ
∂
∂ϖ

ϖξϖ

+ 1
ϖ
∂ξφ
∂φ + ∂ξz
∂z
(11.76)
in cylindrical coordinates and
 = ∇. ξ = ∂ξr
∂r + 1
r
∂ξθ
∂θ +
1
r sin θ
∂ξφ
∂φ + 2ξr
r
+ cot θξθ
r
= 1
r2
∂
∂r (r2ξr) +
1
r sin θ
∂
∂θ (sin θξθ) +
1
r sin θ
∂ξφ
∂φ
(11.77)
in spherical coordinates, in agreement with formulas in standard textbooks, such as
the ﬂyleaf of Jackson (1999).
The components of the rotation are most easily deduced using Rij = −ϵijkφk with
φ = 1
2∇× ξ, and the standard expressions for the curl in cylindrical and spherical
coordinates (Jackson, 1999). Since the rotation does not enter into elasticity theory in
a signiﬁcant way, we refrain from writing down the results. The components of the
shear are computed in Box 11.4.
By a computation analogous to Eq. (11.72), we can construct an expression for the
gradient of a tensor of any rank. For a second-rank tensor T = Tijei ⊗ej we obtain
(Ex. 11.21)
components of gradient of
a tensor
Tij;k = Tij ,k + ilkTlj + jlkTil.
(11.78)
Equation (11.78) for the components of the gradient can be understood as follows.
In cylindrical or spherical coordinates, the components Tij can change from point to
point as a result of two things: a change of the tensor T or the turning of the basis
vectors. The two connection coefﬁcient terms in Eq. (11.78) remove the effects of the
basis turning, leaving in Tij;k only the inﬂuence of the change of T itself. There are
two correction terms corresponding to the two slots (indices) of T; the effects of basis
turning on each slot get corrected one after another. If T had had n slots, then there
would have been n correction terms, each with the form of the two in Eq. (11.78).
These expressions for derivatives of tensors are not required for dealing with the
vector ﬁelds of introductory electromagnetic theory or quantum theory, but they are
essential for manipulating the tensor ﬁelds encountered in elasticity. As we shall see
in Sec. 24.3, with one further generalization, we can go on to differentiate tensors in
11.8 Cylindrical and Spherical Coordinates
617

BOX 11.4.
SHEAR TENSOR IN SPHERICAL AND CYLINDRICAL
COORDINATES
Using our rules (11.75) for forming the gradient of a vector, we can derive a
general expression for the shear tensor:
Σij = 1
2(ξi;j + ξj;i) −1
3δijξk;k
= 1
2(ξi,j + ξj ,i + iljξl + jliξl) −1
3δij(ξk,k + klkξl).
(1)
Evaluating this in cylindrical coordinates using the connection coefﬁcients
(11.70), we obtain
Σϖϖ = 2
3
∂ξϖ
∂ϖ −1
3
ξϖ
ϖ −
1
3ϖ
∂ξφ
∂φ −1
3
∂ξz
∂z ,
Σφφ =
2
3ϖ
∂ξφ
∂φ + 2
3
ξϖ
ϖ −1
3
∂ξϖ
∂ϖ −1
3
∂ξz
∂z ,
Σzz = 2
3
∂ξz
∂z −1
3
∂ξϖ
∂ϖ −1
3
ξϖ
ϖ −
1
3ϖ
∂ξφ
∂φ ,
Σφz = Σzφ =
1
2ϖ
∂ξz
∂φ + 1
2
∂ξφ
∂z ,
Σzϖ = Σϖz = 1
2
∂ξϖ
∂z + 1
2
∂ξz
∂ϖ ,
Σϖφ = Σφϖ = 1
2
∂ξφ
∂ϖ −ξφ
2ϖ +
1
2ϖ
∂ξϖ
∂φ .
(2)
Likewise, in spherical coordinates using the connection coefﬁcients (11.71),
we obtain
Σrr = 2
3
∂ξr
∂r −2
3r ξr −cot θ
3r ξθ −1
3r
∂ξθ
∂θ −
1
3r sin θ
∂ξφ
∂φ ,
Σθθ = 2
3r
∂ξθ
∂θ + ξr
3r −1
3
∂ξr
∂r −cot θξθ
3r
−
1
3r sin θ
∂ξφ
∂φ ,
Σφφ =
2
3r sin θ
∂ξφ
∂φ + 2 cot θξθ
3r
+ ξr
3r −1
3
∂ξr
∂r −1
3r
∂ξθ
∂θ ,
Σθφ = Σφθ = 1
2r
∂ξφ
∂θ −cot θξφ
2r
+
1
2r sin θ
∂ξθ
∂φ ,
Σφr = Σrφ =
1
2r sin θ
∂ξr
∂φ + 1
2
∂ξφ
∂r −ξφ
2r ,
Σrθ = Σθr = 1
2
∂ξθ
∂r −ξθ
2r + 1
2r
∂ξr
∂θ .
(3)
618
Chapter 11. Elastostatics

any basis (orthonormal or nonorthonormal) in a curved spacetime, as is needed to
perform calculations in general relativity.
Although the algebra of evaluating the components of derivatives such as in
Eq. (11.78) in explicit form (e.g., in terms of {r, θ, φ}) can be long and tedious when
done by hand, in the modern era of symbolic manipulation using computers (e.g.,
Mathematica, Matlab, or Maple), the algebra can be done quickly and accurately to
obtain expressions such as Eqs. (3) of Box 11.4.
EXERCISES
Exercise 11.21 Derivation and Practice: Gradient of a Second-Rank Tensor
By a computation analogous to Eq. (11.72), derive Eq. (11.78) for the components of
the gradient of a second-rank tensor in any orthonormal basis.
Exercise 11.22 Derivation and Practice: Connection in Spherical Coordinates
(a) By drawing pictures analogous to Fig. 11.15, show that
∇φer = 1
r eφ,
∇θer = 1
r eθ,
∇φeθ = cot θ
r
eφ.
(11.79)
(b) From these relations and antisymmetry on the ﬁrst two indices [Eq. (11.69)],
deduce the connection coefﬁcients (11.71).
Exercise 11.23 Derivation and Practice: Expansion in Cylindrical
and Spherical Coordinates
Derive Eqs. (11.76) and (11.77) for the divergence of the vector ﬁeld ξ in cylindrical
and spherical coordinates using the connection coefﬁcients (11.70) and (11.71).
11.9
11.9 Solving the 3-Dimensional Navier-Cauchy Equation
in Cylindrical Coordinates
11.9.1
11.9.1 Simple Methods: Pipe Fracture and Torsion Pendulum
As an example of an elastostatic problem with cylindrical symmetry, consider a cylin-
drical pipe that carries a high-pressure ﬂuid (e.g., water, oil, natural gas); Fig. 11.16.
How thick must the pipe’s wall be to ensure that it will not burst due to the ﬂuid’s
pressure? We sketch the solution, leaving the details to Ex. 11.24.
We suppose, for simplicity, that the pipe’s length is held ﬁxed by its support system:
it does not lengthen or shorten when the ﬂuid pressure is changed. Then by symmetry,
the displacement ﬁeld in the pipe wall is purely radial and depends only on radius:
its only nonzero component is ξϖ(ϖ). The radial dependence is governed by radial
force balance,
fϖ = K;ϖ + 2μΣϖj;j = 0
(11.80)
[Eq. (11.30)].
11.9 Solving the 3-Dimensional Navier-Cauchy Equation
619

ϖ2
ϖ1
FIGURE 11.16 A pipe whose wall has inner
and outer radii ϖ1 and ϖ2.
Because ξϖ is independent of φ and z, the expansion [Eq. (11.76)] is given by
 = dξϖ
dϖ + ξϖ
ϖ .
(11.81)
The second term in the radial force balance equation (11.80) is proportional to ϖj;j
which—usingEq.(11.78)andnotingthattheonlynonzeroconnectioncoefﬁcientsare
ϖφφ = −φϖφ = −1/ϖ [Eq. (11.70)] and that symmetry requires the shear tensor
to be diagonal—becomes
Σϖj;j = Σϖϖ ,ϖ + ϖφφΣφφ + φϖφΣϖϖ.
(11.82)
Inserting the components of the shear tensor from Eqs. (2) of Box 11.4 and the values
of the connection coefﬁcients and comparing the result with expression (11.81) for
the expansion, we obtain the remarkable result that Σϖj;j = 2
3∂/∂ϖ. Inserting this
into the radial force balance equation (11.80), we obtain
fϖ =

K + 4μ
3
 d
dϖ = 0.
(11.83)
Thus, inside the pipe wall, the expansion is independent of radius ϖ, and correspond-
ingly, the radial displacement must have the form [cf. Eq. (11.81)]
ξϖ = Aϖ + B
ϖ
(11.84)
for some constants A and B, whence  = 2A and Σϖϖ = 1
3A −B/ϖ 2. The values of
A and B are ﬁxed by the boundary conditions at the inner and outer faces of the pipe
wall: Tϖϖ = P at ϖ = ϖ1 (inner wall) and Tϖϖ = 0 at ϖ = ϖ2 (outer wall). Here P
isthepressureoftheﬂuidthatthepipecarries, andwehaveneglectedtheatmosphere’s
pressure on the outer face by comparison. Evaluating Tϖϖ = −K −2μΣϖϖ and
then imposing these boundary conditions, we obtain
A =
P
2(K + μ/3)
ϖ 2
1
(ϖ 2
2 −ϖ 2
1) ,
B = P
2μ
ϖ 2
1ϖ 2
2
(ϖ 2
2 −ϖ 2
1).
(11.85)
620
Chapter 11. Elastostatics

The only nonvanishing components of the strain then work out to be
Sϖϖ = ∂ξϖ
∂ϖ = A −B
ϖ 2 ,
Sφφ = ξϖ
ϖ = A + B
ϖ 2 .
(11.86)
This strain is maximal at the inner wall of the pipe; expressing it in terms of the ratio
ζ ≡ϖ2/ϖ1 of the outer to the inner pipe radius and using the values of K = 180 GPa
and μ = 81GPa for steel, we bring this maximum strain into the form
Sϖϖ ≃−P
μ
5ζ 2 −2
10(ζ 2 −1) ,
Sφφ ≃P
μ
5ζ 2 + 2
10(ζ 2 −1).
(11.87)
Note that |Sφφ| > |Sϖϖ|.
criterion for safety against
fracture
The pipe will fracture at a strain ∼10−3; for safety it is best to keep the actual
strain smaller than this by an order of magnitude, |Sij| <∼10−4. A typical pressure for
an oil pipeline is P ≃10 atmospheres (≃106 Pa), compared to the shear modulus of
steel μ = 81GPa, so P/μ ≃1.2 × 10−5. Inserting this number into Eq. (11.87) with
|Sφφ| <∼10−4, we deduce that the ratio of the pipe’s outer radius to its inner radius
must be ζ = ϖ2/ϖ1 >∼1.04. If the pipe has a diameter of a half meter, then its wall
thickness should be about 1 cm or more. This is typical of oil pipelines.
Exercise 11.25 presents a second fairly simple example of elastostatics in cylindri-
cal coordinates: a computation of the period of a torsion pendulum.
EXERCISES
Exercise 11.24 Derivation and Practice: Fracture of a Pipe
Fill in the details of the text’s analysis of the deformation of a pipe carrying a high-
pressure ﬂuid, and the wall thickness required to protect the pipe against fracture.
(See Fig. 11.16.)
Exercise 11.25 Practice: Torsion Pendulum
A torsion pendulum is a very useful tool for testing the equivalence principle
(Sec. 25.2), for seeking evidence for hypothetical ﬁfth (not to mention sixth!) forces,
and for searching for deviations from gravity’s inverse-square law on submillimeter
scales, which could arise from gravity being inﬂuenced by macroscopic higher spatial
dimensions. (See, e.g., Kapner et al., 2008; Wagner et al., 2012.) It would be advanta-
geous to design a torsion pendulum with a 1-day period (Fig. 11.17). Here we estimate
whether this is possible. The pendulum consists of a thin cylindrical wire of length ℓ
and radius a. At the bottom of the wire are suspended three masses at the corners of
an equilateral triangle at a distance b from the wire.
(a) Show that the longitudinal strain is
ξz;z = 3mg
πa2E .
(11.88a)
11.9 Solving the 3-Dimensional Navier-Cauchy Equation
621

2a
m
m
m
b
ℓ
FIGURE 11.17 Torsion pendulum.
(b) What component of shear is responsible for the restoring force in the wire, which
causes the torsion pendulum to oscillate?
(c) Show that the pendulum undergoes torsional oscillations with period
P = 2π
 ℓ
g
1/2 *
2b2Eξz;z
a2μ
+1/2
.
(11.88b)
(d) Do you think you could design a pendulum that attains the goal of a 1-day period?
11.9.2
11.9.2 Separation of Variables and Green’s Functions: Thermoelastic Noise
in Mirrors
In complicated situations that have moderate amounts of symmetry, the elastostatic
equations can be solved by the same kinds of sophisticated mathematical techniques
asoneusesinelectrostatics:separationofvariables, Green’sfunctions, complexpoten-
tials, or integral transform methods (see, e.g., Gladwell, 1980). We provide an example
in this section, focusing on separation of variables and Green’s functions.
MOTIVATION
Our example is motivated by an important issue in high-precision measurements
with light, including, among others, gravitational-wave detectors and quantum-optics
experiments in which photons and atoms are put into entangled nonclassical states
by coupling them to one another inside Fabry-Perot cavities.
In these situations, noise due to thermal motions of the mirror is a serious issue.
It can hide a gravitational wave, and it can cause decoherence of the atom/photon
quantum states. In Sec. 6.8.2, we formulated a generalized ﬂuctuation-dissipation
theorem by which this mirror thermal noise can be computed (Levin, 1998).
622
Chapter 11. Elastostatics

Speciﬁcally, in a thought experiment one applies to the mirror face a force Fo
that oscillates at some frequency f at which one wants to evaluate the thermal noise.
This force has the same transverse pressure distribution as the light beam—say, for
concreteness, a Gaussian distribution:
T applied
zz
= e−ϖ 2/ϖ 2
o
πϖ 2
o
Fo cos(2πf t).
(11.89)
This applied pressure induces a strain distribution S inside the mirror, and that oscil-
lating strain interacts with imperfections to dissipate energy at some rate Wdiss(f ).
The ﬂuctuation-dissipation theorem states that in the real experiment, where the
light beam bounces off the mirror, the reﬂected light will encode a noisy transverse-
averaged position q for the mirror face, and the noise spectral density for q will be
Sq(f ) = 8Wdiss(f )kBT
(2πf )2F 2
o
(11.90)
[Eq. (6.88b)].
Even if one could make the mirror perfect (no dislocations or impurities), so
there is no dissipation due to imperfections, there will remain one other source of
dissipation in this thought experiment: the applied pressure (11.89) will produce a
spatially inhomogeneous expansion (x, t) inside the mirror, which in turn will pro-
duce the thermoelastic temperature change T /T = −[3αK/(ρcV )] [Eq. (11.29)].
The gradient of this temperature will induce heat ﬂow, with a thermal energy ﬂux
Fth = −κ∇T , where κ is the thermal conductivity. When an amount Q of this ther-
mal energy ﬂows from a region with temperature T to a region of lower temperature
T −dT , it produces an entropy increase dS = Q/(T −dT ) −Q/T = QdT /T 2;
and correspondingly, there is a rate of entropy increase per unit volume given by
d2S/dV dt = −Fth . ∇T /T 2 = κ(∇T )2/T 2. This entropy increase has an accom-
panying energy dissipation rate Wdiss =

T (d2S/dtdV )dV =

(κ/T )(∇T )2dV .
Expressing T in terms of the expansion that drives it via T /T = −[3αK/(ρcV )]
and inserting that into Eq. (11.90) and using the third of Eqs. (11.39), we obtain the
thermal noise spectral density that the experimenters must contend with:
Sq(f ) =
8κE2α2kBT 2
(1 −2ν)2c2
V ρ2F 2
o(2πf )2
?
(∇)2ϖdφdϖdz
@
.
(11.91)
Here ⟨.⟩means average over time as  oscillates due to the oscillation of the driving
forceFo cos(2πf t).Becausethedissipationproducingthisnoiseisduetoheatﬂowing
down a thermoelastic temperature gradient, it is called thermoelastic noise.
This is the motivation for an elasticity problem that we shall solve to illustrate
separation of variables: to evaluate this thermoelastic noise, we must compute the
expansion (x, t) inside a mirror, produced by the oscillating pressure (11.89) on
the mirror face; and we must then perform the integral (11.91).
11.9 Solving the 3-Dimensional Navier-Cauchy Equation
623

SOLUTION FOR  VIA SEPARATION OF VARIABLES
The frequencies f at which we wish to evaluate the thermal noise are low compared to
the inverse sound travel time across the mirror, so when computing  we can regard
the force as oscillating very slowly (i.e., we can use our elastostatic equations rather
than dynamical equations of the next chapter). Also, the size of the light spot on the
mirror is usually small compared to the mirror’s transverse size and thickness, so we
can idealize the mirror as being inﬁnitely large and thick—a homogeneous half-space
of isotropic, elastic material.
Because the applied stress is axially symmetric, the induced strain and expansion
will also be axially symmetric and are thus computed most easily using cylindrical
coordinates. Our challenge, then, is to solve the Navier-Cauchy equation f = (K +
1
3μ)∇(∇. ξ) + μ∇2ξ = 0 for the cylindrical components ξϖ(z, ϖ) and ξz(z, ϖ) of
the displacement, and then evaluate the expansion  = ∇. ξ. (The component ξφ
vanishes by symmetry.)
Equations of elasticity in cylindrical coordinates, and their homogeneous solution
It is straightforward, using the techniques of Sec. 11.8, to compute the cylindrical
components of f. Reexpressing the bulk K and shear μ moduli in terms of Young’s
modulus E and Poisson’s ratio ν [Eqs. (11.39)] and setting the internal forces to zero,
we obtain
elastostatic force balance
in cylindrical coordinates
fϖ =
E
2(1 + ν)(1 −2ν)

2(1 −ν)
∂2ξϖ
∂ϖ 2 + 1
ϖ
∂ξϖ
∂ϖ −ξϖ
ϖ 2

+ (1 −2ν)∂2ξϖ
∂z2 + ∂2ξz
∂z∂ϖ

= 0,
(11.92a)
fz =
E
2(1 + ν)(1 −2ν)

(1 −2ν)
 ∂2ξz
∂ϖ 2 + 1
ϖ
∂ξz
∂ϖ

+ 2(1 −ν)∂2ξz
∂z2 + ∂2ξϖ
∂z∂ϖ + 1
ϖ
∂ξϖ
∂z

= 0.
(11.92b)
These are two coupled, linear, second-order differential equations for the two
unknown components of the displacement vector. As with the analogous equations
of electrostatics and magnetostatics, these can be solved by separation of variables,
that is, by setting ξϖ = Rϖ(ϖ)Zϖ(z) and ξz = Rz(ϖ)Zz(z), and inserting into
Eq. (11.92a). We seek the general solution that dies out at large ϖ and z. The general
solution of this sort, to the complicated-looking Eqs. (11.92), turns out to be (really!!)
separation-of-variables
solution of force-balance
equation fj = 0
fj = 0
fj = 0
ξϖ =
 ∞
0
[α(k) −(2 −2ν −kz)β(k)]e−kzJ1(kϖ) dk,
ξz =
 ∞
0
[α(k) + (1 −2ν + kz)β(k)]e−kzJ0(kϖ) dk.
(11.93)
624
Chapter 11. Elastostatics

Here J0 and J1 are Bessel functions of order 0 and 1, and α(k) and β(k) are arbitrary
functions.
Boundary conditions
The functions α(k) and β(k) are determined by boundary conditions on the face of
the test mass. The force per unit area exerted across the face by the strained test-
mass material, Tzj at z = 0 with j = {ϖ , φ, z}, must be balanced by the applied force
per unit area, T applied
zj
[Eq. (11.89)]. The (shear) forces in the φ direction, Tzφ and
T applied
zφ
, vanish because of cylindrical symmetry and thus provide no useful boundary
condition. The (shear) force in the ϖ direction, which must vanish at z = 0 since
T applied
zϖ
= 0, is given by [cf. Eq. (2) in Box 11.4]
shear-force boundary
condition at z = 0
z = 0
z = 0
Tzϖ(z = 0) = −2μΣzϖ = −μ
 ∂ξz
∂ϖ + ∂ξϖ
∂z

= −μ
 ∞
0
[β(k) −α(k)]J1(kz)kdk = 0,
(11.94)
which implies that β(k) = α(k). The (normal) force in the z direction, which must
balance the applied pressure (11.89), is Tzz = −K −2μΣzz; using Eq. (2) in Box
11.4 and Eqs. (11.39), (11.76), (11.93) and (11.89), this reduces to
longitudinal-force
boundary condition at
z = 0
z = 0
z = 0
Tzz(z = 0) = 2μ
 ∞
0
α(k)J0(kϖ)kdk = T applied
zz
= e−ϖ 2/ϖ 2
o
πϖ 2
o
Fo cos(2πf t),
(11.95)
which can be inverted11 to give
α(k) = β(k) =
1
4πμe−k2ϖ 2
o/4Fo cos(2πf t).
(11.96)
Inserting this equation into the Eqs. (11.93) for the displacement and then evaluating
solution for expansion
coefﬁcients
the expansion  = ∇. ξ = ξz,z + ϖ −1(ϖξϖ),ϖ, we obtain
 = 2(1 −2ν)
 ∞
0
α(k)e−kzJ0(kϖ)k dk.
(11.97)
As in electrostatics and magnetostatics, so also in elasticity theory, one can solve
an elastostatics problem using Green’s functions instead of separation of variables. We
explore this option for our applied Gaussian force in Ex. 11.27. For greater detail on
11. The inversion and the subsequent evaluation of the integral of (∇)2 are aided by the following
expressions for the Dirac delta function:
δ(k −k′) = k
 ∞
0
J0(kϖ)J0(k′ϖ)ϖdϖ = k
 ∞
0
J1(kϖ)J1(k′ϖ)ϖdϖ .
11.9 Solving the 3-Dimensional Navier-Cauchy Equation
625

Green’s functions in elastostatics and their applications from an engineer’s viewpoint,
see Johnson (1985). For other commonly used solution techniques, see Box 11.3.
THERMOELASTIC NOISE SPECTRAL DENSITY
Let us return to the mirror-noise problem that motivated our calculation. It is straight-
forward to compute the gradient of the expansion (11.97), and square and integrate it
to get the spectral density Sq(f ) [Eq. (11.91)]. The result is (Braginsky, Gorodetsky,
and Vyatchanin, 1999; Liu and Thorne, 2000)
Sq(f ) = 8(1 + ν)2κα2kBT 2
√
2πc2
V ρ2ϖ 3
o(2πf )2 .
(11.98)
Early plans for advanced LIGO gravitational wave detectors (Sec. 9.5; LIGO Sci-
entiﬁc Collaboration, 2015) called for mirrors made of high-reﬂectivity dielectric
coatings on sapphire crystal substrates. Sapphire was chosen because it can be grown
in giant crystals with very low impurities and dislocations, resulting in low ther-
mal noise. However, the thermoelastic noise (11.98) in sapphire turns out to be un-
comfortablyhigh.Usingsapphire’sν = 0.29, κ = 40 W m−1 K−1, α = 5.0 × 10−6 K−1,
cV = 790 J kg−1 K−1, ρ = 4,000 kg m−3, and a light-beam radius ϖo = 4 cm and
room temperature T = 300 K, Eq. (11.98) gives the following for the noise in a band-
width equal to frequency:

f Sq(f ) = 5 × 10−20 m
1
100 Hz
f
.
(11.99)
Because this was uncomfortably high at low frequencies, f ∼10 Hz, and because of
the birefringence of sapphire, which could cause technical problems, a decision was
made to switch to fused silica for the advanced LIGO mirrors.
EXERCISES
Exercise 11.26 Derivation and Practice: Evaluation of Elastostatic Force
in Cylindrical Coordinates
DeriveEqs.(11.92)forthecylindricalcomponentsoftheinternalelastostaticforceper
unit volume f = (K + 1
3μ)∇(∇. ξ) + μ∇2ξ in a cylindrically symmetric situation.
Exercise 11.27 **Example: Green’s Function for Normal Force on a Half-Inﬁnite
Body
Suppose that a stress T applied
zj
(xo) is applied on the face z = 0 of a half-inﬁnite elastic
body (one that ﬁlls the region z > 0). Then by virtue of the linearity of the elastostatics
equation f = (K + 1
3μ)∇(∇. ξ) + μ∇2ξ = 0 and the linearity of its boundary con-
ditions, T internal
zj
= T applied
zj
, there must be a Green’s function Gjk(x −xo) such that
the body’s internal displacement ξ(x) is given by
ξj(x) =

Gjk(x −x0)T applied
kz
(xo)d2xo.
(11.100)
626
Chapter 11. Elastostatics

Here the integral is over all points xo on the face of the body (z = 0), and x can be
anywhere inside the body, z ≥0.
(a) Show that if a force Fj is applied on the body’s surface at a single point (the origin
of coordinates), then the displacement inside the body is
ξj(x) = Gjk(x)Fk.
(11.101)
Thus, the Green’s function can be thought of as the body’s response to a point
force on its surface.
(b) As a special case, consider a point force Fz directed perpendicularly into the body.
The resulting displacement turns out to have cylindrical components12
ξz = Gzz(ϖ , z)Fz = (1 + ν)
2πE
2(1 −ν)
r
+ z2
r3

Fz,
ξϖ = Gϖz(ϖ , z)Fz = −(1 + ν)
2πE
(1 −2ν)ϖ
r(r + z)
−ϖz
r3

Fz,
(11.102)
where r =
√
ϖ 2 + z2. It is straightforward to show that this displacement does
satisfy the elastostatics equations (11.92). Show that it also satisﬁes the required
boundary condition Tzϖ(z = 0) = −2μΣzϖ = 0.
(c) Show that for this displacement [Eq. (11.102)], Tzz = −K −2μΣzz vanishes
everywhere on the body’s surface z = 0 except at the origin ϖ = 0 and is inﬁnite
there. Show that the integral of this normal stress over the surface is Fz, and there-
fore, Tzz(z = 0) = Fzδ2(x), where δ2 is the 2-dimensional Dirac delta function on
the surface. This is the second required boundary condition.
(d) Plot the integral curves of the displacement vector ξ (i.e., the curves to which ξ
is parallel) for a reasonable choice of Poisson’s ratio ν. Explain physically why the
curves have the form you ﬁnd.
(e) One can use the Green’s function (11.102) to compute the displacement ξ induced
by the Gaussian-shaped pressure (11.89) applied to the body’s face, and to then
evaluate the induced expansion and thence the thermoelastic noise; see Bragin-
sky, Gorodetsky, and Vyatchanin (1999) and Liu and Thorne (2000). The results
agree with Eqs. (11.97) and (11.98) deduced using separation of variables.
Bibliographic Note
Elasticity theory was developed in the eighteenth, nineteenth, and early twentieth
centuries.TheclassicadvancedtextbookfromthateraisLove(1927).Anoutstanding,
somewhat more modern advanced text is Landau and Lifshitz (1986)—originally
12. For the other components of the Green’s function, written in Cartesian coordinates (since a non-normal
applied force breaks the cylindrical symmetry), see Landau and Lifshitz [1986, Eqs. (8.18)].
Bibliographic Note
627

written in the 1950s and revised in a third edition shortly before Lifshitz’s death. This
isamongthemostreadabletextbooksthatLandauandLifshitzwroteandisstillwidely
used by physicists in the early twenty-ﬁrst century.
Some signiﬁcant new insights, both mathematical and physical, have been de-
veloped in recent decades, for example, catastrophe theory and its applications to
bifurcations and stability, practical insights from numerical simulations, and practical
applications based on new materials (e.g., carbon nanotubes). For a modern treat-
ment that deals with these and much else from an engineering viewpoint, we strongly
recommend Ugural and Fenster (2012). For a fairly brief and elementary modern
treatment, werecommendLautrup(2005, PartIII).Othergoodtextsthatfocuspartic-
ularly on solving the equations for elastostatic equilibrium include Southwell (1941),
Timoshenko and Goodier (1970), Gladwell (1980), Johnson (1985), Boresi and Chong
(1999), and Slaughter (2002); see also the discussion and references in Box 11.3.
628
Chapter 11. Elastostatics

12
CHAPTER TWELVE
Elastodynamics
. . . logarithmic plots are a device of the devil.
CHARLES RICHTER (1980)
12.1
12.1 Overview
Inthepreviouschapterweconsideredelastostaticequilibria, inwhichtheforcesacting
on elements of an elastic solid were balanced, so the solid remained at rest. When this
equilibrium is disturbed, the solid will undergo accelerations. This is the subject of
this chapter—elastodynamics.
In Sec. 12.2, we derive the equations of motion for elastic media, paying partic-
ular attention to the underlying conservation laws and focusing especially on elasto-
dynamic waves. We show that there are two distinct wave modes that propagate in
a uniform, isotropic solid—longitudinal waves and shear waves—and both are non-
dispersive (their phase speeds are independent of frequency).
A major use of elastodynamics is in structural engineering, where one encounters
vibrations (usually standing waves) on the beams that support buildings and bridges.
In Sec. 12.3, we discuss the types of waves that propagate on bars, rods, and beams
and ﬁnd that the boundary conditions at the free transverse surfaces make the waves
dispersive. We also return brieﬂy to the problem of bifurcation of equilibria (treated in
Sec. 11.6) and show how, as the parameters controlling an equilibrium are changed so
it passes through a bifurcation point, the equilibrium becomes unstable; the instability
drives the system toward the new, stable equilibrium state.
A second application of elastodynamics is to seismology (Sec. 12.4). Earth is
mostly a solid body through which waves can propagate. The waves can be excited
naturally by earthquakes or artiﬁcially using human-made explosions. Understanding
how waves propagate through Earth is important for locating the sources of earth-
quakes, for diagnosing the nature of an explosion (was it an illicit nuclear bomb test?),
and for analyzing the structure of Earth. We brieﬂy describe some of the wave modes
that propagate through Earth and some of the inferences about Earth’s structure that
have been drawn from studying their propagation. In the process, we gain some ex-
perience in applying the tools of geometric optics to new types of waves, and we learn
629

BOX 12.1.
READERS’ GUIDE
.
This chapter is a companion to Chap. 11 (Elastostatics) and relies
heavily on it.
.
This chapter also relies rather heavily on geometric-optics concepts
and formalism, as developed in Secs. 7.2 and 7.3, especially phase
velocity, group velocity, dispersion relation, rays, and the propagation
of waves and information and energy along them, the role of the
dispersion relation as a hamiltonian for the rays, and ray tracing.
.
The discussion of continuum-mechanics wave equations in Box
12.2 underlies this book’s treatment of waves in ﬂuids (Chap. 16),
especially in plasmas (Part VI) and in general relativity (Chap. 27).
.
The experience that the reader gains in this chapter with waves in
solids will be useful when we encounter much more complicated
waves in plasmas in Part VI.
.
No other portions of this chapter are important for subsequent parts
of this book.
how rich can be the Green’s function for elastodynamic waves, even when the me-
dium is as simple as a homogeneous half-space. We brieﬂy discuss how the methods
by which geophysicists probe Earth’s structure using seismic waves also ﬁnd appli-
cation in ultrasonic technology: imaging solid structures and the human body using
high-frequency sound waves.
Finally, in Sec. 12.5, we return to physics to consider the quantum theory of
elastodynamic waves. We compare the classical theory with the quantum theory,
specializing to quantized vibrations in an elastic solid: phonons.
12.2
12.2 Basic Equations of Elastodynamics; Waves in a Homogeneous Medium
Inthissection, wederiveavectorialequationthatgovernsthedynamicaldisplacement
ξ(x, t) of a dynamically disturbed elastic medium. We then consider monochromatic
planewavesolutionsandexplorewavepropagationthroughinhomogeneousmediain
the geometric optics limit. This general approach to wave propagation in continuum
mechanics will be taken up again in Chap. 16 for waves in ﬂuids, Part VI for waves in
plasmas, and Chap. 27 for general relativistic gravitational waves. We conclude this
section with a discussion of the energy density and energy ﬂux of these waves.
12.2.1
12.2.1 Equation of Motion for a Strained Elastic Medium
In Chap. 11, we learned that when an elastic medium undergoes a displacement ξ(x),
it builds up a strain Sij = 1
2(ξi;j + ξj;i), which in turn produces an internal stress
630
Chapter 12. Elastodynamics

T = −Kg −2μ. Here  ≡∇. ξ is the expansion, and  ≡(the trace-free part of
S) is the shear; see Eqs. (11.4) and (11.18). The stress T produces an elastic force per
unit volume
f = −∇. T =

K + 1
3μ

∇(∇. ξ) + μ∇2ξ
(12.1)
[Eq. (11.30)], where K and μ are the bulk and shear moduli.
In Chap. 11, we restricted ourselves to elastic media that are in elastostatic equilib-
rium, so they are static. This equilibrium requires that the net force per unit volume
acting on the medium vanish. If the only force is elastic, then f must vanish. If the
pull of gravity is also signiﬁcant, then f + ρg vanishes, where ρ is the medium’s mass
density and g the acceleration of gravity.
In this chapter, we focus on dynamical situations, in which an unbalanced force
per unit volume causes the medium to move—with the motion taking the form of an
elastodynamic wave. For simplicity, we assume unless otherwise stated that the only
signiﬁcant force is elastic (i.e., the gravitational force is negligible by comparison). In
Ex. 12.1, we show that this is the case for elastodynamic waves in most media on Earth
when the wave frequency ω/(2π) is higher than about 0.001 Hz (which is usually the
case in practice). Stated more precisely, in a homogeneous medium we can ignore
when gravity can be
ignored
the gravitational force when the elastodynamic wave’s angular frequency ω is much
larger than g/C, where g is the acceleration of gravity, and C is the wave’s propagation
speed.
Consider, then, a dynamical, strained medium with elastic force per unit volume
(12.1) and no other signiﬁcant force (negligible gravity), and with velocity
v = ∂ξ
∂t .
(12.2a)
The law of momentum conservation states that the force per unit volume f, if nonzero,
must produce a rate of change of momentum per unit volume ρv according to the
equation1
elastodynamic momentum
conservation
∂(ρv)
∂t
= f = −∇. T =

K + 1
3μ

∇(∇. ξ) + μ∇2ξ.
(12.2b)
Notice that, when rewritten in the form
∂(ρv)
∂t
+ ∇. T = 0,
(12.2b′)
1.
In Sec. 13.5, we learn that the motion of the medium produces a stress ρv ⊗v that must be included
in this equation if the velocities are large. However, this subtle dynamical stress is always negligible in
elastodynamic waves, because the displacements and hence velocities v are tiny and ρv ⊗v is second
order in the displacement. For this reason, we delay studying this subtle nonlinear effect until Chap. 13.
A similar remark applies to Eq. (12.2c). In general the conservation laws of continuum mechanics are
nonlinear, as we discuss in Box 12.2.
12.2 Basic Equations of Elastodynamics; Waves in a Homogeneous Medium
631

this is the version of the law of momentum conservation discussed in Chap. 1 [Eq.
(1.36)]. It has the standard form for a conservation law (time derivative of density of
something plus divergence of ﬂux of that something vanishes; see end of Sec. 1.8); ρv
is the density of momentum, and the stress tensor T is by deﬁnition the ﬂux of mo-
mentum. Equations (12.2a) and (12.2b), together with the law of mass conservation
[the obvious analog of Eqs. (1.30) for conservation of charge and particle number],
mass conservation
∂ρ
∂t + ∇. (ρv) = 0,
(12.2c)
are a complete set of equations for the evolution of the displacement ξ(x, t), the
velocity v(x, t), and the density ρ(x, t).
To derive a linear wave equation, we must ﬁnd some small parameter in which to
expand. The obvious choice in elastodynamics is the magnitude of the components
of the strain Sij = 1
2(ξi;j + ξj;i), which are less than about 10−3 so as to remain below
the proportionality limit (i.e., to remain in the realm where stress is proportional
to strain; Sec. 11.3.2). Equally well, we can regard the displacement ξ itself as our
small parameter (or more precisely, ξ/-λ, the magnitude of ξ divided by the reduced
wavelength of its perturbations).
If the medium’s equilibrium state were homogeneous, the linearization would be
trivial. However, we wish to be able to treat perturbations of inhomogeneous equi-
libria, such as seismic waves in Earth, or perturbations of slowly changing equilib-
ria, such as vibrations of a pipe or mirror that is gradually changing temperature.
In most practical situations the lengthscale L and timescale T on which the me-
dium’s equilibrium properties (ρ, K, μ) vary are extremely large compared to the
lengthscale and timescale of the dynamical perturbations [their reduced wavelength
-λ = wavelength/(2π) and 1/ω = period/(2π)]. This permits us to perform a two-
lengthscaleexpansion(liketheonethatunderliesgeometricoptics; Sec.7.3)alongside
our small-strain expansion.
When analyzing a dynamical perturbation of an equilibrium state, we use ξ(x, t)
to denote the dynamical displacement (i.e., we omit from it the equilibrium’s static dis-
placement, and similarly we omit from S the equilibrium strain). We write the density
density perturbation
as ρ + δρ, where ρ(x) is the equilibrium density distribution, and δρ(x, t) is the dy-
namical density perturbation, which is ﬁrst order in the dynamical displacement ξ.
Inserting these into the equation of mass conservation (12.2c), we obtain ∂δρ/∂t +
∇. [(ρ + δρ)v]= 0. Because v = ∂ξ/∂t is ﬁrst order, the term (δρ)v is second order
and can be dropped, resulting in the linearized equation ∂δρ/∂t + ∇. (ρv) = 0. Be-
cause ρ varies on a much longer lengthscale than does v (L versus -λ), we can pull
ρ out of the derivative. Setting v = ∂ξ/∂t and interchanging the time derivative and
divergence, we then obtain ∂δρ/∂t + ρ∂(∇. ξ)/∂t = 0. Noting that ρ varies on a
632
Chapter 12. Elastodynamics

BOX 12.2.
WAVE EQUATIONS IN CONTINUUM MECHANICS
Here we make an investment for future chapters by considering wave equations
in some generality. Most wave equations arise as approximations to the full set
of equations that govern a dynamical physical system. It is usually possible to
arrange those full equations as a set of ﬁrst-order partial differential equations
that describe the dynamical evolution of a set of n physical quantities, VA,
with A = 1, 2, . . . , n:
∂VA
∂t
+ FA(VB) = 0.
(1)
[For elastodynamics there are n = 7 quantities VA: {ρ, ρvx, ρvy, ρvz, ξx,
ξy, ξz} (in Cartesian coordinates); and the seven equations (1) are mass
conservation, momentum conservation, and ∂ξj/∂t = vj; Eqs. (12.2).]
Most dynamical systems are intrinsically nonlinear (Maxwell’s equations
in a vacuum being a conspicuous exception), and it is usually quite hard
to ﬁnd nonlinear solutions. However, it is generally possible to make a
perturbation expansion in some small physical quantity about a time-
independent equilibrium and retain only those terms that are linear in this
quantity. We then have a set of n linear partial differential equations that are
much easier to solve than the nonlinear ones—and that usually turn out to
have the character of wave equations (i.e., to be hyperbolic; see Arfken, Weber,
and Harris, 2013). Of course, the solutions will only be a good approximation
for small-amplitude waves. [In elastodynamics, we justify linearization by
requiring that the strains be below the proportionality limit and linearize in
the strain or displacement of the dynamical perturbation. The resulting linear
wave equation is ρ∂2ξ/∂t2 = (K + 1
3μ)∇(∇. ξ) + μ∇2ξ; Eq. (12.4b).]
BOUNDARY CONDITIONS
In some problems (e.g., determining the normal modes of vibration of a
building during an earthquake, or analyzing the sound from a violin or the
vibrations of a ﬁnite-length rod), the boundary conditions are intricate and
have to be incorporated as well as possible to have any hope of modeling
the problem. The situation is rather similar to that familiar from elementary
quantum mechanics. The waves are often localized in some region of space,
like bound states, in such a way that the eigenfrequencies are discrete (e.g.,
standing-wave modes of a plucked string). In other problems the volume in
which the wave propagates is essentially inﬁnite (e.g., waves on the surface
of the ocean, or seismic waves propagating through Earth), as happens with
(continued)
12.2 Basic Equations of Elastodynamics; Waves in a Homogeneous Medium
633

BOX 12.2.
(continued)
unbound quantum states. Then the only boundary condition is essentially
that the wave amplitude remain ﬁnite at large distances. In this case, the wave
spectrum is usually continuous.
GEOMETRIC-OPTICS LIMIT AND DISPERSION RELATIONS
The solutions to the wave equation will reﬂect the properties of the medium
through which the wave is propagating, as well as its boundaries. If the
medium and boundaries have a ﬁnite number of discontinuities but are
otherwise smoothly varying, there is a simple limiting case: waves of short
enough wavelength and high enough frequency can be analyzed in the
geometric-optics approximation (Chap. 7).
The key to geometric optics is the dispersion relation, which (as we
learned in Sec. 7.3) acts as a hamiltonian for the propagation. Recall from
Chap. 7 that although the medium may actually be inhomogeneous and
might even be changing with time, when deriving the dispersion relation,
we can approximate it as precisely homogeneous and time independent
and can resolve the waves into plane-wave modes [i.e., modes in which the
perturbations vary ∝exp i(k . x −ωt)]. Here k is the wave vector and ω is
the angular frequency. This allows us to remove all the temporal and spatial
derivatives and converts our set of partial differential equations into a set of
homogeneous, linear algebraic equations. When we do this, we say that our
normal modes are local. If, instead, we were to go to the trouble of solving the
partial differential wave equation with its attendant boundary conditions, the
modes would be referred to as global.
The linear algebraic equations for a local problem can be written in the
form MABVB = 0, where VA is the vector of n dependent variables, and the
elements MAB of the n × n matrix ||MAB|| depend on k and ω as well as
on parameters pα that describe the local conditions of the medium. [See,
e.g., Eq. (12.6).] This set of equations can be solved in the usual manner
by requiring that the determinant of ∥MAB∥vanish. Carrying through this
procedure yields a polynomial, usually of nth order, for ω(k, pα). This
polynomial is the dispersion relation. It can be solved (analytically in simple
cases and numerically in general) to yield a number of complex values for
ω (the eigenfrequencies), with k regarded as real. (Some problems involve
complex k and real ω, but for concreteness, we shall take k to be real.)
Armed with the complex eigenfrequencies, we can solve for the associated
eigenvectors VA. The eigenfrequencies and eigenvectors fully characterize the
(continued)
634
Chapter 12. Elastodynamics

BOX 12.2.
(continued)
solution of the local problem and can be used to solve for the waves’ temporal
evolution from some given initial conditions in the usual manner. (As we shall
see several times, especially when we discuss Landau damping in Sec. 22.3,
there are some subtleties that can arise.)
What does a complex value of the angular frequency ω mean? We have
posited that all small quantities vary ∝exp[i(k . x −ωt)]. If ω has a positive
imaginary part, then the small perturbation quantities will grow exponentially
with time. Conversely, if it has a negative imaginary part, they will decay. Now,
polynomial equations with real coefﬁcients have complex conjugate solutions.
Therefore, if there is a decaying mode there must also be a growing mode.
Growing modes correspond to instability, a topic that we shall encounter often.
timescale T long compared to the 1/ω of ξ and δρ, we can integrate this to obtain the
linear relation
δρ
ρ = −∇. ξ.
(12.3)
This linearized equation for the fractional perturbation of density could equally
well have been derived by considering a small volume V of the medium that con-
tains mass M = ρV and noting that the dynamical perturbations lead to a volume
change δV/V =  = ∇. ξ [Eq. (11.7)]. Then conservation of mass requires 0 =
δM = δ(ρV ) = V δρ + ρδV = V δρ + ρV ∇. ξ, which implies δρ/ρ = −∇. ξ. This
is the same as Eq. (12.3).
The equation of momentum conservation (12.2b) can be handled similarly. By
setting ρ →ρ(x) + δρ(x, t), then linearizing (i.e., dropping the δρ v term) and
pulling the slowly varying ρ(x) out from the time derivative, we convert ∂(ρv)/∂t
into ρ∂v/∂t = ρ∂2ξ/∂t2. Inserting this into Eq. (12.2b), we obtain the linear wave
equation
ρ ∂2ξ
∂t2 = −∇. Tel,
(12.4a)
where Tel is the elastic contribution to the stress tensor. Expanding it, we obtain
elastodynamic wave
equation
ρ ∂2ξ
∂t2 =

K + 1
3μ

∇(∇. ξ) + μ∇2ξ.
(12.4b)
In this equation, terms involving a derivative of K or μ have been omitted, because
the two-lengthscale assumption L ≫-λ makes them negligible compared to the terms
we have kept.
12.2 Basic Equations of Elastodynamics; Waves in a Homogeneous Medium
635

Equation (12.4b) is the ﬁrst of many wave equations we shall encounter in elasto-
dynamics, ﬂuid mechanics, plasma physics, and general relativity.
12.2.2
12.2.2 Elastodynamic Waves
Continuingtofollowourgeneralprocedureforderivingandanalyzingwaveequations
asoutlinedinBox12.2, wenextderivedispersionrelationsfortwotypesofwaves(lon-
gitudinal and transverse) that are jointly incorporated into the general elastodynamic
wave equation (12.4b).
Recall from Sec. 7.3.1 that, although a dispersion relation can be used as a hamilto-
nian for computing wave propagation through an inhomogeneous medium, one can
derive the dispersion relation most easily by specializing to monochromatic plane
waves propagating through a medium that is precisely homogeneous. Therefore, we
seek a plane-wave solution, that is, a solution of the form
ξ(x, t) ∝ei(k.x−ωt),
(12.5)
to the wave equation (12.4b) with ρ, K, and μ regarded as homogeneous (constant).
(To deal with more complicated perturbations of a homogeneous medium, we can
think of this wave as being an individual Fourier component and linearly superpose
many such waves as a Fourier integral.) Since our wave is planar and monochromatic,
we can remove the derivatives in Eq. (12.4b) by making the substitutions ∇→ik
and ∂/∂t →−iω (the ﬁrst of which implies ∇2 →−k2, ∇. →ik., ∇× →ik×).
We thereby reduce the partial differential equation (12.4b) to a vectorial algebraic
equation:
elastodynamic
eigenequation for plane
waves
ρω2ξ =

K + 1
3μ

k(k . ξ) + μk2ξ.
(12.6)
[This reduction is only possible because the medium is uniform, or in the geometric-
optics limit of near uniformity; otherwise, we must solve the second-order partial
differential equation (12.4b).]
How do we solve this equation? The sure way is to write it as a 3 × 3 matrix
equation Mijξj = 0 for the vector ξ and set the determinant of Mij to zero (Box
12.2 and Ex. 12.3). This is not hard for small or sparse matrices. However, some
wave equations are more complicated, and it often pays to think about the waves in a
geometric, coordinate-independent way before resorting to brute force.
The quantity that oscillates in the elastodynamic waves of Eq. (12.6) is the vector
ﬁeld ξ. The nature of its oscillations is inﬂuenced by the scalar constants ρ, μ, K,
and ω and by just one quantity that has directionality: the constant vector k. It seems
reasonable to expect the description (12.6) of the oscillations to simplify, then, if we
resolve the oscillations into a “longitudinal” component (or “mode”) along k and a
“transverse” component (or “mode”) perpendicular to k, as shown in Fig. 12.1:
decomposition into
longitudinal and
transverse modes
ξ = ξL + ξT ,
ξL = ξLˆk,
ξT . ˆk = 0.
(12.7a)
636
Chapter 12. Elastodynamics

(a)
(b)
k
k
ξξ
ξ
FIGURE 12.1 Displacements in an isotropic, elastic solid, perturbed by
(a) a longitudinal mode and (b) a transverse mode.
Here ˆk ≡k/k is the unit vector along the propagation direction. It is easy to see
that the longitudinal mode ξL has nonzero expansion  ≡∇. ξL ̸= 0 but vanishing
rotation φ = 1
2∇× ξL = 0. It can therefore be written as the gradient of a scalar
potential:
ξL = ∇ψ.
(12.7b)
By contrast, the transverse mode has zero expansion but nonzero rotation and can
thus be written as the curl of a vector potential:
ξT = ∇× A;
(12.7c)
cf. Ex. 12.2.
12.2.3
12.2.3 Longitudinal Sound Waves
For the longitudinal mode the algebraic wave equation (12.6) reduces to the following
simple relation [as one can easily see by inserting ξ ≡ξL = ξLˆk into Eq. (12.6), or,
alternatively, by taking the divergence of Eq. (12.6), which is equivalent to taking the
scalar product with k]:
longitudinal dispersion
relation
ω2 = K + 4
3μ
ρ
k2;
or
ω = (k) =
*
K + 4
3μ
ρ
+1/2
k.
(12.8)
Here k = |k] is the wave number (the magnitude of k). This relation between ω and
k is the longitudinal mode’s dispersion relation.
From the geometric-optics analysis in Sec. 7.3 we infer that if K, μ, and ρ vary
spatially on an inhomogeneity lengthscale L large compared to 1/k = -λ, and
vary temporally on a timescale T large compared to 1/ω, then the dispersion re-
lation (12.8)—with  now depending on x and t through K, μ, and ρ—serves as a
12.2 Basic Equations of Elastodynamics; Waves in a Homogeneous Medium
637

hamiltonian for the wave propagation. In Sec. 12.4 and Fig. 12.5 below we use this
hamiltonian to deduce details of the propagation of seismic waves through Earth’s
inhomogeneous interior.
As discussed in great detail in Sec. 7.2, associated with any wave mode is its phase
velocity Vph = (ω/k)ˆk and its phase speed Vph = ω/k. The dispersion relation (12.8)
implies that for longitudinal elastodynamic modes, the phase speed is
longitudinal wave speed
CL = ω
k =
*
K + 4
3μ
ρ
+1/2
.
(12.9a)
As Eq. (12.9a) does not depend on the wave number k ≡|k|, the mode is non-
dispersive. As it does not depend on the direction ˆk of propagation through the
medium, the phase speed is also isotropic, naturally enough, and the group velocity
Vgj = ∂/∂kj is equal to the phase velocity:
Vg = Vph = CLˆk.
(12.9b)
Elastodynamic longitudinal modes are similar to sound waves in a ﬂuid. However,
in a ﬂuid, as we can infer from Eq. (16.48), the sound waves travel with phase speed
Vph = (K/ρ)1/2 [thelimitofEq.(12.9a)whentheshearmodulusvanishes].2 Thisﬂuid
sound speed is lower than the CL of a solid with the same bulk modulus, because
the longitudinal displacement necessarily entails shear (note that in Fig. 12.1a the
motions are not an isotropic expansion), and in a solid there is a restoring shear stress
(proportional to μ) that is absent in a ﬂuid.
Because the longitudinal phase velocity is independent of frequency, we can write
down general planar longitudinal-wave solutions to the elastodynamic wave equation
(12.4b) in the following form:
general longitudinal plane
wave
ξ = ξLˆk = F(ˆk . x −CLt)ˆk,
(12.10)
where F(x) is an arbitrary function. This describes a wave propagating in the (arbi-
trary) direction ˆk with an arbitrary proﬁle determined by the function F.
12.2.4
12.2.4 Transverse Shear Waves
To derive the dispersion relation for a transverse wave we can simply make use of the
transversality condition k . ξT = 0 in Eq. (12.6); or, equally well, we can take the curl
of Eq. (12.6) (multiply it by ik×), thereby projecting out the transverse piece, since
2.
Equation (16.48) below gives the ﬂuid sound speed as C =

(∂P/∂ρ)s (i.e., the square root of the
derivative of the ﬂuid pressure with respect to density at ﬁxed entropy). In the language of elasticity
theory, the fractional change of density is related to the expansion  by δρ/ρ = − [Eq. (12.3)],
and the accompanying change of pressure is δP = −K [sentence preceding Eq. (11.18)], so δP =
K(δρ/ρ). Therefore, the ﬂuid mechanical sound speed is C = √δP/δρ = √K/ρ [see passage following
Eq. (12.43)].
638
Chapter 12. Elastodynamics

the longitudinal part of ξ has vanishing curl. The result is
transverse dispersion
relation
ω2 = μ
ρ k2,
or
ω = (k) ≡
μ
ρ
1/2
k.
(12.11)
This dispersion relation ω = (k) serves as a geometric-optics hamiltonian for wave
propagation when μ and ρ vary slowly with x and/or t. It also implies that the trans-
verse waves propagate with a phase speed CT and phase and group velocities given by
transverse wave speed
CT =
μ
ρ
1/2
;
(12.12a)
Vph = Vg = CT ˆk.
(12.12b)
As K > 0, the shear wave speed CT is always less than the speed CL of longitudinal
waves [Eq. (12.9a)].
These transverse modes are known as shear waves, because they are driven by the
shear stress; cf. Fig. 12.1b. There is no expansion and therefore no change in volume
associated with shear waves. They do not exist in ﬂuids, but they are close analogs of
the transverse vibrations of a string.
Longitudinal waves can be thought of as scalar waves, since they are fully describ-
able by a single component ξL of the displacement ξ: that along ˆk. Shear waves, by
contrast, are inherently vectorial. Their displacement ξT can point in any direction or-
thogonal to k. Since the directions orthogonal to k form a 2-dimensional space, once
polarization
k has been chosen, there are two independent states of polarization for the shear wave.
These two polarization states, together with the single one for the scalar, longitudinal
wave, make up the three independent degrees of freedom in the displacement ξ.
In Ex. 12.3 we deduce these properties of ξ using matrix techniques.
EXERCISES
Exercise 12.1 **Problem: Inﬂuence of Gravity on Wave Speed
Modify the wave equation (12.4b) to include the effect of gravity. Assume that the
medium is homogeneous and the gravitational ﬁeld is constant. By comparing the
orders of magnitude of the terms in the wave equation, verify that the gravitational
terms can be ignored for high-enough frequency elastodynamic modes: ω ≫g/CL,T .
For wave speeds ∼3 km s−1, this gives ω/(2π) ≫0.0005 Hz. Seismic waves are mostly
in this regime.
Exercise 12.2 Example: Scalar and Vector Potentials for Elastic Waves
in a Homogeneous Solid
Just as in electromagnetic theory, it is sometimes useful to write the displacement ξ
in terms of scalar and vector potentials:
ξ = ∇ψ + ∇× A.
(12.13)
12.2 Basic Equations of Elastodynamics; Waves in a Homogeneous Medium
639

(The vector potential A is, as usual, only deﬁned up to a gauge transformation,
A →A + ∇ϕ, where ϕ is an arbitrary scalar ﬁeld.) By inserting Eq. (12.13) into
the general elastodynamic wave equation (12.4b), show that the scalar and vector
potentials satisfy the following wave equations in a homogeneous solid:
∂2ψ
∂t2 = C2
L∇2ψ,
∂2A
∂t2 = C2
T ∇2A.
(12.14)
Thus, the scalar potential ψ generates longitudinal waves, while the vector potential
A generates transverse waves.
Exercise 12.3 Example: Solving the Algebraic Wave Equation by Matrix Techniques
By using the matrix techniques discussed in the next-to-the-last paragraph of Box
12.2, deduce that the general solution to the algebraic wave equation (12.6) is the sum
of a longitudinal mode with the properties deduced in Sec. 12.2.3 and two transverse
modes with the properties deduced in Sec. 12.2.4. [Note: This matrix technique is
necessary and powerful when the algebraic dispersion relation is complicated, such
as for plasma waves; Secs. 21.4.1 and 21.5.1. Elastodynamic waves are simple enough
that we did not need this matrix technique in the text.] Speciﬁcally, do the following.
(a) Rewrite the algebraic wave equation in the matrix form Mijξj = 0, obtaining
thereby an explicit form for the matrix ||Mij|| in terms of ρ, K, μ, ω and the
components of k.
(b) This matrix equation from part (a) has a solution if and only if the determinant of
the matrix ||Mij|| vanishes. (Why?) Show that det||Mij|| = 0 is a cubic equation
for ω2 in terms of k2, and that one root of this cubic equation is ω = CLk, while the
other two roots are ω = CT k with CL and CT given by Eqs. (12.9a) and (12.12a).
(c) Orient Cartesian axes so that k points in the z direction. Then show that, when
ω = CLk, the solution to Mijξj = 0 is a longitudinal wave (i.e., a wave with ξ
pointing in the z direction, the same direction as k).
(d) Show that, when ω = CT k, there are two linearly independent solutions to
Mijξj = 0, one with ξ pointing in the x direction (transverse to k) and the other
in the y direction (also transverse to k).
12.2.5
12.2.5 Energy of Elastodynamic Waves
Elastodynamic waves transport energy, just like waves on a string. The waves’ kinetic
energy density is obviously 1
2ρv2 = 1
2ρ˙ξ2, where the dot means ∂/∂t. The elastic
energy density is given by Eq. (11.24), so the total energy density is
U = 1
2ρ˙ξ2 + 1
2K2 + μijij.
(12.15a)
In Ex. 12.4 we show that (as one might expect) the elastodynamic wave equation
(12.4b) can be derived from an action whose lagrangian density is the kinetic energy
640
Chapter 12. Elastodynamics

density minus the elastic energy density. We also show that associated with the waves
is an energy ﬂux F(not to be confused with a force for which we use the same notation)
given by
energy density and ﬂux
for general elastodynamic
wave in isotropic medium
Fi = −K˙ξi −2μij ˙ξj = Tij ˙ξj.
(12.15b)
As the waves propagate, energy sloshes back and forth between the kinetic and the
elastic parts, with the time-averaged kinetic energy being equal to the time-averaged
elastic energy (equipartition of energy). For the planar, monochromatic, longitudinal
mode, the time-averaged energy density and ﬂux are
energy density and ﬂux
for plane, monochromatic
elastodynamic wave
UL = ρ⟨˙ξ2
L⟩,
FL = ULCLˆk,
(12.16)
where ⟨.⟩denotes an average over one period or wavelength of the wave. Similarly, for
the planar, monochromatic, transverse mode, the time-averaged density and ﬂux of
energy are
UT = ρ⟨˙ξ2
T ⟩, FT = UT CT ˆk
(12.17)
(Ex. 12.4). Thus, elastodynamic waves transport energy at the same speed CL,T as
the waves propagate, and in the same direction ˆk. This is the same behavior as
electromagnetic waves in vacuum, whose Poynting ﬂux and energy density are related
by FEM = UEMcˆk with c the speed of light, and the same as all forms of dispersion-
free scalar waves [e.g., sound waves in a medium; cf. Eq. (7.31)]. Actually, this is the
dispersion-free limit of the more general result that the energy of any wave, in the
geometric-optics limit, is transported with the wave’s group velocity Vg; see Sec. 7.2.2.
EXERCISES
Exercise 12.4 Example: Lagrangian and Energy for Elastodynamic Waves
Derive the energy-density, energy-ﬂux, and lagrangian properties of elastodynamic
waves given in Sec. 12.2.5. Speciﬁcally, do the following.
(a) For ease of calculation (and for greater generality), consider an elastodynamic
wave in a possibly anisotropic medium, for which
Tij = −Yijklξk;l,
(12.18)
with Yijkl the tensorial modulus of elasticity, which is symmetric under inter-
change (i) of the ﬁrst two indices ij, (ii) of the last two indices kl, and (iii) of the
ﬁrst pair ij with the last pair kl [Eq. (11.17) and associated discussion]. Show that
for an isotropic medium
Yijkl =

K −2
3μ

gijgkl + μ(gikgjl + gilgjk).
(12.19)
(Recall that in the orthonormal bases to which we have conﬁned ourselves, the
components of the metric are gij = δij, i.e., the Kronecker delta.)
12.2 Basic Equations of Elastodynamics; Waves in a Homogeneous Medium
641

(b) For these waves the elastic energy density is 1
2Yijklξi;jξk;l [Eq. (11.25)]. Show that
the kinetic energy density minus the elastic energy density,
L = 1
2ρ ˙ξi ˙ξi −1
2Yijklξi;jξk;l,
(12.20)
is a lagrangian density for the waves; that is, show that the vanishing of its
variational derivative δL/δξj ≡∂L/∂ξj −(∂/∂t)(∂L/∂˙ξj) = 0 is equivalent to
the elastodynamic equations ρ¨ξ = −∇. T.
(c) The waves’ energy density and ﬂux can be constructed by the vector-wave analog
of the canonical procedure of Eq. (7.36c):
U = ∂L
∂˙ξi
˙ξi −L = 1
2ρ ˙ξi ˙ξi + 1
2Yijklξi;jξk;l,
Fj = ∂L
∂ξi;j
˙ξi = −Yijkl ˙ξiξk;l.
(12.21)
Verify that these density and ﬂux values satisfy the energy conservation law,
∂U/∂t + ∇. F = 0. Using Eq. (12.19), verify that for an isotropic medium, ex-
pressions (12.21) for the energy density and ﬂux become the expressions (12.15)
given in the text.
(d) Show that in general (for an arbitrary mixture of wave modes), the time av-
erage of the total kinetic energy in some huge volume is equal to that of the
total elastic energy. Show further that for an individual longitudinal or trans-
verse, planar, monochromatic mode, the time-averaged kinetic energy density
and time-averaged elastic energy density are both independent of spatial loca-
tion. Combining these results, infer that for a single mode, the time-averaged
kinetic and elastic energy densities are equal, and therefore the time-averaged to-
tal energy density is equal to twice the time-averaged kinetic energy density. Show
that this total time-averaged energy density is given by the ﬁrst of Eqs. (12.16)
and (12.17).
(e) Show that the time average of the energy ﬂux (12.15b) for the longitudinal and
transverse modes is given by the second of Eqs. (12.16) and (12.17), so the energy
propagates with the same speed and direction as the waves themselves.
12.3
12.3 Waves in Rods, Strings, and Beams
Before exploring applications (Sec. 12.4) of the longitudinal and transverse waves just
described, we discuss how the wave equations and wave speeds are modiﬁed when
the medium through which they propagate is bounded. Despite this situation being
formally “global” in the sense of Box 12.2, elementary considerations enable us to
derive the relevant dispersion relations without much effort.
642
Chapter 12. Elastodynamics

12.3.1
12.3.1 Compression Waves in a Rod
First consider a longitudinal wave propagating along a light (negligible gravity), thin,
unstressed rod. We shall call this a compression wave.Introduce a Cartesian coordinate
system with the x-axis parallel to the rod. When there is a small displacement ξx
independent of y and z, the restoring stress is given by Txx = −E∂ξx/∂x, where E
is Young’s modulus [cf. Eq. (11.37)]. Hence the restoring force density f = −∇. T is
fx = E∂2ξx/∂x2. The wave equation then becomes
∂2ξx
∂t2 =
E
ρ
 ∂2ξx
∂x2 ,
(12.22)
and so the sound speed for compression waves in a long straight rod is
speed of compression
wave in a rod
CC =
E
ρ
 1
2
.
(12.23)
Referring to Table 11.1 we see that a typical value of Young’s modulus in a solid is
∼100 GPa. If we adopt a typical density of ∼3 × 103 kg m−3, then we estimate the
compressional sound speed to be ∼5 km s−1. This is roughly 15times the sound speed
in air.
As this compressional wave propagates, in regions where the rod is compressed
longitudinally, it bulges laterally by an amount given by Poisson’s ratio; where it
is expanded longitudinally, the rod shrinks laterally. By contrast, for a longitudinal
wave in a homogeneous medium, transverse forces do not cause lateral bulging and
shrinking. This accounts for the different propagation speeds, CC ̸= CL; see Ex. 12.6.
12.3.2
12.3.2 Torsion Waves in a Rod
Next consider a rod with circular cross section of radius a, subjected to a twisting
force (Fig. 12.2). Let us introduce an angular displacement φ ≡ϕ(x) that depends
on distance x down the rod. The only nonzero component of the displacement vector
is ξφ = ϖϕ(x), where ϖ =

y2 + z2 is the cylindrical radius. We can calculate the
total torque, exerted by the portion of the rod to the left of x on the portion to the right,
by integating over a circular cross section. For small twists, there is no expansion, and
the only components of the shear tensor are
φx = xφ = 1
2ξφ,x = ϖ
2
∂ϕ
∂x .
(12.24)
The torque contributed by an annular ring of radius ϖ and thickness dϖ is ϖ . Tφx .
2πϖdϖ, and we substitute Tφx = −2μφx to obtain the total torque of the rod to
the left of x on that to the right:
N = −
 a
0
2πμϖ 3dϖ ∂ϕ
∂x = −μ
ρ I ∂ϕ
∂x ,
where
I = π
2 ρa4
(12.25)
is the moment of inertia per unit length.
12.3 Waves in Rods, Strings, and Beams
643

ϕ
x
x
ϖ
dϖ
a
FIGURE 12.2 When a rod with circular cross section is twisted, there will be a
restoring torque.
Equating the net torque on a segment with length x to the rate of change of its
angular momentum, we obtain
−∂N
∂x x = I ∂2ϕ
∂t2 x,
(12.26)
which, using Eq. (12.25), becomes the wave equation for torsional waves:
μ
ρ
 ∂2ϕ
∂x2 = ∂2ϕ
∂t2 .
(12.27)
The speed of torsional waves is thus
speed of torsion wave in a
rod
CT =
μ
ρ
 1
2
.
(12.28)
Notethatthisisthesamespeedasthatoftransverseshearwavesinauniformmedium.
This might have been anticipated, as there is no change in volume in a torsional
oscillation and so only the shear stress acts to produce a restoring force.
12.3.3
12.3.3 Waves on Strings
This example is surely all too familiar. When a string under a tensile force T (not force
per unit area) is plucked, there will be a restoring force proportional to the curvature
of the string. If ξz ≡η is the transverse displacement (in the same notation as we used
for rods in Secs. 11.5 and 11.6), then the wave equation will be
T ∂2η
∂x2 =  ∂2η
∂t2 ,
(12.29)
644
Chapter 12. Elastodynamics

where  is the mass per unit length. The wave speed is thus
speed of wave in a string
under tension
CS =
T
 
1/2
.
(12.30)
12.3.4
12.3.4 Flexural Waves on a Beam
Now consider the small-amplitude, transverse displacement of a horizontal rod or
beam that can be ﬂexed. In Sec. 11.5 we showed that such a ﬂexural displacement
produces a net elastic restoring force per unit length given by D∂4η/∂x4, and we
considered a situation where that force was balanced by the beam’s weight per unit
length, W =  g [Eq. (11.45)]. Here
D = 1
12Ewh3
(12.31)
is the ﬂexural rigidity [Eq. (11.41b)], h is the beam’s thickness in the direction of
bend, w is its width, η = ξz is the transverse displacement of the neutral surface from
the horizontal,  is the mass per unit length, and g is Earth’s acceleration of gravity.
The solution of the resulting force-balance equation, −D∂4η/∂x4 = W =  g, is the
quartic (11.46a), which describes the equilibrium beam shape.
When gravity is absent and the beam is allowed to bend dynamically, the accel-
eration of gravity g gets replaced by the beam’s dynamical acceleration, ∂2η/∂t2. The
result is a wave equation for ﬂexural waves on the beam:
−D ∂4η
∂x4 =  ∂2η
∂t2 .
(12.32)
(This derivation of the wave equation is an elementary illustration of the principle
of equivalence—the equivalence of gravitational and inertial forces, or gravitational
and inertial accelerations—which underlies Einstein’s general relativity theory; see
Sec. 25.2.)
dispersion relation for
ﬂexural waves on a beam
The wave equations we have encountered so far in this chapter have all described
nondispersive waves, for which the wave speed is independent of the frequency.
Flexural waves, by contrast, are dispersive. We can see this by assuming that η ∝
exp[i(kx −ωt)]and thereby deducing from Eq. (12.32) the dispersion relation:
ω =

D/ k2 =

Eh2/(12ρ) k2.
(12.33)
Here we have used Eq. (12.31) for the ﬂexural rigidity D and  = ρwh for the mass
per unit length.
Before considering the implications of this dispersion relation, we complicate the
equilibrium a little. Let us suppose that, in addition to the net shearing force per
12.3 Waves in Rods, Strings, and Beams
645

unit length −D∂4η/∂x4, the beam is also held under a tensile force T . We can then
combine the two wave equations (12.29) and (12.32) to obtain
dispersion relation for
ﬂexural waves on a
stretched beam
−D ∂4η
∂x4 + T ∂2η
∂x2 =  ∂2η
∂t2 ,
(12.34)
for which the dispersion relation is
ω2 = C2
Sk2
*
1 + k2
k2
c
+
,
(12.35)
where CS = √T/ is the wave speed when the ﬂexural rigidity D is negligible so the
beam is string-like, and
kc =

T /D
(12.36)
is a critical wave number. If the average strain induced by the tension is ϵ = T /(Ewh),
then kc = (12ϵ)1/2h−1, where h is the thickness of the beam, w is its width, and
we have used Eq. (12.31). [Notice that kc is equal to 1/(the lengthscale on which a
pendulum’s support wire—analog of our beam—bends), as discussed in Ex. 11.11.]
For short wavelengths k ≫kc, the shearing force dominates, and the beam behaves
like a tension-free beam; for long wavelengths k ≪kc, it behaves like a string.
phase and group velocities
for ﬂexural waves on a
stretched beam
A consequence of dispersion is that waves with different wave numbers k propa-
gate with different speeds, and correspondingly, the group velocity Vg = dω/dk with
which wave packets propagate differs from the phase velocity Vph = ω/k with which
a wave’s crests and troughs move (see Sec. 7.2.2). For the dispersion relation (12.35),
the phase and group velocities are
Vph ≡ω/k = CS(1 + k2/k2
c)1/2,
Vg ≡dω/dk = CS(1 + 2k2/k2
c)(1 + k2/k2
c)−1/2.
(12.37)
As we discussed in detail in Sec. 7.2.2 and Ex. 7.2, for dispersive waves such as this
one, the fact that different Fourier components in the wave packet propagate with
different speeds causes the packet to gradually spread; we explore this quantitatively
for longitudinal waves on a beam in Ex. 12.5.
EXERCISES
Exercise 12.5 Derivation: Dispersion of Flexural Waves
Verify Eqs. (12.35) and (12.37). Sketch the dispersion-induced evolution of a Gaussian
wave packet as it propagates along a stretched beam.
Exercise 12.6 Problem: Speeds of Elastic Waves
Show that the sound speeds for the following types of elastic waves in an isotropic ma-
terial
are
in
the
ratios
1 : (1 −ν2)−1/2 :
2
1−ν
(1+ν)(1−2ν)
31/2
: [2(1 + ν)]−1/2 :
[2(1 + ν)]−1/2. The elastic waves are (i) longitudinal waves along a rod, (ii) longi-
tudinal waves along a sheet, (iii) longitudinal waves along a rod embedded in an
646
Chapter 12. Elastodynamics

incompressible ﬂuid, (iv) shear waves in an extended solid, and (v) torsional waves
along a rod. [Note: Here and elsewhere in this book, if you encounter grungy algebra
(e.g., frequent conversions from {K, μ} to {E, ν}), do not hesitate to use Mathe-
matica, Matlab, Maple, or other symbolic manipulation software to do the algebra!]
Exercise 12.7 Problem: Xylophones
Consider a beam of length ℓ, whose weight is negligible in the elasticity equations,
supported freely at both ends (so the slope of the beam is unconstrained at the ends).
Show that the frequencies of standing ﬂexural waves satisfy
ω =
nπ
ℓ
2  D
ρA
1/2
,
where A is the cross sectional area, and n is an integer. Now repeat the exercise
when the ends are clamped. Based on your result, explain why xylophones don’t have
clamped ends.
12.3.5
12.3.5 Bifurcation of Equilibria and Buckling (Once More)
We conclude this discussion by returning to the problem of buckling, which we in-
troduced in Sec. 11.6. The example we discussed there was a playing card compressed
until it wants to buckle. We can analyze small dynamical perturbations of the card,
η(x, t), by treating the tension T of the previous section as negative, T = −F, where
F is the compressional force applied to the card’s two ends in Fig. 11.11. Then the
equation of motion (12.34) becomes
−D ∂4η
∂x4 −F ∂2η
∂x2 =  ∂2η
∂t2 .
(12.38)
We seek solutions for which the ends of the playing card are held ﬁxed (as shown in
Fig. 11.11): η = 0 at x = 0 and at x = ℓ. Solving Eq. (12.38) by separation of variables,
we see that
η = ηn sin
nπ
ℓx

e−iωnt.
(12.39)
Heren = 1, 2, 3, . . .labelsthecard’smodesofoscillation, n −1isthenumberofnodes
eigenfrequencies for
normal modes of a
compressed beam
in the card’s sinusoidal shape for mode n, ηn is the amplitude of deformation for mode
n, and the mode’s eigenfrequency ωn (of course) satisﬁes the same dispersion relation
(12.35) as for waves on a long, stretched beam, with T →−F and k →nπ/ℓ:
ω2
n = 1
 
nπ
ℓ
2 'nπ
ℓ
2
D −F
(
= 1
 
nπ
ℓ
2 2
n2Fcrit −F
3
,
(12.40)
where Fcrit = π2D/ℓ2 is the critical force that we introduced in Chap. 11 [Eq. (11.54)].
12.3 Waves in Rods, Strings, and Beams
647

Consider the lowest normal mode, n = 1, for which the playing card is bent in the
single-arch manner of Fig. 11.11 as it oscillates. When the compressional force F is
small, ω2
1 is positive, so ω1 is real and the normal mode oscillates sinusoidally and
stably. But for F > Fcrit = π2D/ℓ2, ω2
1 is negative, so ω1 is imaginary and there are
two normal-mode solutions, one decaying exponentially with time, η ∝exp(−|ω1|t),
and the other increasing exponentially with time, η ∝exp(+|ω1|t), signifying an
instability against buckling.
Notice that the onset of instability occurs at the same compressional force, F =
onset of buckling for a
compressed beam
Fcrit, as the bifurcation of equilibria [Eq. (11.54)], where a new (bent) equilibrium
state for the playing card comes into existence. Notice, moreover, that the card’s n = 1
normal mode has zero frequency, ω1 = 0, at this onset of instability and bifurcation
of equilibria; the card can bend by an amount that grows linearly in time, η =
A sin(πx/ℓ) t, with no restoring force or exponential growth. This zero-frequency
motion leads the card from its original, straight equilibrium shape, to its new, bent
equilibrium shape.
This is an example of a very general phenomenon, which we shall meet again
in ﬂuid mechanics (Sec. 15.6.1). For mechanical systems without dissipation (no
energy losses to friction, viscosity, radiation, or anything else), as one gradually
changes some “control parameter” (in this case the compressional force F), there
can occur bifurcation of equilibria. At each bifurcation point, a normal mode of the
zero-frequency mode at
bifurcation of equilibria
originalequilibriumbecomesunstable, andatitsonsetofinstabilitythemodehaszero
frequency and represents a motion from the original equilibrium (which is becoming
unstable) to the new, stable equilibrium.
In our simple playing-card example, we see this phenomenon repeated again and
again as the control parameter F is increased. One after another, at F = n2Fcrit,
the modes n = 1, n = 2, n = 3, . . . become unstable. At each onset of instability, ωn
vanishes, and the zero-frequency mode (with n −1 nodes in its eigenfunction) leads
from the original, straight-card equilibrium to the new, stable, (n −1)-noded, bent
equilibrium.
12.4
12.4 Body Waves and Surface Waves—Seismology and Ultrasound
In Sec. 12.2, we derived the dispersion relations ω = CLk and ω = CT k for longitu-
dinal and transverse elastodynamic waves in uniform media. We now consider how
the waves are modiﬁed in an inhomogeneous, ﬁnite body: Earth. Earth is well ap-
proximated as a sphere of radius R ∼6,000 km and mean density ¯ρ ∼6,000 kg m−3.
The outer crust, extending down to 5–10 km below the ocean ﬂoor and comprising
rocks of high tensile strength, rests on a more malleable mantle, the two regions being
separated by the famous Mohoroviˇci´c (or Moho for short) discontinuity. Underlying
the mantle is an outer core mainly composed of liquid iron, which itself surrounds a
denser, solid inner core of mostly iron; see Table 12.1 and Fig. 12.5 below.
The pressure in Earth’s interior is much larger than atmospheric, and the rocks
are therefore quite compressed. Their atomic structure cannot be regarded as a small
648
Chapter 12. Elastodynamics

V
(a)
(b)
r
V
r
r0
r0
FIGURE 12.3 Potential energy curves (dashed) for nearest neighbors in a crystal lattice.
(a) At atmospheric (effectively zero) pressure, the equilibrium spacing is set by
the minimum in the potential energy, which is a combination of hard electrostatic
repulsion by the nearest neighbors (upper solid curve) and a softer overall attraction
associated with all the nearby ions (lower solid curve). (b) At much higher pressure,
the softer, attractive component is moved inward, and the equilibrium spacing is
greatly reduced. The bulk modulus is proportional to the curvature of the potential
energy curve at its minimum and so is considerably increased.
perturbation from their structure in a vacuum. Nevertheless, we can still use linear
elasticity theory to discuss small perturbations about their equilibrium. This is be-
cause the crystal lattice has had plenty of time to establish a new equilibrium with
a much smaller lattice spacing than at atmospheric pressure (Fig. 12.3). The density
of lattice defects and dislocations will probably not differ appreciably from those at
atmospheric pressure, so the proportionality limit and yield stress should be about
the same as for rocks near Earth’s surface. The linear stress-strain relation will still
apply below the proportionality limit, although the elastic moduli are much greater
than those measured at atmospheric pressure.
We can estimate the magnitude of the pressure P in Earth’s interior by idealizing
the planet as an isotropic medium with negligible shear stress, so its stress tensor is
like that of a ﬂuid, T = P g (where g is the metric tensor). Then the equation of static
equilibrium takes the form
dP
dr = −gρ,
(12.41)
where ρ is density, and g(r) is the acceleration of gravity at radius r. This equation
can be approximated by
pressure at Earth’s center
P ∼¯ρgR ∼300 GPa ∼3 × 106 atmospheres,
(12.42)
where g is now the acceleration of gravity at Earth’s surface r = R, and ¯ρ is Earth’s
mean density. This agrees well numerically with the accurate value of 360 GPa
12.4 Body Waves and Surface Waves—Seismology and Ultrasound
649

at Earth’s center. The bulk modulus produces the isotropic pressure P = −K
bulk modulus related to
equation of state
[Eq. (11.18)]; and since  = −δρ/ρ [cf. Eq. (12.3)], the bulk modulus can be ex-
pressed as
K =
dP
d ln ρ .
(12.43)
[Strictly speaking, we should distinguish between adiabatic and isothermal variations
in Eq. (12.43), but the distinction is small for solids; see Sec. 11.3.5. It is signiﬁcant
for gases.] Typically, the bulk modulus inside Earth is 4 to 5 times the pressure, and
the shear modulus in the crust and mantle is about half the bulk modulus.
12.4.1
12.4.1 Body Waves
Virtually all our direct information about the internal structure of Earth comes from
measurements of the propagation times of elastic waves that are generated by earth-
quakes and propagate through Earth’s interior (body waves). There are two fundamen-
tal kinds of body waves: the longitudinal and transverse modes of Sec. 12.2. These are
P-modes and S-modes
known in seismology as P-modes (P for pressure) and S-modes (S for shear), respec-
tively. The two polarizations of the transverse shear waves are designated SH and SV,
whereHandVstandfor“horizontal”and“vertical”displacements(i.e., displacements
orthogonal to k that are fully horizontal, or that are obtained by projecting the vertical
direction ez orthogonal to ˆk).
We shall ﬁrst be concerned with what seismologists call high-frequency (of order
1 Hz) modes, which leads to three related simpliﬁcations. As typical wave speeds lie
in the range 3–14 km s−1, the wavelengths lie in the range ∼1 to 10 km, which is
generally small compared with the distance over which gravity causes the pressure
to change signiﬁcantly—the pressure scale height. It turns out that we then can ignore
the effects of gravity on the propagation of small perturbations. In addition, we can
regard the medium locally as effectively homogeneous and so use the local dispersion
relations ω = CL,T k. Finally, as the wavelengths are short, we can trace rays through
Earth using geometrical optics (Sec. 7.3).
Now, Earth is quite inhomogeneous globally, and the sound speeds therefore vary
signiﬁcantly with radius; see Table 12.1. To a fair approximation, Earth is horizontally
stratiﬁed below the outer crust (whose thickness is irregular). Two types of variation
can be distinguished, the abrupt and the gradual. There are several abrupt changes
in the crust and mantle (including the Moho discontinuity at the interface between
crust and mantle), and also at the transitions between mantle and outer core, and
between outer core and inner core. At these surfaces of discontinuity, the density and
surfaces of discontinuity
elastic constants apparently change over distances short compared with a wavelength.
Seismic waves incident on these discontinuities behave like light incident on the
surface of a glass plate; they can be reﬂected and refracted. In addition, as there are
now two different waves with different phase speeds, it is possible to generate SV
waves from pure P waves and vice versa at a discontinuity (Fig. 12.4). However, this
650
Chapter 12. Elastodynamics

TABLE 12.1: Typical outer radii (R), densities (ρ), bulk moduli (K), shear moduli (μ), P-wave
speeds (CP), and S-wave speeds (CS) in different zones of Earth
R
ρ
K
μ
CP
CS
Zone
(103 km)
(103 kg m−3)
(GPa)
(GPa)
(km s−1)
(km s−1)
Inner core
1.2
13
1,400
160
11
2
Outer core
3.5
10–12
600–1,300
—
8–10
—
Mantle
6.35
3–5
100–600
70–250
8–14
5–7
Crust
6.37
3
50
30
6–7
3–4
Ocean
6.37
1
2
—
1.5
—
Notes: Note the absence of shear waves (denoted by a —) in the ﬂuid regions. Adapted from Stacey (1977).
SVi
SVr
SVt
αSVt
αSVi
Pr
Pt
boundary
FIGURE 12.4 An incident shear wave polarized in the vertical direction (SVi), incident
from above on a surface of discontinuity, produces both a longitudinal (P) wave and
an SV wave in reﬂection and in transmission. If the wave speeds increase across the
boundary (the case shown), then the transmitted waves, SVt, Pt, will be refracted
away from the vertical. A shear mode, SVr, will be reﬂected at the same angle as the
incident wave. However, the reﬂected P mode, Pr, will be reﬂected at a greater angle
to the vertical, as it has greater speed than the incident wave.
wave-wave mixing is conﬁned to SV and P; the SH waves do not mix with SV or P;
see Ex. 12.9.
The junction conditions that control this wave mixing and all other details of
the waves’ behavior at a surface of discontinuity are: (i) the displacement ξ must
be continuous across the discontinuity (otherwise inﬁnite strain and inﬁnite stress
would develop there); and (ii) the net force acting on an element of surface must be
zero (otherwise the surface, having no mass, would have inﬁnite acceleration), so the
force per unit area acting from the front face of the discontinuity to the back must be
balanced by that acting from the back to the front. If we take the unit normal to the
horizontal discontinuity to be ez, then these boundary conditions become
wave boundary conditions
at interfaces
[ξj]= [Tjz]= 0,
(12.44)
12.4 Body Waves and Surface Waves—Seismology and Ultrasound
651

where the notation [X]signiﬁes the difference in X across the boundary, and the j is
a vector index. (For an alternative, more formal derivation of [Tjz]= 0, see Ex. 12.8.)
One consequence of these boundary conditions is Snell’s law for the directions
of propagation of the waves. Since these continuity conditions must be satisﬁed all
along the surface of discontinuity and at all times, the phase φ = k . x −ωt of the
wave must be continuous across the surface at all locations x on it and all times,
which means that the phase φ must be the same on the surface for all transmitted
waves and all reﬂected waves as for the incident waves. This is possible only if the
frequency ω, the horizontal wave number kH = k sin α, and the horizontal phase
speed CH = ω/kH = ω/(k sin α) are the same for all the waves. (Here kH = k sin α
is the magnitude of the horizontal component of a wave’s propagation vector,
and α is the angle between its propagation direction and the vertical; cf. Fig. 12.4.)
Thus we arrive at Snell’s law: for every reﬂected or transmitted wave J, the horizontal
phase speed must be the same as for the incident wave:
Snell’s law for waves at
interfaces
CJ
sin αJ
= CH is the same for all J .
(12.45)
It is straightforward though tedious to compute the reﬂection and transmission
coefﬁcients (e.g., the strength of a transmitted P-wave produced by an incident SV
wave) for the general case using the boundary conditions (12.44) and (12.45) (see, e.g.,
Eringen and Suhubi, 1975, Sec. 7.7). For the very simplest of examples, see Ex. 12.10.
In the regions between the discontinuities, the pressures (and consequently, the
elasticmoduli)increasesteadily, overmanywavelengths, withdepth.Theelasticmod-
uli generally increase more rapidly than the density does, so the wave speeds generally
also increase with depth (i.e., dC/dr < 0). This radial variation in C causes the rays
along which the waves propagate to bend. The details of this bending are governed by
Hamilton’s equations, with the hamiltonian (x, k) determined by the simple non-
dispersive dispersion relation  = C(x)k (Sec. 7.3.1). Hamilton’s equations in this
case reduce to the simple ray equation (7.48), which (since the index of refraction is
∝1/C) can be rewritten as
geometric optics
ray equation for
elastodynamic waves
in inhomogeneous elastic
medium
d
ds
 1
C
dx
ds

= ∇
 1
C

.
(12.46)
Here s is distance along the ray, so dx/ds = n is the unit vector tangent to the ray.
This ray equation can be reexpressed in the following form:
dn/ds = −(∇ln C)⊥,
(12.47)
where the subscript ⊥means “projected perpendicular to the ray;” and this in turn
means that the ray bends away from the direction in which C increases (i.e., it bends
upward inside Earth, since C increases downward) with the radius of curvature of the
bend given by
652
Chapter 12. Elastodynamics

E
q
a
c
r
s
b
t
u
SV
SV
SV
SV
SV
SV
SV
SV
SV
P
P
P
P
P
P
v
inner
core
outer
core
mantle
crust
FIGURE 12.5 Seismic wave propagation in a schematic Earth model. A P wave made by an earthquake,
E, propagates to the crust-mantle boundary at a where it generates two transmitted waves (SV and
P) and two reﬂected waves (SV and P). The transmitted SV wave propagates along a ray that bends
upward a bit (geometric-optics bending) and hits the mantle–outer-core boundary at b. There can be
no transmitted SV wave at b, because the outer core is ﬂuid; there can be no transmitted or reﬂected P
wave, because the angle of incidence of the SV wave is too great. So the SV wave is perfectly reﬂected.
It then travels along an upward curving ray, to the crust-mantle interface at c, where it generates
four waves, two of which hit Earth’s surface. The earthquake E also generates an SV wave traveling
almost radially inward, through the crust-mantle interface at q, to the mantle–outer-core interface
at r. Because the outer core is liquid, it cannot support an SV wave, so only a P wave is transmitted
into the outer core at r. That P wave propagates to the interface with the inner core at s, where it
regenerates an SV wave along with the transmitted and reﬂected P waves (not shown). The SV wave
refracts back upward in the inner core and generates a P wave at the interface with the outer core
t. That P wave propagates through the liquid outer core to u, where it generates an SV wave along
with its transmitted and reﬂected P waves (not shown); that SV wave travels nearly radially outward,
through v and to Earth’s surface.
R =
1
|(∇ln C)⊥| =
1
|(d ln C/dr) sin α|.
(12.48)
Here α is the angle between the ray and the radial direction.
seismic wave propagation
Figure 12.5 shows schematically the propagation of seismic waves through Earth.
At each discontinuity in Earth’s material, Snell’s law governs the directions of the
reﬂected and transmitted waves. As an example, note from Eq. (12.45) that an SV
mode incident on a boundary cannot generate any P mode when its angle of incidence
exceeds sin−1(CT i/CLt). (Here we use the standard notation CT for the phase speed
of an S wave and CL for that of a P wave.) This is what happens at point b in Fig. 12.5.
12.4 Body Waves and Surface Waves—Seismology and Ultrasound
653

EXERCISES
Exercise 12.8 Derivation: Junction Condition at a Discontinuity
Derive the junction condition [Tjz]= 0 at a horizontal discontinuity between two
media by the same method as one uses in electrodynamics to show that the normal
componentofthemagneticﬁeldmustbecontinuous:Integratetheequationofmotion
ρdv/dt = −∇. T over the volume of an inﬁnitesimally thin pill box centered on the
boundary (see Fig. 11.7), and convert the volume integral to a surface integral via
Gauss’s theorem.
Exercise 12.9 Derivation: Wave Mixing at a Surface of Discontinuity
Using the boundary conditions (12.44), show that at a surface of discontinuity inside
Earth, SV and P waves mix, but SH waves do not mix with the other waves.
Exercise 12.10 Example: Reﬂection and Transmission of Normal, Longitudinal Waves
at a Boundary
Consider a longitudinal elastic wave incident normally on the boundary between two
media, labeled 1 and 2. By matching the displacement and the normal component of
stress at the boundary, show that the ratio of the transmitted wave amplitude to the
incident amplitude is given by
t =
2Z1
Z1 + Z2
,
where Z1,2 = [ρ1,2(K1,2 + 4μ1,2/3)]1/2 is known as the acoustic impedance. (The
impedance is independent of frequency and is just a characteristic of the material.)
Likewise, evaluate the amplitude reﬂection coefﬁcient, and verify that wave energy
ﬂux is conserved.
12.4.2
12.4.2 Edge Waves
edge waves and surface
waves
One phenomenon that is important in seismology (and also occurs in plasmas;
Ex. 21.17) but is absent for many other types of wave motion is edge waves, i.e., waves
that propagate along a discontinuity in the elastic medium. An important example
is surface waves, which propagate along the surface of a medium (e.g., Earth’s sur-
face) and that decay exponentially with depth. Waves with such exponential decay
are sometimes called evanescent.
Rayleigh wave
The simplest type of surface wave is the Rayleigh wave, which propagates along
the surface of an elastic medium. We analyze Rayleigh waves for the idealization of a
plane semi-inﬁnite solid—also sometimes called a homogeneous half-space.When it is
applied to Earth, this discussion must be modiﬁed to allow for both the density strat-
iﬁcation and (if the wavelength is sufﬁciently long) the surface curvature. However,
the qualitative character of the mode is unchanged.
654
Chapter 12. Elastodynamics

Rayleigh waves are an intertwined mixture of P and SV waves. When analyzing
them, it is useful to resolve their displacement vector ξ into a sum of a (longitudinal)
P-wave component ξL and a (transverse) SV-wave component ξT .
Consider a semi-inﬁnite elastic medium, and introduce a local Cartesian coordi-
nate system with ez normal to the surface, ex lying in the surface, and the propagation
vector k in the ez-ex plane. The propagation vector has a real component along the
horizontal (ex) direction, corresponding to true propagation, and an imaginary com-
ponent along the ez direction, corresponding to an exponential decay of the amplitude
as one goes down into the medium. For the longitudinal (P-wave) and transverse (SV-
wave) parts of the wave to remain in phase with each other as they propagate along
the boundary, they must have the same values of the frequency ω and horizontal wave
number kx. However, there is no reason why their vertical e-folding lengths should be
the same (i.e., why their imaginary kz values should be the same). We therefore denote
their imaginary kzs by −iqL for the longitudinal (P-wave) component and −iqT for
the transverse (S-wave) component, and we denote their common kx by k.
First focus attention on the longitudinal part of the wave. Its displacement can be
written as the gradient of a scalar [Eq. (12.7b)], ξL = ∇(ψ0eqLz+i(kx−ωt)):
ξL
x = ikψ0eqLz+i(kx−ωt),
ξL
z = qLψ0eqLz+i(kx−ωt),
z ≤0.
(12.49)
Substitutingintothegeneraldispersionrelationω2 = C2
Lk2 forlongitudinalwaves,
we obtain
qL =
*
k2 −ω2
C2
L
+1/2
.
(12.50)
Because the transverse part of the wave is divergence free, the wave’s expansion comes
entirely from the longitudinal part,  = ∇. ξL, and is given by
 = (q2
L −k2)ψ0eqLz+i(kx−ωt).
(12.51)
The transverse (SV) part of the wave can be written as the curl of a vector
potential [Eq. (12.7c)], which we can take to point in the y direction, ξT = ∇×
(A0eyeqT z+i(kx−ωt)):
ξT
x = −qT A0eqT z+i(kx−ωt),
ξT
z = ikA0eqT z+i(kx−ωt),
z ≤0.
(12.52)
The dispersion relation ω2 = C2
T k2 for transverse waves tells us that
qT =
*
k2 −ω2
C2
T
+1/2
.
(12.53)
We next impose boundary conditions at the surface. Since the surface is free, there
will be no force acting on it:
T . ez|z=0 = 0,
(12.54)
which is a special case of the general boundary condition (12.44). (Note that we can
evaluate the stress at the unperturbed surface rather than at the displaced surface as we
12.4 Body Waves and Surface Waves—Seismology and Ultrasound
655

are only working to linear order.) The tangential stress is Txz = −2μ(ξz,x + ξx,z) = 0,
so its vanishing is equivalent to
ξz,x + ξx,z = 0
at z = 0.
(12.55)
Inserting ξ = ξL + ξT and Eqs. (12.49) and (12.52) for the components and solving
for the ratio of the transverse amplitude to the longitudinal amplitude, we obtain
A0
ψ0
= 2ikqL
k2 + q2
T
.
(12.56)
The normal stress is Tzz = −K −2μ(ξz,z −1
3) = 0, so from the values C2
L =
(K + 4
3μ)/ρ and C2
T = μ/ρ of the longitudinal and transverse sound speeds, which
imply K/μ = (CL/CT )2 −4
3, we deduce that vanishing Tzz is equivalent to
(1 −2κ) + 2κξz,z = 0
at z = 0,
where
κ ≡C2
T
C2
L
= 1 −2ν
2(1 −ν).
(12.57)
Here we have used Eqs. (11.39) to express the speed ratio in terms of Poisson’s ratio ν.
Inserting  from Eq. (12.51) and ξz = ξL
z + ξT
z with components from Eqs. (12.49)
and(12.52), usingtherelationq2
L −k2 + 2κk2 = κ(q2
T + k2)[whichfollowsfromEqs.
(12.50), (12.53), and (12.57)], and solving for the ratio of amplitudes, we obtain
A0
ψ0
= k2 + q2
T
−2ikqT
.
(12.58)
The dispersion relation for Rayleigh waves is obtained by equating the two expres-
sions (12.56) and (12.58) for the amplitude ratio:
4k2qT qL = (k2 + q2
T )2.
(12.59)
We can express this dispersion relation more explicitly in terms of the ratio of the
Rayleigh-wave speed CR = ω/k to the transverse-wave speed CT :
ζ =
 ω
CT k
2
=
CR
CT
2
.
(12.60)
ByinsertingqT = k√1 −ζ [fromEqs.(12.53)and(12.60)]andqL = k√1 −κζ [from
Eqs. (12.50), (12.57), and (12.60)], and expressing κ in terms of Poisson’s ratio via
Eq. (12.57), we bring Eq. (12.59) into the explicit form
dispersion relation for
Rayleigh wave
ζ 3 −8ζ 2 + 8
2 −ν
1 −ν

ζ −
8
(1 −ν) = 0.
(12.61)
This dispersion relation is a third-order polynomial in ζ ∝ω2 with just one posi-
tive real root ζ(ν), which we plot in Fig. 12.6. From that plot, we see that for a Poisson’s
ratio characteristic of rocks, 0.2 <∼ν <∼0.3, the phase speed of a Rayleigh wave is roughly
phase speed of Rayleigh
wave
0.9 times the speed of a pure shear wave; cf. Fig. 12.6.
656
Chapter 12. Elastodynamics

CR
—
CT
1.0
0.9
0.8
0.00
0.25
0.50
ν
FIGURE 12.6 Solution CR/CT = √ζ of the dispersion
relation (12.61) as a function of Poisson’s ratio ν.
FIGURE 12.7 Rayleigh waves in a semi-inﬁnite elastic medium.
The displacement vector for Rayleigh waves is the sum of Eqs. (12.49) and (12.52)
with the amplitudes related by (12.56):
material displacement in
Rayleigh wave
ξx = ikψo
'
eqLz −2qLqT
k2 + q2
T
eqT z
(
ei(kx−ωt),
ξz = qLψo
'
eqLz −
2k2
k2 + q2
T
eqT z
(
ei(kx−ωt).
(12.62)
Equation (12.62) represents a backward rotating, elliptical motion for each ﬂuid
element near the surface (as depicted in Fig. 12.7), reversing to a forward rotation
at depths where the sign of ξx has ﬂipped.
Rayleigh waves propagate around the surface of Earth rather than penetrate its
interior. However, our treatment is inadequate, because their wavelengths—typically
1–10 km if generated by an earthquake—are not necessarily small compared with the
scale heights in the outer crust over which CS and CT vary. Our wave equation has to
be modiﬁed to include these vertical gradients.
12.4 Body Waves and Surface Waves—Seismology and Ultrasound
657

This vertical stratiﬁcation has an important additional consequence. Ignoring
these gradients, if we attempt to ﬁnd an orthogonal surface mode just involving SH
waves, we ﬁnd that we cannot simultaneously satisfy the surface boundary conditions
on displacement and stress with a single evanescent wave. We need two modes to
do this. However, when we allow for stratiﬁcation, the strong refraction allows an
SH surface wave to propagate. This is known as a Love wave. The reason for its
Love waves
practical importance is that seismic waves are also created by underground nuclear
explosions, and it is important to be able to distinguish explosion-generated waves
from earthquake waves. An earthquake is usually caused by the transverse slippage
of two blocks of crust across a fault line. It is therefore an efﬁcient generator of shear
modes, including Love waves. By contrast, explosions involve radial motions away
from the point of explosion and are inefﬁcient emitters of Love waves. This allows
these two sources of seismic disturbance to be distinguished.
EXERCISES
Exercise 12.11 Example: Earthquakes
The magnitude M of an earthquake, on modern variants of the Richter scale, is a
quantitative measure of the strength of the seismic waves it creates. The earthquake’s
seismic-wave energy release can be estimated using a rough semi-empirical formula
due to B˚ath (1966):
earthquake magnitude
E = 105.24+1.44MJ.
(12.63)
The largest earthquakes have magnitude ∼9.5.
One type of earthquake is caused by slippage along a fault deep in the crust.
Suppose that most of the seismic power in an earthquake with M ∼8.5 is emitted
at frequencies ∼1Hz and that the quake lasts for a time T ∼100 s. If C is an average
wave speed, then it is believed that the stress is relieved over an area of fault of length
∼CT and a depth of order one wavelength (Fig. 12.8). By comparing the stored
elastic energy with the measured energy release, make an estimate of the minimum
strain prior to the earthquake. Is your answer reasonable? Hence estimate the typical
displacement during the earthquake in the vicinity of the fault. Make an order-of-
magnitude estimate of the acceleration measurable by a seismometer in the next
state and in the next continent. (Ignore the effects of density stratiﬁcation, which are
actually quite signiﬁcant.)
12.4.3
12.4.3 Green’s Function for a Homogeneous Half-Space
To gain insight into the combination of waves generated by a localized source, such as
an explosion or earthquake, it is useful to examine the Green’s function for excitations
in a homogeneous half-space. Physicists deﬁne the Green’s function Gjk(x, t; x′, t′) to
be the displacement response ξj(x, t) to a unit delta-function force in the ek direction
at location x′ and time t′: F = δ(x −x′)δ(t −t′)ek. Geophysicists sometimes ﬁnd
658
Chapter 12. Elastodynamics

fault
CT
λ
FIGURE 12.8 Earthquake: The region of a fault that slips
(solid rectangle), and the volume over which the strain
is relieved, on one side of the fault (dashed region).
it useful to work, instead, with the “Heaviside Green’s function,” GH
jk(x, t; x′, t′),
Heaviside Green’s function
for elastodynamic waves
which is the displacement response ξj(x, t) to a unit step-function force (one that
turns on to unit strength and remains forever constant afterward) at x′ and t′: F =
δ(x −x′)H(t −t′)ek. Because δ(t −t′) is the time derivative of the Heaviside step
function H(t −t′), the Heaviside Green’s function is the time integral of the physicists’
Green’s function. The Heaviside Green’s function has the advantage that one can easily
see the size of the step functions it contains, by contrast with the size of the delta
functions contained in the physicists’ Green’s function.
It is a rather complicated task to compute the Heaviside Green’s function, and
geophysicists have devoted much effort to doing so. We shall not give the details
of such computations, but merely show the function graphically in Fig. 12.9 for
an instructive situation: the displacement produced by a step-function force in a
homogeneous half-space with the observer at the surface and the force at two different
locations: a point nearly beneath the observer (Fig. 12.9a), and a point close to the
surface and some distance away in the x direction (Fig. 12.9b).
Properties of Heaviside
Green’s function
Several features of this Heaviside Green’s function deserve note:
.
Because of their relative propagation speeds, the P waves arrive at the ob-
server ﬁrst, then (about twice as long after the excitation) the S waves, and
shortly thereafter the Rayleigh waves. From the time interval T between
the ﬁrst P waves and ﬁrst S waves, one can estimate the distance to the source:
ℓ≃(CP −CS)T ∼3(T /s) km.
.
For the source nearly beneath the observer (Fig. 12.9a), there is no sign of
any Rayleigh wave, whereas for the source close to the surface, the Rayleigh
wave is the strongest feature in the x and z (longitudinal and vertical) dis-
placements but is absent from the y (transverse) displacement. From this,
one can infer the waves’ propagation direction.
.
The y (transverse) component of force produces a transverse displacement
that is strongly concentrated in the S wave.
.
The x and z (longitudinal and vertical) components of force produce x and
z displacements that include P waves, S waves, and (for the source near the
surface) Rayleigh waves.
12.4 Body Waves and Surface Waves—Seismology and Ultrasound
659

1
P
GH
xx
GH
zx
GH
xz
GH
zz
GH
yy
GH
xx
GH
zx
GH
xz
GH
zz
GH
yy
P
S
S
t (s)
(a)
(b)
t (s)
R
2
3
4
4
1
horizontal,
longitudinal force
horizontal,
longitudinal force
horizontal,
transverse force
vertical force
vertical force
horizontal,
longitudinal force
horizontal,
transverse force
vertical force
vertical force
2
3
FIGURE 12.9 The Heaviside Green’s function (displacement response to a step-function force) in a
homogeneous half-space. The observer is at the surface. The force is applied at a point in the x-z plane,
with a direction stated in words and also given by the second index of GH; the displacement direction
is given by the ﬁrst index of GH. The longitudinal and transverse speeds are CL = 8.00 km s−1 and
CS = 4.62 km s−1, and the density is 3.30 × 103 kg m−3. For a force of 1 Newton, a division on the
vertical scale is 10−16 m. The moments of arrival of the P wave, S wave, and Rayleigh (R) wave from
the moment the force is turned on are indicated on the horizontal axis. (a) The source is nearly directly
beneath the observer, so the waves propagate nearly vertically upward. More speciﬁcally, the source
is at 10 km depth and is 2 km distant along the horizontal x direction. (b) The source is close to the
surface, and the waves propagate nearly horizontally (in the x direction). More speciﬁcally, the source
is at 2 km depth and is 10 km distant along the horizontal x direction. Adapted from Johnson (1974,
Figs. 2, 4).
.
The gradually changing displacements that occur between the arrival of the
turn-on P wave and the turn-on S wave are due to P waves that hit the surface
some distance from the observer, and from there diffract to the observer as
a mixture of P and S waves. Similarly for gradual changes of displacement
after the turn-on S wave.
The complexity of seismic waves arises in part from the richness of features in
this homogeneous-half-space Heaviside Green’s function, in part from the inﬂuences
of Earth’s inhomogeneities, and in part from the complexity of an earthquake’s or
explosion’s forces.
660
Chapter 12. Elastodynamics

(a)
(b)
(c)
FIGURE 12.10 Displacements associated with three types of global modes for an elastic
sphere, such as Earth. The polar axis points upward. (a) A radial mode shown on a cross
section through the sphere’s center; matter originally on the solid circle moves in and
out between the two dashed circles. (b) An l = 1, m = 0 torsional mode; the arrows are
proportional to the displacement vector on the sphere’s surface at one moment of time.
(c) An l = 2, m = 0 spheroidal mode shown on a cross section through the sphere’s
center; matter originally on the solid circle moves between the two ellipses.
12.4.4
12.4.4 Free Oscillations of Solid Bodies
Whencomputingthedispersionrelationsforbody(P-andS-wave)modesandsurface
(Rayleigh-wave) modes, we have assumed that the wavelength is small compared with
Earth’s radius; therefore the modes have a continuous frequency spectrum. However,
it is also possible to excite global modes in which the whole Earth “rings” with a
discrete spectrum. If we approximate Earth as spherically symmetric and ignore its
rotation (whose period is long compared to a normal-mode period), then we can
types of normal modes of
an elastic sphere
isolate three types of global modes: radial, torsional, and spheroidal.
To compute the details of these modes, we can solve by separation of variables
the equations of elastodynamics for the displacement vector in spherical polar coor-
dinates. This is much like solving the Schr¨odinger equation for a central potential.
See Ex. 12.12 for a relatively simple example. In general (as in that example), each of
the three types of modes has a displacement vector ξ characterized by its own type of
spherical harmonic.
radial modes
The radial modes have spherically symmetric, purely radial displacements ξr(r)
and so have spherical harmonic order l = 0; see Fig. 12.10a and Ex. 12.12a.
torsional modes
The torsional modes have vanishing radial displacements, and their nonradial
displacements are proportional to the vector spherical harmonic ˆL Y m
l (θ, φ), where
θ, φ are spherical coordinates, Y m
l
is the scalar spherical harmonic, and ˆL = x × ∇
is the angular momentum operator (aside from an omitted factor ℏ/i), which plays
a major role in quantum theory. Spherical symmetry guarantees that these modes’
eigenfrequencies are independent of m (because by reorienting the polar axis, the
various m are mixed among one another), so m = 0 is representative. In this case,
∇Y 0
l ∝∇Pl(cos θ) is in the θ direction, so ˆLY 0
l is in the φ direction. Hence the only
nonzero component of the displacement vector is
ξφ ∝∂Pl(cos θ)/∂θ = sin θP ′
l (cos θ).
(12.64)
12.4 Body Waves and Surface Waves—Seismology and Ultrasound
661

(Here Pl is the Legendre polynomial and P ′
l is the derivative of Pl with respect to its
argument.) Therefore, in these modes alternate zones of different latitude oscillate
in opposite directions (clockwise or counterclockwise at some chosen moment of
time) in such a way as to conserve total angular momentum. See Fig. 12.10b and
Ex. 12.12b. In the high-frequency limit, the torsional modes become SH waves (since
their displacements are horizontal).
spheroidal modes
The spheroidal modes have radial displacements proportional to Y m
l (θ, φ)er, and
they have nonradial components proportional to ∇Y m
l . These two displacements can
combine into a single mode, because they have the same parity (and opposite parity
from the torsional modes) as well as the same spherical-harmonic orders l and m. The
eigenfrequencies again are independent of m and thus can be studied by specializing
to m = 0, in which case the displacements become
ξr ∝Pl(cos θ),
ξθ ∝sin θP ′
l (cos θ).
(12.65)
These displacements deform the sphere in a spheroidal manner for the special case l =
2 (Fig. 12.10c and Ex. 12.12c), whence their name “spheroidal.” The radial modes are
the special case l = 0 of these spheroidal modes. It is sometimes mistakenly asserted
that there are no l = 1 spheroidal modes because of conservation of momentum. In
fact, l = 1modes do exist: for example, the central regions of the sphere can move up,
while the outer regions move down. For Earth, the lowest-frequency l = 2 spheroidal
mode has a period of 53 minutes and can ring for about 1,000 periods (i.e., its quality
factor is Q ∼1,000). This is typical for solid planets. In the high-frequency limit, the
spheroidal modes become a mixture of P and SV waves.
solving elastodynamic
equations for modes
Whenonewritesthedisplacementvectorξ forageneralvibrationofEarthasasum
over these various types of global modes and inserts that sum into the wave equation
(12.4b) (augmented, for greater realism, by gravitational forces), spherical symmetry
of unperturbed Earth guarantees that the various modes will separate from one an-
other. For each mode the wave equation will give a radial wave equation analogous to
that for a hydrogen atom in quantum mechanics. The boundary condition T . er = 0
mode spectra
at Earth’s surface constrains the solutions of the radial wave equation for each mode
to be a discrete set, which one can label by the number n of radial nodes that the mode
possesses (just as for the hydrogen atom). The frequencies of the modes increase with
both n and l. See Ex. 12.12 for details in a relatively simple case.
For small values of the quantum numbers l and n, the modes are quite sensitive to
the model assumed for Earth’s structure. For example, they are sensitive to whether
one correctly includes the gravitational restoring force in the wave equation. However,
for large l and n, the spheroidal and toroidal modes become standing combinations
of P, SV, SH, Rayleigh, and Love waves, and therefore they are rather insensitive to the
effects of gravity.
662
Chapter 12. Elastodynamics

12.4.5
12.4.5 Seismic Tomography
Observations of all of these types of seismic waves clearly code much information
about Earth’s structure. Inverting the measurements to infer this structure has become
a highly sophisticated and numerically intensive branch of geophysics—and also of
oil exploration! The travel times of the P and S body waves can be measured between
various pairs of points over Earth’s surface and essentially allow CL and CT (and hence
K/ρ and μ/ρ) to be determined as functions of radius inside Earth. Travel times are
<∼1 hour. Using this type of analysis, seismologists can infer the presence of hot and
cold regions in the mantle and then infer how the rocks are circulating under the crust.
It is also possible to combine the observed travel times with Earth’s equation of
elastostatic equilibrium
elastostatic equilibrium
equation for gravitating,
elastic sphere (e.g., Earth)
dP
dr = −g(r)ρ,
g(r) = 4πG
r2
 r
0
r′2ρ(r′)dr′,
(12.66)
where g(r) is the gravitational acceleration, to determine the distributions of density,
pressure, and elastic constants. Measurements of Rayleigh and Love waves can be
used to probe the surface layers. The results of this procedure are then input to obtain
free oscillation frequencies (global mode frequencies), which compare well with the
observations. The damping rates for the free oscillations furnish information on the
interior viscosity.
12.4.6
12.4.6 Ultrasound; Shock Waves in Solids
Sound waves at frequencies above 20,000 Hz (where human hearing ends) are widely
used in modern technology, especially for imaging and tomography. This is much like
exploring Earth with seismic waves.
Just as seismic waves can travel from Earth’s solid mantle through its liquid outer
core and into its solid inner core, so these ultrasonic waves can travel through both
solids and liquids, with reﬂection, refraction, and transmission similar to those in
Earth.
Applications of ultrasound include, among others, medical imaging (e.g., of struc-
tures in the eye and of a human fetus during pregnancy), inspection of materials (e.g.,
ofcracks, voids, andweldingjoints), acousticmicroscopyatfrequenciesupto∼3 GHz
(e.g., by scanning acoustic microscopes), ultrasonic cleaning (e.g., of jewelry), and ul-
trasonic welding (with sonic vibrations creating heat at the interface of the materials
to be joined).
When an ultrasonic wave (or any other sound wave) in an elastic medium reaches
a sufﬁciently high amplitude, its high-amplitude regions propagate faster than its low-
amplitude regions. This causes it to develop a shock front, in which the compression
increases almost discontinuously. This nonlinear mechanism for shock formation in
a solid is similar to that in a ﬂuid, where we shall study the mechanism in detail
(Sec. 17.4.1). The theory of the elastodynamic shock itself, especially jump conditions
across the shock,is also similar to that in a ﬂuid (Sec. 17.5.1). For details of the theory in
12.4 Body Waves and Surface Waves—Seismology and Ultrasound
663

solids, including effects of plastic ﬂow at sufﬁciently high compressions, see Davison
(2010). Ultrasonic shock waves are used to break up kidney stones in the human body.
In laboratories, shocks from the impact of a rapidly moving projectile on a material
specimen, or from intense pulsed laser-induced ablation (e.g., at the U.S. National
Ignition Facility, Sec. 10.2.2), are used to compress the specimen to pressures similar
to those in Earth’s core or higher and thereby explore the specimen’s high-density
properties. Strong shock waves from meteorite impacts alter the properties of the rock
through which they travel and can be used to infer aspects of the equation of state for
planetary interiors.
EXERCISES
Exercise 12.12 **Example: Normal Modes of a Homogeneous, Elastic Sphere3
Show that, for frequency-ω oscillations of a homogeneous elastic sphere with negligi-
ble gravity, the displacement vector can everywhere be written as ξ = ∇ψ + ∇× A,
where ψ is a scalar potential that satisﬁes the longitudinal-wave Helmholtz equa-
tion, and A is a divergence-free vector potential that satisﬁes the transverse-wave
Helmholtz equation:
ξ = ∇ψ + ∇× A,
(∇2 + k2
L)ψ = 0,
(∇2 + k2
T )A = 0,
∇. A = 0;
kL = ω
CL
,
kT = ω
CT
.
(12.67)
[Hint: See Ex. 12.2, and make use of gauge freedom in the vector potential.]
(a) Radial Modes. The radial modes are purely longitudinal; their scalar potential
[general solution of (∇2 + k2
L)ψ = 0 that is regular at the origin] is the spherical
Bessel function of order zero: ψ = j0(kLr) = sin(kLr)/(kLr). The corresponding
displacement vector ξ = ∇ψ has as its only nonzero component
ξr = j′
0(kLr),
(12.68)
where the prime on j0 and on any other function in this exercise means the
derivative with respect to its argument. (Here we have dropped a multiplicative
factor kL.) Explain why the only boundary condition that need be imposed is
Trr = 0 at the sphere’s surface. By computing Trr for the displacement vector of
3.
For a detailed and extensive treatment of this problem and many references, see Eringen and Suhubi
(1975, Secs. 8.13, 8.14). Our approach to the mathematics is patterned after that of Ashby and Dreitlein
(1975, Sec. III), and our numerical evaluations are for the same cases as Love (1927, Secs. 195, 196)
and as the classic paper on this topic, Lamb (1882). It is interesting to compare the mathematics of
our analysis with the nineteenth-century mathematics of Lamb and Love, which uses radial functions
ψl(r) ∼r−ljl(r) and solid harmonics that are sums over m of rlY m
l (θ, φ) and satisfy Laplace’s equation.
Here jl is the spherical Bessel function of order l, and Y m
l
is the spherical harmonic. Solid harmonics
can be written as Fij ...qxixj . . . xq, with F a symmetric, trace-free tensor of order l. A variant of them
is widely used today in multipolar expansions of gravitational radiation (see, e.g., Thorne, 1980, Sec. II).
664
Chapter 12. Elastodynamics

Eq. (12.68) and setting it to zero, deduce the following eigenequation for the wave
numbers kL and thence frequencies ω = CLkL of the radial modes:
tan xL
xL
=
1
1 −(xT /2)2 ,
(12.69)
where
xL ≡kLR = ωR
CL
= ωR
&
ρ
K + 4μ/3,
xT ≡kT R = ωR
CT
= ωR
& ρ
μ ,
(12.70)
with R the radius of the sphere. For (xT /xL)2 = 3, which corresponds to a
Poisson’s ratio ν = 1/4 (about that of glass and typical rock; see Table 11.1),
numerical solution of this eigenequation gives the spectrum for modes {l = 0;
n = 0, 1, 2, 3, . . .}:
xL
π =
ω
πCL/R = {0.8160, 1.9285, 2.9539, 3.9658, . . .}.
(12.71)
Note that these eigenvalues get closer and closer to integers as one ascends the
spectrum; this also will be true for any other physically reasonable value of xT /xL.
Explain why.
(b)
Torsional Modes. The general solution to the scalar Helmholtz equation
(∇2 + k2)ψ that is regular at the origin is a sum over eigenfunctions of the form
jl(kr)Y m
l (θ, φ). Show that the angular momentum operator ˆL = x × ∇com-
mutes with the laplacian ∇2, and thence infer that ˆL [jlY m
l ] satisﬁes the vector
Helmholtz equation. Verify further that it is divergence free, which means it must
be expressible as the curl of a vector potential that is also divergence free and sat-
isﬁes the vector Helmholtz equation. This means that ξ = ˆL [jl(kT r)Y m
l (θ, φ)]
is a displacement vector that satisﬁes the elastodynamic equation for transverse
waves. Since ˆL differentiates only transversely (in the θ and φ directions), we
can rewrite this expression as ξ = jl(kT r)ˆL Y m
l (θ, φ). To simplify computing the
eigenfrequencies (which are independent of m), specialize to m = 0, and show
that the only nonzero component of the displacement is
ξφ ∝jl(kT r) sin θP ′
l (θ).
(12.72)
Equation (12.72), for our homogeneous sphere, is the torsional mode discussed
in the text [Eq. (12.64)]. Show that the only boundary condition that must be
imposed on this displacement function is Tφr = 0 at the sphere’s surface, r =
R. Compute this component of the stress tensor (with the aid of Box 11.4 for
the shear), and by setting it to zero, derive the following eigenequation for the
torsional-mode frequencies:
xT j′
l(xT ) −jl(xT ) = 0.
(12.73)
12.4 Body Waves and Surface Waves—Seismology and Ultrasound
665

For l = 1 (the case illustrated in Fig. 12.10b), this eigenequation reduces to (3 −
x2
T ) tan xT = 3xT , and the lowest few eigenfrequencies are
xT
π =
ω
πCT /R = {1.8346, 2.8950, 3.9225, 4.9385, . . .}.
(12.74)
As for the radial modes, these eigenvalues get closer and closer to integers as one
ascends the spectrum. Explain why.
(c)
Ellipsoidal Modes. The displacement vector for the ellipsoidal modes is the
sum of a longitudinal piece ∇ψ [with ψ = jl(kLr)Y m
l (θ, φ) satisfying the lon-
gitudinal wave Helmholtz equation] and a transverse piece ∇× A [with A =
jl(kT r)ˆL Y m
l (θ, φ), which as we saw in part (b) satisﬁes the transverse wave
Helmholtz equation and is divergence free]. Specializing to m = 0 to derive the
eigenequation (which is independent of m), show that the components of the
displacement vector are
ξr =
 α
kL
j′
l(kLr) + β
kT
l(l + 1)jl(kT r)
kT r

Pl(cos θ),
ξθ =

−α
kL
jl(kLr)
kLr
+ β
kT

j′(kT r) + j(kT r)
kT r

sin θP ′
l (cos θ),
(12.75)
where α/kL and β/kT are constants that determine the weightings of the lon-
gitudinal and transverse pieces, and we have included the kL and kT to simplify
the stress tensor derived below. (To get the β term in ξr, you will need to use
a differential equation satisﬁed by Pl.) Show that the boundary conditions we
must impose on these eigenfunctions are Trr = 0 and Trθ = 0 at the sphere’s sur-
face, r = R. By evaluating these [using the shear components in Box 11.4, the
differential equation satisﬁed by jl(x), and (K + 4
3μ)/μ = (xT /xL)2], obtain the
following expressions for these components of the stress tensor at the surface:
Trr = −μPl(cos θ)

α
A
2j′′
l (xL) −[(xT /xL)2 −2]jl(xL)
B
+ β 2l(l + 1)f1(xT )

= 0,
Trθ = μ sin θP ′
l (cos θ)

α 2f1(xL) + β
C
j′′
l (xT ) + [l(l + 1) −2]f0(xT )
D 
= 0,
where f0(x) ≡jl(x)/x2
and
f1(x) ≡(jl(x)/x)′.
(12.76)
These simultaneous equations for the ratio α/β have a solution if and only if the
determinant of their coefﬁcients vanishes:
A
2j′′
l (xL) −[(xT /xL)2 −2]jl(xL)
BA
j′′
l (xT ) + (l + 2)(l −1)f0(xT )
B
−4l(l + 1)f1(xL)f1(xT ) = 0.
(12.77)
This is the eigenequation for the ellipsoidal modes. For l = 2 and (xT /xL)2 = 3,
it predicts for the lowest four ellipsoidal eigenfrequencies
xT
π =
ω
πCT /R = {0.8403, 1.5487, 2.6513, 3.1131, . . .}.
(12.78)
666
Chapter 12. Elastodynamics

Notice that these are signiﬁcantly smaller than the torsional frequencies. Show
that, in the limit of an incompressible sphere (K →∞) and for l = 2, the
eigenequation becomes (4 −x2
T )[j′′
2 (xT ) + 4f0(xT )]−24f1(xT ) = 0, which pre-
dicts for the lowest four eigenfrequencies
xT
π =
ω
πCT /R = {0.8485, 1.7421, 2.8257, 3.8709, . . .}.
(12.79)
These are modestly larger than the compressible case, Eq. (12.78).
12.5
12.5 The Relationship of Classical Waves
to Quantum Mechanical Excitations
In the previous chapter, we identiﬁed the effects of atomic structure on the contin-
uum approximation for elastic solids. Speciﬁcally, we showed that atomic structure
accounts for the magnitude of the elastic moduli and explains why most solids yield
under comparatively small strain. A quite different connection of the continuum the-
ory to atomic structure is provided by the normal modes of vibration of a ﬁnite solid
body (e.g., the sphere treated in Sec. 12.4.4 and Ex. 12.12).
For any such body, one can solve the vector wave equation (12.4b) [subject to the
vanishing-surface-force boundary condition T . n = 0, Eq. (11.33)] to ﬁnd the body’s
normal modes, as we did in Ex. 12.12 for the sphere. In this section, we label the
normal modes of a general
elastic body
normal modes by a single indexN (encompassing{l, m, n} in the case of a sphere) and
denotetheeigenfrequencyofmodeN byωN andits(typicallycomplex)eigenfunction
by ξN. Then any general, small-amplitude disturbance in the body can be decomposed
into a linear superposition of these normal modes:
displacement expanded in
normal modes
ξ(x, t) = ℜ
 
N
aN(t)ξN(x),
aN = AN exp(−iωNt).
(12.80)
Here ℜmeans to take the real part, aN is the complex generalized coordinate of mode
N, and AN is its complex amplitude. It is convenient to normalize the eigenfunctions
so that

ρ|ξN|2dV = M,
(12.81)
where M is the mass of the body; AN then measures the mean physical displacement
in mode N.
Classical electromagnetic waves in a vacuum are described by linear Maxwell
equations; so after they have been excited, they will essentially propagate forever. This
is not so for elastic waves, where the linear wave equation is only an approximation.
Nonlinearities—and most especially impurities and defects in the structure of the
12.5 The Relationship of Classical Waves to Quantum Mechanical Excitations
667

body’s material—will cause the different modes to interact weakly and also damp, so
that their complex amplitudes AN change slowly with time according to a damped
simple harmonic oscillator differential equation of the form
equation of motion for a
normal mode
¨aN + (2/τN)˙aN + ω2
NaN = F ′
N/M.
(12.82)
Here the second term on the left-hand side is a damping term (due to frictional
heating and weak coupling with other modes) that will cause the mode to decay as
long as τN > 0; F ′
N is a ﬂuctuating or stochastic force on mode N (also caused by
weak coupling to the other modes). Equation (12.82) is the Langevin equation that we
studied in Sec. 6.8.1. The spectral density of the ﬂuctuating force F ′
N is proportional to
1/τN and is determined by the ﬂuctuation-dissipation theorem, Eqs. (6.74) or (6.86).
If the modes are thermalized at temperature T , then the ﬂuctuating forces maintain
an average energy of kT in each mode.
What happens quantum mechanically? The ions and electrons in an elastic solid
interact so strongly that it is difﬁcult to analyze them directly. A quantum mechanical
treatment is much easier if one makes a canonical transformation from the coordi-
quantization of a normal
mode
nates and momenta of the individual ions or atoms to new, generalized coordinates
ˆxN and momenta ˆpN that represent weakly interacting normal modes. These coor-
dinates and momenta are Hermitian operators, and they are related to the quantum
mechanical complex generalized coordinate ˆaN by
ˆxN = 1
2(ˆaN + ˆa†
N),
(12.83a)
ˆpN = MωN
2i
(ˆaN −ˆa†
N),
(12.83b)
where the dagger denotes the Hermitian adjoint. We can transform back to obtain an
expression for the displacement of the ith ion:
ˆxi = 1
2N[ˆaNξN(xi) + ˆa†
Nξ∗
N(xi)]
(12.84)
[a quantum version of Eq. (12.80)].
The hamiltonian can be written in terms of these coordinates as
ˆH = N
*
ˆp2
N
2M + 1
2Mω2
N ˆx2
N
+
+ ˆHint,
(12.85)
where the ﬁrst term is a sum of simple harmonic oscillator hamiltonians for individual
modes; and ˆHint is the perturbative interaction hamiltonian, which takes the place
of the combined damping and stochastic forcing terms in the classical Langevin
668
Chapter 12. Elastodynamics

equation (12.82). When the various modes are thermalized, the mean energy in mode
N takes on the standard Bose-Einstein form:
thermalized normal modes
¯EN = ℏωN
1
2 +
1
exp[ℏωN/(kBT )]−1

(12.86)
[Eq. (4.28b) with vanishing chemical potential and augmented by a “zero-point en-
ergy” of 1
2ℏω], which reduces to kBT in the classical limit ℏ→0.
As the unperturbed hamiltonian for each mode is identical to that for a particle
in a harmonic oscillator potential well, it is sensible to think of each wave mode as
analogous to such a particle-in-well. Just as the particle-in-well can reside in any
one of a series of discrete energy levels lying above the zero-point energy of ℏω/2
and separated by ℏω, so each wave mode with frequency ωN must have an energy
(n + 1/2)ℏωN, where n is an integer. The operator that causes the energy of the mode
to decrease by ℏωN is the annihilation operator for mode n:
creation and annihilation
operatorsfornormal-mode
quanta (phonons)
ˆαN =
MωN
2ℏ
1/2
ˆaN,
(12.87)
the operator that causes an increase in the energy by ℏωN is its Hermitian conjugate,
the creation operator ˆα†
N, and their commutator is [ˆαN, ˆα†
N]= 1, corresponding to
[ˆxN, ˆpN]= iℏ; see for example Chap. 5 of Cohen-Tannoudji, Diu, and Lalo¨e (1977).
It is useful to think of each increase or decrease of a mode’s energy as the creation or
annihilation of an individual quantum or “particle” of energy, so that when the energy
in mode N is (n + 1/2)ℏωN, there are n quanta (particles) present. These particles are
called phonons.Because phonons can coexist in the same state (the same mode), they
phonons are bosons
are bosons. They have individual energies and momenta which must be conserved in
their interactions with one another and with other types of particles (e.g., electrons).
This conservation law shows up classically as resonance conditions in mode-mode
mixing (cf. the discussion in nonlinear optics, Sec. 10.6.1).
The important question is, given an elastic solid at ﬁnite temperature, do we think
of its thermal agitation as a superposition of classical modes, or do we regard it as a gas
of quanta? The answer depends on what we want to do. From a purely fundamental
relation of classical and
quantum theories for
normal modes
viewpoint, the quantum mechanical description takes precedence. However, for many
problems where the number of phonons per mode (the mode’s mean occupation
number)ηN ∼kBT/(ℏωN)islargecomparedtoone, theclassicaldescriptionisamply
adequate and much easier to handle. We do not need a quantum treatment when
computing the normal modes of a vibrating building excited by an earthquake or
when trying to understand how to improve the sound quality of a violin. Here the
difﬁculty often is in accommodating the boundary conditions so as to determine the
normal modes. All this was expected. What comes as more of a surprise is that often,
for purely classical problems (where ℏis quantitatively irrelevant), the fastest way to
12.5 The Relationship of Classical Waves to Quantum Mechanical Excitations
669

analyze a practical problem formally is to follow the quantum route and then take the
limit ℏ→0. We shall see this graphically demonstrated when we discuss nonlinear
plasma physics in Chap. 23.
Bibliographic Note
The classic textbook treatments of elastodynamics from a physicist’s viewpoint are
Landau and Lifshitz (1986) and—in nineteenth-century language—Love (1927). For
a lovely and very readable introduction to the basic concepts, with a focus on elasto-
dynamic waves, see Kolsky (1963). Our favorite advanced textbook and treatise is
Eringen and Suhubi (1975).
By contrast with elastostatics, where there are a number of good, twenty-ﬁrst-
century engineering-oriented textbooks at the elementary and intermediate levels,
there are none that we know of for elastodynamics.
However, we do know two good, advanced engineering-oriented books on meth-
ods to solve the elastodynamic equations in nontrivial situations: Poruchikov,
Khokhryakov, and Groshev (1993) and Kausel (2006). And for a compendium of
practical engineering lore about vibrations of engineering structures, from building
foundations to bell towers to suspension bridges, see Bachman (1994).
For seismic waves and their geophysical applications, we recommend the text-
books by Stein and Wysession (2003) and by Shearer (2009).
670
Chapter 12. Elastodynamics

V
PART V
FLUID DYNAMICS
Having studied elasticity theory, we now turn to a second branch of continuum me-
chanics: ﬂuid dynamics.Three of the four states of matter (gases, liquids, and plasmas)
can be regarded as ﬂuids, so it is not surprising that interesting ﬂuid phenomena
surround us in our everyday lives. Fluid dynamics is an experimental discipline;
much of our current understanding has come in response to laboratory investigations.
Fluid dynamics ﬁnds experimental application in engineering, physics, biophysics,
chemistry, and many other ﬁelds. The observational sciences of oceanography, me-
teorology, astrophysics, and geophysics, in which experiments are less frequently
performed, also rely heavily on ﬂuid dynamics. Many of these ﬁelds have enhanced
our appreciation of ﬂuid dynamics by presenting ﬂows under conditions that are in-
accessible to laboratory study.
Despite this rich diversity, the fundamental principles are common to all these
applications. The key assumption that underlies the equations governing the motion
of a ﬂuid is that the length- and timescales associated with the ﬂow are long compared
with the corresponding microscopic scales, so the continuum approximation can be
invoked.
The fundamental equations of ﬂuid dynamics are, in some respects, simpler than
the corresponding laws of elastodynamics. However, as with particle dynamics, sim-
plicity of equations does not imply the solutions are simple. Indeed, they are not!
One reason is that ﬂuid displacements are usually not small (by contrast with elasto-
dynamics, where the elastic limit keeps them small), so most ﬂuid phenomena are
immediately nonlinear.
Relatively few problems in ﬂuid dynamics admit complete, closed-form, analytic
solutions, so progress in describing ﬂuid ﬂows has usually come from introduc-
ing clever physical models and using judicious mathematical approximations. Semi-
empirical scaling laws are also common, especially for engineering applications. In
more recent years, numerical ﬂuid dynamics has come of age, and in many areas of
671

ﬂuid dynamics, computer simulations are complementing and even supplanting lab-
oratory experiments and measurements. For example, most design work for airplanes
and automobiles is now computational.
In ﬂuid dynamics, considerable insight accrues from visualizing the ﬂow. This is
true of ﬂuid experiments, where much technical skill is devoted to marking the ﬂuid
so it can be imaged; it is also true of numerical simulations, where frequently more
timeisdevotedtocomputergraphicsthantosolvingtheunderlyingpartialdifferential
equations. Indeed, obtaining an analytic solution to the equations of ﬂuid dynamics is
not the same as understanding the ﬂow; as a tool for understanding, at the very least
it is usually a good idea to sketch the ﬂow pattern.
We present the fundamental concepts of ﬂuid dynamics in Chap. 13, focusing par-
ticularly on the underlying physical principles and the conservation laws for mass,
momentum, and energy. We explain why, when ﬂow velocities are very subsonic, a
ﬂuid’s density changes very little (i.e., it is effectively incompressible), and we special-
ize the fundamental principles and equations to incompressible ﬂows.
Vorticity plays major roles in ﬂuid dynamics. In Chap. 14, we focus on those roles
for incompressible ﬂows, both in the fundamental equations of ﬂuid dynamics and
in applications. Our applications include, among others, tornados and whirlpools,
boundary layers abutting solid bodies, the inﬂuence of boundary layers on bulk
ﬂows, and how wind drives ocean waves and is ultimately responsible for deep-ocean
currents.
Viscosity has a remarkably strong inﬂuence on ﬂuid ﬂows, even when the viscosity
is weak. When strong, it keeps a ﬂow laminar (smooth); when weak, it controls details
of the turbulence that pervades the bulk ﬂow (the ﬂow away from boundary layers). In
Chap. 15, we describe turbulence, a phenomenon so difﬁcult to handle theoretically
that semiquantitative ideas and techniques pervade its theoretical description, even
in the incompressible approximation (to which we adhere). The onset of turbulence
is especially intriguing. We illuminate it by exploring a closely related phenomenon:
chaotic behavior in mathematical maps.
In Chap. 16, we focus on waves in ﬂuids, beginning with waves on the surface
of water, where we shall see, for shallow water, how nonlinear effects and dispersion
together give rise to “solitary waves” (solitons) that hold themselves together as they
propagate. In this chapter, we abandon the incompressible approximation, which
has permeated Part V thus far, to study sound waves. Radiation reaction in sound
generation is much simpler than in, for example, electrodynamics, so we use sound
waves to elucidate the physical origin of radiation reaction and the nonsensical nature
of pre-acceleration.
In Chap. 17, we turn to transonic and supersonic ﬂows, in which density changes
are of major importance. Here we meet some beautiful and powerful mathematical
tools: characteristics and their associated Riemann invariants. We focus especially
on ﬂow through rocket nozzles and other constrictions, and on shock fronts, with
applications to explosions (bombs and supernovae).
672
Part V

Convectionisanotherphenomenoninwhichdensitychangesarecrucial—though
here the density changes are induced by thermal expansion rather than by physical
compression. We study convection in Chap. 18, paying attention to the (usually small
but sometimes large) inﬂuence of diffusive heat conduction and the diffusion of
chemical constituents (e.g., salt).
When a ﬂuid is electrically conducting and has an embedded magnetic ﬁeld, the
exchange of momentum between the ﬁeld and the ﬂuid can produce remarkable phe-
nomena (e.g., dynamos that amplify a seed magnetic ﬁeld, a multitude of instabilities,
and Alfv´en waves and other magnetosonic waves). This is the realm of magneto-
hydrodynamics, which we explore in Chap. 19. The most common application of
magnetohydrodynamics is to a highly ionized plasma, the topic of Part VI of this
book, so Chap. 19 serves as a transition from ﬂuid dynamics (Part V) to plasma phys-
ics (Part VI).
Fluid Dynamics
673


13
CHAPTER THIRTEEN
Foundations of Fluid Dynamics
ϵ‘´υρηκα
ARCHIMEDES (CA. 250 BC)
13.1
13.1 Overview
In this chapter, we develop the fundamental concepts and equations of ﬂuid dynam-
ics, ﬁrst in the ﬂat-space venue of Newtonian physics (Track One) and then in the
Minkowski spacetime venue of special relativity (Track Two). Our relativistic treat-
ment is rather brief. This chapter contains a large amount of terminology that may be
unfamiliar to readers. A glossary of terminology is given in Box 13.5, near the end of
the chapter.
We begin in Sec. 13.2 with a discussion of the physical nature of a ﬂuid: the
possibility of describing it by a piecewise continuous density, velocity, and pressure
and the relationship between density changes and pressure changes. Then in Sec. 13.3,
we discuss hydrostatics (density and pressure distributions of a static ﬂuid in a static
gravitational ﬁeld); this parallels our discussion of elastostatics in Chap. 11. After
explaining the physical basis of Archimedes’ law, we discuss stars, planets, Earth’s
atmosphere, and other applications.
Our foundation for moving from hydrostatics to hydrodynamics will be conserva-
tion laws for mass, momentum, and energy. To facilitate that transition, in Sec. 13.4,
we examine in some depth the physical and mathematical origins of these conserva-
tion laws in Newtonian physics.
The stress tensor associated with most ﬂuids can be decomposed into an isotropic
pressure and a viscous term linear in the rate of shear (i.e., in the velocity gradient).
Under many conditions the viscous stress can be neglected over most of the ﬂow,
and diffusive heat conductivity is negligible. The ﬂuid is then called ideal or perfect.1
ideal ﬂuid (perfect ﬂuid)
We study the laws governing ideal ﬂuids in Sec. 13.5. After deriving the relevant
1.
An ideal ﬂuid (also called a perfect ﬂuid) should not be confused with an ideal or perfect gas—one
whose pressure is due solely to kinetic motions of particles and thus is given by P = nkBT , with n the
particle number density, kB Boltzmann’s constant, and T temperature, and that may (ideal gas) or may
not (perfect gas) have excited internal molecular degrees of freedom; see Box 13.2.
675

BOX 13.1.
READERS’ GUIDE
.
This chapter relies heavily on the geometric view of Newtonian
physics (including vector and tensor analysis) laid out in Chap. 1.
.
This chapter also relies on some elementary thermodynamic
concepts treated in Chap. 5 and on the concepts of expansion,
shear, and rotation (the irreducible tensorial parts of the gradient of
displacement) introduced in Chap. 11.
.
Our brief introduction to relativistic ﬂuid dynamics (Track Two of
this chapter) relies heavily on the geometric viewpoint on special
relativity developed in Chap. 2.
.
Chapters 14–19 (ﬂuid dynamics including magnetohydrodynamics)
are extensions of this chapter; to understand them, the Track-One
parts of this chapter must be mastered.
.
Portions of Part VI, Plasma Physics (especially Chap. 21 on the
“two-ﬂuid formalism”), rely heavily on Track-One parts of this
chapter.
.
Portions of Part VII, General Relativity, entail relativistic ﬂuids in
curved spacetime, for which the Track-Two Sec. 13.8 serves as a
foundation.
conservation laws and equation of motion (the Euler equation), we derive and discuss
Bernoulli’s theorem for an ideal ﬂuid and explain how it can simplify the description
of many ﬂows. In ﬂows for which the ﬂuid velocities are much smaller than the speed
of sound and gravity is too weak to compress the ﬂuid much, the fractional changes
in ﬂuid density are small. It can then be a good approximation to treat the ﬂuid as
incompressible,which leads to considerable simpliﬁcation, also addressed in Sec. 13.5.
As we shall see in Sec. 13.6, incompressibility can be a good approximation not just for
liquids (which tend to have large bulk moduli) but also, more surprisingly, for gases. It
is so widely applicable that we restrict ourselves to the incompressible approximation
throughout Chaps. 14 and 15.
InSec.13.7, weaugmentourbasicequationswithtermsdescribingviscousstresses
and also heat conduction. This allows us to derive the famous Navier-Stokes equation
and illustrate its use by analyzing the ﬂow of a ﬂuid through a pipe, and then use this
to make a crude model of blood ﬂowing through an artery. Much of our study of ﬂuids
in future chapters will focus on this Navier-Stokes equation.
In our study of ﬂuids we often deal with the inﬂuence of a uniform gravitational
ﬁeld (e.g., Earth’s, on lengthscales small compared to Earth’s radius). Occasionally,
676
Chapter 13. Foundations of Fluid Dynamics

however, weconsiderinhomogeneousgravitationalﬁeldsproducedbytheﬂuidwhose
motion we study. For such situations it is useful to introduce gravitational contribu-
tions to the stress tensor and energy density and ﬂux. We present and discuss these in
Box 13.4, where they will not impede the ﬂow of the main stream of ideas.
We conclude this chapter in Sec. 13.8 with a brief, Track-Two overview of relativis-
tic ﬂuid mechanics for a perfect (ideal) ﬂuid. As an important application, we explore
the structure of a relativistic astrophysical jet: the conversion of internal thermal en-
ergy into the energy of organized bulk ﬂow as the jet travels outward from the nucleus
of a galaxy into intergalactic space and widens. We also explore how the fundamental
equations of Newtonian ﬂuid mechanics arise as low-velocity limits of the relativistic
equations.
13.2
13.2 The Macroscopic Nature of a Fluid: Density, Pressure,
Flow Velocity; Liquids versus Gases
ﬂuid
The macroscopic nature of a ﬂuid follows from two simple observations. The ﬁrst is
that in most ﬂows the macroscopic continuum approximation is valid. Because the
molecular mean free paths in a ﬂuid are small compared to macroscopic lengthscales,
we can deﬁne a mean local velocity v(x, t) of the ﬂuid’s molecules, which varies
smoothly both spatially and temporally; we call this the ﬂuid’s velocity. For the same
reason, other quantities that characterize the ﬂuid [e.g., the density ρ(x, t)] also vary
smoothly on macroscopic scales. This need not be the case everywhere in the ﬂow.
An important exception is a shock front, which we study in Chap. 17; there the ﬂow
varies rapidly, over a length of order the molecules’ mean free path for collisions. In
this case, the continuum approximation is only piecewise valid, and we must perform
a matching at the shock front. One might think that a second exception is a turbulent
ﬂow, where it seems plausible that the average molecular velocity will vary rapidly on
whateverlengthscalewechoosetostudy, allthewaydowntointermoleculardistances,
so averaging becomes problematic. As we shall see in Chap. 15, this is not the case;
turbulent ﬂows generally have a lengthscale far larger than intermolecular distances,
below which the ﬂow varies smoothly.
The second observation is that ﬂuids do not oppose a steady shear strain. This is
easy to understand on microscopic grounds, as there is no lattice to deform, and the
molecular velocity distribution remains locally isotropic in the presence of a static
shear. By kinetic theory considerations (Chap. 3), we therefore expect that a ﬂuid’s
stress tensor T will be isotropic in the local rest frame of the ﬂuid (i.e., in a frame
where v = 0). Because of viscosity, this is not quite true when the shear varies with
time. However, we neglect viscosity as well as diffusive heat ﬂow until Sec. 13.7 (i.e.,
we restrict ourselves to ideal ﬂuids). This assumption allows us to write T = P g in the
local rest frame, where P is the ﬂuid’s pressure, and g is the metric (with Kronecker
delta components, gij = δij, in Cartesian coordinates).
13.2 The Macroscopic Nature of a Fluid
677

The laws of ﬂuid mechanics as we develop them are equally valid for liquids, gases,
and (under many circumstances) plasmas. In a liquid, as in a solid, the molecules are
liquid
packed side by side (but can slide over one another easily). In a gas or plasma, the
gas or plasma
molecules are separated by distances large compared to their sizes. This difference
leads to different behaviors under compression.
For a liquid (e.g., water in a lake), the molecules resist strongly even a small
compression; as a result, it is useful to characterize the pressure increase by a bulk
modulus K, as in an elastic solid (Chap. 11):
pressure changes in a
liquid
δP = −K = K δρ
ρ
for a liquid.
(13.1)
(Here we have used the fact that the expansion  is the fractional increase in volume,
or equivalently by mass conservation, it is the fractional decrease in density.) The bulk
modulus for water is about 2.2 GPa, so as one goes downward in a lake far enough to
double the pressure from one atmosphere (105 Pa to 2 × 105 Pa), the fractional change
in density is only δρ/ρ = (2 × 105/2.2 × 109) ≃1 part in 10,000.
By contrast, gases and plasmas are much less resistant to compression. Due to
the large distance between molecules, a doubling of the pressure requires, in order of
magnitude, a doubling of the density:
pressure changes in a gas
or plasma
δP
P =  δρ
ρ
for a gas,
(13.2)
where  is a proportionality factor of order unity. The numerical value of  depends
on the physical situation. If the gas is ideal [so P = ρkBT /(μmp) in the notation
of Box 13.2, Eq. (4)] and the temperature T is being held ﬁxed by thermal contact
with some heat source as the density changes (isothermal process), then δP ∝δρ, and
 = 1. Alternatively, and much more commonly, a ﬂuid element’s entropy may remain
constant, because no signiﬁcant heat can ﬂow in or out of it during the density change.
In this case  is called the adiabatic index, and (continuing to assume ideality), it can
adiabatic index
be shown using the laws of thermodynamics that
 = γ ≡cP/cV
for adiabatic processes in an ideal gas.
(13.3)
Here cP and cV are the speciﬁc heats at constant pressure and volume; see Ex. 5.4 in
speciﬁc heats per unit
mass
Chap. 5.2
2.
In ﬂuid dynamics, our speciﬁc heats, and other extensive variables, such as energy, entropy, and enthalpy,
are deﬁned per unit mass and are denoted by lowercased letters. So cP = T (∂s/∂T )P is the amount of
heat that must be added to a unit mass of the ﬂuid to increase its temperature by one unit, and similarly
for cV = T (∂s/∂T )ρ. By contrast, in statistical thermodynamics (Chap. 5) our extensive variables are
deﬁned for some chosen sample of material and are denoted by capital letters, e.g., CP = T (∂S/∂T )P.
678
Chapter 13. Foundations of Fluid Dynamics

BOX 13.2.
THERMODYNAMIC CONSIDERATIONS
One feature of ﬂuid dynamics (especially gas dynamics) that distinguishes
it from elastodynamics is that the thermodynamic properties of the ﬂuid
are often important, so we must treat energy conservation explicitly. In this
box we review, from Chap. 5 or any book on thermodynamics (e.g., Kittel
and Kroemer, 1980), the thermodynamic concepts needed in our study
of ﬂuids. We have no need for partition functions, ensembles, and other
statistical aspects of thermodynamics. Instead, we only need elementary
thermodynamics.
We begin with the nonrelativistic ﬁrst law of thermodynamics (5.8) for a
sample of ﬂuid with energy E, entropy S, volume V , number NI of molecules
of species I, temperature T , pressure P , and chemical potential μI for
species I:
dE = T dS −P dV +
 
I
μIdNI.
(1)
Almost everywhere in our treatment of ﬂuid dynamics (and throughout
this chapter), we assume that the term !
I μIdNI vanishes. Physically this
holds because (i) all relevant nuclear reactions are frozen (occur on timescales
τreact far longer than the dynamical timescales τdyn of interest to us), so
dNI = 0, and (ii) each chemical reaction is either frozen dNI = 0 or goes
so rapidly (τreact ≪τdyn) that it and its inverse are in local thermodynamic
equilibrium: !
I μIdNI = 0 for those species involved in the reactions. In the
rare intermediate situation, where some relevant reaction has τreact ∼τdyn, we
would have to carefully keep track of the relative abundances of the chemical
or nuclear species and their chemical potentials.
Consider a small ﬂuid element with mass m, internal energy per unit
mass u, entropy per unit mass s, and volume per unit mass 1/ρ. Then inserting
E = um, S = sm, andV = m/ρ intotheﬁrstlawdE = T dS −P dV , we
obtain the form of the ﬁrst law that we use in almost all of our ﬂuid-dynamics
studies:
du = T ds −P d
 1
ρ

.
(2)
The internal energy (per unit mass) u comprises the random translational
energy of the molecules that make up the ﬂuid, together with the energy
associated with their internal degrees of freedom (rotation, vibration, etc.)
and with their intermolecular forces. The term T ds represents some amount
of heat (per unit mass) that may be injected into a ﬂuid element (e.g., by
(continued)
13.2 The Macroscopic Nature of a Fluid
679

BOX 13.2.
(continued)
viscous heating; Sec. 13.7) or may be removed (e.g., by radiative cooling). The
term −Pd(1/ρ) represents work done on the ﬂuid.
In ﬂuid mechanics it is useful to introduce the enthalpy H = E + P V of
a ﬂuid element (cf. Ex. 5.5) and the corresponding enthalpy per unit mass
h = u + P/ρ. Inserting u = h −P/ρ into the left-hand side of the ﬁrst law
(2), we obtain the ﬁrst law in the enthalpy representation [Eq. (5.47)]:
dh = T ds + dP
ρ .
(3)
Because we assume that all reactions are frozen or are in local
thermodynamic equilibrium, the relative abundances of the various nuclear
and chemical species are fully determined by a ﬂuid element’s density ρ and
temperature T (or by any two other variables in the set ρ, T , s, and P ).
Correspondingly, the thermodynamic state of a ﬂuid element is completely
determined by any two of these variables. To calculate all features of that
state from two variables, we must know the relevant equations of state, such
as P(ρ, T ) and s(ρ, T ); P (ρ, s) and T (ρ, s); or the ﬂuid’s fundamental
thermodynamic potential (Table 5.1), from which follow the equations of
state.
We often deal with ideal gases (i.e., gases in which intermolecular forces
and the volume occupied by the molecules are treated as totally negligible).
For any ideal gas, the pressure arises solely from the kinetic motions of the
molecules, and so the equation of state P (ρ, T ) is
P = ρkBT
μmp
.
(4)
Here μ is the mean molecular weight, and mp is the proton mass [cf. Eqs.
(3.39b), with the number density of particles n reexpressed as ρ/μmp]. The
mean molecular weight μ is the mean mass per gas molecule in units of the
proton mass (e.g., μ = 1 for hydrogen, μ = 32 for O2, and μ = 28.8 for air).
This μ should not be confused with the chemical potential of species I, μI
(which will rarely if ever be used in our ﬂuid dynamics analyses). [The concept
of an ideal gas must not be confused with an ideal ﬂuid; see footnote 1.]
An idealization that is often accurate in ﬂuid dynamics is that the ﬂuid
is adiabatic: no heating or cooling from dissipative processes, such as viscosity,
(continued)
680
Chapter 13. Foundations of Fluid Dynamics

BOX 13.2.
(continued)
thermal conductivity, or the emission and absorption of radiation. When this
is a good approximation, the entropy per unit mass s of a ﬂuid element is
constant.
In an adiabatic ﬂow, there is only one thermodynamic degree of freedom,
so we can write P = P(ρ, s) = P(ρ). Of course, this function will be different
for ﬂuid elements that have different s. In the case of an ideal gas, a standard
thermodynamic argument (Ex. 5.4) shows that the pressure in an adiabatically
expanding or contracting ﬂuid element varies with density as δP/P = γ δρ/ρ,
where γ = cP/cV is the adiabatic index [Eqs. (13.2) and (13.3)]. If, as is often
the case, the adiabatic index remains constant over several doublings of the
pressure and density, then we can integrate this expression to obtain the
equation of state
P = K(s)ργ ,
(5)
where K(s) is some function of the entropy. Equation (5) is sometimes
called the polytropic equation of state, and a polytropic index n (not to be
confused with number density of particles!) is deﬁned by γ = 1 + 1/n. See
the discussion of stars and planets in Sec. 13.3.2 and Ex. 13.4. A special
case of adiabatic ﬂow is isentropic ﬂow. In this case, the entropy is constant
everywhere, not just inside individual ﬂuid elements.
When the pressure can be regarded as a function of the density alone (the
same function everywhere), the ﬂuid is called barotropic.
From Eqs. (13.1) and (13.2), we see that K = P ; so why use K for liquids and 
for gases and plasmas? Because in a liquid K remains nearly constant when P changes
by large fractional amounts δP/P >∼1, while in a gas or plasma it is  that remains
nearly constant.
For other thermodynamic aspects of ﬂuid dynamics that will be relevant as we
proceed, see Box 13.2.
13.3
13.3 Hydrostatics
Just as we began our discussion of elasticity with a treatment of elastostatics, so we
introduce ﬂuid mechanics by discussing hydrostatic equilibrium.
equation of hydrostatic
equilibrium
The equation of hydrostatic equilibrium for a ﬂuid at rest in a gravitational ﬁeld g
is the same as the equation of elastostatic equilibrium with a vanishing shear stress,
so T = P g:
∇. T = ∇P = ρg
(13.4)
13.3 Hydrostatics
681

[Eq. (11.14) with f = −∇. T]. Here g is the acceleration of gravity (which need not
be constant; e.g., it varies from location to location inside the Sun). It is often useful
to express g as the gradient of the Newtonian gravitational potential :
Newtonian gravitational
potential
g = −∇.
(13.5)
Note our sign convention:  is negative near a gravitating body and zero far from all
bodies, and it is determined by Newton’s ﬁeld equation for gravity:
Newtonian ﬁeld equation
for gravity
∇2 = −∇. g = 4πGρ.
(13.6)
We can draw some immediate and important inferences from Eq. (13.4). Take the
curl of Eq. (13.4) and use Eq. (13.5) to obtain
∇ × ∇ρ = 0.
(13.7)
Equation (13.7) tells us that in hydrostatic equilibrium, the contours of constant
theorems about
hydrostatic structure
density (isochores) coincide with the equipotential surfaces: ρ = ρ(). Equation
(13.4) itself, with (13.5), then tells us that, as we move from point to point in the ﬂuid,
the changes in P and  are related by dP/d = −ρ(). This, in turn, implies that
the difference in pressure between two equipotential surfaces 1 and 2 is given by
P = −
 2
1
ρ()d.
(13.8)
Moreover, as ∇P ∝∇, the surfaces of constant pressure (the isobars) coincide with
the gravitational equipotentials. This is all true whether g varies inside the ﬂuid or is
constant.
pressure is weight of
overlying ﬂuid
The gravitational acceleration g is actually constant to high accuracy in most non-
astrophysical applications of ﬂuid dynamics, for example, on the surface of Earth. In
this case the pressure at a point in a ﬂuid is, from Eq. (13.8), equal to the total weight
of ﬂuid per unit area above the point,
P (z) = g
 ∞
z
ρdz,
(13.9)
where the integral is performed by integrating upward in the gravitational ﬁeld (cf.
Fig. 13.1). For example, the deepest point in the world’s oceans is the bottom of
the Mariana Trench in the Paciﬁc, 11 km below sea level. Adopting a density ρ ≃
103 kg m−3 for water and g ≃10 m s−2, we obtain a pressure of ≃108 Pa or ≃103
atmospheres. This is comparable with the yield stress of the strongest materials. It
should therefore come as no surprise that the record for the deepest dive ever recorded
by a submersible—a depth of 10.91 km (just ∼100 m shy of the lowest point in the
trench) achieved by the Trieste in 1960—remained unbroken for more than half a
century. Only in 2012 was that last 100 m conquered and the trench’s bottom reached,
by the ﬁlmmaker James Cameron in the Deep Sea Challenger.Since the bulk modulus
682
Chapter 13. Foundations of Fluid Dynamics

water
water
water
mercury
P1
g
P2
P3
FIGURE 13.1 Elementary demonstration of the principles of hydrostatic equilibrium. Water
and mercury, two immiscible ﬂuids of different density, are introduced into a container
with two connected chambers as shown. In each chamber, isobars (surfaces of constant
pressure) coincide with surfaces of constant  = −gz, and so are horizontal. The
pressure at each point on the ﬂat bottom of a container is equal to the weight per unit
area of the overlying ﬂuid [Eq. (13.9)]. The pressures P1 and P2 at the bottom of the left
chamber are equal, but because of the density difference between mercury and water,
they differ from the pressure P3 at the bottom of the right chamber.
of sea water is K = 2.3 GPa, at the bottom of the trench the water is compressed by
δρ/ρ = P/K ≃0.05.
EXERCISES
Exercise 13.1 Example: Earth’s Atmosphere
As mountaineers know, it gets cooler as you climb. However, the rate at which the
temperature falls with altitude depends on the thermal properties of air. Consider
two limiting cases.
(a) In the lower stratosphere (Fig. 13.2), the air is isothermal. Use the equation of
hydrostatic equilibrium (13.4) to show that the pressure decreases exponentially
with height z:
P ∝exp(−z/H),
(13.10a)
where the scale height H is given by
H = kBT
μmpg ,
(13.10b)
with μ the mean molecular weight of air and mp the proton mass. Evaluate this
numerically for the lower stratosphere, and compare with the stratosphere’s thick-
ness. By how much does P drop between the bottom and top of the isothermal
region?
(b) Suppose that the air is isentropic, so that P ∝ργ [Eq. (5) of Box 13.2], where γ
is the speciﬁc heat ratio. (For diatomic gases like nitrogen and oxygen, γ ∼1.4;
see Ex. 17.1.) Show that the temperature gradient satisﬁes
dT
dz = −
γ −1
γ
 gμmp
k
.
(13.10c)
13.3 Hydrostatics
683

180
220
270
295
48
100
35
16
0
altitude (km)
thermosphere
mesopause
mesosphere
stratopause
stratosphere
troposphere
T (K)
FIGURE 13.2 Actual temperature variation of Earth’s mean atmosphere at temperate latitudes.
Note that the temperature gradient vanishes when γ →1. Evaluate the tempera-
ture gradient, also known at low altitudes as the lapse rate.The average lapse rate
is measured to be ∼6 K km−1 (Fig. 13.2). Show that this is intermediate between
the two limiting cases of isentropic and isothermal lapse rates.
13.3.1
13.3.1 Archimedes’ Law
Archimedes’ law
The law of Archimedes states that, when a solid body is totally or partially immersed
in a ﬂuid in a uniform gravitational ﬁeld g = −gez, the total buoyant upward force of
the ﬂuid on the body is equal to the weight of the displaced ﬂuid.
Proof of Archimedes’ Law.
A formal proof can be made as follows (Fig. 13.3). The
ﬂuid, pressing inward on the body across a small element of the body’s surface d,
exerts a force dFbuoy = T(
, −d) [Eq. (1.32)], where T is the ﬂuid’s stress tensor,
and the minus sign is because by convention, d points out of the body rather than
into it. Converting to index notation and integrating over the body’s surface ∂V, we
obtain for the net buoyant force
F buoy
i
= −

∂V
Tijdj.
(13.11a)
Now, imagine removing the body and replacing it by ﬂuid that has the same pressure
P(z) and density ρ(z), at each height z as the surrounding ﬂuid; this is the ﬂuid that
was originally displaced by the body. Since the ﬂuid stress on ∂V has not changed,
the buoyant force will be unchanged. Use Gauss’s law to convert the surface inte-
gral (13.11a) into a volume integral over the interior ﬂuid (the originally displaced
ﬂuid):
684
Chapter 13. Foundations of Fluid Dynamics

d
∂V
V
FIGURE 13.3 Derivation
of Archimedes’ law.
F buoy
i
= −

V
Tij;jdV .
(13.11b)
The displaced ﬂuid obviously is in hydrostatic equilibrium with the surrounding ﬂuid,
anditsequationofhydrostaticequilibriumTij;j = ρgi [Eq.(13.4)], wheninsertedinto
Eq. (13.11b), implies that
Fbuoy = −g

V
ρdV = −Mg,
(13.12)
where M is the mass of the displaced ﬂuid. Thus, the upward buoyant force on the
original body is equal in magnitude to the weight Mg of the displaced ﬂuid. Clearly,
if the body has a higher density than the ﬂuid, then the downward gravitational force
on it (its weight) will exceed the weight of the displaced ﬂuid and thus exceed the
buoyant force it feels, and the body will fall. If the body’s density is less than that
of the ﬂuid, the buoyant force will exceed its weight and it will be pushed upward.
short-range versus long-
range forces
A key piece of physics underlying Archimedes’ law is the fact that the inter-
molecular forces acting in a ﬂuid, like those in a solid (cf. Sec. 11.3.6), are short
range. If, instead, the forces were long range, Archimedes’ law could fail. For example,
consider a ﬂuid that is electrically conducting, with currents ﬂowing through it that
produce a magnetic ﬁeld and resulting long-range magnetic forces (the magnetohy-
drodynamic situation studied in Chap. 19). If we then substitute an insulating solid for
some region V of the conducting ﬂuid, the force that acts on the solid will be different
from the force that acted on the displaced ﬂuid.
EXERCISES
Exercise 13.2 Practice: Weight in Vacuum
How much more would you weigh in a vacuum?
Exercise 13.3 Problem: Stability of Boats
Use Archimedes’ law to explain qualitatively the conditions under which a boat ﬂoat-
ing in still water will be stable to small rolling motions from side to side. [Hint: You
might want to deﬁne and introduce a center of buoyancy and a center of gravity inside
13.3 Hydrostatics
685

center of gravity
center of buoyancy
FIGURE 13.4 The center of gravity and center of buoyancy of a boat when it is upright (left) and tilted
(right).
the boat, and pay attention to the change in the center of buoyancy when the boat
tilts. See Fig. 13.4.]
13.3.2
13.3.2 Nonrotating Stars and Planets
Stars and massive planets—if we ignore their rotation—are self-gravitating ﬂuid
spheres. We can model the structure of such a nonrotating, spherical, self-gravitating
ﬂuid body by combining the equation of hydrostatic equilibrium (13.4) in spherical
polar coordinates,
dP
dr = −ρ d
dr ,
(13.13)
with Poisson’s equation,
∇2 = 1
r2
d
dr

r2d
dr

= 4πGρ,
(13.14)
to obtain
1
r2
d
dr
r2
ρ
dP
dr

= −4πGρ.
(13.15)
Equation (13.15) can be integrated once radially with the aid of the boundary con-
dition dP/dr = 0 at r = 0 (pressure cannot have a cusp-like singularity) to obtain
equations of structure for
nonrotating star or planet
dP
dr = −ρ Gm
r2 ,
(13.16a)
where
m = m(r) ≡
 r
0
4πρr2dr
(13.16b)
is the total mass inside radius r. Equation (13.16a) is an alternative form of the
equation of hydrostatic equilibrium (13.13) at radius r inside the body: Gm/r2 is
the gravitational acceleration g at r, ρ(Gm/r2) = ρg is the downward gravitational
force per unit volume on the ﬂuid, and dP/dr is the upward buoyant force per unit
volume.
686
Chapter 13. Foundations of Fluid Dynamics

Equations (13.13)–(13.16b) are a good approximation for solid planets (e.g.,
Earth) as well as for stars and ﬂuid planets (e.g., Jupiter) because at the enormous
stresses encountered in the interior of a solid planet, the strains are so large that plas-
tic ﬂow occurs. In other words, the shear stresses are much smaller than the isotropic
part of the stress tensor.
Let us make an order-of-magnitude estimate of the interior pressure in a star or
planet of mass M and radius R. We use the equation of hydrostatic equilibrium (13.4)
or (13.16a), approximating m by M, the density ρ by M/R3, and the gravitational
acceleration by GM/R2; the result is
P ∼GM2
R4 .
(13.17)
To improve this estimate, we must solve Eq. (13.15). For that, we need a pre-
scription relating the pressure to the density (i.e., an equation of state). A common
idealization is the polytropic relation:
polytropic equation of
state
P ∝ρ1+1/n,
(13.18)
where n is the polytropic index (cf. last part of Box 13.2). [This ﬁnesses the issue of
the generation and ﬂow of heat in stellar interiors, which determines the temperature
T (r) and thence the pressure P(ρ, T ).] Low-mass white-dwarf stars are well approx-
imated as n = 1.5 polytropes [Eq. (3.53c)], and red-giant stars are somewhat similar
in structure to n = 3 polytropes. The giant planets, Jupiter and Saturn, are mainly
composed of an H-He ﬂuid that can be approximated by an n = 1 polytrope, and the
density of a small planet like Mercury is roughly constant (n = 0).
boundary conditions for
stellar/planetary structure
To solve Eqs. (13.16), we also need boundary conditions. We can choose some
density ρc and corresponding pressure Pc = P (ρc) at the star’s center r = 0, then
integrate Eqs. (13.16) outward until the pressure P drops to zero, which will be the
star’s (or planet’s) surface. The values of r and m there will be the star’s radius R and
mass M. For mathematical details of polytropic stellar models constructed in this
manner, see Ex. 13.4. This exercise is particularly important as an example of the
power of converting to dimensionless variables, a procedure we use frequently in this
part of the book.
We can easily solve the equations of hydrostatic equilibrium (13.16) for a planet
with constant density (n = 0) to obtain m = (4π/3)ρr3 and
P = P0

1 −r2
R2

,
(13.19)
where the central pressure is
pressure in constant-
density planet
P0 =
 3
8π
 GM2
R4 ,
(13.20)
consistent with our order-of-magnitude estimate (13.17).
13.3 Hydrostatics
687

EXERCISES
Exercise 13.4 **Example: Polytropes—The Power of Dimensionless Variables
When dealing with differential equations describing a physical system, it is often
helpful to convert to dimensionless variables. Polytropes (nonrotating, spherical ﬂuid
bodies with the polytropic equation of state P = Kρ1+1/n) are a nice example.
(a) Combine the two equations of stellar structure (13.16) to obtain a single second-
order differential equation for P and ρ as functions of r.
(b) Intheequationfrompart(a)setP = Kρ1+1/n toobtainanonlinear, second-order
differential equation for ρ(r).
(c) It is helpful to change dependent variables from ρ(r) to some other variable, call
it θ(r), so chosen that the quantity being differentiated is linear in θ and the only
θ nonlinearity is in the driving term. Show that choosing ρ ∝θn achieves this.
(d) It is helpful to choose the proportionality constant in ρ ∝θn in such a way that θ
is dimensionless and takes the value 1 at the polytrope’s center and 0 at its surface.
This is achieved by setting
ρ = ρcθn,
(13.21a)
where ρc is the polytrope’s (possibly unknown) central density.
(e) Similarly, it is helpful to make the independent variabler dimensionless by setting
r = aξ, where a is a constant with dimensions of length. The value of a should
be chosen wisely, so as to simplify the differential equation as much as possible.
Show that the choice
r = aξ ,
where a =
'
(n + 1)Kρ(1/n−1)
c
4πG
(1/2
,
(13.21b)
brings the differential equation into the form
1
ξ2
d
dξ ξ2dθ
dξ = −θn.
(13.22)
Equation (13.22) is called the Lane-Emden equation of stellar structure, after
Jonathan Homer Lane and Jacob Robert Emden, who introduced and explored
it near the end of the nineteenth century. There is an extensive literature on
solutions of the Lane-Emden equation (see, e.g., Chandrasekhar, 1939, Chap. 4;
Shapiro and Teukolsky, 1983, Sec. 3.3).
(f) Explain why the Lane-Emden equation (13.22) must be solved subject to the
following boundary conditions (where θ′ ≡dθ/dξ):
θ = 1
and
θ′ = 0
at ξ = 0.
(13.23)
(g) OnecanintegratetheLane-Emdenequation, numericallyoranalytically, outward
from ξ = 0 until some radius ξ1 at which θ (and thus also ρ and P ) goes to
zero. That is the polytrope’s surface. Its physical radius is then R = aξ1, and its
mass is M =
 R
0 4πρr2dr, which is readily shown to be M = 4πa3ρcξ2
1|θ′(ξ1)|.
688
Chapter 13. Foundations of Fluid Dynamics

Then, using the value of a given in Eq. (13.21b), we have:
R =
(n + 1)K
4πG
1/2
ρ(1−n)/2n
c
ξ1,
M = 4π
(n + 1)K
4πG
3/2
ρ(3−n)/2n
c
ξ2
1|θ′(ξ1)|,
(13.24a)
whence
M = 4πR(3−n)/(1−n)
(n + 1)K
4πG
n/(n−1)
ξ(n+1)/(n−1)
1
|θ′(ξ1)|.
(13.24b)
(h) When one converts a problem into dimensionless variables that satisfy some
differential or algebraic equation(s) and then expresses physical quantities in
terms of the dimensionless variables, the resulting expressions describe how the
physical quantities scale with one another. As an example, Jupiter and Saturn
are both made up of an H-He ﬂuid that is well approximated by a polytrope
of index n = 1, P = Kρ2, with the same constant K. Use the information that
MJ = 2 × 1027 kg, RJ = 7 × 104 km, and MS = 6 × 1026 kg to estimate the radius
of Saturn. For n = 1, the Lane-Emden equation has a simple analytical solution:
θ = sin ξ/ξ. Compute the central densities of Jupiter and Saturn.
13.3.3
13.3.3 Rotating Fluids
The equation of hydrostatic equilibrium (13.4) and the applications of it discussed
above are valid only when the ﬂuid is static in a nonrotating reference frame. However,
they are readily extended to bodies that rotate rigidly with some uniform angular
velocity  relative to an inertial frame. In a frame that corotates with the body, the
ﬂuid will have vanishing velocity v (i.e., will be static), and the equation of hydrostatic
equilibrium (13.4) will be changed only by the addition of the centrifugal force per
unit volume:
hydrostatic equilibrium in
corotating reference frame
∇P = ρ(g + gcen) = −ρ∇( + cen).
(13.25)
Here
gcen = − × ( × r) = −∇cen
(13.26)
is the centrifugal acceleration, ρgcen is the centrifugal force per unit volume, and
cen = −1
2( × r)2
(13.27)
is a centrifugal potential whose gradient is equal to the centrifugal acceleration
when  is constant. The centrifugal potential can be regarded as an augmenta-
tion of the gravitational potential . Indeed, in the presence of uniform rotation, all
hydrostatic theorems for
rotating body
hydrostatic theorems [e.g., Eqs. (13.7) and (13.8)] remain valid in the corotating refer-
ence frame with  replaced by  + cen.
13.3 Hydrostatics
689

We can illustrate this by considering the shape of a spinning ﬂuid planet. Let us
suppose that almost all the planet’s mass is concentrated in its core, so the gravitational
potential  = −GM/r is unaffected by the rotation. The surface of the planet must
be an equipotential of  + cen [coinciding with the zero-pressure isobar; cf. the sen-
tence following Eq. (13.8), with  → + cen]. The contribution of the centrifugal
potential at the equator is −2R2
e/2, and at the pole it is zero. The difference in the
gravitational potential  between the equator and the pole is ≃g(Re −Rp) where
Re and Rp are the equatorial and polar radii, respectively, and g is the gravitational
acceleration at the planet’s surface. Therefore, adopting this centralized-mass model
and requiring that  + cen be the same at the equator as at the pole, we estimate the
difference between the polar and equatorial radii to be
centrifugal ﬂattening
Re −Rp ≃2R2
2g .
(13.28a)
Earth, although not a ﬂuid, is unable to withstand large shear stresses, because its
shear strain cannot exceed the yield strain of rock, ∼0.001; see Sec. 11.3.2 and Table
11.1. Since the heights of the tallest mountains are also governed by the yield strain,
Earth’s surface will not deviate from its equipotential by more than the maximum
height of a mountain, ≃9 km.
If, for Earth, we substitute g ≃10 m s−2, R ≃6 × 106 m, and  ≃7×
10−5 rad s−1 into Eq. (13.28a), we obtain Re −Rp ≃10 km, about half the correct
value of 21 km. The reason for this discrepancy lies in our assumption that all the
planet’s mass resides at its center. In fact, the mass is distributed fairly uniformly in
radius and, in particular, some mass is found in the equatorial bulge. This deforms
the gravitational equipotential surfaces from spheres to ellipsoids, which accentuates
the ﬂattening. If, following Newton (in his Principia Mathematica,published in 1687),
we assume that Earth has uniform density, then the ﬂattening estimate is 2.5 times
larger than our centralized-mass estimate (Ex. 13.5) (i.e., Re −Rp ≃25 km), in fairly
good agreement with Earth’s actual shape.
EXERCISES
Exercise 13.5 Example: Shape of a Constant-Density, Spinning Planet
(a) Show that the spatially variable part of the gravitational potential for a uniform-
density, nonrotating planet can be written as  = 2πGρr2/3, where ρ is the
density.
(b) Hence argue that the gravitational potential for a slowly spinning planet can be
written in the form
 = 2πGρr2
3
+ Ar2P2(μ),
where A is a constant, and P2 is the Legendre polynomial with argument μ =
sin(latitude). What happens to the P1 term?
690
Chapter 13. Foundations of Fluid Dynamics

(c) Give an equivalent expansion for the potential outside the planet.
(d) Now transform into a frame spinning with the planet, and add the centrifugal
potential to give a total potential.
(e) By equating the potential and its gradient at the planet’s surface, show that the
difference between the polar and the equatorial radii is given by
Re −Rp ≃52R2
4g
,
(13.28b)
where g is the gravitational acceleration at the surface. Note that this is 5/2 times
the answer for a planet whose mass is concentrated at its center [Eq. (13.28a)].
Exercise 13.6 Problem: Shapes of Stars in a Tidally Locked Binary System
Consider two stars with the same mass M orbiting each other in a circular orbit
with diameter (separation between the stars’ centers) a. Kepler’s laws tell us that
the stars’ orbital angular velocity is  =

2GM/a3. Assume that each star’s mass
is concentrated near its center, so that everywhere except near a star’s center the
gravitational potential, in an inertial frame, is  = −GM/r1 −GM/r2 with r1 and
r2 the distances of the observation point from the center of star 1 and star 2. Suppose
that the two stars are “tidally locked”: tidal gravitational forces have driven them each
to rotate with rotational angular velocity equal to the orbital angular velocity . (The
Moon is tidally locked to Earth, which is why it always keeps the same face toward
Earth.) Then in a reference frame that rotates with angular velocity , each star’s gas
will be at rest, v = 0.
(a) Write down the total potential  + cen for this binary system in the rotating
frame.
(b) Using Mathematica, Maple, Matlab, or some other computer software, plot the
equipotentials  + cen = const for this binary in its orbital plane, and use these
equipotentials to describe the shapes that these stars will take if they expand to
larger and larger radii (with a and M held ﬁxed). You should obtain a sequence
in which the stars, when compact, are well separated and nearly round. As they
grow, tidal gravity elongates them ultimately into tear-drop shapes, followed by
merger into a single, highly distorted star. With further expansion, the merged
star starts ﬂinging mass off into the surrounding space (a process not included in
this hydrostatic analysis).
13.4
13.4 Conservation Laws
As a foundation for the transition from hydrostatics to hydrodynamics [i.e., to situa-
tions with nonzero ﬂuid velocity v(x, t)], we give a general discussion of Newtonian
conservation laws, focusing especially on the conservation of mass and of linear
momentum.
13.4 Conservation Laws
691

We begin with the differential law of mass conservation,
mass conservation:
differential form
∂ρ
∂t + ∇. (ρv) = 0,
(13.29)
which we met and used in our study of elastic media [Eq. (12.2c)]. Eq. (13.29) is
the obvious analog of the laws of conservation of charge, ∂ρe/∂t + ∇. j = 0, and of
particles, ∂n/∂t + ∇. S = 0, which we met in Chap. 1 [Eqs. (1.30)]. In each case the
law has the form (∂/∂t)(density of something) +∇. (ﬂux of that something) = 0. In
fact, this form is universal for a differential conservation law.
Each Newtonian differential conservation law has a corresponding integral con-
servation law (Sec. 1.8), which we obtain by integrating the differential law over
some arbitrary 3-dimensional volume V, for example, the volume used in Fig. 13.3
to discuss Archimedes’ law: (d/dt)

V ρdV =

V(∂ρ/∂t)dV = −

V ∇. (ρv)dV .
Applying Gauss’s law to the last integral, we obtain
mass conservation:
integral form
d
dt

V
ρdV = −

∂V
ρv . d,
(13.30)
where ∂V is the closed surface bounding V. The left-hand side is the rate of change
of mass inside the region V. The right-hand side is the rate at which mass ﬂows into
V through ∂V (since ρv is the mass ﬂux, and the inward pointing surface element is
−d). This is the same argument, connecting differential to integral conservation
laws, as we gave when deriving Eqs. (1.29) and (1.30) for electric charge and for
particles, but going in the opposite direction. And this argument depends in no way
on whether the ﬂowing material is a ﬂuid or not. The mass conservation laws (13.29)
and (13.30) are valid for any kind of material.
Writing the differential conservation law in the form (13.29), where we monitor
the changing density at a given location in space rather than moving with the material,
is called the Eulerian approach. There is an alternative Lagrangian approach to mass
conservation, in which we focus on changes of density as measured by somebody
who moves, locally, with the material (i.e., with velocity v). We obtain this approach
by differentiating the product ρv in Eq. (13.29) to obtain
mass conservation:
alternative differential
form
dρ
dt = −ρ∇. v,
(13.31)
where
convective (advective)
time derivative
d
dt ≡∂
∂t + v . ∇.
(13.32)
The operator d/dt is known as the convective time derivative (or advective time deriva-
tive) and crops up often in continuum mechanics. Its physical interpretation is very
692
Chapter 13. Foundations of Fluid Dynamics

simple. Consider ﬁrst the partial derivative (∂/∂t)x. This is the rate of change of some
quantity [the density ρ in Eq. (13.31)] at a ﬁxed point x in space in some reference
frame. In other words, if there is motion, ∂/∂t compares this quantity at the same
point P in space for two different points in the material: one that is at P at time
t + dt; the other that was at P at the earlier time t. By contrast, the convective time
derivative d/dt follows the motion, taking the difference in the value of the quantity
at successive times at the same point in the moving matter. It is the time derivative for
the Lagrangian approach.
For a ﬂuid, the Lagrangian approach can also be expressed in terms of ﬂuid
elements.Considerasmallﬂuidelementwithaboundingsurfaceattachedtotheﬂuid,
and denote its volume by V . The mass inside the ﬂuid element is M = ρV . As the ﬂuid
ﬂows, this mass must be conserved, so dM/dt = (dρ/dt)V + ρ(dV/dt) = 0, which
we can rewrite as
Lagrangian formulation of
mass conservation
dρ
dt = −ρ dV/dt
V
.
(13.33)
Comparing with Eq. (13.31), we see that
∇. v = dV/dt
V
.
(13.34)
Thus, the divergence of v is the fractional rate of increase of a ﬂuid element’s volume.
NoticethatthisisjustthetimederivativeofourelastostaticequationV/V = ∇. ξ =
 [Eq. (11.7)] (since v = dξ/dt). Correspondingly we denote
rate of expansion of ﬂuid
∇. v ≡θ = d/dt,
(13.35)
and call it the ﬂuid’s rate of expansion.
Equation (13.29), ∂ρ/∂t + ∇. (ρv) = 0, is our model for Newtonian conservation
laws. It says that there is a quantity (in this case mass) with a certain density (ρ), and
a certain ﬂux (ρv), and this quantity is neither created nor destroyed. The temporal
derivative of the density (at a ﬁxed point in space) added to the divergence of the
ﬂux must vanish. Of course, not all physical quantities have to be conserved. If there
were sources or sinks of mass, then these would be added to the right-hand side of
Eq. (13.29).
Now turn to momentum conservation. The (Newtonian) law of momentum con-
servation must take the standard conservation-law form (∂/∂t)(momentum density)
+∇. (momentum ﬂux) = 0.
If we just consider the mechanical momentum associated with the motion of mass,
its density is the vector ﬁeld ρv. There can also be other forms of momentum density
(e.g., electromagnetic), but these do not enter into Newtonian ﬂuid mechanics. For
ﬂuids, as for an elastic medium (Chap. 12), the momentum density is simply ρv.
13.4 Conservation Laws
693

The momentum ﬂux is more interesting and rich. Quite generally it is, by deﬁni-
tion, the stress tensor T, and the differential conservation law states
momentum conservation:
Eulerian formulation
∂(ρv)
∂t
+ ∇. T = 0
(13.36)
[Eq. (1.36)]. For an elastic medium, T = −Kg −2μ [Eq. (11.18)], and the con-
servation law (13.36) gives rise to the elastodynamic phenomena that we explored in
Chap. 12. For a ﬂuid we build up T piece by piece.
We begin with the rate dp/dt that mechanical momentum ﬂows through a small
element of surface area d, from its back side to its front. The rate that mass ﬂows
through is ρv . d, and we multiply that mass by its velocity v to get the momentum
ﬂow rate: dp/dt = (ρv)(v . d). This rate of ﬂow of momentum is the same thing as
a force F = dp/dt acting across d; so it can be computed by inserting d into the
second slot of a “mechanical” stress tensor Tm: dp/dt = Tm(
, d) [cf. the deﬁnition
(1.32)ofthestresstensor].Bywritingthesetwoexpressionsforthemomentumﬂowin
index notation, dpi/dt = (ρvi)vjdj = Tm ijdj, we read off the mechanical stress
tensor: Tm ij = ρvivj:
mechanical stress tensor
Tm = ρv ⊗v.
(13.37)
This tensor is symmetric (as any stress tensor must be; Sec. 1.9), and it obviously
is the ﬂux of mechanical momentum, since it has the form (momentum density) ⊗
(velocity).
force fff per unit volume
acting on ﬂuid
Let us denote by f the net force per unit volume that acts on the ﬂuid. Then instead
of writing momentum conservation in the usual Eulerian differential form (13.36), we
can write it as
∂(ρv)
∂t
+ ∇. Tm = f
(13.38)
(conservation law with a source on the right-hand side). Inserting Tm = ρv ⊗v into
thisequation, convertingtoindexnotation, usingtherulefordifferentiatingproducts,
and combining with the law of mass conservation, we obtain the Lagrangian law
momentum conservation:
Lagrangian formulation
ρ dv
dt = f.
(13.39)
Here d/dt = ∂/∂t + v . ∇is the convective time derivative (i.e., the time derivative
moving with the ﬂuid); so this equation is just Newton’s F = ma, per unit volume. For
the equivalent equations (13.38) and (13.39) of momentum conservation to also be
equivalent to the Eulerian formulation (13.36), there must be a stress tensor Tf such
that
stress tensor for the
force fff
f = −∇. Tf;
and
T = Tm + Tf.
(13.40)
Then Eq. (13.38) becomes the Eulerian conservation law (13.36).
694
Chapter 13. Foundations of Fluid Dynamics

Evidently, a knowledge of the stress tensor Tf for some material is equivalent to
stress tensor for force
density fff
a knowledge of the force density f that acts on the material. It often turns out to be
much easier to ﬁgure out the form of the stress tensor, for a given situation, than
the form of the force. Correspondingly, as we add new pieces of physics to our ﬂuid
analysis (e.g., isotropic pressure, viscosity, gravity, magnetic forces), an efﬁcient way
to proceed at each stage is to insert the relevant physics into the stress tensor Tf and
force density as divergence
of stress tensor
then evaluate the resulting contribution f = −∇. Tf to the force density and thence
to the Lagrangian law of force balance (13.39). At each step, we get out in the form
f = −∇. Tf the physics that we put into Tf.
There may seem something tautological about the procedure (13.40) by which we
went from the Lagrangian F = ma equation (13.39) to the Eulerian conservation law
(13.36), (13.40). The F = ma equation makes it look like mechanical momentum is
not conserved in the presence of the force density f. But we make it be conserved
by introducing the momentum ﬂux Tf. It is almost as if we regard conservation of
momentum as a principle to be preserved at all costs, and so every time there appears
to be a momentum deﬁcit, we simply deﬁne it as a bit of the momentum ﬂux. However,
this is not the whole story. What is important is that the force density f can always
be expressed as the divergence of a stress tensor; that fact is central to the nature of
force and of momentum conservation. An erroneous formulation of the force would
not necessarily have this property, and so no differential conservation law could
be formulated. Therefore, the fact that we can create elastostatic, thermodynamic,
viscous, electromagnetic, gravitational, etc. contributions to some grand stress tensor
(that go to zero outside the regions occupied by the relevant matter or ﬁelds)—as we
shall do in the coming chapters—is signiﬁcant. It afﬁrms that our physical model is
complete at the level of approximation to which we are working.
We can proceed in the same way with energy conservation as we have with mo-
mentum. There is an energy density U(x, t) for a ﬂuid and an energy ﬂux F(x, t), and
energy density UUU, energy
ﬂux FFF, and energy
conservation
they obey a conservation law with the standard form
∂U
∂t + ∇. F = 0.
(13.41)
At each stage in our buildup of ﬂuid dynamics (adding, one by one, the inﬂuences of
compressional energy, viscosity, gravity, and magnetism), we can identify the relevant
contributions to U and F and then grind out the resulting conservation law (13.41).
At each stage we get out the physics that we put into U and F.
13.5
13.5 The Dynamics of an Ideal Fluid
We now use the general conservation laws of the previous section to derive the
fundamental equations of ﬂuid dynamics. We do so in several stages. In this section
and Sec. 13.6, we conﬁne our attention to ideal ﬂuids—ﬂows for which it is safe to
13.5 The Dynamics of an Ideal Fluid
695

ignore dissipative processes (viscosity and thermal conductivity) and thus for which
the entropy of a ﬂuid element remains constant with time. In Sec. 13.7, we introduce
the effects of viscosity and diffusive heat ﬂow.
13.5.1
13.5.1 Mass Conservation
As we have seen, mass conservation takes the (Eulerian) form ∂ρ/∂t + ∇. (ρv) = 0
[Eq. (13.29)], or equivalently the (Lagrangian) form dρ/dt = −ρ∇. v [Eq. (13.31)],
where d/dt = ∂/∂t + v . ∇is the convective time derivative [i.e., the time derivative
moving with the ﬂuid; Eq. (13.32)].
As we shall see in Sec. 13.6, when ﬂow speeds are small compared to the speed of
sound and the effects of gravity are sufﬁciently modest, the density of a ﬂuid element
remains nearly constant: |(1/ρ)dρ/dt| = |∇. v| ≪1/τ, where τ is the ﬂuid ﬂow’s
characteristic timescale. It is then a good approximation to rewrite the law of mass
incompressible
approximation
conservation as ∇. v = 0, which is the incompressible approximation.
13.5.2
13.5.2 Momentum Conservation
For an ideal ﬂuid, the only forces that can act are those of gravity and of the ﬂuid’s
isotropic pressure P. We have already met and discussed the contribution of P
to the stress tensor, T = P g, when dealing with elastic media (Chap. 11) and in
hydrostatics (Sec. 13.3). The gravitational force density ρg is so familiar that it is
easier to write it down than the corresponding gravitational contribution to the stress.
Correspondingly, we can most easily write momentum conservation in the form
momentum conservation
for an ideal ﬂuid
∂(ρv)
∂t
+ ∇. T = ρg;
or
∂(ρv)
∂t
+ ∇. (ρv ⊗v + P g) = ρg,
(13.42)
where the stress tensor is given by
stress tensor for an ideal
ﬂuid
T = ρv ⊗v + P g
for an ideal ﬂuid
(13.43)
[cf. Eqs. (13.37), (13.38), and (13.4)]. The ﬁrst term, ρv ⊗v, is the mechanical
momentum ﬂux (also called the kinetic stress), and the second, P g, is that associated
with the ﬂuid’s pressure.
In most of our Newtonian applications, the gravitational ﬁeld g will be externally
imposed (i.e., it will be produced by some object, e.g., Earth that is different from
the ﬂuid we are studying). However, the law of momentum conservation remains the
same [Eq. (13.42)], independently of what produces gravity—the ﬂuid, or an external
body, or both. And independently of its source, one can write the stress tensor Tg
for the gravitational ﬁeld g in a form presented and discussed in the Track-Two Box
13.4 later in the chapter—a form that has the required property −∇. Tg = ρg = (the
gravitational force density).
696
Chapter 13. Foundations of Fluid Dynamics

13.5.3
13.5.3 Euler Equation
The Euler equation is the equation of motion that one gets out of the momentum
conservation law (13.42) for an ideal ﬂuid by performing the differentiations and
invoking mass conservation (13.29):3
Euler equation
(momentum conservation)
for an ideal ﬂuid
dv
dt ≡∂v
∂t + (v . ∇)v = −∇P
ρ
+ g
for an ideal ﬂuid.
(13.44)
The Euler equation has a simple physical interpretation: dv/dt is the convective
derivative of the velocity (i.e., the derivative moving with the ﬂuid), which means it is
the acceleration felt by the ﬂuid. This acceleration has two causes: gravity, g, and the
pressure gradient, ∇P. In a hydrostatic situation, v = 0, the Euler equation reduces
to the equation of hydrostatic equilibrium: ∇P = ρg [Eq. (13.4)].
In Cartesian coordinates, the Euler equation (13.44) and mass conservation
dρ/dt + ρ∇. v = 0[Eq.(13.31)]comprisefourequationsinﬁveunknowns, ρ, P , vx,
vy, and vz. The remaining ﬁfth equation gives P as a function of ρ. For an ideal ﬂuid,
this equation comes from the fact that the entropy of each ﬂuid element is conserved
(because there is no mechanism for dissipation):
entropy conservation
ds
dt = 0,
(13.45)
together with an equation of state for the pressure in terms of the density and the en-
tropy: P = P(ρ, s). In practice, the equation of state is often well approximated by in-
compressibility, ρ = const, or by a polytropic relation, P = K(s)ρ1+1/n [Eq. (13.18)].
13.5.4
13.5.4 Bernoulli’s Theorem
Bernoulli’s theorem is well known. Less well appreciated are the conditions under
which it is true. To deduce these, we must ﬁrst introduce a kinematic quantity known
as the vorticity:
vorticity
ω ≡∇× v.
(13.46)
The physical interpretation of vorticity is simple. Consider a small ﬂuid element. As it
moves and deforms over a tiny period of time δt, each bit of ﬂuid inside it undergoes a
tiny displacement ξ = vδt. The gradient of that displacement ﬁeld can be decomposed
into an expansion, rotation, and shear (as we discussed in the context of an elastic
mediuminSec.11.2.2).Thevectorialangleoftherotationisφ = 1
2∇× ξ [Eq.(11.9b)].
The time derivative of that vectorial angle, dφ/dt = 1
2dξ/dt = 1
2∇× v, is obviously
angular velocity of a ﬂuid
element
the ﬂuid element’s rotational angular velocity; hence the vorticity ω = ∇× v is twice
3.
This equation was ﬁrst derived in 1757 by the Swiss mathematician and physicist Leonhard Euler—the
same Euler who formulated the theory of buckling of a compressed beam (Sec. 11.6.1).
13.5 The Dynamics of an Ideal Fluid
697

the angular velocity of rotation of a ﬂuid element. Vorticity plays a major role in ﬂuid
mechanics, as we shall see in Chap. 14.
To derive Bernoulli’s theorem (with the aid of vorticity), we begin with the Euler
equation for an ideal ﬂuid, dv/dt = −(1/ρ)∇P + g. We express g as −∇ and
convert the convective derivative of velocity (i.e., the acceleration) into its two parts
dv/dt = ∂v/∂t + (v . ∇)v. Then we rewrite (v . ∇)v using the vector identity
v × ω ≡v × (∇× v) = 1
2∇v2 −(v . ∇)v.
(13.47)
The result is
Bernoulli’s theorem: most
general version
∂v
∂t + ∇
1
2v2 + 

+ ∇P
ρ
−v × ω = 0.
(13.48)
This is just the Euler equation written in a new form, but it is also the most general
version of Bernoulli’s theorem—valid for any ideal ﬂuid. Two special cases are of
interest.
BERNOULLI’S THEOREM FOR STEADY FLOW OF AN IDEAL FLUID
Since the ﬂuid is ideal, dissipation (due to viscosity and heat ﬂow) can be ignored, so
the entropy is constant following the ﬂow: ds/dt = (v . ∇)s = 0. When, in addition,
the ﬂow is steady, meaning ∂(everything)/∂t = 0, the thermodynamic identity dh =
T ds + dP/ρ [Eq. (3) of Box 13.2] combined with ds/dt = 0 implies
(v . ∇)P = ρ(v . ∇) h.
(13.49)
Dotting the velocity v into the most general Bernoulli theorem (13.48) and invoking
Eq. (13.49) and ∂v/∂t = 0, we obtain
dB
dt = (v . ∇)B = 0,
(13.50)
where
Bernoulli function
B ≡1
2v2 + h + .
(13.51)
Equation (13.50) states that in a steady ﬂow of an ideal ﬂuid, the Bernoulli function B,
like the entropy, is conserved moving with a ﬂuid element. This is the most elementary
Bernoulli’s theorem for
steady ﬂow of an ideal ﬂuid
form of the Bernoulli theorem.
Let us deﬁne streamlines, analogous to lines of force of a magnetic ﬁeld, by the
differential equations
streamlines
dx
vx
= dy
vy
= dz
vz
.
(13.52)
In the language of Sec. 1.5, these are just the integral curves of the (steady) velocity
ﬁeld; they are also the spatial world lines of ﬂuid elements. Equation (13.50) states: In
a steady ﬂow of an ideal ﬂuid, the Bernoulli function B is constant along streamlines.
698
Chapter 13. Foundations of Fluid Dynamics

BOX 13.3.
FLOW VISUALIZATION
Various methods are used to visualize ﬂuid ﬂows. One way is via streamlines,
which are the integral curves of the velocity ﬁeld v at a given time [Eq.
(13.52)]. Streamlines are the analog of magnetic ﬁeld lines. They coincide
with the paths of individual ﬂuid elements if the ﬂow is steady, but not if
the ﬂow is time dependent. In general, the paths are the solutions of the
equation dx/dt = v(x, t). These paths are the analog of particle trajectories
in mechanics.
Another type of ﬂow line is a streak. Monitoring streaks is a common
way of visualizing a ﬂow experimentally. Streaks are usually produced by
introducing some colored or ﬂuorescent tracer into the ﬂow continuously at
some ﬁxed release point xr, and observing the locus of the tracer at some ﬁxed
time, say, t0. Each point on the streak can be parameterized by the common
release point xr, the common time of observation t0, and the time tr at which
its marker was released, x(xr, tr; t0); so the streak is the parameterized curve
x(tr) = x(xr, tr; t0).
Examples of streamlines, paths, and streaks are sketched below.
streamlines
t = t0 = const
v
v
x0
xr
x(t)
paths
streak
individual paths
Streamlines are a powerful way to visualize ﬂuid ﬂows. There are other ways, sketched
in Box 13.3.
The Bernoulli function B = 1
2v2 + h +  = 1
2v2 + u + P/ρ +  has a simple
physical meaning. It is the ﬂuid’s total energy density (kinetic plus internal plus
potential) per unit mass, plus the work P (1/ρ) that must be done to inject a unit
mass of ﬂuid (with volume 1/ρ) into surrounding ﬂuid that has pressure P . This goes
hand in hand with the enthalpy h = u + P/ρ being the injection energy (per unit
mass) in the absence of kinetic and potential energy; see the last part of Ex. 5.5. This
meaning of B leads to the following physical interpretation of the constancy of B for
a stationary, ideal ﬂow.
In a steady ﬂow of an ideal ﬂuid, consider a stream tube made of a bundle of
streamlines(Fig.13.5).AﬂuidelementwithunitmassoccupiesregionA ofthestream
13.5 The Dynamics of an Ideal Fluid
699

B
A
FIGURE 13.5 A stream tube used to explain the Bernoulli
theorem for stationary ﬂow of an ideal ﬂuid.
tube at some early time and has moved into region B at some later time. When it
vacates region A, the ﬂuid element carries an energy B [including the energy P(1/ρ)
it acquires by being squeezed out of A by the pressure of the surrounding ﬂuid]. When
it moves into region B, it similarly carries the total injection energy B. Because the
ﬂow is steady, the energy it extracts from A must be precisely what it needs to occupy
B (i.e., B mustbeconstantalongthestreamtube, andhencealsoalongeachstreamline
in the tube).
The most immediate consequence of Bernoulli’s theorem for steady ﬂow is that, if
gravity is having no signiﬁcant effect, then the enthalpy falls when the speed increases,
and conversely. This is just the conversion of internal (injection) energy into bulk
kinetic energy, and conversely. For our ideal ﬂuid, entropy must be conserved moving
with a ﬂuid element, so the ﬁrst law of thermodynamics says dh = T ds + dP/ρ =
dP/ρ. Therefore, as the speed increases and h decreases, P will also decrease.
Pitot tube
This behavior is the foundation for the Pitot tube, a simple device used to measure
the air speed of an aircraft (Fig. 13.6). The Pitot tube extends out from the side
of the aircraft, all the way through a boundary layer of slow-moving air and into
the bulk ﬂow. There it bends into the ﬂow. The Pitot tube is actually two tubes: (i)
an outer tube with several oriﬁces along its sides, past which the air ﬂows with its
incoming speed V and pressure P, so the pressure inside that tube is also P; and
(ii) an inner tube with a small oriﬁce at its end, where the ﬂowing air is brought
essentially to rest (to stagnation). At this stagnation point and inside the oriﬁce’s inner
tube, the pressure, by Bernoulli’s theorem with  and ρ both essentially constant, is
the stagnation pressure: Pstag = P + 1
2ρV 2. The pressure difference P = Pstag −P
stagnation pressure
between the two tubes is measured by an instrument called a manometer,from which
the air speed is computed as V = (2P/ρ)1/2. If V ∼100 m s−1 and ρ ∼1 kg m−3,
then P ∼5,000 N m−3 ∼0.05 atmospheres.
In this book, we shall meet many other applications of the Bernoulli theorem for
steady, ideal ﬂows.
BERNOULLI’S THEOREM FOR IRROTATIONAL FLOW OF AN IDEAL, ISENTROPIC FLUID
An even more specialized type of ﬂow is one that is isentropic (so s is the same every-
where) and irrotational (meaning its vorticity vanishes everywhere), as well as ideal.
700
Chapter 13. Foundations of Fluid Dynamics

air
O
O
O
air
S
manometer
V
V
M
FIGURE 13.6 Schematic illustration of a Pitot tube used to measure
air speed. The manometer M measures the pressure difference
between the stagnation point S and the oriﬁces O.
(In Sec. 14.2, we shall learn that if an incompressible ﬂow initially is irrotational and
it encounters no walls and experiences no signiﬁcant viscous stresses, then it remains
irrotational.) As ω = ∇× v vanishes, we can follow the electrostatic precedent and
introduce a velocity potential ψ(x, t), so that at any time,
velocity potential for
irrotational (vorticity-free)
ﬂow
v = ∇ψ
for an irrotational ﬂow.
(13.53)
The ﬁrst law of thermodynamics [Eq. (3) of Box 13.2] implies that ∇h = T ∇s +
(1/ρ)∇P. Therefore, in an isentropic ﬂow, ∇P = ρ∇h. Imposing these conditions
on Eq. (13.48), we obtain, for a (possibly unsteady) isentropic, irrotational ﬂow:
Bernoulli’s theorem for
isentropic, irrotational
ﬂow of an ideal ﬂuid
∇
∂ψ
∂t + B

= 0.
(13.54)
Thus in an isentropic, irrotational ﬂow of an ideal ﬂuid, the quantity ∂ψ/∂t + B is
constant everywhere.(If ∂ψ/∂t + B is a function of time, we can absorb that function
into ψ without affecting v, leaving it constant in time as well as in space.) Of course,
if the ﬂow is steady, so ∂(everything)/∂t = 0, then B itself is constant.
EXERCISES
Exercise 13.7 Problem: A Hole in My Bucket
There’s a hole in my bucket. How long will it take to empty? (Try an experiment, and
if the time does not agree with the estimate, explain why not.)
Exercise 13.8 Problem: Rotating Planets, Stars, and Disks
Consider a stationary, axisymmetric planet, star, or disk differentially rotating under
the action of a gravitational ﬁeld. In other words, the motion is purely in the azimuthal
direction.
13.5 The Dynamics of an Ideal Fluid
701

(a) Suppose that the ﬂuid has a barotropic equation of state P = P (ρ). Write down
the equations of hydrostatic equilibrium, including the centrifugal force, in cylin-
drical polar coordinates. Hence show that the angular velocity must be constant
on surfaces of constant cylindrical radius. This is called von Zeipel’s theorem. (As
an application, Jupiter is differentially rotating and therefore might be expected
to have similar rotation periods at the same latitudes in the north and the south.
This is only roughly true, suggesting that the equation of state is not completely
barotropic.)
(b) Now suppose that the structure is such that the surfaces of constant entropy per
unit mass and angular momentum per unit mass coincide. (This state of affairs
can arise if slow convection is present.) Show that the Bernoulli function (13.51)
is also constant on these surfaces. [Hint: Evaluate ∇B.]
Exercise 13.9 **Problem: Crocco’s Theorem
(a) Consider steady ﬂow of an ideal ﬂuid. The Bernoulli function (13.51) is conserved
along streamlines. Show that the variation of B across streamlines is given by
Crocco’s theorem:
∇B = T ∇s + v × ω.
(13.55)
(b) As an example, consider the air in a tornado. In the tornado’s core, the velocity
vanishes; it also vanishes beyond the tornado’s outer edge. Use Crocco’s theorem
to show that the pressure in the core is substantially different from that at the outer
edge. Is it lower, or is it higher? How does this explain the ability of a tornado to
make the walls of a house explode? For more detail, see Ex. 14.5.
Exercise 13.10 Problem: Cavitation (Suggested by P. Goldreich)
A hydrofoil moves with speed V at a depth D = 3 m below the surface of a lake;
see Fig. 13.7. Estimate how fast V must be to make the water next to the hydrofoil
boil. [This boiling, which is called cavitation, results from the pressure P trying to go
negative (see, e.g., Batchelor, 2000, Sec. 6.12; Potter, Wiggert, and Ramadan, 2012,
Sec. 8.3.4).] [Note: For a more accurate value of the speed V that triggers cavitation,
V
D
hydrofoil
FIGURE 13.7 Water ﬂowing past a hydrofoil as seen in
the hydrofoil’s rest frame.
702
Chapter 13. Foundations of Fluid Dynamics

one would have to compute the velocity ﬁeld v(x) around the hydrofoil—for example,
using the method of Ex. 14.17—and identify the maximum value of v = |v| near the
hydrofoil’s surface.]
Exercise 13.11 Example: Collapse of a Bubble
Suppose that a spherical bubble has just been created in the water above the hydrofoil
in the previous exercise. Here we analyze its collapse—the decrease of the bubble’s
radius R(t) from its value Ro at creation, using the incompressible approximation
(which is rather good in this situation). This analysis is an exercise in solving the
Euler equation.
(a) Introduce spherical polar coordinates with origin at the center of the bubble,
so the collapse entails only radial ﬂuid motion, v = v(r, t)er. Show that the
incompressibility approximation ∇. v = 0 implies that the radial velocity can be
written in the form v = w(t)/r2. Then use the radial component of the Euler
equation (13.44) to show that
1
r2
dw
dt + v ∂v
∂r + 1
ρ
∂P
∂r = 0.
At ﬁxed time t, integrate this outward from the bubble surface at radius R(t) to
a large enough radius that the bubble’s inﬂuence is no longer felt. Thereby obtain
−1
R
dw
dt + 1
2
˙R2(R) = P0
ρ ,
where P0 is the ambient pressure and −˙R(R) is the speed of collapse of the
bubble’s surface when its radius is R. Assuming vanishing collapse speed when
the bubble is created, ˙R(Ro) = 0, show that
˙R(R) = −
2P0
3ρ
1/2 'R0
R
3
−1
(1/2
,
which can be integrated to get R(t).
(b) Suppose that bubbles formed near the pressure minimum on the surface of the
hydrofoil are swept back onto a part of the surface where the pressure is much
larger. By what factor Ro/R must the bubbles collapse if they are to create stresses
that inﬂict damage on the hydrofoil?
Pistol shrimp can create collapsing bubbles and use the shock waves to stun their
prey. A modiﬁcation of this solution is important in interpreting the fascinating phe-
nomenon of sonoluminescence (Brenner, Hilgenfeldt, and Lohse, 2002), which arises
when ﬂuids are subjected to high-frequency acoustic waves that create oscillating
bubbles. The temperatures inside these bubbles can get so large that the air becomes
ionized and radiates.
13.5 The Dynamics of an Ideal Fluid
703

13.5.5
13.5.5 Conservation of Energy
As well as imposing conservation of mass and momentum, we must also address
energy conservation in its general form (by contrast with the specialized version of
energy conservation inherent in Bernoulli’s theorem for a stationary, ideal ﬂow).
In general, energy conservation is needed for determining the temperature T of a
ﬂuid, whichinturnisneededtocomputethepressureP (ρ, T ).Sofarinourtreatment
of ﬂuid dynamics, we have ﬁnessed this issue by either postulating some relationship
between the pressure P and the density ρ (e.g., the polytropic relation P = Kργ) or
by focusing on the ﬂow of ideal ﬂuids, where the absence of dissipation guarantees the
entropyisconstantmovingwiththeﬂow, sothatP = P (ρ, s)withconstants.Inmore
generalsituations, onecannotavoidconfrontingenergyconservation.Moreover, even
for ideal ﬂuids, understanding how energy is conserved is often useful for gaining
physical insight—as we have seen in our discussion of Bernoulli’s theorem.
The most fundamental formulation of the law of energy conservation is Eq.
(13.41): ∂U/∂t + ∇. F = 0. To explore its consequences for an ideal ﬂuid, we must
insert the appropriate ideal-ﬂuid forms of the energy density U and energy ﬂux F.
When (for simplicity) the ﬂuid is in an externally produced gravitational ﬁeld ,
its energy density is obviously
energy density for ideal
ﬂuid with external gravity
U = ρ
1
2v2 + u + 

for ideal ﬂuid with external gravity.
(13.56)
Here the three terms are kinetic, internal, and gravitational energy. When the ﬂuid
participates in producing gravity and one includes the energy of the gravitational ﬁeld
itself, the energy density is a bit more subtle; see the Track-Two Box 13.4.
In an external gravitational ﬁeld, one might expect the energy ﬂux to be F = Uv,
but this is not quite correct. Consider a bit of surface area dA orthogonal to the
direction in which the ﬂuid is moving (i.e., orthogonal to v). The ﬂuid element that
crosses dA during time dt moves through a distance dl = vdt, and as it moves, the
ﬂuid behind this element exerts a force P dA on it. That force, acting through the
distancedl, feedsanenergydE = (P dA)dl = P vdAdt acrossdA; thecorresponding
energy ﬂux across dA has magnitude dE/dAdt = P v and points in the v direction,
so it contributes Pv to the energy ﬂux F. This contribution is missing from our initial
guess F = Uv. We explore its importance at the end of this subsection. When it is
added to our guess, we obtain for the total energy ﬂux
energy ﬂux for ideal ﬂuid
with external gravity
F = ρv
1
2v2 + h + 

for ideal ﬂuid with external gravity.
(13.57)
Here h = u + P/ρ is the enthalpy per unit mass (cf. Box 13.2). Inserting Eqs. (13.56)
and(13.57)intothelawofenergyconservation(13.41), andrequiringthattheexternal
704
Chapter 13. Foundations of Fluid Dynamics

BOX 13.4.
SELF-GRAVITY
In the text, we mostly treat the gravitational ﬁeld as externally imposed and
independent of the ﬂuid. This approximation is usually a good one. However,
it is inadequate for planets and stars, whose self-gravity is crucial. It is easiest
to discuss the modiﬁcations due to the ﬂuid’s self-gravitational effects by
amending the conservation laws.
As long as we work in the domain of Newtonian physics, the mass
conservation equation (13.29) is unaffected by self-gravity. However, we
included the gravitational force per unit volume ρg as a source of momentum
in the momentum conservation law (13.42). It would ﬁt much more neatly
in our formalism if we could express it as the divergence of a gravitational
stress tensor Tg. To see that this is indeed possible, use Poisson’s equation
∇. g = −4πGρ (which embodies self-gravity) to write
∇. Tg = −ρg = (∇. g)g
4πG
= ∇. [g ⊗g −1
2g2g]
4πG
,
so
Tg = g ⊗g −1
2g2g
4πG
.
(1)
Readers familiar with classical electromagnetic theory will notice an obvious
and understandable similarity to the Maxwell stress tensor [Eqs. (1.38) and
(2.80)], whose divergence equals the Lorentz force density.
What of the gravitational momentum density? We expect that it can be
related to the gravitational energy density using a Lorentz transformation.
That is to say, it is O(v/c2) times the gravitational energy density, where
v is some characteristic speed. However, in the Newtonian approximation,
the speed of light c is regarded as inﬁnite, and so we should expect the
gravitational momentum density to be identically zero in Newtonian theory—
and indeed it is. We therefore can write the full equation of motion (13.42),
including gravity, as a conservation law:
∂(ρv)
∂t
+ ∇. Ttotal = 0,
(2)
where Ttotal includes Tg.
Now consider energy conservation. We have seen in the text that in
a constant, external gravitational ﬁeld, the ﬂuid’s total energy density U
and ﬂux F are given by Eqs. (13.56) and (13.57), respectively. In a general
(continued)
13.5 The Dynamics of an Ideal Fluid
705

BOX 13.4.
(continued)
situation, we must add to these some ﬁeld energy density and ﬂux. On
dimensional grounds, these must be Uﬁeld ∝g2/G and Fﬁeld ∝,tg/G (where
g = −∇). The proportionality constants can be deduced by demanding that
for an ideal ﬂuid in the presence of gravity, the law of energy conservation
when combined with mass conservation, momentum conservation, and the
ﬁrst law of thermodynamics, lead to ds/dt = 0 (no dissipation in, so no
dissipation out); see Eq. (13.59) and associated discussion. The result (Ex.
13.13) is
U = ρ
1
2v2 + u + 

+
g2
8πG ,
(3)
F = ρv
1
2v2 + h + 

+
1
4πG
∂
∂t g.
(4)
Actually, there is an ambiguity in how the gravitational energy is localized.
This ambiguity arises physically because one can transform away the
gravitational acceleration g, at any point in space, by transforming to a
reference frame that falls freely there. Correspondingly, it turns out, one can
transform away the gravitational energy density at any desired point in space.
This possibility is embodied mathematically in the possibility of adding to the
energy ﬂux F the time derivative of α∇/(4πG) and adding to the energy
density U minus the divergence of this quantity (where α is an arbitrary
constant), while preserving energy conservation ∂U/∂t + ∇. F = 0. Thus
the following choice of energy density and ﬂux is just as good as Eqs. (3) and
(4); both satisfy energy conservation:
U = ρ
1
2v2 + u + 

+
g2
8πG −α∇.
∇
4πG

= ρ
1
2v2 + u + (1 −α)

+ (1 −2α) g2
8πG ,
(5)
F = ρv
1
2v2 + h + 

+
1
4πG
∂
∂t g + α ∂
∂t
∇
4πG

= ρv
1
2v2 + h + 

+ (1 −α)
1
4πG
∂
∂t g −
α
4πG∂g
∂t .
(6)
[Here we have used the gravitational ﬁeld equation ∇2 = 4πGρ and
g = −∇.] Note that the choice α = 1/2 puts all the energy density into the
(continued)
706
Chapter 13. Foundations of Fluid Dynamics

BOX 13.4.
(continued)
ρ term, while the choice α = 1puts all the energy density into the ﬁeld term
g2. In Ex. 13.14 it is shown that the total gravitational energy of an isolated
system is independent of the arbitrary parameter α, as it must be on physical
grounds.
A full understanding of the nature and limitations of the concept of
gravitational energy requires the general theory of relativity (Part VII). The
relativistic analog of the arbitrariness of Newtonian energy localization is
an arbitrariness in the gravitational “stress-energy pseudotensor” (see, e.g.,
Misner, Thorne, and Wheeler, 1973, Sec. 20.3).
gravity be static (time independent), so the work it does on the ﬂuid is conservative,
we obtain the following ideal-ﬂuid equation of energy balance:
energy conservation for
ideal ﬂuid with external
gravity
∂
∂t

ρ
1
2v2 + u + 

+ ∇.

ρv
1
2v2 + h + 

= 0
for an ideal ﬂuid and static external gravity.
(13.58)
When the gravitational ﬁeld is dynamical or is being generated by the ﬂuid itself
(or both), we must use a more complete gravitational energy density and stress; see
Box 13.4.
By combining the law of energy conservation (13.58) with the corresponding
laws of momentum (13.29) and mass conservation (13.42), and using the ﬁrst law
of thermodynamics dh = T ds + (1/ρ)dP, we obtain the remarkable result that the
entropy per unit mass is conserved moving with the ﬂuid:
entropy conservation for
ideal ﬂuid
ds
dt = 0
for an ideal ﬂuid.
(13.59)
The same conclusion can be obtained when the gravitational ﬁeld is dynamical and
not external (cf. Box 13.4 and Ex. 13.13), so no statement about gravity is included
with this equation. This entropy conservation should not be surprising. If we put no
dissipative processes into the energy density, energy ﬂux, or stress tensor, then we get
no dissipation out. Moreover, the calculation that leads to Eq. (13.59) ensures that, so
long as we take full account of mass and momentum conservation, then the full and sole
content of the law of energy conservation for an ideal ﬂuid is ds/dt = 0.
Table 13.1 summarizes our formulas for the density and ﬂux of mass, momentum,
and energy in an ideal ﬂuid with externally produced gravity.
13.5 The Dynamics of an Ideal Fluid
707

TABLE 13.1: Densities and ﬂuxes of mass, momentum, and energy for an
ideal ﬂuid in an externally produced gravitational ﬁeld
Quantity
Density
Flux
Mass
ρ
ρv
Momentum
ρv
T = P g + ρv ⊗v
Energy
U = ( 1
2v2 + u + )ρ
F = ( 1
2v2 + h + )ρv
EXERCISES
Exercise 13.12 Example: Joule-Kelvin Cooling
A good illustration of the importance of the P v term in the energy ﬂux is provided
by the Joule-Kelvin method commonly used to cool gases (Fig. 13.8). Gas is driven
from a high-pressure chamber 1 through a nozzle or porous plug into a low-pressure
chamber 2, where it expands and cools.
(a) Using the energy ﬂux (13.57), including the P v term contained in h, show that a
mass M ejected through the nozzle carries a total energy E1 that is equal to
the enthalpy H1 that this mass had while in chamber 1.
(b) This ejected gas expands and crashes into the gas of chamber 2, temporarily going
out of statistical (thermodynamic) equilibrium. Explain why, after it has settled
down into statistical equilibrium as part of the chamber-2 gas, the total energy it
has deposited into chamber 2 is its equilibrium enthalpy H2. Thereby conclude
that the enthalpy per unit mass is the same in the two chambers, h1 = h2.
(c) From h1 = h2, show that the temperature drop between the two chambers is
T =
 P2
P1
μJKdP ,
(13.60)
where μJK ≡(∂T /∂P )h is the Joule-Kelvin coefﬁcient (also called Joule-
Thomson). A straightforward thermodynamic calculation yields the identity
nozzle
P1
P2
v2
v1
FIGURE 13.8 Schematic illustration of Joule-Kelvin cooling of a gas. Gas ﬂows steadily
through a nozzle from a chamber at high pressure P1 to one at low pressure P2.
The ﬂow proceeds at constant enthalpy. Work done against attractive intermolecular
forces leads to cooling. The efﬁciency of cooling can be enhanced by exchanging heat
between the two chambers. Gases can also be liquiﬁed in this manner.
708
Chapter 13. Foundations of Fluid Dynamics

μJK ≡
∂T
∂P

h
= −
1
ρ2cp
∂(ρT )
∂T

P
.
(13.61)
(d) Show that the Joule-Kelvin coefﬁcient of an ideal gas vanishes. Therefore, the
coolingmustarisebecauseoftheattractiveforces(vanderWaalsforces; Sec.5.3.2)
between the molecules, which are absent in an ideal gas. When a real gas expands,
work is done against these forces, and the gas therefore cools.
Exercise 13.13 Derivation: No Dissipation “in” Means No Dissipation “out”
and Veriﬁcation of the Claimed Gravitational Energy Density and Flux
Consider an ideal ﬂuid interacting with a (possibly dynamical) gravitational ﬁeld
that the ﬂuid itself generates via ∇2 = 4πGρ. For this ﬂuid, take the law of energy
conservation, ∂U/∂t + ∇. F = 0, and from it subtract the scalar product of v with
the law of momentum conservation, v . [∂(ρv)/∂t + ∇. T)]; then simplify using the
law of mass conservation and the ﬁrst law of thermodynamics, to obtain ρds/dt = 0.
In your computation, use for U and F the expressions given in Eqs. (3) and (4) of
Box 13.4. This calculation tells us two things. (i) The law of energy conservation for
an ideal ﬂuid reduces simply to conservation of entropy moving with the ﬂuid; we
have put no dissipative physics into the ﬂuxes of momentum and energy, so we get
no dissipation out. (ii) The gravitational energy density and ﬂux contained in Eqs. (3)
and (4) of Box 13.4 must be correct, since they guarantee that gravity does not alter
this “no dissipation in, no dissipation out” result.
Exercise 13.14 Example: Gravitational Energy
Integrate the energy density U of Eq. (5) of Box 13.4 over the interior and surround-
ings of an isolated gravitating system to obtain the system’s total energy. Show that
the gravitational contribution to this total energy (i) is independent of the arbitrari-
ness (parameter α) in the energy’s localization, and (ii) can be written in the following
forms:
Eg =

dV 1
2ρ = −
1
8πG

dVg2 = −G
2
 
dV dV ′ρ(x)ρ(x′)
|x −x′| .
(13.62)
Interpret each of these expressions physically.
13.6
13.6 Incompressible Flows
A common assumption made when discussing the ﬂuid dynamics of highly subsonic
ﬂows is that the density is constant—that the ﬂuid is incompressible. This is a natural
approximation to make when dealing with a liquid like water, which has a very large
bulk modulus. It is a bit of a surprise that it is also useful for ﬂows of gases, which are
far more compressible under static conditions.
To see its validity, suppose that we have a ﬂow in which the characteristic length L
over which the ﬂuid variables P , ρ, v, and so forth vary is related to the characteristic
timescale T over which they vary by L <∼vT . In this case, we can compare the
13.6 Incompressible Flows
709

magnitude of the various terms in the Euler equation (13.44) to obtain an estimate of
the magnitude of the pressure variation:
∂v
∂t
	

v/T
+ (v . ∇)v
 	
 
v2/L
= −∇P
ρ
	

δP/ρL
−∇
	

δ/L
.
(13.63)
Multiplying through by L and using L/T <∼v, we obtain δP/ρ ∼v2 + |δ|. The
variation in pressure will be related to the variation in density by δP ∼C2δρ, where
C =

(∂P/∂ρ)s is the sound speed (Sec. 16.5), and we drop constants of order unity
when making these estimates. Inserting this into our expression for δP , we obtain the
estimate for the fractional density ﬂuctuation:
δρ
ρ ∼v2
C2 + δ
C2 .
(13.64)
Therefore, if the ﬂuid speeds are highly subsonic (v ≪C) and the gravitational poten-
incompressible
approximation
tial does not vary greatly along ﬂow lines (|δ| ≪C2), then we can ignore the density
variations moving with the ﬂuid when solving for the velocity ﬁeld. More speciﬁcally,
since ρ−1dρ/dt = −∇. v = −θ [Eq. (13.35)], we can make the incompressible ap-
proximation
∇. v ≃0
(13.65)
(which means that the velocity ﬁeld is solenoidal, like a magnetic ﬁeld; i.e., is express-
ible as the curl of some potential). This argument breaks down when we are dealing
with sound waves for which L ∼CT .
For air at atmospheric temperature, the speed of sound is C ∼300 m/s, which
is very fast compared to most ﬂow speeds one encounters, so most ﬂows are
incompressible.
It should be emphasized, though, that the incompressible approximation for the
velocity ﬁeld, ∇. v ≃0, does not imply that the density variation can be neglected
in all other contexts. A particularly good example is provided by convection ﬂows,
which are driven by buoyancy, as we shall discuss in Chap. 18.
Incompressibility is a weaker condition than requiring the density to be constant
everywhere; for example, the density varies substantially from Earth’s center to its
surface, but if the material inside Earth were moving more or less on surfaces of
constant radius, the ﬂow would be incompressible.
We restrict ourselves to incompressible ﬂows throughout the next two chapters
and then abandon incompressibility in subsequent chapters on ﬂuid dynamics.
13.7
13.7 Viscous Flows with Heat Conduction
13.7.1
13.7.1 Decomposition of the Velocity Gradient into Expansion, Vorticity, and Shear
It is an observational fact that many ﬂuids, when they ﬂow, develop a shear stress
(also called a viscous stress). Honey pouring off a spoon is a nice example. Most ﬂuids,
710
Chapter 13. Foundations of Fluid Dynamics

however, appear to ﬂow quite freely; for example, a cup of tea appears to offer little
resistance to stirring other than the inertia of the water. In such cases, it might be
thought that viscous effects only produce a negligible correction to the ﬂow’s details.
However, this is not so.
One of the main reasons is that most ﬂows touch solid bodies, at whose surfaces
the velocity must vanish. This leads to the formation of boundary layers, whose
thickness and behavior are controlled by viscous forces. The boundary layers in turn
can exert a controlling inﬂuence on the bulk ﬂow (where the viscosity is negligible);
for example, they can trigger the development of turbulence in the bulk ﬂow—witness
the stirred tea. For details see Chaps. 14 and 15.
We must therefore augment our equations of ﬂuid dynamics to include viscous
stresses. Our formal development proceeds in parallel to that used in elasticity, with
the velocity ﬁeld v = dξ/dt replacing the displacement ﬁeld ξ. We decompose the
velocity gradient tensor ∇v into its irreducible tensorial parts: a rate of expansion θ;
a symmetric, trace-free rate of shear tensor σ; and an antisymmetric rate of rotation
tensor r:
∇v = 1
3θg + σ + r.
(13.66)
Note that we use lowercased symbols to distinguish the ﬂuid case from its elastic
counterpart: θ = d/dt, σ = d/dt, r = dR/dt. Proceeding directly in parallel to
the treatment in Sec. 11.2.2 and Box 11.2, we can invert Eq. (13.66) to obtain
rates of expansion, shear,
and rotation
θ = ∇. v,
(13.67a)
σij = 1
2(vi;j + vj;i) −1
3θgij,
(13.67b)
rij = 1
2(vi;j −vj;i) = −1
2ϵijkωk,
(13.67c)
where ω = 2dφ/dt is the vorticity, which we introduced and discussed in Sec. 13.5.4.
EXERCISES
Exercise 13.15 **Example: Kinematic Interpretation of Vorticity
Consider a velocity ﬁeld with nonvanishing curl. Deﬁne a locally orthonormal basis
at a point in the velocity ﬁeld, so that one basis vector, ex, is parallel to the vorticity.
Now imagine the remaining two basis vectors as being frozen into the ﬂuid. Show that
they will both rotate about the axis deﬁned by ex and that the vorticity will be the sum
of their angular velocities (i.e., twice the average of their angular velocities).
13.7.2
13.7.2 Navier-Stokes Equation
Although, as we have emphasized, a ﬂuid at rest does not exert a shear stress, and
this distinguishes it from an elastic solid, a ﬂuid in motion can resist shear in the
13.7 Viscous Flows with Heat Conduction
711

shear
stress
shear
stress
rheopectic
Newtonian
Newtonian
thixotropic
plastic
time
(a)
(b)
rate of shear σ
FIGURE 13.9 Some examples of non-Newtonian behavior in ﬂuids. (a) In a Newtonian ﬂuid
the shear stress is proportional to the rate of shear σ and does not vary with time when σ is
constant as here. However, some substances, such as paint, ﬂow more freely with time and
are said to be thixotropic. Microscopically, the long, thin paint molecules gradually become
aligned with the ﬂow, which reduces their resistance to shear. The opposite behavior is
exhibited by rheopectic substances such as ink and some lubricants. (b) An alternative type of
non-Newtonian behavior is exhibited by various plastics, where a threshold stress is needed
before ﬂow will commence.
velocity ﬁeld. It has been found experimentally that in most ﬂuids the magnitude of
this shear stress is linearly related to the velocity gradient. This law, due to Hooke’s
contemporary, Isaac Newton, is the analog of the linear relation between stress and
strainthatweusedinourdiscussionofelasticity.Fluidsthatobeythislawareknownas
Newtonian.(Some examples of non-Newtonian ﬂuid behavior are shown in Fig. 13.9.)
We analyze only Newtonian ﬂuids in this book.
Fluids are usually isotropic. (Important exceptions include smectic liquid crystals.)
In this book we restrict ourselves to isotropic ﬂuids. By analogy with the theory
of elasticity, we describe the linear relation between stress and rate of strain using
two constants called the coefﬁcients of bulk and shear viscosity, denoted ζ and η,
coefﬁcients of bulk and
shear viscosity
respectively. We write the viscous contribution to the stress tensor as
viscous stress tensor
Tvis = −ζθg −2ησ,
(13.68)
by analogy to Eq. (11.18), Telas = −Kg −2μ, for an elastic solid. Here as there,
shear-free rotation about a point does not produce a resistive stress.
If we include this viscous contribution in the stress tensor, then the law of mo-
mentum conservation ∂(ρv)/∂t + ∇. T = ρg gives the following generalization of
Euler’s equation (13.44):
Navier-Stokes equation:
general form
ρ dv
dt = −∇P + ρg + ∇(ζθ) + 2∇. (ησ).
(13.69)
This is the Navier-Stokes equation,and the last two terms are the viscous force density.
For incompressible ﬂows (e.g., when the ﬂow is highly subsonic; Sec. 13.6), θ can
be approximated as zero, so the bulk viscosity can be ignored. The viscosity coefﬁcient
712
Chapter 13. Foundations of Fluid Dynamics

TABLE 13.2: Approximate kinematic viscosity for
common ﬂuids
Kinematic viscosity ν
Quantity
(m2 s−1)
Water
10−6
Air
10−5
Glycerine
10−3
Blood
3 × 10−6
η generallyvariesinspacefarmoreslowlythantheshearσ, andsocanbetakenoutside
the divergence. In this case, Eq. (13.69) simpliﬁes to
Navier-Stokes equation for
incompressible ﬂow
dv
dt = −∇P
ρ
+ g + ν∇2v,
(13.70)
where
kinematic shear viscosity
coefﬁcient
ν ≡η
ρ
(13.71)
is known as the kinematic viscosity, by contrast to η, which is often called the dy-
namic viscosity. Equation (13.70) is the commonly quoted form of the Navier-Stokes
equation; it is the form that we shall almost always use. Approximate values of the
kinematic viscosity for common ﬂuids are given in Table 13.2.
13.7.3
13.7.3 Molecular Origin of Viscosity
estimate of shear viscosity
We can distinguish gases from liquids microscopically. In a gas, a molecule of mass
m travels a distance of order its mean free path λ before it collides. If there is a shear
in the ﬂuid (Fig. 13.10), then the molecule, traveling in the y direction, on average
λ
vx + σxyλ
vx
FIGURE 13.10 Molecular origin of viscosity in a gas. A molecule travels
a distance λ in the y direction between collisions. Its mean x velocity
at its point of origin is that of the ﬂuid there, vx, which differs from
the mean x velocity at its next collision by −σxyλ. As a result, it
transports a momentum −mσxyλ to the location of its next collision.
13.7 Viscous Flows with Heat Conduction
713

will transfer an x momentum of about −mλσxy between collision points. If there
are n molecules per unit volume traveling with mean thermal speeds vth, then the
transferred momentum crossing a unit area in unit time is Txy ∼−nmvthλσxy, from
which, by comparison with Eq. (13.68), we can extract an estimate of the coefﬁcient
of shear viscosity:
η ≃1
3ρvthλ.
(13.72)
Here the numerical coefﬁcient of 1/3 (which arises from averaging over molecular
directions and speeds) has been inserted to agree with a proper kinetic-theory calcu-
lation; see Ex. 3.19 in Chap. 3. Note from Eq. (13.72) that in a gas, where the mean
thermal kinetic energy 3
2kBT is ∼mv2
th, the coefﬁcient of viscosity will increase with
temperature as ν ∝T 1/2.
In a liquid, where the molecules are less mobile, it is the close intermolecular
attraction that produces the shear stress. The ability of molecules to slide past one
anotherincreasesrapidlywiththeirthermalactivation, causingtypicalliquidviscosity
coefﬁcients to fall dramatically with rising temperature.
EXERCISES
Exercise 13.16 Problem: Mean Free Path
Estimate the collision mean free path of the air molecules around you. Hence verify
the estimate for the kinematic viscosity of air given in Table 13.2.
13.7.4
13.7.4 Energy Conservation and Entropy Production
The viscous stress tensor represents an additional momentum ﬂux that can do work
on the ﬂuid at a rate Tvis . v per unit area. Therefore a contribution
viscous energy ﬂux
Fvis = Tvis . v
(13.73)
is made to the energy ﬂux, just like the term P v appearing (as part of the ρvh) in
Eq. (13.57). Diffusive heat ﬂow (thermal conductivity) can also contribute to the
energy ﬂux; its contribution is [Eq. (3.70b)]
energy ﬂux for heat
conduction
Fcond = −κ∇T ,
(13.74)
where κ is the coefﬁcient of thermal conductivity. The molecules or particles that
coefﬁcient of thermal
conductivity κκκ
produce the viscosity and the heat ﬂow also carry energy, but their energy density
already is included in u, the total internal energy per unit mass, and their energy ﬂux
in ρvh. The total energy ﬂux, including these contributions, is shown in Table 13.3,
along with the energy density and the density and ﬂux of momentum.
We see most clearly the inﬂuence of the dissipative viscous forces and heat conduc-
tion on energy conservation by inserting the energy density and ﬂux from Table 13.3
into the law of energy conservation ∂U/∂t + ∇. F = 0, subtracting v . [∂(ρv)/∂t +
714
Chapter 13. Foundations of Fluid Dynamics

TABLE 13.3: Densities and ﬂuxes of mass, momentum, and energy for a dissipative ﬂuid in
an externally produced gravitational ﬁeld
Quantity
Density
Flux
Mass
ρ
ρv
Momentum
ρv
T = ρv ⊗v + P g −ζθg −2ησ
Energy
U = ( 1
2v2 + u + )ρ
F = ( 1
2v2 + h + )ρv −ζθv −2ησ . v −κ∇T
Note: For self-gravitating systems, see Box 13.4.
∇. T = ρg](v dottedintomomentumconservation), andsimplifyingusingmasscon-
servation and the ﬁrst law of thermodynamics. The result (Ex. 13.17) is the following
equation for the evolution of entropy:
Lagrangian equation for
entropy evolution, for
viscous, heat-conducting
ﬂuid
T

ρ
ds
dt

+ ∇.
Fcond
T

= ζθ2 + 2ησ : σ + κ
T (∇T )2,
(13.75)
where σ : σ is the double scalar product σijσij. The term in square brackets on the
left-hand side represents an increase of entropy per unit volume moving with the ﬂuid
due to dissipation (the total increase minus that due to heat ﬂowing conductively into
a unit volume); multiplied by T , this is the dissipative increase in entropy density.
This increase of random, thermal energy is being produced, on the right-hand side,
by viscous heating (ﬁrst two terms), and by the ﬂow of heat Fcond = −κ∇T down a
temperature gradient −∇T (third term).
The dissipation equation (13.75) is the full content of the law of energy conserva-
tion for a dissipative ﬂuid, when one takes account of mass conservation, momentum
conservation, and the ﬁrst law of thermodynamics.
We can combine this Lagrangian rate of viscous dissipation with the equation of
mass conservation (13.29) to obtain an Eulerian differential equation for the entropy
increase:
Eulerian equation for
entropy evolution
∂(ρs)
∂t
+ ∇. (ρsv −κ∇ln T ) = 1
T

ζθ2 + 2ησ : σ + κ
T (∇T )2

.
(13.76)
The left-hand side of this equation describes the rate of change of entropy density plus
the divergence of entropy ﬂux. The right-hand side is therefore the rate of production
ofentropyperunitvolume.Invokingthesecondlawofthermodynamics, thisquantity
must be positive deﬁnite. Therefore the two coefﬁcients of viscosity, like the bulk and
shear moduli, must be positive, as must the coefﬁcient of thermal conductivity κ (heat
must ﬂow from hotter regions to cooler ones).
In most laboratory and geophysical ﬂows, thermal conductivity is unimportant,
so we largely ignore it until our discussion of convection in Chap. 18.
13.7 Viscous Flows with Heat Conduction
715

EXERCISES
Exercise 13.17 Derivation: Entropy Increase
(a) Derive the Lagrangian equation (13.75) for the rate of increase of entropy in a
dissipative ﬂuid by carrying out the steps in the sentence preceding that equa-
tion. [Hint: If you have already done the analogous problem (Ex. 13.13) for an
ideal ﬂuid, then you need only compute the new terms that arise from the dissi-
pative momentum ﬂux Tvis = −ζθg −2ησ and dissipative energy ﬂuxes Fvis =
Tvis . v and Fcond = −κ∇T . The sum of these new contributions, when you sub-
tract v . (momentum conservation) from energy conservation, is ∇. Fcond + ∇.
(Tvis . v) −v . (∇. Tvis); this must be added to the left-hand side of the result
ρT ds/dt = 0, Eq. (13.59), for an ideal ﬂuid. When doing the algebra, it may be
usefultodecomposethegradientofthevelocityintoitsirreducibletensorialparts,
Eq. (13.66).]
(b) From the Lagrangian equation of entropy increase (13.75) derive the correspond-
ing Eulerian equation (13.76).
13.7.5
13.7.5 Reynolds Number
The kinematic viscosityν has dimensions length2/time. This suggests that we quantify
the importance of viscosity in a ﬂuid ﬂow by comparing ν with the product of the
ﬂow’s characteristic velocity V and its characteristic lengthscale L. The dimensionless
combination
Reynolds number
Re = LV
ν
(13.77)
is known as the Reynolds number and is the ﬁrst of many dimensionless numbers we
shall encounter in our study of ﬂuid mechanics. Flows with Reynolds number much
less than unity are dominated by viscosity. Large Reynolds number ﬂows can also be
strongly inﬂuenced by viscosity (as we shall see in later chapters), especially when the
viscosity acts near boundaries—even though the viscous stresses are negligible over
most of the ﬂow’s volume.
13.7.6
13.7.6 Pipe Flow
Let us now consider a simple example of viscous stresses at work, namely, the steady-
state ﬂow of blood down an artery.4 We model the artery as a cylindrical pipe of radius
a, through which the blood is forced by a time-independent pressure gradient. This
is an example of what is called pipe ﬂow.
Because gravity is unimportant and the ﬂow is time independent, the Navier-
Stokes equation (13.70) reduces to
4.
We approximate the blood as a Newtonian ﬂuid although, in reality, its shear viscosity η decreases at
high rates of shear σ.
716
Chapter 13. Foundations of Fluid Dynamics

(v . ∇)v = −∇P
ρ
+ ν∇2v.
(13.78)
We assume that the ﬂow is laminar (smooth, as is usually the case for blood in arter-
laminar ﬂow contrasted
with turbulent ﬂow
ies), so v points solely along the z direction and is only a function of cylindrical radius
ϖ. (This restriction is very important. As we discuss in Chap. 15, in other types of
pipe ﬂow, e.g., in crude oil pipelines, it often fails because the ﬂow becomes turbulent,
which has a major impact on the ﬂow. In arteries, turbulence occasionally occurs and
can lead to blood clots and a stroke!) Writing Eq. (13.78) in cylindrical coordinates,
and denoting by v(ϖ) the z component of velocity (the only nonvanishing compo-
nent), we deduce that the nonlinear v . ∇v term vanishes, and the pressure P is a
function of z only and not of ϖ:
1
ϖ
d
dϖ

ϖ dv
dϖ

= 1
η
dP
dz .
(13.79)
Here dP/dz (which is negative) is the pressure gradient along the pipe, and η = νρ
velocity proﬁle for laminar
pipe ﬂow
is the dynamic viscosity. This differential equation must be solved subject to the
boundary conditions that the velocity gradient vanish at the center of the pipe and
the velocity vanish at its walls. The solution is
v(ϖ) = −dP
dz
a2 −ϖ 2
4η
.
(13.80)
Using this velocity ﬁeld, we can evaluate the pipe’s total ﬂow rate—volume per unit
Poiseuille’s law for pipe
ﬂow
time—for (incompressible) blood volume:
F =
 a
0
v2πϖdϖ = −dP
dz
πa4
8η .
(13.81)
This relation is known as Poiseuille’s law and because of the parabolic shape of the
velocity proﬁle (13.80), this pipe ﬂow is sometimes called parabolic Poiseuille ﬂow.
blood ﬂow in human body
Now let us apply this result to a human body. The healthy adult heart, beating at
about 60 beats per minute, pumps F ∼5 L min−1 (liters per minute) of blood into
a circulatory system of many branching arteries that reach into all parts of the body
and then return. This circulatory system can be thought of as like an electric circuit,
and Poiseuille’s law (13.81) is like the current-voltage relation for a small segment
of wire in the circuit. The ﬂow rate F in an arterial segment plays the role of the
electric current I in the wire segment, the pressure gradient dP/dz is the voltage
drop per unit length dV/dz, and dR/dz ≡8η/πa4 is the resistance per unit length.
Thus −dP/dz = F dR/dz [Eq. (13.81)] is equivalent to the voltage-current relation
−dV/dz = I dR/dz. Moreover, just as the total current is conserved at a circuit
branch point (sum of currents in equals sum of currents out), so also the total blood
ﬂow rate is conserved at an arterial branch point. These identical conservation laws
and identical pressure-and-voltage-drop equations imply that the analysis of pressure
changes and ﬂow distributions in the body’s many-branched circulatory system is
the same as that of voltage changes and current distributions in an equivalent many-
branched electrical circuit.
13.7 Viscous Flows with Heat Conduction
717

Because of the heart’s periodic pumping, blood ﬂow is pulsatile (pulsed; periodic)
in the great vessels leaving the heart (the aorta and its branches); see Ex. 13.19. How-
ever, as the vessels divide into smaller and smaller arterial branches, the pulsatility
becomes lost, so the ﬂow is steady in the smallest vessels, the arterioles. Since a ves-
sel’s resistance per unit length scales with its radius as dR/dz ∝1/a4, and hence its
pressure drop per unit length −dP/dz = FdR/dz also scales as 1/a4 [Eq. (13.81)],
it should not be surprising that in a healthy human the circulatory system’s pressure
drop occurs primarily in the tiny arterioles, which have radii a ∼5–50 μm.
The walls of these arterioles have circumferentially oriented smooth muscle struc-
tures, which are capable of changing the vessel radius a by as much as a factor ∼2 or
3 in response to various stimuli (exercise, cold, stress, etc.). Note that a factor 3 radius
increase means a factor 34 ∼100 decrease in pressure gradient at ﬁxed ﬂow rate! Ac-
cordingly, drugs designed to lower blood pressure do so by triggering radius changes
in the arterioles. And anything you can do to keep your arteries from hardening, nar-
rowing, or becoming blocked will help keep your blood pressure down. Eat salads!
EXERCISES
Exercise 13.18 Problem: Steady Flow between Two Plates
A viscous ﬂuid ﬂows steadily (no time dependence) in the z direction, with the ﬂow
conﬁned between two plates that are parallel to the x-z plane and are separated by a
distance 2a. Show that the ﬂow’s velocity ﬁeld is
vz = −dP
dz
a2
2η
'
1 −
y
a
2(
,
(13.82a)
and the mass ﬂow rate (the discharge) per unit width of the plates is
dm
dtdx = −dP
dz
2ρa3
3η .
(13.82b)
Here dP/dz (which is negative) is the pressure gradient along the direction of ﬂow.
(In Sec. 19.4 we return to this problem, augmented by a magnetic ﬁeld and electric
current, and discover great added richness.)
Exercise 13.19 Example: Pulsatile Blood Flow
Consider the pulsatile ﬂow of blood through one of the body’s larger arteries. The
pressure gradient dP/dz = P ′(t) consists of a steady term plus a term that is periodic,
with the period of the heart’s beat.
(a) Assuming laminar ﬂow with v pointing in the z direction and being a function
of radius and time, v = v(ϖ , t)ez, show that the Navier-Stokes equation reduces
to ∂v/∂t = −P ′/ρ + ν∇2v.
(b) Explain why v(ϖ , t) is the sum of a steady term produced by the steady (time-
independent)partofP ′, plustermsatangularfrequenciesω0, 2ω0, . . . , produced
by parts of P ′ that have these frequencies. Here ω0 ≡2π/(heart’s beat period).
718
Chapter 13. Foundations of Fluid Dynamics

(c) Focus on the component with angular frequency ω = nω0 for some integer n.
For what range of ω do you expect the ϖ dependence of v to be approximately
Poiseuille [Eq. (13.80)], and what ϖ dependence do you expect in the opposite
extreme, and why?
(d) By solving the Navier-Stokes equation for the frequency-ω component, which
is driven by the pressure-gradient term dP/dz = ℜ(P ′
ωe−iωt), and by imposing
appropriate boundary conditions at ϖ = 0 and ϖ = a, show that
v = ℜ
'
P ′
ωe−iωt
iωρ
*
1 −J0(
√
i Wϖ/a)
J0(
√
i W)
+(
.
(13.83)
Here ℜmeans take the real part, a is the artery’s radius, J0 is the Bessel function,
i is √−1, and W ≡

ωa2/ν is called the (dimensionless) Womersley number.
(e) Plot the pieces of this v(ϖ) that are in phase and out of phase with the driving
pressure gradient. Compare with the prediction you made in part (b). Explain
the phasing physically. Notice that in the extreme non-Poiseuille regime, there
is a boundary layer attached to the artery’s wall, with sharply changing ﬂow
velocity. What is its thickness in terms of a and the Womersley number? We study
boundary layers like this one in Sec. 14.4 and especially Ex. 14.18.
13.8
13.8 Relativistic Dynamics of a Perfect Fluid
When a ﬂuid’s speed v = |v| becomes comparable to the speed of light c, or P/(ρc2)
or u/c2 become of order unity, Newtonian ﬂuid mechanics breaks down and must
be replaced by a relativistic treatment. In this section, we brieﬂy sketch the resulting
laws of relativistic ﬂuid dynamics for an ideal (perfect) ﬂuid. For the extension to a
ﬂuid with dissipation (viscosity and heat conductivity), see, e.g., Misner, Thorne, and
Wheeler (1973, Ex. 22.7).
Our treatment takes off from the brief description of an ideal, relativistic ﬂuid in
Secs. 2.12.3 and 2.13.3. As done there, we shall use geometrized units in which the
speed of light is set to unity: c = 1 (see Sec. 1.10).
13.8.1
13.8.1 Stress-Energy Tensor and Equations of Relativistic Fluid Mechanics
rest-massdensityandtotal
density of mass-energy for
relativistic ﬂuid
For relativistic ﬂuids we use ρ to denote the total density of mass-energy (including
rest mass and internal energy) in the ﬂuid’s local rest frame; it is sometimes written as
ρ = ρo(1 + u),
where
ρo = ¯mBn
(13.84)
is the density of rest mass, ¯mB is some standard mean rest mass per baryon, n is the
number density of baryons, ρo is the density of rest mass, and u is the speciﬁc internal
energy (Sec. 2.12.3).
13.8 Relativistic Dynamics of a Perfect Fluid
719

The stress-energy tensor T αβ for a relativistic, ideal ﬂuid takes the form [Eq.
stress-energy tensor for
relativistic, ideal ﬂuid
(2.74b)]
T αβ = (ρ + P )uαuβ + Pgαβ,
(13.85)
where P is the ﬂuid’s pressure (as measured in its local rest frame), uα is its 4-velocity,
andgαβ isthespacetimemetric.Intheﬂuid’slocalrestframe, whereu0 = 1anduj = 0,
the components of this stress-energy tensor are, of course, T 00 = ρ, T j0 = T 0j = 0,
and T jk = Pgjk = Pδjk.
The dynamics of our relativistic, ideal ﬂuid are governed by ﬁve equations. The
ﬁrst equation is the law of rest-mass conservation,(ρouα);α = 0, which can be rewritten
rest-mass conservation
in the form [Eqs. (2.64) and (2.65) of Ex. 2.24]
dρo
dτ = −ρo ⃗∇. ⃗u,
or
d(ρoV )
dτ
= 0,
(13.86a)
where d/dτ = ⃗u . ⃗∇is the derivative with respect to proper time moving with the
ﬂuid, ⃗∇. ⃗u = (1/V )(dV/dτ) is the divergence of the ﬂuid’s 4-velocity, and V is the
volume of a ﬂuid element. The second equation is energy conservation, in the form
of the vanishing divergence of the stress-energy tensor projected onto the ﬂuid 4-
velocity, uαT αβ;β = 0, which, when combined with the law of rest-mass conservation,
reduces to [Eqs. (2.76)]
energy conservation
dρ
dτ = −(ρ + P ) ⃗∇. ⃗u,
or
d(ρV )
dτ
= −P dV
dτ .
(13.86b)
The third equation follows from the ﬁrst law of thermodynamics moving with the
ﬂuid, d(ρV )/dτ = −P dV/dτ + T d(ρoV s)/dτ, combined with rest-mass conser-
vation (13.86a) and energy conservation (13.86b), to yield conservation of the entropy
per unit rest mass s (adiabaticity of the ﬂow):
entropy conservation for
relativistic, ideal ﬂuid
ds
dτ = 0.
(13.86c)
As in Newtonian theory, the ultimate source of this adiabaticity is our restriction to
an ideal ﬂuid (i.e., one without any dissipation). The fourth equation is momentum
conservation, which we obtain by projecting the vanishing divergence of the stress-
energy tensor orthogonally to the ﬂuid’s 4-velocity, PαμT μν;ν = 0, resulting in [Eq.
(2.76c)]
momentum conservation
(relativistic Euler
equation)
(ρ + P)duα
dτ = −P αμP;μ,
where P αμ = gαμ + uαuμ.
(13.86d)
This is the relativistic Euler equation, and P αμ (not to be confused with the ﬂuid
pressure P or its gradient P;μ) is the tensor that projects orthogonally to ⃗u. Note that
the inertial mass per unit volume is ρ + P (Ex. 2.27), and that the pressure gradient
produces a force that is orthogonal to ⃗u. The ﬁfth equation is an equation of state, for
example, in the form
equation of state
P = P (ρo, s).
(13.86e)
720
Chapter 13. Foundations of Fluid Dynamics

A1
A2
v
FIGURE 13.11 A tube generated by streamlines for a
stationary ﬂow. The tube ends are orthogonal to the
streamlines and have areas A1 and A2.
Equations (13.86) are four independent scalar equations and one vector equation for
the four scalars ρo, ρ, P, and s, and one vector ⃗u.
As an example of an equation of state, one that we use below, consider a ﬂuid so hot
that its pressure and energy density are dominated by thermal motions of relativistic
particles (photons, electron-positron pairs, etc.), so P = ρ/3 [Eqs. (3.54a)]. Then
from the ﬁrst law of thermodynamics for a ﬂuid element, d(ρV ) = −P dV , and the
law of rest-mass conservation, d(ρoV ) = 0, one can deduce the relativistic polytropic
equation of state
P = 1
3ρ = K(s)ρ4/3
o .
(13.87)
13.8.2
13.8.2 Relativistic Bernoulli Equation and Ultrarelativistic Astrophysical Jets
When the relativistic ﬂow is steady (independent of time t in some chosen inertial
frame), the law of energy conservation in that frame, T 0μ;μ = 0, and the law of mass
conservation, (ρouμ);μ = 0, together imply that the relativistic Bernoulli function B
is conserved along ﬂow lines; speciﬁcally:
Bernoulli theorem for
steady ﬂow of relativistic,
ideal ﬂuid
dB
dτ = γ vj
∂B
∂xj = 0,
where B = (ρ + P )γ
ρo
.
(13.88)
Here γ = u0 = 1/
√
1 −v2. A direct proof is left as an exercise (Ex. 13.20). The fol-
lowing more indirect geometric proof provides useful insight.
Consider a narrow tube in space, whose walls are generated by steady ﬂow lines
(streamlines), which are tangent to the steady velocity ﬁeld v (Fig. 13.11). Denote the
tube’s interior by V and its boundary by ∂V. Because the ﬂow is steady, the law of mass
conservation, (ρouα);α = 0, reduces to the vanishing spatial divergence: (ρouj);j =
(ρoγ vj);j = 0. Integrate this equation over the tube’s interior, and apply Gauss’s law
toobtain

∂V ρoγ vjdj = 0.Becausethewallsofthetubeareparalleltovj, theymake
no contribution. The contribution from the ends is (ρoγ v)2A2 −(ρoγ v)1A1 = 0. In
other words, the product ρoγ vA—the discharge—is constant along the stream tube.
Similarly, for our steady ﬂow the law of energy conservation, T 0α;α = 0, reduces
to the vanishing spatial divergence, T 0j;j = [(ρ + P )γ 2vj];j = 0, which, when in-
tegrated over the tube’s interior and converted to a surface integral using Gauss’s
13.8 Relativistic Dynamics of a Perfect Fluid
721

theorem, implies that the product (ρ + P )γ 2vA—the power—is constant along the
stream tube.
The ratio of these two constants, (ρ + P)γ/ρo = B, must also be constant along
the stream tube; equivalently (since it is independent of the area of the narrow tube),
B must be constant along a streamline, which is Bernoulli’s theorem.
relativistic jets
Important venues for relativistic ﬂuid mechanics are the early universe (Secs. 28.4
and 28.5), and also the narrow relativistic jets that emerge from some galactic nu-
clei and gamma ray bursts. The ﬂow velocities in some of these jets are measured to
be so close to the speed of light that γ ∼1,000. For the moment, ignore dissipation
and electromagnetic contributions to the stress-energy tensor (which are quite im-
portant in practice), and assume that the gas pressure P and mass-energy density ρ
are dominated by relativistic particles, so the equation of state is P = ρ/3 = Kρ4/3
o
[Eq. (13.87)]. Then we can use the above, italicized conservation laws for the dis-
charge, power, and Bernoulli function to learn how ρ, P , and γ evolve along such
a jet.
FromtherelativisticBernoullitheorem(theratio B ofthetwoconstants, discharge
and power) and the equation of state, we deduce that γ ∝Bρo/(ρ + P ) ∝ρo/ρ4/3
o
∝
ρ−1/3
o
∝ρ−1/4. This describes a conversion of the jet’s internal mass-energy (∼ρ) into
bulk ﬂow energy (∼γ ): as the internal energy (energy of random thermal motions of
the jet’s particles) goes down, the bulk ﬂow energy (energy of organized ﬂow) goes up.
This energy exchange is actually driven by changes in the jet’s cross sectional
area, which (in some jets) is controlled by competition between the inward pressure
of surrounding, slowly moving gas and outward pressure from the jet itself. Since
ρoγ vA ≃ρoγ A is constant along the jet, we have A ∝1/(ρoγ ) ∝γ 2 ∝ρ−1/2. There-
fore, asthejet’scrosssectionalareaAincreases, internalenergy(ρ ∝1/A2)goesdown,
and the energy of bulk ﬂow ( γ ∝A1/2) goes up. Another way to think about this is
in terms of the relativistic distribution function of the constituent particles. As the
volume of conﬁguration space dVx that they occupy increases, their volume of mo-
mentum space dVp decreases (Secs. 3.2.2 and 3.6).
We explore the origin of relativistic jets in Sec. 26.5.
EXERCISES
Exercise 13.20 Derivation: Relativistic Bernoulli Theorem
By manipulating the differential forms of the law of rest-mass conservation and the
law of energy conservation, derive the constancy of B = (ρ + P)γ/ρo along steady
ﬂow lines, Eq. (13.88).
Exercise 13.21 Example: Relativistic Momentum Conservation
Give an expression for the change in the thrust—the momentum crossing a surface
perpendicular to the tube per unit time—along a slender stream tube when the
discharge and power are conserved. Explain why the momentum has to change.
722
Chapter 13. Foundations of Fluid Dynamics

13.8.3
13.8.3 Nonrelativistic Limit of the Stress-Energy Tensor
It is instructive to evaluate the nonrelativistic limit of the perfect-ﬂuid stress-energy
tensor, T αβ = (ρ + P)uαuβ + P gαβ, andverifythatithastheformwededucedinour
study of nonrelativistic ﬂuid mechanics (see Table 13.1) with vanishing gravitational
potential  = 0.
Inthenonrelativisticlimit, theﬂuidisnearlyatrestinthechosenLorentzreference
frame. It moves with ordinary velocity v = dx/dt that is small compared to the speed
of light, so the temporal part of its 4-velocity u0 = 1/
√
1 −v2 and the spatial part
u = u0v can be approximated as
nonrelativistic limit of
4-velocity
u0 ≃1 + 1
2v2,
u ≃

1 + 1
2v2

v.
(13.89a)
We write ρ = ρo(1 + u) [Eq. (13.84)], where u is the speciﬁc internal energy (not to
be confused with the ﬂuid 4-velocity ⃗u or its spatial part u). In our chosen Lorentz
frame the volume of each ﬂuid element is Lorentz contracted by the factor
√
1 −v2,
and therefore the rest mass density is increased fromρo to ρo/
√
1 −v2 = ρou0. Corre-
spondingly the rest-mass ﬂux is increased from ρov to ρou0v = ρou [Eq. (2.62)], and
the law of rest-mass conservation becomes ∂(ρou0)/∂t + ∂(ρouj)/∂xj = 0. When
taking the Newtonian limit, we should identify the Newtonian mass ρN with the low-
velocity limit of this Lorentz-contracted rest-mass density:
nonrelativistic limit of
Lorentz-contracted mass
density
ρN = ρou0 ≃ρo

1 + 1
2v2

.
(13.89b)
In the nonrelativistic limit the speciﬁc internal energy u, the kinetic energy per unit
mass 1
2v2, and the ratio of pressure to rest-mass density P/ρo are of the same order
of smallness:
u ∼1
2v2 ∼P
ρo
≪1,
(13.90)
and the momentum density T j0 is accurate to ﬁrst order in v ≡|v|, the momentum
nonrelativistic limit of
stress-energy tensor for
ideal (perfect) ﬂuid
ﬂux (stress) T jk and the energy density T 00 are both accurate to second order in v,
and the energy ﬂux T 0j is accurate to third order in v. To these accuracies, the perfect-
ﬂuid stress-energy tensor (13.85), when combined with Eqs. (13.84) and (13.89), takes
the following form:
T j0 = ρNvj,
T jk = Pgjk + ρNvjvk,
T 00 = ρN + 1
2ρNv2 + ρNu,
T 0j = ρNvj +
1
2v2 + u + P
ρN

ρNvj ;
(13.91)
see Ex. 13.22. These are precisely the same as the nonrelativistic momentum density,
momentum ﬂux, energy density, and energy ﬂux in Table 13.1, aside from (i) the
13.8 Relativistic Dynamics of a Perfect Fluid
723

notational change ρ →ρN from there to here, (ii) including the rest mass-energy,
ρN = ρNc2, in T00 here but not there, and (iii) including the rest-mass-energy ﬂux
ρNvj in T 0j here but not there.
EXERCISES
Exercise 13.22 Derivation: Nonrelativistic Limit
of Perfect-Fluid Stress-Energy Tensor
(a) Show that in the nonrelativistic limit, the components of the perfect-ﬂuid stress-
energy tensor (13.85) take on the forms (13.91), and verify that these agree with
the densities and ﬂuxes of energy and momentum that are used in nonrelativistic
ﬂuid mechanics (Table 13.1).
(b) Show that the contribution of the pressure P to the relativistic density of inertial
mass causes the term (P/ρN)ρNv = P v to appear in the nonrelativistic energy
ﬂux.
BOX 13.5.
TERMINOLOGY USED IN CHAPTER 13
This chapter introduces a large amount of terminology. We list much of it here.
adiabatic A process in which each ﬂuid element conserves its entropy.
adiabatic index The parameter  that relates pressure and density
changes, δP/P = δρ/ρ, in an adiabatic process. For an ideal gas,
it is the ratio of speciﬁc heats:  = γ ≡CP/CV .
advective time derivative The time derivative moving with the ﬂuid:
d/dt = ∂/∂t + v . ∇. Also called the convective time derivative.
barotropic A process or equation in which pressure can be regarded as
a function solely of density: P = P (ρ).
Bernoulli function, also sometimes called Bernoulli constant:
B = ρ( 1
2v2 + h + ).
bulk viscosity, coefﬁcient of The proportionality constant ζ relating
rate of expansion to viscous stress: Tvis = −ζθg.
convective time derivative See advective time derivative.
dissipation A process that increases the entropy. Viscosity and diffusive
heat ﬂow (heat conduction) are forms of dissipation.
dynamic viscosity The coefﬁcient of shear viscosity, η.
(continued)
724
Chapter 13. Foundations of Fluid Dynamics

BOX 13.5.
(continued)
equation of state In this chapter, where chemical and nuclear reactions
do not occur: relations of the form u(ρ, s), P (ρ, s) or u(ρ, T ),
P(ρ, T ).
Euler equation Newton’s second law for an ideal ﬂuid: ρdv/dt =
−∇P + ρg.
Eulerian changes Changes in a quantity measured at ﬁxed locations in
space; cf. Lagrangian changes.
expansion, rate of Fractional rate of increase of a ﬂuid element’s
volume: θ = ∇. v.
gas A ﬂuid in which the separations between molecules are large
compared to the molecular sizes, and no long-range forces act
among molecules except gravity; cf. liquid.
ideal ﬂow A ﬂow in which there is no dissipation.
ideal ﬂuid A ﬂuid in which there are no dissipative processes (also
called “perfect ﬂuid”).
ideal gas A gas in which the sizes of the molecules and (nongravita-
tional) forces among them are neglected, so the pressure is due solely
to the molecules’ kinetic motions: P = nkBT = [ρ/(μmp)]kBT .
incompressible A process or ﬂuid in which the fractional changes of
density are small, δρ/ρ ≪1, so the velocity can be approximated as
divergence free: ∇. v = 0.
inviscid Having negligible viscosity.
irrotational A ﬂow or ﬂuid with vanishing vorticity.
isentropic A process or ﬂuid in which the entropy per unit rest mass s
is the same everywhere.
isobar A surface of constant pressure.
isothermal A process or ﬂuid in which the temperature is the same
everywhere.
kinematic viscosity The ratio of the coefﬁcient of shear viscosity to the
density: ν ≡η/ρ.
Lagrangian changes Changes measured moving with the ﬂuid; cf.
Eulerian changes.
laminar ﬂow A nonturbulent ﬂow.
(continued)
13.8 Relativistic Dynamics of a Perfect Fluid
725

BOX 13.5.
(continued)
liquid A ﬂuid in which the molecules are packed side by side (e.g.,
water); contrast this with a gas.
mean molecular weight The average mass of a molecule in a ﬂuid,
divided by the mass of a proton: μ.
Navier-Stokes equation Newton’s second law for a viscous,
incompressible ﬂuid: dv/dt = −(1/ρ)∇P + ν∇2v + g.
Newtonian ﬂuid A (i) nonrelativistic ﬂuid, or (ii) a ﬂuid in which
the shear-stress tensor is proportional to the rate of shear σ and is
time-independent when σ is constant.
perfect ﬂuid See ideal ﬂuid.
perfect gas An ideal gas (with P = [ρ/(μmp)]kBT ) that has negligible
excitation of internal molecular degrees of freedom.
polytropic A barotropic pressure-density relation of the form
P ∝ρ1+1/n for some constant n called the polytropic index. The
proportionality constant is usually a function of entropy.
Reynolds number The ratio Re = LV/ν, where L is the characteristic
lengthscale of a ﬂow, V is the characteristic velocity, and ν is
the kinematic viscosity. In order of magnitude it is the ratio of
inertial acceleration (v . ∇)v to viscous acceleration ν∇2v in the
Navier-Stokes equation.
rotation, rateofAntisymmetricpartofthegradientofvelocity; vorticity
converted into an antisymmetric tensor using the Levi-Civita tensor.
shear, rate of Symmetric, trace-free part of the gradient of velocity: σ.
shear viscosity, coefﬁcient of The proportionality constant η relating
rate of shear to viscous stress: Tvis = −ησ.
steady ﬂow Flow that is independent of time in some chosen reference
frame.
turbulent ﬂow Flow characterized by chaotic ﬂuid motions.
vorticity The curl of the velocity ﬁeld: ω = ∇× v.
Bibliographic Note
There are many good texts on ﬂuid mechanics. Among those with a physicist’s per-
spective, we particularly like Acheson (1990) and Lautrup (2005) at an elementary
level, and Lighthill (1986) and Batchelor (2000) at a more advanced level. Landau
726
Chapter 13. Foundations of Fluid Dynamics

and Lifshitz (1959), as always, is terse but good for physicists who already have some
knowledge of the subject. Tritton (1987) takes an especially physical approach to the
subject with lots of useful diagrams and photographs of ﬂuid ﬂows. Faber (1995) gives
a more deductive yet still physical approach, including a broader range of ﬂows. A
general graduate text covering many topics that we discuss (including blood ﬂow) is
Kundu, Cohen, and Dowling (2012). For relativistic ﬂuid mechanics we recommend
Rezzolla and Zanotti (2013).
Given the importance of ﬂuids to modern engineering and technology, it should
not be surprising that there are many more texts with an engineering perspective than
with a physics one. Those we particularly like include Potter, Wiggert, and Ramadan
(2012), which has large numbers of useful examples, illustrations, and exercises; also
recommended are Munson, Young, and Okiishi (2006) and White (2008).
Physical intuition is very important in ﬂuid mechanics and is best developed
with the aid of visualizations—both movies and photographs. In recent years many
visualizations have been made available on the web. Movies that we have found
especially useful are those produced by the National Committee for Fluid Mechanics
Films (Shapiro 1961a) and those produced by Hunter Rouse (1963a–f).
The numerical solution of the equations of ﬂuid dynamics on computers (com-
putational ﬂuid dynamics, or CFD) is a mature ﬁeld of science in its own right. CFD
simulations are widely used in engineering, geophysics, astrophysics, and the movie
industry. We do not treat CFD in this book. For an elementary introduction, see
Lautrup (2005, Chap. 21) and Kundu, Cohen, and Dowling (2012, Chap. 11). For
more thorough pedagogical treatments see, for example, Fletcher (1991) and Toro
(2010); in the relativistic domain, see Rezzolla and Zanotti (2013).
Bibliographic Note
727


14
CHAPTER FOURTEEN
Vorticity
The ﬂow of wet water
RICHARD FEYNMAN (1964, VOLUME 2, CHAP. 41)
14.1
14.1 Overview
In the last chapter, we introduced an important quantity called vorticity, which is the
principal subject of the present chapter. Although the most mathematically simple
ﬂows are potential, with velocity v = ∇ψ for some ψ so the vorticity ω = ∇× v
vanishes, mostnaturallyoccurringﬂowsarevortical,withω ̸= 0.Bystudyingvorticity,
we shall develop an intuitive understanding of how ﬂows evolve. We shall also see that
computing the vorticity can be a powerful step along the path to determining a ﬂow’s
full velocity ﬁeld.
We all think we can recognize a vortex. The most hackneyed example is water dis-
appearing down a drainhole in a bathtub or shower. The angular velocity around the
drain increases inward, because the angular momentum per unit mass is conserved
when the water moves radially slowly, in addition to rotating. Remarkably, angular
momentum conservation means that the product of the circular velocity vφ and the
radius ϖ is independent of radius, which in turn implies that ∇× v = 0. So this is
a vortex without vorticity! (Except, as we shall see, a delta-function spike of vortic-
ity right at the drainhole’s center; see Sec. 14.2 and Ex. 14.24.) Vorticity is a precise
physical quantity deﬁned by ω = ∇× v, not just any vaguely circulatory motion.
In Sec. 14.2, we introduce two tools for analyzing and using vorticity: vortex lines
and circulation. Vorticity is a vector ﬁeld and therefore has integral curves obtained
by solving dx/dλ = ω for some parameter λ. These integral curves are the vortex
lines; they are analogous to magnetic ﬁeld lines. The ﬂux of vorticity

S ω . d across
a surface S is equal to the integral of the velocity ﬁeld,  ≡

∂S v . dx, around the
surface’s boundary ∂S (by Stokes’ theorem). We call this  the circulation around ∂S;
it is analogous to magnetic-ﬁeld ﬂux. In fact, the analogy with magnetic ﬁelds turns
out to be extremely useful. Vorticity, like a magnetic ﬁeld, automatically has vanishing
divergence, which means that the vortex lines are continuous, just like magnetic ﬁeld
lines. Vorticity, again like a magnetic ﬁeld, is an axial vector and thus can be written
729

BOX 14.1.
READERS’ GUIDE
.
This chapter relies heavily on Chap. 13.
.
Chapters 15–19 (ﬂuid mechanics and magnetohydrodynamics) are
extensions of this chapter; to understand them, this chapter must be
mastered.
.
Portions of Part VI, Plasma Physics (especially Chap. 21 on the
two-ﬂuid formalism), rely on this chapter.
as the curl of a polar vector potential, the velocity v.1 Vorticity has the interesting
property that it evolves in a perfect ﬂuid (ideal ﬂuid) in such a manner that the ﬂow
carries the vortex lines along with it; we say that the vortex lines are “frozen into the
ﬂuid.” When viscous stresses make the ﬂuid imperfect, then the vortex lines diffuse
through the moving ﬂuid with a diffusion coefﬁcient that is equal to the kinematic
viscosity ν.
In Sec. 14.3, we study a classical problem that illustrates both the action and the
propagation of vorticity: the creeping ﬂow of a low-Reynolds-number ﬂuid around
a sphere. (Low-Reynolds-number ﬂow arises when the magnitude of the viscous-
acceleration term in the equation of motion is much larger than the magnitude of the
inertial acceleration.) The solution to this problem ﬁnds contemporary application in
the sedimentation rates of soot particles in the atmosphere.
In Sec. 14.4, we turn to high-Reynolds-number ﬂows, in which the viscous stress
is quantitatively weak over most of the ﬂuid. Here, the action of vorticity can be
concentrated in relatively thin boundary layers in which the vorticity, created at a
wall, diffuses away into the main body of the ﬂow. Boundary layers arise because in
real ﬂuids, intermolecular attraction requires that the component of the ﬂuid velocity
parallel to the boundary (not just the normal component) vanish. The vanishing of
both components of velocity distinguishes real ﬂuid ﬂow at high Reynolds number
(i.e., low viscosity) from the solutions obtained assuming no vorticity. Nevertheless, it
is often (but sometimes not) a good approximation to seek a solution to the equations
of ﬂuid dynamics in which vortex-free ﬂuid slips freely past the solid and then match
it to a boundary-layer solution near the solid.
Stirred water in a tea cup and Earth’s oceans and atmosphere rotate nearly rigidly,
so they are most nicely analyzed in a co-rotating reference frame. In Sec. 14.5, we use
1.
Pursuing the electromagnetic analogy further, we can ask the question, “Given a speciﬁed vorticity ﬁeld
ω(x, t), can I solve uniquely for the velocity v(x, t)?” The answer, of course, is “No.” There is gauge
freedom, so many solutions exist. Interestingly, if we specify that the ﬂow be incompressible ∇. v = 0
(i.e., be the analog of the Coulomb gauge), then v(x, t) is unique up to an additive constant.
730
Chapter 14. Vorticity

BOX 14.2.
MOVIES RELEVANT TO THIS CHAPTER
In the 1960s, Asher Shapiro and the National Committee for Fluid Mechanics
Films and Hunter Rouse at the University of Iowa produced movies that are
pedagogically powerful and still fully relevant a half-century later. Those most
germane to this chapter are:
.
Shapiro (1961b), relevant to the entire chapter;
.
Taylor (1964), relevant to Sec. 14.3;
.
Abernathy (1968), the portion dealing with (nonturbulent) laminar
boundary layers, relevant to Sec. 14.4;
.
Rouse (1963e), relevant to Sec. 14.4;
.
Fultz (1969), relevant to Sec. 14.5; and
.
Taylor (1968), relevant to Sec. 14.5.4.
Also relevant are many segments of the movies produced at the University of
Iowa, such as Rouse (1963a–f).
suchananalysistodiscovernovelphenomenaproducedbyCoriolisforces—including
winds around pressure depressions; Taylor columns of ﬂuid that hang together like a
rigid body; Ekman boundary layers with spiral-shaped velocity ﬁelds; gyres (humps
of water, e.g., the Sargasso Sea), around which ocean currents (e.g., the Gulf Stream)
circulate; and tea leaves that accumulate at the bottom center of a tea cup.
When a ﬂow has a large amount of shear, Nature often ﬁnds ways to tap the rela-
tive kinetic energy of neighboring stream tubes. In Sec. 14.6 we explore the resulting
instabilities, focusing primarily on horizontally stratiﬁed ﬂuids with relative horizon-
tal velocities, which have vorticity concentrated in regions where the velocity changes
sharply. The instabilities we encounter show up, in Nature, as (among other things)
billow clouds and clear-air turbulence in the stratosphere. These phenomena provide
motivation for the principal topic of the next chapter: turbulence.
Physical insight into the phenomena of this chapter is greatly aided by movies of
ﬂuid ﬂows. The reader is urged to view relevant movies in parallel with reading this
chapter; see Box 14.2.
14.2
14.2 Vorticity, Circulation, and Their Evolution
In Sec. 13.5.4, we deﬁned the vorticity as the curl of the velocity ﬁeld, ω = ∇× v,
analogous to deﬁning the magnetic ﬁeld as the curl of a vector potential. To get insight
into vorticity, consider the three simple 2-dimensional ﬂows shown in Fig. 14.1.
14.2 Vorticity, Circulation, and Their Evolution
731

y
x
P
(a)
(b)
(c)
v
v
v
ϖ
ϖ

FIGURE 14.1 Vorticity in three 2-dimensional ﬂows. The vorticity vector points in the z direction
(orthogonal to the plane of the ﬂow) and so can be thought of as a scalar (ω = ωz). (a) Constant
angular velocity . If we measure radius ϖ from the center P, the circular velocity satisﬁes
v = ϖ. This ﬂow has vorticity ω = 2 everywhere. (b) Constant angular momentum per unit
mass j, with v = j/ϖ. This ﬂow has zero vorticity except at its center, ω = 2πjδ(x). (c) Shearing
ﬂow in a laminar boundary layer, vx = −ωy with ω < 0. The vorticity is ω = −vx/y, and the rate
of shear is σxy = σyx = −1
2ω.
Figure 14.1a shows uniform (rigid) rotation, with constant angular velocity
 = ez. The velocity ﬁeld is v =  × x, where x is measured from the rotation
axis. Taking its curl, we discover that ω = 2 everywhere.
Figure 14.1b shows a ﬂow in which the angular momentum per unit mass j = jez is
constant, because it was approximately conserved as the ﬂuid gradually drifted inward
to create this ﬂow. In this case the rotation is differential (radially changing angular
velocity), with v = j × x/ϖ 2 (where ϖ = |x| and j = const). This is the kind of ﬂow
that occurs around a bathtub vortex and around a tornado—but outside the vortex’s or
tornado’s core. The vorticity is ω = 2πjδ(x) (where δ(x) is the 2-dimensional Dirac
vortex without verticity
except at its center
delta function in the plane of the ﬂow), so it vanishes everywhere except at the center,
x = 0 (or, more precisely, except in the vortex’s or tornado’s core). Anywhere in the
ﬂow, two neighboring ﬂuid elements, separated tangentially, rotate about each other
with an angular velocity +j/ϖ 2, but when the two elements are separated radially,
their relative angular velocity is −j/ϖ 2; see Ex. 14.1. The average of these two angular
velocities vanishes, which seems reasonable, since the vorticity vanishes.
The vanishing vorticity in this case is an illustration of a simple geometrical
description of vorticity in any 2-dimensional ﬂow (Ex. 13.15): If we orient the ez axis
of a Cartesian coordinate system along the vorticity, then
ω =
∂vy
∂x −∂vx
∂y

ez.
(14.1)
This expression implies that the vorticity at a point is the sum of the angular velocities
vorticity measured by a
vane with orthogonal ﬁns
of a pair of mutually perpendicular, inﬁnitesimal lines passing through that point (one
along the x direction, the other along the y direction) and moving with the ﬂuid; for
example, these lines could be thin straws suspended in the ﬂuid. If we ﬂoat a little
732
Chapter 14. Vorticity

vane with orthogonal ﬁns in the ﬂow, with the vane parallel to ω, then the vane will
rotate with an angular velocity that is the average of the ﬂow’s angular velocities at its
ﬁns, which is half the vorticity. Equivalently, the vorticity is twice the rotation rate of
the vane. In the case of constant-angular-momentum ﬂow in Fig. 14.1b, the average
of the two angular velocities is zero, the vane doesn’t rotate, and the vorticity vanishes.
Figure 14.1c shows the ﬂow in a plane-parallel shear layer. In this case, a line in the
ﬂow along the x direction does not rotate, while a line along the y direction rotates
with angular velocity ω. The sum of these two angular velocities, 0 + ω = ω, is the
vorticity. Evidently, curved streamlines are not a necessary condition for vorticity.
EXERCISES
Exercise 14.1 Practice: Constant-Angular-Momentum Flow—Relative
Motion of Fluid Elements
Verifythatfortheconstant-angular-momentumﬂowofFig.14.1b, withv = j × x/ϖ 2,
twoneighboringﬂuidelementsmovearoundeachotherwithangularvelocity+j/ϖ 2
when separated tangentially and −j/ϖ 2 when separated radially. [Hint: If the ﬂuid
elements’ separation vector is ξ, then their relative velocity is ∇ξv = ξ . ∇v. Why?]
Exercise 14.2 Practice: Vorticity and Incompressibility
Sketch the streamlines for the following stationary 2-dimensional ﬂows, determine
whether the ﬂow is compressible, and evaluate its vorticity. The coordinates are Carte-
sian in parts (a) and (b), and are circular polar with orthonormal bases {eϖ , eφ} in
(c) and (d).
(a) vx = 2xy, vy = x2,
(b) vx = x2, vy = −2xy,
(c) vϖ = 0, vφ = ϖ,
(d) vϖ = 0, vφ = ϖ −1.
Exercise 14.3 **Example: Rotating Superﬂuids
At low temperatures certain ﬂuids undergo a phase transition to a superﬂuid state. A
good example is 4He, for which the transition temperature is 2.2 K. As a superﬂuid
has no viscosity, it cannot develop vorticity. How then can it rotate? The answer (e.g.,
Feynman 1972, Chap. 11) is that not all the ﬂuid is in a superﬂuid state; some of it is
normal and can have vorticity. When the ﬂuid rotates, all the vorticity is concentrated
in microscopic vortex cores of normal ﬂuid that are parallel to the rotation axis and
have quantized circulations  = h/m, where m is the mass of the atoms and h is
Planck’s constant. The ﬂuid external to these vortex cores is irrotational (has vanishing
vorticity). These normal ﬂuid vortices may be pinned at the walls of the container.
(a) Explain, using a diagram, how the vorticity of the macroscopic velocity ﬁeld,
averaged over many vortex cores, is twice the mean angular velocity of the ﬂuid.
14.2 Vorticity, Circulation, and Their Evolution
733

(b) Make an order-of-magnitude estimate of the spacing between these vortex cores
in a beaker of superﬂuid helium on a turntable rotating at 10 rpm.
(c) Repeat this estimate for a neutron star, which mostly comprises superﬂuid neu-
tron pairs at the density of nuclear matter and spins with a period of order a
millisecond. (The mass of the star is roughly 3 × 1030 kg.)
14.2.1
14.2.1 Vorticity Evolution
vortex lines
By analogy with magnetic ﬁeld lines, we deﬁne a ﬂow’s vortex lines to be parallel to
the vorticity vector ω and to have a line density proportional to ω = |ω|. These vortex
lines are always continuous throughout the ﬂuid, because the vorticity ﬁeld, like the
magnetic ﬁeld, is a curl and therefore is necessarily solenoidal (∇. ω = 0). However,
vortex lines can begin and end on solid surfaces, as the equations of ﬂuid dynamics
no longer apply there. Figure 14.2 shows an example: vortex lines that emerge from
the wingtip of a ﬂying airplane.
Vorticity and its vortex lines depend on the velocity ﬁeld at a particular instant and
evolve with time as the velocity ﬁeld evolves. We can determine how by manipulating
the Navier-Stokes equation.
In this chapter and the next one, we restrict ourselves to ﬂows that are incompress-
ible in the sense that ∇. v = 0. As we saw in Sec. 13.6, this is the case when the ﬂow
is substantially subsonic and gravitational potential differences are not too extreme.
We also require (as is almost always the case) that the shear viscosity vary spatially far
(a)
(b)
(c)
vortex
lines


FIGURE 14.2 (a) Sketch of the wing of a ﬂying airplane and the vortex lines that emerge from the wing
tip and sweep backward behind the plane. The lines are concentrated in a region with small cross
section, a vortex of whirling air. The closed red curves encircle the wing and the vortex; the integral
of the velocity ﬁeld around these curves,  =

v . dx, is the circulation contained in the wing and its
boundary layers, and in the vortex; see Sec. 14.2.4 and especially Ex. 14.8. (b) Photograph of the two
vortices emerging from the wingtips of an Airbus, made visible by light scattering off water droplets
in the vortex cores (Ex. 14.6). Photo © Daniel Uma˜na. (c) Sketch of vortex lines (dashed) in the
wingtip vortices of a ﬂying bird and the ﬂow lines (solid) of air around them. Sketch from Vogel, 1994,
Fig. 12.7c, reprinted by permission.
734
Chapter 14. Vorticity

more slowly than the shear itself. These restrictions allow us to write the Navier-Stokes
equation in its simplest form:
dv
dt ≡∂v
∂t + (v . ∇)v = −∇P
ρ
−∇ + ν∇2v
(14.2)
[Eq. (13.70) with g = −∇].
To derive the desired evolution equation for vorticity, we take the curl of Eq. (14.2)
and use the vector identity (v . ∇)v = ∇(v2)/2 −v × ω (easily derivable using the
Levi-Civita tensor and index notation) to obtain
∂ω
∂t = ∇× (v × ω) −∇P × ∇ρ
ρ2
+ ν∇2ω.
(14.3)
Although the ﬂow is assumed incompressible, ∇. v = 0, the density can vary spatially
due to a varying chemical composition (e.g., some regions might be oil and others
water) or varying temperature and associated thermal expansion. Therefore, we must
not omit the ∇P × ∇ρ term.
It is convenient to rewrite the vorticity evolution equation (14.3) with the aid of
the relation (again derivable using the Levi-Civita tensor)
∇× (v × ω) = (ω . ∇)v + v(∇. ω) −ω(∇. v) −(v . ∇)ω.
(14.4)
Inserting this into Eq. (14.3), using ∇. ω = 0 and ∇. v = 0, and introducing a new
type of time derivative2
Dω
Dt ≡∂ω
∂t + (v . ∇)ω −(ω . ∇)v = dω
dt −(ω . ∇)v,
(14.5)
we bring Eq. (14.3) into the following form:
vorticity evolution equa-
tion for incompressible
ﬂow
Dω
Dt = −∇P × ∇ρ
ρ2
+ ν∇2ω.
(14.6)
This is our favorite form for the vorticity evolution equation for an incompressible ﬂow,
∇. v = 0. If there are additional accelerations acting on the ﬂuid, then their curls
must be added to the right-hand side. The most important examples are the Coriolis
acceleration −2 × v in a reference frame that rotates rigidly with angular velocity
 (Sec. 14.5.1), and the Lorentz-force acceleration j × B/ρ when the ﬂuid has an
internal electric current density j and an immersed magnetic ﬁeld B (Sec. 19.2.1);
then Eq. (14.6) becomes
inﬂuence of Coriolis and
Lorentz forces on vorticity
Dω
Dt = −∇P × ∇ρ
ρ2
+ ν∇2ω −2∇× ( × v) + ∇× (j × B/ρ).
(14.7)
2.
The combination of spatial derivatives appearing here is called the Lie derivative and is denoted Lvω ≡
(v . ∇)ω −(ω . ∇)v; it is also the commutator of v and ω and is denoted [v, ω]. It is often encountered
in differential geometry.
14.2 Vorticity, Circulation, and Their Evolution
735

x
x
vdt
(v + dv)dt
(x ¢ r)vdt
P
P′
Q
Q′
FIGURE 14.3 Equation of motion for an inﬁnitesimal
vector x connecting two ﬂuid elements. As the ﬂuid
elements at P and Q move to P′ and Q′ in a time
interval dt, the vector changes by (x . ∇)vdt.
In the remainder of Sec. 14.2, we explore the predictions of our favorite form
[Eq. (14.6)] of the vorticity evolution equation.
TheoperatorD/Dt [deﬁnedbyEq.(14.5)whenactingonavectorandbyD/Dt =
d/dt when acting on a scalar] is called the ﬂuid derivative. (Warning: The notation
D/Dt is used in some older texts for the convective derivative d/dt.) The geometrical
meaning of the ﬂuid derivative can be understood from Fig. 14.3. Denote by x(t)
the vector connecting two points P and Q that are moving with the ﬂuid. Then the
ﬁgure shows that the convective derivative dx/dt is the relative velocity of these two
points, namely (x . ∇)v. Therefore, by the second equality in Eq. (14.5), the ﬂuid
derivative of x vanishes:
Dx
Dt
= 0.
(14.8)
Correspondingly, the ﬂuid derivative of any vector is its rate of change relative to a
meaning of the ﬂuid
derivative D/Dt
D/Dt
D/Dt
vector, such as x, whose tail and head move with the ﬂuid.
14.2.2
14.2.2 Barotropic, Inviscid, Compressible Flows: Vortex Lines Frozen into Fluid
To understand the vorticity evolution law (14.6) physically, we explore various special
cases in this and the next few subsections.
Here we specialize to a barotropic [P = P (ρ)], inviscid (ν = 0) ﬂuid ﬂow. (This
kind of ﬂow often occurs in Earth’s atmosphere and oceans, well away from solid
boundaries.) Then the right-hand side of Eq. (14.6) vanishes, leaving Dω/Dt = 0.
For generality, we temporarily (this subsection only) abandon our restriction to
incompressible ﬂow, ∇. v = 0, but keep the ﬂow barotropic and inviscid. Then it is
straightforward to deduce, from the curl of the Euler equation (13.44), that
Dω
Dt = −ω∇. v
(14.9)
(Ex. 14.4). This equation shows that the vorticity has a ﬂuid derivative parallel to itself:
the ﬂuid slides along its vortex lines, or equivalently, the vortex lines are frozen into
736
Chapter 14. Vorticity

x

vortex lines
FIGURE 14.4 Simple demonstration of the kinematics of vorticity
propagation in a compressible, barotropic, inviscid ﬂow. A short,
thick cylindrical ﬂuid element with generators parallel to the local
vorticity is deformed, by the ﬂow, into a long, slender cylinder.
By virtue of Eq. (14.10), we can think of the vortex lines as being
convectedwiththeﬂuid, withnocreationofnewlinesordestruction
of old ones, so that the number of vortex lines passing through the
cylinder (through its end surface ) remains constant.
(i.e., are carried by) the moving ﬂuid. The wingtip vortex lines of Fig. 14.2 are an
example. They are carried backward by the air that ﬂowed over the wingtips, and they
endow that air with vorticity that emerges from a wingtip.
We can actually make the ﬂuid derivative vanish by substituting ∇. v =
−ρ−1dρ/dt (the equation of mass conservation) into Eq. (14.9); the result is
D
Dt
ω
ρ

= 0
for barotropic, inviscid ﬂow.
(14.10)
Therefore, the quantity ω/ρ evolves according to the same equation as the separation
x of two points in the ﬂuid. To see what this implies, consider a small cylindrical
ﬂuid element whose symmetry axis is parallel to ω (Fig. 14.4). Denote its vectorial
length by x, its vectorial cross sectional area by , and its conserved mass by
M = ρx . .Then, sinceω/ρ pointsalong x andbotharefrozenintotheﬂuid,
it must be that ω/ρ = const × x. Therefore, the ﬂuid element’s conserved mass is
M = ρx .  = const × ω . , so ω .  is conserved as the cylindrical ﬂuid
element moves and deforms. We thereby conclude that the ﬂuid’s vortex lines, with
for barotropic, inviscid
ﬂow: vortex lines are
convected (frozen into the
ﬂuid)
number per unit area proportional to |ω|, are convected by our barotropic, inviscid
ﬂuid, without being created or destroyed.
Now return to an incompressible ﬂow, ∇. v = 0(which includes, of course, Earth’s
oceans and atmosphere), so the vorticity evolution equation becomes Dω/Dt = 0.
Suppose that the ﬂow is 2 dimensional (as it commonly is to moderate accuracy when
averaged over transverse scales large compared to the thickness of the atmosphere and
oceans), so v is in the x and y directions and is independent of z. Then ω = ωez, and
we can regard the vorticity as the scalar ω. Then Eq. (14.5) with (ω . ∇)v = 0 implies
that the vorticity obeys the simple propagation law
dω
dt = 0.
(14.11)
14.2 Vorticity, Circulation, and Their Evolution
737

Thus, in a 2-dimensional, incompressible, barotropic, inviscid ﬂow, the scalar vorticity
is conserved when convected, just like entropy per unit mass in an adiabatic ﬂuid.
EXERCISES
Exercise 14.4 Derivation: Vorticity Evolution in a Compressible,
Barotropic, Inviscid Flow
BytakingthecurloftheEulerequation(13.44), derivethevorticityevolutionequation
(14.9) for a compressible, barotropic, inviscid ﬂow.
14.2.3
14.2.3 Tornados
A particularly graphic illustration of the behavior of vorticity is provided by a tornado.
Tornados in North America are most commonly formed at a front where cold, dry
air from the north meets warm, moist air from the south, and huge, cumulonimbus
thundercloudsform.Astrongupdraftofthewarm, moistaircreatesrotationalmotion
about a horizontal axis, and updraft of the central part of the rotation axis itself
makes it somewhat vertical. A low-pressure vortical core is created at the center of this
spinning ﬂuid (recall Crocco’s theorem, Ex. 13.9), and the spinning region lengthens
under the action of up- and downdrafts. Now, consider this process in the context
of vorticity propagation. As the ﬂow (to ﬁrst approximation) is incompressible, a
lengthening of the spinning region’s vortex lines corresponds to a reduction in the
cross section and a strengthening of the vorticity. This in turn corresponds to an
increase in the tornado’s circulatory speeds. (Speeds in excess of 450 km/hr have been
reported.) If and when the tornado touches down to the ground and its very-low-
pressure core passes over the walls and roof of a building, the far larger, normal
atmospheric pressure inside the building can cause the building to explode. Further
details are explored in Exs. 13.9 and 14.5.
EXERCISES
Exercise 14.5 Problem: Tornado
(a) Figure 14.5 shows photographs of two particularly destructive tornados and one
waterspout (a tornado sucking water from the ocean). For the tornados the wind
speeds near the ground are particularly high: about 450 km/hr. Estimate the wind
speeds at the top, where the tornados merge with the clouds. For the water spout,
the wind speed near the water is about 150 km/hr. Estimate the wind speed at the
top.
(b) Estimate the air pressure in atmospheres in the cores of these tornados and water
spout. (Hint: Use Crocco’s theorem, Ex. 13.9.)
738
Chapter 14. Vorticity

(a)
(b)
(c)
FIGURE 14.5 (a,b) Two destructive tornados and (c) a waterspout. (a) Eric Nguyen / Science Source;
(b) Justin James Hobson, licensed under Creative Commons-ShareAlike 3.0 Unported (CC BY-SA
3.0); (c) NOAA; http://www.spc.noaa.gov/faq/tornado/wtrspout.htm.
Exercise 14.6 Problem: Visualizing a Wingtip Vortex
Explain why the pressure and temperature of the core of a wingtip vortex are
signiﬁcantly lower than the pressure and temperature of the ambient air. Under what
circumstances will this lead to condensation of tiny water droplets in the vortex core,
off which light can scatter, as in Fig. 14.2b?
14.2.4
14.2.4 Circulation and Kelvin’s Theorem
circulation
Intimately related to vorticity is a quantity called circulation ; it is deﬁned as the line
integral of the velocity around a closed curve ∂S lying in the ﬂuid:
 ≡

∂S
v . dx;
(14.12a)
it can be regarded as a property of the closed curve ∂S. We can invoke Stokes’ theorem
to convert this circulation into a surface integral of the vorticity passing through a
surface S bounded by ∂S:
 =

S
ω . d.
(14.12b)
[Note, though, that Eq. (14.12b) is only valid if the area bounded by the contour
circulation as the ﬂux of
vorticity
is simply connected. If the area enclosed contains a solid body, this equation may
fail.] Equation (14.12b) states that the circulation  around ∂S is the ﬂux of vor-
ticity through S, or equivalently, it is proportional to the number of vortex lines
passing through S. Circulation is thus the ﬂuid counterpart of magnetic ﬂux.
14.2 Vorticity, Circulation, and Their Evolution
739

Kelvin’s theorem tells us the rate of change of the circulation associated with a
particular contour ∂S that is attached to the moving ﬂuid. Let us evaluate this rate
directly using the convective derivative of . We do this by differentiating the two
vector quantities inside the integral (14.12a):
d
dt =

∂S
dv
dt
. dx +

∂S
v . d
dx
dt

= −

∂S
∇P
ρ
. dx −

∂S
∇ . dx + ν

∂S
(∇2 v) . dx +

∂S
d 1
2v2,
(14.13)
where we have used the Navier-Stokes equation (14.2) with ν = constant. The second
and fourth terms on the right-hand side of Eq. (14.13) vanish around a closed curve,
and the ﬁrst can be rewritten in different notation to give
Kelvin’s theorem for
evolution of circulation
d
dt = −

∂S
dP
ρ + ν

∂S
(∇2 v) . dx.
(14.14)
This is Kelvin’s theorem for the evolution of circulation. It is an integral version of
our evolution equation (14.6) for vorticity. In a rotating reference frame it must be
augmented by the integral of the Coriolis acceleration −2 × v around the closed
curve∂S, andiftheﬂuidiselectricallyconductingwithcurrentdensityjandpossesses
a magnetic ﬁeld B, it must be augmented by the integral of the Lorentz force per unit
mass (j × B)/ρ around ∂S:
d
dt = −

∂S
dP
ρ + ν

∂S
(∇2 v) . dx −2

∂S
 × v . dx +

∂S
j × B
ρ
. dx.
(14.15)
This is the integral form of Eq. (14.7).
If the ﬂuid is barotropic, P = P (ρ), and the effects of viscosity are negligible (and
the coordinates are inertial and there is no magnetic ﬁeld and no electric current),
then the right-hand sides of Eqs. (14.14) and (14.15) vanish, and Kelvin’s theorem
takes the simple form
conservation of circulation
in a barotropic inviscid
ﬂow
d
dt = 0
for barotropic, inviscid ﬂow.
(14.16)
Eq. (14.16) is the global version of our result that the circulation ω .  of an in-
ﬁnitesimal ﬂuid element is conserved.
The qualitative content of Kelvin’s theorem is that vorticity in a ﬂuid is long lived.
A ﬂuid’s vorticity and circulation (or lack thereof) will persist, unchanged, unless and
until viscosity or a (∇P × ∇ρ)/ρ2 term (or a Coriolis or Lorentz force term) comes
into play in the vorticity evolution equation (14.3). We now explore these sources and
modiﬁcations of vorticity and circulation.
740
Chapter 14. Vorticity

14.2.5
14.2.5 Diffusion of Vortex Lines
First consider the action of viscous stresses on an existing vorticity distribution. For an
incompressible, barotropic ﬂuid with nonnegligible viscosity, the vorticity evolution
law (14.6) becomes
diffusion equation for
vorticity
Dω
Dt = ν∇2ω
for an incompressible, barotropic ﬂuid.
(14.17)
This is a convective vectorial diffusion equation: the viscous term ν∇2ω causes the
vortex lines to diffuse through the moving ﬂuid, and the kinematic viscosity ν is the
diffusion coefﬁcient for the vorticity. When viscosity is negligible, the vortex lines
are frozen into the ﬂow. When viscosity is signiﬁcant and no boundaries impede the
vorticity’s diffusion and the vorticity initially is concentrated in a thin vortex, then
as time t passes the vorticity diffuses outward into a cross sectional area ∼νt in the
diffusion of vortex lines
moving ﬂuid (Ex. 14.7; i.e., the vortex expands). Thus the kinematic viscosity not only
has the dimensions of a diffusion coefﬁcient, it also actually controls the diffusion of
vortex lines relative to the moving ﬂuid.
As a simple example of the spreading of vortex lines, consider an inﬁnite plate
moving parallel to itself relative to a ﬂuid at rest. Transform to the rest frame of the
plate (Fig. 14.6a) so the ﬂuid moves past it. Suppose that at time t = 0 the velocity has
δ(0)
t À δ2(0)/ν
t = 0
vx
vx
x
y
y
y
V
V
(a)
(b)
(c)
δ(t) ~ (νt)1/2
FIGURE 14.6 A simple shear layer that is translation invariant along the ﬂow direction x. Vorticity
diffuses away from the static plate at y = 0, under the action of viscous torques, in much the
same way that heat diffuses away from a heated surface.
14.2 Vorticity, Circulation, and Their Evolution
741

only a component vx parallel to the plate, which depends solely on the distance y from
the plate, so the ﬂow is translation invariant in the x direction; then it will continue
always to be translation invariant. Suppose further that, at t = 0, vx is constant,
vx = V , except in a thin boundary layer near the plate, where it drops rapidly to 0 at
y = 0 (as it must, because of the plate’s no-slip boundary condition; Fig. 14.6b). As the
ﬂow is a function only of y (and t), and v and ω point in directions orthogonal to ey,
in this ﬂow the ﬂuid derivative D/Dt [Eq. (14.5)] reduces to ∂/∂t, and the convective
diffusion equation (14.17) becomes an ordinary scalar diffusion equation for the only
nonzero component of the vorticity: ∂ωz/∂t = ν∇2ωz. Let the initial thickness of the
boundary layer at time t = 0 be δ(0). Then our experience with the diffusion equation
(e.g., Exs. 3.17 and 6.3) tells us that the viscosity will diffuse through the ﬂuid under
the action of viscous stress, and as a result, the boundary-layer thickness will increase
with time as
δ(t) ∼(νt)
1
2
for
t >∼δ(0)2/ν;
(14.18)
see Fig. 14.6c. We compute the evolving structure vx(y, t) of the expanding boundary
layer in Sec. 14.4.
EXERCISES
Exercise 14.7 **Example: Diffusive Expansion of a Vortex
At time t = 0, a 2-dimensional barotropic ﬂow has a velocity ﬁeld, in circular polar co-
ordinates,
v = (j/ϖ)eφ
(Fig.
14.1b);
correspondingly,
its
vorticity
is
ω = 2πjδ(x)δ(y)ez: it is a delta-function vortex. In this exercise you will solve for
the full details of the subsequent evolution of the ﬂow.
(a) Solve the vorticity evolution equation (14.6) to determine the vorticity as a func-
tion of time. From your solution, show that the area in which the vorticity is
concentrated (the cross sectional area of the vortex) at time t is A ∼νt, and show
that the vorticity is becoming smoothed out—it is evolving toward a state of uni-
form vorticity, where the viscosity will no longer have any inﬂuence.
(b) From your computed vorticity in part (a), plus circular symmetry, compute the
velocity ﬁeld as a function of time.
(c) From the Navier-Stokes equation (or equally well, from Crocco’s theorem), com-
pute the evolution of the pressure distribution P (ϖ , t).
Remark: This exercise illustrates a frequent phenomenon in ﬂuid mechanics: The
pressure adjusts itself to whatever it needs to be to accommodate the ﬂow. One
can often solve for the pressure distribution in the end, after having worked out
other details. This happens here because, when one takes the curl of the Navier-
Stokes equation for a barotropic ﬂuid (which we did to get the evolution equation
for vorticity), the pressure drops out—it decouples from the evolution equation for
vorticity and hence velocity.
742
Chapter 14. Vorticity

(b)
(a)
v
v
V
V
FL
FL
sail
boat
FIGURE 14.7 (a) Air ﬂow around an airfoil viewed in cross section.
The solid green lines are ﬂow lines with velocity v; the incoming
velocity is V. (b) Air ﬂow around a sail. The shaded body represents
the hull of a boat seen from above.
Exercise 14.8 **Example: The Lift on an Airplane Wing, Wingtip Vortices,
Sailing Upwind, and Fish Locomotion
When an appropriately curved airfoil (e.g., an airplane wing) is introduced into a
steady ﬂow of air, the air has to ﬂow faster along the upper surface than along the lower
surface, which can create a lifting force (Fig. 14.7a). In this situation, compressibility
and gravity are usually unimportant for the ﬂow.
(a) Show that the pressure difference across the airfoil is given approximately by
P = 1
2ρ(v2) = ρvv. Hence show that the lift exerted by the air on an airfoil
of length L is given approximately by
FL = L

Pdx = ρV L,
(14.19)
where  is the circulation around the airfoil, and V is the air’s incoming speed in
the airfoil’s rest frame. This is known as Kutta-Joukowski’s theorem. Interpret this
result in terms of the conservation of linear momentum, and sketch the overall
ﬂow pattern.
(b) Explain why the circulation around an airplane wing (left orange curve
in Fig. 14.2a) is the same as that around the wingtip’s vortex (right orange curve in
14.2 Vorticity, Circulation, and Their Evolution
743

(a)
(b)
FIGURE 14.8 (a) Smoke rings blown by a man travel away from his mouth. Photo ©Andrew Vargas.
(b) A ring-shaped wingtip vortex is produced by each half beat of the wings of a hovering
hummingbird; the vortices travel downward. Sketch from Vogel, 1994, Fig. 12.7a, reprinted by
permission.
Fig. 14.2a), and correspondingly explain why wingtip vortices are essential fea-
tures of an airplane’s ﬂight. Without them, an airplane could not take off.
(c) How might birds’ wingtip vortices (Fig. 14.2c) be related to the V-shaped conﬁg-
uration of birds in a ﬂying ﬂock? (For discussion, see Vogel, 1994, p. 288.)
(d) Explain how the same kind of lift as occurs on an airplane wing propels a sailboat
forward when sailing upwind, as in Fig. 14.7b.
(e) Snakes, eels, and most ﬁsh undulate their bodies and/or ﬁns as they swim. Draw
pictures that explain how the same principle that propels a sailboat pushes these
animals forward as well.
Exercise 14.9 Problem: Vortex Rings
Smoke rings (ring-shaped vortices) blown by a person (Fig. 14.8a) propagate away
from him. Similarly, a hovering hummingbird produces ring-shaped vortices that
propagate downward (Fig. 14.8b). Sketch the velocity ﬁeld of such a vortex and explain
how it propels itself through the ambient air. For the hovering hummingbird, discuss
the role of the vortices in momentum conservation.
14.2.6
14.2.6 Sources of Vorticity
Having discussed how vorticity is conserved in simple inviscid ﬂows and how it
diffuses away under the action of viscosity, we now consider its sources. The most
important source is a solid surface. When ﬂuid suddenly encounters a solid surface,
such as the leading edge of an airplane wing or a spoon stirring coffee, intermolecular
forcesacttodeceleratetheﬂuidrapidlyinathinboundarylayeralongthesurface.This
deceleration introduces circulation and consequently vorticity into the ﬂow, where
744
Chapter 14. Vorticity

fluid
element
center
of mass
F
P = const
ρ = const
FIGURE 14.9 Mechanical explanation for the creation of vorticity in a
nonbarotropic ﬂuid. The net pressure gradient force F, acting at the
geometric center of a small ﬂuid element, is normal to the isobars (solid
lines) and does not pass through the center of mass of the element; thereby
a torque is produced.
none existed before; that vorticity then diffuses into the bulk ﬂow, thickening the
boundary layer (Sec. 14.4).
If the ﬂuid is nonbarotropic (usually due to spatially variable chemical composi-
tion or spatially variable temperature), then pressure gradients can also create vor-
ticity, as described by the ﬁrst term on the right-hand side of the vorticity evolution
vorticity generated by
nonbarotropic pressure
gradients
law (14.6): (−∇P × ∇ρ)/ρ2. Physically, when the surfaces of constant pressure (iso-
bars) do not coincide with the surfaces of constant density (isochors), then the net
pressure force on a small ﬂuid element does not pass through its center of mass.
The pressure therefore exerts a torque on the ﬂuid element, introducing some rota-
tional motion and vorticity (Fig. 14.9). Nonbarotropic pressure gradients can there-
fore create vorticity within the body of the ﬂuid. Note that because the vortex lines
must be continuous, any fresh ones that are created in the ﬂuid must be created as
loops that expand from a point or a line.
There are three other common sources of vorticity in ﬂuid dynamics:
1. Coriolis forces, when one’s reference frame is rotating rigidly;
2. Lorentz forces, when the ﬂuid is magnetized and electrically conducting [last
vorticity generated by
Coriolis forces, Lorentz
forces, and curving shock
fronts
two terms in Eqs. (14.7) and (14.15)]; and
3. curving shock fronts (when the ﬂuid speed is supersonic).
We discuss these sources in Sec. 14.5 and Chaps. 19 and 17, respectively.
EXERCISES
Exercise 14.10 Problem: Vortices Generated by a Spatula
Fill a bathtub with water and sprinkle baby powder liberally over the water’s surface
to aid in viewing the motion of the surface water. Then take a spatula, insert it gently
into the water, move it slowly and brieﬂy perpendicular to its ﬂat face, then extract it
14.2 Vorticity, Circulation, and Their Evolution
745

gently from the water. Twin vortices will have been generated. Observe the vortices’
motions. Explain (i) the generation of the vortices, and (ii) the sense in which the
velocity ﬁeld of each vortex convects the other vortex through the ambient water. Use
your bathtub or a swimming pool to perform other experiments on the generation
and propagation of vortices.
Exercise 14.11 Example: Vorticity Generated by Heating
Rooms are sometimes heated by radiators (hot surfaces) that have no associated
blowers or fans. Suppose that, in a room whose air is perfectly still, a radiator is
turned on to high temperature. The air will begin to circulate (convect), and that
air motion contains vorticity. Explain how the vorticity is generated in terms of the
−

dP/ρ term of Kelvin’s theorem (14.14) and the (−∇P × ∇ρ)/ρ2 term of the
vorticity evolution equation (14.6).
14.3
14.3 Low-Reynolds-Number Flow—Stokes Flow and Sedimentation
Reynolds number as ratio
of inertial acceleration to
viscous acceleration
In the previous chapter, we deﬁned the Reynolds number Re to be the product of the
characteristic speed V and lengthscale a of a ﬂow divided by its kinematic viscosity
ν = η/ρ: Re ≡V a/ν. The signiﬁcance of the Reynolds number follows from the fact
that, in the Navier-Stokes equation (14.2), the ratio of the magnitude of the inertial
acceleration |(v . ∇)v| to the viscous acceleration |ν∇2v| is approximately equal to
Re. Therefore, when Re ≪1, the inertial acceleration can often be ignored, and the
low-Re ﬂow: pressure
gradient balances viscous
stress
velocity ﬁeld is determined by balancing the pressure gradient against the viscous
stress. The velocity then scales linearly with the magnitude of the pressure gradient
and vanishes when the pressure gradient vanishes.
low-Re ﬂow is nearly
reversible
This has the amusing consequence that a low-Reynolds-number ﬂow driven by
a solid object moving through a ﬂuid at rest is effectively reversible. An example,
depicted in the movie by Taylor (1964), is a rotating sphere. If it is rotated slowly
in a viscous ﬂuid for N revolutions in one direction, then rotated in reverse for N
revolutions, the ﬂuid elements will return almost to their original positions. This
phenomenon is easily understood by examining the Navier-Stokes equation (14.2)
with the inertial acceleration dv/dt neglected and gravity omitted: ∇P = η∇2v;
pressure gradient balances viscous force density. No time derivatives appear here,
and the equation is linear. When the direction of the sphere’s rotation is reversed,
the pressure gradients reverse and the velocity ﬁeld reverses, bringing the ﬂuid back
to its original state.
From the magnitudes of viscosities of real ﬂuids (Table 13.2), it follows that the
regimes of low-Re ﬂow
low-Reynolds-number limit is appropriate either for small-scale ﬂows (e.g., the mo-
tion of microorganisms in water; see Box 14.3) or for very viscous large scale ﬂuids
(e.g., Earth’s mantle; Ex. 14.13).
746
Chapter 14. Vorticity

BOX 14.3.
SWIMMING AT LOW AND HIGH REYNOLDS NUMBER:
FISH VERSUS BACTERIA
Swimming provides insight into the differences between ﬂows with low and
high Reynolds numbers. In water, the ﬂow around a swimming ﬁsh has Re
∼10+6, while that around a bacterium has Re ∼10−5. In the simplest variant
of ﬁsh locomotion, the ﬁsh wags its tail ﬁn back and forth nearly rigidly,
pushing water backward and itself forward with each stroke [schematic
drawing (a) below]. And a simple variant of bacterial propulsion is that of
the E. coli bacterium: it has a rigid corkscrew-shaped tail (made from several
ﬂagella), which rotates, pushing water backward via friction (viscosity) and
itself forward [schematic drawing (b), adapted from Nelson (2008)].
F
F
V
V
(a)
(b)

A ﬁsh’s tail-wagging propulsion would fail at low Reynolds number,
because the ﬂow would be reversible: after each back-forth wagging cycle,
the ﬂuid would return to its original state—a consequence of the linear, no-
time-derivatives balance of pressure and viscous forces: ∇P = η∇2v (see
second paragraph of Sec. 14.3). However, for the ﬁsh with high Reynolds
number, aside from a very thin boundary layer near the ﬁn’s surface,
viscosity is negligible, and so the ﬂow is governed by Euler’s equation:
dv/dt = (∂/∂t + v . ∇)v = −∇P/ρ (and of course mass conservation).
The time derivatives and nonlinearity make the ﬂuid’s motion nonreversible
in this case. With each back-forth cycle of wag, the tail feeds substantial
net backward momentum into the water, and the ﬁsh acquires net forward
momentum (which will be counteracted by friction in boundary layers along
the ﬁsh’s body if the ﬁsh is moving fast enough).
(continued)
14.3 Low-Reynolds-Number Flow—Stokes Flow and Sedimentation
747

BOX 14.3.
(continued)
E. coli’s corkscrew propulsion would fail at high Reynolds number,
because its tail’s ﬂagella are so thin (d ∼20 nm) that they could not push
any noticeable amount of water inertially. However, at E. coli’s low Reynolds
number, the amount of water entrained by the tail’s viscous friction is almost
independent of the tail’s thickness. To understand the resulting frictional
propulsion, consider a segment of the tail shown white in drawing (b). It
moves laterally with velocity V. If the segment’s length ℓis huge compared
to its thickness d, then the water produces a drag force F on it of magnitude
F ∼2πηV ℓ/ ln(ν/V d) (Ex. 14.12) that points not opposite to V but rather
somewhat forward of that direction, as shown in the drawing. The reason
is that this segment of a thin rod has a drag that is larger (by about a factor
two) when pulled perpendicular to its long axis than when pulled along its
long axis. Hence the drag is a tensorial function of V, Fi = HijVj, and is not
parallel to V. In drawing (b) the transverse component of the drag cancels
out when one integrates it along the winding tail, but the forward component
adds coherently along the tail, giving the bacterium a net forward force.
For further discussion of ﬁsh as well as bacteria, see, for example, Vogel
(1994) and Nelson (2008).
14.3.1
14.3.1 Motivation: Climate Change
An important example of a small-scale ﬂow arises when we ask whether cooling of
Earth due to volcanic explosions can mitigate global warming.
The context is concern about anthropogenic (human-made) climate change.
Earth’s atmosphere is a subtle and fragile protector of the environment that allows life
to ﬂourish. Especially worrisome is the increase in atmospheric carbon dioxide—by
nearly 25% over the past 50 years to a mass of 3 × 1015 kg. As an important greenhouse
gas, carbon dioxide traps solar radiation. Increases in its concentration are contribut-
ing to the observed increase in mean surface temperature, the rise of sea levels, and
the release of oceanic carbon dioxide with potential runaway consequences.
These effects are partially mitigated by volcanos like Krakatoa, which exploded in
1883,3 releasing roughly 250megatons or ∼1018 J of energy and nearly 1014 kg of small
particles (aerosols, ash, soot, etc.), of which ∼1012 kg was raised into the stratosphere,
3.
A more recent example was the Pinatubo volcano in 1991, which released roughly a tenth the mass of
Krakatoa. Studying the consequences of this explosion provided important calibration for models of
greater catastrophes.
748
Chapter 14. Vorticity

x
a
FIGURE14.10 FlowlinesforStokesﬂowaround
a sphere.
where much of it remained for several years. These micron-sized particles absorb light
with roughly their geometrical cross section. The area of Earth’s surface is roughly
5 × 1014 m2, and the density of the particles is roughly 2000 kg m−3, so that 1012 kg
ofaerosolsissufﬁcienttoblotouttheSun.Morespeciﬁcally, themicron-sizedparticles
absorb solar optical and ultraviolet radiation while remaining reasonably transparent
to infrared radiation escaping from Earth’s surface. The result is a noticeable global
cooling of Earth for as long as the particles remain suspended in the atmosphere.4
A key issue in assessing how our environment is likely to change over the next
century is how long particles of size 1–10 μm will remain in the atmosphere after
volcanic explosions (i.e., their rate of sedimentation). This problem is one of low-
Reynolds-number ﬂow.
We model the sedimentation by computing the speed at which a spherical soot
particle falls through quiescent air when the Reynolds number is small. The speed
is governed by a balance between the downward force of gravity and the speed-
dependent upward drag force of the air. We compute this sedimentation speed by
ﬁrst evaluating the force of the air on the moving particle ignoring gravity, and then,
at the end of the calculation, inserting the inﬂuence of gravity.
14.3.2
14.3.2 Stokes Flow
Stokes ﬂow
We model the soot particle as a sphere with radius a. The low-Reynolds-number ﬂow
of a viscous ﬂuid past such a sphere is known as Stokes ﬂow. We calculate the ﬂow’s
velocity ﬁeld, and then from it, the force of the ﬂuid on the sphere. (This calculation
also ﬁnds application in the famous Millikan oil-drop experiment and is a prototype
for many more complex calculations of low-Reynolds-number ﬂow.)
SOLUTION FOR VELOCITY FIELD AND PRESSURE
It is easiest to tackle this problem in the frame of the sphere, where the ﬂow is station-
ary (time-independent; Fig. 14.10). We seek a solution to the Navier-Stokes equation
in which the ﬂow velocity v(x) tends to a constant value V (the velocity of the sphere
4.
Similar effects could follow the explosion of nuclear weapons in a major nuclear war according to Turco
et al. (1986), a phenomenon they called nuclear winter.
14.3 Low-Reynolds-Number Flow—Stokes Flow and Sedimentation
749

through the ﬂuid) at large distances from the sphere’s center. We presume the asymp-
totic ﬂow velocity V to be highly subsonic, so the ﬂow is effectively incompressible:
∇. v = 0.
insigniﬁcance of inertial
acceleration
We deﬁne the Reynolds number for this ﬂow by Re = ρV a/η = V a/ν. As this is
assumed to be small, in the Navier-Stokes equation (14.2) we can ignore the inertial
term, whichisO(V v/a), incomparisonwiththeviscousterm, whichisO(νv/a2);
here v ∼V is the total velocity variation. The time-independent Navier-Stokes
equation (14.2) can thus be well approximated by ∇P = ρg + η∇2v. The uniform
gravitational force density ρg is obviously balanced by a uniform pressure gradient
(hydrostatic equilibrium). Removing these uniform terms from both sides of the
equation, we get
∇P = η∇2v,
(14.20)
where ∇P is now just the nonuniform part of the pressure gradient required to
balance the viscous force density. The full details of the ﬂow are governed by this
force-balance equation, the ﬂow’s incompressibility
∇. v = 0,
(14.21)
and the boundary conditions v = 0 at r = a and v →V at r →∞.
From force balance (14.20) we infer that in order of magnitude the difference
between the ﬂuid’s pressure on the front of the sphere and that on the back is P ∼
ηV/a. We also expect a viscous drag stress along the sphere’s sides of magnitude
Trθ ∼ηV/a, where V/a is the magnitude of the shear. These two stresses, acting
on the sphere’s surface area ∼a2, will produce a net drag force F ∼ηV a. Our goal
is to verify this order-of-magnitude estimate, compute the force more accurately,
then balance this force against gravity (adjusted for the much smaller Archimedes
buoyancy force produced by the uniform part of the pressure gradient), and thereby
infer the speed of fall V of a soot particle.
For a highly accurate analysis of the ﬂow, we could write the full solution as a
perturbation expansion in powers of the Reynolds number Re. We compute only the
leading term in this expansion; the next term, which corrects for inertial effects, will
be smaller than our solution by a factor O(Re).
some general solution
ideas
Our solution to this classic problem is based on some general ideas that ought to be
familiar from other areas of physics. First, we observe that the quantities in which we
are interested are the pressure P , the velocity v, and the vorticity ω—a scalar, a polar
vector, and an axial vector, respectively—and to ﬁrst order in the Reynolds number
they should be linear in V. The only scalar we can form that is linear in V is V . x,
so we expect the variable part of the pressure to be proportional to this combination.
For the polar-vector velocity we have two choices, a part ∝V and a part ∝(V . x)x;
both terms are present. Finally, for the axial-vector vorticity, our only option is a term
∝V × x. We use these combinations below.
750
Chapter 14. Vorticity

Now take the divergence of Eq. (14.20), and conclude that the pressure must satisfy
Laplace’s equation: ∇2P = 0. The solution should be axisymmetric about V, and we
know that axisymmetric solutions to Laplace’s equation that decay as r →∞can be
expanded as a sum over Legendre polynomials, !∞
ℓ=0 Pℓ(μ)/rℓ+1, where μ is the
cosine of the angle θ between V and x, and r is |x|. Since the variable part of P is
proportional to V . x, the dipolar (ℓ= 1) term [for which P1(μ) = μ = V . x/(V r)]
is all we need; the higher-order polynomials will be higher-order in V and thus must
arise at higher orders of the Reynolds-number expansion. We therefore write
P = P∞+ kη(V . x)a
r3
.
(14.22)
Here k is a numerical constant that must be determined, we have introduced a factor
η to make k dimensionless, and P∞is the pressure far from the sphere.
Next consider the vorticity. Since it is proportional to V × x and cannot depend
in any other way on V, it must be expressible as
ω = V × x
a2
f (r/a).
(14.23)
The factor a appears in the denominator to make the unknown function f dimen-
sionless. We determine this unknown function by rewriting Eq. (14.20) in the form
∇P = −η∇× ω
(14.24)
[which we can do because ∇× ω = −∇2v + ∇(∇. v), and ∇. v = 0], and then
inserting Eqs. (14.22) and (14.23) into (14.24) to obtain f (ξ) = kξ−3; hence we have
ω = k(V × x)a
r3
.
(14.25)
electromagnetic analogy
Equation (14.25) for the vorticity looks familiar. It has the form of the Biot-Savart
law for the magnetic ﬁeld from a current element. We can therefore write down
immediately a formula for its associated “vector potential,” which in this case is the
velocity:
v(x) = kaV
r
+ ∇ψ.
(14.26)
The addition of the ∇ψ term corresponds to the familiar gauge freedom in deﬁning
the vector potential. However, in the case of ﬂuid dynamics, where the velocity is
a directly observable quantity, the choice of the scalar ψ is ﬁxed by the boundary
conditions instead of being free. As ψ is a scalar linear in V, it must be expressible in
terms of a second dimensionless function g(ξ) as
ψ = g(r/a)V . x.
(14.27)
14.3 Low-Reynolds-Number Flow—Stokes Flow and Sedimentation
751

Next we recall that the ﬂow is incompressible: ∇. v = 0. Substituting Eq. (14.27)
into Eq. (14.26) and setting the divergence expressed in spherical polar coordinates
to zero, we obtain an ordinary differential equation for g:
d2g
dξ2 + 4
ξ
dg
dξ −k
ξ3 = 0.
(14.28)
This has the solution
g(ξ) = A −k
2ξ + B
ξ3 ,
(14.29)
where A and B are integration constants. As v →V far from the sphere, the constant
A = 1. The constants B and k can be found by imposing the boundary condition v = 0
for r = a. We thereby obtain B = −1/4 and k = −3/2. After substituting these values
into Eq. (14.26), we obtain for the velocity ﬁeld:
v =
'
1 −3
4
a
r

−1
4
a
r
3(
V −3
4
a
r
3 '
1 −
a
r
2(
(V . x)x
a2
.
(14.30)
The associated pressure and vorticity, from Eqs. (14.22) and (14.25), are given by
velocity, pressure, and
vorticity in Stokes ﬂow
P = P∞−3ηa(V . x)
2r3
,
ω = 3a(x × V)
2r3
.
(14.31)
The pressure is seen to be largest on the upstream hemisphere, as expected. However,
the vorticity, which points in the direction of eφ, is seen to be symmetric between
the front and the back of the sphere. This is because our low-Reynolds-number
approximation neglects the advection of vorticity by the velocity ﬁeld and only retains
the diffusive term. Vorticity is generated on the front surface of the sphere and diffuses
into the surrounding ﬂow; then, after the ﬂow passes the sphere’s equator, the vorticity
diffuses back inward and is absorbed onto the sphere’s back face.
An analysis that includes higher orders in the Reynolds number would show that
not all of the vorticity is reabsorbed; a small portion is left in the ﬂuid downstream
from the sphere.
We have been able to obtain a simple solution for low-Reynolds-number ﬂow past
a sphere. Although closed-form solutions like this are not common, the methods used
to derive it are of widespread applicability. Let us recall them. First, we approximated
the equation of motion by omitting the subdominant inertial term and invoked a
symmetry argument. We used our knowledge of elementary electrostatics to write the
pressure in the form of Eq. (14.22). We then invoked a second symmetry argument
to solve for the vorticity and drew on another analogy with electromagnetic theory
to derive a differential equation for the velocity ﬁeld, which was solved subject to the
no-slip boundary condition on the surface of the sphere.
752
Chapter 14. Vorticity

Having obtained a solution for the velocity ﬁeld and pressure, it is instructive to
reexamine our approximations. The ﬁrst point to notice is that the velocity pertur-
bation, given by Eq. (14.30), dies off slowly—it is inversely proportional to distance
r from the sphere. Thus for our solution to be valid, the region through which the
sphere is moving must be much larger than the sphere; otherwise, the boundary con-
ditions at r →∞have to be modiﬁed. This is not a concern for a soot particle in
the atmosphere. A second, related point is that, if we compare the sizes of the iner-
tial term (which we neglected) and the pressure gradient (which we kept) in the full
Navier-Stokes equation, we ﬁnd that
|(v . ∇)v| ∼V 2a
r2 ,
8888
∇P
ρ
8888 ∼ηaV
ρr3 .
(14.32)
At r = a their ratio is V aρ/η = V a/ν, which is the (small) Reynolds number. How-
matched asymptotic
expansions
ever, at a distance r ∼η/ρV = a/Re from the sphere’s center, the inertial term
becomes comparable to the pressure term. Correspondingly, to improve on our zero-
order solution, we must perform a second expansion at large r including inertial
effects and then match it asymptotically to our near-zone expansion (see, e.g., Pan-
ton, 2005, Sec. 21.9). This technique of matched asymptotic expansions (Panton, 2005,
Chap. 15) is a very powerful and general way of ﬁnding approximate solutions valid
over a wide range of lengthscales, where the dominant physics changes from one scale
to the next. We present an explicit example of such a matched asymptotic expansion
in Sec. 16.5.3.
DRAG FORCE
Let us return to the problem that motivated this calculation: computing the drag force
on the sphere. It can be computed by integrating the stress tensor T = P g −2ησ over
the sphere’s surface. If we introduce a local orthonormal basis {er, eθ, eφ} with polar
axis (θ = 0) along the ﬂow direction V, then we readily see that the only nonzero
viscous contribution to the surface stress tensor is Trθ = Tθr = η∂vθ/∂r. The net
resistive force along the direction of the velocity (drag force) is then given by
F =

r=a
d . T . V
V
=
 2π
0
2πa2 sin θdθ

−P∞cos θ + 3ηV cos2 θ
2a
+ 3ηV sin2 θ
2a

,
(14.33)
where the ﬁrst two terms are from the ﬂuid’s pressure on the sphere and the third is
from its viscous stress. The integrals are easy and give F = 6πηaV for the force, in
the direction of the ﬂow. In the rest frame of the ﬂuid, the sphere moves with velocity
Vsphere = −V, so the drag force that the sphere experiences is
Stokes’ law for drag force
in low-Re ﬂow
F = −6πηaVsphere.
(14.34)
Eq. (14.34) is Stokes’ law for the drag force in low-Reynolds-number ﬂow. Two-thirds
of the force comes from the viscous stress and one third from the pressure. When the
14.3 Low-Reynolds-Number Flow—Stokes Flow and Sedimentation
753

inﬂuence of inertial forces at r >∼a/Re is taken into account via matched asymptotic
expansions, one obtains a correction to the drag force:
correction to drag force
F = −6πηaVsphere

1 + 3aV
8ν

= −6πηaVsphere

1 + 3 Red
16

,
(14.35)
where (as is common) the Reynolds number Red is based on the sphere’s diameter
d = 2a rather than its radius.
EXERCISES
Exercise 14.12 Problem: Stokes Flow around a Cylinder: Stokes’ Paradox
Consider low-Reynolds-number ﬂow past an inﬁnite cylinder whose axis coincides
with the z-axis. Try to repeat the analysis we used for a sphere to obtain an order-of-
magnitude estimate for the drag force per unit length. [Hint: You might ﬁnd it useful
to write v = ∇× (ζez), which guarantees ∇. v = 0 (cf. Box 14.4); then show that
the scalar stream function ζ(ϖ , φ) satisﬁes the biharmonic equation ∇2∇2ζ = 0.]
You will encounter difﬁculty in ﬁnding a solution for v that satisﬁes the necessary
boundary conditions at the cylinder’s surface ϖ = a and at large radii ϖ ≫a. This
difﬁculty is called Stokes’ paradox, and the resolution to it by including inertial forces
atlargeradiiwasgivenbyCarlWilhelmOseen(see, e.g., Panton, 2005, Sec.21.10).The
result for the drag force per unit length is F = −2πηV(α−1 −0.87α−3 + . . .), where
α = ln(3.703/Red), and Red = 2aV/ν is the Reynolds number computed from the
cylinder’sdiameterd = 2a.ThelogarithmicdependenceontheReynoldsnumberand
thence on the cylinder’s diameter is a warning of the subtle mixture of near-cylinder
viscous ﬂow and far-distance inertial ﬂow that inﬂuences the drag.
14.3.3
14.3.3 Sedimentation Rate
Now we return to the problem that motivated our study of Stokes ﬂow: the rate of sed-
imentation of soot particles (the rate at which they sink to the ground) after a gigantic
volcanic eruption. To analyze this, we must restore gravity to our analysis. We can
do so by restoring to the Navier-Stokes equation the uniform pressure gradient and
balancing gravitational term that we removed just before Eq. (14.20). Gravity and the
buoyancy (Archimedes) force from the uniform pressure gradient exert a net down-
ward force (4πa3/3)(ρs −ρ)g on the soot particle, which must balance the upward
resistive force (14.34). Here ρs ∼2,000 kg m−3 is the density of soot and ρ ∼1kg m−3
is the far smaller (and here negligible) density of air. Equating these forces, we obtain
sedimentation speed
V = 2ρsa2g
9η
.
(14.36)
The kinematic viscosity of air at sea level is, according to Table 13.2, ν ∼10−5 m2 s−1,
and the density is ρa ∼1 kg m−3, so the coefﬁcient of viscosity is η = ρaν ∼
10−5 kg m−1 s−1. This viscosity is proportional to the square root of temperature
and is independent of the density [cf. Eq. (13.72)]; however, the temperature does not
754
Chapter 14. Vorticity

vary by more than about 25% up to the stratosphere (Fig. 13.2), so for an approxi-
mate calculation, we can use its value at sea level. Substituting the above values into
Eq. (14.36), we obtain an equilibrium sedimentation speed
V ∼0.5(a/1 μm)2 mm s−1.
(14.37)
For self-consistency we should also estimate the Reynolds number:
Re ∼2ρaV a
η
∼10−4

a
1 μm
3
.
(14.38)
Our analysis is therefore only likely to be adequate for particles of radius a <∼10 μm.
limitations on validity of
analysis
There is also a lower bound to the size of the particle for validity of this analysis: the
meanfreepathofthenitrogenandoxygenmoleculesmustbesmallerthantheparticle.
The mean free path is ∼0.3 μm, so the resistive force is reduced when a <∼1 μm.5
The sedimentation speed (14.37) is much smaller than wind speeds in the upper
atmosphere: vwind ∼30 m s−1. However, as the stratosphere is reasonably stratiﬁed,
the net vertical motion due to the winds is quite small,6 and so we can estimate the
settling time by dividing the stratosphere’s height ∼30 km by the speed [Eq. (14.37)]
to obtain
tsettle ∼6 × 107

a
1 μm
−2
s ∼2

a
1 μm
−2
years.
(14.39)
This calculation is a simple model for more serious and complex analyses of sed-
imentation after volcanic eruptions, and the resulting mitigation of global warming.
Of course, huge volcanic eruptions are rare, so no matter the result of reliable fu-
ture analyses, we cannot count on volcanos to save humanity from runaway global
warming. And the consequences of “geo-engineering” ﬁxes in which particles are de-
liberately introduced into the atmosphere are correspondingly uncertain.
EXERCISES
Exercise 14.13 Problem: Viscosity of Earth’s Mantle
Episodic glaciation subjects Earth’s crust to loading and unloading by ice. The last
major ice age was 10,000 years ago, and the subsequent unloading produces a nontidal
contribution to the acceleration of Earth’s rotation rate of order ||/| ˙| ≃6 × 1011 yr,
detectable from observing the positions of distant stars. Corresponding changes in
Earth’soblatenessproduceadecreaseintherateofnodallineregressionofthegeodetic
satellites LAGEOS.
(a) Estimate the speed with which the polar regions (treated as spherical caps of
radius ∼1,000 km) are rebounding now. Do you think the speed was much greater
in the past?
5.
A dimensionless number—the ratio of the mean free path to the lengthscale of the ﬂow (in this case the
radius of the particle), called the Knudsen number or Kn—has been deﬁned to describe this situation.
Corrections to Stokes’ law for the drag force are needed when Kn >∼1.
6.
Brownian motion also affects the sedimentation rate for very small particles.
14.3 Low-Reynolds-Number Flow—Stokes Flow and Sedimentation
755

(b) Geological evidence suggests that a particular glaciated region of radius about
1,000 km sank in ∼3,000 yr during the last ice age. By treating this as a
low-Reynolds-number viscous ﬂow, make an estimate of the coefﬁcient of vis-
cosity for the mantle.
Exercise 14.14 Example: Undulatory Locomotion in Microorganisms
Many microorganisms propel themselves, at low Reynolds number, using undulatory
motion. Examples include the helical motion of E. coli’s corkscrew tail (Box 14.3),
and undulatory waves in a forest of cilia attached to an organism’s surface, or near a
bare surface itself. As a 2-dimensional model for locomotion via surface waves, we
idealize the organism’s undisturbed surface as the plane y = 0, and we assume the
surface undulates in and out with displacement δy = (−u/kC) sin[k(x −Ct)] and
hence velocity Vy = u cos[k(x −Ct)]. Here u is the amplitude, k the wave number,
and C the surface speed in the organism’s rest frame. Derive the velocity ﬁeld v for
the ﬂuid at y > 0 produced by this wall motion, and from it deduce the velocity of the
organism through the ﬂuid. You could proceed as follows.
(a) The velocity ﬁeld must satisfy the incompressible, low-Reynolds-number equa-
tions ∇P = η∇2v and ∇. v = 0 [Eqs. (14.20) and (14.21)]. Explain why v (which
must point in the x and y directions) can be expressed as the curl of a vector po-
tential that points in the z direction: v = ∇× (ζez); and show that ζ(t, x, y) (the
stream function; see Box 14.4 in Sec. 14.4.1) satisﬁes the biharmonic equation:
∇2∇2ζ = 0.
(b) Show that the following ζ satisﬁes the biharmonic equation and satisﬁes the
required boundary conditions at the organism’s surface, vx[x, δy(x, t), t]= 0and
vy[x, δy(x, t), t]= Vy(x, t), andtheappropriateboundaryconditionsaty →∞:
ζ = −u
k (1 + ky) exp(−ky) sin[k(x −Ct)]
+ u2
2C y{1 −exp(−2ky) cos[2k(x −Ct)]} + O(u3).
(14.40)
Explain how ∇P = η∇2v is then easily satisﬁed.
(c) Show that the streamlines (tangent to v) are surfaces of constant ζ. Plot these
streamlines at t = 0 and discuss how they change as t passes. Explain why they
are physically reasonable.
(d) Show that at large y the ﬂuid moves with velocity v = [u2/(2C)]ex, and that
therefore, in the asymptotic rest frame of the ﬂuid, the organism moves with
velocity −[u2/(2C)]ex, opposite to k. Is this physically reasonable? Why does
the organism’s inertia (and hence its mass) not inﬂuence this velocity? That the
organism’s velocity is second order in the velocity of its surface waves illustrates
the difﬁculty of locomotion at low Reynolds number.
756
Chapter 14. Vorticity

(e) Now consider what happens if the undulation is longitudinal with motion lying
in the plane of the undulating surface. Sketch the ﬂow pattern, and show that the
organism will now move in the direction of k.
14.4
14.4 High-Reynolds-Number Flow—Laminar Boundary Layers
As we have described, ﬂow near a solid surface creates vorticity, and consequently,
the velocity ﬁeld near the surface cannot be derived from a scalar potential, v = ∇ψ.
However, if the Reynolds number is high, then the vorticity may be localized in a thin
boundary layers in high-Re
ﬂow
boundary layer adjacent to the surface, as in Fig. 14.6. Then the ﬂow may be very
nearly of potential form v = ∇ψ outside that boundary layer. In this section, we use
the equations of hydrodynamics to model the ﬂow in the simplest example of such
a boundary layer: that formed when a long, thin plate is placed in a steady, uniform
ﬂow v = V ex with its surface parallel to the ﬂow (Fig. 14.11).
laminar ﬂow
If the plate is not too long, then the ﬂow will be laminar, that is, steady and
2-dimensional—a function only of the distances x along the plate’s length and y
perpendicular to the plate (both being measured from an origin at the plate’s front).
We assume the ﬂow to be highly subsonic, so it can be regarded as incompressible. As
the viscous stress decelerates the ﬂuid close to the plate, it must therefore be deﬂected
away from the plate to avoid accumulating, thereby producing a small y component of
velocity along with the larger x component. As the velocity is uniform well away from
the plate, the pressure is constant outside the boundary layer. We use this condition
to motivate the approximation that P is also constant in the boundary layer. After
solving for the ﬂow, we will check the self-consistency of this ansatz (guess). With
plate
boundary layer
y
δ(x)
x
V
FIGURE 14.11 Laminar boundary layer formed by a long, thin plate in a ﬂow with
asymptotic speed V . The length ℓof the plate must give a Reynolds number
Reℓ≡V ℓ/ν in the range 10 <∼Reℓ<∼106. If Reℓis much less than 10, the plate will
be in or near the regime of low-Reynolds-number ﬂow (Sec. 14.3), and the boundary
layer will be so thick everywhere that our analysis will fail. If Reℓis much larger
than 106, then at sufﬁciently great distances x down the plate (Rex = V x/ν >∼106),
a portion of the boundary layer will become turbulently unstable and its simple
laminar structure will be destroyed (see Chap. 15).
14.4 High-Reynolds-Number Flow—Laminar Boundary Layers
757

P = constant and the ﬂow stationary, only the inertial and viscous terms remain in
the Navier-Stokes equation (14.2):
(v . ∇)v ≃ν∇2v.
(14.41)
This equation must be solved in conjunction with ∇. v = 0 and the boundary con-
ditions v →V ex as y →∞and v →0 as y →0.
The ﬂuid ﬁrst encounters the no-slip boundary condition at the front of the plate,
x = y = 0. The ﬂow there abruptly decelerates to vanishing velocity, creating a steep
velocity gradient that contains a sharp spike of vorticity. This is the birth of the
vorticity created at
beginning of plate;
circulation conserved
thereafter
boundary layer.
Farther downstream, the total ﬂux of vorticity inside the rectangle C of Fig. 14.12,

ω . d, is equal to the circulation C =

C v . dx around C. The ﬂow velocity is
zero on the bottom leg of C, and it is (very nearly) orthogonal to C on the vertical
legs, so the only nonzero contribution is from the top leg, which gives C = V x.
Therefore, the circulation per unit length (ﬂux of vorticity per unit length C/x)
is V everywhere along the plate. This means that there is no new vorticity acquired,
and none is lost after the initial spike at the front of the plate.
As the ﬂuid ﬂows down the plate, from x = 0 to larger x, the spike of vorticity,
created at the plate’s leading edge, gradually diffuses outward from the wall into the
ﬂow, thickening the boundary layer.
Let us compute the order of magnitude of the boundary layer’s thickness δ(x)
as a function of distance x down the plate. Incompressibility, ∇. v = 0, implies that
vy ∼vxδ/x. Using this to estimate the relative magnitudes of the various terms in the
x component of the force-balance equation (14.41), we see that the dominant inertial
term (left-hand side) is ∼V 2/x and the dominant viscous term (right-hand side) is
boundary layer thickens
due to viscous diffusion of
vorticity
∼νV/δ2. We therefore obtain the estimate δ ∼√νx/V . This motivates us to deﬁne
the function
δ(x) ≡
&νx
V
(14.42)
for use in our quantitative analysis. Our analysis will reveal that the actual thickness
of the boundary layer is several times larger than this δ(x).
Equation (14.42) shows that the boundary layer has a parabolic shape: y ∼δ(x) =
√νx/V . To keep the analysis manageable, we conﬁne ourselves to the region, not too
close to the front of the plate, where the layer is thin, δ ≪x, and the velocity is nearly
parallel to the plate, vy ∼(δ/x)vx ≪vx.
14.4.1
14.4.1 Blasius Velocity Proﬁle Near a Flat Plate:
Stream Function and Similarity Solution
similarity ansatz
To proceed further, we use a technique of widespread applicability in ﬂuid mechanics:
wemakeasimilarityansatz,whosevalidityweelucidateneartheendofthecalculation.
758
Chapter 14. Vorticity

boundary layer
v = 0
y
V
C
δ
x
FIGURE 14.12 A rectangle C used in showing that a boundary
layer’s circulation per unit length C/x is equal to the ﬂow
speed V just above the boundary layer.
Wesupposethat, oncetheboundarylayerhasbecomethin(δ ≪x), thecrosssectional
shape of the ﬂow is independent of distance x down the plate (it is “similar” at all x,
also called “self-similar”). Stated more precisely, we assume that vx(x, y) (which has
magnitude ∼V ) and (x/δ)vy (which also has magnitude ∼V ) are functions only of
the single transverse, dimensionless variable:
ξ =
y
δ(x) = y
&
V
νx .
(14.43)
Thenourtaskistocomputev(ξ)subjecttotheboundaryconditionsv = 0atξ = 0,
and v = V ex at ξ ≫1. We do so with the aid of a second, very useful calculational
device. Recall that any vector ﬁeld [v(x) in our case] can be expressed as the sum of
the gradient of a scalar potential and the curl of a vector potential: v = ∇ψ + ∇× A.
If our ﬂow were irrotational (ω = 0), we would need only ∇ψ, but it is not; the
vorticity in the boundary layer is large. On the other hand, to high accuracy the ﬂow
is incompressible, θ = ∇. v = 0, which means we need only the vector potential:
v = ∇× A. And because the ﬂow is 2-dimensional (depends only on x and y and
has v pointing only in the x and y directions), the vector potential need only have a z
component: A = Azez. We denote its nonvanishing component by Az ≡ζ(x, y) and
stream function
give it the name stream function, since it governs how the laminar ﬂow streams. In
terms of the stream function, the relation v = ∇× A takes the simple form
vx = ∂ζ
∂y ,
vy = −∂ζ
∂x .
(14.44)
Equation (14.44) automatically satisﬁes ∇. v = 0. Notice that v . ∇ζ = vx∂ζ/∂x +
vy∂ζ/∂y = −vxvy + vyvx = 0. Thus the stream function is constant along streamlines.
(As an aside that often will be useful, e.g., in Exs. 14.12 and 14.20, we generalize this
stream function in Box 14.4.)
14.4 High-Reynolds-Number Flow—Laminar Boundary Layers
759

BOX 14.4.
STREAM FUNCTION FOR A GENERAL,
TWO-DIMENSIONAL, INCOMPRESSIBLE FLOW
Consider any orthogonal coordinate system in ﬂat 3-dimensional space, for
which the metric coefﬁcients are independent of one of the coordinates,
say, x3:
ds2 = g11(x1, x2) dx2
1 + g22(x1, x2) dx2
2 + g33(x1, x2) dx2
3.
(1)
The most common examples are Cartesian coordinates {x, y, z} with
g11 = g22 = g33 = 1; cylindrical coordinates {ϖ , z, φ} with g11 = g22 = 1
and g33 = ϖ 2; and spherical coordinates {r, θ, φ} with g11 = 1, g22 = r2, and
g33 = r2 sin2 θ. Suppose the velocity ﬁeld is also independent of x3, so it is
effectively 2-dimensional (translation invariant for Cartesian coordinates;
axisymmetric for cylindrical or spherical coordinates).
Because the ﬂow is incompressible, ∇. v = 0, we can write the velocity
as the curl of a vector potential: v = ∇× A(t, x1, x2). By imposing the
Lorenz gauge on the vector potential (i.e., making it divergence free,
as is commonly done in electromagnetism), we can ensure that its only
nonvanishing component is A3 = A . e3, where e3 is the unit vector pointing
in the x3 direction. Now, a special role is played by the vector that generates
local translations along the x3 direction (i.e., that generates the ﬂow’s
symmetry). If we write a location P in space as a function of the coordinates
P(x1, x2, x3), then this generator is ∂P/∂x3 = √g33 e3. We deﬁne the ﬂow’s
stream function by
ζ(t, x1, x2) ≡A . ∂P/∂x3,
(2)
which implies that the only nonzero component of the vector potential is
A3 = ζ/√g33.
Then it is straightforward to show (Ex. 14.19) the following. (i) The
orthonormal components of the velocity ﬁeld v = ∇× A are
v1 =
1
√g22g33
∂ζ
∂x2
,
v2 =
−1
√g11g33
∂ζ
∂x1
.
(3)
These expressions enable one to reduce an analysis of the ﬂow to solving
for three scalar functions of (t, x1, x2): the stream function ζ, the pressure
P , and the density ρ. (ii) The stream function is a constant along ﬂow
lines: v . ∇ζ = 0. (iii) The stream function is proportional to the ﬂow rate
(theamountofﬂuidvolumecrossingasurfaceperunittime).Morespeciﬁcally,
(continued)
760
Chapter 14. Vorticity

BOX 14.4.
(continued)
consider a segment of some curve reaching from point A to point B in a
surface of constant x3, and expand this curve into a segment of a 2-dimensional
surface by translating it through some x3 along the symmetry generator
∂P/∂x3. Then the ﬂow rate across this surface is
F =
 B
A
v .

x3
∂P
∂x3
× dx

=
 B
A
v . √g33x3e3 × dx

= [ζ(B) −ζ(A)]x3.
(4)
Since the stream function varies on the lengthscale δ, to produce a velocity ﬁeld
with magnitude ∼V , it must have magnitude ∼V δ. This motivates us to guess that it
has the functional form
ζ = V δ(x)f (ξ),
(14.45)
where f (ξ) is some dimensionless function of order unity. This guess will be good
mathematical form of
self-similar boundary layer
if, when inserted into Eq. (14.44), it produces a self-similar ﬂow [i.e., one with vx
and (x/δ)vy depending only on ξ]. Indeed, inserting Eq. (14.45) into Eq. (14.44), we
obtain
vx = Vf ′,
vy = δ(x)
2x V (ξf ′ −f ),
(14.46a)
where the prime denotes d/dξ. These equations have the desired self-similar form.
By inserting these self-similar vx and vy into the x component of the force-
balance equation v . ∇v = ν∇2v [Eq. (14.41)] and neglecting ∂2vx/∂x2 compared to
∂2vx/∂y2, we obtain a nonlinear third-order differential equation for f (ξ):
d3f
dξ3 + f
2
d2f
dξ2 = 0.
(14.46b)
That this equation involves x and y only in the combination ξ = y√V/νx conﬁrms
that our self-similar ansatz was a good one. Equation (14.46b) must be solved subject
to the boundary condition that the velocity vanish at the surface and approach V as
y →∞(ξ →∞) [cf. Eqs. (14.46a)]:
f (0) = f ′(0) = 0,
f ′(∞) = 1.
(14.46c)
Not surprisingly, Eq. (14.46b) does not admit an analytic solution. However, it
is simple to compute a numerical solution with the boundary conditions (14.46c).
14.4 High-Reynolds-Number Flow—Laminar Boundary Layers
761

vx/V
–(δ/V )ω
ξ = y/δ
1.0
0.8
0.6
0.4
0.2
0.0
0
1
2
3
4
5
6
FIGURE 14.13 Laminar boundary layer near a ﬂat plate: the Blasius
velocity proﬁle vx/V = f ′(ξ) (blue curve) and vorticity proﬁle
(δ/V )ω = −f ′′′(ξ) (red curve) as functions of scaled perpendicular
distance ξ = y/δ. Note that the ﬂow speed is 90% of V at a distance
of 3δ from the surface, so δ is a good measure of the thickness of the
boundary layer.
The result for vx/V = f ′(ξ) is shown in Fig. 14.13. This solution, the Blasius proﬁle,
Blasius proﬁle for self-
similar boundary layer
qualitatively has the form we expected: the velocity vx rises from 0 to V in a smooth
manner as one moves outward from the plate, achieving a sizable fraction of V at a
distance several times larger than δ(x).
This Blasius proﬁle is not only our ﬁrst example (aside from Ex. 14.12) of the
use of a stream function (vx = ∂ζ/∂y, vy = −∂ζ/∂x); it is also our ﬁrst example of
another common procedure in ﬂuid dynamics: taking account of a natural scaling in
the problem to make a self-similar ansatz and thereby transform the partial differential
ﬂuid equations into ordinary differential equations. Solutions of this type are known
as similarity solutions and also as self-similar solutions.
self-similar solutions
The motivation for using similarity solutions is obvious. The nonlinear partial
differential equations of ﬂuid dynamics are much harder to solve, even numerically,
than are ordinary differential equations. Elementary similarity solutions are espe-
cially appropriate for problems where there is no intrinsic characteristic lengthscale
or timescale associated with the relevant physical quantities except those explicitly
involving the spatial and temporal coordinates. High-Reynolds-number ﬂow past a
large plate has a useful similarity solution, whereas ﬂow with Reℓ∼1, where the size
of the plate is clearly a signiﬁcant scale in the problem, does not. We shall encounter
more examples of similarity solutions in the following chapters.
Now that we have a solution for the ﬂow, we must examine a key approximation
that underlies it: constancy of the pressure P . To do this, we begin with the y compo-
nent of the force-balance equation (14.41) (a component that we never used explicitly
in our analysis). The inertial and viscous terms are both O(V 2δ/x2), so if we reinstate
a term −∇P/ρ ∼−P/ρδ, it can be no larger than ∼V 2δ/x2. From this we estimate
762
Chapter 14. Vorticity

that the pressure difference across the boundary layer is P <∼ρV 2δ2/x2. Using this
estimate in the x component of force balance (14.41) (the component on which our
analysis was based), we verify that the pressure gradient term is smaller than those
we kept by a factor <∼δ2/x2 ≪1. For this reason, when the boundary layer is thin,
we can indeed neglect pressure gradients across it when computing its structure from
longitudinal force balance.
14.4.2
14.4.2 Blasius Vorticity Proﬁle
It is illuminating to consider the structure of the Blasius boundary layer in terms of
its vorticity. Since the ﬂow is 2-dimensional with velocity v = ∇× (ζez), its vorticity
is ω = ∇× ∇× (ζez) = −∇2(ζez), which has as its only nonzero component
ω ≡ωz = −∇2ζ = −V
δ f ′′(ξ),
(14.47)
aside from fractional corrections of order δ2/x2. This vorticity is exhibited in Fig.
14.13.
From Eq. (14.46b), we observe that the gradient of vorticity vanishes at the plate.
This means that the vorticity is not diffusing out from the plate’s surface. Neither is it
being convected away from the plate’s surface, as the perpendicular velocity vanishes
there. This conﬁrms what we already learned from Fig. 14.12: the ﬂux of vorticity per
unit length is conserved along the plate, once it has been created as a spike at the plate’s
leading edge.
If we transform to a frame moving with an intermediate speed ∼V/2, and measure
time t since passing the leading edge, the vorticity will diffuse a distance ∼(νt)1/2 ∼
vorticity diffusion in
boundary layer
(νx/V )1/2 = δ(x) away from the surface after time t; see the discussion of vorticity
diffusion in Sec. 14.2.5. This behavior exhibits the connection between that diffusion
discussion and the similarity solution for the boundary layer in this section.
14.4.3
14.4.3 Viscous Drag Force on a Flat Plate
It is of interest to compute the total drag force exerted on the plate. Let ℓbe the plate’s
length and w ≫ℓbe its width. Noting that the plate has two sides, the drag force
produced by the viscous stress acting on the plate’s surface is
F = 2

T vis
xy dxdz = 2

(−2ησxy)dxdz = 2w
 ℓ
0
ρν
∂vx
∂y

y=0
dx.
(14.48)
Inserting ∂vx/∂y = (V/δ)f ′′(0) = V

V/(νx)f ′′(0) from Eqs. (14.46a) and per-
forming the integral, we obtain
F = 1
2ρV 2 × (2ℓw) × CD,
(14.49)
where
CD = 4f ′′(0)Re−1/2
ℓ
.
(14.50)
14.4 High-Reynolds-Number Flow—Laminar Boundary Layers
763

Herewehaveintroducedanoften-usednotationforexpressingthedragforceofaﬂuid
drag coefﬁcient
on a solid body. We have written it as half the incoming ﬂuid’s kinetic stress ρV 2 times
the surface area of the body 2ℓw on which the drag force acts, times a dimensionless
drag coefﬁcient CD. We have expressed the drag coefﬁcient in terms of the Reynolds
number
Reℓ= V ℓ
ν
(14.51)
formed from the body’s relevant dimension, ℓ, and the speed and viscosity of the
incoming ﬂuid.
From Fig. 14.13, we estimate that f ′′(0) ≃0.3 (an accurate numerical value is
0.332), and so CD ≃1.328R−1/2
ℓ
. Note that the drag coefﬁcient decreases as the vis-
cosity decreases and the Reynolds number increases. However, as we discuss in Sec.
15.5, this model breaks down for very large Reynolds numbers Reℓ>∼106, because a
portion of the boundary layer becomes turbulent (cf. caption of Fig. 14.11).
14.4.4
14.4.4 Boundary Layer Near a Curved Surface: Separation
Next consider ﬂow past a nonplanar surface (e.g., the aircraft wings of Fig. 14.2a,b). In
this case, in general a longitudinal pressure gradient exists along the boundary layer,
which cannot be ignored, in contrast to the transverse pressure gradient across the
boundary layer. If the pressure decreases along the ﬂow, the ﬂow will accelerate, and
so more vorticity will be created at the surface and will diffuse away from the surface.
However, if there is an “adverse” pressure gradient causing the ﬂow to decelerate, then
adverse pressure gradient
negative vorticity must be created at the wall. For a sufﬁciently adverse gradient, the
negative vorticity gets so strong that it cannot diffuse fast enough into and through the
boundary layer to maintain a simple boundary-layer-type ﬂow. Instead, the boundary
layer separates from the surface, as shown in Fig. 14.14, and a backward ﬂow is
boundary-layer separation
generated beyond the separation point by the negative vorticity. This phenomenon
can occur on an aircraft when the wings’ angle of attack (i.e., the inclination of the
wings to the horizontal) is too great. An adverse pressure gradient develops on the
surface of separation
V
FIGURE 14.14 Separation of a boundary layer in the presence of an adverse
pressure gradient.
764
Chapter 14. Vorticity

upper wing surfaces, the ﬂow separates, and the plane stalls. The designers of wings
make great efforts to prevent this, as we discuss brieﬂy in Sec. 15.5.2.
EXERCISES
Exercise 14.15 Problem: Reynolds Numbers
Estimate the Reynolds numbers for the following ﬂows. Make sketches of the ﬂow
ﬁelds, pointing out any salient features.
(a) A hang glider in ﬂight.
(b) Plankton in the ocean.
(c) A physicist waving her hands.
Exercise 14.16 **Problem: Fluid Dynamical Scaling
An auto manufacturer wishes to reduce the drag force on a new model by changing
its design. She does this by building a one-sixth scale model and putting it into a wind
tunnel. How fast must the air travel in the wind tunnel to simulate the ﬂow at 40 mph
on the road?
[Remark: This is our ﬁrst example of “scaling” relations in ﬂuid dynamics, a
powerful concept that we develop and explore in later chapters.]
Exercise 14.17 Example: Potential Flow around a Cylinder (D’Alembert’s Paradox)
Consider stationary incompressible ﬂow around a cylinder of radius a with sufﬁ-
cientlylargeReynoldsnumberthatviscositymaybeignoredexceptinathinboundary
layer, which is assumed to extend all the way around the cylinder. The velocity is as-
sumed to have the uniform value V at large distances from the cylinder.
(a) Show that the velocity ﬁeld outside the boundary layer can be derived from a
scalarvelocitypotential (introducedinSec.13.5.4), v = ∇ψ, thatsatisﬁesLaplace’s
equation: ∇2ψ = 0.
(b) Write down suitable boundary conditions for ψ.
(c) Write the velocity potential in the form
ψ = V . x + f (x),
and solve for f . Sketch the streamlines and equipotentials.
(d) Use Bernoulli’s theorem to compute the pressure distribution over the surface
and the net drag force given by this solution. Does your drag force seem reason-
able? It did not seem reasonable to d’Alembert in 1752, and it came to be called
d’Alembert’s paradox.
(e) Finally, considertheeffectofthepressuredistributionontheboundarylayer.How
do you think this will make the real ﬂow different from the potential solution?
How will the drag change?
14.4 High-Reynolds-Number Flow—Laminar Boundary Layers
765

Exercise 14.18 Example: Stationary Laminar Flow down a Long Pipe
Fluid ﬂows down a long cylindrical pipe of length b much larger than radius a, from a
reservoir maintained at pressure P0 (which connects to the pipe at x = 0) to a free end
at large x, where the pressure is negligible. In this problem, we try to understand the
velocity ﬁeld vx(ϖ , x) as a function of radius ϖ and distance x down the pipe, for a
given discharge (i.e., mass ﬂow per unit time) ˙M. Assume that the Reynolds number
is small enough for the ﬂow to be treated as laminar all the way down the pipe.
(a) Close to the entrance of the pipe (small x), the boundary layer will be thin, and
the velocity will be nearly independent of radius. What is the ﬂuid velocity outside
the boundary layer in terms of its density and ˙M?
(b) How far must the ﬂuid travel along the pipe before the vorticity diffuses into the
center of the ﬂow and the boundary layer becomes as thick as the radius? An
order-of-magnitude calculation is adequate, and you may assume that the pipe is
much longer than your estimate.
(c) At a sufﬁciently great distance down the pipe, the proﬁle will cease evolving with x
and settle down into the Poiseuille form derived in Sec. 13.7.6, with the discharge
˙M given by the Poiseuille formula. Sketch how the velocity proﬁle changes along
the pipe, from the entrance to this ﬁnal Poiseuille region.
(d) Outline a procedure for computing the discharge in a long pipe of arbitrary cross
section.
Exercise 14.19 Derivation: Stream Function in General
Derive results (i), (ii), and (iii) in the last paragraph of Box 14.4. [Hint: The derivation
issimplestifoneworksinacoordinatebasis(Sec.24.3)ratherthanintheorthonormal
bases that we use throughout Parts I–VI of this book.]
Exercise 14.20 Problem: Stream Function for Stokes Flow around a Sphere
Consider low-Reynolds-number ﬂow around a sphere. Derive the velocity ﬁeld
(14.30) using the stream function of Box 14.4. This method is more straightforward
but less intuitive than that used in Sec. 14.3.2.
14.5
14.5 Nearly Rigidly Rotating Flows—Earth’s Atmosphere and Oceans
InNatureoneoftenencountersﬂuidsthatrotatenearlyrigidly(i.e., ﬂuidswithanearly
uniform distribution of vorticity). Earth’s oceans and atmosphere are important ex-
amples, where the rotation is forced by the underlying rotation of Earth. Such rotating
ﬂuids are best analyzed in a rotating reference frame, in which the unperturbed ﬂuid is
at rest and the perturbations are inﬂuenced by Coriolis forces, resulting in surprising
phenomena. We explore some of these phenomena in this section.
766
Chapter 14. Vorticity

14.5.1
14.5.1 Equations of Fluid Dynamics in a Rotating Reference Frame
As a foundation for this exploration, we transform the Navier-Stokes equation from
the inertial frame in which it was derived to a uniformly rotating frame: the mean rest
frame of the ﬂows we study.
We begin by observing that the Navier-Stokes equation has the same form as
Newton’s second law for particle motion:
dv
dt = f,
(14.52)
where the force per unit mass is f = −∇P/ρ −∇ + ν∇2v. We transform to a
Coriolis and centrifugal
accelerations in rigidly
rotating reference frame
frame rotating with uniform angular velocity  by adding “ﬁctitious” Coriolis and
centrifugal accelerations, given by −2 × v and − × ( × x), respectively, and
expressing the force f in rotating coordinates. The ﬂuid velocity transforms as
v →v +  × x.
(14.53)
It is straightforward to verify that this transformation leaves the expression for the
viscous acceleration, ν∇2v, unchanged. Therefore the expression for the force f is
unchanged, and the Navier-Stokes equation in rotating coordinates becomes
Navier-Stokes equation in
rotating reference frame
dv
dt = −∇P
ρ
−∇ + ν∇2v −2 × v − × ( × x).
(14.54)
The centrifugal acceleration − × ( × x) can be expressed as the gradient of a
centrifugal potential, ∇[1
2( × x)2]= ∇[1
2(ϖ)2], where ϖ is distance from the
rotation axis. (The location of the rotation axis is actually arbitrary, aside from the
requirement that it be parallel to ; see Box 14.5.) For simplicity we conﬁne ourselves
to an incompressible ﬂuid, so that ρ is constant. This allows us to deﬁne an effective
pressure
effective pressure for
incompressible ﬂuid in
rotating reference frame
P ′ = P + ρ

 −1
2( × x)2

(14.55)
that includes the combined effects of the real pressure, gravity, and the centrifugal
force. In terms of P ′ the Navier-Stokes equation in the rotating frame becomes
Navier-Stokes equation
for incompressible ﬂuid in
rotating reference frame
dv
dt = −∇P ′
ρ
+ ν∇2v −2 × v.
(14.56a)
The quantity P ′ will be constant if the ﬂuid is at rest in the rotating frame, v = 0, in
contrast to the true pressure P, which does have a gradient. Equation (14.56a) is the
most useful form for the Navier-Stokes equation in a rotating frame. In keeping with
our assumptions that ρ is constant and the ﬂow speeds are very low in comparison
with the speed of sound, we augment Eq. (14.56a) by the incompressibility condition
14.5 Nearly Rigidly Rotating Flows—Earth’s Atmosphere and Oceans
767

∇. v = 0, whichisleftunchangedbythetransformation(14.53)toarotatingreference
frame:
∇. v = 0.
(14.56b)
It should be evident from Eq. (14.56a) that two dimensionless numbers charac-
terize rotating ﬂuids. The ﬁrst is the Rossby number,
Rossby number
Ro = V
L ,
(14.57)
where V is a characteristic velocity of the ﬂow relative to the rotating frame, and L is
a characteristic length. Ro measures the relative strength of the inertial acceleration
and the Coriolis acceleration:
Ro ∼|(v . ∇)v|
|2 × v| ∼inertial force
Coriolis force.
(14.58)
The second dimensionless number is the Ekman number,
Ekman number
Ek =
ν
L2 ,
(14.59)
which analogously measures the relative strengths of the viscous and Coriolis
accelerations:
Ek ∼|ν∇2v|
|2 × v| ∼viscous force
Coriolis force.
(14.60)
Notice that Ro/Ek = Re is the Reynolds number.
storms, ocean currents,
and tea cups
The three traditional examples of rotating ﬂows are large-scale storms and other
weather patterns on rotating Earth, deep currents in Earth’s oceans, and water in a
stirred tea cup.
For a typical storm, the wind speed might be V ∼25 mph (∼10 m s−1), and a
characteristic lengthscale might be L ∼1,000 km. The effective angular velocity at
a temperate latitude is (see Box 14.5) ⋆= ⊕sin 45◦∼10−4 rad s−1, where ⊕is
Earth’s rotational angular velocity. As the air’s kinematic viscosity is ν ∼10−5 m2 s−1,
we ﬁnd that Ro ∼0.1 and Ek ∼10−13. This tells us immediately that Coriolis forces
are important but not totally dominant, compared to inertial forces, in controlling the
weather, and that viscous forces are unimportant except in thin boundary layers.
For deep ocean currents, such as the Gulf Stream, V ranges from ∼0.01 to
∼1 m s−1, so we use V ∼0.1 m s−1, lengthscales are L ∼1,000 km, and for water
ν ∼10−6 m2 s−1, so Ro ∼10−3 and Ek ∼10−14. Thus, Coriolis accelerations are far
more important than inertial forces, and viscous forces are important only in thin
boundary layers.
768
Chapter 14. Vorticity

BOX 14.5.
ARBITRARINESS OF ROTATION AXIS;  FOR
ATMOSPHERIC AND OCEANIC FLOWS
ARBITRARINESS OF ROTATION AXIS
Imagine yourself on the rotation axis x = 0 of a rigidly rotating ﬂow. All
ﬂuid elements circulate around you with angular velocity . Now move
perpendicular to the rotation axis to a new location x = a, and ride with the
ﬂow there. All other ﬂuid elements will still rotate around you with angular
velocity ! The only way you can tell you have moved (if all ﬂuid elements look
identical) is that you will now experience a centrifugal force  × ( × a).
This shows up mathematically in the rotating-frame Navier-Stokes
equation (14.54). When we set x = xnew −a, the only term that changes is
the centrifugal force; it becomes − × ( × xnew) +  × ( × a). If we
absorb the new, constant, centrifugal term  × ( × a) into the gravitational
acceleration g = −∇, then the Navier-Stokes equation is completely
unchanged. In this sense, the choice of rotation axis is arbitrary.
ANGULAR VELOCITY  FOR LARGE-SCALE FLOWS IN EARTH’S ATMOSPHERE
AND OCEANS
For large-scale ﬂows in Earth’s atmosphere and oceans (e.g., storms), the
rotation of the unperturbed ﬂuid is that due to the rotation of Earth. One
might think that this means we should take as the angular velocity  in
the Coriolis term of the Navier-Stokes equation (14.56a) Earth’s angular
velocity ⊕. Not so. The atmosphere and ocean are so thin vertically that
vertical motions cannot achieve small Rossby numbers: Coriolis forces are
unimportant for vertical motions. Correspondingly, the only component
of Earth’s angular velocity ⊕that is important for Coriolis forces is that
which couples horizontal ﬂows to horizontal ﬂows: the vertical component
∗= ⊕sin(latitude). (A similar situation occurs for a Foucault pendulum.)
Thus, in the Coriolis term of the Navier-Stokes equation, we must set
 = ∗ez = ⊕sin(latitude)ez, where ez is the vertical unit vector. By
contrast, in the centrifugal potential 1
2( × x)2,  remains the full angular
velocity of Earth, ⊕—unless (as is commonly done) we absorb a portion of
it into the gravitational potential as when we change rotation axes, in which
case we can use  = ∗ez in the centrifugal potential.
14.5 Nearly Rigidly Rotating Flows—Earth’s Atmosphere and Oceans
769

For water stirred in a tea cup (with parameters typical of many ﬂows in the
laboratory), L ∼10 cm,  ∼V/L ∼10 rad s−1, and ν ∼10−6 m2 s−1 giving Ro ∼1
and Ek ∼10−5. Coriolis and inertial forces are comparable in this case, and viscous
forces again are conﬁned to boundary layers, but the layers are much thicker relative
to the bulk ﬂow than in the atmospheric and oceanic cases.
Notice that for all these ﬂows—atmospheric, oceanic, and tea cup—the (effective)
rotation axis is vertical:  is vertically directed (cf. Box 14.5). This will be the case for
all nearly rigidly rotating ﬂows considered in this chapter.
14.5.2
14.5.2 Geostrophic Flows
geostrophic ﬂow
Stationary ﬂows ∂v/∂t = 0 in which both the Rossby and Ekman numbers are small
(i.e., with Coriolis forces big compared to inertial and viscous forces) are called
geostrophic,eveninthelaboratory.Geostrophicﬂowisconﬁnedtothebulkoftheﬂuid,
well away from all boundary layers, since viscosity will become important in those
layers. For such geostrophic ﬂows, the Navier-Stokes equation (14.56a) reduces to
Navier-Stokes equation for
geostrophic ﬂow
2 × v = −∇P ′
ρ
.
(14.61)
This equation states that the velocity v (measured in the rotating frame) is orthog-
onal to the body force ∇P ′, which drives it. Correspondingly, the streamlines are
perpendicular to the gradient of the generalized pressure (i.e., they lie on surfaces of
constant P ′).
An example of geostrophic ﬂow is the motion of atmospheric winds around a
low pressure region or depression. [Since P ′ = P + ρ( −1
22ϖ 2), when the ac-
tual pressure P goes up or down at some ﬁxed location, P ′ goes up or down by the
same amount, so a depression of P ′ is a depression of P .] The geostrophic equation
(14.61) tells us that such winds must be counterclockwise in the northern hemisphere
as seen from a satellite, and clockwise in the southern hemisphere. For a ﬂow with
speed v ∼10 m s−1 around a ∼1,000-km depression, the drop in effective pressure
at the depression’s center is P ′ = P ∼1 kPa ∼10 mbar ∼0.01 atmosphere ∼0.3
inches of mercury ∼4 inches of water. Around a high-pressure region, winds circulate
in the opposite direction.
It is here that we can see the power of introducing the effective pressure P ′.
In the case of atmospheric and oceanic ﬂows, the true pressure P changes signif-
icantly vertically, and the pressure scale height is generally much shorter than the
horizontal lengthscale. However, the effective pressure will be almost constant verti-
cally, any small variation being responsible for minor updrafts and downdrafts, which
we generally ignore when describing the wind or current ﬂow pattern. It is the hor-
izontal pressure gradients that are responsible for driving the ﬂow. When pressures
are quoted, they must therefore be referred to some reference equipotential surface:
 −1
2( × x)2 = const. The convenient one to use is the equipotential associated
770
Chapter 14. Vorticity

side view

top view
L
FIGURE 14.15 Taylor column. A solid cylinder (white) is placed in a large container of water, which is
then spun up on a turntable to a high enough angular velocity  that the Ekman number is small:
Ek = ν/(L2) ≪1. A slow, steady ﬂow relative to the cylinder is then induced. [The ﬂow’s velocity
v in the rotating frame must be small enough to keep the Rossby number Ro = v/(L) ≪1.] The
water in the bottom half of the container ﬂows around the cylinder. The water in the top half does
the same as if there were an invisible cylinder present. This is an illustration of the Taylor-Proudman
theorem, which states that there can be no vertical gradients in the velocity ﬁeld. The effect can also be
demonstrated with vertical velocity: If the cylinder is slowly made to rise, then the ﬂuid immediately
above it will also be pushed upward rather than ﬂow past the cylinder—except at the water’s surface,
where the geostrophic ﬂow breaks down. The ﬂuid above the cylinder, which behaves as though it
were rigidly attached to the cylinder, is called a Taylor column.
with the surface of the ocean, usually called “mean sea level.” This is the pressure that
appears on a meteorological map.
14.5.3
14.5.3 Taylor-Proudman Theorem
There is a simple theorem due to Taylor and Proudman that simpliﬁes the description
of 3-dimensional, geostrophic ﬂows. Take the curl of Eq. (14.61) and use ∇. v = 0;
the result is
Taylor-Proudman theorem
for geostrophic ﬂow
( . ∇)v = 0.
(14.62)
Thus, there can be no vertical gradient (gradient along ) of the velocity under
geostrophic conditions. This result provides a good illustration of the stiffness of
vortex lines: the vortex lines associated with the rigid rotation are frozen in the ﬂuid
under geostrophic conditions (where other contributions to the vorticity are small),
and they refuse to be bent. The simplest demonstration of this is the Taylor column
of Fig. 14.15.
It is easy to see that any vertically constant, divergence-free velocity ﬁeld v(x, y)
can be a solution to the geostrophic equation (14.61). The generalized pressure P ′
can be adjusted to make it a solution (see the discussion of pressure adjusting itself
to whatever the ﬂow requires, in Ex. 14.7). However, one must keep in mind that to
guarantee it is also a true (approximate) solution of the full Navier-Stokes equation
(14.56a), its Rossby and Ekman numbers must be ≪1.
14.5 Nearly Rigidly Rotating Flows—Earth’s Atmosphere and Oceans
771

14.5.4
14.5.4 Ekman Boundary Layers
As we have seen, Ekman numbers are typically small in the bulk of a rotating ﬂuid.
However, as was true in the absence of rotation, the no-slip condition at a solid surface
generates a boundary layer that can signiﬁcantly inﬂuence the global velocity ﬁeld,
albeit indirectly.
When the Rossby number is less than one, the structure of a laminar boundary
layer is dictated by a balance between viscous and Coriolis forces rather than between
viscous and inertial forces. Balancing the relevant terms in Eq. (14.56a), we obtain an
Ekman boundary layer and
its thickness
estimate of the boundary-layer thickness:
thickness ∼δE ≡
& ν
.
(14.63)
In other words, the thickness of the boundary layer is that which makes the layer’s
Ekman number unity: Ek(δE) = ν/(δ2
E) = 1.
Consider such an “Ekman boundary layer” at the bottom or top of a layer of
geostrophically ﬂowing ﬂuid. For the same reasons as for ordinary laminar boundary
layers (Sec. 14.4), the generalized pressure P ′ will be nearly independent of height z
through the Ekman layer, that is, it will have the value dictated by the ﬂow just outside
the layer: ∇P ′ = −2ρ × V = const. Here V is the velocity just outside the layer (the
velocity of the bulk ﬂow), which we assume to be constant on scales ∼δE. Since  is
vertical, ∇P ′, like V, will be horizontal (i.e., they both will lie in the x-y plane). To
simplify the analysis, we introduce the ﬂuid velocity relative to the bulk ﬂow,
w ≡v −V,
(14.64)
which goes to zero outside the boundary layer. When rewritten in terms of w,
the Navier-Stokes equation (14.56a) [with ∇P ′/ρ = −2 × V and with dv/dt =
∂v/∂t + (v . ∇)v = 0, because the ﬂow in the thin boundary layer is steady and v is
horizontal and varies only vertically] takes the simple form d2w/dz2 = (2/ν) × w.
Choosing Cartesian coordinates with an upward vertical z direction, assuming
 = +ez (as is the case for the oceans and atmosphere in the northern hemisphere),
and introducing the complex quantity
complex velocity ﬁeld
w = wx + iwy
(14.65)
to describe the horizontal velocity ﬁeld, we can rewrite d2w/dz2 = (2/ν) × w as
d2w
dz2 = 2i
δ2
E
w =
1 + i
δE
2
w.
(14.66)
Equation (14.66) must be solved subject to w →0 far from the water’s boundary and
some appropriate condition at the boundary.
For a ﬁrst illustration of an Ekman layer, consider the effects of a wind blowing in
the ex direction above a still ocean, V = 0, and set z = 0 at the ocean’s surface. The
772
Chapter 14. Vorticity

¯
applied stress
z = 0
z =
–3πδE
—
4
z =
–πδE
—
4
new mass flux
vy
vx
FIGURE 14.16 Ekman spiral (water velocity as a
function of depth) at the ocean surface, where the
wind exerts a stress.
wind will exert, through a turbulent boundary layer of air, a stress −Txz > 0 on the
ocean’s surface. This stress must be balanced by an equal, viscous stress νρ dwx/dz
at the top of the water’s boundary layer, z = 0. Thus there must be a velocity gradient,
dwx/dz = −Txz/νρ = |Txz|/vρ, in the water at z = 0. (This replaces the no-slip
boundary condition that we have when the boundary is a solid surface.) Imposing
this boundary condition along with w →0 as z →−∞(down into the ocean), we
ﬁnd from Eqs. (14.66) and (14.65):
wind-driven Ekman
boundary layer at top of a
geostrophic ﬂow
vx = wx =
*
|Txz|δE
√
2 νρ
+
ez/δE cos(z/δE −π/4),
vy = wy =
*
|Txz|δE
√
2 νρ
+
ez/δE sin(z/δE −π/4),
(14.67)
for z ≤0 (Fig. 14.16). As a function of depth, this velocity ﬁeld has the form of a
structure of the boundary
layer: Ekman spiral
spiral—the so-called Ekman spiral. When  points toward us (as in Fig. 14.16), the
spiral is clockwise and tightens as we move away from the boundary (z = 0 in the
ﬁgure) into the bulk ﬂow.
By integrating the mass ﬂux ρw over z, we ﬁnd for the total mass ﬂowing per unit
time per unit length of the ocean’s surface
F = ρ
 0
−∞
wdz = −δ2
E
2ν |Txz|ey;
(14.68)
see Fig. 14.16. Thus the wind, blowing in the ex direction, causes a net mass ﬂow in the
direction of ex × / = −ey. This response (called “Ekman pumping”) may seem
Ekman pumping
less paradoxical if one recalls how a gyroscope responds to applied forces.
gyres
This mechanism is responsible for the creation of gyres in the oceans (Ex. 14.21
and Fig. 14.18 below).
As a second illustration of an Ekman boundary layer, we consider a geostrophic
ﬂow with nonzero velocity V = V ex in the bulk of the ﬂuid, and examine this ﬂow’s
14.5 Nearly Rigidly Rotating Flows—Earth’s Atmosphere and Oceans
773

¯
z = 0
V
z = δEπ/4
vy
vx
FIGURE 14.17 Ekman spiral (water velocity as a function of
height) in the bottom boundary layer, when the bulk ﬂow
above it moves geostrophically with speed V ex.
interaction with a static, solid surface at its bottom. We set z = 0 at the bottom, with
z increasing upward, in the  direction. The structure of the boundary layer on the
bottom is governed by the same differential equation (14.66) as at the wind-blown
surface, but with altered boundary conditions. The solution is
Ekman boundary layer at
bottom of a geostrophic
ﬂow
vx −V = wx = −V exp(−z/δE) cos(z/δE),
vy = wy = +V exp(−z/δE) sin(z/δE).
(14.69)
This solution is shown in Fig. 14.17.
Recall that we have assumed  points in the upward +z direction, which is
appropriate for the ocean and atmosphere in the northern hemisphere. If, instead, 
points downward (as in the southern hemisphere), then the handedness of the Ekman
spiral is reversed.
Ekman boundary layers
drive circulation in rotating
ﬂuids
Ekman boundary layers are important, because they can circulate rotating ﬂuids
faster than viscous diffusion can. Suppose we have a nonrotating container (e.g., a
tea cup) of radius L containing a ﬂuid that rotates with angular velocity  (e.g., due
to stirring; cf. Ex. 14.22). As you will see in your analysis of Ex. 14.22, the Ekman
layer at the container’s bottom experiences a pressure difference between the wall
and the container’s center given by P ∼ρL22. This drives a ﬂuid circulation in
the Ekman layer, from the wall toward the center, with radial speed V ∼L. The
circulating ﬂuid must upwell at the bottom’s center from the Ekman layer into the
bulk ﬂuid. This produces a poloidal mixing of the ﬂuid on a timescale given by
tE ∼
L3
LδEV ∼LδE
ν .
(14.70)
This timescale is shorter than that for simple diffusion of vorticity, tν ∼L2/ν, by a
factor tE/tν ∼
√
Ek, which (as we have seen) can be very small. This circulation and
mixing are key to the piling up of tea leaves at the bottom center of a stirred tea cup,
and to the mixing of the tea or milk into the cup’s hot water (Ex. 14.22).
774
Chapter 14. Vorticity

The circulation driven by an Ekman layer is an example of a secondary ﬂow—a
weakly perturbative bulk ﬂow that is produced by interaction with a boundary. For
secondary ﬂows
other examples of secondary ﬂows, see Taylor (1968).
EXERCISES
Exercise 14.21 **Example: Winds and Ocean Currents in the North Atlantic
The north Atlantic Ocean exhibits the pattern of winds and ocean currents shown
in Fig. 14.18. Westerly winds blow from west to east at 40° latitude. Trade winds
blow from east to west at 20° latitude. In between, around 30° latitude, is the Sargasso
Sea: a 1.5-m-high gyre (raised hump of water). The gyre is created by ocean surface
currents, extending down to a depth of only about 30 m, that ﬂow northward from
the trade-wind region and southward from the westerly wind region (upper inset
in Fig. 14.18). A deep ocean current, extending from the surface down to near the
bottom, circulates around the Sargasso Sea gyre in a clockwise manner. This current
goes under different names in different regions of the ocean: Gulf Stream, West Wind
Drift, Canaries Current, and North Equatorial Current. Explain both qualitatively
and semiquantitatively (in terms of order of magnitude) how the winds are ultimately
responsible for all these features of the ocean. More speciﬁcally, do the following.
(a) Explain the surface currents in terms of an Ekman layer at the top of the ocean,
with thickness δE about 30 m. From this measured δE compute the kinematic
viscosity ν in the boundary layer. Your result, ν ∼0.03 m2 s−1, is far larger than
North
America
Europe
trade winds
westerly winds
We
st
 
W
i
n
d
 
D
r
i
f
t
Gul
f St
rea
m
oc
ea
n s
ur
fa
ce
C
a
n
a
r
i
e
s 
C
u
r
r
e
n
t
Nort
h Eq
uator
ial C
urre
nt
Sargasso
Sea
Africa
FIGURE 14.18 Winds and ocean currents in the north Atlantic. The upper inset shows the surface
currents, along the dotted north-south line, that produce the Sargasso Sea gyre.
14.5 Nearly Rigidly Rotating Flows—Earth’s Atmosphere and Oceans
775

the molecular viscosity of water, ∼10−6 m2 s−1 (Table 13.2). The reason is that
the boundary layer is turbulent, and its eddies produce this large viscosity (see
Sec. 15.4.2).
(b) Explain why the height of the gyre that the surface currents produce in the
Sargasso Sea is about 1.5 m.
(c) Explain the deep ocean current (Gulf Stream, etc.) in terms of a geostrophic ﬂow,
and estimate the speed of this current. This current, like circulation in a tea cup,
is an example of a “secondary ﬂow.”
(d) If there were no continents on Earth, but only an ocean of uniform depth, what
would be the ﬂow pattern of this deep current—its directions of motion at var-
ious locations around Earth, and its speeds? The continents (North America,
Europe, and Africa) must be responsible for the deviation of the actual current
(Gulf Stream, etc.) from this continent-free ﬂow pattern. How do you think the
continents give rise to the altered ﬂow pattern?
Exercise 14.22 **Example: Circulation in a Tea Cup
Place tea leaves and water in a tea cup, glass, or other larger container. Stir the water
until it is rotating uniformly, and then stand back and watch the motion of the water
and leaves. Notice that the tea leaves tend to pile up at the cup’s center. An Ekman
boundary layer on the bottom of the cup is responsible for this phenomenon. In this
exercise you explore the origin and consequences of this Ekman layer.
(a) Evaluate the pressure distribution P (ϖ , z) in the bulk ﬂow (outside all boundary
layers), assuming that it rotates rigidly. (Here z is height and ϖ is distance from
thewater’srotationaxis.)Performyourevaluationinthewater’srotatingreference
frame. From this P (ϖ , z) deduce the shape of the top surface of the water.
Compare your deduced shape with the actual shape in your experiment.
(b) Estimate the thickness of the Ekman layer at the bottom of your container. It is
very thin. Show, using the Ekman spiral diagram (Fig. 14.17), that the water in
this Ekman layer ﬂows inward toward the container’s center, causing the tea leaves
to pile up at the center. Estimate the radial speed of this Ekman-layer ﬂow and
the mass ﬂux that it carries.
(c) To get a simple physical understanding of this inward ﬂow, examine the radial
gradient ∂P/∂ϖ of the pressure P in the bulk ﬂow just above the Ekman layer.
Explain why ∂P/∂ϖ in the Ekman layer will be the same as in the rigidly rotating
ﬂow above it. Then apply force balance in an inertial frame to deduce that the
water in the Ekman layer will be accelerated inward toward the center.
(d) Using geostrophic-ﬂow arguments, deduce the fate of the boundary-layer water
after it reaches the center of the container’s bottom. Where does it go? What is the
large-scale circulation pattern that results from the “driving force” of the Ekman
layer’s mass ﬂux? What is the Rossby number for this large-scale circulation
776
Chapter 14. Vorticity

pattern? How and where does water from the bulk, nearly rigidly rotating ﬂow,
enter the bottom boundary layer so as to be swept inward toward the center?
(e) Explain how this large-scale circulation pattern can mix much of the water
through the boundary layer in the time tE of Eq. (14.70). What is the value of
this tE for the water in your container? Explain why this, then, must also be the
time for the angular velocity of the bulk ﬂow to slow substantially. Compare your
computed value of tE with the observed slow-down time for the water in your
container.
Exercise 14.23 **Problem: Water down a Drain in Northern
and Southern Hemispheres
One often hears the claim that water in a bathtub or basin swirls down a drain clock-
wise in the northern hemisphere and counterclockwise in the southern hemisphere.
In fact, on YouTube you are likely to ﬁnd video demonstrations of this (e.g., by search-
ing on “water down drain at equator”). Show that for Earth-rotation centrifugal forces
to produce this effect, it is necessary that the water in the basin initially be moving
with a speed smaller than
vmax ∼a∗∼a⊕
ℓ
R⊕
∼30 cm
yr
 a
1 m
 
ℓ
1 km

.
(14.71)
Here ⊕is Earth’s rotational angular velocity, ∗is its vertical component (Box 14.5),
R⊕is Earth’s radius, a is the radius of the basin, and ℓis the distance of the basin from
the equator. Even for a basin in Europe or North America, this maximum speed is
∼3 mm min−1 for a 1-m-diameter basin—exceedingly difﬁcult to achieve. Therefore,
the residual initial motion of the water in any such basin will control the direction in
which the water swirls down the drain. There is effectively no difference between
northern and southern hemispheres.
Exercise 14.24 **Example: Water down Drain: Experiment
(a) In a shower or bathtub with the drain somewhere near the center, not the wall,
set water rotating so a whirlpool forms over the drain. Perform an experiment to
see where the water going down the drain comes from: the surface of the water,
its bulk, or its bottom. For example, you could sprinkle baby powder on top of
the water, near the whirlpool, and measure how fast the powder is pulled inward
and down the drain; put something neutrally buoyant in the bulk and watch its
motion; andputsandonthebottomoftheshowernearthewhirlpoolandmeasure
how fast the sand is pulled inward and down the drain.
(b) Explain the result of your experiment in part (a). How is it related to the tea cup
problem, Ex. 14.22?
(c) Compute the shape of the surface of the water near and in the whirlpool.
14.5 Nearly Rigidly Rotating Flows—Earth’s Atmosphere and Oceans
777

14.6
14.6 Instabilities of Shear Flows—Billow Clouds
and Turbulence in the Stratosphere
Hereweexplorethestabilityofavarietyofshearﬂows.Webeginwiththesimplestcase
of two incompressible ﬂuids, one above the other, that move with different uniform
speeds, when gravity is negligible. Such a ﬂow has a delta-function spike of vorticity at
the interface between the ﬂuids, and, as we shall see, the interface is always unstable
Kelvin-Helmholtz
instability
against growth of so-called internal waves. This is the Kelvin-Helmholtz instability.
We then explore the ability of gravity to suppress this instability. If the densities
of the two ﬂuids are nearly the same, there is no suppression, which is why the
Kelvin-Helmholtz instability is seen in a variety of places in Earth’s atmosphere and
oceans. If the densities are substantially different, then gravity easily suppresses the
instability, unless the two ﬂow speeds are very different. Finally, we allow the density
and horizontal velocity to change continuously in the vertical direction (e.g., in Earth’s
stratosphere), and for such a ﬂow we deduce the Richardson criterion for instability,
which is often satisﬁed in the stratosphere and leads to turbulence. Along the way we
brieﬂy visit several other instabilities that occur in stratiﬁed ﬂuids.
14.6.1
14.6.1 Discontinuous Flow: Kelvin-Helmholtz Instability
A particularly interesting and simple type of vorticity distribution is one where the
vorticity is conﬁned to a thin, plane interface between two immiscible ﬂuids. In other
words, oneﬂuidisinuniformmotionrelativetotheother.Thistypeofﬂowarisesquite
frequently; for example, when the wind blows over the ocean or when smoke from
a smokestack discharges into the atmosphere (a ﬂow that is locally but not globally
planar).
We analyze the stability of such ﬂows, initially without gravity (this subsection),
then with gravity present (next subsection). Our analysis provides another illustration
of the behavior of vorticity and an introduction to techniques that are commonly used
to analyze ﬂuid instabilities.
Werestrictattentiontothesimplestversionofthisﬂow:anequilibriumwithaﬂuid
of density ρ+ moving horizontally with speed V above a second ﬂuid, which is at rest,
with density ρ−. Let x be a Cartesian coordinate measured along the planar interface
in the direction of the ﬂow, and let y be measured perpendicular to it. The equilibrium
contains a sheet of vorticity lying in the plane y = 0, across which the velocity changes
discontinuously. Now, this discontinuity ought to be treated as a boundary layer,
with a thickness determined by the viscosity. However, in this problem we analyze
disturbances with lengthscales much greater than the thickness of the boundary layer,
and so we can ignore it. As a corollary, we can also ignore viscous stresses in the body
of the ﬂow. In addition, we specialize to very subsonic speeds, for which the ﬂow can
be treated as incompressible; we also ignore the effects of surface tension as well as
gravity.
778
Chapter 14. Vorticity

A full description of this ﬂow requires solving the full equations of ﬂuid dynamics,
which are quite nonlinear and, as it turns out, for this problem can only be solved nu-
merically. However, we can make progress analytically on an important subproblem.
This is the issue of whether this equilibrium ﬂow is stable to small perturbations, and
if unstable, the nature of the growing modes. To answer this question, we linearize the
ﬂuid equations in the amplitude of the perturbations.
We consider a small vertical perturbation δy = ξ(x, t) in the location of the inter-
face (see Fig. 14.19a below). We denote the associated perturbations to the pressure
and velocity by δP and δv. That is, we write
P(x, t) = P0 + δP (x, t),
v = V H(y)ex + δv(x, t),
(14.72)
where P0 is the constant pressure in the equilibrium ﬂow about which we are perturb-
ing, V is the constant speed of the ﬂow above the interface, and H(y) is the Heaviside
step function (1 for y > 0 and 0 for y < 0). We substitute these P (x, t) and v(x, t)
into the governing equations: the incompressibility relation,
∇. v = 0,
(14.73)
and the viscosity-free Navier-Stokes equation (i.e., the Euler equation),
dv
dt = −∇P
ρ
.
(14.74)
We then subtract off the equations satisﬁed by the equilibrium quantities to obtain,
for the perturbed variables,
∇. δv = 0,
(14.75)
dδv
dt = −∇δP
ρ
.
(14.76)
Combining these two equations, we ﬁnd, as for Stokes ﬂow (Sec. 14.3.2), that the
pressure satisﬁes Laplace’s equation:
∇2δP = 0.
(14.77)
We now follow the procedure used in Sec. 12.4.2 when treating Rayleigh waves
on the surface of an elastic medium: we seek an internal wave mode, in which the
perturbed quantities vary ∝exp[i(kx −ωt)]f (y), with f (y) dying out away from
the interface. From Laplace’s equation (14.77), we infer an exponential falloff with |y|:
δP = δP0e−k|y|+i(kx−ωt),
(14.78)
where δP0 is a constant.
Our next step is to substitute this δP into the perturbed Euler equation (14.76) to
obtain
δvy =
ikδP
(ω −kV )ρ+
for y > 0,
δvy = −ikδP
ωρ−
for y < 0.
(14.79)
14.6 Instabilities of Shear Flows—Billow Clouds and Turbulence in the Stratosphere
779

Wemustimposetwoboundaryconditionsattheinterfacebetweentheﬂuids:continu-
ityoftheverticaldisplacement ξ oftheinterface(thetangentialdisplacementneednot
be continuous, since we are examining scales large compared to the boundary layer),
and continuity of the pressure P across the interface. [See Eq. (12.44) and associated
discussion for the analogous boundary conditions at a discontinuity in an elastic me-
dium.] The vertical interface displacement ξ is related to the velocity perturbation by
dξ/dt = δvy(y = 0), which implies that
ξ =
iδvy
(ω −kV )
at y = 0+
(immediately above the interface),
ξ =
iδvy
ω
at y = 0−
(immediately below the interface).
(14.80)
Then, by virtue of Eqs. (14.78), (14.80), and (14.79), the continuity of pressure and
vertical displacement at y = 0 imply that
ρ+(ω −kV )2 + ρ−ω2 = 0,
(14.81)
where ρ+ and ρ−are the densities of the ﬂuid above and below the interface, respec-
tively. Solving for frequency ω as a function of horizontal wave number k, we obtain
the following dispersion relation for internal wave modes localized at the interface,
which are also called linear Kelvin-Helmholtz modes:
dispersion relation for
linear Kelvin-Helmholtz
modes at an interface
ω = kV
*
ρ+ ± i(ρ+ρ−)1/2
ρ+ + ρ−
+
.
(14.82)
This dispersion relation can be used to describe both a sinusoidal perturbation whose
amplitude grows in time, and a time-independent perturbation that grows spatially:
TEMPORAL GROWTH
Suppose that we create some small, localized disturbance at time t = 0. We can
Fourier analyze the disturbance in space, and—as we have linearized the problem—
can consider the temporal evolution of each Fourier component separately. What we
ought to do is solve the initial value problem carefully, taking account of the initial
conditions. However, when there are growing modes, we can usually infer the long-
term behavior by ignoring the transients and just considering the growing solutions.
In our case, we infer from Eqs. (14.78)–(14.80) and the dispersion relation (14.82)
that a mode with spatial frequency k must grow as
temporal growth of mode
with wavelength 2π/k
2π/k
2π/k
δP , ξ ∝exp
'*
kV (ρ+ρ−)1/2
(ρ+ + ρ−)
+
t + ik
*
x −V
ρ+
ρ+ + ρ−
t
+(
.
(14.83)
Thus, this mode grows exponentially with time (Fig. 14.19a). Note that the mode is
nondispersive, and if the two densities are equal, it e-folds in 1/(2π) times a period.
This means that the fastest modes to grow are those with the shortest periods and
hence the shortest wavelengths. (However, the wavelength must not approach the
780
Chapter 14. Vorticity

(a)
at rest
at rest
at rest
V
V
V
t = 0
t > 0
y
x
(b)
FIGURE 14.19 Kelvin-Helmholtz instability. (a) Temporally growing mode. (b) Spatially
growing mode.
thickness of the boundary layer and thereby compromise our assumption that the
effects of viscosity are negligible.)
We can understand this growing mode somewhat better by transforming to the
center-of-momentum frame, which moves with speed ρ+V/(ρ+ + ρ−) relative to
the frame in which the lower ﬂuid is at rest. In this (primed) frame, the velocity of the
upper ﬂuid is V ′ = ρ−V/(ρ+ + ρ−), and so the perturbations evolve as
δP , ξ ∝exp[kV ′(ρ+/ρ−)1/2t]cos(kx′).
(14.84)
In this frame the wave is purely growing, whereas in our original frame it oscillated
with time as it grew.
SPATIAL GROWTH
An alternative type of mode is one in which a small perturbation is excited temporally
at some point where the shear layer begins (Fig. 14.19b). In this case we regard the
frequency ω as real and look for the mode with negative imaginary k corresponding
to spatial growth. Using Eq. (14.82), we obtain
spatial growth of mode
with angular frequency ωωω
k = ω
V
⎡
⎣1 −i
*
ρ−
ρ+
+1/2⎤
⎦.
(14.85)
The mode therefore grows exponentially with distance from the point of excitation.
PHYSICAL INTERPRETATION OF THE INSTABILITY
physical origin of Kelvin-
Helmholtz instability
We have performed a normal mode analysis of a particular ﬂow and discovered that
there are unstable internal wave modes. However much we calculate the form of the
growing modes, though, we cannot be said to understand the instability until we can
explainitphysically.InthecaseofthisKelvin-Helmholtzinstability, thistaskissimple.
The ﬂow pattern is shown schematically in Fig. 14.20. The upper ﬂuid will have to
move faster when passing over a crest in the water wave, because the cross sectional
14.6 Instabilities of Shear Flows—Billow Clouds and Turbulence in the Stratosphere
781

Plarge
vlarge
Psmall
vsmall
Plarge
vlarge
Psmall
vsmall
FIGURE 14.20 Physical explanation for the Kelvin-Helmholtz instability.
area of a ﬂow tube diminishes and the ﬂux of ﬂuid must be conserved. By Bernoulli’s
theorem, the upper pressure will be lower than ambient at this point, and so the crest
will rise even higher. Conversely, in the trough of the wave the upper ﬂuid will travel
slower, and its pressure will increase. The pressure differential will push the trough
downward, making it grow.
Equivalently, we can regard the boundary layer as a plane containing parallel vor-
tex lines that interact with one another, much like magnetic ﬁeld lines exert pressure
on one another. When the vortex lines all lie strictly in a plane, they are in equilibrium,
because the repulsive force exerted by one on its neighbor is balanced by an opposite
force exerted by the opposite neighbor. However, when this equilibrium is disturbed,
the forces become unbalanced and the vortex sheet effectively buckles.
More generally, when there is a large amount of relative kinetic energy available in
a high-Reynolds-number ﬂow, there exists the possibility of unstable modes that can
tap this energy and convert it into a spectrum of growing modes. These modes can
then interact nonlinearly to create ﬂuid turbulence, which ultimately is dissipated as
heat. However, the availability of free kinetic energy does not necessarily imply that
the ﬂow is unstable; sometimes it is stable. Instability must be demonstrated—often
a very difﬁcult task.
14.6.2
14.6.2 Discontinuous Flow with Gravity
What happens to this Kelvin-Helmholtz instability if we turn on gravity? To learn the
answer, we insert a downward gravitational acceleration g into the above analysis. The
result (Ex. 14.25) is the following modiﬁcation of the dispersion relation (14.82):
ω
k =
ρ+V
ρ+ + ρ−
±
'
g
k
*
ρ−−ρ+
ρ+ + ρ−
+
−
ρ+ρ−
(ρ+ + ρ−)2V 2
(1/2
.
(14.86)
gravity suppresses Kelvin-
Helmholtz instability
If the lower ﬂuid is sufﬁciently more dense than the upper ﬂuid (ρ−sufﬁciently
bigger than ρ+), then gravity g will change the sign of the quantity inside the square
root, making ω/k real, which means the Kelvin-Helmholtz instability is suppressed.
In other words, for the ﬂow to be Kelvin-Helmholtz unstable in the presence of gravity,
the two ﬂuids must have nearly the same density:
782
Chapter 14. Vorticity

FIGURE 14.21 Billow clouds above San Francisco. The cloud structure is generated by the Kelvin-
Helmholtz instability. These types of billow clouds may have inspired the swirls in Vincent van
Gogh’s famous painting “Starry Night.” Courtesy of Science Source.
ρ−−ρ+
ρ+ + ρ−
<
ρ+ρ−
(ρ+ + ρ−)2
kV 2
g .
(14.87)
This is the case for many interfaces in Nature, which is why the Kelvin-Helmholtz
instability is often seen. An example is the interface between a water-vapor-laden layer
ofairunderafast-moving, drierlayer.Theresultistheso-called“billowclouds”shown
in Fig. 14.21. Other examples are ﬂow interfaces in the ocean and the edges of dark
smoke pouring out of a smoke stack.
As another application of the dispersion relation (14.86), consider the excitation
of ocean waves by a laminar-ﬂowing wind. In this case, the “+” ﬂuid is air, and the “−”
ﬂuid is water, so the densities are very different: ρ+/ρ−≃0.001. The instability crite-
rion (14.87) tells us the minimum wind velocity V required to make the waves grow:
Vmin ≃
*
g
k
ρ−
ρ+
+1/2
≃450 km h−1
λ/10 m,
(14.88)
where λ = 2π/k is the waves’ wavelength.
Obviously, this answer is physically wrong. Water waves are easily driven by winds
that are far slower than this. Evidently, some other mechanism of interaction between
wind and water must drive the waves much more strongly. Observations of wind over
water reveal the answer: The winds near the sea’s surface are typically quite turbulent
(Chap. 15), not laminar. The randomly ﬂuctuating pressures in a turbulent wind are
far more effective than the smoothly varying pressure of a laminar wind in driving
ocean waves. For two complementary models of this, see Phillips (1957) and Miles
(1993).
Rayleigh-Taylor instability
As another, very simple application of the dispersion relation (14.86), set the speed
V oftheupperﬂuidtozero.Inthiscase, theinterfaceisunstableifandonlyiftheupper
14.6 Instabilities of Shear Flows—Billow Clouds and Turbulence in the Stratosphere
783

ﬂuid has higher density than the lower ﬂuid: ρ+ > ρ−. This is called the Rayleigh-
Taylor instability for incompressible ﬂuids.
EXERCISES
Exercise 14.25 Problem: Discontinuous Flow with Gravity
Insert gravity into the analysis of the Kelvin-Helmholtz instability (with the uniform
gravitational acceleration g pointing perpendicularly to the ﬂuid interface, from the
upper “+” ﬂuid to the lower “−” ﬂuid). Thereby derive the dispersion relation (14.86).
14.6.3
14.6.3 Smoothly Stratiﬁed Flows: Rayleigh and Richardson Criteria for Instability
Sometimes one can diagnose a ﬂuid instability using simple physical arguments rather
than detailed mathematical analysis. We conclude this chapter with two examples.
rotating Couette ﬂow
First, we consider rotating Couette ﬂow: the azimuthal ﬂow of an incompressible,
effectively inviscid ﬂuid, rotating axially between two coaxial cylinders (Fig. 14.22).
We explore the stability of this ﬂow to purely axisymmetric perturbations by
using a thought experiment in which we interchange two ﬂuid rings. As there are
no azimuthal forces (no forces in the φ direction), the interchange will occur at
constant angular momentum per unit mass. Suppose that the ring that moves outward
in radius ϖ has lower speciﬁc angular momentum j than the surroundings into
which it has moved; then it will have less centrifugal force per unit mass j2/ϖ 3 than
its surroundings and will thus experience a restoring force that drives it back to its
original position. Conversely, if the surroundings’ angular momentum per unit mass
decreases outward, then the displaced ring will continue to expand. We conclude on
Rayleigh criterion for
instability of rotating ﬂows
this basis that Couette and similar ﬂows are unstable when the angular momentum per
unit mass decreases outward. This is known as the Rayleigh criterion. We return to
Couette ﬂow in Sec. 15.6.1.
Compact stellar objects (black holes, neutron stars, and white dwarfs) are some-
times surrounded by orbiting accretion disks of gas (Exs. 26.17 and 26.18). The gas in
these disks orbits with its angular velocity approximately dictated by Kepler’s laws.
Therefore, the speciﬁc angular momentum of the gas increases radially outward,
approximately proportional to the square root of the orbital radius. Consequently,
accretion disks are stable to this type of instability.
For our second example of a simple physical diagnosis of instability, consider the
situation analyzed in Ex. 14.25 (Kelvin-Helmholtz instability with gravity present)
but with the density and velocity changing continuously instead of discontinuously,
as one moves upward. More speciﬁcally, focus on Earth’s stratosphere, which extends
from ∼10 km height to ∼40 km. The density in the stratosphere decreases upward
stability of a
superadiabatic density
gradient
faster than if the stratosphere were isentropic. This means that, when a ﬂuid element
movesupwardadiabatically, itspressure-induceddensityreductionissmallerthanthe
density decrease in its surroundings. Since it is now more dense than its surroundings,
the downward pull of gravity on the ﬂuid element will exceed the upward buoyant
784
Chapter 14. Vorticity

v
v
v
φ
ϖ
z
FIGURE 14.22 Rotating Couette ﬂow.
force, so the ﬂuid element will be pulled back down. Therefore, the stratosphere
is stably stratiﬁed. (We shall return to this phenomenon, in the context of stars, in
Sec. 18.5.)
However, itmaybepossibleforthestratospheretotaptherelativekineticenergyin
its horizontal winds, so as to mix the air vertically. Consider the pedagogical example
of two thin stream tubes of horizontally ﬂowing air in the stratosphere, separated
vertically by a distance δℓlarge compared to their thicknesses. The speed of the upper
stream will exceed that of the lower stream by δV = V ′δℓ, where V ′ = dV/dz is the
velocity gradient. In the center of velocity frame, the streams each have speed δV/2,
and they differ in density by δρ = |ρ′δℓ|. To interchange these streams requires doing
work per unit mass7 δW = g[δρ/(2ρ)]δℓagainst gravity (where the factor 2 comes
from the fact that there are two unit masses involved in the interchange, one going
up and the other coming down). This work can be supplied by the streams’ kinetic
energy, if the available kinetic energy per unit mass, δEk = (δV/2)2/2, exceeds the
required work. A necessary condition for instability is then that
δEk = (δV )2/8 > δW = g|ρ′/(2ρ)|δℓ2,
(14.89)
or
Richardson criterion for
instability of a stratiﬁed
shear ﬂow
Ri = |ρ′|g
ρV ′2 < 1
4 ,
(14.90)
7.
Here, for simplicity we idealize the streams’ densities as not changing when they move vertically—an
idealization that makes gravity be more effective at resisting the instability. In the stratosphere, where the
temperature is constant (Fig. 13.2) so the density drops vertically much faster than if it were isentropic,
this idealization is pretty good.
14.6 Instabilities of Shear Flows—Billow Clouds and Turbulence in the Stratosphere
785

where V ′ = dV/dz is the velocity gradient. This is known as the Richardson criterion
for instability,and Ri is the Richardson number.Under a wide variety of circumstances
Richardson number
this criterion turns out to be sufﬁcient for instability.
The density scale height in the stratosphere is ρ/|ρ′| ∼10 km. Therefore the
maximum velocity gradient allowed by the Richardson criterion is
V ′ <∼60m s−1
km .
(14.91)
Larger velocity gradients are rapidly disrupted by instabilities. This instability is re-
sponsible for much of the clear air turbulence encountered by airplanes, and it is to a
discussion of turbulence that we turn in the next chapter.
Bibliographic Note
Vorticity is so fundamental to ﬂuid mechanics that it and its applications are treated
in detail in all ﬂuid-dynamics textbooks. Among those with a physicist’s perspective,
we particularly like Acheson (1990) and Lautrup (2005) at an elementary level, and
Landau and Lifshitz (1959), Lighthill (1986), and Batchelor (2000) at a more advanced
level. Tritton (1987) is especially good for physical insight. Panton (2005) is almost
encyclopedic and nicely bridges the viewpoints of physicists and engineers. For an en-
gineering emphasis, we like Munson, Young, and Okiishi (2006) and Potter, Wiggert,
and Ramadan (2012); see also the more advanced text on viscous ﬂow, White (2006).
For the viewpoint of an applied mathematician, see Majda and Bertozzi (2002).
To build up physical intuition, we recommend Tritton (1987) and the movies listed
in Box 14.2. For a textbook treatment of rotating ﬂows and weak perturbations of
them, we recommend Greenspan (1973). For geophysical applications at an elemen-
tary level, we like Cushman-Roisin and Beckers (2011), and for a more mathematical
treatment Pedlosky (1987). A more encyclopedic treatment at an elementary level
(including some discussion of simulations) can be found in Gill (1982) and Vallis
(2006).
786
Chapter 14. Vorticity

15
CHAPTER FIFTEEN
Turbulence
Big whirls have little whirls, which feed on their velocity.
Little whirls have lesser whirls, and so on to viscosity.
LEWIS RICHARDSON (1922)
15.1
15.1 Overview
In Sec. 13.7.6, we derived the Poiseuille formula for the ﬂow of a viscous ﬂuid down
a pipe by assuming that the ﬂow is laminar (i.e., that it has a velocity parallel to the
pipe wall). We showed how balancing the stress across a cylindrical surface led to a
parabolic velocity proﬁle and a rate of ﬂow proportional to the fourth power of the
pipe diameter d. We also deﬁned the Reynolds number; for pipe ﬂow it is Red ≡¯vd/ν,
where ¯v is the mean speed in the pipe, and ν is the kinematic viscosity. Now, it turns
out experimentally that the pipe ﬂow only remains laminar up to a critical Reynolds
number that has a value in the range ∼103–105, depending on the smoothness of the
pipe’s entrance and roughness of its walls. If the pressure gradient is increased further
(and thence the mean speed ¯v and Reynolds number Red are increased), then the
velocity ﬁeld in the pipe becomes irregular both temporally and spatially, a condition
known as turbulence.
Turbulence is common in high-Reynolds-number ﬂows. Much of our experience
with ﬂuids involves air or water, for which the kinematic viscosities are ∼10−5 and
10−6 m2 s−1, respectively. For a typical everyday ﬂow with a characteristic speed of
v ∼10 m s−1 and a characteristic length of d ∼1m, the Reynolds number is huge:
Re = vd/ν ∼106 −107. It is therefore not surprising that we see turbulent ﬂows all
around us. Smoke in a smokestack, a cumulus cloud, and the wake of a ship are
examples.
In Sec. 15.2 we illustrate the phenomenology of the transition to turbulence as
the Reynolds number increases using a particularly simple example: the ﬂow of a
ﬂuid past a circular cylinder oriented perpendicular to the ﬂow’s incoming velocity.
We shall see how the ﬂow pattern is dictated by the Reynolds number, and how the
velocity changes from steady creeping ﬂow at low Re to fully developed turbulence at
high Re.
787

BOX 15.1.
READERS’ GUIDE
.
This chapter relies heavily on Chaps. 13 and 14.
.
The remaining chapters on ﬂuid mechanics and magnetohydro-
dynamics (Chaps. 16–19) do not rely signiﬁcantly on this chapter,
nor do any of the remaining chapters in this book.
What is turbulence? Fluid dynamicists can recognize it, but they have a hard
time deﬁning it precisely1 and an even harder time describing it quantitatively.2 So
typically for a deﬁnition they rely on empirical, qualitative descriptions of its physical
properties (Sec. 15.3). Closely related to this description is the crucial role of vorticity
in driving turbulent energy from large scales to small (Sec. 15.3.1).
At ﬁrst glance, a quantitative description of turbulence appears straightforward.
Decompose the velocity ﬁeld into Fourier components just as is done for the electro-
magnetic ﬁeld when analyzing electromagnetic radiation. Then recognize that the
equations of ﬂuid dynamics are nonlinear, so there will be coupling between different
modes (akin to wave-wave coupling between optical modes in a nonlinear crystal,
discussed in Chap. 10). Analyze that coupling perturbatively. The resulting weak-
turbulence formalism is sketched in Secs. 15.4.1 and 15.4.2 and in Ex. 15.5.3
However, most turbulent ﬂows come under the heading of fully developed or
strong turbulence and cannot be well described by weak-turbulence models. Part
of the problem is that the (v . ∇)v term in the Navier-Stokes equation is a strong
nonlinearity, not a weak coupling between linear modes. As a consequence, eddies of
size ℓpersist for typically no more than one turnover timescale ∼ℓ/v before they are
broken up, and so they do not behave like weakly coupled normal modes.
In the absence of a decent quantitative theory of strong turbulence, ﬂuid dy-
namicists sometimes simply push the weak-turbulence formalism into the strong-
turbulenceregimeanduseittheretogainqualitativeorsemiquantitativeinsights(e.g.,
Fig. 15.7 below and associated discussion in the text). A simple alternative (which we
explore in Sec. 15.4.3 in the context of wakes and jets and in Sec. 15.5 for turbu-
lent boundary layers) is intuitive, qualitative, and semiquantitative approaches to the
physical description of turbulence. We emphasize the adjective “physical,” because our
goal is to start to comprehend the underlying physical character of turbulence, going
beyond empirical descriptions of its consequences on the one hand and uninstruc-
1.
The analogy to Justice Potter Stewart’s deﬁnition of pornography should be resisted.
2.
Werner Heisenberg’s dissertation was “On the Stability and Turbulence of Fluid Flow.” He was disap-
pointed with his progress and was glad to change to a more tractable problem.
3.
Another weak-turbulence formalism that is developed along similar lines is the quasilinear theory of
nonlinear plasma interactions, which we discuss in Chap. 23.
788
Chapter 15. Turbulence

tive mathematical expansions on the other. Much modern physics has this character.
An important feature that we meet in Sec. 15.4.3, when we discuss wakes and jets, is
entrainment. This leads to irregular boundaries of turbulent ﬂows caused by giant
eddies and to dramatic time dependence, including intermittency.
One triumph of this approach (Sec. 15.4.4) is the Kolmogorov analysis of the
shape of the time-averaged turbulent energy spectrum (the turbulent energy per unit
wave number as a function of wave number) in a stationary turbulent ﬂow. This
spectrum has been veriﬁed experimentally under many different conditions. The
arguments used to justify it are characteristic of many semiempirical derivations of
scaling relations that ﬁnd conﬁdent practical application in the world of engineering.
In the context of turbulent boundary layers, our physical approach will reveal
semiquantitatively the structures of such boundary layers (Sec. 15.5.1), and it will
explain why turbulent boundary layers generally exert more shear stress on a surface
than do laminar boundary layers, but nevertheless usually produce less total drag on
airplane wings, baseballs, etc. (Sec. 15.5.2).
Whether or not a ﬂow becomes turbulent can have a major inﬂuence on how fast
chemical reactions occur in liquids and gases. In Sec. 15.5.3, we brieﬂy discuss how
turbulence can arise through instability of a laminar boundary layer.
One can gain additional insight into turbulence by a technique that is often useful
when struggling to understand complex physical phenomena: Replace the system
being studied by a highly idealized model system that is much simpler than the
original one, both conceptually and mathematically, but that retains at least one
central feature of the original system. Then analyze the model system completely,
with the hope that the quantitative insight so gained will be useful in understanding
the original problem. Since the 1970s, new insights into turbulence have come from
studying idealized dynamical systems that have very few degrees of freedom but have
the same kinds of nonlinearities as produce turbulence in ﬂuids (e.g., Ott, 1982; Ott,
1993). We examine several such low-dimensional dynamical systems and the insights
they give in Sec. 15.6.
The most useful of those insights deal with the onset of weak turbulence and the
observation that it seems to have much in common with the onset of chaos (irregular
and unpredictable dynamical behavior) in a wide variety of other dynamical systems.
A great discovery of modern classical physics/mathematics has been that there exist
organizational principles that govern the behavior of these seemingly quite different
chaotic physical systems.
In parallel with studying this chapter, to build up physical intuition the reader is
urged to watch movies and study photographs that deal with turbulence; see Box 15.2.
15.2
15.2 The Transition to Turbulence—Flow Past a Cylinder
We illustrate qualitatively how a ﬂow (and especially its transition to turbulence)
depends on its Reynolds number by considering a speciﬁc problem: the ﬂow of a
15.2 The Transition to Turbulence—Flow Past a Cylinder
789

BOX 15.2.
MOVIES AND PHOTOGRAPHS ON TURBULENCE
The most relevant movies for this chapter are:
.
Stewart (1968)—demonstrates key features of turbulent ﬂows.
.
Rouse (1963d)—exhibits the transition from laminar to turbulent
ﬂow.
Also useful are photographs of turbulence (e.g., in Van Dyke, 1982).
uniformly moving ﬂuid past a cylinder oriented transversely to the ﬂow’s incoming
velocity (Fig. 15.1). We assume that the ﬂow velocity is small compared with the speed
of sound, so the effects of compressibility can be ignored. Let the cylinder diameter be
d, and choose this as the characteristic length in the problem. Similarly, let the velocity
far upstream be V and choose this as the characteristic velocity, so the Reynolds
number is4
Reynolds number
Red = V d
ν .
(15.1)
Initially, we assume that the ﬂow is stationary (no turbulence) as well as incom-
pressible, and the effects of gravity are negligible. Then the equations governing the
equations governing
stationary, unperturbed
ﬂows
ﬂow are incompressibility,
∇. v = 0,
(15.2a)
and the time-independent Navier-Stokes equation (13.69) with ∂v/∂t = 0:
(v . ∇)v = −∇P
ρ
+ ν∇2v.
(15.2b)
These four equations (one for incompressibility, three for the components of Navier-
Stokes) can be solved for the pressure and the three components of velocity subject
to the velocity vanishing on the surface of the cylinder and becoming uniform far
upstream.
From the parameters of the ﬂow (the cylinder’s diameter d; the ﬂuid’s incoming
velocity V , its density ρ, and its kinematic viscosity ν) we can construct only one
dimensionless number, the Reynolds number Red = V d/ν. (If the ﬂow speed were
high enough that incompressibility fails, then the sound speed cs would also be a
relevant parameter, and a second dimensionless number could be formed: the Mach
number, M = V/cs; Chap. 17.) With Red the only dimensionless number, we are
4.
The subscript d is just a reminder that in this instance we have chosen the diameter as the characteristic
lengthscale; for other applications, the length of the cylinder might be more relevant.
790
Chapter 15. Turbulence

(a) Red ¿ 1
(b) Red = 2
(c) Red = 20
(d) Red = 200
(e) Red = 2,000
(f) Red = 2 £ 106
d
V
FIGURE 15.1 Schematic depiction of ﬂow past a cylinder for steadily increasing values of the Reynolds
number Red = V d/ν as labeled. There are many photographs, drawings, and simulations of this ﬂow
on the web, perhaps best found by doing a search on “K´arm´an vortex street.”
guaranteed on dimensional grounds that the solution to the ﬂow equations can be
expressed as
dimensional analysis gives
functional form of ﬂow
v/V = U(x/d, Red).
(15.3)
Here U is a dimensionless function of the dimensionless x/d, and it can take wildly
different forms, depending on the value of the Reynolds number Red (cf. Fig. 15.1,
which we discuss below).
The functional form of v [Eq. (15.3)] has important implications. If we compute
the ﬂow for speciﬁc values of the upstream velocity V , the cylinder’s diameter d,
and the kinematic viscosity ν and then double V and d and quadruple ν so that
Red is unchanged, then the new solution will be similar to the original one. It can
be produced from the original by rescaling the ﬂow velocity to the new upstream
velocity and the distance to the new cylinder diameter. [For this reason, Eq. (15.3) is
sometimes called a scaling relation.] By contrast, if we had only doubled the kinematic
scaling relation
15.2 The Transition to Turbulence—Flow Past a Cylinder
791

viscosity, theReynoldsnumberwouldhavealsodoubled, andwecouldbedealingwith
a qualitatively different ﬂow.
When discussing ﬂow past the cylinder, a useful concept is the stagnation pressure
in the upstream ﬂow. This is the pressure the ﬂuid would have, according to the
Bernoulli principle (v2/2 +

dP/ρ = const), if it were brought to rest at the leading
edge of the cylinder without signiﬁcant action of viscosity. Ignoring the effects of
compressibility (so ρ is constant), this stagnation pressure is
stagnation pressure
Pstag = P0 + 1
2 ρV 2 ,
(15.4)
where P0 is the upstream pressure. Suppose that this stagnation pressure were to
act over the whole front face of the cylinder, while the pressure P0 acted on the
downstream face. The net force on the cylinder per unit length, FD, would then be
1
2ρV 2d. This is a ﬁrst rough estimate for the drag force. It is conventional to deﬁne
a drag coefﬁcient as the ratio of the actual drag force per unit length to this rough
estimate:
drag coefﬁcient
CD ≡
FD
1
2ρV 2d
.
(15.5)
This drag coefﬁcient, being a dimensionless feature of the ﬂow (15.3), can depend
only on the dimensionless Reynolds number Red: CD = CD(Red); see Fig. 15.2.
drag coefﬁcient is function
of Reynolds number
Similarlyforﬂowpasta3-dimensionalbodywithcrosssectionalareaAperpendicular
to the ﬂow and with any other shape, the drag coefﬁcient
CD ≡
FD
1
2 ρV 2A
(15.6)
Red
CD     6/Red
CD
100
10
1
0.1
0.1
103
1
104
10
105
100
106
boundary layer
becomes
turbulent
FIGURE 15.2 Drag coefﬁcient CD for ﬂow past a cylinder as a function of Reynolds number
Red = V d/ν. This graph, adapted from Tritton (1987, Fig. 3.15), is based on experimental
measurements.
792
Chapter 15. Turbulence

will be a function only of Re. However, the speciﬁc functional form of CD(Re) will
depend on the body’s shape and orientation.
at Red ≪1
Red ≪1
Red ≪1: creeping ﬂow
and CD ∼6/Red
CD ∼6/Red
CD ∼6/Red
Now, turn to the details of the ﬂow around a cylinder as described in Figs. 15.1 and
15.2.AtlowReynoldsnumber, Red ≪1, thereiscreepingﬂow(Fig.15.1a)justlikethat
analyzed in detail for a spherical obstacle in Sec. 14.3.2. As you might have surmised
by tackling Ex. 14.12, the details of low-Reynolds-number ﬂow past a long object,
such as a cylinder, are subtly different from those of ﬂow past a short one, such as a
sphere. This is because, for a cylinder, inertial forces become comparable with viscous
and pressure forces at distances ∼d/Red, where the ﬂow is still signiﬁcantly perturbed
from uniform motion, while for short objects inertial forces become signiﬁcant only at
much larger radii, where the ﬂow is little perturbed by the object’s presence. Despite
this, the ﬂow streamlines around a cylinder at Red ≪1 (Fig. 15.1a) are similar to
those for a sphere (Fig. 14.10) and are approximately symmetric between upstream
and downstream. The ﬂuid is decelerated by viscous stresses as it moves past the
cylinder along these streamlines, and the pressure is higher on the cylinder’s front face
than on its back. Both effects contribute to the net drag force acting on the cylinder.
The momentum removed from the ﬂow is added to the cylinder. At cylindrical
radius ϖ ≪d/Red the viscous stress dominates over the ﬂuid’s inertial stress, and
the ﬂuid momentum therefore is being transferred largely to the cylinder at a rate
per unit area ∼ρV 2. In contrast, for ϖ >∼d/Red the viscous and inertial stresses are
comparable and balance each other, and the ﬂow’s momentum is not being transferred
substantially to the cylinder. This implies that the effective cross sectional width over
which the cylinder extracts the ﬂuid’s momentum is ∼d/Red, and correspondingly,
the net drag force per unit length is F ∼ρV 2d/Red, which implies [cf. Eq. (15.5)] a
drag coefﬁcient ∼1/Red at low Reynolds numbers (Red ≪1). A more careful analysis
gives CD ∼6/Red, as shown experimentally in Fig. 15.2.
As the Reynolds number is increased to ∼1(Fig. 15.1b), the effective cross section
gets reduced to roughly the cylinder’s diameter d; correspondingly, the drag coefﬁ-
cient decreases to CD ∼1. At this Reynolds number, Red ∼1, the velocity ﬁeld begins
to appear asymmetric from front to back.
at Red ∼1
Red ∼1
Red ∼1: CD ∼1
CD ∼1
CD ∼1 and
laminar boundary layer
starts to form
With a further increase in Red, a laminar boundary layer of thickness δ ∼d/√Red
starts to form. The viscous force per unit length due to this boundary layer is F ∼
ρV 2d/√Red [cf. Eqs. (14.49)–(14.51) divided by the transverse length w, and with
ℓ∼d and vo = V ]. It might therefore be thought that the drag would continue to
decrease as CD ∼1/√Red, when Red increases substantially above unity, making the
boundary layer thin and the external ﬂow start to resemble potential ﬂow. However,
this does not happen. Instead, at Red ∼5, the ﬂow begins to separate from the back
at Red ∼5
Red ∼5
Red ∼5: separation
begins
side of the cylinder and is there replaced by two retrograde eddies (Fig. 15.1c). As
described in Sec. 14.4.4, this separation occurs because an adverse pressure gradient
(v . ∇)P > 0 develops outside the boundary layer, near the cylinder’s downstream
face, and causes the separated boundary layer to be replaced by these two counter-
rotating eddies. The pressure in these eddies, and thus also on the cylinder’s back face,
15.2 The Transition to Turbulence—Flow Past a Cylinder
793

is of order the ﬂow’s incoming pressure P0 and is signiﬁcantly less than the stagna-
tion pressure Pstag = P0 + 1
2ρV 2 at the cylinder’s front face, so the drag coefﬁcient
stabilizes at CD ∼1.
As the Reynolds number increases above Red ∼5, the size of the two eddies
increases until, at Red ∼100, the eddies are shed dynamically, and the ﬂow becomes
nonstationary. The eddies tend to be shed alternately in time, ﬁrst one and then the
at Red ∼100
Red ∼100
Red ∼100: eddies shed
dynamically; form K´arm´an
vortex street
other, producing a beautiful pattern of alternating vortices downstream known as a
K´arm´an vortex street (Fig. 15.1d).
at Red ∼1,000
Red ∼1,000
Red ∼1,000: turbulent
wake
When Red ∼1,000, the downstream vortices are no longer visible, and the wake
behind the cylinder contains a velocity ﬁeld irregular on all macroscopic scales
(Fig. 15.1e). This downstream ﬂow has become turbulent. Finally, at Red ∼3 × 105,
at Red ∼3 × 105
Red ∼3 × 105
Red ∼3 × 105: turbulent
boundary layer
the boundary layer itself, which has been laminar up to this point, becomes turbulent
(Fig. 15.1f), reducing noticeably the drag coefﬁcient (Fig. 15.2). We explore the cause
of this reduction in Sec. 15.5. [The physically relevant Reynolds number for onset of
turbulence in the boundary layer is that computed not from the cylinder diameter d,
Red = V d/ν, but rather from the boundary layer thickness δ ∼d/Re1/2
d :
Reδ = V δ
ν ∼V dRe−1/2
d
ν
=

Red.
(15.7)
The onset of boundary-layer turbulence is at Reδ ∼
√
3 × 105 ∼500, about the same
as the Red ∼1,000 for the onset of turbulence in the wake.]
turbulence is
3-dimensional
An important feature of this changing ﬂow pattern is that at Red ≪1,000
(Figs. 15.1a–d), before any turbulence sets in, the ﬂow (whether steady or dynamical)
istranslationsymmetric—itisindependentofdistancez downthecylinder(i.e., itis2-
dimensional). This is true even of the K´arm´an vortex street. By contrast, the turbulent
velocity ﬁeld at Red >∼1,000 is fully 3-dimensional. At these high Reynolds num-
bers, small, nontranslation-symmetric perturbations of the translation-symmetric
ﬂow grow into vigorous, 3-dimensional turbulence. This is a manifestation of the
inability of 2-dimensional ﬂows to exhibit all the chaotic motion associated with 3-
dimensional turbulence (Sec. 15.4.4).
The most important feature of this family of ﬂows—one that is characteristic
of most such families—is that there is a critical Reynolds number for the onset of
critical Reynolds number
for onset of turbulence
turbulence. That critical number can range from ∼30 to ∼105, depending on the
geometry of the ﬂow and on precisely what length and speed are used to deﬁne the
Reynolds number.
EXERCISES
Exercise 15.1 **Example: The 2-Dimensional Laminar Wake behind a Cylinder
In Sec. 15.4.3, we explore the structure of the wake behind the cylinder when the
Reynolds number is high enough that the ﬂow is turbulent. For comparison, here we
794
Chapter 15. Turbulence

uo
u(x, y)
y
x
V
vx
w
FIGURE 15.3 The 2-dimensional laminar wake behind an inﬁnitely long cylinder.
(This ﬁgure also describes a turbulent wake, at high Reynolds numbers, if vx is
replaced by the time-averaged ¯vx; Sec. 15.4.3.)
compute the wake’s structure at lower Reynolds numbers, when the wake is laminar.
This computation is instructive: using order-of-magnitude estimates ﬁrst, followed
by detailed calculations, it illustrates the power of momentum conservation. It is our
ﬁrst encounter with the velocity ﬁeld in a wake.
(a) Begin with an order-of-magnitude estimate. Characterize the wake by its width
w(x) at distance x downstream from the cylinder and by the reduction in the ﬂow
velocity (the “velocity deﬁcit”), uo(x) ≡V −vx(x), at the center of the wake; see
Fig. 15.3. From the diffusion of vorticity show that w ≃2√νx/V .
(b) Explain why momentum conservation requires that the force per unit length on
the cylinder, FD = CD
1
2ρV 2d [Eq. (15.5)], equals the transverse integral

Txxdy
of the ﬂuid’s kinetic stress (Txx = ρvxvx) before the ﬂuid reaches the sphere,
minus that integral at distance x after the sphere. Use this requirement to show
that the fractional velocity deﬁcit at the center of the wake is uo/V ≃1
4CDd/w ≃
CD

d Red/(64x).
(c) For a more accurate description of the ﬂow, solve the Navier-Stokes equation to
obtain the proﬁle of the velocity deﬁcit, u(x, y) ≡V −vx(x, y). [Hint: Ignoring
the pressure gradient, which is negligible (Why?), the Navier-Stokes equation
shouldreducetothe1-dimensionaldiffusionequation, whichwehavemetseveral
times previously in this book.] Your answer should be
u = uoe−(2y/w)2,
w = 4
νx
V
1/2
,
uo = V CD
d Red
16πx
1/2
,
(15.8)
where w and uo are more accurate values of the wake’s width and its central
velocity deﬁcit.
15.2 The Transition to Turbulence—Flow Past a Cylinder
795

y
x
ambient fluid
at rest
ambient fluid
at rest
jet
jet
w(x)
FIGURE 15.4 2-dimensional laminar jet. As the jet widens, it entrains ambient ﬂuid.
Exercise 15.2 Problem: The 3-Dimensional Laminar Wake behind a Sphere
Repeat Ex. 15.1 for the 3-dimensional laminar wake behind a sphere.
Exercise 15.3 Example: Structure of a 2-Dimensional Laminar Jet; Entrainment
Consider a narrow, 2-dimensional, incompressible (i.e., subsonic) jet emerging from
a 2-dimensional nozzle into ambient ﬂuid at rest with the same composition and
pressure.(By2-dimensionalwemeanthatthenozzleandjetaretranslationsymmetric
in the third dimension.) Let the Reynolds number be low enough for the ﬂow to be
laminar; westudytheturbulentregimeinEx.15.7.Wewanttounderstandhowrapidly
this laminar jet spreads.
(a) Show that the pressure forces far downstream from the nozzle are likely to be
much smaller than the viscous forces and can therefore be ignored.
(b) Let the jet’s thrust per unit length (i.e., the momentum per unit time per unit
length ﬂowing through the nozzle) be F. Introduce Cartesian coordinates x, y,
with x parallel to and y perpendicular to the jet (cf. Fig. 15.4). As in Ex. 15.1, use
vorticity diffusion (or the Navier-Stokes equation) and momentum conservation
to estimate the speed vx of the jet and its width w as functions of distance x
downstream.
(c) Use the scalings from part (b) to modify the self-similarity analysis of the
Navier-Stokes equation that we used for the laminar boundary layer in Sec. 14.4,
and thereby obtain the following approximate solution for the jet’s velocity
proﬁle:
vx =
 3F 2
32ρ2νx
1/3
sech2
'
F
48ρν2x2
1/3
y
(
.
(15.9)
(d) Equation (15.9) shows that the jet width w increases downstream as x2/3. As the
jet widens, it scoops up (entrains) ambient ﬂuid, as depicted in Fig. 15.4. This
796
Chapter 15. Turbulence

entrainment actually involves pulling ﬂuid inward in a manner described by the
y component of velocity, vy. Solve the incompressibility equation ∇. v = 0 to
obtain the following expression for vy:
vy = −1
3x
 3F 2
32ρ2νx
1/3
(15.10)
×
;48ρν2x2
F
1/3
tanh
'
F
48ρν2x2
1/3
y
(
−2y sech2
'
F
48ρν2x2
1/3
y
(=
≃−
1
6
Fν
ρx2
1/3
sign(y)
for
|y| ≫1
2w(x) =
48ρν2x2
F
1/3
.
Thusambientﬂuidispulledinwardfrombothsidestosatisfythejet’sentrainment
appetite.
Exercise 15.4 Example: Marine Animals
One does not have to be a biologist to appreciate the strong evolutionary advantage
that natural selection confers on animals that can reduce their drag coefﬁcients. It
should be no surprise that the shapes and skins of many animals are highly stream-
lined. This is particularly true for aquatic animals. Of course, an animal minimizes
drag while developing efﬁcient propulsion and lift, which change the ﬂow pattern.
Comparisons of the properties of ﬂows past different stationary (e.g., dead or towed)
animals are, therefore, of limited value. The species must also organize its internal
organs in 3 dimensions, which is an important constraint. The optimization varies
from species to species and is suited to the environment. There are some impressive
performers in the animal world.
(a) First, idealizeouranimalasathinrectanglewiththicknesst, lengthℓ, andwidthw
such that t ≪ℓ≪w.5 Let the animal be aligned with the ﬂow parallel to the ℓ
direction. Assuming an area of A = 2ℓw, the drag coefﬁcient is CD = 1.33Re−0.5
ℓ
[Eq. (14.50)]. This assumes that the ﬂow is laminar. The corresponding result for
a turbulent ﬂow is CD ≃0.072Re−0.2
ℓ
. Show that the drag can be considerably
reduced if the transition to turbulence takes place at high Reℓ. Estimate the
effective Reynolds number for an approximately ﬂat ﬁsh like a ﬂounder of size
∼0.3 m that can move with a speed ∼0.3 m s−1, and then compute the drag force.
Express your answer as a stopping length.
(b) One impressive performer is the mackerel (a highly streamlined ﬁsh), for which
the reported drag coefﬁcient is 0.0043 at Re ∼105. Compare this with a thin plate
and a sphere. (The drag coefﬁcient for a sphere is CD ∼0.5, assuming a reference
area equal to the total area of the sphere. The drag decreases abruptly when there
is a transition to turbulence, just as we found with the cylinder.)
5.
The aquatic counterpart to the famous Spherical Cow!
15.2 The Transition to Turbulence—Flow Past a Cylinder
797

(c) Another ﬁne swimmer is the California sea lion, which has a drag coefﬁcient of
CD = 0.0041 at Re ∼2 × 106. How does this compare with a plate and a sphere?
Further details can be found in Vogel (1994) and references therein.
15.3
15.3 Empirical Description of Turbulence
Empirical studies of turbulent ﬂows have revealed some universal properties that
are best comprehended through movies (Box 15.2). Here we simply list the most
important of them and comment on them brieﬂy. We revisit most of them in more
detail in the remainder of the chapter. Throughout, we restrict ourselves to turbulence
with velocities that are very subsonic, and thus the ﬂuid is incompressible.
characteristics of
turbulence
Turbulence is characterized by:
.
Disorder, irreproducibleindetailbutwithrich, nonrandomstructure.Thisdis-
order is intrinsic to the ﬂow. It appears to arise from a variety of instabilities.
No forcing by external agents is required to produce it. If we try to resolve
the ﬂow into modes, however, we ﬁnd that the phases of the modes are not
fully random, either spatially or temporally: there are strong correlations.6
Correspondingly, if we look at a snapshot of a turbulent ﬂow, we frequently
observe large, well-deﬁned coherent structures like eddies and jets, which
suggests that the ﬂow is more organized than a purely random superposition
of modes, just as the light reﬂected from the surface of a painting differs from
that emitted by a blackbody. If we monitor the time variation of some ﬂuid
variable, such as one component of the velocity at a given point in the ﬂow,
we observe intermittency—the irregular starting and ceasing of strong tur-
bulence. Again, this effect is so pronounced that more than a random-mode
superposition is at work, reminiscent of the distinction between noise and
music (at least some music). [A major consequence that we shall have to
face is that strong turbulence is not well treated by perturbation theory. As
an alternative, semiquantitative techniques of analysis must be devised.]
.
A wide range of interacting scales. When the ﬂuid velocity and pressure are
Fourier analyzed, one ﬁnds them varying strongly over many decades of
wave number and frequency. We can think of these variations as due to
eddies with a huge range of sizes. These eddies interact strongly. Typically,
large eddies appear to feed their energy to smaller eddies, which in turn
feed energy to still smaller eddies, and so forth. Occasionally, amazingly, the
ﬂow of energy appears to reverse: small-scale turbulent structures give rise
6.
As we discuss in Chap. 28, many cosmologists suspected that the primordial ﬂuctuations, out of which
galaxies and stars eventually grew, would share this characteristic with turbulence. Insofar as we can
measure, this is not the case, and the ﬂuctuations appear to be quite random and uncorrelated.
798
Chapter 15. Turbulence

(a)
(b)
(c)
ω
FIGURE 15.5 Schematic illustration of the propagation of turbulence by the stretching
of vortex lines. The tube of vortex lines in (a) is stretched and thereby forced into a
reduced cross section by the turbulent evolution from (a) to (b) to (c). The reduced
cross section means an enhanced vorticity on smaller scales.
to large-scale structures,7 resulting in intermittency. A region of the ﬂow
that appears to have calmed down may suddenly and unexpectedly become
excited again.
.
Vorticity, irregularly distributed in three dimensions. This vorticity varies in
magnitude and direction over the same wide range of scales as for the ﬂuid
velocity. It appears to play a central role in coupling large scales to small; see
Sec. 15.3.1.
.
Large dissipation.Typically, turbulent energy is fed from large scales to small
in just one turnover time of a large eddy. This is extremely fast. The energy
cascades down to smaller and smaller lengthscales in shorter and shorter
timescales until it reaches eddies so small that their shear, coupled to molec-
ular viscosity, converts the turbulent energy into heat.
.
Efﬁcient mixing and transport. Most everything that can be transported is
efﬁciently mixed and moved: momentum, heat, salt, chemicals, and so forth.
15.3.1
15.3.1 The Role of Vorticity in Turbulence
Turbulent ﬂows contain tangled vorticity. As we discussed in Sec. 14.2.2, when viscos-
ity is unimportant, vortex lines are frozen into the ﬂuid and can be stretched by the
action of neighboring vortex lines. As a bundle of vortex lines is stretched and twisted
(Fig. 15.5), the incompressibility of the ﬂuid causes the bundle’s cross section to de-
crease and correspondingly causes the magnitude of its vorticity to increase and the
evolution of vorticity
in turbulence: toward
progressively smaller
scales
lengthscale on which the vorticity changes to decrease (cf. Sec. 14.2). The continuous
lengthening and twisting of ﬂuid elements therefore creates vorticity on progressively
smaller lengthscales.
7.
The creation of larger structures from smaller ones—sometimes called an inverse cascade—is a strong
feature of 2-dimensional ﬂuid turbulence.
15.3 Empirical Description of Turbulence
799

Note that, when the ﬂow is 2-dimensional (i.e., has translation symmetry), the
vortex lines point in the translational direction, so they do not get stretched, and
there is thus no inexorable driving of the turbulent energy to smaller and smaller
lengthscales. This is one reason why true turbulence does not occur in 2 dimensions,
only in 3.
However, something akin to turbulence but with much less richness and small-
scale structure, does occur in 2 dimensions (e.g., in 2-dimensional simulations of
the Kelvin-Helmholtz instability; Box 15.3). But in the real world, once the Kelvin-
Helmholtz instability is fully developed, 3-dimensional instabilities grow strong,
vortex-line stretching increases, and the ﬂow develops full 3-dimensional turbulence.
The same happens in other ostensibly 2-dimensional ﬂows (e.g., the “2-dimensional”
wake behind a long circular cylinder and “2-dimensional” jets and boundary layers;
Secs. 15.4.3 and 15.5).
15.4
15.4 Semiquantitative Analysis of Turbulence
weak turbulence versus
strong turbulence
Inthissection, wedevelopasemiquantitativemathematicalanalysisofturbulenceand
explore a few applications. This analysis is fairly good for weak turbulence. However,
for the much more common strong turbulence, it is at best semiquantitative—but
nonetheless widely used for lack of anything simple that is much better.
15.4.1
15.4.1 Weak-Turbulence Formalism
The meaning of weak turbulence can be explained in terms of interacting eddies (a
concept we exploit in Sec. 15.4.4 when studying the ﬂow of turbulent energy from
large scales to small). One can regard turbulence as weak if the timescale τ∗for a large
weak turbulence
eddy to feed most of its energy to smaller eddies is long compared to the large eddy’s
turnover time τ (i.e., its rotation period). The weak-turbulence formalism (model)
that we sketch here can be thought of as an expansion in τ/τ∗.
Unfortunately, for most turbulence seen in ﬂuids, the large eddies’ energy-loss
time is of order its turnover time, τ/τ∗∼1, which means the eddy loses its identity
in roughly one turnover time and the turbulence is strong. In this case, the weak-
turbulence formalism that we sketch here is only semiquantitatively accurate.
Our formalism for weak turbulence (with gravity negligible and the ﬂow highly
subsonic, so it can be regarded as incompressible) is based on the standard in-
compressibility equation and the time-dependent Navier-Stokes equation, which we
write as
∇. v = 0,
(15.11a)
ρ ∂v
∂t + ∇. (ρv ⊗v) = −∇P + ρν∇2v,
(15.11b)
assuming for simplicity that ρ is constant. [Equation (15.11b) is equivalent to (15.2b)
with ∂v/∂t added to account for time dependence and with the inertial force term
rewritten using ∇. (ρv ⊗v) = ρ(v . ∇)v, or equivalently in index notation,
(ρvivj);i = ρ,ivivj + ρ(vi;ivj + vivj;i) = ρvivj;i.] Equations (15.11) are four scalar
800
Chapter 15. Turbulence

BOX 15.3.
CONSEQUENCES OF THE KELVIN-HELMHOLTZ INSTABILITY
The Kelvin-Helmholtz instability arises when two ﬂuids with nearly the same
density are in uniform motion past each other (Sec. 14.6.1). Their interface
(a vortex sheet) develops corrugations that grow (Figs. 14.19 and 14.20).
That growth bends the corrugations more and more sharply. Along the
corrugated interface the ﬂuids on each side are still sliding past each other,
so the instability arises again on this smaller scale—and again and again,
somewhat like the cascade of turbulent energy from large scales to small.
In the real world, 3-dimensional instabilities also arise, and the ﬂow
becomes fully turbulent. However, much insight is gained into the difference
between 2- and 3-dimensional ﬂow by artiﬁcially constraining the Kelvin-
Helmholtz ﬂow to remain 2-dimensional. This is easily done in numerical
simulations. Movies of such simulations abound on the web (e.g., on the
Wikipedia web page for the Kelvin-Helmholtz instability; the following
picture is a still from that movie).
By Bdubb12 (Own work) [Public domain], via Wikimedia Commons.
https://commons.wikimedia.org/wiki/File%3AKHI.gif.
Although the structures in this simulation are complex, they are much
less rich than those that appear in fully 3-dimensional turbulence—perhaps
largely due to the absence of stretching and twisting of vortex lines when
the ﬂow is conﬁned to 2 dimensions. (Not surprisingly, the structures in this
simulation resemble some in Jupiter’s atmosphere, which also arise from a
Kelvin-Helmholtz instability.)
equations for four unknowns, P(x, t) and the three components of v(x, t); ρ and ν
can be regarded as constants.
To obtain the weak-turbulence versions of these equations, we split the velocity
foundations for weak-
turbulence theory
ﬁeld v(x, t) and pressure P(x, t) into steady parts ¯v, ¯P , plus ﬂuctuating parts, δv,
δP :
v = ¯v + δv,
P = ¯P + δP .
(15.12)
15.4 Semiquantitative Analysis of Turbulence
801

We can think of (or, in fact, deﬁne) ¯v and ¯P as the time averages of v and P , and
deﬁne δv and δP as the difference between the exact quantities and the time-averaged
quantities.
The time-averaged variables ¯v and ¯P are governed by the time-averaged in-
compressibility and Navier-Stokes equations (15.11). Because the incompressibility
equation is linear, its time average,
∇. ¯v = 0,
(15.13a)
entails no coupling of the steady variables to the ﬂuctuating ones. By contrast, the
nonlinear inertial term ∇. (ρv ⊗v) in the Navier-Stokes equation gives rise to such
a coupling in the (time-independent) time-averaged equation:
ρ(¯v . ∇)¯v = −∇¯P + ρν∇2¯v −∇. TR.
(15.13b)
Here
time-averaged Navier-
Stokes equation: couples
turbulence (via Reynolds
stress tensor) to time-
averaged ﬂow
TR ≡ρδv ⊗δv
(15.13c)
is known as the Reynolds stress tensor.It serves as a driving term in the time-averaged
Navier-Stokes equation (15.13b)—a term by which the ﬂuctuating part of the ﬂow
acts back on and so inﬂuences the time-averaged ﬂow.
This Reynolds stress TR can be regarded as an additional part of the total stress
tensor, analogous to the gas pressure computed in kinetic theory,8 P = 1
3ρv2, where v
is the molecular speed. TR will be dominated by the largest eddies present, and it can
be anisotropic, especially when the largest-scale turbulent velocity ﬂuctuations are
distorted by interaction with an averaged shear ﬂow [i.e., when ¯σij = 1
2(¯vi;j + ¯vj;i) is
large].
Reynolds stress for
stationary, homogeneous
turbulence
If the turbulence is both stationary and homogeneous (a case we specialize to
below when studying the Kolmogorov spectrum), then the Reynolds stress tensor
can be written in the form TR = PRg, where PR is the Reynolds pressure, which is
independent of position, and g is the metric, so gij = δij. In this case, the turbulence
exerts no force density on the mean ﬂow, so ∇. TR = ∇PR will vanish in the time-
averaged Navier-Stokes equation (15.13b). By contrast, near the edge of a turbulent
region (e.g., near the edge of a turbulent wake, jet, or boundary layer), the turbulence
is inhomogeneous, and thereby (as we shall see in Sec. 15.4.2) exerts an important
inﬂuence on the time-independent, averaged ﬂow.
correlation functions in
turbulence
Notice that the Reynolds stress tensor is the tensorial correlation function (also
called “autocorrelation function”) of the velocity ﬂuctuation ﬁeld at zero time delay
(multiplied by density ρ; cf. Secs. 6.4.1 and 6.5.1). Notice also that it involves the
8.
Deducible from Eq. (3.37c) or from Eqs. (3.39b) and (3.39c) with mean energy per particle ¯E = 1
2mv2.
802
Chapter 15. Turbulence

temporal cross-correlation function of components of the velocity ﬂuctuation [e.g.,
δvx(x, t)δvy(x, t); Sec. 6.5.1]. It is possible to extend this weak-turbulence formal-
ism so it probes the statistical properties of turbulence more deeply, with the aid
of correlation functions with ﬁnite time delays and correlation functions of veloc-
ity components (or other relevant physical quantities) at two different points in space
simultaneously; see, for example, Sec. 28.5.3. (It is relatively straightforward experi-
mentally to measure these correlation functions.) As we discuss in greater detail in
Sec. 15.4.4 (and also saw for 1- and 2-dimensional random processes in Secs. 6.4.4 and
6.5.2, and for multidimensional, complex random processes in Ex. 9.8), the Fourier
transforms of these correlation functions give the spatial and temporal spectral den-
sities of the ﬂuctuating quantities.
Just as the structure of the time-averaged ﬂow is governed by the time-averaged
incompressibility and Navier-Stokes equations (15.13) (with the ﬂuctuating variables
acting on the time-averaged ﬂow through the Reynolds stress), so also the ﬂuctuating
part of the ﬂow is governed by the ﬂuctuating (difference between instantaneous and
time-averaged) incompressibility and Navier-Stokes equations. For details, see Ex.
15.5. This exercise is important; it exhibits the weak-turbulence formalism in action
and underpins the application to spatial energy ﬂow in a 2-dimensional, turbulent
wake in Fig. 15.7 below.
EXERCISES
Exercise 15.5 **Example: Reynolds Stress; Fluctuating Part
of Navier-Stokes Equation in Weak Turbulence
(a) Derive the time-averaged Navier-Stokes equation (15.13b) from the time-
dependent form [Eq. (15.11b)], and thereby infer the deﬁnition (15.13c) for the
Reynolds stress. Equation (15.13b) shows how the Reynolds stress affects the evo-
lution of the mean velocity. However, it does not tell us how the Reynolds stress
evolves.
(b) Explain why an equation for the evolution of the Reynolds stress must involve
averagesoftripleproductsofthevelocityﬂuctuation.Similarly, thetimeevolution
of the averaged triple products will involve averaged quartic products, and so on
(cf. the BBGKY hierarchy of equations in plasma physics, Sec. 22.6.1). How do
you think you might “close” this sequence of equations (i.e., terminate it at some
low order) and get a fully determined system of equations? [Answer: The simplest
way is to use the concept of turbulent viscosity discussed in Sec. 15.4.2.]
(c) Show that the ﬂuctuating part of the Navier-Stokes equation (the difference be-
tween the exact Navier-Stokes equation and its time average) takes the follow-
ing form:
∂δv
∂t + (¯v . ∇)δv + (δv . ∇)¯v + [(δv . ∇)δv −(δv . ∇)δv]=
−1ρ ∇δP + ν∇2(δv)
.
(15.14a)
15.4 Semiquantitative Analysis of Turbulence
803

This equation and the ﬂuctuating part of the incompressibility equation
∇. δv = 0
(15.14b)
govern the evolution of the ﬂuctuating variables δv and δP . [The challenge, of
course, is to devise ways to solve these equations despite the nonlinearities and
the coupling to the mean ﬂow ¯v that show up strongly in Eq. (15.14a).]
(d) By dotting δv into Eq. (15.14a) and then taking its time average, derive the
following law for the spatial evolution of the turbulent energy density 1
2ρδv2:
spatial evolution equation
for turbulent energy
density
¯v . ∇(1
2ρδv2) + ∇.
1
2ρδv2δv + δP δv

= −T ij
R ¯vi;j + νρδv . (∇2δv).
(15.15)
Here T ij
R = ρδviδvj is the Reynolds stress [Eq. (15.13c)]. Interpret each term
in this equation. [The four interpretations will be discussed below, for a 2-
dimensional turbulent wake, in Sec. 15.4.3.]
(e) Now derive a similar law for the spatial evolution of the energy density of ordered
motion, 1
2ρ¯v2. Show that the energy lost by the ordered motion is compensated
for by the energy gained by the turbulent motion.
15.4.2
15.4.2 Turbulent Viscosity
Additional tools that are often introduced in the theory of weak turbulence come
from taking the analogy with the kinetic theory of gases one stage further and deﬁning
turbulenttransportcoefﬁcients,mostimportantlyaturbulentviscositythatgovernsthe
turbulent transport of momentum. These turbulent transport coefﬁcients are derived
by simple analogy with the kinetic-theory transport coefﬁcients (Sec. 3.7).
Momentum, heat, and so forth are transported most efﬁciently by the largest
turbulent eddies in the ﬂow; therefore, when estimating the transport coefﬁcients,
we replace the particle mean free path by the size ℓof the largest eddies and the mean
particle speed by the magnitude vℓof the ﬂuctuations of velocity in the largest eddies.
The result, for momentum transport, is a model turbulent viscosity:
turbulent viscosity
determined by largest
eddies
νt ≃1
3vℓℓ
(15.16)
[cf. Eq. (13.72) for molecular viscosity, with ν = η/ρ]. The Reynolds stress is then
approximated as a turbulent shear stress of the standard form:
TR ≃−2ρνt ¯σ.
(15.17)
Here ¯σ is the rate of shear tensor (13.67b) evaluated using the mean velocity ﬁeld ¯v.
Note that the turbulent kinematic viscosity deﬁned in this manner, νt, is a property of
804
Chapter 15. Turbulence

the turbulent ﬂow and not an intrinsic property of the ﬂuid; it differs from molecular
viscosity in this important respect.
We have previously encountered turbulent viscosity in our study of the physical
origin of the Sargasso Sea gyre in the north Atlantic Ocean and the gyre’s role in
generating the Gulf Stream (Ex. 14.21). The gyre is produced by water ﬂowing in
a wind-driven Ekman boundary layer at the ocean’s surface. From the measured
thickness of that boundary layer, δE ∼30 m, we deduced that the boundary layer’s
viscosity is ν ∼0.03 m2 s−1, which is 30,000 times larger than water’s molecular
viscosity; it is the turbulent viscosity of Eq. (15.16).
By considerations similar to those above for turbulent viscosity, one can deﬁne and
estimate a turbulent thermal conductivity for the spatial transport of time-averaged
turbulent thermal
conductivity and turbulent
diffusion coefﬁcient
heat (cf. Sec. 3.7.2) and a turbulent diffusion coefﬁcient for the spatial transport of one
component of a time-averaged ﬂuid through another, for example, an odor crossing
a room (cf. Ex. 3.20).
The turbulent viscosity νt and the other turbulent transport coefﬁcients can be far
larger than their kinetic-theory counterparts. Besides the Sargasso Sea gyre, another
example is air in a room subjected to typical uneven heating and cooling. The air may
circulate with an average largest eddy velocity of vℓ∼1cm s−1and an associated eddy
size of ℓ∼3 m. (The values can be estimated by observing the motion of illuminated
dust particles.) The turbulent viscosity νt and the turbulent diffusion coefﬁcient Dt
(Ex.3.20)associatedwiththesemotionsareνt ∼Dt ∼10−2 m2 s−1, somethreeorders
of magnitude larger than the molecular values.
15.4.3
15.4.3 Turbulent Wakes and Jets; Entrainment; the Coanda Effect
As instructive applications of turbulent viscosity and related issues, we now explore
in an order-of-magnitude way the structures of turbulent wakes and jets. The more
complicated extension to a turbulent boundary layer will be explored in Sec. 15.5.
In the text of this section we focus on the 2-dimensional wake behind a cylinder. In
Exs. 15.6, 15.7, and 15.8, we study the 3-dimensional wake behind a sphere and 2-
and 3-dimensional jets.
TWO-DIMENSIONAL TURBULENT WAKE: ORDER-OF-MAGNITUDE
COMPUTATION OF WIDTH AND VELOCITY DEFICIT; ENTRAINMENT
For the turbulent wake behind a cylinder at high Reynolds number (see Fig. 15.3),
we begin by deducing the turbulent viscosity νt ∼1
3vℓℓ. It is reasonable to expect
(and observations conﬁrm) that the largest eddies in a turbulent wake, at distance x
past the cylinder, extend transversely across nearly the entire width w(x) of the wake,
so their size is ℓ∼w(x). What is the largest eddies’ circulation speed vℓ? Because
these eddies’ energies are fed into smaller eddies in (roughly) one eddy turnover time,
these eddies must be continually regenerated by interaction between the wake and the
uniformﬂowatitstransverseboundaries.Thismeansthatthewake’scirculationspeed
vℓcannot be sensitive to the velocity difference V between the incoming ﬂow and the
15.4 Semiquantitative Analysis of Turbulence
805

cylinder far upstream; the wake has long since lost memory of that difference. The
only characteristic speed that inﬂuences the wake is the difference between its own
mean downstream speed ¯vx and the speed V of the uniform ﬂow at its boundaries. It
seems physically reasonable that the interaction between these two ﬂows will drive the
wake’s eddy circulation
speed and turbulent
viscosity
eddy to circulate with that difference speed, the deﬁcit uo depicted in Fig. 15.3, which
observations show to be true. Thus we have vℓ∼uo. This means that the turbulent
viscosity is νt ∼1
3vℓℓ∼1
3uo(x)w(x).
Knowing the viscosity, we can compute our two unknowns, the wake’s velocity
deﬁcit uo(x) and its width w(x), from vorticity diffusion and momentum conserva-
tion, as we did for a laminar wake in Ex. 15.1a,b.
First, consider momentum conservation. Here, as in Ex. 15.1b, the drag force per
unit length on the cylinder, FD = CD
1
2ρV 2d, must be equal to the difference between
the momentum per unit length (

ρV 2dy) in the water impinging on the cylinder and
that (

ρv2
xdy) at any chosen distance x behind the cylinder. That difference is easily
seen, from Fig. 15.3, to be ∼ρV uow. Equating this to FD, we obtain the product uow
and thence νt ∼1
3uow ∼1
6CDV d.
Thus, remarkably, theturbulentviscosityisindependentofdistancex downstream
from the cylinder. This means that the wake’s vorticity (which is contained primarily
in its large eddies) will diffuse transversely in just the manner we have encountered
several times before [Sec. 14.2.5, Eq. (14.42), and Ex. 15.1a], causing its width to grow
as w ∼

νtx/V . Inserting νt ∼1
6CDV d ∼1
3uow, we obtain
average structure of
turbulent wake
w ∼
CDd
6
x
1/2
,
uo ∼V
3CDd
2x
1/2
(15.18)
for the width and velocity deﬁcit in the turbulent wake.
In this analysis, our appeal to vorticity diffusion obscures the physical mechanism
by which the turbulent wake widens downstream. That mechanism is entrainment—
entrainment and its role in
a turbulent wake
the capture of ﬂuid from outside the wake into the wake (a phenomenon we met
for a laminar jet in Ex. 15.3d). The inertia of the largest eddies enables them to
sweep outward into the surrounding ﬂow with a transverse speed that is a sizable
fractionoftheirturnoverspeed, say, 1
6vℓ(the1/6ensuresagreementwiththediffusion
argument). This means that, moving with the ﬂow at speed V, the eddy widens by
entrainment at a rate dw/dt = V dw/dx ∼1
6vℓ∼1
6uo. Inserting uo ∼1
2V CDd/w
from momentum conservation and solving the resulting differential equation, we
obtain the same wake width w ∼

CDd x/6 as we got from our diffusion argument.
DISTRIBUTION OF VORTICITY IN THE WAKE; IRREGULARITY OF THE WAKE’S EDGE
The wake’s ﬂuid can be cleanly distinguished from the exterior, ambient ﬂuid by
vorticity: the ambient ﬂow velocity v(x, t) is vorticity free; the wake has nonzero
vorticity. If we look at the actual ﬂow velocity and refrain from averaging, the only way
a ﬂuid element in the wake can acquire vorticity is by molecular diffusion. Molecular
diffusion is so slow that the boundary between a region with vorticity and one without
806
Chapter 15. Turbulence

FIGURE 15.6 Contours of constant magnitude of vorticity |ω| in the 2-
dimensional turbulent wake between and behind a pair of cylinders. The
outer edge of the blue region is the edge of the wake. From a numerical
simulation by the research group of Sanjiva K. Lele at Stanford University,
http://ﬂowgallery.stanford.edu/research.html.
(the boundary between the wake ﬂuid and the ambient ﬂuid) is very sharp. Sharp, yes,
but straight, no! The wake’s eddies, little as well as big, drive the boundary into a very
convoluted shape (Fig. 15.6). Correspondingly, the order-of-magnitude wake width
w ∼

CDd x/6 that we have derived is only the width of a thoroughly averaged ﬂow
and is not at all the instantaneous, local width of the wake.
Intermittency is one consequence of the wake’s highly irregular edge. A ﬁxed
intermittency
location behind the cylinder that is not too close to the wake’s center will sometimes
be outside the wake and sometimes inside it. This will show up in one’s measurement
of any ﬂow variable [e.g., vy(t), ωx(t), or pressure P] at the ﬁxed location. When
outside the wake, the measured quantities will be fairly constant; when inside, they
will change rapidly and stochastically. The quiet epochs combined with interspersed
stochastic epochs are a form of intermittency.
AVERAGED ENERGY FLOW IN THE WAKE
The weak-turbulence formalism of Sec. 15.4.1 and Ex. 15.5 can be used to explore
the generation and ﬂow of turbulent energy in the 2-dimensional wake behind a
cylinder. This formalism, even when extended, is not good enough to make deﬁnitive
predictions, but it can be used to deduce the energy ﬂow from measurements of the
mean (time-averaged) ﬂow velocity ¯v, the turbulent velocity δv, and the turbulent
pressure δP . A classic example of this was carried out long ago by Townsend (1949)
and is summarized in Fig. 15.7.
15.4 Semiquantitative Analysis of Turbulence
807

0.0
0
0.1
0.2
0.3
0.4
0.5
y
—
w(x)
y
—
    xd
advection by mean flow
advection by turbulent flow
dissipation
production
FIGURE 15.7 The four terms in the rate of change of the time-averaged turbulent
energy density [Eq. (15.15)] for the 2-dimensional turbulent wake behind a
cylinder. The horizontal axis measures the distance y across the wake in units of
the wake’s mean width w(x). The vertical axis shows the numerical value of each
term. For a discussion of the four terms, see the four bulleted points in the text.
Energy conservation and stationarity of the averaged ﬂow guarantee that the sum
of the four terms vanishes at each y [Eq. (15.15)]. Adapted from Tritton (1987,
Fig. 21.8), which is based on measurements and analysis by Townsend (1949) at
Red = 1,360 and x/d > 500.
The time-averaged turbulent energy density changes due to four processes that
are graphed in that ﬁgure as a function of distance y across the wake:
averaged energy ﬂow
in a wake: production,
advection, and dissipation
.
Production. Energy in the organized bulk ﬂow (mean ﬂow) ¯v is converted
into turbulent energy by the interaction of the mean ﬂow’s shear with the
turbulence’s Reynolds stress, at a rate per unit volume of T ij
R ¯vi;j. This pro-
duction vanishes at the wake’s center (y = 0), because the shear of the mean
ﬂow vanishes there; it also vanishes at the edge of the wake, because both the
mean-ﬂow shear and the Reynolds stress go to zero there.
.
Advection by mean ﬂow. Once produced, the turbulent energy is advected
across the wake by the mean ﬂow. This causes an increase in turbulent energy
density in the center of the wake and a decrease in the wake’s outer parts at
the rate ∇. ( 1
2ρδv2¯v) = (¯v . ∇)( 1
2ρδv2).
808
Chapter 15. Turbulence

FIGURE 15.8 The Coanda effect. A turbulent jet emerging from an oriﬁce in the left
wall is attracted to the solid bottom wall.
.
Advection by turbulent ﬂow. The turbulent energy also is advected by the
turbulent part of the ﬂow, causing a decrease of turbulent energy density in
the central regions of the wake and an increase in the outer regions at the
rate ∇. ( 1
2ρδv2δv + δP δv).
.
Dissipation.The turbulent energy is converted to heat by molecular viscosity
at a rate per unit volume given by −νρδv . (∇2δv). This dissipation is largest
at the wake’s center and falls off gradually toward the wake’s averaged edge.
Energy conservation plus stationarity of the averaged ﬂow guarantees that the sum of
these four terms vanishes at all locations in the wake (all y of Fig. 15.7). This is the
physical content of Eq. (15.15) and is conﬁrmed in Fig. 15.7 by the experimental data.
ENTRAINMENT AND COANDA EFFECT
Notice how much wider the (averaged) turbulent wake is than the corresponding lam-
inar wake of Ex. 15.1. The ratio of their widths [Eqs. (15.18) and (15.8)] is wt/wl ∼

CDV d/ν. For CD ∼1 in the turbulent wake, V ∼1 m s−1, d ∼1 m, and water’s
strong entrainment in
turbulent jets and wakes
kinematic viscosity ν ∼10−6 m2 s−1, the ratio is wt/wl ∼103, independent of dis-
tance x downstream. In this sense, entrainment in the turbulent wake is a thousand
times stronger than entrainment in the laminar wake. Turbulent wakes and jets have
voracious appetites for ambient ﬂuid!
Entrainment is central to the Coanda effect, depicted in Fig. 15.8. Consider a
turbulentﬂow(e.g., thejetofFig.15.8)thatiswideningbyentrainmentofsurrounding
ﬂuid. The jet normally widens downstream by pulling surrounding ﬂuid into itself,
and the inﬂow toward the jet extends far beyond the jet’s boundaries (see, e.g., Ex.
15.3d). However, when a solid wall is nearby, so there is no source for inﬂowing
ambient ﬂuid, the jet’s entrainment causes a drop in the pressure of the ambient ﬂuid
nearthewall.Theresultingpressuregradientpushesthejettowardthewallasdepicted
in Fig. 15.8.
15.4 Semiquantitative Analysis of Turbulence
809

Similarly, if a turbulent ﬂow is already close to a wall and the wall begins to curve
away from the ﬂow, the ﬂow develops a pressure gradient that tends to keep the
turbulent region attached to the wall. In other words, turbulent ﬂows are attracted
Coanda effect
to solid surfaces and tend to stick to them. This is the Coanda effect.
The Coanda effect also occurs for laminar ﬂows, but because entrainment is
typically orders of magnitude weaker in laminar ﬂows than in turbulent ones, the
effect is also orders of magnitude weaker.
The Coanda effect is important in aeronautics; for example, it is exploited to
prevent the separation of the boundary layer from the upper surface of a wing, thereby
improving the wing’s lift and reducing its drag, as we discuss in Sec. 15.5.2.
EXERCISES
Exercise 15.6 Problem: Turbulent Wake behind a Sphere
Compute the width w(x) and velocity deﬁcit uo(x) for the 3-dimensional turbulent
wake behind a sphere.
Exercise 15.7 Problem: Turbulent Jets in 2 and 3 Dimensions
Consider a 2-dimensional turbulent jet emerging into an ambient ﬂuid at rest, and
contrast it to the laminar jet analyzed in Ex. 15.3.
(a) Find how the mean jet velocity and the jet width scale with distance downstream
from the nozzle.
(b) Repeat the exercise for a 3-dimensional jet.
Exercise 15.8 Problem: Entrainment and Coanda Effect in a 3-Dimensional Jet
(a) Evaluate the scaling of the rate of mass ﬂow (discharge)
˙M(x) along the 3-
dimensional turbulent jet of the previous exercise. Show that ˙M increases with
distance from the nozzle, so that mass must be entrained in the ﬂow and become
turbulent.
(b) Compare the entrainment rate for a turbulent jet with that for a laminar jet
(Ex. 15.3). Do you expect the Coanda effect to be stronger for a turbulent or a
laminar jet?
15.4.4
15.4.4 Kolmogorov Spectrum for Fully Developed, Homogeneous,
Isotropic Turbulence
When a ﬂuid exhibits turbulence over a large volume that is well removed from any
solid bodies, there will be no preferred directions and no substantial gradients in the
statistically averaged properties of the turbulent velocity ﬁeld. This suggests that the
statistical properties of the turbulence will be stationary and isotropic. We derive a
semiquantitative description of some of these statistical properties, proceeding in two
steps:ﬁrstweanalyzetheturbulence’svelocityﬁeldandthentheturbulentdistribution
of quantities that are transported by the ﬂuid.
810
Chapter 15. Turbulence

TURBULENT VELOCITY FIELD
Our analysis will be based on the following simple physical model. We idealize the
physical model underlying
Kolmogorov spectrum
for turbulence: cascading
eddies
turbulent velocity ﬁeld as made of a set of large eddies, each of which contains a set
of smaller eddies, and so on. We suppose that each eddy splits into eddies roughly
half its size after a few turnover times. This process can be described mathematically
as nonlinear or triple velocity correlation terms [terms like the second one in Eq.
(15.15)] producing, in the law of energy conservation, an energy transfer (a “cascade”
of energy) from larger eddies to smaller ones. Now, for large enough eddies, we can
ignore the effects of molecular viscosity in the ﬂow. However, for sufﬁciently small
eddies, viscous dissipation will convert the eddy bulk kinetic energy into heat. This
simple model enables us to derive a remarkably successful formula (the Kolmogorov
spectrum) for the distribution of turbulent energy over eddy size.
We must ﬁrst introduce and deﬁne the turbulent energy per unit wave number and
per unit mass, uk(k). For this purpose, we focus on a volume V much larger than the
largest eddies. At some moment of time t, we compute the spatial Fourier transform
of the ﬂuctuating part of the velocity ﬁeld δv(x), conﬁned to this volume [with δv(x)
set to zero outside V], and also write down the inverse Fourier transform:
δ˜v(k) =

V
d3x δv(x)e−ik.x,
δv =

d3k
(2π)3δ˜veik.x
inside V.
(15.19)
The total energy per unit mass u in the turbulence, averaged over the box V, is then
u =
 d3x
V
1
2|δv|2 =

d3k
(2π)3
|δ˜v|2
2V ≡
 ∞
0
dk uk(k),
(15.20)
where we have used Parseval’s theorem in the second equality, we have used d3k =
4πk2dk, and we have deﬁned
spectral energy per unit
mass in turbulence
uk(k) ≡|δ˜v|2k2
4π2V .
(15.21)
Here the bars denote a time average, k is the magnitude of the wave vector: k ≡
|k| (i.e., it is the wave number or equivalently 2π divided by the wavelength), and
uk(k) is called the spectral energy per unit mass of the turbulent velocity ﬁeld δv. In
the third equality in Eq. (15.20), we have assumed that the turbulence is isotropic,
so the integrand depends only on wave number k and not on the direction of k.
Correspondingly, we have deﬁned uk(k) as the energy per unit wave number rather
than an energy per unit volume of k-space. This means that uk(k)dk is the average
kinetic energy per unit mass associated with modes that have k lying in the interval
dk; we treat k as positive.
In Chap. 6, we introduced the concepts of a random process and its spectral den-
sity. The Cartesian components of the ﬂuctuating velocity δvx, δvy, and δvz obviously
are random processes that depend on vectorial location in space x rather than on time
15.4 Semiquantitative Analysis of Turbulence
811

as in Chap. 6. It is straightforward to show that their double-sided spectral densities
are related to uk(k) by
spectral densities of
velocity ﬁeld
Svx(k) = Svy(k) = Svz(k) = (2π)2
3k2
× uk(k).
(15.22)
If we fold negative kx into positive, and similarly for ky and kz, so as to get the kind of
single-sided spectral density (Sec. 6.4.2) that we used in Chap. 6, then these spectral
densities should be multiplied by 23 = 8.
We now use our physical model of turbulence to derive an expression for uk(k).
Denote by kmin = 2π/ℓthe wave number of the largest eddies, and by kmax that of the
smallest ones (those in which viscosity dissipates the cascading, turbulent energy).
Our derivation will be valid (and the result valid) only when kmax/kmin ≫1: only
when there is a long sequence of eddies from the largest to half the largest to a quarter
the largest and so forth down to the smallest.
As a tool in computing uk(k), we introduce the root-mean-square turbulent
turnover speed of the eddies with wave number k: v(k) ≡v. Ignoring factors of
eddy turnover speed and
time
order unity, we treat the size of these eddies as k−1. Then their turnover time is
τ(k) ∼k−1/v(k) = 1/[kv(k)]. Our model presumes that in this same time τ (to within
a factor of order unity), each eddy of size k−1 splits into eddies of half this size (i.e.,
the turbulent energy cascades from k to 2k). In other words, our model presumes the
turbulence is strong. Since the energy cascade is presumed stationary (i.e., no energy
is accumulating at any wave number), the energy per unit mass that cascades in a
unit time from k to 2k must be independent of k. Denote by q that k-independent,
cascading energy per unit mass per unit time. Since the energy per unit mass in the
eddies of size k−1 is v2 (aside from a factor 2, which we neglect), and the cascade time
is τ ∼1/(kv), then q ∼v2/τ ∼v3k. This tells us that the rms turbulent velocity is
v(k) ∼(q/k)1/3.
(15.23)
Ourmodellumpstogetheralleddieswithwavenumbersinarange k ∼k around
k and treats them all as having wave number k. The total energy per unit mass in these
eddies is uk(k)k ∼kuk(k) when expressed in terms of the sophisticated quantity
uk(k); it is ∼v(k)2 when expressed in terms of our simple model. Thus our model
predicts that uk(k) ∼v(k)2/k, which by Eqs. (15.23) and (15.22) implies
Kolmogorov spectrum
for stationary, isotropic,
incompressible turbulence
uk(k) ∼q2/3k−5/3,
Svj(k) ∼q2/3k−11/3
for kmin ≪k ≪kmax;
(15.24)
see Fig. 15.9. This is the Kolmogorov spectrum for the spectral energy density of
stationary, isotropic, incompressible turbulence. It is valid only in the range kmin ≪
k ≪kmax, because only in this range are the turbulent eddies continuously receiving
energy from larger lengthscales and passing it on to smaller scales. At the ends of
the range, the spectrum has to be modiﬁed in the manner illustrated qualitatively in
Fig. 15.9.
812
Chapter 15. Turbulence

log uk(k)
kmin
~Re–3/4 kmax
kmax
~q–1/4 v–3/4
uk ~ q2/3 k–5/3
log k
FIGURE 15.9 The Kolmogorov spectral energy per unit mass for
stationary, homogeneous turbulence.
At the smallest lengthscales present, k−1
max, the molecular viscous forces become
competitive with inertial forces in the Navier-Stokes equation; these viscous forces
convert the cascading energy into heat. Since the ratio of inertial forces to viscous
forces is the Reynolds number, the smallest eddies have a Reynolds number of order
unity: Rekmax = v(kmax)k−1
max/ν ∼1. Inserting Eq. (15.23) for v(k), we obtain
kmax ∼q1/4ν−3/4.
(15.25)
The largest eddies have sizes ℓ∼k−1
min and turnover speeds vℓ= v(kmin) ∼
(q/kmin)1/3. By combining these relations with Eq. (15.25), we see that the ratio of
the largest wave numbers present in the turbulence to the smallest is
range of wave numbers in
turbulence
kmax
kmin
∼
vℓℓ
ν
3/4
= Re3/4
ℓ.
(15.26)
Here Reℓis the Reynolds number for the ﬂow’s largest eddies.
Let us now take stock of our results. If we know the scale ℓof the largest eddies
and their rms turnover speeds vℓ(and, of course, the viscosity of the ﬂuid), then we
can compute their Reynolds number Reℓ; from that, Eq. (15.26), and kmin ∼ℓ−1,
we can compute the ﬂow’s maximum and minimum wave numbers; and from
q ∼v3
ℓ/ℓand Eq. (15.24), we can compute the spectral energy per unit mass in the
turbulence.
We can also compute the total time required for energy to cascade from the
largest eddies to the smallest. Since τ(k) ∼1/(kv) ∼1/(q1/3k2/3), each successive set
of eddies feeds its energy downward in a time 2−2/3 shorter than the preceding set
did. As a result, it takes roughly the same amount of time for energy to pass from
the second-largest eddies (size ℓ/2) to the very smallest (size k−1
max) as it takes for the
second-largest to extract the energy from the very largest. The total cascade occurs
in a time of several ℓ/vℓ(during which time, of course, the mean ﬂow has fed new
energy into the largest eddies and they are sending it downward).
15.4 Semiquantitative Analysis of Turbulence
813

These results are accurate only to within factors of order unity—with one major
exception. The −5/3 power law in the Kolmogorov spectrum is very accurate. That
this ought to be so one can verify in two equivalent ways: (i) Repeat the above
derivation inserting arbitrary factors of order unity at every step. These factors will
inﬂuence the ﬁnal multiplicative factor in the Kolmogorov spectrum but will not
inﬂuence the −5/3 power. (ii) Use dimensional analysis. Speciﬁcally, notice that the
only dimensional entities that can inﬂuence the spectrum in the region kmin ≪k ≪
kmax are the energy cascade rate q and the wave number k. Then notice that the only
quantity with the dimensions of uk(k) (energy per unit mass per unit wave number)
that can be constructed from q and k is q2/3k−5/3. Thus, aside from a multiplicative
factor of order unity, this must be the form of uk(k).
phenomena missed by
Kolmogorov spectrum
Let us now review and critique the assumptions that went into our derivation
of the Kolmogorov spectrum. First, we assumed that the turbulence is stationary
and homogeneous. Real turbulence is neither of these, since it exhibits intermittency
intermittency
(Sec. 15.3), and smaller eddies tend to occupy less volume overall than do larger
eddies and so cannot be uniformly distributed in space. Second, we assumed that
the energy source is large-lengthscale motion and that the energy transport is local
in k-space from the large lengthscales to steadily smaller ones. In the language of
a Fourier decomposition into normal modes, we assumed that nonlinear coupling
between modes with wave number k causes modes with wave number of order 2k to
grow but does not signiﬁcantly enhance modes with wave number 100k or 0.01k.
Again this behavior is not completely in accord with observations, which reveal
the development of coherent structures—large-scale regions with correlated vorticity
coherent structures, ﬂow
of energy from small scales
to large, and entrainment
in the ﬂow. These structures are evidence for a reversed ﬂow of energy in k-space
from small scales to large ones, and they play a major role in another feature of real
turbulence, entrainment—the spreading of an organized motion (e.g., a jet) into the
surrounding ﬂuid (Sec. 15.4.3).
Despite these issues with its derivation, the Kolmogorov law is surprisingly accu-
rate and useful. It has been veriﬁed in many laboratory ﬂows, and it describes many
naturally occurring instances of turbulence. For example, the twinkling of starlight is
caused by refractive index ﬂuctuations in Earth’s atmosphere, whose power spectrum
we can determine optically. The underlying turbulence spectrum turns out to be of
Kolmogorov form; see Box 9.2.
KOLMOGOROV SPECTRUM FOR QUANTITIES TRANSPORTED BY THE FLUID
In applications of the Kolmogorov spectrum, including twinkling starlight, one often
must deal with such quantities as the index of refraction n that, in the turbulent cas-
cade, are transported passively with the ﬂuid, so that dn/dt = 0.9 As the cascade
9.
In Earth’s atmospheric turbulence, n is primarily a function of the concentration of water molecules and
the air density, which is controlled by temperature via thermal expansion and contraction. Both water
concentration and temperature are carried along by the ﬂuid in the turbulent cascade, whence so is n.
814
Chapter 15. Turbulence

strings out and distorts ﬂuid elements, it will also stretch and distort any inhomo-
geneities of n, driving them toward smaller lengthscales (larger k).
What is the k-dependence of the resulting spectral density Sn(k)? The quickest
route to an answer is dimensional analysis. This Sn can be inﬂuenced only by the
quantities that characterize the velocity ﬁeld (its wave number k and its turbulent-
energy cascade rate q) plus a third quantity: the rate qn = dσ 2n/dt at which the
variance σ 2n =

Sn d3k/(2π)3 of n would die out if the forces driving the turbulence
were turned off. (This qn is the analog, for n, of q for velocity.) The only combination
of k, q, and qn that has the same dimensions as Sn is (Ex. 15.9)
Kolmogorov spectrum for
quantities transported
with the ﬂuid in its
turbulent cascade
Sn ∼qnq−1/3k−11/3.
(15.27)
This is the same −11/3 power law as for Svj [Eq. (15.24)], and it will hold true also for
any other quantity  that is transported with the ﬂuid (d/dt = 0) in the turbulent
cascade.
As for the velocity’s inhomogeneities, so also for the inhomogeneities of n, there is
some small lengthscale, 1/kn max, at which diffusion wipes them out, terminating the
cascade. Because n is a function of temperature and water concentration, the relevant
diffusion is a combination of thermal diffusion and water-molecule diffusion, which
will proceed at a (perhaps modestly) different rate from the viscous diffusion for
velocity inhomogeneities. Therefore, the maximum k in the cascade may be different
for the index of refraction (and for any other quantity transported by the ﬂuid) than
for the velocity.
In applications, one often needs a spatial description of the turbulent spectrum
rather than a wave-number description. This is normally given by the Fourier trans-
form of the spectral density, which is the correlation function Cn(ξ) = ⟨δn(x)δn(x +
ξ)⟩(where δn is the perturbation away from the mean and ⟨.⟩is the ensemble average
or average over space); see Sec. 6.4. For turbulence, the correlation function has the
unfortunate property that Cn(0) = ⟨δn2⟩≡σ 2n is the variance, which is dominated by
the largest lengthscales, where the Kolmogorov power-law spectrum breaks down. To
avoid this problem it is convenient, when working with turbulence, to use in place of
the correlation function the so-called structure function:
structure function for
spatial structure of
turbulence
Dn(ξ) = ⟨[δn(x + ξ) −δn(x)]2⟩= 2[σ 2n −Cn(ξ)].
(15.28)
By Fourier transforming the spectral density (15.27), or more quickly by dimensional
analysis, one can infer the Kolmogorov spectrum for this structure function:
Dn(ξ) ∼(qn/q1/3)ξ2/3
for
k−1
max <∼ξ <∼k−1
min.
(15.29)
In Box 9.2, we use this version of the spectrum to analyze the twinkling of starlight
due to atmospheric turbulence.
15.4 Semiquantitative Analysis of Turbulence
815

EXERCISES
Exercise 15.9 Derivation and Practice: Kolmogorov Spectrum
for Quantities Transported by the Fluid
(a) Fill in the details of the dimensional-analysis derivation of the Kolmogorov spec-
trum (15.27) for a quantity such as n that is transported by the ﬂuid and thus
satisﬁes dn/dt = 0. In particular, convince yourself (or refute!) that the only
quantities Sn can depend on are k, q, and qn, identify their dimensions and the
dimension of Sn, and use those dimensions to deduce Eq. (15.27).
(b) Derive the spatial version (15.29) of the Kolmogorov spectrum for a transported
quantity by two methods: (i) Fourier transforming the wave-number version
(15.27), and (ii) dimensional analysis.
Exercise 15.10 Example: Excitation of Earth’s Normal Modes
by Atmospheric Turbulence10
Earthhasnormalmodesofoscillation, manyofwhichareinthemilli-Hertzfrequency
range. Large earthquakes occasionally excite these modes strongly, but the quakes are
usually widely spaced in time compared to the ringdown time of a particular mode
(typically a few days). There is evidence of a background level of continuous excitation
of these modes, with an rms ground acceleration per mode of ∼10−10 cm s−2 at
seismically “quiet” times. The excitation mechanism is suspected to be stochastic
forcing by the pressure ﬂuctuations associated with atmospheric turbulence. This
exercise deals with some aspects of this hypothesis.
(a) Estimate the rms pressure ﬂuctuations P (f ) at frequencyf , in a bandwidth equal
to frequency f = f , produced on Earth’s surface by atmospheric turbulence,
assuming a Kolmogorov spectrum for the turbulent velocities and energy. Make
your estimate using two methods: (i) using dimensional analysis (what quantity
can you construct from the energy cascade rate q, atmospheric density ρ, and fre-
quency f that has dimensions of pressure?) and (ii) using the kinds of arguments
about eddy sizes and speeds developed in Sec. 15.4.4.
(b) Your answer using method (i) in part (a) should scale with frequency as P (f ) ∝
1/f .Inactuality, themeasuredpressurespectrahaveascalinglawmorenearlylike
P(f ) ∝1/f 2/3, not P (f ) ∝1/f (e.g., Tanimoto and Um, 1999, Fig. 2a). Explain
this discrepancy [i.e., what is wrong with the argument in method (i) and how
can you correct it to give P (f ) ∝1/f 2/3?].
(c) The low-frequency cutoff for the P (f ) ∝1/f 2/3 pressure spectrum is about
0.5 mHz, and at 1 mHz, P (f ) has the value P (f = 1 mHz) ∼0.3 Pa, which is
10. Problem devised by David Stevenson, based in part on Tanimoto and Um (1999), who, however, used
the pressure spectrum deduced in method (i) of part (a) rather than the more nearly correct spectrum
of part (b). The difference in spectra does not much affect their conclusions.
816
Chapter 15. Turbulence

about 3 × 10−6 of atmospheric pressure. Assuming that 0.5 mHz corresponds to
the largest eddies, which have a lengthscale of a few kilometers (a little less than
the scale height of the atmosphere), derive an estimate for the eddies’ turbulent
viscosity νt in the lower atmosphere. By how many orders of magnitude does
this exceed the molecular viscosity? What fraction of the Sun’s energy input to
Earth (∼106 erg cm−2 s−1) goes into maintaining this turbulence (assumed to be
distributed over the lowermost 10 km of the atmosphere)?
(d) At f = 1mHz, what is the characteristic spatial scale (wavelength) of the relevant
normal modes of Earth? [Hint: The relevant modes have few or no nodes in the
radial direction. All you need to answer this question is a typical wave speed for
seismicshearwaves, whichyoucantaketobe5 km s−1.]Whatisthecharacteristic
spatial scale (eddy size) of the atmospheric pressure ﬂuctuations at this same
frequency, assuming isotropic turbulence? Suggest a plausible estimate for the
rms amplitude of the pressure ﬂuctuation averaged over a surface area equal to
one square wavelength of Earth’s normal modes. (You must keep in mind the
random spatially and temporally ﬂuctuating character of the turbulence.)
(e) Challenge: Using your answer from part (d) and a characteristic shear and bulk
modulus for Earth’s deformations of K ∼μ ∼1012 dyne cm−2, comment on how
the observed rms normal-mode acceleration (10−10 cm s−2) compares with that
expected from stochastic forcing due to atmospheric turbulence. You may need
to review Chaps. 11 and 12, and think about the relationship between surface
force and surface deformation. [Note: Several issues emerge when doing this
assessment accurately that have not been dealt with in this exercise (e.g., number
of modes in a given frequency range), so don’t expect to be able to get an answer
more accurate than an order of magnitude.]
15.5
15.5 Turbulent Boundary Layers
Great interest surrounds the projection of spheres of cork, rubber, leather, and string
by various parts of the human anatomy, with and without the mechanical advantage
of levers of willow, ceramic, and the ﬁnest Kentucky ash. As is well known, changing
the surface texture, orientation, and spin of a sphere in various sports can inﬂuence
its trajectory markedly. Much study has been made of ways to do this both legally
and illegally. Some procedures used by professional athletes are pure superstition, but
many others ﬁnd physical explanations that are good examples of the behavior of
boundary layers. Many sports involve the motion of balls at Reynolds numbers where
the boundary layers can transition between laminar and turbulent, which allows
opportunities for controlling the ﬂow. With the goal of studying this transition, let
us now consider the structure of a turbulent boundary layer—ﬁrst along a straight
wall and later along a ball’s surface.
15.5 Turbulent Boundary Layers
817

15.5.1
15.5.1 Proﬁle of a Turbulent Boundary Layer
In Sec. 14.4.1, we derived the Blasius proﬁle for a laminar boundary layer and showed
that its thickness a distance x downstream from the start of the boundary layer was
roughly 3δ = 3(νx/V )1/2, where V is the free-stream speed (cf. Fig. 14.13). As we
have described, when the Reynolds number is large enough—Red = V d/ν ∼3 × 105
or Reδ ∼√Red ∼500 in the case of ﬂow past a cylinder (Figs. 15.1 and 15.2)—the
boundary layer becomes turbulent.
turbulent boundary layer’s
laminar sublayer and
turbulent zone
A turbulent boundary layer consists of a thin laminar sublayer of thicknessδls close
to the wall and a much thicker turbulent zone of thickness δt (Fig. 15.10).
In the following paragraphs we use the turbulence concepts developed in the
previous sections to compute the order of magnitude of the structures of the laminar
sublayer and the turbulent zone, and the manner in which those structures evolve
along the boundary. We let the wall have any shape, so long as its radius of curvature
is large compared to the boundary layer’s thickness, so it looks locally planar. We
also use locally Cartesian coordinates with distance y measured perpendicular to the
boundary and distance x along it, in the direction of the near-wall ﬂow.
One key to the structure of the boundary layer is that, in the x component of
the time-averaged Navier-Stokes equation, the stress-divergence term Txy,y has the
potential to be so large (because of the boundary layer’s small thickness) that no other
term can compensate for it. This is true in the turbulent zone, where Txy is the huge
Reynolds stress; it is also true in the laminar sublayer, where Txy is the huge viscous
stress produced by a large shear that results from the thinness of the layer. (One can
check at the end of the following analysis that, for the computed boundary-layer
structure, other terms in the x component of the Navier-Stokes equation are indeed
so small that they could not compensate a signiﬁcantly nonzero Txy,y.) This potential
dominance by Txy,y implies that the ﬂow must adjust itself to make Txy,y nearly zero,
so Txy must be (very nearly) independent of distance y from the boundary.
v–x
δls
δls
V
y
y
x
laminar
(b)
(a)
turbulent
δt
laminar sublayer
FIGURE 15.10 (a) Physical structure of a turbulent boundary layer. (b) Mean ﬂow speed ¯vx as a
function of distance from the wall for the turbulent boundary layer [solid curve, Eqs. (15.30)]
and for a laminar boundary layer [dashed curve; the Blasius proﬁle, Eqs. (14.46)].
818
Chapter 15. Turbulence

In the turbulent zone, Txy is the Reynolds stress, ρv2
ℓ, where vℓis the turbulent
velocity of the largest eddies at a distance y from the wall; therefore, constancy of Txy
implies constancy of vℓ. The largest eddies at y have a size ℓof order the distance
y from the wall; correspondingly, the turbulent viscosity is νt ∼vℓy/3. Equating
the expression ρv2
ℓfor the Reynolds stress to the alternative expression 2ρνt
1
2 ¯v,y
(where ¯v is the mean-ﬂow speed at y, and 1
2 ¯v,y is the shear), and using νt ∼vℓy/3 for
the turbulent viscosity, we discover that in the turbulent zone the mean ﬂow speed
varies logarithmically with distance from the wall: ¯v ∼vℓln y + constant. Since the
turbulence is created at the inner edge of the turbulent zone, y ∼δls (Fig. 15.10) by
interaction of the mean ﬂow with the laminar sublayer, the largest turbulent eddies
there must have their turnover speeds vℓequal to the mean-ﬂow speed there: ¯v ∼vℓ
at y ∼δls. This tells us the normalization of the logarithmically varying mean-ﬂow
speed:
proﬁle of mean ﬂow speed
in turbulent zone
¯v ∼vℓ[1 + ln(y/δls)]
at y >∼δls.
(15.30a)
Turn next to the structure of the laminar sublayer. There the constant shear stress
is viscous, Txy = ρν ¯v,y. Stress balance at the interface between the laminar sublayer
and the turbulent zone requires that this viscous stress be equal to the turbulent zone’s
ρv2
ℓ. This equality implies a linear proﬁle for the mean-ﬂow speed in the laminar
sublayer, ¯v = (v2
ℓ/ν)y. The thickness of the sublayer is then ﬁxed by continuity of ¯v
at its outer edge: (v2
ℓ/ν)δls = vℓ. Combining these last two relations, we obtain the
following proﬁle and laminar-sublayer thickness:
mean ﬂow velocity in
laminar sublayer
¯v ∼vℓ
 y
δls

at y <∼δls ∼ν/vℓ.
(15.30b)
Havingdeducedtheinternalstructureoftheboundarylayer, weturntotheissueof
what determines the y-independent turbulent velocity vℓof the largest eddies. This
vℓis ﬁxed by matching the turbulent zone to the free-streaming region outside it.
The free-stream velocity V (which may vary slowly with x due to curvature of the
wall) must be equal to the mean ﬂow velocity ¯v [Eq. (15.30a)] at the outer edge of the
turbulent zone. The logarithmic term dominates, so V = vℓln(δt/δls). Introducing an
overall Reynolds number for the boundary layer,
Reδ ≡V δt/ν,
(15.31)
andnotingthatturbulencerequiresahugevalue(>∼1,000)ofthisReδ, wecanreexpress
V as V ∼vℓln Reδ. This should actually be regarded as an equation for the turbulent
velocity of the largest-scale eddies in terms of the free-stream velocity:
turbulent velocity of
largest-scale eddies in
turbulent zone
vℓ∼
V
ln Reδ
.
(15.32)
15.5 Turbulent Boundary Layers
819

If the free-stream velocity V (x) and the thickness δt + δls ≃δt of the entire bound-
ary layer are given, then Eq. (15.31) determines the boundary layer’s Reynolds num-
ber, Eq. (15.32) then determines the turbulent velocity, and Eqs. (15.30) determine
the layer’s internal structure.
Finally, we turn to the issue of how the boundary layer thickness δt evolves with
distance x down the wall (and, correspondingly, how the rest of the boundary layer’s
structure, which is ﬁxed by δt, evolves). The key to the evolution of δt is entrainment,
which we met in our discussion of turbulent wakes and jets (Sec. 15.4.3). At the
turbulent zone’s outer edge, the largest turbulent eddies move with speed ∼vℓinto
the free-streaming ﬂuid, entraining that ﬂuid into themselves. Correspondingly, the
thickness grows at a rate
thickness of turbulent
boundary layer
dδt
dx ∼vℓ
V ∼
1
ln Reδ
.
(15.33)
Since ln Reδ depends only extremely weakly on δt, the turbulent boundary layer
expands essentially linearly with distance x, by contrast with a laminar boundary
layer’s δ ∝x1/2.
15.5.2
15.5.2 Coanda Effect and Separation in a Turbulent Boundary Layer
One can easily verify that not only does the turbulent boundary layer expand more
rapidly than the corresponding laminar boundary layer would (if it were stable) but
also that the turbulent layer is thicker at all locations down the wall. Physically, this
distinction can be traced, in part, to the fact that the turbulent boundary layer involves
a3-dimensionalvelocityﬁeld, whereasthecorrespondinglaminarlayerwouldinvolve
only a 2-dimensional ﬁeld. The enhanced thickness and expansion contribute to the
Coanda effect for a turbulent boundary layer—the layer’s ability to stick to the wall
under adverse conditions (Sec. 15.4.3).
However, there is a price to be paid for this beneﬁt. Since the velocity gra-
dient is increased near the surface, the actual surface shear stress exerted by the
turbulent layer, through its laminar sublayer, is signiﬁcantly larger than in the cor-
responding laminar boundary layer. As a result, if the entire boundary layer were to
remain laminar, the portion that would adhere to the surface would produce less
viscous drag than the near-wall laminar sublayer of the turbulent boundary layer.
Correspondingly, in a long, straight pipe, the drag on the pipe wall goes up when the
boundary layer becomes turbulent.
inﬂuence of turbulence on
separation of boundary
layer and thence on drag
However, for ﬂow around a cylinder or other conﬁned body, the drag goes down!
(Cf. Fig. 15.2.) The reason is that in the separated, laminar boundary layer the dom-
inant source of drag is not viscosity but rather a pressure differential between the
front face of the cylinder (where the layer adheres) and the back face (where the re-
verse eddies circulate). The pressure is much lower in the back-face eddies than in the
front-face boundary layer, and that pressure differential gives rise to a signiﬁcant drag,
which is reduced when the boundary layer goes turbulent and adheres to the back
820
Chapter 15. Turbulence

v
v
v
v
(b)
(a)
surface of separation
surface of separation
vortex generators
FIGURE 15.11 (a) A laminar boundary layer separating from an airplane wing due to an adverse
pressure gradient in the wing’s back side. (b) Vortex generators attached to the wing’s top face
generate turbulence. The turbulent boundary layer sticks to the wing more effectively than does the
laminar boundary layer (the Coanda effect). Separation from the wing is delayed, and the wing’s lift
is increased and drag is decreased.
face. Therefore, if one’s goal is to reduce the overall drag and the laminar ﬂow is prone
to separation, a nonseparating (or delayed-separation) turbulent layer is preferred to
the laminar layer. Similarly (and for essentially the same reason), for an airplane wing,
if one’s goal is to maintain a large lift, then a nonseparating (or delayed-separation)
turbulent layer is superior to a separating, laminar one.11
For this reason, steps are often taken in engineering ﬂows to ensure that boundary
layers become and remain turbulent. A crude but effective example is provided by
the vortex generators that are installed on the upper surfaces of some airplane wings
vortex generators on
airplane wings
(Fig. 15.11). These structures are small obstacles on the wing that penetrate through a
laminar boundary layer into the free ﬂow. By changing the pressure distribution, they
force air into the boundary layer and initiate 3-dimensional vortical motion in the
boundary layer, forcing it to become partially turbulent. This turbulence improves the
11. Another example of separation occurs in “lee waves,” which can form when wind blows over a mountain
range. These consist of standing-wave eddies in the separated boundary layer, somewhat analogous to
the K´arm´an vortex street of Fig. 15.1d. Lee waves are sometimes used by glider pilots to regain altitude.
15.5 Turbulent Boundary Layers
821

wing’slift, itallowstheairplanetoclimbmoresteeplywithoutstallingfromboundary-
layer separation, and it helps reduce aerodynamical drag.
15.5.3
15.5.3 Instability of a Laminar Boundary Layer
Much work has been done on the linear stability of laminar boundary layers. The
principles of such stability analyses should now be familiar, although the technical
details are formidable. In the simplest case, an equilibrium ﬂow is identiﬁed (e.g., the
Blasiusproﬁle), andtheequationsgoverningthetimeevolutionofsmallperturbations
are written down. The individual Fourier components are assumed to vary in space
and time as exp i(k . x −ωt), and we seek modes that have zero velocity perturbation
on the solid surface past which the ﬂuid ﬂows and that decay to zero in the free
stream. We ask whether there are unstable modes (i.e., modes with real k for which the
imaginary part of ω is positive, so they grow exponentially in time). Such exponential
growth drives the perturbation to become nonlinear, which then typically triggers
turbulence.
The results can generally be expressed in the form of a diagram like that in
Fig. 15.12. As shown in that ﬁgure, there is generally a critical Reynolds number
Recrit ∼500 at which one mode becomes linearly unstable. At higher values of the
Reynolds number, modes with a range of k-vectors are linearly unstable. One inter-
esting result of these calculations is that in the absence of viscous forces (i.e., in the
limit Reδ →∞), the boundary layer is unstable if and only if there is a point of inﬂec-
tion in the velocity proﬁle (a point where d2vx/dy2 changes sign; cf. Fig. 15.12 and
Ex. 15.11).
dynamically stable and
unstable modes in laminar
boundary layer
stable
stable
Im (ω) ≤ 0
Recrit ~ 500
Reδ
kδ
Im (ω) ≤ 0
with inflection
Im (ω) > 0
unstable
no
inflection
FIGURE 15.12 Values of wave number k for stable and unstable wave modes in a laminar
boundary layer with thickness δ, as a function of the boundary layer’s Reynolds number
Reδ = V δ/ν. If the unperturbed velocity distribution vx(y) has no inﬂection point (i.e.,
if d2vx/dy2 < 0 everywhere, as is the case for the Blasius proﬁle; Fig. 14.13), then the
unstable modes are conﬁned to the shaded region. If there is an inﬂection point (so
d2vx/dy2 is positive near the wall but becomes negative farther from the wall, as is the
case near a surface of separation; Fig. 14.14), then the unstable region is larger (dashed
boundary) and does not asymptote to k = 0 as Reδ →∞.
822
Chapter 15. Turbulence

Although, in the absence of an inﬂection, an inviscid ﬂow vx(y) is stable, for
secular instabilities
contrasted with dynamical
instabilities
some such proﬁles even the slightest viscosity can trigger instability. Physically, this is
because viscosity can tap the relative kinetic energies of adjacent ﬂow lines. Viscous-
triggered instabilities of this sort are sometimes called secular instabilities by contrast
with the dynamical instabilities that arise in the absence of viscosity. Secular instabil-
ities are quite common in ﬂuid mechanics.
EXERCISES
Exercise 15.11 Problem: Tollmien-Schlichting Waves
Consider an inviscid (ν = 0), incompressible ﬂow near a plane wall where a laminar
boundary layer is established. Introduce coordinates x parallel to the wall and y
perpendicular to it. Let the components of the equilibrium velocity be vx(y).
(a) Show that a weak propagating-wave perturbation in the velocity, δvy ∝
exp ik(x −Ct), with k real and frequency Ck possibly complex, satisﬁes the
differential equation
∂2δvy
∂y2 =

1
(vx −C)
d2vx
dy2 + k2

δvy.
(15.34)
These are called Tollmien-Schlichting waves.
(b) Hence argue that a sufﬁcient condition for unstable wave modes [Im(C) > 0] is
that the velocity ﬁeld possess a point of inﬂection (i.e., a point where d2vx/dy2
changes sign; cf. Fig. 15.12). The boundary layer can also be unstable in the
absence of a point of inﬂection, but viscosity must then trigger the instability.
15.5.4
15.5.4 Flight of a Ball
physics of sports balls
Havingdevelopedsomeinsightsintoboundarylayersandtheirstability, wenowapply
those insights to the balls used in various sports.
The simplest application is to the dimples on a golf ball (Fig. 15.13a). The dimples
provideﬁnite-amplitudedisturbancesintheﬂowthatcantriggergrowingwavemodes
and then turbulence in the boundary layer. The adherence of the boundary layer to
golf ball: turbulent
boundary layer reduces
drag
the ball is improved, and separation occurs farther behind the ball, leading to a lower
drag coefﬁcient and a greater range of ﬂight; see Figs. 15.2 and 15.13a.
A variant on this mechanism is found in the game of cricket, which is played
with a ball whose surface is polished leather with a single equatorial seam of rough
stitching. When the ball is “bowled” in a nonspinning way with the seam inclined
cricket ball: two boundary
layers, turbulent and
laminar, produce
deﬂection
to the direction of motion, a laminar boundary layer exists on the smooth side and
a turbulent one on the side with the rough seam (Fig. 15.13b). These two boundary
layers separate at different points behind the ﬂow, leading to a net deﬂection of the
air. The ball therefore swerves toward the side with the leading seam. (The effect is
strongest when the ball is new and still shiny and on days when the humidity is high,
so the thread in the seam swells and is more efﬁcient at making turbulence.)
15.5 Turbulent Boundary Layers
823

turbulent
boundary layer
turbulent
boundary
layer
turbulent
wake
force
force
(a) Golf ball
(b) Cricket ball
(c) Baseball
laminar
boundary layer

FIGURE 15.13 Boundary layers around (a) golf ball, (b) cricket ball, and (c) baseball as they move
leftward relative to the air (i.e., as the air ﬂows rightward as seen in their rest frames).
This mechanism is different from that used to throw a slider or curveball in base-
ball, in which the pitcher causes the ball to spin about an axis roughly perpendicular
to the direction of motion. In the slider the axis is vertical; for a curveball it is inclined
at about 45◦to the vertical. The spin of the ball creates circulation (in a nonrotating,
baseball and table tennis:
circulation produces
deﬂection
inertial frame) like that around an airfoil. The pressure forces associated with this
circulation produce a net sideways force in the direction of the baseball’s rotational
velocity on its leading hemisphere (i.e., as seen by the hitter; Fig. 15.13c). The physical
origin of this effect is actually quite complex and is only properly described with ref-
erence to experimental data. The major effect is that separation is delayed on the side
of the ball where the rotational velocity is in the same direction as the airﬂow and hap-
pens sooner on the opposite side (Fig. 15.13c), leading to a pressure differential. The
reader may be curious as to how this circulation can be established in view of Kelvin’s
theorem, Eq. (14.16), which states that if we use a closed curve ∂S, Eq. (14.12a), that
is so far from the ball and its wake that viscous forces cannot cause the vorticity to
diffuse to it, then the circulation must be zero. What actually happens is similar to
an airplane wing (Fig. 14.2b). When the ﬂow is initiated, starting vortices are shed by
the baseball and are then convected downstream, leaving behind the net circulation
 that passes through the ball (Fig. 15.14). This effect is very much larger in 2 dimen-
sions with a rotating cylinder than in 3 dimensions, because the magnitude of the
shed vorticity is much larger. It goes by the name of Magnus effect in 2 dimensions
Magnus and Robins effects
and Robins effect in 3, and it underlies Kutta-Joukowski’s theorem for the lift on an
airplane wing (Ex. 14.8).
In table tennis, a drive is often hit with topspin, so that the ball rotates about a
horizontal axis perpendicular to the direction of motion. In this case, the net force
is downward, and the ball falls faster toward the table, the effect being largest after it
has somewhat decelerated. This allows a ball to be hit hard over the net and bounce
before passing the end of the table, increasing the margin for errors in the direction
of the hit.
824
Chapter 15. Turbulence

vortex lines
starting vortex
V
v
v
v

ω
FIGURE 15.14 Vortex lines passing through a spinning ball. The starting
vortex is created and shed when the ball is thrown and is carried
downstream by the ﬂow as seen in the ball’s frame of reference. The
vortex lines connecting this starting vortex to the ball lengthen as the
ﬂow continues.
Those wishing to improve their curveballs or cure a bad slice are referred to the
monographs by Adair (1990), Armenti (1992), and Lighthill (1986).
EXERCISES
Exercise 15.12 Problem: Effect of Drag
A well-hit golf ball travels about 300 yards. A fast bowler or fastball pitcher throws a
cricketballorbaseballatmorethan90 mph(milesperhour).Atable-tennisplayercan
hit a forehand return at about 30 mph. The masses and diameters of each of these four
typesofballsaremg ∼46 g, dg ∼43 mm; mc ∼160 g, dc ∼70 mm; mb ∼140 g, db ∼
75 mm; and mtt ∼2.5 g, dtt ∼38 mm.
(a) For golf, cricket (or baseball), and table tennis, estimate the Reynolds number of
the ﬂow and infer the drag coefﬁcient CD. (The variation of CD with Red can be
assumed to be similar to that in ﬂow past a cylinder; Fig. 15.2.)
(b) Hence estimate the importance of aerodynamic drag in determining the range of
a ball in each of these three cases.
15.6
15.6 The Route to Turbulence—Onset of Chaos
15.6.1
15.6.1 Rotating Couette Flow
Let us examine qualitatively how a viscous ﬂow becomes turbulent. A good example is
rotating Couette ﬂow between two long, concentric, differentially rotating cylinders,
as introduced in Sec. 14.6.3 and depicted in Fig. 15.15a. This ﬂow was studied in
a classic set of experiments by Gollub, Swinney, and collaborators (Fenstermacher,
Swinney, and Gollub, 1979; Gorman and Swinney, 1982, and references therein). In
these experiments, the inner cylinder rotates and the outer one does not, and the
ﬂuid is a liquid whose viscosity is gradually decreased by heating it, so the Reynolds
number gradually increases. At low Reynolds numbers, the equilibrium ﬂow is stable,
15.6 The Route to Turbulence—Onset of Chaos
825

bifurcation
point
stable
stable
unstable
equilibria with no
Taylor rolls
equilibria with
Taylor rolls
dashed: center
of unperturbed
Taylor roll
solid: center of
perturbed, wavy
Taylor roll
(a)
(b)
(c)
z
ϖ
jPj
ω
ω
ω
φ
z
ϖ
φ
v
v
v
v
v
v
Rec1
Re
FIGURE 15.15 Bifurcation of equilibria in rotating Couette ﬂow. (a) Equilibrium ﬂow with Taylor rolls.
(b) Bifurcation diagram in which the amplitude of the poloidal circulation |P| in a Taylor roll is
plotted against the Reynolds number. At low Reynolds numbers (Re < Rec1), the only equilibrium
ﬂow conﬁguration is smooth, azimuthal ﬂow. At larger Reynolds numbers (Rec1 < Re < Rec2), there
are two equilibria, one with Taylor rolls and stable; the other with smooth, azimuthal ﬂow, which
is unstable. (c) Shape of a Taylor roll at Rec1 < Re < Rec2 (dashed ellipse) and at higher values,
Rec2 < Re < Rec3 (solid, wavy curve).
stationary, and azimuthal (strictly in the φ direction; Fig. 15.15a). At very high
Reynolds numbers, the ﬂow is unstable, according to the Rayleigh criterion (angular
momentum per unit mass decreases outward; Sec. 14.6.3). Therefore, as the Reynolds
number is gradually increased, at some critical value Rec1, the ﬂow becomes unstable
to the growth of small perturbations. These perturbations drive a transition to a new
stationary equilibrium whose form is what one might expect from the Rayleigh-
criterion thought experiment (Sec. 14.6.3): it involves poloidal circulation (quasi-
circular motions in the r and z directions, called Taylor rolls; see Fig. 15.15a).
Taylor rolls
Thus an equilibrium with a high degree of symmetry has become unstable, and
a new, lower-symmetry, stable equilibrium has been established; see Fig. 15.15b.
bifurcation to a lower
symmetry state
Translational invariance along the cylinder axis has been lost from the ﬂow, even
though the boundary conditions remain translationally symmetric. This transition
is another example of the bifurcation of equilibria that we discussed when treating
the buckling of beams and playing cards (Secs. 11.6 and 12.3.5).
As the Reynolds number is increased further, this process repeats. At a sec-
ond critical Reynolds number Rec2, a second bifurcation of equilibria occurs in
which the azimuthally smooth Taylor rolls become unstable and are replaced by new,
azimuthally wavy Taylor rolls; see Fig. 15.15c. Again, an equilibrium with higher sym-
metry (rotation invariance) has been replaced at a bifurcation point by one of lower
symmetry (no rotation invariance). A fundamental frequency f1 shows up in the
ﬂuid’s velocity v(x, t) as the wavy Taylor rolls circulate around the central cylinder.
826
Chapter 15. Turbulence

(a)
(b)
(c)
U( f )
U( f )
U( f )
f1
f
2f1
f1 f2
f2 – f1
f2 – f1
f1 + f2
f1 + f2
2f1 + f2
2f1 + f2
f
f
2f1
f1 f2
2f1
3f1
FIGURE 15.16 The energy spectrum of velocity ﬂuctuations in rotating Couette ﬂow (schematic).
(a) Spectrum for a moderate Reynolds number, Rec2 < Re < Rec3, at which the stable equilibrium
ﬂow is that with the wavy Taylor rolls of Fig. 15.15c. (b) Spectrum for a higher Reynolds number,
Rec3 < Re < Rec4, at which the stable ﬂow has wavy Taylor rolls with two incommensurate
fundamental frequencies present. (c) Spectrum for a still higher Reynolds number, Re > Rec4, at
which turbulence has set in.
Since the waves are nonlinearly large, harmonics of this fundamental are also seen
when the velocity ﬁeld is Fourier decomposed (cf. Fig. 15.16a). When the Reynolds
number is increased still further to some third critical value Rec3, there is yet another
bifurcation. The Taylor rolls now develop a second set of waves, superimposed on the
wavy Taylor rolls: two
frequencies
ﬁrst, with a corresponding new fundamental frequency f2 that is incommensurate
with f1. In the energy spectrum one now sees various harmonics of f1 and of f2, as
well as sums and differences of these two fundamentals (Fig. 15.16b).
It is exceedingly difﬁcult to construct an experimental apparatus that is clean
enough—and sufﬁciently free from the effects of ﬁnite lengths of the cylinders—
to reveal what happens next as the Reynolds number increases. However, despite
the absence of clean experiments, it seemed obvious before the 1970s what would
happen. The sequence of bifurcations would continue, with ever-decreasing intervals
of Reynolds number Re between them, eventually producing such a complex maze
of frequencies, harmonics, sums, and differences, as to be interpreted as turbulence.
Indeed, one ﬁnds the onset of turbulence described in just this manner in the classic
ﬂuid mechanics textbook of Landau and Lifshitz (1959), based on earlier research by
Landau (1944).
The 1970s and 1980s brought a major breakthrough in our understanding of
the onset of turbulence. This breakthrough came from studies of model dynamical
systems with only a few degrees of freedom, in which nonlinear effects play similar
roles to the nonlinearities of the Navier-Stokes equation. These studies revealed only
a handful of routes to irregular or unpredictable behavior known as chaos, and none
were of the Landau type. However, one of these routes starts out in the same manner
route to turbulence
in rotating Couette
ﬂow: one frequency,
two frequencies, then
turbulence (chaos)
as does rotating Couette ﬂow: As a control parameter (the Reynolds number in the
case of Couette ﬂow) is gradually increased, ﬁrst oscillations with one fundamental
frequency f1and its harmonics turn on; then a second frequency f2 (incommensurate
with the ﬁrst) and its harmonics turn on, along with sums and differences of f1
15.6 The Route to Turbulence—Onset of Chaos
827

and f2; and then, suddenly, chaos sets in. Moreover, the chaos is clearly not being
produced by a complicated superposition of new frequencies; it is fundamentally
different from that.
Remarkably, the experiments of Gollub, Swinney, and colleagues gave convincing
evidence that the onset of turbulence in rotating Couette ﬂow takes precisely this route
(Fig. 15.16c).
15.6.2
15.6.2 Feigenbaum Sequence, Poincar´e Maps, and the Period-Doubling
Route to Turbulence in Convection
The simplest of systems in which one can study the several possible routes to chaos
are 1-dimensional mathematical maps. A lovely example is the Feigenbaum sequence,
explored by Mitchell Feigenbaum (1978).
The Feigenbaum sequence is a sequence {x1, x2, x3, . . .} of values of a real variable
x, given by the rule (sometimes called the logistic equation)12
logistic equation and its
Feigenbaum sequence
xn+1 = 4axn(1 −xn).
(15.35)
Here a is a ﬁxed control parameter. It is easy to compute Feigenbaum sequences
{x1, x2, x3, . . .} for different values of a on a personal computer (Ex. 15.13). What
is found is that there are critical parameters a1, a2, . . . at which the character of the
sequence changes sharply. For a < a1, the sequence asymptotes to a stable ﬁxed point.
For a1 < a < a2, the sequence asymptotes to stable, periodic oscillations between two
ﬁxed points. If we increase the parameter further, so that a2 < a < a3, the sequence
becomes a periodic oscillation between four ﬁxed points. The period of the oscillation
has doubled. This period doubling (not to be confused with frequency doubling)
period doubling route to
chaos for Feigenbaum
sequence
happens again: When a3 < a < a4, x asymptotes to regular motion between eight
ﬁxed points. Period doubling increases with shorter and shorter intervals of a until at
some value a∞, the period becomes inﬁnite, and the sequence does not repeat. Chaos
has set in.
This period doubling is a second route to chaos, very different in character from
the one-frequency, two-frequencies, chaos route that appears to occur in rotating
Couette ﬂow. Remarkably, ﬂuid dynamical turbulence can set in by this second route
as well as by the ﬁrst. It does so in certain very clean experiments on convection. We
return to this phenomenon at the end of this section and then again in Sec. 18.4.
How can so starkly simple and discrete a model as a 1-dimensional map bear any
relationship to the continuous solutions of the ﬂuid dynamical differential equations?
The answer is quite remarkable.
12. This equation ﬁrst appeared in discussions of population biology (Verhulst, 1838). If we consider xn
as being proportional to the number of animals in a species (traditionally rabbits), the number in the
next season should be proportional to the number of animals already present and to the availability of
resources, which will decrease as xn approaches some maximum value, in this case unity. Hence the
terms xn and 1 −xn in Eq. (15.35).
828
Chapter 15. Turbulence

(a)
(b)
y
y
ẏ
ẏ
x
x
x2
x2
x4
x3
x1 = x3
x1 = x5
FIGURE 15.17 (a) Representation of a single periodic oscillation as motion in phase space.
(b) Motion in phase space after period doubling. The behavior of the system may also be
described by using the coordinate x of the Poincar´e map.
Consider a steady ﬂow in which one parameter a (e.g., the Reynolds number) can
be adjusted. Now, as we change a and approach turbulence, the ﬂow may develop a
periodic oscillation with a single frequency f1. We could measure this by inserting
some probe at a ﬁxed point in the ﬂow to measure a ﬂuid variable y (e.g., one
component of the velocity). We can detect the periodicity either by inspecting the
readout y(t) or its Fourier transform ˜y. However, there is another way, which may be
familiar from classical mechanics. This is to regard {y, ˙y} as the two coordinates of
phase-space
representation of
dynamics
a 2-dimensional phase space. (Of course, instead one could measure many variables
and their time derivatives, resulting in an arbitrarily large phase space, but let us keep
matters as simple as possible.) For a single periodic oscillation, the system will follow
a closed path in this phase space (Fig. 15.17a). As we increase a further, a period
doubling may occur, and the trajectory in phase space may look like Fig. 15.17b. As
we are primarily interested in the development of the oscillations, we need only keep
one number for every fundamental period P1 = 1/f1. Let us do this by taking a section
through phase space and introducing a coordinate x on this section, as shown in
Fig. 15.17. The nth time the trajectory crosses this section, its crossing point is xn, and
the mapping from xn to xn+1 can be taken as a representative characterization of the
ﬂow. When only the frequency f1 is present, the map reads xn+2 = xn (Fig. 15.17a).
When f1 and f2 = 1
2f1 are present, the map reads xn+4 = xn (Fig. 15.17b). (These
speciﬁc maps are overly simple compared to what one may encounter in a real ﬂow,
but they illustrate the idea.)
reducing the dynamics of a
ﬂuid’s route to turbulence
to a 1-dimensional map:
the Poincar´e map
To reiterate, instead of describing the ﬂow by the full solution v(x, t) to the Navier-
Stokes equation and the ﬂow’s boundary conditions, we can construct the simple
map xn →xn+1 to characterize the ﬂow. This procedure is known as a Poincar´e
map. The mountains have labored and brought forth a mouse! However, this mouse
turns out to be all that we need. For some convection experiments, the same period-
15.6 The Route to Turbulence—Onset of Chaos
829

doubling behavior and approach to chaos are present in these maps as in the
2-dimensional phase-space diagram and in the full solution to the ﬂuid dynamical
equations. Furthermore, when observed in the Poincar´e maps, the transition looks
qualitativelythesameasintheFeigenbaumsequence.Itisremarkablethatforasystem
with so many degrees of freedom, chaotic behavior can be observed by suppressing
almost all of them.
If, in the period-doubling route to chaos, we compute the limiting ratio of succes-
sive critical parameters,
Feigenbaum number for
period doubling route to
chaos, and its universality
F = lim
j→∞
aj −aj−1
aj+1 −aj
,
(15.36)
we ﬁnd that it has the value 4.66920160910 . . . . This Feigenbaum number seems
to be a universal constant characteristic of most period-doubling routes to chaos,
independent of the particular map that was used. For example, if we had used
xn+1 = a sin πxn
(15.37)
we would have gotten the same constant.
period doubling route to
turbulence in Libchaber
convection experiments
The most famous illustration of the period-doubling route to chaos is a set of
experiments by Libchaber and colleagues on convection in liquid helium, water, and
mercury, culminating with the mercury experiment by Libchaber, Laroche, and Fauve
(1982). In each experiment (depicted in Fig. 18.1), the temperature at a point was
monitored with time as the temperature difference T between the ﬂuid’s bottom
and top surfaces was slowly increased. In each experiment, at some critical temper-
ature difference T1 the temperature began to oscillate with a single period; then at
some T2 that oscillation was joined by another at twice the period; at some T3
another period doubling occurred; at T4 another; and at T5 yet another. The fre-
quency doubling could not be followed beyond this because the signal was too weak,
but shortly thereafter the convection became turbulent. In each experiment it was
possible to estimate the Feigenbaum ratio (15.36), with aj being the jth critical T .
universality in the route to
chaos
For the highest-accuracy (mercury) experiment, the experimental result agreed with
the Feigenbaum number 4.669 . . . to within the experimental accuracy (about 6%);
the helium and water experiments also agreed with Feigenbaum to within their ex-
perimental accuracies. This result was remarkable. There truly is a deep universality in
the route to chaos, a universality that extends even to ﬂuid-dynamical convection! This
work won Libchaber and Feigenbaum together the prestigious 1986 Wolf Prize.
EXERCISES
Exercise 15.13 Problem: Feigenbaum Number for the Logistic Equation
Use a computer to calculate the ﬁrst ﬁve critical parameters aj for the sequence of
numbers generated by the logistic equation (15.35). Hence verify that the ratio of
successive differences tends toward the Feigenbaum number F quoted in Eq. (15.36).
(Hint: To ﬁnd suitable starting values x1 and starting parameter a, you might ﬁnd it
830
Chapter 15. Turbulence

helpful to construct a graph.) For insights into the universality of the Feigenbaum
number, based in part on the renormalization group (Sec. 5.8.3), see Sethna (2006,
Ex. 12.9).
15.6.3
15.6.3 Other Routes to Turbulent Convection
Some other routes to turbulence have been seen in convection experiments, in
addition to the Feigenbaum/Libchaber period-doubling route. Particularly impres-
sive were convection experiments by Gollub and Benson (1980), which showed—
depending on the experimental parameters and the nature of the initial convective
ﬂow—four different routes:
four different routes to
turbulence in convection
experiments
1. The period-doubling route.
2. A variant of the one-frequency, two-frequencies, chaos route. In this variant,
a bit after (at higher T ) the second frequency appears, incommensurate
with the ﬁrst, the two frequencies become commensurate and their modes
become phase locked (one entrains the other); and then a bit later (higher
T ) the phase lock is broken and simultaneously turbulence sets in.
3. A one-frequency, two-frequencies, three-frequencies, chaos route.
4. An intermittency route, in which, as T is increased, the ﬂuid oscillates
between a state with two or three incommensurate modes and a state with
turbulence.
These four routes to chaos are all seen in simple mathematical maps or low-
dimensional dynamical systems; for example, the intermittency route is seen in the
Lorenz equations of Ex. 15.16.
weaknessandconﬁnement
of the turbulence that
follows these routes
Note that the convective turbulence that is triggered by each of these routes is
weak; the control parameter T must be increased further to drive the ﬂuid into a
fully developed, strong-turbulence state.
Also important is the fact that these experimental successes, which compare
the onset of turbulence with the behaviors of simple mathematical maps or low-
dimensional dynamical systems, all entail ﬂuids that are conﬁned by boundaries and
have a modest aspect ratio (ratio of the largest to the smallest dimension), 20:1 for
rotating Couette ﬂow and 5:1 for convection. For conﬁned ﬂuids with much larger
aspect ratios, and for unconﬁned ﬂuids, there has been no such success. It may be
that the successes are related to the small number of relevant modes in a system with
modest aspect ratio.
These successes occurred in the 1970s and 1980s. Much subsequent research fo-
cuses on the mechanism by which the ﬁnal transition to turbulence occurs [e.g., the
role of the Navier-Stokes nonlinear term (v . ∇)v]. This research involves a mixture
of analytical work and numerical simulations, plus some experiment (see, e.g., Gross-
man, 2000).
15.6 The Route to Turbulence—Onset of Chaos
831

15.6.4
15.6.4 Extreme Sensitivity to Initial Conditions
The evolution of a dynamical system becomes essentially incalculable after the onset
of chaos. This is because, as can be shown mathematically, the state of the system (as
measured by the value of a map, or in a ﬂuid by the values of a set of ﬂuid variables) at
some future time becomes highly sensitive to the assumed initial state. Paths (in the
map or in phase space) that start arbitrarily close together diverge from each other
exponentially rapidly with time.
It is important to distinguish this unpredictability of classical chaos from un-
predictability in the evolution of a quantum mechanical system. A classical system
evolves under precisely deterministic differential equations. Given a full characteri-
zation of the system at any time t, the system is fully speciﬁed at a later time t + t,
for any t. However, what characterizes chaos is that the evolution of two identical
systems in neighboring initial states will eventually evolve so that they follow totally
different histories. The time it takes for this to happen is called the Lyapunov time.
Lyapunov time:
characterizes sensitivity of
a classical system to initial
conditions
The practical signiﬁcance of this essentially mathematical feature is that if, as will al-
ways be the case, we can only specify the initial state up to a given accuracy (due to
practical considerations, not issues of principle), then the true initial state could be
any one of those lying in some region, so we have no way of predicting what the state
will be after a few Lyapunov times have elapsed.
quantum indeterminacy
Quantum mechanical indeterminacy is different. If we can prepare a system in
a given state described by a wave function, then the wave function’s evolution will
be governed fully deterministically by the time-dependent Schr¨odinger equation.
However, if we choose to make a measurement of an observable, many quite distinct
outcomes are immediately possible, and (for a high-precision measurement) the
system will be left in an eigenstate corresponding to the actual measured outcome.
Thequantummechanicaldescriptionofclassicalchaosisthesubjectofquantumchaos
(e.g., Gutzwiller, 1990).
The realization that many classical systems have an intrinsic unpredictability
despite being deterministic from instant to instant has been widely publicized in
popularizations of research on chaos. However, the concept is not particularly new.
It was well understood, for example, by Poincar´e around 1900, and watching the
weather report on the nightly news bears witness to its dissemination into popular
culture! What is new and intriguing is the manner in which a system transitions from
a deterministic to an unpredictable evolution.
examples of chaotic
behavior
Chaotic behavior is well documented in a variety of physical dynamical systems:
electrical circuits, nonlinear pendula, dripping faucets, planetary dynamics, and so
on. The extent to which the principles that have been devised to describe chaos in
these systems can also be applied to general ﬂuid turbulence remains a matter for
debate. There is no question that similarities exist, and (as we have seen) quantitative
success has been achieved by applying chaos results to particular forms of turbulent
convection. However, most forms of turbulence are not so easily described, and
832
Chapter 15. Turbulence

there is still a huge gap between the intriguing mathematics of chaotic dynamics and
practical applications to natural and technological ﬂows.
EXERCISES
Exercise 15.14 Example: Lyapunov Exponent
Consider the logistic equation (15.35) for the special case a = 1, which is large enough
to ensure that chaos has set in.
(a) Make the substitution xn = sin2 πθn, and show that the logistic equation can be
expressed in the form θn+1 = 2θn (mod 1); that is, θn+1 equals the fractional part
of 2θn.
(b) Write θn as a “binimal” (binary decimal). For example, 11/16 = 1/2 + 0/4 +
1/8 + 1/16 has the binary decimal form 0.1011. Explain what happens to this
number in each successive iteration.
(c) Now suppose that an error is made in the ith digit of the starting binimal. When
will it cause a major error in the predicted value of xn?
(d) If the error after n iterations is written ϵn, show that the Lyapunov exponent p
deﬁned by
p = lim
n→∞
1
n ln
8888
ϵn
ϵ0
8888
(15.38)
is ln 2 (so ϵn ≃2nϵ0 for large enough n). Lyapunov exponents play an important
role in the theory of dynamical systems.
Exercise 15.15 Example: Strange Attractors
Another interesting 1-dimensional map is provided by the recursion relation
xn+1 = a

1 −2
8888xn −1
2
8888

.
(15.39)
(a) Consider the asymptotic behavior of the variable xn for different values of the
parameter a, with both xn and a being conﬁned to the interval [0, 1]. In particular,
ﬁnd that for 0 < a < acrit (for some acrit), the sequence xn converges to a stable
ﬁxed point, but for acrit < a < 1, the sequence wanders chaotically through some
interval [xmin, xmax].
(b) Using a computer, calculate the value of acrit and the interval [xmin, xmax] for
a = 0.8.
(c) The interval [xmin, xmax] is an example of a strange attractor. It has the property
that if we consider sequences with arbitrarily close starting values, their values
of xn in this range will eventually diverge. Show that the attractor is strange by
computing the sequences with a = 0.8 and starting values x1 = 0.5, 0.51, 0.501,
and0.5001.Determinethenumberofiterationsnϵ requiredtoproducesigniﬁcant
divergence as a function of ϵ = x1 −0.5. It is claimed that nϵ ∼−ln2(ϵ). Can you
15.6 The Route to Turbulence—Onset of Chaos
833

verify this? Note that the onset of chaos at a = acrit is quite sudden in this case,
unlike the behavior exhibited by the Feigenbaum sequence. See Ruelle (1989) for
more on strange attractors.
Exercise 15.16 Problem: Lorenz Equations
One of the ﬁrst discoveries of chaos in a mathematical model was by Lorenz (1963),
who made a simple model of atmospheric convection. In this model, the temperature
and velocity ﬁeld are characterized by three variables, x, y, and z, which satisfy the
coupled, nonlinear differential equations
dx/dt = 10(y −x),
dy/dt = −xz + 28x −y,
dz/dt = xy −8z/3.
(15.40)
(The precise deﬁnitions of x, y, and z need not concern us here.) Integrate these
equations numerically to show that x, y, and z follow nonrepeating orbits in the 3-
dimensional phase space that they span, and quickly asymptote to a 2-dimensional
strangeattractor.(Itmaybehelpfultoplotoutthetrajectoriesofpairsofthedependent
variables.)
These Lorenz equations are often studied with the numbers 10, 28, 8/3 replaced
by parameters σ, ρ, and β. As these parameters are varied, the behavior of the system
changes.
Bibliographic Note
For physical insight into turbulence, we strongly recommend the movies cited in
Box 15.2 and the photographs in Van Dyke (1982) and Tritton (1987).
Many ﬂuid mechanics textbooks have good treatments of turbulence. We particu-
larlylikeWhite(2008), andalsorecommendLautrup(2005)andPanton(2005).Some
treatisesonturbulencegointothesubjectmuchmoredeeply(thoughthedeepertreat-
ments often have somewhat limited applicability); among these, we particularly like
Tennekes and Lumley (1972) and also recommend the more up-to-date Davidson
(2005) and Pope (2000). Standard ﬂuid mechanics textbooks for engineers focus par-
ticularly on turbulence in pipe ﬂow and in boundary layers (see, e.g., Munson, Young,
and Okiishi, 2006; White, 2006; Potter, Wiggert, and Ramadan, 2012).
For the inﬂuence of boundary layers and turbulence on the ﬂight of balls of various
sorts, see Lighthill (1986), Adair (1990), and Armenti (1992).
For the onset of turbulence in unstable laminar ﬂows, we particularly like Sagdeev,
Usikov, and Zaslovsky (1988, Chap. 11) and Acheson (1990, Chap. 9). For the route to
chaos in low-dimensional dynamical systems with explicit connections to the onset
of turbulence, see Ruelle (1989); for chaos theory with little or no discussion of
turbulence, Baker and Gollub (1990), Alligood, Sauer, and Yorke (1996), and Strogatz
(2008).
834
Chapter 15. Turbulence

16
CHAPTER SIXTEEN
Waves
An ocean traveller has even more vividly the impression
that the ocean is made of waves than that it is made of water.
ARTHUR EDDINGTON (1927)
16.1
16.1 Overview
In the preceding chapters, we have derived the basic equations of ﬂuid dynamics and
developed a variety of techniques to describe stationary ﬂows. We have also demon-
strated how, even if there exists a rigorous, stationary solution of these equations for
a time-steady ﬂow, instabilities may develop, in which the amplitude of an oscillatory
disturbance grows with time. These unstable modes of an unstable ﬂow can usually be
thought of as waves that interact strongly with the ﬂow and extract energy from it. Of
course, wave modes can also be stable and can be studied as independent, individual
modes.
Fluid dynamical waves come in a wide variety of forms. They can be driven by
a combination of gravitational, pressure, rotational, and surface-tension stresses and
also by mechanical disturbances, such as water rushing past a boat or air passing
through a larynx. In this chapter, we describe a few examples of wave modes in ﬂuids,
chosen to illustrate general wave properties.
The most familiar types of wave are probably gravity waves on the surface of a
large body of water (Sec. 16.2), such as ocean waves and waves on lakes and rivers.
We consider them in the linear approximation and ﬁnd that they are dispersive in
general, though they become nondispersive in the long-wavelength (shallow-water)
limit(i.e., whentheyareinﬂuencedbythewater’sbottom).Wealsoexaminetheeffects
of surface tension on gravity waves, which converts them into capillary waves, and in
this connection we develop a mathematical description of surface tension (see Box
16.4). Boundary conditions can give rise to a discrete spectrum of normal modes,
which we illustrate by helioseismology: the study of coherent-wave modes excited in
the Sun by convective overturning motions.
By contrast with the elastodynamic waves of Chap. 12, waves in ﬂuids often de-
velop amplitudes large enough that nonlinear effects become important (Sec. 16.3).
The nonlinearities can cause the front of a wave to steepen and then break—a phe-
nomenon we have all seen at the sea shore. It turns out that, at least under some
835

BOX 16.1.
READERS’ GUIDE
.
This chapter relies heavily on Chaps. 13 and 14, and less heavily on
geometric-optics concepts introduced in Secs. 7.2 and 7.3.
.
Chap. 17 relies to some extent on Secs. 16.2, 16.3, and 16.5 of this
chapter.
.
Sec. 16.3 on solitons on water is a foundation for Sec. 23.6 on solitons
in plasmas.
.
The remaining chapters of this book do not rely signiﬁcantly on this
chapter.
restrictive conditions, nonlinear waves have very surprising properties. There exist
soliton or solitary-wave modes, in which the front-steepening due to nonlinearity is
stably held in check by dispersion, so particular wave proﬁles are quite robust and
propagate for long intervals of time without breaking or dispersing. We demonstrate
this behavior by studying ﬂow in a shallow channel. We also explore the remarkable
behaviors of such solitons when they pass through each other.
In a nearly rigidly rotating ﬂuid, there are remarkable waves in which the restoring
force is the Coriolis effect; they have the unusual property that their group and phase
velocities are oppositely directed. These so-called Rossby waves, studied in Sec. 16.4,
are important in both the oceans and the atmosphere.
The simplest ﬂuid waves of all are small-amplitude sound waves—a paradigm
for scalar waves. They are nondispersive, just like electromagnetic waves, and are
therefore sometimes useful for human communication. We shall study sound waves
in Sec. 16.5 and use them to explore (i) the radiation reaction force that acts back
on a wave-emitting object (a fundamental physics issue) and (ii) matched asymptotic
expansions (a mathematical physics technique). We also describe how sound waves
can be produced by ﬂuid ﬂows. This process will be illustrated with the problem of
sound generation by high-speed turbulent ﬂows—a problem that provides a good
starting point for the topic of the following chapter, compressible ﬂows.
Other examples of ﬂuid waves are treated elsewhere in Part V: Kelvin-Helmholtz
waves at the interface between two ﬂuids that move relative to each other (Sec. 14.6.1);
Tollmien-Schlichting waves in a laminar boundary layer (Ex. 15.11); lee waves in a
separated boundary layer (footnote in Sec. 15.5.2); wavy Taylor rolls in rotating Cou-
ette ﬂow (Sec. 15.6.1); shock waves (Sec. 17.5); Sedov-Taylor blast waves (Sec. 17.6);
hydraulic jumps (Ex. 17.10); internal waves, which propagate when ﬂuid is stratiﬁed
in a gravitational ﬁeld (Ex. 18.8); and various types of magnetohydrodynamic waves
(Chap. 19).
836
Chapter 16. Waves

BOX 16.2.
MOVIES RELEVANT TO THIS CHAPTER
We strongly recommend that the reader view the following movies dealing
with waves:
.
Bryson (1964)—waves in ﬂuids.
.
Fultz (1969)—relevant to Rossby waves, Sec. 16.4.
.
Rouse (1963c)—relevant to gravity waves on the surface of water,
Sec. 16.2.
As in Chaps. 14 and 15, readers are urged to watch movies in parallel with reading
this chapter; see Box 16.2.
16.2
16.2 Gravity Waves on and beneath the Surface of a Fluid
Gravity waves1 are waves on and beneath the surface of a ﬂuid, for which the restoring
gravity waves
forceisthedownwardpullofgravity.Familiarexamplesareoceanwavesandthewaves
produced on the surface of a pond when a pebble is thrown in. Less familiar examples
are “g modes” of vibration inside the Sun, discussed at the end of this section.
Consider a small-amplitude wave propagating along the surface of a ﬂat-bottomed
lake with depth ho, as shown in Fig. 16.1. As the water’s displacement is small, we can
describe the wave as a linear perturbation about equilibrium. The equilibrium water is
at rest (i.e., it has velocity v = 0). The water’s perturbed motion is essentially inviscid
and incompressible, so ∇. v = 0. A simple application of the equation of vorticity
transport, Eq. (14.6), assures us that, since the water is static and thus irrotational
before and after the wave passes, it must also be irrotational in the wave. Therefore,
we can describe the wave inside the water by a velocity potential ψ whose gradient is
the velocity ﬁeld:
velocity potential
v = ∇ψ.
(16.1)
Incompressibility, ∇. v = 0, applied to this equation, implies that ψ satisﬁes Laplace’s
equation:
Laplace’s equation
for irrotational,
incompressible ﬂow
∇2ψ = 0.
(16.2)
We introduce horizontal coordinates x, y and a vertical coordinate z measured
upward from the lake’s equilibrium surface (Fig. 16.1). For simplicity we conﬁne
1.
Not to be confused with gravitational waves, which are waves in the relativistic gravitational ﬁeld
(spacetime curvature) that propagate at the speed of light, and which we meet in Chap. 27.
16.2 Gravity Waves on and beneath the Surface of a Fluid
837

z
ξ(x, t)
x
ho
2π/k
FIGURE 16.1 Gravity waves propagating horizontally across a lake with
constant depth ho.
attention to a sinusoidal wave propagating in the x direction with angular frequency
ω and wave number k. Then ψ and all other perturbed quantities have the form
f (z) exp[i(kx −ωt)] for some function f (z). More general disturbances can be
expressed as a superposition of many of these elementary wave modes propagating
in various horizontal directions (and in the limit, as a Fourier integral over modes).
All the properties of such superpositions follow straightforwardly from those of our
elementary plane-wave mode (see Secs. 7.2.2 and 7.3), so we continue to focus on it.
We can use Laplace’s equation (16.2) to solve for the vertical variation f (z) of the
velocity potential. As the horizontal variation at a particular time is ∝exp(ikx), direct
substitution into Eq. (16.2) gives two possible vertical variations: ψ ∝exp(±kz). The
precise linear combination of these two forms is dictated by the boundary conditions.
The boundary condition we need is that the vertical component of velocity vz =
boundary condition at
bottom of lake
∂ψ/∂z vanish at the bottom of the lake (z = −ho). The only combination that can
vanish is a sinh function. Its integral, the velocity potential, therefore involves a cosh
function:
velocity potential for
gravity waves
ψ = ψ0 cosh[k(z + ho)] exp[i(kx −ωt)].
(16.3)
An alert reader might note at this point that, for this ψ, the horizontal component
of velocity vx = ψ,x = ikψ does not vanish at the lake bottom, in violation of the no-
slip boundary condition. In fact, as we discussed in Sec. 14.4, a thin, viscous boundary
layeralongthebottomofthelakewilljoinourpotential-ﬂowsolution(16.3)tononslip
ﬂuid at the bottom. We ignore the boundary layer under the (justiﬁable) assumption
that for our oscillating waves, it is too thin to affect much of the ﬂow.
Returning to the potential ﬂow, we must also impose a boundary condition at the
surface. This can be obtained from Bernoulli’s law. The version of Bernoulli’s law that
we need is that for an irrotational, isentropic, time-varying ﬂow:
v2/2 + h +  + ∂ψ/∂t = const everywhere in the ﬂow
(16.4)
838
Chapter 16. Waves

[Eqs. (13.51), (13.54)]. We apply this law at the surface of the perturbed water. Let us
Boundary condition at
surface of water
examine each term:
1. The term v2/2 is quadratic in a perturbed quantity and therefore can be
dropped.
2. The enthalpy h = u + P/ρ (cf. Box 13.2) is a constant, since u and ρ are
constants throughout the ﬂuid and P is constant on the surface (equal to
the atmospheric pressure).2
3. The gravitational potential at the ﬂuid surface is  = gξ, where ξ(x, t) is the
surface’s vertical displacement from equilibrium, and we ignore an additive
constant.
4. The constant on the right-hand side, which could depend on time [C(t)],
can be absorbed in the velocity potential term ∂ψ/∂t without changing the
physical observable v = ∇ψ.
Bernoulli’s law applied at the surface therefore simpliﬁes to give
gξ + ∂ψ
∂t = 0.
(16.5)
The vertical component of the surface velocity in the linear approximation is just
vz(z = 0, t) = ∂ξ/∂t. Expressing vz in terms of the velocity potential, we then obtain
∂ξ
∂t = vz = ∂ψ
∂z .
(16.6)
Combining this expression with the time derivative of Eq. (16.5), we obtain an equa-
tion for the vertical gradient of ψ in terms of its time derivative:
g ∂ψ
∂z = −∂2ψ
∂t2 .
(16.7)
Finally, substituting Eq. (16.3) into Eq. (16.7) and setting z = 0 [because we derived
Eq. (16.7) only at the water’s surface], we obtain the dispersion relation3 for linearized
gravity waves:
dispersion relation for
gravity waves in water of
arbitrary depth
ω2 = gk tanh(kho).
(16.8)
How do the individual elements of ﬂuid move in a gravity wave? We can answer
this question (Ex. 16.1) by computing the vertical and horizontal components of the
velocity vx = ψ,x, and vz = ψ,z, with ψ given by Eq. (16.3). We ﬁnd that the ﬂuid
elements undergo forward-rotating elliptical motion, as depicted in Fig. 16.1, similar
2.
Actually, a slight variation of the surface pressure is caused by the varying weight of the air above the
surface, but as the density of air is typically ∼10−3 that of water, this correction is very small.
3.
For a discussion of the dispersion relation, phase velocity, and group velocity for waves, see Sec. 7.2.
16.2 Gravity Waves on and beneath the Surface of a Fluid
839

to that for Rayleigh waves on the surface of a solid (Sec. 12.4.2). However, in gravity
waves, the sense of rotation is the same (forward) at all depths, in contrast to reversals
with depth found in Rayleigh waves [cf. the discussion following Eq. (12.62)].
We now consider two limiting cases: deep water and shallow water.
16.2.1
16.2.1 Deep-Water Waves and Their Excitation and Damping
When the water is deep compared to the wavelength of the waves, kho ≫1, the
dispersion relation (16.8) becomes
dispersion relation for
gravity waves in deep
water
ω =

gk.
(16.9)
Thus deep-water waves are dispersive (see Sec. 7.2); their group velocity Vg ≡
dω/dk = 1
2
√g/k is half their phase velocity, Vph ≡ω/k = √g/k. [Note that we
could have deduced the deep-water dispersion relation (16.9), up to a dimensionless
multiplicative constant, by dimensional arguments: The only frequency that can be
dispersion relation from
dimensional argument
constructed from the relevant variables g, k, and ρ is √gk.]
The quintessential example of deep-water waves is waves on an ocean or a lake
before they near the shore, so the water’s depth is much greater than their wavelength.
Such waves, of course, are excited by wind. We have discussed this excitation in
Sec. 14.6.2. There we found that the Kelvin-Helmholtz instability (where air ﬂowing
in a laminar fashion over water would raise waves) is strongly suppressed by gravity,
so this mechanism does not work. Instead, the excitation is by a turbulent wind’s
randomly ﬂuctuating pressures pounding on the water’s surface. Once the waves have
been generated, they can propagate great distances before viscous dissipation damps
them; see Ex. 16.2.
16.2.2
16.2.2 Shallow-Water Waves
For shallow-water waves (kho ≪1), the dispersion relation (16.8) becomes
dispersion relation for
gravity waves in shallow
water
ω =

gho k.
(16.10)
Thus these waves are nondispersive; their phase and group velocities are equal: Vph =
Vg =

gho.
Later, when studying solitons, we shall need two special properties of shallow-
waterwaves.First, whenthedepthofthewaterissmallcomparedwiththewavelength,
but not very small, the waves will be slightly dispersive. We can obtain a correction to
Eq. (16.10) by expanding the tanh function of Eq. (16.8) as tanhx = x −x3/3 + . . . .
The dispersion relation then becomes
ω =

gho

1 −1
6k2h2
o

k.
(16.11)
Second, by computing v = ∇ψ from Eq. (16.3), we ﬁnd that in the shallow-water
limit the water’s horizontal motions are much larger than its vertical motions and are
840
Chapter 16. Waves

essentially independent of depth. The reason, physically, is that the ﬂuid acceleration
is produced almost entirely by a horizontal pressure gradient (caused by spatially
variable water depth) that is independent of height; see Ex. 16.1.
Often shallow-water waves have heights ξ that are comparable to the water’s
undisturbed depth ho, and ho changes substantially from one region of the ﬂow to
another. A familiar example is an ocean wave nearing a beach. In such cases, the
wave equation is modiﬁed by nonlinear and height-dependent effects. In Box 16.3
we derive the equations that govern such waves, and in Ex. 16.3 and Sec. 16.3 we
explore properties of these waves.
BOX 16.3.
NONLINEAR SHALLOW-WATER WAVES
WITH VARIABLE DEPTH
Consider a nonlinear shallow-water wave propagating on a body of water
with variable depth. Let ho(x, y) be the depth of the undisturbed water at
location (x, y), and let ξ(x, y, t) be the height of the wave, so the depth of the
water in the presence of the wave is h = ho + ξ. As in the linear-wave case,
the transverse ﬂuid velocity (vx, vy) inside the water is nearly independent of
height z, so the wave is characterized by three functions ξ(x, y, t), vx(x, y, t),
and vy(x, y, t). These functions are governed by the law of mass conservation
and the inviscid Navier-Stokes equation (i.e., the Euler equation).
The mass per unit area is ρh = ρ(ho + ξ), and the corresponding mass
ﬂux (mass crossing a unit length per unit time) is ρhv = ρ(ho + ξ)v, where
v is the 2-dimensional, horizontal vectorial velocity v = vxex + vyvy. Mass
conservation, then, requires that ∂[ρ(ho + ξ)]/∂t + (2)∇. [ρ(ho + ξ)v]= 0,
where (2)∇is the 2-dimensional gradient operator that acts solely in the
horizontal (x-y) plane. Since ρ is constant, and ho is time independent, this
expression becomes
∂ξ/∂t + (2)∇. [(ho + ξ)v]= 0.
(1a)
The Euler equation for v at an arbitrary height z in the water is
∂v/∂t + (v . (2)∇)v = −(1/ρ)(2)∇P , and hydrostatic equilibrium gives
the pressure as the weight per unit area of the overlying water: P = g(ξ −z)ρ
(where height z is measured from the water’s undisturbed surface). Combining
these equations, we obtain
∂v/∂t + (v . (2)∇)v + g (2)∇ξ = 0.
(1b)
Equations (1) are used, for example, in theoretical analyses of tsunamis
(Ex. 16.3).
16.2 Gravity Waves on and beneath the Surface of a Fluid
841

EXERCISES
Exercise 16.1 Example: Fluid Motions in Gravity Waves
(a) Show that in a gravity wave in water of arbitrary depth (deep, shallow, or in be-
tween), each ﬂuid element undergoes forward-rolling elliptical motion as shown
in Fig. 16.1. (Assume that the amplitude of the water’s displacement is small com-
pared to a wavelength.)
(b) Calculate the longitudinal diameter of the motion’s ellipse, and the ratio of vertical
to longitudinal diameters, as functions of depth.
(c) Show that for a deep-water wave, kho ≫1, the ellipses are all circles with diame-
ters that die out exponentially with depth.
(d) We normally think of a circular motion of ﬂuid as entailing vorticity, but a
gravity wave in water has vanishing vorticity. How can this vanishing vorticity
be compatible with the circular motion of ﬂuid elements?
(e) Show that for a shallow-water wave, kho ≪1, the motion is (nearly) horizontal
and is independent of height z.
(f) Computetheﬂuid’spressureperturbationδP (x, z, t)insidetheﬂuidforarbitrary
depth.Showthat, forashallow-waterwave, thepressureisdeterminedbytheneed
to balance the weight of the overlying ﬂuid, but for greater depth, vertical ﬂuid
accelerations alter this condition of weight balance.
Exercise 16.2 Problem: Viscous Damping of Deep-Water Waves
(a) Show that viscosity damps a monochromatic deep-water wave with an amplitude
e-folding time τ∗= (2νk2)−1, where k is the wave number, and ν is the kinematic
viscosity.[Hint:ComputetheenergyE inthewaveandtherateoflossofenergyto
viscous heating ˙E, and argue that τ∗= −2E/ ˙E. Recall the discussions of energy
in Sec. 13.5.5 and viscous heating in Sec. 13.7.4.]
(b) As an example, consider the ocean waves that one sees at an ocean beach when
the surf is “up” (large-amplitude waves). These are usually generated by turbulent
winds in storms in the distant ocean, 1,000 km or farther from shore. The shortest
wavelengths present should be those for which the damping length Cτ∗is about
1,000 km; shorter wavelengths than that will have been dissipated before reaching
shore. Using the turbulent viscosity ν ∼0.03 m2 s−1 that we deduced from the
observed thicknesses of wind-driven Ekman layers in the ocean (Ex. 14.21),
compute this shortest wavelength for the large-amplitude waves, and compare
with the wavelengths you have observed at an ocean beach. You should get pretty
good agreement, thanks to a weak sensitivity of the wavelength to the rather
uncertain turbulent viscosity.
(c) Make similar comparisons of theory and observation for (i) the choppy, short-
wavelength ocean waves that one sees when (and only when) a local wind is
blowing, and (ii) waves on a small lake.
842
Chapter 16. Waves

Exercise 16.3 Example: Shallow-Water Waves with Variable Depth; Tsunamis4
Consider small-amplitude (linear) shallow-water waves in which the height of the
bottom boundary varies, so the unperturbed water’s depth is variable: ho = ho(x, y).
(a) Usingthetheoryofnonlinearshallow-waterwaveswithvariabledepth(Box16.3),
show that the wave equation for the perturbation ξ(x, y, t) of the water’s height
takes the form
∂2ξ
∂t2 −(2)∇. (gho
(2)∇ξ) = 0.
(16.12)
Here (2)∇is the 2-dimensional gradient operator that acts in the horizontal (i.e.,
x-y) plane. Note that gho is the square of the wave’s propagation speed C2 (phase
speed and group speed), so this equation takes the same form as Eq. (7.17) from
the geometric-optics approximation in Sec. 7.3.1, with W = 1.
(b) Describe what happens to the direction of propagation of a wave as the depth ho
of the water varies (either as a set of discrete jumps in ho or as a slowly varying
ho). As a speciﬁc example, how must the propagation direction change as waves
approach a beach (but when they are sufﬁciently far out from the beach that
nonlinearities have not yet caused them to begin to break)? Compare with your
own observations at a beach.
(c) Tsunamis are gravity waves with enormous wavelengths (∼100 km or so) that
propagate on the deep ocean. Since the ocean depth is typically ho ∼4 km,
tsunamis are governed by the shallow-water wave equation (16.12). What would
youhavetodototheoceanﬂoortocreatealensthatwouldfocusatsunami, gener-
atedbyanearthquakenearJapan, sothatitdestroysLosAngeles?(Forsimulations
of tsunami propagation, see, e.g., http://bullard.esc.cam.ac.uk/~taylor/Tsunami
.html.)
(d) The height of a tsunami, when it is in the ocean with depth ho ∼4 km, is only
∼1m or less. Use the geometric-optics approximation (Sec. 7.3) to show that
the tsunami’s wavelength decreases as λ ∝

ho and its amplitude increases as
max(ξ) ∝1/ho
1/4 as the tsunami nears land and the water’s depth ho decreases.
Howhigh[max(ξ)]doesthetsunamigetwhennonlinearitiesbecomestrongly
important? (Assume a height of 1 m in the deep ocean.) How does this compare
with the heights of historically disastrous tsunamis when they hit land? From
your answer you should conclude that the nonlinearities must play a major role
in raising the height. Equations (16.11) in Box 16.3 are used by geophysicists to
analyze this nonlinear growth of the tsunami height. If the wave breaks, then
these equations fail, and ideas developed (in rudimentary form) in Ex. 17.10
must be used.
4.
Exercise courtesy of David Stevenson.
16.2 Gravity Waves on and beneath the Surface of a Fluid
843

16.2.3
16.2.3 Capillary Waves and Surface Tension
surface tension
When the wavelength is short (so k is large), we must include the effects of surface ten-
sion on the surface boundary condition. Surface tension can be treated as an isotropic
force per unit length, γ , that lies in the surface and is unaffected by changes in the
shape or size of the surface; see Box 16.4. In the case of a gravity wave traveling in the
x direction, this tension produces on the ﬂuid’s surface a net downward force per unit
area −γ d2ξ/dx2 = γ k2ξ, where k is the horizontal wave number. [This downward
force is like that on a violin string; cf. Eq. (12.29) and associated discussion.] This
additional force must be included as an augmentation of ρgξ. Correspondingly, the
effect of surface tension on a mode with wave number k is simply to change the true
acceleration of gravity to an effective acceleration of gravity:
g →g + γ k2
ρ .
(16.13)
The remainder of the derivation of the dispersion relation for deep-water gravity
waves carries over unchanged, and the dispersion relation becomes
BOX 16.4.
SURFACE TENSION
In a water molecule, the two hydrogen atoms stick out from the larger oxygen
atom somewhat like Mickey Mouse’s ears, with an H-O-H angle of 105°. This
asymmetry of the molecule gives rise to a large electric dipole moment. In the
interior of a body of water the dipole moments are oriented rather randomly,
but near the water’s surface they tend to be parallel to the surface and bond
with one another to create surface tension—a macroscopically isotropic, 2-
dimensional tension force (force per unit length) γ that is conﬁned to the
water’s surface.
L
x
y
z
(a)
(b)
P
γ
γ
More speciﬁcally, consider a line L of unit length in the water’s surface
[drawing (a)]. The surface water on one side of L exerts a tension (pulling)
force on the surface water on the other side. The magnitude of this force is γ ,
and it is orthogonal to the line L regardless of L’s orientation. This behavior is
analogous to an isotropic pressure P in 3 dimensions, which acts orthogonally
across any unit area.
(continued)
844
Chapter 16. Waves

BOX 16.4.
(continued)
Choose a point P in the water’s surface, and introduce local Cartesian
coordinates there with x and y lying in the surface and z orthogonal to it
[drawing (b)]. In this coordinate system, the 2-dimensional stress tensor
associated with surface tension has components (2)T xx = (2)T yy = −γ ,
analogous to the 3-dimensional stress tensor for an isotropic pressure:
Txx = Tyy = Tzz = P. Wecanalsousea3-dimensionalstresstensortodescribe
the surface tension: Txx = Tyy = −γ δ(z); all other Tjk = 0. If we integrate
this 3-dimensional stress tensor through the water’s surface, we obtain the 2-
dimensional stress tensor:

Tjkdz =(2) Tjk (i.e.,

Txxdz =

Tyydz = −γ ).
The 2-dimensional metric of the surface is (2)g = g −ez ⊗ez; in terms of
this 2-dimensional metric, the surface tension’s 3-dimensional stress tensor is
T = −γ δ(z)(2)g.
Water is not the only ﬂuid that exhibits surface tension; all ﬂuids do so, at
the interfaces between themselves and other substances. For a thin ﬁlm (e.g.,
a soap bubble), there are two interfaces (the top and bottom faces of the ﬁlm),
so if we ignore the ﬁlm’s thickness, its stress tensor is twice as large as for a
single surface, T = −2γ δ(z)(2)g.
The hotter the ﬂuid, the more randomly its surface molecules will be
oriented (and hence the smaller the ﬂuid’s surface tension γ will be). For
water, γ varies from 75.6 dyne/cm at T = 0 °C, to 72.0 dyne/cm at T = 25 °C,
to 58.9 dyne/cm at T = 100 °C.
In Exs. 16.4–16.6, we explore some applications of surface tension. In Sec.
16.2.3 and Exs. 16.7 and 16.8, we consider the inﬂuence of surface tension on
water waves. In Ex. 5.14, we study the statistical thermodynamics of surface
tension and its role in the nucleation of water droplets in clouds and fog.
ω2 = gk + γ k3
ρ
(16.14)
[cf. Eqs. (16.9) and (16.13)]. When the second term dominates, the waves are some-
dispersion relation for
gravity waves in deep
water with surface tension
capillary waves
times called capillary waves. In Exs. 16.7 and 16.8 we explore some aspects of capillary
waves. In Exs. 16.4–16.6 we explore some other aspects of surface tension.
EXERCISES
Exercise 16.4 Problem: Maximum Size of a Water Droplet
What is the maximum size of water droplets that can form by water very slowly
dripping out of a syringe? Out of a water faucet (whose opening is far larger than
that of a syringe)?
16.2 Gravity Waves on and beneath the Surface of a Fluid
845

Exercise 16.5 Problem: Force Balance for an Interface between Two Fluids
Consider a point P in the curved interface between two ﬂuids. Introduce Cartesian
coordinates at P with x and y parallel to the interface and z orthogonal [as in
diagram (b) in Box 16.4], and orient the x- and y-axes along the directions of the
interface’s principal curvatures, so the local equation for the interface is
z = x2
2R1
+ y2
2R2
.
(16.15)
Here R1 and R2 are the surface’s principal radii of curvature at P; note that each of
them can be positive or negative, depending on whether the surface bends up or down
along their directions. Show that, in equilibrium, stress balance, ∇. T = 0, for the
surface implies that the pressure difference across the surface is
P = γ
 1
R1
+ 1
R2

,
(16.16)
where γ is the surface tension.
Exercise 16.6 Challenge: Minimum Area of a Soap Film
For a soap ﬁlm that is attached to a bent wire (e.g., to the circular wire that a child uses
to blow a bubble), the air pressure on the ﬁlm’s two sides is the same. Therefore, Eq.
(16.16) (with γ replaced by 2γ , since the ﬁlm has two faces) tells us that at every point
in the ﬁlm, its two principal radii of curvature must be equal and opposite: R1 = −R2.
It is an interesting exercise in differential geometry to show that this requirement
means that the soap ﬁlm’s surface area is an extremum with respect to variations of the
ﬁlm’s shape, holding its boundary on the wire ﬁxed. If you know enough differential
geometry, prove this extremal-area property of soap ﬁlms, and then show that for the
ﬁlm’s shape to be stable, its extremal area must actually be a minimum.
Exercise 16.7 Problem: Capillary Waves
Consider deep-water gravity waves of short enough wavelength that surface tension
must be included, so the dispersion relation is Eq. (16.14). Show that there is a
minimum value of the group velocity, and ﬁnd its value together with the wavelength
of the associated wave. Evaluate these for water (γ ∼0.07 N m−1 = 70 dyne/cm). Try
performing a crude experiment to verify this phenomenon.
Exercise 16.8 Example: Boat Waves
A toy boat moves with uniform velocity u across a deep pond (Fig. 16.2). Consider the
wave pattern (time-independent in the boat’s frame) produced on the water’s surface
at distances large compared to the boat’s size. Both gravity waves and surface-tension
(capillary) waves are excited. Show that capillary waves are found both ahead of and
behind the boat, whereas gravity waves occur solely inside a trailing wedge. More
speciﬁcally, do the following.
846
Chapter 16. Waves

gravity waves
u
Vgo
P
Q
φ
θ
θgw
FIGURE 16.2 Capillary and gravity waves excited by a small
boat (Ex. 16.8).
(a) In the rest frame of the water, the waves’ dispersion relation is Eq. (16.14). Change
notation so that ω is the waves’ angular velocity as seen in the boat’s frame, and
ωo in the water’s frame, so the dispersion relation becomes ω2
o = gk + (γ/ρ)k3.
Use the Doppler shift (i.e., the transformation between frames) to derive the boat-
frame dispersion relation ω(k).
(b) The boat radiates a spectrum of waves in all directions. However, only those
with vanishing frequency in the boat’s frame, ω = 0, contribute to the time-
independent (stationary) pattern. As seen in the water’s frame and analyzed in
the geometric-optics approximation of Chap. 7, these waves are generated by the
boat (at points along its horizontal dash-dot trajectory in Fig. 16.2) and travel
outward with the group velocity Vgo. Regard Fig. 16.2 as a snapshot of the boat
and water at a particular moment of time. Consider a wave that was generated at
an earlier time, when the boat was at location P, and that traveled outward from
there with speed Vgo at an angle φ to the boat’s direction of motion. (You may
restrict yourself to 0 ≤φ ≤π/2.) Identify the point Q that this wave has reached,
at the time of the snapshot, by the angle θ shown in the ﬁgure. Show that θ is
given by
tan θ =
Vgo(k) sin φ
u −Vgo(k) cos φ ,
(16.17a)
where k is determined by the dispersion relation ω0(k) together with the vanish-
ing ω condition:
ω0(k, φ) = uk cos φ.
(16.17b)
(c) Specialize to capillary waves [k ≫√gρ/γ ]. Show that
tan θ =
3 tan φ
2 tan2 φ −1.
(16.18)
16.2 Gravity Waves on and beneath the Surface of a Fluid
847

Demonstrate that the capillary-wave pattern is present for all values of θ (includ-
ing in front of the boat, π/2 < θ < π, and behind it, 0 ≤θ ≤π/2).
(d) Next, specialize to gravity waves, and show that
tan θ =
tan φ
2 tan2 φ + 1.
(16.19)
Demonstrate that the gravity-wave pattern is conﬁned to a trailing wedge with
angles θ < θgw = sin−1(1/3) = 19.47o (cf. Fig. 16.2). You might try to reproduce
these results experimentally.
16.2.4
16.2.4 Helioseismology
The Sun provides an excellent example of the excitation of small-amplitude waves in a
ﬂuid body. In the 1960s, Robert Leighton and colleagues at Caltech discovered that the
surface of the Sun oscillates vertically with a period of roughly 5 min and a speed of
∼1 km s−1. This motion was thought to be an incoherent surface phenomenon until
it was shown that the observed variation was, in fact, the superposition of thousands
of highly coherent wave modes excited in the Sun’s interior—normal modes of the
Sun. Present-day techniques allow surface velocity amplitudes as small as 2 mm s−1
to be measured, and phase coherence for intervals as long as a year has been observed.
StudyingthefrequencyspectrumanditsvariationprovidesauniqueprobeoftheSun’s
interior structure, just as the measurement of conventional seismic waves (Sec. 12.4)
probes Earth’s interior.
The description of the Sun’s normal modes requires some modiﬁcation of our
treatment of gravity waves. We eschew the details and just outline the principles—
which are rather similar to those for normal modes of a homogeneous elastic sphere
(Sec. 12.4.4 and Ex. 12.12). First, the Sun is (very nearly) spherical. We therefore
properties of the Sun that
inﬂuence its helioseismic
modes
work in spherical polar coordinates rather than Cartesian coordinates. Second, the
Sun is made of hot gas, and it is no longer a good approximation to assume that
the ﬂuid is incompressible. We must therefore replace the equation ∇. v = 0 with
the full equation of continuity (mass conservation) together with the equation of
energy conservation, which governs the relationship between the perturbations of
density and pressure. Third, the Sun is not uniform. The pressure and density in
the unperturbed gas vary with radius in a known manner and must be included.
Fourth, the Sun has a ﬁnite surface area. Instead of assuming a continuous spectrum
of waves, we must now anticipate that the boundary conditions will lead to a discrete
spectrum of normal modes. Allowing for these complications, it is possible to derive
a differential equation for the perturbations to replace Eq. (16.7). It turns out that
a convenient dependent variable (replacing the velocity potential ψ) is the pressure
perturbation. The boundary conditions are that the displacement vanish at the center
of the Sun and the pressure perturbation vanish at the surface.
At this point the problem is reminiscent of the famous solution for the eigenfunc-
tions of the Schr¨odinger equation for a hydrogen atom in terms of associated Laguerre
848
Chapter 16. Waves

g10 (l = 2)
p17 (l = 20)
g18 (l = 4)
r/R
r/R
p10 (l = 60)
vr
vr
frequency (mHz)
spherical harmonic degree l
4
3
2
1
0
20
40
60
80
100
120
140
0.0
0.5
1.0 0.0
0.5
1.0
(b)
(a)
FIGURE 16.3 (a) Measured frequency spectrum for solar p modes with different values of the quantum
numbers n and l. The error bars are magniﬁed by a factor of 1,000. The lowest ridge is n = 0, the
next is n = 1, . . . . (b) Sample eigenfunctions for g and p modes labeled by n (subscripts) and l (in
parentheses). The ordinate is the radial velocity, and the abscissa is fractional radial distance from
the Sun’s center to its surface. The solar convection zone is the shaded region at the bottom. Adapted
from Libbrecht and Woodard (1991).
polynomials. The wave frequencies of the Sun’s normal modes are given by the eigen-
values of the differential equation. The corresponding eigenfunctions can be classiﬁed
using three quantum numbers, n, l, m, where n counts the number of radial nodes
in the eigenfunction, and the angular variation of the pressure perturbation is pro-
portional to the spherical harmonic Y m
l (θ, φ). If the Sun were precisely spherical, the
modes with the same n and l but different m would be degenerate, just as is the case for
an atom when there is no preferred direction in space. However, the Sun rotates with
a latitude-dependent period in the range ∼25–30 days, which breaks the degeneracy,
just as an applied magnetic ﬁeld in an atom breaks the degeneracy of the atom’s states
(theZeemaneffect).Fromtheobservedsplittingofthesolar-modespectrum, itispos-
sible to learn about the distribution of rotational angular momentum inside the Sun.
When this problem is solved in detail, it turns out that there are two general classes
of modes. One class is similar to gravity waves, in the sense that the forces that drive
the gas’s motions are produced primarily by gravity (either directly, or indirectly via
ggg modes of the Sun or
other gravitating ﬂuid
spheres
the weight of overlying material producing pressure that pushes on the gas). These
are called g modes. In the second class (known as p modes),5 the pressure forces arise
ppp modes of the Sun or
other gravitating ﬂuid
spheres
mainly from the compression of the ﬂuid just like in sound waves (which we study
in Sec. 16.5). It turns out that the g modes have large amplitudes in the middle of the
Sun, whereas the p modes are dominant in the outer layers (Fig. 16.3b). The reasons
for this are relatively easy to understand and introduce ideas to which we shall return.
5.
There are also formally distinguishable f -modes, which for our purposes are just a subset of the p-
modes.
16.2 Gravity Waves on and beneath the Surface of a Fluid
849

The Sun is a hot body, much hotter at its center (T ∼1.5 × 107 K) than on its sur-
face (T ∼6,000 K). The sound speed C is therefore much greater in its interior, and so
p modes of a given frequency ω can carry their energy ﬂux ∼ρξ2ω2C (Sec. 16.5) with
properties of ppp modes
much smaller amplitudes ξ than near the surface. Therefore the p-mode amplitudes
are much smaller in the center of the Sun than near its surface.
properties of ggg modes
The g modes are controlled by different physics and thus behave differently. The
outer ∼30% (by radius) of the Sun is convective (Chap. 18), because the diffusion of
heat is inadequate to carry the huge amount of nuclear power being generated in the
solar core. The convection produces an equilibrium variation of pressure and density
with radius that are just such as to keep the Sun almost neutrally stable, so that regions
that are slightly hotter (cooler) than their surroundings will rise (sink) in the solar
gravitational ﬁeld. Therefore there cannot be much of a mechanical restoring force
that would cause these regions to oscillate about their average positions, and so the g
modes (which are inﬂuenced almost solely by gravity) have little restoring force and
thus are evanescent in the convection zone; hence their amplitudes decay quickly with
increasing radius there.
We should therefore expect only p modes to be seen in the surface motions, which
is indeed the case. Furthermore, we should not expect the properties of these modes
to be very sensitive to the physical conditions in the core. A more detailed analysis
bears this out.
16.3
16.3 Nonlinear Shallow-Water Waves and Solitons
In recent decades, solitons or solitary waves have been studied intensively in many
different areas of physics. However, ﬂuid dynamicists became familiar with them in
the nineteenth century. In an oft-quoted passage, John Scott-Russell (1844) described
how he was riding along a narrow canal and watched a boat stop abruptly. This
deceleration launched a single smooth pulse of water which he followed on horseback
for 1 or 2 miles, observing it “rolling on a rate of some eight or nine miles an hour,
preserving its original ﬁgure some thirty feet long and a foot to a foot and a half
in height.” This was a soliton—a 1-dimensional, nonlinear wave with ﬁxed proﬁle
traveling with constant speed. Solitons can be observed fairly readily when gravity
waves are produced in shallow, narrow channels. We use the particular example of a
shallow, nonlinear gravity wave to illustrate solitons in general.
16.3.1
16.3.1 Korteweg–de Vries (KdV) Equation
The key to a soliton’s behavior is a robust balance between the effects of dispersion
and those of nonlinearity. When one grafts these two effects onto the wave equation
for shallow-water waves, then to leading order in the strengths of the dispersion
and nonlinearity one gets the Korteweg–de Vries (KdV) equation for solitons. Since
a completely rigorous derivation of the KdV equation is quite lengthy, we content
ourselves with a somewhat heuristic derivation that is based on this grafting process
and is designed to emphasize the equation’s physical content.
850
Chapter 16. Waves

We choose as the dependent variable in our wave equation the height ξ of the
water’s surface above its quiescent position, and we conﬁne ourselves to a plane wave
that propagates in the horizontal x direction, so ξ = ξ(x, t).
Inthelimitofveryweakwaves, ξ(x, t)isgovernedbytheshallow-waterdispersion
relation, ω =

gho k, where ho is the depth of the quiescent water. This dispersion
relation implies that ξ(x, t) must satisfy the following elementary wave equation [cf.
Eq. (16.12)]:
0 = ∂2ξ
∂t2 −gho
∂2ξ
∂x2 =
 ∂
∂t −

gho
∂
∂x
  ∂
∂t +

gho
∂
∂x

ξ.
(16.20)
In the second expression, we have factored the wave operator into two pieces, one
that governs waves propagating rightward, and the other for those moving left-
ward. To simplify our derivation and the ﬁnal wave equation, we conﬁne ourselves
to rightward-propagating waves; correspondingly, we can simply remove the left-
propagation operator, obtaining
∂ξ
∂t +

gho
∂ξ
∂x = 0.
(16.21)
(Leftward-propagating waves are described by this same equation with a change of
sign on one of the terms.)
We now graft the effects of dispersion onto this rightward-wave equation. The
dispersion relation, including the effects of dispersion to leading order, is ω =

gho k(1−1
6k2h2
o) [Eq. (16.11)]. Now, this dispersion relation ought to be derivable
by assuming a variation ξ ∝exp[i(kx −ωt)]and substituting into a generalization of
Eq. (16.21) with corrections that take account of the ﬁnite depth of the channel. We
take a short cut and reverse this process to obtain the generalization of Eq. (16.21)
from the dispersion relation. The result is
∂ξ
∂t +

gho
∂ξ
∂x = −1
6

gho h2
o
∂3ξ
∂x3 ,
(16.22)
as a simple calculation conﬁrms. This is the linearized KdV equation. It incorporates
weak dispersion associated with the ﬁnite depth of the channel but is still a linear
equation, only useful for small-amplitude waves.
Now let us set aside the dispersive correction and tackle the nonlinearity using
the equations derived in Box 16.3. Denoting the depth of the disturbed water by
h = ho + ξ, the nonlinear law of mass conservation [Eq. (1a) of Box 16.3] becomes
∂h
∂t + ∂(hv)
∂x
= 0,
(16.23a)
and the Euler equation [Eq. (1b) of Box 16.3] becomes
∂v
∂t + v ∂v
∂x + g ∂h
∂x = 0.
(16.23b)
16.3 Nonlinear Shallow-Water Waves and Solitons
851

Here we have specialized the equations in Box 16.3 to a 1-dimensional wave in the
channel and to a constant depth ho of the channel’s undisturbed water. Equations
(16.23a) and (16.23b) can be combined to obtain
∂

v −2√gh

∂t
+
2
v −

gh
3 ∂

v −2√gh

∂x
= 0.
(16.23c)
This equation shows that the quantity v −2√gh is constant along characteristics that
propagate with speed v −√gh. (This constant quantity is a special case of a Riemann
invariant, a concept that we study in Sec. 17.4.1.) When (as we require below) the
nonlinearities are modest, so h does not differ greatly from ho and the water speed
v is small, these characteristics propagate leftward, which implies that for rightward-
propagating waves they begin at early times in undisturbed ﬂuid, where v = 0 and
h = ho. Therefore, the constant value of v −2√gh is −2

gho, and correspondingly
in regions of disturbed ﬂuid we have
v = 2
2
gh −

gho
3
.
(16.24)
Substituting this into Eq. (16.23a), we obtain
∂h
∂t +
2
3

gh −2

gho
3 ∂h
∂x = 0.
(16.25)
We next substitute ξ = h −ho and expand to second order in ξ to obtain the ﬁnal
form of our wave equation with nonlinearities but no dispersion:
∂ξ
∂t +

gho
∂ξ
∂x = −3ξ
2
& g
ho
∂ξ
∂x ,
(16.26)
where the term on the right-hand side is the nonlinear correction.
We now have separate dispersive corrections (16.22) and nonlinear corrections
(16.26) to the rightward-wave equation (16.21). Combining the two corrections into
a single equation, we obtain
∂ξ
∂t +

gho
'
1 + 3ξ
2ho
 ∂ξ
∂x + h2
o
6
∂3ξ
∂x3
(
= 0.
(16.27)
Finally, we substitute
rightward moving spatial
coordinate
χ ≡x −

gho t
(16.28)
to transform to a frame moving rightward with the speed of small-amplitude gravity
waves. The result is the full Korteweg–de Vries or KdV equation:
Korteweg–de Vries (KdV)
equation
∂ξ
∂t + 3
2
& g
ho

ξ ∂ξ
∂χ + 1
9h3
o
∂3ξ
∂χ3

= 0.
(16.29)
852
Chapter 16. Waves

–2
–1
0
(a)
(b)
(c)
1
2
–2
–1
0
1
2
–2
–1
0
1
2
ξ
ξ
ξ
χ
χ
χ
1.0
0.8
0.6
0.4
0.2
1.0
0.8
0.6
0.4
0.2
1.0
0.8
0.6
0.4
0.2
FIGURE 16.4 Steepening of a Gaussian wave proﬁle by the nonlinear term in the KdV equation. The
increase of wave speed with amplitude causes the leading part of the proﬁle to steepen with time
(going left to right) and the trailing part to ﬂatten. In the full KdV equation (16.29), this effect can
be balanced by the effect of dispersion, which causes the high-frequency Fourier components in the
wave to travel slightly slower than the low-frequency ones. This allows stable solitons to form.
16.3.2
16.3.2 Physical Effects in the KdV Equation
Before exploring solutions to the KdV equation (16.29), let us consider the physical
effects of its nonlinear and dispersive terms. The second (nonlinear) term
3
2

g/ho ξ∂ξ/∂χ derives from the nonlinearity in the (v . ∇)v term of the Euler
equation. The effect of this nonlinearity is to steepen the leading edge of a wave pro-
ﬁle and ﬂatten the trailing edge (Fig. 16.4). Another way to understand the effect of
this term is to regard it as a nonlinear coupling of linear waves. Since it is nonlinear in
the wave amplitude, it can couple waves with different wave numbers k. For example,
if we have a purely sinusoidal wave ∝exp(ikx), then this nonlinearity leads to the
growth of a ﬁrst harmonic ∝exp(2ikx). Similarly, when two linear waves with spatial
frequencies k and k′ are superposed, this term describes the production of new waves
at the sum and difference of spatial frequencies. We have already met such wave-wave
coupling in our study of nonlinear optics (Chap. 10), and in the route to turbulence
for rotating Couette ﬂow (Fig. 15.16). We meet it again in nonlinear plasma physics
(Chap. 23).
The third term in Eq. (16.29), 1
6

g/ho h3
o ∂3ξ/∂χ3, is linear and is responsible
for a weak dispersion of the wave. The higher-frequency Fourier components travel
with slower phase velocities than do the lower-frequency components. This has two
effects. One is an overall spreading of a wave in a manner qualitatively familiar
from elementary quantum mechanics (cf. Ex. 7.2). For example, in a Gaussian wave
packet with width x, the range of wave numbers k contributing signiﬁcantly to the
proﬁle is k ∼1/x. The spread in the group velocity is then vg ∼k ∂2ω/∂k2 ∼
(gho)1/2h2
o kk [cf. Eq. (16.11)]. The wave packet will then double in size in a time
tspread ∼x
vg
∼
x
ho
2
1
k

gho
.
(16.30)
16.3 Nonlinear Shallow-Water Waves and Solitons
853

(a)
(b)
dispersing
waves
stable solitons
ξ(x, t)
ξ(x, t)
x
x
FIGURE 16.5 Production of stable solitons out of an irregular initial wave proﬁle.
The second effect is that since the high-frequency components travel somewhat
slower than the low-frequency ones, the proﬁle tends to become asymmetric, with
the leading edge less steep than the trailing edge.
Given the opposite effects of these two corrections (nonlinearity makes the wave’s
leading edge steeper; dispersion reduces its steepness), it should not be too surprising
in hindsight that it is possible to ﬁnd solutions to the KdV equation in which non-
linearitybalancesdispersion, sothereisnochangeofshapeasthewavepropagatesand
solitons in which
nonlinearity balances
dispersion
no spreading. What is quite surprising, though, is that these solutions, called solitons,
are very robust and arise naturally out of random initial data. That is to say, if we solve
an initial value problem numerically starting with several peaks of random shape and
size, then although much of the wave will spread and disappear due to dispersion, we
will typically be left with several smooth soliton solutions, as in Fig. 16.5.
16.3.3
16.3.3 Single-Soliton Solution
We can discard some unnecessary algebraic luggage in the KdV equation (16.29) by
transforming both independent variables using the substitutions
ζ = ξ
ho
,
η = 3χ
ho
= 3(x −

gho t)
ho
,
τ = 9
2
& g
ho
t.
(16.31)
The KdV equation then becomes
simpliﬁed form of KdV
equation
∂ζ
∂τ + ζ ∂ζ
∂η + ∂3ζ
∂η3 = 0.
(16.32)
There are well-understood mathematical techniques (see, e.g., Whitham, 1974)
for solving equations like the KdV equation. However, here we just quote solutions
andexploretheirproperties.ThesimplestsolutiontothedimensionlessKdVequation
(16.32) is
single-soliton solution of
KdV equation
ζ = ζ0 sech2
' ζ0
12
1/2 
η −1
3ζ0τ
(
.
(16.33)
854
Chapter 16. Waves

ξo
—
2ho
1 +
(gho)1/2
4ho
3
—
3ξo
χ1/2 = 
1/2
χ
ξ
ξo
FIGURE 16.6 Proﬁle of the single-soliton solution [Eqs. (16.33) and (16.31)] of the KdV
equation. The half-width χ1/2 is inversely proportional to the square root of the peak
height ξo.
This solution, depicted in Fig. 16.6, describes a one-parameter family of stable soli-
tons. For each such soliton (each ζ0), the soliton maintains its shape while propagating
at speed dη/dτ = ζ0/3 relative to a weak wave. By transforming to the rest frame of
the unperturbed water using Eqs. (16.28) and (16.31), we ﬁnd for the soliton’s speed
there:
speed of soliton
dx
dt =

gho

1 + ξo
2ho

.
(16.34)
The ﬁrst term is the propagation speed of a weak (linear) wave. The second term is the
nonlinear correction, proportional to the wave amplitude ξo = hoζo. A “half-width”
of the wave may be deﬁned by setting the argument of the hyperbolic secant to unity.
It is η1/2 = (12/ζo)1/2, corresponding to
half-width of soliton
x1/2 = χ1/2 =
*
4h3
o
3ξo
+1/2
.
(16.35)
The larger the wave amplitude, the narrower its width will be, and the faster it will
propagate (cf. Fig. 16.6).
Let us return to Scott-Russell’s soliton (start of Sec. 16.3). Converting to SI units,
the observed speed was about 4 m s−1, giving an estimate of the depth of the canal
of ho ∼1.6 m. Using the observed half-width x1/2 ∼5 m, we obtain a peak height
ξo ∼0.22 m, somewhat smaller than quoted but within the errors allowing for the
uncertainty in the deﬁnition of the width.
16.3.4
16.3.4 Two-Soliton Solution
One of the most fascinating properties of solitons is the way that two or more waves
interact. The expectation, derived from physics experience with weakly coupled nor-
mal modes, might be that, if we have two well-separated solitons propagating in the
16.3 Nonlinear Shallow-Water Waves and Solitons
855

η
η
η
τ = –9
–25
–20
–15
–10
–5
0
6
4
2
6
4
2
6
4
2
–10
–5
0
5
10
0
5
10
15
20
25
τ = 9
τ = 0
ζ
ζ
ζ
FIGURE 16.7 Two-soliton solution to the dimensionless KdV equation (16.32). This solution describes
two waves well separated at τ →−∞that coalesce and then separate, producing the original two
waves in reverse order at τ →+∞. The notation is that of Eq. (16.36); the values of the parameters
in that equation are η1 = η2 = 0 (so the solitons will merge at position η = 0), α1 = 1, and α2 = 1.4.
same direction with the larger wave chasing the smaller one, then the larger will even-
tually catch up with the smaller, and nonlinear interactions between the two waves
will essentially destroy both, leaving behind a single, irregular pulse that will spread
and decay after the interaction. However, this is not what happens. Instead, the two
waves pass through each other unscathed and unchanged, except that they emerge
from the interaction a bit sooner than they would have had they moved with their
original speeds during the interaction. See Fig. 16.7. We shall not pause to explain
why the two waves survive unscathed, except to remark that there are topological in-
variants in the solution that must be preserved. However, we can exhibit one such
two-soliton solution analytically:
two-soliton solution of
KdV equation
ζ = ∂2
∂η2[12 ln F(η, τ)],
where F = 1 + f1 + f2 +
α2 −α1
α2 + α1
2
f1f2,
and fi = exp[−αi(η −ηi) + α3
i τ],
i = 1, 2;
(16.36)
here αi and ηi are constants. This solution is depicted in Fig. 16.7.
16.3.5
16.3.5 Solitons in Contemporary Physics
Solitons were rediscovered in the 1960s when they were found in numerical sim-
ulations of plasma waves. Their topological properties were soon understood, and
general methods to generate solutions were derived. Solitons have been isolated in
such different subjects as the propagation of magnetic ﬂux in a Josephson junction,
elastic waves in anharmonic crystals, quantum ﬁeld theory (as instantons), and classi-
calgeneralrelativity(assolitary, nonlineargravitationalwaves).Mostclassicalsolitons
are solutions to one of a relatively small number of nonlinear partial differential equa-
some equations with
soliton solutions
tions, including the KdV equation, the nonlinear Schr¨odinger equation (which governs
856
Chapter 16. Waves

solitons in optical ﬁbers; Sec. 10.8.3), Burgers equation,and the sine-Gordon equation.
Unfortunately, it has proved difﬁcult to generalize these equations and their soliton
solutions to 2 and 3 spatial dimensions.
Just like research into chaos (Sec. 15.6), studies of solitons have taught physicists
that nonlinearity need not lead to maximal disorder in physical systems, but instead
can create surprisingly stable, ordered structures.
EXERCISES
Exercise 16.9 Example: Breaking of a Dam
Consider the ﬂow of water along a horizontal channel of constant width after a dam
breaks.Sometimeaftertheinitialtransientshavediedaway6 theﬂowmaybedescribed
by the nonlinear, unidirectional, shallow-water wave equations (16.23a) and (16.23b):
∂h
∂t + ∂(hv)
∂x
= 0,
∂v
∂t + v ∂v
∂x + g ∂h
∂x = 0.
(16.37)
Here h is the height of the ﬂow, v is the horizontal speed of the ﬂow, and x is distance
along the channel measured from the location of the dam. Solve for the ﬂow, assuming
that initially (at t = 0) h = ho for x < 0 and h = 0 for x > 0 (no water). Your solution
should have the form shown in Fig. 16.8. What is the speed of the front of the water?
[Hint: From the parameters of the problem we can construct only one velocity,

gho,
and no length except ho. It therefore is a reasonable guess that the solution has the self-
similar form h = ho ˜h(ξ), v =

gho ˜v(ξ), where ˜h and ˜v are dimensionless functions
of the similarity variable
ξ = x/t

gho
.
(16.38)
h
ho
x
t = 0
1
2
3
FIGURE 16.8 The water’s height h(x, t) after a
dam breaks.
6.
In the idealized case that the dam is removed instantaneously, there are no transients, and Eqs. (16.37)
describe the ﬂow from the outset.
16.3 Nonlinear Shallow-Water Waves and Solitons
857

Using this ansatz, convert the partial differential equations (16.37) into a pair of
ordinarydifferentialequationsthatcanbesolvedsoastosatisfytheinitialconditions.]
Exercise 16.10 Derivation: Single-Soliton Solution
Verify that expression (16.33) does indeed satisfy the dimensionless KdV equation
(16.32).
Exercise 16.11 Derivation: Two-Soliton Solution
(a) Verify, using symbolic-manipulation computer software (e.g., Maple, Matlab, or
Mathematica) that the two-soliton expression (16.36) satisﬁes the dimensionless
KdV equation. (Warning: Considerable algebraic travail is required to verify this
by hand directly.)
(b) Verifyanalyticallythatthetwo-solitonsolution(16.36)hasthepropertiesclaimed
in the text. First consider the solution at early times in the spatial region where
f1 ∼1, f2 ≪1. Show that the solution is approximately that of the single soliton
described by Eq. (16.33). Demonstrate that the amplitude is ζ01 = 3α2
1, and ﬁnd
the location of its peak. Repeat the exercise for the second wave and for late
times.
(c) Use a computer to follow numerically the evolution of this two-soliton so-
lution as time η passes (thereby ﬁlling in timesteps between those shown in
Fig. 16.7).
16.4
16.4 Rossby Waves in a Rotating Fluid
Coriolis force as restoring
force for Rossby waves
In a nearly rigidly rotating ﬂuid with the rotational angular velocity  parallel or
antiparallel to the acceleration of gravity g = −gez, the Coriolis effect observed in
the co-rotating reference frame (Sec. 14.5) provides the restoring force for an unusual
type of wave motion called Rossby waves. These waves are seen in Earth’s oceans
and atmosphere [with  = (Earth’s rotational angular velocity) sin(latitude)ez; see
Box 14.5].
For a simple example, we consider the sea above a sloping seabed; Fig. 16.9.
We assume the unperturbed ﬂuid has vanishing velocity v = 0 in Earth’s rotating
frame, and we study weak waves in the sea with oscillating velocity v. (Since the
ﬂuid is at rest in the equilibrium state about which we are perturbing, we write the
perturbed velocity as v rather than δv.) We assume that the wavelengths are long
enough that viscosity and surface tension are negligible. In this case we also restrict
attention to small-amplitude waves, so that nonlinear terms can be dropped from the
dynamical equations. The perturbed Navier-Stokes equation (14.56a) then becomes
(after linearization)
∂v
∂t + 2 × v = −∇δP ′
ρ
.
(16.39)
858
Chapter 16. Waves

z
y

α
h
FIGURE 16.9 Geometry of the sea for Rossby waves.
Here, as in Sec. 14.5, δP ′ is the perturbation in the effective pressure [which includes
gravitational and centrifugal effects: P ′ = P + ρ −1
2ρ( × x)2]. Taking the curl
of Eq. (16.39), we obtain for the time derivative of the waves’ vorticity:
∂ω
∂t = 2( . ∇)v.
(16.40)
We seek a wave mode with angular frequency ω (not to be confused with vorticity ω)
and wave number k, in which the horizontal ﬂuid velocity oscillates in the x direction
and (in accord with the Taylor-Proudman theorem; Sec. 14.5.3) is independent ofz, so
vx and vy ∝exp[i(kx −ωt)],
∂vx
∂z =
∂vy
∂z = 0.
(16.41)
The only allowed vertical variation is in the vertical velocity vz; differentiating
∇. v = 0 with respect to z, we obtain
∂2vz
∂z2 = 0.
(16.42)
The vertical velocity therefore varies linearly between the surface and the sea ﬂoor
(Fig. 16.9). One boundary condition is that the vertical velocity must vanish at the
sea’s surface. The other is that at the sea ﬂoor z = −h, we must have vz(−h) = −αvy,
where α is the tangent of the angle of inclination of the sea ﬂoor. The solution to
Eq. (16.42) satisfying these boundary conditions is
vz = αz
h vy.
(16.43)
Taking the vertical component of Eq. (16.40) and evaluating ωz = vy,x −vx,y =
ikvy, we obtain
ωkvy = 2∂vz
∂z =
2αvy
h
.
(16.44)
The dispersion relation therefore has the quite unusual form ω ∝1/k:
dispersion relation for
Rossby waves
ωk = 2α
h .
(16.45)
16.4 Rossby Waves in a Rotating Fluid
859

Rossby waves have interesting properties. They can only propagate in one
properties of Rossby
waves
direction—parallel to the intersection of the sea ﬂoor with the horizontal (our ex
direction). Their phase velocity Vph and group velocity Vg are equal in magnitude
but opposite in direction:
Vph = −Vg = 2α
k2h ex.
(16.46)
Using ∇. v = 0, we discover that the two components of horizontal velocity are in
quadrature: vx = iαvy/(kh). This means that the ﬂuid circulates in the opposite sense
to the angular velocity .
Rossby waves play an important role in the circulation of Earth’s oceans (see, e.g.,
Chelton and Schlax, 1996). A variant of these Rossby waves in air can be seen as
undulations in the atmosphere’s jet stream, produced when the stream goes over
a sloping terrain, such as that of the Rocky Mountains. Another variant found in
neutron stars, called “r modes,” generates gravitational waves (ripples of spacetime
curvature) that are a promising source for ground-based gravitational-wave detectors,
such as LIGO.
EXERCISES
Exercise 16.12 Example: Rossby Waves in a Cylindrical Tank with a Sloping Bottom
In the ﬁlm Fultz (1969), about 20 min 40 s into the ﬁlm, an experiment is described
in which Rossby waves are excited in a rotating cylindrical tank with inner and outer
vertical walls and a sloping bottom. Figure 16.10a is a photograph of the tank from
the side, showing its bottom, which slopes upward toward the center, and a hump
on the bottom that generates the Rossby waves. The tank is ﬁlled with water, then
set into rotation with an angular velocity . The water is given time to settle down
into rigid rotation with the cylinder. Then the cylinder’s angular velocity is reduced
by a small amount, so the water is rotating at angular velocity  ≪ relative to the
cylinder. As the water passes over the hump on the tank bottom, the hump generates
Rossby waves. Those waves are made visible by injecting dye at a ﬁxed radius through
a syringe attached to the tank. Figure 16.10b is a photograph of the dye trace as seen
looking down on the tank from above. If there were no Rossby waves present, the
trace would be circular. The Rossby waves make it pentagonal. In this exercise you
will work out the details of the Rossby waves, explore their physics, and explain the
shape of the trace.
Because the slope of the bottom is cylindrical rather than planar, this is somewhat
different from the situation discussed in the text (see Fig. 16.9). However, we can
deduce the details of the waves in this cylindrical case from those for the planar case by
using geometric-optics considerations (Sec. 7.3), making modest errors because the
wavelengthofthewavesisnotallthatsmallcomparedtothecircumferenceofthetank.
(a) Using geometric optics, show that the rays along which the waves propagate are
circles centered on the tank’s symmetry axis.
860
Chapter 16. Waves

(a)
(b)
FIGURE 16.10 Rossby waves in a rotating cylinder with sloping bottom. (a) Side view. (b) Top
view, showing dye trace. Images from NCFMF Book of Film Notes,1972; The MIT Press with
Education Development Center, Inc. © 2014 Education Development Center, Inc. Reprinted
with permission with all other rights reserved.
(b) Focus on the ray that is halfway between the inner and outer walls of the tank. Let
its radius be a, the depth of the water there be h, and the slope angle of the tank
ﬂoor be α. Introduce quasi-Cartesian coordinates x = aφ and y = −ϖ, where
{ϖ , φ, z} are cylindrical coordinates. By translating the Cartesian-coordinate
waves of the text into quasi-Cartesian coordinates and noting from Fig. 16.10b
that ﬁve wavelengths must ﬁt into the circumference around the cylinder, show
that the velocity ﬁeld has the form vϖ , vφ, vz ∝ei(5φ+ωt), and deduce the ratios of
the three components of velocity to one another. The solution has nonzero radial
velocityatthewalls—a warningthat edge effects will modify the waves somewhat.
This analysis ignores those edge effects.
(c) Because the waves are generated by the ridge on the bottom of the tank, the wave
pattern must remain at rest relative to that ridge, which means it must rotate
relative to the ﬂuid’s frame with the angular velocity dφ/dt = −. From the
waves’ dispersion relation, deduce / (the fractional slowdown of the tank
that had to be imposed to generate the observed pentagonal wave).
(d) Compute the displacement ﬁeld δx(ϖ , φ, z, t) of a ﬂuid element whose undis-
placed location (in the rigidly rotating cylindrical coordinates) is (ϖ , φ, z). Ex-
plain the pentagonal shape of the movie’s dye lines in terms of this displacement
ﬁeld.
(e) Compute the wave’s vertical vorticity ﬁeld ωz (relative to the rigidly rotating ﬂow),
and show that as a ﬂuid element moves and the vertical vortex line through it
shortens or lengthens due to the changing water depth, ωz changes proportionally
to the vortex line’s length.
16.4 Rossby Waves in a Rotating Fluid
861

16.5
16.5 Sound Waves
So far our discussion of ﬂuid dynamics has mostly been concerned with ﬂows sufﬁ-
ciently slow that the density can be treated as constant. We now introduce the effects
of compressibility in the context of sound waves (in a nonrotating reference frame).
Sound waves are prototypical scalar waves and therefore are simpler in many respects
than vector electromagnetic waves and tensor gravitational waves.
Consider a small-amplitude sound wave propagating through a homogeneous,
time-independent ﬂuid. The wave’s oscillations are generally quick compared to the
time for heat to diffuse across a wavelength, so the pressure and density perturbations
are adiabatically related:
δP = C2δρ,
(16.47)
where
adiabatic sound speed
C ≡
∂P
∂ρ

s
1/2
,
(16.48)
which will turn out to be the wave’s propagation speed—the speed of sound. The
perturbation of the ﬂuid velocity (which we denote v, since the unperturbed ﬂuid is
static) is related to the pressure perturbation by the linearized Euler equation:
∂v
∂t = −∇δP
ρ
.
(16.49a)
A second relation between v and δP can be obtained by combining the linearized law
of mass conservation, ∂ρ/∂t = −ρ∇. v, with the adiabatic pressure-density relation
(16.47):
∇. v = −
1
ρ C2
∂δP
∂t .
(16.49b)
By equating the divergence of Eq. (16.49a) to the time derivative of Eq. (16.49b), we
obtain a simple, dispersion-free wave equation for the pressure perturbation:
wave equation for sound
waves
 ∂2
∂t2 −C2∇2

δP = 0.
(16.50)
Thus, as claimed, C is the wave’s propagation speed.
For a perfect gas, this adiabatic sound speed is C = (γ P/ρ)1/2, where γ is the
ratio of speciﬁc heats (see Ex. 5.4). The sound speed in air at 20 °C is 343 m s−1. In
water under atmospheric conditions, it is about 1.5 km s−1 (not much different from
sound speeds in solids).
Because the vorticity of the unperturbed ﬂuid vanishes and the wave contains no
vorticity-producingforces, thewave’svorticityvanishes:∇× v = 0.Thispermitsusto
expressthewave’svelocityperturbationasthegradientofavelocitypotential:v = ∇ψ.
862
Chapter 16. Waves

Inserting this expression into the perturbed Euler equation (16.49a), we express the
pressure perturbation in terms of ψ:
velocity potential for
sound waves
δP = −ρ ∂ψ
∂t ,
where
v = ∇ψ.
(16.51)
The ﬁrst of these relations guarantees that ψ satisﬁes the same wave equation as δP :
 ∂2
∂t2 −C2∇2

ψ = 0.
(16.52)
It is sometimes useful to describe the wave by its oscillating pressure δP and some-
times by its oscillating potential ψ.
The general solution of the wave equation (16.52) for plane sound waves propa-
gating in the ±x directions is
ψ = f1(x −Ct) + f2(x + Ct),
(16.53)
where f1 and f2 are arbitrary functions.
EXERCISES
Exercise 16.13 Problem: Sound Wave in an Inhomogeneous Fluid
Consider a sound wave propagating through a static, inhomogeneous ﬂuid with no
gravity. Explain why the unperturbed ﬂuid has velocity v = 0 and pressure Po =
constant, but can have variable density and sound speed, ρo(x) and C(x, t). By repeat-
ing the analysis in Eqs. (16.47)–(16.50), show that the wave equation is ∂2δP/∂t2 =
C2ρo∇.(ρ−1
o ∇δP ), which can be rewritten as
W ∂2δP
∂t2 −∇.(WC2∇δP ) = 0,
(16.54)
where W = (C2ρo)−1. [Hint: It may be helpful to employ the concept of Lagrangian
versus Eulerian perturbations, as described by Eq. (19.44).] Equation (16.54) is an
example of the prototypical wave equation (7.17) that we used in Sec. 7.3.1 to illustrate
the geometric-optics formalism. The functional form of W and the placement of
W and C2 (inside versus outside the derivatives) have no inﬂuence on the wave’s
dispersion relation or its rays or phase in the geometric-optics limit, but they do
inﬂuence the propagation of the wave’s amplitude. See Sec. 7.3.1.
16.5.1
16.5.1 Wave Energy
In Sec. 7.3.1 and Ex. 7.4, we used formal mathematical techniques to derive the
energy density U and energy ﬂux F [Eqs. (7.18)] associated with waves satisfying the
prototypical wave equation (16.54). In this section, we rederive U and F for sound
16.5 Sound Waves
863

wavesusingaphysical, ﬂuiddynamicalanalysis.Wegetpreciselythesameexpressions
uptoaconstantmultiplicativefactorρ2.Becauseoftheformalnatureofthearguments
leading to Eqs. (7.18), we only had a right to expect the same answer up to some
multiplicative constant.
The ﬂuid’s energy density is U = ( 1
2v2 + u)ρ (Table 13.1 with  = 0). The ﬁrst
term is the ﬂuid’s kinetic energy density; the second is its internal energy density. The
internal energy density can be evaluated by a Taylor expansion in the wave’s density
perturbation:
uρ = [uρ]+
∂(uρ)
∂ρ

s

δρ + 1
2
∂2(uρ)
∂ρ2

s

δρ2,
(16.55)
wherethethreecoefﬁcientsinsquarebracketsareevaluatedattheequilibriumdensity.
The ﬁrst term in Eq. (16.55) is the energy of the background ﬂuid, so we drop it. The
second term averages to zero over a wave period, so we also drop it. The third term can
be simpliﬁed using the ﬁrst law of thermodynamics in the form du = T ds −P d(1/ρ)
(which implies [∂(uρ)/∂ρ]s = u + P/ρ). We then apply the deﬁnition h = u + P/ρ
of enthalpy density, followed by the ﬁrst law in the form dh = T ds + dP/ρ, and then
followed by expression (16.48) for the speed of sound. The result is
∂2(uρ)
∂ρ2

s
=
∂h
∂ρ

s
= C2
ρ .
(16.56)
Inserting this relation into the third term of Eq. (16.55) and averaging over a wave
period and wavelength, we obtain for the wave energy per unit volume U = 1
2ρv2 +
[C2/(2ρ)]δρ2. Using v = ∇ψ [the second of Eqs. (16.51)] and δρ = (ρ/C2)∂ψ/∂t
[from δρ = (∂ρ/∂P )sδP = δP/C2 and the ﬁrst of Eqs. (16.51)], we bring the equa-
tion for Uinto the form
energy density for sound
waves
U = 1
2ρ
⎡
⎣(∇ψ)2 + 1
C2
∂ψ
∂t
2
⎤
⎦= ρ(∇ψ)2.
(16.57)
The second equality can be deduced by multiplying the wave equation (16.52) by
ψ and averaging. Thus, energy is equipartitioned between the kinetic and internal
energy terms.
The energy ﬂux is F = ( 1
2v2 + h)ρv (Table 13.1 with  = 0). The kinetic energy
ﬂux (ﬁrst term) is third order in the velocity perturbation and therefore vanishes on
average. For a sound wave, the internal energy ﬂux (second term) can be brought into
a more useful form by expanding the enthalpy per unit mass:
h = [h]+
 ∂h
∂P

s

δP = [h]+ δP
ρ .
(16.58)
Here we have used the ﬁrst law of thermodynamics dh = T ds + (1/ρ)dP and adia-
baticity of the perturbation (s = const); the terms in square brackets are unperturbed
quantities. Inserting Eq. (16.58) into F = hρv, expressing δP and v in terms of the
864
Chapter 16. Waves

velocity potential [Eqs. (16.51)], and averaging over a wave period and wavelength,
we obtain for the energy ﬂux F = ρhv = δP v, which becomes
energyﬂuxforsoundwaves
F = −ρ
∂ψ
∂t

∇ψ .
(16.59)
Aside from a multiplicative constant factor ρ2, this equation and Eq. (16.57) agree
with Eqs. (7.18) [with ψ there being this chapter’s velocity potential ψ, and with
W = (C2ρ)−1; Eq. (16.54)], which we derived by formal techniques in Sec. 7.3.1 and
Ex. 7.4.
For a locally plane wave with ψ = ψo cos(k . x −ωt + ϕ) (where ϕ is an arbitrary
phase), the energy density (16.57) is U = 1
2ρψ2
ok2, and the energy ﬂux (16.59) is
F = 1
2ρψ2
oωk. Since for this dispersion-free wave, the phase and group velocities
are both V = (ω/k)ˆk = C ˆk (where ˆk = k/k is the unit vector pointing in the wave-
propagation direction), the energy density and ﬂux are related by
F = UV = UC ˆk.
(16.60)
The energy ﬂux is therefore the product of the energy density and the wave velocity,
as it must be [Eq. (7.31), where we see that, if the waves were to have dispersion, it
would be the group velocity that appears in this expression].
The energy ﬂux carried by sound is conventionally measured in dB (decibels). The
ﬂux in decibels, FdB, is related to the ﬂux F in W m−2 by
FdB = 120 + 10 log10(F).
(16.61)
Sound that is barely audible is about 1 dB. Normal conversation is about 50–60 dB.
Jet aircraft, rock concerts, and volcanic eruptions can cause exposure to more than
120 dB, with consequent damage to the ear.
16.5.2
16.5.2 Sound Generation
So far in this book we have been concerned with describing how different types of
waves propagate. It is also important to understand how they are generated. We now
outline some aspects of the theory of sound generation.
The reader should be familiar with the theory of electromagnetic wave emission
(e.g., Jackson, 1999, Chap. 9). For electromagnetic waves one considers a localized
region containing moving charges and varying currents. The source can be described
as a sum over electric and magnetic multipoles, and each multipole produces a char-
acteristic angular variation of the distant radiation ﬁeld. The radiation-ﬁeld ampli-
tude decays inversely with distance from the source, and so the Poynting ﬂux varies
with the inverse square of the distance. Integrating over a large sphere gives the total
power radiated by the source, broken down into the power radiated by each multi-
polar component. The ratio of the power in successive multipole pairs [e.g., (magnetic
dipole power)/(electric dipole power) ∼(electric quadrupole power)/(electric dipole
power)] is typically ∼(b/-λ)2, where b is the size of the source, and -λ = 1/k is the
16.5 Sound Waves
865

waves’ reduced wavelength. When -λ is large compared to b (a situation referred to as
slow motion, since the source’s charges then generally move at speeds ∼(b/-λ)c small
compared to the speed of light c), the most powerful radiating multipole is the electric
dipole d(t), unless it happens to be suppressed. The dipole’s average emitted power is
given by the Larmor formula:
P =
¨d2
6πϵ0c3 ,
(16.62)
where ¨d is the second time derivative of d, the bar denotes a time average, ϵ0 is the
permittivity of free space, and c is the speed of light.
This same procedure can be followed when describing sound generation. How-
ever, as we are dealing with a scalar wave, sound can have a monopolar source. As
a pedagogical example, let us set a small, spherical, elastic ball, surrounded by ﬂuid,
into radial oscillation (not necessarily sinusoidal) with oscillation frequencies of order
ω, so the emitted waves have reduced wavelengths of order -λ = C/ω. Let the surface
of the ball have radius a + ξ(t), and impose the slow-motion and small-amplitude
conditions that
-λ ≫a ≫|ξ|.
(16.63)
As the waves will be spherical, the relevant outgoing-wave solution of the wave
equation (16.52) is
ψ = f (t −r/C)
r
,
(16.64)
where f is a function to be determined. Since the ﬂuid’s velocity at the ball’s surface
must match that of the ball, we have (to ﬁrst order in v and ψ):
˙ξer = v(a, t) = ∇ψ ≃−f (t −a/C)
a2
er ≃−f (t)
a2 er,
(16.65)
where in the third equality we have used the slow-motion condition -λ ≫a. Solving
for f (t) and inserting into Eq. (16.64), we see that
ψ(r, t) = −a2˙ξ(t −r/C)
r
.
(16.66)
It is customary to express the radial velocity perturbation v in terms of an oscil-
lating ﬂuid monopole moment
monopole moment for
spherical sound waves
from an oscillating ball
q = 4πρa2˙ξ.
(16.67)
Physically, thisisthetotalradialdischargeofairmass(i.e., massperunittime)crossing
an imaginary ﬁxed spherical surface of radius slightly larger than that of the oscillating
ball.Intermsofq, wehave ˙ξ(t) = q(t)/[4πρa2].UsingthisexpressionandEq.(16.66),
we compute for the power radiated as sound waves [Eq. (16.59) integrated over a
sphere centered on the ball]:
866
Chapter 16. Waves

P =
˙q2
4πρC .
(16.68)
Note that the power is inversely proportional to the signal speed, which is characteris-
power emitted into
spherical sound waves
tic of monopolar emission and is in contrast to the inverse-cube variation for dipolar
emission [Eq. (16.62)].
The emission of monopolar waves requires that the volume of the emitting solid
body oscillate. When the solid simply oscillates without changing its volume (e.g., the
reed in a musical instrument), dipolar emission usually dominates. We can think of
this as two monopoles of size a in antiphase separated by some displacement b ∼a.
The velocity potential in the far ﬁeld is then the sum of two monopolar contributions,
which almost cancel. Making a Taylor expansion, we obtain
typical multipolar sound-
wave strengths
ψdipole
ψmonopole
∼b
-λ ∼ωb
C ,
(16.69)
where ω and -λ are the characteristic magnitudes of the angular frequency and reduced
wavelength of the waves (which we have not assumed to be precisely sinusoidal).
This reduction of ψ by the slow-motion factor b/-λ implies that the dipolar power
emission is weaker than the monopolar power by a factor ∼(b/-λ)2 for similar fre-
quencies and amplitudes of motion—the same factor as for electromagnetic waves
(see the start of this subsection). However, to emit dipole radiation, momentum must
be given to and removed from the ﬂuid. In other words, the ﬂuid must be forced by
lowest order sound
wave emitted in absence
of solid-body forcing:
quadrupolar
a solid body. In the absence of such a solid body, the lowest multipole that can be
radiated effectively is quadrupolar radiation, which is weaker by yet one more factor
of (b/-λ)2.
sound-wave power from
free turbulence
These considerations are important for understanding how noise is produced
by the intense turbulence created by jet engines, especially close to airports. We
expect that the sound emitted by the free turbulence in the wake just behind the
engine will be quadrupolar and will be dominated by emission from the largest (and
hence fastest) turbulent eddies. (See the discussion of turbulent eddies in Sec. 15.4.4.)
Denote by ℓand vℓthe size and turnover speed of these largest eddies. Then the
characteristic size of the sound’s source is a ∼b ∼ℓ, the mass discharge is q ∼ρℓ2vℓ,
the characteristic frequency is ω ∼vℓ/ℓ, the reduced wavelength of the sound waves
is -λ = C/ω ∼ℓC/vℓ, and the slow-motion parameter is b/-λ ∼ωb/C ∼vℓ/C. The
quadrupolar power radiated per unit volume [Eq. (16.68) divided by the volume ℓ3
of an eddy and reduced by ∼(b/-λ)4] is therefore
dP
d3x ∼ρ v3
ℓ
ℓ
vℓ
C
5
,
(16.70)
and this power is concentrated around frequency ω ∼vℓ/ℓ. For air of ﬁxed sound
speed and lengthscale ℓof the largest eddies, and for which the largest eddy speed vℓ
isproportionaltosomecharacteristicspeedV (e.g., theaveragespeedoftheairleaving
16.5 Sound Waves
867

the engine), Eq. (16.70) says the sound generation increases proportional to the eighth
poweroftheMachnumberM = V/C.ThisisknownasLighthill’slaw(Lighthill1952,
Lighthill’s law for sound
generation by turbulence
1954). The implications for the design of jet engines should be obvious.
EXERCISES
Exercise 16.14 Problem: Attenuation of Sound Waves
Viscosity and thermal conduction will attenuate sound waves. For the moment just
consider a monatomic gas where the bulk viscosity can be neglected.
(a) Consider the entropy equation (13.75), and evaluate the inﬂuence of the heat ﬂux
on the relationship between the pressure and the density perturbations. [Hint:
Assume that all quantities vary as ei(kx−ωt), where k is real and ω complex.]
(b) Consider the momentum equation (13.69), and include the viscous term as a
perturbation.
(c) Combine these two relations in parts (a) and (b), together with the equation of
mass conservation, to solve for the imaginary part of ω in the linear regime.
(d) Substitute kinetic-theory expressions for the coefﬁcient of shear viscosity and
the coefﬁcient of thermal conductivity (Secs. 13.7.3 and 3.7) to obtain a simple
expression for the attenuation length involving the wave’s wavelength and the
atoms’ collisional mean free path.
(e) How do you think the wave attenuation will be affected if the ﬂuid is air or is
turbulent, or both?
See Faber (1995) for more details.
Exercise 16.15 Example: Plucked Violin String
Consider the G string (196 Hz) of a violin. It is ∼30 cm from bridge to nut (the ﬁxed
endpoints), and the tension in the string is ∼40 N.
(a) Infer the mass per unit length in the string and estimate its diameter. Hence
estimatethestraininthestringbeforebeingplucked.Estimatethestrain’sincrease
if its midpoint is displaced through 3 mm.
(b) Now suppose that the string is released. Estimate the speed with which it moves
as it oscillates back and forth.
(c) Estimate the dipolar sound power emitted and the distance out to which the note
can be heard (when its intensity is a few decibels). Do your answers seem reason-
able? What factors, omitted from this calculation, might change your answers?
Exercise 16.16 Example: Trumpet
Idealize the trumpet as a bent pipe of length 1.2 m from the mouthpiece (a node of
the air’s displacement) to the bell (an antinode). The lowest note is a ﬁrst overtone
and should correspond to B ﬂat (233 Hz). Does it?
868
Chapter 16. Waves

Exercise 16.17 Problem: Aerodynamic Sound Generation
Consider the emission of quadrupolar sound waves by a Kolmogorov spectrum of free
turbulence (Sec. 15.4.4). Show that the power radiated per unit frequency interval has
a spectrum
Pω ∝ω−7/2.
Also show that the total power radiated is roughly a fraction M5 of the power dissi-
pated in the turbulence, where M is the Mach number.
16.5.3
16.5.3 Radiation Reaction, Runaway Solutions,
and Matched Asymptotic Expansions
sound waves from radially
oscillating ball
Let us return to our idealized example of sound waves produced by a radially oscillat-
ing, spherical ball. We use this example to illustrate several deep issues in theoretical
physics: the radiation-reaction force that acts back on a source due to its emission
of radiation, a spurious runaway solution to the source’s equation of motion caused
by the radiation-reaction force, and matched asymptotic expansions, a mathematical
technique for solving ﬁeld equations when there are two different regions of space
in which the equations have rather different behaviors.7 These issues also arise, in a
rather more complicated way, in analyses of the electromagnetic radiation reaction
force on an accelerated electron (the “Abraham-Lorentz force”), and the radiation-
reaction force caused by emission of gravitational waves; see the derivation, by Burke
(1971), of gravitational results quoted in Sec. 27.5.3.
For our oscillating ball, the two different regions of space that we match to each
other are the near zone, r ≪-λ, and the wave zone, r >∼-λ.
near zone and wave zone
We consider, ﬁrst, the near zone, and we redo, from a new point of view, the
analysis of the matching of the near-zone ﬂuid velocity to the ball’s surface velocity
and the computation of the pressure perturbation. Because the region near the ball
is small compared to -λ and the ﬂuid speeds are small compared to C, the ﬂow is
very nearly incompressible, ∇. v = ∇2ψ = 0; see the discussion of conditions for
incompressibility in Sec. 13.6. (The near-zone equation ∇2ψ = 0 is analogous to
∇2 = 0 for the Newtonian gravitational potential in the weak-gravity near zone of
a gravitational-wave source; Sec. 27.5.)
The general monopolar (spherical) solution to ∇2ψ = 0 is
ψ = A(t)
r
+ B(t).
(16.71)
Matching the ﬂuid’s radial velocity v = ∂ψ/∂r = −A/r2 at r = a to the ball’s radial
velocity ˙ξ, we obtain
A(t) = −a2˙ξ(t).
(16.72)
7.
Our treatment is based on Burke (1970).
16.5 Sound Waves
869

From the point of view of near-zone physics, no mechanism exists for generating a
nonzero spatially constant term B(t) in ψ [Eq. (16.71)], so if one were unaware of the
emitted sound waves and their action back on the source, one would be inclined to set
B(t) to zero. [This line of reasoning is analogous to that of a Newtonian physicist, who
would be inclined to write the quadrupolar contribution to an axisymmetric source’s
external gravitational ﬁeld in the form  = P2(cos θ)[A(t)r−3 + B(t)r2] and then,
being unaware of gravitational waves and their action back on the source, would set
B(t) to zero.] Taking this near-zone viewpoint, with B = 0, we infer that the ﬂuid’s
pressure perturbation acting on the ball’s surface is
δP = −ρ ∂ψ(a, t)
∂t
= −ρ
˙A
a = ρa¨ξ
(16.73)
[Eqs. (16.51) and (16.72)].
The motion ξ(t) of the ball’s surface is controlled by the elastic restoring forces
in its interior and the ﬂuid pressure perturbation δP on its surface. In the absence
of δP the surface would oscillate sinusoidally with some angular frequency ωo, so
¨ξ + ω2
oξ = 0. The pressure will modify this expression to
m(¨ξ + ω2
oξ) = −4πa2δP ,
(16.74)
where m is an effective mass, roughly equal to the ball’s true mass, and the right-hand
side is the integral of the radial component of the pressure perturbation force over the
sphere’s surface. Inserting the near-zone viewpoint’s pressure perturbation (16.73), we
obtain
(m + 4πa3ρ)¨ξ + mω2
oξ = 0.
(16.75)
Evidently, the ﬂuid increases the ball’s effective inertial mass (it loads additional mass
on the ball) and thereby reduces its frequency of oscillation to
ω =
ωo
√1 + κ
,
where κ = 4πa3ρ
m
(16.76)
is a measure of the coupling strength between the ball and the ﬂuid. In terms of this
loaded frequency, the equation of motion becomes
¨ξ + ω2ξ = 0.
(16.77)
This near-zone viewpoint is not quite correct, just as the standard Newtonian
viewpoint is not quite correct for the near-zone gravity of a gravitational-wave source
(Sec. 27.5.3). To improve on this viewpoint, we temporarily move out into the wave
zone and identify the general, outgoing-wave solution to the sound wave equation:
ψ = f (t −ϵr/C)
r
(16.78)
[Eq. (16.64)]. Here f is a function to be determined by matching to the near zone,
and ϵ is a parameter that has been inserted to trace the inﬂuence of the outgoing-wave
870
Chapter 16. Waves

boundary condition. For outgoing waves (the real, physical, situation), ϵ = +1; if the
waves were ingoing, we would have ϵ = −1.
This wave-zone solution remains valid into the near zone. In the near zone we
can perform a slow-motion expansion to bring it into the same form as the near-zone
slow-motion expansion
velocity potential (16.71):
ψ = f (t)
r
−ϵ
˙f (t)
C
+ . . . .
(16.79)
The second term is sensitive to whether the waves are outgoing or incoming and thus
radiation-reaction
potential
must ultimately be responsible for the radiation-reaction force that acts back on the
oscillating ball; for this reason we call it the radiation-reaction potential.
Equating the ﬁrst term of this ψ to the ﬁrst term of Eq. (16.71) and using the value
in Eq. (16.72) of A(t), which was obtained by matching the ﬂuid velocity to the ball
velocity, we obtain
f (t) = A(t) = −a2˙ξ(t).
(16.80)
This equation tells us that the wave ﬁeld f (t −r/C)/r generated by the ball’s surface
displacement ξ(t) is given by ψ = −a2˙ξ(t −r/C)/r [Eq. (16.66)]—the result we
derived more quickly in the previous section. We can regard Eq. (16.80) as matching
the near-zone solution outward onto the wave-zone solution to determine the wave
ﬁeld as a function of the source’s motion.
Equating the second term of Eq. (16.79) to the second term of the near-zone
velocity potential (16.71), we obtain
B(t) = −ϵ
˙f (t)
C
= ϵ a2
C
¨ξ(t).
(16.81)
This is the term in the near-zone velocity potential ψ = A/r + B that is responsible
for radiation reaction. We can regard this radiation-reaction potential ψRR = B(t)
as having been generated by matching the wave zone’s outgoing (ϵ = +1) or ingoing
how radiation-reaction
potential is generated
(ϵ = −1) wave ﬁeld back into the near zone. [A similar matching analysis by Burke
(1971) led him to the gravitational radiation-reaction potential (27.64).]
This pair of matchings, outward then inward (Fig. 16.11), is a special, almost trivial
example of the technique of matched asymptotic expansions—a technique developed
matched asymptotic
expansions
by applied mathematicians to deal with much more complicated matching problems
than this one (see, e.g., Cole, 1974).
The radiation-reaction potential ψRR = B(t) = ϵ(a2/C)¨ξ(t) gives rise to a
radiation-reaction contribution to the pressure on the ball’s surface: δP RR =
radiation-reaction
pressure on ball’s surface
−ρ ˙ψRR = −ϵ(ρa2/C)˙˙˙ξ. Inserting this into the equation of motion (16.74) along
with the loading pressure (16.73) and performing the same algebra as before, we get
the following radiation-reaction-modiﬁed form of Eq. (16.77):
ball’s equation of motion
with radiation reaction
¨ξ + ω2ξ = ϵτ˙˙˙ξ ,
where
τ =
κ
1 + κ
a
C
(16.82)
16.5 Sound Waves
871

ψRR = B = ϵ(a2/C)ξׂ ׂ
A(t – r/C)
—
r
–a2 ξׂ(t – r/C)
—
r
ψ =
=
near
zone
wave zone
FIGURE 16.11 Matched asymptotic expansions for an oscillating ball
emitting sound waves. The near-zone expansion feeds the radiation
ﬁeld ψ = 1
r A(t −r/C) = −1
r a2˙ξ(t −r/C) into the wave zone.
The wave-zone expansion then feeds the radiation-reaction ﬁeld
ψRR = B = ϵ(a2/C)¨ξ back into the near zone, where it produces
the radiation-reaction pressure δP RR = −ρ ˙ψRR on the ball’s surface.
is less than the ﬂuid’s sound travel time to cross the ball’s radius, a/C. The term ϵτ˙˙˙ξ
in the equation of motion is the ball’s radiation-reaction acceleration, as we see from
the fact that it would change sign if we switched from outgoing waves (ϵ = +1) to
incoming waves (ϵ = −1).
radiation-reaction induced
damping
In the absence of radiation reaction, the ball’s surface oscillates sinusoidally in
time: ξ = e±iωt. The radiation-reaction term produces a weak damping of these
oscillations:
ξ ∝e±iωte−σt,
σ = 1
2ϵ(ωτ)ω,
(16.83)
where σ is the radiation-reaction-induced damping rate (with ϵ = +1). Note that
in order of magnitude the ratio of the damping rate to the oscillation frequency is
σ/ω ∼ωτ <∼ωa/C = a/-λ, which is small compared to unity by virtue of the slow-
motion assumption. If the waves were incoming rather than outgoing, ϵ = −1, the
ﬂuid’s oscillations would grow. In either case, outgoing waves or ingoing waves, the
radiation-reaction force removes energy from the ball or adds it at the same rate as
the sound waves carry energy off or bring it in. The total energy, wave plus ball, is
conserved.
Expression (16.83) is two linearly independent solutions to the equation of motion
(16.82), one with the plus sign and the other with the minus sign. Since this equation
of motion has been made third order by the radiation-reaction term, there must be
a third independent solution. It is easy to see that, up to a tiny fractional correction,
that third solution is
ξ ∝eϵt/τ.
(16.84)
Foroutgoingwaves, ϵ = +1, thissolutiongrowsexponentiallyintimeonanextremely
runaway solution to ball’s
equation of motion
rapid timescale, τ <∼a/C; it is called a runaway solution.
872
Chapter 16. Waves

Such runaway solutions are ubiquitous in equations of motion with radiation
runaway solutions for
an electrically charged
particle
reaction. For example, a computation of the electromagnetic radiation reaction on
a small, classical, electrically charged, spherical particle gives the Abraham-Lorentz
equation of motion:
m(¨x −τ˙˙˙x) = Fext
(16.85)
(Rohrlich, 1965; Jackson, 1999, Sec. 16.2). Here x(t) is the particle’s world line, Fext is
the external force that causes the particle to accelerate, and the particle’s inertial mass
m includes an electrostatic contribution analogous to 4πa3ρ in our ﬂuid problem.
The timescale τ, like that in our ﬂuid problem, is very short, and when the external
force is absent, there is a runaway solution x ∝et/τ.
Much human heat and confusion were generated, in the early and mid-twentieth
century, overtheserunawaysolutions(see, e.g., Rohrlich, 1965).Foroursimplemodel
problem, there need be little heat or confusion. One can easily verify that the runaway
solution (16.84) violates the slow-motion assumption a/-λ ≪1 that underlies our
derivation of the radiation-reaction acceleration. It therefore is a spurious solution.
Our model problem is sufﬁciently simple that one can dig deeper into it and
learn that the runaway solution arises from the slow-motion approximation failing
origin of runaway solution
to reproduce a genuine, rapidly damped solution and getting the sign of the damping
wrong (Ex. 16.19 and Burke, 1970).
EXERCISES
Exercise 16.18 Problem: Energy Conservation for Radially Oscillating
Ball Plus Sound Waves
For the radially oscillating ball as analyzed in Sec. 16.5.3, verify that the radiation-
reaction acceleration removes energy from the ball, plus the ﬂuid loaded onto it, at
the same rate as the sound waves carry energy away. See Ex. 27.12 for the analogous
gravitational-wave result.
Exercise 16.19 Problem: Radiation Reaction without the Slow-Motion Approximation
Redo the computation of radiation reaction for a radially oscillating ball immersed in
a ﬂuid without imposing the slow-motion assumption and approximation. Thereby
obtain the following coupled equations for the radial displacement ξ(t) of the ball’s
surface and the function (t) ≡a−2f (t −ϵa/C), where ψ = r−1f (t −ϵr/C) is the
sound-wave ﬁeld:
¨ξ + ω2
oξ = κ ˙,
˙ξ = − −ϵ(a/C) ˙.
(16.86)
Show that in the slow-motion regime, this equation of motion has two weakly damped
solutions of the same form as we derived using the slow-motion approximation
[Eq. (16.83)], and one rapidly damped solution: ξ ∝exp(−ϵκt/τ). Burke (1970)
shows that the runaway solution (16.84) obtained using the slow-motion approxi-
mation is caused by that approximation’s futile attempt to reproduce this genuine,
rapidly damped solution.
16.5 Sound Waves
873

Exercise 16.20 Problem: Sound Waves from a Ball Undergoing
Quadrupolar Oscillations
Repeat the analysis of sound-wave emission, radiation reaction, and energy
conservation—as given in Sec. 16.5.3 and Ex. 16.18—for axisymmetric, quadrupolar
oscillations of an elastic ball: rball = a + ξ(t)P2(cos θ).
Comment: Since the lowest multipolar order for gravitational waves is quadrupo-
lar, this exercise is closer to the analogous problem of gravitational wave emission
(Secs. 27.5.2 and 27.5.3) than is the monopolar analysis in the text.
[Hint: If ω is the frequency of the ball’s oscillations, then the sound waves have the
form
ψ = Kℜ

e−iωt
n2(ωr/C) −iϵj2(ωr/C)
r

P2(cos θ),
(16.87)
where K is a constant; ℜ(X) is the real part of X; ϵ is +1 for outgoing waves and −1
for ingoing waves; j2 and n2 are the spherical Bessel and spherical Neuman functions
of order 2, and P2 is the Legendre polynomial of order 2. In the distant wave zone,
x ≡ωr/C ≫1, we have
n2(x) −iϵj2(x) = eiϵx
x ;
(16.88)
in the near zone x = ωr/C ≪1, we have
n2(x) = −3
x3
2
1 & x2 & x4 & . . .
3
,
j2(x) = x2
15
2
1 & x2 & x4 & . . .
3
.
(16.89)
Here “& xn” means “+ (some constant) xn”.]
Bibliographic Note
For physical insight into waves in ﬂuids, we recommend the movies discussed in Box
16.2. Among ﬂuid-dynamics textbooks, those that we most like for their treatment of
waves are Acheson (1990), Lautrup (2005), and Kundu, Cohen, and Dowling (2012).
For greater depth and detail, we recommend two books solely devoted to waves:
Lighthill (2001) and Whitham (1974).
For Rossby waves (which are omitted from most ﬂuid-dynamics texts), we recom-
mend the very physical descriptions and analyses in Tritton (1987). For solitons, we
like Whitham (1974, Chap. 17); also Drazin and Johnson (1989), which focuses on
themathematicsoftheKorteweg–deVriesequation; Ablowitz(2011), whichtreatsthe
mathematics of solitons plus applications to ﬂuids and nonlinear optics; and Dauxois
and Peyrard (2010), which treats the mathematics and applications to plasmas and
condensed-matter physics.
The mathematics of matched asymptotic expansions is nicely developed by Cole
(1974) and Lagerstrom (1988). Radiation reaction in wave emission is not treated
pedagogically in any textbook that we know of except ours; for pedagogical original
literature, we like Burke (1970).
874
Chapter 16. Waves

17
CHAPTER SEVENTEEN
Compressible and Supersonic Flow
Rocket science is tough, and rockets have a way of failing.
PHYSICIST, ASTRONAUT, AND EDUCATOR SALLY RIDE (2012)
17.1
17.1 Overview
So far we have mainly been concerned with ﬂows that are slow enough that they may
be treated as incompressible. We now consider ﬂows in which the velocity approaches
or even exceeds the speed of sound and in which changes of density along streamlines
cannot be ignored. Such ﬂows are common in aeronautics and astrophysics. For
example, the motion of a rocket through the atmosphere is faster than the speed of
sound in air. In other words, it is supersonic. Therefore, if we transform into the frame
of the rocket, the ﬂow of air past the rocket is also supersonic.
When the ﬂow speed exceeds the speed of sound in some reference frame, it is
not possible for a pressure pulse to travel upstream in that frame and change the
direction of the ﬂow. However, if there is a solid body in the way (e.g., a rocket or
aircraft), the ﬂow direction must change (Fig. 17.1). In a supersonic ﬂow, this change
happens nearly discontinuously, through the formation of shock fronts, at which the
ﬂow suddenly decelerates from supersonic to subsonic. Shock fronts are an inevitable
feature of supersonic ﬂows.
In another example of supersonic ﬂow, a rocket itself is propelled by the thrust
created by its nozzle’s escaping hot gases. These hot gases move through the rocket
nozzle at supersonic speeds, expanding and cooling as they accelerate. In this manner,
the random thermal motion of the gas molecules is converted into an organized bulk
motion that carries negative momentum away from the rocket and pushes it forward.
The solar wind furnishes yet another example of a supersonic ﬂow. This high-
speed ﬂow of ionized gas is accelerated in the solar corona and removes a fraction
of ∼10−14 of the Sun’s mass every year. Its own pressure accelerates it to supersonic
speeds of ∼400 km s−1. When the outﬂowing solar wind encounters a planet, it is
rapidly decelerated to subsonic speed by passing through a strong discontinuity,
known as a bow shock, that surrounds the planet (Fig. 17.2). The bulk kinetic energy
in the solar wind, built up during acceleration, is rapidly and irreversibly transformed
into heat as it passes through this shock front.
875

BOX 17.1.
READERS’ GUIDE
.
This chapter relies heavily on Chap. 13 and on Secs. 16.2, 16.3, and
16.5.
.
No subsequent chapters rely substantially on this one.
FIGURE 17.1 Complex pattern of shock fronts formed around a model aircraft in a wind tunnel
with air moving 10% faster than the speed of sound (i.e., with Mach number M = 1.1). Image
from NASA/Ames Imaging Library System.
Earth
bow shock
400 km s–1
Sun
FIGURE 17.2 The supersonic solar wind forms a type of shock front known
as a bow shock when it passes by a planet. Earth is ∼200 solar radii from
the Sun.
876
Chapter 17. Compressible and Supersonic Flow

BOX 17.2.
MOVIES RELEVANT TO THIS CHAPTER
We strongly recommend that the reader view the following movies dealing
with compressible and supersonic ﬂows:
.
Rouse (1963f)—covers most of this chapter except Riemann
invariants.
.
Coles (1965)—focuses on shock fronts and quasi-1-dimensional
ﬂow through throats.
.
Bryson (1964)—includes segments on shock fronts and hydraulic
jumps.
In this chapter, we study some properties of supersonic ﬂows. After restating the
basic equations of compressible ﬂuid dynamics (Sec. 17.2), we analyze three impor-
tant, simple cases: stationary, quasi-1-dimensional ﬂow (Sec. 17.3); time-dependent,
1-dimensional ﬂow (Sec. 17.4); and normal adiabatic shock fronts (Sec. 17.5). In
these sections, we apply the results of our analyses to some contemporary exam-
ples, including the Space Shuttle (Box 17.4); rocket engines; shock tubes; and the
Mach cone, N-wave, and sonic booms produced by supersonic projectiles and air-
craft. In Sec. 17.6, we develop similarity-solution techniques for supersonic ﬂows and
apply them to supernovae, underwater depth charges, and nuclear-bomb explosions
in Earth’s atmosphere.
As in our previous ﬂuid-dynamics chapters, we strongly encourage readers to view
relevant movies in parallel with reading this chapter. See Box 17.2.
17.2
17.2 Equations of Compressible Flow
equations of compressible
ﬂow
In Chap. 13, we derived the equations of ﬂuid dynamics, allowing for compressibility.
We expressed them as laws of mass conservation [Eq. (13.29)], momentum conser-
vation [∂(ρv)/∂t + ∇. T = 0, with T as given in Table 13.3], energy conservation
[∂U/∂t + ∇. F = 0, withU andFasgiveninTable13.3], andalsoanevolutionlawfor
entropy [Eq. (13.76)]. When, as in this chapter, heat conduction is negligible (κ →0)
and the gravitational ﬁeld is a time-independent, external one (not generated by the
ﬂowing ﬂuid), these equations become
mass conservation
∂ρ
∂t + ∇. (ρv) = 0,
(17.1a)
momentum conservation
∂(ρv)
∂t
+ ∇. (P g + ρv ⊗v −2ησ −ζθg) = ρg,
(17.1b)
17.2 Equations of Compressible Flow
877

∂
∂t
2
1
2v2 + u + 
3
ρ

+∇.
2
1
2v2 + h + 
3
ρv −2ησ . v −ζθv

= 0,
(17.1c)
∂(ρs)
∂t
+ ∇. (ρsv) = 1
T
2
2ησ : σ + ζθ23
.
(17.1d)
Here σ : σ is index-free notation for σijσij.
energy conservation
entropy evolution
Some comments are in order. Equation (17.1a) is the complete mass-conservation
equation (continuity equation), assuming that matter is neither added to nor removed
from the ﬂow, for example, no electron-positron pair creation. Equation (17.1b) ex-
presses the conservation of momentum allowing for one external force, gravity. Other
external forces (e.g., electromagnetic) can be added. Equation (17.1c), expressing en-
ergy conservation, includes a viscous contribution to the energy ﬂux. If there are
sources or sinks of ﬂuid energy, then these must be included on the right-hand side of
this equation. Possible sources of energy include chemical or nuclear reactions; possi-
ble energy sinks include cooling by emission of radiation. Equation (17.1d) expresses
the evolution of entropy and will also need modiﬁcation if there are additional con-
tributions to the energy equation. The right-hand side of this equation is the rate of
increase of entropy due to viscous heating. This equation is not independent of the
preceding equations and the laws of thermodynamics, but it is often convenient to
use. In particular, one often uses it (together with the ﬁrst law of thermodynamics) in
place of energy conservation (17.1c).
These equations must be supplemented with an equation of state in the form
P(ρ, T ) or P(ρ, s). For simplicity, we often focus on an ideal gas (one with P ∝
equation of state
ρkBT ) that undergoes adiabatic evolution with constant speciﬁc-heat ratio (adiabatic
adiabatic index
index γ ; Ex. 5.4), so the equation of state has the simple polytropic form (Box 13.2)
polytropic equation of
state
P = K(s)ργ .
(17.2a)
Here K(s) is a function of the entropy per unit mass s and is thus constant during
adiabatic evolution, but it will change across shocks, because the entropy increases in
a shock (Sec. 17.5). The value of γ depends on the number of thermalized internal
degrees of freedom of the gas’s constituent particles (Ex. 17.1). For a gas of free
particles (e.g., fully ionized hydrogen), the value is γ = 5/3; for Earth’s atmosphere at
temperatures between about 10 K and 400 K, it is γ = 7/5 = 1.4 (Ex. 17.1).
polytropic relations
For a polytropic gas with P = K(s)ργ, we can integrate the ﬁrst law of thermo-
dynamics (Box 13.2) to obtain a formula for the internal energy per unit mass:
u =
P
(γ −1)ρ ,
(17.2b)
where we have assumed that the internal energy vanishes as the temperature T →0
and thence P →0. It will prove convenient to express the density ρ, the internal
878
Chapter 17. Compressible and Supersonic Flow

energy per unit mass u, and the enthalpy per unit mass h in terms of the sound speed:
C =
1∂P
∂ρ

s
=
1
γ P
ρ
(17.2c)
[Eq. (16.48)]. A little algebra gives
ρ =
 C2
γ K
1/(γ −1)
,
u =
C2
γ (γ −1) ,
h = u + P
ρ =
C2
γ −1 =
γ P
(γ −1)ρ .
(17.2d)
EXERCISES
Exercise 17.1 **Example: Values of γ
Consider an ideal gas consisting of several different particle species (e.g., diatomic
oxygenmoleculesandnitrogenmoleculesinthecaseofEarth’satmosphere).Consider
a sample of this gas with volume V , containing NA particles of various species A, all in
thermodynamic equilibrium at a temperature T sufﬁciently low that we can ignore the
effects of special relativity. Let species A have νA internal degrees of freedom with the
hamiltonian quadratic in their generalized coordinates (e.g., rotation and vibration),
and assume that those degrees of freedom are sufﬁciently thermally excited to have
reached energy equipartition. Then the equipartition theorem (Sec. 4.4.4) dictates
that each such particle has 3
2kBT of translational energy plus 1
2νAkBT of internal
energy, and because the gas is ideal, each particle contributes kBT /V to the pressure.
Correspondingly, the sample’s total energy E and pressure P are
E =
 
A
3
2 + νA
2

NAkBT ,
P = 1
V
 
A
NAkB T .
(17.3a)
(a) Use the laws of thermodynamics to show that the speciﬁc heats at ﬁxed volume
and pressure are
CV ≡

T ∂S
∂T

V ,NA
= E
T =
 
A
3
2 + νA
2

NAkB,
CP =

T ∂S
∂T

P ,NA
= CV + P V
T ,
(17.3b)
so the ratio of speciﬁc heats is
γ = CP
CV
= 1 +
!
A NA
!
A NA
 3
2 + νA
2

(17.3c)
(cf. Ex. 5.4).
(b) If there are no thermalized internal degrees of freedom, νA = 0 (e.g., for a fully
ionized, nonrelativistic gas), then γ = 5/3. For Earth’s atmosphere, at tempera-
tures between about 10 K and 400 K, the rotational degrees of freedom of the O2
and N2 molecules are thermally excited, but the temperature is too low to excite
their vibrational degrees of freedom. Explain why this means that νO2 = νN2 = 2,
17.2 Equations of Compressible Flow
879

1.40
1.38
1.36
1.34
1.32
300
500
700
1,000
γ
T (K)
FIGURE 17.3 The ratio of speciﬁc heats γ for air as a function of
temperature.
which implies γ = 7/5 = 1.4. [Hint: There are just two orthogonal axes around
which the diatomic molecule can rotate.]
(c) Between about 1,300 K and roughly 10,000 K the vibrational degrees of freedom
are thermalized, but the molecules have not dissociated substantially into individ-
ual atoms, nor have they become substantially ionized. Explain why this means
that νO2 = νN2 = 4 in this temperature range, which implies γ = 9/7 ≃1.29.
[Hint: An oscillator has kinetic energy and potential energy.]
(d) At roughly 10,000 K the two oxygen atoms in O2 dissociate, the two nitrogen
atoms in N2 dissociate, and electrons begin to ionize. Explain why this drives γ
up toward 5/3 ≃1.67.
The actual value of γ as a function of temperature for the range 200 K to 1,300 K
is shown in Fig. 17.3. Evidently, as stated, γ = 1.4 is a good approximation only
up to about 400 K, and the transition toward γ = 1.29 occurs gradually between
about 400 K and 1,400 K as the vibrational degrees of freedom gradually become
thermalized and begin to obey the equipartition theorem (Sec. 4.4.4).
17.3
17.3 Stationary, Irrotational, Quasi-1-Dimensional Flow
17.3.1
17.3.1 Basic Equations; Transition from Subsonic to Supersonic Flow
In their full generality, the ﬂuid dynamic equations (17.1) are quite unwieldy. To
demonstrate some of the novel features of supersonic ﬂow, we proceed as in earlier
chapters: we specialize to a simple type of ﬂow in which the physical effects of interest
are strong, and extraneous effects are negligible.
In particular, in this section, we seek insight into smooth transitions between
subsonic and supersonic ﬂow by restricting ourselves to a stationary (∂/∂t = 0),
880
Chapter 17. Compressible and Supersonic Flow

subsonic
(a)
(b)
supersonic
1
1
A*
A
M
A
—
A*
FIGURE 17.4 Stationary, transonic ﬂow in a converging and then
diverging streamtube. (a) The streamtube. (b) The ﬂow’s Mach number
M = v/C (horizontal axis) as a function of the streamtube’s area A
(vertical axis). The ﬂow is subsonic to the left of the streamtube’s throat
A = A∗, sonic at the throat, and supersonic to the right.
irrotational (∇× v = 0) ﬂow in which gravity and viscosity are negligible ( = g =
η = ζ = 0), as are various effects not included in our general equations: chemical reac-
stationary, irrotational,
isentropic ﬂow without
gravity or viscosity
tions, thermal conductivity, and radiative losses. (We explore some effects of gravity
in Ex. 17.5.) The vanishing viscosity implies [from the entropy evolution equation
(17.1d)] that the entropy per baryon s is constant along each ﬂow line. We assume
that s is the same on all ﬂow lines, so the ﬂow is fully isentropic (s is constant every-
where), and the pressure P = P(ρ, s) can thus be regarded as a function only of the
density: P = P(ρ). When we need a speciﬁc form for P (ρ), we will use the polytropic
form P = K(s)ργ for an ideal gas with constant speciﬁc-heat ratio γ [Eqs. (17.2); Ex.
17.1], but much of our analysis is done for a general isentropic P (ρ). We make one
further approximation: the ﬂow is almost 1-dimensional. In other words, the velocity
vectors all make small angles with one another in the region of interest.
These drastic simpliﬁcations are actually appropriate for many cases of prac-
tical interest. Granted these simpliﬁcations, we can consider a narrow bundle of
streamlines—which we call a streamtube—and introduce as a tool for analysis its cross
streamtube
sectional area A normal to the ﬂow (Fig. 17.4a).
As the ﬂow is stationary, the equation of mass conservation (17.1a) states that
the rate ˙m at which mass passes through the streamtube’s cross section must be
independent of position along the tube:
ρvA = ˙m = const;
(17.4a)
17.3 Stationary, Irrotational, Quasi-1-Dimensional Flow
881

here v is the speed of the ﬂuid in the streamtube. Rewriting this in differential form,
we obtain
dA
A + dρ
ρ + dv
v = 0.
(17.4b)
Because the ﬂow is stationary and inviscid, the law of energy conservation (17.1c)
reduces to Bernoulli’s theorem [Eqs. (13.51), (13.50)]:
h + 1
2v2 = h1 = const
(17.4c)
along each streamline and thus along our narrow streamtube. Here h1 is the speciﬁc
enthalpy at a location where the ﬂow velocity v vanishes (e.g., in chamber 1 of Fig.
17.5a below). Since the ﬂow is adiabatic, we can use the ﬁrst law of thermodynamics
(Box 13.2) dh = dP/ρ + T ds = dP/ρ = C2dρ/ρ [where C is the speed of sound;
Eq. (17.2c)] to write Eq. (17.4c) in the differential form
dρ
ρ + vdv
C2 = 0.
(17.4d)
Finally and most importantly, we combine Eqs. (17.4b) and (17.4d) to obtain
dv
v = dA/A
M2 −1,
dρ
ρ =
dA/A
M−2 −1,
(17.5)
where
Mach number
M ≡v/C
(17.6)
is the Mach number. This Mach number is an important dimensionless number that
is used to characterize compressible ﬂows. When the Mach number is less than 1, the
ﬂow is subsonic; when M > 1, it is supersonic. By contrast with the Reynolds, Rossby,
subsonic and supersonic
ﬂow
and Ekman numbers, which are usually deﬁned using a single set of (characteristic)
values of the ﬂow parameters (V , ν, , and L) and thus have a single value for any
given ﬂow, the Mach number by convention is deﬁned at each point in the ﬂow and
thus is a ﬂow variable, M(x), similar to v(x) and ρ(x).
properties of subsonic and
supersonic ﬂow
Equations (17.5) make remarkable predictions, which we illustrate in Fig. 17.4 for
a particular ﬂow called “transonic”:
1. The only locations along a streamtube at which M can be unity (v = C) are
those where A is an extremum—for example, for the streamtube in Fig. 17.4,
the minimum A = A∗(the tube’s throat).
2. At points along a streamtube where the ﬂow is subsonic, M < 1 (left side of
the streamtube in Fig. 17.4), v increases when A decreases, in accord with
everyday experience.
882
Chapter 17. Compressible and Supersonic Flow

3. At points where the ﬂow is supersonic, M > 1 (right side of Fig. 17.4), v
increases when A increases—just the opposite of everyday experience.
These conclusions are useful when analyzing stationary, high-speed ﬂows.
17.3.2
17.3.2 Setting up a Stationary, Transonic Flow
At this point the reader may wonder whether it is easy to set up a transonic ﬂow
in which the speed of the ﬂuid changes continuously from subsonic to supersonic,
as in Fig. 17.4. The answer is quite illuminating. We can illustrate the answer using
two chambers maintained at different pressures, P1 and P2, and connected through
a narrow channel, along which the cross sectional area passes smoothly through a
minimum A = A∗, the channel’s throat (Fig. 17.5a). When P2 = P1, no ﬂow occurs
between the two chambers. When we decrease P2 slightly below P1, a slow subsonic
inducing transonic ﬂow
by increasing pressure
difference
ﬂow moves through the channel (curves 1 in Fig. 17.5b,c). As we decrease P2 further,
there comes a point (P = P crit
2
) at which the ﬂow becomes transonic at the channel’s
throat A = A∗(curves 2). For all pressures P2 < P crit
2
, the ﬂow is also transonic at
the throat and has a universal form to the left of and near the throat, independent
of the value of P2 (curves 2)—including a universal value ˙mcrit for the rate of mass
ﬂow through the throat! This universal ﬂow is supersonic to the right of the throat
(curves 2b), but it must be brought to rest in chamber 2, since there is a hard wall at
the chamber’s end. How is it brought to rest? Through a shock front, where it is driven
subsonic almost discontinuously (curves 3 and 4; see Sec. 17.5).
How, physically, is it possible for the transonic ﬂow to have a universal form to the
left of the shock? The key is that, in any supersonic region of the ﬂow, disturbances
are unable to propagate upstream, so the upstream ﬂuid has no way of knowing what
the pressure P2 is in chamber 2. Although the ﬂow to the left of the shock is universal,
the location of the shock and the nature of the subsonic, post-shock ﬂow are affected
by P2, since information can propagate upstream through that subsonic ﬂow, from
chamber 2 to the shock.
The reader might now begin to suspect that the throat, in the transonic case, is
a special location. It is, and that location is known as a critical point of the station-
criticalpointofastationary
ﬂow
ary ﬂow. From a mathematical point of view, critical points are singular points of
the equations (17.4) and (17.5) of stationary ﬂow. This singularity shows up in the
solutions to the equations, as depicted in Fig. 17.5c. The universal solution that passes
transonically through the critical point (solution 2) joins onto two different solutions
to the right of the throat: solution 2a, which is supersonic, and solution 2b, which
is subsonic. Which solution occurs in practice depends on conditions downstream.
Other solutions that are arbitrarily near this universal solution (dashed curves in
Fig. 17.5c) are either double valued and consequently unphysical, or are everywhere
subsonic or everywhere supersonic (in the absence of shocks); see Box 17.3 and
Ex. 17.2.
17.3 Stationary, Irrotational, Quasi-1-Dimensional Flow
883

1
2
3
4
2b
2a
critical point
(a)
(b)
(c)
Amin
P1
P1
P
x
v
x
P2
P2
1
2
3
4
2b
2a
FIGURE 17.5 Stationary ﬂow through a channel between two chambers maintained at
different pressures P1 and P2. (a) Setup of the chambers. When the pressure difference
P1 −P2 is large enough [see curves in panel (b)], the ﬂow is subsonic to the left of the
channel’s throat and supersonic to the right [see curves in panel (c)]. As it nears or
enters the second chamber, the supersonic ﬂow must encounter a strong shock, where
it decelerates abruptly to subsonic speed [panels (b) and (c)]. The forms of the various
velocity proﬁles v(x) in panel (c) are explained in Box 17.3.
884
Chapter 17. Compressible and Supersonic Flow

BOX 17.3.
VELOCITY PROFILES FOR 1-DIMENSIONAL FLOW
BETWEEN CHAMBERS
Consider the adiabatic, stationary ﬂow of an isentropic, polytropic ﬂuid
P = Kργ between the two chambers shown in Fig. 17.5. Describe the channel
between chambers by its cross sectional area A(x) as a function of distance
x, and describe the ﬂow by the ﬂuid’s velocity v(x) and its sound speed
C(x). There are two coupled algebraic equations for v(x) and C(x): mass
conservation ρvA = ˙m [Eq. (17.4a)] and the Bernoulli theorem h + 1
2v2 = h1
[Eq. (17.4c)], which, for our polytropic ﬂuid, become [see Eqs. (17.2d)]:
C2/(γ −1)v = (γ K)1/(γ −1) ˙m/A,
C2
γ −1 + v2
2 =
C2
1
γ −1.
(1)
These equations are graphed in diagrams below for three different mass
ﬂow rates ˙m. Mass conservation [the ﬁrst of Eqs. (1)] is a set of generalized
hyperbolas, one for each value of the channel’s area A∗< Aa < Ab < Ac. The
Bernoulli theorem [the second of Eqs. (1)] is a single ellipse. On a chosen
diagram (for a chosen ˙m), the dot at the intersection of the ellipse with a
hyperbola tells us the ﬂow velocity v and speed of sound C at each of the two
points in the channel where the area A has the hyperbola’s value.
A*
A*
ṁ < ṁcrit
ṁ = ṁcrit
ṁ > ṁcrit
Aa
Aa
Aa
Ab
Ab
Ab
Ac
Ac
Ac
C
C
C
v = C
v = C
v = C
v
v
v
A*
There is a critical mass-ﬂow rate ˙mcrit (central diagram above), such that
the hyperbola A = A∗(the channel’s throat) is tangent to the ellipse at the
point v = C, so the ﬂow is Mach 1 (v = C). For this ˙m, the sequence of
dots along the ellipse, moving from lower right to upper left, represents the
transonic ﬂow, which begins as subsonic and becomes supersonic (upward
swooping solid curve in the drawing below); and the same sequence of dots,
moving in the opposite direction from upper left to lower right, represents a
ﬂow that begins as supersonic and smoothly transitions to subsonic (down-
ward swooping solid curve, below). When ˙m < ˙mcrit (left diagram above;
top and bottom quadrants below), the sequence of dots beginning at lower
(continued)
17.3 Stationary, Irrotational, Quasi-1-Dimensional Flow
885

BOX 17.3.
(continued)
right reaches the throat A = A∗at a subsonic velocity, so the solution climbs up
along the ellipse to that point and then descends back down, mapping out a
fully subsonic solution v(x) below—and similarly for the dots on the upper
branch of the ellipse, which map out a fully supersonic solution below. When
˙m > ˙Mcrit (right diagram above), the dots map out curves in the left and right
quadrants below that never reach the sonic point and are double valued for
v(x)—and are thus unphysical. Therefore, the mass ﬂow rate ˙m can never
exceed ˙mcrit.
ṁ < ṁcrit
ṁ < ṁcrit
ṁ > ṁcrit
ṁ > ṁcrit
Aa
Aa
x
Ab
Ab
Ac
Ac
v
A*
The existence of critical points is a price we must pay, mathematically, for not
allowing our equations to be time dependent. If we were to solve the time-dependent
equations (which would then be partial differential equations), we would ﬁnd
that they change from elliptic to hyperbolic as the ﬂow passes through a critical
point.
From a physical point of view, critical points are the places where a sound wave
properties of critical points
propagating upstream remains at rest in the ﬂow. They are therefore the one type of
place from which time-dependent transients, associated with setting up the ﬂow in
the ﬁrst place, cannot decay away (if the equations are dissipation-free, i.e., inviscid).
Thus, even the time-dependent equations can display peculiar behaviors at a critical
point. However, when dissipation, for example due to viscosity, is introduced, these
dissipation smears out
critical points
peculiarities get smeared out.
EXERCISES
Exercise 17.2 Problem: Explicit Solution for Flow between Chambers When γ = 3
For γ = 3 and for a channel with A = A∗(1 + x2), solve the ﬂow equations (1) of
Box 17.3 analytically and explicitly for v(x), and verify that the solutions have the
qualitative forms depicted in the last ﬁgure of Box 17.3.
886
Chapter 17. Compressible and Supersonic Flow

P1
Ve
A*
P*
De Laval nozzle
combustion
chamber
skirt
subsonic flow
supersonic
flow
FIGURE 17.6 Schematic illustration of a rocket engine.
Note the skirt, which increases the thrust produced by
the escaping exhaust gases.
17.3.3
17.3.3 Rocket Engines
We have shown that, to push a quasi-1-dimensional ﬂow from subsonic to supersonic,
one must send it through a throat. This result is exploited in the design of rocket
engines and jet engines.
In a rocket engine, hot gas is produced by controlled burning of fuel in a large
chamber, and the gas then escapes through a converging-diverging (also known as a
De Laval1) nozzle, as shown in Fig. 17.6. The nozzle is designed with a skirt so the
De Laval nozzle
ﬂow becomes supersonic smoothly when it passes through the nozzle’s throat.
To analyze this ﬂow in some detail, let us approximate it as precisely steady,
isentropic, and quasi-1-dimensional, and the gas as ideal and inviscid with a constant
ratio of speciﬁc heats γ . In this case, the enthalpy is h = C2/(γ −1) [Eqs. (17.2d)],
so Bernoulli’s theorem (17.4c) reduces to
C2
(γ −1) + 1
2v2 =
C2
1
(γ −1).
(17.7)
Here C is the sound speed in the ﬂow and C1 is the stagnation sound speed (i.e., the
sound speed evaluated in the rocket chamber where v = 0). Dividing this Bernoulli
theorem by C2 and manipulating, we learn how the sound speed varies with Mach
number M = v/C:
how sound speed varies
with Mach number
C = C1

1 + γ −1
2
M2
−1/2
.
(17.8)
From mass conservation [Eq. (17.4a)], we know that the cross sectional area A varies
as A ∝ρ−1v−1 ∝ρ−1M−1C−1 ∝M−1C(γ +1)/(1−γ ), where we have used ρ ∝C2/(γ −1)
[Eqs. (17.2d)]. Combining with Eq. (17.8), and noting that M = 1where A = A∗(i.e.,
1.
First used in a steam turbine in 1882 by the Swedish engineer Gustaf de Laval. De Laval is most famous
for developing a device to separate cream from milk, centrifugally!
17.3 Stationary, Irrotational, Quasi-1-Dimensional Flow
887

the ﬂow is sonic at the throat), we ﬁnd that
how Mach number varies
with area
A
A∗
= 1
M

2
γ + 1 +
γ −1
γ + 1

M2
 (γ +1)
2(γ −1)
.
(17.9)
The pressure P∗at the throat can be deduced from P ∝ργ ∝C2γ/(γ −1) [Eqs. (17.2a)
and (17.2d)] together with Eq. (17.8) with M = 0 and P = P1 = (stagnation pressure)
in the chamber and M = 1 at the throat:
P∗= P1

2
γ + 1
 γ
γ −1
.
(17.10)
We use these formulas in Box 17.4 and Ex. 17.3 to evaluate, numerically, some features
of the Space Shuttle and its rocket engines.
Bernoulli’s theorem is a statement that the ﬂuid’s energy is conserved along a
streamtube. (For conceptual simplicity we regard the entire interior of the nozzle as a
single streamtube.) By contrast with energy, the ﬂuid’s momentum is not conserved,
momentum ﬂow inside
nozzle
since it pushes against the nozzle wall as it ﬂows. As the subsonic ﬂow accelerates
down the nozzle’s converging region, the area of its streamtube diminishes, and the
momentum ﬂowing per second in the streamtube, (P + ρv2)A, decreases; momen-
tum is being transferred to the nozzle wall. If the rocket did not have a skirt but instead
opened up completely to the outside world at its throat, the rocket thrust would be
T∗= (ρ∗v2
∗+ P∗)A∗= (γ + 1)P∗A∗.
(17.11)
This is much less than if momentum had been conserved along the subsonic, accel-
erating streamtubes.
role of a rocket engine’s
skirt
Much of the “lost” momentum is regained, and the thrust is made signiﬁcantly
larger than T∗, by the force of the skirt on the stream tube in the diverging part of the
nozzle (Fig. 17.6). The nozzle’s skirt keeps the ﬂow quasi-1-dimensional well beyond
the throat, driving it to be more and more strongly supersonic. In this accelerating,
supersonicﬂowthetube’srateofmomentumﬂow (ρv2 + P )Aincreasesdownstream,
with a compensating increase of the rocket’s forward thrust. This skirt-induced force
accounts for a signiﬁcant fraction of the thrust of a well-designed rocket engine.
matching exit pressure to
external pressure
Rockets work most efﬁciently when the exit pressure of the gas, as it leaves the base
of the skirt, matches the external pressure in the surrounding air. When the pressure
in the exhaust is larger than the external pressure, the ﬂow is termed underexpanded
and a pulse of low pressure, known as a rarefaction, will be driven into the escaping
gases, causing them to expand and increasing their speed. However, the exhaust
will now be pushing on the surrounding air, rather than on the rocket. More thrust
could have been exerted on the rocket if the ﬂow had not been underexpanded. By
contrast, when the exhaust has a smaller pressure than the surrounding air (i.e.,
is overexpanded), shock fronts will form near the exit of the nozzle, affecting the
ﬂuid ﬂow and sometimes causing separation of the ﬂow from the nozzle’s walls. It
is important that the nozzle’s skirt be shaped so that the exit ﬂow is neither seriously
over- nor underexpanded.
888
Chapter 17. Compressible and Supersonic Flow

BOX 17.4.
SPACE SHUTTLE
NASA’s (now retired) Space Shuttle provides many nice examples of the
behavior of supersonic ﬂows. At launch, the shuttle and fuel had a mass
∼2 × 106 kg. The maximum thrust, T ∼3 × 107 N, occurred at lift-off and
gave the rocket an initial acceleration relative to the ground of ∼0.5g. This
increased to ∼3g as the fuel was burned and the total mass diminished.
Most of the thrust was produced by two solid-fuel boosters that burned
fuel at a combined rate of ˙m ∼10,000 kg s−1 over a 2-min period. Their
combined thrust was T ∼2 × 107 N averaged over the 2 minutes, from which
we can estimate the speed of the escaping gases as they left the nozzles’
skirts. Assuming this speed was quite supersonic (so Pe ≪ρev2
e), we estimate
that ve ∼T/ ˙m ∼2 km s−1. The combined exit areas of the two skirts was
Ae ∼20 m2, roughly four times the combined throat area, A∗. Using Eq. (17.9)
with γ ∼1.29, we deduce that the exit Mach number was Me ∼3.
From T ∼ρev2
eAe and Pe = C2
eρe/γ , we deduce the exit pressure,
Pe ∼T /(γ M2
eAe) ∼8 × 104 N m−2, about atmospheric. The stagnation
pressure in the combustion region was [combine Eqs. (17.2a), (17.2d),
and (17.8)]
P1 ∼Pe
'
1 + (γ −1)M2
e
2
( γ
γ −1
∼35 atmospheres.
(1)
Of course, the actual operation was far more complex than this. For example,
to optimize the ﬁnal altitude, one must allow for the decreasing mass and
atmospheric pressure as well as the 2-dimensional gas ﬂow through the nozzle.
The Space Shuttle can also be used to illustrate the properties of shock
waves (Sec. 17.5). When the shuttle reentered the atmosphere, it was highly
supersonic, and therefore was preceded by a strong shock front that heated
the onrushing air and consequently heated the shuttle. The shuttle continued
moving supersonically down to an altitude of 15 km, and until this time it
created a shock-front pattern that could be heard on the ground as a sonic
boom. The maximum heating rate occurred at 70 km. Here, the shuttle moved
at V ∼7 km s−1, and the sound speed is about 280 m s−1, giving a Mach
number of 25. For the speciﬁc-heat ratio γ ∼1.5 and mean molecular weight
μ ∼10 appropriate to dissociated air, the strong-shock Rankine-Hugoniot
relations (17.37) (see Sec. 17.5.2), together with P = [ρ/(μmp)]kBT and
C2 = γ P/ρ, predict a post-shock temperature of
T ∼
2(γ −1)μmpV 2
(γ + 1)2kB
∼9,000 K.
(2)
Exposure to gas at this high temperature heated the shuttle’s nose to ∼1,800 K.
(continued)
17.3 Stationary, Irrotational, Quasi-1-Dimensional Flow
889

BOX 17.4.
(continued)
There is a second, well-known consequence of this high temperature: it is
sufﬁcient to ionize the air partially as well as dissociate it. As a result, during
reentry the shuttle was surrounded by a sheath of plasma, which, as we shall
discover in Chap. 19, prevented radio communication. The blackout lasted
for about 12 minutes.
EXERCISES
Exercise 17.3 Problem: Space Shuttle’s Solid-Fuel Boosters
Use the rough ﬁgures in Box 17.4 to estimate the energy released per unit mass in
burning the fuel. Does your answer seem reasonable?
Exercise 17.4 Problem: Relativistic 1-Dimensional Flow
Use the development of relativistic gas dynamics in Sec. 13.8.2 to show that the cross
sectionalareaofarelativistic1-dimensionalﬂowtubeisalsominimizedwhentheﬂow
is transonic. Assume that the equation of state is P = 1
3ρc2. For details see Blandford
and Rees (1974).
Exercise 17.5 **Example: Adiabatic, Spherical Accretion of Gas
onto a Black Hole or Neutron Star
Consider a black hole or neutron star with mass M at rest in interstellar gas that has
constant ratio of speciﬁc heats γ . In this exercise you will derive some features of the
adiabatic, spherical accretion of the gas onto the hole or star, a problem ﬁrst solved
by Bondi (1952b). This exercise shows how gravity can play a role analogous to a
De Laval nozzle: it can trigger a transition of the ﬂow from subsonic to supersonic.
Although, near the black hole or neutron star, spacetime is signiﬁcantly curved and
the ﬂow becomes relativistic, we shall conﬁne ourselves to a Newtonian treatment.
(a) Let ρ∞and C∞be the density and sound speed in the gas far from the hole (at
radius r = ∞). Use dimensional analysis to estimate the rate of accretion of mass
˙Monto the star or hole in terms of the parameters of the system: M, γ , ρ∞, C∞,
and Newton’s gravitation constant G. [Hint: Dimensional considerations alone
cannot give the answer. Why? Augment your dimensional considerations by a
knowledge of how the answer should scale with one of the parameters (e.g., the
density ρ∞).]
(b) Give a simple physical argument, devoid of dimensional considerations, that
produces the same answer for ˙M, to within a multiplicative factor of order unity,
as you deduced in part (a).
(c) Because the neutron star and black hole are both very compact with intense
gravity near their surfaces, the inﬂowing gas is guaranteed to accelerate to su-
890
Chapter 17. Compressible and Supersonic Flow

personic speeds as it falls in. Explain why the speed will remain supersonic
in the case of the hole, but must transition through a shock to subsonic ﬂow
near the surface of the neutron star. If the star has the same mass M as the hole,
will the details of its accretion ﬂow [ρ(r), C(r), v(r)] be the same as or different
from those for the hole, outside the star’s shock? Will the mass accretion rates ˙M
be the same or different? Justify your answers physically.
(d) By combining the Euler equation for v(r) with the equation of mass conservation,
˙M = 4πr2ρv, and with the sound-speed equation C2 = (∂P/∂ρ)s, show that
(v2 −C2) 1
ρ
dρ
dr = GM
r2
−2v2
r ,
(17.12)
and the ﬂow speed vs, sound speed Cs, and radius rs at the sonic point (the
transition from subsonic to supersonic; the ﬂow’s critical point) are related by
v2
s = C2
s = GM
2rs
.
(17.13)
(e) By combining with the Bernoulli equation (with the effects of gravity included),
deduce that the sound speed at the sonic point is related to that at inﬁnity by
C2
s = 2C2
∞
5 −3γ
(17.14)
and that the radius of the sonic point is
rs = (5 −3γ )
4
GM
C2
∞
.
(17.15)
Thence also deduce a precise value for the mass accretion rate ˙M in terms of
the parameters of the problem. Compare with your estimate of ˙M in parts (a)
and (b). [Comment: For γ = 5/3, which is the value for hot, ionized gas, this
analysis places the sonic point at an arbitrarily small radius. In this limiting case,
(i) general relativistic effects strengthen the gravitational ﬁeld (Sec. 26.2), thereby
moving the sonic point well outside the star or hole, and (ii) the answer for ˙M
has a ﬁnite value close to the general relativistic prediction.]
(f) Much of the interstellar medium is hot and ionized, with a density of about
1 proton per cubic centimeter and temperature of about 104 K. In such a medium,
what is the mass accretion rate onto a 10-solar-mass hole, and approximately how
long does it take for the hole’s mass to double?
17.4
17.4 1-Dimensional, Time-Dependent Flow
17.4.1
17.4.1 Riemann Invariants
1-dimensional ﬂow
of an isentropic ﬂuid
without viscosity, thermal
conductivity, or gravity
Let us turn now to time-dependent ﬂows. Again we conﬁne our attention to the sim-
plest situation that illustrates the physics—in this case, truly 1-dimensional motion
of an isentropic ﬂuid in the absence of viscosity, thermal conductivity, and gravity, so
17.4 1-Dimensional, Time-Dependent Flow
891

the ﬂow is adiabatic as well as isentropic (entropy constant in time as well as space).
The motion of the gas in such a ﬂow is described by the equation of continuity (17.1a)
and the Euler equation (17.1b) specialized to 1 dimension:
dρ
dt = −ρ ∂v
∂x ,
dv
dt = −1
ρ
∂P
∂x ,
(17.16)
where
d
dt = ∂
∂t + v ∂
∂x
(17.17)
is the convective (advective) time derivative—the time derivative moving with the
ﬂuid.
Given an isentropic equation of state P = P (ρ) that relates the pressure to the
density, these two nonlinear equations can be combined into a single second-order
differential equation in the velocity. However, it is more illuminating to work with the
ﬁrst-order set. As the gas is isentropic, the density ρ and sound speed C = (dP/dρ)1/2
can both be regarded as functions of a single thermodynamic variable, which we
choose to be the pressure.
Taking linear combinations of Eqs. (17.16), we obtain two partial differential
equations:
∂v
∂t ±
1
ρC
∂P
∂t + (v ± C)
∂v
∂x ±
1
ρC
∂P
∂x

= 0,
(17.18)
which together are equivalent to Eqs. (17.16). We can rewrite these equations in terms
of Riemann invariants
Riemann invariants
J± ≡v ±
 dP
ρC
(17.19)
and characteristic speeds
characteristic speeds
V± ≡v ± C
(17.20)
in the following way:
ﬂow equations
 ∂
∂t + V±
∂
∂x

J± = 0.
(17.21)
Equation (17.21) tells us that the convective derivative of each Riemann invariant
J± vanishes for an observer who moves, not with the ﬂuid speed, but, instead, with
the speed V±. We say that each Riemann invariant is conserved along its characteristic
Riemann invariant
conserved along its
characteristic
(denoted by C±), which is a path through spacetime satisfying
C±:
dx
dt = v ± C.
(17.22)
Note that in these equations, both v and C are functions of x and t.
892
Chapter 17. Compressible and Supersonic Flow

x
t
∂S
A
B
C– :
C+ :
J– = const
J+ = const
P
FIGURE 17.7 Spacetime diagram showing the characteristics (thin solid and dashed
lines) for a 1-dimensional adiabatic ﬂow of an isentropic gas. The paths of the ﬂuid
elements are shown as thick solid lines. Initial data are presumed to be speciﬁed over
some interval ∂S of x at time t = 0. The Riemann invariant J+ is constant along
each characteristic C+ (thin dashed line) and thus at point P it has the same value,
unchanged, as at point A in the initial data. Similarly J−is invariant along each
characteristic C−(thin solid line) and thus at P it has the same value as at B. The
shaded area of spacetime is the domain of dependence S of ∂S.
The characteristics have a natural interpretation. They describe the motion of
physical interpretation of
characteristics
small disturbances traveling backward and forward relative to the ﬂuid at the local
sound speed. As seen in the ﬂuid’s local rest frame v = 0, two neighboring events in
the ﬂow, separated by a small time interval t and a space interval x = +Ct—
so that they lie on the same C+ characteristic—will have small velocity and pressure
differences satisfying v = −P/(ρC) [as one can deduce from Eqs. (17.16) with
v = 0, d/dt = ∂/∂t, and C2 = dP/dρ]. Now, for a linear sound wave propagating
along the positive x direction, v and P will separately vanish. However, in a
nonlinear wave, only the combination J+ = v + P/(ρC) will vanish along C+.
Integrating over a ﬁnite interval of time, we recover the constancy of J+ along the
characteristic C+ [Eq. (17.21)].
using characteristics and
Riemann invariants to
solve for details of ﬂow in
domain of dependence
The Riemann invariants provide a general method for deriving the details of the
ﬂow from initial conditions. Suppose that the ﬂuid velocity and the thermodynamic
variables are speciﬁed over an interval of x, designated ∂S, at an initial time t = 0
(Fig. 17.7). This means that J± are also speciﬁed over this interval. We can then
determine J± at any point P in the domain of dependence S of ∂S (i.e., at any point
linked to ∂S by two characteristics C±) by simply propagating each of J± unchanged
along its characteristic. From these values of J± at P, we can solve algebraically for all
the other ﬂow variables (v, P , ρ, etc.) at P. To learn the evolution outside the domain
of dependence S, we must specify the initial conditions outside ∂S.
17.4 1-Dimensional, Time-Dependent Flow
893

x
x
q
q
(a)
(b)
q0
q0
t = 0
t À 0
FIGURE 17.8 Evolution of a nonlinear sound wave. (a) The ﬂuid at the crest of the wave
moves faster than the ﬂuid in the trough. (b) Mathematically, the ﬂow eventually
becomes triple-valued (dashed curve). Physically, a shock wave develops (vertical
solid line).
In practice, we do not actually know the characteristics C± until we have solved
for the ﬂow variables, so we must solve for the characteristics as part of the solution
process. This means, in practice, that the solution involves algebraic manipulations
of (i) the equation of state and the relations J± = v ±

dP/(ρC), which give J±
in terms of v and C; and (ii) the conservation laws that J± are constant along C±
(i.e., along curves dx/dt = v ± C). These algebraic manipulations have the goal of
deducing C(x, t) and v(x, t) from the initial conditions on ∂S. We exhibit a speciﬁc
example in Sec. 17.4.2.
how a nonlinear sound
wave evolves to form a
shock wave
We can use Riemann invariants to understand qualitatively how a nonlinear sound
wave evolves with time. If the wave propagates in the positive x direction into previ-
ously undisturbed ﬂuid (ﬂuid with v = 0), then the J−invariant, propagating back-
ward along C−, is constant everywhere, so v =

dP/(ρC) + const. Let us use q ≡

dP/(ρC) as our wave variable. For an ideal gas with a constant ratio of speciﬁc
heats γ , we have q = 2C/(γ −1), so our oscillating wave variable is essentially the
oscillating sound speed. Constancy of J−then says that v = q −q0, where q0 is the
stagnation value of q (i.e., the value of q in the undisturbed ﬂuid in front of the wave).
Now, J+ = v + q is conserved on each rightward characteristic C+, and so both
v and q are separately conserved on each C+. If we sketch a proﬁle of the wave
pulse as in Fig. 17.8 and measure its amplitude using the quantity q, then the re-
lation v = q −q0 requires that the ﬂuid at the crest of the wave moves faster than
the ﬂuid in a trough. This causes the leading edge of the wave to steepen, a pro-
cess we have already encountered in our discussion of shallow-water solitons (Fig.
16.4). Now, sound waves, by contrast with shallow-water waves (where dispersion
counteracts the steepening), are nondispersive so the steepening will continue until
|dv/dx| →∞(Fig. 17.8). When the velocity gradient becomes sufﬁciently large, vis-
cosity and dissipation become strong, producing an increase of entropy and a break-
down of our isentropic ﬂow. This breakdown and entropy increase will occur in an
extremely thin region—a shock wave, which we study in Sec. 17.5.
894
Chapter 17. Compressible and Supersonic Flow

x
(a)
(b)
(c)
vacuum
vacuum
rarefaction
gas front
C0t
C–
C–
C–
C–
C–
C–
C+
C+
C+
x = –C0t
2C0t
—
(γ – 1)
x = 2C0t
—
(γ – 1)
t = 0
t > 0
t
x
P0
undisturbed
rarefaction wave
FIGURE 17.9 Shock tube. (a) At t ≤0 gas is held at rest at high pressure P0 in the left half of the tube.
(b) At t > 0the high-pressure gas moves rightward down the tube at high speed, and a rarefaction wave
propagates leftward at the sound speed. (c) Space-time diagram showing the ﬂow’s characteristics (C+:
thin dashed lines; C−: thin solid lines) and ﬂuid paths (thick solid lines). To the left of the rarefaction
wave, x < −Cot, the ﬂuid is undisturbed. To the right of the gas front, x > [2/(γ −1)]Cot, resides
undisturbed (near) vacuum.
17.4.2
17.4.2 Shock Tube
We have shown how 1-dimensional isentropic ﬂows can be completely analyzed by
propagatingtheRiemanninvariantsalongcharacteristics.Letusillustratethisinmore
detail by analyzing a shock tube, a laboratory device for creating supersonic ﬂows and
studying the behavior of shock waves. In a shock tube, high-pressure gas is retained
at rest in the left half of a long tube by a thin membrane (Fig. 17.9a). At time t = 0, the
membrane is ruptured by a laser beam, and the gas rushes into the tube’s right half,
which has usually been evacuated. Diagnostic photographs and velocity and pressure
measurements are synchronized with the onset of the ﬂow.
Let us idealize the operation of a shock tube by assuming, once more, that the gas
is ideal with constant γ , so that P ∝ργ. For times t ≤0, we suppose that the gas has
uniform density ρ0 and pressure P0 (and consequently, uniform sound speed C0) at
x ≤0, and that ρ = P = 0 at x ≥0. At time t = 0, the barrier is ruptured, and the gas
ﬂows toward positive x. The ﬁrst Riemann invariant J+ is conserved on C+, which
originates in the static gas, so it has the value
J+ = v +
2C
γ −1 = 2C0
γ −1.
(17.23)
Note that in this case, the invariant is the same on all rightward characteristics (i.e.,
throughout the ﬂow), so that
v = 2(C0 −C)
γ −1
everywhere.
(17.24)
17.4 1-Dimensional, Time-Dependent Flow
895

The second invariant is
J−= v −
2C
γ −1.
(17.25)
Its constant values are not so easy to identify, because those characteristics C−that
travel through the perturbed ﬂow all emerge from the origin, where v and C are
indeterminate (cf. Fig. 17.9c). However, by combining Eq. (17.24) with Eq. (17.25),
we deduce that v and C are separately constant on each characteristic C−. This
enables us, trivially, to solve the differential equation dx/dt = v −C for the leftward
characteristics C−, obtaining
C−:
x = (v −C)t.
(17.26)
Here we have set the constant of integration equal to zero to obtain all the character-
istics that propagate through the perturbed ﬂuid. (For those in the unperturbed ﬂuid,
v = 0 and C = C0, so x = x0 −C0t, with x0 < 0 the characteristic’s initial location.)
ﬂow in a shock tube
Now Eq. (17.26) is true on each characteristic in the perturbed ﬂuid. Therefore, it
is true throughout the perturbed ﬂuid. We can then combine Eqs. (17.24) and (17.26)
tosolveforv(x, t)andC(x, t)throughouttheperturbedﬂuid.Thatsolution, together
with the obvious solution (same as initial data) to the left and right of the perturbed
ﬂuid, is:
v = 0,
C = C0
at x < −C0t,
v =
2
γ + 1

C0 + x
t

,
C = 2C0
γ + 1 −
γ −1
γ + 1
 x
t
at −C0t < x < 2C0
γ −1t,
vacuum prevails at x > 2C0
γ −1t.
(17.27)
In this solution, notice that the gas at x < 0 remains at rest until a rarefaction wave
rarefaction wave as ﬂow
initiator
from the origin reaches it. Thereafter, it is accelerated rightward by the local pressure
gradient, and as it accelerates it expands and cools, so its sound speed C goes down;
asymptotically it reaches zero temperature, as exhibited by C = 0 and an asymptotic
speed v = 2C0/(γ −1) [cf. Eq. (17.23)]; see Fig. 17.9b,c. In the expansion, the internal
random velocity of the gas molecules is transformed into an ordered velocity, just as
in a rocket’s exhaust. However, the total energy per unit mass in the stationary gas
is u = C2
0/[γ (γ −1)] [Eq. (17.2d)], which is less than the asymptotic kinetic energy
per unit mass of 2C2
0/(γ −1)2. The additional energy has come from the gas in the
rarefaction wave, which is pushing the asymptotic gas rightward.
In the more realistic case, where there initially is some low-density gas in the
evacuated half of the tube, the expanding driver gas creates a strong shock as it plows
into the low-density gas; hence the name “shock tube.” In the next section we explore
the structure of this and other shock fronts.
896
Chapter 17. Compressible and Supersonic Flow

EXERCISES
Exercise 17.6 Problem: Fluid Paths in Free Expansion
We have computed the velocity ﬁeld for a freely expanding gas in 1 dimension,
Eqs. (17.27). Use this result to show that the path of an individual ﬂuid element, which
begins at x = x0 < 0, is
x = 2C0t
γ −1 +
γ + 1
γ −1

x0
−C0t
x0

2
γ +1
at
0 < −x0
C0
< t.
Exercise 17.7 Problem: Riemann Invariants for Shallow-Water Flow;
Breaking of a Dam
Consider the 1-dimensional ﬂow of shallow water in a straight, narrow channel,
neglecting dispersion and boundary layers. The equations governing the ﬂow, as
derived and discussed in Box 16.3 and Eqs. (16.23), are
∂h
∂t + ∂(hv)
∂x
= 0,
∂v
∂t + v ∂v
∂x + g ∂h
∂x = 0.
(17.28)
Here h(x, t) is the height of the water, and v(x, t) is its depth-independent velocity.
(a) Find two Riemann invariants J± for these equations, and ﬁnd two conservation
laws for these J± that are equivalent to the shallow-water equations (17.28).
(b) Use these Riemann invariants to demonstrate that shallow-water waves steepen
in the manner depicted in Fig. 16.4, a manner analogous to the peaking of the
nonlinear sound wave in Fig. 17.8.
(c) Use these Riemann invariants to solve for the ﬂow of water h(x, t) and v(x, t)
after a dam breaks (the problem posed in Ex. 16.9, and there solved via similarity
methods). The initial conditions (at t = 0) are v = 0 everywhere, and h = ho at
x < 0, h = 0 (no water) at x > 0.
17.5
17.5 Shock Fronts
We have just demonstrated that in an ideal gas with constant adiabatic index γ , large
perturbations to ﬂuid dynamical variables inevitably evolve to form a divergently
inevitability of shock fronts
large velocity gradient—a “shock front,” or a “shock wave,” or simply a “shock.” When
the velocity gradient becomes large, we can no longer ignore the viscous stress,
because the viscous terms in the Navier-Stokes equation involve second derivatives of
v in space, whereas the inertial term involves only ﬁrst derivatives. As in turbulence
and in boundary layers, so also in a shock front, the viscous stresses convert the ﬂuid’s
ordered, bulk kinetic energy into microscopic kinetic energy (i.e., thermal energy).
The ordered ﬂuid velocity v thereby is rapidly—almost discontinuously—reduced
from supersonic to subsonic, and the ﬂuid is heated.
17.5 Shock Fronts
897

The cooler, supersonic region of incoming ﬂuid is said to be ahead of or upstream
terminology for shocks
fromthe shock, and it hits the shock’s front side; the hotter, subsonic region of outgoing
ﬂuidissaidtobebehind ordownstreamfromtheshock, anditemergesfromtheshock’s
back side; see Fig. 17.10 below.
17.5.1
17.5.1 Junction Conditions across a Shock; Rankine-Hugoniot Relations
role of viscosity in a shock
Viscosityiscrucialtotheinternalstructureoftheshock, butitisjustasnegligibleinthe
downstream ﬂow behind the shock as in the upstream ﬂow ahead of the shock, since
there velocity gradients are modest again. Remarkably, if (as is usually the case) the
shockfrontisverythincomparedtothelengthscalesintheupstreamanddownstream
ﬂows, and the time for the ﬂuid to pass through the shock is short compared to
the upstream and downstream timescales, then we can deduce the net inﬂuence of the
shock on the ﬂow without any reference to the viscous processes that operate in
the shock and without reference to the shock’s detailed internal structure. We do so by
treating the shock as a discontinuity across which certain junction conditions must
be satisﬁed. This is similar to electromagnetic theory, where the junction conditions
for the electric and magnetic ﬁelds across a material interface are independent of the
detailed structure of the interface.
The keys to the shock’s junction conditions are the conservation laws for mass,
momentum, and energy: The ﬂuxes of mass, momentum, and energy must usually be
the same in the downstream ﬂow, emerging from the shock, as in the upstream ﬂow,
entering it. To understand this, we ﬁrst note that, because the time to pass through
the shock is so short, mass, momentum, and energy cannot accumulate in the shock,
so the ﬂow can be regarded as stationary. In a stationary ﬂow, the mass ﬂux is always
constant, as there is no way to create new mass or destroy old mass. Its continuity
across the shock can be written as
mass conservation across
shock
[ρv . n]= 0,
(17.29a)
where n is the unit normal to the shock front, and the square bracket means the
difference in the values on the downstream and upstream sides of the shock. Sim-
ilarly, the total momentum ﬂux T . n must be conserved in the absence of external
forces. Now T has both a mechanical component, P g + ρv ⊗v, and a viscous com-
ponent, −ζθg −2ησ. However, the viscous component is negligible in the upstream
and downstream ﬂows, which are being matched to each other, so the mechanical
component by itself must be conserved across the shock front:
momentum conservation
[(P g + ρv ⊗v) . n]= 0.
(17.29b)
Similar remarks apply to the energy ﬂux, though here we must be slightly more
restrictive. There are three ways that a change in the energy ﬂux could occur. First,
energy may be added to the ﬂow by chemical or nuclear reactions that occur in the
shock front. Second, the gas may be heated to such a high temperature that it will
lose energy in the shock front through the emission of radiation. Third, energy may
898
Chapter 17. Compressible and Supersonic Flow

be conducted far upstream by suprathermal particles so as to preheat the incoming
gas. Any of these processes will thicken the shock front and may make it so thick
that it can no longer sensibly be approximated as a discontinuity. If any of these
processes occurs, we must check to see whether it is strong enough to signiﬁcantly
inﬂuence energy conservation across the shock. What such a check often reveals is
that preheating is negligible, and the lengthscales over which the chemical and nuclear
reactions and radiation emission operate are much greater than the length over which
viscosity acts. In this case we can conserve energy ﬂux across the viscous shock and
then follow the evolutionary effects of reactions and radiation (if signiﬁcant) in the
downstream ﬂow.
A shock with negligible preheating—and with negligible radiation emission and
chemical and nuclear reactions inside the shock—will have the same energy ﬂux in
the departing, downstream ﬂow as in the entering, upstream ﬂow, so it will satisfy
energy conservation
1
2v2 + h

ρv . n

= 0.
(17.29c)
Shocks that satisfy the conservation laws of mass, momentum, and energy, Eqs.
(17.29), are said to be adiabatic.
By contrast to mass, momentum, and energy, the entropy will not be conserved
across a shock front, since viscosity and other dissipative processes increase the
entropy as the ﬂuid ﬂows through the shock. So far, the only type of dissipation that
we have discussed is viscosity, and this is sufﬁcient by itself to produce a shock front
and keep it thin. However, heat conduction (Sec. 18.2) and electrical resistivity, which
is important in magnetic shocks (Chap. 19), can also contribute to the dissipation and
can inﬂuence the detailed structure of the shock front.
For an adiabatic shock, the three requirements of mass, momentum, and energy
conservation [Eqs. (17.29)], known collectively as the Rankine-Hugoniot relations,
enable us to relate the downstream ﬂow and its thermodynamic variables to their
upstream counterparts.2
Let us work in a reference frame where the incoming ﬂow is normal to the shock
front and the shock is at rest, so the ﬂow is stationary in the shock’s vicinity. Then the
conservation of tangential momentum—the tangential component of Eq. (17.29b)—
tells us that the outgoing ﬂow is also normal to the shock in our chosen reference
frame. We say that the shock is normal, not oblique.
We use the subscripts 1, 2 to denote quantities measured ahead of and behind the
shock, respectively (i.e., 1 denotes the incoming ﬂow, and 2 denotes the outgoing ﬂow;
2.
The existence of shocks was actually understood quite early on, more or less in this way, by Stokes.
However, he was persuaded by his former student Rayleigh and others that such discontinuities were
impossible, because they would violate energy conservation. With a deference that professors tradition-
ally show their students, Stokes believed Rayleigh. They were both making an error in their analysis of
energy conservation, due to an inadequate understanding of thermodynamics in that era.
17.5 Shock Fronts
899

downstream
front
back
shock
upstream
P1, u1,
V1 = 1/ρ1
P2, u2,
V2 = 1/ρ2
v2
v1
FIGURE 17.10 Terminology and notation for a shock front
and the ﬂow into and out of it.
Fig. 17.10). The Rankine-Hugoniot relations (17.29) then take the forms:
ρ2v2 = ρ1v1 = j ,
(17.30a)
P2 + ρ2v2
2 = P1 + ρ1v2
1,
(17.30b)
h2 + 1
2v2
2 = h1 + 1
2v2
1,
(17.30c)
where j is the mass ﬂux, which is determined by the upstream ﬂow.
These equations can be brought into a more useful form by replacing the density
ρ with the speciﬁc volume V ≡1/ρ, replacing the speciﬁc enthalpy h by its value
in terms of P and V , h = u + P/ρ = u + P V , and performing some algebra. The
result is
Rankine-Hugoniot jump
conditions across a shock
u2 −u1 = 1
2(P1 + P2)(V1 −V2),
(17.31a)
j2 = P2 −P1
V1 −V2
,
(17.31b)
v1 −v2 = [(P2 −P1)(V1 −V2)]1/2.
(17.31c)
This is the most widely used form of the Rankine-Hugoniot relations. It must be
augmented by an equation of state in the form
equation of state
u = u(P , V ).
(17.32)
Some of the physical content of these Rankine-Hugoniot relations is depicted in
Fig. 17.11. The thermodynamic state of the upstream (incoming) ﬂuid is the point
(V1, P1) in this volume-pressure diagram. The thick solid curve, called the shock
shock adiabat
adiabat,isthesetofallpossibledownstream(outgoing)ﬂuidstates.Thisshockadiabat
can be computed by combining Eq. (17.31a) with the equation of state (17.32). Those
900
Chapter 17. Compressible and Supersonic Flow

possible downstream state
shock adiabat
increasing entropy
upstream state
slope –j2
s = const
s = const
P2
P1
V2
V1
V
P
FIGURE 17.11 Shock adiabat. The pressure and speciﬁc volume V = 1/ρ in the upstream
ﬂow are P1and V1, and in the downstream ﬂow they are P2 and V2. The dashed curves
are ordinary adiabats (curves of constant entropy per unit mass s). The thick curve
is the shock adiabat, the curve of allowed downstream states (V2, P2) for a given
upstream state (V1, P1). The actual location of the downstream state on this adiabat
is determined by the mass ﬂux j ﬂowing through the shock: the slope of the dotted
line connecting the upstream and downstream states is −j2.
equations will actually give a curve that extends away from (V1, P1) in both directions,
up-leftward and down-rightward. Only the up-leftward portion is compatible with an
increase of entropy across the shock; the down-rightward portion requires an entropy
decrease, which is forbidden by the second law of thermodynamics and therefore is
not drawn in Fig. 17.11. The actual location (V2, P2) of the downstream state along the
shock adiabat is determined by Eq. (17.31b) in a simple way: the slope of the dotted
line connecting the upstream and downstream states is −j2, where j is the mass ﬂux
passing through the shock. When one thereby has learned (V2, P2), one can compute
the downstream speed v2 from Eq. (17.31c).
It can be shown that the pressure and density always increase across a shock (as is
the case in Fig. 17.11), and the ﬂuid always decelerates:
pressure and density
increase, and velocity
decrease across shock
P2 > P1,
V2 < V1,
v2 < v1;
(17.33)
seeEx.17.8.Italsocanbedemonstratedingeneral—andwillbeveriﬁedinaparticular
case below, that the Rankine-Hugoniot relations require the ﬂow to be supersonic
with respect to the shock front upstream v1 > C1 and subsonic downstream, v2 < C2.
Physically, this requirement is sensible (as we have seen): When the ﬂuid approaches
the shock supersonically, it is not possible to communicate a pressure pulse upstream
from the shock (via a Riemann invariant moving at the speed of sound relative to the
17.5 Shock Fronts
901

ﬂow) and thereby cause the ﬂow to decelerate; therefore, to slow the ﬂow, a shock
must develop.3 By contrast, the shock front can and does respond to changes in the
downstream conditions, since it is in causal contact with the downstream ﬂow; sound
waves and a Riemann invariant can propagate upstream, through the downstream
ﬂow, to the shock.
summary of shocks
To summarize, shocks are machines that decelerate a normally incident upstream
ﬂow to a subsonic speed, so it can be in causal contact with conditions downstream. In
the process, bulk momentum ﬂux ρv2 is converted into pressure, bulk kinetic energy
is converted into internal energy, and entropy is manufactured by the dissipative
processes at work in the shock front. For given upstream conditions, the downstream
conditions are ﬁxed by the conservation laws of mass, momentum, and energy and
are independent of the detailed dissipation mechanisms.
EXERCISES
Exercise 17.8 Derivation and Challenge: Signs of Change across a Shock
(a) Almost all equations of state satisfy the condition (∂2V/∂P 2)s > 0. Show that,
when this condition is satisﬁed, the Rankine-Hugoniot relations and the law of
entropy increase imply that the pressure and density must increase across a shock
and the ﬂuid must decelerate: P2 > P1, V2 < V1, and v2 < v1.
(b) Show that in a ﬂuid that violates (∂2V/∂P 2)s > 0, the pressure and density must
still increase and the ﬂuid decelerate across a shock, as otherwise the shock would
be unstable.
For a solution to this exercise, see Landau and Lifshitz (1959, Sec. 84).
Exercise 17.9 Problem: Relativistic Shock
In astrophysics (e.g., in supernova explosions and in jets emerging from the vicinities
of black holes), one sometimes encounters shock fronts for which the ﬂow speeds
relative to the shock approach the speed of light, and the internal energy density is
comparable to the ﬂuid’s rest-mass density.
(a) Show that the relativistic Rankine-Hugoniot equations for such a shock take the
following form:
η2
2 −η2
1 = (P2 −P1)(η1V1 + η2V2),
(17.34a)
j2 =
P2 −P1
η1V1 −η2V2
,
(17.34b)
v2γ2 = jV2,
v1γ1 = jV1.
(17.34c)
3.
Of course, if there is some faster means of communication, for example, photons or, in an astrophysical
context, cosmicraysorneutrinos, thentheremaybeacausalcontactbetweentheshockandtheinﬂowing
gas, which can either prevent shock formation or lead to a more complex shock structure.
902
Chapter 17. Compressible and Supersonic Flow

Here,
(i) We use units in which the speed of light is 1 (as in Chap. 2).
(ii) The volume per unit rest mass is V ≡1/ρo, and ρo is the rest-mass density
(equal to some standard rest mass per baryon times the number density of
baryons; cf. Sec. 2.12.3).
(iii) We denote the total density of mass-energy including rest mass by ρR (it
was denoted ρ in Chap. 2) and the internal energy per unit rest mass by
u, so ρR = ρo(1 + u). In terms of these the quantity η ≡(ρR + P )/ρo =
1 + u + P/ρo = 1 + h is the relativistic enthalpy per unit rest mass (i.e.,
the enthalpy per unit rest mass, including the rest-mass contribution to the
energy) as measured in the ﬂuid rest frame.
(iv) The pressure as measured in the ﬂuid rest frame is P.
(v) The ﬂow velocity in the shock’s rest frame is v, and γ ≡1/
√
1 −v2 (not the
adiabatic index!), so vγ is the spatial part of the ﬂow 4-velocity.
(vi) The rest-mass ﬂux is j (rest mass per unit area per unit time) entering and
leaving the shock.
(b) Use a pressure-volume diagram to discuss these relativistic Rankine-Hugoniot
equations in a manner analogous to Fig. 17.11.
(c) Showthatinthenonrelativisticlimit, therelativisticRankine-Hugoniotequations
(17.34) reduce to the nonrelativistic ones (17.31).
(d) It can be shown (Thorne, 1973) that relativistically, just as for nonrelativistic
shocks, in general P2 > P1, V2 < V1, and v2 < v1. Consider, as an example, a
relativistic shock propagating through a ﬂuid in which the mass density due
to radiation greatly exceeds that due to matter (a radiation-dominated ﬂuid),
so P = ρR/3 (Sec. 3.5.5). Show that v1v2 = 1/3, which implies v1 > 1/
√
3 and
v2 < 1/
√
3. Show further that P2/P1 = (9v12 −1)/[3(1 −v12)].
Exercise 17.10 **Problem: Hydraulic Jumps and Breaking Ocean Waves
Run water at a high ﬂow rate from a kitchen faucet onto a dinner plate (Fig. 17.12).
What you see is called a hydraulic jump. It is the kitchen analog of a breaking ocean
wave, and the shallow-water-wave analog of a shock front in a compressible gas. In this
exercise you will develop the theory of hydraulic jumps (and breaking ocean waves)
using the same tools as those used for shock fronts.
(a) Recall that for shallow-water waves, the water motion, below the water’s surface,
is nearly horizontal, with speed independent of depth z (Ex. 16.1). The same is
true of the water in front of and behind a hydraulic jump. Apply the conservation
of mass and momentum to a hydraulic jump, in the jump’s rest frame, to obtain
equations for the height of the water h2 and water speed v2 behind the jump
(emerging from it) in terms of those in front of the jump, h1 and v1. These
are the analog of the Rankine-Hugoniot relations for a shock front. [Hint: For
17.5 Shock Fronts
903

FIGURE 17.12 Hydraulic jump on a dinner plate under a kitchen tap.
momentum conservation you will need to use the pressure P as a function of
height in front of and behind the jump.]
(b) You did not use energy conservation across the jump in your derivation, but it
was needed in the analysis of a shock front. Why?
(c) Show that the upstream speed v1 is greater than the speed

gh1 of small-
amplitude, upstream gravity waves [shallow-water waves; Eq. (16.10) and as-
sociated discussion]; thus the upstream ﬂow is supersonic. Similarly, show that
the downstream ﬂow speed v2 is slower than the speed

gh2 of small-amplitude,
downstream gravity waves (i.e., the downstream ﬂow is subsonic).
(d) We normally view a breaking ocean wave in the rest frame of the quiescent
upstream water. Use your hydraulic-jump equations to show that the speed of
the breaking wave as seen in this frame is related to the depths h1 and h2 in front
of and behind the breaking wave by
vbreak =
g(h1 + h2)h2
2h1
1/2
;
see Fig. 17.13.
17.5.2
17.5.2 Junction Conditions for Ideal Gas with Constant γ
shock Mach number
To make the shock junction conditions more explicit, let us again specialize to an ideal
gas with constant speciﬁc-heat ratio γ (a polytropic gas), so the equation of state is
904
Chapter 17. Compressible and Supersonic Flow

h2
h1
vbreak
v = 0
FIGURE 17.13 An ocean wave breaking on a gradually sloping beach. The depth of
water ahead of the wave is h1, and the depth behind the wave is h2.
u = PV/(γ −1), and the sound speed is C = √γ P/ρ = √γ P V [Eqs. (17.2)]. We
measure the strength of the shock using the shock Mach number M, which is deﬁned
to be the Mach number in the upstream ﬂow relative to the shock:
M ≡M1 = v1/C1 =

v2
1/(γ P1V1).
(17.35)
With the aid of this equation of state and Mach number, we can bring the Rankine-
Hugoniot relations (17.31) into the form:
Rankine-Hugoniot
relations for polytropic
equation of state
ρ1
ρ2
= V2
V1
= v2
v1
= γ −1
γ + 1 +
2
(γ + 1)M2 ,
(17.36a)
P2
P1
= 2γ M2
γ + 1 −γ −1
γ + 1,
(17.36b)
M2
2 = 2 + (γ −1)M2
2γ M2 −(γ −1).
(17.36c)
Here M2 ≡v2/c2 is the downstream Mach number.
The results for this equation of state illustrate a number of general features of
shocks. The density and pressure increase across the shock, the ﬂow speed decreases,
and the downstream ﬂow is subsonic—all discussed previously—and one important
new feature: a shock weakens as its Mach number M decreases. In the limit that
M →1, the jumps in pressure, density, and speed vanish, and the shock disappears.
In the strong-shock limit, M ≫1, the jumps are
Rankine-Hugoniot
relations for strong
polytropic shock
ρ1
ρ2
= V2
V1
= v2
v1
≃γ −1
γ + 1,
(17.37a)
P2
P1
≃2γ M2
γ + 1 .
(17.37b)
17.5 Shock Fronts
905

Thus the density jump is always of order unity, but the pressure jump grows ever larger
asM increases.Airhasγ ≃1.4 (Ex.17.1), sothedensitycompressionratioforastrong
shock in air is ρ2/ρ1 = 6, and the pressure ratio is P2/P1 = 1.2M2. The Space Shuttle’s
reentry provides a nice example of these strong-shock Rankine-Hugoniot relations;
see the bottom half of Box 17.4.
EXERCISES
Exercise 17.11 Problem: Shock Tube
Consider a shock tube as discussed in Sec. 17.4.2 and Fig. 17.9. High density “driver”
gas with sound speed C0 and speciﬁc heat ratio γ is held in place by a membrane
that separates it from target gas with very low density, sound speed C1, and the same
speciﬁc-heat ratio γ . When the membrane is ruptured, a strong shock propagates into
the target gas. Show that the Mach number of this shock is given approximately by
M =
γ + 1
γ −1
 C0
C1

.
(17.38)
[Hint: Think carefully about which side of the shock is supersonic and which side
subsonic.]
17.5.3
17.5.3 Internal Structure of a Shock
Although they are often regarded as discontinuities, shocks, like boundary layers, do
havestructure.Thesimplestcaseisthatofagasinwhichtheshear-viscositycoefﬁcient
is molecular in origin and is given by η = ρν ∼ρλvth/3, where λ is the molecular
molecular collisions as
dissipation mechanism in
some shocks
mean free path, and vth ∼C is the mean thermal speed of the molecules (Ex. 3.19).
In this case for 1-dimensional ﬂow v = vx(x), the viscous stress Txx = −ζθ −2ησxx
is −(ζ + 4η/3)dv/dx, where ζ is the coefﬁcient of bulk viscosity, which can be of
the same order as the coefﬁcient of shear viscosity. In the shock, this viscous stress
must roughly balance the total kinetic momentum ﬂux ∼ρv2. If we estimate the
velocity gradient dv/dx by v1/δS, where δS is a measure of the shock thickness, and we
estimate the sound speed in the shock front by C ∼v1, then we deduce that the shock
thickness δS is roughly equal to λ, the collision mean free path in the gas. For air at
standard temperature and pressure, the mean free path is λ ∼(
√
2nπσ 2)−1 ∼70 nm,
where n is the molecular density, and σ is the molecular diameter. This is very small!
Microscopically, itmakessensethatδS ∼λ, asanindividualmoleculeonlyneedsafew
collisionstorandomizeitsorderedmotionperpendiculartotheshockfront.However,
this estimate raises a problem, as it brings into question our use of the continuum
approximation (cf. Sec. 13.2). It turns out that, when a more careful calculation of the
shock structure is carried out incorporating heat conduction, the shock thickness is
shock thickness: several
mean free paths
several mean free paths, ﬂuid dynamics is acceptable for an approximate theory, and
the results are in rough accord with measurements of the velocity proﬁles of shocks
with modest Mach numbers. Despite this, for an accurate description of the shock
structure, a kinetic treatment is usually necessary.
906
Chapter 17. Compressible and Supersonic Flow

vp
vpt1
vpt2
α
C0t1
C0t2
present projectile position
FIGURE 17.14 Construction for the Mach cone formed by a supersonic projectile.
The cone angle is α = sin−1(1/M), where M = vp/C0 is the Mach number of
the projectile.
So far we have assumed that the shocked ﬂuid is made of uncharged molecules. A
more complicated type of shock can arise in an ionized gas (i.e., a plasma; Part VI).
Shocks in the solar wind are examples. In this case the collision mean free paths
are enormous; in fact, they are comparable to the transverse size of the shock, and
therefore one might expect the shocks to be so thick that the Rankine-Hugoniot
relations fail. However, spacecraft measurements reveal solar-wind shocks that are
relatively thin—far thinner than the collisional mean free paths of the plasma’s elec-
dissipation mechanisms
for shocks in collisionless
plasmas
trons and ions. In this case, it turns out that collisionless, collective electromagnetic
and charged-particle interactions in the plasma are responsible for the viscosity and
dissipation. (The particles create plasma waves, which in turn deﬂect the particles.)
These processes are so efﬁcient that thin shock fronts can occur without individual
particles having to hit one another. Since the shocks are thin, they must satisfy the
Rankine-Hugoniotrelations.WediscussthesecollisionlessshocksfurtherinSec.23.6.
17.5.4
17.5.4 Mach Cone
Mach cone
The shock waves formed by a supersonically moving body are quite complex close to
the body and depend on its detailed shape, Reynolds’ number, and so forth (see, e.g.,
Fig. 17.1). However, far from the body, the leading shock has the form of the Mach
cone shown in Fig. 17.14. We can understand this cone by the construction shown in
the ﬁgure. The shock is the boundary between the ﬂuid that is in sound-based causal
contact with the projectile and the ﬂuid that is not. This boundary is mapped out
by (conceptual) sound waves that propagate into the ﬂuid from the projectile at the
ambient sound speed C0. When the projectile is at the indicated position, the envelope
of the circles is the shock front and has the shape of the Mach cone, with opening angle
(the Mach angle)
α = sin−1(1/M).
(17.39)
17.5 Shock Fronts
907

δP
ground
FIGURE 17.15 Double shock created by a supersonic body and its associated N-wave pressure
distribution on the ground.
Usually, there are two such shock cones, one attached to the projectile’s bow
shock and the other formed out of the complex shock structure in its tail region. The
pressure must jump twice, once across each of these shocks, and therefore forms an N
wave,which propagates cylindrically away from the projectile, as shown in Fig. 17.15.
Behind the ﬁrst shock, the density and pressure drop off gradually by more than the
ﬁrst shock’s compression. As a result, the ﬂuid ﬂowing into the second shock has a
lower pressure, density, and sound speed than that ﬂowing into the ﬁrst (Fig. 17.15).
This causes the Mach number of the second shock to be higher than that of the ﬁrst,
and its Mach angle thus to be smaller. As a result, the separation between the shocks
increases as they travel as ϖ 1/2, it turns out. The pressure jumps across the shocks
decrease as ϖ −3/4. Here ϖ is the perpendicular distance of the point of observation
from the projectile’s trajectory. Often a double boom can be heard on the ground. For
a detailed analysis, see Whitham (1974, Sec. 9.3).
EXERCISES
Exercise 17.12 Problem: Sonic Boom from the Space Shuttle
Use the quoted scaling of N-wave amplitude with cylindrical radius ϖ to make
an order-of-magnitude estimate of the ﬂux of acoustic energy produced by the
Space Shuttle ﬂying at Mach 2 at an altitude of 20 km. Give your answer in decibels
[Eq. (16.61)].
17.6
17.6 Self-Similar Solutions—Sedov-Taylor Blast Wave
Strong explosions can generate shock waves. Examples include atmospheric nuclear
explosions, supernova explosions, and depth charges. The debris from a strong explo-
sion is at much higher pressure than the surrounding gas and therefore drives a strong
spherical shock into its surroundings. Initially, this shock wave travels at roughly the
908
Chapter 17. Compressible and Supersonic Flow

radial speed of the expanding debris. However, the mass of ﬂuid swept up by the shock
eventually exceeds that of the explosion debris. The shock then decelerates and the
energy of the explosion is transferred to the swept-up ﬂuid. It is of obvious importance
to be able to calculate how fast and how far the shock front will travel.
17.6.1
17.6.1 The Sedov-Taylor Solution
We ﬁrst make an order-of-magnitude estimate. Let the total energy of the explosion
be E and the density of the surrounding ﬂuid (assumed uniform) be ρ0. Then after
time t, when the shock radius is R(t), the mass of swept-up ﬂuid will be m ∼ρ0R3.
The ﬂuid velocity behind the shock will be roughly the radial velocity of the shock
front, v ∼˙R ∼R/t, and so the kinetic energy of the swept-up gas will be ∼mv2 ∼
ρ0R5/t2. There will also be internal energy in the post-shock ﬂow, with energy density
roughly equal to the post-shock pressure: ρu ∼P ∼ρ0 ˙R2 [cf. the strong-shock jump
condition (17.37b) with P1 ∼ρ0C2
0, so P1M2 ∼ρ0v2 ∼ρ0 ˙R2]. The total internal
energybehindtheexpandingshockwillthenbe∼ρ ˙R2R3 ∼ρ0R5/t2, equalinorderof
magnitude to the kinetic energy. Equating this to the total energy E of the explosion,
we obtain the estimate
E = κρ0R5t−2,
(17.40)
where κ is a numerical constant of order unity. This expression implies that at time t
the shock front has reached the radius
radius of a strong,
spherical shock as a
function of time
R =
 E
κρ0
1/5
t2/5.
(17.41)
This scaling should hold roughly from the time that the mass of the swept-up gas is
of order that of the exploding debris, to the time that the shock weakens to a Mach
number of order unity so we can no longer use the strong-shock value ∼ρ0 ˙R2 for the
post-shock pressure.
Note that we could have obtained Eq. (17.41) by a purely dimensional argu-
ment: E and ρ0 are the only signiﬁcant controlling parameters in the problem, and
E1/5ρ−1/5
0
t2/5 is the only quantity with dimensions of length that can be constructed
from E, ρ0, and t. However, it is usually possible and always desirable to justify any
such dimensional argument on the basis of the governing equations.
If, as we shall assume, the motion remains radial and the gas is ideal with constant
speciﬁc-heat ratio γ , then we can solve for the details of the ﬂow behind the shock
front by integrating the radial ﬂow equations:
∂ρ
∂t + 1
r2
∂
∂r (r2ρv) = 0,
(17.42a)
∂v
∂t + v ∂v
∂r + 1
ρ
∂P
∂r = 0,
(17.42b)
∂
∂t
 P
ργ

+ v ∂
∂r
 P
ργ

= 0.
(17.42c)
17.6 Self-Similar Solutions—Sedov-Taylor Blast Wave
909

TheﬁrsttwoequationsarethefamiliarcontinuityequationandEulerequationwritten
for a spherical ﬂow. The third equation is energy conservation expressed as the
adiabatic-expansion relation, P/ργ = const moving with a ﬂuid element. Although
P/ργ is time independent for each ﬂuid element, its value will change from element to
element. Gas that has passed through the shock more recently will be given a smaller
entropy than gas that was swept up when the shock was stronger, and thus it will have
a smaller value of P/ργ.
Given suitable initial conditions, the partial differential equations (17.42) can
be integrated numerically. However, there is a practical problem: it is not easy to
determine the initial conditions in an explosion! Fortunately, at late times, when the
initialdebrismassisfarlessthantheswept-upmass, theﬂuidevolutionisindependent
of the details of the initial expansion and in fact can be understood analytically as
a similarity solution. By this term we mean that the shape of the radial proﬁles of
pressure, density, and velocity are independent of time.
examples of similarity
solutions
We have already met three examples of similarity solutions: the Blasius structure
of a laminar boundary layer (Sec. 14.4.1), the structure of a turbulent jet (Ex. 15.3),
and the ﬂow of water following the sudden rupture of a dam (Ex. 16.9). The one
we explored in greatest detail was the Blasius boundary layer (Sec. 14.4.1). There
we argued on the basis of mass and momentum conservation (or, equally well, by
dimensionalanalysis)thatthethicknessoftheboundarylayerasafunctionofdistance
x downstream would be ∼δ = (νx/V )1/2, where V is the speed of the ﬂow above the
boundary layer. This motivated us to introduce the dimensionless variable ξ = y/δ
and argue that the boundary layer’s speed vx(x, y) would be equal to the free-stream
velocity V times some universal function f ′(ξ). This ansatz converted the ﬂuid’s
partial differential equations into an ordinary differential equation for f (ξ), which
we solved numerically.
Our explosion problem is somewhat similar. The characteristic scaling length in
the explosion is the radius R(t) = [E/(κρ0)]1/5t2/5 of the shock [Eq. (17.41)], with
κ an as-yet-unknown constant, so the ﬂuid and thermodynamic variables should be
expressible as some characteristic values multiplying universal functions of
ξ ≡r/R(t).
(17.43)
Our thermodynamic variables are P , ρ, and u, and natural choices for their character-
similarity solution behind
strong, spherical shock
istic values are the values P2, ρ2, and v2 immediately behind the shock. If we assume
the shock is strong, then we can use the strong-shock jump conditions (17.37) to
determine those values, and then write
P =
2
γ + 1ρ0 ˙R2 ˜P (ξ),
(17.44a)
ρ = γ + 1
γ −1ρ0 ˜ρ(ξ),
(17.44b)
v =
2
γ + 1
˙R ˜v(ξ),
(17.44c)
910
Chapter 17. Compressible and Supersonic Flow

with ˜P (1) = ˜ρ(1) = ˜v(1) = 1, since ξ = 1is the shock’s location. Note that the velocity
v is scaled to the post-shock velocity v2 measured in the inertial frame in which the
upstream ﬂuid is at rest, rather than in the noninertial frame in which the decelerating
shock is at rest. The self-similarity ansatz (17.44) and resulting similarity solution for
the ﬂow are called the Sedov-Taylor blast-wave solution, since L. I. Sedov and G. I.
Taylor independently developed it (Sedov, 1946, 1993; Taylor, 1950).
The partial differential equations (17.42) can now be transformed into ordinary
differential equations by inserting the ansatz (17.44) together with expression (17.41)
for R(t), changing the independent variables from r and t to R and ξ and using
 ∂
∂t

r
= −
*
ξ ˙R
R
+  ∂
∂ξ

R
+ ˙R
 ∂
∂R

ξ
= −
2ξ
5t
  ∂
∂ξ

R
+ 2R
5t
 ∂
∂R

ξ
,
(17.45)
 ∂
∂r

t
=
 1
R
  ∂
∂ξ

R
.
(17.46)
Mass conservation, the Euler equation, and the equation of adiabatic expansion be-
come, in that order:
differential equations for
similarity solution
0 = 2 ˜ρ ˜v′ −(γ + 1)ξ ˜ρ′ + ˜v

2 ˜ρ′ + 4
ξ ˜ρ

,
(17.47a)
0 = ˜ρ ˜v[3(γ + 1) −4˜v′]+ 2(γ + 1)ξ ˜ρ ˜v′ −2(γ −1) ˜P ′,
(17.47b)
3 =
 2˜v
γ + 1 −ξ
 *
˜P ′
˜P
−γ ˜ρ′
˜ρ
+
.
(17.47c)
These self-similarity equations can be solved numerically, subject to the boundary
conditions that ˜v, ˜ρ, and ˜P are all zero at ξ = 0 and 1 at ξ = 1. Remarkably, Sedov
and Taylor independently found an analytic solution (also given in Landau and Lif-
shitz, 1959, Sec. 99). The solutions for an explosion in air (γ = 1.4) are exhibited in
Fig. 17.16.
Armed with the solution for ˜v(ξ), ˜ρ(ξ), and ˜P (ξ) (numerical or analytic), we can
evaluate the ﬂow’s energy E, which is equal to the explosion’s total energy during the
time interval when this similarity solution is accurate. The energy E is given by the
integral
explosion’s total energy
E =
 R
0
4πr2drρ
1
2v2 + u

= 4πρ0R3 ˙R2(γ + 1)
(γ −1)
 1
0
dξξ2 ˜ρ
*
2˜v2
(γ + 1)2 +
2 ˜P
(γ + 1)2 ˜ρ
+
.
(17.48)
Here we have used Eqs. (17.44) and substituted u = P/[ρ(γ −1)] for the internal
energy [Eq. (17.2b)]. The energy E appears not only on the left-hand side of this
equation but also on the right, in the terms ρoR3 ˙R2 = (4/25)E/κ. Thus, E cancels
17.6 Self-Similar Solutions—Sedov-Taylor Blast Wave
911

v˜(ξ)
ξ
ρ˜(ξ)
P˜(ξ)
γ = 1.4
1.0
0.5
0.0
0.5
1.0
FIGURE 17.16 Scaled pressure, density, and
velocity as a function of scaled radius behind
a Sedov-Taylor blast wave in air with γ = 1.4.
out, and Eq. (17.48) becomes an equation for the unknown constant κ. Evaluating that
equation numerically, we ﬁnd that κ varies from κ = 0.85 for γ = 1.4 (air) to κ = 0.49
for γ = 1.67 (monatomic gas or fully ionized plasma).
It is enlightening to see how the ﬂuid behaves in this blast-wave solution. The ﬂuid
that passes through the shock is compressed, so that it mostly occupies a fairly thin
spherical shell immediately behind the shock [see the spike in ˜ρ(ξ) in Fig. 17.16].
The ﬂuid in this shell moves somewhat more slowly than the shock [v = 2 ˙R/(γ + 1);
Eq. (17.44c) and Fig. 17.16]; it ﬂows from the shock front through the high-density
shell (fairly slowly relative to the shell, which remains attached to the shock), and on
into the lower density post-shock region. Since the post-shock ﬂow is subsonic, the
pressure in the blast wave is fairly uniform [see the curve ˜P (ξ) in Fig. 17.16]; in fact
the central pressure is typically about half the maximum pressure immediately behind
the shock. This pressure pushes on the spherical shell, thereby accelerating the freshly
swept-up ﬂuid.
17.6.2
17.6.2 Atomic Bomb
TheﬁrstatomicbombwasexplodedinNewMexicoin1945, andphotographsreleased
in 1947 (Fig. 17.17) showed the radius of the blast wave as a function of time. The
pictures were well ﬁt by R ∼37(t/1 ms)0.4 m up to about t = 100 ms, when the
shock Mach number fell to about unity (Fig. 17.17). Combining this information with
the similarity solution (Sec. 17.6.1), that they had earlier derived independently, the
Russian physicist L. I. Sedov and the British physicist G. I. Taylor were both able to
infer the total energy released, which was an ofﬁcial American secret at the time. Their
analyses of the data were published later (Taylor, 1950; Sedov, 1957, 1993).
Adopting the speciﬁc-heat ratio γ = 1.4 of air, the corresponding value κ = 0.85,
and the measured R ∼37(t/1 ms)0.4 m, we obtain from Eq. (17.48) the estimate
912
Chapter 17. Compressible and Supersonic Flow

100 meters
FIGURE 17.17 Photographs of the ﬁreball (very hot post-shock gas) from the ﬁrst
atomic bomb explosion, at Almagordo, New Mexico, on July 16, 1945. Courtesy of
the Los Alamos National Laboratory Archives.
E ∼7.2 × 1013 J, which is about the same energy release as 17 kilotons of TNT. This
estimate is close to the Los Alamos scientists’ estimate of 18–20 kilotons. (Hydrogen
bombs have been manufactured that are more than a thousand times more energetic
than this—as much as 57 megatons—but such awesome weapons have not been
deemed militarily useful, so today’s arsenals contain bombs that are typically only
∼1 megaton!)
We can use the Sedov-Taylor solution to infer some further features of the ex-
plosion. The post-shock gas is at density ∼(γ + 1)/(γ −1) ∼5 times the ambient
density ρ0 ∼1 kg m−3. Similarly, using the ideal gas law P = [ρ/(mpμ)]kBT with
17.6 Self-Similar Solutions—Sedov-Taylor Blast Wave
913

a mean molecular weight μ ∼10 and the strong-shock jump conditions (17.37), the
post-shock temperature can be computed:
T2 =
mpμ
ρ2kB
P2 ∼4 × 104

t
1 ms
−1.2
K.
(17.49)
At early times, this temperature is high enough to ionize the gas.
17.6.3
17.6.3 Supernovae
The evolution of most massive stars ends in a supernova explosion (like the one
observed in 1987 in the Large Magellanic Cloud), in which a neutron star of mass
m ∼3 × 1030 kg is usually formed. This neutron star has a gravitational binding
energy of about 0.1mc2 ∼3 × 1046 J. Most of this binding energy is released in the
form of neutrinos in the collapse that forms the neutron star, but an energy E ∼1044 J
drives off the outer envelope of the pre-supernova star, a mass M0 ∼1031 kg. This
stellar material escapes with an rms speed V0 ∼(2E/M0)1/2 ∼5,000 km s−1. The
expanding debris drives a blast wave into the surrounding interstellar medium, which
has density ρ0 ∼10−21 kg m−3. The expansion of the blast wave can be modeled
using the Sedov-Taylor solution after the mass of the swept-up interstellar gas has
become large enough to dominate the blast debris, so the star-dominated initial
conditions are no longer important—after a time ∼(3M0/4πρ0)1/3/V0 ∼1,000 yr.
The blast wave then decelerates as for a Sedov-Taylor similarity solution until the
shock speed nears the sound speed in the surrounding gas; this takes about 100,000 yr.
Supernova remnants of this sort are efﬁcient emitters of radio waves and X-rays, and
several hundred have been observed in our Milky Way galaxy.
In some of the younger examples, like Tycho’s remnant (Fig. 17.18), it is possible
to determine the expansion speed, and the effects of deceleration can be measured.
The observations from remnants like this are close to the prediction of the Sedov-
Taylor solution; namely, the radius variation satisﬁes d ln R/d ln t = 0.4. (For Tycho’s
remnant, a value of 0.54 ± 0.05 is found, and using the estimated density of the
interstellar medium plus the kinematics, an explosion energy of E ∼5 × 1043 J is
inferred.)
EXERCISES
Exercise 17.13 Problem: Underwater Explosions
A simple analytical solution to the Sedov-Taylor similarity equations can be found for
the particular case γ = 7. This is a fair approximation to the behavior of water under
explosive conditions, as it will be almost incompressible.
(a) Make the ansatz (whose self-consistency we will check later) that the velocity
in the post-shock ﬂow varies linearly with radius from the origin to the shock:
˜v(ξ) = ξ. Use Eq. (17.45) to transform the equation of continuity into an ordinary
differential equation and hence solve for the density function ˜ρ(ξ).
914
Chapter 17. Compressible and Supersonic Flow

FIGURE 17.18 This remnant of the supernova explosion observed by the astronomer
Tycho Brahe in 1572 is roughly 7,000 light-years from us. (Recent observations
of a light echo have demonstrated that the supernova was of the same type used
to discover the acceleration of the universe, which is discussed in Ex. 28.6.) This
image was made by the Chandra X-ray Observatory and shows the emission from
the hot (in red) (∼1−10 × 107 K) gas heated by the outer and inner shock fronts
as well as the even more energetic (in blue) X-rays that delineate the position of the
outer shock front. Shock fronts like this are believed to be the sites for acceleration
of galactic cosmic rays (cf. Sec. 19.7, Ex. 23.8). NASA/CXC/Rutgers/J. Warren
and J. Hughes, et al.
(b) Next use the equation of motion to discover that ˜P (ξ) = ξ3.
(c) Verify that your solutions for the functions ˜P , ˜ρ, and ˜v satisfy the remaining
entropy equation, thereby vindicating the original ansatz.
(d) Substitute your results from parts (a) and (b) into Eq. (17.48) to show that
E = 2πR5ρ0
225t2 .
(e) An explosive charge weighing 100 kg with an energy release of 108 J kg−1 is deto-
nated underwater. For what range of shock radii do you expect the Sedov-Taylor
similarity solution to be valid?
Exercise 17.14 Problem: Stellar Winds
Many stars possess powerful stellar winds that drive strong spherical shock waves into
the surrounding interstellar medium. If the strength of the wind remains constant, the
17.6 Self-Similar Solutions—Sedov-Taylor Blast Wave
915

kinetic and internal energy of the swept-up interstellar medium will increase linearly
with time.
(a) Modify the text’s analysis of a point explosion to show that in this case the speed
of the shock wave at time t is 3
5R(t)/t, where R is the associated shock radius.
What is the speed of the post-shock gas?
(b) Now suppose that the star explodes as a supernova, and the blast wave expands
into the relatively slowly moving stellar wind. Suppose that before the explosion
the rate at which mass left the star and the speed of the wind were constant for a
long time. How do you expect the density of gas in the wind to vary with radius?
Modify the Sedov-Taylor analysis again to show that the expected speed of the
shock wave at time t is now 2
3R(t)/t.
Exercise 17.15 Problem: Similarity Solution for a Shock Tube
Use a similarity analysis to derive the solution (17.27) for the shock-tube ﬂow depicted
in Fig. 17.9.
Bibliographic Note
For physical insight into compressible ﬂows and shock waves, we recommend the
movies cited in Box 17.2. For textbook treatments, we recommend the relevant sec-
tionsofLandauandLifshitz(1959); Thompson(1984); LiepmannandRoshko(2002);
Anderson (2003); and, at a more elementary and sometimes cursory level, Lautrup
(2005). Whitham (1974) is superb on all aspects, from an applied mathematician’s
viewpoint.
Engineering-oriented textbooks on ﬂuid mechanics generally contain detailed
treatments of quasi-1-dimensional ﬂows, shocks, hydraulic jumps, and their real-
world applications. We like Munson, Young, and Okiishi (2006), White (2006), and
Potter, Wiggert, and Ramadan (2012).
The two-volume treatise Zel’dovich and Raizer (2002) is a compendium of insights
into shock waves and high-temperature hydrodynamics by an author (Yakov Boriso-
vich Zel’dovich) who had a huge inﬂuence on the design of atomic and thermonuclear
weapons in the Soviet Union and later on astrophysics and cosmology. Stanyukovich
(1960) is a classic treatise on nonstationary ﬂows, shocks and detonation waves. Sedov
(1993)—the tenth edition of a book whose ﬁrst was in 1943—is a classic and insightful
treatise on similarity methods in physics.
916
Chapter 17. Compressible and Supersonic Flow

18
CHAPTER EIGHTEEN
Convection
Approximation methods derived from physical intuition are frequently more reliable than
rigorous mathematical methods, because in the case of the latter it is easier
for errors to creep into the fundamental assumptions.
WERNER HEISENBERG (1969)
18.1
18.1 Overview
In Chaps. 13 and 14, we demonstrated that viscosity can exert a major inﬂuence
on subsonic ﬂuid ﬂows. When the viscosity ν is large and the Reynolds number
(Re = LV/ν) is low, viscous stresses transport momentum directly, and the ﬂuid’s
behavior can be characterized by the diffusion of the vorticity (ω = ∇× v) through
the ﬂuid [cf. Eq. (14.3)]. As the Reynolds number increases, the advection of the
vorticity becomes more important. In the limit of large Reynolds number, we think of
the vortex lines as being frozen into the ﬂow. However, as we learned in Chap. 15,
this insight is only qualitatively helpful, because high-Reynolds-number ﬂows are
invariably turbulent. Large, irregular, turbulent eddies transport shear stress very
efﬁciently. This is particularly in evidence in turbulent boundary layers.
When viewed microscopically, heat conduction is a similar transport process to
viscosity, and it is responsible for analogous physical effects. If a viscous ﬂuid has
high viscosity, then vorticity diffuses through it rapidly; similarly, if a ﬂuid has high
thermal conductivity, then heat diffuses through it rapidly. In the other extreme,
when viscosity is low (i.e., when the Reynolds number is high), instabilities produce
turbulence, which transports vorticity far more rapidly than diffusion could possibly
do. Analogously, in heated ﬂuids with low conductivity, the local accumulation of
heat drives the ﬂuid into convective motion, and the heat is transported much more
efﬁciently by this motion than by thermal diffusion. As the convective heat transport
increases, the ﬂuid motion becomes more vigorous, and if the viscosity is sufﬁciently
low, the thermally driven ﬂow can also become turbulent. These effects are very much
in evidence near solid boundaries, where thermal boundary layers can be formed,
analogous to viscous boundary layers.
In addition to thermal effects that resemble the effects of viscosity, there are also
unique thermal effects—particularly the novel and subtle combined effects of gravity
and heat. Heat, unlike vorticity, causes a ﬂuid to expand and thus, in the presence
917

BOX 18.1.
READERS’ GUIDE
.
This chapter relies heavily on Chap. 13.
.
No subsequent chapters rely substantially on this one.
of gravity, to become buoyant; this buoyancy can drive thermal circulation or free
convection in an otherwise stationary ﬂuid. (Free convection should be distinguished
from forced convection,in which heat is carried passively in a ﬂow driven by externally
imposed pressure gradients, e.g., when you blow on hot food to cool it, or stir soup
on a hot stove.)
The transport of heat is a fundamental characteristic of many ﬂows. It dictates the
form of global weather patterns and ocean currents. It is also of great technological
importance and is studied in detail, for example, in the cooling of nuclear reactors
and the design of automobile engines. From a more fundamental perspective, as we
have already discussed, the analysis and experimental studies of convection have led
to major insights into the route to chaos (Sec. 15.6).
In this chapter, we describe some ﬂows where thermal effects are predominant. We
begininSec.18.2bywritingdownandthensimplifyingtheequationsofﬂuidmechan-
ics with heat conduction. Then in Sec. 18.3, we discuss the Boussinesq approximation,
which is appropriate for modest-scale ﬂows where buoyancy is important. This allows
us in Sec. 18.4 to derive the conditions under which convection is initiated. Unfortu-
nately, this Boussinesq approximation sometimes breaks down. In particular, as we
discuss in Sec. 18.5, it is inappropriate for convection in stars and planets, where cir-
culation takes place over several gravitational scale heights. For such cases we have to
use alternative, more heuristic arguments to derive the relevant criterion for convec-
tive instability, known as the Schwarzschild criterion, and to quantify the associated
heat ﬂux. We shall apply this theory to the solar convection zone.
Finally, in Sec. 18.6 we return to simple buoyancy-driven convection in a stratiﬁed
ﬂuid to consider double diffusion,a quite general type of instability that can arise when
the diffusion of two physical quantities (in our case heat and the concentration of salt)
render a ﬂuid unstable even though the ﬂuid would be stably stratiﬁed if there were
only concentration gradients of one of these quantities.
18.2
18.2 Diffusive Heat Conduction—Cooling a Nuclear Reactor;
Thermal Boundary Layers
So long as the mean free path of heat-carrying particles is small compared to the
ﬂuid’s inhomogeneity lengthscales (as is almost always the case), and the fractional
temperature change in one mean free path is small (as is also almost always true), the
918
Chapter 18. Convection

energy ﬂux of heat ﬂow takes the thermal-diffusion form
Fcond = −κ∇T ;
(18.1)
see Secs. 3.7 and 13.7.4. Here κ is the thermal conductivity.
evolution equations for a
viscous, heat-conducting
ﬂuid in an external
gravitational ﬁeld
For a viscous, heat-conducting ﬂuid ﬂowing in an external gravitational ﬁeld,
the most general governing equations are the fundamental thermodynamic potential
u(ρ, s); the ﬁrst law of thermodynamics, Eq. (2) or (3) of Box 13.2; the law of mass
conservation [Eq. (13.29) or (13.31)]; the Navier-Stokes equation (13.69); and the law
of dissipative entropy production (13.75):
u = u(ρ, s),
(18.2a)
du
dt = T ds
dt −P d(1/ρ)
dt
,
(18.2b)
dρ
dt = −ρ∇. v,
(18.2c)
ρ dv
dt = −∇P + ρg + ∇(ζθ) + 2∇. (ησ),
(18.2d)
T

ρ
ds
dt

+ ∇.
−κ∇T
T

= ζθ2 + 2ησ : σ + κ
T (∇T )2.
(18.2e)
These are four scalar equations and one vector equation for four scalar and one
vector variables: the density ρ, internal energy per unit mass u, entropy per unit mass
s, pressure P, and velocity v. The thermal conductivity κ and coefﬁcients of shear
viscosity ζ and bulk viscosity η = ρν are presumed to be functions of ρ and s (or
equally well, ρ and T ).
approximations
This set of equations is far too complicated to solve, except via massive numerical
simulations, unless some strong simpliﬁcations are imposed. We therefore introduce
approximations. Our ﬁrst approximation (already implicit in the above equations) is
that thethermalconductivityκ is constant, asarethecoefﬁcientsofviscosity.For most
real applications this approximation is close to true, and no signiﬁcant physical effects
are missed by assuming it. Our second approximation, which does limit somewhat the
type of problem we can address, is that the ﬂuid motions are very slow—slow enough
that, not only can the ﬂow be regarded as incompressible (θ = ∇. v = 0), but also the
squares of the shear σ and expansion θ (which are quadratic in the ﬂuid speed) are
negligibly small, and we thus can ignore viscous dissipation. These approximations
bring the last three of the ﬂuid evolution equations (18.2) into the simpliﬁed form
∇. v ≃0,
dρ/dt ≃0,
(18.3a)
dv
dt = −∇P
ρ
+ g + ν∇2v,
(18.3b)
ρT ds
dt = κ∇2 T .
(18.3c)
18.2 Diffusive Heat Conduction—Cooling a Nuclear Reactor; Thermal Boundary Layers
919

[Our reasons for using “≃” in Eqs. (18.3a) become clear in Sec. 18.3, in connec-
tion with buoyancy.] Note that Eq. (18.3b) is the standard form of the Navier-Stokes
equation for incompressible ﬂows, which we have used extensively in the past several
chapters. Equation (18.3c) is an elementary law of energy conservation: the temper-
ature times the rate of increase of entropy density moving with the ﬂuid is equal to
minus the divergence of the conductive energy ﬂux, Fheat = −κ∇T .
We can convert the entropy evolution equation (18.3c) into an evolution equation
for temperature by expressing the changes ds/dt of entropy per unit mass in terms
of changes dT /dt of temperature. The usual way to do this is to note that T ds (the
amount of heat deposited in a unit mass of ﬂuid) is given by cdT , where c is the ﬂuid’s
speciﬁc heat per unit mass. However, the speciﬁc heat depends on what one holds
ﬁxed during the energy deposition: the ﬂuid element’s volume or its pressure. As we
have assumed that the ﬂuid motions are slow, the fractional pressure ﬂuctuations will
be correspondingly small. (This assumption does not preclude signiﬁcant tempera-
ture perturbations, provided they are compensated by density ﬂuctuations of opposite
sign.) Therefore, the relevant speciﬁc heat for a slowly moving ﬂuid is the one at con-
stant pressure, cP, and we must write T ds = cPdT .1 Equation (18.3c) then becomes
a linear partial differential equation for the temperature:
temperature diffusion
equation
dT
dt ≡∂T
∂t + v . ∇T = χ∇2T ,
(18.4)
where
thermal diffusivity
χ = κ/(ρ cP)
(18.5)
isknownasthethermaldiffusivity,andwehaveagaintakentheeasiestrouteintreating
cP and ρ as constant. When the ﬂuid moves so slowly that the advective term v . ∇T
is negligible, then Eq. (18.4) shows that the heat simply diffuses through the ﬂuid,
with the thermal diffusivity χ being the diffusion coefﬁcient for temperature.
Prandtl number: vorticity
diffusion over heat
diffusion
The diffusive transport of heat by thermal conduction is similar to the diffusive
transport of vorticity by viscous stress [Eq. (14.3)], and the thermal diffusivity χ is the
directanalogofthekinematicviscosityν.Thisobservationmotivatesustointroducea
new dimensionless number known as the Prandtl number,which measures the relative
importance of viscosity and heat conduction (in the sense of their relative abilities to
diffuse vorticity and heat):
Pr = ν
χ .
(18.6)
1.
See, e.g., Turner (1973) for a more formal justiﬁcation of the use of the speciﬁc heat at constant pressure
rather than at constant volume.
920
Chapter 18. Convection

TABLE 18.1: Order-of-magnitude estimates for kinematic
viscosity ν, thermal diffusivity χ, and Prandtl number
Pr = ν/χ for earth, ﬁre, air, and water
Fluid
ν (m2 s−1)
χ (m2 s−1)
Pr
Earth’s mantle
1017
10−6
1023
Solar interior
10−2
102
10−4
Atmosphere
10−5
10−5
1
Ocean
10−6
10−7
10
For gases, both ν and χ are given to order of magnitude by the product of the mean
typical Prandtl numbers
molecular speed and the mean free path, and so Prandtl numbers are typically of
order unity. (For air, Pr ∼0.7.) By contrast, in liquid metals the free electrons carry
heat very efﬁciently compared with the transport of momentum (and vorticity) by
diffusing ions, and so their Prandtl numbers are small. This is why liquid sodium is
used as a coolant in nuclear power reactors. At the other end of the spectrum, water is
a relatively poor thermal conductor with Pr ∼6, and Prandtl numbers for oils, which
are quite viscous and are poor conductors, measure in the thousands. Other Prandtl
numbers are given in Table 18.1.
One might think that, when the Prandtl number is small (so κ is large compared
to ν), one should necessarily include heat ﬂow in the ﬂuid equations and pay atten-
tion to thermally induced buoyancy (Sec. 18.3). Not so. In some low-Prandtl-number
ﬂows the heat conduction is so effective that the ﬂuid becomes essentially isothermal,
and buoyancy effects are minimized. Conversely, in some large-Prandtl-number ﬂows
the large viscous stress reduces the velocity gradient so that slow, thermally driven
circulation takes place, and thermal effects are very important. In general the kine-
matic viscosity is of direct importance in controlling the transport of momentum, and
hence in establishing the velocity ﬁeld, whereas heat conduction affects the velocity
ﬁeld only indirectly (Sec. 18.3). We must therefore examine each ﬂow on its individual
merits.
Another dimensionless number is commonly introduced when discussing ther-
mal effects: the P´eclet number. It is deﬁned, by analogy with the Reynolds number, as
P´eclet number: heat
advection over heat
conduction
Pe = LV
χ ,
(18.7)
where L is a characteristic length scale of the ﬂow, and V is a characteristic speed. The
P´eclet number measures the relative importance of advection and heat conduction.
18.2 Diffusive Heat Conduction—Cooling a Nuclear Reactor; Thermal Boundary Layers
921

EXERCISES
Exercise 18.1 Problem: Fukushima-Daiichi Power Plant
After the earthquake that triggered the catastrophic failure of the Fukushima-Daiichi
nuclear power plant on March 11, 2011, reactor operation was immediately stopped.
However, the subsequent tsunami disabled the cooling system needed to remove the
decay heat, which was still being generated. This system failure led to a meltdown of
three reactors and escape of radioactive material.
Theboilingwaterreactors thatwereinuseeachgenerated∼500 MWofheat, under
normal operation, and the decay-heat production amounted to ∼30 MW. Suppose
that this decay heat was being carried off equally by a large number of cylindrical
pipes of length L ∼10 m and inner radius R ∼10 mm, taking it from the reactor core,
where the water temperature was T0 ∼550 K and the pressure was P0 ∼107 N m−2, to
a heat exchanger. Suppose, initially, that the ﬂow was laminar, so that the ﬂuid velocity
had the parabolic Poiseuille proﬁle:
v = 2¯v

1 −ϖ 2
R2

(18.8)
[Eq. (13.80) and associated discussion]. Here, ϖ is the cylindrical radial coordinate
measured from the axis of the pipe, and ¯v is the mean speed along the pipe. As the goal
was to carry the heat away efﬁciently during normal operation, the pipe was thermally
well insulated, so its inner wall was at nearly the same temperature as the core of
the ﬂuid (at ϖ = 0). The total temperature drop T down the length L was then
T ≪T0, andthelongitudinaltemperaturegradientwasconstant, sothetemperature
distribution in the pipe had the form:
T = T0 −T z
L + f (ϖ).
(18.9)
(a) Use Eq. (18.4) to show that
f = ¯vR2T
2χL
3
4 −ϖ 2
R2 + 1
4
ϖ 4
R4

.
(18.10)
(b) Derive an expression for the conductive heat ﬂux through the walls of the pipe
and show that the ratio of the heat escaping through the walls to that advected
by the ﬂuid was T /T . (Ignore the inﬂuence of the temperature gradient on
the velocity ﬁeld, and treat the thermal diffusivity and speciﬁc heat as constant
throughout the ﬂow.)
(c) The ﬂow would only remain laminar so long as the Reynolds number was Re <∼
Recrit ∼2,000, the critical value for transition to turbulence. Show that the max-
imum power that could be carried by a laminar ﬂow was:
˙Qmax ∼π
2 ρRνRecritcpT0 ∼π
4
ρP0R5Recrit
L
1/2
cpT0.
(18.11)
922
Chapter 18. Convection

Estimate the mean velocity ¯v, the temperature drop T , and the number of
cooling pipes needed in normal operation, when the ﬂow was about to transition
to turbulence. Assume that χ = 10−7 m2 s−1, cp = 6 kJ kg−1 K−1, and ρν = η =
1 × 10−4 Pa s−1.
(d) Describe qualitatively what would happen if the ﬂow became turbulent (as it did
under normal operation).
Exercise 18.2 Problem: Thermal Boundary Layers
In Sec. 14.4, we introduced the notion of a laminar boundary layer by analyzing
ﬂow past a thin plate. Now suppose that this same plate is maintained at a different
temperature from the free ﬂow. A thermal boundary layer will form, in addition to
the viscous boundary layer, which we presume to be laminar. These two boundary
layers both extend outward from the wall but (usually) have different thicknesses.
(a) Explain why their relative thicknesses depend on the Prandtl number.
(b) Using Eq. (18.4), show that in order of magnitude the thickness δT of the thermal
boundary layer is given by
v(δT )δ2
T = ℓχ,
where v(δT ) is the ﬂuid velocity parallel to the plate at the outer edge of the
thermal boundary layer, and ℓis the distance downstream from the leading edge.
(c) Let V be the free-stream ﬂuid velocity and T be the temperature difference
between the plate and the body of the ﬂow. Estimate δT in the limits of large and
small Prandtl numbers.
(d) What will be the boundary layer’s temperature proﬁle when the Prandtl number
is exactly unity? [Hint: Seek a self-similar solution to the relevant equations. For
the solution, see Lautrup (2005, Sec. 31.1).]
18.3
18.3 Boussinesq Approximation
When heat ﬂuxes are sufﬁciently small, we can use Eq. (18.4) to solve for the temper-
ature distribution in a given velocity ﬁeld, ignoring the feedback of thermal effects
on the velocity. However, if we imagine increasing the ﬂow’s temperature differences,
so the heat ﬂuxes also increase, at some point thermal feedback effects begin to inﬂu-
ence the velocity signiﬁcantly. Typically, the ﬁrst feedback effect to occur is buoyancy,
thetendencyofthehotter(andhencelower-density)ﬂuidtoriseinagravitationalﬁeld
and the colder (and hence denser) ﬂuid to descend.2 In this section, we describe the
2.
This effect is put to good use in a domestic “gravity-fed” warm-air circulation system. The furnace
generally resides in the basement, not the attic!
18.3 Boussinesq Approximation
923

effects of buoyancy as simply as possible. The minimal approach, which is adequate
surprisingly often, is called the Boussinesq approximation. Leading to Eqs. (18.12),
Boussinesq approximation
for describing heat-driven
buoyancy effects
(18.18), and (18.19), it can be used to describe many heat-driven laboratory ﬂows
and atmospheric ﬂows, and some geophysical ﬂows.
ThetypesofﬂowsforwhichtheBoussinesqapproximationisappropriatearethose
in which the fractional density changes are small (|ρ| ≪ρ). By contrast, the velocity
can undergo large changes, though it remains constrained by the incompressibility
relation (18.3a):
∇. v = 0
Boussinesq (1).
(18.12)
One might think that this constraint implies constant density moving with a ﬂuid ele-
ment, since mass conservation requires dρ/dt = −ρ∇. v. However, thermal expan-
sion causes small density changes, with tiny corresponding violations of Eq. (18.12);
this explains the “≃” that we used in Eqs. (18.3a). The key point is that, for these
types of ﬂows, the density is controlled to high accuracy by thermal expansion, and
the velocity ﬁeld is divergence free to high accuracy.
When discussing thermal expansion, it is convenient to introduce a reference
density ρ0 and reference temperature T0, equal to some mean of the density and
temperature in the region of ﬂuid that one is studying. We shall denote by
τ ≡T −T0
(18.13)
the perturbation of the temperature away from its reference value. The thermally
perturbed density can then be written as
thermal expansion
ρ = ρ0(1 −ατ),
(18.14)
where α is the thermal expansion coefﬁcient for volume3 [evaluated at constant
pressure for the same reason as the speciﬁc heat was chosen as at constant pressure in
the paragraph following Eq. (18.3c)]:
α = −
∂ln ρ
∂T

P
.
(18.15)
Equation (18.14) enables us to eliminate density perturbations as an explicit variable
and replace them by temperature perturbations.
NowturntotheNavier-Stokesequation(18.3b)inauniformexternalgravitational
ﬁeld. We expand the pressure-gradient term as
−∇P
ρ
≃−∇P
ρ0
(1 + ατ) = ∇P
ρ0
−ατg,
(18.16)
3.
Note that α is three times larger than the thermal expansion coefﬁcient for the linear dimensions of the
ﬂuid.
924
Chapter 18. Convection

where we have used hydrostatic equilibrium for the unperturbed ﬂow. As in our
analysis of rotating ﬂows [Eq. (14.55)], we introduce an effective pressure designed
to compensate for the ﬁrst-order effects of the uniform gravitational ﬁeld:
P ′ = P + ρ0 = P −ρ0g . x.
(18.17)
(Notice that P ′ measures the amount the pressure differs from the value it would
have in supporting a hydrostatic atmosphere of the ﬂuid at the reference density.)
The Navier-Stokes equation (18.3b) then becomes
dv
dt = −∇P ′
ρ0
−ατg + ν∇2v
Boussinesq (2),
(18.18)
dropping the small term O(αP ′). In words, a ﬂuid element accelerates in response
to a buoyancy force [the sum of the ﬁrst and second terms on the right-hand side of
Eq. (18.18)] and a viscous force.
To solve this equation, we must be able to solve for the temperature perturbation τ.
This evolves according to the standard equation of heat diffusion [Eq. (18.4)]:
dτ
dt = χ∇2τ
Boussinesq (3).
(18.19)
Equations (18.12), (18.18), and (18.19) are the equations of ﬂuid ﬂow in the Boussi-
Boussinesq equations
nesq approximation; they control the coupled evolution of the velocity v and the
temperature perturbation τ. We now use them to discuss free convection in a lab-
oratory apparatus.
18.4
18.4 Rayleigh-B´enard Convection
Rayleigh-B´enard
convection
In a relatively simple laboratory experiment to demonstrate convection, a ﬂuid is
conﬁned between two rigid plates a distance d apart, each maintained at a ﬁxed
temperature, with the upper plate cooler than the lower by T . When T is small,
viscous stresses, together with the no-slip boundary conditions at the plates, inhibit
circulation; so, despite the upward buoyancy force on the hotter, less-dense ﬂuid near
the bottom plate, the ﬂuid remains stably at rest with heat being conducted diffusively
upward. If the plates’ temperature difference T is gradually increased, the buoyancy
becomes gradually stronger. At some critical T it will overcome the restraining
viscous forces, and the ﬂuid starts to circulate (convect) between the two plates. Our
goal is to determine the critical temperature difference Tcrit for the onset of this
Rayleigh-B´enard convection.
We now make some physical arguments to simplify the calculation of Tcrit.
From our experience with earlier instability calculations, especially those involving
elastic bifurcations (Secs. 11.6.1 and 12.3.5), we anticipate that for T < Tcrit the
response of the equilibrium to small perturbations will be oscillatory (i.e., will have
positive squared eigenfrequency ω2), while for T > Tcrit, perturbations will grow
18.4 Rayleigh-B´enard Convection
925

T0 – T/2
T0 + T/2
x
z
d
FIGURE 18.1 Rayleigh-B´enard convection. A ﬂuid is conﬁned between two
horizontal surfaces separated by a vertical distance d. When the temperature
difference between the two plates T is increased sufﬁciently, the ﬂuid starts
to convect heat vertically. The reference effective pressure P ′
0 and reference
temperature T0 are the values of P ′ and T measured at the midplane z = 0.
exponentially (i.e., will have negative ω2). Correspondingly, at T = Tcrit, ω2 for
some mode will be zero. This zero-frequency mode marks the bifurcation of equilibria
from one with no ﬂuid motions to one with slow, convective motions. We search for
Tcrit by searching for a solution to the Boussinesq equations (18.12), (18.18), and
(18.19) that represents this zero-frequency mode. In those equations, we choose for
the reference temperature T0, density ρ0, and effective pressure P0 the values at the
midplane between the plates, z = 0 (cf. Fig. 18.1).
The unperturbed equilibrium, when T = Tcrit, is a solution of the Boussinesq
equations (18.12),
(18.18),
and (18.19) with vanishing velocity,
a time-
independent vertical temperature gradient dT /dz = −T /d, and a compensating,
time-independent, vertical pressure gradient:
v = 0,
τ = T −T0 = −T
d z,
P ′ = P ′
0 + gρ0α T
d
z2
2 .
(18.20)
When the zero-frequency mode is present, the velocity v is nonzero, and the temper-
ature and effective pressure have additional perturbations δτ and δP ′:
v ̸= 0,
τ = T −T0 = −T
d z + δτ ,
P ′ = P ′
0 + gρ0α T
d
z2
2 + δP ′.
(18.21)
The perturbations v, δτ, and δP ′ are governed by the Boussinesq equations and
the boundary conditions at the plates (z = ±d/2): v = 0 (no-slip) and δτ = 0. We
manipulate these equations and boundary conditions in such a way as to get a partial
differential equation for the scalar temperature perturbation δτ by itself, decoupled
from the velocity and the pressure perturbation.
First consider the result of inserting expressions (18.21) into the Boussinesq-
approximated Navier-Stokes equation (18.18). Because the perturbation mode has
926
Chapter 18. Convection

zero frequency, ∂v/∂t vanishes; and because v is extremely small, we can neglect the
quadratic advective term v . ∇v, thereby bringing Eq. (18.18) into the form:
∇δP ′
ρ0
= ν∇2v −gαδτ.
(18.22)
We want to eliminate δP ′ from this equation. The other Boussinesq equations are of
no help for this, since δP ′ is absent from them. One might be tempted to eliminate
δP using the equation of state P = P(ρ, T ); but in the present analysis our Boussi-
nesq approximation insists that the only signiﬁcant changes of density are those due
to thermal expansion (i.e., it neglects the inﬂuence of pressure on density), so the
equation of state cannot help us. Lacking any other way to eliminate δP ′, we employ a
common trick: we take the curl of Eq. (18.22). As the curl of a gradient vanishes, δP ′
drops out. We then take the curl one more time and use ∇. v = 0 to obtain
ν∇2(∇2v) = αg∇2δτ −α(g . ∇)∇δτ.
(18.23)
Next turn to the Boussinesq version of the equation of heat transport [Eq. (18.19)].
Inserting into it Eqs. (18.21) for τ and v, setting ∂δτ/∂t to zero (because our pertur-
bation has zero frequency), linearizing in the perturbation, and using g = −gez, we
obtain
vzT
d
= −χ∇2δτ.
(18.24)
This is an equation for the vertical velocity vz in terms of the temperature perturbation
δτ. By inserting this vz into the z component of Eq. (18.23), we achieve our goal of a
scalar equation for δτ alone:
linearized perturbation
equation for Rayleigh-
B´enard convection
νχ∇2∇2∇2δτ = αgT
d
∂2δτ
∂x2 + ∂2δτ
∂y2

.
(18.25)
This is a sixth-order differential equation, even more formidable than the fourth-
order equations that arise in the elasticity calculations of Chaps. 11 and 12. We now
see how prudent it was to make simplifying assumptions at the outset!
The differential equation (18.25) is, however, linear, so we can seek solutions using
separation of variables. As the equilibrium is unbounded horizontally, we look for a
single horizontal Fourier component with some wave number k; that is, we seek a
solution of the form
δτ ∝exp(ikx)f (z),
(18.26)
where f (z) is some unknown function. Such a δτ will be accompanied by motions v
in the x and z directions (i.e., vy = 0) that also have the form vj ∝exp(ikx)fj(z) for
some other functions fj(z).
18.4 Rayleigh-B´enard Convection
927

The ansatz (18.26) converts the partial differential equation (18.25) into the single
ordinary differential equation
 d2
dz2 −k2
3
f + Ra k2f
d4
= 0,
(18.27)
where we have introduced yet another dimensionless number
Rayleigh number:
buoyancy force over
viscous force
Ra = αgT d3
νχ
(18.28)
called the Rayleigh number. By virtue of relation (18.24) between vz and δτ, the
Rayleigh number is a measure of the ratio of the strength of the buoyancy term −αδτg
to the viscous term ν∇2v in the Boussinesq version [Eq. (18.18)] of the Navier-Stokes
equation:
Ra ∼buoyancy force
viscous force .
(18.29)
The general solution of Eq. (18.27) is an arbitrary, linear combination of three sine
functions and three cosine functions:
f =
3
 
n=1
An cos(μnkz) + Bn sin(μnkz),
(18.30)
where the dimensionless numbers μn are given by
μn =
' Ra
k4d4
1/3
e2πni/3 −1
(1/2
;
n = 1, 2, 3,
(18.31)
which involves the three cube roots of unity, e2πni/3. The values of ﬁve of the coefﬁ-
cients An, Bn are ﬁxed in terms of the sixth (an overall arbitrary amplitude) by ﬁve
boundary conditions at the bounding plates. A sixth boundary condition then deter-
mines the critical temperature difference Tcrit (or equivalently, the critical Rayleigh
number Racrit) at which convection sets in.
boundary conditions
for Rayleigh-B´enard
convection
The six boundary conditions are paired as follows:
1. The requirement that the ﬂuid temperature be the same as the plate temper-
ature at each plate, so δτ = 0 at z = ±d/2.
2. The no-slip boundary condition vz = 0 at each plate, which by virtue of
Eq. (18.24) and δτ = 0 at the plates, translates to δτ,zz = 0 at z = ±d/2
(where the indices after the comma are partial derivatives).
3. The no-slip boundary condition vx = 0, which by virtue of incompressibility
∇. v = 0 implies vz,z = 0 at the plates, which in turn by Eq. (18.24) implies
δτ,zzz + δτ,xxz = 0 at z = ±d/2.
928
Chapter 18. Convection

It is straightforward but computationally complex to impose these six boundary
toy problem for Rayleigh-
B´enard convection
conditionsandfromthemdeducethecriticalRayleighnumberforonsetofconvection
(Pellew and Southwell, 1940). Rather than present the nasty details, we switch to a toy
problem in which the boundary conditions are adjusted to give a simpler solution but
one with the same qualitative features as for the real problem. Speciﬁcally, we replace
the no-slip condition (3) (vx = 0 at the plates) by a condition of no shear:
3′. vx,z = 0 at the plates. By virtue of incompressibility ∇. v = 0, the x deriva-
tive of this condition translates to vz,zz = 0, which by Eq. (18.24) becomes
δτ,zzxx + δτ,zzzz = 0.
To recapitulate, we seek a solution of the form (18.30) and (18.31) that satisﬁes the
boundary conditions (1), (2), and (3′).
The terms in Eq. (18.30) with n = 1, 2always have complex arguments and thus al-
ways have z dependences that are products of hyperbolic and trigonometric functions
with real arguments. For n = 3 and a large enough Rayleigh number, μ3 is positive,
and the solutions are pure sines and cosines. Let us just consider the n = 3terms alone,
in this regime, and impose boundary condition (1): δτ = 0 at the plates. The cosine
term by itself,
δτ = const × cos(μ3kz) eikx,
(18.32)
satisﬁes this boundary condition, if we set
μ3kd
2
≡
' Ra
k4d4
1/3
−1
(1/2
kd
2 =

m + 1
2

π,
(18.33)
where m is an integer. It is straightforward to show, remarkably, that Eqs. (18.32) and
(18.33) also satisfy boundary conditions (2) and (3′), so they solve the toy version of
our problem.
As T is gradually increased from zero, the Rayleigh number gradually grows,
passing through the sequence of values given by Eq. (18.33) with m = 0, 1, 2, . . . (for
any chosen k). At each of these values there is a zero-frequency, circulatory mode
of ﬂuid motion with horizontal wave number k, which is passing from stability to
instability. The ﬁrst of these, m = 0, represents the onset of circulation for the chosen
k, and the Rayleigh number at this onset [Eq. (18.33) with m = 0] is
Ra = (k2d2 + π2)3
k2d2
.
(18.34)
This Ra(k) relation is plotted as a thick curve in Fig. 18.2.
Notice in Fig. 18.2 that there is a critical Rayleigh number Racrit below which all
modes are stable, independent of their wave numbers, and above which modes in
some range kmin < k < kmax are unstable. From Eq. (18.34) we deduce that for our
toy problem, Racrit = 27π4/4 ≃658.
18.4 Rayleigh-B´enard Convection
929

kcrit
Racrit
Ra
ω real
stability
marginal
stability
ω = 0
ω imaginary
instability
k
FIGURE 18.2 Horizontal wave number k of the ﬁrst mode
to go unstable, as a function of Rayleigh number. Along
the solid curve the mode has zero frequency; to the left of
the curve it is stable, to the right it is unstable. Racrit is the
minimum Rayleigh number for convective instability.
When one imposes the correct boundary conditions (1), (2), and (3) [instead of
our toy choice (1), (2), and (3′)] and works through the nasty details of the compu-
tation, one obtains a relation for Ra(k) that looks qualitatively the same as Fig. 18.2.
One deduces that convection should set in at Racrit = 1,708, which agrees reasonably
well with experiment. One can carry out the same computation with the ﬂuid’s upper
critical Rayleigh number
for onset of Rayleigh-
B´enard convection
surface free to move (e.g., due to placing air rather than a solid plate at z = d/2). Such
a computation predicts that convection begins at Racrit ≃1,100, though in practice
surface tension is usually important, and its effect must be included.
One feature of these critical Rayleigh numbers is very striking. Because the
Rayleigh number is an estimate of the ratio of buoyancy forces to viscous forces
[Eq. (18.29)], an order-of-magnitude analysis suggests that convection should set
in at Ra ∼1—which is wrong by three orders of magnitude! This provides a vivid
reminder that order-of-magnitude estimates can be quite inaccurate. In this case, the
how order-of-magnitude
analyses can fail
main reason for the discrepancy is that the convective onset is governed by a sixth-
order differential equation (18.25) and thus is highly sensitive to the lengthscale d
used in the order-of-magnitude analysis. If we choose d/π rather than d as the length
scale, then an order-of-magnitude estimate could give Ra ∼π6 ∼1,000, a much more
satisfactory value.
Once convection has set in, the unstable modes grow until viscosity and non-
linearities stabilize them, at which point they carry far more heat upward between the
plates than does conduction. The convection’s velocity pattern depends in practice on
the manner in which the heat is applied, the temperature dependence of the viscosity,
patterns of convection
cells in Rayleigh-B´enard
convection
and the ﬂuid’s boundaries. For a limited range of Rayleigh numbers near Racrit, it is
possible to excite a hexagonal pattern of convection cells as is largely but not entirely
the case in Fig. 18.3; however other patterns can also be excited.
930
Chapter 18. Convection

FIGURE 18.3 Convection cells in Rayleigh-B´enard convection. The ﬂuid, which is
visualized using aluminum powder, rises at the center of each cell and falls around
its edges. From Maroto, Perez-Munuzuri, and Romero-Cano (2007).
Drazin and Reid (2004) suggest a kitchen experiment for observing convection
cells. Place a 2-mm layer of corn or canola oil on the bottom of a skillet, and sprin-
kitchen experiment
kle cocoa or Ovaltine or other powder over it. Heat the skillet bottom gently and
uniformly. The motion of the powder particles will reveal the convection cells, with
upwelling at the cell centers and surface powder collecting and falling at the edges.
In Rayleigh-B´enard convection experiments, as the Rayleigh number is increased
bifurcation of Rayleigh-
B´enard equilibria leading
to convective turbulence
beyond the onset of convection, one or another sequences of equilibrium bifurcations
leads to weak turbulence (see Secs. 15.6.2 and 15.6.3). When the Rayleigh number
becomes very large, the convection becomes strongly turbulent.
Free convection, like that in these laboratory experiments, also occurs in meteoro-
logical and geophysical ﬂows. For example, for air in a room, the relevant parameter
values are α = 1/T ∼0.003 K−1 (Charles’ Law), and ν ∼χ ∼10−5 m2 s−1, so the
Rayleigh number is Ra ∼3 × 108(T /1 K)(d/1 m)3. Convection in a room thus
occurs extremely readily, even for small temperature differences. In fact, so many
modes of convective motion can be excited that heat-driven air ﬂow is invariably
turbulent. It is therefore common in everyday situations to describe heat transport
using a phenomenological turbulent thermal conductivity (Sec. 15.4.2; White, 2008,
Sec. 6.10.1).
A second example, convection in Earth’s mantle, is described in Box 18.2.
18.4 Rayleigh-B´enard Convection
931

BOX 18.2.
MANTLE CONVECTION AND CONTINENTAL DRIFT
As is now well known, the continents drift over the surface of the globe
on a timescale of roughly 100 million years. Despite the clear geographical
evidence that the continents ﬁt together, some geophysicists were, for a long
while, skeptical that this occurred, because they were unable to identify the
forces responsible for overcoming the visco-elastic resilience of the crust. It
is now known that these motions are in fact slow convective circulation of
the mantle driven by internally generated heat from the radioactive decay of
unstable isotopes, principally uranium, thorium, and potassium.
When the heat is generated in the convective layer (which has radial
thickness d), rather than passively transported from below, we must modify
our deﬁnition of the Rayleigh number. Let the heat generated per unit mass
per unit time be Q. In the analog of our laboratory analysis, where the ﬂuid
is assumed marginally unstable to convective motions, this Q will generate
a heat ﬂux ∼ρQd, which must be carried diffusively. Equating this ﬂux to
κT/d, we can solve for the temperature difference T between the lower
and upper edges of the convective mantle: T ∼ρQd2/κ. Inserting this T
into Eq. (18.28), we obtain a modiﬁed expression for the Rayleigh number
Ra′ = αρgQd5
κχν
.
(1)
Let us now estimate the value of Ra′ for Earth’s mantle. The mantle’s
kinematic viscosity can be measured by post-glacial rebound studies (cf.
Ex. 14.13) to be ν ∼1017 m2 s−1. We can use the rate of attenuation of
diurnal and annual temperature variation with depth in surface rock to
estimate a thermal diffusivity χ ∼10−6 m2 s−1. Direct experiment furnishes
an expansion coefﬁcient, α ∼3 × 10−5 K−1 and thermal conductivity
κ ∼4 W m−1 K−1. The thickness of the upper mantle is d ∼700 km, and
the rock density is ρ ∼4,000 kg m−3. The rate of heat generation can be
estimated both by chemical analysis and direct measurement at Earth’s
surface and turns out to be Q ∼10−11 W kg−1. Combining these quantities,
we obtain an estimated Rayleigh number Ra′ ∼107, well in excess of the
critical value for convection under free slip conditions, which evaluates to
Ra′
crit = 868 (Turcotte and Schubert, 1982). For this reason, it is now believed
that continental drift is driven primarily by mantle convection.
932
Chapter 18. Convection

EXERCISES
Exercise 18.3 Problem: Critical Rayleigh Number
Use the Rayleigh criterion to estimate the temperature difference that would have to
be maintained for 2 mm of corn/canola oil, or water, or mercury in a skillet to start
convecting. Look up the relevant physical properties and comment on your answers.
Do not perform this experiment with mercury.
Exercise 18.4 Problem: Width of a Thermal Plume
Consider a knife on its back, so its sharp edge points in the upward, z direction. The
edge (idealized as extending inﬁnitely far in the y direction) is hot, and by heating
adjacent ﬂuid, it creates a rising thermal plume. Introduce a temperature deﬁcit
T (z) that measures the typical difference in temperature between the plume and
the surrounding, ambient ﬂuid at height z above the knife edge, and let δp(z) be the
width of the plume at height z.
(a) Show that energy conservation implies the constancy of δpT ¯vz, where ¯vz(z) is
the plume’s mean vertical speed at height z.
(b) Make an estimate of the buoyancy acceleration, and use it to estimate ¯vz.
(c) Use Eq. (18.19) to relate the width of the plume to the speed. Hence, show that the
width of the plume scales as δp ∝z2/5 and the temperature deﬁcit as T ∝z−3/5.
(d) Repeat this exercise for a 3-dimensional plume above a hot spot.
18.5
18.5 Convection in Stars
The Sun and other stars generate heat in their interiors by nuclear reactions. In most
stars the internal energy is predominantly in the form of hot hydrogen and helium
ions and their electrons, while the thermal conductivity is due primarily to diffusing
photons (Sec. 3.7.1), which have much longer mean free paths than the ions and
electrons. When the photon mean free path becomes small due to high opacity (as
happens in the outer 30% of the Sun; Fig. 18.4), the thermal conductivity goes down,
so to transport the heat from nuclear burning, the star develops an increasingly steep
convection
zone
photosphere
core
FIGURE 18.4 A convection zone occupies
the outer 30% of a solar-type star.
18.5 Convection in Stars
933

temperature gradient. The star may then become convectively unstable and transport
its energy far more efﬁciently by circulating its hot gas than it could have done
by photon diffusion. Describing this convection is a key step in understanding the
interiors of the Sun and other stars.
A heuristic argument provides the basis for a surprisingly simple description of
this convection. As a foundation for our argument, let us identify the relevant physics:
1. The pressure in stars varies through many orders of magnitude (a factor
∼1012 for the Sun). Therefore, we cannot use the Boussinesq approximation;
instead, as a ﬂuid element rises or descends, we must allow for its density to
change in response to large changes of the surrounding pressure.
2. The convection involves circulatory motions on such large scales that the
attendant shears are small, and viscosity is thus unimportant.
3. Because the convection is driven by the ineffectiveness of conduction, we
can idealize each ﬂuid element as retaining its heat as it moves, so the ﬂow
is adiabatic.
4. The convection is usually well below sonic, as subsonic motions are easily
sufﬁcient to transport the nuclear-generated heat, except very close to the
solar surface.
heuristic analysis of the
onset of convection in
stars
Our heuristic argument, then, focuses on convecting ﬂuid blobs that move
through the star’s interior very subsonically, adiabatically, and without viscosity. As
the motion is subsonic, each blob remains in pressure equilibrium with its surround-
ings. Now, suppose we make a virtual interchange between two blobs at different
heights (Fig. 18.5). The blob that rises (blob B in the ﬁgure) experiences a decreased
pressure and thus expands, so its density diminishes. If its density after rising is lower
than that of its surroundings, then it is buoyant and continues to rise. Conversely, if
the raised blob is denser than its surroundings, then it will sink back to its original
location. Therefore, a criterion for convective instability is that the raised blob has
lower density than its surroundings. Since the blob and its surroundings have the
same pressure, and since the larger is the entropy s per unit mass of gas, the lower is
its density (there being more phase space available to its particles), the ﬂuid is con-
vectively unstable if the raised blob has a higher entropy than its surroundings. Now,
the blob’s motion was adiabatic, so its entropy per unit mass s is the same after it rises
as before. Therefore, the ﬂuid is convectively unstable if the entropy per unit mass s at
the location where the blob began (lower in the star) is greater than that at the location
to which it rose (higher in the star); that is, the star is convectively unstable if its entropy
per unit mass decreases outward: ds/dr < 0. For small blobs, this instability will be
counteracted by both viscosity and heat conduction. But for large blobs, viscosity and
conduction are ineffective, and the convection proceeds.
When building stellar models, astrophysicists ﬁnd it convenient to determine
whether a region of a model is convectively unstable by computing what its struc-
934
Chapter 18. Convection

before
B
A
A
B
after
g
rs
FIGURE 18.5 Convectively unstable interchange of two blobs in a star whose
entropy per unit mass increases downward. Blob B rises to the former
position of blob A and expands adiabatically to match the surrounding
pressure. The entropy per unit mass of the blob is higher than that of the
surrounding gas, and so the blob has a lower density. It will therefore be
buoyant and continue to rise. Similarly, blob A will continue to sink.
ture would be without convection (i.e., with all its heat carried radiatively). That
computation gives some temperature gradient dT /dr. If this computed dT /dr is
Schwarzschild criterion for
convection in stars
superadiabatic, that is, if
−d ln T
d ln r >
∂ln T
∂ln P

s

−d ln P
d ln r

≡−
d ln T
d ln r

s
,
(18.35)
then the entropy s decreases outward, and the star is convectively unstable. This is
known as the Schwarzschild criterion for convection, since it was formulated by the
same Karl Schwarzschild who discovered the Schwarzschild solution to Einstein’s
equations (which describes a nonrotating black hole; Chap. 26).
actual temperature
gradient in convective
region of a star
In practice, if the star is convective, then the convection is usually so efﬁcient at
transporting heat that the actual temperature gradient is only slightly superadiabatic,
that is, the entropy s is nearly independent of radius—it decreases outward only very
slightly. (Of course, the entropy can increase signiﬁcantly outward in a convectively
stable zone, where radiative diffusion is adequate to transport heat.)
We can demonstrate the efﬁciency of convection by estimating the convective heat
ﬂux when the temperature gradient is slightly superadiabatic, that is, when |∇T | ≡
|(dT/dr)| −|(dT /dr)s| is slightly positive. As a tool in our estimate, we introduce the
concept of the mixing length, denoted by l—the typical distance a blob travels before
mixing length
breaking up. As the blob is in pressure equilibrium, we can estimate its fractional
density difference from its surroundings by ρ/ρ ∼T /T ∼|∇T |l/T . Invoking
Archimedes’ law, we estimate the blob’s acceleration to be ∼gρ/ρ ∼g|∇T |l/T
(where g is the local acceleration of gravity); hence the average speed with which a
18.5 Convection in Stars
935

blob rises or sinks is ¯v ∼(g|∇T |/T )1/2l. The convective heat ﬂux is then given by
estimate of convective
heat ﬂux
Fconv ∼cPρ ¯vl|∇T |
∼cPρ(g/T )1/2(|∇T |)3/2l2.
(18.36)
We can bring this expression into a more useful form, accurate to within factors
estimate of amount
by which temperature
gradient exceeds adiabatic
in convective region
of order unity, by (i) setting the mixing length equal to the pressure scale height
l ∼H = |dr/d ln P| (as is usually the case in the outer parts of a star); (ii) setting
cP ∼h/T , where h is the enthalpy per unit mass [cf. the ﬁrst law of thermodynamics,
Eq. (3) of Box 13.2]; (iii) setting g = −(P/ρ)d ln P/dr ∼C2|d ln P/dr| [cf. the
equation of hydrostatic equilibrium (13.13) and Eq. (16.48) for the speed of sound
C]; and (iv) setting |∇T | ≡|dT /dr| ∼T |d ln P/dr|. The resulting expression for
Fconv can then be inverted to give
|∇T |
|∇T | ∼
Fconv
hρC
2/3
∼
*
Fconv
5
2P kBT /mp
+2/3
.
(18.37)
Here the last expression is obtained from the fact that the gas is fully ionized, so its
enthalpy is h = 5
2P/ρ, and its speed of sound is about the thermal speed of its protons
(the most numerous massive particle), C ∼kBT /mp (with kB Boltzmann’s constant
and mp the proton rest mass).
It is informative to apply this estimate to the convection zone of the Sun (the outer
solar convection zone
∼30% of its radius; Fig. 18.4). The luminosity of the Sun is ∼4 × 1026 W, and its radius
is 7 × 105 km, so its convective energy ﬂux is Fconv ∼108 W m−2. First consider
the convection zone’s base. The pressure there is P ∼1TPa, and the temperature
is T ∼106 K, so Eq. (18.37) predicts |∇T |/|∇T | ∼3 × 10−7, so the temperature
gradient at the base of the convection zone need only be superadiabatic by a few parts
in 10 million to carry the solar energy ﬂux.
By contrast, at the top of the convection zone (which is nearly at the solar surface),
the gas pressure is only ∼10 kPa, and the sound speed is ∼10 km s−1, so hρc ∼
108 W m−2, and |∇T |/|∇T | ∼1; that is, the temperature gradient must depart
signiﬁcantly from the adiabatic gradient to carry the heat. Moreover, the convective
elements, in their struggle to carry the heat, move with a signiﬁcant fraction of the
sound speed, so it is no longer true that they are in pressure equilibrium with their
surroundings. A more sophisticated theory of convection is therefore necessary near
the solar surface.
Convection is important in some other types of stars. It is the primary means
of heat transport in the cores of stars with high mass and high luminosity, and
throughout very young stars before they start to burn their hydrogen in nuclear
reactions.
936
Chapter 18. Convection

EXERCISES
Exercise 18.5 Problem: Radiative Transport
The density and temperature in the deep interior of the Sun are roughly 0.1 kg m−3
and 1.5 × 107 K.
(a) Estimate the central gas pressure and radiation pressure and their ratio.
(b) The mean free path of the radiation is determined almost equally by Thomson
scattering, bound-free absorption, and free-free absorption. Estimate numeri-
cally the photon mean free path and hence estimate the photon escape time and
the luminosity. How well do your estimates compare with the known values for
the Sun?
Exercise 18.6 Problem: Bubbles
Consider a small bubble of air rising slowly in a large expanse of water. If the bubble
is large enough for surface tension to be ignored, then it will form an irregular cap of
radius r. Show that the speed with which the bubble rises is roughly (gr)1/2. (A more
reﬁned estimate gives a numerical coefﬁcient of 2/3.)
18.6
18.6 Double Diffusion—Salt Fingers
As we have described it so far, convection is driven by the presence of an unbalanced
buoyancy force in an equilibrium distribution of ﬂuid. However, it can also arise as
a higher-order effect, even if the ﬂuid initially is stably stratiﬁed (i.e., if the density
gradient is in the same direction as gravity). An example is salt ﬁngering,a rapid mix-
ing that can occur when warm, salty water lies at rest above colder fresh water. The
salt ﬁngering and the
mechanism behind it
highertemperatureoftheupperﬂuidoutbalancestheweightofitssalt, makingitmore
buoyant than the fresh water below. However, in a small, localized, downward per-
turbation of the warm, salty water, heat diffuses laterally into the colder surrounding
water faster than salt diffuses, increasing the perturbation’s density, so it will continue
to sink.
It is possible to describe this instability using a local perturbation analysis. The
setup is somewhat similar to the one we used in Sec. 18.4 to analyze Rayleigh-B´enard
convection. We consider a stratiﬁed ﬂuid in an equilibrium state, in which there is a
vertical gradient of the temperature, and as before, we measure its departure from a
reference temperature T0 at a midplane (z = 0) by τ ≡T −T0. We presume that in
the equilibrium state τ varies linearly with z, so ∇τ = (dτ/dz)ez is constant. Simi-
larly, we characterize the salt concentration by C ≡(concentration) −(equilibrium
concentration at the midplane); and we assume that in the equilibrium state, C, like
τ, varies linearly with height, so ∇C = (dC/dz)ez is constant. The density ρ is equal
to the equilibrium density at the midplane plus corrections due to thermal expansion
and salt concentration:
ρ = ρ0 −αρ0τ + βρ0C
(18.38)
18.6 Double Diffusion—Salt Fingers
937

[cf. Eq. (18.14)]. Here β is a constant for concentration analogous to the thermal
expansion coefﬁcient α for temperature. In this problem, by contrast with Rayleigh-
B´enard convection, it is easier to work directly with the pressure than with the
modiﬁed pressure. In equilibrium, hydrostatic equilibrium dictates that its gradient
be ∇P = −ρg.
Now, let us perturb about this equilibrium state and write down the linearized
equations for the evolution of the perturbations. We denote the perturbation of tem-
perature (relative to the reference temperature) by δτ, of salt concentration by δC, of
density by δρ, of pressure by δP , and of velocity by simply v (since the unperturbed
state has v = 0). We do not ask about the onset of instability, but rather (because we
expect our situation to be generically unstable) we seek a dispersion relation ω(k) for
the perturbations. Correspondingly, in all our perturbation equations we replace ∂/∂t
perturbation equations
with −iω and ∇with ik, except for the equilibrium ∇C and ∇τ, which are constants.
The ﬁrst of our perturbation equations is the linearized Navier-Stokes equation
(18.3b):
−iωρ0v = −ikδP + gδρ −νk2ρ0v,
(18.39a)
where we have kept the viscous term, because we expect the Prandtl number to be of
order unity (for water, Pr ∼6). Low velocity implies incompressibity ∇. v = 0, which
becomes
k . v = 0.
(18.39b)
The density perturbation follows from the perturbed form of Eq. (18.38):
δρ = −αρ0δτ + βρ0δC.
(18.39c)
The temperature perturbation is governed by Eq. (18.19), which linearizes to
−iωδτ + (v . ∇)τ = −χk2δτ.
(18.39d)
Assuming that the timescale for the salt to diffuse is much longer than that for the
temperature to diffuse, we can ignore salt diffusion altogether, so that dδC/dt = 0:
−iωδC + (v . ∇)C = 0.
(18.39e)
Equations (18.39) are ﬁve equations for the ﬁve unknowns δP , δρ, δC, δτ, and
v, one of which is a three-component vector! Unless we are careful, we will end
up with a seventh-order algebraic equation. Fortunately, there is a way to keep the
algebra manageable. First, we eliminate the pressure perturbation by taking the curl
of Eq. (18.39a) [or equivalently, by crossing k into Eq. (18.39a)]:
(−iω + νk2)ρ0k × v = k × gδρ.
(18.40a)
Taking the curl of this equation again allows us to incorporate incompressibility
(18.39b). Then dotting into g, we obtain
(iω −νk2)ρ0k2g . v = [(k . g)2 −k2g2]δρ.
(18.40b)
938
Chapter 18. Convection

Since g points vertically, Eq. (18.40b) is one equation for the density perturbation in
terms of the vertical velocity perturbation vz. We can obtain a second equation of this
sort by inserting Eq. (18.39d) for δτ and Eq. (18.39e) for δC into Eq. (18.39c); the
result is
δρ = −

αρ0
iω −χk2

(v . ∇)τ + βρ0
iω (v . ∇)C.
(18.40c)
Since the unperturbed gradients of temperature and salt concentration are both ver-
tical, Eq. (18.40c), like Eq. (18.40b), involves only vz and not vx or vy. Solving both
Eqs. (18.40b) and (18.40c) for the ratio δρ/vz and equating these two expressions, we
obtain the following dispersion relation for our perturbations:
dispersion relation for salt-
ﬁngering perturbations
ω(ω + iνk2)(ω + iχk2) +

1 −(k . g)2
k2g2

[ωα(g . ∇)τ −(ω + iχk2)β(g . ∇)C]= 0.
(18.41)
When k is real, as we shall assume, we can write this dispersion relation as a cubic
equation for p = −iω with real coefﬁcients. The roots for p are either all real or one
real and two complex conjugates, and growing modes have the real part of p positive.
When the constant term in the cubic is negative, that is, when
(g . ∇)C < 0,
(18.42)
we are guaranteed that there is at least one positive, real root p and this root corre-
sufﬁcient condition for
salt-ﬁngering instability
sponds to an unstable, growing mode. Therefore, a sufﬁcient condition for instability
is that the concentration of salt increase with height!
fastest salt-ﬁngering
modes
By inspecting the dispersion relation, we conclude that the growth rate will be
maximal when k . g = 0 (i.e., when the wave vector is horizontal). What is the direc-
tion of the velocity v for these fastest-growing modes? The incompressibility equation
(18.39b) shows that v is orthogonal to the horizontal k; Eq. (18.40a) states that k × v
points in the same direction as k × g, which is horizontal, since g is vertical. These
two conditions imply that v points vertically. Therefore, these fastest modes repre-
sent ﬁngers of salty water descending past rising ﬁngers of fresh water (Fig. 18.6). For
large k (narrow ﬁngers), the dispersion relation (18.41) predicts a growth rate given
approximately by
p = −iω ∼β(−g . ∇)C
νk2
.
(18.43)
Thus the growth of narrow ﬁngers is driven by the concentration gradient and re-
tarded by viscosity. For larger ﬁngers, the temperature gradient participates in the
retardation, since the heat must diffuse to break the buoyant stability.
Now let us turn to the nonlinear development of this instability. Although we have
just considered a single Fourier mode, the ﬁngers that grow are roughly cylindrical
ratherthansheet-like.Theylengthenataratethatisslowenoughfortheheattodiffuse
horizontally, though not so slow that the salt can diffuse. Let the diffusion coefﬁcient
for the salt be χC by analogy with χ for temperature. If the length of the ﬁngers is L
18.6 Double Diffusion—Salt Fingers
939

v
δf
L
FIGURE 18.6 Salt ﬁngers in a ﬂuid in which warm,
salty water lies on top of cold, fresh water.
and their width is δf, then to facilitate heat diffusion and prevent salt diffusion, the
vertical speed v must satisfy
χC L
δ2
f
≪v ≪χ L
δ2
f
.
(18.44)
Balancing the viscous acceleration vν/δ2
f by the buoyancy acceleration gβδC, we
obtain
v ∼
gβδCδ2
f
ν
.
(18.45)
We can therefore rewrite Eq. (18.44) as
width of nonlinear salt-
ﬁngering modes
χCνL
gβδC
1/4
≪δf ≪
 χνL
gβδC
1/4
.
(18.46)
Typically, χC ∼0.01χ, so Eq. (18.46) implies that the widths of the ﬁngers lie in a
narrow range, as is veriﬁed by laboratory experiments.
Salt ﬁngering can occur naturally, for example, in an estuary where cold river water
ﬂows beneath sea water warmed by the Sun. However, the development of salt ﬁngers
is quite slow, and in practice it only leads to mixing when the equilibrium velocity
ﬁeld is very small.
This instability is one example of a quite general type of instability known as double
diffusion, which can arise when two physical quantities can diffuse through a ﬂuid at
different rates. Other examples include the diffusion of two different solutes and the
diffusion of vorticity and heat in a rotating ﬂow.
EXERCISES
Exercise 18.7 Problem: Laboratory Experiment with Salt Fingers
Make an order-of-magnitude estimate of the size of the ﬁngers and the time it takes
for them to grow in a small transparent jar. You might like to try an experiment.
940
Chapter 18. Convection

Exercise 18.8 Problem: Internal Waves
Considerastablystratiﬁedﬂuidatrestwithasmall(negative)verticaldensitygradient
dρ/dz.
(a) By modifying the analysis in this section, ignoring the effects of viscosity, heat
conduction, and concentration gradients, show that small-amplitude linear
waves, which propagate in a direction making an angle θ to the vertical, have an
angular frequency given by ω = N| sin θ|, where N ≡[(g . ∇) ln ρ]1/2 is known
as the Brunt-V¨ais¨al¨a frequency. These waves are called internal waves. They can
also be found at abrupt discontinuities as well as in the presence of a slow vari-
ation in the background medium. They are analogous to the Love and Rayleigh
waves we have already met in our discussion of seismology (Sec. 12.4.2). Another
type of internal wave is the Kelvin-Helmholtz wave (Sec. 14.6.1).
(b) Show that the group velocity of these waves is orthogonal to the phase velocity,
and interpret this result physically.
Bibliographic Note
For pedagogical treatments of almost all the topics in this chapter plus much more re-
lated material, we particularly like Tritton (1987), whose phenomenological approach
is lucid and appealing; and also Turner (1973), which is a thorough treatise on the
inﬂuence of buoyancy (thermally induced and otherwise) on ﬂuid motions.
Lautrup (2005) treats very nicely all this chapter’s topics except convection in stars,
salt ﬁngers, and double diffusion. Landau and Lifshitz (1959, Chaps. 5 and 6) give a
fairly succinct treatment of diffusive heat ﬂow in ﬂuids, the onset of convection in
several different physical situations, and the concepts underlying double diffusion.
Chandrasekhar (1961, Chaps. 2–6) gives a thorough and rich treatment of the inﬂu-
ence of a wide variety of phenomena on the onset of convection, and on the types of
ﬂuid motions that can occur near the onset of convection. For a few pages on strongly
turbulent convective heat transfer, see White (2006, Sec. 6-10).
Engineering-oriented textbooks typically say little about convection. For an engi-
neer’s viewpoint and engineering issues in convection, we recommend more special-
ized texts, such as Bejan (2013). For an applied mathematician’s viewpoint, we suggest
the treatise Pop and Ingham (2001).
Bibliographic Note
941


19
CHAPTER NINETEEN
Magnetohydrodynamics
. . . it is only the plasma itself which does not ‘understand’ how beautiful the theories are
and absolutely refuses to obey them.
HANNES ALFV´EN (1970)
19.1
19.1 Overview
In preceding chapters we have described the consequences of incorporating viscosity
and thermal conductivity into the description of a ﬂuid. We now turn to our ﬁnal
embellishment of ﬂuid mechanics, in which the ﬂuid is electrically conducting and
moves in a magnetic ﬁeld. The study of ﬂows of this type is known as magnetohydro-
dynamics, or MHD for short. In our discussion, we eschew full generality and with
one exception just use the basic Euler equation (no viscosity, no heat diffusion,
etc.) augmented by magnetic terms. This approach sufﬁces to highlight peculiarly
magnetic effects and is adequate for many applications.
The simplest example of an electrically conducting ﬂuid is a liquid metal, for
example, mercury or liquid sodium. However, the major application of MHD is in
plasma physics—discussed in Part VI. (A plasma is a hot, ionized gas containing free
electrons and ions.) It is by no means obvious that plasmas can be regarded as ﬂuids,
since the mean free paths for Coulomb-force collisions between a plasma’s electrons
and ions are macroscopically long. However, as we shall learn in Sec. 20.5, collective
interactions between large numbers of plasma particles can isotropize the particles’
velocity distributions in some local mean reference frame, thereby making it sensible
to describe the plasma macroscopically by a mean density, velocity, and pressure.
These mean quantities can then be shown to obey the same conservation laws of
mass, momentum, and energy as we derived for ﬂuids in Chap. 13. As a result, a
ﬂuid description of a plasma is often reasonably accurate. We defer to Part VI further
discussion of this point, asking the reader to take it on trust for the moment. In MHD,
we also implicitly assume that the average velocity of the ions is nearly the same as
the average velocity of the electrons. This is usually a good approximation; if it were
not so, then the plasma would carry an unreasonably large current density.
TwoserioustechnologicalapplicationsofMHDmaybecomeveryimportantinthe
future. In the ﬁrst, strong magnetic ﬁelds are used to conﬁne rings or columns of hot
plasma that (it is hoped) will be held in place long enough for thermonuclear fusion
to occur and for net power to be generated. In the second, which is directed toward a
943

BOX 19.1.
READERS’ GUIDE
.
This chapter relies heavily on Chap. 13 and somewhat on the
treatment of vorticity transport in Sec. 14.2.
.
Part VI, Plasma Physics (Chaps. 20–23), relies heavily on this chapter.
similar goal, liquid metals or plasmas are driven through a magnetic ﬁeld to generate
electricity. The study of magnetohydrodynamics is also motivated by its widespread
application to the description of space (in the solar system) and astrophysical plasmas
(beyond the solar system). We illustrate the principles of MHD using examples drawn
from all these areas.
After deriving the basic equations of MHD (Sec. 19.2), we elucidate magnetostatic
(also called “hydromagnetic”) equilibria by describing a tokamak (Sec. 19.3). This is
currently the most popular scheme for the magnetic conﬁnement of hot plasma. In
our second application (Sec. 19.4) we describe the ﬂow of conducting liquid metals or
plasma along magnetized ducts and outline its potential as a practical means of elec-
trical power generation and spacecraft propulsion. We then return to the question
of magnetostatic conﬁnement of hot plasma and focus on the stability of equilibria
(Sec. 19.5). This issue of stability has occupied a central place in our development of
ﬂuid mechanics, and it will not come as a surprise to learn that it has dominated re-
search on thermonuclear fusion in plasmas. When a magnetic ﬁeld plays a role in the
equilibrium (e.g., for magnetic conﬁnement of a plasma), the ﬁeld also makes possible
new modes of oscillation, and some of these MHD modes can be unstable to expo-
nentialgrowth.Manymagnetic-conﬁnementgeometriesexhibitsuchinstabilities.We
demonstrate this qualitatively by considering the physical action of the magnetic ﬁeld,
and also formally by using variational methods.
In Sec. 19.6, we turn to a geophysical problem, the origin of Earth’s magnetic ﬁeld.
ItisgenerallybelievedthatcomplexﬂuidmotionsinEarth’sliquidcoreareresponsible
for regenerating the ﬁeld through dynamo action. We use a simple model to illustrate
this process.
When magnetic forces are added to ﬂuid mechanics, a new class of waves, called
magnetosonic waves, can propagate. We conclude our discussion of MHD in Sec. 19.7
by deriving the properties of these wave modes in a homogeneous plasma and dis-
cussing how they control the propagation of cosmic rays in the interplanetary and
interstellar media.
As in previous chapters, we encourage our readers to view ﬁlms; on magneto-
hydrodynamics, for example, Shercliff (1965).
19.2
19.2 Basic Equations of MHD
The equations of MHD describe the motion of a conducting ﬂuid in a magnetic ﬁeld.
This ﬂuid is usually either a liquid metal or a plasma. In both cases, the conductivity,
944
Chapter 19. Magnetohydrodynamics

strictly speaking, should be regarded as a tensor (Sec. 20.6.3) if the electrons’ cyclotron
frequency (Sec. 20.6.1) exceeds their collision frequency (the inverse of the mean time
between collisions; Sec. 20.4.1). (If there are several collisions per cyclotron orbit, then
the inﬂuence of the magnetic ﬁeld on the transport coefﬁcients will be minimal.)
However, to keep the mathematics simple, we treat the conductivity as a constant
scalar, κe. In fact, it turns out that for many of our applications, it is adequate to take
the conductivity as inﬁnite, and it does not matter whether that inﬁnity is a scalar or
a tensor!
Two key physical effects occur in MHD, and understanding them well is key to
developing physical intuition. The ﬁrst effect arises when a good conductor moves
into a magnetic ﬁeld (Fig. 19.1a). Electric current is induced in the conductor, which,
by Lenz’s law, creates its own magnetic ﬁeld. This induced magnetic ﬁeld tends to
canceltheoriginal, externallysupportedﬁeld, therebyineffectexcludingthemagnetic
ﬁeld lines from the conductor. Conversely, when the magnetic ﬁeld penetrates the
conductor and the conductor is moved out of the ﬁeld, the induced ﬁeld reinforces
the applied ﬁeld. The net result is that the lines of force appear to be dragged along
with the conductor—they “go with the ﬂow.” Naturally, if the conductor is a ﬂuid with
complex motions, the ensuing magnetic ﬁeld distribution can become quite complex,
and the current builds up until its growth is balanced by Ohmic dissipation.
The second key effect is dynamical. When currents are induced by a motion of a
conducting ﬂuid through a magnetic ﬁeld, a Lorentz (or j × B) force acts on the ﬂuid
and modiﬁes its motion (Fig. 19.1b). In MHD, the motion modiﬁes the ﬁeld, and the
ﬁeld, in turn, reacts back and modiﬁes the motion. This behavior makes the theory
highly nonlinear.
Before deriving the governing equations of MHD, we should consider the choice
of primary variables. In electromagnetic theory, we specify the spatial and temporal
variation of either the electromagnetic ﬁeld or its source, the electric charge density
and current density. One choice is computable (at least in principle) from the other
N
S
N
S
B
B
(a)
(b)
F = j × B
j¯
v
two key physical effects in
MHD
FIGURE 19.1 The two key physical effects that occur in MHD. (a) A moving conductor
modiﬁes the magnetic ﬁeld by dragging the ﬁeld lines with it. When the conductivity
is inﬁnite, the ﬁeld lines are frozen in the moving conductor. (b) When electric
current, ﬂowing in the conductor, crosses magnetic ﬁeld lines, a Lorentz force is
generated that accelerates the ﬂuid.
19.2 Basic Equations of MHD
945

using Maxwell’s equations, augmented by suitable boundary conditions. So it is with
MHD, and the choice depends on convenience. It turns out that for the majority of
applications, it is most instructive to deal with the magnetic ﬁeld as primary, and to
in MHD the magnetic ﬁeld
is the primary variable
use Maxwell’s equations
Maxwell’s equations
∇. E = ρe
ϵ0
,
(19.1a)
∇. B = 0,
(19.1b)
∇× E = −∂B
∂t ,
(19.1c)
∇× B = μ0j + μ0ϵ0
∂E
∂t
(19.1d)
to express the electric ﬁeld E, the current density j, and the charge density ρe in terms
of the magnetic ﬁeld (next subsection).
19.2.1
19.2.1 Maxwell’s Equations in the MHD Approximation
As normally formulated, Ohm’s law is valid only in the rest frame of the conductor. In
particular, for a conducting ﬂuid, Ohm’s law relates the current density j′ measured
in the ﬂuid’s local rest frame to the electric ﬁeld E′ measured there:
j′ = κeE′,
(19.2)
where κe is the scalar electric conductivity. Because the ﬂuid is generally accelerated,
dv/dt ̸= 0, its local rest frame is generally not inertial. Since it would produce a
terrible headache to have to transform time and again from some inertial frame to
the continually changing local rest frame when applying Ohm’s law, it is preferable to
reformulate Ohm’s law in terms of the ﬁelds E, B, and j measured in an inertial frame.
To facilitate this (and for completeness), we explore the frame dependence of all our
electromagnetic quantities E, B, j, and ρe.
Throughout our development of magnetohydrodynamics, we assume that the
ﬂuid moves with a nonrelativistic speed v ≪c relative to our chosen reference frame.
We can then express the rest-frame electric ﬁeld in terms of the inertial-frame electric
and magnetic ﬁelds as
E′ = E + v × B;
E′ = |E′| ≪E,
so E ≃−v × B.
(19.3a)
In the ﬁrst equation we have set the Lorentz factor γ ≡1/

1 −v2/c2 to unity, con-
sistent with our nonrelativistic approximation. The second equation follows from the
high conductivity of the ﬂuid, which guarantees that current will quickly ﬂow in what-
evermanneritmusttoannihilateanyelectricﬁeldE′ thatmightbeformedintheﬂuid’s
local rest frame. By contrast with the extreme frame dependence (19.3a) of the electric
946
Chapter 19. Magnetohydrodynamics

ﬁeld, the magnetic ﬁeld is essentially the same in the ﬂuid’s local rest frame as in the
laboratory. More speciﬁcally, the analog of Eq. (19.3a) is B′ = B −(v/c2) × E; and
since E ∼vB, the second term is of magnitude (v/c)2B, which is negligible, giving
B′ ≃B.
(19.3b)
Because E is highly frame dependent, so is its divergence, the electric charge density
ρe. In the laboratory frame, where E ∼vB, Gauss’s and Amp`ere’s laws [Eqs. (19.1a,d)]
imply that ρe ∼ϵ0vB/L ∼(v/c2)j, where L is the lengthscale on which E and Bvary;
and the relation E′ ≪E with Gauss’s law implies |ρ′
e| ≪|ρe|:
ρe ∼j v/c2,
|ρ′
e| ≪|ρe|.
(19.3c)
By transforming the current density between frames and approximating γ ≃1, we
obtain j′ = j + ρev = j + O(v/c)2j; so in the nonrelativistic limit (ﬁrst order in v/c)
we can ignore the charge density and write
j′ = j.
(19.3d)
in MHD, magnetic ﬁeld
and current density are
approximately frame
independent; electric ﬁeld
and charge density are
smallandframedependent
To recapitulate, in nonrelativistic magnetohydrodynamic ﬂows, the magnetic ﬁeld
and current density are frame independent up to fractional corrections of order
(v/c)2, while the electric ﬁeld and charge density are highly frame dependent and
are generally small in the sense that E/c ∼(v/c)B ≪B and ρe ∼(v/c2)j ≪j/c [in
Gaussian cgs units we have E ∼(v/c)B ≪B and ρec ∼(v/c)j ≪j].
Combining Eqs. (19.2), (19.3a), and (19.3d), we obtain the nonrelativistic form of
Ohm’s law in terms of quantities measured in our chosen inertial, laboratory frame:
Ohm’s law
j = κe(E + v × B).
(19.4)
We are now ready to derive explicit equations for the (inertial-frame) electric ﬁeld
and current density in terms of the (inertial-frame) magnetic ﬁeld. In our derivation,
we denote by L the lengthscale on which the magnetic ﬁeld changes.
WebeginwithAmp`ere’slawwrittenas∇× B −μ0j = μ0ϵ0∂E/∂t = (1/c2)∂E/∂t,
and we notice that the time derivative of E is of order Ev/L ∼Bv2/L (since E ∼vB).
Therefore, the right-hand side is O[Bv2/(c2L)]and thus can be neglected compared
to the O(B/L) term on the left, yielding:
current density in terms of
magnetic ﬁeld
j = 1
μ0
∇× B.
(19.5a)
We next insert this expression for j into the inertial-frame Ohm’s law (19.4), thereby
obtaining
electric ﬁeld in terms of
magnetic ﬁeld
E = −v × B +
1
κeμ0
∇× B.
(19.5b)
19.2 Basic Equations of MHD
947

If we happen to be interested in the charge density (which is rare in MHD), we can
compute it by taking the divergence of this electric ﬁeld:
charge density in terms of
magnetic ﬁeld
ρe = −ϵ0∇. (v × B).
(19.5c)
Equations (19.5) express all the secondary electromagnetic variables in terms of our
primary one, B. This has been possible because of the high electric conductivity κe and
our choice to conﬁne ourselves to nonrelativistic (low-velocity) situations; it would
not be possible otherwise.
We next derive an evolution law for the magnetic ﬁeld by taking the curl of Eq.
(19.5b), usingMaxwell’sequation∇× E = −∂B/∂t andthevectoridentity∇× (∇×
B) = ∇(∇. B) −∇2B, and using ∇. B = 0. The result is
evolution law for magnetic
ﬁeld
∂B
∂t = ∇× (v × B) +

1
μ0κe

∇2B,
(19.6)
which, using Eqs. (14.4) and (14.5) with ω replaced by B, can also be written as
DB
Dt = −B∇. v +

1
μ0κe

∇2B,
(19.7)
where D/Dt is the ﬂuid derivative deﬁned in Eq. (14.5). When the ﬂow is in-
compressible (as it often will be), the ∇. v term vanishes.
Equation (19.6)—or equivalently, Eq. (19.7)—is called the induction equation and
describes the temporal evolution of the magnetic ﬁeld. It is the same in form as the
propagation law for vorticity ω in a ﬂow with ∇P × ∇ρ = 0 [Eq. (14.3), or (14.6) with
ω∇. v addedinthecompressiblecase].The∇× (v × B)terminEq.(19.6)dominates
when the conductivity is large and can be regarded as describing the freezing of
for large conductivity:
freezing of magnetic ﬁeld
into the ﬂuid
magnetic ﬁeld lines in the ﬂuid in the same way as the ∇× (v × ω) term describes
the freezing of vortex lines in a ﬂuid with small viscosity ν (Fig. 19.2). By analogy
with Eq. (14.10), when ﬂux-freezing dominates, the ﬂuid derivative of B/ρ can be
written as
D
Dt
B
ρ

≡d
dt
B
ρ

−
B
ρ
. ∇

v = 0,
(19.8)
where ρ is mass density (not to be confused with charge density ρe). Equation (19.8)
states that B/ρ evolves in the same manner as the separation x between two points
in the ﬂuid (cf. Fig. 14.4 and associated discussion).
The term [1/(μ0κe)]∇2B in the B-ﬁeld evolution equation (19.6) or (19.7) is
analogous to the vorticity diffusion term ν∇2ω in the vorticity evolution equation
(14.3) or (14.6). Therefore, when κe is not too large, magnetic ﬁeld lines will diffuse
through the ﬂuid. The effective diffusion coefﬁcient (analogous to ν) is
magnetic diffusion
coefﬁcient
DM = 1/(μ0κe).
(19.9a)
948
Chapter 19. Magnetohydrodynamics

B
B
ω
(a)
(b)
FIGURE 19.2 Pictorial representation of the evolution of the magnetic ﬁeld
in a ﬂuid endowed with inﬁnite electrical conductivity. (a) A uniform
magnetic ﬁeld at time t = 0 in a vortex. (b) At a later time, when the ﬂuid
has rotated through ∼30◦, the circulation has stretched and distorted
the magnetic ﬁeld.
Earth’s magnetic ﬁeld provides an example of ﬁeld diffusion. That ﬁeld is believed
to be supported by electric currents ﬂowing in Earth’s iron core. Now, we can estimate
the electric conductivity of iron under these conditions and from it deduce a value
for the diffusivity, DM ∼1 m2 s−1. The size of Earth’s core is L ∼104 km, so if there
were no ﬂuid motions, then we would expect the magnetic ﬁeld to diffuse out of the
core and escape from Earth in a time
magnetic decay time
τM ∼L2
DM
(19.9b)
∼3 million years, which is much shorter than the age of Earth, ∼5 billion years.
The reason for this discrepancy, as we discuss in Sec. 19.6, is that there are internal
circulatory motions in the liquid core that are capable of regenerating the magnetic
ﬁeld through dynamo action.
AlthoughEq.(19.6)describesagenuinediffusionofthemagneticﬁeld, tocompute
with conﬁdence the resulting magnetic decay time, one must solve the complete
boundary value problem. To give a simple illustration, suppose that a poor conductor
(e.g., a weakly ionized column of plasma) is surrounded by an excellent conductor
(e.g., the metal walls of the container in which the plasma is contained), and that
magnetic ﬁeld lines supported by wall currents thread the plasma. The magnetic ﬁeld
will only diminish after the wall currents undergo Ohmic dissipation, which can take
much longer than the diffusion time for the plasma column alone.
It is customary to introduce a dimensionless number called the magnetic Reynolds
number, RM, directly analogous to the ﬂuid Reynolds number Re, to describe the rel-
ative importance of ﬂux freezing and diffusion. The ﬂuid Reynolds number can be
regarded as the ratio of the magnitude of the vorticity-freezing term, ∇× (v × ω) ∼
(V/L)ω, in the vorticity evolution equation, ∂ω/∂t = ∇× (v × ω) + ν∇2ω, to the
magnitude of the diffusion term, ν∇2ω ∼(ν/L2)ω: Re = (V/L)(ν/L2)−1 = V L/ν.
Here V is a characteristic speed, and L a characteristic lengthscale of the ﬂow.
Similarly, the magnetic Reynolds number is the ratio of the magnitude of the
19.2 Basic Equations of MHD
949

TABLE 19.1: Characteristic magnetic diffusivities DM, decay times τM, and magnetic
Reynolds numbers RM for some common MHD ﬂows with characteristic length scales L
and velocities V
Substance
L (m)
V (m s−1)
DM (m2 s−1)
τM (s)
RM
Mercury
0.1
0.1
1
0.01
0.01
Liquid sodium
0.1
0.1
0.1
0.1
0.1
Laboratory plasma
1
100
10
0.1
10
Earth’s core
107
0.1
1
1014
106
Interstellar gas
1017
103
103
1031
1017
magnetic-ﬂux-freezing term, ∇× (v × B) ∼(V/L)B, to the magnitude of the mag-
netic-ﬂux-diffusionterm, DM∇2B = [1/(μoκe)]∇2B ∼B/(μoκeL2), intheinduction
equation (19.6):
magnetic Reynolds
number and magnetic ﬁeld
freezing
RM =
V/L
DM/L2 = V L
DM
= μ0κeV L.
(19.9c)
When RM ≫1, the ﬁeld lines are effectively frozen in the ﬂuid; when RM ≪1, Ohmic
dissipation is dominant, and the ﬁeld lines easily diffuse through the ﬂuid.
Magnetic Reynolds numbers and diffusion times for some typical MHD ﬂows
are given in Table 19.1. For most laboratory conditions, RM is modest, which means
that electric resistivity 1/κe is signiﬁcant, and the magnetic diffusivity DM is rarely
negligible. By contrast, in space physics and astrophysics, RM is usually very large,
RM ≫1, so the resistivity can be ignored almost always and everywhere. This limiting
perfect MHD: inﬁnite
conductivity and magnetic
ﬁeld freezing
case, when the electric conductivity is treated as inﬁnite, is often called perfect MHD.
The phrase “almost always and everywhere” needs clariﬁcation. Just as for large-
Reynolds-number ﬂuid ﬂows, so also here, boundary layers and discontinuities can be
formed, in which the gradients of physical quantities are automatically large enough
to make RM ∼1 locally. An important example discussed in Sec. 19.6.3 is magnetic
magnetic reconnection
and its inﬂuence
reconnection. This occurs when regions magnetized along different directions are
juxtaposed, for example, when the solar wind encounters Earth’s magnetosphere. In
such discontinuities and boundary layers, the current density is high, and magnetic
diffusion and Ohmic dissipation are important. As in ordinary ﬂuid mechanics, these
dissipative layers and discontinuities can control the character of the overall ﬂow
despite occupying a negligible fraction of the total volume.
19.2.2
19.2.2 Momentum and Energy Conservation
The ﬂuid dynamical aspects of MHD are handled by adding an electromagnetic force
term to the Euler or Navier-Stokes equation. The magnetic force density j × B is the
sum of the Lorentz forces acting on all the ﬂuid’s charged particles in a unit volume.
950
Chapter 19. Magnetohydrodynamics

There is also an electric force density ρeE, but this is smaller than j × B by a factor
O(v2/c2) by virtue of Eqs. (19.5), so we ignore it. When j × B is added to the Euler
equation (13.44) (or equivalently, to the Navier-Stokes equation with the viscosity
neglected as unimportant in the situations we shall study), it takes the following form:
MHD equation of motion
for ﬂuid
ρ dv
dt = ρg −∇P + j × B = ρg −∇P + (∇× B) × B
μ0
.
(19.10)
Here we have used expression (19.5a) for the current density in terms of the magnetic
ﬁeld. This is our basic MHD force equation. In Sec. 20.6.2 we will generalize it to
situations where, due to electron cyclotron motion, the pressure P is anisotropic.
Like all other force densities in this equation, the magnetic one j × B can be
expressed as minus the divergence of a stress tensor, the magnetic portion of the
Maxwell stress tensor:
magnetic stress tensor
TM = B2g
2μ0
−B ⊗B
μ0
;
(19.11)
see Ex. 19.1. By virtue of j × B = −∇. TM and other relations explored in Sec. 13.5
momentum conservation
and Box 13.4, we can convert the force-balance equation (19.10) into the conservation
law for momentum [generalization of Eq. (13.42)]:
∂(ρv)
∂t
+ ∇. (P g + ρv ⊗v + Tg + TM) = 0.
(19.12)
Here Tg is the gravitational stress tensor [Eq. (1) of Box 13.4], which resembles the
magnetic one:
Tg = −g2g
8πG + g ⊗g
4πG ;
(19.13)
it is generally unimportant in laboratory plasmas but can be quite important in and
near stars and black holes.
ThetwotermsinthemagneticMaxwellstresstensor[Eq.(19.11)]canbeidentiﬁed
as the “push” of an isotropic magnetic pressure of B2/(2μ0) that acts just like the gas
pressure P, and the “pull” of a tension B2/μ0 that acts parallel to the magnetic ﬁeld.
The combination of the tension and the isotropic pressure give a net tension B2/(2μ0)
along the ﬁeld and a net pressure B2/(2μ0) perpendicular to the ﬁeld lines (Ex. 1.14).
magnetic force density
The magnetic force density
fm = −∇. TM = j × B = (∇× B) × B
μ0
(19.14)
can be rewritten, using standard vector identities, as
fm = −∇
 B2
2μ0

+ (B . ∇)B
μ0
= −

∇
 B2
2μ0

⊥
+
(B . ∇)B
μ0

⊥
.
(19.15)
19.2 Basic Equations of MHD
951

B
B2
—
μ0R
(a)
(b)
rB2
—
2μ0
–
?
R
FIGURE 19.3 Contributions to the electromagnetic force density acting on a
conducting ﬂuid in a nonuniform magnetic ﬁeld. A magnetic-pressure force
density −[∇B2/(2μ0)]⊥acts perpendicularly to the ﬁeld. And a magnetic-
curvature force density [(B . ∇)B/μ0]⊥, which is also perpendicular to the
magnetic ﬁeld and lies in the plane of the ﬁeld’s bend, points toward its center
of curvature. The magnitude of this curvature force density is B2/(μ0R),
where R is the radius of curvature.
Here “⊥” means keep only the components perpendicular to the magnetic ﬁeld; the
fact that fm = j × B guarantees that the net force parallel to B must vanish, so we
can throw away the component along B in each term. This transversality of fm means
that the magnetic force neither inhibits nor promotes motion of the ﬂuid along the
magnetic ﬁeld. Instead, ﬂuid elements are free to slide along the ﬁeld like beads that
slide without friction along a magnetic “wire.”
The “⊥” expressions in Eq. (19.15) indicate that the magnetic force density has
two parts: ﬁrst, the negative of the 2-dimensional gradient of the magnetic pressure
B2/(2μ0) orthogonal to B (Fig. 19.3a), and second, an orthogonal curvature force
(B . ∇)B/μ0, which has magnitude B2/(μ0R), where R is the radius of curvature of
a ﬁeld line. This curvature force acts toward the ﬁeld line’s center of curvature (Fig.
19.3b) and is the magnetic-ﬁeld-line analog of the force that acts on a curved wire or
curved string under tension.
Just as the magnetic force density dominates and the electric force is negligible
[O(v2/c2)] in our nonrelativistic situation, so also the electromagnetic contribution
to the energy density is predominantly due to the magnetic termUM = B2/(2μ0) with
negligible electric contribution. The electromagnetic energy ﬂux is just the Poynting
ﬂux FM = E × B/μ0, with E given by Eq. (19.5b). Inserting these expressions into the
law of energy conservation (13.58) (and continuing to neglect viscosity), we obtain
energy conservation
∂
∂t
1
2v2 + u + 

ρ + B2
2μ0

+ ∇.
1
2v2 + h + 

ρv + E × B
μ0

= 0.
(19.16)
When the ﬂuid’s self-gravity is important, we must augment this equation with the
gravitational energy density and ﬂux, as discussed in Box 13.4.
952
Chapter 19. Magnetohydrodynamics

As in Sec. 13.7.4, we can combine this energy conservation law with mass conser-
vation and the ﬁrst law of thermodynamics to obtain an equation for the evolution of
entropy: Eqs. (13.75) and (13.76) are modiﬁed to read
entropy evolution; Ohmic
dissipation
∂(ρs)
∂t
+ ∇. (ρsv) = ρ ds
dt = j2
κeT .
(19.17)
Thus, just as viscosity increases entropy through viscous dissipation, and thermal
conductivity increases entropy through diffusive heat ﬂow [Eqs. (13.75) and (13.76)],
so also electrical resistivity (formally, κe−1) increases entropy through Ohmic dissipa-
tion. From Eq. (19.17) we see that our fourth transport coefﬁcient κe, like our previous
three (the two coefﬁcients of viscosity η ≡ρν and ζ and the thermal conductivity κ),
is constrained to be positive by the second law of thermodynamics.
EXERCISES
Exercise 19.1 Derivation: Basic Equations of MHD
(a) Verify that −∇. TM = j × B, where TM is the magnetic stress tensor (19.11).
(b) Take the scalar product of the ﬂuid velocity v with the equation of motion (19.10)
and combine with mass conservation to obtain the energy conservation equation
(19.16).
(c) Combine
energy
conservation
(19.16)
with
the
ﬁrst
law
of
thermo-
dynamics and mass conservation to obtain Eq. (19.17) for the evolution of the
entropy.
19.2.3
19.2.3 Boundary Conditions
types of interfaces: contact
discontinuity and shock
front
The equations of MHD must be supplemented by boundary conditions at two differ-
ent types of interfaces. The ﬁrst is a contact discontinuity (i.e., the interface between
two distinct media that do not mix; e.g., the surface of a liquid metal or a rigid wall
of a plasma containment device). The second is a shock front that is being crossed by
the ﬂuid. Here the boundary is between shocked and unshocked ﬂuid.
We can derive the boundary conditions by transforming into a primed frame in
which the interface is instantaneously at rest (not to be confused with the ﬂuid’s local
rest frame) and then transforming back into our original unprimed inertial frame.
In the primed frame, we resolve the velocity and magnetic and electric vectors into
components normal and tangential to the surface. If n is a unit vector normal to the
surface, then the normal and tangential components of velocity in either frame are
vn = n . v,
vt = v −(n . v)n,
(19.18)
19.2 Basic Equations of MHD
953

S
C
V
FIGURE 19.4 Elementary pill box V and elementary circuit C used in
deriving the MHD junction conditions at a surface S.
and similarly for the E and B. At a contact discontinuity, we have
boundary conditions at
interfaces: Eqs. (19.19)
v′
n = vn −vsn = 0
(19.19a)
on both sides of the interface surface; here vsn is the normal velocity of the surface.
At a shock front, mass ﬂux across the surface is conserved [cf. Eq. (17.29a)]:
junction condition for mass
ﬂux
[ρv′
n]= [ρ(vn −vsn)]= 0.
(19.19b)
Here, as in Sec. 17.5, we use the notation [X]to signify the difference in some quantity
X across the interface, that is, the junction condition for X.
When we consider the magnetic ﬁeld, it does not matter which frame we use, since
B is unchanged to the Galilean order at which we are working. Let us construct a thin
“pill box”V (Fig. 19.4) and integrate the equation ∇. B = 0over its volume, invoke the
divergence theorem, and let the box thickness diminish to zero; thereby we see that
electromagnetic junction
conditions
[Bn]= 0.
(19.19c)
By contrast, the tangential component of the magnetic ﬁeld can be discontinuous
across an interface because of surface currents: by integrating ∇× B = μ0jacross the
shock front, we can deduce that
[Bt]= −μ0n × J,
(19.19d)
where J is the surface current density.
We deduce the junction condition on the electric ﬁeld by integrating Maxwell’s
equation ∇× E = −∂B/∂t over the area bounded by the circuit C in Fig. 19.4 and
using Stokes’ theorem, letting the two short legs of the circuit vanish. We thereby
obtain
[E′
t]= [Et]+ [(vs × B)t]= 0,
(19.19e)
954
Chapter 19. Magnetohydrodynamics

where vs is the velocity of a frame that moves with the surface. Note that only the
normal component of the velocity contributes to this expression, so we can replace vs
by vsnn. The normal component of the electric ﬁeld, like the tangential component
of the magnetic ﬁeld, can be discontinuous, as there may be surface charge at the
interface.
There are also dynamical junction conditions that can be deduced by integrating
the laws of momentum conservation (19.12) and energy conservation (19.16) over the
pill box and using Gauss’s theorem to convert the volume integral of a divergence to a
surface integral. The results, naturally, are the requirements that the normal ﬂuxes of
momentum T . n and energy F . n be continuous across the surface. Here T is the total
stress [i.e., the quantity inside the divergence in Eq. (19.12)], and F is the total energy
ﬂux [i.e., the quantity inside the divergence in Eq. (19.16)]; see Eqs. (17.29)–(17.31)
and associated discussion. The normal and tangential components of [T . n]= 0 read
dynamical junction
conditions
'
P + ρ(vn −vsn)2 + B2
t
2μ0
(
= 0,
(19.19f)

ρ(vn −vsn)(vt −vst) −BnBt
μ0

= 0,
(19.19g)
where we have omitted the gravitational stress, since it will always be continuous in
situations studied in this chapter (no surface layers of mass). Similarly, continuity of
the energy ﬂux [F . n]= 0 reads
1
2v2 + h

ρ(vn −vsn) + n . [(E + vs × B) × B]
μ0

= 0.
(19.19h)
When the interface has plasma on one side and a vacuum magnetic ﬁeld on the
other, as in devices for magnetic conﬁnement of plasmas (Sec. 19.3), the vacuum elec-
tromagnetic ﬁeld, like that in the plasma, has small time derivatives: ∂/∂t ∼v∂/∂xj.
As a result, the vacuum displacement current ϵ0∂E/∂t is very small, and the vacuum
Maxwell equations reduce to the same form as those in the MHD plasma but with
ρe and j zero. As a result, the boundary conditions at the vacuum-plasma interface
(Ex. 19.2) are those discussed above [Eqs. (19.19)], but with ρ and P vanishing on
the vacuum side.
EXERCISES
Exercise 19.2 Example and Derivation: Perfect MHD Boundary
Conditions at a Fluid-Vacuum Interface
When analyzing the stability of conﬁgurations for magnetic conﬁnement of a plasma
(Sec. 19.5), one needs boundary conditions at the plasma-vacuum interface for the
special case of perfect MHD (electrical conductivity idealized as arbitrarily large).
19.2 Basic Equations of MHD
955

Denote by a tilde (˜Band ˜E) the magnetic and electric ﬁelds in the vacuum, and reserve
non-tilde symbols for quantities on the plasma side of the interface.
(a) Show that the normal-force boundary condition (19.19f) reduces to an equation
for the vacuum region’s tangential magnetic ﬁeld:
˜B2
t
2μ0
= P + B2
t
2μ0
.
(19.20a)
(b) By combining Eqs. (19.19c) and (19.19g) and noting that vn −vsn must vanish
(why?), and assuming that the magnetic conﬁnement entails surface currents on
the interface, show that the normal component of the magnetic ﬁeld must vanish
on both sides of the interface:
˜Bn = Bn = 0.
(19.20b)
(c) When analyzing energy ﬂow across the interface, it is necessary to know the
tangential electric ﬁeld. On the plasma side ˜Et is a secondary quantity ﬁxed by
projecting tangentially the relation E + v × B = 0. On the vacuum side it is ﬁxed
by the boundary condition (19.19e). By combining these two relations, show that
˜Et + vsn × ˜Bt = 0.
(19.20c)
Exercise 19.3 Problem: Diffusion of Magnetic Field
Consider an inﬁnitely long cylinder of plasma with constant electric conductivity,
surrounded by vacuum. Assume that the cylinder initially is magnetized uniformly
parallel to its length, and assume that the ﬁeld decays quickly enough that the plasma’s
inertia keeps it from moving much during the decay (so v ≃0).
(a) Show that the reduction of magnetic energy as the ﬁeld decays is compensated
by the Ohmic heating of the plasma plus energy lost to outgoing electromagnetic
waves (which will be negligible if the decay is slow).
(b) Compute the approximate magnetic proﬁle after the ﬁeld has decayed to a small
fractionofitsoriginalvalue.YouranswershouldbeexpressibleintermsofaBessel
function.
Exercise 19.4 Example: Shock with Transverse Magnetic Field
Consider a normal shock wave (v perpendicular to the shock front), in which the
magnetic ﬁeld is parallel to the shock front, analyzed in the shock front’s rest frame.
(a) Show that the junction conditions across the shock are the vanishing of all the
following quantities:
[ρv]= [P + ρv2 + B2/(2μ0)]= [h + v2/2 + B2/(μ0ρ)]= [vB]= 0.
(19.21)
(b) Specialize to a ﬂuid with equation of state P ∝ργ. Show that these junction
conditions predict no compression, [ρ]= 0, if the upstream velocity is v1 = Cf ≡

(B2
1/μ0 + γ P1)/ρ1. For v1 greater than this Cf, the ﬂuid gets compressed.
956
Chapter 19. Magnetohydrodynamics

(c) Explain why the result in part (b) means that the speed of sound perpendicular
to the magnetic ﬁeld must be Cf. As we shall see in Sec. 19.7.2, this indeed is the
case: Cf is the speed [Eq. (19.77)] of a fast magnetosonic wave, the only kind of
sound wave that can propagate perpendicular to B.
Exercise 19.5 Problem: Earth’s Bow Shock
The solar wind is a supersonic, hydromagnetic ﬂow of plasma originating in the solar
corona. At the radius of Earth’s orbit, the wind’s density is ρ ∼6 × 10−21 kg m−3,
its velocity is v ∼400 km s−1, its temperature is T ∼105 K, and its magnetic ﬁeld
strength is B ∼1nT.
(a) By balancing the wind’s momentum ﬂux with the magnetic pressure exerted by
Earth’s dipole magnetic ﬁeld, estimate the radius above Earth at which the solar
wind passes through a bow shock (Fig. 17.2).
(b) Consider a strong perpendicular shock at which the magnetic ﬁeld is parallel to
the shock front. Show that the magnetic ﬁeld strength will increase by the same
ratioasthedensity, whencrossingtheshockfront.Doyouexpectthecompression
to increase or decrease as the strength of the ﬁeld is increased, keeping all of the
other ﬂow variables constant?
19.2.4
19.2.4 Magnetic Field and Vorticity
We have already remarked on how the magnetic ﬁeld and the vorticity are both axial
vectors that can be written as the curl of a polar vector and that they satisfy similar
transport equations. It is not surprising that they are physically intimately related. To
explore this relationship in full detail would take us beyond the scope of this book.
However, wecanillustratetheirinteractionbyshowinghowtheycancreateeachother.
In brief: vorticity can twist a magnetic ﬁeld, amplifying it; and an already twisted ﬁeld,
vorticity–magnetic-ﬁeld
interactions
trying to untwist itself, can create vorticity.
First, consider a simple vortex through which passes a uniform magnetic ﬁeld
(Fig. 19.2a). If the magnetic Reynolds number is large enough, then the magnetic
ﬁeld is carried with the ﬂow and is wound up like spaghetti on the end of a fork
(Fig. 19.2b, continued for a longer time). This process increases the magnetic energy
in the vortex, though not the mean ﬂux of the magnetic ﬁeld. This ampliﬁcation
continues until either the ﬁeld gradient is large enough that the ﬁeld decays through
Ohmic dissipation, or the ﬁeld strength is large enough to react back on the ﬂow and
stop it from spinning.
Second, consider an irrotational ﬂow containing a twisted magnetic ﬁeld
(Fig. 19.5a). Provided that the magnetic Reynolds number is sufﬁciently large, the
magnetic stress, attempting to untwist the ﬁeld, will act on the ﬂow and induce vor-
ticity (Fig. 19.5b). We can describe this formally by taking the curl of the equation
19.2 Basic Equations of MHD
957

B
B
(a)
(b)
ω
v
v
FIGURE 19.5 (a) A twisted magnetic ﬁeld is frozen in an irrotational ﬂow. (b) The ﬁeld
tries to untwist and in the process creates vorticity.
of motion (19.10). Assuming, for simplicity, that the density ρ is constant and the
electric conductivity is inﬁnite, we obtain
∂ω
∂t −∇× (v × ω) = ∇× [(∇× B) × B]
μ0ρ
.
(19.22)
The term on the right-hand side of this equation changes the number of vortex lines
threading the ﬂuid, just like the −∇P × ∇ρ/ρ2 term on the right-hand side of Eq.
(14.3). However, because the divergence of the vorticity is zero, any fresh vortex lines
that are made must be created as continuous curves that grow out of points or lines
where the vorticity vanishes.
19.3
19.3 Magnetostatic Equilibria
19.3.1
19.3.1 Controlled Thermonuclear Fusion
GLOBAL POWER DEMAND
We start this section with an oversimpliﬁed discussion of the underlying problem.
Earth’s population has quadrupled over the past century to its present (2016) value
motivation for controlled
fusion program
of 7.4 billion and is still rising. We consume ∼16 TW of power more or less equally
for manufacture, transportation, and domestic use. The power is derived from oil (∼
5 TW), coal (∼4 TW), gas (∼4 TW), nuclear (ﬁssion) reactors (∼1TW), hydroelec-
tric turbines (∼1TW), and alternative sources, such as solar, wind, wave, and biomass
(∼1TW). The average power consumption is ∼2 kW per person, with Canada and
the United States in the lead, consuming ∼10 kW per person. Despite conservation
efforts, the demand for energy still appears to be rising.
Meanwhile, the burning of coal, oil, and gas produces carbon dioxide at a rate of
∼1 Gg s−1, about 10% of the total transfer rate in Earth’s biomass–atmosphere–ocean
carbon cycle. This disturbance of the carbon-cycle equilibrium has led to an increase
in the atmospheric concentration of carbon dioxide by about a third over the past
century and it is currently growing at an average rate of about a half percent per year.
There is strong evidence to link this increase in carbon dioxide and other greenhouse
gases to climate change, as exempliﬁed by an increase in the globally averaged mean
temperature of ∼1K over the past century. Given the long time constants associated
with the three components of the carbon cycle, future projections of climate change
958
Chapter 19. Magnetohydrodynamics

are alarming. These considerations strongly motivate the rapid deployment of low-
carbon sources of power—renewables and nuclear—and conservation.
THERMONUCLEAR FUSION
For more than 60 years, plasma physicists have striven to address this problem by
releasing nuclear energy in a controlled, peaceful manner through conﬁning plasma
at a temperature in excess of 100 million degrees using strong magnetic ﬁelds. In
the most widely studied scheme, deuterium and tritium combine according to the
reaction
d, t fusion reaction
d + t →α + n + 22.4 MeV.
(19.23)
The energy release is equivalent to ∼400 TJ kg−1. The fast neutrons can be absorbed
in a surrounding blanket of lithium, and the heat can then be used to drive a generator.
PLASMA CONFINEMENT
At ﬁrst this task seemed quite simple. However, it eventually became clear that it is
very difﬁcult to conﬁne hot plasma with a magnetic ﬁeld, because most conﬁnement
geometries are unstable. In this book we restrict our attention to a few simple con-
ﬁnement devices, emphasizing the one that is the basis of most modern efforts, the
tokamak.1 In this section, we treat equilibrium conﬁgurations; in Sec. 19.5, we con-
sider their stability.
In our discussions of both equilibrium and stability, we treat the plasma as a
magnetized ﬂuid in the MHD approximation. At ﬁrst sight, treating the plasma as
a ﬂuid might seem rather unrealistic, because we are dealing with a dilute gas of ions
and electrons that undergo infrequent Coulomb collisions. However, as we discuss
in Sec. 20.5.2 and justify in Chaps. 22 and 23, collective effects produce a sufﬁciently
high effective collision frequency to make the plasma behave like a ﬂuid, so MHD
is usually a good approximation for describing these equilibria and their rather slow
temporal evolution.
Let us examine some numbers that characterize the regime in which a successful
controlled-fusion device must operate.
PLASMA PRESSURE
The ratio of plasma pressure to magnetic pressure
pressure ratio βββ for
controlled fusion
β ≡
P
B2/(2μ0)
(19.24)
plays a key role. For the magnetic ﬁeld to have any chance of conﬁning the plasma,
its pressure must exceed that of the plasma (i.e., β must be less than one). The
most successful designs achieve β ∼0.2. The largest ﬁeld strengths that can be safely
1.
Originally proposed in the Soviet Union by Andrei Sakharov and Igor Tamm in 1950. The word is a
Russian abbreviation for “toroidal magnetic ﬁeld.”
19.3 Magnetostatic Equilibria
959

sustained in the laboratory are B ∼10 T = 100 kG, so β <∼0.2 limits the gas pressure
maximum gas pressure for
magnetic conﬁnement
to P <∼107 Pa ∼100 atmospheres.
LAWSON CRITERION
Plasma fusion can only be economically feasible if more power is released by nuclear
reactions than is lost to radiative cooling. Both heating and cooling are proportional to
the square of the number density of hydrogen ions, n2. However, while the radiative
cooling rate increases comparatively slowly with temperature, the nuclear reaction
rate increases very rapidly. (This is because, as the mean energy of the ions increases,
thenumberofionsintheMaxwelliantailofthedistributionfunctionthatareenergetic
enough to penetrate the Coulomb barrier increases exponentially.) Thus for the rate
of heat production to greatly exceed the rate of cooling, the temperature need only
be modestly higher than that required for the rates to be equal—which is a minimum
temperatureessentiallyﬁxedbyatomicandnuclearphysics.Inthecaseofad-tplasma,
minimum temperature
for fusion and maximum
density for conﬁnement
this is Tmin ∼108 K. The maximum hydrogen density that can be conﬁned is therefore
nmax = P/(2kBTmin) ∼3 × 1021 m−3. (The factor 2 comes from the electrons, which
produce the same pressure as the ions.)
Now, if a volume V of plasma is conﬁned at a given number density n and
temperature Tmin for a time τ, then the amount of nuclear energy generated will
be proportional to n2V τ, while the energy to heat the plasma up to Tmin is ∝nV .
Therefore, there is a minimum value of the product nτ that must be attained before
net energy is produced. This condition is known as the Lawson criterion.Numerically,
the plasma must be conﬁned for
Lawson criterion for net
energy production in
controlled fusion
τ ∼(n/1020 m−3)−1 s,
(19.25)
typically ∼30 ms. The sound speed at these temperatures is ∼1 × 106 m s−1, and so
an unconﬁned plasma would hit the few-meter-sized walls of the vessel in which it is
held in a few μs. Therefore, the magnetic conﬁnement must be effective for typically
104–105 dynamical timescales (sound-crossing times). It is necessary that the plasma
be conﬁned and conﬁned well if we want to build a viable fusion reactor.
19.3.2
19.3.2 Z-Pinch
Z-pinch conﬁguration for
plasma conﬁnement
Before discussing plasma conﬁnement by tokamaks, we describe a simpler conﬁne-
ment geometry known as the Z-pinch and often called the Bennett pinch (Fig. 19.6a).
In a Z-pinch, electric current is induced to ﬂow along a cylinder of plasma. This
current creates a toroidal magnetic ﬁeld whose tension prevents the plasma from ex-
panding radially, much like hoops on a barrel prevent it from exploding. Let us assume
that the cylinder has a radius R and is surrounded by vacuum.
Now, in static equilibrium we must balance the plasma pressure gradient by a
Lorentz force:
∇P = j × B.
(19.26)
960
Chapter 19. Magnetohydrodynamics

(a)
(b)
(c)
B
B
j
j
j
j
transformer
primary
toroidal
field cell
vacuum
vessel
plasma current
R
magnetic field lines
magnetic
flux surfaces
FIGURE 19.6 (a) The Z-pinch. (b) The -pinch. (c) The tokamak.
19.3 Magnetostatic Equilibria
961

(Gravitational forces can safely be ignored.) Equation (19.26) implies immediately
that B . ∇P = j . ∇P = 0, so both the magnetic ﬁeld and the current density lie on
constant pressure (or isobaric) surfaces. An equivalent version of the force-balance
equation (19.26), obtained using Eq. (19.15) and Fig. 19.3, is
d
dϖ

P + B2
2μ0

= −B2
μ0ϖ ,
(19.27)
where ϖ is the radial cylindrical coordinate. Equation (19.27) exhibits the balance
between the gradient of plasma and magnetic pressure on the left, and the magnetic
tension (the “hoop force”) on the right. Treating it as a differential equation for B2 and
integrating it, assuming that P falls to zero at the surface of the column, we obtain for
the surface magnetic ﬁeld
B2(R) = 4μ0
R2
 R
0
P ϖdϖ .
(19.28)
We can reexpress the surface toroidal ﬁeld in terms of the total current ﬂowing along
the plasma as B(R) = μ0I/(2πR) (Amp`ere’s law); and assuming that the plasma is
primarily hydrogen (so its ion density n and electron density are equal), we can write
the pressure as P = 2nkBT . Inserting these expressions into Eq. (19.28), integrating,
and solving for the current, we obtain
I =
16πNkBT
μ0
1/2
,
(19.29)
where N is the number of ions per unit length. For a column of plasma with diameter
2R ∼1 m, hydrogen density n ∼1020 m−3, and temperature T ∼108 K, Eq. (19.29)
indicates that currents ∼1 MA are required for conﬁnement.
The most promising Z-pinch experiments to date have been carried out at Sandia
National Laboratories in Albuquerque, New Mexico. The experimenters have im-
pulsively compressed a column of gas into a surprisingly stable cylinder of diameter
∼1mm for a time ∼100 ns, using a current of ∼30 MA from giant capaciter banks. A
transient ﬁeld of ∼1kT was created.
19.3.3
19.3.3 -Pinch
-pinch conﬁguration for
plasma conﬁnement
There is a complementary equilibrium for a cylindrical plasma, in which the mag-
netic ﬁeld lies parallel to the axis and the current density encircles the cylinder (Fig.
19.6b). This conﬁguration is called the -pinch. It is usually established by making a
cylindrical metal tube with a small gap, so that current can ﬂow around it as shown
in the ﬁgure. The tube is ﬁlled with cold plasma, and then the current is turned on
quickly, producing a quickly growing longitudinal ﬁeld in the tube (as in a solenoid).
Since the plasma is highly conducting, the ﬁeld lines cannot penetrate the plasma
column but instead exert a pressure on its surface, causing it to shrink radially and
rapidly.TheplasmaheatsupduetoboththeradialworkdoneonitandOhmicheating.
Equilibrium is established when the plasma’s pressure P balances the magnetic pres-
sure B2/(2μ0) at the plasma’s surface.
962
Chapter 19. Magnetohydrodynamics

Despite early promise, interest in -pinches has waned, and mirror machines
(Sec. 19.5.3) have become more popular.
19.3.4
19.3.4 Tokamak
tokamak conﬁguration for
plasma conﬁnement
One of the problems with the - and Z-pinches (and we shall ﬁnd other problems
below!) is that they have ends through which plasma can escape. This is readily
addressed by replacing the cylinder with a torus. The most stable geometry, called the
tokamak, combines features of both Z- and -pinches; see Fig. 19.6c. If we introduce
spherical coordinates (r, θ, φ), then magnetic ﬁeld lines and currents that lie in an
r-θ plane (orthogonal to eφ) are called poloidal, whereas their φ components are
called toroidal.In a tokamak, the toroidal magnetic ﬁeld is created by external poloidal
current windings. However, the poloidal ﬁeld is mostly created as a consequence of
toroidal current induced to ﬂow in the plasma torus. The resulting net ﬁeld lines wrap
around the plasma torus in a helical manner, deﬁning a magnetic surface on which
the pressure is constant. The number of poloidal transits around the torus during one
toroidal transit is denoted ι/(2π); ι is called the rotational transform and is a property
of the magnetic surface on which the ﬁeld line resides. If ι/(2π) is a rational number,
then the ﬁeld line will close after a ﬁnite number of circuits. However, in general,
ι/(2π) will not be rational, so a single ﬁeld line will cover the whole magnetic surface
ergodically. This allows the plasma to spread over the whole surface rapidly. The
rotational transform is a measure of the toroidal current ﬂowing inside the magnetic
surface and of course increases as we move out from the innermost magnetic surface,
while the pressure decreases.
JET
The best performers to date (2016) include the MIT Alcator C-Mod (n ∼
2 × 1020 m−3, T ∼35 MK, B ∼6 T, τ ∼2 s), and the larger Joint European Torus
or JET (Keilhacker and the JET team, 1998). JET generated 16 MW of nuclear power
with τ ∼1 s by burning d-t fuel, but its input power was ∼25 MW and so, despite
being a major step forward, JET fell short of achieving “break even.”
ITER
The largest device, currently under construction, is the International Thermo-
nuclear Experimental Reactor (ITER) (whose acronym means “journey” in Latin).
ITER is a tokamak-based experimental fusion reactor being constructed in France by
a large international consortium (see http://www.iter.org/). The outer diameter of the
device is ∼20 m, and the maximum magnetic ﬁeld produced by its superconducting
magnets will be ∼14 T. Its goal is to use d-t fuel to convert an input power of
∼50 MW into an output power of ∼500 MW, sustained for ∼3,000 s.2 However, many
engineering, managerial, ﬁnancial, and political challenges remain to be addressed
before mass production of economically viable, durable, and safe fusion reactors can
begin.
2.
Note that it would require of order 10,000 facilities with ITER’s projected peak power operating contin-
uously to supply, say, one-third of the current global power demand.
19.3 Magnetostatic Equilibria
963

EXERCISES
Exercise 19.6 Problem: Strength of Magnetic Field in a Magnetic Conﬁnement Device
The currents that are sources for strong magnetic ﬁelds have to be held in place
by solid conductors. Estimate the limiting ﬁeld that can be sustained using normal
construction materials.
Exercise 19.7 Problem: Force-Free Equilibria
In an equilibrium state of a very low-β plasma, the plasma’s pressure force density
−∇P is ignorably small, and so the Lorentz force density j × B must vanish [Eq.
(19.10)]. Such a plasma is said to be “force-free.” As a result, the current density is
parallel to the magnetic ﬁeld, so ∇× B = αB. Show that α must be constant along
a ﬁeld line, and that if the ﬁeld lines eventually travel everywhere, then α must be
constant everywhere.
Exercise 19.8 Example and Challenge: Spheromak
Another magnetic conﬁnement device which brings out some important principles is
thespheromak.Spheromakscanbemadeinthelaboratory(Bellan, 2000)andhavealso
been proposed as the basis of a fusion reactor.3 It is simplest to consider a spheromak
in the limit when the plasma pressure is ignorable (low β) and the magnetic ﬁeld
distribution is force-free (Ex. 19.7). We just describe the simplest example of this
regime.
(a) As in the previous exercise, assume that α is constant everywhere and, without
loss of generality, set it equal to unity. Show that the magnetic ﬁeld—and also the
current density and vector potential, adopting the Coulomb gauge—satisfy the
vector Helmholtz equation: ∇2B + α2B = 0.
(b) Introduce a scalar χ such that B = αr × ∇χ + ∇× (r × ∇χ), with r the radial
vector pointing out of the spheromak’s center, and show that χ satisﬁes the scalar
Helmholtz equation: ∇2χ + α2χ = 0.
(c) The Helmholtz equation in part (b) separates in spherical coordinates (r, θ, φ).
Show that it has a nonsingular solution χ = jl(αr)Ylm(θ, φ), where jl(αr) is a
spherical Bessel function, and Ylm(θ, φ) is a spherical harmonic. Evaluate this for
the simplest example, the spheromak, with l = 2 and m = 0.
(d) Calculateexpressionsfortheassociatedmagneticﬁeldinpart(c)andeithersketch
or plot it.
(e) Show that the magnetic ﬁeld’s radial component vanishes on the surface of a
sphere of radius equal to the ﬁrst zero of jl. Hence explain why a spheromak
may be conﬁned in a conducting sphere or, alternatively, by a current-free ﬁeld
that is uniform at large distance.
3.
Spheromak conﬁgurations of magnetic ﬁelds have even been associated with ball lightning!
964
Chapter 19. Magnetohydrodynamics

Exercise 19.9 Problem: Magnetic Helicity
(a) A physical quantity that turns out to be useful in describing the evolution of
magnetic ﬁelds in conﬁnement devices is magnetic helicity. This is deﬁned by
H =

dV A . B, where A is the vector potential, and the integral should be
performed over all the space visited by the ﬁeld lines to remove a dependence
on the electromagnetic gauge. Compute the partial derivative of A and B with
respect to time to show that H is conserved if E . B = 0.
(b) The helicity H primarily measures the topological linkage of the magnetic ﬁeld
lines. Therefore, it should not be a surprise that H turns out to be relatively
well-preserved, even when the plasma is losing energy through resistivity and
radiation. To discuss magnetic helicity properly would take us too far into the
domain of classical electromagnetic theory, but some indication of its value fol-
lows from computing it for the case of two rings of magnetic ﬁeld containing
ﬂuxes 1 and 2. Start with the rings quite separate, and show that H = 0. Then
allow the rings to be linked while not sharing any magnetic ﬁeld lines. Show that
now H = 212 and that dH/dt = −2

dV E . B.4
19.4
19.4 Hydromagnetic Flows
Hartmann ﬂow and its
applications
We now introduce ﬂuid motions into our applications of magnetohydrodynamics.
Speciﬁcally, we explore a simple class of stationary hydromagnetic ﬂows: the ﬂow of an
electrically conducting ﬂuid along a duct of constant cross section perpendicular to a
uniform magnetic ﬁeld B0 (see Fig. 19.7). This is sometimes known as Hartmann ﬂow.
The duct has two insulating walls (top and bottom, as shown in the ﬁgure), separated
by a distance 2a that is much smaller than the separation of short side walls, which
are electrically conducting.
To relate Hartmann ﬂow to magnetic-free Poiseuille ﬂow (viscous, laminar ﬂow
between plates; Ex. 13.18), we reinstate the viscous force in the equation of motion.
For simplicity we assume that the time-independent ﬂow (∂v/∂t = 0) has traveled
sufﬁciently far down the duct (x direction) to have reached a z-independent form, so
v . ∇v = 0 and v = v(y, z). We also assume that gravitational forces are unimportant.
Then the ﬂow’s equation of motion takes the form
∇P = j × B + η∇2v,
(19.30)
where η = ρν is the coefﬁcient of dynamical viscosity. The magnetic (Lorentz) force
j × B alters the balance between the Poiseuille ﬂow’s viscous force η∇2v and the
4.
For further discussion, see Bellan (2000).
19.4 Hydromagnetic Flows
965

2a
v
B0
z
x
y
E0
FIGURE 19.7 Hartmann ﬂow with average speed v along
a duct of thickness 2a, perpendicular to an applied
magnetic ﬁeld of strength B0. The short side walls
are conducting and the two long horizontal walls are
electrically insulating.
pressure gradient ∇P. The details of that altered balance and the resulting magnetic-
inﬂuenced ﬂow depend on how the walls are connected electrically. Let us consider
four versions of Hartmann
ﬂow
four possibilities chosen to bring out the essential physics.
ELECTROMAGNETIC BRAKE
We short circuit the electrodes, so a current j can ﬂow (Fig. 19.8a). The magnetic ﬁeld
lines are partially dragged by the ﬂuid, bending them (as embodied in ∇× B = μ0j),
so they can exert a decelerating tension force j × B = (∇× B) × B/μ0 = B . ∇B/μ0
on the ﬂow (Fig. 19.3b). This conﬁguration is an electromagnetic brake. The pressure
gradient, which is trying to accelerate the ﬂuid, is balanced by the magnetic tension
and viscosity. The work being done (per unit volume) by the pressure gradient,
v . (−∇P), is converted into heat through viscous and Ohmic dissipation.
MHD POWER GENERATOR
The MHD power generator is similar to the electromagnetic brake except that an
external load is added to the circuit (Fig. 19.8b). Useful power can be extracted from
the ﬂow. Variants of this conﬁguration were developed in the 1970s–1990s in many
countries, but they are currently not seen to be economically competitive with other
power-generation methods.
FLOW METER
When the electrodes in a ﬂow meter are on an open circuit, the induced electric
ﬁeld produces a measurable potential difference across the duct (Fig. 19.8c). This
voltage will increase monotonically with the rate of ﬂow of ﬂuid through the duct
and therefore can provide a measurement of the ﬂow.
ELECTROMAGNETIC PUMP
Finally, we can attach a battery to the electrodes and allow a current to ﬂow (Figs. 19.7
and 19.8d). This produces a Lorentz force which either accelerates or decelerates the
966
Chapter 19. Magnetohydrodynamics

0
(a)
(b)
(c)
(d)
+V
I
R
FIGURE 19.8 Four variations on Hartmann ﬂow: (a) Electromagnetic
brake. (b) MHD power generator. (c) Flow meter. (d) Electromagnetic
pump.
ﬂow, depending on the direction of the magnetic ﬁeld. This method can be used to
pump liquid sodium coolant around a nuclear reactor. It has also been proposed as a
means of spacecraft propulsion in interplanetary space.
We consider in more detail two limiting cases of the electromagnetic pump. When
there is a constant pressure gradient Q = −dP/dx but no magnetic ﬁeld, a ﬂow
with modest Reynolds number will be approximately laminar with velocity proﬁle
(Ex. 13.18):
vx(z) = Qa2
2η
'
1 −
 z
a
2(
,
(19.31)
where a is the half-width of the channel. This ﬂow is the 1-dimensional version of the
Poiseuille ﬂow in a pipe, such as a blood artery, which we studied in Sec. 13.7.6 [cf.
Eq. (13.82a)]. Now suppose that uniform electric and magnetic ﬁelds E0 and B0 are
applied along the ey and ez directions, respectively (Fig. 19.7). The resulting magnetic
force j × B can either reinforce or oppose the ﬂuid’s motion. When the applied mag-
netic ﬁeld is small, B0 ≪E0/vx, the effect of the magnetic force will be similar to that
of the pressure gradient, and Eq. (19.31) must be modiﬁed by replacing Q ≡−dP/dx
by −dP/dx + jyBz = −dP/dy + κeE0B0. [Here jy = κe(Ey −vxBz) ≃κeE0.]
If the strength of the magnetic ﬁeld is increased sufﬁciently, then the magnetic
force will dominate the viscous force, except in thin boundary layers near the walls.
Outside the boundary layers, in the bulk of the ﬂow, the velocity will adjust so that the
electric ﬁeld vanishes in the rest frame of the ﬂuid (i.e., vx = E0/B0). In the boundary
layers vx drops sharply from E0/B0 to zero at the walls, and correspondingly, a strong
viscous force η∇2v develops. Since the pressure gradient ∇P must be essentially the
same in the boundary layer as in the adjacent bulk ﬂow and thus cannot balance this
19.4 Hydromagnetic Flows
967

–1.0
1.0
–0.5
0.5
0.0
0.8
0.6
0.4
0.2
vx(z)
—
vx(0)
z/a
FIGURE 19.9 Velocity proﬁles [Eq. (19.35)] for ﬂow in an electromagnetic pump of
width 2a with small and large Hartmann number scaled to the velocity at the center
of the channel. The dashed curve shows the almost parabolic proﬁle for Ha = 0.1
[Eq. (19.31)]. The solid curve shows the almost ﬂat-topped proﬁle for Ha = 10.
large viscous force, it must be balanced instead by the magnetic force: j × B + η∇2v =
0 [Eq. (19.30)], with j = κe(E + v × B) ∼κevxB0ey. We thereby see that the thickness
of the boundary layer is given by
δH ∼
*
η
κeB2
0
+1/2
.
(19.32)
This suggests a new dimensionless number to characterize the ﬂow,
Hartmann number
Ha = a
δH
= B0a
κe
η
1/2
,
(19.33)
called the Hartmann number.The square of the Hartmann number, Ha2, is essentially
the ratio of the magnetic force, |j × B| ∼κevxB2
0, to the viscous force, ∼ηvx/a2,
assuming a lengthscale a rather than δH for variations of the velocity.
The detailed velocity proﬁle vx(z) away from the vertical side walls is computed in
Ex. 19.10 and is shown for low and high Hartmann numbers in Fig. 19.9. Notice that
at low Hartmann numbers, the plotted proﬁle is nearly parabolic as expected, and at
high Hartmann numbers it consists of boundary layers at z ∼−a and z ∼a, and a
uniform ﬂow in between.
InExs.19.11and19.12weexploretwoimportantastrophysicalexamplesofhydro-
magnetic ﬂow: the magnetosphere of a rotating, magnetized star or other body, and
the solar wind.
EXERCISES
Exercise 19.10 Example: Hartmann Flow
Compute the velocity proﬁle of a conducting ﬂuid in a duct of thickness 2a
perpendicular to externally generated, uniform electric and magnetic ﬁelds (E0ey
968
Chapter 19. Magnetohydrodynamics

and B0ez) as shown in Fig. 19.7. Away from the vertical sides of the duct, the velocity
vx isjustafunctionofy, andthepressurecanbewrittenintheformP = −Qx + p(z),
where Q is the longitudinal pressure gradient.
(a) Show that the velocity ﬁeld satisﬁes the differential equation
d2vx
dz2 −κeB2
0
η
vx = −(Q + κeB0E0)
η
.
(19.34)
(b) Impose suitable boundary conditions at the bottom and top walls of the channel,
and solve this differential equation to obtain the following velocity ﬁeld:
vx = Q + κeB0E0
κeB2
0

1 −cosh(Ha z/a)
cosh(Ha)

,
(19.35)
where Ha is the Hartmann number (see Fig. 19.9).
Exercise 19.11 **Example: Rotating Magnetospheres
Many self-gravitating cosmic bodies are both spinning and magnetized. Examples are
Earth, the Sun, black holes surrounded by highly conducting accretion disks (which
hold a magnetic ﬁeld on the hole), neutron stars (pulsars), and magnetic white dwarfs.
As a consequence of the magnetic ﬁeld’s spin-induced motion, large electric ﬁelds are
produced outside the rotating body. The divergence of these electric ﬁelds must be
balanced by free electric charge, which implies that the region around the body can-
not be a vacuum. It is usually ﬁlled with plasma and is called a magnetosphere. MHD
provides a convenient formalism for describing the structure of this magnetosphere.
Magnetospheres are found around most planets and stars. Magnetospheres surround-
ing neutron stars and black holes are believed to be responsible for the emissions from
pulsars and quasars.
As a model of a rotating magnetosphere, consider a magnetized and inﬁnitely con-
ducting star, spinning with angular frequency ∗. Suppose that the magnetic ﬁeld is
stationary and axisymmetric with respect to the spin axis and that the magnetosphere,
like the star, is perfectly conducting.
(a) Show that the azimuthal component Eφ of the magnetospheric electric ﬁeld must
vanish if the magnetic ﬁeld is to be stationary. Hence show that there exists a
function (r) that must be parallel to ∗and must satisfy
E = −( × r) × B.
(19.36)
Show that if the motion of the magnetosphere’s conducting ﬂuid is simply a
rotation, then its angular velocity must be .
(b) Use the induction equation (magnetic-ﬁeld transport law) to show that
(B . ∇) = 0.
(19.37)
19.4 Hydromagnetic Flows
969

(c) Use the boundary condition at the surface of the star to show that the magne-
tosphere corotates with the star (i.e.,  = ∗). This is known as Ferraro’s law of
isorotation.
Exercise 19.12 Example: Solar Wind
The solar wind is a magnetized outﬂow of plasma that emerges from the solar corona.
We make a simple model of it by generalizing the results from the previous exer-
cise that emphasize its hydromagnetic features while ignoring gravity and thermal
pressure (which are also important in practice). We consider stationary, axisymmet-
ric motion in the equatorial plane, and idealize the magnetic ﬁeld as having the form
Br(r), Bφ(r). (If this were true at all latitudes, the Sun would have to contain magnetic
monopoles!)
(a) Use the results from the previous exercise plus the perfect MHD relation, E =
−v × B, to argue that the velocity ﬁeld can be written in the form
v = κB
ρ + ( × r),
(19.38)
where κ and are constant along a ﬁeld line. Interpret this relation kinematically.
(b) Resolve the velocity and the magnetic ﬁeld into radial and azimuthal components,
vr, vφ, and Br, Bφ, and show that ρvrr2 and Brr2 are constant.
(c) Use the induction equation to show that
vr
vφ −r = Br
Bφ
.
(19.39)
(d) Use the equation of motion to show that the speciﬁc angular momentum, includ-
ing both the mechanical and the magnetic contributions,
 = rvφ −rBrBφ
μ0ρvr
,
(19.40)
is constant.
(e) Combine Eqs. (19.39) and (19.40) to argue that
vφ = r[M2
A /(r2) −1]
M2
A −1
,
(19.41)
where
MA = vr(μ0ρ)1/2
Br
(19.42)
is the Alfv´en Mach number [cf. Eq. (19.73)]. Show that the solar wind must pass
through a critical point (Sec. 17.3.2) where its radial speed equals the Alfv´en
speed.
(f) Suppose that the critical point in part (e) is located at 20 solar radii and that
vr = 100 km s−1, vφ = 20 km s−1, and Br = 400 nT there. Calculate values for
 , Bφ, ρ and use these to estimate the fraction of the solar mass and the solar
970
Chapter 19. Magnetohydrodynamics

angular momentum that could have been carried off by the solar wind over its
∼5 Gyr lifetime. Comment on your answer.
(g) Suppose that there is no poloidal current density so that Bφ ∝r−1, and deduce
values for the velocity and the magnetic ﬁeld in the neighborhood of Earth where
r ∼200 solar radii. Sketch the magnetic ﬁeld and the path of the solar wind as it
ﬂows from rc to Earth.
The solar mass, radius and rotation period are ∼2 × 1030 kg, ∼7 × 108 m, and ∼25 d.
19.5
19.5 Stability of Magnetostatic Equilibria
Having used the MHD equation of motion to analyze some simple ﬂows, we return
to the problem of magnetic conﬁnement and demonstrate a procedure to analyze the
stability of the conﬁnement’s magnetostatic equilibria. We ﬁrst perform a straight-
forward linear perturbation analysis about equilibrium, obtaining an eigenequation
for the perturbation’s oscillation frequencies ω. For sufﬁciently simple equilibria, this
eigenequation can be solved analytically, but most equilibria are too complex for this
approach, so the eigenequation must be solved numerically or by other approxima-
tion techniques. This is rather similar to the task one faces in attempting to solve
the Schr¨odinger equation for multi-electron atoms. It will not be a surprise to learn
that variational methods are especially practical and useful, and we develop a suitable
formalism for them.
We develop the perturbation theory, eigenequation, and variational formalism in
some detail not only because of their importance for the stability of magnetostatic
equilibria, but also because essentially the same techniques (with different equations)
are used in studying the stability of other equilibria. One example is the oscillations
and stability of stars, in which the magnetic ﬁeld is unimportant, while self-gravity is
crucial [see, e.g., Shapiro and Teukolsky (1983, Chap. 6), and Sec. 16.2.4 of this book,
on helioseismology]. Another example is the oscillations and stability of elastostatic
equilibria, in which B is absent but shear stresses are important (Secs. 12.3 and 12.4).
19.5.1
19.5.1 Linear Perturbation Theory
Consider a perfectly conducting, isentropic ﬂuid at rest in equilibrium, with pressure
gradients that balance magnetic forces—for example, the Z-pinch, -pinch, and
tokamak conﬁgurations of Fig. 19.6. For simplicity, we ignore gravity. (This is usually
justiﬁed in laboratory situations.) The equation of equilibrium then reduces to
equation of magnetostatic
equilibrium without gravity
∇P = j × B
(19.43)
[Eq. (19.10)].
We now perturb slightly about our chosen equilibrium and ignore the (usually
negligible) effects of viscosity and magnetic-ﬁeld diffusion, so η = ρν ≃0 and κe ≃
∞. It is useful and conventional to describe the perturbations in terms of two different
types of quantities: (i) The change in a quantity (e.g., the ﬂuid density) moving with
Lagrangian and Eulerian
perturbations and how
they are related
the ﬂuid, which is called a Lagrangian perturbation and is denoted by the symbol 
(e.g., the lagrangian density perturbation ρ). (ii) The change at a ﬁxed location in
19.5 Stability of Magnetostatic Equilibria
971

space, which is called an Eulerian perturbation and is denoted by the symbol δ (e.g.,
the Eulerian density perturbation δρ). The fundamental variable used in the theory is
the ﬂuid’s Lagrangian displacement x ≡ξ(x, t) (i.e., the change in a ﬂuid element’s
location).Aﬂuidelementwhoselocationisx intheunperturbedequilibriumismoved
to location x + ξ(x, t) by the perturbations. From their deﬁnitions, one can see that
the Lagrangian and Eulerian perturbations are related by
 = δ + ξ . ∇
(e.g., ρ = δρ + ξ . ∇ρ).
(19.44)
Nowconsiderthetransportlawforthemagneticﬁeldinthelimitofinﬁniteelectri-
cal conductivity, ∂B/∂t = ∇× (v × B) [Eq. (19.6)]. To linear order, the ﬂuid velocity
is v = ∂ξ/∂t. Inserting this into the transport law and setting the full magnetic ﬁeld at
ﬁxed x and t equal to the equilibrium ﬁeld plus its Eulerian perturbation B →B + δB,
we obtain ∂δB/∂t = ∇× [(∂ξ/∂t) × (B + δB)]. Linearizing in the perturbation, and
integrating in time, we obtain for the Eulerian perturbation of the magnetic ﬁeld:
δB = ∇× (ξ × B).
(19.45a)
Since the current and the ﬁeld are related, in general, by the linear equation j =
∇× B/μ0, their Eulerian perturbations are related in the same way:
δj = ∇× δB/μ0.
(19.45b)
Intheequationofmassconservation, ∂ρ/∂t + ∇. (ρv) = 0, wereplacethedensity
by its equilibrium value plus its Eulerian perturbation, ρ →ρ + δρ, and replace v by
∂ξ/∂t. We then linearize in the perturbation to obtain
δρ + ρ∇. ξ + ξ . ∇ρ = 0.
(19.45c)
The lagrangian density perturbation, obtained from this via Eq. (19.44), is
ρ = −ρ∇. ξ.
(19.45d)
We assume that, as it moves, the ﬂuid gets compressed or expanded adiabatically
(no Ohmic or viscous heating, or radiative cooling). Then the Lagrangian change of
pressure P in each ﬂuid element (moving with the ﬂuid) is related to the Lagrangian
change of density by
P =
∂P
∂ρ

s
ρ = γ P
ρ ρ = −γ P ∇. ξ,
(19.45e)
where γ is the ﬂuid’s adiabatic index (ratio of speciﬁc heats), which might or might
not be independent of position in the equilibrium conﬁguration. Correspondingly,
the Eulerian perturbation of the pressure (perturbation at ﬁxed location) is
δP = P −(ξ . ∇)P = −γ P (∇. ξ) −(ξ . ∇)P .
(19.45f)
This is the pressure perturbation that appears in the ﬂuid’s equation of motion.
972
Chapter 19. Magnetohydrodynamics

By replacing v →∂ξ/∂t, P →P + δP , B →B + δB, and j →j + δj in the
ﬂuid’s equation of motion (19.10) and neglecting gravity, and by then linearizing
in the perturbation, we obtain
dynamical equation for
adiabatic perturbations
of a magnetostatic
equilibrium
ρ ∂2ξ
∂t2 = j × δB + δj × B −∇δP ≡ˆF[ξ].
(19.46)
Here ˆFisareal, lineardifferentialoperator, whoseformonecandeducebysubstituting
expressions (19.45a), (19.45b), and (19.45f) for δB, δj, and δP , and by substituting
∇× B/μ0 for j. Performing these substitutions and carefully rearranging the terms,
weeventuallyconverttheoperator ˆFintothefollowingform, expressedinslot-naming
index notation:
ˆFi[ξ]=
,
(γ −1)P + B2
2μ0

ξk;k + BjBk
μ0 ξj;k
-
;i
+

P + B2
2μ0

ξj;i + BjBk
μ0 ξi;k + BiBj
μ0 ξk;k

;j
.
(19.47)
Honestly! Here the semicolons denote gradients (partial derivatives in Cartesian co-
ordinates; connection coefﬁcients (Sec. 11.8) are required in curvilinear coordinates).
force operator ˆFi[ξ]
ˆFi[ξ]
ˆFi[ξ] is
self-adjoint
We write the operator ˆFi in the explicit form (19.47) because of its power for
demonstrating that ˆFi is self-adjoint (Hermitian, with real variables rather than com-
plex): by introducing the Kronecker-delta components of the metric, gij = δij, we can
easily rewrite Eq. (19.47) in the form
ˆFi[ξ]= (Tijklξk;l);j,
(19.48)
where Tijkl are the components of a fourth-rank tensor that is symmetric under
interchange of its ﬁrst and second pairs of indices: Tijkl = Tklij.
Now, our magnetic-conﬁnement equilibrium conﬁguration (e.g., Fig. 19.6) typi-
cally consists of a plasma-ﬁlled interior region V surrounded by a vacuum magnetic
ﬁeld (which in turn may be surrounded by a wall). Our MHD equations with force
operator ˆF are valid only in the plasma region V, and not in vacuum, where Maxwell’s
equations with small displacement current prevail. We use Eq. (19.48) to prove that
ˆF is a self-adjoint operator when integrated over V, with the appropriate boundary
conditions at the vacuum interface.
Speciﬁcally, we contract a vector ﬁeld ζ into ˆF[ξ], integrate over V, and perform
two integrations by parts to obtain

V
ζ . F[ξ]dV =

V
ζi(Tijklξk;l);jdV = −

V
Tijklζi;jξk;ldV =

V
ξi(Tijklζk;l);jdV
=

V
ξ . F[ζ]dV .
(19.49)
19.5 Stability of Magnetostatic Equilibria
973

Herewehavediscardedtheintegralsoftwodivergences, whichbyGauss’stheoremcan
be expressed as surface integrals at the ﬂuid-vacuum interface ∂V. Those unwanted
surface integrals vanish if ξ and ζ satisfy
Tijklξk;lζinj = 0,
and
Tijklζk;lξinj = 0,
(19.50)
with nj the normal to the interface ∂V .
boundary conditions for
perturbations
Now, ξ and ζ are physical displacements of the MHD ﬂuid, and as such, they
must satisfy the appropriate boundary conditions at the boundary ∂V of the plasma
region V. In the simplest, idealizedcase, the conducting ﬂuidwouldextendfar beyond
the region where the disturbances have appreciable amplitude, so ξ = ζ = 0 at the
distant boundary, and Eqs. (19.50) are satisﬁed. More reasonably, the ﬂuid might
butt up against rigid walls at ∂V, where the normal components of ξ and ζ vanish,
guaranteeing again that Eqs. (19.50) are satisﬁed. This conﬁguration is ﬁne for liquid
mercury or sodium, but not for a hot plasma, which would quickly destroy the walls.
For conﬁnement by a surrounding vacuum magnetic ﬁeld, no current ﬂows outside
V, and the displacement current is negligible, so ∇× δB = 0 there. By combining this
with the rest of Maxwell’s equations and paying careful attention to the motion of the
interface and boundary conditions [Eqs. (19.20)] there, one can show, once again, that
Eqs. (19.50) are satisﬁed (see, e.g., Goedbloed and Poedts, 2004, Sec. 6.6.2). Therefore,
in all these cases Eq. (19.49) is also true, which demonstrates the self-adjointness
(Hermiticity) of ˆF.5 We use this property below.
Returning to our perturbed MHD system, we seek its normal modes by assuming
a harmonic time dependence, ξ ∝e−iωt. The ﬁrst-order equation of motion (19.46)
then becomes
Sturm-Liouville type
eigenequation for
perturbations
ˆF[ξ]+ ρω2ξ = 0.
(19.51)
This is an eigenequation for the ﬂuid’s Lagrangian displacement ξ, with eigenvalue
ω2. It must be augmented by the boundary conditions (19.20) at the edge ∂V of the
ﬂuid.
By virtue of the elegant, self-adjoint mathematical form (19.48) of the differen-
tial operator ˆF, our eigenequation (19.51) is of a very special and powerful type,
called Sturm-Liouville; see any good text on mathematical physics (e.g., Mathews and
Walker, 1970; Arfken, Weber, and Harris, 2013; Hassani, 2013). From the general
(rather simple) theory of Sturm-Liouville equations, we can infer that all the eigen-
values ω2 are real, so the normal modes are purely oscillatory (ω2 > 0, ξ ∝e±i|ω|t)
properties of eigen-
frequencies and
eigenfunctions
or are purely exponentially growing or decaying (ω2 < 0, ξ ∝e±|ω|t). Exponentially
growing modes represent instabilities. Sturm-Liouville theory also implies that all
5.
Self-adjointness can also be deduced from energy conservation without getting entangled in detailed
boundary conditions (see, e.g., Bellan, 2006, Sec. 10.4.2).
974
Chapter 19. Magnetohydrodynamics

eigenfunctions [labeled by indices “(n)”] with different eigenfrequencies are orthog-
onal to one another, in the sense that

V ρξ(n) . ξ(m)dV = 0.
EXERCISES
Exercise 19.13 Derivation: Properties of Eigenmodes
Derive the properties of the eigenvalues and eigenfunctions for perturbations of an
MHD equilibrium that are asserted in the last paragraph of Sec. 19.5.1, namely, the
following.
(a) For each normal mode the eigenfrequency ωn is either real or imaginary.
(b) Eigenfunctions ξ(m) and ξ(n) that have different eigenvalues ωm ̸= ωn are orthog-
onal to each other:

ρ ξ(m) . ξ(m)dV = 0.
19.5.2
19.5.2 Z-Pinch: Sausage and Kink Instabilities
We illustrate MHD stability theory using a simple, analytically tractable example: a
variant of the Z-pinch conﬁguration of Fig. 19.6a. We consider a long, cylindrical
column of a conducting, incompressible liquid (e.g., mercury) with column radius R
and ﬂuid density ρ. The column carries a current I longitudinally along its surface
(rather than in its interior as in Fig. 19.6a), so j = [I/(2πR)]δ(ϖ −R)ez, and the
liquid is conﬁned by the resulting external toroidal magnetic ﬁeld Bφ ≡B. The
interior of the plasma is ﬁeld free and at constant pressure P0. From ∇× B = μ0j,
we deduce that the exterior magnetic ﬁeld is
Bφ ≡B = μ0I
2πϖ
at ϖ ≥R.
(19.52)
Here (ϖ , φ, z) are the usual cylindrical coordinates. This is a variant of the Z-pinch,
because the z-directed current on the column’s surface creates the external toroidal
ﬁeld B, which pinches the column until its internal pressure is balanced by the ﬁeld’s
pressure:
P0 =
 B2
2μ0

ϖ=R
.
(19.53)
It is quicker and more illuminating to analyze the stability of this Z-pinch equilib-
rium directly instead of by evaluating ˆF, and the outcome is the same. (For a treatment
based on ˆF, see Ex. 19.16.) Treating only the most elementary case, we consider small,
axisymmetric perturbations with an assumed variation ξ ∝ei(kz−ωt)f(ϖ) for some
function f. As the magnetic ﬁeld interior to the column vanishes, the equation of
motion ρdv/dt = −∇(P + δP ) becomes
−ω2ρξϖ = −δP ′,
−ω2ρξz = −ikδP ,
(19.54a)
where the prime denotes differentiation with respect to radius ϖ. Combining these
two equations, we obtain
ξ′
z = ikξϖ.
(19.54b)
19.5 Stability of Magnetostatic Equilibria
975

Because the ﬂuid is incompressible, it satisﬁes ∇. ξ = 0:
ϖ −1(ϖξϖ)′ + ikξz = 0,
(19.54c)
which, with Eq. (19.54b), leads to
ξ′′
z + ξ′
z
ϖ −k2ξz = 0.
(19.54d)
The solution of this equation that is regular at ϖ = 0 is
ξz = AI0(kϖ)
at ϖ ≤R,
(19.54e)
where A is a constant, and In(x) is the modiﬁed Bessel function: In(x) = i−nJn(ix).
From Eq. (19.54b) and dI0(x)/dx = I1(x), we obtain
ξϖ = −iAI1(kϖ).
(19.54f)
Next we consider the region exterior to the ﬂuid column. As this is vacuum, it
must be current free; and as we are dealing with a purely axisymmetric perturbation,
the ϖ component of Maxwell’s equation ∇× δB = 0 (with negligible displacement
current) reads
∂δBφ
∂z
= ikδBφ = 0.
(19.54g)
The φ component of the magnetic perturbation therefore vanishes outside the
column.
The interior and exterior solutions must be connected by the law of force balance,
that is, by the boundary condition (19.19f) [or equivalently, Eq. (19.20a) with the
tildes removed] at the plasma’s surface. Allowing for the displacement of the surface
and retaining only linear terms, this becomes
P0 + P = P0 + (ξ . ∇)P0 + δP = (B + Bφ)2
2μ0
= B2
2μ0
+ B
μ0
(ξ . ∇)B + BδBφ
μ0
,
(19.54h)
where all quantities are evaluated at ϖ = R. The equilibrium force-balance condition
gives us P0 = B2/(2μ0) [Eq. (19.53)] and ∇P0 = 0. In addition, we have shown that
δBφ = 0. Therefore, Eq. (19.54h) becomes simply
δP = BB′
μ0
ξϖ.
(19.54i)
976
Chapter 19. Magnetohydrodynamics

(a)
(b)
B
B
j
j
v
v
v
v
FIGURE 19.10 Physical interpretation of (a) sausage and (b) kink instabilities.
Substituting δP from Eqs. (19.54a) and (19.54e), B from Eq. (19.52), and ξϖ from
Eq. (19.54f), we obtain the dispersion relation
ω2 = −μ0I 2
4π2R4ρ
kRI1(kR)
I0(kR)
≃−μ0I 2
8π2R2ρ k2;
for k ≪R−1
≃−μ0I 2
4π2R3ρ k;
for k ≫R−1,
(19.55)
where we have used I0(x) ∼1, I1(x) ∼x/2 as x →0 and I1(x)/I0(x) →1as x →∞.
Because I0 and I1 are positive for all kR > 0, for every wave number k this disper-
sion relation shows that ω2 is negative. Therefore, ω is imaginary, the perturbation
grows exponentially with time, and so the Z-pinch conﬁguration is dynamically un-
stable. If we deﬁne a characteristic Alfv´en speed by a = B(R)/(μ0ρ)1/2 [see Eq.
(19.73)], then we see that the growth time for modes with wavelengths comparable to
the column diameter is roughly an Alfv´en crossing time 2R/a. This is fast!
sausage instability of
Z-pinch
This instability is sometimes called a sausage instability, because its eigenfunction
ξϖ ∝eikz consists of oscillatory pinches of the column’s radius that resemble the
pinches between sausages in a link. This sausage instability has a simple physical
interpretation (Fig. 19.10a), one that illustrates the power of the concepts of ﬂux
freezing and magnetic tension for developing intuition. If we imagine an inward radial
motion of the ﬂuid, then the toroidal loops of magnetic ﬁeld will be carried inward,
too, and will therefore shrink. As the external ﬁeld is unperturbed, δBφ = 0, we have
Bφ ∝1/ϖ, whence the surface ﬁeld at the inward perturbation increases, leading to
a larger “hoop” stress or, equivalently, a larger j × B Lorentz force, which accelerates
the inward perturbation (see Fig. 19.10a).
So far, we have only considered axisymmetric perturbations. We can generalize
our analysis by allowing the perturbations to vary as ξ ∝exp(imφ). (Our sausage in-
stability corresponds to m = 0.) Modes with m ≥1, like m = 0, are also generically
unstable. The m = 1modes are known as kink modes. In this case the column bends,
kink instability of Z-pinch
19.5 Stability of Magnetostatic Equilibria
977

(a)
(b)
B
FIGURE 19.11 (a) Stabilizing magnetic ﬁelds for -pinch conﬁguration. (b) Flute instability for
-pinch conﬁguration made into a torus.
and the ﬁeld strength is intensiﬁed along the inner face of the bend and reduced on the
outer face, thereby amplifying the instability (Fig. 19.10b). The incorporation of com-
pressibility, as is appropriate for plasma instead of mercury, introduces only algebraic
complexity; the conclusions are unchanged. The column is still highly unstable. It re-
mains so if we distribute the longitudinal current throughout the column’s interior,
thereby adding a magnetic ﬁeld to the interior, as in Fig. 19.6a.
MHD instabilities such as these have bedeviled attempts to conﬁne plasma long
enough to bring about nuclear fusion. Indeed, considerations of MHD stability were
one of the primary motivations for the tokamak, the most consistently successful of
experimental fusion devices.
19.5.3
19.5.3 The -Pinch and Its Toroidal Analog; Flute Instability; Motivation for Tokamak
full stability of -pinch
By contrast with the extreme instability of the Z-pinch conﬁguration, the -pinch
conﬁguration (Sec. 19.3.3 and Fig. 19.6b) is fully stable against MHD perturbations!
(See Ex. 19.14.) This is easily understood physically (Fig. 19.11a). When the plasma
cylinder is pinched or bent, at outward displaced regions of the cylinder, the external
longitudinal magnetic ﬁeld lines are pushed closer together, thereby strengthening
the magnetic ﬁeld and its pressure and thence creating an inward restoring force.
Similarly, at inward displaced regions, the ﬁeld lines are pulled apart, weakening their
pressure and creating an outward restoring force.
Unfortunately, the -pinch conﬁguration cannot conﬁne plasma without closing
its ends. The ends can be partially closed by a pair of magnetic mirrors, but there
remain losses out the ends that cause problems. The ends can be fully closed by
bending the column into a closed torus, but, sadly, the resulting toroidal -pinch
toroidal -pinch: ﬂute
instability
conﬁguration exhibits a new MHD “ﬂute” instability (Fig. 19.11b).
978
Chapter 19. Magnetohydrodynamics

This ﬂute instability arises on and near the outermost edge of the torus. That edge
is curved around the torus’s symmetry axis in just the same way as the face of the Z-
pinch conﬁguration is curved around its symmetry axis—with the magnetic ﬁeld in
both cases forming closed loops around the axis. As a result, this outer edge is subject
to a sausage-type instability, similar to that of the Z-pinch. The resulting corrugations
are translated along the torus, so they resemble the ﬂutes on a Greek column that
supports an architectural arch or roof (hence the name “ﬂute instability”). This ﬂuting
can also be understood as a ﬂux-tube interchange instability (Ex. 19.15).
how tokamak
conﬁguration
counteracts
instabilities
The ﬂute instability can be counteracted by endowing the torus with an internal
magnetic ﬁeld that twists (shears) as one goes radially inward (the tokamak conﬁg-
uration of Fig. 19.6c). Adjacent magnetic surfaces (isobars), with their different ﬁeld
directions, counteract each other’s MHD instabilities. The component of the mag-
netic ﬁeld along the plasma torus provides a pressure that stabilizes against sausage
instabilities and a tension that stabilizes against kink-type instabilities; the compo-
nent around the torus’s guiding circle acts to stabilize its ﬂute modes. In addition, the
formation of image currents in the conducting walls of a tokamak vessel can also have
a stabilizing inﬂuence.
EXERCISES
Exercise 19.14 Problem and Challenge: Stability of -Pinch
Derive the dispersion relation ω2(k) for axisymmetric perturbations of the -pinch
conﬁguration when the magnetic ﬁeld is conﬁned to the cylinder’s exterior, and con-
clude from it that the -pinch is stable against axisymmetric perturbations. [Hint:
The analysis of the interior of the cylinder is the same as for the Z-pinch analyzed
in the text.] Repeat your analysis for a general, variable-separated perturbation of
the form ξ ∝ei(mθ+kz−ωt), and thereby conclude that the -pinch is fully MHD
stable.
Exercise 19.15 Example: Flute Instability Understood by Flux-Tube Interchange
Carry out an analysis of the ﬂute instability patterned after that for rotating Cou-
ette ﬂow (ﬁrst long paragraph of Sec. 14.6.3) and that for convection in stars (Fig.
18.5): Imagine exchanging two plasma-ﬁlled magnetic ﬂux tubes that reside near
the outermost edge of the torus. Argue that the one displaced outward experi-
ences an unbalanced outward force, and the one displaced inward experiences an
unbalanced inward force. [Hint: (i) To simplify the analysis, let the equilibrium mag-
netic ﬁeld rise from zero continuously in the outer layers of the torus rather than
arising discontinuously at its surface, and consider ﬂux tubes in that outer, continu-
ous region. (ii) Argue that the unbalanced force per unit length on a displaced ﬂux
tube is [−∇(P + B2/(2μ0)) −(B2
tube/ϖ)eϖ]A. Here A is the tube’s cross sectional
area, ϖ is distance from the torus’s symmetry axis, eϖ is the unit vector point-
ing away from the symmetry axis, Btube is the ﬁeld strength inside the displaced
tube, and ∇(P + B2/(2μ0)) is the net surrounding pressure gradient at the tube’s
19.5 Stability of Magnetostatic Equilibria
979

displaced location.] Argue further that the innermost edge of the torus is stable
against ﬂux-tube interchange, so the ﬂute instability is conﬁned to the torus’s outer
face.
19.5.4
19.5.4 Energy Principle and Virial Theorems
For the perturbation eigenequation (19.46) and its boundary conditions, analytical or
even numerical solutions are only readily obtained in the most simple of geometries
and for the simplest ﬂuids. However, as the eigenequation is self-adjoint, it is possible
to write down a variational principle and use it to derive approximate stability criteria.
This variational principle has been a powerful tool for analyzing the stability of
tokamak and other magnetostatic conﬁgurations.
To derive the variational principle, we begin by multiplying the ﬂuid velocity
˙ξ = ∂ξ/∂t into the eigenequation (equation of motion) ρ∂2ξ/∂t2 = ˆF[ξ]. We then
integrate over the plasma-ﬁlled region V, and use the self-adjointness of ˆF to write

V dV ˙ξ . ˆF[ξ]= 1
2

V dV (˙ξ . ˆF[ξ]+ ξ . ˆF[˙ξ]). We thereby obtain
conserved energy for
adiabatic perturbations
of magnetostatic
conﬁgurations
dE
dt = 0,
where E = T + W ,
(19.56a)
T =

V
dV 1
2ρ˙ξ2,
and
W = W[ξ]≡−1
2

V
dV ξ . ˆF[ξ].
(19.56b)
The integrals T and W are the perturbation’s kinetic and potential energy, and E =
T + W is the conserved total energy.
Any solution of the equation of motion ∂2ξ/∂t2 = ˆF[ξ] can be expanded in
terms of a complete set of normal modes ξ(n)(x) with eigenfrequencies ωn: ξ =
!
n Anξ(n)e−iωnt. Because ˆF is a real, self-adjoint operator, these normal modes can all
be chosen to be real and orthogonal, even when some of their frequencies are degen-
erate. As the perturbation evolves, its energy sloshes back and forth between kinetic
T and potential W, so time averages of T and W are equal: T = W. This implies, for
each normal mode,
ω2
n =
W[ξ(n)]

V dV 1
2ρξ(n)2 .
(19.57)
As the denominator is positive deﬁnite, we conclude that a magnetostatic equilibrium
energy principle (Rayleigh
principle) for stability
is stable against small perturbations if and only if the potential energy W[ξ]is a positive-
deﬁnite functional of the perturbation ξ.This is sometimes called the Rayleigh principle
for a general Sturm-Liouville problem. In the MHD context, it is known as the energy
principle.
action principle for
eigenfrequencies
It is straightforward to verify, by virtue of the self-adjointness of ˆF[ξ], that ex-
pression (19.57) serves as an action principle for the eigenfrequencies: If one inserts
into Eq. (19.57) a trial function ξtrial in place of ξ(n), then the resulting value of the
equation will be stationary under small variations of ξtrial if and only if ξtrial is equal to
980
Chapter 19. Magnetohydrodynamics

some eigenfunction ξ(n); and the stationary value of Eq. (19.57) is that eigenfunction’s
squared eigenfrequency ω2
n. This action principle is most useful for estimating the
lowest few squared frequencies ω2
n. Because ﬁrst-order differences between ξtrial and
ξ(n) produce second-order errors in ω2
n, relatively crude trial eigenfunctions can fur-
nish surprisingly accurate eigenvalues.
Whatever may be our chosen trial function ξtrial, the computed value of the action
(19.57) will always be larger than ω2
0, the squared eigenfrequency of the most unstable
mode. Therefore, if we compute a negative value of Eq. (19.57) using some trial
eigenfunction, we know that the equilibrium must be even more unstable.
The MHD energy principle and action principle are special cases of the general
conservation law and action principle for Sturm-Liouville differential equations (see,
e.g., Mathews and Walker, 1970; Arfken, Weber, and Harris, 2013; Hassani, 2013). For
further insights into the energy and action principles, see the original MHD paper by
Bernstein et al. (1958), in which these ideas were developed; also see Mikhailovskii
(1998), Goedbloed and Poedts (2004, Chap. 6), and Bellan (2006, Chap. 10).
EXERCISES
Exercise 19.16 Example: Reformulation of the Energy Principle;
Application to Z-Pinch
The form of the potential energy functional derived in the text [Eq. (19.47)] is optimal
for demonstrating that the operator ˆF is self-adjoint. However, there are several
simpler, equivalent forms that are more convenient for practical use.
(a) Use Eq. (19.46) to show that
ξ . ˆF[ξ]= j × b . ξ −b2/μ0 −γ P (∇. ξ)2 −(∇. ξ)(ξ . ∇)P
+ ∇. [(ξ × B) × b/μ0 + γ Pξ(∇. ξ) + ξ(ξ . ∇)P],
(19.58)
where b ≡δB is the Eulerian perturbation of the magnetic ﬁeld.
(b) Insert Eq. (19.58) into expression (19.56b) for the potential energy W[ξ] and
convert the volume integral of the divergence into a surface integral. Then impose
the boundary condition of a vanishing normal component of the magnetic ﬁeld
at ∂V [Eq. (19.20b)] to show that
W[ξ]= 1
2

V
dV

−j × b . ξ + b2/μ0 + γ P (∇. ξ)2 + (∇. ξ)(ξ . ∇)P

−1
2

∂V
d . ξ
"
γ P(∇. ξ) + ξ . ∇P −B . b/μ0
#
.
(19.59)
(c) Consider axisymmetric perturbations of the cylindrical Z-pinch of an incom-
pressible ﬂuid, as discussed in Sec. 19.5.2, and argue that the surface integral
vanishes.
(d) Adoptasimpletrialeigenfunction, andobtainavariationalestimateofthegrowth
rate of the sausage instability’s fastest growing mode.
19.5 Stability of Magnetostatic Equilibria
981

Exercise19.17 Problem: Potential Energy in Its Most Physically Interpretable Form
(a) Show that the potential energy (19.59) can be transformed into the following
form:
W[ξ]= 1
2

V
dV

−j × b . ξ + b2
μ0
+ δP ρ
ρ

+ 1
2

∂V
d . ∇
*
˜B2
2μ0
−P −B2
2μ0
+
ξ2
n + 1
2

vacuum
dV
˜b2
μ0
.
(19.60)
Here symbols without tildes represent quantities in the plasma region, and those
withtildesareinthevacuumregion; ξn isthecomponentoftheﬂuiddisplacement
orthogonal to the vacuum-plasma interface.
(b) Explain the physical interpretation of each term in the expression for the
potential energy in part (a). Notice that, although our original expression for
the potential energy, W = −1
2

V ξ . F[ξ]dV , entails an integral only over the
plasma region, it actually includes the vacuum region’s magnetic energy.
Exercise 19.18 Example: Virial Theorems
Additional mathematical tools that are useful in analyzing MHD equilibria and their
stability—and are also useful in astrophysics—are the virial theorems.In this exercise
and the next, you will deduce time-dependent and time-averaged virial theorems for
any system for which the law of momentum conservation can be written in the form
∂(ρvj)
∂t
+ Tjk;k = 0.
(19.61)
Here ρ is mass density, vj is the material’s velocity, ρvj is momentum density, and
Tjk is the stress tensor. We have met this formulation of momentum conservation
in elastodynamics [Eq. (12.2b)], in ﬂuid mechanics with self-gravity [Eq. (2) of Box
13.4], and in magnetohydrodynamics with self-gravity [Eq. (19.12)].
The virial theorems involve integrals over any region V for which there is no mass
ﬂux or momentum ﬂux across its boundary: ρvjnj = Tjknk = 0 everywhere on ∂V,
where nj is the normal to the boundary.6 For simplicity we use Cartesian coordinates,
so there are no connection coefﬁcients to worry about, and momentum conservation
becomes ∂(ρvj) + ∂Tjk/∂xk = 0.
(a) Show that mass conservation, ∂ρ/∂t + ∇. (ρv) = 0, implies that for any ﬁeld f
(scalar, vector, or tensor), we have
d
dt

V
ρf dV =

V
ρ df
dt dV .
(19.62)
6.
If self-gravity is included, then the boundary will have to be at spatial inﬁnity (i.e., no boundary), as
T grav
jk nk cannot vanish everywhere on a ﬁnite enclosing wall.
982
Chapter 19. Magnetohydrodynamics

(b) Use Eq. (19.62) to show that
d2Ijk
dt2 = 2

V
TjkdV ,
(19.63a)
where Ijk is the second moment of the mass distribution:
Ijk =

V
ρxjxkdV
(19.63b)
with xj the distance from a chosen origin. This is the time-dependent tensor
virial theorem. (Note that the system’s mass quadrupole moment is the trace-
free part of Ijk, Ijk = Ijk −1
3Igjk, and the system’s moment of inertia tensor
is Ijk = Ijk −Igjk, where I = Ijj is the trace of Ijk.)
(c) If the time integral of d2Ijk/dt2 vanishes, then the time-averaged stress tensor
satisﬁes

V
¯TjkdV = 0.
(19.64)
This is the time-averaged tensor virial theorem. Under what circumstances is this
theorem true?
Exercise 19.19 Example: Scalar Virial Theorems
(a) By taking the trace of the time-dependent tensorial virial theorem and specializ-
ing to an MHD plasma with (or without) self-gravity, show that
1
2
d2I
dt2 = 2Ekin + Emag + Egrav + 3EP ,
(19.65a)
where I is the trace of Ijk, Ekin is the system’s kinetic energy, Emag is its magnetic
energy, EP is the volume integral of its pressure, and Egrav is its gravitational
self-energy:
I =

V
ρx2dV ,
Ekin =

V
1
2ρv2dV ,
Emag =

B2
2μ0
,
EP =

V
P dV,
Egrav = 1
2

V
ρ = −

V
1
8πG(∇)2 = −1
2

V

V
Gρ(x)ρ(x′)
|x −x′| dV ′dV, (19.65b)
with  the gravitational potential energy [cf. Eq. (13.62)].
(b) When the time integral of d2I/dt2 vanishes, then the time average of the right-
hand side of Eq. (19.65a) vanishes:
2 ¯Ekin + ¯Emag + ¯Egrav + 3 ¯EP = 0.
(19.66)
This is the time-averaged scalar virial theorem.Give examples of circumstances in
which it holds.
19.5 Stability of Magnetostatic Equilibria
983

(c) Equation (19.66) is a continuum analog of the better-known scalar virial theorem,
2 ¯Ekin + ¯Egrav = 0, for a system consisting of particles that interact via their self-
gravity—for example, the solar system (see, e.g., Goldstein, Poole, and Safko,
2002, Sec. 3.4).
(d) As a simple but important application of the time-averaged scalar virial theorem,
show—neglecting self-gravity—that it is impossible for internal currents in a
plasma to produce a magnetic ﬁeld that conﬁnes the plasma to a ﬁnite volume:
external currents (e.g., in solenoids) are necessary.
(e) For applications to the oscillation and stability of self-gravitating systems, see
Chandrasekhar (1961, Sec. 118).
19.6
19.6 Dynamos and Reconnection of Magnetic Field Lines
As we have already remarked, the timescale for Earth’s magnetic ﬁeld to decay is
estimated to be roughly 1 million years. Since Earth is far older than that, some
process inside Earth must be regenerating the magnetic ﬁeld. This process is known
as a dynamo. Generally speaking, in a dynamo the motion of the ﬂuid stretches
dynamo
the magnetic ﬁeld lines, thereby increasing their magnetic energy density, which
compensates for the decrease in magnetic energy associated with Ohmic decay. The
details of how this happens inside Earth are not well understood. However, some
general principles of dynamo action have been formulated, and their application to
the Sun is somewhat better understood (Exs. 19.20 and 19.21).
19.6.1
19.6.1 Cowling’s Theorem
It is simple to demonstrate the impossibility of dynamo action in any time-
independent, axisymmetric ﬂow. Suppose that there were such a dynamo conﬁgura-
tion, and the time-independent, poloidal (meridional) ﬁeld had—for concreteness—
the form sketched in Fig. 19.12. Then there must be at least one neutral point marked
P (actually a circle about the symmetry axis), where the poloidal ﬁeld vanishes. How-
ever, the curl of the magnetic ﬁeld does not vanish at P, so a toroidal current jφ must
exist there. Now, in the presence of ﬁnite resistivity, there must also be a toroidal
electric ﬁeld at P, since
jφ = κe[Eφ + (vP × BP)φ]= κeEφ.
(19.67)
Here vP and BP are the poloidal components of v and B. The nonzero Eφ in turn
implies, via ∇× E = −∂B/∂t, that the amount of poloidal magnetic ﬂux threading
the circle at P must change with time, violating our original supposition that the
magnetic ﬁeld distribution is stationary.
Cowling’s theorem for
dynamos
We therefore conclude that any time-independent, self-perpetuating dynamo
must be more complicated than a purely axisymmetric magnetic ﬁeld. This result
is known as Cowling’s theorem.
984
Chapter 19. Magnetohydrodynamics

B
P
FIGURE 19.12 Impossibility of an axisymmetric dynamo.
19.6.2
19.6.2 Kinematic Dynamos
The simplest types of dynamo to consider are those in which we specify a particular
velocity ﬁeld and allow the magnetic ﬁeld to evolve according to the transport law
(19.6). Under certain circumstances, this can produce dynamo action. Note that we
do not consider in our discussion the dynamical effect of the magnetic ﬁeld on the
velocity ﬁeld.
dynamo cycle
The simplest type of motion is one in which a dynamo cycle occurs. In this cycle,
there is one mechanism for creating a toroidal magnetic ﬁeld from a poloidal ﬁeld
and a separate mechanism for regenerating the poloidal ﬁeld. The ﬁrst mechanism
is usually differential rotation. The second is plausibly magnetic buoyancy, in which
a toroidal magnetized loop is lighter than its surroundings and therefore rises in the
gravitational ﬁeld. As the loop rises, Coriolis forces twist the ﬂow, causing a poloidal
magnetic ﬁeld to appear, which completes the dynamo cycle.
dynamo action in
turbulence
Small-scale, turbulent velocity ﬁelds may also be responsible for dynamo action.
In this case, it can be shown on general symmetry grounds that the velocity ﬁeld
must contain hydrodynamic helicity—a nonzero mean value of v . ω [which is an
hydrodynamic helicity
obvious analog of magnetic helicity (Ex. 19.9), the volume integral or mean value
of A . B = A . (∇× A)].
If the magnetic ﬁeld strength grows, then its dynamical effect will eventually react
back on the ﬂow and modify the velocity ﬁeld. A full description of a dynamo must
include this back reaction. Dynamos are a prime target for numerical simulations of
MHD, and in recent years, signiﬁcant progress has been made using these simulations
to understand the terrestrial dynamo and other specialized problems.
EXERCISES
Exercise 19.20 Problem: Differential Rotation in the Solar Dynamo
This problem shows how differential rotation leads to the production of a toroidal
magnetic ﬁeld from a poloidal ﬁeld.
(a) Verify that for a ﬂuid undergoing differential rotation around a symmetry axis
with angular velocity (r, θ), the φ component of the induction equation reads
19.6 Dynamos and Reconnection of Magnetic Field Lines
985

∂Bφ
∂t
= sin θ

Bθ
∂
∂θ + Brr ∂
∂r

,
(19.68)
where θ is the co-latitude. (The resistive term can be ignored.)
(b) It is observed that the angular velocity on the solar surface is largest at the equa-
tor and decreases monotonically toward the poles. Analysis of solar oscillations
(Sec. 16.2.4) has shown that this variation (θ) continues inward through the
convection zone (cf. Sec. 18.5). Suppose that the ﬁeld of the Sun is roughly
poloidal. Sketch the appearance of the toroidal ﬁeld generated by the poloidal
ﬁeld.
Exercise 19.21 Problem: Buoyancy in the Solar Dynamo
Consider a slender ﬂux tube with width much less than its length which, in turn, is
much less than the external pressure scale height H. Also assume that the magnetic
ﬁeld is directed along the tube so there is negligible current along the tube.
(a) Show that the requirement of magnetostatic equilibrium implies that inside the
ﬂux tube
∇

P + B2
2μ0

≃0.
(19.69)
(b) Consider a segment of this ﬂux tube that is horizontal and has length ℓ. Holding
both ends ﬁxed, bend it vertically upward so that the radius of curvature of its
center line is R ≫ℓ. Assume that the ﬂuid is isentropic with adiabatic index γ .
By balancing magnetic tension against buoyancy, show that magnetostatic equi-
librium is possible if R ≃2γ H. Do you think this equilibrium could be stable?
(c) In the solar convection zone (cf. Sec. 18.5), small entropy differences are impor-
tant in driving the convective circulation. Following Ex. 19.20(b), suppose that
a length of toroidal ﬁeld is carried upward by a convecting “blob.” Consider the
action of the Coriolis force due to the Sun’s rotation (cf. Sec. 14.2.1) on a single
blob, and argue that it will rotate. What will this do to the magnetic ﬁeld? Sketch
the generation of a large-scale poloidal ﬁeld from a toroidal ﬁeld through the
combined effects of many blobs. What do you expect to observe when a ﬂux tube
breaks through the solar surface (known as the photosphere)?
The combined effect of differential rotation, magnetic stress, and buoyancy, as
outlined in Exs. 19.20 and 19.21, is thought to play an important role in sustaining
the solar dynamo cycle. See Goedbloed and Poedts (2004, Secs. 8.2, 8.3) for
further insights.
19.6.3
19.6.3 Magnetic Reconnection
So far, our discussion of the evolution of the magnetic ﬁeld has centered on the
induction equation (19.6) (the magnetic transport law). We have characterized the
986
Chapter 19. Magnetohydrodynamics

B
v
v
FIGURE 19.13 Magnetic reconnection. In the shaded reconnection region,
Ohmic diffusion is important and allows magnetic ﬁeld lines to
“exchange partners,” changing the overall ﬁeld topology. Magnetic
ﬁeld components perpendicular to the plane of the illustration do not
develop large gradients and so do not inhibit the reconnection process.
magnetized ﬂuid by a magnetic Reynolds number using some characteristic length L
associated with the ﬂow, and have found that, when RM ≫1, Ohmic dissipation and
ﬁeld-line diffusion in the transport law are unimportant. This is reminiscent of the
procedurewefollowedwhendiscussingvorticity.However, forvorticitywediscovered
a very important exception to an uncritical neglect of viscosity, dissipation, and
vortex-line diffusion at large Reynolds numbers, namely, boundary layers (Sec. 14.4).
In particular, we found that large-Reynolds-number ﬂows near solid surfaces develop
large velocity gradients on account of the no-slip boundary condition, and that the
local Reynolds number can thereby decrease to near unity, allowing viscous stress
to change the character of the ﬂow completely. Something similar, called magnetic
reconnection, can happen in hydromagnetic ﬂows with large RM, even without the
presence of solid surfaces.
how magnetic
reconnection occurs
at high RM
RM
RM
Consider two oppositely magnetized regions of conducting ﬂuid moving toward
each other (the upper and lower regions in Fig. 19.13). Mutual magnetic attraction
of the two regions occurs, as magnetic energy would be reduced if the two sets of
ﬁeld lines were superposed. However, strict ﬂux freezing prevents superposition.
Something has to give! What happens is a compromise. The attraction causes large
magnetic gradients to develop, accompanied by a buildup of large current densities,
until Ohmic diffusion ultimately allows the magnetic ﬁeld lines to slip sideways
throughtheﬂuidandtoreconnect withtheﬁeldintheotherregion(thesharplycurved
ﬁeld lines in Fig. 19.13).
This reconnection mechanism can be clearly observed at work in tokamaks and
in Earth’s magnetopause, where the solar wind’s magnetic ﬁeld meets Earth’s mag-
netosphere. However, the details of the reconnection mechanism are quite complex,
involving plasma instabilities, anisotropic electrical conductivity, and shock fronts.
19.6 Dynamos and Reconnection of Magnetic Field Lines
987

Large, inductive electric ﬁelds can also develop when the magnetic geometry un-
dergoes rapid change. This can happen in the reversing magnetic ﬁeld in Earth’s
magnetotail,7 leading to the acceleration of charged particles that impact Earth during
a magnetic substorm.Like dynamo action, reconnection has a major role in determin-
ing how magnetic ﬁelds actually behave in both laboratory and space plasmas.
For further detail on the physics and observations of reconnection, see, for exam-
ple, Birn and Priest (2007) and Forbes and Priest (2007).
19.7
19.7 Magnetosonic Waves and the Scattering of Cosmic Rays
In Sec. 19.5, we discussed global perturbations of a nonuniform magnetostatic plasma
and described how they may be unstable. We now consider a different, particularly
simple example of dynamical perturbations: planar, monochromatic, propagating
waves in a uniform, magnetized, conducting medium. These are called magnetosonic
magnetosonic waves
waves.They can be thought of as sound waves that are driven not just by gas pressure
but also by magnetic pressure and tension.
Although magnetosonic waves have been studied experimentally under labora-
tory conditions, there the magnetic Reynolds numbers are generally quite small, so
the waves damp quickly by Ohmic dissipation. No such problem arises in space plas-
mas, where magnetosonic waves are routinely studied by the many spacecraft that
monitor the solar wind and its interaction with planetary magnetospheres. It appears
that these modes perform an important function in space plasmas: they control the
transport of cosmic rays. Let us describe some properties of cosmic rays before giving
a formal derivation of the magnetosonic-wave dispersion relation.
19.7.1
19.7.1 Cosmic Rays
Cosmic rays are the high-energy particles, primarily protons, that bombard Earth’s
magnetosphere from outer space. They range in energy from ∼1MeV to ∼3 ×
cosmic-ray spectrum
1011 GeV = 0.3 ZeV ∼50 J.(Thehighestcosmic-rayenergyevermeasuredwas∼50 J.
Thus, naturally occurring particle accelerators are far more impressive than their ter-
restrial counterparts, which can only reach ∼10 TeV = 104 GeV!) Most subrelativistic
particles originate in the solar system. Their relativistic counterparts, up to energies
∼100 TeV, are believed to come mostly from interstellar space, where they are accel-
erated by expanding shock waves created by supernova explosions (cf. Sec. 17.6.3).
The origin of the highest energy particles, greater than ∼100 TeV, is an intriguing
mystery.
The distribution of cosmic-ray arrival directions at Earth is inferred to be quite
isotropic (to better than 1 part in 104 at an energy of 10 GeV). This is somewhat sur-
isotropy
prising, because their sources, both in and beyond the solar system, are believed to be
distributed anisotropically, so the isotropy needs to be explained. Part of the reason
for the isotropy is that the interplanetary and interstellar media are magnetized, and
7.
The magnetotail is the region containing trailing ﬁeld lines on the night side of Earth.
988
Chapter 19. Magnetohydrodynamics

the particles gyrate around the magnetic ﬁeld with the gyro (relativistic cyclotron)
frequency ωG = eBc2/E, where E is the (relativistic) particle energy including rest
mass, and B is the magnetic ﬁeld strength. The gyro (Larmor) radii of the non-
relativistic particle orbits are typically small compared to the size of the solar system,
and those of the relativistic particles are typically small compared to characteristic
lengthscales in the interstellar medium. Therefore, this gyrational motion can effec-
tively erase any azimuthal asymmetry around the ﬁeld direction. However, this does
evidence for scattering
not stop the particles from streaming away from their sources along the magnetic
ﬁeld, thereby producing anisotropy at Earth. So something else must be impeding
this along-line ﬂow, by scattering the particles and causing them to effectively diffuse
along and across the ﬁeld through interplanetary and interstellar space.
AsweverifyinSec.20.4, Coulombcollisionsarequiteineffective(eveniftheywere
effective, they would cause huge cosmic-ray energy losses, in violation of observa-
tions). We therefore seek some means of changing a cosmic ray’s momentum without
altering its energy signiﬁcantly. This is reminiscent of the scattering of electrons in
metals, where it is phonons (elastic waves in the crystal lattice) that are responsible
for much of the scattering. It turns out that in the interstellar medium, magnetosonic
waves can play a role analogous to phonons and can scatter the cosmic rays. As an aid
to understanding this phenomenon, we now derive the waves’ dispersion relation.
19.7.2
19.7.2 Magnetosonic Dispersion Relation
Ourprocedureforderivingthedispersionrelation(lastparagraphofSec.7.2.1)should
be familiar by now. We consider a uniform, isentropic, magnetized ﬂuid at rest; we
perform a linear perturbation and seek monochromatic plane-wave solutions varying
as ei(k.x−ωt). We ignore gravity and dissipative processes (speciﬁcally, viscosity, ther-
mal conductivity, and electrical resistivity), as well as gradients in the equilibrium,
which can all be important in some circumstances.
It is convenient to use the velocity perturbation δv as the independent variable.
The perturbed and linearized equation of motion (19.10) then takes the form
−iρωδv = −iC2kδρ + (ik × δB) × B
μ0
.
(19.70)
Here C is the sound speed [C2 = (∂P/∂ρ)s = γ P/ρ, not to be confused with the
speed of light c], and δP = C2δρ is the Eulerian pressure perturbation for our ho-
mogeneous equilibrium.8 (Note that ∇P = ∇ρ = 0, so Eulerian and Lagrangian per-
turbations are the same.) The perturbed equation of mass conservation, ∂ρ/∂t + ∇.
(ρv) = 0, becomes
ωδρ = ρk . δv,
(19.71)
8.
Note that we are assuming that (i) the equilibrium pressure tensor is isotropic and (ii) the perturbations
to the pressure are also isotropic. This is unlikely to be the case for a collisionless plasma, so our treatment
there must be modiﬁed. See Sec. 20.6.2 and Ex. 21.1.
19.7 Magnetosonic Waves and the Scattering of Cosmic Rays
989

and the MHD law of magnetic-ﬁeld transport with dissipation ignored, ∂B/∂t =
∇× (v × B), becomes
ωδB = −k × (δv × B).
(19.72)
We introduce the Alfv´en velocity
Alfv´en velocity
a ≡
B
(μ0ρ)1/2 ,
(19.73)
and insert δρ [Eq. (19.71)] and δB [Eq. (19.72)] into Eq. (19.70) to obtain
eigenequation for
magnetosonic waves
{k × [k × (δv × a)]} × a + C2(k . δv)k = ω2δv.
(19.74)
Equation (19.74) is an eigenequation for the wave’s squared frequency ω2 and
eigendirection δv. The straightforward way to solve it is to rewrite it in the standard
matrix form Mijδvj = ω2δvi and then use standard matrix (determinant) methods.
It is quicker, however, to seek the three eigendirections δv and eigenfrequencies ω one
by one, by projection along preferred directions.
Alfv´en mode and its
dispersion relation
We ﬁrst seek a solution to Eq. (19.74) for which δv is orthogonal to the plane
formed by the unperturbed magnetic ﬁeld and the wave vector, δv = a × k up to a
multiplicative constant. Inserting this δv into Eq. (19.74), we obtain the dispersion
relation
ω = ±a . k;
ω
k = ±a cos θ,
(19.75)
where θ is the angle between k and the unperturbed ﬁeld, and a ≡|a| = B/(μoρ)1/2
is the Alfv´en speed. This type of wave is known as the intermediate magnetosonic
mode and also as the Alfv´en mode. Its phase speed ω/k = a cos θ is plotted as the
larger ﬁgure-8 curve in Fig. 19.14. The velocity and magnetic perturbations δv and
Alfv´en-mode properties
δB are both along the direction a × k, so the Alfv´en wave is fully transverse. There
is no compression (δρ = 0), which accounts for the absence of the sound speed C in
the dispersion relation. This Alfv´en mode has a simple physical interpretation in the
limiting case when k is parallel to B. We can think of the magnetic ﬁeld lines as strings
with tension B2/μ0 and inertia ρ, which are plucked transversely. Their transverse
oscillations then propagate with speed √tension/inertia = B/√μ0ρ = a. For details
and delicacies, see Ex. 21.8.
The dispersion relations for the other two modes can be deduced by projecting the
eigenequation (19.74) successively along k and along a to obtain two scalar equations:
k2(k . a)(a . δv) = [(a2 + C2)k2 −ω2](k . δv),
C2(k . a)(k . δv) = ω2(a . δv).
(19.76)
990
Chapter 19. Magnetohydrodynamics

B
f
f
ω/k
θ
i
i
s
s
FIGURE 19.14 Phase-velocity surfaces for the three types of
magnetosonic modes: fast (f), intermediate (i), and slow (s).
The three curves are polar plots of the wave phase velocity
ω/k in units of the Alfv´en speed a = B/√μ0ρ. In the
particular example shown, the sound speed C is half the
Alfv´en speed.
Combining these equations, we obtain the dispersion relation
dispersion relation for
fast (+++) and slow (−−−)
magnetosonic modes
ω
k
2
= 1
2(a2 + C2)
'
1 ±

1 −4C2a2 cos2 θ
(a2 + C2)2
1/2(
.
(19.77)
(By inserting this dispersion relation, with the upper or lower sign, back into Eqs.
(19.76), we can deduce the mode’s eigendirection δv.) This dispersion relation tells us
that ω2 is positive, so no unstable modes exist, which seems reasonable, as there is no
source of free energy. (The same is true, of course, for the Alfv´en mode.)
These waves are compressive, with the gas being moved by a combination of
gas pressure and magnetic pressure and tension. The modes can be seen to be non-
dispersive, which is also to be expected, as we have introduced neither a characteristic
timescale nor a characteristic length into the problem.
fast magnetosonic-mode
properties
The mode with the plus signs in Eq. (19.77) is called the fast magnetosonic mode;
its phase speed is depicted by the outer, quasi-circular curve in Fig. 19.14. A good
approximation to its phase speed when a ≫C or a ≪C is ω/k ≃±(a2 + C2)1/2.
When propagating perpendicularly to B, the fast mode can be regarded as simply
a longitudinal sound wave in which the gas pressure is augmented by the magnetic
pressure B2/(2μ0) (adopting a speciﬁc-heat ratio γ for the magnetic ﬁeld of 2, as
B ∝ρ and so Pmag ∝ρ2 under perpendicular compression).
slow magnetosonic-mode
properties
The mode with the minus signs in Eq. (19.77) is called the slow magnetosonic
mode. Its phase speed (depicted by the inner ﬁgure-8 curve in Fig. 19.14) can be
approximated by ω/k = ±aC cos θ/(a2 + C2)1/2 when a ≫C or a ≪C. Note that
19.7 Magnetosonic Waves and the Scattering of Cosmic Rays
991

slow mode—like the intermediate mode but unlike the fast mode—is incapable of
propagating perpendicularly to the unperturbed magnetic ﬁeld; see Fig. 19.14. In the
limit of vanishing Alfv´en speed or vanishing sound speed, the slow mode ceases to
exist for all directions of propagation.
In Chap. 21, we will discover that MHD is a good approximation to the behavior
of plasmas only at frequencies below the “ion cyclotron frequency,” which is a rather
low frequency. For this reason, magnetosonic modes are usually regarded as low-
frequency modes.
19.7.3
19.7.3 Scattering of Cosmic Rays by Alfv´en Waves
mechanism for Alfv´en
waves to scatter cosmic-
ray particles
Now let us return to the issue of cosmic-ray propagation, which motivated our in-
vestigation of magnetosonic modes. Let us consider 100-GeV particles in the inter-
stellar medium. The electron (and ion, mostly proton) density and magnetic ﬁeld
strength are typically n ∼−3 × 104 m−3 and B ∼300 pT. The Alfv´en speed is then
a ∼30 km s−1, much slower than the speeds of the cosmic rays. When analyzing
cosmic-ray propagation, a magnetosonic wave can therefore be treated as essen-
tially a magnetostatic perturbation. A relativistic cosmic ray of energy E has a gyro
(relativistic Larmor) radius of rG = E/eBc, in this case ∼3 × 1012 m. Cosmic rays
will be unaffected by waves with wavelength either much greater than or much less
than rG. However, magnetosonic waves (especially Alfv´en waves, which are respon-
sible for most of the scattering), with wavelength matched to the gyro radius, will
be able to change the particle’s pitch angle α (the angle its momentum makes with
the mean magnetic ﬁeld direction). See Sec. 23.4.1 for some details. If the Alfv´en
waves in this wavelength range have rms dimensionless amplitude δB/B ≪1, then
the particle’s pitch angle will change by an amount δα ∼δB/B for every wavelength.
Now, if the wave spectrum is broadband, individual waves can be treated as un-
correlated, so the particle pitch angle changes stochastically. In other words, the par-
ticle diffuses in pitch angle. The effective diffusion coefﬁcient is
Dα ∼
δB
B
2
ωG,
(19.78)
whereωG = c/rG isthegyrofrequency(relativisticanalogofcyclotronfrequencyωc).
The particle is therefore scattered by roughly a radian in pitch angle every time it
traverses a distance ℓ∼(B/δB)2rG. This is effectively the particle’s collisional mean
free path. Associated with this mean free path is a spatial diffusion coefﬁcient
Dx ∼ℓc
3 .
(19.79)
It is thought that δB/B ∼10−1 in the relevant wavelength range in the inter-
estimated and measured
cosmic-ray anisotropy
stellar medium. An estimate of the collision mean free path is then ℓ(100 GeV) ∼
1014 m. Now, the thickness of our galaxy’s interstellar disk of gas is roughly
L ∼3 × 1018 m ∼104ℓ. Therefore, an estimate of the cosmic-ray anisotropy is
992
Chapter 19. Magnetohydrodynamics

∼ℓ/L ∼3 × 10−5, roughly compatible with the measurements. Although this dis-
cussion is an oversimpliﬁcation, it does demonstrate that the cosmic rays in the
interplanetary, interstellar, andintergalacticmediacanbescatteredefﬁcientlybymag-
netosonic waves. This allows the particle transport to be impeded without much loss
of energy, so that the theory of cosmic-ray acceleration (Ex. 23.12) and scattering (this
section) together can account for the particle ﬂuxes observed as a function of energy
and direction at Earth.
A good question to ask at this point is “Where do the Alfv´en waves come from?”
The answer turns out to be that they are maintained as part of a turbulence spectrum
and created by the cosmic rays themselves through the growth of plasma instabilities.
To proceed further and give a more quantitative description of this interaction, we
must go beyond a purely ﬂuid description and explore the motions of individual
particles. This is where we shall turn in the next few chapters, culminating with a
return to the interaction of cosmic rays with Alfv´en waves in Sec. 23.4.1.
Bibliographic Note
For intuitive insight into magnetohydrodynamics, we recommend Shercliff (1965).
For textbook introductions to magnetohydrodynamics, we recommend the rel-
evant chapters of Landau, Pitaevskii, and Lifshitz (1979), Schmidt (1979), Boyd and
Sanderson (2003), and Bellan (2006). For far greater detail, we recommend a textbook
that deals solely with magnetohydrodynamics: Goedbloed and Poedts (2004) and its
advanced supplement Goedbloed, Keppens, and Poedts (2010). For a very readable
treatment from the viewpoint of an engineer, with applications to engineering and
metallurgy, see Davidson (2001).
For the theory of MHD instabilities and applications to magnetic conﬁnement, see
theabovereferences, andalsoBateman(1978)andthecollectionofearlypapersedited
by Jeffrey and Taniuti (1966). For applications to astrophysics and space physics, see
Parker (1979), Parks (2004), and Kulsrud (2005).
Bibliographic Note
993


VI
PART VI
PLASMA PHYSICS
A plasma is a gas that is signiﬁcantly ionized (through heating or photoionization)
and thus is composed of electrons and ions, and that has a low enough density to
behave classically (i.e., to obey Maxwell-Boltzmann statistics rather than Fermi-Dirac
or Bose-Einstein). Plasma physics originated in the nineteenth century, with the study
of gas discharges (Crookes, 1879). In 1902, Heaviside and Kennelly realized that
plasma is also the key to understanding the propagation of radio waves across the
Atlantic. The subject received a further boost in the early 1950s, with the start of
the controlled (and the uncontrolled) thermonuclear fusion program. The various
conﬁnement devices described in the preceding chapter are intended to hold plasma
at temperatures as high as ∼108 K, high enough for fusion to begin; the difﬁculty
of this task has turned out to be an issue of plasma physics as much as of MHD.
The next new venue for plasma research was extraterrestrial. Although it was already
understoodthatEarthwasimmersedinatenuousoutﬂowofionizedhydrogenknown
as the solar wind, the dawn of the space age in 1957 also initiated experimental space
plasma physics.More recently, the interstellar and intergalactic media beyond the solar
system as well as exotic astronomical objects like quasars and pulsars have allowed us
to observe plasmas under quite extreme conditions, irreproducible in any laboratory
experiment.
The dynamical behavior of a plasma is more complex than the dynamics of the
gases and ﬂuids we have met so far. This dynamical complexity has two main origins:
1. The dominant form of interparticle interaction in a plasma, Coulomb scat-
tering, is so weak that the mean free paths of the electrons and ions are often
larger than the plasma’s macroscopic lengthscales. This allows the particles’
momentum distribution functions to deviate seriously from their equilib-
rium Maxwellian forms and, in particular, to be highly anisotropic.
2. The electromagnetic ﬁelds in a plasma are of long range. This allows charged
particles to couple to one another electromagnetically and act in concert as
modesofexcitation(plasmawaves)thatbehavelikesingledynamicalentities
995

(plasmons). Much of plasma physics consists of the study of the properties
and interactions of these modes.
The dynamical behavior of a plasma depends markedly on frequency. At the low-
est frequencies, the ions and electrons are locked together by electrostatic forces and
behave like an electrically conducting ﬂuid; this is the regime of MHD (Chap. 19). At
somewhat higher frequencies, the electrons and the ions can move relative to each
other, behaving like two separate, interpenetrating ﬂuids; we study this two-ﬂuid
regime in Chap. 21. At still higher frequencies, complex dynamics are supported by
momentum space anisotropies and can be analyzed using a variant of the kinetic-
theory collisionless Boltzmann equation that we introduced in Chap. 3. We study
such dynamics in Chap. 22. In the two-ﬂuid and collisionless-Boltzmann analyses of
Chaps. 21 and 22, we focus on phenomena that can be treated as linear perturbations
of an equilibrium state. However, the complexities and long mean free paths of plas-
mas also produce rich nonlinear phenomena; we study some of these in Chap. 23. But
ﬁrst, as a foundation for the dynamical studies in Chaps. 21, 22, and 23, we develop
in Chap. 20 detailed insights into the microscopic structure of a plasma.
996
Part VI

20
CHAPTER TWENTY
The Particle Kinetics of Plasma
The study of individual particles frequently gives insight
into the behavior of an ionized gas.
LYMAN SPITZER (1962)
20.1
20.1 Overview
The preceding chapter, Chap. 19, can be regarded as a transition from ﬂuid mechanics
to plasma physics. In the context of a magnetized plasma, it describes equilibrium
and low-frequency dynamical phenomena using ﬂuid-mechanics techniques. In this
chapter, we prepare for more sophisticated descriptions of a plasma by introducing
a number of elementary foundational concepts peculiar to plasmas and by exploring
a plasma’s structure on the scale of individual particles using elementary techniques
from kinetic theory.
Speciﬁcally, in Sec. 20.2, we identify the region of densities and temperatures in
which matter, in statistical equilibrium, takes the form of a plasma, and we meet
speciﬁc examples of plasmas that occur in Nature and in the laboratory. Then in
Sec. 20.3, we study two phenomena that are important for plasmas: the collective
manner in which large numbers of electrons and ions shield out the electric ﬁeld of
a charge in a plasma (Debye shielding), and the oscillations of a plasma’s electrons
relative to its ions (plasma oscillations).
In Sec. 20.4, we study the Coulomb scattering by which a plasma’s electrons
and ions deﬂect an individual charged particle from straight-line motion and ex-
change energy with it. We then examine the statistical properties of large numbers
of such Coulomb scatterings—most importantly, the rates (inverse timescales) for
the velocities of a plasma’s electrons and ions to isotropize, and the rates for them
to thermalize. Our calculations reveal that Coulomb scattering is so weak that, in
most plasmas encountered in Nature, it is unlikely to produce isotropized or ther-
malized velocity distributions. In Sec. 20.5, we give a brief preview of the fact that
in real plasmas the scattering of electrons and ions off collective plasma excitations
(plasmons) often isotropizes and thermalizes their velocities far faster than would
Coulomb scattering. Thus many real plasmas are far more isotropic and thermal-
ized than our Coulomb-scattering analyses suggest. (We explore this “anomalous”
behavior in Chaps. 22 and 23.) In Sec. 20.5, we also use the statistical properties
997

BOX 20.1.
READERS’ GUIDE
.
This chapter relies signiﬁcantly on portions of nonrelativistic kinetic
theory as developed in Chap. 3.
.
It also relies a bit (but not greatly) on portions of MHD as developed
in Chap. 19.
.
Chapters 21–23 of Part VI rely heavily on this chapter.
of Coulomb scatterings to derive a plasma’s transport coefﬁcients—speciﬁcally, its
electrical and thermal conductivities—for situations where Coulomb scattering dom-
inates over particle-plasmon scattering.
Most plasmas are signiﬁcantly magnetized. This introduces important new fea-
tures into their dynamics, which we describe in Sec. 20.6: cyclotron motion (the spi-
raling of particles around magnetic ﬁeld lines), a resulting anisotropy of the plasma’s
pressure (different pressures along and orthogonal to the ﬁeld lines), and the split of
a plasma’s adiabatic index into four different adiabatic indices for four different types
of compression. Finally, in Sec. 20.7, we examine the motion of an individual charged
particle in a slightly inhomogeneous and slowly time-varying magnetic ﬁeld, and we
describe adiabatic invariants, which control that motion in easily understood ways.
20.2
20.2 Examples of Plasmas and Their Density-Temperature Regimes
The density-temperature regime in which matter behaves as a nonrelativistic plasma
is shown in Fig. 20.1. In this ﬁgure, and in most of Part VI, we conﬁne our attention to
pure hydrogen plasma comprising protons and electrons. Many plasmas contain large
fractions of other ions, which can have larger charges and do have greater masses than
protons. This generalization introduces few new issues of principle so, for simplicity,
we eschew it and focus on a hydrogen plasma.
The boundaries of the plasma regime in Fig. 20.1 are dictated by the following
considerations.
20.2.1
20.2.1 Ionization Boundary
We are mostly concerned with fully ionized plasmas, even though partially ionized
plasmas, such as the ionosphere, are often encountered in physics, astronomy, and en-
gineering, and more complex plasmas (such as dusty plasmas) can also be important.
The plasma regime’s ionization boundary is the bottom curve in Fig. 20.1, at a temper-
ionization boundary
ature of a few thousand Kelvins. This boundary is dictated by chemical equilibrium
for the reaction
H ↔p + e,
(20.1)
998
Chapter 20. The Particle Kinetics of Plasma

10
8
6
4
2
3
1
–1
–3
–5
–27
–22
–17
–12
–7
–2
3
8
0
2
4
6
8
10
12
14
16
18
20
5
10
15
20
25
30
35
relativistic
intergalactic medium
interstellar medium
solar wind
magneto-
 sphere
log T (K)
log kBT (keV)
log n (m–3)
log ωp (s–1)
log ρ (kg m–3)
nonrelativistic
independent
particles
pairs
ionized
neutral
nonrelativistic
plasma
nondegenerate
degenerate
collective behavior
nondegenerate
degenerate
ionosphere
fusion
expmnts
sun
core
gas
discharge
FIGURE 20.1 The density-temperature regime in which matter, made largely of hydrogen, behaves as a
nonrelativistic plasma. The densities and temperatures of speciﬁc examples of plasmas are indicated
by dashed lines. The number density n of electrons (and also of protons) is shown horizontally at the
bottom, and the corresponding mass density ρ is shown at the top. The temperature T is shown at
the left in Kelvins, and at the right kBT is shown in keV, thousands of electron volts. The bottom-
most scale is the plasma frequency, discussed in Sec. 20.3.3. This ﬁgure is a more detailed version of
Fig. 3.7.
as described by the Saha equation (Ex. 5.10):
nenp
nH
= (2πmekBT )3/2
h3
e−IP /(kBT ).
(20.2)
Here ne, np, and nH are the number densities of electrons, protons, and neutral hy-
drogen atoms (at the relevant temperatures hydrogen molecules have dissociated into
individual atoms), respectively; T is temperature; me is the electron rest mass; h
is Planck’s constant; kB is Boltzmann’s constant; and IP = 13.6 eV is the ionization
20.2 Examples of Plasmas and Their Density-Temperature Regimes
999

energy of hydrogen (i.e., the binding energy of its ground state). Notice that the
prefactor in Eq. (20.2) is λ−3
T dB with λT dB ≡h/

2πmekBT , the electrons’ thermal de
Broglie wavelength. The bottom boundary in Fig. 20.1 is that of 50% ionization [i.e.,
ne = np = nH = ρ/(2mH), with mH the mass of a hydrogen atom]; but because of the
exponential factor in Eq. (20.2), the line of 90% ionization is virtually indistinguish-
able from that of 50% ionization on the scale of the ﬁgure. Using the rough equivalence
1 eV ∼= 104 K, wemighthaveexpectedthattheionizationboundarywouldcorrespond
to a temperature T ∼IP/kB ∼105 K. However, this is true only near the degeneracy
boundary (see below). When the plasma is strongly nondegenerate, ionization occurs
at a signiﬁcantly lower temperature due to the vastly greater number of states avail-
able to an electron when free than when bound in a hydrogen atom. Equivalently,
at low densities, once a hydrogen atom has been broken up into an electron plus a
proton, the electron (or proton) must travel a large distance before encountering an-
other proton (or electron) with which to recombine, making a new hydrogen atom;
as a result, equilibrium occurs at a lowered temperature, where the ionization rate is
thereby lowered to match the smaller recombination rate.
20.2.2
20.2.2 Degeneracy Boundary
The electrons, with their small rest masses, become degenerate more easily than
degeneracy boundary
the protons or hydrogen atoms. The slanting line on the right side of Fig. 20.1 is
the plasma’s boundary of electron degeneracy. This boundary is determined by the
demand that the mean occupation number of the electrons’ single-particle quantum
statesnotbe≪1.Inotherwords, thevolumeofphasespaceperelectron—theproduct
of the volumes of real space ∼n−1
e
and of momentum space ∼(mekBT )3/2 occupied
by each electron—should be comparable with the elementary quantum mechanical
phase-space volume given by the uncertainty principle, h3. Inserting the appropriate
factors of order unity [cf. Eq. (3.41)], this relation becomes the boundary equation:
ne ≃2(2πmekBT )3/2
h3
.
(20.3)
When the electrons become degenerate (rightward of the degeneracy line in
Fig.20.1), astheydoinametalorawhitedwarf, theelectrondeBrogliewavelengthbe-
comes large compared with the mean interparticle spacing, and quantum mechanical
considerations are of paramount importance.
20.2.3
20.2.3 Relativistic Boundary
Another important limit arises when the electron thermal speeds become relativistic.
relativistic boundary
This occurs when
T ∼mec2/kB ∼6 × 109 K
(20.4)
(top horizontal line in Fig. 20.1). Although we shall not consider them much further,
the properties of relativistic plasmas (above this line) are mostly analogous to those
of nonrelativistic plasmas (below it).
1000
Chapter 20. The Particle Kinetics of Plasma

20.2.4
20.2.4 Pair-Production Boundary
Finally, for plasmas in statistical equilibrium, electron-positron pairs are created in
profusion at high enough temperatures. In Ex. 5.9 we showed that, for kBT ≪mec2
but T high enough that pairs begin to form, the density of positrons divided by that
of protons is
n+
np
=
1
2y[y + (1 + y2)1/2] ,
where y ≡1
4ne
*
h

2πmekBT
+3
emec2/(kBT ).
(20.5)
Setting this expression to unity gives the pair-production boundary. This boundary
pair-production boundary
curve, labeled “pairs” in Fig. 20.1, is similar in shape to the ionization boundary but
shifted in temperature by ∼2 × 104 ∼α−2
F , where αF is the ﬁne structure constant.
This is because we are now effectively “ionizing the vacuum” rather than a hydrogen
atom, and the “ionization potential of the vacuum” is ∼2mec2 = 4IP/α2
F.
We shall encounter a plasma above the pair-production boundary, and thus with
a profusion of electron-positron pairs, in our discussion of the early universe in
Secs. 28.4.1 and 28.4.2.
20.2.5
20.2.5 Examples of Natural and Human-Made Plasmas
Figure 20.1 and Table 20.1 show the temperature-density regions for the following
plasmas:
.
Laboratory gas discharge. The plasmas created in the laboratory by electric
currents ﬂowing through hot gas (e.g., in vacuum tubes, spark gaps, welding
arcs, and neon and ﬂuorescent lights).
.
Controlled thermonuclear fusion experiments. The plasmas in which ex-
periments for controlled thermonuclear fusion are carried out (e.g., in
tokamaks).
.
Ionosphere.The part of Earth’s upper atmosphere (at heights of ∼50–300 km)
that is partially photoionized by solar ultraviolet radiation.
.
Magnetosphere.The plasma of high-speed electrons and ions that are locked
on Earth’s dipolar magnetic ﬁeld and slide around on its ﬁeld lines at several
Earth radii.
.
Sun’s core. The plasma at the center of the Sun, where fusion of hydrogen to
form helium generates the Sun’s heat.
.
Solar wind.The wind of plasma that blows off the Sun and outward through
the region between the planets.
.
Interstellar medium. The plasma, in our galaxy, that ﬁlls the region between
the stars. This plasma exhibits a fairly wide range of density and tempera-
ture as a result of such processes as heating by photons from stars, heating
and compression by shock waves from supernovae, and cooling by thermal
emission of radiation.
20.2 Examples of Plasmas and Their Density-Temperature Regimes
1001

TABLE 20.1: Representative electron number densities n, temperatures T , and magnetic ﬁeld
strengths B, together with derived plasma parameters in a variety of environments
n
T
B
λD
ωp
νee
ωc
rL
Plasma
(m−3)
(K)
(T)
(m)
ND
(s−1)
(s−1)
(s−1)
(m)
Gas discharge
1016
104
—
10−4
104
1010
105
—
—
Fusion experiments
1020
108
10
10−4
108
1012
104
1012
10−5
Ionosphere
1012
103
10−5
10−3
105
108
103
106
10−1
Magnetosphere
107
107
10−8
102
1010
105
10−8
103
104
Sun’s core
1032
107
—
10−11
1
1018
1016
—
—
Solar wind
106
105
10−9
10
1011
105
10−6
102
104
Interstellar medium
105
104
10−10
10
1010
104
10−5
10
104
Intergalactic medium
10−1
106
—
105
1015
102
10−12
—
—
Notes: The derived parameters, discussed later in this chapter, are: λD, Debye length; ND, Debye number;
ωp, plasma frequency; νee, equilibration rate for electron energy; ωc, electron cyclotron frequency; and
rL, electron Larmor radius. Values are given to order of magnitude, as all of these environments are quite
inhomogeneous. — indicates this quantity is irrelevant.
.
Intergalactic medium. The plasma that ﬁlls the space outside galaxies and
clusters of galaxies (the locale of almost all the universe’s plasma). We shall
meet the properties and evolution of this intergalactic plasma in our study
of cosmology, Sec. 28.3.1.
Characteristic plasma properties in these various environments are collected
in Table 20.1. In the next three chapters we study applications from all these
environments.
EXERCISES
Exercise 20.1 Derivation: Boundary of Degeneracy
Show that the condition ne ≪(2πmekBT )3/2/h3 [cf. Eq. (20.3)] that electrons be
nondegenerate is equivalent to the following statements.
(a) The mean separation between electrons, l ≡n−1/3
e
, is large compared to the
electrons’ thermal de Broglie wavelength, λT dB = h/

2πmekBT .
(b) The uncertainty in the location of an electron drawn at random from the thermal
distribution is small compared to the average inter-electron spacing.
(c) The quantum mechanical zero-point energy associated with squeezing each elec-
tron into a region of size l = n−1/3
e
is small compared to the electron’s mean
thermal energy kBT .
1002
Chapter 20. The Particle Kinetics of Plasma

20.3
20.3 Collective Effects in Plasmas—Debye Shielding and Plasma Oscillations
In this section, we introduce two key ideas that are associated with most of the
collective effects in plasma dynamics: Debye shielding (also called Debye screening)
and plasma oscillations.
20.3.1
20.3.1 Debye Shielding
Any charged particle inside a plasma attracts other particles with opposite charge and
mechanism of Debye
shielding
repels those with the same charge, thereby creating a net cloud of opposite charges
around itself. This cloud shields the particle’s own charge from external view (i.e., it
causes the particle’s Coulomb ﬁeld to fall off exponentially at large radii, rather than
falling off as 1/r2).1
This Debye shielding (or screening) of a particle’s charge can be demonstrated and
quantiﬁed as follows. Consider a single ﬁxed test charge Q surrounded by a plasma
of protons and electrons. Denote the average densities of protons and electrons—
considered as smooth functions of radius r from the test charge—by np(r) and ne(r),
and let the mean densities of electrons and protons (averaged over a large volume)
be ¯n. (The mean electron and proton densities must be equal because of overall
charge neutrality, which is enforced by the electrostatic restoring force that we explore
in Sec. 20.3.3.) Then the electrostatic potential (r) outside the particle satisﬁes
Poisson’s equation, which we write in SI units:2
Poisson’s equation
∇2 = −
(np −ne)e
ϵ0
−Q
ϵ0
δ(r).
(20.6)
(Wedenotethepositivechargeofaprotonby+e andthenegativechargeofanelectron
by −e.)
A proton at radius r from the particle has an electrostatic potential energy e(r).
Correspondingly, the number density of protons at radius r is altered from ¯n by the
Boltzmann factor exp[−e/(kBT )]; and, similarly, the density of electrons is altered
by exp[+e/(kBT )]:
np = ¯n exp[−e/(kBT )]≃¯n[1 −e/(kBT )],
ne = ¯n exp[+e/(kBT )]≃¯n[1 + e/(kBT )],
(20.7)
where we have made a Taylor expansion of the Boltzmann factor valid for |e| ≪
kBT . By inserting the linearized versions of Eqs. (20.7) into Eq. (20.6), we obtain
∇2 = 2e2¯n
ϵ0kBT  −Q
ϵ0
δ(r).
(20.8)
1.
Analogous effects are encountered in condensed-matter physics and quantum electrodynamics.
2.
For those who prefer Gaussian units, the translation is most easily effected by the transformations
4πϵ0 →1 and μ0/(4π) →1, and inserting factors of c by inspection using dimensional analysis. It
is also useful to recall that 1 T ≡104 Gauss and that the charge on an electron is −1.602 × 10−19 C ≡
−4.803 × 10−10 esu.
20.3 Collective Effects in Plasmas—Debye Shielding and Plasma Oscillations
1003

The spherically symmetric solution to this equation,
 =
Q
4πϵ0r e−
√
2 r/λD,
(20.9)
has the form of a Coulomb ﬁeld with an exponential cutoff. The characteristic length-
scale of the exponential cutoff,
Debye length
λD ≡
ϵ0kBT
¯ne2
1/2
= 69
 T /1 K
¯n/1 m−3
1/2
m,
(20.10)
is called the Debye length.It is a rough measure of the size of the Debye shielding cloud
that the charged particle carries with itself.
The charged particle could be some foreign charged object (not a plasma electron
or proton), or equally well, it could be one of the plasma’s own electrons or protons.
Thus, we can think of each electron in the plasma as carrying with itself a positively
charged Debye shielding cloud of size λD, and each proton as carrying a negatively
charged cloud. Each electron and proton not only carries its own cloud; it also plays
a role as one of the contributors to the clouds around other electrons and protons.
20.3.2
20.3.2 Collective Behavior
A charged particle’s Debye cloud is almost always made of a huge number of electrons
and very nearly the same number of protons. It is only a tiny, time-averaged excess of
electrons over protons (or protons over electrons) that produces the cloud’s net charge
and the resulting exponential decay of the electrostatic potential. Ignoring this tiny
excess, the mean number of electrons in the cloud and the mean number of protons
are roughly
Debye number
ND ≡¯n4π
3 λD
3 = 1.4 × 106 (T /1 K)3/2
(¯n/1 m−3)1/2 .
(20.11)
This Debye number is large compared to unity throughout the density-temperature
regimeofplasmas, exceptforthetinylowerright-handcornerofFig.20.1.Thebound-
ary of that region (labeled “collective behavior”/“independent particles”) is given
by ND = 1. The upper left-hand side of that boundary has ND ≫1 and is called
the regime of collective behavior, because a huge number of particles are collec-
tively responsible for the Debye cloud; this leads to a variety of collective dynamical
phenomena in the plasma. The lower right-hand side has ND < 1 and is called the
regime of independent particles, because in it collective phenomena are of small
importance. (In this regime  on the right-hand side of Eq. (20.8) is replaced by
(kT /e) sinh[e/(kBT )].) In this book we restrict ourselves to the extensive regime
of collective behavior and ignore the tiny regime of independent particles.
Characteristic values for the Debye length and Debye number in a variety of
environments are listed in Table 20.1.
1004
Chapter 20. The Particle Kinetics of Plasma

20.3.3
20.3.3 Plasma Oscillations and Plasma Frequency
Of all the dynamical phenomena that can occur in a plasma, perhaps the most
important is a relative oscillation of the plasma’s electrons and protons. A simple,
idealized version of this plasma oscillation is depicted in Fig. 20.2. Suppose for the
moment that the protons are all ﬁxed, and displace the electrons rightward (in the
x direction) with respect to the protons by an amount ξ, thereby producing a net
negative charge per unit area −e¯nξ at the right end of the plasma, a net positive charge
per unit area +e¯nξ at the left end, and a corresponding electric ﬁeld E = e¯nξ/ϵ0
in the x direction throughout the plasma. The electric ﬁeld pulls on the plasma’s
electrons and protons, giving the electrons an acceleration d2ξ/dt2 = −eE/me and
theprotonsanaccelerationsmallerbyme/mp = 1/1,836, whichweneglect.Theresult
is an equation of motion for the electrons’ collective displacement:
d2ξ
dt2 = −e
me
E = −e2¯n
ϵ0me
ξ.
(20.12)
SinceEq.(20.12)isaharmonic-oscillatorequation, theelectronsoscillatesinusoidally,
ξ = ξo cos(ωpt), at the plasma (angular) frequency
plasma frequency, for
plasma oscillations
ωp ≡
 ¯ne2
ϵ0me
1/2
= 56.3

¯n
1 m−3
1/2
s−1.
(20.13)
Notice that this frequency of plasma oscillations depends only on the plasma
density ¯n and not on its temperature. Note that, if we deﬁne the electron thermal
speed to be ve ≡(kBTe/me)1/2, then ωp ≡ve/λD. In other words, a thermal electron
travels roughly a Debye length in a plasma oscillation period. We can think of the
Debye length as the electrostatic correlation length, and the plasma period as the
electrostatic correlation time.
neutral
ξ
E = enˉξ
—
ϵ0
+ + +
+ + +
+ + +
+ + +
+ + +
+ + +
+ + +
+ + +
+ + +
– – –
– – –
– – –
– – –
– – –
– – –
– – –
– – –
– – –
FIGURE 20.2 Idealized depiction of the displacement
of electrons relative to protons, which occurs during
plasma oscillations.
20.3 Collective Effects in Plasmas—Debye Shielding and Plasma Oscillations
1005

Characteristic values for the plasma frequency in a variety of environments are
listed in Table 20.1 and depicted on the bottom-most scale of Fig. 20.1.
20.4
20.4 Coulomb Collisions
In this section and the next, we study transport coefﬁcients (electrical and ther-
mal conductivities) and the establishment of local thermodynamic equilibrium in a
plasma under the hypothesis that Coulomb collisions are the dominant source of scat-
tering for both electrons and protons. In fact, as we shall see later, Coulomb scattering
is usually a less-effective scattering mechanism than collisionless processes mediated
by ﬂuctuating electromagnetic ﬁelds (plasmons).
20.4.1
20.4.1 Collision Frequency
Consider ﬁrst, as we did in our discussion of Debye shielding, a single test particle—
let it be an electron—interacting with background ﬁeld particles—let these be protons
for the moment. The test electron moves with speed ve. The ﬁeld protons will move
much more slowly if the electron and protons are near thermodynamic equilibrium
(as the proton masses are much greater than that of the electron), so the protons can
be treated, for the moment, as at rest. When the electron ﬂies by a single proton,
we can characterize the encounter using an impact parameter b, which is what the
distance of closest approach would have been if the electron were not deﬂected; see
Fig. 20.3. The electron will be scattered by the Coulomb ﬁeld of the proton, a process
sometimes called Rutherford scattering. If the deﬂection angle is small, θD ≪1, we
Rutherford scattering
can approximate its value by computing the perpendicular impulse exerted by the
proton’s Coulomb ﬁeld, integrating along the electron’s unperturbed straight-line
trajectory:
meveθD =
 +∞
−∞
e2b
4πϵo(b2 + v2
et2)3/2dt =
e2
2πϵoveb ,
(20.14a)
which implies that
θD = bo/b for b ≫bo,
(20.14b)
where
bo ≡
e2
2πϵ0mev2
e
.
(20.14c)
When b <∼bo, this approximation breaks down, and the deﬂection angle is of order
1 radian.3
Below we shall need to know how much energy the electron loses, for the large-
impact-parameter case. That energy loss, −E, is equal to the energy gained by the
3.
A more careful calculation gives 2 tan(θD/2) = bo/b; see, e.g., Bellan (2006, Assignment 1 in Sec. 1.13).
1006
Chapter 20. The Particle Kinetics of Plasma

θD
v
e
p
b
FIGURE 20.3 The geometry of a Coulomb collision.
proton. Since the proton is initially at rest, and since momentum conservation implies
it gains a momentum p = meveθD, E must be
E = −(p)2
2mp
= −me
mp
bo
b
2
E,
for b ≫bo.
(20.15)
Here E = 1
2mev2
e is the electron’s initial energy.
We turn from an individual Coulomb collision to the net, statistically averaged
effect of many collisions. The ﬁrst thing we compute is the mean time tD required
for the orbit of the test electron to be deﬂected by an angle of order 1 radian from its
initial direction, and the inverse of tD, which we call the “deﬂection rate” or “deﬂection
frequency” and denote νD = 1/tD. If the dominant source of this deﬂection were a
single large-angle scattering event, then the relevant cross section would be σ = πb2
o
(since all impact parameters <∼bo produce large-angle scatterings), and the mean
deﬂection time and frequency would be
time and frequency for
a single large-angle
deﬂection of an electron
by a proton
νD ≡1
tD
= nσve = nπb2
ove.
(20.16)
Here n is the proton number density, which is the same as the electron number density
in our hydrogen plasma.
The cumulative, random-walk effects of many small-angle scatterings off ﬁeld
protons actually produce a net deﬂection of order 1 radian in a time shorter than
this. As the directions of the individual scatterings are random, the mean deﬂection
angle after many scatterings vanishes. However, the mean-square deﬂection angle,
⟨2⟩= !
all encounters θD
2, will not vanish. That mean-square deﬂection angle, during
a time t, accumulates to
mean-square deﬂection
from small-angle
scatterings
⟨2⟩=
 bmax
bmin
bo
b
2
nvet 2πb db = n2πb2
ovet ln
bmax
bmin

.
(20.17)
Here the factor (bo/b)2 in the integrand is the squared deﬂection angle θD
2 for impact
parameter b, and the remaining factor nvet 2πb db is the number of encounters that
occur with impact parameters between b and b + db during time t. The integral
diverges logarithmically at both its lower limit bmin and its upper limit bmax. In
Sec. 20.4.2 we discuss the physical origins of and values of the cutoffs bmin and bmax.
The value of t that makes the mean-square deﬂection angle ⟨2⟩equal to unity is, to
20.4 Coulomb Collisions
1007

within factors of order unity, the deﬂection time tD (and inverse deﬂection frequency
ν−1
D ):
time and frequency for
large net deﬂection of an
electron by protons
νep
D = 1
tep
D
= n2πb2
ove ln  = ne4 ln  
2πϵ2
0m2
ev3
e
,
where  = bmax/bmin.
(20.18a)
Here the superscript ep indicates that the test particle is an electron and the ﬁeld
particles are protons. Notice that this deﬂection frequency is larger, by a factor 2 ln  ,
than the frequency (20.16) for a single large-angle scattering.
We must also consider the repulsive collisions of our test electron with ﬁeld
electrons. Although we are no longer justiﬁed in treating the ﬁeld electrons as being
at rest, the impact parameter for a large angle deﬂection is still ∼b0, so Eq. (20.18a) is
also appropriate to this case, in order of magnitude:
time and frequency for
large net deﬂection of an
electron by electrons
νee
D = 1
tee
D
∼νep
D = n2πb2
0ve ln  = ne4 ln  
2πϵ2
0m2
ev3
e
.
(20.18b)
Finally, and in the same spirit, we can compute the collision frequency for the pro-
tons.Becauseelectronsaresomuchlighterthanprotons, proton-protoncollisionswill
be more effective in deﬂecting protons than are proton-electron collisions. Therefore,
the proton collision frequency is given by Eq. (20.18b) with the electron subscripts
replaced by proton subscripts:
time and frequency for
large net deﬂection of a
proton by protons
νpp
D = 1
tpp
D
∼ne4 ln  
2πϵ2
0m2
pv3
p
.
(20.18c)
20.4.2
20.4.2 The Coulomb Logarithm
The maximum impact parameter bmax, which appears in  ≡bmax/bmin, is the Debye
length λD, since for impact parameters b ≫λD the Debye shielding screens out a ﬁeld
particle’s Coulomb ﬁeld, while for b ≪λD Debye shielding is unimportant.
The minimum impact parameter bmin has different values, depending on whether
quantum mechanical wave-packet spreading is important for the test particle during
the collision. Because of wave-packet spreading, the nearest the test particle can come
to a ﬁeld particle is the test particle’s de Broglie wavelength: bmin = ℏ/mv. However,
if the de Broglie wavelength is smaller than b0, then the effective value of bmin will be
simply b0. Therefore, in ln  = ln(bmax/bmin) (the Coulomb logarithm), we have
Coulomb logarithm
bmin = max[bo = e2/(2πϵ0mev2
e), ℏ/(meve)],
and
bmax = λD
for test electrons;
bmin = max[bo = e2/(2πϵ0mpv2
p), ℏ/(mpvp)],
and
bmax = λD
for test protons.
(20.19)
Over most of the accessible range of density and temperature for a plasma, we have
3 <∼ln  <∼30. Therefore, if we set
1008
Chapter 20. The Particle Kinetics of Plasma

ln  ≃10,
(20.20)
our estimate is good to a factor ∼3. For numerical values of ln  in a thermalized
plasma, see Spitzer (1962, Table 5.1).
Logarithmic terms, closely related to the Coulomb logarithm, arise in a variety
of other situations where one is dealing with a ﬁeld whose potential varies as 1/r
and force as 1/r2—and for the same reason: one encounters integrals of the form

(1/r)dr that diverge logarithmically. Speciﬁc examples are (i) the Gaunt factors,
which arise in the theory of bremsstrahlung radiation (electromagnetic waves from
Coulomb scattering of charged particles), (ii) Coulomb wave functions (solutions to
the Schr¨odinger equation for the quantum mechanical theory of Coulomb scattering),
and (iii) the Shapiro time delay for electromagnetic waves that travel past a general
relativistic gravitating body, such as the Sun (Sec. 27.2.4).
EXERCISES
Exercise 20.2 Problem: The Coulomb Logarithm
(a) Express the Coulomb logarithm in terms of the Debye number, ND, in the clas-
sical regime, where bmin ∼b0.
(b) What range of electron temperatures corresponds to the classical regime, and
what range to the quantum regime?
(c) Use the representative parameters from Table 20.1 to evaluate Coulomb loga-
rithms for the Sun’s core, a tokamak, and the interstellar medium, and verify that
they lie in the range 3 <∼ln  <∼30.
Exercise 20.3 Example: Parameters for Various Plasmas
Estimate the Debye length λD, the Debye number ND, the plasma frequency fp ≡
ωp/2π, and the electron deﬂection timescale tee
D ∼tep
D , for the following plasmas.
(a) An atomic bomb explosion in Earth’s atmosphere 1 ms after the explosion. (Use
theSedov-Taylorsimilaritysolutionforconditionsbehindthebomb’sshockwave;
Sec. 17.6.)
(b) The ionized gas that enveloped the Space Shuttle (Box 17.4) as it reentered Earth’s
atmosphere.
(c) The expanding universe during its early evolution, just before it became cool
enough for electrons and protons to combine to form neutral hydrogen (i.e., just
before ionization “turned off”). (As we shall discuss in Chap. 28, the universe
today is ﬁlled with blackbody radiation, produced in the big bang, that has a
temperature T = 2.7 K, and the universe today has a mean density of hydrogen
ρ ∼4 × 10−28 kg m−3. Extrapolate backward in time to infer the density and
temperature at the epoch just before ionization turned off.)
20.4 Coulomb Collisions
1009

20.4.3
20.4.3 Thermal Equilibration Rates in a Plasma
Suppose that a hydrogen plasma is heated in some violent way (e.g., by a shock
wave). Such heating will typically give the plasma’s electrons and protons a non-
Maxwellian velocity distribution. Coulomb collisions then, as time passes (and in
the absence of more violent disruptions), will force the particles to exchange energy
in random ways, gradually driving them into thermal equilibrium. As we shall see,
thermal equilibration
times
thermal equilibration is achieved at different rates for the electrons and the protons.
Correspondingly, the following three timescales are all different:
teq
ee ≡
 time required for electrons to equilibrate with one another,
achieving a near-Maxwellian velocity distribution

,
teq
pp ≡

time for protons to equilibrate with one another

,
teq
ep ≡

time for electrons to equilibrate with protons

.
(20.21)
In this section we compute these three equilibration times.
ELECTRON-ELECTRON EQUILIBRATION
To evaluate teq
ee , we assume that the electrons begin with typical individual energies
of order kBTe, where Te is the temperature to which they are going to equilibrate,
but their initial velocity distribution is rather non-Maxwellian. Then we can choose a
typical electron as the “test particle.” We have argued that Coulomb interactions with
electrons and protons are comparably effective in deﬂecting test electrons. However,
they are not comparably effective in transferring energy. When the electron collides
with a stationary proton, the energy transfer is
E
E ≃−me
mp
θD
2
(20.22)
[Eq. (20.15)]. This is smaller than the typical energy transfer in an electron-electron
collision by the ratio me/mp. Therefore, the collisions between electrons are respon-
sible for establishing an electron Maxwellian distribution function.
The alert reader may spot a problem at this point. According to Eq. (20.22),
electronsalwaysloseenergytoprotonsandnevergainit.Thiswouldcausetheelectron
temperature to continue to fall below the proton temperature, in clear violation of the
second law of thermodynamics. Actually what happens in practice is that, if we allow
for nonzero proton velocities, then the electrons can gain energy from some electron-
proton collisions. This is also the case for the electron-electron collisions of immediate
concern.
The most accurate formalism for dealing with this situation is the Fokker-Planck
formalism, discussed in Sec. 6.9 and made explicit for Coulomb scattering in Ex. 20.8.
Fokker-Planck is appropriate because, as we have shown, many weak scatterings dom-
inate the few strong scatterings. If we use the Fokker-Planck approach to compute an
energy equilibration time for a nearly Maxwellian distribution of electrons with tem-
1010
Chapter 20. The Particle Kinetics of Plasma

peratureTe, thenitturnsoutthatasimpleestimate, basedoncombiningthedeﬂection
time (20.16) with the typical energy transfer (20.22) (with mp →me), and on assum-
ing a typical electron velocity ve = (3kBTe/me)1/2, gives an answer good to a factor
of 2. It is actually convenient to express this electron energy equilibration timescale
using its reciprocal, the electron-electron equilibration rate, νee. This facilitates com-
parison with the other frequencies characterizing the plasma. The true Fokker-Planck
result for electrons near equilibrium is then
electron-electron
equilibration rate
νee = 1tee = nσT c ln  
2π1/2

kBTe
mec2
−3/2
= 2.6 × 10−5

n
1 m−3
 
Te
1 K
−3/2 2ln  
10
3
s−1
,
(20.23a)
where we have used the Thomson cross section
σT = 8π
3

e2
4πϵ0mec2
2
= 6.65 × 10−29 m2.
(20.23b)
PROTON-PROTON EQUILIBRATION
As for proton deﬂections [Eq. (20.18c)], so also for proton energy equilibration: the
light electrons are far less effective at inﬂuencing the protons than are other protons.
Therefore, the protons achieve a thermal distribution by equilibrating with one an-
other, and their proton-proton equilibration rate can be written down immediately
from Eq. (20.23a) by replacing the electron masses and temperatures with the proton
values:
proton-proton
equilibration rate
νpp = 1
tpp = nσT c ln  
2π1/2

me
mp
1/2 kBTp
mec2
−3/2
= 6.0 × 10−7

n
1 m−3
  Tp
1 K
−3/2 2ln  
10
3
s−1
.
(20.23c)
ELECTRON-PROTON EQUILIBRATION
Finally, if the electrons and protons have different temperatures, we should compute
the timescale for the two species to equilibrate with each other. This again is easy
to estimate using the energy-transfer equation (20.22): tep ≃(mp/me)tee. The more
accurate Fokker-Planck result for the electron-proton equilibration rate is again close
to this value and is given by
electron-proton
equilibration rate
νep = 1
tep = 2nσT c ln  
π1/2

me
mp
 
kBTe
mec2
−3/2
= 5.6 × 10−8

n
1 m−3
 
Te
1 K
−3/2 2ln  
10
3
s−1
.
(20.23d)
Thus, at the same density and temperature, protons require ∼(mp/me)1/2 = 43 times
longer to reach thermal equilibrium among themselves than do the electrons, and
20.4 Coulomb Collisions
1011

proton-electron equilibration takes a time ∼(mp/me) = 1,836 longer than electron-
electron equilibration.
20.4.4
20.4.4 Discussion
Table 20.1 lists the electron-electron equilibration rates for a variety of plasma en-
vironments. Generally, they are very small compared with the plasma frequencies.
For example, if we take parameters appropriate to fusion experiments (e.g., a toka-
mak), we ﬁnd that νee ∼10−8ωp and νep ∼10−11ωp. In fact, the equilibration time is
comparable, to order of magnitude, with the total plasma conﬁnement time ∼0.1s (cf.
Sec. 19.3). The disparity betweenνee and ωp is even greater in the interstellar medium.
Forthisreasonmostplasmasarewelldescribedascollisionless, andwemustanticipate
that the particle distribution functions will depart signiﬁcantly from Maxwellian.
EXERCISES
Exercise 20.4 Derivation: Electron-Electron Equilibration Rate
Using the non-Fokker-Planck arguments outlined in the text, compute an estimate
of the electron-electron equilibration rate, and show that it agrees with the Fokker-
Planck result, Eq. (20.23a), to within a factor of 2.
Exercise 20.5 Problem: Dependence of Thermal Equilibration on Charge and Mass
Compute the ion equilibration rate for a pure He3 plasma with electron density
1020 m−3 and temperature 108 K.
Exercise 20.6 Example: Stopping of α-Particles
A 100-MeV α-particle is incident on a plastic object. Estimate the distance that
it will travel before coming to rest. This is known as the particle’s range. [Hints:
(i) Debye shielding does not occur in a plastic. (Why?) (ii) The α-particle loses far
more energy to Coulomb scattering off electrons than off atomic nuclei. (Why?)
Estimate the electron density as ne = 2 × 1029 m−3. (iii) Ignore relativistic corrections
and reﬁnements, such as the so-called density effect. (iv) Consider the appropriate
values of bmax and bmin.]
Exercise 20.7 Problem: Equilibration Time for a Globular Star Cluster
Collections of stars have many similarities to a plasma of electrons and ions. These
similarities arise from the fact that in both cases the interaction between the indi-
vidual particles (stars, or ions and electrons) is a radial, 1/r2 force. The principal
difference is that the force between stars is always attractive, so there is no analog of
Debye shielding. One consequence of this difference is that a plasma can be spatially
homogeneous and static, when one averages over lengthscales large compared to the
interparticle separation; but a collection of stars cannot be—the stars congregate into
clusters that are held together by the stars’ mutual gravity.
A globular star cluster is an example. A typical globular cluster is a nearly spherical
swarm of stars with the following parameters: cluster radius ≡R = 10 light-years;
1012
Chapter 20. The Particle Kinetics of Plasma

total number of stars in the cluster ≡N = 106; and mass of a typical star ≡m =
0.4 solar masses = 8 × 1032 g. Each star moves on an orbit of the average, “smeared
out” gravitational ﬁeld of the entire cluster. Since that smeared-out gravitational ﬁeld
is independent of time, each star conserves its total energy (kinetic plus gravitational)
as it moves. Actually, the total energy is only approximately conserved. Just as in
a plasma, gravitational “Coulomb collisions” of the star with other stars produce
changes in the star’s energy.
(a) What is the mean time tE for a typical star in a globular cluster to change its energy
substantially? Express your answer, accurate to within a factor of ∼3, in terms of
N, R, and m. Evaluate it numerically and compare it with the age of the universe.
(b) The cluster evolves substantially on the timescale tE. What type of evolution
would you expect to occur? What type of stellar energy distribution would you
expect to result from this evolution?4
Exercise 20.8 **Example and Challenge: Fokker-Planck Formalism
for Coulomb Collisions
Consider two families of particles that interact via Coulomb collisions (e.g., elec-
trons and protons, or electrons and electrons). Regard one family as test particles,
with masses m and charges q and a kinetic-theory distribution function f (v) =
dN/dVxdVv that is homogeneous in space and thus only a function of the test par-
ticles’ velocities v. (For discussion of this distribution function, see Sec. 3.2.3, and in
greater detail, Sec. 22.2.1.) Regard the other family as ﬁeld particles, with masses m′
and charges q′ and a spatially homogeneous distribution function fF(v′).
The Fokker-Planck equation (Sec. 6.9.3) can be used to give a rather accurate
description of how the ﬁeld particles’ distribution function f (v, t) evolves due to
Coulomb collisions with the test particles. In this exercise, you will work out explicit
versions of this Fokker-Planck equation. These explicit versions are concrete founda-
tions for deducing Eqs. (20.23) for the electron and proton equilibration rates, Eqs.
(20.26) for the thermal and electrical conductivities of a plasma, and other evolution-
ary effects of Coulomb collisions.
(a) Explain why, for a spatially homogeneous plasma with the only electromagnetic
ﬁelds present being the Coulomb ﬁelds of the plasma particles, the collisionless
Boltzmann transport equation (3.65) (with N replaced by f and pj by vj)
becomes simply ∂f/∂t = 0. Then go on to explain why the collision terms in
the collisional Boltzmann transport equation (3.66) are of Fokker-Planck form,
Eq. (6.106a):
∂f
∂t = −∂
∂vj
"
Aj(v)f (v, t)
#
+ 1
2
∂2
∂vj∂vk
"
Bjk(v)f (v, t)
#
,
(20.24a)
4.
For a detailed discussion, see, e.g., Binney and Tremaine (2003).
20.4 Coulomb Collisions
1013

where Aj and Bjk are, respectively, the slowdown rate and velocity diffusion rate
of the test particles due to Coulomb scatterings off the ﬁeld particles:
Aj = lim
t→0
*
vj
t
+
,
Bjk = lim
t→0
*
vjvk
t
+
[Eqs. (6.106b) and (6.106c)].
(b) Analyze, in the center-of-mass reference frame, the small-angle Coulomb scat-
tering of a test particle off a ﬁeld particle (with some chosen impact parameter b
and relative velocity vrel = v −v′ = difference between lab-frame velocities), and
then transform to the laboratory frame where the ﬁeld particles on average are at
rest. Then add up the scattering inﬂuences of all ﬁeld particles on the chosen test
particle (i.e., integrate over b and over v′) to show that the test particle’s rate of
change of velocity is
Aj =  ∂
∂vj
h(v).
(20.24b)
Here the constant  and the ﬁrst Rosenbluth potential h are
 = q2q′2 ln  
4πϵ2
0m2 ,
h(v) = m
μ

fF(v′)
|v −v′|dVv′.
(20.24c)
In addition, μ = mm′/(m + m′) is the reduced mass, which appears in the center-
of-mass-frame analysis of the Coulomb collision;  = bmax/bmin is the ratio of
the maximum to the minimum possible impact parameters as in Sec. 20.4.2;
and dVv′ = dv′
xdv′
ydv′
z is the volume element in velocity space. Although bmin
depends on the particles’ velocities, without signiﬁcant loss of accuracy we can
evaluate it for some relevant mean velocity and pull it out from under the integral,
as we have done. This is because  = bmax/bmin appears only in the logarithm.
(c) By the same method as in part (b), show that the velocity diffusion rate is
Bjk(v) = 
∂2
∂vj∂vk
g(v),
(20.24d)
where the second Rosenbluth potential is
g(v) =

|v −v′|fF(v′)dVv′.
(20.24e)
(d) Show that, with Aj and Bjk expressed in terms of the Rosenbluth potentials [Eqs.
(20.24b) and (20.24d)], the Fokker-Planck equation (20.24a) can be brought into
the following alternative form:
∂f
∂t = m
2
∂
∂vj
 ∂2|v −v′|
∂vj∂vk
'
fF(v′)
m
∂f (v)
∂vk
−f (v)
m′
∂fF(v′)
∂v′
k
(
dVv′.
(20.25)
1014
Chapter 20. The Particle Kinetics of Plasma

[Hint: Manipulate the partial derivatives in a wise way and perform integrations
by parts.]
(e) Using Eq. (20.25), show that, if the two species—test and ﬁeld—are thermalized
at the same temperature, then the test-particle distribution function will remain
unchanged: ∂f/∂t = 0.
For details of the solution to this exercise see, for example, the original paper by
Rosenbluth, MacDonald, and Judd (1957), or the pedagogical treatments in standard
plasma physics textbooks (e.g., Boyd and Sanderson, 2003, Sec. 8.4; Bellan, 2006,
Sec. 13.2).
The explicit form (20.24) of the Fokker-Planck equation has been solved approx-
imately for idealized situations. It has also been integrated numerically for more
realistic situations, so as to evolve the distribution functions of interacting particle
species and, for example, watch them thermalize. (See, e.g., Bellan, 2006, Sec. 13.2;
Boyd and Sanderson, 2003, Secs. 8.5, 8.6; and Shkarofsky, Johnston, and Bachynski,
1966, Secs. 7.5–7.11.) An extension to a plasma with an applied electric ﬁeld and/or
temperature gradient (using techniques developed in Sec. 3.7.3) has been used to de-
duce the electrical and thermal conductivities discussed in the next section (see, e.g.,
Shkarofsky, Johnston, and Bachynski, 1966, Chap. 8).
20.5
20.5 Transport Coefﬁcients
Because electrons have far lower masses than ions, they have far higher typical speeds
at ﬁxed temperature and are much more easily accelerated (i.e., they are much more
mobile). As a result, it is the motion of the electrons, not the ions, that is responsible
for the transport of heat and charge through a plasma. In the spirit of the discussion
above, we can compute transport properties, such as the electric conductivity and
thermal conductivity, on the presumption that it is Coulomb collisions that determine
the electron mean free paths and that magnetic ﬁelds are unimportant. (Later we will
see that collisionless effects—scattering off plasmons—usually provide a more serious
impediment to charge and heat ﬂow than Coulomb collisions and thus dominate the
conductivities.)
20.5.1
20.5.1 Coulomb Collisions
First consider an electron exposed to a constant, accelerating electric ﬁeld E. The
electron’s typical ﬁeld-induced velocity is along the direction of the electric ﬁeld and
has magnitude −eE/(meνD), where νD is the deﬂection frequency (rate) evaluated
in Eqs. (20.18a) and (20.18b). We call this a drift velocity, because it is superposed
on the electrons’ collision-induced isotropic velocity distribution. The associated
current density is j ∼ne2E/(meνD), and the electrical conductivity therefore is κe
∼ne2/(meνD). (Note that electron-electron collisions conserve momentum and thus
20.5 Transport Coefﬁcients
1015

do not impede the ﬂow of current, so electron-proton collisions, which happen about
as frequently, produce all the electrical resistance and are thus responsible for this κe.)
The thermal conductivity can likewise be estimated by noting that a typical elec-
tron travels a mean distance ℓ∼ve/νD between large net deﬂections, from an initial
location where the average temperature is different from the ﬁnal location’s tempera-
turebyanamountT ∼ℓ|∇T |.Theheatﬂuxtransportedbytheelectronsistherefore
∼nvekBT , which should be equated to −κ∇T . We thereby obtain the electron con-
tribution to the thermal conductivity as κ ∼nk2
BT /(meνD).
Computations based on the Fokker-Planck approach (Spitzer and Harm, 1953;
see also Ex. 20.8) produce equations for the electrical and thermal conductivities that
agree with the above estimates within factors of order ten:
electrical and thermal
conductivities when
Coulomb collisions are
responsible for the
resistivity
κe = 4.9

e2
σT c ln  me
 kBTe
mec2
3/2
= 1.5 × 10−3
 Te
1 K
3/2 ln  
10
−1
−1 m−1,
(20.26a)
κ = 19.1

kBc
σT ln  
 kBTe
mec2
5/2
= 4.4 × 10−11
 Te
1 K
5/2 ln  
10
−1
W m−1 K−1.
(20.26b)
Here σT is the Thomson cross section, Eq. (20.23b). Note that neither transport
coefﬁcient depends explicitly on the density; increasing the number of charge or heat
carriers is compensated by the reduction in their mean free paths.
20.5.2
20.5.2 Anomalous Resistivity and Anomalous Equilibration
We have demonstrated that the theoretical Coulomb interaction between charged
particles gives very long mean free paths. Correspondingly, the electrical and ther-
mal conductivities (20.26) are very large in practical, geophysical, and astrophysical
applications. Is this the way that real plasmas behave? The answer is almost always
“no.”
mechanism for
anomalous resistivity
and equilibration
As we shall show in the next three chapters, a plasma can support a variety of
modes of collective excitation (plasmons), in which large numbers of electrons and/or
ionsmoveincollective, correlatedfashionsthataremediatedbyelectromagneticﬁelds
that they create. When the modes of a plasma are sufﬁciently excited (which is com-
mon), the electromagnetic ﬁelds carried by the excitations can be much more effective
than Coulomb scattering at deﬂecting the orbits of individual electrons and ions and
at feeding energy into or removing it from the electrons and ions. Correspondingly,
the electrical and thermal conductivities will be reduced. The reduced transport co-
efﬁcients are termed anomalous, as is the scattering by plasmons that controls them.
Providing quantitative calculations of the anomalous scattering and these anomalous
transport coefﬁcients is one of the principal tasks of nonlinear plasma physics—as we
start to discuss in Chap. 22.
1016
Chapter 20. The Particle Kinetics of Plasma

EXERCISES
Exercise 20.9 Example: Bremsstrahlung
Bremsstrahlung (or free-free radiation) arises when electrons are accelerated by ions
and the changing electric dipole moment that they create leads to the emission of
photons. This process can only be fully described using quantum mechanics, though
the low-frequency spectrum can be calculated accurately using classical electro-
magnetism. Here we make a “back of the envelope” estimate of the absorption
coefﬁcient and convert it into an emission coefﬁcient.
(a) Consider an electron with average speed v oscillating in an electromagnetic wave
of electric ﬁeld amplitude E and (slow) angular frequency ω. Show that its energy
of oscillation is Eosc ∼e2E2m−1ω−2.
(b) Let the electron encounter an ion and undergo a rapid deﬂection. Explain why the
electron will, on average, gain energy of ∼Eosc as a result of the encounter. Hence
estimate the average rate of electron heating. (You may ignore the cumulative
effects of distant encounters.)
(c) Recognizing that classical absorption at low frequency is the difference between
quantum absorption and stimulated emission (e.g., Sec. 10.2.1), convert the result
frompart(b)intoaspontaneousemissionrate, assumingthattheelectronvelocity
is typical for a gas in thermal equilibrium at temperature T .
(d) Hence show that the free-free cooling rate (power radiated per unit volume)
of an electron-proton plasma with electron density ne and temperature T is
∼n2
eαFσT c2 
kBT me
1/2, whereαF = e2/(4πϵ0ℏc) = 7.3 × 10−3istheﬁnestruc-
ture constant, and σT = 6.65 × 10−29 m2 is the Thomson cross section. In a more
detailed analysis, the long-range (1/r2) character of the electric force gives rise
to a multiplicative logarithmic factor, called the Gaunt factor, analogous to the
Coulomb logarithm of Sec. 20.4.2.
This approach is useful when the plasma is so dense that the emission rate is signiﬁ-
cantly different from the rate in a vacuum (Boyd and Sanderson, 2003, Chap. 9).
Exercise 20.10 Challenge and Example: Thermoelectric Transport Coefﬁcients
(a) Consider a plasma in which the magnetic ﬁeld is so weak that it presents little
impediment to the ﬂow of heat and electric current. Suppose that the plasma has
a gradient ∇Te of its electron temperature and also has an electric ﬁeld E. It is a
familiar fact that the temperature gradient will cause heat to ﬂow and the electric
ﬁeld will create an electric current. Not so familiar, but somewhat obvious if one
stops to think about it, is that the temperature gradient also creates an electric
current and the electric ﬁeld also causes heat ﬂow. Explain in physical terms why
this is so.
(b) So long as the mean free path of an electron between substantial deﬂections
by electrons and protons, ℓD,e = (3kBTe/me)1/2tD,e, is short compared to the
lengthscale for substantial temperature change, Te/|∇Te|, and short compared to
20.5 Transport Coefﬁcients
1017

the lengthscale for the electrons to be accelerated to near the speed of light by
the electric ﬁeld, mec2/(eE), the ﬂuxes of heat q and of electric charge j will be
governed by nonrelativistic electron diffusion and will be linear in ∇T and E:
q = −κ∇T −βE ,
j = κeE + α∇T .
(20.27)
The coefﬁcients κ (heat conductivity), κe (electrical conductivity), β, and α
are called thermoelectric transport coefﬁcients. Use kinetic theory (Chap. 3), in
a situation where ∇T = 0, to derive the conductivity equations j = κeE and
q = −βE, and the following approximate formulas for the transport coefﬁcients:
κe ∼ne2tD,e
me
,
β ∼kBT
e κe.
(20.28a)
Show that, aside from a coefﬁcient of order unity, this κe, when expressed in
termsoftheplasma’stemperatureanddensity, reducestotheFokker-Planckresult
Eq. (20.26a).
(c) Use kinetic theory, in a situation where E = 0 and the plasma is near thermal
equilibrium at temperature T , to derive the conductivity equations q = −κ∇T
and j = α∇T , and the approximate formulas
κ ∼kBnkBT
me
tD,e,
α ∼
e
kBT κ.
(20.28b)
Show that, aside from a coefﬁcient of order unity, this κ reduces to the Fokker-
Planck result Eq. (20.26b).
(d) It can be shown (Spitzer and Harm, 1953) that for a hydrogen plasma
αβ
κeκ = 0.581.
(20.28c)
By studying the entropy-governed probability distributions for ﬂuctuations away
from statistical equilibrium, one can derive another relation among the thermo-
electric transport coefﬁcients, the Onsager relation (Kittel, 2004, Secs. 33, 34; Reif,
2008, Sec. 15.8):
β = αT + 5
2
kBTe
e
κe;
(20.28d)
Eqs. (20.28c) and (20.28d) determine α and β in terms of κe and κ. Show that
your approximate values of the transport coefﬁcients, Eqs. (20.28a) and (20.28b),
are in rough accord with Eqs. (20.28c) and (20.28d).
(e) If a temperature gradient persists for sufﬁciently long, it will give rise to sufﬁcient
charge separation in the plasma to build up an electric ﬁeld (called a “secondary
ﬁeld”) that prevents further charge ﬂow. Show that this cessation of charge ﬂow
suppresses the heat ﬂow. The total heat ﬂux is then q = −κT effective∇T , where
κT effective =

1 −αβ
κeκ

κ = 0.419κ.
(20.29)
1018
Chapter 20. The Particle Kinetics of Plasma

20.6
20.6 Magnetic Field
20.6.1
20.6.1 Cyclotron Frequency and Larmor Radius
Many of the plasmas that we will encounter are endowed with a strong magnetic ﬁeld.
This causes the charged particles to travel along helical orbits about the ﬁeld direction
rather than move rectilinearly between collisions.
If we denote the magnetic ﬁeld by B, then the equation of motion for a nonrela-
tivistic electron becomes
me
dv
dt = −e v × B,
(20.30)
which gives rise to a constant speed v|| parallel to the magnetic ﬁeld and a circular
motion perpendicular to the ﬁeld with angular velocity sometimes denoted ωce and
sometimes ωc:
(electron) cyclotron
frequency
ωce = ωc = eB
me
= 1.76 × 1011
 B
1 T

s−1.
(20.31)
This angular velocity is called the electron cyclotron frequency, or simply the cyclotron
frequency; and it is sometimes called the gyro frequency. Notice that this cyclotron
frequency depends only on the magnetic ﬁeld strength B and not on the plasma’s
density n or the electron velocity (i.e., the plasma temperature T ). Nor does it depend
on the angle between v and B (the pitch angle, α).
The radius of the electron’s gyrating (spiraling) orbit, projected perpendicular to
the direction of the magnetic ﬁeld, is called the Larmor radius and is given by
Larmor radius
rL = v⊥
ωce
= v sin α
ωce
= 5.7 × 10−9

v⊥
1 km s−1
  B
1 T
−1
m,
(20.32)
where v⊥is the electron’s velocity projected perpendicular to the ﬁeld. Protons (and
other ions) in a plasma also undergo cyclotron motion. Because the proton mass is
larger by mp/me = 1,836 than the electron mass, its angular velocity
proton cyclotron frequency
ωcp = eB
mp
= 0.96 × 108 s−1
 B
1 T

(20.33)
is 1,836 times lower. The quantity ωcp is called the proton cyclotron frequency or ion
cyclotronfrequency.Thesenseofgyrationis, ofcourse, oppositetothatoftheelectrons.
If the protons have similar temperatures to the electrons, their speeds are typically
∼mp/me = 43 times smaller than those of the electrons, and their typical Larmor
radii are ∼43 times larger than those of the electrons.
We demonstrated in Sec. 20.3.3 that all the electrons in a plasma can oscillate in
phase at the plasma frequency. The electrons’ cyclotron motions can also be coherent.
Such coherent motions are called cyclotron resonances or cyclotron oscillations,and we
cyclotron resonances
(oscillations)
shall study them in Chap. 21. Ion cyclotron resonances can also occur. Characteristic
electron cyclotron frequencies and Larmor radii are tabulated in Table 20.1. As shown
20.6 Magnetic Field
1019

there, the cyclotron frequency, like the plasma frequency, is typically far larger than
the rates for Coulomb-mediated energy equilibration.
20.6.2
20.6.2 Validity of the Fluid Approximation
MAGNETOHYDRODYNAMICS
conditions for validity of
MHD approximation
In Chap. 19, we developed the magnetohydrodynamic (MHD) description of a mag-
netized plasma. We described the plasma by its density and temperature (or equiv-
alently, its pressure). Under what circumstances, for a plasma, is this description
accurate? The answer to this question turns out to be quite complex, and a full dis-
cussion would go well beyond the scope of this book. Some aspects, however, are easy
to describe. A ﬂuid description ought to be acceptable when (i) the timescales τ that
characterize the macroscopic ﬂow are long compared with the time required to estab-
lish Maxwellian equilibrium (i.e., τ ≫ν−1
ep ), and (ii) the excitation level of collective
wave modes is so small that the modes do not interfere seriously with the inﬂuence of
Coulomb collisions. Unfortunately, these conditions rarely apply. (One type of plasma
where they might be a quite good approximation is that in the interior of the Sun.)
Magnetohydrodynamics can still provide a moderately accurate description of a
plasma, even if the electrons and ions are not fully equilibrated, when the electrical
conductivity can be treated as very large and the thermal conductivity as very small.
Then we can treat the magnetic Reynolds number [Eq. (19.9c)] as effectively inﬁnite
and the plasma as an adiabatic perfect ﬂuid (as we assumed in much of Chap. 19).
It is not so essential that the actual particle distribution functions be Maxwellian,
merely that they have second moments that can be associated with a (roughly deﬁned)
common temperature.
Quite often in plasma physics almost all of the dissipation is localized—for exam-
ple, to the vicinity of a shock front or a site of magnetic-ﬁeld-line reconnection—and
the remainder of the ﬂow can be treated using MHD. The MHD description then
provides a boundary condition for a fuller plasma physical analysis of the dissipative
region. This approach simpliﬁes the analysis of such situations.
GENERALIZATIONS OF MHD
The great advantage of ﬂuid descriptions, and the reason physicists abandon them
withsuchreluctance, isthattheyaremuchsimplerthanotherdescriptionsofaplasma.
One only has to cope with the ﬂuid pressure, density, and velocity and does not have
to deal with an elaborate statistical description of the positions and velocities of all
the particles. Generalizations of the simple ﬂuid approximation have therefore been
devised that can extend the domain of validity of simple MHD ideas.
two-ﬂuid approximation
One extension, which we develop in the following chapter, is to treat the protons
and the electrons as two separate ﬂuids and derive dynamical equations that describe
their (coupled) evolution. Another extension, which we describe now, is to acknowl-
edge that, in most plasmas:
1020
Chapter 20. The Particle Kinetics of Plasma

1. the cyclotron period is very short compared with the Coulomb collision time
(and with the anomalous scattering time), and
2. the timescale on which energy is transferred back and forth among the
electrons, the protons, and the electromagnetic ﬁeld is intermediate between
ω−1
c
and ν−1
ee .
Intuitively, these assumptions allow the electron and proton velocity distributions to
become axisymmetric with respect to the magnetic ﬁeld direction, though not fully
anisotropic ﬂuid in
presence of magnetic ﬁeld
isotropic. In other words, we can characterize the plasma using a density and two
separate components of pressure, one associated with motion along the direction of
the magnetic ﬁeld, and the other with gyration around the ﬁeld lines.
For simplicity, let us just consider the electrons and their stress tensor, which we
can write as
T jk
e
=

Ne pjpk dVp
m
(20.34)
[Eq. (3.32d)], where Ne is the electron number density in phase space and dVp =
dpxdpydpz is the volume element in phase space. If we orient Cartesian axes so that
the direction of ez is parallel to the local magnetic ﬁeld, then
anisotropic pressure
||T jk
e || =
⎡
⎢⎣
Pe⊥
0
0
0
Pe⊥
0
0
0
Pe||
⎤
⎥⎦,
(20.35)
where Pe⊥is the electron pressure perpendicular to B, and Pe|| is the electron pressure
parallel toB. Now suppose that there is a compression or expansion on a timescale that
is long compared with the cyclotron period but short compared with the Coulomb
collision and anomalous scattering timescales. Then we should not expect Pe⊥to
be equal to Pe||, and we anticipate that they will evolve with density according to
different laws.
The adiabatic indices governing P⊥and P|| in such a situation are easily derived
from kinetic-theory arguments (Ex. 20.11). For compression perpendicular to B and
no change of length along B, we have
collisionless, anistotropic
adiabatic indices
γ⊥≡
∂ln P⊥
∂ln ρ

s
= 2,
γ|| ≡
∂ln P||
∂ln ρ

s
= 1;
(20.36a)
for compression parallel to B and no change of transverse area, we have
γ⊥≡
∂ln P⊥
∂ln ρ

s
= 1,
γ|| ≡
∂ln P||
∂ln ρ

s
= 3.
(20.36b)
20.6 Magnetic Field
1021

By contrast, if the expansion is sufﬁciently slow that Coulomb collisions are effective
(thoughnotsoslowthatheatconductioncanoperate), thenweexpectthevelocitydis-
tribution to maintain isotropy and both components of pressure to evolve according
to the law appropriate to a monatomic gas:
collisional, isotropic
adiabatic index
γ =
∂ln P⊥
∂ln ρ

s
=
∂ln P||
∂ln ρ

s
= 5
3.
(20.37)
20.6.3
20.6.3 Conductivity Tensor
As is evident from the foregoing remarks, if we are in a regime where Coulomb
scattering really does determine the particle mean free path, then an extremely small
magnetic ﬁeld strength sufﬁces to ensure that individual particles complete gyrational
orbits before they collide. Speciﬁcally, for electrons, the deﬂection time tD, given by
Eq. (20.18a,b), exceeds ω−1
c
if
B >∼10−16

n
1 m−3
  Te
1 K
−3/2
T.
(20.38)
This is almost always the case. It is also almost always true for the ions.
When inequality (20.38) is satisﬁed and also anomalous scattering is negligible on
the timescale ω−1
c , the transport coefﬁcients must be generalized to form tensors. Let
us compute the electrical conductivity tensor for a plasma in which a steady electric
ﬁeld E is applied. Once again orienting our coordinate system so that the magnetic
ﬁeld is parallel to ez, we can write down an equation of motion for the electrons by
balancing the electromagnetic acceleration with the average rate of loss of momentum
due to collisions or anomalous scattering:
electron equation of
motion
−e(E + v × B) −meνDv = 0.
(20.39)
Solving for the velocity, we obtain
⎛
⎜⎝
vx
vy
vz
⎞
⎟⎠= −
e
meνD(1 + ω2
c/ν2
D)
⎛
⎜⎝
1
ωc/νD
0
−ωc/νD
1
0
0
0
1 + ω2
c/ν2
D
⎞
⎟⎠
⎛
⎜⎝
Ex
Ey
Ez
⎞
⎟⎠.
(20.40)
As the current density is je = −nev = κeE, the electrical conductivity tensor is
given by
anisotropic electric
conductivity
κe =
ne2
meνD(1 + ω2
c/ν2
D)
⎛
⎜⎝
1
ωc/νD
0
−ωc/νD
1
0
0
0
1 + ω2
c/ν2
D
⎞
⎟⎠.
(20.41)
It is apparent from the form of this conductivity tensor that, when ωc ≫νD (as
is almost always the case), the conductivity perpendicular to the magnetic ﬁeld is
1022
Chapter 20. The Particle Kinetics of Plasma

greatly inhibited, whereas that along the magnetic ﬁeld is unaffected. Similar remarks
apply to the ﬂow of heat. It is therefore often assumed that only transport parallel to
the ﬁeld is effective. However, as is made clear in the next section, if the plasma is
inhomogeneous, then cross-ﬁeld transport can be quite rapid in practice.
EXERCISES
Exercise 20.11 Example and Derivation: Adiabatic Indices for Compression
of a Magnetized Plasma
Consider a plasma in which, in the local mean rest frame of the electrons, the electron
stress tensor has the form (20.35) with ez the direction of the magnetic ﬁeld. The
following analysis for the electrons can be carried out independently for the ions,
resulting in the same formulas.
(a) Show that
Pe|| = nme⟨v2
||⟩,
Pe ⊥= 1
2nme⟨|v⊥|2⟩,
(20.42)
where ⟨v2
||⟩is the mean-square electron velocity parallel to B, and ⟨|v⊥|2⟩is
the mean-square velocity orthogonal to B. (The velocity distributions are not
assumed to be Maxwellian.)
(b) Consider a ﬂuid element with length l along the magnetic ﬁeld and cross sectional
area A orthogonal to the ﬁeld. Let ¯v be the mean velocity of the electrons (¯v = 0
in the mean electron rest frame), and let θ and σjk be the expansion and shear of
the mean electron motion as computed from ¯v (Sec. 13.7.1). Show that
dl/dt
l
= 1
3θ + σ jkbjbk ,
dA/dt
A
= 2
3θ −σ jkbjbk,
(20.43)
where b = B/|B| = ez is a unit vector in the direction of the magnetic ﬁeld.
(c) Assume that the timescales for compression and shearing are short compared
with those for Coulomb scattering and anomalous scattering: τ ≪tD,e. Show,
using the laws of energy and particle conservation, that
1
⟨v2
||⟩
d⟨v2
||⟩
d
= −2
l
dl
dt ,
1
⟨v2
⊥⟩
d⟨v2
⊥⟩
dt
= −1
A
dA
dt ,
(20.44)
1
n
dn
dt = −1
l
dl
dt −1
A
dA
dt .
(d) Show that
1
Pe||
dPe||
dt
= −3dl/dt
l
−dA/dt
A
= −5
3θ −2σ jkbjbk,
1
Pe⊥
dPe⊥
dt
= −dl/dt
l
−2dA/dt
A
= −5
3θ + σ jkbjbk.
(20.45)
20.6 Magnetic Field
1023

(e) Show that, when the ﬂuid is expanding or compressing entirely perpendicular
to B, with no expansion or compression along B, the pressures change in accord
with the adiabatic indices of Eq. (20.36a). Show, similarly, that when the ﬂuid
expands or compresses along B, with no expansion or compression in the per-
pendicular direction, the pressures change in accord with the adiabatic indices of
Eq. (20.36b).
(f) Hence derive the so-called double adiabatic or CGL (Chew, Goldberger, and Low,
1956) equations of state:
P|| ∝n3/B2,
P⊥∝nB,
(20.46)
validforchangesontimescaleslongcomparedwiththecyclotronperiodbutshort
compared with all Coulomb collision and anomalous scattering times.
Exercise 20.12 Problem: Relativistic Electron Motion
Use the relativistic equation of motion to show that the relativistic electron cyclotron
frequency is ωc = eB/(γ me), where γ = 1/

1 −(v/c)2 is the electron Lorentz fac-
tor. What is the relativistic electron Larmor radius? What is the relativistic proton
cyclotron frequency and Larmor radius?
Exercise 20.13 Example: Ultra-High-Energy Cosmic Rays
The most energetic (ultra-high-energy) cosmic rays are probably created with ener-
gies up to ∼1 ZeV = 1021 eV in sources roughly 100 million light-years away.
(a) Show that they start with the “energy of a well-hit baseball and the momentum
of a snail.” By the time they arrive at Earth, their energies are likely to have been
reduced by a factor of ∼3.
(b) Assuming that the intergalactic magnetic ﬁeld is ∼10−13 T ∼10−9 G, compute
the cosmic rays’ Larmor radii, assuming that they are protons and iron nuclei.
(c) Do you expect their arrival directions to point back to their sources?
(d) Suppose that an ultra-high-energy cosmic ray collides with a stationary nitrogen
nucleus in our atmosphere. How much energy becomes available in the center-of-
mass frame? Compare this with the energy at the Large Hadron Collider, where
protons, each with energy ∼7 TeV, collide head on.
20.7
20.7 Particle Motion and Adiabatic Invariants
In the next three chapters we shall meet a variety of plasma phenomena that can be
understood in terms of the orbital motions of individual electrons and ions. These
phenomena typically entail motions in an electromagnetic ﬁeld that is nearly but not
quite spatially homogeneous on the scale of the Larmor radius rL and nearly but
not quite constant during a cyclotron period 2π/ωc. In this section, in preparation
1024
Chapter 20. The Particle Kinetics of Plasma

for the next three chapters, we review charged-particle motion in such nearly homo-
geneous, nearly time-independent ﬁelds.
Since the motions of electrons are usually of greater interest than those of ions, we
presume throughout this section that the charged particle is an electron. We denote
its charge by −e and its mass by me.
20.7.1
20.7.1 Homogeneous, Time-Independent Magnetic Field and No Electric Field
From the nonrelativistic version of the Lorentz force equation, dv/dt = −(e/me)v ×
B, one readily deduces that an electron in a homogeneous, time-independent mag-
netic ﬁeld B moves with uniform velocity v|| parallel to the ﬁeld, and it moves perpen-
dicular to the ﬁeld in a circular orbit with the cyclotron frequency ωc = eB/me and
Larmor radius rL = mev⊥/(eB). Here v⊥is the electron’s time-independent trans-
verse speed (speed perpendicular to B).
20.7.2
20.7.2 Homogeneous, Time-Independent Electric and Magnetic Fields
Suppose that the homogeneous magnetic ﬁeld B is augmented by a homogeneous
electric ﬁeld E, and assume initially that |E × B| < B2c. Then examine the electric
and magnetic ﬁelds in a new reference frame, one that moves with the velocity
vD = E × B
B2
,
(20.47)
relative to the original frame. Note that the moving frame’s velocity vD is perpendicu-
lar to both the magnetic ﬁeld and the electric ﬁeld. From the Lorentz transformation
law for the electric ﬁeld, E′ = γ (E + vD × B), we infer that in the moving frame the
electric ﬁeld and the magnetic ﬁeld are parallel to each other. As a result, in the mov-
ing frame the electron’s motion perpendicular to the magnetic ﬁeld is purely circular;
and, correspondingly, in the original frame its perpendicular motion consists of a drift
with velocity vD, and superposed on that drift, a circular motion (Fig. 20.4). In other
guiding-center
approximation; E ××× B
E ××× B
E ××× B
drift
words, the electron moves in a circle whose center (the electron’s guiding center) drifts
with velocity vD. Notice that the drift velocity (20.47) is independent of the electron’s
charge and mass, and thus is the same for ions as for electrons. This drift is called the
“E × B drift.”
breakdown of guiding-
center approximation
when BBB is large
When the component of the electric ﬁeld orthogonal to B is so large that the drift
velocity computed from Eq. (20.47) exceeds the speed of light, the electron’s guiding
center, of course, cannot move with that velocity. Instead, the electric ﬁeld drives
the electron up to higher and higher velocities as time passes, but in a sinusoidally
modulated manner. Ultimately, the electron velocity becomes arbitrarily close to the
speed of light.
guiding-center
approximation in
gravitational ﬁeld
When a uniform, time-independent gravitational ﬁeld g accompanies a uniform,
time-independent magnetic ﬁeld B, its effect on an electron will be the same as that
20.7 Particle Motion and Adiabatic Invariants
1025

B
v
v
E
proton
electron
FIGURE 20.4 The proton motion (upper trajectory) and electron motion (lower
trajectory) orthogonal to the magnetic ﬁeld, when there are constant electric and
magnetic ﬁelds with |E × B| < B2c. Each electron and proton moves in a circle
with a superposed drift velocity vD given by Eq. (20.47).
of an electric ﬁeld Eequivalent = −(me/e)g: The electron’s guiding center will acquire
a drift velocity
vD = −me
e
g × B
B2 ,
(20.48)
and similarly for a proton. This gravitational drift velocity is typically very small.
20.7.3
20.7.3 Inhomogeneous, Time-Independent Magnetic Field
When the electric ﬁeld vanishes, but the magnetic ﬁeld is spatially inhomogeneous
and time-independent, and the inhomogeneity scale is large compared to the Larmor
radius rL of the electron’s orbit, the electron motion again is nicely described in terms
of a guiding center.
First consider the effects of a curvature of the ﬁeld lines (Fig. 20.5a). Suppose that
thespeedoftheelectronalongtheﬁeldlinesisv||.Wecanthinkofthisasalongitudinal
guiding-center motion. As the ﬁeld lines bend in, say, the direction of the unit vector
n with radius of curvature R, this longitudinal guiding-center motion experiences the
acceleration a = v2
||n/R. That acceleration is equivalent to the effect of an electric ﬁeld
curvature drift
Eeffective = (−me/e)v2
||n/R, and it therefore produces a transverse drift of the guiding
center with vD = (Eeffective × B)/B2. Since the curvature R of the ﬁeld line and the
direction n of its bend are given by B−2(B . ∇)B = n/R, this curvature drift velocity is
vD = −
mev2
||
e
B × (B . ∇)B
B4
.
(20.49)
Notice that the magnitude of this drift is
vD = rL
R
v||
v⊥
v||.
(20.50)
This particle drift and others discussed below also show up as ﬂuid drifts in a mag-
netized plasma; see Ex. 21.1.
1026
Chapter 20. The Particle Kinetics of Plasma

B
B
B
n
vD
vD
out of paper
 α = 0
 α
mirror point
(b)
(c)
(a)
large B
rB
small B
FIGURE 20.5 An electron’s motion in a time-independent, inhomogeneous magnetic ﬁeld. (a) The
drift induced by the curvature of the ﬁeld lines. (b) The drift induced by a transverse gradient of the
magnitude of the magnetic ﬁeld. (c) The change in electron pitch angle induced by a longitudinal
gradient of the magnitude of the magnetic ﬁeld.
A second kind of inhomogeneity is a transverse spatial gradient ∇B of the mag-
gradient drift
nitude of B. As is shown in Fig. 20.5b, such a gradient causes the electron’s circular
motion to be tighter (smaller radius of curvature of the circle) in the region of larger
B than in the region of smaller B; this difference in radii of curvature clearly induces
a drift. It is straightforward to show that the resulting gradient drift velocity is
vD = −mev2
⊥
2e
B × ∇B
B3
.
(20.51)
The third and ﬁnal kind of inhomogeneity is a longitudinal gradient of the magni-
effects of longitudinal
gradient of BBB
tude of B (Fig. 20.5c). Such a gradient results from the magnetic ﬁeld lines converging
toward (or diverging away from) one another. The effect of this convergence (or diver-
gence)ismosteasilyinferredinaframethatmoveslongitudinallywiththeelectron.In
such a frame the magnetic ﬁeld changes with time, ∂B′/∂t ̸= 0, and correspondingly,
the resultant electric ﬁeld satisﬁes ∇× E′ = −∂B′/∂t. The kinetic energy of the elec-
tron as measured in this longitudinally moving frame is the same as the transverse
energy 1
2mev2
⊥in the original frame. This kinetic energy is forced to change by the
electric ﬁeld E′. The change in energy during one circuit around the magnetic ﬁeld is

1
2mev2
⊥

= −e
E
E′ . d l = e
 ∂B′
∂t
. dA = e
 ωc
2π B

πr2
L = mev2
⊥
2
B
B .
(20.52)
Here the second expression in the equation involves a line integral once around the
electron’s circular orbit. The third expression involves a surface integral over the
interior of the orbit and has ∂B′/∂t parallel to dA. In the fourth the time derivative of
the magnetic ﬁeld has been expressed as (ωc/(2π))B, where B is the change in
magnetic ﬁeld strength along the electron’s guiding center during one circular orbit.
Equation (20.52) can be rewritten as a conservation law along the world line of
the electron’s guiding center:
mev2
⊥
2B
= const.
(20.53)
20.7 Particle Motion and Adiabatic Invariants
1027

Notice that the conserved quantity mev2
⊥/(2B) is proportional to the total magnetic
conservation of enclosed
ﬂux (i.e., of magnetic
moment)
ﬂux threading the electron’s circular orbit, πr2
LB. Thus the electron moves along
the ﬁeld lines in such a manner as to keep constant the magnetic ﬂux enclosed
in its orbit; see Fig. 20.5c. A second interpretation of Eq. (20.53) is in terms of
the magnetic moment created by the electron’s circulatory motion. That moment is
μ = −mev2
⊥/(2B2)B, and its magnitude is the conserved quantity
μ = mev2
⊥
2B
= const.
(20.54)
An important consequence of the conservation law (20.54) is a gradual change in
the electron’s pitch angle,
pitch angle of electron
orbit
α ≡tan−1(v||/v⊥),
(20.55)
as it spirals along the converging ﬁeld lines. Because there is no electric ﬁeld in the
original frame, the electron’s total kinetic energy is conserved in that frame:
Ekin = 1
2me(v2
|| + v2
⊥) = const.
(20.56)
This expression, together with the constancy of μ = mev2
⊥/(2B) and the deﬁnition of
the electron pitch angle [Eq. (20.55)], implies that the pitch angle varies with magnetic
ﬁeld strength as
variation of pitch angle
along guiding center
tan2 α = Ekin
μB −1.
(20.57)
Notice that as the ﬁeld lines converge, B increases in magnitude, and α decreases.
Ultimately, when B reaches a critical value Bcrit = Ekin/μ, the pitch angle α goes to
zero. The electron then “reﬂects” off the strong-ﬁeld region and starts moving back
toward weak ﬁelds, with increasing pitch angle. The location at which the electron
reﬂects is called the electron’s mirror point.
mirror point
Figure 20.6 shows two examples of this mirroring. The ﬁrst example is a “magnetic
bottle” (Ex. 20.14). Electrons whose pitch angles at the center of the bottle are sufﬁ-
magnetic bottle
ciently small have mirror points in the bottle and thus cannot leak out. The second
example is the van Allen belts of Earth. Electrons (and also ions) travel up and down
the magnetic ﬁeld lines of the van Allen belts, reﬂecting at mirror points.
It is not hard to show that the gradient of B can be split up into the three pieces
we have studied: a curvature with no change of B = |B| (Fig. 20.5a), a change of B
orthogonal to the magnetic ﬁeld (Fig. 20.5b), and a change of B along the magnetic
ﬁeld (Fig. 20.5c). When (as we have assumed) the lengthscales of these changes are
far greater than the electron’s Larmor radius, their effects on the electron’s motion
superpose linearly.
1028
Chapter 20. The Particle Kinetics of Plasma

B
B
mirror point
mirror point
mirror point
mirror point
(b)
(a)
FIGURE 20.6 Two examples of the mirroring of particles in an inhomogeneous magnetic ﬁeld.
(a) A magnetic bottle. (b) Earth’s van Allen belts.
20.7.4
20.7.4 A Slowly Time-Varying Magnetic Field
When the magnetic ﬁeld changes on timescales long compared to the cyclotron pe-
riod 2π/ωc, its changes induce alterations of the electron’s orbit that can be deduced
with the aid of adiabatic invariants—quantities that are nearly constant when the ﬁeld
adiabatic invariants
changes adiabatically, in other words, slowly (see, e.g., Lifshitz and Pitaevskii, 1981;
Northrop, 1963). The conserved magnetic moment μ = mev2
⊥/(2B) associated with
an electron’s transverse, circular motion is an example of an adiabatic invariant. We
proved its invariance in Eqs. (20.52) and (20.53) (in Sec. 20.7.3, where we were work-
ing in a reference frame in which the magnetic ﬁeld changed slowly, and associated
with that change was a weak electric ﬁeld). This adiabatic invariant can be shown to
magnetic moment as
circular-motion action
be, aside from a constant multiplicative factor 2πme/e, the action associated with
the electron’s circular motion: Jφ =
.
pφdφ. Here φ is the angle around the circu-
lar orbit, and pφ = (mev⊥−eAφ)rL is the φ component of the electron’s canonical
momentum. The action Jφ is a well-known adiabatic invariant.
When a slightly inhomogeneous magnetic ﬁeld varies slowly in time, not only is
μ = mev2
⊥/(2B) adiabatically invariant (conserved), so also are two other actions.
One is the action associated with motion from one mirror point of the magnetic ﬁeld
to another and back:
longitudinal, mirror-point
action
J|| =
E
p|| . d l.
(20.58)
Here p|| = mev|| −eA|| = mev|| is the generalized (canonical) momentum along the
ﬁeld line, and d l is distance along the ﬁeld line. Thus the adiabatic invariant is the
spatial average ⟨v||⟩of the longitudinal speed of the electron, multiplied by me and
twice the distance l between mirror points: J|| = 2me⟨v||⟩l.
guiding-center-drift action
The other (third) adiabatic invariant is the action associated with the drift of
the guiding center: an electron mirroring back and forth along the ﬁeld lines drifts
sideways, and by its drift it traces out a 2-dimensional surface to which the magnetic
20.7 Particle Motion and Adiabatic Invariants
1029

ﬁeld is tangent (e.g., the surface of the center of the magnetic bottle in Fig. 20.6a,
rotated around the horizontal axis). The action of the electron’s drift around this
magnetic surface turns out to be proportional to the total magnetic ﬂux enclosed
by the surface. Thus, if the ﬁeld geometry changes slowly, the magnetic ﬂux enclosed
by the magnetic surface on which the electron’s guiding center moves is adiabatically
conserved.
How nearly constant are the adiabatic invariants? The general theory of adiabatic
accuracy of adiabatic
invariants
invariants shows that, so long as the temporal changes of the magnetic ﬁeld structure
aresmoothenoughtobedescribedbyanalyticfunctionsoftime, thefractionalfailures
of the adiabatic invariants to be conserved are of order e−τ/P. Here τ is the timescale
on which the ﬁeld changes, and P is the period of the motion associated with the
adiabatic invariant. (This period P is 2π/ωc for the invariant μ; it is the mirroring
period for the longitudinal action, and it is the drift period for the magnetic ﬂux
enclosed in the electron’s magnetic surface.) Because the exponential e−τ/P dies out
so quickly with increasing timescale τ, the adiabatic invariants are conserved to very
high accuracy when τ ≫P .
20.7.5
20.7.5 Failure of Adiabatic Invariants; Chaotic Orbits
When the magnetic ﬁeld changes as fast as or more rapidly than a cyclotron orbit (in
space or in time), then the adiabatic invariants fail, and the charged-particle orbits
may even be chaotic in some cases.
failure of adiabatic
invariants and chaotic
motion near a magnetic
neutral line
An example is charged-particle motion near a neutral line (also called an X-
line) of a magnetic ﬁeld. Near an X-line, the ﬁeld has the hyperbolic shape B =
B0(y ex + γ x ey) with constants B0 and γ ; see Fig. 19.13 for an example that occurs
inmagnetic-ﬁeld-linereconnection.TheX-lineisthez-axis, (x, y) = (0, 0), onwhich
the ﬁeld vanishes. Near there the Larmor radius becomes arbitrarily large, far larger
than the scale on which the ﬁeld changes. Correspondingly, no adiabatic invariants
exist near the X-line, and it turns out that some charged-particle orbits near there
are chaotic in the sense of extreme sensitivity to initial conditions (Sec. 15.6.4). An
electric ﬁeld in the ez direction (orthogonal to B and parallel to the X-line) enhances
the chaos (for details, see, e.g., Martin, 1986).
EXERCISES
Exercise 20.14 Example: Mirror Machine
One method for conﬁning hot plasma is to arrange electric coils so as to make a mirror
machine in which the magnetic ﬁeld has the geometry sketched in Fig. 20.6a. Suppose
that the magnetic ﬁeld in the center is 1 T and the ﬁeld strength at the two necks is
10 T, and that plasma is introduced with an isotropic velocity distribution near the
center of the bottle.
(a) What fraction of the plasma particles will escape?
(b) Sketch the pitch-angle distribution function for the particles that remain.
1030
Chapter 20. The Particle Kinetics of Plasma

B
E
e3
d
ring
ring
cap
cap
FIGURE 20.7 Penning trap for localizing individual charged particles.
The magnetic ﬁeld is uniform and parallel to the vertical axis of
symmetry ez. The electric ﬁeld is maintained between a pair of
hyperboloidal caps and a hyperboloidal ring.
(c) Suppose that Coulomb collisions cause particles to diffuse in pitch angle α with
a diffusion coefﬁcient
Dαα ≡
?α2
t
@
= t−1
D .
(20.59)
Estimate how long it will take most of the plasma to escape the mirror machine.
(d) What do you suspect will happen in practice?
Exercise 20.15 Challenge: Penning Trap
Aclevertechniqueforstudyingthebehaviorofindividualelectronsorionsistoentrap
themusingacombinationofelectricandmagneticﬁelds.Oneofthesimplestandmost
useful devices is the Penning trap (see, e.g., Brown and Gabrielse, 1986). Basically this
comprises a uniform magnetic ﬁeld B combined with a hyperboloidal electrostatic
ﬁeld that is maintained between hyperboloidal electrodes as shown in Fig. 20.7. The
electrostatic potential has the form (x) = 0(z2 −x2/2 −y2/2)/(2d2), where 0
is the potential difference maintained across the electrodes, and d is the minimum
axial distance from the origin to the hyperboloidal cap (as well as being 1/
√
2 times
the minimum radius of the ring electrode).
(a) Show that the potential satisﬁes Laplace’s equation, as it must.
(b) Now consider an individual charged particle in the trap. Show that three separate
oscillations can be excited:
(i) cyclotron orbits in the magnetic ﬁeld with angular frequency ωc,
(ii) “magnetron” orbits produced by E × B drift around the axis of symmetry
with angular frequency ωm (which you should compute), and
20.7 Particle Motion and Adiabatic Invariants
1031

(iii) axial oscillations parallel to the magnetic ﬁeld with angular frequency ωz
(which you should also compute).
Assume that ωm ≪ωz ≪ωc, and show that ω2
z ≃2ωmωc.
(c) Typically, the potential difference across the electrodes is ∼10 V, the magnetic
ﬁeld strength is B ∼6 T, and the radius of the ring and the height of the caps
above the center of the traps are ∼3 mm. Estimate the three independent angular
frequencies for electrons and ions, verifying the ordering ωm ≪ωz ≪ωc. Also
estimate the maximum velocities associated with each of these oscillations if the
particle is to be retained in the trap.
(d) Solve the classical equation of motion exactly, and demonstrate that the mag-
netron motion is formally unstable.
Penning traps have been used to perform measurements of the electron-proton mass
ratio and the magnetic moment of the electron with unprecedented precision.
Bibliographic Note
For a thorough treatment of the particle kinetics of plasmas, see Shkarofsky, John-
ston, and Bachynski (1966). For less detailed treatments, we recommend the relevant
portions of Spitzer (1962), Bittencourt (2004), and Bellan (2006).
For applications of the Fokker-Planck equation to Coulomb scattering in plasmas,
we like Shkarofsky, Johnston, and Bachynski (1966, Chaps. 7 and 8), Boyd and
Sanderson (2003, Chap. 8), Kulsrud (2005, Chap. 8), and Bellan (2006, Chap. 13).
For charged-particle motion in inhomogeneous and time-varying magnetic ﬁelds,
we recommend Northrop (1963); Jackson (1999, Chap. 12), which is formulated using
special relativity; Bittencourt (2004, Chaps. 2–4); and Bellan (2006, Chap. 3).
1032
Chapter 20. The Particle Kinetics of Plasma

21
CHAPTER TWENTY-ONE
Waves in Cold Plasmas: Two-Fluid Formalism
Waves from moving sources: Adagio. Andante. Allegro moderato.
OLIVER HEAVISIDE (1912)
21.1
21.1 Overview
The growth of plasma physics came about, in the early twentieth century, through
studies of oscillations in electric discharges and the contemporaneous development
of means to broadcast radio waves over great distances by reﬂecting them off Earth’s
ionosphere. It is therefore not surprising that most early plasma-physics research was
devoted to describing the various modes of wave propagation. Even in the simplest,
linear approximation for a plasma sufﬁciently cold that thermal effects are unimpor-
tant, we will see that the variety of possible modes is immense.
Inthepreviouschapter, weintroducedseverallength-andtimescales, mostimpor-
tantly the Larmor (gyro) radius, the Debye length, the plasma period, the cyclotron
(gyro) period, the collision time (inverse collision frequency), and the equilibration
times (inverse collision rates). To these we must now add the wavelength and period
of the wave under study. The wave’s characteristics are controlled by the relative sizes
of these parameters, and in view of the large number of parameters, there is a bewil-
dering number of possibilities. If we further recognize that plasmas are collisionless,
so there is no guarantee that the particle distribution functions can be characterized
by a single temperature, then the possibilities multiply further.
Fortunately, the techniques needed to describe the propagation of linear wave per-
turbations in a particular equilibrium conﬁguration of a plasma are straightforward
and can be amply illustrated by studying a few simple cases. In this chapter, we fol-
low this course by restricting our attention to one class of modes, those where we can
either ignore completely the thermal motions of the ions and electrons that compose
the plasma (i.e., treat these species as cold) or include them using just a velocity disper-
sion or temperature. We can then apply our knowledge of ﬂuid dynamics by treating
the ions and electrons separately as ﬂuids acted on by electromagnetic forces. This is
called the two-ﬂuid formalism for plasmas. In the next chapter, we explore when and
how waves are sensitive to the actual distribution of particle speeds by developing
1033

BOX 21.1.
READERS’ GUIDE
.
This chapter relies signiﬁcantly on:
– Chap. 20 on the particle kinetics of plasmas;
– the basic concepts of ﬂuid dynamics, Secs. 13.4 and 13.5;
– magnetosonic waves, Sec. 19.7; and
– the basic concepts of geometric optics, Secs. 7.2 and 7.3.
.
The remaining Chaps. 22 and 23 of Part VI rely heavily on this
chapter.
the more sophisticated kinetic-theory formalism and using it to study waves in warm
plasmas.
We begin our two-ﬂuid study of plasma waves in Sec. 21.2 by deriving a very
general wave equation, which governs weak waves in a homogeneous plasma that
may or may not have a magnetic ﬁeld and also governs electromagnetic waves in any
other dielectric medium. That wave equation and the associated dispersion relation
for the wave modes depend on a dielectric tensor, which must be derived from an
examination of the motions of the electrons and protons (or other charge carriers)
inside the wave. Those motions are described, in our two-ﬂuid (electron-ﬂuid and
proton-ﬂuid) model by equations that we write down in Sec. 21.3.
In Sec. 21.4, we use those two-ﬂuid equations to derive the dielectric tensor, and
then we combine with our general wave equation from Sec. 21.2 to obtain the dis-
persion relation for wave modes in a uniform, unmagnetized plasma. The modes
fall into two classes: (i) Transverse or electromagnetic waves, with the electric ﬁeld
E perpendicular to the wave’s propagation direction. These are modiﬁed versions of
electromagnetic waves in vacuum. As we shall see, they can propagate only at fre-
quencies above the plasma frequency; at lower frequencies they become evanescent.
(ii) Longitudinal waves, with E parallel to the propagation direction, which come in
two species: Langmuir waves and ion-acoustic waves.Longitudinal waves are a melded
combination of sound waves in a ﬂuid and electrostatic plasma oscillations; their
restoring force is a mixture of thermal pressure and electrostatic forces.
In Sec. 21.5, we explore how a uniform magnetic ﬁeld changes the character of
these waves. The B ﬁeld makes the plasma anisotropic but axially symmetric. As
a result, the dielectric tensor, dispersion relation, and wave modes have much in
common with those in an anisotropic but axially symmetric dielectric crystal, which
we studied in the context of nonlinear optics in Chap. 10. A plasma, however, has
a much richer set of characteristic frequencies than does a crystal (electron plasma
frequency, electron cyclotron frequency, ion cyclotron frequency, etc.). As a result,
1034
Chapter 21. Waves in Cold Plasmas: Two-Fluid Formalism

even in the regime of weak linear waves and a cold plasma (no thermal pressure), the
plasma has a far greater richness of modes than does a crystal.
In Sec. 21.5.1, we derive the general dispersion relation that encompasses all these
cold-magnetized-plasma modes, and in Secs. 21.5.2 and 21.5.3, we explore the special
cases of modes that propagate parallel to and perpendicular to the magnetic ﬁeld.
Then in Sec. 21.5.4, we examine a practical example: the propagation of radio waves
in Earth’s ionosphere, where it is a good approximation to ignore the ion motion
and work with a one-ﬂuid (i.e., electron-ﬂuid) theory. Having gained insight into
simple cases (parallel modes, perpendicular modes, and one-ﬂuid modes), we return
in Sec. 21.5.5 to the full class of linear modes in a cold, magnetized, two-ﬂuid plasma
and brieﬂy describe some tools by which one can make sense of them all.
Finally, in Sec. 21.6, we turn to the question of plasma stability. In Sec. 14.6.1 and
Chap. 15, we saw that ﬂuid ﬂows that have sufﬁcient shear are unstable; perturbations
can feed off the relative kinetic energy of adjacent regions of the ﬂuid and use that
energy to power an exponential growth. In plasmas, with their long mean free paths,
there can similarly exist kinetic energies of relative, ordered motion in velocity space;
and perturbations, feeding off those energies, can grow exponentially. To study this
phenomenon in full requires the kinetic-theory description of a plasma, which we
developinChap.22; butinSec.21.6wegaininsightintoaprominentexampleofsucha
velocity-space instability by analyzing two cold plasma streams moving through each
other. We illustrate the resulting two-stream instability by a short discussion of particle
beams that are created in disturbances on the surface of the Sun and propagate out
through the solar wind.
21.2
21.2 Dielectric Tensor, Wave Equation, and General Dispersion Relation
We begin our study of waves in plasmas by deriving a general wave equation that ap-
plies equally well to electromagnetic waves in unmagnetized plasmas; in magnetized
plasmas; and in any other kind of dielectric medium, such as an anisotropic crystal.
This wave equation is the same one we used in our study of nonlinear optics in Chap.
10 [Eqs. (10.50) and (10.51a)], and the derivation is essentially a linearized variant of
the one we gave in Chap. 10 [Eqs. (10.16a)–(10.22b)].
When a wave propagates through a plasma (or other dielectric), it entails a relative
motion of electrons and protons (or other charge carriers). Assuming the wave has
small enough amplitude to be linear, those charge motions can be embodied in an
oscillating polarization (electric dipole moment per unit volume) P(x, t), which is
polarization vector
related to the plasma’s (or dielectric’s) varying charge density ρe and current density
j in the usual way:
ρe = −∇. P,
j = ∂P
∂t .
(21.1)
21.2 Dielectric Tensor, Wave Equation, and General Dispersion Relation
1035

(These relations enforce charge conservation, ∂ρe/∂t + ∇. j = 0.) When these ρe and
j are inserted into the standard Maxwell equations for E and B, one obtains
Maxwell equations
∇. E = −∇. P
ϵ0
,
∇. B = 0,
∇× E = −∂B
∂t ,
∇× B = μ0
∂P
∂t + 1
c2
∂E
∂t .
(21.2)
If the plasma is endowed with a uniform magnetic ﬁeld Bo, that ﬁeld can be left out
of these equations, as its divergence and curl are guaranteed to vanish. Thus we can
regard E, B, and P in these Maxwell equations as the perturbed quantities associated
with the waves.
From a detailed analysis of the response of the charge carriers to the oscillating
E and B ﬁelds, one can deduce a linear (frequency-dependent and wave-vector-
dependent) relationship between the waves’ electric ﬁeld E and the polarization P:
Pj = ϵ0χjkEk.
(21.3)
Here ϵ0 is the vacuum permittivity, and χjk is a dimensionless, tensorial electric
tensorial electric
susceptibility
susceptibility [cf. Eq. (10.21)]. A different, but equivalent, viewpoint on the relation-
ship between P and E can be deduced by taking the time derivative of Eq. (21.3);
setting ∂P/∂t = j; assuming a sinusoidal time variation e−iωt so that ∂E/∂t = −iωE;
and then reinterpreting the result as Ohm’s law with a tensorial electric conductivity
κejk:
tensorial electric
conductivity
jj = κejkEk,
κejk = −iωϵ0χjk.
(21.4)
Evidently, for sinusoidal waves the electric susceptibility χjk and the electric conduc-
tivity κejk embody the same information about the wave-particle interactions.
dielectric tensor
That information is also embodied in a third object: the dimensionless dielectric
tensor ϵjk, which relates the electric displacement D to the electric ﬁeld E:
Dj ≡ϵ0Ej + Pj = ϵ0ϵjkEk,
ϵjk = δjk + χjk = δjk +
i
ϵ0ωκejk.
(21.5)
In the next section, we derive the value of the dielectric tensor ϵjk for waves in an
unmagnetized plasma, and in Sec. 21.4.1, we derive it for a magnetized plasma.
Using the deﬁnition D = ϵ0E + P, we can eliminate P from Eqs. (21.2), thereby
obtaining the familiar form of Maxwell’s equations for dielectric media with no
nonpolarization-based charges or currents:
∇. D = 0,
∇. B = 0,
∇× E = −∂B
∂t ,
∇× B = μ0
∂D
∂t .
(21.6)
By taking the curl of the third of these equations and combining with the fourth and
general wave equation in a
dielectric
with Dj = ϵ0ϵjkEk, we obtain the wave equation that governs the perturbations:
1036
Chapter 21. Waves in Cold Plasmas: Two-Fluid Formalism

∇2E −∇(∇. E) −ϵ . 1
c2
∂2E
∂t2 = 0,
(21.7)
where ϵ is our index-free notation for ϵjk. [This is the same as the linearized approxi-
mation Eq. (10.50) to our nonlinear-optics wave equation (10.22a).] Specializing to a
plane-wave mode with wave vector k and angular frequency ω, so E ∝eikxe−iωt, we
convert this wave equation into a homogeneous, algebraic equation for the Cartesian
components of the electric vector Ej (cf. Box 12.2):
algebratized wave
equation
LijEj = 0,
(21.8)
where
algebratized wave
operator
Lij = kikj −k2δij + ω2
c2 ϵij.
(21.9)
We call Eq. (21.8) the algebratized wave equation, and Lij the algebratized wave
operator.
The algebratized wave equation (21.8) can have a solution only if the determinant
of the 3-dimensional matrix Lij vanishes:
general dispersion relation
for electromagnetic waves
in a dielectric medium
det||Lij|| ≡det
8888
8888kikj −k2δij + ω2
c2 ϵij
8888
8888 .
(21.10)
This is a polynomial equation for the angular frequency as a function of the wave
vector (with ω and k appearing not only explicitly in Lij but also implicitly in the
functional form of ϵjk). Each solution ω(k) of this equation is the dispersion relation
for a particular wave mode. Therefore, we can regard Eq. (21.10) as the general
dispersion relation for plasma waves—and for linear electromagnetic waves in any
other kind of dielectric medium.
To obtain an explicit form of the dispersion relation (21.10), we must give a
prescription for calculating the dielectric tensor ϵij(ω, k), or equivalently [cf. Eq.
(21.5)] the conductivity tensor κe ij or the susceptibility tensor χij. The simplest
prescription involves treating the electrons and ions as independent ﬂuids; so we
digress, brieﬂy, from our discussion of waves to present the two-ﬂuid formalism for
plasmas.
21.3
21.3 Two-Fluid Formalism
two-ﬂuid formalism
A plasma necessarily contains rapidly moving electrons and ions, and their individual
responses to an applied electromagnetic ﬁeld depend on their velocities. In the sim-
plest model of these responses, we average over all the particles in a species (electrons
or protons in this case) and treat them collectively as a ﬂuid. Now, the fact that all
the electrons are treated as one ﬂuid does not mean that they have to collide with one
21.3 Two-Fluid Formalism
1037

another. In fact, as we have already emphasized in Chap. 20, electron-electron colli-
sions are quite rare, and we can usually ignore them. Nevertheless, we can still deﬁne
a mean ﬂuid velocity for both the electrons and the protons by averaging over their
total velocity distribution functions just as we would for a gas:
mean ﬂuid velocity
us = ⟨v⟩s;
s = p, e,
(21.11)
where the subscripts p and e refer to protons and electrons. Similarly, for each ﬂuid
we deﬁne a pressure tensor using the ﬂuid’s dispersion of particle velocities:
pressure tensor
Ps = nsms⟨(v −us) ⊗(v −us)⟩
(21.12)
[cf. Eqs. (20.34) and (20.35)].
The density ns and mean velocity us of each species s must satisfy the equation of
continuity (particle conservation):
particle conservation
∂ns
∂t + ∇. (nsus) = 0.
(21.13a)
They must also satisfy an equation of motion: the law of momentum conservation
(i.e., the Euler equation with the Lorentz force added to the right-hand side):
momentum conservation
nsms
∂us
∂t + (us . ∇)us

= −∇. Ps + nsqs(E + us × B).
(21.13b)
Here we have neglected the tiny inﬂuence of collisions between the two species. In
these equations and below, qs = ±e is the particles’ charge (positive for protons and
negative for electrons). Note that, as collisions are ineffectual, we cannot assume that
the pressure tensors are isotropic.
Although the particle- and momentum-conservation equations (21.13) for each
species (electron or proton) are formally decoupled from the equations for the other
species, there is actually a strong physical coupling induced by the electromagnetic
ﬁeld. The two species together produce E and B through their joint charge density
and current density:
charge and current density
ρe =
 
s
qsns,
j =
 
s
qsnsus,
(21.14)
and those E and B ﬁelds strongly inﬂuence the electron and proton ﬂuids’ dynamics
via their equations of motion (21.13b).
EXERCISES
Exercise 21.1 Problem: Fluid Drifts in a Magnetized Plasma
We developed a one-ﬂuid (MHD) description of plasma in Chap. 19, and in Chap. 20
we showed how to describe the orbits of individual charged particles in a magnetic
ﬁeld that varies slowly compared with the particles’ orbital periods and radii. In this
1038
Chapter 21. Waves in Cold Plasmas: Two-Fluid Formalism

chapter, we describe the plasma as two or more cold ﬂuids. We relate these three
approaches in this exercise.
(a) Generalize Eq. (21.13b) to a single ﬂuid as:
ρa = ρg −∇. P + ρeE + j × B,
(21.15)
where a is the ﬂuid acceleration, and g is the acceleration of gravity, and write
the pressure tensor as P = P⊥g + (P|| −P⊥)B ⊗B/B2, where we suppress the
subscript s.1 Show that the component of current density perpendicular to the
local magnetic ﬁeld is
j⊥= B × ∇. P
B2
+ ρe
E × B
B2
+ ρ (g −a) × B
B2
.
(21.16a)
(b) Use vector identities to rewrite Eq. (21.16a) in the form:
j⊥= P||
B × (B . ∇)B
B4
+ P⊥
B × ∇B
B3
−(∇× M)⊥+ ρe
E × B
B2
+ ρ (g −a) × B
B2
,
(21.16b)
where
M = P⊥
B
B3
(21.16c)
is the magnetization.
(c) Identify the ﬁrst term of Eq. (21.16b) with the curvature drift (20.49) and the
second term with the gradient drift (20.51).
(d) Using a diagram, explain how the magnetization (20.54)—the magnetic moment
per unit volume—can contribute to the current density. In particular, consider
what might happen at the walls of a cavity containing plasma.2 Argue that there
should also be a local magnetization current parallel to the magnetic ﬁeld, even
when there is no net drift of the particles.
(e) Associate the ﬁnal two terms of Eq. (21.16b) with the “E × B” drift (20.47) and
the gravitational drift (20.48). Explain the presence of the acceleration in the
gravitational drift.
(f) Discuss how to combine these contributions to rederive the standard formulation
of MHD, and specify some circumstances under which MHD might be a poor
approximation.
1.
Note that when writing the pressure tensor this way, we are implicitly assuming that it has only two
components, along and perpendicular to the local magnetic ﬁeld. Physically, this is reasonable if the
particles that make up the ﬂuid are magnetized, i.e., the particles’ orbital periods and radii are short
compared to the scales on which the magnetic ﬁeld changes.
2.
This is an illustration of a general theorem in statistical mechanics due to Niels Bohr in 1911, which
essentially shows that magnetization cannot arise in classical physics. This theorem may have had a role
in the early development of quantum mechanics.
21.3 Two-Fluid Formalism
1039

Note that this single-ﬂuid formalism does not describe the component of the current
parallel to the magnetic ﬁeld, j||. For this, we need to introduce an effective collision
frequency for the electrons and ions either with waves (Chap. 23) or with other
particles (Chap. 20). If we assume that the electrical conductivity is perfect, then
E . B = 0, and j|| is essentially ﬁxed by the boundary conditions.
21.4
21.4 Wave Modes in an Unmagnetized Plasma
We now specialize to waves in a homogeneous, unmagnetized electron-proton
plasma.
First consider an unperturbed plasma in the absence of a wave, and work in a
unperturbed plasma
frame in which the proton ﬂuid velocity up vanishes. By assumption, the equilibrium
is spatially uniform. If there were an electric ﬁeld, then charges would quickly ﬂow to
neutralize it; so there can be no electric ﬁeld, and hence (since ∇. E = ρe/ϵ0) no
net charge density. Therefore, the electron density must equal the proton density.
Furthermore, there can be no net current, as this would lead to a magnetic ﬁeld; so
since the proton current e npup vanishes, the electron current = −e neue must also
vanish. Hence the electron ﬂuid velocity ue must vanish in our chosen frame. Thus
in an equilibrated homogeneous, unmagnetized plasma, ue, up, E, and B all vanish in
the protons’ mean rest frame.
Now apply an electromagnetic perturbation. This will induce a small, oscillating
ﬂuid velocity us in both the proton and electron ﬂuids. It should not worry us that the
ﬂuid velocity is small compared with the random speeds of the constituent particles;
the same is true in any subsonic gas dynamical ﬂow, but the ﬂuid description remains
good there and also here.
21.4.1
21.4.1 Dielectric Tensor and Dispersion Relation for a Cold, Unmagnetized Plasma
Continuing to keep the plasma unmagnetized, let us further simplify matters (until
Sec. 21.4.3) by restricting ourselves to a cold plasma, so the tensorial pressures vanish:
Ps = 0. As we are only interested in linear wave modes, we rewrite the two-ﬂuid
equations (21.13), just retaining terms that are ﬁrst order in perturbed quantities [i.e.,
dropping the (us . ∇)us and us × B terms]. Then, focusing on a plane-wave mode,
∝exp[i(k . x −ωt)], we bring the equation of motion (21.13b) into the form
linearized perturbative
equation of motion
−iωnsmsus = qsnsE
(21.17)
for each species, s = p, e. From this, we can immediately deduce the linearized
current density:
j =
 
s
nsqsus =
 
s
insq2
s
msω E,
(21.18)
1040
Chapter 21. Waves in Cold Plasmas: Two-Fluid Formalism

from which we infer that the conductivity tensor κe has Cartesian components
κe ij =
 
s
insq2
s
msω δij,
(21.19)
where δij is the Kronecker delta. Note that the conductivity is purely imaginary, which
means that the current oscillates out of phase with the applied electric ﬁeld, which
in turn implies that there is no time-averaged ohmic energy dissipation: ⟨j . E⟩= 0.
Inserting the conductivity tensor (21.19) into the general equation (21.5) for the
dielectric tensor, we obtain
ϵij = δij +
i
ϵ0ωκe ij =
*
1 −
ω2
p
ω2
+
δij.
(21.20)
Here and throughout this chapter, the plasma frequency ωp is slightly different from
that used in Chap. 20: it includes a tiny (1/1,836) correction due to the motion of the
protons, which we neglected in our analysis of plasma oscillations in Sec. 20.3.3:
plasma frequency
ω2
p =
 
s
nsq2
s
msϵ0
= ne2
meϵ0
*
1 + me
mp
+
= ne2
μϵ0
,
(21.21)
where μ is the reduced mass μ = memp/(me + mp). Note that because there is no
physical source of a preferred direction in the plasma, the dielectric tensor (21.20) is
isotropic.
Now, without loss of generality, let the waves propagate in the z direction, so
k = kez. Then the algebratized wave operator (21.9), with ϵ given by Eq. (21.20), takes
the following form:
algebratized wave
operator and general
dispersion relation
for waves in a cold,
unmagnetized plasma
Lij = ω2
c2
⎛
⎜⎜⎜⎜⎜⎜⎝
1 −c2k2
ω2 −
ω2
p
ω2
0
0
0
1 −c2k2
ω2 −
ω2
p
ω2
0
0
0
1 −
ω2
p
ω2
⎞
⎟⎟⎟⎟⎟⎟⎠
.
(21.22)
The corresponding dispersion relation det||Ljk|| = 0 [Eq. (21.10)] becomes
*
1 −c2k2
ω2 −
ω2
p
ω2
+2 *
1 −
ω2
p
ω2
+
= 0.
(21.23)
This is a polynomial equation of order 6 for ω as a function of k, so formally there
are six solutions corresponding to three pairs of modes propagating in opposite
directions.
Two of the pairs of modes are degenerate with frequency
ω =

ω2
p + c2k2.
(21.24)
21.4 Wave Modes in an Unmagnetized Plasma
1041

These are called plasma electromagnetic modes, and we study them in the next sub-
plasma electromagnetic
modes
section. The remaining pair of modes exist at a single frequency:
ω = ωp.
(21.25)
These must be the electrostatic plasma oscillations that we studied in Sec. 20.3.3
electrostatic plasma
oscillations
(though now with an arbitrary wave number k, while in Sec. 20.3.3 the wave number
was assumed to be zero). In Sec. 21.4.3, we show that this is so and explore how these
plasma oscillations are modiﬁed by ﬁnite-temperature effects.
21.4.2
21.4.2 Plasma Electromagnetic Modes
To learn the physical nature of the modes with dispersion relation ω =

ω2
p + c2k2
properties of plasma
electromagnetic modes
[Eq.(21.24)], wemustexaminethedetailsoftheirelectric-ﬁeldoscillations, magnetic-
ﬁeld oscillations, and electron and proton motions. A key to this is the algebratized
wave equation LijEj = 0, with Lij specialized to the dispersion relation (21.24):
||Lij|| = diag[0, 0, (ω2 −ω2
p)/c2]. In this case, the general solution to LijEj = 0
is an electric ﬁeld that lies in the x-y plane (transverse plane) and that therefore
is orthogonal to the waves’ propagation vector k = kez. The third of the Maxwell
transverse electric and
magnetic ﬁelds
equations (21.2) implies that the magnetic ﬁeld is
B = (k/ω) × E,
(21.26)
which also lies in the transverse plane and is orthogonal to E. Evidently, these modes
are close analogs of electromagnetic waves in vacuum; correspondingly, they are
known as the plasma’s electromagnetic modes. The electron and proton motions in
these modes, as given by Eq. (21.17), are oscillatory displacements in the direction of
E but are out of phase with E. The amplitudes of the ﬂuid motions, at ﬁxed electric-
ﬁeld amplitude, vary as 1/ω; when ω decreases, the ﬂuid amplitudes grow.
The dispersion relation for these modes, Eq. (21.24), implies that they can only
propagate (i.e., have real angular frequency when the wave vector is real) if ω exceeds
the plasma frequency. As ω is decreased toward ωp, k approaches zero, so these modes
become electrostatic plasma oscillations with arbitrarily long wavelength orthogonal
to the oscillation direction (i.e., they become a spatially homogeneous variant of the
plasmaoscillationsstudiedinSec.20.3.3).Atω < ωp thesemodesbecomeevanescent.
In their regime of propagation, ω > ωp, these cold-plasma electromagnetic waves
have a phase velocity given by
phase velocity
Vph = ω
k
ˆk = c
*
1 −
ω2
p
ω2
+−1/2
ˆk,
(21.27a)
where ˆk ≡k/k is a unit vector in the propagation direction. Although this phase
velocity exceeds the speed of light, causality is not violated, because information (and
energy) propagate at the group velocity, not the phase velocity. The group velocity is
readily shown to be
1042
Chapter 21. Waves in Cold Plasmas: Two-Fluid Formalism

Vg = ∇k ω = c2k
ω = c
*
1 −
ω2
p
ω2
+1/2
ˆk,
(21.27b)
which is less than c as it must be.
group velocity
These cold-plasma electromagnetic modes transport energy and momentum just
like wave modes in a ﬂuid. There are three contributions to the waves’ mean (time-
averaged) energy density: the electric, the magnetic, and the kinetic-energy densities.
(If we had retained the pressure, then an additional contribution would come from
the internal energy.) To compute these mean energy densities, we must form the
time average of products of physical quantities. Now, we have used the complex
representation to denote each of our oscillating quantities (e.g., Ex), so we must be
careful to remember that A = aei(k.x−ωt) is an abbreviation for the real part of this
quantity—which is the physical A. It is easy to show (Ex. 21.3) that the time-averaged
value of the physical A times the physical B (which we shall denote by ⟨AB⟩) is given
in terms of their complex amplitudes by
time-averaged product
in terms of complex
amplitudes
⟨AB⟩= AB∗+ A∗B
4
,
(21.28)
where * denotes a complex conjugate.
Using Eqs. (21.26) and (21.27a), we can write the magnetic energy density in
the form ⟨B2⟩/(2μ0) = (1 −ω2
p/ω2)ϵ0⟨E2⟩/2. Using Eq. (21.17), the particle kinetic
energy is !
s nsms⟨u2
s⟩/2 = (ω2
pe/ω2)ϵ0⟨E2⟩/2. Summing these contributions and
using Eq. (21.28), we obtain
energy density
U = ϵ0EE∗
4
+ BB∗
4μ0
+
 
s
nsmsusu∗
s
4
= ϵ0EE∗
2
.
(21.29a)
The mean energy ﬂux in the wave is carried (to quadratic order) by the electro-
magnetic ﬁeld and is given by the Poynting ﬂux. (The kinetic energy ﬂux vanishes to
this order.) A straightforward calculation gives
energy ﬂux
FEM = ⟨E × B⟩= E × B∗+ E∗× B
4
= EE∗k
2μ0ω
= UVg,
(21.29b)
where we have used μ0 = c−2ϵ−1
0 . We therefore ﬁnd that the energy ﬂux is the product
of the energy density and the group velocity, as is true quite generally (cf. Sec. 6.3). (If
it were not true, then a localized wave packet, which propagates at the group velocity,
would move along a different trajectory from its energy, and we would wind up with
energy in regions with vanishing amplitude!)
21.4 Wave Modes in an Unmagnetized Plasma
1043

EXERCISES
Exercise 21.2 Derivation: Phase and Group Velocities for Electromagnetic Modes
Derive Eqs. (21.27) for the phase and group velocities of electromagnetic modes in a
plasma.
Exercise 21.3 Derivation: Time-Averaging Formula
Verify Eq. (21.28).
Exercise 21.4 Problem: Collisional Damping in an Electromagnetic Wave Mode
Consider a transverse electromagnetic wave mode propagating in an unmagnetized,
partially ionized gas in which the electron-neutral collision frequency is νe. Include
the effects of collisions in the electron equation of motion (21.17), by introducing
a term −nemeνeue on the right-hand side. Ignore ion motion and electron-ion and
electron-electron collisions.
Derive the dispersion relation when ω ≫νe, and show by explicit calculation that
the rate of loss of energy per unit volume (−∇. FEM, where FEM is the Poynting ﬂux)
is balanced by the Ohmic heating of the plasma. [Hint: It may be easiest to regard ω
as real and k as complex.]
21.4.3
21.4.3 Langmuir Waves and Ion-Acoustic Waves in Warm Plasmas
For our case of a cold, unmagnetized plasma, the third pair of modes embodied in
the dispersion relation (21.23) only exists at a single frequency, the plasma frequency:
ω = ωp. These modes’ wave equation LijEj = 0 with ||Lij|| = diag(−k2, −k2, 0)
longitudinal electrostatic
plasma oscillations
[Eq. (21.22) with ω2 = ω2
p] implies that E points in the z direction (i.e., along k,
which is to say the longitudinal direction). Maxwell’s equations then imply B = 0,
and the equation of motion (21.17) implies that the ﬂuid displacements are also in the
direction of E—the longitudinal direction. Clearly, these modes, like electromagnetic
modesinthelimitk = 0andω = ωp, areelectrostaticplasmaoscillations.However, in
this case, where the spatial variations of E and us are along the direction of oscillation
instead of perpendicular to it, k is not constrained to vanish; instead, all wave numbers
are allowed. This means that the plasma can undergo plane-parallel oscillations at
ω = ωp with displacements in some Cartesian z direction and with any arbitrary z-
dependent amplitude that one might wish. But these oscillations cannot transport
energy: because ω is independent of k, their group velocity, Vg = ∇k ω, vanishes.
Their phase velocity, Vph = (ωp/k)ˆk, by contrast, is ﬁnite.
ﬁnite temperature
converts longitudinal
plasma oscillations into
Langmuir waves
So far, we have conﬁned ourselves to wave modes in cold plasmas. When thermal
motions are turned on, the resulting thermal pressure gradients convert longitudinal
plasma oscillations, at ﬁnite wave number k, into propagating, energy-transporting,
longitudinal modes called Langmuir waves.3 As we have already intimated, because
3.
The chemist Irving Langmuir observed these waves and introduced the name “plasma” for ionized gas
in 1927.
1044
Chapter 21. Waves in Cold Plasmas: Two-Fluid Formalism

the plasma is collisionless, we must turn to kinetic theory (Chap. 22) to understand
thethermaleffectsfully.However, usingthepresentchapter’stwo-ﬂuidformalismand
with the guidance of physical arguments, we can deduce the leading-order effects of
ﬁnite temperature.
In our physical arguments, we assume that the electrons are thermalized with one
anotheratatemperatureTe, theprotonsarethermalizedattemperatureTp, andTe and
Tp maydiffer(becausethetimescaleforelectronsandprotonstoexchangeenergyisso
much longer than the timescales for electrons to exchange energy among themselves
and for protons to exchange energy among themselves; see Sec. 20.4.3).
Physically, the key to the Langmuir waves’ propagation is the warm electrons’
thermal pressure. (The proton pressure is unimportant here, because the protons
oscillate electrostatically with an amplitude that is tiny compared to the electron
amplitude; nevertheless, as we shall see below, the proton pressure is important in
other ways.)
In an adiabatic sound wave in a ﬂuid (where the particle mean free paths are
small compared to the wavelength), we relate the pressure perturbation to the density
perturbation by assuming that the entropy is held constant in each ﬂuid element.
In other words, we write ∇P = C2m∇n, where C = [γ P/(nm)]1/2 is the adiabatic
sound speed, n is the particle density, m is the particle mass, and γ is the adiabatic
index [which is equal to the speciﬁc heat ratio γ = cP/cV (Ex. 5.4)], whose value is
5/3 for a monatomic gas.
However, the electron gas in the plasma we are considering is collisionless on the
short timescale of a perturbation period, and we are only interested in the tensorial
pressure gradient parallel to k (which we take to point in the z direction), δPe zz,z. We
can therefore ignore all electron motion perpendicular to the wave vector, as it is not
coupled to the parallel motion. The electron motion is then effectively 1-dimensional,
since there is only one (translational) degree of freedom. The relevant speciﬁc heat
properties of Langmuir
waves:
at constant volume is therefore just kB/2 per electron, while that at constant pres-
sure is 3kB/2, giving γ = 3.4 The effective sound speed for the electron gas is then
C = (3kBTe/me)1/2, and correspondingly, the perturbations of longitudinal electron
pressure and electron density are related by
perturbations of pressure,
electron density, electron
ﬂuid velocity, and electric
ﬁeld
δPe zz
meδne
= C2 = 3kBTe
me
.
(21.30a)
This is one of the equations governing Langmuir waves. The others are the lin-
earized equation of continuity (21.13a), which relates the electrons’ density perturba-
tion to the longitudinal component of their ﬂuid velocity perturbation:
δne = ne
k
ωue z,
(21.30b)
4.
We derived this longitudinal adiabatic index γ = 3 by a different method in Ex. 20.11e [Eq. (20.36b)]
in the context of a plasma with a magnetic ﬁeld along the longitudinal (or z) direction. It is valid also in
our unmagnetized case, because the magnetic ﬁeld has no inﬂuence on longitudinal electron motions.
21.4 Wave Modes in an Unmagnetized Plasma
1045

the linearized equation of motion (21.13b), which relates ue z and δPe zz to the longi-
tudinal component of the oscillating electric ﬁeld:
−iωnemeue z = −ikδPe zz −neeEz,
(21.30c)
and the linearized form of Poisson’s equation ∇. E = ρe/ϵ0, which relates Ez to δne:
ikEz = −δnee
ϵ0
.
(21.30d)
Equations (21.30) are four equations for three ratios of the perturbed quantities.
By combining these equations, we obtain a condition that must be satisﬁed for them
to have a solution:
Bohm-Gross dispersion
relation
ω2 = ω2
pe + 3kBTe
me
k2 = ω2
pe(1 + 3k2λ2
D).
(21.31)
Here λD =

ϵ0kBTe/(nee2) is the Debye length [Eq. (20.10)]. Equation (21.31) is the
Bohm-Gross dispersion relation for Langmuir waves.
From this dispersion relation, we deduce the phase speed of a Langmuir wave:
phase speed
Vph = ω
k =
kBTe
me
1/2 *
3 +
1
k2λ2
D
+1/2
.
(21.32)
Evidently, when the reduced wavelength λ/(2π) = 1/k is less than or of order the
Debye length (kλD >∼1), the phase speed becomes comparable with the electron
thermal speed. It is then possible for individual electrons to transfer energy between
adjacent compressions and rarefactions in the wave. As we shall see in Sec. 22.3,
when we recover Eq. (21.31) from a kinetic treatment, the resulting energy transfers
damp the wave; this is called Landau damping.Therefore, the Bohm-Gross dispersion
Landau damping
relation is only valid for reduced wavelengths much longer than the Debye length (i.e.,
kλD ≪1; Fig. 21.1).
In our analysis of Langmuir waves we have ignored the proton motion. This is jus-
tiﬁed as long as the proton thermal speeds are small compared to the electron thermal
speeds (i.e., Tp ≪mpTe/me), which will almost always be the case. Proton motion is,
properties of ion-acoustic
waves:
however, not ignorable in a second type of plasma wave that owes its existence to ﬁ-
nite temperature: ion-acoustic waves (also called ion-sound waves). These are waves
thatpropagatewithfrequenciesfarbelowtheelectronplasmafrequency—frequencies
low frequencies; electrons
locked to protons
so low that the electrons remain locked electrostatically to the protons, keeping the
plasma charge neutral and preventing electromagnetic ﬁelds from participating in the
oscillations.AsforLangmuirwaves, wecanderivetheion-acousticdispersionrelation
using ﬂuid theory combined with physical arguments.
Using kinetic theory in the next chapter, we shall see that ion-acoustic waves can
propagate only when the proton temperature is small compared with the electron
temperature: Tp ≪Te; otherwise they are damped. (Such a temperature disparity
1046
Chapter 21. Waves in Cold Plasmas: Two-Fluid Formalism

ω
1—
λD
ωp
ωpp
k
Vph = c
Langmuir
electromagnetic
ion-acoustic
resonance
cutoff
Vph =
kBTe/mp
Vph =
3kBTe/me
1—
λD
Te
—Tp
FIGURE 21.1 Dispersion relations for electromagnetic waves, Langmuir waves, and ion-
acoustic waves in an unmagnetized plasma, whose electrons are thermalized with one
another at temperature Te, and whose protons are thermalized at a temperature Tp that
might not be equal to Te. In the dotted regions the waves are strongly damped, according
to kinetic-theory analyses (Chap. 22). Ion-acoustic waves are wiped out by that damping
at all k unless Tp ≪Te (as is assumed on the horizontal axis), in which case they survive
on the non-dotted part of their curve.
can be produced, e.g., when a plasma passes through a shock wave, and it can be
maintained for a long time because Coulomb collisions are so ineffective at restoring
Tp ∼Te; cf. Sec. 20.4.3.) Because Tp ≪Te, the proton pressure can be ignored, and the
require low proton
temperature; restoring
force is electron pressure
and inertia is proton mass
waves’restoringforceisprovidedbyelectronpressure.Now, inanion-acousticwave—
by contrast with a Langmuir wave—the individual thermal electrons can travel over
many wavelengths during a single wave period, so the electrons remain isothermal
as their mean motion oscillates in lock-step with the protons’ mean motion. Corre-
spondingly, the electrons’ effective (1-dimensional) speciﬁc-heat ratio is γeff = 1.
Although the electrons provide the ion-acoustic waves’ restoring force, the inertia
of the electrostatically locked electrons and protons is almost entirely that of the heavy
protons. Correspondingly, the waves’ phase velocity is
phase velocity
Via =
*
γeffPe
npmp
+1/2
ˆk =
*
kBTe
mp
+1/2
ˆk
(21.33)
(cf. Ex. 21.5), and the dispersion relation is ω = Vphk = (kBTe/mp)1/2k.
From this phase velocity and our physical description of these ion-acoustic
waves, it should be evident that they are the magnetosonic waves of MHD theory
(Sec. 19.7.2), in the limit that the plasma’s magnetic ﬁeld is turned off.
21.4 Wave Modes in an Unmagnetized Plasma
1047

In Ex. 21.5, we show that the character of these waves is modiﬁed when their
wavelength becomes of order the Debye length (i.e., when kλD ∼1). The dispersion
relation then becomes
dispersion relation
ω =
*
kBTe/mp
1 + λ2
Dk2
+1/2
k,
(21.34)
which means that for kλD ≫1, the waves’ frequency approaches the proton plasma
frequency ωpp ≡

ne2/(ϵ0mp) ≃me/mpωp. A kinetic-theory treatment reveals
proton plasma frequency
that these waves are strongly damped when kλD >∼
Te/Tp. These features of the
ion-acoustic dispersion relation are shown in Fig. 21.1.
The regime in which ion-acoustic (magnetosonic) waves can propagate, ω < ωpp,
is quite generally the regime in which the electrons and ions are locked to each other,
MHD regime
making magnetohydrodynamics a good appoximation to the plasma’s dynamics.
EXERCISES
Exercise 21.5 Derivation: Ion-Acoustic Waves
Ion-acoustic waves can propagate in an unmagnetized plasma when the electron
temperature Te greatly exceeds the ion temperature Tp. In this limit, the electron
density ne can be approximated by ne = n0 exp[e/(kBTe)], where n0 is the mean
electron density, and  is the electrostatic potential.
(a) Show that for ion-acoustic waves that propagate in the z direction, the nonlinear
equations of continuity, the motion for the ion (proton) ﬂuid, and Poisson’s
equation for the potential take the form
∂n
∂t + ∂(nu)
∂z
= 0,
∂u
∂t + u∂u
∂z = −e
mp
∂
∂z ,
∂2
∂z2 = −e
ϵ0
2
n −n0ee/(kBTe)3
.
(21.35)
Here n is the proton density, and u is the proton ﬂuid velocity (which points in
the z direction).
(b) Linearize Eqs. (21.35), and show that the dispersion relation for small-amplitude
ion-acoustic modes is
ω = ωpp
*
1 +
1
λ2
Dk2
+−1/2
=
*
kBTe/mp
1 + λ2
Dk2
+1/2
k,
(21.36)
where λD is the Debye length.
Exercise 21.6 Challenge: Ion-Acoustic Solitons
In this exercise we explore nonlinear effects in ion-acoustic waves (Ex. 21.5), and
show that they give rise to solitons that obey the same KdV equation as governs
1048
Chapter 21. Waves in Cold Plasmas: Two-Fluid Formalism

solitonic water waves (Sec. 16.3). This version of the solitons is only mildly nonlinear.
In Sec. 23.6 we will generalize to strong nonlinearity.
(a) Introduce a bookkeeping expansion parameter ε whose numerical value is unity,5
and expand the ion density, ion velocity, and potential in the forms
n = n0(1 + εn1 + ε2n2 + . . .),
u = (kBTe/mp)1/2(εu1 + ε2u2 + . . .),
 = (kBTe/e)(ε1 + ε22 + . . .).
(21.37)
Here n1, u1, and 1 are small compared to unity, and the factors of ε tell us that,
as the wave amplitude is decreased, these quantities scale proportionally to one
another, while n2, u2, and 2 scale proportionally to the squares of n1, u1, and 1,
respectively. Change independent variables from (t, z) to (τ , η), where
η =
√
2ε1/2λ−1
D [z −(kBTe/mp)1/2t],
τ =
√
2ε3/2ωppt.
(21.38)
Explain, now or at the end, the chosen powers ε1/2 and ε3/2. By substituting
Eqs. (21.37) and (21.38) into the nonlinear equations (21.35), equating terms of
the same order in ε, and then setting ε = 1(bookkeeping parameter!), show that
n1, u1, and 1 each satisfy the KdV equation (16.32):
∂ζ
∂τ + ζ ∂ζ
∂η + ∂3ζ
∂η3 = 0.
(21.39)
(b) In Sec. 16.3 we discussed the exact, single-soliton solution (16.33) to this KdV
equation. Show that for an ion-acoustic soliton, this solution propagates with the
physical speed (1+ n1o)(kBTe/mp)1/2 (where n1o is the value of n1 at the peak of
the soliton), which is greater the larger is the wave’s amplitude.
21.4.4
21.4.4 Cutoffs and Resonances
Electromagnetic waves, Langmuir waves, and ion-acoustic waves in an unmagnetized
plasma provide examples of cutoffs and resonances.
cutoff, where kkk goes to
zero
A cutoff is a frequency at which a wave mode ceases to propagate because its
wave number k there becomes zero. Langmuir and electromagnetic waves at ω →ωp
are examples; see their dispersion relations in Fig. 21.1. For concreteness, consider
a monochromatic radio-frequency electromagnetic wave propagating upward into
Earth’s ionosphere at some nonzero angle to the vertical (left side of Fig. 21.2), and
neglect the effects of Earth’s magnetic ﬁeld. As the wave moves deeper (higher) into
the ionosphere, it encounters a rising electron density n and correspondingly, a rising
plasma frequency ωp. The wave’s wavelength will typically be small compared to the
5.
See Box 7.2 for a discussion of such bookkeeping parameters in a different context.
21.4 Wave Modes in an Unmagnetized Plasma
1049

height
low
low
high
electron
density
ion-acoustic wave
electromagnetic
wave
resonance
cutoff
FIGURE 21.2 Cutoff and resonance illustrated by wave propagation in Earth’s
ionosphere. The thick, arrowed curves are rays, and the thin, dashed lines are
phase fronts. The electron density is proportional to the darkness of the shading.
inhomogeneity scale for ωp, so the wave propagation can be analyzed using geometric
optics (Sec. 7.3). Across a phase front, the portion of the wave that is higher in the
ionosphere will have a smaller k and thus a larger wavelength and phase speed; it
thus has a greater distance between phase fronts (dashed lines). Therefore, the rays,
which are orthogonal to the phase fronts, will bend away from the vertical (left side
of Fig. 21.2); that is, the wave will be reﬂected away from the cutoff, at which ωp →ω
waves are reﬂected by
cutoff regions
and k →0. Clearly, this behavior is quite general. Wave modes are generally reﬂected
from regions in which slowly changing plasma conditions give rise to cutoffs.
resonance, where kkk
becomes inﬁnite
A resonance is a frequency at which a wave mode ceases to propagate because its
wave number k there becomes inﬁnite (i.e., its wavelength goes to zero). Ion-acoustic
waves provide an example; see their dispersion relation in Fig. 21.1. For concreteness,
consider an ion-acoustic wave deep in the ionosphere, where ωpp is larger than the
wave’s frequency ω (right side of Fig. 21.2). As the wave propagates toward the upper
edge of the ionosphere, at some nonzero angle to the vertical, the portion of a phase
front that is higher sees a smaller electron density and thus a smaller ωpp; thence it has
a larger k and shorter wavelength and thus a shorter distance between phase fronts
(dashed lines). This causes the rays to bend toward the vertical (right side of Fig. 21.2).
The wave is “attracted” to the region of the resonance, ω →ωpp, k →∞, where it is
waves are attracted to
resonance regions, and
damped
“Landau damped” (Chap. 22) and dies. This behavior is quite general. Wave modes
are generally attracted to regions in which slowly changing plasma conditions give
rise to resonances, and on reaching a resonance, they die.
We study wave propagation in the ionosphere in greater detail in Sec. 21.5.4.
21.5
21.5 Wave Modes in a Cold, Magnetized Plasma
21.5.1
21.5.1 Dielectric Tensor and Dispersion Relation
We now complicate matters somewhat by introducing a uniform magnetic ﬁeld B0
into the unperturbed plasma. To avoid additional complications, we make the plasma
1050
Chapter 21. Waves in Cold Plasmas: Two-Fluid Formalism

cold (i.e., we omit thermal effects). The linearized equation of motion (21.13b) for
each species s then becomes
−iωus = qsE
ms
+ qs
ms
us × B0.
(21.40)
It is convenient to multiply this equation of motion by nsqs/ϵ0 and introduce for each
species a scalar plasma frequency and scalar and vectorial cyclotron frequencies:
electron and proton
plasma frequencies, and
cyclotron frequencies
ωps =
*
nsq2
s
ϵ0ms
+1/2
,
ωcs = qsB0
ms
,
ωcs = ωcs ˆB0 = qsB0
ms
(21.41)
[so ωpp = (me/mp) ωpe ≃ωpe/43, ωp =

ω2
pe + ω2
pp, ωce < 0, ωcp > 0, and
ωcp = (me/mp)|ωce| ≃|ωce|/1,836].Therebywebringtheequationofmotion(21.40)
into the form
−iω
nsqs
ϵ0
us

+ ωcs ×
nsqs
ϵ0
us

= ω2
psE.
(21.42)
By combining this equation with ωcs×(this equation) and ωcs . (this equation), we
properties of wave modes
in a cold, magnetized
plasma:
can solve for the ﬂuid velocity of species s as a linear function of the electric ﬁeld E:
ﬂuid velocities
nsqs
ϵ0
us = −i
*
ωω2
ps
ω2
cs −ω2
+
E −
ω2
ps
(ω2
cs −ω2)ωcs × E + ωcs
iω2
ps
(ω2
cs −ω2)ωωcs . E.
(21.43)
(This relation is useful for deducing the physical properties of wave modes.) From
this ﬂuid velocity we can read off the current j = !
s nsqsus as a linear function of
E; by comparing with Ohm’s law, j = κe . E, we then obtain the tensorial conductivity
κe, which we insert into Eq. (21.20) to get the following expression for the dielectric
tensor (in which B0 and hence ωcs are taken to be along the z-axis):
dielectric tensor
ϵ =
⎛
⎜⎝
ϵ1
−iϵ2
0
iϵ2
ϵ1
0
0
0
ϵ3
⎞
⎟⎠,
(21.44)
where
ϵ1 = 1 −
 
s
ω2
ps
ω2 −ω2
cs
,
ϵ2 =
 
s
ω2
psωcs
ω(ω2 −ω2
cs) ,
ϵ3 = 1 −
 
s
ω2
ps
ω2 .
(21.45)
21.5 Wave Modes in a Cold, Magnetized Plasma
1051

Let the wave propagate in the x-z plane at an angle θ to the z-axis (i.e., to the
magnetic ﬁeld). Then the algebratized wave operator (21.9) takes the form
8888Lij
8888 = ω2
c2
⎛
⎜⎝
ϵ1 −n2 cos2 θ
−iϵ2
n2 sin θ cos θ
iϵ2
ϵ1 −n2
0
n2 sin θ cos θ
0
ϵ3 −n2 sin2 θ
⎞
⎟⎠,
(21.46)
where
index of refraction
n = ck
ω
(21.47)
is the wave’s index of refraction (i.e., the wave’s phase velocity is Vph = ω/k = c/n).
(Note: n must not be confused with the number density of particles n.) The algebra-
tized wave operator (21.46) will be needed when we explore the physical nature of
modes, in particular, the directions of their electric ﬁelds, which satisfy LijEj = 0.
From the wave operator (21.46), we deduce the waves’ dispersion relation
det||Lij|| = 0. Some algebra brings this into the form
dispersion relation
tan2 θ =
−ϵ3(n2 −ϵR)(n2 −ϵL)
ϵ1(n2 −ϵ3)

n2 −ϵR ϵL/ϵ1
 ,
(21.48)
where
ϵL = ϵ1 −ϵ2 = 1 −
 
s
ω2
ps
ω(ω −ωcs) ,
ϵR = ϵ1 + ϵ2 = 1 −
 
s
ω2
ps
ω(ω + ωcs).
(21.49)
21.5.2
21.5.2 Parallel Propagation
waves propagating parallel
to the magnetic ﬁeld
As a ﬁrst step in making sense out of the general dispersion relation (21.48) for waves
in a cold, magnetized plasma, let us consider wave propagation along the magnetic
ﬁeld, so θ = 0. The dispersion relation (21.48) then factorizes to give three solutions:
dispersion relations for
three modes: left, right,
and plasma oscillations;
Fig. 21.3
n2 ≡c2k2
ω2 = ϵL,
n2 ≡c2k2
ω2 = ϵR,
ϵ3 = 0.
(21.50)
LEFT AND RIGHT MODES; PLASMA OSCILLATIONS
Consider the ﬁrst solution in Eq. (21.50): n2 = ϵL. The algebratized wave equation
LijEj = 0 [with Lij given by Eq. (21.46)] in this case with the wave propagating along
the B(ez) direction, requires that the electric ﬁeld direction be E ∝(ex −iey)e−iωt,
which we deﬁne to be a left-hand circular polarized mode. The second solution in
(21.50), n2 = ϵR, is the corresponding right-hand circular polarized mode. From
Eqs. (21.49) we see that these two modes propagate with different phase velocities
(but only slightly different, if ω is far from the electron cyclotron frequency and far
1052
Chapter 21. Waves in Cold Plasmas: Two-Fluid Formalism

resonance
resonance
Alfvén
whistler
evanescent
evanescent
cutoffs
L
R
L
L
R
R
ωcp
θ = 0
1
n2 = (c–ω–k)
2
ω
ωcoR
ωcoL
|ωce|
|ωce|/2
ωpe
c2 /a2 + 1
 + 1
c2 
—
4.59a2
FIGURE 21.3 Square of wave refractive index for circularly polarized waves propagating along
the static magnetic ﬁeld in a proton-electron plasma with ωpe > ωce. The horizontal, angular-
frequency scale is logarithmic. L means left-hand circularly polarized (“left mode”), and R,
right-hand circularly polarized (“right mode”).
from the proton cyclotron frequency). The third solution in Eq. (21.50), ϵ3 = 0, is
just the electrostatic plasma oscillation in which the electrons and protons oscillate
parallel to and are unaffected by the static magnetic ﬁeld.
As an aid to exploring the frequency dependence of the left and right modes,
Fig. 21.3 shows the refractive index n = ck/ω squared as a function of ω.
HIGH-FREQUENCIES: FARADAY ROTATION
In the high-frequency limit, the refractive index for both modes is slightly less
than unity and approaches the index for an unmagnetized plasma, n = ck/ω ≃
1 −1
2ω2
p/ω2 [cf. Eq. (21.27a)], but with a small difference between the modes given,
to leading order, by
nL −nR ≃−
ω2
peωce
ω3
.
(21.51)
This difference is responsible for an important effect known as Faraday rotation.
Faraday rotation at high
frequency: difference
between left and right
modes
Suppose that a linearly polarized wave is incident on a magnetized plasma and
propagates parallel to the magnetic ﬁeld. We can deduce the behavior of the polariza-
tion by expanding the mode as a linear superposition of the two circularly polarized
eigenmodes, left and right. These two modes propagate with slightly different phase
21.5 Wave Modes in a Cold, Magnetized Plasma
1053

velocities, so after propagating some distance through the plasma, they acquire a rel-
ative phase shift φ. When one then reconstitutes the linear polarized mode from
the circular eigenmodes, this phase shift is manifest in a rotation of the plane of po-
larization through an angle φ/2 (for small φ). This—together with the difference
in refractive indices [Eq. (21.51)], which determines φ—implies a Faraday rotation
rate for the plane of polarization given by (Ex. 21.7)
rate of rotation
dχ
dz = −
ω2
peωce
2ω2c .
(21.52)
INTERMEDIATE FREQUENCIES: CUTOFFS
As the wave frequency is reduced, the refractive index decreases to zero, ﬁrst for the
right circular wave, then for the left one (Fig. 21.3). Vanishing of n at a ﬁnite frequency
corresponds to vanishing of k and inﬁnite wavelength, that is, it signals a cutoff
(Fig. 21.2 and associated discussion). When the frequency is lowered further, the
squared refractive index becomes negative, and the wave mode becomes evanescent.
Correspondingly, whenacircularlypolarizedelectromagneticwavewithconstantreal
frequency propagates into an inhomogeneous plasma parallel to its density gradient
and parallel to a magnetic ﬁeld, then beyond the spatial location of the wave’s cutoff,
its wave number k becomes purely imaginary, and the wave dies out with distance
(gradually at ﬁrst, then more rapidly).
The cutoff frequencies are different for the two modes and are given by
cutoff frequencies
ωcoR,L = 1
2
A
(ωce + ωcp)2 + 4(ω2
pe + ω2
pp)
B1/2
± (|ωce| −ωcp)

≃ωpe ± 1
2|ωce|
if ωpe ≫|ωce|,
as is often the case.
(21.53)
LOW FREQUENCIES: RESONANCES; WHISTLER MODES
As we lower the frequency further (Fig. 21.3), ﬁrst the right mode and then the left
regain the ability to propagate. When the wave frequency lies between the proton
and electron gyro frequencies, ωcp < ω < |ωce|, only the right mode propagates.
whistler mode at
intermediate frequencies
This mode is sometimes called a whistler. As the mode’s frequency increases toward
the electron gyro frequency |ωce| (where it ﬁrst recovered the ability to propagate),
its refractive index and wave vector become inﬁnite—a signal that ω = |ωce| is a
resonance for the whistler (Fig. 21.2 and associated discussion). The physical origin
of this resonance is that the wave frequency becomes resonant with the gyrational
resonance with electron
gyrations
frequency of the electrons that are orbiting the magnetic ﬁeld in the same sense as the
wave’s electric vector rotates. To quantify the strong wave absorption that occurs at
this resonance, one must carry out a kinetic-theory analysis that takes account of the
electrons’ thermal motions (Chap. 22).
large dispersion near
resonance
Another feature of the whistler is that it is highly dispersive close to resonance; its
dispersion relation there is given approximately by
ω ≃
|ωce|
1 + ω2
pe/(c2k2).
(21.54)
1054
Chapter 21. Waves in Cold Plasmas: Two-Fluid Formalism

The group velocity, obtained by differentiating Eq. (21.54), is given approximately by
Vg = ∇k ω ≃2ωcec
ωpe

1 −
ω
|ωce|
3/2
ˆB0.
(21.55)
This velocity varies extremely rapidly close to resonance, so waves of slightly different
frequency propagate at very different speeds.
This is the physical origin of the phenomenon by which whistlers were discovered.
They were encountered in World War One by radio operators who heard, in their
earphones, strange tones with rapidly changing pitch. These turned out to be whistler
modes excited by lightning in the southern hemisphere; they propagated along Earth’s
magnetic ﬁeld through the magnetosphere to the northern hemisphere. Only modes
below the lowest electron gyro frequency on the waves’ path (their geometric-optics
ray) could propagate, and these were highly dispersed, with the lower frequencies
arriving ﬁrst.
There is also a resonance associated with the left circularly polarized wave, which
propagates below the proton cyclotron frequency; see Fig. 21.3.
VERY LOW FREQUENCIES: ALFV´EN MODES
Finally, let us examine the very low-frequency limit of these waves (Fig. 21.3). We
ﬁnd that both dispersion relations n2 = ϵL and n2 = ϵR asymptote, at arbitrarily low
frequencies, to
ω = ak

1 + a2
c2
−1/2
.
(21.56)
Here a = B0[μ0ne(mp + me)]−1/2 is the Alfv´en speed that arose in our discussion of
magnetohydrodynamics[Eq.(19.75)].Infactatverylowfrequencies, bothmodes, left
Alfv´en modes at very low
frequencies
and right, have become the Alfv´en waves that we studied using MHD in Sec. 19.7.2.
However, our two-ﬂuid formalism reports a phase speed ω/k = a/

1 + a2/c2 for
these Alfv´en waves that is slightly lower than the speed ω/k = a predicted by our
MHD formalism. The 1/

1 + a2/c2 correction could not be deduced using non-
relativistic correction to
phase speed
relativistic MHD, because that formalism neglects the displacement current. (Rela-
tivistic MHD includes the displacement current and predicts precisely this correction
factor.)
We can understand the physical origin of this correction by examining the par-
ticles’ motions in a very-low-frequency Alfv´en wave; see Fig. 21.4. Because the wave
frequency is far below both the electron and the proton cyclotron frequencies, both
types of particle orbit the ﬁeld B0 many times in a wave period. When the wave’s slowly
interpretation as drift
motion
changing electric ﬁeld is applied, the guiding centers of both types of orbits acquire
the same slowly changing drift velocity v = E × B0/B2
0, so the two ﬂuid velocities
also drift at this rate, and the currents associated with the proton and electron drifts
cancel. However, when we consider corrections to the guiding-center response that
are of higher order in ω/ωcp and ω/ωce, we ﬁnd that the ions drift slightly faster than
the electrons, which produces a net current that modiﬁes the magnetic ﬁeld and gives
rise to the 1/

1 + a2/c2 correction to the Alfv´en wave’s phase speed.
21.5 Wave Modes in a Cold, Magnetized Plasma
1055

drift
drift
electron
ion
E
B
FIGURE 21.4 Gyration of electrons and ions in a very-low-frequency Alfv´en wave.
Although the electrons and ions gyrate with opposite senses about the magnetic ﬁeld,
their E × B drifts are similar. It is only in the next highest order of approximation
that a net ion current is produced parallel to the applied electric ﬁeld. Note that, if the
electrons and ions have the same temperature, then the ratio of radii of the orbits is
∼(me/mi)1/2, or ∼0.02 for protons.
A second way to understand this correction is by the contribution of the magnetic
interpretation as magnetic
contribution to inertia
ﬁeld to the plasma’s inertial mass per unit volume (Ex. 21.8).
EXERCISES
Exercise 21.7 Derivation: Faraday Rotation
Derive Eq. (21.52) for Faraday rotation.
Exercise 21.8 Example: Alfv´en Waves as Plasma-Laden,
Plucked Magnetic Field Lines
A narrow bundle of magnetic ﬁeld lines with cross sectional area A, together with the
plasma attached to them, can be thought of as like a stretched string. When such a
string is plucked, waves travel down it with phase speed √T / , where T is the string’s
tension, and  is its mass per unit length (Sec. 12.3.3). The plasma analog is Alfv´en
waves propagating parallel to the plasma-laden magnetic ﬁeld.
(a) Analyzed nonrelativistically, the tension for our bundle of ﬁeld lines is T =
[B2/(2μ0)]A and the mass per unit length is  = ρA, so we expect a phase
velocity √T/ =

B2/(2μ0ρ), which is 1/
√
2 of the correct result. Where is the
error? [Hint: In addition to the restoring force on bent ﬁeld lines, due to tension
along the ﬁeld, there is also the curvature force (B . ∇)B/μ0; Eq. (19.15).]
(b) In special relativity, the plasma-laden magnetic ﬁeld has a tensorial inertial mass
per unit volume that is discussed in Ex. 2.27. Explain why, when the ﬁeld lines
(which point in the z direction) are plucked so they vibrate in the x direction,
the inertial mass per unit length that resists this motion is  = (T 00 + T xx)A =
[ρ + B2/(μ0c2)]A. (In the ﬁrst expression for  , T 00 is the mass-energy density
of plasma and magnetic ﬁeld, T xx is the magnetic pressure along the x direction,
and the speed of light is set to unity as in Chap. 2; in the second expression, the
1056
Chapter 21. Waves in Cold Plasmas: Two-Fluid Formalism

speed of light has been restored to the equation using dimensional arguments.)
Show that the magnetic contribution to this inertial mass gives the relativistic
correction 1/

1 + a2/c2 to the Alfv´en waves’ phase speed, Eq. (21.56).
21.5.3
21.5.3 Perpendicular Propagation
Turn next to waves that propagate perpendicular to the static magnetic ﬁeld: k = kex;
waves propagating
perpendicular to the
magnetic ﬁeld
B0 = B0ez; θ = π/2. In this case our general dispersion relation (21.48) again has
three solutions corresponding to three modes:
n2 ≡c2k2
ω2 = ϵ3,
n2 ≡c2k2
ω2 = ϵRϵL
ϵ1
,
ϵ1 = 0.
(21.57)
The ﬁrst solution
ordinary mode—EEE and vvv
parallel to B0
B0
B0
n2 = ϵ3 = 1 −
ω2
p
ω2
(21.58)
has the same index of refraction as for an electromagnetic wave in an unmagnetized
plasma [cf. Eq. (21.24)], so this is called the ordinary mode. In this mode the electric
vector and velocity perturbation are parallel to the static magnetic ﬁeld, so the ﬁeld
has no inﬂuence on the wave. The wave is identical to an electromagnetic wave in an
unmagnetized plasma.
The second solution in Eq. (21.57),
extraordinary mode—EEE
orthogonal to B0
B0
B0
n2 = ϵRϵL/ϵ1 = ϵ2
1 −ϵ2
2
ϵ1
,
(21.59)
is known as the extraordinary mode and has an electric ﬁeld that is orthogonal to B0
but not to k. (Note that the names “ordinary” and “extraordinary” are used differently
here than for waves in a nonlinear crystal in Sec. 10.6.)
The refractive indices for the ordinary and extraordinary modes are plotted as
functions of frequency in Fig. 21.5. The ordinary-mode curve is dull; it is just like
that in an unmagnetized plasma. The extraordinary-mode curve is more interesting.
It has two cutoffs, with frequencies (ignoring the ion motions)
cutoffs and resonances
ωco1,2 ≃

ω2
pe + 1
4ω2
ce
1/2
± 1
2ωce,
(21.60)
and two resonances with strong absorption, at frequencies known as the upper hy-
brid (UH) and lower hybrid (LH) frequencies. These frequencies are given approxi-
mately by
ωUH ≃(ω2
pe + ω2
ce)1/2,
ωLH ≃
'(ω2
pe + |ωce|ωcp)|ωce|ωcp
ω2
pe + ω2
ce
(1/2
.
(21.61)
21.5 Wave Modes in a Cold, Magnetized Plasma
1057

LH resonance
UH resonance
evanescent
evanescent
evanescent
E
E
E
E
O
O
c2/a2
ωLH
ωUH
θ = π–2
1
n2 = (c–ω–k)
2
ω
ωco1
ωco2
|ωce|
ωpe
cutoff
cutoff
FIGURE 21.5 Square of wave refractive index n as a function of frequency ω, for wave propagation
perpendicular to the magnetic ﬁeld in an electron ion plasma with ωpe > ωce. The ordinary
mode is designated by O, the extraordinary mode by E.
very low frequencies: fast
magnetosonic mode and
Alfv´en mode
In the limit of very low frequency, the extraordinary, perpendicularly propagating
modehasthesamedispersionrelationω = ak/

1 + a2/c2 astheparallelpropagating
modes [Eq. (21.56)]. In this regime the mode has become the fast magnetosonic
wave, propagating perpendicularly to the static magnetic ﬁeld (Sec. 19.7.2), while the
parallel waves have become the Alfv´en modes.
The third solution in Eq. (21.57), ϵ1 = 0, has vanishing eigenvector E (i.e., LijEj =
0 for ϵ1 = 0 implies Ej = 0), so it does not represent a physical oscillation of any sort.
21.5.4
21.5.4 Propagation of Radio Waves in the Ionosphere; Magnetoionic Theory
The discovery that radio waves could be reﬂected off the ionosphere, and thereby
could be transmitted over long distances,6 revolutionized communications and stim-
ulated intensive research on radio-wave propagation in a magnetized plasma. In this
magnetoionic theory for
radio waves in ionosphere
section, we discuss radio-wave propagation in the ionosphere for waves whose prop-
6.
This effect was predicted independently by Heaviside and Kennelly in 1902. Appleton demonstrated
its existence in 1924, for which he received the Nobel prize. It was claimed by some physicists that the
presence of a wave speed > c violated special relativity until it was appreciated that it is the group velocity
that is relevant.
1058
Chapter 21. Waves in Cold Plasmas: Two-Fluid Formalism

agation vectors make arbitrary angles θ to the magnetic ﬁeld. The approximate for-
malism we develop is sometimes called magneto-ionic theory.
properties of ionosphere
The ionosphere is a dense layer of partially ionized gas between 50 and 300 km
above the surface of Earth. The ionization is due to incident solar ultraviolet radiation.
Although the ionization fraction increases with height, the actual density of free
electrons passes through a maximum whose height rises and falls with the position
of the Sun.
The electron gyro frequency varies from ∼0.5 to ∼1MHz in the ionosphere, and
the plasma frequency increases from effectively zero to a maximum that can be as high
as 100 MHz; so typically, but not everywhere, ωpe ≫|ωce|. We are interested in wave
propagation at frequencies above the electron plasma frequency, which in turn is well
in excess of the ion plasma frequency and the ion gyro frequency. It is therefore a good
approximationtoignoreionmotionsaltogether.Inaddition, atthealtitudesofgreatest
interest for radio-wave propagation, the temperature is low, Te ∼200–600 K, so the
cold plasma approximation is well justiﬁed. A complication that one must sometimes
face in the ionosphere is the inﬂuence of collisions (see Ex. 21.4), but in this section
we ignore it.
It is conventional in magneto-ionic theory to introduce two dimensionless
parameters:
X =
ω2
pe
ω2 ,
Y = |ωce|
ω
,
(21.62)
in terms of which (ignoring ion motions) the components (21.45) of the dielectric
tensor (21.44) are
ϵ1 = 1 +
X
Y 2 −1,
ϵ2 =
XY
Y 2 −1,
ϵ3 = 1 −X.
(21.63)
In this case it is convenient to rewrite the dispersion relation det||Lij|| = 0 in a form
different from Eq. (21.48)—a form derivable, for example, by computing explicitly
the determinant of the matrix (21.46), setting
x = X −1 + n2
1 −n2
,
(21.64)
solving the resulting quadratic in x, and then solving for n2. The result is the Appleton-
Hartree dispersion relation:
Appleton-Hartree
dispersion relation
n2 = 1 −
X
1 −Y 2 sin2 θ
2(1−X) ±

Y 4 sin4 θ
4(1−X)2 + Y 2 cos2 θ
1/2 .
(21.65)
quasi-longitudinal
approximation
There are two commonly used approximations to this dispersion relation. The
ﬁrst is the quasi-longitudinal approximation, which is used when k is approximately
parallel to the static magnetic ﬁeld (i.e., when θ is small). In this case, just retaining
21.5 Wave Modes in a Cold, Magnetized Plasma
1059

the dominant terms in the dispersion relation, we obtain
n2 ≃1 −
X
1 ± Y cos θ .
(21.66)
This is just the dispersion relation (21.50) for the left and right modes in strictly par-
allel propagation, with the substitution B0 →B0 cos θ. By comparing the magnitude
of the terms that we dropped from the full dispersion relation in deriving Eq. (21.66)
with those that we retained, one can show that the quasi-longitudinal approximation
is valid when
Y sin2 θ ≪2(1 −X) cos θ.
(21.67)
The second approximation is the quasi-transverse approximation; it is appropriate
quasi-transverse
approximation
when inequality (21.67) is reversed. In this case the two modes are generalizations of
thepreciselyperpendicularordinaryandextraordinarymodes, andtheirapproximate
dispersion relations are
n2
O ≃1 −X,
n2
X ≃1 −
X(1 −X)
1 −X −Y 2 sin2 θ .
(21.68)
The ordinary-mode dispersion relation (subscript O) is unchanged from the strictly
perpendicular one, Eq. (21.58); the extraordinary dispersion relation (subscript X)
is obtained from the strictly perpendicular one [Eq. (21.59)] by the substitution
B0 →B0 sin θ.
Thequasi-longitudinalandquasi-transverseapproximationssimplifytheproblem
of tracing rays through the ionosphere.
ionospheric reﬂection of
AM and SW radio waves
Commercial radio stations operate in the AM (amplitude-modulated) band
(0.5–1.6 MHz), the SW (short-wave) band (2.3–18 MHz), and the FM (frequency-
modulated) band (88–108 MHz). Waves in the ﬁrst two bands are reﬂected by the
ionosphere and can therefore be transmitted over large surface areas (Ex. 21.12). FM
waves, with their higher frequencies, are not reﬂected and must therefore be received
as “ground waves” (waves that propagate directly, near the ground). However, they
have the advantage of a larger bandwidth and consequently a higher ﬁdelity audio out-
put. As the altitude of the reﬂecting layer rises at night, short-wave communication
over long distances becomes easier.
EXERCISES
Exercise 21.9 Derivation: Appleton-Hartree Dispersion Relation
Derive Eq. (21.65).
Exercise 21.10 Example: Dispersion and Faraday Rotation of Pulsar Pulses
A radio pulsar emits regular pulses at 1-s intervals, which propagate to Earth through
the ionized interstellar plasma with electron density ne ≃3 × 104 m−3. The pulses ob-
1060
Chapter 21. Waves in Cold Plasmas: Two-Fluid Formalism

served at f = 100 MHz are believed to be emitted at the same time as those observed
at much higher frequency, but they arrive with a delay of 100 ms.
(a) Explainbrieﬂywhypulsestravelatthegroupvelocityinsteadofthephasevelocity,
and show that the expected time delay of the f = 100-MHz pulses relative to the
high-frequency pulses is given by
t =
e2
8π2meϵ0f 2c

nedx,
(21.69)
where the integral is along the waves’ propagation path. Hence compute the
distance to the pulsar.
(b) Now suppose that the pulses are linearly polarized and that their propagation
is accurately described by the quasi-longitudinal approximation. Show that the
plane of polarization will be Faraday rotated through an angle
χ = et
me
⟨B∥⟩,
(21.70)
where ⟨B∥⟩=

neB . dx
F
nedx. The plane of polarization of the pulses emitted
at100 MHzisbelievedtobethesameastheemissionplaneforhigherfrequencies,
but when the pulses arrive at Earth, the 100-MHz polarization plane is observed
to be rotated through 3 radians relative to that at high frequencies. Calculate the
mean parallel component of the interstellar magnetic ﬁeld.
Exercise 21.11 Challenge: Faraday Rotation Paradox
Consider a wave mode propagating through a plasma—for example, the ionosphere—
in which the direction of the background magnetic ﬁeld is slowly changing. We have
just demonstrated that so long as B is not almost perpendicular to k, we can use the
quasi-longitudinal approximation, the difference in phase velocity between the two
eigenmodes is ∝B . k, and the integral for the magnitude of the rotation of the plane
of polarization is ∝

ne B . dx.
Now, suppose that the parallel component of the magnetic ﬁeld changes sign. It has
been implicitly assumed that the faster eigenmode, which is circularly polarized in the
quasi-longitudinal approximation, becomes the slower eigenmode (and vice versa)
when the ﬁeld is reversed, and the Faraday rotation is undone. However, if we track
the modes using the full dispersion relation, we ﬁnd that the faster quasi-longitudinal
eigenmode remains the faster eigenmode in the quasi-perpendicular regime, and
it becomes the faster eigenmode with opposite sense of circular polarization in the
ﬁeld-reversed quasi-longitudinal regime. Now, let there be a second ﬁeld reversal
where an analogous transition occurs. Following this logic, the net rotation should
be ∝

ne|B . dx|. What is going on?
Exercise 21.12 Example: Reﬂection of Short Waves by the Ionosphere
The free electron density in the night-time ionosphere increases exponentially from
109 m−3 to 1011 m−3 as the altitude increases from 100 to 200 km, and the density
21.5 Wave Modes in a Cold, Magnetized Plasma
1061

diminishes above this height. Use Snell’s law [Eq. (7.49)] to calculate the maximum
range of 10-MHz waves transmitted from Earth’s surface, assuming a single iono-
spheric reﬂection.
21.5.5
21.5.5 CMA Diagram for Wave Modes in a Cold, Magnetized Plasma
Magnetized plasmas are anisotropic, just like many nonlinear crystals (Chap. 10).
depicting phase speed
as function of angle
to magnetic ﬁeld, two
methods:
This implies that the phase speed of a propagating wave mode depends on the angle
between the direction of propagation and the magnetic ﬁeld. Two convenient ways
are used to exhibit this anisotropy diagrammatically. The ﬁrst method, due originally
to Fresnel, is to construct phase-velocity surfaces (also called wave-normal surfaces),
phase-velocity (wave-
normal) surfaces,
Fig. 21.6a
which are polar plots of the wave phase velocity Vph = ω/k, at ﬁxed frequency ω, as
a function of the angle θ that the wave vector k makes with the magnetic ﬁeld; see
Fig. 21.6a.
refractive-index surface,
Fig. 21.6b
The second type of surface, used originally by Hamilton, is the refractive-index
surface. This is a polar plot of the refractive index n = ck/ω for a given frequency,
again as a function of the wave vector’s angle θ to B; see Fig. 21.6b. This plot
has the important property that the group velocity is perpendicular to the surface
(a)
(b)
B
B
Vg
Vph = ω–k kˆ
ω = const
ω = const
ω = const
ω = const
ck/ω
θ
θ
FIGURE 21.6 (a) Wave-normal surface (i.e., phase-velocity surface) for a whistler mode propagating
at an angle θ with respect to the magnetic ﬁeld direction. This diagram plots the phase velocity
Vph = (ω/k)ˆk as a vector from the origin, with the direction of the magnetic ﬁeld chosen as upward.
When we ﬁx the frequency ω of the wave, the tip of the phase velocity vector sweeps out the ﬁgure-8
curve as its angle θ to the magnetic ﬁeld changes. This curve should be thought of as rotated around
the vertical (magnetic-ﬁeld) direction to form the ﬁgure-8 wave-normal surface. Note that there are
some directions where no mode can propagate. (b) Refractive-index surface for the same whistler
mode. Here we plot ck/ω as a vector from the origin, and as its direction changes with ﬁxed ω, this
vector sweeps out the two hyperboloid-like surfaces. Since the length of the vector is ck/ω = n, this
ﬁgure can be thought of as a polar plot of the refractive index n as a function of wave-propagation
direction θ for ﬁxed ω; hence the name “refractive-index surface.” The group velocity Vg is orthogonal
to the refractive-index surface (Ex. 21.13). Note that for this whistler mode, the energy ﬂow (along
Vg) is focused toward the direction of the magnetic ﬁeld.
1062
Chapter 21. Waves in Cold Plasmas: Two-Fluid Formalism

(Ex. 21.13). As discussed above, the energy ﬂow is along the direction of the group
velocity and, in a magnetized plasma, this velocity can make a large angle with the
wave vector.
CMA diagram, Fig. 21.7
A particularly useful application of these ideas is to a graphical representation of
the various types of wave modes that can propagate in a cold, magnetized plasma
(Fig. 21.7). This representation is known as the Clemmow-Mullaly-Allis or CMA
diagram. The character of waves of a given frequency ω depends on the ratio of
this frequency to the plasma frequency and the cyclotron frequency. This suggests
horizontal and vertical
axes
deﬁning two dimensionless numbers, ω2
p/ω2 ≡(ω2
pe + ω2
pp)/ω2 and |ωce|ωcp/ω2,
which are plotted on the horizontal and vertical axes of the CMA diagram. [Recall
that ωpp = ωpe
me/mp and ωcp = ωce(me/mp).] The CMA space deﬁned by these
sixteen regions;
topological form of
wave-normal surfaces
twodimensionlessparameterscanbesubdividedintosixteenregions, ineachofwhich
thepropagatingmodeshaveadistinctivecharacter.Themodepropertiesareindicated
by sketching the topological form of the wave-normal surfaces associated with each
region.
The form of the wave-normal surface in each region can be deduced from the gen-
eral dispersion relation (21.48). To deduce it, one must solve the dispersion relation
for 1/n = ω/kc = Vph/c as a function of θ and ω, and then generate the polar plot of
Vph(θ).
On the CMA diagram’s wave-normal curves, the characters of the parallel and
perpendicular modes are indicated by labels: R and L for right and left parallel
modes (θ = 0), and O and X for ordinary and extraordinary perpendicular modes
(θ = π/2). As one moves across a boundary from one region to another, there is often
a change of which parallel mode gets deformed continuously, with increasing θ, into
which perpendicular mode. In some regions a wave-normal surface has a ﬁgure-8
shape, indicating that the waves can propagate only over a limited range of angles,
θ < θmax. In some regions there are two wave-normal surfaces, indicating that—at
least in some directions θ—two modes can propagate; in other regions there is just
one wave-normal surface, so only one mode can propagate; and in the bottom-right
two regions there are no wave-normal surfaces, since no waves can propagate at these
high densities and low magnetic-ﬁeld strengths.
EXERCISES
Exercise 21.13 Derivation: Refractive-Index Surface
Verify that the group velocity of a wave mode is perpendicular to the refractive-index
surface (Fig. 21.6b).
Exercise 21.14 Problem: Exploration of Modes in the CMA Diagram
For each of the following modes studied earlier in this chapter, identify in the CMA
diagram the phase speed, as a function of frequency ω, and verify that the turning on
and cutting off of the modes, and the relative speeds of the modes, are in accord with
the CMA diagram’s wave-normal curves.
21.5 Wave Modes in a Cold, Magnetized Plasma
1063

B
n
mp
—
me
me
—
mp
ε3 = 0
ε1 = 0
ε1 = 0
εL = 1
εR = 1
εR = 0
εL = 0
εRεL = ε1ε3
ω
ω2
pe + ω2
pp
—
ω2
|ωce|ωcp
—
ω2
X
X
L
O
O
LX
R
R
X
X
O
O
O
O
R
R
R
R
R
R
R
R
O
O
L
L
L
L
1
L
L
L
L
X
X
X
X
X
R
FIGURE 21.7 CMA diagram for wave modes with frequency ω propagating in a plasma
with plasma frequencies ωpe, ωpp and gyro frequencies ωce, ωcp. Plotted upward is the
dimensionless quantity |ωce|ωcp/ω2, which is proportional to B2, so magnetic ﬁeld strength
also increases upward. Plotted rightward is the dimensionless quantity (ω2
pe + ω2
pp)/ω2,
which is proportional to n, so the plasma number density also increases rightward. Since both
the ordinate and the abscissa scale as 1/ω2, ω increases in the left-down direction. This plane
is split into sixteen regions by a set of curves on which various dielectric components have
special values. In each of the sixteen regions are shown two, one, or no wave-normal surfaces
(phase-velocity surfaces) at ﬁxed ω (cf. Fig. 21.6a). These surfaces depict the types of wave
modes that can propagate for that region’s values of frequency ω, magnetic ﬁeld strength B,
and electron number density n. In each wave-normal diagram the dashed circle indicates the
speed of light; a point outside that circle has phase velocity Vph greater than c; inside the circle,
Vph < c. The topologies of the wave-normal surfaces and speeds relative to c are constant
throughout each of the sixteen regions; they change as one moves between regions. Adapted
from Boyd and Sanderson (2003, Fig. 6.12), which in turn is adapted from Allis, Buchsbaum,
and Bers (1963).
1064
Chapter 21. Waves in Cold Plasmas: Two-Fluid Formalism

(a) Electromagnetic modes in an unmagnetized plasma.
(b) Left and right modes for parallel propagation in a magnetized plasma.
(c) Ordinary and extraordinary modes for perpendicular propagation in a magne-
tized plasma.
21.6
21.6 Two-Stream Instability
When considered on large enough scales, plasmas behave like ﬂuids and are subject to
a wide variety of ﬂuid dynamical instabilities. However, as we are discovering, plasmas
have internal degrees of freedom associated with their velocity distributions, which
offers additional opportunities for unstable wave modes to grow and for free energy to
be released. A full description of velocity-space instabilities is necessarily kinetic and
must await the following chapter. However, it is instructive to consider a particularly
simple example, the two-stream instability, using cold-plasma theory, as this brings
out several features of the more general theory in a particularly simple manner.
We will apply our results in a slightly unusual way, to the propagation of fast
electron beams through the slowly outﬂowing solar wind. These electron beams are
created by coronal disturbances generated on the surface of the Sun (speciﬁcally,
those associated with “Type III” radio bursts). The observation of these fast electron
beams was initially a puzzle, because plasma physicists knew that they should be
unstable to the exponential growth of electrostatic waves. What we do in this section
is demonstrate the problem. What we will not do is explain what is thought to be its
resolution, since that involves nonlinear plasma-physics considerations beyond the
scope of this book (see, e.g., Melrose, 1980, or Sturrock, 1994).
Consider a simple, cold (i.e., with negligible thermal motions) electron-proton
plasmaatrest.Ignoretheprotonsforthemoment.Wecanwritethedispersionrelation
for electron plasma oscillations in the form
ω2
pe
ω2 = 1.
(21.71)
Nowallowtheionsalsotooscillateabouttheirmeanpositions.Thedispersionrelation
is slightly modiﬁed to
ω2
p
ω2 =
ω2
pe
ω2 +
ω2
pp
ω2 = 1
(21.72)
[cf. Eq. (21.23)]. If we were to add other components (e.g., helium ions), that would
simply add extra terms to Eq. (21.72).
Next, return to Eq. (21.71) and look at it in a reference frame in which the electrons
are moving with speed u. The observed wave frequency is then Doppler shifted, and
so the dispersion relation becomes
dispersion relation
for electron plasma
oscillations in a frame
where electrons move with
speed uuu
ω2
pe
(ω −ku)2 = 1,
(21.73)
21.6 Two-Stream Instability
1065

ku1
ω2
pi
—
(ω − kui)2
i
k′u1
ku2
k′u2
1
ω
small k
large k′
 
FIGURE 21.8 Left-hand side of the dispersion relation (21.74) for two cold
plasma streams and two different choices of wave vector, k (small) and k′
(large). For small enough k, there are only two real roots for ω.
whereω isnowtheangularfrequencymeasuredinthisnewframe.Itshouldbeevident
from this how to generalize Eq. (21.72) to the case of several cold streams moving with
different speeds ui. We simply add the terms associated with each component using
angular frequencies that have been appropriately Doppler shifted:
dispersion relation
for electron plasma
oscillations in a plasma
with counterstreaming
beams
ω2
p1
(ω −ku1)2 +
ω2
p2
(ω −ku2)2 + . . . = 1.
(21.74)
(This procedure will be justiﬁed via kinetic theory in the next chapter.)
The left-hand side of the dispersion relation (21.74) is plotted in Fig. 21.8 for the
caseoftwocoldplasmastreams.Equation(21.74)inthiscaseisaquarticinω, andsoit
shouldhavefourroots.However, forsmallenoughk onlytwooftheserootswillbereal
(solid curves in Fig. 21.8). The remaining two roots must be a complex-conjugate pair,
andtherootwiththepositiveimaginarypartcorrespondstoagrowingmode.Wehave
therefore shown that for small enough k the two-stream plasma will be unstable. Small
two-stream instability:
tapping free energy of
anisotropic particle-
distribution functions
electrostatic disturbances will grow exponentially to large amplitude and ultimately
react back on the plasma. As we add more cold streams to the plasma, we add more
modes, some of which will be unstable. This simple example demonstrates how easy
it is for a plasma to tap the free energy residing in anisotropic particle-distribution
functions.
two-stream instability for
electron beams in solar
wind
Let us return to our solar-wind application and work in the rest frame of the wind
(u1 = 0), where the plasma frequency is ωp1 = ωp. If the beam density is a small
fraction α of the solar-wind density, so ω2
p2 = αω2
p, and the beam velocity (as seen
in the wind’s rest frame) is u2 = V , then by differentiating Eq. (21.74), we ﬁnd that
the local minimum of the left-hand side occurs at ω = kV/(1 + α1/3). The value of
1066
Chapter 21. Waves in Cold Plasmas: Two-Fluid Formalism

the left-hand side at that minimum is ω2
p(1+ α1/3)/ω2. This minimum exceeds unity
(thereby making two roots of the dispersion relation complex) for
k <
ωp
V (1 + α1/3)3/2.
(21.75)
This is therefore the condition for the existence of a growing mode. The maximum
value for the growth rate can be found simply by varying k. It occurs at k = ωp/V
and is
ωi =
31/2α1/3ωp
24/3
.
(21.76)
For the solar wind near Earth, we have ωp ∼105 rad s−1, α ∼10−3, and V ∼
104 km s−1. We therefore ﬁnd that the instability should grow, thereby damping the
fast electron beam, in a length of 30 km, which is much less than the distance from
the Sun (1.5 × 108 km)! This describes the problem that we will not resolve here.
EXERCISES
Exercise 21.15 Derivation: Two-Stream Instability
Verify Eq. (21.76).
Exercise 21.16 Problem: Relativistic Two-Stream Instability
In a very strong magnetic ﬁeld, we can consider electrons as constrained to move in
1 dimension along the direction of the magnetic ﬁeld. Consider a beam of relativistic
protons propagating with density nb and speed ub ∼c through a cold electron-proton
plasma along B. Generalize the dispersion relation (21.74) for modes with k ∥B.
Exercise 21.17 Example: Drift Waves
Another type of wave mode that can be found from a ﬂuid description of a plasma
(but requires a kinetic treatment to understand completely) is a drift wave.Just as the
two-stream instability provides a mechanism for plasmas to erase nonuniformity in
velocity space, so drift waves can rapidly remove spatial irregularities.
The limiting case that we consider here is a modiﬁcation of an ion-acoustic mode
in a strongly magnetized plasma with a density gradient. Suppose that the magnetic
ﬁeld is uniform and points in the ez direction. Let there be a gradient in the equilib-
rium density of both the electrons and the protons: n0 = n0(x). In the spirit of our
description of ion-acoustic modes in an unmagnetized, homogeneous plasma [cf. Eq.
(21.33)], treat the proton ﬂuid as cold, but allow the electrons to be warm and isother-
mal with temperature Te. We seek modes of frequency ω propagating perpendicular
to the density gradient [i.e., with k = (0, ky, kz)].
(a) Consider the equilibrium of the warm electron ﬂuid, and show that there must
be a ﬂuid drift velocity along the direction ey of magnitude
Vde = −V 2
ia
ωci
1
n0
dn0
dx ,
(21.77)
21.6 Two-Stream Instability
1067

where Via = (kBTe/mp)1/2 is the ion-acoustic speed. Explain in physical terms
the origin of this drift and why we can ignore the equilibrium drift motion for
the ions (protons).
(b) We limit our attention to low-frequency electrostatic modes that have phase
velocities below the Alfv´en speed. Under these circumstances, perturbations
to the magnetic ﬁeld can be ignored, and the electric ﬁeld can be written as
E = −∇. Write down the three components of the linearized proton equation
of motion in terms of the perturbation to the proton density n, the proton ﬂuid
velocity u, and the electrostatic potential .
(c) Write down the linearized equation of proton continuity, including the gradient
in n0, and combine with the equation of motion to obtain an equation for the
fractional proton density perturbation at low frequencies:
δn
n0
=
*(ω2
cpk2
z −ω2k2)V 2
ia + ω2
cpωkyVde
ω2(ω2
cp −ω2)
+  e
kBTe

.
(21.78)
(d) Argue that the fractional electron-density perturbation follows a linearized Boltz-
mann distribution, so that
δne
n0
= e
kBTe
.
(21.79)
(e) Use both the proton- and the electron-density perturbations in Poisson’s equation
to obtain the electrostatic drift wave dispersion relation in the low-frequency
(ω ≪ωcp), long-wavelength (kλD ≪1) limit:
ω =
kyVde
2
± 1
2
2
k2
yV 2
de + 4k2
zV 2
ia
31/2
.
(21.80)
Describe the physical character of the mode in the additional limit kz →0. A
proper justiﬁcation of this procedure requires a kinetic treatment, which also
shows that, under some circumstances, drift waves can be unstable and grow
exponentially.
Bibliographic Note
The deﬁnitive monograph on waves in plasmas is Stix (1992); also very good, and
with a controlled-fusion orientation, is Swanson (2003).
For an elementary and lucid textbook treatment, which makes excellent contact
with laboratory experiments, see Chap. 4 of Chen (1974) or Chen (2016). For more
sophisticated and detailed textbook treatments, we especially like the relevant chap-
ters of Clemmow and Dougherty (1969), Krall and Trivelpiece (1973), Lifshitz and
Pitaevskii (1981), Sturrock (1994), Boyd and Sanderson (2003), Bittencourt (2004),
and Bellan (2006). For treatments that focus on astrophysical plasmas, see Melrose
(1980) and Parks (2004).
1068
Chapter 21. Waves in Cold Plasmas: Two-Fluid Formalism

22
CHAPTER TWENTY-TWO
Kinetic Theory of Warm Plasmas
Any complete theory of the kinetics of a plasma
cannot ignore the plasma oscillations.
IRVING LANGMUIR (1928)
22.1
22.1 Overview
At the end of Chap. 21, we showed how to generalize cold-plasma two-ﬂuid theory
to accommodate several distinct plasma beams, and thereby we discovered the two-
stream instability. If the beams are not individually monoenergetic (i.e., cold), as we
assumed there, but instead have broad velocity dispersions that overlap in velocity
space (i.e., if the beams are warm), then the two-ﬂuid approach of Chap. 21 cannot
be used, and a more powerful, kinetic-theory description of the plasma is required.
Chapter 21’s approach entailed specifying the positions and velocities of speciﬁc
groups of particles (the “ﬂuids”); this is an example of a Lagrangian description. It
turns out that the most robust and powerful method for developing the kinetic theory
of warm plasmas is an Eulerian one in which we specify how many particles are to be
found in a ﬁxed volume of one-particle phase space.
In this chapter, using this Eulerian approach, we develop the kinetic theory of plas-
mas. We begin in Sec. 22.2 by introducing kinetic theory’s one-particle distribution
function f (v, x, t) and recovering its evolution equation (the collisionless Boltzmann
equation, also called the Vlasov equation), which we have met previously in Chap. 3.
We then use this Vlasov equation to derive the two-ﬂuid formalism used in Chap. 21
and to deduce some physical approximations that underlie the two-ﬂuid description
of plasmas.
In Sec. 22.3, we explore the application of the Vlasov equation to Langmuir
waves—the 1-dimensional electrostatic modes in an unmagnetized plasma that we
studied in Chap. 21 using the two-ﬂuid formalism. Using kinetic theory, we rederive
Sec. 21.4.3’s Bohm-Gross dispersion relation for Langmuir waves, and as a bonus we
uncover a physical damping mechanism, called Landau damping, that did not and
cannot emerge from the two-ﬂuid analysis. This subtle process leads to the transfer
of energy from a wave to those particles that can “surf” or “phase-ride” the wave (i.e.,
thosewhosevelocityprojectedparalleltothewavevectorisslightlylessthanthewave’s
phase speed). We show that Landau damping works because there are usually fewer
1069

BOX 22.1.
READERS’ GUIDE
.
This chapter relies signiﬁcantly on:
– Portions of Chap. 3 on kinetic theory: Secs. 3.2.1 and 3.2.3
on the distribution function, and Sec. 3.6 on Liouville’s
theorem and the collisionless Boltzmann equation.
– Section 20.3 on Debye shielding, collective behavior of
plasmas, and plasma oscillations.
– Portions of Chap. 21: Sec. 21.2 on the wave equation and
dispersion relation for dielectrics, Sec. 21.3 on the two-ﬂuid
formalism, Sec. 21.4 on Langmuir and ion-acoustic waves,
and Sec. 21.6 on the two-stream instability.
.
Chapter 23 on nonlinear dynamics of plasmas relies heavily on this
chapter.
particles traveling faster than the wave and losing energy to it than those traveling
slower and extracting energy from it. However, in a collisionless plasma, the parti-
cle distributions need not be Maxwellian. In particular, it is possible for a plasma to
possess an “inverted” particle distribution with more fast than slow ones; then there
is a net injection of particle energy into the waves, which creates an instability. In
Sec. 22.4, we use kinetic theory to derive a necessary and sufﬁcient criterion for this
instability.
In Sec. 22.5, we examine in greater detail the physics of Landau damping and
showthatitisanintrinsicallynonlinearphenomenon; andwegiveasemi-quantitative
discussion of nonlinear Landau damping, preparatory to a more detailed treatment of
some other nonlinear plasma effects in the following chapter.
Although the kinetic-theory, Vlasov description of a plasma that is developed
and used in this chapter is a great improvement on the two-ﬂuid description of
Chap. 21, it is still an approximation, and some situations require more accurate
descriptions. We conclude this chapter in Sec. 22.6 by introducing greater accuracy
via N-particle distribution functions, and as applications we use them (i) to explore the
approximations underlying the Vlasov description, and (ii) to explore two-particle
correlations that are induced in a plasma by Coulomb interactions and the inﬂuence
of those correlations on a plasma’s equation of state.
22.2
22.2 Basic Concepts of Kinetic Theory and Its Relationship to Two-Fluid Theory
22.2.1
22.2.1 Distribution Function and Vlasov Equation
In Chap. 3, we introduced the number density of particles in phase space, the distribu-
tion function N (p, x, t). We showed that this quantity is Lorentz invariant, and that
it satisﬁes the collisionless Boltzmann equation (3.64) and (3.65). We interpreted this
1070
Chapter 22. Kinetic Theory of Warm Plasmas

equation as N being constant along the phase-space trajectory of any freely moving
particle.
To comply with the conventions of the plasma-physics community, we use the
name Vlasov equation in place of collisionless Boltzmann equation.1 We change nota-
Vlasov equation
tion in a manner described in Sec. 3.2.3: we use a particle’s velocity v rather than its
momentum p as an independent variable, and we deﬁne the distribution function f
to be the number density of particles in physical and velocity space:
distribution function
in plasma physics
conventions
f (v, x, t) =
dN
dVxdVv
=
dN
dxdydzdvxdvydvz
.
(22.1)
Note that the integral of f over velocity space is the number density n(x, t) of particles
in physical space:

f (v, x, t) dVv = n(x, t),
(22.2)
where dVv ≡dvxdvydvz is the 3-dimensional volume element of velocity space. (For
simplicity, we also restrict ourselves to nonrelativistic speeds; the generalization to
relativistic plasma theory is straightforward.)
This one-particle distribution function f (v, x, t) and its resulting kinetic theory
give a good description of a plasma in the regime of large Debye number, ND ≫1—
which includes almost all plasmas that occur in the universe (cf. Sec. 20.3.2 and
Fig. 20.1). The reason is that, whenND ≫1, we can deﬁnef (v, x, t) by averaging over
aphysical-spacevolumethatislargecomparedtotheaverageinterparticlespacingand
that thus contains many particles, but is still small compared to the Debye length. By
such an average—the starting point of kinetic theory—the electric ﬁelds of individual
particlesaremadeunimportant, asaretheCoulomb-interaction-inducedcorrelations
between pairs of particles. We explore this issue in detail in Sec. 22.6.2, using a two-
particle distribution function.
In Chap. 3, we showed that, in the absence of collisions (a good assumption
for plasmas!), the distribution function evolves in accord with the Vlasov equation
(3.64) and (3.65). We now rederive that Vlasov equation beginning with the law of
conservation of particles for each species s = e (electrons) and p (protons):
particle conservation for
species sss (electron or
proton)
∂fs
∂t + ∇. (fsv) + ∇v . (fsa) ≡∂fs
∂t +
∂(fsvj)
∂xj
+
∂(fsaj)
∂vj
= 0.
(22.3)
1.
This equation was introduced and explored in 1913 by James Jeans in the context of stellar dynamics,
and then rediscovered and explored by Anatoly Alexandrovich Vlasov in 1938 in the context of plasma
physics. Plasma physicists have honored Vlasov by naming the equation after him. For details of this
history, see H´enon (1982).
22.2 Basic Concepts of Kinetic Theory and Its Relationship to Two-Fluid Theory
1071

Here
a = dv
dt = qs
ms
(E + v × B)
(22.4)
is the electromagnetic acceleration of a particle of species s, which has mass ms and
charge qs, and E and B are the electric and magnetic ﬁelds averaged over the same
volume as is used in constructing f . Equation (22.3) has the standard form for a
conservation law: the time derivative of a density (in this case density of particles
in phase space, not just physical space), plus the divergence of a ﬂux (in this case
the spatial divergence of the particle ﬂux, f v = f dx/dt, in the physical part of phase
space, plusthevelocitydivergenceoftheparticleﬂux, f a = f dv/dt, invelocityspace)
is equal to zero.
Now x and v are independent variables, so that ∂xi/∂vj = 0 and ∂vi/∂xj = 0.
In addition, E and B are functions of x and t but not of v, and the term v × B is
perpendicular to v. Therefore, we have
∇v . (E + v × B) = 0.
(22.5)
These facts permit us to pull v and a out of the derivatives in Eq. (22.3), thereby
obtaining
Vlasov equation for
species sss
∂fs
∂t + (v . ∇)fs + (a . ∇v)fs ≡∂fs
∂t +
dxj
dt
∂fs
∂xj
+
dvj
dt
∂fs
∂vj
= 0.
(22.6)
Werecognizethisasthestatementthat fs isaconstantalongthetrajectoryofaparticle
in phase space:
dfs
dt = 0,
(22.7)
which is the Vlasov equation for species s.
Equation (22.7) tells us that, when the space density near a given particle increases,
the velocity-space density must decrease, and vice versa. Of course, if we ﬁnd that
other forces or collisions are important in some situation, we can represent them by
extra terms added to the right-hand side of the Vlasov equation (22.7) in the manner
of the Boltzmann transport equation (3.66) (cf. Sec. 3.6).
So far, we have treated the electromagnetic ﬁeld as being somehow externally
imposed. However, it is actually produced by the net charge and current densities as-
sociated with the two particle species. These are expressed in terms of the distribution
functions by
charge density and current
density as integrals over
distribution functions
ρe =
 
s
qs

fs dVv,
j =
 
s
qs

fsv dVv.
(22.8)
1072
Chapter 22. Kinetic Theory of Warm Plasmas

Equations (22.8), together with Maxwell’s equations and the Vlasov equation (22.6),
with a = dv/dt given by the Lorentz force law (22.4), form a complete set of equations
for the structure and dynamics of a plasma. They constitute the kinetic theory of
plasmas.
22.2.2
22.2.2 Relation of Kinetic Theory to Two-Fluid Theory
Before developing techniques to solve the Vlasov equation, we ﬁrst relate it to the two-
ﬂuid approach used in the previous chapter. We begin by constructing the moments
of the distribution function fs, deﬁned by
macroscopic, two-ﬂuid
quantities as integrals over
distribution functions
ns =

fs dVv,
us = 1
ns

fsv dVv,
Ps = ms

fs(v −us) ⊗(v −us) Vv.
(22.9)
These are respectively the density, the mean ﬂuid velocity, and the pressure tensor
for species s. (Of course, Ps is just the 3-dimensional stress tensor Ts [Eq. (3.32d)]
evaluated in the rest frame of the ﬂuid.)
By integrating the Vlasov equation (22.6) over velocity space and using

(v . ∇)fs dVv =

∇. (fsv) dVv = ∇.

fsv dVv,

(a . ∇v)fs dVv = −

(∇v . a)fs dVv = 0,
(22.10)
together with Eq. (22.9), we obtain the continuity equation,
continuity equation
∂ns
∂t + ∇. (nsus) = 0,
(22.11)
foreachparticlespeciess.[ItshouldnotbesurprisingthattheVlasovequationimplies
the continuity equation, since the Vlasov equation is equivalent to the conservation
of particles in phase space [Eq. (22.3)], while the continuity equation is just the
conservation of particles in physical space.]
The continuity equation is the ﬁrst of the two fundamental equations of two-ﬂuid
theory. The second is the equation of motion (i.e., the evolution equation for the ﬂuid
velocity us). To derive this, we multiply the Vlasov equation (22.6) by the particle
velocityv andthenintegrateovervelocityspace(i.e., wecomputetheVlasovequation’s
ﬁrst moment). The details are a useful exercise for the reader (Ex. 22.1); the result is
equation of motion
nsms
∂us
∂t + (us . ∇)us

= −∇. Ps + nsqs(E + us × B),
(22.12)
which is identical with Eq. (21.13b).
22.2 Basic Concepts of Kinetic Theory and Its Relationship to Two-Fluid Theory
1073

A difﬁculty now presents itself in the two-ﬂuid approximation to kinetic theory.
constructing two-ﬂuid
equations from kinetic
theory by method of
moments
We can use Eqs. (22.8) to compute the charge and current densities from ns and us,
which evolve via the ﬂuid equations (22.11) and (22.12). However, we do not yet
know how to compute the pressure tensor Ps in the two-ﬂuid approximation. We
could derive a ﬂuid equation for its evolution by taking the second moment of the
Vlasov equation (i.e., multiplying it by v ⊗v and integrating over velocity space),
but that evolution equation would involve an unknown third moment of fs on the
right-hand side, M3 =

fsv ⊗v ⊗v dVv, which is related to the heat-ﬂux tensor. To
determine the evolution of this M3, we would have to construct the third moment of
the Vlasov equation, which would involve the fourth moment of fs as a driving term,
and so on. Clearly, this procedure will never terminate unless we introduce some
the need for a closure
relation
additional relationship between the moments. Such a relationship, called a closure
relation, permits us to build a self-contained theory involving only a ﬁnite number of
moments.
For the two-ﬂuid theory of Chap. 21, the closure relation that we implicitly used
was the same idealization that one makes when regarding a ﬂuid as perfect, namely,
that the heat-ﬂux tensor vanishes. This idealization is less well justiﬁed in a collision-
less plasma, with its long mean free paths, than in a normal gas or liquid (which has
short mean free paths).
An example of an alternative closure relation is one that is appropriate if radiative
processes thermostat the plasma to a particular temperature, so Ts = const; then we
can set Ps = nskBTsg ∝ns, where g is the metric tensor. Clearly, a ﬂuid theory of
plasmas can be no more accurate than its closure relation.
22.2.3
22.2.3 Jeans’ Theorem
Let us now turn to the difﬁcult task of ﬁnding solutions to the Vlasov equation. There
isanelementary(and, afterthefact, obvious)methodtowritedownaclassofsolutions
that is often useful. This is based on Jeans’ theorem (named after the astronomer who
ﬁrst drew attention to it in the context of stellar dynamics; Jeans, 1929).
Suppose that we know the particle acceleration a as a function of v, x, and t. (We
assume this for pedagogical purposes; it is not necessary for our ﬁnal conclusion.)
Then for any particle with phase-space coordinates (x0, v0) speciﬁed at time t0, we
can (at least in principle) compute the particle’s future motion: x = x(x0, v0, t), v =
v(x0, v0, t). These particle trajectories are the characteristics of the Vlasov equation,
analogous to the characteristics of the equations for 1-dimensional supersonic ﬂuid
ﬂow that we studied in Sec. 17.4 (see Fig. 17.7). For many choices of the acceleration
a(v, x, t), there are constants of the motion, also known as integrals of the motion,
constants of motion for a
particle
that are preserved along the particle trajectories. Simple examples, familiar from
elementary mechanics, include the energy (for a time-independent plasma) and the
angular momentum (for a spherically symmetric plasma). These integrals can be
expressed in terms of the initial coordinates (x0, v0). If we know n constants of
1074
Chapter 22. Kinetic Theory of Warm Plasmas

the motion, then only 6 −n additional variables need be chosen from (x0, v0) to
completely specify the motion of the particle.
The Vlasov equation tells us that fs is constant along a trajectory in x-v space.
Therefore, in general fs must be expressible as a function of (x0, v0). Equivalently,
it can be rewritten as a function of the n constants of the motion and the remaining
6 −ninitialphase-spacecoordinates.However, thereisnorequirementthatitactually
depend on all of these variables. In particular, any function of the integrals of motion
alone that is independent of the remaining initial coordinates will satisfy the Vlasov
equation (22.6). This is Jeans’ theorem. In words, functions of constants of the motion
Jeans’ theorem: solution
of Vlasov equation based
on constants of particle
motion
take constant values along actual dynamical trajectories in phase space and therefore
satisfy the Vlasov equation.
Of course, a situation may be so complex that no integrals of the particles’ equation
ofmotioncanbefound, inwhichcaseJeans’theoremwon’thelpusﬁndsolutionsofthe
Vlasov equation. Alternatively, there may be integrals but the initial conditions may
be sufﬁciently complex that extra variables are required to determine fs. However, it
turns out that in a wide variety of applications, particularly those with symmetries
(e.g., time independence ∂fs/∂t = 0), simple functions of simple constants of the
motion sufﬁce to describe a plasma’s distribution functions.
We have already met and used a variant of Jeans’ theorem in our analysis of
statisticalequilibriuminSec.4.4.Therethestatisticalmechanicsdistributionfunction
ρ was found to depend only on the integrals of the motion.
We have also, unknowingly, used Jeans’ theorem in our discussion of Debye
shielding in a plasma (Sec. 20.3.1). To understand this, let us suppose that we have
a single isolated positive charge at rest in a stationary plasma (∂fs/∂t = 0), and
we want to know the electron distribution function in its vicinity. Let us further
suppose that the electron distribution at large distances from the charge is known
to be Maxwellian with temperature T : fe(v, x, t) ∝exp[−1
2mev2/(kBT )]. Now, the
electrons have an energy integral, E = 1
2mev2 −e, where  is the electrostatic
potential. As  becomes constant at large distances from the charge, we can therefore
write fe ∝exp[−E/(kBT )]at large distances. However, the particles near the charge
must have traveled there from a large distance and so must have this same distribution
function. Therefore, close to the charge, we have
fe ∝e−E/kBT = e−[(mev2/2−e)/(kBT )],
(22.13)
and the electron density is obtained by integration over velocity:
ne =

fe dVv ∝e[e/(kBT )].
(22.14)
ThisisjusttheBoltzmanndistributionthatweassertedtobeappropriateinSec.20.3.1.
22.2 Basic Concepts of Kinetic Theory and Its Relationship to Two-Fluid Theory
1075

EXERCISES
Exercise 22.1 Derivation: Two-Fluid Equation of Motion
Derive the two-ﬂuid equation of motion (22.12) by multiplying the Vlasov equation
(22.6) by v and integrating over velocity space.
Exercise 22.2 Example: Positivity of Distribution Function
The particle distribution function f (v, x, t) ought not to become negative if it is to
remain physical. Show that this is guaranteed if it initially is everywhere nonnegative
and it evolves by the collisionless Vlasov equation.
Exercise 22.3 Problem and Challenge: Jeans’ Theorem in Stellar Dynamics
Jeans’ theorem is of great use in studying the motion of stars in a galaxy. The stars are
also almost collisionless and can be described by a distribution function f (v, x, t).
However, there is only one sign of “charge” and no possibility of screening. In this
problem, we make a model of a spherical galaxy composed of identical-mass stars.2
(a) The simplest type of distribution function is a function of one integral of a star’s
motion, the energy per unit mass: E = 1
2v2 + , where  is the gravitational
potential. A simple example is f (E) ∝| −E|7/2 for negative energy and zero
for positive energy. Verify that the associated mass density satisﬁes: ρ ∝[1 +
(r/s)2]−5/2, where r is the radius, and s is a scale that you should identify.
(b) This density proﬁle does not agree with observations, so we need to ﬁnd an
algorithm for computing the distribution function that gives a speciﬁed density
proﬁle. Show that for a general f (E) satisfying appropriate boundary conditions,
dρ
d = −81/2π m
 0

dE
f (E)
(E −)1/2 ,
(22.15a)
where m is the mass of a star.
(c) Equation (22.15a) is an Abel integral equation. Conﬁrm that it can be inverted to
give the desired algorithm:
f (E) =
1
81/2π2 m
d
dE
 0
E
d
dρ/d
( −E)1/2 .
(22.15b)
(d) ComputethedistributionfunctionthatispairedwiththeJaffe proﬁle, whichlooks
more like a real galaxy:
ρ ∝
1
r2(r + s)2 .
(22.16)
2.
We now know that the outer parts of galaxies are dominated by dark matter (Sec. 28.3.2), which may
comprise weakly interacting elementary particles that should satisfy the Vlasov equation just as stars do.
1076
Chapter 22. Kinetic Theory of Warm Plasmas

(e) We can construct two-integral spherical models using f (E, L), where L is a star’s
totalangularmomentumperunitmass.Whatextrafeaturecanwehopetocapture
using this broader class of distribution functions?
22.3
22.3 Electrostatic Waves in an Unmagnetized Plasma: Landau Damping
As our principal application of the kinetic theory of plasmas, we explore its predic-
tions for the dispersion relations; stability; and damping of longitudinal, electrostatic
waves in an unmagnetized plasma—Langmuir waves and ion-acoustic waves. When
studying these waves in Sec. 21.4.3 using two-ﬂuid theory, we alluded time and again
to properties of the waves that could not be derived by ﬂuid techniques. Our goal now
is to elucidate those properties using kinetic theory. As we shall see, their origin lies
in the plasma’s velocity-space dynamics.
22.3.1
22.3.1 Formal Dispersion Relation
Consider an electrostatic wave propagating in the z direction. Such a wave is 1-
dimensional in that the electric ﬁeld points in the z direction, E = Eez, and varies
as ei(kz−ωt), so it depends only on z and not on x or y; the distribution function
similarly varies as ei(kz−ωt) and is independent of x, y; and the Vlasov, Maxwell, and
Lorentz force equations produce no coupling of particle velocities vx and vy to the
z direction. These properties suggest the introduction of 1-dimensional distribution
functions, obtained by integration over vx and vy:
1-dimensional distribution
function for plasma
interacting with a
longitudinal electrostatic
wave (Langmuir or
ion-acoustic)
Fs(v, z, t) ≡

fs(vx, vy, v = vz, z, t)dvxdvy.
(22.17)
Here and throughout we suppress the subscript z on vz.
Restricting ourselves to weak waves, so nonlinearities can be neglected, we lin-
earize the 1-dimensional distribution functions:
Fs(v, z, t) ≃Fs0(v) + Fs1(v, z, t).
(22.18)
Here Fs0(v) is the distribution function of the unperturbed particles (s = e for elec-
trons and s = p for protons) in the absence of the wave, and Fs1 is the perturbation
induced by and linearly proportional to the electric ﬁeld E. The evolution of Fs1 is
governed by the linear approximation to the Vlasov equation (22.6):
∂Fs1
∂t
+ v ∂Fs1
∂z + qsE
ms
dFs0
dv = 0.
(22.19)
Here E is a ﬁrst-order quantity, so in its term we keep only the zero-order dFs0/dv.
22.3 Electrostatic Waves in an Unmagnetized Plasma: Landau Damping
1077

Weseekamonochromaticplane-wavesolutiontothisVlasovequation, so∂/∂t →
−iω and ∂/∂z →ik in Eq. (22.19). Solving the resulting equation for Fs1, we obtain
solution of linearized
Vlasov equation
Fs1 =
−iqs
ms(ω −kv)
dFs0
dv E.
(22.20)
This equation implies that the charge density associated with the wave is related to
the electric ﬁeld by
ρe =
 
s
qs
 +∞
−∞
Fs1dv =
* 
s
−iq2
s
ms
 +∞
−∞
F ′
s0 dv
ω −kv
+
E,
(22.21)
where the prime denotes a derivative with respect to v: F ′
s0 = dFs0/dv.
A quick route from here to the waves’ dispersion relation is to insert this charge
density into Poisson’s equation, ∇. E = ikE = ρe/ϵ0, and note that both sides are
proportional to E, so a solution is possible only if
1 +
 
s
q2
s
msϵ0k
 +∞
−∞
F ′
s0 dv
ω −kv = 0.
(22.22)
An alternative route, which makes contact with the general analysis of waves in a
dielectric medium (Sec. 21.2), is developed in Ex. 22.4. This route reveals that the
dispersion relation is given by the vanishing of the zz component of the dielectric
tensor, which we denoted ϵ3 in Chap. 21 [Eq. (21.45)], and it shows that ϵ3 is given by
expression (22.22):
ϵ3(ω, k) = 1 +
 
s
q2
s
msϵ0k
 +∞
−∞
F ′
s0 dv
ω −kv = 0.
(22.23)
Since ϵ3 = ϵzz is the only component of the dielectric tensor that we meet in this
chapter, we simplify notation henceforth by omitting the subscript 3 (i.e., by denoting
ϵzz = ϵ).
The form of the dispersion relation (22.23) suggests that we combine the un-
perturbed electron and proton distribution functions Fe0(v) and Fp0(v) to produce
a single, uniﬁed distribution function:
uniﬁed distribution
function
F(v) ≡Fe0(v) + me
mp
Fp0(v),
(22.24)
in terms of which the dispersion relation takes the form
general dispersion
relation for electrostatic
waves—derived by Fourier
techniques
ϵ(ω, k) = 1 +
e2
meϵ0k
 +∞
−∞
F ′ dv
ω −kv = 0.
(22.25)
1078
Chapter 22. Kinetic Theory of Warm Plasmas

Note that each proton is weighted less heavily than each electron by a factor
me/mp = 1/1,836 in the uniﬁed distribution function (22.24) and the dispersion
relation (22.25). This is due to the protons’ greater inertia and corresponding weaker
response to an applied electric ﬁeld; it causes the protons to be of no importance
in Langmuir waves (Sec. 22.3.5). However, in ion-acoustic waves (Sec. 22.3.6), the
protons can play an important role, because large numbers of them may move with
thermalspeedsthatareclosetothewaves’phasevelocity, andtherebytheycaninteract
resonantly with the waves.
EXERCISES
Exercise 22.4 Example: Dielectric Tensor and Dispersion Relation
for Longitudinal, Electrostatic Waves
Derive expression (22.23) for the zz component of the dielectric tensor in a plasma
excited by a weak electrostatic wave, and show that the wave’s dispersion relation is
ϵ3 = 0. [Hint: Notice that the z component of the plasma’s electric polarization Pz is
related to the charge density by ∇. P = ikPz = −ρe [Eq. (21.1)]. Combine this with
Eq. (22.21) to get a linear relationship between Pz and Ez = E. Argue that the only
nonzero component of the plasma’s electric susceptibility is χzz, and deduce its value
by comparing the above result with Eq. (21.3). Then construct the dielectric tensor ϵij
from Eq. (21.5) and the algebratized wave operator Lij from Eq. (21.9), and deduce
thatthedispersionrelationdet||Lij|| = 0takestheformϵzz ≡ϵ3 = 0, whereϵ3isgiven
by Eq. (22.23).]
22.3.2
22.3.2 Two-Stream Instability
As a ﬁrst application of the general dispersion relation (22.25), we use it to rederive
the dispersion relation (21.74) associated with the cold-plasma two-stream instability
of Sec. 21.6.
multi-stream approach to
two-stream instability
We begin by performing an integration by parts on the general dispersion relation
(22.25), obtaining:
e2
meϵ0
 +∞
−∞
Fdv
(ω −kv)2 = 1.
(22.26)
We then presume, as in Sec. 21.6, that the ﬂuid consists of two or more streams of cold
particles (protons or electrons) moving in the z direction with different ﬂuid speeds
u1, u2, . . . , so F(v) = n1δ(v −u1) + n2δ(v −u2) + . . . . Here nj is the number
density of particles in stream j if the particles are electrons, and me/mp times the
number density if they are protons. Inserting this F(v) into Eq. (22.26) and noting
22.3 Electrostatic Waves in an Unmagnetized Plasma: Landau Damping
1079

that nje2/(meϵ0) is the squared plasma frequency ω2
pj of stream j, we obtain the
dispersion relation
ω2
p1
(ω −ku1)2 +
ω2
p2
(ω −ku2)2 + . . . = 1,
(22.27)
which is identical to the dispersion relation (21.74) used in our analysis of the two-
stream instability.
It should be evident that the general dispersion relation (22.26) [or equally well,
Eq. (22.25)] provides us with a tool for exploring how the two-stream instability is
inﬂuenced by a warming of the plasma (i.e., by a spread of particle velocities around
the mean, ﬂuid velocity of each stream). We explore this in Sec. 22.4.
22.3.3
22.3.3 The Landau Contour
The general dispersion relation (22.25) has a troubling feature: for real ω and k its
integrand becomes singular at v = ω/k = (the waves’ phase velocity) unless dF/dv
vanishes there, which is generically unlikely. This tells us that if k is real (as we shall
assume), then ω cannot be real, except perhaps for a nongeneric mode whose phase
velocity happens to coincide with a velocity for which dF/dv = 0.
ambiguity in general
dispersion relation
With ω/k complex, we must face the possibility of some subtlety in how the
integral over v in the dispersion relation (22.25) is performed—the possibility that
we may have to make v complex in the integral and follow some special route in the
complex velocity plane from v = −∞to v = +∞. Indeed, there is such a subtlety,
as Landau (1946) has shown. Our simple derivation of the dispersion relation in
Sec. 22.3.1 cannot reveal this subtlety—and, indeed, is suspicious, since in going from
Eq. (22.19) to Eq. (22.20), our derivation entailed dividing by ω −kv, which vanishes
when v = ω/k, and dividing by zero is always a suspicious practice. Faced with this
derivation of general
dispersion relation by
Landau’s method
conundrum, Landau developed a more sophisticated derivation of the dispersion
relation. It is based on posing generic initial data for electrostatic waves, then evolving
those data forward in time and identifying the plasma’s electrostatic modes by their
late-time sinusoidal behaviors, and ﬁnally reading off the dispersion relation for the
modes from the equations for the late-time evolution. In the remainder of this section,
we present a variant of Landau’s analysis.
This analysis is very important, including the portion (Ex. 22.5) assigned for the
reader to work out. The reader is encouraged to read through this section slowly, with
care, so as to understand clearly what is going on.
For simplicity, from the outset we restrict ourselves to plane waves propagating in
the z direction with some ﬁxed, real wave number k, so the linearized 1-dimensional
distribution function and the electric ﬁeld have the forms
Fs(v, z, t) = Fs0(v) + Fs1(v, t)eikz,
E(z, t) = E(t)eikz.
(22.28)
1080
Chapter 22. Kinetic Theory of Warm Plasmas

ω1
ω2
ω4
ω3
σ
ωi
ωr
FIGURE 22.1 Contour of integration for evaluating E(t) [Eq. (22.29)]
as a sum over residues of the integrand’s poles ωn—the complex
frequencies of the plasma’s modes.
At t = 0 we pose initial data Fs1(v, 0) for the electron and proton velocity distribu-
tions; these data determine the initial electric ﬁeld E(0) via Poisson’s equation. We
presume that these initial distributions [and also the unperturbed plasma’s velocity
distribution Fs0(v)] are analytic functions of velocity v, but aside from this constraint,
the Fs1(v, 0) are generic. (A Maxwellian distribution is analytic, and most any physi-
cally reasonable initial distribution can be well approximated by an analytic function.)
We then evolve these initial data forward in time. The ideal tool for such evo-
lution is the Laplace transform, and not the Fourier transform. The power of the
key to the derivation—
evolve arbitrary initial data
using Laplace transform
Laplace transform is much appreciated by engineers and is underappreciated by many
physicists. Those readers who are not intimately familiar with evolution via Laplace
transforms should work carefully through Ex. 22.5. That exercise uses Laplace trans-
forms, followed by conversion of the ﬁnal answer into Fourier language, to derive the
following formula for the time-evolving electric ﬁeld in terms of the initial velocity
distributions Fs1(v, 0):
E(t) =
 iσ+∞
iσ−∞
e−iωt
ϵ(ω, k)
' 
s
qs
2πϵ0k
 +∞
−∞
Fs1(v, 0)
ω −kv dv
(
dω.
(22.29)
Here the integral in frequency space is along the solid horizontal line at the top of Fig.
22.1, with the imaginary part of ω held ﬁxed at ωi = σ and the real part ωr varying
from −∞to +∞. The Laplace techniques used to derive this formula are carefully
designed to avoid any divergences and any division by zero. This careful design leads
to the requirement that the height σ of the integration line above the real frequency
axis be greater than the e-folding rate ℑ(ω) of the plasma’s most rapidly growing mode
(or, if none grow, still larger than zero and thus larger than ℑ(ω) for the most slowly
decaying mode):
σ > po ≡max
n
ℑ(ωn),
and
σ > 0.
(22.30)
22.3 Electrostatic Waves in an Unmagnetized Plasma: Landau Damping
1081

L
L
(a)
(b)
(c)
ω/k
ω/k
ω/k
vi
vi
vi
vr
vr
vr
σ/k
FIGURE 22.2 Derivation of the Landau contour L. (a) The dielectric function ϵ(ω, k) is originally
deﬁned, in Eq. (22.31), solely for the pole (the point labeled ω/k) lying in the upper half plane;
that is, for ωi/k = σ/k > 0. (b,c) Since ϵ(ω, k) must be an analytic function of ω at ﬁxed k and
thus must vary continuously as ω is continuously changed, the dashed contour of integration
in Eq. (22.31) must be kept always below the pole v = ω/k.
Here n = 1, 2, . . . labels the modes, ωn is the complex frequency of mode n, and ℑ
means take the imaginary part of. We shall see that the ωn are the zeros of the dielectric
function ϵ(ω, k) that appears in Eq. (22.29), that is, they are poles of the integrand of
the frequency integral.
Equation (22.29) also entails a velocity integral. In the Laplace-based analysis (Ex.
22.5) that leads to this formula, there is never any question about the nature of the
velocity v: it is always real, so the integral is over real v running from −∞to +∞.
However, because all the frequencies ω appearing in Eq. (22.29) have imaginary parts
ωi = σ > 0, there is no possibility in the velocity integral of any divergence of the
integrand.
In Eq. (22.29) for the evolving ﬁeld, ϵ(ω, k) is the same dielectric function (22.25)
as we deduced in our previous analysis (Sec. 22.3.1):
ϵ(ω, k) = 1 +
e2
meϵ0k
 +∞
−∞
F ′ dv
ω −kv ,
where F(v) = Fe0(v) + me
mp
Fp0.
(22.31)
However, by contrast with Sec. 22.3.1, our derivation here dictates unequivocally how
to handle the v integration—the same way as in Eq. (22.29): v is strictly real, and
the only frequencies appearing in the evolution equations have ωi = σ > 0, so the
v integral, running along the real velocity axis, passes under the integrand’s pole at
v = ω/k, as shown in Fig. 22.2a.
To read off the modal frequencies from the evolving ﬁeld E(t) at times t > 0,
we use techniques from complex-variable theory. It can be shown that, because (by
hypothesis) Fs1(v, 0) and Fs0(v) are analytic functions of v, the integrand of the ω
integral in Eq. (22.29) is meromorphic: when the integrand is analytically continued
throughout the complex frequency plane, its only singularities are poles. This permits
us to evaluate the frequency integral, at times t > 0, by closing the integration contour
in the lower-half frequency plane, as shown by the dashed curve in Fig. 22.1. Because
of the exponential factor e−iωt, the contribution from the dashed part of the contour
vanishes, which means that the integral around the contour is equal to E(t) (the
1082
Chapter 22. Kinetic Theory of Warm Plasmas

contributionfromthesolidhorizontalpart).Complex-variabletheorytellsusthatthis
integral is given by a sum over the residues Rn of the integrand at the poles (labeled
n = 1, 2, . . .):
E(t) = 2πi
 
n
Rn =
 
n
Ane−iωnt.
(22.32)
Here ωn is the frequency at pole n, and An is 2πiRn with its time dependence e−iωnt
factored out. It is evident, then, that each pole of the analytically continued integrand
of Eq. (22.29) corresponds to a mode of the plasma, and the pole’s complex frequency
is the mode’s frequency.
Now, for special choices of the initial data Fs1(v, 0), there may be poles in the
square-bracketed term in Eq. (22.29), but for generic initial data there will be none,
and the only poles will be the zeros of ϵ(ω, k). Therefore, generically, the modes’
frequencies are the zeros of ϵ(ω, k)—when that function (which was originally de-
ﬁned only for ω along the line ωi = σ) has been analytically extended throughout the
complex frequency plane.
So how do we compute the analytically extended dielectric function ϵ(ω, k)?
Imagine holding k ﬁxed and real, and exploring the (complex) value of ϵ, thought
of as a function of ω/k, by moving around the complex ω/k plane (same as the
complex velocity plane). In particular, imagine computing ϵ from Eq. (22.31) at one
point after another along the arrowed path shown in Fig. 22.2b,c. This path begins
at an initial location ω/k, where ωi/k = σ/k > 0, and travels down to some other
location below the real axis. At the starting point, the discussion in the paragraph
following Eq. (22.30) tells us how to handle the velocity integral: just integrate v along
the real axis. As ω/k is moved continuously (with k held ﬁxed), ϵ(ω, k) must vary
continuously, because it is analytic. When ω/k crosses the real velocity axis, if the
integrationcontourinEq.(22.31)weretoremainonthevelocityaxis, thenthecontour
would jump over the integral’s moving pole v = ω/k, and the function ϵ(ω, k) would
jump discontinuously at the moment of crossing, which is not possible. To avoid such
a discontinuous jump, it is necessary that the contour of integration be kept below the
pole, v = ω/k, asthatpolemovesintothelowerhalfofthevelocityplane(Fig.22.2b,c).
Landau contour and the
unambiguous general
dispersion relation for
electrostatic waves in an
unmagnetized plasma
Therulethattheintegrationcontourmustalwayspassbeneaththepolev = ω/k as
shown in Fig. 22.2 is called the Landau prescription; the contour is called the Landau
contour and is denoted L. Our ﬁnal formula for the dielectric function (and for its
vanishing at the modal frequencies—the dispersion relation) is
ϵ(ω, k) = 1 +
e2
meϵ0k

L
F ′dv
ω −kv = 0,
where
F(v) = Fe(v) + me
mp
Fp(v).
(22.33)
For future use we have omitted the subscript 0 from the unperturbed distribu-
tion functions Fs, as there should be no confusion in future contexts. We refer
22.3 Electrostatic Waves in an Unmagnetized Plasma: Landau Damping
1083

to Eq. (22.33) as the general dispersion relation for electrostatic waves in an un-
magnetized plasma.
EXERCISES
Exercise 22.5 **Example: Electric Field for Electrostatic Wave Deduced
Using Laplace Transforms
Use Laplace-transform techniques to derive Eqs. (22.29)–(22.31) for the time-
evolving electric ﬁeld of electrostatic waves with ﬁxed wave number k and initial
velocity perturbations Fs1(v, 0). A sketch of the solution follows.
(a) When the initial data are evolved forward in time, they produce Fs1(v, t) and
E(t). Construct the Laplace transforms (see, e.g., Arfken, Weber, and Har-
ris, 2013, Chap. 20, or Mathews and Walker, 1970, Sec. 4-3) of these evolving
quantities:
˜Fs1(v, p) =
 ∞
0
dt e−ptFs1(v, t),
˜E(p) =
 ∞
0
dt e−ptE(t). (22.34)
To ensure that the time integral is convergent, insist that ℜ(p) be greater than
p0 ≡maxn ℑ(ωn) ≡(the e-folding rate of the most strongly growing mode—or, if
none grow, then the most weakly damped mode). Also, to simplify the subsequent
analysis, insistthatℜ(p) > 0.Below, inparticular, weneedtheLaplacetransforms
for ℜ(p) = (some ﬁxed value σ that satisﬁes σ > po and σ > 0).
(b) By constructing the Laplace transform of the 1-dimensional Vlasov equation
(22.19) and integrating by parts the term involving ∂Fs1/∂t, obtain an equa-
tion for a linear combination of ˜Fs1(v, p) and ˜E(p) in terms of the initial data
Fs1(v, t = 0). By then combining with the Laplace transform of Poisson’s equa-
tion, show that
˜E(p) =
1
ϵ(ip, k)
 
s
qs
kϵ0
 ∞
−∞
Fs1(v, 0)
ip −kv dv.
(22.35)
Here ϵ(ip, k) is the dielectric function (22.25) evaluated for frequency ω = ip,
with the integral running along the real v-axis, and [as we noted in part (a)] with
ℜ(p)greaterthanp0, thelargestωi ofanymode, andgreaterthan0.Thissituation
for the dielectric function is the one depicted in Fig. 22.2a.
(c) Laplace-transform theory tells us that the time-evolving electric ﬁeld (with wave
number k) can be expressed in terms of its Laplace transform (22.35) by
E(t) =
 σ+i∞
σ−i∞
˜E(p) ept dp
2πi ,
(22.36)
where σ [as introduced in part (a)] is any real number larger than p0 and larger
than0.Combinethisequationwithexpression(22.35)for ˜E(p), andsetp = −iω.
Thereby arrive at the desired result, Eq. (22.29).
1084
Chapter 22. Kinetic Theory of Warm Plasmas

22.3.4
22.3.4 Dispersion Relation for Weakly Damped or Growing Waves
In most practical situations, electrostatic waves are weakly damped or weakly un-
stable: |ωi| ≪ωr (where ωr and ωi are the real and imaginary parts of the wave
frequency ω), so the amplitude changes little in one wave period. In this case, the
dielectric function (22.33) can be evaluated at ω = ωr + iωi using the ﬁrst term in a
Taylor series expansion away from the real axis:
ϵ(ωr + iωi, k) ≃ϵ(ωr, k) + ωi
 ∂ϵr
∂ωi
+ i ∂ϵi
∂ωi

ωi=0
= ϵ(ωr, k) + ωi

−∂ϵi
∂ωr
+ i ∂ϵr
∂ωr

ωi=0
≃ϵ(ωr, k) + iωi
 ∂ϵr
∂ωr

ωi=0
.
(22.37)
Here ϵr and ϵi are the real and imaginary parts of ϵ. In going from the ﬁrst line to the
second we have assumed that ϵ(ω, k) is an analytic function of ω near the real axis and
hence have used the Cauchy-Riemann equations for the derivatives (see, e.g., Arfken,
Weber, and Harris, 2013). In going from the second line to the third we have used
the fact that ϵi →0 when the velocity distribution is one that produces ωi →0 [cf.
Eq. (22.39)], so the middle term on the second line is second order in ωi and can be
neglected.
Equation (22.37) expresses the dielectric function slightly away from the real axis
in terms of its value and derivative on and along the real axis. The on-axis value can be
computed from Eq. (22.33) by breaking the Landau contour depicted in Fig. 22.2b into
three pieces—two lines from ±∞to a small distance δ from the pole, plus a semicircle
of radius δ under and around the pole—and by then taking the limit δ →0. The ﬁrst
two terms (the two straight lines) together produce the Cauchy principal value of the
integral (denoted

P below), and the third produces 2πi times half the residue of the
pole at v = ωr/k, so Eq. (22.33) becomes:
ϵ(ωr, k) = 1 −
e2
meϵ0k2

P
F ′ dv
v −ωr/k dv + iπF ′(v = ωr/k)

.
(22.38)
Inserting this equation and its derivative with respect to ωr into Eq. (22.37), and
setting the result to zero, we obtain
ϵ(ωr + iωi, k) ≃1 −
e2
meϵ0k2

P
F ′ dv
v −ωr/k + iπF ′(ωr/k)
+iωi
∂
∂ωr

P
F ′ dv
v −ωr/k

= 0.
(22.39)
Notice that the vanishing of ϵr determines the real part ωr of the frequency:
1 −
e2
meϵ0k2

P
F ′
v −ωr/k dv = 0,
(22.40a)
22.3 Electrostatic Waves in an Unmagnetized Plasma: Landau Damping
1085

and the vanishing of ϵi determines the imaginary part:
ωi =
πF ′(ωr/k)
−∂
∂ωr

P
F ′
v−ωr/kdv
.
(22.40b)
Equations (22.40) are the dispersion relation in the limit |ωi| ≪ωr. We refer to
general dispersion relation
for weakly damped
elastostatic waves in an
unmagnetized plasma
this as the small-|ωi| dispersion relation for electrostatic waves in an unmagnetized
plasma.
Notice that the sign of ωi is inﬂuenced by the sign of F ′ = dF/dv at v = ωr/k =
Vph = (the waves’ phase velocity). As we shall see, this has a simple physical origin
and important physical consequences. Usually, but not always, the denominator of
Eq. (22.40b) is positive, so the sign of ωi is the same as the sign of F ′(ωr/k).
22.3.5
22.3.5 Langmuir Waves and Their Landau Damping
We now apply the small-|ωi| dispersion relation (22.40) to Langmuir waves in a
thermalized plasma. Langmuir waves typically move so fast that the slow ions cannot
interact with them, so their dispersion relation is inﬂuenced signiﬁcantly only by the
electrons. Therefore, we ignore the ions and include only the electrons in F(v). We
obtain F(v) by integrating out vy and vz in the 3-dimensional Boltzmann distribution
[Eq. (3.22d) with E = 1
2me(v2
x + v2
y + v2
z)]; the result, correctly normalized so that

F(v)dv = n, is
F ≃Fe = n

me
2πkBT
1/2
e−[mev2/(2kBT )],
(22.41)
where T is the electron temperature.
Now, as we saw in Eq. (22.40b), ωi is proportional to F ′(v = ωr/k) with a propor-
tionality constant that is usually positive. Physically, this proportionality arises from
the manner in which electrons surf on the waves. Those electrons moving slightly
faster than the waves’ phase velocity Vph = ωr/k (usually) lose energy to the waves
energy conservation in
Landau damping
onaverage, whilethosemovingslightlyslower(usually)extractenergyfromthewaves
on average. Therefore,
1. iftherearemoreslightlyslowerparticlesthanslightlyfaster[F ′(v = ωr/k) <
0], then the particles on average gain energy from the waves and the waves
are damped [ωi < 0];
2. iftherearemoreslightlyfasterparticlesthanslightlyslower[F ′(v = ωr/k) >
0], then the particles on average lose energy to the waves and the waves are
ampliﬁed [ωi > 0]; and
3. the bigger the disparity between the number of slightly faster electrons and
the number of slightly slower electrons [i.e., the bigger |F ′(ωr/k)|], the
larger will be the damping or growth of wave energy (i.e., the larger will
be |ωi|).
1086
Chapter 22. Kinetic Theory of Warm Plasmas

Quantitatively, it turns out that if the waves’ phase velocity ωr/k is anywhere near
the steepest point on the side of the electron velocity distribution (i.e., if ωr/k is
of order the electron thermal velocity

kBT /me), then the waves will be strongly
damped: ωi ∼−ωr. Since our dispersion relation (22.41) is valid only when the waves
are weakly damped, we must restrict ourselves to waves with ωr/k ≫

kBT /me (a
physically allowed regime) or to ωr/k ≪

kBT /me (a regime that does not occur in
Langmuir waves; cf. Fig. 21.1).
Requiring, then, thatωr/k ≫

kBT /me andnotingthattheintegralinEq.(22.39)
gets its dominant contribution from velocities v <∼

kBT /me, we can expand 1/(v −
ωr/k) in the integrand as a power series in vk/ωr, obtaining

P
F ′ dv
v −ωr/k = −
 ∞
−∞
dvF ′
'
k
ωr
+ k2v
ω2
r
+ k3v2
ω3
r
+ k4v3
ω4
r
+ . . .
(
= nk2
ω2
r
+ 3n⟨v2⟩k4
ω4
r
+ . . .
= nk2
ω2
r
*
1 + 3kBT k2
meω2
r
+ . . .
+
≃nk2
ω2
r
*
1 + 3k2λ2
D
ω2
p
ω2
r
+
.
(22.42)
Substituting Eqs. (22.41) and (22.42) into Eqs. (22.40a) and (22.40b), and noting
that ωr/k ≫

kBT/me ≡ωpλD implies kλD ≪1 and ωr ≃ωp, we obtain
dispersion relation
for Langmuir waves
in an unmagnetized,
thermalized plasma
ωr = ωp(1 + 3k2λ2
D)1/2,
(22.43a)
ωi = −
π
8
1/2 ωp
k3λ3
D
exp
*
−
1
2k2λ2
D
−3
2
+
.
(22.43b)
The real part of this dispersion relation, ωr = ωp

1 + 3k2λ2
D, reproduces the
Bohm-Gross result (21.31) that we derived using the two-ﬂuid theory in Sec. 21.4.3
and plotted in Fig. 21.1. The imaginary part reveals the damping of these Langmuir
Landau damping of
Langmuir waves
waves by surﬁng electrons—so-called Landau damping. The two-ﬂuid theory could
not predict this Landau damping, because the damping is a result of internal dynamics
in the electrons’ velocity space, of which that theory is oblivious.
Notice that, as the waves’ wavelength is decreased (i.e., as k increases), the waves’
phase velocity decreases toward the electron thermal velocity and the damping be-
comes stronger, as is expected from our discussion of the number of electrons that can
surf on the waves. In the limit k →1/λD (where our dispersion relation has broken
down and so is only an order-of-magnitude guide), the dispersion relation predicts
that ωr/k ∼

kBT/me and ωi/ωr ∼1/10.
22.3 Electrostatic Waves in an Unmagnetized Plasma: Landau Damping
1087

In the opposite regime of large wavelength kλD ≪1 (where our dispersion rela-
tion should be quite accurate), the Landau damping is very weak—so weak that ωi
decreases to zero with increasing k faster than any power of k.
22.3.6
22.3.6 Ion-Acoustic Waves and Conditions for Their Landau Damping to Be Weak
As we saw in Sec. 21.4.3, ion-acoustic waves are the analog of ordinary sound waves
in a ﬂuid: they occur at low frequencies where the mean (ﬂuid) electron velocity is
very nearly locked to the mean (ﬂuid) proton velocity, so the electric polarization is
small; the restoring force is due to thermal pressure and not to the electrostatic ﬁeld;
and the inertia is provided by the heavy protons. It was asserted in Sec. 21.4.3 that
to avoid these waves being strongly damped, the electron temperature must be much
higher than the proton temperature: Te ≫Tp. We can now understand this condition
requirement that Te ≫Tp
Te ≫Tp
Te ≫Tp
for ion-acoustic waves
in terms of particle surﬁng and Landau damping.
Suppose that the electrons and protons have Maxwellian velocity distributions
but possibly with different temperatures. Because of their far greater inertia, the pro-
tons will have a far smaller mean thermal speed than the electrons, kBTp/mp ≪

kBTe/me, so the net 1-dimensional distribution function F(v) = Fe(v) +
(me/mp)Fp(v) [Eq. (22.24)] that appears in the kinetic-theory dispersion relation has
the form shown in Fig. 22.3. Now, if Te ∼Tp, then the contributions of the electron
pressure and proton pressure to the waves’ restoring force will be comparable, and the
waves’ phase velocity will therefore be ωr/k ∼kB(Te + Tp)/mp ∼kBTp/mp =
vth,p, which is the thermal proton velocity and also is the speed at which the proton
contribution to F(v) has its steepest slope (see the left tick mark on the horizontal
axis in Fig. 22.3); so |F ′(v = ωr/k)| is large. This means large numbers of protons
ion-acoustic waves’
strong Landau damping
if electrons and ions are
thermalized at same
temperature
can surf on the waves and a disparity develops between the number moving slightly
slower than the waves (which extract energy from the waves) and the number mov-
ing slightly faster (which give energy to the waves). The result will be strong Landau
damping by the protons.
This strong Landau damping is avoided if Te ≫Tp. Then the waves’ phase velocity
will be ωr/k ∼kBTe/mp, which is large compared to the proton thermal velocity
vth,p = kBTp/mp and so is way out on the tail of the proton velocity distribution,
where there are few protons that can surf and damp the waves; see the right tick mark
on the horizontal axis in Fig. 22.3. Thus Landau damping by protons has been shut
down by raising the electron temperature.
WhataboutLandaudampingbyelectrons?Thephasevelocityωr/k ∼kBTe/mp
is small compared to the electron thermal velocity vth,e =

kBTe/me, so the waves
reside near the peak of the electron velocity distribution, where Fe(v) is large, so
many electrons can surf with the waves. But F ′
e(v) is small, so there are nearly equal
numbers of faster and slower electrons, and the surﬁng produces little net Landau
damping. Thus Te/Tp ≫1 leads to successful propagation of ion acoustic waves.
A detailed computation, based on our small-ωi kinetic-theory dispersion relation
(22.40) makes this physical argument quantitative. The details are carried out in
1088
Chapter 22. Kinetic Theory of Warm Plasmas

v
0
kBTp/mp
kBTe/mp
Fp
Fe
F
F
FIGURE 22.3 Electron and ion contributions to the net distribution function F(v) in a
thermalized plasma. When Te ∼Tp, the phase speed of ion acoustic waves is near the left
tick mark on the horizontal axis—a speed at which surﬁng protons have maximum ability
to Landau-damp the waves, and the waves are strongly damped. When Te ≫Tp, the phase
speed is near the right tick mark—far out on the tail of the proton velocity distribution—so
few protons can surf and damp the waves. The phase speed is near the peak of the electron
distribution, so the number of electrons moving slightly slower than the waves is nearly the
same as the number moving slightly faster, and there is little net damping by the electrons. In
this case the waves can propagate.
Ex. 22.6 under the assumptions that Te ≫Tp and kBTp/mp ≪ωr/k ≪

kBTe/me
(corresponding to the above discussion). The result is
dispersion relation for
ion-acoustic waves in an
unmagnetized plasma
with electrons and ions
thermalized at different
temperatures, Te ≫Tp
Te ≫Tp
Te ≫Tp
ωr
k =
1
kBTe/mp
1 + k2λ2
D
,
(22.44a)
ωi
ωr
= −
√π/8
(1 + k2λ2
D)3/2
⎡
⎣
1
me
mp
+
*
Te
Tp
+3/2
exp
*
−Te/Tp
2(1 + k2λ2
D) −3
2
+⎤
⎦.
(22.44b)
The real part of this dispersion relation was plotted in Fig. 21.1. As is shown there
and in the above formulas, for kλD ≪1 the waves’ phase speed is kBTe/mp, and
the waves are only weakly damped: they can propagate for roughly mp/me ∼43
periodsbeforedampinghasastrongeffect.Thisdampingisindependentoftheproton
temperature, so it must be due to surﬁng electrons. When the wavelength is decreased
(k isincreased)intotheregimekλD >∼1, thewaves’frequencyasymptotestowardωr =
ωpp, the proton plasma frequency. Then the phase velocity decreases, so more protons
can surf the waves, and the Landau damping increases. Equations (22.44) show us that
the damping becomes very strong when kλD ∼Te/Tp, and that this is also the point
at which ωr/k has decreased to the proton thermal velocity kBTp/mp—which is in
accord with our physical arguments about proton surﬁng.
22.3 Electrostatic Waves in an Unmagnetized Plasma: Landau Damping
1089

WhenTe/Tp isdecreasedfrom ≫1towardunity, theiondampingbecomesstrong
regardless of how small may be k [cf. the second term of Eq. (22.44b)]. This is also in
accord with our physical reasoning.
Ion-acoustic waves are readily excited at Earth’s bow shock, where Earth’s mag-
netosphere impacts the solar wind. It is observed that these waves are not able to
propagate very far away from the shock, by contrast with Alfv´en waves, which are
much less rapidly damped.
EXERCISES
Exercise 22.6 Derivation: Ion-Acoustic Dispersion Relation
Consider a plasma in which the electrons have a Maxwellian velocity distribution
with temperature Te, the protons are Maxwellian with temperature Tp, and Tp ≪Te.
Consider an ion acoustic mode in this plasma for which kBTp/mp ≪ωr/k ≪

kBTe/me (i.e., the wave’s phase velocity is between the left and right tick marks
in Fig. 22.3). As was argued in the text, for such a mode it is reasonable to expect
weak damping: |ωi| ≪ωr. Making approximations based on these “≪” inequalities,
show that the small-|ωi| dispersion relation (22.40) reduces to Eqs. (22.44).
Exercise 22.7 Problem: Dispersion Relations for a Non-Maxwellian
Distribution Function
Consider a plasma with cold protons and hot electrons with a 1-dimensional distri-
bution function proportional to 1/(v2
0 + v2), so the full 1-dimensional distribution
function is
F(v) =
nv0
π(v2
0 + v2) + n me
mp
δ(v).
(22.45)
(a) Show that the dispersion relation for Langmuir waves, with phase speeds large
compared to v0, is
ω ≃ωpe −ikv0.
(22.46)
(b) Compute the dispersion relation for ion-acoustic waves, assuming that their
phase speeds are much less than v0 but are large compared to the cold protons’
thermal velocities (so the contribution from proton surﬁng can be ignored). Your
result should be
ω ≃
kv0(me/mp)1/2
[1 + (kv0/ωpe)2]1/2 −
ikv0(me/mp)
[1 + (kv0/ωpe)2]2 .
(22.47)
22.4
22.4 Stability of Electrostatic Waves in Unmagnetized Plasmas
Our small-ωi dispersion relation (22.40) implies that the sign of F ′ at resonance
dictates the sign of the imaginary part of ω. This raises the interesting possibility that
1090
Chapter 22. Kinetic Theory of Warm Plasmas

distribution functions that increase with velocity over some range of positive v might
be unstable to the exponential growth of electrostatic waves. In fact, the criterion for
instability turns out to be a little more complex than this [as one might suspect from
the fact that the sign of the denominator of Eq. (22.40b) is not obvious], and deriving
it is an elegant exercise in complex-variable theory.
We carry out our derivation in two steps. We ﬁrst introduce a general method, due
to Harry Nyquist, for diagnosing instabilities of dynamical systems. Then we apply
Nyquist’s method explicitly to electrostatic waves in an unmagnetized plasma and
thereby deduce an instability criterion due to Oliver Penrose.
22.4.1
22.4.1 Nyquist’s Method
Consider any dynamical system whose modes of oscillation have complex eigen-
freqencies ω that are zeros of some function D(ω). [In our case the dynamical system
is electrostatic waves in an unmagnetized plasma with some chosen wave number k,
and because the waves’ dispersion relation is ϵ(ω, k) = 0, Eq. (22.33), the function D
can be chosen as D(ω) = ϵ(ω, k).] Unstable modes are zeros of D(ω) that lie in the
upper half of the complex-ω plane.
Assume that D(ω) is analytic in the upper half of the ω plane. Then a well-known
theorem in complex-variable theory3 says that the number Nz of zeros of D(ω) in
the upper half-plane, minus the number Np of poles, is equal to the number of times
that D(ω) encircles the origin counterclockwise, in the complex-D plane, as ω travels
Nyquist diagram and
method for deducing the
number of unstable modes
of a dynamical system
counterclockwise along the closed path C that encloses the upper half of the frequency
plane; see Fig. 22.4.
If one knows the number of poles of D(ω) in the upper half of the frequency plane,
then one can infer, from the Nyquist diagram, the number of unstable modes of the
dynamical system.
In Sec. 22.4.2, we use this Nyquist method to derive the Penrose criterion for
instability of electrostatic modes of an unmagnetized plasma. As a second example,
in Box 22.2, we show how it can be used to diagnose the stability of a feedback control
system.
22.4.2
22.4.2 Penrose’s Instability Criterion
The straightforward way to apply Nyquist’s method to electrostatic waves would be to
set D(ω) = ϵ(ω, k). However, to reach our desired instability criterion more quickly,
we set D = k2ϵ; then the zeros of D are still the electrostatic waves’ modes. From Eq.
(22.33) for ϵ, we see that
D(ω) = k2 −Z(ω/k),
(22.48a)
3.
This is variously called “the principle of the argument” or “Cauchy’s theorem,” and it follows from the
theorem of residues (e.g., Copson, 1935, Sec. 6.2; Arfken, Weber, and Harris, 2013, Chap. 11).
22.4 Stability of Electrostatic Waves in Unmagnetized Plasmas
1091

ωi
Di
Dr
ωr
ω plane
D plane
(a)
(b)
C
C′
FIGURE 22.4 Nyquist diagram for stability of a dynamical system. (a) The curve C in the complex-
ω plane extends along the real frequency axis from ωr = −∞to ωr = +∞, then closes up
along the semicircle at |ω| = ∞, so it encloses the upper half of the frequency plane. (b) As
ω travels along C, D(ω) travels along the closed curve C′ in the complex-D plane, which
counterclockwise encircles the origin twice. Thus the number of zeros of the analytic function
D(ω) in the upper half of the frequency plane minus the number of poles is Nz −Np = 2.
.
where
Z(ζ) ≡
e2
meϵ0

L
F ′
v −ζ dv,
(22.48b)
with ζ = ω/k the waves’ phase velocity.
These equations have several important consequences.
1. For ζ in the upper half-plane—the region that concerns us—we can choose
the Landau contour L to travel along the real v-axis from −∞to +∞, and
the resulting D(ω) is analytic in the upper half of the frequency plane, as
required for Nyquist’s method.
2. For all ζ in the upper half-plane, and for all distribution functions F(v)
that are nonnegative and normalizable and thus physically acceptable, the
velocity integral is ﬁnite, so there are no poles of D(ω) in the upper half-
plane. Thus there is an unstable mode, for ﬁxed k, if and only if D(ω)
encircles the origin at least once, as ω travels around the curve C of Fig. 22.4.
Note that the encircling is guaranteed to be counterclockwise, since there are
no poles.
3. The wave frequency ω traveling along the curve C in the complex-frequency
plane is equivalent to ζ traveling along the same curve in the complex-
phase-velocity plane; and D encircling the origin of the complex-D plane
is equivalent to Z(ζ) encircling the point Z = k2 on the positive real axis of
the complex-Z plane.
4. For every point on the semicircular segment of the curve C at |ζ| →∞
(Fig. 22.4), Z(ζ) vanishes, so the curve C can be regarded as going just along
the real axis from −∞to +∞, during which Z(ζ) emerges from the origin,
travels around some curve, and returns to the origin.
1092
Chapter 22. Kinetic Theory of Warm Plasmas

BOX 22.2.
STABILITY OF A FEEDBACK-CONTROL SYSTEM:
ANALYSIS BY NYQUIST’S METHOD
A control system can be described quite generally by the following block
diagram.
H
ui
u = ui + uf
uo
uo
uf
G
An input signal ui(t) and the feedback signal uf(t) are added, then fed
through a ﬁlter G to produce an output signal uo(t) =
 +∞
−∞G(t −t′)u(t′)dt′;
or, in the Fourier domain, ˜uo(ω) = ˜G(ω)˜u(ω). [See Sec. 6.7 for ﬁltering of
signals. Here, for consistency with this plasma-physics chapter, we adopt the
opposite sign convention for Fourier transforms from that in Sec. 6.7.] Then
the output signal is fed through a ﬁlter H to produce the feedback signal
uf(t).
As an example, consider the following simple model for an automobile’s
cruise control. The automobile’s speed v is to be locked to some chosen
value V by measuring v and applying a suitable feedback acceleration. To
simplify the analysis, we focus on the difference u ≡v −V , which is to be
locked to zero. The input to the control system is the speed ui(t) that the
automobile would have in the absence of feedback, plus the speed change
uf(t) due to the feedback acceleration. Their sum, u = ui + uf, is measured
by averaging over a short time interval, with the average exponentially
weighted toward the present (in our simple model), so the output of the
measurement is uo(t) = (1/τ)
 t
−∞e(t′−t)/τu(t′)dt′. By comparing with
uo =
 +∞
−∞G(t −t′)u(t′)dt′ to infer the measurement ﬁlter’s kernel G(t), then
Fourier transforming, we ﬁnd that ˜G(ω) ≡
 +∞
−∞G(t)eiωtdt = 1/(1 −iωτ).
If uo(t) is positive, we apply to the automobile a negative feedback
acceleration af(t) proportional to it; if uo is negative, we apply a positive
feedback acceleration; so in either case, af = −Kuo for some positive
constant K. The feedback speed uf is the time integral of this acceleration:
uf(t) = −K
 t
−∞uo(t′)dt′. Setting this to
 ∞
−∞H(t −t′)uo(t′)dt′, reading off
thekernelH, andcomputingitsFouriertransform, weﬁnd ˜H(ω) = −K/(iω).
From the block diagram, we see, fully generally, that in the Fourier domain
˜uo = ˜G(˜ui + ˜uf) = ˜G(˜ui + ˜H ˜uo); so the output in terms of the input is
˜uo =
˜G
1 + ˜G ˜H
˜ui.
(1)
(continued)
22.4 Stability of Electrostatic Waves in Unmagnetized Plasmas
1093

BOX 22.2.
(continued)
Evidently, the feedback system will undergo self-excited oscillations, with no
input, at any complex frequency ω that is a zero of D(ω) ≡1 + ˜G(ω) ˜H(ω). If
that ω is in the lower half of the complex frequency plane, the oscillations will
die out and so are not a problem; but if it is in the upper half-plane, they will
grow exponentially with time. Thus the zeros of D(ω) in the upper half of the
ω plane represent unstable modes of self-excitation and must be avoided in
the design of any feedback-control system.
For our cruise-control example, D is 1 + ˜G ˜H = 1 −K[iω(1 −iωτ)]−1,
which can be brought into a more convenient form by introducing the
dimensionless frequency z = ωτ and dimensionless feedback strength
κ = Kτ: D = 1 −κ[iz(1 −iz)]−1. The Nyquist diagram for this D has the
following form.
Di
Di
Dr
Dr
–1 0
κ = 2
κ = 0.2
–1 0
1
1
(a)
(b)
As z = ωτ travels around the upper half of the frequency plane (curve C
in Fig. 22.4a), D travels along the left curve (for feedback strength κ = 0.2), or
the right curve (for κ = 2) in the above diagram. These curves do not encircle
the origin at all—nor does the curve for any other κ > 0, so the number of
zeros minus the number of poles in the upper half-plane is Nz −Np = 0.
Moreover, D = 1 −κ[iz(1 −iz)]−1 has no poles in the upper half-plane, so
Np = 0 and Nz = 0: our cruise-control feedback system is stable. For further
details, see Ex. 22.10.
When designing control systems, it is important to have a signiﬁcant
margin of protection against instability. As an example, consider a control
system for which ˜G ˜H = −κ(1 + iz)[iz(1 −iz)]−1 (Ex. 22.11). The Nyquist
diagrams take the common form shown here.
(continued)
1094
Chapter 22. Kinetic Theory of Warm Plasmas

BOX 22.2.
(continued)
Di
Di
Di
Dr
Dr
–1 0
κ = 0.8
κ = 0.8
κ = 1.2
–1
0
0
1
1
1
unity gain
(a)
(b)
(c)
PM
GM
Dr
There are no poles in the upper half-plane; and for κ > 1 (drawing a) the
origin is encircled twice, while for κ < 1 it is not encircled at all (drawing
b). Therefore, the control system is unstable for κ > 1 and stable for κ < 1.
One often wants to push κ as high as possible to achieve one’s stabilization
goals but must maintain a margin of safety against instability. That margin is
quantiﬁed by either or both of two quantities: (i) The phase margin (labeled
PM in diagram c): the amount by which the phase of ˜G ˜H = D −1 exceeds
180o at the unity gain point, | ˜G ˜H| = 1 (red curve). (ii) The gain margin GM:
the amount by which the gain | ˜G ˜H| is less than 1 when the phase of ˜G ˜H
reaches 180◦. As κ is increased toward the onset of instability, κ = 1, both PM
and GM approach zero.
For the theory of control systems, see, for example, Franklin, Powell, and
Emami-Naeini (2005); Dorf and Bishop (2012).
Nyquist’s method for
diagnosing unstable
electrostatic modes in an
unmagnetized plasma
In view of these facts, Nyquist’s method tells us the following: there will be an
unstable mode, for one or more values of k, if and only if, as ζ travels from −∞to
+∞, Z(ζ) encloses one or more points on the positive real Z-axis. In addition, the wave
numbers for any resulting unstable modes are k = ±
√
Z, for all Z on the positive real
axis that are enclosed.
In Fig. 22.5, we show three examples of Z(ζ) curves. For Fig. 22.5a, no points on
the positive real axis are enclosed, so all electrostatic modes are stable for all wave
numbers k. For Fig. 22.5b,c, a segment of the positive real axis is enclosed, so there
are unstable modes; those unstable modes have k = ±
√
Z for all Z on the enclosed
line segment.
Notice that in Fig. 22.5a,b, the rightmost crossing of the real axis is at positive Z,
and the curve C′ moves upward as it crosses. A little thought reveals that this must
22.4 Stability of Electrostatic Waves in Unmagnetized Plasmas
1095

Zi
Zr
Zr
Zr
P
P
Z plane
Zi
Z plane
Zi
Z plane
ζ = –1
ζ = +1
ζ = –1
ζ = +1
ζ = –1
ζ = +1
ζ = vmin
ζ = vmin
(a)
(b)
(c)
C′
C′
C′
FIGURE 22.5 Nyquist diagrams for electrostatic waves. As a mode’s real phase velocity ζ increases from
−∞to +∞, Z(ζ) travels, in the complex-Z plane, around the closed curve C′, which always begins
and ends at the origin. (a) The curve C′ encloses no points on the positive real axis, so there are no
unstable electrostatic modes. (b,c) The curve does enclose a set of points on the positive real axis, so
there are unstable modes.
always be the case: Z(ζ) will encircle, counterclockwise, points on the positive-Z axis
if and only if it somewhere crosses the positive-Z axis traveling upward.
Therefore, an unstable electrostatic mode exists in an unmagnetized plasma if and
alternative Nyquist
criterion for instability
only if, as ζ travels along its real axis from −∞to +∞, Z(ζ) crosses some point P on
its positive real axis, traveling upward. This version of the Nyquist criterion enables
us to focus on the small-ωi domain (while still treating the general case)—for which
ϵ(ζ , k) is given by Eq. (22.39). From that expression and real ζ (our case), we infer
that Z(ζ) = k2[1 −ϵ]is given by
Z(ζ) =
e2
meϵ0

P
F ′ dv
v −ζ + iπF ′(ζ)

,
(22.49a)
where P means the Cauchy principal value of the integral. This means that Z(ζ)
crosses its real axis at any ζ where F ′(ζ) = 0, and it crosses moving upward if and
only if F ′′(ζ) > 0 at that crossing point. These two conditions together say that, at the
crossing point P, ζ = vmin, a particle speed at which F(v) has a minimum. Moreover,
Eq. (22.49a) says that Z(ζ) crosses its positive real axes (rather than negative) if and
only if

P[F ′/(v −vmin)]dv > 0. We can evaluate this integral using an integration
by parts:

P
F ′
v −vmin
dv =

P
d[F(v) −F(vmin)]/dv
v −vmin
dv
=

P
[F(v) −F(vmin)]
(v −vmin)2
dv + lim
δ→0
F(vmin −δ) −F(vmin)
−δ
(22.49b)
−F(vmin + δ) −F(vmin)
δ

.
The limδ→0 terms inside the square bracket vanish since F ′(vmin) = 0, and in the ﬁrst

P term we do not need the Cauchy principal value, because F is a minimum at vmin.
Therefore, our requirement is that
1096
Chapter 22. Kinetic Theory of Warm Plasmas

 +∞
−∞
[F(v) −F(vmin)]
(v −vmin)2
dv > 0.
(22.50)
Penrose’s criterion
for instability of an
electrostatic wave in an
unmagnetized plasma
Thus, a necessary and sufﬁcient condition for an unstable mode is that there exist
some velocity vmin at which the distribution function F(v) has a minimum, and that in
addition the minimum be deep enough that the integral (22.50) is positive.This is called
the Penrose criterion for instability (Penrose, 1960).
For a more in-depth, pedagogical derivation and discussion of the Penrose crite-
rion, see, for example, Krall and Trivelpiece (1973, Sec. 9.6).
EXERCISES
Exercise 22.8 Example: Penrose Criterion
Consider an unmagnetized electron plasma with a 1-dimensional distribution
function:
F(v) ∝[(v −v0)2 + u2]−1 + [(v + v0)2 + u2]−1,
(22.51)
where v0 and u are constants. Show that this distribution function possesses a mini-
mum if v0 > 3−1/2u, but the minimum is not deep enough to cause instability unless
v0 > u.
Exercise 22.9 Problem: Range of Unstable Wave Numbers
Consider a plasma with a distribution function F(v) that has precisely two peaks, at
v = v1 and v = v2 [with F(v2) ≥F(v1)], and a minimum between them at v = vmin,
and assume that the minimum is deep enough to satisfy the Penrose criterion for
instability [Eq. (22.50)]. Show that there will be at least one unstable mode for every
wave number k in the range kmin < k < kmax, where
k2
min =
e2
ϵ0me
 +∞
−∞
F(v) −F(v1)
(v −v1)2
dv,
k2
max =
e2
ϵ0me
 +∞
−∞
F(v) −F(vmin)
(v −vmin)2
dv.
(22.52)
Show, further, that the marginally unstable mode at k = kmax has phase velocity
ω/k = vmin, and the marginally unstable mode at k = kmin has ω/k = v1. [Hint: Use
a Nyquist diagram like those in Fig. 22.5.]
Exercise 22.10 Example and Derivation: Cruise-Control System
(a) Show that the cruise-control feedback system described at the beginning of Box
22.2 has ˜G(z) = 1/(1 −iz) and ˜H = −κ/(iz), with z = ωτ and κ = Kτ, as
claimed.
(b) Show that the Nyquist diagram has the forms shown in the second ﬁgure in
Box 22.2, and that this control system is stable for all feedback strengths κ > 0.
(c) Solve explicitly for the zeros of D = 1 + ˜G(z) ˜H(z), and verify that none are in
the upper half of the frequency plane.
22.4 Stability of Electrostatic Waves in Unmagnetized Plasmas
1097

(d) To understand the stability from a different viewpoint, imagine that the automo-
bile’s speed v is oscillating with an amplitude δv and a real frequency ω around the
desired speed V , v = V + δv sin(ωt), and that the feedback is turned off. Show
that the output of the control system is uo = [δv/
√
1 + ω2τ 2] sin(ωt −ϕ), with
a phase delay ϕ = arctan(ωτ) relative to the oscillations of v. Now turn on the
feedback, but at a low strength, so it only weakly changes the speed’s oscillations
in one period. Show that, because ϕ < π/2, d(δv2)/dt is negative, so the feed-
back damps the oscillations. Show that an instability would arise if the phase
delay were in the range π/2 < |ϕ| < 3π/2. For high-frequency oscillations,
ωτ ≫1, ϕ approaches π/2, so the cruise-control system is only marginally
stable.
Exercise 22.11 Derivation: Phase Margin and Gain Margin
for a Feedback-Control System
Consider the control system discussed in the last two long paragraphs of Box 22.2. It
has ˜G ˜H = −κ(1 + iz)[iz(1 −iz)]−1, with z = ωτ a dimensionless frequency and τ
some time constant.
(a) Show that there are no poles of D = 1 + ˜G ˜H in the upper half of the complex
frequency plane (z plane).
(b) Construct the Nyquist diagram for various feedback strengths κ. Show that
for κ > 1 the curve encircles the origin twice (diagram a in the third ﬁgure in
Box 22.2), so the control system is unstable, while for κ < 1, it does not encircle
the origin (diagram b in the same ﬁgure), so the control system is stable.
(c) Show that the phase margin and gain margin, deﬁned in diagram c in the third
ﬁgureinBox22.2, approachzeroasκ increasestowardtheinstabilitypoint, κ = 1.
(d) Compute explicitly the zeros of D = 1 + ˜G ˜H, and plot their trajectories in the
complex frequency plane as κ increases from zero through one to ∞. Verify that
two zeros enter the upper half of the frequency plane as κ increases through one,
and they remain in the upper half-plane for all κ > 1, as is guaranteed by the
Nyquist diagrams.
22.5
22.5 Particle Trapping
We now return to the description of Landau damping. Our treatment so far has been
essentially linear in the wave amplitude (or equivalently, in the perturbation to the
distribution function). What happens when the wave amplitude is not inﬁnitesimally
small?
Consider a single Langmuir wave mode as observed in a frame moving with the
mode’s phase velocity and, for the moment, ignore its growth or damping. Then in
this frame the electrostatic ﬁeld oscillates spatially, E = E0 sin kz, but has no time
1098
Chapter 22. Kinetic Theory of Warm Plasmas

z
v
FIGURE 22.6 Phase-space orbits for trapped (dashed lines) and un-
trapped (solid lines) electrons.
dependence. Figure 22.6 shows some phase-space orbits of electrons in this oscillatory
potential. The solid curves are orbits of particles that move fast enough to avoid being
trapped in the potential wells at kz = 0, 2π, 4π, . . . . The dashed curves are orbits
trapped and untrapped
electrons in a Langmuir
wave
of trapped particles. As seen in another frame, these trapped particles are surﬁng
on the wave, with their velocities performing low-amplitude oscillations around the
wave’s phase velocity ω/k.
The equation of motion for an electron trapped in the minimum z = 0 has the
form
¨z = −eE0 sin kz
me
≃−ω2
bz,
(22.53)
where we have assumed small-amplitude oscillations and approximated sin kz ≃kz,
and where
ωb =
eE0k
me
1/2
(22.54)
is known as the bounce frequency.Since the potential well is actually anharmonic, the
trapped particles will mix in phase quite rapidly.
Landau damping
associated with
accelerating or
decelerating untrapped
particles
The growth or damping of the wave is characterized by a growth or damping of
E0, and correspondingly by a net acceleration or deceleration of untrapped particles,
when averaged over a wave cycle. It is this net feeding of energy into and out of the
untrapped particles that causes the wave’s Landau damping or growth.
Now suppose that the amplitude E0 of this particular wave mode is changing on
a time scale τ due to interactions with the electrons, or possibly (as we shall see in
Chap. 23) due to interactions with other waves propagating through the plasma. The
potential well then changes on this same timescale, and we expect that τ is also a
measure of the maximum length of time a particle can be trapped in the potential
well. Evidently, nonlinear wave-trapping effects should only be important when the
bounce period ∼ω−1
b is short compared with τ, that is, when E0 ≫me/(ekτ 2).
22.5 Particle Trapping
1099

Electron trapping can cause particles to be bunched together at certain preferred
phases of a growing wave. This can have important consequences for the radiative
properties of the plasma. Suppose, for example, that the plasma is magnetized. Then
the electrons gyrate around the magnetic ﬁeld and emit cyclotron radiation. If their
gyrational phases are random, then the total power that they radiate will be the sum
of their individual particle powers. However, if N electrons are localized at the same
gyrational phase due to being trapped in a potential well of a wave, then they will ra-
radiation from bunched,
trapped electrons:
example of a nonlinear
plasma effect
diate like one giant electron with a charge −Ne. As the radiated power is proportional
to the square of the charge carried by the radiating particle, the total power radiated
by the bunched electrons will be N times the power radiated by the same number
of unbunched electrons. Very large ampliﬁcation factors are thereby possible both in
the laboratory and in Nature, for example, in the Jovian magnetosphere.
This brief discussion suggests that there may be much more richness in plasma
waves than is embodied in our dispersion relations with their simple linear growth
and decay, even when the wave amplitude is small enough that the particle motion is
only slightly perturbed by its interaction with the wave. This motivates us to discuss
more systematically nonlinear plasma physics, which is the topic of our next chapter.
EXERCISES
Exercise 22.12 Challenge: BGK Waves
Consider a steady, 1-dimensional, large-amplitude electrostatic wave in an un-
magnetized, proton-electron plasma. Write down the Vlasov equation for each par-
ticle species in a frame moving with the wave [i.e., a frame in which the electrostatic
potential is a time-independent function of z,  = (z), not necessarily precisely
sinusoidal].
(a) Use Jeans’ theorem to argue that proton and electron distribution functions that
are just functions of the energy,
Fs = Fs(Ws),
Ws = msvs2
2
+ qs(z),
(22.55a)
satisfy the Vlasov equation; here s = p, e, and as usual qp = e, qe = −e. Then
show that Poisson’s equation for the potential  can be rewritten in the form
1
2
d
dz
2
+ V () = const,
(22.55b)
where the potential V is −2/ϵ0 times the kinetic-energy density of the particles:
V = −2
ϵ0
 
s

1
2msvs
2Fs dvs,
(22.55c)
which depends on . (Yes, it is weird to construct a potential V from kinetic
energy, and a “kinetic energy” term from the electrical potential , but it also is
very clever.)
(b) It is possible to ﬁnd many electrostatic potential proﬁles (z) and distribution
functions Fs[Ws(v, )]that satisfy Eqs. (22.55). These are called BGK waves after
1100
Chapter 22. Kinetic Theory of Warm Plasmas

e", Wp
kz
e"0
–e"0
We
W+
W–
0
4π
3π
2π
π
FIGURE 22.7 BGK waves as analyzed in Ex. 22.12. Two quantitites are plotted
upward: e, where (z) is the 1-dimensional electrostatic potential, and Wp,
the proton total energy. Values e0 and −e0 of e, and W+ of Wp are marked
on the vertical axis. The electron total energy We is plotted downward, and its
value W−is marked on the axis. The shaded region shows the range of bound
electron energies as a function of location z; the solid line W+ and dashed line
W−are the energies of the unbound protons and electrons.
Bernstein, Greene, and Kruskal (1957), who ﬁrst analyzed them. Explain how,
in principle, one can solve for (nonunique) BGK distribution functions Fs in a
large-amplitude wave of given electrostatic potential proﬁle (z).
(c) Carryoutthisprocedure, assumingthatthepotentialproﬁleisoftheform(z) =
0 cos kz, with 0 > 0. Assume also that the protons are monoenergetic, with
Wp = W+ > e0, and move along the positive z direction. In addition, assume
thattherearebothmonoenergetic(withWe = W−> −e0), untrappedelectrons
(also moving along the positive z direction), and trapped electrons with distribu-
tion Fe(We), −e0 ≤We < e0; see Fig. 22.7. Show that the density of trapped
electrons must vanish at the wave troughs [at z = (2n + 1)π/k; n = 0, 1, 2, 3 . . .].
Let the proton density at the troughs be np0, and assume that there is no net cur-
rent. Show that the total electron density can then be written as
ne(z) =
'
me(W+ + e0)
mp(W−+ e)
(1/2
np0 +
 e0
−e
dWeFe(We)
[2me(We + e)]1/2 .
(22.56)
(d) Use Poisson’s equation to show that
 e0
−e
dWeFe(We)
[2me(We + e)]1/2
= −ϵ0k2
e
+ np0
⎡
⎣
*
W+ + e0
W+ −e
+1/2
−
*
me(W+ + e0)
mp(W−+ e)
+1/2⎤
⎦.
(22.57)
(e) Solve the integral equation in part (d) for Fe(We). [Hint: It is of Abel type.]
(f) Exhibit some solutions of Eq. (22.57) graphically.
22.5 Particle Trapping
1101

22.6
22.6 N-Particle Distribution Function
particle correlations are
missed by the Vlasov
formalism
Before turning to nonlinear phenomena in plasmas (the next chapter), let us digress
brieﬂy and explore ways to study correlations among particles, of which our Vlasov
formalism is oblivious.
The Vlasov formalism treats each particle as independent, migrating through
phase space in response to the local mean electromagnetic ﬁeld and somehow un-
affected by individual electrostatic interactions with neighboring particles. As we
discussed in Chap. 20, this approximation is likely to be good in a collisionless
plasma because of the inﬂuence of Debye screening—except in the tiny “independent-
particle” region of Fig. 20.1. However, we would like to have some means of quantify-
ingthisandofderivinganimprovedformalismthattakesintoaccountthecorrelations
among individual particles.
One environment where this formalism may be relevant is the interior of the
Sun. Here, although the gas is fully ionized, the Debye number is not particularly
large (i.e., one is near the independent-particle region of Fig. 20.1). As a result,
Coulomb corrections to the perfect-gas equation of state may be responsible for
measurable changes in the Sun’s internal structure, as deduced, for example, using
helioseismological analysis (cf. Sec. 16.2.4). In this application our task is simpler than
in the general case, because the gas will locally be in thermodynamic equilibrium at
some temperature T . It turns out that the general case, where the plasma departs
signiﬁcantly from thermal equilibrium, is extremely hard to treat.
kkk-particle distribution
functions
The one-particle distribution function that we use in the Vlasov formalism is the
ﬁrst member of a hierarchy of k-particle distribution functions: f (k)(x1, x2, . . . , xk,
v1, v2, . . . , vk, t). For example, f (2)(x1, x2, v1, v2, t)dx1dv1dx2dv2 ≡[the probability
of ﬁnding a particle (any particle) in a volume dx1dv1 ≡dx1dy1dz1dvx1dvy1dvz1 of
phase space, and another particle (any particle) in volume dx2dv2 of phase space].4
This deﬁnition and its obvious generalization dictate the normalization

f (k)dx1dv1 . . . dxkdvk = Nk,
(22.58)
where N ≫k ≥1 is the total number of particles.
It is useful to relate the distribution functions f (k) to the concepts of statistical
NNN-particle distribution
function fall
fall
fall in NNN-particle
plasma
mechanics, which we developed in Chap. 4. Suppose we have an ensemble of N-
electron plasmas, and let the probability that a member of this ensemble is in a volume
dNx dNv of the 6N-dimensional phase space of all its particles be falldNx dNv (N is
4.
In this section—and only in this section—we adopt the volume notation commonly used in this multi-
particle subject: we use dxj ≡dxjdyjdzj and dvj ≡dvxjdvyjdvzj to denote the volume elements for
particle j. Warning: Despite the boldface notation, dxj and dvj are not vectors! Also, in this section we
do not study waves, so k represents the number of particles in a distribution function, rather than a wave
number.
1102
Chapter 22. Kinetic Theory of Warm Plasmas

a very large number!). Of course, fall satisﬁes the Liouville equation
Liouville equation for fall
fall
fall
∂fall
∂t
+
N
 
i=1
"
(vi . ∇i)fall + (ai . ∇vi)fall
#
= 0,
(22.59)
where ai is the electromagnetic acceleration of the ith particle, and ∇i and ∇vi
are gradients with respect to the position and velocity of particle i, respectively.
We can construct the k-particle “reduced” distribution function from the statistical-
mechanics distribution function fall by integrating over all but k of the particles:
kkk-particle distribution
function constructed
from fall
fall
fall
f (k)(x1, x2, . . . , xk, v1, v2, . . . , vk, t)
= Nk

dxk+1 . . . dxNdvk+1 . . . dvNfall(x1, . . . , xN, v1, . . . , vN). (22.60)
(Note that k is typically a very small number, by contrast with N; below we shall
only be concerned with k = 1, 2, 3.) The reason for the prefactor Nk in Eq. (22.60) is
that, whereas fall refers to the probability of ﬁnding particle 1 in dx1dv1, particle 2 in
dx2dv2, and so forth, the reduced distribution function f (k) describes the probability
of ﬁnding any of the N identical (though distinguishable) particles in dx1dv1 and so
on. (As long as we are dealing with nondegenerate plasmas we can count the electrons
classically.) As N ≫k, the number of possible ways we can choose k particles for k
locations in phase space is approximately Nk.
For simplicity, suppose that the protons are immobile and form a uniform, neu-
tralizing background of charge, so we need only consider the electron distribution
and its correlations. Let us further suppose that the forces associated with the mean
electromagnetic ﬁelds produced by external charges and currents can be ignored. We
can then restrict our attention to direct electron-electron electrostatic interactions.
The acceleration of an electron is then
ai = e
me
 
j
∇iij,
(22.61)
where ij(xij) = −e/(4πϵ0xij) is the electrostatic potential of electron i at the loca-
tion of electron j, and xij ≡|xi −xj|.
22.6.1
22.6.1 BBGKY Hierarchy
We can now derive the so-called BBGKY hierarchy of kinetic equations (Bogolyubov,
1962; Born and Green, 1949; Kirkwood, 1946; Yvon, 1935) which relate the k-particle
distribution function to integrals over the (k + 1)-particle distribution function. The
ﬁrst equation in this hierarchy is given by integrating the Liouville equation (22.59)
over dx2 . . . dxNdv2 . . . dvN. If we assume that the distribution function decreases
22.6 N-Particle Distribution Function
1103

to zero at large distances, then integrals of the type

dxi∇ifall vanish, and the one-
particle distribution function evolves according to
∂f (1)
∂t
+ (v1 . ∇1)f (1) = −eN
me

dx2 . . . dxNdv2 . . . dvNj∇11j . ∇v1fall
= −eN2
me

dx2 . . . dxNdv2 . . . dvN∇112 . ∇v1fall
= −e
me

dx2dv2
2
∇v1f (2) . ∇1
3
12,
(22.62)
where, in the second line, we have replaced the probability of having any particle at a
location in phase space by N times the probability of having one speciﬁc particle there.
The left-hand side of Eq. (22.62) describes the evolution of independent particles, and
the right-hand side takes account of their pairwise mutual correlation.
The evolution equation for f (2) can similarly be derived by integrating the Liou-
ville equation (22.59) over dx3 . . . dxNdv3 . . . dvN:
∂f (2)
∂t
+ (v1 . ∇1)f (2) + (v2 . ∇2)f (2) + e
me
2
∇v1f (2) . ∇1
3
12 +
2
∇v2f (2) . ∇2
3
12

= −e
me

dx3dv3
2
∇v1f (3) . ∇1
3
13 +
2
∇v2f (3) . ∇2
3
23

.
(22.63)
Generalizing and allowing for the presence of a mean electromagnetic ﬁeld (in
BBGKY hierarchy of
evolution equations for
kkk-particle distribution
functions, derived by
integrating the Liouville
equation
addition to the inter-electron electrostatic ﬁeld) causing an acceleration aext =
−(e/me)(E + v × B), we obtain the BBGKY hierarchy of kinetic equations:
∂f (k)
∂t
+
k
 
i=1
⎡
⎣(vi . ∇i)f (k) + (aext
i
. ∇vi)f (k) + e
me
(∇vif (k) . ∇i)
k
 
j̸=i
ij
⎤
⎦
= −e
me

dxk+1dvk+1
k
 
i=1
2
∇vif (k+1) . ∇i
3
ik+1.
(22.64)
This kth equation in the hierarchy shows explicitly how we require knowledge of
the (k + 1)-particle distribution function to determine the evolution of the k-particle
distribution function.
22.6.2
22.6.2 Two-Point Correlation Function
It is convenient to deﬁne the two-point correlation function, ξ12(x1, v1, x2, v2, t) for
two-point correlation
function
particles 1 and 2, by
f (2)(x1, v1, x2, v2, t) = f1f2(1 + ξ12),
(22.65)
where we introduce the notation f1 = f (1)(x1, v1, t), and f2 = f (1)(x2, v2, t). For
the analysis that follows to be accurate, we require |ξ12| ≪1. We restrict attention
to a plasma in thermal equilibrium at temperature T . In this case, f1 and f2 are
1104
Chapter 22. Kinetic Theory of Warm Plasmas

Maxwelliandistributionfunctions, independentofx andt.Now, letusmakeanansatz,
namely, that ξ12 is just a function of the electrostatic interaction energy between the
two electrons, and therefore it does not involve the electron velocities. (It is, actually,
possible to justify this directly for an equilibrium distribution of particles interacting
electrostatically, but we make do with showing that our ﬁnal answer for ξ12 is just a
function of x12 = |x1 −x2|, in accord with our ansatz.) As Debye screening should be
effective at large distances, we anticipate that ξ12 →0 as x12 →∞.
Now turn to Eq. (22.62), and introduce the simplest imaginable closure relation:
ξ12 = 0. In other words, completely ignore all correlations. We can then replace f (2)
by f1f2 and perform the integral over x2 and v2 to recover the collisionless Vlasov
equation (22.6). Therefore, we see explicitly that particle-particle correlations are
indeed ignored in the simple Vlasov approach.
For the three-particle distribution function, we expect that, when electron 1 is dis-
tant from both electrons 2 and 3, then f (3) ∼f1f2f3(1+ ξ23), and so forth. Summing
over all three pairs, we write:
three-particle distribution
function and three-point
correlation function
f (3) = f1f2f3(1 + ξ23 + ξ31 + ξ12 + χ123),
(22.66)
where χ123 is the three-point correlation function that ought to be signiﬁcant when all
three particles are close together. The function χ123 is, of course, determined by the
next equation in the BBGKY hierarchy.
closure relation for
computing two-point
correlation function
We next make the closure relation χ123 = 0, that is to say, we ignore the inﬂuence
of third bodies on pair interactions. This is plausible because close, three-body en-
counters are even less frequent than close two-body encounters. We can now derive
an equation for ξ12 by seeking a steady-state solution to Eq. (22.63), that is, a solu-
tion with ∂f (2)/∂t = 0. We substitute Eqs. (22.65) and (22.66) into Eq. (22.63) (with
χ123 = 0) to obtain
f1f2

(v1 . ∇1)ξ12 + (v2 . ∇2)ξ12 −e(1 + ξ12)
kBT
C
(v1 . ∇1)12 + (v2 . ∇2)12
D
= ef1f2
kBT

dx3dv3f3

1 + ξ23 + ξ31 + ξ12
 "
(v1 . ∇1)13 + (v2 . ∇2)23
#
,
(22.67)
where we have used the relation
∇v1f1 = −mev1f1
kBT
,
(22.68)
valid for an unperturbed Maxwellian distribution function. We can rewrite this equa-
tion using the relations
∇112 = −∇212,
∇1ξ12 = −∇2ξ12,
ξ12 ≪1,

dv3f3 = n,
(22.69)
22.6 N-Particle Distribution Function
1105

to obtain
(v1 −v2) . ∇1

ξ12 −e12
kBT

= ne
kBT

dx3(1 + ξ23 + ξ31 + ξ12)[(v1 . ∇1)13 + (v2 . ∇2)23].
(22.70)
Now, symmetry considerations tell us that

dx3(1 + ξ31)∇113 = 0,

dx3(1 + ξ23)∇223 = 0,
(22.71)
and, in addition,

dx3ξ12∇113 = −ξ12

dx3∇313 = 0,

dx3ξ12∇223 = −ξ12

dx3∇323 = 0.
(22.72)
Therefore, we end up with
(v1 −v2) . ∇1

ξ12 −e12
kBT

= ne
kBT

dx3[ξ23(v1 . ∇1)13 + ξ31(v2 . ∇2)23].
(22.73)
As this equation must be true for arbitrary velocities, we can set v2 = 0 and obtain
∇1(kBT ξ12 −e12) = ne

dx3ξ23∇113.
(22.74)
WetakethedivergenceofEq.(22.74)andusePoisson’sequation, ∇2
112 = eδ(x12)/ϵ0,
to obtain
∇2
1ξ12 −ξ12
λ2
D
=
e2
ϵ0kBT δ(x12),
(22.75)
where λD = [kBT ϵ0/(ne2)]1/2 is the Debye length [Eq. (20.10)]. The solution of
Eq. (22.75) is
two-point correlation
function for electrons
in an unmagnetized,
thermalized plasma
ξ12 =
−e2
4πϵ0kBT
e−x12/λD
x12
.
(22.76)
Note that the sign is negative, because the electrons repel one another. Note also
that, to order of magnitude, ξ12(x12 = λD) ∼−N−1
D , which is ≪1 in magnitude if
the Debye number ND is much greater than unity. At the mean interparticle spacing,
we have ξ12(x12 = n−1/3) ∼−N−2/3
D
. Only for distances x12 <∼e2/(ϵ0kBT ) will the
correlation effects become large and our expansion procedure and truncation (χ123 =
0) become invalid. This analysis justiﬁes the use of the Vlasov equation when ND ≫1;
see the discussion at the end of Sec. 22.6.3.
1106
Chapter 22. Kinetic Theory of Warm Plasmas

EXERCISES
Exercise 22.13 Problem: Correlations in a Tokamak Plasma
For a tokamak plasma, compute, to order of magnitude, the two-point correlation
function for two electrons separated by
(a) a Debye length, and
(b) the mean interparticle spacing.
22.6.3
22.6.3 Coulomb Correction to Plasma Pressure
Let us now turn to the problem of computing the Coulomb correction to the pressure
of a thermalized ionized gas. It is easiest to begin by computing the Coulomb correc-
tion to the internal energy density. Once again ignoring the protons, this is simply
given by
Uc = −e
2

dx1n1n2ξ1212,
(22.77)
where the factor 1/2 compensates for double counting the interactions. Substituting
Eq. (22.76) and performing the integral, we obtain
Uc =
−ne2
8πϵ0λD
= −(e2n/ϵ0)3/2
8π(kBT )1/2 ,
(22.78)
where n is the number density of electrons. The pressure can be obtained from
this energy density using elementary thermodynamics. From the deﬁnition (5.32)
of the physical free energy converted to a per-unit-volume basis and the ﬁrst law of
thermodynamics [Eq. (5.33)], the volume density of Coulomb free energy, Fc, is given
by integrating
Uc = −T 2
∂(Fc/T )
∂T

n
.
(22.79)
From this expression, we obtain Fc = 2
3Uc. The Coulomb contribution to the pressure
is then given by P = −∂F/∂V [Eq. (5.33)], rewritten as
Pc = n2
∂(Fc/n)
∂n

T
= 1
3Uc.
(22.80)
Therefore, includingtheCoulombinteractiondecreasesthepressureatagivendensity
and temperature.
So far we have only allowed the electrons to move and have kept the protons ﬁxed,
and we found a Coulomb pressure and energy density independent of the mass of the
electron. Therefore, if we had only allowed the protons to move, we would have gotten
the same answer. If (as is the case in reality) we allow both protons and electrons to
move, we must include the proton-electron attractions as well; but because Uc and
Pc are proportional to e2, these contribute with identical magnitude and sign to the
22.6 N-Particle Distribution Function
1107

electron-electron repulsions. Therefore the electrons and protons play completely
equivalent roles, and the full electron-proton Uc and Pc are simply obtained by
replacing n by the total density of particles, 2n. Inserting λD =

ϵ0kBT /(ne2), the
end result for the Coulomb correction to the pressure is
Coulomb correction to
pressure in a thermalized
plasma
Pc =
−n3/2e3
23/23πϵ3/2
0 (kBT )1/2 ,
(22.81)
where n is still the number density of electrons. Numerically, the gas pressure for a
perfect electron-proton gas is
P = 1.6 × 1013(ρ/1,000 kg m−3)(T /106 K) N m−2,
(22.82)
and the Coulomb correction to this pressure is
Pc = −7.3 × 1011(ρ/1,000 kg m−3)3/2(T /106 K)−1/2 N m−2.
(22.83)
In the interior of the Sun this is about 1% of the total pressure. In denser, cooler stars,
it is signiﬁcantly larger.
By contrast, for most of the plasmas that one encounters, our analysis implies that
the order of magnitude of the two-point correlation function ξ12 is ∼N−1
D across a
Debye sphere and only ∼N−2/3
D
at the distance of the mean interparticle spacing (see
end of Sec. 22.6.2). Only those particles that are undergoing large deﬂections, through
angles ∼1 radian, are close enough together for ξ12 = O(1). This is the ultimate
justiﬁcation for treating plasmas as collisionless and for using mean electromagnetic
ﬁelds in the Vlasov description.
EXERCISES
Exercise 22.14 Derivation: Thermodynamic Identities
Verify Eqs. (22.79) and (22.80).
Exercise 22.15 Problem: Thermodynamics of a Coulomb Plasma
Compute the entropy of a proton-electron plasma in thermal equilibrium at temper-
ature T including the Coulomb correction.
Bibliographic Note
The kinetic theory of warm plasmas and its application to electrostatic waves and
their stability are treated in nearly all texts on plasma physics. For maximum detail
and good pedagogy, we particularly like Krall and Trivelpiece (1973, Chaps. 7, 8) (but
beware of typographical errors). We also recommend, in Bellan (2006): the early parts
of Chap. 2, and all of Chap. 5, and for the extension to magnetized plasmas, Chap. 8.
1108
Chapter 22. Kinetic Theory of Warm Plasmas

Also useful are Schmidt (1979, Chaps. 3, 7), Lifshitz and Pitaevskii (1981, Chap. 3),
Stix (1992, Chaps. 8, 10), Boyd and Sanderson (2003, Chap. 8), and Swanson (2003,
Chap. 4).
For brief discussions of the BBGKY hierarchy of N-particle distribution functions
and their predicted correlations in a plasma, see Boyd and Sanderson (2003, Chap.
12) and Swanson (2003, Sec. 4.1.3). For detailed discussions, see the original literature
cited in Sec. 22.6.1.
The theory of galaxy dynamics is very clearly developed in Binney and Tremaine
(2003).Thereaderwillﬁndmanyparallelsbetweenwarmplasmasandself-gravitating
stellar distributions.
Bibliographic Note
1109


23
CHAPTER TWENTY-THREE
Nonlinear Dynamics of Plasmas
Plasma seems to have the kinds of properties one would like for life. It’s somewhat like liquid water—
unpredictable and thus able to behave in an enormously complex fashion. It could probably carry as
much information as DNA does. It has at least the potential for organizing itself in interesting ways.
FREEMAN DYSON (1986)
23.1
23.1 Overview
In Sec. 21.6 we met our ﬁrst example of a velocity-space instability: the two-stream
instability, which illustrated the general principle that in a collisionless plasma, de-
partures from Maxwellian equilibrium in velocity space can be unstable and lead to
exponential growth of small-amplitude waves. This is similar to the Kelvin-Helmholtz
instability in a ﬂuid (Sec. 14.6.1), where a spatially varying ﬂuid velocity produces an
instability. In Chap. 22, we derived the dispersion relation for electrostatic waves in a
warm, unmagnetized plasma. We discovered Landau damping of the waves when the
phase-space density of the resonant particles diminishes with increasing speed, and
we showed that in the opposite case of an increasing phase-space density, the waves
can grow at the expense of the energies of near-resonant particles (a generalization of
the two-stream instability). In this chapter, we explore the back-reaction of the waves
on the near-resonant particles. This back-reaction is a (weakly) nonlinear process, so
we have to extend our analysis of wave-particle interactions to include the leading
nonlinearity.
This extension is called quasilinear theory or the theory of weak plasma turbulence,
anditallowsustofollowthetimedevelopmentofthewavesandthenear-resonantpar-
ticlessimultaneously. We develop this formalism in Sec. 23.2 and verify that it enforces
the laws of particle conservation, energy conservation, and momentum conserva-
tion. Our initial development of the formalism is entirely in classical language and
meshes nicely with the kinetic theory of electrostatic waves as presented in Chap. 22.
In Sec. 23.3, we reformulate the theory in terms of the emission, absorption, and scat-
tering of wave quanta, which are called plasmons. Although waves in plasmas almost
always entail large quantum occupation numbers and thus are highly classical, this
quantum formulation of the classical theory has great computational and heuristic
power. And, as one might expect, despite the presence of Planck’s reduced constant ℏ
in the formalism, ℏnowhere appears in the ﬁnal answers to problems.
1111

BOX 23.1.
READERS’ GUIDE
.
This chapter relies signiﬁcantly on:
– portions of Chap. 3 on kinetic theory: Secs. 3.2.1 and
3.2.3 on the distribution function, Sec. 3.2.5 on the mean
occupation number, and Sec. 3.6 on Liouville’s theorem and
the collisionless Boltzmann equation;
– portions of Secs. 7.2 and 7.3 on geometric optics;
– Sec. 20.3 on Debye shielding, collective behavior of plasmas
and plasma oscillations; and
– Secs. 22.1–22.5 on kinetic theory of warm plasmas.
.
This chapter also relies to some extent but not greatly on:
– the concept of spectral density as developed in Sec. 6.4, and
– Sec. 6.9 on the Fokker-Planck equation.
.
No subsequent material in this book relies signiﬁcantly on this
chapter.
Our initial derivation and development of the formalism is restricted to the
interaction of electrons with electrostatic waves, but in Sec. 23.3 we also describe
how the formalism can be generalized to describe a multitude of wave modes and
particle species interacting with one another.
We also describe circumstances in which this formalism can fail because the
resonant particles couple strongly, not to a broad-band distribution of incoherent
waves (as the formalism presumes) but instead to one or a few individual, coherent
modes. (In Sec. 23.6, we explore an example.)
In Sec. 23.4, we give two illustrative applications of quasilinear theory. For a
warm electron beam that propagates through a stable plasma, generating Langmuir
plasmons, we show how the plasmons act back on the beam’s particle distribution
function so as to shut down the plasmon production. For our second application,
we describe how galactic cosmic rays (relativistic charged particles) generate Alfv´en
waves, which in turn scatter the cosmic rays, isotropizing their distribution functions
and conﬁning them to our galaxy’s interior much longer than one might expect.
In the remainder of this chapter, we describe a few of the many other nonlinear
phenomena that can be important in plasmas. In Sec. 23.5, we consider parametric
instabilities in plasmas (analogs of the optical parametric ampliﬁcation that we met
in nonlinear crystals in Sec. 10.7). These instabilities are important for the absorption
of laser light in experimental studies of the compression of small deuterium-tritium
pellets—a possible forerunner of a commercial nuclear fusion reactor. In Sec. 23.6, we
return to ion-acoustic solitons (which we studied, for small amplitudes, in Ex. 21.6)
1112
Chapter 23. Nonlinear Dynamics of Plasmas

and explore how they behave when their amplitudes are so large that nonlinearities
are strong. We discover that dissipation can convert such a soliton into a collisionless
shock, similar to the bow shock that forms where Earth’s magnetic ﬁeld meets the
solar wind.
23.2
23.2 Quasilinear Theory in Classical Language
23.2.1
23.2.1 Classical Derivation of the Theory
In Chap. 22, we discovered that hot, thermalized electrons or ions can Landau damp a
wave mode. We also showed that some nonthermal particle velocity distributions lead
to exponential growth of the waves. Either way there is energy transfer between the
waves and the particles. We now turn to the back-reaction of the waves on the near-
resonant particles that damp or amplify them. For simplicity, we derive and explore
the back-reaction equations (“quasilinear theory”) in the special case of electrons
interacting with electrostatic Langmuir waves. Then we assert the (rather obvious)
generalization to protons or other ions and (less obviously) to interactions with other
types of wave modes.
derivation of quasilinear
theory
TWO-LENGTHSCALE EXPANSION
We begin with the electrons’ 1-dimensional distribution function Fe(v, z, t)
[Eq. (22.17)]. As in Sec. 22.3.1, we split Fe into two parts, but we must do so more
carefully here than we did there. The foundation for our split is a two-lengthscale
expansion of the same sort as we used in developing geometric optics (Sec. 7.3). We
introduce two disparate lengthscales, the short one being the typical reduced wave-
length of a Langmuir wave -λ ∼1/k, and the long one being a scale L ≫-λ over which
we perform spatial averages. Later, when applying our formalism to an inhomoge-
neous plasma, L must be somewhat shorter than the spatial inhomogeneity scale but
still ≫-λ. In our present situation of a homogeneous background plasma, there can
still be large-scale spatial inhomogeneities caused by the growth or damping of the
wave modes via their interaction with the electrons. We must choose L somewhat
smaller than the growth or damping length but still large compared to -λ.
Our split of Fe is into the spatial average of Fe over the length L (denoted F0) plus
a rapidly varying part that averages to zero (denoted F1):
two-lengthscale expansion
of electron distribution
function
F0 ≡⟨Fe⟩,
F1 ≡Fe −F0,
Fe = F0 + F1.
(23.1)
[For simplicity, we omit the subscript e from F0 and F1. Therefore—by contrast with
Chap. 22, where F0 = Fe0 + (me/mp)Fp0—we here include only Fe0 in F0.]
ThetimeevolutionofFe, andhenceofF0 andF1, isgovernedbythe1-dimensional
Vlasov equation, in which we assume a uniform neutralizing ion (proton) back-
ground, no background magnetic ﬁeld, and interaction with 1-dimensional (planar)
electrostatic waves. We cannot use the linearized Vlasov equation (22.19), which
formed the foundation for all of Chap. 22, because the processes we wish to study
are nonlinear. Rather, we must use the fully nonlinear Vlasov equation [Eq. (22.6)
23.2 Quasilinear Theory in Classical Language
1113

integrated over the irrelevant components vx and vy of velocity, as in Eq. (22.17)]:
∂Fe
∂t + v ∂Fe
∂z −eE
me
∂Fe
∂v = 0.
(23.2)
Here E is the rapidly varying electric ﬁeld (pointing in the z direction) associated with
the waves.
Inserting Fe = F0 + F1 into this Vlasov equation, and arranging the terms in an
order that will make sense below, we obtain
∂F0
∂t + v ∂F0
∂z −e
me
∂F1
∂v E + ∂F1
∂t + v ∂F1
∂z −e
me
∂F0
∂v E = 0.
(23.3)
We then split this equation into two parts: its average over the large lengthscale L and
its remaining time-varying part.
The averaged part gets contributions only from the ﬁrst three terms (since the last
three are linear in F1 and E, which have vanishing averages):
evolution of slowly
varying part F0
F0
F0 of electron
distribution function
∂F0
∂t + v ∂F0
∂z −e
me
?∂F1
∂v E
@
= 0.
(23.4)
This is an evolution equation for the averaged distribution F0; the third, nonlinear
term drives the evolution. This driving term is the only nonlinearity that we keep in
the quasilinear Vlasov equation.
RAPID EVOLUTION OF F1
The rapidly varying part of the Vlasov equation (23.3) is just the last three terms of
Eq. (23.3):
evolution of rapidly
varying part F1
F1
F1 of electron
distribution function
∂F1
∂t + v ∂F1
∂z −e
me
∂F0
∂v E = 0,
(23.5)
plus a nonlinear term
−e
me
∂F1
∂v E −
?∂F1
∂v E
@
,
(23.6)
which we discard as being far smaller than the linear ones. If we were to keep this
three-wave mixing
term, we would ﬁnd that it can produce a “three-wave mixing” (analogous to that for
light in a nonlinear crystal, Sec. 10.6), in which two electrostatic waves with different
wave numbers k1 and k2 interact weakly to try to generate a third electrostatic wave
with wave number k3 = k1 ± k2. We discuss such three-wave mixing in Sec. 23.3.6;
for the moment we ignore it and correspondingly discard the nonlinearity (23.6).
Equation (23.5) is the same linear evolution equation for F1 as we developed and
studied in Chap. 22. Here, as there, we bring its physics to the fore by decomposing
into monochromatic modes; but here we are dealing with many modes and sums over
the effects of many modes, so we must do the decomposition a little more carefully
1114
Chapter 23. Nonlinear Dynamics of Plasmas

than in Chap. 22. The foundation for the decomposition is a spatial Fourier transform
inside our averaging “box” of length L:
Fourier analysis inside an
averaging box
˜F1(v, k, t) =
 L
0
e−ikzF1(v, z, t)dz,
˜E(k, t) =
 L
0
e−ikzE(z, t)dz.
(23.7)
We take F1 and E to represent the physical quantities and thus to be real; this implies
that ˜F1(−k) = ˜F ∗
1 (k) and similarly for ˜E, so the inverse Fourier transforms are
F1(v, z, t) =
 ∞
−∞eikz ˜F1(v, k, t) dk
2π ,
E(z, t) =
 ∞
−∞eikz ˜E(v, k, t) dk
2π ,
for 0 < z < L.
(23.8)
(This choice of how to do the mathematics corresponds to idealizing F1 and E as
vanishing outside the box; alternatively, we could treat them as though they were
periodic with period L and replace Eq. (23.8) by a sum over discrete values of k—
multiples of 2π/L.)
From our study of linearized waves in Chap. 21, we know that a mode with real
conventions for linear
modes
wave number k will oscillate in time with some complex frequency ω(k):
˜F1 ∝e−iω(k)t,
˜E ∝e−iω(k)t.
(23.9)
For simplicity, we assume that the mode propagates in the +z direction; when study-
ing modes traveling in the opposite direction, we just turn our z-axis around. (In Sec.
23.2.4, we generalize to 3-dimensional situations and include all directions of prop-
agation simultaneously.) For simplicity, we also assume that for each wave number k
there is at most one mode type present (i.e., only a Langmuir wave or only an ion-
acoustic wave). With these simpliﬁcations, ω(k) is a unique function with its real part
positive (ωr > 0) when k > 0. Notice that the reality of E(z, t) implies [from the sec-
ond of Eqs. (23.7)] that ˜E(−k, t) = ˜E∗(k, t) for all t; in other words [cf. Eqs. (23.9)],
˜E(−k, 0)e−iω(−k)t = ˜E∗(k, 0)e+iω∗(k)t for all t, which in turn implies
ω(−k) = −ω∗(k);
or
ωr(−k) = −ωr(k),
ωi(−k) = ωi(k).
(23.10)
These equations should be obvious physically: they say that, for our chosen conven-
tions, both the negative k and positive k contributions to Eq. (23.8) propagate in the
+z direction, and both grow or are damped in time at the same rate. In general, ω(k)
is determined by the Landau-contour dispersion relation (22.33). However, through-
out Secs. 23.2–23.4, we specialize to weakly damped or growing Langmuir waves with
phase velocities ωr/k large compared to the rms electron speed:
vph = ωr
k ≫vrms =
1
1
n

v2F0(v)dv.
(23.11)
23.2 Quasilinear Theory in Classical Language
1115

For such waves, from Eqs. (22.40a), (22.40b), and the ﬁrst two lines of Eq. (22.42), we
deduce the following explicit forms for the real and imaginary parts of ω:
dispersion relation for
slowly evolving Langmuir
waves
ω2
r = ω2
p
*
1 + 3
v2
rms
(ωp/k)2
+
,
for k > 0,
(23.12a)
ωi = πe2
2ϵ0me
ωr
k2 F ′
0(ωr/k),
for k > 0.
(23.12b)
The linearized Vlasov equation (23.5) implies that the modes’ amplitudes
˜F1(v, k, t) and ˜E(k, t) are related by
˜F1 = ie
me
∂F0/∂v
(ω −kv)
˜E.
(23.13)
This is just Eq. (22.20) with d/dv replaced by ∂/∂v, because F0 now varies slowly in
space and time as well as varying with v.
SPECTRAL ENERGY DENSITY EK
Now leave the rapidly varying quantities F1 and E and their Vlasov equation (23.5),
dispersion relation (23.12a), and damping rate (23.12b), and turn to the spatially
averaged distribution function F0 and its spatially averaged Vlasov equation (23.4).
We shall bring this Vlasov equation’s nonlinear term into a more useful form. The key
quantity in this nonlinear term is the average of the product of the rapidly varying
quantities F1 and E. Parseval’s theorem permits us to rewrite this as
⟨EF1⟩= 1
L
 L
0
EF1dz = 1
L
 ∞
−∞
EF1dz =
 ∞
−∞
dk
2π
˜E∗˜F1
L
,
(23.14)
where in the second step we have used our mathematical idealization that F1 and
E vanish outside our averaging box, and the third equality is Parseval’s theorem.
Inserting Eq. (23.13), we bring Eq. (23.14) into the form
⟨EF1⟩= e
me
 ∞
−∞
dk
2π
˜E∗˜E
L
i
ω −kv
∂F0
∂v .
(23.15)
The quantity ˜E∗˜E/L is a function of wave number k, time t, and also the location
and size L of the averaging box. For Eq. (23.15) to be physically and computationally
useful, it is essential that this quantity not ﬂuctuate wildly as k, t, L, and the box
locationarevaried.Inmostcircumstances, iftheboxischosentobefarlargerthan -λ =
1/k, then ˜E∗˜E/L indeed will not ﬂuctuate wildly. When one develops the quasilinear
theory with greater care and rigor than we can do in so brief a treatment, one discovers
that this nonﬂuctuation is a consequence of the random-phase approximation or RPA
random-phase
approximation (RPA)
for short—an approximation that the phase of ˜E varies randomly with k, t, L, and
1116
Chapter 23. Nonlinear Dynamics of Plasmas

the box location on suitably short lengthscales.1 Like ergodicity (Secs. 4.6 and 6.2.3),
although the RPA is often valid, sometimes it can fail. Sometimes there is an organized
bunching of the particles in phase space that induces nonrandom phases on the
plasma waves. Quasilinear theory requires that RPA be valid, and for the moment we
assume it is, but in Sec. 23.6 we meet an example for which it fails: strong ion-acoustic
solitons.
The RPA implies that, as we increase the length L of our averaging box, ˜E∗˜E/L
will approach a well-deﬁned limit. This limit is half the spectral density SE(k) of the
random process E(z, t) at ﬁxed time t [cf. Eq. (6.25)]. Correspondingly, it is natural
to express quasilinear theory in the language of spectral densities. We shall do so, but
with a normalization of the spectral density that is tied to the physical energy density
and differs slightly from that used in Chap. 6: in place of SE(k), we use the Langmuir-
wave spectral energy density Ek. We follow plasma physicists’ conventions by deﬁning
this quantity to include the oscillatory kinetic energy in the electrons, as well as the
electrical energy to which it is, on average, equal. As in the theory of random processes
(Chap. 6), we add the energy at −k to that at +k, so that all the energy is regarded
as residing at positive wave number, and
 ∞
0
dk Ek is the total wave energy per unit
volume in the plasma, averaged over length L.
Invoking the RPA, we can use Parseval’s theorem to compute the electrical energy
density:
ϵ0⟨E2⟩
2
=
 ∞
−∞
dk
2π ϵ0
<
˜E ˜E∗
2L
>
=
 ∞
0
dk
2π ϵ0
<
˜E ˜E∗
L
>
,
(23.16)
where we have used ˜E(k) ˜E∗(k) = ˜E(−k) ˜E∗(−k). We double this quantity to account
for the wave energy in the oscillating electrons and then read off the spectral energy
density as the integrand:
spectral energy density of
Langmuir waves
Ek = ϵ0⟨˜E ˜E∗⟩
πL
.
(23.17)
This wave energy density can be regarded as a function either of wave number k
or wave phase velocity vph = ωr/k. It is useful to plot Ek(vph) on the same graph as
the averaged electron velocity distribution F0(v). Figure 23.1 is such a plot. It shows
the physical situation we are considering: approximately thermalized electrons with
(possibly) a weak beam (bump) of additional electrons at velocities v ≫vrms, and a
distribution of Langmuir waves with phase velocities vph ≫vrms.
EVOLUTION OF WAVE SPECTRAL ENERGY DENSITY EK
Thereisanimplicittimedependenceassociatedwiththegrowthordecayofthewaves,
so Ek ∝e2ωit. Now, the waves’ energy density Ek travels through phase space (physical
1.
For detailed discussions, see Davidson (1972) and Pines and Schrieffer (1962).
23.2 Quasilinear Theory in Classical Language
1117

Fo(v)
vrms
v, vph = ωr/k
Ek(vph)
FIGURE 23.1 The spatially averaged electron velocity distribution
F0(v) (solid curve) and wave spectral energy density Ek(vph) (dashed
curve) for the situation treated in Secs. 23.2–23.4.
space and wave-vector space) on the same trajectories as a wave packet (i.e., along the
geometric-optics rays discussed in Sec. 7.3), which for our waves propagating in the
z direction are given by
derivatives moving with
Langmuir-wave rays (wave
packets)
dz
dt

wp
= ∂ωr
∂kj
,
dk
dt

wp
= −∂ωr
∂z
(23.18)
[Eqs. (7.25)]. Correspondingly, the waves’ growth or decay actually occurs along these
rays (with the averaging boxes also having to be carried along the rays). Thus the
equation of motion for the waves’ energy density is
evolution of Langmuir
waves’ spectral energy
density along a ray
dEk
dt ≡∂Ek
∂t +
dz
dt

wp
∂Ek
∂z +
dk
dt

wp
∂Ek
∂k = 2ωiEk.
(23.19)
Here we have used the fact that the electrostatic waves are presumed to propagate
in the z direction, so the only nonzero component of k is kz ≡k, and the only
nonzero component of the group velocity is Vg z = (dz/dt)wp = (∂ωr/∂k)z. For
weakly damped, high-phase-speed Langmuir waves, ωr(x, k) is given by Eq. (23.12a),
with the x dependence arising from the slowly spatially varying electron density n(x),
which induces a slow spatial variation in the plasma frequency: ωp =

ne2/(ϵ0me).
SLOW EVOLUTION OFF0
evolution of slowly
varying part F0
F0
F0 of electron
distribution function
The context in which the quantity ˜E(k)∗˜E(k) = (πL/ϵ0)Ek arose was our evaluation
of the nonlinear term in the Vlasov equation (23.4) for the electrons’ averaged dis-
tribution function F0. By inserting Eqs. (23.15) and (23.17) into Eq. (23.4), we bring
that nonlinear Vlasov equation into the form
∂F0
∂t + v ∂F0
∂z = ∂
∂v

D ∂F0
∂v

,
(23.20)
1118
Chapter 23. Nonlinear Dynamics of Plasmas

where
diffusion coefﬁcient for
electrons
D(v) =
e2
2ϵ0m2
e
 ∞
−∞
dk Ek
i
ω −kv
=
e2
ϵ0m2
e
 ∞
0
dk Ek
ωi
(ωr −kv)2 + ω2
i
.
(23.21)
In the second equality we have used Eq. (23.10).
Equation (23.20) says that F0(v, z, t) is transported in physical space with the
electron speed v and diffuses in velocity space with the velocity diffusion coefﬁcient
D(v). Notice that D(v) is manifestly real, and a major contribution to it comes from
waves whose phase speeds ωr/k nearly match the particle speed v (i.e., from resonant
waves).
The two-lengthscale approximation that underlies quasilinear theory requires
that the waves grow or damp on a lengthscale long compared to a wavelength, and
equivalently, that |ωi| be much smaller than ωr. This allows us, for each v, to split the
integral in Eq. (23.21) into a piece due to modes that can resonate with electrons of
that speed because ωr/k ≃v plus a piece that cannot so resonate. We consider these
two pieces in turn.
The resonant piece of the diffusion coefﬁcient can be written, in the limit |ωi| ≪
ωr, by approximating the resonance in Eq. (23.21) as a delta function:
diffusion coefﬁcient for
electrons that are resonant
with the waves
Dres ≃e2π
ϵ0m2
e
 ∞
0
dkEkδ(ωr −kv).
(23.22a)
In the diffusion equation (23.20) this inﬂuences F0(v) only at those velocities v of
resonating waves with substantial wave energy (i.e., on the tail of the electron velocity
distribution, under the dashed Ek curve of Fig. 23.1). We refer to electrons in this
region as the resonant electrons. In Sec. 23.4, we explore the dynamical inﬂuence of
this resonant diffusion coefﬁcient on the velocity distribution F0(v) of the resonant
electrons.
Nearly all the electrons reside at velocities |v| <∼vrms, where there are no waves
(because waves there get damped very quickly). For these nonresonant electrons, the
denominator in Eq. (23.21) for the diffusion coefﬁcient is approximately equal to
ω2
r ≃ω2
p = e2n/(ϵ0me), and correspondingly, the diffusion coefﬁcient has the form
diffusion coefﬁcient for
nonresonant electrons
Dnon-res ≃
1
nme
 ∞
0
ωiEkdk,
(23.22b)
which is independent of the electron velocity v.
The nonresonant electrons at v <∼vrms are the ones that participate in the wave
motions and account for the waves’ oscillating charge density (via F1). The time-
averaged kinetic energy of these nonresonant electrons (embodied in F0) thus must
23.2 Quasilinear Theory in Classical Language
1119

include a conserved part independent of the waves plus a part associated with the
waves. The wave part must be equal to the waves’ electrical energy and so to half the
waves’ total energy, 1
2
 ∞
0
dkEk, and it thus must change at a rate 2ωi times that energy.
Correspondingly, we expect the nonresonant piece of D(v) to produce a rate change
of the time-averaged electron energy (embodied in F0) given by
nonresonant energy
conservation
∂Ue
∂t + ∂Fez
∂z
= 1
2
 ∞
0
dk 2ωiEk,
(23.23)
where Fez is the electron energy ﬂux. Indeed, this is the case; see Ex. 23.1. Because
we have already accounted for this electron contribution to the wave energy in our
deﬁnition of Ek, we ignore it henceforth in the evolution of F0(v), and correspond-
ingly, for weakly damped or growing waves we focus solely on the resonant part of
the diffusion coefﬁcient, Eq. (23.22a).
EXERCISES
Exercise 23.1 Problem: Nonresonant Particle Energy in Wave
Show that the nonresonant part of the diffusion coefﬁcient in velocity space, Eq.
(23.22b), produces a rate of change of electron kinetic energy given by Eq. (23.23).
23.2.2
23.2.2 Summary of Quasilinear Theory
All the fundamental equations of quasilinear theory are now in hand. They are:
summary: fundamental
equations of quasilinear
theory for electrons
interacting with Langmuir
waves
1. The general dispersion relation (22.40) for the (real part of the) waves’
frequency ωr(k) and their growth rate ωi(k) [which, for the high-speed
Langmuir waves on which we are focusing, reduces to Eqs. (23.12)]; this
dispersion relation depends on the electrons’ slowly evolving, time-averaged
velocity distribution F0(v, z, t).
2. Theequationofmotion(23.19)forthewaves’slowlyevolvingspectralenergy
density Ek(k, z, t), in which appear ωr(k) and ωi(k).
3. Equations (23.21) or (23.22) for the diffusion coefﬁcient D(v) in terms
of Ek.
4. The diffusive evolution equation (23.20) for the slow evolution of F0(v, z, t).
The fundamental functions in this theory are Ek(k, z, t) for the waves and F0(v, z, t)
for the electrons.
Quasilinear theory sweeps under the rug and ignores the details of the oscillating
electric ﬁeld E(z, t) and the oscillating part of the distribution function F1(v, z, t).
Those quantities were needed in deriving the quasilinear equations, but they are
needed no longer—except, sometimes, as an aid to physical understanding.
1120
Chapter 23. Nonlinear Dynamics of Plasmas

23.2.3
23.2.3 Conservation Laws
It is instructive to verify that the quasilinear equations enforce the conservation of
particles, momentum, and energy.
We begin with particles (electrons). The number density of electrons is n =

F0dv, and the z component of particle ﬂux is Sz =

nvdv (where F1 contributes
nothing because it is oscillatory, and here and below all velocity integrals go from
−∞to +∞). Therefore, by integrating the diffusive evolution equation (23.20) for
F0 over velocity, we obtain
particle conservation
∂n
∂t + ∂Sz
∂z =
  ∂
∂t F0 + v ∂
∂zF0

dv =

∂
∂v

D ∂F0
∂v

dv = 0,
(23.24)
which is the law of particle conservation for our 1-dimensional situation where noth-
ing depends on x or y.
The z component of electron momentum density is Ge
z ≡

mevF0dv, and the zz
component of electron momentum ﬂux (stress) is T e
zz =

mev2F0dv; so evaluating
the ﬁrst moment of the evolution equation (23.20) for F0, we obtain
∂Ge
z
∂t
+ ∂T e
zz
∂z = me

v
∂F0
∂t + v ∂F0
∂z

dv
= me

v ∂
∂v

D ∂F0
∂v

dv = −me

D ∂F0
∂v dv,
(23.25)
where we have used integration by parts in the last step. The waves inﬂuence the
momentum of the resonant electrons through the delta-function part of the diffusion
coefﬁcientD [Eq.(23.22a)], andthemomentumofthenonresonantelectronsthrough
the nonresonant part of the diffusion coefﬁcient (23.22b). Because we have included
the evolving part of the nonresonant electrons’ momentum and energy as part of the
waves’momentumandenergy, wemustrestrictattentioninEq.(23.25)totheresonant
electrons (see last sentence in Sec. 23.2.1). We therefore insert the delta-function part
of D [Eq. (23.22a)] into Eq. (23.25), thereby obtaining
∂Ge
z
∂t
+ ∂T e
zz
∂z = −πe2
ϵ0me

dv

dkEkδ(ωr −kv)∂F0
∂v = −πe2
ϵ0me

EkF ′
0(ωr/k)dk
k .
(23.26)
Here we have changed the order of integration, integrated out v, and set F ′
0(v) ≡
∂F0/∂v. Assuming, for deﬁniteness, high-speed Langmuir waves, we can rewrite the
last expression in terms of ωi with the aid of Eq. (23.12b):
conservation of total
momentum in quasilinear
theory
∂Ge
z
∂t
+ ∂T e
zz
∂z = −2

dkωi
Ekk
ωr
= −∂
∂t

dk Ekk
ωr
−∂
∂z

dk Ekk
ωr
∂ωr
∂k
= −∂Gw
z
∂t
−∂T w
zz
∂z .
(23.27)
23.2 Quasilinear Theory in Classical Language
1121

The second equality follows from Eq. (23.19) together with the fact that for high-
speed Langmuir waves, ωr ≃ωp so ∂ωr/∂z ≃1
2(ωp/ne)∂ne/∂z is independent of k.
After the second equality in Eq. (23.19),

dk Ekk/ωr = Gw
z is the waves’ density of
the z component of momentum [as one can see from the fact that each plasmon
(wave quantum) carries a momentum pz = ℏk and an energy ℏωr; cf. Secs. 7.3.2
and 23.3]. Similarly, since the waves’ momentum and energy travel with the group
velocity dωr/dk,

dk Ek(k/ωr)(∂ωr/∂k) = T w
zz is the waves’ ﬂux of momentum.
Obviously, Eq. (23.27) represents the conservation of total momentum, that of the
resonant electrons plus that of the waves (which includes the evolving part of the
nonresonant electron momentum).
conservation of total
energy in quasilinear
theory
Energy conservation can be handled in a similar fashion; see Ex. 23.2.
EXERCISES
Exercise 23.2 Problem: Energy Conservation
Show that the quasilinear evolution equations guarantee conservation of total energy
—that of the resonant electrons plus that of the waves. Pattern your analysis after that
for momentum, Eqs. (23.25)–(23.27).
23.2.4
23.2.4 Generalization to 3 Dimensions
quasilinear equations in 3
dimensions
So far, we have restricted our attention to Langmuir waves propagating in one
direction, +ez. The generalization to 3 dimensions is straightforward. The waves’
wave number k is replaced by the wave vector k = k ˆk, where ˆk is a unit vector in the
direction of the phase velocity. The waves’ spectral energy density becomes Ek, which
waves’ spectral energy
density
depends on k, varies slowly in space x and time t, and is related to the waves’ total
energy density by
Uw =

EkdVk,
(23.28)
where dVk ≡dkxdkydkz is the volume integral in wave-vector space.
Because the plasma is isotropic, the dispersion relation ω(k) = ω(|k|) has the
sameformasinthe1-dimensionalcase, andthegroupandphasevelocitiespointinthe
same direction ˆk: Vph = (ω/k)ˆk, Vg = (dωr/dk)ˆk. The evolution equation (23.19)
for the waves’ spectral energy density moving along a ray (a wave-packet trajectory)
becomes
evolution of waves’
spectral energy density
dEk
dt ≡∂Ek
∂t +
dxj
dt

wp
∂Ej
∂xj
+
dkj
dt

wp
∂Ek
∂kj
= 2ωiEk,
(23.29a)
and the rays themselves are given by
rays
dxj
dt

wp
= ∂ωr
∂kj
= Vg j,
dkj
dt

wp
= −∂ωr
∂xj
.
(23.29b)
1122
Chapter 23. Nonlinear Dynamics of Plasmas

We shall conﬁne ourselves to the resonant part of the diffusion coefﬁcient, as the
nonresonant part is only involved in coupling a wave’s electrostatic part to its oscillat-
ing, nonresonant-electron part, and we already understand that issue [Eqs. (23.22b),
(23.23), and associated discussion] and shall not return to it.
The 3-dimensional velocity diffusion coefﬁcient acts only along the direction of
the waves; that is, its ˆk ⊗ˆk component has the same resonant form [Eq. (23.22a)] as
in the 1-dimensional case, and components orthogonal to ˆk vanish, so
tensorial diffusion
coefﬁcient for resonant
electrons
D = πe2
ϵ0m2
e

Ek ˆk ⊗ˆk δ(ωr −k . v)dVk.
(23.29c)
Because the waves will generally propagate in a variety of directions, the net D is not
unidirectional. This diffusion coefﬁcient enters into the obvious generalization of the
Fokker-Planck-like evolution equation (23.20) for the averaged distribution function
f0(v, x, t)—in which we suppress the subscript 0 for ease of notation:
evolution of electrons’
averaged distribution
function
∂f
∂t + v . ∇f = ∇v . (D . ∇vf ),
or
∂f
∂t + vj
∂f
∂xj
= ∂
∂vi
*
Dij
∂f
∂vj
+
.
(23.29d)
Here∇v (inindexnotation, ∂/∂vj)isthegradientinvelocityspace, nottobeconfused
with the spatial derivative along a vector v, ∇v ≡v . ∇= vj∂/∂xj.
23.3
23.3 Quasilinear Theory in Quantum Mechanical Language
The attentive reader will have noticed a familiar structure to our quasilinear theory. It
is reminiscent of the geometric-optics formalism that we introduced in Chap. 7. Here,
as there, we can reinterpret the formalism in terms of quanta carried by the waves.
At the most fundamental level, we could (second) quantize the ﬁeld of plasma waves
plasmons: quantized
plasma wave’s particles
into quanta (usually called “plasmons”), and describe their creation and annihilation
using quantum mechanical transition probabilities. However, there is no need to go
through the rigors of the quantization procedure, since the basic concepts of creation,
annihilation, and transition probabilities should already be familiar to most readers
in the context of photons coupled to atomic systems. Those concepts can be carried
over essentially unchanged to plasmons, and by doing so, we recover our quasilinear
theory rewritten in quantum language.
23.3.1
23.3.1 Plasmon Occupation Number η
A major role in the quantum theory is played by the occupation number for electro-
static wave modes, which are just the single-particle states of quantum theory. Our
electrostaticwaveshavespinzero, sincethereisnopolarizationfreedom(thedirection
of E is unique: it must point along k). In other words, there is only one polariza-
tion state for each k, so the number of modes (i.e., of quantum states) in a volume
23.3 Quasilinear Theory in Quantum Mechanical Language
1123

dVxdVk = dxdydzdkxdkydkz of phase space is dNstates = dVxdVk/(2π)3, and cor-
respondingly, the number density of states in phase space is
dNstates/dVxdVk = 1/(2π)3
(23.30)
(cf. Sec. 3.2.5 with p = ℏk). The density of energy in phase space is Ek, and the energy
of an individual plasmon is ℏωr, so the number density of plasmons in phase space is
dNplasmons/dVxdVk = Ek/ℏωr.
(23.31)
Therefore, the states’ occupation number is given by
Langmuir plasmons’ mean
occupation number
η(k, x, t) =
dNplasmons/dVxdVk
dNstates/dVxdVk
=
dNplasmons
dVx dVk/(2π)3 = (2π)3Ek
ℏωr
.
(23.32)
This is actually the mean occupation number; the occupation numbers of individual
states will ﬂuctuate statistically around this mean. In this chapter (as in most of our
treatment of statistical physics in Part II of this book), we do not deal with the
individual occupation numbers, since quasilinear theory is oblivious to them and
deals only with the mean. Thus, without any danger of ambiguity, we simplify our
terminology by suppressing the word “mean.”
Equation (23.32) says that η(k, x, t) and Ek are the same quantity, aside from
normalization. In the classical formulation of quasilinear theory we use Ek; in the
equivalent quantum formulation we use η. We can think of η equally well as a function
of the state’s wave number k or of the momentum p = ℏk of the individual plasmons
that reside in the state.
The third expression in Eq. (23.32) allows us to think of η as the number density
in x-k phase space, with the relevant phase-space volume renormalized from dVk to
dVk/(2π)3 = (dkx/2π)(dky/2π)(dkz/2π). The factors of 2π appearing here are the
same ones as appear in the relationship between a spatial Fourier transform and its
inverse [e.g., Eq. (23.8)]. We shall see the quantity dVk/(2π)3 appearing over and over
again in the quantum mechanical theory, and it can generally be traced to that Fourier
transform relationship.
23.3.2
23.3.2 Evolution of η for Plasmons via Interaction with Electrons
CLASSICAL FORMULA FOR EVOLUTION OF η
The motion of individual plasmons is governed by Hamilton’s equations with the
hamiltonian determined by their dispersion relation:
H(p, x, t) = ℏωr(k = p/ℏ, x, t);
(23.33)
see Sec. 7.3.2. The plasmon trajectories in phase space are, of course, identical to the
wave-packet trajectories (the rays) of the classical wave theory, since
dxj
dt = ∂H
∂pj
= ∂ωr
∂kj
,
dpj
dt = ℏ
∂kj
∂t = −∂H
∂xj
= −ℏ∂ωr
∂xj
.
(23.34)
1124
Chapter 23. Nonlinear Dynamics of Plasmas

ħk
ħk
p
p
(b)
(a)
p – ħk
p – ħk
FIGURE 23.2 Feynman diagrams showing (a) creation
and (b) annihilation of a plasmon (with momentum
ℏk) by an electron (with momentum p).
Interactions between the waves and resonant electrons cause Ek to evolve as
dEk/dt = 2ωiEk [Eq. (23.29a)]. Therefore, the plasmon occupation number will also
vary as
evolution of plasmon
(mean) occupation
number
dη
dt ≡∂η
∂t +
dxj
dt
∂η
∂xj
+
dpj
dt
∂η
∂pj
= 2ωiη,
(23.35)
where dxj/dt and dpj/dt are given by Hamilton’s equations (23.34).
QUANTUM FORMULA FOR EVOLUTION OF η
The fundamental process that we are dealing with in Eq. (23.35) is the creation (or
annihilation) of a plasmon by an electron (Fig. 23.2). The kinematics of this process
is simple: energy and momentum must be conserved in the interaction. In plasmon
creation(Fig.23.2a), theplasmagainsonequantumofenergyℏωr sotheelectronmust
lose this same energy: ℏωr = −(mev2/2) ≃−p . v, where p is the electron’s
change of momentum, and v is its velocity; by “≃” we assume that the electron’s
fractional change of energy is small (an assumption inherent in quasilinear theory).
Since the plasmon momentum change, ℏk, is minus the electron momentum change,
we conclude that
conservation of energy and
momentum in the creation
of plasmons: electron
resonance and surﬁng
ℏωr = −(mev2/2) ≃−p . v = ℏk . v.
(23.36)
This is just the resonance condition contained in the delta function δ(ωr −k . v) of
Eq. (23.29c). Thus, energy and momentum conservation in the fundamental plasmon
creation process imply that the electron producing the plasmon must resonate with
the plasmon’s mode (i.e., the component of the electron’s velocity along k must be the
same as the mode’s phase speed). In other words, the electron must “surf” with the
wave mode in which it is creating the plasmon, always remaining in the same trough
or crest of the mode.
A fundamental quantity in the quantum description is the probability per unit
time for an electron with velocity v to spontaneously emit a Langmuir plasmon into a
volume Vk in k space (i.e., the number of k plasmons emitted by a single velocity-v
23.3 Quasilinear Theory in Quantum Mechanical Language
1125

electron per unit time into the volume Vk centered on some wave vector k). This
probability is expressed in the following form:
spontaneous emission
of Langmuir plasmons:
fundamental probability W
W
W
dNplasmons
dt

from one electron
≡W(v, k) Vk
(2π)3.
(23.37)
In a volume Vx of physical space and Vv of electron-velocity space, there are
dNe = f (v)VxVv electrons. Equation (23.37) tells us that these electrons increase
the number of plasmons in Vx, and with k in Vk, by
dNplasmons
dt

from all electrons in VxVv
≡W(v, k) Vk
(2π)3f (v)VxVv.
(23.38)
Dividing by Vx and by Vk/(2π)3, and using the second expression for η in Eq.
(23.32), we obtain for the rate of change of the plasmon occupation number produced
by electrons with velocity v in Vv:
dη(k)
dt

from all electrons in Vv
= W(v, k)f (v)Vv.
(23.39)
Integrating over all of velocity space, we obtain a ﬁnal expression for the inﬂuence
of spontaneous plasmon emission, by electrons of all velocities, on the plasmon
occupation number:
spontaneous plasmon
emission
dη(k)
dt

s
=

W(v, k)f (v)dVv.
(23.40)
(Here and below the subscript s means “spontaneous.”) Our introduction of the factor
(2π)3 in the deﬁnition (23.37) of W(v, k) was designed to avoid a factor (2π)3 in this
equation for the evolution of the occupation number.
Below [Eq. (23.45)] we deduce the fundamental emission rate W for high-speed
Langmuir plasmons by comparing with our classical formulation of quasilinear the-
ory.
Because the plasmons have spin zero, they obey Bose-Einstein statistics, which
means that the rate for induced emission of plasmons is larger than that for sponta-
neous emission by the occupation number η of the state that receives the plasmons.
Furthermore, the principle of detailed balance (“unitarity” in quantum mechanical
language) tells us that W is also the relevant transition probability for the inverse
process of absorption of a plasmon in a transition between the same two electron
momentum states (Fig. 23.2b). This permits us to write down a master equation for
the evolution of the plasmon occupation number in a homogeneous plasma:
master equation for
evolution of plasmon
occupation number
dη
dt =

W(v, k)
A
f (v)[1 + η(k)]−f (v −ℏk/me)η(k)
B
dVv.
(23.41)
1126
Chapter 23. Nonlinear Dynamics of Plasmas

The f (v) term in the integrand is the contribution from spontaneous emission, the
f (v)η(k) term is that from induced emission, and the f (v −ℏk/me)η(k) term is from
absorption.
COMPARISON OF CLASSICAL AND QUANTUM FORMULAS FOR dη/dt;
THE FUNDAMENTAL QUANTUM EMISSION RATE W
The master equation (23.41) is actually the evolution law (23.35) for η in disguise,
with the e-folding rate ωi written in a fundamental quantum mechanical form. To
make contact with Eq. (23.35), we ﬁrst notice that in our classical development of
quasilinear theory, for which η ≫1, we neglected spontaneous emission, so we drop
it from Eq. (23.41). In the absorption term, the momentum of the plasmon is so much
smaller than the electron momentum that we can make a Taylor expansion:
f (v −ℏk/me) ≃f (v) −(ℏ/me)(k . ∇v)f .
(23.42)
Inserting this into Eq. (23.41) and removing the spontaneous-emission term, we
obtain
dη
dt ≃η

W ℏ
me
(k . ∇v)f dVv.
(23.43)
For comparison, Eq. (23.35), with ωi given by the classical high-speed Langmuir
relation (23.12b) and converted to 3-dimensional notation, becomes
dη
dt = η

πe2ωr
ϵ0k2me
δ(ωr −k . v)k . ∇vf dVv.
(23.44)
Comparing Eqs. (23.43) and (23.44), we infer that the fundamental quantum emission
rate for plasmons must be
fundamental plasmon
emission rate deduced
from classical limit
W = πe2ωr
ϵ0k2ℏδ(ωr −k . v).
(23.45)
Note that this emission rate is inversely proportional to ℏand is therefore a very large
number under the classical conditions of our quasilinear theory.
Thiscomputationhasshownthattheclassicalabsorptionrate−ωi isthedifference
between the quantum mechanical absorption rate and induced emission rate. Under
normal conditions, when k . ∇vf < 0 (∂F0/∂v < 0 in 1-dimensional language), the
absorptiondominatesoveremission, sotheabsorptionrate−ωi ispositive, describing
Landau damping. However (as we saw in Chap. 22), when this inequality is reversed,
there can be wave growth [subject of course to there being a suitable mode into which
the plasmons can be emitted, as guaranteed when the Penrose criterion (22.50) is
fulﬁlled].
SPONTANEOUS EMISSION OF LANGMUIR PLASMONS AS CERENKOV RADIATION
Although spontaneous emission was absent from our classical development of quasi-
linear theory, it nevertheless can be a classical process and therefore must be added
23.3 Quasilinear Theory in Quantum Mechanical Language
1127

α
Vph
v
kˆ
FIGURE 23.3 Geometry for Cerenkov emission. An electron
moving with velocity v and speed v = |v| emits waves with
phase speed Vph < v along a direction ˆk that makes an angle
α = cos−1(Vph/v) with the direction of the electron’s motion.
The slanted solid line is a phase front.
to the quasilinear formalism. Classically or quantum mechanically, the spontaneous
plasmon emission as
Cerenkov radiation
emission is a form of Cerenkov radiation, since (as for Cerenkov light emitted by elec-
trons moving through a dielectric medium), the plasmons are produced when an
electron moves through the plasma faster than the waves’ phase velocity. More specif-
ically, only when v > Vph = ωr/k can there be an angle α of k relative to v along
which the resonance condition is satisﬁed: v . ˆk = v cos α = ωr/k. The plasmons are
emitted at this angle α to the electron’s direction of motion (Fig. 23.3).
The spontaneous Cerenkov emission rate (23.40) takes the following form when
we use the Langmuir expression (23.45) for W:
dη
dt

s
= πe2
ϵ0ℏ
ωr
k2

f (v)δ(ωr −k . v)dVv.
(23.46)
Translated into classical language via Eq. (23.32), this Cerenkov emission rate is
dEk
dt

s
=
e2
8π2ϵ0
ω2
r
k2

f (v)δ(ωr −k . v)dVv.
(23.47)
Note that Planck’s constant is absent from the classical expression, but present in the
quantum one.
In the above analysis, we computed the fundamental emission rate W by com-
paring the quantum induced emission rate minus absorption rate with the classical
growth rate for plasma energy. An alternative route to Eq. (23.45) for W would have
been to use classical plasma considerations to compute the classical Cerenkov emis-
sion rate (23.47), then convert to quantum language using η = (2π)3Ek/ℏωr, thereby
obtaining Eq. (23.46), and then compare with the fundamental formula (23.40).
By comparing Eqs. (23.44) and (23.46) and assuming a thermal (Maxwellian)
distributionfortheelectronvelocities, weseethatthespontaneousCerenkovemission
conditions for
spontaneous Cerenkov
emission to be ignorable
is ignorable in comparison with Landau damping when the electron temperature Te
is smaller than ηℏωr/kB. Sometimes it is convenient to deﬁne a classical brightness
1128
Chapter 23. Nonlinear Dynamics of Plasmas

temperature TB(k) for the plasma waves given implicitly by
η(k) ≡[eℏωr/[kBTB(k)] −1]−1
(23.48)
≃kBTB(k)
ℏωr
when η(k) ≫1, as in the classical regime.
In this language, spontaneous emission of plasmons with wave vector k is gener-
ally ignorable when the wave brightness temperature exceeds the electron kinetic
temperature—as one might expect on thermodynamic grounds. In a plasma in strict
the balance of Cerenkov
emission by Landau
damping in thermal
equilibrium
thermal equilibrium, Cerenkov emission is balanced by Landau damping, so as to
maintain a thermal distribution of Langmuir waves with a temperature equal to that
of the electrons: TB(k) = Te for all k.
EXERCISES
Exercise 23.3 Problem: Cerenkov Power in Electrostatic Waves
Show that the Langmuir wave power radiated by an electron moving with speed v in
a plasma with plasma frequency ωp is given by
P ≃
e2ω2
p
4πϵ0v ln
*
kmaxv
ωp
+
,
(23.49)
where kmax is the largest wave number at which the waves can propagate. (For larger
k the waves are strongly Landau damped.)
23.3.3
23.3.3 Evolution of f for Electrons via Interaction with Plasmons
Now turn from the evolution of the plasmon distribution η(k, x, t) to that of the
particle distribution f (v, x, t). Classically, f evolves via the velocity-space diffusion
equation(23.29d).Weshallwritedownafundamentalquantummechanicalevolution
equation (the “kinetic equation”) that appears at ﬁrst sight to differ remarkably from
Eq. (23.29d), but then we will recover (23.29d) in the classical limit.
To derive the electron kinetic equation, we must consider three electron velocity
states, v andv ± ℏk/me (Fig.23.4).Momentumconservationsaysthatanelectroncan
move between these states by emission or absorption of a plasmon with wave vector k.
The fundamental probability for these transitions is the same one, W, as for plasmon
(1 + η)
(1 + η)
η
η
v
v + ħk/me
v – ħk/me
FIGURE 23.4 Three-level system for under-
standing the electron kinetic equation.
23.3 Quasilinear Theory in Quantum Mechanical Language
1129

emission, since these transitions are merely plasmon emissions and absorptions as
seen from the electron’s viewpoint. Therefore, the electron kinetic equation must take
the form
evolution of averaged
electron distribution
function due to plasmon
emission and absorption—
fundamental form of
equation
df (v)
dt
=

dVk
(2π)3
C
(1 + η)[W(v + ℏk/me, k)f (v + ℏk/me) −W(v, k)f (v)]
−η[W(v + ℏk/me, k)f (v) −W(v, k)f (v −ℏk/me)]
D
.
(23.50)
The four terms can be understood by inspection of Fig. 23.4. The two downward
transitions in that diagram entail plasmon emission and thus are weighted by (1+ η),
where the 1 is the spontaneous contribution and the η is the induced emission. In
the ﬁrst of these (1 + η) terms in Eq. (23.50), the v electron state gets augmented, so
the sign is positive; in the second it gets depleted, so the sign is negative. The two
upward transitions entail plasmon absorption and thus are weighted by η; the sign in
Eq. (23.50) is plus when the ﬁnal electron state has velocity v, and minus when the
initial state is v.
In the domain of classical quasilinear theory, the momentum of each emitted or
absorbed plasmon must be small compared to that of the electron, so we can expand
the terms in Eq. (23.50) in powers of ℏk/me. Carrying out that expansion to second
order and retaining those terms that are independent of ℏand therefore classical, we
obtain (Ex. 23.4) the quasilinear electron kinetic equation:
evolution of averaged
electron distribution in
quasilinear domain—
Fokker-Planck equation
df
dt = ∇v . [R(v)f + D(v) . ∇vf ],
(23.51a)
where ∇v is the gradient in velocity space (and not v . ∇), and where
R(v) =

dVk
(2π)3
W(v, k)ℏk
me
,
(23.51b)
D(v) =

dVk
(2π)3
η(k)W(v, k)ℏk ⊗ℏk
m2
e
.
(23.51c)
Note that R is a resistive coefﬁcient associated with spontaneous emission, and D is
a diffusive coefﬁcient associated with plasmon absorption and induced emission in
the limit that electron recoil due to spontaneous emission can be ignored. Following
Eq. (6.106c), we can rewrite Eq. (23.51c) for D as
D =
?v ⊗v
t
@
(23.51d)
with v = −ℏk/me.
Ourelectronkineticequation(23.51a)hasthestandardFokker-Planckform(6.94)
derived in Sec. 6.9.1 (generalized to three dimensions), except that the resistive co-
efﬁcient there is A = −R + ∂D/∂v and the diffusion coefﬁcient there is B = 2D.
Note that the diffusive term here has the form (∂/∂v)(D ∂f/∂v) discussed in Ex. 6.21
[Eq. (6.102)], as it should, because our formalism does not admit electron recoil (so
1130
Chapter 23. Nonlinear Dynamics of Plasmas

the probability of a change in v due to plasmon absorption is the same as for the
opposite change due to plasmon emission).
In our classical, quasilinear analysis, we ignored spontaneous emission and thus
had no resistive term R in the evolution equation (23.29d) for f . We can recover that
evolution equation and its associated D by dropping the resistive term from the quan-
tum kinetic equation (23.51a) and inserting expression (23.45) for W into Eq. (23.51c)
forthequantum D.Theresultsagreewiththeclassicalequations(23.29c)and(23.29d).
EXERCISES
Exercise 23.4 Derivation: Electron Fokker-Planck Equation
Fill in the missing details in the derivation of the electron Fokker-Planck equation
(23.51a). It may be helpful to use index notation.
23.3.4
23.3.4 Emission of Plasmons by Particles in the Presence of a Magnetic Field
Let us return brieﬂy to Cerenkov emission by an electron or ion. In the presence of a
background magnetic ﬁeld B, the resonance condition for Cerenkov emission must
be modiﬁed. Only the momentum parallel to the magnetic ﬁeld need be conserved,
not the total vectorial momentum. The unbalanced components of momentum per-
pendicular to B are compensated by a reaction force from B itself and thence by the
steady currents that produce B; correspondingly, the unbalanced perpendicular mo-
mentum ultimately does work on those currents. In this situation, one can show that
the Cerenkov resonance condition ωr −k . v = 0 is modiﬁed to
ωr −k∥. v∥= 0,
(23.52)
where || means the component parallel to B. If we allow for the electron gyrational
motion as well, then some number N of gyrational (cyclotron) quanta can be fed into
each emitted plasmon, so Eq. (23.52) gets modiﬁed to read
Cerenkov resonance
condition in presence of a
magnetic ﬁeld
ωr −k∥. v∥= Nωce,
(23.53)
where N is an integer. For nonrelativistic electrons, the strongest resonance is for
N = 1. We use this modiﬁed Cerenkov resonance condition in Sec. 23.4.1.
23.3.5
23.3.5 Relationship between Classical and Quantum Mechanical Formalisms
We have demonstrated how the structure of the classical quasilinear equations is
mandated by quantum mechanics. In developing the quantum equations, we had
to rely on one classical calculation, Eq. (23.44), which gave us the emission rate W.
However, even this was not strictly necessary, since with signiﬁcant additional effort
we could have calculated the relevant quantum mechanical matrix elements and then
computed W directly from Fermi’s golden rule.2 This has to be the case, because
2.
See, for example, Cohen-Tannoudji, Diu, and Lalo¨e (1977), and, in the plasma physics context, Melrose
(2008, 2012).
23.3 Quasilinear Theory in Quantum Mechanical Language
1131

quantummechanicsisthefundamentalphysicaltheoryandthusmustbeapplicableto
plasma excitations just as it is applicable to atoms. Of course, if we are only interested
in classical processes, as is usually the case in plasma physics, then we end up taking
the limit ℏ→0 in all observable quantities, and the classical rate is all we need.
This raises an important point of principle. Should we perform our calculations
using quantum
calculations in the
classical domain
classically or quantum mechanically? The best answer is to be pragmatic. Many
calculations in nonlinear plasma theory are so long and arduous that we need all the
help we can get to complete them. We therefore combine both classical and quantum
considerations (conﬁdent that both must be correct throughout their overlapping
domain of applicability), in whatever proportion minimizes our computational effort.
23.3.6
23.3.6 Evolution of η via Three-Wave Mixing
We have discussed plasmon emission and absorption both classically and quantum
mechanically. Our classical and quantum formalisms can be generalized straight-
forwardly to encompass other nonlinear processes.
Among the most important other processes are three-wave interactions (in which
two waves coalesce to form a third wave or one wave splits up into two) and scattering
processes (in which waves are scattered off particles without creating or destroying
plasmons). In this section we focus on three-wave mixing. We present the main ideas
in the text but leave most of the details to Exs. 23.5 and 23.6.
three-wave mixing in
general
In three-wave mixing, where wavesA and B combine to create wave C (Fig. 23.5a),
the equation for the growth of the amplitude of wave C will contain nonlinear driving
terms that combine the harmonic oscillations of waves A and B, that is, driving terms
proportional to exp[i(kA . x −ωAt)]exp[i(kB . x −ωBt)]. For wave C to build up co-
herently over many oscillation periods, it is necessary that the spacetime dependence
of these driving terms be the same as that of wave C, exp[i(kC . x −ωCt)]; in other
words, it is necessary that
kC = kA + kB,
ωC = ωA + ωB.
(23.54)
Quantum mechanically, these expressions can be recognized as momentum and en-
ergy conservation for the waves’ plasmons. We have met three-wave mixing previ-
ously, for electromagnetic waves in a nonlinear dielectric crystal (Sec. 10.6). There,
as here, the conservation laws (23.54) were necessary for the mixing to proceed; see
Eqs. (10.29) and associated discussion.
When the three waves are all electrostatic, the three-wave mixing arises from the
nonlinear term (23.6) in the rapidly varying part [wave part, Eq. (23.5)] of the Vlasov
equation, whichwediscardedinourquasilinearanalysis.Generalizedto3dimensions
with this term treated as a driver, that Vlasov equation takes the form
three-wave mixing for
electrostatic waves:
driving term from
quasilinear analysis
∂f1
∂t + v . ∇f1 −e
me
E . ∇vf0 = e
me

E . ∇vf1 −⟨E . ∇vf1⟩

.
(23.55)
In the driving term (right-hand side of this equation), E could be the electric ﬁeld of
wave A and f1 could be the perturbed velocity distribution of wave B or vice versa,
1132
Chapter 23. Nonlinear Dynamics of Plasmas

(a)
(b)
A
A
B
B
C
C
FIGURE 23.5 (a) A three-wave process in which two plasmons A and B interact
nonlinearly to create a third plasmon C. Conserving energy and linear momen-
tum, we obtain ωC = ωA + ωB and kC = kA + kB. For example, A and C might
be transverse electromagnetic plasmons satisfying the dispersion relation (21.24),
and B might be a longitudinal plasmon (Langmuir or ion acoustic); or A and
C might be Langmuir plasmons, and B might be an ion-acoustic plasmon—the
case treated in the text and in Exs. 23.5 and 23.6. (b) The time-reversed three-
wave process in which plasmon C generates plasmon B by an analog of Cerenkov
emission, and while doing so recoils into plasmon state A.
and the E and f1 terms on the left side could be those of wave C. If the wave vectors
and frequencies are related by Eq. (23.54), then via this equation waves A and B will
coherently generate wave C.
electrostatic three-wave
mixing—two Langmuir
waves (AAA and CCC) and one
ion-acoustic wave (BBB)
The dispersion relations for Langmuir and ion-acoustic waves permit the conser-
vation law (23.54) to be satisﬁed if A is Langmuir (so ωA ∼ωpe), B is ion acoustic (so
ωB <∼ωpp ≪ωA), andC isLangmuir.Byworkingoutthedetailedconsequencesofthe
driving term (23.55) in the quasilinear formalism and comparing with the quantum
equations for three-wave mixing (Ex. 23.5), one can deduce the fundamental rate for
the process A + B →C [Fig. 23.5a; Eqs. (23.56)]. Detailed balance (unitarity) guar-
antees that the time-reversed process C →A + B (Fig. 23.5b) will have identically
the same fundamental rate. This time-reversed process has a physical interpretation
analogous to the emission of a Cerenkov plasmon by a high-speed, resonant elec-
tron: C is a “high-energy” Langmuir plasmon (ωC ∼ωpe) that can be thought of as
Cerenkov-emitting a “low-energy” ion-acoustic plasmon (ωB <∼ωpp ≪ωC) and in
the process recoiling slightly into Langmuir state A.
The fundamental rate that one obtains for this wave-wave Cerenkov process A +
B →C and its time reversal C →A + B, when the plasma’s electrons are thermalized
at temperature Te, is (Ex. 23.5)3
fundamental rate for
Cerenkov emission of
ion-acoustic plasmon by
Langmuir plasmon
WAB↔C = RAB↔C(kA, kB, kC)δ(kA + kB −kC)δ(ωA + ωB −ωC),
(23.56a)
3.
See also Tsytovich (1970, Eq. A.3.12). The rates for many other wave-wave mixing processes are worked
out in this book, but beware: it contains a large number of typographical errors.
23.3 Quasilinear Theory in Quantum Mechanical Language
1133

where
RAB↔C(kA, kB, kC) =
8π5ℏe2(mp/me)ω3
B
(kBTe)2k2
ia
(ˆkA . ˆkC)2.
(23.56b)
[Here we have written the ion-acoustic plasmon’s wave number as kia instead of kB,
to avoid confusion with Boltzmann’s constant; i.e., kia ≡|kB|.]
Thisistheanalogoftherate(23.45)forCerenkovemissionbyanelectron.Theion-
acoustic occupation number will evolve via an evolution law analogous to Eq. (23.41)
with this rate replacing W on the right-hand side, η replaced by the ion-acoustic
occupation number ηB, and the electron distribution replaced by the A-mode or C-
mode Langmuir occupation number; see Ex. 23.5. Moreover, there will be a similar
evolution law for the Langmuir occupation number, involving the same fundamental
rate (23.56); Ex. 23.6.
EXERCISES
Exercise 23.5 Example and Challenge: Three-Wave
Mixing—Ion-Acoustic Evolution
Consider the three-wave processes shown in Fig. 23.5, with A and C Langmuir plas-
mons and B an ion-acoustic plasmon. The fundamental rate is given by Eqs. (23.56a)
and (23.56b).
(a) By summing the rates of forward and backward reactions (Fig. 23.5a,b), show
that the occupation number for the ion-acoustic plasmons satisﬁes the kinetic
equation
dηB
dt =

WAB↔C[(1 + ηA + ηB)ηC −ηAηB]
dVkA
(2π)3
dVkC
(2π)3.
(23.57)
[Hint: (i) The rate for A + B →C (Fig. 23.5a) will be proportional to
(ηC + 1)ηAηB; why? (ii) When you sum the rates for the two diagrams, Fig. 23.5a
and b, the terms involving ηAηBηC should cancel.]
(b) The ion-acoustic plasmons have far lower frequencies than the Langmuir plas-
mons, so ωB ≪ωA ≃ωC. Assume that they also have far lower wave numbers,
|kB| ≪|kA| ≃|kC|. Assume further (as will typically be the case) that the ion-
acoustic plasmons, because of their tiny individual energies, have far larger oc-
cupation numbers than the Langmuir plasmons, so ηB ≫ηA ∼ηC. Using these
approximations, show that the evolution law (23.57) for the ion-acoustic waves
reduces to the form
dηB(k)
dt
= ηB(k)

RAB↔C(k′ −k, k, k′)δ[ωB(k) −k . Vg L(k′)]k . ∇k′ηL(k′) dVk′
(2π)6 ,
(23.58)
1134
Chapter 23. Nonlinear Dynamics of Plasmas

where ηL is the Langmuir (waves A and C) occupation number, Vg L is the
Langmuir group velocity, and RC↔BA is the fundamental rate (23.56b).
(c) Notice the strong similarities between the evolution equation (23.58) for the
ion-acoustic plasmons that are Cerenkov emitted and absorbed by Langmuir
plasmons, and the evolution equation (23.44) for Langmuir plasmons that are
Cerenkov emitted and absorbed by fast electrons! Discuss the similarities and
the physical reasons for them.
(d) Challenge: Carry out an explicit classical calculation of the nonlinear interaction
between Langmuir waves with wave vectors kA and kC to produce ion-acoustic
waves with wave vector kB = kC −kA. Base your calculation on the nonlinear
Vlasovequation(23.55)and[foruseinrelatingE andf1inthenonlinearterm]the
3-dimensional analog of Eq. (23.13). Assume a spatially independent Maxwellian
averaged electron velocity distribution f0 with temperature Te (so ∇f0 = 0).
From your result compute, in the random-phase approximation, the evolution
of the ion-acoustic energy density Ek and thence the evolution of the occupation
number η(k). Bring that evolution equation into the functional form (23.58). By
comparing quantitatively with Eq. (23.58), read off the fundamental rate RC↔BA.
Your result should be the rate in Eq. (23.56b).
Exercise 23.6 Example and Challenge: Three-Wave Mixing—Langmuir Evolution
This exercise continues the analysis of the preceding one.
(a) Derive the kinetic equation for the Langmuir occupation number. [Hint: You
will have to sum over four Feynman diagrams, corresponding to the mode of
interest playing the role of A and then the role of C in each of the two diagrams
in Fig. 23.5.]
(b) Using the approximations outlined in part (b) of Ex. 23.5, show that the Langmuir
occupation number evolves in accord with the diffusion equation
dηL(k′)
dt
= ∇k′ . [D(k′) . ∇k′ηL(k′)],
(23.59a)
where the diffusion coefﬁcient is given by the following integral over the ion-
acoustic-wave distribution:
D(k′) =

ηB(k) k ⊗k RAB↔C(k′ −k, k, k′) δ[ωB(k) −k . Vg L(k′)] dVk′
(2π)6 .
(23.59b)
(c) Discuss the strong similarity between the evolution law (23.59) for resonant
Langmuir plasmons interacting with ion-acoustic waves, and the one for resonant
electronsinteractingwithLangmuirwaves[Eqs.(23.29c), (23.29d)].Whyarethey
so similar?
23.3 Quasilinear Theory in Quantum Mechanical Language
1135

23.4
23.4 Quasilinear Evolution of Unstable Distribution
Functions—A Bump in the Tail
In plasma physics, one often encounters a weak beam of electrons passing through
a stable Maxwellian plasma, with electron density ne, beam density nb, and beam
speed vb much larger than the thermal width σe of the background plasma. When the
velocity width of the beam σb is small compared with vb, the distribution is known
as a bump-in-tail distribution (see Fig. 23.6). In this section, we explore the stability
and nonlinear evolution of such a distribution.
We focus on the simple case of a 1-dimensional electron distribution function
F0(v) and approximate the beam by a Maxwellian distribution:
Fb(v) =
nb
(2π)1/2σb
e−(v−vb)2/(2σ 2
b),
(23.60)
where nb is the beam electron density. For simplicity, we treat the protons as a uniform
neutralizing background.
Now, let us suppose that at time t = 0, the beam is established, and the Langmuir
wave energy density Ek is very small. The waves will grow fastest when the waves’
phase velocity Vph = ωr/k resides where the slope of the distribution function is
most positive (i.e., when Vph = vb −σb). The associated maximum growth rate as
computed from Eq. (23.12b) is
maximum growth rate for
Langmuir waves
ωimax =
 π
8e
1/2 vb
σb
2 nb
ne

ωp,
(23.61)
where e = 2.718 . . . is not the electron charge. Modes will grow over a range of wave
phase velocities Vph ∼σb. By using the Bohm-Gross dispersion relation (21.31)
rewritten in the form
ω = ωp(1 −3σ 2
e /V 2
ph)−1/2,
(23.62)
we ﬁnd that the bandwidth of the growing modes is given roughly by
ω = Kωp
σb
vb
,
(23.63)
whereK = 3(σe/vb)2[1−3(σe/vb)2]−3/2 isaconstanttypically>∼0.1.CombiningEqs.
(23.61) and (23.63), we obtain
ωimax
ω ∼

π
8eK2
1/2 vb
σb
3 nb
ne

.
(23.64)
Dropping constants of order unity, we conclude that the waves’ growth time
∼(ωimax)−1 is long compared with their coherence time ∼(ω)−1, provided that
σb >∼
nb
ne
1/3
vb.
(23.65)
When inequality (23.65) is satisﬁed, the waves will take several coherence times
validity of quasilinear
analysis
to grow, and so we expect that no permanent phase relations will be established in
1136
Chapter 23. Nonlinear Dynamics of Plasmas

F(v)
time
σe
2σb
vb
v
FIGURE 23.6 Evolution of the 1-dimensional electron distribution
function from a bump-on-tail shape to a ﬂat distribution function,
duetothegrowthandscatteringofelectrostaticwaves.Thedirection
of evolution is indicated by the downward-pointing arrow at v = vb.
the electric ﬁeld and that quasilinear theory is an appropriate tool. However, when
this inequality is reversed, the instability resembles more the two-stream instability
of Chap. 21, and the growth is so rapid as to imprint special phase relations on the
waves, so the random-phase approximation fails and quasilinear theory is invalid.
Restricting ourselves to slow growth, we use quasilinear theory to explore the
evolution of the wave and particle distributions. We can associate the wave energy
density Ek not just with a given value of k but also with a corresponding value of
Vph = ωr/k, and thence with the velocities v = Vph of electrons that resonate with the
waves. Using Eq. (23.22a) for the velocity diffusion coefﬁcient and Eq. (23.12b) for
the associated wave-growth rate, we can then write the temporal evolution equations
for the electron distribution function F0(v, t) and the wave energy density Ek(v, t) as
evolution equations for
bump-in-tail instability
of electrons interacting
with Langmuir waves that
all propagate in the same
direction
∂F0
∂t = πe2
m2
eϵ0
∂
∂v
Ek
v
∂F0
∂v

,
∂Ek
∂t =
πe2
meϵ0ωp
v2Ek
∂F0
∂v .
(23.66)
Here v = ωr/k and, for simplicity, we have assumed a spatially homogeneous distri-
bution of particles and waves so d/dt →∂/∂t.
qualitative description of
the evolution
This pair of nonlinear equations must be solved numerically, but their qualitative
behavior can be understood analytically without much effort; see Fig. 23.6. Waves
resonant with the rising part of the electron distribution function at ﬁrst grow expo-
nentially, causing the particles to diffuse and ﬂatten the slope of F0 and thereby reduce
the wave-growth rate. Ultimately, the slope ∂F0/∂v diminishes to zero and the wave
energy density becomes constant, with its integral, by energy conservation (Ex. 23.2),
equal to the total kinetic energy lost by the beam. In this way we see that a velocity-
space irregularity in the distribution function leads to the growth of electrostatic waves,
which can react back on the particles in such a way as to saturate the instability. The
23.4 Quasilinear Evolution of Unstable Distribution Functions
1137

net result is a beam of particles with a much-broadened width propagating through
the plasma. The waves will ultimately damp through three-wave processes or other
damping mechanisms, converting their energy into heat.
EXERCISES
Exercise 23.7 Problem: Stability of Isotropic Distribution Function
For the bump-in-tail instability, the bump must show up in the 1-dimensional distri-
bution function F0 (after integrating out the electron velocity components orthogonal
to the wave vector v).
Consider an arbitrary, isotropic, 3-dimensional distribution function f0 = f0(|v|)
for electron velocities—one that might even have an isotropic bump at large |v|. Show
that this distribution is stable against the growth of Langmuir waves (i.e., it produces
ωi < 0 for all wave vectors k).
23.4.1
23.4.1 Instability of Streaming Cosmic Rays
For a simple illustration of this general type of instability (but one dealing with a
different wave mode), we return to the issue of the isotropization of galactic cosmic
rays, which we introduced in Sec. 19.7. We argued there that cosmic rays propagating
through the interstellar medium are effectively scattered by hydromagnetic Alfv´en
waves. We did not explain where these Alfv´en waves originated. Although often there
is an independent turbulence spectrum, sometimes these waves are generated by the
cosmic rays themselves.
example of bump-in-tail
instability: Alfv´en waves
generated by Cerenkov
emission from cosmic rays’
motion along interstellar
magnetic ﬁeld
Suppose we have a beam of cosmic rays propagating through the interstellar gas
at high speed. The interstellar gas is magnetized, which allows many more types of
wave modes to propagate than in the unmagnetized case. It turns out that the particle
distribution is unstable to the growth of Alfv´en wave modes satisfying the resonance
condition (23.53), modiﬁed to account for mildly relativistic protons rather than
nonrelativistic electrons:
ω −k∥. v∥= ωg.
(23.67)
Here ωg = ωcp

1 −v2/c2 is the proton’s gyro frequency, equal to its nonrelativistic
cyclotron frequency reduced by its Lorentz factor, and we assume that the number
of cyclotron (gyro) quanta fed into each emitted Alfv´en plasmon is N = 1. For ped-
agogical simplicity, let the wave propagate parallel to the magnetic ﬁeld so k = k||.
Then, since cosmic rays travel much faster than the Alfv´en waves (v ≫a = ω/k), the
wave’s frequency ω can be neglected in the resonance condition (23.67); equivalently,
we can transform to a reference frame that moves with the Alfv´en wave, so ω becomes
zero, altering v|| hardly at all. The resonance condition (23.67) then implies that the
distance the particle travels along the magnetic ﬁeld when making one trip around
its Larmor orbit is v||(2π/ωg) = 2π/k, which is the Alfv´en wave’s wavelength. This
makes sense physically; it enables the wave to resonate with the particle’s gyrational
motion, absorbing energy from it.
1138
Chapter 23. Nonlinear Dynamics of Plasmas

The growth rate of these waves can be studied using a kinetic theory analogous to
theonewehavejustdevelopedforLangmuirwaves(Kulsrud, 2005, Chap.12; Melrose,
1984, Sec. 10.5). Dropping factors of order unity, the growth rate for waves that scatter
cosmic rays of energy E is given approximately by
ωi ≃
*
ncr
np
+
ωcp
ucr
a −1

,
(23.68)
where ncr is the number density of cosmic rays with energy ∼E, np is the number
density of thermal protons in the background plasma, ucr is the mean speed of the
cosmic ray protons through the background plasma, and a is the Alfv´en speed; see
Ex. 23.8. Therefore, if the particles have a mean speed greater than the Alfv´en speed,
the waves will grow, exponentially at ﬁrst.
It is observed that the energy density of cosmic rays in our galaxy builds up until
it is roughly comparable with that of the thermal plasma. As more cosmic rays are
produced, they escape from the galaxy at a sufﬁcient rate to maintain this balance.
Therefore, in a steady state, the ratio of the number density of cosmic rays to the
thermal proton density is roughly the inverse of their mean-energy ratio. Adopting
a mean cosmic ray energy of ∼1GeV and an ambient temperature in the interstellar
medium of T ∼104 K, this ratio of number densities is ∼10−9. The ion gyro period
in the interstellar medium is ∼100 s for a typical ﬁeld of strength of ∼100 pT. Cosmic
rays streaming at a few times the Alfv´en speed create Alfv´en waves in ∼1010 s, of order
a few hundred years—long before they escape from the galaxy (e.g., Longair, 2011).
Thewavesthenreactbackonthecosmicrays, scatteringtheminmomentumspace
[Eq. (23.51a)]. Now, each time a particle is scattered by an Alfv´en-wave quantum, the
ratio of its energy change to the magnitude of its momentum change must be the
same as that in the waves and equal to the Alfv´en speed, which is far smaller than
the original energy-to-momentum ratio of the particle (∼c) for a mildly relativistic
proton. Therefore, the effect of the Alfv´en waves is to scatter the particle directions
without changing their energies signiﬁcantly. As the particles are already gyrating
around the magnetic ﬁeld, the effect of the waves is principally to change the angle
Alfv´en waves scatter
cosmic rays until their
speeds along the magnetic
ﬁeld are reduced to Alfv´en
speed, saturating the
bump-in-tail instability
between their momenta and the ﬁeld (known as the pitch angle), so as to reduce their
mean speed along the magnetic ﬁeld.
When this mean speed is reduced to a value of order the Alfv´en speed, the growth
rate diminishes, just like the growth rate of Langmuir waves is diminished after the
electron distribution function is ﬂattened. Under a wide variety of conditions, cosmic
rays are believed to maintain the requisite energy density in Alfv´en-wave turbulence
to prevent them from streaming along the magnetic ﬁeld with a mean speed much
faster than the Alfv´en speed (which varies between ∼3 and ∼30 km s−1). This model
of their transport differs from spatial diffusion, which we assumed in Sec. 19.7.3, but
the end result is similar, and cosmic rays are conﬁned to our galaxy for more than
∼10 million years. These processes can be observed directly using spacecraft in the
interplanetary medium.
23.4 Quasilinear Evolution of Unstable Distribution Functions
1139

EXERCISES
Exercise 23.8 Challenge: Alfv´en Wave Emission by Streaming Cosmic Rays
Consider a beam of high-energy cosmic ray protons streaming along a uniform back-
ground magnetic ﬁeld in a collisionless plasma. Let the cosmic rays have an isotropic
distribution function in a frame that moves along the magnetic ﬁeld with speed u, and
assume that u is large compared with the Alfv´en speed but small compared with the
speeds of the individual cosmic rays. Adapt our discussion of the emission of Lang-
muir waves by a bump-on-tail distribution to show that the growth rate is given to
order of magnitude by Eq. (23.68).
For a solution using an order-of-magnitude analysis, see Kulsrud (2005, Sec. 12.2).
For a detailed analysis using quasilinear theory, and then a quasilinear study of the
diffusion of cosmic rays in the Alfv´en waves they have generated, see Kulsrud (2005,
Secs. 12.3–12.5).
23.5
23.5 Parametric Instabilities; Laser Fusion
One of the approaches to the goal of attaining commercial nuclear fusion (Sec. 19.3.1)
is to compress and heat pellets containing a mixture of deuterium and tritium by using
laser fusion
powerful lasers. The goal is to produce gas densities and temperatures large enough,
and for long enough, that the nuclear energy released exceeds the energy expended in
producing the compression (Box 23.2). At these densities the incident laser radiation
behaves like a large-amplitude plasma wave and is subject to a new type of instability
that may already be familiar from dynamics, namely, a parametric instability.
Consider how the incident light is absorbed by the relatively tenuous ionized
plasma around the pellet. The critical density at which the incident wave frequency
equals the plasma frequency is ρ ∼5λ−2
μm kg m−3, where λμm is the wavelength mea-
sured in microns. For an incident wave energy ﬂux F ∼1018 W m−2, the amplitude
of the wave’s electric ﬁeld E ∼[F/(ϵ0c)]1/2 ∼2 × 1010 V m−1. The velocity of a free
electron oscillating in a wave this strong is v ∼eE/(meω) ∼2,000 km s−1, which is
almost 1% of the speed of light. It is therefore not surprising that nonlinear wave
processes are important.
One of the most important such processes is called stimulated Raman scattering.In
this interaction the coherent electromagnetic wave with frequency ω convects a small
preexisting density ﬂuctuation—one associated with a relatively low-frequency Lang-
muir wave with frequency ωpe—and converts the Langmuir density ﬂuctuation into a
stimulated Raman
scattering of laser
beam parametrically
ampliﬁes a Langmuir
wave, strengthening the
scattering (a parametric
instability) and impeding
laser fusion
current that varies at the beat frequency ω −ωpe. This creates a new electromagnetic
mode with this frequency. The vector sum of the k vectors of the two modes must also
equal the incident k vector. When this condition can ﬁrst be met, the new k is almost
antiparallel to that of the incident mode, and so the radiation is backscattered.
The new mode can combine nonlinearly with the original electromagnetic wave
to produce a pressure force ∝∇E2, which ampliﬁes the original density ﬂuctuation.
Provided the growth rate of the wave is faster than the natural damping rates (e.g.,
1140
Chapter 23. Nonlinear Dynamics of Plasmas

BOX 23.2.
LASER FUSION
In the simplest proposed scheme for laser fusion, solid pellets of deuterium
and tritium would be compressed and heated to allow the reaction
d + t →α + n + 17.6 MeV
(1)
to proceed. (We will meet this reaction again in Sec. 28.4.2.) An individual
pellet would have mass m ∼3 mg and initial diameter ri ∼2 mm. The total
latent nuclear energy in a single pellet is ∼1GJ. So if, optimistically, the useful
energy extraction were ∼3% of this, pellets would have to burn at a combined
rate of ∼105 s−1 in reactors all around the world to supply, say, a ﬁfth of the
current (2016) global power usage ∼15 TW.
The largest program designed to accomplish this goal is at the National
Ignition Facility in Lawrence Livermore National Laboratory in California.
Neodymium-glass pulsed lasers are used to illuminate a small pellet from
192 directions at a wavelength of 351 nm. (The frequency is tripled from the
initial infrared frequency using KDP crystals; Box 10.2.) The goal is to deliver
a power of ∼0.5 PW for a few nanoseconds. The nominal initial laser energy is
∼3 MJ derived from a capacitor bank storing ∼400 MJ of energy. The energy
is delivered to a small metal cylinder, called a hohlraum, where a signiﬁcant
fraction of the incident energy is converted to X-rays that illuminate the fuel
pellet, a technique known as indirect drive.The energy absorbed in the surface
layers of the pellet is ∼150 kJ. This causes the pellet to implode to roughly a
tenth of its initial size and a density of ∼106 kg m−3; nuclear energy releases
of 20 MJ are projected. It has recently become possible to create as much
fusion energy as the energy deposited in the pellet (Hurricane et al., 2014).
The shot repetition rate is currently about one per day. There is clearly a long
road ahead to safe commercial reactors supplying a signiﬁcant fraction of the
global power usage, but progress is being made.
that of Landau damping) there can be a strong backscattering of the incident wave at
a density well below the critical density of the incident radiation. (A further condition
that must be satisﬁed is that the bandwidth of the incident wave must also be less
than the growth rate. This will generally be true for a laser.) This stimulated Raman
scattering is an example of a parametric instability. The incident wave frequency is
called the pump frequency. One difference between parametric instabilities involving
waves as opposed to just oscillations is that it is necessary to match spatial as well as
temporal frequencies.
Reﬂection of the incident radiation by this mechanism reduces the ablation of the
pellet and also creates a population of suprathermal electrons, which conduct heat
23.5 Parametric Instabilities; Laser Fusion
1141

into the interior of the pellet and inhibit compression. Various strategies, including in-
creasing the wave frequency, have been devised to circumvent Raman backscattering
(and also a related process called Brillouin backscattering, in which the Langmuir
mode is replaced by an ion-acoustic mode).
EXERCISES
Exercise 23.9 Example: Ablation vs. Radiation Pressure in Laser Fusion
Demonstrate that ablation pressure is necessary to compress a pellet to densities at
which nuclear reactions can progress efﬁciently. More speciﬁcally, do the following.
(a) Assume that a temperature T ∼30 keV is necessary for nuclear reactions to pro-
ceed. Using the criteria developed in Sec. 20.2.2, evaluate the maximum density
before the electrons become degenerate. Estimate the associated pressure and
sound speed.
(b) Employ the Lawson criterion (19.25) to estimate the minimum size of a pellet for
break-even.
(c) Using the laser performance advertised in Box 23.2, compare the radiation pres-
sure in the laser light with the pressure needed from part (a). Do you think that
radiation pressure can create laser fusion?
(d) Assume instead that the incident laser energy is carried off by an outﬂow. Show
that the associated ablation pressure can be orders of magnitude higher than the
laser light pressure, and compute an upper bound on the speed of the outﬂow for
laser fusion to be possible.
23.6
23.6 Solitons and Collisionless Shock Waves
In Sec. 21.4.3, we introduced ion-acoustic waves that have a phase speed Vph ∼
(kBTe/mp)1/2, determined by a combination of electron pressure and ion inertia. In
Sec. 22.3.6, we argued that these waves would be strongly Landau-damped unless the
electron temperature greatly exceeded the proton temperature. However, this formal-
ism was only valid for waves of small amplitude so that the linear approximation could
be used. In Ex. 21.6, we considered the proﬁle of a nonlinear wave and found a solu-
tion for a single ion-acoustic soliton valid when the waves are weakly nonlinear. We
now consider this problem in a slightly different way, one valid for a wave amplitude
that is strongly nonlinear. However, we restrict our attention to waves that propagate
without change of form and so will not generalize the KdV equation.
Once again we use the ﬂuid model and introduce an ion-ﬂuid velocity u. We pre-
sume the electrons are highly mobile and so have a local density ne ∝exp[eφ/(kBTe)],
where φ (not  as above) is the electrostatic potential. The ions must satisfy equations
of continuity and motion:
1142
Chapter 23. Nonlinear Dynamics of Plasmas

∂n
∂t + ∂
∂z(nu) = 0,
∂u
∂t + u∂u
∂x = −e
mp
∂φ
∂z .
(23.69)
We now seek a solution for an ion-acoustic wave moving with constant speed V
two-ﬂuid theory of a
strongly nonlinear ion-
acoustic soliton with
speed VVV in a plasma with
thermalized electrons: ion
speed uuu and electrostatic
potential φφφ as functions of
ξ = z −V t
ξ = z −V t
ξ = z −V t
through the ambient plasma. In this case, all physical quantities must be functions
of a single dependent variable: ξ = z −V t. Using a prime to denote differentiation
with respect to ξ, Eqs. (23.69) become
(u −V )n′ = −nu′,
(u −V )u′ = −e
mp
φ′.
(23.70)
These two equations can be integrated and combined to obtain an expression for the
ion density n in terms of the electrostatic potential:
n = n0[1 −2eφ/(mpV 2)]−1/2,
(23.71)
where n0 is the ion density, presumed uniform, long before the wave arrives. The
next step is to combine this ion density with the electron density and substitute
into Poisson’s equation to obtain a nonlinear ordinary differential equation for the
potential:
φ′′ = −n0e
ϵ0
⎧
⎨
⎩
*
1 −2eφ
mpV 2
+−1/2
−eeφ/(kBTe)
⎫
⎬
⎭.
(23.72)
Now, the best way to think about this problem is to formulate the equivalent dy-
namical problem of a particle moving in a 1-dimensional potential well (φ), with φ
the particle’s position coordinate and ξ its time coordinate. Then Eq. (23.72) becomes
φ′′ = −d/dφ, whence 1
2φ′2 + (φ) = E, where E is the particle’s conserved energy.
Integrating −d/dφ = [right-hand side of Eq. (23.72)], and assuming that  →0 as
φ →0 (i.e., as ξ →∞, long before the arrival of the pulse), we obtain
(φ) = n0kBTe
ϵ0
A
1 −

1 −φ/φo
1/2
M2 −(eM2φ/(2φo) −1)
B
,
(23.73a)
where
φo = mpV 2/(2e),
M = [mpV 2/(kBTe)]1/2.
(23.73b)
We have assumed that 0 < φ < φo; when φ →φo, the proton density n →∞
[Eq. (23.71)].
The shape of this potential well (φ) is sketched in Fig. 23.7; it is determined
by the parameter M = [mpV 2/(kBTe)]1/2, which is readily recognizable as the ion-
acoustic Mach number (i.e., the ratio of the speed of the soliton to the ion-acoustic
speed in the undisturbed medium). A solution for the soliton’s potential proﬁle φ(ξ)
23.6 Solitons and Collisionless Shock Waves
1143

φ/φo
ϵ0"
—
n0kBTe
M = 1.0
1.3
1.58
1.65
0.4
0.0
–0.6
0.0
1.0
FIGURE 23.7 Potential function (φ) used for exhibiting the properties
of an ion-acoustic soliton for four different values of the ion-acoustic
Mach number M.
corresponds to the trajectory of the particle. Physically, a soliton (solitary wave) must
beconcentratedinaﬁniteregionofspaceatﬁxedtime; thatis, φ(ξ) = φ(z −V t)must
go to zero as ξ →±∞. For the particle moving in the potential (φ) this is possible
only if its total energy E vanishes, so 1
2φ′2 + (φ) = 0. The particle then starts at
φ = 0, with zero kinetic energy (i.e., φ′ = 0) and then accelerates to a maximum speed
near the minimum in the potential before decelerating. If there is a turning point, the
particle will come to rest, φ(ξ) will attain a maximum, and then the particle will
return to the origin. This particle trajectory corresponds to a symmetrical soliton,
propagating with uniform speed.
Two conditions must be satisﬁed for a soliton solution. First, the potential well
must be attractive. This only happens when d2/dφ2(0) < 0, which implies that
M > 1. Second, there must be a turning point. This happens if (φ = φo) > 0. The
maximum value of M for which these two conditions are met is a solution of the
equation
eM2/2 −1 −M2 = 0
(23.74)
(i.e., M = 1.58). Hence, ion-acoustic-soliton solutions only exist for
Mach number for
ion-acoustic soliton
1 < M < 1.59.
(23.75)
If M < 1, the particle’s potential  acts as a barrier, preventing it from moving into
the φ > 0 region. If M > 1.59, the plasma’s electrons short out the potential; that is,
the electron term (eM2φ/(2φo) −1) in Eq. (23.73a) becomes so negative that it makes
(φo) negative.
This analogy with particle dynamics is not only helpful in understanding large-
amplitude solitons. It also assists us to understand a deep connection between these
solitons and laminar shock fronts. The equations that we have been solving so far
1144
Chapter 23. Nonlinear Dynamics of Plasmas

φ/φo
φ/φo
ξ
"
0
1
0
(a)
(b)
FIGURE23.8 Ion-acousticshockwave.(a)Solutionintermsofdampedparticlemotionφ(ξ)
(blue curve) in the equivalent potential (φ) (black curve). (b) Electrostatic potential
proﬁle φ(ξ) = φ(z −V t) in the shock. The proton number-density variation n(ξ) in the
shock can be inferred from this φ(ξ) using Eq. (23.71).
contain the two key ingredients for a soliton: nonlinearity to steepen the wave proﬁle
and dispersion to spread it. However, they do not make provision for any form
of dissipation, a necessary condition for a shock front, in which the entropy must
increase.
In a real collisionless plasma, this dissipation can take on many forms. It may be
associated with anomalous resistivity or perhaps with some viscosity associated with
the ions. In many circumstances, some ions are reﬂected by the electrostatic potential
barrier and counterstream against the incoming ions, which they eventually heat.
Whatever its origin, the net effect of this dissipation will be to cause the equivalent
particle to lose its total energy, so that it can never return to its starting point. Given
adding dissipation
converts soliton into a
laminar, collisionless
shock
an attractive and bounded potential well, we ﬁnd that the particle has no alternative
except to sink to the bottom of the well. Depending on the strength of the dissipation,
the particle may undergo several oscillations before coming to rest. See Fig. 23.8a.
The structure to which this type of solution corresponds is a laminar shock front.
Unlike that for a soliton, the wave proﬁle in a shock wave is not symmetric in this case
and instead describes a permanent change in the electrostatic potential φ (Fig. 23.8b).
Repeating the arguments above, we ﬁnd that a shock wave can only exist when M > 1,
that is to say, it must be supersonic with respect to the ion-acoustic sound speed. In
addition there is a maximum critical Mach number close to M = 1.6, above which a
laminar shock becomes impossible.
What happens when the critical Mach number is exceeded? In this case there are
several possibilities, which include relying on a more rapidly moving wave to form
the shock front or appealing to turbulent conditions downstream from the front to
enhance the dissipation rate.
This ion-acoustic shock front is the simplest example of a collisionless shock.
Essentially every wave mode can be responsible for the formation of a shock. The
dissipation in these shocks is still not very well understood, but we can observe them
in several different environments in the heliosphere and also in the laboratory. The
23.6 Solitons and Collisionless Shock Waves
1145

solar wind
polar
wind
polar
magnetosheath
magnetopause
boundary layer
geomagnetic tail
radiation belt and
ring current
plasmasphere
cusp
bow shock
BIMF
plasmasheet
FIGURE 23.9 The form of the collisionless bow shock formed around Earth’s magnetosphere.
Earth’s bow shock has been extensively studied using spacecraft. Alfv´en, ion-acoustic, whistler,
and Langmuir waves are all generated with large amplitudes in the vicinity of shock fronts by
the highly nonthermal particle distributions. Adapted from Parks (2004).
best studied of these shock waves are those based on magnetosonic waves, which
were introduced in Sec. 19.7. The solar wind moves with a speed that is typically
5 times the Alfv´en speed. It should therefore form a bow shock (one based on the
collisionless bow shock
at interface of Earth’s
magnetic ﬁeld with solar
wind
fast magnetosonic mode) when it encounters a planetary magnetosphere. This bow
shock forms even though the mean free path of the ions for Coulomb scattering in
the solar wind is typically much larger than the thickness of the shock front. The
thickness turns out to be a few ion Larmor radii. This is a dramatic illustration of the
importance of collective effects in controlling the behavior of essentially collisionless
plasmas (Fig. 23.9; see Sagdeev and Kennel, 1991).
EXERCISES
Exercise 23.10 Derivation: Maximum Mach Number for an Ion-Acoustic Shock Wave
Verify Eq. (23.73a), and show numerically that the maximum Mach number for a
laminar shock front is M = 1.58.
Exercise 23.11 Problem: Solar-Wind Termination Shock
The solar wind is a quasi-spherical outﬂow of plasma from the Sun. At the radius of
Earth’s orbit, the mean proton and electron densities are np ∼ne ∼4 × 106 m−3,
their temperatures are Tp ∼Te ∼105 K, and their common radial ﬂuid speed is
1146
Chapter 23. Nonlinear Dynamics of Plasmas

∼400 km s−1. The mean magnetic ﬁeld strength is ∼1nT. Eventually, the radial mo-
mentum ﬂux in the solar wind falls to the value of the mean interstellar pressure,
∼10−13 N m−2, and a shock develops.
(a) Estimate the radius where the shock develops.
(b) Thesolarsystemmovesthroughtheinterstellarmediumwithaspeed∼30 kms−1.
Sketch the likely ﬂow pattern near this radius.
(c) How do you expect the magnetic ﬁeld to vary with radius in the outﬂowing solar
wind? Estimate its value at the termination shock.
(d) Estimate the electron plasma frequency, the ion-acoustic Mach number, and the
proton Larmor radius just ahead of the termination shock front, and comment
on the implications of these values for the shock structure.
(e) The Voyager 1 spacecraft was launched in 1977 and is traveling radially away
from the Sun with a terminal speed ∼17 km s−1. It was observed to cross the
termination shock in 2004, and in 2012 it passed beyond the limit of the shocked
solar wind into the interstellar medium. The Voyager 2 spacecraft passed through
the termination shock a few years after Voyager 1. How do these observations
compare with your answer to part (a)?
Exercise 23.12 Example: Diffusive Shock Acceleration of Galactic Cosmic Rays
Cosmic ray particles with energies between ∼1GeV and ∼1PeV are believed to be
accelerated at the strong shock fronts formed by supernova explosions in the strongly
scattering, local, interstellar medium. We explore a simple model of the way in which
this happens.
(a) In a reference frame where the shock is at rest, consider the stationary (time-
independent) ﬂow of a medium (a plasma) with velocity u(x) ex, and consider
relativistic cosmic rays, diffusing through the medium, that have reached a sta-
tionary state. Assume that the mean free paths of the cosmic rays are so short that
their distribution function f = dN/dVxdVp is nearly isotropic in the local rest
frame of the medium, so f = f0( ˜p, x) + f1(p, x), where ˜p is the magnitude of
a cosmic ray’s momentum as measured in the medium’s local rest frame, ˜p ≡|˜p|,
f0 ≡⟨f ⟩is the average over cosmic-ray propagation direction in the medium’s
local rest frame, and |f1| ≪|f0|. Show that in terms of the cosmic ray’s momen-
tum p = |p| and energy E =

p2 + m2 as measured in the shock’s rest frame,
˜p = p −u(x)E cos θ, where θ is the angle between p and the direction ex of the
medium’s motion. (Here and throughout this exercise we set the speed of light to
unity, as in Chap. 2.)
(b) ByexpandingthefullVlasovequationtosecondorderintheratioofthescattering
mean free path to the scale on which u(x) varies, it can be shown (e.g., Blandford
and Eichler, 1987, Sec. 3.5) that, in the shock’s frame,
u∂f
∂x −u ∂
∂x

D ∂f
∂x

= ˜p
3
∂f
∂˜p
∂u
∂x ,
(23.76a)
23.6 Solitons and Collisionless Shock Waves
1147

where D( ˜p, x) > 0 is the spatial diffusion coefﬁcient which arises from f1. Ex-
plore this convection-diffusion equation. For example, by integrating it over mo-
mentum space in the shock’s frame, show that it conserves cosmic ray particles.
Also, show that, when the diffusion term is unimportant, f0 is conserved moving
with the medium’s ﬂow in the sense that u∂f0/∂x + (d ˜p/dt)∂f0/∂˜p = 0, where
d ˜p/dt is the rate of change of cosmic ray momenta due to elastic scattering in
the expanding medium (for which a volume element changes as d ln Vx/dt =
∂u/∂x).
(c) Argue that the ﬂux of cosmic-ray particles, measured in the shock’s frame, is given
by
 ∞
0
F(p, x)4πp2dp, where F(p, x) = −D(∂f0/∂x) −u(p/3)(∂f/∂˜p); or, to
leading order in u/v, where v = p/E is the cosmic ray speed,
F( ˜p, x) = −D ∂f0
∂x −u ˜p
3
∂f
∂˜p .
(23.76b)
This F is often called the ﬂux of particles at momentum ˜p.
(d) Idealize the shock as a planar discontinuity at x = 0 in the medium’s velocity u(x);
idealize the velocity as constant before and after the shock, u = u−= constant
for x < 0, and u = u+ = constant for x > 0; and denote by r = u−/u+ > 1 the
shock’s compression ratio. Show that upstream from the shock, the solution to
the convection-diffusion equation (23.76a) is
f0( ˜p, x) = f−( ˜p) + [fs( ˜p) −f−( ˜p)]exp
'
−
 0
x
u−dx′
D( ˜p, x′)
(
at x< 0. (23.76c)
Here f−( ˜p) ≡f0( ˜p, x = −∞), and fs( ˜p) ≡f0( ˜p, x = 0) is the value of f0 at
the shock, which must be continuous across the shock. (Why?) Show further that
downstream from the shock f0 cannot depend on x, so
f0( ˜p, x) = fs( ˜p)
at x > 0 .
(23.76d)
(e) By matching the ﬂux of particles at momentum ˜p, F( ˜p, x) [Eq. (23.76b)], across
the shock, show that the post-shock distribution function is
fs( ˜p) = q ˜p−q

˜p
0
d ˜p′ f−( ˜p′) ˜p′(q−1) ,
(23.76e)
where q = 3r/(r −1).
(f) The fact that this stationary solution to the convection-diffusion equation has
a power-law spectrum fs ∝˜p−q, in accord with observations, suggests that the
observed cosmic rays may indeed be accelerated in shock fronts. How, physically,
do you think the acceleration occurs and how does this lead to a power-law
spectrum? What is the energy source for the acceleration? It may help to explore
the manner in which Eq. (23.76c) evolves an arbitrary initial distribution function
f−( ˜p) into the power-law distribution (23.76d). [For discussion and details, see,
e.g., Blandford and Eichler (1987), and Longair (2011).]
1148
Chapter 23. Nonlinear Dynamics of Plasmas

Bibliographic Note
Foraconcisetreatmentoftheclassicalquasilineartheoryofwave-particleinteractions
as in Sec. 23.2, see Lifshitz and Pitaevskii (1981, Sec. 49 for quasilinear theory, and
Sec. 51 for ﬂuctuations and correlations).
For more detailed and rich, pedagogical, classical treatments of quasilinear theory
and some stronger nonlinear effects in plasmas, see Bellan (2006, Chaps. 14, 15),
Boyd and Sanderson (2003, Chap. 10), Swanson (2003, Chaps. 7, 8), and Krall and
Trivelpiece (1973, Chaps. 10, 11). For a classical treatment of quasilinear theory that is
extended to include excitations of magnetized plasmas, see Stix (1992, Chaps. 16–18).
For the interactions of cosmic rays with Alfv´en waves, see Kulsrud (2005, Chap. 12).
For wave-wave coupling parametric instabilities, see Swanson (2003, Sec. 8.4). For
ion-acousticsolitonsandassociatedshocks, seeKrallandTrivelpiece(1973, Sec.3.9.4)
and Swanson (2003, Sec. 8.2).
A classic text on radiation processes in plasmas is Bekeﬁ(1966). An extensive
treatment of nonlinear plasma physics from a quantum viewpoint is contained in
Melrose (2008, 2012).
For applications to astrophysical plasmas, see Melrose (1984), Parks (2004), and
Kulsrud (2005), and for applications to laser-plasma interactions, see Kruer (1988).
Bibliographic Note
1149


VII
PART VII
GENERAL RELATIVITY
We have reached the ﬁnal part of this book, in which we present an introduction
to the basic concepts of general relativity and its most important applications. This
subject, although a little more challenging than the material that we have covered so
far, is nowhere near as formidable as its reputation. Indeed, if you have mastered the
techniques developed in the ﬁrst ﬁve parts, the path to the Einstein ﬁeld equations
should be short and direct.
The general theory of relativity is the crowning achievement of classical physics,
the last great fundamental theory created prior to the discovery of quantum mechan-
ics. Its formulation by Albert Einstein in 1915 marks the culmination of the great
intellectual adventure undertaken by Newton 250 years earlier. Einstein created it af-
ter many wrong turns and with little experimental guidance, almost by pure thought.
Unlike the special theory, whose physical foundations and logical consequences were
clearly appreciated by physicists soon after Einstein’s 1905 formulation, the unique
and distinctive character of the general theory only came to be widely appreciated
long after its creation. Ultimately, in hindsight, rival classical theories of gravitation
came to seem unnatural, inelegant, and arbitrary by comparison [see Will (1993b) for
a popular account and Pais (1982) for a more scholarly treatment].
Experimental tests of Einstein’s theory also were slow to come. Only since 1970
have there been striking tests of high enough precision to convince most empiricists
that—in all probability and in its domain of applicability—general relativity is essen-
tially correct. Despite these tests, it is still very poorly tested compared to, for example,
quantum electrodynamics.
We begin our discussion of general relativity in Chap. 24 with a review and an
elaboration of special relativity as developed in Chap. 2, focusing on those concepts
that are crucial for the transition to general relativity. Our elaboration includes (i) an
extension of differential geometry to curvilinear coordinate systems and general bases
both in the ﬂat spacetime of special relativity and in the curved spacetime that is the
venue for general relativity; (ii) an in-depth exploration of the stress-energy tensor,
which in general relativity generates the curvature of spacetime; and (iii) construction
1151

and exploration of the reference frames of accelerated observers (e.g., physicists who
reside on Earth’s surface).
In Chap. 25, we turn to the basic concepts of general relativity, including space-
time curvature, the Einstein ﬁeld equation that governs the generation of spacetime
curvature, the laws of physics in curved spacetime, and weak-gravity limits of general
relativity.
In the remaining chapters, we explore applications of general relativity to stars,
black holes, gravitational waves, experimental tests of the theory, and cosmology. We
begin in Chap. 26 by studying the spacetime curvature around and inside highly com-
pact stars (such as neutron stars). We then discuss the implosion of massive stars and
describe the circumstances under which the implosion inevitably produces a black
hole.Weexplorethesurprisingand, initially, counterintuitivepropertiesofblackholes
(both nonspinning and spinning holes), and we learn about the many-ﬁngered nature
of time in general relativity. In Chap. 27, we study experimental tests of general rela-
tivity and then turn to gravitational waves (i.e., ripples in the curvature of spacetime
that propagate with the speed of light). We explore the properties of these waves, and
their close analogy with electromagnetic waves, and their production by binary stars
and merging black holes. We also describe projects to detect them (both on Earth
and in space) and the prospects and success for using them to explore observationally
the “warped side of the universe” and the nature of ultrastrong spacetime curvature.
Finally, in Chap. 28,1 we draw on all the previous parts of this book, combining them
with general relativity to describe the universe on the largest of scales and longest
of times: cosmology. It is here, more than anywhere else in classical physics, that we
are conscious of reaching a frontier where the still-promised land of quantum gravity
beckons.
1.
Chapter 28 is very different in style from the rest of the book. It presents a minimalist treatment of the
now standard description of the universe at large. This is a huge subject from which we have ruthlessly
excised history, observational justiﬁcation, and didacticism. Our goal is limited to showing that much
of what is now widely accepted about the origin and evolution of the cosmos can be explained directly
and quantitatively using the ideas developed in this book.
1152
Part VII

24
CHAPTER TWENTY-FOUR
From Special to General Relativity
The Theory of Relativity confers an absolute meaning on a magnitude which in classical theory has only
a relative signiﬁcance: the velocity of light. The velocity of light is to the Theory of Relativity as the
elementary quantum of action is to the Quantum Theory: it is its absolute core.
MAX PLANCK (1949)
24.1
24.1 Overview
We begin our discussion of general relativity in this chapter with a review, and elab-
oration of relevant material already covered in earlier chapters. In Sec. 24.2, we give
a brief encapsulation of special relativity drawn largely from Chap. 2, emphasizing
those aspects that underpin the transition to general relativity. Then in Sec. 24.3 we
collect, review, and extend the fundamental ideas of differential geometry that have
been scattered throughout the book and that we shall need as foundations for the
mathematics of spacetime curvature (Chap. 25). Most importantly, we generalize dif-
ferential geometry to encompass coordinate systems whose coordinate lines are not
orthogonal and bases that are not orthonormal.
Einstein’s ﬁeld equation (to be studied in Chap. 25) is a relationship between the
curvature of spacetime and the matter that generates it, akin to the Maxwell equations’
relationship between the electromagnetic ﬁeld and the electric currents and charges
that generate it. The matter in Einstein’s equation is described by the stress-energy
tensor that we introduced in Sec. 2.13. We revisit the stress-energy tensor in Sec. 24.4
and develop a deeper understanding of its properties.
In general relativity one often wishes to describe the outcome of measurements
made by observers who refuse to fall freely—for example, an observer who hovers in a
spaceship just above the horizon of a black hole, or a gravitational-wave experimenter
in an Earthbound laboratory. As a foundation for treating such observers, in Sec. 24.5
we examine measurements made by accelerated observers in the ﬂat spacetime of
special relativity.
24.2
24.2 Special Relativity Once Again
Our viewpoint on general relativity is unapologetically geometrical. (Other view-
points, e.g., those of particle theorists such as Feynman and Weinberg, are quite differ-
ent.) Therefore, a prerequisite for our treatment of general relativity is understanding
special relativity in geometric language. In Chap. 2, we discussed the foundations of
1153

BOX 24.1.
READERS’ GUIDE
.
This chapter relies signiﬁcantly on:
– Chap. 2 on special relativity, which now should be regarded
as Track One.
– The discussion of connection coefﬁcients in Sec. 11.8.
.
This chapter is a foundation for the presentation of general relativity
theory and cosmology in Chaps. 25–28.
specialrelativitywiththisinmind.Inthissectionwebrieﬂyreviewthemostimportant
points.
We suggest that any reader who has not studied Chap. 2 read Sec. 24.2 ﬁrst, to
get an overview and ﬂavor of what will be important for our development of general
relativity, and then (or in parallel with reading Sec. 24.2) read those relevant sections
of Chap. 2 that the reader does not already understand.
24.2.1
24.2.1 Geometric, Frame-Independent Formulation
review of the geometric,
frame-independent
formulation of special
relativity
In Secs. 1.1.1 and 2.2.2, we learned that every law of physics must be expressible
as a geometric, frame-independent relationship among geometric, frame-independent
objects. This is equally true in Newtonian physics, in special relativity, and in general
relativity. The key difference between the three is the geometric arena: in Newto-
nian physics, the arena is 3-dimensional Euclidean space; in special relativity, it
is 4-dimensional Minkowski spacetime; in general relativity (Chap. 25), it is 4-
dimensional curved spacetime (see Fig. 1 in the Introduction to Part I and the
associated discussion).
Principle of Relativity—
laws as geometric relations
between geometric objects
In special relativity, the demand that the laws be geometric relationships among
geometric objects that live in Minkowski spacetime is the Principle of Relativity; see
Sec. 2.2.2. Examples of the geometric objects are:
examples of geometric
objects: points, curves,
proper time ticked by
an ideal clock, vectors,
tensors, scalar product
1. A point P in spacetime (which represents an event); Sec. 2.2.1.
2. Aparameterizedcurveinspacetime, suchastheworldlineP(τ)ofaparticle,
for which the parameter τ is the particle’s proper time (i.e., the time measured
by an ideal clock1 that the particle carries; Fig. 24.1); Sec. 2.4.1.
1.
Recall that an ideal clock is one that ticks uniformly when compared, e.g., to the period of the light
emitted by some standard type of atom or molecule, and that has been made impervious to accelerations.
Thus two ideal clocks momentarily at rest with respect to each other tick at the same rate independent of
their relative acceleration; see Secs. 2.2.1 and 2.4.1. For greater detail, see Misner, Thorne, and Wheeler
(1973, pp. 23–29, 395–399).
1154
Chapter 24. From Special to General Relativity

t
y
→u
→u
τ = 0
1
2
4
5
6
7
x
3
FIGURE 24.1 The world line P(τ) of a particle in Minkowski spacetime and the tangent
vector ⃗u = dP/dτ to this world line; ⃗u is the particle’s 4-velocity. The bending of the
world line is produced by some force that acts on the particle, such as the Lorentz force
embodied in Eq. (24.3). Also shown is the light cone emitted from the event P(τ = 1).
Although the axes of an (arbitrary) inertial reference frame are shown, no reference
frame is needed for the deﬁnition of the world line, its tangent vector ⃗u, or the light cone.
Nor is one needed for the formulation of the Lorentz force law.
3. Vectors, suchastheparticle’s4-velocity ⃗u = dP/dτ [thetangentvectortothe
curve P(τ)] and the particle’s 4-momentum ⃗p = m⃗u (with m the particle’s
rest mass); Secs. 2.2.1 and 2.4.1.
4. Tensors, such as the electromagnetic ﬁeld tensor FFF(
,
); Secs. 1.3 and 2.3.
Recall that a tensor is a linear real-valued function of vectors; when one puts vectors
⃗A and ⃗B into the two slots of FFF, one obtains a real number (a scalar) FFF( ⃗A, ⃗B) that
is linear in ⃗A and in ⃗B so, for example: FFF( ⃗A, b ⃗B + c ⃗C) = bFFF( ⃗A, ⃗B) + cFFF( ⃗A, ⃗C).
When one puts a vector ⃗B into just one of the slots of FFF and leaves the other empty, one
obtains a tensor with one empty slot, FFF(
, ⃗B), that is, a vector. The result of putting a
vector into the slot of a vector is the scalar product: ⃗D( ⃗B) = ⃗D . ⃗B = ggg( ⃗D, ⃗B), where
ggg(
,
) is the metric.
spacetime metric
In Secs. 2.3 and 2.4.1, we tied our deﬁnitions of the inner product and the
spacetime metric to the ticking of ideal clocks: If ⃗x is the vector separation of two
neighboring events P(τ) and P(τ + τ) along a particle’s world line, then
ggg(⃗x, ⃗x) ≡⃗x . ⃗x ≡−(τ)2.
(24.1)
This relation for any particle with any timelike world line, together with the linearity
of ggg(
,
) in its two slots, is enough to determine ggg completely and to guarantee that
it is symmetric: ggg( ⃗A, ⃗B) = ggg( ⃗B, ⃗A) for all ⃗A and ⃗B. Since the particle’s 4-velocity ⃗u is
⃗u = dP
dτ = lim
τ→0
P(τ + τ) −P(τ)
τ
≡lim
τ→0
⃗x
τ ,
(24.2)
Eq. (24.1) implies that ⃗u . ⃗u = ggg(⃗u, ⃗u) = −1 (Sec. 2.4.1).
light cone; timelike, null,
and spacelike vectors
The 4-velocity ⃗u is an example of a timelike vector (Sec. 2.2.3); it has a negative
inner product with itself (negative “squared length”). This shows up pictorially in the
24.2 Special Relativity Once Again
1155

fact that ⃗u lies inside the light cone (the cone swept out by the trajectories of photons
emitted from the tail of ⃗u; see Fig. 24.1). Vectors ⃗k on the light cone (the tangents
to the world lines of the photons) are null and so have vanishing squared lengths:
⃗k . ⃗k = ggg(⃗k, ⃗k) = 0; vectors ⃗A that lie outside the light cone are spacelike and have
positive squared lengths: ⃗A . ⃗A > 0 (Sec. 2.2.3).
An example of a physical law in 4-dimensional geometric language is the Lorentz
force law (Sec. 2.4.2):
Lorentz force law
d ⃗p
dτ = qFFF(
, ⃗u).
(24.3)
Here q is the particle’s charge (a scalar), and both sides of this equation are vectors,
or equivalently, ﬁrst-rank tensors (i.e., tensors with just one slot). As we learned in
Secs. 1.5.1 and 2.5.3, it is convenient to give names to slots. When we do so, we can
rewrite the Lorentz force law as
dpα
dτ = qF αβuβ.
(24.4)
Here α is the name of the slot of the vector d ⃗p/dτ, α and β are the names of the slots
slot-naming index notation
of FFF, β is the name of the slot of u. The double use of β with one up and one down
on the right-hand side of the equation represents the insertion of ⃗u into the β slot
of FFF, whereby the two β slots disappear, and we wind up with a vector whose slot is
named α. As we learned in Sec. 1.5, this slot-naming index notation is isomorphic to
the notation for components of vectors, tensors, and physical laws in some reference
frame. However, no reference frames are needed or involved when one formulates the
laws of physics in geometric, frame-independent language as above.
Those readers who do not feel completely comfortable with these concepts, state-
ments, and notation should reread the relevant portions of Chaps. 1 and 2.
EXERCISES
Exercise 24.1 Practice: Frame-Independent Tensors
Let AAA, BBB be second-rank tensors.
(a) Show that AAA + BBB is also a second-rank tensor.
(b) Show that AAA ⊗BBB is a fourth-rank tensor.
(c) Show that the contraction of AAA ⊗BBB on its ﬁrst and fourth slots is a second-rank
tensor. (If necessary, consult Secs. 1.5 and 2.5 for discussions of contraction.)
(d) Write the following quantities in slot-naming index notation: the tensor AAA ⊗BBB,
and the simultaneous contraction of this tensor on its ﬁrst and fourth slots and
on its second and third slots.
24.2.2
24.2.2 Inertial Frames and Components of Vectors, Tensors, and Physical Laws
inertial reference frame
In special relativity, a key role is played by inertial reference frames, Sec. 2.2.1. An
inertial frame is an (imaginary) latticework of rods and clocks that moves through
spacetime freely (inertially, without any force acting on it). The rods are orthogonal to
oneanotherandattachedtoinertial-guidancegyroscopes, sotheydonotrotate.These
1156
Chapter 24. From Special to General Relativity

rods are used to identify the spatial, Cartesian coordinates (x1, x2, x3) = (x, y, z) of
an event P [which we also denote by lowercased Latin indices xj(P), with j running
over 1, 2, 3]. The latticework’s clocks are ideal and are synchronized with one another
by the Einstein light-pulse process. They are used to identify the temporal coordinate
x0 = t of an event P: x0(P) is the time measured by that latticework clock whose
world line passes through P, at the moment of passage. The spacetime coordinates
of P are denoted by lowercased Greek indices xα, with α running over 0, 1, 2, 3. An
inertial frame’s spacetime coordinates xα(P) are called Lorentz coordinates or inertial
Lorentz (inertial)
coordinates
coordinates.
In the real universe, spacetime curvature is small in regions well removed from
concentrations of matter (e.g., in intergalactic space), so special relativity is highly
accurate there. In such a region, frames of reference (rod-clock latticeworks) that are
nonaccelerating and nonrotating with respect to cosmologically distant galaxies (and
hence with respect to a local frame in which the cosmic microwave radiation looks
isotropic) constitute good approximations to inertial reference frames.
orthonormal basis vectors
of an inertial frame
Associated with an inertial frame’s Lorentz coordinates are basis vectors ⃗eα that
point along the frame’s coordinate axes (and thus are orthogonal to one another) and
have unit length (making them orthonormal); see Sec. 2.5. This orthonormality is
embodied in the inner products
⃗eα . ⃗eβ = ηαβ,
(24.5)
where by deﬁnition:
η00 = −1,
η11 = η22 = η33 = +1,
ηαβ = 0
if α ̸= β.
(24.6)
Here and throughout Part VII (as in Chap. 2), we set the speed of light to unity (i.e.,
we use the geometrized units introduced in Sec. 1.10), so spatial lengths (e.g., along
geometrized units
the x-axis) and time intervals (e.g., along the t-axis) are measured in the same units,
seconds or meters, with 1 s = 2.99792458 × 108 m.
In Sec. 2.5 (see also Sec. 1.5), we used the basis vectors of an inertial frame to
build a component representation of tensor analysis. The fact that the inner products
of timelike vectors with each other are negative (e.g., ⃗e0 . ⃗e0 = −1), while those of
spacelike vectors are positive (e.g., ⃗e1 . ⃗e1 = +1), forced us to introduce two types
of components: covariant (indices down) and contravariant (indices up). The co-
variant components of a tensor are computable by inserting the basis vectors into
covariant and contra-
variant components of
vectors and tensors
the tensor’s slots: uα = ⃗u(⃗eα) ≡⃗u . ⃗eα; Fαβ = FFF(⃗eα, ⃗eβ). For example, in our Lorentz
basis the covariant components of the metric are gαβ = ggg(⃗eα, ⃗eβ) = ⃗eα . ⃗eβ = ηαβ.
The contravariant components of a tensor were related to the covariant components
via “index lowering” with the aid of the metric, Fαβ = gαμgβνF μν, which simply
said that one reverses the sign when lowering a time index and makes no change of
sign when lowering a space index. This lowering rule implied that the contravariant
components of the metric in a Lorentz basis are the same numerically as the covariant
24.2 Special Relativity Once Again
1157

components, gαβ = ηαβ, and that they can be used to raise indices (i.e., to perform
the trivial sign ﬂip for temporal indices): F μν = gμαgνβFαβ. As we saw in Sec. 2.5,
tensors can be expressed in terms of their contravariant components as ⃗p = pα⃗eα,
and FFF = F αβ⃗eα ⊗⃗eβ, where ⊗represents the tensor product [Eqs. (1.5)].
We also learned in Chap. 2 that any frame-independent geometric relation among
tensors can be rewritten as a relation among those tensors’ components in any
chosen Lorentz frame. When one does so, the resulting component equation takes
precisely the same form as the slot-naming-index-notation version of the geometric
component equations
are same as slot-naming-
index-notation equations
relation (Sec. 1.5.1). For example, the component version of the Lorentz force law
says dpα/dτ = qF αβuβ, which is identical to Eq. (24.4). The only difference is the
interpretation of the symbols. In the component equation F αβ are the components
of FFF and the repeated β in F αβuβ is to be summed from 0 to 3. In the geometric
relation F αβ means FFF(
,
), with the ﬁrst slot named α and the second β, and the
repeated β in F αβuβ implies the insertion of ⃗u into the second slot of FFF to produce a
single-slotted tensor (i.e., a vector) whose slot is named α.
As we saw in Sec. 2.6, a particle’s 4-velocity ⃗u (deﬁned originally without the aid
of any reference frame; Fig. 24.1) has components, in any inertial frame, given by
u0 = γ , uj = γ vj, where vj = dxj/dt is the particle’s ordinary velocity and γ ≡
components of 4-velocity
in an inertial frame
1
J
1 −δijvivj. Similarly, the particle’s energy E ≡p0 is mγ , and its spatial momen-
tum is pj = mγ vj (i.e., in 3-dimensional geometric notation: p = mγ v). This is an
3 + 1 split
exampleofthemannerinwhichachoiceofLorentzframeproducesa“3+1”splitofthe
physics: a split of 4-dimensional spacetime into 3-dimensional space (with Cartesian
coordinatesxj)plus1-dimensionaltimet = x0; asplitoftheparticle’s4-momentum ⃗p
into its 3-dimensional spatial momentum p and its 1-dimensional energy E = p0; and
similarly a split of the electromagnetic ﬁeld tensor FFF into the 3-dimensional electric
ﬁeld E and 3-dimensional magnetic ﬁeld B (cf. Secs. 2.6 and 2.11).
The Principle of Relativity (all laws expressible as geometric relations between
geometric objects in Minkowski spacetime), when translated into 3+1 language, says
that, when the laws of physics are expressed in terms of components in a speciﬁc
Principle of Relativity
restated: laws take same
form in every inertial frame
Lorentz frame, the form of those laws must be independent of one’s choice of frame.
When translated into operational terms, it says that, if two observers in two different
Lorentz frames are given identical written instructions for a self-contained physics
experiment, then their two experiments must yield the same results to within their
experimental accuracies (Sec. 2.2.2).
Lorentz transformations
The components of tensors in one Lorentz frame are related to those in another
by a Lorentz transformation (Sec. 2.7), so the Principle of Relativity can be restated
as saying that, when expressed in terms of Lorentz-frame components, the laws of
Principle of Relativity
restated: laws are Lorentz
invariant
physics must be Lorentz-invariant (unchanged by Lorentz transformations). This is the
version of the Principle of Relativity that one meets in most elementary treatments of
special relativity. However, as the above discussion shows, it is a mere shadow of the
true Principle of Relativity—the shadow cast into Lorentz frames when one performs
1158
Chapter 24. From Special to General Relativity

a 3+1 split. The ultimate, fundamental version of the Principle of Relativity is the one
that needs no frames at all for its expression: all the laws of physics are expressible as
ultimate version of
Principle of Relativity
geometric relations among geometric objects that reside in Minkowski spacetime.
24.2.3
24.2.3 Light Speed, the Interval, and Spacetime Diagrams
One set of physical laws that must be the same in all inertial frames is Maxwell’s
equations. Let us discuss the implications of Maxwell’s equations and the Principle
of Relativity for the speed of light c. (For a more detailed discussion, see Sec. 2.2.2.)
According to Maxwell, c can be determined by performing nonradiative laboratory
experiments; it is not necessary to measure the time it takes light to travel along some
path; see Box 2.2. The Principle of Relativity requires that such experiments must give
the same result for c, independent of the reference frame in which the measurement
light speed is the same in
all inertial frames
apparatus resides, so the speed of light must be independent of reference frame. It is
this frame independence that enables us to introduce geometrized units with c = 1.
Another example of frame independence (Lorentz invariance) is provided by the
interval between two events (Sec. 2.2.3). The components gαβ = ηαβ of the metric
imply that, if ⃗x is the vector separating the two events and xα are its components
in some Lorentz coordinate system, then the squared length of ⃗x [also called the
interval and denoted (s)2] is given by
interval between two
events
(s)2 ≡⃗x . ⃗x = ggg(⃗x, ⃗x) = gαβxαxβ
= −(t)2 + (x)2 + (y)2 + (z)2.
(24.7)
Since ⃗x is a geometric, frame-independent object, so must be the interval. This
implies that the equation (s)2 = −(t)2 + (x)2 + (y)2 + (z)2 by which one
computes the interval between the two chosen events in one Lorentz frame must give
the same numerical result when used in any other frame (i.e., this expression must be
Lorentz invariant). This invariance of the interval is the starting point for most intro-
invariance of the interval
ductions to special relativity—and, indeed, we used it as a starting point in Sec. 2.2.
spacetime diagrams
Spacetime diagrams play a major role in our development of general relativity.
Accordingly, it is important that the reader feel very comfortable with them. We
recommend reviewing Fig. 2.7 and Ex. 2.14.
EXERCISES
Exercise 24.2 Example: Invariance of a Null Interval
You have measured the intervals between a number of adjacent events in spacetime
and thereby have deduced the metric ggg. Your friend claims that the metric is some
other frame-independent tensor ˜ggg that differs from ggg. Suppose that your correct
metric ggg and his wrong one ˜ggg agree on the forms of the light cones in spacetime
(i.e., they agree as to which intervals are null, which are spacelike, and which are
timelike), but they give different answers for the value of the interval in the spacelike
and timelike cases: ggg(⃗x, ⃗x) ̸= ˜ggg(⃗x, ⃗x). Prove that ˜ggg and ggg differ solely by
24.2 Special Relativity Once Again
1159

a scalar multiplicative factor, ˜ggg = aggg for some scalar a. We say that ˜ggg and ggg are
conformal to each other. [Hint: Pick some Lorentz frame and perform computations
there, then lift yourself back up to a frame-independent viewpoint.]
Exercise 24.3 Problem: Causality
If two events occur at the same spatial point but not simultaneously in one inertial
frame, prove that the temporal order of these events is the same in all inertial frames.
Prove also that in all other frames the temporal interval t between the two events
is larger than in the ﬁrst frame, and that there are no limits on the events’ spatial or
temporal separation in the other frames. Give twoproofs of these results, one algebraic
and the other via spacetime diagrams.
24.3
24.3 Differential Geometry in General Bases and in Curved Manifolds
The differential geometry (tensor-analysis) formalism reviewed in the last section is
inadequate for general relativity in several ways.
First, in general relativity we need to use bases ⃗eα that are not orthonormal (i.e.,
for which ⃗eα . ⃗eβ ̸= ηαβ). For example, near a spinning black hole there is much
power in using a time basis vector ⃗et that is tied in a simple way to the metric’s
time-translation symmetry and a spatial basis vector ⃗eφ that is tied to its rotational
symmetry. This time basis vector has an inner product with itself ⃗et . ⃗et = gtt that is
inﬂuenced by the slowing of time near the hole (so gtt ̸= −1); and ⃗eφ is not orthogonal
to ⃗et (⃗et . ⃗eφ = gtφ ̸= 0), as a result of the dragging of inertial frames by the hole’s spin.
In this section, we generalize our formalism to treat such nonorthonormal bases.
Second, in the curved spacetime of general relativity (and in any other curved
space, e.g., the 2-dimensional surface of Earth), the deﬁnition of a vector as an arrow
connecting two points (Secs. 1.2 and 2.2.1) is suspect, as it is not obvious on what
route the arrow should travel nor that the linear algebra of tensor analysis should be
valid for such arrows. In this section, we reﬁne the concept of a vector to deal with
this problem. In the process we introduce the concept of a tangent space in which the
linear algebra of tensors takes place—a different tangent space for tensors that live at
different points in the space.
Third, oncewehavebeenforcedtothinkofatensorasresidinginaspeciﬁctangent
spaceataspeciﬁcpointinthespace, thequestionarises:howcanonetransporttensors
from the tangent space at one point to the tangent space at an adjacent point? Since
the notion of a gradient of a vector depends on comparing the vector at two different
points and thus depends on the details of transport, we have to rework the notion of
a gradient and the gradient’s connection coefﬁcients.
Fourth, when doing an integral, one must add contributions that live at different
points in the space, so we must also rework the notion of integration.
We tackle each of these four issues in turn in the following four subsections.
1160
Chapter 24. From Special to General Relativity

24.3.1
24.3.1 Nonorthonormal Bases
Consider an n-dimensional manifold, that is, a space that, in the neighborhood of
manifold
any point, has the same topological and smoothness properties as n-dimensional
Euclidean space, though it might not have a locally Euclidean or locally Lorentz
metric and perhaps has no metric at all. If the manifold has a metric (e.g., 4-
dimensional spacetime, 3-dimensional Euclidean space, and the 2-dimensional sur-
face of a sphere) it is called “Riemannian.” In this chapter, all manifolds we consider
will be Riemannian.
At some point P in our chosen n-dimensional manifold with metric, introduce
a set of basis vectors {⃗e1, ⃗e2, . . . , ⃗en} and denote them generally as ⃗eα. We seek to
generalize the formalism of Sec. 24.2 in such a way that the index-manipulation rules
tensors in a nonortho-
normal basis
for components of tensors are unchanged. For example, we still want it to be true that
covariant components of any tensor are computable by inserting the basis vectors
into the tensor’s slots, Fαβ = FFF(⃗eα, ⃗eβ), and that the tensor itself can be reconstructed
from its contravariant components: FFF = F μν⃗eμ ⊗⃗eν. We also require that the two
sets of components are computable from each other via raising and lowering with the
metric components: Fαβ = gαμgβνF μν. The only thing we do not want to preserve
is the orthonormal values of the metric components: we must allow the basis to
be nonorthonormal and thus ⃗eα . ⃗eβ = gαβ to have arbitrary values (except that the
metric should be nondegenerate, so no linear combination of the ⃗eαs vanishes, which
means that the matrix ||gαβ|| should have nonzero determinant).
dual sets of basis vectors
Wecaneasilyachieveourgoalbyintroducingasecondsetofbasisvectors, denoted
{⃗e1, ⃗e2, . . . , ⃗en}, which is dual to our ﬁrst set in the sense that
⃗eμ . ⃗eβ ≡ggg(⃗eμ, ⃗eβ) = δμ
β.
(24.8)
Here δαβ is the Kronecker delta. This duality relation actually constitutes a deﬁnition
of the eμ once the ⃗eα have been chosen. To see this, regard ⃗eμ as a tensor of rank
one. This tensor is deﬁned as soon as its value on each and every vector has been
determined. Expression (24.8) gives the value ⃗eμ(⃗eβ) = ⃗eμ . ⃗eβ of ⃗eμ on each of the
four basis vectors ⃗eβ; and since every other vector can be expanded in terms of
the ⃗eβs and ⃗eμ(
) is a linear function, Eq. (24.8) thereby determines the value
of ⃗eμ on every other vector.
The duality relation (24.8) says that ⃗e1 is always perpendicular to all the ⃗eαs except
⃗e1, and its scalar product with ⃗e1 is unity—and similarly for the other basis vectors.
This interpretation is illustrated for 3-dimensional Euclidean space in Fig. 24.2. In
Minkowskispacetime, ifthe ⃗eα areanorthonormalLorentzbasis, thendualitydictates
that ⃗e0 = −⃗e0, and ⃗ej = +⃗ej.
The duality relation (24.8) leads immediately to the same index-manipulation
formalism as we have been using, if one deﬁnes the contravariant, covariant, and
mixed components of tensors in the obvious manner:
covariant, contravariant,
and mixed components of
a tensor
F μν = FFF(⃗eμ, ⃗eν),
Fαβ = FFF(⃗eα, ⃗eβ),
F μ
β = FFF(⃗eμ, ⃗eβ);
(24.9)
24.3 Differential Geometry in General Bases and in Curved Manifolds
1161

→e3
→e3
→e1
→e1
→e2
FIGURE 24.2 Nonorthonormal basis vectors ⃗ej in Euclidean
3-space and two members ⃗e1 and ⃗e3 of the dual basis. The
vectors ⃗e1and ⃗e2 lieinthehorizontalplane, so ⃗e3isorthogonal
to that plane (i.e., it points vertically upward), and its inner
product with ⃗e3 is unity. Similarly, the vectors ⃗e2 and ⃗e3 span
a vertical plane, so ⃗e1 is orthogonal to that plane (i.e., it points
horizontally), and its inner product with ⃗e1 is unity.
see Ex. 24.4. Among the consequences of this duality are the following:
covariant and contra-
variant components
of the metric
1. The matrix of contravariant components of the metric is inverse to that of
the covariant components, ||gμν|| = ||gαβ||−1, so that
gμβgβν = δμ
ν.
(24.10)
This relation guarantees that when one raises an index on a tensor Fαβ with
gμβ and then lowers it back down with gβμ, one recovers one’s original
covariant components Fαβ unaltered.
reconstructing a tensor
from its components
2. One can reconstruct a tensor from its components by lining up the indices
in a manner that accords with the rules of index manipulation:
FFF = F μν⃗eμ ⊗⃗eν = Fαβ⃗eα ⊗⃗eβ = F μ
β⃗eμ ⊗⃗eβ.
(24.11)
component equations
are same as slot-naming-
index-notation equations
3. The component versions of tensorial equations are identical in mathematical
symbology to the slot-naming-index-notation versions:
FFF( ⃗p, ⃗q) = F αβpαpβ.
(24.12)
Associated with any coordinate system xα(P) there is a coordinate basis whose
basis vectors are deﬁned by
coordinate basis
⃗eα ≡∂P
∂xα .
(24.13)
Since the derivative is taken holding the other coordinates ﬁxed, the basis vector ⃗eα
points along the α coordinate axis (the axis on which xα changes and all the other
coordinates are held ﬁxed).
1162
Chapter 24. From Special to General Relativity

→eϖ
→eϖ = ∂P/∂ϖ
→eφ = ∂P/∂φ
→eφ
→eφˆ
FIGURE 24.3 A circular coordinate system {ϖ , φ} and its
coordinate basis vectors ⃗eϖ = ∂P/∂ϖ, ⃗eφ = ∂P/∂φ at
several locations in the coordinate system. Also shown is the
orthonormal basis vector ⃗e ˆφ.
In an orthogonal curvilinear coordinate system [e.g., circular polar coordinates
orthogonal curvilinear
coordinates
(ϖ , φ) in Euclidean 2-space; Fig. 24.3], this coordinate basis is quite different from
the coordinate system’s orthonormal basis. For example, ⃗eφ = (∂P/∂φ)ϖ is a very
long vector at large radii and a very short one at small radii; the corresponding
unit-length vector is ⃗e ˆφ = (1/ϖ)⃗eφ = (1/ϖ)∂/∂φ (i.e., the derivative with respect
to physical distance along the φ direction). By contrast, ⃗eϖ = (∂P/∂ϖ)φ already has
unit length, so the corresponding orthonormal basis vector is simply ⃗e ˆϖ = ⃗eϖ. The
metric components in the coordinate basis are readily seen to be gφφ = ϖ 2, gϖϖ = 1,
and gϖφ = gφϖ = 0, which are in accord with the equation for the squared distance
(interval) between adjacent points: ds2 = gijdxidxj = dϖ 2 + ϖ 2dφ2. Of course, the
metric components in the orthonormal basis are gˆi ˆj = δij.
Henceforth, we use hats to identify orthonormal bases; bases whose indices do
not have hats will typically (though not always) be coordinate bases.
We can construct the basis {⃗eμ} that is dual to the coordinate basis {⃗eα} =
{∂P/∂xα} by taking the gradients of the coordinates, viewed as scalar ﬁelds xα(P):
the basis dual to a
coordinate basis
⃗eμ = ⃗∇xμ.
(24.14)
It is straightforward to verify the duality relation (24.8) for these two bases:
⃗eμ . ⃗eα = ⃗eα . ⃗∇xμ = ∇⃗eαxμ = ∇∂P/∂xαxμ = ∂xμ
∂xα = δμ
α.
(24.15)
In any coordinate system, the expansion of the metric in terms of the dual basis,
ggg = gαβ⃗eα ⊗⃗eβ = gαβ ⃗∇xα ⊗⃗∇xβ, is intimately related to the line element ds2 =
gαβdxαdxβ. Consider an inﬁnitesimal vectorial displacement d ⃗x = dxα(∂/∂xα). In-
sert this displacement into the metric’s two slots to obtain the interval ds2 along
24.3 Differential Geometry in General Bases and in Curved Manifolds
1163

d ⃗x. The result is ds2 = gαβ∇xα ⊗∇xβ(d ⃗x, d ⃗x) = gαβ(d ⃗x . ∇xα)(d ⃗x . ∇xβ) =
gαβdxαdxβ:
the line element for the
invariant interval along a
displacement vector
ds2 = gαβdxαdxβ.
(24.16)
Here the second equality follows from the deﬁnition of the tensor product ⊗, and the
third from the fact that for any scalar ﬁeld ψ, d ⃗x . ∇ψ is the change dψ along d ⃗x.
Any two bases {⃗eα} and {⃗e ¯μ} can be expanded in terms of each other:
transformation matrices
linking two bases
⃗eα = ⃗e ¯μL ¯μ
α,
⃗e ¯μ = ⃗eαLα
¯μ.
(24.17)
(By convention the ﬁrst index on L is always placed up, and the second is always
placed down.) The quantities ||L ¯μα|| and ||Lα ¯μ|| are transformation matrices, and
since they operate in opposite directions, they must be the inverse of each other:
L ¯μ
αLα
¯ν = δ ¯μ
¯ν,
Lα
¯μL ¯μ
β = δα
β.
(24.18)
These ||L ¯μα|| are the generalizations of Lorentz transformations to arbitrary bases
[cf. Eqs. (2.34) and (2.35a)]. As in the Lorentz-transformation case, the transforma-
tion laws (24.17) for the basis vectors imply corresponding transformation laws for
components of vectors and tensors—laws that entail lining up indices in the obvious
manner:
transformation of tensor
components between
bases
A ¯μ = Lα ¯μAα,
T ¯μ¯ν ¯ρ = L ¯μαL¯νβLγ ¯ρT αβγ ,
and similarly in the opposite direction.
(24.19)
For coordinate bases, these L ¯μα are simply the partial derivatives of one set of
coordinates with respect to the other:
transformation matrices
between coordinate bases
L ¯μ
α = ∂x ¯μ
∂xα ,
Lα
¯μ = ∂xα
∂x ¯μ ,
(24.20)
as one can easily deduce via
⃗eα = ∂P
∂xα = ∂xμ
∂xα
∂P
∂xμ = ⃗eμ
∂xμ
∂xα .
(24.21)
In many physics textbooks a tensor is deﬁned as a set of components Fαβ that obey
the transformation laws
Fαβ = Fμν
∂xμ
∂xα
∂xν
∂xβ .
(24.22)
This deﬁnition (valid only in a coordinate basis) is in accord with Eqs. (24.19) and
(24.20), though it hides the true and very simple nature of a tensor as a linear function
of frame-independent vectors.
1164
Chapter 24. From Special to General Relativity

EXERCISES
Exercise 24.4 Derivation: Index-Manipulation Rules from Duality
For an arbitrary basis {⃗eα} and its dual basis {⃗eμ}, use (i) the duality relation (24.8),
(ii) the deﬁnition (24.9) of components of a tensor, and (iii) the relation ⃗A . ⃗B =
ggg( ⃗A, ⃗B) between the metric and the inner product to deduce the following results.
(a) The relations
⃗eμ = gμα⃗eα,
⃗eα = gαμ⃗eμ.
(24.23)
(b) The fact that indices on the components of tensors can be raised and lowered
using the components of the metric:
F μν = gμαFα
ν,
pα = gαβpβ.
(24.24)
(c) The fact that a tensor can be reconstructed from its components in the manner
of Eq. (24.11).
Exercise 24.5 Practice: Transformation Matrices for Circular Polar Bases
Consider the circular polar coordinate system {ϖ , φ} and its coordinate bases and
orthonormal bases as shown in Fig. 24.3 and discussed in the associated text. These
coordinates are related to Cartesian coordinates {x, y} by the usual relations: x =
ϖ cos φ, y = ϖ sin φ.
(a) Evaluate the components (Lxϖ, etc.) of the transformation matrix that links the
two coordinate bases {⃗ex, ⃗ey} and {⃗eϖ , ⃗eφ}. Also evaluate the components (Lϖ x,
etc.) of the inverse transformation matrix.
(b) Similarly, evaluate the components of the transformation matrix and its inverse
linking the bases {⃗ex, ⃗ey} and {⃗e ˆϖ , ⃗e ˆφ}.
(c) Consider the vector ⃗A ≡⃗ex + 2⃗ey. What are its components in the other two
bases?
24.3.2
24.3.2 Vectors as Directional Derivatives; Tangent Space; Commutators
As discussed in the introduction to Sec. 24.3, the notion of a vector as an arrow
connecting two points is problematic in a curved manifold and must be reﬁned. As
a ﬁrst step in the reﬁnement, let us consider the tangent vector ⃗A to a curve P(ζ)
at some point Po ≡P(ζ = 0). We have deﬁned that tangent vector by the limiting
process:
tangent vector to a curve
⃗A ≡dP
dζ ≡lim
ζ→0
P(ζ) −P(0)
ζ
(24.25)
[Eq. (24.2)]. In this deﬁnition the difference P(ζ) −P(0) means the tiny arrow
reaching from P(0) ≡Po to P(ζ). In the limit as ζ becomes vanishingly small,
these two points get arbitrarily close together. In such an arbitrarily small region of
the manifold, the effects of the manifold’s curvature become arbitrarily small and
24.3 Differential Geometry in General Bases and in Curved Manifolds
1165

ζ = –0.5
ζ =  0.5
ζ = 0
dP
—
dζ
A
→ =
FIGURE 24.4 A curve P(ζ) on the surface of a sphere and the
curve’s tangent vector ⃗A = dP/dζ at P(ζ = 0) ≡Po. The
tangent vector lives in the tangent space at Po (i.e., in the ﬂat
plane that is tangent to the sphere there, as seen in the ﬂat
Euclidean 3-space in which the sphere’s surface is embedded).
negligible (just think of an arbitrarily tiny region on the surface of a sphere), so the
notion of the arrow should become sensible. However, before the limit is completed,
we are required to divide by ζ, which makes our arbitrarily tiny arrow big again.
What meaning can we give to this?
One way to think about it is to imagine embedding the curved manifold in
a higher-dimensional ﬂat space (e.g., embed the surface of a sphere in a ﬂat 3-
dimensional Euclidean space, as shown in Fig. 24.4). Then the tiny arrow P(ζ) −
P(0) can be thought of equally well as lying on the sphere, or as lying in a surface
that is tangent to the sphere and is ﬂat, as measured in the ﬂat embedding space. We
can give meaning to [P(ζ) −P(0)]/ζ if we regard this expression as a formula
for lengthening an arrow-type vector in the ﬂat tangent surface; correspondingly, we
must regard the resulting tangent vector ⃗A as an arrow living in the tangent surface.
tangent space at a point
The (conceptual) ﬂat tangent surface at the point Po is called the tangent space
to the curved manifold at that point. It has the same number of dimensions n as the
manifold itself (two in the case of the surface of the sphere in Fig. 24.4). Vectors at Po
are arrows residing in that point’s tangent space, tensors at Po are linear functions of
these vectors, and all the linear algebra of vectors and tensors that reside at Po occurs
in this tangent space. For example, the inner product of two vectors ⃗A and ⃗B at Po
(two arrows living in the tangent space there) is computed via the standard relation
⃗A . ⃗B = ggg( ⃗A, ⃗B) using the metric ggg that also resides in the tangent space. (Scalars
reside in both the manifold and the tangent space.)
This pictorial way of thinking about the tangent space and vectors and tensors that
reside in it is far too heuristic to satisfy most mathematicians. Therefore, mathemati-
cians have insisted on making it much more precise at the price of greater abstraction.
Mathematicians deﬁne the tangent vector to the curve P(ζ) to be the derivative d/dζ
1166
Chapter 24. From Special to General Relativity

that differentiates scalar ﬁelds along the curve. This derivative operator is well deﬁned
by the rules of ordinary differentiation: if ψ(P) is a scalar ﬁeld in the manifold, then
ψ[P(ζ)] is a function of the real variable ζ, and its derivative (d/dζ)ψ[P(ζ)] eval-
uated at ζ = 0 is the ordinary derivative of elementary calculus. Since the derivative
operator d/dζ differentiates in the manifold along the direction in which the curve is
moving, it is often called the directional derivative along P(ζ). Mathematicians notice
directional derivative
that all the directional derivatives at a point Po of the manifold form a vector space
(they can be multiplied by scalars and added and subtracted to get new vectors), and
so the mathematicians deﬁne this vector space to be the tangent space at Po.
This mathematical procedure turns out to be isomorphic to the physicists’ more
heuristic way of thinking about the tangent space. In physicists’ language, if one intro-
duces a coordinate system in a region of the manifold containing Po and constructs
the corresponding coordinate basis ⃗eα = ∂P/∂xα, then one can expand any vector
in the tangent space as ⃗A = Aα∂P/∂xα. One can also construct, in physicists’ lan-
guage, the directional derivative along ⃗A; it is ∂⃗A ≡Aα∂/∂xα. Evidently, the com-
ponents Aα of the physicist’s vector ⃗A (an arrow) are identical to the coefﬁcients Aα
in the coordinate-expansion of the directional derivative ∂⃗A. Therefore a one-to-one
correspondence exists between the directional derivatives ∂⃗A at Po and the vectors
⃗A there, and a complete isomorphism holds between the tangent-space manipula-
tions that a mathematician performs treating the directional derivatives as vectors,
and those that a physicist performs treating the arrows as vectors.
tangent vector as
directional derivative
along a curve
“Whynotabandonthefuzzyconceptofavectorasanarrow, andredeﬁne the vector
⃗A to be the same as the directional derivative ∂⃗A?” mathematicians have demanded
of physicists. Slowly, over the past century, physicists have come to see the merit in
this approach. (i) It does, indeed, make the concept of a vector more rigorous than
before. (ii) It simpliﬁes a number of other concepts in mathematical physics (e.g., the
commutator of two vector ﬁelds; see below). (iii) It facilitates communication with
mathematicians. (iv) It provides a formalism that is useful for calculation. With these
motivations in mind, and because one always gains conceptual and computational
power by having multiple viewpoints at one’s ﬁngertips (see Feynman, 1966, p. 160),
we henceforth shall regard vectors both as arrows living in a tangent space and as
directional derivatives. Correspondingly, we assert the equalities:
∂P
∂xα =
∂
∂xα ,
⃗A = ∂⃗A,
(24.26)
and often expand vectors in a coordinate basis using the notation
⃗A = Aα ∂
∂xα .
(24.27)
This directional-derivative viewpoint on vectors makes natural the concept of the
commutator of two vector
ﬁelds
commutator of two vector ﬁelds ⃗A and ⃗B: [ ⃗A, ⃗B] is the vector that, when viewed
24.3 Differential Geometry in General Bases and in Curved Manifolds
1167

3A
→, B
→4
A
→
A
→
B
→
B
→
FIGURE 24.5 The commutator [ ⃗A, ⃗B]of two vector ﬁelds. The vectors are assumed to be so small
that the curvature of the manifold is negligible in the region of the diagram, so all the vectors can
be drawn lying in the manifold itself rather than in their respective tangent spaces. In evaluating
the two terms in the commutator (24.28), a locally orthonormal coordinate basis is used, so
Aα∂Bβ/∂xα is the amount by which the vector ⃗B changes when one travels along ⃗A (i.e., it is
the rightward-and-downward pointing dashed arrow in the upper right), and Bα∂Aβ/∂xα is
the amount by which ⃗A changes when one travels along ⃗B (i.e., it is the rightward-and-upward
pointing dashed arrow). According to Eq. (24.28), the difference of these two dashed arrows is
the commutator [ ⃗A, ⃗B]. As the diagram shows, this commutator closes the quadrilateral whose
legs are ⃗A and ⃗B. If the commutator vanishes, then there is no gap in the quadrilateral, which
means that in the region covered by this diagram, one can construct a coordinate system in
which ⃗A and ⃗B are coordinate basis vectors.
as a differential operator, is given by [∂⃗A, ∂⃗B]—where the latter quantity is the same
commutator as one meets elsewhere in physics (e.g., in quantum mechanics). Using
this deﬁnition, we can compute the components of the commutator in a coordinate
basis:
[ ⃗A, ⃗B]≡

Aα ∂
∂xα , Bβ ∂
∂xβ

=

Aα ∂Bβ
∂xα −Bα ∂Aβ
∂xα

∂
∂xβ .
(24.28)
This is an operator equation where the ﬁnal derivative is presumed to operate on a
scalar ﬁeld, just as in quantum mechanics. From this equation we can read off the
components of the commutator in any coordinate basis; they are AαBβ ,α −BαAβ ,α,
where the comma denotes partial differentiation. Figure 24.5 uses this equation to
deduce the geometric meaning of the commutator: it is the ﬁfth leg needed to close a
quadrilateral whose other four legs are constructed from the vector ﬁelds ⃗A and ⃗B. In
other words, it is “the change in ⃗B relative to ⃗A,” and as such it is a type of derivative
of ⃗B along ⃗A, called the Lie derivative: L ⃗A ⃗B ≡[ ⃗A, ⃗B](cf. footnote 2 in Chap. 14).
The commutator is useful as a tool for distinguishing between coordinate bases
and noncoordinate bases (also called nonholonomic bases). In a coordinate
basis, the basis vectors are just the coordinate system’s partial derivatives, ⃗eα = ∂/∂xα,
coordinate bases have
vanishing commutators
and since partial derivatives commute, it must be that [⃗eα, ⃗eβ]= 0. Conversely (as
Fig. 24.5 shows), if one has a basis with vanishing commutators [⃗eα, ⃗eβ]= 0, then it
1168
Chapter 24. From Special to General Relativity

is possible to construct a coordinate system for which this is the coordinate basis. In
a noncoordinate basis, at least one of the commutators [⃗eα, ⃗eβ]will be nonzero.
24.3.3
24.3.3 Differentiation of Vectors and Tensors; Connection Coefﬁcients
In a curved manifold, the differentiation of vectors and tensors is rather subtle. To
elucidate the problem, let us recall how we deﬁned such differentiation in Minkowski
spacetimeorEuclideanspace(Sec.1.7).ConvertingtothenotationusedinEq.(24.25),
webeganbydeﬁningthedirectionalderivativeofatensorﬁeld FFF(P)alongthetangent
vector ⃗A = d/dζ to a curve P(ζ):
directional derivative of a
tensor ﬁeld
∇⃗AFFF ≡lim
ζ→0
FFF[P(ζ)]−FFF[P(0)]
ζ
.
(24.29)
This deﬁnition is problematic, because FFF[P(ζ)] lives in a different tangent space
than does FFF[P(0)]. To make the deﬁnition meaningful, we must identify some con-
nection between the two tangent spaces, when their points P(ζ) and P(0) are
arbitrarily close together. That connection is equivalent to identifying a rule for trans-
porting FFF from one tangent space to the other.
In ﬂat space or ﬂat spacetime, and when FFF is a vector ⃗F, that transport rule is
obvious:keep ⃗F paralleltoitselfandkeepitslengthﬁxedduringthetransport.Inother
words, keep constant its components in an orthonormal coordinate system (Cartesian
coordinates in Euclidean space, Lorentz coordinates in Minkowski spacetime). This
is called the law of parallel transport. For a tensor FFF, the parallel transport law is the
same: keep its components ﬁxed in an orthonormal coordinate basis.
Now, just as the curvature of Earth’s surface prevents one from placing a Cartesian
coordinate system on it, so nonzero curvature of any other manifold prevents one
from introducing orthonormal coordinates; see Sec. 25.3. However, in an arbitrarily
small region on Earth’s surface, one can introduce coordinates that are arbitrarily close
to Cartesian (as surveyors well know); the fractional deviations from Cartesian need
be no larger than O(L2/R2), where L is the size of the region and R is Earth’s radius
(see Sec. 25.3). Similarly, in curved spacetime, in an arbitrarily small region, one can
introduce coordinates that are arbitrarily close to Lorentz, differing only by amounts
quadratic in the size of the region—and similarly for a local orthonormal coordinate
basis in any curved manifold.
When deﬁning ∇⃗AFFF, one is sensitive only to ﬁrst-order changes of quantities,
not second, so the parallel transport used in deﬁning it in a ﬂat manifold, based
on constancy of components in an orthonormal coordinate basis, must also work
in a local orthonormal coordinate basis of any curved manifold: In Eq. (24.29), one
must transport FFF from P(ζ) to P(0), holding its components ﬁxed in a locally
orthonormal coordinate basis (parallel transport), and then take the difference in the
tangent space at Po = P(0), divide by ζ, and let ζ →0. The result is a tensor at
Po: the directional derivative ∇⃗AFFF of FFF.
24.3 Differential Geometry in General Bases and in Curved Manifolds
1169

Having made the directional derivative meaningful, one can proceed as in Secs. 1.7
and 2.10: deﬁne the gradient of FFF by ∇⃗AFFF = ⃗∇FFF(
,
, ⃗A) [i.e., put ⃗A in the last—
gradient of a tensor ﬁeld
differentiation—slot of ⃗∇FFF; Eq. (1.15b)].
As in Chap. 2, in any basis we denote the components of ⃗∇FFF by Fαβ;γ. And as in
Sec. 11.8 (elasticity theory), we can compute these components in any basis with the
aid of that basis’s connection coefﬁcients.
In Sec. 11.8, we restricted ourselves to an orthonormal basis in Euclidean space
and thus had no need to distinguish between covariant and contravariant indices;
all indices were written as subscripts. Now, dealing with nonorthonormal bases in
spacetime, we must distinguish covariant and contravariant indices. Accordingly, by
analogy with Eq. (11.68), we deﬁne the connection coefﬁcients μαβ as
connection coefﬁcients for
a basis and its dual
∇β⃗eα ≡∇⃗eβ⃗eα = μ
αβ⃗eμ.
(24.30)
The duality between bases ⃗eν . ⃗eα = δνα then implies
∇β⃗eμ ≡∇⃗eβ⃗eμ = −μ
αβ⃗eα.
(24.31)
Note the sign ﬂip, which is required to keep ∇β(⃗eμ . ⃗eα) = 0, and note that the
differentiation index always goes last on . Duality also implies that Eqs. (24.30) and
(24.31) can be rewritten as
μ
αβ = ⃗eμ . ∇β⃗eα = −⃗eα . ∇β⃗eμ.
(24.32)
With the aid of these connection coefﬁcients, we can evaluate the components
Aα;β of the gradient of a vector ﬁeld in any basis. We just compute
Aμ
;β⃗eμ = ∇β ⃗A = ∇β(Aμ⃗eμ) = (∇βAμ)⃗eμ + Aμ∇β⃗eμ
= Aμ
,β⃗eμ + Aμα
μβ⃗eα
= (Aμ
,β + Aαμ
αβ)⃗eμ.
(24.33)
In going from the ﬁrst line to the second, we have used the notation
Aμ
,β ≡∂⃗eβAμ;
(24.34)
that is, the comma denotes the result of letting a basis vector act as a differential operator
on the component of the vector. In going from the second line of (24.33) to the third, we
have renamed some summed-over indices. By comparing the ﬁrst and last expressions
in Eq. (24.33), we conclude that
components of the
gradient of a vector ﬁeld
Aμ
;β = Aμ
,β + Aαμ
αβ.
(24.35)
Theﬁrstterminthisequationdescribesthechangesin ⃗Aassociatedwithchangesofits
component Aμ; the second term corrects for artiﬁcial changes of Aμ that are induced
by turning and length changes of the basis vector ⃗eμ. We shall use the short-hand
terminology that the second term “corrects the index μ.”
1170
Chapter 24. From Special to General Relativity

By a similar computation, we conclude that in any basis the covariant components
of the gradient are
Aα;β = Aα,β −μ
αβAμ,
(24.36)
where again Aα,β ≡∂⃗eβAα. Notice that, when the index being corrected is down [α
in Eq. (24.36)], the connection coefﬁcient has a minus sign; when it is up [μ in Eq.
(24.35)], the connection coefﬁcient has a plus sign. This is in accord with the signs in
Eqs. (24.30) and (24.31).
These considerations should make obvious the following equations for the com-
ponents of the gradient of a second rank tensor ﬁeld:
components of the
gradient of a tensor ﬁeld
F αβ
;γ = F αβ
,γ + α
μγF μβ + β
μγF αμ,
Fαβ;γ = Fαβ,γ −μ
αγFμβ −μ
βγFαμ,
F α
β;γ = F α
β,γ + α
μγF μ
β −μ
βγF α
μ.
(24.37)
Notice that each index of FFF must be corrected, the correction has a sign dictated by
whether the index is up or down, the differentiation index always goes last on the ,
and all other indices can be deduced by requiring that the free indices in each term
be the same and all other indices be summed.
If we have been given a basis, then how can we compute the connection coefﬁ-
cients? We can try to do so by drawing pictures and examining how the basis vectors
change from point to point—a method that is fruitful in spherical and cylindrical co-
ordinates in Euclidean space (Sec. 11.8). However, in other situations this method is
fraught with peril, so we need a ﬁrm mathematical prescription. It turns out that the
following prescription works (see Ex. 24.7 for a proof).
1. Evaluate the commutation coefﬁcients cαβρ of the basis, which are deﬁned
by the two equivalent relations:
commutation coefﬁcients
for a basis
[⃗eα, ⃗eβ]≡cαβ
ρ⃗eρ,
cαβ
ρ ≡⃗eρ . [⃗eα, ⃗eβ].
(24.38a)
(Note that in a coordinate basis the commutation coefﬁcients will vanish.
Warning: Commutation coefﬁcients also appear in the theory of Lie groups;
there it is conventional to use a different ordering of indices than here:
cαβρ
here = cραβLie groups.)
2. Lower the last index on the commutation coefﬁcients using the metric com-
ponents in the basis:
cαβγ ≡cαβ
ρgργ .
(24.38b)
3. Compute the quantities
formulas for computing
connection coefﬁcients
αβγ ≡1
2(gαβ,γ + gαγ ,β −gβγ ,α + cαβγ + cαγβ −cβγ α).
(24.38c)
24.3 Differential Geometry in General Bases and in Curved Manifolds
1171

Here the commas denote differentiation with respect to the basis vectors as
though the metric components were scalar ﬁelds [as in Eq. (24.34)]. Notice
that the pattern of indices is the same on the gs and on the cs. It is a
peculiar pattern—one of the few aspects of index gymnastics that cannot
be reconstructed by merely lining up indices. In a coordinate basis the c
terms will vanish, so αβγ will be symmetric in its last two indices. In an
orthonormal basis gμν are constant, so the g terms will vanish, and αβγ
will be antisymmetric in its ﬁrst two indices. And in a Cartesian or Lorentz
coordinate basis, which is both coordinate and orthonormal, both the c
terms and the g terms will vanish, so αβγ will vanish.
4. Raise the ﬁrst index on αβγ to obtain the connection coefﬁcients
μ
βγ = gμααβγ .
(24.38d)
In a coordinate basis, the μβγ are sometimes called Christoffel symbols,
though we will use the name connection coefﬁcients independent of the
nature of the basis.
The ﬁrst three steps in the above prescription for computing the connection
coefﬁcients follow from two key properties of the gradient ⃗∇. First, the gradient of
the metric tensor vanishes:
vanishing gradient of the
metric tensor
⃗∇ggg = 0.
(24.39)
Second, for any two vector ﬁelds ⃗A and ⃗B, the gradient is related to the commutator by
relation of gradient to
commutator
∇⃗A ⃗B −∇⃗B ⃗A = [ ⃗A, ⃗B].
(24.40)
For a derivation of these relations and then a derivation of the prescription 1–4, see
Exs. 24.6 and 24.7.
The gradient operator ⃗∇is an example of a geometric object that is not a tensor.
The connection coefﬁcients μβγ = ⃗eμ .
2
∇⃗eγ ⃗eβ
3
can be regarded as the components
of ⃗∇; becauseitisnotatensor, thesecomponentsdonotobeythetensorialtransforma-
tion law (24.19) when switching from one basis to another. Their transformation law
is far more complicated and is rarely used. Normally one computes them from scratch
in the new basis, using the above prescription or some other, equivalent prescription
(cf. Misner, Thorne, and Wheeler, 1973, Chap. 14). For most curved spacetimes that
one meets in general relativity, these computations are long and tedious and therefore
are normally carried out on computers using symbolic manipulation software, such as
Maple, Matlab, or Mathematica, or such programs as GR-Tensor and MathTensor that
run under Maple or Mathematica. Such software is easily found on the Internet using
a search engine. A particularly simple Mathematica program for use with coordinate
1172
Chapter 24. From Special to General Relativity

bases is presented and discussed in Appendix C of Hartle (2003) and is available on
that book’s website: http://web.physics.ucsb.edu/~gravitybook/.
EXERCISES
Exercise 24.6 Derivation: Properties of the Gradient ⃗∇
(a) Derive Eq. (24.39). [Hint: At a point P where ⃗∇ggg is to be evaluated, introduce a
locally orthonormal coordinate basis (i.e., locally Cartesian or locally Lorentz).
When computing in this basis, the effects of curvature show up only to second
order in distance from P. Show that in this basis, the components of ⃗∇ggg vanish,
and from this infer that ⃗∇ggg, viewed as a frame-independent third-rank tensor,
vanishes.]
(b) Derive Eq. (24.40). [Hint: Again work in a locally orthonormal coordinate basis.]
Exercise 24.7 Derivation and Example: Prescription
for Computing Connection Coefﬁcients
Derive the prescription 1–4 [Eqs. (24.38)] for computing the connection coefﬁcients
in any basis. [Hints: (i) In the chosen basis, from ⃗∇ggg = 0 infer that αβγ + βαγ =
gαβ,γ. Notice that this determines the part of αβγ that is symmetric in its ﬁrst
two indices. Show that the number of independent components of αβγ thereby
determined is 1
2n2(n + 1), where n is the manifold’s dimension. (ii) From Eq. (24.40)
infer that γβα −γ αβ = cαβγ, which ﬁxes the part of  antisymmetric in the last
two indices. Show that the number of independent components thereby determined
is 1
2n2(n −1). (iii) Infer that the number of independent components determined
by (i) and (ii) together is n3, which is the entirety of αβγ. By somewhat complicated
algebra, deduce Eq. (24.38c) forαβγ. (The algebra is sketched in Misner, Thorne, and
Wheeler, 1973, Ex. 8.15.) (iv) Then infer the ﬁnal answer, Eq. (24.38d), for μβγ.]
Exercise 24.8 Practice: Commutation and Connection Coefﬁcients
for Circular Polar Bases
Consider the circular polar coordinates {ϖ , φ} of Fig. 24.3 and their associated bases.
(a) Evaluate
the
commutation
coefﬁcients
cαβρ
for
the
coordinate
basis
{⃗eϖ , ⃗eφ}, and also for the orthonormal basis {⃗e ˆϖ , ⃗e ˆφ}.
(b) Compute by hand the connection coefﬁcients for the coordinate basis and also for
the orthonormal basis, using Eqs. (24.38). [Note: The answer for the orthonormal
basis was worked out pictorially in our study of elasticity theory; Fig. 11.15 and
Eq. (11.70).]
(c) Repeat this computation using symbolic manipulation software on a computer.
Exercise 24.9 Practice: Connection Coefﬁcients for Spherical Polar Coordinates
(a) Consider spherical polar coordinates in 3-dimensional space, and verify that the
nonzero connection coefﬁcients, assuming an orthonormal basis, are given by
Eq. (11.71).
24.3 Differential Geometry in General Bases and in Curved Manifolds
1173

(b) Repeat the exercise in part (a) assuming a coordinate basis with
er ≡∂
∂r ,
eθ ≡∂
∂θ ,
eφ ≡∂
∂φ .
(24.41)
(c) Repeat both computations in parts (a) and (b) using symbolic manipulation
software on a computer.
Exercise 24.10 Practice: Index Gymnastics—Geometric Optics
This exercise gives the reader practice in formal manipulations that involve the
gradient operator. In the geometric-optics (eikonal) approximation of Sec. 7.3, for
electromagnetic waves in Lorenz gauge, one can write the 4-vector potential in the
form ⃗A = ⃗Aeiϕ, where ⃗A is a slowly varying amplitude and ϕ is a rapidly varying
phase. By the techniques of Sec. 7.3, one can deduce from the vacuum Maxwell equa-
tions that the wave vector, deﬁned by ⃗k ≡⃗∇ϕ, is null: ⃗k . ⃗k = 0.
(a) Rewrite all the equations in the above paragraph in slot-naming index notation.
(b) Using index manipulations, show that the wave vector ⃗k (which is a vector ﬁeld,
because the wave’s phase ϕ is a scalar ﬁeld) satisﬁes the geodesic equation ∇⃗k⃗k = 0
(cf. Sec. 24.5.2). The geodesics, to which ⃗k is the tangent vector, are the rays
discussed in Sec. 7.3, along which the waves propagate.
24.3.4
24.3.4 Integration
Our desire to use general bases and work in curved manifolds gives rise to two new
issues in the deﬁnition of integrals.
The ﬁrst issue is that the volume elements used in integration involve the Levi-
Civita tensor [Eqs. (2.43), (2.52), and (2.55)], so we need to know the components
of the Levi-Civita tensor in a general basis. It turns out (see, e.g., Misner, Thorne,
and Wheeler, 1973, Ex. 8.3) that the covariant components differ from those in an
orthonormal basis by a factor √|g| and the contravariant by 1/√|g|, where
g ≡det ||gαβ||
(24.42)
is the determinant of the matrix whose entries are the covariant components of
the metric. More speciﬁcally, let us denote by [αβ . . . ν] the value of ϵαβ...ν in an
orthonormal basis of our n-dimensional space [Eq. (2.43)]:
[12 . . . n] = +1,
[αβ . . . ν] =
⎧
⎪⎨
⎪⎩
+1
if α, β, . . . , ν is an even permutation of 1, 2, . . . , n
−1
if α, β, . . . , ν is an odd permutation of 1, 2, . . . , n
0
if α, β, . . . , ν are not all different.
(24.43)
1174
Chapter 24. From Special to General Relativity

(In spacetime the indices must run from 0 to 3 rather than 1 to n = 4.) Then in a
general right-handed basis the components of the Levi-Civita tensor are
components of Levi-Civita
tensor in an arbitrary basis
ϵαβ...ν =

|g| [αβ . . . ν],
ϵαβ...ν = ±
1
√|g| [αβ . . . ν],
(24.44)
where the ± is plus in Euclidean space and minus in spacetime. In a left-handed basis
the sign is reversed.
As an example of these formulas, consider a spherical polar coordinate system
(r, θ, φ) in 3-dimensional Euclidean space, and use the three inﬁnitesimal vectors
dxj(∂/∂xj) to construct the volume element d [cf. Eq. (1.26)]:
dV = ϵ

dr ∂
∂r , dθ ∂
∂θ , dφ ∂
∂φ

= ϵrθφdrdθdφ = √
g drdθdφ = r2 sin θdrdθdφ.
(24.45)
Here the second equality follows from linearity of ϵ and the formula for computing
its components by inserting basis vectors into its slots; the third equality follows from
our formula (24.44) for the components. The fourth equality entails the determinant
of the metric coefﬁcients, which in spherical coordinates are grr = 1, gθθ = r2, and
gφφ = r2 sin2 θ; all other gjk vanish, so g = r4 sin2 θ. The resulting volume element
r2 sin θdrdθdφ should be familiar and obvious.
The second new integration issue we must face is that such integrals as

∂V
T αβdβ
(24.46)
[cf. Eqs. (2.55), (2.56)] involve constructing a vector T αβdβ in each inﬁnitesimal
region dβ of the surface of integration ∂V and then adding up the contributions
from all the inﬁnitesimal regions. A major difﬁculty arises because each contribution
lives in a different tangent space. To add them together, we must ﬁrst transport them
all to the same tangent space at some single location in the manifold. How is that
transport to be performed? The obvious answer is “by the same parallel transport
techniquethatweusedindeﬁningthegradient.”However, whendeﬁningthegradient,
we only needed to perform the parallel transport over an inﬁnitesimal distance, and
now we must perform it over long distances. When the manifold is curved, long-
distance parallel transport gives a result that depends on the route of the transport,
andingeneralthereisnowaytoidentifyanypreferredroute(see, e.g., Misner, Thorne,
and Wheeler, 1973, Sec. 11.4).
As a result, integrals such as Eq. (24.46) are ill-deﬁned in a curved manifold. The
integrals in a curved
manifold are well deﬁned
only if inﬁnitesimal
contributions are scalars
only integrals that are well deﬁned in a curved manifold are those such as

∂V Sαdα,
whose inﬁnitesimal contributions Sαdα are scalars (i.e., integrals whose value is a
scalar). This fact will have profound consequences in curved spacetime for the laws of
conservation of energy, momentum, and angular momentum (Secs. 25.7 and 25.9.4).
24.3 Differential Geometry in General Bases and in Curved Manifolds
1175

EXERCISES
Exercise 24.11 Practice: Integration—Gauss’s Theorem
In 3-dimensional Euclidean space Maxwell’s equation ∇. E = ρe/ϵ0 can be combined
with Gauss’s theorem to show that the electric ﬂux through the surface ∂V of a sphere
is equal to the charge in the sphere’s interior V divided by ϵ0:

∂V
E . d =

V
(ρe/ϵ0) dV .
(24.47)
Introduce spherical polar coordinates so the sphere’s surface is at some radius r = R.
Consider a surface element on the sphere’s surface with vectorial legs dφ∂/∂φ and
dθ∂/∂θ. Evaluate the components dj of the surface integration element d =
ϵ(. . . , dθ∂/∂θ, dφ∂/∂φ). (Here ϵ is the Levi-Civita tensor.) Similarly, evaluate dV
in terms of vectorial legs in the sphere’s interior. Then use these results for dj and
dV to convert Eq. (24.47) into an explicit form in terms of integrals over r, θ, and φ.
The ﬁnal answer should be obvious, but the above steps in deriving it are informative.
24.4
24.4 The Stress-Energy Tensor Revisited
In Sec. 2.13.1, we deﬁned the stress-energy tensor TTT of any matter or ﬁeld as a
symmetric, second-rank tensor that describes the ﬂow of 4-momentum through
spacetime. More speciﬁcally, the total 4-momentum ⃗P that ﬂows through some small
3-volume ⃗ (deﬁned in Sec. 2.12.1), going from the negative side of ⃗ to its positive
side, is
stress-energy tensor
TTT(
, ⃗) = (total 4-momentum ⃗P that ﬂows through ⃗);
T αββ = P α
(24.48)
[Eq. (2.66)]. Of course, this stress-energy tensor depends on the location P of the
3-volume in spacetime [i.e., it is a tensor ﬁeld TTT(P)].
From this geometric, frame-independent deﬁnition of the stress-energy tensor,
we were able to read off the physical meaning of its components in any inertial
reference frame [Eqs. (2.67)]: T 00 is the total energy density, including rest mass-
energy; T j0 = T 0j is the j-component of momentum density, or equivalently, the
j-component of energy ﬂux; and T jk are the components of the stress tensor, or
equivalently, of the momentum ﬂux.
In Sec. 2.13.2, we formulated the law of conservation of 4-momentum in a local
form and a global form. The local form,
local form of 4-momentum
conservation
⃗∇. TTT = 0,
(24.49)
says that, in any chosen Lorentz frame, the time derivative of the energy density plus
the divergence of the energy ﬂux vanishes, ∂T 00/∂t + ∂T 0j/∂xj = 0, and similarly
1176
Chapter 24. From Special to General Relativity

for the momentum, ∂T j0/∂t + ∂T jk/∂xk = 0. The global form,

∂V T αβdβ = 0
[Eq. (2.71)], says that all the 4-momentum that enters a closed 4-volume V in space-
timethroughitsboundary∂V inthepastmustultimatelyexitthrough∂V inthefuture
(Fig. 2.11). Unfortunately, this global form requires transporting vectorial contribu-
tions T αβdβ to a common location and adding them, which cannot be done in a
route-independent way in curved spacetime (see the end of Sec. 24.3.4). Therefore (as
we shall discuss in greater detail in Secs. 25.7 and 25.9.4), the global conservation law
becomes problematic in curved spacetime.
The stress-energy tensor and local 4-momentum conservation play major roles in
our development of general relativity. Almost all of our examples will entail perfect
ﬂuids.
Recall [Eq. (2.74a)] that in the local rest frame of a perfect ﬂuid, there is no
energy ﬂux or momentum density, T j0 = T 0j = 0, but there is a total energy density
(including rest mass) ρ and an isotropic pressure P :
T 00 = ρ,
T jk = P δjk.
(24.50)
FromthisspecialformofT αβ intheﬂuid’slocalrestframe, onecanderiveageometric,
frame-independent expression for the ﬂuid’s stress-energy tensor TTT in terms of its 4-
velocity ⃗u, the metric tensor ggg, and the rest-frame energy density ρ and pressure P :
stress-energy tensor for a
perfect ﬂuid
TTT = (ρ + P)⃗u ⊗⃗u + P ggg;
T αβ = (ρ + P )uαuβ + P gαβ
(24.51)
[Eq. (2.74b)]; see Ex. 2.26. This expression for the stress-energy tensor of a perfect
ﬂuid is an example of a geometric, frame-independent description of physics.
The equations of relativistic ﬂuid dynamics for a perfect ﬂuid are obtained by
inserting the stress-energy tensor (24.51) into the law of 4-momentum conservation
⃗∇. TTT = 0, and augmenting with the law of rest-mass conservation. We explored this
in brief in Ex. 2.26, and in much greater detail in Sec. 13.8. Applications that we have
explored are the relativistic Bernoulli equation and ultrarelativistic jets (Sec. 13.8.2)
and relativistic shocks (Ex. 17.9). In Sec. 13.8.3, we explored in detail the slightly subtle
wayinwhichaﬂuid’snonrelativisticenergydensity, energyﬂux, andstresstensorarise
from the relativistic perfect-ﬂuid stress-energy tensor (24.51).
These issues for a perfect ﬂuid are so important that readers are encouraged
to review them (except possibly the applications) in preparation for our foray into
general relativity.
Four other examples of the stress-energy tensor are those for the electromagnetic
ﬁeld (Ex. 2.28), for a kinetic-theory swarm of relativistic particles (Secs. 3.4.2 and
3.5.3), for a point particle (Box 24.2), and for a relativistic ﬂuid with viscosity and
diffusive heat conduction (Ex. 24.13). However, we shall not do much with any of
these during our study of general relativity, except viscosity and heat conduction in
Sec. 28.5.
24.4 The Stress-Energy Tensor Revisited
1177

BOX 24.2.
STRESS-ENERGY TENSOR FOR A POINT PARTICLE
For a point particle that moves through spacetime along a world line P(ζ)
[where ζ is the afﬁne parameter such that the particle’s 4-momentum is
⃗p = d/dζ, Eq. (2.14)], the stress-energy tensor vanishes everywhere except
on the world line itself. Correspondingly, TTT must be expressed in terms of a
Dirac delta function. The relevant delta function is a scalar function of two
points in spacetime, δ(Q, P), with the property that when one integrates
over the point P, using the 4-dimensional volume element d (which in any
inertial frame just reduces to d = dtdxdydz), one obtains

V
f (P)δ(Q, P)d = f (Q).
(1)
Here f (P) is an arbitrary scalar ﬁeld, and the region V of 4-dimensional
integration must include the point Q. One can easily verify that in terms of
Lorentz coordinates this delta function can be expressed as
δ(Q, P) = δ(tQ −tP)δ(xQ −xP)δ(yQ −yP)δ(zQ −zP),
(2)
where the deltas on the right-hand side are ordinary 1-dimensional Dirac
delta functions. [Proof: Simply insert Eq. (2) into Eq. (1), replace d by
dtQdxQdyQdzQ, and perform the four integrations.]
The general deﬁnition (24.48) of the stress-energy tensor TTT implies that
the integral of a point particle’s stress-energy tensor over any 3-surface S that
slices through the particle’s world line just once, at an event P(ζo), must be
equal to the particle’s 4-momentum at the intersection point:

S
T αβdβ = pα(ζo).
(3)
It is a straightforward but sophisticated exercise (Ex. 24.12) to verify that the
following frame-independent expression has this property:
TTT(Q) =
 +∞
−∞
⃗p(ζ) ⊗⃗p(ζ) δ[Q, P(ζ)]dζ .
(4)
Here the integral is along the world line P(ζ) of the particle, and Q is the
point at which TTT is being evaluated. Therefore, Eq. (4) is the point-particle
stress-energy tensor.
1178
Chapter 24. From Special to General Relativity

EXERCISES
Exercise 24.12 Derivation: Stress-Energy Tensor for a Point Particle
Show that the point-particle stress-energy tensor (4) of Box 24.2 satisﬁes that box’s
Eq. (3), as claimed.
Exercise 24.13 Example: Stress-Energy Tensor for a Viscous Fluid
with Diffusive Heat Conduction
This exercise serves two roles: It develops the relativistic stress-energy tensor for a
viscous ﬂuid with diffusive heat conduction, and in the process it allows the reader to
gain practice in index gymnastics.
In our study of elasticity theory, we introduced the concept of the irreducible
tensorial parts of a second-rank tensor in Euclidean space (Box 11.2). Consider a
relativisticﬂuidﬂowingthroughspacetimewitha4-velocity ⃗u(P).Theﬂuid’sgradient
⃗∇⃗u (uα;β in slot-naming index notation) is a second-rank tensor in spacetime. With
the aid of the 4-velocity itself, we can break it down into irreducible tensorial parts as
follows:
uα;β = −aαuβ + 1
3θPαβ + σαβ + ωαβ.
(24.52)
Here: (i)
Pαβ ≡gαβ + uαuβ
(24.53)
isatensorthatprojectsvectorsintothe3-spaceorthogonalto ⃗u(itcanalsoberegarded
as that 3-space’s metric; see Ex. 2.10); (ii) σαβ is symmetric, trace-free, and orthogonal
to the 4-velocity; and (iii) ωαβ is antisymmetric and orthogonal to the 4-velocity.
(a) Show that the rate of change of ⃗u along itself, ∇⃗u⃗u (i.e., the ﬂuid 4-acceleration)
is equal to the vector ⃗a that appears in the decomposition (24.52). Show, further,
that ⃗a . ⃗u = 0.
(b) Show that the divergence of the 4-velocity, ∇. ⃗u, is equal to the scalar ﬁeld θ that
appears in the decomposition (24.52). As we shall see in part (d), this is the ﬂuid’s
rate of expansion.
(c) The quantities σαβ and ωαβ are the relativistic versions of a Newtonian ﬂuid’s
shear and rotation tensors, which we introduced in Sec. 13.7.1. Derive equations
for these tensors in terms of uα;β and Pμν.
(d) Show that, as viewed in a Lorentz reference frame where the ﬂuid is moving with
speed small compared to the speed of light, to ﬁrst order in the ﬂuid’s ordinary
velocity vj = dxj/dt, the following statements are true: (i) u0 = 1, uj = vj; (ii) θ
isthenonrelativisticrateofexpansionoftheﬂuid, θ = ∇. v ≡vj ,j [Eq.(13.67a)];
(iii) σjk is the ﬂuid’s nonrelativistic shear [Eq. (13.67b)]; and (iv) ωjk is the ﬂuid’s
nonrelativistic rotation tensor [denoted rij in Eq. (13.67c)].
(e) At some event P where we want to know the inﬂuence of viscosity on the ﬂuid’s
stress-energy tensor, introduce the ﬂuid’s local rest frame. Explain why, in that
24.4 The Stress-Energy Tensor Revisited
1179

frame, the only contributions of viscosity to the components of the stress-energy
tensor are T jk
visc = −ζθgjk −2μσ jk, where ζ and μ are the coefﬁcients of bulk
and shear viscosity, respectively; the contributions to T 00 and T j0 = T 0j vanish.
[Hint: See Eq. (13.73) and associated discussions.]
(f) From nonrelativistic ﬂuid mechanics, infer that, in the ﬂuid’s rest frame at P,
the only contributions of diffusive heat conductivity to the stress-energy tensor
are T 0j
cond = T j0
cond = −κ∂T /∂xj, where κ is the ﬂuid’s thermal conductivity and
T is its temperature. [Hint: See Eq. (13.74) and associated discussion.] Actually,
this expression is not fully correct. If the ﬂuid is accelerating, there is a correction
term: ∂T /∂xj gets replaced by ∂T /∂xj + ajT , where aj is the acceleration. After
reading Sec. 24.5 and especially Ex. 24.16, explain this correction.
(g) Using the results of parts (e) and (f), deduce the following geometric, frame-
invariant form of the ﬂuid’s stress-energy tensor:
Tαβ = (ρ +P)uαuβ +P gαβ −ζθgαβ −2μσαβ −2κu(αPβ)
μ(T;μ + aμT ).(24.54)
Here the subscript parentheses in the last term mean to symmetrize in the α and
β slots.
From the divergence of this stress-energy tensor, plus the ﬁrst law of thermo-
dynamics and the law of rest-mass conservation, one can derive the full theory of
relativistic ﬂuid mechanics for a ﬂuid with viscosity and heat ﬂow (see, e.g., Misner,
Thorne, and Wheeler, 1973, Ex. 22.7). This particular formulation of the theory, in-
cluding Eq. (24.54), is due to Carl Eckart (1940). Landau and Lifshitz (1959) have
given a slightly different formulation. For discussion of the differences, and of causal
difﬁculties with both formulations and the difﬁculties’ repair, see, for example, the
reviews by Israel and Stewart (1980), Andersson and Comer (2007, Sec. 14), and
L´opez-Monsalvo (2011, Sec. 4).
24.5
24.5 The Proper Reference Frame of an Accelerated Observer
Physics experiments and astronomical measurements almost always use an apparatus
that accelerates and rotates. For example, if the apparatus is in an Earthbound labo-
ratory and is attached to the laboratory ﬂoor and walls, then it accelerates upward
(relative to freely falling particles) with the negative of the “acceleration of gravity,”
and it rotates (relative to inertial gyroscopes) because of the rotation of Earth. It is use-
ful, in studying such an apparatus, to regard it as attached to an accelerating, rotating
reference frame. As preparation for studying such reference frames in the presence
of gravity, we study them in ﬂat spacetime. For a somewhat more sophisticated treat-
ment, see Misner, Thorne, and Wheeler (1973, pp. 163–176, 327–332).
Consider an observer with 4-velocity ⃗U, who moves along an accelerated world
line through ﬂat spacetime (Fig. 24.6) so she has a nonzero 4-acceleration:
⃗a = ⃗∇⃗U ⃗U.
(24.55)
1180
Chapter 24. From Special to General Relativity

x
y
observer’s world line
x0ˆ = const
x0ˆ = const
t
→eŷ
→eŷ
→e0ˆ
→exˆ
→exˆ
FIGURE 24.6 The proper reference frame of an accelerated observer. The spatial basis vectors ⃗eˆx,
⃗e ˆy, and ⃗eˆz are orthogonal to the observer’s world line and rotate, relative to local gyroscopes,
as they move along the world line. The ﬂat 3-planes spanned by these basis vectors are surfaces
of constant coordinate time xˆ0 ≡(proper time as measured by the observer’s clock at the event
where the 3-plane intersects the observer’s world line); in other words, they are the observer’s
slices of simultaneity and “3-space.” In each of these ﬂat 3-planes the spatial coordinates {ˆx,
ˆy, ˆz} are Cartesian, with ∂/∂ˆx = ⃗eˆx, ∂/∂ˆy = ⃗e ˆy, and ∂/∂ˆz = ⃗eˆz.
Have that observer construct, in the vicinity of her world line, a coordinate system
proper reference frame of
an accelerated observer
{x ˆα} (called her proper reference frame) with these properties: (i) The spatial origin
is centered on her world line at all times (i.e., her world line is given by x ˆj = 0).
(ii) Along her world line, the time coordinate x ˆ0 is the same as the proper time ticked
by an ideal clock that she carries. (iii) In the immediate vicinity of her world line, the
spatial coordinates x ˆj measure physical distance along the axes of a little Cartesian
latticework that she carries (and that she regards as purely spatial, which means it
lies in the 3-plane orthogonal to her world line). These properties dictate that, in
the immediate vicinity of her world line, the metric has the form ds2 = ηˆα ˆβdx ˆαdx ˆβ,
where ηˆα ˆβ are the Lorentz-basis metric coefﬁcients, Eq. (24.6); in other words, all
along her world line the coordinate basis vectors are orthonormal:
gˆα ˆβ =
∂
∂x ˆα .
∂
∂x ˆβ = ηˆα ˆβ
at x ˆj = 0.
(24.56)
Moreover, properties (i) and (ii) dictate that along the observer’s world line, the basis
vector ⃗eˆ0 ≡∂/∂x ˆ0 differentiates with respect to her proper time, and thus is identically
equal to her 4-velocity ⃗U:
⃗eˆ0 =
∂
∂x ˆ0 = ⃗U.
(24.57)
rotating and nonrotating
proper reference frames
There remains freedom as to how the observer’s latticework is oriented spatially.
The observer can lock it to the gyroscopes of an inertial-guidance system that she
carries (Box 24.3), in which case we say that it is “nonrotating”; or she can rotate it
relative to such gyroscopes. For generality, we assume that the latticework rotates.
24.5 The Proper Reference Frame of an Accelerated Observer
1181

BOX 24.3.
INERTIAL GUIDANCE SYSTEMS
Aircraft and rockets often carry inertial guidance systems, which consist of
an accelerometer and a set of gyroscopes.
The accelerometer measures the system’s 4-acceleration ⃗a (in relativistic
language). Equivalently, it measures the system’s Newtonian 3-acceleration a
relative to inertial coordinates in which the system is momentarily at rest. As
we see in Eq. (24.58), these quantities are two different ways of thinking about
the same thing.
Each gyroscope is constrained to remain at rest in the aircraft or rocket
by a force that is applied at its center of mass. Such a force exerts no torque
around the center of mass, so the gyroscope maintains its direction (does not
precess) relative to an inertial frame in which it is momentarily at rest.
As the accelerating aircraft or rocket turns, its walls rotate with some
angular velocity ⃗ relative to these inertial-guidance gyroscopes. This is the
angular velocity discussed in the text between Eqs. (24.57) and (24.58).
From the time-evolving 4-acceleration ⃗a(τ) and angular velocity ⃗(τ), a
computer can calculate the aircraft’s (or rocket’s) world line and its changing
orientation.
Its angular velocity, as measured by the observer (by comparing the latticework’s
orientation with inertial-guidance gyroscopes), is a 3-dimensional spatial vector  in
the 3-plane orthogonal to her world line; and as viewed in 4-dimensional spacetime,
it is a 4-vector ⃗ whose components in the observer’s reference frame are  ˆj ̸= 0 and
ˆ0 = 0. Similarly, the latticework’s acceleration, as measured by an inertial-guidance
accelerometer attached to it (Box 24.3), is a 3-dimensional spatial vector a that can be
thought of as a 4-vector with components in the observer’s frame:
aˆ0 = 0,
a ˆj = ( ˆj-component of the measured a).
(24.58)
This 4-vector is the observer’s 4-acceleration, as one can verify by computing the
4-acceleration in an inertial frame in which the observer is momentarily at rest.
constructing coordinates
of proper reference frame
Geometrically, the coordinates of the proper reference frame are constructed as
follows. Begin with the basis vectors ⃗eˆα along the observer’s world line (Fig. 24.6)—
basis vectors that satisfy Eqs. (24.56) and (24.57), and that rotate with angular velocity
⃗ relative to gyroscopes. Through the observer’s world line at time x ˆ0 construct the
ﬂat 3-plane spanned by the spatial basis vectors ⃗e ˆj. Because ⃗e ˆj . ⃗eˆ0 = 0, this 3-plane
is orthogonal to the world line. All events in this 3-plane are given the same value of
coordinate time x ˆ0 as the event where it intersects the world line; thus the 3-plane is
a surface of constant coordinate time x ˆ0. The spatial coordinates in this ﬂat 3-plane
are ordinary, Cartesian coordinates x ˆj with ⃗e ˆj = ∂/∂x ˆj.
1182
Chapter 24. From Special to General Relativity

24.5.1
24.5.1 Relation to Inertial Coordinates; Metric in Proper Reference Frame;
Transport Law for Rotating Vectors
It is instructive to examine the coordinate transformation between these proper-
reference-frame coordinates x ˆα and the coordinates xμ of an inertial reference frame.
We pick a very special inertial frame for this purpose. Choose an event on the ob-
server’s world line, near which the coordinate transformation is to be constructed;
adjust the origin of the observer’s proper time, so this event is x ˆ0 = 0 (and of course
x ˆj = 0); and choose the inertial frame to be one that, arbitrarily near this event,
coincides with the observer’s proper reference frame. If we were doing Newtonian
physics, then the coordinate transformation from the proper reference frame to the
inertial frame would have the form (accurate through terms quadratic in x ˆα):
xi = xˆi + 1
2aˆi(x ˆ0)2 + ϵˆi
ˆj ˆk ˆjx ˆkx ˆ0,
x0 = x ˆ0.
(24.59)
Here the term 1
2aˆi(x ˆ0)2 is the standard expression for the vectorial displacement pro-
duced after time x ˆ0 by the acceleration aˆi; and the term ϵˆi
ˆj ˆk ˆjx ˆkx ˆ0 is the standard
expression for the displacement produced by the rotation rate (rotational angular ve-
locity)  ˆj during a short time x ˆ0. In relativity theory there is only one departure from
these familiar expressions (up through quadratic order): after time x ˆ0 the acceleration
has produced a velocity v ˆj = a ˆjx ˆ0 of the proper reference frame relative to the iner-
tial frame; correspondingly, there is a Lorentz-boost correction to the transformation
of time: x0 = x ˆ0 + v ˆjx ˆj = x ˆ0(1 + a ˆjx ˆj) [cf. Eq. (2.37c)], accurate only to quadratic
order. Thus, the full transformation to quadratic order is
inertial coordinates
related to those of the
proper reference frame of
an accelerated, rotating
observer
xi = xˆi + 1
2aˆi(x ˆ0)2 + ϵˆi
ˆj ˆk ˆjx ˆkx ˆ0,
x0 = x ˆ0(1 + a ˆjx ˆj).
(24.60a)
From this transformation and the form of the metric, ds2 = −(dx0)2 + δijdxidxj
in the inertial frame, we easily can evaluate the form of the metric, accurate to linear
order in x, in the proper reference frame:
metric in proper reference
frame of an accelerated,
rotating observer
ds2 = −(1 + 2a . x)(dx ˆ0)2 + 2( × x) . dx dx ˆ0 + δjkdx ˆjdx ˆk
(24.60b)
(Ex. 24.14a). Here the notation is that of 3-dimensional vector analysis, with x the
3-vector whose components are x ˆj, dx that with components dx ˆj, a that with com-
ponents a ˆj, and  that with components  ˆj.
Because the transformation (24.60a) was constructed near an arbitrary event on
the observer’s world line, the metric (24.60b) is valid near any and every event on the
world line (i.e., it is valid all along the world line). In fact, it is the leading order in an
expansion in powers of the spatial separation x ˆj from the world line. For higher-order
terms in this expansion see, for example, Ni and Zimmermann (1978).
24.5 The Proper Reference Frame of an Accelerated Observer
1183

Notice that precisely on the observer’s world line, the metric coefﬁcients gˆα ˆβ [the
coefﬁcients of dx ˆαdx ˆβ in Eq. (24.60b)] are gˆα ˆβ = ηˆα ˆβ, in accord with Eq. (24.56).
However, as one moves farther away from the observer’s world line, the effects of
the acceleration a ˆj and rotation  ˆj cause the metric coefﬁcients to deviate more and
more strongly from ηˆα ˆβ.
From the metric coefﬁcients of Eq. (24.60b), one can compute the connection
coefﬁcients  ˆα ˆβ ˆγ on the observer’s world line, and from these connection coefﬁcients,
one can infer the rates of change of the basis vectors along the world line: ∇⃗U ⃗eˆα =
∇ˆ0⃗eˆα =  ˆμ
ˆαˆ0⃗e ˆμ. The result is (Ex. 24.14b):
equations for transport
of proper reference
frame’s basis vectors along
observer’s world line
∇⃗U ⃗eˆ0 ≡∇⃗U ⃗U = ⃗a,
(24.61a)
∇⃗U ⃗e ˆj = (⃗a . ⃗e ˆj) ⃗U + ϵ( ⃗U , ⃗, ⃗e ˆj,
).
(24.61b)
Equation (24.61b) is the general “law of transport” for constant-length vectors
that are orthogonal to the observer’s world line and that the observer thus sees as
purely spatial. For the spin vector ⃗S of an inertial-guidance gyroscope (Box 24.3), the
transport law is Eq. (24.61b) with ⃗e ˆj replaced by ⃗S and with ⃗ = 0:
Fermi-Walker transport
for the spin of an inertial-
guidance gyroscope
∇⃗U ⃗S = ⃗U(⃗a . ⃗S).
(24.62)
ThisiscalledFermi-Walkertransport.Thetermontheright-handsideofthistransport
law is required to keep the spin vector always orthogonal to the observer’s 4-velocity:
∇⃗U(⃗S . ⃗U) = 0. For any other vector ⃗A that rotates relative to inertial-guidance gyro-
scopes, the transport law has, in addition to this “keep-it-orthogonal-to ⃗U” term, a
second term, which is the 4-vector form of dA/dt =  × A:
transport law for a vector
that is orthogonal to
observer’s 4-velocity
and rotates relative to
gyroscopes
∇⃗U ⃗A = ⃗U(⃗a . ⃗A) + ϵ( ⃗U , ⃗, ⃗A,
).
(24.63)
Equation (24.61b) is this general transport law with ⃗A replaced by ⃗e ˆj.
24.5.2
24.5.2 Geodesic Equation for a Freely Falling Particle
Consider a particle with 4-velocity ⃗u that moves freely through the neighborhood of
an accelerated observer. As seen in an inertial reference frame, the particle travels
through spacetime on a straight line, also called a geodesic of ﬂat spacetime. Corre-
spondingly, a geometric, frame-independent version of its geodesic law of motion is
geodesic law of motion for
freely falling particle
∇⃗u⃗u = 0
(24.64)
(i.e., theparticleparalleltransportsits4-velocity ⃗ualong ⃗u).Itisinstructivetoexamine
the component form of this geodesic equation in the proper reference frame of the
observer. Since the components of ⃗u in this frame are uα = dxα/dτ, where τ is the
particle’s proper time (not the observer’s proper time), the components uˆα; ˆμu ˆμ = 0 of
the geodesic equation (24.64) are
1184
Chapter 24. From Special to General Relativity

uˆα
, ˆμu ˆμ +  ˆα
ˆμˆνu ˆμuˆν =
*
∂
∂x ˆμ
dx ˆα
dτ
+
dx ˆμ
dτ +  ˆα
ˆμˆνu ˆμuˆν = 0;
(24.65)
or equivalently,
d2x ˆα
dτ 2 +  ˆα
ˆμˆν
dx ˆμ
dτ
dx ˆν
dτ = 0.
(24.66)
Suppose, for simplicity, that the particle is moving slowly relative to the observer, so its
ordinaryvelocityv ˆj = dx ˆj/dx ˆ0 isnearlyequaltou ˆj = dx ˆj/dτ andissmallcompared
to unity (the speed of light), and uˆ0 = dx ˆ0/dτ is nearly unity. Then to ﬁrst order in
the ordinary velocity v ˆj, the spatial part of the geodesic equation (24.66) becomes
d2xˆi
(dx ˆ0)2 = −ˆi
ˆ0ˆ0 −(ˆi
ˆj ˆ0 + ˆi
ˆ0 ˆj)v ˆj.
(24.67)
By computing the connection coefﬁcients from the metric coefﬁcients of Eq. (24.60b)
(Ex. 24.14), we bring this low-velocity geodesic law of motion into the form
geodesic equation for
slowly moving particle in
proper reference frame
of accelerated, rotating
observer
d2xˆi
(dx ˆ0)2 = −aˆi −2ϵˆi
ˆj ˆk ˆjv ˆk,
that is,
d2x
(dx ˆ0)2 = −a −2 × v.
(24.68)
This is the standard nonrelativistic form of the law of motion for a free particle as
seen in a rotating, accelerating reference frame. The ﬁrst term on the right-hand side
is the inertial acceleration due to the failure of the frame to fall freely, and the second
term is the Coriolis acceleration due to the frame’s rotation. There would also be a
centrifugal acceleration if we had kept terms of higher order in distance away from
the observer’s world line, but this acceleration has been lost due to our linearizing the
metric (24.60b) in that distance.
This analysis shows how the elegant formalism of tensor analysis gives rise to
familiar physics. In the next few chapters we will see it give rise to less familiar, general
relativistic phenomena.
EXERCISES
Exercise 24.14 Derivation: Proper Reference Frame
(a) Show that the coordinate transformation (24.60a) brings the metric ds2 =
ηαβdxαdxβ into the form of Eq. (24.60b), accurate to linear order in separation
x ˆj from the origin of coordinates.
(b) Compute the connection coefﬁcients for the coordinate basis of Eq.
(24.60b) at an arbitrary event on the observer’s world line. Do so ﬁrst by hand
calculations, and then verify your results using symbolic-manipulation software
on a computer.
(c) Using the connection coefﬁcients from part (b), show that the rate of change of
the basis vectors eˆα along the observer’s world line is given by Eq. (24.61).
24.5 The Proper Reference Frame of an Accelerated Observer
1185

(d) Using the connection coefﬁcients from part (b), show that the low-velocity limit
of the geodesic equation [Eq. (24.67)] is given by Eq. (24.68).
24.5.3
24.5.3 Uniformly Accelerated Observer
As an important example (cf. Ex. 2.16), consider an observer whose accelerated world
transformation between
inertial coordinates and
uniformly accelerated
coordinates
line, written in some inertial (Lorentz) coordinate system {t, x, y, z}, is
t = (1/κ) sinh(κτ),
x = (1/κ) cosh(κτ),
y = z = 0.
(24.69)
Here τ is proper time along the world line, and κ is the magnitude of the observer’s
4-acceleration: κ = |⃗a| (which is constant along the world line; see Ex. 24.15, where
the reader can derive the various claims made in this subsection and the next).
The world line (24.69) is depicted in Fig. 24.7 as a thick, solid hyperbola that
asymptotes to the past light cone at early times and to the future light cone at
late times. The dots along the world line mark events that have proper times τ =
−1.2, −0.9, −0.6, −0.3, 0.0, +0.3, +0.6, +0.9, +1.2 (in units of 1/κ). At each of
these dots, the 3-plane orthogonal to the world line is represented by a dashed line
(with the 2 dimensions out of the plane of the paper suppressed from the diagram).
This 3-plane is labeled by its coordinate time x ˆ0, which is equal to the proper time
of the dot. The basis vector ⃗eˆ1 is chosen to point along the observer’s 4-acceleration,
so ⃗a = κ⃗eˆ1. The coordinate xˆ1 measures proper distance along the straight line that
starts out tangent to ⃗eˆ1. The other two basis vectors ⃗eˆ2 and ⃗eˆ3 point out of the plane
of the ﬁgure and are parallel transported along the world line: ∇⃗U ⃗eˆ2 = ∇⃗U ⃗eˆ3 = 0. In
addition, xˆ2 and xˆ3 are measured along straight lines, in the orthogonal 3-plane, that
start out tangent to these vectors. This construction implies that the resulting proper
reference frame has vanishing rotation, ⃗ = 0 (Ex. 24.15), and that xˆ2 = y and xˆ3 = z,
where y and z are coordinates in the {t, x, y, z} Lorentz frame that we used to deﬁne
the world line [Eqs. (24.69)].
Usually, when constructing an observer’s proper reference frame, one conﬁnes
attention to the immediate vicinity of her world line. However, in this special case it is
instructive to extend the construction (the orthogonal 3-planes and their resulting
spacetime coordinates) outward arbitrarily far. By doing so, we discover that the
3-planes all cross at location xˆ1 = −1/κ, which means the coordinate system {x ˆα}
singularity of uniformly
accelerated coordinates
becomes singular there. This singularity shows up in a vanishing gˆ0ˆ0(xˆ1 = −1/κ) for
the spacetime metric, written in that coordinate system:
spacetime metric in
uniformly accelerated
coordinates
ds2 = −(1 + κxˆ1)2(dx ˆ0)2 + (dxˆ1)2 + (dxˆ2)2 + (dxˆ3)2.
(24.70)
[Note that for |xˆ1| ≪1/κ this metric agrees with the general proper-reference-frame
metric (24.60b).] From Fig. 24.7, it should be clear that this coordinate system can
only cover smoothly one quadrant of Minkowski spacetime: the quadrant x > |t|.
1186
Chapter 24. From Special to General Relativity

x
x0ˆ = 1.2
x1ˆ = –1
x0ˆ = –1
x1ˆ = –1
x1ˆ = 0.5
x1ˆ = 0
x0ˆ = 1
x0ˆ = 0.9
x0ˆ = 0.6
x0ˆ = 0.3
x0ˆ = 0
x0ˆ = –0.3
x0ˆ = –0.6
x0ˆ = –0.9
x0ˆ = –1.2
2
1
0
–1
–2
0.5
1.0
2.0
1.5
t
x1ˆ = –0.5
FIGURE 24.7 The proper reference frame of a uniformly accelerated observer. All
lengths and times are measured in units of 1/κ. We show only 2 dimensions of
the reference frame—those in the 2-plane of the observer’s curved world line.
24.5.4
24.5.4 Rindler Coordinates for Minkowski Spacetime
The spacetime metric (24.70) in our observer’s proper reference frame resembles the
metric in the vicinity of a black hole, as expressed in coordinates of observers who
accelerate so as to avoid falling into the hole. In preparation for discussing this in
24.5 The Proper Reference Frame of an Accelerated Observer
1187

Chap. 26, we shift the origin of our proper-reference-frame coordinates to the singular
point and rename them. Speciﬁcally, we introduce so-called Rindler coordinates:
Rindler coordinates
t′ = x ˆ0,
x′ = xˆ1 + 1/κ,
y′ = xˆ2,
z′ = xˆ3.
(24.71)
It turns out (Ex. 24.15) that these coordinates are related to the Lorentz coordinates
that we began with, in Eqs. (24.69), by
t = x′ sinh(κt′),
x = x′ cosh(κt′),
y = y′,
z = z′.
(24.72)
The metric in this Rindler coordinate system, of course, is the same as (24.70) with
displacement of the origin:
spacetime metric in
Rindler coordinates
ds2 = −(κx′)2dt′2 + dx′2 + dy′2 + dz′2.
(24.73)
The world lines of constant {x′, y′, z′} have uniform acceleration: ⃗a = (1/x′)⃗ex′.
Thus we can think of these coordinates as the reference frame of a family of uniformly
accelerated observers, each of whom accelerates away from their horizon x′ = 0 with
horizon of Rindler
coordinates
acceleration equal to 1/(her distance x′ above the horizon). (We use the name “hori-
zon” for x′ = 0, because it represents the edge of the region of spacetime that these
observers are able to observe.) The local 3-planes orthogonal to these observers’ world
lines all mesh to form global 3-planes of constant t′. This is a major factor in making
the metric (24.73) so simple.
EXERCISES
Exercise 24.15 Derivation: Uniformly Accelerated Observer and Rindler Coordinates
In this exercise you will derive the various claims made in Secs. 24.5.3 and 24.5.4.
(a) Show that the parameter τ along the world line (24.69) is proper time and that
the 4-acceleration has magnitude |⃗a]= 1/κ.
(b) Show that the unit vectors ⃗e ˆj introduced in Sec. 24.5.3 all obey the Fermi-Walker
transport law (24.62) and therefore, by virtue of Eq. (24.61b), the proper reference
frame built from them has vanishing rotation rate: ⃗ = 0.
(c) Show that the coordinates xˆ2 and xˆ3 introduced in Sec. 24.5.3 are equal to the y
and z coordinates of the inertial frame used to deﬁne the observer’s world line
[Eqs. (24.69)].
(d) Show that the proper-reference-frame coordinates constructed in Sec. 24.5.3 are
related to the original {t, x, y, z} coordinates by
t = (xˆ1 + 1/κ) sinh(κx ˆ0),
x = (xˆ1 + 1/κ) cosh(κx ˆ0),
y = xˆ2,
z = xˆ3;
(24.74)
and from this, deduce the form (24.70) of the Minkowski spacetime metric in the
observer’s proper reference frame.
1188
Chapter 24. From Special to General Relativity

(e) Show that, when converted to Rindler coordinates by moving the spatial origin,
the coordinate transformation (24.74) becomes (24.72), and the metric (24.70)
becomes (24.73).
(f) Show that observers at rest in the Rindler coordinate system (i.e., who move along
world lines of constant {x′, y′, z′}) have 4-acceleration ⃗a = (1/x′)⃗ex′.
Exercise 24.16 Example: Gravitational Redshift
Inside a laboratory on Earth’s surface the effects of spacetime curvature are so small
that current technology cannot measure them. Therefore, experiments performed
in the laboratory can be analyzed using special relativity. (This fact is embodied in
Einstein’s equivalence principle; end of Sec. 25.2.)
(a) Explainwhythespacetimemetricintheproperreferenceframeofthelaboratory’s
ﬂoor has the form
ds2 = (1 + 2gz)(dx ˆ0)2 + dx2 + dy2 + dz2,
(24.75)
plus terms due to the slow rotation of the laboratory walls, which we neglect in
this exercise. Here g is the acceleration of gravity measured on the ﬂoor.
(b) An electromagnetic wave is emitted from the ﬂoor, where it is measured to have
wavelength λo, and is received at the ceiling. Using the metric (24.75), show that,
as measured in the proper reference frame of an observer on the ceiling, the
received wave has wavelength λr = λo(1+ gh), where h is the height of the ceiling
above the ﬂoor (i.e., the light is gravitationally redshifted by λ/λo = gh). [Hint:
Show that all crests of the wave must travel along world lines that have the same
shape, z = F(x ˆ0 −x ˆ0
e), where F is some function, and x ˆ0
e is the coordinate time
at which the crest is emitted from the ﬂoor. You can compute the shape function
F if you wish, but it is not needed to derive the gravitational redshift; only its
universality is needed.]
The ﬁrst high-precision experiments to test this prediction were by Robert
Pound and his student Glen Rebka and postdoc Joseph Snider, in a tower at
Harvard University in the 1950s and 1960s. They achieved 1% accuracy. We
discuss this gravitational redshift in Sec. 27.2.1.
Exercise 24.17 Example: Rigidly Rotating Disk
Consider a thin disk with radius R at z = 0 in a Lorentz reference frame. The disk
rotates rigidly with angular velocity . In the early years of special relativity there was
much confusion over the geometry of the disk: In the inertial frame it has physical
radius (proper distance from center to edge) R and physical circumference C = 2πR.
But Lorentz contraction dictates that, as measured on the disk, the circumference
shouldbe
√
1 −v2 C (withv = R), andthephysicalradius, R, shouldbeunchanged.
This seemed weird. How could an obviously ﬂat disk in ﬂat spacetime have a curved,
24.5 The Proper Reference Frame of an Accelerated Observer
1189

non-Euclidean geometry, with physical circumference divided by physical radius
smaller than 2π? In this exercise you will explore this issue.
(a) Consider a family of observers who ride on the edge of the disk. Construct a
circular curve, orthogonal to their world lines, that travels around the disk (at

x2 + y2 = R). This curve can be thought of as lying in a 3-surface of constant
time xˆ0 of the observers’ proper reference frames. Show that it spirals upward
in a Lorentz-frame spacetime diagram, so it cannot close on itself after traveling
around the disk. Thus the 3-planes, orthogonal to the observers’ world lines at the
edge of the disk, cannot mesh globally to form global 3-planes (by contrast with
the case of the uniformly accelerated observers in Sec. 24.5.4 and Ex. 24.15).
(b) Next, consider a 2-dimensional family of observers who ride on the surface of the
rotating disk. Show that at each radius

x2 + y2 = const, the constant-radius
curve that is orthogonal to their world lines spirals upward in spacetime with
a different slope. Show this means that even locally, the 3-planes orthogonal to
each of their world lines cannot mesh to form larger 3-planes—thus there does
not reside in spacetime any 3-surface orthogonal to these observers’ world lines.
There is no 3-surface that has the claimed non-Euclidean geometry.
Bibliographic Note
Foraveryreadablepresentationofmostofthischapter’smaterial, frommuchthesame
point of view, see Hartle (2003, Chap. 20). For an equally elementary introduction
from a somewhat different viewpoint, see Schutz (2009, Chaps. 1–4). A far more
detailed and somewhat more sophisticated introduction, largely but not entirely from
our viewpoint, will be found in Misner, Thorne, and Wheeler (1973, Chaps. 1–6).
More sophisticated treatments from rather different viewpoints than ours are given in
Wald (1984, Chaps. 1, 2, and Sec. 3.1), and Carroll (2004, Chaps. 1, 2). A treasure trove
of exercises on this material, with solutions, is in Lightman et al. (1975, Chaps. 6–8).
See also the bibliography for Chap. 2.
For a detailed and sophisticated discussion of accelerated observers and the mea-
surements they make, see Gourgoulhon (2013).
1190
Chapter 24. From Special to General Relativity

25
CHAPTER TWENTY-FIVE
Fundamental Concepts of General Relativity
The physical world is represented as a four dimensional continuum. If in this I adopt a Riemannian
metric, and look for the simplest laws which such a metric can satisfy, I arrive at the relativistic
gravitation theory of empty space.
ALBERT EINSTEIN (1934)
25.1
25.1 History and Overview
Newton’s theory of gravity is logically incompatible with the special theory of rela-
tivity. Newtonian gravity presumes the existence of a universal, frame-independent
3-dimensional space in which lives the Newtonian potential  and a universal, frame-
independent time t with respect to which the propagation of  is instantaneous. By
contrast, special relativity insists that the concepts of time and of 3-dimensional space
are frame dependent, so that instantaneous propagation of  in one frame would
mean noninstantaneous propagation in another.
The most straightforward way to remedy this incompatibility is to retain the as-
sumption that gravity is described by a scalar ﬁeld  but modify Newton’s instanta-
neous, action-at-a-distance ﬁeld equation
 ∂2
∂x2 + ∂2
∂y2 + ∂2
∂z2

 = 4πGρ
(25.1)
(where G is Newton’s gravitation constant and ρ is the mass density) to read
 ≡gαβ;αβ = −4πGT μ
μ,
(25.2a)
where
≡⃗∇. ⃗∇is the squared gradient (i.e., d’alembertian or wave operator) in
Minkowski spacetime, and T μμ is the trace (i.e., contraction on its two slots) of
the stress-energy tensor. This modiﬁed ﬁeld equation at ﬁrst sight is attractive and
satisfactory (but see Ex. 25.1): (i) it satisﬁes Einstein’s Principle of Relativity in that it is
expressed as a geometric, frame-independent relationship among geometric objects;
and (ii) in any Lorentz frame it takes the form [with factors of c = (speed of light)
restored]:

−1
c2
∂2
∂t2 + ∂2
∂x2 + ∂2
∂y2 + ∂2
∂z2

 = 4πG
c2 (T 00 −T xx −T yy −T zz),
(25.2b)
which reduces to the Newtonian ﬁeld equation (25.1) in the kinds of situation contem-
plated by Newton [energy density predominantly due to rest-mass density, T 00 ∼= ρc2;
1191

BOX 25.1.
READERS’ GUIDE
.
This chapter relies signiﬁcantly on:
– Chap. 2 on special relativity; and
– Chap. 24 on the transition from special relativity to general
relativity.
.
This chapter is a foundation for the applications of general relativity
theory in Chaps. 26–28.
stress negligible compared to rest mass-energy density, |T jk| ≪ρc2; and 1/c × (time
rate of change of ) negligible compared to spatial gradient of ].
Not surprisingly, most theoretical physicists in the decade following Einstein’s for-
mulation of special relativity (1905–1915) presumed that gravity would be correctly
describable, in the framework of special relativity, by this type of modiﬁcation of
Newton’s theory, or something resembling it. For a brief historical account, see Pais
(1982, Chap. 13). To Einstein, by contrast, it seemed clear that the correct description
of gravity should involve a generalization of special relativity rather than an incorpo-
ration into special relativity: since an observer in a local, freely falling reference frame
near Earth should not feel any gravitational acceleration at all, local freely falling
frames (local inertial frames) should in some sense be the domain of special rela-
tivity, and gravity should somehow be described by the relative acceleration of such
key idea of general
relativity: gravity
described by relative
acceleration of local
inertial frames
frames.
Although the seeds of this idea were in Einstein’s mind as early as 1907 [see the
discussion of the equivalence principle in Einstein (1907)], it required 8 years for
him to bring them to fruition. A ﬁrst crucial step, which took half the 8 years, was
for Einstein to conquer his initial aversion to Minkowski’s geometric formulation
of special relativity and to realize that a curvature of Minkowski’s 4-dimensional
spacetime is the key to understanding the relative acceleration of freely falling frames.
Thesecondcrucialstepwastomasterthemathematicsofdifferentialgeometry, which
describes spacetime curvature, and using that mathematics, to formulate a logically
themathematicsofgeneral
relativity: differential
geometry in curved
spacetime
self-consistent theory of gravity. This second step took an additional 4 years and
culminated in Einstein’s (1915, 1916a) general theory of relativity. For a historical
account of Einstein’s 8-year struggle toward general relativity, see, for example, Pais
(1982, Part IV). For selected quotations from Einstein’s technical papers during this
8-year period, which tell the story of his struggle, see Misner, Thorne, and Wheeler
(1973, Sec. 17.7). For his papers themselves with scholarly annotations, see Einstein
(1989, vols. 2–4, 6).
It is remarkable that Einstein was led, not by experiment, but by philosophical
and aesthetic arguments, to reject the incorporation of gravity into special relativity
[Eqs. (25.2) and Ex. 25.1], and to insist instead on describing gravity by curved
1192
Chapter 25. Fundamental Concepts of General Relativity

spacetime. Only after the full formulation of his general relativity did experiments
begin to conﬁrm that he was right and that the advocates of special-relativistic gravity
were wrong, and only a half century after general relativity was formulated did the
experimental evidence become extensive and strong. For detailed discussions see, for
example, Will (1993a,b, 2014).
The mathematical tools, the diagrams, and the phrases by which we describe
general relativity have changed somewhat in the century since Einstein formulated
his theory. Indeed, we can even assert that we understand the theory more deeply
than did Einstein. However, the basic ideas are unchanged, and general relativity’s
claim to be the most elegant and aesthetic of physical theories has been reinforced
and strengthened by our growing insights.
general relativity as a
framework for all the laws
of physics
General relativity is not merely a theory of gravity. Like special relativity before it,
thegeneraltheoryisaframeworkinwhichtoformulateallthelawsofphysics, classical
and quantum—but now with gravity included. However, there is one remaining,
crucial, gaping hole in this framework. It is incapable of functioning—indeed, it fails
completely—when conditions become so extreme that space and time themselves
must be quantized. In those extreme conditions general relativity must be married
in some deep, as-yet-ill-understood way, with quantum theory, to produce an all-
inclusive quantum theory of gravity—a theory that, one may hope, will be a “theory
of everything.” To this we shall return, brieﬂy, in Chaps. 26 and 28.
In this chapter, we present, in modern language, the foundations of general rela-
tivity. Our presentation is proudly geometrical, as this seems to us the most power-
ful approach to general relativity for most situations. By contrast, some outstanding
physicists, particularly Weinberg (1972, especially his preface), prefer a ﬁeld-theoretic
approach. Our presentation relies heavily on the geometric concepts, viewpoint, and
formalism developed in Chaps. 2 and 24.
We begin in Sec. 25.2 with a discussion of three concepts that are crucial to Ein-
stein’s viewpoint on gravity: a local Lorentz frame (the closest thing there is, in the
presence of gravity, to special relativity’s “global” Lorentz frame), the extension of the
Principle of Relativity to deal with gravitational situations, and Einstein’s equivalence
principle by which one can “lift” laws of physics out of the ﬂat spacetime of special
relativity and into the curved spacetime of general relativity. In Sec. 25.3, we see how
gravity prevents the meshing of local Lorentz frames to form global Lorentz frames
and infer from this that spacetime must be curved. In Sec. 25.4, we lift into curved
spacetime the law of motion for free test particles, and in Sec. 25.5, we see how space-
time curvature pushes two freely moving test particles together or apart, and we use
this phenomenon to make contact between spacetime curvature and the Newtonian
“tidal gravitational ﬁeld” (gradient of the Newtonian gravitational acceleration). In
Sec. 25.6, we study some mathematical and geometric properties of the tensor ﬁeld
that embodies spacetime curvature: the Riemann tensor. In Sec. 25.7, we examine
“curvaturecouplingdelicacies”thatplaguetheliftingoflawsofphysicsfromﬂatspace-
time to curved spacetime. In Sec. 25.8, we meet the Einstein ﬁeld equation, which
25.1 History and Overview
1193

describes the manner in which spacetime curvature is produced by the total stress-
energy tensor of all matter and nongravitational ﬁelds. In Sec. 25.9.1, we examine in
some detail how Newton’s laws of gravity arise as a weak-gravity, slow-motion, low-
stress limit of general relativity. In Sec. 25.9.2, we develop an approximation to general
relativity called “linearized theory” that is valid when gravity is weak but speeds and
stresses may be high, and in Sec. 25.9.3, we use this approximation to deduce the
weak relativistic gravitational ﬁeld outside a stationary (unchanging) source. Finally,
in Secs. 25.9.4 and 25.9.5, we examine the conservation laws for energy, momentum,
and angular momentum of gravitating bodies that live in “asymptotically ﬂat” regions
of spacetime.
EXERCISES
Exercise 25.1 Example: A Special Relativistic, Scalar-Field Theory of Gravity
Equation (25.2a) is the ﬁeld equation for a special relativistic theory of gravity with
gravitational potential . To complete the theory, one must describe the forces that
the ﬁeld  produces on matter.
(a) One conceivable choice for the force on a test particle of rest mass m is the
following generalization of the familiar Newtonian expression:
∇⃗u ⃗p = −m ⃗∇;
that is,
dpα
dτ = −m,α
in a Lorentz frame,
(25.3)
where τ is proper time along the particle’s world line, ⃗p is the particle’s 4-
momentum, ⃗u is its 4-velocity, and ⃗∇ is the spacetime gradient of the gravi-
tational potential. Show that this equation of motion reduces, in a Lorentz frame
and for low particle velocities, to the standard Newtonian equation of motion.
Show, however, that this equation of motion is ﬂawed in that the gravitational ﬁeld
will alter the particle’s rest mass—in violation of extensive experimental evidence
that the rest mass of an elementary particle is unique and conserved.
(b) Show that the equation of motion (25.3), when modiﬁed to read:
∇⃗u ⃗p = −(ggg + ⃗u ⊗⃗u) . m ⃗∇;
that is,
dpα
dτ = −(gαβ + uαuβ)m,β
in a Lorentz frame,
(25.4)
preserves the particle’s rest mass. In this equation of motion ⃗u is the particle’s 4-
velocity, ggg is the metric, and ggg + ⃗u ⊗⃗u projects ⃗∇ into the 3-space orthogonal
to the particle’s world line (cf. Fig. 24.6 and Ex. 2.10).
(c) Show, by treating a zero-rest-mass particle as the limit of a particle of ﬁnite rest
mass ( ⃗p = m⃗u and ζ = τ/m ﬁnite as τ and m go to zero), that the theory sketched
in parts (a) and (b) predicts that in any Lorentz reference frame, pαe (with
α = 0, 1, 2, 3) are constant along the zero-rest-mass particle’s world line. Explain
why this prediction implies that there will be no gravitational deﬂection of light by
the Sun, which conﬂicts severely with experiments that were done after Einstein
formulated his general theory of relativity (see Sec. 27.2.3). (There was no way,
1194
Chapter 25. Fundamental Concepts of General Relativity

experimentally, to rule out this theory in the epoch, ca. 1914, when Einstein
was doing battle with his colleagues over whether gravity should be treated by
adding a gravitational force to special relativity or should be treated as a geometric
extension of special relativity.)
25.2
25.2 Local Lorentz Frames, the Principle of Relativity,
and Einstein’s Equivalence Principle
One of Einstein’s greatest insights was to recognize that special relativity is valid
not globally, but only locally, inside local, freely falling (inertial) reference frames.
Figure 25.1 shows an example of a local inertial frame: the interior of a Space Shuttle
local inertial (Lorentz)
frame
in Earth orbit, where an astronaut has set up a freely falling (from his viewpoint “freely
ﬂoating”)latticeworkofrodsandclocks.Thislatticeworkisconstructedbyalltherules
appropriate to a special relativistic, inertial (Lorentz) reference frame (Secs. 2.2.1 and
24.2.2): (i) the latticework moves freely through spacetime, so no forces act on it,
and its rods are attached to gyroscopes so they do not rotate; (ii) the measuring rods
are orthogonal to one another, with their intervals of length uniform compared, for
example, to the wavelength of light (orthonormal lattice); (iii) the clocks are densely
packed in the lattice, they tick uniformly relative to ideal atomic standards (they are
ideal clocks), and they are synchronized by the Einstein light-pulse process. However,
there is one crucial change from special relativity: The latticework must be small
enough that one can neglect the effects of inhomogeneities of gravity (which general
relativity will associate with spacetime curvature; and which, e.g., would cause two
freely ﬂoating particles, one nearer Earth than the other, to gradually move apart, even
though initially they are at rest with respect to each other). The necessity for smallness
is embodied in the word “local” of “local inertial frame,” and we shall quantify it with
ever greater precision as we move through this chapter.
We use the phrases local Lorentz frame and local inertial frame interchangeably
to describe the above type of synchronized, orthonormal latticework. The spacetime
coordinates {t, x, y, z} that the latticework provides (in the manner of Sec. 2.2.1) we
local inertial (Lorentz)
coordinates
call, interchangeably, local Lorentz coordinates and local inertial coordinates.
z
y
x
Earth
FIGURE 25.1 A local inertial frame (local Lorentz frame) inside a Space Shuttle that is orbiting Earth.
25.2 Local Lorentz Frames, the Principle of Relativity, and Einstein’s Equivalence Principle
1195

Since in the presence of gravity, inertial reference frames must be restricted to
be local, the inertial-frame version of the Principle of Relativity (Sec. 2.2.2) must
similarly be restricted: all the local, nongravitational laws of physics are the same in
every local inertial frame, everywhere and everywhen in the universe. Here, by “local”
Principle of Relativity in
presence of gravity
laws we mean those laws, classical or quantum, that can be expressed entirely in
terms of quantities conﬁned to (measurable in) a local inertial frame. The exclusion of
gravitational laws from this version of the Principle of Relativity is necessary, because
gravity is to be described by a curvature of spacetime, which (by deﬁnition; see below)
cannot show up in a local inertial frame. This version of the Principle of Relativity
can be described in operational terms using the same language as for the special
relativistic version (Secs. 2.2.2 and 24.2.2): If two different observers, in two different
local Lorentz frames, in different (or the same) regions of the universe, are given
identical written instructions for a physics experiment that can be performed within
the conﬁnes of their local Lorentz frames, then their two experiments must yield the
same results to within their experimental accuracies.
It is worth emphasizing that the Principle of Relativity is asserted to hold every-
where and everywhen in the universe: the local laws of physics must have the same
form in the early universe, a fraction of a second after the big bang, as they have on
Earth today, and as they have at the center of the Sun or inside a black hole.
Einstein’s equivalence
principle
It is reasonable to expect that the speciﬁc forms that the local, nongravitational laws
of physics take in general relativistic local Lorentz frames are the same as they take in
the (global) Lorentz frames of special relativity. This assertion is a modern version of
Einstein’s equivalence principle. (Einstein’s original version states that local physical
measurements in a uniformly accelerated reference frame cannot be distinguished
from those in a uniform gravitational ﬁeld. How is this related to the modern version?
See Ex. 26.11.) In the next section, we use this principle to deduce some properties of
the general relativistic spacetime metric. In Sec. 25.7 we use it to deduce the forms of
some nongravitational laws of physics in curved spacetime, and we discover delicacies
(ambiguities) in this principle of equivalence triggered by spacetime curvature.
25.3
25.3 The Spacetime Metric, and Gravity as a Curvature of Spacetime
The Einstein equivalence principle guarantees that nongravitational physics in a local
Lorentz frame can be described using a spacetime metric ggg, which gives for the
invariant interval between neighboring events with separation vector ⃗ξ = xα∂/∂xα,
the standard special relativistic expression
⃗ξ2 = gαβξαξβ = (s)2 = −(t)2 + (x)2 + (y)2 + (z)2.
(25.5)
Correspondingly, in a local Lorentz frame the components of the spacetime metric
take on their standard special relativity values:
gαβ = ηαβ ≡{−1 if α = β = 0,
+1 if α = β = (x, y, or z),
0 otherwise}.
(25.6)
1196
Chapter 25. Fundamental Concepts of General Relativity

(a)
(b)
FIGURE 25.2 (a) A family of local Lorentz frames, all momentarily
at rest above Earth’s surface. (b) A family of local, 2-dimensional
Euclidean coordinate systems on Earth’s surface. The nonmeshing of
Lorentz frames in (a) is analogous to the nonmeshing of Euclidean
coordinates in (b) and motivates attributing gravity to a curvature
of spacetime.
Turn, now, to a ﬁrst look at gravity-induced constraints on the size of a local
Lorentz frame. Above Earth, set up a family of local Lorentz frames scattered over
the entire region from two Earth radii out to four Earth radii, with all the frames
initially at rest with respect to Earth (Fig. 25.2a). From experience—or, if you prefer,
from Newton’s theory of gravity which after all is quite accurate near Earth—we know
that, as time passes, these frames will all fall toward Earth. If (as a pedagogical aid) we
drill holes through Earth to let the frames continue falling after reaching its surface,
the frames will all pass through Earth’s center and ﬂy out the opposite side.
Obviously, two adjacent frames, which initially were at rest with respect to each
other, acquire a relative velocity during their fall, which causes them to interpenetrate
and pass through each other. Gravity is the cause of their relative velocity.
If these two adjacent frames could be meshed to form a larger Lorentz frame,
then as time passes they would always remain at rest relative to each other. Thus, a
meshing to form a larger Lorentz frame is impossible. The gravity-induced relative
nonmeshing of local
Lorentz frames
velocity prevents it. In brief: gravity prevents the meshing of local Lorentz frames to
form global Lorentz frames.
This situation is closely analogous to the nonmeshing of local, 2-dimensional,
Euclidean coordinate systems on the surface of Earth (Figure 25.2b): the curvature of
Earth prevents a Euclidean mesh—thereby giving grief to mapmakers and surveyors.
ThisanalogysuggestedtoEinsteinin1912apowerfulnewviewpointongravity.Justas
the curvature of Earth prevents the meshing of local Euclidean coordinates on Earth’s
surface, so it must be that a curvature of spacetime prevents the meshing of local
Lorentz frames in the spacetime above Earth—or anywhere else, for that matter. And
since it is already known that gravity is the cause of the nonmeshing of Lorentz frames,
gravity is a manifestation
of spacetime curvature
it must be that gravity is a manifestation of spacetime curvature.
25.3 The Spacetime Metric, and Gravity as a Curvature of Spacetime
1197

To make this idea more quantitative, consider, as a pedagogical tool, the 2-
dimensional metric of Earth’s surface, idealized as spherical and expressed in terms
of a spherical polar coordinate system in line-element form [Eq. (2.24)]:
ds2 = R2dθ2 + R2 sin2 θdφ2.
(25.7a)
Here R is the radius of Earth, or equivalently, the “radius of curvature” of Earth’s
surface. This line element, rewritten in terms of the alternative coordinates
x ≡Rφ,
y ≡R
π
2 −θ

,
(25.7b)
has the form
ds2 = cos2(y/R)dx2 + dy2 = dx2 + dy2 + O(y2/R2)dx2,
(25.7c)
where as usual, O(y2/R2) means “terms of order y2/R2 or smaller.” Notice that
the metric coefﬁcients have the standard Euclidean form gjk = δjk all along the
equator (y = 0); but as one moves away from the equator, they begin to differ
from Euclidean by fractional amounts of O(y2/R2) = O[y2/(radius of curvature of
Earth)2]. Thus, local Euclidean coordinates can be meshed and remain Euclidean
nonmeshing of local
Euclidean coordinates on
Earth’s curved surface
all along the equator—or along any other great circle—but Earth’s curvature forces
the coordinates to cease being Euclidean when one moves off the chosen great cir-
cle, thereby causing the metric coefﬁcients to differ from δjk by amounts gjk =
O[(distance from great circle)2/(radius of curvature)2].
Turn next to a speciﬁc example of curved spacetime: that of a k = 0 Robertson-
Walker model for our expanding universe (to be studied in depth in Chap. 28). In
spherical coordinates {η, χ, θ, φ}, the 4-dimensional metric of this curved spacetime,
described as a line element, can take the form
ds2 = a2(η)[−dη2 + dχ2 + χ2(dθ2 + sin2 θdφ2)].
(25.8a)
Here a, the “expansion factor of the universe,” is a monotonic increasing function of
the“time”coordinateη (nottobeconfusedwiththeﬂatmetricηαβ).Thislineelement,
cosmological example of
nonmeshing
rewritten near χ = 0 in terms of the alternative coordinates
t =
 η
0
adη + 1
2χ2da
dη ,
x = aχ sin θ cos φ,
y = aχ sin θ sin φ,
z = aχ cos θ,
(25.8b)
takes the form (Ex. 25.2)
ds2 = ηαβdxαdxβ + O
x2 + y2 + z2
R2

dxαdxβ,
(25.8c)
where R is a quantity that, by analogy with the radius of curvature R of Earth’s surface,
can be identiﬁed as a radius of curvature of spacetime:
1198
Chapter 25. Fundamental Concepts of General Relativity

1
R2 = O
 ˙a2
a2

+ O
 ¨a
a

,
where
˙a ≡
da
dt

x=y=z=0
,
¨a ≡
d2a
dt2

x=y=z=0
.
(25.8d)
From the form of the metric coefﬁcients in Eq. (25.8d), we see that, all along the
world line x = y = z = 0, the coordinates are precisely Lorentz, but as one moves
away from that world line they cease to be Lorentz, and the metric coefﬁcients be-
gin to differ from ηαβ by amounts gαβ = O[(distance from the chosen world line)2/
(radius of curvature of spacetime)2]. This result is completely analogous to our equa-
torial Euclidean coordinates on Earth’s surface. The curvature of Earth’s surface pre-
vented our local Euclidean coordinates from remaining Euclidean as we moved away
from the equator; here the curvature of spacetime prevents our local Lorentz coordi-
spacetime curvature
forces Lorentz coordinates
to be only locally Lorentz
nates from remaining Lorentz as we move away from the chosen world line.
Notice that the chosen world line is the spatial origin of our local Lorentz coordi-
nates. Thus we can think of those coordinates as provided by a tiny, spatial latticework
of rods and clocks, like that of Figure 25.1. The latticework remains locally Lorentz
for all time (as measured by its own clocks), but it ceases to be locally Lorentz when
one moves a ﬁnite spatial distance away from the spatial origin of the latticework.
This behavior is generic. One can show [see, e.g., Misner, Thorne, and Wheeler
(1973, Sec. 13.6, esp. item (5) on p. 331)] specialized to vanishing acceleration and
rotation] that, if any freely falling observer, anywhere in spacetime, sets up a little
latticework of rods and clocks in accord with our standard rules and keeps the lattice-
work’s spatial origin on her free-fall world line, then the coordinates provided by the
latticework will be locally Lorentz, with metric coefﬁcients
metric coefﬁcients in a
local Lorentz frame
gαβ =
;
ηαβ + O

δjkxjxk
R2

,
ηαβ
at spatial origin
=
in a local Lorentz frame,
(25.9a)
where R is the radius of curvature of spacetime. Notice that, because the deviations of
the metric from ηαβ are of second order in the distance from the spatial origin, the ﬁrst
derivatives of the metric coefﬁcients are of ﬁrst order: gαβ,k = O(xj/R2). This, plus
the vanishing of the commutation coefﬁcients in our coordinate basis, implies that the
connection coefﬁcients of the local Lorentz frame’s coordinate basis are [Eqs. (24.38c)
and (24.38d)]1
connection coefﬁcients in
a local Lorentz frame
αβγ =
⎧
⎨
⎩
O
*
δjkxjxk
R2
+
,
0 at spatial origin
⎫
⎬
⎭in a local Lorentz frame.
(25.9b)
1.
In any manifold, coordinates for which the metric and connection have the form of Eqs. (25.9) in the
vicinity of some chosen geodesic (the “spatial origin”) are called Fermi coordinates or sometimes Fermi
normal coordinates.
25.3 The Spacetime Metric, and Gravity as a Curvature of Spacetime
1199

It is instructive to compare Eq. (25.9a) for the metric in the local Lorentz frame
of a freely falling observer in curved spacetime with Eq. (24.60b) for the metric in
the proper reference frame of an accelerated observer in ﬂat spacetime. Whereas the
spacetime curvature in Eq. (25.9a) produces corrections to gαβ = ηαβ of second order
in distance from the world line, the acceleration and spatial rotation of the reference
frame in Eq. (24.60b) produce corrections of ﬁrst order. This remains true when one
studies accelerated observers in curved spacetime (e.g., Sec. 26.3.2). In their proper
reference frames, the metric coefﬁcients gαβ contain both the ﬁrst-order terms of
Eq. (24.60b) due to acceleration and rotation [e.g., Eq. (26.26)], and the second-order
terms of Eq. (25.9a) due to spacetime curvature.
EXERCISES
Exercise 25.2 Derivation: Local Lorentz Frame in Robertson-Walker Universe
By inserting the coordinate transformation (25.8b) into the Robertson-Walker metric
(25.8a), derive the metric (25.8c), (25.8d) for a local Lorentz frame.
25.4
25.4 Free-Fall Motion and Geodesics of Spacetime
To make more precise the concept of spacetime curvature, we need to study quanti-
tatively the relative acceleration of neighboring, freely falling particles. Before we can
carry out such a study, however, we must understand quantitatively the motion of a
single freely falling particle in curved spacetime. That is the objective of this section.
In a global Lorentz frame of ﬂat, special relativistic spacetime, a free particle moves
along a straight world line—one with the form
(t, x, y, z) = (to, xo, yo, zo) + (p0, px, py, pz)ζ ;
that is,
xα = xα
o + pαζ .
(25.10a)
Here the pα are the Lorentz-frame components of the particle’s 4-momentum; ζ is
the afﬁne parameter such that ⃗p = d/dζ, so pα = dxα/dζ [Eq. (2.10) and subsequent
material]; and xα
o are the coordinates of the particle when its afﬁne parameter is ζ = 0.
The straight-line motion (25.10a) can be described equally well by the statement that
the Lorentz-frame components pα of the particle’s 4-momentum are constant (i.e.,
are independent of ζ):
dpα
dζ = 0.
(25.10b)
Even nicer is the frame-independent description, which says that, as the particle
moves, it parallel-transports its tangent vector ⃗p along its world line:
∇⃗p ⃗p = 0,
or equivalently,
pα
;βpβ = 0.
(25.10c)
For a particle with nonzero rest mass m, which has ⃗p = m⃗u and ζ = τ/m (with
⃗u = d/dτ its 4-velocity and τ its proper time), Eq. (25.10c) is equivalent to ∇⃗u⃗u = 0.
1200
Chapter 25. Fundamental Concepts of General Relativity

This is the geodesic form of the particle’s law of motion [Eq. (24.64)]; Eq. (25.10c) is
the extension of that geodesic law to a particle that may have vanishing rest mass.
Recall that the word geodesic refers to the particle’s straight world line.
This geodesic description of the motion is readily carried over into curved space-
time using the equivalence principle. Let P(ζ) be the world line of a freely moving
particle in curved spacetime. At a speciﬁc event Po = P(ζo) on that world line, in-
troduce a local Lorentz frame (so the frame’s spatial origin, carried by the particle,
passes through Po as time progresses). Then the equivalence principle tells us that
the particle’s law of motion must be the same in this local Lorentz frame as it is in the
global Lorentz frame of special relativity [Eq. (25.10b)]:
dpα
dζ

ζ=ζo
= 0.
(25.11a)
More powerful than this local-Lorentz-frame description of the motion is a de-
scription that is frame independent. We can easily deduce such a description from
Eq. (25.11a). Since the connection coefﬁcients vanish at the spatial origin of the local
Lorentz frame where Eq. (25.11a) is being evaluated [cf. Eq. (25.9b)], Eq. (25.11a) can
be written equally well, in our local Lorentz frame, as
0 =
dpα
dζ + α
βγpβ dxγ
dζ

ζ=ζo
=

(pα
,γ + α
βγpβ)dxγ
dζ

ζ=ζo
= (pα
;γpγ)ζ=ζo.
(25.11b)
Thus, as the particle passes through the spatial origin of our local Lorentz coordinate
system, the components of the directional derivative of its 4-momentum along itself
vanish. Now, if two 4-vectors have components that are equal in one basis, their com-
ponents are guaranteed [by the tensorial transformation law (24.19)] to be equal in
all bases; correspondingly, the two vectors, viewed as frame-independent, geometric
objects, must be equal. Thus, since Eq. (25.11b) says that the components of the 4-
vector ∇⃗p ⃗p and the zero vector are equal in our chosen local Lorentz frame, it must
be true that
geodesic equation of
motion for a freely
falling particle in curved
spacetime
∇⃗p ⃗p = 0
(25.11c)
at the moment when the particle passes through the point Po = P(ζo). Moreover,
since Po is an arbitrary point (event) along the particle’s world line, it must be
that Eq. (25.11c) is a geometric, frame-independent equation of motion for the
particle, valid everywhere along its world line. Notice that this geometric, frame-
independent equation of motion ∇⃗p ⃗p = 0 in curved spacetime is precisely the same
as that [Eq. (25.10c)] for ﬂat spacetime. We generalize this conclusion to other laws
of physics in Sec. 25.7.
Our equation of motion (25.11c) for a freely moving point particle says, in words,
that the particle parallel transports its 4-momentum along its world line. As in ﬂat
25.4 Free-Fall Motion and Geodesics of Spacetime
1201

spacetime, so also in curved spacetime, if the particle has ﬁnite rest mass, we can
rewrite the equation of motion ∇⃗p ⃗p = 0 as
geodesic equation for
particle with ﬁnite rest
mass
∇⃗u⃗u = 0,
(25.11d)
where ⃗u = ⃗p/m = d/dτ is the particle’s 4-velocity, and τ = mζ is proper time along
the particle’s world line.
In any curved manifold, not just in spacetime, the relation ⃗∇⃗u⃗u = 0 (or ∇⃗p ⃗p = 0)
is called the geodesic equation, and the curve to which ⃗u is the tangent vector is called
a geodesic. If the geodesic is spacelike, its tangent vector can be normalized such
that ⃗u = d/ds, with s the proper distance along the geodesic—the obvious analog
of ⃗u = d/dτ for a timelike geodesic.
Onthesurfaceofasphere, suchasEarth, thegeodesicsarethegreatcircles; theyare
the unique curves along which local Euclidean coordinates can be meshed, keeping
one of the two Euclidean coordinates constant along the curve [cf. Eq. (25.7c)]. They
are also the trajectories generated by an airplane’s inertial guidance system, which
guides the plane along the straightest trajectory it can. Similarly, in spacetime the
trajectories of freely falling particles are geodesics. They are the unique curves along
which local Lorentz coordinates can be meshed, keeping the three spatial coordinates
constant along the curve and letting the time vary, thereby producing a local Lorentz
reference frame [Eqs. (25.9)]. They are also the spacetime trajectories along which
inertial guidance systems guide a spacecraft.
The geodesic equation ∇⃗p ⃗p = 0 for a particle in spacetime guarantees that the
square of the 4-momentum will be conserved along the particle’s world line; in slot-
naming index notation, we have:
(gαβpαpβ);γpγ = 2gαβpαpβ
;γpγ = 0.
(25.12)
Here the standard Leibniz rule for differentiating products has been used; this rule
follows from the deﬁnition (24.29) of the frame-independent directional derivative
of a tensor; it also can be deduced in a local Lorentz frame, where αμν = 0, so
each gradient with a “;” reduces to a partial derivative with a “,”. In Eq. (25.12)
the term involving the gradient of the metric has been discarded, since it vanishes
[Eq. (24.39)], and the two terms involving derivatives of pα and pβ, being equal, have
been combined. In index-free notation the frame-independent relation (25.12) says
∇⃗p( ⃗p . ⃗p) = 2 ⃗p . ∇⃗p ⃗p = 0.
(25.13)
conservation of rest mass
for freely falling particle
This is a pleasing result, since the square of the 4-momentum is the negative of the
particle’s squared rest mass, ⃗p . ⃗p = −m2, which surely should be conserved along
the particle’s free-fall world line! Note that, as in ﬂat spacetime, so also in curved, for
a particle of ﬁnite rest mass the free-fall trajectory (the geodesic world line) is timelike,
⃗p . ⃗p = −m2 < 0, while for a zero-rest-mass particle it is null, ⃗p . ⃗p = 0. Spacetime
1202
Chapter 25. Fundamental Concepts of General Relativity

also supports spacelike geodesics [i.e., curves with tangent vectors ⃗p that satisfy the
geodesic equation (25.11c) and are spacelike, ⃗p . ⃗p > 0]. Such curves can be thought
of as the world lines of freely falling “tachyons” (i.e., faster-than-light particles)—
though it seems unlikely that such particles exist in Nature. Note that the constancy
of ⃗p . ⃗p along a geodesic implies that a geodesic can never change its character: if
initially timelike, it always remains timelike; if initially null, it remains null; if initially
spacelike, it remains spacelike.
The geodesic world line of a freely moving particle has three very important
properties:
1. When written in a coordinate basis, the geodesic equation, ∇⃗p ⃗p = 0, be-
comes the following differential equation for the particle’s world line xα(ζ)
in the coordinate system (Ex. 25.3):
coordinate representation
of geodesic equation
d2xα
dζ 2 + α
μν
dxμ
dζ
dxν
dζ = 0.
(25.14)
Here αμν are the connection coefﬁcients of the coordinate system’s coor-
dinate basis. [Equation (24.66) was a special case of this.] Note that these
are four coupled equations (α = 0, 1, 2, 3) for the four coordinates xα as
functions of afﬁne parameter ζ along the geodesic. If the initial position, xα
at ζ = 0, and initial tangent vector (particle momentum), pα = dxα/dζ at
ζ = 0, are speciﬁed, then these four equations will determine uniquely the
coordinates xα(ζ) as a function of ζ along the geodesic.
2. Consider a spacetime that possesses a symmetry, which is embodied in the
fact that the metric coefﬁcients in some coordinate system are independent
of one of the coordinates xA. Associated with that symmetry there will be
a so-called Killing vector ﬁeld ⃗ξ = ∂/∂xA and a conserved quantity pA ≡
⃗p . ∂/∂xA for free-particle motion. Exercises 25.4 and 25.5 discuss Killing
Killing vectors and
conserved quantities for
geodesic motion
vector ﬁelds, derive this conservation law, and develop a familiar example.
3. Among all timelike curves linking two events P0 and P1 in spacetime, those
whose proper time lapse (timelike length) is stationary under small vari-
action principle of
stationary proper time
lapse for geodesic motion
ations of the curve are timelike geodesics; see Ex. 25.6. In other words,
timelike geodesics are the curves that satisfy the action principle (25.19).
Now, one can always send a photon from P0 to P1 by bouncing it off a set
of strategically located mirrors, and that photon path is the limit of a time-
like curve as the curve becomes null. Therefore, there exist timelike curves
from P0 to P1 with vanishingly small length, so no timelike geodesics can be
an absolute minimum of the proper time lapse, but one can be an absolute
maximum.
25.4 Free-Fall Motion and Geodesics of Spacetime
1203

EXERCISES
Exercise 25.3 Derivation and Problem: Geodesic Equation
in an Arbitrary Coordinate System
Show that in an arbitrary coordinate system xα(P) the geodesic equation (25.11c)
takes the form of Eq. (25.14).
Exercise 25.4 **Derivation and Example: Constant of Geodesic Motion
in a Spacetime with Symmetry
(a) Suppose that in some coordinate system the metric coefﬁcients are independent
of some speciﬁc coordinate xA: gαβ,A = 0 (e.g., in spherical polar coordinates
{t, r, θ, φ} in ﬂat spacetime gαβ,φ = 0, so we could set xA = φ). Show that
pA ≡⃗p .
∂
∂xA
(25.15)
is a constant of the motion for a freely moving particle [pφ = (conserved z-
componentofangularmomentum)intheabove, sphericallysymmetricexample].
[Hint: Show that the geodesic equation can be written in the form
dpα
dζ −μανpμpν = 0,
(25.16)
where μαν is the covariant connection coefﬁcient of Eqs. (24.38c), (24.38d)
with cαβγ = 0, because we are using a coordinate basis.] Note the analogy of the
constant of the motion pA with Hamiltonian mechanics: there, if the hamiltonian
is independent of xA, then the generalized momentum pA is conserved; here, if
the metric coefﬁcients are independent of xA, then the covariant component pA
of the momentum is conserved. For an elucidation of the connection between
these two conservation laws, see Ex. 25.7c.
(b) As
an
example,
consider
a
particle
moving
freely
through
a
time-
independent, Newtonian gravitational ﬁeld. In Ex. 25.18, we learn that such a
gravitational ﬁeld can be described in the language of general relativity by the
spacetime metric
ds2 = −(1 + 2)dt2 + (δjk + hjk)dxjdxk,
(25.17)
where (x, y, z) is the time-independent Newtonian potential, and hjk are con-
tributions to the metric that are independent of the time coordinate t and have
magnitude of order ||. That the gravitational ﬁeld is weak means || ≪1 (or,
in conventional—SI or cgs—units, |/c2| ≪1). The coordinates being used are
Lorentz, asidefromtinycorrectionsoforder||, andasthisexerciseandEx.25.18
show, they coincide with the coordinates of the Newtonian theory of gravity. Sup-
pose that the particle has a velocity vj ≡dxj/dt through this coordinate system
that is <∼||
1
2 and thus is small compared to the speed of light. Because the met-
1204
Chapter 25. Fundamental Concepts of General Relativity

ric is independent of the time coordinate t, the component pt of the particle’s
4-momentum must be conserved along its world line. Since throughout physics,
the conserved quantity associated with time-translation invariance is always the
energy, we expect that pt, when evaluated accurate to ﬁrst order in ||, must be
equal to the particle’s conserved Newtonian energy, E = m + 1
2mvjvkδjk, aside
from some multiplicative and additive constants. Show that this, indeed, is true,
and evaluate the constants.
Exercise 25.5 Example: Killing Vector Field
A Killing vector ﬁeld2 is a coordinate-independent tool for exhibiting symmetries of
the metric. It is any vector ﬁeld ⃗ξ that satisﬁes
ξα;β + ξβ;α = 0
(25.18)
(i.e., any vector ﬁeld whose symmetrized gradient vanishes).
(a) Let ⃗ξ be a vector ﬁeld that might or might not be Killing. Show, by construction,
that it is possible to introduce a coordinate system in which ⃗ξ = ∂/∂xA for some
coordinate xA.
(b) Show that in the coordinate system of part (a) the symmetrized gradient of ⃗ξ is
ξα;β + ξβ;α = ∂gαβ/∂xA. From this infer that a vector ﬁeld ⃗ξ is Killing if and only
if there exists a coordinate system in which (i) ⃗ξ = ∂/∂xA and (ii) the metric is
independent of xA.
(c) Use Killing’s equation (25.18) to show, without introducing a coordinate system,
that, if ⃗ξ is a Killing vector ﬁeld and ⃗p is the 4-momentum of a freely falling
particle, then ⃗ξ . ⃗p is conserved along the particle’s geodesic world line. This is the
same conservation law as we proved in Ex. 25.4a using a coordinate-dependent
calculation.
Exercise 25.6 Problem: Timelike Geodesic as Path of Extremal Proper Time
By introducing a speciﬁc but arbitrary coordinate system, show that among all time-
like world lines that a particle could take to get from event P0 to event P1, the one or
ones whose proper time lapse is stationary under small variations of path are the free-
fall geodesics. In other words, an action principle for a timelike geodesic P(λ) [i.e.,
xα(λ) in any coordinate system xα] is
δ
 P1
P0
dτ = δ
 1
0

−gαβ
dxα
dλ
dxβ
dλ
 1
2
dλ = 0,
(25.19)
2.
Named after Wilhelm Killing, the mathematician who introduced it.
25.4 Free-Fall Motion and Geodesics of Spacetime
1205

where λ is an arbitrary parameter, which by construction ranges from 0 at P0 to 1
at P1. [Note: Unless, after the variation, you choose the arbitrary parameter λ to be
“afﬁne” (λ = aζ + b, where a and b are constants and ζ is such that ⃗p = d/dζ), your
equation for d2xα/dλ2 will not look quite like Eq. (25.14).]
Exercise 25.7 Problem: Super-Hamiltonian for Free Particle Motion
(a) Show that, among all curves P(ζ) that could take a particle from event P0 = P(0)
to event P1 = P(ζ1) (for some ζ1), those that satisfy the action principle
δ 1
2
 ζ1
0
gαβ
dxα
dζ
dxβ
dζ dζ = 0
(25.20)
are geodesics, and ζ is the afﬁne parameter along the geodesic related to the
particle’s 4-momentum by ⃗p = d/dζ. [Note: In this action principle, by contrast
with Eq. (25.19), the integration parameter is necessarily afﬁne.]
(b) The lagrangian L(xμ, dxμ/dζ) associated with this action principle is
1
2gαβ(dxα/dζ)(dxβ/dζ), wherethecoordinates{x0, x1, x2, x3}appearinthemet-
ric coefﬁcients and their derivatives appear explicitly. Using standard principles
of Hamiltonian mechanics, show that the momentum canonically conjugate to
xμ is pμ = gμνdxν/dζ—which in fact is the covariant component of the particle’s
4-momentum. Show, further, that the hamiltonian associated with the particle’s
lagrangian is
super-hamiltonian for
geodesic motion
H = 1
2
gμνpμpν.
(25.21)
Explain why this guarantees that Hamilton’s equations dxα/dζ = ∂H/∂pα and
dpα/dζ = −∂H/∂xα are satisﬁed if and only if xα(ζ) is a geodesic with afﬁne
parameter ζ and pα is the tangent vector to the geodesic.
(c) Show that Hamilton’s equations guarantee that, if the metric coefﬁcients are
independent of some coordinate xA, then pA is a conserved quantity. This is the
same conservation law as we derived by other methods in Exs. 25.4 and 25.5.
H = 1
2gμνpμpν is often called the geodesic’s super-hamiltonian. It turns out that,
often, the easiest way to compute geodesics numerically (e.g., for particle motion
around a black hole) is to solve the super-hamiltonian’s Hamilton equations (see, e.g.,
Levin and Perez-Giz, 2008).
25.5
25.5 Relative Acceleration, Tidal Gravity, and Spacetime Curvature
Now that we understand the motion of an individual freely falling particle in curved
spacetime, we are ready to study the effects of gravity on the relative motions of such
particles. Before doing so in general relativity, let us recall the Newtonian description.
1206
Chapter 25. Fundamental Concepts of General Relativity

(a)
(b)
z
z
t
t = 0
t = 0
→p = (∂/∂ζ)λ
ξ
→ = (∂/∂λ)ζ
ζ = 0
ζ = 0
λ = 0
λ = .5
λ = 1
1
1
2
2
3
3
3
2
2
1
1
3
y
x
x
A
B
A
B
ξ
→p
FIGURE 25.3 The effects of tidal gravity on the relative motions of two freely falling particles. (a) In
Euclidean 3-space using Newton’s theory of gravity. (b) In spacetime using Einstein’s theory of gravity,
general relativity.
25.5.1
25.5.1 Newtonian Description of Tidal Gravity
Consider, as shown in Fig. 25.3a, two point particles, A and B, falling freely through
3-dimensional Euclidean space under the action of an external Newtonian potential
 (i.e., a potential generated by other masses, not by the particles themselves). At
Newtonian time t = 0 the particles are separated by only a small distance and are
moving with the same velocity: vA = vB. As time passes, however, the two particles,
being at slightly different locations in space, experience slightly different gravitational
potentials  and gravitational accelerations g = −∇ and thence develop slightly
different velocities: vA ̸= vB. To quantify this, denote by ξ the vector separation of
the two particles in Euclidean 3-space. The components of ξ on any Euclidean basis
(e.g., that of Fig. 25.3a) are ξj = xj
B −xj
A, where xj
I is the coordinate location of
particle I. Correspondingly, the rate of change of ξj with respect to Newtonian time
is dξj/dt = vj
B −vj
A (i.e., the relative velocity of the two particles is the difference of
their velocities). The second time derivative of the relative separation (i.e., the relative
acceleration of the two particles) is thus given by
d2ξj
dt2 = d2xj
B
dt2 −d2xj
A
dt2 = −
 ∂
∂xj

B
+
 ∂
∂xj

A
= −∂2
∂xj∂xk ξk,
(25.22)
accurate to ﬁrst order in the separation ξk. This equation gives the components of the
relative acceleration in an arbitrary Euclidean basis. Rewritten in geometric, basis-
independent language, this equation is
relative acceleration of
freely falling particles
d2ξ
dt2 = −E(
, ξ);
or
d2ξj
dt2 = −Ej
kξk,
(25.23)
25.5 Relative Acceleration, Tidal Gravity, and Spacetime Curvature
1207

where E is a symmetric, second-rank tensor, called the Newtonian tidal gravitational
ﬁeld:
Newtonian tidal
gravitational ﬁeld
E ≡∇∇ = −∇g;
that is,
Ejk =
∂2
∂xj∂xk
in Euclidean coordinates.
(25.24)
The name “tidal gravitational ﬁeld” comes from the fact that this is the ﬁeld which,
generated by the Moon and the Sun, produces the tides on Earth’s oceans. Note that,
since this ﬁeld is the gradient of the Newtonian gravitational acceleration g, it is a
quantitative measure of the inhomogeneities of Newtonian gravity.
Equation (25.23) shows quantitatively how the tidal gravitational ﬁeld produces
the relative acceleration of our two particles. As a speciﬁc application, one can use it to
compute, in Newtonian theory, the relative accelerations and thence relative motions
of two neighboring local Lorentz frames as they fall toward and through the center of
Earth (Fig. 25.2a and associated discussion).
25.5.2
25.5.2 Relativistic Description of Tidal Gravity
Now turn to the general relativistic description of the relative motions of two free
particles. As shown in Fig. 25.3b, the particles, labeled A and B, move along geodesic
world lines with afﬁne parameters ζ and 4-momentum tangent vectors ⃗p = d/dζ.
The origins of ζ along the two world lines can be chosen however we wish, so long as
events with the same ζ on the two world lines, PA(ζ) and PB(ζ), are close enough to
each other that we can perform power-series expansions in their separation, ⃗ξ(ζ) =
PB(ζ) −PA(ζ), and keep only the leading terms. As in our Newtonian analysis, we
require that the two particles initially have vanishing relative velocity, ∇⃗p⃗ξ = 0, and
we compute the tidal-gravity-induced relative acceleration ∇⃗p∇⃗p⃗ξ.
As a tool in our calculation, we introduce into spacetime a 2-dimensional sur-
face that contains our two geodesics A and B, and also contains an inﬁnity of other
geodesics in between and alongside them. On that surface, we introduce two coor-
dinates, ζ = (afﬁne parameter along each geodesic) and λ = (a parameter that la-
bels the geodesics); see Fig. 25.3b. Geodesic A carries the label λ = 0; geodesic B is
λ = 1; ⃗p = (∂/∂ζ)λ=const is a vector ﬁeld that, evaluated on any geodesic (A, B, or
other curve of constant λ), is equal to the 4-momentum of the particle that moves
along that geodesic; and ⃗ξ ≡(∂/∂λ)ζ=const is a vector ﬁeld that, when evaluated on
geodesic A (i.e., at λ = 0), we identify as a rigorous version of the separation vector
PB(ζ) −PA(ζ) that we wish to study. This identiﬁcation requires, for good accuracy,
that the geodesics be close together and be so parameterized that PA(ζ) is close to
PB(ζ).
Our objective is to compute the relative acceleration of particles B and A, ∇⃗p∇⃗p⃗ξ,
evaluated at λ = 0. The quantity ∇⃗p⃗ξ, which we wish to differentiate a second time in
1208
Chapter 25. Fundamental Concepts of General Relativity

that computation, is one of the terms in the following expression for the commutator
of the vector ﬁelds ⃗p and ⃗ξ [Eq. (24.40)]:
[ ⃗p, ⃗ξ]= ∇⃗p⃗ξ −∇⃗ξ ⃗p.
(25.25)
Because ⃗p = (∂/∂ζ)λ and ⃗ξ = (∂/∂λ)ζ, these two vector ﬁelds commute, and
Eq. (25.25) tells us that ∇⃗p⃗ξ = ∇⃗ξ ⃗p. Correspondingly, the relative acceleration of
our two particles can be expressed as
∇⃗p∇⃗p⃗ξ = ∇⃗p∇⃗ξ ⃗p = (∇⃗p∇⃗ξ −∇⃗ξ∇⃗p) ⃗p.
(25.26)
Here the second equality results from adding on, for use below, a term that vanishes
because ∇⃗p ⃗p = 0 (geodesic equation).
This ﬁrst part of our calculation was performed efﬁciently using index-free no-
tation. The next step will be easier if we introduce indices as names for slots. Then
expression (25.26) takes the form
(ξα
;βpβ);γpγ = (pα
;γξγ);δpδ −(pα
;γpγ);δξδ,
(25.27)
which can be evaluated by using the rule for differentiating products and then re-
naming indices and collecting terms. The result is
(ξα
;βpβ);γpγ = (pα
;γ δ −pα
;δγ)ξγpδ + pα
;γ(ξγ
;δpδ −pγ
;δξδ).
(25.28)
The second term in this expression vanishes, since it is just the commutator of ⃗ξ and
⃗p [Eq. (25.25)] written in slot-naming index notation, and as we noted above, ⃗ξ
and ⃗p commute. The resulting equation,
(ξα
;βpβ);γpγ = (pα
;γ δ −pα
;δγ)ξγpδ,
(25.29)
reveals that the relative acceleration of the two particles is caused by noncommutation
of the two slots of a double gradient (slots here named γ and δ). In the ﬂat spacetime
of special relativity, the two slots would commute3 and there would be no relative
acceleration. Spacetime curvature prevents them from commuting and thereby causes
the relative acceleration.
Now, one can show that for any vector ﬁeld ⃗p(P), pα
;γ δ −pα
;δγ is linear in
pα; see Ex. 25.8. Thus there must exist a fourth-rank tensor ﬁeld RRR(
,
,
,
)
such that
Riemann curvature tensor
pα
;γ δ −pα
;δγ = −Rα
βγ δpβ
(25.30)
3.
In ﬂat spacetime, in global Lorentz coordinates, αβγ = 0 everywhere, so pα
;γ δ = ∂2pα/∂xγ∂xδ. Be-
cause partial derivatives commute, expression (25.29) vanishes.
25.5 Relative Acceleration, Tidal Gravity, and Spacetime Curvature
1209

for any ⃗p. The tensor RRR can be regarded as responsible for the failure of gradients to
commute, so it must be some aspect of spacetime curvature. It is called the Riemann
curvature tensor.
Inserting Eq. (25.30) into Eq. (25.29) and writing the result in both slot-naming
index notation and abstract notation, we obtain
equation of geodesic
deviation
(ξα
;βpβ);γpγ = −Rα
βγ δpβξγpδ,
∇⃗p∇⃗p⃗ξ = −RRR(
, ⃗p, ⃗ξ , ⃗p).
(25.31)
This is the equation of relative acceleration for freely moving test particles. It is also
called the equation of geodesic deviation, because it describes the manner in which
spacetime curvature RRR forces geodesics that are initially parallel (the world lines of
freely moving particles with zero initial relative velocity) to deviate from one another
(Fig. 25.3b).
EXERCISES
Exercise 25.8 Derivation: Linearity of the Commutator of the Double Gradient
(a) Let a and b be scalar ﬁelds with arbitrary but smooth dependence on location in
curved spacetime, and let ⃗A and ⃗B be vector ﬁelds. Show that
(aAα + bBα);γ δ −(aAα + bBα);δγ = a(Aα
;γ δ −Aα
;δγ) + b(Bα
;γ δ −Bα
;δγ).
(25.32)
[Hint: The double gradient of a scalar ﬁeld commutes, as one can easily see in a
local Lorentz frame.]
(b) Use Eq. (25.32) to show that (i) the commutator of the double gradient is in-
dependent of how the differentiated vector ﬁeld varies from point to point and
depends only on the value of the ﬁeld at the location where the commutator is
evaluated, and (ii) the commutator is linear in that value. Thereby conclude that
there must exist a fourth-rank tensor ﬁeld RRR such that Eq. (25.30) is true for any
vector ﬁeld ⃗p.
25.5.3
25.5.3 Comparison of Newtonian and Relativistic Descriptions
It is instructive to compare this relativistic description of the relative acceleration of
freely moving particles with the Newtonian description. For this purpose we consider
a region of spacetime, such as our solar system, in which the Newtonian description
of gravity is highly accurate; and there we study the relative acceleration of two free
particles from the viewpoint of a local Lorentz frame in which the particles are both
initially at rest.
In the Newtonian description, the transformation from a Newtonian universal
reference frame (e.g., that of the center of mass of the solar system) to the chosen
local Lorentz frame is achieved by introducing new Euclidean coordinates that are
uniformly accelerated relative to the old ones, with just the right uniform acceleration
1210
Chapter 25. Fundamental Concepts of General Relativity

to annul the gravitational acceleration at the center of the local Lorentz frame. This
transformationaddsaspatiallyhomogeneousconstanttotheNewtonianacceleration,
g = −∇, but leaves unchanged the tidal ﬁeld, E = ∇∇. Correspondingly, the
Newtonian equation of relative acceleration in the local Lorentz frame retains its
standard Newtonian form, d2ξj/dt2 = −Ejkξk [Eq. (25.23)], with the components
of the tidal ﬁeld computable equally well in the original universal reference frame or
in the local Lorentz frame, using the standard relation Ejk = Ejk = ∂2/∂xj∂xk.
As an aid in making contact between the relativistic and the Newtonian descrip-
tions, we convert from using the 4-momentum ⃗p as the relativistic tangent vector and
ζ as the relativistic parameter along the particles’ world lines to using the 4-velocity
⃗u = ⃗p/m and the proper timeτ = mζ. This conversion brings the relativistic equation
of relative acceleration (25.31) into the form
geodesic deviation for
particles with ﬁnite rest
mass
∇⃗u∇⃗u⃗ξ = −RRR(. . . , ⃗u, ⃗ξ , ⃗u).
(25.33)
Because the particles are (momentarily) at rest near the origin of the local Lorentz
frame, their 4-velocities are ⃗u ≡d/dτ = ∂/∂t, which implies that the components of
their 4-velocities are u0 = 1, uj = 0, and their proper times τ are equal to coordinate
time t, which in turn coincides with the time t of the Newtonian analysis: τ = t. In
the relativistic analysis, as in the Newtonian, the separation vector ⃗ξ will have only
spatial components, ξ0 = 0 and ξj ̸= 0. (If this were not so, we could make it so by
readjusting the origin of proper time for particle B, so ⃗ξ . ⃗p = m⃗ξ . ⃗u = 0, whence
ξ0 = 0; Fig. 25.3b.) These facts, together with the vanishing of all the connection
coefﬁcients and derivatives of them (jk0,0 = 0) that appear in (ξj;βuβ);γuγ at the
origin of the local Lorentz frame [cf. Eqs. (25.9)], imply that the local Lorentz com-
ponents of the equation of relative acceleration (25.33) take the form
d2ξj
dt2 = −Rj
0k0ξk.
(25.34)
By comparing this with the Newtonian equation of relative acceleration (25.23), we
infer that, in the Newtonian limit, in the local rest frame of the two particles, we have
space-time-space-time
components of Riemann
tensor become tidal ﬁeld in
Newtonian limit of general
relativity
Rj
0k0 = Ejk =
∂2
∂xj∂xk .
(25.35)
Thus, the Riemann curvature tensor is the relativistic generalization of the Newtonian
tidal ﬁeld. This conclusion and the above equations make quantitative the statement
that gravity is a manifestation of spacetime curvature.
components of Riemann
tensor outside a
Newtonian, gravitating
body
Outside a spherical body with weak (Newtonian) gravity, such as Earth, the New-
tonian potential is  = −GM/r, where G is Newton’s gravitation constant, M is the
body’s mass, and r is the distance from its center. If we introduce Cartesian coordi-
nates with origin at the body’s center and with the point at which the Riemann tensor
is to be measured lying on the z-axis at {x, y, z} = {0, 0, r}, then  near that point is
25.5 Relative Acceleration, Tidal Gravity, and Spacetime Curvature
1211

 = −GM/(z2 + x2 + y2)
1
2, and on the z-axis the only nonzero Rj0k0 components,
as computed from Eq. (25.35), are
Rz
0z0 = −2GM
r3
,
Rx
0x0 = Ry
0y0 = +GM
r3
.
(25.36)
Correspondingly, for two particles separated from each other in the radial (z) di-
rection, the relative acceleration (25.34) is d2ξj/dt2 = (2GM/r3)ξj (i.e., the
particles are pulled apart by the body’s tidal gravitational ﬁeld). Similarly, for two
particles separated from each other in a transverse direction (in the x-y plane), we
have d2ξj/dt2 = −(GM/r3)ξj (i.e., the particles are pushed together by the body’s
tidal gravitational ﬁeld). There thus is a radial tidal stretch and a lateral tidal squeeze;
the lateral squeeze has half the strength of the radial stretch but occurs in two lat-
eral dimensions compared to the one radial dimension. This stretch and squeeze,
produced by the Sun and the Moon, are responsible for the tides on Earth’s oceans;
Ex. 25.9.
EXERCISES
Exercise 25.9 **Example: Ocean Tides
(a) Place a local Lorentz frame at the center of Earth, and let Ejk be the tidal ﬁeld
there, produced by the Newtonian gravitational ﬁelds of the Sun and the Moon.
For simplicity, treat Earth as precisely spherical. Show that the gravitational ac-
celeration (relative to Earth’s center) at some location on or near Earth’s surface
(radius r) is
gj = −GM
r2 nj −Ej
krnk,
(25.37)
where M is Earth’s mass, and nj is a unit vector pointing from Earth’s center to
the location at which gj is evaluated.
(b) Show that this gravitational acceleration is minus the gradient of the Newtonian
potential
 = −GM
r
+ 1
2Ejk r2njnk.
(25.38)
(c) Consider regions of Earth’s oceans that are far from any coast and have ocean
depth large compared to the heights of ocean tides. If Earth were nonrotating,
then explain why the analysis of Sec. 13.3 predicts that the ocean surface in these
regions would be a surface of constant . Explain why this remains true to good
accuracy also for the rotating Earth.
(d) Showthatintheseoceanregions, theMooncreateshightidespointingtowardand
away from itself and low tides in the transverse directions on Earth; and similarly
for the Sun. Compute the difference between high and low tides produced by
the Moon and by the Sun, and the difference of the total tide when the Moon
and the Sun are in approximately the same direction in the sky. Your answers are
1212
Chapter 25. Fundamental Concepts of General Relativity

reasonably accurate for deep-ocean regions far from any coast, but near a coast,
thetidesaretypicallylargerand sometimesfarlarger, andtheyare shiftedinphase
relative to the positions of the Moon and Sun. Why?
25.6
25.6 Properties of the Riemann Curvature Tensor
We now pause in our study of the foundations of general relativity to examine a few
properties of the Riemann curvature tensor RRR.
As a tool for deriving other things, we begin by evaluating the components of the
Riemann tensor at the spatial origin of a local Lorentz frame (i.e., at a point where
gαβ = ηαβ and αβγ vanishes, but its derivatives do not). For any vector ﬁeld ⃗p, a
straightforward computation reveals
pα
;γ δ −pα
;δγ = (α
βγ ,δ −α
βδ,γ)pβ.
(25.39)
By comparing with Eq. (25.30), we can read off the local-Lorentz components of the
Riemann tensor:
Rα
βγ δ = α
βδ,γ −α
βγ ,δ
at the spatial origin of a local Lorentz frame.
(25.40)
From this expression we infer that, at a spatial distance

δijxixj from the origin of a
local Lorentz frame, the connection coefﬁcients and the metric have magnitudes
inﬂuence of spacetime
curvature on connection
and metric in a local
Lorentz frame
α
βγ = O(Rμ
νλρ

δijxixj),
gαβ −ηαβ = O(Rμ
νλρ δijxixj)
in a local Lorentz frame.
(25.41)
Comparison with Eqs. (25.9) shows that the radius of curvature of spacetime (a
concept deﬁned only semiquantitatively) is of order the inverse square root of the
components of the Riemann tensor in a local Lorentz frame:
radius of curvature of
spacetime
R = O
⎛
⎝
1
|Rαβγ δ|
1
2
⎞
⎠
in a local Lorentz frame.
(25.42)
By comparison with Eq. (25.36), we see that at radius r outside a weakly gravitating
body of mass M, the radius of curvature of spacetime is
R ∼
 r3
GM
 1
2
=
 c2r3
GM
 1
2
,
(25.43)
where the factor c (speed of light) in the second expression makes the formula valid
in conventional units. For further discussion, see Ex. 25.10.
components of Riemann
tensor in a local Lorentz
frame
Using the components (25.40) of the Riemann tensor in a local Lorentz frame in
terms of the connection coefﬁcients, and using expressions (24.38) for the connection
coefﬁcients in terms of the metric components and commutation coefﬁcients together
25.6 Properties of the Riemann Curvature Tensor
1213

with the vanishing of the commutation coefﬁcients (because a local Lorentz frame is
a coordinate basis), one easily can show that
Rαβγ δ = 1
2(gαδ,βγ + gβγ ,αδ −gαγ ,βδ −gβδ,αγ)
in a local Lorentz frame.
(25.44)
From these expressions, plus the commutation of partial derivatives gαγ ,βδ = gαγ ,δβ
and the symmetry of the metric, one readily can show that in a local Lorentz frame
the components of the Riemann tensor have the following symmetries:
three symmetries of
Riemann tensor
Rαβγ δ = −Rβαγ δ , Rαβγ δ = −Rαβδγ , Rαβγ δ = +Rγ δαβ
(25.45a)
(antisymmetry in ﬁrst pair of indices, antisymmetry in second pair of indices, and
symmetry under interchange of the pairs). When one computes the value of the
tensor on four vectors, RRR( ⃗A, ⃗B, ⃗C, ⃗D) using component calculations in this frame,
one trivially sees that these symmetries produce corresponding symmetries under
interchange of the vectors inserted into the slots, and thence under interchange of
the slots themselves. (This is always the case: any symmetry that the components
of a tensor exhibit in any special basis will induce the same symmetry on the slots
of the geometric, frame-independent tensor.) The resulting symmetries for RRR are
given by Eq. (25.45a) with the “Escher mind-ﬂip” (Sec. 1.5.1) in which the indices
switch from naming components in a special frame to naming slots. The Riemann
tensor is antisymmetric under interchange of its ﬁrst two slots, antisymmetric under
interchange of the last two, and symmetric under interchange of the two pairs.
One additional symmetry can be veriﬁed by calculation in the local Lorentz frame
[i.e., from Eq. (25.44)]:4
a fourth symmetry of
Riemann tensor
Rαβγ δ + Rαγ δβ + Rαδβγ = 0.
(25.45b)
One can show that the full set of symmetries (25.45) reduces the number of
independent components of the Riemann tensor, in 4-dimensional spacetime, from
Riemann tensor has 20
independent components
generically
44 = 256 to “just” 20.
Of these 20 independent components, 10 are contained in the Ricci curvature
tensor, which is the contraction of the Riemann tensor on its ﬁrst and third slots:
Ricci tensor and its
symmetry
Rαβ ≡Rμ
αμβ,
(25.46)
and which, by the symmetries (25.45) of Riemann, is itself symmetric:
4.
Note that this cyclic symmetry is the same as occurs in the second of Maxwell’s equations (2.48),
ϵαβγ δFγ δ;β = 0; it is also the same as occurs in the Jacobi identity for commutators

⃗B, [ ⃗C, ⃗D]

+

⃗C, [ ⃗D, ⃗B]

+

⃗D, [ ⃗B, ⃗C]

= 0.
1214
Chapter 25. Fundamental Concepts of General Relativity

Rαβ = Rβα.
(25.47)
The other 10 independent components of Riemann are contained in the Weyl curva-
ture tensor:
Weyl tensor
Cμν
ρσ = Rμν
ρσ −2g[μ
[ρ Rν]
σ] + 1
3
g[μ
[ρ gν]
σ] R.
(25.48)
Here the square brackets denote antisymmetrization, A[αβ] ≡1
2(Aαβ −Aβα), and R
scalar curvature
is the contraction of the Ricci tensor on its two slots,
R ≡Rα
α,
(25.49)
and is called thecurvature scalar or scalar curvature.The Weyl curvature tensorCμνρσ
has vanishing contraction on every pair of slots and has the same symmetries as the
Riemann tensor; Ex. 25.12.
components of Riemann
tensor in an arbitrary basis
One often needs to know the components of the Riemann curvature tensor in
some non-local-Lorentz basis. Exercise 25.11 derives the following equation for them
in an arbitrary basis:
Rα
βγ δ = α
βδ,γ −α
βγ ,δ + α
μγμ
βδ −α
μδμ
βγ −α
βμcγ δ
μ.
(25.50)
Here αβγ are the connection coefﬁcients in the chosen basis; αβγ ,δ is the re-
sult of letting the basis vector ⃗eδ act as a differential operator on αβγ, as though
αβγ were a scalar; and cγ δμ are the basis vectors’ commutation coefﬁcients. Calcu-
lations with this equation are usually long and tedious, and so are carried out using
symbolic-manipulation software on a computer. See, for example, the simple Math-
ematica program (specialized to a coordinate basis) in Hartle (2003, Appendix C),
also available on that textbook’s website: http://web.physics.ucsb.edu/~gravitybook/
mathematica.html.
EXERCISES
Exercise 25.10 Example: Orders of Magnitude for the Radius
of Curvature of Spacetime
With the help of the Newtonian limit (25.35) of the Riemann curvature tensor, show
that near Earth’s surface the radius of curvature of spacetime has a magnitude R ∼(1
astronomical unit) ≡(distance from the Sun to Earth). What is the radius of curvature
of spacetime near the Sun’s surface? Near the surface of a white-dwarf star? Near
the surface of a neutron star? Near the surface of a one-solar-mass black hole? In
intergalactic space?
Exercise 25.11 Derivation: Components of the Riemann Tensor in an Arbitrary Basis
By evaluating expression (25.30) in an arbitrary basis (which might not even be a
coordinate basis), derive Eq. (25.50) for the components of the Riemann tensor.
In your derivation keep in mind that commas denote partial derivations only in a
25.6 Properties of the Riemann Curvature Tensor
1215

coordinate basis; in an arbitrary basis they denote the result of letting a basis vector
act as a differential operator [cf. Eq. (24.34)].
Exercise 25.12 Derivation: Weyl Curvature Tensor
Show that the Weyl curvature tensor (25.48) has vanishing contraction on all its slots
and has the same symmetries as Riemann: Eqs. (25.45). From these properties, show
that Weyl has just 10 independent components. Write the Riemann tensor in terms
of the Weyl tensor, the Ricci tensor, and the scalar curvature.
Exercise 25.13 Problem: Curvature of the Surface of a Sphere
On the surface of a sphere, such as Earth, introduce spherical polar coordinates in
which the metric, written as a line element, takes the form
ds2 = a2(dθ2 + sin2 θdφ2),
(25.51)
where a is the sphere’s radius.
(a) Show (ﬁrst by hand and then by computer) that the connection coefﬁcients for
the coordinate basis {∂/∂θ, ∂/∂φ} are
θ
φφ = −sin θ cos θ,
φ
θφ = φ
φθ = cot θ,
all others vanish.
(25.52a)
(b) Show that the symmetries (25.45) of the Riemann tensor guarantee that its only
nonzero components in the above coordinate basis are
Rθφθφ = Rφθφθ = −Rθφφθ = −Rφθθφ.
(25.52b)
(c) Show, ﬁrst by hand and then by computer, that
Rθφθφ = a2 sin2 θ.
(25.52c)
(d) Show that in the basis
{⃗e ˆθ, ⃗e ˆφ} =
, 1
a
∂
∂θ ,
1
a sin θ
∂
∂φ
-
,
(25.52d)
the components of the metric, the Riemann tensor, the Ricci tensor, the curvature
scalar, and the Weyl tensor are
g ˆj ˆk = δjk,
R ˆθ ˆφ ˆθ ˆφ = 1
a2 ,
R ˆj ˆk = 1
a2g ˆj ˆk,
R = 2
a2 ,
C ˆθ ˆφ ˆθ ˆφ = 0,
(25.52e)
respectively. The ﬁrst of these implies that the basis is orthonormal; the rest
imply that the curvature is independent of location on the sphere, as it should
be by spherical symmetry. [The θ dependence in the coordinate components
of Riemann, Eq. (25.52c), like the θ dependence in the metric component gφφ,
is a result of the θ dependence in the length of the coordinate basis vector ⃗eφ:
|⃗eφ| = a sin θ.]
1216
Chapter 25. Fundamental Concepts of General Relativity

Exercise 25.14 Problem: Geodesic Deviation on a Sphere
Consider two neighboring geodesics (great circles) on a sphere of radius a, one the
equator and the other a geodesic slightly displaced from the equator (by θ = b) and
parallel to it at φ = 0. Let ⃗ξ be the separation vector between the two geodesics, and
note that at φ = 0, ⃗ξ = b∂/∂θ. Let l be proper distance along the equatorial geodesic,
so d/dl = ⃗u is its tangent vector.
(a) Show that l = aφ along the equatorial geodesic.
(b) Show that the equation of geodesic deviation (25.31) reduces to
d2ξθ
dφ2 = −ξθ,
d2ξφ
dφ2 = 0.
(25.53)
(c) Solve Eq. (25.53), subject to the above initial conditions, to obtain
ξθ = b cos φ,
ξφ = 0.
(25.54)
Verify, by drawing a picture, that this is precisely what one would expect for the
separation vector between two great circles.
25.7
25.7 Delicacies in the Equivalence Principle, and Some Nongravitational
Laws of Physics in Curved Spacetime
Suppose that one knows a local, special relativistic, nongravitational law of physics
in geometric, frame-independent form—for example, the expression for the stress-
energy tensor of a perfect ﬂuid in terms of its 4-velocity ⃗u and its rest-frame mass-
energy density ρ and pressure P:
TTT = (ρ + P )⃗u ⊗⃗u + P ggg
(25.55)
[Eq. (24.51)]. Then the equivalence principle guarantees that in general relativity this
law will assume the same geometric, frame-independent form. One can see that this is
so by the same method as we used to derive the general relativistic equation of motion
∇⃗p ⃗p = 0 for free particles [Eq. (25.11c) and associated discussion]:
1. RewritethespecialrelativisticlawintermsofcomponentsinaglobalLorentz
frame [T αβ = (ρ + P)uαuβ + P gαβ].
2. Infer from the equivalence principle that this same component form of the
law will hold, unchanged, in a local Lorentz frame in general relativity.
3. Deduce that this component law is the local-Lorentz-frame version of the
original geometric law [TTT = (ρ + P )⃗u ⊗⃗u + P ggg], now lifted into general
relativity.
25.7 Curvature Coupling Delicacies in the Equivalence Principle
1217

Thus, when the local, nongravitational laws of physics are known in frame-
equivalence principle
implies that local
nongravitational laws
are the same in general
relativity as in special
relativity
independent form, one need not distinguish between whether they are special rel-
ativistic or general relativistic.
In this conclusion the word local is crucial. The equivalence principle is strictly
valid only at the spatial origin of a local Lorentz frame; correspondingly, it is in
danger of failure for any law of physics that cannot be formulated solely in terms
of quantities that reside at the spatial origin (i.e., along a timelike geodesic). For the
above example, TTT = (ρ + P )⃗u ⊗⃗u + P ggg, there is no problem; and for the local law of
examples of the inﬂuence
of spacetime curvature on
nonlocal laws:
4-momentum conservation, ⃗∇. TTT = 0, there is no problem. However, for the global
law of 4-momentum conservation

∂V
T αβdβ = 0
(25.56)
[Eq. (2.71) and Fig. 2.11], there is serious trouble. This law is severely nonlocal,
since it involves integration over a ﬁnite, closed 3-surface ∂V in spacetime. Thus the
equivalence principle fails for it. The failure shows up especially clearly when one
notices (as we discussed in Sec. 24.3.4) that the quantity T αβdβ, which the integral
is trying to add up over ∂V, has one empty slot, named α (i.e., it is a vector). This
means that, to compute the integral (25.56), we must transport the contributions
T αβdβ from the various tangent spaces in which they normally live to the tangent
space of some single, agreed-on location, where they are to be added. The result of that
transport depends on the route used, and in general no preferred route is available.
As a result, the integral (25.56) is ill deﬁned, and in general relativity we lose the
no global conservation of
4-momentum in general
relativity, generically
global conservation law for 4-momentum!—except in special situations, one of which
is discussed in Sec. 25.9.5.
25.7.1
25.7.1 Curvature Coupling in the Nongravitational Laws
Another instructive example is the law by which a freely moving particle transports
its spin angular momentum. The spin angular momentum is readily deﬁned in the
instantaneous local Lorentz rest frame of the particle’s center of mass; there it is a
4-vector ⃗S with vanishing time component (so ⃗S is orthogonal to the particle’s 4-
velocity), with space components given by the familiar integral
Si =

interior of body
ϵijkxjT k0 dV ,
(25.57)
where the T k0 are components of the momentum density. In special relativity, the
law of angular momentum conservation (e.g., Misner, Thorne, and Wheeler, 1973,
Sec. 5.11) guarantees that the Lorentz-frame components Sα of this spin angular
momentum remain constant, so long as no external torques act on the particle. This
conservation law can be written in special relativistic, frame-independent notation as
Eq. (24.62), specialized to a nonaccelerated particle:
∇⃗u ⃗S = 0;
(25.58)
1218
Chapter 25. Fundamental Concepts of General Relativity

that is, the spin vector ⃗S is parallel-transported along the world line of the freely falling
particle (which has 4-velocity ⃗u). If this were a local law of physics, it would take
this same form, unchanged, in general relativity (i.e., in curved spacetime). Whether
the law is local or not clearly depends on the size of the particle. If the particle is
vanishingly small in its own rest frame, then the law is local, and Eq. (25.58) will be
valid in general relativity. However, if the particle has ﬁnite size, the law (25.58) is in
danger of failing—and, indeed, it does fail if the particle’s ﬁnite size is accompanied by
a ﬁnite quadrupole moment. In that case, the coupling of the quadrupole moment Iαβ
to the curvature of spacetime Rαβγ δ produces a torque on the “particle,” so Eq. (25.58)
acquires a driving term on the right-hand side:
Sα
;μuμ = ϵαβγ δIβμRμ
νγ ζuδuνuζ;
(25.59)
see Ex. 25.16. Earth is a good example: the Riemann tensor Rαβγ δ produced at Earth
tidally induced precession
of Earth’s spin axis
bytheMoonandtheSuncouplestoEarth’scentrifugal-ﬂattening-inducedquadrupole
moment Iμν. The resulting torque (25.59) causes Earth’s spin axis to precess relative
to the distant stars, with a precession period of 26,000 years—sufﬁciently fast to show
up clearly in historical records5 as well as in modern astronomical measurements.
This example illustrates the fact that, if a small amount of nonlocality is present in
a physical law, then, when lifted from special relativity into general relativity, the law
may acquire a small curvature-coupling modiﬁcation.
What is the minimum amount of nonlocality that can produce curvature-coupling
modiﬁcations in physical laws? As a rough rule of thumb, the minimum amount is
double gradients. Because the connection coefﬁcients vanish at the origin of a local
Lorentz frame, the local Lorentz components of a single gradient are the same as
the components in a global Lorentz frame (e.g., Aα;β = ∂Aα/∂xβ). However, because
spacetime curvature prevents the spatial derivatives of the connection coefﬁcients
from vanishing at the origin of a local Lorentz frame, any law that involves double
double gradients as
a source of curvature
coupling in physical laws
gradients is in danger of acquiring curvature-coupling corrections when lifted into
general relativity. As an example, it turns out that the vacuum wave equation for the
electromagnetic vector 4-potential, which in Lorenz gauge (Jackson, 1999, Sec. 6.3)
takes the form Aα;μμ = 0 in ﬂat spacetime, becomes in curved spacetime:
example: curvature
coupling in wave equation
for electromagnetic
4-potential
Aα;μ
μ = RαμAμ,
(25.60)
where Rαμ is the Ricci curvature tensor; see Ex. 25.15. [In Eq. (25.60)—and always—
all indices that follow the semicolon represent differentiation slots: Aα;μμ ≡Aα;μ;μ .]
curvature-coupling
ambiguities in general
relativity are analogous
to factor-ordering
ambiguities in the
quantum mechanical
correspondence principle
The curvature-coupling ambiguities that occur when one lifts slightly nonlocal
laws from special relativity into general relativity using the equivalence principle are
very similar to “factor-ordering ambiguities” that occur when one lifts a hamilto-
nian from classical mechanics into quantum mechanics using the correspondence
5.
Forexample, Earth’snorthpoledidnotpointtowardthestarPolarisintheeraoftheancientEgyptianciv-
ilization. Hipparchus of Nicaea discovered this precession in 127 BC by comparing his own observations
of the stars with those of earlier astronomers.
25.7 Curvature Coupling Delicacies in the Equivalence Principle
1219

principle. In the case of the equivalence principle, the curvature coupling can be re-
garded as stemming from double gradients that commute in special relativity but do
not commute in general relativity. In the case of the correspondence principle, the
factor-ordering difﬁculties result because quantities that commute classically (e.g.,
position x and momentum p) do not commute quantum mechanically (ˆx ˆp ̸= ˆp ˆx),
so when the products of such quantities appear in a classical hamiltonian one does
not know, a priori, their correct order in the quantum hamiltonian [does xp become
ˆx ˆp, or ˆp ˆx, or 1
2(ˆx ˆp + ˆp ˆx)?]. (However, in each case, general relativity or quantum
mechanics, the true curvature coupling or true factor ordering is unambiguous. The
ambiguity is solely in the prescription for deducing it via the equivalence principle or
the correspondence principle.)
EXERCISES
Exercise 25.15 Example and Derivation: Curvature Coupling
in the Electromagnetic Wave Equation
Since Maxwell’s equations, written in terms of the classically measurable electromag-
netic ﬁeld tensor FFF [Eqs. (2.48)] involve only single gradients, it is reasonable to
expect them to be lifted into curved spacetime without curvature-coupling additions.
Assume this is true. It can be shown that: (i) if one writes the electromagnetic ﬁeld
tensor FFF in terms of a 4-vector potential ⃗A as
Fαβ = Aβ;α −Aα;β,
(25.61)
then half of the curved-spacetime Maxwell equations, Fαβ;γ + Fβγ ;α + Fγ α;β = 0
[the second of Eqs. (2.48)] are automatically satisﬁed; (ii) FFF is unchanged by gauge
transformations in which a gradient is added to the vector potential, ⃗A →⃗A + ⃗∇ψ;
and (iii) by such a gauge transformation one can impose the Lorenz-gauge condition
⃗∇. ⃗A = 0 on the vector potential.
Show that, when the charge-current 4-vector vanishes, ⃗J = 0, the other half of the
Maxwell equations, F αβ;β = 0 [the ﬁrst of Eqs. (2.48)] become, in Lorenz gauge and
in curved spacetime, the wave equation with curvature coupling [Eq. (25.60)].
Exercise 25.16 Example and Derivation: Curvature-Coupling Torque
(a) In the Newtonian theory of gravity, consider an axisymmetric, spinning body
(e.g., Earth) with spin angular momentum Sj and time-independent mass dis-
tribution ρ(x), interacting with an externally produced tidal gravitational ﬁeld
Ejk (e.g., that of the Sun and the Moon). Show that the torque around the body’s
center of mass, exerted by the tidal ﬁeld, and the resulting evolution of the body’s
spin are
dSi
dt = −ϵijkIjlEkl.
(25.62)
Here
Ikl =

ρ

xkxl −1
3r2δkl

dV
(25.63)
1220
Chapter 25. Fundamental Concepts of General Relativity

is the body’s mass quadrupole moment, with r = δijxixj the distance from the
center of mass.
(b) For the centrifugally ﬂattened Earth interacting with the tidal ﬁelds of the Moon
and the Sun, estimate in order of magnitude the spin-precession period produced
by this torque. [The observed precession period is 26,000 years.]
(c) Show that when rewritten in the language of general relativity, and in frame-
independent, geometric language, Eq. (25.62) takes the form (25.59) discussed
in the text. As part of showing this, explain the meaning of Iβμ in that equation.
For a derivation and discussion of this relativistic curvature-coupling torque when the
spinning body is a black hole rather than a Newtonian body, see, for example, Thorne
and Hartle (1985).
25.8
25.8 The Einstein Field Equation
One crucial issue remains to be studied in this overview of the foundations of general
relativity: What is the physical law that determines the curvature of spacetime? Ein-
stein’s search for that law, his Einstein ﬁeld equation, occupied a large fraction of his
efforts during the years 1913, 1914, and 1915. Several times he thought he had found
it, but each time his proposed law turned out to be fatally ﬂawed; for some ﬂavor of
his struggle, see the excerpts from his writings in Misner, Thorne, and Wheeler (1973,
Sec. 17.7).
In this section, we brieﬂy examine one segment of Einstein’s route toward his ﬁeld
equation: the segment motivated by contact with Newtonian gravity.
The Newtonian potential  is a close analog of the general relativistic spacetime
Newtonian gravity
metric ggg. From  we can deduce everything about Newtonian gravity, and from ggg we
can deduce everything about spacetime curvature. In particular, by differentiating 
twice we can obtain the Newtonian tidal ﬁeld E [Eq. (25.24)], and by differentiating
the components of ggg twice we can obtain the components of the relativistic gener-
alization of E: the Riemann curvature tensor [Eq. (25.44) in a local Lorentz frame;
Eq. (25.50) in an arbitrary basis].
In Newtonian gravity,  is determined by Newton’s ﬁeld equation
∇2 = 4πGρ,
(25.64)
which can be rewritten in terms of the tidal ﬁeld, Ejk = ∂2/∂xj∂xk, as
Ej
j = 4πGρ.
(25.65)
Note that this equates a piece of the tidal ﬁeld—its contraction or trace—to the density
of mass. By analogy we can expect the Einstein ﬁeld equation to equate a piece of the
deducing the Einstein ﬁeld
equation from Newtonian
gravity
Riemann curvature tensor (the analog of the Newtonian tidal ﬁeld) to some tensor
analog of the Newtonian mass density. Further guidance comes from the demand that
in nearly Newtonian situations (e.g., in the solar system), the Einstein ﬁeld equation
25.8 The Einstein Field Equation
1221

should reduce to Newton’s ﬁeld equation. To exploit that guidance, we can (i) write the
Newtonian tidal ﬁeld for nearly Newtonian situations in terms of general relativity’s
Riemann tensor, Ejk = Rj0k0 [Eq. (25.35); valid in a local Lorentz frame], (ii) then
take the trace and note that by its symmetries R0000 = 0 so that Ejj = Rα0α0 = R00,
and (iii) thereby infer that the Newtonian limit of the Einstein equation should read,
in a local Lorentz frame:
R00 = 4πGρ.
(25.66)
Here R00 is the time-time component of the Ricci curvature tensor, which can be
regarded as a piece of the Riemann tensor. An attractive proposal for the Einstein ﬁeld
equation should now be obvious. Since the equation should be geometric and frame
independent, andsinceitmusthavetheNewtonianlimit(25.66), itpresumablyshould
say Rαβ = 4πG×(a second-rank symmetric tensor that generalizes the Newtonian
mass density ρ). The obvious generalization of ρ is the stress-energy tensor Tαβ, so a
candidate is
a failed ﬁeld equation
Rαβ = 4πGTαβ.
(25.67)
Einstein ﬂirted extensively with this proposal for the ﬁeld equation during 1913–
1915. However, it, like several others he studied, was fatally ﬂawed. When expressed in
a coordinate system in terms of derivatives of the metric components gμν, it becomes
(because Rαβ and Tαβ both have 10 independent components) 10 independent dif-
ferential equations for the 10 gμν. This is too many equations. By an arbitrary change
of coordinates, xα
new = F α(x0
old, x1
old, x2
old, x3
old), involving four arbitrary functions F 0,
F 1, F 2, and F 3, one should be able to impose on the metric components four arbitrary
conditions, analogous to gauge conditions in electromagnetism (e.g., one should be
able to set g00 = −1 and g0j = 0 everywhere). Correspondingly, the ﬁeld equations
should constrain only 6, not 10 of the components of the metric (the 6 gij in our
example).
In November 1915, Einstein (1915), and independently Hilbert (1915) [who
was familiar with Einstein’s struggle as a result of private conversations and cor-
respondence] discovered the resolution of this dilemma. Because the local law of
the need for a divergence-
free curvature tensor
4-momentum conservation guarantees T αβ;β = 0 independent of the ﬁeld equation,
if we replace the Ricci tensor in Eq. (25.67) by a constant (to be determined) times
some new curvature tensor Gαβ that is also automatically divergence free indepen-
dently of the ﬁeld equation (Gαβ;β ≡0), then the new ﬁeld equation Gαβ = κT αβ
(with κ = constant) will not constrain all 10 components of the metric. Rather, the
fourequations, (Gαβ −κT αβ);β = 0withα = 0, 1, 2, 3, willautomaticallybesatisﬁed;
they will not constrain the metric components in any way, and only six independent
constraints on the metric components will remain in the ﬁeld equation, precisely the
desired number.
1222
Chapter 25. Fundamental Concepts of General Relativity

It turns out, in fact, that from the Ricci tensor and the scalar curvature one can
construct a curvature tensor Gαβ with the desired property:
Einstein curvature tensor
Gαβ ≡Rαβ −1
2Rgαβ.
(25.68)
Today we call this the Einstein curvature tensor. That it has vanishing divergence,
independently of how one chooses the metric,
Bianchi identity and
contracted Bianchi identity
⃗∇. GGG ≡0,
(25.69)
is called the contracted Bianchi identity, since it can be obtained by contracting the
following Bianchi identity on the tensor ϵαβμνϵνγ δϵ:
Rα
βγ δ;ϵ + Rα
βδϵ;γ + Rα
βϵγ ;δ = 0.
(25.70)
[This Bianchi identity holds true for the Riemann curvature tensor of any and every
manifold (i.e., of any and every smooth space; Ex. 25.17). For an extensive discussion
of the Bianchi identities (25.70) and (25.69) and their geometric interpretation, see
Misner, Thorne, and Wheeler (1973, Chap. 15).]
The Einstein ﬁeld equation should then equate a multiple of T αβ to the Einstein
tensor Gαβ:
Gαβ = κT αβ.
(25.71a)
The proportionality constant κ is determined from the Newtonian limit as follows.
By rewriting the ﬁeld equation (25.71a) in terms of the Ricci tensor
Rαβ −1
2
gαβR = κT αβ,
(25.71b)
then taking the trace to obtain R = −κgμνT μν and inserting this back into (25.71a),
we obtain
Rαβ = κ

T αβ −1
2
gαβgμνT μν

.
(25.71c)
In nearly Newtonian situations and in a local Lorentz frame, the mass-energy density
T 00 ∼= ρ is far greater than the momentum density T j0 and is also far greater than the
stress T jk. Correspondingly, the time-time component of the ﬁeld equation (25.71c)
becomes
R00 = κ

T 00 −1
2η00η00T 00

= 1
2κT 00 = 1
2κρ.
(25.71d)
By comparing with the correct Newtonian limit (25.66) and noting that in a local
Lorentz frame R00 = R00, we see that κ = 8πG, whence the Einstein ﬁeld equation is
Einstein ﬁeld equation
Gαβ = 8πGT αβ.
(25.72)
25.8 The Einstein Field Equation
1223

EXERCISES
Exercise 25.17 Derivation and Example: Bianchi Identities
(a) Derive the Bianchi identity (25.70) in 4-dimensional spacetime. [Hint: (i) Intro-
duce a local Lorentz frame at some arbitrary event. (ii) In that frame show, from
Eq. (25.50), that the components Rαβγ δ of Riemann have the form of Eq. (25.44)
plus corrections that are quadratic in the distance from the origin. (iii) Compute
the left-hand side of Eq. (25.70), with index α down, at the origin of that frame,
and show that it is zero. (iv) Then argue that because the origin of the frame was an
arbitrary event in spacetime, and because the left-hand side of Eq. (25.70) is an ar-
bitrary component of a tensor, the left-hand side viewed as a frame-independent
geometric object must vanish at all events in spacetime.]
(b) By contracting the Bianchi identity (25.70) on ϵαβμνϵνγ δϵ, derive the contracted
Bianchi identity (25.69).
These derivations are easily generalized to an arbitrary manifold with any dimen-
sion by replacing the 4-dimensional local Lorentz frame by a locally orthonormal
coordinate system (cf. the third and fourth paragraphs of Sec. 24.3.3).
25.8.1
25.8.1 Geometrized Units
By now the reader should be accustomed to our use of geometrized units in which
the speed of light is unity. Just as setting c = 1has simpliﬁed greatly the mathematical
notation in Chaps. 2 and 24, so also subsequent notation is greatly simpliﬁed if we
set Newton’s gravitation constant G to unity. This further geometrization of our units
corresponds to equating mass units to length units via the relation
geometrized units: setting
Newton’s gravitational
constant to one
1 = G
c2 = 7.426 × 10−28 m kg−1;
so
1 kg = 7.426 × 10−28 m.
(25.73)
Any equation can readily be converted from conventional units to geometrized units
by removing all factors of c and G; it can readily be converted back by inserting what-
ever factors of c and G one needs to make both sides of the equation dimensionally
the same. Table 25.1 lists a few important numerical quantities in both conventional
units and geometrized units.
In geometrized units, the Einstein ﬁeld equation (25.72) assumes the following
standard form, to which we appeal extensively in the three coming chapters:
the Einstein ﬁeld equation
in geometrized units
Gαβ = 8πT αβ;
or
GGG = 8πTTT .
(25.74)
25.9
25.9 Weak Gravitational Fields
All the foundations of general relativity are now in our hands. In this concluding sec-
tionofthechapter, weexploretheirpredictionsforthepropertiesofweakgravitational
1224
Chapter 25. Fundamental Concepts of General Relativity

TABLE 25.1: Some useful quantities in conventional and geometrized units
Quantity
Conventional units
Geometrized units
Speed of light, c
2.998 × 108 m sec−1
one
Newton’s gravitation constant, G
6.674 × 10−11 m3 kg−1 s−2
one
G/c2
7.426 × 10−28 m kg−1
one
c5/G
3.628 × 1052 W
one
Planck’s reduced constant ℏ
1.055 × 10−34 kg m2 s−1
(1.616 × 10−35 m)2
Sun’s mass, M⊙
1.989 × 1030 kg
1.477 km
Sun’s radius, R⊙
6.957 × 108 m
6.957 × 108 m
Earth’s mass, M⊕
5.972 × 1024 kg
4.435 mm
Earth’s mean radius, R⊕
6.371 × 106 m
6.371 × 106 m
Note: 1 Mpc = 106 parsecs (pc), 1 pc = 3.262 light-years (lt-yr), 1 lt-yr = 0.9461 × 1016 m, 1 AU = 1.496 ×
1011 m. For other useful astronomical constants, see Cox (2000).
ﬁelds, beginning with the Newtonian limit of general relativity and then moving on
to other situations.
25.9.1
25.9.1 Newtonian Limit of General Relativity
Ageneralrelativisticgravitationalﬁeld(spacetimecurvature)issaidtobeweak ifthere
exist “nearly globally Lorentz” coordinate systems in which the metric coefﬁcients
differ only slightly from unity:
gαβ = ηαβ + hαβ,
with |hαβ| ≪1.
(25.75a)
The Newtonian limit requires that gravity be weak in this sense throughout the system
conditions required for
general relativity to
become Newton’s theory
of gravity (the Newtonian
limit)
being studied. It further requires a slow-motion constraint, which has three aspects:
1. The sources of gravity must have slow enough motions that the following
holds for some speciﬁc choice of the nearly globally Lorentz coordinates:
|hαβ,t| ≪|hαβ,j|;
(25.75b)
2. the sources’ motions must be slow enough that in this frame the momentum
density is very small compared to the energy density:
|T j0| ≪T 00 ≡ρ;
(25.75c)
3. and any particles on which the action of gravity is to be studied must move
with low velocities, so they must have 4-velocities satisfying
|uj| ≪u0.
(25.75d)
25.9 Weak Gravitational Fields
1225

Finally, the Newtonian limit requires that the stresses in the gravitating bodies be
small compared to their mass densities:
|T jk| ≪T 00 ≡ρ.
(25.75e)
When conditions (25.75) are all satisﬁed, then to leading nontrivial order in the small
dimensionlessquantities|hαβ|, |hαβ,t|/|hαβ,j|, |T j0|/T 00, |uj|/u0, and|T jk|/T 00 the
laws of general relativity reduce to those of Newtonian theory.
The details of this reduction are an exercise for the reader (Ex. 25.18); here we give
an outline.
details of the Newtonian
limit:
The low-velocity constraint |uj|/u0 ≪1 on the 4-velocity of a particle, together
with its normalization uαuβgαβ = −1 and the near ﬂatness of the metric (25.75a),
implies that
u0 ∼= 1, uj ∼= vj ≡dxj
dt .
(25.76)
Since u0 = dt/dτ, the ﬁrst of these relations implies that in our nearly globally Lorentz
coordinate system the coordinate time is very nearly equal to the proper time of
our slow-speed particle. In this way, we recover the “universal time” of Newtonian
theory. The universal, Euclidean space is that of our nearly Lorentz frame, with
hμν completely ignored because of its smallness. The universal time and universal
Euclidean space become the arena in which Newtonian physics is formulated.
Equation(25.76)for the componentsofa particle’s4-velocity, together with|vj| ≪
1 and |hμν| ≪1, imply that the geodesic equation for a freely moving particle to
leading nontrivial order is
dvj
dt
∼= 1
2
∂h00
∂xj ,
where d
dt ≡∂
∂t + v . ∇.
(25.77)
(Because our spatial coordinates are Cartesian, we can put the spatial index j up on
one side of the equation and down on the other without creating any danger of error.)
By comparing Eq. (25.77) with Newton’s equation of motion for the particle, we
deduce that h00 must be related to the Newtonian gravitational potential by
h00 = −2,
(25.78)
so the spacetime metric in our nearly globally Lorentz coordinate system must be
spacetime metric in the
Newtonian limit
ds2 = −(1 + 2)dt2 + (δjk + hjk)dxjdxk + 2h0jdt dxj.
(25.79)
Because gravity is weak, only those parts of the Einstein tensor that are linear in
hαβ are signiﬁcant; quadratic and higher-order contributions can be ignored. Now,
by the same mathematical steps as led us to Eq. (25.44) for the components of the
Riemann tensor in a local Lorentz frame, one can show that the components of
1226
Chapter 25. Fundamental Concepts of General Relativity

the linearized Riemann tensor in our nearly global Lorentz frame have that same form
(i.e., setting gαβ = ηαβ + hαβ):
Rαβγ δ = 1
2(hαδ,βγ + hβγ ,αδ −hαγ ,βδ −hβδ,αγ).
(25.80)
From this equation and the slow-motion constraint |hαβ,t| ≪|hαβ,j|, we infer that
the space-time-space-time components of Riemann are
tidal gravity in the
Newtonian limit
Rj0k0 = −1
2h00,jk = ,jk = Ejk.
(25.81)
In the last step we have used Eq. (25.78). We have thereby recovered the relation
between the Newtonian tidal ﬁeld Ejk ≡,jk and the relativistic tidal ﬁeld Rj0k0.
That relation can now be used, via the train of arguments in the preceding section, to
show that the Einstein ﬁeld equation, Gμν = 8πT μν, reduces to the Newtonian ﬁeld
equation, ∇2 = 4πT 00 ≡4πρ.
This analysis leaves the details of h0j and hjk unknown, because the Newtonian
limit is insensitive to them.
EXERCISES
Exercise 25.18 Derivation: Newtonian Limit of General Relativity
Consider a system that can be covered by nearly globally Lorentz coordinates in which
the Newtonian-limit constraints (25.75) are satisﬁed. For such a system, ﬂesh out
the details of the text’s derivation of the Newtonian limit. More speciﬁcally, do the
following.
(a) Derive Eq. (25.76) for the components of the 4-velocity of a particle.
(b) Show that the geodesic equation reduces to Eq. (25.77).
(c) Show that to linear order in the metric perturbation hαβ, the components of the
Riemann tensor take the form of Eq. (25.80).
(d) Show that in the slow-motion limit the space-time-space-time components of
Riemann take the form of Eq. (25.81).
25.9.2
25.9.2 Linearized Theory
details of linearized theory
(weak-gravity limit of
general relativity):
There are many systems in the universe that have weak gravity [Eq. (25.75a)], but
for which the slow-motion approximations (25.75b)–(25.75d) and/or weak-stress
approximation (25.75e) fail. Examples are high-speed particles and electromagnetic
ﬁelds. For such systems, we need a generalization of Newtonian theory that drops the
spacetime metric and
metric perturbation
slow-motion and weak-stress constraints but keeps the weak-gravity constraint:
gαβ = ηαβ + hαβ,
with |hαβ| ≪1.
(25.82)
25.9 Weak Gravitational Fields
1227

The obvious generalization is a linearization of general relativity in hαβ, with no
other approximations being made—the so-called linearized theory of gravity. In this
subsection we develop it.
In formulating linearized theory we can regard the metric perturbation hμν as a
gravitational ﬁeld that lives in ﬂat spacetime, and correspondingly, we can carry out
our mathematics as though we were in special relativity. In other words, linearized
theory can be regarded as a ﬁeld theory of gravity in ﬂat spacetime—a variant of the
type of theory that Einstein toyed with and then rejected (Sec. 25.1).
In linearized theory, the Riemann tensor takes the form of Eq. (25.80), but we have
no right to simplify it further to the form of Eq. (25.81), so we must follow a different
route to the linearized Einstein ﬁeld equation.
Contracting the ﬁrst and third indices in Eq. (25.80), we obtain an expression for
the linearized Ricci tensor Rμν in terms of hαβ. Contracting once again, we obtain the
scalar curvature R, and then from Eq. (25.68) we obtain for the Einstein tensor and
the Einstein ﬁeld equation:
linearized Einstein ﬁeld
equation
2Gμν = hμα,ν
α + hνα,μ
α −hμν,α
α −h,μν −ημν(hαβ
,αβ −h,α
α)
= 16πTμν.
(25.83)
Here all indices, subscript or superscript, that follow the comma are partial-derivative
indices [e.g., h,β
β = (∂2h/∂xβ∂xα)ηαβ], and
h ≡ηαβhαβ
(25.84)
is the “trace” of the metric perturbation. We can simplify the ﬁeld equation (25.83) by
reexpressing it in terms of the quantity
trace-reversed metric
perturbation
¯hμν ≡hμν −1
2hημν.
(25.85)
One can easily check that this quantity has the opposite trace to that of hμν (¯h ≡
¯hαβηαβ = −h), so it is called the trace-reversed metric perturbation. In terms of it, the
ﬁeld equation (25.83) becomes
−¯hμν,α
α −ημν ¯hαβ,
αβ + ¯hμα,ν
α + ¯hνα,μ
α = 16πTμν.
(25.86)
We can simplify this ﬁeld equation further by specializing our coordinates. We
introduce a new nearly globally Lorentz coordinate system that is related to the old
one by
inﬁnitesimal coordinate
transformation (gauge
change)
xα
new(P) = xα
old(P) + ξα(P),
(25.87)
where ξα is a small vectorial displacement of the coordinate grid. This change of
coordinates via four arbitrary functions (α = 0, 1, 2, 3) produces a change of the
functional form of the metric perturbation hαβ to
inﬂuence of gauge change
on metric perturbation
hnew
μν = hold
μν −ξμ,ν −ξν,μ
(25.88)
1228
Chapter 25. Fundamental Concepts of General Relativity

(Ex. 25.19), and a corresponding change of the trace-reversed metric perturbation.
This is linearized theory’s analog of a gauge transformation in electromagnetic the-
ory. Just as an electromagnetic gauge change generated by a scalar ﬁeld ψ alters the
vector potential, Anew
μ
= Aold
μ −ψ,μ, so the linearized-theory gauge change gener-
ated by ξα alters hμν and ¯hμν; and just as the force-producing electromagnetic ﬁeld
tensor Fμν is unaffected by an electromagnetic gauge change, so the tidal-force-
producing linearized Riemann tensor is left unaffected by the gravitational gauge
change (Ex. 25.19).
By a special choice of the four functions ξα (Ex. 25.19), we can impose the follow-
ing four gauge conditions on ¯hμν:
gravitational Lorenz gauge
condition
¯hμν,
ν = 0.
(25.89)
These are linearized theory’s analog of the electromagnetic Lorenz gauge condition
Aμ,
μ = 0, so they are called the gravitational Lorenz gauge. Just as the ﬂat-spacetime
Maxwell equations take the remarkably simple wave-equation form Aμ,α
α = 4πJμ in
Lorenz gauge, so also the linearized Einstein equation (25.86) takes the corresponding
simple wave-equation form in gravitational Lorenz gauge:
linearized Einstein ﬁeld
equation in Lorenz gauge
−¯hμν,α
α = 16πTμν.
(25.90)
By the same method as one uses in electromagnetic theory (e.g., Jackson, 1999,
Sec. 6.4), one can solve this gravitational ﬁeld equation for the ﬁeld ¯hμν produced by
an arbitrary stress-energy-tensor source:
Lorenz-gauge trace-
reversed metric
perturbation as retarded
integral over stress-energy
tensor
¯hμν(t, x) =
 4Tμν(t −|x −x′|, x′)
|x −x′|
dVx′.
(25.91)
The quantity in the numerator is the stress-energy source evaluated at the “retarded
time” t′ = t −|x −x′|. This equation for the ﬁeld, and the wave equation (25.90) that
underlies it, show explicitly that dynamically changing distributions of stress-energy
must generate gravitational waves, which propagate outward from their source at the
speed of light (Einstein, 1916b; Einstein, 1918). We study these gravitational waves in
Chap. 27.
EXERCISES
Exercise 25.19 Derivation: Gauge Transformations in the Linearized Theory
(a) Show that the “inﬁnitesimal” coordinate transformation (25.87) produces the
change (25.88) of the linearized metric perturbation and that it leaves the Rie-
mann tensor (25.80) unchanged.
(b) Exhibit a differential equation for the ξα that brings the metric perturbation into
gravitational Lorenz gauge [i.e., that makes hnew
μν obey the Lorenz gauge condition
(25.89)].
25.9 Weak Gravitational Fields
1229

particle’s
world line
O
P
→p
k
→
FIGURE 25.4 The past light cone of an observation event O,
the world line of a particle, and two 4-vectors: the particle’s 4-
momentum ⃗p at the point P where it passes through O’s past
light cone, and the past-directed null vector ⃗k that reaches
from O to P.
(c) Show that in gravitational Lorenz gauge, the Einstein ﬁeld equation (25.86) re-
duces to Eq. (25.90).
Exercise 25.20 Example: Gravitational Field of a Rapidly Moving Particle
In this exercise we illustrate linearized theory by computing the gravitational ﬁeld of
a moving particle with ﬁnite rest mass and then that of a zero-rest-mass particle that
moves with the speed of light.
(a) From Eq. (25.91), deduce that, for a particle with mass M at rest at the origin, the
only nonvanishing component of ¯hμν is ¯h00 = 4M/r.
(b) Regarding ¯hμν as a ﬁeld that lives in ﬂat spacetime, show that it can be written in
frame-independent, special relativistic form as
¯hμν = 4pμpν
⃗k . ⃗p
,
(25.92)
where ⃗p is the particle’s 4-momentum, and ⃗k is the past-directed null vector that
reaches from the observation event O to the event P at which the particle’s world
line passes through the observer’s past light cone; see Fig. 25.4. Equation (25.92)
is a very powerful formula. It is an explicit form of the solution (25.91) to the wave
equation (25.90) not only for a particle that moves inertially (and thus could be at
rest in our original reference frame) but also for an arbitrarily accelerated particle.
Explain why.
(c) In the Lorentz rest frame of the observer, let the particle move along the x-
axis with speed v, so its world line is {x = vt, y = z = 0}, and its 4-momentum
has components p0 = Mγ and px = Mvγ , with γ = 1/
√
1 −v2. Show that,
expressed in terms of the observation event’s coordinates (t, x, y, z),
⃗k . ⃗p = γ MR,
where R =

(1 −v2)(y2 + z2) + (x −vt)2.
(25.93)
1230
Chapter 25. Fundamental Concepts of General Relativity

Show, further, that the linearized spacetime metric is
ds2 =

1 + 2M
γ R

(−dt2 + dx2 + dy2 + dz2) + 4γ M
R
(dt −vdx)2.
(25.94)
(d) Take the limit of a zero-rest-mass particle moving at the speed of light by send-
ing m →0, v →1, and Mγ →E (the particle’s energy). [The limit of 1/R =
1/

(1 −v2)(y2 + z2) + (x −vt)2 is quite tricky. It turns out to be 1/|x −t| −
δ(x −t) ln(y2 + z2), where δ is the Dirac delta function (Aichelberg and Sexl,
1971).] Show that the resulting metric is
ds2 = −dt2 + dx2 + dy2 + dz2
+ 4E

1
|x −t| −ln(y2 + z2)δ(x −t)

(dx −dt)2.
By a change of coordinates, get rid of the 1/|x −t| term, thereby obtaining our
ﬁnal form for the metric of a zero-rest-mass particle:
ds2 = −dt2 + dx2 + dy2 + dz2 −4E ln(x2 + y2) δ(x −t)(dx −dt)2.(25.95)
Equation (25.95) turns out to be an exact solution of the fully nonlinear Einstein
ﬁeld equation for a zero-rest-mass particle; it is called the Aichelberg-Sexl ultraboost
solution. Just as, when a charged particle is accelerated to near light speed, its electric
ﬁeld lines are compressed into its transverse plane, so the metric (25.95) has all its
deviations from ﬂat spacetime concentrated in the particle’s transverse plane.
25.9.3
25.9.3 Gravitational Field outside a Stationary, Linearized Source of Gravity
Let us specialize to a time-independent source of weak gravity (so Tμν,t = 0 in our
stationary source of
gravity
chosen nearly globally Lorentz frame) and compute its external gravitational ﬁeld as
a power series in 1/(distance to source). We place our origin of coordinates at the
mass-centered
coordinates
source’s center of mass, so

xjT 00dV = 0,
(25.96)
and in the same manner as in electromagnetic theory, we expand
1
|x −x′| = 1
r + xjxj′
r3
+ . . . ,
(25.97)
where r ≡|x| is the distance of the ﬁeld point from the source’s center of mass.
Inserting Eq. (25.97) into the general solution (25.91) of the Einstein equation and
25.9 Weak Gravitational Fields
1231

taking note of the conservation laws T αj ,j = 0, we obtain for the source’s external
ﬁeld:
trace-reversed metric
perturbation
¯h00 = 4M
r
+ O
 1
r3

,
¯h0j = −
2ϵjkmJ kxm
r3
+ O
 1
r3

,
¯hij = O
 1
r3

.
(25.98a)
Here M and J k are the source’s mass and angular momentum:
source’s mass and angular
momentum
M ≡

T 00dV ,
Jk ≡

ϵkabxaT 0bdV
(25.98b)
(see Ex. 25.21). This expansion in 1/r, as in the electromagnetic case, is a multipolar
expansion. At order 1/r the ﬁeld is spherically symmetric and the monopole moment
is the source’s mass M. At order 1/r2 there is a “magnetic-type dipole moment,” the
source’s spin angular momentum Jk. These are the leading-order moments in two
inﬁnite sets: the “mass multipole” moments (analog of electric moments), and the
“mass-current multipole” moments (analog of magnetic moments). For details on all
the higher-order moments, see, for example, Thorne (1980).
The metric perturbation can be computed by reversing the trace reversal: hαβ =
¯hαβ −ηαβ ¯h. Thereby we obtain for the spacetime metric, gαβ = ηαβ + hαβ, at linear
order, outside the source:
spacetime metric
ds2 = −
2
1 −2M
r
3
dt2 −4ϵjkmJ kxm
r3
dtdxj
+
2
1 + 2M
r
3
δjkdxjdxk + O

1
r3

dxαdxβ
.
(25.98c)
In spherical polar coordinates, with the polar axis along the direction of the source’s
angular momentum, the leading-order terms take the form
ds2 = −
2
1 −2M
r
3
dt2 −4Jr sin2 θdtdφ
+
2
1 + 2M
r
3
(dr2 + r2dθ2 + r2 sin2 θdφ2)
,
(25.98d)
where J ≡|J| is the magnitude of the source’s angular momentum.
reading off the source’s
mass and angular
momentum from its
metric
This is a very important result. It tells us that we can “read off” the mass M and
angular momentum J k from the asymptotic form of the source’s metric. More specif-
ically: (i) The mass M shows up in g00 in just the way we expect from the Newtonian
limit—by comparing Eqs. (25.98c) and (25.79), we see that  = −M/r, and from our
experience with Newtonian gravity, we conclude that M is the mass that governs the
reading off mass from
Keplerian orbits of planets
Keplerian orbits of planets around our gravitational source. (ii) The angular momen-
tum J k shows up in g0j = −(2/r3)ϵjkmJ kxm. The physical manifestation of this g0j
is a gravitational torque on gyroscopes.
1232
Chapter 25. Fundamental Concepts of General Relativity

Consider an inertial-guidance gyroscope whose center of mass is at rest in the
coordinate system of Eq. (25.98c) (i.e., at rest relative to the gravitating source). The
transport law for the gyroscope’s spin is ∇⃗u⃗S = ⃗u(⃗a . ⃗S) [Eq. (24.62) boosted from
special relativity to general relativity via the equivalence principle]. Here ⃗u is the
gyroscope’s 4-velocity (so uj = 0, u0 = 1/√1 −2M/r ≃1 + M/r ≃1), and ⃗a is its
4-acceleration. The spatial components of this transport law are
Sj
,tu0 ≃Sj
,t = −j
k0Sku0 ≃−j
k0Sk ≃−jk0Sk ≃1
2(g0k,j −g0j ,k)Sk.
(25.99)
Hereeach“≃”means“isequal, uptofractionalcorrectionsoforderM/r.”Byinserting
g0j from the line element (25.98c) and performing some manipulations with Levi-
Civita tensors, we can bring Eq. (25.99) into the form (cf. Ex. 26.19 and Sec. 27.2.5)
reading off angular
momentum from
gyroscopic precession
(frame dragging)
dS
dt = prec × S,
where prec = 1
r3[−J + 3(J . n)n].
(25.100)
Here n = eˆr is the unit radial vector pointing away from the gravitating source.
Equation (25.100) says that the gyroscope’s spin angular momentum rotates (pre-
cesses) with angular velocity prec in the coordinate system (which is attached to
distant inertial frames, i.e., to distant galaxies and quasars). This is sometimes called
a gravitomagnetic precession, because the off-diagonal term gj0 in the metric, when
thought of as a 3-vector, is −2J × n/r2, which has the same form as the vector po-
tential of a magnetic dipole; and the gyroscopic precession is similar to that of a
magnetized spinning body interacting with that magnetic dipole. It is also called a
frame-dragging precession, because one can regard the source’s angular momentum
as dragging inertial frames into precession and regard those inertial frames as being
locked to inertial-guidance gyroscopes, such as S. And it is sometimes called Lense-
Thirring precession after the physicists who ﬁrst discovered it mathematically, with
Einstein’s help (Pﬁster, 2007).
Figure 25.5 shows this frame-dragging precessional angular velocity prec as a
vector ﬁeld attached to the source. Notice that it has precisely the same form as
a dipolar magnetic ﬁeld in electromagnetic theory. In Sec. 27.2.5, we discuss the
magnitude of this frame dragging in the solar system and the experiments that have
measured it.
For a time-independent body with strong internal gravity (e.g., a black hole), the
distant gravitational ﬁeld will have the same general form [Eqs. (25.98)] as for a weakly
gravitating body, but the constants M and J k that appear in the metric will not be
expressible as the integrals (25.98b) over the body’s interior. Nevertheless, they will
be measurable by the same techniques as for a weakly gravitating body (Kepler’s laws
and frame dragging), and they can be interpreted as the body’s total mass and angular
momentum. We explore this in the next chapter [Eq. (26.71)], where the body will be
a spinning black hole.
25.9 Weak Gravitational Fields
1233

J
FIGURE 25.5 The precessional angular velocity prec [Eq. (25.100)] of an
inertial-guidance gyroscope at rest outside a stationary, linearized source
of gravity that has angular momentum J. The arrows are all drawn with
the same length rather than proportional to the magnitude of prec.
EXERCISES
Exercise 25.21 Derivation and Example: External Field of a Stationary,
Linearized Source
Derive Eqs. (25.98a) for the trace-reversed metric perturbation outside a stationary
(time-independent), linearized source of gravity. More speciﬁcally, do the following.
(a) First derive ¯h00. In your derivation identify a dipolar term of the form 4Djxj/r3,
and show that by placing the origin of coordinates at the center of mass, Eq.
(25.96), one causes the dipole moment Dj to vanish.
(b) Next derive ¯h0j. The two terms in Eq. (25.97) should give rise to two terms. The
ﬁrst of these is 4Pj/r, where Pj is the source’s linear momentum. Show, using
the gauge condition ¯h0μ,μ = 0 [Eq. (25.89)], that if the momentum is nonzero,
then the mass dipole term of part (a) must have a nonzero time derivative, which
violates our assumption of stationarity. Therefore, the linear momentum must
vanish for this source. Show that the second term gives rise to the ¯h0j of Eq.
(25.98a). [Hint: You will have to add a perfect divergence, −1
2(T 0axjxm),a to the
integrand T 0jxm.]
(c) Finally derive ¯hij. [Hint: Show that T ij = (T iaxi),a and thence that the volume
integral of T ij vanishes; similarly for T ijxk.]
Exercise 25.22 Derivation and Problem: Differential Precession
and Frame-Drag Field
(a) Derive the equation i = Bijξj for the precession angular velocity of a gyro-
scope at the tip of ξ as measured in an inertial frame at its tail. Here Bij is the
frame-drag ﬁeld introduced in Box 25.2. [For a solution, see Nichols et al. (2011,
Sec. III.C).]
1234
Chapter 25. Fundamental Concepts of General Relativity

BOX 25.2.
DECOMPOSITION OF RIEMANN: TIDAL AND
FRAME-DRAG FIELDS
In any local Lorentz frame, and also in a Lorentz frame of the linearized theory,
the electromagnetic ﬁeld tensor Fμν can be decomposed into two spatial vector
ﬁelds: the electric ﬁeld Ei = Fi0 and magnetic ﬁeld Bi = 1
2ϵipqF pq (Sec. 2.11).
Similarly, in vacuum (for simplicity) the Riemann curvature tensor can be
decomposed into two spatial tensor ﬁelds: the tidal ﬁeld Eij = Ri0j0 and
the frame-drag ﬁeld Bij = 1
2ϵipqRpqj0. The symmetries (25.45) of Riemann,
and the fact that in vacuum it is trace-free, imply that both Eij and Bjk are
symmetric and trace-free (STF). In the 3-space of the chosen frame, they are
the irreducible tensorial parts of the vacuum Riemann tensor (cf. Box 11.2).
In a local Lorentz frame for strong gravity, and also in the linearized theory
for weak gravity, the Bianchi identities (25.70) take on the following Maxwell-
like form [Nichols et al., 2011, Eqs. (2.4), (2.15)], in which the superscript S
means to symmetrize:
∇. E = 0,
∇. B = 0,
∂E
∂t −(∇× B)S = 0,
∂B
∂t + (∇× E)S = 0.
(1)
This has motivated some physicists to call the tidal ﬁeld E and the frame-drag
ﬁeld B the “electric” and “magnetic” parts of the vacuum Riemann tensor.
We avoid this language because of the possibility of confusing these second-
rank tensorial gravitational ﬁelds with their truly electromagnetic vector-ﬁeld
counterparts E and B.
The tidal and frame-drag ﬁelds get their names from the forces they
produce. The equation of geodesic deviation (25.34) says that, in a local
Lorentz frame or in linearized theory, the relative acceleration of two test
particles, separated by the vector ξ, is ai = −Eijξj. Similarly, a gyroscope at
the tip of ξ precesses relative to an inertial frame at its tail with the differential
frame-dragging angular velocity i = Bijξj (Ex. 25.22). Not surprisingly,
in linearized theory, B is the symmetrized gradient of the angular velocity
prec of precession relative to distant inertial frames: B =
2
∇prec
3S
.
Just as the electric and magnetic ﬁelds can be visualized using ﬁeld lines
that are the integral curves of E and B, E and B can be visualized using the inte-
gral curves of their eigenvectors. Since each ﬁeld, E or B, has three orthogonal
eigenvectors, each has a network of three orthogonal sets of ﬁeld lines. The
ﬁeld lines of B are called (Nichols et al., 2011) frame-drag vortex lines or simply
“vortex lines”; those of E are called tidal tendex lines or simply “tendex lines”
(continued)
25.9 Weak Gravitational Fields
1235

BOX 25.2.
(continued)
(from the Latin tendere, meaning “to stretch” by analogy with vortex from
vertere, meaning “to turn”). For a spinning point mass in linearized theory,
E and B are given by Eqs. (25.101), and their tendex and vortex lines are
as shown below (adapted from Nichols et al., 2011). The red tendex lines
(left diagram) stretch; the blue squeeze. The red vortex lines (right) twist a
gyroscope at a person’s feet (or head) counterclockwise relative to inertial
frames at her head (or feet). The blue vortex lines twist clockwise. We explore
these concepts in greater detail in Box 26.3.
J
(b) Show that in linearized theory, B is the symmetrized gradient of the angular
velocity prec of precession of a gyroscope relative to distant inertial frames.
Exercise 25.23 Problem: Spinning Particle in Linearized Theory:
Tidal and Frame-Drag Fields
Show that in linearized theory, for a spinning particle at the origin with mass M and
with its spin J along the polar axis, the orthonormal-frame components of E and
B are
Eˆr ˆr = −2E ˆθ ˆθ = −2E ˆφ ˆφ = −2M
r3 ,
(25.101a)
Bˆr ˆr = −2B ˆθ ˆθ = −2B ˆφ ˆφ = −6J cos θ
r4
,
Bˆr ˆθ = B ˆθ ˆr = −3J sin θ
r4
. (25.101b)
What are the eigenvectors of these ﬁelds? Convince yourself that these eigenvectors’
integral curves (the tidal tendex lines and frame-drag vortex lines) are as depicted at
the bottom of Box 25.2.
1236
Chapter 25. Fundamental Concepts of General Relativity

25.9.4
25.9.4 Conservation Laws for Mass, Momentum, and Angular Momentum
in Linearized Theory
Consider a static (unmoving) sphere S surrounding our time-independent source
of gravity, with such a large radius r that the O(1/r3) corrections in ¯hμν and in the
metric [Eqs. (25.98)] can be ignored. Suppose that a small amount of mass-energy E
for a stationary source
of gravity perturbed by
an infalling or outﬂowing
stress-energy tensor:
(as measured in the sphere’s and source’s rest frame) is injected through the sphere,
into the source. Then the special relativistic law of mass-energy conservation tells us
that the source’s mass M =

T 00dV will increase by M = E. Similarly, if an energy
ﬂux T 0j ﬂows through the sphere, the source’s mass will change by
mass conservation
dM
dt = −

S
T 0jdj,
(25.102)
where dj is the sphere’s outward-pointing surface-area element, and the minus sign
is because dj points outward, not inward. Since M is the mass that appears in the
source’s asymptotic gravitational ﬁeld ¯hμν and metric gαβ, this conservation law can
be regarded as describing how the source’s gravitating mass changes when energy is
injected into it.
Fromthespecialrelativisticlawforangularmomentumconservation(e.g., Misner,
Thorne, and Wheeler, 1973, Box 5.6), we deduce a similar result. A ﬂux ϵijkxjT km of
angular momentum through the sphere produces the following change in the angular
momentum Ji that appears in the source’s asymptotic ﬁeld ¯hμν and metric:
angular-momentum
conservation
dJi
dt = −

S
ϵijkxjT kmdm.
(25.103)
There is also a conservation law for a gravitationally measured linear momentum.
That linear momentum does not show up in the asymptotic ﬁeld and metric that we
wrote down above [Eqs. (25.98)], because our coordinates were chosen to be attached
to the source’s center of mass (i.e., they are the Lorentz coordinates of the source’s
rest frame). However, if linear momentum Pj is injected through our sphere S and
becomes part of the source, then the source’s center of mass will start moving, and the
asymptotic metric will acquire a new term:
δg0j = −4Pj/r,
(25.104)
where (after the injection)
source’s linear momentum
Pj = P j =

T 0jdV
(25.105)
[see Eq. (25.91) with ¯h0j = −¯h0j = −h0j = −δg0j; also see Ex. 25.21b]. More gen-
erally, the rate of change of the source’s total linear momentum (the Pj term in the
25.9 Weak Gravitational Fields
1237

asymptotic g0j) is the integral of the inward ﬂux of momentum (inward component
of the stress tensor) across the sphere:
momentum conservation
dPj
dt = −

S
T jkdk.
(25.106)
25.9.5
25.9.5 Conservation Laws for a Strong-Gravity Source
For a time-independent source with strong internal gravity, not only does the asymp-
strong-gravity source
surrounded by
asymptotically ﬂat
spacetime:
totic metric, far from the source, have the same form [Eqs. (25.98c), (25.98d),
(25.104)]asforaweaklygravitatingsource, butalsotheconservationlawsforitsgravi-
tationally measured mass, angular momentum, and linear momentum [Eqs. (25.102),
(25.103), (25.106), respectively] continue to hold true. Of course, the sphere S must
be placed far from the source, in a region where gravity is weak, so spacetime is asymp-
totically ﬂat6 and linearized theory is valid in the vicinity of S. When this is done,
in asymptotically ﬂat
region, source’s mass,
momentum, angular
momentum, and their
conservation are the same
as for a weak-gravity
source
then the special relativistic description of inﬂowing mass, angular momentum, and
energy is valid at S, and the linearized Einstein equation, applied in the vicinity of S
(and not extended into the strong-gravity region), turn out to guarantee that the M,
Jj, and Pj appearing in the asymptotic metric evolve in accord with the conservation
laws (25.102), (25.103), and (25.106).
For strongly gravitating sources, these conservation laws owe their existence to the
spacetime’s asymptotic time-translation, rotation, and space-translation symmetries.
In generic, strong-gravity regions of spacetime there are no such symmetries and
correspondingly, no integral conservation laws for energy, angular momentum, or
linear momentum.
If a strongly gravitating source is dynamical rather than static, it will emit gravi-
tational waves (Chap. 27). The amplitudes of those waves, like the inﬂuence of the
source’s mass, die out as 1/r far from the source, so spacetime retains its asymp-
totic time-translation, rotation, and space-translation symmetries. These symmetries
continue to enforce integral conservation laws on the gravitationally measured mass,
angular momentum, and linear momentum [Eqs. (25.102), (25.103), and (25.106)],
but with the new requirement that one include, in the ﬂuxes through S, contributions
from the gravitational waves’ energy, angular momentum, and linear momentum; see
Chap. 27.
For a brief derivation and discussion of these asymptotic conservation laws, see
Thorne (1983, Sec. 3.3.2); for far greater detail, see Misner, Thorne, and Wheeler
(1973, Chaps. 18 and 19).
6.
Ourrealuniverse, ofcourse, isnotasymptoticallyﬂat.However, nearlyeverywherethedistancesbetween
gravitating systems (e.g., between our solar system and the alpha centauri system) are so large that
spacetime is very nearly asymptotically ﬂat as one moves outward into the region between the systems.
Correspondingly, to very high accuracy all the statements in this section remain true.
1238
Chapter 25. Fundamental Concepts of General Relativity

Bibliographic Note
For a superb, detailed historical account of Einstein’s intellectual struggle to formulate
the laws of general relativity, see Pais (1982). For Einstein’s papers of that era, in the
original German and in English translation, with detailed annotations and explana-
tionsbyeditorswithstrongbackgroundsinbothphysicsandthehistoryofscience, see
Einstein (1989). For some key papers of that era by other major contributors besides
Einstein, in English translation, see Lorentz et al. (1923).
This chapter’s pedagogical approach to presenting the fundamental concepts of
generalrelativityisstronglyinﬂuencedbyMisner, Thorne, andWheeler(1973), where
readers will ﬁnd much greater detail. See, especially, Chap. 8 for the mathematics (dif-
ferential geometry) of curved spacetime, or Chaps. 9–14 for far greater detail; Chap.
16 for the Einstein equivalence principle and how to lift laws of physics into curved
spacetime; Chap. 17 for the Einstein ﬁeld equations and many different ways to de-
rive them; Chap. 18 for weak gravitational ﬁelds (the Newtonian limit and linearized
theory); and Chaps. 19 and 20 for the metric in the asymptotically ﬂat region outside
a strongly gravitating source and for the source’s conservation laws for mass, momen-
tum, and angular momentum.
For an excellent, elementary introduction to the fundamental concepts of general
relativity from a viewpoint that is somewhat less mathematical than this chapter or
Misner, Thorne, and Wheeler (1973), see Hartle (2003). We also recommend, at a
somewhat elementary level, Schutz (2009); and at a more advanced level, Carroll
(2004), Straumann(2013), andZee(2013).Ataveryadvancedandmathematicallevel,
we recommend Wald (1984). For a rather different approach to general relativity, one
that emphasizes the connection to ﬁeld theory over that to geometry, we recommend
Weinberg (1972).
Our physicist’s approach to differential geometry in this chapter lacks much of
the rigor and beauty of a mathematician’s approach, for which we recommend Spivak
(1999).
Bibliographic Note
1239


26
CHAPTER TWENTY-SIX
Relativistic Stars and Black Holes
All light emitted from such a body would be made to return towards it by its own proper gravity.
JOHN MICHELL (1783)
26.1
26.1 Overview
Having sketched the fundamentals of Einstein’s theory of gravity, general relativity, we
now illustrate his theory by several concrete applications: stars and black holes in this
chapter, gravitational waves in Chap. 27, and the large-scale structure and evolution
of the universe in Chap. 28.
While stars and black holes are the central thread of this chapter, we study them
less for their own intrinsic interest than for their roles as vehicles by which to under-
stand general relativity. Using them, we elucidate some issues we have already met:
the physical and geometric interpretations of spacetime metrics and of coordinate sys-
tems, the Newtonian limit of general relativity, the geodesic motion of freely falling
particles and photons, local Lorentz frames and the tidal forces measured therein,
proper reference frames, the Einstein ﬁeld equation, the local law of conservation of
4-momentum, and the asymptotic structure of spacetime far from gravitating sources.
Stars and black holes also serve to introduce several new physical phenomena that did
not show up in our study of the foundations of general relativity: the “many-ﬁngered”
nature of time, event horizons, and spacetime singularities.
We begin this chapter, in Sec. 26.2, by studying the geometry of the curved space-
time outside any static star, as predicted by the Einstein ﬁeld equation. In Sec. 26.3,
we study general relativity’s description of the interiors of static stars. In Sec. 26.4,
we turn attention to the spherically symmetric gravitational implosion by which a
nonrotating star is transformed into a black hole, and to the Schwarzschild spacetime
geometry outside and inside the resulting static, spherical hole. In Sec. 26.5, we study
the Kerr spacetime geometry of a spinning black hole. In Sec. 26.6, we elucidate the
nature of time in the curved spacetimes of general relativity. And in Ex. 26.13, we
explore the role of the vacuum Schwarzschild solution of the Einstein ﬁeld equation
as a wormhole.
1241

BOX 26.1.
READERS’ GUIDE
.
This chapter relies signiﬁcantly on:
– Chap. 2 on special relativity;
– Chap. 24 on the transition from special relativity to general
relativity; and
– Chap. 25 on the fundamental concepts of general relativity.
.
Portions of this chapter are a foundation for the applications of
general relativity theory to gravitational waves (Chap. 27) and to
cosmology (Chap. 28).
26.2
26.2 Schwarzschild’s Spacetime Geometry
26.2.1
26.2.1 TheSchwarzschildMetric, ItsConnectionCoefﬁcients, andItsCurvatureTensors
On January 13, 1916, just 7 weeks after formulating the ﬁnal version of his ﬁeld
equation, GGG = 8πTTT, Albert Einstein read to a meeting of the Prussian Academy of Sci-
ences in Berlin a letter from the eminent German astrophysicist Karl Schwarzschild.
Schwarzschild, as a member of the German army, had written from the World-War-I
Russian front to tell Einstein of a mathematical discovery he had made: he had found
the world’s ﬁrst exact solution to the Einstein ﬁeld equation.
Written as a line element in a special coordinate system (coordinates {t, r, θ, φ})
that Schwarzschild invented for the purpose, Schwarzschild’s solution takes the form
(Schwarzschild, 1916a)
Schwarzschild metric
ds2 = −(1 −2M/r)dt2 +
dr2
(1 −2M/r) + r2(dθ2 + sin2 θdφ2),
(26.1)
where M is a constant of integration. The connection coefﬁcients, Riemann tensor,
and Ricci and Einstein tensors for this metric can be computed by the methods of
Chaps. 24 and 25; see Ex. 26.1. The results are tabulated in Box 26.2. The key bottom
line is that the Einstein tensor vanishes. Therefore, the Schwarzschild metric (26.1) is
a solution of the Einstein ﬁeld equation with vanishing stress-energy tensor.
roles of the Schwarzschild
metric: exterior of static
star and imploding star;
black hole and wormhole
Many readers know already the lore of this subject. The Schwarzschild metric is
reputed to represent the vacuum exterior of a nonrotating, spherical star; and also the
exterior of a spherical star as it implodes to form a black hole; and also the exterior
and interior of a nonrotating, spherical black hole; and also a wormhole that connects
two different universes or two widely separated regions of our own universe.
How does one discover these physical interpretations of the Schwarzschild metric
(26.1)? The tools for discovering them—and, more generally, the tools for interpreting
1242
Chapter 26. Relativistic Stars and Black Holes

BOX 26.2.
CONNECTION COEFFICIENTS AND CURVATURE
TENSORS FOR SCHWARZSCHILD SOLUTION
The coordinate basis vectors for the Schwarzschild solution of Einstein’s
equation are
⃗et = ∂
∂t ,
⃗er = ∂
∂r ,
⃗eθ = ∂
∂θ ,
⃗eφ = ∂
∂φ ;
⃗et = ⃗∇t,
⃗er = ⃗∇r,
⃗eθ = ⃗∇θ,
⃗eφ = ⃗∇φ.
(1)
The covariant and contravariant metric coefﬁcients in this coordinate basis
are [cf. Eq. (26.1)]
gtt = −

1 −2M
r

,
grr =
1
(1 −2M/r) ,
gθθ = r2,
gφφ = r2 sin2 θ;
(2a)
gtt = −
1
(1 −2M/r) ,
grr =

1 −2M
r

,
gθθ = 1
r2
gφφ =
1
r2 sin2 θ .
(2b)
The nonzero connection coefﬁcients in this coordinate basis are
t
rt = t
tr = M
r2
1
(1 −2M/r) , r
tt = M
r2 (1−2M/r), r
rr = −M
r2
1
(1 −2M/r) ,
r
θθ = −r(1 −2M/r), θ
rθ = θ
θr = φ
rφ = φ
φr = 1
r ,
(3)
r
φφ = −r sin2 θ(1−2M/r), θ
φφ = −sin θ cos θ, φ
θφ = φ
φθ = cot θ.
The orthonormal basis associated with the above coordinate basis is
⃗eˆ0 =
1
√1 −2M/r
∂
∂t ,
⃗eˆr =
&
1 −2M
r
∂
∂r ,
⃗e ˆθ = 1
r
∂
∂θ ,
⃗e ˆφ =
1
r sin θ
∂
∂φ .
(4)
The nonzero connection coefﬁcients in this orthonormal basis are
ˆr
ˆ0ˆ0 = ˆ0
ˆrˆ0 =
M
r2√1 −2M/r ,
 ˆφ
ˆθ ˆφ = − ˆθ
ˆφ ˆφ = cot θ
r
,
 ˆθ
ˆr ˆθ =  ˆφ
ˆr ˆφ = −ˆr
ˆθ ˆθ = −ˆr
ˆφ ˆφ =
√1 −2M/r
r
.
(5)
(continued)
26.2 Schwarzschild’s Spacetime Geometry
1243

BOX 26.2.
(continued)
The nonzero components of the Riemann tensor in this orthonormal basis
are
Rˆrˆ0ˆrˆ0 = −R ˆθ ˆφ ˆθ ˆφ = −2M
r3 ,
R ˆθ ˆ0 ˆθ ˆ0 = R ˆφˆ0 ˆφˆ0 = −Rˆr ˆφˆr ˆφ = −Rˆr ˆθ ˆr ˆθ = M
r3 ,
(6)
and those obtainable from these via the symmetries (25.45a) of Riemann.
The Ricci tensor, curvature scalar, and Einstein tensor all vanish—which
implies that the Schwarzschild metric is a solution of the vacuum Einstein
ﬁeld equation.
physically any spacetime metric that one encounters—are a central concern of this
chapter.
EXERCISES
Exercise 26.1 Practice: Connection Coefﬁcients and the Riemann Tensor
for the Schwarzschild Metric
(a) Explain why, for the Schwarzschild metric (26.1), the metric coefﬁcients in the
coordinate basis have the values given in Eqs. (2a,b) of Box 26.2.
(b) Using tensor-analysis software on a computer,1 derive the connection coefﬁcients
given in Eq. (3) of Box 26.2.
(c) Show that the basis vectors in Eqs. (4) of Box 26.2 are orthonormal.
(d) Using tensor-analysis software on a computer, derive the connection coefﬁcients
(5) and Riemann components (6) of Box 26.2 in the orthonormal basis.
26.2.2
26.2.2 The Nature of Schwarzschild’s Coordinate System,
and Symmetries of the Schwarzschild Spacetime
When presented with a line element such as Eq. (26.1), one of the ﬁrst questions one
is tempted to ask is “What is the nature of the coordinate system?” Since the metric
coefﬁcients will be different in some other coordinate system, surely one must know
something about the coordinates to interpret the line element.
Remarkably, one need not go to the inventor of the coordinates to ﬁnd out their
nature. Instead, one can turn to the line element itself: the line element (or metric
1.
Such as the simple Mathematica program in Hartle (2003, Appendix C), which is available on that book’s
website: http://web.physics.ucsb.edu/~gravitybook/mathematical.html.
1244
Chapter 26. Relativistic Stars and Black Holes

coefﬁcients) contain full information not only about the details of the spacetime
properties of the
Schwarzschild metric
and its Schwarzschild
coordinates:
geometry, but also about the nature of the coordinates. The line element (26.1) is
a good example:
Look ﬁrst at the 2-dimensional surfaces in spacetime that have constant values
of t and r. We can regard {θ, φ} as a coordinate system on each such 2-surface. The
spacetime line element (26.1) tells us that the geometry of the 2-surface is given in
terms of those coordinates by
(2)ds2 = r2(dθ2 + sin2 θdφ2)
(26.2)
(where the preﬁx (2) refers to the dimensionality of the surface). This is the line ele-
ment (metric) of an ordinary, everyday 2-dimensional sphere expressed in standard
spherical polar coordinates. Thus we have learned that the Schwarzschild spacetime
spherically symmetric
is spherically symmetric, and moreover, θ and φ are standard spherical polar coor-
dinates. This is an example of extracting from a metric information about both the
coordinate-independent spacetime geometry and the coordinate system being used.
Furthermore, note from Eq. (26.2) that the circumferences and surface areas of
the spheres (t, r) = const in Schwarzschild spacetime are given by
radial coordinate rrr is
circumference/2π
/2π
/2π, or
square root of area/4π
4π
4π
circumference = 2πr,
area = 4πr2 .
(26.3)
This tells us one aspect of the geometric interpretation of the r coordinate: r is a ra-
dial coordinate in the sense that the circumferences and surface areas of the spheres
in Schwarzschild spacetime are expressed in terms of r in the standard manner of
Eq. (26.3). We must not go further, however, and assert that r is radius in the sense
of being the proper distance from the center of one of the spheres to its surface. The
center, and the line from center to surface, do not lie on the sphere itself, and they
thus are not described by the spherical line element (26.2). Moreover, since we know
that spacetime is curved, we have no right to expect that the proper distance from the
center of a sphere to its surface will be given by distance = circumference/2π = r as
in ﬂat spacetime.
26.2.3
26.2.3 Schwarzschild Spacetime at Radii r ≫M: The Asymptotically Flat Region
Returning to the Schwarzschild line element (26.1), let us examine several speciﬁc
regions of spacetime: At “radii” r large compared to the integration constant M, the
line element (26.1) takes the form
ds2 = −dt2 + dr2 + r2(dθ2 + sin2 θdφ2).
(26.4)
This is the line element of ﬂat spacetime, ds2 = −dt2 + dx2 + dy2 + dz2 written in
spherical polar coordinates {x = r sin θ cos φ, y = r sin θ sin φ, z = r cos θ}. Thus,
asymptotically ﬂat
Schwarzschild spacetime is asymptotically ﬂat in the region of large radii r/M →∞.
Thisisjustwhatonemightexpectphysicallywhenonegetsfarawayfromallsourcesof
26.2 Schwarzschild’s Spacetime Geometry
1245

gravity. Thus, it is reasonable to presume that the Schwarzschild spacetime geometry
is that of some sort of isolated, gravitating body that is located in the region r ∼M.
The large-r line element (26.4) not only reveals that Schwarzschild spacetime
is asymptotically ﬂat; it also shows that in the asymptotically ﬂat region the
Schwarzschild coordinate t is the time coordinate of a Lorentz reference frame. No-
tice that the region of strong spacetime curvature has a boundary (say, r ∼100M)
that remains forever ﬁxed relative to the asymptotically Lorentz spatial coordinates
{x = r sin θ cos φ, y = r sin θ sin φ, z = r cos θ}. This means that the asymptotic
Lorentz frame can be regarded as the body’s asymptotic rest frame. We conclude,
asymptotic rest frame
then, that far from the body the Schwarzschild t coordinate becomes the Lorentz
time of the body’s asymptotic rest frame, and the Schwarzschild {r, θ, φ} coordinates
become spherical polar coordinates in the body’s asymptotic rest frame.
As we move inward from r = ∞, we gradually begin to see spacetime curvature.
That curvature shows up, at r ≫M, in slight deviations of the Schwarzschild metric
coefﬁcients from those of a Lorentz frame: to ﬁrst order in M/r the line element (26.1)
becomes
ds2 = −

1 −2M
r

dt2 +

1 + 2M
r

dr2 + r2(dθ2 + sin2 θdφ2),
(26.5)
or, equivalently, in Cartesian spatial coordinates:
ds2 = −
*
1 −
2M

x2 + y2 + z2
+
dt2 + dx2 + dy2 + dz2
+ 2M
r
x
r dx + y
r dy + z
r dz
2
.
(26.6)
It is reasonable to expect that, at these large radii where the curvature is weak,
Newtonian gravity will be a good approximation to Einsteinian gravity. In Sec. 25.9.1,
we studied in detail the transition from general relativity to Newtonian gravity, and
found that in nearly Newtonian situations, if one uses a nearly globally Lorentz
coordinate system (as we are doing), the line element should take the form [Eq.
(25.79)]:
ds2 = −(1 + 2)dt2 + (δjk + hjk)dxjdxk + 2htjdt dxj,
(26.7)
where the hμν are metric corrections that are small compared to unity, and  (which
shows up in the time-time part of the metric) is the Newtonian potential. Direct
comparison of Eq. (26.7) with (26.6) shows that a Newtonian description of the body’s
Newtonian limit of
Schwarzschild metric
distant gravitational ﬁeld will entail a Newtonian potential given by
 = −M
r
(26.8)
( = −GM/r in conventional units). This, of course, is the external Newtonian ﬁeld
of a body with mass M. Thus, the integration constant M in the Schwarzschild line
1246
Chapter 26. Relativistic Stars and Black Holes

element is the mass that characterizes the body’s distant, nearly Newtonian gravita-
M
M
M is the mass that
characterizes the
asymptotic Newtonian
gravitational ﬁeld
tional ﬁeld. This is an example of reading the mass of a body off the asymptotic form
of the metric (last paragraph of Sec. 25.9.3).
Notice that the asymptotic metric here [Eq. (26.5)] differs in its spatial part from
that in Sec. 25.9.3 [Eq. (25.98d)]. This difference arises from the use of different radial
coordinates here. If we deﬁne ¯r by r = ¯r + M at radii r ≫M, then to linear order in
M/r, the asymptotic Schwarzschild metric (26.5) becomes
ds2 = −

1 −2M
¯r

dt2 +

1 + 2M
¯r

[d ¯r2 + ¯r2(dθ2 + sin2 θdφ2)],
(26.9)
which is the same as Eq. (25.98d) with vanishing angular momentum J = 0. This easy
changeofthespatialpartofthemetricreinforcesthefactthatonereadstheasymptotic
Newtonian potential and the source’s mass M from the time-time components of the
metric and not from the spatial part of the metric.
We can describe, in operational terms, the physical interpretation of M as the
body’s mass as follows. Suppose that a test particle (e.g., a small planet) moves around
our central body in a circular orbit with radius r ≫M. A Newtonian analysis of the
orbit predicts that, as measured using Newtonian time, the period of the orbit will be
P = 2π(r3/M)
1
2 (oneofKepler’slaws).Moreover, sinceNewtoniantimeisverynearly
equal to the time t of the nearly Lorentz coordinates used in Eq. (26.5) (cf. Sec. 25.9.1),
and since that t is Lorentz time in the body’s relativistic, asymptotic rest frame, the
orbital period as measured by observers at rest in the asymptotic rest frame must be
P = 2π(r3/M)
1
2. Thus, M is the mass that appears in Kepler’s laws for the orbits of test
M
M
M is the mass in Kepler’s
laws for distant planets
particles far from the central body. This quantity is sometimes called the body’s “active
gravitational mass,” since it is the mass that characterizes the body’s gravitational pull.
It is also called the body’s “total mass-energy,” because it turns out to include all forms
of mass and energy that the body possesses (rest mass; internal kinetic energy; and
all forms of internal binding energy, including gravitational).
relativistic analysis of
Keplerian orbital motion
We note in passing that one can use general relativity to deduce the Keplerian
role of M without invoking the Newtonian limit: place a test particle in the body’s
equatorial plane θ = π/2 at a radius r ≫M, and give it an initial velocity that lies in
the equatorial plane. Then symmetry guarantees the particle remains in the equatorial
plane: there is no way to prefer going toward north, θ < π/2, or toward south,
θ > π/2. Furthermore, adjust the initial velocity so the particle remains always at a
ﬁxed radius. Then the only nonvanishing components uα = dxα/dτ of the particle’s
4-velocity are ut = dt/dτ and uφ = dφ/dτ. The particle’s orbit is governed by the
geodesic equation ∇⃗u ⃗u = 0, where ⃗u is its 4-velocity. The radial component of this
geodesic equation, computed in Schwarzschild coordinates, is [cf. Eq. (25.14) with a
switch from afﬁne parameter ζ to proper time τ = mζ]
d2r
dτ 2 = −r
μν
dxμ
dτ
dxν
dτ = −r
tt
dt
dτ
dt
dτ −r
φφ
dφ
dτ
dφ
dτ .
(26.10)
26.2 Schwarzschild’s Spacetime Geometry
1247

(Here we have used the vanishing of all dxα/dτ except the t and φ components and
haveusedthevanishingofrtφ = rφt [Eq.(3)ofBox26.2].)Sincetheorbitiscircular,
with ﬁxed r, the left-hand side of Eq. (26.10) must vanish; correspondingly, the right-
hand side gives
dφ
dt = dφ/dτ
dt/dτ =
*
−rtt
rφφ
+ 1
2
=
M
r3
 1
2
,
(26.11)
where we have used the values of the connection coefﬁcients from Eq. (3) of Box
26.2, specialized to the equatorial plane θ = π/2. Equation (26.11) tells us that the
amount of coordinate time t required for the particle to circle the central body once,
0 ≤φ ≤2π, is t = 2π(r3/M)
1
2. Since t is the Lorentz time of the body’s asymptotic
rest frame, observers in the asymptotic rest frame will measure for the particle an
orbitalperiodP = t = 2π(r3/M)
1
2.This, ofcourse, isthesameresultasweobtained
from the Newtonian limit—but our relativistic analysis shows it to be true for circular
orbits of arbitrary radius r, not just for r ≫M.
26.2.4
26.2.4 Schwarzschild Spacetime at r ∼M
Next we move inward, from the asymptotically ﬂat region of Schwarzschild spacetime
toward smaller and smaller radii. As we do so, the spacetime geometry becomes more
and more strongly curved, and the Schwarzschild coordinate system becomes less and
lessLorentz.AsanindicationofextremedeviationsfromLorentz, noticethatthesigns
of the metric coefﬁcients,
∂
∂t
. ∂
∂t = gtt = −

1 −2M
r

,
∂
∂r
. ∂
∂r = grr =
1
(1 −2M/r)
(26.12)
reverse as one moves from r > 2M through r = 2M and into the region r < 2M.
outside r = 2M
r = 2M
r = 2M, ttt is a time
coordinate and rrr a space
coordinate; inside, their
roles are reversed
Correspondingly, outside r = 2M, world lines of changing t but constant {r, θ, φ}
are timelike, while inside r = 2M, those world lines are spacelike. Similarly outside
r = 2M, world lines of changing r but constant {t, θ, φ} are spacelike, while inside
they are timelike. In this sense, outside r = 2M, t plays the role of a time coordinate
and r the role of a space coordinate; while inside r = 2M, t plays the role of a space
coordinate and r the role of a time coordinate. Moreover, this role reversal occurs
without any change in the role of r as 1/(2π) times the circumference of circles around
the center [Eq. (26.3)].
For many decades this role reversal presented severe conceptual problems, even to
the best experts in general relativity. We return to it in Sec. 26.4. Henceforth we refer to
the location of role reversal, r = 2M, as the gravitational radius of the Schwarzschild
spacetime, henceforthgravitationalradius.ItisalsoknownastheSchwarzschildradius
and, as we shall see, is the location of an absolute event horizon. In Sec. 26.4, we seek
a clear understanding of the “interior” region, r < 2M; but until then, we conﬁne
attention to the region r > 2M, outside the gravitational radius.
1248
Chapter 26. Relativistic Stars and Black Holes

Notice that the metric coefﬁcients in the Schwarzschild line element (26.1) are all
the spacetime geometry is
static outside r = 2M
r = 2M
r = 2M
independent of the coordinate t. This means that the geometry of spacetime itself
is invariant under the translation t →t + const. At radii r > 2M, where t plays
the role of a time coordinate, t →t + const is a time translation; correspondingly,
the Schwarzschild spacetime geometry is time-translation-invariant (i.e., “static”)
outside the gravitational radius.
EXERCISES
Exercise 26.2 Example: The Bertotti-Robinson Solution of the Einstein Field Equation
Bruno Bertotti (1959) and Ivor Robinson (1959) independently solved the Einstein
ﬁeld equation to obtain the following metric for a universe endowed with a uniform
magnetic ﬁeld:
ds2 = Q2(−dt2 + sin2t dz2 + dθ2 + sin2θ dφ2).
(26.13)
Here
Q = const,
0 ≤t ≤π,
−∞< z < +∞,
0 ≤θ ≤π,
0 ≤φ ≤2π. (26.14)
If one computes the Einstein tensor from the metric coefﬁcients of the line ele-
ment (26.13) and equates it to 8π times a stress-energy tensor, one ﬁnds a stress-
energy tensor that is precisely the same as for an electromagnetic ﬁeld [Eqs. (2.75)
and (2.80)] lifted, unchanged, into general relativity. The electromagnetic ﬁeld is one
that, as measured in the local Lorentz frame of an observer with ﬁxed {z, θ, φ} (a
“static” observer), has vanishing electric ﬁeld and has a magnetic ﬁeld directed along
∂/∂z with magnitude independent of where the observer is located in spacetime. In
this sense, the spacetime metric (26.13) is that of a homogeneous magnetic universe.
Discuss the geometry of this universe and the nature of the coordinates {t, z, θ, φ}.
More speciﬁcally, do the following.
(a) Which coordinate increases in a timelike direction and which coordinates in
spacelike directions?
(b) Is this universe spherically symmetric?
(c) Is this universe cylindrically symmetric?
(d) Is this universe asymptotically ﬂat?
(e) How does the geometry of this universe change as t ranges from 0 to π? [Hint:
Show that the curves {(z, θ, φ) = const, t = τ/Q} are timelike geodesics—the
world lines of the static observers referred to above. Then argue from symmetry,
or use the result of Ex. 25.4a.]
(f) Give as complete a characterization as you can of the coordinates {t, z,
θ, φ}.
26.2 Schwarzschild’s Spacetime Geometry
1249

26.3
26.3 Static Stars
26.3.1
26.3.1 Birkhoff’s Theorem
In 1923, George Birkhoff, a professor of mathematics at Harvard, proved a remarkable
theorem (Birkhoff, 1923). (For a textbook proof, see Misner, Thorne, and Wheeler,
Birkhoff’s theorem:
uniqueness of
Schwarzschild solution
1973, Sec. 32.2.) The Schwarzschild spacetime geometry is the unique spherically
symmetric solution of the vacuum Einstein ﬁeld equation GGG = 0. This Birkhoff theo-
rem can be restated in more operational terms as follows. Suppose that you ﬁnd a
solution of the vacuum Einstein ﬁeld equation, written as a set of metric coefﬁcients
g¯α ¯β in some coordinate system {x ¯μ}. Suppose, further, that these g¯α ¯β(x ¯μ) coefﬁcients
exhibit spherical symmetry but do not coincide with the Schwarzschild expressions
[Eqs. (2a) of Box 26.2]. Then the Birkhoff theorem guarantees the existence of a co-
ordinate transformation from your coordinates x ¯μ to Schwarzschild’s coordinates xν
such that, when that transformation is performed, the resulting new metric com-
ponents gαβ(xν) have precisely the Schwarzschild form [Eqs. (2a) of Box 26.2]. For
an example, see Ex. 26.3. This implies that, thought of as a coordinate-independent
spacetime geometry, the Schwarzschild solution is completely unique.
Now consider a static, spherically symmetric star (e.g., the Sun) residing alone in
an otherwise empty universe (or, more realistically, residing in our own universe but
so far from other gravitating matter that we can ignore all other sources of gravity
when studying it). Since the star’s interior is spherical, it is reasonable to presume that
the exterior will be spherical; since the exterior is also vacuum (TTT = 0), its spacetime
geometry must be that of Schwarzschild. If the circumference of the star’s surface
is 2πR and its surface area is 4πR2, then that surface must reside at the location
r = R in the Schwarzschild coordinates of the exterior. In other words, the spacetime
geometry will be described by the Schwarzschild line element (26.1) at radii r > R,
but by something else inside the star, at r < R.
Since real atoms with ﬁnite rest masses reside on the star’s surface, and since
such atoms move along timelike world lines, it must be that the world lines {r = R,
θ = const, φ = const, t varying} are timelike. From the Schwarzschild invariant
interval (26.1) we read off the squared proper time, dτ 2 = −ds2 = (1 −2M/R)dt2,
along those world lines. This dτ 2 is positive (timelike world line) if and only if
R > 2M. Thus, a static star with total mass-energy (active gravitational mass) M can
a static star must have
radius RRR greater than 2M
2M
2M
neverhaveacircumferencesmallerthan2πR = 4πM.Restatedinconventionalunits:
circumference
2π
= R ≡

radius
of star

> 2M = 2GM
c2
= 2.953 km

M
M⊙

≡

gravitational
radius

.
(26.15)
Here M⊙is the mass of the Sun. The Sun satisﬁes this constraint by a huge margin:
R = 7 × 105 km ≫2.953 km. A 1-solar-mass white-dwarf star satisﬁes it by a smaller
margin: R ≃6 × 103 km. And a 1-solar-mass neutron star satisﬁes it by only a modest
1250
Chapter 26. Relativistic Stars and Black Holes

margin: R ≃10 km. For a pedagogical and detailed discussion see, for example,
Shapiro and Teukolsky (1983).
EXERCISES
Exercise 26.3 Problem: Schwarzschild Geometry in Isotropic Coordinates
(a) It turns out that the following line element is a solution of the vacuum Einstein
ﬁeld equation GGG = 0:
ds2 = −
1 −M/(2¯r)
1 + M/(2¯r)
2
dt2 +

1 + M
2¯r
4
[d ¯r2 + ¯r2(dθ2 + sin2 θdφ2)].
(26.16)
Since this solution is spherically symmetric, Birkhoff’s theorem guarantees it
must represent the standard Schwarzschild spacetime geometry in a coordinate
system that differs from Schwarzschild’s. Show that this is so by exhibiting a
coordinate transformation that converts this line element into Eq. (26.1). [Note:
The {t, ¯r, θ, φ} coordinates are called isotropic,because in them the spatial part of
the line element is a function of ¯r times the 3-dimensional Euclidean line element,
and Euclidean geometry picks out at each point in space no preferred spatial
directions (i.e., it is isotropic).]
(b) Show that at large radii r ≫M, the line element (26.16) takes the form (25.98c)
discussed in Chap. 25, but with vanishing spin angular momentum J = 0.
Exercise 26.4 **Example: Gravitational Redshift of Light from a Star’s Surface
Consider a photon emitted by an atom at rest on the surface of a static star with mass
M and radius R. Analyze the photon’s motion in the Schwarzschild coordinate system
of the star’s exterior, r ≥R > 2M. In particular, compute the “gravitational redshift”
of the photon by the following steps.
(a) Since the emitting atom is nearly an ideal clock, it gives the emitted photon nearly
the same frequency νem, as measured in the emitting atom’s proper reference
frame (as it would give were it in an Earth laboratory or ﬂoating in free space).
Thus the proper reference frame of the emitting atom is central to a discussion of
the photon’s properties and behavior. Show that the orthonormal basis vectors of
that proper reference frame are
⃗eˆ0 =
1
√1 −2M/r
∂
∂t ,
⃗eˆr =

1 −2M/r ∂
∂r ,
⃗e ˆθ = 1
r
∂
∂θ ,
⃗e ˆφ =
1
r sin θ
∂
∂φ ,
(26.17)
with r = R (the star’s radius).
(b) Explain why the photon’s energy as measured in the emitter’s proper reference
frame is E = hνem = −pˆ0 = −⃗p . ⃗eˆ0. (Here and below h is Planck’s constant, and
⃗p is the photon’s 4-momentum.)
26.3 Static Stars
1251

(c) Show that the quantity E∞≡−pt = −⃗p . ∂/∂t is conserved as the photon travels
outward from the emitting atom to an observer at very large radius, which we
idealize as r = ∞. [Hint: Recall the result of Ex. 25.4a.] Show, further, that E∞
is the photon’s energy, as measured by the observer at r = ∞—which is why it is
called the photon’s “energy-at-inﬁnity” and denoted E∞. The photon’s frequency,
as measured by that observer, is given, of course, by hν∞= E∞.
(d) Show that E∞= E√1 −2M/R and thence that ν∞= νem
√1 −2M/R, and that
therefore the photon is redshifted by an amount
λrec −λem
λem
=
1
√1 −2M/R −1.
(26.18)
Here λrec is the wavelength that the photon’s spectral line exhibits at the receiver,
and λem is the wavelength that the emitting kind of atom would produce in an
Earth laboratory. Note that for a nearly Newtonian star (i.e., one with R ≫M),
this redshift becomes ≃M/R = GM/Rc2.
(e) Evaluate this redshift for Earth, for the Sun, and for a 1.4-solar-mass, 10-km-
radius neutron star.
26.3.2
26.3.2 Stellar Interior
We now take a temporary detour from our study of the Schwarzschild geometry to
discuss the interior of a static, spherical star. We do so less because of an interest in
stars than because the detour will illustrate the process of solving the Einstein ﬁeld
equation and the role of the contracted Bianchi identity in the solution process.
Since the star’s spacetime geometry is to be static and spherically symmetric, we
can introduce as coordinates in its interior: (i) spherical polar angular coordinates θ
and φ, (ii) a radial coordinate r such that the circumferences of the spheres are 2πr,
and (iii) a time coordinate ¯t such that the metric coefﬁcients are independent of ¯t. By
their geometrical deﬁnitions, these coordinates will produce a spacetime line element
of the form
ds2 = g¯t ¯td ¯t2 + 2g¯trd ¯tdr + grrdr2 + r2(dθ2 + sin2 θdφ2),
(26.19)
with gαβ independent of ¯t, θ, and φ. Metric coefﬁcients g¯tθ, grθ, g¯tφ, and grφ are
absent from Eq. (26.19), because they would break the spherical symmetry: they
would distinguish the +φ direction from −φ or +θ from −θ, since they would give
nonzero values for the scalar products of ∂/∂φ or ∂/∂θ with ∂/∂t or ∂/∂r. [Recall that
the metric coefﬁcients in a coordinate basis are gαβ = ggg(∂/∂xα, ∂/∂xβ) = (∂/∂xα) .
(∂/∂xβ).] We can get rid of the off-diagonal g¯tr term in the line element (26.19) by
specializing the time coordinate. The coordinate transformation
¯t = t −
 
g¯tr
g¯t ¯t

dr
(26.20)
1252
Chapter 26. Relativistic Stars and Black Holes

brings the line element into the form
coordinates and line
element for interior of a
static star
ds2 = −e2dt2 + e2 dr2 + r2(dθ2 + sin2 θdφ2).
(26.21)
Here, after the transformation (26.20), we have introduced the names e2 and e2 for
the time-time and radial-radial metric coefﬁcients, respectively. The signs of these
coefﬁcients (negative for gtt and positive for grr) are dictated by the fact that inside
the star, as on its surface, real atoms move along world lines of constant {r, θ, φ}
and changing t, and thus those world lines must be timelike. The name e2 is chosen
because when gravity is nearly Newtonian, the time-time metric coefﬁcient −e2
must reduce to −(1 + 2), with  the Newtonian potential [Eq. (25.79)]. Thus, the
 used in Eq. (26.21) is a generalization of the Newtonian potential to relativistic,
spherical, static gravitational situations.
To solve the Einstein ﬁeld equation for the star’s interior, we must specify the
stress-energytensor.Stellarmaterialisexcellentlyapproximatedbyaperfectﬂuid, and
since our star is static, at any point inside the star the ﬂuid’s rest frame has constant
{r, θ, φ}. Correspondingly, the 4-velocity of the ﬂuid is
ﬂuid 4-velocity inside
static star
⃗u = e− ∂
∂t .
(26.22)
Here the factor e− guarantees that the 4-velocity will have ⃗u2 = −1, as it must.
Of course, this ﬂuid is not freely falling. Rather, for a ﬂuid element to remain
always at ﬁxed {r, θ, φ} it must accelerate relative to local freely falling observers
with a 4-acceleration ⃗a ≡∇⃗u ⃗u ̸= 0 (i.e., aα = uα;μuμ ̸= 0). Symmetry tells us that
this 4-acceleration cannot have any θ or φ components, and orthogonality of the
4-acceleration to the 4-velocity tells us that it cannot have any t component. The
r component, computed from ar = ur;μuμ = r00u0u0, is ar = e−2 ,r; and thus
we have
ﬂuid 4-acceleration inside
static star
⃗a = e−2 ,r
∂
∂r .
(26.23)
orthonormal basis vectors
of ﬂuid’s local rest frame
(its proper reference
frame)
Each ﬂuid element can be thought of as carrying an orthonormal set of basis
vectors:
⃗eˆ0 = ⃗u = e− ∂
∂t ,
⃗eˆr = e− ∂
∂r ,
⃗e ˆθ = 1
r
∂
∂θ ,
⃗e ˆφ =
1
r sin θ
∂
∂φ ;
(26.24a)
⃗eˆ0 = e ⃗∇t,
⃗eˆr = e ⃗∇r,
⃗e ˆθ = r ⃗∇θ,
⃗e ˆφ = r sin θ ⃗∇φ.
(26.24b)
These basis vectors play two independent roles. (i) One can regard the tangent space
of each event in spacetime as being spanned by the basis (26.24), specialized to that
event. From this viewpoint, Eqs. (26.24) constitute an orthonormal, noncoordinate
basis that covers every tangent space of the star’s spacetime. This basis is called the
26.3 Static Stars
1253

ﬂuid’s orthonormal, local-rest-frame basis. (ii) One can focus attention on a speciﬁc
ﬂuid element, which moves along the world line r = ro, θ = θo, φ = φo; and one can
construct the proper reference frame of that ﬂuid element in the same manner as we
constructed the proper reference frame of an accelerated observer in ﬂat spacetime in
Sec. 24.5. That proper reference frame is a coordinate system {x ˆα} whose basis vectors
on the ﬂuid element’s world line are equal to the basis vectors (26.24):
∂
∂x ˆμ = ⃗e ˆμ,
⃗∇x ˆμ = ⃗e ˆμ at x ˆj = 0,
with ˆ1 = ˆr, ˆ2 = ˆθ, ˆ3 = ˆφ.
(26.25a)
More speciﬁcally, the proper-reference-frame coordinates x ˆμ are given, to second-
order in spatial distance from the ﬂuid element’s world line, by
coordinates of ﬂuid
element’s proper reference
frame
x ˆ0 = eot,
xˆ1 =
 r
ro
e dr −1
2e− oro[(θ −θo)2 + sin2 θo(φ −φo)2],
xˆ2 = r(θ −θo) −1
2ro sin θo cos θo(φ −φo)2,
xˆ3 = r sin θ(φ −φo),
(26.25b)
from which one can verify relation (26.25a) with the basis vectors given by Eqs.
(26.24). [In Eqs. (26.25b) and throughout this discussion all quantities with subscripts
o are evaluated on the ﬂuid’s world line.] In terms of the proper-reference-frame
coordinates (26.25b), the line element (26.21) takes the following form, accurate to
ﬁrst order in distance from the ﬂuid element’s world line:
ds2 = −[1 + 2,r(r −ro)](dx ˆo)2 + δijdxˆi dx ˆj.
(26.25c)
Notice that the quantity ,r(r −ro) is equal to the scalar product of (i) the spatial
separation ˆx ≡(r −ro)∂/∂r + (θ −θo)∂/∂θ + (φ −φo)∂/∂φ of the “ﬁeld point”
(r, θ, φ) from the ﬂuid element’s world line, with (ii) the ﬂuid’s 4-acceleration
(26.23), viewed as a spatial 3-vector a = e−2 o,r∂/∂r. Correspondingly, the space-
time line element (26.25c) in the ﬂuid element’s proper reference frame takes the
standard proper-reference-frame form (24.60b):
ds2 = −(1 + 2a . ˆx)(dx ˆ0)2 + δjkdx ˆjdx ˆk,
(26.26)
accurate to ﬁrst order in distance from the ﬂuid element’s world line. To second order,
as discussed at the end of Sec. 25.3, there are corrections proportional to the spacetime
curvature.
In the local rest frame of the ﬂuid [i.e., when expanded on the ﬂuid’s orthonormal
rest-frame basis vectors (26.24) or equally well (26.25a)], the components T ˆα ˆβ =
(ρ + P)uˆαu ˆβ + P g ˆα ˆβ of the ﬂuid’s stress-energy tensor take on the standard form
[Eq. (24.50)]:
stress-energy tensor in
ﬂuid’s proper reference
frame: ﬂuid density and
pressure
T ˆ0ˆ0 = ρ,
T ˆr ˆr = T ˆθ ˆθ = T ˆφ ˆφ = P ,
(26.27)
1254
Chapter 26. Relativistic Stars and Black Holes

corresponding to a rest-frame mass-energy density ρ and isotropic pressure P . By
contrast with the simplicity of these local-rest-frame components, the contravariant
components T αβ = (ρ + P)uαuβ + P gαβ in the {t, r, θ, φ} coordinate basis are
rather more complicated:
T tt = e−2ρ,
T rr = e−2 P ,
T θθ = r−2P ,
T φφ = (r sin θ)−2 P .
(26.28)
This shows one advantage of using orthonormal bases: the components of vectors
and tensors are generally simpler in an orthonormal basis than in a coordinate basis.
A second advantage occurs when one seeks the physical interpretation of formulas.
Because every orthonormal basis is the proper-reference-frame basis of some local
observer (the observer with 4-velocity ⃗u = ⃗eˆo), components measured in such a basis
have an immediate physical interpretation in terms of measurements by that observer.
For example, T ˆ0ˆ0 is the total density of mass-energy measured by the local observer.
By contrast, components in a coordinate basis typically do not have a simple physical
interpretation.
EXERCISES
Exercise 26.5 Derivation: Proper-Reference-Frame Coordinates
Show that in the coordinate system {x ˆ0, xˆ1, xˆ2, xˆ3} of Eqs. (26.25b), the coordinate
basis vectors at x ˆj = 0 are Eqs. (26.24), and, accurate through ﬁrst order in distance
from x ˆj = 0, the spacetime line element is Eq. (26.26); that is, errors are no larger
than second order.
26.3.3
26.3.3 Local Conservation of Energy and Momentum
Before inserting the perfect-ﬂuid stress-energy tensor (26.27) into the Einstein ﬁeld
equation, we impose on it the local law of conservation of 4-momentum: ⃗∇. TTT = 0.
In doing so we require from the outset that, since the star is to be static and spherical,
its density ρ and pressure P must be independent of t, θ, and φ (i.e., like the metric
coefﬁcients  and  , they must be functions of radius r only).
The most straightforward way to impose 4-momentum conservation is to equate
to zero the quantities
T αβ
;β = ∂T αβ
∂xβ + β
μβT αμ + α
μβT μβ = 0
(26.29)
in our coordinate basis, making use of expressions (26.28) for the contravariant
components of the stress-energy tensor, and the connection coefﬁcients and metric
components given in Box 26.2.
This straightforward calculation requires a lot of work. Much better is an analysis
based on the local proper reference frame of the ﬂuid. The temporal component of
⃗∇. TTT = 0 in that reference frame [i.e., the projection ⃗u . ( ⃗∇. TTT) = 0 of this conserva-
26.3 Static Stars
1255

tion law onto the time basis vector ⃗eˆ0 = e−∂/∂t = ⃗u] represents energy conservation
as seen by the ﬂuid—the ﬁrst law of thermodynamics:
ﬁrst law of thermo-
dynamics
d(ρV )
dτ
= −P dV
dτ .
(26.30)
Here τ is proper time as measured by the ﬂuid element we are following, and V is the
ﬂuid element’s volume. (This equation is derived in Ex. 2.26b, in a special relativistic
context; but since it involves only one derivative, there is no danger of curvature
coupling, so that derivation and the result can be lifted without change into general
relativity, i.e., intothestar’scurvedspacetime; cf.Ex.26.6a.)Now, insidethisstaticstar,
the ﬂuid element sees and feels no changes. Its density ρ, pressure P , and volume V
always remain constant along the ﬂuid element’s world line, and energy conservation
is therefore guaranteed to be satisﬁed. Equation (26.30) tells us nothing new.
The spatial part of ⃗∇. TTT = 0 in the ﬂuid’s local rest frame can be written in
geometric form as PPP . ( ⃗∇. TTT) = 0. Here PPP ≡ggg + ⃗u ⊗⃗u is the tensor that projects
all vectors into the 3-surface orthogonal to ⃗u, that is, into the ﬂuid’s local 3-surface
of simultaneity (Exs. 2.10 and 25.1b). By inserting the perfect-ﬂuid stress-energy
tensor TTT = (ρ + P)⃗u ⊗⃗u + P ggg = ρ⃗u ⊗⃗u + P PPP into PPP . ( ⃗∇. TTT) = 0, reexpressing
the result in slot-naming index notation, and carrying out some index gymnastics,
we must obtain the same result as in special relativity (Ex. 2.26c):
force balance inside the
ﬂuid
(ρ + P )⃗a = −PPP . ⃗∇P
(26.31)
(cf. Ex. 26.6b). Here ⃗a is the ﬂuid’s 4-velocity. Recall from Ex. 2.27 that for a perfect
ﬂuid, ρ + P is the inertial mass per unit volume. Therefore, Eq. (26.31) says that the
ﬂuid’s inertial mass per unit volume times its 4-acceleration is equal to the negative of
its pressure gradient, projected orthogonally to its 4-velocity. Since both sides of Eq.
(26.31) are purely spatially directed as seen in the ﬂuid’s local proper reference frame,
we can rewrite this equation in 3-dimensional language as
(ρ + P )a = −∇P .
(26.32)
A Newtonian physicist, in the proper reference frame, would identify −a as the
local gravitational acceleration, g, and correspondingly, would rewrite Eq. (26.31) as
Newtonian viewpoint on
force balance
∇P = (ρ + P )g.
(26.33)
This is the standard equation of hydrostatic equilibrium for a ﬂuid in an Earthbound
laboratory(orswimmingpoolorlakeorocean), exceptforthepresenceofthepressure
P in the inertial mass per unit volume (Ex. 2.27). On Earth the typical pressures of
ﬂuids, even deep in the ocean, are only P <∼109 dyne/cm2 ≃10−12 g cm−3 <∼10−12ρ.
Thus, to extremely good accuracy one can ignore the contribution of pressure to the
1256
Chapter 26. Relativistic Stars and Black Holes

inertial mass density. However, deep inside a neutron star, P may be within a factor
2 of ρ, so the contribution of P cannot be ignored.
We can convert the law of force balance (26.31) into an ordinary differential
equation for the pressure P by evaluating its components in the ﬂuid’s proper ref-
erence frame. The 4-acceleration (26.23) is purely radial; its radial component is
aˆr = e− ,r = , ˆr. The gradient of the pressure is also purely radial, and its radial
component is P; ˆr = P, ˆr = e− P,r. Therefore, the law of force balance reduces to
force balance rewritten
dP
dr = −(ρ + P )d
dr .
(26.34)
EXERCISES
Exercise 26.6 Practice and Derivation: Local Conservation of Energy and Momentum
for a Perfect Fluid
(a) Use index manipulations to show that in general (not just inside a static star), for
a perfect ﬂuid with T αβ = (ρ + P )uαuβ + P gαβ, the law of energy conservation
uα T αβ;β = 0 reduces to the ﬁrst law of thermodynamics (26.30). [Hint: You will
need the relation uμ;μ = (1/V )(dV/dτ); cf. Ex. 2.24.]
(b) Similarly, show that PμαT αβ;β = 0 reduces to the force-balance law (26.31).
26.3.4
26.3.4 The Einstein Field Equation
Turn, now, to the Einstein ﬁeld equation inside a static, spherical star with isotropic
pressure. To impose it, we must ﬁrst compute, in our {t, r, θ, φ} coordinate system,
the components of the Einstein tensor Gαβ. In general, the Einstein tensor has 10 in-
dependent components. However, the symmetries of the line element (26.21) impose
identical symmetries on the Einstein tensor computed from it: The only nonzero com-
ponents in the ﬂuid’s proper reference frame will be Gˆ0ˆ0, Gˆr ˆr, and G ˆθ ˆθ = G ˆφ ˆφ; and
these three independent components will be functions of radius r only. Correspond-
ingly, the Einstein equation will produce three independent differential equations for
our four unknowns: the metric coefﬁcients (“gravitational potentials”)  and  [Eq.
(26.21)], and the radial distribution of density ρ and pressure P .
These three independent components of the Einstein equation will actually be
redundant with the law of hydrostatic equilibrium (26.34). One can see this as follows.
If we had not yet imposed the law of 4-momentum conservation, then the Einstein
equation GGG = 8πTTT, together with the Bianchi identity ⃗∇. GGG ≡0 [Eq. (25.69)], would
enforce ⃗∇. TTT = 0. More explicitly, our three independent components of the Einstein
equation together would imply the law of radial force balance [i.e., of hydrostatic
with force balance
imposed, Einstein’s
equation provides just two
additional constraints on
the stellar structure
equilibrium (26.34)]. Since we have already imposed Eq. (26.34), we need evaluate
only two of the three independent components of the Einstein equation; they will
give us full information.
26.3 Static Stars
1257

Alongandrathertediouscalculation(bestdoneonacomputer), basedonthemet-
riccoefﬁcientsofEq.(26.21)andonEqs.(24.38), (25.50), (25.46), (25.49), and(25.68),
produces the following for the time-time and radial-radial components of the Einstein
tensor, and thence of the Einstein ﬁeld equation:
Gˆ0ˆ0 = 1
r2
d
dr [r(1 −e−2 )]= 8πT ˆ0ˆ0 = 8πρ,
(26.35)
Gˆr ˆr = −1
r2(1 −e−2 ) + 2
r e−2 d
dr = 8πT ˆr ˆr = 8πP .
(26.36)
We can bring these components of the ﬁeld equation into simpler form by deﬁning a
new metric coefﬁcient m(r) by
e2 ≡
1
1 −2m/r .
(26.37)
Note [cf. Eqs. (26.1), (26.21), and (26.37)] that outside the star, m is equal to the star’s
total mass-energy M. This, plus the fact that in terms of m the time-time component
of the ﬁeld equation (26.35) takes the form
Einstein equation for the
mass inside radius r, m(r)
r, m(r)
r, m(r)
dm
dr = 4πr2ρ,
(26.38a)
motivates the name mass inside radius r for the quantity m(r). In terms of m the
radial-radial component (26.36) of the ﬁeld equation becomes
Einstein equation for (r)
(r)
(r)
d
dr = m + 4πr3P
r(r −2m) ;
(26.38b)
combining this with Eq. (26.34), we obtain an alternative form of the equation of
hydrostatic equilibrium:
TOV equation of
hydrostatic equilibrium
dP
dr = −(ρ + P )(m + 4πr3P )
r(r −2m)
.
(26.38c)
[This form is called the Tolman-Oppenheimer-Volkoff (or TOV) equation, because
it was ﬁrst derived by Tolman (1939) and ﬁrst used in a practical calculation by
Oppenheimer and Volkoff (1939).] Equations (26.38a), (26.38b), (26.38c) plus an
equation of state for the pressure of the stellar material P in terms of its density of
total mass-energy ρ,
P = P (ρ),
(26.38d)
determine the four quantities , m, ρ, and P as functions of radius. In other words,
summary: the relativistic
equations of stellar
structure, Eqs. (26.38)
Eqs. (26.38) are the relativistic equations of stellar structure.
Actually, for full determination, one also needs boundary conditions. Just as the
surfaceofasphereiseverywherelocallyEuclidean(i.e., isarbitrarilyclosetoEuclidean
1258
Chapter 26. Relativistic Stars and Black Holes

in arbitrarily small regions), so also spacetime must be everywhere locally Lorentz;
cf. Eqs. (25.9). For spacetime to be locally Lorentz at the star’s center (in particular, for
circumferences of tiny circles around the center to be equal to 2π times their radii),
it is necessary that m vanish at the center:
boundary conditions for
relativistic equations of
stellar structure
m = 0 at r = 0,
and thus m(r) =
 r
0
4πr2ρdr
(26.39)
[cf. Eqs. (26.21) and (26.37)]. At the star’s surface the interior spacetime geometry
(26.21) must join smoothly to the exterior Schwarzschild geometry (26.1):
m = M
and
e2 = 1 −2M/r at r = R.
(26.40)
26.3.5
26.3.5 Stellar Models and Their Properties
Alittlethoughtnowrevealsastraightforwardmethodofproducingarelativisticstellar
procedure for constructing
a relativistic stellar model
model.
1. Specify an equation of state for the stellar material P = P (ρ), and specify a
central density ρc or central pressure Pc for the star.
2. Integrate the coupled hydrostatic-equilibrium equation (26.38c) and “mass
equation” (26.38a) outward from the center, beginning with the initial con-
ditions m = 0 and P = Pc at the center.
3. Terminate the integration when the pressure falls to zero; this is the surface
of the star.
4. At the surface read off the value of m; it is the star’s total mass-energy M,
which appears in the star’s external, Schwarzschild line element (26.1).
5. From this M and the radius r ≡R of the star’s surface, read off the value of
the gravitational potential  at the surface [Eq. (26.40)].
6. IntegratetheEinsteinﬁeldequation(26.38b)inwardfromthesurfacetoward
the center to determine  as a function of radius inside the star.
Just 6 weeks after reading to the Prussian Academy of Science the letter in which
Karl Schwarzschild derived his vacuum solution (26.1) of the ﬁeld equation, Albert
Einstein again presented the Academy with results from Schwarzschild’s fertile mind:
an exact solution for the structure of the interior of a star that has constant density
ρ. [And just 4 months after that, on June 29, 1916, Einstein had the sad task of
announcing to the Academy that Schwarzschild had died of an illness contracted on
the World-War-I Russian front.]
details of a relativistic star
with constant density ρρρ
In our notation, Schwarzschild’s solution for the interior of a star is characterized
by its uniform density ρ, its total mass M, and its radius R, which is given in terms of
ρ and M by
M = 4π
3 ρR3
(26.41)
26.3 Static Stars
1259

[Eq. (26.39)]. In terms of these quantities, the mass M inside radius r, the pressure
P, and the gravitational potential  as functions of r are (Schwarzschild, 1916b)
m = 4π
3 ρr3,
P = ρ
'
(1 −2Mr2/R3)
1
2 −(1 −2M/R)
1
2
3(1 −2M/R)
1
2 −(1 −2Mr2/R3)
1
2
(
,
(26.42a)
e = 3
2

1 −2M
R
 1
2
−1
2

1 −2Mr2
R3
 1
2
.
(26.42b)
We present these details less for their speciﬁc physical content than to illustrate
the solution of the Einstein ﬁeld equation in a realistic, astrophysically interesting
situation. For discussions of the application of this formalism to neutron stars, where
relativistic deviations from Newtonian theory can be rather strong, see, for example,
Shapiro and Teukolsky (1983). For the seminal work on the theory of neutron-star
structure, see Oppenheimer and Volkoff (1939).
Among the remarkable consequences of the TOV equation of hydrostatic equi-
librium (26.38c) for neutron-star structure are the following. (i) If the mass m inside
radius r ever gets close to r/2, the “gravitational pull” [right-hand side of (26.38c)]
becomes divergently large, forcing the pressure gradient that counterbalances it to be
divergently large, and thereby driving the pressure quickly to zero as one integrates
outward. This protects the static star from having M greater than R/2 (i.e., from hav-
ing its surface inside its gravitational radius). (ii) Although the density of matter near
upper limit on mass of a
neutron star, and how it
comes about
the center of a neutron star is above that of an atomic nucleus (2.3 × 1017 kg m−3),
wheretheequationofstateisill-understood, wecanbeconﬁdentthatthereisanupper
limit on the masses of neutron stars, a limit in the range 2M⊙<∼Mmax <∼3M⊙.2 This
mass limit cannot be avoided by postulating that a more massive neutron star develops
an arbitrarily large central pressure and thereby supports itself against gravitational
implosion. The reason is that an arbitrarily large central pressure is self-defeating: The
“gravitational pull” that appears on the right-hand side of Eq. (26.38c) is quadratic in
the pressure at very high pressures (whereas it would be independent of pressure in
Newtonian theory). This purely relativistic feature guarantees that, if a star develops
too high a central pressure, it will be unable to support itself against the resulting
“quadratically too high” gravitational pull.
EXERCISES
Exercise 26.7 Problem: Mass-Radius Relation for Neutron Stars
The equation of state of a neutron star is very hard to calculate at the supra-nuclear
densities required, because the calculation is a complex, many-body problem and the
particle interactions are poorly understood and poorly measured. Observations of
2.
Measured neutron star masses range from ∼1.2 solar masses to more than 2.0 solar masses.
1260
Chapter 26. Relativistic Stars and Black Holes

neutron stars’ masses and radii can therefore provide valuable constraints on fun-
damental nuclear physics. As we discuss brieﬂy in the following chapter, various
candidate equations of state can already be excluded on these observational grounds.
A necessary step for comparing observation with theory is to compute the stellar
structure for candidate equations of state. We can illustrate the approach using a
simple functional form, which, around nuclear density (ρnuc ≃2.3 × 1017 kg m−3),
is a fair approximation to some of the models:
P = 3 × 1032
 ρ
ρnuc
3
N m−2.
(26.43)
For this equation of state, use the equations of stellar structure (26.38a) and (26.38c)
to ﬁnd the masses and radii of stars with a range of central pressures, and hence
deduceamass-radiusrelation, M(R).Youshoulddiscoverthat, asthecentralpressure
is increased, the mass passes through a maximum, while the radius continues to
decrease. (Stars with radii smaller than that at the maximum mass are unstable to
radial perturbations.)
26.3.6
26.3.6 Embedding Diagrams
Weconcludeourdiscussionofstaticstarsbyusingthemtoillustrateausefultechnique
for visualizing the curvature of spacetime: the embedding of the curved spacetime,
or a piece of it, in a ﬂat space of higher dimensionality.
the problem of embedding
a curved manifold inside
a ﬂat higher-dimensional
manifold (the embedding
space); number of
dimensions needed in
the embedding space
The geometry of a curved, n-dimensional manifold is characterized by 1
2n(n + 1)
metric components (since those components form a symmetric n × n matrix), of
which only 1
2n(n + 1) −n = 1
2n(n −1) are of coordinate-independent signiﬁcance
(since we are free to choose arbitrarily the n coordinates of our coordinate system
and can thereby force n of the metric components to take on any desired values, e.g.,
zero). If this n-dimensional manifold is embedded in a ﬂat N-dimensional manifold,
that embedding will be described by expressing N −n of the embedding manifold’s
Euclidean (or Lorentz) coordinates in terms of the other n. Thus, the embedding is
characterized by N −n functions of n variables. For the embedding to be possible, in
general, this number of choosable functions must be at least as large as the number
of signiﬁcant metric coefﬁcients 1
2n(n −1). From this argument we conclude that
the dimensionality of the embedding space must be N ≥1
2n(n + 1). Actually, this
argument analyzes only the local features of the embedding. If one also wants to
preserve the global topology of the n-dimensional manifold, one must in general go
to an embedding space of even higher dimensionality.
Curved spacetime has n = 4 dimensions and thus requires for its local embedding
a ﬂat space with at least N = 1
2n(n + 1) = 10 dimensions. This is a bit much for
3-dimensional beings like us to visualize. If, as a sop to our visual limitations, we
reduce our ambitions and seek only to extract a 3-surface from curved spacetime
26.3 Static Stars
1261

and visualize it by embedding it in a ﬂat space, we will require a ﬂat space of N = 6
dimensions. This is still a bit much. In frustration, we are driven to extract from
spacetime n = 2 dimensional surfaces and visualize them by embedding in ﬂat spaces
with N = 3 dimensions. This is doable—and, indeed, instructive.
embedding the equatorial
planeofastatic, relativistic
star in a ﬂat 3-dimensional
embedding space
As a nice example, consider the equatorial “plane” through the spacetime of a static
spherical star, at a speciﬁc “moment” of coordinate time t [i.e., consider the 2-surface
t = const, θ = π/2 in the spacetime of Eqs. (26.21), (26.37)]. The line element on this
equatorial 2-surface is
(2)ds2 =
dr2
1 −2m/r + r2dφ2,
where m = m(r) =
 r
0
4πr2ρdr
(26.44)
[cf. Eq. (26.39)]. We seek to construct in a 3-dimensional Euclidean space a 2-
dimensional surface with precisely this same 2-geometry. As an aid, we introduce
in the Euclidean embedding space a cylindrical coordinate system {r, z, φ}, in terms
of which the space’s 3-dimensional line element is
(3)ds2 = dr2 + dz2 + r2dφ2.
(26.45)
The surface we seek to embed is axially symmetric, so we can describe its embedding
by the value of z on it as a function of radius r: z = z(r). Inserting this (unknown)
embedding function into Eq. (26.45), we obtain for the surface’s 2-geometry,
(2)ds2 = [1 + (dz/dr)2]dr2 + r2dφ2.
(26.46)
Comparing with our original expression (26.44) for the 2-geometry, we obtain a
differential equation for the embedding function:
dz
dr =

1
1 −2m/r −1
 1
2
.
(26.47)
If we set z = 0 at the star’s center, then the solution of this differential equation is
shape of embedded
equatorial plane in general
z =
 r
0
dr′
[r′/(2m) −1]
1
2
.
(26.48)
Near the star’s center m(r) is given by m = (4π/3)ρcr3, where ρc is the star’s central
shape outside the star
where the spacetime
geometry is Schwarzschild
density; and outside the star m(r) is equal to the star’s r-independent total mass M.
Correspondingly, in these two regions Eq. (26.48) reduces to
z =

(2π/3)ρc r2
at r very near zero.
z =

8M(r −2M) + const at r > R,
i.e., outside the star.
(26.49)
Figure 26.1 shows the embedded 2-surface z(r) for a star of uniform density ρ = const
(Ex. 26.8). For any other star the embedding diagram will be qualitatively similar,
though quantitatively different.
1262
Chapter 26. Relativistic Stars and Black Holes

r
x
y
interior of star
exterior of star
z
ϕ
FIGURE 26.1 Embedding diagram depicting an equatorial, 2-dimensional slice t = const, θ = π/2
through the spacetime of a spherical star with uniform density ρ and with radius R equal to
2.5 times the gravitational radius 2M. See Ex. 26.8 for details.
The most important feature of this embedding diagram is its illustration of the
fact [also clear in the original line element (26.44)] that, as one moves outward from
the star’s center, its circumference 2πr increases less rapidly than the proper ra-
dial distance traveled, l =
 r
0 (1 −2m/r)−1
2dr. As a speciﬁc example, the distance
from the center of Earth to a perfect circle near Earth’s surface is more than the
circumference/2π by about 1.5 mm—a number whose smallness compared to the
actual radius, 6.4 × 108 cm, is a measure of the weakness of the curvature of space-
time near Earth. As a more extreme example, the distance from the center of a
massive neutron star to its surface is about 1 km greater than its circumference/2π—
greater by an amount that is roughly 10% of the ∼10-km circumference/2π. Cor-
respondingly, in the embedding diagram for Earth the embedded surface would
be so nearly ﬂat that its downward dip at the center would be imperceptible,
whereas the diagram for a neutron star would show a downward dip about like that
of Fig. 26.1.
EXERCISES
Exercise 26.8 Example: Embedding Diagram for Star with Uniform Density
(a) Show that the embedding surface of Eq. (26.48) is a paraboloid of revolution
everywhere outside the star.
(b) Show that in the interior of a uniform-density star, the embedding surface is a
segment of a sphere.
(c) Show that the match of the interior to the exterior is done in such a way that, in
the embedding space, the embedded surface shows no kink (no bend) at r = R.
(d) Show that, in general, the circumference/(2π) for a star is less than the distance
from the center to the surface by an amount of order one sixth the star’s gravita-
tional radius, M/3. Evaluate this amount analytically for a star of uniform density,
and numerically (approximately) for Earth and for a neutron star.
26.3 Static Stars
1263

26.4
26.4 Gravitational Implosion of a Star to Form a Black Hole
26.4.1
26.4.1 The Implosion Analyzed in Schwarzschild Coordinates
J. Robert Oppenheimer, on discovering with his student George Volkoff that there is a
maximum mass limit for neutron stars (Oppenheimer and Volkoff, 1939), was forced
to consider the possibility that, when it exhausts its nuclear fuel, a more massive star
will implode to radii R ≤2M. Just before the outbreak of World War II, Oppenheimer
andhisgraduatestudentHartlandSnyderinvestigatedthedetailsofsuchanimplosion
for the idealized case of a perfectly spherical star in which all the internal pressure is
suddenly extinguished (Oppenheimer and Snyder, 1939). In this section, we repeat
their analysis, though from a more modern viewpoint and using somewhat different
arguments.
By Birkhoff’s theorem, the spacetime geometry outside an imploding, spherical
star must be that of Schwarzschild. This means, in particular, that an imploding,
spherical star cannot produce any gravitational waves; such waves would break the
spherical symmetry. By contrast, a star that implodes nonspherically can produce a
burst of gravitational waves (Chap. 27).
Since the spacetime geometry outside an imploding, spherical star is that of
Schwarzschild, we can depict the motion of the star’s surface by a world line in a
2-dimensional spacetime diagram with Schwarzschild coordinate time t plotted up-
ward and Schwarzschild coordinate radius r plotted rightward (Fig. 26.2). The world
line of the star’s surface is an ingoing curve. The region to the left of the world line
must be discarded and replaced by the spacetime of the star’s interior, while the region
to the right, r > R(t), is correctly described by Schwarzschild.
r = R(t)
6
4
2
0
2
4
6
8
t—
M
r/M
FIGURE 26.2 Spacetime diagram depicting the gravitationally induced implo-
sion of a star in Schwarzschild coordinates. The thick solid curve is the world
line of the star’s surface, r = R(t), in the external Schwarzschild coordinates.
The stippled region to the left of that world line is not correctly described
by the Schwarzschild line element (26.1); it requires for its description the
spacetime metric of the star’s interior. The surface’s world line r = R(t) is
constrained to lie inside the light cones.
1264
Chapter 26. Relativistic Stars and Black Holes

As for a static star, so also for an imploding one: because real atoms with ﬁnite
rest masses live on the star’s surface, the world line of that surface, {r = R(t), θ and φ
constant}, must be timelike. Consequently, at each point along the world line it must
lie within the local light cones that are depicted in Fig. 26.2.
The radial edges of the light cones are lines along which the Schwarzschild line
element, the ds2 of Eq. (26.1), vanishes with θ and φ held ﬁxed:
0 = ds2 = −(1 −2M/R)dt2 +
dr2
1 −2M/R ;
that is,
dt
dr = ±
1
1 −2M/R . (26.50)
Therefore, instead of having 45° opening angles dt/dr = ±1 as they do in a Lorentz
frame of ﬂat spacetime, the light cones “squeeze down” toward dt/dr = ∞as the star’s
surface r = R(t) approaches the gravitational radius: R →2M. This is a peculiarity
due not to spacetime curvature, but rather to the nature of the Schwarzschild coordi-
nates: If, at any chosen event of the Schwarzschild spacetime, we were to introduce a
local Lorentz frame, then in that frame the light cones would have 45° opening angles.
Since the world line of the star’s surface is conﬁned to the interiors of the local light
cones, the squeezing down of the light cones near r = 2M prevents the star’s world
line r = R(t) from ever, in any ﬁnite coordinate time t, reaching the gravitational
radius, r = 2M.
This conclusion is completely general; it relies in no way on the details of what is
going on inside the star or at its surface. It is just as valid for completely realistic stellar
implosion (with ﬁnite pressure and shock waves) as for the idealized, Oppenheimer-
Snyder case of zero-pressure implosion. In the special case of zero pressure, one can
explore the details further:
Because no pressure forces act on the atoms at the star’s surface, those atoms must
move inward along radial geodesic world lines. Correspondingly, the world line of the
star’s surface in the external Schwarzschild spacetime must be a timelike geodesic of
constant (θ, φ). In Ex. 26.9, the geodesic equation is solved to determine that world
line R(t), with a conclusion that agrees with the above argument: only after a lapse of
inﬁnite coordinate time t does the star’s surface reach the gravitational radius r = 2M.
A byproduct of that calculation is equally remarkable. Although the implosion to
the surface of an
imploding star reaches
the gravitational radius
r = 2M
r = 2M
r = 2M in ﬁnite proper
time τττ, but inﬁnite
coordinate time ttt
R = 2M requires inﬁnite Schwarzschild coordinate time t, it requires only a ﬁnite
proper time τ as measured by an observer who rides inward on the star’s surface. In
fact, the proper time is
τ ≃π
2
*
R3
o
2M
+ 1
2
= 15 μs
 Ro
2M
3/2 M
M⊙
if Ro ≫2M,
(26.51)
where Ro is the star’s initial radius when it ﬁrst begins to implode freely, M⊙denotes
the mass of the Sun, and proper time τ is measured from the start of implosion. Note
that this implosion time is equal to 1/(4
√
2) times the orbital period of a test particle
at the radius of the star’s initial surface. For a star with mass and initial radius equal
26.4 Gravitational Implosion of a Star to Form a Black Hole
1265

to those of the Sun, τ is about 30 minutes; for a neutron star that has been pushed
over the maximum mass limit by accretion of matter from its surroundings, τ is about
50 μs. For a hypothetical supermassive star with M = 109M⊙and Ro ∼a few M, τ
would be about a day.
26.4.2
26.4.2 Tidal Forces at the Gravitational Radius
What happens to the star’s surface, and an imagined observer on it, when—after
inﬁnite coordinate time but a brief proper time—it reaches the gravitational radius?
There are two possibilities: (i) the tidal gravitational forces there might be so strong
that they destroy the star’s surface and any observers on it; or (ii) the tidal forces are
not that strong, and so the star and observers must continue to exist, moving into a
region of spacetime (presumably r < 2M) that is not smoothly joined onto r > 2M in
the Schwarzschild coordinate system. In the latter case, the pathology is all due to poor
properties of Schwarzschild’s coordinates. In the former case, it is due to an intrinsic,
coordinate-independent singularity of the tide-producing Riemann curvature.
To see which is the case, we must evaluate the tidal forces felt by observers on the
surface of the imploding star. Those tidal forces are produced by the Riemann curva-
ture tensor. More speciﬁcally, if an observer’s feet and head have a vector separation
ξ at time τ as measured by the observer’s clock, then the curvature of spacetime will
exert on them a relative gravitational acceleration given by the equation of geodesic
deviation in the form appropriate to a local Lorentz frame:
d2ξ ¯j
dτ 2 = −R ¯j ¯0¯k¯0ξ ¯k
(26.52)
[Eq. (25.34)]. Here the barred indices denote components in the observer’s local
Lorentz frame. The tidal forces will become inﬁnite and will thereby destroy the
observer and all forms of matter on the star’s surface, if and only if the local Lorentz
Riemann components R ¯j ¯0¯k¯0 diverge as the star’s surface approaches the gravitational
radius. Thus, to test whether the observer and star survive, we must compute the
components of the Riemann curvature tensor in the local Lorentz frame of the star’s
imploding surface.
The easiest way to compute those components is by a transformation from compo-
nents as measured in the proper reference frames of observers who are “at rest” (ﬁxed
r, θ, φ) in the Schwarzschild spacetime. At each event on the world tube of the star’s
surface, then, we have two orthonormal frames: one (barred indices) a local Lorentz
frame imploding with the star; the other (hatted indices) a proper reference frame
at rest. Since the metric coefﬁcients in these two bases have the standard ﬂat-space
form g¯α ¯β = ηαβ, gˆα ˆβ = ηαβ, the bases must be related by a Lorentz transformation
[cf. Eq. (2.35b) and associated discussion]. A little thought makes it clear that the
required transformation matrix is that for a pure boost [Eq. (2.37a)]:
Lˆ0¯0 = Lˆr
¯r = γ ,
Lˆ0
¯r = Lˆr ¯0 = −βγ ,
L ˆθ ¯θ = L ˆφ ¯φ = 1;
γ =
1

1 −β2 , (26.53)
1266
Chapter 26. Relativistic Stars and Black Holes

with β the speed of implosion of the star’s surface, as measured in the proper reference
frame of the static observer when the surface ﬂies by. The transformation law for the
components of the Riemann tensor has, of course, the standard form for any fourth-
rank tensor:
R¯α ¯β ¯γ ¯δ = L ˆμ
¯αLˆν ¯βLˆλ
¯γLˆσ ¯δR ˆμˆνˆλˆσ.
(26.54)
The basis vectors of the proper reference frame are given by Eqs. (4) of Box 26.2, and
from that box we learn that the components of Riemann in this basis are
Rˆ0ˆrˆ0ˆr = −2M
R3 ,
Rˆ0 ˆθ ˆ0 ˆθ = Rˆ0 ˆφˆ0 ˆφ = + M
R3 ,
R ˆθ ˆφ ˆθ ˆφ = 2M
R3 ,
Rˆr ˆθ ˆr ˆθ = Rˆr ˆφˆr ˆφ = −M
R3.
(26.55)
These are the components measured by static observers.
By inserting these static-observer components and the Lorentz-transformation
matrix (26.53) into the transformation law (26.54) we reach our goal: the following
components of Riemann in the local Lorentz frame of the star’s freely imploding
surface:
R¯0¯r¯0¯r = −2M
R3 ,
R¯0 ¯θ ¯0 ¯θ = R¯0 ¯φ¯0 ¯φ = + M
R3 ,
R ¯θ ¯φ ¯θ ¯φ = 2M
R3 ,
R¯r ¯θ ¯r ¯θ = R¯r ¯φ¯r ¯φ = −M
R3.
(26.56)
These components are remarkable in two ways. First, they remain perfectly ﬁnite as
the Riemann tensor (tidal
ﬁeld), as measured on the
imploding star’s surface,
remains ﬁnite as the
surface approaches radius
r = 2M
r = 2M
r = 2M
the star’s surface approaches the gravitational radius, R →2M; correspondingly, tidal
gravity cannot destroy the star or the observers on its surface. Second, the components
ofRiemannareidenticallythesameinthetwoorthonormalframes, hattedandbarred,
which move radially at ﬁnite speed β with respect to each other [expressions (26.56)
are independent of β and are the same as Eqs. (26.55)]. This is a result of the very
special algebraic structure that Riemann’s components have for the Schwarzschild
spacetime; it will not be true in typical spacetimes.
26.4.3
26.4.3 Stellar Implosion in Eddington-Finkelstein Coordinates
From the ﬁniteness of the components of Riemann in the local Lorentz frame of
the star’s surface, we conclude that something must be wrong with Schwarzschild’s
{t, r, θ, φ} coordinate system in the vicinity of the gravitational radius r = 2M:
although nothing catastrophic happens to the star’s surface as it approaches 2M, those
coordinates refuse to describe passage through r = 2M in a reasonable, smooth, ﬁnite
way. Thus to study the implosion as it passes through the gravitational radius and
beyond, we need a new, improved coordinate system.
Several coordinate systems have been devised for this purpose. For a study and
comparison of them see, for example, Misner, Thorne, and Wheeler (1973, Chap. 31).
In this chapter we conﬁne ourselves to one of them: a coordinate system devised for
26.4 Gravitational Implosion of a Star to Form a Black Hole
1267

6
4
2
0
6
4
2
0
2
4
6
8
2
4
6
8
(a)
(b)
˜t—
M
˜t/M = 4
˜t/M = 4
t/M = 4
t/M = 4
t/M = 2
t/M = 2
t/M = 6
t/M = 6
˜t/M = 2
˜t/M = 2
˜t/M = 0
˜t/M = 0
t—
M
r/M
r/M
FIGURE 26.3 (a) The 3-surfaces of constant Eddington-Finkelstein time coordinate ˜t drawn in
a Schwarzschild spacetime diagram, with the angular coordinates {θ, φ} suppressed. (b) The 3-
surfaces of constant Schwarzschild time coordinate t drawn in an Eddington-Finkelstein spacetime
diagram, with angular coordinates suppressed.
other purposes by Arthur Eddington (1922), then long forgotten and only rediscov-
ered independently and used for this purpose by Finkelstein (1958). Yevgeny Lifshitz,
of Landau-Lifshitz fame, told one of the authors many years later what an enormous
impact Finkelstein’s coordinate system had on peoples’ understanding of the implo-
sion of stars. “You cannot appreciate how difﬁcult it was for the human mind before
Finkelstein to understand [the Oppenheimer-Snyder analysis of stellar implosion],”
Lifshitz said. When, 19 years after Oppenheimer and Snyder, the issue of Physical Re-
view containing Finkelstein’s paper arrived in Moscow, suddenly everything was clear.
Finkelstein, a postdoctoral fellow at the Stevens Institute of Technology in Hobo-
ken, New Jersey, found the following simple transformation, which moves the region
{t = ∞, r = 2M} of Schwarzschild coordinates in to a ﬁnite location. His trans-
formation involves introducing a new time coordinate
Eddington-Finkelstein time
coordinate
˜t = t + 2M ln
88[r/(2M)]−1
88,
(26.57)
but leaving unchanged the radial and angular coordinates. Figure 26.3 shows the
surfaces of constant Eddington-Finkelstein time 3 ˜t in Schwarzschild coordinates, and
the surfaces of constant Schwarzschild time t in Eddington-Finkelstein coordinates.
Notice, asadvertised, that{t = ∞, r = 2M}ismovedtoaﬁniteEddington-Finkelstein
location.
By inserting the coordinate transformation (26.57) into the Schwarzschild line
element (26.1), we obtain the following line element for Schwarzschild spacetime
written in Eddington-Finkelstein coordinates:
3.
Sometimes ˜t is also called “ingoing Eddington-Finkelstein time,” because it enables one to analyze infall
through the gravitational radius.
1268
Chapter 26. Relativistic Stars and Black Holes

6
4
2
0
6
4
2
0
2
4
6
A
A
A
B
B
C
D
E
E
E
A
A
A
A
B
B
C
D
E
E
8
2
4
6
8
(a)
(b)
t—
M
t—
M
r/M
r/M
FIGURE 26.4 (a) Radial light rays and light cones for the Schwarzschild spacetime as depicted
in Eddington-Finkelstein coordinates [Eq. (26.59)]. (b) The same light rays and light cones as
depicted in Schwarzschild coordinates [cf. Fig. 26.2]. A and B are ingoing light rays that start far
outside r = 2M; C and D are outgoing rays that start near r = 2M; E is an outgoing ray that is
trapped inside the gravitational radius.
ds2 = −

1 −2M
r

d ˜t2 + 4M
r d ˜t dr +

1 + 2M
r

dr2 + r2(dθ2 + sin2 θdφ2).
(26.58)
Notice that, by contrast with the line element in Schwarzschild coordinates, none
Schwarzschild metric in
Eddington-Finkelstein
coordinates
of the metric coefﬁcients diverge as r approaches 2M. Moreover, in an Eddington-
Finkelstein spacetime diagram, by contrast with Schwarzschild, the light cones do
not pinch down to slivers at r = 2M (compare Figs. 26.4a and 26.4b): The world lines
of radial light rays are computable in Eddington-Finkelstein, as in Schwarzschild, by
setting ds2 = 0 (null world lines) and dθ = dφ = 0 (radial world lines) in the line
element. The result, depicted in Fig. 26.4a, is
edges of radial light cone
in Eddington-Finkelstein
coordinates
d ˜t
dr = −1 for ingoing rays;
and
d ˜t
dr =
1 + 2M/r
1 −2M/r

for outgoing rays.
(26.59)
Note that, in the Eddington-Finkelstein coordinate system, the ingoing light rays
plunge unimpeded through r = 2M and onward into r = 0 along 45° lines. The
outgoing light rays, by contrast, are never able to escape outward through r = 2M:
because of the inward tilt of the outer edge of the light cone, all light rays that begin
inside r = 2M are forced forever to remain inside, and in fact are drawn inexorably
into r = 0, whereas light rays initially outside r = 2M can escape to r = ∞.
imploding star passes
through the gravitational
radius and onward to
r = 0
r = 0
r = 0 in ﬁnite Eddington-
Finkelstein coordinate
time
Now return to the implosion of a star. The world line of the star’s surface, which be-
came asymptotically frozen at the gravitational radius when studied in Schwarzschild
coordinates, plunges unimpeded through r = 2M and to r = 0 when studied in
26.4 Gravitational Implosion of a Star to Form a Black Hole
1269

6
4
2
0
6
4
2
0
2
4
6
8
2
4
6
8
t—
M
r/M
r/M
(a)
(b)
˜t—
M
FIGURE 26.5 World line of an observer on the surface of an imploding star, as depicted (a) in
an Eddington-Finkelstein spacetime diagram, and (b) in a Schwarzschild spacetime diagram;
see Ex. 26.9.
Eddington-Finkelstein coordinates; see Ex. 26.9 and compare Figs. 26.5b and 26.5a.
Thus to understand the star’s ultimate fate, we must study the region r = 0.
EXERCISES
Exercise 26.9 Example: Implosion of the Surface of a Zero-Pressure Star Analyzed in
Schwarzschild and in Eddington-Finkelstein Coordinates
Consider the surface of a zero-pressure star, which implodes along a timelike geodesic
r = R(t) in the Schwarzschild spacetime of its exterior. Analyze that implosion using
Schwarzschild coordinates {t, r, θ, φ} and the exterior metric (26.1) in those coor-
dinates, and then repeat your analysis in Eddington-Finkelstein coordinates. More
speciﬁcally, do the following.
(a) Using Schwarzschild coordinates, show that the covariant time component ut of
the 4-velocity ⃗u of a particle on the star’s surface is conserved along its world line
(cf. Ex. 25.4a). Evaluate this conserved quantity in terms of the star’s mass M and
the radius r = Ro at which it begins to implode.
(b) Use the normalization of the 4-velocity to show that the star’s radius R as a
function of the proper time τ since implosion began (proper time as measured
on its surface) satisﬁes the differential equation
dR
dτ = −[const + 2M/R]
1
2 ,
(26.60)
and evaluate the constant. Compare this with the equation of motion for the sur-
faceaspredictedbyNewtoniangravity, withpropertimeτ replacedbyNewtonian
time. (It is a coincidence that the two equations are identical.)
(c) Show from the equation of motion (26.60) that the star implodes through the
gravitational radius R = 2M and onward to R = 0 in a ﬁnite proper time given
1270
Chapter 26. Relativistic Stars and Black Holes

by Eq. (26.51). Show that this proper time has the magnitudes cited in Eq. (26.51)
and the sentences following it.
(d) Show that the Schwarzschild coordinate time t required for the star to reach its
gravitational radius, R →2M, is inﬁnite.
(e) Show, further, that when studied in Eddington-Finkelstein coordinates, the sur-
face’s implosion to R = 2M requires only ﬁnite coordinate time ˜t; in fact, a time
of the same order of magnitude as the proper time (26.51). [Hint: Derive a differ-
ential equation for d ˜t/dτ along the world line of the star’s surface, and use it to
examine the behavior of d ˜t/dτ near R = 2M.]
(f) Show that the world line of the star’s surface as depicted in an Eddington-
Finkelstein spacetime diagram has the form shown in Fig. 26.5a, and that in a
Schwarzschild spacetime diagram it has the form shown in Fig. 26.5b.
26.4.4
26.4.4 Tidal Forces at r = 0—The Central Singularity
As with r →2M, there are two possibilities: either the tidal forces as measured on the
star’s surface remain ﬁnite as r →0, in which case something must be going wrong
with the coordinate system; or else the tidal forces diverge, destroying the star. The
tidalforcesarecomputedinEx.26.10, witharemarkableresult:theydiverge.Thus, the
r = 0
r = 0
r = 0 is a spacetime
singularity; tidal gravity
becomes inﬁnite there
region r = 0 is a spacetime singularity: a region where tidal gravity becomes inﬁnitely
large, destroying everything that falls into it.
This conclusion, of course, is very unsatisfying. It is hard to believe that the correct
laws of physics will predict such total destruction. In fact, they probably do not. As
we will ﬁnd in Sec. 28.7.1, in discussing the origin of the universe, when the radius of
curvature of spacetime becomes as small as LP ≡(Gℏ/c3)
1
2 ≃10−33 cm, space and
time must cease to exist as classical entities; they and the spacetime geometry must
then become quantized. Correspondingly, general relativity must then break down
andbereplacedbyaquantumtheoryofthestructureofspacetime—aquantumtheory
of gravity. That quantum theory will describe and govern the classically singular
the singularity is governed
by the laws of quantum
gravity
region at r = 0. Since, however, only rough hints of the structure of that quantum
theory are in hand at this time, it is not known what that theory will say about the
endpoint of stellar implosion.
EXERCISES
Exercise 26.10 Example: Gore at the Singularity
(a) Show that, as the surface of an imploding star approaches R = 0, its world line in
Schwarzschildcoordinatesasymptotestothecurve{(t, θ, φ) =const, r variable}.
(b) Show that this curve to which it asymptotes [part (a)] is a timelike geodesic. [Hint:
Use the result of Ex. 25.4a.]
26.4 Gravitational Implosion of a Star to Form a Black Hole
1271

(c) Show that the basis vectors of the infalling observer’s local Lorentz frame near
r = 0 are related to the Schwarzschild coordinate basis by
⃗eˆ0 = −
2M
r
−1
 1
2 ∂
∂r ,
⃗eˆ1 =
2M
r
−1
−1
2 ∂
∂t ,
⃗eˆ2 = 1
r
∂
∂θ ,
⃗eˆ3 =
1
r sin θ
∂
∂φ .
(26.61)
What are the components of the Riemann tensor in that local Lorentz frame?
(d) Show that the tidal forces produced by the Riemann tensor stretch an infalling
observer in the radial, ⃗eˆ1, direction and squeeze the observer in the tangential, ⃗eˆ2
and ⃗eˆ3, directions.Showthatthestretchingandsqueezingforcesbecomeinﬁnitely
strong as the observer approaches r = 0.
(e) Idealize the body of an infalling observer to consist of a head of mass μ ≃20 kg
and feet of mass μ ≃20 kg separated by a distance h ≃2 m, as measured in the
observer’s local Lorentz frame, and with the separation direction radial. Compute
the stretching force between head and feet, as a function of proper time τ, as
the observer falls into the singularity. Assume that the hole has the mass M =
7 × 109M⊙, which has been measured by astronomical observations for the black
hole at the center of the supergiant elliptical galaxy M87. How long before hitting
the singularity (at what proper time τ) does the observer die, if he or she is a
human being made of ﬂesh, bone, and blood?
26.4.5
26.4.5 Schwarzschild Black Hole
Unfortunately, the singularity and its quantum mechanical structure are totally invis-
ible to observers in the external universe: the only way the singularity can possibly be
seen is by means of light rays, or other signals, that emerge from its vicinity. However,
because the future light cones are all directed into the singularity (Fig. 26.5), no light-
speed or sub-light-speed signals can ever emerge from it. In fact, because the outer
edge of the light cone is tilted inward at every event inside the gravitational radius
(Figs. 26.4 and 26.5), no signal can emerge from inside the gravitational radius to tell
external observers what is going on there. In effect, the gravitational radius is an ab-
gravitational radius as an
absolute event horizon
solute event horizon for our universe, a horizon beyond which we cannot see—except
by plunging through it, and paying the ultimate price for our momentary exploration
of the hole’s interior: we cannot publish the results of our observations.
As most readers are aware, the region of strong, vacuum gravity left behind by
the implosion of the star is called a black hole. The horizon, r = 2M, is the surface
black hole, its interior,
surface (horizon), and
exterior
of the hole, and the region r < 2M is its interior. The spacetime geometry of the
black hole, outside and at the surface of the star that creates it by implosion, is that of
1272
Chapter 26. Relativistic Stars and Black Holes

6
4
2
0
stellar surface
singularity
nonsingular
stellar matter,
r = 0
˜t—
M
2
4
6
8
r/M
horizon
FIGURE 26.6 Spacetime diagram depicting the formation and evolution of the horizon
of a black hole. The coordinates outside the surface of the imploding star are those
of Eddington and Finkelstein; those inside are a smooth continuation of Eddington
and Finkelstein (not explored in this book). Note that the horizon is the boundary
of the region that is unable to send outgoing null geodesics to radial inﬁnity.
Schwarzschild—though, of course, Karl Schwarzschild had no way of knowing this in
the few brief months left to him after his discovery of the Schwarzschild line element.
evolution of the horizon as
black hole is formed
The horizon—deﬁned as the boundary between spacetime regions that can and
cannot communicate with the external universe—actually forms initially at the star’s
center and then expands to encompass the star’s surface at the precise moment when
the surface penetrates the gravitational radius. This evolution of the horizon is de-
picted in an Eddington-Finkelstein-type spacetime diagram in Fig. 26.6.
Our discussion here has been conﬁned to spherically symmetric, nonrotating
black holes created by the gravitational implosion of a spherically symmetric star. Of
course, real stars are not spherical, and it was widely believed—perhaps we should say,
hoped—in the 1950s and 1960s that black-hole horizons and singularities would be
so unstable that small nonsphericities or small rotations of the imploding star would
save it from the black-hole fate. However, elegant and very general analyses carried
out in the 1960s, largely by the British physicists Roger Penrose and Stephen Hawk-
ing, showed otherwise. More recent numerical simulations on supercomputers have
conﬁrmed those analyses: singularities are a generic outcome of stellar implosion, as
genericity of singularities
inside black holes
are the black-hole horizons that clothe them.
EXERCISES
Exercise 26.11 Example: Rindler Approximation near the Horizon
of a Schwarzschild Black Hole
(a) Near the event {r = 2M, θ = θo, φ = φo, t ﬁnite}, on the horizon of a black
hole, introduce locally Cartesian spatial coordinates {x = 2M sin θo(φ −φo),
y = 2M(θ −θo), z =
 r
2M dr/√1 −2M/r}, accurate to ﬁrst order in distance
26.4 Gravitational Implosion of a Star to Form a Black Hole
1273

from that event. Show that the metric in these coordinates has the form (accurate
to leading order in distance from the chosen event):
ds2 = −(gH z)2dt2 + dx2 + dy2 + dz2,
where
gH =
1
4M
(26.62)
is the horizon’s so-called surface gravity, to which we shall return, for a rotating
black hole, in Eq. (26.90).
(b) Notice that the metric (26.62) is the same as that for ﬂat spacetime as seen by a
family of uniformly accelerated observers (i.e., as seen in the Rindler coordinates
of Sec. 24.5.4). Why is this physically reasonable?
Exercise 26.12 **Example: Orbits around a Schwarzschild Black Hole
Around a Schwarzschild black hole, spherical symmetry dictates that every geodesic
orbit lies in a plane that bifurcates the t = const 3-volume. We are free to orient our
coordinate system, for any chosen geodesic, so its orbital plane is equatorial: θ = π/2.
Then the geodesic has three conserved quantities: the orbiting particle’s rest mass μ,
energy-at-inﬁnity E∞, and angular momentum L, which are given by
μ2 = −⃗p2 = −gαβ
dxα
dζ
dxβ
dζ ,
E∞= −pt = −gtt
dt
dζ ,
L = pφ = gφφ
dφ
dζ ,
(26.63)
respectively. In this exercise we focus on particles with ﬁnite rest mass. Zero-rest-mass
particles can be analyzed similarly; see the references at the end of this exercise.
(a) Set the rest mass μ to unity; equivalently, switch from 4-momentum to 4-velocity
for the geodesic’s tangent vector. Then, by algebraic manipulation of the constants
of motion (26.63), derive the following orbital equations:
 dr
dζ
2
+ V 2(r) = E2
∞,
where
V 2(r) =

1 −2M
r
 
1 + L2
r2

, (26.64a)
dφ
dζ = L
r2 ,
dt
dζ =
E∞
1 −2M/r .
(26.64b)
(b) We use a device that we have also encountered in our treatment of ion acoustic
solitons in Sec. 23.6. We think of Eq. (26.64a) as an equivalent nonrelativistic
energy equation with 1
2V 2 being the effective potential energy and 1
2E2
∞the
effective total energy. As the energy we actually care about is E∞, it is more direct
to refer to V (r) as our potential and investigate its properties. This V (r) is plotted
inFig.26.7aforseveralvaluesoftheparticle’sangularmomentumL.Explainwhy:
(i) Circular geodesic orbits are at extrema of V (r)—the large dots in the ﬁgure. (ii)
Each bound orbit can be described by a horizontal line, such as the red one in the
ﬁgure, with height equal to the orbit’s E∞; and the particle’s radial motion is back
and forth between the points at which the horizontal line intersects the potential.
(c) Show that the innermost stable circular orbit (often abbreviated as ISCO) is at
r = 6M, and it occurs at a saddle point of the potential, for L = 2
√
3 M. Show
1274
Chapter 26. Relativistic Stars and Black Holes

that all inward-moving particles with L < 2
√
3 M are doomed to fall into the
black hole.
(d) Show that the innermost unstable circular orbit is at r = 3M and has inﬁnite
energyforﬁniterestmass.Fromthisinferthatthereshouldbeanunstablecircular
orbit for photons at r = 3M.
(e) The geodesic equations of motion in the form (26.64) are not very suitable for nu-
merical integration: at each radial turning point, where V (r) = E∞and dr/dζ =
0, the accuracy of straightforward integrations goes bad, and one must switch
signs of dr/dζ by hand, unless one is sophisticated. For these reasons and others,
it is preferable in numerical integrations to use the super-hamiltonian form of
the geodesic equation (Ex. 25.7), or to convert Eq. (26.64a) into a second-order
differential equation before integrating. Show that Hamilton’s equations, for the
super-hamiltonian, are
dr
dζ =

1 −2M
r

pr,
dpr
dζ = L2
r3 −M
r2 p2
r −
M
(r −2M)2E2
∞,
dφ
dζ = L
r2 .
(26.65)
When integrating these equations, one must make sure that the initial value of pr
satisﬁes gαβpαpβ = −1(for our unit-rest-mass particle). Show that this condition
reduces to
pr = ±
1
E∞
2/(1 −2M/r) −L2/r2 −1
1 −2M/r
.
(26.66)
(f) Integrate the super-hamiltonian equations (26.65) numerically for the orbit
described by the red horizontal line in Fig. 26.7a, which has L = 3.75M and
1.00
0.98
0.96
0.94
0.92
(a)
(b)
L = 4M
4.4M
25.6M
L = 3.75M
L = 2 3M
V(r)
0
5
10
15
20
25
r/M
FIGURE 26.7 (a) The potential V (r) for the geodesic radial motion r(ζ) of ﬁnite-rest-mass particles
around a Schwarzschild black hole. Each curve is labeled by the particle’s orbital angular momentum
L. (b) The orbit r(φ) corresponding to the horizontal red line in (a); it has L = 3.75M and
E∞= 0.9704. It is called a zoom-whirl orbit, because its particle zooms inward from a large radius,
whirls around the black hole several times, then zooms back out—and then repeats.
26.4 Gravitational Implosion of a Star to Form a Black Hole
1275

E∞= 0.9704. The result should be the zoom-whirl orbit depicted in Fig. 26.7b.
(The initial conditions used in that ﬁgure were r = 25M, φ = 0, and [from Eq.
(26.66)] pr = 0.0339604.)
(g) Carry out other numerical integrations to explore the variety of shapes of ﬁnite-
rest-mass orbits around a Schwarzschild black hole.
Orbits around a Schwarzschild black hole are treated in most general relativity
textbooks; see, forexample, Misner, Thorne, andWheeler(1973, Chap.25)andHartle
(2003); see also Frolov and Novikov (1998), Sec. 2.8. Analytic solutions to the geodesic
equation, expressed in terms of elliptic functions, are given by Darwin (1959).
Exercise 26.13 Example: Schwarzschild Wormhole
Our study of the Schwarzschild solution of Einstein’s equations in this chapter has
been conﬁned to situations where, at small radii, the Schwarzschild geometry joins
onto that of a star—either a static star or one that implodes to form a black hole.
Suppose, bycontrast, thatthereisnomatteranywhereintheSchwarzschildspacetime.
To get insight into this situation, construct an embedding diagram for the equatorial
2-surfaces {t = const, θ = π/2} of the vacuum Schwarzschild spacetime, using as the
starting point the line element of such a 2-surface written in isotropic coordinates
(Ex. 26.3):
(2)ds2 =

1 + M
2¯r
4
(d ¯r2 + ¯r2dφ2).
(26.67)
Show that the region 0 < ¯r ≪M/2 is an asymptotically ﬂat space, that the region
¯r ≫M/2 is another asymptotically ﬂat space, and that these two spaces are connected
byawormhole (“bridge,” “tunnel”)throughtheembeddingspace.Thisexercisereveals
that the pure vacuum Schwarzschild spacetime represents a wormhole that connects
two different universes—or, with a change of topology, a wormhole that connects two
widely separated regions of one universe.
Exercise 26.14 Example: Dynamical Evolution of Schwarzschild Wormhole
The isotropic-coordinate line element (26.16) describing the spacetime geometry of a
Schwarzschild wormhole is independent of the time coordinate t. However, because
gtt = 0 at the wormhole’s throat, ¯r = M/2, the proper time dτ =
√
−ds2 measured
by an observer at rest appears to vanish, which cannot be true. Evidently, the isotropic
coordinates are ill behaved at the throat.
(a) Martin Kruskal (1960) and George Szekeres (1960) independently introduced
a coordinate system that covers the wormhole’s entire spacetime and elucidates
its dynamics in a nonsingular manner. The Kruskal-Szekeres time and radial
coordinates v and u are related to the Schwarzschild t and r by
[r/(2M) −1]er/(2M) = u2 −v2,
(26.68)
t = 4M tanh−1(v/u)
at r > 2M,
t = 4M tanh−1(u/v)
at r < 2M.
1276
Chapter 26. Relativistic Stars and Black Holes

Show that the metric of Schwarzschild spacetime written in these Kruskal-
Szekeres coordinates is
ds2 = (32M3/r)e−r/(2M)(−dv2 + du2) + r2(dθ2 + sin2 θdφ2),
(26.69)
where r(u, v) is given by Eq. (26.68).
(b) Draw a spacetime diagram with v increasing upward and u increasing hori-
zontally and rightward. Show that the radial light cones are 45° lines every-
where. Show that there are two r = 0 singularities, one on the past hyperbola,
v = −
√
u2 + 1, and the other on the future hyperbola, v = +
√
u2 + 1. Show that
the gravitational radius, r = 2M, is at v = ±u. Show that our universe, outside
the wormhole, is at u ≫1, and there is another universe at u ≪−1.
(c) Draw embedding diagrams for a sequence of spacelike hypersurfaces, the ﬁrst of
which hits the past singularity and the last of which hits the future singularity.
Thereby show that the metric (26.69) represents a wormhole that is created in the
past, expands to maximum throat circumference 4πM, then pinches off in the
future to create a pair of singularities, one in each universe.
(d) Showthatnothingcanpassthroughthewormholefromoneuniversetotheother;
anything that tries gets crushed in the wormhole’s pinch off.
For a solution, see Fuller and Wheeler (1962), or Misner, Thorne, and Wheeler (1973,
Chap. 31). For discussions of what is required to hold a wormhole open so it can be
traversed, see Morris and Thorne (1988); and for discussions of whether arbitrarily
advanced civilizations can create wormholes and hold them open for interstellar
travel, seethenontechnicaldiscussionsandtechnicalreferencesinEverettandRoman
(2011). For a discussion of the possible use of traversable wormholes for backward
time travel, see Sec. 2.9, and also Everett and Roman (2011) and references therein.
For the visual appearance of wormholes and for guidance in constructing wormhole
images by propagating light rays through and around them, see Thorne (2014) and
James et al. (2015a).
26.5
26.5 Spinning Black Holes: The Kerr Spacetime
26.5.1
26.5.1 The Kerr Metric for a Spinning Black Hole
Consider a star that implodes to form a black hole, and assume for pedagogical sim-
plicity that during the implosion no energy, momentum, or angular momentum ﬂows
through a large sphere surrounding the star. Then the asymptotic conservation laws
discussed in Secs. 25.9.4 and 25.9.5 guarantee that the mass M, linear momentum Pj,
and angular momentum Jj of the newborn hole, as encoded in its asymptotic metric,
will be identical to those of its parent star. If (as we shall assume) our asymptotic co-
ordinates are those of the star’s rest frame (Pj = 0), then the hole will also be at rest
in those coordinates (i.e., it will also have Pj = 0).
26.5 Spinning Black Holes: The Kerr Spacetime
1277

If the star was nonspinning (Jj = 0), then the hole will also have Jj = 0, and a
powerful theorem due to Werner Israel (reviewed in Carter 1979) guarantees that—
after it has settled down into a quiescent state—the hole’s spacetime geometry will be
that of Schwarzschild.
If, instead, the star was spinning (Jj ̸= 0), then the ﬁnal, quiescent hole cannot
be that of Schwarzschild. Instead, according to powerful theorems due to Stephen
Hawking, Brandon Carter, David Robinson, and others (also reviewed in Carter
1979), its spacetime geometry will be that described by the following exact, vacuum
solution to the Einstein ﬁeld equation:
the Kerr metric for a
spinning black hole
in Boyer-Lindquist
coordinates
ds2 = −α2dt2 + ρ2
 dr2 + ρ2dθ2 + ϖ 2(dφ −ωdt)2,
(26.70a)
where
 = r2 + a2 −2Mr,
ρ2 = r2 + a2 cos2 θ,
2 = (r2 + a2)2 −a2 sin2 θ,
α2 = ρ2
2,
ϖ 2 = 2
ρ2 sin2 θ,
ω = 2aMr
2 .
(26.70b)
This is called the Kerr solution, because it was discovered by the New Zealand math-
ematician Roy Kerr (1963).
In this line element, {t, r, θ, φ} are the coordinates, and there are two constants,
M and a. The physical meanings of M and a can be deduced from the asymptotic
form of the Kerr metric (26.70) at large radii:
ds2 = −

1 −2M
r

dt2 −4Ma
r
sin2 θdφdt
+

1 + O
M
r

[dr2 + r2(dθ2 + sin2 θdφ2)].
(26.71)
By comparing with the standard asymptotic metric in spherical coordinates
the black hole’s mass
M
M
M and spin angular
momentum Ma
Ma
Ma
[Eq. (25.98d)], we see that M is the mass of the black hole, Ma ≡JH is the mag-
nitude of its spin angular momentum, and its spin points along the polar axis, θ = 0.
Evidently, then, the constant a is the hole’s angular momentum per unit mass; it has
the same dimensions as M: length (in geometrized units).
It is easy to verify that, in the limit a →0, the Kerr metric (26.70) reduces to the
Schwarzschild metric (26.1), and the coordinates {t, r, θ, φ} in which we have written
it (called “Boyer-Lindquist coordinates”) reduce to Schwarzschild’s coordinates.
Just as it is convenient to read the covariant metric components gαβ off the line
element (26.70a) via ds2 = gαβdxαdxβ, so also it is convenient to read the contra-
variant metric components
gαβ
off an expression for the wave operator:
≡⃗∇. ⃗∇= gαβ∇α∇β. (Here ∇α ≡∇⃗eα is the directional derivative along the ba-
sis vector ⃗eα.) For the Kerr metric (26.70), a straightforward inversion of the matrix
1278
Chapter 26. Relativistic Stars and Black Holes

||gαβ|| gives the ||gαβ|| embodied in the following equation:
the wave operator and
contravariant components
of the Kerr metric
= −1
α2(∇t + ω∇φ)2 + 
ρ2∇r
2 + 1
ρ2∇θ
2 + 1
ϖ 2∇φ
2.
(26.72)
26.5.2
26.5.2 Dragging of Inertial Frames
As we saw in Sec. 25.9.3, the angular momentum of a weakly gravitating body can
be measured by its frame-dragging, precessional inﬂuence on the orientation of
gyroscopes. Because the asymptotic metric (26.71) of a Kerr black hole is identi-
cal to the weak-gravity metric used to study gyroscopic precession in Sec. 25.9.3, the
black hole’s spin angular momentum JBH can also be measured via frame-dragging
gyroscopic precession.
This frame dragging also shows up in the geodesic trajectories of freely falling
particles. For concreteness, consider a particle dropped from rest far outside the black
hole. Its initial 4-velocity will be ⃗u = ∂/∂t, and correspondingly, in the distant, ﬂat
regionofspacetime, thecovariantcomponentsof ⃗uwillbeut = −1, ur = uθ = uφ = 0.
Now, theKerrmetriccoefﬁcients gαβ, likethoseofSchwarzschild, areindependent
of t and φ: the Kerr metric is symmetric under time translation (it is stationary) and
under rotation about the hole’s spin axis (it is axially symmetric). These symmetries
impose corresponding conservation laws on the infalling particle (Ex. 25.4a): ut and
uφ are conserved (i.e., they retain their initial values ut = −1 and uφ = 0 as the
particlefalls).Byraisingindices—uα = gαβuβ, usingthemetriccoefﬁcientsembodied
in Eq. (26.72)—we learn the evolution of the contravariant 4-velocity components:
ut = −gtt = 1/α2, uφ = −gtφ = ω/α2. These in turn imply that, as the particle falls,
it acquires an angular velocity around the hole’s spin axis given by
frame dragging: angular
velocity of a particle that
falls in from r = ∞
r = ∞
r = ∞
 = dφ
dt = dφ/dτ
dt/dτ = uφ
ut = ω.
(26.73)
(The coordinates φ and t are tied to the rotational and time-translation symmetries
of the spacetime, so they are very special; that is why we can use them to deﬁne a
physically meaningful angular velocity.)
At large radii, ω = 2aM/r3 →0 as r →∞. Therefore, when ﬁrst dropped, the
particle falls radially inward. However, as the particle nears the hole and picks up
speed, itacquiresasigniﬁcantangularvelocityaroundthehole’sspinaxis.Thephysical
cause of this is frame dragging: The hole’s spin drags inertial frames into rotation
around the spin axis, and that inertial rotation drags the inertially falling particle into
a circulatory orbital motion.
26.5.3
26.5.3 The Light-Cone Structure, and the Horizon
Just as for a Schwarzschild hole, so also for Kerr: the light-cone structure is a powerful
tool for identifying the horizon and exploring the spacetime geometry near it.
26.5 Spinning Black Holes: The Kerr Spacetime
1279

At any event in spacetime, the tangents to the light cone are those displacements
{dt, dr, dθ, dφ} along which ds2 = 0. The outermost and innermost edges of the
cone are those for which (dr/dt)2 is maximal. By setting expression (26.70a) to zero,
we see that dr2 has its maximum value, for a given dt2, when dφ = ωdt and dθ = 0. In
outer and inner edges of
light cone
other words, the photons that move radially outward or inward at the fastest possible
rate are those whose angular motion is that of frame dragging [Eq. (26.73)]. For these
extremal photons, the radial motion (along the outer and inner edges of the light
cone) is
dr
dt = ±α
√

ρ
= ±
 .
(26.74)
Now,  is positive deﬁnite, but  is not; it decreases monotonically with decreasing
radius, reaching zero at
r = rH ≡M +

M2 −a2
(26.75)
[Eq. (26.70b)]. (We assume that |a| < M, so rH is real; we justify this assumption
below.) Correspondingly, the light cone closes up to a sliver and then pinches off as
r →rH; it pinches onto a null curve (actually, a null geodesic) given by
r = rH ,
θ = const,
φ = Ht + const,
(26.76)
where
H = ω(r = rH) =
a
2MrH
.
(26.77)
This light-cone structure is depicted in Fig. 26.8a,b. The light-cone pinch-off as
shown there is the same as that for Schwarzschild spacetime (Fig. 26.2) except for the
light cones’ frame-dragging-induced angular tilt dφ/dt = ω. In the Schwarzschild
case, as r →2M, the light cones pinch onto the geodesic world lines {r = 2M, θ =
const, φ = const} of photons that travel along the horizon. These null world lines
are called the horizon’s generators. In the Kerr case, the light-cone pinch-off reveals
the horizon, r = rH
r = rH
r = rH, and its
rotational angular velocity,
H
H
H
that the horizon is at r = rH, and the horizon generators are null geodesics that travel
around and around the horizon with angular velocity H. This motivates us to regard
the horizon itself as having the rotational angular velocity H.
When a ﬁnite-rest-mass particle falls into a spinning black hole, its world line,
as it nears the horizon, is constrained always to lie inside the light cone. The light-
cone pinch-off then constrains its motion asymptotically to approach the horizon
generators. Therefore, as seen in Boyer-Lindquist coordinates, the particle is dragged
in Boyer-Lindquist
coordinates, infalling
particles asymptote to
horizon and to its angular
velocity
into an orbital motion, just above the horizon, with asymptotic angular velocity
dφ/dt = H, and it travels around and around the horizon “forever” (for inﬁnite
Boyer-Lindquist coordinate time t), and never (as t →∞) manages to cross through
the horizon.
1280
Chapter 26. Relativistic Stars and Black Holes

(a)
(c)
(b)
(d)
horizon
horizon
horizon
horizon
generator
generator
FIGURE 26.8 (a), (b): Light-cone structure of Kerr spacetime depicted in Boyer-
Lindquist coordinates. Drawing (b) is a spacetime diagram; drawing (a) is the
same diagram as viewed from above. (c), (d): The same light-cone structure
in Kerr coordinates.
As in the Schwarzschild case, so also in Kerr: this infall to r = rH requires only
ﬁnite proper time τ as measured by the particle, and the particle feels only ﬁnite tidal
forces (only ﬁnite values of the components of Riemann in its proper reference frame).
Therefore, as for Schwarzschild spacetime, the “barrier” to infall through r = rH must
be an illusion produced by a pathology of the Boyer-Lindquist coordinates at r = rH.
This coordinate pathology can be removed by a variety of different coordinate
transformations. One is the following change of the time and angular coordinates:
Kerr coordinates
˜t = t +
 2Mr
 dr,
˜φ = φ +

a
dr.
(26.78)
Thenew(tilded)coordinatesareavariantofacoordinatesystemoriginallyintroduced
Kerr metric in Kerr
coordinates
by Kerr, so we call them “Kerr coordinates.”4 By inserting the coordinate transforma-
tion (26.78) into the line element (26.70a), we obtain the following form of the Kerr
metric in Kerr coordinates:
4.
They are often called “ingoing Kerr coordinates,” because they facilitate analyzing infall through the
horizon.
26.5 Spinning Black Holes: The Kerr Spacetime
1281

ds2 = −α2d ˜t2 + 4Mrρ2
2
drd ˜t + ρ2(ρ2 + 2Mr)
2
dr2
+ ρ2dθ2 + ϖ 2

d ˜φ −ωd ˜t −a(ρ2 + 2Mr)
2
dr
2 .
(26.79)
It is easy to verify that when a →0 (so Kerr spacetime becomes Schwarzschild),
the Kerr coordinates (26.78) become those of Eddington and Finkelstein [Eq. (26.57)],
and the Kerr line element (26.79) becomes the Eddington-Finkelstein one [Eq.
(26.58)]. Similarly, when one explores the light-cone structure for a spinning black
holeintheKerrcoordinates(Fig.26.8c,d), oneﬁndsastructurelikethatofEddington-
Finkelstein (Fig. 26.4a): At large radii, r ≫M, the light cones have their usual 45°
form, but as one moves inward toward the horizon, they begin to tilt inward. In ad-
dition to the inward tilt, there is a frame-dragging-induced tilt in the direction of the
hole’s rotation, +φ. At the horizon, the outermost edge of the light cone is tangent to
the horizon generators; in Kerr coordinates, as in Boyer-Lindquist, these generators
rotate around the horizon with angular velocity d ˜φ/d ˜t = H [cf. Eq. (26.78), which
says that at ﬁxed r, ˜t = t + const and ˜φ = φ + const].
This light-cone structure demonstrates graphically that the horizon is at the radius
r = rH. Outside there, the outer edge of the light cone tilts toward increasing r, and
so it is possible to escape to radial inﬁnity. Inside rH the outer edge of the light cone
in Kerr coordinates,
infalling particles cross the
horizon and are pulled on
inward
tilts inward, and all forms of matter and energy are forced to move inward, toward a
singularity whose structure, presumably, is governed by the laws of quantum gravity.5
26.5.4
26.5.4 Evolution of Black Holes—Rotational Energy and Its Extraction
When a spinning star collapses to form a black hole, its centrifugal forces will ﬂat-
ten it, and the dynamical growth of ﬂattening will produce gravitational radiation
(Chap. 27). The newborn hole will also be ﬂattened and will not have the Kerr shape;
newborn black holes settle
down into Kerr form
but rather quickly, within a time t ∼100M ∼0.5 ms (M/M⊙), the deformed hole
will shake off its deformations as gravitational waves and settle down into the Kerr
shape. This is the conclusion of extensive analyses, both analytic and numerical.
Many black holes are in binary orbits with stellar companions and pull gas off their
companions and swallow it. Other black holes accrete gas from interstellar space. Any
such accretion causes a hole’s mass and spin to evolve in accord with the conservation
laws (25.102) and (25.103). One might have thought that by accreting a large amount
of angular momentum, a hole’s angular momentum per unit mass a could grow larger
than its mass M. If this were to happen, then rH = M +
√
M2 −a2 would cease to
5.
Much hoopla has been made of the fact that in the Kerr spacetime it is possible to travel inward,
through a “Cauchy horizon” and then into another universe. However, the Cauchy horizon, located
at r = M −
√
M2 −a2, is highly unstable against perturbations, which convert it into a singularity with
inﬁnite spacetime curvature. For details of this instability and the singularity, see, e.g., Brady, Droz, and
Morsink (1998), Marolf and Ori (2013), and references therein.
1282
Chapter 26. Relativistic Stars and Black Holes

be a real radius—a fact that signals the destruction of the hole’s horizon: as a grows
to exceed M, the inward light-cone tilt gets reduced, so that everywhere the outer
edge of the cone points toward increasing r, which means that light, particles, and
information are no longer trapped.
accretion of matter onto
a black hole pushes its
spin parameter aaa up to a
maximum value that is a
little less than a = M
a = M
a = M
Remarkably, however, it appears that the laws of general relativity forbid a ever to
grow larger than M. As accretion pushes a/M upward toward unity, the increasing
drag of inertial frames causes a big increase of the hole’s cross section to capture
material with negative angular momentum (which will spin the hole down) and
a growing resistance to capturing any further material with large positive angular
momentum. Infalling particles that might try to push a/M over the limit get ﬂung
back out by huge centrifugal forces, before they can reach the horizon. A black hole,
it appears, is totally resistant to having its horizon destroyed.
In 1969, Roger Penrose discovered that a large fraction of the mass of a spinning
black hole is in the form of rotational energy, stored in the whirling spacetime curva-
ture outside the hole’s horizon. Although this rotational energy cannot be localized in
any precise manner, it nevertheless can be extracted. Penrose discovered this by the
following thought experiment, which is called the Penrose process.
From far outside the hole, you throw a massive particle into the vicinity of the
hole’s horizon. Assuming you are at rest with respect to the hole, your 4-velocity
Penrose process for
extracting spin energy
from a black hole
is ⃗U = ∂/∂t. Denote by Ein
∞= −⃗pin . ⃗U = −⃗pin . (∂/∂t) = −pin
t the energy of the
particle (rest mass plus kinetic), as measured by you—its energy-at-inﬁnity in the
language of Ex. 26.4 and Sec. 4.10.2. As the particle falls, Ein
∞= −pin
t is conserved
because of the Kerr metric’s time-translation symmetry. Arrange that, as the particle
nears the horizon, it splits into two particles; one (labeled “plunge”) plunges through
thehorizonandtheother(labeled“out”)ﬂiesbackouttolargeradii, whereyoucatchit.
DenotebyEplunge
∞
≡−pplunge
t
theconservedenergy-at-inﬁnityoftheplungingparticle
and by Eout
∞≡−pout
t
that of the out-ﬂying particle. Four-momentum conservation
at the event of the split dictates that ⃗pin = ⃗pplunge + ⃗pout, which implies this same
conservation law for all components of the 4-momenta, in particular:
Eout
∞= Ein
∞−Eplunge
∞
.
(26.80)
Now, it is a remarkable fact that the Boyer-Lindquist time basis vector ∂/∂t has
a squared length ∂/∂t . ∂/∂t = gtt = −α2 + ϖ 2ω2 that becomes positive (so ∂/∂t
becomes spacelike) at radii
r < rergo ≡M +

M2 −a2 cos2 θ.
(26.81)
Notice that rergo is larger than rH everywhere except on the hole’s spin axis: θ = 0, π.
black hole’s ergosphere
The region rH < r < rergo is called the hole’s ergosphere. If the split into two parti-
cles occurs in the ergosphere, then it is possible to arrange the split such that the
scalar product of the timelike vector ⃗pplunge with the spacelike vector ∂/∂t is posi-
26.5 Spinning Black Holes: The Kerr Spacetime
1283

tive, which means that the plunging particle’s conserved energy-at-inﬁnity, Eplunge
∞
=
−⃗pplunge . (∂/∂t), is negative; whence [by Eq. (26.80)]
Eout
∞> Ein
∞.
(26.82)
See Ex. 26.16a.
When the outﬂying particle reaches your location, r ≫M, its conserved energy
is equal to its physically measured total energy (rest-mass plus kinetic), and the fact
that Eout
∞> Ein
∞means that you get back more energy (rest-mass plus kinetic) than
you put in. The hole’s asymptotic energy-conservation law (25.102) implies that the
hole’s mass has decreased by precisely the amount of energy that you have extracted:
M = −(Eout
∞−Ein
∞) = Eplunge
∞
< 0.
(26.83)
A closer scrutiny of this process (Ex. 26.16f) reveals that the plunging particle must
have had negative angular momentum, so it has spun the hole down a bit. The energy
you extracted, in fact, came from the hole’s enormous store of rotational energy, which
makes up part of its mass M. Your extraction of energy has reduced that rotational
energy.
Stephen Hawking has used sophisticated mathematical techniques to prove that,
independently of how you carry out this thought experiment, and, indeed, indepen-
dently of what is done to a black hole, general relativity requires that the horizon’s
surface area AH never decrease. This is called the second law of black-hole mechanics,
the second law of black-
hole mechanics
and it actually turns out to be a variant of the second law of thermodynamics in dis-
guise (Ex. 26.16g). A straightforward calculation (Ex. 26.15) reveals that the horizon
surface area is given by
AH = 4π(r2
H + a2) = 8πMrH
for a spinning hole,
(26.84a)
AH = 16πM2
for a nonspinning hole, a = 0.
(26.84b)
Dimitrious Christodoulou has shown (cf. Ex. 26.16) that, in the Penrose process
described here, the nondecrease of AH is the only constraint on how much energy
one can extract, so by a sequence of optimally designed particle injections and splits
that keep AH unchanged, one can reduce the mass of the hole to
Mirr =
&
AH
16π =
1
M(M +
√
M2 −a2)
2
,
(26.85)
but no smaller. This is called the hole’s irreducible mass. The hole’s total mass is the
black hole’s irreducible
mass and rotational energy
sum of its irreducible mass and its rotational energy Mrot; so the rotational energy is
Mrot = M −Mirr = M
'
1 −
&
1
2
2
1 +

1 −a2/M2
3(
.
(26.86)
1284
Chapter 26. Relativistic Stars and Black Holes

For the fastest possible spin, a = M, this gives Mrot = M(1−1/
√
2) ≃0.2929M. This
is the maximum amount of energy that can be extracted, and it is enormous compared
to the energy ∼0.005M that can be released by thermonuclear burning in a star of
mass M.
The Penrose process of throwing in particles and splitting them in two is highly
idealized, and of little or no importance in Nature. However, Nature seems to have
found a very effective alternative method for extracting rotational energy from spin-
Blandford-Znajek process
by which magnetic ﬁelds
extract energy from black
holes in Nature
ning black holes (Blandford and Znajek, 1977; Thorne, Price, and MacDonald, 1986;
McKinney, Tchekhovskoy, and Blandford, 2012; Ex. 26.21) in which magnetic ﬁelds,
threading through a black hole and held on the hole by a surrounding disk of hot
plasma, extract energy electromagnetically. This process is thought to power the gi-
gantic jets that shoot out of the nuclei of some active galaxies. It might also be the
engine for some powerful gamma-ray bursts.
EXERCISES
Exercise 26.15 Derivation: Surface Area of a Spinning Black Hole
From the Kerr metric (26.70) derive Eqs. (26.84) for the surface area of a spinning
black hole’s horizon—that is, the surface area of the 2-dimensional surface {r =
rH , t = constant}.
Exercise 26.16 **Example: Penrose Process, Hawking Radiation,
and Thermodynamics of Black Holes
This exercise is a foundation for the discussion of black-hole thermodynamics in
Sec. 4.10.2.
(a) Consider the Penrose process, described in the text, in which a particle ﬂying
inward toward a spinning hole’s horizon splits in two inside the ergosphere, and
one piece plunges into the hole while the other ﬂies back out. Show that it is always
possible to arrange this process so the plunging particle has negative energy-
at-inﬁnity: Eplunge
∞
= −⃗pplunge . ∂/∂t < 0. [Hint: Perform a calculation in a local
Lorentz frame in which ∂/∂t points along a spatial basis vector, ⃗eˆ1. Why is it
possible to ﬁnd such a local Lorentz frame?]
(b) Around a spinning black hole consider the vector ﬁeld
⃗ξH ≡∂/∂t + H∂/∂φ,
(26.87)
where H is the horizon’s angular velocity. Show that at the horizon (at radius
r = rH) this vector ﬁeld is null and is tangent to the horizon generators. Show
that all other vectors in the horizon are spacelike.
(c) In the Penrose process the plunging particle changes the hole’s mass by an amount
M and its spin angular momentum by an amount JH. Show that
M −HJH = −⃗pplunge . ⃗ξH.
(26.88)
26.5 Spinning Black Holes: The Kerr Spacetime
1285

Here ⃗pplunge and ⃗ξH are to be evaluated at the event where the particle plunges
through the horizon, so they both reside in the same tangent space. [Hint: The
angular momentum carried into the horizon is the quantity pplunge
φ
= ⃗pplunge .
∂/∂φ. Why? This quantity is conserved along the plunging particle’s world line.
Why?] Note that in Sec. 4.10.2, pφ is denoted j . ˆH—the projection of the
particle’s orbital angular momentum on the black hole’s spin axis.
(d) Show that if ⃗A is any future-directed timelike vector and ⃗K is any null vector,
both living in the tangent space at the same event in spacetime, then ⃗A . ⃗K < 0.
[Hint: Perform a calculation in a specially chosen local Lorentz frame.] Thereby
conclude that −⃗pplunge . ⃗ξH is positive, whatever may be the world line and rest
mass of the plunging particle.
(e) Show that for the plunging particle to decrease the hole’s mass, it must also
decrease the hole’s angular momentum (i.e., it must spin the hole down a bit).
(f) Hawking’s second law of black-hole mechanics says that, whatever may be the
particle’s world line and rest mass, when the particle plunges through the horizon,
it causes the horizon’s surface area AH to increase. This suggests that the always
positive quantity M −HJH = −⃗pplunge . ⃗ξH might be a multiple of the
increase AH of the horizon area. Show that this is indeed the case:
M = HJH + gH
8π AH ,
(26.89)
where gH is given in terms of the hole’s mass M and the radius rH of its horizon by
gH = rH −M
2MrH
.
(26.90)
(You might want to do the algebra, based on Kerr-metric formulas, on a com-
puter.) The quantity gH (which we have met previously in the Rindler approx-
imation; Ex. 26.11) is called the hole’s “surface gravity” for a variety of reasons.
One reason is that an observer who hovers just above a horizon generator, blast-
ing his or her rocket engines to avoid falling into the hole, has a 4-acceleration
with magnitude gH/α and thus feels a “gravitational acceleration” of this mag-
nitude; here α = gtt is a component of the Kerr metric called the lapse function
[Eqs. (26.70) and (26.72)]. This gravitational acceleration is arbitrarily large for
an observer arbitrarily close to the horizon (where  and hence α are arbitrarily
close to zero); when renormalized by α to make it ﬁnite, the acceleration is gH.
Equation (26.89) is called the “ﬁrst law of black-hole mechanics” because of its
resemblance to the ﬁrst law of thermodynamics.
(g) Stephen Hawking has shown, using quantum ﬁeld theory, that a black hole’s
horizon emits thermal (blackbody) radiation. The temperature of this “Hawking
radiation,” as measured by the observer who hovers just above the horizon, is
proportional to the gravitational acceleration gH/α that the observer measures,
1286
Chapter 26. Relativistic Stars and Black Holes

with a proportionality constant ℏ/(2πkB), where ℏis Planck’s reduced constant
and kB is Boltzmann’s constant. As this thermal radiation climbs out of the
horizon’s vicinity and ﬂies off to large radii, its frequencies and temperature get
redshifted by the factor α, so as measured by distant observers the temperature is
TH =
ℏ
2πkB
gH.
(26.91)
This suggests a reinterpretation of the ﬁrst law of black-hole mechanics (26.89)
as the ﬁrst law of thermodynamics for a black hole:
M = HJH + THSH ,
(26.92)
where SH is the hole’s entropy [cf. Eq. (4.62)]. Show that this entropy is related to
the horizon’s surface area by
SH = kB
AH
4LP
2 ,
(26.93)
where LP =

ℏG/c3 = 1.616 × 10−33 cm is the Planck length (with G Newton’s
gravitation constant and c the speed of light). Because SH ∝AH, the second
law of black-hole mechanics (nondecreasing AH) is actually the second law of
thermodynamics (nondecreasing SH) in disguise.6
(h) For a 10-solar-mass, nonspinning black hole, what is the temperature of the
Hawking radiation in Kelvins, and what is the hole’s entropy in units of the
Boltzmann constant?
(i) Rereadthediscussionsofblack-holethermodynamicsandentropyintheexpand-
ing universe in Secs. 4.10.2 and 4.10.3, which rely on the results of this exercise.
Exercise 26.17 Problem: Thin Accretion Disks: Circular, Equatorial,
Geodesic Orbits around a Kerr Black Hole
Astronomers ﬁnd and observe black holes primarily through the radiation emitted by
infalling gas. Usually this gas has sufﬁcient angular momentum to form an accretion
disk around the black hole, lying in its equatorial plane. When the gas can cool
efﬁciently, the disk is physically thin. The ﬁrst step in describing accretion disks is
to compute their equilibrium structure, which is usually approximated by assuming
that the ﬂuid elements follow circular geodesic orbits and pressure can be ignored.
6.
Actually, the emission of Hawking radiation decreases the hole’s entropy and surface area; but general
relativity is oblivious to this, because general relativity is a classical theory, and Hawking’s prediction of
the thermal radiation is based on quantum theory. Thus, the Hawking radiation violates the second law
of black-hole mechanics. It does not, however, violate the second law of thermodynamics, because the
entropy carried into the surrounding universe by the Hawking radiation exceeds the magnitude of the
decrease of the hole’s entropy. The total entropy of hole plus universe increases.
26.5 Spinning Black Holes: The Kerr Spacetime
1287

The next step is to invoke some form of magnetic viscosity that catalyzes the outward
transport of angular momentum through the disk and the slow inspiral of the disk’s
gas.Theﬁnalstepistocomputethespectrumoftheemittedradiation.Inthisproblem,
we consider only the ﬁrst step: the gas’s circular geodesic orbits.
(a) Following Ex. 26.12, we can write the 4-velocity in covariant form as uα =
{−E∞, ur, 0, L}, where E∞and L are the conserved energy and angular mo-
mentum per unit mass, respectively, and ur describes the radial motion (which
we eventually set to zero). Use uαuα = −1 and ur = dr/dτ to show that, for any
equatorial geodesic orbit:
1
2
 dr
dτ
2
+ Veff = 0, where Veff = 1 + utut + uφuφ
2grr
(26.94a)
is an effective potential that includes E∞and L inside itself [by contrast with
the effective potential we used for a Schwarzschild black hole, Eq. (26.64a), from
which E∞was pulled out].
(b) Explain why a circular orbit is deﬁned by the twin conditions, Veff = 0, ∂rVeff = 0,
and use the Boyer-Lindquist metric coefﬁcients plus computer algebra to solve for
the conserved energy and angular momentum:
E∞=
1 −2M/r ± aM1/2/r3/2
(1 −3M/r ± 2aM1/2/r3/2)1/2 , L = ±M1/2r1/2 −2aM/r ± M1/2a2/r3/2
(1 −3M/r ± 2aM1/2/r3/2)1/2
,
(26.94b)
where, in ±, the + is for a prograde orbit (same direction as hole spins) and −is
for retrograde.
(c) Explain mathematically and physically why the angular velocity  = uφ/ut
satisﬁes
∂E∞
∂r
= ∂L
∂r ,
(26.94c)
and show that it evaluates to
 =
±M1/2
r3/2 ± aM1/2 .
(26.94d)
(d) Modify the argument from Ex. 26.12 to show that the binding energy of a gas
particle in its smallest, stable, circular, equatorial orbit around a maximally rotat-
ing (a = M) Kerr hole is 1−3−1/2 = 0.423 per unit mass for prograde orbits and
1−5/33/2 = 0.0377 per unit mass for retrograde orbits. The former is a measure
of the maximum power that can be released as gas accretes onto a hole through a
thin disk in a cosmic object like a quasar. Note that it is two orders of magnitude
larger than the energy typically recoverable from nuclear reactions.
For the visual appearance of a thin accretion disk around a black hole, distorted by
gravitational lensing (bending of light rays in the Kerr metric), and for other aspects of
1288
Chapter 26. Relativistic Stars and Black Holes

ablackhole’sgravitationallensing, see, forexample, Jamesetal.(2015b)andreferences
therein.
Exercise 26.18 Problem: Thick Accretion Disks
A quite different type of accretion disk forms when the gas is unable to cool. This
can occur when its gas supply rate is either very large or very small. In the former
case, the photons are trapped by the inﬂowing gas; in the latter, the radiative cooling
timescale exceeds the inﬂow timescale. (In practice such inﬂows are likely to produce
simultaneous outﬂows to carry off the energy released.) Either way, pressure and
gravity are of comparable importance. There is an elegant description of gas ﬂow
close to the black hole as a sort of toroidal star, where the metric is associated with
the hole and not the gas. In this problem we make simple assumptions to solve for the
equilibrium ﬂow.
(a) Treat the gas as a perfect ﬂuid, and use as thermodynamic variables its pressure P
and enthalpy density w. When the gas supply rate is large, the pressure is generally
dominated by radiation. Show that in this case w = ρo + 4P, with ρo the rest-
mass density of the plasma. Show, further, that w = ρo + 5
2P when the pressure
is due primarily to nonrelativistic ions and their electrons.
(b) Assume that the motion is purely azimuthal, so the only nonzero covariant com-
ponents of the gas’s 4-velocity, in the Boyer-Lindquist coordinate system, are ut
and uφ. (In practice there will also be slow poloidal circulation and slow inﬂow.)
Show that the equation of hydrostatic equilibrium (26.31) can be written in the
form
P,a
w = utut,a + uφuφ,a,
(26.95a)
where a = r, θ, and the commas denote partial derivatives.
(c) Deﬁne for the gas the speciﬁc energy at inﬁnity, E∞= −ut; the speciﬁc ﬂuid
angular momentum, ℓ= −uφ/ut (which is L/E∞in the notation of the previous
exercise); and the angular velocity,  = dφ/dt = uφ/ut. Show that Eq. (26.95a)
can be rewritten as
−
⃗∇P
w = ⃗∇ln E∞− ⃗∇ℓ
1 −ℓ,
(26.95b)
where the spacetime gradient ⃗∇has components only in the r and θ directions,
and ℓand E∞are regarded as scalar ﬁelds.
(d) Now make the ﬁrst simplifying assumption: the gas obeys a barotropic equation
of state, P = P(w) (cf. Sec. 14.2.2). Show that this assumption implies that the
speciﬁc angular momentum ℓis a function of the angular velocity.
(e) Show that the nonrelativistic limit of this result—applicable to stars like white
dwarfs—is that the angular velocity is constant on cylindrical surfaces, which is
von Zeipel’s theorem (Ex. 13.8).
26.5 Spinning Black Holes: The Kerr Spacetime
1289

(f) Compute the shape of the surfaces on which  and ℓare constant in the r-θ
“plane” (surface of constant t and φ) for a spinning black hole with a = 0.9 M.
(g) Now make the second simplifying assumption: the speciﬁc angular momentum ℓ
is constant. Compute the shape of the isobars, also in the r-θ plane, and show that
they exhibit a cusp along a circle in the equatorial plane, whose radius shrinks as
ℓincreases.
(h) Compute the speciﬁc energy at inﬁnity, E∞, of the isobar that passes through
the cusp, and show that it can vanish if ℓis large enough. Interpret your answer
physically.
Of course it is possible to deal with more realistic assumptions about the equation
of state and the angular momentum distribution, but this relatively simple model
brings out some salient features of the equilibrium ﬂow.
Exercise 26.19 Problem: Geodetic and Lense-Thirring Precession
(a) Consider a pulsar in a circular, equatorial orbit around a massive Kerr black
hole, with the pulsar’s spin vector ⃗S lying in the hole’s equatorial plane. Using
the fact that the spin vector is orthogonal to the pulsar’s 4-velocity (Sec. 25.7),
show that its only nonzero covariant components are Sr, Sφ, and St = −Sφ,
where  = dφ/dt is the pulsar’s orbital angular velocity [Eq. (26.94d)]. Now,
neglecting usually negligible quadrupole-curvature coupling forces (Sec. 25.7),
the spin is parallel-transported along the pulsar’s geodesic, so ∇⃗u⃗S = 0. Show
that this implies
d2Sα
dτ 2 = δ
αγβ
δϵuγuϵSβ.
(26.96a)
(b) Next use Boyer-Lindquist coordinates and the results from Ex. (26.17) plus com-
puter algebra to show that the spatial part of Eq. (26.96a) takes the remarkably
simple form
d2Si
dτ 2 = −MSi
r3 ,
(26.96b)
where i = r, φ. Interpret this equation geometrically. In particular, comment on
the absence of the hole’s spin parameter a in the context of the dragging of inertial
frames, and consider how two counter-orbiting stars would precess relative to
each other.
(c) Explain why the rate of precession of the pulsar’s spin as measured by a distant
observer is given by
p =  −M1/2
r3/2ut ,
(26.96c)
where ut = dt/dτ is the contravariant time component of the pulsar’s 4-velocity.
1290
Chapter 26. Relativistic Stars and Black Holes

(d) Usecomputeralgebratoevaluatep, andshowthataTaylorexpansionforr ≫M
gives
p = 3M3/2
2r5/2 −aM
r3 + . . . .
(26.96d)
The ﬁrst term on the right-hand side is known as geodetic precession; the second
as Lense-Thirring precession.
Exercise 26.20 Challenge: General Orbits around a Kerr Black Hole
By combining the techniques used for general orbits around a Schwarzschild black
hole (Ex. 26.12) with those for equatorial orbits around a Kerr black hole (Ex. 26.17),
explore the properties and shapes of general, geodesic orbits around a Kerr hole. To
make progress on this exercise, note that because the Kerr spacetime is not spherically
symmetric, the orbits will not, in general, lie in “planes” (2- or 3-dimensional surfaces)
of any sort. Correspondingly, one must explore the orbits in 4 spacetime dimensions
rather than 3. In addition to the fairly obvious three constants of motion that the Kerr
hole shares with Schwarzschild—μ, E∞, and L [Eqs. (26.63)]—there is a fourth called
the Carter constant after Brandon Carter, who discovered it:
Q = p2
θ + cos2 θ[a2(μ2 −E2
∞) + sin−2 θL2].
(26.97)
The numerical integrations are best carried out using Hamilton’s equations for the
super-hamiltonian (Ex. 25.7).
Formulas for the geodesics and some of their properties are given in most gen-
eral relativity textbooks, for example, Misner, Thorne, and Wheeler (1973, Sec. 33.5)
and Straumann (2013, Sec. 8.4). For an extensive numerical exploration of the or-
bital shapes, based on the super-hamiltonian, see Levin and Perez-Giz (2008)—who
present and discuss the Hamilton equations in their Appendix A.
Exercise 26.21 Challenge: Electromagnetic Extraction of Energy from a Spinning
Black Hole
As discussed in the text, spinning black holes contain a considerable amount of rota-
tional energy [Eq. (26.86)]. This exercise sketches how this energy may be extracted
by an electromagnetic ﬁeld: the Blandford-Znajek process.
(a) Suppose that a Kerr black hole, described using Boyer-Lindquist coordinates
{t, r, θ, φ}, is orbited by a thick accretion disk (Ex. 26.18), whose surface near
the hole consists of two funnels, axisymmetric around the hole’s rotation axis
θ = 0 and θ = π. Suppose, further, that the funnels’ interiors contain a stationary,
axisymmetric electromagnetic ﬁeld described by a vector potential Aα(r, θ). The
surface of each funnel contains surface current and charge that keep the disk’s
interiorfreeofelectromagneticﬁeld, andthedisk’sgassuppliespressureacrossthe
26.5 Spinning Black Holes: The Kerr Spacetime
1291

funnel’s surface to balance the electromagnetic stress. Whatever plasma there may
be inside the funnel has such low density that the electromagnetic contribution
to the stress-energy tensor is dominant, and so we can write FαβJ β = 0 [cf.
Eq. (2.81b)]. Show that the electromagnetic ﬁeld tensor [Eq. (25.61)] in the Boyer-
Lindquist coordinate basis can be written Fαβ = Aβ,α −Aα,β, where the commas
denote partial derivatives.
(b) Write Aφ = /(2π), At = −V , and by considering the electromagnetic ﬁeld for
r ≫M, interpret  and V as the magnetic ﬂux contained in a circle of ﬁxed
r, θ and the electrical potential of that circle, respectively. This also remains true
near the black hole, where we deﬁne the magnetic and electric ﬁelds as those
measured by observers who move orthogonally to the hypersurfaces of constant
Boyer-Lindquist time t, so ⃗E and ⃗B can be regarded as spatial vectors E and B
that lie in those hypersurfaces of constant t. Can you prove all this?
(c) Explain why it is reasonable to expect the electric ﬁeld E to be orthogonal to
the magnetic ﬁeld B near the hole as well as far away, and use Faraday’s law to
show that its toroidal component E ˆφ must vanish. Thereby conclude that the
equipotential surfaces V = constant coincide with the magnetic surfaces  =
constant.
(d) Deﬁne an angular velocity by  = −2πV,θ/,θ, show that it, too, is constant
on magnetic surfaces, and show that an observer who moves with this angular
velocity dφ/dt =  measures vanishing electric ﬁeld. Thereby conclude that
the magnetic ﬁeld lines rotate rigidly with this angular velocity, and deduce an
expressionfortheelectricﬁeldE intermsofand.(Youmightwanttocompare
with Ex. 19.11.)
(e) Use the inhomogeneous Maxwell equations to show that the current density J α
describes a ﬂow of charge along the magnetic ﬁeld lines. Hence calculate the
current I ﬂowing inside a magnetic surface. Express B in terms of I and .
(f) Now sketch the variation of the electromagnetic ﬁeld in the funnel both near the
horizon and at a large distance from it, assuming that there is an outward ﬂow of
energy and angular momentum.
(g) Use the fact that ∂/∂t and ∂/∂φ are Killing vectors (Ex. 25.5) to conﬁrm that
electromagnetic energy and angular momentum are conserved in the funnels.
(h) We have derived these general principles without giving an explicit solution
that demonstrates energy extraction. In order to do this, we must also specify
boundary conditions at the horizon of the black hole and at inﬁnity. The former
is essentially that the electromagnetic ﬁeld be nonsingular when measured by
an infalling observer or when expressed in Kerr coordinates, for example. The
latter describes the ﬂow of energy and angular momentum as outward. Stable
solutions can be exhibited numerically and, typically, they have  ∼0.3to 0.5H
(McKinney, Tchekhovskoy, and Blandford, 2012). These solutions demonstrate
1292
Chapter 26. Relativistic Stars and Black Holes

that energy and angular momentum can ﬂow outward across the event horizon
so the mass of the black hole gradually decreases. How can this be?
26.6
26.6 The Many-Fingered Nature of Time
We conclude this chapter with a discussion of a concept that John Archibald Wheeler
(the person who has most clariﬁed the conceptual underpinnings of general relativity)
calls the many-ﬁngered nature of time.
in special relativity,
different inertial observers
slice spacetime into space
plus time differently, but
all slices are ﬂat
In the ﬂat spacetime of special relativity there are preferred families of observers:
each such family lives in a global Lorentz reference frame and uses that frame to
split spacetime into space plus time. The hypersurfaces of constant time (slices of
simultaneity) that result from that split are ﬂat hypersurfaces slicing through all of
spacetime (Fig. 26.9a). Of course, different preferred families live in different global
Lorentz frames and thus split up spacetime into space plus time in different manners
(e.g., the dotted and dashed slices of constant time in Fig. 26.9a in contrast to the solid
ones). As a result, no universal concept of time exists in special relativity. But at least
there are some strong restrictions on time: each inertial family of observers will agree
that another family’s slices of simultaneity are ﬂat slices.
In general relativity (i.e., in curved spacetime), even this restriction is gone. In a
generic curved spacetime there are no ﬂat hypersurfaces, and hence no candidates for
in general relativity, the
slices of constant time
have arbitrary shapes;
hence, the “many-ﬁngered
nature of time”
ﬂat slices of simultaneity. In addition, no global Lorentz frames and thus no preferred
families of observers exist in a generic curved spacetime. A family of observers who
are all initially at rest with respect to one another, and each of whom moves freely
(inertially), will soon acquire relative motion because of tidal forces. As a result, their
(a)
(b)
(c)
t = 3
t
x
t = 2
t = 1
t = 0
observer
observer
observer
FIGURE 26.9 Spacetime diagrams showing the slices of simultaneity as deﬁned by various families
of observers. (a) Flat spacetime. The three families (those with solid slices, those with dashed, and
those with dotted) are inertial, so their slices of constant time are those of global Lorentz frames.
(b) Curved spacetime. The two families’ slices of simultaneity illustrate the “many-ﬁngered” nature
of time. (c) Curved spacetime. The selection of an arbitrary foliation of spacelike hypersurfaces of
simultaneity, and the subsequent construction of the world lines of observers who move orthogonally
to those hypersurfaces (i.e., for whom light-ray synchronization will deﬁne those hypersurfaces as
simultaneities).
26.6 The Many-Fingered Nature of Time
1293

slices of simultaneity (deﬁned locally by Einstein light-ray synchronization, and then
deﬁned globally by patching together the little local bits of slices) may soon become
rather contorted. Correspondingly, as is shown in Fig. 26.9b, different families of
observers will slice spacetime up into space plus time in manners that can be quite
distorted, relative to one another—with “ﬁngers” of one family’s time slices pushing
forward, aheadoftheotherfamily’shere, andlaggingbehindthere, andpushingahead
in some other place.
In curved spacetime it is best to not even restrict oneself to inertial (freely falling)
observers. For example, in the spacetime of a static star, or of the exterior of a
Schwarzschild black hole, the family of static observers [observers whose world lines
are {(r, θ, φ) = const, t varying}] are particularly simple; their world lines mold
themselves to the static structure of spacetime in a simple, static manner. However,
these observers are not inertial; they do not fall freely. This need not prevent us from
using them to split up spacetime into space plus time, however. Their proper reference
frames produce a perfectly good split. When one uses that split, in the case of a black
hole, one obtains a 3-dimensional-space version of the laws of black-hole physics that
is a useful tool in astrophysical research; see Thorne, Price, and MacDonald (1986).
For any family of observers, accelerated or inertial, the slices of simultaneity as
deﬁned by Einstein light-ray synchronization over small distances (or equivalently by
the space slices of the observer’s proper reference frames) are the 3-surfaces orthogo-
an observer’s local slice
of physical simultaneity
is orthogonal to the
observer’s world line
nal to the observers’ world lines (cf. Fig. 26.9c). To see this most easily, pick a speciﬁc
event along a speciﬁc observer’s world line, and study the slice of simultaneity there
from the viewpoint of a local Lorentz frame in which the observer is momentarily at
rest. Light-ray synchronization guarantees that locally, the observer’s slice of simul-
taneity will be the same as that of this local Lorentz frame. Since the frame’s slice is
orthogonal to its own time direction and that time direction is the same as the direc-
tion of the observer’s world line, the slice is orthogonal to the observer’s world line. By
the discussion in Sec. 24.5, the slice is also locally the same (to ﬁrst order in distance
away from the world line) as a slice of constant time in the observer’s proper reference
frame.
if observers rotate around
one another, their local
slices of simultaneity
cannot mesh; so best to
choose time slices ﬁrst and
then compute observers’
orthogonal world lines
If the observers rotate around one another (in curved spacetime or in ﬂat), it is
not possible to mesh their local slices of simultaneity, deﬁned in this manner, into
global slices of simultaneity (i.e., there are no global 3-dimensional hypersurfaces
orthogonal to their world lines). We can protect against this eventuality by choosing
the slices ﬁrst: select any family of nonintersecting spacelike slices through the curved
spacetime (Fig. 26.9c). Then there will be a family of timelike world lines that are
everywhere orthogonal to these hypersurfaces. A family of observers who move along
those orthogonal world lines and who deﬁne their 3-spaces of simultaneity by local
light-ray synchronization will thereby identify the orthogonal hypersurfaces as their
simultaneities. Exercise 26.22 illustrates these ideas using Schwarzschild spacetime,
and Box 26.3 uses these ideas to visualize a black hole’s spacetime curvature.
1294
Chapter 26. Relativistic Stars and Black Holes

BOX 26.3.
TENDEX AND VORTEX LINES OUTSIDE A BLACK HOLE
When one uses a family of spacelike slices (a foliation) with unit normals (4-
velocities of orthogonally moving observers) ⃗w to split spacetime up into
space plus time, the electromagnetic ﬁeld tensor FFF splits into the electric ﬁeld
Eα = F αβwβ and the magnetic ﬁeld Bβ = 1
2ϵαβγ δFγ δwα. These are 3-vectors
lying in the spacelike slices. In terms of components in the observers’ proper
reference frames, they are E ˆj = F ˆ0 ˆj and Bˆi = ϵˆi ˆj ˆkF ˆj ˆk (see Sec. 2.11 and
especially Fig. 2.9). Similarly, the foliation splits the vacuum Riemann tensor
into the symmetric, trace-free tidal ﬁeld Eˆi ˆj = Rˆiˆ0 ˆj ˆ0 (which produces relative
accelerations aˆi = −Eˆi ˆjξ ˆj of particles separated by ξ ˆj), and the frame-
drag ﬁeld Bˆi ˆj = 1
2ϵˆi ˆp ˆqR ˆp ˆq ˆj ˆ0 (which produces differential frame dragging
ˆi = Bˆi ˆjξ ˆj). See Box 25.2.
Just as the electromagnetic ﬁeld can be visualized using electric and
magnetic ﬁeld lines that live in the spacelike slices, so also the tidal ﬁeld
Eˆi ˆj and frame-drag ﬁeld Bˆi ˆj can each be visualized using integral curves of
its three eigenvector ﬁelds: the tidal ﬁeld’s tendex lines and the frame-drag
ﬁeld’s vortex lines (Box 25.2). These lines lie in the space slices and are often
color coded by their eigenvalues, which are called the lines’ tendicities and
(frame-drag) vorticities.
For a nonspinning (Schwarzschild) black hole, the frame-drag ﬁeld van-
ishes (no spin implies no frame dragging); and the tidal ﬁeld (with slicing
either via Schwarzschild coordinate time t or Eddington-Finkelstein coordi-
nate time ˜t) has proper-reference-frame components Eˆr ˆr = −2M/r3, E ˆθ ˆθ =
E ˆφ ˆφ = +M/r3[Eq.(6)ofBox26.2].Thistidalﬁeld’seigenvectorsare ⃗eˆr, ⃗e ˆθ, and
⃗e ˆφ, and their integral curves (the tendex lines) are identical to those shown for
a weakly gravitating, spherical body in the ﬁgure at the bottom left of Box 25.2.
For a black hole with large spin, a/M = 0.95 for example, it is convenient
to choose as our space slices, hypersurfaces of constant Kerr coordinate time ˜t
[Eq. (26.78)], since these penetrate smoothly through the horizon. The tendex
and vortex lines that live in those slices have the following forms (Zhang et al.,
2012).
The tendex lines are shown on the left and in the central inset; the vortex
lines are shown on the right. The horizon is color coded by the sign of the
tendicity (left) and vorticity (right) of the lines that emerge from it: blue for
positive and red for negative.
The blue tendex lines have positive tendicity, and the tidal-acceleration
equation aˆi = −Eˆi ˆjξ ˆj says that a woman whose body is oriented along them
(continued)
26.6 The Many-Fingered Nature of Time
1295

BOX 26.3.
(continued)
tendex lines: integral curves
of eigenvectors of Eˆiˆj
vortex lines: integral curves
of eigenvectors of Bˆiˆj
gets squeezed with relative “gravitational” acceleration between head and foot
equal to the lines’ tendicity times her body length. The red lines have negative
tendicity, so they stretch a man with a head-to-foot relative acceleration equal
to the magnitude of their tendicity times his body length. Notice that near
the poles of a fast-spinning black hole, the radial tendex lines are blue, and
in the equatorial region they are red. Therefore, a man falling into the polar
regions of a fast-spinning hole gets squeezed radially, and one falling into the
equatorial regions gets stretched radially.
For a woman with her body oriented along a vortex line, the differential
frame-drag equation ˆi = Bˆi ˆjξ ˆj says that a gyroscope at her feet precesses
clockwise (blue line, positive vorticity) or counterclockwise (red line, negative
vorticity) relative to inertial frames at her head. And a gyroscope at her head
precesses in that same direction relative to inertial frames at her feet. Thus,
the vortex lines can be regarded as either counterclockwise (red) or clockwise
(blue). The precessional angular velocity is equal to the line’s (frame-drag)
vorticity times the woman’s body length.
Notice that counterclockwise (red) vortex lines emerge from the north
polar region of the horizon, swing around the south pole, and descend back
into the north polar region. Similarly, (blue) vortex lines emerge from the
horizon’s south polar region, swing around the north pole, and descend
back into the south. This is similar to the vortex lines for a spinning body in
linearized theory (bottom right ﬁgure in Box 25.2). The differential precession
is counterclockwise along the (red) near-horizon radial lines in the north
polar region, because gyroscopes near the horizon are dragged into precession
more strongly by the hole’s spin, the nearer one is to the horizon. This also
explains the clockwise precession along the (blue) near-horizon radial lines
in the south polar region.
For more details about the tendex and vortex lines of Kerr black holes, see
Zhang et al. (2012).
1296
Chapter 26. Relativistic Stars and Black Holes

EXERCISES
Exercise 26.22 Practice: Slices of Simultaneity in Schwarzschild Spacetime
(a) One possible choice of slices of simultaneity for Schwarzschild spacetime is the set
of 3-surfaces {t = const}, where t is the Schwarzschild time coordinate. Show that
the unique family of observers for whom these are the simultaneities are the static
observers, with world lines {(r, θ, φ) = const, t varying}. Explain why these slices
of simultaneity and families of observers exist only outside the horizon of a black
hole and cannot be extended into the interior. Draw a picture of the world lines
of these observers and their slices of simultaneity in an Eddington-Finkelstein
spacetime diagram.
(b) A second possible choice of simultaneities is the set of 3-surfaces {˜t =
const}, where ˜t is the Eddington-Finkelstein time coordinate. What are the world
lines of the observers for whom these are the simultaneities? Draw a picture of
those world lines in an Eddington-Finkelstein spacetime diagram. Note that they
and their simultaneities cover the interior of the hole as well as its exterior.
Bibliographic Note
In our opinion, the best elementary textbook treatment of black holes and relativistic
stars is that in Hartle (2003, Chaps. 12, 13, 15, 24); this treatment is also remarkably
complete.
For the treatment of relativistic stars at an elementary level, we also recommend
Schutz (2009, Chap. 10), and at a more advanced level (including stellar pulsations),
Straumann (2013, Chaps. 4, 9) and Misner, Thorne, and Wheeler (1973, Chaps.
31–34).
For the study of black holes at an intermediate level, see Carroll (2004, Chaps. 5, 6),
and Hobson, Efstathiou, and Lasenby (2006, Chaps. 9, 11, 13), and at more advanced
levels, Wald (1984, Chap. 12), which is brief and highly mathematical, and Straumann
(2013, Chap. 7) and Misner, Thorne, and Wheeler (1973, Chaps. 23, 24, 26), which
are long and less mathematical.
The above are all portions of general relativity textbooks. There are a number of
books and monographs devoted solely to the theory of black holes and/or relativistic
stars. Among these, we particularly recommend the following. Shapiro and Teukolsky
(1983) is an astrophysically oriented book at much the same level as this chapter, but
with much greater detail and extensive applications; it deals with black holes, neu-
tron stars, and white dwarf stars in astrophysical settings. Meier (2012) is a much
more up-to-date and quite comprehensive treatment of the astrophysics and observa-
tions of black holes of all sizes. Frolov and Novikov (1998) is a thorough monograph
on black holes, including their fundamental theory and their interactions with the rest
of the universe; it includes extensive references to the original literature and readable
summaries of all the important issues that had been treated by black-hole researchers
Bibliographic Note
1297

as of 1997. Chandrasekhar (1983) is an idiosyncratic but elegant and complete mono-
graph on the theory of black holes and especially small perturbations of them. Thorne,
Price, and MacDonald (1986) is an equally idiosyncratic monograph that formulates
the theory of black holes in 3+1 language, which facilitates physical understanding.
1298
Chapter 26. Relativistic Stars and Black Holes

27
CHAPTER TWENTY-SEVEN
Gravitational Waves and Experimental Tests
of General Relativity
A system of moving bodies emits gravitational waves. . . . We shall assume that the speeds of all
the system’s bodies are small compared to the speed of light [and that the system’s gravity is
weak]. . . . Because of the presence of matter, the equation for the radiated waves . . . will have the
form 1
2
ψk
i = κτ k
i , . . . where τ k
i . . . contain, along with the [material stress-energy tensor], also
terms of quadratic order from [the Einstein tensor].1
LEV LANDAU AND EVGENY LIFSHITZ (1941)
27.1
27.1 Overview
In 1915, when Einstein formulated general relativity, human technology was in-
adequate for testing it deﬁnitively. Only a half century later did technology begin to
catch up. In the years since then, the best experiments have improved from accuracies
of a few tens of percent to a part in 10,000 or 100,000, and general relativity has passed
the tests with ﬂying colors. In Sec. 27.2, we describe some of these tests, derive general
relativity’s predictions for them, and discuss the experimental results.
Observations of gravitational waves are changing the character of research on
general relativity. As of 2016, they have enabled observational studies of the large-
amplitude, highly nonlinear vibrations of curved spacetime triggered when two black
holes collide. Thereby, they have produced, for the ﬁrst time, tests of general rela-
tivity when gravity is ultra strong and dynamical. They are enabling high-accuracy
studies of relativistic effects in inspiraling black-hole binaries and soon should do the
same for neutron stars—where they may also teach us about the equation of state of
high-density nuclear matter. In the future, they will enable us to map the spacetime
geometries of quiescent black holes with high precision. And they might provide a
window into the physical conditions present during the ﬁrst moments of the expan-
sion of the universe (Sec. 28.7.1).
In this chapter, we develop the theory of gravitational waves in much detail and
describe efforts to detect them and the sources that may be seen. More speciﬁcally,
in Sec. 27.3, we develop the mathematics of gravitational waves, both classically and
quantum mechanically (in the language of gravitons), and we study their propaga-
tion through ﬂat spacetime. Then, in Sec. 27.4, we study their propagation through
curved spacetime using the tools of geometric optics. In Sec. 27.5, we develop the
simplest approximate method for computing the generation of gravitational waves,
the “quadrupole-moment formalism.” We also describe and present a few details of
1.
By including the quadratic terms from the Einstein tensor, Landau and Lifshitz made their analysis
of gravitational-wave generation valid for self-gravitating bodies such as binary stars—a remarkable
achievement at this early date in the development of gravitational-wave theory.
1299

BOX 27.1.
READERS’ GUIDE
.
This chapter relies signiﬁcantly on:
– Chap. 2 on special relativity;
– Chap. 24 on the transition from special relativity to general
relativity;
– Chap. 25 on the fundamental concepts of general relativity,
especially Sec. 25.9 on weak, relativistic gravitational ﬁelds;
– Chap. 26 on relativistic stars and black holes; and
– Sec. 7.3 on geometric optics.
.
In addition, Sec. 27.2.3 on Fermat’s principle and gravitational lenses
is closely linked to Sec. 7.3.6 on Fermat’s principle, Sec. 7.6 on
gravitational lenses, and Sec. 8.6 on diffraction at a caustic.
.
Portions of this chapter are a foundation for Chap. 28 on cosmology.
other, more sophisticated and accurate methods based on multipolar expansions,
post-Newtonian techniques, and numerical simulations on supercomputers (numeri-
cal relativity). In Sec. 27.6, we turn to gravitational-wave detection, focusing especially
on the Laser Interferometer Gravitational wave Observatory (LIGO), pulsar timing
arrays, and the proposed Laser Interferometer Space Antenna (LISA).
27.2
27.2 Experimental Tests of General Relativity
In this section, we describe brieﬂy some of the most important experimental tests of
general relativity. For greater detail and other tests, see Will (1993a, 2014).
27.2.1
27.2.1 Equivalence Principle, Gravitational Redshift, and Global Positioning System
A key aspect of the equivalence principle is the prediction that any object, whose size
is extremely small compared to the radius of curvature of spacetime and on which no
nongravitational forces act, should move on a geodesic. This means, in particular, that
weak equivalence principle
(i.e., universality of free
fall) and tests of it
its trajectory through spacetime should be independent of its chemical composition.
This is called the weak equivalence principle, or the universality of free fall.
Efforts to test the universality of free fall date back to Galileo’s (perhaps apoc-
ryphal) experiment of dropping objects from the leaning tower of Pisa. Over the
past century, a sequence of ever-improving experiments led by Roland von E¨otv¨os
(ca. 1920), Robert Dicke (ca. 1964), Vladimir Braginsky (ca. 1972), and Eric Adel-
berger (ca. 2008) have led to an accuracy a/a < 2 × 10−13 for the difference of
gravitational acceleration toward the Sun for Earthbound bodies with very different
chemical compositions (Schlamminger et al., 2008). A planned atom-interferometer
experiment is designed to reach a/a <∼1× 10−15 (Biedermann et al., 2015). A pro-
posed space experiment called STEP has the prospect to increase this accuracy to the
phenomenal level of a/a <∼1 × 10−18 (Overduin et al., 2012).
1300
Chapter 27. Gravitational Waves and Experimental Tests of General Relativity

General relativity predicts that bodies with signiﬁcant self-gravity (even black
tests for self-gravitating
bodies
holes) should also fall, in a nearly homogeneous external gravitational ﬁeld, with the
same acceleration as a body with negligible self-gravity. This prediction, sometimes
called the strong equivalence principle, has been tested by comparing the gravitational
accelerations of Earth and the Moon toward the Sun. Their fractional difference
of acceleration (as determined by tracking the relative motions of the Moon and
Earth using laser beams ﬁred from Earth, reﬂected off mirrors that astronauts and
cosmonauts have placed on the Moon, and received back at Earth) has been measured
to be a/a <∼1 × 10−13. Since Earth and the Moon have (gravitational potential
energy)/(rest-mass energy) ≃−4 × 10−10 and ≃−2 × 10−11, respectively, this veriﬁes
that gravitational energy falls with the same acceleration as other forms of energy to
within about 2.5 parts in 10,000. A recently discovered pulsar, J0337+1715, is in orbit
about a white dwarf binary (Ransom et al. 2014). As the gravitational binding energy
of the pulsar is roughly 10% of its mass, this will soon allow a high-accuracy test of the
strong equivalence principle. For references and for discussions of a variety of other
tests of the equivalence principle, see Merkowitz (2010) and Will (1993a, 2014).
gravitational redshift, and
tests of it
From the equivalence principle one can deduce that, for an emitter and absorber at
rest in a Newtonian gravitational ﬁeld , light (or other electromagnetic waves) must
be gravitationally redshifted by an amount λ/λ = , where  is the difference
in Newtonian potential between the locations of the emitter and receiver. (See Ex. 26.4
for a general relativistic derivation when the ﬁeld is that of a nonspinning, spherical
central body with the emitter on the body’s surface and the receiver far from the
body; see Ex. 24.16 for a derivation when the emitter and receiver are on the ﬂoor
and ceiling of an Earthbound laboratory.) Relativistic effects produce a correction to
this shift of magnitude ∼()2 [cf. Eq. (26.18)], but for experiments performed in
the solar system, the currently available precision is too poor to detect this correction,
so such experiments test the equivalence principle and not the details of general
relativity.
The highest-precision test of this gravitational redshift thus far was NASA’s 1976
Gravity-Probe-A Project (led by Robert Vessot), in which several atomic clocks were
ﬂown to a height of about 10,000 km above Earth and were compared with atomic
clocks on Earth via radio signals transmitted downward. After correcting for special
relativistic effects due to the relative motions of the rocket’s clocks and the Earth
clocks, the measured gravitational redshift agreed with the prediction to within the
experimental accuracy of about 2 parts in 10,000.
The Global Positioning System (GPS), by which one can routinely determine
inﬂuence of gravitational
redshift on GPS
one’s location on Earth to within an accuracy of about 10 m, is based on signals
transmitted from a set of Earth-orbiting satellites. Each satellite’s position is encoded
on its transmitted signals, together with the time of transmission as measured by
atomic clocks onboard the satellite. A person’s GPS receiver contains a high-accuracy
clock and a computer. It measures the signal arrival time and compares with the
encoded transmission time to determine the distance from satellite to receiver. It uses
27.2 Experimental Tests of General Relativity
1301

those distances from several satellites, together with the encoded satellite positions,
to determine (by triangulation) the receiver’s location on Earth.
The transmission times encoded on the signals are corrected for the gravitational
redshift before transmission. Without this redshift correction, the satellite clocks
would quickly get out of synchronization with all the clocks on the ground, thereby
eroding the GPS accuracy; see Ex. 27.1. Thus a clear understanding of general rela-
tivity was crucial to the design of GPS!
EXERCISES
Exercise 27.1 Practice: Gravitational Redshift for GPS
The GPS satellites are in circular orbits at a height of 20,200 km above Earth’s surface,
where their orbital period is 12 sidereal hours. If the ticking rates of the clocks on the
satellites were not corrected for the gravitational redshift, roughly how long would
it take them to accumulate a time shift, relative to clocks on Earth, large enough to
degrade the GPS position accuracy by 10 m? by 1 km?
27.2.2
27.2.2 Perihelion Advance of Mercury
It was known at the end of the nineteenth century that the point in Mercury’s orbit
closest to the Sun, known as its perihelion, advances at a rate of about 575′′ per century
with respect to the ﬁxed stars, of which about 532′′ can be accounted for by Newtonian
perturbations due to the other planets. The remaining∼43′′ per century was a mystery
until Einstein showed that it can be accounted for quantitatively by the general theory
of relativity.
More speciﬁcally (as is demonstrated in Ex. 27.2), if we idealize the Sun as non-
rotating and spherical (so its external gravitational ﬁeld is Schwarzschild), we ignore
the presence of the other planets, and we note that the radius of Mercury’s orbit is very
large compared to the Sun’s mass (in geometrized units), then Mercury’s orbit will be
predicted perihelion or
periastron advance
very nearly an ellipse; and the ellipse’s perihelion will advance, from one orbit to the
next, by an angle
φ = 6πM/p + O(M2/p2) radians.
(27.1)
Here M is the Sun’s mass,2 and p is the ellipse’s semi-latus rectum, which is related to
its semimajor axis a (half its major diameter) and its eccentricity e by p = a(1 −e2).
FortheparametersofMercury’sorbit(M = M⊙≃1.4766 km, a = 5.79089 × 107 km,
e = 0.205628), this advance is 0.10352′′ per orbit. Since the orbital period is 0.24085
Earth years, this advance corresponds to 42.98′′ per century.
Although the Sun is not precisely spherical, its tiny gravitational oblateness (as
inferred from measurements of its spectrum of pulsations; Fig. 16.3) has been shown
to contribute negligibly to this perihelion advance. In addition, the frame dragging
2.
The same formula is true in a binary whose two masses are comparable, with M the sum of the masses.
1302
Chapter 27. Gravitational Waves and Experimental Tests of General Relativity

due to the Sun’s rotational angular momentum is also (sadly!) negligible compared
to the experimental accuracy, so 42.98′′ per century is the relativistic contribution to
measurements of
perihelion advance of
Mercury’s orbit
Mercury’s perihelion advance. Modern observational data agree with this to within
the data’s accuracy of about 1 part in 1,000.
measurements of
periastron advance in
binary pulsars
The advance of periastron has also been measured in several binary pulsars. In the
double pulsar, PSR J0737-3039 (see Sec. 27.2.4), the rate is 17◦yr−1. In practice this is
used to measure the masses of the binary’s neutron stars, but it also validates Eq. (27.1)
for the advance rate at the same level, ∼10−3, as the Mercury measurement, with the
important difference that it is testing the inﬂuence of having comparable masses.
Gravity in the solar system is weak. Even at Mercury’s orbit, the gravitational po-
tential of the Sun is only || ∼3 × 10−8. Therefore, when one expands the spacetime
metric in powers of , current experiments with their fractional accuracies ∼10−5 or
worse are able to see only the ﬁrst-order terms beyond Newtonian theory (i.e., terms
of ﬁrst post-Newtonian order). To move on to second post-Newtonian order, O(2)
higher-order post-
Newtonian corrections
to periastron advance
beyond Newton, in our solar system will require major advances in technology. How-
ever, second- and higher-order effects are beginning to be measured via gravitational
waves from inspiraling compact binaries, where || is >∼0.1.
EXERCISES
Exercise 27.2 Example: Perihelion Advance
Consider a small satellite in a noncircular orbit about a spherical body with much
larger mass M, for which the external gravitational ﬁeld is Schwarzschild. The satellite
will follow a timelike geodesic. Orient the Schwarzschild coordinates so the satellite’s
orbit is in the equatorial plane: θ = π/2.
(a) Because the metric coefﬁcients are independent of t and φ, the satellite’s energy-
at-inﬁnity E∞= −pt and angular momentum L = pφ must be constants of the
satellite’s motion (Ex. 25.4a). Show that
E∞=

1 −2M
r
 dt
dτ ,
L = r2dφ
dτ .
(27.2a)
See Ex. 26.12. Here and below we take the satellite to have unit mass, so its
momentum and 4-velocity are the same, and its afﬁne parameter ζ and proper
time τ are the same.
(b) Introduce the coordinate u = r−1 and use the normalization of the 4-velocity to
derive the following differential equation for the orbit:
du
dφ
2
= E2
∞
L2 −

u2 + 1
L2

(1 −2Mu).
(27.2b)
(c) Differentiate this equation with respect to φ to obtain a second-order differential
equation:
d2u
dφ2 + u −M
L2 = 3Mu2.
(27.2c)
27.2 Experimental Tests of General Relativity
1303

By reinstating the constants G, c, and comparing with the Newtonian orbital
equation, argue that the right-hand side represents a relativistic perturbation to
the Newtonian equation of motion.
(d) Henceforth in this exercise, assume that r ≫M (i.e., u ≪1/M), and solve the
orbital equation (27.2c) by perturbation theory. More speciﬁcally, at zero order
(i.e., setting the right-hand side to zero), show that the Kepler ellipse (Goldstein,
Poole, and Safko, 2002, Sec. 3.7),
uK =
 M
L2

(1 + e cos φ),
(27.2d)
is a solution. Here e (a constant of integration) is the ellipse’s eccentricity, and
L2/M is the ellipse’s semi-latus rectum, p. The orbit has its minimum radius at
φ = 0.
(e) By substituting uK from part (d) into the right-hand side of the relativistic equa-
tion of motion (27.2c), show (to ﬁrst-order in the relativistic perturbation) that
in one orbit the angle φ at which the satellite is closest to the mass advances
by φ ≃6πM2/L2. [Hint: Try to write the differential equation in the form
d2u/dφ2 + (1 + ϵ)2u ≃. . . , where ϵ ≪1.]
(f) For the planet Mercury, using the parameter values given after Eq. (27.1), deduce
that the relativistic contribution to the rate of advance of the perihelion (point of
closest approach to the Sun) is 42.98′′ per century.
Exercise 27.3 Example: Gravitational Deﬂection of Light
RepeattheanalysisofEx.27.2foraphotonfollowinganullgeodesic.Morespeciﬁcally,
do the following.
(a) Show that the photon trajectory u(φ) (with u ≡1/r) obeys the differential
equation
d2u
dφ2 + u = 3Mu2.
(27.3)
(b) Obtain the zeroth-order solution by ignoring the right-hand side:
u = sin φ
b
,
(27.4)
where b is an integration constant. Show that this is just a straight line in the
asymptotically ﬂat region far from the body, and b is the impact parameter
(projected distance of closest approach to the body).
(c) Substitute this solution (27.4) into the right-hand side of Eq. (27.3), and show that
the perturbed trajectory satisﬁes
u = sin φ
b
+ M
b2 (1 −cos φ)2.
(27.5)
(d) Hence show that a ray with impact parameter b ≫M will be deﬂected through
an angle
1304
Chapter 27. Gravitational Waves and Experimental Tests of General Relativity

φ = 4M
b
(27.6)
[cf. Eq. (7.87) and associated discussion].
27.2.3
27.2.3 Gravitational Deﬂection of Light, Fermat’s Principle, and Gravitational Lenses
Einstein not only explained the anomalous perihelion shift of Mercury. He also pre-
gravitational deﬂection of
starlight
dicted (Ex. 27.3) that the null rays along which starlight propagates will be deﬂected,
when passing through the curved spacetime near the Sun, by an angle
φ = 4M/b + O(M2/b2)
(27.7)
relative to their trajectories if spacetime were ﬂat. Here M is the Sun’s mass, and
b is the ray’s impact parameter (distance of closest approach to the Sun’s center).
For comparison, theories that incorporated a Newtonian-like gravitational ﬁeld into
special relativity (Sec 25.1 and Ex. 25.1) predicted no deﬂection of light rays; the
corpuscular theory of light combined with Newtonian gravity predicted half the
general relativistic deﬂection, as did a 1911 principle-of-equivalence argument by
Einsteinthatwasignorantofthecurvatureofspace.Thedeﬂectionwasmeasuredtoan
measurements of
gravitational light
deﬂection
accuracy ∼20% during the 1919 solar eclipse and agreed with general relativity rather
than with the competing theories—a triumph that helped make Einstein famous.
Modern experiments, based on the deﬂection of radio waves from distant quasars,
as measured using very long baseline interferometry (interfering the waves arriving
at radio telescopes with transcontinental or transworld separations; Sec. 9.3), have
achieved accuracies of about 1 part in 10,000, and they agree completely with general
relativity. Similar accuracies are now achievable using optical interferometers in space
and may soon be achievable via optical interferometry on the ground.
These accuracies are so great that, when astronomers make maps of the sky using
either radio interferometers or optical interferometers, they must now correct for
gravitational deﬂection of the rays not only when the rays pass near the Sun but also
for rays coming in from nearly all directions. This correction is not quite as easy as Eq.
light deﬂection for large
impact parameters:
inﬂuences on astronomical
observations
(27.7) suggests, since that equation is valid only when the telescope is much farther
from the Sun than the impact parameter. In the more general case, the correction is
more complicated and must include aberration due to the telescope motion as well as
the effects of spacetime curvature.
gravitational lensing
The gravitational deﬂection of light rays passing through or near a cluster of
galaxies can produce a spectacular array of distorted images of the light source. In
Sec. 7.6, we deduced the details of this gravitational lens effect using a model in which
we treated spacetime as ﬂat but endowed with a refractive index n(x) = 1 −2(x),
where (x) is the Newtonian gravitational potential of the lensing system. This model
can also be used to compute light deﬂection in the solar system. We now derive this
model from general relativity.
27.2 Experimental Tests of General Relativity
1305

The foundation for this model is the following general relativistic version of Fer-
mat’s principle [see Eq. (7.46) for the Newtonian version]: Consider any static space-
time geometry [i.e., one for which we can introduce a coordinate system in which
∂gαβ/∂t = 0 and gjt = 0; so the only nonzero metric coefﬁcients are g00(xk) and
gij(xk)]. In such a spacetime the time coordinate t is special, since it is tied to the
spacetime’s temporal symmetry. An example is Schwarzschild spacetime and the
Schwarzschild time coordinate t. Now, consider a light ray emitted from a spatial
point xj = aj in the static spacetime and received at a spatial point xj = bj. Assum-
ing the spatial path along which the ray travels is xj(η), where η is any parameter with
xj(0) = aj, xj(1) = bj, then the total coordinate time t required for the light’s trip
from aj to bj is
general relativistic
Fermat’s principle
t =
 1
0
1
γjk
dxj
dη
dxk
dη dη,
where γjk ≡
gjk
−g00
(27.8)
(computed using the fact that the ray must be null so ds2 = g00dt2 + gijdxidxj = 0).
Fermat’s principle says that the actual spatial trajectory of the light path, in any static
spacetime, is one that extremizes this coordinate time lapse.
This principle can be proved (Ex. 27.4) by showing that the Euler-Lagrange equa-
tion for the action (27.8) is equivalent to the geodesic equation for a photon in the
static spacetime with metric gμν(xk).
Derivation of Index-of-Refraction Model.
The index-of-refraction model used to
study gravitational lenses in Sec. 7.6 is easily deduced as a special case of this Fermat
principle. In a nearly Newtonian situation, the linearized-theory, Lorenz-gauge, trace-
reversedmetricperturbationhastheform(25.91)withonlythetime-timecomponent
being signiﬁcantly large: ¯h00 = −4, ¯h0j ≃0, ¯hjk ≃0. Correspondingly, the metric
perturbation [obtained by inverting Eq. (25.85)] is h00 = −2, hjk = −2δjk, and
the full spacetime metric gμν = ημν + hμν is
ds2 = −(1 + 2)dt2 + (1 −2)δjkdxjdxk.
(27.9)
This is the standard spacetime metric (25.79) in the Newtonian limit with a special
choice of spatial coordinates, those of linearized-theory Lorenz gauge. The Newto-
nian limit includes the slow-motion constraint that time derivatives of the metric are
small compared to spatial derivatives [Eq. (25.75b)], so on the timescale for light to
travel through a lensing system, the Newtonian potential can be regarded as static:
 = (xj). Therefore, the Newtonian-limit metric (27.9) can be regarded as
Newtonian limit of
Fermat’s principle
static, and the coordinate time lapse along a trajectory between two spatial points,
Eq. (27.8), reduces to
t =
 L
0
(1 −2)dℓ,
(27.10)
where dℓ=

δjkdxjdxk is distance traveled treating the coordinates as though they
were Cartesian in ﬂat space and L is that total distance between the two points.
1306
Chapter 27. Gravitational Waves and Experimental Tests of General Relativity

According to the relativistic Fermat principle (27.8), this t is extremal for light rays.
However, Eq. (27.10) is also the action for the Newtonian, nongravitational version
of Fermat’s principle [Eq. (7.47)], with index of refraction
refractive-index model for
computing gravitational
lensing when gravity is
weak
n(xj) = 1 −2(xj).
(27.11)
Therefore, the spatial trajectories of the light rays can be computed via the Newtonian
Fermat principle, with the index of refraction (27.11).
Although this index-of-refraction model involves treating a special (Lorenz-
gauge) coordinate system as though the spatial coordinates were Cartesian and space
were ﬂat (so dℓ2 = δjkdxjdxk)—which does not correspond to reality—nevertheless,
this model predicts the correct gravitational lens images. The reason is that it predicts
the correct rays through the Lorenz-gauge coordinates, and when the light reaches
Earth, the cumulative lensing has become so great that the slight difference in the
coordinates here from truly Cartesian has negligible inﬂuence on the images one sees.
EXERCISES
Exercise 27.4 Derivation: Fermat’s Principle for a Photon’s Path in a Static Spacetime
Show that the Euler-Lagrange equation for the action principle (27.8) is equivalent
to the geodesic equation for a photon in the static spacetime metric g00(xk), gij(xk).
Speciﬁcally, do the following.
(a) The action (27.8) is the same as that for a geodesic in a 3-dimensional space with
metric γjk and with t playing the role of proper distance traveled [Eq. (25.19)
converted to a positive-deﬁnite, 3-dimensional metric]. Therefore, the Euler-
Lagrange equation for Eq. (27.8) is the geodesic equation in that (ﬁctitious) space
[Eq. (25.14) with t the afﬁne parameter]. Using Eq. (24.38c) for the connection
coefﬁcients, show that the geodesic equation can be written in the form
γjk
d2xk
dt2 + 1
2(γjk,l + γjl,k −γkl,j)dxk
dt
dxl
dt = 0.
(27.12a)
(b) Take the geodesic equation (25.14) for the light ray in the real spacetime, with
spacetime afﬁne parameter ζ, and change parameters to coordinate time t.
Thereby obtain
gjk
d2xk
dt2 + jkl
dxk
dt
dxl
dt −j00
gkl
g00
dxk
dt
dxl
dt + d2t/dζ 2
(dt/dζ)2gjk
dxk
dt = 0,
d2t/dζ 2
(dt/dζ)2 + 20k0
dxk/dt
g00
= 0.
(27.12b)
(c) Insert the second of these equations into the ﬁrst, and write the connection coef-
ﬁcients in terms of derivatives of the spacetime metric. With a little algebra, bring
your result into the form Eq. (27.12a) of the Fermat-principle Euler-Lagrange
equation.
27.2 Experimental Tests of General Relativity
1307

27.2.4
27.2.4 Shapiro Time Delay
In 1964, Irwin Shapiro proposed a new experiment to test general relativity: monitor
Shapiro time delay
the round-trip travel time for radio waves transmitted from Earth and bounced off
Venus or some other planet, or transponded by a spacecraft. As the line-of-sight
between Earth and the planet or spacecraft gradually moves nearer and then farther
from the Sun, the waves’ rays will pass through regions of greater and then smaller
spacetime curvature, which will inﬂuence the round-trip travel time by greater and
thensmalleramounts.Fromthetimeevolutionoftheround-triptime, onecandeduce
the changing inﬂuence of the Sun’s spacetime curvature.
One can compute the round-trip travel time with the aid of Fermat’s (geometric-
optics) principle. The round-trip proper time, as measured on Earth (neglecting,
for simplicity, Earth’s orbital motion; i.e., pretending Earth is at rest relative to the
Sun while a radio-wave’s rays go out and back), is τ⊕= 1 −2M/r⊕t ≃(1 −
M/r⊕)t, where M is the Sun’s mass, r⊕is Earth’s distance from the Sun’s center,
t is the round-trip coordinate time in the static solar-system coordinates, and we
have used g00 = −(1 −2M/r⊕) at Earth. Because t obeys Fermat’s principle, it is
stationary under small perturbations of the ray’s spatial trajectory. This allows us
to compute it using a straight-line trajectory through the spatial coordinate system.
Letting b be the impact parameter (the ray’s closest coordinate distance to the Sun)
and ℓbe coordinate distance along the straight-line trajectory and neglecting the
gravitational ﬁelds of the planets, we have  = −M/
√
ℓ2 + b2, so the coordinate time
lapse out and back is [Eq. (27.10)]
t = 2
 
r2
reﬂ−b2
−
r2
⊕−b2

1 +
2M
√
ℓ2 + b2

dℓ.
(27.13)
Hererreﬂistheradiusofthelocationatwhichtherayisreﬂected(ortransponded)back
to Earth. Performing the integral and multiplying by √g00 ≃1−M/r⊕, we obtain for
the round-trip travel time measured on Earth:
τ⊕= 2

a⊕+ areﬂ

*
1 −M
r⊕
+
+ 4M ln
(a⊕+ r⊕)(areﬂ+ rreﬂ)
b2

,
(27.14)
where a⊕=

r2
⊕−b2, and areﬂ=

r2
reﬂ−b2.
sharply varying term in
Shapiro time delay
As Earth and the reﬂecting planet or transponding spacecraft move along their
orbits, only one term in this round-trip time varies sharply: the term
τ⊕= 4M ln(1/b2) = −8M ln b ≃−40 μs ln b.
(27.15)
When the planet or spacecraft passes nearly behind the Sun, as seen from Earth, b
plunges to a minimum (on a timescale of hours or days) and then rises back up; corre-
spondingly, thetimedelayshowsasharpblip.Bycomparingtheobservedblipwiththe
1308
Chapter 27. Gravitational Waves and Experimental Tests of General Relativity

theory in a measurement with the Cassini spacecraft, this Shapiro time delay has been
veriﬁed to the remarkable precision of 2 × 10−5 (Bertotti, Iess, and Tortora, 2003).
The Shapiro effect has been seen in several binary pulsar systems. The two best
measurements of Shapiro
time delay in the solar
system and in binary
pulsars
examples are the double pulsar PSR J0737-3039 and PSR J1614-2230, where the lines
of sight pass within 1◦of the orbital plane, very close to the companions. The peak
Shapiro delays are 51 μs and 21 μs, respectively. Remarkably, in the second example,
the neutron star has a well-measured mass of 2.0 M⊙, which is large enough to rule
out several candidate equations of state for cold nuclear matter (DeMorest et al., 2010)
(cf. Sec. 26.3.5).
27.2.5
27.2.5 Geodetic and Lense-Thirring Precession
As we have discussed in Secs. 25.9.3 and 26.5, the mass M and the angular momentum
J of a gravitating body place their imprint on the body’s asymptotic spacetime metric:
ds2 = −

1 −2M
r

dt2 −
4ϵjkmJ kxm
r3
dt dxj +

1 + O
M
r

δjkdxjdxk (27.16)
[Eq.(25.98c)].Themassimprintcanbededucedfrommeasurementsoftheorbitalan-
gularvelocity =

M/r3ofanobjectinacircularorbit, andtheangular-momentum
imprint, from the precession it induces in an orbiting gyroscope [Eq. (25.100)].
As we deduced in Ex. 26.19, there are actually two precessions: geodetic preces-
sion and Lense-Thirring precession. The geodetic precession, like the orbital angular
geodetic precession of a
gyroscope
velocity, arises from the spherically symmetric part of the metric; it says that the spin
of a gyroscope in a circular orbit of radius r will precess around the orbit’s angular
momentum vector at a rate 3
2(M/r). The Lense-Thirring precession is the average
Lense-Thirring precession
of a gyroscope
of Eq. (25.100) around the orbit, which gives J/(2r3) for a polar orbit, −J/r3 for an
equatorial orbit, and (−Ji + 3
2PijJj)/r3 for a general circular orbit, where J is the
central body’s angular momentum, r is the orbital radius, and Pij projects into the
plane of the orbit.
measurements of
precessions by GP-B
and LAGEOS
The earth-orbiting experiment Gravity Probe B (GP-B), led by Francis Everitt, has
measured these two precessions (Everitt et al., 2011). GP-B comprises four spinning
spheres (gyroscopes) in one satellite on a polar orbit, and has veriﬁed the geodetic
precession of 6.6′′ yr−1 to a fractional accuracy of 0.003, and the Lense-Thirring
precession of 0.040′′ yr−1 to fractional accuracy 0.2. More recently, a combination
of three satellites, LAGEOS, LAGEOS2, and LARES, has been used to measure the
Lense-Thirring precession of an inclined equatorial orbit (rather than a gyroscope in
orbit), where the prediction is J/r3 = 0.080′′ yr−1. A fractional accuracy of 0.05 has
been reported (Ciufolini et al., 2016).
Relativistic precession has also been observed in six binary pulsar systems. Here
we must take account of the pulsar (p) and its compact companion (c). We can give a
heuristic argument for the precession rate. When mp ≪mc, the dominant precession
is geodetic in the gravitational ﬁeld of the companion at a rate p = 3
2(mc/r). In
the opposite limit, the companion undergoes orbital Lense-Thirring precession at a
27.2 Experimental Tests of General Relativity
1309

rate p = 2Jp/r3 and so the torque is (2mc ⃗Jp/r) × ⃗, and the reﬂex precession of
the pulsar, about the total (orbital plus spin) angular momentum, will be at a rate
p = (2mc/r). The simplest interpolation between these two limiting cases is
precession in binary
pulsars
p = mc
r
(3mc + 4mp)
2(mc + mp) .
(27.17)
This turns out to be correct. If the orbit is elliptical, we (again) replace the radius r
with the semi-latus rectum p.
The best measured example is the double pulsar PSR J0737-3039, where pulses
from both pulsars were observed. One pulsar has a spin almost aligned with the
orbital angular momentum, and so its precession is hard to measure. The other has an
inclined spin, which has now precessed so far that the pulses are no longer detected.
However, this precession changes the projected shape of the magnetosphere, which
occults the pulses from the nonprecessing pulsar, allowing a measurement of the
measurements of
precession in double
pulsars
rate of precession of 4.7 ± 0.6◦yr−1, which is consistent with the predicted value of
5.1◦yr−1 (Kramer et al., 2006).
27.2.6
27.2.6 Gravitational Radiation Reaction
Radio observations ofbinarypulsarshave alreadyprovidedseveral indirect detections
of gravitational waves, via radiation reaction in the binary.
Hulse-Taylor pulsar
The ﬁrst binary pulsar (PSR B1913+16) was discovered in 1974 by Russell Hulse
and Joseph Taylor. One star is a pulsar that emits radio pulses with a period of ∼59 ms
at predictable times (allowing for the slowing down of the pulsar), and their arrival
times can be determined to ∼15 μs. Its companion is almost certainly a neutron star,
but it does not pulse. The orbital period is roughly 8 hours, and the orbit’s eccentricity
is ∼0.6. The pulses are received at Earth with Shapiro time delays due to crossing the
binary orbit, and with other relativistic effects.
We do not know a priori the orbital inclination or the neutron-star masses.
However, we obtain one relation between these three quantities by analyzing the
Newtonian orbit. A second relation comes from measuring the consequences of the
combined second-order Doppler shift and gravitational redshift as the pulsar moves
in and out of its companion’s gravitational ﬁeld. A third relation comes from mea-
suring the relativistic precession of the orbit’s periastron. From these three relations,
one can solve for the stars’ masses and the orbital inclination, and as a check can
verify that the Shapiro time delay comes out correctly. One can then use the sys-
measurement of
gravitational radiation
reaction in binary pulsars
tem’s parameters to predict the rate of orbital inspiral due to gravitational radiation
reaction—a phenomenon with a magnitude of ∼||2.5 beyond Newton (i.e., 2.5
post-Newtonian order; Sec. 27.5.3). The prediction agrees with the measurements
to an accuracy of ∼2 × 10−3 (Weissberg, Nice, and Taylor, 2010)—a major triumph
for general relativity! The agreement is even better, <10−3, for the double pulsar
PSR J0737-3039.
1310
Chapter 27. Gravitational Waves and Experimental Tests of General Relativity

In LIGO’s observations of gravitational waves from the inspiral of binary black
holes, the radiation reaction is measured with lower accuracy than this, but because
the binary is so compact—with M/a increasing from ∼0.01 to ∼0.3—higher-order
corrections to the radiation reaction are readily measured.
For reviews of other tests of general relativity using binary pulsars, see Kaspi and
Kramer (2016) and papers cited therein.
27.3
27.3 Gravitational Waves Propagating through Flat Spacetime
Gravitational waves are ripples in the curvature of spacetime that are emitted by
nature of gravitational
waves
violent astrophysical events and that propagate with the speed of light. It was clear
to Einstein and others, even before general relativity was fully formulated, that his
theory would have to predict gravitational waves, and within months after completing
the theory, Einstein (1916b, 1918) worked out those waves’ basic properties.
penetrating power of
gravitational waves
It turns out that, after they have been emitted, gravitational waves propagate
through matter with near impunity: they propagate as though in vacuum, even when
other matter and ﬁelds are present. (For a proof and discussion see, e.g., Thorne, 1983,
Sec. 2.4.3.) This justiﬁes specializing our analysis to vacuum propagation.
27.3.1
27.3.1 Weak, Plane Waves in Linearized Theory
Once the waves are far from their source, the radii of curvature of their phase fronts
are huge compared to a wavelength, as is the radius of curvature of the spacetime
through which they propagate. Thus to high accuracy, we can idealize the waves as
plane-fronted and as propagating through ﬂat spacetime. The appropriate formalism
linearized theory of
gravitational-wave
propagation:
for describing this is the linearized theory developed in Sec. 25.9.2.
We introduce coordinates that are as nearly Lorentz as possible, so the spacetime
metric can be written as
metric perturbation
gαβ = ηαβ + hαβ,
with |hαβ| ≪1
(27.18a)
[Eq. (25.82)], and we call hαβ the waves’ metric perturbation.We perform an “inﬁnites-
imal coordinate transformation” (gauge change):
xα
new(P) = xα
old(P) + ξα(P),
which produces hnew
μν = hold
μν −ξμ,ν −ξν,μ
(27.18b)
[Eqs. (25.87) and (25.88)], with the gauge-change generators ξα(P) chosen to impose
impose Lorenz gauge
the Lorenz gauge condition
¯hμν
,ν = 0
(27.18c)
[Eq. (25.89)] on the new trace-reversed metric perturbation:
trace-reversed metric
perturbation
¯hμν ≡hμν −1
2h ημν,
h ≡ηαβhαβ
(27.18d)
27.3 Gravitational Waves Propagating through Flat Spacetime
1311

[Eqs. (25.85) and (25.84)]. In this Lorenz gauge, the vacuum Einstein ﬁeld equation
becomes the ﬂat-space wave equation for ¯hμν and so also for hμν:
wave equation
¯hμν,α
α = hμν,α
α = 0
(27.18e)
[Eq. (25.90)]. Here all indices after a comma are partial derivatives and they are raised
with the ﬂat metric hμν,α
α = hμν,αβηβα.
This is as far as we went in vacuum (far from the waves’ source) in Chap. 25.
We now go further. We simplify the mathematics by orienting the axes of our nearly
Lorentz coordinates so the waves are planar and propagate in the z direction. Then
the obvious solution to the wave equation (27.18e) and the consequence of the Lorenz
gauge condition (27.18c) are
¯hμν = ¯hμν(t −z),
¯hμ0 = −¯hμz.
(27.19)
Therearenowsixindependentcomponentsofthetrace-reversedmetricperturbation:
the six spatial ¯hij; the second of Eqs. (27.19) ﬁxes the time-space and time-time
components in terms of them.
Remarkably, these six independent components can be reduced to two by a further
specializationofgauge.Theoriginalinﬁnitesimalcoordinatetransformation(27.18b),
which brought us into Lorenz gauge, relied on four functions ξμ(P) = ξμ(xα) of four
spacetime coordinates. A more restricted set of gauge-change generators, ξμ(t −z),
further specialization to
TT gauge
that are functions solely of retarded time (and thus satisfy the wave equation) will
keep us in Lorenz gauge and can be used to annul the four components ¯hxz, ¯hyz, ¯hzz,
and ¯h ≡ημν ¯hμν, whence (thanks to the Lorenz conditions ¯hμ0 = −¯hμz) all the ¯hμ0
are also annulled. See Ex. 27.5. As a result, the trace-reversed metric perturbation ¯hμν
and the metric perturbation hμν are now equal, and their only nonzero components
are hxx = −hyy and hxy = +hyx.
for locally plane waves
propagating in zzz direction
This special new gauge has the name transverse-traceless gauge or TT gauge, be-
cause in it the metric perturbation is purely spatial, it is transverse to the waves’
propagation direction (the z direction), and it is traceless. It is convenient to use the
notation hTT
μν for the metric perturbation in this TT gauge, and convenient to give the
names h+ and h× to its two independent, nonzero components (which are associated
with two polarization states for the waves, “+” and “×”):
the metric perturbation in
TT gauge; gravitational-
wave ﬁelds h+
h+
h+ and
h×
h×
h×
hTT
xx = −hTT
yy = h+(t −z),
hTT
xy = +hTT
yx = h×(t −z).
(27.20)
The Riemann curvature tensor in this TT gauge, as in any gauge, can be expressed as
Riemann tensor
Rαβγ δ = 1
2hTT
{αβ,γ δ} ≡1
2(hTT
αδ,βγ + hTT
βγ ,αδ −hTT
αγ ,βδ −hTT
βδ,αγ)
(27.21)
[Eq. (25.80)]. Here the subscript symbol {.}, analogous to [.] for antisymmetrization
and (.) for symmetrization, means the combination of four terms on the right side of
the ≡sign. Of particular interest for physical measurements is the relativistic tidal
1312
Chapter 27. Gravitational Waves and Experimental Tests of General Relativity

ﬁeld Eij = Ri0j0, which produces a relative acceleration of freely falling particles
[geodesic deviation; Eq. (25.34)]. Since the temporal components of hTT
μν vanish, the
only nonzero term in Eq. (27.21) for Ri0j0 is the third one, in which the temporal
components are derivatives, whence
tidal ﬁelds
Eij = Ri0j0 = −1
2
¨hTT
ij ;
or
Exx = −Eyy = −1
2
¨h+(t −z),
Exy = +Eyx = −1
2
¨h×(t −z).
(27.22)
Here the dots mean time derivatives: ¨h+(t −x) ≡∂2h+/∂t2. A useful index-free way
to write these equations is
E = −1
2
¨hhhTT = −1
2
¨h+eee+ −1
2
¨h×eee×,
(27.23a)
where
polarization tensors
eee+ = ⃗ex ⊗⃗ex −⃗ey ⊗⃗ey,
eee× = ⃗ex ⊗⃗ey + ⃗ey ⊗⃗ex
(27.23b)
are the polarization tensors associated with the + and × polarizations, respectively.
gauge invariance of
Riemann tensor
It is a very important fact that the Riemann curvature tensor is gauge invariant.
An inﬁnitesimal coordinate transformationxα
new(P) = xα
old(P) + ξα(P) changes it by
tiny fractional amounts of order ξα, by contrast with the metric perturbation, which
is changed by amounts of order itself: δhμν = −2ξ(μ,ν) (i.e., by fractional amounts of
order unity; Ex. 25.19). This has two important consequences. (i) The gauge-invariant
Riemann tensor (or its space-time-space-time part, the tidal ﬁeld) is an optimal
tool for discussing physical measurements (Sec. 27.3.2)—a much better tool than,
for example, the gauge-dependent metric perturbation. (ii) The gauge invariance of
Riemann motivates us to change our viewpoint on hTT
ij in the following way.
alternative viewpoint:
gravitational wave ﬁeld
deﬁned in terms of
Riemann tensor’s tidal
ﬁeld
We deﬁne a dimensionless “gravitational-wave ﬁeld” hTT
ij to be minus twice the
double time integral of the wave’s tidal ﬁeld:
hTT
ij ≡−2

dt

dt Eij.
(27.24)
And we regard the computation that led to Eq. (27.22) as a demonstration that it is
possibletoﬁndagaugeinwhichthemetricperturbationispurelyspatialanditsspatial
part is equal to this gravitational-wave ﬁeld: h0μ = 0 and hij = hTT
ij .
In Box 27.2, we show that, if we have found a gauge in which the metric per-
turbation propagates as a plane wave at the speed of light, then we can compute the
gravitational-wave ﬁeld hTT
ij from that gauge’s hαβ or ¯hαβ by a simple projection pro-
cess. This result is useful in the theory of gravitational-wave generation (see, e.g.,
Sec. 27.5.2).
27.3 Gravitational Waves Propagating through Flat Spacetime
1313

BOX 27.2.
PROJECTING OUT THE GRAVITATIONAL-WAVE FIELD hTT
ij
Suppose that, for some gravitational wave, we have found a gauge (not
necessarily TT) in which hμν = hμν(t −z). Then a simple calculation with
Eq. (25.80) reveals that the only nonzero components of this wave’s tidal
ﬁeld are Eab = −1
2 ¨hab, where a and b run over x and y. But by deﬁnition,
Eab = −1
2 ¨hTT
ab . Therefore, in this gauge we can compute the gravitational-wave
ﬁeld by simply throwing away all parts of hμν except the spatial, transverse
parts: hTT
xx = hxx, hTT
xy = hxy, and hTT
yy = hyy.
When computing the generation of gravitational waves, it is often easier
to evaluate the trace-reversed metric perturbation ¯hαβ than the metric
perturbation itself [e.g., Eq. (25.91)]. But ¯hαβ differs from hαβ by only a trace,
and the gravitational-wave ﬁeld hTT
jk is traceless. Therefore, in any gauge where
¯hμν = ¯hμν(t −z), we can compute the gravitational-wave ﬁeld hTT
jk from ¯hμν
by throwing away everything except its spatial, transverse part, and by then
removing its trace (i.e., by projecting out the spatial, transverse, traceless part):
hTT
jk =
¯hjk
TT ;
or
h+ = hTT
xx = ¯hxx −1
2(¯hxx + ¯hyy) = 1
2(hxx −hyy),
h× = hTT
xy = ¯hxy.
(1)
Here the symbol
¯hjk
TT means “project out the spatial, transverse, traceless
part.”
If we rotate the spatial axes so the waves propagate along the unit spatial
vector n instead of along ez, then the “speed-of-light-propagation” forms of
the metric perturbation and its trace reversal become hαβ = hαβ(t −n . x)
and ¯hαβ = ¯hαβ(t −n . x), respectively, and the TT projection can be achieved
with the aid of the transverse projection tensor:
P jk ≡δjk −nj nk.
(2)
Speciﬁcally, we have
hTT
jk = (¯hjk)TT = Pj
lPk
m ¯hlm −1
2PjkP lm ¯hlm.
(3)
Here the notation is that of Cartesian coordinates with Pj
k = P jk = Pjk.
1314
Chapter 27. Gravitational Waves and Experimental Tests of General Relativity

EXERCISES
Exercise 27.5 Derivation: Bringing hμν into TT Gauge
Consider a weak, planar gravitational wave propagating in the z direction, written
in a general Lorenz gauge [Eqs. (27.19)]. Show that by appropriate choices of new
gauge-change generators that have the plane-wave form ξμ(t −z), one can (i) keep
the metric perturbation in Lorenz gauge; (ii) annul ¯hxz, ¯hyz, ¯hzz, and ¯h ≡ημν ¯hμν;
and (iii) thereby make the only nonzero components of the metric perturbation be
hxx = −hyy and hxy = +hyx. [Hint: Show that a gauge change (27.18b) produces
¯hnew
μν = ¯hold
μν −ξμ,ν −ξν,μ + ημνξα
,α, and use this in your computations.]
27.3.2
27.3.2 Measuring a Gravitational Wave by Its Tidal Forces
We seek physical insight into gravitational waves by studying the following idealized
problem. Consider a cloud of test particles that ﬂoats freely in space and is static and
spherical before the waves pass. Study the wave-induced deformations of the cloud as
viewedinthenearestthingthereistoarigid, orthonormalcoordinatesystem:thelocal
Lorentz frame (in the physical spacetime) of a “ﬁducial particle” that sits at the cloud’s
center.Inthatframethedisplacementvectorζ j betweentheﬁducialparticleandsome
other particle has components ζ j = xj + δxj, where xj is the other particle’s spatial
coordinate before the waves pass, and δxj is its coordinate displacement produced by
the waves. By inserting this into the local-Lorentz-frame variant of the equation of
geodesic deviation [Eq. (25.34)], and neglecting the tiny δxk compared to xk on the
right-hand side, we obtain
gravitational-wave tidal
acceleration
d2δxj
dt2
= −Rj0k0xk = −Ejkxk = 1
2
¨hTT
jk xk,
(27.25)
which can be integrated twice to give
gravitational-wave tidal
displacement
δxj = 1
2hTT
jk xk.
(27.26)
Expression (27.25) is the gravitational-wave tidal acceleration that moves the particles
back and forth relative to one another. It is completely analogous to the Newtonian
tidal acceleration, −Ejkxk = −(∂2/∂xj∂xk)xk, by which the Moon raises tides on
Earth’s oceans (Sec. 25.5.1).
Now specialize to a wave with + polarization (for which h× = 0). By inserting
expression (27.20) into (27.26), we obtain
tidal displacements
produced by h+
h+
h+
δx = 1
2h+x,
δy = −1
2h+y,
δz = 0.
(27.27)
This displacement is shown in Fig. 27.1a,b. Notice that as the gravitational-wave ﬁeld
h+ oscillates at the spherical cloud’s location, the cloud is left undisturbed in the
z-direction (propagation direction), and in transverse planes it gets deformed into
an ellipse elongated ﬁrst along the x-axis (when h+ > 0), then along the y-axis (when
27.3 Gravitational Waves Propagating through Flat Spacetime
1315

(a)
(b)
y
y
y
y
x
x
x
x
(c)
(d)
FIGURE 27.1 Physical manifestations, in a particle’s local Lorentz frame, of h+ gravitational waves.
(a) Transverse deformation of an initially spherical cloud of test particles in a transeverse plane
at a phase of the wave when h+ > 0. (b) Deformation of the cloud when h+ < 0. (c) Field lines
representing the acceleration ﬁeld δ¨x that produces the cloud’s deformation, at a phase when ¨h+ > 0.
(d) Acceleration ﬁeld lines when ¨h+ < 0.
h+ < 0). Because Exx = −Eyy (i.e., because Ejk is traceless), the ellipse is squashed
along one axis by the same amount as it is stretched along the other (i.e., the area of
the ellipse is preserved during the oscillations).
The effects of the h+ polarization state can also be described in terms of the tidal
h+
h+
h+ tidal acceleration
described by lines of force
acceleration ﬁeld that it produces in the central particle’s local Lorentz frame:
d2
dt2δx = −E+ . x = 1
2
¨h+(xex −yey),
(27.28)
where ¨h+ ≡∂2h+/∂t2. Notice that this acceleration vector ﬁeld δ¨x is divergence free.
Becauseitisdivergencefree, itcanberepresentedbylinesofforceanalogoustoelectric
ﬁeld lines, which point along the ﬁeld and have a density of lines proportional to the
magnitude of the ﬁeld. When this is done, the ﬁeld lines never end. Figure 27.1c,d
shows this acceleration ﬁeld at the phases of oscillation when ¨h+ is positive and when
itisnegative.Noticethattheﬁeldisquadrupolarinshape, withaﬁeldstrength(density
oflines)thatincreaseslinearlywithdistancefromtheoriginofthelocalLorentzframe.
The elliptical deformations of the spherical cloud of test particles shown in Fig. 27.1a,b
are the responses of that cloud to this quadrupolar acceleration ﬁeld. The polarization
state that produces these accelerations and deformations is called the + state because
of the orientation of the axes of the quadrupolar acceleration ﬁeld (Fig. 27.1c,d).
tidal effects of h×
h×
h×
Next consider the × polarization state. In this state the deformations of the initially
spherical cloud are described by
δx = 1
2h×y,
δy = 1
2h×x,
δz = 0.
(27.29)
These deformations, like those for the + state, are purely transverse; they are depicted
in Fig. 27.2a,b. The acceleration ﬁeld that produces these deformations is
d2
dt2δx = −E× . x = 1
2
¨h×(yex + xey).
(27.30)
1316
Chapter 27. Gravitational Waves and Experimental Tests of General Relativity

(a)
(b)
y
y
y
y
x
x
x
x
(c)
(d)
FIGURE 27.2 Physical manifestations, in a particle’s local Lorentz frame, of h× gravitational waves.
(a) Deformation of an initially spherical cloud of test particles in a transverse plane at a phase of
the wave when h× > 0. (b) Deformation of the sphere when h× < 0. (c) Field lines representing the
acceleration ﬁeld δ¨x that produces the sphere’s deformation, at a phase of the wave when ¨h× > 0.
(d) Acceleration ﬁeld lines when ¨h× < 0.
This acceleration ﬁeld, like the one for the + polarization state, is divergence free
and quadrupolar; the ﬁeld lines describing it are depicted in Fig. 27.2c,d. The name
“× polarization state” comes from the orientation of the axes of this quadrupolar
acceleration ﬁeld.
Planar gravitational waves can also be depicted in terms of the tendex and vortex
lines associated with their tidal tensor ﬁeld E and frame-drag tensor ﬁeld B; see
Box 27.3.
When deﬁning the gravitational-wave ﬁelds h+ and h×, we have relied on a
choice of (local Lorentz) reference frame (i.e., a choice of local Lorentz basis vectors
⃗eα). Exercise 27.6 explores how these ﬁelds change when the basis is changed. The
conclusions are simple. (i) When one rotates the transverse basis vectors ⃗ex and ⃗ey
behavior of gravitational
wave ﬁelds under rotations
and boosts
through an angle ψ, then h+ and h× rotate through 2ψ in the sense that:
(h+ + ih×)new = (h+ + ih×)olde2iψ,
when (⃗ex + i⃗ey)new = (⃗ex + i⃗ey)oldeiψ.
(27.31)
(ii) When one boosts from an old frame to a new one moving at some other speed
but chooses the old and new spatial bases such that (a) the waves propagate in
the z direction in both frames and (b) the plane spanned by ⃗ex and ⃗κ ≡⃗e0 + ⃗ez =
(propagation direction in spacetime) is the same in both frames, then h+ and h× are
the same in the two frames—they are scalars under such a boost! The same is true of
the transverse components of the vector potential A for an electromagnetic wave.
EXERCISES
Exercise 27.6 Derivation: Behavior of h+ and h× under Rotations and Boosts
(a) Derive the behavior [Eq. (27.31)] of h+ and h× under rotations in the trans-
verse plane. [Hint: Write the gravitational-wave ﬁeld, viewed as a geometric ob-
ject, as hhhTT = ℜ
"
(h+ + ih×)(eee+ −ieee×)
#
, where eee+ = (⃗ex ⊗⃗ex −⃗ey ⊗⃗ey) and
27.3 Gravitational Waves Propagating through Flat Spacetime
1317

BOX 27.3.
TENDEX AND VORTEX LINES FOR A
GRAVITATIONAL WAVE
A plane gravitational wave with + polarization, propagating in the z direction,
has as its only nonzero tidal-ﬁeld components Exx = −Eyy = −1
2 ¨h+(t −z)
[Eq. (27.22)]. This tidal ﬁeld’s eigenvectors are ex and ey, so its tendex lines
(Boxes 25.2 and 26.3) are straight lines pointing along these basis vectors (i.e.,
the solid lines in the following picture).
These lines’ tendicities Exx and Eyy are equal and opposite, so one set of
lines stretches (red) and the other squeezes (blue). As the wave propagates,
each line’s tendicity oscillates as seen at ﬁxed z, so its color oscillates between
red and blue.
From the Maxwell-like Bianchi identity ∂B/∂t = −(∇× E)S (Box
25.2)—with E a function of t −n . x, and n = ez the wave’s propagation
direction—we infer that the wave’s frame-drag ﬁeld and tidal ﬁeld are
related by B = (n × E)S. This means that the nonzero components of B are
Bxy = Byx = Exx = −Eyy = −1
2 ¨h+(t −z). Therefore, the gravitational wave’s
vortex lines are the dashed lines in the ﬁgure above (where the propagation
direction, n = ez, is out of the screen or paper, toward you).
Electric and magnetic ﬁeld lines are generally drawn with line densities
proportional to the magnitude of the ﬁeld—a convention motivated by ﬂux
conservation. Not so for tendex and vortex lines, which have no corresponding
conservation law. Instead, their ﬁeld strengths (tendicities and vorticities) are
usually indicated by color coding (see, e.g., Nichols et al., 2011).
Most discussions of gravitational waves (including the text of this chapter)
focus on their tidal ﬁeld E and its physical stretch and squeeze; they ignore
the frame-drag ﬁeld with its differential precession (twisting) of gyroscopes.
The reason is that modern technology is able to detect and monitor the stretch
and squeeze, but the precession is far too small to be detected.
1318
Chapter 27. Gravitational Waves and Experimental Tests of General Relativity

eee× = (⃗ex ⊗⃗ey + ⃗ey ⊗⃗ex) are the polarization tensors associated with + and ×
polarized waves, respectively [Eqs. (27.23b)]. Then show that e+ −ie× rotates
through −2ψ, and use this to infer the desired result.]
(b) Showthat, withtheorientationsofspatialbasisvectorsdescribedafterEq.(27.31),
h+ and h× are unchanged by boosts.
27.3.3
27.3.3 Gravitons and Their Spin and Rest Mass
Most of the abovementioned features of gravitational waves (though not expressed
in this language) were clear to Einstein in 1918. Two decades later, as part of the
effort to understand quantum ﬁelds, Markus Fierz and Wolfgang Pauli (1939), at the
Eidgen¨ossische Technische Hochschule (ETH) in Zurich, Switzerland, formulated a
classical theory of linear ﬁelds of arbitrary spin so designed that the ﬁelds would be
quantizable by canonical methods. Remarkably, their canonical theory for a ﬁeld of
quantization of
gravitational waves:
gravitons with zero rest
mass and spin two
spin two and zero rest mass is identical to general relativity with nonlinear effects
removed, and the plane waves of that spin-two theory are identical to the waves
described above. When quantized by canonical techniques, these waves are carried
by zero-rest-mass, spin-two gravitons.
One can see by simple arguments that the gravitons that carry gravitational waves
must have zero rest mass and spin two. First, fundamental principles of quantum
theory guarantee that any wave that propagates in vacuum with the speed of light
elementary explanations
of the graviton rest mass
and spin
mustbecarriedbyparticlesthathavethatsamespeed(i.e., particleswhose4-momenta
are null, which means particles with zero rest mass). General relativity predicts that
gravitational waves propagate with the speed of light. Therefore, its gravitons must
have zero rest mass.
Second, consider any plane-wave ﬁeld (neutrino, electromagnetic, gravitational,
etc.) that propagates at the speed of light in the z-direction of a (local) Lorentz frame.
At any moment of time examine any physical manifestation of that ﬁeld (e.g., the
acceleration ﬁeld it produces on test particles). Rotate that manifestation of the ﬁeld
around the z-axis, and ask what minimum angle of rotation is required to bring the
ﬁeld back to its original conﬁguration. Call that minimum angle, θret, the waves’ return
angle.The spin S of the particles that carry the wave will necessarily be related to that
return angle by3
S = 360◦
θret
.
(27.32)
This simple formula corresponds to the elegant mathematical statement that “the
waves generate an irreducible representation of order S = 360◦/θret of that subgroup
of the Lorentz group that leaves their propagation vector unchanged (the ‘Little group’
3.
For spin 0 this formula fails. Spin 0 corresponds to circular symmetry around the spin axis.
27.3 Gravitational Waves Propagating through Flat Spacetime
1319

of the propagation vector).” For electromagnetic waves, a physical manifestation is the
electric ﬁeld, which is described by a vector lying in the x-y plane; if one rotates that
vector about the z-axis (propagation axis), it returns to its original orientation after
a return angle θret = 360◦. Correspondingly, the spin of the particle that carries the
electromagnetic waves (the photon) is one. For neutrinos, the return angle is θret =
720◦; and correspondingly, the spin of a neutrino is 1
2. For gravitational waves,
the physical manifestations include the deformation of a sphere of test particles
(Figs. 27.1a,b and 27.2a,b) and the acceleration ﬁelds (Figs. 27.1c,d and 27.2c,d). Both
the deformed, ellipsoidal spheres and the quadrupolar lines of force return to their
original orientations after rotation through θret = 180◦; correspondingly, the gravi-
ton must have spin two. This spin two also shows up in the rotation factor ei2ψ of
Eq. (27.31).
Although Fierz and Pauli (1939) showed us how to quantize linearized general
relativity, the quantization of full, nonlinear general relativity remains a difﬁcult
subject of current research.
27.4
27.4 Gravitational Waves Propagating through Curved Spacetime
Richard Isaacson (1968a,b) has developed a geometric-optics formulation of the
theory of gravitational waves propagating through curved spacetime, and as a by-
product he has given a rigorous mathematical description of the waves’ stress-energy
tensor and thence the energy and momentum carried by the waves. In this section,
we sketch the main ideas and results of Isaacson’s analysis.4
two-lengthscale expansion
for gravitational waves in
curved spacetime
The foundation for the analysis is a two-lengthscale expansion -λ/L like we used in
Sec. 7.3 when formulating geometric optics. For any physical quantity, we identify the
wave contribution as the portion that varies on some short lengthscale -λ = λ/(2π)
(the waves’ reduced wavelength), and the background as the portion that varies on
a far longer lengthscale L (which is less than or of order the background’s spacetime
radius of curvature R); see Fig. 27.3.
steady coordinates
To make this idea work, we must use “steady” coordinates (i.e., coordinates that
are smooth to as great an extent as the waves permit, on lengthscales shorter than
L). In such coordinates, components of the spacetime metric gαβ and of the Riemann
curvature tensor Rαβγ δ split into background (B) plus gravitational waves (GW),
metric and Riemann tensor
split into background and
gravitational-wave parts
gαβ = gB
αβ + hαβ,
Rαβγ δ = RB
αβγ δ + RGW
αβγ δ,
(27.33a)
where the background quantities are deﬁned as the averages (denoted ⟨.⟩) of the full
quantities over lengthscales long compared to -λ and short compared to L:
gB
αβ ≡⟨gαβ⟩,
RB
αβγ δ ≡⟨Rαβγ δ⟩.
(27.33b)
4.
In the 1980s and 1990s, Isaacson, as the Program Director for Gravitational Physics at the U.S. National
Science Foundation (NSF), played a crucial role in the creation of the LIGO Project for detecting
gravitational waves and in moving LIGO toward fruition.
1320
Chapter 27. Gravitational Waves and Experimental Tests of General Relativity

R
curved spacetime
background
waves
L
2πλ–
=
+
FIGURE 27.3 Heuristic embedding diagram for the decomposition of curved spacetime into a
background spacetime plus gravitational waves.
To assist us in solving the Einstein equation, we treat the Einstein tensor Gαβ a
bit differently from the metric and Riemann. We begin by expanding Gαβ as a power
series in the metric perturbation hαβ: Gαβ = GB
αβ + G(1)
αβ + G(2)
αβ + . . . . Here GB
αβ
is the Einstein tensor computed from the background metric gB
αβ, G(1)
αβ is linear in
hαβ, G(2)
αβ is quadratic, and so forth. We then split Gαβ into its rapidly varying part,
which is simply G(1)
αβ to leading order, and its smoothly varying part, which through
quadratic order is ⟨Gαβ⟩= GB
αβ + ⟨G(2)
αβ⟩. The vacuum Einstein equation Gαβ = 0
will be satisﬁed only if the rapidly and smoothly varying parts both vanish.
In Sec. 27.4.1, by setting the fast-varying part G(1)
αβ to zero, we obtain a wave
equation in the background curved spacetime for hαβ (the gravitational waves), which
wecansolve(Sec.27.4.2)usingthegeometric-opticsapproximationthatunderliesthis
analysis. Then, in Sec. 27.4.3, by setting the slowly varying part GB
αβ + ⟨G(2)
αβ⟩to zero,
we obtain Isaacson’s description of gravitational-wave energy and momentum.
27.4.1
27.4.1 Gravitational Wave Equation in Curved Spacetime
The metric perturbation hαβ can be regarded as a tensor ﬁeld that lives in the back-
ground spacetime.5 The rapidly varying part of the Einstein equation, G(1)
αβ = 0, gives
rise to a wave equation for this tensorial metric perturbation (Isaacson, 1968a; Misner,
Thorne, and Wheeler, 1973, Secs. 35.13, 35.14). We can infer this wave equation most
easily from a knowledge of the form it takes in any local Lorentz frame of the back-
ground (with size ≫-λ but ≪L). In such a frame, G(1)
αβ = 0 must reduce to the ﬁeld
equation of linearized theory [the vacuum version of Eq. (25.83)]. And if we introduce
Lorenz gauge [Eq. (27.18c)], then G(1)
αβ = 0 must become, in a local Lorentz frame, the
vacuum wave equation (27.18e). The frame-invariant versions of these local-Lorentz-
frame equations, in the background spacetime, should be obvious. The trace-reversed
metric perturbation (27.18d) in frame-invariant form must become
¯hμν ≡hμν −1
2h gB
μν,
h ≡gαβ
B hαβ.
(27.34a)
The Lorenz-gauge condition (27.18c) must become
Lorenz-gauge condition
¯hμν|
ν = 0,
(27.34b)
5.
Actually, this characterization requires that we restrict the coordinates to be steady.
27.4 Gravitational Waves Propagating through Curved Spacetime
1321

where the | denotes a gradient in the background spacetime (i.e., a covariant derivative
computed using connection coefﬁcients constructed from gB
μν) and the index is raised
with the background metric, ¯hμν|ν = ¯hμν|αgαν
B . And the gravitational wave equation
(Einstein ﬁeld equation) (27.18e) must become
gravitational wave
equation
¯hμν|α
α = 0
(27.34c)
plus curvature coupling terms, such as RB
αμβν ¯hαβ, that result from the noncom-
mutation of the double gradients. The curvature coupling terms have magnitude
curvature coupling is
negligible
h/R2 <∼h/L2 (where R is the radius of curvature of the background spacetime; cf.
Fig. 27.3), while the terms kept in Eq. (27.34c) have the far-larger magnitude h/-λ2, so
the curvature coupling terms can be (and are) neglected.
27.4.2
27.4.2 Geometric-Optics Propagation of Gravitational Waves
When one solves Eqs. (27.34) using the geometric-optics techniques developed in
geometric-optics wave
propagation
Sec. 7.3, one obtains precisely the results that one should expect, knowing the solution
(27.19) for weak, planar gravitational waves in ﬂat spacetime (linearized theory).
1. If we split hμν up into two polarization pieces + and ×, each with its own
rapidly varying phase ϕ and slowly varying amplitude Aμν, then the Lorenz-
gauge, trace-reversed metric perturbation for each piece takes the standard
geometric-optics form [eikonal approximation; Eq. (7.20)]:
eikonal approximation
hμν = ℜ(Aμνeiϕ).
(27.35a)
2. Because the linearized-theory waves propagate in a straight line (z direc-
tion) and travel at the speed of light, the geometric-optics waves propagate
rays are null geodesics
through curved spacetime on rays that are null geodesics. More speciﬁcally,
the wave vector ⃗k = ⃗∇ϕ is tangent to the null-ray geodesics, and ϕ is con-
stant along a ray and hence is a rapidly varying function of the retarded time
τr at which the source (in its own reference frame) emitted the ray:
ϕ = ϕ(τr),
⃗k = ⃗∇ϕ,
⃗k . ⃗k = 0,
∇⃗k ⃗k = 0,
∇⃗kϕ = 0. (27.35b)
3. Because the x- and y-axes that deﬁne the two polarizations in linearized
theory remain ﬁxed as the wave propagates, for each polarization we can
split the amplitude Aμν up into a scalar amplitude A+ or A×, and a polar-
ization tensor eee+ or eee× [like those of Ex. 27.6 and Eqs. (27.23b)], and the
polarization tensors are parallel-transported along the rays:
polarization tensors are
parallel propagated along
rays
Aμν = A eμν,
∇⃗k eee = 0.
(27.35c)
4. Because gravitons are conserved (cf. the conservation of quanta in our gen-
graviton conservation
implies amplitude scales
inversely with square root
of cross section of a bundle
of rays
eral treatment of geometric optics, Sec. 7.3.2), the ﬂux of gravitons (which
is proportional to the square A2 of the scalar amplitude) times the cross sec-
tional area A of a bundle of rays that are carrying the gravitons must be
1322
Chapter 27. Gravitational Waves and Experimental Tests of General Relativity

constant. Therefore, the scalar wave amplitude A must die out as 1/(square
root of cross sectional area A of a bundle of rays):
A ∝1/
√
A.
(27.35d)
Now, just as the volume of a 3-dimensional ﬂuid element, for a perfect
ﬂuid, changes at the rate d ln V/dτ = ⃗∇. ⃗u, where ⃗u is the 4-velocity of
the ﬂuid [Eq. (2.65)], so (it turns out) the cross sectional area of a bundle
of rays increases as ∇⃗k A = ⃗∇. ⃗k. Therefore, the transport law for the wave
amplitude, A ∝1/
√
A, becomes
transport law for
amplitude
∇⃗kA = −1
2( ⃗∇. ⃗k)A.
(27.35e)
Equations (27.35) are derived more rigorously in Isaacson (1968a) and Misner,
Thorne, and Wheeler (1973, Sec. 35.14). They can be used to compute the inﬂuence of
the cosmological curvature of our universe, and the gravitational ﬁelds of intervening
bodies, on the propagation of gravitational waves from their sources to Earth. Once
the waves have reached Earth, we can compute the measured gravitational-wave
ﬁelds h+ and h× by projecting out the spatial, transverse-traceless parts of hμν =
ℜ(Aeμν eiϕ), as discussed in Box 27.2.
The geometric-optics propagation of gravitational waves, as embodied in Eqs.
(27.35), is essentially identical to that of electromagnetic waves. Both waves, gravita-
tionalandelectromagnetic, propagatealongraysthatarenullgeodesics.Bothparallel-
transport their polarizations. Both are carried by quanta that are conserved as they
propagate along bundles of rays and as a result both have scalar amplitudes that vary
as A ∝1/
√
A, where A is the cross sectional area of a ray bundle.
gravitational waves
exhibit same vacuum
propagation phenomena
as electromagnetic waves:
redshifts, ray deﬂection,
gravitational lensing
Therefore, gravitational waves must exhibit exactly the same vacuum propagation
phenomena as electromagnetic waves: Doppler shifts, cosmological redshifts, gravi-
tational redshifts, gravitational deﬂection of rays, and gravitational lensing!
In Ex. 27.14, we illustrate this geometric optics propagation of gravitational waves
by applying it to the waves from a binary system, which travel outward through our
expanding universe.
Exercise 27.7 explores an application where geometric optics breaks down due to
diffraction.
EXERCISES
Exercise 27.7 **Example: Gravitational Lensing of Gravitational Waves by the Sun
Gravitational waves from a distant source travel through the Sun with impunity
(negligible absorption and scattering), and their rays are gravitationally deﬂected. The
Sun is quite centrally condensed, so most of the deﬂection is produced by a central
region with mass Mc ≃0.3M⊙and radius Rc ≃105 km ≃R⊙/7, and the maximum
deﬂection angle is therefore φ ≃4Mc/Rc [Eq. (27.7)]. A few of the deﬂected rays,
alongwhichthewavespropagateaccordingtogeometricoptics, areshowninFig.27.4.
27.4 Gravitational Waves Propagating through Curved Spacetime
1323

f
FIGURE 27.4 Some gravitational-wave rays that pass
through the Sun are brought to an imperfect focus at a
distance f, the focal length.
(a) Show that the rays are brought to an imperfect focus and thence produce caustics
(Sec. 7.5) at a distance from the Sun (the focal length) f ∼R2
c/(4Mc) ∼38 AU. A
calculation with a more accurate solar model gives f ∼20 AU, which is near the
orbit of Uranus.
(b) If the waves were to have arbitrarily small wavelength λ, then at the caustics,
their wave ﬁelds h+ and h× would become divergently large (Sec. 7.5). Finite
wavelengthcausesdiffractionnearthecaustics(Sec.8.6).Explainwhythefocused
ﬁeld thereby is smeared out over a region with transverse size σ ∼[-λ/(2Rc)]f ∼
[-λ/(8Mc)]Rc. [Hint: See Eq. (8.9) and associated discussion.]
(c) Explain why, if σ ≪Rc (i.e., if -λ ≪8Mc ∼3M⊙), substantial focusing occurs,
and the ﬁeld near the caustics is strongly ampliﬁed; but if σ >∼Rc (i.e., -λ >∼3M⊙),
there is only slight or no focusing. Explain why it is unlikely that any discrete,
strong gravitational-wave sources in the universe emit wavelengths shorter than
3M⊙∼5 km and therefore are strongly lensed by the Sun.
27.4.3
27.4.3 Energy and Momentum in Gravitational Waves
Now turn from the rapidly varying piece of the vacuum Einstein equation, G(1)
μν = 0,
to the piece that is averaged over scales long compared to -λ and short compared to L:
GB
αβ + ⟨G(2)
αβ⟩= 0.
(27.36)
(Recall that GB
αβ is the Einstein tensor constructed from the slowly varying back-
ground metric, and G(2)
αβ is the piece of the full Einstein tensor that is quadratic in the
rapidly varying metric perturbation hμν and that therefore does not average to zero.)
Notice that Eq. (27.36) can be brought into the standard form for Einstein’s equa-
tion in the background spacetime,
Einstein equation for
background metric in
vacuum
GB
αβ = 8πT GW
αβ ,
(27.37)
by moving ⟨G(2)
αβ⟩to the right-hand side and then attributing to the waves a stress-
energy tensor deﬁned by
stress-energy tensor for
gravitational waves: formal
expression
T GW
αβ
= −1
8π ⟨G(2)
αβ⟩.
(27.38)
1324
Chapter 27. Gravitational Waves and Experimental Tests of General Relativity

Because this stress-energy tensor involves an average over a few wavelengths, its
energy density, momentum density, energy ﬂux, and momentum ﬂux are not deﬁned
on lengthscales shorter than a wavelength. One cannot say how much energy or
momentum resides in the troughs of the waves and how much in the crests. One
can only say how much total energy there is in a region containing a few or more
wavelengths. However, once reconciled to this amount of nonlocality, one ﬁnds that
T GW
αβ
has all the other properties expected of any good stress-energy tensor. Most
especially, in the absence of coupling of the waves to matter (the situation we are
treating), it obeys the standard conservation law:
conservation law for
gravitational-wave energy
and momentum
T GW αβ
|β = 0,
(27.39)
where, as above, the symbol | denotes the covariant derivative in the background
spacetime (i.e., the derivative using the connection coefﬁcients of gB
αβ). This law is a
direct consequence of the averaged ﬁeld equation (27.37) and the contracted Bianchi
identity for the background spacetime: GB αβ|β = 0.
By grinding out the second-order perturbation of the Einstein tensor and inserting
it into Eq. (27.38), performing several integrations by parts in the average ⟨.⟩, and
expressing the result in terms of h+ and h×, one arrives at the following simple
expression for T GW
αβ
in terms of the wave ﬁelds h+ and h×:
stress-energy tensor in
terms of gravitational-
wave ﬁelds
T GW
αβ
=
1
16π ⟨h+,αh+,β + h×,αh×,β⟩.
(27.40)
[For details of the derivation, see Isaacson (1968b) or Misner, Thorne, and Wheeler
(1973, Secs. 35.13, 35.15).]
Letusexaminethisstress-energytensorinalocalLorentzframeofthebackground
spacetime where the waves are locally plane and are propagating in the z direction—
the kind of frame we used in Sec. 27.3.2 when exploring the properties of gravitational
waves. Because in this frame, h+ = h+(t −z) and h× = h×(t −z), the only nonzero
components of Eq. (27.40) are
T GW 00 = T GW 0z = T GW z0 = T GW zz =
1
16π ⟨˙h2
+ + ˙h2
×⟩.
(27.41)
This has the same form as the stress-energy tensor for a plane electromagnetic wave
propagating in the z direction, and the same form as the stress-energy tensor for any
collection of zero-rest-mass particles moving in the z-direction [cf. Eq. (3.32d)], as
it must, since the gravitational waves are carried by zero-rest-mass gravitons just as
electromagnetic waves are carried by zero-rest-mass photons.
Suppose that the waves have frequency ∼f and that the amplitudes of oscilla-
tion of h+ and h× are ∼hamp. Then by inserting factors of G and c into Eq. (27.41)
(i.e., by switching from geometrized units to conventional units) and by setting
27.4 Gravitational Waves Propagating through Curved Spacetime
1325

4
(∂h+/∂t)25
≃1
2(2πf hamp)2 and similarly for h×, we obtain the following approx-
imate expression for the energy ﬂux in the waves:
magnitude of
gravitational-wave
energy ﬂux
T GW 0z ≃π
4
c3
Gf 2h2
amp ≃0.01W
m2

f
200 Hz
2  hamp
10−21
2
.
(27.42)
The numbers in this equation are those for the ﬁrst gravitational waves ever de-
tected: LIGO’s GW150914 at its peak brightness. Those waves’ observed energy ﬂux,
∼0.01 W m−2,wasseveraltimeshigherthanthatfromthefullmoonasseenonEarth,
but the waves’ source, two ∼30M⊙colliding black holes, is ∼1.2 billion light years
away compared to the Moon’s distance of 1 light second. Of course, the moon shines
steadily, while the holes’ collision and this enormous ﬂux lasted for only ∼20 ms.
For a short gravitational wave burst such as GW150914 (only a few wave cycles,
which we shall approximate as just one), the enormous energy ﬂux (27.42) corre-
spondstoahugemeanoccupationnumberforthequantumstatesofthegravitational-
wave ﬁeld (i.e., a huge value for the number of spin-two, zero-rest-mass gravitons in
each quantum state). To compute that occupation number, we evaluate the volume in
phase space occupied by the waves and then divide by the volume occupied by each
quantum state (cf. Sec. 3.2.5). At a time when the waves have reached a distance r from
the source, they occupy a spherical shell of area 4πr2 and thickness ∼c/f = 2π -λ,
where -λ = 1/(2πf ) is their reduced wavelength, so their volume in physical space
is Vx ∼8π2r2-λ. As seen by observers whom the waves are passing, they come from
a solid angle  ∼(2-λ/r)2 centered on the source, and they have a spread of an-
gular frequencies ω ∼ω = c/-λ. Since each graviton carries an energy ℏω = ℏc/-λ
and a momentum ℏω/c = ℏ/-λ, the volume that they occupy in momentum space is
Vp ∼(ℏ/-λ)3, or Vp ∼4ℏ3/(λr2). The gravitons’ volume in phase space, then, is
VxVp ∼32π2ℏ3 ∼(2πℏ)3.
(27.43)
Since each quantum state for a zero rest-mass particle occupies a volume (2πℏ)3 in
phase space [Eq. (3.17) with gs = 1], the total number of quantum states occupied by
the gravitons is of order unity! Correspondingly, for a total energy radiated like that of
GW150914, ∼M⊙c2 ∼1047J with each graviton carrying an energy ℏc/-λ ∼10−31J,
the mean occupation number of each occupied state is of order the total number of
gravitons emitted:
mean occupation number
for quantum states of
gravitational waves from a
strong gravitational wave
burst
η ∼M⊙c2
ℏω
∼1078.
(27.44a)
This is the mean occupation number from the viewpoint of the emitter.
A detector on Earth has available to it only those gravitons that pass through
a region with transverse size of order their wavelength λ—which means a fraction
(2π -λ)2/(4πr2) of the emitted waves’ volume. We can think of the detector as collaps-
ing the gravitons’ wave function into that volume. The number of available quantum
1326
Chapter 27. Gravitational Waves and Experimental Tests of General Relativity

states is still of order unity (demonstrate this!), but the number of gravitons occupying
them is reduced by this factor, so from the detector’s viewpoint, the mean occupation
number is
ηcollapsed ∼M⊙c2
ℏω
(2π -λ)2
4πr2 ∼T GW0z
ℏωc (2π -λ)3 ∼1039.
(27.44b)
Notice that this is the number of gravitons in a cubic wavelength at the wave burst.
mean occupation number
from viewpoint of a
detector on Earth
Whichever viewpoint one takes, the occupation number is enormous. It guaran-
tees that the waves behave exceedingly classically; quantum-mechanical corrections
to the classical theory have fractional magnitude 1/√η ∼10−39, or ∼10−20.
27.5
27.5 The Generation of Gravitational Waves
When analyzing the generation of gravitational waves, it is useful to divide space
around the source (in the source’s rest frame) into the regions shown in Fig. 27.5.
If the source has size L <∼M, where M is its mass, then spacetime is strongly
curved inside and near it, and we refer to it as a strong-gravity source. The region
with radii (measured from its center of mass) r <∼10M is called the source’s strong-
regions of space around a
gravitational-wave source:
Fig. 27.5
ﬁeld region. Examples of strong-gravity sources are vibrating or spinning neutron
stars, and merging binary black holes. The region with radii 10M <∼r <∼-λ = (the
reduced wavelength of the emitted waves) is called the source’s weak-ﬁeld near zone.
In this region, the source’s gravity is fairly well approximated by Newtonian theory
and a Newtonian gravitational potential . As in electromagnetic theory, the region
-λ <∼r <∼λ is called the induction zone or the intermediate zone.The wave zone begins
at r ∼λ = 2π -λ.
It is useful to divide the wave zone into two parts: a part near the source (r <∼ro
for some ro) called the local wave zone, in which the spacetime curvatures of external
bodies and of the universe as a whole are unimportant, and the distant wave zone
(r >∼ro), in which the emitted waves are signiﬁcantly affected by external bodies
and the external universe (i.e., by background spacetime curvature). The theory of
theory of wave generation
predicts waves in source’s
local wave zone; geometric
optics carries them onward
through distant wave zone
local asymptotic rest frame
local
wave zone
induction
zone
weak-field
near zone
10M
L
strong-field
region
λ
λ–
distant
wave zone
ro
FIGURE 27.5 Regions of space around a source of gravitational waves.
27.5 The Generation of Gravitational Waves
1327

gravitational-wave generation deals with computing, from the source’s dynamics, the
gravitational waves in the local wave zone. Propagation of the waves to Earth is dealt
with by using geometric optics (or other techniques) to carry the waves from the local
wave zone outward, through the distant wave zone, to Earth.
source’s local asymptotic
rest frame
The entire region in which gravity is weak and the spacetime curvatures of ex-
ternal bodies and the universe are unimportant (10M <∼r <∼ro)—when viewed in
nearly Lorentz coordinates in which the source is at rest—is called the source’s local
asymptotic rest frame.
27.5.1
27.5.1 Multipole-Moment Expansion
The electromagnetic waves emitted by a dynamical charge distribution are usually
expressed as a sum over the source’s multipole moments. There are two families of
moments: the electric moments (moments of the electric-charge distribution) and
the magnetic moments (moments of the electric-current distribution).
source’s mass moments
and current moments
Similarly, the gravitational waves emitted by a dynamical distribution of mass-
energy and momentum can be expressed, in the local wave zone, as a sum over
multipole moments. Again there are two families of moments: the mass moments
(moments of the mass-energy distribution) and the current moments (moments of the
mass-current distribution, i.e., the momentum distribution). The multipolar expan-
sion of gravitational waves is developed in great detail in Blanchet (2014) and Thorne
(1980). In this section, we sketch and explain its qualitative and order-of-magnitude
features.
In the source’s weak-gravity near zone (if it has one), the mass moments show up
in the time-time part of the metric in a form familiar from Newtonian theory:
multipolar expansion of
metric outside a source
g00 = −(1 + 2) = −1 & I0
r & I1
r2 & I2
r3 & . . .
(27.45)
[cf. Eq. (25.79)]. Here r is radius, Iℓis the mass moment of order ℓ, and “&” means
“plus a term with the form” (i.e., a term whose magnitude and parameter dependence
are shown but whose multiplicative numerical coefﬁcients do not interest us, at least
not for the moment). The mass monopole moment I0 is the source’s mass, and the
mass dipole moment I1 can be made to vanish by placing the origin of coordinates at
the center of mass [Eq. (25.96) and Ex. 25.21].
In the source’s weak-gravity near zone, its current moments Sℓsimilarly show up
in the space-time part of the metric:
g0j = S1
r2 & S2
r3 & . . . .
(27.46)
Just as there is no magnetic monopole moment in classical electromagnetic theory,
so there is no current monopole moment in general relativity. The current dipole
moment S1 is the source’s angular momentum Jk, so the leading-order term in the
expansion (27.46) has the form (25.98c), which we have used to deduce the angular
momenta of gravitating bodies.
1328
Chapter 27. Gravitational Waves and Experimental Tests of General Relativity

If the source has mass M, size L, and internal velocities ∼v, then the magnitudes
of its moments are
magnitudes of moments
Iℓ∼MLℓ,
Sℓ∼MvLℓ.
(27.47)
Theseformulasguaranteethatthenear-zoneﬁelds g00 and g0j, asgivenbyEqs.(27.45)
and (27.46), are dimensionless.
As the source’s moments oscillate dynamically, they produce gravitational waves.
Mass-energy conservation [Eq. (25.102)] prevents the mass monopole moment I0 =
M fromoscillating; angular-momentumconservation[Eq.(25.103)]preventsthecur-
rentdipolemomentS1 = (angularmomentum)fromoscillating; andbecausethetime
derivative of the mass dipole moment I1 is the source’s linear momentum, momen-
tum conservation [Eq. (25.106)] prevents the mass dipole moment from oscillating.
Therefore, the lowest-order moments that can oscillate and thereby contribute to the
lowest-order moments
that produce gravitational
waves are quadrupolar
waves are the quadrupolar ones. The wave ﬁelds h+ and h× in the source’s local wave
zone must (i) be dimensionless, (ii) die out as 1/r, and (iii) be expressed as a sum over
derivatives of the multipole moments. These considerations guarantee that the waves
will have the following form:
multipolar expansion of
gravitational waves
h+ ∼h× ∼∂2I2/∂t2
r
& ∂3I3/∂t3
r
& . . . & ∂2S2/∂t2
r
& ∂3S3/∂t3
r
& . . .
(27.48)
(Ex. 27.8).
The timescale on which the moments oscillate is T ∼L/v, so each time derivative
produces a factor v/L. Correspondingly, the ℓ-pole contributions to the waves have
magnitudes
∂ℓIℓ/∂tℓ
r
∼M
r vℓ,
∂ℓSℓ/∂tℓ
r
∼M
r v(ℓ+1).
(27.49)
This means that, for a slow-motion source (one with internal velocities v small com-
for slow-motion source:
relative magnitudes of
gravitational waves’
multipolar components
pared to light, so the reduced wavelength -λ ∼L/v is large compared to the source
size L), the mass quadrupole moment I2 will produce the strongest waves. The mass
octupole (3-pole) waves and current quadrupole waves will be weaker by ∼v ∼L/-λ;
the mass 4-pole and current octupole waves will be weaker by ∼v2 ∼L2/-λ2, and so
forth. This is analogous to the electromagnetic case, where the electric dipole waves
are the strongest, the electric quadrupole and magnetic dipole are smaller by ∼L/-λ,
and so on.
In the next section, we develop the theory of mass quadrupole gravitational waves.
For the corresponding theory of higher-order multipoles, see, for example, Thorne
(1980, Secs. IV and VIII) and Blanchet (2014). In Sec. 27.5.3, we will see that a source’s
mass quadruopole waves cannot, by themselves, carry net linear momentum. Net
wave momentum and the corresponding recoil of the source require a beating of mass
quadrupole waves against current quadrupole or mass octupole waves.
27.5 The Generation of Gravitational Waves
1329

EXERCISES
Exercise 27.8 Derivation: Multipolar Expansion of Gravitational Waves
Show that conditions (i), (ii), and (iii) preceding Eq. (27.48) guarantee that the multi-
polar expansion of the gravitational-wave ﬁelds will have the form (27.48).
27.5.2
27.5.2 Quadrupole-Moment Formalism
Consider a weakly gravitating, nearly Newtonian system (which is guaranteed to be
a slow-motion gravitational-wave source, since Newtonian theory requires internal
velocities v ≪1). An example is a binary star system. Write the system’s Newtonian
potential (in its near zone) in the usual way:
(x) = −

ρ(x′)
|x −x′|dVx′.
(27.50)
By using Cartesian coordinates, placing the origin of coordinates at the center of mass
so

ρxjdVx = 0, and expanding:
1
|x −x′| = 1
r + xjxj′
r3
+
xjxk(3xj′xk′ −r′2δjk)
2r5
+ . . . ,
(27.51)
we obtain the multipolar expansion of the Newtonian potential:
for nearly Newtonian
source: multipolar
expansion of Newtonian
potential
(x) = −M
r −
3Ijkxjxk
2r5
+ . . . .
(27.52)
Here
M =

ρdVx,
Ijk =

ρ

xjxk −1
3r2δjk

dVx
(27.53)
are the system’s mass and mass quadrupole moment. Note that the mass quadrupole
moment is equal to the second moment of the mass distribution with its trace
removed.
As we have discussed, dynamical oscillations of the quadrupole moment generate
the source’s strongest gravitational waves. Those waves must be describable, in the
source’s near zone and local wave zone, by an outgoing-wave solution to the Lorenz-
gauge, linearized Einstein equation,
¯hμν,
ν = 0,
¯hμν,α
α = 0
(27.54)
[Eqs. (25.89) and (25.90)], that has the near-zone Newtonian limit:
1
2(¯h00 + ¯hxx + ¯hyy + ¯hzz) = h00 = −(quadrupole part of 2) =
3Ijkxjxk
r5
(27.55)
[cf. Eq. (25.79)].
1330
Chapter 27. Gravitational Waves and Experimental Tests of General Relativity

The desired solution can be written in the form
Newtonian potential
transitions into this
linearized-theory
gravitational ﬁeld in
transition and local wave
zones
¯h00 = 2
Ijk(t −r)
r

,jk
,
¯h0j = 2
' ˙Ijk(t −r)
r
(
,k
,
¯hjk = 2
¨Ijk(t −r)
r
,
(27.56)
where the coordinates are Cartesian, r ≡

δjkxjxk, and the dots denote time deriva-
tives. To verify that this is the desired solution: (i) Compute its divergence ¯hαβ, β and
obtain zero almost trivially. (ii) Notice that each Lorentz-frame component of ¯hαβ
has the form f (t −r)/r aside from some derivatives that commute with the wave
operator, which implies that it satisﬁes the wave equation. (iii) Notice that in the near
zone, the slow-motion assumption inherent in the Newtonian limit makes the time
derivatives negligible, so ¯hjk ≃0 and ¯h00 is twice the right-hand side of Eq. (27.55),
as desired.
Because the trace-reversed metric perturbation (27.56) in the local wave zone has
the speed-of-light-propagation form, aside from its very slow decay as 1/r, we can
compute the gravitational-wave ﬁeld hTT
jk from it by transverse-traceless projection
[Eq. (3) of Box 27.2 with n = er]:
resulting quadrupolar
gravitational-wave ﬁeld
hTT
jk = 2
' ¨Ijk(t −r)
r
(TT
.
(27.57)
This is called the quadrupole-moment formula for gravitational-wave generation. Our
derivation shows that it is valid for any nearly Newtonian source.
Looking back more carefully at the derivation, one can see that, in fact, it relies
only on the linearized Einstein equation and the Newtonian potential in the source’s
local asymptotic rest frame. Therefore, this quadrupole formula is also valid for slow-
motion sources that have strong internal gravity (e.g., slowly spinning neutron stars),
validity for strong-gravity
slow-motion sources
so long as we read the quadrupole moment Ijk(t −r) off the source’s weak-ﬁeld, near-
zone Newtonian potential (27.52) and don’t try to compute it via the Newtonian volume
integral (27.53).
When the source is nearly Newtonian, so the volume integral (27.53) can be used
to compute the quadrupole moment, the computation of the waves is simpliﬁed by
computing instead the second moment of the mass distribution:
Ijk =

ρxjxkdVx,
(27.58)
which differs from the quadrupole moment solely in its trace. Then, because the
TT projection is insensitive to the trace, the gravitational-wave ﬁeld (27.57) can be
computed as
for Newtonian source:
gravitational-wave ﬁeld in
terms of second moment
of mass distribution
hTT
jk = 2
' ¨Ijk(t −r)
r
(TT
.
(27.59)
27.5 The Generation of Gravitational Waves
1331

27.5.3
27.5.3 Quadrupolar Wave Strength, Energy, Angular Momentum,
and Radiation Reaction
To get an order-of-magnitude feel for the strength of the gravitational waves, notice
that the second time derivative of the quadrupole moment, in order of magnitude, is
the nonspherical part of the source’s internal kinetic energy, Ens
kin:
magnitude of slow-motion
source’s quadrupolar
gravitational-wave ﬁeld
h+ ∼h× ∼Ens
kin
r
= GEns
kin
c4r ,
(27.60)
where the second expression is written in conventional units. Although this estimate
is based on the slow-motion assumption of source size small compared to reduced
wavelength, L ≪-λ, it remains valid in order of magnitude when extrapolated into
the realm of the strongest of all realistic astrophysical sources, which have L ∼-λ. In
Ex. 27.17 we use Eq. (27.60) to estimate the strongest gravitational waves that might
be seen by ground-based gravitational-wave detectors.
Because the gravitational stress-energy tensor T GW
μν
produces background curva-
ture via the Einstein equation GB
μν = 8πT GW
μν , just like nongravitational stress-energy
tensors, it must contribute to the rate of change of the source’s mass M, linear momen-
tum Pj, and angular momentum Ji [Eqs. (25.102)–(25.106)] just like other stress-
energies. When one inserts the quadrupolar T GW
μν
into Eqs. (25.102)–(25.106) and
integrates over a sphere in the wave zone of the source’s local asymptotic rest frame,
one ﬁnds that (Ex. 27.11):
source’s rate of change
of mass, momentum, and
angular momentum due
to mass quadrupolar
gravitational-wave
emission
dM
dt = −1
5
<
∂3Ijk
∂t3
∂3Ijk
∂t3
>
,
(27.61)
dJi
dt = −2
5ϵijk
<
∂2Ijm
∂t2
∂3Ikm
∂t3
>
,
(27.62)
and dPj/dt = 0. It turns out (cf. Thorne, 1980, Sec. IV) that the dominant linear-
momentum change (i.e., the dominant radiation-reaction “kick”) arises from a beat-
ing of the mass quadrupole moment against the mass octupole moment, and mass
quadrupole against current quadrupole:
dPi
dt = −2
63
<
∂3Ijk
∂t3
∂4Ijki
∂t4
>
−16
45ϵijk
<
∂3Ijl
∂t3
∂3Skl
∂t3
>
.
(27.63)
Here the mass octupole moment Ijki is the trace-free part of the third moment of the
mass distribution, and the current quadrupole moment Skp is the symmetric, trace-
free part of the ﬁrst moment of the vectorial angular momentum distribution. (See,
e.g., Thorne, 1980, Secs. IV.C, V.C; Thorne, 1983, Sec. 3.)
1332
Chapter 27. Gravitational Waves and Experimental Tests of General Relativity

The back reaction of the emitted waves on their source shows up not only in
changes of the source’s mass, momentum, and angular momentum, but also in ac-
companying changes of the source’s internal structure. These structure changes can
be deduced fully, in many cases, from dM/dt, dJj/dt, and dPj/dt. A nearly Newto-
nianbinarysystemisanexample(Sec.27.5.4).However, inothercases(e.g., acompact
body orbiting near the horizon of a massive black hole), the only way to compute the
structure changes is via a gravitational-radiation-reaction force that acts back on the
system.
The simplest example of such a force is one derived by William Burke (1971)
for quadrupole waves emitted by a nearly Newtonian system. Burke’s quadrupolar
radiation-reaction force can be incorporated into Newtonian gravitation theory by
simply augmenting the system’s near-zone Newtonian potential with a radiation-
reaction term, computed from the ﬁfth time derivative of the system’s quadrupole
moment:
gravitational radiation-
reaction potential
react = 1
5
∂5Ijk
∂t5 xjxk.
(27.64)
This potential satisﬁes the vacuum Newtonian ﬁeld equation ∇2 ≡δjk,jk = 0,
because Ijk is traceless.
This augmentation of the Newtonian potential arises as a result of general rela-
tivity’s outgoing-wave condition. If one were to switch to an ingoing-wave condition,
react would change sign, and if the system’s oscillating quadrupole moment were
joined onto standing gravitational waves, react would go away. In Ex. 27.12, it is
radiation-reaction force
density in source
shown that the radiation-reaction force density −ρ∇react saps energy from the sys-
tem at the same rate as the gravitational waves carry it away.
Burke’s gravitational radiation-reaction potential react and force density
−ρ∇react are close analogs of the radiation-reaction potential [last term in Eq.
(16.79)] and acceleration [right-hand side of Eq. (16.82)] that act on an oscillating ball
that emits sound waves into a surrounding ﬂuid. Moreover, Burke’s derivation of his
gravitational radiation-reaction potential is conceptually the same as the derivation,
in Sec. 16.5.3, of the sound-wave reaction potential.
EXERCISES
Exercise 27.9 Problem: Gravitational Waves from Arm Waving
Wave your arms rapidly, and thereby try to generate gravitational waves.
(a) Using classical general relativity, compute in order of magnitude the wavelength
of the waves you generate and their dimensionless amplitude at a distance of one
wavelength away from you.
(b) Howmanygravitonsdoyouproducepersecond?Discusstheimplicationsofyour
result.
27.5 The Generation of Gravitational Waves
1333

Exercise 27.10 Example: Quadrupolar Wave Generation in Linearized Theory
Derive the quadrupolar wave-generation formula (27.59) for a slow-motion, weak-
gravity source in linearized theory using Lorenz gauge and beginning with the
retarded-integral formula:
¯hμν(t, x) =
 4Tμν(t −|x −x′|, x′)
|x −x′|
dVx′
(27.65)
[Eq. (25.91)]. Your derivation might proceed as follows.
(a) Show that for a slow-motion source, the retarded integral gives for the 1/r ≡1/|x|
(radiative) part of ¯hjk:
¯hjk(t, x) = 4
r

Tjk(t −r, x′)dVx′.
(27.66)
(b) Show that in linearized theory using Lorenz gauge, the vacuum Einstein equation
−¯hμν,αα = 16πTμν [Eq. (25.90)] and the Lorenz gauge condition ¯hμν, ν = 0 [Eq.
(25.89)]togetherimplythatthestress-energytensorthatgeneratesthewavesmust
have vanishing coordinate divergence: T μν,ν = 0. This means that linearized
theory is ignorant of the inﬂuence of self-gravity on the gravitating T μν!
(c) Show that this vanishing divergence implies [T 00xjxk],00 = [T lmxjxk],ml
−2[T ljxk + T lkxj],l + 2T jk.
(d) By combining the results of parts (a) and (c), deduce that
¯hjk(t, x) = 2
r
d2Ijk(t −r)
dt2
,
(27.67)
where Ijk is the second moment of the source’s (Newtonian) mass-energy distri-
bution T 00 = ρ [Eq. (27.58)].
(e) Noticing
that
the
trace-reversed
metric
perturbation
(27.67)
has
the
“speed-of-light-propagation” form, deduce that the gravitational-wave ﬁeld hTT
jk
can be computed from Eq. (27.67) by a transverse-traceless projection [Box 27.2].
Part (b) shows that this linearized-theory analysis is incapable of deducing the gravi-
tational waves emitted by a source whose dynamics is controlled by its self-gravity
(e.g., a nearly Newtonian binary star system). By contrast, the derivation of the
quadrupole formula given in Sec. 27.5.2 is valid for any slow-motion source, re-
gardless of the strength and roles of its internal gravity; see the discussion following
Eq. (27.57).
Exercise 27.11 Problem: Energy and Angular Momentum Carried
by Gravitational Waves
(a) Compute the net rate at which the quadrupolar waves (27.57) carry energy away
from their source, by carrying out the surface integral (25.102) with T 0j being
Isaacson’s gravitational-wave energy ﬂux (27.40). Your answer should be Eq.
(27.61). [Hint: Perform the TT projection in Cartesian coordinates using the
1334
Chapter 27. Gravitational Waves and Experimental Tests of General Relativity

projection tensor, Eq. (2) of Box 27.2, and make use of the following integrals
over the solid angle on the unit sphere:
1
4π

nid = 0,
1
4π

ninjd = 1
3δij,
1
4π

ninjnkd = 0,
1
4π

ninjnknld = 1
15(δijδkl + δikδjl + δilδjk).
(27.68)
These integrals should be obvious by symmetry, aside from the numerical factors
out in front. Those factors are most easily deduced by computing the z compo-
nents (i.e., by setting i = j = k = l = z and using nz = cos θ).]
(b) The computation of the waves’ angular momentum can be carried out in the same
way, but is somewhat delicate, because a tiny nonradial component of the energy
ﬂux, that dies out as 1/r3, gives rise to the O(1/r2) angular momentum ﬂux (see
Thorne, 1980, Sec. IV.D).
Exercise 27.12 Problem: Energy Removed by Gravitational Radiation Reaction
Burke’s radiation-reaction potential (27.64) produces a force per unit volume
−ρ∇react on its nearly Newtonian source. If we multiply this force per unit vol-
ume by the velocity v = dx/dt of the source’s material, we obtain thereby a rate of
change of energy per unit volume. Correspondingly, the net rate of change of the
system’s mass-energy must be
dM
dt = −

ρv . ∇reactdVx.
(27.69)
Show that, when averaged over a few gravitational-wave periods, this formula agrees
with the rate of change of mass (27.61) that we derived in Ex. 27.11 by integrating the
outgoing waves’ energy ﬂux.
27.5.4
27.5.4 Gravitational Waves from a Binary Star System
A very important application of the quadrupole formalism is to wave emission by a
nearly Newtonian binary star system. Denote the stars by indices A and B and their
masses by MA and MB, so their total and reduced mass are (as usual)
M = MA + MB,
μ = MAMB
M
;
(27.70a)
and for simplicity, let the binary’s orbit be circular, with separation a between the
stars’ centers of mass. Then Newtonian force balance dictates that the orbital angular
dynamics of a Newtonian
binary in a circular orbit
velocity  is given by Kepler’s law:
 =

M/a3,
(27.70b)
27.5 The Generation of Gravitational Waves
1335

and the orbits of the two stars are
xA = MB
M a cos t,
yA = MB
M a sin t,
xB = −MA
M a cos t,
yB = −MA
M a sin  t.
(27.70c)
The second moment of the mass distribution [Eq. (27.58)] is Ijk = MAxj
Axk
A +
MBxj
Bxk
B. Inserting the stars’ time-dependent positions (27.70c), we obtain as the
only nonzero components:
Ixx = μa2 cos2 t,
Iyy = μa2 sin2 t,
Ixy = Iyx = μa2 cos  t sin  t. (27.70d)
Noting that cos2 t = 1
2(1 + cos 2t), sin2 t = 1
2(1 −cos 2t), and cos t sin t
= 1
2 sin 2t and evaluating the double time derivative, we obtain:
¨Ixx = −2μ(M)2/3 cos 2t,
¨Iyy = 2μ(M)2/3 cos 2t,
¨Ixy = ¨Iyx = −2μ(M)2/3 sin 2 t.
(27.70e)
We express these components in terms of  rather than a, because  is a direct
gravitational-wave observable: the waves’ angular frequency is 2.
Tocomputethegravitational-waveﬁeld(27.59), wemustprojectoutthetransverse
traceless part of this ¨Ijk. The projection is most easily performed in an orthonormal
spherical basis, since there the transverse part is just the projection onto the plane
spanned by ⃗e ˆθ and ⃗e ˆφ, and the transverse-traceless part has components
( ¨I ˆθ ˆθ)TT = −( ¨I ˆφ ˆφ)TT = 1
2( ¨I ˆθ ˆθ −¨I ˆφ ˆφ),
( ¨I ˆθ ˆφ)TT = ¨I ˆθ ˆφ
(27.70f)
[cf. Eq. (1) of Box 27.2]. Now, a little thought will save us much work: We need
only compute these quantities at φ = 0 (i.e., in the x-z plane), since their circular
motion guarantees that their dependence on t and φ must be solely through the
quantity t −φ. At φ = 0, ⃗e ˆθ = ⃗ex cos θ −⃗ez sin θ and ⃗e ˆφ = ⃗ey, so the only nonzero
components of the transformation matrices from the Cartesian basis to the transverse
part of the spherical basis are Lx ˆθ = cos θ, Lz ˆθ = −sin θ, and Ly ˆφ = 1. Using this
transformation matrix at φ = 0, we obtain: ¨I ˆθ ˆθ = ¨Ixx cos2 θ, ¨I ˆφ ˆφ = ¨Iyy, and ¨I ˆθ ˆφ =
¨Ixy cos θ. Inserting these and expressions (27.70e) into Eq. (27.70f), and setting t →
t −φ to make the formulas valid away from φ = 0, we obtain:
( ¨I ˆθ ˆθ)TT = −( ¨I ˆφ ˆφ)TT = −(1 + cos2 θ) μ(M)2/3 cos[2(t −φ)],
( ¨I ˆθ ˆφ)TT = +( ¨I ˆφ ˆθ)TT = −2 cos θ μ(M)2/3 sin[2(t −φ)].
(27.70g)
Thegravitational-waveﬁeld(27.59)is2/r timesthisquantityevaluatedattheretarded
time t −r.
1336
Chapter 27. Gravitational Waves and Experimental Tests of General Relativity

We make the conventional choice for the polarization tensors:
eee+ = (⃗e ˆθ ⊗⃗e ˆθ −⃗e ˆφ ⊗⃗e ˆφ),
eee× = (⃗e ˆθ ⊗⃗e ˆφ + ⃗e ˆφ ⊗⃗e ˆθ);
⃗e ˆθ = 1
r
∂
∂θ ,
⃗e ˆφ =
1
r sin θ
∂
∂φ .
(27.71a)
Then Eqs. (27.59) and (27.70g) tell us that the gravitational-wave ﬁeld is, in slot-
gravitational waves from
Newtonian binary
naming index notation:
hTT
μν = h+e+
μν + h×e×
μν,
(27.71b)
where
h+ = hTT
ˆθ ˆθ = 2
r [ ¨I ˆθ ˆθ(t −r)]TT = −2(1 + cos2 θ) μ(M)2/3
r
cos[2(t −r −φ)],
(27.71c)
h× = hTT
ˆθ ˆφ = 2
r [ ¨I ˆθ ˆφ(t −r)]TT = −4 cos θ μ(M)2/3
r
sin[2(t −r −φ)].
(27.71d)
We have expressed the amplitudes of these waves in terms of the dimensionless
quantity (M)2/3 = M/a = v2, where v is the relative velocity of the two stars.
Notice that, as viewed from the polar axis θ = 0, h+ and h× are identical except
for a π/2 phase delay, which means that the net stretch-squeeze ellipse (the combi-
nation of those in Figs. 27.1 and 27.2) rotates with angular velocity . This is the
gravitational-wave variant of circular polarization, and it arises because the binary
motion as viewed from the polar axis looks circular. By contrast, as viewed by an ob-
server in the equatorial plane θ = π/2, h× vanishes, so the net stretch-squeeze ellipse
just oscillates along the + axes, and the waves have linear polarization. This is natural,
since the orbital motion as viewed by an equatorial observer is just a linear, horizontal,
back-and-forth oscillation. Notice also that the gravitational-wave frequency is twice
binary’s gravitational-
wave frequency is twice its
orbital frequency
the orbital frequency:
f = 2 
2π = 
π .
(27.72)
To compute, via Eqs. (27.61) and (27.62), the rate at which energy and angular
momentum are lost from the binary, we need to know the double and triple time
derivatives of its quadrupole moment Ijk. The double time derivative is just ¨Ijk with
its trace removed, but Eq. (27.70e) shows that ¨Ijk is already traceless so ¨Ijk = ¨Ijk.
Inserting Eq. (27.70e) for this quantity into Eqs. (27.61) and (27.62) and performing
27.5 The Generation of Gravitational Waves
1337

the average over a gravitational-wave period, we ﬁnd that
dM
dt = −32
5
μ2
M2(M)10/3,
dJz
dt = −1

dM
dt ,
dJx
dt =
dJy
dt = 0.
(27.73)
binary’s orbital inspiral
due to gravitational-wave
emission
This loss of energy and angular momentum causes the binary to spiral inward,
decreasing the stars’ separation a and increasing their orbital angular velocity .
By comparing Eqs. (27.73) with the standard equations for the binary’s orbital en-
ergy and angular momentum [M −(sum of rest masses of stars) = E = −1
2μM/a =
−1
2μ(M)2/3, and Jz = μa2 = μ(M)2/3/], we obtain an equation for d/dt,
which we can integrate to give
 = πf =
 5
256
1
μM2/3
1
to −t
3/8
.
(27.74)
Here to (an integration constant) is the time remaining until the two stars merge,
if the stars are thought of as point masses so their surfaces do not collide sooner.
This equation can be inverted to read off the time until merger as a function of
gravitational-wave frequency.
These results for a binary’s waves and radiation-reaction-induced inspiral are of
great importance for gravitational-wave detection (see, e.g., Cutler and Thorne, 2002;
Sathyaprakash and Schutz, 2009).
EXERCISES
Exercise 27.13 Problem: Gravitational Waves Emitted by a Linear Oscillator
Consider a mass m attached to a spring, so it oscillates along the z-axis of a Cartesian
coordinate system, moving along the world line z = a cos t, y = x = 0. Use the
quadrupole-momentformalismtocomputethegravitationalwavesh+(t, r, θ, φ)and
h×(t, r, θ, φ) emitted by this oscillator, with the polarization tensors chosen as in
Eqs. (27.71a). Pattern your analysis after the computation of waves from a binary in
Sec. 27.5.4.
Exercise 27.14 **Example: Propagation of a Binary’s Waves Through
an Expanding Universe
As we shall see in Sec. 28.3, the following line element is a possible model for the
large-scale structure of our universe:
ds2 = b2[−dη2 + dχ2 + χ2(dθ2 + sin2 θdφ2)],
where b = boη2,
(27.75)
and bo is a constant with dimensions of length. This is an expanding universe with
ﬂat spatial slices η = constant. Notice that the proper time measured by observers at
rest in the spatial coordinate system is t = bo

η2dη = (bo/3)η3.
1338
Chapter 27. Gravitational Waves and Experimental Tests of General Relativity

A nearly Newtonian, circular binary is at rest at χ = 0 in an epoch when η ≃ηo.
The coordinates of the binary’s local asymptotic rest frame are {t, r, θ, φ}, where
r = bχ and the coordinates cover only a tiny region of the universe: χ <∼χo ≪ηo. The
gravitational waves in this local asymptotic rest frame are described by Eqs. (27.71).
Usegeometricoptics(Sec.27.4.2)topropagatethesewavesoutthroughtheexpanding
universe. In particular, do the following.
(a) Show that the null rays along which the waves propagate are the curves of constant
θ, φ, and η −χ.
(b) Each ray can be characterized by the retarded time τr at which the source emitted
it. Show that
τr = 1
3bo(η −χ)3.
(27.76a)
(c) Show that in the source’s local asymptotic rest frame, this retarded time is τr = t −
r, and the phase of the wave is ϕ = 2( τr + φ) [cf. Eqs. (27.71c) and (27.71d)].
Because the frequency  varies with time due to the binary inspiral, a more
accurate formula for the wave’s phase is ϕ = 2(

 dτr + φ). Using Eq. (27.74),
show that
ϕ = 2φ −
to −τr
5M
5/8
,
 = dϕ
dτr
=
 5
256
1
M5/3
1
to −τr
3/8
, (27.76b)
where
M ≡μ3/5M2/5
(27.76c)
(with μ the reduced mass and M the total mass) is called the binary’s chirp mass,
because, as Eqs. (27.76b) show, it controls the rate at which the binary’s orbital
angular frequency  and the gravitational-wave angular frequency 2 “chirp
upward” as time passes. The quantity τr as given by Eq. (27.76a) is constant along
rayswhentheytraveloutofthelocalwavezoneandintoandthroughtheuniverse.
Correspondingly, if we continue to write ϕ in terms of τr on those rays using
Eqs. (27.76b), this ϕ will be conserved along the rays in the external universe and
therefore will satisfy the geometric-optics equation: ∇⃗k ϕ = 0 [Eqs. (27.35b)].
(d) Show that the orthonormal basis vectors and polarization tensors
⃗e ˆθ = 1
bχ
∂
∂θ ,
⃗e ˆφ =
1
bχ sin θ
∂
∂φ ,
eee+ = (⃗e ˆθ ⊗⃗e ˆθ −⃗e ˆφ ⊗⃗e ˆφ),
eee× = (⃗e ˆθ ⊗⃗e ˆφ + ⃗e ˆφ ⊗⃗e ˆθ)
(27.76d)
in the external universe: (i) are parallel-transported along rays and (ii) when
carried backward on rays into the local asymptotic rest frame, become the basis
vectors and tensors used in that frame’s solution (27.71) for the gravitational
27.5 The Generation of Gravitational Waves
1339

waves. Therefore, these eee+
μν and eee×
μν are the polarization tensors needed for our
geometric-optics waves.
(e) Consider a bundle of rays that, at the source, extends from φ to φ + φ and from
θ to θ + θ. Show that this bundle’s cross sectional area, as it moves outward
to larger and larger χ, is A = r2 sin θθφ, where r is a function of η and χ
given by
r = bχ = boη2χ.
(27.76e)
Show that in the source’s local asymptotic rest frame, this r is the same as the
distance r from the source that appears in Eqs. (27.71c) and (27.71d) for h+
and h×.
(f) Byputtingtogetherallthepiecesfromparts(a)through(e), showthatthesolution
to the equations of geometric optics (27.35) for the gravitational-wave ﬁeld as it
travels outward through the universe is
hhhTT = h+eee+ + h×eee×,
(27.76f)
with eee+ and eee× given by Eqs. (27.76d), with h+ and h× given by
h+ = −2(1 + cos2 θ)M5/32/3
r
cos ϕ,
h× = −4 cos θ M5/32/3
r
sin ϕ,
(27.76g)
and with , ϕ, and r given by Eqs. (27.76b), (27.76a), and (27.76e). [Hint: Note
that all quantities in this solution except r are constant along rays, and r varies as
1/
√
A, where A is the area of a bundle of rays.]
(g) Theangularfrequencyofthewavesthatareemittedatretardedtimeτr isωe = 2.
When received at Earth these waves have a cosmologically redshifted frequency
ωr = ∂ϕ/∂t, where t = (bo/3)η3 is proper time measured at Earth, and in the
derivative we must hold ﬁxed the spatial coordinates of Earth: {χ, θ, φ}. The
ratio of these frequencies is ωe/ωr = 1+ z, where z is the so-called cosmological
redshift of the waves. Show that 1 + z = (∂τr/∂t)−1 = η2/(η −χ)2.
(h) Show that the information carried by the binary’s waves is the following. (i) From
the ratio of the amplitudes of the two polarizations, one can read off the inclina-
tion angle θ of the binary’s spin axis to the line of sight to the binary. (ii) From the
waves’ measured angular frequency ω and its time rate of change dω/dt, one can
read off (1 + z)M, the binary’s redshifted chirp mass. (iii) From the amplitude
of the waves, with θ and (1 + z)M known, one can read off (1 + z)r, a quantity
known to cosmologists as the binary’s luminosity distance.[Note: It is remarkable
that gravitational waves by themselves reveal the source’s luminosity distance but
not its redshift, while electromagnetic observations reveal the redshift but not the
1340
Chapter 27. Gravitational Waves and Experimental Tests of General Relativity

luminosity distance. This complementarity illustrates the importance and power
of combined gravitational-wave and electromagnetic observations.]
27.5.5
27.5.5 Gravitational Waves from Binaries Made of Black Holes,
Neutron Stars, or Both: Numerical Relativity
Among the most interesting sources of gravitational waves are binary systems made
of two black holes, a black hole and a neutron star, or two neutron stars—so-called
compact binaries. When the two bodies are far apart, their motion and waves can
compact binaries analyzed
by a post-Newtonian
expansion
be described accurately by Newtonian gravity and the quadrupole-moment formal-
ism: the formulas in Sec. 27.5.4. As the bodies spiral inward, (M)2/3 = M/a =
v2 grows larger, h+ and h× grow larger, and relativistic corrections to our New-
tonian, quadrupole analysis grow larger. Those relativistic corrections (including
current-quadrupole waves, mass-octupole waves, etc.) can be computed using a post-
Newtonian expansion of the Einstein ﬁeld equations (i.e., an expansion in M/a ∼
v2). The accuracies of ground-based detectors such as LIGO require that, for com-
pact binaries, the expansion be carried at least to order v7 beyond our Newtonian,
quadrupole analysis! (See Blanchet, 2014.)
merger analyzed by
numerical relativity
At the end of the inspiral, the binary’s bodies come crashing together. To compute
the waves from this ﬁnal merger with an accuracy comparable to the observations, it
is necessary to solve the Einstein ﬁeld equation on a computer. The techniques for do-
ing this are called numerical relativity (Baumgarte and Shapiro, 2010; Shibata, 2016)
and were pioneered by Bryce DeWitt, Larry Smarr, Saul Teukolsky, Frans Pretorius,
and others.
For binary black holes with approximately equal masses, simulations using nu-
merical relativity reveal that the total energy radiated in gravitational waves is E ∼
0.1Mc2, where M is the binary’s total mass. Most of this energy is emitted in the last
∼5 to 10 cycles of waves, at wave periods P ∼(10 to 20)GM/c3 [i.e., frequencies
f = 1/P ∼1,000 Hz (10M⊙/M)]. The gravitational-wave power output in these last
gravitational-wave power
output in black hole
mergers: 100 universe
luminosities
5–10 cycles is dE/dt ∼0.1Mc2/(100GM/c3) = 0.001c5/G, which is roughly 1023
times the luminosity of the Sun, and 100 times the luminosity of all the stars in the
observable universe put together! If the holes have masses ∼10M⊙, this enormous
luminosity lasts for only ∼0.1 s, and the total energy emitted is the rest-mass energy
of the Sun. If the holes have masses ∼109M⊙, the enormous luminosity lasts for ∼1 yr,
and the energy emitted is the rest-mass energy of ∼108 Suns.
For the simplest case of two identical, nonspinning black holes that spiral together
in a circular orbit, both waveforms (both wave shapes) have the simple time evolution
shown in Fig. 27.6. As the holes spiral together, their amplitude and phase increase in
accord with the Newtonian-quadrupole formulas (27.71), (27.72), and (27.74) but by
the time of this ﬁgure, post-Newtonian corrections are producing noticeable differ-
ences from those formulas. When the holes merge, the gravitational-wave amplitude
27.5 The Generation of Gravitational Waves
1341

0.002
0.000
–0.002
0.1
0.0
–0.1
0
1,000
2,000
3,000
4,000
4,100
4,200
t/M
t/M
rM h+
FIGURE 27.6 For a binary made of two identical, nonspinning black holes that spiral together and
merge: the time evolution of the gravitational-wave tidal ﬁeld Eij ∝¨h+ [Eq. (27.22)] for the +
polarization. The × polarization waveform is the same as this but with a phase shift. The right
panel shows the detailed signal just prior to merger. Based on simulations performed by the
Caltech/Cornell/CITA numerical relativity group (Mrou´e et. al. 2013). (CITA is the Canadian
Institute for Theoretical Astrophysics.)
reaches a maximum amplitude. The merged hole then vibrates and the waves “ring
down” with exponentially decaying amplitude.
Much more interesting are binaries made of black holes that spin. In this case, the
angular momentum of each spinning hole drags inertial frames, as does the binary’s
orbital angular momentum. This frame-dragging causes the spins and the orbital
plane to precess, and those precessions modulate the waves. Figure 27.7 depicts a
generic example: a binary whose holes have a mass ratio 6:1, dimensionless spins
aA/MA = 0.91, aB/MB = 0.30, and randomly chosen initial spin axes and orbital
plane. Frame dragging causes the orbital motion to be rather complex, and corre-
spondingly, the two waveforms are much richer than in the nonspinning case. The
waveforms carry detailed information about the binary’s masses, spins, and orbital
information in
gravitational waves
evolution, and also about the geometrodynamics of its merger (Box 27.4).
EXERCISES
Exercise 27.15 Problem: Maximum Gravitational-Wave Amplitude
Extrapolating Eqs. (27.71)–(27.73) into the strong-gravity regime, estimate the maxi-
mumgravitational-waveamplitudeandemittedpowerforanonspinningbinaryblack
hole with equal masses and with unequal masses. Compare with the results from nu-
merical relativity discussed in the text.
Exercise 27.16 Problem: Gravitational Radiation from Binary Pulsars
in Elliptical Orbits
Many precision tests of general relativity are associated with binary pulsars in elliptical
orbits (Sec. 27.2.6).
(a) Verify that the radius of the relative orbit of the pulsars can be written as
r = p/(1 + e cos φ), where p is the semi-latus rectum, e is the eccentricity, and
dφ/dt = (Mp)1/2/r2 with M the total mass.
1342
Chapter 27. Gravitational Waves and Experimental Tests of General Relativity

0
200
400
600
800
1,000
to Earth
(a)
(b)
t/M
ḧ+, ḧ×
FIGURE 27.7 (a) The orbital motion of a small black hole around a larger black hole (mass ratio
MB/MA = 1/6), when the spins are aB/MB = 0.30 and aA/MA = 0.91and the initial spin axes and
orbital plane are as shown in panel b. (b) The two gravitational waveforms emitted in the direction
toward Earth (blue dashed line). These waveforms are from a catalog of simulations of 174 different
binary-black-hole mergers, carried out by the Caltech/Cornell/CITA numerical relativity group
(Mrou´e et al., 2013).
(b) Show that the traceless mass quadrupole moment, Eq. (27.53), in suitable coor-
dinates, is [cf. Eq. (27.70d)]
Ijk =
μp2
(1 + e cos φ)2
⎛
⎜⎝
cos2 φ −1
3
cos φ sin φ
0
cos φ sin φ
sin2 φ −1
3
0
0
0
−1
3
⎞
⎟⎠.
(27.77a)
(c) Use computer algebra to evaluate the second and third time derivatives of this
tensor, and then use Eqs. (27.61) and (27.62) to calculate the orbit-averaged
energy and angular momentum emitted in gravitational waves, per orbit.
27.5 The Generation of Gravitational Waves
1343

BOX 27.4.
GEOMETRODYNAMICS
When spinning black holes collide, they excite nonlinear vibrations of curved
spacetime—a phenomenon that John Wheeler has called geometrodynamics.
This nonlinear dynamics can be visualized using tidal tendex lines (which
depict the tidal ﬁeld Eij) and frame-drag vortex lines (which depict the frame-
drag ﬁeld Bij); see Boxes 25.2 and 26.3. Particularly helpful are the concepts of
a tendex (a collection of tendex lines with large tendicities) and a (frame-drag)
vortex (a collection of vortex lines with large vorticities). A spinning black
hole has a counterclockwise vortex emerging from its north polar region, and
a clockwise vortex emerging from its south polar region (right diagram in
Box 26.3).
As an example of geometrodynamics, consider two identical black holes
that collide head on, with their spins transverse to the collision direction.
Numerical-relativity simulations (Owen et al., 2011) reveal that, when the
holes collide and merge, each hole deposits its two vortices onto the merged
horizon. The four vortices dynamically attach to each other in pairs (panel a
in ﬁgure below). The pairs then interact, with surprising consequences. The
blue (clockwise) vortex disconnects from the hole and forms a set of closed
vortex loops that wrap around a torus (thick blue lines in panel c), and the red
(counterclockwise) vortex does the same (thin red lines in panel c). This torus
expands outward at the speed of light, while energy temporarily stored in near-
horizon tendices (not shown) regenerates the new pair of horizon-penetrating
vortices shown in panel b, with reversed vorticities (reversed directions of
twist). As the torus expands outward, its motion, via the Maxwell-like Bianchi
identity ∂E/∂t = (∇× B)S (Box 25.2), generates a set of tendex lines that
wrap around the torus at 45◦angles to the vortex lines (dashed lines in panel c).
The torus’s interleaved vortex and tendex lines have become a gravitational
wave, which locally looks like the plane wave discussed in Box 27.3. This
process repeats, with amplitude damping, generating a sequence of expanding
tori. (Figure adapted from Owen et al., 2011.)
(continued)
Your answer should be
E = 64πμ2M5/2
5p7/2

1 + 73
24e2 + 37
96e4

,
J = 64πμ2M2
5p2

1 + 7
8e2

.
(27.77b)
(d) Combine the results from part (c) with Kepler’s laws to calculate an expression for
therateofincreaseofpulseperiodanddecreaseoftheeccentricity(cf.Sec.27.2.6).
1344
Chapter 27. Gravitational Waves and Experimental Tests of General Relativity

BOX 27.4.
(continued)
(c)
(b)
(a)
(e) Consider a parabolic encounter between two stars, and show that the energy and
angular momentum radiated are, respectively,
E = 170πμ2M5/2
3p7/2
,
L = 24πμ2M2
p2
.
(27.78)
27.6
27.6 The Detection of Gravitational Waves
27.6.1
27.6.1 Frequency Bands and Detection Techniques
Physicists and astronomers are searching for gravitational waves in four different
frequency bands using four different techniques:
gravitational-wave
frequency bands: ELF,
VLF, LF, and HF; sources
and detection techniques
in each band
.
In the extremely low-frequency (ELF) band, ∼10−18 to ∼10−15 Hz, gravita-
tional waves are sought via their imprint on the polarization of the cosmic
microwave background (CMB) radiation. There is only one expected ELF
source of gravitational waves, but it is a very interesting one: quantum ﬂuc-
tuations in the gravitational ﬁeld (spacetime curvature) that emerge from the
big bang’s quantum-gravity regime, the Planck era,and that are subsequently
ampliﬁed to classical, detectable sizes by the universe’s early inﬂationary ex-
pansion.WeshallstudythisampliﬁcationandtheresultingELFgravitational
waves in Sec. 28.7.1 and shall see these waves’ great potential for probing the
physics of inﬂation.
27.6 The Detection of Gravitational Waves
1345

.
In the very-low-frequency (VLF) band, ∼10−9 to ∼10−7 Hz, gravitational
waves are sought via their inﬂuence on the propagation of radio waves emit-
ted by pulsars (spinning neutron stars) and by the resulting ﬂuctuations in
the arrival times of the pulsars’ radio-wave pulses at Earth (Sec. 27.6.6 and
Ex. 27.20). The expected VLF sources are violent processes in the ﬁrst frac-
tion of a second of the universe’s life (Secs. 28.4.1 and 28.7.1) and the orbital
motion of extremely massive pairs of black holes in the distant universe.
.
In the low-frequency (LF) band, ∼10−4 to ∼0.1 Hz, gravitational waves have
been sought, in the past, via their inﬂuence on the radio signals by which
NASA tracks interplanetary spacecraft. In the 2020s or 2030s, this tech-
nique will likely be supplanted by some variant of the proposed LISA—three
“drag-free” spacecraft in a triangular conﬁguration with 5-km-long arms,
that track one another via laser beams. LISA is likely to see waves from mas-
sive black-hole binaries (hole masses ∼105 to 107M⊙) out to cosmological
distances; from small holes, neutron stars, and white dwarfs spiraling into
massive black holes out to cosmological distances; from the orbital motion
of white-dwarf binaries, neutron-star binaries, and stellar-mass black-hole
binaries in our own galaxy; and possibly from violent processes in the very
early universe.
.
The high-frequency (HF) band, ∼10 to ∼103 Hz, is where Earth-based de-
tectors operate: laser interferometer gravitational-wave detectors, such as
LIGO, and resonant-mass detectors in which a gravitational wave alters the
amplitude and phase of vibrations of a normal mode of a large, solid cylinder
or sphere. On September 14, 2015, the advanced LIGO gravitational wave
detectors made their ﬁrst detection: a wave burst named GW150914 with
amplitude 1.0 × 10−21, duration ∼150 ms, and frequency chirping upward
from ∼50 Hz (when it entered the LIGO band) to 240 Hz. By comparing the
observed waveform with those from numerical relativity simulations, the
LIGO-VIRGO scientists deduced that the waves came from the merger of a
29M⊙black hole with a 36M⊙black hole, 1.2 billion light years from Earth,
to form a 62M⊙black hole, with a release of 3M⊙c2 of energy in gravitational
waves. When this textbook went to press, additional black hole binaries were
being detected. As LIGO’s sensitivity improves and additional interferome-
terscomeonline, theLIGOscientistsexpecttoseeothersources:wavesfrom
spinning, slightly deformed neutron stars (e.g., pulsars) in our Milky Way
galaxy, the ﬁnal inspiral and collisions of binaries made from neutron stars in
themoredistantuniverse, thetearingapartofaneutronstarbythespacetime
curvature of a companion black hole, supernovae, the triggers of gamma-ray
bursts, and possibly waves from violent processes in the very early universe.
For detailed discussions of these gravitational-wave sources in all four frequency
bands, andofprospectsfortheirdetection, see, forexample, CutlerandThorne(2002)
1346
Chapter 27. Gravitational Waves and Experimental Tests of General Relativity

and Sathyaprakash and Schutz (2009) and references therein. It is likely that waves will
be seen in all four bands by about 2030.
EXERCISES
Exercise 27.17 Example: Strongest Gravitational Waves in HF Band
(a) Using an order-of-magnitude analysis based on Eq. (27.60), show that the
strongest gravitational waves that are likely to occur each year in LIGO’s HF band
have h+ ∼h× ∼10−21—which is the actual amplitude of LIGO’s ﬁrst observed
wave burst, GW150914. [Hint: The highest nonspherical kinetic energy achiev-
able must be for a highly deformed object (or two colliding objects), in which
the internal velocities approach the speed of light—say, for realism, v ∼0.3c. To
achieve these velocities, the object’s size L must be of order 2 or 3 Schwarzschild
radii, L ∼5M, where M is the source’s total mass. The emitted waves must have
f ∼200 Hz (the frequency at the minimum of Advanced LIGO’s noise curve—
which is similar to initial LIGO, Fig. 6.7, but a factor ∼10 lower). Using these
considerations, estimate the internal angular frequency of the source’s motion,
and thence the source’s mass, and ﬁnally the source’s internal kinetic energy.
Such a source will be very rare, so to see a few per year, its distance must be some
substantial fraction of the Hubble distance. From this, estimate h+ ∼h×.]
(b) As a concrete example, estimate the gravitational-wave strength from the ﬁnal
moments of inspiral and merger of two black holes, as described by Eqs. (27.71)
and (27.70b) extrapolated into the highly relativistic domain.
27.6.2
27.6.2 Gravitational-Wave Interferometers: Overview and Elementary Treatment
We brieﬂy discussed Earth-based gravitational-wave interferometers such as LIGO
in Sec. 9.5, focusing on optical interferometry issues. In this section we analyze the
idealized gravitational-
wave interferometer
interaction of a gravitational wave with such an interferometer. This analysis will not
only teach us much about gravitational waves, but it will also illustrate some central
issues in the physical interpretation of general relativity theory.
To get quickly to the essentials, we examine a rather idealized interferometer: a
Michelson interferometer (one without the input mirrors of Fig. 9.13) that ﬂoats freely
in space, so there is no need to hang its mirrors by wires; see Fig. 27.8. In Sec. 27.6.5,
we brieﬂy discuss more realistic interferometers.
Ifweignoredelicatedetails, theoperationofthisidealizedinterferometerissimple.
As seen in a local Lorentz frame of the beam splitter, the gravitational wave changes
the length of the x arm by δx = 1
2h+ℓx, where ℓx is the unperturbed length, and it
changes that of the y arm by the opposite amount: δy = −1
2h+ℓy [Eqs. (27.29)]. The
interferometer is operated with unperturbed lengths ℓx and ℓy that are nearly but
not quite equal, so there is a small amount of light going toward the photodetector.
The wave-induced change of arm length causes a relative phase shift of the light
27.6 The Detection of Gravitational Waves
1347

end mirror
end
mirror
laser
beam splitter
photo-
detector
y
x
ℓx
ℓy
FIGURE 27.8 An idealized gravitational-wave interferometer.
returning down the two arms to the beam splitter given by ϕ(t) = ωo(2δy −2δx) =
ωo(ℓx + ℓy)h+(t), where ωo is the light’s angular frequency (and we have set the speed
of light to unity); cf. Sec. 9.5. This oscillating phase shift modulates the intensity of
the light going into the photodetector by IPD(t) ∝ϕ(t). Setting ℓx ≃ℓy = ℓ, this
interferometer’s
photodetector current
output
modulation is
IPD(t) ∝ϕ(t) = 2ωoℓh+(t).
(27.79)
Therefore, thephotodetectoroutputtellsusdirectlythegravitationalwaveformh+(t).
In the following two (Track-Two) subsections, we rederive this result much more
carefully in two different coordinate systems (two different gauges). Our two analyses
predict the same result (27.79) for the interferometer output, but they appear to
attribute that result to two different mechanisms.
TT-gauge analysis
attributes output signal
to inﬂuence of waves on
interferometer’s light
In our ﬁrst analysis (performed in TT gauge; Sec. 27.6.3), the interferometer’s test
mass remains always at rest in our chosen coordinate system, and the gravitational
wave h+(t −z) interacts with the interferometer’s light. The imprint that h+(t −z)
leaves on the light causes a ﬂuctuating light intensity Iout(t) ∝h+(t) to emerge from
the interferometer’s output port and be measured by the photodetector.
In our second analysis (a more rigorous version of the above quick analysis, per-
formed in the proper reference frame of the interferometer’s beam splitter; Sec. 27.6.4)
the gravitational waves interact hardly at all with the light. Instead, they push the end
proper-reference-frame
analysis attributes output
signal to interaction of
waves with interferometer
mirrors
mirrors back and forth relative to the coordinate system, thereby lengthening one
arm while shortening the other. These changing arm lengths cause a changing inter-
ferenceofthelightreturningtothebeamsplitterfromthetwoarms, andthatchanging
interference produces the ﬂuctuating light intensity Iout(t) ∝h+(t) measured by the
photodetectors.
1348
Chapter 27. Gravitational Waves and Experimental Tests of General Relativity

These differences of viewpoint are somewhat like the differences between the
analogy with Heisenberg
and Schr¨odinger pictures
in quantum mechanics
Heisenberg picture and the Schr¨odinger picture in quantum mechanics. The intu-
itivepicturesassociatedwithtwoviewpointsappeartobeverydifferent(Schr¨odinger’s
wave function versus Heisenberg’s matrices; gravitational waves interacting with light
versus gravitational waves pushing on mirrors). But when one computes the same
physical observable from the two different viewpoints (probability for a quantum
measurement outcome; light intensity measured by photodetector), the two view-
points give the same answer.
27.6.3
27.6.3 Interferometer Analyzed in TT Gauge
For our ﬁrst analysis, we place the interferometer at rest in the x-y plane of a TT
interferometer analyzed in
TT gauge
coordinate system, with its arms along the x- and y-axes and its beam splitter at the
origin, as shown in Fig. 27.8. For simplicity, we assume that the gravitational wave
propagates in the z direction and has + polarization, so the linearized spacetime
metric has the TT-gauge form:
spacetime metric
ds2 = −dt2 + [1 + h+(t −z)]dx2 + [1 −h+(t −z)]dy2 + dz2
(27.80)
[Eq. (27.20)]. For ease of notation, we omit the subscript + from h+ in the remainder
of this section.
The beam splitter and end mirrors move freely and thus travel along geodesics of
the metric (27.80). The splitter and mirrors are at rest in the TT coordinate system
before the wave arrives, so initially, the spatial components of their 4-velocities vanish:
uj = 0.Becausethemetriccoefﬁcients gαβ areallindependentofx andy, thegeodesic
equation dictates that the components ux and uy are conserved and thus remain zero
as the wave passes, which implies (since the metric is diagonal) ux = dx/dτ = 0 and
uy = dy/dτ = 0. One can also show (see Ex. 27.18) that uz = dz/dτ = 0 throughout
the wave’s passage. Thus, in terms of motion relative to the TT coordinate system, the
mirrors and beam splitter
do not move relative to TT
coordinates
gravitational wave has no inﬂuence at all on the beam splitter and mirrors; they all
remain at rest (constant x, y, and z) as the waves pass.
(Despite this lack of motion, the proper distances between the mirrors and the
beam splitter—the interferometer’s physically measured arm lengths—do change. If
the unchanging coordinate lengths of the two arms are x = ℓx and y = ℓy, then
the metric (27.80) says that the physically measured arm lengths are
Lx =

1 + 1
2h(t)

ℓx,
Ly =

1 −1
2h(t)

ℓy.
(27.81)
Whenhispositive, thex armislengthenedandthe y armisshortened; whennegative,
Lx is shortened and Ly is lengthened.)
Next turn to the propagation of light in the interferometer. We assume, for simplic-
ity, that the light beams have large enough transverse sizes that we can idealize them,
on their optic axes, as plane electromagnetic waves. (In reality, they will be Gaussian
27.6 The Detection of Gravitational Waves
1349

beams, of the sort studied in Sec. 8.5.5.) The light’s vector potential Aα satisﬁes the
curved-spacetime vacuum wave equation Aα;μμ = 0 [Eq. (25.60) with vanishing Ricci
tensor]. We write the vector potential in geometric optics (eikonal-approximation)
form as
Aα = ℜ(Aαeiϕ),
(27.82)
where Aα is a slowly varying amplitude, and ϕ is a rapidly varying phase [cf. Eq.
(7.20)]. Because the wavefronts are (nearly) planar and the spacetime metric is nearly
ﬂat, the light’s amplitude Aα will be nearly constant as it propagates down the arms,
and we can ignore its variations. Not so the phase. It oscillates at the laser frequency
ωo/2π ∼3 × 1014 Hz [i.e., ϕout
x arm ≃ωo(x −t) for light propagating outward from the
beam splitter along the x arm, and similarly for the returning light and the light in
the y arm]. The gravitational wave places tiny deviations from this ωo(x −t) onto the
phase; we must compute those deviations.
In the spirit of geometric optics, we introduce the light’s spacetime wave vector
⃗k ≡⃗∇ϕ,
(27.83)
and we assume that ⃗k varies extremely slowly compared to the variations of ϕ. Then
the wave equation Aα;μμ = 0 reduces to the statement that the wave vector is null:
⃗k . ⃗k = ϕ,αϕ,βgαβ = 0. For light in the x arm the phase depends only on x and t; for
that in the y arm it depends only on y and t. Combining this with the TT metric
(27.80) and noting that the interferometer lies in the z = 0 plane, we obtain
inﬂuence of waves
on phase of light in
interferometer arms
−
∂ϕx arm
∂t
2
+ [1 −h(t)]
∂ϕx arm
∂x
2
= 0,
−
∂ϕy arm
∂t
2
+ [1 + h(t)]
∂ϕy arm
∂y
2
= 0.
(27.84)
We idealize the laser as perfectly monochromatic, and we place it at rest in our TT
coordinates, arbitrarily close to the beam splitter. Then the outgoing light frequency,
as measured by the beam splitter, must be precisely ωo and cannot vary with time.
Since proper time as measured by the beam splitter is equal to coordinate time
t [cf. the metric (27.80)], the frequency that the laser and beam splitter measure
must be ω = −∂ϕ/∂t = −kt. This dictates the following boundary conditions (initial
conditions) on the phase of the light that travels outward from the beam splitter:
∂ϕout
x arm
∂t
= −ωo at x = 0,
∂ϕout
y arm
∂t
= −ωo at y = 0.
(27.85)
It is straightforward to verify that the solutions to Eq. (27.84) (and thence to
the wave equation and thence to Maxwell’s equations) that satisfy the boundary
conditions (27.85) are
1350
Chapter 27. Gravitational Waves and Experimental Tests of General Relativity

ϕout
x arm = −ωo

t −x + 1
2H(t −x) −1
2H(t)

,
ϕout
y arm = −ωo

t −y −1
2H(t −y) + 1
2H(t)

,
(27.86)
where H(t) is the ﬁrst time integral of the gravitational waveform:
H(t) ≡
 t
0
h(t′)dt′
(27.87)
(cf. Ex. 27.19).
The outgoing light reﬂects off the mirrors, which are at rest in the TT coordinates
at locations x = ℓx and y = ℓy. As measured by observers at rest in these coordinates,
there is no Doppler shift of the light, because the mirrors are not moving. Correspond-
ingly, the phases of the reﬂected light, returning back along the two arms, have the
following forms:
ϕback
x arm = −ωo

t + x −2ℓx + 1
2H(t + x −2ℓx) −1
2H(t)

,
ϕback
y arm = −ωo

t + y −2ℓy −1
2H(t + y −2ℓy) + 1
2H(t)

.
(27.88)
The difference of the phases of the returning light, at the beam splitter (x = y = 0), is
difference between arms
for output light’s phase
shift
ϕ ≡ϕback
x arm −ϕback
y arm = −ωo[−2(ℓx −ℓy) + 1
2H(t −2ℓx) + 1
2H(t −2ℓy) −H(t)]
≃+2ωo[ℓx −ℓy + ℓh(t)]
for Earth-based interferometers.
(27.89)
In the ﬁnal expression we have used the fact that for Earth-based interferometers op-
erating in the HF band, the gravitational wavelength λGW ∼c/(100 Hz) ∼3,000 km
is long compared to the interferometers’ ∼4-km arms, and the arms have nearly the
same length: ℓy ≃ℓx ≡ℓ.
Thebeamsplittersendsalightﬁeld∝eiϕback
x arm + eiϕback
y arm backtowardthelaser, anda
ﬁeld ∝eiϕback
x arm −eiϕback
y arm = eiϕback
y arm(eiϕ −1) toward the photodetector. The intensity
of the light entering the photodetector is proportional to the squared amplitude of the
ﬁeld: IPD ∝|eiϕ −1|2. We adjust the interferometer’s arm lengths so their difference
ℓx −ℓy is small compared to the light’s reduced wavelength 1/ωo = c/ωo but large
compared to |ℓh(t)|. Correspondingly, |ϕ| ≪1, so only a tiny fraction of the light
goes toward the photodetector (it is the interferometer’s “dark port”), and that dark-
port light intensity is
photodiode output
IPD ∝|eiϕ −1|2 ≃|ϕ|2 ≃4ω2
o(ℓx −ℓy)2 + 8ω2
o(ℓx −ℓy)ℓh+(t).
(27.90)
Here we have restored the subscript + onto h. The time-varying part of this intensity
is proportional to the gravitational waveform h+(t) [in agreement with Eq. (27.79)]. It
is this time-varying part that the photodetector reports as the interferometer output.
27.6 The Detection of Gravitational Waves
1351

EXERCISES
Exercise 27.18 Derivation and Practice: Geodesic Motion in TT Coordinates
Consider a particle that is at rest in the TT coordinate system of the gravitational-wave
metric (27.80) before the gravitational wave arrives. In the text it is shown that the
particle’s 4-velocity has ux = uy = 0 as the wave passes. Show that uz = 0 and ut = 1
as the wave passes, so the components of the particle’s 4-velocity are unaffected by the
passing gravitational wave, and the particle remains at rest (constant x, y, and z) in
the TT coordinate system.
Exercise 27.19 Example: Light in an Interferometric Gravitational-Wave
Detector in TT Gauge
Consider the light propagating outward from the beam splitter, along the x arm of an
interferometric gravitational-wave detector, as analyzed in TT gauge, so (suppressing
the subscript “x arm” and superscript “out”) the electromagnetic vector potential
is Aα = ℜ(Aαeiϕ(x,t)), with Aα constant and with ϕ = −ωo
"
t −x + 1
2H(t −x)−
1
2H(t)
#
[Eqs. (27.86) and (27.87)].
(a) Show that this ϕ satisﬁes the nullness equation (27.84), as claimed in the
text—which implies that Aα = ℜ(Aαeiϕ(x,t)) satisﬁes Maxwell’s equations in the
geometric-optics limit.
(b) Show that this ϕ satisﬁes the initial condition (27.85), as claimed in the text.
(c) Show that, because the gradient ⃗k = ⃗∇ϕ of this ϕ satisﬁes ⃗k . ⃗k = 0, it also satisﬁes
∇⃗k⃗k = 0. Thus, the wave vector is the tangent vector to geometric-optics rays that
are null geodesics in the gravitational-wave metric. Photons travel along these
null geodesics and have 4-momenta ⃗p = ℏ⃗k.
(d) Because the gravitational-wave metric (27.80) is independent of x, the px com-
ponent of a photon’s 4-momentum must be conserved along its geodesic world
line. Compute px = kx = ∂ϕ/∂x, and thereby verify this conservation law.
(e) Explain why the photon’s frequency, as measured by observers at rest in our TT
coordinate system, is ω = −kt = −∂ϕ/∂t. Explain why the rate of change of this
frequency, as computed moving with the photon, is dω/dt ≃(∂/∂t + ∂/∂x)ω,
and show that dω/dt ≃−1
2ωodh/dt.
27.6.4
27.6.4 Interferometer Analyzed in the Proper Reference Frame of the Beam Splitter
We now carefully reanalyze our idealized interferometer in the proper reference frame
proper-reference-frame
analysis
of its beam splitter, denoting that frame’s coordinates by ˆxα. Because the beam splitter
is freely falling (moving along a geodesic through the gravitational-wave spacetime),
its proper reference frame is locally Lorentz (LL), and its metric coefﬁcients have the
form gˆα ˆβ = ηαβ + O(δjk ˆxj ˆxk/R2) [Eq. (25.9a)]. Here R is the radius of curvature of
spacetime, and 1/R2 is of order the components of the Riemann tensor, which have
1352
Chapter 27. Gravitational Waves and Experimental Tests of General Relativity

magnitude ¨h(ˆt −ˆz) [Eq. (27.22) with t and z equal to ˆt and ˆz, aside from fractional
corrections of order h]. Thus we have:
gˆα ˆβ = ηαβ + O[¨h(ˆt −ˆz)δjk ˆxj ˆxk].
(27.91)
(Here and below we again omit the subscript + on h for ease of notation.)
The following coordinate transformation takes us from the TT coordinates xα
used in Sec. 27.6.3 to the beam splitter’s LL coordinates:
x =

1 −1
2h(ˆt −ˆz)

ˆx,
y =

1 + 1
2h(ˆt −ˆz)

ˆy,
t = ˆt −1
4
˙h(ˆt −ˆz)(ˆx2 −ˆy2),
z = ˆz −1
4
˙h(ˆt −ˆz)(ˆx2 −ˆy2).
(27.92)
It is straightforward to insert this coordinate transformation into the TT-gauge metric
(27.80) and thereby obtain, to linear order in h:
spacetime metric in proper
reference frame of beam
splitter
ds2 = −d ˆt2 + d ˆx2 + d ˆy2 + dˆz2 + 1
2(ˆx2 −ˆy2)¨h(t −z)(d ˆt −dˆz)2.
(27.93)
This has the expected LL form (27.91) and, remarkably, it turns out not only to be
a solution of the vacuum Einstein equation in linearized theory but also an exact
solution to the full vacuum Einstein equation (cf. Misner, Thorne, and Wheeler, 1973,
Ex. 35.8)!
Throughout our idealized interferometer, the magnitude of the metric perturba-
tion in these LL coordinates is |hˆα ˆβ| <∼(ℓ/-λGW)2h, where -λGW = λGW/(2π) is the
waves’ reduced wavelength, and h is the magnitude of h(ˆt −ˆz). For Earth-based
interferometers operating in the HF band (∼10 to ∼1000 Hz), -λGW is of order 50–
5,000 km, and the arm lengths are ℓ≤4 km, so (L/-λ)2 <∼10−6 to 10−2. Thus, the
metric coefﬁcients hˆα ˆβ are no larger than h/100. This has a valuable consequence for
the analysis of the interferometer: up to fractional accuracy ∼(ℓ/-λGW)2h <∼h/100,
the LL coordinates are globally Lorentz throughout the interferometer (i.e., ˆt mea-
sures proper time, and ˆxj are Cartesian and measure proper distance). In the rest of
this section, we restrict attention to such Earth-based interferometers but continue
to treat them as though they were freely falling. (See Sec. 27.6.5 for the inﬂuence of
Earth’s gravity.)
Being initially at rest at the origin of these LL coordinates, the beam splitter
remains always at rest, but the mirrors move. Not surprisingly, the geodesic equation
for the mirrors in the metric (27.93) dictates that their coordinate positions are, up to
fractional errors of order (ℓ/-λGW)2h,
27.6 The Detection of Gravitational Waves
1353

ˆx = Lx =

1 + 1
2h(ˆt)

ℓx,
ˆy = ˆz = 0
for mirror in x arm,
ˆy = Ly =

1 −1
2h(ˆt)

ℓy,
ˆx = ˆz = 0
for mirror in y arm.
(27.94)
[Equations (27.94) can also be deduced from the gravitational-wave tidal acceleration
mirror motions in proper
reference frame
−E ˆj ˆk ˆxk, as in Eq. (27.25), and from the fact that to good accuracy ˆx and ˆy measure
proper distance from the beam splitter.] So even though the mirrors do not move in
TT coordinates, they do move in LL coordinates. The two coordinate systems predict
the same time-varying physical arm lengths (the same proper distances from beam
splitter to mirrors), Lx and Ly [Eqs. (27.81) and (27.94)].
As in TT coordinates, so also in LL coordinates, we can analyze the light prop-
agation in the geometric-optics approximation, with Aˆα = ℜ(A ˆαeiϕ). Just as the
wave equation for the vector potential dictates in TT coordinates that the rapidly
varying phase of the outward light in the x arm has the form ϕout
x arm = −ωo(t −
x) + O(ωoℓhμν) [Eqs. (27.86) with x ∼ℓ≪-λGW, so H(t −x) −H(t) ≃˙H(t)x =
h(t)x ∼hℓ∼hμνℓ], so similarly the wave equation in LL coordinates turns out to
dictate that
ϕout
x arm = −ωo(ˆt −ˆx) + O(ωoℓh ˆμˆν) = −ωo(ˆt −ˆx) + O
*
ωoℓh ℓ2
-λ2
GW
+
,
(27.95)
and similarly for the returning light and the light in the y arm. The term O(ωoℓh ℓ2/
-λ2
GW) is the inﬂuence of the direct interaction between the gravitational wave and the
light, and it is negligible in the ﬁnal answer (27.96) for the measured phase shift. Aside
from this term, the analysis of the interferometer proceeds in exactly the same way as
in ﬂat space (because ˆt measures proper time and ˆx and ˆy proper distance): the light
travels a round trip distance Lx in one arm and Ly in the other, and therefore acquires
a phase difference, on arriving back at the beam splitter, given by
difference in output phase
shift between arms: same
as in TT gauge
ϕ = −ωo[−2(Lx −Ly)]+ O
*
ωoℓh ℓ2
-λ2
GW
+
≃+2ωo[ℓx −ℓy + ℓh(ˆt)]+ O
*
ωoℓh ℓ2
-λ2
GW
+
.
(27.96)
This net phase difference for the light returning from the two arms is the same
as we deduced in TT coordinates [Eq. (27.89)], up to the negligible correction
O(ωoℓh ℓ2/-λ2
GW), and therefore the time-varying intensity of the light into the
photodetector will be the same [Eq. (27.90)].
In our TT analysis the phase shift 2ωoℓh(t) arose from the interaction of the
light with the gravitational waves. In the LL analysis, it is due to the displacements
1354
Chapter 27. Gravitational Waves and Experimental Tests of General Relativity

of the mirrors in the LL coordinates (i.e., the displacements as measured in terms of
proper distance) that cause the light to travel different distances in the two arms. The
direct LL interaction of the waves with the light produces only the tiny correction
O(ωoℓh ℓ2/-λ2
GW) to the phase shift.
It should be evident that the LL description is much closer to elementary physics
than the TT description is. This is always the case, when one’s apparatus is sufﬁciently
small that one can regard ˆt as measuring proper time and ˆxj as Cartesian coordinates
that measure proper distance throughout the apparatus. But for a large apparatus (e.g.,
planned space-based interferometers such as LISA, with arm lengths ℓ>∼-λGW, and
the pulsar timing arrays of Sec. 27.6.6) the LL analysis becomes quite complicated, as
one must pay close attention to the O(ωoℓh ℓ2/-λ2
GW) corrections. In such a case, the
TT analysis is much simpler.
27.6.5
27.6.5 Realistic Interferometers
For realistic, Earth-based interferometers, one must take account of the acceleration
of gravity. Experimenters do this by hanging their beam splitters and test masses on
wires or ﬁbers. The simplest way to analyze such an interferometer is in the proper
reference frame of the beam splitter, where the metric must now include the inﬂuence
of the acceleration of gravity by adding a term −2gˆz to the metric coefﬁcient hˆ0ˆ0 [cf.
Eq. (24.60b)]. The resulting analysis, like that in the LL frame of our freely falling
interferometer, will be identical to what one would do in an accelerated reference
frame of ﬂat spacetime, so long as one takes account of the motion of the test masses
driven by the gravitational-wave tidal acceleration −Eˆi ˆj ˆxj, and so long as one is
willing to ignore the tiny effects of O(ωoℓh ℓ2/-λ2
GW).
To make the realistic interferometer achieve high sensitivity, the experimenters
introduce a lot of clever complications, such as the input mirrors of Fig. 9.13, which
turn the arms into Fabry-Perot cavities. All these complications can be analyzed, in
the beam splitter’s proper reference frame, using standard ﬂat-spacetime techniques
augmented by the gravitational-wave tidal acceleration. The direct coupling of the
light to the gravitational waves can be neglected, as in our idealized interferometer.
27.6.6
27.6.6 Pulsar Timing Arrays
A rather different approach to direct detection of gravitational waves is by the inﬂu-
ence of the waves on the timing of an array of radio pulsars (Hobbs et al., 2010).
gravitational-wave
searches via pulsar
timing arrays in VLF band
As we have discussed in Sec. 27.2.6, many pulsars, especially those with milli-
second periods, have pulse arrival times at the radio telescope that can be predicted
with high accuracy—30 to 100 ns in the best cases—after correcting for slowing down
of the pulsar, propagation effects, and the motion of the telescope relative to the center
of mass of the solar system. If the radio pulses travel through a gravitational wave, then
they incur tiny variations in arrival time that can be used to detect the wave. This
technique is most sensitive to waves with frequency f ∼30 nHz (the gravitational
27.6 The Detection of Gravitational Waves
1355

VLF band; see Sec. 27.6.1), so a few periods are sampled over the duration of an
observation, typically a few years. The most promising sources are supermassive
binary black holes in the nuclei of distant galaxies.
Let us consider the idealized problem of radio pulses emitted at a steady rate by
a stationary pulsar with position z relative to a stationary telescope on Earth and
traveling at the speed of light. Now, suppose that there is a single, monochromatic,
plane gravitational wave, hhh = hhho cos[2πf (t + x . ˆr)], where ˆr is a unit vector pointing
toward the source. For the wave, adopt the metric (27.18a) and TT gauge. The pulsar
and the telescope will remain at rest with respect to the coordinates (Ex. 27.18), and
t measures their proper times.
The wave-induced time delay in the arrival of a pulse, called the residual R(t),
is then given by integrating along a past directed null geodesic (ds = 0) from the
telescope to the pulsar:6
inﬂuence of gravitational
wave on radio pulses’ time
delay (their “residual”)
R(t) = −1
2
 z
0
dz′ˆz . hhho . ˆz cos

2πf [t −z′(1 −ˆz . ˆr)]

= ˆz . hhho . ˆz
C
sin(2πf [t −z(1 −ˆz . ˆr)]) −sin(2πf t)
D
4πf (1 −ˆz . ˆr)
(27.97)
(Ex. 27.20a). Note that two terms contribute to the residual; the ﬁrst is associated
with the wave as it passes the pulsar, the second is local and associated with the wave
passing Earth.
This search for gravitational waves is being prosecuted not just with a single pulsar
but also with an array of tens (currently and hundreds in the future) of millisecond
pulsars. Programs using different telescopes are being coordinated and combined
through the International Pulsar Timing Array (IPTA) collaboration (http://www
.ipta4gw.org). The local residual (27.97) is correlated between different lines of sight
correlation of residuals
between different pulsars
to different pulsars with differing polarization projections ˆz . hhho . ˆz. This facilitates
identifying the waves amidst different noises associated with different pulsars, and it
allows a coherent addition of the data from many pulsars, which will be particularly
valuable in searches for individual sources of gravitational radiation. If and when a
source is located, the array can be used to ﬁx its direction ˆr and the polarization of
the waves. In addition to extracting astrophysics of the source, there should be a clear
afﬁrmation that gravitational waves have spin two and travel at the speed of light.
gravitational-wave sources
in VLF band
However, unless we are very lucky, it is more likely that the ﬁrst detection or the
most prescriptive upper limit will relate to a stochastic background created by the
superposedwavesfrommanyblackholebinaries(Ex.27.21).Althoughthebandwidth
from an individual source will be of order the reciprocal of the time it takes the binary
6.
Of course the actual null geodesic followed by the radio waves changes in the presence of the gravitational
wave but, invoking Fermat’s principle, the travel time is unchanged to O(h) if we integrate along the
unperturbed trajectory.
1356
Chapter 27. Gravitational Waves and Experimental Tests of General Relativity

frequencytodouble—inthefHztopHzrange—therandomlyphasedsignalsarelikely
to overlap in frequency, ensuring that the gravitational radiation can be well described
by a spectral energy density.
Other more speculative sources of gravitational waves in the VLF frequency band
have been proposed, especially cosmic strings. There could be many surprises waiting
to be discovered.
EXERCISES
Exercise 27.20 Example: Pulsar Timing Array
Explore how pulsar timing can be used to detect a plane gravitational wave.
(a) Derive Eq. (27.97). [Hint: One way to derive this result is from the action
1
2

gαβ(dxα/dζ)(dxβ/dζ)dζ
that underlies the rays’ super-hamiltonian; Ex. 25.7. The numerical value of the
action is zero, and since it is an extremum along each true ray, if you evaluate it
along a path that is a straight line in the TT coordinate system instead of along
the true ray, you will still get zero at ﬁrst order in hhho.]
(b) Recognizing local and pulsar contributions to the timing residuals, explain how
much information about the amplitude, direction, and polarization of a gravita-
tional wave from a single black-hole binary can be obtained using accurate timing
data from one, two, three, four, and many pulsars.
(c) Suppose, optimistically, that 30 pulsars will be monitored with timing accuracy
∼100 ns, and that arrival times will be measured 30 times a year. Make an estimate
of the minimum measurable amplitude of the sinusoidal residual created by a
single binary as a function of observing duration and wave frequency f .
(d) Using the result from part (c) and using the predicted residual averaged over
the direction and the orientation of the source from Eqs. (27.71c) and (27.71d),
estimate the maximum distance to which an individual source could be detected
as a function of the chirp mass M and the frequency f .
Exercise 27.21 Problem: Stochastic Background from Binary Black Holes
The most likely signal to be detected using a pulsar timing array is a stochastic
background formed by perhaps billions of binary black holes in the nuclei of galaxies.
(a) For simplicity, suppose that these binaries are all on circular orbits and that
they lose energy at a rate given by Eqs. (27.73). Show that for each binary the
gravitational wave energy radiated per unit log wave frequency is
dEGW
d ln f = −dE
d ln f = −2E
3 = π2/3
3 M5/3f 2/3,
(27.98a)
where Mis the chirp mass given by Eq. (27.76c) and E is its orbital energy given
by −1
2μM/a.
27.6 The Detection of Gravitational Waves
1357

(b) Suppose that, on astrophysical grounds, binaries only radiate gravitational radia-
tion efﬁciently if they merge in less than tmerge ∼300 Myr. Show that this requires
M >
*
5
256 tmerge
+3/5
(πf )−8/5.
(27.98b)
This evaluates to ∼1million solar masses for f ∼30 nHz. By contrast, measured
masses of the large black holes in the nuclei of galaxies range from about 4 million
solar masses as in our own modest spiral galaxy to perhaps 20 billion solar masses
in the largest galaxies observed.
(c) Now suppose that these black holes grew mostly through mergers of holes with
very different masses. Show that the total energy radiated per unit log frequency
over the course of the many mergers that led to a black hole with mass M is
dEGW
d ln f ∼π2/3
5 M5/3f 2/3.
(27.98c)
(d) The number density per unit mass dn/dM today of these merging black holes
has been estimated to be
dn
d ln M = ρBHM2
2M3
t
e−M/Mt,
(27.98d)
where ρBH ∼2 × 10−15 J m−3 is the contribution of black holes (i.e., of their
masses) to the average energy density in the local universe and Mt = 5 × 107
solar masses ∼1038 kg. Show that
dρGW
d ln f ∼π2/3 (11/3)
10
(Mtf )2/3ρBH ∼7 × 10−19

f
30 nHz
2/3
J m−3. (27.99)
This is an overestimate, because most of the black holes were likely assembled
in the past, when the universe was about three times smaller than it is today. If
one thinks of the gravitational waves as gravitons that lose energy as the universe
expands, then this energy density should be reduced by a factor of three. Further-
more, as the black holes are thought to grow through accretion of gas and not by
mergers, this estimate should be considered an upper bound.
(e) Making the same assumptions as in the previous exercise, determine whether it
will be possible to detect this background in 5 years of observation.
Bibliographic Note
For an elementary introduction to experimental tests of general relativity in the solar
system, we recommend Hartle (2003, Chap. 10). For an enjoyable, popular-level book
on experimental tests, see Will (1993b). For a very complete monograph on the theory
1358
Chapter 27. Gravitational Waves and Experimental Tests of General Relativity

underlying experimental tests, see Will (1993a), and for a more nearly up-to-date
review of experimental tests, see Will (2014).
For elementary and fairly complete introductions to gravitational waves, we rec-
ommend Hartle (2003, Chaps. 16, 23) and Schutz (2009, Chap. 9). For more advanced
treatments, we suggest Misner, Thorne, and Wheeler (1973, Sec. 18.2 and Chaps. 35,
36), Thorne (1983), and Straumann (2013, Secs. 5.3–5.7); but Misner, Thorne, and
Wheeler (1973, Chap. 37) on gravitational-wave detection is terribly out of date and
is not recommended. For fairly complete reviews of gravitational-wave sources for
ground-based detectors (LIGO, etc.) and space-based detectors (LISA, etc.), see Cut-
ler and Thorne (2002) and Sathyaprakash and Schutz (2009). For a lovely monograph
on the physics of interferometric gravitational-wave detectors, see Saulson (1994).
Because gravitational-wave science is a rapidly maturing and burgeoning ﬁeld,
there are long, in-depth treatments that include considerable experimental detail
and much detail on data analysis techniques, as well as on wave sources and the
fundamental theory: Thorne, Bondarescu, and Chen (2002), Maggiore (2007), and
Creighton and Anderson (2011).
Bibliographic Note
1359


28
CHAPTER TWENTY-EIGHT
Cosmology
The expansion thus took place in three phases, a ﬁrst period of rapid expansion in which the atom
universe was broken into atomic stars, a period of slowing down,
followed by a third period of accelerated expansion.
GEORGES LEMAˆITRE (1933)
28.1
28.1 Overview
The extragalactic sky is isotropic and dark at night. Distant galaxies accelerate away
from us. Five-sixths of the matter in the universe is in a “dark” form that we can
only detect through its gravitational effects. We are immersed in a bath of blackbody
radiation—the cosmic microwave background (CMB)—with a temperature of ∼2.7 K
that exhibits tiny ﬂuctuations with fractional amplitude ∼10−5. These four profound
observations lead inexorably to a description of the universe that began from a hot
big bang nearly 14 billion years ago. Remarkable progress over recent years in making
careful measurements of these features has led to a standard cosmology that involves
mostly classical physics and incorporates many of the ideas and techniques we have
discussed in the preceding 27 chapters.
Let us begin by describing the universe. We live on Earth, the “third rock” out from
an undistinguished star located in the outskirts of a quite ordinary galaxy—the sec-
ond largest in a loose federation of galaxies called the local group on the periphery of
the local supercluster.Our neighbors are no more remarkable. Meanwhile, the distant
galaxies and microwave background photons that we observe exhibit no preferred di-
rections. In short, we do not appear to be special, and nowhere else that we can see
appearstobespecial.Itisthereforereasonabletoassumethattheuniversehasno“cen-
ter” and that it is essentially homogeneous on the largest scales that we observe, so that
all parts are equivalent at the same time. By extension, the average observed properties
of the universe and its inferred history would be similar if we lived in any other galaxy.
However, it has long been known that the universe cannot also be inﬁnite and
static. If it were, then any line of sight would eventually intercept the surface of a star,
and the night sky would be bright. Instead, as we observe directly, galaxies and their
constituent stars are receding from us, and the speed of recession is now increasing
with time, contrary to our Newtonian expectation. This expansion is observed out to
distances that are so great that the recession velocities are relativistic, dimming the
light from the distant stars and galaxies, and making the night sky between nearby
1361

BOX 28.1.
READERS’ GUIDE
.
This chapter draws on every one of the preceding chapters:
– Chap. 1—geometry, tensors;
– Chap. 2—stress energy tensor, Lorentz invariance;
– Chap. 3—phase space, radiation thermodynamics, Liouville
equation, stars, Boltzmann equation;
– Chap. 4—entropy, Fermi-Dirac and Bose-Einstein
distribution functions, statistical mechanics in the presence
of gravity;
– Chap. 5—chemical potential, Monte Carlo method;
– Chap. 6—correlation functions and spectral density,
Wiener-Khintchine theorem, Fokker-Planck formalism;
– Chap. 7—paraxial optics, gravitational lenses, polarization;
– Chap. 8—Fourier transforms, point spread function;
– Chap. 9—coherence and random processes;
– Chap. 10—radiation physics, parametric resonance;
– Chap. 11—strain tensor, spherical coordinates;
– Chap. 12—longitudinal modes, zero point ﬂuctuations;
– Chap. 13—relativistic ﬂuids, stars;
– Chap. 14—barotropic equation of state, viscosity;
– Chap. 15—turbulence, power law spectrum;
– Chap. 16—sound waves, nonlinear waves;
– Chap. 17—compressible ﬂow, 1-dimensional ﬂow;
– Chap. 18—heat conduction;
– Chap. 19—nuclear reactions, magnetic stress tensor;
– Chap. 20—Saha equation, Coulomb collisions;
– Chap. 21—plasma oscillations, Debye screening;
– Chap. 22—Jeans’ theorem, collisionless particles, Landau
damping;
– Chap. 23—nonlinear wave dynamics, quantization of
classical ﬁelds, collisionless shocks;
– Chap. 24—differential geometry, local Lorentz frames;
– Chap. 25—Riemann tensor, Einstein equation, geodesic
deviation, geometrized units;
– Chap. 26—horizons, pressure as source of gravitation; and
– Chap. 27—gravitational time dilation, gravitational waves.
1362
Chapter 28. Cosmology

starsasdarkasweobserve.Furthermore, theamountofmatterintheuniverseinduces
gravitational potential differences of order c2 across the observed universe.
These features require a general relativistic description. However, even if we had
tested it adequately in the strong ﬁeld regime of black holes and neutron stars (which
we have only begun to do), there is no more guarantee that general relativity describes
the universe at large than that classical mechanics and electromagnetism sufﬁce to
describe atoms! Despite this, the best way to proceed is to continue to adopt general
relativity and be alert to the possibility that it could fail us. What we shall discover is
that it provides a sufﬁcient and successful framework for describing the observations.
The discovery of the CMB in 1964 transformed cosmology. This radiation must
havedominatedthestress-energytensorand, consequently, thegeometryanddynam-
ics of the universe in the past. More recently, it has been used to show that the spatial
curvature of the universe is very small and that the CMB’s tiny temperature ﬂuctua-
tions have simple behavior consistent with basic (mostly classical) physics. And the
ﬂuctuations can be used to argue that the universe exhibited a brief growth spurt,
called inﬂation, when it was very young—a surge that established both the observed
uniformity and the structure that we see around us today. No less important has been
the quantitative description, mostly developed over the past 20 years, of the two invis-
ible entities (popularly known as dark matter and the cosmological constant or, more
generally, dark energy) that account for 95% of the modern universe. In fact, the mea-
surements have become so good that most alternative descriptions of the universe
have been ruled out and no longer need to be discussed. This is a good time to beneﬁt
from this simpliﬁcation.
This chapter is longer, more ambitious, and less didactic—there are no practice
and derivation exercises—than its predecessors, because we want to take advantage
of the opportunity to exhibit modern classical physics in one of its most exciting
and currently successful applications. The reader must expect to read slowly and
carefully to “connect the dots.” To keep the chapter at a manageable length, we eschew
essentially all critical discussion of the observations and measurements, including
errors. We also avoid the idiosyncratic terminology and conventions of astronomy.
Finally, we stop short of describing the birth and development of galaxies, stars, and
planets, as these phenomenological investigations would take us too far away from
the direct application of general principles. Despite these limitations, it is striking how
much of what is known about the universe can be calculated with passable accuracy
using the ideas, principles, and techniques discussed in this book.
We begin in Sec. 28.2 by developing general relativistic cosmology, emphasizing
the geometry and the kinematics before turning to the dynamics. In Sec. 28.3, we
describe all the major constituents of the universe today and we follow this in Sec. 28.4
with a development of standard cosmology starting from when the temperature was
roughly 1011 K, distinguishing seven distinct ages. In Sec. 28.5, we develop a theory
to describe the growth of perturbations, which ultimately led to clustered galaxies.
Most of what we know about the universe comes from observing photons, and so in
28.1 Overview
1363

Sec. 28.6, we develop the cosmological optics that we need to draw inferences about
the birth and growth of the universe. In Sec. 28.7, we conclude by discussing three
foci of current research and incipient progress—attempts to understand the origin of
the universe, notably inﬂation, theories of the creation of dark matter and baryons,
and speculations about the fate of the universe involving the role of the cosmological
constant.
28.2
28.2 General Relativistic Cosmology
28.2.1
28.2.1 Isotropy and Homogeneity
We start by introducing galaxies and describing their distribution in space. A typ-
ical galaxy, like our own, comprises ∼1011 luminous stars (with a combined lu-
galaxies at a glance
minosity of ∼1037 W)1 and gas, mostly concentrated in a sphere of radius about
3 × 1020 m ∼10 kpc located at the center of a sphere about ten times larger domi-
nated by collisionless dark matter (Fig. 28.1). A typical galaxy mass is 1042 kg. There
is a large range in galaxy masses from less than a millionth of the mass of our galaxy
to more than a hundred times its mass.
Roughly a trillion galaxies can be seen over the whole sky (Fig. 28.1; Beckwith
distribution of galaxies
et al., 2006). Their distribution appears to be quite isotropic. We can estimate their
distances and study their spatial distribution. It is found that the galaxies are strongly
clustered on scales of <∼3 × 1023 m ∼10 Mpc. Especially prominent are clusters of
roughly a thousand galaxies. The strength of their relative clustering diminishes with
increasing linear scale to |δN/N| ∼10−5 when the scale size is comparable with
the “size” of the universe (which we will deﬁne more carefully below as ∼1026 m ∼
3 Gpc). Insofar as luminous galaxies fairly sample all material in the universe, it seems
that on large enough scales, we can regard the matter distribution today as quite
homogeneous.
An even more impressive demonstration of this uniformity comes from observa-
cosmic microwave
background
tions of the CMB (Fig. 28.1; Penzias and Wilson, 1965). Not only does it retain a
blackbody spectrum, the temperature ﬂuctuations are also only |δT/T | <∼3 × 10−5
on angular scales from radians to arcminutes. (There is a somewhat larger dipolar
component, but this is attributable to a Doppler shift caused by the compounded
motion of Earth, the Sun, and our galaxy.) This radiation has propagated to us from
an epoch when the universe was a thousand times smaller than it is today and, as we
shall demonstrate, the temperature was a thousand times greater, roughly 3,000 K.
If the universe were signiﬁcantly inhomogeneous at this time, then we would see
far larger ﬂuctuations in its temperature, spectrum, and polarization. We conclude
that the young universe was quite homogeneous, just like the contemporary universe
appears to be on the largest scales.
1.
For calibration, the Sun has a mass of 2.0 × 1030 kg and a luminosity of 3.9 × 1026 W. The standard
astronomical distance measure is 1 parsec (pc) = 3.1 × 1016 m.
1364
Chapter 28. Cosmology

(a)
(b)
(c)
(d)
–300
–200
–100
0
100
200
300
μK
FIGURE 28.1 Four astronomical images that illustrate recent discoveries about the universe. (a) Image
of the whole sky made by the Planck satellite, exhibiting ∼10 μK ﬂuctuations in the observed
∼3 K temperature of the CMB (Sec. 28.6.1; credit: Planck Collaboration, 2016a). These ﬂuctuations,
observed when the universe was ∼400,000 yr old, depict the seeds out of which grew the large
structures we see around us today. (b) The deepest image of the sky taken by Hubble Space Telescope,
roughly2 arcminacross(HubbleeXtremeDeepField, http://en.wikipedia.org/wiki/Hubble_eXtreme_
Deep_Field; credit: NASA; ESA; G. Illingworth, and the HUDF09 Team, 2013). The light from the
most distant galaxies in this image is estimated to have been emitted when the universe was only
∼0.08 of its present size and less than 500 Myr old (Sec. 28.4.5). (c) Combined ultraviolet and
infrared image of the Andromeda galaxy, the nearest large galaxy to our Milky Way galaxy. (Credit:
NASA/JPL-Caltech.) Orbiting hydrogen gas can be seen out to about ﬁve times the size of this image,
demonstrating that the stars we see form at the bottom of a large potential well of dark matter
(Sec. 28.2.1). (d) The Bullet cluster of galaxies. (Credit: X-ray: NASA/CXC/CfA/M. Markevitch et
al.; lensing map: NASA/STScI; ESO WFI; Magellan/University of Arizona/D. Clowe et al.; optical:
NASA/STScI; Magellan/University of Arizona/D. Clowe et al.) Two clusters, each containing roughly
several hundred galaxies, are in the process of merging. The hot gas, in red, can be traced by its X-ray
emission and is separated from the dark matter, in blue, which can be located by the weak gravitational
lensing distortion it imposes on the images of background galaxies (Sec. 28.6.2). The separation of
these concentrations of matter demonstrates that dark matter is effectively collisionless (Sec. 28.3.2).
28.2 General Relativistic Cosmology
1365

There is only one conceivable escape from this conclusion. We could live at the
origin of a spherically symmetric, radially inhomogeneous universe. The assumption
that this is not the case is sometimes known as the Copernican Principle by analogy
with the proposition that Earth is not at the center of the solar system. According
to this principle, the universe would look similarly isotropic from all other vantage
points at the same time. If one accepts this hypothesis, then isotropy about us and
aboutallotherpointsatthesametimeimplieshomogeneity.Thiscanbedemonstrated
formally.
These observational data justify a procedure in modeling the average universe,
which was adopted by Einstein (1917) and others with little more than philosophical
justiﬁcation in the early days of relativistic cosmology. Like Einstein, we assume, as
a zeroth order approximation, that the universe is homogeneous and isotropic at a
homogeneous and
isotropic universe
given time. This can be stated more carefully as follows. There exists a family of slices of
simultaneity (3-dimensional spacelike hypersurfaces; Fig. 28.2), which completely covers
spacetime, with the special property that on a given slice of simultaneity (i) no two points
are distinguishable from each other (homogeneity) and (ii) at a given point no one spatial
direction is distinguishable from any other (isotropy).
So, how do we assign these slices of simultaneity? Fortunately, the universe comes
with a clock, the temperature of the CMB. (For the moment, ignore the tiny ﬂuctua-
tions.) We then introduce a set of imaginary fundamental observers (FOs; Fig. 28.2)
fundamental observers
and give them the velocity that removes the dipole anisotropy in the temperature dis-
tribution.2 (Henceforth when we talk about observations at Earth, we imagine that
these are observations made by an FO coincident with Earth today. To get the actual
Earth-based observations, we just add a small Doppler shift to these FO observa-
tions.) These FOs individually move on world lines that keep the CMB isotropic. We
regard the 3-dimensional hypersurfaces that they inhabit when they all measure the
same CMB temperature as spaces in their own right, which we approximate as homo-
geneous. Isotropy guarantees that the FO world lines are orthogonal to these “slices
of simultaneity.” Let us focus on the hypersurface that we inhabit today, formed by
freezing the action when everyone measures the CMB temperature to be 2.725 K.
28.2.2
28.2.2 Geometry
METRIC TENSOR
We want to explore the geometry of this frozen, 3-dimensional space.3 Our ﬁrst
task is to deduce the form of its metric tensor. Introduce a spherical coordinate
system {χ, θ, φ}, centered on us. Here χ is the radius, the proper distance (mea-
spatial coordinates
sured by a rather large number of meter rules) from us to a distant point; θ, φ
are spherical polar angles, measured from Earth’s north pole and the direction of
2.
Roughly 360 km s−1 for Earth.
3.
For a fuller treatment see, e.g., Misner, Thorne, and Wheeler (1973), Sec. 27.6 and Box 27.2.
1366
Chapter 28. Cosmology

t = 2
t = 1
t = 0
world line of
fundamental observer 
χ1 = 1
χ1 = 1
χ1 = 1
χ2 = 3
χ2 = 3
χ2 = 3
FIGURE 28.2 The slices of simultaneity, world lines of
fundamental observers, and synchronous coordinate
system for a homogeneous, isotropic model of the
universe.
the Sun at the vernal equinox, for example.4 We will also ﬁnd it convenient to in-
troduce an equivalent Cartesian coordinate system (Fig. 28.2): χ ≡{χ1, χ2, χ3} =
{χ sin θ cos φ, χ sin θ sin φ, χ cos θ}. We know that the space around us is isotropic,
which implies that the angular part of the metric is dθ2 + sin2 θdφ2 at each radius.5
However, we cannot assume that the space is globally ﬂat and that the area of a sphere
of constant radius χ is 4πχ2. Therefore, we generalize the metric to become
(3)ds2 = dχ2 + 2(dθ2 + sin2 θdφ2),
(28.1)
where (χ) is a function to be determined. Now we know that  ≃χ for small χ to
satisfy the requirement that space be locally ﬂat.
HOMOGENEOUS 2-DIMENSIONAL SPACES
Restrict attention to the 2-dimensional subspace φ = const, which has metric
(2)ds2 = dχ2 + 2(χ)dθ2, and consider a curve with θ = 0 emanating from us at
point O. This is obviously a geodesic—the shortest distance between its start at O
and any point we care to choose along it. Let this geodesic pass through two galaxies
labeled A, B and end at a third galaxy C (Fig. 28.3). Let the proper distances from
O to A, A to B, and B to C, be χ1, χ2, χ3, respectively. Now add a second geodesic,
also emanating from O, and inclined to the ﬁrst geodesic by a small angle θ.6 As θ is
4.
This is how astronomers set up their equivalent “right ascension”–“declination” coordinate system.
5.
The deep, underlying reason it is not possible to cover the surface of a sphere with a metric with constant
coefﬁcientsisthatthevectorﬁeld(∂/∂φ)θ thatgeneratesrotationsaboutthepolaraxisdoesnotcommute
withthevectorﬁeldthatgeneratesrotationsaboutanyotheraxis.Inprinciple, wecouldrotateourangular
coordinate system from one radius to the next, but this would hide the symmetry that we are so eager
to exploit!
6.
This is similar in spirit to the description of gravitational lensing in Sec. 7.6.
28.2 General Relativistic Cosmology
1367

O
A
χ1
χ2
χ3
ηA
ηB
ηC
ψ
ζ
θ
B
C
FIGURE 28.3 Geodesics in a homogeneous 2-dimensional space. We suppose that the angles θ, ψ, ζ
are small and compute the transverse displacements η assuming the metric (28.1).
small, the proper separations of these geodesics (measured along short paths perpen-
dicular to the ﬁrst geodesic at A, B, and C) will be ηA = θ(χ1), ηB = θ(χ1 + χ2),
ηC = θ(χ1 + χ2 + χ3), respectively, ignoring terms O(θ3), which will vanish in the
limit θ →0. Next, introduce a third geodesic backward from C and intersecting with
the second geodesic, at a point a perpendicular distance ηA from galaxy A. Denote
the (small) angle it makes with the ﬁrst geodesic at C to be ψ and with the second
geodesic near A to be ζ.
Now, by assumption, the metric must have the same form, with the same metric
derivation of metric tensor
function (χ) when the origin is at O, A, or C. We can use this to derive a functional
relationship that must be satisﬁed by (χ) by evaluating ηB in two different ways:
ηB = θ(χ1 + χ2) = ψ(χ3) + ζ(χ2)
= θ
(χ3)(χ1)
(χ2 + χ3) + (χ2)(χ1 + χ2 + χ3)
(χ2 + χ3)

.
(28.2)
(In the last equality, we have used elementary geometry to express ψ and ζ in terms
of θ.) Rearranging, we obtain
(χ1 + χ2)(χ2 + χ3) = (χ1)(χ3) + (χ1 + χ2 + χ3)(χ2),
(28.3)
for all choices of χ1, χ2, χ3.7
This sort of nonlocal, functional relationship is probably quite unfamiliar and, in
general, such equations are hard to solve. However, in this instance we can use the
device of solving it in a special case and then showing that the solution satisﬁes the
original equation. If we assume that χ1 and χ3 are equal and small, and we expand
Eq. (28.3) to second order in χ1 with χ2 ≡χ ﬁnite, we ﬁnd that
′′ −′2 + 1 = 0.
(28.4)
Next, multiply the left-hand side by 2′/3, and note that it is the derivative of
(′2 −1)/2. Hence, we get
′2 + K2 −1 = 0,
(28.5)
7.
The well-educated reader may notice a similarity to Ptolemy’s theorem. The comparison is instructive.
1368
Chapter 28. Cosmology

where the integration constant K is known as the Gaussian curvature of the 2-
Gaussian curvature KKK
dimensional surface, or equivalently, half the scalar curvature (Sec. 25.6). Differ-
entiating this equation leads to the simple harmonic equation
′′ + K = 0.
(28.6)
We need solutions that will be locally Euclidean with (0) = 0, ′(0) = 1.
Therearethreecases.IfK = 0, then = χ.IfK ispositive, wewriteitasK = R−2,
where R is the radius of curvature and (χ) = R sin(χ/R). If K < 0, we write it as
K = −R−2 and (χ) = R sinh(χ/R). The ﬁnal step is to verify that these solutions
are valid for general χ1, χ2, χ3, which they are. We have therefore found three general
solutions to the functional equation (28.3). Suppose that there were an additional
solution. We could subject it to the same limiting procedure and recover the same
nonlinear differential equation (28.4) as χ1 = χ3 →0 for all χ2 = χ. However, we
know all the locally Euclidean solutions (χ) to this equation, and our hypothetical
fourth solution would not be among them. Therefore, it cannot exist, and so we have
found all possible distance relations for homogeneous 2-dimensional spaces.
We summarize these three solutions by introducing a parameter k = ±1 or 0:
K = k/R2;
 = R sin(χ/R) for k = +1, χ for k = 0, R sinh(χ/R) for k = −1.
(28.7)
NON-EUCLIDEAN GEOMETRIES
The K = 0 solution is instantly recognizable as describing the geometry of ﬂat, Eu-
clidean space. The K > 0 solution describes the 2-dimensional surface of a sphere
homogeneous positive
curvature space
embedded in 3-dimensional ﬂat space. The circumference of a circle of radius χ is
2πR sin(χ/R) < 2πχ and vanishes at an antipodal point, where χ = πR. The space
has a natural end—we call it closed.The associated area of this space is 2π
 πR
0
dχ =
4πR2. The geodesics we have been using are simply “great circles” on the 2-sphere.8
The theorems of spherical trigonometry, which we could have gone on to prove, are
familiar to navigators, astronomers, and crystallographers.
When K < 0, the circumference is 2πR sinh(χ/R) > 2πχ and the area is un-
homogeneous negative
curvature space
bounded, so the space is open. This 2-dimensional space cannot be embedded in 3-
dimensional Euclidean space. This discovery, made independently in the nineteenth
century by Bolyai, Gauss, and Lobachevsky, was a source of mathematical wonder and
philosophical consternation.9
8.
To go from the skinny triangles we have been considering so far to large values of η, we need to construct
the geodesic χ(θ) by minimizing the length

dθ(χ′2 + 2)1/2 of the curve connecting the endpoints.
This is a standard exercise in the calculus of variations, and carrying it out opens the door to deriving
counterparts to the theorems of Euclidean geometry for non-Euclidean spaces.
9.
This hyperbolic geometry can be embedded in 3-dimensional Minkowski space, and we could have used
our understanding of special relativity to explore it by analogy with what is done with the positively
curved space. Had we done so, we would have discovered that it is the same as the mass hyperboloid
depicted in Fig. 3.2. However, the spirit of Riemannian geometry is not to do this but instead to explore
the space through its inner properties.
28.2 General Relativistic Cosmology
1369

HOMOGENEOUS 3-DIMENSIONAL SPACES
The generalization to 3 dimensions is straightforward. If space is isotropic, then
the geometrical statements we made about the subspace φ =const must be true
about any 2-dimensional subspace; so we arrive at the same three possibilities for
 in the 3-dimensional metric (28.1). We replace the circumference of a circle by
the area of a sphere of radius χ, which is less than (more than) 4πχ2 for positive
(negative) curvature. The total volume of the positively curved, closed 3-space is
4π
 πR
0
dχ2 = 2π2R3.10
ROBERTSON-WALKER METRIC
Relativistic cosmology is transacted in spacetime, not space (Sec. 25.2). How do we
generalize our understanding of these homogeneous subspaces to include a time
coordinate and allow for the expansion of the universe? The ﬁrst step is to assume
that the 3-spaces in the past were also homogeneous and so had the same geometry
as today. The only thing that can change is the radius of curvature, and so we write
scale factor
R(t) = a(t)R0,
(28.8)
where R0 is its value today when t = t0 and a = 1. We call a(t) the scale factor. (We
handle a ﬂat space by taking the limit R0 →∞.) An FO then moves from one spatial
hypersurface to the next carrying the same spherical coordinates {χ, θ, φ} (Fig. 28.2).
We call these three coordinates comoving coordinates.
comoving coordinates
The basis vector ∂t ≡∂/∂t is tangent to the world line of an FO, which is orthog-
onal to the spatial hypersurface t = const. Thus, gti ≡∂t . ∂i = 0.11 Next consider gtt.
We have so far implicitly measured time using the temperature of the CMB, but as
we want to be quantitative, we choose as a time coordinate the proper time (or cosmic
time or simply, time) t that elapses, as measured by a clock carried by an exceedingly
patient FO with uα = (1, 0, 0, 0), from one hypersurface to the next. (We set c = 1in
all subsequent equations.) It is implicit in the assumption of homogeneity that this
interval of time will be the same for all FOs, and we can add up all the intervals to
make our time coordinate t the total age of the universe since the big bang. With this
time coordinate
choice, gtt = −1.12
10. Although homogeneity and isotropy force the cosmological model’s hypersurfaces to have one of the
three metrics we have described, the topologies of those hypersurfaces need not be the obvious ones
adopted here. For example, a ﬂat model could have a closed topology with ﬁnite volume rather than
an open topology with inﬁnite volume. This could come about in much the same way as a ﬂat piece of
paper can be rolled into a cylinder. The geometry is still Euclidean, but one of the two coordinates, say
x, is identiﬁed with x + C, where C is the length of the circumference of the cylinder. In 3 dimensions
we can make similar identiﬁcations for the y and z coordinates. There are no credible observations to
suggest that the universe is like this, but the possibility is worth keeping in mind.
11. Such a coordinate system is termed synchronous.
12. Other time coordinates, such as conformal time,

dt/a, are in common use for a variety of technical
reasons, but we shall eschew these.
1370
Chapter 28. Cosmology

Our full metric is then
ds2 = −dt2 + a(t)2[dχ2 + 2(dθ2 + sin2 θdφ2)].
(28.9)
This is known as the Robertson-Walker metric.13 Using this metric, we can easily verify
that the acceleration ∇⃗u⃗u of an FO vanishes, so FOs with ﬁxed χ follow geodesics.
The scale factor a(t) is very important. Not only does it measure the size of the
meaning of a(t)
a(t)
a(t)
universe in the past, it also measures the separation of any two FOs as a fraction
of their separation today. Insofar as the universe is well described as homogeneous
and isotropic, this single function tells us all we need to know about how the uni-
verse expanded and how it will continue to expand. We shall use it—actually, its
logarithm—as our independent variable, because physical quantities such as densi-
ties and temperatures scale simply with it and because it is closely related to what
astronomers commonly measure. Measuring t(a) is the kinematic challenge to ob-
servational cosmology; explaining it is the dynamical challenge to general relativity.
EINSTEIN TENSOR
Our ﬁnal geometrical task is to calculate the Einstein tensor (Sec. 25.8). Although
the calculation can be simpliﬁed by exploiting symmetry, it is best to use computer
algebra. The only nonzero elements are
components of Einstein
tensor in orthonormal
basis
Gˆt ˆt = −Gt
t = −2′′ + ′2 −32˙a2 −1
2a2
,
G ˆχ ˆχ = Gχ
χ = ′2 −2(2¨aa + ˙a2) −1
2a2
,
G ˆθ ˆθ = Gθ
θ = G ˆφ ˆφ = Gφ
φ = ′′ −(2¨aa + ˙a2)
a2
.
(28.10)
Here each dot or prime denotes a derivative with respect to t or χ; the hatted com-
ponents are in the proper reference frame of an FO [with orthonormal basis vectors
⃗eˆt = ∂t, ⃗e ˆχ = a−1∂χ, ⃗e ˆθ = (a)−1∂θ, ⃗e ˆφ = (a sin θ)−1∂φ; cf. the metric (28.9)]; the
unhatted components are those of the coordinate basis. The mixed-coordinate com-
ponents (one index up, the other down) are the easiest to evaluate mathematically,
but the orthonormal components are the best for physical interpretation, since they
are what an FO measures. The two sets of components are equal up to a sign, because
the metric is diagonal.
13. Historically, thethreepossiblechoicesforthegeometryofahomogeneous, isotropiccosmologicalmodel
were discovered by the Russian meteorologist Alexander Friedmann (1922). These solutions were found
independently by a Belgian priest, Georges Lemaˆıtre (1927), who included a cosmological constant and
discussed the growth of perturbations. The ﬁrst proof that these three choices are the only possibilities
was due to Robertson (1935, 1936a,b) and Walker (1935).
28.2 General Relativistic Cosmology
1371

If we now substitute our geometrical conditions (28.4) and (28.5) with K = kR−2
0
inclusion of geometry
[Eqs. (28.7) and (28.8)], we obtain
Gˆt ˆt = 3 ˙a2 + kR−2
0
a2
, G ˆχ ˆχ = G ˆθ ˆθ = G ˆφ ˆφ = −2¨aa + ˙a2 + kR−2
0
a2
.
(28.11)
Note that the spatial part of the Einstein tensor is proportional to the 3-metric
gˆi ˆj = δij. In other words, it is isotropic, as we expect.
EXERCISES
Exercise 28.1 Example: Alternative Derivation of the Spatial Metric
Not surprisingly, there are several other approaches to deriving the possible forms of
(χ).14 Another derivation exploits the symmetries of the Riemann tensor.
(a) The 3-dimensional Riemann curvature tensor of the hypersurface must be ho-
mogeneous and isotropic. Explain why it should therefore only involve the metric
tensor and not any other tensor, for example, not the Levi-Civita tensor.
(b) Show that the only combination of these quantities that exhibits the full symmetry
properties of the Riemann tensor is
(3)Rijkl = K(gikgjl −gilgjk),
(28.12)
where K is a constant.
(c) Write a computer algebra routine to evaluate the Riemann tensor from the metric
tensor (28.1) directly. By equating it to Eq. (28.12), show that two differential
equations must be satisﬁed and these are identical to Eqs. (28.5) and (28.6).
(d) Compute the Ricci tensor, and compare it with the metric tensor. Comment.
Exercise 28.2 Problem: Area of a Spherical Triangle
Consider the triangle formed by the three geodesics in Fig. 28.3. In a ﬂat space,
the exterior angle ζ must equal θ + ψ. However, if the space is homogeneous and
positively curved, then the angle deﬁcit  ≡θ + ψ −ζ will be positive.
(a) By considering the geometry of the 2-dimensional surface of a sphere embedded
in 3-dimensional Euclidean space, show that the area of the triangle is /K.
[Hint: We know that the area of a lune lying between two lines of longitude
separated by an angle φ is 2φ/K.]
(b) Make a conjecture (or, better still, devise a demonstration) as to the formula for
the area of a triangle in a negatively curved homogeneous space.
These results are special cases of the famous Gauss-Bonnet theorem,15 which allows
for the possibility that the topology of the space might not be simple.
14. For example, there is an elegant, group-theoretic approach (e.g., Ryan and Shepley, 1975).
15. See, e.g., Peacock (1999) and Carroll (2004).
1372
Chapter 28. Cosmology

28.2.3
28.2.3 Kinematics
RAYS AND WORLD LINES
We are interested in events which lie at the intersection of our past light cone and
the world lines of other FOs. Imagine a single wavelength of light emitted in the χ
direction at time te. Let there be two FOs at either end of the wavelength, and let
their comoving radii be χe and χe + dχe. Their physical separation at the time of
emission is λe, the emitted wavelength. Their separation in terms of the comoving
coordinate is therefore dχ = λe/a(te). Let the light be observed by us today. Let the
front of the wavelength be observed at time t0 and the end of the wavelength at t0 + P0,
where P0 is the observed period. Using the metric (28.9) with ds = dθ = dφ = 0, we
see that χe =
 t0
te dt/a and χe + λe/a(te) =
 t0+P0
te
dt/a, from which we deduce that
λe/a(te) = Pe/a(te) = P0 or in terms of the frequencies, ν0 = a(te)νe.16 Put another
cosmological redshift
way, as a photon crosses the universe, its frequency, as measured by the FOs, satisﬁes
ν ∝a−1. So, if we observe a spectral line that was emitted by the stars in a distant
galaxy with frequency νe and we observe it today with frequency ν0, then we can
deduce immediately that the scale factor a at the time of emission was ν0/νe. The ﬁrst
stars and galaxies to form, and therefore the most distant ones that we can see, emitted
their light when a ∼0.1, so that a Lyman α spectral line of hydrogen emitted with a
wavelength of λe = 122 nm is observed in the infrared today with λ0 ∼1.2 μm.
THERMODYNAMICS
Construct a small, imaginary sphere around us with radius χ and let the sphere’s
surface be carried by a population of FOs, so it comoves and expands with them.
Theseobserverseachseeisotropicblackbodyradiation.Everytimeaphotonleavesthe
sphere, it will be replaced, on average, by an entering photon. The FOs could therefore
construct a spherical mirror, perfectly reﬂecting on both sides and expanding with the
universe. Nothing would change. The radiation inside this sphere will undergo slow
adiabatic expansion. If it starts off as thermal blackbody radiation, it will remain so.
The blackbody temperature Tγ, photon number density nγ, pressure Pγ, and energy
density ργ will therefore vary as (cf. Secs. 3.2.4 and 3.5.5)
radiation in an expanding
universe
Tγ ∝a−1;
nγ ∝a−3;
ργ , Pγ ∝a−4 ∝n4/3
γ ,
(28.13)
and the speciﬁc heat ratio is 4/3. If the radiation is isotropic but not blackbody,
its distribution function ηγ(p, a) will not change along a trajectory in phase space
(Sec. 3.6), and so ηγ(p′, a′) = ηγ(p = p′a′/a, a). Here p = |p| is the magnitude of
the photon’s momentum, or equally well its energy E = p.
By parallel arguments, the individual momenta p of massive particles vary as
p ∝a−1—their de Broglie wavelengths expand with the universe just like photon
16. This argument neatly avoids a generally unhelpful separation into the Doppler shift and gravitational
redshift. The quantity redshift, z = (νe −ν0)/ν0 = 1/a −1, is in common use by astronomers. However,
we shall continue to work with the scale factor a(t), as we are focusing on the kinematics of the expansion
and not the observations through which this has been inferred.
28.2 General Relativistic Cosmology
1373

wavelengths—so long as their behavior is adiabatic. When nonrelativistic, their ki-
netic energies and temperatures vary according to T ∝p2 ∝a−2, and their pressure
gas in an expanding
universe
P scales with their number density n as P ∝nT ∝a−5 ∝n5/3, recovering the familiar
speciﬁc heat ratio for a monatomic gas.
EXPANSION, DECELERATION, AND JERK
The kinematic behavior of the homogeneous universe is fully described by the single
kinematics of the
expansion
function a(t). Not surprisingly, its derivatives turn out to be very useful. Adopting
standard (if archaic) conventions, we deﬁne the expansion rate H(t), the deceleration
function q(t), and the jerk function j(t) by
expansion rate HHH,
deceleration qqq and jerk jjj
H = ˙a
a ≡

dt
d ln a
−1
,
q = −¨aa
˙a2 ,
j =
˙˙˙aa2
˙a3 ,
(28.14)
respectively. Note that H −1 = dt/d ln a converts a derivative with respect to time
(denoted with a dot) to a derivative with respect to ln a (denoted with a prime), which
is our preferred independent variable. The expansion rate H is a reciprocal time; q
and j are dimensionless. A galaxy at small radius χ emitted its photons when the scale
factor was a ≃1 −χ ˙a, and so the shift in the wavelengths of spectral lines observed
on Earth will satisfy to ﬁrst order δλ/λ ≡v = ˙aχ ≡H0χ,17 where v is the inferred
recession speed, and the Hubble constant18 H0 ≡H(t0) is the contemporary value of
Hubble constant H0
H0
H0
H and is one of the key parameters of observational cosmology. It measures the age
and size of the universe. We now know that the universe is accelerating q0 ≡q(t0) < 0
and j0 ≡j(t0) > 0 (Riess et al., 1998; Perlmutter et al., 1999).
DISTANCE MEASUREMENT
There are two common measures of distance in cosmology. The ﬁrst is based on
observing a small source of known physical size, η, perpendicular to the line of sight
at radius χ. The source’s angular size measured at Earth will be θ = η/(a) (Fig. 28.3,
angular diameter distance
dA
dA
dA
where O at χ = 0 is Earth’s location). This motivates us to deﬁne the angular diameter
distance dA ≡a.
The second measure is based on an isotropic source of known luminosity L. If the
universe were ﬂat and static, the source’s measured ﬂux would be F = L/(4πχ2).
Relativistic cosmology introduces three modiﬁcations. First, the area of a sphere
centered on the source with comoving radius χ, at the time of observation (today),
is 4π(χ)2. Second, the source emits photons, and their individual energies hν as
observed at O will be reduced by a factor a from their energies when emitted. Third,
17. The quantity χ must be large enough for the recession speed to exceed the random motion with respect
to a local FO.
18. The Hubble “law,” that the recession velocity is proportional to the distance, was published in 1929
by Edwin Hubble, following theory by Lemaˆıtre and observations by himself, Slipher, and others. It
providedtheﬁrstcompellingdemonstrationthattheuniversewasexpanding, althoughHubble’sinferred
constant of proportionality, H0 ∼500 km s−1Mpc−1, was over seven times larger than the contemporary
measurement.
1374
Chapter 28. Cosmology

the time it takes to emit a ﬁxed number of photons will be shorter by another factor a
than the time it takes these same photons to pass the observer on Earth. The ﬂux will
therefore be modiﬁed to F = a2L/(4π2). This motivates us to deﬁne a luminosity
luminosity distance dL
dL
dL
distance dL = /a = a−2dA.
Making cosmological distance measurements is challenging. There are many as-
tronomicalcandidatesforsourcesofknownsizeorluminosityforuseinmeasuringdA
or dL. However, they should all be greeted with suspicion, as it is not just the universe
that evolves with time; its contents can likewise change. The most natural distance
measures use variable and exploding stars. As we discuss below, statistical measures
in the CMB and distribution of galaxies as well as gravitational lenses are also impor-
tant. Many methods are anchored by local trigonometric surveys. Inevitably, there
are systematic errors (inaccuracy), which are now more limiting than random er-
ror (imprecision). Remarkably, the spread in measurements of H0 has been reduced
measurement of H0
H0
H0
to roughly 10%. For speciﬁcity, we shall use cosmological parameters from Planck
Collaboration (2016b), starting with H0 = 67.7 km s−1 Mpc−1 ≡(4.56 × 1017 s)−1 ≡
(14.4 Gyr)−1 ≡(1.37 × 1026 m)−1 ≡(4.43 Gpc)−1.
HORIZON
The ﬁnal kinematic quantity we introduce is the horizon19 radius χH(t) of the event
horizon radius χH
χH
χH
on our past world line at time t. This is the comoving radius of a sphere, centered on
a point on our past world line, that contains the region of the universe that can have
sent signals to the event since the big bang. We also ﬁnd it useful to introduce the
acoustic horizon radius χA = C/˙a. This is the comoving distance a sound wave can
acoustic horizon radius χA
χA
χA
travel at the local sound speed C during one expansion time scale a/˙a = H −1:
χH(t) =
 t
0
dt′
a(t′) =
 a(t)
0
da′
a′2H(a′); χA = C
˙a .
(28.15)
When the ﬂuid is ultrarelativistic, C is simply 3−1/2 and χA ≡χR = 3−1/2H −1.
EXERCISES
Exercise 28.3 Example: Mildly Relativistic Particles
Suppose that the universe contained a signiﬁcant component in the form of isotropic
but noninteracting particles with momentum p and rest mass m. Suppose that they
were created with a distribution function f (p, a) ∝p−q, with 4 < q < 5 extending
from p ≪m to p ≫m (Sec. 3.5.3).
(a) Show that the pressure and the internal energy density (not including rest mass)
of these particles are both well deﬁned.
(b) Show that the adiabatic index of this component is q/3and interpret your answer.
(c) Explain how P and ρ for this component should vary with the scale factor a.
19. Or more properly the particle horizon, to distinguish it from an event horizon (Sec. 26.4.5).
28.2 General Relativistic Cosmology
1375

Exercise 28.4 Problem: Observations of the Luminosity Distance
Astronomers ﬁnd it convenient to use the redshift z = 1/a −1to measure the size of
the universe when the light they observed was emitted.
(a) Perform a Taylor expansion in z to show that the luminosity distance of a source
is given to quadratic order by
dL = H −1
0 [z + 1/2(1 −q0)z2 + . . .].
(b) The cubic term in this expansion involves the curvature K0 and the jerk j0 today.
Calculate it.
28.2.4
28.2.4 Dynamics
FRIEDMANN EQUATIONS
Ultimately, we must understand how the universe’s individual constituents—matter,
photons, neutrinos—behave and interact. However, for the initial purposes of provid-
ing an idealized description of the average contents of the universe that can match our
idealized description of its geometry and kinematics, we approximate everything as
a homogeneous perfect ﬂuid at rest in the FOs’ proper reference frame, with pressure
T ˆχ ˆχ = T ˆθ ˆθ = T ˆφ ˆφ = P (Sec. 2.13). This is related to the Einstein tensor through the
Einstein ﬁeld equation (Sec. 25.8). We start with the time-time part and employ ge-
ometrizedunits(Sec.25.8.1):Gˆt ˆt = 8πT ˆt ˆt, whichbecomes, withtheaidofEq.(28.11):
equation of motion
˙a2 = 8π
3 ρa2 −k
R2
0
.
(28.16)
This equation of motion is the foundation of relativistic cosmology. It relates the
universe’s expansion rate ˙a to its mean mass-energy density ρ and curvature k/R2
0.
It is illuminating to write Eq. (28.16) in the form
1
2(˙aχ)2 −4πρ(aχ)3
3(aχ)
= −kχ2
2R2
0
= const,
(28.17)
for ﬁxed χ. Again imagine that we are at the center of a small, imaginary, expand-
ing sphere of radius aχ carried by FOs. We can regard the ﬁrst term as the kinetic
energy of a unit mass resting on the surface of the sphere and the second as its New-
tonian gravitational potential energy. So this looks just like an equation of Newtonian
energy conservation. Could we not have written it down without recourse to gen-
inadequacy of Newtonian
treatment
eral relativity? The answer is “No.” Equation (28.16) addresses three crucial issues on
which Newtonian cosmology must remain silent. First, it neatly handles the inﬂuence
of the exterior matter. Second, it relates the total energy of the expansion, the right-
hand side of Eq. (28.17), to the spatial curvature. Third, it has taken account of the
pressure, which as we saw with neutron stars [(Eqs. 26.38)], can contribute an ac-
tive gravitational mass. The absence of pressure in Eq. (28.16) is correct but does not
1376
Chapter 28. Cosmology

have a simple Newtonian explanation. These three features demonstrate the power of
general relativistic cosmology and the inadequacy of a purely Newtonian approach.
Next, consider the spatial part of the Einstein equation Gˆi ˆj = 8πT ˆi ˆj = 8πP δˆi ˆj.
With the aid of Eqs. (28.11) and (28.16), this gives a second-order differential
equation:
cosmic acceleration
¨a = −4π
3 (ρ + 3P )a.
(28.18)
The divergence of the stress-energy tensor must vanish. We have seen many times
in this book [Ex. 2.26, Eqs. (13.86), Secs. 13.8.1, 26.3.3] that for any perfect ﬂuid, in
the ﬂuid’s rest frame (which for cosmology is the same as the FO rest frame), the
time component T ˆt ˆα;ˆα = 0 is energy conservation, or equivalently, the ﬁrst law of
thermodynamics.Foraﬂuidelementwithunitcomovingvolume, thephysicalvolume
is a3, so the ﬁrst law states
ﬁrst law of
thermodynamics
d(ρa3) = −P d(a3).
(28.19)
If the ﬂuid comprises two or more independent components that do not exchange
heat and evolve separately, then Eq. (28.19) must apply to each component.
We have also seen many times [Ex. 2.26, Eqs. (13.86), Sec. 26.3.3] that in the
ﬂuid’s rest frame, the spatial component T ˆi ˆα; ˆα = 0 is force balance; it equates
the ﬂuid’s pressure gradient ∇P to its inertial mass per unit volume (ρ + P ) times
its 4-acceleration. However, homogeneity and isotropy guarantee that in our cosmo-
logical situation, the ﬂuid’s pressure gradient and 4-acceleration vanish, so T ˆi ˆα; ˆα = 0
is satisﬁed identically and automatically. It teaches us nothing new.
Equations (28.16), (28.18), and (28.19) are called the Friedmann equations in
honor of Alexander Friedmann. They are not independent; the contracted Bianchi
identity guarantees that from any two of them, one can deduce the third (Sec. 25.8).
CRITICAL DENSITY
Not only does the Hubble constant deﬁne a scale of length and of time, it also deﬁnes
a critical density, ρcr—the value of ρ for which the universe’s spatial curvature K =
k/R2
0 vanishes today [Eqs. (28.16) and (28.14)]:
ρcr = 3H 2
0
8π = 8.6 × 10−27 kg m−3 ≡7.7 × 10−10 J m−3.
(28.20)
It is conventional to express the energy density of constituent i today (e.g., radia-
density fraction
tion or baryonic matter) as a fraction by introducing
i = ρi
ρcr
;
 = ρ
ρcr
=
 
i
i = 1 −k,
(28.21)
where  refers to the total energy density, and
k = −
k
H 2
0R2
0
(28.22)
takes account of curvature.
28.2 General Relativistic Cosmology
1377

The kinematic quantities, H, q, j [Eq. (28.14)] are then given by
expansion rate,
deceleration function,
and jerk function
H = H0
 ρ
ρcr
+ k
a2
1/2
;
q = 1
2
ρ + 3P
ρ + kρcr
a2
;
j = ρ −3
2
dP
d ln a
ρ + kρcr
a2
,
(28.23)
respectively.Notethatifthecurvatureisnegligible, q = 1
2 whenP = 0andj = 1when
P is constant.
A FLAT UNIVERSE
At this point we introduce a key simpliﬁcation. Essentially geometrical arguments,
based largely on observations of CMB ﬂuctuations, have shown that the radius of
curvature today is |R0| >∼14/H0. Equivalently, k <∼0.005. This is so small, and was
even smaller in the past (when we replace R0 by R) that henceforth we shall set k = 0
and  = χ. If signiﬁcant spatial curvature is measured one day, then small corrections
will be required to what follows, while the principles are unaffected. However, none
of this absolves us from the obligation to explain why the universe is so ﬂat, an issue
to which we shall return in Sec. 28.7.1.
SUMMARY
We have described an idealized universe that is homogeneous and isotropic every-
where. We have shown its spatial geometry can take one of three different forms and
have invoked observation to restrict attention to the spatially ﬂat case. We have also
introduced some useful cosmological measures, most notably the scale factor a(t), to
characterize the kinematics of the universe. We have married the universe’s geometry
to its kinematics to calculate the two independent components of the Einstein tensor,
which we then combined with the volume-averaged stress-energy tensor of the con-
tents of the universe to derive the Friedmann equations. We now turn to cataloging
the contributions to the stress-energy tensor today.
EXERCISES
Exercise 28.5 Example: Einstein–de Sitter Universe
Suppose, as was once thought to be the case, that the universe today is ﬂat and
dominated by cold (pressure-free) matter.
(a) Show that a ∝t2/3 and evaluate the age of the universe assuming the Hubble
constant given in Sec. 28.2.3: H0 = 67.7 km s−1 Mpc−1.
(b) Evaluate an expression for the angular diameter distance as a function of a and
ﬁnd its maximum value.
(c) Calculate the comoving volume within the universe back to very early times.
1378
Chapter 28. Cosmology

28.3
28.3 The Universe Today
28.3.1
28.3.1 Baryons
Among all the constituents in our universe, baryonic matter is the easiest form to
identify, because it is capable of radiating when hot and absorbing when cool. The
baryons from the very early universe are mostly in the form of hydrogen, with mass
fraction0.75, andhelium, withmassfraction0.25 ≡YHe.Someofthesebaryonsfound
their way into stars, which produced more helium and created about 1% by mass, on
stars at a glance
average, of heavier elements. Stars have masses ranging from a tenth to more than 100
times that of the Sun. The most massive stars shine for roughly a million years, while
the least massive ones will last more than a trillion years, much longer than the age of
the universe.
Very roughly 10−4 of the total mass of a typical galaxy is found in a massive,
spinning black hole residing in its nucleus. When this black hole is supplied with
gas, roughly 10% of the rest mass energy of this gas is converted into radiation. The
galaxy is then said to have an active galactic nucleus, and when this outshines the entire
active galactic nuclei and
quasars
galaxy, it is called a quasar.
It is common practice to use the luminosity of a galaxy as a measure of its stellar
mass. However, this must be done with care, because the answer depends on the
relative proportions of low- and high-mass stars. The latter are far more luminous per
unit mass. It also depends on the time that has elapsed since the stars were formed. If
the stars are old, the luminous high-mass ones will have consumed all their nuclear
fuel and evolved to form neutron stars and black holes. Absorption is also an issue.
Despite all these difﬁculties, astronomers estimate that the average fraction of stellar
mass today is ∗∼0.005.
The baryons that are not contained in stars exist as gas. We can assay this gas
fraction by measuring the X-ray emission from clusters of galaxies and ﬁnd that
gas ∼0.05. More accurate measurements of the total baryon fraction b are made
measuring b
b
b
possible by measuring the tiny fraction of deuterium and other light elements that
are created in trace amounts in the early universe (Sec. 28.4.2) and through inter-
preting the spectrum of CMB ﬂuctuations (Sec. 28.6.1). The best estimate today is
b = 0.049, implying that the mean energy and number densities of baryons in the
universe are ρb0 = 3.8 × 10−11 J m−3 = 4.2 × 10−28 kg m−3 and nb0 = 0.25 m−3. The
equivalent proton, electron, and helium densities (Sec. 28.4.2) are np0 = 0.19 m−3,
ne0 = 0.22 m−3, and nα0 = 0.016 m−3 (Table 28.1). Of course, these densities are sub-
stantially higher in galaxies.
EXERCISES
Exercise 28.6 Example: Stars and Massive Black Holes in Galaxies
Assume that a fraction ∼0.2 of the baryons in the universe is associated with galaxies,
split roughly equally between stars and gas. Also assume that a fraction ∼10−3 of the
baryons in each galaxy is associated with a massive black hole and that most of the
radiation from stars and black holes was radiated when a ∼0.3.
28.3 The Universe Today
1379

TABLE 28.1: The universe today
Geometric
k = 0
Kinematic
Hubble constant
Deceleration parameter
Jerk parameter
H0 = 67.7 km s−1 Mpc−1 q0 = −0.54
j0 = 1
Derived
Hubble time
Hubble distance
Critical density
tH = H −1
0
= 4.6 × 1017 s
dH = ctH = 1.4 × 1026 m ρcr = 7.7 × 10−10 J m−3
Constituent
Energy fraction
Energy density (J m−3)
Number density (m−3)
Baryons
b = 0.049
ρb0 = 3.8 × 10−11
nb0, ne0 = 0.25, 0.22
Dark matter
D = 0.26
ρD0 = 2.0 × 10−10
nD0 = 0.0013mD,12−1
Cosmological  = 0.69
ρ = 5.3 × 10−10
Photons
γ = 5.4 × 10−5
ργ 0 = 4.2 × 10−14
nγ 0 = 4.1 × 108
Neutrinos
ν = 0.0014mν,−1
ρν0 = 1.1 × 10−12mν,−1
nν0 = 3.4 × 108
Note: The notation is explained in the text.
(a) The current energy density in light from all the galaxies is ∼4×10−16 J m−3. Es-
timate what fraction of stellar hydrogen has been converted by nuclear reactions
into helium. (You may assume that heat is created by these reactions at a rate of
6.4 MeV per nucleon.)
(b) The current energy density of light radiated by observed accreting black holes—
dominated by quasars—is ∼6 × 10−17 J m−3. Estimate the actual efﬁciency with
which the rest mass energy of the accreting gas is released.
(c) Estimate the total entropy per baryon associated with the horizons of massive
black holes today and compare with the entropy per baryon associated with the
microwave background and the intergalactic medium (see Sec. 4.10.2).
28.3.2
28.3.2 Dark Matter
After studying the Coma cluster of galaxies, Fritz Zwicky (1933)20 argued that most of
clusters of galaxies
thegravitationalmassinclustersofgalaxiesisneitherintheformofstarsnorofgasbut
in a dark form that has only been detectable through its gravity (Fig. 28.1c). In effect,
the gas and the galaxies move in giant gravitational potential wells formed by this dark
matter.Carefulmeasurementsofthemotionsofgasandstarshaveledtoanestimateof
the dark matter density about ﬁve times the baryon density. Again, CMB observations
improve the accuracy, and today we ﬁnd that the dark matter fraction is D = 0.26
so that b + D = 0.31 is the total matter fraction. It is widely suspected that dark
20. Oort (1932) realized that there is invisible matter in the solar neighborhood. Important subsequent
evidence came from optical and radio observations of nearby spiral galaxies by Rubin, Roberts, and
others; e.g., Rubin and Ford (1970); and Roberts and Whitehurst (1975).
1380
Chapter 28. Cosmology

matter mostly comprises new elementary particles. Furthermore, the development of
cold dark matter
gravitational clustering on small linear scales points to this matter being collisionless
and having negligible pressure when the perturbations grow.21 The inferred energy
and number density of putative dark matter particles is ρD0 = 2.0 × 10−10 J m−3,
nD0 = 0.0013mD,12−1 m−3, where mD,12 is the mass of the hypothesized particle in
units of 1 TeV. Of course, the local dark matter density in our galaxy is much larger
than this.
EXERCISES
Exercise 28.7 Challenge: Galaxies
Make a simple (numerical) model of a spherical galaxy in which the dark matter parti-
cles moving in the (Newtonian) gravitational ﬁeld they create behave like collisionless
plasma particles moving in an electromagnetic ﬁeld. Ignore the baryons.
(a) Adopt the ﬂuid approximation, treat the pressure P as isotropic and equal to
Kρ4/3, and use the equation of hydrostatic equilibrium (Sec. 13.3) to solve for
the mass and radius. Comment on the answer you get, and make a suitable
approximation to deﬁne an effective mass and radius.
(b) Consider a line passing through the galaxy with impact parameter relative to the
center given by b. Solve for the dark matter particles’ rms velocity along this line
as a function of b.
(c) It is observed that the central densities of galaxies scale as the inverse square of
the rms velocity for b = 0. How does the mass scale with the velocity?
(d) Solve for the distribution function of the dark matter particles assuming that it is
just a function of the energy (Sec. 22.2).
28.3.3
28.3.3 Photons
The next contributor to the energy density of the universe is the CMB. With its
measured temperature of Tγ 0 = 2.725 K, the energy density is ργ 0 = 4.2 × 10−14
J m−3 (Sec. 3.5). Equivalently, γ = 5.4 × 10−5. This is dynamically insigniﬁcant
today but was very important in the past. We can also compute the number density
photon number density
of photons to be nγ 0 = 4.1× 108 m−3 = 1.6 × 109nb0. An equivalent measure, which
we need below, is the photon entropy per baryon (Secs. 4.8 and 4.10):
entropy of the CMB
σγ 0 =
ργ 0 + Pγ 0
nb0Tγ 0
= 32π5
45nb0
kBTγ 0
h
3
kB = 5.9 × 109kB.
(28.24)
The photon entropy per baryon—the entropy in a box that contains, on average, one
baryon and expands with the universe—is therefore conserved to high accuracy.
21. It is often called cold dark matter. However, “cold” is inappropriate at early times, when the particles are
probably relativistic, and at late times, when they virialize in dark matter potential wells with thermal
speeds ∼100–1,000 km s−1.
28.3 The Universe Today
1381

28.3.4
28.3.4 Neutrinos
There is also a (currently) undetectable background of neutrinos that was in ther-
mal equilibrium with the photons at early epochs and then became thermodynam-
ically isolated with an approximate Fermi-Dirac distribution. As we show in the
next section, the current total neutrino density is nν0 = 3.4 × 108 m−3. There are
three ﬂavors of neutrinos (νe, νμ, ντ) plus their antiparticles, and they are known to
neutrino ﬂavors
have small masses. The contemporary total neutrino energy density and mass frac-
tion are then ρν0 = 1.8 × 10−12mν,−1 J m−3, ν = 0.0023mν,−1, respectively, where
mν,−1 = (mνe + mνμ + mντ)/100 meV. This total mν is bounded below through neu-
trino oscillation measurements (e.g., Cahn and Goldhaber, 2009) at 60 meV and
above by cosmological observations at 230 meV. For illustration purposes, we shall
assume that there is a single, dominant neutrino of mass 100 meV (i.e., 0.1 eV).
28.3.5
28.3.5 Cosmological Constant
In 1998, it was discovered that the universe is accelerating. This was ﬁrst inferred from
observations of exploding stars called supernovae,22 which turn out to be surprisingly
good distance indicators. As we know the scale factor at the time of the explosion,
we can measure χ(a) and infer contemporary values for the deceleration and jerk
functions: q0 = −0.54 and j0 consistent with 1. Using Eq. (28.23), we infer that the
pressure is also negative, P = −0.69ρ, where ρ includes the matter density.
As we have mentioned, Einstein anticipated this possibility in 1917 when he
noted that the ﬁeld equations would remain “covariant”—in our language, would
continue to obey the Principle of Relativity (be expressible in geometric language)—if
anadditionaltermproportionaltothemetrictensor ggg wereaddedtotheﬁeldequation
(Sec. 25.8):23
GGG +  ggg = 8πTTT .
(28.25)
The constant of proportionality  is known as the cosmological constant. As the Ein-
the cosmological
constant    
stein tensor involves second derivatives of the metric tensor, a cosmological constant
term that is signiﬁcant on a cosmological scale should be undetectable on the scale of
the solar system or a compact object.
Although we might interpret Eq. (28.25) as a modiﬁcation to the ﬁeld equation,
we can instead incorporate  into the stress-energy tensor T [move  ggg to the right-
hand side of Eq. (28.25) and absorb it into 8πTTT], resulting in a cosmological energy
density ρ and cosmological pressure P satisfying
ρ = −P =  
8π .
(28.26)
22. Perlmutter et al. (1999), Riess et al. (1998).
23. Einstein then went on to propose a static universe, made possible by the cosmological constant  . But
it was proved wrong when observations revealed the Hubble expansion of the universe, and it was also
unstable; so he renounced  (Einstein, 1931).
1382
Chapter 28. Cosmology

In the absence of another major component of the universe, we deduce that  =
1 −b −D −γ −ν = 0.69 and ρ = −P = 5.3 × 10−10 J m−3.
Although the large negative pressure may seem strange, it is precedented in clas-
   as density and negative
pressure
sical electromagnetism. Consider a uniform magnetic ﬁeld B permeating a cylinder
plus piston and aligned with their axis. The energy density is ρmag = B2/(2μ0), and
the total stress acting on the piston—the combination of the isotropic magnetic pres-
sure and the magnetic tension—is Pmag = −B2/(2μ0) = −ρmag. When we withdraw
thepiston, ρmag andPmag willnotchange, inagreementwiththeﬁrstlawofthermody-
namics, just like the cosmological constant. What is different about the cosmological
constant is that the stress is isotropic.
The cosmological constant contribution to the stress-energy tensor is, by assump-
tion, constant on a hypersurface of simultaneity—it is ubiquitous. Applying the ﬁrst
law of thermodynamics [Eq. (28.19)], we see that it was the same in the past and will
be the same in the future—it is (past and future) eternal.In addition, as the contribu-
tion to the stress-energy tensor is directly proportional to the metric tensor, it takes
the same form in all frames—it is invariant. Combining these features, we see that
from a relativistic perspective, it is universal.
   is universal
28.3.6
28.3.6 Standard Cosmology
This cosmological energy density ρ and pressure P are the most conservative
explanation for the universe’s acceleration. They motivate us to deﬁne a standard
cosmology, in which there are no other major components of the universe besides ρ ,
P , baryonic matter, dark matter, photons, and neutrinos, and in which the spatial
geometry is ﬂat.
EXERCISES
Exercise 28.8 Example: The Pressure of the Rest of the Universe
Calculate three contributions to the pressure of the contemporary universe.
(a) Baryons. Assume that most of the baryons in the universe outside of stars make
up a uniform, hot intergalactic medium with temperature 106 K.
(b) Radiation.
(c) Neutrinos. Assume that almost all the neutrino pressure is associated with one
ﬂavor with an associated mass of 100 meV.
28.4
28.4 Seven Ages of the Universe
Given this description of the present contents of the universe, we are now in a position
to describe its history. As our main purpose is to use cosmology to illustrate and
apply many features of classical physics, we do not retrace the tortuous, inferential
path that led to the standard description of the universe. Instead, we proceed more or
less deductively from the earliest time and describe many of the essentially classical
processes that must have occurred along the way. To help us do this, we use the device
ofdividingthehistoryintosevenages, eachdominatedbydifferentphysicalprocesses.
28.4 Seven Ages of the Universe
1383

28.4.1
28.4.1 Particle Age
CONSTITUENTS
As explained at the start of this chapter, the universe began expanding from a very
hot, dense state; we commence our story at a time when we still have conﬁdence in
essentially classical principles. To be speciﬁc, this is when a ∼10−11, T ∼10 MeV ∼
1011 K, and t ∼10 ms. At earlier times, thermodynamic equilibrium required the
presence of a large density of nucleon-antinucleon pairs and pions at near-nuclear
density. A description in terms of quarks and gluons is needed (Cahn and Goldhaber,
2009). However, for a >∼10−11, only a tiny but permanent residue of neutrons n and
protons p was present, and it was dynamically and thermodynamically irrelevant. We
use the comoving density of these baryons as a reference:
baryon density
nb ≡np + nn = nb0a−3 = 2.5 × 1032a−3
−11 m−3;
a >∼10−11,
(28.27)
where a−11 ≡1011a.
There were also muons and τs along with their antiparticles, but like the pions,
they disappeared from thermodynamic equilibrium and quickly decayed. However,
whena ∼10−11, themuchlighterelectronsandpositronswerepresentwithcombined
density ne comparable to that of the photons nγ. The photons and pairs interacted
pair density
electromagnetically and remained in thermodynamic equilibrium with each other, as
well as with the baryons, at a common temperature Tγ(a). Neutrinos, with combined
density nν, were also present at early times. Each of the three neutrino ﬂavors had
an approximate Fermi-Dirac distribution with zero chemical potential (Secs. 4.4.3,
5.5.3); and as they were effectively massless, like the photons, the neutrinos’ tempera-
ture Tν decreased ∝a−1until comparatively recently, when their ﬁnite masses became
signiﬁcant. However, unlike the photons, they did so in thermodynamic isolation
neutrino decoupling
(they were decoupled from other particles) as the rate at which they self-interacted
or exchanged energy with the other constituents quickly became less than the rate of
expansion, as we demonstrate below.
ENTROPY AND TEMPERATURE
Prior to neutrino decoupling, the photons and neutrinos were in equilibrium at the
same temperature. However, when Tγ <∼me/kB ∼1010 K, the pairs became non-
relativistic; they annihilated, and their number (and entropy) density, relative to that
pair annihilation
of the photons, quickly declined to a very small value—ultimately just that required
to equalize the proton charge density—while the photon entropy [Eq. (28.24)] was
augmented. Now, the photon and pair entropies per (conserved) baryon, σγ and σe,
are given by Eq. (28.24) with Tγ 0 replaced by Tγ and nb0 by nb, and by
σe = ρe + Pe
nbTγ
= 16πa3
nb0h3Tγ
 ∞
0
dp p2(E + p2/(3E))
eE/(kBTγ ) + 1
= 7
4σγfσe(y),
(28.28)
where E = (p2 + m2
e)1/2, y = me/(kBTγ), and
fσe(y) = 90y4
7π4
 ∞
0
dx x2(1 + 4x2/3)
(1 + x2)1/2(ey(1+x2)1/2 + 1)
(28.29)
1384
Chapter 28. Cosmology

11
10
9
8
–10
0
1
2
3
log a
log t (s)
log T (K)
σ
—
109 kB
σν
 Tν
σγ
Tγ
σe
–9
–8
6
5
4
3
2
1
0
FIGURE 28.4 Temperature T and entropy σ variation during the particle age. At early times t (or
equivalently, smallscalefactorsa), thephotons, electron-positronpairs, andneutrinos(designated
by subscripts γ , e, and ν, respectively) were in equilibrium with a common temperature. However,
when the temperature approached me/kB, the pairs began to annihilate, and their contribution
to the total entropy was taken up by the photons. (The neutrinos had decoupled by this time, and
their entropy per baryon remained constant.) The photon temperature Tγ increased relative to
the neutrino temperature Tν by a factor of 1.4.
varies between 1 when y →0 (Tγ →∞) and 0 when y →∞(Tγ →0) (Secs. 4.8,
4.10.3). Entropy conservation dictates that σe + σγ = σγ 0. We can therefore solve
for the scale factor a = (y/y0)(1 + 7fσe(y)/4)−1/3, where y0 = me/(kBTγ 0) = 2.2 ×
109, and hence for the photon temperature as a function of a. At early times and
high temperatures, σγ = (4/11)σγ 0, and so Tν/Tγ = (4/11)1/3 = 0.71at later times.24
The neutrino and photon densities satisfy nν = 9
4(Tν/Tγ)3nγ ∝nb, and so nν/nγ
neutrino density
decreased from 9
4 to 9
11, whence nν = 3.4 × 1041a−3
−11 m−3 (Fig. 28.4).
ENERGY DENSITY
We can now sum ργ, ρe, ρν, ρD, ρb, and ρ to give the total energy density for
Tγ <∼1011 K (Fig. 28.5; Secs. 3.5.4, 3.5.5)
variation of energy density
over cosmic time
ρ = aBT 4
γ + 7
4aBT 4
γ fρe(y) + 21
8 aBT 4
ν + ρD0a−3 + ρb0a−3 + ρ ,
(28.30)
where
fρe = 120y4
7π4
 ∞
0
dx x2(1 + x2)1/2
(ey(1+x2)1/2 + 1)
.
(28.31)
24. As neutrinos have mass yet do not interact, they do not maintain a thermal distribution function when
they eventually become nonrelativistic, and so Tν0 is meaningless.
28.4 Seven Ages of the Universe
1385

35
30
25
20
15
10
5
0
–5
–10
–6
–8
–10
–12
–14
11
10
9
8
7
6
5
4
3
2
1
0
1.5
1.0
0.5
0.0
log ρ (J m–3)
log Tγ (K)
log ρ (J m–3)
log Tγ (K)
log t (s)
Pa
Nu
Ph
Gr
Tγ
γ
ν
#
ρ
e
b
D
Tγ
γ
ν
#
ρ
e
b
D
Co
Pl
At
–11
–2
0
2
4
6
8
10
12
14
16
–1.0
16.4
16.6
16.8
17.0
17.2
17.4
17.6
–0.8
–0.6
–0.4
–0.2
–0.0
–10
–9
–8
–7
–6
–5
–4
–3
–2
–1
log t (s)
log a
log a
(a)
(b)
FIGURE 28.5 Energy density in the expanding universe. The energy density ρ (in J m−3) for photons
(γ ), neutrinos (ν), dark matter (D), baryons (b), and electrons (e) as a function of the scale factor a
while the universe evolved. (a) Evolution through the particle (Pa), nuclear (Nu), photon (Ph), plasma
(Pl), and atomic (At) ages ending at the epoch of reionization,when a ∼0.1. (b) Evolution through the
gravitational (Gr) and cosmological (Co) ages. The total energy density is depicted by a thick black
line. Also displayed is the cosmic time (proper time) t and the photon temperature Tγ.
1386
Chapter 28. Cosmology

Only the ﬁrst three terms in Eq. (28.30) are signiﬁcant at early times, but we give the
complete expression here.25 We also make a correction for the (unknown) neutrino
rest mass density as discussed in Sec. 28.3.4; it has small, observable effects at late
times.
AGE
Given the density, we can use the equation of motion to compute the age of the
universe (cosmic time) t as a function of the scale factor a:
time as a function of scale
factor
t(a) =
 3
8π
1/2  a
0
da′
a′ ρ(a′)−1/2
(28.32)
[Eq. (28.16)]. The age today (a = 1) is t0 = 4.4 × 1017 s = 13.8 Gyr.
HORIZON
At early times when matter is ultrarelativistic with Tγ >∼1011 K, t is proportional to
a2, ignoring a weak dependence on the number of types of particle contributing
to the expansion. In this case, using Eq. (28.15), we ﬁnd for the horizon radius
χH = 2t/a ∝a. This tells us that the horizon sphere gets smaller and smaller in
terms of comoving baryon mass MHb = 4πχ3
Hρb0/3 ∝(t/a)3 as we go back in time.
When a ∼10−11, χH ∼3 × 1016 m and MH ∼1025 kg (roughly an Earth mass). As
we have emphasized, the universe that we see around us today grew deterministically
horizon problem
out of a hot big bang and is believed to be homogeneous as far as we can see. Yet the
regions that were able to establish this smoothness through some form of mixing were
comparatively tiny at any time when this could have happened (Fig. 28.6). A plausible
resolution of this longstanding paradox, inﬂation, will be discussed in Sec. 28.7.1.
28.4.2
28.4.2 Nuclear Age
NEUTRON-PROTON RATIO
During the early particle age, neutrons and protons were able to establish thermody-
namic equilibrium primarily through the weak reactions n + ν ↔p + e−and n +
e+ ↔p + ¯ν. When 1012 K >∼Tγ >∼1011 K, nn ∼np ∼0.5nb. As the universe cooled,
a Boltzmann distribution was established: nn/np = exp[−γnpme/(kBT )], where we
write the mass difference mn −mp as γnpme = 2.53me = 1.29 MeV. However, when
Tγ <∼3 × 1010 K, the reaction rate became slower than the expansion rate, and nn/np
neutron freeze out
declined slowly to ∼0.14. If these were the only possible interactions, then the neu-
trons would have eventually undergone β-decay, n →p + e−+ ¯ν, when the universe
had expanded further and the age was of order the mean life of a neutron, ∼15 min.
(γnpme is the maximum electron energy in this decay process.) However, before this
happened, strong interactions intervened, and helium was formed.
25. Although the free electrons are dynamically insigniﬁcant at late times, they are very important for the
evolution of the microwave background, and their density evolution is discussed below.
28.4 Seven Ages of the Universe
1387

2
0
–2
–4
–6
–8
–10
25
20
15
10
5
0
–5
log MHb (M⊙)
log H0χH
log t (s)
16
Earth
star
galaxy
cluster
universe
12
14
10
8
6
4
2
0
–2
–11
–10
–9
–8
–7
–6
–5
–4
–3
–2
–1
0
log a
FIGURE 28.6 Comoving horizon radius χH as a function of the scale factor a. Also displayed is the
associated baryon mass MHb measured in solar masses (see footnote 1 in this chapter). Note that
the mass of baryons in causal contact when a ∼10−11 was equal to only an Earth mass. The mass
associated with a cluster of galaxies entered our horizon when t ∼300 yr. The horizon mass when the
microwave background was last scattered, a ∼10−3, is equivalent to ∼104 galaxy clusters but is only
∼10−5 of the total mass that is observed today, which appears to be impressively homogeneous.
Let us begin analyzing this process by ignoring the expansion of the universe and
considering the conversion of n to p through the single reaction n + ν →p + e−
(cf. Sec. 5.5.3). Let us deﬁne the rate constant λnν by the expression
forward reaction
˙np = −˙nn = λnνnn,
(28.33)
where a dot denotes differentiation with respect to t. To compute λnν, we make some
well-justiﬁed simpliﬁcations. First, we ignore the motion of the nucleons and the
mass of the neutrinos, which is justiﬁed when T ∼109 K. Second, we suppose that all
distribution functions are isotropic, which is ensured by frequent scattering. Third,
we suppose that the electrons and positrons have a common Fermi-Dirac distribution
function fe = (eγ me/(kBTγ ) + 1)−1 with zero chemical potential and temperature Tγ,
which is reasonable, as there were many more electrons than nucleons at this time and
they were strongly coupled to the photons through Compton scattering. Likewise, the
neutrinos and antineutrinos maintain a similar Fermi-Dirac distribution fν with an
independent temperature Tν.
On general grounds [cf. Eqs. (3.28), (23.50), and (23.56)], we expect to be able to
write the rate coefﬁcient in the form:
λnν =
 d3pν
h3 fν
 *
h6W
m5
e
δ(Eν −γ me + γnpme)
+ 
2d3pe
h3 (1 −fe)

.
(28.34)
1388
Chapter 28. Cosmology

The ﬁrst term in this expression describes the number density of neutrinos. The
second is the rate per state,deﬁning W and including a delta function to ensure energy
conservation, while the third describes the electron density of states, taking account
of both spins and including a blocking factor when the states are occupied. The
quantity W can be calculated using the theory of electro-weak interactions and can be
measured experimentally. It has the value W = 2.0 × 10−6 s−1 (e.g., Weinberg, 2008).
As everything is isotropic, we can write d3p = 4π(E2 −m2)1/2EdE and integrate
over the delta function to obtain
integration over phase
space
λnν = 32π2W
 ∞
γnp
dγ
γ (γ 2 −1)1/2(γ −γnp)2
(e(γ −γnp)me/(kBTν) + 1)(e−γ me/(kBTγ ) + 1)
.
(28.35)
The integration is over the range of γ permitted by energy conservation.
Note that if we set Tν = Tγ = T , the neutrons and protons will attain Boltzmann
equilibrium (Sec. 4.4), and so the rate constant λpe for the inverse reaction will be
inverse reaction
e−γnpme/(kT )λnν.26 This, in turn, implies that W, in the integral corresponding to
Eq. (28.34), is the same for the forward and backward reactions. Furthermore, the
theory of electro-weak interactions informs us that W is the same for the n + e+ ↔
p + ¯ν and n →p + e−+ ¯ν reactions. The ﬁve relevant rate constants are exhibited
in Fig. 28.7(a).
Including the expansion of the universe is a straightforward matter. We replace the
including expansion
number density of neutrons and protons with the number contained in a ﬁxed volume
expanding with the universe. If we set this volume as n−1
b , recalling that baryons are
conserved, then we can allow for the expansion by the device of replacing np with the
proton fraction Xp ≡np/nb, and similarly treating nn in Eq. (28.33).
DEUTERIUM AND HELIUM FORMATION
Neutrons and protons can combine to form deuterons (2H ≡d) through the reactions
deuterium formation
p + n ↔d + γ (e.g., Cyburt et al., 2016, and Ex. 4.10). If we just consider the for-
ward reaction and, temporarily, ignore the expansion, d would have formed at the rate
˙nd = npnn⟨σv⟩np. Here the product of the cross section σ and the relative speed v of
the nucleons, averaged over the velocity distribution at a given temperature and over
the evolution of the universe when these reactions are most signiﬁcant, is ⟨σv⟩np =
5 × 10−26 m3 s−1.
We can now include the inverse reaction by observing that, in equilibrium, we can
including inverse reaction
relate the density ni of each species i to the chemical potential μi through
ni = gi
 d3p
h3

e(μi−E)/(kBTγ ) = gi
2πmikBTγ
h2
3/2
eμi/(kBTγ )
(28.36)
26. As we could have inferred quantum mechanically.
28.4 Seven Ages of the Universe
1389

3
2
1
0
–1
–2
–3
–4
–5
1.0
0.8
0.6
0.4
0.2
0.0
log Tγ (K)
Xi
log t (s)
log λ (s–1)
3
2
1
0
–1
–2
11
10
9
–11
–10
–9
–8
–11
–10
–9
(a)
(b)
–8
log a
log a
H
peq
neq
100d
10–10γ
α
p
n
λn
λpν
λnν 
λpe
λne
FIGURE 28.7 (a) Rate coefﬁcients for the ﬁve reactions that determine the neutron-proton ratio n/p;
the subscripts on the rates λ correspond to the left-hand side of the reaction. Note that when time
t >∼300 ms, the equilibration rate is slower than the Hubble expansion rate H, and the neutron
fraction is stabilized. When t >∼600 s, the few remaining neutrons are able to undergo β-decay before
being incorporated in αs. (b) Number fractions (number of particles per baryon) for photons γ ,
protons p, neutrons n, deuterons d, and alpha particles α. When Tγ <∼2 × 1010 K, the nucleons
depart from thermodynamic equilibrium. The deuterons are produced when Tγ ∼109 K before being
quickly incorporated into αs. These two panels demonstrate that the current deuterium and helium
fractions depend sensitively on the expansion rate and the nuclear physics details; the agreement with
observation is a nontrivial validation of standard cosmology.
1390
Chapter 28. Cosmology

(Sec. 5.2), where gi is the degeneracy of species i, and we treat the nucleons as
nonrelativistic particles with E = p2/(2mi) + . . . . Under equilibrium conditions,
the relativistic chemical potentials satisfy ˜μp + ˜μn = ˜μd + ˜μγ = ˜μd, and so we can
eliminate the chemical potentials to obtain the Saha-like (Ex. 5.10) relation:
npnn = S(Tγ)nd,
(28.37a)
where
S(Tγ) = 21/23−1
2πmpkBTγ
h2
3/2
e−γdme/(kBTγ ),
(28.37b)
we have used gp = gn = 2 and gd = 3 and γd me = mn + mp −md = 4.34 me is the
deuteron binding energy. The combined forward-reverse reaction rate must then
be described by dnd/dt = ⟨σv⟩np[npnn −S(Tγ)nd], as this is the only way that we
can maintain equilibrium at all temperatures. At early times, S⟨σv⟩np ≫H and
equilibrium must have been maintained.
The ﬁnal step is to explain how the tritons (nuclei of 3H ≡t), helions (nuclei
of 3He ≡h), and alpha particles (nuclei of 4He ≡α) were formed. There are two
important pathways: d + d →t + p, t + d →α + n; and d + d →h + n, h + d →
deuterium reactions
α + p (cf. Sec. 19.3.1). The effective, combined forward reaction rate is calculated
using ⟨σv⟩dd = 7 × 10−24 m3 s−1. The reverse reaction rates can be calculated using
a simple generalization of the argument leading to Eq. (28.37) for reactions involving
four or more nucleons. We can now allow for the expansion as before, introducing the
d number fraction Xd = nd/nb, to obtain three coupled rate equations for the proton,
neutron, and deuteron number fractions Xp = np/nb, Xn = nn/nb, and Xd = nd/nb:
rate equations
HX′
p = (λnν + λne + λn)Xn −(λpe + λpν)Xp −⟨σv⟩np(nbXpXn −S(Tγ)Xd),
HX′
n = (λpe + λpν)Xp −(λnν + λne + λn)Xn −⟨σv⟩np(nbXpXn −S(Tγ)Xd),
HX′
d = ⟨σv⟩np(nbXpXn −S(Tγ)Xd) −2⟨σv⟩ddnbX2
d,
(28.38)
where a prime denotes differentiation with respect to ln a. It is easiest to solve these
equations by assuming the neutrons and protons are in equilibrium until a ∼10−11
and the deuterons are in equilibrium until a ∼10−9.
The numerical solution to these equations (Fig. 28.7) shows that the neutrons
numerical solution
and protons remained in thermodynamic equilibrium until the temperature fell to
∼2 × 1010 K, at which time the neutron fraction declined slowly, reaching a value
∼0.15 by the time the temperature had fallen to ∼109 K. At this temperature, the
deuteron equilibrium fraction climbed quickly, and the deuteron density became
nucleosynthesis
large enough for the d + d reactions to produce α at Tγ = 8 × 108 K, and then
declined. Most neutrons were incorporated into helium, though a small fraction was
left to decay freely. The ﬁnal helium fraction is27 Xα = nα/nb = 1
4(1 −Xp) = 0.058
ﬁnal helium and deuterium
fractions
(Fig. 28.7), slightly smaller than the (observed) value Xα = 0.062 obtained by more
27. Astronomers reserve the symbol X for hydrogen and use the symbol Y = 4Xα for the helium mass
fraction and Z for the mass fraction of all other elements which they call “metals”!
28.4 Seven Ages of the Universe
1391

detailed calculations that include about ten more reactions, temperature dependence
of the reaction rates, and other reﬁnements. The late-time deuterium number fraction
computes to be Xd = 2.3 × 10−5, consistent with the detailed calculations and with
observations. Yields of h, 6Li, and 7Li are also computed and can be reconciled with
observations if one takes account of large astrophysical uncertainty. The t decays.
It is the absence of stable nuclei with A = 5, 8 that prevented the build-up of
elements beyond helium in the early universe. Instead, the synthesis of these elements
had to await the formation and evolution of stars.
28.4.3
28.4.3 Photon Age
Primordial nucleosynthesis was complete by the time the scale factor had increased to
a ∼10−8 and the temperature had fallen to Tγ ∼3 × 108 K. This marks the beginning
of the photon age, during which the energy density of the universe was still dominated
byphotons(andneutrinos)andργ ∝a−4, a ∝t1/2.Nowisagoodtimetoexaminethe
implicit assumption that we have been making that, with the conspicuous exception
of the neutrinos, all major constituents of the universe are maintained in thermal
equilibrium during the nuclear and photon ages.
PLASMA EQUILIBRATION
Let us ﬁrst consider protons and electrons. The plasma frequency ωP =
[ne2/(mϵ0)]1/2 ∝a−3/2 (Sec. 20.3) is very high in comparison with the expansion
rate. In fact, ωpH ∼1017a1/2
−8, where a−8 = a/10−8. Likewise, the ratio of the Debye
length λD = [ϵ0kBT /(ne2)]1/2 to the horizon radius is λDχH ∼10−18a−1
−8. Therefore,
the use of ﬂuid mechanics in place of plasma physics is amply justiﬁed for the whole
validity of the ﬂuid
approximation
expansion of the universe.
Now let us question our implicit assumption of thermodynamic equilibrium.
Using Eqs. (20.23), (28.27), and (28.13), we ﬁnd that the ratios of the e-e, p-p, and
p-e equilibration timescales (∝T 3/2n−1 ∝a3/2) to the expansion timescale (∝a2)
are given by H{tee, tpp, tep} ∼{1, 40, 1800} × 10−10a−1/2
−8
throughout the photon age,
equilibration timescales
ensuring that baryons remained in thermal equilibrium.
COMPTON SCATTERING
Next consider the interaction between the plasma and the photons, which is
mediated by Compton scattering. If there had been no such interaction, then the
(nonrelativistic) plasma would have maintained its Maxwellian distribution with a
temperature that would have fallen as T ∝a−2 (Sec. 28.2.3). However, each Comp-
ton scattering will lead to an energy transfer from the photons to the electrons through
a combination of the Doppler effect and Compton recoil. This energy change will then
be quickly shared with the protons, so that the plasma is only allowed to become a tiny
bit cooler than the radiation. To be quantitative, the mean fractional energy exchange
per scattering is | ln E| ∼kBT /me. Therefore, it will take ∼me/(kBT ) scatterings
to equilibrate the plasma with the far more numerous photons. The scattering time
is teγ ∼(nγσT )−1, where σT = 8πr2
e/3 = 6.65 × 10−29 m−2 is the Thomson cross
1392
Chapter 28. Cosmology

section, and re = 2.8 fm is the classical electron radius (Sec. 3.7.1). The ratio of the
timescale for the plasma to equilibrate with the radiation, to the expansion timescale,
is Hteγ = Hme/(ργσT ) ∼2 × 10−16a2
−8. The electrons therefore exchange energy
with the radiation ﬁeld even faster than they share it among themselves and with pro-
electron-photon coupling
tons. This justiﬁes our assumption of a common matter and radiation temperature in
the early universe. Insofar as the universe is homogeneous, the far more numerous
photons will automatically maintain their initial Planck distribution without energy
redistribution by electrons. Their response to small, inhomogeneous perturbations is
considered below.
28.4.4
28.4.4 Plasma Age
Eventually, the rest-mass energy density of matter (mostly dark matter) exceeded
that of radiation and neutrinos, and the plasma age began. This happened when
a = aeq = 0.00030, t = teq = 52 kyr, and Tγ = Teq = 9,100 K. Thereafter, according to
onset of matter dominance
Eq. (28.30), ρ ∝a−3 and a ∝t2/3, approximately.28 The Friedmann equation (28.16)
can be integrated in this plasma age to give, more precisely,
t
teq
=
2
1 + 2−1/23
⎡
⎣2 −
*
2 −a
aeq
+ *
1 + a
aeq
+1/2⎤
⎦,
(28.39)
which remains valid until the cosmological age.
Next the helium ions became singly ionized through capturing one electron and
helium recombination
then became neutral by taking on a second electron, leaving a proton-electron
plasma. After a further interval, the hydrogen recombined.29 Unlike the helium re-
combination, the details of this process are highly signiﬁcant.
The total (atomic plus ionized) hydrogen density is nH+p = 1.9 × 108a−3−3 m−3,
where a−3 = a/10−3. In equilibrium, the atomic fraction would satisfy the Saha equa-
tion (5.68). However, just as happened with nucleosynthesis, the universe expanded
too fast for the reactions to keep up. The basic problem is that when an electron
hydrogen recombination
and a proton recombine, they emit one or more photons that have a short mean free
path and are mostly reabsorbed by neighboring atoms, leading to no net change in
ionization. This is especially true of the Lyman α photons emitted with frequency
να = 2.47 × 1015 Hz when a hydrogen atom transitions from its ﬁrst excited state,
designated by quantum number n = 2, to its ground state with n = 1. A good approx-
imation is to treat the n = 2 level as the effective ground state, changing the effective
ionization potential from I1 = 13.6 eV to I2 = 13.6/4 = 3.4 eV and modifying the de-
generacy in the Saha equation, and then to allow for the slow permanent population
of the true, n = 1, ground state.
28. The thermal energy density of the plasma was only 6 × 10−10 times the radiation energy density at this
time.
29. The use of the term recombination is conventional but misleading, because it is the ﬁrst occurrence of
this process.
28.4 Seven Ages of the Universe
1393

If we denote by X1 and X2 the fraction of the hydrogen in the n = 1 and n = 2
states, respectively, and ignore higher energy levels,30 then the ionization fraction is
x = ne/nH+p = 1 −X1 −X2. The rate equations analogous to Eqs. (28.38) are
rate equations
HX2
′ = α2
*
nH+px2 −1
4X2
2πmkBTγ
h2
3/2
e−I2/(kBTγ )
+
−λ21X2,
HX1
′ = λ21X2.
(28.40)
The use of fractional densities once again takes account of the expansion of the
universe. The quantity α2 = 2.8 × 10−19T −1/2
4
m3 s−1 is the recombination coefﬁcient
into the n = 2 level, which is computed by summing over all pathways, excluding
transitions to n = 1. The 1
4 takes into account the 2-fold degeneracy of the n = 1level
and 8-fold degeneracy of the n = 2 level, and the “Saha” factor ensures equilibrium
allowing for inverse
reactions
in the absence of transitions to n = 1, just like the factor S in Eq. (28.37). The rate
constant λ21 describes the permanent transitions to the ground state, corrected for
reverse transitions.
We compute λ21 as follows. The sublevels of the n = 2 level are well mixed by
collisions, so one-quarter of the excited atoms will be in the 2s sublevel, while three-
quarters will be in the 2p sublevel. The 2s atoms can permanently deexcite by emitting
two-photon deexcitation
two photons, neither of which is reabsorbed. This process has a forbidden sponta-
neous rate A2s = 8.2 s−1, and the inverse process can be ignored. The 2p atoms create
Lyman α photons with a permitted rate A2p = 4.7 × 108 s−1. The spectral line will
have a small, combined natural and Doppler width. The cross section for absorbing
a Lyman α photon in the low-frequency wing of the line decreases with decreasing
frequency and eventually becomes small enough that the expansion of the universe
allows the photon to avoid absorption altogether and therefore leads to the forma-
tion of a hydrogen atom in its ground state. Let us deﬁne by Pesc the probability
that one of these photons avoids absorption in this manner. Next let us describe
the line proﬁle by Pν(ν), the cumulative probability that an emitted Lyman α pho-
escape probability
ton has frequency less than ν. (See Ex. 28.9 for this and some other details of the
analysis.)
Kirchhoff’s law of radiation (e.g., Sec. 10.2.1) ensures that the net absorption cross
section has the same frequency dependence as the emissivity. Using the Einstein co-
efﬁcients, we can show that the net absorption cross section associated with the same
atoms as those that are emitting the Lyman α photons is σα = [A2p/(8πν2
α)]dPν/dν.31
The probability that a Lyman α photon with any frequency will escape due to expan-
sion is then given by
30. The fractional occupancy of the n = 2 level never exceeds ∼10−13, and so this is a good
approximation.
31. Another way of expressing this is

dνσα = πrefα, where fα = 0.42 is the oscillator strength (Cohen-
Tannoudji, Diu, and Lalo¨e, 1977).
1394
Chapter 28. Cosmology

4
3
2
1
0
–1
–2
–3
–4
0
–1
–2
–3
–4
–τT′
τT
log τT, log(–τT′ λ)
xs
x
log x
reionization
4
3
2
1
–4
–3
–2
0
–1
log a
log Tγ (K)
last scattering
FIGURE 28.8 Ionization fraction of the universe, x, plotted as a function of the scale factor a. The
blue dashed curve shows the result from assuming Saha equilibrium xS. The solid blue curve
showstheactualionizationfraction, x, deducedfromEqs.(28.40)afterincludinginλ21theatomic
processes that delay recombination of the electrons. The solid red curve shows the Thomson
optical depth τT from now back to scale factor a, while the dashed red curve is its derivative with
respect to −ln a: −τ ′
T = neσT H −1. The shaded region to the left delineates the short interval
when τT fell from ∼3 to ∼1. The shaded region to the right delineates the poorly understood
epoch of reionization (Sec. 28.4.5), when newly formed stars and black holes are thought to have
created sufﬁcient ultraviolet photons to change most hydrogen in the universe back to a plasma.
The ionization fraction adopted for 0.05 < a < 1is x = 1.16[1+ 1.5(a/0.1)−8.7]−1, which allows
for the presence of helium.
Pesc =
 1
0
dPνe−n1

dtσα =
 1
0
dPνe−n1
Hνα

dνσα =
 1
0
dPνe
−
n1A2pPν
8πν3αH ≃8πν3
αH
n1A2p
,
(28.41)
where n1 is the number density of H atoms in the n = 1state, which is effectively con-
stant in the short time it takes the universe to Doppler shift the frequency of the pho-
ton by enough to escape absorption. Therefore λ21 = 1
4A2s + 3
4A2pPesc, independent
of A2p.
To solve Eqs. (28.40), note that X2 ≪X1, and so X2
′ can be set to zero. The result-
ing ionization x (solid blue curve in Fig. 28.8) follows the full Saha evolution as long
as T >∼4,000 K (Fig. 28.8). Thereafter the ionization fraction is signiﬁcantly larger.
The universe is half-ionized when Tγ ∼3,500 as opposed to ∼3,700 K, according to
the Saha equation.
We will need the Thomson optical depth τI on our past light cone:
τT (ln a) =
 0
ln a
(d ln a)neσT /H .
(28.42)
28.4 Seven Ages of the Universe
1395

According to this equation, the average last scattering surface, where τT = 2/3,
last scattering surface
occurred when a = als = 0.00093, Tγ = 2,920 K, t = 1.2 × 1013 s = 380 kyr. These
values are in good agreement with more careful calculations.
EXERCISES
Exercise 28.9 Problem: Spectral Line Formation
In our discussion of recombination, we related the emission of Lyman α photons to
their absorption. This involves some important ideas in the theories of radiation and
thermodynamics.
(a) Consider a population of two-state atoms. Let the number of atoms in the lower
state be N1 and in the upper state N2. The probability per unit time of an upper-
state atom changing to a lower state and releasing a photon of energy hν equal
to the energy difference of the states is denoted by A. We expect that the rate
of upward, 1 →2 transitions is proportional to the occupation number ηγ of
the photons with frequency ν (Sec. 3.2.5). Call this rate Kuηγ. By requiring
that the atoms should be able to remain in Boltzmann equilibrium with the
Planckian radiation ﬁeld of the same temperature, show that there must also be
downward, stimulated emission at a rate per state-2 atom of Kdηγ, and show that
Ku = Kd = A.
(b) The absorption cross section σ for an atom at rest can be written in the Lorentz
or Breit-Wigner form as:
σ =
πA2
(ν −ν0)2 + A2 .
Either make a classical model of an atom as an electron oscillator with natural
frequency ν0, or use time-dependent perturbation theory in quantum mechanics
to justify the form of this formula.
(c) Identify the frequency probability function Pν introduced in Sec. 28.4.4, and plot
the natural line proﬁle for an emission line.
(d) Atoms also have thermal motions, which Doppler shift the photon frequencies.
Modify the line proﬁle by numerically convolving the natural proﬁle with a 1-
dimensional Gaussian velocity distribution and replot it, drawing attention to its
behavior when A is much more than the thermal Doppler shift.
(e) We have restricted our attention to a two-state system. It is usually the case that we
are dealing with energy levels containing several distinct states, and the formal-
ism we have described has to be modiﬁed to include the degeneracies gi of these
levels. Make the necessary corrections and recover the formulas used in the text.
(f) A second complication is polarization (Sec. 7.7). Discuss how to include this.
1396
Chapter 28. Cosmology

28.4.5
28.4.5 Atomic Age
The next age is the atomic age.32 If atomic hydrogen were completely decoupled from
the radiation ﬁeld, then it would cool with temperature TH ∝a−2 and eventually
become cryogenic! However, this is not what happened, as the electrons that remained
electron temperature
were still able to keep in thermal contact with the radiation and with the protons and
atomic hydrogen. The plasma was maintained at roughly the electron temperature.
Eventually, when a ∼0.03, the temperature had fallen to T ∼100 K, and molecular
hydrogen appeared. However, this was also about the time when the very ﬁrst self-
ﬁrst stars and black holes
luminousstarsandblackholesformedandemittedultravioletradiation, whichcaused
the molecular hydrogen to dissociate and the atoms to ionize. This is known as
the epoch of reionization and must have continued until a ∼0.14, because neutral
hydrogen is actually detected at this time through Lyman α absorption of quasar
light. Characterizing the epoch of reionization is a major goal of modern research and
involves many considerations that lie beyond the scope of this book. The evolution
adopted in Fig. 28.8 and Sec. 28.5 is consistent with current observations but is not
yet well constrained.
EXERCISES
Exercise 28.10 Problem: Reionization of the Universe
(a) Estimate the minimum fraction of the rest mass energy of the hydrogen that must
have undergone nuclear reactions inside stars to have ionized the remaining gas
when a ∼0.1.
(b) Suppose that these stars radiated 30 times this minimum energy at optical
frequencies. Estimate the energy density and frequency of this stellar radiation
background today.
You may ﬁnd Exercises 4.11 and 28.6 helpful.
28.4.6
28.4.6 Gravitational Age
SCALE FACTOR
As we discuss further in Sec. 28.5, after recombination small inhomogeneities in the
early universe grew under the inﬂuence of gravity to form galaxies and larger-scale
structures. The inﬂuence of stars was supplemented by that of accreting massive black
holes that formed and grew in the nuclei of galaxies. After reionization this radiative
onslaught kept most baryons in the universe in a multiphase, high-temperature state.
However, this is also the time when the inﬂuence of the cosmological constant
inﬂuence of cosmological
constant
started to become signiﬁcant. If we ignore photons, neutrinos, and spatial curvature,
then Eq. (28.16) describing the expansion of the universe in the gravitational age has
32. Sometimes called the dark age.
28.4 Seven Ages of the Universe
1397

a simple analytical solution derived and discussed by Bondi (1952a):
t =
2
3H0(1 −M)1/2 sinh−1 
(−1
M −1)1/2a3/2
,
(28.43)
where M is the current matter density in units of the critical density. We see that the
inﬂuence of the cosmological constant is negligible at early enough times, t ≪t0, and
the energy density of the matter dominates the expansion. It also dominates any cur-
vature that there might be today. Such a universe is usually called an Einstein–de Sitter
Einstein–de Sitter universe
universe and has a = (3H0t/2)2/3. Similarly, at late times, t ≫t0, we can ignore the
matter and ﬁnd that a ∝exp(Ht), where H = (1−M)1/2H0. This is called a de Sitter
universe. The kinematic properties of our standard universe relative to an Einstein–
de Sitter universe and an open (k = −1) one are best expressed using the deceleration
parameter q [Eqs. (28.14) and (28.23)], which is exhibited in Fig. 28.9. Note that the
jerk parameter is j = 1 throughout the gravitational and cosmological ages.
DISTANCE AND VOLUME
ExceptingtheCMB, mostcosmologicalmeasurementsaremadewhena >∼0.1.There-
fore, now is a good time to calculate distance and volume. The comoving distance
to a source whose light was emitted when the expansion parameter was a, (a)
(equal to the radius χ(a) in our ﬂat universe), can be computed from the Fried-
mann equations and is exhibited in Fig. 28.10. We can also compute the angular
diameter distance dA = aχ(a), which is seen to reach a maximum value of 0.41/H0 =
angular diameter and
luminosity distances
5.6 × 1025 mata = 0.39.Moredistantsourcesofﬁxedphysicallengthwillactuallyap-
pear progressively larger. By contrast, the luminosity distance dL = a−1χ(a) increases
rapidly with distance, and individual sources become unobservably faint. The total
distancetotheearlyuniverseisχH(t0) = 3.2/H0 = 14 Gpc = 4.4 × 1026 mandtheas-
sociated comoving volume is VH(t0) = 4πχH(t0)3/3 = 140H −3
0
= 1.2 × 104 Gpc3 =
volume of observable
universe
3.6 × 1080 m3. The universe is a big place!
EXERCISES
Exercise 28.11 Problem: Type 1a Supernovae and the Accelerating Universe
Rather surprisingly, it turns out that a certain type of supernova explosion (called
“Type 1a” and associated with detonating white-dwarf stars) has a peak luminosity L
that can be determined by studying the way its brightness subsequently declines.
Astronomers can measure the peak ﬂuxes F for a population of supernovae at a range
of distances.
Calculate the ﬂux measured at Earth for a given L as a function of the scale factor
0.3 < a < 1 at the time of emission for the following.
(a) An Einstein–de Sitter universe.
(b) A nonaccelerating universe with a ∝t.
(c) Our standard model universe.
1398
Chapter 28. Cosmology

1.0
0.5
0.0
–0.5
–1.0
40
35
30
25
20
15
10
5
0
q
standard
open
EDS
standard
open
EDS
tstandard(Gyr)
t(Gyr)
0
5
10
20
15
30
25
0.0
0.5
1.0
2.0
(b)
1.5
3.0
2.5
a
0.0
0.5
1.0
2.0
(a)
1.5
3.0
2.5
a
FIGURE28.9 Expansion of the universe during the gravitational and cosmological ages. (a) The variation
of age t with scale factor a is shown for standard cosmology (solid curve). Note that the expansion of
the universe initially decelerated under the pull of gravity, but then began to accelerate at age ∼6 Gyr
under the inﬂuence of the cosmological constant. If this continues for the next ∼15 Gyr, then the
universe will embark on an exponential growth. (b) This exponential growth is brought out in a plot
of the associated deceleration parameter q versus a. Also shown in both panels are the solutions for
a (dashed) Einstein–de Sitter (EDS) model, which is ﬂat and matter dominated, with an identical
Hubble constant as standard cosmology, and a negatively curved (dotted) open model with the same
contemporary density parameter as used in standard cosmology. Neither of these models exhibits
acceleration; the former decelerates forever, the latter eventually expands with constant speed.
28.4 Seven Ages of the Universe
1399

150
120
90
60
30
0
5
4
3
2
1
0
t(Gyr)
dL
V
dA
H0 χ
H0 dL
H0 dA
H0
3
 V
χ
0.0
0
2
4
6
8
10
12
0.2
0.4
0.8
0.6
1.0
a
FIGURE 28.10 Comoving distance χ (in units H −1
0 ) to a source whose light was emitted when
the scale factor was a < 1. Also shown are the luminosity distance dL, the angular diameter
distance dA, and the comoving volume V associated with a sphere of radius χ (red).
Assume the same Hubble constant today, H0. How accurately must F be measured
to conﬁrm the prediction of the standard model with an error of ∼0.1 in a single
measurement at a ∼0.7? Astronomers do not, in practice, measure the total ﬂux but
the ﬂux in a speciﬁc spectral band, but this adjustment can be made if the spectrum
is known.
28.4.7
28.4.7 Cosmological Age
The ﬁnal age, which began about 5 Gyr ago, when a ∼a ∼0.7, is called the cosmo-
logical age because the energy density is thereafter dominated by the cosmological
constant. We are entering a phase of exponential, de Sitter expansion, presaging a
eschatology!
future dominated by dilution and decay—an agoraphobic’s worst nightmare! Opera-
tionally, the acceleration slows the development of large-scale structure in the distri-
bution of galaxies, which provides one way to measure the value of the cosmological
constant. Of course, as a pure cosmological constant is still a weakly constrained ﬁt
to the observations, the future could be more subtle, as we discuss in Sec. 28.7.3.
EXERCISES
Exercise 28.12 Problem: Future Evolution of the Universe
Assume that the universe will continue to expand according to Eq. (28.43).
(a) Calculatethebehavioroftheangulardiameterdistanceandtheassociatedvolume
as a function of the scale factor for the next 20 billion years.
(b) Interpret your answer physically.
1400
Chapter 28. Cosmology

(c) Explain qualitatively what will happen if the universe accelerates even faster than
this.
We return to this topic in Sec. 28.7.3.
28.5
28.5 Galaxy Formation
The universe we have described so far is homogeneous and isotropic and completely
ignores the large density ﬂuctuations on small scales, observed today as clustered
galaxies. Our task now is to set up a formalism to describe the growth under gravity of
the perturbations that produce this structure as the universe ages. Much of this prob-
lem can be handled using Newtonian physics, but as the most interesting questions
are intrinsically relativistic and as we have already developed the necessary formal-
ism, we shall dive right into a fully relativistic analysis (Peebles and Yu, 1970; Sunyaev
and Zel’dovich, 1970).
28.5.1
28.5.1 Linear Perturbations
METRIC
We generalize the Robertson-Walker metric [Eq. (28.9)] to include linear pertur-
relativistic perturbation
theory
bations in a manner inspired by our discussions of weak ﬁelds (Sec. 25.9) and the
Schwarzschild spacetime (Sec. 26.2):
ds2 = −(1 + 2)dt2 + a2(1 −2!)δijdχidχi.
(28.44)
Here a is the same function of t as in the unperturbed model, and FOs (by deﬁnition)
curvature and potential
perturbations
continue to move with ﬁxed comoving coordinate χ. The changes to the spacetime
geometry are all contained in the curvature perturbation ! and in the potential pertur-
bation , which agrees with its Newtonian counterpart when it is small in magnitude
(relative to unity) and inhomogeneity scale33 (relative to the horizon).34
KINEMATICS
An FO no longer follows a timelike geodesic. We use ⃗u . ⃗u = −1 to evaluate the
components of its 4-velocity and 4-acceleration aα = uβuα;β to ﬁrst order in the
perturbation:
ut = 1 −,
uj = 0;
at = 0,
ai = ∂i.
(28.45)
33. Note that  does not include the Newtonian potential difference 2πρr2/3 that we might be tempted to
associate with two points separated by r in the background medium if we had not appreciated the way
that general relativity neatly resolves this ambiguity.
34. The coordinate choice is sometimes called a gauge [cf. Eqs. (25.87), (25.88), and (27.18)] by analogy with
classical electromagnetism and particle physics and is often motivated by considerations of symmetry.
Physical observables should not (and do not) depend on the coordinate/gauge choice. Our choice is
known as the Newtonian gauge and is useful for perturbations that can be expressed as scalar quantities.
(We will encounter tensor perturbations in Sec. 28.7.1.) This gauge choice is appropriate because, when
 and ! are small, it becomes the weak-gravitational-ﬁeld limit of general relativity (Sec. 25.9), which
we need to interpret the actual cosmological observations we make today and which can be used to
discuss the initial conditions, as we shall see in Sec. 28.7.1.)
28.5 Galaxy Formation
1401

These expressions exhibit gravitational time dilation—dt/dτ = 1− (Sec. 27.2.1)—
and Einstein’s equivalence principle (Sec. 25.4). A particle that moves with small
3-velocity v, as measured in an FO’s local Lorentz frame, has a 4-velocity ut = 1−,
acceleration with respect
to FO
ui = vi/a and a 4-acceleration at = 0, ai = d(avi)/dt + ∂i. In the limit  = 0,
v ∝a−1 if the particle is freely moving (Sec. 28.2.3).
FOURIER MODES
We are interested in the linear evolution of perturbations, and it is convenient to
work with the spatial Fourier transform of the perturbed quantities (Sec. 8.3). For
the potential, which is our primary concern, we write
potential oscillations
(t, χ) =

d3k
(2π)3eik.χ ˜(t, k),
(28.46)
where the ∼denotes spatial Fourier transform, the comoving wave vector k does
not change with time, and we treat t and a as interchangeable coordinates. As 
is real, ˜(t, −k) = ˜∗(t, k). Implicit in this Fourier expansion is a box, which we
presume is much larger than the current horizon but which will not feature in our
development. The actual modes can be considered as traveling waves moving in
antiparallel directions or as standing modes in quadrature, which is a better way
to think about their nonlinear development. In what follows, we shall consider the
temporal development of linear perturbations, which can be thought of as either
individual wave modes or as continuous Fourier transforms.
PERTURBED EINSTEIN EQUATION
Now focus on a single Fourier oscillation and use computer algebra to evaluate the
nonzero, linear perturbations to the Einstein ﬁeld equations in a local orthonormal
basis:
perturbed ﬁeld equations
˜Gˆt ˆt = −2[3H( ˙˜! + H ˜) + (k/a)2 ˜!]= 8π ˜T ˆt ˆt = 8π ˜ρ,
(28.47a)
˜Gˆt ˆ∥= −2ik
a ( ˙˜! + H ˜) = 8π ˜T ˆt ˆ∥= 8π(ρ + P )˜v,
(28.47b)
˜Gˆ∥ˆ∥= 2[ ¨˜! + H( ˙˜ + 3 ˙˜!) + (1 −2q)H 2 ˜]= 8π ˜T ˆ∥ˆ∥,
(28.47c)
˜G ˆ⊥ˆ⊥= ˜Gˆ∥ˆ∥+ k2( ˜! −˜)
a2
= 8π ˜T ˆ⊥ˆ⊥,
(28.47d)
where ∥and ⊥are components parallel and perpendicular to k. Equation (28.47b)
deﬁnes the mean velocity perturbation, which is purely parallel, ˜v = ˜v∥. Note that if
the cosmological ﬂuid is perfect, there is no shear stress ( ˜T ˆ∥ˆ∥= ˜T ˆ⊥ˆ⊥= ˜P) and, conse-
quently,
˜! = ˜. This is a major simpliﬁcation, echoing our treatment of
Schwarzschild spacetime (Sec. 26.2). However, when neutrinos or photons have
decoupled from matter and free stream through primordial (dark-matter) density
perturbations, their stresses become sufﬁciently anisotropic to produce a measurable
distinction between ˜ and ˜!.
1402
Chapter 28. Cosmology

Because these equations only involve the component of mean velocity parallel to
k, they describe longitudinal waves, generalizations of the sound waves discussed
in Sec. 16.5. This mean velocity is irrotational and can therefore be written as a
carefully chosen function of time, multiplied by the gradient of a velocity potential ˜ψ
velocity potential
(Sec. 13.5.4):35
˜v = iβ ˜ψ.
(28.48a)
Here we introduce a scaled wave vector
scaled wave vector
β =
k
31/2˙a ,
(28.48b)
which can be regarded as a function of either t or a. (Note that q ≡(∂ln β/∂ln a)k,
which is a useful relation.)
We also deﬁne the total relative density perturbation:
relative density
perturbation
˜δ ≡˜ρ/ρ = (ρb˜δb + ρD ˜δD + ργ ˜δγ + ρν ˜δν)/ρ,
with
˜δb,D,γ ,ν ≡˜ρb,D,γ ,ν/ρb,D,γ ,ν,
(28.49)
where the subscripts b, D, γ , and ν continue to refer to baryons, dark matter, photons,
and neutrinos. Equation (28.47a) then becomes
potential evolution
equation
˜!′ + β2 ˜! + ˜ = −1
2
˜δ,
(28.50)
where the prime denotes a derivative with respect to ln a.
EARLY EVOLUTION
Before neutrino decoupling, when a <∼10−11, the stress-energy tensor TTT is dominated
by a well-coupled, relativistic ﬂuid consisting of radiation, neutrinos, and elementary
particles with P = ρ/3 and a ∝t1/2, so that q = 1, ˜! = ˜, and ˜T ˆ∥ˆ∥= ˜ρ/3. This
remains a pretty good approximation until dark matter dominates the density during
the plasma era when a ∼aeq, and it can be used to bring out some important features
of the general evolution. We can identify β as the ratio of the (relativistic) acoustic
horizon χR [Eq. (28.15) and subsequent line] to the size of the perturbation, measured
by 1/k, both in comoving coordinates. Further simpliﬁcation results from changing
theindependentvariabletoβ ∝a andcombiningEqs.(28.47b)and(28.47d)toobtain
a single second-order, homogeneous differential equation:36
evolution under radiation
dominance
d2 ˜
dβ2 + 4
β
d ˜
dβ + ˜ = 0.
(28.51)
35. Actually there are modes with vorticity (embodied in the perpendicular part of the velocity ˜v⊥), and they
evolve according to the relativistic generalization of the equations discussed in Sec. 14.2.1. In principle,
they could have been created by some sort of primordial turbulence. However, in practice they decay
quickly as the universe expands and so will be ignored.
36. This equation, like many other equations describing the evolution of perturbations, has the form of a
damped simple harmonic oscillator equation. The ﬁrst derivative term is then often called a “friction”
term. However, this is only a mathematical analogy. Physically, it represents the loss of energy in work
done on the expanding medium, not a true dissipation.
28.5 Galaxy Formation
1403

1.5
1.0
0.5
0.0
–0.5
–1.0
–1.5
2βψ/33/2"(0)
"/"(0)
0
1
3
5
2
4
7
9
8
6
10
β
δ/6"(0)


FIGURE 28.11 Early growth of a single spatial Fourier component of the perturbations. The
amplitudeofthepotential ˜, relativedensity ˜δ, andvelocitypotential ˜ψ perturbationsare
shown as functions of β = kχR for a single spatial Fourier component. The perturbations
are frozen until they “enter the horizon” when β ∼1. The perturbations then convert
oscillations in which the amplitude of ˜δ is constant while ˜ is in antiphase and ˜ψ is in
quadrature.
This has a unique solution, nonsingular as β, a →0 and valid for all scales:
˜(t, k) = 3 ˜(0, k)
β2
sin β −β cos β
β

= ˜(0, k)(1 −β2/10 + . . .). (28.52)
The mode does not evolve signiﬁcantly until it is contained by the acoustic horizon.37
Using Eq. (28.50), the relative density and velocity potential perturbations are then
given by
˜δ = −6 ˜(0)
2(β2 −1) sin β −β(β2 −2) cos β
β3

= −2 ˜(0)(1 + 7β2/10 + . . .),
˜ψ = −33/2 ˜(0)
2
(β2 −2) sin β + 2β cos β
β3

= −31/2 ˜(0)
2
(1 −3β2/10 + . . .)
(28.53)
(see Fig. 28.11). When β ≫1, the wavelength is smaller than the acoustic horizon and
evolution after entering
horizon
the amplitude of the velocity perturbation is 31/2δ/4, in agreement with the expecta-
tion for a sound wave in a stationary, relativistic ﬂuid. The angular frequency of the
37. What this really means is that we have chosen a coordinate system in which the expectation is clearly
expressed that a physical perturbation not change signiﬁcantly until a signal can cross it. Even in the
absence of a genuine physical perturbation, we could have created the illusion of one simply by changing
to a “wrinkled” set of coordinates.
1404
Chapter 28. Cosmology

2
1
0
–1
–2
ψ/"(–2,k)
log t (s)
log a
"/"(–2,k)
δM(H0/k)2/"(–2,k)

–2.0
–1.5
15
16
17
–1.0
–0.5
0.0

FIGURE 28.12 Evolution of the potential ˜, the matter density perturbation ˜δM, and
the velocity potential ˜ψ for −2.0 ≤log a ≤0.0. Note that ˜ and ˜ψ only change
slowly during the cosmological era when the cosmological constant is signiﬁcant.
By contrast, the density perturbation ˜δM is ∝k2 and grows rapidly to create the
structure we observe today.
wave is ω = dβ/dt = k/(31/2a), just what is expected for a sound wave (Sec. 16.5) in
a relativistic ﬂuid. The amplitude of the potential  decays as ∼3 ˜0/β2, in accord
with Poisson’s equation.
The constancy of the wave amplitude ˜δ turns out to be a nice illustration of adia-
batic invariance (cf. Ex. 7.4). The locally measured wave energy in a single wavelength
is ∝˜δ2ρa3. This should scale with the wave frequency, implying that ˜δ is constant
(since ω ∝a−1).
LATE EVOLUTION
We can also describe the evolution during the gravitational and cosmological ages,
when photons, neutrinos, and pressure can be ignored.38 The space-space part of the
Einstein tensor [Eq. (28.47d)] gives
˜′′ + (3 −q) ˜′ + (1 −2q) ˜ = 0,
(28.54)
where q = 1
2 −3ρ /2ρ is initially ∼1
2. This says that the Fourier transform of the
slow potential evolution
potential ˜ is almost constant until the cosmological constant becomes important;
then it decreases to ∼0.80 times its starting value (Fig. 28.12). The density and velocity
38. Photons and neutrinos contribute small corrections right after recombination, and there are transients
associated with the sudden decrease of the coupling of baryons to photons. These are preserved in the
full solution below but can be ignored in this approximate treatment.
28.5 Galaxy Formation
1405

potential perturbations for β ≫1 [cf. Eqs. (28.53)] are
growth of density
perturbations
˜δM ≡˜ρM
ρM
= ˜ρD + ˜ρb
ρD + ρb
∼−3β2 ˜
1 + q ;
˜ψM ∼−31/2
1 + q ( ˜′ + ˜)
(28.55)
for short wavelengths β ≫1, where we have introduced the relative matter pertur-
bation ˜δM, which grows ∝β2 ∝a in accord with Poisson’s equation until ρ takes
over and the growth rate is reduced. The velocity potential ˜ψM is that of the matter
(baryons and dark matter). Note also that, although this potential is always small, the
density ﬂuctuation ˜δM becomes nonlinear for large β. The resulting corrections must
be computed numerically.
SUMMARY
We have described the early evolution of linear perturbations that were frozen until
they entered the horizon and became sound waves with constant ˜δ and the universe
could no longer be approximated as a single relativistic ﬂuid. We have also outlined
the growth of matter perturbations when galaxies are visible—speciﬁcally when 0.1<∼
a < 1. To connect these two limits, we must examine the behavior of the separate
perturbations to dark matter, neutrinos, photons, and baryons.
28.5.2
28.5.2 Individual Constituents
DARK MATTER
Because the nongravitational interactions of dark matter, neutrinos, baryons, and
photons are negligible during the epoch of galaxy formation, we handle the evolu-
tion of the different constituent perturbations by equating the 4-divergence of their
dark matter density
perturbation and velocity
potential
individual stress-energy tensors to zero in the given spacetime.39 Dark matter has
no pressure, so the nonzero, mixed, orthonormal stress-energy tensor components
are ˜T ˆt ˆt
D = ρD ˜δD, ˜T ˆt ˆ∥
D = ρD ˜vD = iβρD ˜ψD. Setting its divergence to zero leads to two
independent equations:
˜δ′
D −3 ˜!′ −31/2β2 ˜ψD = 0;
˜ψ′
D + (1 + q) ˜ψD + 31/2 ˜ = 0,
(28.56)
where we have used the conservation law ρ′
D + 3ρD = 0 [cf. Eq. (28.19)].
Importantly for what follows, we can derive the ﬁrst of Eqs. (28.56) from the ﬂux
of dark matter particles, (ρD/mD)[1 + ˜δD, ˜vD] in orthonormal coordinates, setting
its divergence to zero.
What is the initial dark matter density perturbation? It could have been quite in-
dependent of the perturbation to the photons, neutrinos, pairs, etc. However, the
simplest assumption to make is that it just depended on local physics and that equi-
librium was established on a timescale short compared with the expansion time.40
39. The derivations in this section are only sketched. Conﬁrming them will take some work.
40. It is not necessary that the initial conditions be established simultaneously—for example, during
inﬂation—only that they be ﬁxed before the neutrinos start to decouple (when a ∼10−11) and before
the pairs annihilate (a ∼10−9).
1406
Chapter 28. Cosmology

Equivalently, the number of photons per dark matter particle ∝ρ3/4
γ /ρD was a ﬁxed
number and so, using Eqs. (28.53), ˜δD(0) = 3
4 ˜δγ(0) = −3
2 ˜(0). Using a similar argu-
ment we can deduce that ˜δb(0) = ˜δD(0), ˜δν(0) = ˜δγ(0).This type of perturbation is
adiabatic perturbations
called adiabatic and is found to describe the observations very accurately, vindicating
our trust in basic principles. The initial velocity potential perturbation, common to
all constituents, is ˜ψD(0) = −(31/2/2) ˜, from Eqs. (28.53).
NEUTRINOS
Neutrinos add pressure but are effectively massless and travel at the speed of light
until recent epochs, and are collisionless after decoupling. Let us throw caution to
the winds and follow our treatment of a warm plasma (Sec. 22.3.5) to develop a ﬂuid
model. We set
ﬂuid approximation
˜T ˆt ˆt
ν = ρν ˜δν,
˜T ˆt ˆ∥
ν = 4ρν ˜vν/3,
˜T ˆ∥ˆ∥
ν
= ˜T ˆ⊥ˆ⊥
ν
= ρν ˜δν/3.
(28.57)
When we set the divergence of the neutrino stress-energy tensor to zero, we
obtain two equations for the perturbations. These equations are the same as those
that we would have gotten if we had treated neutrinos as collisional and would lead
to oscillations after the mode entered the horizon. However, the neutrinos can free
stream through the mode to damp δν and ψν. If we ignore the potential ˜ and imagine
starting with a simple sine wave, we can use Jeans’ theorem to solve approximately
for the time evolution of the distribution function. We ﬁnd that the wave will decay
in a time ∼2a/k. A neutrino wave initialized in this fashion and with no other
perturbationswouldthendecayaccordingtoδ′
ν ∼−βδν, δψ′
ν ∼−βδψν.Wetherefore
add these terms to the perturbation equations to account for free-streaming. The ﬁnal
results are:
˜δ′
ν −4 ˜!′ −(4/31/2)β2 ˜ψν = −β ˜δν;
˜ψ′
ν + q ˜ψν + 31/2 ˜ + (31/2/4)˜δν = −β ˜ψν.
(28.58)
BARYONS AND PHOTONS
Prior to recombination at the end of the plasma age, the photons and baryons were
baryon-photon coupling
tightly coupled by Thomson scattering and behaved as a single ﬂuid with the photons
dominating the density. The baryons were therefore prevented from falling into dark-
matter gravitational potential wells. However, around the time of recombination,
the baryon density grew larger than the photon density, and the photon mean free
paths lengthened, causing the photon-baryon ﬂuctuations to damp through heat
Silk damping
conduction and viscosity (Sec. 18.2). This effect is known as Silk damping (Silk, 1968).
If there were no cold dark matter, structure would have been erased on small scales
and we would have had to ﬁnd some other explanation for galaxy formation. Instead,
as baryons released themselves from photons, they fell into potential wells formed by
the dark matter. It is this complex evolution that we must now try to address.
The baryons are relatively easy. They can be treated as a cold ﬂuid, just like the
dark matter (because their pressure is never signiﬁcant in the linear regime), with a
single ﬂuid velocity ˜vb = iβ ˜ψb parallel to k (because the ions and electrons must have
28.5 Galaxy Formation
1407

net zero charge density on all scales larger than the Debye length; Sec. 20.3). Their
conservation law can be obtained by setting the divergence of the ﬂux of baryons to
zero just like we did for dark matter, Eq. (28.56):
baryon density evolution
˜δ′
b −3 ˜!′ −31/2β2 ˜ψb = 0.
(28.59)
Now turn to the photons. Just as with the neutrinos, the photons contribute ργ ˜δγ
to the energy density and 1
3ργ ˜δγ to the pressure. Initially, they shared the baryon
velocity and so also contributed a term 4
3ργ ˜vb to the momentum density/energy
ﬂux. Under the diffusive approximation, their heat ﬂux in the baryon rest frame is
−ikργ ˜δγ/(3neσT a), where we do not have to worry about frequency shifts of the
photons. We now deﬁne a photon velocity potential, ˜ψγ, in the frame of the FOs, by
equating the photon heat ﬂux to (4i/3)βργ( ˜ψγ −˜ψb) [cf. Eq. (28.48a)]. However, this
heat ﬂux
relation breaks down when the photon mean free path approaches the wavelength of
theperturbation.Theheatﬂuxwillthenbelimitedby∼ργ ˜δγ/3, andwesimplymodify
the photon velocity potential by adding a ﬂux-limiter:
˜ψγ = ˜ψb + 31/2˜δγ/4(τ ′
T −31/2β),
(28.60)
substituting the Thomson optical depth from Eq. (28.42). The combined baryon-
photon energy ﬂux in the FO frame is then ˜T ˆt ˆ∥
bγ = iβ(ρb ˜ψb + 4ργ ˜ψγ/3).
We can now take the divergence of the stress-energy tensor to obtain
˜δ′
γ −4 ˜ψ′ −4β2 ˜ψγ/31/2 = 0,
ρb[ ˜ψ′
b + (1 + q) ˜ψb + 31/2 ˜]+ (4/3)ργ[ ˜ψ′
γ + q ˜ψγ + 31/2 ˜ + 31/2˜δγ/4]= 0.
(28.61)
As with the neutrinos, accurate calculation mandates a kinetic treatment (Ex. 28.12;
need for kinetic treatment
Sec. 28.6.1), but this simpliﬁed treatment captures most of the kinetic results.
SUMMARY
We have now derived a complete set of linear equations describing the evolution of
a single mode with wave vector k. These equations can be used over the observable
range, 10−4 <∼k/H0 <∼0.3, and for the whole range of evolution for 10−11 < a < 1,
although different terms are signiﬁcant during different epochs, as we have described.
We next turn to the solution of these equations.
EXERCISES
Exercise 28.13 Challenge: Kinetic Treatment of Neutrino Perturbations
The ﬂuid treatment of the neutrino component would only be adequate if the neutri-
nos were self-collisional, which they are not.41 The phenomenon of Landau damping
(Sec. 22.3) alerts us to the need for a kinetic approach. We develop this in stages.
41. If we were to introduce shear stress, then viscous damping should also be included (cf. the discussion of
stars in Sec. 3.7.1).
1408
Chapter 28. Cosmology

Following the discussion in Sec. 3.2.5, we introduce the neutrino distribution
function ην(t, xi, pj), where xi is the (contravariant) comoving (spatial) coordinate,
and pj is the (covariant) conjugate 3-momentum (Sec. 3.6, Box 3.2, and Ex. 4.1). The
function ην satisﬁes the collisionless Boltzmann equation [Eq. (3.65)]:
∂ην
∂t + dxi
dt
∂ην
∂xi +
dpj
dt
∂ην
∂pj
= 0.
(28.62)
We work with this equation to linear order.
(a) Show that the neutrino equation of motion in phase space can be written as
dχi
dt =
pi
a(t)(pkpk)1/2(1 +  + !);
dpj
dt = −(pkpk)1/2
a(t)
∂( + !)
∂xj
,
(28.63)
and explain why it is necessary to express the right-hand sides in terms of t, xi,
and pi.
(b) Interpret the momentum equation in terms of the expansion of the universe
(Sec. 28.2.3) and gravitational lensing (Sec. 7.6.1).
(c) IntroducelocallyorthonormalcoordinatesintherestframeoftheFOs, anddeﬁne
p ˆα = {E, pˆ1, pˆ2, pˆ3}. Carefully interpret the density, velocity, and pressure in this
frame, remembering that it is only necessary to work to linear order in .
(d) Multiply the Boltzmann equation successively by 1, E, and pˆi, and integrate over
the momentum space volume element dpˆ1dpˆ2dpˆ3 to show that
˜δ′
nν −3 ˜!′ + 31/2iβ . ˜Sν = 0;
˜δ′
ν −4 ˜!′ + 4iβ
31/2 ˜vν = 0;
i˜v′
ν −31/2β
*
˜δν
4 + ˜ + ˜!
+
,
(28.64)
where ˜δnν is the fractional ﬂuctuation in neutrino number density, and ˜Sν is the
associated number ﬂux. In deriving these equations, it is necessary to impose
the same closure relation (cf. Sec. 22.2.2) as was used to derive the ﬂuid equa-
tions (28.57).42 These kinetic equations have the same form as the ﬂuid equations,
although the coefﬁcients are different and would change again if we changed the
closure relation. This demonstrates that ﬂuid equations can only be approximate,
even when derived using the Boltzmann equation.
(e) One standard way to handle the neutrino perturbations accurately is to expand
the distribution function in spherical harmonics. Outline how you would carry
this out in practice, and how you would then use the more accurate neutrino
distribution to improve the evolution equation for the dark-matter, baryon, and
photon components.
42. Thus the trace of the stress-energy tensor vanishes in all Lorentz frames.
28.5 Galaxy Formation
1409

Exercise 28.14 Problem: Neutrino Mass
Neutrinos have mass, which becomes measurable at late times through its inﬂuence
on the growth of structure.
(a) Explain how the expansion of the universe is changed if there is a single dominant
neutrino species of mass 100 meV.
(b) Modify the equations for neutrino phase-space trajectories described in the pre-
ceding problem to allow for neutrino rest mass, and outline how this will affect
the growth of perturbations.
(c) Describe how you could, in principle, measure the individual neutrino masses
using cosmological observations. (In practice, this would be extremely difﬁcult.)
28.5.3
28.5.3 Solution of the Perturbation Equations
GROWTH VECTOR
If we ignore shear stress and equate ! to  [as discussed after Eq. (28.47d)], we have
eight ﬁrst-order, coupled, linear differential equations [Eqs. (28.50), (28.56), (28.58),
(28.59), and (28.61)] plus an algebraic equation (28.60), describing the evolution of
small perturbations in the presence of a single wave mode. A simple reorganization
gives
linear growth of
perturbations
˜Υ ′ = M ˜Υ ,
(28.65)
where ˜Υ = { ˜, ˜δD, ˜ψD, ˜δν, ˜ψν, ˜δb, ˜!b, ˜δγ , ˜ψγ} is dimensionless, and the elements
of the matrix M are all real functions of a that we have already calculated and that
describe the unperturbed universe. The solution of Eq. (28.65) can be written as ˜Υ =
Γ (a, k) ˜(0, k), whereΓ isthegrowthvector foradiabaticperturbations,initializedby
Γ (0, k) =
,
1, −3
2, −31/2
2 , −2, −31/2
2 , −3
2, −31/2
2 , −2, −31/2
2
-
.
(28.66)
[Note that we here switch from the scaled wave vector β, Eq. (28.48b), to its unscaled,
comoving form k, as that is what we will need in using the growth vector.]
In the above equations and analysis, we have neither allowed for uncertainty in the
governing parameters nor the addition of speculative physical processes (Ex. 28.26).
We have also ignored nonlinear corrections (cf. Sec. 23.2, Ex. 28.15). Nonetheless, in
their domain of applicability, these equations allow us to exhibit much that is observed
and measured (Fig. 28.13).
POTENTIAL POWER SPECTRUM
What determined the initial amplitudes ˜(0, k)? It turns out that a simple early
conjecture43 accounts very well for a large number of independent cosmological mea-
43. First proposed by Harrison (1970), who considered the mode amplitudes when they entered the horizon,
not when they were initialized much earlier, as we shall do. The idea was put on a more general footing
by Zel’dovich (1972); see also Peebles and Yu (1970).
1410
Chapter 28. Cosmology

2
0
–2
–4
–6
–8
–4.5
–4.0
11
12
13
"
δD
δν
δγ
ψγ
δb
ψD
ψν
ψb
–3.5
–3.0
–2.5
log t (s)
ΓΓ
log a
FIGURE 28.13 Variation of the growth vector Γ for one choice of wave number keq = 78H0, which
enters the horizon, β = 1, when the universe becomes matter dominated (a = aeq = 0.00030;
log aeq = −3.52). The solid black line is the potential perturbation; the dashed lines are the density
perturbations, δ; the dotted lines are the velocity potential perturbations. The potential decreases
slowly as the universe expands through the radiation, plasma, and atomic ages. The dark matter
density perturbation starts to grow ∝a after it enters the horizon. By contrast, the neutrino and photon
perturbations, being hot, do not fall into the dark matter potential wells. The baryon perturbations
are initially coupled to the photon perturbations, as can be seen by their common velocity potentials,
but after recombination, they are released to fall into the dark matter potential wells. The model for
the neutrino and photon perturbations is decreasingly realistic after recombination but irrelevant for
our purpose here, and so is not shown.
surements. The conjecture is that the initial metric perturbations were scale invariant
and isotropic.To explain what this means, adopt the formalism developed in Sec. 6.4,
and imagine an ensemble of universes44 deﬁning a dimensionless power spectrum of
potential ﬂuctuations P(a, k). Speciﬁcally, we deﬁne [cf. Eq. (6.31)]
⟨˜(a, k) ˜∗(a, k′)⟩= (2π)3P(a, k)δ(k −k′) = (2π)31(a, k)2P(0, k)δ(k −k′).
(28.67)
Henceforth, we use ⟨.⟩to denote an ensemble average; all other averages that can be
ensemble average
computed by integrating known functions over position, angle, frequency, etc. will
44. Of course, we only have one universe to observe, but when we study many small regions, the average
properties are well deﬁned. By contrast, when we examine large regions, the cosmic variance is also large,
and no matter how precisely we make our measurements, there is a limit to how much we can learn about
the statistical properties of the ensemble.
28.5 Galaxy Formation
1411

be denoted by an overbar. Scale invariance is the assertion that P(0, k) ∝k−3.45
Equivalently, the primordial contribution to ⟨2⟩from each octave of k is a constant:
⟨2⟩k ≡
 k
2π
3
P(k) ≡Q = const.
(28.68)
Observations of the CMB and galaxies imply that the dimensionless quantity Q, the
initial cosmic noise
initial cosmic noise, is 1.8 × 10−10.46
In general, a power spectrum does not capture all possible statistical properties
of noise. However, in this case a stronger statement was conjectured—that the initial
amplitudes of individual Fourier modes had a Gaussian distribution with zero mean,
Gaussian ﬂuctuation
spectrum
constant variance, and random phases (implying no covariance and no need for any
other independent statistical measures beyond Q; cf. Secs 6.3.2 and 6.3.3).
We can now employ the Wiener-Khintchine theorem (Sec. 6.4) to obtain a sym-
metric correlation matrix:
correlation matrix
Cij(s, a) ≡⟨ϒi(a, χ + s)ϒj(a, χ)⟩= Q

d3k
4πk3eik.si(a, k)j(a, k)
(28.69)
(cf. Ex. 9.8). Many entries in this matrix have been veriﬁed observationally, thereby
validating the remarkably simple physical model that we have outlined. The birth of
the universe was accompanied by a hum, not a fanfare!
SUMMARY
We have set up a general formalism for describing, approximately and linearly, the
growth of perturbations under general relativity in the expanding universe all the
way from neutrino decoupling to the present day. The principal output is the evo-
lution of the potential functions !,  and the accompanying density perturbations
through recombination and after reionization. This provides a basis for a more careful
treatment of the photons, to which we turn in Sec. 28.6, and the observed clustering
of galaxies, which we now address.
28.5.4
28.5.4 Galaxies
SURVEYS
Much of what we have learned about cosmology has come from systematic surveys
observations of galaxies
of distant galaxies over large areas of sky. As we have emphasized (cf. Sec. 28.2.1),
galaxiesarenotwellstandardized; theyaremorelikepeoplethanelementaryparticles!
However, it is possible to average over this diversity to study their clustering. To date,
45. This spectrum may be thought of as the (3-dimensional) spatial generalization of ﬂicker or “1/f ” noise
that is commonly measured in time series, such as music (Sec. 6.6.1). The common property is that there
are no characteristic spectral features, and the power diverges logarithmically at both small and large
scales. The measured spectrum has slightly more power at small k, as we discuss in Sec. 28.7.1.
46. For reasons that make perfect sense to astronomers, the conventional normalization is expressed as
the rms relative density ﬂuctuation in a sphere of radius 11Mpc, assuming linear evolution of the
perturbations. This quantity, known as σ8, has the value ∼0.82.
1412
Chapter 28. Cosmology

roughly a billion galaxies (out of the roughly one trillion that are observable) have had
their positions, shapes, and ﬂuxes measured in a few spectral bands. Over a million
of these have had their spectra taken, so their distances can be determined using the
Hubble law.
GALAXY POWER SPECTRUM
The power spectrum of density perturbations in the gravitational and cosmological
ages, PM(a, k), deﬁned by ⟨˜δM(a, k)˜δ∗
M(a, k′)⟩= (2π)3PM(a, k)δ(k −k′), can be
simply related to the power spectrum for the gravitational perturbations P(a, k) [the
evolved Eq. (28.68)] using Eqs. (28.55). If we also assume that, despite the different
evolution of baryons and dark matter, the space density of galaxies is directly propor-
tional to their combined density,47 then we can use galaxy counts to measure the total
matter power spectrum. The computed power spectrum is exhibited in Fig. 28.14,
and its high-k region is explored in Ex. 6.7. Note that after recombination, the small-
scale (large k) structure was relatively more important than the larger-scale structure
in comparison with today. In other words, smaller groups of protogalaxies merged to
merging of galaxies and
groups
create larger groups as the universe expanded. This principle is also apparent before
reionization, when smaller, pregalactic dark matter halos merged to form larger halos,
which eventually made observable galaxies when the gas was able to cool and form
luminous stars.
To describe merging requires that we handle the perturbations nonlinearly. Mild
nonlinearity of evolution
nonlinearity can be handled by a variety of analytical techniques, but the best ap-
proach is to assume that the dark matter is collisionless and to perform N-body
numerical simulations, which can now (2016) follow over a trillion test particles.
These calculations can then be supplemented with prescriptions for handling the non-
gravitational behavior of the baryons on the smallest length scales as they cool to form
stars and massive black holes. This happened most vigorously when a ∼0.3. The cur-
rent incidence of small structure appears to be signiﬁcantly less than expected. This
may be a result of nongravitational effects, or it could signify a high-k cutoff in the
initial potential power spectrum [Eq. (28.68)].
BARYON ACOUSTIC OSCILLATIONS
The perturbations at recombination are basically sound waves whose amplitude de-
pends on the phase of the oscillation measured since the time when the wave mode
entered the horizon. As a result, at recombination (380 kyr), the amplitude oscillates
with the (comoving) wavelength. These oscillations are observed directly in angu-
lar ﬂuctuations of the CMB (see Fig. 28.15), where they are known as acoustic peaks.
Baryons were released from the grip of photons during recombination and fell into
dark matter potential wells. There should thus be preferred scales imprinted on the
47. This turns out to be a better approximation than might be imagined, but it fails on small scales, where
cooling and stellar activity become more important than gravity in determining what we see. These
effects are addressed by attempting to compute bias factors.
28.5 Galaxy Formation
1413

log [H0
3PM(k)]
log (k/H0)
k–1 (Gpc)
log a = 0
log a = 0
log a = –0.5
log a = –1
1.5
0.30
0.10
0.03
0.01
2.0
3.0
2.0
2.2
2.4
2.6
–6.0
–6.4
–6.8
2.5
1.0
–6
–7
–8
FIGURE 28.14 Matter ﬂuctuation power spectrum PM(k) for log a = −1, −0.5, and 0, corre-
sponding to recombination, reionization, the epoch of maximal galaxy and star formation,
and today, respectively. The spectrum demonstrates clearly that structure grows ﬁrst on small
scales, and it provides a fair description of the results of large-scale galaxy surveys. Note the
wiggles in the power spectrum for 2 < log(k/H0) < 2.7, shown more clearly in the inset for
log a = 0. These are baryon acoustic oscillations—echoes of the acoustic oscillations observed
using CMB measurements at recombination.
distribution of galaxies we see around us today. These baryon acoustic oscillations are
very important, because they allow astronomers to follow the expansion of a comov-
ing ruler over time—in other words, to measure a(t). As we shall see, the calibration
length at recombination is very well determined by observations of the radiation
(Sec. 28.6.1). Baryon acoustic oscillations can be seen in the angular correlation func-
tions measured in large galaxy surveys and also in studies of the radial velocities of
these galaxies.
EXERCISES
Exercise 28.15 Example: Nonlinearity
Explore nonlinear effects in the growth of perturbations in the gravitational age—
when radiation and the cosmological constant can be ignored—by considering the
evolution of a sphere in which the matter density is uniform and exceeds the external
density by a small quantity.
(a) Use the Friedmann equations (28.16), (28.18), and (28.19) to show that the
sphere behaves like a universe with density greater than the critical density
and stops expanding when its density exceeds the external value by a factor of
9π2/16.
1414
Chapter 28. Cosmology

(b) Assume that the perturbation remains strictly spherical, and determine by what
additional scale factor the external universe will have expanded when the pertur-
bation collapses to a point.
(c) Argue
that
realistic
perturbations
behave
quite
differently,
that
non-
spherical perturbations grow during the collapse, and that the infall kinetic
energy effectively randomizes during the collapse. Show that the collapse stops
when the radius of the sphere is roughly half its maximum value and that this
occurs when the average density exceeds that in the still-expanding external uni-
verse by a factor of ∼150.
28.6
28.6 Cosmological Optics
28.6.1
28.6.1 Cosmic Microwave Background
OVERVIEW
So far, we have emphasized the dynamical effects that govern the evolution of small
perturbations in the expanding universe and have shown how these lead to a statistical
description of the potential, density, and velocity perturbations. We now consider
the effect of these perturbations on extragalactic observations where the radiation
propagates passively through them. We start with the CMB. As we have explained
in Sec. 28.4.4, most of the action happens at recombination—over an interval of time
short compared with the age of the universe—when free electrons are rapidly captured
and retained by protons and the rate of Thomson scattering plummets. We need to
describe photons as they transition from belonging to a perfect ﬂuid to uninterrupted,
radiative transfer
free propagation along null geodesics. We then discuss the statistical properties of the
relative temperature and polarization ﬂuctuations.
MONTE CARLO RADIATIVE TRANSFER
The standard way to compute the radiative transfer is to generalize the moments of the
Boltzmann equation (28.64) to include baryon motion and the potentials ˜ and ˜!.
Hundreds of spherical harmonics are necessary to achieve the requisite accuracy. As
we have already discussed many calculations of this general character in the preceding
chapters, we shall elucidate the underlying physical processes by using a Monte Carlo
description (cf. Sec. 5.8.4). Monte Carlo methods are often used for problems that are
too complex for a Boltzmann approach.
To do this, we ﬁrst ignore the perturbations and follow backward in time a photon
observed by us, today (at time t0), with initial direction n and polarization (elec-
tric ﬁeld unit vector) ˆE. (The backward transition probabilities are just the same
as for the actual, forward path.) We then assign the Thomson optical depth to the
Thomson optical depth
ﬁrst scattering (going backward) according to τT = −ln R1, where R1 is a ran-
dom number distributed uniformly in [0, 1]. Using the discussion in Sec. 28.4.4, we
associate this optical depth with the location of the scatterer in spacetime, which is
28.6 Cosmological Optics
1415

speciﬁed by t1 and χ1 = n
 t0
t1 dt/a. The differential cross section for electron scat-
tering into direction n1 is dσ/d = r2
e(1 −μ2
s), where re is the classical electron
radius, and μs = ˆE . n1 (e.g., Jackson, 1999).48 The cumulative probability distribu-
scattering probability
tion for μs is (3μs/4 −μ3
s/4 + 1/2), and so we equate this to another uniformly
distributed random number R2 and solve for μs. The scattered photon’s azimuth is
polarization
likewise assigned as 2πR3, with R3 a third random number uniform on [0, 1], and
the new polarization vector ˆE1 is along the direction of (ˆE × n1) × n1. We iterate
and trace the photon path backward until the scatterings were so frequent that the
evolution of the radiation can be treated as adiabatic. This happened at time tad and
location χad.
Having determined the path, we consider a photon traveling forward along it.
According to Eq. (28.63) with  = ! = 0, the covariant momentum pi is constant
between scatterings, and so the photon’s frequency is ν ∝a−1. This frequency is
unchanged by scattering, as the electrons are assumed to be at rest with respect to
the FOs. When we repeat this exercise many times, we ﬁnd no net polarization to
statistical accuracy, as we must.
We now switch on a single perturbation with wave vector k. [It is helpful to
express the perturbation’s ! and  as standing waves rather than running waves;
cf. the passage following Eq. (28.46).] And we make the approximation that ! = 
[i.e., we neglect gravitational effects of anisotropies in the free-streaming photon
and neutrino stresses; see passage following Eq. (28.47d).] We need to calculate the
linear relative frequency shift δν ≡δν/ν induced by the perturbation for a photon
propagating forward in time along the above path, superposing four effects. The ﬁrst
is that the perturbation mode changes the initial frequency through the radiation
starting frequency shift
density perturbation, the Doppler shift associated with the baryon velocity, and the
gravitational frequency shift (Sec. 25.9). Speciﬁcally, δν = 1
4 ˜δγ(tad) −nad . ˜vb(tad) +
˜(tad). The second effect is more subtle. The proper time (age of the universe)
at the start of the path differs from that of an FO in a homogeneous universe by
starting time shift
δ˜t =
 tad
0
dt ˜(t) (cf. Eq. 28.44). Since the universe is expanding according to local
laws, the local scale factor (as measured, for example, by the local temperature) is
modiﬁed by δ ˜a/a = Hδ˜t; and correspondingly, the frequency of the photon moving
along the above Monte Carlo path is modiﬁed by δν = −H(tad)
 tad
0
dt ˜(t).49
The third effect is related to the second one. The scattering rate is neσ(1−ni . ˜vb),
and its perturbation leads to a change in the propagation time and consequently to
48. The Compton recoil is ignorable, and so the Thomson cross section sufﬁces.
49. This is known as the Sachs-Wolfe effect (Sachs and Wolfe, 1967). The largest inﬂuence on the pho-
ton frequency comes from long-wavelength (low-k) gravitational perturbations, for which ˜—which
arises from dark matter—is nearly time independent during 0 < t < tad. Combining this with the value
H(tad) = 2/(3tad) in the plasma age, we obtain for the second effect δν = −2
3 ˜(tad). And adding this to
our ﬁrst effect’s gravitational frequency shift δν = + ˜(tad), we obtain a combined direct gravitational
frequency shift δν = + 1
3 ˜(tad).
1416
Chapter 28. Cosmology

the time and frequency at the start of the path. The baryon density perturbations ˜δb
induce relative electron density perturbations ˜δe. They can be estimated using
ionization shift
˜δe =
∂ln(npx)
∂ln nb

˜δb + 1
4
*
∂ln(npx)
∂ln Tγ
+
˜δγ ,
(28.70)
where x is the ionization fraction (Sec. 28.4.4), and the partial derivatives are com-
puted at the recombination surface using the formalism of Sec. 28.4.4. (A more careful
treatment includes many more atomic processes.) When the scattering rate increased
and the total duration of the path decreased, the universe became colder, which
contributes a negative frequency shift δν = −
 t0
tad dtHτ ′
T [˜δe + n(t) . ˜vb]/τ ′
T (tad). The
fourth and ﬁnal effect is the Doppler shift applied at each scattering: δν = !
i(ni −
Doppler shift
ni−1) . ˜v(ti).
Now, the point of the Boltzmann equation is that the photon distribution function
ηγ = {exp[hν/(kBTγ)]−1}−1isconservedalongatrajectoryinphasespace(Sec.3.6).
Furthermore, it is not changed by scattering in the electron rest frame or by Lorentz
transformation into and out of this frame. Therefore, the relative temperature ﬂuc-
temperature ﬂuctuation
tuation, which is what is actually measured, satisﬁes δTγ ≡δT = ⟨δν⟩, averaging over
the sum of the four contributions.
We can also consider the effect on the polarization. The natural basis for the
electric vector is ea = k × n/|k × n| and eb = n × ea, and we expect any measured
polarization to be perpendicular or parallel to the projection of k on the sky. (See
polarization
Ex. 28.16.) However, vb is along k, and transforming into and out of the electron rest
frame does not rotate the polarization vector in the {ea, eb} basis. And the inﬂuence
of gravitational deﬂections on the polarization is also negligible.
SPHERICAL HARMONIC EXPANSION
The Monte-Carlo calculation that we have just outlined allows us to compute the
expected temperature ﬂuctuation and write it in the form
˜δT (n, k) = Tk(n . ˆk) ˜(0, k)
(28.71)
where Tk is the initial potential-temperature transfer function. As Tk is deﬁned on a
sphere, it is natural to expand it in Legendre polynomials, the functional equivalent
of a Fourier series:
Tk(n . ˆk) =
∞
 
l=0
TklPl(n . ˆk),
where
Tkl = (2l + 1)
2
 1
−1
d(n . ˆk)TkPl(n . ˆk).
(28.72)
We are interested in the cross correlation of the temperature ﬂuctuations
⟨δT (n)δT (n′)⟩, where the average is over all directions n, n′ separated by a ﬁxed angle
and we take the ensemble average over perturbations using Eqs. (28.67), (28.68). This
28.6 Cosmological Optics
1417

must depend only on that angle and can therefore be expanded as another sum over
Legendre polynomials:50
expansion in Legendre
polynomials
⟨δT (n)δT (n′)⟩=

d3k
(2π)3P(0, k)
 
l, l′
TklT ∗
kl′⟨Pl(ˆk . n)Pl′(ˆk . n′)⟩
=

d3k
(2π)3P(0, k)
∞
 
l=0
|Tkl|2Pl(n . n′)
2l + 1 .
(28.73)
This is the functional equivalent of the Wiener-Khintchine theorem (Sec. 6.4.4). It is
conventional to express ⟨δT (n)δT (n′)⟩in terms of the total multipole coefﬁcient Cl:
⟨δT (n)δT (n′)⟩=
∞
 
l=0
2l + 1
4π T 2
γ o
Cl Pl(n . n′) ;
(28.74a)
Cl =
4πT 2
γ 0
(2l + 1)2

d3k
(2π)3 P(0, k)|Tlk|2
=
16π2 Q T 2
γ 0
(2l + 1)2
 ∞
0
d ln k |Tlk|2 ,
(28.74b)
where we have used the scale-invariant form (28.68) of the initial perturbation
spectrum P(0, k).
REIONIZATION SCATTERING
The rapid increase in electron density and Thomson scattering following reionization
inﬂuence of intervening
electrons
at the end of the atomic age (see Fig. 28.8) can actually be detected in the observations
of the CMB and is described by essentially the same equations that we used for
recombination. The Thomson optical depth, backward in time from us through
reionization (as deﬁned in Sec. 28.4.4) averages to τT ∼0.066.
INTEGRATED SACHS-WOLFE EFFECT
Another late-time effect is better described in conﬁguration space. Consider a photon
inﬂuence of intervening
structure
crossing a large negative gravitational potential well, associated with an excess of
matter during the cosmological age. The cosmological constant causes the potential
perturbation to decrease [cf. Eq. (28.54)] while the photon crosses it and so the photon
loses less energy climbing out of it than it gained by falling into it, so there is a net
positive temperature ﬂuctuation. This is most apparent at long wavelengths and is
most easily detected by cross-correlating the matter distribution with the temperature
ﬂuctuations.
GRAVITATIONAL LENSING
As we describe in more detail in Sec. 28.6.2, the gravitational deﬂection of rays
crossing the universe leads to the distortion of the images of background sources. Of
50. To verify this identity, consider the special case n = n′.
1418
Chapter 28. Cosmology

μK 2
l(l + 1)Cl
—
2π
log l
ϑ (deg)
1.0
1.5
2.0
2.5
3.0
10.0
3.0
1.0
TT
10TE
100EE
0.3
6,000
5,000
4,000
3,000
2,000
1,000
0
–1,000
–2,000
FIGURE 28.15 Theoretical spectra for anisotropy of the microwave background ﬂuctuations
as measured by the coefﬁcients Cl, where l is the spherical harmonic quantum number
as deﬁned in Eqs. (28.74). The curve labeled TT shows the Cls for the temperature
ﬂuctuations [Eqs. (28.74); multiplied by l(l + 1)/(2π)]; that labeled EE shows the Cls for
the E-mode polarization ﬂuctuations; and that labeled TE shows the Cls for the temperature-
polarizationcrosscorrelation.ThesecurvesareadaptedfromtheoreticalcalculationsbyPlanck
Collaboration (2016b) for parameter values that best ﬁt the observations. The low-l portion of
the TT curve can be reproduced with the formalism presented in this section. The ﬂuctuations’
angular scale on the top axis is ϑ = 180o/l. Note the prominence of the ﬁrst “acoustic peak” at
l ∼200, which corresponds to waves that have reached maximum amplitude at recombination.
The large-angle ﬂuctuations with l <∼70 are basically gravitational redshifts associated with
perturbations that have not yet entered the horizon at the time of recombination. Modes with
l >∼300 are dominated by density changes. Velocity effects contribute heavily to intermediate
l harmonics. Ten of the predicted acoustic peaks have been measured in the TT spectrum out
to l ∼3,000. The observations agree extremely well with these predictions after correcting for
some additional effects listed in the text.
course this makes no difference to the appearance of a uniform background radiation.
However, it will change the ﬂuctuation spectrum. The formalism used is an adaption
of that developed below. This has turned out to be a powerful probe of intervening
structure and, consequently, an important consistency check on the standard model.
TEMPERATURE FLUCTUATION SPECTRUM
The theoretical temperature ﬂuctuation spectrum computed using more detailed
the spectrum of
temperature ﬂuctuations
calculations than ours (Planck Collaboration, 2016b) is shown in Fig. 28.15. It ﬁts
the observational data extremely well with only six adjustable parameters. Our Monte
Carlo results (not shown) roughly recover this spectrum for low l. The detailed ﬁt of
the observations to the theory is responsible for many of the features of the standard
model described earlier in this chapter.
28.6 Cosmological Optics
1419

POLARIZATION
A very important recent development has been the calculation and measurement of
polarization in the CMB. The calculation outlined above predicts that a single wave
perturbation will produce roughly 10% polarization along the projected direction of
k on the sky and also predicts that the polarization observed along neighboring direc-
tions will be correlated (Ex. 28.22). When we sum over all modes, expand in spherical
harmonics, and average over the sky, there is a net polarization signal of a few percent
and a cross correlation with the temperature spectrum (Fig. 28.15). Measurements
of these effects are used to reﬁne the standard model. A simple generalization of
Eq. (28.74b) gives the multipole coefﬁcients for the polarization as well as the cross
correlation with the temperature ﬂuctuations (Fig. 28.15).
Because this polarization arises from photon scattering in the presence of density
ﬂuctuations, itturnsouttohaveapatterndescribedbytensorsphericalharmonicsthat
are double gradients (on the sky) of scalar spherical harmonics; these are sometimes
called“electric-type”sphericalharmonics, andpolarizationpatternsconstructedfrom
them are called E-modes. Primordial gravitational waves, interacting with the plasma
during recombination, can catalyze a second type of polarization pattern called B-
modes, whose “magnetic-type” spherical harmonics are constructed by operating on
ascalarsphericalharmonicwithonegradient∇andoneangularmomentumoperator
L = eˆr × ∇. For some details of E-modes, B-modes, and other aspects of the predicted
polarization, see Ex. 28.22.
RADIATION STRESS-ENERGY TENSOR
The least satisfactory aspect of our treatment of the growth of perturbations is the
approximation of the radiation as a perfect ﬂuid. Our treatment of radiative transfer
allows one to reﬁne this approximation by including in Eq. (28.61) an estimate of the
anisotropic part of the photon stress-energy tensor.
EXERCISES
Exercise 28.16 Example: Stokes’ Parameters
There are many ways to represent the polarization of electromagnetic radiation
(Sec. 7.7). A convenient one that is used in the description of CMB ﬂuctuations was
introduced by Stokes.
(a) Consider a monochromatic wave propagating along ez with electric vector E =
{Ex, Ey}eiωt, where the components are complex numbers. Explain why this
wave is completely polarized, and introduce the Stokes’ parameters (following
Jackson, 1999) I = ExE∗
x + EyE∗
y, Q = ExE∗
x −EyE∗
y, U = 2ℜ(ExE∗
y), and
V = −2ℑ(ExE∗
y). Sketch the behavior of the electric vector as the complex ratio
r = Ey/Ex is varied, and hence associate Q, U, and V with different states of
polarization.
1420
Chapter 28. Cosmology

(b) Derive the transformation laws for the Stokes’ parameters if we rotate the ex, ey
directions about ez through an angle ψ.
(c) Show that Q2 + U2 + V 2 = I 2 and that the polarization of the wave may be
represented as a point on a sphere, which you should identify.
(d) Now suppose that the wave is polychromatic and partially polarized, and replace
the deﬁnitions of I, Q, U, and V with the time averages ⟨ExE∗
x⟩, and so forth.
ShowthatQ2 + U2 + V 2 < I 2, andgiveexpressionsforthedegreeofpolarization
and the associated position angle in terms of I, Q, U, and V .
Exercise 28.17 Problem: Cosmic Variance
The precision with which the low-l spherical harmonic power spectrum can be de-
termined observationally is limited because of the low number of independent mea-
surements that can be averaged over. Give an approximate expression for the cosmic
variance that should be associated with the CMB ﬂuctuation spectrum.
Exercise 28.18 Problem: Acoustic Peaks
We have explained how the peaks in the CMB temperature ﬂuctuation spectrum arise
because the sound waves all began at the same time and are all effectively observed
at the same time, while they entered the horizon at different times. Suppose that the
universe had been radiation dominated up to recombination, so that Eq. (28.51) is
valid and oscillatory waves of constant amplitude were created with different values
of k. Calculate the total relative density perturbation ˜δ(k) at recombination. Describe
the main changes in standard cosmology that are introduced.
Exercise 28.19 Example: Cosmic Dawn
The cosmic dawn that preceded the epoch of reionization can be probed by low-
frequency CMB observations using a special radio hyperﬁne line emitted and ab-
sorbed by hydrogen atoms. This line is associated with a ﬂip in direction of the mag-
netic dipole associated with the central proton relative to the magnetic ﬁeld created
by the orbiting electron. The line’s frequency and strength can be calculated using
quantum mechanics. For our purposes, all that we need to know is that the frequency
associated with the transition is νH = 1.42 GHz, the degeneracy of the ground/upper
state is 1/3, and the rate of spontaneous transition is A = 3 × 10−15 s−1 (Ex. 28.9).
(a) Explain why these hyperﬁne transitions should produce a change in the measured
CMB spectrum over a range of frequencies ∼20–150 MHz, where the lower limit
is due to the practicality of making the measurement.
(b) Consider hydrogen atoms with total number density n1 in the ground state and
n2 = 3n1 exp(−hνH/kBTS) in the excited state, where TS deﬁnes the spin temper-
ature,andwemeasurefrequenciesandrateslocally.Showthatthenetcreationrate
28.6 Cosmological Optics
1421

of photons per unit volume and frequency can be written as 3n1Aδ(ν −νH)(1 −
Tγ/TS). [Hint: TS, Tγ ≫hνH/kB.]
(c) Hence, show that the CMB temperature ﬂuctuation at frequency ν0 = νH/a,
produced when the expansion factor was a, is
δT =
 3
32π
 *
nH
ν3
H
+ 
A
H(a)

[1 −Tγ 0/Ts(a)],
where nH is the atomic hydrogen density, H(a) is the expansion rate, and Tγ 0
is the CMB temperature today while Tγ is the CMB temperature at the point of
emission.
(d) It is predicted that TS ∼10 K when a ∼0.05. Estimate the associated temperature
perturbation, δT .
The spin temperature Ts will follow the nonrelativistic gas and fall faster than the
radiation temperature Tγ (Sec. 28.2.3), creating absorption above ∼10 MHz. The
ﬁrst stars will heat the gas and create Lyman alpha photons (Sec. 28.4.4), which
end up populating the upper hyperﬁne state (cf. Sec. 10.2.1), increasing the spin
temperature and reducing the absorption above ∼50 MHz. Black holes are expected
to create highly penetrating X-rays, which may make Ts > Tγ and lead to emission
above 100 MHz. Eventually the gas will be fully ionized, so that the spectrum above
∼200 MHz should be unaffected.
At the lowest frequencies observable today, the radiation from our galaxy is ∼300
times brighter than the CMB and has to be carefully removed, along with the inﬂuence
of the ionosphere (cf. Sec. 21.5.4). Most attention is now (2016) focused on measuring
a signal associated with the growing density perturbations from the time just before
reionization. If the measurements are successful, we will have another powerful probe
of the growth of matter perturbations (Sec. 28.5.3).
28.6.2
28.6.2 Weak Gravitational Lensing
NULL GEODESIC CONGRUENCE
We introduced strong gravitational lensing in Sec. 7.6. Such lensing is important
for rare lines of sight where the galaxy-induced gravitational deﬂections of light
rays are strong enough to image background sources more than once. There is a
complementary effect called weak gravitational lensing,which is a consequence of the
weak lensing
growth of perturbations in the universe and is present for all images (e.g., Schneider,
Ehlers, and Falco, 1992). Basically, the tidal actions of gravitational perturbations
distort galaxy images, inducing a correlated ellipticity that we can measure if we
assumethatthegalaxies’intrinsicshapesarerandomlyorientedonthesky.Toquantify
this effect, we need to consider the propagation of neighboring rays through the
inhomogeneous universe, under the geometrical optics approximation.
1422
Chapter 28. Cosmology

What we actually do is a little more subtle and much more powerful. We consider
one ﬁducial ray and a congruence of rays that encircle it—a generalization of the
paraxial optics developed in Sec. 7.4. We imagine this congruence as propagating
backward in time from us, now (in a scholastically correct manner!), toward a distant
ray congruence
galaxy. We label rays that belong to the congruence by the vectorial angle ψ they
make with the ﬁducial ray here and now—what an astronomer observes. The ﬁducial
ray will follow a crooked path, but we are concerned with the proper transverse
separations of neighboring rays ξ(χ; ψ). This is a job for the equation of geodesic
deviation [Eq. (25.31)]. (For a more detailed analysis along the lines of the following,
see Blandford et al., 1991.)
As we have discussed in Sec. 25.4, we parameterize distance along a null geodesic
afﬁne parameter
using an afﬁne parameter ζ, which must satisfy dt/dζ ∝p0 [cf. Eq. (2.14)]. Now, p0
is the energy of a photon measured by an FO; in the homogeneous universe, this will
vary ∝a−1. A convenient choice for ζ is therefore
ζ(a) =
 t0
t(a)
dt′a(t′) =
 1
a
da′
H(a′) =
 χ(a)
0
dχ′a(χ′)2.
(28.75)
Notethatweusethescalefactorappropriatetotheunperturbeduniverseindeﬁningζ,
because the overall expansion of the universe is dictated by the behavior of the stress-
energy tensor TTT on the largest scales where it is, by assumption, homogeneous. The
associated tangent vector to use in the equation of geodesic deviation is dxα/dζ =
{a−1, 0, 0, a−2}.
The Riemann tensor for the perturbed metric (28.44), like the Einstein tensor
(28.47), is easily computed to linear order in the perturbations and then inserted
into the equation of geodesic deviation (25.31). In contrast to our treatment of the
CMB, for weak lensing we explicitly assume that the relevant perturbations are of
short wavelength and are effectively static when crossed by the photons we see today,
allowing us to use local Lorentz coordinates parallel-propagated along the ray with
ˆe3 aligned along the ray. Assuming that  = ! as dictated by the Einstein equations
(28.47d) for a perfect ﬂuid, and just retaining lowest order terms, the equation of
geodesic deviation becomes
equation of geodesic
deviation
a2d2ξi
dζ 2 −˙Hξi = −
2
,3
3ξi + 2,j
iξj3
= −
2
4πδρMξi + 2 ¯
i
,j ξj3
,
for i, j = 1, 2,
(28.76)
where we have used Poisson’s equation ,k
k + ,3
3 = 4πδρM and have introduced
thetrace-freetidaltensor ¯
i
,j ≡,j
i −1
2,k
kδj
i; andwherespatialindicesareraised
and lowered with the ﬂat metric, and all indices following a comma represent partial
derivatives.
28.6 Cosmological Optics
1423

CONVERGENCE AND SHEAR
It is instructive and helpful to express this equation in terms of comoving coordinates.
Substituting ξ →aη and dζ →a2dχ, we obtain51
d2ηi
dχ2 = −
2
4πδρMδj
i + 2 ¯
i
,j
3
a2ηj.
(28.77)
The right-hand side vanishes in the absence of perturbations, which is what we
expect, as the 3-space associated with the homogeneous universe is ﬂat (Sec. 28.2.2).
Equation (28.77), made linear by inserting the unperturbed ηi on the right-hand side,
admits a Green function solution:
η = ξ
a = χ[(1 −κ)I −γ] . ψ;
{κ, γj
i} =
 χ
0
dχ′

χ′ −χ′2
χ

a(χ′)2 A
4πδρM(χ′), 2 ¯
,i
,j (χ′)
B
.
(28.78)
Here ψ = (dξ/dζ)0 = (dξ/dχ)0 is the observed angular displacement from the ﬁdu-
convergence
cial ray, and I is the 2-dimensional unit tensor (metric). Also, we introduce the con-
vergence κ; it is the analog of the expansion that appears in the theory of elastostatics
(Sec. 11.2), and it is produced by matter density perturbations inside the congruence.
The quantity γ is the trace-free cosmic shear tensor produced by matter distributed
cosmic shear
anisotropically outside the congruence.
If we replace χ with dA/a, Eq. (28.78) appears to be a simple linear generaliza-
tion of the formalism introduced in our discussion of strong gravitational lensing
(Sec. 7.6). However, the equation of geodesic deviation is necessary to justify the ne-
glect of the cosmological constant, to handle the potential derivatives along the ray,
and to include large density perturbations.
Now we jump into k-space, write ¯ in terms of the Fourier transform ˜, and
express the two components of the distortion as:
distortion
{κ, γj
i} = −
 χ
0
dχ′

χ′ −χ′2
χ
 
d3k
(2π)3
,
k2, kjki −1
2klklδj
i
-
˜eik.χ′. (28.79)
The ﬁrst component is a scalar; the second is a tensor.52
CORRELATION FUNCTIONS
The ensemble average distortion vanishes, because the wave phases are random.
When we consider the convergence and shear along two congruences labeled 1, 2,
51. The cosmological constant does not contribute to the focusing, but we should include radiation and
neutrinos when considering weak lensing of the CMB.
52. Formally, κ should be a tensor with an antisymmetric part describing image rotation. In the case of
elastostatics, this term is dropped, because it induces no stress. Weak lensing rotation vanishes in the
linear, scalar approximation, but there is a tiny nonlinear contribution. In principle, an antisymmetric
part of κ could be created by a hypothetical cosmic torsion ﬁeld, which has been sought (unsuccessfully!)
using polarization observations.
1424
Chapter 28. Cosmology

and separated by an angle ϑ, the contribution from the products of different waves
likewise vanishes. Even the contribution from a single wave is small except when it is
directed almost perpendicular to the line of sight and we are integrating along its crest
or trough. We formalize these expectations by using the potential power spectrum
[Eq. (28.67)] and keeping faith with the magic of delta functions. Let us assume that
ϑ ≪1, so the sky can be treated as ﬂat, and introduce local basis vectors e|| parallel to
the separation of the congruences and e⊥perpendicular to the separation. We then
deﬁne two independent components of shear by γ+ ≡γ|||| −γ⊥⊥and γ× ≡2γ⊥||. The
convergence correlation function is Cκκ = ⟨κ1κ2⟩, where the average is over all pairs of
rays on the sky separated by an angle ϑ. We can likewise deﬁne correlation functions
involving the shear. Then the values of the nonzero correlation functions are
⎛
⎜⎜⎜⎜⎝
Cκκ
Cκ+
C++
C××
⎞
⎟⎟⎟⎟⎠
=
 χ
0
dχ′
 χ
0
dχ′′

χ′ −χ′2
χ
 
χ′′ −χ′′2
χ

×

d3k
(2π)3ei(k∥ϑχ′+k3(χ′−χ′′))P(a, k)
⎛
⎜⎜⎜⎜⎜⎝
k4
k2(k2
∥−k2
⊥)
(k2
∥−k2
⊥)2
4k2
∥k2
⊥
⎞
⎟⎟⎟⎟⎟⎠
.
(28.80)
(The vanishing of the two remaining averages provides a check on the accuracy of
the measurements.) As kχ ≫1, we approximate the integral over χ′′ by an inﬁnite
integral over χ′′ −χ′ to produce a delta function, which can then be integrated over
to obtain
⎛
⎜⎜⎜⎜⎝
Cκκ
Cκ+
C++
C××
⎞
⎟⎟⎟⎟⎠
=
 χ
0
dχ′

χ′ −χ′2
χ
2 
dk
2π k5P(a, k)
 2π
0
dφk
2π eikϑχ′ cos φk
⎛
⎜⎜⎜⎜⎝
1
cos 2φk
cos2 2φk
sin2 2φk
⎞
⎟⎟⎟⎟⎠
= (2π)2Q
 χ
0
dχ′

χ′ −χ′2
χ
2 
dk k22
1(a, k)
⎛
⎜⎜⎜⎜⎝
J0(kχϑ)
−J2(kχϑ)
1
2[J0(kχϑ) + J4(kχϑ)]
1
2[J0(kχϑ) −J4(kχϑ)]
⎞
⎟⎟⎟⎟⎠
,
(28.81)
where we have substituted the initial cosmic noise [Eq. (28.68)] for P, 1(a, k) is the
ﬁrst component of the growth vector Eq. (28.66), and J0, J2, J4 are Bessel functions.
The remaining integrals must be performed numerically; see Fig. 28.16. Note that
28.6 Cosmological Optics
1425

C++
C××
104Cij
Cκ+
Cκκ
ϑ (deg)
4
3
2
1
0.
2
1
0
–1
FIGURE 28.16 Two-point correlation functions for weak gravitational lensing for sources located
at log a = −0.5, calculated from Eq. (28.81) and adopting the growth factor1(a, k) calculated
numerically from Eq. (28.65). The cross correlation of magniﬁcation ﬂuctuations is Cκκ.
The correlation function for parallel stretching of galaxy images is C++. The correlation
function for stretching along a direction inclined at 45◦to the separation vector is C××. The
magniﬁcation-shear cross correlation is Cκ+.
C++ + C××, the total shear cross correlation, equals Cκκ, as can be seen directly from
shear correlation
Eq. (28.80) if we recall that k3 ∼0. Note also that C××(ϑ) can change sign. This effect
has been observed. The calculation is performed here in the linear approximation,
which breaks down for small scales, and so numerical simulations must be used in
practice.
These four correlation functions refer to galaxies at a ﬁxed distance. In practice, a
given survey averages over a range of distances and, by varying this range, can make
tomography
a tomographic examination of the growth of the potential power spectrum P.
STATISTICAL MEASUREMENT
How do we actually use observations of galaxies to measure convergence and shear?
Weak lensing does not change the intensity of radiation. Therefore a source’s ﬂux F
is determined by the solid angle it subtends. Using Eq. (28.78) to linear order, we see
ﬂux perturbation
that F/F = 2κ. Now, we do not know the intrinsic galaxy luminosities. However,
their distribution should be the same in different directions at the same distance if
the universe is homogeneous, and the predicted magniﬁcations have been measured.
Unfortunately, absorption in our galaxy and other problems limit the utility of this
approach. Conversely, Cκκ(0) is a measure of the variance of a ﬂux measurement
and a limit on how precisely a measurement need be made in a single case when
1426
Chapter 28. Cosmology

attempting to use “standard candles” (sources of known luminosity) to measure the
universe.
Statistical shear measurements are more useful. We expect the orientations of
intrinsic galaxy alignment
galaxies to be uncorrelated,53 and so, if we associate the ﬁducial ray with the center
of an observed galaxy, the tensor ⟨ξ ⊗ξ⟩should be proportional to the unit tensor.
Inverting the ﬁrst part of Eq. (28.78) then provides a linear estimator of the shear:
shear estimator
{γ+, γ×} =
⟨{ψ2
∥−ψ2
⊥, 2ψ∥ψ⊥}⟩
⟨ψ2
∥+ ψ2
⊥⟩
,
(28.82)
where the averages are over the photons associated with observed images of individual
galaxies and then over galaxies adjacent on the sky but at differing distances. This esti-
mator is quite general, and different types of source54 and weighting can be employed
in evaluating it observationally.
There are many observational challenges. For example, the dominance of Fourier
observing cosmic shear
modes with k almost perpendicular to the line of sight means that occasional struc-
tures elongated along the line of sight can hinder the measurement of an unbiased esti-
mate of the ensemble-averaged correlations. Despite this, cosmic shear measurements
are consistent with the predicted perturbation spectrum (28.68) and its evolution and
show great promise for future surveys that will image 20 billion galaxies.
EXERCISES
Exercise 28.20 Example: Weak Lensing in an Empty Universe
Consider an extended congruence propagating through an otherwise homogeneous
universe, from which all matter has been removed. Show that the afﬁne distance
functions as an effective angular diameter distance in this congruence. Now reinstate
the matter as compact galaxies and modify Eq. (28.79) for the convergence and shear.
Bookkeep the average density of matter as purely positive density perturbations.
Explain qualitatively how the convergence and shear are changed when the ray passes
through one or more galaxies, when it misses all of them, and on average.
Exercise 28.21 Problem: Mean Deviation
Consider a single light ray propagating across the universe from a source at log a =
−0.5 to us. The cumulative effect of all the deﬂections caused by large-scale inho-
mogeneities makes the observed direction of this ray deviate by a small angle from
the direction it would have had in the absence of the inhomogeneities. Estimate this
deviation angle. Is it large enough to be observable?
53. In fact, neighboring galaxies are systematically aligned, but provided we average over large enough
volumes, this is ignorable. In addition, systematic biases associated with telescope and atmospheric
distortion must be removed carefully.
54. For example, the CMB ﬂuctuations and the galaxy correlation function at the smallest angular scales can
be used.
28.6 Cosmological Optics
1427

Exercise 28.22 Challenge: CMB Polarization
Polarization observations of the CMB provide an extremely important probe of ﬂuc-
tuations in the early universe.
(a) By invoking the electromagnetic features of Thomson scattering by free electrons,
give a heuristic demonstration of why a net linear polarization signal is expected.
(b) Using the Monte Carlo formalism sketched in Sec. 28.6.1, calculate the polariza-
tion expected from a single ﬂuctuational mode ˜eiκ.χ of given amplitude.
(c) The description of polarization has many similarities with the formalism we have
outlined to describe cosmic shear. Linear polarization is unchanged by rotation
through π just like a shear deformation. In addition, the polarization pattern
that should be seen from a single inhomogeneity mode should have an electric
vector that alternates between parallel and perpendicular to the projection of
the mode’s wave vector k on the sky, just like the elongation of the images of
background galaxies in weak gravitational lensing. We do not expect to produce
a signal in either case along a direction at 45◦to the projection of k. These
predicted polarization/shear patterns are commonly called “E-modes.” However,
as we discuss in Sec. 28.7.1, primordial gravitational wave modes may also be
present. Explain qualitatively how a single gravitational wave mode can produce
a “B-mode” polarization pattern with electric vectors inclined at ±45◦to the
direction of the projection of k on the sky.
(d) When one sums over inhomogeneity modes, and over gravitational-wave modes,
the resulting polarization E-modes and B-modes have distinctive patterns that
differ from each other. In what ways do they differ? Read, explain, and elaborate
the discussion of E-modes and B-modes near the end of Sec. 28.6.1.
(e) Outline how our perturbed metric, Eq. (28.44), would have to be modiﬁed to
accommodate the presence of primordial gravitational waves.
28.6.3
28.6.3 Sunyaev-Zel’dovich Effect
When we discussed CMB radiative transfer in Sec. 28.6.1, we assumed that the plasma
was cold. This was appropriate when the temperature was Te ∼3,000 K. However,
the gas that settles in rich clusters of galaxies (see Sec. 28.2.1 and Fig. 28.1) has a
clusters of galaxies
temperature of ∼108 K, and thermal effects are very important. To understand these
important effects in general, consider a homogeneous and isotropic radiation ﬁeld
with distribution function ηγ(ν). Every time a photon is scattered by an electron, its
energy changes through small increments by Doppler shifting and Compton recoil.
This problem is ideally suited for a Fokker-Planck treatment (Sec. 6.9.1). If we ignore
emission and absorption, photons are conserved, and the Fokker-Planck equation
must have the form
Fokker-Planck formalism
∂ηγ
∂t + 1
ν2
∂
∂ν
2
ν2Fγ
3
= 0,
(28.83)
1428
Chapter 28. Cosmology

where the ﬂux Fγ in frequency space depends on ηγ and its frequency derivative.
When the electrons are very cold, each scattering produces a Compton recoil with
average frequency change ⟨ν⟩= −hν2/me, and so Fγ = −(neσT hν2/me)ηγ. Now,
our experience with the Fokker-Planck equation suggests that we add a term pro-
portional to ∂ηγ/∂ν to account for the heating of the photons by hot electrons with
temperature Te. However, Fγ must vanish when ηγ is Planckian with temperature Te.
A quick inspection shows that to deal with this, we must also add a term quadratic
in ηγ:
Kompaneets equation
Fγ = −neσT hν2
me

ηγ + η2
γ + kBTe
h
∂ηγ
∂ν

.
(28.84)
This Fγ vanishes when ηγ has the Bose-Einstein form {exp[(hν −μ)/(kBTe)]−1}−1,
with μ the chemical potential. This is entirely reasonable, as the total photon num-
ber density is ﬁxed in pure electron scattering and the equilibrium photon distri-
bution function under these conditions has the Bose-Einstein form, not the Planck
form (Sec. 4.4). The kinetic equation (28.83), adopting the ﬂux Fγ of Eq. (28.84), is
known as the Kompaneets equation (Kompaneets, 1957). The third term in parenthe-
ses in Eq. (28.84) describes the diffusion of photons in frequency space due to the
Doppler shift ν ∼ν(kBTe/me)1/2, leading to the familiar second-order frequency
increase. The diffusion coefﬁcient in frequency space, Dνν = neσT ν2kBTe/me, can
be calculated explicitly by averaging over all electron velocities, assuming a Maxwell-
Boltzmann distribution function.
The quadratic term in parentheses in Eq. (28.84) describes the induced Compton
induced Compton
scattering
effect, in which the scattering rate between two photon states (from unprimed to
primed) is ∝ηγ(1 + η′
γ). To lowest order, the product term is canceled by inverse
scattering. However, when we make allowance for the electron recoil, there is a ﬁnite
effect, which is important at low frequency. This term is also derivable from classical
electrodynamics without recourse to quantum mechanics.55
Now return to what happens in a galaxy cluster. The radiation is still effec-
tively isotropic, and time should be interpreted as path length through the cluster.
The derivative term in Fν dominates at high Te, and so the observed CMB relative
frequency shift
temperature change measured at a ﬁxed frequency is given by
δT SZ =
*
∂ηγ
∂ln Tγ
+−1
ν
kBTeτT
meν2
  ∂
∂ν

ν4∂ηγ
∂ν

Tγ
=
kBTeτT
me
 '*
hν
kBTγ
+
coth
*
hν
2kBTγ
+
−4
(
.
(28.85)
55. The ﬁrst realization that induced Compton scattering could be important was by Kapitsa and Dirac
(1933).
28.6 Cosmological Optics
1429

δT me
—
τT kB Te
ν
—
100 GHz
hν
—
kB Tγ
8
7
6
5
4
3
2
1
0
4
3
2
1
0
3
2
1
0
–1
–2
FIGURE 28.17 Sunyaev-Zel’dovich effect: Distortion of the CMB blackbody spectrum by passage
of radiation through a cluster of galaxies, where the hot electrons Doppler boost (on average)
the frequencies of individual photons. At frequencies well below the peak in the spectrum, the
intensity decreases, while at high frequencies, it increases.
This is known as the Sunyaev-Zel’dovich (1970) effect (Fig. 28.17). In a typical cluster,
the optical depth is τT ∼0.1and δT SZ ∼10−3. The photon temperature decreases by
a fractional amount δT = −2kBTeτT /me in the Rayleigh-Jeans part of the spectrum
and increases in the Wien part. The crossover occurs at ν = 3.83kBTγ/h = 217 GHz,
as observed.
EXERCISES
Exercise 28.23 Example and Challenge: The Music of the Sphere
We have hitherto focused on the statistical properties of the cosmological perturba-
tions as probed by a variety of observations. However, we on Earth occupy a unique
location in a speciﬁc realization of wave modes that we have argued are drawn from a
speciﬁc set of waves with particular amplitudes and phases, despite these supposedly
being drawn from a statistical distribution (in much the same way that different pieces
of music are distinct despite having similar power spectra). It should not be too long
before we can produce a 3-dimensional “map” of our universe out to recombination
based on a suite of observations, presuming that our standard cosmology and theory
for the evolution of perturbations is correct.
(a) Calculate the comoving radii of recombination, reionization, and the most distant
galaxies and quasars.
1430
Chapter 28. Cosmology

(b) Suppose that we have noise-free CMB ﬂuctuation maps in temperature and polar-
ization up to spherical harmonic quantum number l = 100. How many numbers
would be contributed by these measurements?
(c) How many numbers would we need to measure to describe the potential and
the associated density perturbations out to the radius of recombination with
comparable resolution?
(d) Would these modes still be in the linear regime today?
(e) Challenge.Explore some of the practical challenges of carrying out this program,
paying attention to the investigations we have described in Sec. 28.6 and assuming
them to be carried out over the whole sky.
28.7
28.7 Three Mysteries
The cosmology that we have described depends on the application of basic physical
laws, mostly classical—including (among others) general relativity with a cosmolog-
ical constant—in locales where the laws are not independently tested; and it also
depends on the “simplest” assumptions, including ﬂatness and an initial, scale-free
spectrum of adiabatic ﬂuctuations. In this cosmology’s most elementary version, on
which we have focused, what we observe follows from just four dimensionless param-
eters, which we can choose to be b, D, γ, and Q, plus a single length/timescale
which we can choose to be t0; and we learn these parameters by ﬁtting observations.
In a more comprehensive version of this cosmology, one must also ﬁt additional as-
trophysical parameters associated with reionization and galaxy formation.
We conclude this chapter with a brief summary of contemporary views on the
more fundamental processes that presumably determine this cosmology’s assump-
tions and parameters.
28.7.1
28.7.1 Inﬂation and the Origin of the Universe
KINEMATICS
Early in our discussion of cosmology, we introduced the horizon and emphasized
that it was smaller and smaller when the universe was younger and younger, so less
and less of the universe was in causal contact at early times (Fig. 28.6). However, the
universe we observe today is nearly homogeneous and isotropic. In particular, large-
scale, spatially coherent ﬂuctuations in the CMB are seen at recombination, when the
horizon problem
horizon was less than 1% of their size. We have argued that the universe began in
thermodynamic equilibrium at a very high temperature and that key properties (such
as the net number of baryons and dark matter particles per photon and the amplitude
of the potential perturbations) were determined by speciﬁc, though unknown, local
physical laws. If this is so, how can there be spacelike slices of simultaneity that are
homogeneous on the largest scale? It is also surprising that the universe is as ﬂat as
28.7 Three Mysteries
1431

it appears to be.56 As was realized surprisingly early in the development of modern
cosmology, these mysteries may have a common explanation called inﬂation.57
Under the inﬂationary scenario, it is proposed that the material of the universe
we see today was initially in causal contact and was well mixed and therefore homo-
geneous. There followed an epoch of runaway expansion—inﬂation—when parts of
causal behavior
the universe on different world lines from our own exited our horizon and lost con-
tact with us. After this phase ended, these parts independently followed the evolution
we described in Sec. 28.4 and, primed with the same features as us, their world lines
then reentered our horizon, the last to leave being the ﬁrst to return. “Hello, goodbye,
hello!”
We have not demonstrated that the universe had such an origin, but all recent
observations are consistent with the simplest version of inﬂation, and nothing that we
have learned is in conﬂict with it. At the very least, the theory of inﬂation illustrates
some fascinating features of general relativity, bringing out clearly the challenge that
will have to be met by any rational description of the very early universe.58
We do not understand the physics that underlies inﬂation, but let us make a guess,
inspired by observation. We have explained that the inferred initial amplitude of
a potential perturbation is almost independent of its comoving length scale (scale
invariance). We presume that each perturbation was laid down by local physics just
prior to that scale exiting the horizon and argue that the physical conditions were
therefore constant in time. The one homogeneous cosmology that has this character
is a de Sitter expansion with ρ = const and a ∝eHit for ti < t < th, with a constant
de Sitter expansion
inﬂation Hubble constant Hi and where the subscript h denotes the end of inﬂation.
It is commonly supposed that inﬂation began during the epoch of “grand uni-
ﬁcation” of the electroweak and strong forces, when t ∼ti ∼H −1
i
∼10−36 s. If we
also assume that the universe was homogeneous on the scale of the horizon ∼ti, and
inﬂation went on for long enough to encompass our horizon, then ai ∼ti/χ0H ∼3 ×
10−55. However, we also know that ah ∼ai exp(Hith); and if we denote the start of the
particle era by ap ∼10−11 when tp ∼3 ms, then we also have that ah ∼ap(th/tp)1/2.
These two relations and the above numbers imply that th ∼64ti, ah ∼2 × 10−27. In
this simple example, 64 e-foldings of inﬂationary expansion sufﬁce to explain the
homogeneity of our universe today.
Furthermore, any signiﬁcant curvature that may have been present when the
universestartedtoinﬂatewouldhavemadeafractionalcontributiontotheFriedmann
equation (28.16) ∼(ai/ah)2 ∼10−56 at th. This fractional contribution would then
56. There are additional quantum ﬁeld theory puzzles, especially the apparent scarcity of topological defects
like monopoles, strings, and domain walls that are addressed by this theory.
57. Pioneers of these ideas included Kazanas (1980), Starobinsky (1980), Guth (1981), Sato (1981), Albrecht
and Steinhardt (1982), and Linde (1982).
58. We exclude “Just So” stories—for example, ﬂood geology—that assert that the world began at a speciﬁc
time in the relatively recent past with just the right initial conditions necessary to evolve to the world of
today.
1432
Chapter 28. Cosmology

grow by a factor ∼(aeq/ah)2 ∼1046 by the end of the radiation era and by a further
factor ∼a /aeq ∼3,000 by the start of the cosmological era. In this example it is only
∼10−56 × 1046 × 3,000 ∼3 × 10−7 in the early cosmological age (today). However,
with other plausible assumptions, it may just be detectable. Therefore, the observed
ﬂatness, which otherwise requires very careful ﬁne tuning of the initial conditions,
also has a natural explanation.
CLASSICAL ELECTROMAGNETIC FIELD THEORY
The constant energy density that we have argued is needed to drive inﬂation is
commonly associated with a classical scalar ﬁeld, sometimes called the inﬂaton.
inﬂaton ﬁeld
To describe its properties necessitates a short digression into classical ﬁeld theory
(cf. Ex. 7.4).
Lagrangian methods were devised to solve problems in celestial mechanics and
turned out to be useful for a larger class of classical problems (Goldstein, Poole, and
Safko, 2002). To summarize the approach (with which the reader is presumed to be
quite familiar), the coordinates x of all particles are replaced by a sufﬁcient number of
generalized coordinates q(x, t)—for example, three Euler angles for a spinning top—
to describe the system. A scalar lagrangian L(q, ˙q, t) is introduced as the difference
Lagrangian dynamics
of the kinetic and potential energies, and the system evolves so as to make the action

dt L stationary.59 This implies the Euler-Lagrange equations ∂qL = d(∂˙qL)/dt,
where ∂q is shorthand notation for ∂/∂qi. A hamiltonian, ∂˙qL . ˙q −L, is introduced,
whichequalstheconservedenergyifthesystemdoesnotinteractwithitsenvironment
and evolve explicitly with time.
This Lagrangian approach was generalized to describe the classical electromag-
netic ﬁeld60 (where it is not very much used in practice; Jackson, 1999).61 For this,
three changes need to be made to the particle lagrangian. First, as we are dealing with
a relativistic theory, we work in spacetime coordinates. Second, we use the lagrangian
density L, so that the action is

dtdV L; L must be a Lorentz-invariant scalar (cf.
Sec. 2.12 and Ex. 7.4). Third, we treat the electromagnetic ﬁeld itself as a generalized
coordinate. However, instead of being an N-dimensional vector, we take the limit
N →∞and treat it as a continuous variable.
The natural choice of ﬁeld coordinate is the 4-vector potential Aα constrained
by the Lorenz gauge condition ∂αAα = 0. (We use indices here to avoid notational
confusion, we use ∂α for partial derivatives, ∂αAα ≡∂Aα/∂xα, and for simplicity we
assume spacetime is ﬂat.) For the free electromagnetic ﬁeld, the only choice for the
59. In a phrase that captures the philosophical, political, theological, and literary context in which this
revolutionary approach to physics was created, we live “in the best of all possible worlds.”
60. Faraday ﬁrst conceptualized a ﬁeld description of electromagnetism and gravity in the 1820s, contrasting
it with the Newtonian “action at a distance” and gradually developed this idea (Faraday, 1846). Although
Maxwell and others sought a variational description of electromagnetism, it was the astronomer Karl
Schwarzschild (1903) who ﬁrst got it right, 2 years before the advent of special relativity.
61. It is, of course, indispensible for understanding quantum mechanics, quantum electrodynamics, and
quantum ﬁeld theory and is extremely useful for probing the fundamental character of general relativity.
28.7 Three Mysteries
1433

lagrangian density (except for an additive or multiplicative constant) consistent with
these requirements is LEM =
1
4π ∂[αAβ]∂[βAα], in Gaussian units. Comparing with the
particle lagrangian, we recognize this as kinetic energy–like with no potential energy–
lagrangian density for
electromagnetic ﬁeld
like contribution. Varying the action leads to the Euler-Lagrange equations:
δLEM
δAα
≡−∂β
*
∂LEM
∂(∂βAα)
+
= 0 ⇒F αβ
,β = 0
where Fαβ = 2∂[βAα].
(28.86)
These are the free-ﬁeld Maxwell equations.62
The electromagnetic stress-energy tensor is a natural generalization of the hamil-
tonian for particle dynamics:63
Tβ
α = LEMδβ
α −
*
∂LEM
∂(∂αAγ)
+
∂βAγ = 1
4π
2
∂[γAδ]∂[δAγ ]δα
β −4∂[αAγ ]∂[γAβ]
3
.
(28.87)
This agrees with the standard form, Eq. (2.75).
SCALAR FIELD THEORY
The observed isotropy of the universe suggests that the fundamental inﬂaton ﬁeld
we seek—henceforth designated as ϕ—is a real scalar and not a vector ﬁeld (as in
electromagnetism) or a tensor ﬁeld (as in general relativity) or a complex or spinorial
quantum ﬁeld (like the Higgs ﬁeld). In this section we set G = c = 1, so that ϕ is
dimensionless and we deal with the real universe where spacetime is curved. The
simplest form for the lagrangian density, by analogy with LEM, is L = −1
2 ⃗∇ϕ . ⃗∇ϕ −
V (ϕ) (where we no longer need to use indices, as the ﬁeld is a scalar). The ﬁrst term
lagrangian density for
scalar ﬁeld
is the only invariant choice we have for the kinetic energy–like part (except that the
−1
2 is a convention); the second term is the simplest potential energy–like part, which
is absent for classical electromagnetism but necessary here. Continuing the analogy,
the stress-energy tensor is given by
stress-energy tensor
TTT = Lggg −
∂L
∂( ⃗∇ϕ)
⊗⃗∇ϕ = Lggg + ⃗∇ϕ ⊗⃗∇ϕ.
(28.88)
Now consider a harmonic potential V = 1
2ω2
h(ϕ −ϕh)2, in which ϕh is the (vac-
potential minimum
uum) value of the ﬁeld, where the potential vanishes. The (Euler-Lagrange) ﬁeld
equation for our lagrangian density is ∇α∇αϕ = dV/dϕ. If we seek a wave solution
in a local Lorentz frame, then we recover the dispersion relation: ω2 −k2 = ω2
h, where
ωh isLorentzinvariant.Thisdescribesalongitudinalscalarwavepropagatinginvacuo
but has a similar dispersion relation to a transverse vector wave propagating in an un-
magnetized plasma [cf. Eq. (21.24)]. Note that we can Lorentz transform into a frame
62. Including a current source requires the addition of an interaction lagrangian, which is straightforward
but need not concern us here.
63. The formal justiﬁcation of this heuristic argument hinges on the celebrated theorem (Noether, 1918)
that relates conserved quantities to symmetry.
1434
Chapter 28. Cosmology

in which ω = ωh and k = 0, and the wave becomes a pure oscillation with no spatial
gradients. In this frame, the ﬁeld is directly analogous to a classical particle moving
in a stationary potential well. In a general frame, the stress tensor for an individual
wave is anisotropic and oscillatory.
Next, consider a potential maximum V = Vi −1
2ω2
i ϕ2, and transform into the
potential maximum
frame where there are no spatial gradients. The equation of motion for the ﬁeld
is ¨ϕ −ω2
i ϕ = 0. It is simplest to imagine the ﬁeld as starting with ϕ(0) = 0 and
a small positive velocity ˙ϕ(0), so that ˙ϕ(t) = ˙ϕ(0) cosh ωit, which soon increases
exponentially with time.
SLOW-ROLL INFLATION
We have now introduced all the ideas we need to design a potential that allows the
universe to slow roll and inﬂate for ∼64 e-foldings before transitioning classically
to a decelerating expansion. Qualitatively, we require a potential maximum with
small enough curvature for sufﬁcient inﬂation to take place, joined to a potential
minimum into which the ﬁeld can settle and allow fundamental particles to take over
the dynamics.64
A convenient and illustrative choice for the potential is V = Vi[1 −(ϕ/ϕh)2]2
model potential
(Fig. 28.18a). The two parameters Vi and ϕh measure the height and the width
of the potential and ought to be derivable from basic physics. Let us work in the
frame in which ϕ = ϕ(t) with no spatial gradients, which will deﬁne and evolve into
the sequence of homogeneous spatial hypersurfaces that we have been using. Using
Eq. (28.88) and comparing with the perfect ﬂuid stress-energy tensor, we can identify
the energy density ρ and the pressure P :
density and pressure for
ﬁeld
ρϕ = V + 1
2 ˙ϕ2,
Pϕ = −V + 1
2 ˙ϕ2.
(28.89)
If we ignore all other possible contributions and insert these expressions into the
evolution of the ﬁeld
ﬁrst law of thermodynamics [Eq. (28.19)], we obtain the cosmological scalar ﬁeld
equation:
¨ϕ + 3H ˙ϕ + dV/dϕ = 0,
(28.90)
whereH 2 = 8πρϕ/3.WesetVi = 3H 2
i /8π = 1.6 × 1098 J m−3andwechooseϕh = 1.5
and the value of the scalar ﬁeld ˙ϕ(0) so as to prolong inﬂation for 64 e-foldings and
to match the expansion during the particle age (Fig. 28.18).
Now, this model thus far is seriously incomplete, because its evolution asymptotes
toanempty, staticuniversewithH = 0anda = const.Wehavecompletelyignoredthe
relativistic, fundamental particles that drive the post-inﬂationary expansion. These
particle production
cannot be primordial, because their contribution would have inﬂated away; instead,
they must have been generated at the end of inﬂation, speciﬁcally, as the ﬁeld oscillates
in the potential well. From a quantum mechanical perspective, this is quite reasonable,
64. In the original theory, this transition—called the graceful exit—was attributed, unsuccessfully, to quan-
tum mechanical tunneling.
28.7 Three Mysteries
1435

 .ϕ—
Hi
ϕ
ϕ
ϕ
ϕ
–55
1.40
1.45
1.50
1.60
1.55
10
20
30
40
50
60
70 80
0.0
0.5
1.0
(a)
(b)
(c)
2.0
1.5
–50
–45
  ρr(1096J m–3)
  V(1096J m–3)
–40
log a
t(10–36 s)
–35
–30
10
8
6
4
2
0
universe
cluster
galaxy
star
Earth
2.0
1.5
1.0
0.5
0.0
0.050
0.025
0.00
–0.025
–0.050
200
150
100
50
0
ρr
FIGURE 28.18 (a) The three types of potential considered in the text. The dashed line is a (shifted)
potential minimum, the dotted line is a potential maximum, and the solid line is the simple model
inﬂaton potential that joins these two solutions. (b) Variation of ϕ as it oscillates about the potential
minimum exhibited in the ϕ– ˙ϕ plane. The red curve is the free ﬁeld variation; the blue curve includes
the ad hoc particle production. (c) Variation of the ﬁeld ϕ, the scale factor a, and the relativistic
particle energy density ρr as a function of a. The rapid decline in ρr at late time is due to expansion.
The times at which perturbations, on the comoving scale of various cosmic structures, leave the
horizon are indicated by vertical lines.
1436
Chapter 28. Cosmology

though the detailed mechanisms are not understood.65 The production of particles is
irreversible, and this is where the entropy of today’s universe, mostly carried by CMB
photons, would have originated.
So (inspired by the treatment of collisionless shocks in Sec. 23.6), let us make
an ad hoc modiﬁcation to Eq. (28.90) by changing the “friction” term from 3H ˙ϕ to
(3H + krHi) ˙ϕ with kr > 0, to include some genuine dissipation. The equation for the
production of relativistic particle energy density ρr is then
particle production ansatz
˙ρr + 4Hρr = krHi ˙ϕ2,
(28.91)
where the source term on the right is the negative of the dissipative rate of loss
of inﬂaton energy, ˙ρϕ diss. The results from adding this particle production to our
evolution equation are shown in Fig. 28.18b. We see that a choice of kr = 0.2 leads to
a scale factor evolution similar to what we suggest may have happened.
One of the more serious issues glossed over in this abbreviated account of inﬂation
is the value of the potential at its minimum. Our model potential has V (ϕh) = 0.
What this really means is that after inﬂation is over, the ﬁnite scalar ﬁeld contributed
potential must asymptote
to 0
nothing to the stress-energy tensor and generated no spacetime curvature. This must
be essentially forever, because all other contributions to ρ diminish with time, at
least until the cosmological age. Quantum mechanically, the issue is even murkier.
We return to this point when we discuss the fate of the universe.
PERTURBATIONS
We have not yet explained why the primordial potential perturbations have their in-
ferred amplitude. It is widely argued that these perturbations are quantum mechanical
in origin, and to describe the associated theory goes beyond the scope of this book.
See, for example, Mukhanov (2005) for details. However, we can give a heuristic semi-
classical argument that captures the essence of the calculations.
In the early stages of inﬂation, when the perturbations that we measure leave our
horizon, the inﬂaton ﬁeld ϕ is very small, V and Hi are almost constant, and the
end of inﬂation is far in the future. There is a limit to how far a photon can travel in
comoving coordinate χ, since dt = adχ ∝eHitdχ. The de Sitter spacetime therefore
has an effective event horizon.It should therefore come as no surprise to discover that
de Sitter horizon
there is an associated temperature similar to the Hawking temperature for a black
hole, Ti = ℏHi/(2πkB) ∼1024 K as Hi is the effective acceleration (Secs. 4.10.2 and
relation to Hawking
radiation
4.10.3). This temperature is too low for excited states to be important, so we are only
interested in zero-point ﬂuctuations in ϕ (Sec. 12.5). We can estimate the magnitude
δϕ of the ﬂuctuations by equating the energy associated with it, ∼(Hiδϕ)2(1/Hi)3/G,
to the zero-point energy in a mode ∼ℏHi, temporarily abandoning geometrized units
and reinstating G for clarity. We deduce that δϕ ∼(Gℏ)1/2Hi.
65. The production of electron-positron pairs by a rapidly varying electromagnetic ﬁeld is an analogous
process. The most developed explanations involve parametric resonance, as discussed in Secs. 23.5 and
10.7.2.
28.7 Three Mysteries
1437

The quantity (Gℏ)1/2 is known as the Planck length, denoted LP ∼10−35 m, and
is equivalent to the Planck time tP ∼10−43 s. It marks the scale when gravitational,
relativistic, and quantum mechanical effects should be comparably important and it
Planck units
makes no sense to invoke classical physics alone. The physics must be described by
some future complete theory of quantum gravity, perhaps derived from string theory.
Associated with the Planck length/time is a Planck mass mP ∼(ℏ/G)1/2 ∼10−8 kg ∼
1028 eV, and a Planck energy density ∼(G2ℏ)−1 ∼10114 J m−3. The associated Planck
temperature is ∼1032 K. In our model for inﬂation, tstart ∼107tP, and this justiﬁes a
semi-classical treatment.
The way these ﬁeld ﬂuctuations δφ are transformed into density and potential
ﬂuctuations is a bit more subtle. Spatial gradients can no longer be ignored when there
are perturbations. Positive ﬂuctuations develop faster than negative ﬂuctuations, just
as we saw in the gravitational age. However, we can ignore ¨ϕ so the rate of change of
ϕ is ˙ϕ ∼−(dV/dϕ)/(3Hi) from Eq. (28.90), and the time interval to change the ﬁeld
is δt ∼δϕ/ ˙ϕ. The absolute values of the relative density and potential ﬂuctuations on
a given scale are then estimated by δ ∼ ∼Hiδt (Peacock, 1999, pp. 338–340). Now
allowing ϕ to be dynamical and to evolve means that the production of the potential
ﬂuctuations from quantum ﬂuctuations is not completely scale free, and the detailed
shape of the potential V (ϕ) should be reﬂected in the observed ﬂuctuation spectrum.
We mentioned at the start of our discussion of perturbations (Sec. 28.5.1) that we
were conﬁning our attention to scalar perturbations. If the inﬂationary mechanism
for creating them is basically correct, then they should also be accompanied by tensor
perturbations, which take the form of gravitational wave modes whose wavelengths
expand with the universe in just the same way. Repeating the zero-point energy
calculationusinganestimateofthegravitationalwaveenergyof∼(Hiδh)2(1/Hi)3/G,
where δh is the amplitude of the wave (cf. Sec. 27.4.3), we ﬁnd that δh ∼HitP. A
full discussion of the growth of the tensor perturbations requires the addition of
extra terms to the perturbed Robertson-Walker metric, and care must be taken to
deal only with physical quantities that are independent of the choice of coordinate
system/gauge.
TESTING INFLATION
We have addressed several cosmological riddles by invoking an inﬂaton scalar ﬁeld
accompanied by a speciﬁc potential for which we have no experimental evidence.
Although this may seem quite unscientiﬁc, there are many precedents for astronomi-
cal observations anticipating laboratory measurement, including the deduction of an
inverse square law of gravitation, the discovery of helium, and the prediction of the
excited state of carbon that allowed stellar nucleosynthesis to proceed. Although there
is a limit to what we can hope to learn, the recent determination that the spectrum of
potential perturbations was not quite scale-free—speciﬁcally, that P (0, k) ∝k−3.04,
so the longer-wavelength modes have slightly larger amplitudes—is encouraging. As
1438
Chapter 28. Cosmology

can be appreciated from the preceding discussion, this is a fairly general feature of
simple, slow-roll potentials, because the vacuum ﬂuctuations diminish as the ﬁeld
“rolls” down the potential.
As outlined in Ex. 28.22, gravitational waves are detectable through the polariza-
tion patterns that they produce in the CMB. Speciﬁcally, the B-modes, which have
speciﬁc handedness locally, have been sought observationally and have been found
with levels that are attributable to gravitational lensing and interstellar dust. More
sensitive measurements are planned to seek the primordial signal.
INITIAL CONDITIONS
Even if we accept uncritically—on theoretical or observational grounds—that inﬂa-
tion happened roughly as just described,66 the mechanism has not explained the birth
of the universe. It has only translated the discussion of this question to earlier times.
The simplest explanation of the origin of the universe is that there is only one uni-
verse that began as quantum mechanical decay of a Planck-scale entity.67 Discussion
of “outside” or “before” is relegated to metaphysics. More appealing ideas are that the
initial state was chaotic, that it involved extra spatial dimensions, or that the evolution
of the inﬂaton was not semi-classical.
However, the most discussed and intriguing possibility is that our universe is just
one member of an ensemble of universes—the multiverse—that may be both past and
multiverse
future eternal. Members of this ensemble—also called the landscape—correspond
landscape
to a large number68 of possible vacuum states that are continuously created and
destroyed—most on Planckian timescales. The initial conditions (Kachru et al., 2003;
Susskind, 2005) mandated by the existence of our universe (e.g., that it has existed for
14 billion years) are highly specialized and will arise extremely rarely. These unusual
circumstances may also extend beyond the starting requirements to the actual laws of
physics that come into play as the universe expands. They may need to be ﬁne-tuned
as well to allow dark matter, baryons, nuclei, atoms, molecules, galaxies, stars, planets,
and life to have developed.
The apparent improbability of this outcome has been turned on its head by con-
jecturing that our very existence actually selects, as opposed to just allows us to infer,
the initial conditions and perhaps also the laws of physics. This is known as the
anthropic principle (Dicke, 1961). Things were as they were because we are as we
anthropic principle
are! Many physicists are repelled by such a principle, arguing that it is basically
66. A minority of cosmologists argue that the inﬂation theory creates more problems than it solves.
67. If we try to do away with inﬂation altogether and assume that there were only relativistic particles present,
then the scale factor at the Planck time is a ∼10−32, and we would have to explain how a region ∼1 μm
(or ∼1029 Planck lengths) across could be homogenized and synchronized!
68. Over 10500 in some formulations! This is sufﬁcient for adopting the precepts of statistical mechanics.
The problem is that we do not have a Liouville equation for assigning a priori probabilities to individual
states.
28.7 Three Mysteries
1439

teleological—abeliefintheexistenceofﬁnalcauses—andanabandonmentofthequest
to understand the foundations of science. Others see it as an important extension of
the scientiﬁc method to accommodate the discussion of hypotheses that cannot be
extension of scientiﬁc
method
tested experimentally69 and as the only practical way to advance our understanding
of physics at energies well beyond current experimental reach. It will be interesting
to see which of these viewpoints holds sway as our measurement of cosmological pa-
rameters continues to improve. What is undeniable, though, is that the contemplation
of a universe in which, for example, P or b have very different values or a phys-
ics under which planets obey an inverse cube law of gravitation, nuclear interactions
fail to produce carbon or even helium, or the ﬁne structure constant is 0.170 greatly
sharpens our appreciation of the laws that we otherwise take for granted.
EXERCISES
Exercise 28.24 Example: Blind Cosmologist
A blind (but hearing) cosmologist observed the radiation-dominated universe. He
detected faint tones and noted that their frequencies declined as t−1/2 and believed
(correctly) that the sound speed is constant. As he was blind, he knew nothing
of photons but did understand classical scalar ﬁeld theory. What did he conclude
about V (ϕ)?
28.7.2
28.7.2 Dark Matter and the Growth of Structure
The material content of the modern universe is dominated by dark matter and
baryons. The existence of each of these constituents is puzzling. Let us consider them
in turn.
DARK PARTICLES
It is widely conjectured that dark matter comprises one or more new elementary
particles. For speciﬁcity, let us suppose that there is a single particle that is neutral
(like a neutron), fermionic with spin 1
2 (like an electron), its own antiparticle (like
a photon), weakly interacting (like a neutrino), and stable (like a proton appears to
be).71 Introduce ZD ≡nD/nν, the ratio of its density nD to the neutrino density nν,
WIMPs
and let its mass be mD ≡mD,12 TeV. When T ≫mD/kB ∼1016mD,12 K, the dark
particles were presumably created and destroyed freely in thermal equilibrium with
other particles and with zero chemical potential, so that ZD = 1
3, as there are three
69. It can be argued that many of the most important modern applications of classical physics (e.g., geo-
physics, climate change, and astrophysics) are of this character, although when we understand the
governing principles, we substitute simulation for experiment and Bayesian likelihood for frequentist
statistics.
70. In some extreme formulations, even the laws of arithmetic are allowed to vary!
71. Such dark matter particles are often called Weakly Interacting Massive Particles or WIMPs!
1440
Chapter 28. Cosmology

neutrino species. Using the current dark matter and neutrino densities from Table
28.1, we ﬁnd that today ZD = 4 × 10−12mD,12−1 (Table 28.1).
So, most of the dark matter particles must have vanished. The simplest explanation
is that during binary collisions they annihilated to form less massive, relativistic par-
ticles when they became mildly relativistic, like electrons and positrons annihilated,
consistent with thermodynamic equilibrium (cf. Sec 28.4.1). Eventually the annihi-
lation rate fell below the Hubble expansion rate, and a small relict density was left
relict density
over, out of equilibrium, constituting the dark matter we see today (Lee and Wein-
berg, 1977). Using the principles we established in our discussion of nucleosynthesis
(Sec. 28.4.2), we can write down immediately a kinetic equation for the dark particles
that balances annihilation with the reverse reactions:
˙ZD = nν⟨σDDvD⟩
*
n2
Dth
n2
ν
−Z2
D
+
,
(28.92a)
where
nDth(T , mD) = 2
 ∞
0
4πp2dp
h3
1
e(m2
D+p2)1/2/(kBT ) + 1
(28.92b)
[cf. Eqs. (28.38)], and where ⟨σDDvD⟩is the annihilation rate, nDth(mD, T ) is the
densitythedarkparticleswouldhaveinthermalequilibrium, andtheneutrinodensity
is nν(T ) = 3nDth(0, T ). (The particle speeds vD are nonrelativistic when they stop
annihilating and typically, σDD ∝v−1
D .) We assume that the dark particles are kept at
the same temperature as the rest of the universe and that the expansion obeyed the
same t ∝a2 law as at the start of the photon age. Eq. (28.92a) is now easily solved
“WIMP miracle”
numerically for different masses to derive the relation σDD(mD) needed to produce
the contemporary value of ZD. More simply, though less accurately, we note that
⟨σDDvD⟩∼H/nD ∝mDaD when a ∼aD and annihilation ceased. Guided by pair
annihilation, we estimate that the associated temperature was TD ∼0.1 mD/kB ∝
a−1
D . In order for this to be the origin of dark matter, we require that ⟨σDDvD⟩∼
3 × 10−32 m3 s−1, which is also the result from the more careful calculation and is
pretty insensitive to the more detailed assumptions and entirely consistent with the
expectations from particle physics.
We do not understand the properties of the dark particle, and the choices we have
just made look like they have been delivered by a committee! (Indeed, every single one
of them can be negated and still lead to a viable explanation.) However, these choices
do describe the most widely supported explanation for dark matter, namely, that it is
the lightest supersymmetric particle.72 Supersymmetry is a promising extension of the
supersymmetry
standard model of particle physics that postulates the existence of fermionic partners
to the bosons of the standard model and vice versa. A major experimental program
72. Alternatives that have been seriously considered and sought include axions (Peccei and Quinn, 1977)
and sterile neutrinos (Pontecorvo, 1968).
28.7 Three Mysteries
1441

under way at the Large Hadron Collider seeks evidence for it. Many direct searches
are also being conducted in deep mines (to ﬁlter out the cosmic ray background) for
very rare collisions between dark particles and atomic nuclei. Finally, the small rate
dark matter searches
of annihilations still going on today might lead to γ -rays and positrons that can be
seen, indirectly, by astronomers. All three searches—below, on, and above ground—
are under way or are being undertaken in 2016. What is interesting and encouraging
is that the sensitivity attainable, in each case, is roughly compatible with the value of
⟨σDDv⟩inferred on the basis of cosmology observations and theoretical calculations.
To date, despite exquisite experiments, no convincing evidence for dark particles
hasbeenfound.Instead, signiﬁcantconstraintsontheirpropertiesarebeingmeasured
by all three techniques, and improvements in sensitivity should be forthcoming over
the next several years. Only Nature knows whether we are now on the threshold of
identifying most of the matter in the universe and exploring a second standard model
of particle physics or if we must look elsewhere for an explanation, but the hunt is on.
BARYOGENESIS
The puzzle over baryons is why there are any of them at all! Protons have antiparticles
with which they can annihilate with very large cross sections, so symmetry would
seem to suggest that none should have been left over after the temperature fell far
below ∼mp/kB ∼1013 K. The only way residual baryons could have been created is if
some imbalance were created between baryons and antibaryons.73 The protons (and
neutrons, which decay into protons) derived from quarks and primordial asymmetry
can be preserved through the quark phase of the universe by a conserved quantum
baryon number
number—the baryon number. Essentially, what we seek is some process occurring
during the very early universe and involving a signiﬁcant constituent that creates
such an asymmetry. Any serious discussion of this topic involves highly speculative
high-energy-physics considerations that we cannot go into here. However, there are
essentially classical considerations that should underlie any proposed mechanism,
and these we now discuss.
Let us suppose that a particle—one with a distinct antiparticle—undergoes a de-
cay that creates a net baryon number. Such a possibility is permitted—and indeed,
suggested—by the existence of ﬁnite neutrino masses, though it has never been ob-
served. The problem is that on quite general grounds, an antiparticle will create the
opposite baryon number and so we have to explain why there is a difference between
the amounts of matter and antimatter. Now, the laws of classical physics are tacitly
assumed to be the same when the spatial coordinates are inverted: x →−x. In the
language of particle physics, we say that they are invariant under a parity (P) transfor-
mation. Likewise, the laws of classical electromagnetism are unchanged if we change
73. Equally effective would be a process that created and maintained an asymmetry between electrons
and positrons, so that a baryon asymmetry would be needed to preserve charge neutrality. However,
baryogenesis is thought to be more likely than leptogenesis.
1442
Chapter 28. Cosmology

the signs of all the charges. This is invariance under a charge (C) transformation. Fi-
nally, the microscopic classical laws (e.g., those describing collisions of particles or
the evolution of an electromagnetic ﬁeld) are invariant under time reversal—a time
(T) transformation. This last observation does not imply that all physical phenom-
ena are reversible. As discussed in Sec. 4.7, the act of averaging (or “coarse graining”)
introduces the arrow of time, embodied in the second law of thermodynamics.
This need not have been the case and is not true in particle physics. Speciﬁcally,
it was shown in the 1950s that β decay—a weak interaction—produces left-handed
(not right-handed) neutrinos, which violates P symmetry. This was a surprise to many
physicists. Likewise, if we were to change the signs of all charges in this decay, we
would expect to produce a left-handed antineutrino, and this is not seen either, so
C symmetry is violated as well. However, combined C and P transformations lead to
thepreservationofCPsymmetryinβ decay.Thisisimportant, becauseafundamental
theorem states that CPT symmetry must be respected, and so a violation of CP would
imply a violation of T.
It therefore came as a second, even greater, shock when in the 1960s, experimen-
tal measurements of neutral K mesons showed that their decay into two channels
that were CP equivalent occurred at different rates. CP symmetry is violated, and
Nature can distinguish matter from antimatter and forward from backward in time.
For the universe to have actually made this distinction also requires a departure
from thermodynamic equilibrium in the past. If this did not happen, the particles
and antiparticles would have had identical distribution functions with zero chemical
potentials, and no net baryons would have been made. Now, thermodynamic equilib-
rium would not have been maintained had the expansion been too fast for the particle
reactions (cf. Secs. 28.4.1 and 28.4.2). An alternative possibility is that the particles
did not scatter, so that their momenta evolved according to p ∝a−1 (cf. Sec. 28.2.3).
This automatically leads to a nonthermal distribution function74 and allows baryon
asymmetry to proceed. We are probably a long way from understanding the detailed
particle physics of baryogenesis, but determining that its general requirements could
plausibly have been satisﬁed is a good ﬁrst step.
EXERCISES
Exercise 28.25 Challenge: Including More Details
We have made many simplifying assumptions in this chapter to demonstrate the
strong connection to the principles and techniques developed in the preceding 27
chapters. It is possible to improve on our standard cosmological model by being more
careful without introducing anything fundamentally new. (The research frontier, of
course, is advancing fast and contains much we have not attempted to explain.)
Consider how to implement the following corrections to standard cosmology that
74. That all three violations—baryon number, C/CP symmetry, and thermal equilibrium—were necessary
was ﬁrst recognized by Sakharov (1965).
28.7 Three Mysteries
1443

are mandated by observation, and then repeat the calculations with these changes,
comparing with the research literature.
(a) Changing the slope of the initial cosmic noise spectrum (Sec. 28.5.3).
(b) Including more spherical harmonics in the description of the radiation ﬁeld and
using the Boltzmann equation instead of a Monte Carlo simulation (Sec. 28.6.1).
(c) Including tensor perturbations in the Robertson-Walker metric (Secs. 28.5.1,
28.5.3, and 28.7.1).
(d) Accounting for neutrino mass (Sec. 28.3.4).
Exercise 28.26 Challenge: Testing Standard Cosmology
There are many elaborations of standard cosmology either involving new features fol-
lowing from known physics or involving new physics. While no convincing evidence
exists for any of them as of this writing, they are all being actively sought. Explain how
to generalize standard cosmology to accommodate these possibilities and to test for
them, repeating calculations, where possible.
(a) Space curvature (Sec. 28.2.2).
(b) Dark energy. Adopt an empirical equation of state with the parameter w being
constant and slightly greater than −1 (Sec. 28.7.3).
(c) Additional neutrino ﬂavors, including sterile neutrinos (Secs. 28.4.1 and 28.4.2).
(d) Nonadiabatic and non-Gaussian initial ﬂuctuations (Sec. 28.5.3). [Hint: Consult-
ing an advanced textbook is recommended.]
28.7.3
28.7.3 The Cosmological Constant and the Fate of the Universe
We have explained (Sec. 28.3.5) that the observed acceleration of the universe requires
an effective negative pressure in the stress-energy tensor, and how such a possibility
was anticipated by Einstein (1917). Furthermore, we have explained that Einstein’s
Einstein’s cosmological
constant,    
cosmological constant is consistent with the data. This is important, because it is a
simple prescription whose consequences can be computed without too many extrane-
ous assumptions and is therefore readily falsiﬁable. However, there are also theoretical
reasonsforquestioningthisinterpretation; they, too, lieattheinterfacebetweenquan-
tum and classical physics.
The earliest view of the cosmological constant (implicitly, that of Einstein) was
that its presence in the ﬁeld equations is an expression of the true law of gravitation
necessary on a large scale, in an analogous fashion to Newton proposing the inverse
square law for planets and expanding our understanding of gravitational force beyond
what is needed on the surface of Earth. The ultimate connection between the general
relativity of, say, stellar-mass black holes and that of the universe at large has yet to
be divined, but it should exist independent of the messy details of our cosmic envi-
ronment. Many interesting ideas have been proposed, in particular those involving
1444
Chapter 28. Cosmology

extra spatial dimensions and oscillating universes. There have even been proposals to
dispense with dark matter particles altogether and to interpret the observed motions
of stars and galaxies in terms of modiﬁed Newtonian gravity or entanglement.
Today it is more common to view the ﬁeld equations (Sec. 25.8) as providing a
completeframeworkfordescribinggravitationandthecosmologicalconstantasbeing
just one of several contributions to the stress-energy tensor. This is the approach we
   as a contribution to the
stress-energy tensor
followed in Sec. 28.3.5. Its most natural identiﬁcation is with the quantum mechanical
vacuum. Having TTT  ∝ggg ensures that the vacuum looks the same in all local Lorentz
   as the vacuum
frames, consistent with the principle of relativity. However, attempts to develop this
relationship quantitatively have mostly foundered on the tiny size of  relative to
the Planck scale of quantum gravity75—G2ℏρ ∼10−122. Either this represents an
unprecedented degree of ﬁne tuning, or the cosmological constant has even less to do
with quantum mechanics than, say, oceanography, and it is instead some ungrasped
expression of the “fabric” of spacetime on a supraclassical scale.76 If so, it throws down
a challenge to the reductionist view of physics, under which physics at essentially
all scales (especially classical physics) is viewed as being derivative of physics at the
reductionist view of
physics
smallest lengthscales and highest energies. The properties of materials depend on
the behavior of atoms and molecules, which depend on electrons and nuclei, which
depend on quantum electrodynamics and the interactions of quarks, and so on. This
does not preclude the existence, interest, or importance of emergent phenomena (e.g.,
ferromagnetism, shock fronts, or astrophysical black holes) that require appealing
to the properties of matter in bulk, but it is a statement of faith that ultimately, the
governing principles of these phenomena are reducible to the physics of the smallest
scales, even if this is not useful in describing what we observe. In this sense  might
   as emergent phenomena
be like ferromagnetism.
However, the square peg of quantum ﬁeld theory need not be forced into the round
hole of Riemannian geometry. The very existence of something like a cosmological
constant should also cause us to inquire whether some physics is derivative of the
largest scales and lowest energies instead of the smallest scales and the highest en-
ergies. Consider, allegorically, a bug in a still pond, living its low-Reynolds-number
life. A ﬁsh swims by, and the bug ﬁnds itself in the ﬁsh’s turbulent wake. It observes
that its food is moving more rapidly with an average speed that increases as the cube
root of its distance [Eq. (15.23)] and, if it is very sensitive, it might ﬁnd the water
75. A more intriguing possibility is that the natural, quantum mechanical mass scale for  is
∼(ℏ3ρ /c3)1/4 ∼10 meV, similar to the neutrino mass scale. However, there is no known good reason
for this.
76. It is interesting that the cosmological constant was taken very seriously before the 1980s (e.g., Lemaˆıtre,
1934; Tolman, 1934; Bondi, 1952a; Zel’dovich, 1968) because it allowed the universe to be older than its
contentsandbecauseitprovidedascaledistinctfromthoseassociatedwithatoms, nuclei, andelementary
particles (e.g., Eddington, 1933). However, the challenge of reconciling it with quantum ﬁeld theory
then led to its near abandonment. The subsequent discovery of cosmic acceleration therefore came as a
surprise to many physicists.
28.7 Three Mysteries
1445

heating up a little. While it is true that the Navier-Stokes equations can be derived by
suitable averaging of a kinetic theory, if the bug desires to reconcile its observations
with their causes, it is to the outer scale of a turbulent spectrum that it should turn, not
the properties of water molecules. The speculations involving the anthropic principle
and the multiverse contain some of this spirit. Perhaps  is “situational”—our ﬁrst
   as a “situational”
phenomenon
glimpse of physics on the large scale—just like blackbody radiation and the photo-
electric effect opened the door to the physics of small scales and quantum mechanics
more than a century ago. Of course, this physics, dependent on conditions at and
beyond our current horizon, might reﬂect what happened immediately prior to our
observable universe leaving the horizon during inﬂation; alternatively, it might reﬂect
the accidental properties of our contemporary cosmological environment.
Amorepragmaticapproachistoconsidergeneralizationsofthecosmologicalcon-
stant. These include dark energy (or quintessence; Perlmutter et al., 1999). In partic-
dark energy
ular, the behavior of the stress-energy tensor has been parameterized by introducing
an equation of state P = wρ , where w is negative, although there is no compelling
theoretical reason for doing this. Several observational studies have concluded that
|w + 1| <∼0.08, and more accuracy is in the works. Another common approach is to
invoke classical ﬁeld theory (just as we did for inﬂation) and to use the same formal-
ism to develop a description of contemporary inﬂation. It is tempting to suppose that
there have been many instances of inﬂation over the history of the universe, and that
Nature has managed to ﬁnd graceful exits from every one of these expansions in the
past and, in the fullness of time, it will do so again. However, there is no requirement
that this will ever happen. Another way to connect to inﬂation is to suppose that the
bottom of the inﬂaton potential well is associated with some sort of quantum me-
chanical zero-point energy or a classical offset, and that this is what the universe is
experiencing now.
A particularly interesting outcome would be if future observations demonstrated
that −P > ρ > 0; for example, if w < −1.77 This condition corresponds to negative
cosmological enthalpy and negative kinetic energy for a scalar ﬁeld (cf. Sec. 28.7.1).
Not only would it exclude a simple scalar ﬁeld; it would also, if taken literally, predict
an unusual fate for the universe. If w = const, then the ﬁrst law of thermodynamics
implies that eventually ρ ∝a−3(w+1). The energy density increases as the universe
expands if w < −1; the universe reaches inﬁnite size in ﬁnite time, while the hori-
big rip
zon shrinks and closer and closer neighbors disappear, a behavior dubbed “the big
rip.” Despite its eschatological fascination, many cosmologists reject this outcome on
grounds of physics inconsistency and regard w ≥−1 as a prediction.
As with the experimental searches for dark matter, the prospects for learning more
future measurements
about the expansion and fate of the universe from astronomical studies over the next
decade are bright, and the observations will presumably continue to corral speculative
77. This is sometimes known as a violation of the weak energy condition.
1446
Chapter 28. Cosmology

interpretation. At present, progress in cosmology seems to be following that in the
standard model of particle physics, where a relatively simple physical model sufﬁces
to account for essentially all data pertaining to questions addressed by the model,
whileleavingotherquestionstobeconfrontedbynewphysicsandfutureexperiments.
Three familiar constituents, baryons, neutrinos, and photons—supplemented by dark
matter, zero curvature, and a cosmological constant and imprinted with an almost
scale-freespectrumofadiabatic, Gaussianpotentialperturbations—sufﬁcetoaccount
for most of what we measure. It will be fascinating to see whether this apparent
simplicity is maintained through the next phase of cosmological exploration, when
the true nature of inﬂation, dark matter, and the cosmological constant will likely be
a focus of attention.
Bibliographic Note
The literature on cosmology is enormous, and it is not hard to ﬁnd excellent texts and
research papers to elaborate on the many topics we have touched on in this chapter.
Arguably, the most useful advanced text is Weinberg (2008). Other books that are
helpful on the physics but are rather out of date observationally are Padmanabhan
(1993); Peebles (1993); Kolb and Turner (1994); Peacock (1999); Dodelson (2003);
and Hobson, Efstathiou, and Lasenby (2006). Texts that emphasize the early universe
include Liddle and Lyth (2000) and Mukhanov (2005). An especially lucid and up-to-
date textbook accessible to undergraduates that emphasizes observational cosmology
is Schneider (2015). Excellent discussions of cosmology from a more elementary
standpoint include Ryden (2002) and Hartle (2003). Among the most important con-
temporary observations are the CMB results from the Planck (Planck Collaboration,
2016a, 2016b) and Wilkinson Microwave Anisotropy Probe (WMAP) (Komatsu et al.,
2011) satellites, one of several careful analyses of weak-lensing observations (Hey-
mans et al., 2012), and the preliminary results on galaxy clustering from the Baryon
Oscillation Spectroscopic Survey (BOSS) galaxy survey (Anderson et al., 2014).
Bibliographic Note
1447


REFERENCES
Abbott, B. P., R. Abbott, T. D. Abbott, M. R. Abernathy, et al. (2016a). Observation of gravita-
tional waves from a binary black hole merger. Physical Review Letters 116, 061102.
——— (2016b). GW150914: The advanced LIGO detectors in the era of ﬁrst discoveries.
Physical Review Letters 116, 131103.
Abbott, B. P., R. Abbott, R. Adhikari, P. Ajith, et al. (2009a). Observation of a kilogram-scale
oscillator near its quantum ground state. New Journal of Physics 11, 1–13.
——— (2009b). LIGO: the Laser Interferometer Gravitational-wave Observatory. Reports on
Progress in Physics 72, 076901.
Abernathy, F. (1968). National Committee for Fluid Mechanics Films movie: Fundamentals of
boundary layers.
Ablowitz, M. J. (2011). Nonlinear Dispersive Waves: Asymptotic Analysis and Solitons. Cam-
bridge: Cambridge University Press.
Acheson, D. J. (1990). Elementary Fluid Dynamics. Oxford: Clarendon Press.
Adair, R. K. (1990). The Physics of Baseball. New York: Harper and Row.
Ade, P. A. R., R. W. Aikin, D. Barkats, S. J. Benton, et al. (2014). BICEP2 I: Detection of B-mode
polarization at degree angular scales. Physical Review Letters 112, 241101.
Aichelberg, P. C., and R. U. Sexl (1971). On the gravitational ﬁeld of a massless particle. General
Relativity and Gravitation 2, 303–312.
Albrecht, A., and P. Steinhardt (1982). Cosmology for grand uniﬁed theories with radiatively
induced symmetry breaking. Physical Review Letters 48, 1220–1223.
Alfv´en, H. (1970). Plasma physics, space research and the origin of the solar system. Nobel lec-
ture. Available at http://www.nobelprize.org/nobel_prizes/physics/laureates/1970/alfven-
lecture.pdf. Chapter 19 epigraph reprinted with permission of The Nobel Foundation.
Alligood, K. T., T. D. Sauer, and J. A. Yorke (1996). Chaos, an Introduction to Dynamical
Systems. Berlin: Springer-Verlag.
Allis, W. P., S. J. Buchsbaum, and A. Bers (1963). Waves in Anisotropic Plasmas. Cambridge,
Mass.: MIT Press.
Almheiri, A., D. Marolf, J. Polchinski, and J. Sully (2013). Black holes: Complementarity or
ﬁrewalls? Journal of High Energy Physics 2, 62–78.
Anderson, J. D. (2003). Modern Compressible Flow: With Historical Perspective. New York:
McGraw-Hill.
1449

Anderson, L., E. Aubourg, S. Bailey, F. Beutler, et al. (2014). The clustering of galaxies in the
SDSS-III baryon oscillation spectroscopic survey: Baryon acoustic oscillations in the data
releases 10 and 11 galaxy samples. Monthly Notices of the Royal Astronomical Society 441,
24–62.
Anderson, M. H., J. R. Ensher, M. R. Matthews, C. E. Wieman, and E. A. Cornell (1995).
Observation of Bose-Einstein condensation in a dilute atomic vapor. Science 269, 198–201.
Andersson, N., and G. L. Comer (2007). Relativistic ﬂuid dynamics: Physics for many different
scales. Living Reviews in Relativity 10, 1.
Archimedes (ca 250 BC). Exclamation (perhaps apochryphal) upon discovering a variant of
Archimedes’ Law, which is presented in his book On Floating Bodies.
Arfken, G. B., H. J. Weber, and F. E. Harris (2013). Mathematical Methods for Physicists.
Amsterdam: Elsevier.
Armenti, A. J. (1992). The Physics of Sports. New York: American Institute of Physics.
Arnol’d, V. I. (1992). Catastrophe Theory. Cham, Switzerland: Springer.
Ashby, N., and J. Dreitlein (1975). Gravitational wave reception by a sphere. Physical Re-
view D 12, 336–349.
Bachman, H. E. (1994). Vibration Problems in Structures. Basel: Birkhauser.
Baker, G. L., and J. P. Gollub (1990). Chaotic Dynamics, An Introduction. Cambridge: Cam-
bridge University Press.
Basov, N. G., and A. M. Prokhorov (1954). First Russian ammonia maser. Journal of Experi-
mental and Theoretical Physics 27, 431–438.
——— (1955). Possible methods for obtaining active molecules for a molecular oscillator.
Journal of Experimental and Theoretical Physics 28, 249–250.
Batchelor, G. K. (2000). An Introduction to Fluid Dynamics. Cambridge: Cambridge University
Press.
Bateman, G. (1978). MHD Instabilities. Cambridge, Mass.: MIT Press.
B˚ath, M. (1966). Earthquake energy and magnitude. In L. H. Ahrens, F. Press, S. K. Runcorn,
and H. C. Urey (eds.), Physics and Chemistry of the Earth, pp. 115–165. Oxford: Pergamon.
Baumgarte, T. W., and S. Shapiro (2010). Numerical Relativity: Solving Einstein’s Equations on
the Computer. Cambridge: Cambridge University Press.
Beckwith, S. V., M. Stiavelli, A. M. Koekemoer, J. A. R. Caldwell, et al. (2006). The Hubble
Ultra Deep Field. Astronomical Journal 132, 1729–1755.
Bejan, A. (2013). Convection Heat Transfer. New York: Wiley.
Bekeﬁ, G. (1966). Radiation Processes in Plasmas. New York: Wiley.
Bekenstein, J. (1952). Black holes and the second law. Lettre al Nuovo Cimento 4, 737–740.
Bellan, P. M. (2000). Spheromaks. London: Imperial College Press.
——— (2006). Fundamentals of Plasma Physics. Cambridge: Cambridge University Press.
Bennett, C. A. (2008). Principles of Physical Optics. New York: Wiley.
Bennett, C. L., M. Halpern, G. Hinshaw, and N. E. Jarosik (2003). First-year Wilkinson
Microwave Anisotropy Probe (WMAP) Observations: Preliminary Maps and Basic Re-
sults. Astrophysical Journal Supplement 148, 1–28.
Bernstein, I. B., J. M. Greene, and M. D. Kruskal (1957). Exact nonlinear plasma oscillations.
Physical Review 108, 546–550.
Bernstein, I. B., E. A. Frieman, M. D. Kruskal, and R. M. Kulsrud (1958). An energy principle
for hydromagnetic stability problems. Proceedings of the Royal Society A 244, 17–40.
Berry, M. (1990). Anticipations of the geometric phase. Physics Today 43, 34–40.
1450
References

Berry, M. V., and C. Upstill (1980). Catastrophe optics: Morphologies of caustics and their
diffraction patterns. Progress in Optics 18, 257–346.
Bertotti, B. (1959). Uniform electromagnetic ﬁeld in the theory of general relativity. Physical
Review 116, 1331–1333.
Bertotti, B., L. Iess, and P. Tortora (2003). A test of general relativity using radio links with the
Cassini spacecraft. Nature 425, 374–376.
Biedermann, G. W., X. Wu, L. Deslauriers, S. Roy, C. Mahadeswaraswamy, and M. A. Kasevich
(2015). Testing gravity with cold-atom interferometers. Physical Review A 91, 033629.
Binney, J. J., and S. Tremaine (2003). Galactic Dynamics. Princeton, N.J.: Princeton University
Press.
Birkhoff, G. (1923). Relativity and Modern Physics. Cambridge, Mass.: Harvard University
Press.
Birn, J., and E. Priest (2007). Reconnection of Magnetic Fields. Cambridge: Cambridge Univer-
sity Press.
Bittencourt, J. A. (2004). Fundamentals of Plasma Physics. Berlin: Springer-Verlag.
Black, E. D. (2001). An introduction to Pound–Drever–Hall laser frequency stabilization.
American Journal of Physics 69, 79–87.
Blanchet, L. (2014). Gravitational radiation from post-Newtonian sources and inspiraling
compact binaries. Living Reviews in Relativity 17, 2.
Blandford, R. D., and D. Eichler (1987). Particle acceleration at astrophysical shocks: A theory
of cosmic ray origin. Physics Reports 154, 1–75.
Blandford, R. D., and R. Narayan (1992). Cosmological applications of gravitational lensing.
Annual Reviews of Astronomy and Astrophysics 30, 311–358.
Blandford R. D., and M. J. Rees (1974). A “twin-exhaust” for double radio sources. Monthly
Notices of the Royal Astronomical Society 169, 395–415.
Blandford, R. D., and R. L. Znajek (1977). The electromagnetic extraction of energy from Kerr
black holes. Monthly Notices of the Royal Astronomical Society 179, 433–456.
Blandford, R. D., A. B. Saust, T. G. Brainerd, and J. Villumsen (1991). The distortion of distant
galaxy images by large-scale structure. Monthly Notices of the Royal Astronomical Society
251, 600–627.
Boas, M. L. (2006). Mathematical Methods in the Physical Sciences. New York: Wiley.
Bogolyubov, N. N. (1962). Problems of a dynamical theory in statistical physics. In J. de
Boer and G. E. Uhlenbeck (eds.), Studies in Statistical Mechanics, p. 1. Amsterdam: North
Holland.
Bondi, H. (1952a). Cosmology. Cambridge: Cambridge University Press.
——— (1952b). On spherically symmetric accretion. Monthly Notices of the Royal Astronomical
Society 112, 195–204.
Boresi, A. P., and K. P. Chong (1999). Elasticity in Engineering Mechanics. New York: Wiley.
Born, M., and H. S. Green (1949). A General Kinetic Theory of Liquids. Cambridge: Cambridge
University Press.
Born, M., and E. Wolf (1999). Principles of Optics: Electromagnetic Theory of Propagation,
Interference and Diffraction of Light. Cambridge: Cambridge University Press.
Boyd, R. W. (2008). Nonlinear Optics. New York: Academic Press.
Boyd, T. J. M., and J. J. Sanderson (2003). The Physics of Plasmas. Cambridge: Cambridge
University Press.
References
1451

Brady, P. R., S. Droz, and S. M. Morsink (1998). The late-time singularity inside non-spherical
black holes. Physical Review D 58, 084034–084048.
Braginsky, V. B., and F. Y. Khalili (1992). Quantum Measurement. Cambridge: Cambridge
University Press.
Braginsky, V.B., M.L.Gorodetsky, andS.P.Vyatchanin(1999).Thermodynamicalﬂuctuations
and photo-thermal shot noise in gravitational wave antennae. Physics Letters A 264, 1–10.
Brenner, M. P., S. Hilgenfeldt, and D. Lohse (2002). Single bubble sonoluminescence. Reviews
of Modern Physics 74, 425–484.
Brooker, G. (2003). Modern Classical Optics. Oxford: Oxford University Press.
Brown, L., and G. Gabrielse (1986). Geonium theory: Physics of a single electron or ion in a
Penning trap. Reviews of Modern Physics 58, 233–311.
Brown, R. (1828). XXVII. A brief account of microscopical observations made in the months
of June, July and August 1827, on the particles contained in the pollen of plants; and on
the general existence of active molecules in organic and inorganic bodies. Philosophical
Magazine 4, 161–173.
Bryson, A. (1964). National Committee for Fluid Mechanics Films movie: Waves in ﬂuids.
Burke, W. L. (1970). Runaway solutions: Remarks on the asymptotic theory of radiation
damping. Physical Review A 2, 1501–1505.
——— (1971). Gravitational radiation damping of slowly moving systems calculated using
matched asymptotic expansions. Journal of Mathematical Physics 12, 402–418.
Cahn, R., and G. Goldhaber (2009). The Experimental Foundations of Particle Physics. Cam-
bridge: Cambridge University Press.
Callen, H. B., and T. A. Welton (1951). Irreversibility and generalized noise. Physical Review 83,
34–40.
Carroll, S.M.(2004).SpacetimeandGeometry.AnIntroductiontoGeneralRelativity.NewYork:
Addison-Wesley.
Carter, B. (1979). The general theory of the mechanical, electromagnetic and thermodynamic
properties of black holes. In S. W. Hawking and W. Israel (eds.), General Relativity, an
Einstein Centenary Survey. Cambridge: Cambridge University Press.
Cathey, W. T. (1974). Optical Information Processing and Holography. New York: Wiley.
Caves, C. M. (1980). Quantum-mechanical radiation-pressure ﬂuctuations in an interferom-
eter. Physical Review Letters 45, 75–79.
——— (1981). Quantum mechanical noise in an interferometer. Physical Review D 23, 1693–
1708.
Chan, J., T. M. Alegre, A. H. Safavi-Naeini, J. T. Hill, et al. (2011). Laser cooling of a nano-
mechanical oscillator into its quantum ground state. Nature 478, 89–92.
Chandler, D. (1987). Introduction to Modern Statistical Mechanics. Oxford: Oxford University
Press.
Chandrasekhar, S. (1939). Stellar Structure. Chicago: University of Chicago Press.
——— (1961). Hydrodynamics and Hydromagnetic Stability. Oxford: Oxford University Press.
——— (1962). Ellipsoidal Figures of Equilibrium. New Haven, Conn.: Yale University Press.
——— (1983). The Mathematical Theory of Black Holes. Oxford: Oxford University Press.
Chelton, D., and M. Schlax (1996). Global observations of oceanic Rossby waves. Science 272,
234–238.
Chen, F. F. (1974). Introduction to Plasma Physics. New York: Plenum Press.
1452
References

——— (2016). Introduction to Plasma Physics and Controlled Fusion, third edition. Heidelberg:
Springer.
Chew, G. F., M. L. Goldberger, and F. E. Low (1956). The Boltzmann equation and the one-
ﬂuid hydromagnetic equations in the absence of particle collisions. Proceedings of the Royal
Society A 236, 112–118.
Chou, C. W., D. B. Hume, T. Rosenband, and D. J. Wineland (2010). Optical clocks and
relativity. Science 329, 1630–1633.
Chu, S., C. Cohen-Tannoudji, and W. D. Phillips (1998). Nobel lectures. Reviews of Modern
Physics 70, 685–742.
Ciufolini, I., et al. (2016). A test of general relativity using the LARES and LAGEOS satellites
and a GRACE Earth gravity model. Measurement of Earth’s dragging of inertial frames.
The European Physical Journal C 76, 120.
Clash, J. (2012). An interview with the late Sally Ride. Available at http://www.askmen.com/
entertainment/right-stuff/sally-ride-interview.html. Chapter 17 epigraph reprinted with
permission of Jim Clash.
Clayton, D. D. (1968). Principles of Stellar Evolution and Nucleosynthesis. Chicago: University
of Chicago Press.
Clemmow, P. C., and J. P. Dougherty (1969). Electrodynamics of Particles and Plasmas. New
York: Addison-Wesley.
Cohen-Tannoudji, C., B. Diu, and F. Lalo¨e (1977). Quantum Mechanics. New York: Wiley.
Cole, J. (1974). Perturbation Methods in Applied Mathematics. New York: Blaisdell Publishing.
Coles, D. (1965). National Committee for Fluid Mechanics Films movie: Channel ﬂow of a
compressible ﬂuid.
Constantinescu, A., and A. Korsunsky (2007). Elasticity with Mathematica. Cambridge: Cam-
bridge University Press.
Copson, E. T. (1935). An Introduction to the Theory of Functions of a Complex Variable. Oxford:
Oxford University Press.
Cornell, E. (1996). Very cold indeed: The nanokelvin physics of Bose-Einstein condensation.
Journal of Research of NIST 101, 419–434.
Cox, Arthur N., ed. (2000). Allen’s Astrophysical Quantities. Cham, Switzerland: Springer.
Creighton, J. D. E., and W. G. Anderson (2011). Listening to the Universe. New York: Wiley.
Crookes, W. (1879). The Bakerian lecture: On the illumination of lines of molecular pressure,
and the trajectory of molecules. Philosophical Transactions of the Royal Society 170, 135–
164.
Cundiff, S. T. (2002). Phase stabilization of ultrashort optical pulses. Journal of Physics D 35,
43–59.
Cundiff, S. T., and J. Ye (2003). Colloquium: Femtosecond optical frequency combs. Reviews
of Modern Physics 75, 325–342.
Cushman-Roisin, B., and J.-M. Beckers (2011). Introduction to Geophysical Fluid Dynamics.
New York: Academic Press.
Cutler, C., and K. S. Thorne (2002). An overview of gravitational wave sources. In N. Bishop
and S. D. Maharaj (eds.), Proc. GR16 Conference on General Relativity and Gravitation,
pp. 72–111. Singapore: World Scientiﬁc.
Cyburt, R. H., B. D. Fields, K. A. Olive, and T.-H. Yeh (2016). Big bang nucleosynthesis: Present
status. Reviews of Modern Physics 88, 015004.
References
1453

Dalfovo, F., S. Giorgini, L. P. Pitaevskii, and S. Stringari (1999). Theory of Bose-Einstein
condensation in trapped gases. Reviews of Modern Physics 71, 463–512.
Darwin, C. (1959). The gravity ﬁeld of a particle. Proceedings of the Royal Society A 249, 180–
194.
Dauxois, T., and M. Peyrard (2010). Physics of Solitons. Cambridge: Cambridge University
Press.
Davidson, P. A. (2001). An Introduction to Magnetohydrodynamics. Cambridge: Cambridge
University Press.
——— (2005). Turbulence: An Introduction for Scientists and Engineers. Oxford: Oxford Uni-
versity Press.
Davidson, R. C. (1972). Methods in Nonlinear Plasma Theory. New York: Academic Press.
Davies, P. C. W. (1977). The thermodynamic theory of black holes. Proceedings of the Royal
Society A 353, 499–521.
Davison, L. (2010). Fundamentals of Shock Wave Propagation in Solids.Berlin: Springer-Verlag.
DeMorest, P. B., T. Pennucci, S. M. Ransom, M. S. E. Roberts, et al. (2010). A two solar mass
neutron star measured using Shapiro delay. Nature 467, 1081–1083.
Dicke, R. H. (1961). Dirac’s cosmology and Mach’s principle. Nature 192, 440–441.
Dodelson, S. (2003). Modern Cosmology. New York: Academic Press.
Doob, J. L. (1942). The Brownian movement and stochastic equations. Annals of Mathemat-
ics 43, 351–369.
Dorf, R. C., and R. H. Bishop (2012). Modern Control Systems. Upper Saddle River, N.J.:
Pearson.
Drazin, P. G., and R. S. Johnson (1989). Solitons: An Introduction. Cambridge: Cambridge
University Press.
Drazin, P. G., and W. H. Reid (2004). Hydrodynamic Stability. Cambridge: Cambridge Univer-
sity Press.
Duderstadt, J. J., and L. J. Hamilton (1976). Nuclear Reactor Analysis. New York: Wiley.
Dyson, F. (1986). Quoted in T. A. Heppenheimer, After the Sun dies. Omni 8, no. 11, 38.
Chapter 23 epigraph reprinted with permission of Freeman Dyson.
Eckart, C. (1940). The thermodynamics of irreversible processes, III: Relativistic theory of the
simple ﬂuid. Physical Review 58, 919–924.
Eddington, A. S. (1919). The total eclipse of 1919 May 29 and the inﬂuence of gravitation on
light. Observatory 42, 119–122.
——— (1922). The Mathematical Theory of Relativity. Cambridge: Cambridge University Press.
——— (1927). March 1927 Gifford lecture at the University of Edinburgh. As published in
Arthur S. Eddington: The Nature of the Physical World Gifford Lectures of 1927: An
Annotated Edition by H. G. Callaway. Cambridge: Cambridge Scholars Publishing (2014).
Chapter 16 epigraph reprinted with permission of the publisher.
——— (1933). The Expanding Universe. Cambridge: Cambridge University Press.
Einstein, A. (1907). ¨Uber das Relativit¨atsprinzip und die ausdemselben gesogenen Folgerun-
gen. Jahrbuch der Radioaktivit¨at und Elektronik 4, 411–462.
——— (1915). Die Feldgleichungen der Gravitation. Sitzungsberichte der Preussischen
Akademie 1915, 844–847.
——— (1916a). Die Grundlage der allgemeinen Relativit¨atstheorie. Annalen der Physik 49,
769–822.
1454
References

——— (1916b). N¨aherungsweise Integration der Feldgleichungen der Gravitation. Sitzungs-
berichte der Preussischen Akademie der Wissenschaften 1916, 688–696.
——— (1917). Kosmologische Betrachtungen zur allgemeinen Relativit¨atstheorie. Sitzungs-
berichte der Preussischen Akademie der Wissenschaften 1917, 142–152.
——— (1918). ¨Uber Gravitationswellen. Sitzungsberichte der Preussischen Akademie der Wis-
senschaften 1918, 154–167.
——— (1925). Quantum theory of ideal gases. Sitzungsberichte der Preussischen Akademie der
Wissenschaften 3, 18–25.
——— (1931). Zum kosmologischen Problem der allgemeinen Relativit¨atstheorie. Sitzungs-
berichte der Preussischen Akademie der Wissenschaften 1931, 235–237.
——— (1934) On the method of theoretical physics. Philosphy of Science 1, 163–169. Pub-
lished version of Einstein’s Herbert Spencer Lecture, delivered at Oxford, June 10, 1933.
Chapter 25 epigraph reprinted with permission of the University of Chicago Press.
——— (1989). The Collected Papers of Albert Einstein. Princeton, N.J.: Princeton University
Press.
Eisenstein, D. J., I. Zehavi, D. W. Hogg, R. Scoccimarro, et al. (2005). Detection of the baryon
acoustic peak in the large-scale correlation function of SDSS luminous red galaxies. Astro-
physical Journal 633, 560–574.
Ensher, J. R., D. S. Jin, M. R. Matthews, C. E. Wieman, and E. A. Cornell (1996). Bose-Einstein
condensationinadilutegas:Measurementofenergyandground-stateoccupation.Physical
Review Letters 77, 4984–4987.
Eringen, A. C., and E. S. Suhubi (1975). Elastodynamics, Vol. II: Linear Theory. New York:
Academic Press.
Everett, A., and T. Roman (2011). Time Travel and Warp Drives: A Scientiﬁc Guide to Shortcuts
through Time and Space. Chicago: University of Chicago Press.
Everitt, C. W. F., D. B. DeBra, B. W. Parkinson, J. P. Turneaure, et al. (2011). Gravity Probe B:
Final results of a space experiment to test general relativity. Physical Review Letters 106,
221101.
Faber, T. E. (1995). Fluid Dynamics for Physicists. Cambridge: Cambridge University Press.
Faraday, M. (1846). Thoughts on ray vibrations. Philosophical Magazine 140, 147–161.
Farquhar, I. E. (1964). Ergodic Theory in Statistical Mechanics. London: Interscience.
Feigenbaum, M. (1978). Universal behavior in nonlinear systems. Journal of Statistical Phys-
ics 19, 25–52.
Fenstermacher, P. R., H. L. Swinney, and J. P. Gollub (1979). Dynamical instabilities and the
transition to chaotic Taylor vortex ﬂow. Journal of Fluid Mechanics 94, 103–128.
Feynman, R. P. (1966). The Character of Physical Law. Cambridge, Mass.: MIT Press.
——— (1972). Statistical Mechanics. New York: Benjamin.
Feynman, R. P., R. B. Leighton, and M. Sands (1964). The Feynman Lectures on Physics. Read-
ing, Mass.: Addison-Wesley. Chapter 14 epigraph reprinted with permission of Caltech.
Fierz, M., and W. Pauli (1939). On relativistic wave equations for particles of arbitrary spin in
an electromagnetic ﬁeld. Proceedings of the Royal Society A 173, 211–232.
Finkelstein, D. (1958). Past-future asymmetry of the gravitational ﬁeld of a point particle.
Physical Review 110, 965–967.
Flanders, H. (1989). Differential Forms with Applications to the Physical Sciences, corrected
edition. Mineola, N.Y.: Courier Dover Publications.
References
1455

Fletcher, C. A. J. (1991). Computational Techniques for Fluid Dynamics, Vol I: Fundamental
and General Techniques. Berlin: Springer-Verlag.
Forbes, T., and E. Priest (2007). Magnetic Reconnection. Cambridge: Cambridge University
Press.
Fortere, Y., J. M. Skothelm, J. Dumals, and L. Mahadevan (2005). How the Venus ﬂytrap snaps.
Nature 433, 421–425.
Francon, M., and I. Willmans (1966). Optical Interferometry. New York: Academic Press.
Franklin, G. F., J. D. Powell, and A. Emami-Naeini (2005). Feedback Control of Dynamic
Systems. Upper Saddle River, N.J.: Pearson.
Fraunhofer, J. von (1814–1815). Determination of the refractive and color-dispersing power
of different types of glass, in relation to the improvement of achromatic telescopes.
Denkschriften der K¨oniglichen Academie der Wissenschaften zu M¨unchen 5, 193–226.
Frautschi, S. (1982). Entropy in an expanding universe. Science 217, 593–599.
Friedman, J., and A. Higuchi (2006). Topological censorship and chronology protection.
Annalen der Physik 15, 109–128.
Friedmann, A. A. (1922). ¨Uber die Kr¨ummung des Raumes. Zeitschrift f¨ur Physik 10, 377–386.
Frolov, V. P., and I. D. Novikov (1990). Physical effects in wormholes and time machines.
Physical Review D 42, 1057–1065.
——— (1998). Black Hole Physics: Basic Concepts and New Developments. Dordrecht: Kluwer.
Frolov, V. P., and D. N. Page (1993). Proof of the generalized second law for quasistationary
semiclassical black holes. Physical Review Letters 71, 3902–3905.
Frolov, V. P., and A. Zelnikov (2011). Introduction to Black Hole Physics. Oxford: Oxford
University Press.
Fuller, R. W., and J. A. Wheeler (1962). Causality and multiply connected spacetime. Physical
Review 128, 919–929.
Fultz, D. (1969). National Committee for Fluid Mechanics Films movie: Rotating ﬂows.
Galleani, L. (2012). The statistics of the atomic clock noise. In L. Cohen et al. (eds.), Classical,
Semi-classical and Quantum Noise, pp. 63–77. Cham, Switzerland: Springer Science +
Business Media.
Genzel, R., F. Eisenhauer, and S. Gillessen (2010). The galactic center massive black hole and
nuclear star cluster. Reviews of Modern Physics 82, 3121–3195.
Ghatak, A. (2010). Optics. New Delhi: McGraw-Hill.
Ghez, A. M., S. Salim, N. N. Weinberg, J. R. Lu, et al. (2008). Measuring distance and properties
of the Milky Way central supermassive black hole with stellar orbits. Astrophysical Journal
689, 1044–1062.
Gibbs, J. W. (1881). Letter accepting the Rumford Medal. Quoted in A. L. Mackay, Dictionary
of Scientiﬁc Quotations. London: IOP Publishing.
——— (1902). Elementary Principles in Statistical Mechanics. New York: Charles Scribner’s
Sons.
Gill, A. E. (1982). Atmosphere-Ocean Dynamics. New York: Academic Press.
Gladwell, G. M. L. (1980). Contact Problems in the Classical Theory of Elasticity. Alphen aan
den Rijn: Sijthoff and Noordhoff.
Goedbloed, J. P., R. Keppens, and S. Poedts (2010). Advanced Magnetohydrodynamics. Cam-
bridge: Cambridge University Press.
Goedbloed, J. P., and S. Poedts (2004). Principles of Magnetohydrodynamics, with Applications
to Laboratory and Astrophysical Plasmas. Cambridge: Cambridge University Press.
1456
References

Goldstein, H., C. Poole, and J. Safko (2002). Classical Mechanics. New York: Addison-Wesley.
Gollub, J. P., and S. V. Benson (1980). Many routes to turbulent convection. Journal of Fluid
Mechanics 100, 449–470.
Goodman, J. W. (1985). Statistical Optics. New York: Wiley.
——— (2005). Introduction to Fourier Optics. Englewood, Colo.: Roberts and Company.
Goodman, J. J., R. W. Romani, R. D. Blandford, and R. Narayan (1987). The effect of caustics on
scintillating radio sources. Monthly Notices of the Royal Astronomical Society 229, 73–102.
Goodstein, D. L. (2002). States of Matter. Mineola, N.Y.: Courier Dover Publications.
Goodstein, D. L., and J. R. Goodstein (1996). Feynman’s Lost Lecture: The Motion of Planets
around the Sun. New York: W. W. Norton.
Gordon, J. P., H. J. Zeiger, and C. H. Townes (1954). Molecular microwave oscillator and new
hyperﬁne structure in the microwave spectrum of NH3. Physical Review 95, 282–284.
——— (1955). The maser—new type of microwave ampliﬁer, frequency standard, and spec-
trometer. Physical Review 99, 1264–1274.
Gorman, M., and H. L. Swinney (1982). Spatial and temporal characteristics of modulated
waves in the circular Couette system. Journal of Fluid Mechanics 117, 123–142.
Gourgoulhon, E. (2013). Special Relativity in General Frames: From Particles to Astrophysics.
Berlin: Springer-Verlag.
Grad, H. (1958). Principles of the Kinetic Theory of Gases. Cham, Switzerland: Springer.
Greenspan, H. P. (1973). The Theory of Rotating Fluids. Cambridge: Cambridge University
Press.
Grifﬁths, D. J. (1999). Introduction to Electrodynamics. Upper Saddle River, N.J.: Prentice-Hall.
——— (2004). Introduction to Quantum Mechanics. Upper Saddle River, N.J.: Prentice-Hall.
Grossman, S. (2000). The onset of shear ﬂow turbulence. Reviews of Modern Physics 72, 603–
618.
Guth, A. H. (1981). Inﬂationary universe: A possible solution to the horizon and ﬂatness
problems. Physical Review D 23, 347–356.
Gutzwiller, M. C. (1990). Chaos in Classical and Quantum Mechanics. New York: Springer
Verlag.
Hafele, J. C., and R. E. Keating (1972a). Around-the-world atomic clocks: Predicted relativistic
time gains. Science 177, 166–168.
——— (1972b). Around-the-world atomic clocks: Observed relativistic time gains. Science 177,
168–170.
Hariharan, P. (2007). Basics of Interferometry. New York: Academic Press.
Harrison, E. R. (1970). Fluctuations at the threshold of classical cosmology. Physical Re-
view D 1, 2726–2730.
Hartle, J. B. (2003). Gravity: An Introduction to Einstein’s General Relativity. San Francisco:
Addison-Wesley.
Hassani, S. (2013). Mathematical Physics: A Modern Introduction to Its Foundations. Cham,
Switzerland: Springer.
Hawking, S. W. (1975). Particle creation by black holes. Communications in Mathematical
Physics 43, 199–220.
——— (1976). Black holes and thermodynamics. Physical Review D 13, 191–197.
Hawking, S. W., and R. Penrose (2010). The Nature of Space and Time. Princeton, N.J.: Prince-
ton University Press.
References
1457

Heaviside, O. (1912). Electromagnetic Theory, Volume III, p. 1. London: “The Electrician”
Printing and Publishing.
Hecht, E. (2017). Optics. New York: Addison-Wesley.
Heisenberg, W. (1969). Signiﬁcance of Sommerfeld’s work today. In Bopp F., and H. Kleinpop-
pen (eds.), Physics of the One and Two Electron Atoms, p. 1. Amsterdam: North Holland.
Chapter 18 epigraph reprinted with permission of the publisher.
H´enon, M. (1982). Vlasov equation? Astronomy and Astrophysics 114, 211–212.
Heymans, C., L. van Waerbeke, L. Miller, T. Erben, et al. (2012). CFHTLenS: The Canada-
France-Hawaii telescope lensing survey. Monthly Notices of the Royal Astronomical Soci-
ety 427, 146–166.
Hilbert, D. (1915). Die Grundlagen der Physik. K¨onigliche Gesellschaft der Wissenschaften zu
G¨ottingen. Mathematische-physikalische Klasse. Nachrichten 1917, 53–76.
Hobbs, G., A. Archibald, Z. Arzoumanian, D. Backer, et al. (2010). The International Pulsar
Timing Array project: Using pulsars as a gravitational wave detector. Classical and Quan-
tum Gravity 27, 8, 084013.
Hobson, M. P., G. P. Efstathiou, and A. N. Lasenby (2006). General Relativity: An Introduction
for Physicists. Cambridge: Cambridge University Press.
Hooke, R. (1678). Answer to the anagram “ceiiinosssttuv,” which he had previously published,
to establish his priority on the linear law of elasticity. De Potentia, or of spring explaining
the power of springing bodies, Hooke’s Sixth Cutler Lecture, R. T. Gunther facsimile
reprint. In Early Science in Oxford. Vol. 8. London: Dawsons of Pall Mall (1968).
Hubble, E. P. (1929). A relation between distance and radial velocity among extragalactic
nebulae. Proceedings of the National Academy of Sciences 15, 169–173.
Hull, J. C. (2014). Options, Futures and Other Derivatives, ninth edition. Upper Saddle River,
N.J.: Pearson.
Hurricane, O. A., D. A. Callahan, D. T. Casey, P. M. Cellers, et al. (2014). Fuel gain exceeding
unity in an inertially conﬁned fusion explosion. Nature 506, 343–348.
Iizuka, K. (1987). Engineering Optics. Berlin: Springer-Verlag.
Illingworth, G. D., and the HUDF09 team (2013). The HST extreme deep ﬁeld (XDF): Com-
bining all ACS and WFC3/IR data on the HUDF region into the deepest ﬁeld ever. Astro-
physical Journal Supplement Series 209, 6.
Iorio, L., M. L. Ruggiero, and C. Corda (2013). Novel considerations about the error budget
of the LAGEOS-based tests of frame-dragging with GRACE geopotential models. Acta
Astronautica 91, 141–148.
Isaacson, R. A. (1968a). Gravitational radiation in the limit of high frequency. I. The linear
approximation and geometrical optics. Physical Review 166, 1263–1271.
——— (1968b). Gravitational radiation in the limit of high frequency. II. Nonlinear terms and
the effective stress tensor. Physical Review 166, 1272–1280.
Israel, W., and J. M. Stewart (1980). Progress in relativistic thermodynamics and electrody-
namics of continuous media. In A. Held, (ed.), General Relativity and Gravitation. Vol. 2.
One Hundred Years after the Birth of Albert Einstein, p. 491. New York: Plenum Press.
Jackson, J. D. (1999). Classical Electrodynamics. New York: Wiley.
James, O., E. von Tunzelmann, P. Franklin, and K. S. Thorne (2015a). Gravitational lensing by
spinning black holes in astrophysics, and in the movie Interstellar. Classical and Quantum
Gravity 32, 065001.
——— (2015b). Visualizing Interstellar’s Wormhole. American Journal of Physics 83, 486–499.
1458
References

Jeans, J. H. (1929). Astronomy and Cosmology, second edition. Cambridge: Cambridge Uni-
versity Press.
Jeffrey, A. and T. Taniuti, eds. (1966). Magnetohydrodynamic Stability and Thermonuclear
Conﬁnement: A Collection of Reprints. New York: Academic Press.
Jenkins, F. A., and H. E. White (1976). Fundamentals of Optics. New York: McGraw-Hill.
Johnson, J. B. (1928). Thermal agitation of electricity in conductors. Physical Review 32, 97–
109.
Johnson, K. L. (1985). Contact Mechanics. Cambridge: Cambridge University Press.
Johnson, L. R. (1974). Green’s function for Lamb’s problem. Geophysical Journal of the Royal
Astronomical Society 37, 99–131.
Kachru, S., R. Kallosh, A. Linde, and S. Trivedi (2003). De Sitter vacua in string theory. Physical
Review D 68, 046005.
Kapitsa, P. L., and P. A. M. Dirac (1933). The reﬂection of electrons from standing light waves.
Proceedings of the Cambridge Philosophical Society 29, 297–300.
Kapner, D.J., T.S.Cook, E.G.Adelberger, J.H.Gundlach, etal.(2008).Testsofthegravitational
inverse-square law below the dark-energy length scale. Physical Review Letters 98, 021101.
Kardar, M. (2007). Statistical Physics of Particles. Cambridge: Cambridge University Press.
Kaspi, V., and M. Kramer (2016). Radio pulsars: The neutron star population and fundamental
physics. In R. D. Blandford, D. Gross, and A. Sevrin (eds.), Proceedings of the 26th Solvay
Conference on Physics, Astrophysics and Cosmology, pp. 21–62. Singapore: World Scientiﬁc.
Kausel, E. (2006). Fundamental Solutions in Elastodynamics. Cambridge: Cambridge Univer-
sity Press.
Kay, B. S., M. J. Radzikowski, and R. M. Wald (1997). Quantum ﬁeld theory on spacetimes
with a compactly generated Cauchy horizon. Communications in Mathematical Physics
183, 533–556.
Kazanas, D. (1980). Dynamics of the universe and spontaneous symmetry breaking. Astro-
physical Journal 241, L59–L63.
Keilhacker, M., and the JET Team (1998). Fusion physics progress on JET. Fusion Engineering
and Design 46, 273–290.
Kerr, R. P. (1963). Gravitational ﬁeld of a spinning mass as an example of algebraically special
metrics. Physical Review Letters 11, 237–238.
Kim, S.-W., and K. S. Thorne (1991). Do vacuum ﬂuctuations prevent the creation of closed
timelike curves? Physical Review D 43, 3929–3949.
Kirkwood, J. G. (1946). Statistical mechanical theory of transport processes. I. General theory.
Journal of Chemical Physics 14, 180–201.
Kittel, C. (2004). Elementary Statistical Physics. Mineola, N.Y.: Courier Dover Publications.
Kittel, C., and H. Kroemer (1980). Thermal Physics. London: Macmillan.
Klein, M. V., and T. E. Furtak (1986). Optics. New York: Wiley.
Kleppner, D., and R. K. Kolenkow (2013). An Introduction to Mechanics. Cambridge: Cam-
bridge University Press.
Kolb, E. W., and M. S. Turner (1994). The Early Universe. New York: Addison-Wesley.
Kolsky, H. (1963). Stress Waves in Solids. Mineola, N.Y.: Courier Dover Publications.
Komatsu, E., K. M. Smith, J. Dunkley, C. L. Bennett, et al. (2011). Seven-year Wilkinson
Microwave Anisotropy Probe (WMAP) observations: Cosmological interpretation. Astro-
physical Journal Supplement 192, 18–35.
References
1459

Kompaneets, A. (1957). The establishment of thermal equilibrium between quanta and elec-
trons. Journal of Experimental and Theoretical Physics 4, 730–737.
Krall, N. A., and A. W. Trivelpiece (1973). Principles of Plasma Physics. New York: McGraw-
Hill.
Kramer, M., I. H. Stairs, R. N. Manchester, M. A. McLaughlin, et al. (2006). Tests of general
relativity from timing the double pulsar. Science 314, 97–102.
Kravtsov, Y. A. (2005). Geometrical Optics in Engineering Physics. Oxford: Alpha Science
International.
Kruer, W. L. (1988). The Physics of Laser-Plasma Interactions. New York: Addison-Wesley.
Kruskal, M. D. (1960). The maximal extension of the Schwarzschild metric. Physical Re-
view 119, 1743–1745.
Kulsrud, R. M. (2005). Plasma Physics for Astrophysics. Princeton, N.J.: Princeton University
Press.
Kundu, P. K., I. M. Cohen, and D. R. Dowling (2012). Fluid Mechanics. New York: Academic
Press.
La Porta, A., R. Slusher, and B. Yurke (1989). Back-action evading measurements of an optical
ﬁeld using parametric down conversion. Physical Review Letters 62, 28–31.
Lagerstrom, P. (1988). Matched Asymptotic Expansions: Ideas and Techniques. Berlin: Springer-
Verlag.
Lamb, H.(1882).Onthevibrationsofanelasticsphere.ProceedingsoftheLondonMathematical
Society 13, 189–212.
Landau, L. D. (1944). On the problem of turbulence. Doklady Akademii Nauk SSSR 44, 311–
314.
——— (1946). On the vibrations of the electronic plasma. Journal of Physics USSR 10, 25–37.
Landau, L. D., and E. M. Lifshitz (1941). Teoriya Polya. Moscow: Gosudarstvennoye Izda-
tel’stvo Tekhniko-Teoreticheskoi Literaturi. First Russian edition of Landau and Lifshitz
(1951).
——— (1951). The Classical Theory of Fields, ﬁrst English edition. Cambridge, Mass.: Addison-
Wesley.
——— (1959). Fluid Mechanics. Oxford: Pergamon.
——— (1975). The Classical Theory of Fields, fourth English edition. Oxford: Butterworth-
Heinemann.
——— (1976). Mechanics. Oxford: Butterworth-Heinemann.
——— (1986). Elasticity. Oxford: Pergamon.
Landau, L. D., L. P. Pitaevskii, and E. M. Lifshitz (1979). Electrodynamics of Continuous Media.
Oxford: Butterworth-Heinemann.
Landauer, R. (1961). Irreversibility and heat generation in the computing process. IBM Journal
of Research and Development 5, 183–191.
——— (1991). Information is physical. Physics Today 44, 23–29.
Langmuir, I. (1928). Oscillations in Ionized Gases. Proceedings of the National Academy of
Sciences 14, 627–637. Chapter 22 epigraph reprinted with permission of the publisher.
Lautrup, B. (2005). Physics of Continuous Matter. Bristol and Philadelphia: Institute of Physics
Publishing.
Lax, M. J., W. Cai, M. Xu, and H. E. Stanley (2006). Random Processes in Physics and Finance.
Oxford: Oxford University Press.
1460
References

Lee, B. W., and S. Weinberg (1977). Cosmological lower bound on heavy-neutrino masses.
Physical Review Letters 39, 165–167.
Lemaˆıtre, G. (1927). Un univers homog`ene de masse constante et de rayon croissant rendant
compte de la vitesse radiale des n´ebuleuses extra-galactiques. Annales de la Soci´et´e Scien-
tiﬁque Bruxelles A 47, 49–59.
——— (1933). La formation des nebuleuses dans l’univers en expansion. Comptes Rendus 196,
903–904. Translated in Cosmology and Controversy: The Historical Development of Two
Theories of the Universe by Helge Kragh. Copyright © 1996 by Princeton University Press.
Chapter 28 epigraph reprinted with permission of Princeton University Press.
——— (1934). Evolution of the expanding universe. Proceedings of the National Academy of
Sciences 20, 12–17.
Levin, J., and G. Perez-Giz (2008). A periodic table for black hole orbits. Physical Review D 77,
103005–103023.
Levin, Y. (1998). Internal thermal noise in the LIGO test masses: A direct approach. Physical
Review D 57, 659–663.
Lewin, L. (1981). Polylogarithms and Associated Functions. New York: North Holland.
Libbrecht, K. G., and M. F. Woodard (1991). Advances in helioseismology. Science 253, 152–
157.
Libchaber, A., C. Laroche, and S. Fauve (1982). Period doubling cascade in mercury, a quan-
titative measurement. Journal de Physique—Lettres 43, L211–L216.
Liddle, A., and D. Lyth (2000). Cosmological Inﬂation and Large Scale Structure. Cambridge:
Cambridge University Press.
Liepmann, H., and A. Roshko (2002). Compressible Gas Dynamics. Mineola, N.Y.: Courier
Dover Publications.
Lifshitz, E. M., and L. P. Pitaevskii (1980). Statistical Physics, Part 1. Oxford: Pergamon.
——— (1981). Physical Kinetics. Oxford: Pergamon.
Lighthill, M. J. (1952). On sound generated aerodynamically. I. General theory. Proceedings of
the Royal Society A 211, 564–587.
——— (1954). On sound generated aerodynamically. II. Turbulence as a source of sound.
Proceedings of the Royal Society A 222, 1–32.
——— (1986). An Informal Introduction to Theoretical Fluid Mechanics. Oxford: Oxford Uni-
versity Press.
——— (2001). Waves in Fluids. Cambridge: Cambridge University Press.
Lightman, A. P., W. H. Press, R. H. Price, and S. A. Teukolsky (1975). Problem Book in Relativity
and Gravitation. Princeton, N.J.: Princeton University Press.
LIGO Scientiﬁc Collaboration (2015). Advanced LIGO. Classical and Quantum Gravity 32,
074001.
Linde, A. (1982). A new inﬂationary universe scenario: A possible solution to the horizon,
ﬂatness, homogeneity, isotropy and primordial monopole problems. Physics Letters B 108,
389–393.
Liu, Y. T., and K. S. Thorne (2000). Thermoelastic noise and thermal noise in ﬁnite-sized
gravitational-wave test masses. Physical Review D 62, 122002–122011.
Longair, M. S. (2011). High Energy Astrophysics. Cambridge: Cambridge University Press.
Longhurst, R. S. (1973). Geometrical and Physical Optics. London: Longmans.
L´opez-Monsalvo, C. S. (2011). Covariant Thermodynamics and Relativity, PhD thesis, Univer-
sity of Southampton. Available at https://arxiv.org/pdf/1107.1005.pdf.
References
1461

Lorentz, H. A. (1904). Electromagnetic phenomena in a system moving with any velocity
smaller than that of light. Proceedings of the Royal Netherlands Academy of Arts and Sciences
(KNAW) 6, 809–831.
Lorentz, H. A., A. Einstein, H. Minkowski, and H. Weyl (1923). The Principle of Relativity: A
Collection of Original Memoirs on the Special and General Theory of Relativity. Mineola,
N.Y.: Courier Dover Publications.
Lorenz, E. N. (1963). Deterministic nonperiodic ﬂow. Journal of Atmospheric Sciences 20, 130–
141.
Love, A. E. H. (1927). A Treatise on the Mathematical Theory of Elasticity. Mineola, N.Y.:
Courier Dover Publications.
Lynden-Bell, D. (1967). Statistical mechanics of violent relaxation in stellar systems. Monthly
Notices of the Royal Astronomical Society 136, 101–121.
Macintosh, B., J. R. Graham, P. Ingraham, Q. Konopacky, et al. (2014). First light of the Gemini
planet imager. Proceedings of the National Academy of Sciences 111, 12661–12666.
Mack, J. E. (1947). Semi-Popular Motion Picture Record of the Trinity Explosion. University of
Michigan Library, Ann Arbor.
Maggiore, M. (2007). Gravitational Waves. Volume 1: Theory and Experiment. Oxford: Oxford
University Press.
Maiman, T. H. (1960). Stimulated optical radiation in ruby. Nature 187, 493–494.
Majda, A. J., and A. L. Bertozzi (2002). Vorticity and Incompressible Flow. Cambridge: Cam-
bridge University Press.
Marion, J. B., and S. T. Thornton (1995). Classical Dynamics of Particles and Systems. Philadel-
phia: Saunders College Publishing.
Maris, H. J., and L. P. Kadanoff (1978). Teaching the renormalization group. American Journal
of Physics 46, 653–657.
Marko, J. F., and S. Cocco (2003). The micro mechanics of DNA. Physics World 16, 37–41.
Marolf, D., and A. Ori (2013). Outgoing gravitational shock-wave at the inner horizon: The
late-time limit of black hole interiors. Physical Review D 86, 124026.
Maroto, J. A., V. Perez-Munuzuri, and M. S. Romero-Cano (2007). Introductory analysis of
Benard-Marangoni convection. European Journal of Physics 28, 311–320.
Marsden, J. E., and T. J. Hughes (1986). Mathematical Foundations of Elasticity. Upper Saddle
River, N.J.: Prentice-Hall.
Martin, R. F. (1986). Chaotic particle dynamics near a two-dimensional neutral point with
application to the geomagnetic tail. Journal of Geophysical Research 91, 11985–11992.
Mather, J. C., E. S. Cheng, D. A. Cottingham, R. E. Eplee Jr., et al. (1994). Measurement of the
cosmic microwave background spectrum by the COBE FIRAS instrument. Astrophysical
Journal 420, 439–444.
Mathews, J., and R. L. Walker (1970). Mathematical Methods of Physics. New York: Benjamin.
Maxwell, J. C. (1873). Letter to William Grylls Adams (3 Dec 1873). In P. M. Harman (ed.).
(1995). The Scientiﬁc Letters and Papers of James Clerk Maxwell, Vol 2, 1862–1873, pp.
949–950. Cambridge: Cambridge University Press.
McClelland, D. E., N. Mavalvala, Y. Chen, and R. Schnabel (2011). Advanced interferometry,
quantum optics and optomechanics in gravitational wave detectors. Lasers and Photonics
Reviews 5, 677–696.
McEliece, R. J. (2002). The Theory of Information and Coding. Cambridge: Cambridge Univer-
sity Press.
1462
References

McKinney, J. C., A. Tchekhovskoy, and R. D. Blandford (2012). General relativistic magneto-
hydrodynamical simulations of magnetically choked accretion ﬂows around black holes.
Monthly Notices of the Royal Astronomical Society 423, 3083–3117.
Meier, D. L. (2012). Black Hole Astrophysics: The Engine Paradigm. Cham, Switzerland:
Springer.
Melrose, D. B. (1980). Plasma Astrophysics. New York: Gordon and Breach.
——— (1984). Instabilities in Space and Laboratory Plasmas. Cambridge: Cambridge University
Press.
——— (2008). Quantum Plasmadynamics, Vol 1: Unmagnetized Plasmas. Cham, Switzerland:
Springer.
——— (2012). Quantum Plasmadynamics, Vol 2: Magnetized Plasmas. Cham, Switzerland:
Springer.
Merkowitz, S. M. (2010). Tests of gravity using lunar laser ranging. Living Reviews in Relativ-
ity 13, 7.
Messiah, A. (1962). Quantum Mechanics, Volume II. New York: North Holland.
Metropolis, N., A. Rosenbluth, M. Rosenbluth, A. Teller, and E. Teller (1953). Combinatorial
minimization. Journal of Chemical Physics 21, 1087–1092.
Michell, J. (1783). On the means of discovering the distance, magnitude, etc., of the ﬁxed stars,
in consequence of the diminution of their light, in case such a diminution should be found
to take place in any of them, and such other data should be procured from observations, as
would be further necessary for that purpose. Philosophical Transactions of the Royal Society
of London 74, 35–57; presented to the Royal Society on November 27, 1783.
Michelson, A. A., and F. G. Pease (1921). Measurement of the diameter of α Orionis with the
interferometer. Astrophysical Journal 53, 249–259.
Mikhailovskii, A. B. (1998). Instabilities in a Conﬁned Plasma. Bristol and Philadelphia: Insti-
tute of Physics Publishing.
Miles, J. (1993). Surface-wave generation revisited. Journal of Fluid Mechanics 256, 427–441.
Millikan, R. A. (1938). Biographical Memoir of Albert Abraham Michelson, 1852–1931. Bio-
graphical Memoirs of the National Academy of Sciences of the United States of America 19,
121–146. Chapter 4 epigraph reprinted with permission of the publisher.
Minkowski, H. (1908). Space and time. Address delivered at the 80th Assembly of German
NaturalScientistsandPhysicians, atCologne, Germany, September21, 1908.FirstGerman
publication: Jahresbericht der Deutschen Mathematiker-Vereinigung 1909, 75–88. English
translation in Lorentz et al. (1923).
Misner, C. W., K. S. Thorne, and J. A. Wheeler (1973). Gravitation. San Francisco: Freeman.
Morris, M., and K. S. Thorne (1988). Wormholes in spacetime and their use for interstellar
travel: A tool for teaching general relativity. American Journal of Physics 56, 395–416.
Morris, M. S., K. S. Thorne, and U. Yurtsever (1988). Wormholes, time machines, and the weak
energy condition. Physical Review Letters 61, 1446–1449.
Mrou´e, A. H., M. A. Scheel, B. Szilagyi, H. P. Pfeiffer, et al. (2013). Catalog of 174 black hole
simulations for gravitational wave astronomy. Physical Review Letters 111, 241104.
Mukhanov, V. (2005). Physical Foundations of Modern Cosmology. Cambridge: Cambridge
University Press.
Munson, B. R., D. F. Young, and T. H. Okiishi (2006). Fundamentals of Fluid Mechanics. New
York: Wiley.
References
1463

NIST (2005). Final Report on the Collapse of the World Trade Center Towers. National Institute
of Standards and Technology Report Number NIST NCSTAR 1. Washington, D.C.: U.S.
Government Printing Ofﬁce.
——— (2008). Final Report on the Collapse of the World Trade Center Building 7. National
Institute of Standards and Technology Report Number NIST NCSTAR 1A. Washington,
D.C.: U.S. Government Printing Ofﬁce.
Nelson, P. (2008). Biological Physics. San Francisco: Freeman.
Newton, I. (1687). Philosophiae Naturalis Principia Mathematica. London: Royal Society. En-
glish translation by I. B. Cohen and A. Whitman. Berkeley: University of California Press
(1999).
Ni, W.-T., and M. Zimmermann (1978). Inertial and gravitational effects in the proper refer-
ence frame of an accelerated, rotating observer. Physical Review D 17, 1473–1476.
Nichols, D., R. Owen, F. Zhang, A. Zimmerman, et al. (2011). Visualizing spacetime curvature
via frame-drag vortexes and tidal tendexes: General theory and weak-gravity applications.
Physical Review D 84, 124014.
Noether, E. (1918). Invariante Variationenprobleme. Nachrichten von der Gesellschaft der
Wissenschaften zu G¨ottingen 1918, 235–257.
Northrop, T. (1963). Adiabatic Motion of Charged Particles. New York: Interscience.
Nye, J. (1999). Natural Focusing and Fine Structure of Light. Bristol and Philadelphia: Institute
of Physics Publishing.
Nyquist, H. (1928). Thermal agitation of electric charge in conductors. Physical Review 32,
110–113.
Oelker, T. I., T. Isogai, J. Miller, M. Tse, et al. (2016). Audio-band frequency-dependent
squeezing for gravitational-wave detectors. Physical Review Letters 116, 041102.
Ogorodnikov, K. F. (1965). Dynamics of Stellar Systems. Oxford: Pergamon.
Onsager, L. (1944). Crystal statistics. I. A two-dimensional model with an order-disorder
transition. Physical Review 65, 117–149.
Oort, J. H. (1932). The force exerted by the stellar system in the direction perpendicular to
the galactic plane and some related problems. Bulletin of the Astronomical Institute of the
Netherlands 238, 249–287.
Oppenheimer, J. R., and H. Snyder (1939). On continued gravitational contraction. Physical
Review 56, 455–459.
Oppenheimer, J. R., and G. Volkoff (1939). On massive neutron cores. Physical Review 55,
374–381.
Ott, E.(1982).Strangeattractorsandchaoticmotionsofdynamicalsystems.Reviews of Modern
Physics 53, 655–671.
——— (1993). Chaos in Dynamical Systems. Cambridge: Cambridge University Press.
Overduin, J., F. Everitt, P. Worden, and J. Mester (2012). STEP and fundamental physics.
Classical and Quantum Gravity 29, 184012.
Owen, R., J. Brink, Y. Chen, J. D. Kaplan, et al. (2011). Frame-dragging vortexes and tidal
tendexes attached to colliding black holes: Visualizing the curvature of spacetime. Physical
Review Letters 106, 151101.
Padmanabhan, T. (1993). Structure Formation in the Universe. Cambridge: Cambridge Univer-
sity Press.
Page, D. N., F. Weinhold, R. L. Moore, F. Weinhold, and R. E. Barker (1977). Thermodynamic
paradoxes. Physics Today 30, 11.
1464
References

Pais, A. (1982). Subtle Is the Lord. . . . The Science and Life of Albert Einstein. Oxford: Oxford
University Press.
Panton, R. L. (2005). Incompressible Flow. New York: Wiley.
Parker, E. N. (1979). Cosmical Magnetic Fields. Oxford: Clarendon Press.
Parker, L., and D. Toms (2009). Quantum Field Theory in Curved Spacetime: Quantized Fields
and Gravity. Cambridge: Cambridge University Press.
Parks, G. K. (2004). Physics of Space Plasmas: An Introduction. Boulder: Westview Press.
Pathria, R. K., and P. D. Beale (2011). Statistical Mechanics, third edition. Amsterdam: Elsevier.
Paul, W., and J. Baschnagel (2010). Stochastic Processes: From Physics to Finance. Cham,
Switzerland: Springer.
Peacock, J. A. (1999). Cosmological Physics. Cambridge: Cambridge University Press.
Peccei, R. D., and H. R. Quinn (1977). CP conservation in the presence of pseudoparticles.
Physical Review Letters 38, 1440–1443.
Pedlosky, J. (1987). Geophysical Fluid Dynamics. Berlin: Springer-Verlag.
Pedrotti, F. L., L. S. Pedrotti, and L. M. Pedrotti (2007). Introduction to Optics. Upper Saddle
River, N.J.: Pearson.
Peebles, P. J. E. (1993). Principles of Physical Cosmology. Princeton, N.J.: Princeton University
Press.
Peebles, P. J. E., and J. T. Yu (1970). Primeval adiabatic perturbation in an expanding universe.
Astrophysical Journal 162, 815–836.
Pellew, A., and R. V. Southwell (1940). On maintained convective motion in a ﬂuid heated
from below. Proceedings of the Royal Society A 176, 312–343.
Penrose, O. (1960). Electrostatic instabilities of a uniform non-Maxwellian plasma. Physics of
Fluids 3, 258–265.
Penrose, R. (1999). The Emperor’s New Mind: Concerning Computers, Minds, and the Laws of
Physics. Oxford: Oxford University Press.
——— (2016). Fashion, Faith and Fantasy in the New Physics of the Universe. Princeton, N.J.:
Princeton University Press.
Penzias, A. A., and R. W. Wilson (1965). A measurement of excess antenna temperature at
4080 Mc/s. Astrophysical Journal 142, 419–421.
Perlmutter, S., M. Turner, and M. White (1999). Constraining dark energy with Type Ia
supernovae and large-scale structure. Physical Review Letters 83, 670–673.
Perlmutter, S., G. Aldering, G. Goldhaber, R. A. Knop, et al. (1999). Measurements of  and
 from 42 high-redshift supernovae. Astrophysical Journal 517, 565–586.
Petters, A. O., H. Levine, and J. Wambsganss (2001). Singularity Theory and Gravitational
Lensing. Cham, Switzerland: Springer.
Pﬁster, H. (2007). On the history of the so-called Lense-Thirring effect. General Relativity and
Gravitation 39, 1735–1748.
Phillips, O. M. (1957). On the generation of waves by turbulent wind. Journal of Fluid Mechan-
ics 2, 417–445.
Pierce, J. R. (2012). An Introduction to Information Theory: Symbols, Signals and Noise. Mine-
ola, N.Y.: Courier Dover Publications.
Pines, D., and J. R. Schrieffer (1962). Approach to equilibrium of electrons, plasmons and
phonons in quantum and classical plasmas. Physical Review 125, 804–812.
Planck, M.(1949).ScientiﬁcAutobiographyandOtherPapers.NewYork:PhilosophicalLibrary.
Chapter 24 epigraph reprinted with permission of the publisher.
References
1465

Planck Collaboration (2016a). Planck 2015 results. I. Overview of products and scientiﬁc
results. Astronomy and Astrophysics 594, A1.
——— (2016b). Planck 2015 results. XIII. Cosmological parameters. Astronomy and Astro-
physics 594, A13.
Pontecorvo, B. (1968). Neutrino experiments and the problem of conservation of leptonic
charge. Soviet Physics JETP 26, 984–988.
Pop, I., and D. B. Ingham (2001). Convective Heat Transfer: Mathematical Computational
Modelling of Viscous Fluids and Porous Media. Amsterdam: Elsevier.
Pope, S. B. (2000). Turbulent Flows. Cambridge: Cambridge University Press.
Poruchikov, V. B., V. A. Khokhryakov, and G. P. Groshev (1993). Methods of the Classical
Theory of Elastodynamics. Berlin: Springer-Verlag.
Poston, T., and I. Stewart (2012). Catastrophe Theory and Its Applications. Mineola, N.Y.:
Courier Dover Publications.
Potter, M. C., D. C. Wiggert, and B. H. Ramadan (2012). Mechanics of Fluids. Stamford, Conn.:
Cengage Learning.
Press, W. H. (1978). Flicker noises in astronomy and elsewhere. Comments on Astrophysics 7,
103–119.
Press, W. H., S. A. Teukolsky, W. T. Vetterling, and B. P. Flannery (2007). Numerical Recipes:
The Art of Scientiﬁc Computing. Cambridge: Cambridge University Press.
Purcell, E. M. (1983). The back of the envelope. American Journal of Physics 51, 205.
Raisbeck, G. (1963). Information Theory. Cambridge, Mass.: MIT Press.
Ransom, S. M., I. H. Stairs, A. M. Archibald, J.W.T. Hessels, et al. (2014). A millisecond pulsar
in a stellar triple system. Nature 505, 520–524.
Rashed, R. 1990. A pioneer in anaclastics: Ibn Sahl on burning mirrors and lenses. Isis 1, 464–
491.
Reichl, L. E. (2009). A Modern Course in Statistical Physics. London: Arnold.
Reif, F. (2008). Fundamentals of Statistical and Thermal Physics. Long Grove, Ill.: Waveland
Press.
Rezzolla, L., and O. Zanotti (2013). Relativistic Hydrodynamics. Oxford: Oxford University
Press.
Richardson, L. (1922). Weather Prediction by Numerical Process. Cambridge: Cambridge at the
University Press.
Richter, C. F. (1980). Interview with Henry Spall. Earthquake Information Bulletin, January–
February. Chapter 12 epigraph reprinted with permission of the publisher.
Ride, S.(2012).InterviewwithJimClash.Availableathttp://www.askmen.com/entertainment/
right-stuff/sally-ride-interview.html. Reprinted by permission of Jim Clash.
Riess, A. G., A. Filippenko, P. Challis, A. Clochiatti, et al. (1998). Observational evidence
from supernovae for an accelerating universe and a cosmological constant. Astronomical
Journal 116, 1009–1038.
Roberts, M. S., and R. Whitehurst (1975). The rotation curve and geometry of M31 at large
galactocentric distances. Astrophysical Journal 201, 327–346.
Robertson, H. P. (1935). Kinematics and world structure I. Astrophysical Journal 82, 248–301.
——— (1936a). Kinematics and world structure II. Astrophysical Journal 83, 187–201.
——— (1936b). Kinematics and world structure III. Astrophysical Journal 83, 257–271.
Robinson, I. (1959). A solution of the Maxwell-Einstein equations. Bulletin of the Polish
Academy of Sciences 7, 351–352.
1466
References

Roddier, F. (1981). The effects of atmospheric turbulence in optical astronomy. Progress in
Optics 19, 281–376.
Rohrlich, F. (1965). Classical Charged Particles. New York: Addison-Wesley.
Rosenbluth, M. N., M. MacDonald, and D. L. Judd (1957). Fokker-Planck equation for an
inverse square force. Physical Review 107, 1–6.
Rouse, H. (1963a). University of Iowa movie: Introduction to the study of ﬂuid motion.
Available at
http://www.iihr.uiowa.edu/research/publications-and-media/ﬁlms-by-hunter-rouse/.
——— (1963b). University of Iowa movie: Fundamental principles of ﬂow. Available at
http://www.iihr.uiowa.edu/research/publications-and-media/ﬁlms-by-hunter-rouse/.
——— (1963c). University of Iowa movie: Fluid motion in a gravitational ﬁeld. Available at
http://www.iihr.uiowa.edu/research/publications-and-media/ﬁlms-by-hunter-rouse/.
——— (1963d). University of Iowa movie: Characteristics of laminar and turbulent ﬂow.
Available at
http://www.iihr.uiowa.edu/research/publications-and-media/ﬁlms-by-hunter-rouse/.
——— (1963e). University of Iowa movie: Form, drag, lift, and propulsion. Available at
http://www.iihr.uiowa.edu/research/publications-and-media/ﬁlms-by-hunter-rouse/.
——— (1963f). University of Iowa movie: Effects of ﬂuid compressibility. Available at
http://www.iihr.uiowa.edu/research/publications-and-media/ﬁlms-by-hunter-rouse/.
Rubin, V. C., and W. K. Ford, Jr. (1970). Rotation of the Andromeda nebula from a spectro-
scopic survey of emission regions. Astrophysical Journal 159, 379–403.
Ruelle, D. (1989). Chaotic Evolution and Strange Attractors. Cambridge: Cambridge University
Press.
Ryan, M., and L. Shepley (1975). Homogeneous, Relativistic Cosmology.Princeton, N.J.: Prince-
ton University Press.
Ryden, B. S. (2002). Introduction to Cosmology. New York: Addison-Wesley.
Sachs, R. K., and A. M. Wolfe (1967). Perturbations of a cosmological model and angular
variations of the microwave background. Astrophysical Journal 147, 73–90.
Sagdeev, R. Z., and C. F. Kennel (1991). Collisionless shock waves. Scientiﬁc American 264,
April issue, 106–113.
Sagdeev, R.Z., D.A.Usikov, andG.M.Zaslovsky(1988).Non-linearPhysicsfromthePendulum
to Turbulence and Chaos. Newark, N.J.: Harwood Academic Publishers.
Sakharov, A. D. (1965). The initial stage of an expanding universe and the appearance of a
nonuniform distribution of matter. Journal of Experimental and Theoretical Physics 49,
345–358.
Sahl, I. (984). On Burning Mirrors and Lenses. Discussed in Rashed (1990).
Saleh, B. E., and M. C. Teich (2007). Fundamentals of Photonics. New York: Wiley.
Sathyaprakash, B. S., and B. F. Schutz (2009). Physics, astrophysics and cosmology with grav-
itational waves. Living Reviews in Relativity 12, 3.
Sato, K. (1981). Cosmological baryon number domain structure and the ﬁrst order phase
transition of the vacuum. Physics Letters B 33, 66–70.
Saulson, P. (1994). Fundamentals of Interferometric Gravitational Wave Detectors. Singapore:
World Scientiﬁc.
Saunders, P. T. (1980). An Introduction to Catastrophe Theory. Cambridge: Cambridge Univer-
sity Press.
References
1467

Schlamminger, S., K.-Y. Choi, T. A. Wagner, J. H. Gundlach, and E. G. Adelberger (2008). Test
of the equivalence principle using a rotating torsion balance. Physical Review Letters 100,
041101.
Schmidt, G. (1979). Physics of High Temperature Plasmas. New York: Academic Press.
Schneider, P. (2015). Extragalactic Astronomy and Cosmology. Heidelberg: Springer.
Schneider, P., J. Ehlers, and E. Falco (1992). Gravitational Lensing. Berlin: Springer-Verlag.
Schneier, B. (1997). Applied Cryptography: Protocols, Algorithms and Source Code in C. New
York: Wiley.
Schr¨odinger, E. (1944). What Is Life? Cambridge: Cambridge University Press.
Schutz, B. (2009). A First Course in General Relativity. Cambridge: Cambridge University
Press.
Schwarzschild, K. (1903). Zur Elektrodynamik. 1. Zwei Formen des Princips der Action in der
Elektrontheorie. Nachrichten von der Gesellschaft der Wissenschaften zu G¨ottingen 1903,
126–131.
——— (1916a). ¨Uber das Gravitationsfeld eines Massenpunktes nach der Einsteinschen The-
orie. Sitzungsberichte der Preussischen Akademie der Wissenschaften 1916, 189–196.
——— (1916b). ¨Uber das Gravitationsfeld einer Kugel aus Inkompressibler Fl¨ussigkeit nach
der Einsteinschen Theorie. Sitzungsberichte der Preussischen Akademie der Wissenschaften
1916, 424–434.
Scott-Russell, J. (1844). Report on waves. British Association for the Advancement of Science 14,
311–390, Plates XLVII–LVII.
Sedov, L. I. (1946). Propagation of strong blast waves. Prikhladnaya Matematika i Mekhanika
10, 241–250.
———(1957).RussianLanguageFourthEdtionofSedov(1993):Metodypodobiyairazmernosti
v mekhanike. Moskva: Gostekhizdat.
——— (1993). Similarity and Dimensional Methods in Mechanics. Boca Raton, Fla.: CRC Press.
Sethna, J. P. (2006). Statistical Mechanics: Entropy, Order Parameters, and Complexity. Oxford:
Oxford University Press.
Shannon, C. E. (1948). A mathematical theory of communication. Bell System Technical Jour-
nal 27, 379–423.
Shapiro, A. (1961a). National Committee for Fluid Mechanics Films. Available at web.mit.edu/
hml/ncfmf.html.
——— (1961b). National Committee for Fluid Mechanics Films movie: Vorticity.
Shapiro, S. L., and S. A. Teukolsky (1983). Black Holes, White Dwarfs and Neutron Stars: The
Physics of Compact Objects. New York: Wiley.
Sharma, K. (2006). Optics: Principles and Applications. New York: Academic Press.
Shearer, P. M. (2009). Introduction to Seismology. Cambridge: Cambridge University Press.
Shercliff, J. A. (1965). National Committee for Fluid Mechanics Films movie: Magnetohydro-
dynamics.
Shibata, M. (2016). Numerical Relativity. Singapore: World Scientiﬁc.
Shkarofsky, I. P., T. W. Johnston, and M. P. Bachynski (1966). The Particle Kinetics of Plasmas.
New York: Addison-Wesley.
Silk, J. (1968). Cosmic black-body radiation and galaxy formation. Astrophysical Journal 151,
459–471.
Slaughter, W. S. (2002). The Linearized Theory of Elasticity. Boston: Birkh¨auser.
1468
References

Southwell, R. V. (1941). An Introduction to the Theory of Elasticity for Engineers and Physicists.
Oxford: Clarendon Press.
Spitzer, Jr., L. (1962). Physics of Fully Ionized Gases. New York: Interscience. Chapter 20
epigraph reprinted with permission of the publisher.
Spitzer, Jr., L., and R. Harm (1953). Transport phenomena in a completely ionized gas. Physical
Review 89, 977–981.
Spivak, M. (1999). A Comprehensive Introduction to Differential Geometry,Volumes 1–5. Hous-
ton: Publish or Perish.
Stacey, F. D. (1977). Physics of the Earth. New York: Wiley.
Stanyukovich, K. P. (1960). Unsteady Motion of Continuous Media. Oxford: Pergamon.
Starobinsky, A.(1980).Anewtypeofisotropiccosmologicalmodelwithoutsingularity.Physics
Letters B 91, 99–102.
Stein, S., and M. Wysession (2003). An Introduction to Seismology, Earthquakes and Earth
Structure. Oxford: Blackwell.
Stewart, R. W. (1968). National Committee for Fluid Mechanics Films movie: Turbulence.
Stix, T. H. (1992). Waves in Plasmas. New York: American Institute of Physics.
Straumann, N. (2013). General Relativity. Cham, Switzerland: Springer.
Strogatz, S. H. (2008). Nonlinear Dynamics and Chaos: With Applications to Physics, Biology,
Chemistry and Engineering. Boulder: Westview Press.
Sturrock, P. A. (1994). Plasma Physics: An Introduction to the Theory of Astrophysical, Geophys-
ical and Laboratory Plasmas. Cambridge: Cambridge University Press.
Sunyaev, R. A., and Ya. B. Zel’dovich (1970). Small-scale ﬂuctuations of relic radiation. Astro-
physics and Space Science 7, 3–19.
Susskind, L. (2005). The Cosmic Landscape: String Theory and the Illusion of Intelligent Design.
New York: Little, Brown.
Swanson, D. G. (2003). Plasma Waves. Bristol and Philadelphia: Institute of Physics Publishing.
Szekeres, G. (1960). On the singularities of a Riemann manifold. Publicationes Mathematicae
Debrecen 7, 285–301.
Tanimoto, T., and J. Um (1999). Cause of continuous oscillations of the earth. Journal of
Geophysical Research 104, 28723–28739.
Taylor, E. (1968). National Committee for Fluid Mechanics Films movie: Secondary ﬂow.
Taylor, E. F., and J. A. Wheeler (1966). Spacetime Physics, ﬁrst edition. San Francisco: Freeman.
——— (1992). Spacetime Physics, second edition. San Francisco: Freeman.
Taylor, G. (1950). The formation of a blast wave by a very intense explosion. II. The atomic
explosion of 1945. Proceedings of the Royal Society A 201, 175–186.
——— (1964). National Committee for Fluid Mechanics Films movie: Low Reynolds number
ﬂows.
Tennekes, H., and J. L. Lumley (1972). A First Course on Turbulence. Cambridge, Mass.: MIT
Press.
ter Haar, D. (1955). Foundations of statistical mechanics. Reviews of Modern Physics 27, 289–
338.
Thom, R. (1994). Structural Stability and Morphogenesis. Boulder: Westview Press.
Thompson, P. A. (1984). Compressible Fluid Dynamics. Boulder: Maple Press.
Thorne, K.S.(1973).Relativisticshocks:TheTaubadiabat.AstrophysicalJournal 179, 897–907.
References
1469

——— (1980). Multipole expansions of gravitational radiation. Reviews of Modern Physics 52,
299–340.
———(1981).Relativisticradiativetransfer—momentformalisms.MonthlyNoticesoftheRoyal
Astronomical Society 194, 439–473.
——— (1983). The theory of gravitational radiation: An introductory review. In N. Dereulle
and T. Piran (eds.), Gravitational Radiation, pp. 1–57. New York: North Holland.
——— (1994). Black Holes and Time Warps: Einstein’s Outrageous Legacy. New York: W. W.
Norton.
——— (2014). The Science of Interstellar. New York: W. W. Norton.
Thorne, K. S., M. Bondarescu, and Y. Chen (2002). Gravitational waves: A web-based course.
Available at http://elmer.caltech.edu/ph237/.
Thorne, K. S., and J. Hartle (1985). Laws of motion and precession for black holes and other
bodies. Physical Review D 31, 1815–1837.
Thorne, K. S., R. H. Price, and D. A. MacDonald (1986). Black holes: the Membrane Paradigm.
New Haven, Conn.: Yale University Press.
Timoshenko, S., and J. N. Goodier (1970). Theory of Elasticity. New York: McGraw-Hill.
Todhunter, I., and K. Pearson (1886). A History of the Theory of Elasticity and of the Strength
of Materials, from Galilei to the Present Time. Cambridge: Cambridge University Press.
Tolman, R. C. (1934). Relativity, Thermodynamics and Cosmology. Oxford: Oxford University
Press.
——— (1938). The Principles of Statistical Mechanics. Mineola, N.Y.: Courier Dover
Publications.
——— (1939). Static solutions of Einstein’s ﬁeld equations for spheres of ﬂuid. Physical Re-
view 55, 364–373.
Toro, E. F. (2010). Riemann Solvers and Numerical Methods for Fluid Dynamics: A Practical
Introduction. Berlin: Springer-Verlag.
Townes, C. H. (2002). How the Laser Happened: Adventures of a Scientist. Oxford: Oxford
University Press. Chapter 10 epigraph reprinted with permission of the publisher.
Townsend, A. A. (1949). The fully developed turbulent wake of a circular cylinder. Australian
Journal of Scientiﬁc Research 2, 451–468.
Tranah, D., and P. T. Landsberg (1980). Thermodynamics of non-extensive entropies II. Col-
lective Phenomena 3, 81–88.
Tritton, D. J. (1987). Physical Fluid Dynamics. Oxford: Oxford University Press.
Tsytovich, V. (1970). Nonlinear Effects in Plasma. New York: Plenum.
Turco, R. P., O. B. Toon, T. B. Ackerman, J. B. Pollack, and C. Sagan (1986). Nuclear winter:
Global consequences of multiple nuclear explosions. Science 222, 1283–1292.
Turcotte, D. L., and G. Schubert (1982). Geodynamics. New York: Wiley.
Turner, J. S. (1973). Buoyancy Effects in Fluids. Cambridge: Cambridge University Press.
Ugural, A. C., and S. K. Fenster (2012). Advanced Mechanics of Materials and Applied Elasticity.
Upper Saddle River, N.J.: Prentice-Hall.
Unruh, W. G. (1976). Notes on black hole evaporation. Physical Review D 14, 870–892.
Vallis, G. K. (2006). Atmospheric and Oceanic Fluid Dynamics. Cambridge: Cambridge Uni-
versity Press.
Van Dyke, M. (1982). An Album of Fluid Flow. Stanford, Calif.: Parabolic Press.
1470
References

Van Kampen, N. G. (2007). Stochastic Processes in Physics and Chemistry. New York: North
Holland.
Verhulst, P. F. (1838). Notice sur la loi que la population poursuit dans son accroissement.
Correspondance Math´ematique et Physique 10, 113–121.
Vogel, S. (1994). Life In Moving Fluids: The Physical Biology Of Flow, 2nd Edition, Revised and
Expanded by Steven Vogel, Illustrated by Susan Tanner Beety and the Author.
Wagner, T., S. Schlamminger, J. Gundlach, and E. Adelberger (2012). Torsion-balance tests of
the weak equivalence principle. Classical and Quantum Gravity 29, 1–15.
Wainstein, L. A., and V. D. Zubakov (1962). Extraction of Signals from Noise. London: Prentice-
Hall.
Wald, R. M. (1984). General Relativity. Chicago: University of Chicago Press.
——— (1994). Quantum Field Theory in Curved Spacetime and Black Hole Thermodynamics.
Chicago: University of Chicago Press.
——— (2001). The thermodynamics of black holes. Living Reviews in Relativity 4, 6.
Walker, A. G. (1935). On Milne’s theory of world structure. Proceedings of the London Mathe-
matical Society 42, 90–127.
Weber, J. (1953). Ampliﬁcation of microwave radiation by substances not in thermal equilib-
rium. IRE Transactions of the Professional Group on Electron Devices 3, 1–4.
Weinberg, S. (1972). Gravitation and Cosmology. Principles and Applications of the General
Theory of Relativity. New York: Wiley.
——— (2008). Cosmology. Oxford: Oxford University Press.
Weiss, R. (1972). Electromagnetically coupled broadband gravitational antenna. Quarterly
Progress Report of the Research Laboratory of Electronics, M.I.T., 105, 54–76.
Weissberg, J. M., D. J. Nice, and J. H. Taylor (2010). Timing measurements of the relativistic
binary pulsar PSR B1913+16. Astrophysical Journal 722, 1030–1034.
Weld, D. M., J. Xia, B. Cabrera, and A. Kapitulnik (2008). A new apparatus for detecting
micron-scale deviations from Newtonian gravity. Physical Review D 77, 062006.
Welford, W. T. (1988). Optics. Oxford: Oxford University Press.
Wheeler, J. A. (2000). Geons, Black Holes, and Quantum Foam: A Life in Physics. New York:
W. W. Norton.
White, F. M. (2006). Viscous Fluid Flow. New York: McGraw-Hill.
——— (2008). Fluid Mechanics. New York: McGraw-Hill.
Whitham, G. B. (1974). Linear and Non-linear Waves. New York: Wiley.
Wiener, N. (1949). The Extrapolation, Interpolation, and Smoothing of Stationary Time Series
with Engineering Applications. New York: Wiley.
Will, C. M. (1993a). Theory and Experiment in Gravitational Physics. Cambridge: Cambridge
University Press.
——— (1993b). Was Einstein Right? New York: Basic Books.
——— (2014). The confrontation between general relativity and experiment. Living Reviews in
Relativity 17, 4.
Wolgemuth, C. W., T. R. Powers, and R. E. Goldstein (2000). Twirling and whirling: Viscous
dynamics of rotating elastic ﬁlaments. Physical Review Letters 84, 1623–1626.
Xing, X., P. M. Goldbart, and L. Radzihovsky (2007). Thermal ﬂuctuations and rubber elastic-
ity. Physical Review Letters 98, 075502.
References
1471

Yariv, A. (1978). Phase conjugate optics and real time holography. IEEE Journal of Quantum
Electronics 14, 650–660.
——— (1989). Quantum Electronics. New York: Wiley.
Yariv, A., and P. Yeh (2007). Photonics: Optical Electronics in Modern Communications. Oxford:
Oxford University Press.
Yeganeh-Haeri, A., D. J. Weidner, and J. B. Parise (1992). Elasticity of α-Cristobalite: A silicon
dioxide with a negative Poisson’s ratio. Science 257, 650.
Young, T. (1802). On the theory of light and colours (read in 1801). Philosophical Transactions
92, 34.
Yvon, J. (1935). La Th´eorie des Fluides et l’´Equation d’´Etat. Paris: Hermann.
Zangwill, A. (2013). Modern Electrodynamics. Cambridge: Cambridge University Press.
Zee, A. (2013). Einstein Gravity in a Nutshell. Princeton, N.J.: Princeton University Press.
Zel’dovich, B. Ya., V. I. Popovichev, V. V. Ragul’skii, and F. S. Faizullov (1972). Connection
between the wavefronts of the reﬂected and exciting light in stimulated Mandel’shtem-
Brillouin scattering. Journal of Experimental and Theoretical Physics Letters 15, 160–164.
Zel’dovich, Ya. B. (1968). The cosmological constant and the theory of elementary particles.
Soviet Physics Uspekhi 11, 381–393.
——— (1972). A hypothesis, unifying the structure and the entropy of the universe. Monthly
Notices of the Royal Astronomical Society 160, 1p–3p.
Zel’dovich, Ya. B., and Yu. P. Raizer (2002). Physics of Shock Waves and High Temperature
Hydrodynamic Phenomena. Mineola, N.Y.: Courier Dover Publications.
Zhang, F., A. Zimmerman, D. Nichols, Y. Chen, et al. (2012). Visualizing spacetime curvature
via frame-drag vortexes and tidal tendexes II. Stationary black holes. Physical Review D 86,
084049.
Zipf, G. K. (1935). The Psycho-Biology of Language. Boston: Houghton-Mifﬂin.
Zurek, W. H., and K. S. Thorne (1985). Statistical mechanical origin of the entropy of a rotating,
charged black hole. Physical Review Letters 54, 2171–2175.
Zwicky, F.(1933).DieRotverschiebungvonextragalaktischenNebeln.HelveticaPhysicsActa 6,
110–127.
1472
References

NAME INDEX
Page numbers for entries in boxes are followed by “b,” those for epigraphs at the beginning of a chapter by
“e,” those for ﬁgures by “f,” and those for notes by “n.”
Abb´e, Ernst, 439
Adelberger, Eric, 1300
Albrecht, Andreas, 1432n
Alfv´en, Hannes, 943e
Anderson, Wilhelm, 127
Appleton, Edward Victor, 1058n
Arago, Fran¸cois, 436n
Archimedes of Syracuse, 675e
Bacon, Roger, 347
Basov, Nicolay Gennadiyevich, 517
Bekenstein, Jacob, 206
Bernstein, Ira B., 981, 1101
Berry, Michael, 406
Bertotti, Bruno, 1249
Birkhoff, George, 1250
Bogolyubov, Nikolai Nikolayevich, 1103
Bohr, Niels, 1039n
Boltzmann, Ludwig, 181n, 182n
Bondi, Hermann, 890, 1398, 1445n
Born, Max, 1103
Braginsky, Vladimir Borisovich, 1300
Brown, Robert, 283e, 313
Burke, William, 869, 1333
Callen, Herbert, 331
Carlini, Francesco, 358n
Carter, Brandon, 1278, 1291
Cauchy, Augustin-Louis, 565, 588n
Christodoulou, Demetrios, 1284
Chu, Steven, 340
Ciufolini, Ignazio, 1309
Clough, Ray W., 565
Cohen-Tannoudji, Claude, 340
Cornell, Eric, 193
Davies, Paul, 204
De Laval, Gustaf, 887n
DeWitt, Bryce, 1341
Dicke, Robert, 1300
Dirac, Paul, 438n, 1429n
Doob, Joseph, 295n
Drever, Ronald W. P., 498, 503
Dyson, Freeman, 1111e
Eddington, Arthur, 396, 835e, 1268
Einstein, Albert, 41, 42, 51, 53, 140n, 193, 396, 398n, 1151,
1191e, 1192, 1193, 1194, 1195, 1197, 1221, 1222, 1228,
1233, 1239, 1242, 1259, 1299, 1302, 1305, 1311, 1319,
1366, 1382, 1382n, 1444
Emden, Robert, 688
E¨otv¨os, Roland von, 1300
Euclid, 9n
Euler, Leonhard, 371n, 565, 600, 602, 603, 697n
Everitt, Francis, 1309
Faraday, Michael, 5n, 1433n
Feigenbaum, Mitchell, 828
Feynman, Richard P., 14n, 35, 438n, 729e
Fierz, Marcus, 1319, 1320
Finkelstein, David, 1268
Fraunhofer, Joseph von, 411e
Fresnel, Augustin-Jean, 436n
Friedmann, Alexander, 1371n, 1377
1473

Gabor, Dennis, 521n
Galileo Galilei, 347, 565, 1300
Genzel, Reinhard, 471b
Germain, Marie-Sophie, 565
Ghez, Andrea, 471b
Gibbs, J. Willard, 5n, 155e, 160, 219e, 219
Goldreich, Peter, 702
Goldwasser, Samuel M., 554f
Gordon, James P., 517
Green, George, 358n
Green, Herbert S. 1103
Greene, John M., 1101
Grimaldi, Francesco Maria, 347
Guth, Alan, 1432n
Hafele, Josef, 70
Hall, John, 498
Hamilton, William Rowan, 5n, 347, 1062
Hanbury Brown, Robert, 509, 511
H¨ansch, Theodor, 498
Harrison, Edward R., 1410
Hawking, Stephen, 204, 206, 1273, 1278, 1284, 1286, 1287n
Hazard, Cyril, 433
Heaviside, Oliver, 5n, 995, 1033e, 1058n
Hecht, Eugene, 434f
Heisenberg, Werner, 788n, 917e
Hertz, Heinrich, 347, 502
Hipparchus of Nicaea, 1219n
Hooke, Robert, 565, 567e
Hubble, Edwin, 1374n
Hulse, Russell, 502, 1310
Huygens, Christiaan, 347, 411
Isaacson, Richard, 1320, 1320n, 1321
Ising, Ernst, 272n
Jeans, James, 1071n
Jeffreys, Harold, 358n
Johnson, John, 327
Kapitsa, Pyotr, 1429n
Kazanas, Demosthenes, 1432n
Keating, Richard, 70
Kennelly, Arthur, 995, 1058e
Kerr, Roy, 1278
Ketterle, Wolfgang, 193
Killing, Wilhelm, 1205n
Kirkwood, John, 1103
Kruskal, Martin, 1101, 1276
Lagrange, Joseph-Louis, 5n, 14, 565
Landau, Lev Davidovich, 1080, 1299e
Lane, Jonathan Homer, 688
Langmuir, Irving, 1044, 1069e
Laplace, Pierre-Simon, 155e
Leibniz, Gottfried Wilhelm, 371n
Lele, Sanjiva K., 807f
Lemaˆıtre, Georges, 1371n, 1374n, 1445n
Lense, Josef, 1233
Levin, Yuri, 334
Libchaber, Albert, 830
Lifshitz, Evgeny Mikhailovich, 1268, 1299e
Linde, Andrei, 1432n
Liouville, Joseph, 358n
Lorentz, Hendrik, 41n, 88
Lorenz, Edward, 834
Love, Augustus Edward Hugh, 565
Lynden-Bell, Donald, 113n
Maiman, Theodore H. 517
Marriotte, Edme, 565
Martin, H. C., 565
Maupertuis, Pierre Louis, 371n
Maxwell, James Clerk, 5n, 95e, 155e, 347, 1433n
Metropolis, Nicholas, 280
Michell, John, 1241e
Michelson, Albert A., 455, 464, 470b, 474, 479, 483
Millikan, Robert, 155e, 749
Minkowski, Hermann, 1n, 37e, 88, 1192
Morley, Edward, 474, 483
Navier, Claude-Louis, 565, 588n
Nelson, Jerry, 609
Newton, Isaac, 5e, 5n, 14, 41, 347, 398n, 690, 712, 1151, 1444
Noether, Emmy, 1434n
Nyquist, Harry, 327, 1091
Onsager, Lars, 273, 275, 278
Oort, Jan, 1380n
Oppenheimer, J. Robert, 1258, 1260, 1264, 1268
Oseen, Carl Wilhelm, 754
Page, Don, 206
Pauli, Wolfgang, 160, 1319, 1320
Pease, Francis, 464, 470b
Penrose, Oliver, 1091
Penrose, Roger, 210n, 1273, 1283
Penzias, Arno, 1363, 1364
Phillips, William D., 340
Planck, Max, 1153e
Poisson, Sim´eon, 436n
Pound, Robert, 498, 1189
Pretorius, Frans, 1341
Prokhorov, Alexander Mikhailovich, 517
1474
Name Index

Rayleigh, Lord (John William Strutt), 899n
Richardson, Bernard, 529f
Richardson, Lewis, 787e
Richter, Charles, 629e
Ride, Sally, 875e
Rittenhouse, David, 422n
Roberts, Morton S., 1380n
Robertson, Howard P., 1371n
Robinson, David, 1278
Robinson, Ivor, 1249
Rouse, Hunter, 727, 731b
Rubin, Vera, 1380n
Ryle, Martin, 480n
Sahl, Ibn, 351e
Saint-Venant, Barr´e de, 590bn
Sakharov, Andrei Dmitrievich, 532n, 959n,
1443n
Sato, Katsuhiko, 1432n
Schmidt, Maarten, 433
Schr¨odinger, Erwin, 210n
Schwarzschild, Karl, 935, 1242, 1259, 1273, 1433n
Scott-Russell, John, 850, 855
Sedov, Leonid I., 911, 912
Seurat, Georges, 427, 427f
Shannon, Claude, 212
Shapiro, Ascher, 731b
Shapiro, Irwin, 1308
Slipher, Vesto, 1374n
Smarr, Larry, 1341
Snell (Willebrord Snellius), 347
Snyder, Hartland, 1264, 1268
Spitzer, Lyman, 997e
Starobinsky, Alexei Alexandrovich, 1432n
Steinhardt, Paul, 1432n
Stevenson, David, 816n, 843n
Stewart, Potter, 788n
Stokes, George G., 486, 754, 899n
Stoner, Edmund, 127
Sunyaev, Rashid, 1430
Szekeres, George, 1276
Taam, Igor Yevgenyevich, 959n
Taylor, Geoffrey Ingram, 458, 746, 911, 912
Taylor, Joseph, 502, 1310
Teukolsky, Saul, 1341
Thirring, Hans, 1233
Tolman, Richard Chace, 1258, 1445n
Topp, L. J., 565
Townes, Charles H. 513e, 517
Turner, M. J., 565
Twiss, Richard Q., 509, 511
Unruh, William, 204
Vessot, Robert, 1301
Vlasov, Anatoly Alexandrovich, 1071n
Volkoff, George, 1258, 1264
Walker, Arthur Geoffrey, 1371n
Weber, Joseph, 517
Weinberg, Steven, 1153, 1193
Weiss, Rainer, 503
Welton, Theodore A., 331
Wheeler, John Archibald, 88, 153, 1293, 1344b
Whitehurst, R. N., 1380n
Wieman, Carl, 193
Wiener, Norbert, 319, 438n
Wilson, Robert, 1363, 1364
Yariv, Amnon, 532
Young, Thomas, 347, 455e
Yvon, Jacques, 1103
Zeiger, Herbert, 517
Zel’dovich, Boris Yakovlevich, 532, 532n
Zel’dovich, Yakov Borisovich, 532n, 916, 1410n, 1430, 1445n
Zwicky, Fritz, 1380
Name Index
1475


SUBJECT INDEX
Second and third level entries are not ordered alphabetically. Instead, the most important or general entries
come ﬁrst, followed by less important or less general ones, with speciﬁc applications last.
Page numbers for entries in boxes are followed by “b,” those for epigraphs at the beginning of a chapter
by “e,” those for ﬁgures by “f,” for notes by “n,” and for tables by “t.”
E × B drift, 1025, 1026f, 1039
-pinch for plasma conﬁnement, 961f, 962–963, 971
stability of, 978–979
-pinch, toroidal, for plasma conﬁnement, 978
ﬂute instability of, 978–979, 978f
3+1 split
of spacetime into space plus time, 60, 1158
of electromagnetic ﬁeld tensor, 72–74
of stress-energy tensor, 82–84, 120
of 4-momentum conservation, 60, 85–88
4-acceleration related to acceleration that is felt, 69, 1182
4-force
as a geometric object, 51
orthogonal to 4–velocity, 52
4-momentum
as a geometric object, 50
components in Lorentz frame: energy and momentum,
58–59
and afﬁne parameter, 51
related to 4–velocity, 50
related to quantum wave vector, 50
related to stress-energy tensor, 82–84
4-momentum conservation (energy-momentum
conservation)
3+1 split: energy and momentum conservation, 60, 85–88
expressed in terms of stress-energy tensor, 84–85
global, for asymptotically ﬂat system, 1237–1238
global version fails in generic curved spacetime, 1177,
1218
for particles, 51, 52f, 60
for perfect ﬂuid, 86–87
for electromagnetic ﬁeld and charged matter, 88
4-momentum density, 82
4–vector. See vector in spacetime
4–velocity
as a geometric object, 49
3+1 split: components in Lorentz frame, 58
Abb´e condition, 373n
aberration of photon propagation direction, 107, 1305
aberrations of optical instruments, 395–396
of Hubble space telescope 426–427
absorption of radiation, 115–116, 131, 260, 341–342,
515–516, 937, 1017, 1054, 1057, 1126–1130,
1394–1397
accelerated observer
proper reference frame of, 1180–1186, 1181f, 1200, 1254,
1274
uniformly, 1186–1189, 1187f
acceleration of universe, 1382, 1398–1401, 1444, 1445n
accretion disk around spinning black hole, 784, 969
thin, 1287–1289
thick, 1289–1290
accretion of gas onto neutron star or black hole, 205, 890–891,
1266, 1282–1283
1477

acoustic horizon radius, χA, 1375
ultrarelativistic, χR, 1375, 1403–1404
acoustic peaks, in CMB anisotropy spectrum, 1413, 1419f,
1421
action principles
Hamilton’s, in analytical mechanics, 15
for geodesic equation, 1203, 1205–1206, 1357
for rays in geometric optics, 371–373
for elastic stress, 584
for eigenfrequencies of normal modes, 980–981
active galactic nuclei, 1379
adaptive optics, 470b–471b, 472
adiabatic index
deﬁnition, 243, 724b
polytropic, 878
for ideal gas: ratio of speciﬁc heats, 244, 678, 681b, 724b
inﬂuence of molecules’ internal degrees of freedom,
879–880
for air, as function of temperature, 880f
in plasma: anisotropic, 1020–1024
adiabatic invariants
accuracy of, 1030
failure of, 1030
for charged particle in magnetic ﬁeld, 1028–1030
wave action of a classical wave, 365–366
advective (convective) time derivative, 32, 692, 724b, 892
afﬁne parameter, 50–51, 99–100, 133, 136b, 1178b, 1200,
1203, 1206, 1208, 1247, 1303, 1307, 1423
Aichelberg-Sexl ultraboost metric of a light-speed particle,
1231
airplane wing or airfoil, lift on, 743f, 743–744, 824
Airy diffraction pattern for circular aperture, 426–428, 437,
442
Airy disk
for diffraction pattern of a circular aperture, 426–427,
437, 471
for low-pass ﬁlter to clean laser beam, 441
in phase-contrast microscopy, 442–443, 442f
in Strehl ratio for a telescope’s performance, 472
Airy function, for diffraction near a caustic, 451–454, 452f
Alcator C-Mod, 963
Alfv´en waves, 354, 990–991, 1053f
two-ﬂuid analysis of, 1055–1058
dispersion relation of, 354, 990
phase velocity of, 354, 990
group velocity of, 355f, 356
polarization of, 405
relativistic corrections for, 1055–1056
as plasma-laden, plucked magnetic ﬁeld lines, 990,
1056–1057
in magnetosphere, 370f
in solar wind, 970–971
generated near shock fronts, 1146f
interaction with cosmic rays. See cosmic rays
Allan variance of clocks, 310f, 320–21
allometry, 587, 609
ALMA (Atacama Large Millimeter Array), 480, 482
Andromeda galaxy, 305, 1365f
angular momentum
and moment of inertia tensor, 6
of fundamental particles (spin), 22
of a Kerr black hole, 204–205, 226n, 1278, 1282–1283,
1285–1286, 1342. See also frame dragging by spinning
bodies
of a relativistic, spinning body, 1218, 1220, 1232–1234,
1237–1238, 1328
in accretion disks, 1287–1292
carried by gravitational waves, 1332–1333, 1335, 1338,
1345
in statistical mechanics, 169, 172–173, 179
in elastodynamics, 644, 661–662
in ﬂuid mechanics, 702, 729, 732, 733, 784, 826, 849
angular momentum conservation, Newtonian, 14–15
in circulating water, 729, 732–733
angular momentum conservation, relativistic
global, for asymptotically ﬂat system, 1237–1238
for geodesic orbits around a black hole, 1274, 1303
angular-diameter distance, dA, 1374, 1378, 1398–1400,
1427
anthropic principle, 1439–1440, 1446
aperture synthesis, in radio astronomy, 480
Appleton-Hartree dispersion relation, 1059–1060
Archimedes law, 675, 684–685, 692
artery, blood ﬂow in, 716–719
astigmatism, 390, 395
astronomical seeing, 425, 464–472, 481, 511
asymptotic rest frame, 1237, 1246–1248
local, 1328, 1331, 1332, 1339–1340
asymptotically ﬂat system in general relativity, 1194, 1238,
1238n
imprint of mass and angular momentum on exterior
metric, 1232–1233, 1238
conservation laws for mass and angular momentum,
1237–1238, 1332, 1338
atmosphere of Earth. See also tornados; winds
structure of, 683–684, 684f
chemical reactions in, 256–258
and greenhouse effect, 138, 748–749
storms in, 768, 769b
excitation of ocean waves by, 783
billow clouds in, 783, 783f
sedimentation in, 748–755
1478
Subject Index

turbulence of
and astronomical seeing, 425, 464–472, 481, 511
excitation of earth’s normal modes by, 816–817
atomic bomb, 153, 912–914, 1009
B-modes, of CMB polarization, 1420, 1428, 1439
Babinet’s principle, 428–429, 523
bacterium, swimming, 747b–748b, 756–757
bafﬂes, to control scattered light, 448–451
balls, physics of ﬂight, 817, 823–825
bandwidth of a ﬁlter, 315–318
barotropic ﬂuid, 681b,724b
baryogenesis, 1442–1443
baryons in universe
origin of: baryogenesis, 1442–1443
evolution of, 1407–1408, 1410–1414
observations today, 1379
basis vectors in Euclidean space
orthogonal transformation of, 20–21
Cartesian, 16–17
spherical and Cartesian, orthonormal, 614
basis vectors in spacetime
dual sets of, 1161
coordinate, 1162–1163, 1167
orthonormal (Lorentz), 54, 1157
Lorentz transformation of, 63–65
nonorthonormal, 1160–1163
transformation between, 1164
baths for statistical-mechanical systems
concept of, 160
general, 172
tables summarizing, 160t, 221t, 251t
BBGKY hierarchy of kinetic equations, 803, 1103–1106, 1109
BD, 530, 531
beam, bent. See bent beam
bending modulus (ﬂexural rigidity), 594
bending torque, 593f, 594, 596, 600, 602, 603, 608, 611, 612
bent beam, elastostatics of, 592–596
elastostatic force-balance equation for, 595
solutions of force-balance equation
for clamped cantilever pulled by gravity, 596–597
for Foucault pendulum, 597–598
for elastica, 600–601, 601f
bent plate, elastostatics of, 609–613
elastostatic force-balance equation: shape equation, 610
Bernoulli function, 698–700, 702, 721, 722, 724b
Bernoulli’s theorem
most general version: for any ideal ﬂuid, 698
for steady ﬂow of an ideal ﬂuid, 698, 700
for irrotational ﬂow of an ideal, isentropic ﬂuid, 701
relativistic, 722
Berry’s phase (geometric phase), 406–409
BGK waves in a plasma, 1100–1101
Bianchi identities, 1223–1224
in Maxwell-like form, 1235b, 1318b
bifurcation of equilibria
formal mathematical foundations for, 384
onset of dynamical instability at bifurcation
in general, in absence of dissipation, 648
for beam under compression, 647–648
for convection, Rayleigh-B´enard, 931
for beam under compression, 603–605
for rapidly spinning star, 607
for rotating Couette ﬂow, 826–827
for Venus ﬂy trap, 607
for whirling shaft, 607
big rip, 1446
biharmonic equation, 589, 610, 754, 756
billow clouds, 783, 783f
binary black holes, 1341–1342, 1342f, 1343f, 1344b–1345b
binary pulsars
Hulse-Taylor: B1913+16, 502, 1310
J0337+715, 1301
J0737+3039, 1303, 1309, 1310
J1614–2230, 1309
observation of gravitational radiation reaction in,
1310–1311
tests of general relativity in, 1301, 1303, 1311
binary star system. See also binary pulsars
gravitational waves from, 1335–1341
tidally locked, shapes of stars, 691
bird ﬂight
V-shaped conﬁguration, 744
wingtip vortices, 734f, 739, 744, 744f
birefringent crystals, 541b–542b, 546, 547. See also nonlinear
crystals
phase-matching via birefringence, 546–548
three-wave mixing in. See three-wave mixing in nonlinear
crystals
Birkhoff’s theorem, 1250–1251, 1264
black holes. See also horizon, black-hole event; Kerr metric;
Schwarzschild metric
nonspinning, Schwarzschild, 1272–1276. See also
Schwarzschild metric
geodesic orbits around, 1274–1276, 1275f
spinning, Kerr, 1277–1293. See also Kerr metric
laws of black-hole mechanics and thermodynamics,
205–209, 1284–1287
statistical mechanics of, 204–206
entropy of, 205–209, 1287
irreducible mass of, 1284
inside a box: thermal equilibrium, 206–209
Subject Index
1479

black holes (continued)
rotational energy and its extraction, 1282–1287, 1291–
1293
evolution of, 1282–1287
quantum thermal atmosphere of, 204–205
Hawking radiation from, 204–205, 1286–1287
accretion of gas onto, 205, 784, 890–891, 969, 1282–1283,
1287–1290
binary, 1341–1342, 1342f, 1343f, 1344b–1345b
collisions of and their gravitational waves, 1341–1342,
1342f, 1343f, 1344b–1345b
in the universe, 1379–1380, 1397
blackbody (Planck) distribution and speciﬁc intensity, 113,
128, 132
Blandford-Znajek process, 1285, 1291–1293
Blasius proﬁle for laminar boundary layer, 758–764
blast wave. See explosion and blast wave
blood ﬂow in arteries, 717–719
boat waves, 846–848
boat, stability of, 685–686
Boltzmann distribution (mean occupation number), 113,
177
entropy of, 187
Boltzmann equation, collisionless, 134–135, 167, 169. See
also Vlasov equation
derivation from Hamiltonian, 136b–137b
implies conservation of particles and 4-momentum, 135
Boltzmann transport equation, 135, 139
for photons scattered by thermalized electrons, 144–148
accuracy of solutions, 140–141
order-of-magnitude solution, 143–144
solution via Fokker-Planck equation, 343
solution via Monte Carlo methods, 1415–1418, 1428
solution via two-lengthscale expansion, 145–148
boost, Lorentz, 64–65
Bose-Einstein condensate, 193–201
condensation process, 193, 196, 197f, 198–200
critical temperature, 196
speciﬁc heat change, 200
in cubical box, 201
Bose-Einstein ensemble
probabilistic distribution function for, 176
mean occupation number of, 112–113, 176–177
entropy of, 187
bosons, 110
boundary layers
laminar, 757–766
Blasius proﬁle, 758–764
sublayer of turbulent boundary layer, 818
Ekman, for rotating ﬂow, 772–777
vorticity creation in, 758
diffusion of vorticity in, 741–742, 741f, 758
instability of, 822–823
in a pipe, 766
near curved surface, 764–765
separation from boundary, 764, 793
turbulent, 817–825
proﬁle of, 818–820, 818f
separation from boundary, 821f, 820–821
thermal, 923
inﬂuence on ﬂight of sports balls, 823–825
Boussinesq approximation, 923–925
bow shock around Earth, 876f, 957, 1090, 1146–1147, 1146f
bremsstrahlung, 142, 260, 1009, 1017
brightness temperature, 482
Brillouin scattering, 1142
Brownian motion, 296, 309, 313–315. See also random walk
spectral density and correlation function for, 313–314
relaxation time for, 328
ﬂuctuation-dissipation theorem applied to, 327–329
Brunt-V¨ais¨al¨a frequency for internal waves in stratiﬁed ﬂuid,
941
bubbles
in water, collapse of, 703
in water, rising, 937
soap, 846
buckling of compressed beam or card, 602
onset of buckling at bifurcation of equilibria, 603–605
onset of elastostatic instability at bifurcation of equilibria,
648
elementary theory of, 602–605, 608–609
free energy for, 604
applications
collapse of World Trade Center buildings, 605–607
mountain building, 609
thermal expansion of pipes, 609
bulk modulus, for elasticity, 581
values of, 586t, 651t
atomic origin of, 649f
relation to equation of state, 650
bump-in-tail instability, 1136–1137, 1138–1139
bunching of bosons, 511, 511n, 1117
canonical ensemble, 160t, 169–172, 221t
distribution function, 171, 173
canonical transformation, 162, 164, 166
cantilever, 566, 592–593, 596–597
capillary waves, 844–848
Cartesian coordinates, 16, 26, 28
local, on curved surface, 1198
catastrophe theory
caustics as examples of catastrophes, 384
1480
Subject Index

state variables, 385
control parameters, 386
ﬁve elementary catastrophes
fold catastrophe, 386–388, 393f
cusp catastrophe, 389, 392, 391f, 393f
swallowtail catastrophe, 389–390, 391f, 393f
hyperbolic umbillic catastrophe, 389–390, 391f, 393f
elliptic umbillic catastrophe, 391f, 392, 393f
applications
to caustics of light propagation, 384–394
to elliptic gravitational lens, 403
to van der Waals equation, 394–395
to buckling of a beam, 606–607
caustics, 351, 384–394. See also catastrophe theory
diffraction near, 451–454
examples
sunlight on bottom of swimming pool, 384, 384n, 385f
sunlight reﬂected onto bottom of a cup, 385f
cavitation, 702–703
CD, 530, 531
central limit theorem, 292–294
examples and applications of, 261, 294–295, 322, 465, 510
centrifugal acceleration, 689, 767
Cerenkov emission of plasmons by fast electrons in a plasma,
1127–1129, 1131, 1133, 1138
CGL equations of state, 1024
chaos in dynamical systems, 832–834
Lyapunov exponent, 833
Lyapunov time, 832
strange attractors, 833–834
examples of, 832, 1030
quantum chaos, 832
chaos, onset of in dynamical systems, 825–833. See also
turbulence, onset of
in idealized equations and mathematical maps
logistic equation and Feigenbaum sequence, 828–831
Lorenz equations, 834
universality of routes to chaos, 830
Chapman-Kolmogorov equation. See Smoluchowski
equation
characteristics of a dynamical ﬂuid ﬂow, 852, 892–893, 893f,
894–896
charge density
as integral over plasma distribution function, 1072
as time component of charge-current 4–vector, 74
charge-current 4–vector
geometric deﬁnition, 78
components: charge and current density, 78
local (differential) conservation law for, 79
global (integral) conservation law for, 79, 79f
evaluation in a Lorentz frame, 81
relation to nonrelativistic conservation of charge, 81
charged-particle motion in electromagnetic ﬁeld, 1024–1032
chemical free energy (Gibbs potential), 246–249. See also
under fundamental thermodynamic potentials;
fundamental thermodynamic potentials out of
statistical equilibrium
chemical potential, excluding rest mass, μ, 112, 173
chemical potential, including rest mass, ˜μ, 112, 172–173
chemical reactions, including nuclear and particle, 256
direction controlled by Gibbs potential (chemical-
potential sum), 256–258
partial statistical equilibrium for, 256
examples
water formation from hydrogen and oxygen, 256–257
electron-positron pair formation, 258–259, 1001
emission and absorption of photons, 115–116
ionization of hydrogen: Saha equation, 259–260,
998–1000
controlled thermonuclear fusion, 959–960, 1141b
nucleosynthesis in nuclear age of early universe,
192–193, 1387–1392
recombination in early universe, 1393–1396
annihilation of dark-matter particles, 1440–1442
Christoffel symbols, 1172
chromatic resolving power, 424, 496
chronology protection, 69
circular polar coordinates, 1163, 1163f, 1165, 1173. See also
cylindrical coordinates
circulation, 729, 733, 734, 739–740
and lift on airplane wing, 743
as ﬂux of vorticity, 739
evolution equations and Kelvin’s theorem, 740
Clausius-Clapeyron equation, 254–256
climate change, 748–749, 755, 958, 1440n. See also
greenhouse effect
clocks
ideal, 39, 39n, 49, 1154n
frequency ﬂuctuations of, 310f, 310n, 320–321
closure phase, in multiple-element interferometry, 481
closure relation, in plasma kinetic theory, 1074, 1105, 1409
clouds, billow, 783, 783f
CMA diagram for waves in cold, magnetized plasma,
1062–1065, 1064f
CMB. See cosmic microwave background
Coanda effect, 809f, 809–810, 820, 821f
coarse graining, 183–185, 184f, 206, 210–211, 1443
COBE (Cosmic Background Explorer), 476
coherence length
longitudinal or temporal, 472–473
spatial or lateral, 462–463
volume of coherence, 477
Subject Index
1481

coherence of radiation
qualitative description, 437–438
perfect coherence, 459
incoherent superposition of radiation, 460
spatial coherence, 456–464
temporal (longitudinal) coherence, 472–474, 458n
degree of coherence, 461n
lateral, 460–461
spatial, 462
longitudinal (temporal), 472–474, 458n
3-dimensional, 477
applications of, 463–465, 466b–471b, 474
fringe visibility, 461–463, 475
coherent state, quantum mechanical, for light, 518
collective effects in plasmas, 907, 943, 1003–1006, 1016,
1020, 1070, 1146
collisionless shocks, 907, 1145–1147
communication theory, 211–217
commutation coefﬁcients, 1171, 1215
commutator
of two vector ﬁelds, 735n, 1167–1169, 1172, 1209, 1214n
comoving coordinates, in cosmology, 1370
component manipulation rules
in Euclidean space, 16–19
in spacetime with orthormal basis, 54–57
in spacetime with arbitrary basis, 1161–1165
components of vectors and tensors. See under vector in
Euclidean space; vector in spacetime; tensor in
Euclidean space; tensor in spacetime
compressible ﬂuid ﬂow
equations for, 877–879
1-dimensional, time-dependent, 891–897
Riemann invariants for, 891–895
nonlinear sound wave, steepening to form shock, 894,
894f
in shock tube. See shock tube, ﬂuid ﬂow in
transonic, quasi-1-dimensional, steady ﬂow, 884f,
880–891
equations in a stream tube, 880–882
properties of, 882–883
relativistic, 890
Compton scattering, 1388, 1392–1393, 1428–1430
conductivity, electrical, κe, 139
in plasmas with Coulomb collisions, 1015, 1018
in magnetized plasma, tensorial, 1022–1023, 1036
conductivity, thermal, κ, 139
energy ﬂux for, 714
for photons scattered by thermalized electrons, 148,
derivation from Boltzmann transport equation, 144–148
conformally related metrics, 1159–1160
congruence of light rays, 1423–1424
connection coefﬁcients
for an arbitrary basis, 1171–1173
for orthonormal bases in Euclidean space, 615
pictorial evaluation of, 616f
used to compute components of gradient, 617
for cylindrical orthonormal basis, 615
for spherical orthonormal basis, 616
conservation laws. See also speciﬁc conserved quantities
differential and integral, in Euclidean 3-space, 28
differential and integral, in spacetime, 79
related to symmetries, 1203–1205
contact discontinuity, 953
continental drift, 932b
contraction of tensors
formal deﬁnition, 12–13, 48
in slot-naming index notation, 19
component representation, 17, 56
controlled fusion. See fusion, controlled thermonuclear
convection
onset of convection and of convective turbulence,
830–831, 931
Boussinesq approximation for, 924–925
between two horizontal plates at different temperatures:
Rayleigh-B´enard convection, 925–933
Boussinesq-approximation analysis, 925–928, 930
critical Rayleigh number for onset, 930, 930f, 933
pattern of convection cells, 930–931, 931f
toy model, 929
in a room, 931
in Earth’s mantle, 932
in a star, 933–937
in the solar convection zone, 936
convergence of light rays, 1424
convolution theorem, 421–422
coordinate independence. See geometric principle; principle
of relativity
coordinates. See speciﬁc names of coordinates
Copernican principle, 1366
Coriolis acceleration, 735, 767–768, 1185
as restoring force for Rossby waves, 858
Cornus spiral, for Fresnel integrals and Fraunhofer
diffraction, 431f
correlation functions
for 1-dimensional random process, 297
correlation (relaxation) time of, 297
value at zero delay is variance, 297
for 2-dimensional random process, 306–308
cross correlation, 307
for 3-dimensional random process
cosmological density ﬂuctuations (galaxy distribution),
304–306, 306f
1482
Subject Index

for many-particle system, 1104–1106
two-point and three-point, 1104–1106
applications of
Brownian motion, 314
cosmological density ﬂuctuations, 303–306, 1414
distortion of galaxy images due to weak lensing,
1424–1427
angular anisotropy of cosmic microwave background,
1417–1420
correlation (relaxation) time, 297, 298f
Cosmic Background Explorer (COBE), 476
cosmic dawn, 1421–1422
cosmic microwave background (CMB)
evolution of in universe
before recombination, 1384–1387, 1407–1408
during and since recombination, 1415–1422
redshifting as universe expands, 1373
observed properties today, 1381, 1419f
Doppler shift of due to Earth’s motion, 116–117
isotropy of, 1364
map of, by Planck, 1365f
frequency spectrum of, today
measured by COBE, 476
Sunyaev-Zeldovich effect on, 1428–1430
anisotropies of, today
predicted spectrum, 1419f
acoustic peaks, 1413, 1419f, 1421
polarization of, today, 1416, 1417, 1420, 1428
E-mode 1419f, 1420, 1428
B-mode, 1420, 1428, 1439
cosmic rays
spectrum of, 988
ultra-high-energy, 1024
anisotropy of arrival directions, 992–993
acceleration of in strong shock fronts, 1147–1148
interaction with Alfv´en waves, 992–993, 1138–1139
Cerenkov emission of Alfv´en waves by, 1138–1139
observational evidence for scattering of, 989
scattering of, by Alfv´en waves, 992–993, 1138–1139
cosmic shear tensor, 1424, 1427
cosmic strings, 1357, 1432n
cosmic variance, 1411n, 1421
cosmological constant
observational evidence for, 1382–1383
history of ideas about, 1382n, 1444–1445, 1445n
as energy density and negative pressure, 1282–1383, 1445
as a property of the vacuum, 1445
as a “situational” phenomenon, 1446
as an emergent phenomenon, 1445
cosmology, standard, 1383
Coulomb correction to pressure in plasma, 1108
Coulomb logarithm, 1008–1009
Coulomb scattering
Rutherford scattering analysis, 1006–1007
Fokker-Planck analysis of, 1013–1015
deﬂection times and frequencies, 1008
energy equilibration times, 1010–1012, 1002t
Cowling’s theorem, for dynamos, 984
critical density for universe, 1377
critical point of transonic ﬂuid ﬂow, 883, 886, 891
Crocco’s theorem, 702, 742
Cross correlation, 306–308
cross product, 25–26
Cross spectral density, 307–308
cruise-control system for automobiles, 1097–1098
crystals, nonlinear. See nonlinear crystals
curl, 25–26
current density
as spatial part of charge-current 4–vector, 74
as integral over plasma distribution function, 1072
current moments, gravitational, 1328–1332
curvature coupling in physical laws, 1219–1221
curvature drift, 1026, 1027f
curve, 9, 49, 1154–1155
cutoff, in wave propagation, 1049–1050, 1050f
cyclic symmetry, 1214n
cyclotron frequencies, 1019, 1002t
relativistic, 1024
Cygnus X-1, 111
cylindrical coordinates
related to Cartesian coordinates, 614
orthonormal basis and connection coefﬁcients for,
614–615
expansion and shear tensor in, 617, 618
coordinate basis for, 1163, 1163f
d’Alembertian (wave operator), 71, 1191, 1434
d’Alembert’s paradox, for potential ﬂow around a cylinder,
765
dam, water ﬂow after breaking, 857–858, 897
dark energy, 1363, 1444, 1446. See also cosmological constant
dark matter
observational evidence for, 1380–1381
physical nature of, 1440–1442
searches for dark-matter particles, 1442
evolution of, in early universe, 1406–1407, 1411f
de Broglie waves, 44b
De Laval nozzle, 887
de Sitter universe or expansion, 1398, 1400, 1432, 1437
Debye length, 1002t, 1004
Debye number, 1002t, 1004
Debye shielding, 1003–1004
Subject Index
1483

decay time for magnetic ﬁeld, in MHD, 949, 950t
deceleration function q(t) for the universe, 1374, 1378
value today, 1382
decibel, 865
decoherence, quantum, and entropy increase, 185, 186b–
187b, 190–191
deﬂection of starlight, gravitational, 1304–1307. See also
gravitational lensing
degeneracy, of gas, 122–124, 122f, 1000, 1002
relativistic, 122f, 125, 127
degree of coherence. See under coherence of radiation
density fractions, k, for cosmology, 1377–1378
density of states (modes)
for free particles, 108–110
in statistical mechanics, 162–163
density operator (matrix), in quantum statistical mechanics,
165b–166b
derivatives of scalars, vectors, and tensors
directional derivatives, 22–23, 70, 1167, 1169
gradients, 23, 70–71, 617, 1170–1171, 1173
Lie derivative, 735n
deuterium formation in early universe, 1389–1392
dielectric tensor, 1036
in nonlinear crystal, 537
in cold, magnetized plasma, 1051–1052
differential forms, 78
one-forms used for 3–volumes and integration, 77n
and Stokes’ theorem, 78
diffraction grating, 422–424, 524–529
diffraction: scalar, Helmholtz-equation formalism for, 413–
436. See also under Fraunhofer diffraction; Fresnel
diffraction
propagator through an aperture, 416–417
Fresnel and Fraunhofer regions deﬁned, 417–419, 418f
Fraunhofer diffraction, 420–429
Fresnel diffraction, 429–436
failure near edges of apertures, 415
application to weak sound waves in a homogenous
medium, 413
application to electromagnetic waves in vacuum or a
homogeneous dielectric medium, 413
failure due to polarization effects, 413, 413n, 416n
diffusion. See also Boltzmann transport equation; diffusion
coefﬁcient; diffusion equation
approximation: criteria for validity, 140
conditional probability for, 291–292
of neutrons in a nuclear reactor, 151–153
diffusion coefﬁcient
deﬁned, 139
for particle diffusion through thermalized scatterers,
150–151
for temperature, in thermally conducting ﬂuid, 142,
920
for vorticity, in viscous ﬂuid, 741
for electrons interacting with electrostatic waves in
plasma, 1118–1119, 1123
for magnetic ﬁeld, in MHD, 948
diffusion equation, 140
solution in inﬁnite, homogenous medium, 141, 291
and random walk, 140, 140n
Fokker-Planck equation as, 339
for temperature in homogenous medium, 142, 920
for vorticity, in viscous ﬂuid, 741
for magnetic ﬁeld, in MHD, 948
in nonlinear plasma physics, 1118–1119, 1135, 1148
dimensional analysis for functional form of a ﬂuid ﬂow,
790–791
dimensional reduction in elasticity theory, 590b
for bent beam, 592–595
for bent plate, 609–613
Dirac equation, 44b
energy eigenstates (modes) of, 175n
directional derivative, 22–23, 70, 1167, 1169
dispersion relation, 353. See also under geometric optics;
speciﬁc types of wave
as Hamiltonian for rays, 361, 367
displacement vector, in elasticity, 570
gradient of, decomposed into expansion, shear, and
rotation, 570–571
Navier-Cauchy equation for, 587. See also Navier-Cauchy
equation for elastostatic equilibrium
dissipation, 724b. See also ﬂuctuation-dissipation theorem
distortion of images, 1424
distribution function. See also under speciﬁc ensembles
as a geometrical object, 162
Newtonian number density in phase space, 99
relativistic number density in phase space, 104
statistical mechanical, number density of systems in phase
space, 163
statistical mechanical, probabilistic, ρ, 161
in statistical equilibrium, general, 173
normalization, 163
mean occupation number, 108–110. See also occupation
number, mean
N-particle, 1102–1103
isotropic, 120–121
integrals over momentum space, 117–121
evolution of. See Boltzmann equation, collisionless;
Boltzmann transport equation; Vlasov equation
for photons, 106–108
in terms of speciﬁc intensity, 107
for particles with range of rest masses, 104–105
1484
Subject Index

for particles in a plasma, 105–106, 1071
N-particle, 1102–1103
divergence, 24, 71
DNA molecule, elastostatics of, 599–600
domain walls, 1432n
Doob’s theorem, 295–296
proof of, 298–299
Doppler shift, 62
of temperature of CMB, 116–117
double diffusion, 937–940
drag force and drag coefﬁcient, 792
at low Reynolds number (Stokes ﬂow), 753–754
inﬂuence of turbulence on, 792f, 794, 820–821
on a ﬂat plate, 763–764
on a cylinder, 792–794, 792f
on an airplane wing, 820–821
on sports balls, 825
on ﬁsh of various shapes, 797–798
drift velocities
for charged particles in electromagnetic ﬁeld, 1025–1027
for electron and ion ﬂuids, 1038–1039
drift waves, 1067–1068
DVD, 530, 531
dynamos, 984–988
E-modes, of CMB polarization, 1419f, 1420, 1428
Earth. See also atmosphere of Earth; elastodynamic waves in
Earth
internal structure of, 651t
pressure at center of, 649
Moho discontinuity, 650
mantle viscosity, 755–756
mantle convection, 932
continental drift, 932
normal modes excited by atmospheric turbulence, 816
eddies
in ﬂow past a cylinder, 791f, 793–794
in turbulence, 798–800, 802, 804–807, 811–814
eikonal approximation. See geometric optics
Einstein curvature tensor, 1223
contracted Bianchi identity for, 1223
components in speciﬁc metrics
static, spherical metric, 1258
linearized metric, 1228
Robertson-Walker metric for universe, 1371–1372
perturbations of Robertson-Walker metric, 1401–1402
Einstein ﬁeld equation, 1223, 1224
derivation of, 1221–1223
Newtonian limit of, 1223, 1226–1227
linearized, 1229
cosmological perturbations of, 1402
solutions of, for speciﬁc systems. See under spacetime
metrics for speciﬁc systems
Einstein summation convention, 16, 55
Einstein–de Sitter universe, 1378, 1398, 1399f
Ekman boundary layer, 772–777
Ekman number, 768
Ekman pumping, 773
elastic energy density, 583–584
elastic physical free energy density, 584
elastic limit, 580, 581f
elastic moduli, 580–582
physical origin of, and magnitudes, 585–586, 586t
for anisotropic solid, 580
for isotropic solid
shear and bulk, 581–582
Young’s, 591
numerical values, 586t
in Earth, 651t
elastodynamic waves in a homogeneous, isotropic medium,
630–642
inﬂuence of gravity at ultralow frequencies, 639
wave equation, 635–636
energy density, energy ﬂux, and Lagrangian for, 641–642
decomposition into longitudinal and transverse, 636, 636f,
640
Heaviside Green’s functions for, 658–660
longitudinal waves, 637–638
displacement is gradient of scalar, 637, 639–640
sound speed, dispersion relation, group and phase
velocities, 637–638
transverse waves, 638–639
displacement is curl of a vector, 637, 639–640
sound speed, dispersion relation, group and phase
velocities, 638–639
Rayleigh waves at surface, 654–657
elastodynamic waves in Earth
body waves, 650–654
P-modes and S-modes, 650
wave speeds at different depths, 651t
geometric optics ray equation, 652
junction conditions and mixing of, at discontinuities,
651–654, 651f, 653f
rays inside Earth, 653f
edge waves, 654
Rayleigh wave at Earth’s surface, 654–657
Love waves at Earth’s surface, 658
internal waves, 941
elastodynamic waves in rods, strings, and beams, 642–648
waves on a string under tension, 644–645
ﬂexural waves in a stretched or compressed beam, 645–646
torsion waves in a circular rod, 643–644
Subject Index
1485

elastodynamics. See also elastodynamic waves in Earth;
elastodynamic waves in a homogeneous, isotropic
medium; elastodynamic waves in rods, strings, and
beams
force density, 587
in cylindrical coordinates, 624
when gravity can be ignored, 631
momentum conservation, 631
wave equation for displacement vector, 635–636
quantization of, 667–670
elastostatic force balance. See Navier-Cauchy equation for
elastostatic equilibrium
electric charge. See charge density
electromagnetic ﬁeld. See also electromagnetic waves;
Maxwell’s equations
electromagnetic ﬁeld tensor, 52, 53, 72
electric and magnetic ﬁelds, 72
as 4–vectors living in observer’s slice of simultaneity,
72–73, 73f
4–vector potential, 74–75
scalar and 3–vector potentials, 75
electric displacement vector, 536, 1036
stress tensor, 33
stress-energy tensor. See under stress-energy tensor
electromagnetic waves
vacuum wave equation for vector potential, 75, 1219–1220
in curved spacetime: curvature coupling, 1219–1220
in nonlinear dielectric medium, 536–564. See also wave-
wave mixing; three-wave mixing in nonlinear
crystals; four-wave mixing in isotropic, nonlinear
media
wave equation, 537
in anisotropic, linear dielectric medium, 551, 1035–1037
wave equation and dispersion relation, 551, 1037
in cold plasma, 1035–1068
electron microscope, 444–445
electron motion in electromagnetic ﬁeld, 1024–1032
electro-optic effects, 539
electrostatic waves. See also Langmuir waves; ion-acoustic
waves; Landau damping
dispersion relation for, 1083–1084
for weakly damped or growing modes, 1085–1086
kinetic-theory analysis of, 1077–1079
stability analysis of, 1090–1092, 1095–1098
quasilinear theory of, 1113–1135
nonlinear: BGK waves, 1100–1101
embedding diagram, 1261–1263, 1276–1277, 1321f
emission
spontaneous, 115
in lasers, 515
of plasmons, in a plasma, 1126–1128
stimulated, 115
in lasers, 496, 515–516, 516f
of plasmons, in a plasma, 1134
energy conservation, Newtonian, 359, 695
energy conservation, relativistic
differential, 85, 1176
integral (global) in ﬂat spacetime, 84, 86
global, incurved, asymptoticallyﬂatspacetime, 1237–1238
global, in generic curved spacetime: fails!, 1177, 1218
energy density, Newtonian, U
deduced from lagrangian, 365
as integral over distribution function, 121
for prototypical wave equation, 365
energy density, relativistic
as component of stress-energy tensor, 83
as integral over distribution function, 120, 126
energy ﬂux, Newtonian, F,
deduced from lagrangian, 365
in diffusion approximation, 147–148
for prototypical wave equation, 365
energy ﬂux, relativistic
as integral over distribution function, 120
as component of stress-energy tensor, 83
energy potential. See under fundamental thermodynamic
potentials
energy principle for perturbations of magnetostatic
equilibria, 980–982
energy, relativistic, 34, 59
as inner product of 4-momentum and observer’s
4–velocity, 60–61
for zero-rest-mass particle, 60, 106
kinetic, 34, 59
Newtonian limit, 34, 112
engine, adiabatic, 241
engine, isothermal, 241
ensemble average
in statistical mechanics, 163–164
in theory of random processes, 287
ensemble of systems, 160. See also speciﬁc ensembles
in statistical equilibrium, 160–161, 172–177
general, 172–173
tables summarizing, 160t, 221t
out of statistical equilibrium, 248–270
table summarizing, 251t
enthalpy ensemble, 221t, 245
enthalpy, 174
entrainment of one ﬂuid by another
laminar, 796–797
turbulent, 806, 809–810
entropy, 181
additivity of, derived, 185
1486
Subject Index

estimates of, 185
maximized in statistical equilibrium, 183
per particle, 187, 191–192
increase of. See thermodynamics, second law of
of speciﬁc entities
general ensemble, 181
microcanonical ensemble, 182
thermalized mode, 187
thermalized radiation, 188
classical, nonrelativistic, perfect gas, 188–190
mixing of two different gases, 190
black hole, 206
black hole and radiation inside a box, 206–209
the universe, 209–210
information, 211–217
E¨otv¨os experiment, 1300
equations of state
computed from kinetic theory, 121
polytropic, 681b, 687, 726b, 878
thermodynamic quantities in terms of sound speed,
878–879
for ideal or perfect gas, 228, 675n
for ﬂuids, 680b–681b, 725b
for nonrelativistic hydrogen gas, 122–125
for van der Waals gas, 234
for thermalized radiation, 128–129
equipartition theorem, 177–178
equivalence principle
weak, 1300–1301
Einstein’s, 1196, 1217
delicacies of, 1218–1221
used to lift laws of physics into curved spacetime,
1217–1218
ergodic hypothesis,
in statistical mechanics, 180–181
in theory of random processes, 288–289
ergodic theory, 181n
ergosphere of black hole, 1283–1284
eschatology of universe, 1400–1401
etalon, 483–486, 489
reﬂection and transmission coefﬁcients, 484, 485, 486–488
power reﬂectivity and transmissivity, 486
Euler equation of ﬂuid dynamics, 697, 725b
Euler’s equation (relation) in thermodynamics, 226–227,
231, 240, 247, 256–257
Eulerian changes, 725b
Eulerian perturbations, 971–972
evanescent wave, 654
event, 40
expansion, in elasticity theory, , 571, 572b, 574, 577
temperature change during, 585
expansion rate of ﬂuid, θ, 693, 725b
expansion rate of universe, H(t), 1374
explosions and blast waves
in atmosphere or interstellar space, 908–914
into stellar wind, 915–916
underwater, 914–915
extensive variables, 169, 172, 221
complete set of, for a closed system, 222
extraordinary waves
in nonlinear crystals, 546–548, 551
in a cold, magnetized plasma, 1057–1058, 1060, 1063,
1064f
Fabry-Perot interferometer (cavity), 490, 491–502
with spherical mirrors: modes of, 491b–492b
ﬁnesse, 493
free spectral range, 493
Gouy phase, 493
reﬂection and transmission coefﬁcients, 490
power transmissivity and reﬂectivity, 494f
resonance FWHM, 493
Bose-Einstein behavior on resonance, 495
applications of
laser stabilization, 497–498, 501
lasers, 496
mode cleaner for laser beam, 496–497
reshaping light beam, 497
spectrometer, 496
optical frequency comb, 498–501
factor ordering in correspondence principle, 1219–
1220
Faraday rotation, 1053–1054, 1060–1061
feedback-control system, 1093b
stability analysis of, 1093b–1095b, 1098
Feigenbaum sequence and number, 828–831
Fermat’s principle, 371
for dispersionless waves, 372–373
and Feynman sum over paths, 372
for general relativistic light rays, 1306–1307. See also
gravitational lensing
Fermi momentum, 124
Fermi-Dirac distribution
probabilistic distribution function for, 176
mean occupation number of, 112–113, 176
near-degenerate, 124f, 125
entropy of, 187
Fermi-Walker transport, 1184
fermion, 110
Ferraro’s law of isorotation for magnetosphere,
970
ﬁltering of images. See image processing
Subject Index
1487

ﬁltering of random processes (noise), 311–313
types of ﬁlters
differentiation and integration, 311
averaging, 317–318
band-pass, 315–317
high-pass, 441
low-pass, 441
notch, 441
ﬁnite-Fourier-transform, 317–318
Wiener’s optimal, 318–320
ﬁnesse, of a Fabry-Perot interferometer, 493
ﬁnite-element methods, 565, 590b, 606f
ﬁsh
streamlining and drag coefﬁcients, 797–798
swimming, 744, 747b–748b
ﬂexural rigidity (bending modulus), 594
ﬂexural waves on a beam or rod, 353, 355f, 356, 645–646
ﬂows, ﬂuid. See ﬂuid ﬂows
ﬂuctuation-dissipation theorem
Langevin equation, 324–325
physics underlying, 323–325
elementary version of, 325–326
derivation of, 326–327
generalized version of, 331–334
derivation of, 334–335
applications of
Johnson noise in a resistor, 327
thermal noise in an oscillator, 329–330. See also noise,
thermal
laser-beam measurement of mirror position, 331–334
ﬂuctuations away from statistical equilibrium. See under
statistical equilibrium
ﬂuid, 677. See also ﬂuid dynamics, fundamental equations;
ﬂuid dynamics, relativistic; ﬂuid ﬂows; ﬂuid-ﬂow
instabilities
thermodynamics for, 679b–681b
perfect (ideal), 675, 675n
Newtonian, 712, 726b
non-Newtonian, 712f
ﬂuid dynamics, fundamental equations. See also ﬂuid
dynamics, relativistic
terminology, 724b–726b
mass density and ﬂux, 708t
mass conservation, 32–33, 692–693
for ideal ﬂuid in external gravitational ﬁeld
momentum density and ﬂux, 708t
Euler equation (momentum conservation), 696–697
energy density and ﬂux, 704, 708t
energy conservation, 707
entropy conservation, 697, 707
for self-gravitating ideal ﬂuid, 705b–707b, 709
for viscous, heat-conducting ﬂuid in external gravitational
ﬁeld, 710–719, 919–920
momentum and energy densities and stress tensor,
715t
viscous stress tensor, 712
Navier-Stokes equation (momentum conservation),
712–713. See also Navier-Stokes equation
total energy ﬂux, 715t
viscous and thermal-conductive energy ﬂux, 714
entropy evolution (dissipative heating), 715–716
for viscous, heat-conducting, incompressible ﬂow with
negligible dissipation, 919–920
Boussinesq approximation, 924–925. See also
convection
in rotating reference frame, 767–768, 770
ﬂuid dynamics, relativistic, 719–724
fundamental equations, 719–720
nonrelativistic limit, 723–724
relativistic Bernoulli equation and theorem, 721–722
application to steady, relativistic jet, 721–722
application to relativistic shock wave, 902–903
ﬂuid ﬂows. See also ﬂuid-ﬂow instabilities; ﬂuid dynamics,
fundamental equations; ﬂuid dynamics, relativistic
between two plates, steady, 718
through a pipe
laminar, 716–717, 766
onset of turbulence, 787
around a body at low Reynolds number: Stokes ﬂow,
749–754, 749f
around a cylinder: high-Reynolds-number, potential ﬂow,
765, 789–794
types of
barotropic, inviscid, 736–738, 740
viscous, 710–716.
high-Reynolds-number, 757–766
low-Reynolds-number, 746–757. See also low-
Reynolds-number ﬂow
irrotational (potential), 701
irrotational, incompressible, 837
incompressible, 709–710
compressible, 875–916. See also compressible ﬂuid ﬂow
laminar, 716–717. See also under boundary layers;
wakes; jets
turbulent, 787–834. See also under boundary layers;
wakes; jets
nearly rigidly rotating, 766–768
geostrophic, 770–777
self-similar, 759. See self-similar ﬂows
ﬂuid-ﬂow instabilities. See also ﬂuid ﬂows
convective. See convection
density inversion: Rayleigh-Taylor instability, 783–784
1488
Subject Index

shear ﬂows
Kelvin-Helmholtz instability, 778–782
inﬂuence of gravity and density stratiﬁcation, 782–783,
784–786
laminar boundary layer, 822–823
rotating Couette ﬂow, 784, 785f, 825–828
ﬂute instability for toroidal -pinch, 978–979, 978f
Fokker-Planck equation
in one dimension, 335–337
as a conservation law for probability, 339
derivation of, 337–338
for a Gaussian, Markov process, 338–339
for detailed-balance processes, 339–340
time-independent, 338
in multiple dimensions, 343
for Coulomb collisions, 1013–1016, 1032
for Doppler cooling of atoms by laser beams, 340–343,
341f
for electrons interacting with plasmons, 1123, 1130–1131
solutions of
for Brownian motion of a dust particle, 340
for Doppler cooling of atoms by laser beams, 340–343,
341f
for photon propagation through intergalactic gas
(Sunyaev-Zel’dovich effect), 1428–1430
for thermal noise in an oscillator, 344
force density, as divergence of stress tensor, 578
force-free magnetic ﬁeld, 964
Foucault pendulum, 407, 597–598
Fourier transform, conventions for
in theory of random processes, 299
in theory of diffraction, 420
in plasma physics, 1115
Fourier-transform spectroscopy, 474–476
four-wave mixing in isotropic, nonlinear media, 540,
558–564
speciﬁc nonlinear materials used, 559t
fully degenerate, evolution equations for, 561
resonance conditions, 560, 562
phase conjugation via, 559–562, 560f
squeezing via, 562
optical Kerr effect in an optical ﬁber, 562–564
fracture, criterion for safety against, 621
frame dragging by spinning bodies, 1233–1236, 1279–1282,
1295b–1296b, 1342
frame-drag ﬁeld, 1235b–1236b
frame-drag vortex lines, 1235b–1236b
around a linearized, spinning particle, 1236b
around a Kerr black hole, 1295b–1296b
around colliding black holes, 1344b–1345b
in a gravitational wave, 1318b, 1345b
Fraunhofer diffraction, 420–429
diffracted ﬁeld as Fourier transform of aperture’s
transmission function, 420
convolution theorem applied to, 422, 423f
Babinet’s principle for, 428–429
speciﬁc diffraction patterns
slit, 421, 434
diffraction grating, 422, 423f, 424
circular aperture: Airy pattern, 425–427
free energy, 241n
chemical (Gibbs) free energy. See under fundamental
thermodynamic potentials
physical (Helmholtz) free energy, 241–246
physical meaning of, 241, 241f
for elastic medium, 584, 603–604
free spectral range, of a Fabry-Perot interferometer, 493
free-fall motion and geodesics, 1200–1203
frequency and time standards, 310f, 310n
frequency doubling in nonlinear optics, 545–546, 553–555
Fresnel diffraction, 429–436. See also paraxial Fourier optics
Fresnel integrals for, 430–431
Cornu spiral, 431f
speciﬁc diffraction patterns
unobscured plane wave, 432
straight edge, 432–434
aperture with arbitrary shape, 430, 433–434, 434f
rectangular aperture, 430–431
circular aperture: Fresnel zones and zone plates,
434–436
near a caustic, 451–454, 452f
Fresnel integrals, 430–431
Fresnel length, 418
Fresnel zones and zone plates, 435–436
Fried parameter, 468b
Friedmann equations for expansion of the universe,
1376–1377
fringe visibility, 461–463
fringes, interference. See interference fringes
fundamental observers (FOs), in cosmology, 1366–1367
fundamental thermodynamic potentials. See also under
thermodynamics
energy potential
for energy representation of thermodynamics, 222–223
for nonrelativistic, classical, perfect gas, 227
Gibbs potential, 246–247
physical interpretation as chemical free energy, 247–248
computed by a statistical sum, 246, 248
grand potential, 229–230
computed by a statistical sum, 230, 232–238
for relativistic, perfect gas, 238–239
for van der Waals gas, 234
Subject Index
1489

fundamental thermodynamic potentials (continued)
physical-free-energy potential, 239–240
computed by a statistical sum, 239, 242–243
for ideal gas with internal degrees of freedom, 243
for elastic medium, 584, 603–604
enthalpy potential, 244–245
fundamental thermodynamic potentials out of statistical
equilibrium
Gibbs potential, 248–250, 251t
minimum principle for, 249, 251t
other potentials and their extremum principles, 250, 251t
used to analyze ﬂuctuations away from statistical
equilibrium, 260–270
fusion, controlled thermonuclear, 959–964, 999f, 1001,
1002t, 1140–1142
motivation for, 958–959
Lawson criterion for, 960
d, t fusion reaction, 959
magnetic conﬁnement for, 960–964.
laser fusion, 1140–1142
g modes of sun, 837, 849–850
gain margin, for stability of control system, 1095b, 1098
galaxies
structures of, 201–202
observed properties of, 1364, 1365f, 1412–1413
distortion of images by gravitational lensing, 1424–1427
spatial distribution of, 1364
power spectrum for, 1412–1415, 1414f
correlation function for, 306f
statistical mechanics of, 202–204
formation of in early universe, 210–211, 1401–1406
dark matter in, 201–204, 1076n, 1364, 1365f, 1381
mergers of, 1413
galaxy clusters
dark matter in, 1380–1381
hot gas in, and Sunyaev-Zel’dovich effect, 1428–1430
merging, image of, 1365f
gas, 678, 725b
perfect gas, nonrelativistic, 121, 188–189, 726b
perfect, relativistic, 127, 238–239
ideal, 242–244, 725b
hydrogen, 122–123, 122f, 127, 999f
degenerate, 127–128
gas discharge, in laboratory, 999f, 1001, 1002t
gauge transformations and choices
in linearized theory of gravity, 1228–1229, 1312
in cosmological perturbations, 1401n
Gauss’s theorem
in Euclidean 3-space, 27
in spacetime, 78
Gaussian beams, 445–448
in Fabry-Perot cavity with spherical mirrors, 491b–
492b
in interferometric gravitational wave detectors (LIGO),
447–448
manipulation of, 447, 448
Gaussian random process, 292–294. See also Markov,
Gaussian random process
general relativity, 1191–1224
some history of, 1191–1193
linearized approximation to, 1227–1231
Newtonian limit of, 1225–1227
experimental tests of, 1299–1311
geodesic deviation, equation of, 1210
for light rays, 1423
on surface of a sphere, 1217
geodesic equation
geometric form, 1201–1202
in coordinate system, 1203
conserved rest mass, 1202
super-hamiltonian for, 1206, 1357
action principles for
stationary proper time, 1203, 1205–1206
super-Hamiltonian, 1357
conserved quantities associated with symmetries,
1203–1205
geodetic precession, 1290–1291, 1309–1310
geometric object, 1, 5, 41
geometric optics, 357–375, 1174. See also Fermat’s principle;
paraxial ray optics
as two-lengthscale expansion for a wave, 357, 359, 360
limitations (failure) of, 369–371
for a completely general wave, 366–368
for prototypical wave equation, 358–366
eikonal approximation, 359
connection to quantum theory, 362–365
rays and Hamilton’s equations for them, 361
dispersion relation as Hamiltonian, 361, 367
amplitude and its propagation, 359, 361, 364–365, 368
phase and its propagation, 359, 362, 367
angular frequency and wave vector, 359
energy density, U, 359
energy ﬂux, F, 359
quanta, 363
conservation of, 364, 365, 368
Hamiltonian, energy, momentum, number density, and
ﬂux of, 363
polarization vector, for electromagnetic waves, 405–406
propagation of: parallel transport along rays, 406–409
geometric phase, 406–409
eikonal equation (Hamilton-Jacobi equation), 362
1490
Subject Index

for dispersionless waves in time-independent medium
index of refraction, 372
ray equation, 373
Fermat’s principle: rays have extremal time, 372
Snell’s law, 373, 374f
examples
light propagating through lens, 370f,
light rays in an optical ﬁber, 374–375
ﬂexural waves in a tapering rod, 368–369
spherical sound waves, 368, 369
Alfv´en waves in Earth’s magnetosphere, 370f
gravitational waves, 1320–1324, 1338–1341
geometric phase, 406–409
geometric principle, 1, 6–7, 10
examples, 28, 29
geometrized units, 33–34, 35, 1157, 1224
numerical values of quantities in, 1225t
geometrodynamics, 1344b–1345b
geostrophic ﬂow, 770–777
Gibbs ensemble, 160t, 173–174, 221t. See also under
fundamental thermodynamic potentials;
thermodynamics
distribution function, 174
Gibbs potential. See under fundamental thermodynamic
potentials; fundamental thermodynamic potentials
out of statistical equilibrium
global positioning system, 1301–1302
global warming, 748–749, 755, 958, 1440n
globular star cluster, energy equilibration time for, 1012–
1013. See also stellar dynamics
Gouy phase
for freely propagating Gaussian beam, 446
for mode of a Fabry-Perot interferometer, 493
gradient drift, 1027, 1027f
gradient operator, 23, 70–71, 617, 1170–1171, 1173
Gran Telescopio Canarias, 609
grand canonical ensemble, 160t, 174, 221t, 229–239. See
also under fundamental thermodynamic potentials;
thermodynamics
distribution function, 174
grand partition function. See also fundamental
thermodynamic potentials, grand potential
as log of grand potential, 229–230
grand potential. See under fundamental thermodynamic
potentials
gravitation theories
general relativity, 1191–1224
Newtonian theory. See gravity, Newtonian
relativistic scalar theory, 53, 1194–1195
gravitational drift of charged particle in magnetic ﬁeld,
1026
gravitational ﬁelds of relativistic systems. See spacetime
metrics for speciﬁc systems
gravitational lensing, 396–404, 1305–1307, 1422–1427. See
also deﬂection of starlight, gravitational
refractive index models for, 396–397
derivation of, 1305–1307
Fermat’s principle for, 396–397, 1306–1307
microlensing by a point mass, 398–401
Einstein ring, 399, 400f
time delay in, 401
lensing by galaxies, 401–404, 404f
lensing of gravitational waves, 1323–1324
weak lensing, 1422–1427
gravitational waves, 1321f. See also gravitons
speed of, same as light, 45b
stress-energy tensor of, 1324–1326
energy and momentum carried by, 1324–1326
dispersion relation for, 354
generation of, 1327–1345
multipole-moment expansion, 1328–1329
quadrupole-moment formalism, 1330–1335
radiation reaction in source, 1333, 1338
numerical relativity simulations, 1341–1342
energy, momentum, and angular momentum emitted,
1332, 1334–1335
mean occupation number of modes, 1326–
1327
propagation through ﬂat spacetime, 1229, 1311–
1320
h+ and h×, 1315–1316
behavior under rotations and boosts, 1317, 1319
TT gauge, 1312–1315
projecting out TT-gauge ﬁeld, 1314b
Riemann tensor and tidal ﬁelds, 1312–1313
deformations, stretches and squeezes, 1315–1317
tidal tendex and frame-drag vortex lines for, 1318b
propagation through curved spacetime (geometric optics),
1320–1327, 1338–1341
same propagation phenomena as electromagnetic
waves, 1323
gravitational lensing of, 1323–1324
penetrating power, 1311
frequency bands for: ELF, VLF, LF, and HF, 1345–1347
sources of
human arm waving, 1333
linear oscillator, 1338
supernovae, 111
binary star systems, 1335–1342
binary pulsars in elliptical orbits, 1342–1345
binary black holes, 1341–1342, 1342f, 1343f, 1344b–
1345b
Subject Index
1491

gravitational waves (continued)
sources of (continued)
stochastic background from binary black holes,
1356–1358,
cosmic strings, 1357
detection of, 1345–1357
gravitational wave interferometers, 1347–1355. See
also LIGO; laser interferometer gravitational wave
detector
pulsar timing arrays, 1355–1357
gravitons
speed of, same as light, 45b, 1319
spin and rest mass, 1319–1320
gravity, Newtonian
gravitational potential, , 682
ﬁeld equation for , 682
gravitational acceleration g, 682
gravitational stress tensor, 705b
gravitational energy density, 706b
gravitational energy ﬂux, 706b
total gravitational energy, 709
gravity probe A, 1301
gravity probe B, 1309
gravity waves on water, 353, 355f, 356, 837–843
arbitrary depth, 837–840
shallow water, 840–843
dam breaking: water ﬂow after, 857
nonlinear, 840–841, 843, 850–858, 897
solitary waves (solitons) and KdV equation, 850–
858
deep water, 353, 355f, 356, 840
viscous damping of, 842
capillary (with surface tension), 844–848
Green’s functions
for wave diffraction, 417
in paraxial optics, 438
for elasticity theory, 590b
for elastostatic displacement, 626–627
for elastodynamic waves, 658–661, 660f
in Fokker-Planck theory, 343
greenhouse effect, 135, 137–138, 748, 958. See also climate
change
group velocity, 355
guide star, for adaptive optics, 470–471
guiding-center approximation for charged-particle motion,
1025–1030, 1055
gyre, 773, 775–776, 805
gyro frequencies. See cyclotron frequencies
gyroscope, propagation of spin
in absence of tidal gravity
parallel transport if freely falling, 1218–1219
Fermi-Walker transport if accelerated, 1184
precession due to tidal gravity (curvature coupling),
1219–1221
gyroscopes
inertial-guidance, 1182
used to construct reference frames, 39, 1156, 1180–1182,
1195
precession of due to frame-dragging by spinning body,
1232–1236, 1279, 1296b, 1309, 1318
laser, 501, 502f, 520
on Martian rover, 409
Hamilton-Jacobi equation, 362, 375
Hamilton’s equations
for particle motion, 136b
for particle motion in curved spacetime, 1206, 1275, 1291
for rays in geometric optics, 361–363, 367
for plasmons, 1124
in statistical mechanics, 158
Hamilton’s principal function, 362, 375
hamiltonian, constructed from lagrangian, 1433
hamiltonian for speciﬁc systems
harmonic oscillator, 159
L-C circuit, 332
crystal
fundamental mode, 159
all modes, weakly coupled, 159
damped system, 159n
star moving in galaxy, 159
particle motion in curved spacetime. See also geodesic
equation
super-hamiltonian, 1206, 1357
Hanbury Brown and Twiss intensity interferometer, 509–511
harmonic generation by nonlinear medium, 537, 545–546,
553–55
harmonic oscillator
hamiltonian for, 159
complex amplitude for, 344
thermal noise in, 344
Harriet delay line, 381
Hartmann ﬂow, 965–969
Hartmann number, 968
Hawking radiation
from black holes, 204–205, 1286–1287
from cosmological horizon, 1437
heat conduction, diffusive. See also conductivity, thermal;
diffusion; diffusion equation; random walk
in a stationary, homogeneous medium, 141–142
in a star, 142–148
in the sun, 937
in a ﬂowing ﬂuid, 920
ﬂuid ﬂow equations with heat conduction. See under
ﬂuid dynamics, fundamental equations
1492
Subject Index

Heaviside Green’s functions, 658–660, 660b
helicity
hydrodynamic, 985
magnetic, 965
helioseismology, 848–850
helium formation in early universe, 192–193, 1387–
1392
Helmholtz equation, 413
Helmholtz free energy. See under free energy
Helmholtz-Kirkhoff integral for diffraction, 414, 415f
high-Reynolds-number ﬂow, 757–766
boundary layers in. See boundary layers
Hilbert space, 18b
hologram, 522–531. See also holography
holography, 521–531
recording hologram, 522–525, 530
reconstructing 3-dimensional image from hologram,
525–527, 530
secondary (phase conjugated) wave and image, 525b, 527,
535
types of
simple (standard) holography, 521–528
reﬂection holography, 528, 530
white-light holography, 528
full-color holography, 528–529
phase holography, 528
volume holography, 528
applications of
holographic interferometry, 529, 529f
holographic lenses, 529, 530–531
homogeneity of the universe, 1364–1366
homogeneous spaces
2-dimensional, 1367–1370
3-dimensional, 1370, 1372
Hooke’s law, 568f, 591
realm of validity and breakdown of, 580, 581f
horizon problem in cosmology, 1387, 1388f, 1431–1432
horizon radius of universe, χH, 1375
horizon, black-hole event
nonrotating (Schwarzschild), 1272
formation of, in imploding star, 1273, 1273f
surface gravity of, 1274
rotating (Kerr), 1279–1280
generators of, 1280, 1281f, 1282
angular velocity of, 1280
surface gravity of, 1286
surface area of, 1284, 1285
horizon, cosmological, 1375
horizon radius, χH, 1375
horizon problem, 1387, 1388f, 1431–1432
and theory of inﬂation, 1437–1438
acoustic horizon and radius, χA, 1375
Hubble constant, H0, 1374
measurements of, 1375
Hubble law for expansion of universe, 1374
Hubble Space Telescope
images from, 400, 404, 1365
spherical aberration in, and its repair, 426–427
Huygen’s model for wave propagation, 411, 417
hydraulic jump, 903–904, 904f
hydrogen gas. See gas, hydrogen
hydromagnetic ﬂows, 965–971
hydrostatic equilibrium
in uniform gravitational ﬁeld
equation of, 681
theorems about, 682–683
of nonrotating stars and planets, 686–689
of rotating stars and planets, 689–691
barotropic: von Zeipel’s theorem, 702
centrifugal ﬂattening, 690, 691
of spherical, relativistic star, 1258
hydrostatics, 681–691
ideal ﬂuid. See perfect ﬂuid
ideal gas. See gas, ideal
image processing
via paraxial Fourier optics, 436–437, 441–445
low-pass ﬁlter: cleaning laser beam, 441
high-pass ﬁlter, accentuating features, 441
notch ﬁlter: removing pixellation, 441
convolution of two images or functions, 443–
444
phase-contrast microscopy, 442–443
transmission electron microscope, 444–445
speckle, 470b, 472
impedance
acoustic, 654
complex, for ﬂuctuation-dissipation theorem, 332
incompressible approximation for ﬂuid dynamics, 709–710,
725b
index gymnastics. See component manipulation rules
index of refraction, 372
numerical values, 541b–542b, 547f, 559t
for axisymmetric optical systems, 377
for optical elements, 483, 486–489, 497n
for optical ﬁber, 374, 447, 534
for anisotropic crystals, 546
for plasma waves, 1052, 1057, 1058f
for Earth’s atmosphere, 466b–469b, 814–815
for seismic waves in Earth, 652
for model of gravitational lensing, 396, 1307
induction zone, 1327f
inertial (Lorentz) coordinates, 41, 54, 1157
inertial-guidance system, 1182b
Subject Index
1493

inertial mass density (tensorial)
deﬁnition, 87
for perfect ﬂuid, 87
inertial reference frame. See Lorentz reference frame
inﬂation, cosmological, 1431–1440
motivation for, 1431–1432
theory of, 1434–1438
particle production at end of, 1435, 1437
tests of, 1438–1439
inﬂaton ﬁeld, 1433
potential for, 1435, 1436b
energy density and pressure of, 1435
evolution of, 1435, 1436b, 1437
dissipation of, produces particles, 1437
information
deﬁnition of, 212
properties of, 216
statistical mechanics of, 211–218
per symbol in a message, 214, 215
gain deﬁned by entropy decrease, 211–212
inner product
in Euclidean space, 10–12, 17
in spacetime, 48, 56
in quantum theory, 18b
instabilities in ﬂuid ﬂows. See ﬂuid-ﬂow instabilities
integrals in Euclidean space
over 2-surface, 27
over 3–volume, 27
Gauss’s theorem, 27, 1176
integrals in spacetime, 75–78, 1174–1176
over 3-surface, 77, 80–81, 1175
over 4–volume, 75, 1175
Gauss’s theorem, 27, 78
not well deﬁned in curved spacetime unless inﬁnitesimal
contributions are scalars, 1175
intensive variables, 172, 221–222
interference by division of the amplitude, 473
interference by division of the wavefront, 458
interference fringes
for two-beam interference, 457f, 458, 458n
for perfectly coherent waves, 459
for waves from an extended source, 460
fringe visibility, 460–463, 475
in Fresnel diffraction, 419f,
near a caustic, 452f, 453
interferogram, 475, 476
interferometer
Fabry-Perot, 490–495. See also Fabry-Perot interferometer
gravitational wave. See LIGO; laser interferometer
gravitational wave detector
Michelson, 474, 475f
Michelson stellar,464, 465f
Sagnac, 501–502
radio-telescope, 479–483
very long baseline (VLBI), 482
intensity, 509–511
stellar intensity, 511
interferometric gravitational wave detector. See laser
interferometer gravitational wave detector; LIGO
interferometry, multiple-beam, 483–486
intergalactic medium, 999f, 1002, 1002t
intermittency in turbulence, 798–799, 807
internal waves in a stratiﬁed ﬂuid, 941
international pulsar timing array (IPTA), 1356
interstellar medium, 891, 914–916, 950t, 989, 992, 999f, 1001,
1002t, 1012, 1060–1061, 1138–1139, 1146–1147
interval
deﬁned, 45, 1159
invariance of, 45–48, 1159–1160
spacelike, timelike, and null (lightlike), 45
inviscid, 725b
ion-acoustic waves. See also electrostatic waves; plasmons
in two-ﬂuid formalism, 1046–1050
in kinetic theory, 1088–1090
Landau damping of, 1088
nonlinear interaction with Langmuir waves, 1132–1135
solitons, 1142–1146
ionosphere, 999f, 1001, 1002t, 1059
radio waves in, 1058–1062
irreducible mass of black hole, 1284–1287
irreducible tensorial parts of second-rank tensor, 572b–574b,
577, 711
irrotational ﬂow (vorticity-free), 701, 725b, 837
isentropic, 725b
Ising model for ferromagnetic phase transition, 272–282
1-dimensional Ising model, 278–279
2-dimensional Ising model, 272–273
solved by Monte Carlo methods, 279–282
solved by renormalization group methods, 273–278
isobar, 725b
isothermal engine, 241
isotropy of the universe, 1364–1366
ITER (International Thermonuclear Experimental Reactor),
963
James Webb Space Telescope, 427
Jeans’ theorem, 169, 1074–1077, 1100, 1407
jerk function j(t) for universe, 1374, 1378
value today, 1382
JET (Joint European Torus), 963
jets
laminar, 796–797
1494
Subject Index

turbulent, 809f, 810
Johnson noise in a resistor, 327
Joukowski’s (Kutta-Joukowski’s) theorem, 743
Joule-Kelvin cooling, 708, 708f
junction conditions
elastodynamic, 588–589, 651, 654
hydraulic jump, 903–904
MHD, 953–956
shock front. See Rankine-Hugoniot relations for a shock
wave
Jupiter, 455, 687, 689, 702, 801, 1100
JVLA (Jansky Very Large Array), 480
K´arm´an vortex street, 791f, 794
KDP nonlinear crystal, 541b, 546–548, 1141
Keck telescopes, 609–611
Kelvin-Helmholtz instability in shear ﬂow, 778–782
inﬂuence of gravity on, 782–783
onset of turbulence in, 801b
Kelvin’s theorem for circulation, 740, 746, 824
Kepler’s laws, 14, 691, 784, 1232–1233, 1247, 1304, 1335,
1344
kernel of a ﬁlter, in theory of random processes (noise),
311–313
Kerr metric. See also black holes; horizon, black-hole event
in Boyer-Lindquist coordinates, 1277–1279
in (ingoing) Kerr coordinates, 1281–1282, 1281n
geodesic orbits in, 1291
dragging of inertial frames in, 1279, 1290–1291
precession of gyroscope in orbit around, 1290–1291
tidal tendex lines and frame-drag vortex lines in,
1295b–1296b
light-cone structure of, 1279–1282
event horizon of, 1280
Cauchy horizon of and its instability, 1282n
Killing vector ﬁeld, 1203–1205
kink instability, of magnetostatic equilibria, 977–978
Knudsen number, 755n
Kolmogorov spectrum for turbulence, 467, 810–815
phenomena missed by, 814
derivation of, 810–812
for transported quantities, 467, 814–816
in Earth’s atmosphere, 466b–471b
Kompaneets equation, 1429
Korteweg–de Vries equation and soliton solutions, 850–856,
858, 1048–1049
KTP nonlinear crystal, 542, 554–555
Kutta-Joukowski’s theorem, 743
Lagrange multiplier, 183
Lagrangian changes, 725b
lagrangian methods for dynamics, 1433
lagrangian density
energy density and ﬂux in terms of, 365, 642, 1434
for prototypical wave equation, 365
for scalar ﬁeld, 1434
for electrodynamics, 1433–1434
for elastodynamic waves, 642
Lagrangian perturbations, 971–972
Lam´e coefﬁcients, 582
laminar ﬂow, 716–717. See also under boundary layers; jets;
wakes
Landau contour, 1082f, 1083
Landau damping
physics of: particle surﬁng, 1046, 1069–1070, 1098–1099
for ion-acoustic waves, 1088–1090
for Langmuir waves, 1086–1088
in quantum language, 1127–1129
Landauer’s theorem in communication theory, 217–218
Langmuir waves. See also electrostatic waves; plasmons
in two-ﬂuid formalism, 1044–1047
in kinetic theory, 1086–1088, 1090
in quasilinear theory, 1115–1123
summary of, in one dimension, 1120
evolution of electron distribution, 1118–1120
evolution of wave spectral density, 1118
in three dimensions, 1122–1123
Landau damping of, 1086–1088, 1098–1099
particle trapping in, 1098–1100
nonlinear interaction with ion-acoustic waves, 1132–
1135
Laplace transform, 1081, 1084
used to evolve initial data, 1081
laplacian, 24, 402, 665
Larmor radius, 1019, 1002t
laser
principles of, 515–519
light in quantum coherent state, 518
pump mechanisms, 519
types of
continuous wave, 517, 519
pulsed, 517, 519
Nd:YAG, 553
mode-locked, 520–521. See also optical frequency
comb
free electron, 521
nuclear powered X-ray, 521
laser frequency stabilization
locking to atomic transition, 519
locking to mode of an optical cavity: PDH locking,
497–498, 501, 519
laser gyroscope, 501, 502f, 520
Subject Index
1495

laser interferometer gravitational wave detector. See also
LIGO
spectral density of noise, 302
in initial LIGO detectors, 302f
sensitivity: weakest detectable signal, 505
order-of-magnitude analysis of, 503–505
general relativistic analyses of
in proper reference frame of beam splitter, 1347–1349,
1352–1355
in TT gauge, 1347–1352
for more realistic interferometer, 1355
Gaussian beams in, 447–448
power recycling in, 505
signal recycling in, 506
phase shift in arm, 506–507
photon shot noise in, 507–509
scattered light in, 448–451
experimental challenges, 505
laser pointer, 554–555
latent heat, 252, 254, 255, 270
Lawson criterion for controlled fusion, 960
least action, principle of, 371, 371n
left modes, for plasma electromagnetic waves parallel to
magnetic ﬁeld, 1052–1056
lens, thin: light propagation through
geometric optics description of, 378–379, 379f
paraxial Fourier optics description of (Abb´e’s theory),
439–441
and optical Fourier transforms, 439–441
Lense-Thirring precession, 1233, 1290–1291, 1309–1310
Lenz’s law, 945
Levi-Civita tensor in Euclidean space, 24–26
product of two, 25
Levi-Civita tensor in spacetime, 71, 1174–1175
Lie derivative, 735n
light cones, 1155–1156, 1155f, 1159, 1186–1187, 1230, 1230f
near Schwarzschild black hole, 1264–1265, 1269, 1272
near Kerr black hole, 1279–1283
LIGO (Laser Interferometer Gravitational-Wave
Observatory). See also laser interferometer
gravitational wave detector
discovery of gravitational waves, 506, 1326, 1346
initial LIGO detectors (interferometers), 447–448, 503
noise in, 302f, 323, 334, 448–451, 507–509, 626
order-of-magnitude analysis of, 503–506
schematic design of, 503f
advanced LIGO detectors (interferometers), 448, 503, 506,
1346–1347
signal recycling in, 506
Gaussian beams in, 447–448
laser frequency stabilization in, 519
signal processing for, 320, 329–330, 1341
squeezed states of light in, 557
LINAC Coherent Light Source (LCLS), 521
line element, 57, 1163–1164
linearized theory (approximation to general relativity),
1227–1231
Liouville equation, in statistical mechanics, 167
quantum analog of, 165b–166b
Liouville’s theorem
in kinetic theory, 132–134, 133f
in statistical mechanics, 166, 168f
liquid, 678, 726b
bulk modulus for, 678
liquid crystals and LCDs, 539, 712
Lithium formation in early universe, 1392
local Lorentz reference frame and coordinates, 1195–1196,
1195f
connection coefﬁcients in, 1199–1200
inﬂuence of spacetime curvature on, 1213
metric components in, 1196–1200
inﬂuence of spacetime curvature on, 1213
Riemann tensor components in, 1214
nonmeshing of neighboring frames in curved spacetime,
1197–1199, 1197f
logistic equation, 828–831
Lorentz contraction
of length, 66–67
of volume, 99
of rest-mass density, 81, 723
Lorentz coordinates, 41, 54, 1157
Lorentz factor, 58
Lorentz force
in terms of electromagnetic ﬁeld tensor, 53, 71,
1156
in terms of electric and magnetic ﬁelds, 6, 14, 72
geometric derivation of, 52–53
Lorentz group, 64
Lorentz reference frame, 39, 39f, 1156–1157. See also local
Lorentz reference frame and coordinates
slice of simultaneity (3-space) in, 58, 59f
Lorentz transformation, 63–65, 1158
boost, 64, 65f
rotation, 65
Lorenz equations for chaotic dynamics, 834
Lorenz gauge
electromagnetic, 75, 760, 1219–1220
gravitational, 1229–1230
low-pass ﬁlter, optical, 441
low-Reynolds-number ﬂow, 746–757
nearly reversible, 746
pressure gradient balances viscous stress, 746
1496
Subject Index

regimes of: small-scale ﬂow, or very viscous large-scale
ﬂow, 746
luminosity distance, dL, 1375–1376
Lyapunov time and exponent, 832–833
Lyman alpha spectral line, 1373, 1393–1396
Mach number, 882
magnetic bottle, 1028, 1029f
magnetic conﬁnement of plasma, for controlled fusion,
960–964
magnetic ﬁeld diffusion in MHD, 948–950, 950t, 956
magnetic ﬁeld interaction with vorticity, 957–958, 958f
magnetic ﬁeld-line reconnection, 950, 986–988, 987f
magnetic force density on ﬂuid, in MHD, 951–952
magnetic lenses for charged particles, 381–383
magnetic materials, 270–282
paramagnetism and Curie’s law, 271–272
ferromagnetism, 272–282
phase transition into, 272–273. See also Ising model for
ferromagnetic phase transition
magnetic Reynolds number, 950, 950t
magnetization
in magnetic materials, 270
in magnetized plasma, 1039
magnetohydrodynamics (MHD), 943–993
conditions for validity, 1020
fundamental equations of
electric ﬁeld, charge, and current density in terms of
magnetic ﬁeld, 947–948
magnetic-ﬁeld evolution equation, 948
freezing-in of magnetic ﬁeld, 948
magnetic ﬁeld diffusion, 948
ﬂuid equation of motion, 951
magnetic force density on ﬂuid, 951–952
boundary conditions and junction conditions, 953–956
momentum conservation, 951
energy conservation, 952
entropy evolution, 953
ohm’s law, 947
generalizations of, 1020–1022
magnetoionic theory, for radio waves in ionosphere,
1058–1062
magnetosonic waves, 988–992
Alfv´en waves (intermediate magnetosonic mode),
354–355, 990–991, 1053f. See also Alfv´en waves
fast magnetosonic mode, 990–992
slow magnetosonic mode, 990–992
magnetosphere, 999f, 1001, 1002t
rotating, 969–970
in binary pulsars, 1310
Alfv´en waves in, 370
interaction of solar wind with Earth’s, 950, 957, 987–988,
1090, 1146–1147, 1146f
magnetostatic equilibria, 958–965, 971, 1030–1031
equations of, 960, 962
perturbations and stability of, 971–984
dynamical equation, 973
boundary conditions, 974
energy principle, 980–982
virial theorems, 982–984
magniﬁcation of images
by thin lens, 379
near a caustic, 390
in gravitational microlensing, 399, 400f, 401
Maple, 129, 132, 431, 619, 647, 691, 858, 1172
Markov random process, 289–291
Markov, Gaussian random process
probabilities for (Doob’s theorem), 295–296, 298–299
spectral density for, 303, 304f
correlation function for, 297, 304f
and ﬂuctuation-dissipation theorem, 325
Fokker-Planck equation for, 336–338, 343
mass conservation, 32–33, 80, 692–693
mass density
rest-mass density, 81
as integral over distribution function, 121
mass hyperboloid, 100–101, 100f
mass moments, gravitational, 1328–1332
mass-energy density, relativistic
as component of stress-energy tensor, 83, 85
as integral over distribution function, 126
matched asymptotic expansions, 874
in Stokes ﬂow, 753–754
in theory of radiation reaction, 869–871, 872f
Mathematica, 129n, 132, 431, 619, 647, 691, 858, 1172
Matlab, 129n, 132, 431, 619, 647, 691, 858, 1172
Maxwell relations, thermodynamic, 227–228, 232, 240, 247
as equality of mixed partial derivatives of fundamental
thermodynamic potential, 227–228
Maxwell velocity distribution for nonrelativistic thermalized
particles, 113–114, 114f
Maxwell-J¨uttner velocity distribution for relativistic
thermalized particles, 114–115, 114f
Maxwell’s equations
in terms of electromagnetic ﬁeld tensor, 73–74
in terms of electric and magnetic ﬁelds, 74, 946
in linear, polarizable (dielectric) medium, 1036
in nonlinear, polarizable (dielectric) medium, 536–537
mean free path, 140, 143–145, 146b, 149
mean molecular weight, 680b, 726b
Mercury, perihelion advance of, 1302–1304
method of moments. See moments, method of
Subject Index
1497

metric perturbation and trace-reversed metric perturbation,
1227–1228, 1311
metric tensor
in Euclidean space
geometric deﬁnition, 11–12
components in orthonormal basis, 17
in spacetime, 48, 1155
geometric deﬁnition, 48, 1155
components in orthonormal basis, 55, 1157
metrics for speciﬁc systems. See spacetime metrics for
speciﬁc systems
Metropolis rule in Monte Carlo computations, 280
MHD electromagnetic brake, 966, 967f
MHD electromagnetic pump, 966–968, 967f
MHD ﬂow meter, 966, 967f
MHD power generator, 966, 967f
Michelson interferometer, 474, 475f, 476
application to Fourier-transform spectroscopy, 475–476
Michelson stellar interferometer, 464, 465f
Michelson-Morley experiment, 474, 483
microcanonical ensemble, 160t, 178–180, 221–228, 221t
correlations of subensembles in, 179
distribution function for, 179
and energy representation of thermodynamics, 221–
228
microcantilever, 597
microscope
simple, 380f
rays traveling through, 380, 380f
phase-contrast, 442–443, 442f
transmission electron, 444–445
Minkowski spacetime, 1–2
mirror machine for conﬁning plasma, 963, 1030–1031
mirror point for particle motion in magnetic ﬁeld, 1027f,
1028–1029, 1029f
mixing length for convection in a star, 935–936
modes (single-particle quantum states), 174–176
for Bose-Einstein condensate, 194–195
Moho discontinuity, 648, 650
moments, method of: applications
solving Boltzmann transport equation, 147n
dimensional reduction in elasticity theory, 594–595,
612–613
constructing ﬂuid models from kinetic theory, 1074
momentum, relativistic, 34, 59
relation to 4-momentum and observer, 59, 61
of a zero-rest-mass particle, 60, 106
Newtonian limit, 34
momentum conservation, Newtonian
differential, 32, 694–695
integral, 32
momentum conservation, relativistic
for particles, 60
differential, 85, 1176–1177
global, for asymptotically ﬂat system, 1237–1238
global, fails in generic curved spacetime, 1177, 1218
momentum density
as component of stress-energy tensor, 83
as integral over distribution function, 118
momentum space
Newtonian, 98, 98f
relativistic, 100–101, 100f
monopoles, 1432n
Monte Carlo methods
origin of name, 279n
for 2-dimensional Ising model of ferromagnetism,
279–282
for radiative transfer, 1415–1419, 1428
Morse theory, 384
multiplicity factor for states in phase space, M, 163
multiplicity for particle’s spin states, gs, 109
multipole moments
in sound generation, 865–867
gravitational, 1232, 1328–1334
of CMB anisotropy, 1418, 1419f
method of moments. See moments, method of
National Ignition Facility, 519, 664, 1141
Navier-Cauchy equation for elastostatic equilibrium, 588
in cylindrical coordinates, 624
displacement is biharmonic, 589
boundary conditions for, 588–589
methods for solving, 590b
simple methods, 619–622
separation of variables, 624–626
Green’s function, 626–627
Navier-Stokes equation
general form, 712
for incompressible ﬂow, 713, 726b
in rotating reference frame, 767
Nd:YAG crystal and laser, 447, 553–554, 561
Nd:YVO4 crystal, 554
near zone, 1327f
nephroid, 384n
neutral surface, in elasticity theory, 592–593
neutrinos
chirality of, 109n
spin of, deduced from return angle, 1319–1320
spin-state multiplicity, 109
from supernovae, 914
in universe today, 1380t, 1382
in universe, evolution of, 1384, 1385f
1498
Subject Index

temperature and number density compared to photons,
1385, 1385n
decoupling in early universe, 1384, 1385f, 1406n
thermodynamically isolated after decouping, 192, 209,
1384
inﬂuence of rest mass, 1385n, 1410
free streaming through dark matter potentials,
1407–1409
neutron stars. See also binary pulsars; pulsars; stars, spherical,
in general relativity
birth in supernovae, 111, 914
equation of state, 125, 1257
structures of, 579, 734, 1258–1260
upper limit on mass of, 1260
magnetospheres of, 969–970
r-modes of oscillation, 860
accretion of gas onto, 784, 890–891
neutrons in early universe, 1384, 1387–1392, 1390f
noise. See also ﬂuctuation-dissipation theorem; LIGO;
random process; spectral density
as a random process, 308–313
types of spectra (spectral densities)
ﬂicker noise, 308–310, 323
random-walk noise, 308–310
white noise, 308–310
information missing from spectral density, 310–311
ﬁltering of, 311–313
Johnson noise in a resistor, 327
shot noise, 321–323, 507–509
thermal noise, 302f, 329–330, 334, 343–345, 448, 505,
598, 622–623, 626. See also ﬂuctuation-dissipation
theorem
nonlinear crystals
dielectric tensor for, 537
dielectric susceptibilities of, 536–540
for isotropic crystal, 538, 538n, 539–540
speciﬁc crystals and their properties, 541b–542b
wave-wave mixing in. See three-wave mixing in nonlinear
crystals; wave-wave mixing
nonlinear media. See nonlinear crystals; wave-wave mixing;
three-wave mixing; four-wave mixing in isotropic,
nonlinear media
normal modes
Sturm-Liouville, 974–975
of elastic bodies, 661–662, 664–668
quantization of, 668–669
of elastic, homogeneous sphere, 661–662, 664–667
radial, 661, 664–665
ellipsoidal, 662, 666–667
torsional, 661–662, 665–666
of Earth. See under Earth
of sun, 848–850
of magnetostatic equilibria, 975–976, 980–981
nuclear reactions. See chemical reactions, including nuclear
and particle
nuclear reactor
neutron diffusion in, 151–153
cooling of, 922–923
xenon poisoning in, 153
nucleosynthesis, in nuclear age of early universe, 192–193,
1387–1392
number density
as time component of number-ﬂux 4–vector, 79–80
as integral over distribution function, 117, 119, 121, 126
number ﬂux
as spatial part of number-ﬂux 4–vector, 79–80
as integral over distribution function, 117
number-ﬂux 4–vector
geometric deﬁnition, 79–80
as integral over distribution function, 118, 119
components: number density and ﬂux, 79–80
conservation laws for, 79–80
Nyquist diagram and method for analyzing stability,
1091–1098, 1092f
observer in spacetime, 41
occupation number, mean
deﬁned, 110
ranges, for fermions, bosons, distinguishable particles,
and classical waves, 110, 111
for plasmon modes in a plasma, 1123–1124
for cosmic X-rays, 111
for astrophysical gravitational waves, 111, 1326–1327
ocean currents
surface currents driven by winds, 775–776
deep currents driven by gyre pressure, 768, 775–776
ocean tides, 1212–1213
ocean waves
generation by atmospheric pressure ﬂuctuations in storms,
783
damping by turbulent viscosity, 842
breaking near shore, 903–904
Ohm’s law, 139. See also conductivity, electrical
in magnetohydrodynamics, 946–947
tensorial in magnetized plasmas, 1036
ohmic dissipation, 945, 949–950, 953, 957, 966, 987–988
Olber’s paradox, 138–139
Onsager relation, 1018
optical cavity
paraxial (ray) optics of, 380–381, 381f
modes of, 491b–492b
optical depth, 1395
Subject Index
1499

optical ﬁber
light rays in, 374
Gaussian beams in, 447, 448
image distortions in, 534, 534f
geometric phase in, 406–409
four-wave mixing in, 562–564
solitons in, 564
optical frequency comb, 310n, 498–501, 512, 520–521
optical Kerr effect, 562–564
optimal ﬁltering, 318–320
ordinary waves
in nonlinear crystals, 546–548, 551
in a cold, magnetized plasma, 1057–1058, 1060, 1063,
1064f
orthogonal transformation, 20–21
p modes of sun, 849–850
pairs, electron-positron
thermal equilibrium of, 258–259, 1001
temperature-density boundary for, 259f, 999f
annihilation of, in early universe, 1384, 1385f
parallel transport
for polarization vector in geometric optics, 406–409
for 4–vectors in curved or ﬂat spacetime, 1169
parametric ampliﬁcation, 555–558, 1140–1142
parametric instability, 1140–1141
paraxial Fourier optics, 436–451
point spread functions for, 438–439
image processing using. See image processing
paraxial ray optics, 375–384. See also catastrophe theory,
caustics
ray equation, 376
transfer matrices, 377–378
for optical elements: straight section, thin lens,
spherical mirror, 378
conjugate planes, 378
applications
thin lens, 378, 379f
microscope, 380, 380f
refracting telescope, 379f, 379–380
optical cavity, 380–381, 381f
magnetic lenses, 381–383
Parseval’s theorem, 300, 303, 478, 811, 1116–1117
particle conservation law
Newtonian, 28
relativistic, 80
in plasma, 1071
particle density. See number density
particle kinetics
in Euclidean space
geometric form, 13–15
in index notation, 19–20
in ﬂat spacetime
geometric form, 49–52, 1154–1156, 1178b
in index notation, 57–62
in Newtonian phase space, 97–99
partition function, in statistical mechanics. See also
fundamental thermodynamic potentials, physical-
free-energy potential
as log of physical free energy, 239
Pascal, unit of stress, 578
path integrals in quantum mechanics, 371–372, 438n
path of particle (Newtonian analog of world line), 9–10
paths, for visualizing ﬂuid ﬂows, 699b
P´eclet number, 921
Penning trap, 1031–1032
Penrose process for black holes, 1283–1285
Penrose stability criterion for electrostatic waves, 1097
perfect ﬂuid (ideal ﬂuid), 30, 675, 675n
Euler equation for, 33, 697
stress tensor for, 30–31, 32
perfect gas. See gas, perfect
perfect MHD, 950
perihelion and periastron advances due to general relativity,
1302–1304
perturbations in expanding universe
origin of, 1437
initial spectrum of, 1410–1412
evolution of, 1401–1422
phase conjugation of an optical wave, 531–535
and time reversal, 535
in holographic secondary image, 527
used to remove wave-front distortions, 532–535, 533f,
534f
produced by phase-conjugating mirror, 532
implemented via four-wave mixing in a nonlinear
medium, 559–562
phase margin, for stability of control system, 1098
phase matching, in nonlinear optics, 543, 548–549
phase mixing in statistical mechanics, 184, 184f, 210–211
phase of a wave. See under geometric optics
phase space
Newtonian, 98–99
relativistic, 101–105
in statistical mechanics, 161–163
phase transitions, 251
governed by Gibbs potential, 251–254
ﬁrst-order, 252
Clausius-Clapeyron equation for, 254–255
second-order, 253
speciﬁc heat discontinuity in, 200, 254
triple point, 254–255, 255f
speciﬁc examples
water-ice, 251–252, 254–255
1500
Subject Index

water vapor–water, 255
van der Waals gas, 266–268
crystal structure change, 253–254
Bose-Einstein condensation, 196–197, 197f, 254
ferromagnetism, 272–282. See also Ising model for
ferromagnetic phase transition
phase velocity, 352
phonons
modes for, 175, 175n
for modes of an elastic solid, mathematical theory of,
667–670
momentum and energy of, 363
speciﬁc heat of in an isotropic solid, 131–132
photography, 522, 522f
photon, gravitational ﬁeld of in linearized theory, 1231
physical laws
frameworks and arenas for, 1–3
geometric formulation of. See geometric principle;
principle of relativity
piezoelectric ﬁelds, 586
pipe
stressed, elastostatics of, 619–621
ﬂuid ﬂow in, 716–717, 766, 787
pitch angle, 1028
Pitot tube, 700, 701f
Planck energy, 580, 1438
Planck length, 579, 580, 1287, 1438, 1439
Planck satellite, 1365f
Planck time, 209, 1438, 1439
Planck units, 1438
planets. See also Earth; Jupiter
Mercury, perihelion advance of, 1302–1304
plasma electromagnetic waves
validity of ﬂuid approximation for, 1020, 1392
in unmagnetized plasma, 1042–1044, 1050
in magnetized plasma, parallel to magnetic ﬁeld: left and
right modes, 1052–1066
plasma frequency, 1005, 1002t, 1041
plasma oscillations
elementary analysis of, 1005
in two-ﬂuid formalism, 1041–1042
in moving reference frame, 1065
two-stream instability for, 1065–1067
plasma waves
in an unmagnetized, cold plasma, 1040–1044. See also
plasma electromagnetic waves; plasma oscillations
in a magnetized, cold plasma, 1050–1065. See also
Alfv´en waves; ordinary waves; extraordinary waves;
magnetosonic waves; plasma oscillations; whistler
wave in plasma
in an unmagnetized, warm plasma, 1044–1050. See also
ion-acoustic waves; Langmuir waves
plasmas. See also magnetohydrodynamics; plasma waves;
plasmons
summary in density-temperature plane, 999
summary of parameter values for, 1002t
electron correlations (antibunching) in, 1106
electron-positron pair production in, 1001
ionization of, 999–1000
degeneracy of, 1000, 1002
examples of, 999f, 1001–1002, 1002t
relativistic, 1000
plasmons. See also ion-acoustic waves; Langmuir waves;
quasilinear theory in plasma physics
mean occupation number for, 1124
master equation for evolution of, 1126
fundamental emission rates, 1127, 1133–1134
interaction with electrons, 1124–1131
nonlinear interaction with each other, 1132–1135
plate, bent. See bent plate, elastosatics of
Pockels cell, 497n, 539
point spread functions for paraxial Fourier optics, 438–
439
pointillist paintings, 427
Poiseuille ﬂow (conﬁned laminar, viscous ﬂow)
between two plates, 718–719
with MHD magnetic ﬁeld, 965–969
down a pipe, 717, 922
Poiseuille’s law, for laminar ﬂuid ﬂow in a pipe, 717
Poisson distribution, 264, 505
Poisson’s equation, 686, 705, 1003, 1078
Poisson’s ratio, 591–592, 586t
polarization of charge distribution
in a linear dielectric medium, 1036
in a nonlinear dielectric medium, 536
dielectric tensor, 537
energy density, 538
nonlinear susceptibilities, 536–540. See also
susceptibilities, dielectric; nonlinear crystals
in a plasma, 1035–1036
polarization of electromagnetic waves
for CMB radiation, 1415–1416, 1417, 1419f, 1420–1421,
1428, 1439
Stokes parameters for, 1420–1421
polarization vector in geometric optics, 405–409
polarization of gravitational waves, 1312–1313, 1316–1317
polytrope, 687–689
population inversion, 516
creation of by pumping, 517 517f
and lasing, 513, 518–519
post-Newtonian approximation to general relativity, 1303,
1310, 1341
potential ﬂow (irrotational ﬂow), 701
Prandtl number, 920, 921t
Subject Index
1501

pressure, 30
as component of stress tensor, 30–31
as component of stress-energy tensor, 85
as integral over distribution function, 121, 126
pressure ratio β in MHD, 959
pressure self-adjustment in ﬂuid dynamics, 742
primordial nucleosynthesis, 192–193, 1387–1392
principle of relativity, 42, 1154, 1158–1159
in presence of gravity, 1196
probability distributions, 286–288
conditional, 287
projection tensors
into Lorentz frame’s 3-space, 61
for TT-gauge gravitational waves, 1314b
proper reference frame of accelerated, rotating observer,
1180–1186, 1181f
metric in, 1183
geodesic equation in, 1185
for observer at rest inside a spherical, relativistic star,
1253–1254
proper time, 49, 1154
proportionality limit, in elasticity, 580, 581f
PSR B1913+16 binary pulsar, 502, 1310. See also binary
pulsars
pulsar. See also binary pulsars; neutron stars
radio waves from, 1060–1061
timing arrays for gravitational wave detection, 1355–
1357
quadratic degree of freedom, 177
quantum state
single-particle (mode), 174–175
for Bose-Einstein condensate, 194–195
many-particle, 175
distribution function for, 175
quantum statistical mechanics, 165b–166b
quasars, 193, 309, 396, 403, 404f, 433, 482, 969, 995, 1233,
1288, 1305, 1379, 1380, 1397, 1430
quasilinear theory in plasma physics. See also ion-acoustic
waves; Langmuir waves
in classical language, 1113–1123
in three dimensions, 1122–1123
in quantum language, 1123–1135
quintessence, 1446
radiation, equation of state for thermalized, 128–129, 132
radiation reaction, gravitational: predictions and
observations
predictions of, 1333, 1335
measurements of, in binary pulsars, 1310
measurements of, in binary black holes, by LIGO, 1311
radiation reaction, theory of
slow-motion approximation, 871
matched asymptotic expansion, 871
radiation-reaction potential, 871, 1333, 1335
damping and energy conservation, 872, 873, 1335
runaway solutions, their origin and invalidity, 872–873
examples
electromagnetic waves from accelerated, charged
particle, 873
sound waves from oscillating ball, 869–874
gravitational waves from any slow-motion, gravitating
system, 1333, 1335
radiative processes. See also under chemical reactions
in statistical equilibrium, 115–116
bremsstrahlung, 142, 260, 1009, 1017
Thomson scattering, 142–144, 937, 1407–1408, 1415,
1416n, 1418, 1428
Compton scattering, 1388, 1392–1393, 1428–1430
Raman scattering, 1140
Rayleigh scattering, 471
radiative transfer, Boltzmann transport analysis of
by two-lengthscale-expansion, 145–148
by Monte Carlo methods, 1415–1418, 1428
radio waves: AM, FM, and SW, 1060
RadioAstron, 482
radius of curvature of spacetime, 1213
Raman scattering, stimulated, 1140
random process, 1-dimensional, 285
stationary, 287–288
ergodic, 288–289
Gaussian, 292–294
Markov, 289–290
Gaussian, Markov. See Markov, Gaussian random process
random process, 3-dimensional
complex, 478–479
cosmological density ﬂuctuations, 304–306
random process, 2-dimensional, 306–308
random variable, 285
random walk, 139, 140, 140n, 141, 286f, 291–292, 294–
295, 309, 310, 314–315, 320, 321, 465, 1007. See also
diffusion
random-number generator, 279n, 294, 294n
random-phase approximation, 1116–1117, 1137
rank of tensor, 11
Rankine-Hugoniot relations for a shock wave, 900
derivation from conservation laws, 898–900
physical implications of, 900–902
for polytropic equation of state, 905
for strong polytropic shock, 905
relativistic, 902–903
rarefaction wave, 895–896
1502
Subject Index

Rayleigh criterion for instability of rotating ﬂows, 784
Rayleigh number, 928
Rayleigh principle, 980. See also action principles
Rayleigh scattering, 471
Rayleigh waves at surface of a homogeneous solid, 654–657,
659, 661, 839–840, 941
Rayleigh-B´enard convection. See under convection
Rayleigh-Jeans spectrum, 482, 1430
Rayleigh-Taylor instability, 783–784
reciprocity relations for reﬂection and transmission
coefﬁcients, 485, 486–488
recombination in early universe, 1392–1396
redshift, cosmological, 1373
redshift, gravitational
in proper reference frame of accelerated observer, 1189
from surface of spherical star, to inﬁnity, 1251–1252
inﬂuence on GPS, 1301–1302
experimental tests of, 70, 1301
reference beam for holography, 525, 525f
reﬂection and transmission coefﬁcients
reciprocity relations for, 485, 486–488
for an interface between dielectric media, 489
for a locally planar optical device, 486–488
for an etalon, 484, 485, 486–488
for a Fabry-Perot interferometer, 490
modulus squared: power reﬂectivity and transmissivity,
486
refractive-index surface, 1062–1063, 1062f
reionizaton of universe, 193, 1386f, 1395f, 1397, 1418, 1431
relaxation (correlation) time, 297, 298f
renormalization group
idea of, 273
applied to 2-dimensional Ising model for ferromagnetism,
273–278
applied to the onset of chaos in the logistic equation,
831
resistance
in electrical circuit, 324
in an oscillator, 326
in Stokes ﬂuid ﬂow, 328, 753
as real part of complex impedance, 332
resonance conditions in wave-wave mixing, 542, 543–544,
1132
rest frame
momentary, 49
local, 85, 86, 366, 677, 719–720
asymptotic, 1237, 1246–1248
local asymptotic, 1327f, 1328, 1331, 1332, 1339–1340
rest mass, 34, 58–59
global and local conservation laws for, 80, 82
rest-mass density, relativistic, 81
rest-mass-ﬂux 4–vector
geometric deﬁnition of, 80
components: rest-mass density and ﬂux, 81
Reynolds number, 716, 726b
as ratio of inertial to viscous acceleration, 746
magnetic, 950, 987
Reynolds stress for turbulence, 802
and turbulent viscosity, 804
Ricci (curvature) tensor, 1214–1215
Richardson criterion for instability of shear ﬂows, 785–786
Richardson number, 785–786
Riemann curvature tensor
deﬁnition, 1209
symmetries of, 1214
components of
in an arbitrary basis, 1215–1216
in local Lorentz frame, 1214
Bianchi identity for, 1223
decomposition into tidal and frame-drag ﬁelds, in
vacuum, 1235b–1236b
components in speciﬁc spacetimes or spaces
surface of a sphere, 1216
general linearized metric, 1227
Schwarzschild metric, 1244b, 1267
Newtonian limit of, 1227
magnitude of, 1213
outside Newtonian, gravitating body, 1212–1213
Riemann invariants, 852, 891–897, 901–902
right modes, for plasma electromagnetic waves parallel to
magnetic ﬁeld, 1052–1056
rigidly rotating disk, relativistic, 1189–1190
Rindler approximation, 1273–1274
Rindler coordinates
in ﬂat spacetime, 1187–1189
near black-hole horizon, 1273–1274
Robertson-Walker metric for a homogeneous, isotropic
universe, 1371
coordinates for, 1370
derivation of, 1366–1372
Einstein tensor for, 1371–1372
perturbations of, and their evolution, 1401–1422
rocket engines, ﬂuid ﬂow through, 887–890
rod. See bent beam, elastostatics of
Rossby number, 768
Rossby waves in rotating ﬂuid, 858–861
rotating disk, relativistic, 1189–1190
rotating reference frame, ﬂuid dynamics in, 766–777
rotation, rate of, in ﬂuid mechanics, 711, 726b
as vorticity in disguise, 711
rotation group, 21, 572b–574b
rotation matrix, 21, 65
Subject Index
1503

rotation tensor and vector, in elasticity theory, 571,
573b–574b, 575–576, 577
rupture point, in elasticity, 580, 581f
Rutherford scattering, 1006–1007
Sackur-Tetrode equation for entropy of a perfect gas, 189
Sagnac interferometer, 501–502, 502f
Saha equation for ionization equilibrium, 259–260, 999–1000
Saint-Venant’s principle, for elastostatic equilibrium, 590b
salt ﬁngers due to double diffusion of salt and heat, 937–940
sausage instability, of magnetostatic equilibria, 977
scale factor, in cosmology, 1370
as a function of time, 1387, 1388f, 1390f, 1399f, 1400f
scaling relations in ﬂuid ﬂows
between similar ﬂows, 791–792
for drag force on an object, 765
for Kolmogorov turbulence spectrum, 789, 810–814
scaling relations near a catastrophe (caustic), 392
scattering of light. See also under radiative processes
by large, opaque particle, 429
in LIGO, 448–451
Schr¨odinger equation
energy eigenstates (modes) of, 175n, 194–195, 848–849
and Coulomb wave functions, 1009
propagation speed of waves, 44b
geometric optics for, 375, 409
nonlinear variant of, and solitons, 856–857
Schwarzschild criterion for onset of convection in a star, 935,
935f
Schwarzschild metric, 1242. See also black holes; horizon,
black-hole event; stars; wormhole
uniqueness of: Birchoff’s theorem, 1250
in Schwarzschild coordinates, 1242
bases, connection coefﬁcients, and Riemann tensor,
1243b–1244b
Schwarzschild coordinate system and symmetries,
1244–1249
in isotropic coordinate system, 1251
in ingoing Eddington-Finkelstein coordinates, 1269
gravitational (horizon) radius of, 1250
Rindler approximation near horizon, 1273–1274
geodesic orbits in, 1247–1248, 1274–1276
Newtonian limit of, 1246
roles of
exterior metric of static star, 1250–1252
exterior metric of imploding star, 1264–1266, 1269
metric of nonspinning black hole, 1272–1276
metric of wormhole, 1276–1277
second quantization, 175
secondary ﬂuid ﬂows, 775–776
sedimentation, 749, 754–755
Sedov-Taylor blast wave, 909–912
seeing, atmospheric, 425, 465, 466b–471b, 471–472
seismic waves. See elastodynamic waves in Earth
self-gravity, in ﬂuid dynamics, 705b–706b, 709
self-similar ﬂows
boundary layer near ﬂat plate: Blasius proﬁle, 758–763
Sedov-Taylor blast wave, 909–912
underwater blast wave, 914–915
ﬂow in shock tube, 916
stellar wind, 915–916
water ﬂow when dam breaks, 857–858
separation of variables for Navier-Cauchy equation, 590b,
624–625
Shapiro time delay, 1009, 1308–1309
shear, rate of, 711, 726b
shear modulus, for elasticity, 581, 586t, 651t
shear tensor, in elasticity theory, 571, 572b–574b, 574–577
stretch and squeeze along principal axes, 574–575, 575f
shock fronts. See shock waves in various media
shock tube, ﬂuid ﬂow in
analyzed using similarity methods, 916
analyzed using Riemann invariants, 895–896
shock front in, 906
shock waves (shock fronts) in a ﬂuid, adiabatic
terminology for, 898, 900f
inevitability of, 897
Rankine-Hugoniot relations for, 900. See also Rankine-
Hugoniot relations for a shock wave
shock adiabat, 900–901, 901f
properties of, 900–901
internal structure of, 898, 906–907
role of viscosity in, 898
patterns of
around a supersonic aircraft, 876f
bow shock in solar wind around Earth, 876f, 957,
1146–1147, 1146f
Mach cone, 907–908, 907f
Sedov-Taylor blast wave, 909–912
sonic boom, 908, 908f
acceleration of cosmic rays in, 1145–1148
shock waves in an elastic medium, 663–664
shock waves in a plasma, collisionless, 907, 1145–1147, 1146f
shot noise, 321–323, 504–505, 506–509, 557
signal-to-noise ratio
for band-pass ﬁlter, 317
for Wiener’s optimal ﬁlter, 319–320
similarity methods in ﬂuid mechanics. See self-similar ﬂows
simultaneity in relativity
breakdown of, 66
slices of, 58, 73, 73f, 1181f, 1293–1294, 1293f, 1297
single-particle quantum states (modes), 174–175, 194–195
1504
Subject Index

singularity, spacetime
at center of Schwarzschild black hole, 1271–1272, 1273f
generic, inside all black holes, 1273, 1282n
for Schwarzschild wormhole, 1277
SLAC National Accelerator Laboratory, 521
slot-naming index notation, 19–20, 23, 25, 56–57, 70, 1156
smoke rings, 744f
Smoluchowski equation, 290
applications of, 291–292, 337
soap ﬁlm, shapes of, 846
solar dynamo, 985–986
solar furnace, 138–139
solar wind, 875, 876f, 970–971, 988, 999f, 1001, 1002t
two-stream instability in, 1066–1077
collisionless shocks in, 907, 1146
bow shock at interface with Earth, 876f, 957, 1090,
1146–1147, 1146f
termination shock with interstellar medium, 1146–1147
solid-body normal modes. See normal modes, of elastic
bodies
solitons
balance of nonlinearity against dispersion in, 853–854
equations exhibiting, 856–857
Korteweg–de Vries equation and solutions, 852–856,
858
venues for, 856–857
in optical ﬁber, 564
in ion-acoustic waves in plasma, 1142–1146
in nonlinear gravity waves on water, 852–856, 858
sonic boom, 889b, 907–908
sound speed in elastic solid, CL, 586t, 638
sound waves in a ﬂuid
wave equation, 862
sound speed, 862
analysis of, 862–865
dispersion relation, 353
phase velocity and group velocity, 355
energy density, 864
energy ﬂux, 865
in inhomogeneous ﬂuid: example of prototypical wave
equation, 863
generation of, 865–869
radiation reaction on source, 869–874
attenuation of, 868
nonlinearity of, and shock formation, 894
propagating in a horizontal wind with shear, 366
quanta: phonons, 363. See also phonons
space shuttle, 889b–890b
sonic boom from, 889b, 907–908
space telescope. See Hubble Space Telescope; James Webb
Space Telescope
spacetime diagram, 40–41
for Lorentz boost, 65–67, 65f
spacetime metrics for speciﬁc systems
for a spherical star, 1250, 1253, 1258–1260. See also stars,
spherical in general relativity
for a moving particle, linearized, 1230–1231
for a photon: Aichelberg-Sexl ultraboost metric, 1231
for exterior of any weak-gravity stationary system,
1231–1234, 1236
conservation of mass and angular momentum:
inﬂuence on, 1237–1238
reading off source’s mass and angular momentum from
exterior metric, 1232–1233
for exterior of any asymptotically ﬂat, strong-gravity,
stationary system, 1238
for gravitational waves in ﬂat spacetime, 1311–1314
Schwarzschild metric for a spherical star, black hole, or
wormhole, 1242. See also Schwarzschild metric
Robertson-Walker metric for a homogeneous, isotropic
universe, 1371, 1366–1372. See also Robertson-
Walker metric for a homogeneous, isotropic
universe
Bertotti-Robinson metric, for a homogeneous magnetic
universe, 1249
speciﬁc heats, Cp, cp, CV , and cV , 244, 678. See also adiabatic
index
for ideal gas with internal degrees of freedom, 879–880
for nonrelativistic, degenerate electrons, 130–131
for phonons in an isotropic solid, 131–132
speciﬁc intensity (spectral intensity) of radiation, 107,
107f
speckle image processing, 470b, 472
speckles, in light images, 466bf, 469b–470b
spectral density
for a 1-dimensional random process, 299–300
as mean of square of Fourier transform, 303, 304
double-sided vs single-sided, 300
for sum of two random processes, 308
integral of is variance, 300
physical meaning of, 301–302
rms oscillations in terms of, 301
for a 2-dimensional random process, 307–308
cross spectral density, 307
for a 3-dimensional random process,
cosmological density ﬂuctuations (galaxy distribution),
304–306, 306f
Wiener-Khintchine theorem for. See Wiener-Khintchine
theorem
inﬂuence of ﬁltering on, 312. See also ﬁltering of random
process
types of spectral densities. See under noise
Subject Index
1505

spectral density (continued)
applications of
Brownian motion, 314
light, 301
LIGO gravitational wave detector, 302
noise, 308–311, 321–323, 334. See also noise
cosmological density ﬂuctuations, 304–306
spectral energy density Ek, in quasilinear theory of plasma
waves, 1117
spectral energy ﬂux (or spectrum), Fω, 473, 473n
spectral intensity, Iν or Iω. See speciﬁc intensity
spectrometer, Fabry-Perot cavity as, 496
spectroscopy, Fourier-transform using Michelson
interferometer, 474–476
spectrum (spectral energy ﬂux), 473, 473n
spectrum of light related to spectral density, 301
speed of light
constancy of, 34, 42, 1159
measuring without light, 43b
in geometrized units, 34
contrasted with speeds of other waves, 44b
spherical coordinates
related to Cartesian coordinates, 614
orthonormal bases and connection coefﬁcients, 614, 616
expansion and shear tensor in, 617, 618b
spherical triangle, 1372
spheromak, 964
sports, physics of, 823–825
spy satellite, 436
squeezed vacuum and squeezed states of light, 556–558, 558f
stagnation pressure, 700, 792
standard cosmology, 1383
Star Wars (Strategic Defense Initiative), 521
stars. See also neutron stars
formation of ﬁrst stars in early universe, 1397
observed properties of, 1379
diffusive heat conduction in, 142–148
spherical, in general relativity, 1250–1263
equations of stellar structure, 1258–1259
interior metric, 1253, 1258–1259
exterior spacetime metric: Schwarzschild, 1250
embedding diagram for, 1262–1263, 1263f
star with constant density, full structure, 1260
implosion to form black holes, 1264–1272
in Schwarzschild coordinates, 1264–1267, 1270–1271
in ingoing Eddington-Finkelstein coordinates,
1267–1271
statistical equilibrium, 168–178
ensembles in, 168–177. See also speciﬁc ensembles
general, 172–173
tables summarizing, 160t, 221t
ﬂuctuations away from, 260–270
for ensemble of closed systems, 260–261
for particle distribution in a closed box, 262–263
for particle number in an open box, 263–264
for temperature and volume of an ideal gas, 264–265
for van der Waals gas: volume ﬂuctuations, 266–268
for volume of a thermally isolated gas (constant-
pressure balloon), 265–266
statistical equilibrium for fundamental particles
for identical bosons, Bose-Einstein distribution, 112–113
for identical fermions, Fermi-Dirac distribution, 112
for identical classical particles, Boltzmann distribution,
113
statistical independence, 170
steady ﬂuid ﬂow, 726b
stellar dynamics. See also under galaxies
statistical mechanics of galaxies and star clusters, 201–204
Jeans’ theorem in, 1076–1077
evolution of cluster due to ejection of stars, 203–204
equilibration time for stars in cluster, 1012–1013
violent relaxation of star clusters, 113n
stochastic differential equations, 325
Stokes ﬂow, 749–754, 749f, 766
drag force in: Stokes’ law, 753
Stokes parameters for polarization of radiation, 1420–1421
Stokes’ paradox for ﬂuid ﬂow past a cylinder, 754
Stokes’ theorem for integrals, 27
storms, ﬂuid dynamics of, 768, 769b, 842
strain tensor, in elasticity theory, 576
strange attractors, 833–834
Strategic Defense Initiative, 521
stratosphere, 683, 684f, 731, 748, 755, 784–786
streaks, for visualizing ﬂuid ﬂows, 699b
stream function for 2-dimensional incompressible ﬂow
in Cartesian coordinates, 759
in any orthogonal coordinate system, 760b–761b, 766
stream tube, in ﬂuid dynamics, 699–700, 700f, 721–722, 721f
streamlines, for visualizing ﬂuid ﬂows, 698, 699f
stress polishing mirrors, 609–611, 611f, 613
stress tensor
geometric deﬁnition of, 29, 577
components, meaning of, 30
symmetry of, 30
as integral over distribution function, 118
as spatial part of relativistic stress-energy tensor, 83
for speciﬁc entities
electromagnetic ﬁeld, 33
perfect ﬂuid, 30–31, 32, 696
strained elastic solid, 581, 584
strained and heated elastic solid, 584
magnitudes of, 578–580
1506
Subject Index

stress-energy tensor
geometric deﬁnition of, 82, 1176
constructed from Lagrangian, 1434
components of, 82–83, 120, 1176
symmetry of, 83–84
as integral over distribution function, 118, 120
and 4-momentum conservation, 84–85, 1176–1177
for electromagnetic ﬁeld
in terms of electromagnetic ﬁeld tensor, 86
in terms of electric and magnetic ﬁelds, 88
in terms of vector potential, 1434
for perfect ﬂuid, 85, 720, 1177
nonrelativistic limit, 723–724
for point particle, 1178b, 1179
for viscous, heat-conducting ﬂuid, 1179–1180
structure function, for ﬂuctuations, 467b, 815
Sturm-Liouville equation and theory, 974–975, 980–981
subensemble, 170
sun. See also solar dynamo; solar wind
core of, 933f, 937, 999f, 1001, 1002t
convection zone, 933f, 936
disturbances on surface, 1035, 1065
normal modes of, 848–850. See also normal modes
Sunyaev-Zel’dovich effect, 1428–1430
superﬂuid, rotating, 733–734
supernovae
neutron stars produced in, 111, 914
as gravitational-wave sources, 111
Sedov-Taylor blast wave from, 914–915
observations of reveal acceleration of the universe, 1398,
1400
supersymmetry, 1441
surface tension, 844b–845b
force balance at interface between two ﬂuids, 846
surﬁng of electrons and protons on electrostatic waves, 1046,
1069–1070, 1098–1099. See also Landau damping
susceptibilities, dielectric
linear, 536–537, 1036
nonlinear, 536–540
isotropic, 538, 538n, 539–540
magnitudes of, 539
swimming mechanisms, 744, 747b–748b, 756–757
symmetries and conservation laws, 1203–1205
system, in statistical mechanics
deﬁned, 157
closed, 158–159
semiclosed, 157–158
tangent space, 9, 1160, 1165–1169, 1166f, 1175, 1218, 1253
tangent vector, 9, 49, 1155, 1155f, 1165–1166
as directional derivative, 1167
Taylor rolls, in rotating Couette ﬂow, 826, 826f
Taylor-Proudman theorem for geostrophic ﬂow, 771
tea cup: circulating ﬂow and Ekman boundary layer, 776–
777
telescopes, optical. See also adaptive optics; astronomical
seeing; Gran Telescopio Canarias; Hubble Space
Telescope; James Webb Space Telescope; Keck
telescopes
simple refracting, and light rays, 379f, 379–380
angular resolution of, 425–427
aberrations in, 395
telescopes, radio, 479–483
angular resolution of, 479, 480, 482
temperature
deﬁnition, 168, 168n, 171
measured by idealized thermometer, 223–224
temperature diffusion equation, 142, 920
tensor in Euclidean space
deﬁnition and rank, 11
algebra of without coordinates or bases, 11–13
expanded in basis, 16
component representation, 17–19
tensor in quantum theory, 18b
tensor in spacetime. See also component manipulation rules;
speciﬁc tensors
deﬁnition and rank, 48
bases for, 55
components of, 54–57
contravariant, covariant, and mixed components, 55,
1157–1158, 1161–1162
raising and lowering indices, 55, 1164
algebra of
without coordinates or bases, 48, 61–62
component representation in orthonormal basis,
54–57, 1157–1158
component representation in arbitrary basis, 1162–
1165
tensor product, 12, 48
thermal diffusivity, 920, 921t
thermal equilibrium. See statistical equilibrium
thermal noise. See under noise
thermal plume, 933
thermodynamics. See also equations of state; Euler’s equation;
fundamental thermodynamic potentials; Maxwell
relations, thermodynamic
representations of, summarized, 221t, 228
Legendre transformation between representations,
230–232, 240, 244, 247
energy representation, and microcanonical ensemble,
221–229
enthalpy representation, 244–246
Subject Index
1507

thermodynamics (continued)
grand-potential representation and grand canonical
ensemble, 229–239
physical-free-energy representation, and canonical
ensemble, 239–244
Gibbs representation and Gibbs ensemble, 246–260
ﬁrst law of, 225
in all representations, 221t
as mnemonic for deducing other relations, 227–228
for ﬂuid, in ﬂuid dynamics, 679b–680b
for black hole, 205
second law of, 182
underlying physics of: coarse graining and discarding
correlations, 183–185, 184f, 186b–187b
underlying quantum physics of: discarding correlations
(quantum decoherence), 185, 186b–187b, 190–191
in theory of information: when information is erased,
217–218
of black holes, 204–209, 1286–1287
thermoelastic noise in mirrors, 623, 626
thermoelasticity, 584–585
thermoelectric transport coefﬁcients, 1017–1018
Thomson scattering of photons by electrons, 142–144, 937,
1407–1408, 1415, 1416n, 1418, 1428
three-point correlation function, 1105
three-wave mixing in nonlinear crystals, 540–558
polarization for, 540, 542
evolution equations
for birefringent crystal, 546–552
for medium that is linearly dispersion-free and
isotropic, 544–546
phase matching for, 543, 548–549
applications of
frequency doubling, 545–546, 553–555
optical parametric ampliﬁcation, 555–557
degenerate optical parametric ampliﬁcation, 556–558
squeezing, 556–558, 558f
three-wave mixing in plasmas
driving term for, in Vlasov equation, 1114
quasilinear theory of, 1132–1135
tidal gravitational ﬁeld
Newtonian, 1207–1208
relativistic, 1211–1212, 1235b–1236b
tidal gravity
Newtonian description, 1207–1208
relativistic description, 1208–1210
comparison of Newtonian and relativistic descriptions,
1210–1212, 1227
tidal tendex lines, 1235b–1236b
around a linearized, spinning particle, 1236b
around Kerr black hole, 1295b–1296b
around colliding black holes, 1344b–1345b
in a gravitational wave, 1318b, 1345b
time. See also clocks, ideal; simultaneity in relativity, slices of
coordinate, of inertial frame, 39–40
proper, 49
imaginary, 54
in cosmology, 1370
in general relativity: many-ﬁngered nature of, 1293–1294,
1297
time and frequency standards, 310f, 310n
time derivative
advective (convective), 32, 692, 724b, 892
ﬂuid, 736
with respect to proper time, 49, 52
time dilation, 66
observations of, 70
time travel, 67–70
tokamak, 963
MHD stability of, 979
Tollmien-Schlichting waves, 823
tomography, seismic, 663
topological defects, 1432n
tornado, 738, 739f
pressure differential in, 702, 738
torsion pendulum, elastostatics of, 621–622
TOV equation of hydrostatic equilibrium, 1258,
1260
trace-reversed metric perturbation, 1228, 1311
transformation matrices, between bases, 1164
orthogonal, 20–21
Lorentz, 63–65, 65f, 1158
transport coefﬁcients, 139. See also conductivity, electrical;
conductivity, thermal; diffusion coefﬁcient; viscosity
in plasmas, 1015–1018
thermoelectric, 1017–1018
triple point for phase transitions, 254–255, 255f
trumpet, sound generation by, 868
tsunamis, 841b, 843, 922
TT gauge, 1312–1315
turbulence, 787–834
weak and strong, 800
characteristics of
3-dimensional, 794
disorder, 798
irregularly distributed vorticity, 799
wide range of interacting scales, 798–799
eddies, 798–800, 802, 804–807, 811–814
efﬁcient mixing and transport, 799
large dissipation, 799
intermittency, 798–799, 807, 814, 831
onset of. See turbulence, onset of
1508
Subject Index

vorticity in, 799–800
drives energy from large scales to small, 799f
semiquantitative analysis of, 800–817
Kolmogorov spectrum, 467, 810–813, 813f, 815. See
also Kolmogorov spectrum for turbulence
weak turbulence formalism, 800–810. See also weak
turbulence formalism
generation of sound by, 869
turbulence, 2-dimensional analog of, 801b
inverse cascade of energy, 799n
transition to (3-dimensional) turbulence, 800
turbulence, onset of. See also chaos, onset of in dynamical
systems
critical Reynolds number for, 787, 794, 822, 826
in convection, 830, 831
in ﬂow past a cylinder, 789–794, 800
in rotating Couette ﬂow, 825–828
routes to turbulence
one frequency, two frequencies, turbulence, 825–828
one frequency, two frequencies, phase locking,
turbulence, 831
one frequency, two frequencies, three frequencies,
turbulence, 831
period doubling sequence, 830–831
intermittency, 831
twins paradox, 67–70
two-ﬂuid formalism, for plasma physics, 1037–1068
fundamental equations, 1037–1038
deduced from kinetic theory, 1073–1074
two-lengthscale expansion, 146b
bookkeeping parameter for, 360b
and statistical independence in statistical mechanics,
170n
for solving Boltzmann transport equation, 145
for geometric optics, 357–358, 359–360
for quasi-linear theory in plasma physics, 1113–1114
for gravitational waves in curved spacetime, 1320–1321,
1321f
two-point correlation function, 305, 1104–1107, 1424–1426
for Coulomb corrections to pressure in a plasma,
1107–1108
for electron antibunching in a plasma, 1104–1107
for galaxy clustering, 305, 306f
for weak gravitational lensing, 1424–1426
two-stream instability
in two-ﬂuid formalism, 1065–1068
in kinetic theory, 1079–1080, 1137
ultrasound, 663–664
universe, evolution of
expansion, kinematics of, 1373–1376
evolution of radiation and gas properties during,
1373–1375
expansion, dynamics of, 1376–1378
Friedman equations, 1376–1377
graphical summaries of
entire life: distances as functions of scale factor, 1400f
entire life: energy densities of constituents, 1386f
particle age: temperatures and entropies of particle
constituents, 1385f
nuclear age: reaction rates; nuclear and particle
abundances, 1390f
plasma and atomic ages: ionization fraction and optical
depths, 1395f
gravitational and cosmological ages: scale factor and
deceleration function, 1399f
perturbations, evolution of, 1404f, 1405f, 1411f, 1414f
formation of structure
origin of primordial perturbations, 1437–1440
perturbations, initial spectrum, 1410–1412
evolution of perturbations, 1401–1422
statistical mechanics of, 210–211
seven ages
before the particle age, 1431–1440
particle age, before nucleosynthesis, 1384–1387
nuclear age, primordial nucleosynthesis, 192–193,
1387–1392
photon age, from nucleosynthesis to matter dominance,
1392–1393
plasma age, from matter dominance through
recombination, 1393–1396
atomic age, from recombination through reionization,
193, 1394
gravitational age, from reionization to dark-energy
inﬂuence, 1394–1400
cosmological age, the era of dark-energy inﬂuence,
1400–1401
galaxy formation, 210–211, 1401–1415
universe, observed properties of
isotropy and homogeneity, 1364–1366
spatial ﬂatness, 1378
parameter values today, 1380t
age of, 1387
volume of, 1398
constituents of
baryons, 1379. See also baryons in universe
neutrinos, 1382
photons: cosmic microwave background, 1381. See also
cosmic microwave background
dark matter, 1380–1381. See also dark matter
dark energy or cosmological constant, 1382–1383,
1444–1447
Subject Index
1509

universe, observed properties of (continued)
constituents of (continued)
galaxies. See galaxies
black holes, 1379–1380, 1397
acceleration of, 1382, 1398, 1400, 1444
spectral line formation, 1396
universe, statistical mechanics of, 209–211
van Allen belts, 1028, 1029f
van Cittern-Zernike theorem
for lateral coherence, 461, 463
for temporal coherence, 473
3-dimensional, 477–478
relation to Wiener-Khintchine theorem, 478–479
van der Waals gas
equation of state for, 234
grand potential for, 234
derivation of, 232–238
phase transition for, 266–268
volume ﬂuctuations in, 266–268
catastrophe theory applied to, 394–395
variance, 287
vector
as arrow, 8, 40, 1166
as derivative of a point, 9, 49, 1165
as differential operator, 1167–1169
vector in Euclidean space (3–vector): components, 16
vector in quantum theory, 18b
vector in spacetime (4–vector)
contravariant and covariant components of, 55
raising and lowering indices of, 55
timelike, null, and spacelike, 47, 1155–1156
velocity
Newtonian, in Euclidean space, 9
ordinary, in relativity, 58, 59f, 61–62. See also 4–velocity
velocity potential for irrotational ﬂow, 701
in cosmological perturbations, 1403
violent relaxation of star distributions, 210
violin string, sound generation by, 868
virial theorems
for any system obeying momentum conservation, 982–984
for self-gravitating systems, 984
MHD application, 982, 984
virtual image vs real image, 527
viscosity, bulk, coefﬁcient of, 712, 724b
viscosity, molecular origin of, 713–714
viscosity, shear, coefﬁcient of, 139, 712, 726b
dynamic, η, 713, 724b
kinematic, ν, 713, 725b
values of, for various ﬂuids, 713t, 921t
for monatomic gas, 149–150, 714
VLA (Jansky Very Large Array), 480
Vlasov equation, in plasma kinetic theory, 1071–1072
solution via Jeans’ theorem, 1075
VLBI (very long baseline interferometry), 482
volcanic explosions, 748, 755
volume in Euclidean space
2–volume (area), 26
vectorial surface area in 3-space, 27
3–volume, 27
n-volume, 24
differential volume elements, 28
volume in phase space
Newtonian, 98
relativistic, 102–104
Lorentz invariance of, 103–104, 105f
volume in spacetime, 75–77
4–volume, 75
vectorial 3–volume, 76–77, 77f
positive and negative sides and senses, 76
differential volume elements, 77
volume of coherence, 477
von Zeipel’s theorem, 702
vortex. See also vortex lines; vorticity
diffusive expansion of, 742
above a water drain, 729, 732, 777
vortex sheet, 782, 801b
vortex ring, 744
starting vortex, 824, 825b
vortex street, K´arm´an, 791f, 794
wingtip vortex, 734f, 739, 744, 744f
tornado, 702, 732, 738, 739f
vortex generated by spatula, 745–746
vortex generators, on airplane wing, 821–822, 821f
vortex cores, in superﬂuid, 733–734
vortex generator on airplane wing, 821–822, 821f
vortex lines, 734, 734f. See also frame-drag vortex lines
diffuse due to viscosity, 741–742
frozen into ﬂuid, for barotropic, inviscid ﬂows, 736–738,
737f
vortex rings, 744, 744f
vorticity, 697, 731–732, 732f
relation to angular velocity of a ﬂuid element, 697–698
measured by a vane with orthogonal ﬁns, 732
sources of, 744–746
evolution equations for, 735–738, 741
diffusion of vorticity, 741
frozen into an inviscid, barotropic ﬂow, 736–737
interaction with magnetic ﬁeld, 957–958
delta-function: constant-angular-momentum ﬂow,
732–733
Voyager spacecraft, 1147
1510
Subject Index

wakes
2-dimensional, behind cylinder
laminar, 794–795
turbulent, 805–810
3-dimensional, behind sphere
laminar, 796
turbulent, 810
water waves. See gravity waves on water; sound waves in a
ﬂuid
wave equations
prototypical, 358
lagrangian, energy density ﬂux, and adiabatic invariant
for, 365–366
algebratized, 1037
for electromagnetic waves. See electromagnetic waves
for elastodynamic waves, 635. See also elastodynamic
waves in various media
for gravitational waves, 1312, 1322. See also gravitational
waves
for sound waves, 862, 863
wave packet, 354–356
Gaussian, 356–357
spreading of (dispersion), 356–357
wave zone, 1327f
wave-normal surface, 1062–1063, 1062f, 1064f
wave-wave mixing. See also three-wave mixing in various
media; four-wave mixing in isotropic, nonlinear
media
in nonlinear dielectric media, 540–564
in plasmas, 1132–1135
waves, monochromatic in homogeneous medium. See also
sound waves in a ﬂuid; gravity waves on water;
ﬂexural waves on a beam or rod; gravitational waves;
Alfv´en waves; Rossby waves in rotating ﬂuid
dispersion relation, 353
group velocity, 355
phase velocity, 352
plane, 352
weak turbulence formalism, 800–810
Reynolds stress and turbulent viscosity, 802, 803–804
turbulent diffusion coefﬁcient, 805
turbulent thermal conductivity, 805
correlation functions in, 802–803
spatial evolution of turbulent energy, 804, 808f, 808–
809
Weyl (curvature) tensor, 1215, 1216
whistler wave in plasma, 1053f, 1054–1055, 1062f, 1146f
Wiener-Khintchine theorem
for 1-dimensional random process, 303
for 2-dimensional random process, 307–308
for complex 3-dimensional random process (van
Cittert-Zernike theorem), 478–479
Wiener’s optimal ﬁlter, 318–320
WIMPs, 1440–1441
winds
around low-pressure region, 770
drive ocean’s surface currents, 772–776, 805
in stratosphere, 784–785
lee waves in, 821n
propagation of sound waves in, 366
wingtip vortices, 734f, 739, 744, 744f
WKB approximation, as example of eikonal approximation,
358
Womersley number, 719
world line, 49, 59f, 1155f
World Trade Center buildings, collapse of, 605–607
world tube, 49n, 68f, 69
wormhole, 68–69, 68f
as time machine, 69
Schwarzschild, 1276–1277
yield point, in elasticity, 580, 581f
origin of yield: dislocations, 586, 587f
yield strains for various materials, 586t
Young’s modulus, 582, 589–592
values of, for speciﬁc materials, 586t
Young’s slits, 456–458
zero point energy, 175n, 669, 1002, 1437–1438, 1446
zone plate, 435–436
Z-pinch for plasma conﬁnement, 960–962, 961f
stability of, 975–978
Subject Index
1511

