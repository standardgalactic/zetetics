
Reliability and Risk
A Bayesian Perspective
Nozer D. Singpurwalla
The George Washington University, Washington DC, USA


Reliability and Risk

WILEY SERIES IN PROBABILITY AND STATISTICS
established by Walter A. Shewhart and Samuel S. Wilks
Editors
David J. Balding, Peter Bloomfield, Noel A.C. Cressie, Nicholas I. Fisher, Iain M. Johnstone,
J.B. Kadane, Geert Molenberghs, Louise M. Ryan, David W. Scott, Adrian F.M. Smith
Editors Emeriti
Vic Barnett, J. Stuart Hunter, David G. Kendall, Jozef L. Teugels
A complete list of the titles in this series appears at the end of this volume.

Reliability and Risk
A Bayesian Perspective
Nozer D. Singpurwalla
The George Washington University, Washington DC, USA

Copyright © 2006
John Wiley & Sons Ltd, The Atrium, Southern Gate, Chichester,
West Sussex PO19 8SQ, England
Telephone
(+44) 1243 779777
Email (for orders and customer service enquiries): cs-books@wiley.co.uk
Visit our Home Page on www.wiley.com
All Rights Reserved. No part of this publication may be reproduced, stored in a retrieval system or
transmitted in any form or by any means, electronic, mechanical, photocopying, recording, scanning or
otherwise, except under the terms of the Copyright, Designs and Patents Act 1988 or under the terms of a
licence issued by the Copyright Licensing Agency Ltd, 90 Tottenham Court Road, London W1T 4LP, UK,
without the permission in writing of the Publisher. Requests to the Publisher should be addressed to the
Permissions Department, John Wiley & Sons Ltd, The Atrium, Southern Gate, Chichester, West Sussex
PO19 8SQ, England, or emailed to permreq@wiley.co.uk, or faxed to +44 1243 770620.
Designations used by companies to distinguish their products are often claimed as trademarks. All brand names
and product names used in this book are trade names, service marks, trademarks or registered trademarks of their
respective owners. The Publisher is not associated with any product or vendor mentioned in this book.
This publication is designed to provide accurate and authoritative information in regard to the subject matter
covered. It is sold on the understanding that the Publisher is not engaged in rendering professional services.
If professional advice or other expert assistance is required, the services of a competent professional
should be sought.
Other Wiley Editorial Offices
John Wiley & Sons Inc., 111 River Street, Hoboken, NJ 07030, USA
Jossey-Bass, 989 Market Street, San Francisco, CA 94103-1741, USA
Wiley-VCH Verlag GmbH, Boschstr. 12, D-69469 Weinheim, Germany
John Wiley & Sons Australia Ltd, 42 McDougall Street, Milton, Queensland 4064, Australia
John Wiley & Sons (Asia) Pte Ltd, 2 Clementi Loop #02-01, Jin Xing Distripark, Singapore 129809
John Wiley & Sons Canada Ltd, 22 Worcester Road, Etobicoke, Ontario, Canada M9W 1L1
Wiley also publishes its books in a variety of electronic formats. Some content that appears in print may not be
available in electronic books.
British Library Cataloguing in Publication Data
A catalogue record for this book is available from the British Library
ISBN-13 978-0-470-85502-7 (HB)
ISBN-10 0-470-85502-9 (HB)
Typeset in 9.5/11.5pt Times by Integra Software Services Pvt. Ltd, Pondicherry, India
Printed and bound in Great Britain by Antony Rowe Ltd, Chippenham, Wiltshire
This book is printed on acid-free paper responsibly manufactured from sustainable forestry
in which at least two trees are planted for each one used for paper production.

There are
NO FACTS
only
INTERPRETATIONS
Friedrich Nietzsche
German Philosopher
(1844–1900)


Contents
Preface
xiii
Acknowledgements
xv
1
Introduction and Overview
1
1.1
Preamble: What do ‘Reliability’, ‘Risk’ and ‘Robustness’ Mean?
1
1.2
Objectives and Prospective Readership
3
1.3
Reliability, Risk and Survival: State-of-the-Art
3
1.4
Risk Management: A Motivation for Risk Analysis
4
1.5
Books on Reliability, Risk and Survival Analysis
6
1.6
Overview of the Book
7
2
The Quantification of Uncertainty
9
2.1
Uncertain Quantities and Uncertain Events: Their Definition and Codification
9
2.2
Probability: A Satisfactory Way to Quantify Uncertainty
10
2.2.1
The Rules of Probability
11
2.2.2
Justifying the Rules of Probability
12
2.3
Overview of the Different Interpretations of Probability
13
2.3.1
A Brief History of Probability
14
2.3.2
The Different Kinds of Probability
16
2.4
Extending the Rules of Probability: Law of Total Probability and Bayes’ Law
19
2.4.1
Marginalization
20
2.4.2
The Law of Total Probability
20
2.4.3
Bayes’ Law: The Incorporation of Evidence and the Likelihood
20
2.5
The Bayesian Paradigm: A Prescription for Reliability, Risk and Survival
Analysis
22
2.6
Probability Models, Parameters, Inference and Prediction
23
2.6.1
The Genesis of Probability Models and Their Parameters
24
2.6.2
Statistical Inference and Probabilistic Prediction
26
2.7
Testing Hypotheses: Posterior Odds and Bayes Factors
27
2.7.1
Bayes Factors: Weight of Evidence and Change in Odds
28
2.7.2
Uses of the Bayes Factor
30
2.7.3
Alternatives to Bayes Factors
31

viii
CONTENTS
2.8
Utility as Probability and Maximization of Expected Utility
32
2.8.1
Utility as a Probability
32
2.8.2
Maximization of Expected Utility
33
2.8.3
Attitudes to Risk: The Utility of Money
33
2.9
Decision Trees and Influence Diagrams for Risk Analysis
34
2.9.1
The Decision Tree
34
2.9.2
The Influence Diagram
35
3
Exchangeability and Indifference
45
3.1
Introduction to Exchangeability: de Finetti’s Theorem
45
3.1.1
Motivation for the Judgment of Exchangeability
46
3.1.2
Relationship between Independence and Exchangeability
46
3.1.3
de Finetti’s Representation Theorem for Zero-one Exchangeable
Sequences
48
3.1.4
Exchangeable Sequences and the Law of Large Numbers
49
3.2
de Finetti-style Theorems for Infinite Sequences of Non-binary Random
Quantities
50
3.2.1
Sufficiency and Indifference in Zero-one Exchangeable Sequences
51
3.2.2
Invariance Conditions Leading to Mixtures of Other Distributions
51
3.3
Error Bounds on de Finetti-style Results for Finite Sequences of Random
Quantities
55
3.3.1
Bounds for Finitely Extendable Zero-one Random Quantities
55
3.3.2
Bounds for Finitely Extendable Non-binary Random Quantities
56
4
Stochastic Models of Failure
59
4.1
Introduction
59
4.2
Preliminaries: Univariate, Multivariate and Multi-indexed Distribution Functions
59
4.3
The Predictive Failure Rate Function of a Univariate Probability Distribution
62
4.3.1
The Case of Discontinuity
65
4.4
Interpretation and Uses of the Failure Rate Function – the Model Failure Rate
66
4.4.1
The True Failure Rate: Does it Exist?
69
4.4.2
Decreasing Failure Rates, Reliability Growth, Burn-in and the Bathtub
Curve
69
4.4.3
The Retrospective (or Reversed) Failure Rate
74
4.5
Multivariate Analogues of the Failure Rate Function
76
4.5.1
The Hazard Gradient
76
4.5.2
The Multivariate Failure Rate Function
77
4.5.3
The Conditional Failure Rate Functions
78
4.6
The Hazard Potential of Items and Individuals
79
4.6.1
Hazard Potentials and Dependent Lifelengths
81
4.6.2
The Hazard Gradient and Conditional Hazard Potentials
83
4.7
Probability Models for Interdependent Lifelengths
85
4.7.1
Preliminaries: Bivariate Distributions
85
4.7.2
The Bivariate Exponential Distributions of Gumbel
89
4.7.3
Freund’s Bivariate Exponential Distribution
91
4.7.4
The Bivariate Exponential of Marshall and Olkin
93
4.7.5
The Bivariate Pareto as a Failure Model
107
4.7.6
A Bivariate Exponential Induced by a Shot-noise Process
110
4.7.7
A Bivariate Exponential Induced by a Bivariate Pareto’s Copula
115
4.7.8
Other Specialized Bivariate Distributions
115

CONTENTS
ix
4.8
Causality and Models for Cascading Failures
117
4.8.1
Probabilistic Causality and Causal Failures
117
4.8.2
Cascading and Models of Cascading Failures
118
4.9
Failure Distributions with Multiple Scales
120
4.9.1
Model Development
120
4.9.2
A Failure Model Indexed by Two Scales
123
5
Parametric Failure Data Analysis
125
5.1
Introduction and Perspective
125
5.2
Assessing Predictive Distributions in the Absence of Data
127
5.2.1
The Exponential as a Chance Distribution
127
5.2.2
The Weibull (and Gamma) as a Chance Distribution
128
5.2.3
The Bernoulli as a Chance Distribution
129
5.2.4
The Poisson as a Chance Distribution
133
5.2.5
The Generalized Gamma as a Chance Distribution
135
5.2.6
The Inverse Gaussian as a Chance Distribution
136
5.3
Prior Distributions in Chance Distributions
136
5.3.1
Eliciting Prior Distributions via Expert Testimonies
137
5.3.2
Using Objective (or Default) Priors
141
5.4
Predictive Distributions Incorporating Failure Data
144
5.4.1
Design Strategies for Industrial Life-testing
145
5.4.2
Stopping Rules: Non-informative and Informative
147
5.4.3
The Total Time on Test
149
5.4.4
Exponential Life-testing Procedures
150
5.4.5
Weibull Life-testing Procedures
155
5.4.6
Life-testing Under the Generalized Gamma and the Inverse
Gaussian
156
5.4.7
Bernoulli Life-testing Procedures
157
5.4.8
Life-testing and Inference Under the BVE
159
5.5
Information from Life-tests: Learning from Data
161
5.5.1
Preliminaries: Entropy and Information
161
5.5.2
Learning for Inference from Life-test Data: Testing for Confidence
164
5.5.3
Life-testing for Decision Making: Acceptance Sampling
166
5.6
Optimal Testing: Design of Life-testing Experiments
170
5.7
Adversarial Life-testing and Acceptance Sampling
173
5.8
Accelerated Life-testing and Dose–response Experiments
175
5.8.1
Formulating Accelerated Life-testing Problems
175
5.8.2
The Kalman Filter Model for Prediction and Smoothing
177
5.8.3
Inference from Accelerated Tests Using the Kalman Filter
179
5.8.4
Designing Accelerated Life-testing Experiments
183
6
Composite Reliability: Signatures
187
6.1
Introduction: Hierarchical Models
187
6.2
‘Composite Reliability’: Partial Exchangeability
188
6.2.1
Simulating Exchangeable and Partially Exchangeable Sequences
189
6.2.2
The Composite Reliability of Ultra-reliable Units
190
6.2.3
Assessing Reliability and Composite Reliability
192
6.3
Signature Analysis and Signatures as Covariates
193
6.3.1
Assessing the Power Spectrum via a Regression Model
195
6.3.2
Bayesian Assessment of the Power Spectrum
195

x
CONTENTS
6.3.3
A Hierarchical Bayes Assessment of the Power Spectrum
198
6.3.4
The Spectrum as a Covariate Using an Accelerated Life Model
200
6.3.5
Closing Remarks on Signatures and Covariates
202
7
Survival in Dynamic Environments
205
7.1
Introduction: Why Stochastic Hazard Functions?
205
7.2
Hazard Rate Processes
206
7.2.1
Hazard Rates as Shot-noise Processes
207
7.2.2
Hazard Rates as Lévy Processes
208
7.2.3
Hazard Rates as Functions of Diffusion Processes
210
7.3
Cumulative Hazard Processes
211
7.3.1
The Cumulative Hazard as a Compound Poisson Process
213
7.3.2
The Cumulative Hazard as an Increasing Lévy Process
213
7.3.3
Cumulative Hazard as Geometric Brownian Motion
214
7.3.4
The Cumulative Hazard as a Markov Additive Process
215
7.4
Competing Risks and Competing Risk Processes
218
7.4.1
Deterministic Competing Risks
219
7.4.2
Stochastic Competing Risks and Competing Risk Processes
220
7.5
Degradation and Aging Processes
222
7.5.1
A Probabilistic Framework for Degradation Modeling
223
7.5.2
Specifying Degradation Processes
223
8
Point Processes for Event Histories
227
8.1
Introduction: What is Event History?
227
8.1.1
Parameterizing the Intensity Function
229
8.2
Other Point Processes in Reliability and Life-testing
229
8.2.1
Multiple Failure Modes and Competing Risks
229
8.2.2
Items Experiencing Degradation and Deterioration
231
8.2.3
Units Experiencing Maintenance and Repair
231
8.2.4
Life-testing Under Censorship and Withdrawals
233
8.3
Multiplicative Intensity and Multivariate Point Processes
234
8.3.1
Multivariate Counting and Intensity Processes
234
8.4
Dynamic Processes and Statistical Models: Martingales
236
8.4.1
Decomposition of Continuous Time Processes
238
8.4.2
Stochastic Integrals and a Martingale Central Limit Theorem
239
8.5
Point Processes with Multiplicative Intensities
240
9
Non-parametric Bayes Methods in Reliability
243
9.1
The What and Why of Non-parametric Bayes
243
9.2
The Dirichlet Distribution and its Variants
244
9.2.1
The Ordered Dirichlet Distribution
246
9.2.2
The Generalized Dirichlet – Concept of Neutrality
246
9.3
A Non-parametric Bayes Approach to Bioassay
247
9.3.1
A Prior for Potency
248
9.3.2
The Posterior Potency
249
9.4
Prior Distributions on the Hazard Function
250
9.4.1
Independent Beta Priors on Piecewise Constant Hazards
250
9.4.2
The Extended Gamma Process as a Prior
251

CONTENTS
xi
9.5
Prior Distributions for the Cumulative Hazard Function
253
9.5.1
Neutral to the Right Probabilities and Gamma Process Priors
253
9.5.2
Beta Process Priors for the Cumulative Hazard
255
9.6
Priors for the Cumulative Distribution Function
259
9.6.1
The Dirichlet Process Prior
260
9.6.2
Neutral to the Right-prior Processes
264
10
Survivability of Co-operative, Competing and Vague Systems
269
10.1
Introduction: Notion of Systems and their Components
269
10.1.1
Overview of the Chapter
269
10.2
Coherent Systems and their Qualitative Properties
270
10.2.1
The Reliability of Coherent Systems
274
10.3
The Survivability of Coherent Systems
281
10.3.1
Performance Processes and their Driving Processes
282
10.3.2
System Survivability Under Hierarchical Independence
283
10.3.3
System Survivability Under Interdependence
284
10.3.4
Prior Distributions on the Unit Hypercube
286
10.4
Machine Learning Methods in Survivability Assessment
291
10.4.1
An Overview of the Neural Net Methodology
292
10.4.2
A Two-phased Neural Net for System Survivability
293
10.5
Reliability Allocation: Optimal System Design
294
10.5.1
The Decision Theoretic Formulation
294
10.5.2
Reliability Apportionment for Series Systems
296
10.5.3
Reliability Apportionment for Parallel Redundant
Systems
297
10.5.4
Apportioning Node Reliabilities in Networks
298
10.5.5
Apportioning Reliability Under Interdependence
298
10.6
The Utility of Reliability: Optimum System Selection
299
10.6.1
Decision-making for System Selection
300
10.6.2
The Utility of Reliability
301
10.7
Multi-state and Vague Stochastic Systems
303
10.7.1
Vagueness or Imprecision
304
10.7.2
Many-valued Logic: A Synopsis
305
10.7.3
Consistency Profiles and Probabilities of Vague Sets
305
10.7.4
Reliability of Components in Vague Binary States
307
10.7.5
Reliability of Systems in Vague Binary States
307
10.7.6
Concluding Comments on Vague Stochastic Systems
308
11
Reliability and Survival in Econometrics and Finance
309
11.1
Introduction and Overview
309
11.2
Relating Metrics of Reliability to those of Income Inequality
310
11.2.1
Some Metrics of Reliability and Survival
310
11.2.2
Metrics of Income Inequality
311
11.2.3
Relating the Metrics
313
11.2.4
The Entropy of Income Shares
315
11.2.5
Lorenz Curve Analysis of Failure Data
315
11.3
Invoking Reliability Theory in Financial Risk Assessment
317
11.3.1
Asset Pricing of Risk-free Bonds: An Overview
317
11.3.2
Re-interpreting the Exponentiation Formula
319

xii
CONTENTS
11.3.3
A Characterization of Present Value Functions
320
11.3.4
Present Value Functions Under Stochastic Interest Rates
325
11.4
Inferential Issues in Asset Pricing
328
11.4.1
Formulating the Inferential Problem
329
11.4.2
A Strategy for Pooling Present Value Functions
329
11.4.3
Illustrative Example: Pooling Present Value Functions
331
11.5
Concluding Comments
332
Appendix A
Markov Chain Monté Carlo Simulation
335
A.1
The Gibbs Sampling Algorithm
335
Appendix B Fourier Series Models and the Power Spectrum
339
B.1
Preliminaries: Trigonometric Functions
339
B.2
Orthogonality of Trigonometric Functions
340
B.3
The Fourier Representation of a Finite Sequence of Numbers
341
B.4
Fourier Series Models for Time Series Data
342
B.4.1
The Spectrum and the Periodgram of f(t)
343
Appendix C Network Survivability and Borel’s Paradox
345
C.1
Preamble
345
C.2
Re-assessing Testimonies of Experts Who have Vanished
345
C.3
The Paradox in Two Dimensions
346
C.4
The Paradox in Network Survivability Assessment
347
Bibliography
349
Index
365

Preface
Over the past few years, there has been an increasing emphasis on what is commonly referred
to as ‘risk’, and how best to manage it. The management of risk calls for its quantification, and
this in turn entails the quantification of its two elements: the uncertainty of outcomes and the
consequences of each outcome. The outcomes of interest here are adverse events such as the
failure of an infrastructure element, e.g. a dam; or the failure of a complex system, e.g. a nuclear
power plant; or the failure of a biological entity, e.g. a human being. ‘Reliability’ pertains to
the quantification of the occurrence of adverse events in the context of engineering and physical
systems. In the biological context, the quantification of adverse outcomes is done under the label
of ‘survival analysis’. The mathematical underpinnings of both reliability and survival analysis
are the same; the methodologies could sometimes be very different. A quantification of the
consequences of adverse events is done under the aegis of what is known as utility theory.
The literature on reliability and survival analysis is diverse, scattered and plentiful. It ranges
over outlets in engineering, statistics (to include biostatistics), mathematics, philosophy, demog-
raphy, law and public policy. The literature on utility theory is also plentiful, but it is concentrated
in outlets that are of interest to decision theorists, economists and philosophers. However, despite
what seems like a required connection, there appears to be a dearth of material describing a
linkage between reliability (and survival analysis) and utility. One of the aims of this book is
to help start the process of bridging this gap. This is done in two ways. The first is to develop
material in reliability with the view that the ultimate goal of doing a reliability analysis is to
appreciate the nature of the underlying risk and to propose strategies for managing it. The second
is to introduce the notion of the ‘utility of reliability’, and to describe how this notion can be cast
within a decision theoretic framework for managing risk. But in order to do the latter, we need
to make a distinction between reliability as an objective chance or propensity, and survivability
as the expected value of one’s subjective probability about this propensity. In other words, from
the point of view of this book
reliability is a chance not a probability
and that probability, which describes one’s uncertainty about reliability, is personal. It is this
de Finettian-style perspective of an objective propensity and a subjective probability that distin-
guishes the material here from that of its several competitors. Hopefully, it changes the way in
which one looks at the subject of reliability and survival analysis; a minor shift in paradigm, if
you will.
With the above as a driving principle, the underlying methodology takes a Bayesian flavor,
and the second aim of this book is to summarize this methodology in its broader context. Much

xiv
PREFACE
of this Bayesian methodology is directed toward predicting lifetimes of surviving units. Here,
the probabilistic notion of ‘exchangeability’ plays a key role. Consequently, a chapter has been
devoted to this important topic, namely, Chapter 3.
The personalistic interpretation of probability is controversial, and unlike what is done by us,
not all Bayesians subscribe to it. Thus it is deemed important to trace the historical evolution
of personal probability, and to contrast it with the other interpretations. With that in mind, a
brief history of probability has been included here. This historical material is embedded in a
chapter that summarizes the quantification of uncertainty from a Bayesian perspective. Readers
whose exposure to the essentials of Bayesian inference is limited may find the material of this
chapter useful – so I hope. At the very least, Chapter 2 serves as the springboard in which the
terminology and notation used throughout the book are established.
The heart of the book starts with Chapter 4, on stochastic models of failure. Included herein
are mathematical concepts such as absolute continuity, singularity, the Lebesgue integral and
the Lebesgue–Stieltjes integral, notions that may appear to be distracting. However, these are
required for a better appreciation of some modern developments in reliability, in particular, the
treatment of interdependence. They are included here because most analysts who do reliability,
risk and survival analysis tend to be applied statisticians, engineers, and other physical and
biological scientists whose exposure to concepts in mathematical analysis may be limited.
As a final point to this preface, I feel obliged to be upfront about some limitations of this
book. For one, its current version does not have much by the way of examples, exercises or
data. I hope this limitation will be addressed in a subsequent edition. For now, the focus has
been on breadth of coverage and the spectrum of issues that the general topic of reliability and
survivability can spawn. An example is the use of concepts and notions in reliability theory that
are germane to econometrics and finance, in particular the assessment of income inequalities
and financial risk. Chapter 11 is devoted to these topics; hopefully, it gives this book an unusual
flavor among books in reliability and survival analysis. Another limitation of this book is that
in some instances, I may have merely mentioned an issue or a topic without dwelling on its
details in any substantive manner. This, I am aware, could frustate some readers. All the same,
I have chosen to do so in order to keep the material to a reasonable size and at the same time
maintain a focus on breadth and scope. As a compensatory measure, a large list of references has
been provided. On the matter of maintaining breadth and scope, I may have also ventured into
territory that some may consider unproven. My hope is that such excursions into the unknown
may provide a platform to others for new and additional research. Finally, given the size of this
book, and the amount of time it has taken to develop it, there are bound to be errors, typos,
inconsistencies and mistakes. For this I apologize to the readers and ask for their tolerance and
understanding. I would of course greatly value receiving comments pointing to any and all of
the above, and advice upon how to improvise upon the current text.
The material of this book can be most profitably used by practioners and research workers
in reliability and survivability as a source of information and open problems. It can also form
the basis of a graduate-level course in reliability and risk analysis for engineers, statisticians and
other mathematically orientated scientists, wherein the instructor supplements the material with
examples, exercises and real problems.
The epitaphs in the chapter opening pages are not for real. All were given to me by a
colleague, save for the one in Chapter 5 which is due to me. For this I ask forgiveness of
Reverend Bayes.
Washington, DC
June 2006

Acknowledgements
Work on this book began in February 1994 at the Belagio Study and Conference Center of
the Rockefeller Foundation in Belagio, Italy. The author thanks the Foundation for providing
an environment conducive to jump-starting this project. Subsequent places wherein the author
found habitats to work on this book have been The Santa Fe Institute, The Los Alamos National
Laboratory, and the Departments of Statistics, University of Oxford, England, and the Université
de Brentage-Sud, France. The author acknowledges with thanks the hospitality provided by
these institutions, orchestrated by Sallie Keller-McNulty, Mary and Dan Lunn, and Mounir
Mesbah. Of course, the author’s home institution, The George Washington University, warrants a
special acknowledgement for nurturing his interests, and for providing an atmosphere conducive
to their development. The author’s deep gratitude also goes to the sponsors of his research,
The Office of Naval Research and the Army Research Office, particularly the latter for its
continuous sponsorship over the past several years. Much of this work is embedded in the
material presented here.
Since its beginnings in 1994, this book project has gone through several changes in title and
publishing house. The project was initiated by John Kimmel, and the initial encouragement and
guidance came from Sir David Cox of Oxford; for this I thank him. The book project underwent
several publishing house changes until Adrian Smith navigated its safe landing in the hands of
Sian Jones of John Wiley, UK; thanks to both. The persistent nags of Wiley’s Kathryn Sharples
forced the author to accelerate the writing in earnest and bring about the book’s closure. Kathryn
deserves an applause.
There are others who have directly or indirectly contributed to the completion of this project
that the author acknowledges. The late Professor Louis Nanni got him interested in statistics,
and Professors John Kao, Richard Barlow and (the late) Frank Proschan got him interested
in reliability. Professors Denis Lindley and Jay Sethuraman contributed much to the author’s
appreciation of probability, which is really what the book is all about. Both occupy a special
place in the author’s heart and mind.
The nitty-gritty aspects of this book would not have been taken care of without the tremendous
and dedicated help of Josh Landon. Later on, Josh was joined by Bijit Roy, and the two being
masters in the art of manipulating equations and harnessing computers, provided invaluable
support toward the book’s completion; thanks to both.
Last but not the least, the author singles out two members of his family for their understanding
and unconditional support. His sister Khorshed bore the brunt of his domestic responsibilities
in India and freed him to pursue his professional career. His wife Norah did the same here
in the US and spent, without anger or resentment, many an evening and weekend in isolation
when the author sequestered himself in his basement cocoon. Thank you Norah; you can freely
spend the royalties – if any!


Chapter 1
Introduction and Overview
G.H. Hardy: Here lies Hardy, with no apologies.
1.1
PREAMBLE: WHAT DO ‘RELIABILITY’, ‘RISK’ AND ‘ROBUSTNESS’
MEAN?
Words such as ‘credibility’, ‘hazard’, ‘integrity’, ‘reliability’, ‘risk’, ‘robustness’ and ‘survivabil-
ity’ have now become very much a part of our daily vocabulary. For instance, the derogatory term
unreliable is used to describe the undependable behavior of an individual or an item, whereas
the cautionary term risky is used to warn of possible exposure to an adverse consequence. The
term survival is generally used in biomedical contexts and is intended to convey the possibility
of overcoming a life-threatening situation or a disease. Robustness encapsulates the feature of
the persistence of some attribute in the presence of an insult, such as a shock, or an unexpectedly
large change, such as a surge in electrical power, or an encounter with an unexpectedly large
(or small) observation. Thus robustness imparts the attribute of reliability to a physical or a
biological unit, and sometimes even to a mathematical or a statistical procedure. In what follows,
we point out that all the above terms convey notions that are intertwined, and thus, in principle,
they tend to be used interchangeably. Our choice of the words ‘reliability’ and ‘risk’ in the title
of this book reflects their common usage.
It is often the case, even among engineers and scientists, that the above terminology is purely
conversational, and is intended to convey an intuitive feel. When such is the case, there is little
need to be specific. Often, however, with our increasing reliance on technology, and for decisions
pertaining to the use of a technology, we are required to be precise. This has resulted in efforts
to sharpen the notions of risk and reliability and to quantify them. Quantification is required
for normative decision making, especially decisions pertaining to our safety and well-being;
some examples are mentioned in section 1.4. When quantified measures of risk are coupled with
normative decision making, it is called risk management (cf. The National Research Council’s
Report on “Improving the Continued Airworthiness of Civil Aircraft”, 1998).
Historically, the need for quantifying risk pre-dates normative decision making. It goes back
to the days of Huygens (1629–1695), who was motivated by problems of annuities. In the early
1930s, it was problems in commerce and insurance that sustained an interest in this topic. During
Reliability and Risk: A Bayesian Perspective
N.D. Singpurwalla
© 2006 John Wiley & Sons, Ltd

2
INTRODUCTION AND OVERVIEW
the 1960s and the 1970s, quantified measures of reliability were needed to satisfy specifications
for government acquisitions, mostly in aerospace and defense; and quantified measures of risk
were needed for regulation, mostly drug approval, and for matters of public policy, such as reactor
safety. During the 1980s, pressures of consumerism, competitiveness and litigation have forced
manufacturers and service organizations to use quantified measures of reliability for specifying
assurances and designing warranties. The coming era appears to be one of ensuring infrastructure
integrity, infrastructure protection and with the advent of test-ban treaties, the stewardship of
nuclear weapons stockpiles. Here again, quantified measures of reliability are poised to play a
signal role.
The above developments have given birth to the general topic of risk analysis, which in the
context of engineering applications takes the form of reliability analysis, and in the context
of biomedicine, survival analysis. These two scenarios have provided most of the applications
and case histories. The 1990s have also witnessed the use of risk management in business and
finance – for acquisitions, bond pricing, mergers, and the trading of options – and in political
science for matters of disarmament and national security. The applications mentioned above, be
they for the design of earthquake-resistant structures, or for the approval of medical procedures,
have one feature in common: they all pertain to situations of uncertainty, and it is this common
theme of uncertainty that paves the way for their unified treatment. Uncertainty is about the
occurrence of an undesirable event, such as the failure of an item, or an adverse reaction to a drug,
or some other loss. Since a conversational use of the words ‘reliability’ and ‘risk’ conveys an
expression of uncertainty, it is the quantification of uncertainty that is, de facto, the quantification
of reliability and risk. To summarize, reliability and risk analysis pertains to quantified measures
of uncertainty about certain adverse events.1 However, since quantified measures of uncertainty
are only an intermediate step in the process of normative decision making, one may take a broader
view and claim that reliability and risk analysis is simply methods for decision making under
uncertainty. This is the point of view taken in ‘Risk: Analysis, Perception, and Management.
Report of a Royal Society Group’ (1992).
The quantification of uncertainty is an age-old problem dating back to the days of Gioralimo
Kardano (1501–1575) (cf. Gnedenko, 1993), and decision making under uncertainty can trace its
roots to von Neumann and Morgenstern’s (1944) theory of games and economic behavior, if not
to Daniel Bernoulli (1700–1782). It was Bernoulli who, in proposing a solution to the famous
‘St. Petersburg paradox’, introduced the idea of a utility, i.e. the consequence of each possible
outcome in a situation of uncertainty. Thus, putting aside the matter of a focus on certain types
of events, what is new and different about reliability and risk analysis, and why do we need
another book devoted to this topic?
The answer to the first part of the above question is disappointing. It is that from a foundational
point of view there is nothing special about problems in reliability and risk analysis that the
existing paradigms used to quantify uncertainty cannot handle. The fundamental territory has
been introduced, developed and explored by individuals bearing illustrious names like Bernoulli,
De Moivre, de Finetti, Fermat, Huygens, Laplace, Pascal, and Poisson. I attempt to answer the
second part of the question in the following sections, but I am unsure of success. This is because
my main reason for writing this book is to articulate a way of conceptualizing the problems of
reliability and risk analysis, and to use this conceptualization to develop a unified approach to
quantify them. I warn the reader, however, that my point of view may not be acceptable to all,
though my hope is that once the fundamentals driving this point of view are appreciated and
understood – which I hope to do here – my position will be more palatable.
1 Not to be considered as being synonymous with Heisenberg’s ‘uncertainty principle’, which says that in the quantum mechanical
framework the error (uncertainty) in the measurement of position multiplied by the error (uncertainty) in time measurement must
exceed a certain constant called Planck’s constant. This principle was enunciated by Werner Heisenberg in the mid-1920s.

RELIABILITY, RISK AND SURVIVAL: STATE-OF-THE-ART
3
1.2
OBJECTIVES AND PROSPECTIVE READERSHIP
The aim of this book is twofold. The first is to discuss a mathematical framework in which our
uncertainty about certain adverse effects can be quantified, so that the notions of hazard, risk,
reliability and survival can be discussed in a unified manner. The second aim is to describe
several reliability and risk analysis techniques that have been developed under the framework
alluded above. My intention is to focus strongly on the matter of how to think about reliability and
risk, rather than to focus on particular methodologies. Since the quantification of uncertainty has
been the subject of much debate, it is essential that the key arguments of this debate be reviewed,
so that the point of view I adopt is put in its proper context. Thus we start off with an overview
of the philosophical issues about the quantification of uncertainty, and decision making in the
presence of uncertainty. The overview material should be familiar to most graduate students in
probability and statistics; however, those who have not had exposure to Bayesian thinking may
find it useful. The overview is followed by a description of the key ideas and methodologies
for assessing reliability and risk. The latter material constitutes the bulk of my effort and should
appeal to those with applied interests. However, the importance of the foundational material
needs to be underscored; it sets the tone for the ensuing developments and provides a common
ground for addressing the various applications.
Because of the current widespread interest in reliability, risk and uncertainty, the book should
be of appeal to academics, students and practitioners in the mathematical, economic, environ-
mental, biological and the engineering sciences. It has been developed while keeping in mind
these multiple communities. The material here could possibly also be of some interest to quanti-
tative philosophers and mathematically oriented specialists in the areas of medicine, finance, law,
national security and public policy. However, by and large, the bulk of its readership would come
from graduate students in engineering, systems analysis, operations research, biostatistics and
statistics. With the above diversity of clientele, it is important to draw the reader’s attention to
one matter. Specifically, throughout this book, the uncertain event that I focus upon is the failure
of items in biological and engineering systems, rather than, say, the occurrence of a financial
or a strategic loss. This admission would appear to suggest that the material here may not be
of relevance to risk analysts in business, finance and other such areas. This need not be true,
because the manner in which I propose to quantify uncertainty is not restricted to a particular
class of problems. The choice of applications and examples is determined by my experience,
which necessarily is limited. All the same, I admit to the difficulty of using my approach for
addressing risk problems that are basically communal or political. Matters pertaining to single
issue campaigns involving extreme positions are not in the scope of our discussion.
1.3
RELIABILITY, RISK AND SURVIVAL: STATE-OF-THE-ART
Even though the first truly empirical mortality table was constructed as early as 1693 by Edmund
Halley, formal material on survival analysis appeared in actuarial journals – mostly Scandinavian.
The term ‘hazard rate’ seems to have originated there. Since the late 1960s the literature on
reliability, risk and survival analysis has experienced an explosive growth. It has appeared in
diverse and scattered sources, ranging from journals in philosophy, mathematics (predominantly
statistics), biomedicine, engineering, law, finance, environment and public policy. In the last 30
years or so, there have been annual conferences and symposia devoted to the various aspects of
these topics. More recently, journals that pertain exclusively to these subjects have also begun to
appear. These conferences, journals and symposia have been sponsored by different professional
groups, with different interests and different emphases.
The activities of the various interest groups have been unconnected because each emphasizes
a particular type of an application, or a particular point of view or a particular style of analysis.

4
INTRODUCTION AND OVERVIEW
For example, risk analysis done by nuclear engineers and physicists is significantly different
from survival analysis done by biostatisticians. The difference is due not just to the nature
of their applications, but more so to their attitudes toward quantifying uncertainty. Physicists,
being generally trained as objective scientists, have come to realize and to accept subjectivity
in the sciences (cf. Schrodinger, 1947); consequently, their analyses of technological risks have
incorporated subjective elements. By contrast, biostatisticians, being subjected to public scrutiny,
have tended to be cautious and very factual with their analyses. Similarly, the type of reliability
analysis done by, say, an electronics engineer differs from that done by an applied probabilist
or a statistician. The former tends to emphasize the physics of failure and tends to downplay
the mathematics of uncertainty; the latter two tend to do the opposite. Certainly there is a need
for both, the physics of failure and the mathematics of uncertainty. A mathematical paradigm
that can formally incorporate the physics of failure into the quantification of uncertainty would
help integrate the activities of the two groups and produce results that would be more realistic.
A goal of this book is to present a point of view that facilitates the above interplay.
A different type of situation seems to have arisen with software engineers working on reliability
problems. They often do a credible job analyzing the causes of software failure, but then quantify
their uncertainties using a myriad of analytical techniques, many of them ad hoc. This has caused
much concern about the state-of-the-art of software risk assessment (cf. Statistical Software
Engineering, 1996). Difficulties of this type have also arisen in other scenarios. A possible
explanation is that most risk analysts tend to be subject matter specialists who concentrate on
the science of the application and tend to accept analytical methodologies without an evaluation
of their limitations and theoretical underpinnings.
A credible risk analysis requires an integration of the activities of the various groups, and one
step toward achieving this goal would be to identify and agree upon a common theme under
which the notions of risk, reliability and survival can be discussed and quantified, independent
of the application. Our purpose here is to advocate such a theme and I endeavor to do so in a
manner understandable by subject matter specialists who are mathematically mature; as a result,
all risk analysts will have a common basis from which to start and a common goal to aim for.
1.4
RISK MANAGEMENT: A MOTIVATION FOR RISK ANALYSIS
We have seen that risk management is decision making under uncertainty using quantified
measures of the latter. The purpose of this section is to elaborate on the above with a view
toward providing a motivation for conducting risk analysis. A few scenarios are cited that are
suitable candidates for risk management and, in one case, the steps by which one can proceed
are outlined.
Most studies in risk management come into play because of the possible dangers faced
whenever new technologies in engineering or medicine are proposed. New technologies advance
the way we live, but occasionally at a price. In some cases, the price is unacceptable. The
objective in risk management is to investigate the trade-off between the conveniences and the
consequences, both tangible and intangible. The end result is often a binary decision to introduce,
or not, a proposed technology. As an illustration, consider the following medical scenario:
cholesterol-lowering drugs decrease the chances of heart attacks, but are expensive to administer,
cause physical discomfort to the patient and often have side effects such as damage to the
kidneys. If in an individual case, the possibility of the side effects materializing is small, if
the patient is willing to bear the cost of the drug and is able to withstand its discomfort, then
there is more to be gained by prescribing the drug, than by not. But to arrive at such a decision
we need to quantify at least six uncertainties, four connected with the administration of the
drug, and the remaining two if the drug is not administered (Figure 1.1). Risk analysis is the

RISK MANAGEMENT: A MOTIVATION FOR RISK ANALYSIS
5
Random
Node
1
()

Decision
Node

p1
p2
p3
p4
[, ]
[, ()]
[(), ()]
[(), ]
[]
[()]
q
1
2
3
4
5
pi and qi: Probabilities;
: Administer Drug;
: Patient Suffers a Heart Attack;
: Patient Suffers Side Effects;
i : Utilities;
(): Do not Administer Drug;
(): Patient Avoids a Heart Attack;
(): Patient Avoids Side Effects.
Random
Node
2
q1
q2
6
Key:
Figure 1.1
Decision tree for the cholesterol lowering drug problem.
process of quantifying such uncertainties. We also need to evaluate the patient’s utilities, i.e. the
consequences, usually expressed as costs, associated with each of the above six uncertainties.
The utilities should include the cost of administering the drug, a cost figure associated with
the discomfort of side effects, cost figures attached to suffering a heart attack, and the rewards
of avoiding one. The assessment of utilities is a very crucial and, perhaps, the most difficult
step in risk analysis. It is best performed by individuals knowledgeable in economics and the
behavioral sciences. Determining an individual’s utilities usually involves asking them to express
preferences among different options. Clearly, assigning cost figures to the consequences of
having a heart attack and to the merits of avoiding one is not a standard exercise, but one that
nevertheless has to be addressed. The matter of utilities is discussed in some detail in section 2.8.
Quantifying uncertainties is often a detailed task which, in our example, would start with the
patient’s medical history and would involve tracing the causes of a heart attack and the drug’s
side effects. A useful device that graphically portrays the causes and the sequences of events that
lead to an undesirable event is a fault tree, also known as an event tree; see Barlow, Fussell,
and Singpurwalla (1975) for examples on how to construct fault trees. The more detailed an
accounting of the causes, the more credible is the quantification of uncertainty. Clearly, such a
task would require the active participation of subject matter specialists, such as physicians and
biochemists. The actual quantification should be done by someone knowledgeable in the calculus
of uncertainties, which we hope that this book will help quantitative subject matter specialists
to become. Thus, risk analysis is often a multi-disciplinary process involving participation by
economists, mathematicians, social scientists, engineers and other subject matter specialists.
Figure 1.1 is a decision tree which shows the various steps that are involved in deal-
ing with the cholesterol drug problem. The rectangle at the leftmost end of the tree denotes
a decision node, which shows the two possible actions that a decision maker, usually the

6
INTRODUCTION AND OVERVIEW
physician, can take:  – to administer the drug; or () – not to administer it, the parentheses
surrounding  denote its complement. The circles denote the random nodes, which show the
possible (unpredictable) outcomes that can occur under each action taken by the decision maker.
The notation  denotes the event that the patient suffers a heart attack, whereas () denotes
the event that the patient escapes it. Similarly,  denotes the event that the patient experiences
the drug’s side effects, whereas () denotes the event that the patient does not experience side
effects. Observe that a heart attack can occur whether or not the drug is administered, but that
there can be no side effects when the drug is not administered. At the right-hand end of the tree,
we indicate the patient’s utilities that are encountered with each of the six terminal branches
of the tree; these are denoted by the is. Important to Figure 1.1 are the numerical values that
quantify the uncertainties associated with the events describing each of the six terminal branches;
these have been denoted by the pi’s and the qi’s. A focus of this book is to describe procedures by
which such numerical values can be assigned. Once this has been done, standard decision theory
(cf. Lindley, 1985, pp. 139–159) prescribes a procedure by which the decision to administer the
drug, or not, can be made. More details about this are given in section 2.9. The decision would
depend on the assessed values of the patient’s utilities and the numerical values of the assessed
uncertainties. These of course would vary from patient to patient.
A similar type of analysis should be used for analyzing the risk of introducing the recently
proposed ‘fly-by-wire airplanes’, in which the control of aircraft is under the direction of a
computer. The advantage of such airplanes is less reliance on pilots who are prone to human
error. Their main disadvantage is the possible presence of a fatal flaw in the software which
directs the computer. What are the chances of having such a flaw and, should there be one,
what are the chances of encountering it during flight? A numerical assessment of these chances,
together with an assessment of utilities, would enable us to decide whether or not to commission
the fly-by-wire airplanes. A less daunting example, also in connection with airplane travel,
pertains to the current trend by aircraft manufacturers to equip large passenger jets with only
two engines rather than the usual four, which is known as ETOPS (for extended twin engine
operations). Whereas most people would prefer to fly in aircraft equipped with four engines, it
is possible that having only two engines lowers the stresses on the rest of the airplane, making
its overall reliability better than that of an aircraft with four engines. Decisions of this type
should be supported by a formal exercise in risk management; see Appendix E of the National
Research Council’s 1998 Report mentioned earlier. Also see sections 10.5 and 10.6, wherein we
describe decision making for allocating reliability in systems design and for system selection
(procurement), respectively. In the context of reliability, decision trees also come into play when
one considers life testing and the design of life testing experiments (sections 5.5 and 5.6).
Indeed, if one of the main purposes of doing reliability analysis is to facilitate a good
engineering design, and because design involves a trade-off among alternatives, one may take
the view that the purpose of a reliability study is to help make sound decisions in the face of
uncertainty.
1.5
BOOKS ON RELIABILITY, RISK AND SURVIVAL ANALYSIS
In section 1.1, we raised the issue about the need for another book on reliability and survival
analysis. I have given the reader some hints about my aims here but have said little about
what is currently available and how it differs from what is planned here. In what follows, a
broad-brushed perspective on published material on these topics is given.
The existing books and monographs on reliability, risk and survival analysis can be classified
into the following three categories: 1) works that are heavily focused on the subject matter
details of a particular application, say nuclear reactor safety; 2) works that develop models for

OVERVIEW OF THE BOOK
7
quantifying uncertainties and which focus on the detailed mathematical structure of such models;
and 3) works that emphasize statistical issues pertaining to the quantification of uncertainty and
the treatment of data. The first category does not warrant concern vis-à-vis duplication because
the material there does not advocate an overall theme for addressing a general class of problems,
nor does it articulate any particular paradigm for thinking about problems in reliability and
risk analysis. The treatment is generally on a case-by-case basis, and its greatest appeal is to
practitioners whose interests are non-mathematical. In the second category, of which the two
books by Barlow and Proschan (1965, 1981) are landmarks, the emphasis is on material that may
be labeled ‘academic’. The authors refer to their work as a ‘mathematical theory of reliability’,
and correctly so. The main handicap of this second category is that the initial uncertainties are
treated as being quantified (via probability), and the emphasis is on how these initial uncertainties
propagate. That is, the initial probabilities (be they objective, subjective or logical) are assumed
known. The attitude there is more in keeping with the Russian school of probability, wherein
the source and nature of initial probabilities are not a matter of concern. Furthermore, the
mathematical theory is not integrated into the broader framework of risk management. That is,
its place in the context of decision making under uncertainty has not been sufficiently articulated.
For us here, the real overlap – if any – is with respect to the third category, which also happens
to be the biggest. Representatives of this group that have a focus toward engineering problems,
data and applications are the books by Gnedenko, Belyaev, and Soloyev (1969) Mann, Schafer,
and Singpurwalla (1974), Crowder et al. (1991) and Meeker and Escobar (1998); sandwiched
between these are a myriad of others (cf. Singpurwalla 1993). I have mentioned these three
books because the first is one of the oldest and the third, one of the latest. In the area of survival
analysis, a classic source is the book by Kalbfleisch and Prentice (1980). Recent additions to this
field include several books on counting process models, the one by Anderson et al. (1993) being
encyclopedic. In all the above books, the statistical paradigm that is subscribed to is different
from what we propose to do here. Thus, the possibilities of duplication appear to be minimum.
As a final comment, in Barlow, Clarotti and Spizzichino (1993), the need to integrate reliability
analysis into risk management has been recognized, but the material is more along the lines of
a research monograph rather than an expository development.
1.6
OVERVIEW OF THE BOOK
Chapters 2 and 3 pertain to foundational issues; they present the underlying paradigm for our
development. Chapter 2 starts off with a discussion of uncertainty and its quantification, leading
up to decision making under uncertainty. In the interim we also present standard statistical
notions such as ‘inference’, ‘likelihood’ and ‘prediction’. Professionally trained statisticians,
biostatisticians and applied probabilists may find little, if any, that is new to them here. By and
large, the material of Chapter 2 is pitched toward engineers, operations research analysts and
other mathematically oriented subject matter specialists. The material may also appeal to graduate
students in the statistical sciences, and other statisticians who may not have had an exposure to
subjective Bayesian thinking. Chapter 3 is specialized and pertains to the important notion of
‘exchangeability’, which plays a key role in selecting models for quantifying uncertainty. Most
readers may want to skip this material on a first reading. Chapter 4 is basic and pertains to
a discussion of standard notions in reliability and survival analysis. However, the perspective
that we take in Chapter 4 is not traditional; the material given here should be viewed as being
foundational to reliability and survival analysis. Chapter 5 presents a different perspective on the
same topics that are covered in the books of category three mentioned before. Chapter 6 builds on
the material of Chapter 5; it pertains to the propagation of uncertainty through a system of items.
The material in the remaining chapters is mildly advanced and pertains to specialized topics,

8
INTRODUCTION AND OVERVIEW
many of which may appeal to only certain segments of the readership. Thus, Chapter 7 focuses
on dynamic environments and the use of stochastic process models, Chapter 8 on counting
processes and event history data and Chapter 9 on non-parametric methods within the Bayesian
paradigm. Chapter 10 pertains to the survivability of systems with interdependent failures and
Chapter 11 describes the role of reliability and survival analysis in econometrics, asset pricing
and mathematical finance. Our overall aim has been to give as broad a coverage as is possible,
even if this means an occasional sacrifice of specifics. We compensate for this compromise
of completeness by providing adequate references so that a reader can patch together a more
complete picture.

Chapter 2
The Quantification of Uncertainty
Heisenberg: Here lies Werner Heisenberg – maybe.
2.1
UNCERTAIN QUANTITIES AND UNCERTAIN EVENTS: THEIR
DEFINITION AND CODIFICATION
The previous chapter stated that an element that is common to all risk analyses is the presence
of uncertain events. What do we mean by the term ‘uncertain’, and what is an uncertain event?
We do have some intuitive notions about these but, to give them structure, we must start with
the basics. We first distinguish between a scientist’s appreciation of the world from that of, say,
an artist. A scientist’s appreciation of the world is in terms of things that can be measured. To
understand and to manipulate things, a scientist must be able to measure them, or at least think
of them as being measurable. Measuring means comparing to a standard, and some commonly
used standards for measurement are those provided by the foot ruler, the scale, the thermometer
and the watch. In effect, the act of measuring comes down to describing things by numbers; that
is, quantifying them. We quantify because with quantification, we have at our disposal the full
force of logic and the mathematical argument. We must of course recognize that not everything is
amenable to measurement, and science excludes such entities from consideration. For example,
works of art like literature, music and painting cannot be understood and manipulated by
measurement, neither can be human feelings like anger and joy. This of course does not suggest
that we cannot assess the utilities of things that cannot be quantified. Recall, from the example of
Chapter 1, that risk analysis requires that we assess utilities for outcomes, such as the discomfort
caused by a drug.
Given this background, we shall begin by noting that at any point in time, say  ≥0, a
scientist – henceforth us – contemplates a collection of things, called ‘quantities’, some whose
numerical values are known to us and some whose values are not known, and may indeed
never be known. The reference time  plays an important role in our development, though
by convention it is often taken to be zero. The collection of quantities known to us at  will
be denoted by , for history. Quantities whose values are unknown to us are called random
quantities or uncertain quantities and, for convenience, are denoted by a capital letter, such
as T. The numerical value that T can take will be denoted by the corresponding lower-case
Reliability and Risk: A Bayesian Perspective
N.D. Singpurwalla
© 2006 John Wiley & Sons, Ltd

10
THE QUANTIFICATION OF UNCERTAINTY
letter. When T becomes known (at some time later than ) we shall replace it by its revealed
value, say t. Our ‘uncertainty’ about T is our inability to assign a numerical value for t. The
possible values that t can take depend on the situation being encapsulated. If t can take only
discrete values, like say t = 123   , then T is said to be a discrete random quantity; if t is
allowed to take any value in an interval, say 0, then T is said to be a continuous random
quantity. Thus, for example, T could denote the number of defectives in a particular batch, or
the unknown time to failure of an item that was surviving at , or the unknown number of miles
to the next failure of an automobile that was serviced at , or the remission time of a disease
since a medical intervention at , or the amount of radioactive release, or the amount of loss
incurred, etc. If the item fails after operating for 38 755 hours, that is at time  + 38755, then
t = 38755 hours, and the continuous random quantity T has become known at  + 38755 hours.
Similarly, if the automobile fails after accumulating 5000 miles since servicing, and if the time
taken by the automobile to accumulate the 5000 miles is 5 months, then t = 5000 miles and the
discrete random quantity T has become known at  + 5 months.
An important subclass of random quantities is that in which t is restricted to be binary, i.e. t
can take only two values, say t = 0 and t = 1. Such random quantities are called random events
or uncertain events and, for purposes of distinction, we denote them by the letter X, with X
taking the value x = 0 or 1. It is often the case that random events are constructed from random
quantities. For example, if the random quantity T denotes the time to failure of an item, and if
we are interested in the proposition that T be at least t, then we may define a random event X,
with x = 1, whenever T ≥t, and x = 0, when T < t. With this construction, our uncertainty about
T ≥t is synonymous with our uncertainty about X = 1. Because of this synonymity, we may
also refer to T ≥t as ‘the event that T is at least t’. In general, random events are ‘indicators’
constructed for encapsulating situations that involve the truth or the falsity of a proposition. The
general convention is that x = 10 if the proposition is true (false). Examples of propositions
that are common in risk analysis are: the patient will have a reaction to a drug; a business
decision will lead to a loss; an earthquake will occur within the next five years; an automobile
will provide service between 70 and 100 thousand miles, and so on.
We close this section on the codification of uncertain quantities and uncertain events by
emphasizing two points. The first is that we have been talking about the known and unknown
quantities for a ‘particular’ scientist, say us, and that we are referring to our state of knowledge
at a ‘particular’ time . What is unknown to us at  may very well be known to another scientist,
and also what is unknown at  may become known to us later. The important point is that what
we are talking about is personal to us, with respect to both our state of knowledge and our
time of reference. These matters play a key role when we quantify uncertainty, because it is our
uncertainty that we will be quantifying, not someone else’s. More about this essential point is
said later, in section 2.3.2.
2.2
PROBABILITY: A SATISFACTORY WAY TO QUANTIFY
UNCERTAINTY
Continuing with the setup of the preceding section, let us focus attention on some reference time
 at which there is an uncertain quantity T that we are interested in and have at our disposal
history, or background knowledge, . Even though we are uncertain about T, i.e. are unable to
assign a numerical value for t, we are not completely ignorant about T. At the very minimum,
we know the range of values that t can take, and since it is reasonable to suppose that  gives
us information about T, we may be able to guess which values of t are more likely to arise (when
T will reveal itself) than the others. Our aim is to quantify this uncertainty or partial knowledge
about T, in the light of , at time . By this, we mean that we want to associate a number with
every value of t. What should we call this number and what should its properties be?

PROBABILITY: A SATISFACTORY WAY TO QUANTIFY UNCERTAINTY
11
There have been several suggestions. However, Lindley (1982a) asserts that probability is the
only satisfactory way to quantify our uncertainty. Furthermore, under some mild but reasonable
assumptions, probability is inevitable (cf. Lindley, 1982b). To describe the properties of this
number called ‘probability’, it is convenient to introduce some additional notation. When T is
discrete, we write PT = t to denote the number we associate with the event that when
T reveals itself, its numerical value will be t, and that this assessment is made at time , in
light of background knowledge . It is common to suppress  by setting it equal to zero, so
that PT = t is simply PT = t. We refer to PT = t as ‘the probability that the
random quantity T takes the value t’ or equivalently, ‘the probability of the event T = t’. Often
PT = t is abbreviated as PTt or simply Pt. Analogously, for a random event
X PXx [or simply Px] denotes the probability that when X is revealed, it will take the
value x. Irrespective of whether T is discrete or continuous, PT ≤t denotes the probability
that T is at most t; it is called the distribution function of T. It is common to abbreviate
PT ≤t as FTt, or simply Ft. If fTt, the derivative of FTt, exists for
(almost) all values of t, and if the latter is given by an indefinite integral of the former, then
FTt is said to be absolutely continuous, and fTt is called the probability density
function (or simply, the density) generated by FTt at t (section 4.2). As was done with
FTt, the subscript T may be omitted – when there is no cause for confusion – and the
probability density at t simply written as ft. In all of the above, we have adopted the
convention that the semicolon separates the knowns from the unknowns; this convention is not
standard. Finally, we wish to emphasize that probability makes sense only for events whose
disposition is unknown to the assessor of probability at the time of making the probability
assessment.
The setup described above generalizes when we have two (or more) uncertainties, say T1 ≤t1
and T2 ≤t2. Specifically, if PT1 ≤t1T2 ≤t2=Ft1t2 is absolutely continuous, then
its derivative ft1t2 exists for (almost) all values of t1 and t2, and ft1t2 is known as
the joint probability density function (or simply the joint density) generated by Ft1t2;
more details are given in section 4.2. Note that PT1 ≤t1T2 ≤t2 represents the event
PT1 ≤t1 and T2 ≤t2.
To describe how different uncertainties relate to each other, we restrict attention to the case of
random events and extend the above setup by contemplating, at time , two (or more) random
events, say X1 and X2, with Xi taking values xi i = 12. Note that each xi is either 0 or 1.
We state below the rules (or the calculus) of probability. Often these rules are stated as axioms;
however, as is pointed out in section 2.2.2, they can be motivated by both behavioristic as well
as operational arguments.
2.2.1
The Rules of Probability
For coherence, a notion that will be explained in section 2.3.2, all probability specifications must
obey the following rules (stated here for the case of random events):
Convexity:
0 ≤PX = x ≤1	
Addition: If X1 and X2 are mutually exclusive, that is both X1 and X2 cannot logically take
the same value (be it 0 or 1), then
PX1 = x1 or X2 = x2 = PX1 = x1 + PX2 = x2	

12
THE QUANTIFICATION OF UNCERTAINTY
Multiplication:
PX1 = x1 and X2 = x2 = PX1 = x1  X2 = x2 PX2 = x2 or equivalently,
= PX2 = x2  X1 = x1 PX1 = x1
where PX1 = x1  X2 = x2 is known as the conditional probability that X1 = x1 given that
X2 = x2, and in light of . It is typical to refer to PX1 = x1  X2 = x2 as the conditional
probability of X1 given X2. The interpretation of conditional probabilities is subtle; it is in the
subjunctive mood. Specifically PX1 = x1  X2 = x2 denotes the probability of the event
X1 = x1, in light of , if it were to be (i.e. supposing) that X2, when it reveals itself, is
x2. The conditioning event X2 = x2 is not known to be true (or false) at time , when X1 is
assessed; all that is known at time  is only . Consequently, the event X2 = x2 is to the left
of the semicolon whereas  is to the right, and the vertical slash preceding the conditioning
event signals its subjunctive feature. Finally, X1 and X2 are said to be mutually independent if
PX2 =x2  X1 =x1=PX2 =x2 and also if PX1 =x1  X2 =x2=PX1 =x1.
The convexity rule states that all probabilities are numbers between 0 and 1. The addition and
the multiplication rules specify how the various uncertainties combine or cohere. A collection
of uncertainty statements that obey the above rules are, according to Lindley (1982a), coherent.
The notion of conditional probability has been the subject of some discussion. Of particular
concern are issues such as protocols for obtaining new information and the timing of events;
the writings of Shafer (1982b, 1985) make interesting reading. By a repeated application of the
addition rule, we can see that for any finite collection of mutually exclusive random events, say
X1   Xn n < ,
PX1 = x1 or X2 = x2 or    Xn = xn =
n
i=1
PXi = xi
this is known as the finite additivity property of probability. Under countable additivity we
allow n to be infinite, so that
PX1 = x1 or X2 = x2 or    Xn = xn =


i=1
PXi = xi	
When countable additivity is allowed, and the multiplication rule is taken as a definition of
conditional probability, the above three rules are generally known as the Kolmogorov axioms.
2.2.2
Justifying the Rules of Probability
A question arises as to why probabilities should combine in the manner shown above. For
example, in Zadeh’s (1979) theory, his ‘possibilities’ do not combine using the addition rule,
and Shafer (1976), following Dempster (1968) and Smith (1961), extends the idea of using a
single number for describing uncertainties to two numbers, called upper and lower probabilities.
The same is also true of Jeffrey (cf. Diaconis and Zabell, 1982), who uses a rule of combination
that is unlike those used in probability.
There are two lines of reasoning that justify the calculus of probability given before. The first
is an ‘axiomatic’ one, and the second a pragmatic one. The axiomatic argument, first proposed by
Ramsey in 1931, and further developed by Savage (1954) and by DeGroot (1970), is an argument
in mathematics. It proceeds by searching for simple, self-obvious truths about uncertainty, taking
these as axioms, and then developing a system of theorems that result in the above rules. The
second, a more operational argument, is due to de Finetti (1974, ch. 4). It is called the scoring
rule argument, and goes along the following lines:

OVERVIEW OF THE DIFFERENT INTERPRETATIONS OF PROBABILITY
13
A person contemplating an uncertain event X, say a proposition, assigns a number p to
describe the person’s uncertainty about the truth of the proposition. The person receives a penalty
score of an amount p −12 if the proposition turns out to be true, and an amount p2 if the
proposition turns out to be false. The person should choose p in a manner that minimizes the
penalty score. Thus if the person were to be certain that the proposition is true, then p will
be specified as 1, whereas if the opposite were to be the case, then p would be zero. Now
suppose that such a person contemplates several uncertain events X1X2X3   , and assigns
to each the corresponding numbers p1p2p3   . Then, it is an argument due to de Finetti that
if the scores for the different events are additive, then in order to avoid a sure loss, that is, a
gamble in which the bettor loses irrespective of the outcome, the pi’s must obey the rules of
probability given above; that is, the pi’s must indeed be probabilities. It is for this reason that
probability and the calculus of probability are said to be inevitable for specifying uncertainty.
The quadratic scoring rule mentioned above has been used to rate meteorological predictions and
is known as the Brier score. Savage (1971) and Lindley (1982b) have generalized de Finetti’s
result to scores other than the Brier score. Many prefer the abstract axiomatic argument over the
pragmatic scoring rule argument of de Finetti. One reason is that people do not like to be scored
and may therefore not agree to specify numbers in the context of being scored. The second,
and perhaps more important reason, is that the scoring rule argument can be used to extend
the addition (and also the multiplication) rule to the case of only a finite number of events.
Consequently, according to this argument the resulting probabilities are only finitely additive,
not countably additive (or 
-additive), as in the Kolmogorov axiomatization. This means that
countable additivity has to be introduced as an additional axiom, or by some extra axiom that is
effectively equivalent. One such equivalent axiom is the axiom of conglomerability (cf. Lindley,
1997a). According to this axiom, if the events Xi = xi i = 12   , are a countable partition
of an event C, and if for some event APAXi = xi ∩C = a, for all i, then PA  C = a.
That is, a statement true for every member of a partition is true overall. As an aside, it is useful
to note that not everyone is willing to accept the Kolmogorov axiomatization of probability. de
Finetti for one rejected countable additivity (cf. Lane, 1987) and Hartigan (1983), among others,
retains countable additivity but rejects the convexity rule, and develops a theory of improper
probability. More on this is said in sections 2.5, 5.2.3 and 5.3.2.
2.3
OVERVIEW OF THE DIFFERENT INTERPRETATIONS OF
PROBABILITY
In the previous section, we have outlined the premise that the probability of an uncertain event
is a number between zero and one that behaves according to certain rules, and which is specified
by a person with background knowledge  who is contemplating the event at some time . In
Chapter 1, we stressed the fact that, in any problem involving decision under uncertainty, the
numerical values assigned to the uncertain events determine the optimum decision to be taken.
However, we have said little about how these numerical values are arrived upon, whether they
are unique and how to make them operationally meaningful. For this, we need to review the
several interpretations of probability and, in order to gain their broader appreciation, trace their
historical development. Such material is relevant because the interpretation of probability that
we adopt will, to a great extent, determine the methodologies that we will advocate, the problems
we are able to address and the results we are able to obtain. Thus, whereas the interpretation of
probability may not be of much concern to a mathematical probabilist, to a user of probability,
like an engineer, a statistician or an operations research analyst, the interpretation is germane. The
material of section 2.3.1, on the historical development of probability, can be skipped without a
loss in continuity.

14
THE QUANTIFICATION OF UNCERTAINTY
2.3.1
A Brief History of Probability
Probability can trace its roots to the times of Gioralimo Kardano (1501–1575), an ardent gambler
who, in his treatise, ‘Book on Dice Tossing’, did consider the ratio of successes to the total
number of trials but never fully explored the usefulness of this idea. So, who was it that introduced
the idea of a random event, guessed that it was rational that probability be a number between
zero and one and made precise the addition and the multiplication rules for calculating the
probabilities of complex events? To answer these questions, we need to trace the development
of probability, which in the beginning appears to have evolved along two paths: fair price and
belief.
The word ‘probability’, derived from the Latin verb probare, means ‘to prove’. Until about
1689, probability was not a number between zero and one; probability was an argument or a
belief for which there are good proofs (cf. Shafer, 1996). It is widely believed that numerical
probability was born in 1654 when Blaise Pascal (1623–1662), in correspondence [initiated by
Chavalier de Méré (1607–1684), a philosopher and a man of letters] with Pierre Fermat (1601–
1665), was the first to propose a correct solution to the problem of points, or fair prices. But
Pascal and Fermat did not use the word ‘probability’ in their letters. They were not thinking
about probability, which, as stated before, was then a qualitative idea used for evaluating an
argument or evidence. They were thinking about problems of equity or fair prices. Shafer (1990),
who provides an interesting perspective on the evolution of mathematical probability, and upon
whose writings much of what we say here is based, describes the problem of points as follows:
 and  are playing a game contending on equal chances. They have both put five chips on
the table, and have agreed that the winner gets the entire stake of ten chips. The game consists of
several rounds of play, the winner of each round gains a point, and the first person to gain three
points wins the game. At a certain time, when  needs two more points to win and  needs
only one,  has to leave the game.  is prepared to take ’s place in the game. What is the fair
price that  should pay  for his position in the game? Pascal’s argument was that  should
pay  2.50 units; this answer was different from the more traditional answer of 3.33 units.
Probability theory got started from this kind of reasoning. Christian Huygens rediscovered Pascal
and Fermat’s reasoning (their correspondence was published in 1679), and wrote it up in 1657
in the widely circulated De ratiociniis in ludo aleae. Later on, Huygens and Montmort found
fair prices for positions in more and more complicated games and also for practical applications
such as annuities and insurance.
It would be nearly 60 years after the Pascal–Fermat correspondence that the idea of fair price
would be tied up with that of probability (or belief) in James (or Jakob) Bernoulli’s masterpiece
Ars Conjectandi, published posthumously in 1713 by his nephew Nicholas Bernoulli.
Bernoulli’s introduction of probability was motivated by his desire of applying the Pascal–
Fermat–Huygens theory of fair price and expectations to problems other than games of chance
where the qualitative idea of probability was traditionally used. He reasoned that, just as how the
rounds won and lost in a game of chance entitle one to a fair price, the arguments that one finds
for and against an opinion entitle one to a portion of certainty. Arguments in practical problems
earn a certain portion of certainty, just as a position in a game of chance earns a certain portion
of the stake. This portion is the opinion’s probability. This analogy between the rounds in a game
of chance and arguments about an opinion also appears to have been made by Pascal’s friends
in a widely used textbook called the Port Royal Logic (Arnauld and Nicole, 1662). According to
Shafer (1986), the English cleric George Hooper used the word ‘probability’ to refer to a number
between zero and one in a 1699 anonymous article in The Philosophical Transactions of the Royal
Society. However, it was Bernoulli who made the case for the existence and meaningfulness of
numerical probabilities, and went beyond the analogy between arguments and rounds to develop
numerical rules for the combination of arguments, showed the inapplicability of the addition rule
to non-disjoint events, gave his formula for the binomial distribution, and went on to prove his

OVERVIEW OF THE DIFFERENT INTERPRETATIONS OF PROBABILITY
15
great theorem, the law of large numbers (section 3.1.4). This law was motivated by Bernoulli’s
recognition that, in practical problems, unlike games of chance, fair prices could not be deduced
from assumptions about equal possibilities; probabilities in practical problems would have to
be found (approximated) from observation. He proved that, if a large number of rounds are
played, then the relative frequency with which an event occurs will approximate the relative
ease with which it will happen, namely, its probability. Thus Bernoulli, to whom probability
was a piece of the certainty (and not a relative frequency), bound up together fair price, belief
and frequency. Bernoulli subscribed to Newton’s notion of metaphysical determinism; i.e. an
unconditional belief in the powers of omnipotence and formal logic as an instrument for cognition
and description of the external world. To him, probability was not just chance; it was a state of
our knowledge. Chance was viewed as the absence of a divine plan or design.
Bernoulli’s idea of approximating probability by a frequency was taken up by De Moivre
(1718) who made it the basis of his famous book The Doctrine of Chances. However, other
elements of Bernoulli’s strategy, like his rules for combining arguments that were based on
the traditional view of probability theory in philosophy, theology and the law, were nowhere
to be seen in De Moivre’s book. Indeed, it was De Moivre who introduced the concept of
independent random events and proposed both the summation and the multiplication rule of
probability. However, to De Moivre, the rules for combining probabilities had to be derived from
Huygen’s rules, which could be justified directly using the idea of expectations under fairness.
This is contrary to current thinking in which rules for expected values are derived from rules
for probabilities. Despite the great influence that De Moivre’s book had during the eighteenth
century, Bernoulli’s rules for combining probabilities survived that century in the writings of
philosophers such as Lambert and Diderot (cf. Shafer, 1996). It was almost 75 years later, when
Laplace (1795) (in his Essai de Philosophique sur de Probabilite) discussed Bayes’ formula and
the formula of total probability, that Bernoulli’s rules for combining arguments disappeared.
After Bernoulli and De Moivre, the next important step was taken by Thomas Bayes (1702–
1761), whose famous essay on inverse probability was published in 1764. It appears (cf.
Gnedenko, 1993) that Bayes’ main contribution was an elucidation of the multiplication rule,
which allows one to calculate conditional probabilities from unconditional probabilities. This
formula was crucial for Laplace’s development of the law of total probability and Bayes’ law –
discussed later. Shafer (1982b) gives a fascinating account of Bayes’ treatment of conditional
probability, and Stigler (1982) interprets Bayes’ essay from the angle of predictive inference.
After Bernoulli, Laplace (1749–1827) was the next great philosophical mind to come to grips
with probability. Like Bernoulli, Laplace was a determinist who regarded numerical probability
as a degree of certainty and to him the doctrine of chances was the universal tool for measuring
partial knowledge. Assured by his success in giving a probabilistic justification to the method of
least squares, Laplace associated mathematical probability with the very idea of rationality. Thus,
to Laplace, probability was a ‘rational belief’ and the rules of probability were self-evident so
that the additivity of probability no longer needed to be derived from fair price and expectation –
it was axiomatic, a natural and obvious property of rational belief. Similarly, to him, rules for the
values of expectation arose from viewing probability as rational belief. Thus Laplace’s picture
of probability differed from De Moivre’s in several ways, the most salient differences being an
expanded number of applications (which now included the combination of observations and of
testimony) and the absence of the requirement that observations, or equally likely cases, were
needed to get started (Shafer, 1996). Poisson (1781–1840) did much work on the technical and
practical aspects of probability, his main contributions being a generalization of Bernoulli’s
theorem. Like Laplace, he too was a determinist and one who also greatly expanded the scope
of applications of probability.
Laplace’s definition of probability as a degree of belief was criticized in the 1840s by empiri-
cist philosophers, like John Venn, and by mathematicians like Richard von Mises (1883–1953),

16
THE QUANTIFICATION OF UNCERTAINTY
who were equally unhappy with Bernoulli’s notion of probability as ease of happening. Prob-
ability made sense to the empiricists only if it was empirically defined as a frequency. Thus,
Bernoulli’s theorem (which is (incorrectly) interpreted by some as probability equals frequency)
was nonsense. To them, frequency itself was the starting point, and was the definition of prob-
ability. However, in doing so, the empiricists were willing to leave vast domains outside their
range of application. If, in a problem such as the authorship of the gospels or station blackout in
a nuclear reactor, one could not conceive relevant limiting frequencies, then it was not a problem
for probability.
The modern era in probability began in the early 1930s after Kolmogorov axiomatized prob-
ability and freed it from the paradoxes and confusions of interpretation. He treated events as
sets and probabilities as numbers assigned to these sets which obey certain rules (or axioms),
the main one being additivity (section 2.2.1). The key to this adaptation was the philosophy of
the German mathematician David Hilbert, who believed that mathematics was a formal exercise
without an essential connection to reality. The perspective given by Kolmogorov is far from the
setting of Pascal and Fermat, where repeated rounds of a game are played and, hence, prices
and probabilities change. In Kolmogorov’s scheme, neither price nor repetition is fundamental;
they are both arbitrary elements added on top of the axioms which are foundational. All the
same, Kolmogorov’s intent was to view these axioms as providing a mathematical foundation
for the frequency definition of probability.1 Of course, their neutrality makes them susceptible
to a degree-of-belief interpretation as well.
Our brief history of probability would end here, except for the resurgence of subjective ideas
during the past 40 years. This happened in 1954 with Savage’s publication of Foundations
of Statistics. Motivated, among other things, by difficulties and limitations of the empiricist
philosophy, the view that probability is a degree of belief was revived. The foundation for this
subjectivist revival was provided in the 1920s and the 1930s by the philosopher Frank Ramsey
and the mathematician-philosopher Bruno de Finetti, who gave the degree of belief an empiricist
interpretation by insisting that people be willing to bet on their beliefs.
2.3.2
The Different Kinds of Probability
In tracing the historical development of probability we have seen that it has had various inter-
pretations, starting from Bernoulli’s notion of probability as a part of certainty, to De Moivre’s
equally likely cases, Laplace’s degree of knowledge, the empiricists’ relative frequency and
finally to the subjectivists’ degree of belief. This has prompted many, like Good (1950) and
Savage (1954), to classify the different kinds of probability, and to discuss the nature of each.
The purpose of this section is to examine this classification, so that the relevance of each type
to problems in reliability, risk and survival analysis can be judged; see, for example, Bement,
Booker, Keller-McNulty and Singpurwalla (2003). Following Good (1965, p. 6), we shall broadly
classify probabilities as being either logical, physical, or psychological, with some having further
sub-classifications. The former two are called objective probabilities, and the third is called
epistemological probability.
Logical Probability
A logical probability (or what is also known as credibility) is a rational intensity of conviction,
implicit in the given information such that if a person does not agree with it, the person is
1 Though it was Kolmogorov (1963) who stated: ‘The frequency concept, based on the notion of limiting frequency as the number
of trials increases to infinity, does not contribute anything to substantiate the applicability of the results of probability theory to
real practical problems where we have always to deal with a finite number of trials. The frequency concept applied to a large but
finite number of trials does not admit a rigorous formal exposition within the framework of pure mathematics’.

OVERVIEW OF THE DIFFERENT INTERPRETATIONS OF PROBABILITY
17
wrong. This notion of probability has its roots in antiquity (cf. Savage, 1972); its more recent
leading proponents have been Carnap (1950), Jeffreys (1961) and Keynes (1921), all of whom
formulated theories in which credibilities were central. Savage (1972) calls this the ‘necessary’ or
the ‘symmetry’ concept of probability and does not subscribe to its existence. According to this
concept, there is one and only one opinion justified by any body of evidence, so that probability
is an objective logical relationship between an event  and evidence . Savage and also Good
claim that both Keynes and Carnap have, in the latter parts of their work, either renounced this
notion or have tempered it. The logical probability concept has not been popular with statisticians,
though Jeffreys has used it to address many practical problems. Other objections to this notion
of probability have recently been raised by Shafer (1991). Cowell et al. (1999) claim that no
satisfactory theory or method for the evaluation of logical probabilities has yet been devised.
Physical Probability
A physical probability (also called propensity, material probability, intrinsic probability or
chance) is a probability that is an intrinsic property of the material world, just like density, mass
or specific gravity, and it exists irrespective of minds and logic. Many people subscribe to the
existence of such probabilities, especially those who, following Venn (1866) and von Mises
(1939), interpret probability as a relative frequency. This happens to be the majority of statis-
ticians; the influential Neyman–Pearson approach to statistical inference is based on a relative
frequency interpretation of probability (Neyman and Pearson, 1967). The words ‘frequentist’ or
‘frequentist statistics’ are often used to describe such statisticians (and their procedures). Much
of the current literature in reliability and survival analysis, including several government stan-
dards for acceptance sampling and drug approval, has been developed under the paradigm that
probability is a relative frequency. Here, the probability of an event is the long-run frequency
with which the event occurs in a certain experimental setup or a certain population. Specifically,
suppose that a certain experiment is performed n times under ‘almost identical’ conditions, and
suppose that an event of interest  occurs in k of the n trials of the experiment. Then the relative
frequency of the event  is the ratio k/n. If as n increases, this ratio converges to a number,
say p, then p is defined to be the probability of the event .
There have been several criticisms of this interpretation of probability. For one, the concept
is applicable to only those situations for which we can conceive of a repeatable experiment.
This excludes many ordinary isolated events, such as the release of radioactivity at a nuclear
power plant, the guilt or innocence of an accused individual, or the risk of commissioning a
newly designed aircraft or a newly developed medical procedure. There are many events in
our daily lives whose probabilities we would like to know, but these probabilities would not
be available in the frequency sense. Another objection to this notion of probability is that the
conditions under which the repeatable experiments are to be performed are not clear. What does
it mean to say that the experiments are to be performed under almost identical conditions? If
they are performed under exactly identical conditions we will always get the same outcome, and
the ratio k/n will equal to 1 or 0. How much deviation should we allow from the conduct of
one experiment to the next? Finally, how large should n be allowed to get before the limit p
is obtained, and how close to p should the ratio k/n get? Whereas the relative frequency view
of probability makes Kolmogorov’s axioms easy to justify, there are still some concerns about
the adequacy of this point of view for interpreting conditional probability and independence
(cf. Shafer, 1991). Kolmogorov simply defined conditional probability as the ratio of two
unconditional probabilities, but offered no interpretation that could be used to assess conditional
probabilities directly. A consequence is our inability to interpret the law of total probability,
mentioned in section 2.4. These and other concerns, such as inadmissibility (cf. Basu, 1975;
Cornfield, 1969; Efron, 1978), have recently caused many statisticians, and also others, such
as economists, engineers, and operation research analysts, to rethink this empiricist view of

18
THE QUANTIFICATION OF UNCERTAINTY
probability, and to explore other alternatives. In this book, we will not subscribe to the relative
frequency interpretation of probability (footnote 2); this is a feature that distinguishes this work
in reliability from that of the others.
Psychological Probability
A psychological probability is a degree of belief or intensity of conviction that is used for betting,
or making decisions, not necessarily with an attempt at being consistent with our other opinions.
When a person uses a consistent set of psychological probabilities, then these probabilities are
called subjective probabilities; see below. A consistent set of probabilities is one against which
it is not possible for an opponent to make a selection of bets against which you are bound to loose,
no matter what happens. Both de Finetti (1937) and Savage (1972) regard subjective probability
as the only notion of probability that is defensible, and most Bayesian statisticians subscribe to
this notion of probability. Savage (1972) calls subjective probability personal probability, and
describes it as a certain kind of numerical measure of the opinions of somebody about something.
The point of view of probability that we strive to adopt here is subjective or personal; thus it
behooves us to elaborate on this notion and to discuss its pros and cons.
Making Personal (or Subjective) Probability Operational
The notion of a personal probability of an event was made operational by de Finetti (1937),
who defined it as the price that you would pay in return for a unit of payment to you in case
the event actually occurs. Thus, for example, if you declared that your personal probability for
some event, say , is .75, then this means that you are willing to put $0.75 on the table on ,
if the person you are betting with is willing to put $0.25 on the table against . If the event 
occurs, you win the other person’s $0.25; if  does not occur, you lose your $0.75 to the other
person. Put another way, when you declare that your personal probability for an event  is .75,
then you are de facto paying $0.75 for a ticket that returns $1 if  happens. It is important to
recognize that in taking the above bet, you are also willing to take the other side of the bet. That
is, you are willing to paying $0.25 for a ticket that returns $1 if  does not happen. Therefore,
according to de Finetti, the probability of a proposition is the price at which you are neutral
between buying and selling a ticket that is worth $1 if the proposition is true, and is worthless
otherwise. Alternatively put, probability is a two-sided bet. Since there is no physically realizable
way to exchange more than a finite number of dollars, de Finetti insisted that the number of
transactions be limited to a finite number of sales and purchases. Finally, even though we used
the US monetary unit of a dollar to illustrate the mechanics of betting, the basic requirement of
de Finetti is that the betting be done in terms of any desirable monetary unit. A consequence is
that probability is a unitless quantity. This feature is germane to the material of section 4.4.
Probabilities and odds on (odds against) are related. Specifically, when we say that the odds
on (against) an event  are x to y, we are implying that we are willing to pay an amount xy
now, in exchange for an amount x +y should  occur. The odds of x to y on are the same as the
odds y to x against. Thus, probabilities and odds are related in the sense that the odds against an
event  are 1 −P/P and P = y/x + y. Consequently, we can change from odds
to probability and vice versa (Lindley, 1985).
Conditional probabilities can also be made operational via the above betting scheme. Specif-
ically, suppose that our knowledge of an event  were to precede our knowledge of an event
. Then the conditional probability P   is the degree to which you currently believe
in  if in addition to  you were also to learn that  has occurred. That is, it is the amount
you are willing to pay now for a $1 ticket on  right after  happens, but with the provision
that all bets are off if  does not happen. Finally, the notion of independent events can be easily
explained in the context of bets. To say that any two events  and  are independent means that
a knowledge of the occurrence or the non-occurrence of  will not change our bets on , and

LAW OF TOTAL PROBABILITY AND BAYES’ LAW
19
vice versa. That is, the probability we would assign to the event  will be the same, irrespective
of us being informed of whether  has occurred or not occurred.
Since there is no such thing as the right amount that one should put on the table, personal
or subjective probabilities are not objective. However, employing personal probabilities requires
one to be honest with oneself, in the sense that it takes a lot of self-discipline not to exaggerate
the probabilities that one would have attached to any hypotheses before they were suggested.
Also, when we theorize about personal probabilities, we theorize about opinions generated by
a ‘coherent person’, that is a person who does not allow book to be made against them. By
making a book against a person we mean that if we offered this person various contingencies we
can, by some sleight of hand, sell a bill of goods such that the person will be paying us money
no matter what happens. A coherent person is one who declares personal probabilities that are
consistent, and personal probabilities will be consistent if they are coherent, as defined at the
end of section 2.2.1.
There are other aspects of personal probability that are important to note. The first is that
personal probabilities, all of them, are always relative to one’s state of knowledge. That is, their
specification at any time  depends on the background information  that we have at . If 
were to be different, our specified personal probability is also likely to be different. When 
changes with the passage of time, either due to added knowledge or due to actual data, the personal
probabilities may also change. Bayes’ law, which will be discussed later, gives us a prescription
of precisely how to change our personal probability in light of new information to include new
data. Contrast this to probabilities based on relative frequencies; they, being independent of minds
and logic, are always absolute. The second point to note is that the notion of personal probability
encompasses the logical probability notion of symmetry (or equally likely cases) considered by
De Moivre and others. The reason is that symmetry is a judgment, and is therefore personal or
subjective. It is physically impossible to make coins and dice that are perfectly symmetrical, so
the judgment of symmetry is one of practical convenience, and thus personal. Furthermore, to say
that something is symmetrical or equally likely implies that it is equally probable, and to define
probability in terms of its likeliness could be viewed as circular reasoning. Thirdly, the notion
of personal probability does not exclude from consideration information pertaining to relative
frequency; it simply incorporates frequencies into the background information . Our final point
pertains to the issue of consistency and coherence into the specification of personal probabilities.
This may be difficult to enforce in real life, and psychologists such as Tversky and Kahneman
(1986) have given many examples showing that people do not conform to the rules of probability
in their actual behavior. Consequently, some regard the theory of personal probability and the
rules of probability (i.e. the Kolmogorov axioms) as being primarily a normative theory –
that is, a theory which prescribes rules by which we ought to behave or strive to behave and
not by which we actually behave. For a discourse on the elicitation of personal probabilities
(Savage, 1971).
2.4
EXTENDING THE RULES OF PROBABILITY: LAW OF TOTAL
PROBABILITY AND BAYES’ LAW
Mathematical probability theory deals with developing the necessary techniques for calculating
the probabilities of complicated events based on probabilities of simpler events. The theory
per se does not concern itself with the interpretation of probability. Of course, when one uses
probability for addressing a specific problem and for communicating the result to others, the
interpretation of probability becomes crucial. The foundation for the theory is the three rules,
or axioms, that were given in section 2.2.1. From these, several other rules can be derived, of
which two stand out as being important. The first is the law of total probability, and the second

20
THE QUANTIFICATION OF UNCERTAINTY
is Bayes’ law. For reasons that will be explained later, the law of total probability is also known
as the law of the extension of conversation. As a historical note, it appears to be likely (Stigler,
1983) that Thomas Bayes (1702–1761) may not have been the one to derive the law that bears
his name; it could have been a Cambridge mathematician by the name of Saunderson. However,
Laplace (1774), unaware of Bayes’ earlier work, is often credited with both Bayes’ law (or
what is also known as the law of inverse probability) and the law of total probability (Stigler,
1986). In this section, we motivate and develop these laws using the notation and terminology
of sections 2.1 and 2.2, except that here X is generic and not restricted to denoting only random
events.
With respect to the introductory material of section 2.1, we note that in general, X and 
should embrace all that we don’t know and do know, and so they could be multidimensional and
continuous. However, in the interest of simplifying matters, we shall assume X to be discrete,
so that we may use summation instead of the more general integration.
2.4.1
Marginalization
Suppose that an outcome X is a vector that can be partitioned as X1 and X2, and it is only an
appreciation of X1 (in light of ) that is of concern to us. For example, suppose that X denotes
the size of the next person that we encounter, with X1 and X2 denoting the person’s height and
weight respectively. Then, by the addition rule of probability, we can easily verify the marginal
distribution of X1 as
PX1 =

X2
PX1X2
where 
X2 denotes the summation over all values, say x2, that X2 can take. We may now state
2.4.2
The Law of Total Probability
Applying the multiplication rule to the right-hand side of the previous expression, we see that
PX1 =

X2
PX1  X2 PX2
which is the law of total probability. This law is also known as the law of the extension of
conversation because it suggests that when required to assess our uncertainty about X1 in the
light of  alone, we may find it easier to assess X1 if, in addition to , X2 were also known;
that is, we have extended our discussion from  to both X2 and . As an illustration of the
use of this law, suppose that a scientist was asked to assess the temperature at a certain spot on
another planet given all the relevant information  that we currently have. Now it is possible
that the scientist may find it easier to assess the temperature if additional information X2, say the
thermometer readings on a space probe, were also available. However, since X2 is not available,
we weight the scientist’s assessment of X1 under both X2 and , by the last term of the above
law, and sum over all possible values that X2 can take. The law of total probability plays a key
role in our development of probability models; this will be seen later, in section 2.6.
2.4.3
Bayes’ Law: The Incorporation of Evidence and the Likelihood
Experimentation, observation and data collection are some of the most important tools of science.
Their purpose is to expand the background information because quantities that were previously
unknown now become known. Let X1 and X2 be two unknown quantities, and suppose that the
background information is . Let PX1 X2 describe our uncertainty about X1 and X2, and

LAW OF TOTAL PROBABILITY AND BAYES’ LAW
21
suppose now that the previously unknown quantity X2 were to become known, but in actuality,
it is not known. Then by an application of the multiplication rule, our appreciation of X1, were
we to know X2 and also , would be given by
PX1  X2 = PX1X2
PX2
	
However, by the marginalization rule, PX2 = 
X1 PX1 X2, and so
PX1  X2 =
PX1X2

X1
PX1X2	
The above relationship provides a prescription for passing from our original uncertainty about
both X1 and X2 to only that of X1, were X2 to become known. It tells us how we should
incorporate the observation X2 into our appreciation of X1. Applying the multiplication rule to
the numerator and the denominator of the above expression, we get
PX1  X2 =
PX2  X1 PX1

X1
PX2  X1 PX1
(2.1)
which is known as Bayes’ Rule, or the law of inverse probability; the latter name is a conse-
quence of the fact that the positions of X1 and X2 get reversed as we go from the left-hand side
of (2.1) to its right-hand side.
Bayes’ Rule, as another rule of probability, is a straightforward mathematical result. In essence,
the rule also follows as a theorem from the assumption of coherence and the subjective inter-
pretation of conditional probability; however, Hacking (1975) disagrees and sees the law as an
assumption. Since the denominator of (2.1) can be interpreted as a normalizing constant, i.e. a
constant whose role is to ensure that PX1  X2 is between zero and one, we may rewrite
(2.1) as
PX1  X2 ∝PX2  X1 PX1
(2.1a)
where ‘∝’ indicates proportionality.
A use of Bayes’ Rule as a vehicle of statistical inference and data analysis (see, for example,
Gelman et al., 1995) has raised issues that are the subject of much debate. To indicate the nature
of some aspects of this debate, suppose that X2 has in actuality revealed itself as say x2. Then
what can we say about X1 in the light of x2 and ? Alternatively put, how should we update
our quantification of uncertainty about X1 from PX1 to PX1x2?
One possibility is to simply re-assess X1 in light of both x2 and . That is, to make x2 a
part of . Let us denote this assessment as P∗X1. The second possibility is based on the
notion that prior to observing x2 we had said – using Bayes’ Rule – that were X2 to reveal itself
as x2, we would use (2.1) to describe our uncertainty about X1. We are now obliged to do what
we have said we will do, and so now
PX1 = x1x2 ∝PX2 = x2  X1 = x1 PX1 = x1	
(2.2)
When P∗X1 = PX1 = x1x2, we say that the principle of conditionalization has
been invoked (Howson and Urbach, 1989, p. 68). Thus implicit in the use of Bayes’ Law, (2.1) is
an adherence to the principle of conditionalization. However, it is not mandatory that the principle

22
THE QUANTIFICATION OF UNCERTAINTY
of conditionalization be upheld. There is precedence from quantum mechanics for violating this
principle. Specifically, in the famous ‘double slit experiment’2 it has been experimentally shown
that the probability of some event, say B, when an event A always occurs is not equal to the
conditional probability of B given A found from an experiment in which A occurs in some
replications and the complement of A occurs in other replications.
Equation (2.2) relates the two uncertainties about X1PX1 =x1 which is prior to observing
x2 and PX1 =x1x2 which is posterior to observing x2, via the term PX2 =x2  X1 =x1.
Since X2 has been observed as x2, and since probability makes sense only for unknown entities,
PX2 =x2 X1 =x1 should not be interpreted as a probability; consequently, it need not obey
the rules of probability given in section 2.2.1. It is for this reason that PX2 =x2  X1 =x1 is
called the likelihood of X1 = x which for a fixed (observed) value of X2 = x2. The likelihood is
to be interpreted as a weight that is assigned to PX1 =x1, our uncertainty about X1 (prior to
observing x2), for describing our uncertainty about X1 subsequent to observing x2. The likelihood
shows us the role of the data (new information) in relating our prior and posterior uncertainties
about X1. Since X1 is unknown, and X2 is observed as x2, PX2 =x2  X1 =x1 can be viewed
as a function of x1 for a fixed x2 (and ). This function is known as the likelihood function
of X1 for a fixed x2, and can be interpreted as a weight function. It is convenient to denote the
likelihood function PX2 = x2  X1 = x1 by x1x2. The likelihood, originally noted
by Gauss and rediscovered by Fisher, can be interpreted as a scale of comparative support lent
by the known x2 to the various possible values of the unknown X1 (Singpurwalla, 2002). Finally
note that, in the above, it is only x2 that matters and not the other possible values that X2 could
have taken; these are irrelevant. For this reason, the likelihood is said to be sufficient. The above
feature constitutes the essence of what is known as the likelihood principle, more about which
is in Berger and Wolpert (1988).
2.5
THE BAYESIAN PARADIGM: A PRESCRIPTION FOR RELIABILITY,
RISK AND SURVIVAL ANALYSIS
The Bayesian paradigm for statistical inference and noncompetitive decision making is straight-
forward to enunciate. Essentially, it is a probabilistic view of the world which says that all
uncertainty should only be described by probability and its calculus, and that probability is
personal or subjective. Statisticians who subscribe to this paradigm are called Bayesians, and
Bayesian statistics (or procedures) are statistical techniques developed in adherence to the
Bayesian paradigm.
The formal use of Bayes’ law is simply one aspect of the Bayesian paradigm. A mere use
of this law or a use of background information does not necessarily imply an adherence to the
Bayesian paradigm. A deeper characterization of the Bayesian paradigm is the exploitation and
systematic use of the concept of subjective or personal probability. This provides a framework for
statistics and decision making that is complete, logical and unified. Adherence to this paradigm
eliminates from consideration other ways of describing uncertainty, such as by confidence limits,
maximum likelihood estimation, significance levels and hypothesis testing with Type I and
Type II errors, not to mention alternate ways of describing and combining uncertainties such
as by Zadeh’s (1979) possibility theory, by Jeffrey’s Rule of Combination (R. Jeffrey, 1965)
and by Dempster’s Rule of Combination (Dempster, 1968). Some of the above procedures, in
considering data that would have been observed but was not, do not adhere to the likelihood
principle.
2 I wish to thank Professor J.K. Ghosh for drawing my attention to the double split experiment.

PROBABILITY MODELS, PARAMETERS, INFERENCE AND PREDICTION
23
Why is the above paradigm relevant for problems of reliability, risk and survival anal-
ysis? From a philosophical point of view, the answer is a natural one: that the Bayesian
paradigm is founded on the logical framework of the calculus of probability. From a
pragmatic point of view, one may say that, in risk analysis, we are often dealing with
one-of-a-kind situations so the notion of relative frequency is not always relevant (Bement,
Booker and Singpurwalla, 2002; and Singpurwalla, 2002). Another argument is that, many
times, there are no direct previous data to go by so all assessments of uncertainty can
only be based on background information alone; the Bayesian paradigm allows for this.
Finally, risk, reliability and survival analyses are most credibly performed when subject
matter experts are required to play a key role; the Bayesian paradigm enables the formal
incorporation of the expertise of the experts into the analysis, via a consideration of prior
probabilities.
The point of view that we take here is Bayesian. However, we want to qualify what we
are attempting to do with some caution. Even among those who view probability as being
subjective, there have been concerns about the appropriateness of Bayes’ law as a mechanism
for ‘changing one’s mind’. Many of these concerns have to do with the adequacy of conditioning
as an exclusive model for belief revision. Difficulties in updating when new information arises
as a result of introspection, unanticipated knowledge or probable knowledge have been cited.
Diaconis and Zabel (1982), Lane (1987) and Shafer (1981), among others, have written on such
topics and related issues. Some of these concerns go to the heart of the subject by questioning
the nature of the Kolmogorov axioms and the rules of probability (section 2.2.1). Under debate
is also the issue of whether probability needs to be countably additive or only finitely additive. A
consequence is compatibility with improper probabilities, unless the axiom of conglomerability
gets introduced (section 2.2.1). In de Finetti’s theory of personal probability, all that is needed is
finite additivity. Frequentists do not always describe uncertainty by probability, but subscribe to
the Kolmogorov axiomatization of uncertainty. The above difficulties, plus the normative nature
of Bayesian inference, have provided many statisticians a reason for not adopting the Bayesian
paradigm; see, for example, Efron (1986). The concerns of many of these authors are worthy of
consideration.
The material that follows is foundational. It provides a deeper appreciation of some of the
most commonly used techniques in reliability and survival analysis. It should not be viewed as
being detracting.
2.6
PROBABILITY MODELS, PARAMETERS, INFERENCE AND
PREDICTION
Much of the statistical analyses that one encounters, save that which is called ‘exploratory
data analysis’ and ‘computational statistics’, pertain to inference about ‘parameters’; these are
generally denoted by Greek symbols. This is generally true of both Bayesian and frequentist
statistics, and more so with the latter. By statistical inference, we mean statements of uncertainty;
these may entail estimation and the testing of hypotheses. Parameters appear in ‘probability
models’ which have played a key role in both reliability and survival analysis. Examples of
some well-known probability models for continuous random quantities and their parameters are:
the normal distribution with location  and scale 
; the uniform distribution on ; the
exponential distribution with mean ; the Weibull distribution with scale  and shape , and
so on. In this section, we address the important question, where do probability models come
from? With the computer revolution, exploratory data analysis and computational statistics may
be paradigms of the future. However, as of now, they are a form of art, intuition and innovation.
They are therefore not a part of our discussion.

24
THE QUANTIFICATION OF UNCERTAINTY
2.6.1
The Genesis of Probability Models and Their Parameters
We start by considering an uncertain quantity X with background information ; our aim is to
specify PX. In general, the dimensions of X and  could be very large, particularly of ,
since it includes all that we know. We therefore seek ways of simplification. For this, we may
appeal to the law of the extension of conversation and write that, for some unknown quantity 
which we for now assume to take discrete values,
PX =


PX   P	
If we suppose that X is independent of , were we to know , that is if PX  =PX  
abbreviated ‘X ⊥, given ’, then the above expression becomes
PX =


PX   P
(2.3)
 could be vector-valued, and, if it is continuous, an integral would replace the summation. When
PX   = PX   for all values of , X is said to be conditionally (given ) independent
of .
The term PX   is known as a probability model for X with a parameter , and the term
P is known as the prior distribution for . If the dimensions of  are smaller than the
dimensions of , then the specification of the probability model is a simpler task than the
specification of PX. The assumption of independence is crucial, since it says that were
we to know , we need not keep track of . It is important to note that, like probability,
independence is also a judgment; it is always conditional (in our case, conditional on ).
Probability models play a central role in statistic, both frequentist and Bayesian. There are no
restrictions on the functional form that PX   can take, other than the fact that it must obey the
rules of probability. The choice of a model is subjective, and from the point of view of personal
probability, the notion of a ‘true probability model’ is as elusive as that of a ‘right bet’. Often, our
choice of the model is dictated by the nature of the problem that is being studied. For example,
in reliability and biometry, where probability models are called failure models or lifelength
models, the notion of ‘aging’ is used to specify a model, or sometimes the model is based on
a probabilistic description of the physics of failure of the item (cf. Singpurwalla, 1988a; 2002).
Often, models such as the Bernoulli, the multinomial, the Poisson, etc., are justified as ‘chance
distributions’ that arise as a consequence of the judgment of ‘exchangeability’ (Chapter 3). More
recently, the ‘principle of indifference’ (Barlow and Mendel, 1992) has been used to motivate
the use of failure models such as the exponential, the gamma and the Weibull. The principle of
indifference has its roots in the work of Laplace, who used the notion of ‘insufficient reason’
to convert ignorance to a uniform distribution of prior probabilities. Non-parametric analysis
pertains to the scenario wherein one is reluctant to specify the probability model PX  ;
Hollander and Wolfe (1972) give a readable account of such analysis.
Regarding the parameter , we have seen that it was introduced as a mathematical device
with the aim of simplifying our probability specifications. However, it was understood that even
though  may not be observable, as typically is the case, it influences the observable X, upon
which bets can be made and gambles settled. The above interpretation of a parameter, as a
summarization of the background information , though simple to appreciate, is naive. A more
satisfying interpretation of parameters (cf. Hill, 1993) comes from de Finetti’s theorem about
‘exchangeable sequences’, a topic discussed in Chapter 3; there, parameters are seen as limits of
some functions of observable sequences. Section 4.4 contains a discussion about the nature of
the units of measurement for parameters in probability models.

PROBABILITY MODELS, PARAMETERS, INFERENCE AND PREDICTION
25
Observe that in (2.3), the prior distribution P has arisen naturally, as a consequence of
the laws of probability. Whereas subjectivity in the specification of probability models has not
been the center of debate, the specification of the prior has been; it is the bone of contention for
many frequentists. Consequently, they have chosen to drop the last term of (2.3) and to base their
analysis on the probability model alone; see Singpurwalla (2001) for a discussion of the genesis
of failure models in a frequentist’s approach to reliability analysis. Several strategies for choosing
the prior have been proposed (cf. Berger, 1985; or Kass and Wasserman, 1996) and these range
from choosing the ‘natural conjugate priors’ (section 5.4.7) to priors that are ‘objective’, such
as the reference priors, the indifference priors, robust priors and so on (sections 5.2 and 5.3).
The dialogue with Bernardo (1997) provides an informative overview. Whereas such ‘neutral’
priors used by none other than Bayes, Laplace and Jeffreys are germane when dealing with
issues pertaining to public policy and scientific inquiries, some Bayesians object to a choice
of automated priors because they violate the spirit of a truly subjective approach. Instead, they
advocate priors based on expert testimonies; see, for example, Lindley and Singpurwalla (1986),
and the references therein.
In the above development, a probability model was motivated via a consideration of a single
random quantity X. This can be extended for the case of two or more random quantities by
following a parallel line of reasoning. To see how, consider two random quantities, X1 and X2,
and suppose that we are interested in assessing our uncertainty about them in the light of .
Then, for any random quantity , we have, by the law of the extension of conversation,
PX1X2 =


PX1 X2  P
which by the multiplication rule of probability can be written as
PX1X2 =


P1X1  X2P2X2  P
where the suffixes associated with the Ps reflect the fact that assessed probabilities could have
different functional forms. If we assume, as is commonly done, that X2 ⊥, given , and that
X1 ⊥X2 ⊥, given , then simplification results. As a consequence, we have
PX1 X2 =


P1X1  P2X2  P	
Observe that the role of  has been to stand not only between X2 and  and give them the
property of independence, but also between X2 and X1 and make them independent. In essence,
these assumptions imply that, were  to be known, the uncertainty of any random quantity can
be described without an appreciation of the background information  or the revealed values
of the other random quantities.
A further simplification that is often made in practice is to assume that PiXi  =fXi   i=
1 2; that is, X1 and X2 are ‘identically distributed’. When this is done,
PX1X2 =


fX1  fX2  P
and generalizing to the case on n random quantities Xn = X1X2   Xn, we have
PXn =


n
i=1
fXi  P
(2.4)

26
THE QUANTIFICATION OF UNCERTAINTY
which is a convenient starting point for discussing inference about  and predictions about
observables. An expansion of the P of (2.4) via the total law of probability produces
what are known as hierarchical models (section 6.1). Such models have proved to be useful for
addressing a large class of problems in reliability.
2.6.2
Statistical Inference and Probabilistic Prediction
With reference to (2.4), the frequentist approach to statistics focuses attention only on
n
i=1 fXi   and generally emphasizes estimation and hypotheses testing about . By con-
trast, the Bayesian approach considers the entire right-hand side of (2.4), and emphasis is
placed on PXn+1xn, the predictive distribution of the future observable, in light of
xn = x1   xn, where xi is the observed value of Xi i = 1   n, and . The predictive
distribution is a statement of uncertainty about a future observation, in light of all the previous
information including the data xn. However, in order to be able to assess PXn+1xn
efficiently, we need to obtain Pxn, the posterior distribution of  in the light of xn
and . The posterior distribution of  is a statement of uncertainty about , posterior to xn,
and in the Bayesian paradigm is indeed the estimation of . Furthermore, as we shall see later
in section 2.7, Pxn plays a key role for testing hypotheses about .
To see how the above works, we start with a consideration of the quantity PXn+1  Xn and
note that by the law of the extension of conversation and the usual assumptions of independence
PXn+1  Xn =


fXn+1   P  Xn
(2.5)
where the first term on the right-hand side of (2.5) is a consequence of the assumption that
Xn+1 ⊥Xn given . In order to assess P  Xn, we invoke Bayes’ law so that
P  Xn ∝
n
i=1
fXi   P	
(2.6)
When the Xi’s get revealed as xi i = 1   n Xn gets replaced by xn, and the left-hand
terms of (2.5) and (2.6) become PXn+1 xn and P xn, respectively. However, the
product term on the right-hand side of (2.6) is no longer a probability. Rather, it is the likelihood
xn, which, as a function of , is the likelihood function of the unknown  for a fixed xn.
Thus, to summarize, the predictive distribution of Xn+1 in light of xn and  is given as
PXn+1xn ∝


fXn+1   xn P
(2.7)
so that, once the prior distribution P and the likelihood function xn are specified,
the problem of inference about  and prediction of Xn+1 can be addressed in a unified manner.
It has been a common practice to specify the function xn via the functional form that
is adopted for fXn+1  . For example, if fx   = e−x, then xn is taken to be
n exp− n
i=1 xi. However, there is nothing in the subjectivistic theme which requires that
the likelihood be based on the probability model. That is, an adherence to the principle of
conditionalization is not mandatory (section 2.4.3). Since the likelihood function describes the
relative support that the data xn provides to the various values of  (in the opinion of the assessor
of probabilities), one is free to choose any functional form for xn. The symmetric form
illustrated above is one of convenience. This flexibility, namely that of being able to divorce the
likelihood from the model, is not available within the frequentist paradigm (Singpurwalla, 2002).

TESTING HYPOTHESES: POSTERIOR ODDS AND BAYES FACTORS
27
The development leading to (2.7) above can be easily generalized to cover the case of predicting
m future observations, Xn+1   Xn+m, in light of xn and . It is easy to verify – the details
left as an exercise for the reader – that
PXn+1    Xn+mxn ∝


m
n+1
fXi   xn P	
The predictive approach in Bayesian statistical inference has been comprehensively treated by
Geisser (1993); also see San Martini and Spezzaferri (1974).
Before closing this section, we need to highlight two important matters. The first pertains to
the fact that the predictivity of Xn+1 given Xn – see (2.5) – assumes that all the observations
bear a relationship to each other, so that a knowledge of Xn enhances an appreciation of Xn+1.
The notion that makes this idea concrete is that of exchangeability; this notion, overviewed in
Chapter 3, is due to de Finetti. For now it suffices to say that the random quantities X1   Xn+1
are judged exchangeable if they can be represented in the form of (2.5). Like the notion of
independence, exchangeability is a judgment. The second matter pertains to the fact that in (2.6),
if there was any value of , say ∗, for which P∗ was zero, then no amount of evidence
provided by xn would be able to change the result that P∗xn should also be zero. To
avoid this scenario (namely an inability to change one’s opinion in light of glaring evidence),
zero prior probabilities should not be assigned to discrete quantities – unless this is dictated by
a logical argument – and the probability density should nowhere vanish for quantities that are
continuous. Lindley (1982a) refers to this feature of an unwillingness to assign zero probabilities
as an adherence to Cromwell’s Rule.
2.7
TESTING HYPOTHESES: POSTERIOR ODDS AND BAYES FACTORS
The statistical testing of a hypothesis is usually done to verify a theory or a claim, be it in science,
engineering, law or medicine, in light of evidence or data. We have said that reliability and risk
analysis pertains to decision making under uncertainty. Then why should we be interested in the
topic of testing hypotheses?
There could be many answers to the above question, but the one that immediately comes to
mind pertains to the fact that associated with each action of a decision tree are consequences, and
a consequence could have been entertained as the result of verifying a claim. For example, in
the cholesterol drug problem of Chapter 1, we consider administering a drug because we believe
that the drug has the potential of avoiding a heart attack. How did we arrive upon this belief? It
is most likely that an experiment was conducted on several individuals, some of whom received
the drug and some did not, and the results of this experiment provided evidence to certify the
claim that the drug was effective in avoiding a heart attack. The certification of this claim could
have been based on the test of a hypothesis. Similarly, the claim that the drug has minimal
side effects could have been based on the test of suitable hypotheses. Other such examples of
hypotheses testing in reliability and risk analyses are claims about the improved performance of
an engine in a new design, claims that emergency diesel generators in nuclear power plants have
a reliability that exceeds requirements (cf. Chen and Singpurwalla, 1996), claims that a piece of
computer software is free of bugs (cf. Singpurwalla and Wilson, 1999) and so on. To summarize,
the testing of statistical hypotheses is a part of decision making under uncertainty and as such
plays an important role in reliability, risk and survival analysis. Indeed, one of the most visible
exports of statistical reliability theory is the Military Standard 781-C, which is used worldwide
for life-testing and acceptance sampling. Its theoretical basis is in the testing of hypothesis about
the mean of an exponential distribution (cf. Montagne and Singpurwalla, 1985).

28
THE QUANTIFICATION OF UNCERTAINTY
Because the testing of hypothesis is an important scientific problem, much has been written
about it, starting from the days of Laplace. Lehmann (1950) gives an authoritative account of the
frequentist treatment of this topic. However, Berger and Berry (1988) are critical of frequentist
methods for testing hypotheses, their criticism centering upon a violation of the likelihood
principle. A review article by Berger and Delampady (1987) proposes Bayesian alternatives. The
book by Lee (1989), from which much of the material that follows is taken, provides a nice
account of Bayesian hypothesis testing.
We begin with the following setup. Consider an unknown quantity X, discrete or continuous,
and ignoring technicalities, suppose that PX   is a suitable probability model for X, where
the parameter  belongs to the set ; i.e.  ∈. Let P be our prior distribution for ,
assuming that  is discrete. Suppose that  = 0 ∪1, with 0 ∩1 = ∅, where ∪ ∩and ∅
denoting union, intersection and the empty (null) set, respectively. That is, the parameter set 
is partitioned into two non-overlapping sets of 0 and 1. Suppose now that X has revealed
itself as x. The problem that we wish to entertain is that, given x and , does  ∈0 or does
 ∈1? In the context of any particular application,  ∈0 could correspond to the validity of a
claim, and  ∈1, its negation, i.e. the falsity of the claim.
The premise behind a Bayesian approach to testing a hypothesis is that it is unreasonable,
except in rare situations, that x gives us conclusive evidence about the disposition of . However,
x could give us evidence that enhances our prior opinion about H0, the null hypothesis, that
 ∈0, or about H1, the alternate hypothesis, that  ∈1. Bayes’ law enables us to incorporate
the evidence provided by x. To see how, let 0 = P ∈0 and 1 = 1 −0 be our prior
probabilities, and consider the quantity 0/1, which is our prior odds on H0 against H1; the
prior probabilities are obtained via our prior distribution P. The notion of odds is useful
because if the prior odds is close to one, we regard H0 and H1 to be equally likely, whereas if
the ratio is large, then we regard H0 to be more likely than H1; vice versa if the ratio is small.
Given x, Bayes’ law is used to compute the posterior probabilities p0 = P ∈0x ∝
 ∈0x0, and p1 = P ∈1x ∝ ∈1x1, where  ∈0x
is the likelihood that  ∈0, in light of x and . The posterior odds p0/p1 are analogously
interpreted as the prior odds. It is easy to verify that
p0
p1
=  ∈0x
 ∈1x
0
1
	
The above development was initiated by Jeffreys in the 1920s (Jeffreys, 1961) as an approach
to testing hypotheses.
2.7.1
Bayes Factors: Weight of Evidence and Change in Odds
The absence of evidence is not evidence of absence.
Simple Hypotheses
Suppose that the two hypotheses are simple; i.e.0 = 0 and 1 = 1, for some singletons
0 ̸= 1. Then the posterior odds on H0 against H1 will be of the form
p0
p1
= 0x
1x
0
1

implying that the posterior odds are the prior odds multiplied by the middle term, which is called
the Bayes factor  in favor of H0 against H1. Thus  is simply the ratio of the likelihoods under
H0 and H1. Alternatively,

TESTING HYPOTHESES: POSTERIOR ODDS AND BAYES FACTORS
29
 = p0/p1
0/1
= Posterior odds (on H0 against H1
Prior odds (on H0 against H1

this terminology is due to Good (1950), who attributed the method to Turing, in addition to and
independently of Jeffreys.
If, 0 = 1 = 1/2, then 0/1 = 1, and now  = p0/p1, the posterior odds on H0 against H1.
Since  is the ratio of likelihoods (when the hypotheses are simple), the Bayes factor gives the
odds on H0 against H1, in light of the data x.
Composite Hypotheses
When  is continuous, one (or both) of the two hypotheses H0 and H1 will be composite.
Composite hypotheses are of interest in reliability and life-testing whenever concerns center
around items satisfying requirements, like the mean time to failure should exceed a specified
number, or the failure rate should not exceed a specified number, and so on. Indeed MIL-STD-
781C mentioned before pertains to the testing of composite hypotheses.
Suppose that  is continuous and let f denote its probability density at . Then, the
prior probabilities 0 and 1, mentioned before, are:
0 =

∈0
fd and 1 =

∈1
fd	
Let 0 and 1 denote the restriction of f on 0 and 1, respectively, re-normalized
so that they are probability density functions. That is,
0 = f
0
 for  ∈0 and
1 = f
1
 for  ∈1	
Given x, the posterior probability of H0 is
p0 = P ∈0x ∝

∈0 x fd
=

∈0 x 00d	
Similarly,
p1 ∝

∈1
x11d
so that the posterior odds on H0 against H1 is
p0
p1
= 0
1

∈0 x0d

∈1 x1d	
Thus in the case of composite hypotheses, the Bayes factor  in favor of H0 against H1 is
 = p0/p1
0/1
=

∈0 x0d

∈1 x1d	

30
THE QUANTIFICATION OF UNCERTAINTY
The above suggests that, in the case of composite hypotheses, the Bayes factor is the ratio
of weighted likelihoods, with weights 0 and 1. This is in contrast to the structure of
the Bayes factor when the hypotheses are simple; there,  was solely determined by the data
(and the assumed model) irrespective of the prior. In the composite hypotheses case, the prior
enters into the construction of the Bayes factor via the weights 0 and 1; it is not solely
determined by the data.
Point (or Sharp) Null Hypotheses
Point null hypotheses are particularly useful when one wishes to test a theory or a claim,
such as ‘aspirin cures headaches’. Other examples were given at the beginning of this
section. Point null hypotheses are characterized by the fact that even though  can take
continuous values, 0 is simple (say 0 = 0, and 1 is the complement of 0. The
prior distribution of  f, is such that a point mass 0 ≥0 is assigned to 0 and the
rest, 1 = 1 −0, is spread over the remaining values of ̸= 0 according to a probability
density function 11, where 1 integrates to one. It is usual to choose 0 = 1/2, and
1 to be uniform, so that all the values of , save 0, receive equal prior probability
(cf. Lindley, 1957a).
Given x, the Bayesian approach for testing H0   = 0 versus the alternative H1   ̸= 0,
proceeds along the lines outlined before. However, in this case the Bayesian conclusions
often differ quite substantially from those obtained by frequentist methods. This disparity has
sometimes been referred to as the ‘Jeffreys Paradox’ (cf. Jeffreys, 1961) or as ‘Lindley’s
Paradox’ (cf. Shafer, 1982a). The discussion by Hill (1982) in Shafer (1982a) provides insights
about the nature of this paradox.
Verify that the posterior probabilities for H0 and H1 are:
p0 =
0x0
0x0 + ℓ1x1
= 0x0
ℓx
and
p1 = 1ℓ1x
ℓx
where
ℓ1x =

1xd and ℓx = 0x0 + ℓ1x1	
Thus, for the case of a sharp null hypothesis, the Bayes factor  is of the form
 = p0/p1
0/1
= 0x
ℓ1x
	
2.7.2
Uses of the Bayes Factor
Good (1950) refers to the logarithm of the Bayes factor as the weight of evidence. His motivation
for considering logarithms is that, if we have several experiments pertaining to the testing of two
simple hypotheses, then the Bayes factors multiply whereas the weights of evidence add. To see
how, consider the two simple hypotheses of section 2.7.1, and suppose that the observed data is
x1. Then, the posterior odds corresponding to x1 are given by
p0
p1
= x10
1


TESTING HYPOTHESES: POSTERIOR ODDS AND BAYES FACTORS
31
where x1 is the Bayes factor based on x1. Now suppose that subsequent to observing x1, we
observe x2. The posterior odds corresponding to x2 will be x2 p0/p1 = x2 x1 0/1.
The Bayes factors multiply, but by taking the logarithms of the prior and the posterior odds, the
weights of evidence would add.
From the material of sections 2.7.1 and 2.7.2, we have seen that
posterior odds = Bayes factor × prior odds.
The above feature has motivated some to claim that the Bayes factor is a summary of the
evidence provided by the data in favor of one scientific theory (represented by a statistical model)
as opposed to another (cf. Kass and Raftery, 1995). Indeed Jeffreys suggests using log10−1 as
evidence against H1 according to the following guidelines: (0 to 0.5) ⇒not worth more than a
bare mention; (0.5 to 1) ⇒substantial; (1 to 2) ⇒strong; and >2⇒decisive. In view of such
guidelines, some Bayesians have declined to specify prior odds, and have chosen to use only
Bayes factors as an alternative to the frequentist’s significance probabilities. Whereas this strat-
egy may be appropriate in the case of simple hypotheses (with 0 = 1 = 1/2), it is not so in the
case of composite hypotheses because, here, the Bayes factor also depends on how the prior mass
is spread over the two hypotheses see (section 2.7.1). In the latter case, the Bayes factor cannot
be interpreted as a summary of the evidence provided by the data alone. Rather, the Bayes factor
measures the change in the odds in favor of the hypothesis when going from the prior to the pos-
terior; see Lindley (1997a), and Lavine and Schervish (1999) for a discussion of this and related
matters. Bayes factors also play a role in the general area of model selection, model comparison
and model monitoring; see the lecture notes by Chipman, George, and McCulloch (2001). Model
selection and model comparison are commonly discussed issues in reliability and failure data
analyses.
2.7.3
Alternatives to Bayes Factors
The foregoing discussion has assumed that the prior distributions used are proper, i.e. they
integrate to one. When using Bayes factors for model choice or for tests of hypotheses, it is
sometimes the case that the prior distributions used are improper. Improper distributions come
into play when one wishes to adopt an impartial stance or when one claims to have little
knowledge of the parameters. A consequence is that the Bayes factor contains an arbitrary ratio,
say c0/c1, where the prior is i=cihi i=01, for a known hi, but an arbitrary, positive
multiplier ci. Thus, when calculating the Bayes factor the ci’s do not cancel, so that c0/c1 appears.
Ways of overcoming this difficulty have been proposed by O’Hagan (1995) via his fractional
Bayes factors, and by Berger and Pericchi (1996) via their intrinsic Bayes factors (IBF). A recent
paper by Ghosh and Samanta (2002) provides a unified derivation of the fractional and intrinsic
Bayes factors and concludes that these factors are close to each other and to certain Bayes factors
based on proper priors.
It is of interest to note that when the probability model PX has a density at x of the
exponential form, namely −1 exp−x/, and we wish to test a point (or sharp) null hypothesis
at 0, the methodology of producing an IBF yields a proper prior, namely f=0/0 +2
[personal communication with James Berger]. The fact that this prior depends on 0, the point
at which the null hypothesis is positioned, makes 0/0 + 2 non-subjective, and therefore
impartial to all those whose interest centers around 0. In the context of estimation and prediction
(section 5.3.2), this prior cannot be called objective, because using it involves anchoring it
around a specific value of , namely 0.

32
THE QUANTIFICATION OF UNCERTAINTY
2.8
UTILITY AS PROBABILITY AND MAXIMIZATION OF EXPECTED
UTILITY
The idea of utilities and their relevance to decision making under uncertainty was introduced in
the context of the cholesterol drug problem of Chapter 1, section 1.4. There, it was stated that
utilities are typically functions of costs incurred as a consequence of a particular decision. In
many standard business and engineering problems, it may be possible to assess meaningful costs
and to transform these to utilities (section 2.8.1). However, there are many decision problems,
especially those in medicine, public policy and safety, in which it is difficult to assign costs to
the outcomes of a decision; examples are pain, suffering, quality of life, pleasure, etc. All the
same, the insurance industry and modern legal practice have used some of these intangibles as
a basis for specifying policies or for litigation, and have succeeded in assigning costs to them.
The above goes to suggest that there needs to be a scale to quantify and measure preferences
that are not monetary. Utilities are indeed such a scale, and they are measured in terms of the
units called utiles. The aim of this section is to overview utility theory, and to argue that sensible
decision making involves choosing the action that will maximize expected utility. Specifically,
we shall point out that utilities are probabilities, that utility cannot be separated from probability,
and that it is the laws of probability that lead us to the ‘principal of maximization of expected
utility’.
The theory of utility can be developed together with that of subjective probability, as was done
by Ramsey (1926) and Savage (1972). A theory of utility that is separate from that of probability,
as long as we are speaking of not too large sums of money, was developed by de Finetti. DeGroot
(1970) gives an excellent account of the axiomatic development of utility theory; also see Hill
(1978). A more recent contribution is by Rubin (1987), who sets up a weak system of axioms
to argue the existence of utilities and point out that utility cannot be separated from the prior.
An intuitive and readable account of the essence of utility theory is given by Lindley (1985),
from which the following material has been abstracted. Readers not interested in foundational
issues pertaining to the notion of utility and those who find the principle of the maximization
of expected utility intuitive, may choose to skip the rest of this section and proceed directly to
the next.
2.8.1
Utility as a Probability
Consider a situation of uncertainty involving m decisions d1   dm, and n uncertain events,
say 1   n. Let pij denote the probability that event i occurs when decision dj is chosen,
i = 1   n j = 1   m. For example, in the cholesterol drug problem of Chapter 1, we had
two decisions  and (), and the six uncertain events shown in Figure 1.1. The probability of the
event [] when the decision chosen is  was denoted by p1. Let Cij be the consequence
of decision di when outcome j occurs. An example of a consequence in the cholesterol drug
problem, when the drug is administered and a heart attack occurs, together with the discomfort
caused by the side effects of the drug, the cost of administering the drug, the pain of suffering
a heart attack, and the difficulties due to the loss of life or a restricted lifestyle because of the
attack. Clearly, this consequence is difficult to quantify in terms of cost alone because several
intangibles are involved. To introduce the notion of a numerical value to the consequences, we
need to have a standard and the means for coherent comparisons to it. The standard is given by
two reference consequences, C and c, where C is such that no other consequence is preferable
to it, and c such that no other consequence is worse than it.
Let us now focus on any consequence Cij and inquire its relationship to C and c. For instance,
is Cij closer to C or to c? To address this issue, we consider an urn with N balls of which U
are black and N −U are white. Suppose that a ball is drawn from the urn at random, and if it

UTILITY AS PROBABILITY AND MAXIMIZATION OF EXPECTED UTILITY
33
is black then C results, and if it is white then c results. Thus we will receive C with a ‘chance’
(not probability) U/N = u, say, and c with a chance 1 −u. We now ask, ‘how does C with
chance u compare with Cij?’ Clearly, if u = 1, then C with chance u is preferable (denoted >∗)
to Cij, and if u = 0 C with chance u, is not preferable (denoted <∗) to Cij. As u increases,
the gamble gets better, and so there is a unique value of u, say u∗, at which the two gambles
(C with chance u∗and Cij) are equally preferable (denoted =∗). To summarize, associated with
every consequence Cij, there is a unique number u∗∈01 such that Cij =∗C with chance u∗
and c with chance 1 −u∗). The number u∗[denoted uCij] is called the utility of Cij. Observe
that Cij >∗Ckl implies that uCij > uCkl, and that Cij =∗Ckl implies that uCij = uCkl.
Since u and u∗are like probabilities, i.e. they obey the rules of probability, we say that utilities
are probabilities and follow the rules of probability. However, whereas probabilities measure our
(personal) uncertainties about events, utilities measure our preferences about the consequences
of events and, like probabilities, are personal and subjective. Furthermore, like the axioms of
probability, the axioms of utility theory (not given here) prescribe normative behavior. Novick
and Lindley (1979) describe a statistical approach for the coherent assessment of utilities (see
also Singpurwalla and Wilson, 2006).
We may ask as to why it is useful to view utilities as probabilities? The answer is that now we
are able to use the laws of probability which tell us how to combine utilities with probabilities
and to arrive upon a paradigm for decision making under uncertainty. This is described next.
2.8.2
Maximization of Expected Utility
To see the role of utility and probability in decision making under uncertainty, consider what
happens if we choose decision di and outcome j occurs. The consequence of this decision–
outcome combination is Cij, which, in line with our discussion of the previous section, suggests
that Cij =∗[C with chance uCij]. Thus, whatever be the outcome of choosing di, we can think
about it in terms of C or c. To reflect this fact [namely that, if we choose di and j occurs, the
probability of obtaining C is uCij], we write
PC  dij = uCij	
However, pij is the probability that j occurs when decision di is chosen. Thus, by the law of
total probability, we have
PC  di =
n
j
PC  dij pij =
n
j
uCij pij
and we must choose that decision for which the above is maximum. The term on the right-hand
side of the above expression is called the expected utility of action di, and the decision problem
is therefore to choose that decision for which the expected utility is maximum. This therefore,
is the principle of maximization of expected utility (MEU).
2.8.3
Attitudes to Risk: The Utility of Money
Making decisions based on the principle of MEU may sometimes lead to decisions that are not
intuitively appealing. This is typically the case when utility is assumed to be linear in monetary
units. As an example, consider the decision to choose between one of the following two lotteries:
in Lottery 1, you win $30 with probability .5 and loose $1 with probability .5; in Lottery 2, you
win $2000 with probability .5 and loose $1900 with probability .5. Assuming that our utility is
a linear function of the amounts won or lost, the MEU principle leads to Lottery 2, because its
expected utility is 2000×	5−1900×	5=50, whereas that of Lottery 1 is 14.5. However, most

34
THE QUANTIFICATION OF UNCERTAINTY
people would prefer Lottery 1 over Lottery 2 because the latter would be viewed as being more
‘risky’ than the former. Such individuals are said to be risk averse, and this attitude toward risk
is best captured by a utility function that is concave in money. If x denotes a monetary unit,
say a dollar, then some commonly used examples of utility functions 	x that are concave are
	x=logx 	x=√x or 	x=1−exp−x/, for some >0, where  is known as the risk
tolerance. The logarithmic form of the utility function was considered by Daniel Bernoulli in
1738 in his resolution of the St. Petersburg paradox. Not everyone displays risk averse behavior,
and so utility curves need not always be concave. Convex utility functions describe risk seeking
or risk proneness, an example of which is participants in state lotteries which typically cost $1
and have an expected value of approximately $0.5. Individuals whose utility function is linear
in x are known as risk neutral. For a general discussion on attitudes to risk and the assessment
of utility functions, see section 4.9 of Keeney and Raiffa (1976).
2.9
DECISION TREES AND INFLUENCE DIAGRAMS FOR RISK
ANALYSIS
We have said before that reliability and risk analyses are the ingredients for decision making
in the face of uncertainty. The cholesterol drug problem of Chapter 1 serves as an illustrative
example. There are several approaches to decision making under uncertainty, some of which
have a statistical foundation (frequentist or Bayesian), and some which are more grounded in
deterministic mathematics. Of the latter, ‘The Analytical Hierarchy Process’ of Saaty (cf. Forman
and Dyer, 1991) seems to have the upper hand. The foundation for a frequentist theory of decision
making was laid out by Wald (1950). Bayesians are critical of this theory because it violates the
likelihood principle. The Bayesian attitude to decision making under uncertainty is based on two
themes: the first is that all uncertainty should be described only by probability, and the second is
that we choose only those actions that maximize expected utility. A tool that graphically portrays
the various steps that are involved in implementing the above is the decision tree, introduced
in Chapter 1. The decision tree originally appeared in Wald’s frequentist decision theory, but
since the late 1950s has emerged as the best known practical Bayesian technique. Besides its
attractiveness as a visual device, the decision tree is easy to codify for computer applications,
making an implementation of the Bayesian risk analysis methodology feasible for actual use.
A more recent development is the influence diagram of Howard and Matheson (1984); it is a
generalization of the fault tree mentioned in Chapter 1. Whereas the decision tree graphically
portrays the steps in implementing statistical decision theory, the influence diagram graphically
displays the relationships and dependencies among the random and decision nodes in a decision
problem. Both these tools complement each other and should be of interest to those who wish
to model decision problems and implement Bayesian decision theory for risk analysis.
2.9.1
The Decision Tree
A decision tree consists of nodes and branches (Figure 1.1). There are two kinds of nodes:
a decision node and a random node. The decision nodes are indicated by rectangles and the
random nodes by circles. The branches that emanate from a decision node show the possible
decisions (or actions) that a decision maker can take. The branches that emanate from a random
node indicate the various outcomes (also known as states of nature) that follow a particular
action. Effectively, at each decision node, the decision maker acts whereas, at each random node,
nature acts. Associated with each branch of a random node are probabilities. These are personal
probabilities of the decision maker and reflect the probability of occurrence of the outcome
associated with the branch. At the terminus of the tree are the utilities of the decision maker.
Each utility represents the consequence of an action–outcome combination. For example, the

DECISION TREES AND INFLUENCE DIAGRAMS FOR RISK ANALYSIS
35
utility associated with the topmost branch of Figure 1.1 comprises of the cost of administering
the drug and the discomfort of suffering from both a heart attack and the drug’s side effects.
At each random node, we compute the expected utility at that node by multiplying each utility
associated with that node by its probability, and summing these products. At each decision node,
we choose that decision which has the largest expected utility. Our final decision is the one we
make at the decision node that is the leftmost in the tree. Thus, to solve a decision problem,
we commence from the right-hand end (the terminus) of the tree and work our way back to the
left-hand end (the root) of the tree, by taking expectations at each random node and choosing
the maximum at each decision node. One way to think of this process is that at each random
node, we bundle up all the branches and at each decision node, we prune the branches. Finally,
we are left with only one branch and the decision we choose is that decision associated with the
last branch. Even though the decision tree of Figure 1.1 shows only one decision node 
 and
two random nodes 1 and 2, decision trees in general can have several such nodes.
To illustrate the above process, suppose that, in the decision tree of Figure 1.1, we first
concentrate on the random node 1 and denote by p1p2p3 and p4, the physicians’ probabilities
for the events [, ], [, (E)], [(), ] and [(), ()], respectively, when the
action taken is , to administer the drug; note that 
i pi = 1. The abbreviations used here have
been explained in section 1.4. Let the utilities associated with the above events be U1, U2, U3
and U4, respectively. That is, U1 is the utility to the patient suffering both a heart attack and the
drug’s side effects when the drug is administered. We would expect to have U1 < U2 < U3 < U4,
and that p3 > p4 > p1 > p2, though not necessarily. Similarly, at random node 2, let q1 and q2
be the probabilities of the events [] and [()], respectively, when the action taken is (),
to not administer the drug; also q1 + q2 = 1. Finally, let U5 and U6 be the utilities associated
with the above two events; we would expect to see U5 < U6. The expected utility of action ,
administering the drug, calculated at the random node 1 is 4
i=1 piUi = 	1, say. Similarly, the
expected utility of (), not administering the drug, calculated at 2 is q1U5 + q2U6 = 	2, say.
At the decision node 
, we would choose action  if 	1 > 	2 and action () if 	1 ≤	2.
Figure 2.1, abstracted from the National Research Council’s Report (1998), is another illus-
tration of the use of decision trees. It pertains to an engineering design issue involving aircraft
safety; the role of reliability and associated techniques, like fault tree analysis, failure data
analysis, the use of expert judgments, etc., is shown.
In Figure 2.1, 
1 pertains to the decision of installing a smoke detector in the hold of all cargo
planes, and 
2 to forgo such an illustration. The outcomes O1O2O3 and O4 pertain to the events
‘no fire in the hold’, ‘fire in the hold and the smoke detector functions reliably’, ‘fire in the hold
and the smoke detector fails to function’ and ‘no inflammable material in the hold’, respectively.
With these decisions and outcomes in place, consequences for each decision–outcome pair are
calculated. Thus, for example, 	
1O3 is the consequence of having installed a failed detector
when there is a fire in the hold. Once these consequences are assessed, the next task is to
calculate the probabilities associated with each consequence. Thus P
1O3 is the probability
of a fire in the hold and the failure of an installed detector. To assess this probability, we need
to assess the reliability of the detector, for which techniques such as failure data analysis, expert
judgments and fault tree analysis would play a role. The assessed probabilities and consequences
result in expected utilities, which in turn give us a means for choosing 
1 or 
2.
2.9.2
The Influence Diagram
Whereas decision trees depict the many scenarios of a decision problem (including the time
sequence of events and decisions), they suffer from the disadvantage that they become very
large, even for modestly sized situations. The size of a decision tree, as measured by the number
of its terminal branches, increases exponentially with the number of variables in the problem.

36
THE QUANTIFICATION OF UNCERTAINTY
DECISION
OUTCOME
1
1
Consequences
of 1 & O1
Consequences
of 1 & O2
Consequences
of 1 & O3
O1
O2
O3
OUTCOME
2
O1
O4
Consequences
of 2 & O1
Consequences
of 2 & O3
Consequences
of 2 & O4
DECISION TREE
2
Utility/Cost
Estimating
Tools
Failure Data
Analysis Tools
Expected
Utility
Expected
Utility
O3
Utility/Cost
Estimating
Tools
Probabilities
Fault Tree
Analysis
Reliability
Operational
Data
Expert
Judgment
Maintenance
Records
Figure 2.1
A decision tree for safety risk management (abstracted from NRR (1998)).
Another limitation of decision trees is that they do not explicitly depict the interdependencies
between the various nodes that appear in a decision problem. Influence diagrams overcome these
limitations of decision trees. They depict the decision problem as a compact graph, whose size,
as measured by the number of its nodes, grows linearly with the number of variables. All the
same, decision trees and influence diagrams are isomorphic; that is, any properly constructed
influence diagram can be converted to a decision tree, and vice versa. A common strategy is
to start off by using an influence diagram to help understand the major elements of a problem
and its interdependencies, and then to convert it to a decision tree for its systematic solution.
It has been the experience of many practitioners that communicating the elements of a decision
problem via influence diagrams is more effective than doing so via decision trees. However,
it is also the experience of many that drawing an influence diagram is much more involved
than drawing a decision tree. An expository tutorial on influence diagrams, together with several
examples of their applications, is in Clemen (1991); a more mathematical treatment is in Barlow
(1988) and in Barlow and Pereira (1990). The material which follows has been abstracted from
these sources.
As is done with decision trees, the elements of a decision problem (namely the decisions to be
made), the uncertain outcomes and the consequences of a decision–outcome combination show
up in the influence diagram as different shapes. These shapes, called nodes, are then linked up
by arrows to show the interrelationships between the elements. A decision node is indicated by a

DECISION TREES AND INFLUENCE DIAGRAMS FOR RISK ANALYSIS
37
rectangle and a random node by a circle; the consequence node, also called the value or payoff, is
denoted by two concentric rectangles with rounded corners (Figure 2.2). The arrows connecting
the nodes are called arcs, and the entire display is known as a graph. The node at the beginning
of an arc is called a predecessor, and the node at the end of an arc is called a successor. A node
with no adjacent predecessors is called a root node, and a node with no adjacent successors is
called a sink node. A path between two nodes, say 1 and 2, is a collection of arcs that leads
one from 1 to 2 via intermediate connecting nodes. In Figure 2.2, the node labeled 
 is a
root node, whereas the node labeled ‘Value’ is a sink node. Also, node R is a successor to the
node labeled 
, which is a predecessor to .
The simplest decision problem is one in which there is only one decision to make, one uncertain
event and one outcome that is determined by both the decision and the uncertain event. Thus,
for example, consider a simplified version of the cholesterol drug problem considered before,
in which the only decision to be made at node 
 is  or () and the only uncertain event of
interest is  or  at node R; that is, we ignore the issue of the drug’s side effects. An
influence diagram for this decision problem is shown in Figure 2.2. Observe that, since both
the decision node and the random node precede the value node and also influence it, there are
arcs going from these nodes to the value node. Also, since the decision to administer the drug
would influence the occurrence or not of a heart attack, there is an arc going from the decision
node to the random node. The absence of an arc from the random node to the decision node
reflects the fact that, when the decision is made, we do not know if the patient will suffer a heart
attack or not. Any arc going from a random node to a decision node indicates the fact that, when
the decision is made, the outcome of the (predecessor) random node is known; such arcs are
usually denoted by dotted lines. Also denoted by dotted lines are arcs going from one decision
node to another; these indicate the fact that the first decision is made before the second. Finally,
a well-constructed influence diagram should have no cycles of all solid lines; that is, once we
leave a node we cannot get back to it, and the diagram must have at least one root node and one
sink node.
 
 or ()
 
 or ()
Value
: Administer Drug 
(): Do Not Administer Drug 
: Patient Suffers Heart Attack 
(): Patient Avoids Heart Attack
Key:
Figure 2.2
Influence diagram for a simplified version of the cholesterol drug problem.

38
THE QUANTIFICATION OF UNCERTAINTY
1 
Condition
2
Positive or
Negative

 or ()

 or ()
Value
Figure 2.3
Influence diagram for the cholesterol drug problem with imperfect information.
The influence diagram of Figure 2.2 can be expanded to include the commonly occurring
situation of imperfect information which decision makers often have prior to making a decision.
With respect to the cholesterol drug problem of Chapter 1, suppose that we have the benefit
of an inexpensive medical test on the general health of the patient which gives us added but
inconclusive information about the patient’s susceptibility to a heart attack. In Figure 2.3, the

()
*
*

()


()
Result
of Test
1
2
3
4
Figure 2.4
Decision tree for the cholesterol drug problem with imperfect information.

DECISION TREES AND INFLUENCE DIAGRAMS FOR RISK ANALYSIS
39
general health of the patient is indicated by a random node 1, and the additional test by a
random node 2. This latter node is a random node because the test may reveal whether the
patient is risking a heart attack (test positive) or not (test negative). The results of the test would
of course depend on the true condition of the patient, and thus we have an arc going from 1
to 2. Furthermore, when the decision to administer the drug is made, the result of the test is
known. Thus, we have a dotted arc going from 2 to 
 (Figure 2.3). Note that the situation
described above is different from that in which we have the option of deciding whether to order
the test or not. In the latter case, we would have an additional decision node pertaining to the
test and preceding node 
.
To see how an influence diagram displays features of interdependence between the nodes
that the decision tree does not, we show in Figure 2.4 a decision tree that is isomorphic to the
influence diagram of Figure 2.3. Observe that, unlike the arc going from 
 to  in the influence
diagram, there is nothing in the decision tree which graphically portrays the fact that our decision
influences the outcome. However, node  of the influence diagram corresponds to nodes ∗
and ∗of the decision tree to indicate the fact that our decision could influence the outcome.
Similarly, the decision tree has no analog for the arc from 1 to R of the influence diagram,
which reflects the fact that the outcome of the test depends on the health of the patient.
Lauritzen and Spiegelhalter (1988) discuss the use of influence diagrams in medical expert
systems, whereas Good (1961) has used a similar vehicle to illustrate notions of causality.
The examples given here do not illustrate the fact that influence diagrams are generally more
compact than decision trees. This feature is better appreciated in the context of sequential
decision problems which have a tendency to grow exponentially. The fact that influence diagrams
are useful aids for decision making vis-à-vis communication dependencies needs no further
elaboration. However, the fact that they are generally difficult to construct and that they do not
supplant decision trees in their entirety makes them less of a panacea than what their proponents
have us believe.
Probabilistic influence diagrams
A probabilistic influence diagram is a special influence diagram in which all the nodes are
random and, as before, the arcs between the nodes indicate their possible dependencies. If there
is no arc connecting two nodes, then these nodes are judged to be conditionally independent,
given the states of their adjacent predecessor nodes. Also, any two root nodes in a probabilistic
influence diagram are independent. Associated with each node is a conditional probability for
the node, and this probability depends on the states of the adjacent predecessor nodes, if any.
Probabilities associated with the root nodes are conditioned on the background information. Given
a probabilistic influence diagram, there exists a unique joint probability function corresponding
to the random quantities represented by the nodes. This joint probability is the product of the
probabilities associated with all the nodes in the diagram. Consequently, in addressing practical
problems, it may be easier to use an influence diagram to assess the joint probability distribution
by multiplying the node probabilities, as opposed to a direct probability assessment.
Probabilistic influence diagrams are in essence a pictorial depiction of the calculus of proba-
bility, and as such have been used by some to ensure that the laws of probability are observed.
That is, probabilistic influence diagrams are isomorphic with the calculus of probability and
serve as an aid for ensuring coherence. This isomorphism is achieved by introducing the three
operations, ‘node splitting’, ‘node merging’ and ‘arc reversal’, all of which are derived from the
addition and multiplication rules and Bayes’ Rule. The following example in forensic science,
taken from Barlow and Pereira (1990), is illustrative. Scenarios involving medical diagnosis and
machine maintenance can be seen as alternate versions of this example.
An archetypal problem in forensic science goes as follows. A robbery has been committed by
breaking a window and, in the process, a blood stain has been left by the robber. An individual

40
THE QUANTIFICATION OF UNCERTAINTY
with the same blood type as that on the window stain has been charged with the crime. Based on
this evidence, we need to assess the probability of the individual’s guilt. Let 12 denote the
blood type of the individual (window stain), and let  denote the ‘culpability’ of the individual,
with  = 10 implying guilt (innocence). Let i = 10i = 12, if the blood type is  (not ).
We need to evaluate P = 11 = 2 = 1. The probabilistic influence diagram of Figure 2.5
describes the probability model for this problem.
Observe that the diagram does not portray the actual values of the is that are known to us. It
merely describes the dependence relationships among the quantities and the probabilities to be
used. Specifically, if p represents the proportion (chance) of persons in the population having
blood type A, and q our prior probability that the suspect is guilty of the crime, where q has been
assessed before we learn of the blood type evidence, then P1 = 1 p = p, and P = 1 q = q.
The probabilities p and q are assessed based on background history  alone, and thus  and 1
go to define the root nodes 1 and 2; note that p ̸= 1 −q. A knowledge of p helps us assess
the conditional probability of 2. Specifically, we can see that
P21 = p
if  ̸= 2 = 1
= 1 −p
if  = 2 = 0
= 1
if  = 1 and 1 = 2 and
= 0
otherwise.
Thus all the probabilities associated with the nodes of Figure 2.5 can be assessed.
Because 1 and 2 are root nodes, the events  and 1 are judged independent, and thus
P12 = P21 P1 P
by the multiplication rule. Therefore, we see that the joint probability of all the events in a
probabilistic influence diagram is simply the product of probabilities associated with the nodes.
1
Event 
3
Event 
2
Event 
() = q
(2 | 1, )
(1) = p
Figure 2.5
Probabilistic influence diagram for a problem in forensic science.

DECISION TREES AND INFLUENCE DIAGRAMS FOR RISK ANALYSIS
41
To obtain P = 1 1 = 2 = 1 we use the multiplication rule where
P12 = P12
P12 
and proceed to evaluate P12. The evaluation of this latter quantity gives us an opportunity
to illustrate the node splitting operation of influence diagrams. Since
P12 = P1 P21 = P2 P12
there are two ways in which the node representing the event 1 2 can be split (Figure 2.6).
The choice of how to split a node depends on our ability to assess the ensuing probabilities.
For example, if we choose to go with the third box of Figure 2.6, then we are required to assess
P12, the probability that an individual having blood type A is liable to commit a robbery
and, in so doing, get hurt. That is, we need the probability that persons of blood type A are
sloppy thieves. Similarly, the node representing the event  1 2 can be split in six different
ways, two of which are shown in Figure 2.7.
The second probabilistic influence diagram operation is node merging. This operation is the
reverse of node splitting, and a simple way to appreciate this operation is to look at the first two
boxes of Figure 2.7 in reverse order. That is, we can go from the two nodes of the second box to
the single node of the first box. The same is also true of the third box. However, it is not always
possible to merge any two adjacent nodes in a probabilistic influence diagram. In general, two
nodes, say 1 and 2, can be merged into a single node 1 2 only if there is a list ordering of
the nodes such that 1 is an immediate predecessor or successor of 2 in the list. For example,
in the diagram of Figure 2.8, the two nodes  and 2 cannot be merged because the only list
Event
Event
1
2
1
2
Event
Event
Event
(1 | 2)
(2 | 1)
(1, 2)
(1)
(2)
Figure 2.6
An illustration of node splitting.
Event
(1, 2)

Event
Event
(1, 2)

Event
Event
(1, 2)
( | 1, 2)
(1, 2 | )
(1, 2, 3)
()
Figure 2.7
Another illustration of node splitting.

42
THE QUANTIFICATION OF UNCERTAINTY
(1, 2)
(1, 2)



Event
Event
Event
Event
Event
2
1
Event
Event
( | 1, 2)
(1, 2 | )
(1, 2)
()
Figure 2.8
Illustration of node merging.
ordering here is  < 1 < 2, and  and 2 are not neighbors on the list. We are, of course, able
to merge  and 1 into  1 and 1 and 2 into (1 2).
The third probabilistic influence diagram operation is arc reversal. This operation corresponds
to Bayes’ formula, which pertains to inverting probabilities. To see how this works, consider the
first box of Figure 2.9, which contains two nodes 1 and 2 with an arc from 1 to 2. Using the
node merging operation, we merge the nodes corresponding to the events 1 and 2 to obtain
the single node box in the center of Figure 2.9. We then apply the node splitting operation to
(1, 2)
Event
Event
Event
2
1
(2 | 1)
(1)
Event
2
1
Event
(1 | 2)
(2)
Figure 2.9
Illustration of arc reversal operation (Bayes’ law).

DECISION TREES AND INFLUENCE DIAGRAMS FOR RISK ANALYSIS
43
the single node of the center box to obtain the third box of Figure 2.9, which has two nodes 1
and 2 with an arc going from 2 to 1. The arcs in the first and the third boxes are reversed.
In order to obtain the probabilities P1 2 and P2 we use Bayes’ law and the law of total
probability, respectively. We may thus interpret the law of total probability and Bayes’ law as
algebraic operations that enable us to go from the first box to the third without going through
the middle box, the first and third boxes entailing a reversal of arcs.
Theorems pertaining to the conditions under which node merging and arc reversal can be
undertaken are given by Barlow and Pereira (1990), who also describe the visual force of the
probabilistic influence diagrams to explain the notions of conditional independence. We find
them interesting, but leave it up to the reader to decide on their usefulness. Our inclusion of
probabilistic influence diagrams is for the sake of completeness.


Chapter 3
Exchangeability and Indifference
Here lies Fermat: This page is too small to contain a proper epitaph.
3.1
INTRODUCTION TO EXCHANGEABILITY: DE FINETTI’S
THEOREM
In section 2.6.1 of Chapter 2, the notion of a probability model (or a failure model) was introduced
and are saw that it was subjectively specified. It was mentioned that the principle of indifference
has sometimes been used to facilitate the subjective specification of failure models. The principle
of indifference derives from the judgment of exchangeability. The aim of this chapter is to
introduce the ideas of indifference and exchangeability, and to explore their ramifications for
specifying failure models. First-time readers and those whose main interested is in methodology
may choose to skip this chapter and proceed directly to Chapter 4. However, I strongly feel that
the material here is at the heart of the theory and the practice of reliability and survival analysis,
and is fundamental to a deeper appreciation of what the subject is all about. This is true for both
probabilistic modeling and life-testing.
Exchangeability is an important notion in probability theory; Kingman (1978) surveys its
features. It has also played a useful role in reliability theory vis-à-vis the mathematical char-
acterization of positively dependent lifelengths (Shaked, 1977). Exchangeability was introduced
by de Finetti in 1937, and has played a key role in both the theory and the practice of Bayesian
statistics. Philosophically, exchangeability has had an impact on the positivist interpretation of
the degree of belief notion of probability. In survival analysis, it has provided a justification
for the predictability of random quantities given observations on similar quantities (Lindley and
Novick, 1981). In reliability, it has facilitated the development of models for failure and life-data
analysis (Barlow and Mendel, 1992). Exchangeability is also the basis for hierarchical models
which have proved to be useful for addressing questions pertaining to the failure of technological
systems, such as emergency diesel generators in nuclear reactors (Chen and Singpurwalla, 1996),
and software for telecommunication systems (Singpurwalla and Soyer, 1992). In addition to the
above, exchangeability has provided the probability theorists fertile territory for research in an
area that is of interest to statisticians [(Diaconis and Freedman, 1980), Diaconis (1988)].
Reliability and Risk: A Bayesian Perspective
N.D. Singpurwalla
© 2006 John Wiley & Sons, Ltd

46
EXCHANGEABILITY AND INDIFFERENCE
3.1.1
Motivation for the Judgment of Exchangeability
A need for the judgment of exchangeability is motivated by restricting attention to a collection
of random events. Consider the following scenario: A subject is administered a drug today; at the
end of the month, the subject is to be observed for its ‘response’ or ‘non-response’. The event
‘response’ is denoted by 1, and the event ‘non-response’ by 0. Suppose that 10 such subjects,
all judged to be similar to each other, are administered the drug and our interest today focuses
on the 210 = 1024 possible outcomes that can occur at the end of the month. What can we say
about the probability of occurrence of each of these 1024 outcomes? Our scenario is generic, and
applies equally well to many other situations ranging from coin tossing to acceptance sampling
and life-testing.
From a personalistic point of view, we should be able to think hard about the subjects and the
drug and coherently assign probabilities to each of the 1024 outcomes. There are no restrictions
on how we make our assessments, the only requirement being that the assigned probabilities
must add up to one. Even with so much latitude, it is a difficult task to come up with a sensible
assignment of so many probabilities. de Finetti suggested exchangeability as a way to simplify
this situation. Specifically, his idea was that all sequences of length 10, comprising of 1s and
0s, be assigned the same probability if they have the same total number of 1s. That is, all
sequences that have a total of five 1s should be assigned the same probability; similarly, all
sequences of eight 1s. This simply means that the probability assignment is ‘symmetric’, or
‘invariant’, or ‘indifferent’ under the changes in order. Thus, as far as the probability assignment
is concerned, what matters in a sequence is the total number of 1s and not their position and order
in the sequence. If exchangeability is to be believed, then the total number of probabilities to be
assigned reduces from 1024 to 11. This simplification has been possible because we have made a
judgment. Our judgment is that all the ten subjects are similar or indistinguishable, so that it does
not matter to us which particular subject produces a response; all that matters to us is how many
of the ten subjects responded to the drug. Thus exchangeability is a subjective judgment that we
have made in order to simplify our assignment of probabilities. A precursor to exchangeability
is Laplace’s principle of ‘insufficient reason’. In actuality, judgments of exchangeability should
be supported by the science of the problem, and there could be situations where exchangeability
cannot be assumed. To alleviate concerns such as these, de Finetti (1938) generalized his idea of
exchangeability and introduced the notion of partial exchangeability. This is a topic that I do not
plan to address, save for the material of section 6.2.1 wherein the simulation of exchangeable
sequences is discussed. We are now ready to define exchangeability.
Exchangeability
Random quantities X1X2   Xn, discrete or continuous, are said to be exchangeable if
their n! permutations, say Xk1   Xkn have the same n-dimensional probability distri-
bution PX1   Xn. The elements of an infinite sequence X1X2   are exchangeable,
if X1X2   Xm are exchangeable for each m. The n-dimensional probability distribution
PX1   Xn is said to be exchangeable if it is invariant under a permutation of the coordinates.
3.1.2
Relationship between Independence and Exchangeability
It has been pointed out that exchangeability was introduced by de Finetti as a way of simplifying
the assignment of probabilities. Are there other attributes of exchangeability that make it attractive
for use? Is there a relationship between independence and exchangeability? Does independence
imply exchangeability or is it the other way around? These are some of the questions that arise,
and the aim of this section is to attempt to answer them. We start off by considering the following
situation which commonly occurs in life-testing and industrial quality control.

INTRODUCTION TO EXCHANGEABILITY: DE FINETTI’S THEOREM
47
Several identically manufactured items are tested for success or failure, with the uncertain
event Xi taking the value one if the i-th item tests successfully, and zero otherwise. Given the
results of the test, interest generally centers around either accepting or rejecting a large lot from
which these items have been selected at random.
A frequentist approach to a problem of this type generally starts with the assumption that
the sequence of zero-one events X1X2   are independent and have a common Bernoulli
distribution with the parameter ; i.e. PXi =1  = i=12   , and PXi =0  =1−.
Experiments which lead to such events are called Bernoulli trials, and the sequence Xis, a
Bernoulli sequence. Once this assumption is made, standard machinery can be applied, provided
that the ‘stopping rule’ (cf. Lindley and Phillips, 1976) is known. For example, we can obtain
point estimates and interval estimates of , test hypotheses about , and so on. Based on the
outcome of such procedures, we can then decide to either accept or to reject the lot. In fact,
procedures like this are so common that they have been codified for use by the United States
government as MIL-STD-105D (MIL-STD-105D, 1963), and have become the standard by which
many organizations, all over the world, do business.
The subjective Bayesian approach, however, proceeds differently. To a subjective Bayesian,
when any of the Xis, say X1 reveals itself, opinion about the uncertainty of the remaining Xis,
namely, X2X3   , changes; similarly, when X2 reveals itself, opinion about the remaining
Xis changes, and so on. By contrast, the assumption of independence of the Xis, which implies
that observing X1 has no impact on X2X3   , is unjustifiably severe. The starting point for a
Bayesian analysis would therefore be something which reflects the dependence between the Xis,
and one such vehicle is the assumption that the zero-one sequence X1X2   is exchangeable.
But why would an exchangeable sequence reflect dependence? The answer was provided by de
Finetti who, after introducing the notion of exchangeability, went on to prove a famous theorem
that bears his name. This theorem formalizes what was said at the end of section 2.6.2 namely
that the defining representation for an exchangeable sequence is an equation of the type (2.4).
That is, an exchangeable sequence can be generated by a mixture of conditionally independent
identically distributed sequences.
Thus a Bayesian can proceed along one of two lines of reasoning, both leading to the same
formulation. The first would be along the lines outlined in sections 2.6.1 and 2.6.2, and the
second based on the judgment of exchangeability. With the first, the driving premise was the law
of total probability, and the assumption that the Xis are conditionally independent, conditioned
on knowing . Given the parameter  the Xis may then be assumed to have a common probability
model, which in this case is a Bernoulli with 0 ≤ ≤1. Since  is an unknown quantity, the laws
of probability require that for making statements of uncertainty about the Xis we average over
all values . This line of development would bring us to the following special versions of (2.5)
and (2.6); namely that, for x = 1 or 0,
P

Xn+1 = x  XnH

=
 1
0 x1 −1−x P  XnHd
(3.1)
where
P

  XnH

∝
n
i=1
xi1 −1−xi PH
(3.2)
and PH is our prior density at . Since 0 <  < 1 is continuous, the prior at  is typically
chosen to be a beta density on (0,1); i.e. P	 = 
 + 	/

	−11 −	−1,
where  and 	 are parameters of this density, and 	>0 
	=
 
0 x	−1 e−x dx is the gamma
function. The notion of a density will be clarified later in section 4.2.

48
EXCHANGEABILITY AND INDIFFERENCE
With the second line of reasoning, a Bayesian would start with the judgment of exchange-
ability, and then appeal to de Finetti’s theorem (given below) to arrive at (3.1) and (3.2). Thus
exchangeability and the theorem can be viewed as providing a foundation for the Bayesian
development. It is important to emphasize that, like all probability judgments, the judgment
of exchangeability is made before the sequence is observed. Once all this is done, the deci-
sion to accept or to reject the lot would be based on the assessed utilities and the principle of
maximization of expected utilities; more details on how this can be done are given in Chapter 5.
It is easy to see, from the definition of exchangeability, that a sequence of independent random
quantities is also an exchangeable sequence. However, exchangeability is a weaker condition than
independence, in the sense that exchangeable random quantities are not necessarily independent.
To verify this – details left as an exercise – consider an urn containing three balls, two of which
are marked ‘1’ and the remaining ball marked ‘0’. If these balls were to be drawn from the
urn, one at a time without replacement, and if Xk were to denote the digit on the k-th ball drawn,
then the sequence of random quantities X1X2X3 would be exchangeable, but not independent.
3.1.3
de Finetti’s Representation Theorem for Zero-one Exchangeable Sequences
We have seen before that the theory of probability does not concern itself with the interpretation
of probability, neither does it concern itself with how the probabilities of the elementary events
are assigned. The aim of the theory is to develop methods by which the probability of compli-
cated events can be obtained from the probabilities of the elementary events. Thus, as a result in
probability theory, de Finetti’s theorem is striking. Controversy about it arises when in a particular
application, the judgment of exchangeability is made and the theorem is then invoked to justify a
Bayesian analysis. Since exchangeability as a judgment is personal, it follows therefore that any
applicationofthetheoremisliabletobethesubjectofdebate.However,wehaveseenthatexchange-
ability as a judgment is more realistic than independence, at least for zero-one sequences. The
following version of the theorem and the proof has been taken from Heath and Sudderth (1976).
Theorem 3.1 (finite form), de Finetti (1937).
Let X1   Xm be a sequence of exchangeable
random quantities taking values 0 or 1. Then,
PX1 = 1   Xk = 1Xk+1 = 0   Xn = 0 =
m

r=0
rrm −rn−k
mn
	
qrfor 0 ≤k ≤n ≤m
where qr = P
m
j=1 Xj = r, and xk = k−1
j=0x −j.
Proof.
From the exchangeability of the sequence X1   Xm it follows that given 
m
j=1 Xj =r,
all possible arrangements of the r ones among the m places is equally likely. The situation is
analogous to drawing from an urn containing r ones and m −r zeros.
Thus
P

X1 = 1   Xk = 1Xk+1 = 0   Xn = 0 
m

j=1
Xj = r

=
r
k
m−r
n−k

m
n

÷
n
k
	

and so
P X1 = 1   Xk = 1Xk+1 = 0   Xn = 0 =
m

r=0
r
k
m−r
n−k

m
n

÷
n
k
	
qr
which, when simplified, reduces to the statement of the theorem. Note that division by
n
k

is
necessary because we are looking for a particular pattern of ones and zeros.

INTRODUCTION TO EXCHANGEABILITY: DE FINETTI’S THEOREM
49
The finite form of the theorem holds for all sequences of length m that cannot be ‘extended’
to a length larger than m. Thus, for example, if we are to sample without replacement from an
urn with m balls in it, we cannot have m+ 1 trials. A similar situation arises in sample surveys
where we have to draw a sample from a finite population. However, in the drug testing scenario
considered by us, the number of subjects to whom we can administer the drug can, in principle,
be extended to a very large number. The same could also be true of the item testing scenario; if
the lot size is very large, the number of items that we can test can, in principle, be very large.
For such situations, the infinite form of de Finetti’s theorem, given below, would apply.
The infinite form of de Finetti’s theorem is simply the limiting case, as m→ and r/m→, of
the above theorem. The proof involves convergence of distribution functions and approximations
by integrals (Heath and Sudderth, 1976); it is therefore omitted.
Theorem 3.2 (infinite form), de Finetti (1937).
For every exchangeable probability assign-
ment that can be extended to a probability assignment on an infinite sequence of zeros and ones,
there corresponds a unique probability distribution function F concentrated on [0,1] such that,
for all n and 0 ≤k ≤n.
PX1 = 1   Xk = 1Xk+1 = 0   Xn = 0 =
 1
0 k1 −n−kFd
where Fd = fd, and f = d
dF is the derivative of F with respect to  F is
the distribution function of .
Comments on the Theorem
The infinite form of de Finetti’s theorem suggests that exchangeable probability assignments of
ones and zeros which can be extended have the special form of mixtures of (the independent and
identically distributed) Bernoulli trials. The mixing distribution F may be regarded as the prior
for the unknown parameter . Note the similarity between the right-hand side of the statement of
the theorem and the right-hand side of (3.1). The theorem also implies that for many problems,
specifying a probability assignment on the number of ones and zeros in any sequence of size n
is equivalent to specifying a prior probability distribution on (0,1).
It is important to note that the infinite form of the theorem fails to hold for finite sequences.
To see this, consider the case of two exchangeable random variables X1 and X2, with PX1 =
1 X2 = 0 = PX1 = 0 X2 = 1 = 1/2. Thus PX1 = 1 X2 = 1 = PX1 = 0 X2 = 0 = 0. Now,
if there exists a probability distribution F such that 0 = PX1 = 1 X2 = 1 =

2 Fd, then F
must put mass 1 at 0, making impossible PX1 = 0 X2 = 0 =

1 −2 Fd = 1. Thus there
cannot exist a probability distribution F concentrated on (0,1) that will satisfy the statement of
the theorem.
Finally, de Finetti’s result generalizes so that every sequence of exchangeable random vari-
ables, not just the zero or one variables, is a mixture of sequences of independent, identically
distributed variables. Thus equation (2.5), which is quite general and which was developed via
a direct argument, can also be motivated via the judgment of exchangeability. However, as we
shall see in section 3.2, a practical implementation of this idea for getting specific versions of
(2.5) is difficult, and conditions that are more restrictive than exchangeability are sought to cut
the problem to a manageable size.
3.1.4
Exchangeable Sequences and the Law of Large Numbers
The law of large numbers was mentioned in section 2.3.1 as Bernoulli’s great theorem which
bound up fair price, belief and frequency. Specifically, in the context of a large sequence of
Bernoulli trials (that is, random quantities whose outcome is either a 1 or a 0 and all having the

50
EXCHANGEABILITY AND INDIFFERENCE
same  as the chance of observing a 1), Bernoulli proved that the relative frequency with which
a 1 occurs approximates . Stated formally, if Sm is the total number of 1s that occur in a large
number, say m, of Bernoulli trials with a parameter , then according to the weak law of large
numbers (for Bernoulli trials),
P

Sm
m −
 < 

→1 for  > 0 arbitrarily small but fixed.
Recall that, even to Bernoulli, a relative frequency was not a probability. Thus both  and the
probability statement of the theorem were regarded by Bernoulli as ‘ease of happening’, not
relative frequencies. The strong law of large numbers (first stated by Cantelli in 1917) asserts
that, with probability 1, Sm/m − becomes small and remains small.
Relative Frequency of Exchangeable Bernoulli Sequences
After proving his theorem for exchangeable sequences, de Finetti went on to prove a second
result which is of great importance. In what follows, I shall adhere to the notation used in
the infinite version of de Finetti’s theorem. He proved that, for exchangeable sequences, the
(personal) probability that the limm→k/m exists is 1 and, if this limit were to be denoted
by , then the (personal) probability distribution for  is F. If F is such that all its mass is
concentrated on a single value, then the weak law of large numbers follows as a special case of
de Finetti’s theorem.
It is important to note that again  is not to be interpreted as a probability, because to a
subjectivist a probability is the amount you are willing to bet on the occurrence of an uncertain
outcome. Lindley and Phillips (1976) view  as a property of the real world and refer to it as a
propensity or a chance, and the quantity k1−n−k as a chance distribution. Some authors on
subjective probability, such as Kyburg and Smokler (1964, pp. 13–14), have suggested that the
above result of de Finetti bridges the gap between personal probability and physical probability.
However, de Finetti (1976) disagrees, and Diaconis and Freedman (1979) also have trouble with
this type of synthesis. Hill (1993) attempts to clarify this misunderstanding by saying that even
though there does not pre-exist a ‘true probability’ , one could implicitly act as though there
were one. Similar things could have also been said about the law of large numbers; however, it
is likely that Bernoulli too would have disagreed.
3.2
DE FINETTI-STYLE THEOREMS FOR INFINITE SEQUENCES OF
NON-BINARY RANDOM QUANTITIES
Most subjectivists find the de Finetti representation theorem for Bernoulli sequences very sat-
isfactory, because specifying a reasonable prior distribution F on (0,1) is a manageable task.
Here, a natural choice for F would be a beta distribution. For example, Laplace in his famous
calculation of the probability that the sun will rise tomorrow given that it has risen in the previ-
ous n days, used the uniform distribution, a special case of the beta distribution, and arrived at
the answer n/n + 1.
However, de Finetti’s representation theorem for sequences that are not zero-one is not
straightforward to implement. It requires that we specify a prior distribution on the class of all
probability distributions on the real line. This class is so large that it is difficult, if not liter-
ally impossible, for a subjectivist to describe a meaningful personal prior on this set. Ferguson
(1974) contains some examples of the various attempts to choose such a prior. Thus it appears
that, for real-valued random quantities, the judgment of exchangeability may not provide the
justification for much of the practical Bayesian analysis that is currently being done. Condi-
tions more restrictive than exchangeability are necessary for pinning down the specific cases

INFINITE SEQUENCES OF NON-BINARY RANDOM QUANTITIES
51
(cf. Diaconis and Freedman, 1979). All the same, the general approach is still in the style of
a de Finetti theorem; that is, to characterize models in terms of an ‘invariance’ property. By
invariance, I mean ‘equiprobable’ or ‘indifference’, just like what we have done in the case of
exchangeable zero-one sequences. The idea is to begin with observables, postulate symmetries
or summary statistics (section 3.2.1), and then find a simple description of all models with the
given symmetries.
The aim of this section is to explore the above symmetries and to produce versions of (2.5)
other than that of the mixture of Bernoulli sequences. Before we do this, we must first gain
additional insight about what we have already done with zero-one exchangeable sequences,
particularly an insight into sufficiency and invariance. Informally speaking, by ‘sufficiency’
I mean a summarization of information in a manner that essentially preserves some needed
characteristics.
3.2.1
Sufficiency and Indifference in Zero-one Exchangeable Sequences
We begin by obtaining an equivalent formulation of an exchangeable, infinitely extendible,
zero-one sequence X1 X2   . Define the partial sum Sn = X1 + X2 + ··· + Xn, and let Sn = t.
Then, given t, exchangeability implies that the sequence X1   Xn is uniformly distributed
over the
n
t

sequences having t ones and n −t zeros. That is, each of the
n
t

sequences has
probability 1/
n
t

. But infinitely exchangeable zero-one sequences are, by de Finetti’s theorem,
mixtures of Bernoulli sequences. Thus we have the following:
Indifference Principle for Zero-one Sequences
An infinite sequence of zero-one variables can be represented as a mixture of Bernoulli sequences
if and only if, for each n, given Sn = t, the sequence X1   Xn is ‘uniformly’ distributed
over the
n
t

sequences having t ones and n −t zeros.
This equivalence formulation for the exchangeability of zero-one sequences of infinite length
paves the way for questions about other kinds of sequences (section 3.3.2), but it also brings
to surface two points: the relevance of the sufficiency of the partial sums Sn, and the uniform
distribution of the sequence X1   Xn. In other words, if zero-one sequences are judged
invariant (i.e. uniformly distributed) under permutation given the sufficient statistic Sn, then
they are also exchangeable, and exchangeability, in turn, gives us the mixture representation.
The ‘indifference principle’ refers to the act of judging invariance (under permutation in the
present case).
3.2.2
Invariance Conditions Leading to Mixtures of Other Distributions
Prompted by the observation that mixtures of Bernoulli sequences arise when we assume invari-
ance under permutation, we look for conditions (i.e. judgments about observables) that lead to
mixtures of other well-known chance distributions that commonly arise in practice. This may
enable us to better interpret specific forms of (2.5) that are used. In what follows, some of the
classical as well as newer results on this topic are summarized. They pertain to mixtures of both
discrete and continuous distributions. We start off with one of the best known distribution, the
Gaussian (known as the ‘normal distribution’).
Scale Mixtures of Gaussian Distributions
When can a sequence of real valued random quantities Xi1 ≤i < , be represented as a scale
mixture of Gaussian 02 variables (or chance distributions)? That is, when is
PX1 ≤x1   Xn ≤xn =
 
0
n
i=1
xi Fd
(3.3)

52
EXCHANGEABILITY AND INDIFFERENCE
where, PX1 ≤x1 = x = 1/

2
 x
− e−u2/2du, is the Gaussian (0,1) distribution function,
and F a unique probability distribution on 0?
Freedman (1962) (also Schoenberg (1938), and Kingman (1972)) has shown that a necessary
and sufficient condition for the above to hold is that, for each n, the joint distribution of
X1   Xn be rotationally symmetric. Note that an n + 1 vector of random quantities, say
X =X1   Xn, is rotationally symmetric (or spherically symmetric, or orthogonally invariant)
if the joint distribution of X is identical to that of MX for all m × n orthogonal matrices M.
An equivalent characterization based on sufficiency and invariance (cf. Diaconis and Freedman,
1981) is that, for every n, given the sufficient statistic 
n
i=1 X2
i 1/2 = t, the joint distribution of
X1   Xn should be ‘uniform’ on the n −1 sphere of radius t in n. Note that an n × 1
vector of random quantities X has a uniform distribution on the unit n sphere if the i-th element
of the vector is defined as
Xi =
Ui
U 2
i + ··· + U 2
n1/2  i = 1   n
where the Uis are independent and identically distributed as the Gaussian (0, 1) distribution.
Location Mixtures of Gaussian Distributions
When can a sequence of real valued random quantities Xi 1 ≤i ≤, be represented as a
location mixture of Gaussian 2 variables with 2 known? That is, when is
PX1 ≤x1   Xn ≤xn   =
 
0
n
i=1
xi Fd
(3.4)
where PX ≤x = x = 1/

2
 x
− e−u−2/2du is the Gaussian 1 distribution func-
tion?
The necessary and sufficient conditions (cf. Diaconis and Freedman, 1981) for the above to
hold are the following:
(i) X1X2   is an exchangeable sequence, and
(ii) Given X1 + ··· + Xn = t, the joint distribution of X1   Xn is a multivariate Gaussian
distribution (Anderson, 1958; pp. 11–19) with mean vector t/n and covariance matrix with
all diagonal terms 2 and off diagonal terms 2/n −1.
Location and Scale Mixtures of Gaussian Distributions
When can a sequence of real-valued random quantities Xi 1≤i≤, be presented as a mixture
of Gaussian 2 variables? That is, when is
PX1 ≤x1   Xn ≤xn =
 
0
n
i=1
xi Fdd
(3.5)
where PX ≤x = x = 1/

2
 x
− e−u−2/2du is the Gaussian 1 distribution func-
tion?
Smith (1981) has shown that a necessary and sufficient condition for the above to hold is that,
for every n, given the two sufficient statistics Un = X1 + ··· + Xn and Vn = X2
1 + ··· + X2
n1/2,
the joint distribution of X1   Xn is ‘uniform’ over the n −2 – sphere in n with center
at Un and radius Vn.
Problems involving location and scale mixtures of Gaussian distributions are often encountered
in many applications of Bayesian statistics, though not necessarily in reliability and survival

INFINITE SEQUENCES OF NON-BINARY RANDOM QUANTITIES
53
analysis. The result given here is important because it shows that, whenever we take location
and scale mixtures of a Gaussian distribution, we are de facto making a judgment of indifference
of the type shown above.
Mixtures of Uniform Distributions
When is X1X2   a mixture over  of sequences of independent uniform 0 variables? That
is, when is
PX1 ≤x1   Xn ≤xn =
 
0
n
i=1
xiFd?
(3.6)
The necessary and sufficient condition is that, for every n, given Mn = maxX1   Xn, the
Xis are independent and ‘uniform’ over 0Mn (Diaconis and Freedman, 1981).
This elementary result provides an opportunity to illustrate the practical value of the de Finetti-
style theorems we are discussing here. To see this, suppose that the Xis represent the lifetimes
of items, and we are to be given only Mn, the largest of n lifetimes. If (upon receiving this
information) our judgment about the other n −1 lifetimes was that each could be anywhere
between 0 and Mn with equal probability, and if the knowledge about any other lifetime did not
change this judgment, then a mixture over  of uniform variables would be a suitable model for
the n lifetimes.
Mixtures of Poisson Distributions
Let Xi 1 ≤i ≤, take integer values. Freedman (1962) has shown that a necessary and a
sufficient condition for the Xis to have a representation as a mixture of Poisson  variables,
i.e. as
PX1 = x1   Xn = xn =
 
0
n
i=1
e−xi
xi!
Fd
(3.7)
is that for every n, the joint distribution of X1   Xn, given Sn =
n
i=1 Xi, is a multinomial on
n-tuples of nonnegative integers whose sum is Sn with ‘uniform’ probabilities 1/n   1/n.
That is, for any integer valued ai i = 12   n, such that Sn = 
n
i=1 ai,
PX1 = a1   Xn = an  Sn =
Sn!
a1! ×    × an!
n
i=1
1/nai
(3.8)
The distribution (3.8) given above is that of Sn balls dropped at random into n boxes, and is also
known as the ‘Maxwell–Boltzman’ distribution.
Much of the more recent work in survival analysis (cf. Andersen et al., 1993) and in reliability
(cf. Asher and Fiengold, 1984) deals with count data. Modeling counts by point process models,
like the Poisson, has turned out to be quite useful. The Bayesian analysis of a Poisson process
model would involve expressions like (3.7). For example, Campodónico and Singpurwalla (1995)
analyze the number of fatigue defects in railroad tracks and encounter a version of (3.7). The
result above says that if we are to use the mixture model (3.7), we must be prepared to make
the judgment implied by (3.8). Alternatively, we may start off in the true spirit of a de Finetti-
style theorem and first elicit expert judgment on counts; if this happens to be of the form (3.8),
we must use the mixture model (3.7).

54
EXCHANGEABILITY AND INDIFFERENCE
Mixtures of Geometric Distributions
Let Xi 1 ≤i ≤, take integer values. Diaconis and Freedman (1981) have shown that a
necessary and a sufficient condition for the Xis to have a representation as a mixture of geometric
 variables, i.e.
PX1 = x1   Xn = xn =
 1
0
n
i=1 1 −xi−1Fd
(3.9)
is that for every n, the joint distribution of X1   Xn, given Sn = 
n
i=1 Xi, is a ‘uniform’
distribution over all nonnegative n-tuples of integers whose sum is Sn. That is,
PX1 = x1   Xn = xn  Sn = 1
k
(3.10)
where k is the total number of n-tuples whose sum is Sn. For example, if Sn = 1, then the
total number of n-tuples whose sum is 1 is n; i.e. k = n. The distribution (3.10) is called the
‘Bose–Einstein’ distribution.
Mixtures of Exponential Distributions
When is X1   Xn a mixture over  of sequences of independent exponential chance variables
with parameter ? That is, when is
PX1 ≤x1   Xn ≤xn =
 
0
n
i=1
1 −e−xi/Fd
(3.11)
where PX ≤x  = 1 −e−x/, an exponential distribution function?
A necessary and sufficient condition (cf. Diaconis and Freedman, 1987) for the above to hold is
that, for each n, given the sufficient statistic Sn = 
n
i=1 Xi, the joint distribution of X1   Xn
is uniform on the simplex Xi ≥0 and Sn.
The exponential chance distribution is one of the most frequently used failure models in
reliability and survival analysis. Its popularity is attributed to its simplicity, and also to the
fact that it characterizes non-aging or lack of wear; that is, its failure rate (section 4.3) is a
constant function of time. In the mathematical theory of reliability, its importance stems from
the fact that the exponential distribution function provides bounds on the distribution function of
a large family of failure models (cf. Barlow and Proschan, 1965). Because of this central role,
many papers dealing with a Bayesian analysis of the exponential failure model have been written.
Much of this focuses on suitable choices for Fd. Martz and Waller (1982) is a convenient
source of reference. The starting point for all such analyses are specific versions of (3.11).
The de Finetti-style result given above says that underlying the use of (3.11) is a judgment of
indifference, namely that, were we given only the sum of the n lifetimes, we would judge all
the lifetimes to be equiprobable over a region which is defined by a simplex. Alternatively, we
could have (in the spirit of de Finetti) started with the judgment of indifference, presumably
provided by an expert’s opinion, and then would be lead to (3.11). This would be a different
motivation for using the exponential failure model.
Mixtures of Gamma and Weibull Distributions
Barlow and Mendel (1992) describe conditions under which X1X2   would be a mixture
of gamma chance distributions. Starting with a finite population of N items with lifetimes
Xi i = 1   N, and guided by the view that the easiest way to make probability judgments
is via the principle of ‘insufficient reason’, they assume indifference of Wis (the transformed
values of the Xis) on the simplex

Xi ≥0 
N
i=1 Xi

with 
N
i=1 Xi known. In the special case

ERROR BOUNDS FOR FINITE SEQUENCES OF RANDOM QUANTITIES
55
when Wi = X	
i and limN→

N
i=1 Xi/N = , they obtain a mixture of gamma distributions with
shape 	 and scale 	/. The density function at x of a gamma-distributed variable X having scale
 and shape 	 is given as exp−x	x	−1/
	 x ≥0, where 
• is the gamma function.
Thus, parameters of failure models are functions of observable lifetimes. Mixtures of Weibull
chance distributions with shape 	 and scale  arise when all of the above hold except that the

N
i=1 Xi in the simplex is replaced by 
N
i=1 X	
i . A random quantity X is said to have a Weibull
distribution with shape 	 and scale  if PX ≥x  	 = exp−x	, for x ≥0.
Results that are analogous to the above, but pertaining to mixtures of the inverse binomial and
the binomial are given by Freedman (1962). I think that these results are important to subjective
Bayesians working on practical problems, because they provide a foundation for the starting
point of their work, namely their choice of a model; also see Spizzichino (1988). All of the
above results explain the consequences of the judgment of indifference on observables, given a
statistic. In practice, since it is much easier to assess and to agree upon a ‘uniform’ distribution
than upon any other distribution, indifference plays a key role. For this reason, I have placed the
word ‘uniform’ within quotes.
3.3
ERROR BOUNDS ON DE FINETTI-STYLE RESULTS FOR FINITE
SEQUENCES OF RANDOM QUANTITIES
There is one disturbing aspect of the material given in the previous section. It pertains to
sequences of random quantities that are infinitely extendable. We have seen before that not
all sequences of length k can be extended to length n > k. Also, the requirement of infinite
extendability is not in keeping with de Finetti’s general program of restricting attention to finite
samples. Yet the results of the infinite case are simple and have been used since the time of
Laplace. Thus a question arises as to how much of an error is committed in using the infinite
case results for sequences that are not infinitely extendable. This question has been addressed
by Diaconis and Freedman in a series of papers; in what follows, I reproduce a few of these for
cases that are of interest to us.
3.3.1
Bounds for Finitely Extendable Zero-one Random Quantities
I start with the simplest case of zero-one variables. Recall, from the infinite version of de Finetti’s
theorem and the notation of section 3.2, that for every infinitely exchangeable sequence,
Pjones in k trials =
k
j
	 1
0 j1 −k−jFd
(3.12)
for a unique F and for every k with the same F.
Now consider a zero-one exchangeable sequence of length k which is extendable to an
exchangeable sequence of length n, where n is finite but greater than or equal to k. Clearly,
(3.12) will not hold for this sequence (see the comments at the end of section 3.1.3), but how
wrong will we be if we use it? Diaconis and Freedman (1980) show that (3.12) almost holds in
the sense that there exists an F such that, for any set A ⊂012   k,
P# of ones in k trials ∈A −

j∈A
k
j
	 1
0 j1 −k−jFd ≤2k/n
uniformly in nk and A.
Thus, in the case of the acceptance sampling and life-testing problem, testing 10 items from
a lot of 1000 and using (3.12) instead of its finite version would imply an error of at most 0.02
in absolute value. For any fixed k, this error goes to zero as the lot size increases to infinity.

56
EXCHANGEABILITY AND INDIFFERENCE
3.3.2
Bounds for Finitely Extendable Non-binary Random Quantities
Bounds analogous to the one above have also been obtained for non-binary random quantities.
These bounds have their origin in a theorem due to Borel (1914) pertaining to the ‘total variation
distance’ (see below) between the joint distribution of a finite number of random quantities and the
joint distribution of the same number of independent Gaussian quantities. But before presenting
these results, I introduce some convenient abbreviation. The Gaussian 2 distribution will
be denoted as  2, the exponential () as , the Poisson  as P, and the geometric
() as .
The Gaussian Case
Suppose that the vector X1   Xn is judged rotationally symmetric, and let Pk be the joint
distribution function (also known as the law) of X1   Xk. Let 1   k be independent
and identically distributed as  01, and let  k be the law of 1   k. Finally, let
Fk =

 kFd (the mixture over  of  k, where F is a probability on 0.
Then, the following theorem provides a (reasonably sharp) bound on the total variation distance
between Pk and Fk.
Theorem 3.3 (Diaconis and Freedman, 1987).
If X1   Xn is rotationally symmetric,
then there is a probability F on 0 such that, for 1 ≤k ≤n −4
Pk −Fk ≤2k + 3/n −k −3
Loosely speaking, if P and Q are two probability distributions defined on all sets A ∈, then
their total variation distance is denoted by P −Q and is defined as
P −Q = 2 sup
A∈
PA −QA
The Exponential Case
Analogous to the above, suppose that the vector X1   Xn is judged uniform on the simplex
Xi ≥0 Sn, given 
n
i=1 Xi = Sn. Let Pk be the law of X1   Xn, and let 1   k, be
independent and identically distributed as . Let k be the law of 1   k, and
Fk =

kFd be the mixture over  of k, where F is a probability on 0. Then,
Theorem 3.4 (Diaconis and Freedman, 1987).
Given 
n
i=1 Xi =Sn, if X1   Xn is uniform
on the simplex Xi ≥0and Sn, then there exists a probability F on 0 such that, for all
1 ≤k ≤n −2,
Pk −Fk ≤2k + 1/n −k + 1
The US Government’s Military Standard MIL-STD-781C (MIL-STD-781C, 1977) codifies
acceptance sampling methods based on life tests. These methods, used worldwide, assume expo-
nentially distributed lifelengths. The result given here indicates the error of this assumption when
sampling from finite-sized lots.
The Geometric Case
Given 
n
i=1 Xi = Sn, suppose that X1   Xn is judged uniform on the simplex Xi ∈I Sn,
where I is the set of nonnegative integers. Let Pk be the law of X1   Xn, and let 1   k
be independent and identically distributed as . Let k be the law of 1   k.
Finally, let Fk =

kFd be the mixture over  of k, where F is a
probability on 0. Then, analogous to the above results we have

ERROR BOUNDS FOR FINITE SEQUENCES OF RANDOM QUANTITIES
57
Theorem 3.5 (Diaconis and Freedman, 1987).
Given 
n
i=1 Xi =Sn, if X1   Xn is judged
uniform on the simplex Xi ∈I Sn, then there exists a probability F on 0 such that, for
all 1 ≤k ≤n −3,
Pk −Fk ≤2

n2
n −k −1n −k −2 −1


The Poisson Case
Let Xi 1≤i≤ take integer values. Suppose that the joint distribution of X1   Xn, given
Sn = 
n
i=1 Xi, is judged a multinomial on n-tuples of nonnegative integers whose sum is Sn,
with uniform probabilities 1/n   1/n. Let Pk be the law of X1   Xk, and let 1   k
be independent and identically distributed as P. Let Pk be the law of 1   k.
Finally, let PFk =

PkFd be the mixture over  of Pk where F is a probability on
0. Then,
Theorem 3.6 (Diaconis and Freedman, 1987).
Let 
n
i=1 Xi = Sn, and Xi 1 ≤i ≤, take
integer values. Given Sn, if X1   Xn is judged multinomial on n-tuples of nonnegative
integers whose sum is Sn with uniform probabilities 1/n   1/n, then there is a probability
F on 0 such that, for all k ≤n/2,
Pk −PFk ≤2k/n
In a recent report, Iglesias, Pereira and Tanka (1994) obtain results similar to the above for
finite sequences of uniformly (over −) distributed variables; their bound is of the order
4k/n. Thus in most cases of interest, the law for finite sequences (of length k) which can be
extended to length n is within 2k/n of the law of mixtures of independent identically distributed
sequences. In view of such results, the search for failure models based on finite population sizes
appears to be of limited value.


Chapter 4
Stochastic Models of Failure
Here lies Henri Lebesgue: Talent beyond measure.
4.1
INTRODUCTION
We have seen that problems of risk analysis entail an assessment of uncertainty associated with
the occurrence of undesirable events, such as the failure of an item or the onset of a disease.
Consequently, probability models for failure play an important role. Indeed much of what is done
in the statistical theory of reliability, and in survival analysis, pertains to the selection of suitable
failure models, assessing a model’s goodness-of-fit to observed data [e.g. Chandra, Singpurwalla
and Stephens (1981)], inference about the parameters of a chosen model, and predictions
based on a chosen model.
In section 2.6.1 of Chapter 2, I stated that there are three general approaches for selecting a
failure model. One is based on an assessment of the aging characteristics of an item, the other
based on exchangeability and indifference, and the third based on a probabilistic modeling of
the physics of failure. Chapter 3 pertained to the role of exchangeability and the principle of
indifference in selecting some of the commonly used models of failure. Many analysts find this
approach to model selection lacking with respect to the incorporation of knowledge about the
causes and the nature of failure. The more traditional approaches for selecting failure models have
been the other two, namely, those based on an appreciation of the aging properties of an item,
and those based on an analysis of its physics of failure [cf. Gertsbach and Kovdonsky (1969)].
The purpose of this chapter is to describe features of these two traditional approaches. But first
it is helpful to overview some notation and terminology introduced in sections 2.1 and 2.2, and
to outline preliminaries which set the stage for a better discussion of the ensuing text.
4.2
PRELIMINARIES: UNIVARIATE, MULTIVARIATE AND
MULTI-INDEXED DISTRIBUTION FUNCTIONS
Suppose that at some reference time , an item is to be commissioned for use, and suppose that T
denotes its unknown time to failure; then T is said to be the lifelength of the item. Suppose that
the possible values that T can take are denoted by t ≥0. Let  be the background information
that is available to an analyst (henceforth us) at time , and let Ft = PT ≤t be our
Reliability and Risk: A Bayesian Perspective
N.D. Singpurwalla
© 2006 John Wiley & Sons, Ltd

60
STOCHASTIC MODELS OF FAILURE
assessment of the uncertainty about T. Let Rt = PT ≥t = 1 −Ft = Ft. In
reliability theory, Rt is known as the survival function of T for a mission of duration
0t. In general, T need not stand for time; alternate candidates could be the number of cycles
to failure, or the number of miles to failure, etc. Furthermore, T need not be a lifelength, and
could denote things such as the time to the onset (or the remission) of a disease subsequent to
the exposure to a hazardous material (or a medical intervention). No matter what T represents,
it is important to bear in mind that like the distribution function Ft, the survival function
Rt is assessed at some reference time , so that Rt encompasses two kinds of time:
the reference time  and the mission time t. Whereas the latter is explicit in the expression
Rt, the former is implicit in ; indeed, for clarity,  should really be read as .
Depending, among other things, on the values t that T is able to take, Ft can be absolutely
continuous (section 2.2), discontinuous with jumps at one or more values of t, or singular.1 A
celebrated result in probability theory is the Lebesgue decomposition formula, which says that
any distribution function can be written as the weighted sum of an absolutely continuous, a
discontinuous and a singular distribution function, (for example, Kolmogorov and Fomin, 1970,
p. 341). This decomposition formula is germane to me; it has made an appearance in reliability
theory via Marshall and Olkin’s (1967) multivariate exponential (chance) distribution.
When Ft is absolutely continuous (Figure 4.1(a)) it is differentiable almost everywhere,
and Ft=
 t
0 fsds, the Lebesgue integral; fs is known as the probability density
generated by Ft at the point s. It is instructive to think of ftds as, approximately, the
probability that T is between s and s + ds, where ds is a small increment of T in the vicinity of
s. In Chapter 3, the quantity fxds was denoted Fds.
When Ft is discontinuous in t, that is, Ft consists of jumps (Figure 4.1(b)) then
the derivative of Ft will not exist everywhere, and T will not have a probability density
at the points of discontinuity of Ft. A jump in Ft will occur at say t = t∗, if it were
known in advance (i.e. at time ) that at t∗there is a nonzero probability of failure. This type
of a situation can arise in engineering reliability under scenarios wherein an item is known to
experience a shock or some other type of a disturbance at a pre-specified time t∗; the same is
also true if T is able to take only discrete values. Whenever Ft contains jumps of the type
mentioned above, Ft =
 t
0 dFs, the Lebesgue–Stieltjes integral. Here

dFs is
taken to be
 t
0 fsds whenever Fs is differentiable at s, and it is the size of the jump
t
0
1
1
1
0
1
t
t
F(t;)
F(t;)
F(t;)
 (a)
 (b)
 (c)
Figure 4.1
Absolutely continuous, discontinuous and continuous distribution functions.
1 A distribution function is said to be ‘singular’ if it is continuous, not identically zero, and has derivatives that exist but vanish,
almost everywhere. In the single variable case, an example of a singular distribution is the ‘Cantor distribution’; this is a continuous
distribution which does not have a probability density (cf. Feller, 1966, pp. 35–36). Singular distributions arise in reliability in the
context of multi-component systems having dependent lifelengths. The multivariate exponential of Marshall and Olkin (1967) has
a singular component. Singular components pose difficulties with inference (section 4.7.4).

PRELIMINARIES
61
in Ft at all s where Ft takes a jump. A discontinuous function is not absolutely
continuous with respect to the Lebesgue integral.
Figure 4.1(c) illustrates the distribution function Ft = t/2 for t ∈01 and Ft =
1/2 + t −1/4 for t ∈13. Clearly, Ft is continuous but not differentiable at t = 1.
Specifically, Ft has a derivative ft = 1/2 for t ∈01, and ft = 1/4 for t ∈
13; thus Ft is differentiable almost everywhere, i.e. for all t ∈03, except t = 1.
Furthermore, since Ft =
 t
0 fsds, the distribution function Ft is also absolutely
continuous. Note that every absolutely continuous function is the indefinite (Lebesgue) integral
of its derivative (cf. Royden, 1968, p. 107). The above technicalities are important; they are
germane to the material of section 4.7.
When Ft is absolutely continuous, the quantity
 
0 tftdt is known as the expected
value of Ft, or since T denotes a lifelength, it is also known as the mean time to failure
(MTTF); it is denoted by ET. When Ft has discontinuities, ET =
 
0 tdFt. With
either case, since T ≥0, it is easy to verify that ET=
 
0 Rtdt. In general, if gT is some
function of T, then EgT=
 
0 gtftdt or if Ft has discontinuities, then EgT=
 
0 gtdFt. The quantity ET 2 −ET2 is the variance of Ft; it is denoted VT.
The quantity

VT is known as the standard deviation of Ft and

VT/ET is known
as the coefficient of variation of Ft. The mode of T is that value of T at which ft
attains its maximum, and the median is that T for which Ft = 1/2.
The remaining lifetimes of a unit of age t is known as the residual life, and its expected
value, the mean residual life (MRL). The latter plays a useful role in planning for maintenance
and replacement, and in the context of health care, issues pertaining to the quality of life.
Using the notation given above, but suppressing the , the residual life is T −t  T ≥t
and ET −t  T ≥t is the MRL. Since PT −t ≥u  T ≥t = Ft + u/Ft, the MRL is
given as
ET −t  T ≥t =
 
t Fu du
Ft
	
Our discussion thus far has been restricted to the case of the lifelength T of a single
item (or a single system) that is to be commissioned for use at time . In practice, inter-
est can also center around the lifelengths of a collection of n items to be commissioned for
use at . For example, we may be interested in the lifelengths of a system of n compo-
nents (or a network of n nodes) with component (node) i having lifelength Ti i = 1
 
 
 n.
If ti ≥0 denotes the possible values that Ti can take, and if  is the background informa-
tion about all the n components (nodes) available to us at time , then PT1 ≤t1
 
 
 Tn ≤
tn our uncertainty about T1
 
 
 Tn at , will be denoted by Ft1
 
 
 tn. As before,
Rt1
 
 
 tn = PT1 ≥t1
 
 
 Tn ≥tn is the joint survival function of T1
 
 
 Tn,
for mission times t1
 
 
 tn respectively. It is important to note that in this multivariate (i.e.
n ≥2) scenario, Rt1
 
 
 tn ̸= 1 −Ft1
 
 
 tn where Ft1
 
 
 tn is the joint
probability distribution function of T1
 
 
 Tn. As a function of t1
 
 
 tn, Ft1
 
 
 tn
can be absolutely continuous, discontinuous or singular; also, by the Lebesgue decomposition
formula, Ft1
 
 
 tn can be written as a weighted sum of the above three components.
As in the univariate (i.e. n = 1) case, if Ft1
 
 
 tn is absolutely continuous, then it is
differentiable at (almost) all values of t1
 
 
 tn, and fs1
 
 
 sn, its partial derivative
at s1
 
 
 sn (known as the joint probability density function generated by Ft1
 
 
 tn at
s1
 
 
 sn) is such that Ft1
 
 
 tn =
 t1
0 
 
 
 tn
0 fs1
 
 
 snds1
 
 
 dsn; specifically,
fs1
 
 
 sn = nFs1
 
 
 sn/s1
 
 
 sn.

62
STOCHASTIC MODELS OF FAILURE
Given Rt1
 
 
 tn it is easy to see that for any ii = 1
 
 
 n, Rti = PTi ≥ti
is given by R0
 
 
 0ti0
 
 
 0; i.e. by setting all the tjs, j ̸= i, in Rt1
 
 
 tn
equal to zero. Once Rti is obtained, Fti = PTi ≤ti, the marginal distribution
function of Ti, is simply Fti = 1 −Rti. Finally, the lifelengths T1
 
 
 Tn are judged
to be mutually independent if the Rti i = 1
 
 
 n, are such that
Rt1
 
 
 tn =
n
i=1
Rti
and the above type of relationship holds for all subsets of T1
 
 
 Tn of size k ≥2, and all
permutations of the indices of Ti.
The judgment of independence, commonly made in reliability, is rarely meaningful; it is often
an idealization. The common environment in which several components are commissioned to
function suggests that it is more realistic to judge their lifelengths as being positively dependent
(for example, Marshall, 1975 or Lindley and Singpurwalla, 1986). Another argument that moti-
vates positive dependence stems from the fact that often the failure of one component induces
added stresses on the surviving components, and this in turn exacerbates their susceptibility to
failure (cf. Freund (1961)). In view of such considerations, several failure models for dependent
lifelengths have been proposed in the literature; a few are discussed in section 4.7. Also discussed
in this chapter (section 4.8) is the notion of what are known as causal and cascading failures,
and models describing such failures are given.
The topic of multi-indexed failure distributions, or distributions with multiple scales, though
introduced by Mercer as early as 1961, and also alluded to by Cox (1972), is relatively new.
Such distributions are to be distinguished from multivariate failure distributions in the sense that
they pertain to the stochastic failure of a single item, where an item’s failure is recorded with
respect to two or more scales, say age (or time) and usage. A classic example is the failure of
an automobile under warranty; when the automobile fails one records both its chronological age
since purchase, and its mileage. Often, there is a positive dependence between the two scales.
For example, the mileage accumulated by an automobile increases with its age, and often a
meaningful relationship between the two scales can be proposed (cf. Singpurwalla and Wilson,
1998). In principle, multi-indexed failure distributions are no different from multivariate failure
distributions; the distinction between the two lies mainly in the context of their use and the
manner in which they are constructed. Some preliminary results on distributions with multiple
scales and other examples of their plausible use are in Singpurwalla and Wilson (1998); these
are overviewed in section 4.9.
4.3
THE PREDICTIVE FAILURE RATE FUNCTION OF A UNIVARIATE
PROBABILITY DISTRIBUTION
A concept that plays a key role in reliability and survival analysis is that of the failure rate
function, also known as the hazard rate function, or the force of mortality. The origins of the
notion of a hazard rate function can be traced to the earliest work in actuarial sciences though
much of the recent work on it has been spawned by problems in reliability. In view of the vast
literature in applied probability that has been devoted to the nature and the crossing properties
of the failure rate function, it is appropriate to make the claim that the notion of the failure
rate is perhaps the main contribution of reliability to probability. In this section, I introduce and
articulate the idea of the failure rate function and show its relationship to the survival function.
In the sequel, I also make the distinction between the predictive failure rate and the model failure
rate. In what follows, I omit the background history argument , so that the Ft of the

PREDICTIVE FAILURE RATE FUNCTION
63
previous section is simply Ft, and similarly Rt is Rt; furthermore, following a common
convention, I denote the quantity RT = 1 −Ft by FT.
Suppose that T is discrete, taking values 02
 
 
 k
 
 
 , for some  > 0, and suppose
that at time , the uncertainty about T is assessed via Fk, for k = 012
 
 
 ,. Then, the
predictive failure rate of Fk at some future time k, and as assessed at time  (the now
time) is defined as
rk = Pk < T ≤k + 1
PT > k
= Fk −Fk + 1
Fk
	
(4.1)
Even though the failure rate is a property of the distribution function Fk, it is common to
refer to it as the failure rate of T. Since rk can be defined for all values of k rk as a
function of k, for k = 012
 
 
 , is known as the predictive failure rate function of Fk.
It is easy to verify that
1 −rk = Fk + 1
Fk

(4.2)
thus, if we are able to specify rk, for k = 012
 
 
 , then because of the fact that F0 = 1
we are able to obtain Fk – the survival function – for k = 012
 
 
 , via the relationship
Fk =
k−1

i=0
1 −ri	
(4.3)
The above relationship, known as the multiplicative formula of reliability and survival, shows
that there exists a one-to-one relationship between the failure rate function rk and the survival
function Fk for k = 01
 
 
 This one-to-one relationship can be advantageously exploited in
the manner discussed below.
We first note that rk is a conditional probability (assessed at time ) that the item in
question fails at the time point k +1, were it to be surviving at k; both k and k +1 are
future (subsequent to ) time points, and rt = 0, for all t ̸= 02
 
 
 Since probability is
subjective, and since conditional probabilities are generally easier to assess than the unconditional
ones, rk as a function of k encapsulates one’s judgment about the aging or the non-aging
features of an item. By ‘aging’ I mean the degradation of an item with use; for example,
humans and mechanical devices experience some form of a deterioration and wear over time. The
characteristic of non-aging is opposite to that of aging. Non-aging as a physical or a biological
phenomenon is rare, and occurs for instance, in the context of work-hardening of materials,
or with the development of a newborn’s immune system. With aging one would assess an
increasing sequence of conditional failure probabilities over equal intervals of time. That is,
rk will be judged increasing in k. Conversely, rk will be judged decreasing if the item
experiences non-aging (section 4.4.2). If the physical state of an item does not change with age
then rk is assessed as being constant over k. For example, it has been claimed that electronic
components neither degrade nor strengthen with age. For such devices rk is constant in k.
Thus to summarize, the failure rate as a conditional probability can be subjectively specified by
a subject matter specialist based on the aging characteristics of an item, and once this is done the
survival function Fk can be induced via (4.3). As an aside, suppose that we are to assume
that the item has failed at k and are required to assess rk. Alternatively put, we are asked

64
STOCHASTIC MODELS OF FAILURE
‘what is the failure rate of a failed item?’ One is tempted to give zero for an answer, but this
is not correct! To see why, we note from (4.2) that assuming failure at k1 −rk = 0/0
which is undefined; this is to be expected since probabilities are meaningful only for those events
whose disposition is not known. Thus it does not make sense to talk about the failure rate of a
failed item.
For T continuous, one is tempted to define the failure rate as the limit of the right-hand side of
(4.1) as ↓0, and k→t. However, such a temptation does not lead us to a satisfactory limiting
operation. Instead for T continuous, the instantaneous predictive failure rate at t (when the
following limit exists) is defined as
rt = lim
dt↓0
Pt < T ≤t + dt  T > t
dt
(4.4)
and rt as a function of t is called the predictive failure rate function of the distribution function
Ft = PT ≤t, or equivalently of T. Informally, rt is a measure of the risk that a failure will
occur at t.
Note that for small values of dt rtdt can be interpreted as, approximately, the probability
that an item of age t will fail in tt + dt. Thus, like rk, the instantaneous failure rate is a
conditional probability, the probability assessment made at time . It is important to note that
the above interpretation of rtdt is not appropriate if PT ≤t is singular, or is otherwise not
absolutely continuous. Since Ft = 1 −Ft, We may rewrite (4.4) as
rt = lim
dt↓0
Ft + dt −Ft
Ftdt

(4.5)
provided that Ft > 0.
Clearly, the above limit will exist if Ft is absolutely continuous, in which case
rtFt = d
dt Ft = −d
dt Ft	
(4.6)
If dFt/dt = ft, the probability density generated by Ft at t, then (4.6) leads us to the
relationship
rt = ft
Ft
(4.7)
which with Ft > 0 is often taken as the definition of the predictive failure rate and is the
starting point of a mathematical theory of reliability (Barlow and Proschan (1965)).
Since the limit in (4.5) need not always exist for all t ≥0, the predictive failure rate at t is
sometimes also defined as
rt = dFt
Ft 
(4.8)
where dFt is ftdt wherever Ft is differentiable, and is otherwise Ft+ −Ft−, the jump
in Ft at t. When Ft is the distribution function of Figure 4.1(c), its failure rate at t = 1 does
not exist.
Equation (4.6), which comes into play when Ft is absolutely continuous, is a differential
equation with F0 = 1 as the initial condition; indeed F0 = 1 is a defining feature of failure
time distributions. The solution of this differential equation is the famous exponentiation formula

PREDICTIVE FAILURE RATE FUNCTION
65
of reliability and survival (not to be confused with the product integral formula which will be
described soon). Specifically, for t ≥0
Ft = exp−
 t
0 rudu	
(4.9)
The quantity Ht =
 t
0 rudu is important. As a function of t, it is known as the cumulative
hazard function of Ft (or equivalently of T). Since Ht = −logFt – a classic relationship
in reliability and survival analysis – it is easy to see that ft the probability density generated
by Ft is given as
ft = exp−
 t
0 rudu rt
for t ≥0	
(4.10)
Finally, using the fact that since Ht = Ht1 + Ht −Ht1, for any t1, 0 ≤t1 ≤t, we have
Ft = e−Ht1e−Ht−Ht1
from which the well-known fact that
Ft = PT ≥t = PT ≥t1 PT ≥t  T ≥t1
follows.
The one-to-one relationship between the failure rate function and the survival function of (4.9)
parallels that given by (4.3) for T discrete. To see this parallel, we may rewrite (4.3) as
Fk = exp

−
k−1

i=0
ln

1
1 −ri
	
	
4.3.1
The Case of Discontinuity
When Ft is not absolutely continuous, it does not have a probability density at all values of
t, and thus it is (4.8) that comes into play. We may use this equation to define the cumulative
hazard function as
Ht =
 t
0 dFs/Fs
Note that Ht will be non-decreasing and right-continuous on 0; it will be interpreted as
dHs = PT ∈ss + ds  T ≥s = dFs/Fs	
Thus
dFs = dHsFs
so that for any 0 ≤a ≤b < 
 b
a dFs =
 b
a dHsFs
or that F ab =
 b
a dHsFs.

66
STOCHASTIC MODELS OF FAILURE
The solution to the above differential equation is the famous product integral formula;
namely, for t ≥0
Ft =

0t
1 −dHs
see (4.3) for a parallel. It can be shown (Hjort (1990), p. 1268) that the right-hand side of the
above equation equals exp−hab if and only if H is continuous. This means that the classic
relationship Ht = −logFt is true only when F is absolutely continuous.
4.4
INTERPRETATION AND USES OF THE FAILURE RATE
FUNCTION – THE MODEL FAILURE RATE
No single concept in probability appears to be more associated with reliability and survival
analysis than that of the failure rate function. Engineers are attracted to the concept of a failure
rate because it captures their intuitive notions about wear, in the sense that items that wear out
should have a failure rate function that increases with time, and vice versa. By wear, we mean
the depletion with use of material or resources so that an item’s ability to perform its intended
functions gets diminished. Similarly, biometricians find the failure rate function a useful device
for expressing their opinions about aging, which again is a deterioration in the ability to perform
specified tasks over time. From a mathematical point of view, the failure rate function is attractive
because of formulae (4.3) and (4.9), which provide a one-to-one relationship between the failure
rate function and the survival function. However, there exist circumstances under which the
formulae (4.3) and (4.9) will not hold. These circumstances are discussed in Singpurwalla and
Wilson (1995) (section 9.5.2). Thus, in practice, the general form of the failure rate function
could be specified by a subject matter specialist, from which the reliability function can be
automatically deduced. In effect, as discussed next, the failure rate is a useful device for making
a connection between the physics or the biology of failure, and the probability of survival.
Suppose that an item is judged to neither age (wear) nor improve with use, then the failure rate
function of its time to failure T, should be a constant, say >0. But often  cannot be specified,
and so our judgment about the constant failure rate of T is conditional on  being known. That
is, the failure rate of T   is rt  , i.e. a constant . From (4.9) it then follows that the
survival function of T   is Ft   = exp−t for t ≥0; this is an exponential distribution
with scale . Barlow (1985) refers to rt   as the model failure rate of T, because this is the
failure rate that generates a probability model (or a failure model, or a lifelength model) for T.
Since FT   = exp−t also appears in (3.11) as a chance distribution, rt   can also be
seen as the chance failure rate of T.
The model failure rate is to be distinguished from the predictive failure rate of T, which is
the unconditional failure rate of T obtained by averaging out our uncertainty about . It will be
pointed out in section 4.4.2 that the predictive failure rate of T is decreasing in t even though
its model failure rate is constant in t. The key distinction between the model and the predictive
failure rate is that the former is the failure rate of T conditioned on parameters, whereas the
latter is its unconditional failure rate. In the current literature, it is the model failure rate that has
been predominantly specified and discussed.
The exponential distribution, with a specified scale parameter , is a suitable failure model for
items that do not deteriorate nor improve with time. For items that are judged to be otherwise,
a commonly used model failure rate is rt   = t−1, for some  > 0, and t ≥0.
Observe that rt   increases (decreases) in t, when ><1, so that conditionally, both the
judgments of aging and improvement of ability to perform can be represented. When  = 1, the
model failure rate is a constant (Figure 4.2). The above form of rt   results, via formula

MODEL FAILURE RATE
67
β < 1
β > 2
β
t
λ
r (t | λ, β)
β = 1
β = 2 
(Rayleigh)
Figure 4.2
The model (chance) failure rate function of a Weibull distribution.
(4.9), in the famous Weibull distribution with scale parameter  and shape parameter ; its
survival function is Ft   = exp−t for t ≥0. With  = 2, the Weibull distribution is
often referred to as the Rayleigh distribution. The scale parameter  is sometimes also referred
to as the characteristic life. The reason behind this is not clear, save for the fact that when
t =  Ft   = e−1 ≈0	37, suggesting that about 63% of the items will experience a failure
by time t = .
The Weibull is a useful failure model in both biomedical and engineering applications, though
Gavrilov and Gavrilova (2001) claim that for biological organisms, the Gompertz Law with a
model failure rate function of the form rt  AB = A + B expt AB > 0 is more
appropriate. The Gompertz Law has been popular in the study of human aging and longevity.
Other forms of the model failure rate and their corresponding survival functions are given in
Chapter 4 of Mann, Schafer and Singpurwalla (1974) and Chapter 2 of Singpurwalla and Wilson
(1999); these include the gamma, the lognormal, the extreme value, the Pareto, the truncated
normal, a family of distributions proposed by Birnbaum and Saunders (1969), etc.
The lognormal with parameters ≥0 and >0 is noteworthy because its failure rate function
need not be monotone in t. For certain combinations of values of  and  rt   can
increase in t and then decrease in t, so that the failure rate function is a reverse U-shape.
The lognormal distribution function PT > t   has a probability density at t of the form
ft  =
1
√
2t exp

−1
2
 logt−

2
 t≥0. The lognormal distribution is related to the Gaussian
distribution via the relationship T = loge X, where X is Gaussian with parameters  (mean)
and 2 (variance); its mean ET is e+2/2, its median is e, its mode e+2 and its variance
e2+2e2 −1.
The extreme value distribution, also known as Gumbel’s distribution – after Gumbel (1958)
who used it extensively to describe extremal phenomena, like floods and gusts – bears a relation-
ship to the Weibull distribution in a manner that is akin to the normal and lognormal. Specifically,
if X has a Weibull distribution, then T = loge X has an extreme value distribution of the form
Ft   = exp−expt −/, for − < t <  . It can be easily seen that with  = 0
and  = 1, the model failure rate of the extreme value distribution is et − < t < ; this is
an exponentially increasing function of t, taking the value 1 when t = 0. The parameter  is a
location parameter and  a scale parameter. Because the support of T is the real line −+,
the extreme value distribution cannot be an appropriate choice for a failure model. Its inclusion
here is for completeness.

68
STOCHASTIC MODELS OF FAILURE
A two-parameter family of distributions was proposed by Birnbaum and Saunders (1969) as
a model for describing failures due to fatigue caused by cyclical loading. Here
PT > t   = 

1

 t

 1
2 −

t
	 1
2 
 0 < t <   > 0
 is a shape parameter and  a scale parameter. The quantity x =
 x
− exp−s2/2ds is the
cumulative distribution function of a standard Gaussian distribution; i.e. a Gaussian distribution
with mean zero and variance one. The distribution given above is absolutely continuous with a
density function that is unimodal. The model failure rate of the Birnbaum–Saunders family of
distributions is not monotonic; however, it has been conjectured that it is U-shaped (Figure 4.6).
The Inverse Gaussian distribution has often been proposed as an alternative to the lognormal
for a failure distribution function (cf. Chhikara and Folks (1977)). Here, given the parameters 
and   > 0 PT > t   has density at t of the form

2
	 1
2
t−3
2 e exp

−
2
 t
 + 
t
	

where , a scale parameter, is the mean of T, and 1/

 is the coefficient of variation;  is a
shape paramter. The model failure rate of this distribution is non-monotonic; it initially increases
and then decreases to a non-zero value as t becomes large. More about this distribution is said
later in section 5.2.6.
Barlow and Proschan (1965) describe a mathematical theory of reliability based on monotone
model (or chance) failure rate functions and the manner in which these functions cross the
constant failure rate function of an exponential distribution. Multivariate versions of some of the
univariate distributions mentioned above will be discussed in section 4.7.
In reliability theory, survival functions of the kind Ft   = exp−t and Ft   =
exp−t are referred to as the reliability of T for a mission time t. In actuality, of course,
these are survival functions of T conditional on  and . Since such functions also appear as
chance distributions in the de Finetti-type representation theorems of Chapter 3 (for example
equation (3.11)) I make the claim that
reliability is a chance: not a probability!
In contrast, the survival function of T when Ft   = exp−t is given as
Ft = PT > t =
 
0
exp−t Fd
similarly for Ft   = exp−t. Thus to summarize, in this book I make the distinction
between reliability of T for a mission of duration t, and the survival function of T. The former
entails unknown parameters; the latter does not. In practice, it is the survival function that is
of interest to engineers and biometricians. The reliability function is a convenient step toward
getting to the survival function.
Units of Measurement for Parameters of Chance Distributions
For purposes of discussion consider the exponential chance distribution with parameter  > 0.
Here PT > t   = exp−t and its probability density at t ft is exp−t. What are

MODEL FAILURE RATE
69
the units of measurement for , or is , like a probability, a unitless quantity? To answer this
question we start by recalling the definition of a probability density function, namely, that
ft = lim
h↓0
Ft + h −Ft
h

for some h > 0. The quantities Ft + h and Ft being probabilities are unitless, and h is
measured in the same units as t. If t is measured in units of time (seconds, minutes, hours, etc.),
then so is h. Consequently, the units in which ft is measured is time−1. Similarly, since
the failure rate rt def
= ft/Ft, the units in which rt is measured is also time−1. Thus no
matter what Ft is, both ft and rt are measured in terms of the reciprocal of the units in
which the random variable T is measured.
With the above in place, recall that for the exponential as a chance distribution of time to
failure, the failure rate rt  =. Consequently, the units in which , the scale parameter would
be measured is time−1. In the case of the Weibull as a chance distribution PT ≥t   =
exp−t  > 0, and its failure rate rt   = t−1. Since the unit of measurement
for rt   is also time−1 – recall that for  = 1, the Weibull becomes an exponential – the
shape parameter  must be a unitless quantity.
4.4.1
The True Failure Rate: Does it Exist?
We have stated that the failure rate, be it model or predictive, is a conditional probability and
that probability, being personal, does not exist outside an analyst’s mind. The same is therefore
also true of the failure rate (cf. Singpurwalla, 1988a; 1995a); however, such a position may be
contrary to the views of many who tend to think of the failure rate as an objective entity, so that
any item has a ‘true failure rate’. Furthermore, to most engineers, the notion of a failure rate is
synonymous with its naive estimate, namely, the number of failures in an interval divided by the
number of items that are surviving at the start of the interval. This parallel between the failure
rate and its estimate is of course a misconception. In our development, the failure rate – be it
model or predictive – is an assessment of our uncertainty about the failure of an item in the time
interval tt + dt were we to assume that the item is surviving at t. If, based on the physics or
the biology of failure, we judge the item to age or to deteriorate with time, so that the capability
of the item to perform its intended function degrades, then our probability for the above event
should increase with t (Figure 4.2). If in our opinion the capability of the item to perform its
intended function is enhanced with time, and there would be two reasons for this (section 4.4.2
below) then the said probability should decrease with t.
4.4.2
Decreasing Failure Rates, Reliability Growth, Burn-in and the Bathtub Curve
Rationale for a Decreasing Failure Rate
Whereas the judgment that the failure rate of an item is increasing with time is easy to support,
namely, that the item deteriorates with use, reasons for the judgment of a decreasing failure rate
are more subtle. There are two possibilities. The first is based on the physics of failure, namely,
that certain items exhibit an improvement (over time) in their ability to perform their intended
tasks. Examples are reinforced concrete that strengthens with exposure, drill bits that sharpen
with use, materials that experience work hardening, and immune systems which mature with
time. The second, and probably the more commonly occurring reason, is a psychological one.
It comes into play when we change our opinion, for the better, about an item’s survivability.
For example, our opinion of the credibility of computer software that is thoroughly tested and
debugged keeps improving with use; thus we may judge the software as having a predictive
failure rate that is decreasing. Since the software does not deteriorate with use, its model failure

70
STOCHASTIC MODELS OF FAILURE
rate should be a constant, but since we do not know this constant, its predictive failure rate is
decreasing; (Singpurwalla and Wilson, 1999, p. 77). Mathematically, the above type of argument
is captured by a celebrated theorem in reliability which says that scale mixtures of certain chance
distributions result in distributions having a decreasing failure rate. For example, in Barlow and
Proschan (1975, p. 103), it is shown that Ft =

exp−tFd, which is a scale mixture
of exponentials with a parameter , has a decreasing failure rate. In particular, if  above
has a gamma distribution with a scale parameter  and a shape parameter  (section 3.2.2),
then Ft = / + t, which is a Pareto distribution. Its density at t is of the form
/t + +1 t ≥0, and its failure rate is /t + , which is a decreasing function of t. The
mean of this Pareto is / −1; it exists only when  > 1. Note that a scale mixture is merely
the law of total probability of section 2.4.2. Scale mixtures of distributions can be motivated by
the following two, related, scenarios.
The first scenario is a tangible one, involving the physical act of putting together several items
to form a batch, with each item having its own model failure rate i. Suppose that the is are
known. We are required to assess the failure rate of an item picked at random from the batch.
We assume that in forming the batch, the identity of each item is lost so that we do not know the
i for the selected item, whose predictive failure rate we are required to assess. Such physical
mixtures arise in practice when items coming from different sources are stored in a common
bin, and the proportion of each i determines the mixing distribution .
The second scenario under which scale mixtures arise is less natural, because it models the
mathematics of our thought process. In the case of exponentially distributed lifelengths, if we
are uncertain about  – as we will be – and if our uncertainty is described by , then our
unconditional distribution of lifelengths would be a scale mixture of exponentials. The mixing
now goes on in our minds and is therefore purely psychological.
An intuitive explanation as to why a scale mixture of exponentials results in a predictive
distribution with a decreasing failure rate is easy to see if we bear in mind the notion that the
failure rate is an individual’s judgment, and that judgments change with added information.
In our case the judgment is made at some reference time , and it pertains to the uncertainty
about failure at a future time t, assuming some added knowledge. The added knowledge is the
supposition that the item has not failed at t. It is important to note that when the failure rate is
assessed at time , for any future time t, we are not saying that in actuality the item is surviving
at t; rather, we inquire as to how we would assess our probability were we to suppose that the
item is surviving at t. Thus we may start off with a poor opinion of the item’s reliability, and
upon the supposition of its continued survival, change our opinion for the better, resulting in a
decreasing failure rate; more details are in Barlow (1985).
To summarize, there are two possible reasons for the judgment of a decreasing failure rate.
The first is motivated by the physics of failure and generally pertains to the model failure rate.
The second pertains to the predictive failure rate and is due to the psychology of altering our
opinion about survivability; this is accomplished by mixtures of distributions.
Often reliability growth and burn-in have been given as the reasons for assuming decreasing
failure rates. This is incorrect because both the above operations change the physical character-
istics of an item, so that the changed item has a failure rate which may be different from its
failure rate before the change.
Reliability Growth and Debugging
Reliability growth pertains to an enhancement of reliability due to changes in the design of the
item or due to an elimination of its identified defects (cf. Singpurwalla, 1998); for example,
debugging a piece of software. To describe reliability growth, we must talk about the concatenated
(or adjoined) failure rates – model or predictive – of different versions of the same item, each
version having a failure rate function that is dominated by the failure rate function of its preceding

MODEL FAILURE RATE
71
Time
Failure rate function
T1
T2
T3
T1
T2
T3
Time
Failure rate function
(a)
(b)
r1(t)
r1(t)
r2(t)
r2(t)
r3(t)
r3(t)
r4(t)
r4(t)
Figure 4.3
Concatenated failure rate functions for items undergoing reliability growth.
version. An example is the reliability growth of computer software that undergoes several stages
of testing and debugging (Chen and Singpurwalla, 1997; or Al-Mutairi, Chen, and Singpurwalla,
1998). In Figure 4.3(a) and (b), we see concatenated failure rate functions that are composed of
constant and decreasing failure rate segments, respectively. Concatenated failure rate functions
are often encountered in the literature on software reliability and have been erroneously cited as
examples of items having a decreasing failure rate.
Burn-in and Screening Tests
Burn-in pertains to the elimination of weak items by subjecting each item to a life test, called a
screening test, for a specified period of time (for example Block and Savits, 1997). The hope
is that the weak and defective items will drop out due to early failures so that what remains are
items that have proven themselves in a life test. In practice, burn-in appears to be almost always
done on a one-of-a-kind item that is to be used in life-critical systems, such as spacecraft. The
bathtub curve, discussed later, is often given as a reason for undertaking burn-in. Because of
an accumulation of age during the screening test, the failure rate of an item that survives the
test will be different from its failure rate before the test. Thus, like reliability growth, burn-in
changes the physical characteristics of the item tested. In particular, for items that are judged to
have an increasing failure rate, a burn-in test will make the surviving items inferior to what they
were before the test. Thus, theoretically, burn-in is advantageous only when lifetimes are judged
to have a decreasing predictive failure rate. Why is it that in practice all life-critical items, even
those that are known to deteriorate with use, are subjected to a burn-in? Are the engineers doing
something they should not be doing, or is it so that even items which deteriorate with use could
be judged as having a failure rate which is initially decreasing and then increasing in time? It
turns out that when we are uncertain about the precise form of an increasing model failure rate
function for a deteriorating device, the predictive failure rate would initially decrease and then
increase (Figure 4.4) and thus the engineer’s hunch to always burn-in makes sense. The intuition
underlying the above phenomenon is analogous to the one used to explain the decreasing failure
rate of mixtures of exponentials. That is, mixtures of distributions are a mathematical description
of the psychological process of altering one’s opinion about the reliability of an item. Figure 4.4
shows, for different values of a and b, a U-shaped predictive failure rate of T when its model
failure rate is increasing and is of the form rt   = t +  with  assumed known and the
uncertainity of  described by a gamma distribution having a shape parameter a and a scale

72
STOCHASTIC MODELS OF FAILURE
20
0
t
Lower bound
2
r(t)
a = 4, b = 2
a = 6, b = 3
a = 2, b = 1
Figure 4.4
A U-shaped predictive failure rate generated by increasing model failure rates.
parameter b (for details, Lynn and Singpurwalla, 1997). Gurland and Sethuraman (1995) describe
an analogous phenomenon in which increasing model failure rates could result in monotonically
decreasing predictive failure rates.
Determining an optimum burn-in time is a problem in decision making under uncertainty
wherein we are trading-off one attribute for another (for example Clarotti and Spizzichino, 1990).
There are two separate cases that need to be discussed. In the case of items whose failure rate is
always decreasing we are trading-off the cost of a burn-in versus having an item with the lowest
possible failure rate. The more time we spend under burn-in, the lower will be the failure rate
of an item that survives the burn-in test. Thus ideally, for items having a decreasing failure rate,
the burn-in period should be indefinite, but then we would never commission a surviving item
for use; thus the trade-off. In the case of items that are known to deteriorate with use, but whose
model failure rate we are unable to specify, the predictive failure rate will be judged to initially
decrease and then increase, and now we are trading off the cost of testing plus the depletion of
useful life for the added knowledge about the specific form of the model failure rate. With the
above perspective on burn-in testing, the prevailing argument that the purpose of burn-in is the
elimination of defective items can be justified if we are to view defective items as those having
large values for the model failure rate.
The Bathtub Curve
Many complex technological systems, and also humans, are judged to have a failure rate function
which is in the form of a bathtub curve (Figure 4.5(a)). In fact the bathtub curve has become one
of the hallmarks of engineering reliability. Observe that there are three segments to the bathtub
curve (which is assessed at a reference time ). The initial decreasing segment is referred to as
the infant mortality phase, the middle constant segment as the random phase, and the final
increasing segment as the aging or the wear-out phase. The rationale behind a choice of the
bathtub curve for the failure rate function is as follows: Typically, a newly developed system
may contain design and manufacturing faults, known as birth defects, that would trigger an early
failure; thus the initial failure rate is described by a decreasing function of time. Were we to
be told that the system does not experience a failure due to birth defects, then it is likely that
its subsequent failure is due to causes that cannot be explained, and so the middle phase of the
failure rate is constant over time. Should we suppose that item survives this random phase, then

MODEL FAILURE RATE
73
Age
0
10
30
Failure Rate
Age
Age
0
0
(a)
(b)
(c)
10
30
10
30
Infant 
mortality 
phase
Random phase
Wear-out phase
Infant 
mortality 
phase
Random phase
Wear-out phase
Infant 
mortality 
phase
Random phase
Wear-out phase
F(t)
f (t)
Figure 4.5
The bathtub curve for humans.
its subsequent failure is predominantly due to deterioration or wear, and so the final phase of
the failure rate is an increasing function of time.
The bathtub form of the failure rate is used by actuaries to establish insurance premiums. The
infant mortality period used by actuaries is from birth to age 10 years, the random phase from
10 to 30 years, and the wear-out phase commences at age 30, when premiums increase. The
failure rate for humans during the initial period of the infant mortality phase is very high; that
is, there is a high risk of death immediately after birth. Consequently, many insurance policies
become effective after 15 days following birth. The causes of death between the ages of 10
and 30 years are assumed to be random and are due to events such as epidemics, wars, etc.;
aging is assumed to commence at age 30. It is important to bear in mind that the bathtub curve
is a specific form of the failure rate function (specified at time ), and like all other forms of
the failure rate function is the opinion or the judgment of an assessor about the survivability
of a unit. Under our interpretation of probability, the bathtub curve does not have a physical
reality, and could be chosen as a model for a single one-of-a-kind item, or for any member of a
population of items. Figures 4.5b and c illustrate the nature of the distribution function Ft
and its corresponding density function ft for the bathtub curve of Figure 4.5a.
Even though the bathtub form of the failure rate function is a reasonable idealization for the
failure rate of humans, it may not be appropriate for certain engineering and biological systems.
For many systems, the judgment of a constant failure rate, which implies that the system neither
improves nor deteriorates with use, may not be meaningful. For such systems, a U-shaped failure
rate function may be a more reasonable description of their failure behavior (Figure 4.6(a)). For
systems that do not experience wear, a strictly decreasing or an L-shaped failure rate function
may be appropriate, whereas for systems that do not experience infant mortality, a failure rate

74
STOCHASTIC MODELS OF FAILURE
U-shaped
L-shaped
Reverse L-shaped
0
t
0
t
(a)
(b)
r (t)
r (t)
Figure 4.6
U-shaped and L-shaped failure rate functions.
function that is strictly increasing, or is a constant, or is initially constant and then increasing
may be reasonable (Figure 4.6(b)).
Before closing this section it is desirable to comment on the infant mortality phase of the
bathtub curve. We also need to comment on whether the failure rate function of a bathtub curve
represents the model failure rate or the predictive failure rate. The decreasing form of the failure
rate function does not necessarily imply that the system is indeed improving with use. As I have
said before, this is a rare phenomenon, restricted to scenarios such as the setting of cement, or
in the case of humans, the building-up of an immune system. Rather, the decreasing form of
the failure rate function typically describes our improving opinion about the survivability of the
item. In actuality, a system may experience a gradual wear and/or destruction due to randomly
occurring events, as soon as it is put to use; but these are not judged as being the predominant
causes of initial failure. It is our lack of precise knowledge about the presence or the absence
of manufacturing (or birth) defects which causes us to judge a decreasing failure rate function
during the initial phase of a system’s life. Thus it appears that in most instances the infant
mortality phase of the bathtub curve should pertain to the predictive failure rate. Since the other
two phases of the bathtub curve are a constant and an increasing function of time, it appears (in
the light of our discussions on decreasing failure rates), that these two phases must pertain to the
model failure rate. Thus, in most instances the bathtub curve is more likely to be a concatenation
of a predictive and a model failure rate. If the bathtub curve is U-shaped, then it could possibly
pertain to the predictive failure rate, but most likely it will be the concatenation of a predictive
and a model failure rate.
To conclude, it is our view that the bathtub curve that is commonly discussed and used
by practitioners has an interpretation that is not as elementary as it is made out to be. In the
framework that has been put forth, it is a representation of the opinion of an individual, or a
collection of individuals, and this could be a concatenation of predictive and model failure rate
functions, or just a predictive failure rate function. More on the shape of the failure rate function
can be found in Aalen and Gjessing (2001).
4.4.3
The Retrospective (or Reversed) Failure Rate
In retrospective studies, like the postmortem of an observed failure, or the (unknown) time of
the onset of a disease, the notion of a retrospective failure rate is useful. The retrospective failure
rate is also known as the ‘reversed hazard rate’, and in many respects its behavior parallels that
of the failure rate. Specifically, were we told that an item is in a failed state at t, we may be

MODEL FAILURE RATE
75
interested in assessing its actual time to failure. For example, in forensic studies involving a
homicide, an investigator may want to know the actual time at which the crime was committed.
Such scenarios are duals of the ones we have discussed so far, in the sense that the direction of
time gets reversed from some time t toward zero, rather from t to infinity.
Following the notation of section 4.3, let T be a continuous random variable with an absolutely
continuous distribution function Ft and probability density ft. Let a = inft  Ft > 0 and
b =suptFt<1; roughly speaking, a is the smallest value that T can take for which Fa>0.
Similarly, b is the largest value that T can take for which Fb < 1. The interval ab with
− ≤a < b <  is called the interval of support of Ft. Then for any t > a rt, the
instantaneous retrospective predictive failure rate of T at t is defined as:
rt = lim
dt↓0
Pt −dt ≤T < t  T < t
dt
 thus
rt = lim
dt↓0
Ft −Ft −dt
Ft dt
= ft
Ft
provided that Ft > 0. The above expression forrt parallels that for the failure rate rt given
by (4.7). If the limit given above does not exist, then rt = dFt/Ft (equation (4.8)). Our
definition for rt suggests that for small values of dt rtdt is approximately the probability
that an item that was recorded as being failed at t, actually failed in t −dtt.
As a function of t, the retrospective failure rate function could be monotonic (increasing
or decreasing) or non-monotonic on the interval of support of Ft. Block, Savits and Singh
(1998) show that distributions whose failure rate is decreasing will necessarily have a decreasing
retrospective failure rate, and that there does not exist a nonnegative random variable with an
upper bound for which the retrospective failure rate is increasing. Thus distributions like the
Weibull or the gamma, which have an increasing failure rate, will have a decreasing retrospective
failure rate. The above feature makes the retrospective failure rate function unattractive vis-á-vis
its ability to discriminate between failure models. Thus for example, whereas the failure rate
function for a gamma distribution is increasing and that for a Pareto distribution is decreasing,
the retrospective failure rate function of both these distribution functions is decreasing. Finally,
Block, Savits and Singh (1998) show that if the retrospective failure rate function is increasing
on the interval of support of some distribution, then the interval must have a finite upper point.
A relationship similar to the one involving the cumulative hazard function and the sur-
vival function (equation (4.9)) is available for the cumulative retrospective hazard function,
defined as
Ht
def=
 b
t ru du
and Ft, the distribution function. Specifically,
Ft = exp−Ht
see Chandra and Roy (2001).
Solving for Ft and ft in (4.8) and the definition of rt given above, we can see that
Ft =
rt
rt +rt
and that
ft =
rtrt
rt +rt	

76
STOCHASTIC MODELS OF FAILURE
A notion that is converse to that of residual life (section 4.2) is that of a dormant life, also
known as the ‘inactivity time’ (cf. Chandra and Roy, 2001). The dormant life of an item that
is recorded as being failed at t is t −T  T ≤t; its expected value Et −T  T ≤t is the
mean dormant life (MDL). The notion of an MDL parallels that of MRL, the mean residual life.
Verify that
Pt −T ≤u  T ≤t = Ft −Ft −u/Ft
so that the dormant life has density at u of the form ft −u/Ft. It now follows that the MDL
is given as
Et −T  T ≤t =
1
Ft
 t
a Fu du	
4.5
MULTIVARIATE ANALOGUES OF THE FAILURE RATE FUNCTION
Multivariate analogues of the failure rate function have been considered, among others, by
Basu (1971), Cox (1972), Johnson and Kotz (1975), Marshall (1975) and by Puri and Rubin
(1974). One such analogue is the ‘hazard gradient’ discussed by Marshall (1975); this will be
considered first.
4.5.1
The Hazard Gradient
A good starting point for introducing the hazard gradient is the cumulative hazard function
Ht = −ln Ft =
 t
0 rudu
t ≥0
(4.11)
mentioned in section (4.3).
Consider Rt1
 
 
 tn = PT1 ≥t1
 
 
 Tn ≥tn, the joint survival function of n lifelengths
T1
 
 
 Tn, where, for convenience, we have omitted the . Let t = t1
 
 
 tn be such that
Rt1
 
 
 tn > 0. Then, analogous to (4.11), we define Ht, the multivariate cumulative
hazard function as Ht=−ln Rt1
 
 
 tn. If the n-dimensional function Ht has a gradient,
say rt = Ht, where rt = r1t
 
 
 rnt, with
rit = 
t Ht
i = 1
 
 
 n
(4.12)
then rt is called the hazard gradient of Rt1
 
 
 tn.
Johnson and Kotz (1975) interpret rit as the conditional failure rate of Ti evaluated at ti,
were it to be so that Tj > tj, for all j ̸= i. That is
rit =
fiti  Tj > tj for all j ̸= i
PTi > ti  Tj > tj for all j ̸= i
(4.13)
where fiti  Tj > tj, for all j ̸= i is the conditional probability density function of Ti, given that
Tj > tj, for all j ̸= i.
From elementary calculus, it now follows that
Ht =
 t
0 rudu
(4.14)

MULTIVARIATE ANALOGUES OF THE FAILURE RATE FUNCTION
77
from which we have as a multivariate analogue of (4.9) the result that
PT1 ≥t1
 
 
 Tn ≥tn = exp−
 t
0 rudu
(4.15)
the role of the hazard gradient is now apparent. Equation (4.14) holds as long as ru exists
almost everywhere and that along the path of integration 0tHt is absolutely continuous.
The following (additive) decomposition of Ht given by Marshall (1975) is noteworthy; it
parallels the (additive) decomposition of Ht in the univariate case. Specifically,
Ht=
 t1
0
r1u10
 
 
 0du1 +
 t2
0
r2t1u20
 
 
 0du2 +
 
 
 +
 tn
0
rnt1
 
 
 tn−1undun
(4.16)
where r1u10
 
 
 0 is the failure rate of T1 at u1, and rit1
 
 
 ti−1ui0
 
 
 0 is the
conditional failure rate of Ti at ui, were it be such that T1 ≥t1T2 ≥t2
 
 
 Ti−1 ≥ti−1. An
interpretation of the decomposition of (4.16) will be given in section 4.6.2; however, a conse-
quence of this decomposition is the well-known (multiplicative) decomposition of Rt1
 
 
 tn.
Specifically,
PT1 ≥t1
 
 
 Tn ≥tn=PT1 ≥t1 PT2 ≥t2  T1 ≥t1
 
 
 
 
 
 PTn ≥tn  T1 ≥t1
 
 
 Tn−1 ≥tn−1
see Marshall (1975).
The univariate analogues of the additive and the multiplicative decompositions given above
appear in section 4.3, following Equation (4.10).
4.5.2
The Multivariate Failure Rate Function
A more natural, though perhaps less useful, multivariate analogue of the univariate failure rate
function is the multivariate failure rate function introduced by Basu (1971). I give below its
bivariate version, and state some of its interesting characteristics.
Suppose that an absolutely continuous bivariate distribution function Ft1t2 with F00=0
generates a probability density function ft1t2 at t1t2. Then the bivariate failure rate of
Ft1t2 at some 12 is, for PT1 ≥1T2 ≥2 > 0, given as
r12 =
f12
PT1 ≥1T2 ≥2
(4.17)
=
f12
1 + F12 −F1 −F2	
Clearly, when T1 and T2 are mutually independent, r12 = r1r2, where r1 and
r2 are the corresponding univariate failure rates at 1 and 2, respectively (equation (4.7)).
The relationship of (4.17) can be extended to the multivariate case.
As seen before, in section 4.4, the only univariate distribution whose failure rate is a constant
is the exponential. We now ask if there is an analog to this result when the r12 of (4.17)
is a constant, say  > 0. Basu (1971) shows that the only absolutely continuous bivariate
distribution with marginal distributions that are exponential and whose bivariate failure rate
function is a constant, is the one that is obtained when T1 and T2 are exponentially distributed.
The search for multivariate distributions with exponential marginals is motivated by the fact
that univariate exponential distributions, because of their simplicity and ease of use, are very
popular in engineering reliability. The attractiveness of absolute continuity stems from the fact

78
STOCHASTIC MODELS OF FAILURE
that statistical inference involving such distributions is relatively easy (cf. Proschan and Sullo,
1974). If Basu’s (1971) requirement of exponential marginals is relaxed, then according to a
theorem by Puri and Rubin (1974), the only absolutely continuous multivariate distribution whose
multivariate failure rate (in the sense of (4.17)) is a constant is the one given by a mixture of
exponential distributions.
Thus to summarize, it appears that the main value of the multivariate analogue of the failure
rate function considered in this subsection is a characterization of the multivariate failure rate
function that is a constant.
4.5.3
The Conditional Failure Rate Functions
Another multivariate analogue of the univariate failure rate function is the one proposed by Cox
(1972) in his classic paper, and under the subheading ‘bivariate life tables’. In the bivariate case
involving lifelengths T1 and T2 we define, analogous to (4.4) of section 4.3, the following four
univariate conditional failure rate functions:
rp0t=lim
dt↓0
Pt ≤Tp ≤t + dt  T1 ≥tT2 ≥t
dt

for p = 12
r21t  u =lim
dt↓0
Pt ≤T2 ≤t + dt  T2 ≥tT1 = u
dt

for u < t
and
r12t  u =lim
dt↓0
Pt ≤T1 ≤t + dt  T1 ≥tT2 = u
dt

for u < t	
(4.18)
In the latter two expressions, Ti = u i = 12, is to be interpreted as Ti ∈uu + du, where
du is infinitesimal.
A motivation for introducing the conditional failure rate functions parallels that for introducing
the failure rate function of (4.4) and (4.5). Namely, that a subject matter specialist can subjectively
specify the functions rp0t, for p = 12, based on the aging characteristics of an item, and the
functions rijt  u ij = 12 based on the aging as well as the load sharing features of the
surviving item; for example, Freund (1961). If Ft1t2 denotes the joint distribution function
of T1 and T2, and ft1t2 the probability density at t1t2 generated by Ft1t2, then using
arguments that parallel to those leading to (4.10), it can be shown that for t1 ≤t2
ft1t2 = exp−
 t1
0 r10u + r20udu −
 t2
t1
r21u  t1dur10t1r21t2  t1
(4.19)
analogously for the case t2 ≤t1.
Consequently, as was the case with the univariate failure rate function, a specification of the
conditional failure rate functions of (4.18) enables us to obtain ft1t2 and hence Ft1t2.
Alternatively, if we are to know Rt1t2 = PT1 ≥t1T2 ≥t2, then we may obtain r10t and
rijt  u ij = 12, via relationships of the type:
r10t = −
1
Rtt
 
t Rtu

u=t

and
r12t  u = −2Rtu
t u
/Rtu
u
	
Finally, it is relatively easy to show that T1 is independent of T2, if and only if r12t  u=r10t,
and r21t  u = r20t.

THE HAZARD POTENTIAL OF ITEMS AND INDIVIDUALS
79
To conclude this section, we note that Rt1
 
 
 tn can be obtained through (4.15) via the
hazard gradient ru or through (4.19) via the conditional failure rate function. The former is
of mathematical interest, especially for the additive decomposition of (4.16); the latter has an
operational appeal since it upholds the original spirit of introducing the failure rate function.
4.6
THE HAZARD POTENTIAL OF ITEMS AND INDIVIDUALS
In sections 4.3 and 4.5, we have seen the useful role played by the cumulative hazard function
Ht, and its multivariate analog Ht. In the univariate case, we have seen that when Ft is
absolutely continuous
Ft = e−Ht
(4.20)
where Ht =
 t
0 rudu; note that for ru > 0, for all u ≥0, Ht monotonically increases in t.
The aim of this section is to interpret the quantity Ht in a manner that provides some insight
into the relationship Ft = exp−Ht.
We start with the remark that since rudu is approximately the conditional probability that
an item of age u will fail in the time interval uu + du, the quantity

rudu is a sum of
conditional probabilities. However, the conditioning events change over time, so that taking
their sum is not a meaningful operation within the calculus of probability. Consequently, the
cumulative hazard function Ht cannot be a probability, and therefore lacks a probabilistic
interpretation. What then does the quantity Ht represent? In what follows I endeavor to address
this question; however, I am cognizant of the possibility that there could be other interpretations.
It is noted that the conditional probability rudu is subjectively specified, at least in the
framework that I have espoused, and as such it incorporates an assessor’s judgment about both
the inherent quality of an item and the environment under which it is scheduled to operate. By
‘quality’ I mean a resistance to failure-causing agents, such as crack growth, wear, a weakening
of the immune system, etc. Consequently, the failure rate function of an item of poor quality that
operates in a benign environment could be smaller than that of a high-quality item operating in a
harsh environment. In effect, the quantity rudu encapsulates an assessor’s judgment about the
manner in which an item and its environment interact, vis-à-vis the item’s lifelength. Keeping
the above in mind we now turn our attention to (4.20), and note that its right-hand side e−Ht
is also the distribution function of an exponentially distributed random variable, say X, with a
scale parameter one, evaluated at Ht. That is
PT ≥t = e−Ht = PX ≥Ht	
(4.21)
Alternatively said, corresponding to every nonnegative random variable T, taking values t,
for t ∈0, and having a distribution function Ft, there exists a random variable X, taking
values Ht, for 0<Ht<, whose distribution function is an exponential with scale parameter
one. The distribution function of T is said to be indexed by t, whereas that of X is indexed by
Ht, where Ht =
 t
0 dFt/Ft.
From (4.21), we see that if T represents the time to failure of an item, then the item will
fail when Ht reaches a random threshold, X (Figure 4.7). We call this threshold the hazard
potential (HP) of the item, and propose the view that when conceived, every item possesses
some kind of an unknown resource X, and that the effect of its use is a depletion of this resource
according to the dictates of Ht. This unknown resource is the hazard potential of the item,
and like potential energy, which reflects the amount of work that an item can do, the hazard
potential represents an item’s resistance to failure. Our uncertainty about the unknown resource
is described by an exponential distribution with scale parameter one, and the function Ht (being

80
STOCHASTIC MODELS OF FAILURE
Cumulative 
hazard H(t)
b
a
0
Ta
Tb (= Time to failure 
         when X = b)
Time t
The (unknown) 
hazard potential, X
Figure 4.7
Illustration of resource depletion by the cumulative hazard function.
nondecreasing in t) depicts the rate at which the resource gets consumed (Figure 4.7). This is one
interpretation of Ht; its role in explaining lifelengths having a decreasing failure rate function
has been articulated by Kotz and Singpurwalla (1999).
An alternate interpretation of Ht is motivated by the fact that the exponential distribution of
X is indexed by Ht. That is, Ht may be viewed as a change of time scale from the natural
clock time t to a transformed time Ht. Under this interpretation of Ht, we may, de facto,
make the claim that the lifelengths of any and all items are always exponentially distributed
(with a scale parameter one) on a suitably chosen scale, Ht. The choice of the scale Ht is
subjective, and is determined by an assessment of the item’s inherent quality and its operating
environment. For example, two different components operating in the same environment may
not necessarily have the same Ht; similarly, changing the environment from say E1 to E2, will
generally change the cumulative hazard function from H1t to H2t (Figure 4.8). In general
Ht > t would reflect a harsh environment (e.g. an accelerated test) whereas Ht < t would
The (unknown) 
hazard potential, X
a
0
Time t
T1 (= Time to failure under
         environment E2)
T1
H1(t)
H2(t)
Figure 4.8
Effect of changing the environment on the cumulative hazard function.

THE HAZARD POTENTIAL OF ITEMS AND INDIVIDUALS
81
correspond to a benign environment. The change of a time scale interpretation of Ht has also
been recognized by Çinlar and Ozekici (1987).
The above material can be summarized via the following two assertions, the second of which
may be interpreted as a type of an indifference principle of survival.
Theorem 4.1.
Corresponding to every nonnegative random variable T having distribution
function F(t), there exists an exponentially distributed random variable X (with a scale parameter
one) that is indexed by Ht =
 t
0 dFt/Ft. Equivalently,
Corollary 4.1.
All lifelengths can be regarded as having an exponential distribution (with a
scale parameter one) on a suitably chosen time scale.
Regarding the exponentially distributed random variable X, it is evident that, in general, it will
not possess the lack of memory property unless Ht=t. A distribution function Fx=1−Fx
is said to possess the lack of memory property if for all x t ≥0 Fx + t = FxFt; the only
univariate distribution function possessing this property is the exponential distribution indexed by
Ht=t. Continuing along this vein, it is also easy to verify that the entropy of the exponentially
distributed random variable X is one, only when Ht = t. The entropy of a random variable X
having an absolutely continuous distribution function Fx is −
 
0 fxlogfxdx, where fx
is the probability density generated by Fx at x.
We close this discussion by noting that three quantities have been introduced here, a lifelength
T that can be observed (i.e. measured), its cumulative hazard function Ht and the hazard
potential X; both X and Ht are not observable. Given any two of these three entities we can
obtain the third. Finally, we are able to interpret X as a resource, and Ht as the rate at which
this resource gets consumed.
4.6.1
Hazard Potentials and Dependent Lifelengths
The likes of Figure 4.8 suggest that T1 and T2, the lifelengths of two items having a common
(unknown) hazard potential X, will be dependent. This is because a knowledge of T1 (or T2)
tells us something about X, and this in turn changes our assessment of T2 (or T1). The notion
of dependent lifelengths is further articulated in section 4.7. Similarly, if the hazard potentials
X1 and X2 are dependent, then their lifelengths T1 and T2 will be dependent, but only if we can
specify both H1t and H2t, for t ≥0, or if only one of these can be specified, then we should
be able to say something about the relationship between H1t and H2t. Such assertions are
best summarized via the following two theorems (and also Theorem 4.4, of section 4.6.2).
Theorem 4.2.
Lifetimes T1 and T2 are independent if and only if their hazard potentials X1
and X2 are indepenent, and if H1t H2t t ≥0 are assumed known.
Proof.
When X1 and X2 are indepenent,
P X1 ≥H1t1X2 ≥H2t2 = PX1 ≥H1t1 · PX2 ≥H2t2
for any H1t1 and H2t2. Consequently,
PT1 ≥t1T2 ≥t2H1tH2tt ≥0
= P X1 ≥H1t1X2 ≥H2t2
= PX1 ≥H1t1 · PX2 ≥H2t2
= PT1 ≥t1H1tt ≥0 · PT2 ≥t2H2tt ≥0	

82
STOCHASTIC MODELS OF FAILURE
Thus knowing H1t and H2t T1 and T2 are independent. Similarly the reverse.
When Hit i = 12 or both i = 1 and 2, for t ≥0 cannot be specified, Theorem 4.2 gets
weakened in the sense that only the ‘if’ part of the theorem will hold. Specifically, T1 and T2 will
be independent even when X1 and X2 are dependent. The intuitive argument proceeds as follows.
Observing T1 provides no added insight about X1 since H1t is not specified. Consequently,
there is no added insight about X2 either, and thence about T2. Similarly, when T2 is observed and
H2t not specified. Thus T1 and T2 are independent (unless of course one is willing to make other
assumptions about H1t and H2t t ≥0). Mathematically, without knowing Hit i = 12,
we are unable to relate PT1 ≥t1T2 ≥t2 with the distribution of X1 and X2. The above is
summarized via
Corollary 4.2.1.
Lifetimes T1 and T2 are independent whenever H1t and/or H2t t ≥0 are
unknown.
The converse of Theorem 4.2 is
Corollary 4.2.2.
Lifetimes T1 and T2 are dependent if and only if their hazard potentials X1
and X2 are depenent, and if H1t and H2t are specified.
Corollary 4.2.2 puts aside the often expressed view that the lifetimes of items sharing a common
environment are necessarily dependent (cf. Marshall, 1975; Lindley and Singpurwalla, 1986).
That is, it is a common environment that causes dependence among lifetimes. Corollary 4.2.2
asserts that it is the commanilities in the (HP)s, that is the cause of interdependent lifetimes.
Dependent (HP)s are a manifestation of similarities in design, manufacture, or a genetic make-up.
In the language of probabilistic causality of Suppes (1970), the common environment can be
interpreted as a spurious cause of dependent lifetimes, whereas dependent (or identical) (HP)s
as their prima facie (or genuine) cause.
Theorem 4.2 and Corollary 4.2.1 pertain to the two extreme cases wherein the Hits i = 12
are either known or are unknown. An intermediate case is wherein one of the Hits, say
H1t t ≥0 is known, and the other unknown, save for the fact that H1t > H2t. For such
scenarios we are able to show that
Theorem 4.3.
Suppose that H1t > ≤H2 t, and either H1t or H2t t ≥0 is specified;
then X1 and X2 dependent implies that T1 and T2 are also dependent.
Proof.
The proof is by contradiction. For this, suppose that X1 and X2 have a bivariate
exponential distribution of Marshall and Olkin (1967). Specifically, for 12 and 12 > 0,
P X1 ≥xX2 ≥y = exp−1x −2y −12 maxxy
= exp−1 + 12x −2y if x > y	
The marginal distribution of Xi PXi ≥x = exp−i + 12x i = 12. For the Xis to be
dependent on (HP)s we need to have i + 12 = 1, for i = 12, and 12 > 0; this would imply
that 1 = 2 = . Thus
P X1 ≥xX2 ≥y = exp−x + 2y	
If we set x = H1t1 and y = H2t2, for some t1t2 ≥0, then x > y would imply that H2t2 =
H1t2 −, for some unknown  > 0	 Consequently
P X1 ≥xX2 ≥y = P X1 ≥H1t1X2 ≥H1t2 −
= exp−H1t1 + 2 H1t2 −	

THE HAZARD POTENTIAL OF ITEMS AND INDIVIDUALS
83
Given the above we need to show that T1 and T2 are dependent. Suppose not; then
P T1 ≥t1T2 ≥t2H1t1H2t2t1t2 ≥0
= P T1 ≥t1H1t1t1 ≥0P T2 ≥t2H2t2t2 ≥0
= P X1 ≥H1t1P X2 ≥H2t2
= exp−H1t1exp−H1t2 −
= P X1 ≥H1t1X2 ≥H1t2 −
since the first term of the above equation does not entail elements of the second. Thus I have
P X1 ≥H1t1X2 ≥H1t2 − = exp−H1t1 + H1t2 −	
The expressions P X1 ≥xX2 ≥y and P X1 ≥H1t1X2 ≥H1t2 − will agree with each
other if 2 =1. However, 2 =1 would imply that 12 =0, which would contradict the hypothesis
that X1 and X2 are dependent. The proof when H1t ≤H2t will follow along similar lines.
A consequence of Corollary 4.2.2 is that we are able to generate families of dependent
lifelengths using a multivariate distribution with exponential marginals as a seed. The multivariate
exponential distribution of Marshall and Olkin (1967) can be one such seed; others could be
the one proposed by Singpurwalla and Youngren (1993) and those referred to in Kotz and
Singpurwalla (1999). Details are in Singpurwalla (2006a).
4.6.2
The Hazard Gradient and Conditional Hazard Potentials
In this section, we obtain a converse to Theorem 4.3. Specifically, we start with dependent
lifelengths and explore the nature of their dependence on the hazard potentials. The hazard
gradient plays a role here, and in the sequel, it motivates the introduction of another notion,
namely that of the ‘conditional hazard potential’. The main result of this section is that a collection
of dependent lifelengths can be replaced by a collection of independent exponentially distributed
random variables indexed on suitably chosen scales. The independent random variables are the
conditional hazard potentials.
To put matters in perspective, we recall from section 4.5.1 that if Ht = −ln Rt, where
Rt = PT1 ≥t1
 
 
 Tn ≥tn, then ru is the hazard gradient of Ht. Furthermore Ht =
 t
0 rudu, and that Ht has an additive decomposition given by (4.16). The first term of this
decomposition is the integral of r1u10
 
 
 0 – the failure rate of T1 at u1. This integral,
which is the cumulative hazard rate function of T1 at t1 will be denoted by H1t1; that is
H1t1 =
 t1
0
r1u10
 
 
 0du1	
Similarly, the second term of the decomposition is denoted by
H2t2  t1 =
 t2
0
r2t1u20
 
 
 0du2
where the integrand r2t1u20
 
 
 0 is the conditional failure rate of T2 at u2 given that
T1 ≥t1. Continuing in this vein, the last term of the decomposition is
Hntn  t1
 
 
 tn−1 =
 tn
0
rnt1
 
 
 tn−1undun	

84
STOCHASTIC MODELS OF FAILURE
Thus we have
Ht = H1t1 + H2t2  t1 + 
 
 
 + Hntn  t1
 
 
 tn−1	
(4.22)
Since the cumulative hazard function has no interpretive content within the calculus of prob-
ability, Ht and its components will also not have any interpretive content. However, since
Rt = exp−Ht, we may write
P T1 ≥t1
 
 
 Tn ≥tn = e−H1t1+H2t2  t1+
 
 
 +Hntn  t1
 
 
 tn−1
= e−H1t1 e−H2t2  t1 
 
 
 e−Hntn  t1
 
 
 tn−1	
(4.23)
Clearly, exp−H1t1 = PT1 ≥t1, since H1t1 is the cumulative hazard function of
T1. Similarly, by following arguments analogous to those leading to (4.9), we can see that
exp−H2t2  t1 = PT2 ≥t2  T1 ≥t1, and in general
PTn ≥tn  T1 ≥t1
 
 
 Tn−1 ≥tn−1 = e−Hntn  t1
 
 
 tn−1	
(4.24)
As a consequence of the above analogies we have, from (4.23), the relationships
P T1 ≥t1
 
 
 Tn ≥tn = e−H1t1 e−H2t2  t1 
 
 
 e−Hntn  t1
 
 
 tn−1
= PT1 ≥t1 PT2 ≥t2  T1 ≥t1
 
 

 
 
 PTn ≥tn  T1 ≥t1
 
 
 Tn−1 ≥tn−1
the latter equality also being true by virtue of the multiplicative decomposition of PT1 ≥
t1
 
 
 Tn ≥tn.
Let X1
 
 
 Xn be the hazard potentials corresponding to the lifelengths T1
 
 
 Tn, and the
cumulative hazard functions H1t1
 
 
 Hntn, respectively. Then a consequence of (4.24) is
the result that
P Tn ≥tn  T1 ≥t1
 
 
 Tn−1 ≥tn−1 = PXn ≥Hntn  X1 ≥H1t1
 
 
 

 
 
 Xn−1 ≥Hn−1tn−1
= e−Hntn  t1
 
 
 tn−1	
(4.25)
Since T1
 
 
 Tn are not assumed to be independent, the hazard potentials X1
 
 
 Xn are, by
virtue of Theorem 2, not independent. However, exp−Hntn  t1
 
 
 tn−1 is the distribution
function of an exponentially distributed random variable, say X∗
n, with a scale parameter one,
evaluated at Hntn  t1
 
 
 tn−1. Thus, a consequence of (4.25) is the result that for all n ≥2
PXn ≥Hntn  X1 ≥H1t1
 
 
 Xn−1 ≥Hn−1tn−1 = PX∗
n ≥Hntn  t1
 
 
 tn−1	
The random variable X∗
n is called the conditional hazard potential of the n-th item; i.e.
the item whose lifelength is Tn. Its (unit) exponential distribution function is indexed by
Hntn  t1
 
 
 tn−1. By contrast, Xn, the hazard potential of the n-th item has a (unit) exponential
distribution that is indexed by Hntn.

PROBABILITY MODELS FOR INTERDEPENDENT LIFELENGTHS
85
Similarly, corresponding to each term of (4.23), save the first, there exist random variables
X∗
2 X∗
3
 
 
 X∗
n−1, independent of each other and also of X∗
n such that
PT1 ≥t1
 
 
 Tn ≥tn =PX1 ≥H1t1 PX∗
2 ≥H2t2  t1 
 
 

 
 
 PX∗
n ≥Hntn  t1
 
 
 tn−1	
We now have, as a multivariate analogue to Theorem 4.1,
Theorem 4.4.
Corresponding to every collection of nonnegative random variables T1
 
 
 Tn
having a survival function Rt1
 
 
 tn, there exists a collection of n independent and exponen-
tially distributed random variables X1X∗
2
 
 
 X∗
n, (with scale parameter one), with X1 indexed
on H1t, and X∗
i indexed on Hiti  t1
 
 
 ti−1, for i = 2
 
 
 n and n ≥2.
4.7
PROBABILITY MODELS FOR INTERDEPENDENT LIFELENGTHS
The notion of independent events was introduced in section 2.2.1, and that of independent
lifelengths in section 4.2. Within the framework of betting, independence is made operational
by asserting that for two events  and , a knowledge of the occurrence (or not) of ,
does not change one’s bets on , and vice versa. Lifelengths that are not independent are
said to be interdependent, or simply, dependent. Dependent lifelengths are also referred to
as interacting lifelengths. An example of dependent lifelengths is a sequence of exchangeable
lifelengths, assuming that the sequence is not entirely comprised of independent random variables
(section 3.1.2). We have seen that both independence and exchangeability are judgments, and
that such judgments simplify the assignment of probabilities. Consequently, dependence, as the
negation of independence, is also a judgment. However, to be useful, judgments of dependence
demand more of a user, namely, a specification of the exact manner in which the bets on one
lifelength change as knowledge about the disposition of the remaining lifelengths were to be
given. Probability models for dependent lifelengths provide such specifications, and the purpose
of this section is to highlight some such models. The models described here are motivated
by scenarios that involve an underlying physical or biological structure. However, there do
exist in the literature several models for dependence that have been motivated by mathematical
considerations alone; an encyclopedic review is in Kotz, Balakrishnan and Johnson (2000). To
gain a deeper appreciation of the mathematical structure of dependence I recommend the research
monograph edited by Block, Sampson and Savits (1990), and the book by Arnold, Castillo, and
Sarabia (1992). For purposes of discussion I focus attention on the bivariate case, so that the
models proposed in sections 4.7.1 and thereafter pertain to two lifelengths. But before doing so,
I introduce some preliminaries.
4.7.1
Preliminaries: Bivariate Distributions
Let T1 and T2 be the lifelengths of two items, and following the notation of section 4.2, let PT1 ≥
t1T2 ≥t2=Rt1t2=Ft1t2. Similarly, let PT1 ≤t1T2 ≤t2=Ft1t2.
In what follows we shall omit . It is easy to verify that
Ft1t2 = 1 −F1t1 −F2t2 + Ft1t2
(4.26)
where Fiti is the marginal distribution function of Ti, obtained via the operations Ft1 =
F1t1 and Ft2 = F2t2. Also, F1t10 = F20t2 = F00 = 0F = 1, and the
expected value of Fiti is, ETi =
 
0 F itidti, where F iti = 1 −Fiti i = 12.

86
STOCHASTIC MODELS OF FAILURE
Suppose that the partial derivative 2Ft1t2/t1t2 exists (almost) everywhere, and let
ft1t2 = 2Ft1t2/t1t2. Then, the bivariate distribution function Ft1t2 is said to have a
bivariate density ft1t2, and
Ft1t2 =
 t1
0
 t2
0
fs1s2ds1ds2	
It is important to note that a bivariate distribution function Ft1t2 is not uniquely determined
by its marginal distribution functions F1t1 and F2t2. There are an infinite number of solutions
to the problem of determining Ft1t2 from F1t1 and F2t2. One such solution is given by
the Fréchet bounds (Fréchet, 1951).
maxF1t1 + F2t2 −10 ≤Ft1t2 ≤minF1t1F2t2
(4.27)
the bounds are themselves bivariate distributions whose marginals are F1t1 and F2t2. An
exception to the above occurs when for all t1t2 ≥0, the events T1 ≤t1 and T2 ≤t2 are judged
independent, because now
Ft1t2 = F1t1 F2t2
and so the marginals provide a unique joint distribution.
Another way to construct Ft1t2 from F1t1 and F2t2 is due to Morgenstern (1956).
Specifically, for some  0 ≤ ≤1,
Ft1t2   = F1t1 F2t2 1 + 1 −F1t11 −F2t2	
(4.28)
A bivariate exponential distribution of Gumbel (1960) (section 4.7.2) is based on this con-
struction. Yet another approach is the method of copulas described below. Singpurwalla and
Kong (2004) have used this approach to construct a new family of bivariate distributions with
exponential marginals (section 4.7.7).
The Method of Copulas
A copula C is a bivariate distribution on 01×01, whose marginal distributions are uniform.
Copulas join (i.e. couple) univariate distribution functions to form multivariate distribution
functions (Nelson, 1995). This feature is encapsulated in the following theorem.
Theorem 4.5.
(Sklar, 1959).
Let F be a two-dimensional distribution function with marginal
distribution functions F1 and F2. Then there exists a copula C such that Ft1t2 =
CF1t1F2t2. Conversely, for any univariate distribution functions F1 and F2 and any cop-
ula C, the function Ft1t2 = CF1t1F2t2 is a two-dimensional function with marginal
distribution functions F1 and F2.
The notion of copulas and Sklar’s theorem generalize to the multivariate case. Sklar’s theorem
enables us to generate copulas, and copulas can be used to characterize certain properties
of sequences of random variables. Specifically, Ft1t2 = CF1t1F2t2 implies that for
0 ≤u v ≤1
Cuv = F

F −1
1 uF −1
2 v


PROBABILITY MODELS FOR INTERDEPENDENT LIFELENGTHS
87
so that knowing F F1 and F2, we are able to generate C. Thus, for example, if T1 and
T2 are independent random variables with distribution functions F1 and F2, respectively, then
Ft1t2=F1t1F2t2 from which it follows that Cuv=uv. Conversely, by Sklar’s theorem,
T1 and T2 are independent if Cuv = uv. Thus T1 and T2 are independent if, and only if,
Cuv = uv. In a similar vein, we can argue that since T1 and T2 are exchangeable implies that
the vectors T1T2 and T2T1 have the same distribution, T1 and T2 are exchangeable if, and
only if, F1 = F2 and Cuv = Cuv.
Sklar’s theorem also enables us to obtain bounds on a copula Cuv via the Fréchet bounds
of (4.27); this is because the Fréchet bounds are themselves distributions. Specifically, for
0 ≤u v ≤1,
maxu + v −10 ≤Cuv ≤minuv
maxu + v −10 is a copula for maxF1t1 + F2t2 −10 and minuv is a copula for
minF1t1F2t2. Finally, Morgenstern’s distribution of (4.28) gives rise to the copula
Cuv = uv1 + 1 −u1 −v	
An alternate method of generating copulas is due to Genest and MacKay (1986).
Whereas a copula C joins univariate distribution functions to form a multivariate distribution,
a survival copula C joins univariate survival functions to form a multivariate survival func-
tion. Thus in the bivariate case, we have Ft1t2 = CF 1t1F 2t2, where it can be easily
seen that
Cuv = u + v −1 + C1 −u1 −v	
Like C C is a copula, but C is not to be confused with Cuv, the bivariate survival function
of two uniformly distributed random variables. This is because
Cuv = 1 −u −v + Cuv = C1 −u1 −v	
Interest in survival copulas stems from the fact that for some multivariate distributions, such
as Marshall and Olkin’s (1967) multivariate exponential, survival copulas take simpler forms
than their corresponding copulas.
Measures of Interdependence
The dependence of T1 on T2 (or vice versa) is best described via the conditional survival
function PT1 ≥t1  T2 = t2, and/or the conditional mean ET1  T2 = t2, where
PT1 ≥t1  T2 = t2 = PT1 ≥t1 T2 = t2
PT2 = t2

and
(4.29)
ET1  T2 = t2 =
 
0 1 −PT1 ≥t1  T2 = t2dt1	
It follows from the above that when (T1 ≥t1 and T2 = t2 are judged independent, PT1 ≥
t1  T2 = t2 = PT1 ≥t1, and ET1  T2 = t2 = ET1. The conditional mean ET1  T2 = t2 is
also known as the regression of T1 on T2.

88
STOCHASTIC MODELS OF FAILURE
If T1 and T2 are judged dependent, then the extend to which T1 and T2 experience a linear
relationship is measured by the product moment ET1T2, where (assuming that ft1t2 exists),
ET1T2 =
 
0
 
0
t1t2ft1t2dt1dt2
(4.30)
=
 
0
t1ET2  T1 = t1f1t1dt1
f1t1 is the probability density generated by F1t1.
A normalization of the product moment to yield values between −1 and +1 results in Pearson’s
coefficient of correlation T1T2, where
T1T2 = ET1T2 −ET1ET2
VT1VT21/2

VTi is the variance of Fitii = 12. The numerator, ET1T2 −ET1ET2, is known as the
covariance of T1 and T2; it is denoted CovT1T2.
It can be verified that −1≤T1T2≤+1, and that T1T2=0 if T1 and T2 are independent.
However, since T1T2 provides an assessment of only the extent of a linear relationship
between T1 and T2 T1T2=0, does not necessarily imply that T1 and T2 are independent; one
exception is the case wherein T1 and T2 have a bivariate Gaussian distribution. Another exception
is the BVE of section 4.7.4. A stronger result pertaining to independence under uncorrelatedness
is due to Joag-Dev (1983), who shows that when T1 and T2 are ‘associated’, T1T2=0 implies
that T1 and T2 are independent. The notion of association, as a measure of dependence, is due to
Esary, Proschan and Walkup (1967). It says that a random vector T = T1
 
 
 Tn is associated
if for every (co-ordinatewise) non-decreasing function f and g, CovfTgT ≥0.
Values of T1T2 > <0 suggest that the events T1 ≥t1 and T2 ≥t2 are positively
(negatively) dependent, for all values of t1 and t2. Under positive dependence the failure of one
component increases the probability of failure of the surviving components. Positive dependence
manifests itself when components share a common load or when components operate in a common
environment. With negative dependence, the failure of one component increases (decreases) the
probability of survival (failure) of the other component. For physical systems, the judgment of
negative dependence is difficult to foresee. With certain biological systems, negative dependence
is justified on grounds that for entities that compete for limited resources, such as food, the
failure of one unit increases the available resources for the surviving unit, and thus its probability
of failure decreases.
The departure of T1 from the regression of T1 on T2 is measured by the squared correla-
tion ratio
2T1  T2 =
1
VT2
 
0 ET1 −ET1  T2 = t22f2t2dt2	
Like the conditional mean and the coefficient of correlation, the squared correlation ratio is also
a measure of the dependence of T1 on T2.
By making the transformations u = F1t1 v = F2t2 and cuv = FF −1
1 uF −1
2 v, it can
be seen that in terms of copulas, the coefficient of correlation takes the form
T1T2 = VT1 VT2−1
2
 1
0
 1
0 Cuv −uvdF −1
1 udF −1
2 v
so that T1T2 = 0, if T1 and T2 are independent.

PROBABILITY MODELS FOR INTERDEPENDENT LIFELENGTHS
89
The above representation of T1T2 suggests some alternate measures of dependence of T1
on T2. These are Spearman’s Rho, given by
rT1T2 = 12
 1
0
 1
0 Cuv −u vdu dv
and Kendall’s Tau given by
T1T2 = 4
 1
0
 1
0 CuvdCuv −1 for 0 ≤uv ≤1	
Finally, there is a measure of positive dependence that is suitable for lifelengths sharing a
common environment. This is a positive quadrant dependence, wherein for all t1 and t2 PT1 ≤
t1T2 ≤t2≥PT1 ≥t1PT2 ≥t2. According to this definition, T1 and T2 are positively quadrant
dependent if, and only if, Cuv ≥uv, for all 0 ≤uv ≤1, or equivalently Cuv ≥uv.
Geometrically, the above inequality suggests that for a positive quadrant dependence, the graph
of Cuv must lie on or above that line of uv. Thus copulas provide a graphical way to portray
the positive dependence between two lifetimes T1 and T2, the strength of dependence being a
function of the deviation of Cuv from uv. Since Cuv changes with u and v, the dependence
portrayed by Cuv≥uv is ‘local’. Spearman’s Rho, rT1T2, provides a more global measure
of positive quadrant dependence.
4.7.2
The Bivariate Exponential Distributions of Gumbel
Gumbel (1960) has proposed a system of bivariate distributions whose marginal distributions
are exponential – thus the name ‘bivariate exponential’. This system may be viewed as the very
first family of probability models for describing dependent lifelengths. A drawback of Gumbel’s
system is that the proposed models lack a physical motivation, and that a generalization to the
multivariate case is not obvious. Its advantages are that unlike many of the other multivariate
lifelength distributions, both positive and negative dependence can be represented; also the
marginal distributions are unit exponential (i.e. an exponential distribution with a scale parameter
one). This latter feature makes the system a natural choice for generating other families of
distributions for dependent lifelengths via hazard potentials (Theorem 4.3). This is one of the
main reasons for introducing the Gumbel family.
Under Gumbel’s system, there are two versions of the bivariate exponential distribution. Under
the first version the correlation is always negative, and the largest value that it can take is
−0	4036. Under the second version, both positive and negative values of the correlation can
be had, and the maximum value of the correlation is ±0	25. I overview below each of the two
versions.
Version I of Gumbel’s Bivariate Exponential Distribution
Motivated by the lower Fréchet bound, Gumbel has proposed, for a parameter , where 0≤≤1,
the bivariate survival function
PT1 ≥t1 T2 ≥t2   = exp−t1 + t2 + t1t2
for t1t2 ≥0	
The marginal distribution functions are unit exponential; i.e. PTi ≥ti  =exp−tii=12.
This suggests that the parameter  plays a role only with respect to the joint distribution function,
and that T1 and T2 are independent when =0. Supressing , the conditional mean is of the form
ET1  T2 = t2 = 1 +  + t2
1 + t22 

90
STOCHASTIC MODELS OF FAILURE
implying that for  > 0, the regression of T1 on T2 decreases from 1 +  when t2 = 0, to zero
when t2 becomes infinite. When  = 0 T1 and T2 are independent; thus ET1  T2 = t2 = 1, for
all values of t2. Analogous to the conditional mean, we may also obtain the conditional variance.
It has been shown (cf. Gumbel, 1960) that the conditional variance
VT1  T2 = t2 = 1 +  + t22 −22
1 + t24
	
Thus like the conditional mean, the conditional variance decreases in t2, ranging from one when
 = 0, to 2 + 4t2 + t2
2/1 + t24, when  = 1.
An expression for the coefficient of correlation involves the integral logarithm and is therefore
cumbersome to write out. However, T1T2 depends on  alone, and is always negative ranging
from zero when =0, to −0	4036 when =1. Because of this negative correlation, the bivariate
exponential given here is a meaningful model only when the dependence between T1 and T2 can
be judged as being negative.
Version II of Gumbel’s Bivariate Exponential Distribution
If in (4.28) the marginals are chosen to be unit exponentials, that is, if Fiti = 1 −exp−ti,
for ti ≥0i = 12, then it can be seen that
PT1 ≥t1 T2 ≥t2   = e−t1+t21 + 1 −e−t1 −e−t2 + e−t1+t2
for −1 ≤ ≤+1
this is Version II of Gumbel’s system. It leads to the copula
Cuv = exp

−−logu + −logv
1


	
Here the regression of T1 on T2 (with  supressed) is of the form
ET1  T2 = t2 = 1 + 
2 −e−t2
suggesting that for  > 0, the conditional mean of T1 increases with t2 from 1 −/2 to
1 + /2. For  < 0, the conditional mean decreases. In either case, the regression curves are
exponential functions of t2 (illustrated in Figure 4.15). Similarly, for  > <0, the conditional
variance increases (decreases) with t2. This is because
VT1  T2 = t2 = 1 + 
2 1 −2e−t2 −2
4 1 −2e−t22	
Finally, it can be shown (Gumbel, 1960), that the coefficient of correlation T1T2 is /4, so
that T1T2 is restricted to take values between −1/4 and +1/4. When  = 0 T1T2 = 0;
however  = 0 also implies that T1 and T2 are independent. Thus the bivariate exponential
distribution discussed here provides another example of the case wherein T1T2 = 0, implies
that T1 and T2 are independent. The same is also true of Version I of Gumbel’s bivariate
exponential distribution; namely, that when =0 T1T2=0, and T1 and T2 are independent.
To summarize, the bivariate Gaussian and Gumbel’s bivariate exponential distributions provide
examples of the case wherein T1T2 = 0, implies that T1 and T2 are independent; another
example is the BVE of section 4.7.4.

PROBABILITY MODELS FOR INTERDEPENDENT LIFELENGTHS
91
System Reliability Considerations
With PT1 ≥t1T2 ≥t2  · specified, it is easy to obtain the reliability of a series or a parallel
(redundant) system having interdependent lifelengths described by Gumbel’s bivariate expo-
nential distributions. Specifically, let Ts and Tp denote the times to failure or a series and a
parallel-redundant two-component system whose lifetimes are T1 and T2. Then, for any t ≥0,
where t is the mission time, the reliability of the series system is
PTs ≥t · = PT1 ≥tT2 ≥t ·
and that of the parallel redundant system is
PTp ≥t · = PT1 ≥t · + PT2 ≥t · −PT1 ≥tT2 ≥t ·
the second equality is a consequence of (4.26). The marginals PTi > t i = 12, are unit
exponentials.
4.7.3
Freund’s Bivariate Exponential Distribution
In contrast to Gumbel’s bivariate exponential distributions which do not appear to have a physical
motivation, Freund (1961) proposed a bivariate extension of the exponential distribution that is
based on the following construction.
Consider a two-unit parallel redundant system; i.e. a system wherein all components are
simultaneously put to use, but all that is needed for the system to function is one working
component. Examples are paired organs like eyes, kidneys and lungs, or a twin-engine aircraft
like Boeing’s 777. The system is considered to be functioning (albeit in a degraded state) even
when one of the two units has failed. However, the failed unit increases the stress on the surviving
unit, and in so doing increases the latter unit’s propensity of failure. Freund (1961) proposed a
simple model for encapsulating such situations. He assumed that, when both the components are
functioning, the lifelength of component i Ti i = 12, has a constant (model) failure rate i.
Upon the failure of the first component of the (model) failure rate of the surviving component
increases from i to ∗
i  i = 12. Figure 4.9 shows the failure rate function of T2 assuming that
component 1 has failed first, at T1 = t1.
For the set-up described above, T1 and T2 are not independent, since the failure of one
component changes the parameter of the surviving one. Consequently, for 0 < t1 < t2 < ,
λ2
Values 
of T2
0
Failure 
rate of T2
λ 2*
T1 = t1
Figure 4.9
Failure rate function of the second to fail component (Freund’s model).

92
STOCHASTIC MODELS OF FAILURE
P t1 ≤T1 ≤t1 + dt1t2 ≤T2 ≤t2 + dt2 = Pt2 ≤T2 ≤t2 + dt2  T1 = t1·
Pt1 ≤T1 ≤t1 + dt1
= e−2 t1∗
2e−∗
2t2−t1dt21e−1t1dt1
= 1∗
2e−∗
2t2−1+2−∗
2t1dt1dt2
similarly for 0 <t2 <t1 <, mutatis mutandis. Thus, suppressing all parameters on the left-hand
side, the joint density function of PT1 ≥t1T2 ≥t2 at t1t2 is
ft1t2 =

1∗
2e−∗
2t2−1+2−∗
2t1
0 < t1 < t2 < 
2∗
1e−∗
1t1−1+2−∗
1t2
0 < t2 < t1 < 	
(4.31)
Since lim
t2↓t1ft1t2 does not equal lim
t2↑t1ft1t2, Freund’s model does not have a probability density
at t1 = t2; i.e. ftt is not defined.
The probability that component 1 is the first to fail is PT1 < T2. Clearly
P T1 < T2 =
 
0
PT2 > t1  T1 = t1 ft1 dt1
=
 
0
e−2 t1 1 e−1 t1 dt1 =
1
1 + 2

provided that the events T2 > t1 and T1 = t1 are judged independent. Similarly, PT2 < T1 =
2/1 + 2.
Properties: Moments, Marginals and Memory
Using moment-generating functions (for details see Freund, 1961) it can be shown that
ET1 = ∗
1 + 2
∗
11 + 2
VT1 = ∗
12 + 2 12 + 2
2
∗
121 + 22
 and
CovT1T2 = ∗
1∗
2 −12
∗
1∗
21 + 22 
similarly, ET2 and VT2.
The marginal density of T1 at t1, obtained by integrating (4.31) over t2, is for 1 +2 −∗
1 ̸=0,
given as
ft1 = 1 −∗
11 + 2 e−1+2t1
1 + 2 −∗
1
+ ∗
12 e−∗
1t1
1 + 2 −∗
1

(4.32)
similarly for ft2. If 1 + 2 −∗
1 = 0, then
ft1 = 1 + ∗
12 t1 e−∗
1t1	
(4.33)
The above equations imply that, unlike the marginal distributions of Gumbel (1960), those of
Freund (1961) are not exponential. In the case of 1 +2 −∗
1 ̸=0, the marginal of T1 is a mixture

PROBABILITY MODELS FOR INTERDEPENDENT LIFELENGTHS
93
of two exponentials, one with scale parameter 1 + 2, and the other with a scale parameter
∗
1. The mixing coefficients are 1 −∗
1/1 + 2 −∗
1 and 2/1 + 2 −∗
1, respectively.
When ∗
1 >1 one of the two mixing coefficients will be negative and so the failure rate function
of the distribution of T1 will be increasing; similarly, with T2.
When ∗
i = i i = 12 ETi = i and fti = ie−iti. Furthermore CovT1T2 = 0
and ft1t2 = 12e−1t1+2t2; thus T1 and T2 are independent. Finally, the expression for
CovT1T2 suggests that when ∗
1∗
2 < 12 T1 and T2 can be negatively dependent. This can
happen if the failure of the first component decreases the propensity of failure of the surviving
component. Such scenarios can arise with resource-sharing systems, which operate under limited
resources; for example, a multi-unit power-generating facility supported by on-line preventive
maintenance. The failure of a unit makes more resources available for the maintenance of the
surviving units.
It is well known that the exponential (chance) distribution PX ≥x   = Fx   = e−x
enjoys the lack of memory property, i.e. PX ≥x + s  X ≥x = PX ≥s  . Indeed,
it is only the univariate distribution for continuous lifelengths having this property. The lack
of memory property is appropriate for items that do not deteriorate (or age) with use, since
the essence of this property is that our assessment of the item’s future survivability is not
influenced by its past use. The bivariate analogue of the lack of memory property is of the
form PT1 ≥t1 + sT2 > t2 + s  T1 ≥t1T2 ≥t2 = PT1 ≥sT2 ≥s; where, for convenience, the
conditioning parameters have been suppressed. Block and Basu (1974) have shown that Freund’s
bivariate exponential distribution is absolutely continuous and that it possesses the bivariate lack
of memory property. Indeed, besides a bivariate distribution based on independent exponential
marginals, Freund’s distribution is one of the few absolutely continuous bivariate distributions
which possess the bivariate lack of memory property.
System Reliability Considerations
It is relatively straightforward to verify that when 1 = 2 =  and ∗
1 = ∗
2 = 2 T, the time to
failure of the paired-organ system has density at t given by
ft   = 4t2 exp−2t
(4.34)
with survival function (or reliability) of the form
PT > t   = 2t exp−2t + exp−2t
(4.35)
thus, the system’s model failure rate function is
rt   =
42t
2t + 1	
(4.36)
More about this system will be said later, in section 4.8 on models for cascading failures.
4.7.4
The Bivariate Exponential of Marshall and Olkin
Freund’s bivariate distribution is absolutely continuous and possesses the bivariate lack of
memory property; however, it does not allow for the simultaneous failure of both components.
Also, it does not generalize easily to the multivariate case. To account for scenarios that involve
the simultaneous failure of two (or more) components, Marshall and Olkin (1967) introduced
a bivariate distribution with exponential marginals, which have the bivariate lack of memory
property. They termed this distribution the ‘BVE’ and its multivariate version the ‘MVE’. As

94
STOCHASTIC MODELS OF FAILURE
we shall soon see, the BVE has many attractive features; its main disadvantage is that it is
not absolutely continuous, a consequence of which is that statistical methods based on densities
cannot be easily invoked. To appreciate the structure of the BVE, it is necessary for us to
overview the notion of a Poisson counting process.
The Poisson Counting Process – An Overview
A point process is, roughly speaking, a countable random collection of points on the real line.
Let Nt be the number of points in 0t. Then Nt, as a function of t ≥0, counts the events
of the point process, and is hence called a counting process. To see why point processes are of
interest to us in reliability, consider a scenario wherein certain events (like shocks) occur over
time t ≥0, according to the postulates of a special and an important kind of a point process,
namely a Poisson process. The postulates of a Poisson process are:
(i)
The probability of an event occuring in an interval of time tt + h = h + oh, where 
is a specified constant.
(ii)
The probability of two or more events occurring in tt + h = oh;
oh is a function of h, say gh, for h > 0 with the property that lim
h↓0gh/h = 0.
As before, let Nt denote the (unknown) number of events that have occurred in the time
interval 0t, with the proviso that N0=0. Then the sequence of random variables Nt t≥0
is called a homogeneous Poisson counting process with intensity . The following properties
of this process are well-known (for example, Ross, 1996).
(a)
For time point s and t with s < t Nt −Ns, the number of events that occur in the
interval st has a Poisson distribution with parameter t −s; i.e.
PNt −Ns = k   = e−t−st −sk
k!

consequently, taking s = 0,
PNt = k   = exp−ttk
k!
with ENt   = t.
(b)
If T1T2
 
 
 , denote the times between the arrivals of the events, i.e. the inter-arrival
times, then given , the Tis are independent and identically exponentially distributed. Thus
PTi ≥t   = e−t i = 12
 
 
(c)
The process Nt t ≥0 has stationary independent increments, i.e. for 0 ≡t0 < t1 <
t2 < ··· < th < th+1 < ···, where ti = t0 + i, for  > 0, the random variables Nt1 −
Nt0Nt2 −Nt1
 
 
 Nth+1 −Nth are independent and identically distributed.
The sequence of random variables Nt t≥0 is called a non-homogeneous Poisson process
with a mean value function  t, if the process has independent increments – see (c) above –
and if for all s and t with s < t,
PNt −Ns = k   t = e− t− s t − sk
k!

here ENt =  t and d t/dt
def= t is called the intensity function of the nonhomoge-
nous Poisson process.

PROBABILITY MODELS FOR INTERDEPENDENT LIFELENGTHS
95
Structure of the Bivariate Exponential Distribution – BVE
Consider a system comprising of two components, connected in series or in parallel. The system
operates in an environment in which three types of shocks occur, each occurring per the postulates
of a homogenous Poisson process. Let Nit t ≥0 i = 123, denote the associated counting
processes, with intensities 12 and 12, respectively. Suppose that the above three sequences
of random variables are contemporaneously independent. The shocks associated with i have
an effect on component i alone, i = 12, and those associated with 12 have an effect on both
components. Whenever a component receives a shock that is associated with it, the component
fails. The set-up given here is very general and one can conceive of many scenarios for which
it is reasonable. A simple example is an electro-mechanical system wherein certain shocks are
pertinent to the mechanical part alone; certain pertinent to the electrical part alone, and certain,
like an earthquake, pertinent to both. Probability models based on scenarios wherein shocks
lead to failure are called ‘shock models’. Let Ti denote the time to failure of component i, and
Uj j = 123 the time to occurrence of the first shock in the process Njt t ≥0. Since the
three Poisson processes mentioned above are independent, i.e., for any t, the random variables
N1tN2t and N3t are independent, the corresponding Ujs are also independent. Furthermore,
by property (b) of homogenous Poisson processes, each Uj has an exponential distribution.
Thus for the ‘fatal shock model’ described above
Ti = minUiU3 i = 12 and so
PT1 ≥t1T2 ≥t2  1212 = PU1 ≥t1U2 ≥t2U3 ≥maxt1t2
= exp−1t1 −2t2 −12 maxt1t2	
(4.37)
A generalization of the fatal shock model is the ‘non-fatal shock model’, wherein each shock is
fatal to its associated component with a certain probability. Specifically, let pi be the probability
that a shock generated by the process Nit t ≥0 destroys component i i = 12, and let p10
be the probability that a shock generated by the process N3t t ≥0 destroys component 1
but keeps component 2 intact. Similarly, p01p00 and p11, where p00 + p10 + p01 + p11 = 1. Then,
using property (b) of the homogenous Poisson process, it can be verified that for 0 ≤t1 ≤t2, and
p = p1p2p00p10p01p11,
PT1 ≥t1T2 ≥t2  1212p =
exp−t11 p1 + 12 p10 −t22 p2 + 121 −p00 −p10
the details can be found in Marshall and Olkin (1967). Similarly, for 0 ≤t2 ≤t1,
PT1 ≥t1T2 ≥t2  1212p =
exp−t11 p1 + 121 −p00 −p01 −t22 p2 + 12 p01	
If we set  1 = 1p1 + 12p10 2 = 2p2 + 12p01 and  12 = 12p11, we obtain
PT1 ≥t1T2 ≥t2   1 2 12 = exp− 1 t1 − 2 t2 − 12 maxt1t2	
(4.38)
To gain insight about the arguments that lead to the above equation, consider the case of a
single component with lifelength T, which experiences shocks per the postulates of a homogenous
Poisson process with intensity . Suppose that each shock is fatal to the component with

96
STOCHASTIC MODELS OF FAILURE
probability p. Then the component survives to time t if all the shocks it experiences in 0t are
non-fatal. Thus
PT ≥t =


j=0
e−ttj
j!
1 −pj = e−pt	
If every shock is a fatal shock, then p = 1, and PT ≥t = e−t, an exponential chance
distribution with parameter .
Similarly, when p1 = p2 = p11 = 1, the non-fatal shock model of (4.38) reduces to the fatal
shock model of (4.37). In deriving (4.38) we have assumed that there are no after-effects of each
shock that is not fatal to its component(s). When T1 and T2 have a survival function of the form
given by (4.37) or (4.38), they are said to have a bivariate exponential distribution, abbreviated
the BVE. The distribution easily generalizes to the n-variate case for n>2. However, its number
of parameters grows exponentially. For example with n = 3, the number of parameters is seven:
123121323 and 123. Thus unless one is prepared to assume that some of the s,
particularly those having multiple indices such as 123, are zero, the MVE as a model for failure
is unwieldy. Engineers refer to such models as being non-scalable, and models with several s
set to zero are said to have a loss of granularity. Thus in using the MVE as a model for failure
one may have to trade off between scalability and granularity; this is perhaps the MVE’s biggest
disadvantage. However, the model has many attractive features, some of which serve to illustrate
the finer aspects of modeling interdependency. These are described below with the bivariate case
as a point of discussion. In the interest of giving a broad coverage, many of the results given
below are without proof; the details can be found in Marshall and Olkin (1967) or in Barlow
and Proschan (1975, pp. 127–138).
Moments, Marginals and Memory of the BVE
Consider the joint survival function of (4.37); here again, in all that follows, we suppress the
conditioning parameters 12, and 12, to write the BVE as
Ft1t2 = PT1 ≥t1T2 ≥t2 = exp−1 t1 −1 t1 −12 maxt1t2	
(4.39)
Claim 4.1 below is a natural consequence of the construction of the BVE.
Claim 4.1.
If T1 and T2 have the BVE, then there exist independent exponentially distributed
random variables U1U2 and U3 such that T1 = minU1U3 and T2 = minU2U3.
By setting t1 (or t2) equal to zero, we see that for any ti > 0 PTi ≥ti = exp−i + 12ti
i = 12. Thus we have
Claim 4.2.
The marginal distributions of the BVE are exponential. Consequently, ETi =
i + 12−1, and VTi = i + 12−2 i = 12.
For any t ≥0, (4.39) leads to the result that for all s1s2 ≥0
PT1 ≥t + s1T2 ≥t + s2  T1 ≥s1T2 ≥s2 = PT1 ≥tT2 ≥t	
(4.40)
Thus we have

PROBABILITY MODELS FOR INTERDEPENDENT LIFELENGTHS
97
Claim 4.3.
The BVE enjoys the bivariate lack of memory property.
Indeed, it can be shown (cf. Barlow and Proschan, 1975, p. 130) that, besides a bivariate
distribution that is based on independent exponential marginals, the BVE is the only bivariate
distribution having exponential marginals which satisfies the bivariate lack of memory property.
A consequence of this feature, plus (4.40) is
Claim 4.4.
The probability of survival of a two-component series system is independent of the
ages of each component if, and only if, the joint lifelengths have the BVE.
The Nature of Dependence in the BVE
To investigate the dependence of T2 on T1, we consider the quantity PT2 ≥t2  T1 = t1
def=
Ft2  t1. This quantity, evaluated via an evaluation of limt1↓0 PT2 ≥t2  t1 ≤T1 < t1 + t1,
leads to the result that
Ft2  t1 =
exp−2 t2
t2 ≤t1
1
1+12 exp−12t2 −t1 −2 t2 t2 > t1	
(4.41)
The regression of T2 on T1, obtained by integrating Ft2  t1 over 0 to , is
ET2  T1 = t1 = 1
2
−
12 e−2 t1
21 + 122 + 12
where  = 1 + 2 + 12. Thus the regression of T2 on T1 is an exponentially increasing function
of t1 that is bounded by 1/2 (Figure 4.15). This behavior parallels that of ET2  T1 = t1 in the
case of Gumbel’s bivariate exponential distribution, Version II, for  > 0; here the conditional
mean is bounded by 1 + /2.
Positive dependence in the case of the BVE can be asserted via the covariance. Specifically,
it can be seen (cf. Barlow and Proschan, 1975, p. 135) that
CovT1T2 =
12
1 + 122 + 12
so that T1T2, Pearson’s coefficient of correlation is 12/. When 12 = 0 T1T2 = 0,
and (4.37) together with Claim 4.2 imply that T1 and T2 are independent. Thus for the BVE,
T1T2 = 0 implies that T1 and T2 are independent. Another distribution which shares this
property, namely that T1T2 = 0 implies that T1 and T2 are independent, is the bivariate
Gaussian.
The BVE of (4.39) generates the survival copula
Cuv = uvminu−v−
where  = 12/1 + 12 and  = 12/2 + 12 (Nelson, 1999, p. 47). Since Cuv ≥uv, the
lifelengths T1 and T2 are positively quadrant dependent.
Whereas Ft2  t1 is well defined at t2 = t1 – see equation (4.41) – it does take a downward
jump of size 12/1 + 12exp−2t1 at that point. The size of the jump depends on both 1
and 2, and is greater than zero, even if 1 = 2; the jump vanishes when 12 = 0. I am able to
show, details omitted, that the size of the jump is (approximately) equal to PT2 = t1  T1 = t1,
(Figure 4.10).

98
STOCHASTIC MODELS OF FAILURE
Values of T2
0
1
λ1 + λ12
λ12 e–λ2t1
F (t2 | t1)
t1
Figure 4.10
Jump in the conditional survival function of the BVE.
0
t1
t1
t1
T2
T2
T2
F (t2 | t1)
dt2
d
−
Jump
(a) λ1 > λ2
0
(b) λ1 < λ2
0
Cusp
(c) λ1 = λ2
Figure 4.11
The conditional density of the BVE.
Corresponding to the jump of the conditional survival function of Figure 4.10 is a jump in
its conditional probability density −dFt2  t1/dt2, which exists for all t2 ̸= t1; for t1 = t2, the
density does not exist. It is easy to verify that the size of the jump in the density, at t2 = t1, is
12/1 + 121 −2e−2t1. The jump is upward when 1 < 2, and the density has a cusp
when 1 = 2; see Figures 4.11 b and c, respectively.
Even though the probability density of Ft2  t1 is not defined at the point t2 = t1, its failure
rate, by virtue of (4.8), is defined everywhere. Specifically, if
rt2  t1 def
= −dFt2  t1/Ft2  t1/dt2
then it is easy to verify that
rt2  t1 =
⎧
⎪⎪⎨
⎪⎪⎩
2
t2 < t1
2 + 12 t2 > t1 and
12
1+12 
t2 = t1
and the last equation is a consequence of the jump in Ft2  t1. Figure 4.12 shows a plot of
rt2  t1. It is instructive to compare Figures 4.9 and 4.12; recall that the former pertains to the

PROBABILITY MODELS FOR INTERDEPENDENT LIFELENGTHS
99
Values of T2
0
Point mass of λ12/(λ1 + λ12)
λ2 + λ12
λ2
Failure rate of
F (t2 | t1)
t1
Figure 4.12
Failure rate function of the second to fail component in the BVE.
0
(a) Survival function
(b) Failure rate function
1
Failure rate
P(T2 ≥ t2) | T1 ≥ t1)
t1
T2
0
t1
T2
λ2 + λ12
λ2
Figure 4.13
The conditional survival function T2 ≥t2  T1 ≥t1 of the BVE and its failure rate function.
failure rate of the second component to fail in Freund’s model. Both the failure rate functions
experience a jump at t2 = t1, but the BVE has a point mass of size 12/1 + 12 at t2 = t1.
The point mass could be smaller than 2, between 2 and 2 + 12, or greater than 2 + 12. In
Figure 4.12, we show only the last case.
Our discussion thus far, pertaining to the nature of dependence of T2 on T1, has been
based on a consideration of PT2 ≥t2  T1 = t1. An analogous discussion based upon T1 ≥
t1 as a conditioning event can also be conducted. The major difference between the cases
PT2 ≥t2  T1 = t1 and PT2 ≥t2  T1 ≥t1 is that whereas the former experiences a jump
at t2 = t1 (Figure 4.10), the latter experiences a cusp at t2 = t1. That is PT2 ≥t2  T1 ≥t1
is continuous, but not differentiable at t2 = t1 (Figure 4.13 (a)). A consequence is that the
failure rate of PT2 ≥t2  T1 ≥t1 is not defined at t2 = t1 (Figure 4.13 (b)). Thus, when
investigating the dependence of T2 on T1, the nature of the conditioning event is to be borne
in mind.
A comparison of Figures 4.9, 4.12 and 4.13(b) is instructive.
Survival Function of the BVE and its Decomposition
The BVE has other noteworthy features, many of which are of mathematical interest alone. Some
of these are given below; they help us gain a deeper appreciation of this remarkably interesting
most referenced but least used joint distribution.

100
STOCHASTIC MODELS OF FAILURE
We start by noting that for t1 > t2 > 0,
lim
t2↑t1
Ft1t2
t1
̸= lim
t2↓t1
Ft1t2
t1

for t2 > t1 > 0. Thus we have
Claim 4.5.
The BVE has a singularity along the line t1 = t2; the singularity disappears when
12 = 0.
We next note that
P T1 = T2 =
 
0
e−1t e−2t 12 e−12tdt
=
12
1 + 2 + 12
	
The integral term is a consequence of the fact that the lifelengths of the two components can
only be equal at the time of occurrence of U3, but provided that U3 precedes both U1 and U2.
Thus we have
Claim 4.6.
The BVE has a probability mass along the line t1 = t2, unless of course 12 = 0.
After some tedious but routine calculations, it is evident that 2Ft1t2/t1t2 exists for
both t1 > t2 > 0 and t2 < t1 < 0; however, it does not exist for t1 = t2. Since t1 = t2 has a two-
dimensional Lebesgue measure zero, we claim that 2Ft1t2/t1t2 exists almost everywhere.
However, it can be seen – again after some tedious calculations – that

t1

t2
2Ft1t2
t1t2
̸= Ft1t2
thus 2Ft1t2/t1t2 cannot be regarded as a density. We therefore have
Claim 4.7.
The BVE is not absolutely continuous; it does not have a probability density with
respect to the two-dimensional Lebesgue measure.
A consequence of Claim 4.7 is that one is unable to use methods based on densities because
writing out the likelihood poses difficulties (Bemis, Bain and Higgins, 1972; and section 5.4.7).
Since the BVE is not absolutely continuous, its Lebesgue decomposition (section 4.2) will entail
discontinuities and/or singularities. However, as shown in Barlow and Proschan (1975, p. 133),
the BVE has an absolutely continuous part and only a singular part; it has no discrete part. This
is summarized via
Claim 4.8.
For  = 1 + 2 + 12, the Lebesgue decomposition of Ft1t2 yields
Ft1t2 = 1 + 2

F at1t2 + 12
 F st1t2
where the absolutely continuous part is
F at1t2 =

1 + 2
e−1t1−2t2−12 maxt1t2 −
12
1 + 2
e−maxt1t2

PROBABILITY MODELS FOR INTERDEPENDENT LIFELENGTHS
101
and the singular part is
F st1t2 = e−maxt1t2	
F at1t2 is the absolutely continuous part because 2F at1t2/t1t2 exists almost every-
where, and because

t1

t2 2F at1t2/t1t2 =F at1t2. Similarly F st1t2 is the singular part
because 2F st1t2/t1t2 = 0 for 0 < t1 < t2 <  and for 0 < t2 < t1 < ; it does not exist
when t1 = t2. A verification of these statements entails several laborious steps.
Let fat1t2 = 2F at1t2/t1t2 be the probability density function of F at1t2. Then, it
is evident that
fat1t2 =
⎧
⎪⎪⎪⎨
⎪⎪⎪⎩
1 + 122
1 + 2
e−1+12t1−2t2 t1 > t2 > 0
2 + 121
1 + 2
e−1t1−2+12t2 t2 > t1 > 0
it is undefined for t1 = t2.
The marginals of F at1t2 F at1 and F at2, obtained by setting in F at1t2 t2 = 0 and
t1 = 0, respectively, turn out to be mixtures of exponential distributions. Specifically,
F at10 = F at1 =

1 + 2
e−1+12t1 −
12
1 + 2
e−t1 t1 > 0 and
F a0t2 = F at2 =

1 + 2
e−2+12t2 −
12
1 + 2
e−t2 t2 > 0	
Interestingly, if in fat1t2 we set
 = 1 + 112
1 + 2
  = 2 + 212
1 + 2

′ = 1 + 12
′ = 2 + 12
then the resulting expression takes the form of (4.31) with parameters ′ and ′. This,
we recall, is the probability density function of Freund’s bivariate exponential distribution. We
thus have
Claim 4.9.
Freund’s bivariate exponential distribution can also be derived via a shock model.
The survival function of Freund’s distribution is F at1t2, the absolutely continuous part of the
BVE, and its marginals are mixtures of exponential distributions.
In F at1 the weights assigned to the exponential components have opposite signs; thus its
failure rate is increasing.
Block and Basu (1974) derive F at1t2 via the bivariate lack of memory property, and call
F at1t2 an ‘absolutely continuous BVE’, abbreviated ACBVE. Because of Claim 4.9, Block
and Basu (1974) state that the ACBVE is a variant of Freund’s distribution, which we recall has
the bivariate lack of memory property; thus the ACBVE F at1t2 also possesses the lack of
memory property.
The marginals of F st1t2, the singular component of the BVE, are F sti = e−ti ti > 0 i =
12. Analogous to Claim 4.8, which is a decomposition of Ft1t2, is a decomposition of Ft1
and Ft2, the marginals of the BVE. This decomposition turns out to be a mixture of F ati and
F sti i = 12, the marginals of the absolutely continuous and the singular components of the
BVE. Specifically

102
STOCHASTIC MODELS OF FAILURE
Claim 4.10.
The marginals of the BVE are mixtures of the marginals F ati and F sti, respec-
tively. That is, for i = 12,
Fti = 1 + 2

F ati + 12
 e−ti ti > 0	
Systems Having Interdependent Lifelengths Described by a BVE
Let Ts and Tp be the times to failure of a series and a parallel system, respectively, for a
two-component system whose lifelengths T1 and T2 have the BVE of (4.39). Clearly,
PTs ≥t = PT1 ≥tT2 ≥t = exp−t
where  = 1 + 2 + 12. Thus the survival function of the series system is exponential, and its
failure rate is constant, .
The case of the parallel system is more interesting. For one, it brings into play the problem of
identifiability of the parameters 12 and 12. Specifically, should the first failure experienced
by the system be an individual failure (i.e. the failure of component 1 or component 2, but not
both), then the cause of the second failure cannot be identified; it could be due to a component-
specific shock or a common shock. With the matter of identifiability, it is difficult to use the
observed time of the second failure, say t2, to estimate 2 and 12. Identifiability also manifests
itself in the form of identical survival functions for the fatal and the non-fatal shock models;
((4.37) and (4.38)).
It is easy to verify (section 4.7.4) that since
P

Tp ≥t

= 1 −PTp ≤t def
= F pt
= exp−1 + 12 t + exp−2 + 12 t −exp−t
the probability density of F pt exists everywhere and that F pt is absolutely continuous. The
failure rate of F pt rpt therefore exists, and can be shown to be
rpt = 12 + 1
e−1+12t1 −e−2t
F pt
+ 2
e−2+12t1 −e−1t
F pt
	
Figure 4.14 is a plot of this failure rate function for 1 = 12 = 2, and 12 = 1	5.
Figure 4.14 reveals some interesting features. The first is that rp0 = 1	5, suggesting that
the two-component system can fail instantly, as soon as it is commissioned into operation.
The second is that rpt initially increases and then decreases (albeit slightly), asymptoting to
a constant 2.5. This feature of rpt is reminiscent of the failure rate function of a gamma
distribution, which starting from zero increases and then asymptotes to a constant (cf. Figure 3.5.2
of Barlow and Proschan 1975, p. 75). The analogy is not surprising, because when 1 = 2 = 
and 12 =0 Tp has a gamma distribution with scale  and shape 2. The decrease in rpt prior to
its asymptoting to 2.5 is a consequence of the fact that 1 ̸=2; the constant 2.5 can be identified
with 12 + min12.
The above behavior of rpt motivates us to consider its decomposition. The components of
this decomposition are shown by the dotted graphs of Figure 4.14; their interpretation – given
below – is instructive.
We start by noting that for the two-component parallel redundant system PT1 < t  Tp > t is
the conditional probability that component 1 has failed by t given that the system has not. Since

PROBABILITY MODELS FOR INTERDEPENDENT LIFELENGTHS
103
0
1.5
2.5
0.5
1
0
2
3
1
2
3
4
5
6
7
8
9
10
rP(t)
λ1P(T2 < t | TP > t)
λ2P(T1 < t | TP > t)
Time t
Failure rate
λ12
Figure 4.14
The Failure rate function for a two-component parallel system whose lifelengths are a BVE.
P

T1 < t  Tp > t

= PT1 < tTp > t
F pt

and since
P

T1 < t Tp > t

= PN1t > 0N2t = N3t = 0
P

T1 < t  Tp > t

= 1 −exp−1texp−2 + 12t
F pt
	
Similarly, we can find PT2 < t  Tp > t, mutatis mutandis. Thus, we may write the following
as a decomposition of rpt:
rpt = 12 + 1PT2 < t  Tp > t + 2PT1 < t  Tp > t	
Since rptdt ≈Pt ≤Tp < t + dt  Tp ≥t, and since idt is approximately the probability that
the i-th shock occurs in an interval dt, the above decomposition has a probabilistic interpretation
in terms of i and rpt.
Generalizations and Extensions of the BVE
Besides a generalization to the n-variate case, a consequence of which is the problem of scala-
bility, the structure and the manner of construction of the BVE suggests some natural ways to
build upon it. Some of these are overviewed below.
One possibility is to allow the shocks in a fatal shock model to have after-effects. Thus, for
example, we may assume that each component can withstand exactly k shocks, be they of a
component-specific type or a common type; k is assumed to be known. When such is the case,
the bivariate survival function Ft1t2 will have gamma distributions for their marginals (cf.
Barlow and Proschan, 1975, p. 138). Such survival functions do not posses the bivariate lack of
memory property. The above theme can be extended by supposing that component i can withstand

104
STOCHASTIC MODELS OF FAILURE
exactly ki shocks, i = 12. Downton (1970) and Hawkes (1972) consider the case wherein k1
and k2 cannot be precisely specified, but their joint bivariate distribution k1k2 can. Downton
assumes a bivariate geometric distribution for k1k2; Hawkes considers a generalization of
the bivariate geometric. Neither Downton nor Hawkes provide a physical motivation for their
particular choice for k1k2. However, in Downton’s case, the regression of T2 in T1 is a
linear function of t1, whereas in Hawkes’ case it is an exponentially increasing function of
t1 that is bounded as t →. A concave, increasing and bounded form of the regression is
more realistic than the linear, increasing and unbounded version. As mentioned by Hawkes, an
infinitely reliable engine in an automobile does not lead one to expect that the automobile’s
exhaust pipe will last forever.
A second strategy for building upon the construction of the BVE is to assume that the shock-
generating processes are non-homogenous Poisson with mean value functions it i=123. In
the case of a fatal shock model with 1t=1t 2t=2t, and 3t=12t, for some >0,
the resulting survival function will have Weibull distributions for its marginals (cf. Marshall and
Olkin, 1967). Since the intensity functions corresponding to it are of the form it−1, which
also happens to be the failure rate of a Weibull distribution, the corresponding non-homogenous
Poisson processes Nit t ≥0 are sometimes referred to as ‘Weibull processes’ (cf. Lee
and Lee, 1978). This terminology is misleading because the finite dimensional distributions of
the process Nit t ≥0 are not Weibull. However, were the model described above to be
extended to the n-variate case, then the sequence of random variables T1T2
 
 
 Tn would
have marginal distributions that are Weibull. Consequently, the process Ti i =1
 
 
 n could
legitimately be called a Weibull process; multivariate Weibull distributions have been discussed
by Lee (1979).
There are other such strategies for building upon the structure of the BVE, each entailing the
addition of new parameters, and in so doing exacerbating the problem of scalability. Thus it does
not pay to pursue them further. However, there is one aspect of the BVE that has attracted much
attention, and in so doing has motivated its many extensions. This aspect pertains to the matter
of absolute continuity, which the survival function of the BVE is not. The ACBVE of Block and
Basu (1974) can be viewed as one such extension. There are at least two other extensions, one by
Sarkar (1987) and the other by Ryu (1993). Like Block and Basu, Sarkar and Ryu question the
appropriateness of the BVE when the available data does not consist of simultaneous failures,
or when the physical scenario is such that simultaneous failures are not possible. However,
complex technological systems, like nuclear reactors and power system networks, often exhibit
simultaneous failures and so the BVE has a useful role to play.
Sarkar’s extension produces an absolutely continuous bivariate distribution with exponential
marginals, which does not have the bivariate lack of memory property. Unlike the BVE, Sarkar’s
bivariate distribution lacks a physical motivation; like the ACBVE, its derivation is based on a
characterization of certain independence properties. For specified constants 12 and 12 > 0,
the survival function of Sarkar’s distribution is of the form
PT1 ≥t1T2 ≥t2 = exp−2 + 12t2
!
1 −A1t2−A1t11+"
 for 0 < t1 ≤t2
= exp−1 + 12t1
!
1 −A2t1−A2t21+"
 for 0 < t2 ≤t1
here  = 12/1 + 2 and Az = 1 −exp−z, for z > 0.
Sarkar (1987) also obtains the coefficient of correlation for his distribution, and shows that it
is bounded on the left by 12/1 + 2 + 12, which we recall is the coefficient of correlation
for the BVE. Specifically, here
12
1 + 2 + 12
≤T1T2 < 1

PROBABILITY MODELS FOR INTERDEPENDENT LIFELENGTHS
105
which implies that the naure of linear dependence between T1 and T2 under Sarkar’s distribution
is stronger than that under the BVE. The fact that T1T2 ≥0 suggests a positive dependence
between T1 and T2; consequently, an absence of the lack of memory property implies that with
Sarkar’s distribution, for any t ≥0, and for all s1s2 ≥0,
PT1 ≥t + s1T2 ≥t + s2  T1 ≥s1T2 ≥s2 ≥PT1 ≥tT2 ≥t	
An extension of the BVE proposed by Ryu (1993) results in an absolutely continuous bivariate
distribution whose marginal distributions have an increasing failure rate, and which does not
have the bivariate lack of memory property. The exponential as a marginal distribution arises as
a limiting case of the marginals of the Ryu’s bivariate model. Unlike the ACBVE and Sarkar’s
bivariate distribution, Ryu’s derivation has a physical motivation. Its construction is based on
Marshall and Olkin’s shock model, but the shocks are assumed to have an after-effect; i.e. the
effect of the shocks is cumulative. The after-effect is reflected via the following construction of
a random (or stochastic) hazard function.
Suppose that the failure rate of the lifelength of component 1 at time t is d1N1t + s1N3t,
where N1t is the number of component-specific shocks received by component 1 at time t,
and N3t the number of common shocks at time t d1 and s1 are constants. The failure rate is
random because when it is specified (at time 0), N1t and N3t are unknown. More about this
useful idea of specifying random failure rate functions will be discussed later in Chapter 7, on
reliability in dynamic environments. Similarly, d2N2t+s2N3t is the failure rate of component
2 at time t. Because the Nit i = 123, are non-decreasing functions of t, the two failure rate
functions are also non-decreasing. This failure will manifest itself in the fact that Ryu’s bivariate
distribution has marginal distributions that have an increasing failure rate. In what follows, we
assume that d1 and d2 are very large, say infinite; this makes every component specific shock a
fatal shock. With d1 = d2 = , and s1s212 and 12 specified, Ryu’s bivariate distribution
has the joint survival function:
P T1 ≥t1T2 ≥t2 = exp
#
−1 + 12t1 −2t2 + 12
s1

1 −e−s1t1−t2
+
12
s1 + s2

e−s1t1−t2 −e−s1t1−s2t2
 for t1 > t2
= exp
#
−1t1 −2 + 12t2 + 12
s1

1 −e−s1t2−t1
+
12
s1 + s2

e−s1t2−t1 −e−s1t1−s2t2
 for t1 ≤t2
for details see Appendix B of Ryu (1993).
The marginal distribution of Ti i = 12, is of the form
PTi > t = exp

−it −12t + 12
si
1 −e−sit

 t ≥0	
The marginals are akin to the exponential marginals of the BVE, save for the last term which
vanishes when si = 0 or when si is large, say infinite. It is easy to verify that hit, the failure
rate function of PTi > t, is hit = i + 121 −e−sit, which is an increasing function of t,
for any si < ; when si is very large, hit is approximately a constant, i + 12. The failure
rate is a constant i, when si = 0. It is important that we distinguish between h1t, the failure
rate of PT1 > t, and the quantity d1N1t + s1N3t, which is the random failure rate function
of PT1 > t conditional on N1t and N3t. The function h1t is unconditional on N1t and
N3t; similarly for h2t.

106
STOCHASTIC MODELS OF FAILURE
In general, it can be seen that when s1 and s2 become large, say infinite, then every common
shock is also a fatal shock, and then Ryu’s survival function reduces, albeit approximately, to
the survival function of the BVE. Thus for 12 > 0, we may claim that Ryu’s construction is an
extension of the BVE rather than claim that the BVE is a special case of Ryu’s construction.
This is because the exponential marginals in Ryu’s bivariate distribution being the consequence
of a limiting argument are only approximations.
Absolutely continuous distributions whose marginals reflect aging, such as the ones by Freund,
Ryu and the ACBVE are attractive in the sense that they capture scenarios that are realistic.
However, some of these distributions are more parsimonious (scalable) than the others. For
example, the ACBVE has only three parameters, whereas Freund’s distribution has four, and
Ryu’s has five. A disadvantage of the ACBVE is that it lacks a physical motivation, its gen-
esis being the bivariate lack of memory property. The other two distributions have a physical
motivation, but circumstances which lead to them, namely load sharing in the case of Freund,
and shocks with after-effects in the case of Ryu, may not be meaningful for all applications.
Thus the choice of which bivariate distribution to use should depend on considerations involving
both the physical scenario at hand, and the properties of the chosen distribution. If simultaneous
failures can occur, then the BVE or its generalizations that result in the gamma or the Weibull as
marginal distributions would be suitable. If simultaneous failures are not possible, then any one
of the absolutely continuous bivariate distributions discussed here could be an appropriate choice
depending on the physical scenario at hand and/or the properties of the chosen distribution.
Table 4.1 gives a summary of some of these properties; also included in this table are two other
bivariate distributions, discussed later. In any particular application the choice of a distribution
will depend on assessing which of the properties of Table 4.1 seem relevant, and then choosing
that family which best captures the desired properties. Thus subjectivity plays a key role in
one’s initial choice of a distribution. The observed failure data, if available, would support this
choice or negate it. The data will also facilitate an estimation of the parameters of the underlying
distribution.
Table 4.1
A Comparison of the Properties of Some Bivariate Disributions
Family
Absolute
continuity
Lack of
memory
Marginals
Failure rate
of marginals
Correlation
Independent exponentials
Yes
Yes
Exponential
Constant
Uncorrelated
Gumbel’s Version II
Yes
No
Exponential
Constant
Positive and
negative
Freund’s load sharing
Yes
Yes
Mixture of
exponentials
Increasing
Positive and
negative
Marshall and Olkin’s BVE
No
Yes
Exponential
Constant
Positive
Block and Basu’s ACBVE
Yes
Yes
Mixture of
exponentials
Increasing
Positive
Sarkar’s extension
Yes
No
exponential
Constant
Positive
Ryu’s extension
Yes
No
General
Increasing
Positive
Bivariate Pareto
Yes
No
Pareto
Decreasing
Positive
Single parameter bivariate
exponential
Yes
No
Exponential
Constant
Positive
Bivariate Pareto
copula-induced bivariate
exponential
Yes
No
Exponential
Constant
Positive

PROBABILITY MODELS FOR INTERDEPENDENT LIFELENGTHS
107
4.7.5
The Bivariate Pareto as a Failure Model
An absolutely continuous bivariate distribution with Pareto marginals can be motivated as a
failure model for certain types of components sharing a common (but unspecified) environment.
The model generalizes to the multivariate case and it is much more scalable than the multivariate
version of the BVE. Its dependence properties are different from those of the models considered
earlier and the model is related to some well-known families of bivariate distributions that
have been considered in other contexts. The physical scenario for which the model is proposed
is quite general, and this generality enables us to consider its several extensions. Indeed, one
such extension leads us to a single parameter family of bivariate distributions with exponential
marginals (section 4.7.6).
Structure of the Bivariate Pareto Distribution
Consider a two-component, parallel redundant system that is required to operate in an environ-
ment whose effect on each component is unknown (in a sense to be described later). Let T1 and
T2 be the lifelengths of each component. Our aim is to assess the reliability of the system for
a mission of duration t t ≥0. Suppose that the model failure rate of the distribution of Ti is
i, where i encapsulates the inherent quality of component i, and  reflects the effect of the
environment on i i = 12. One way to interpret i is to view it as the model failure rate of
Ti when component i operates in some standard, carefully controlled test-bench environment; i
will be called the intrinsic model failure rate of the component. If the operating environment is
judged to be harsher (milder) than the test-bench environment, then  would be greater (smaller)
than one; otherwise  = 1.
Were we to assume that given  1 and 2, the lifelengths T1 and T2 are independent, then the
reliability of the parallel-redundant system is exp−1t + exp−2t −exp−1 + 2t.
Suppose now that 1 and 2 can be specified to a very high degree of accuracy. This is plausible
because the is, being chance parameters, can be assessed by testing a large number of copies
of component i in the test-bench environment. Since the operating environment can change from
one user of the system to another,  will be treated as being unknown with a distribution function
G; this distribution function will involve parameters that have to be specified. With the is
assumed known and  having the distribution function G, the reliability of the two-unit
parallel redundant system becomes
G∗1t + G∗2t −G∗1 + 2t
(4.42)
where G∗y=
 
0 exp−ydG is the Laplace transform of (the probability density function
of) G. The above result easily generalizes to the case of multiple components, each new com-
ponent introducing only one additional parameter, namely its . This feature gives the proposed
model the feature of scalability.
As a special case of (4.42), suppose that G has a gamma distribution with parameters
a > −1 and b > 0, where a is the shape parameter; note that here, it is a = 0 that results in an
exponential distribution. Then, if Tp denotes the time to failure of the system, its reliability
PTp ≥t =

b
1t + b
	a+1
+

b
2t + b
	a+1
−

b
1 + 2t + b
	a+1

(4.43)
in writing the above, the conditioning parameters are suppressed.
Using arguments that mimic those used to obtain (4.43), we can easily obtain
PT1 ≥t1T2 ≥t2 =

b
b + 1t1 + 2t2
	a+1

(4.44)

108
STOCHASTIC MODELS OF FAILURE
its joint density at t1t2 is of the form
ft1t2 = 12a + 1a + 2ba+1
1t1 + 2t2 + ba+3
	
(4.45)
Integrating the above with respect to t2 gives the marginal density of T1 at t1 as
ft1 = 1a + 1ba+1
1t1 + ba+2 	
This is a Pareto density of the first kind (cf. Johnson and Kotz, 1970, p. 234); it yields the
survival function
PT1 ≥t1 =

b
b + 1t1
	a+1

similarly, PT2 ≥t2. Since PT1 ≥t1T2 ≥t2 ̸= PT1 ≥t1PT2 ≥t2 T1 and T2 are not inde-
pendent. By contrast, when  is specified, T1 and T2 are independent – thus dependence here is
attributed to our uncertainty about ; more about this is said later.
If, in (4.44), we set t1 = t2 = t, then PT1 ≥t1T2 ≥t2 is the reliability of a series system of
two components sharing a common environment. Specifically, if Ts denotes the lifelength of the
series system, then
PTs ≥t =

b
b + t1 + 2
	a+1
	
Lindley and Singpurwalla (1986) discuss the relationship of the joint distribution (4.44) to
other bivariate distributions like the Lomax and the logistic, making such distributions suitable
candidates for failure models. Using the fact that the conditional density of T1 at t1, given T2 =t2,
is of the form
ft1  t2 = 1a + 2b∗a+2
1t1 + b∗a+3 
(4.46)
where b∗= b + 2t, it can be seen that the regression of T1 on T2 is of the form
ET1  T2 = t2 = 2t2 + b
1a + 1
also
VT1  T2 = t2 = 1
2
1
a + 2b + 2t22
aa + 12

	
The conditional density of (4.46) is also a Pareto density, and the regression of T1 on T2 is
linear with a positive regression coefficient 2/1a + 1. The latter is to be contrasted with
the exponentially increasing and bounded regression of the Gumbel, the BVE and the Hawkes’
models (Figure 4.15). Recall that for Downton’s model, regression of T1 and T2 was linear,
and this was a criticism of the model; the same criticism would therefore also apply to the
model proposed here. The correlation between T1 and T2 is a + 1−1, which with a > −1

PROBABILITY MODELS FOR INTERDEPENDENT LIFELENGTHS
109
Bivariate Pareto and Downton’s model
Values of t1
0
Gumbel’s type II (α < 0)
Gumbel’s type II (α < 0), the BVE and
Hawkes’ model
E(T2 | T1 = t1)
Figure 4.15
The regression of T2 on T1 for some models of interdependent lifetimes.
is always positive; the correlation depends only on a. Also, the probability that component 2
fails before component 1 is 2/1 + 2, irrespective of  and its distribution. Finally, with
PT1 ≥t1T2 ≥t2 and PT1 ≥t1 known, it is obvious that
PT2 ≥t2  T1 ≥t1 =

b + 1t1
b + 1t1 + 2t2
	a+1

this expression enables us to assess the survivability of component 2, given the survivability of
component 1.
Currit and Singpurwalla (1988) have investigated the crossing properties of PTp ≥t –
equation (4.43) – with
exp−1t + exp−2t −exp−1 + 2t def
= PITp ≥t
the reliability function of a parallel redundant system with independent exponentially distributed
lifetimes. They show that when a and b are such that E2 + V > 1, PTp ≥t crosses
PITp ≥t at least once, and that the crossing occurs from below. This means that the assumption
of independence initially overestimates system reliability. The overestimation tantamounts to an
underestimation of the risk of failure for small mission times, a feature whose consequences
could be serious. A similar result is also true vis-à-vis the crossing of PTs ≥t and PITs ≥
t
def= 1 −exp−1 + 2t – the reliability of a series system with independent exponentially
distributed lifetimes – except that if a crossing occurs, it can occur at most once. Here again, the
assumption of independence results in an overestimation of system reliability, at least initially.
Chaudhuri and Sarkar (1998) strengthen the results of Currit and Singpurwalla (1988) by showing
that when E > 1, there is exactly one crossing of the type described above, for both series
and parallel redundant systems.
There is a subjectivist angle from which the crossings mentioned above can be viewed.
Specifically, the expressions for PTp ≥t and PTs ≥t are a consequence of our uncertainty
about . Their initial domination by PITp ≥t and PITs ≥t can be seen as the price that one
has to pay for not being able to specify  with certainty. The price is an assessment of reliability
that is smaller than that which would have been assessed were  = 1. More on the causes of
dependence is given next.

110
STOCHASTIC MODELS OF FAILURE
The Cause of Interdependent Lifelengths
We have attributed the uncertainty about  as the cause of dependence between T1 and T2.
Does this imply that dependent lifelengths are always a consequence of parameters that are not
precisely specified? The answer to this question cannot be in the affirmative because, for the
BVE, T1 and T2 are dependent even when 12 and 12 are assumed known. This is because
with 1 = 2 = 0, a knowledge of 12̸= 0 does not tell us precisely when the common shock is
going to occur. However, as soon as T1 were to be observed as t1, we do know that a common
shock has occurred at t1, and this causes us to revise our uncertainty assessment about T2;
indeed in the case of the fatal shock model, the uncertainty about T2 vanishes. In the case of the
bivariate Pareto model considered here, the occurrence of failure at t1 tells us something about
the operating environment, and hence about . This in turn changes our belief about T2.
To summarize, in the case of the BVE, a knowledge that T1 = t1, tells us when a common
shock has occurred and this in turn enhances our knowledge about the common environment.
The added knowledge about the common environment causes us to revise our uncertainty about
T2. Similarly, in the case of the bivariate Pareto, T1 = t1 influences our belief about , and this
in turn causes us to change our belief about T2. From a subjective probability point of view,
dependent lifelengths are a manifestation of changes in belief about one lifelength given the
decomposition of the other.
Finally, there is one other issue that needs to be brought into the picture, namely that of hazard
potentials and dependent lifelengths (section 4.6.1). He had seen there that dependence between
lifetimes is a manifestation of dependence between the hazard potentials. This claim is still true;
dependent hazard potentials are the genuine cause of interdependent lifelengths.
4.7.6
A Bivariate Exponential Induced by a Shot-noise Process
Implicit in the set-up of section 4.7.5 is the assumption that the operating environment, be it
harsher or milder than the test-bed environment, is static. Thus  was taken to be an unknown
constant. The more realistic scenario is the one wherein the operating environment changes over
time so that its effect on component i i = 12, is to change i to ti, where t is some
unknown function of t; it is called the modulating function. When such is the case, the operating
environment is said to be dynamic, and the topic of survivability under dynamic environments
is interesting enough for an entire chapter to be devoted to it (Chapter 7). The purpose of this
section, however, is to introduce an absolutely continuous bivariate distribution with exponential
marginals that arises in the context of dynamic environments, and to compare the properties of
this distribution with other bivariate distributions discussed here.
Since t is unknown, we start by introducing a probability model for describing our uncer-
tainty about it. There are several approaches for doing so, a natural one being to suppose that t
is a polynomial function of time with unknown coefficients. For example, t = a0 + $n
i=1 aiti,
where the ai’s are unknown. This kind of strategy is the essence of the approach used by Cox
(1972) in his celebrated paper on ‘proportional hazards’. Another approach is to assume that
t t ≥0 is a meaningful stochastic process. That is, for every value of t ∈0 t
is a random variable with a specified distribution, and for every collection of k time points,
0 < t1 < t2 < ··· < tk k ≥1, the joint distribution of the k random variables t1
 
 
 tk is
also specified. In essence, a stochastic process is simply a collection of random variables whose
marginal and joint distributions can be fully specified. The sample path of a stochastic process is
the collection of values taken by the Poisson process. The homogenous and the non-homogenous
Poisson counting processes of section 4.7.4 are examples of stochastic processes, and so are the
other point processes discussed in Chapter 8.
The advantage of describing t by a stochastic process over assuming that t is some
deterministic function of time is that the latter describes the effect of a systematically changing

PROBABILITY MODELS FOR INTERDEPENDENT LIFELENGTHS
111
environment, whereas the former best encapsulates the features of a haphazard one. In Singpur-
walla and Youngren (1993), two stochastic process models for t are considered. The first
entails the assumption that
! t
0 udYu t ≥0
"
is a ‘gamma process’; u is the intrinsic fail-
ure rate function of a component, and dYu=udu, whenever u exists. The gamma process
will be formally defined in section 4.9.1. An overview of these processes and their generalizations
is in Singpurwalla (1997) and in van der Weide (1997). With
! t
0 udYu t ≥0
"
 i = 12,
described by a gamma process, Singpurwalla and Youngren (1993) produce a generalization of
the BVE whose essence boils down to the feature that in a non-fatal shock model, each shock
induces its own probability of failure on its affiliated component. Recall that in Marshall and
Olkin’s (1967) set-up, the probability of failure from shock to shock (within a shock-generating
process) is a constant. Whereas the above generalization of the BVE is of interest, the focus here
is on the second process for t t ≥0, namely, a ‘shot-noise process’.
The Shot-noise Process
Shot-noise processes have been used in the physical and the biological sciences to describe
phenomenon having residual effects. Examples are surges of electrical power in a control system,
or the after effects of a heart attack. Such residual effects are captured via an attention function,
ht, which typically is a non-decreasing function of t (details are in Cox and Isham, 1980, p. 135).
In the context considered here, suppose that the operating environment consists of shocks, or a
series of events, whose effect is to induce stresses of unknown magnitudes Xk >0 k=01
 
 
 ,
on a component or components; Xk is the stress induced by the k-th shock. The shocks are
assumed to occur according to a non-homogenous Poisson process with a specified intensity
function mt t ≥0. Suppose that when a stress of magnitude X is induced at some epoch of
time t, then its contribution to the modulating function t at time t + u is t + u = Xhu.
Specifically, if 0 ≡T0 < T1 < 
 
 
 are the epochs of time at which stresses of magnitude
X0X1
 
 
 , respectively, are induced then
t =


k=0
Xk ht −Tk
hu = 0, for u < 0 (Figure 4.16). We are assuming here that time is measured from the instant
the first shock occurs; thus 0 = X0. The process t t ≥0 is then a shot-noise process.
Time
T(0) = 0
T(1)
X0
X1
X2
T(2)
η (•)
h(t)
Figure 4.16
A shot-noise process for ·.

112
STOCHASTIC MODELS OF FAILURE
When ht is a constant, the effect of the induced stresses is cumulative; when ht decreases
in t, the unit reveals some form of healing or recovery.
If t t ≥0 is described by a shot-noise process, then the process tt t ≥0 is also
a shot-noise process; t is the intrinsic model failure rate of a component.
A Single-parameter Bivariate Distribution with Exponential Marginals
In what follows, we assume that the failure rate of component i is a constant i i = 12, and
that for all values of k Xk is independent of Tk. Furthermore, the Xis are mutually independent
and have a common distribution function G. Let G∗denote the Laplace transform of G, and
let Mt =
 t
0 mudu and Ht =
 t
0 hudu be the cumulative intensity and attention functions,
respectively. Then, in the case of a solo component experiencing the kind of environment
described above, and having a constant failure rate , Lemoine and Wenocur (1986) give
arguments which can be used to show that T, the time to failure of the component is such that
PT ≥t = G∗Htexp

−Mt +
 t
0 G∗Humt −udu


as before, in writing out the above, the conditioning parameters have been suppressed. The proof
is based on some well-known properties of a non-homogenous Poisson process. The details can
be found in Singpurwalla and Youngren (1993), who also show that in the bivariate case, with
0 ≤t1 ≤t2,
PT1 ≥t1T2 ≥t2 = G∗1Ht1 + 2Ht2 ·
exp
 t1
0
G∗1Ht1 −u1 + 2Ht2 −u1mu1du1

·
(4.47)
exp
 t2
t1
G∗2Ht2 −u2mu2du2 −Mt2


here again, the conditioning parameters have been suppressed.
As a special case of (4.47), suppose that mu = m, so that the shock generating process
is a homogenous Poisson and that G is an exponential distribution with a scale parameter b.
Furthermore, suppose that hu = 1, so that the effect of the imposed stresses is cumulative.
Then, for 0 ≤t1 ≤t2
P T1 ≥t1T2 ≥t2 =

b
b + 1t1 + 2t2
	 b + 2t2 −t1
b + 1t1 + 2t2
	−mb/1+2
·

b
b + 2t2 −t1
	−mb/2
exp−mt2
(4.48)
and its marginal
PTi ≥t =
b + it
b
	 mb
i −1
exp−mt
(4.49)
i=12, is a Pareto distribution of the third kind (Johnson and Kotz, 1970, p. 234). With m=i/b
the survival function (4.49) becomes an exponential distribution. It can be easily verified that
when i/b > <m, the model failure rate of PTi ≥t decreases (increases) in t from i/b to m
(Figure 4.17).

PROBABILITY MODELS FOR INTERDEPENDENT LIFELENGTHS
113
0
Failure rate
Values of t
m
0
b = m
λi
b < m
λi
 m + b
λi
m – b
λi
b < m
λi
Figure 4.17
Model failure rate function of the marginal.
In (4.48), if we set 1 = 2 = , and /b = m, then we see that for 0 ≤t1 ≤t2
PT1 ≥t1T2 ≥t2 =
%
1 −mt1 + mt2
1 + mt1 + mt2
exp−mt2
similarly, its symmetric version holds for 0 ≤t2 ≤t1.
Thus for t1t2 > 0 PT1 ≥t1T2 ≥t2
=
%
1 −mmint1t2 + mmaxt1t2
1 + mt1 + t2
exp−mmaxt1t2
(4.50)
=
%
1 −t −s
1 + t + s exp−maxst
(4.51)
if mt1 = t and mt2 = s.
This is a single parameter bivariate distribution with exponential marginals. The distribution
generalizes easily to the multivariate case, and because it has only one parameter, namely m, it is
highly scalable. Whereas the feature of scalability makes the distribution attractive, the question
of realism needs to be resolved. Of particular concern here is equating the Poisson parameter m
to the ratio of the component’s intrinsic model failure rate  and the scale parameter b of the
exponential distribution for the inflicted stress.
Strength of Dependence in the Single-parameter Bivariate Distribution
It can be shown, details omitted, that the joint survival function PT1 ≥t1T2 ≥t2 of (4.50) has a
probability density at t1t2 for all t1t2 >0, and that it is absolutely continuous. Furthermore, T1
and T2 are positively quadrant dependent, and the distribution does not experience the bivariate
lack of memory property. With PTi > t i = 12, known, it is evident that the conditional
survival function
PT1 ≥t1  T2 ≥t2 =
%
1 −mt1 + mt2
1 + mt1 + mt2

0 < t1 < t2 < 
=
%
1 + mt1 −mt2
1 + mt1 + mt2
exp−mt1 −t2
t1≥t2 > 0	

114
STOCHASTIC MODELS OF FAILURE
To investigate the regression of T2 on T1, we need to find PT1 ≥t1  T2 = t2. After some
routine, but laborious manipulations, this can be shown to be:
⎧
⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎩

1 + mt1
1 + mt1 −t21 + mt1 + t2
	%
1 + mt1 −t2
1 + mt1 + t2e−mt1−t2
for t1 ≥t2 and

1 −
mt1
1 + mt2 −t11 + mt1 + t2
	%
1 + mt2 −t1
1 + mt1 + t2
for 0 < t1 < t2	
Integrating PT1 ≥t1  T2 = t2 with respect to t1 over 0 would give us ET1  T2 = t2.
This is analytically difficult to do. However, its numerical evaluation shows that ET1  T2 = t2
tends to be a convex function of t2 becoming linear as t2 gets large (Figure 4.18).
A comparison of Figures 4.15 and 4.18 indicates that the regression curves of the bivariate
Pareto, the model of Downton, and the model of this section are generally similar. The regression
of T1 on T2 suggests that T1 and T2 are positively correlated. Indeed Kotz and Singpurwalla
(1999) show that the correlation between T1 and T2 is 0.4825, irrespective of the value of m.
Thus m is purely a measure of location and scale.
Systems with Interdependent Lifelengths
If Ts denotes the time to failure of a series system of two components having lifelengths T1 and
T2 described by the joint survival function of (4.50), then by setting t1 = t2 = t, we see that the
reliability of the system is
PTs ≥t =

1
1 + 2mt
	 1
2
exp−mt t ≥0	
(4.52)
Contrast this expression with exp−2mt, the reliability of the system assuming indepen-
dent exponentially distributed lifelengths with a scale parameter m. Clearly, the assumption
of independence underestimates the reliability of a series system functioning in a shot-noise
environment.
Similarly, if Tp denotes the lifelength of a parallel redundant system, then its reliability is
PTp ≥t =

2 −

1
1 + 2mt
	 1
2 
exp−mt t ≥0	
(4.53)
Regression
0
Values of t2
E(T1 | T2 = t2)
Figure 4.18
The Regression of T1 on T2 for the single parameter bivariate exponential.

PROBABILITY MODELS FOR INTERDEPENDENT LIFELENGTHS
115
Comparing the above with 2 −exp−mtexp−mt, the reliability of the system assuming
independent exponentially distributed lifelengths, suggests that independence overestimates sys-
tem reliability of parallel redundant systems.
An intriguing aspect of (4.52) and (4.53) is the feature that as t →, the reliability of both
the series system and the parallel system are approximated by exp−mt. This suggests that the
contribution of redundancy to the reliability of the system asymptotically diminishes, so that
both the series system and the parallel system behave like a single unit having an exponentially
distributed lifelength.
4.7.7
A Bivariate Exponential Induced by a Bivariate Pareto’s Copula
In section 4.7.1, I introduced the notion of copulas and indicated that the ‘method of copulas’
can be used to generate new families of bivarate distributions. Motivated by the consideration
that the regression function of the bivariate distributions discussed in sections 4.7.2 through 4.7.6
do not cover the convex increasing case, Singpurwalla and Kong (2004) develop a family of
bivariate distributions with exponential marginals whose regression function fills the above void.
They use the copula of a bivariate Pareto as a seed. Specifically, they consider the bivariate
Pareto of (4.44) with 1 = 2 = 1; thus
P T1 ≥t1T2 ≥t2 =

b
b + t1 + t2
	a+1

and
P Ti ≥ti =

b
b + ti
	a+1

for i = 12	
By invoking Sklar’s Theorem (section 4.7.1) on the above ingredients one obtains the bivariate
copula
Cauv = u + v −1 +

1 −u−a+1 + 1 −v−a+1 −1
−a+1 	
Observe that in Cauv the scale parameter b does not appear, suggesting that what matters
is only the shape parameter a. If we set u = 1 −exp−t1 and v = 1 −exp−t2 in Cauv,
and invoke Sklar’s Theorem in reverse, then we are able to produce the following bivariate
distribution with exponential (scale parameter 1) marginals:
P T1 ≥t1T2 ≥t2 =

exp

t1
a + 1
	
+ exp

t2
a + 1
	
−1
	a+1
	
The regression function of the above bivariate distribution, namely, ET1  T2 = t2 does
not exist in closed form. However, a numerical evaluation of the regression (with a = 1)
suggests that ET1  T2 = t2 is convex and increases exponentially in t2 (Singpurwalla and
Kong, 2004).
4.7.8
Other Specialized Bivariate Distributions
The bivariate distributions discussed so far had marginals that belong to a common family,
like the exponential, the Pareto and the Weibull. There could arise circumstances wherein the
assumption of a common family for the marginals is unrealistic. With that in mind I give

116
STOCHASTIC MODELS OF FAILURE
below some bivariate distributions whose marginals belong to different families. Such bivariate
distributions provide flexibility of modeling and a means for describing different types of bivariate
dependence.
The Gamma–Pareto Family
Here lifetimes T1 and T2 have a density at t1 > 0 and t2 > 0 of the form
ft1t2 = t1e−t1+t2/
!

with gamma and Pareto marginal densities
ft1 = t−1
1
e−t1
!

t1 > 0
and
ft2 =

 + t2+1 
t2 > 0
respectively. The parameters , and  are positive. Modeling interdependence is best concep-
tualized through conditional distributions. Here the conditional distribution of T1 given t2 is a
gamma density of the form
ft1  t2 = t1
 exp−t1 + t2/
! + 1


+t2
+1

t1t2 > 0
and that of T2 given t1 an exponential of the form
ft2  t1 = t1
 exp

−t1t2

	

t1t2 > 0	
The Gamma–Uniform Family
Here the joint density at t1 > 0 and t2 > 0 is given as
ft1t2 = t−1
1
e−t1
2!

with the marginal of T1 being a gamma distribution with shape (scale) , so that
ft1 = t−1
1
e−t1
!

t1 > 0
and the marginal of T2 a uniform
ft2 = 2−1
 − < t2 <  + 
for some parameter  ≥. Here again, the parameters  and  are positive. The variables
T1 and T2 are independent.

CAUSALITY AND MODELS FOR CASCADING FAILURES
117
4.8
CAUSALITY AND MODELS FOR CASCADING FAILURES
Whereas the notion of dependence has been well incorporated and developed in the literature
on reliability theory – the material of section 4.7 being a testament to this – one also often
encounters in practice terms such as ‘the cause of failure’ and ‘cascading failures’. These terms
do not appear to have been well articulated within a mathematical framework. This section,
based on the work Lindley and Singpurwalla (2002) and Swift (2001), sheds light on some issues
of causal and cascading failures. I start by introducing the notion of probabilistic causality as
enunciated by Suppes (1970). I then argue that failure models such as those of Freund, Marshall
and Olkin, and perhaps some others (but not all) of section 4.7, are models of causal failure.
I then claim that the notion of probabilistic causality with an added condition leads us to the
notion of cascading failures. Consequently, a modified version of the model of Freund paves the
way to developing a probabilistic characterization of cascading events.
4.8.1
Probabilistic Causality and Causal Failures
DeterministiccausalityhasbeenatopicofdiscussionamongphilosopherssincethetimesofHobbes,
Newton,andHume.AprobabilisticapproachtocausalityhasbeensuggestedbyReichenbach,Good,
and Suppes (cf. Salmon, 1980, p. 50). We consider here the version of Suppes (1970), according to
which an event  is said to be a prima facie probabilistic cause of an event  if:
(i)
 occurs before  (in time);
(ii)
P > 0; and
(iii)
P   > P and P   > P.
Condition (iii) above implies that a cause is a probability raising event. Contrast this with
the notion of dependence wherein all that matters is a change (not necessarily an increase) in
probability. The three conditions above label the cause to be a prima facie cause, because the
cause so defined could only be an apparent cause. Suppes labels a cause to be a genuine cause
if it is a prima facie cause that cannot be shown as being a ‘spurious cause’. A prima facie cause
 is said to be a spurious cause of  if and only if there exists, within a conceptual framework,
an event  where:
(i)
 occurs before ;
(ii)
P > 0;
(iii)
 is a prima facie cause of ;
(iv)
P   = P  ; and
(v)
P   ≥P  .
Thus a spurious cause is a prima facie cause that can be explained away by conditioning
on an earlier event (or a common cause of  and ) that accounts as well for the conditional
probability of the effect (i.e. the event ).
Marshall and Olkin’s bivariate exponential distribution provides an example for illustrating the
notions of probabilistic causality discussed above. With respect to the notation of section 4.7.4,
suppose that  is the event T2 = t2, and  the event T1 = t1, where t1 < t2. Then it is easy to
verify that for t1 > 12−1 ln 1 + 12/1, the three conditions of prima facie causality are
satisfied, so that  is a prima facie probabilistic cause of . However,  is not a genuine cause,
because if  denotes the event that the common shock of this distribution occurs at t1, then  is
independent of , given . Indeed, here  is a genuine probabilistic cause of . Consequently,
for all t1 greater than a constant, Marshall and Olkin’s BVE is a model for a causal failure, with

118
STOCHASTIC MODELS OF FAILURE
the event T2 = t2 as the effect, the event T1 = t1 as a prima facie cause, and  as the genuine
cause. Similarly, we can see that in the case of Freund’s model (section 4.7.3) if T1 = t1 denotes
the event that the first component to fail, fails at t1, and if T2 =t2, with t1 <t2, is the event where
the surviving component fails at t2, then the event (T1 = t2) is a prima facie cause of the event
T2 = t2 – the effect. Therefore Freund’s model is also a description of causal failures.
Note that because of the time-ordering of causality, if  is the cause of , then  cannot be the
cause of . Contrast this to the notion of dependence, wherein  dependent on  implies that
 is dependent on . That is, dependence preserves the interchangeability of events; causality
does not. Accordingly, the bivariate Pareto failure model of Lindley and Singpurwalla (1986)
(section 4.7.5) is not a model for causal failures; it is a model for interdependent failures.
Finally, to some, such as Pearl (2000), the approach to causality discussed here is inadequate.
Instead, Pearl introduces his notion of a ‘causal mechanism’, a lucid discussion of which is by
Lindley (2002); also see Singpurwalla (2002). Hesslow (1976, 1981) finds Suppe’s notion of
probabilistic causality unsatisfactory on several grounds, one of which pertains to the view that
for any effect there could be an inexhaustible number of causes and thus every conceivable
cause is a spurious cause. However, Rosen (1978) rebuts Hesslow’s arguments on grounds that
assertions of causal relationships should be within some conceptual framework. In the context of
probabilistic causality, Rosen’s rebuttal re-affirms the importance of  (the background history)
in probability assessments.
4.8.2
Cascading and Models of Cascading Failures
What are cascading failures and how are they different from causal failures? To distinguish
between these two modes of failure, the first thing to note is that in a causal failure model,
simultaneous failures are possible. However, in a model for cascading failures, there is a sequence
of failures, one followed by the other, but within a specified period of time. Cascading is like
a domino effect; the falling of a domino causes its neighbor to fall, but only if the neighbor is
within striking distance of the falling domino. If the dominos are too far apart, a falling domino
will not have any effect on its neighbors. Thus under cascading, there cannot be simultaneous
failures. The failure of one component is followed by that of its neighbor, but within a specified
time called the critical time or a threshold. If the failure of a component causes its neighbor to
fail, but after the critical time has elapsed, then the failure mode is not one of cascading failures.
The power outage of August 2003 in Canada and North-East United States is a classic example
of cascading failures. The failure of a single transmission line due to an overload caused by an
imbalance in the supply and demand of electrical power initiated a sequence (or a cascade) of
failures which literally paralyzed a large region.
Freund’s model (Figure 4.9) provides an architecture for developing the notion of a cascading
failure. Suppose, for example, that Freund’s model is modified so that the failure rate of the
surviving component changes at t1 from 1 to 2, but at some time t1 +   > 0, it reverts back
to 1 (Figure 4.19). The quantity  is the critical time. The choice of  is subjective, but one
possible strategy would be to let  be the time it takes to restore the failed component to an
operational status. In actuality  is best treated as a random quantity having a finite support. In
Figure 4.19, I have chosen the parameters in Freund’s model as 1 = 2 = , and ∗
1 = ∗
2 = 2.
For the set-up of Figure 4.19, it can be seen, details omitted, that the joint density function of
T1 and T2, at t1 and t2, respectively, for t1 < t2, is of the form
⎧
⎪⎨
⎪⎩
22e−2t2
t2 < 
22e−2t2
t1 < t2 < t1 + 
2e−t1+t2+
t2 > t1 + 
Similarly for t2 < t1, mutatis mutandis.

CAUSALITY AND MODELS FOR CASCADING FAILURES
119
2θ
θ
θ
Time
Failure rate
0
δ
t1
t1 + δ
Figure 4.19
Failure rate of the surviving component in a model for cascading failures.
By comparison with the properties of Freund’s model (section 4.7.3) we may verify that T1
and T2 are independent when  = 0, and are positively correlated when  > 0; the model reduces
to Freund’s model when  ↑.
The above model can be generalized to the case of multiple components and can be extended
in several possible directions. For example, we may set ∗
1 =∗
2 =c, where c is random. Another
possibility is to make  random. These and other related issues are discussed by Swift (2001).
System Reliability Under Cascading Failures
As before, if we let Tp denote the time to failure of a parallel redundant system experiencing
cascading failures of the type described by the model of (4.54). Then it can be seen that the
probability density of Tp at t is of the form

42te−2t
t < 
42e−2t + 2e−t+ −2e−2t
t ≥
and that
PTp ≥t =

2te−2t + e−2t
t < 
2e−2t + 2e−t+ −e−2t
t ≥	
(4.55)
Consequently, the failure rate function of PTp ≥t is
rTpt =
⎧
⎪⎪⎨
⎪⎪⎩
42
t
2t + 1
t < 
22e−t + e− −e−t
2e−t + 2e− −e−t

t ≥	
(4.56)
The mean time to system failure ETp is −1 + 2−1e−2, which is greater than −1, the
mean time to failure were the system to experience failure under Freund’s set-up. Were the two-
component parallel-redundant system to be described by independent exponentially distributed
lifelengths, then the mean time to system failure would be 3/2.

120
STOCHASTIC MODELS OF FAILURE
Thus the mean time to failure of a two-component parallel-redundant system experiencing cas-
cading failures is bounded from below (above) by the mean time to failure were it to experi-
ence causally dependent (independent) lifelengths. Results such as these plus those based on a
comparison of the failure rate and the reliability functions, lead to the claim that in the case
of parallel-redundant systems, it is the causal mode of failure that is more deleterious to sys-
tem survivability than a cascading mode. The cascading mode is more deleterious than failures
generated by independent lifelengths; (Lindley and Singpurwalla, 2002; Swift, 2001). The above
conclusion should ease the often expressed concern of some engineers who feel that systems
experiencing cascading failures are the ones that are the most prone to the risk of a total collapse.
4.9
FAILURE DISTRIBUTIONS WITH MULTIPLE SCALES
Our discussion so far has been limited to the development of failure models (univariate and
multivariate) that are indexed by a single scale, namely, time. However, there are scenarios
which require that the occurrence of failure be registered in terms of two (or more) scales;
time and some other metric which may or may not be related to time. For example, when
an automobile fails, we often note its chronological age as well as its mileage. This type of
information is required for making claims against an automobile’s warranty (cf. Singpurwalla
and Wilson 1993). In the biological and medical contexts we would be interested in knowing
the cumulative radiation from diagnostic radiotherapy as a function of age, in order to assess if
the hazards of therapy outweigh its benefits. Often the two scales bear a strong relationship to
each other, and this is what makes the topic of multiple scales interesting. The relationship could
be a deterministic one, though most likely it tends to be stochastic. For example, the mileage
accumulated by an automobile increases with its age, but its value depends on usage, and usage
varies from one individual to the other.
Singpurwalla and Wilson (1998) propose a strategy for constructing failure models
indexed by two scales, time and a time-dependent quantity such as usage. A time-dependent
quantity is considered because most other measures of failure turn out to be functions of time; the
approach generalizes to multiple scales. In what follows I describe the strategy proposed by
Singpurwalla and Wilson (1998) since the emphasis there is on probabilistic modeling in a
reliability setting. However, it is helpful to note that there have been other proposals for the
treatment of multiple scales, namely, those by Nelson (1995), Oakes (1995), Kovdonsky and
Gertsbach (1997), and Jewell and Kalbfleisch (1996). The work of Jewell and Kalbfleisch comes
close in spirit to that described here; the works of Nelson and of Oakes boil down to combining
scales so that the actual analysis is conducted on a single scale.
In section 4.9.1, I outline an overall strategy for developing failure distributions with multiple
scales. Included here are candidate models for relating usage with chronological age, and an
approach for capturing the effect of usage, which now becomes a covariate of the time to failure.
A covariate of the time to failure is to be interpreted as a variable that influences the time to
failure. For example, the operating environment, discussed in section 4.7.5, whose effect on the
failure rate of the item is encapsulated by the parameter , can be viewed as being a covariate.
Our strategy for relating usage with age is based on Cox’s (1972) celebrated proportional hazard
model. The relationships between usage and time are prescribed by some well-known stochastic
processes, such as the Poisson and its variants. In section 4.9.2, I summarize results on a specific
model that is a consequence of the techniques of section 4.9.1.
4.9.1
Model Development
By way of notation, let T denote the time to failure of an item and Mt its cumulative usage
(or dose) at time t ≥0. Thus MT
def= U is the cumulative usage at failure. Both T and U are

FAILURE DISTRIBUTIONS WITH MULTIPLE SCALES
121
random variables; furthermore, by construction they are dependent. Our aim is to specify the
joint probability density function of T and U, at t and u, respectively, assuming that it exists;
both t and u are non negative. Let fTUtu denote this joint density. Then
fTUtu = fTtfU  Tu  t
by the multiplication rule, where fU  Tu  t is the density at u of the conditional distribution
of U given T; we suppose that this conditional density also exists. Since U = MT, the above
decomposition can also be written as
fTUtu = fTtfMT  Tu  t
= fTtfMt  Tu  t since we are conditioning at T = t
= fMTufT  Mtt  u by symmetry of the multiplication rule.
Observe that in fT  Mtt  u t appears two times: as an argument of the variable T  Mt, and
as an indexing parameter of the random variable Mt. Indeed as a function of t fT  Mtt  u
is not a probability density function. Our next step is to prescribe meaningful forms for fMtu
and fT  Mtt  u. This is done next.
Candidate Usage Processes
Since usage varies from unit to unit, a natural model for Mt is a non-decreasing stochastic
process Mt t ≥0, with M0 ≡0. For usage characterized by simple counts, such as the
number of times a unit is turned on (and off), a suitable model for Mt t ≥0 would be a
Poisson process with mean value function  t; (section 4.7.4). Thus, given  t t ≥0,
PMt = u   t = e− t tu/u!u = 01
 
 
(4.57)
For usage that manifests as damage due to shocks of random magnitude, such as the landing
gear of an airplane, the ‘compound Poisson process’ is a meaningful model. Specifically, if
Nt t ≥0, denotes the number of shocks (or landings) inflicted on a unit by time t, and if
Nt t ≥0 is described by a non-homogenous Poisson process with mean value function  t,
then Mt, the cumulative damage (or equivalently, the usage) at time t is Mt =
Nt
$
i=1
Xi, where
Xi is the damage to the unit caused by the i-th shock. If all the Xis are assumed to be independent
and have a distribution that is identical to that of X, where the distribution of X has a density at
x given as fXx, then the random variable Mt has density at u of the form
e− t


j=1
 tj
j!
f j
X u
(4.58)
the stochastic process Mt t ≥0 is known as a compound Poisson process. The quantity
f j
X u is the density at u of the random variable X1 + X2 + ··· + Xj; it is known as the j-fold
convolution of fXu.
The Poisson and the compound Poisson processes have independent increments (section 4.7.4)
and are therefore appropriate if the future of Mt is not influenced by its past. Furthermore
the number of increments of a Poisson process in a finite interval of time are finite. Thus they
are meaningful for describing usage such as damage due to shocks (which are intermittent). By
contrast ‘gamma processes’ (section 4.7.6) have an infinite number of increments in a finite

122
STOCHASTIC MODELS OF FAILURE
interval of time, and are therefore suitable for describing wear caused by continuous use. The
structure of a gamma process is given below.
Suppose that at is non-decreasing and left continuous in t, with a0 = 0, and b ̸= 0, a
positive constant. Then the process Mt t ≥0 is said to be a gamma process with a shape
function at and a scale parameter b, if for any t ≥s ≥0, and M0 ≡0,
(i)
Mt has independent increments, and
(ii)
Mt−Ms has a gamma distribution with a scale parameter 1/b, and a shape parameter
at −as.
When at is linear in t Mt t≥0 will become a ‘Lévy Process’; this process is appropriate
for describing wear caused by a continuous use of the item. Lévy processes are discussed in
section 7.2.2. Like damage, wear (which can be observed and measured) is a proxy for usage.
When usage is intermittent so is the wear; when such is the case Mtt ≥0 can be described by
Çinlar’s (1972), ‘Markov additive process’ (Singpurwalla and Wilson, 1998). Markov additive
processes are overviewed in section 7.3.4, wherein an illustration involving random usage is
also given.
Describing the Effect of Usage on Time to Failure
Suppose that the item in question has a propensity to fail even when it does not experience any
usage. This could happen due to a deterioration in the item’s resistance to failure because of
natural causes. Let r0t be the failure rate of the item were it not to be subjected to any usage;
r0t is known as the baseline failure rate. Usage modifies r0t by increasing it; we assume that
this modification is additive so that rt, the failure rate of the distribution of T, is of the form
rt = r0t + Mt
(4.59)
where  > 0 is a constant. The model of (4.59) is known as an additive hazards model; it
suggests that each unit of use increases the failure rate of T by the same amount. In actuality,
such a model may or may not be true; all the same, it is considered here for illustrative purposes
– also see Section 7.5.2. Let
	t =
 t
0 Mudu and 
0t =
 t
0 r0udu	
Then, by the exponential formula of reliability (section 4.3) conditional on Mt = u and
	t = ,
fT  Mt	tt  u = r0t + uexp−
0t + 
this is the conditional density of T at t, given Mt and 	t. Averaging out with respect to
	t given Mt, enables us to obtain the conditional density of T at t, given Mt. The details
are in (4.6) of Singpurwalla and Wilson (1998), who go on to show that when Mt t ≥0 is
the Poisson process of (4.57), the conditional density of T at t, given Mt = u is of the form:
r0t + ue−
0t
 t
0 e−t−s t
 tds
	u

(4.60)
where s = d
ds s is the intensity function of the process.

FAILURE DISTRIBUTIONS WITH MULTIPLE SCALES
123
4.9.2
A Failure Model Indexed by Two Scales
In section 4.9.1, we discussed several possibilities for fMtu and fT  Mt  u, (4.60) being an
example of the latter. The purpose of this section is to see an illustration of how the above two
can be put together to arrive at fTUtu, the joint density at tu of T and U. Suppose now
that the usage process is the non-homogenous Poisson process of (4.57), and that the additive
hazards model of (4.59) is invoked. Then, fT  Mtt  u will be given by (4.60) and with fMtu
given by (4.57), we have
fTUtu = r0t + u
u!
e−
0t− t
 t
0 se−t−sds
	u

for t ≥0 and u = 012
 
 
A simplification of the above is achieved if r0t = r, a constant and  t = t, for some
constant  > 0; that is, Mt t ≥0 is a homogenous Poisson process. When such is the case
our bivariate failure model, with time t ≥0 as one scale, and usage u = 012
 
 
 , as the other
scale becomes
fTUtu = r + u
u!

1 −e−t
	u
e−r+t	
(4.61)
The marginal distributions of T and U are
PT > t = exp

−r + t + 
1 −e−t
	
 and
PU = u =
ur + u
u&
i=0
 + r + i
	
Results analogous to (4.61) for other processes discussed in section 4.9.1 tend to be cumber-
some; they entail approximations and simulations. More details, with an example involving an
application of the ideas given here to a problem entailing the specification of a warranty for
traction motors of electric locomotives are in Singpurwalla and Wilson (1998).
I conclude this section by citing the work of Lawless and his colleagues on the role of multi-
indexed failure models in the context of statistical analysis of product warranty data; an overview
is in Lawless (1998).


Chapter 5
Parametric Failure Data Analysis
Here lies Thomas Bayes: He rests on his posterior.
5.1
INTRODUCTION AND PERSPECTIVE
Much of the literature in reliability and survival analysis is devoted to the topics of life-testing
and the analysis of failure data. Indeed, the journal Lifetime Data Analysis is exclusively devoted
to research in these topics. In many respects life-testing, failure data analysis and the material of
Chapter 4 on failure models constitute the core of a course in reliability. To appreciate the role
of these three topics in reliability and survival analysis, it is helpful to put in perspective what
has been covered so far.
I start by recalling the key message of Chapter 1, namely the claim that the presence of
uncertain events is common to all problems of risk analysis. In the context of Chapter 4, one such
uncertain event was T>t, where T is some index of measurement, typically, the time to failure
of a unit; another event is Nt = k, where Nt is the number of occurrences of some event of
interest, like a shock. Chapter 2 was devoted to the quantification of uncertainty by probability,
and thus PT > t becomes an entity of interest. This entity was called the survival function,
and a goal of reliability and survival analysis is to prescribe techniques for assessing PT > t.
To facilitate this, the law of total probability (or the law of the extension of conversation) was
invoked, so that for some parameter  (vector or scalar)
PT > t =


PT > t  Fd
(5.1)
where F is the distribution function of . The quantity PT > t   is known as the reliability
of T for a mission time t; de facto, it is a failure model, or a chance distribution for T. The
material of Chapter 4 pertained to considerations in choosing PT > t  . In the absence of any
information other than , which has been suppressed here, F represents one’s best assessment
of the uncertainty about ; it is the prior distribution for . The quantity PT>t is also known as
the predictive distribution of T. Section 5.2 is devoted to the matter of assessing this predictive
distribution assuming some commonly used chance distributions like the exponential, the Weibull
and the Poisson.
Reliability and Risk: A Bayesian Perspective
N.D. Singpurwalla
© 2006 John Wiley & Sons, Ltd

126
PARAMETRIC FAILURE DATA ANALYSIS
Suppose now that interest was centered around n items with Ti as the lifelength of the i-th item.
Then following the line of reasoning that leads us to (2.4), namely conditional independence and
identical distributions, we have as an extension of (5.1)
PT1 ≥t1   Tn ≥tn =


n
i=1
PTi ≥ti  Fd
(5.2)
Furthermore, if T1 ≥t1   Tn ≥tn were denoted by T n, then by the multiplication rule
and the law of total probability, together with the assumptions of conditional independence and
identical distributions, Tn+1, the lifelength of the n + 1-th item, is
PTn+1 ≥tn+1T n =


PTn+1 ≥tn+1 Fd T n
(5.3)
where by Bayes’ law
FdT n ∝
n
i=1
PTi ≥tiFd
The above two equations are analogous to (2.5) and (2.6), respectively. Equations (5.2) and (5.3)
can also be motivated by the judgment of exchangeability; see, for example, (3.11).
When the Tis get revealed as say n, i = 1   n, T n gets replaced by n = 1…n,
and (5.3) becomes
PTn+1 ≥tn+1	n =


PTn+1 ≥tn+1 Fd	n
(5.4)
where Fd	n, the posterior for  is given as
Fd	n ∝L	nFd	
(5.5)
L	n is the likelihood of  for a fixed and known n. Ignoring for now considerations of
the ‘stopping rule’ (section 5.4.2), it is usual to take L	n as
L	n =
n
i=1
fi
(5.6)
where fi is the probability density at i, generated by PTi ≥ti   – provided that
the density exists. In principle, however, L	n could have any suitable functional form
(Singpurwalla, 2002).
The left-hand side of (5.4) is the predictive distribution of Tn+1, the lifelength of the n+1-th,
in the light of n the available failure data on the n lifelengths judged exchangeable with each
other and also with Tn+1. Section 5.4 discusses an assessment of this predictive distribution
supposing the commonly used chance distributions of section 5.2. Equation (5.4) generalizes,
so that the joint predictive distribution of Tn+1Tn+2   Tn+m, lifelengths of m items judged

ASSESSING PREDICTIVE DISTRIBUTIONS IN THE ABSENCE OF DATA
127
exchangeable with each other and with n items whose lifetimes 1   n have been observed.
Specifically, we have
PTn+1 ≥tn+1   Tn+m ≥tn+m	n =


m
i=1
PTn+i ≥tn+i  L	nFd
(5.7)
Such predictive life distributions play a useful role in system reliability analysis.
By life-testing I mean strategies or experimental designs for generating the failure data n.
These strategies are important, in the sense that they may influence a specification of the
likelihood (section 5.4.2). By failure data analysis I mean an assessment of the predictive
distributions of the form given by (5.4) and (5.7). Failure data analysis should, in principle,
also include some form of validating the assumption of exchangeability that is inherent to the
results of (5.4), (5.6) and (5.7). The aim of this chapter is to articulate on the matter of assessing
predictive distributions of the kind mentioned above, on the generation of failure data to facilitate
these assessments, and on using the predictive distributions for making decisions such as lot
acceptance/rejection. In section 5.3 I discuss methods for specifying the prior Fd, either by
elicitation or by standard rules.
Whereas the role of the parameter  has been to facilitate an assessment of predictive distri-
butions, it is sometimes the case that interest may center around  itself. This can happen when
one is able to attach some physical or scientific meaning to  as opposed to viewing it as simply
a Greek symbol. When such is the case, failure data analysis could also mean to include an
assessment of the posterior distribution of  (equation (5.5)).
5.2
ASSESSING PREDICTIVE DISTRIBUTIONS IN THE ABSENCE OF
DATA
The archetypal problem I propose to address here is the assessment of PT>t via (5.1), namely
PT > t =


PT > t  Fd
It is important to bear in mind that implicit to the above is the role of  – history or background
information. For convenience  has been suppressed; however  encapsulates all the engi-
neering and scientific knowledge that an assessor of PT>t has about an item whose lifelength
is T. Such knowledge should play a role in specifying a failure model of the form PT > t  
as well as the prior Fd. What distinguishes the material here from that of section 5.3 is that
in the latter, one has in addition to  the failure data n, so that an assessment of predictive
distributions is made in the light of both n and . The likes of (5.1) are germane when the
item in question is one of a kind, so that it is not possible to obtain failure data from items
judged exchangeable with the said item.
5.2.1
The Exponential as a Chance Distribution
Now suppose that based on , an assessor of PT > t makes the judgment that the item
is immune from aging and wear so that a reasonable choice for its failure model or chance
distribution is an exponential with parameter 
; i.e.  = 
 
 > 0. Then PT > t   = 
 =
exp−
t, for t ≥0, and so
PT > t =


exp−
tFd


128
PARAMETRIC FAILURE DATA ANALYSIS
Recall (section 4.2) that Fd
 = f
d
, where f
 = dF
/d
 is the derivative of F
, the
prior distribution function of 
, provided that the derivative exists. What should F
 be?
Since 
 > 0, F
 should have 0 as its support. One possibility is to assume that F

has a gamma distribution with a scale parameter  and a shape parameter  (sections 3.2.2 and
4.4.2). Then it can be seen that
PT > t = / + t
(5.8)
a Pareto distribution. Since E
 = /, V
 = /2, and ET  
 = 1/
, we may pin down
 and  by setting / equal to our best guess for the values of T, and √/ equal to our
standard deviation about this guess. In principle, one is free to choose any proper distribution
as a prior for 
 as long as there is a rationale and justification for the choice. More about this
matter of proper distributions is said later in section 5.3.2.
5.2.2
The Weibull (and Gamma) as a Chance Distribution
Instead of the exponential, as a failure model for T, we may want to choose the Weibull
distribution with scale parameter 
 > 0, and shape parameter  > 0. Then  = 
 is a
vector, and PT > t   = exp−
t. This choice has an advantage of providing an ability
to incorporate the property of aging or wear with  > 1, and it reduces to an exponential
distribution with  = 1. Thus using this distribution over the exponential makes the analysis
robust to departures from exponentiality. Its disadvantage is that one now has to assess a two-
dimensional joint prior distribution for  = 
, and this results in the unavailability of closed
form expressions of the predictive distribution. Numerical approximations and simulation offers
a way out, but the results so produced lack an interpretive flavor. For example, properties like
the decreasing failure rate of the Pareto predictive distribution of (5.8) cannot be asserted.
The traditional approach for assigning a prior distribution for  has been based on the assump-
tion that 
 and  are independent; an exception is Soland (1969). This cannot be meaningful
because were we to anchor our best judgment about T via ET, its mean, or via MT, its
median, then specifying either confounds 
 and . For example, were PT ≥t  
 to be
parameterized as exp−t/ with 
 = 1/, then it can be seen that MT =  expc/,
where c = ln ln 2, is a constant. Consequently, once MT is specified, both  and  can-
not be freely chosen. Similarly, with ET. How then should a joint prior on  and  be
specified?
Since  characterizes aging or the absence of it, it is possible for subject matter specialists to
offer expert testimonies on . Large values of >1 suggest a rapid deterioration of the item with
age; the converse with  < 1. Thus a gamma distribution with scale  and shape  would seem
to be a reasonable choice for the prior distribution of . The quantity / would encapsulate
ones best guess about  and √/ the uncertainty about this guess. Suppose that 	
denotes the probability density of this prior. However, eliciting from a subject matter specialist,
a prior for  conditioned on  poses a practical difficulty. Most subject matter specialists do not
think in terms of parameters of failure models, and asking an expert to assess  for some fixed
value of  seems far fetched.
In Singpurwalla (1988b), a strategy for inducing a joint prior on  and  based on 	
and an elicited prior on the median MT is proposed. Let MT	 denote the density of
the prior distribution of MT;  and  are the parameters of this density (section 5.3.1). This
prior density is based on the testimony of one or more subject matter specialists about the median
life; it incorporates considerations such as expertise of the experts plus the experts’ disposition
to risk, etc. Details about the elicitation process and the functional form of MT	
are given in section 5.3.1, (5.21). However, there is a caveat to the proposed strategy in the

ASSESSING PREDICTIVE DISTRIBUTIONS IN THE ABSENCE OF DATA
129
sense that the elicitation of MT is not conditional upon ; that is, MT and  are judged
independent. This seems reasonable – and the data analyzed by Singpurwalla (1988b) does not
negate the assumption – because subject matter specialists are able to conceptualize and assess
median lifetimes without any encumbrance from their assessment about aging. Even otherwise
the elicitation of MT conditioned on  is, from a practical point of view, more palatable than
the assessment of  conditioned on . With the prior parameters  and  specified, the
joint prior density at  and  turns out to be of the form:
−1
√
2
exp
 c
 −

−1
2
ec/ −

2

where  =
⎛
⎝


−/
2−1/2 exp

−u2
2

du
⎞
⎠
−1
	
(5.9)
≈1 if ≥3. Equation (5.9) though cumbersome in appearance has the virtue of being a proper
density and one that has been reasonably well motivated. A gamma density for  has also been
advocated by Martz and Waller (1982, p. 237). An advantage in eliciting expert testimony on
the median MT rather than the mean ET is twofold. The first is that the relationship between
MT and the parameters  and  takes a simple form, namely, MT =  expc/ where c is a
known constant; by contrast ET=+1/ where x=
 
0 ux−1e−udu. This simplifies
the task of inducing the joint prior on  and . The second, perhaps a more important reason
is that eliciting expert testimonies on percentiles, like the median, has, according to empirical
and psychological studies, proven to be more effective than that of the mean; see, for example,
Peterson and Beach (1967) and Hogarth (1975).
The approach prescribed above, though focused on the special case of the Weibull, can be
invoked for the other two parameter failure models. All that is required is that any measure
of central tendency, such as the mean, the mode or the median, or for that matter some other
percentile, be expressed as a simple function of the parameters, and that one of the two parameters
be physically interpreted. For example, the mode of a gamma distribution with scale (shape)
 is  −1/, and for ><1 this distribution has an increasing (decreasing) failure rate,
which for large amounts of the lifetime T asymptotes to . Thus under the judgment of aging,
the prior on  should have support 1 ; otherwise its support should be 01. The choice of
gamma as a failure model has been argued for parallel systems in stand-by redundancy, or for
items whose failure can be attributed to the accumulation of damage caused by Poisson shocks
(Mann, Schafer and Singpurwalla, 1974, p. 125). The exact details on how to exploit the above
features for inducing a proper prior distribution on  and  remain to be worked out; they are
left as a project for the reader.
5.2.3
The Bernoulli as a Chance Distribution
The Bernoulli, as a chance distribution, was introduced in section 3.1.3 in connection with
de Finetti-type representation theorems for zero-one exchangeable sequences. In the context of
the set-up of this section, suppose that the event T > t has as its proxy an event X = 1,
and that X = 0 is a proxy for the event T ≤t. A motivation for introducing the binary
X in place of the continuous T is simplification. Specifically, we are able to replace multi-
parameter chance distributions by a single parameter chance distribution. To see why, we note

130
PARAMETRIC FAILURE DATA ANALYSIS
from (5.1) that when the continuous T is replaced by the Bernoulli X with a parameter ,
we have
P X = 1 =


P X = 1  F d
=
1

0
F d
(5.10)
since  has support 01. Thus were PT > t  • to be a Weibull chance distribution of the
form exp−t/, as was done in section 5.2.2, the representation of (5.10) would entail a
chance distribution consisting of a single parameter . Whereas  encapsulates the effect of both
 and , there is a loss of granularity in going from the representation of (5.1) to (5.10). This
is because with the former one can place bets on the event T > t for a range of values of t,
whereas the latter enables bets on only a single event defined by X.
In section 3.1.2, a beta distribution with parameters  and  was chosen as the prior for ,
0 <  < 1. For  > 0, its density at  is of the form
 + 
−11 −−1
(5.11)
where  =
 
0 x−1e−xdx. The mean and variance of this beta distribution are / +  and
/ + 2 +  + 1, respectively.
This distribution is attractive in the sense that by a suitable choice of  and , various forms
of subjective judgments about  can be expressed. For example,  =  = 1 results in a uniform
density for , whereas the choice =2, =1 makes the density of the form 2 – a triangle with
an apex of 2 at  = 1. Identical values of  > 1 and  > 1 make the density symmetrical about
 =1/2, which is where it also attains its maximum. Values of <>1 and ><1 make the
density L-shaped or J-shaped (Figure 5.1). The former is appropriate when one has a strong prior
opinion about the outcome X being 0; the latter when the prior opinion that X when revealed
will be 1 is strong. Values of  and  less than one enable us to describe a U-shaped density
for  (Figure 5.1). The U-shaped density for  is appropriate when one opines that in repeated
trials of the phenomenon that generates X, the values of the Xs when revealed will be a long
sequence of either zeros or ones. When  < =1 and  = <1 the density is L(J)-shaped, but
unlike the illustrations of Figure 5.1, it does have a probability mass at  = 10. A hierarchical
two-stage approach for specifying a prior for  is in section 2 of Chen and Singpurwalla (1996).
L-shaped
α < 1, β > 1
0
1
θ
J-shaped
α > 1, β < 1
0
1
θ
U-shaped
α < 1, β < 1
0
1
θ
Figure 5.1
L, J, and U-shaped densities for the prior of .

ASSESSING PREDICTIVE DISTRIBUTIONS IN THE ABSENCE OF DATA
131
A lot has been written about a suitable choice for the prior distribution of . Much of the
discussion is philosophical and focused on densities that encapsulate little or no knowledge, or
those that best allow the data – when available – to dominate the effect of the prior. Such priors are
known under several names as ‘objective’, ‘default’, ‘reference’ and ‘non-informative’, and are
used when one wishes to adopt an impartial stance. Geisser (1984), following Bayes and Laplace,
advocates the uniform as a noninformative prior for ; Laplace used the principle of indifference
for justifying his use of this prior. Others who have written on this topic are Bernardo (1979a),
Haldane (cf. Jeffreys, 1961; p. 123) and Zellner (1977). Bernardo and Zellner advocate (default)
proper priors that are proportional to −1/21 −−1/2 and 1 −1−, respectively. However,
some of the proposed priors for  are improper, and in some cases they depend on the nature of
the experiment that generates X; such priors are objectionable. For example, Haldane proposes
that the density for  be proportional to 1 −−1 which is improper because its integral is
not one. Lindley (1997a) refers to the property of the failure of the density to integrate to one as
impropriety. The desire to produce priors that are universal, and consequently non-subjective,
has yielded distributions having the objectionable features mentioned above. More about this
will be said in section 5.3.2.
A subjectivistic assessment of  based on expert testimony has been proposed by Chaloner
and Duncan (1983), much in the spirit of eliciting expert testimonies on Weibull lifetimes that
result in (5.9). An alternative approach is to induce a prior distribution for  using the elicited
priors on the parameters of the chance distributions of sections 5.2.1 and 5.2.2. This task is easier
in the case of the exponential than the Weibull. Specifically, for PT>t  
 =exp−
t, I have
proposed the gamma distribution with parameters  and  elicited via expert testimonies on the
mean time to failure ET  
 as a suitable choice. Since
Px = 1   =  = PT > t  
 = exp−
t
a prior on 
 induces a prior on . It can be seen – details left as an exercise for the reader – that
a gamma prior on 
 with scale  and shape  results in the following as a prior density for ,
0 <  < 1:
/t−1


t
 
ln
1

−1

(5.12)
It is important to bear in mind that the mission time t is a parameter of the above prior. This is
to be expected since  depends on t, taking the value 10 when t = 0. In the case of the
Weibull with scale  and shape ,  = exp−t/. This form makes the task of inducing a
prior on  based on a joint prior on  and  cumbersome; it will have to be done by simulation.
Similarly, for the case of a gamma chance distribution.
Since PX = 1 = E (equation (5.10)) we have the result that when the prior on  is a beta
density of the form given by (5.11), PX = 1 = / + , the mean of . When the prior on 
is an induced density of the form given in (5.12), then PX = 1 = / + t, the mean of 
under this density; its variance is / + 2t −/ + t2. Note that the  in / + 
is not the same  in / + t; the former is a parameter of the beta density for , whereas
the latter is the shape parameter of a gamma prior for 
. Since / + t is also the survival
function of a Pareto distribution (equation (5.8)) we have the interesting observation that the
mean value function of the density of (5.12) is the survival function of a Pareto distribution.
Whereas (5.10) pertains to the special case of X = 1, its more general version entailing X = x,
for x = 1 or 0, takes the form
PX = x =
1

0
x 1 −1−x Fd

132
PARAMETRIC FAILURE DATA ANALYSIS
If F is taken to be the beta distribution with parameters  and , then
P X = x =
1

0
x 1 −1−x  + 
−11 −−1d
=  +  + x −x + 1
 + 

(5.13)
Verify that when x = 1, the above expression becomes / + , and that when x = 0 it is
/ + . Furthermore, if the prior on  were to be a uniform distribution, i.e. were  =  = 1,
(5.13) would yield PX = 1 = PX = 2 = 1/2. This result implies that under the uniform prior
for , the reliability of the unit in question is 1/2.
Series Systems with Bernoulli Chance Distributions
Now suppose that we have two such units and that they are connected to form a series system.
What is the reliability of this system supposing that their associated Xis, i = 12, are condition-
ally – given  – independent? The conventional answer, namely
 1
2

·
 1
2

= 1
4, would be incorrect!
The correct answer is 1/3. To see why, we start by considering, for xi = 0 or 1, i = 12,
P X1 = x1X2 = x2 =
1

0
P X1 = x1X2 = x2  Fd
=
1

0
P X1 = x1  PX2 = x2  Fd
since X1 and X2 are conditionally independent, given . Thus
P X1 = x1X2 = x2 =
1

0
x11 −1−x1x21 −1−x2Fd
=
1

0
x1+x21 −2−x1−x2d
(5.14)
since F is a uniform distribution on 01. Simplification of the above yields,
P X1 = x1X2 = x2 = x1 + x2 + 13 −x1 −x2
4

which for x1 = x2 = 1 becomes 31
4
= 1
3
The incorrect answer is a consequence of invoking the assumption of independence after
averaging out . This is flawed because X1 and X2 are independent conditional on . Uncondi-
tionally, they are not independent; they are exchangeable. This example highlights two features:
the assumption of unconditional independence that is commonly made in practice underestimates
the reliability of series systems and the importance of when to average out with respect to the
unknown parameters. The latter point is also illustrated in Singpurwalla (2000), who considers
the prediction of events in a Poisson process with an unknown parameter.

ASSESSING PREDICTIVE DISTRIBUTIONS IN THE ABSENCE OF DATA
133
Note that if F were to be a beta distribution with parameters  and , then (5.14) would
simplify as
P X1 = x1X2 = x2 =  +  + x1 + x2 −x1 −x2 + 2
 +  + 2

5.2.4
The Poisson as a Chance Distribution
The exponential and the Weibull, as chance distributions, were considered in sections 5.2.1 and
5.2.2 on the premise that the former encapsulated an immunity to aging whereas the latter was
able to incorporate aging. A choice of these distributions can also be justified via de Finetti’s
theorems on exchangeable sequences. In this section, I consider the case of the Poisson as a
chance distribution. The appropriateness of this choice can be argued on two grounds. The first
is that the Poisson distribution can be seen as the genesis for the exponential, the Weibull, and
the gamma (an several other) distributions, in a sense to be made clear soon. The second is
that the Poisson also appears in the context of a de Finetti-style representation of nonnegative
integer valued exchangeable sequences (section 3.2.2). Many scenarios in reliability and survival
analysis entail count data of the type X1X2   , where each Xi = 012   For example, Xi
could denote the number of times the i-th machine experiences a failure, assuming that it gets
repaired subsequent to every failure. The Xis here are a generalization of the Bernoulli case of
section 5.2.3 wherein each Xi took only two values 0 and 1.
To see the relationship between the Poisson distribution and the others considered here,
suppose that a unit is scheduled to operate in an environment wherein damage-causing shocks
occur according to the postulates of a Poisson process (section 4.7.4). Suppose that the unit is
able to sustain no shocks, so that it fails upon the occurrence of the first shock. If T denotes the
time to failure of the unit and Nt the number of shocks in the time interval 0t, then
PNt = k  t = exp−ttk/k!
for k = 012; t is the mean value function of the process and its derivative 
t is the
intensity function of the process. This is the Poisson distribution with ENt = t. Since the
unit is unable to sustain any shocks
PT > t = PNt = 0 =

t
PNt = 0  tFdt
by the law of the extension of conversation. But PNt = 0  t = e−t, and thus
PT > t =

t
e−tFdt
(5.15)
If t = 
t, that is, the Poisson process is homogenous then
PT > t =


e−
tFd

a relationship considered by us in section 5.2.1. If t = exp−t/, then
PT > t =


e−t/Fdd
(5.16)

134
PARAMETRIC FAILURE DATA ANALYSIS
the scenario considered by us in section 5.2.2.
Suppose now, that the unit in question can withstand at most K shocks, where K takes values
k = 012   , then
PT > t =


k=0
PT > t  kk
(5.17)
where k = PK = k. However,
P T > t  k =

t
PT > t  ktFdt
=

t
k
j=0
e−ttj
j!
Fdt
(5.18)
since PT>t  kt=PNt≤k  t and the latter is prescribed by a Poisson distribution.
Thus
PT > t =


k=0

t
k
j=0
e−ttj
j!
Fdtk
(5.19)
When the Poisson process is homogeneous, t = 
t, and PT > t  kt becomes
PT > t  k
t =
k
j=0
e−
t
tj
j!

(5.20)
which is a gamma distribution with scale 
 and shape k. Its density at t is given as (also see
section 3.2.2)
Fdt  k
 = e−
t
tk−1
k −1!

Thus we can see that the three chance distributions in question, namely, the exponential, the
gamma and the Weibull, have their genesis in the Poisson process and the Poisson distribution.
Choosing different forms for t motivates chance distributions other than the three mentioned
above. Recall that t must be non-decreasing in t. Its derivative 
t could, however, take
any meaningful form, including the possibility that 
t	t ≥0 be a stochastic process. When
such is the case, the underlying Poisson process is also known as a doubly stochastic Poisson
process or the Cox process, after David Cox who may have been the first to propose it, and

t	t ≥0 is known as the intensity process. When 
t is described by a Markov process
(section 7.3.3), the resulting model for Nt is known as a hidden Markov model. The above
processes are often used for describing software failures (cf. Singpurwalla and Wilson, 1999).
More about these processes is detailed later, in Chapters 7 and 8 on point process models. For
now I concentrate on the issue of specifying prior distributions for t.
Prior for the Mean Value Function of a Poisson Process
In Campódonico and Singpurwalla (1995) a strategy for inducing a prior distribution on the
parameters of the functional form which describes t based on an elicited joint prior on
ti,i=1   n, is proposed. If the functional form of t entails two parameters then n=2;

ASSESSING PREDICTIVE DISTRIBUTIONS IN THE ABSENCE OF DATA
135
in general, n equals the number of parameters used to specify t. Details of the elicitation
process are given in section 5.3.1. For n = 2, with i = ti, i = 12 and 1 ≤2, the joint
prior on 12 12	• can be obtained. It can be shown that this prior is proportional to
2
i=1
exp

−1
2

i−li
ri
2
1 −

ni−i
ri

·
exp

−1
2

s2−s1
2−1
2
1 −

−
s1
2−1

2 −1
·
exp

−
s1
2−1

2 −1
	
(5.21)
liniri and si i = 12, are parameters whose interpretation is given at the end of section 5.3.1.
As before x =
 x
−
1
√
2 e−u2/2du.
Once 12	• is specified, we are able to address the likes of (5.15)–(5.19). However,
to do so, we must write ti in terms of i, i = 12. For example, in the context of (5.16),
i = ti/, i = 12; this when solved gives
 = T1−lnt1/t2/ln1/2
1
and  = ln1/2
lnt1/t2 
and 12	• gets used in place of Fdd.
The cumbersome nature of (5.21) makes computations difficult; this is a disadvantage of proper
priors that are formally elicited. A computer code for numerically addressing the computations
entailed here is in Campódonico (1993).
5.2.5
The Generalized Gamma as a Chance Distribution
Flexibility in the choice of a chance distribution can be achieved by considering the generalized
gamma family of distributions. This family entails four parameters, two for the shape, one for
the scale and one for the threshold. Here, the probability density at t is of the form


t −−1

exp

−
t −


for t >     > 0 and  > 0
The shape of this distribution is determined by both  and ;  is a scale parameter, and 
the threshold parameter. The model assumes that no failures can occur before ; consequently
 is of interest when setting warranties. The generalized gamma reduces to an exponential when
= =1, a gamma with (without) a threshold when =1 (and =0), a Weibull with (without)
a threshold when  = 1 (and  = 0), and a lognormal when  →.
The flexibility of this chance distribution is a consequence of it having several parameters.
This, however, is also its weakness, because now we need to elicit a 4-variate prior distribution,
a task that is not trivial. As a consequence of this difficulty, Upadhyay and Smith (1994) assume
independent priors for each of the four parameters, a gamma for  and , a uniform for , and an
improper prior that is proportional to 1/ for the parameter . This choice of priors is arbitrary;
however, the authors’ objective was not to discuss the selection of a meaningful subjective prior.
Rather, their aim was to describe the use of computer-intensive techniques for analyzing failure
data that is meaningfully described by a generalized gamma distribution. More about the use of
such (objective) priors is said later in section 5.3.2, and the computational technique alluded to
above will be overviewed in Appendix A, in the context of the material of section 5.4.5.

136
PARAMETRIC FAILURE DATA ANALYSIS
5.2.6
The Inverse Gaussian as a Chance Distribution
The Inverse Gaussian (IG) has been introduced before, in section 4.4, as an alternative to the
lognormal distribution. Its attractiveness stems from the fact that it is better able to describe
situations involving early failures, and from a structural point of view, an IG is the distribution
of the first passage (or hitting) time of a Brownian motion process to a threshold (or a barrier).
More about the role of this process in modeling lifetimes is said later, in section 7.3.
Given the parameters  and , the density at t of PT>t   has been given in section 4.4.
Betró and Rotondi (1991) illustrate the behavior of this density for different values of the shape
parameter ; recall that  is a scale parameter. For small values of  ≥1, the density is skewed
to the right, becoming more and more symmetric as  increases to say 50 or so. For values of
 < 1, the density tends to be sharply peaked near the origin making the IG a suitable chance
distribution for scenarios involving the predominance of early failures.
A joint prior distribution for the parameters  and  that is proper has been proposed by Betrò
and Rotondi (1991). Specifically, given , the prior density at  is also an IG with parameters
 and ; it is of the form

2
 1
2
−3
2 e exp

−
2
 
 + 



The prior of  is taken to be a gamma distribution with scale  and shape  > 1, so that the
density at  is of the form

−1e− for  > 0
The joint prior density at  and  is the product of the above two density functions. Besides
propriety (section 5.2.3) this choice for a prior has the attractive feature of resulting in closed
form expressions for the mean and the variance of ; specifically, the former turns out to be 
and the latter 2/ −1. More important, the posterior distribution of  and  also turns
out to be of a computable form (section 5.4.6).
5.3
PRIOR DISTRIBUTIONS IN CHANCE DISTRIBUTIONS
From a purely subjectivistic Bayesian point of view, all prior distributions, be they on unob-
servable parameters or on the observable unknowns, should be proper and should truthfully
reflect the informed opinion of the analyst and any subject matter specialists that the analyst
may consult. Furthermore, the priors should not depend on the nature of the experiment that
generates the observables. For example, in the context of Bernoulli trials, the prior on  should
not be based on whether the experiment to be performed is binomial or negative binomial.
Whereas such subjective priors are deemed appropriate in the context of problems involving
personal decision making, they are often objected to by individuals involved in matters of public
discourse pertaining to issues of government policy and safety. Subjective priors are also of
concern in adversarial scenarios involving litigation and the judiciary and when dealing with
purely scientific investigations, like the assessment of universal constants; e.g. the speed of light.
It is because of such concerns that the so-called ‘objective priors’, like the noninformative and
the reference, have come into being. The purpose of this section is twofold; the first is to discuss
some systematic approaches for eliciting and coding expert testimonies on survival times and
number of events, and the second is to articulate and to overview some key ideas and notions
about objective (or default) priors and the controversies that surround them.

PRIOR DISTRIBUTIONS IN CHANCE DISTRIBUTIONS
137
5.3.1
Eliciting Prior Distributions via Expert Testimonies
In section 5.2, I have considered four chance distributions as points of discussion: the exponential,
the Weibull, the Bernoulli and the Poisson. Since the exponential is a special case of the Weibull,
it suffices to focus on the latter, and this is what we will do. The Bernoulli case has been
amply covered in section 5.2.3 so that need for discussing methods of eliciting a beta prior
for its parameter  is not too pressing. However, those interested in pursuing this topic further
may consult Chaloner and Duncan (1983), or Chen and Singpurwalla (1996); the latter consider
a context-dependent scenario involving higher reliability items. What therefore remains to be
discussed is the case of the Weibull and the Poisson. In the case of the Weibull, I consider an
elicitation of MT, the median life (section 5.2.2). In the case of the Poisson, I consider an
elicitation of T, the mean value function.
Elicitation for the Weibull Distribution
Recall that MT =  expc/ where c = ln ln 2, and  and  are parameters of the Weibull
distribution. The approach given below is based on Singpurwalla (1988b), who adopted, for
problems in reliability, Lindley’s (1983) general plan for eliciting, modulating and coding expert
testimony.
Suppose that an expert  conceptualizes the uncertainty about MT via some distribution with
mean m and standard deviation s, independent of what  thinks about . That is, in ’s view
50% of the units similar to the one of interest will fail by m; s is a measure of ’s conviction in
specifying m. Suppose that  declares the m and the s to an analyst  as ’s expert testimony
about MT.
 uses m and s to construct a likelihood function; the likelihood function incorporates the
expertise of  as perceived by . Specifically, ’s likelihood for MT, with m and s specified
by , is of a Gaussian shape with a mode at m −a/b and a spread reflected by s/b. The
constants ab and  are specified by ; they reflect ’s view of ’s bias and precision in
declaring m and s. Specifically,
(i) If b = 1, then a is a bias term expressing ’s view that  overestimates MT by an
amount a.
(ii) If  feels that  overestimates (underestimates) MT by 10% then a=0 and b =1109.
(iii) If  feels that  exaggerates (is overcautious about) the precision s, then  > <1.
If  has full faith in the expertise of the expert, then a=0 and b ==1. Figure 5.2 illustrates
this likelihood.
Likelihood
M(T)
b
m – a
b
δs
Figure 5.2
’s likelihood for MT for fixed m and s.

138
PARAMETRIC FAILURE DATA ANALYSIS
Suppose further that s alone provides no information to  about MT, and that ’s knowledge
about MT is weak in comparison with ’s input. The first assumption implies that ’s
likelihood of MT for a fixed s is a constant. The second assumption implies that PMT, ’s
prior for MT, is flat in the region where the likelihood is appreciable. With the above in place,
 invokes Bayes’ law to write:
P MT	msp ∝MT	mspPMT
∝MT	msp
since PMT is flat where the likelihood is appreciable; the constant p denotes the vector of
’s inputs ab. The genesis of MT	msp is the probability
P  MT	p = P  MT	pP  MT	p
where  and  are viewed by  as random quantities whose realizations are m and s respectively
(section 2.4.3). Since  and  have been revealed as m and s, respectively, P  MT	p
becomes MT	msp and P  MT	p becomes MT	sp. But s by itself provides
no information to  about MT; consequently, MT	sp is a constant, and MT	msp
has the bell-shaped Gaussian form of Figure 5.2. Thus
P MT	msp ∝MT	msp	
this results in the claim that:
 describes the uncertainty about MT via a Gaussian distribution with mean  = m −a/b
and standard deviation  = s/b.
The above claim would be satisfactory if MT was not restricted to be non negative. Thus,
we need to truncate the above Gaussian distribution at 0, making ’s probability density of the
median at MT of the form
MT	 =
K
√
2
exp

−1
2
MT −

2
 0 < MT < 
where K =
⎛
⎝


−/
1
√
2
exp

−u2
2

du
⎞
⎠
−1
	
(5.22)
K ≈1 when  ≥3.
Once  arrives upon MT	 and a gamma prior for , namely 	
(section 5.2.2)  can induce a joint distribution for  and  by first inducing a distribution
for  conditioned on , say   	 and then multiplying the latter by 	. To
obtain   	,  invokes the relationship MT= expc/ in (5.9), and using standard
techniques arrives on the form:
  	 = Kec/
√
2
exp

−1
2
ec/ −

2

for 0 <  < . Multiplying this equation by 	 gives us an elicited joint prior for the
parameters  and  of the Weibull distribution P T > t   = exp

−t/
. This turns out
to be (5.9) of section 5.2.2.

PRIOR DISTRIBUTIONS IN CHANCE DISTRIBUTIONS
139
The development so far has considered the case of a single expert . Extensions for the case
of multiple experts is relatively straightforward, save for the fact that now  needs to specify,
in addition to the ab and  for each expert, the correlations between the declared values of m
and s, as perceived by . The details tend to get messy (cf. Lindley and Singpurwalla, 1986).
For example, in the case of two experts who provide m1s1 and m2s2 as inputs, and with
 introducing the constants aibii, i = 12, and 12, ’s perceived correlation between
the expert testimonies m1 and m2, ’s final assessment of MT is that MT has a Gaussian
distribution with mean  and variance 2, where
 = m1 −a1

111 + 212
+ m2 −a2

112 + 222
2
111 + 2
222 + 12 12 + 21
 and
 =

2
111 + 2
222 + 12

12 + 21−1/2 	
ij are the elements of a matrix that is the inverse of a matrix with elements 11 =2
1s2
1 22 =2
2s2
2,
and 12 = 21 = 1211221/2. The case of multiple experts follows along similar lines; the
details are in Lindley and Singpurwalla (1986).
Whereas the discussion so far has centered around the scenario of assessing a median MT,
we could, in principle, have chosen any other unknown quantity, such as the mode, the mean,
or some percentile, about which the expert is able to provide testimony. The procedure for
modulating and coding m and s will be the same. Indeed we could also have elicited expert
testimony on the lifelength T itself. The procedure outlined above would still be applicable,
since its basic premise is to use the expert testimony as data to construct a likelihood based on
the expertise of the expert. The assumptions used by us, namely, the flat likelihood of MT for
a specified s, ’s knowledge about MT being flat where the likelihood is appreciable, and
the Gaussian likelihood for MT given m and s, are purely for technical convenience. Other
forms of the likelihood could have been used. For example, Singpurwalla and Song (1986) use
a likelihood based on the chi-squared distribution. The generality of the procedure, vis-à-vis its
applicability to scenarios involving other chance distributions like the Poisson, can be appreciated
via the work of Campodónico and Singpurwalla (1994a, 1995); an overview of which is given
below.
Elicitation for the Non-homogenous Poisson Process
We follow here the general scheme used in the case of MT for the Weibull distribution
involving an analyst  and an expert . Following the notation of section 5.2.4 we consider
i = ti, i = 12, for t1 < t2; we are supposing that the functional form of ti entails two
parameters. Suppose that  provides  testimony about 1 ≤2 via the constants mi and si,
i = 12. According to , mi is a measure of location and si a measure of scale about ’s
uncertainty about i, i = 12.
Suppose that  views mi and si as realizations of the random quantities i and i, and models
their distributions based on ’s opinions about ’s expertise and ’s perceived dependence
between 1 and 2, and 1 and 2. These distributions will enable  to specify the needed
likelihood functions. Since 1 ≤2, it is reasonable to suppose that 1 and 2 will be positively
dependent. Thus with m1m2s1 and s2 given, ’s task is to specify  12	m1m2s1s2;
this, by Bayes’ Law is of the form
 12	• ∝12	m1m2s1s2P 12
where P 12 is ’s prior for 1 and 2.

140
PARAMETRIC FAILURE DATA ANALYSIS
As was true with the case of MT, ’s main task is to specify the likelihood 12	m1,
m2s1s2. For this we note that the genesis of this likelihood would be the joint probability
P1212  12 which by the multiplication rule can be factored as:
P 1212  12 = P 211212 · P 21112
·P 1112 · P 112
(5.23)
 now makes a series of assumptions grouped in four classes, each class corresponding to a
term in (5.23). Specifically, suppose that in ’s view:
•
Given 1 and 1 = s1, 1 is independent of 2; thus
P 1  112 = P 111
Furthermore,
•
1 has a truncated (at zero) Gaussian distribution with mean a+b1 and standard deviation
s1.
As before ab and  reflect ’s view of the biases and attitudes of  in declaring m1 and s1.
•
2 is independent of 1 given 21 = m11 = s1 and 2 = s2	 thus
P 211212 = P 2  1122
•
2 has a truncated Gaussian distribution with mean a + b2 and standard deviation s2;
truncation is on the left and is at the point m1 + ks1, with k specified by .
The parameter k reflects ’s view as to how cautious  is about discriminating between 1
and 2.
•
The distribution of 1 is exponential with mean 2 −1.
This implies that as the disparity between 1 and 2 increases, the measure of scale 1 also
increases.
•
Given 1 = s11 and 2 2 is independent of 1; thus
P 21112 = P 2112
•
2 has a truncated normal distribution with mean s1 and variance 2 −1; truncation is on
the left and is at zero.
The last assumption above implies that 2 has the same mean as 1, but that its variance
depends on the disparity between 1 and 2.
Finally, as was so in the case of MT,  also assumes that P12 is relatively constant
over the range of 1 and 2 on which the likelihood of 1 and 2 is appreciable. That is, ’s
uncertainty about 1 and 2 is vague in comparison with ’s testimony.
With 121 and 2 revealed as m1m2s1 and s2, respectively, the above four probabilities
yield four likelihoods as factorizations of 12	m1m2s1s2. Specifically, P 111

PRIOR DISTRIBUTIONS IN CHANCE DISTRIBUTIONS
141
yields 1	m1s1, P 21122 yields 2	m1m2s1s2, P 112 yields
2 −1	s1, and P 2112 yields 2 −1	s1s2. These likelihoods when mul-
tiplied together yield 12	m1m2s1s2, which with the assumption that P12 is
relatively constant results in (5.21) as the joint prior of 1 and 2. The constants of this prior
are: li = mi −a/b ri = si/b i = 12 n1 = −a/b, and n2 = m1 + ks1 −a/b. The prior
incorporates the dependence between 1 and 2, but it assumes that ’s biases and precision
in declaring 1 and 1 are the same as that for 2 and 2.
Campódonico and Singpurwalla (1994a) illustrate a use of this prior for predicting the number
of software failures using a commonly used Poisson process for describing software failures. In
Campodónico and Singpurwalla (1995) this prior is used for predicting the number of defects in
railroad tracks. In both cases, numerical methods were used and a computer code developed.
5.3.2
Using Objective (or Default) Priors
When the prior distribution is personal to an investigator, that is when the entire distribu-
tion is elicited – as was done in section 5.3.1 – or when the parameters of a suitably cho-
sen distribution are elicited – as was done in section 5.2.1 and 5.2.2, the priors are said to
be subjective. By contrast non-subjective or objective priors are those in which the personal
views of any and all investigators have no role to play. Objective priors are chosen by con-
vention or through structural rules and are to be viewed as a standard of reference. Accord-
ing to Dawid (1997), ‘no theory which incorporates non-subjective priors can truly be called
Bayesian’.
The class of objective priors includes those that claim to be non-informative priors and
those that are labeled ‘reference priors’, though some like Bernardo (1997) maintain that there
is no such thing as a non-informative prior; he claims that ‘any prior reflects some form of
knowledge’. Objective priors are also referred to as ‘default priors’ or ‘neutral priors’. Such
priors have been introduced by us in section 2.7.3 in the context of testing a sharp null hypothesis
about the mean of an exponential distribution, and in section 5.2.3 in the context of Bernoulli
trials. It is often the case that objective priors suffer from impropriety, are dependent on the
probability model that is assumed and could result in posteriors that are also improper (cf.
Casella, 1996). The purpose of this section is to overview the nature of such priors and to discuss
arguments used to rationalize some of their unattractive features. In the sequel, I also present
the kind of improper priors that have been proposed for some of the chance distributions of
section 5.2.
Historical Background
Non-subjective priors were used by default in the works of Bayes (1763) and Laplace (1812).
Bayes used a uniform prior for the Bernoulli  in a binomial setting, and Laplace used an
improper uniform prior for the mean of a Gaussian distribution. During those times no one
considered using priors that were different from the uniform. The rationale was that any prior
other than the uniform would reflect specific knowledge, and in doing so would violate the
principle of insufficient reason. However, in the early 1920s it was felt that the universal use
of uniform priors did not make much sense. For one, a uniform prior on the Bernoulli  does
not imply a uniform prior on 2, and this is tantamount to claiming indifference between all
values of  but a specific knowledge about values of 2. Thus the uniform distribution on 
is not invariant vis-à-vis the principle of insufficient reason. Since most scientists of that day
were reluctant to use personal priors in their scientific work, methods alternate to Bayes’ and
Laplace’s were developed, and were labeled as ‘objective methods of scientific indifference’;
frequentist statistics is one such method. A revival of the Bayes–Laplace paradigm came about
in the 1940s with the publication of Jeffreys (1946), who produced an alternative to the uniform
as a non-subjective prior; this prior is now known as the Jeffreys’ prior.

142
PARAMETRIC FAILURE DATA ANALYSIS
Jeffreys’ General Rule and Jeffreys’ Priors
Jeffreys work started with a collection of rules for several scenarios, each scenario treated sepa-
rately. The simplest is the case of a finite parameter space; i.e.  takes values 12   n, for
n < . He adhered to the principle of insufficient reason and assigned a probability 1/n to each
value of . Jeffreys then considered the case of bounded intervals so that  ∈ab for constants
a<b a≥0 b<. The prior density in this case was taken to be the uniform over ab. When
the parameter space was the interval −+, as is the case for a Gaussian mean, Jeffreys advo-
cated that the prior density be constant over −+. The above priors were in keeping with
Bayes–Laplace tradition of insufficient reason. Note that the second prior results in impropriety,
a matter that did not appear to have been of concern to Jeffreys. When the parameter space is the
interval 0, as is the case with the scale parameter of some well-known chance distributions
like the exponential, the Gaussian and the Weibull, Jeffreys proposed the prior  = 1/. His
justification for this choice was invariance under power transformation of the scale parameter .
That is, if 
 = 2, then by a change of variables technique, it is verified that 
 is of a similar
form, namely 
∝1/
; see Kass and Wasserman’s (1996) comprehensive review of objective
priors. Motivated by considerations of invariance, Jeffreys’ 1946 paper proposes a ‘general rule’
for obtaining priors. For a probability model entailing a single parameter , the prior on  is of the
form
 ∝

EX

− 2
 2 logpX
1/2

(5.24)
where the expectation of X is with respect to the probability model pX.
Jeffreys’ general rule, which yields Jeffreys’ priors, is not based on intervals in which
the parameter lies, and could conflict with the rules based on intervals. For example, when
pX is a binomial, the general rule results in p ∝−1/21 −−1/2 , whereas the rule
based on intervals has p = 1. Interestingly, Jeffreys adhered to the principle of insuf-
ficient reason for priors on bounded intervals and used p = 1 for the Bernoulli  (cf.
Geisser, 1984). When pX is the negative binomial, i.e. when X is the number of tri-
als to the first success in Bernoulli outcomes, so that pX = 1 −x−1, Jeffreys’ gen-
eral rule yields  = −1/21 −−1 as a prior for ; this prior is improper. The Bernoulli
scenario illustrates a feature of Jeffreys’ priors, namely the dependence of the prior on the
model: −1/21 −−1/2 for the binomial, and −1/21 −−1 for the negative binomial. Since
 as the limit of observable zero-one sequences has a physical connotation, namely that 
is a chance (section 3.1.3), dependence of the prior for  on the model for X makes lit-
tle sense.
An extension of Jeffreys’ general rule – equation (5.24), when  = 12 is a vector, takes
the form
 ∝detI1/2
where det• denotes a determinant, and I is the matrix
I = EX

−
 2
 1 2
logpX


(5.25)
Jeffreys observed that the results of this rule could also conflict with the results provided
by the rule based on intervals. For example, with pX12 a Gaussian with mean 1 and
variance 2
2, the general rule gives 12 ∝1/2
2, whereas the rule based on intervals gives
12 ∝1/2; similarly for the lognormal with parameters 1 and 2
2. Jeffreys addressed this
problem by stating that 1 and 2 should be judged independent a priori and the general rule

PRIOR DISTRIBUTIONS IN CHANCE DISTRIBUTIONS
143
applied for 1 given 2 fixed and for 2 given 1 fixed. Thus with 2 fixed, the general rule gives
a uniform prior for 1 and with 1 fixed the general rule gives 2 = 1/2. It is because of the
above that many view Jeffreys’ priors as a collection of ad hoc rules.
Reference Priors: The Berger–Bernardo Method
Prompted by the above concern, and motivated by some work of Good (1966) and Lindley
(1956), Bernardo (1979a) proposed a method for constructing objective priors that he labeled
‘reference priors’. Like Jeffreys’ priors, the reference priors also depend on the underlying
probability model. However, the rationale for this dependence is more transparent in the case of
reference priors than in the case of Jeffreys’ priors. To see why, we first note that Bernardo’s
method is based on the notion of ‘missing information’, a notion that is characterized by the
Kullback–Leibler distance between the posterior and the prior densities. Specifically, for a
prior  and its posterior 	xn, the Kullback–Leibler distance is defined as
Kn

	xn

=


	xnlog
	xn


d
where xn is a realization of Xn = X1   Xn, and the Xis are independent and identically
distributed with pX as a probability model. The quantity Kn • is to be interpreted as the
gain in information about  provided by the experiment that yields xn, and K
n •=EKn • is
the expected gain in information. The expectation is with respect to the predictive distribution
of Xn; i.e.
pXn =

pXnd	
more about this is said later, in section 5.5.1. Bernardo’s idea was to find that  for which
K
 •= lim
n→K
n • is a maximum; the rational here being that K
 • is a measure of the missing
information in the experiment. However, there is a problem with this scheme, in the sense that
K
 could be infinite. To circumvent this difficulty, one finds the prior n which maximizes
K
n •, and computes a posterior based on this n. One then finds the limit of the sequence of
posteriors based on n; denote this limit by 	xn. Then the reference prior is that prior
which by a direct application of Bayes’ law would yield 	xn (Berger and Bernardo, 1992).
Under certain regularity conditions, the reference prior turns out to be that given by (5.24) and
(5.25) for continuous parameter spaces, and a uniform prior for finite parameter spaces. Thus the
aforementioned approach, now known as the Berger–Bernardo method (cf. Kass and Wasserman,
1996), provides, at least under some regularity conditions, a rationale for the construction of
Jeffreys’ priors. Consequently, the reference prior for the Bernoulli  under binomial sampling
is −1/21 −−1/2, and it is −1/21 −−1 under negative binomial sampling. For  uniform
on 0, the reference prior turns out to be  ∝−1, and the reference posterior, i.e. the
posterior distribution resulting from a reference prior, is a Pareto distribution (Bernardo and
Smith, 1994, p. 438).
When the chance distribution is a Weibull with scale parameter  and shape parameter , the
reference prior turns out to be  = −1, whereas Jeffreys’ rules would lead to the prior
1/ (cf. Berger and Pericchi, 1996). With the exponential as a chance distribution, the parameter
 is one, so that  = 1/ is both the reference and the Jeffreys’ priors.
To complete our discussion of the Weibull distribution, I cite here the work of Sun (1997)
and that of Green, et al. (1994), who considered the case of a three-parameter Weibull chance
distribution with a threshold parameter . Specifically,
PT > t = exp

−t −


 for  > 0

144
PARAMETRIC FAILURE DATA ANALYSIS
This distribution is deemed appropriate where T has to be logically strictly greater than zero, as
is the case with diameters of tree trunks. In the context of reliability and survival analysis, a use
of the three-parameter Weibull precludes the possibility of an item’s failure at conception. The
authors cited above, and also Sinha and Sloan (1988), assume that the three parameters are a
priori independent, and assign 1/ and 1/ as priors for  and , respectively. The prior for 
is assumed to be a constant over 0. Whereas the choice 1/ can be justified on the grounds
that it is Jeffreys’ prior, the choice 1/ for the prior on  is unconventional. All the same, the
novelty of Green et al. is the consideration of a Bayesian analysis of threshold parameters,  in
this particular case.
When the chance distribution is Poisson, then reference priors for the mean value function of
the underlying Poisson process can be induced from the reference priors for the parameters of the
distribution of the time to occurrence of the first event in the Poisson process. Thus, for example,
if the underlying Poisson process is homogenous with a mean value function t = t/, then
PT > t   = exp−t/, and the reference prior on t induced from the reference prior on ,
namely, 1/, is t = 1/t. Similarly, with t = exp−t/, though the calculation
of t in this case would be more cumbersome.
Reference priors have several attractive features, namely, invariance under one-to-one transfor-
mations, enable the data to play a dominant role in the construction of the posterior distribution
and generally produce posterior distributions that are proper. More important, under some reg-
ularity conditions, the reference priors coincide with Jeffreys’ priors, the latter having been
justified from many different viewpoints (question 20 of Bernardo, 1997). Their main disadvan-
tage is impropriety and dependence on the underlying probability model. The latter tantamounts
to a violation of the likelihood principle. On the matter of impropriety, Bernardo’s claim is that
non-subjective priors should not be viewed as probability distributions. Rather, they should be
viewed as positive fractions which serve to produce non-subjective posteriors via a formal use of
Bayes’ law. The non-subjective posteriors, namely the reference posteriors, are to be used as a
benchmark or a standard for performing a sensitivity analysis against other, possibly subjective
priors; see answers to questions 7 and 23 in Bernardo (1997). It is crucial that reference posteriors
are proper and their main purpose is to describe the inferential content of the data in scientific
communication. Reference posteriors need not be used in betting or other scenarios of personal
decision making because such posteriors may not be an honest reflection of ‘personal beliefs’.
Other Methods for Constructing Objective Priors
Kass and Wasserman (1996) describe several other methods for constructing non-subjective
priors. Noteworthy among these are the maximum entropy priors of Jaynes reviewed by Zellner
(1991) and by Press (1996), Zellner and Min’s (1993) maximal data information prior, priors of
Chernoff (1954) and Good (1969) based on decision-theoretic arguments, priors based on game
theoretic arguments of Kashyap (1971), the prior by Rissanen (1983) based on coding theory
arguments, and a class of improper priors by Novick and Hall (1965) called ‘indifference priors’.
For the case of the Bernoulli , Novick and Hall’s indifference prior turns out to be 1−−1,
which is improper but which induces a proper posterior as soon as one trial is performed. Several
of the above methods boil down to being the methods of Jeffreys.
5.4
PREDICTIVE DISTRIBUTIONS INCORPORATING FAILURE DATA
I consider here the general set-up of (5.4) and (5.7), where I recall that 
n = 1   n, and
that i is the realization of Ti, the lifelength if the i-th item. The vector 
n constitutes one
form of the observed failure data. But failure data can also be had in other forms, for example
survival times, wherein all that the analyst has is knowledge of the fact that Ti was greater than

PREDICTIVE DISTRIBUTIONS INCORPORATING FAILURE DATA
145
some ∗
i . A knowledge of survival times is common in the bio-medical set-up wherein subjects
have a tendency to drop-off an observational study, or when the study itself is terminated at
some time say ∗. The same can also be true in scenarios involving industrial life-testing for
quality control purposes. Conversely, failure data can also be had in the form Ti < ∗∗
i ; that is,
the analyst has knowledge of the fact that the i-th item had failed by time ∗∗
i , but is not aware
of the exact time of failure. This scenario is prevalent in industrial settings involving inspection
and maintenance at times ∗∗
i , i = 1   n. Thus, by the generic term ‘failure data’, I mean to
include observations of the kind Ti = i, or i > T ∗
i , or Ti < ∗∗
i , i = 1   n. Often failure data
is also had in terms of outcomes of Bernoulli trials so that Xi = xi, with xi = 1 if Ti > ti and
xi = 0 otherwise, for some fixed ti, i = 1   n.
How is failure data obtained? Most often it is reported from field experience. For example, data
on the failure of automobile parts is reported to the manufacturer by the automobile dealers, who
in turn receive this information from the user or from maintenance and repair shops. Similarly,
in the bio-medical scenarios wherein doctors and hospitals report survival and failure histories
to drug manufacturers, such data are called retrospective failure data. However, failure data
can also be obtained from carefully controlled and well-designed experiments called clinical
trials in the bio-medical set-up, and life-testing in the industrial set-up. Clinical trials entail tests
on human subjects and are therefore complicated to discuss because they involve ethical and
moral issues (cf. Kadane and Sedransk, 1979). By contrast industrial life-testing involves tests
on physical units and is thus devoid of moral issues; it is therefore easier to discuss. The same
is also true of drug testing on non-human subjects such as mice and monkeys – though this too
could be a moral issue! In what follows I overview some of the most commonly used design
strategies for industrial life-testing and their relevance for assessing predictive distributions based
on the data they produce.
5.4.1
Design Strategies for Industrial Life-testing
The best way to learn about the credible performance of an item is via retrospective data.
However, for newly designed items such data are not available and so we need life-testing
experiments. Such experiments provide information via failure data and this enables us to make
more realistic assessments of an item’s reliability. Such assessments are used for designing
systems comprising the units in question, for satisfying safety requirements, or for meeting
contractual obligations via acceptance sampling.
Life tests are generally conducted under tightly controlled conditions involving environmental
stresses that are constant during the test or which change over time, either according to a specified
pattern or randomly. The former are called constant stress tests and the latter, dynamic stress
tests. Tests involving environmental conditions that change with time according to a specified
pattern could be of several types: continuously increasing stress, step-stress or cyclical stress;
Figure 5.2 illustrates the nature of these patterns.
With a continuously increasing stress test, we monitor the lifelength of an item that is subjected
to a stress whose intensity increases with time in a manner illustrated by Figure 5.3(a). With step-
stress test, the stress on an item is increased in steps at several pre-specified times s1s2   , until
the item fails or the test is stopped; this is illustrated in Figure 5.3(b). Figure 5.3(c) illustrates a
cyclical stress that is sinusoidal. Such stress patterns are suitable for items experiencing vibrations
due to rotation or other periodic phenomena. When the change in stress over time is random, the
stress–time plots of Figure 5.3 will be the sample path of a stochastic process.
It is often the case that continuously increasing and step-stress tests are conducted to produce
early failures of items that are highly reliable. For such items, obtaining failure times under
conditions in which they are designed to operate would entail long waits. Therefore such tests
are a form of accelerated life tests, though most often accelerated tests entail the testing of items

146
PARAMETRIC FAILURE DATA ANALYSIS
Stress
Time
0
(c) Cyclical-stress (sinusoidal)
Stress
Time
0
(a) Continuous increasing
Stress
Time
0
S1
S2
(b) Step-stress
Figure 5.3
Controlled dynamic stress patterns.
under a constant but elevated (from the design) stress. The opposite of accelerated testing is
decelerated testing. This form of testing entails collecting lifelength information (be it failures or
survival) at low stresses to assess lifelength behavior at higher stresses. Little has been written
on this topic and the assessment methodology here entails the use of some physical models of
degradation together with expert testimonies (Singpurwalla, 2005).
With the above appreciation of the environmental conditions under which life tests can be
conducted, the next matter pertains to the statistical aspects of the testing strategies. The simplest
testing scenario is the one involving item censoring, also known as Type II censoring. Here
n items are put on a test, and the test is stopped when the r-th item fails. Both n and r are
specified in advance, and the r times of failure 1   r are noted; when r = n, the test is
terminated when all the n items on test fail. The choice of n and r is an important matter and
involves a trade-off between the cost of testing and the utility of the added knowledge obtained
via the test. With Type I censoring, also known as a time truncated life test, n items are put
on test, and the test is stopped at some pre-specified time t. The number of observed failures,
k k = 01   n and the times of these k failures 12   k are noted; here k is random.
Once again the choice of n and t entails a trade-off between the costs of testing and the added
knowledge provided by the test. It is important to bear in mind that the added knowledge need
not necessarily result in the reduction of uncertainties about lifetimes. It could happen that the
results of a life-test could increase our uncertainties. There are other types of life-tests, such as
a combination of Type I and Type II censoring, wherein n items are put on test and the test is
stopped at time t or at time r, the time of the r-th failure, whichever comes first.
In the context of life-testing, there is an important issue that arises, namely the relevance of
the design of the life-test to an assessment of the predictive distribution. Specifically, given a
collection of failure times, say 1   u, does it matter whether these data were obtained under

PREDICTIVE DISTRIBUTIONS INCORPORATING FAILURE DATA
147
Type I censoring, or Type II censoring, or a combination of Type I and Type II censoring? In
other words, does the ‘stopping rule’ – which is a prescription of when to stop the test – matter?
If it does matter, then how can one proceed with the analyses of retrospective data wherein it
is rare, if not impossible, to know what the stopping rule was? My claim is that, in general,
the stopping rule does not matter. However, there are certain circumstances wherein it does
matter; these are encapsulated under the label ‘informative stopping rules’. By contrast, under
the frequentist or sample theoretic paradigm, the stopping rule almost always has a role to play.
In what follows I introduce the notion of a stopping rule and describe the conditions under which
it is informative and deal with what it means to say that a stopping rule is noninformative.
5.4.2
Stopping Rules: Non-informative and Informative
The rule by which the sample size is determined is called a stopping rule. It is expressed as
the probability that sampling continued as long as it did and then stopped based on the stopping
rule. The said probability can be conditional on the parameters of the underlying probability
model and/or the values of the observations already made. The stopping rule plays an important
role when inference is based on the sample-theory approach. Specifically, point and interval
estimation and tests of hypotheses depend on the stopping rule, because it is the latter which
determines the sampling distribution. By contrast, under Bayesian inference, the role of the
stopping rule needs to be carefully explored to ensure whether it is relevant or not. The above
difference is best appreciated via the case of Bernoulli trials.
Suppose that r successes have been observed in n Bernoulli trials, with  as the probability
of success of each trial. Then the likelihood for  with n fixed and R = r as the observable is
binomial, whereas it is negatively binomial if r is fixed and N = n is observed. Specifically, the
likelihoods for the binomial and the negative binomial cases are
n
r

r1 −n−r and
n −1
r −1

r1 −n−r,
respectively. The probability models that generate these likelihoods are different, and conse-
quently the sampling distributions for the two scenarios are different. The result is that sample-
theory-based inferences for  under the two models will not be alike. For example, the minimum
variance unbiased estimate of , under binomial sampling, is r/n whereas that under negative
binomial sampling is r −1/n −1. By contrast, under the Bayesian approach, inference for 
will be the same, no matter how the r and n were obtained. This is because the stopping rules
for the two protocols which yield the observable data are non-informative.
To appreciate this notion I start by considering the probability model for a sequence of exactly
n Bernoulli trials, X1   Xn, conditional on the parameter  and a nuisance parameter , where
PXi =1  = i=1   n; I denote this probability by PX1   Xn  . The model has
two components: one for the process that generates the realizations of each Xi and the other for
the process which enables us to conduct the actual trials. Specifically, let P1   denote the
probability that a first trial (leading to an outcome X1) will be performed; the nuisance parameter
 is associated with the probability model for the decision to perform a trial. In general, let
Pk + 1  X1   Xk denote the probability that one more trial will be performed after
the k-th trial. Then,
P X1   Xn   = P1  PX1   · P2  X1PX2  X1  
   Pn  X1   Xn−1 · PXn  X1   Xn−1
·1 −Pn + 1  X1   Xn

148
PARAMETRIC FAILURE DATA ANALYSIS
Since Xi is independent of Xi   Xi−1 and , given ,
PX1   Xn   =
n
i=1
PXi  QnXn
where
Q

n  Xn

= P1   · P2  X1   Pn  X1   Xn−1
· 1 −Pn + 1  X1   Xn
Consequently, once the X1   Xn have been observed as x1   xn, respectively, then
	xn, the likelihood generated by PX1   Xn for a fixed xn = x1   xn is


	xn
=
n
i=1
	xi · 	nxn
= r1 −n−r · 	nxn
(5.26)
where r =
n
1
xi. Thus the likelihood for  (and ) given by the sample x1   xn factors into
two parts, one part pertaining to the process that generates each xi via the term r1 −n−r and
the other pertaining to the process that causes us to stop at the n-th trial, namely the stopping rule,
via the term 	nxn. The quantity QnXn with Xn =X1   Xn is called the
stopping probability.
Suppose now that the stopping probability is independent of , given Xn and . Then
Qn  Xn = Qn  Xn, and consequently 	nxn = 	nxn. This means
that the factor 	nxn of the likelihood (5.26) will be constant in  and will have no
effect on it. Consequently, the likelihood for  will depend only on r1 −n−r. In such cases,
the stopping rule is said to be non-informative for . The same is also true if  and  are a priori
independent. Otherwise the stopping rule is said to be informative.
In the context of Bernoulli trials, were n is fixed by an act of free will, then exactly n trials
will be conducted so that
Pk + 1  X1   Xk =
1 if k < n and
0 if k ≥n	
consequently, 	nxn = 1, a constant. Similarly, were r fixed by an act of free will
Pk + 1  X1   Xk =
⎧
⎪⎨
⎪⎩
1 if
kXi < r and
0 if
kXi ≥r	
and here again 	nxn = 1.
Thus under either scenario, n fixed or r fixed,
	xn = r1 −n−r · 1
and Bayesian inference for  is independent of the stopping rules, these being non-informative
about . The essence of the above development is the feature that with Bayesian inference for

PREDICTIVE DISTRIBUTIONS INCORPORATING FAILURE DATA
149
the Bernoulli , a knowledge of the stopping process is not essential. Whereas non-informative
stopping rules appear to be the norm, there are scenarios involving informative stopping rules;
examples are in Raiffa and Schaifer (1961) and in Roberts (1967).
Suppose that instead of being given the actual sequence x1   xn, we were only told that
n trials resulted in r successes. Then the development proceeds along lines parallel to those
leading to (5.26), with the resulting likelihood still being r1−n−r ·1. However, if in addition
to n and r, we were also told that n was fixed in advance, the resulting likelihood will be
n
r

r1 −n−r · 1. But Bayesian inference about  is not affected by the constant
n
r

, which
cancels out with an application of Bayes’ law. Specifically,
 	nR = r =
n
r

r1 −n−r
 n
r

r1 −n−rd
=
r1 −n−r

r1 −n−rd
Similarly, for the case of r fixed in advance wherein the constant preceeding r1 −n−r is
n−1
r−1

.
In general, with non-informative stopping rules, the constants associated with the stopping
rule – such as 1 in the case of Bernoulli trials – and those associated with the data-generating
process – such as
n
r

or
n−1
r−1

– combine and then cancel out with an application of Bayes’ law.
The resulting inference is therefore not affected by such constants. In what follows, I illustrate
the workings of the aforementioned by considering the scenarios of life-testing for reliability
assessment. However, to do so, it is helpful to introduce an important statistic, namely the ‘total
time on test statistic.’
5.4.3
The Total Time on Test
With life-testing involving the continuous monitoring of lifetimes, the notion of the total time
on test plays a key role, in the case of both Bayesian and non-Bayesian inference. To appreciate
this, consider the case of Type II censoring, wherein n items are put on some carefully controlled
and well-designed life-test that is terminated at the time of the r-th failure. Both n and r are
specified in advance and the r times of failure 1 ≤2 ≤··· ≤r are noted. Then, the total
time on test, say Tnr, is defined as
Tnr = n1 + n −12 −1 + ··· + n −r + 1r −r−1
=
r
1
i + n −rr	
it is the total lifetime of all the n units on test, starting from time zero, until time r, the time to
failure of the r-th item. Observe that when r = n, Tnn =
n
1
i, the sum of the lifetimes of
all the n units.
Similarly, with Type I censoring wherein n items are put on a test that is terminated at some
time t, with n and t pre-specified, and k failures observed at 1 ≤2 ≤··· ≤k, the total time
on test, Tnt, is
Tnt =
n
1
i + n −kt −k	

150
PARAMETRIC FAILURE DATA ANALYSIS
here k is random. When k = n, Tnt is simply the sum of lifetimes
n
1
i. When each item
has its own truncation time ∗
i , i = 1   n, then Tn∗
1   ∗
n the total time on test is
n
1
T1∗
i , where
T1∗
i  =
i if Ti ≤∗
i
∗
i  if Ti > ∗
i 	
i is the realization of Ti, the lifelength of the i-th item. When the test truncation times ∗
i are
ordered, so that ∗
1 ≤∗
2 ≤··· ≤∗
n , the Type I censored life-test is said to be progressively
censored, and if the ∗
i s are themselves random we have the case of random censoring. Inference
under random censoring would entail the specification of a probability model for censoring.
Finally, if the life-test is a combination of Type I and Type II tests, also known as hybrid
testing, the total time on test Tnrt is given by
Tnrt =
Tnr if Tr ≤t
Tnt if Tr > t	
the quantities n, r and t are pre-specified.
Thus, no matter what testing protocol and censoring schemes are specified, a total time on
test for the life-testing experiment can be easily specified. The total time on test statistic also
plays a key role in the mathematical theory of reliability. For example, Barlow and Campo
(1975) use it to assess the failure rates of chance distributions used in reliability and Chandra
and Singpurwalla (1981) relate it to notions of income inequalities in economics. I now show
that for Bayesian inference about parameters of chance distributions used in reliability all that
we need to know is the total time on test; we need not know the actual failure and survival times,
nor do we need to know the censoring protocols, unless of course they are informative.
5.4.4
Exponential Life-testing Procedures
Suppose that the underlying chance distribution is assumed to be an exponential with PT >
t  
 = exp−
t (section 5.2.1) so that (5.4) takes the form
PTn+1 ≥tn+1	• =


exp−
tFd
	•
with • denoting data from a life-test, and
Fd
	• ∝
	•Fd
	
(5.27)
see equation (5.5). Depending on the testing protocol and censoring scheme used, the data
from the life-test could arrive in one of several forms discussed in section 5.4.3. For example,
under Type II censoring with n and r fixed, we would observe the r ordered failure times
1 ≤2 ≤··· ≤r, and the likelihood of 
, 
	•, would be of the form

	• =
n!
n −r!
r
i=1

e−
ie−
n−rr
=
n!
n −r!
re−
Tnr
(5.28)

PREDICTIVE DISTRIBUTIONS INCORPORATING FAILURE DATA
151
where Tnr is the total time on test. This likelihood is a consequence of the fact the stopping
rule for the test is non-informative – an issue than can be verified using the same line of argument
used for the case of Bernoulli testing with n and r specified (section 5.4.2) and the fact that a
probability model for the first r order statistics T1 ≤T2 ≤··· ≤Tr of T1  Tn has density
at 1 ≤2 ≤··· ≤r of the form
n!
n −r!
r
i=1
fi  
PT > i  
n−r
(5.29)
where the Tis are independent (given 
) and identically distributed with distribution PT ≥t  

whose density at t is ft  
. The order statistics of a collection of random variables T1   Tn is
an ordering of these random variables from the smallest to the largest, so that T1 ≤T2 ≤···≤Tn;
thus T1 = min
i
Ti and Tn = max
i
Ti. When r = n, (5.29) simplifies as n!
n
1
fi  
, implying that
the ordering of (conditionally) independent random variables renders them dependent.
Under Type I censoring, with t specified by free will, the stopping rule is again non-informative,
and the likelihood of 
 for an observed k (the number of failures), and 1 ≤2 ≤··· ≤k ≤t
is of the form

	• =
n!
n −k!
k
i=1

e−
ie−
n−kt−k
=
n!
n −k!
ke−
Tnt
(5.30)
where Tnk is the total time on test. The line of reasoning used to obtain (5.28) is also used
here, except that now we need to consider the joint distribution of the first k order statistics out
of n.
When censoring is a combination of Type I and Type II, the likelihood will depend on whether
r ≤t or r > t. In the first case it will be the product of the right-hand side of (5.28) and
the probability that Tr ≤t, which is the distribution function of the r-th order statistic. In the
second case, it will be the product of the right-hand side of (5.30) and the probability that Tr >t.
Specifically, with hybrid testing, 
	• will take the form:

n!
n −r!
re−
Tnr

n
i=r
n
i

1 −e−
ti 
e−
n−it

 if t ≤t
and for r > t, with k < r failures observed by t, it will be

n!
n −k!
ke−
Tnt

r−1

i=0
n
i

1 −e−
ti 
e−
n−it


(5.31)
With retrospective data it is often the case that the censoring rule is not known, and all that
we have at our disposal is n,the number of items under observation, the ordered times to failure
1 ≤2 ≤··· ≤k, and now the time, say t; i.e. t is the time at which observation on the
failure/survival process is terminated. The stopping rule will be non-informative as long as t was
chosen at free will, or it was determined by either k or by 1 ≤2 ≤···≤k. That is, t should
not depend on 
. When such is the case, the likelihood for 
 is that given by (5.30), so that with
a Bayesian analysis all that matters is Tnt, the total time on test; similarly with the case of
progressive censoring.

152
PARAMETRIC FAILURE DATA ANALYSIS
In the context of life-testing the role of informative stopping rules becomes more transparent
via the scenario of random censoring. To see how, consider the case of a single item whose
lifelength T has the exponential chance distribution considered. Suppose that the choice of testing
a single item (to failure or until it gets censored) is done by free will. Now suppose that the
censoring time Y is random with PY > t   having a density gt   at t. Observation on the
item stops when the item fails or gets censored. The parameter of interest is 
, the one associated
with lifelength T;  is a nuisance parameter. Then, the likelihood for 
, were the item to fail
at t, will be governed by the probability 
e−
t · PY > t  , whereas it is governed by the
probability e−t · PT > t  
 if the item were censored at t. The first term of the above two
likelihoods define the stopping rule, which in the second case will be non-informative for 
, if 
and 
 are independent; it will be informative if  = 
 or if  depends on 
. As a special case of
the above, suppose that Y is also exponential with a scale parameter ; i.e. PY > t   = e−t.
Then the said likelihoods are 
e−t
+ and e−t
+, respectively; t is the total time on test.
With n items under observation, where n is chosen by free will, the likelihood will be the
product of the above two likelihoods, the first for every item that fails and the second for every
item that gets censored. Thus, for example, suppose that of the n items under test, k experience
a failure at times 12   k, and the remaining n −k get censored at times ∗
k+1   ∗
n.
Then, the likelihood of 
 and  is

kn−k exp

−
 + 

k
i=1
i +
n
j=k+1
∗
j


where
 k
i=1
i +
n
j=k+1
∗
j

is the total time on test.
If  and 
 are independent then the stopping rule given by the censoring times is non-
informative for 
, and the term  (total time on test) cancels out as a constant in an application
of Bayes’ law. Thus the part of the likelihood that is germane to inference about 
 is

k exp

−

k
i=1
i +
n
j=k+1
∗
j


(5.32a)
If  = 
, the likelihood is

n exp

−2

k
i=1
i +
n
j=k+1
∗
j


(5.32b)
and the stopping rule contributes to inference about 
; it is therefore informative.
In any case, the role of the total time on test for inference about 
 is central with regard to all
the censoring schemes discussed by us.
Going back to where we left off with (5.27), suppose that Fd
 is the gamma density with
a scale parameter  and a shape parameter , where  and  are elicited via the approach
prescribed in section 5.2; thus
Fd
 = 
−1e−


(5.33)
Then for 
	· given by (5.28) – the case of Type II censoring – it is straightforward to
verify that the posterior for 
 is also a gamma density with a scale parameter  + Tnr and
a shape parameter  + n; i.e.
Fd
	• =  + Tnr+n
+n−1e−
+Tnr
 + n

(5.34)

PREDICTIVE DISTRIBUTIONS INCORPORATING FAILURE DATA
153
Consequently, E
	• =  + n/ + Tnr, the role of n and Tnr being to change the
mean of 
 from / to that given above.
Similarly, with Type I censoring, when 
	• is given by (5.30), the gamma prior on 
results in a gamma posterior for 
 of the same form as (5.34), but with Tnr replaced by
Tnt. In general, the above result will also hold when the observed failure data is retrospective,
or the testing is progressive, or the censoring is random and non-informative; all that matters is
a use of the appropriate total time on test statistic. The only exception is the case of informative
censoring wherein the likelihood will entail additional terms involving 
. In the case of hybrid
censoring, it can be verified (cf. Gupta and Kundu, 1998) that the likelihood (equation (5.31))
can also be written as
n!
n −r∗!
r∗exp−
S
(5.35)
where r∗is the number of units that fail in 0t∗, with t∗= minrt and S the total time on
test is
S =
r∗
i=1
i + n −r∗t∗ if r∗≥1
= nt
if r∗= 0
This form of the likelihood parallels that of (5.28) and (5.30), and thus with hybrid testing a
result of the form given by (5.34) continues to hold with Tnr replaced by S.
Once Fd
	• is assessed, it can be used in (5.4) and (5.7) to provide predictions of future
lifetimes. Furthermore, since 
 is the model failure rate of PT>t  
, (5.34) provides inference
about 
, should this be of interest. Specifically, from (5.4), we can derive the result that
P Tn+1 ≥tn+1	• =

 + Tnr
 + Tnr + tn+1
+n
and from (5.7) the result that
P Tn+1 ≥tn+1   Tn+m ≥tn+m	• =

 + Tnr
 + Tnr + t∗
+n

where t∗=
m
i=1
tn+i. Both the predictive distributions are Pareto, the former indexed by tn+1, the
latter by t∗. Indexing by t∗suggests that in the scenario considered here, what matters is t∗,
the total horizon of prediction. The individual times tn+1   tn+m do not matter; only their
sum does. This feature can be seen as a manifestation of the lack of memory property of the
exponential distribution and will always be true, irrespective of the prior distribution 
 that
is used.
Instead of assigning the gamma prior distribution Fd
	 on 
 (equation (5.33)) one may
prefer to assign a prior distribution on 1/
def
= , the mean time to failure. A possible choice is
the inverted gamma distribution with parameters  and ; here for  > 0,
Fd	 = −+1 exp−/


The mean and variance of this distribution are / −1 and 2/ −12 −2; these exist
only if  > 2. With this choice for a prior, it can be seen that (5.12) will continue to hold and

154
PARAMETRIC FAILURE DATA ANALYSIS
that the predictive distribution of Tn+1 is precisely the same Pareto distribution obtained when
the prior on 
 was a gamma distribution; i.e.
P Tn+1 ≥t	• =

 + Tnr
 + Tnr + t
+n

This is because a gamma prior on 
 induces an inverted gamma prior on , and coherence of
the probability calculus will ensure that the predictive distribution remains the same.
There are some other interesting features about the choice of the inverted gamma prior
on . The first thing to note is that E Tn+1	•, the mean of the predictive distribution is
 + Tnr/ + n + 1 – the mean of a Pareto with parameters  + Tnr and  + n.
Consequently, were there to be no failure data under this set-up, both Tnr and n will not
be there so that E Tn+1	, the mean of the predictive distribution will be / −1. But
/ −1 is the mean of the inverted gamma prior on . Thus here we have the curious result
that in the absence of any life-testing data, the mean of the prior and the predictive distributions
are identical, provided that they exist; i.e. provided that  > 1.
This completes our discussion on inference and predictions using an exponential chance dis-
tribution assuming various informative and non-informative censoring schemes. In principle, the
case of the gamma and the Weibull distribution, or for that matter any other chance distribution,
will follow along similar lines, the main difficulty being an assessment of multi-dimensional
parameters and the computational issues that such matters will entail. Here the total time on test
statistic will no more play the central role it plays in the case of the exponential distribution,
and expressions having the closed form nature of (5.34) are hard to come by. In section 5.4.5
the nature of these difficulties via the case of the Weibull distribution is illustrated. However,
before doing so I need to draw attention to the following important point about assessing chance
distributions.
Estimated Reliability – An Approximation to the Predictive Distribution
I start by drawing attention to the feature that what has been discussed thus far pertains to a
coherent assessment of predictive distributions, and the parameter 
 of the underlying exponential
chance distribution exp−
t. The coherent assessment of this chance distribution itself, namely
the reliability function, has not been mentioned. This may seem strange because much of the
non-Bayesian literature in reliability and life-testing focuses on estimating the reliability function.
Why this omission?
Our response to the above question is that in practice, what matters is assessing predictive
distributions of observable quantities like T, and not the predictive distribution of T conditioned
on unobservable parameters like 
, which is what the reliability function is. However, if for some
reason – for instance section 6.2.3 – an assessment of a chance distribution is still desired, then
the best that one can hope to do is to replace 
 by E
	•, the mean of its posterior distribution.
It is important to note that there is no rule of probability that justifies this step. The closest that
comes to a rationale is that exp−E
	•t is an approximation to the predictive distribution
of T. Specifically, by an infinite series expansion of exp−E
	•t and of exp−
t, we can
verify that the predictive distribution of T


0
exp−
tFd
	• ≈exp−E
	•t
Thus our proposed estimate of the reliability function can be seen as a surrogate for the predictive
distribution of T.

PREDICTIVE DISTRIBUTIONS INCORPORATING FAILURE DATA
155
5.4.5
Weibull Life-testing Procedures
Suppose that PT > t
 = exp−
t, for 
 > 0 and t ≥0, and to keep matters simple
we focus attention on the case of Type II censoring. Thus given the r ordered failure times
1 ≤2 ≤··· ≤r, the likelihood of 
 and  is

	• =
n!
n −r! 
r exp
 
−

r
i=1

i + n −r
r
!
r
i=1

i
(5.36)
which when re-parameterized as 
	• with 
 = −, and when multiplied by a prior such
as that given by (5.9) yields a posterior Fd
d	•. This posterior when used in (5.4) and
(5.7) provides predictions of future lifetimes. The computational challenge that such a scenario
involving the integral of a non-linear function of the parameters is daunting. The situation is
no better if other forms of censoring were to be considered or even with the absence of any
censoring. The material in Singpurwalla (1988b), which is based on a conventional numerical
perspective, provides a feel of the ensuing difficulties. It is because of such obstacles that some
Bayesians have abandoned a use of proper, subjectively induced, priors and have then appealed to
computer-intensive approaches such as simulation by the Markov Chain Monte Carlo (MCMC)
(cf. Upadhyay, Vasishta and Smith, 2001). The practical importance of such methods mandates
that some of these be overviewed and this is done in the appendix; the remainder of this section
is devoted to an application of the MCMC method to the scenario at hand. Readers interested in
a better appreciation of the material that follows are urged to first consult Appendix A.
Inference for the Weibull via MCMC
In the interest of generality, suppose that the Weibull chance distribution considered here has
three parameters, with  as a threshold; recall (section 5.3.2) that this was the model considered
by Green et al. (1994). Suppose further, that in (5.36), n = r so that there is no censoring;
from an MCMC point of view this is no more a limitation (Appendix A). Then, with the
re-parameterization 
 = −, the likelihood of (5.36) becomes
n
n
n


i=1

i −
 exp

n
i=1
i −



(5.37)
so that with the joint prior Fddd ∝−1 of Green et al. (1994) (also Sinha and Sloan,
1988), the posterior is proportional to
n−1
n+1
n


i=1

i −
−1 exp

−
n
i=1
i −



(5.38)
We need to emphasize that the prior mentioned above is improper, and from a purely subjective
Bayesian point of view, it should not be entertained. Besides convenience, its virtue is that
it facilitates a straightforward application of the Gibbs sampler; my aim in introducing this
development is to ensure completeness of coverage.
The full conditionals generated by the posterior of (5.38), with  = 1   n, can be
written as:
p	 ∝
1
n+1 exp

−
n
i=1
i −




156
PARAMETRIC FAILURE DATA ANALYSIS
p  	 ∝n−1
n
n


i=1

i −
 exp

−
n
i=1
i −


 and
p  	 ∝
n


i=1

i −
−1 exp

−
n
i=1
i −



Generating random samples from the first of the above three conditionals is straightforward, since
p  	 is, de facto, a gamma density. Generating random samples from p  	 is
via a procedure due to Gilks and Wild (1992), whereas those from p  	 is via a scheme
proposed by Upadhyay, Vasishta and Smith (2001). This latter paper is noteworthy because it
illustrates the above approach by considering some data on the fatigue life of bearings.
To conclude, the success of the Gibbs sampling approach for analyzing failure-time data
assumed to be meaningfully described by a Weibull chance distribution depends on a key feature,
namely the use of a prior that facilitates a generation of random samples from the conditionals
of the posterior.
5.4.6
Life-testing Under the Generalized Gamma and the Inverse Gaussian
The generalized gamma, as a chance distribution, was introduced in section 5.2.5. This distri-
bution is attractive because it encompasses the exponential, the gamma, the Weibull and the
lognormal as special cases. Thus, in principle, a Bayesian analysis of life-test data under the aegis
of the generalized gamma would be very encompassing. However, the subjective assessment of
a joint prior on the four parameters of this distribution is a demanding task. Furthermore, even
if the above were to be meaningfully done, the computational challenge would pose a serious
obstacle. It is because of the above reasons that Upadhyay, Vasishta and Smith (2001) consider
the following three-parameter version of this distribution with density at t of the form


t−1
 exp

−
 t


 for t > 0  > 0
and assign the following independent priors:
p ∝1

p ∝a1b1 and
p ∝a2b2 where
ab denotes a gamma density with shape parameter a and scale parameter b. Assuming a
complete (uncensored) sample of size n from this distribution, the likelihood can be written
out in a straightforward manner, and this when multiplied by the above prior yields a posterior
whose full conditionals, for  = 1   n, are:
p	 =
1
n!+1 exp

−
n
i=1
i



p  	 = n+a1−1
n!
n


i=1
!
i exp

−


b1
+
n
i=1
i


 and
p	 =
 1

n a2−1
n!
n


i=1
!
i exp

−
 
b2



PREDICTIVE DISTRIBUTIONS INCORPORATING FAILURE DATA
157
Generating random samples from the first of the above three conditionals is straightforward
because the distribution is de facto a gamma. For the other two conditionals, the procedure of
Gilks and Wild (1992) can be invoked to generate the required samples. Upadhyay, Vasishta and
Smith (2001) illustrate the workings of this procedure via some failure data on ball-bearings.
Furthermore, they also discuss the matter of model comparisons and model validity via simulated
predictive distributions. Whereas aspects of this work cannot be said as being subjective Bayesian,
the paper of Upadhyay, Vasishta and Smith (2001) represents a significant forward leap in
approaches for analyzing failure time data.
When  =1   n is a complete sample of size n from an Inverse Gaussian distribution
with a joint prior on  and  of the form given in section 5.2.6, the joint posterior at  and  is:
C−1/2n−3/2 exp

−
 1
2 −2 + 3
2


where  = n −2 1 = n +  2 = n +  − 3 = n + / , with
 = 1
n
n
i=1
i  = 1
n
n
i=1

i
−1  and
C is a normalizing constant that can be iteratively evaluated in a manner that parallels an
evaluation of the percentiles of a ‘Student-t’ distribution. The details are in Betro and Rotondi
(1991). The parameter  being the mean of the IG distribution conveys a practical import. Its
posterior distribution – obtained by integrating out the parameter  in the joint posterior of 
and  – turns out to be
C
1
2  + 1

n−3/2
"
1
2 −2 + 3
2
#+1/2 
where • is the gamma function.
5.4.7
Bernoulli Life-testing Procedures
The Bernoulli, as a chance distribution for reliability studies was motivated in section 5.2.3,
and priors for the Bernoulli parameters were also discussed there. In section 5.4.2 the notion
of informative and non-informative stopping rules was illustrated with Bernoulli trials as a
motivating scenario. Proper priors for the Bernoulli parameter  are given by (5.11) and (5.12),
and in what follows attention is focused on the former. Thus if r successes are observed in n
Bernoulli trials, each having  as the probability of success, (5.4) takes the form
P Xn+1 = x	nr =
1

0
x1 −1−xFd	nr
(5.39)
with
Fd	nr ∝	nrFd
(5.40)
where Fd is given by (5.11) and 	nr is proportional to r1 −n−r; x = 10 for
success (failure). It can now be seen (details left as an exercise) that (with  and  suppressed)
(5.39) simplifies as:
P Xn+1 = x	nr =
 +  + n
 + r + n −r
x +  + r + n −r + 1 −x
 +  + n + 1

(5.41)

158
PARAMETRIC FAILURE DATA ANALYSIS
and that
Fd	nr =
 +  + n
 + r + n −r+r−1+n−r−1
(5.42)
The predictive distribution (equation (5.41)) is a ‘beta binomial distribution’, and the posterior
distribution of  (equation (5.42)) is again a beta distribution.
The family of beta distributions is said to be a natural conjugate family under Bernoulli
sampling, because both the prior and the posterior distributions are members of this (same) family.
Similarly, the family of gamma distributions is a natural conjugate family for the parameter 
encountered in section 5.4.4 on exponential life-testing procedures (equations (5.33) and (5.34)).
Since E	 = / + , it follows from (5.42) that E	nr =  + r/ +
 + n; thus the role of the data is to change the mean of  from / +  to that given above.
If the prior on  is a uniform, that is, if ==1 then E	=1/2 and E	nr=
r + 1/n + 2, instead of the usual r/n that one normally tends to use.
The above development generalizes to the case of predicting the number of successes in m
future trials, given r successes in n trials; i.e. the scenario of (5.7). It can be seen – details left
as an exercise for the reader – that for x = 01   m
Px successes in m future trials	nr
=
m
x

BabBa + xb + m −x−1 
(5.43)
where Bab = a+b
ab a =  + r and b =  + n −r
Equation (5.43) is called the beta binomial distribution. It has played a key role in philo-
sophical arguments involving the assertion of a scientific law based on empirical evidence alone.
A feel for these can be best described by the scenario given below.
Infinite Number of Successes Cannot Assert the Certainty of Reliability
Suppose that n identical copies of a unit are tested for some pre-specified time and all of these
result in success; i.e. r = n. If a Bernoulli chance distribution with a parameter  is used to
describe the outcome of each trial, and if the prior on  is taken to be a uniform on 01,
then the probability that the next m trials will lead to m successes is, by (5.43), given as
n + 1/m + n + 1. Suppose now, that n is large and m << n, say m = 1. Then the above
probability tends to (but is not equal to) one. However, if m>>n, and if n is large, conceptually
infinite, then the above probability decreases to zero! This means that under a Bayes–Laplace
type uniform prior, an infinite number of successful tests of a unit cannot guarantee that a large
number of future tests will all result in successes. Jeffreys (1980) used this type of an argument
to claim that empirical observations alone cannot prove a scientific law. He then went on to
construct a prior under which the predictive distribution provides results that are more in accord
with the disposition of experimental scientists; also see Singpurwalla and Wilson (2004).
Bernoulli Testing Under an Exponential-gamma Induced Prior
We consider here the case of Bernoulli testing when the prior Fd	t is of the form given
by (5.12) of section 5.2.3. Recall that under this prior for , the mission time t is a parameter,
and that / + t is the mean value function of this prior. Whereas the merits of such a
prior need to be explored, the results given below could be useful, especially when the lifetimes
are judged to be exponential and the actual times to failure are not available. For example, when
observations can be taken only at time t.

PREDICTIVE DISTRIBUTIONS INCORPORATING FAILURE DATA
159
Suppose, then, that r successes are observed in n trials, where each trial entails the life-testing
of an item until time t, where both n and t are chosen at will; i.e., stopping rule is non-informative.
Then, it can be shown, albeit after some cumbersome algebra, that the posterior distribution of
, Fd	nrt is of the form
 
n−r

j=0
n −r
j

−1j 
j
!−1
 
t +r−11 −n−r

ln
1

−1

(5.44)
where j =
 
t + r + j
. The details are left as an exercise.
The mean of the above distribution gives us the predictive distribution PXn+1 =
1	nrt. This can be seen (details left as an exercise) as being
E	nrt =
 
n−r

j=0
n −r
j

−1j

 
t + r + j + 1

!
·
 
n−r

j=0
n −r
j

−1j

j
!−1

(5.45)
Thus the effect of the data is to change the mean of  from / + t to the elaborate form
given above. Contrast this with the case of a beta prior on , wherein the effect of the data is to
change the mean from / +  to  + r/ +  + n.
The posterior probability that  exceeds 0 is obtained using the incomplete gamma function.
Namely
P ≥0	nrt =
 
n−r

j=0
n −r
j

−1j

j
!−1
n−r

j=0
n −r
j

−1j

j
ln1/0

0
e−sjjs−1

ds
The development of the above material assumes that t is both the mission time for future trials
(namely the Xn+1 case) and also the test time for n trials constituting the observed data. This
need not be so. If the test time is t and the mission time is   ̸= t, and if " = t/, then all of
the above results go through with the following changes:
(c1)
The j’s get replaced by
 
t + "r + j
 	
(c2)
In (5.45),
 
t + r + j + 1

gets replaced by
 
t + "r + j + 1

;
(c3)
In (5.44),
 
t + r −1

gets replaced by
 
t + "r −1

and 1 −n−r gets replaced
by 1 −"n−r.
A verification of the above is left as an exercise for the reader.
5.4.8
Life-testing and Inference Under the BVE
Thus far, our discussion on life-testing has centered around univariate chance distributions like
the exponential, the Weibull, the generalized gamma, and the Bernoulli variables that these
distributions could induce. We have noticed that a key ingredient for producing the predictive
distributions of interest is the posterior distribution of the parameters of the underlying chance

160
PARAMETRIC FAILURE DATA ANALYSIS
distribution. The same will also be true when dealing with multivariate chance distributions
like those of Gumbel, Freund of Marshall and Olkin’s BVE. The posterior distribution of the
underlying parameters is obtained via the product of the likelihood and the prior, where it
has been traditionally so that the likelihood is based on the probability density function of the
assumed chance distribution. Equations (5.28) and (5.46) are examples. Since all the bivariate
distributions discussed in section 4.7, save the BVE, are absolutely continuous (Table 4.1) they
generate probability densities (with respect to the two-dimensional Lebesgue measure). These
densities provide a basis for writing out the appropriate likelihoods. The difficulty arises with
the BVE since this distribution does not have a density with respect to the two-dimensional
Lebesgue measure – Claim 4.7 of section 4.7.4. However, Bemis, Bain and Higgins (1972) have
proposed a way of overcoming this difficulty by introducing
ft1t2 =
⎧
⎨
⎩

1
2 + 
12Ft1t2 t2 > t1 > 0

2
1 + 
12Ft1t2 t1 > t2 > 0 and

12Ft1t2
t1 = t2 > 0
(5.46)
and claiming that ft1t2 is a density with the understanding that the first two equalities of
(5.46) are densities with respect to the two-dimensional Lebesgue measure, and the third equality
a density with respect to the one-dimensional Lebesgue measure. This result has enabled the
application of any theory of inference based on densities, as was done by Bhattacharyya and
Johnson (1973), Shamseldin and Press (1984) and Peña and Gupta (1990). However, there is
another difficulty that the BVE poses which the above did not attempt to cope with, namely the
problem of identifiability mentioned in section 4.7.4. Specifically, the matter of identifiability
arises in the context of observing failure data on parallel redundant systems when the first
failure is an individual failure. Under such circumstances, the cause of the second failure cannot
be exactly determined. A consequence is that data on the second unit to fail cannot be used
for learning about the dependency parameter 
12 and the parameter 
1 or 
2, depending on
which unit is the second to fail. A way of overcoming this obstacle is through the technique of
data augmentation (mentioned in Appendix A) and using the Gibbs sampling algorithm on the
augmented data. A use of this strategy for the problem at hand is outlined below.
Data Augmentation and Gibbs Sampling for the BVE
A Bayesian approach for inference about the parameters 
1
2 and 
12 of the BVE has been
proposed by Shamseldin and Press (1984) and by Pena and Gupta (1990) but without considering
the scenario of life-testing for parallel systems; thus the matter of identifiability has not been
considered by them. Shamseldin and Press (1984) assume that 
1 = 
2 and assign independent
priors for the 
is and 
12; Pena and Gupta (1990) allow dependence. We shall assume independent
gamma priors for 
1
2 and 
12, our main objective being an illustration of the use of the
technique of data augmentation. Accordingly, we assume that the joint prior on 
1
2 and 
12
has a density
1
1 · 2
2 · 3
12
where i
 ∝exp−i

i−1, for ii > 0 i = 12.
For the parallel sampling perspective adopted here, let t = t1jt2j j = 1   n be the
data, with t1j denoting time to failure of unit 1, and t2j the time to failure of unit 2 in a two-
component parallel system; the number of observations is n. Furthermore suppose that of these
n observations, n1 is the number of times t1j < t2j, n2 the number of times t1j > t2j, and n12 the
number of times t1j = t2j; thus n = n1 + n2 + n12. Thus ni is the number of times the failure is
caused by the shock-generating process Nit t ≥0 i = 123.

INFORMATION FROM LIFE-TESTS: LEARNING FROM DATA
161
Since information about the cause of the second failure is not contained in the data t, the data
augmentation process requires that we introduce this information via suitable random variables;
this is the essence of the technique. We are therefore motivated to introduce two new random
variables M1 and M2 where Mi denotes the number of times the failure of component i is caused
by the process Nit, when component i is the second to fail. Since component 1 is the first to
fail n2 times, 0 ≤M1 ≤n2; similarly for M2. Thus conditional on M1 and M2, the likelihood of

1
2 and 
12, in the light of the data t is
L
1
2
12  M1 = m1M2 = m2	t =


1n1+m1 e−
11

2n2+m2 e−
22
·


1n−m1−m2 e−
1212

where 1 =
n1
j=1
t1j 2 =
n2
j=1
t2j and 12 =
n
j=1
maxt1jt2j
The effect of data augmentation has been to factorize the likelihood, because in the absence
of M1 and M2 the likelihood would have been

1 
2
12n1 
2 
1
12n2 
n12
12 exp−
11 −
22 −
1212
As a consequence of the independent priors on 
1, 
2 and 
12 and a factorization of the
likelihood, 
1
2 and 
12 are a posteriori independent, with 
i having a gamma distribution with
scale parameter i + i and a shape parameter i + ni + mii = 12, and 
12 also having a
gamma distribution with scale parameter 12 + 12 and shape parameter 12 + n −m1 −m2.
Sampling from these distributions to generate a Gibbs sample is therefore straightforward.
The other conditional distributions required are those of M1 and M2. Since M1 is the number
of times a unit fails due to the process N1t as opposed to N3t, out of n2 items on test, M1
has a binomial distribution with parameters n2 and 
1/
1 + 
12. The probability that an item
fails due to the process N1t rather than N3t is 
1/
1 + 
12. Similarly, M2 has a binomial
distribution with parameters n1 and 
2/
2 + 
12. All the ingredients needed to invoke the Gibbs
sampling algorithm are at hand. The posterior distributions of 
1
2 and 
12 can now be obtained.
5.5
INFORMATION FROM LIFE-TESTS: LEARNING FROM DATA
I have said that life-testing experiments yield ‘information’ via failure and survival times, and
that such information helps provide realistic assessments of an item’s survivability. I have also
said that data from life-tests enables us to ‘learn more’ about the underlying parameters of chance
distributions, such knowledge being of value when taking actions about the acceptance or not of
an item, or for obtaining an enhanced appreciation (i.e. inference) of the nature of the parameters.
But what do such commonly used terms like ‘information’, ‘learning’ and ‘knowledge’ mean?
The word ‘information’ has already appeared in section 5.3.2 in the context of reference priors,
but little has been said about its basic import. The purpose of this section is to make explicit
notions such as entropy, information, and learning, and to articulate their role in reliability and
survival analysis.
5.5.1
Preliminaries: Entropy and Information
By the term ‘information’, we mean anything that changes our probability distribution about an
unknown quantity, say , which for convenience is assumed to be a parameter of some chance
distribution. A consequence of a change in the probability distribution of  could be a change in
some action that is taken based on an appreciation of . Thus one way to measure the change in

162
PARAMETRIC FAILURE DATA ANALYSIS
the probability distribution of  is via a utility function 	dT ∗n, where dT ∗n is some
action or decision that we may take based on data T ∗obtained via n observations. In the context
of life-testing, the total time on test (section 5.4.3) – best encapsulates T ∗. Recall that the notion
of a utility was introduced in section 1.4, and utilities were discussed in section 2.8.1 where the
notation uCij was used to denote the utility of an action j when the state of nature was i. In
	dT ∗n is to be identified with i and dT ∗n with j. In what follows dT ∗n will be
denoted by just d.
Suppose now that F is our prior distribution of , and FT ∗n our posterior for  were
we to take n observations and observe T ∗as data. Then, by the principle of maximization of
expected utility (section 2.8.2) the expected gain in utility due to T ∗n is measured as
gn = ET ∗
⎧
⎨
⎩max
d


	dFdT ∗n
⎫
⎬
⎭−
⎧
⎨
⎩max
d


	dFd
⎫
⎬
⎭	
(5.47)
it can be seen that gn≥0. The expectation above is with respect to the marginal distribution of
T ∗, and n, a decision variable, is assumed to be specified. Determining an optimum n is discussed
later, in section 5.6. The quantity gn is also known as the expected information about  that
would be provided by the data T ∗were n observations to be taken. It is important to bear in
mind that gn is in the subjunctive mood; i.e. gn is based on the contemplative assumption of
taking n observations and obtaining T ∗as data. It is for this reason that expectation with respect
to the marginal T ∗is taken. In Bayesian statistics, such contemplative analyses are known as
preposterior analyses because they precede the obtaining of any actual posterior.
What are the possible choices for dT ∗n and what possible forms can 	d take? The
answer depends on the practicalities of the situation at hand. The simplest scenario is one wherein
the decision is a tangible course of action, such as accepting or rejecting a batch of items. In this
case, with d as the decision to accept and  a measure of quality, it is reasonable to let 	d
be an increasing function of . More about scenarios involving tangible courses of action is said
later in sections 5.5.3 and 5.6. For now we shall consider a more subtle case wherein the decision
is an enhanced appreciation of .
Choice of Utility Functions for Inference (or Enhanced Appreciation)
Since a probability density best encapsulates our appreciation of uncertainty about , our choice
of d should be some density, say p•. Thus 	d will be of the form 	p•, which is the
utility of declaring the density p•, when the parameter takes the value . But it is the posterior
distribution of  that accords well with our belief about . Thus the question arises as to what
functional form of 	p• will result in the choice that an optimum p• is the posterior
distribution of ? Bernardo (1979b), in perhaps one of the most striking results in Bayesian
decision theory, has shown that the utility function has to be of the logarithmic form; that is
	p•=logp. Consequently, if this form of the utility function is invoked in (5.47), then
gn = ET ∗
⎧
⎨
⎩


logFdT ∗nFdT ∗n
⎫
⎬
⎭−
⎧
⎨
⎩


logFdFd
⎫
⎬
⎭
(5.48)
In order to connect the above notions from Bayesian decision theory to those used in commu-
nication theory, we remark that the Shannon information about , whose uncertainty is given
by Fd, is
I =


logFdFd	
(5.49)

INFORMATION FROM LIFE-TESTS: LEARNING FROM DATA
163
−I is known as the entropy of Fd. Similarly with FdT ∗n, we have the entities
IT ∗n and −IT ∗n. Consequently, gn is ET ∗IT ∗n −I
If the distribution function of T ∗is denoted by FT ∗ – recall that T ∗has not as yet been
observed – then another way of writing gn is
gn =

T ∗


log
 FddT ∗
FdFdT ∗

FddT ∗	
(5.50)
here FT ∗ is the joint distribution function of  ant T ∗. To see why, we note that the first
term of (5.48) is

T ∗


logFdT ∗nFdT ∗nFdT ∗ =

T ∗


logFdT ∗nFddT ∗
and that the second term is

T ∗


logFdFddT ∗
Consequently,
gn = ET ∗

log
 FddT ∗
FdFdT ∗


(5.51)
where the expectation is with respect to FT ∗.
When gn is written as above, it is interpreted as the mutual information between  and
T ∗, or as the Kullback–Leibler distance for discrimination between FdT ∗n and Fd.
Soofi (2000) provides a recent account on these and related matters. Mutual information has the
property that gn ≥0, with equality, if and only if  and T ∗are independent. In the latter case,
knowledge of T ∗gives us no information about . In life-testing, one endeavors to collect that
data which results in a T ∗for which gn is a maximum. In communication theory (Shannon
(1948) and Gallager (1968)), the maximum value of gn is known as channel capacity; here  is
interpreted as the message to be sent, and T ∗interpreted as the message received. The connection
between information theory and the prior to posterior transformation in Bayesian inference
has been articulated by Lindley (1956) in perhaps one of his several landmark papers. Other
references relating the above ideas to the design of (life-testing) experiments are in Verdinelli,
Polson and Singpurwalla (1993), and in Polson (1992).
Our discussion thus far has been conducted on the premise that the n observations have yet
to be taken and the T ∗remains to be observed; i.e. what we have been doing is a pre-posterior
analysis. Thus gn represents the expected gain in utility or the expected information. Suppose
now that the n observations are actually taken and that the data T ∗has indeed been obtained.
Then, by analogy with (5.47), the observed information or the observed change in utility is
gT ∗n = max
d


	dFd	T ∗n −max
d


	dFd
An unpalatable feature of gT ∗n is that unlike gn, which is always non negative, gT ∗n
could be negative. A negative value of gT ∗n signals the fact that data could result in negative
information. This of course, though contrary to popular belief, is still reasonable, because in
actuality one could be surprised by the data one sees, and as a consequence be less sure about 
than one was prior to observing the data.

164
PARAMETRIC FAILURE DATA ANALYSIS
One attempt at avoiding the possible negativity of gT ∗n is to introduce 'gT ∗n, the
conditional value of sample information (cf. De Groot, 1984). Here, let d0 denote that value of
d which maximizes
UFd
def
=


	dFd	
d0 is known as the Bayes’ decision with respect to the prior Fd. We assume that d0 exists
and is unique. Then
'gT ∗n
def
= max
d
U FT ∗nd −U FT ∗nd0
the difference between the expected utility from the Bayes’ decision using the data T ∗n and
the expected utility using d0, the decision that would have been chosen had the data not been
available. By definition, it is true that 'gT ∗n≥0 for every T ∗, and that its expected value with
respect to FT ∗, the marginal of T ∗, is indeed gn.
5.5.2
Learning for Inference from Life-test Data: Testing for Confidence
For the purpose of this section, we shall suppose that the intent of learning is an enhanced
appreciation about an unknown parameter of a chance distribution. The matter of learning for
taking a tangible action such as acceptance or rejection is considered the in section 5.5.3. To
simplify matters, suppose that the chance distribution is an exponential with a parameter 
, so
that for 
 > 0PT > t
 = exp−
t, for t ≥0	
 is the failure rate. Let # = 
−1 be the mean
time to failure of the exponential distribution of T, and as before let T ∗denote data from a
life-test.
In practice, life-testing is commonly done to learn more about the mean time to failure of an
item; i.e. to gain an enhanced appreciation of the parameter #. Whereas learning more about #
may have limited tangible merit, it is often the case that contractual requirements are specified
in terms of #. Thus it behoves us to consider the information about # provided by the data T ∗,
and with that in mind we wish to address the question of how much testing should be done to
obtain sufficient knowledge about #? For this, a strategy has been proposed by Lindley (1957b),
namely, to continue testing until I#	T ∗ =

logFd#	T ∗Fd#	T ∗, the Shannon information
about # (equation (5.49) reaches a prescribed value. Since prescribing a value for I#	T ∗ seems
elusive, one possibility is to continue testing until I#	T ∗ fails to reflect a significant increase.
Lindley’s proposed strategy was for the Bernoulli chance distribution, but the idea is general
enough to be invoked for other distributions as well.
To facilitate calculations, suppose that F
, the prior distribution of 
 is a gamma with shape
(scale)  (section 5.2.1). Then, it is easy to see that upon observing a single failure at time
t the posterior distribution of 
 is also a gamma with shape  + 1 and scale  + t. This fact
allows us to display the testing scheme on a diagram with axes giving the values of the gamma
scale and shape parameters. Specifically, as has been shown by El-Sayyad (1969), when F
 is
a gamma distribution with shape (scale) parameter ab, the Shannon information is to a good
approximation, and for large values of a, of the form I
	ab ≈1
2 logb2/2a −1
2 + 1
2a. Thus
testing should be continued until the values of a and b that are obtained are such that a prescribed
value for I
	• is achieved. For values of a > 5, the relationship between ab and I
	• is
parabolic, and of the form b2 = Ca where C depends on I
	•, the amount of information that
is desired. This relationship is graphically portrayed in Figure 5.4 with the prior parameters 
and  as the starting values of a and b, respectively, and t1t2   , as failure times, assuming
the testing of one item at a time.

INFORMATION FROM LIFE-TESTS: LEARNING FROM DATA
165
b2 = c*a3
b2 = ca 
α
α + 1
α + 2
α + 3
0
ψ
Values of a
(shape parameter)
  Values of b 
(scale parameter)
t1
t2
t3
Figure 5.4
Values of the gamma scale and shape parameters for desired shannon information.
In Figure 5.4 testing will stop after Three failures for a specified value of C, where C is
determined by a desired value of I
	•. In the schemata discussed above, stopping between
failures is not considered.
It is well known (cf. Lindley, 1956) that I
	• is not invariant under transformations of 
,
so that when interest centers around # the mean time to failure, I#	• = I
	• + 2E
log
;
(El-Sayyad, 1969). In this case the boundary in the ab diagram is b2 ≈C∗a3 where the constant
C∗depends on I#	•, the amount of Shannon information that is desired. This boundary is
illustrated by the convex dotted curve of Figure 5.4. A consequence is that for any fixed value
of  and , the amount of testing needed to get the same amount of information about 
 and
# will be different. Thus given a fixed amount of test time and a fixed number of test items, it
matters whether a desired amount of information is needed about the failure rate 
, or about the
mean #. More details pertaining to the implications of the concave and the convex boundaries
of Figure 5.4 are in Singpurwalla (1996). Also discussed therein is an observation by Abel and
Singpurwalla (1993), which shows that at any given point in time t, a failure is more informative
than a survival, if interest centers around # the mean time to failure, but that the opposite is
true when interest centers around the failure rate 
 = #−1. Specifically, I#; failure at t > I#;
survival at t) for all t, but that I
; failure at t < I
; survival at t for all t; (Figure 5.5).
Information Loss Due to Censoring
Recall, (section 5.4.1, that in practice life-tests are often censored to save test time and costs.
However, there is a price to be paid for this saving, namely, the loss of information. The purpose
of this sub-section is to describe ways of assessing the said loss. I start with the case of Type
I (or time truncated) censoring wherein n items are put on a life test that is terminated at some
pre-specified time t. Suppose that k ≥0 failures at times 1 ≤2 ≤··· ≤k are observed so that
the available data is Dt = k12   k. Following Brooks (1982), I focus attention on the
exponential case PT > t  
 = e−
t for 
 > 0 and t ≥0, and compute the expected information
in Dt about 
 – via (5.48) – as
IC = EDt I
Dtn −I


166
PARAMETRIC FAILURE DATA ANALYSIS
Survival at t 
Failure at t 
0
t
Shannon information I(ξ; •)
Survival at t 
Failure at t 
0
t
Shannon information I(λ; •)
Figure 5.5
A comparison of shannon information about failure rate and mean given failure or survival at t.
where the expectation is taken with respect to the marginal distribution of Dt. Similarly, we compute
IC = ED I
Dn −I

where D denotes the case of no censoring; i.e. by setting t =. The difference between IC and
IC represents the loss of information due to censoring; we would expect that IC ≥IC. The detailed
computations tend to be cumbersome, but if a gamma prior with shape (scale)  is assumed,
then according to Brooks (1982), IC −IC ≈−1
2E
log1 −e−
t. An interesting follow on to
the above is the work of Barlow and Hsiung (1983) who show that for a ‘time transformed
exponential’, namely, the one wherein PT > s  
 = e−
Rs, where Rs is a known function
of sIC is concave and increasing in both Rs and n. The prior on 
 is a gamma with shape
(scale) . Note that with Rs = s, we have the exponential as a chance distribution, and that
with Rs	 = s, the Weibull distribution with a known shape parameter  > 0. The concavity
of IC enables us to assess the effects of increasing the test truncation time t and n, the number
of items to be tested; it implies that there is a limit beyond which increasing n and/or t gives
little added information. Figure 5.6 taken from Barlow and Hsiung (1983) illustrates this point;
here  = 279 and  = 478.
The concavity of expected information has also been noted by Ebrahimi and Soofi (1990),
who consider the case of Type II censoring, namely subjecting n items to a test that is stopped
at the r-th failure so that the observed data is Dr = k12   r. Furthermore, the authors
remark that
I∗
C = EDr I
Drn −I

increases in r but decreases in , the shape parameter of the gamma prior distribution of 
.
5.5.3
Life-testing for Decision Making: Acceptance Sampling
Whereas life-testing for enhanced appreciation of unknown parameters has merit in scientific
contexts, in the industrial set-up life-testing is most likely done with the aim of making tangible
decisions such as the acceptance of a batch of items. The best example of this application is
the U.S. Department of Defense’s Military Standard 781 C plan of 1977. Here a sample of n
items from a batch of N items is subjected to a life-test, and based on the results of the test, the
untested items are accepted or rejected. We shall suppose that items which are surviving at the
termination of the test are discarded and that n is specified. The determination of an optimum n

INFORMATION FROM LIFE-TESTS: LEARNING FROM DATA
167
Shannon information
Test time t
Shannon information
Increasing 
test time
2
3
4
5
6
7
8
1
Sample size
00
0
Sample size n
0
Figure 5.6
The effect of sample size n and test time t on Shannon information (from Barlow and Hsiung,
1983).
is discussed later in section 5.6. In what follows, we describe a strategy to be used by a consumer

 who tests the n ≥0 items and then makes an accept/reject decision.
Since n is assumes known, 
’s decision tree will have one decision node and three random
nodes (section 1.4). This decision tree is shown in Figure 5.7.
With n given, 
 tests the n items and obtains as data – at the random node 1 – the quantity
T ∗. Once T ∗is obtained 
 takes an action at the decision node 1 to either accept A or to reject
R the remaining N −n items. Suppose that 
 chooses to accept; then at the random node
2 nature takes its course of action in that the value of the unknown parameter happens to be .
For this sequence of events, working backwards from , 
 experiences a utility 	AT ∗n.
Similarly when 
 chooses to reject and nature takes the action  at 3, the utility to 
 is
	RT ∗n.
Suppose that 
’s prior on  is Fd; then having obtained T ∗, 
 computes Fd	T ∗, the
posterior for . Furthermore, it is reasonable to suppose that
	AT ∗n = 	A and that
	RT ∗n = 	R	
1
3
1
2
T *
A = Accept
R = Reject
n
(θ, A, T *, n)
θ (or T )
θ (or T )
(θ, R, T *, n)
Figure 5.7
Decision tree for acceptance or rejection by 
.

168
PARAMETRIC FAILURE DATA ANALYSIS
this is because n is chosen and the observed data T ∗will not have any effect on 
’s utility
of accepting or rejecting, once  is treated as being known. 
 next invokes the principle of
maximization of expected utility and accepts the N −n untested items if:


	AFd	T ∗ ≥


	RFd	T ∗	
(5.52)
otherwise 
 will reject. As stated before, in section 5.5.1, if  is a measure of the quality of
the item, say the mean time to failure, then 	A will be an increasing function of . For
example, 	A = log, suggesting that the utiles to 
 for very large values of  get de facto
saturated at some constant value.
There is a reinforcement to the argument which leads to (5.52) above. This is based on the
premise that utilities are better understood and appreciated if they are defined in terms of observ-
able entities, like lifelengths, instead of abstract parameters like . With that in mind, suppose
then that T1T2   , the lifelengths of all the N items in the batch are judged exchangeable, and
suppose that T denotes the generic lifelength of any one of the N −n untested items. Then
given T ∗, the predictive distribution of T is
PT > t	T ∗ =


PT ≥tFd	T ∗
(5.53)
With the above in place, I now suppose that at nodes 2 and 3, nature will yield a life-time
T (instead of ) so that 
’s terminal utilities are 	TAT ∗n and 	TRT ∗n. As before,
I suppose that the above utilities do not depend on T ∗and n, so that 
’s criterion for accepting
the untested items will be


	tAFdt	T ∗ ≥


	tRFdt	T ∗
(5.54)
where 	tA is 
’s utility for acceptance when T = t, and Fdt	T ∗ is the probability density
at t generated by (5.53), the predictive distribution of T; similarly 	tR. Here again it is
reasonable to suppose that 	tA is an increasing function of t. What about 	tR, the utility
to 
 of rejecting an item whose lifelength T is t? One possibility is to let 	tR = 0, assuming
that there is no tangible regret in having rejected a very good item. Another possibility is to let
	tR = a3, where the constant a3 encapsulates the utility of a lost opportunity.
Besides ease of interpreting utilities, there is another advantage to the formulation which leads
us to (5.54). This is because the acceptance (or the rejection) criterion of (5.54) can come into play
at any time during the life-test, not just at the time of a failure. The practical merit of this feature
is timely decision making. To see how, suppose that the underlying chance distribution of T is
an exponential with # as the mean time to failure; i.e. PT > t  # = exp−t/# t ≥0 # > 0.
Suppose that the prior on # is an inverted gamma distribution with shape (scale) parameter
; i.e. the prior distribution of 
 = 1/# is a gamma with shape (scale) parameter . Then
Fd#	 = 
 exp

−
#

#−+1
(5.55)
If n items are tested and k failures observed at time t, then the total time on test  =
k
1 i +n−kt, where i is the time of the i-th failure; recall that 1 ≤2 ≤···≤k. It is evident

INFORMATION FROM LIFE-TESTS: LEARNING FROM DATA
169
(details left as an exercise for the reader) that the posterior distribution of # is also an inverted
gamma with shape  + k and scale  + . That is
Fd#	k =  + +k
 + k exp

− + 
#

#−+k+1
(5.56)
We now suppose that 	tA = a1t −a2 and 	tR = a3, where a1 is a utile to 
 for every
unit of time that an item functions, and −a2 the utile to 
 in accepting an item that does not
function at all; a2 encompasses the cost to 
 of purchasing and installing an item. With the
above in place, an application of (5.54) would result in accepting the untested items as soon as
 + 
 + k −1 > a2 + a3
a1
	
(5.57)
the details which entail routine technical manipulations are left as an exercise for the interested
reader. The essence of the intent of (5.57) can be graphically portrayed with the shape parameter
on the horizontal axis and the scale parameter on the vertical axis. The boundary between
An, the region of acceptance, and Rn, the region rejection, is a line with slope a2 + a3/a1
(Figure 5.8).
It is instructive to note the parallels between Figure 5.8 and Figure 5.4. In Figure 5.8,
the sample path of the  + k +  curve takes jumps of size nt1n −12 −1   
n −kk+1 −k   2n−1 −n−2n −n−1. Acceptance occurs at the point marked as
a on the boundary, after the third failure, but prior to the fourth.
A more realistic version of 	tA would be 	tA = a1tp −a2 for p ≤1; this would make
the utility function increasing but concave. When such is the case, 
’s criterion for acceptance
will be
 + p  + k −p
 + k
> a2 + a3
a1
	
(5.58)
α
α + 1
α + 2
α + 3
0
ψ
Shape parameter
(n – 1) (τ2 – τ1)
(n – 2) (τ3 – τ2)
(n – 3) (τ4 – τ3)
(a)
Scale parameter
1
Rejection region R(n)
Acceptance region 
A(n)
Boundary
nτ1
Figure 5.8
Parameters of the inverted gamma and 
’s acceptance–rejection region.

170
PARAMETRIC FAILURE DATA ANALYSIS
this suggests that the boundary between acceptance and rejection is a curve instead of the straight
line of Figure 5.8.
The starting point  in Figure 5.8 is shown to lie in the region of rejection. This means
that based on prior knowledge alone, 
 is unable to accept the lot of untested items. Had the point
 been in the region of acceptance, 
 would accept the lot without any testing. There is an
additional feature to the scheme illustrated by Figure 5.8. This pertains to the fact that had testing
been continued after the point a had been traversed by the sample path of  + k +  – say
until all the n items on test fail – then it is possible that the sample path would cross the boundary
line again and re-enter the region of rejection. That is, acceptance could be premature. Assuming
that n is optimally chosen (section 5.6), the implication of such a switch from acceptance to
rejection would be that added evidence from the life-test suggests rejection as the prudent course
of action. With this caveat in mind, why then should one stop testing as soon as the sample path
of  + k +  reaches the point a? One answer to this question is that since the Shannon
information is concave in the test time (Figure 5.6) I would have gained a sufficient amount of
knowledge about T by the time we accept so that a second crossing is unlikely. That is, our
decision to accept is fairly robust. Furthermore, assuming that acceptance does not occur very
early on in the test, a second crossing can happen if the sample path takes a small jump. But
small jumps correspond to very small inter-failure times, and such inter-failure times could be
seen as outliers, whose effects on the decision process should be tempered. To account for such
outliers, it is important that the predictive distribution of T have heavy tails. Finally, but more
importantly, our set-up had not incorporated a disutility (i.e. a negative utility) associated with
the time needed to conduct the test and the utility gained by making early decisions. Were such
utilities to be incorporated for deigning 
’s actions, then the cost of testing would offset the
added information obtained by additional testing. Multiple crossings are the consequence of the
sample path being close to the accept/reject boundary.
5.6
OPTIMAL TESTING: DESIGN OF LIFE-TESTING EXPERIMENTS
The material of section 5.5 assumed that n, the number of items tested, is specified. In actuality,
n is also a decision variable – like accept or reject – and therefore, it should also be chosen by
the principle of maximization of expected utility. Since the testing of each item entails costs,
namely the cost of the item tested plus the cost of the actual conduct of the test, there is a
disutility associated with the testing of an item. In what follows we assume that any tested item
that does not fail during the test is worthless; i.e. it is discarded. As a start, we shall assume that
the cost, in utiles, of procuring and testing an item to failure is a fixed constant s, irrespective of
how long it takes for the item to fail. Furthermore, the set-up costs associated with the conduct
of the life-test are assumed to be negligible.
Figure 5.9 shows a decision tree that illustrates the problem of choosing an optimal sample
size n for a life-testing experiment. We assume that the cost of sampling and testing is borne
by a consumer 
, who chooses n on the premise that all the n items will be tested to failure.
The adversarial scenario wherein the sampling and testing costs are borne by a manufacturer 
1
2
2
T *
n
1
θ (or T)
(θ, d, T *, n)
d(T *, n)
Figure 5.9

’s Decision tree for sample size selection in a life-test.

OPTIMAL TESTING: DESIGN OF LIFE-TESTING EXPERIMENTS
171
will be considered in section 5.7. In Figure 5.9, the convention of Figures 1.1 and 5.7, and the
notation of section 5.5 are used.
Figure 5.9 is an elaboration of the decision tree of Figures 5.7 in the sense that it has two
decision nodes, 1 at which 
 selects an n, and 2 at which 
 takes an action dT ∗n based on
the data T ∗revealed at the random node 1. The decision dT ∗n could be a tangible action,
like the accept/reject choices of section 5.5.3, or it could be a probability distribution for an
enhanced appreciation of  (sections 5.5.1 and 5.5.2). At the random node 2 nature takes the
action  (or equivalently reveals a T) so that at the terminus of the tree 
 experiences a utility
	dT ∗n, where d = dT ∗n. Following Lindley (1978) (and also the references therein),
we assume that 	dT ∗n does not depend on T ∗and that it is additive and linear in n. Thus
	dT ∗n = 	d −ns
(5.59)
Working the tree backwards, 
 will choose at the decision node 2 that d for which


	dFdT ∗n
is a maximum. At the decision node 1, 
 will choose that n for which
⎡
⎣ET ∗
⎧
⎨
⎩max
d


	dFdT ∗n
⎫
⎬
⎭−ns
⎤
⎦
is a maximum. Were 
 to choose d and n as indicated above, then 
’s expected utility will be
max
n
⎡
⎣ET ∗
⎧
⎨
⎩max
d


	dFdT ∗n
⎫
⎬
⎭−ns
⎤
⎦
(5.60)
Observe that (5.60) is an extension of the first part of (5.47), the expected utility due to T ∗
and n. In principle, the above pre-posterior analysis of 
’s actions provides a normative solution
to the problem of 
 choosing an optimal sample size.
If the goal of life-testing is to obtain an enhanced appreciation of , then 	d=	p•=
logp (section 5.5.1). In this case 
 will choose that n which yields
max
n
⎡
⎣ET ∗
⎧
⎨
⎩


logFdT ∗n
⎫
⎬
⎭−ns
⎤
⎦
(5.61)
If the goal of life-testing is for 
 to make a rational accept/reject decision, then it is best to
formulate the problem in terms of the observable T (instead of the ) as was done in section 5.5.3.
Once this is done, 
 will choose that n which results in
max
n

ET ∗

max
AR 	t•FdtT ∗n

−ns


(5.62)
where 	t• is 	tA or 	tR, and FdtT ∗n is the posterior predictive distribution of T,
were 
 to take a sample of size n and observe T ∗as data. The details leading to (5.62) are
relatively straightforward; they are left as an exercise for the reader. It is important to note that
even though 
 can make a decision to accept prior to the failure of all the n items on test, 
’s

172
PARAMETRIC FAILURE DATA ANALYSIS
pre-posterior analysis for choosing an optimal should be based on the premise that testing will
continue until all n items fail.
An obstacle to using (5.61) and (5.62) is the difficulty of performing the underlying compu-
tations. Even the simplest assumptions regarding the chance distributions and the priors on their
parameters, lead to complex calculations. Computing expectations with respect to the distribution
of T ∗is certainly a hurdle. Thus efficient simulations and approximation schemes, suitably cod-
ified for computer use, are highly desirable. The situation described here gets more complicated
if we wish to incorporate the scenario in which the cost of life-testing is a function of both s,
the cost of procuring an item, and also the duration of the life-test. If 
 chooses an n, then 
expects the life-test to last until n, the failure time of the last item to fail. Thus if 
 incurs a
disutility of s∗utiles for each unit of time the test is in progress, then the expected disutility
incurred by 
 due to the conduct of the test is ns + s∗En	 En is the expected value of n,
the largest order statistic (out of n) of the predictive distribution of the n times to failure in the
test. When this disutility is accounted for, (5.60) becomes
max
n
⎡
⎣ET ∗
⎧
⎨
⎩max
d


	dFdT ∗n
⎫
⎬
⎭−ns −s∗En
⎤
⎦
(5.63)
Since En will entail n, the inclusion of En in the term to be maximized over n is meaningful.
However, a question may arise as to why En is not included in the term within the braces
over which an expectation with respect to the distribution of T ∗is taken. This is a subtle matter
that deserves mention. It has to do with the fact that when 
 is contemplating n at the decision
node 1, all that is available to 
 is the predictive distribution of the n times to failure based on

’s prior alone. However, at 2 when 
 is contemplating an action to take, 
 has, in addition to
the prior, the T ∗that 
 hopes to observe. Thus the expectation with respect to T ∗of the quantity
in braces of (5.63). The above points are best illustrated when we consider an evaluation of
En. The predictive distribution of the times to failure of the items on test is based on the prior
alone. Thus
PT > t =


PT > tFd
Since n is max12   n, its distribution function is
Pn ≤t = 1 −PT ≤tn =
⎡
⎣1 −


PT > tFd
⎤
⎦
n

Let Fdn denote the probability density generated by the above distribution at the point n.
Then
En =


0
nFdn	
En depends on n since Fdn depends on n – thus its inclusion in the term within brackets
over which n is maximized.
Thus to summarize, should 
 wish to incorporate the cost of testing into a pre-posterior
analysis, then 
 will choose that n which yields:
max
n
⎡
⎣ET ∗
⎧
⎨
⎩max
d


	dFdT ∗n
⎫
⎬
⎭−ns −s∗


0
nFdn
⎤
⎦
(5.64)

ADVERSARIAL LIFE-TESTING AND ACCEPTANCE SAMPLING
173
In order to compute an expectation with respect to T ∗, 
 needs to obtain the marginal
distribution of T ∗when n items are tested. Let FT ∗	n denote the marginal distribution of T ∗,
and F
, 
’s prior distribution for. Then for 
FT ∗	n =


FT ∗	nF
d	
(5.65)
let FdT ∗	n be the probability density at T ∗generated by FT ∗	n. Then (5.64) becomes
max
n
⎡
⎣

T ∗
⎧
⎨
⎩max
d


	dFdT ∗n
⎫
⎬
⎭FdT ∗	n −ns −s∗


0
nFdn
⎤
⎦
(5.66)
Evaluating the above, either via numerical approximations or via simulations, is an open
problem – perhaps a challenge – that needs to be addressed. Since 
 has the option of conducting
a time truncated or an item censored test, T ∗is best encapsulated by the total time on test statistic
(section 5.4.3).
5.7
ADVERSARIAL LIFE-TESTING AND ACCEPTANCE SAMPLING
Consider the scenario of section 5.5.3 wherein a consumer 
, who needs a batch of items from a
manufacturer , either accepts or rejects the items offered by . With reference to Figure 5.8,
suppose that for 
, the parameters  and  of the inverted gamma prior on # – the mean time to
failure – lie in the region of rejection. Then 
’s decision is to reject the lot and consider alternate
manufacturers. We are supposing here that 
 is unwilling to incur any disutilities by conducting
a life-test on a sample of items from the batch to either refute or to re-affirm the decision to
reject. 
’s conduct is therefore adversarial. The problem that we wish to consider here is the
case wherein upon rejection by 
,  considers the option of offering a free sample to 
 for
the purpose of testing, in the hope that subsequent to testing 
 will change his (her) mind and
accept the lot; the cost of testing is also to be borne by . Should  offer 
 a sample, and if
so, how large a sample should it be?
The above problem has been discussed by Lindley and Singpurwalla (1991 and 1993); the
former in the context of acceptance sampling for quality control involving Bernoulli, Poisson, and
Gaussian sampling, and the latter in the context of reliability involving exponential life-testing.
In what follows I give an overview of the life-testing scenario by focusing attention on ’s
decision tree (Figure 5.10). Once  offers 
 a sample for life-testing, and if 
 agrees to accept
this offer, then 
’s subsequent actions will be determined by the material of section 5.5.3, and
in particular by the dictates of Figure 5.7.
’s decision of how large a sample n ≥0 to offer 
 will be based on ’s prior about # and
a knowledge of 
’s accept/reject criteria.  and 
 need not agree on a prior neither should they
be required to pool their priors; furthermore,  need to know 
’s prior. However,  needs
to be informed of 
’s accept/reject criteria which are determined by 
’s prior and 
’s utilities.
For example, in Figure 5.8, 
’s accept/reject boundary is a straight line, and 
’s criterion for
acceptance is
 + 
 + k −1 > a2 + a3
a1

If the optimal value of ’s n turns out to be zero, then  does not offer 
 a sample and
the adversarial game is concluded. With n = 0, the implication is that 
’s prior probability

174
PARAMETRIC FAILURE DATA ANALYSIS
2
1
T *
R = Reject
n
n(A, T *, n)
n(R, T *, n)
1
A = Accept
Figure 5.10
’s Decision tree with 
 taking an action at 2.
and utilities are such that, in ’s judgment (based on ’s prior and utilities), no amount of
testing can convince 
 to change his/her mind. Thus as far as  is concerned, offering 
 a free
sample is a losing proposition.
Figure 5.10 shows ’s decision tree for the set-up described above. What is novel here is
that at the decision node labeled 2, it is 
 (not ) who takes an action. In the decision trees
of Figures 5.7 and 5.9, it was 
 who was taking actions at all the decision nodes.
At the decision node 1,  takes the action of choosing an n (much like 
 does in Figure 5.9),
and at the random node 1, nature reveals T ∗as data. Subsequent to this, 
 makes the decision
to either accept or to reject the lot based on 
’s accept/reject criteria. That is 
 takes those
actions which maximize 
’s expected utility. 
’s accept/reject criteria boil down to T ∗belong-
ing to an acceptance region, say n, for acceptance and a rejection region, say n, for
rejection (Figure 5.8). Once 
 takes an action,  experiences a terminal utility 	MAT ∗n or
	MRT ∗n. Note that unlike the decision trees of Figures 5.7 and 5.9, the terminal utility to
 need not be determined by  (or by T) which encapsulate nature’s course of action. All that
could matter to  is acceptance or rejection by 
. The decision tree of Figure 5.10 pertains to
 contemplating what n to offer 
. Thus the analyses that lead to an optimal course of action
by  is a pre-posterior analysis. Consequently, to , the decision node 2 is no different from
a random node in the sense that instead of nature taking an action it is 
 who takes the action.
Furthermore 
’s action at 2 will depend on the data T ∗that will be observed by 
, and whether
T ∗lies in the acceptance region n, or the rejection region n.
Following the principle of maximization of expected utility,  will fold the decision tree of
Figure 5.10 backwards, and will offer 
 that sample size n which results in
max
n
⎧
⎨
⎩

T ∗∈n
	MAT ∗nFdT ∗	n +

T ∗∈n
	MRT ∗nFdT ∗	n
⎫
⎬
⎭
where FdT ∗	n is the probability density at T ∗generated by FT ∗	n, the marginal distribution
of T ∗as perceived by , were  to offer 
 a sample of size n. If Fd denotes ’s prior
distribution for , then
FT ∗	n =


FT ∗	nFd
(5.67)
Contrast (5.67) with (5.65); the former is based on ’s prior for , whereas the latter is on

’s prior for . Since  is to bear the cost of testing,
	MAT ∗n = 	MAn = b1 −b2n

ACCELERATED LIFE-TESTING AND DOSE–RESPONSE EXPERIMENTS
175
assuming that ’s utility for acceptance or rejection by 
 does not depend on T ∗; b1 > 0 is the
utility to  (in utiles) for every item accepted by 
 and b2 > 0, the disutility incurred by  for
every item tested. Similarly, 	MRT ∗n = b3 + b2n is the disutility to  for an item rejected
by 
 subsequent to the testing of n items; b3 > 0. With the above in place,  will offer 
 that
sample size n which results in
max
n
⎧
⎨
⎩

T ∗∈n
b1 −b2nFdT ∗	n −

T ∗∈n
b3 + b2nFdT ∗	n
⎫
⎬
⎭
More details and specific cases can be found in Lindley and Singpurwalla (1991, 1993).
5.8
ACCELERATED LIFE-TESTING AND DOSE–RESPONSE
EXPERIMENTS
Accelerated life-testing was alluded to in section 5.4.1 as a way of economizing on test time
by elevating the environmental conditions under which a life test is performed. Nominal or use
conditions stress means the environmental conditions under which an item is designed to be
used. The elevated conditions under which identical copies of the item are tested are known
as accelerated stresses. An accelerated life-test is a life-test in which items are tested under
accelerated stresses to gain information about its lifelength under nominal stress. This type of
testing is done when it is not physically possible to conduct life-tests under use conditions stress,
or when testing under use conditions entails an excessive amount of test time to yield failures.
Accelerated life-testing came into being in the space age; however, to the best of our knowledge,
it was pioneered at the Bell Telephone Laboratories in the context of assessing the reliability of
underwater telephone cables.
The viability of accelerated life-testing as a way to learn about lifetimes under use conditions
stress depends on an ability to relate the information gained at one stress level to that which would
be gained at lower stress levels. Thus a knowledge of the underlying physics of failure plays a key
role here. Such knowledge is encapsulated in what is known as the time transformation function.
If the time transformation function is ill chosen, then the resulting inferences can be misleading.
In principle, there could be several time transformation functions, each appropriate for a particular
stress regime. Subsequent to the initial papers that laid out a statistical framework to model this
problem (Singpurwalla 1971a, b) much has been written on the topic of accelerated life testing.
A recent treatise on this topic is by Bagdonavicius and Nikulin (2001). In section 5.8.1, I start with
a formal introduction to the accelerated life-testing problem by presenting two commonly occur-
ring versions; one based on time to failure data and the other based on the proportion of observed
failures. Section 5.8.2 is an overview of the technology of Kalman filtering, my proposed method
for dealing with inferential issues underlying the accelerated life-testing problem. Section 5.8.3
pertains to an illustration of the application of the Kalman filter algorithm for inference and
extrapolation in accelerated tests; the material here is expository with details kept to a minimum.
Section 5.8 ends with the important issue of the design of experiments for accelerated testing; the
material of section 5.8.4 draws on the notions of entropy and information discussed in
section 5.5.1.
5.8.1
Formulating Accelerated Life-testing Problems
Suppose that Tj denotes the time to failure of an item under stress Sj, j = 1   m, where
S1 < S2 < ··· < Sm; ‘Sj < Sk’ denotes the fact that Sj is less severe than Sk. Severity of stress

176
PARAMETRIC FAILURE DATA ANALYSIS
manifests itself in the fact that Sj <Sk ⇒Tj
st≥Tk; i.e. for all t ≥0 PTj ≥t≥PTk ≥t. Let Su be
the use conditions stress and suppose that Su < S1; then S1S2   Sm are accelerated stresses.
We assume that it is possible to conduct life tests at all the m accelerated stresses, but that it
may or may not be possible to do any testing at use conditions stress Su and any stress Su < Su.
To keep our discussion simple, suppose that n items are tested under Sj and that the test is
stopped at the time of occurrence of the k-th failure; for j = 1   m; i.e. we have a Type II
censored test at all the accelerated stress levels. In actuality, it is most likely that a large number
of items will be tested at low stress levels so that n1 ≥n2 ≥···≥nm, where nj denotes the number
of items tested under stress Sj; our assumption that nj =n for all j simplifies the notation without
a compromise in generality. Similarly, with the assumption of a common k over all stress levels.
Let Tjll = 12   k denote the time to failure of the l-th item when it experiences a stress
Sj j = 1   m Let Tjl denote the l-th order statistic of the Tjls; i.e. Tj1 ≤Tj2 ≤··· ≤Tjk.
Given that the tjl’s, j = 1   m l = 1   k, our aim is to make statements of uncertainty
about Tu; tjl is a realization of Tjl.
In order to do the above, we need to specify a relationship between Tj and Tu for each
j j = 1   m. It is important that there be some physical or practical justification for such
relationships. These relationships are the time transformation functions mentioned before, and
in principle are under the preview of subject matter specialists. Since specifying several rela-
tionships, one for each Tj, can be cumbersome, a simplifying strategy is to assume a common
general form over all the Tjs with the only variable being the Sjs. An example is the famous
Power Law Model in which for j = 1   m, the random quantities F jTjl, l = 1   k, are
related to each other via the unknown parameters 12 > 0 as:
F jTjl = exp−1S2
j Tjl	
(5.68)
here, F jt = PTj ≥t. Implicit to the above relationship is the assumption that the underlying
chance distribution is exponential.
Traditionally, the Power Law and other such time transformation functions such as the
Arrhenius and Eyring laws (Mann, Schafer and Singpurwalla, 1974), have been stated in
terms of the unknown parameters of the underlying chance distributions. The specification
of (5.68) is due to Blackwell and Singpurwalla (1988). It is a generalization of a tradi-
tional power law model for accelerated life-testing, namely, PTj > tj = exp−t/j, with
j = 1S2
j . Thus in F jTjl = exp−1S2
j t, we replace t by Tjl to produce the model
of (5.68). There are two advantages to our proposed model. One is that it is a relation-
ship between the observables like the Tjls instead of parameters like the j’s. The second
is that the model provides a framework for invoking a computationally efficient filtering
algorithm. A similar strategy may be adopted when the underlying chance distribution is a
Weibull. However, the filtering mechanism will entail computational difficulties due to non-
linearities.
The data from an accelerated life-test tjl, j = 1   m l = 1   k, is used to make
inferences about 1 and 2, and these in turn are used to a obtain predictive distribution for
Tu, namely PTu ≥tu. The Kalman filter model, also known as the Dynamic Linear Model
or a State Space Model, provides a nice mechanism for accomplishing the said inference.
The Kalman filter model is a general methodology with applications to other problems in
reliability. It is overviewed in section 5.8.2, following which I will continue with the problem
posed above. But first I give below another version of the accelerated life-testing problem, a
version that is prompted by scenarios in dose–response studies in the biomedical context, and
in damage assessment experiments in the engineering reliability context. This second version of
the accelerated life-testing problem is also amenable to analysis via a Kalman filter model.

ACCELERATED LIFE-TESTING AND DOSE–RESPONSE EXPERIMENTS
177
Dose–Response and Damage Assessment Studies
In dose–response studies, several subjects are treated to a dose, and the proportion of subjects
that respond to the dose are noted. The dose is a proxy for the stress in accelerated life-testing,
and the response could be a subject’s failure or survival. Thus in a dose–response experiment
the response is a binary variable, whereas in conventional accelerated life-testing the response
is the time to failure. The testing is done at several levels of the dose, and generally, these
levels are higher than the nominal dose. The aim is to make an inference about the subject’s
response at the nominal dose. In damage assessment studies, the situation is slightly different in
the sense that often it is not possible to test an item at any desired stress that is pre-specified; the
consequence that only one item can be tested at any level of the stress. The response in damage
assessment studies is a number between zero and one (both inclusive) indicating the extent of
damage done; often, the response is a subjective judgment. Here again, items are tested at the
several levels of the accelerated stresses, the aim being to assess damage at a nominal stress.
Both the dose–response and the damage assessment scenario can be formulated in a unified way
as described below. In the interest of clarity, the notation used below is different from that used
in the context of conventional accelerated testing.
Quantified values of the dose (or the damage inflicting stress) will be denoted by X, where
X takes values x 0 ≤x < . The response of a subject to a dose x will be denoted by Yx,
where 0 ≤Yx ≤1, for any x. In drug testing, wherein x denotes the dose that is administered
to a patient, the relationship between Yx and x is known as the potency curve or the dose–
response function. In the context of damage assessment, Yx = 0 implies the total demolition
of an item under study, and Yx = 1 denotes a total resistance to the damage causing agent. It is
reasonable to suppose that Yx is non-increasing in x, with Y0=1 and Y=0. Whereas one
can propose several plausible models for describing this behavior of Yx, the model I consider
here is of the form
EYx = exp−x
(5.69)
where  > 0 are unknown parameters. Alternate strategies involve taking a non-parametric
approach wherein no parametric function relating Yx to x is the sole basis of an analysis. More
about this is said later in section 9.3.
Observe that the right-hand side of equation (5.69) is the survival function of a Wiebull distri-
bution. Arguments that support this choice for a model are given by Meinhold and Singpurwalla
(1987), who illustrate its generality for describing the several possible shapes that EYx,
the expected dose–response function, can take. Figure 5.11, taken from the above reference,
illustrates this feature.
The data from a dose–response (or a damage assessment) experiment involving testing at doses
x1   xm will consist of the responses Yx1   Yxm. The pair xjYxj j = 1   m,
will be used in a Kalman filter model for making inferences about  and , and these in turn
will enable us to assess Yxu, the response at nominal dose xu. The specifics on how to proceed
with the above can be best appreciated once the Kalman filter model and the filtering algorithm
are introduced. I therefore digress from the problems at hand and return to them in section 5.8.3,
following an overview of Kalman filtering.
5.8.2
The Kalman Filter Model for Prediction and Smoothing
The Kalman filter model (KF) is based on two equations, an ‘observation equation’, and a
‘system or state equation’, with each equation containing an error term having a Gaussian
distribution with parameters assumed known. The observation equation, given below, says that

178
PARAMETRIC FAILURE DATA ANALYSIS
1.0
0.8
0.6
0.4
0.2
0.0
0.0
0.2
0.4
0.6
0.8
1.0
1.2
1.4
x
y
α = 1.0
β = 5.0
α = 0.5
β = 1.5
α = 1.0
β = 2.5
α = 2.0
β = 1.5
α = 4.0
β = 2.5
Figure 5.11
A Plot of EYx = exp−X for different choices of values of  and .
for some index, say xj, the response Yxj is related to an unknown state of nature xj, via the
relationship:
Yxj = Fxjxj + vxj
(5.70)
where Fxj is a known scalar. The quantity vxj is an error term, assumed Gaussian with mean
0 and variance Vxj, also assumed known; this is denoted as ‘vxj ∼N0Vxj′. The state of
nature xj is assumed to be related to its predecessor xj−1 via the system equation:
xj = Gxjxj−1 + wxj
(5.71)
where wxj ∼N0Wxj with Wxj assumed known. Also, the vxj and the wxj j =
12   , are serially and contemporaneously uncorrelated; furthermore, the Gxj is also
assumed known. For equation (5.71) to be meaningful, the xj’s need to be ordered, as say
x1 ≥x2 ≥··· ≥xj ≥···; this will ensure that the xj’s will also be ordered. Equations (5.70)
and (5.71) are given in scalar form; in principle, they could also be in vector form. Furthermore,
some, but not all, of the error theory assumptions can be relaxed to encompass inter-dependence
and non-Gaussianity; see, for example, Meinhold and Singpurwalla, (1989).
Traditionally, the KF model, which is comprised of the observation and the system equations,
is introduced and discussed with time as an index. My choice of the xj’s as indices is to facilitate
linkage with the accelerated life-testing scenario of section 5.8.1, in particular the dose–response
and the damage assessment models. Thus in what follows, it makes sense to replace xj by j, so
that Yxj is simply Yj and xj is j; similarly the other quantities. With the above notation in
place, suppose now that j−1 ∼N,j−1$j−1, for j = 12   ; for j = 1, we assume that ,0 and
$0 are user specified. Then, the KF mechanism yields the recursive result that on observing Yj,
j ∼N,j$j
(5.72)

ACCELERATED LIFE-TESTING AND DOSE–RESPONSE EXPERIMENTS
179
where ,j and $j are given by the forward recursive equations as:
,j = Gj,j−1 + KjYj −FjGj,j−1
$j = 1 −KjFjRj
Rj = G2
j$j−1 + Wj
and
Kj = RjFjF 2
j Rj + Vj−1	
(5.73)
the details, which entail a Bayesian prior to posterior updating, are in Meinhold and Singpurwalla
(1983).
The recursive nature of (5.72) makes it suitable for the situation wherein given any index j,
the focus is on predicting Yj+1 via inference about j, the latter being based on YjYj−1   Y1.
As an illustration, suppose that Fj = Gj = 1 for all j; then from (5.70) and (5.71) we see
that Yj+1 = j+1 + vj+1 = j + wj+1 + vj+1. But j ∼N,j$j, where ,j and $j are given by
(5.73). Consequently, given YjYj−1   Y1, we note that the predictive distribution of Yj+1 is a
Gaussian with mean ,j and variance $j + Wj+1 + Vj+1. Thus the KF model provides a recursive
mechanism for predicting the future values of an observable given its past values.
The above predictive scheme is appropriate in the context of a time series, that is, when
the index j represents time. A time series is a collection of observations that are obtained over
time; for example, the hourly temperature reading at a certain location. Once Yj+1 becomes
available, attention will shift to j+1 and Yj+2; the assessment of j, which has been based on
Y1Y2   Yj, will not be revised. On the other hand, for those situations wherein all the Yjs,
say m in all, are simultaneously presented, it is meaningful to base inference about any j on all
the available Yjs – not just Y1Y2   Yj. Such an approach is called Kalman filter smoothing,
and is appropriate in the context of dose–response and damage assessment studies wherein all
the Yjs are simultaneously available.
To describe the smoothing formulae, we need to slightly expand our notation. Let ,jm
and $jm denote the mean and the variance of the distribution of j based on m observations
Y1Y2   Ym. Then, it can be shown that the backwards recursion equations (Meinhold and
Singpurwalla, 1987) yield:
,jm =,jj + Jj+1,j+1m −Gj+1,jj and
(5.74)
$jm = $jj −Jj+1$j+1m −Rj+1Jj+1
where Jj = $j−1j −1GjRj−1 The details are in Appendix A of the paper mentioned above.
Note that ,jj and $jj are the mean and variance, respectively, of the distribution of j based
on Y1Y2   Yj alone, and are obtained via (5.73). The predictive distribution of Ym+1 will be
based on inference about m, namely, that m ∼N,mm$mm, with,mm and $mm given
by (5.74). This completes our review of the KF model.
5.8.3
Inference from Accelerated Tests Using the Kalman Filter
The time transformation functions of section 5.8.1 are natural candidates for prescribing the
observation equations of the Kalman filter model. Once this connection is made, and appropriate
change of variables introduced to ensure that the error theory assumptions of the underlying
KF models are satisfied, inference from accelerated life-tests proceeds, at least in principle, in a
straightforward manner; the details tend to get messy and are therefore kept to a minimum. To
see this, let us first consider the dose–response (damage assessment) scenario of section 5.8.1.

180
PARAMETRIC FAILURE DATA ANALYSIS
Filtering and Smoothing Dose–Response (Damage Assessment) Data
Recall the time transformation function of (5.69), namely EYx = exp−x, where
x ∈0 is the dose. To facilitate an application of the KF algorithm, we need to introduce a
transformation of Yx that has a Gaussian distribution. For this, we define a random variable
Y ∗x = log−logYx, and require that Y ∗x have a Gaussian distribution with mean x
and variance 2x. The merits of this transformation will become clear in the sequel, but for now
it suffices to say that with Y ∗x ∼Nx2xYx has what Meinhold and Singpurwalla
(1987) call a double lognormal distribution; its probability density at yx is of the form:
1
√
2xyx−logyx
exp

−
1
22xlog−logyx −x2


for 0 ≤yx ≤1
Figure 5.12 taken from Meinhold and Singpurwalla (1987) shows plots of this density for
different values of x = , and x = . These plots show the versatility of this distribution
to represent one’s subjective opinions about the damage phenomena in the 01 interval.
Properties of the double lognormal distribution are given in Meinhold and Singpurwalla
(1987). The one of immediate interest to us here is its mean EYxx2x, which for
small values of x is approximately exp−expx. However, EYx is also equal
to exp−x, and so EY ∗xx = x ≈log + logx. This relationship forms the basis
μ = 0
σ = 1
μ = –1
σ = 1
μ = 0.25
σ = 0.25
0.0
0.2
0.4
0.6
0.8
1.0
y
μ = –2
σ = 1
μ = 0.5
σ = 0.5
0
1
2
3
4
5
f ( y)
Figure 5.12
Plots of the double lognormal density for different combinations of values of  and .

ACCELERATED LIFE-TESTING AND DOSE–RESPONSE EXPERIMENTS
181
of our observation equation
Y ∗xj = log + logxj + vxj
(5.75)
with vxj ∼N0Vxj
If we let Fxj=1logxj, a row vector, and xj=jj′ =′
j, where j =logj,
then we may rewrite (5.75) in vector form as:
Y ∗xj = Fxjxj + vxj
This is our observation equation in vector form; it is identical to the form of (5.70) save for
the fact that Fxj and xj are vectors. To prescribe a system equation for the state of nature
xj, I use a commonly used strategy in Kalman filtering, namely that of employing the steady
model. Specifically, our system equation is written as:



j
=



j−1
+ wxj
(5.76)
where the vector wxj ∼N0Wxj. The above equation parallels that of (5.71) save for the
feature that the state of nature here is a vector quantity and the Gxj of (5.71) is a 2 × 2 identity
matrix Gj ≡I.
It is important to note that the unknown state of nature  is indexed by j, even though
our time transformation model did not postulate that the parameters change with dose. The
advantage of indexing the parameter vector by j is added flexibility; it makes allowances for
departures from the postulated time transformation function. In vector notation, the forward
recursion equations of (5.73) change, but only slightly. Specifically, j Rj and Kj become:
j = I −KjFjRj Rj = Gjj−1G′
j + Wj, and Kj = RjF′
jFjRjF′
j + Vj−1; the formula for ,j
remains the same, except that now it is a vector.
Although the dose levels for the experimental situation considered here may be ordered, there
is no reason to suppose that the experiments will be conducted in any particular dose order.
Thus inference is more reasonably conducted by smoothing than by filtering. However, in order
to invoke the smoothing algorithm, we need to specify, in addition to Vxj and Wxj, the
starting values ,0 and 0. The latter specification raises the issue of what dose level is to be
treated as x0, the dose from which the forward recursion process is to commence. One strategy
is to label x0 as that dose at which the analyst has the best prior knowledge about Yx0.
Presumably, this will be a high level of dose, because it is at such dose levels that information
is most readily available. As a potential starting value for 0, we may use (5.75) to observe that
for large x0 Y∗x0/logx0 ≈0. If xm is the smallest dose, then using the forward recursion
equations we filter from x0 to xm, and then use the backward recursion to smooth out the filtered
results; this will produce the collection ,j,j j = 01   m. The data used for filtering
and smoothing is the collection Y∗xjxj j = 1   m. The stability of the ,j’s and the
,j’s reflects the appropriateness of the time transformation function. When such is the case,
the smoothed ,m,m pair can be used for extrapolation to xu, namely to assess Yxu via
equations (5.75) and (5.76). Some ad hoc guidelines for choosing Vxj and Wxj are outlined
by Meinhold and Singpurwalla (1987).
Filtering Conventional Accelerated Life-test Data
We start with the time transformation function of (5.68), namely
Fj

Tjl

= exp

−1S2
j Tjl



182
PARAMETRIC FAILURE DATA ANALYSIS
and take logarithms on both sides to obtain
ln
-
−lnFj

Tjl


.
= ln 1 + 2 ln Sj + lnTjl
Letting v∗
jl = ln−lnFj

Tjl

 Y∗
jl = lnTjl Fj = −1−ln Sj, a vector, and jl =
ln 12, also a vector, the above equation may be rewritten as:
Yjl = Fjjl + v∗
jl
This relationship motivates us to consider a ‘tentative’ observation equation as
y∗
jl = Fjjl + v∗
jl
(5.77)
where y∗
jl is a realization of Y∗
jl.
Since Fj

Tjl

has a beta distribution, some straightforward calculations (details left as an
exercise to the reader) show that
EY∗
jl = l
n
l
 l−1

i=0
l −1
i
 
−1i
n −l + i + 1
!
−c −lnn −l + i + 1
where c ≈0577216 is Euler’s constant. Because Ev∗
jl ̸= 0, we subtract it from both sides of
(5.77) to write the observation equation as:
yjl = Fjjl + vjl
(5.78)
where yjl = y∗
jl −Ev∗
jl and vjl = v∗
jl −Ev∗
jl; this set-up ensures that Evjl = 0.
For the system equation, I propose the steady model
jl = Gjj−1l + wjl
(5.79)
where Gj is a 2 × 2 identity matrix I, and wjl is a vector w1jlw2jl whose elements are
Gaussian error terms with means 0 and covariance $w.
Based on an empirical analysis of some numerical results, Blackwell and Singpurwalla (1988)
are able to argue that for n as small as 10 and l close to n, vjl is approximately Gaussian. The
same is also true when n is greater than 10 and l is moderate to large. When n is large, say 25
or more, values of l as small as 6 will suffice to assume that vjl is approximately Gaussian.
Thus for small values of n – the number of items tested at each stress level – it is only the last
few failure times that can be used in the filtering algorithm. It therefore makes sense to test a
large number of items at low-stress levels.
Since the vjl’s are based on order statistics, it is reasonable to suppose that for any j, the
covariance between vjl and vjp l ̸= p will be non-zero. However, the covariance between
vjl and vpl j ̸= p can be assumed to be zero. That is, the error terms across stress levels are
independent but within stress levels they are not. When such is the case the filtering algorithm
tends to get involved; engineers refer to such scenarios as filtering in colored noise. Blackwell
and Singpurwalla (1988) discuss this type of filtering for the problem at hand. Should we ignore
the aforementioned covariance and assume independence of all the vjl’s, then one can invoke
the filtering algorithm of section 5.8.2 starting from the highest stress Sm and filter down to the
lowest stress S1 to obtain the joint posterior distribution of ln 1 and 2; this will be a bivariate
Gaussian. Once the above is at hand, inference about Tu follows along the lines indicated below.

ACCELERATED LIFE-TESTING AND DOSE–RESPONSE EXPERIMENTS
183
Let ln hu =ln 1 +2 ln Su; then ln hu has a Gaussian distribution with a mean u and variance
2
u. These quantities will depend on the bivariate Gaussian distribution of ln 1 and 2. This in
turn implies that hu will have a lognormal distribution with density phu. Consequently
PTu > t =


0
exp−thuphudhu
which is the Laplace transform of a lognormal distribution. Lindley and Singpurwalla (1986)
prescribe an approximation to this Laplace transform, which yields the result that
PTu > t ≈

ht
exp−h + 1
−1/h

5.8.4
Designing Accelerated Life-testing Experiments
In order to conduct an accelerated life test, an experimenter needs to choose several design
variables. With respect to the notation of section 5.8.1, the design variables are: m, the number
of accelerated stress levels at which to perform the tests; the values S1ldotsSm at which the
tests are to be performed; n, the number of items tested at each stress, and k, the number of
items to be tested until failure at each stress level, k ≤n. The design variables are under the
control of the experimenter, and the collection of all possible designs will be donoted by .
The purpose of this section is to prescribe a procedure for designing an accelerated life test,
where by ‘design’ I mean a specification of the elements of . However, in order to do so, we
must first describe a general principle for designing experiments. The essence of this principle
is grounded in the notions of mutual information and channel capacity; these were introduced in
section 5.5.1, but in the context of learning about an unknown parameter. From a more general
point of view, consider two random variables X and Y, whose joint probability density function
at x and y is pxy; let px and py be their marginal probability densities at x and y,
respectively. Then, by direct analogy with (5.51), the mutual information between X and Y is
defined as:
IX % Y = EXY

log pXY
pXpY


where the expectation is with respect to the joint distribution of X and Y, and pX denotes the
density of X evaluated at X; similarly, pY and pXY. How can IX % Y help us design an
experiment?
An answer to the above question lies in the considerations which originally motivated an
introduction of the notion of mutual information. In the coding theory framework, if X represents
the message to be sent and Y the message received by passing a coded version of X through a
channel corrupted by noise – such a channel being represented by pXY – then one strives to
find that channel for which IX % Y is a maximum. Recall that IX % Y is analogous to gn of
(5.47), and gn is the expected gain in utility. The maximum of IX % Y with respect to pXY
is the channel capacity. With the above in place, let us now turn our attention to the problem of
experimental design. Here the experimenter controls the design variables in . Let A ∈, and
suppose that the information contained in Y about X varies with A. I denote this dependence
of X on both Y and A by pX  YA. The quantity pX  YA is like a channel in coding
theory, and the experimenter can choose from a family of channels pXYA	A ∈. Then,

184
PARAMETRIC FAILURE DATA ANALYSIS
the criterion would be to choose that A, say A∗, for which the mutual information about X and
Y is maximized. That is, we seek the A∗which yields
max
A∈ EXYA

log pXYA
pXpYA


(5.80)
An equivalent way of writing the above is
max
A∈ EYAEXYA

log pXYA
pX

	
(5.81)
the details are left as an exercise for the reader.
To invoke the above principle in the context of an experimental design whose aim is predicting
a future observation Yn+1 (which depends on the design variables in ), given Y =Y1   Yn,
we replace X by Yn+1 and Y by Y in (5.81) to write
max
A∈ EYAEYn+1YA

log pYn+1YA
pYn+1

	
(5.82)
pYn+1  YA and pYn+1 are the conditional (on Y and A) and the unconditional predictive
densities of Yn+1, respectively.
This summarizes our discussion of the general principle for designing experiments when the
aim of experimentation is predicting a future observable. If the object of experimentation is
inference about some parameter  which depends on the elements of  as well as Y, then in
(5.82) Yn+1 is replaced by . I now consider the special scenario of invoking this principle in the
context of designing an accelerated test.
Maximizing Mutual Information in Accelerated Tests
The principle underlying (5.82) is easiest to implement when the underlying predictive distribu-
tions are Gaussian and when the dependence of the predictive random variable on A is linear.
Thus it is best that we make some changes to the accelerated life-testing model of section 5.8.1.
Specifically, let us suppose that the Tjls, j = 1   m l = 1   n, have a lognormal dis-
tribution with parameters j and 2
j . This would imply that the ln Tjl’s will have a Gaussian
distribution with mean j and variance 2
j . The lognormal as a chance distribution for lifetimes
has sometimes been considered as an alternative to the Weibull. For the time transformation
function, we consider as before, the Power Law model of the form
ETjlj2
j  = exp

j +
2
j
2

= c
SP
j

where c > 0 and P ≥0 are unknown parameters.
If we let'zjl =ln Tjl a=ln c b =−ln P and Vj =ln Sj, then the above Power Law relationship
becomes zjl = a + bVj −2
j /2 + &jl, where &jl ∼N02
j . Further simplification is achieved, but
without a compromise in generality, if the 2
j ’s are assumed known, j = 1   m. Specifically,
if zjl ='zjl + 2
j /2, then the Power Law-based time transformation function becomes
zjl = a + bVj + &jl
(5.83)
with &jl ∼N02
j  j = 1   m l = 1   n.

ACCELERATED LIFE-TESTING AND DOSE–RESPONSE EXPERIMENTS
185
If z denotes the vector of all the zjl’s, the vector  = ab′, and the design matrix A
A =
 1   1
1   1
···
1   1
V1   V1
V2   V2
···
Vm   Vm

then, in matrix form, (5.83) becomes z = A + , where the vector  is a multivariate Gaussian
with mean vector 0 and covariance matrix 	  is a diagonal matrix with diagonal terms
2
1In2
2In   2
mIn, and In is an n × n identity matrix.
For the prior on , we assume that  ∼N00 where 0 = a0b0′ is specified and so is
0 =
2
a ab
ab 2
b


the variance-covariance matrix of a and b.
Our aim is to predict Tu, the time of failure under Su, and with 2
u assumed known, interest
will therefore be focused on Zu = ln Tu + 2
u/2. For doing so, we invoke (5.82) to find that A,
say A∗which maximizes
EZAEZuZA

log pZuZA
pZu


(5.84)
In Verdinelli, Polson and Singpurwalla (1993), it has been shown that maximizing (5.84) reduces
to minimizing the variance of the predictive distribution of Zu given Z and A, with respect to A.
That is, we need to minimize the quantity
s2 = 1VuA′−1A + −1
0 −1
 1
Vu

+ 2
u
(5.85)
with respect to the design matrix A.
A consideration of some special cases in which the result of (5.85) is invoked yields some
interesting conclusions. For example, when c = m = 1, that is, it is possible to test at only one
accelerated stress level S1, then
s2 = 2
1
n +
V 2
u
V 2
1 +  + 2
u
where  = 2
1n2
b−1. Thus s2 is minimized when V1 is as large as possible.
With C and P unknown, but with m still one,
s2 = V1 −Vu2 + b + V 2
u a
1 + aV 2
1 + b −V 2
1
+ 2
u
where a = 2
1/n2
a and b = 2
1/n2
b. Thus, it is V1 = 1 + aVu that minimizes s2
The above special cases, though unrealistic, illustrate the kind of results that the maximization
of mutual information principle yields. More research involving an application of these ideas to
scenarios other than that considered here is needed. Polson (1992) provides a broad perspective
and indicates several possibilities involving inference about parameters of time transformation
models, censoring, step-stress testing and the treatment of binary data.
I conclude this chapter by acknowledging the fact that much of what I have presented has some
way to go before it can be implemented for day-to-day use. This presents several opportunities
for others to embark on more detailed investigations into the scenarios that interest them and
under conditions that are more realistic than those considered by us. My purpose here has been
to indicate how one may think about life-testing and reliability using some of the more modern
ideas that probability and statistics have to offer.


Chapter 6
Composite Reliability: Signatures
Here lies Isaac Newton: A body at rest shall remain at rest.
6.1
INTRODUCTION: HIERARCHICAL MODELS
Hierarchical modeling was alluded to in section 2.6.1 as an expansion of the prior P,
using the law of total probability. Specifically, for some parameter, say , we may invoke the
law of total probability on P to write (2.4) in an expanded form as
PXn =


n
i=1
fXi  


P  P
(6.1)
where P is a prior on . The scalar or vector  is known as a hyperparameter. The
model of (6.1) is a two-stage hierarchical model because the probability law of Xn entails the
operation of extending the conversation two times, the first to  and then to . In principle, I may
continue the above process by expanding P using another set of hyperparameters, so that
the hierarchy of modeling gets enlarged from two stages to three, and so on. From a subjectivistic
point of view, the motivation for constructing hierarchical models is ease of specifying P
via a consideration of . In other words, a hierarchical approach facilitates the specification of
probability models by a step-by-step breakdown of the underlying uncertainties. In practice, one
often does not go much beyond a two-stage model unless the physics of the situation is such that
it becomes meaningful to do so. The Kalman Filter model of section 5.8.2 (more details about
which can be found in Meinhold and Singpurwalla (1983)) is perhaps one of the best-known
examples of a hierarchical model. The observation (5.70) encapsulates the first stage of the
hierarchy, and the system (5.71) the second stage. From a practical point of view hierarchical
models have, in many cases, provided a better predictive capability than single stage models,
the success of the Kalman Filter being a prime example. A unifying perspective on statistical
modeling via a step-by-step hierarchical expansion is described in Singpurwalla (1989).
Reliability and Risk: A Bayesian Perspective
N.D. Singpurwalla
© 2006 John Wiley & Sons, Ltd

188
COMPOSITE RELIABILITY: SIGNATURES
The purpose of this chapter is twofold. The first is to introduce the notion of ‘composite
reliability’, and the second to introduce a technology called ‘signature analysis’, which reliability
engineers and medical practioners find useful. Both entail hierarchical modeling.
6.2
‘COMPOSITE RELIABILITY’: PARTIAL EXCHANGEABILITY
By ‘composite reliability’, I do not mean the reliability of composite materials. Rather, what I
have in mind here is an omnibus measure for characterizing the trustworthiness of a collection of
unidentical, but similar, items. What has prompted me to introduce and to consider the notion of
an overall reliability? It is that often decision makers in government, industry and public policy,
and also the public at large, are more concerned about the collective trustworthiness of groups
of similar items rather than the trustworthiness of a single or a particular group of items. Some
examples to highlight this matter are: the reliability of automobiles made in the US, the safety of
nuclear power plants, the quality of European medical equipment, etc. Indeed, it was the matter
of nuclear power plant safety that motivated our interest in coming up with a way to describe
overall reliability. Individual power plants may be safe and reliable, but what can we say about the
collective behavior of the power plants given that they differ in design and operating procedures?
Similarly, with automobiles. All compact cars could be judged exchangeable with each other,
but not with mid-sized and full-sized cars. Yet regulators and consumer advocates may want to
know if the automobile industry, taken as a whole, is providing reliable automobiles. Then of
course there are claims such as cars made in Sweden are safer than their Korean counterparts,
and that Japanese autos are more reliable than those made in the US.1 How can we quantify
and make precise statements such as these? Certainly, some brands of US-made cars are more
reliable than certain brands of cars made in Japan. Similar is the case when it comes to quality
and safety. Thus what I need here is a mechanism via which heterogenous but similar groups
of items can be compared vis-à-vis their reliability. One such mechanism is via the notion of
composite reliability described below. This notion has been introduced and discussed by Chen
and Singpurwalla (1996), who were motivated by the problem of assessing the reliability of
emergency diesel generators used in nuclear power plants. Some related work is in a paper by
Arjas and Bhattacharjee (2004), who focus on inter-failure times encountered in a longitudinal
analysis of value failures in nuclear power plants.
To appreciate the notion of ‘composite reliability’, we start by re-visiting the notion of
reliability, or chance, discussed in section 4.4. However, we focus attention here on the case of
Bernoulli random variables, Xij i = 1   k j = 1   ni. Here Xij takes the value 10 if
the j-th item in the i-th group survives (fails) its mission time. We suppose that for each i, the
Xijs, j = 1    ni are exchangeable. That is, all the Xs within the i-th group are exchangeable.
Then, given pi, the reliability (or chance) of the items in the i-th group, i = 1   k, the
Xijsj = 1   ni would be independent and identically distributed Bernoulli random variables
with parameter pi, so that
PXi1 = xi1   Xini = xini =
1

0
ni
j=1
p
xij
i 1 −pi1−xijFdpi
(6.2)
see Theorem 3.2 of section 3.1 (de Finetti’s Theorem). Fdpi describes our uncertainty about
the pi that generates Xi1Xi2   Xini; 0 < pi < 1	
1 See, for example, an article in The Washington Post dated March 10, 2004, wherein it is stated that ‘For the first time in 25
years, U.S. carmakers can say that they make more reliable cars than their competitors in Europe. Asian manufacturers still hold
top bragging rights, however’.

‘COMPOSITE RELIABILITY’: PARTIAL EXCHANGEABILITY
189
To relate the Xi1   Xini to Xk1   Xknk, for all k̸=i, we create a hierarchical architecture.
This we do by supposing that the pi’s themselves are dependent random drawings from some
joint distribution whose nature is described below, by (6.3). Specifically, we assume that given a
(scalar or vector) parameter 
, the pi’s are independent and identically distributed with a density
1p  
 at p, 0 < p < 1. Then unconditionally, the joint density of p1   pk at p∗
1   p∗
k
will be of the form
p∗
1   p∗
k =


k
i=1
1p∗
i  
Fd

(6.3)
where Fd
 describes our uncertainty about 
.
The model of (6.3) makes the pi’s exchangeable, and the quantity 1p
 is the chance
distribution that generates the pi’s. By analogy with the interpretation of (2.4) of Chapter 2, we
call this chance distribution composite reliability. Thus:
Composite Reliability is a Chance Distribution
that generates the individual chances associated with an observable subsequence of exchangeable
lifetimes in a partially exchangeable sequence.
The marginal distribution of pi, obtained via (6.3), gives us the Fdpi of (6.2); thus the linkage
between reliability and composite reliability. Under the models of (6.2) and (6.3), the Xijs,
j = 1   ni, provide information about the pi that generated them, and collectively, the Xijs,
i = 1   k, j = 1   n provide information about the 
 that generates the pi’s. Since the
composite reliability is a (chance) distribution, we may compare the composite reliabilities of
two groups of items by comparing their respective chance distributions. Specifically, suppose
that F1dp denotes the distribution function corresponding to a chance distribution 1p  
 and
F2dp the distribution function corresponding to, say, 2p  
. Then the composite reliability
of the group of items whose lifetimes are a consequence of 1p  
 is greater than the composite
reliability of items whose lifetimes are a consequence of 2p  
, if F1dp ≤F2dp for all
p ∈01.
6.2.1
Simulating Exchangeable and Partially Exchangeable Sequences
It was mentioned before that a linkage between reliability and composite reliability is achieved
by putting together (6.2) and (6.3). The schemata of Figure 6.2 illustrates the mechanics of
how this can be done. Indeed Figure 6.2 can be seen as a roadmap for simulating the partially
exchangeable Bernoulli sequence Xij i=1   k j =1   ni. However, to better appreciate
the anatomy of Figure 6.2, it is helpful if we first consider the simulation of an exchangeable
Bernoulli sequence, say X1   Xn, constructed via the process of (6.2). That is, for any i,
i = 1   n, xi = 0 or 1, and p ∈01,
PXi = xi =
1

0
pxi1 −p1−xiFdp	
(6.4)
Figure 6.1 illustrates the mechanics of simulating the process corresponding to (6.4).
The ui and vi in Figure 6.1 denote sequences of mutually (and also contemporaneously
over i) independent uniformly distributed random deviates on 01. Each ui in conjunction with
the prior Fdp generates a pi, and in turn each pi, in conjunction with the Bernoulli chance
distribution pxi
i 1 −pi1−xi and a vi, generates a Bernoulli xi. This cycle is repeated n times.

190
COMPOSITE RELIABILITY: SIGNATURES
Prior on 
chance p
F(dp)
pi
pi
xi (1 –  pi)1−xi
n times
Bernoulli 
chance distribution
{vi}
{ui}
xi , i = 1, . . . , n
Figure 6.1
Simulating an exchangeable Bernoulli sequence.
wij
ui
vi
pi
ηi
Prior on the
hyperparameter η
F(dη)
pi
xi (1 − pi)1−xi
xij, i = 1, ... , k
j = 1, ... , ni
ni times
Bernoulli
chance distribution
π (p | ηi)
k times
Composite
reliability
Figure 6.2
Simulating a partially exchangeable Bernoulli sequence.
The process of repeatedly generating a pi becomes the equivalent of weighting pxi1 −p1−xi by
Fdp of (6.4), for a range of values of p, 0 < p < 1.
An expansion of Figure 6.1 to encompass the generation of a sequence 
i i = 1   k,
results in Figure 6.2, which is a roadmap for generating the partially exchangeable sequence
Xij i = 1   k, and j = 1   ni. The sequence wi is like the sequences ui and vi, a
collection of independent uniformly distributed random variables on 01. The role of composite
reliability as being an intermediary between the prior Fd
 and the Bernoulli chance distribution
pxi
i 1 −pi1−xi is now transparent.
6.2.2
The Composite Reliability of Ultra-reliable Units
The purpose of this section is to illustrate the foregoing material by developing a specific model
for the composite reliability, and its associated priors. The development here is based on Chen
and Singpurwalla (1996), who were interested in a scenario involving highly reliable units,
namely emergency diesel generators used in nuclear power plants. Let i = 1 −pi denote the
unreliability of the units in the i-th group, i = 1   k; i.e. PXij = xij  i = 
1−xij
i
1 −ixij,
for xij = 0 or 1. We suppose, as is reasonable to do so, that each i is small. That is, the units in
each group are highly reliable. Thus a model for the composite reliability should be such that the

‘COMPOSITE RELIABILITY’: PARTIAL EXCHANGEABILITY
191
i’s it generates should take small values. Our strategy for doing this comprises of two stages;
this I shall describe in the sequel.
Our proposed model (for composite unreliability) has a density at  which is  with parameters

 and 1, i.e.
1  
 = 

 + 1
−11 −
0 <  < 1	
(6.5)
Figure 6.3 illustrates this density for different values of 
.
The model 1  
 illustrated in Figure 6.3 is motivated in two stages. In stage one, we
assume that the probability density of  is L-shaped, with an upper bound , where  < 1
(Figure 6.4). This is best expressed via
0  
 = 

−1/

for 0 <  < 
where 
 and  are hyperparameters. Verify that 0  
 is a beta density on 0 with
parameters 
 and 1. To reflect the belief that small values of  are much more likely than large
values, we require that 
 ∈01. Observe that 0  
 becomes approximately uniform on
0 as 
 →1.
In stage two, I prescribe a model for , the upper bound on . Since it is unlikely that  will
take values that are very small, a meaningful model for  is one wherein its probability density
is uniform with a steep decrease in the vicinity of zero. A way to achieve this is via a beta
density over 01 with parameters  and 1, with  taking values greater than but close to one.
That is, the probability density at  is of the form
  1 ∝−1
0 <  < 1	
One way to ensure that  is greater than one, and yet close to it, is to let  = 1 + 
. An
advantage of this choice is that all that remains to be assessed for the two-stage development
described above is the single parameter 
. With 0  
 and   1 as specified, it
0
1
2
3
4
0.2
0.4
0.6
0.8
1
π1(θ | η)
η = .5
η = .25
η = .05
η = 1
θ
Figure 6.3
Models for the composite reliability of ultra-reliable items.

192
COMPOSITE RELIABILITY: SIGNATURES
0
2
4
6
8
0.25
0.5
0.75
1
θ
η = .05
η = .25
η = .5
π0 (θ | η, γ)
Figure 6.4
Probability density of  for different values of 
, with  = 0	75.
is easy to verify that unconditionally (on ),  has the model of (6.5). More discussion on this
choice as a model for the unreliability (or the composite unreliability) of ultra-reliable items is
given in section 2.1 of Chen and Singpurwalla (1996).
With 1  
 specified, our next task is to obtain a joint distribution for 1   k.
To do so, we follow the steps leading to (6.3). This entails specifying a prior distribution
for 
, Fd
. Since 
 ∈01, a suitable choice for Fd
 would be a beta density on
01 with hyperparameters 1 and 2, where 1 and 2 are so specified that values of 
close to zero get emphasized (Figure 6.3). A natural choice would be to set 1 = 2 = 1, so
that Fd
 is a uniform distribution on 01 (sections 5.2.3 and 5.3.2). With the above in
place, the joint density of the i’s at 1   k becomes the analogue of (6.3); it takes the
form
1   k  12 =
1

0

k
i=1


 + 1
−1
i
1 −i

Fd
12	
(6.6)
6.2.3
Assessing Reliability and Composite Reliability
The aim of this section is to discuss an assessment of the pi’s, i = 1   k, and the 1p  

of section 6.2, in the light of data. Since pi = 1 −i i = 1   k, and since the i’s are viewed
as independent drawings from 1  
 (section 6.2.2) assessing the i’s and 1  
 is
equivalent to assessing the pi’s and 1p  
. In what follows we shall discuss an assessment
of the i’s and 1  
 because the models of section 6.2.2 have been motivated in terms of
these quantities.
Suppose, then, that the observed data, say d, consists of xij j = 1   ni i = 1   k.
Let yi =
ni
j=1
xij i = 1   k and  = 1   k. Since PXij = xij  i = 
1−xij
i
1 −ixij,

SIGNATURE ANALYSIS AND SIGNATURES AS COVARIATES
193
the likelihood of  in the light of d, assuming that the stopping rule is non-informative, is
k
i=1
ni−yi
i
1 −iyi. Consequently, the posterior distribution of  and 
 is given as

d12 ∝d
k
i=1


 + 1
−1
i
1 −iFd
  12
where d denotes the likelihood given above. An attractive feature of this posterior distri-
bution is that it lends itself to an evaluation of the posterior distributions of the i’s i=1   k,
and of 
, via the Markov Chain Monté Carlo method of Appendix A. The specifics of how this
can be done is left as an exercise for the reader.
The posterior distribution of each i i = 1   k, represents our assessment of the unrelia-
bility of the items in group i. The posterior distribution of 
 enables us to numerically obtain
E
d12, its mean. This mean, when plugged into (6.5) replacing 
, provides an estimate
of 1
, which then becomes our assessment of the composite unreliability. See the end
of section 5.4.4 for the rationale behind the substitution of E
d12 for 
. Comparing
composite unreliabilities is isomorphic to the comparison of composite reliabilities.
6.3
SIGNATURE ANALYSIS AND SIGNATURES AS COVARIATES
Defects in certain physical and biological items sometimes manifest themselves as oscillary
periodic motions, like vibrations, or as electrical signals, like leakage currents and voltages.
For example, rotor imbalance in rotating machinery causes an excessive wear on the bearings
and this in turn leads to vibrations that cause damage to electrical insulations and a general
discomfort to humans. In the biomedical context, an electrocardiogram (ECG) – which measures
changes in the electrical potential produced by contractions of the heart – is used by physicians
to assess the condition of the heart muscle. Vibration signals are generally recorded in the time
domain as a time series (section 5.8.2). Similarly, the ECG is a time domain plot of the voltage;
the shape and the pattern of this plot reveal deficiencies. Such time domain plots are known
as signature data, and signature analysis is an interpretation of the signature data. For reasons
that will become clear in the sequel, it is common to interpret signature data in the frequency
domain through its ‘power spectrum’ which is then referred to as the signature.2 The power
spectrum, which is introduced and discussed in Appendix B, is a graphical display of ‘frequency’
(on the horizontal axis) versus ‘amplitude of the spectrum’ (on the vertical axis). The goal of
signature analysis is to identify particular types of defects, if any, and to assess their relative
impact on an item’s survival. In the context of an ECG, large amplitudes at high frequencies are
indicators of potential medical problems. As an example, I illustrate via Figure 6.5 the estimated
power spectrum of a patient’s ECG-generated signature data, prior to and post heart surgery
(Pierce et al., 1989). The effect of surgery has been a dampening of the large amplitudes at all
frequencies (expressed as Hz – see Appendix B), suggesting a positive impact of the surgical
intervention.
Figure 6.5 is but one illustration of the usefulness of signatures, namely comparison and
classification. More importantly, signatures provide a snapshot of several defects that otherwise
might be difficult to observe directly. In the case of rotating machinery, the frequency at which
the amplitude (of the spectrum) takes a large value indicates the nature of the defect, and the
2 Not to be confused with the notion of the signature of a coherent system, discussed by Boland and Samaniego (2004).

194
COMPOSITE RELIABILITY: SIGNATURES
30
60
90
120
150
Frequency (in Hz)
0.00
0.02
0.04
0.06
0.08
0.10
30
60
90
120
150
Frequency (in Hz)
0.00
0.02
0.04
0.06
0.08
0.10
Amplitude
Amplitude
(b) Post-surgery
(a) Pre-surgery
Figure 6.5
Estimated pre- and post-surgery signatures.
magnitude of the amplitude indicates the severity of the defect. Thus, for example, a large
amplitude at a frequency corresponding to one times the motor running speed suggests an imbal-
ance, whereas a large amplitude at two times the motor running speed suggests misalignment.
Similarly, the signature of an ECG can reveal the nature of heart disease and the extent of the
disease.
Whereas an examination of the signature can help one identify the nature and the magnitude of
defects, it cannot by itself help assess the impact of the identified defects on an item’s lifelength.
To do so, we need to link signature analysis with the techniques of life-data analysis. This we
are able to do by treating the signature as a covariate (section 4.9). The motivation here would be
to explore the relative impact of the defects on an item’s lifelength and to explore as to whether
the defects tend to have an additive effect or if they tend to cancel out. For example, in the case
of rotating machinery, would a small amount of imbalance be more deleterious to lifetime than a
large amount of misalignment, or would imbalance and misalignment taken together cancel out
the deleterious effect of each defect?
The aim of this section is to describe a hierarchical Bayesian approach for obtaining signatures
and for harnessing the import of such signatures for lifelength prediction. It is our view that
signatures provide a powerful diagnostic and assessment tool in survival analysis, a tool whose
potential remains to be fully exploited in reliability theory and life-data analysis. What I attempt
to describe here are a few preliminary efforts. But to do so, I need to highlight some standard
material on ‘Fourier series models’, and the spectrum of a periodic function. This I do below
in section 6.3.1 assuming that the reader is familiar with trigonometric functions, Fourier series
models and the power spectrum, which for convenience are described in Appendix B. The
material in Appendix B is abstracted from Anderson’s (1971) classic treatise on time-series
analysis.

SIGNATURE ANALYSIS AND SIGNATURES AS COVARIATES
195
6.3.1
Assessing the Power Spectrum via a Regression Model
Let Yt denote the observed value of a variable of interest, such as the displacement due to
vibration or the voltage of a heart muscle at time t t = 1   T. For purposes of discussion
suppose that T is odd, and that Yt is described via the regression model
Yt = ft + t
(6.7)
where ft is an unknown periodic function with a known period T. For example, T could be
the time taken by a motor to complete a revolution or the time taken by the heart muscle to
complete a pumping cycle. The error t is assumed to be Gaussian with mean 0 and variance
2; also, the sequence t is uncorrelated.
Our aim is to explore if there are hidden periodicities in ft, i.e. periodicities in addition to
the one that is known to be T. As mentioned before, hidden periodicities could be deleterious to
an item’s survival. To identify the hidden periodicities we approximate ft by a Fourier series
model of the form:
ft = 0 +
q
j=1
	
mjcos
	2
T mjt

+ mjsin
	2
T mjt



(6.8)
where 1 ≤q ≤T −1/2, and m1m2   mq is a subset of I = 12   T −1/2 – see
equation (B.3) in Appendix B. The mj and mj are unknown and have to be estimated
from the Yts; they are the amplitudes of the cosine and sine curves having periods T/mj and
frequencies mj/T, j = 1   q. The summand q and the subset m1   mq are chosen in
accordance with our prior beliefs about the number and the order of the hidden periods. A plot
of 2mj
def
= 2mj + 2mj versus the frequency mj/T, j = 1   q is the power spectrum
of ft (section B.4 of Appendix B). Our aim is to describe a Bayesian approach for assessing
the power spectrum using the Yts; this tantamounts to assessing 0, the mj’s, and the
mj’s, j = 1   q.
The problem described above has a rich legacy within the frequentist paradigm. For example,
Anderson (1971, p. 105) describes a least-squares approach for estimating the unknowns 0,
mj and mj, and discusses the properties of the estimators. It makes for some fascinating
reading and sets the tone for what can be done using a Bayesian approach. But before I prescribe
our Bayesian approach, it may be helpful to remind the reader that what we are looking for are
large values of 2mj because these are a measure of how closely the trigonometric functions
having period T/mj describe the data. In essence, signature analysis pertains to identifying those
periods T/mj at which 2mj is large, because it is such periods that give us clues about the
nature and the magnitude of defects.
6.3.2
Bayesian Assessment of the Power Spectrum
For the model of section 6.3.1 as encapsulated via the regression model of (6.7) and (6.8), we
start by defining the vectors
F ′
t =
	
1cos
	2
T m1t

 sin
	2
T m1t

   cos
	2
T mqt

 sin
	2
T mqt



′ =

0m1m1   mqmq


and the scalar  = 1/2.

196
COMPOSITE RELIABILITY: SIGNATURES
Then (6.7) and (6.8) boil down to the statement that
Yt   ∼N F ′
t1/
(6.9)
where N2 denotes a Gaussian distribution with mean  and variance 2. The quantity 
is called the precision of the normal distribution; it is the reciprocal of the variance.
The vector  needs to be endowed with a prior, and so does the scalar . For this, we suppose that
   ∼N

0−1R0

 and that
(6.10)
 ∼G
	n0
2  d0
2


where G denotes a gamma distribution with shape  and scale  (section 5.4.6). The
quantity 0 is the mean vector of the Gaussian distribution of , and −1R0 is its covariance
matrix. The quantities 0 R0 n0 and d0 have to be specified by us and should reflect our prior
beliefs about the order and the extent of the hidden periodicities. The elements of the covariance
matrix −1R0 should reflect our strength of conviction about our specified 0. The motivation
for multiplying R0 by −1 in the Gaussian distribution of  is to make the variances of the
components of  free of the scale used for measuring the Yt. The motivation for using n0/2
and d0/2 as the shape and scale parameters of the gamma distribution is that this choice makes
d0 have a chi-square distribution with n0 degrees of freedom.
Specifying a Prior for the Power Spectrum
The following ground rules for specifying 0 and −1R0 may be helpful.
Should our prior belief be such that there are no hidden periodicities exhibited by the item in
question, then all the elements of 0 should be zero. This could also be seen as a reasonable
choice for a default prior. In the case of rotating machinery, if an imbalance is suspected then
the second and third elements of 0, i.e. the elements corresponding to m1 and m1, would
be assigned the same non-zero value, the value being reflective of the extent of imbalance that
is perceived, similar is the case of misalignment. In essence, specifying a meaningful prior for
 through a judicious choice for 0 will entail a good knowledge of how defects manifest
themselves in the power spectrum, be it in the context of an ECG or a physical item.
With 0 set at its default value 0, the elements of the covariance matrix −1R0, when non-
zero, should be large and decreasing in value with the harmonics of the fundamental frequency
H1 – (section B of Appendix B). This is because it is often the case that the observed spectra of
many time series tend to reveal no amplitudes at large frequencies. It may also be meaningful
to suppose that covariances of the coefficients associated with any two harmonics is zero.
For the paired coefficients within each harmonic, the corresponding variances are set equal,
and the correlation set to be a neutral 0	5. That is, Varmj = Varmj = Vmj and
Covmjmj = 0	5Vmj j = 1   q. Since Vmj is to be a decreasing function of mj,
one plausible choice would be to let Vmj = −1 exp−kmj for some positive k > 0. I denote
the above as Vmj = −1r0mj. Thus, our proposed default values for 0 and −1R0 are:
0 = 0   0′ and
−1R0 =
⎡
⎢⎢⎢⎢⎢⎢⎢⎣
r00
0
0
0
r0m1
0	5r0m1
0
0
0	5r0m1
r0m1
			
0
r0mq
0	5r0mq
0	5r0mq
r0mq
⎤
⎥⎥⎥⎥⎥⎥⎥⎦
	

SIGNATURE ANALYSIS AND SIGNATURES AS COVARIATES
197
For parameters n0 and d0 of the gamma prior on , the choice n0 =2 and d0 =3 would ensure
a strong belief about the rationality of (6.7); this would tend to make  have a small variance.
Another possibility would be to let n0 = d0 = 0, in which case the prior on  is non-informative.
However, this non-informative prior does not adversely affect the updating mechanism.
Posterior Power Spectrum Under the Regression Model
Let the observed data be denoted by the vector Yt = Y1   Yt′ and let Ft = F ′
1   F ′
t
be a 2q + 1 × t matrix. Then upon observing Yt, a standard application of Bayes’ law to (6.9)
and (6.10) leads to the claim (cf. DeGroot 1970, p. 249) that the posterior distribution of ,
given , is of the form
  Yt ∼N

t−1Rt


(6.11)
where t = RtFtYt + R−1
0 0, and Rt = FtF′
t + R−1
0 −1	
Also, the posterior distribution of  is
Yt ∼G
	nt
2  dt
2


where nt = n0 + t, and
dt = d0 + Y′
tYt + ′
0R−1
0 0 −FtYt + R−1
0 0′RtFtYt + R−1
0 0	
Averaging out  in (6.11) with respect to its posterior distribution leads us to the result that
Yt ∼Tnt
	
tRt
dt
nt


(6.12)
i.e. the posterior distribution of  is a multivariate Student’s t distribution in dimension 2q + 1
with n0 + t degrees of freedom with a mode t and a scale matrix Rtdt/nt (DeGroot, 1970,
p. 59) for a description of the multivariate Student’s-t distribution. A consequence of (6.12) is
that the i-th element of  has a univariate Student’s-t distribution whose mode is the i-th element
of t and whose scale is the i-th diagonal entry of the scale matrix Rtdt/nt.
For a posterior assessment of the power spectrum what we need is the posterior distribution
(given Yt) of the vector

2m1 + 2m1

   

2mq + 2mq

	
Obtaining this posterior distribution turns out to be a formidable task unless one resorts to
a MCMC-based simulation (Appendix A); and even this would be a cumbersome endeavor.
However, in Campodónico and Singpurwalla (1994b) an expression for the marginal poste-
rior distribution of 2mj
def
= 2mj + 2mj is obtained (Appendix B of Campodónico and
Singpurwalla, 1994b) from which E2mjYt, the mean of this posterior, can be assessed.
This turns out to be
E2mjYt = t

mj
2 + t

mj
2 +
dt
nt −2

rtmj + rtmj


(6.13)
j = 1   q where t

mj

and t

mj

are the elements of the vector t which corre-
spond to the posterior expected values of mj and mj, and rtmj and rtmj are the

198
COMPOSITE RELIABILITY: SIGNATURES
diagonal elements of the matrix Rt associated with mj and mj. A plot of E2mjYt
versus mj/T j = 1   q, could be used as a posterior Bayes assessment of the power spec-
trum. In principle of course, a proper Bayesian assessment of the power spectrum would be a
q-dimensional surface representing the posterior distribution of the vector 2m1   2mq,
but this would be of little practical value in terms of linkage with survival analysis.
6.3.3
A Hierarchical Bayes Assessment of the Power Spectrum
As an alternative to the model prescribed by (6.7) and (6.8), we may entertain a hierarchical
Bayes–Kalman Filter-type model with an observation equation:
Yt = t0 + tm1 + tm2 + ··· + tmq + t
and a collection of system equations:
t0 = t−10 + vt0
tm1 = t−1m1cos
	2
T m1

+ t−1m1sin
	2
T m1

+ vtm1
tm1 = −t−1m1sin
	2
T m1

+ t−1m1cos
	2
T m1

+ wtm1
			
tmq = t−1mqcos
	2
T mq

+ t−1mqsin
	2
T mq

+ vtmq
tmq = −t−1mqsin
	2
T mq

+ t−1mqcos
	2
T mq

+ wtmq	
In matrix notation, the observation and system equations are written as
Yt = F′t + t
and
(6.14)
t = Gt −1 + Wt
(6.15)
where F, t and Wt are vectors of dimension 2q + 1 taking the form:
F′ = 11010   10
′t =

t0tm1tm1   tmqtmq

 and
Wt =

vt0vtm1wtm1   vtmqwtmq


G is a 2q + 1 × 2q + 1 matrix of the form
G =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
1
0
0
0
cos
 2
T m1

sin
 2
T m1

0
0
−sin
 2
T m1

cos
 2
T m1

			
0
cos
 2
T mq

sin
 2
T mq

−sin
 2
T mq

cos
 2
T mq

⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
	

SIGNATURE ANALYSIS AND SIGNATURES AS COVARIATES
199
The formulation of (6.15) and (6.15) results in a Fourier series model of the form discussed in
section 6.3.1. This can be verified by first invoking the relationship of (6.15) t times, to observe
that
t = Gt0 + t
(6.16)
where Gt is the matrix G multiplied by itself t times (i.e. Gt = G × G × ··· × G), 0 is a
vector of initial values whose 2q + 1 elements are
′0 =

000m10m1   0mq0mq


and the error term t is
t = Gt−1W1 + Gt−2W2 + ··· + GWt −1 + Wt	
If in (6.14) t is replaced by the version shown in (6.16) above, then Yt can also be written
as a Fourier series model of the form
Yt = 00 +
q
j=1
	
0mjcos
	2
T mjt

+ 0mjsin
	2
T mjt


+ t + t	
(6.17)
A comparison of (6.8) and (6.17) suggests that the 0 mj and mj of the former
have been replaced by 00 0mj and 0mj j = 1   q, and that the t of (6.7) gets
supplanted by t + t. This latter feature suggests a larger variability in the model for Yt
in section 6.3.2 than the one in section 6.3.1.
To proceed further we need to make some error theory assumptions and specify a prior
distribution for 0. This we do via the following:
t ∼N01/
Wt ∼N0t/
0 ∼N0R0/ and as before
 ∼G
	n0
2  d0
2

	
The quantities t 0 R0 n0 and d0 are to be specified by us as prior parameters; i.e.
the starting values of a Kalman Filter model. For 0 R0 n0 and d0 considerations analogous
to those discussed in section 6.3.2 under the sub-heading ‘Specifying a prior for the power
spectrum’ would apply. The role of these parameters parallels that of the parameters 0 R0 n0
and d0 of section 6.3.1. A general rule of thumb for specifying t would be to set t = kR0,
for all t, with k ∈01. When the observations Yt t = 12   , are closely spaced, k would
be small, in the vicinity of 0. The motivation for choosing a small value of k is that the goodness
of a Fourier series approximation increases as the time between observations decreases. This
completes our specification of a three-stage hierarchical model for assessing the power spectrum.
The observation and systems equations constitute the first two stages of the hierarchy, and the
gamma distribution of , the third stage.

200
COMPOSITE RELIABILITY: SIGNATURES
Posterior Power Spectrum Under the Hierarchical Bayes Model
Upon observing Yt = Y1   Yt′, we use standard Bayesian updating techniques (in this
case Kalman Filtering) to obtain the posterior distribution of t as:
tYt ∼Tnt ∗
t  R∗
t d∗
t /n∗
t 
(6.18)
where the quantities t Rt nt and dt are prescribed below (West and Harrison, 1989, pp. 118–
119). Observe that (6.18) parallels (6.12), save for the fact that the parameters take different
values. These are of the form:
∗
t = G∗
t−1 + Atet
where
At = GR∗
t−1G′ + tF1 + F′GR∗
t−1G′+tF−1 and
et = Yt −F′G∗
t−1	
Also
n∗
t = n∗
t−1 + 1
d∗
t = e∗
t 21 + F′GR∗
t−1G′+tF−1 + d∗
t−1 and
R∗
t = GR∗
t−1G′ + t −AtA′
t1 + F′GR∗
t−1G′+tF−1	
In the above recursions, n∗
0 = n0 d∗
0 = d0 ∗
0 = 0 and R∗
0 = R0; a strategy for specifying them
was discussed before.
The isomorphism between (6.12) and (6.18) allows us to use the methodology following (6.12)
to assess the power spectrum for this section’s hierarchical Bayes set-up. The main difference is
that ∗
t  R∗
t  n∗
t and d∗
t are used in place of t Rt nt and dt, respectively.
6.3.4
The Spectrum as a Covariate Using an Accelerated Life Model
Since the power spectrum can be seen as a snapshot of potential defects, it makes sense to use
it as a covariate for assessing lifetimes. The purpose of this section is to propose an approach
for doing the above. With this in mind, suppose that T is the lifelength of an item, and suppose
that the vector
∗def
= ∗m1∗m2   ∗mq′
where ∗mj = E2mjYt (equation (6.13) is our assessment of the ∗mj for this item.
Note that ∗could be obtained via either the regression model of section 6.3.2, or via the
Kalman Filter model of section 6.3.3. Recall that a plot of ∗mj versus mj/T, for j =1   q
represents our assessment of the power spectrum.
The linkage between ∗and T can be made through what is known as an ‘accelerated life
model’. One such version of this model – the version used by Campodónico and Singpurwalla
(1994b) – is to assume that
ln T = −
q
j=1
Cj∗mj + ln W
(6.19)

SIGNATURE ANALYSIS AND SIGNATURES AS COVARIATES
201
where C1   Cq are unknown constants, and ln W ∼N02, with 2 unknown. Equation
(6.19) describes what is known as a log-linear model for T.
Suppose that n units are observed to failure and their lifetimes t1   tn noted. Also recorded,
just prior to their failure, are their respective signatures ∗
i  i=1   n. Then, as per the dictates
of the log-linear model,
ln ti = −
q
j=1
Cj∗
i mj + i
(6.20)
where the i’s are independent and are such that i ∼N02. Given the ti’s and their corre-
sponding ∗
i m1∗
i m2   ∗
i mq i=1   n, standard Bayesian analysis of the log-linear
model (cf. Box and Tiao, 1992, p. 113) enables us to assess the posterior distribution of C2,
where C = C1   Cq. The natural conjugate prior for C is a multivariate normal distribution
whose parameters reflect our opinions about the relative impact of each defect on the item’s
lifetime. A neutral choice would be to assume that the prior means of the Cis are zero, that their
variances are large and their covariances are small. A natural conjugate prior for 1/2 would be
a gamma, independent of the prior for C. The mode of the posterior distribution of C provides
a sense of the relative importance of each mj j = 1   q vis-à-vis the item’s lifetime.
A flavor of the above is best illustrated by an overview of the traction motor example
considered by Campodónico and Singpurwalla (1994b). Here, the ‘leakage current’ is a proxy
for motor’s lifetime, and a signature of the motor’s vibration during rotation is an indicator of
its underlying defects.
Illustrative Example – Vibration of Traction Motors
Traction motors for locomotives are normally tested for defects using vibration signals taken at
different running speeds. We shall restrict attention here to the case of the 900 revolutions per
minute (rpm) speed. A large amplitude – i.e. 2mj – at mj = 1 suggests an imbalance or a
bent shaft, whereas a large amplitude at mj = 2 suggests a misalignment of the motor. Similarly,
large amplitudes at mj =34 suggest looseness of the bearing on the shaft (housing). If the gear
in a motor has k teeth, then a large amplitude at mj = k suggests problems having to do with
gearmesh. Finally, if the number of ball-bearings in the motor is n, then large amplitudes at
mj = 0	4n 0	6n suggest defects on the outer (inner) races of the ball-bearings. In our particular
case, k = 18 and n = 13.
Thus, for this scenario, it makes sense to choose the frequencies of 1 through 10 (times the
motor running speed) and the frequency of 18 (times the motor running speed). That is, in the
notation of section 6.3.1,  = 12   1018 and q = 11. We then use the regression model
of (6.7) and (6.8), with Yt as the lateral displacement of the motor, to obtain a Bayesian
assessment of the power spectrum. For the prior specifications, 0 was set to its default value 0
and the diagonal elements of the matrix R0 of Section 6.3.2 were taken to be (1, 0.95, 0.95, 0.9,
0.9, 0.85, 0.85, 0.8, 0.8, 0.75, 0.75, 0.7, 0.7, 0.65, 0.65, 0.6, 0.6, 0.55 and 0.55); the parameters
n0 and d0 were set equal to 0. Equation (6.13) was used to assess the spectrum for mj ∈.
Figure 6.6 shows a plot of the assessed spectrum (or a signature) of a motor labeled #4. The
leakage current for this motor was 1.975.
Signatures similar to those of Figure 6.6 were also obtained for eight other traction motors,
making the total number of motors tested as nine; also recorded were their associated leakage
currents, ti i = 1   9. The log-linear model of (6.20) was invoked on these data and the
Cj j = 1   11 assessed. A plot of the assessed Cjs, rescaled so that they are all between 0
and 1, is shown in Figure 6.7. We refer to such rescaled Cjs as spectral weights. For details on
the priors for C = C1   C11 and 2, see (Campodónico and Singpurwalla 1994b).

202
COMPOSITE RELIABILITY: SIGNATURES
An examination of Figure 6.7 suggests that defects associated with other frequencies (4, 6,
7, 9 and 10) are more deleterious to the motor’s lifetime than those corresponding to the other
frequencies. A comparison of Figures 6.6 and 6.7 suggests that even though the amplitudes
associated with the frequencies at 6, 7, 8, 9 and 10 are small, their impact on lifetimes is large.
Recall that large amplitudes at frequencies 5–10 correspond to defects in the inner and outer
race of the bearings, whereas large amplitudes at frequencies 1–3 suggest an imbalance. Thus,
it appears that good bearing races and tightness of the bearing on the housing is more important
to a traction motor’s lifetime than misalignment and imbalance.
6.3.5
Closing Remarks on Signatures and Covariates
Hopefully the above realistic but simplified example underscores the relevance of signature
analysis in reliability and survival analysis. It enables us to assess the relative importance of
the types of defects on an item’s lifelength. It also provides us with a means for predicting
Amplitude
0
0.001
0.002
0.003
1
2
3
4
5
6
7
8
9
10
18
Frequency (x rpm)
Figure 6.6
Assessed signature of lateral displacement data for motor #4.
Weight
0
0.2
1
2
3
4
5
6
7
8
9
10
18
Frequency (x rpm)
0.4
0.6
0.8
1
Figure 6.7
The spectral weights Cj for traction motor data.

SIGNATURE ANALYSIS AND SIGNATURES AS COVARIATES
203
lifetimes, given an item’s signature. Recently, much has been written under the general rubric
of degradation modeling (for example, Whitmore (1995); also section 7.5). In principle, using
signatures as covariates can also be seen as a form of degradation modeling, provided that one
can relate amplitudes of the spectra with defects. As mentioned before, the full potential of
using signatures as covariates needs to be fully explored. For instance, is the accelerated life
model of (6.19) the only meaningful way of relating signatures and lifetimes? Also needed
is the development of efficient computational tools. The formulae in sections 6.3.2 and 6.3.3
look cumbersome and intimidating. In actuality, they are not; they are nothing more than the
equations of Kalman Filtering, successfully used by engineers using control theory. Modern
computing technologies such as the MCMC will enable us to deal with such expressions in a
rather straightforward manner.
By a way of concluding to this chapter on hierarchical modeling, I remark that hierarchical
models are not only useful with respect to their traditional role of better encapsulating observed
data, as most Bayesians seem to view, but they can also play a role in terms of developing new
ideas, or expanding upon the existing ones. A case in point is our notion of composite reliability.
This can be seen as a way of embedding the current notion of reliability (articulated in the early
1950s) within a more general conceptual framework.


Chapter 7
Survival in Dynamic Environments
Kolmogorov: He almost surely lies here
7.1
INTRODUCTION: WHY STOCHASTIC HAZARD FUNCTIONS?
The actual environment in which most items generally operate is dynamic. That is, factors which
go to constitute an environment, such as temperature, humidity, usage rate, etc., change with
time. Moreover, the manner in which the changes occur is not deterministic, in the sense that the
times of change and the amount of change cannot be pre-specified. Consequently, the behavior
of such factors, actually covariates, is best described via stochastic process models, such as the
Poisson process of section 4.7.4, or the gamma process of section 4.9.1. Static environments are
rare. They are generally encountered in controlled life-tests wherein the conditions of the test
environment are kept constant (section 5.4.1). In the biomedical scenario, the changing covariates
are sometimes referred to as markers, and their random nature described via what are known
as marker processes (cf. Whitmore, Crowder and Lawless, 1998).
One possible way of capturing the effect of a random environment on an item’s lifelength is
to make its failure rate function (be it predictive or model) a stochastic process. This is what
we mean by a stochastic hazard. The standard models of reliability derived from failure rate
functions that are deterministic (Chapter 4) do not account for the dynamics of the observed
and/or the unobserved covariates. The idea of making the failure rate function a stochastic
process can be traced back to Gaver (1963); this was followed up by the works of Antelman and
Savage (1965) and of Harris and Singpurwalla (1967). However, it is only recently, subsequent
to the papers of Arjas (1981) and Kebir (1991), that the merits of the idea are beginning to be
better appreciated (cf. Singpurwalla, 1995b). Stochastic hazards have already been introduced
in sections 4.7.6 and 4.9.1, but these were embedded within the context of a broader class of
problems. The basic features of hazard rate processes remain to be articulated and this is what I
endeavor to do below.
Reliability and Risk: A Bayesian Perspective
N.D. Singpurwalla
© 2006 John Wiley & Sons, Ltd

206
SURVIVAL IN DYNAMIC ENVIRONMENTS
7.2
HAZARD RATE PROCESSES
A stochastic process was introduced in section 4.7.6 as a collection of random variables whose
marginal and joint distributions can be fully specified. Specifically, if for every t ∈0, rt
is a random variable with a specified distribution, and if for every collection of k ≥1 points
0 < t1 < t2 < ··· < tk, the joint distribution of the k random variables rt1   rtk is also
specified, then rtt ≥0	 is a stochastic process. Furthermore, if for all t ∈0, rt is
non-negative, real-valued and continuous in t from the right, then rtt ≥0	 is said to be a
non-negative, real-valued and right-continuous stochastic process. Suppose that rtt ≥0	 is
such a process, and suppose that T denotes the lifelength of an item. Then rtt ≥0	 is said
to be the hazard rate process of T if
PT ≥trs0 ≤s < t = exp

−
 t
0 rsds


(7.1)
The quantity Rt
def=
 t
0 rsds also defines a stochastic process Rtt ≥0	, which is known
as the cumulative hazard process. Such a process has already been encountered by us in
section 4.7.6, wherein it was taken to be a gamma process. Thus in terms of a cumulative hazard
process, the right-hand side of (7.1) can be written as exp−Rt. A consequence of the above
is that for any t ≥0
PT ≥t = Eexp−Rt	
(7.2)
where E denotes the expectation. The arguments leading us from (7.1) to (7.2) are subtle (cf.
Pitman and Speed, 1973) even though the result is intuitive. Before discussing meaningful choices
for the hazard rate and the cumulative hazard process, the following relationship between the
hazard rate process and the intensity function of a doubly stochastic Poisson process is useful to
note.
Relationship with Doubly Stochastic Poisson Processes
Recall that homogenous and non-homogenous Poisson processes and their intensity functions
were introduced in section 4.7.4, and that doubly stochastic Poisson processes and their stochastic
intensity functions introduced in section 5.2.4. Now, for any lifetime T having a survival function
whose failure rate is rt, t ≥0, we have
PT > t = exp

−
 t
0 rsds


(7.3)
But the right-hand side of (7.3) is also the distribution function of U, the time of the first jump
in a non-homogenous Poisson process, say Ntt ≥0	, with intensity function rs, s ≥0.
That is
PU > t = PNt = 0 = exp

−
 t
0 rsds


(7.4)
Thus the failure rate function can also be interpreted as the intensity function of a non-
homogenous Poisson process in the sense of (7.3) and (7.4) above. In the same vein it can be
argued (cf. Kebir, 1991) that a hazard rate process can be interpreted as the intensity process of
a doubly stochastic Poisson process. This connection between Poisson processes and the hazard
rate serves as a motivation for the point process approach to reliability and survival analysis
discussed in Chapter 8. For now we shall concentrate on some specific choices for the hazard
rate process rtt ≥0	 and cumulative hazard rate process Rtt ≥0	.

HAZARD RATE PROCESSES
207
7.2.1
Hazard Rates as Shot-noise Processes
Shot-noise processes were introduced in section 4.7.6 for describing the effect of a certain kind
of environment on the model failure rates of multi-component systems. Here we suppose that the
failure rate function itself can be described by a shot-noise process. For this we will adhere to
the notation and terminology of section 4.7.6. Much of what is said below parallels the material
of section 4.7.6, save for some minor variations. Specifically, for t ≥0, we write
rt =


k=1
Xkht −Tk
where Xk is the size of the jump in the failure rate at time Tk, and h• is the attenuation
function (Figure 4.16); but bear in mind that here X0 ≡0, so that r0=0. The Xks are assumed to
be independent of each other and also of the Tks. Also, the Xks have a common distribution G.
A motivation for describing the failure rate function via a shot-noise process is based on the
premise that the shocks (or events) of the process induce stresses of unknown magnitude on a
component, that the component experiences a residual stress that may or may not decay over
time and that the stresses are additive. We also suppose that stress is the cause of failure, so
that the pattern of the failure rate function is determined by the (time indexed) pattern of the
stress. If, as in section 4.7.6, we let Mt =
 t
0 mudu, where mu is the intensity function of
the Poisson process that generates the jump times of the failure rate, Ht =
 t
0 hudu, and G∗
the Laplace transform of G, then
PT ≥t = exp

−Mt +
 t
0 G∗Humt −udu


(7.5)
T is the time to failure of an item experiencing the shot-noise hazard rate process described
above (for details, see section 4.7.6).
Note, from the material discussed before, that T is also the time to occurrence of the first event
in a doubly stochastic Poisson process whose intensity function is described by a shot-noise
process.
Special cases of h•, G and m• will yield specific forms of the survival function PT ≥t.
For example, when G is exponential with a scale b > 0, mu a constant m > 0, and hu = 1,
so that rt is non-decreasing,
PT ≥t = exp−mt
b + t
b
mb

(7.6)
a Pareto distribution of the third kind. The above result parallels that of (4.49) save for the fact
that here i = 1 and that
	 b +t
b

is raised to the power mb instead of mb −1. The reason for this
difference is that in the present case rt = 0 until the occurrence of the first jump.
As a second example, suppose that the jump sizes are a constant d, where d is set to one, and
that hu = 1 + u−1, signaling a slow decay of the failure rate until the next jump. Then, it can
be verified that for mu = m,
PT ≥t = exp−mt1 + tm 
(7.7)
again a Pareto distribution of the third kind.

208
SURVIVAL IN DYNAMIC ENVIRONMENTS
As a third and final example, suppose that the attenuation function reflects an exponential
decay of the form hu=exp−au, for some a>0, that Mt=mt, and that G is an exponential
distribution with scale b > 0. Then
PT ≥t = exp

−mabt
1 + ab
1 + ab −e−at
ab
 mb
1+ab

(7.8)
I leave it as an exercise for the reader to show that (7.6)–(7.8) are true.
7.2.2
Hazard Rates as Lévy Processes
A Lévy process, though mentioned in section 4.9.1, remains to be formally defined. Processes
with independent increments are called additive processes, and the Lévy process is a special
type of additive process. Specifically, a Lévy process is a continuous process with stationary
independent increments; i.e. the increments of the process have the same distribution. Lévy
processes encompass a large family of processes, the Poisson, the compound Poisson, the
gamma process (of the type discussed in section 4.9.1) and the ‘Brownian motion process’
(to be discussed in section 7.2.3) are some noteworthy examples. Increasing Lévy processes
(also known as ‘non-negative Lévy processes’ or as ‘subordinators’) are Lévy processes whose
stationary independent increments are non-negative. Examples are the Poisson, the compound
Poisson and the gamma process mentioned before.
Lévy processes have turned out to be a valuable modeling tool in reliability and survival
analysis, not only because of their generality but also because they produce, in many cases,
computationally tractable results. This computational tractability is the consequence of a cel-
ebrated decomposition of increasing processes with independent increments, namely, the Itô
decomposition (cf. Itô, 1969). The decomposition takes a particularly simple form when the
underlying process is an increasing Lévy process (equation (7.9). Increasing Lévy processes are
viable candidates for describing failure rate functions that are increasing (and also cumulative
hazard functions; section 7.3.2). Suppose then that the hazard rate process rtt ≥0	 is an
increasing Lévy process. Then, for some  ≥0, where  is known as the drift rate
rt = t +
 t
0
 
0
zNdudz
(7.9)
where N has a Poisson distribution in two dimensions on 0 × 0, with mean ndudz.
That is, for any subset, say B, of 0 × 0, PNB = j = exp−nB nBj
j!
. Furthermore
ndudz = dudz, where dz does not depend on u; dz is known as the Lévy measure.
Intuitively, the Lévy measure characterizes both the expected frequency and the size of jumps in a
Lévy process. The essence of the above result (which is also known as a Lévy representation) is
best appreciated via the specific examples that are discussed below. When  = 0, the underlying
Lévy process does not have an upward drift. Consequently, it does not have any non-random
parts and so rt increases only by jumps. The t term can be replaced by the more general
t, where t is a non-decreasing continuous function of time with 0 = 0.
Based on the decomposition of (7.9), Kebir (1991), in his Corollary 3.2, is able to show that
the survival function of the time to failure T is:
PT ≥t = exp

−t2
2

exp

−
 t
0 ds
 
0
1 −exp−t −sx

dx
(7.10)

HAZARD RATE PROCESSES
209
where dx is the Lévy measure of the underlying Lévy process. Equation (7.10) is strik-
ing. Striking, because its right-hand side is also the survival function of an item which has a
deterministic failure rate function of the form:
rt = t +
 
0
1 −exptxdx
(7.11)
Thus an item experiencing an increasing Lévy process as a hazard rate process has a survival
function that is identical to the survival function of an item experiencing a deterministic failure
rate function of the form given by (7.11). A broader interpretation of this result has been that
a continuous increasing stochastic process with stationary independent increments is essentially
deterministic (cf. Çinlar, 1979; also see section 7.3.2).
Specific choices for the Lévy measure dx yield specific expressions for the survival function
of (7.10). For example, the Lévy measure of a gamma process with shape at, a > 0, and scale
b is
dx = a
x exp−bxdx
x > 0
(7.12)
Consequently, with the drift rate  = 0, (7.10) gives the survival function as:
PT ≥t = exp

−
 t
0 alog
b + x
b

dx


(7.13)
its deterministic failure rate function is alogb−1b + t.
In section 9.4.2, the extended gamma process, which is a weighted gamma process, will be
introduced. Equation (9.11) pertains to the survival function generated by such a process; it
complements (7.13) above.
As a second example, suppose that the hazard rate process is assumed to be a homogenous
compound Poisson process (section 4.9.1), with an intensity function mt = m > 0, and with G
as the distribution of the increments. Then the Lévy measure of this process is dx = mGdx.
Consequently, its survival function is
PT ≥t = exp

−
 t
0 m1 −G∗xdx


(7.14)
where G∗is the Laplace transform of G. If G is assumed to be a gamma distribution with shape
parameter  > 0, and scale parameter b, then the Lévy measure of the process is
dx = m ba
axa−1e−bxdx
and
G∗x = b/b + sa
Consequently, its survival function is
PT ≥t =

exp−mtb + t/bmb
if a = 1
exp−m

t +
b
a−1
	 b
b+t

a−1 −
b
a−1


if a ̸= 1
Finally, if the hazard rate process rtt ≥0	 is a stable process, i.e. if for any t > 0, its
Laplace transform Eexp−srt	 is of the form exp−tbsa, for b > 0 and 0 < a < 1, then the
Lévy measure of the process is
dx = abx−1+a
1 −a 
(7.15)

210
SURVIVAL IN DYNAMIC ENVIRONMENTS
The above when plugged in (7.10) gives us the survival function of an item experiencing a
stable process for its failure rate.
7.2.3
Hazard Rates as Functions of Diffusion Processes
The material of this section is largely based on the work of Myers (1981), who induces a
hazard rate process by assuming a Brownian motion process for the covariates (or markers) that
influence failure. This is in contrast to the material of sections 7.2.1 and 7.2.2 wherein stochastic
process models were directly prescribed for the failure rate function. Myer’s work appears to
have been inspired by ideas on modeling human mortality and aging by Woodbury and Manton
(1977). Yashin and Manton (1997) give an authoritative overview of this and related issues.
A justification for following the modeling strategy proposed by the above is that prescribing
stochastic process models on unobserved entities like the failure rate function is unnatural. Rather,
one should describe the stochastic behavior of observable entities, like covariates (and markers),
by a stochastic process model, and to then induce a stochastic process for the failure rate function
by assuming a relationship between the covariate(s) and the failure rate. Indeed, this was the
strategy used by us in section 4.7.6 wherein the intrinsic failure rate u = , for u ≥0, was
modulated by the covariate-related shot-noise process uu ≥0	 to produce the hazard rate
process uu ≥0	. The material to follow is based on the above line of thinking, save for
the fact that a Brownian motion process is used to describe the evolution of covariate(s), and the
relationship between the covariate(s) and the failure rate is more elaborate than the multiplicative
one mentioned above. We start with an overview of the Wiener process and Brownian motion,
but to set the stage for this I need to introduce some notation. Let the vector Zt denote the
values at t of a collection of covariates that are assumed to influence lifelength. Suppose that
Zt is of dimension m ≥1, and that it is possible to observe and to measure each element of
Zt, for any t ≥0. Let Zitt ≥0, be the i-th element of Zti = 1   m.
Brownian Motion, Wiener Processes and Diffusion
A stochastic process Zitt ≥0	 is said to be a Wiener process, starting from Zi0 = z, say,
where z ≥0, if:
(i)
Zit is continuous in t, for t ≥0;
(ii)
Zit has independent increments; and
(iii)
Zis +t−Zis has a Gaussian distribution with mean 0 and variance 2t, for all st ≥0,
with 2 a positive constant.
When z = 0 and 2 = 1Zitt ≥0	 is called the standard Wiener process; with 2 ̸= 1,
it is the process Zit/t ≥0	 that is a standard Wiener process. It can be verified that for
0 ≤s ≤t, the autocovariance function of Zitt ≥0	, EZit −Zi0Zis −Zi0	 = 2s;
thus for any st ≥0, the autocovariance function is 2 minst. If EZit = t, for some
 > 0, then the Wiener process is said to have a drift parameter . In general, if Ztt ≥0	
is a standard Wiener process, then the process Ztt ≥0	, where Zt = t + 2Wt will be a
Wiener process with drift  and diffusion parameter 2. Furthermore, Zt will have a Gaussian
distribution with mean t and variance 2t, and for s ≤t its covariance will be 2s1 + 2t.
The vector stochastic process Ztt ≥0	 is said to be a Brownian motion process if:
(i)
Z0 = 0, and
(ii)
Zitt ≥0	i = 1   m are independent and identically distributed Wiener processes.
Thus a collection of independent and identically distributed Wiener processes, all starting at
0, constitute a Brownian motion process. It is for this reason that the Wiener process is also

CUMULATIVE HAZARD PROCESSES
211
referred to as Brownian motion. A standard Brownian motion process is a Brownian motion
process in which all the constituent processes Zitt ≥0	 are standard Wiener processes. The
Brownian motion and the Wiener process are archetypal examples of diffusion processes. That
is, processes whose sample paths are continuous and which possess ‘the strong Markov property’
(see Karlin and Taylor (1981), p. 149 for a definition).
Hazard Rate as Squared Brownian Motion
For the covariate vector Ztt ≥0	, Myers (1981) assumes a diffusion process via the Itô
stochastic differential equation
dZt = atZt + btdWt
where at and bt are continuous, and Wtt ≥0	 is a standard Brownian process of
dimension m. The failure rate function is assumed to be a quadratic function of Zt. For the
hazard rate process thus induced, Myers (1981) obtains an expression for the survival function
(the theorem in section 2.2 of Myers’ paper). The expression for this survival function is not
in a closed form and involves the solution of a matrix differential equation (called the ‘Riccati
equation’). However, in the one-dimensional case, i.e. for m = 1, an interesting closed-form
expression for the survival function can be obtained; this is discussed below.
Let Ztt ≥0	 be a one-dimensional covariate process whose dynamic is defined via the
relationship
Zt = Z0 + Wt
where Wt is a one-dimensional standard Wiener process. Thus Zt is a Wiener diffusion
process starting at Z0 > 0, and having scale  > 0. For some constant q > 0, let the hazard rate
process rtt ≥0	 be such that rt = qZt2. Then the survival function of T, the time to
failure, will be
PT ≥t = E

exp

−q
 t
0 Z2udu


see (7.2). The failure rate function of T, namely −d
dt logPT ≥t turns out to be
qZ02sech2At + AtanhAt
where A = 22q1/2sechx =
2
ex + e−x , and tanhx = ex −e−x
ex + e−x .
When Z0 = 0 and 2 = 1, the survival function of T is given as:
PT ≥t = cosh

2qt1/2
where coshx = ex + e−x/2.
The above expression for the survival function is the Laplace transform of a definite integral of
squared Brownian motion (in dimension one), and is known as the Cameron–Martin Formula,
after Cameron and Martin (1944).
7.3
CUMULATIVE HAZARD PROCESSES
The theme of section 7.2 was to obtain expressions for the survival function of items that
operate in a dynamic environment and therefore experience stochastic hazard rate functions.
The exponentiation formula of reliability and survival, averaged over the hazard rate process

212
SURVIVAL IN DYNAMIC ENVIRONMENTS
(equation (7.2)), was the key operational tool. The cumulative hazard process Rtt ≥0	, where
Rt =
 t
0 rudu, was introduced in section 7.2. This process comes about via the argument that
it is a consequence of assuming a failure rate function that is a stochastic process. Different kinds
of stochastic processes were assumed for rtt ≥0	, such as the shot-noise, the Lévy and the
diffusion (namely, a squared Brownian motion). The assumed stochastic process for rtt ≥0	
induces a stochastic process for Rtt ≥0	. Alternatively, one may find it more convenient
to directly prescribe a stochastic process for Rtt ≥0	 itself, and in what follows this is the
point of view that will be adopted here.
The aim of this section is to describe a different approach for obtaining the survival function
of items operating in a dynamic environment. The approach starts by assuming a stochastic
process model for Rtt ≥0	, and instead of using (7.2) to obtain PT ≥t, it uses the hitting
time of this process to a random threshold, say X, to obtain a survival function. The random
threshold X is the hazard potential of the item, and X has an exponential distribution with scale
parameter one (section 4.6). Durham and Padgett (1997) take a similar approach for obtaining
survival functions. Their motivation, however, is different from ours; it is based on cumulative
damage and initial strength, assumed known. Lee and Whitmore (2006) consider the scenario of
hitting times with covariate information.
Hitting times of stochastic processes to a specified threshold (or barrier) is a well-studied
topic in probability; for example, Barndorff-Nielsen, Blaesid and Halgreen (1978). Thus, as an
example, if the process Rtt ≥0	 is assumed to be a Wiener process, then the hitting time
of this process to a specified barrier will have an inverse Gaussian distribution. But using the
above argument as a justification for the inverse Gaussian as a failure model is flawed. This is
because the Wiener process is not monotonically increasing in time, whereas Rt needs to be
non-decreasing in t. However, the process sup
0<u≤t
Wtt ≥0	, where Wtt ≥0	 is a standard
Wiener process, is continuous, non-negative and non-decreasing in t. This process is called a
Brownian Maximum Process. Thus it makes sense to describe Rtt ≥0	 by a Brownian
maximum process. The hitting time of a Brownian maximum process to a specified threshold
will continue to have an inverse Gaussian distribution. That is, if Tx denotes the hitting time of
a Brownian maximum process to a threshold x, then
PTx ≤t = 21 −x/
√
t
where s =
 s
−
1
√
2
e−u2
2 du.
In our particular scenario, the threshold x is not specified. Rather, it is an exponentially
distributed random variable with scale parameter one. This means that T, the time to failure,
will have a distribution that is a scale mixture of inverse Gaussian distributions, the mixing
distribution being exponential (1). Specifically, it can be verified that the survival function is of
the form
PT > t = 2et/2−
√
t
In what follows let us consider some other non-decreasing stochastic processes for Rtt≥0	,
such as a compound Poisson, an increasing Lévy, an integrated geometric Brownian motion and
a Markov additive process to obtain some families of survival functions using the above line of
development. The important question of which process one must use and when to use it remains
to be satisfactorily addressed. In some cases, the choice of a process would be natural, in others,
the choice would be based on subjective (or personalistic) considerations. An empiricist answer
would be to choose that process which best describes the failure data at hand, if any. My aim
here is to offer the reader a menu of possibilities.

CUMULATIVE HAZARD PROCESSES
213
7.3.1
The Cumulative Hazard as a Compound Poisson Process
A compound Poisson process with an intensity function mu=m>0, and having jumps of size
X1X2   , with Xis independent and identically distributed with distribution function G, is
perhaps one of the simplest models for describing the process Rtt ≥0	. Observe that Rt is
right continuous and non-decreasing in t. If the Xis are also independent of the hazard potential
X, as is reasonable to assume, then if T denotes the hitting time of this process to the random
threshold X, the survival function of T, conditional on m known, is
PT > t  m =


k=0
e−mtmtk
k!
 
0
Gkue−u du
(7.16)
where Gk is the k-fold convolution of G with itself. The details are easy to verify. When G is
such that Gu = 0, u < 0 (i.e. the jump sizes are non-negative), Esary, Marshall and Proschan
(1973) show that (7.16) simplifies as
PT > t  m = e−mtt ≥0m > 0
Averaging out m with respect to any reasonable distribution for it would result in a survival
function having a decreasing failure rate function. In particular, if m has a gamma distribution,
then the distribution of T will be a Pareto.
7.3.2
The Cumulative Hazard as an Increasing Lévy Process
An omnibus way to describe Rtt ≥0	 is via an increasing Lévy process (section 7.2.2). Such a
process encompasses the compound Poisson, the gamma, and the stable process. There is another
advantage to using this process in the context of its hitting time distribution to an exponential
threshold. Specifically, the hitting time distribution of an increasing Lévy process with Lévy
measure  is the Laplace transform of the process, and the Laplace transform of the process is
given by the well-known Lévy–Khinchin formula given below. Specifically, I start by noting that
PT > t = PX > Rt =
 
0
e−uBtdu
where Bt is the distribution function of Rt. Thus PT > t = Eexp−Rt, which is the
Laplace transform of Rt. When Rtt ≥0	 is an increasing Lévy process with Lévy measure
, the Laplace transform is of the form
Eexp−Rt = exp

−t −
 
0 1 −e−udu


(7.17)
which is the Lévy–Khinchin formula; see (for example Gjessing, Aalen and Hjort, 2003). As
before, t, a continuous non-decreasing function of t with 0 = 0, is the non-random part
of the process.
By choosing different forms for du, different processes for Rtt ≥0	 can be prescribed.
For example, if du is of the form given by (7.12) or (7.15), the resulting process for Rtt ≥
0	 will be a gamma or a stable process, respectively, whereas if du = mGdu then the
resulting process will be a homogenous compound Poisson process. Once du is specified,
(7.17) can be evaluated to obtain PT > t, the survival function.

214
SURVIVAL IN DYNAMIC ENVIRONMENTS
The Case of a Continuous Increasing Strong Markov Process
A striking feature of such processes is that they are essentially deterministic (cf. Blumenthal,
Getoor and McKean, 1962). For the special case of a continuous increasing Lévy process, Rt
can be written as
Rt = t +
 
0 1 −e−xtdx
where  ≥0 and dx is the Lévy measure of the process. When dx is of the form
dx = a
x exp−bxdx
the continuous increasing Lévy process for Rt will be a gamma process with shape (scale) at
b, and
Rt = t + alog
b + t
b


t ≥0
(7.18)
Note the parallel between (7.18) and (7.13), the latter being a consequence of prescribing a
gamma process for the hazard rate process.
With  = 0, the RT given above hits a threshold X, at T = bexpX/a −1. Since X is the
hazard potential, it has an exponential (1) distribution. Consequently
PT ≥t =

1 + t
b
−a

which is a Pareto distribution.
7.3.3
Cumulative Hazard as Geometric Brownian Motion
When Rtt ≥0	 is described by a Brownian maximum process, as was done in the introduction
to section 7.3, it is implied that the process for Rt increases in t by jumps. As another functional
of the Brownian motion process, and one which ensures that the process for Rt is strictly
increasing in t, I consider the relationship
Rt =
 t
0 exp2Wudu
(7.19)
where Wuu ≥0	 is a standard Wiener process; the scalar 2 is chosen for technical conve-
nience. The quantity expWu defines what is known as a geometric Brownian motion, so
the process Rtt ≥0	 defined by (7.19) is an integrated geometric Brownian motion process.
Such a process has been investigated by Yor (1992), who has obtained results that are useful for
obtaining its hitting time distribution. The details are cumbersome and therefore not spelled out
here. It can be seen (cf. Singpurwalla, 2006a,b) that the survival function of T is of the form
PT > t =
 
0
 
0
PHt ∈dve−xdx
where PHt ∈d/d
=

2
v
 
0
exp

−y2
2t + v
2 cosh2 y

sinh y sin
y
t

1 −√vcosh ydy
with s =
 s
−
1
√
2
e−u2
2 ducoshx = ex + e−x
2
sinhx = ex −e−x
2
.

CUMULATIVE HAZARD PROCESSES
215
7.3.4
The Cumulative Hazard as a Markov Additive Process
In section 7.2.3 I described a strategy for incorporating the effect of a covariate on the survival
function by making the failure rate a function of the covariate. The particular scenario that we
discussed involved a Wiener process for the covariate Zt, and the failure rate was qZt2, for
some constant q>0. With Z0=0 and 2 =1, the above set-up resulted in the survival function
being given by the Cameron–Martin formula. There is another strategy for incorporating the effect
of a stochastically varying covariate on the survival function, and this is through the cumulative
hazard function. This strategy is implemented via the structure of a bivariate stochastic process,
called the Markov additive process, so named because one member of the bivariate process is a
Markov process (see below), and the other an increasing additive process. Such processes were
introduced by Çinlar (1972); I start with an overview of their salient features.
Markov and Markov Additive Processes
For us to discuss Markov additive processes (MAP), it is necessary that I first introduce Markov
processes and the Markov property. To relate these to the material at hand, we shall adhere to
the notation we have been using. Specifically, the covariate process Ztt ≥0	 will be used to
denote a Markov process, and the cumulative hazard process Rtt ≥0	 to denote an increasing
additive process. These two processes constitute a MAP.
A stochastic process Ztt ≥0	, with Zt taking values in a set , where  ⊂−+,
is said to be a Markov process with state space  if it possesses the Markov property. That
is, for any  ⊆, and any st
PZt + s ∈Zu0 ≤u ≤s = PZt + s ∈  Zs
This means that the future course of the process depends only on its present value, the entire
history of the process not being relevant. If the above relationship holds for all values of t, then
the Markov process is said to be time homogenous. When such is the case, we may suppress t,
and write that for any s > 0, and ij ∈
PZt + s = j  Zs = i = psij
(7.20)
The conditional probability psij is known as the transition function of the Markov process.
Note that psij ≥0
j∈ psij = 1, and for any vs ≥0pv+sij = 
k∈ pvikpskj.
Suppose that 0 ≡T0 < T1 < T2 <    , are the times at which a Markov process makes a transition
from one state, say i, to the next, say j. The spacings Tn+1 −Tnn = 012   , are known as
the sojourn times of the process. An important feature of Markov processes is that their sojourn
times have an exponential distribution with a scale parameter that depends only on the current
state of the process, and not the state to which the process is transitioning to. Specifically,
PTn+1 −Tn ≥u  ZTn = iZTn+1 = j = e−iu
(7.21)
for some u ≥0 and i > 0; i does not depend on j. We will be making use of this feature
in an illustration that will be given later.
Turning attention to the MAP, we say that a bivariate stochastic process ZtRtt ≥0	 is
a Markov additive process if:
(i) Zt and Rt are right continuous with left-hand limits;
(ii) Rt ≥0 and increases with t;
(iii) Zt takes values in a set, say , where  is either countable or is a subset of the real line;

216
SURVIVAL IN DYNAMIC ENVIRONMENTS
(iv) For each e ∈, there is a well-defined probability (measure), say Pe, with the feature that
PeZ0 = eR0 = 0 = 1
and
(v) For all e ∈, s, t,  ⊂, and B ⊂−+,
PeZt + s ∈Rs + t −Rs ∈s = PZsZt ∈Rt ∈
where s is the entire history of the process until time s.
Note that v above prescribes the conditions under which the two probability measures Pe
and PZs give identical answers. The essential import of a MAP is encapsulated in Theorem 2.22
of Çinlar (1972), which says that if ZtRtt ≥0	 is a MAP, then:
(a)
Ztt ≥0	 is a Markov process with a state space  and a transition function
PeZt ∈Rt ∈0, and
(b)
Given Zt, the (conditional) law of Rt is that of an increasing additive process (i.e. a
process that can be represented as the sum of independent non-negative random variables).
Using (a) and (b) above, Çinlar (1972) was able to argue that during a small time interval
tt + dt, the probability law of Rt is that of an increasing Lévy process whose parameters
depend on the value Zt. Thus when Ztt ≥0	 represents a covariate process and Rtt ≥0	
the cumulative hazard process, a MAP for ZtRtt ≥0	 is able to describe the dependence
of a covariate on the cumulative hazard. When  consists of a single state, then the MAP reduces
to a univariate process, namely a Lévy process. This completes our overview of the Markov
process and the MAP. We now consider some specific examples of the MAP to illustrate the kind
of results that can be obtained for the problem of relating the cumulative hazard to a covariate.
Random Usage as a Covariate
The simplest scenario is one wherein a unit is intermittently used and which experiences an
increase in its cumulative hazard whenever it is being used. Thus, usage is the covariate which
influences the item’s lifelength. Alternatively put, the item operates in an environment of usage
that is dynamic. Such a covariate can be described by a two-state Markov process, with the
states  denoting working, and r denoting rest; i.e.  = r	. Thus we assume that the usage
process Ztt ≥0	 is a Markov process with a state space  = r	. Recall (Equation (7.21))
that for such a process the (random) amount of time the unit is being used has an exponential
distribution with scale parameter  > 0, and the amount of time for which it is out of use
also has an exponential distribution with scale parameter r>0. The assumption of a two-state
Markov process for usage may or may not be meaningful. It is sometimes the case that rest times
have distributions other than the exponential, such as the lognormal when non-usage (rest) is for
the purpose of repair. Similarly, the usage time distributions could be other than an exponential,
such as say a Weibull signaling the feature that long usage times accentuate the termination of
use. When such is the case, the MAP model to be described below will not be appropriate.
To continue with the modeling process, suppose that when the unit is in state , its cumulative
hazard R• increases by jumps of random size at random points in time (within any period
of usage). Assume that the jump sizes are independent of each other and also of the jump
times, and have a distribution function, say G. Suppose also that the jump times are determined
by a homogenous Poisson process with rate m. In other words, within any interval of usage,
say , the cumulative hazard process Rtt ∈	 is described by a homogenous compound

CUMULATIVE HAZARD PROCESSES
217
~
x
x
x
x
x
~
r
ω
0
Time t
{R(t); t ≥ 0}
{Z(t); t ≥ 0}
.
.
.
. .
.
.
Figure 7.1
The sample path of a MAP for RtZtt ≥0	.
Poisson process with rate m and jump distribution G. When the item is in state r, the cumulative
hazard stays put at its current value; i.e. it does not increase. In other words, the cumulative
hazard is in a state of suspended animation whenever the unit is in state r. Since a homogenous
compound Poisson process is an increasing Lévy process with no drift and a finite Lévy measure
dx = mGdx (section 7.2.2) Rtt ≥0	 is an increasing additive process whose parameter
m depends on the state of the usage process Ztt ≥0	, which is a Markov process. Therefore,
it makes sense to describe the scenario of conceptualizing random usage as a covariate, via the
structure of a MAP for the bivariate process ZtRtt ≥0	. The sample path of the process
constructed above is shown in Figure 7.1. The crosses on the time axis t denote the jump times
of the Rtt ≥0	 process shown on the upper part of Figure 7.1. The lower part shows the
sample path of the two-state usage process Ztt ≥0	. Note that Rt does not experience any
jumps when Zt is in state r.
A unit operating under certain circumstances wherein the bivariate process ZtRtt ≥0	
is a MAP of the kind described above will fail when Rtt ≥0	 hits a random threshold
X, where X has an exponential distribution with scale parameter one. I have seen before, in
section 7.3.2, that PT > t, the survival function of this unit, is the Laplace transform of Rt.
Specifically, PT > t = Eexp−Rt. To obtain this quantity, I appeal to a result of Çinlar
(1977), who shows that given Zu0 ≤u ≤t	 the history of the usage process up to and until
time t, the quantity
Eexp−RtZu0 ≤u ≤t = exp

−At
 
0 1 −e−umGdu


(7.22)
where At is the total amount of time that the covariate process Zu0 ≤u ≤t	 spends in
state . That is, At is the total time spent by the unit in a working state during the time
interval 0t.
A comparison of (7.22) with (7.17) with du in the latter equation replaced by mGdu is
instructive. The main difference is that when the At of (7.22) gets replaced by t, (7.17) comes
about. This makes sense because were the unit to operate in only one state, namely the state
At = t, and I have said before that when  consists of a single state, the MAP reduces to a
univariate increasing additive process. To obtain PT > t = E−expRt, we need to average
out the right-hand side of (7.22) with respect to the distribution of At. It is unlikely that a

218
SURVIVAL IN DYNAMIC ENVIRONMENTS
closed form expression for PT > t can be obtained for any specified G; we will need to resort
to a use of numerical techniques. An exception could be the case wherein the jump sizes are a
constant, say d, so that Gdu = 1 when u = d and zero otherwise. When such is the case
PT > t = E

e−m1−e−dAt

where now the expectation is with respect to the distribution of At. Note that with d = 1, the
MAP discussed here is also the hidden Markov model mentioned in section 5.2.4.
As another illustration of the scenario of random usage, consider the situation wherein the
nature of usage is germane. For example, usage under different climatic conditions such as
average, cold, freezing and hot or such as aggressive, benign and normal. Suppose that the
environment of usage is such that Ztt ≥0	 is a multi-state Markov process. The sojourn times
of Ztt ≥0	 in each state will continue to be exponentially distributed with scale parameters
that are state dependent. Instead of supposing that the cumulative hazard process Rtt ≥0	
increases by jumps, we now assume that it increases continuously, so that locally (i.e. during
the sojourn time in a particular state) Rtt ≥0	 is a gamma process whose shape and scale
parameters are state dependent; they are Zt and Zt, respectively. Then, as before
(equation (7.22)) it can be shown (cf. Çinlar, 1977) that
Eexp−RtZu0 ≤u ≤t = exp

−
 t
0 Zulog

1 +
u
Zu

du


(7.23)
Here again, it is instructive to compare (7.23) above with (7.13) and note the parallel between the
two. When the usage process Ztt≥0	 consists of a single state, Zu=a and Zu=b,
and (7.23) will reduce to (7.13).
7.4
COMPETING RISKS AND COMPETING RISK PROCESSES
Loosely speaking, by the term ‘competing risks’, it is meant competing causes of failure. The
notion of competing risks has its origin in the biomedical context wherein interest centers around
the cause of death of a biological unit, given that there are several agents that compete for its
lifetime. The issue is quite complex since the causes do not operate in isolation of each other, it
often being the case that one cause acerbates the effect of the other. Some celebrated references
on this topic are Makeham (1873), who introduces the problem, and Cornfield (1957), who
articulates the issues that the problem spawns.
A simple way to conceptualize a model for competing risks is through the scenario of a
two-component series system, the failure of the first of the two components being labeled as
the cause of failure of the system. Thus, for example, in the case of an automobile the cause of
failure could be a mechanical defect or an electrical defect. In the interest of simplicity, here we
do not distinguish between a prima facie cause and a genuine cause (section 4.8.1). Accordingly,
let T1 and T2 be the lifetimes of a two-component system, and T the lifetime of the system.
Let R1t and R2t be the cumulative hazard functions of T1 and T2, respectively; t ≥0. The
component labeled 1 will fail when R1t crosses its hazard potential X1 (section 4.6), similarly
with component 2, whose hazard potential is X2. The system fails when R1t crosses X1, or
R2t crosses X2, whichever occurs first. The cause of failure of the system is R1t if R1t
crosses X1 prior to R2t crossing X2, and vice versa. Thus we may interpret the cumulative
hazards as the risks to the system that compete with each other for the system’s lifelength. Recall
(section 4.6) that the cumulative hazard encapsulates an assessor’s judgment about the manner
in which an item’s quality and the environment in which the item operates interact, vis-à-vis the

COMPETING RISKS AND COMPETING RISK PROCESSES
219
item’s lifelength. From an actuarial and an operational point of view, it is the system’s time to
failure T that is of greater interest than the cause of failure. From the point of view of system
design, system maintenance and a postmortem of system failure, it is the cause of failure that
is germane. We start with a consideration of deterministic R1t and R2t, and in section 7.4.2
discuss the scenario of stochastic cumulative hazard functions, independent and dependent.
7.4.1
Deterministic Competing Risks
With the two-component series system as a model for competing risks, the survival function of
T, given by PT ≥t, is of the form
P T ≥t = PR1t ≤X1R2t ≤X2
= PX1 ≥R1tX2 ≥R2t
= exp−R1t + R2t
(7.24)
if X1 and X2, the hazard potentials, are independent. This means that the cumulative hazard
experienced by the system of the two competing cumulative hazards, R1t and R2t. In other
words, under the assumption of independent hazard potentials of each component, the risk to the
system is an additive function of the component risks.
There is another way to look at (7.24). Specifically, this equation can also be seen as the
survival function of a single item that experiences a cumulative hazard of Rt=defR1t+R2t.
But when such is the case, how may we interpret R1t and R2t? More generally, in the case
of a single item experiencing a cumulative hazard of Rt, can there be a decomposition of
Rt, and if so could it be additive? To address these questions, one possible strategy would
be to associate each Rit, i = 12   , with a covariate, such as a factor of the environment,
say the temperature, and to suppose that were the item to experience the factor i alone, then its
cumulative hazard would be Rit. The item fails when Rit crosses the item’s hazard potential
X. With the item simultaneously experiencing m factors that constitute its environment, its
survival function will be
P T ≥t = PR1t ≤XR2t ≤X   Rmt ≤X
= PX ≥maxR1t   Rmt	
= exp−maxR1t   Rmt	
(7.25)
Thus far the scenario described above, the decomposition of Rt, is not additive; rather, here
Rt = maxR1t   Rmt	.
The above two perspectives on competing risk modeling, one entailing the scenario of a
series system and the other the case of a single unit experiencing several failure-causing agents,
lead to different answers. Which of these two perspectives best encapsulates a competing risk
mechanism? Do the two formulae of (7.24) and (7.25) bear some relationship to each other? In
what follows, I attempt to address the above questions.
Relating the Two Formulae of Competing Risk Models
The existing literature on competing risk models is based on a multi-component series system with
independent or dependent component lifelengths T1   Tm, say. Under this conceptualization,
the m lifetimes are assumed to compete with each other for the system’s lifetime. When the
lifetimes are assumed independent, a generalization of (7.24) with additive cumulative hazards
(risks) results. By contrast, we assume independent (and identically distributed) hazard potentials

220
SURVIVAL IN DYNAMIC ENVIRONMENTS
to obtain (7.24) or its generalization. Since independent hazard potentials imply independent
lifetimes (Theorem 4.2) there is a parallel between the manner in which we have approached the
problem and the manner in which it has been traditionally done. However, this parallel loses its
transparency when we consider the scenario of a single unit experiencing k competing hazards,
because now we obtain the formula of (7.25), which for the competing risk scenario appears to be
new. Looking at the competing risk problem from the point of view leading us to (7.25) seems to
be more natural than the one involving a series system. But not too surprisingly, the two scenarios
are related, in the sense that the single unit case is diametrically opposite to the independent
hazard potential case. This is because a single hazard potential X can be seen as a representation
of several identical hazard potentials (namely, the case of total dependence). Recall that any
random variable is totally dependent on itself. As a consequence, for the series system model
of competing risks, when the hazard potentials are positively dependent, the survival function
P T ≥t is bounded as:
exp

−
m

i=1
Rit

≤P T ≥t ≤exp−maxR1t   Rmt	
(7.26)
Thus, the two perspectives on competing risk modeling can be reconciled via the notion of
independent and dependent hazard potentials, the left-hand side of (7.26) reflecting the former
and the right-hand side the latter. It is interesting to note that (7.26) reaffirms a well-known
result in reliability, namely that the reliability of a series system whose lifetimes are ‘associated’
(loosely speaking, positively dependent) is bounded below by the reliability of a series system,
and above by the reliability of a parallel system (cf. Barlow and Proschan, 1975, p. 34).
7.4.2
Stochastic Competing Risks and Competing Risk Processes
The material of section 7.4.1 assumed that the cumulative hazard functions Ritt ≥0i =
12   , were known and specified. Thus, the question of independent or dependent competing
risks was not germane to the material of that section. The issue of independence and dependence
was embodied in the context of hazard potentials. All the same, and for the record, it is useful to
mention that in the existing literature on competing risks, the issue of dependent competing risks
tantamounts to a consideration of dependent lifetimes in the series system model of section 7.4.1.
This I think is a misnomer! A proper framework for describing dependent competing risks
would be to assume that the Rits are random functions, and for this it is best to describe the
cumulative hazard functions via stochastic process models of the form Ritt ≥0	, i=12  
The purpose of this section is to develop a foundation for discussing dependent competing
risks by prescribing a joint stochastic process model for R1tR2t   t ≥0	. The issue of
independent competing risk processes will fall out as a special case. To keep the modeling simple,
I restrict attention to the case of a bivariate stochastic process R1tR2tt ≥0	 and label
it a dependent competing risk process. Dependence between the processes R1tt ≥0	 and
R2tt ≥0	 will induce dependence between the corresponding lifetimes T1 and T2, and this
will ensure that the current view of what constitutes dependent competing risks is encompassed
within the broader framework of dependent competing risk processes. Thus to summarize, in
what follows we consider the scenario of a single item experiencing two dependent competing
risk processes encapsulated via the bivariate stochastic process R1tR2tt ≥0	, where R1t
and R2t, the cumulative hazards, are non-decreasing in t. What kind of models shall we
prescribe for R1t and R2t, and how shall we create interdependence between the two processes
R1tt ≥0	 and R2tt ≥0	? A simple strategy is the one described below. It is based on
the ideas proposed by Lemoine and Wenocur (1985), and by Wenocur (1989), though in a
context different from ours. Note that because of the non-negative and non-decreasing nature of

COMPETING RISKS AND COMPETING RISK PROCESSES
221
the Rits, a bivariate Wiener process for R1tR2tt ≥0	 is unsuitable, and neither is the
two-state MAP of Figure 7.1.
A Bivariate Stochastic Process for the Cumulative Hazards
For purposes of motivation I start with a discrete time version of one of the two processes
mentioned above, say R1tt ≥0	. Suppose that this process can be monitered only at every
h units of time, so that what is at stake here is the sequence R1j	j = 0h2h   nh  
We assume that if at time nh, the state of the process is R1n, then at time n + 1h its state is
determined by a first-order stochastic difference equation:
R1n + 1 −R1n = R1nn + R1nh
(7.27)
where n	 is a sequence of independent and identically distributed random variables. Since
R1t is the cumulative hazard at time t, we need to assume that R10 = 0, and to ensure that
R1t > 0 for t > 0, we require that R10 or R10, or both R10 and R10 are
non-zero. Equation (7.27) states that over h units of time, and starting from some state say ,
R1• will increase on average by an amount E + h, and that the variance of this
average increase is 2V, where E and V are the mean and variance of n. To
guarantee that R1• is strictly increasing with time, we require that •• and n are
non-negative. In particular, we assume that the n’s have a gamma distribution with scale one
and shape h.
As an aside, we note that a diffusion process is a continuous approximation of (7.27), which
in turn can also be seen as a discrete approximation to a diffusion process. When the n’s are
assumed to be normally distributed we are able to utilize the enormous literature of diffusion
processes. But this we are unable to do here because when the n’s are normal, R1t cannot
be non-decreasing in t.
A unit experiencing the process R1tt ≥0	 alone, will fail when this process reaches the
unit’s hazard potential X. If in addition to R1tt ≥0	 the unit also experiences the process
R2tt ≥0	, then the unit will fail when either process first hits X. The two processes in
question compete with each other for the item’s lifelength. With the above in place we need to
make the process R2tt ≥0	 dependent on the process R1tt ≥0	. This after all is what
would genuinely constitute a dependent competing risk process. To do so, a simple strategy
would be to assume that the sample path of R2tt ≥0	 is an impulse function of the form
R2t = 0, for all t ̸= t∗, and R2t∗ = , for some t = t∗> 0, where the rate of occurrence of the
impulse depends on the state of the process R1tt ≥0	. The idea here is that it is a traumatic
event that creates the process R2tt ≥0	, and that the rate of occurrence of trauma depends on
the state of the process R1tt ≥0	. This assumption makes sense if R1tt ≥0	 is interpreted
as degradation or wear [see, for example Yang and Klutke (2000)]. Specifically, we assume that
Pa traumatic event occurs in tt + hR1t = z = 1 −exp−kzh
where k• is some function of z.
If the hazard potential of the item takes the value x, that is if X = x, then given
R10R1h   R1nh, the state of the R1tt ≥0	 process at times 0h   nh the
probability that the unit is surviving at nh is of the form
exp

−h
n−1

j=0
kR1jh

I0xR1nh
(7.28)
where IA• is the indicator function of a set A.

222
SURVIVAL IN DYNAMIC ENVIRONMENTS
Conditioning on R10=0 alone, and taking the limits in (7.28) so that nh→t, the conditional
probability that an item experiencing the dependent competing risk process R1tR2tt ≥0	,
and having its hazard potential set at x, will survive to t is of the form
p0xt = E0

exp
 t
0 −kR1sds

I0xR1t


(7.29)
The right-hand side of (7.29) above can be more generally written as
E

exp
 t
0 −kR1sds

fR1t

def=pt
for some f•; it is known as the Kac Functional of the state process. This functional satisfies
the Feynman–Kac Equation, namely,

t pt = −kpt + Upt
for some U. Under certain conditions on f (namely, that f be bounded and satisfy the Lip1
condition) the Feynman–Kac Equation has a unique solution. Thus, for example, with u =
1u = 0 making Rtt ≥0	 a gamma process, Wenocur (1989) shows that when fu = 1
and ku = u,
pt = exp−t −1 −1 + tlog1 + t
which for  = 0, takes the form
p0t = exp−1 + tlog1 + t + t = PT ≥t
(7.30)
Similarly, when u = 1u = 1fu = 1, and ku = u
PT ≥t = exp−1 + tlog1 + t + t −t2/2
(7.31)
When f• is the indicator function of (7.29) it is bounded but not continuous and therefore
does not satisfy the Lip1 condition. Thus closed-form results analogous to those of (7.30) and
(7.31) cannot be had. All the same if the threshold x is set to a very large value, conceptually
infinite, we may replace the indicator function by the function fu = 1, for all u > 0, and then
use (7.30) and (7.31). In doing so, the effect of x is of course lost.
7.5
DEGRADATION AND AGING PROCESSES
Recently, much is being written on what is known as ‘degradation modeling’, and reliability
assessment using ‘degradation data’; see, (for example, Nair, 1998). According to Lu, Meeker
and Escobar (1996), reliability assessments based on degradation data tend to be superior to those
that are solely based on lifelength data that is either censored and/or truncated. The thinking here
is that the cause of all failures is some degradation mechanism at work, such as the progression
of a chemical reaction, and that failure occurs when the level of degradation hits some threshold.
This is the kind of argument that has been used to motivate the inverse Gaussian as a failure
model (cf. Doksum, 1991). When degradation data is used to assess reliability, the understanding
is that degradation is a phenomenon that can be observed and measured. But this line of thinking

DEGRADATION AND AGING PROCESSES
223
may need a reconsideration because the meaning of degradation seems to suggest that degradation
may not be something that can be directly observed and hence measured. Specifically, our
review of the engineering literature (cf. Bogdanoff and Kozin, 1985) suggests that degradation
is regarded as the irreversible accumulation of damage throughout life, that ultimately leads to
failure. Whereas the term ‘damage’ itself is not defined, it is claimed that damage manifests
as corrosion, cracks, physical wear (i.e. the depletion of material), etc. With regards to aging,
our review of the literature on longevity and mortality indicates that aging pertains to a unit’s
position in a state space wherein the probabilities of failure are greater than in a former position.
Thus it appears that both aging and degradation are abstract constructs that cannot be directly
observed and thus cannot be measured. However, these constructs serve to describe a process
which leads to failure. By contrast, what can be observed and measured are manifestations of
damage, such as crack growth, corrosion and wear. The question therefore arises as to how
one can mathematically model the degradation phenomenon and how can one relate it to the
observables mentioned above. We need to model degradation because it could help us predict,
prolong and manage lifetimes. In what follows, I propose a conceptual framework which links
the unobservable degradation with observable agents such as crack growth and corrosion. This
framework capitalizes on the material of this chapter, in particular, the structure discussed in
section 7.3.4.
7.5.1
A Probabilistic Framework for Degradation Modeling
With degradation seen as an unobservable abstract construct that triggers failure upon hitting a
threshold, and with the observables such as crack growth seen as manifestations of damage, our
proposed framework treats the former as the cumulative hazard and the latter as a covariate or
a marker that influences the former. Recall that covariates and markers are influential variables
that are precursors to failure. In some scenarios, a failure occurs when an influential variable
crosses a threshold. For example, the blood pressure or the pulse rate of a human. When such is
the case, the relationship between a marker and the failure time is deterministic. In some other
situations, failure is not deterministically related to an observable marker. For example, stock
price is a precursor to business failure but there is not a one-to-one relationship between the
two. Some other examples are the tracking of AIDS death by the CD4 cell count and failure
due to fatigue by crack growth. Here, the stock price, CD4 dell counts and crack growth are
markers that provide a diagnostic to impending failure. Markers are often functions of time t,
and as such are best described by stochastic process models, namely, by marker processes. Thus
the phenomenon of degradation (and aging), which we in our framework have identified with
the cumulative hazard, will also be described by a stochastic process Rtt ≥0	, where Rt
is non-decreasing in t. The item fails when Rt hits its hazard potential X, where X has an
exponential distribution with scale one. This fits in well with the view that the failure of an item
occurs when the degradation level hits a threshold.
Thus to summarize, our framework for modeling degradation and an observable that is a
manifestation of damage, is to regard the two as the elements of a bivariate stochastic process
ZtRtt ≥0	 where Zt represents an observable marker, so that Ztt ≥0	 is a marker
process, and Rt represents the unobserved degradation. The behavior of the Rtt ≥0	
process parallels that of the cumulative hazard process discussed in section 7.3. With Zt and
Rt interpreted as above, I shall call the bivariate process ZtRtt ≥0	 a degradation
process.
7.5.2
Specifying Degradation Processes
What are some possible choices for the probabilistic structure of the degradation process
ZtRtt≥0	? A natural one, given the parallel between the basic structure of the degradation

224
SURVIVAL IN DYNAMIC ENVIRONMENTS
process and the material of section 7.3.4, is the Markov additive process. However, this would
require that the process Ztt ≥0	 which represents the observeables such as crack growth,
corrosion and wear be a Markov process. This seems to be a reasonable assumption for which
there is some precedence (cf. Sobczyk, 1987). Should ZtRtt ≥0	 be taken to be a Markov
additive process, and should one wish to use observations on Ztt ≥0	 for inferences about
the process Rtt ≥0	, an exercise that parallels the use of ‘degradation data’ for reliability
assessment, then a statistical theory for inference on degradation processes needs to be developed.
This important issue remains to be addressed and is an open problem.
Another possibility, and one that has been proposed by Whitmore, Crowder and Lawless (1998)
is to use a bivariate Wiener process, actually a Brownian motion process, for ZtRtt ≥0	.
The correlation between the two processes in question determines the usefulness of the marker for
tracking progress of the failure causing process Rtt ≥0	. When a Wiener process is assumed
for Rtt ≥0	, Rt will not be non-decreasing in t. Consequently, looking at degradation as
a cumulative hazard will not make sense and the advantage of interpreting the threshold as an
exponentially distributed (with scale one) hazard potential will not be there. The ability to do
statistical inference using data on the marker process as well as data on failure times is a key
advantage of using a bivariate Wiener process.
The third possibility for linking the degradation and marker processes is through Cox’s
(1972) proportional hazards model. But here we do not specify a direct linkage between Rt
and Zt, rather, a linkage made between the processes rtt ≥0	 and Ztt ≥0	, where
Rt =
 t
0 rsds. With the degradation Rt viewed as the cumulative hazard, rtt ≥0	 is the
hazard rate process of section 7.2. Two strategies for linking rt and Zt have been proposed
in the literature: the proportional hazards model and the additive hazards model (section 4.9.1).
Under the former
rt = r0texpZt
(7.32)
where  is an unknown constant and r0t is a component of rt that is not related to the marker
Zt. Note that in (7.32), rt depends on the value of the marker at time t only, and not the
previous values of the marker. With rt interpreted as the hazard rate, r0t is known as the
baseline hazard (section 4.9.1). Since rt is (informally) the risk that a failure will occur at t,
it is reasonable to attribute the level or risk in terms of the level of a marker, and this is the
motivation behind (7.32).
Under the additive hazards model, proposed by Aalen (1989),
rt = r0t + Zt
(7.33)
where r0t and  have the interpretation given above. The additive hazards model has been
considered by us before (equation (4.59)) albeit in a different context.
Conceptually, the models of (7.32) and (7.33) are a break from the tradition of regression
models in the sense that it is the hazard function, rather than the conditional expectation, that is
the basis of regression. The models are quite flexible and can be generalized in several ways.
For example, Zt can be replaced by its lagged value, say Zt −a for some a ≥0, or by its
integrated value Zt =
 t
0 Zudu. Another possibility would be to extend our consideration to
the case of several markers, say k, so that
rt = r0texpZt
or
= r0t + Zt
(7.34)
where  = 1   k and Zt = Z1t   Zkt′

DEGRADATION AND AGING PROCESSES
225
Processes for Ztt ≥0	 that have been considered before have been a jump process
(cf. Jewell and Kalbfleisch, 1996) and a diffusion process (cf. Woodbury and Manton, 1977)
(section 7.2.3). Recall that in the latter case, the link function used is a quadratic function of the
marker.
A more concrete and manageable possibility is to describe the observable marker Ztt ≥0	
by a Wiener process with drift and diffusion (section 7.2.3) and the degradation process
Rtt ≥0	 by a Brownian Maximum Process (section 7.3), derived from the Wiener process
for Ztt ≥0	. Since the two processes are related to each other, they provide the link between
cumulative hazard and degradation. The details of this kind of modeling and the issues of infer-
ence that it spawns are in Singpurwalla (2006b). The approach leads to a mixture of inverse
Gaussian distributions as the lifetime of a unit experiencing failure due to degradation.
There could be other approaches for modeling the degradation phenomenon discussed here.
One possibility is to consider a Kalman filter type model of section 5.8.2 with Rt as the
unknown state of nature that is non-decreasing in t and an observation equation governed by the
observable Zt. This line of thinking remains to be explored.


Chapter 8
Point Processes for Event Histories
Here lies David Hilbert: He no longer has problems.
8.1
INTRODUCTION: WHAT IS EVENT HISTORY?
The material of Chapter 7 was based on the premise that to capture the effects of dynamic
environments, one may model the hazard function and the cumulative hazard function by a
suitable stochastic process. However, stochastic process models can be made to play a larger
role in reliability theory when one looks at event history data, particularly the life history of
maintained systems, and systems that experience multiple modes of failure, and also when
tracking the condition of degrading units, known to engineers as condition monitoring. Point
process models, which are indeed stochastic processes (section 4.7.6), offer a convenient platform
for doing so. Furthermore, point process models can bring into play the modern technology of
martingales and their associated limit theorems, via the framework of dynamic stochastic process
models (section 8.4). Such theorems facilitate an analysis of point process data, albeit under
asymptotic conditions. Point process data are generated when one continuously tracks the life
history of units and systems.
The aim of this chapter is to give the reader a flavor of the above. But before doing so, it is
incumbent on me to say a few words about what we mean by the terms ‘life-history data’ and
‘event histories’. This I do next.
By life history, we mean here the sample path of a stochastic process as it moves from one
state to another (section 7.3.4). The transition from one state to another creates an event, and
by event history, we mean the collection of points over time, each point representing a time
of transition. Thus, point process models, like the Poisson counting process of section 4.7.4,
come naturally into play. The simplest case is when there are only two states to consider, say
‘functioning’ or ‘failed’, with the latter being an absorbing state (i.e. once the process enters this
state, it is unable to exit it). Figure 8.1 illustrates a two-state system with Figure 8.1(a) depicting
the two states, shown as boxes labeled State 1 and State 0, and Figure 8.1(b) showing the sample
path (or life history) and the event history of the system. The model of Figure 8.1 encapsulates
Reliability and Risk: A Bayesian Perspective
N.D. Singpurwalla
© 2006 John Wiley & Sons, Ltd

228
POINT PROCESSES FOR EVENT HISTORIES
Item
functioning
Item
failed
α (t )
State 1
State 0
(a) State-space of the two-state process
(b) Life and event history of the process
~
Time
States
1
0
0
T
Figure 8.1
State space and sample path of a two-state stochastic process.
much of what we have been discussing thus far under the labels of ‘survival analysis’, ‘life-table
analysis’ and ‘reliability analysis’.
In Figure 8.1 the stochastic process starts in state 1 at time 0, and makes a permanent transition
to state 0 at time T. Since T is unknown at time 0, T is a random variable. The arrow connecting
the boxes in Figure 8.1(a) shows the direction of the transition, and the label t on the arrow
is known as the intensity of the process. It is the rate at which a transition from state 1 to state
0 occurs, and it is akin to the intensity function of a Poisson process (section 4.7.4). In this
two-state scenario, the transition creates a single event at time T, this event being denoted by a
star on the time axis in Figure 8.1(b). With point process models, much interest centers around
the quantity t. I therefore need to first articulate the meaning of t.
Our interpretation of t, the intensity function of a point process, can be motivated by the
material of section 4.7.4 on the intensity function t of the non-homogenous Poisson process.
We recall from there that t = dt/dt, where t = ENt, and Nt is the number of
events up until time t ≥0. Thus, t can also be written as
t = lim
dt↓0
E Nt + dt −Nt
dt
	
(8.1)
The independent increments property of the Poisson process mandates that t does not
depend on the history of the process up until t. Suppose now that I generalize the above by
conditioning on a quantity t, where t denotes the collection of all that can be observed in
0
t, and then define
t = lim
dt↓0
1
dt E Nt + dt −Ntt
(8.2)
as the intensity function of a point process. In doing so we must assume that the limit exists. It
is this generalization that gives birth to the notion of a dynamic model, that is, a model in which
the future development is explained in terms of the past.
In the case of the two-state process of Figure 8.1, t takes a familiar form, namely,
t = lim
dt↓0
Pt ≤T ≤t + dtT ≥t
dt


OTHER POINT PROCESSES IN RELIABILITY AND LIFE-TESTING
229
thus tdt is (approximately) the probability that the process makes a transition from state 1 to
state 0 in the interval t
t + dt, given that it was in state 1 at time t. Alternatively seen, t
is also the failure rate at t of the survival function of T. This type of a connection between the
failure rate function and the intensity function (of a non-homogenous Poisson process) has been
seen by us before vis-à-vis (7.3) and (7.4) of section 7.2. It is important to bear in mind that
the t of (8.2) has been shown to be identical to the failure rate function of PT ≥t when
the stochastic process is a two-state process of the kind described in Figure 8.1. This in general
need not always be the case.
8.1.1
Parameterizing the Intensity Function
In certain scenarios, especially the medical ones, there may be explanatory variables (or covari-
ates) upon which T depends. Such variables could be qualitative, such as sex, geographical
region, name of manufacturer, or quantitative, such as blood pressure, time in storage, etc. When
such is the case, the explanatory variables become a part of t, the observable history, and so
their effect needs to be incorporated in t. One strategy for doing so is to parameterize t
via the multiplicative proportional hazards model of Cox (1972) – equation (7.32). When such
is the case, one writes
t = 0texp′Zt
(8.3)
where  = 1
   
p′ is a vector of parameters and Zt = Z1t
   
Zpt′ is a vector of
time-dependent covariates; 0t, known as the baseline intensity, is the intensity of transition
when Zt = 0, for t ≥0.
There is another, more encompassing, approach for parameterizing t. This approach, due
to Aalen (1987), is known as the multiplicative intensity model. The framework of this model
includes the parameterization specified in (8.3), as well as the intensity functions appropriate to
the several scenarios that will be described in section 8.3. Besides its generality, a key advantage
of the multiplicative intensity model is that it enables us to invoke the martingale theory of
point processes. Because of the importance of this model, its role will be articulated in separate
sections – sections 8.3 and 8.4 – once the practical scenarios of section 8.2 are put forth. Pe˜na and
Hollander (2004) give an exhaustive and up to date overview of the various parameterizations
for (t) with a particular focus towards applications in biomedicine.
8.2
OTHER POINT PROCESSES IN RELIABILITY AND LIFE-TESTING
Whereas the two-state point process discussed before serves as a convenient vehicle for illustrat-
ing the basic ideas and notions about point processes, a better appreciation of the usefulness of
such processes can be had by looking at some other, more general problems in reliability and sur-
vival analysis. I have in mind four archetypical scenarios: the first pertains to items experiencing
multiple modes of failure; second, to items experiencing degradation prior to failure; and third
involving items experiencing maintenance and repair. My last scenario pertains to life-testing
wherein censoring and withdrawals come into play. Each of these is described below.
8.2.1
Multiple Failure Modes and Competing Risks
In general, it is difficult to pinpoint a single incident, or a collection of incidents, as the true (i.e.
a genuine) cause of an item’s failure. However, it may be possible to describe the manner in
which an item can fail, assuming that it can fail in several ways. For example, a series system
of k units can fail in at least k different ways, each corresponding to the failure of a particular

230
POINT PROCESSES FOR EVENT HISTORIES
unit or the simultaneous failure of more than one unit. Engineers refer to the different ways
of failure as failure modes, and often these are taken as the (prima facie) causes of failure.
When an investigation of failure (such as a postmortem) entails specifying the mode of failure,
the exercise is known as failure mode and effects analysis, or simply FMEA. The scenario of
multi-mode failure is not unlike that of competing risks discussed in section 7.4.1. There, the
matter was conceptualized in terms of the hitting times of several cumulative hazard functions
(deterministic or stochastic) to a threshold. The strategy described here is different; it is based
on intensities of transition from working state to the failed state, the failed state being indexed
by a mode of failure (Figure 8.2).
In Figure 8.2(a), I show the possible transitions of a unit that can experience k modes of failure,
from the functioning state labeled 1, to one of the k failed states labeled 01
   
0k. The
it’s denote the intensities of transition from state 1 to state 0i
 i = 1
   
k. Figure 8.2(b)
shows the life and event history of the unit were a transition to state 0i at time Ti be the only
mode of failure.
~
Time
States
1
0
0
Min(Tj)
(c) Life and event history of unit failing
~
Time
States
1
0(i)
0
Ti
(b) Life and event history of unit transitioning to state 0
Item
functioning
Item
failed
Item
failed
Item
failed
State 1
…
…
State 0(1)
State 0(i)
State 0(k)
α1(t)
αi(t)
αk(t)
(a) State space of a unit with k failure modes
Figure 8.2
State space and sample paths of a unit with k failure modes.

OTHER POINT PROCESSES IN RELIABILITY AND LIFE-TESTING
231
Note that for the scenario of Figure 8.2, the underlying stochastic process for the life history
of the unit has a state space of size k + 1, and even though k different events are possible –
with each illustrated via a sample path of the kind shown in Figure 8.2(b), – only one will be
observed, namely, the one corresponding to the time of the first transition. This is shown in
Figure 8.2(c). The challenge here is to prescribe a meaningful model for each of the it’s.
One strategy would be to assume that an it depends on the history of Ti alone (i.e. supposing
that 0i is the only mode of failure), so that it is the failure rate function of PTi ≥t, for
i = 1
   
k. Were we to conglomerate the k-failed states into one (failed) state, say state 0,
and denote by t the intensity of transition from state 1 to state 0, then it is only logical to
suppose that t would depend on the history of all the k Ti’s, so that t must be a function
of 1t
   
kt. With that in mind, one possibility is to set t = k
i=1 it, making t
the sum of the failure rates of the survival functions of the k Tis. But t is itself the failure
rate of the survival function of min
j
Tj (Figure 8.2(c)). Thus, the assumption t = k
i=1 it
yields a result parallel to that of (7.24) on competing risks with independent hazard potentials.
Alternatively put, the assumption of additive intensities can be justified from the point of view of
independent hazard potentials. Similarly, the choice t = max
i
it can be justified via (7.25)
of section 7.4.1 wherein we considered a common hazard potential.
8.2.2
Items Experiencing Degradation and Deterioration
We next turn attention to the scenario of items experiencing degradation prior to failure. Suppose
that a unit can exist in k + 1 states, states 1 to k being functioning states, with state 1 being
a perfect (non-degraded) state, and state 0 being a failed state. In Figure 8.3(a) I show the
state space and one possible transition protocol for this unit. Here, the unit can transition from
its current state to either its neighboring degraded state or the failed state. Other protocols are
possible. In Figures 8.3(b) and (c) I show two possible sample paths for the said process. In the
former the unit traverses all the k degraded states prior to failure; in the latter the unit fails after
existing in only three of the k possible degraded states. The sample path of Figure 8.3(b) shows
that the process can generate k events, each denoted by a star on the time axis. Figure 8.3(c)
illustrates the scenario wherein less than k events are generated by the process.
The arrows between the states have labels involving ij
 i = 1
   
kj = 0
2
   
k. These
encapsulate the intensity of transition from state i to state j. When the probability of transition
from state i to state j depends only on the time, then ij will be indexed by t and written ijt,
where
ijt = lim
dt↓
1
dt Pij t
t + dt	
(8.4)
Here Pij s
t is the probability that a unit in state i at time s will transition to state j at time
t ≥s. With ijt as written above, the underlying process is Markovian. When ijt = i
j for
all i
j = 1
   
k
 and t ≥0, the underlying process is time homogenous and Markovian.
More generally we may want to assume a semi-Markovian structure wherein the transition
intensities depend not only on the states in question but also on the time t and the time spent in
the current state. Thus, a transition form state i to the state j at time t will depend on i, j, t and
Ti, the time spent in state i. This makes sense because a long time spent in the working state
could increase the probability of transitioning to the failed state. When such is the case the ij’s
will be indexed by both t and Ti, and written ijt
Ti.
8.2.3
Units Experiencing Maintenance and Repair
I now consider the scenario of units that are subjected to scheduled maintenance and unscheduled
repairs due to random failures. Often scheduled maintenance occurs at preset times; however,

232
POINT PROCESSES FOR EVENT HISTORIES
(a) State-space of a unit experiencing degradation
~
Time
States
1
0
0
~
2
3
k
…
(b) Life and event history of unit
0
State 1
(perfect)
State k
(degraded)
State 3
(degraded)
State 2
(degraded)
…
State 0
(failed)
α10(t,T1) 
α12(t,T1) 
α23(t)
α20(t)
α30(t)
αK0(t)
T1
T3
T2
Tk
Time
States
1
0
2
3
k
T1
T3
T2
…
(c) Life and event history of unit
Figure 8.3
State space and sample paths of a unit in degraded states.
in actuality it happens at times in the vicinity of the schedule so that planned maintenance
could also be random. Subsequent to any maintenance/repair action, a unit may be restored to
a working state, or it may be permanently discarded. Units that are restored to a working state
may experience a minimal (or imperfect) repair (Brown and Proschan, 1982). The state space of
the above-described maintenance/repair process is shown in Figure 8.4(a). Note that there could
be a transition from maintenance to repair; this is because routine maintenance could uncover
the need for repairs to avoid impending failures. A possible point process generated by this
maintenance/repair phenomenon is shown in Figure 8.4(b). It is for illustrative purposes only;
other life histories are also possible.
The Ti’s of Figure 8.4(b) indicate the up-times (i.e. the functioning times) of the unit; the Di’s
are the down-times, be they due to maintenance or due to repair. Here again the arrows between
the states have labels involving ij, i
j = 0
1
2
3 with each ij indexed by a t alone or by a
t and a Ti. When indexed by t alone the life- (or event-) history process is Markovian; when
indexed by a t and a Ti, the process is semi-Markovian. The simplest life-history process is a
time homogenous Markov process wherein the ij’s are not indexed by time at all.

OTHER POINT PROCESSES IN RELIABILITY AND LIFE-TESTING
233
α13(t)
T1
T3
T2
D1
D2
Item 
discarded
α12(t)
α21(t, T2) 
α31(t, T3) 
Item 
functioning
Item under 
maintenance
Item under 
repair
α30(t, T3) 
α20(t, T2) 
α23(t)
State 1
State 2
State 3
State 0
(a) State space of an item experiencing maintenance/repair
Time
States
1
0
0
2
3
T1
T3
T2
~
D1
D2
(b) Life and event history
Figure 8.4
State space and sample path under maintenance and repair.
In all the scenarios discussed hereto, including the one of section 8.1, interest generally
centres around availability; i.e. the proportion of time (over some time horizon) the unit is in a
functioning state.
8.2.4
Life-testing Under Censorship and Withdrawals
The notion of censoring was introduced by me in section 5.4.1 wherein strategies for designing
industrial life-tests were discussed. Whereas censorship can be a matter of design, often it is
not, and particularly so when we are confronted with retrospective failure data; i.e. data that
is generated in the field. The matter of censorship is quite important in the context of medical
survival studies or studies pertaining to drug approval. Here, a group of (presumably identical)
individuals are observed over some period of time with the aim of assessing the distribution
of the time to a certain event, say the remission of a disease, or relating this distribution to
individual characteristics. Since individuals may opt to withdraw from a study, or the study itself
may be terminated at some arbitrary time, censorship and withdrawals are a facet of medical
survival studies that is outside an experimenter’s control.
Thus, a typical feature of medical survival data with interest centered around the lifetime
Ti of the i-th individual, i = 1
   
n, is that one is not able to observe a Ti for every one
of the n individuals in the study. For some individuals I may know that Ti exceeds some
quantity ci; i.e. Ti is right-censored (or time-truncated) at ci. Any particular ci could be a
consequence of an individual’s withdrawal from the study, or an individual’s record being
lost to a follow-up or the termination of the study. I may therefore describe the event his-
tory of i-th individual by a process which starting from state 1 (surviving) can take at most
one downward jump to state 0 (failed), the occurrence or not of the jump depending on
whether Ti ≤ci, or not (Figure 8.5). The state space of this process is identical to that of
Figure 8.1(a).
There is another aspect of medical survival data that I will not discuss here in the context
of point process models. This pertains to postmortem information wherein the actual value

234
POINT PROCESSES FOR EVENT HISTORIES
~
Time
ci
Time
State 1
State 0
0
Ti
State 1
State 0
0
Figure 8.5
Event history with censoring (failure) at ciTi.
of Ti is not observed, but it is known that Ti < i, where i is the time of the postmortem
(section 4.4.3).
8.3
MULTIPLICATIVE INTENSITY AND MULTIVARIATE POINT
PROCESSES
In section 8.1.1 it was mentioned that there is another, more encompassing, approach for param-
eterizing t, and that was via Aalen’s (1987) multiplicative intensity model. Here one assumes
that the intensity function t is of the general form
t = 0 tZ t
t ≥0
(8.5)
where 0 t is some unknown deterministic function of time, and Zt is an observable stochastic
process over 0
t. Aalen and Huseby (1991) use this kind of an approach to model several
scenarios in biomedicine. Since Zt is a stochastic process, so will be t; consequently, the
process tt ≥0 is known as the intensity process. The notion of an intensity process has
already been introduced by me, in section 5.2.4, via the context of a doubly Stochastic Poisson
process (or the Cox Process). But the idea can be made more general; see Yashin and Arjas
(1998) and section 8.3.1.
To see how the multiple failure mode scenario of section 8.2.1 can be made to fit into the
framework of equation (8.5), consider the relationship t=k
i=1 i t. Suppose, for now, that
1 t = 2 t =    = k t = 0 t, where 0 t is unknown. Then I may write
t = 0 tZ t
(8.6)
where the stochastic process Z tt ≥0 is determined by the relationship Zt = k, for t <
min
i
Ti, and Zt = 0, otherwise. Here Zt can interpreted as the number of failure modes that
are at the risk of transition to state 0 at the time t.
When the i t’s cannot be assumed equal, and also when a unit experiences degradation, or
maintenance and repair, the univariate point process model discussed thus far is inadequate. It
needs to be generalized to the multivariate case; this is described next.
8.3.1
Multivariate Counting and Intensity Processes
A univariate counting (or point) process was informally introduced in section 4.7.4 under the
venue of a Poisson process, and also in the materials of sections 8.1 and 8.2. More formally,
a counting process Ntt ≥0 has a sample path that is an integer-valued step function with
jumps of size +1, and is assumed here to be right continuous, with N0 = 0. Thus Nt denotes
the random number of points (i.e. the events of interest) that have occurred in the time interval
0
t (Figure 8.6).

MULTIPLICATIVE INTENSITY AND MULTIVARIATE POINT PROCESSES
235
Time t
N(t)
1
0
2
3
Figure 8.6
Right-continuous sample path of a counting process.
Associated with any counting process Ntt ≥0 is its intensity process tt ≥0, where
t is defined as:
t dt = PNt jumps in an interval of lengthdt around time tt−
(8.7)
and, as before, t−denotes all that can possibly happen until just before time t (equation (8.2)).
A collection of n univariate counting processes Nitt ≥0
 i = 1
   
n constitutes a
multivariate counting process, denoted Ntt ≥0. Associated with a multivariate counting
process Ntt ≥0 is an intensity process tt ≥0 where t = 1t
   
nt, is a
collection of n intensity processes. There is an additional caveat about what constitutes a multi-
variate counting process, and that is the requirement that no two components of the process jump
at the same time. The components of a multivariate counting process may depend on each other.
With the notion of a multivariate counting process in place, it is easy to see how the scenario
of the multiple mode failure with the it’s distinct can be made to fit into its framework. To
see this, let the counting process Nitt ≥0 be associated with the failure mode i, i=1
   
k.
This process can take at most one jump, and its intensity process is i tZtt ≥0, where
the observable process Ztt ≥0 is such that Zt = 1, if min
i
Ti ≥t; Zt = 0 otherwise.
Thus, the multiple mode failure phenomenon can be modeled as a multivariate counting process
Ntt ≥0, where Nt=N1t
   
Nkt, with intensity process tt ≥0 where t=
1tZt
   
ktZt.
The scenarios of Figures 8.3 and 8.4 can also be modeled via a multivariate counting process
Nijt t ≥0
 i
j ∈, where Nijt denotes the number of transitions from state i to state
j in time 0
t, and  is the state space of the process. For the degrading unit scenario,
 = 0
1
   
k, whereas for the maintenance/repair scenario,  = 0
1
2
3. For defining a
multiplicative intensity function associated with each of the above component processes, we let
the indicator function Zit = 1, if the device is in state i just prior to time t (i.e. the device
is at the risk of transition out of state i), and Zit = 0, otherwise. Then, the intensity process
associated with the counting process Nijtt ≥0 assuming that the process is Markovian is
of the form ijtZitt ≥0. When the process is semi-Markov, the ijt gets replaced by
ijt
Ti.
Perhaps the best known, and possibly the most discussed, application of multivariate point
processes and their intensity processes pertains to the treatment of censored survival data
(section 8.2.4). Here one defines the i-th component of a multivariate counting process via
Nit = ITi ≤t
Di = 1, where I• is the indicator function, and Di = 1, if Ti is an observed
survival time; Di = 0 otherwise. With an exchangeable population of n individuals under obser-
vation, i = 1
   
n, and in what follows we assume that the n pairs Ti
Di are independent.
The process Nitt ≥0 jumps to 1 at Ti, if Ti is a time to failure; otherwise the process does
not jump at all.

236
POINT PROCESSES FOR EVENT HISTORIES
Since the n individuals in the study are judged to be exchangeable, the survival times Ti,
i = 1
   
n, have a common distribution. Let t denote the failure rate of this common
distribution. Then, itt ≥0, the intensity process of Nitt ≥0, is given as it =
tZit, where Zit = 1 if Ti ≥t, and ci ≥t; Zit = 0, otherwise. To see why, note that at
time t, we know that either the i-th individual is surviving and still under observation or the
individual is no more under observation because of censorship or failure. In the latter two cases,
the probability of Nit taking an upward jump (in the vicinity of t) is zero. In the former case
it is the failure rate at t.
Thus to summarize, the life-testing with the censorship scenario of section 8.2.4 can be
described via a multivariate counting process Nt=N1t
   
Nkt with an intensity process
tt ≥0, where t = tZ1t
   
tZkt, with Zit = 1, if the i-th individual is
surviving at t; Zit = 0, otherwise. Alternatively, we may also describe the said scenario via
a univariate counting process Ntt ≥0 with an intensity process tZtt ≥0 where
Nt = t
i=1 Nit, and Zt = t
i=1 Zit. Here Zt would connote the number of individuals at
risk, just prior to t.
When the population under observation cannot be judged homogenous, the intensity process
of the multivariate counting process takes the form t = 1tZ1t
   
ktZkt, where
it is the failure rate of the distribution of Ti.
I close this section by affirming the generality of the multiplicative intensity model vis-à-vis
its relevance to a wide range of scenarios in reliability modeling, and for life-testing under
censorship. The next task is to show how the structure of this model facilitates an analyses of
random failures via martingales and their associated limit theorems. This is outlined in section 8.5,
but to better appreciate the material therein it is necessary to give an informal overview of a
dynamic stochastic process model, its martingale properties and the Doob–Meyer decomposition
of stochastic processes. This is done next in section 8.4.
8.4
DYNAMIC PROCESSES AND STATISTICAL MODELS:
MARTINGALES
The purpose of this section is to provide an overview of dynamic stochastic process models
and their martingale properties. This I do in an informal setting by considering a discrete time
stochastic process Xtt = 1
2
   . The material here is largely based on Aalen (1987). The
essence of a dynamic process is that the present course of the process depends on its past history.
This section also enables us to introduce terminology that is specific to the theory of martingales,
terminology that will facilitate the reading of the material of section 8.5.
Assuming X0 known, I start by focusing attention on Xt −Xt−1, the change experienced by
the process between time t −1 and t. By assuming that the time interval t −1
t is small,
Xt −Xt−1 could be seen as the instantaneous change experienced at time t. We then ask what
would be our ‘best’ prediction of Xt −Xt−1, were we to know X1
   
Xt−1? A meaningful
answer to this question would be the conditional expectation
EXt −Xt−1  X1
   
Xt−1
def= Vt	
With Vt as a predictor of Xt −Xt−1, the error of prediction would be Xt −EXt  X1
   
Xt−1.
Motivated by the fact that
t
j
Xj −Xj−1 = Xt, I may consider the sums
t
j
Vj
def= Ut, and
t
j
Xj −EXj  X1
   
Xj−1
def= Mt, and declare that
Xt = Ut + Mt
t = 1
2
  
(8.7)

DYNAMIC PROCESSES AND STATISTICAL MODELS: MARTINGALES
237
This relationship implies that the sum of changes in Xt equals the sum of all the predicted
changes plus the sum of prediction errors. More generally, we may say that the process Xtt =
1
2
    has been split into two processes Utt = 1
2
    representing the sum of our best
predictions of the instantaneous changes, and the process Mtt = 1
2
    representing the
sum of our errors of prediction. Equation (8.7) is known as the Doob Decomposition of the
process Xtt = 1
2
   .
Innocuous as it may appear, the Doob decomposition is endowed with some striking properties.
These properties enable such decompositions to play a fundamental role in probability theory.
To appreciate why, I start by noting that
EMt  X1
   
Xt−1 = Mt−1
(8.8)
a feature that can be verified via (8.7) and the fact that EXt  X1
   
Xt−1 −Xt−1 = Vt. The
relationship (8.8) implies that the expectation of Mt given the past equals its value at time
t −1. A process Mtt = 1
2
    satisfying the properties of (8.8) is called a martingale
with respect to the process Xtt =1
2
   . The term ‘martingale’ is an acronym that derives
from a French term that describes a gambling strategy of doubling one’s bet until a win is
secured. This gambling strategy captures the notion of a fair game.
In probability and statistics, martingales arise quiet often, in a large variety of contexts.
Some examples are sums of random variables, branching processes, urn schemes, Markov
chains, and likelihood ratios. In other words, martingales are all around us. One of their
biggest virtues is that subject to a condition on their moments, they always converge –
this is Doob’s convergence theorem. Roughly speaking, this theorem says that if Mtt =
1
2
    is a martingale with E

M2
t

< K < , for some K and for all t, then there exists
a random variable M such that Mt converges to M (almost surely and in mean square).1
Theorems like this and other martingale-related theorems such as the Doob–Kolmogorov
inequality2 enable one to study estimators, test statistics, and other likelihood based quan-
tities when they are given a martingale representation. Thus the attractiveness of martin-
gales. But how do martingales differ from the traditional scenario of independent, identically
distributed random variables, and processes with independent increments? To address these
questions let us focus attention on the martingale differences Mt −Mt−1 and explore their
properties.
Using the relationship of (8.8) and the fact that for any two random variables X and Y,
EX = EYEXY, we can show that:
EMt −Mt−1 = 0
(8.9)
and that
EMt −Mt−1Mt−1 −Mt−2 = 0	
(8.10)
Thus, the sequence of martingale differences Mt −Mt−1 can be seen as a generalization of
the usual error theory assumptions made in statistical modeling. The errors are usually described
via zero mean, independent and identically distributed random quantities. The generalization
1 Let M1
M2
   
Mn
   be a sequence of random variables, and M another random variable, with the property that E Mr
n<
for all n and for some r ≥1, and EMn −Mr ↓0 as n ↑. Then the sequence is said to converge in mean (mean square) if
r = 12.
2 If Mtt = 1
2
    is a martingale with respect to Xtt = 1
2
    then P max
1≤i≤nMi ≥ ≤1
2 EM2
n whenever  > 0.

238
POINT PROCESSES FOR EVENT HISTORIES
here is suggested by the property of (8.9), which implies uncorrelatedness (but not necessar-
ily independence). The relationship of (8.9) is known as the property of orthogonal incre-
ments and this is what distinguishes the martingale property from the independent increments
property.
The martingale differences serve the same function as the errors (in predicting the changes
Xt −Xt−1 by Vt), and are also known as innovations since they represent the new development
in the process. Because the Ut’s are a function of the Xt’s up until Xt−1, the process Utt =
1
2
    is called a predictable process. Some other properties of martingales and martingale
differences will be described later, once we discuss the decomposition of continuous time
processes, especially the counting process, which are the focus of our discussion in Chapter 8.
8.4.1
Decomposition of Continuous Time Processes
There is a generalization of the Doob decomposition to continuous time stochastic processes; it
is called a Doob–Meyer decomposition. Here, as a continuos time analogue to (8.7), we write
Xt = Ut + Mt
for t ≥0
(8.11)
where the process Mtt ≥0 is a martingale with respect to the process Xtt ≥0, and the
process Utt ≥0 is determined by an integral of the ‘best’ predictions; i.e.
Ut =
t
0
Vs ds	
(8.12)
The process Vtt ≥0 is such that each Vt is known just before t; it is called a local charac-
teristic. The process Utt ≥0 is known as a compensator of the process Xtt ≥0.
By a dynamic statistical model we mean any parametrization of the predictable process
Vtt = 1
2
   or t ≥0. An archetypal example is the linear model Vt =
k
t
tZt, where the
i’s are unknown coefficients and each of the kZt’s are observable and predictable stochastic
processes. Another example is an autoregressive process with random coefficients
Xt −Xt−1 = tXt−1 + Mt −Mt−1
obtained by setting Vt = tXt−1 and combining it with (8.7).
In the continuous setting, expressions that are analogous to (8.8) and (8.9) of the discrete case
take the forms
EMt  t− = Mt−
and
EdMt  t− = 0
respectively; these expressions have a role to play in describing a central limit for martingales.
I next introduce the notion of a predictable variation process of a martingale, namely, the process

Mtt ≥0, where
d 
Mt
def= E

dM2
t  t−

= VardMt  t−	

DYNAMIC PROCESSES AND STATISTICAL MODELS: MARTINGALES
239
The above process is predictable and non-decreasing. It can be seen as the sum of the
(conditional) variances of the increments Mtt ≥0 over small intervals that partition 0
t
(Gill, 1984), from which the material below has been abstracted.
For two martingales Mtt ≥0 and M′
tt ≥0 the predictable covariance process,

Mt
M′
tt ≥0 can be analogously defined.
The ideas and notions described above can be made concrete via the scenario of a univariate
counting process Ntt ≥0 of section 8.3.1. I start with the Doob–Meyer decomposition of this
process via the template of (8.11) and (8.12) so that the martingale Mtt ≥0 is asserted as
Nt =
t
0
Vs ds + Mt
(8.13)
where the local characteristic Vs is the intensity process ss ≥0 of the point process. This
intensity process can also be written as
t dt = EdNtt−
(8.14)
this is because in a small interval of time dt, Nt either takes a jump or does not.
As an aside, a dynamic statistical model underlying this counting process can be had by param-
eterizing t via one of the several multiplicative intensity processes described in section 8.3.1,
or via the Cox model of (8.3), depending on the scenario at hand.
Since dNtt− is a zero or one random variable with expectation t dt, its conditional
variance is t dt1 −t dt ≈t dt. Consequently, the quantity 
Mt is of the form

Mt =
t
0
s ds
so that the predictable variance process of the counting process Mtt ≥0 is
	 t
0 s dst ≥0

.
To illustrate the nature of the predictable covariance process spawned by two counting processes,
suppose that there is another counting process N ′
t t ≥0 whose intensity process is ′tt≥0.
Suppose that the two counting process under consideration constitute a bivariate counting process,
so that Nt and N ′
t do not simultaneously experience a jump. That is, dNtdN ′
t  is always
zero, and hence the conditional covariance between dNt and dN ′
t is t dt′tdt ≈0.
Consequently the predictable covariance process 
Mt
M′
tt ≥0 = 0. When such is the case
the two martingale processes Mtt ≥0 and M′
tt ≥0 are said to be orthogonal.
8.4.2
Stochastic Integrals and a Martingale Central Limit Theorem
Suppose that Mtt ≥0 is a continuous time martingale and Htt ≥0 some predictable process.
Define a new process, say M∗
t t ≥0, which is a transformation of Mtt ≥0 by the stochastic
integral
M∗
t =
t
0
HsdMs
so that dM∗
t =HsdMs. Then it is easy to verify that the process M∗
t t ≥0 is also a martingale
and that its predictable variance process is

M∗
t  =
t
0
Hs2 d 
Mt	

240
POINT PROCESSES FOR EVENT HISTORIES
In a similar manner, we may obtain the predictable covariance process of the integrals of two
predictable processes with respect to two martingales.
The martingale central limit theorem prescribes conditions under which a martingale converges
to a Brownian motion process Ztt ≥0 (section 7.2.3). Loosely speaking, consider a sequence
of martingale processes Mn
t t ≥0 and n = 1
2
    such that the jumps of Mn
t
becomes
smaller as n increases; that is, Mn
t
gets small as n increases; that is, Mn
t
becomes more and
more continuous. Furthermore, suppose that as n increases, the predictable variance process of

Mn
t t ≥0

becomes deterministic; i.e.

Mn
t

t ≥0

→At, where A• is a deterministic
function. Then Mn
t
converges in distribution to Zt as n →. Specifically, for each t, Mn
t
has a Gaussian distribution with mean 0 and variance At, and the increments of Mn
t
are
independent (and no more merely orthogonal!).
8.5
POINT PROCESSES WITH MULTIPLICATIVE INTENSITIES
To set things in perspective, I start this section with an overview of what has been said so far
in sections 8.1–8.3. Section 8.1 pertained to articulating what one means by event- and life-
history data, and the role of a point process for describing these data. Also introduced therein
was the notion of the intensity function and the parameterization of this function. Section 8.2
pertained to looking at several scenarios in reliability modeling, such as competing risks, degra-
dation and deterioration, multi-mode failures and maintenance (replacement/repair) problems,
as point processes. Also considered therein was the scenario of life-testing with censoring and
withdrawals. In section 8.3, I introduced multivariate counting processes and their associated
intensity processes. A key feature of the material here was a parameterization of the intensity
function in a multiplicative form involving an unknown function and an observable stochastic
process; (equation (8.5)). The observable stochastic process is a consequence of the nuances
associated with the scenarios considered in sections 8.1 and 8.2. In some sense, parameterizing
the intensity function in a multiplicative form is the crux of the material in section 8.3.
Overall, the main message underlying all that has been said thus far is the important role played
by point processes and their multiplicative intensity functions for describing a wide range of
scenarios that arise in reliability modeling and survival analysis. Having done so, we now divert
our attention to the material of section 8.4. The essential import of this material is that a point
process spawns, via the Doob–Meyer decomposition, a martingale process which enjoys, among
other things, convergence to a Brownian motion process, via a central limit theorem. Section 8.4
also describes the transformation of a martingale to another martingale via a stochastic integral.
Such transformations come into play when one wishes to do inference involving point process
data.
The aim of this section is to show how the material of sections 8.1 through 8.3, which is
specific to reliability modeling and survival analysis, can be connected with the material of
section 8.4 on martingales to obtain results that provide meaningful descriptions of the several
stochastic failure processes. The key to doing so is to link counting processes and martingales.
Accordingly, suppose that Ntt ≥0 is a univariate counting process with an intensity process
ss ≥0. Suppose further that t = 0tZt, where 0t is an unknown function of
time and Zt is an observable stochastic process over 0
t (equation (8.5)). Then, by the
Doob–Meyer decomposition of the counting process, we may write, for t ≥0
Mt = Nt −
 t
0 sds
(8.15)
where Mtt ≥0 is a martingale and the process
	 t
0 sdss ≥0

is a compensator of the
counting process. Because Mtt ≥0 is a martingale EMt   u = Mu
u < t.

POINT PROCESSES WITH MULTIPLICATIVE INTENSITIES
241
Equation (8.15) is the basis for a unified approach to studying the behavior of items expe-
riencing the types of issues described in sections 8.1 and 8.2. Since the compensator is a
predictable process, Nt inherits the martingale properties of Mtt ≥0, in particular the
martingale central limit theorem and the Doob convergence theorems. Thus, we are able to
discuss the asymptotic behavior of the univariate and multivariate counting process introduced
in sections 8.1–8.3. These counting processes provide insight about the stochastic behavior of
items and systems under study.


Chapter 9
Non-parametric Bayes Methods in
Reliability
Here lies Stephen Banach: with plenty of space.
9.1
THE WHAT AND WHY OF NON-PARAMETRIC BAYES
By the term ‘non-parametric Bayes methods in reliability’, I mean an analysis of life history
data without the use of any of the chance distributions mentioned in Chapter 5, or for that matter
any other parametric family of chance distributions. Thus the methods of this chapter serve the
same purpose as those of section 5.4. Furthermore, as it will become clear in the sequel, there
are elements of commonality between the strategies to be proposed here and those discussed in
Chapter 7 on stochastic hazards – thus the placement of the material of this chapter subsequent
to that of Chapter 7 (and also that of Chapter 8).
A motivation for considering non-parametric Bayes methods in reliability and survival analysis
is prompted by the often expressed view that, in any Bayesian analysis, the specification of a
realistic likelihood is more important than the kind of priors endowed on its parameters. Chance
distributions almost always form the basis of constructing likelihoods and thus their judicious
choice is a matter of importance. Non-parametric Bayes methods come into play when one
wishes to perform a Bayesian analysis of failure time data using a likelihood function that is
not suggested by any standard distribution used in reliability, such as the exponential and the
Weibull. However, there is a price to be paid for doing so, a price similar to that paid when one
uses binary success/failure data in lieu of the actual time to failure data.
In non-parametric Bayes, the general strategy is to place a prior distribution on the class of
all probability distribution functions, say F, and using life-history data to obtain a posterior
distribution on the class of all probability distributions. The unknown distribution function F is
the ‘parameter’ in non-parametric problems. A variant of the above strategy is to place a prior
distribution on the class of all cumulative hazard functions, or on the hazard rates themselves.
Endowing prior distributions on the hazard rate function is an attractive option because hazard
rates are easy to interpret and can be generalized to more complicated models like Markov
chains.
Reliability and Risk: A Bayesian Perspective
N.D. Singpurwalla
© 2006 John Wiley & Sons, Ltd

244
NON-PARAMETRIC BAYES METHODS IN RELIABILITY
What constitutes a meaningful and workable family of prior distributions is a challenging
issue that has generated an array of imaginative and impressive ideas, the papers by Ferguson
(1973) and by Doksum (1974) being landmark events. A striking feature of these approaches is
the realization that the prior distributions for the underlying distribution functions constitute a
stochastic process, and so the issue boils down to identifying those processes that lend themselves
to a convenient prior to posterior transformation. Connection with the material of Chapter 7 is
now clear, even though the motivations are different; modeling in the case of Chapter 7, and
inference in the case of Chapter 9. The novelty here is that we are considering a prior to posterior
conversion of a stochastic process using life-history data.
In what follows, I give an account of the basic set-up and a broad-brushed perspective of
the key developments. The details have been deliberately kept to a minimum, the hope being
that interested readers will go to the original references cited to fill in the gaps. The Dirichlet
distribution and its variants – the ordered and the generalized Dirichlet – play a fundamental
role, and so does the Lévy process of section 7.2.2. The Dirichlet distribution spawns the
Dirichlet process, which is a candidate prior process on the class of all distribution functions.
Thus, section 9.2 is devoted to a review of the Dirichlet distribution and its variants. In the
context of the theme of this chapter, the Dirichlet distribution has entered into the arena via the
papers of Kraft and Van Eeden (1964) and of Ramsey (1972). These pertain to the development
of Bayesian methods for bioassay (or dose–response experiments). Note that the potency curve
mentioned in section 5.8.1 being non-increasing and bounded between zero and one behaves
like a survival function. Thus, from a chronological point of view, one may see the works of
Kraft and Van Eeden, and Ramsey as a starting point for the highly sophisticated and more
recent work in non-parametric Bayes methods. Because of its foundational position, and also
its intuitive appeal, Ramsey’s (1972) work on a Bayesian estimation of the potency curve
is overviewed in section 9.3. Ramsey’s material can be viewed as the non-parametric Bayes
analogue of the parametric Bayes approach to dose–response and damage assessment discussed in
section 5.8.
The remainder of this chapter is organized as follows. Section 9.4 focuses attention on prior
distributions for the hazard rate functions, whereas Section 9.5 considers priors for the cumulative
hazard functions. Section 9.6 is devoted to a consideration of priors for the cumulative distribution
functions, or equivalently, the survival function.
9.2
THE DIRICHLET DISTRIBUTION AND ITS VARIANTS
The Dirichlet distribution is a generalization of the beta distribution to the multivariate case.
In Bayesian inference, the attractiveness of the beta and the Dirichlet distributions stems
from their conjugacy property (section 5.4.7) with respect to sampling from the Bernoulli and
the multinomial distributions, respectively. The multinomial distribution, though mentioned in
section 3.3, has not been properly introduced. I, therefore, start this section by describing the
multinomial.
The multinomial is a generalization of the Bernoulli, in the sense that a random variable X
can take k possible mutually exclusive and exhaustive values, say a1   ak, with respective
probabilities p1   pk, where k
i=1 pi = 1. Interest centers around the probability that in n
replications of X, the event X = ai occurs Ni times, i = 1   k, with k
i=1 Ni = n. Then,
given p1   pk, it is easy to see that the joint distribution of N1   Nk is the multinomial
distribution:
PN1 = n1   Nk = nk  p1   pkn =
n!
n1!···nk!pn1
1 ···pnk
k 
(9.1)

THE DIRICHLET DISTRIBUTION AND ITS VARIANTS
245
Verify that ENi=npi, and that VarNi=npi1−pi and that CovNiNj=−npipj, for i̸=j.
Also, for any i, Ni has a binomial distribution with parameters n and pi, i = 1   k.
The connection between the multinomial and the Dirichlet is described later, once the latter
is introduced. To do so, we start by considering a random variable X having a beta distribution
with parameters 1 and 2, whose density at x, 0 < x < 1, denoted Beta12, is given as:
fx12 = 	1 + 2
	1	2x1−11 −x2−1
see (5.11). The expectation and the variance of X are: EX = 1/1 + 2 and VarX =
12/1 + 221 + 2 + 1. Furthermore, if Z1 and Z2 are independent with Zi having a
gamma distribution with scale (shape) parameter 1i, denoted 1ii = 12, then X
def=
Z1/Z1 + Z2 will have the above beta distribution. Details about these and related matters can
be found in Wilks (1962, p. 173).
Since a (univariate) beta distribution has two parameters 1 and 2, its k-variate ana-
logue for X1   Xk, with k ≥2, will have k + 1 parameters 1   kk+1. This
k-variate analogue is called a Dirichlet distribution with parameters 1   kk+1, denoted
1   kk+1. For any point x = x1   xk in the set Sk, where Sk = 
x1   xk 
xi ≥0i = 1   kk
i=1 xi ≤1, the distribution 1   kk+1 has at x, density
fx1   k+1 = 	1 + ··· + k+1
	1···	k+1 x1−1
1
···xk−1
k
1 −x1 −x2 −··· −xkk+1−1
(9.2)
for i ≥0. Observe that when k = 1, 1   k+1 = Beta12; thus the Dirichlet is seen
as a generalization of the beta.
Furthermore, if Z1   Zk+1 are independent with Zi having the distribution 1ii =
1   k + 1, then the k ratios Zi/Z1 + ··· + Zk+1i = 1   k, will have 1   k+1 as
their joint distribution.
The mean, variance and the covariance of the Xis are given below:
EXi =
i
1 + ··· + k+1

VXi =
i1 + ··· + k+1 −i
1 + ··· + k+121 + ··· + k+1 + 1
EXiXj = −
ij
1 + ··· + k+121 + ··· + k+1 + 1 i ̸= j
Observe that EXiXj does not account for the proximity between i and j, and this in some
scenarios can be a disadvantage, also note that Xi and Xj are negatively correlated.
Some attractive properties of the Dirichlet are the behavior of its marginal and conditional
distributions, and its property of closure under additivity.
To appreciate these suppose that X1   Xk has the distribution 1   k+1. Then
(a)
For any k1 < k, the random variables X1X2   Xk1 have the distribution
1   k1k1+1 + ··· + k+1
(b)
Given X1   Xk−1, the conditional distribution of the random variable Xk/1 −X1 −
X2 −··· −Xk−1 is Betakk+1;
(c)
The sum X1 + ··· + Xk has the distribution Beta1 + ··· + kk+1.

246
NON-PARAMETRIC BAYES METHODS IN RELIABILITY
Finally, the Dirichlet distribution’s natural conjugacy property vis-à-vis sampling from the
multinomial distribution can be stated by saying that if the p1   pk−1 of (9.1) have the
distribution 1   k as a prior, then upon observing n1   nk, the posterior distribution
of p1   pk−1 will also be a Dirichlet, and it will be of the form 1 + n1   k + nk.
This result is easy to verify (cf. De Groot, 1970, p. 174).
9.2.1
The Ordered Dirichlet Distribution
The ordered Dirichlet distribution has proved to be useful for addressing problems in bioassay,
and in reliability assessment, when the failure rate function is assumed to be increasing. This
distribution arises when we consider successive sums of Dirichlet variables. Specifically, suppose
that the vector X1   Xk has the distribution 1   k+1. Consider the random variables
Y1 = X1Y2 = X1 + X2   Yk = X1 + ··· + Xk. Observe that 0 ≡Y0 < Y1 < ··· < Yk < Yk+1 ≡1;
i.e. the successive Yis are ordered. It can be seen (cf. Wilks, 1962, p. 182) that the vector
Y1   Yk has a joint distribution, with density at y1   yk, where y1 < y2 < ··· < yk is of
the form
	1 + ··· + k+1
	1···	k+1 y1−1
1
y2 −y12−1 ···yk −yk−1k−11 −ykk+1−1
(9.3)
This distribution of Y1   Yk is known as an ordered Dirichlet distribution; it will be
denoted ∗1   k+1. For future reference, when in section 9.6 we consider the Dirichlet
process, it is useful to note that because the Xis are correlated, the increments Y1Y2 −Y1Y3 −
Y2   Yi −Yi−1, are not independent. That is, the Dirichlet process does not have independent
increments.
If we set y0 ≡0 and yk+1 ≡1, then (9.3) can be compactly written as being proportional to
k+1

i=1
yi −yi−1i−1
(9.4)
The above form of the ordered Dirichlet distribution has a constructive appeal whose nature will
be explained in section 9.3. For now I will introduce a generalization of the Dirichlet distribution,
a generalization that is based on the notion of ‘neutrality’.
9.2.2
The Generalized Dirichlet – Concept of Neutrality
Connor and Mossiman (1969) introduce a generalization of the Dirichlet distribution that is
motivated by the problem of how to randomly divide an interval. The matter of randomly dividing
an interval occurs in several contexts. An archetypal scenario is the proportions (say by weight)
of the chemical compounds that constitute a substance. As an example, let P1   Pk denote
the (random) proportions of the k chemical compounds of a rock, with P1 pertaining to silica.
Then a question of interest to geologists is the effect of eliminating silica on the remaining
proportions. In other words, the behavior of the random vector P−1 =

P2
1−P1    
Pk
1−P1

, where
the Pis ≥0i = 1   k, and k
i=1 Pi = 1.
One possibility could be the assumption that the vector P−1 is independent of P1. This means
that P1 does not influence (or is neutral to) the manner in which the remaining proportions
P2   Pk divide the remainder of the interval P11. This also means that P1 is independent
of the vectors

P3
1−P1−P2    
Pk
1−P1−P2



P4
1−P1−P2−P3    
Pk
1−P1−P2−P3

, and so on. When such is
the case P1 is said to be neutral.
The notion of a neutral P1 when extended to all the k proportions yields a completely neutral
vector P1   Pk. The notion of a completely neutral vector, also introduced by Connor and

A NON-PARAMETRIC BAYES APPROACH TO BIOASSAY
247
Mossiman (1969), provides a mechanism for randomly dividing an interval. To see how, we
start by first generating a random variable P1 from some distribution with support (0,1). We
then generate P2, independently of P1, but with some distribution having support 1 −P11,
and then a third random variable P3, independently of the vector P1P2, but over the interval
1 −P1 −P21, and so on. The vector P1   Pk so generated will be completely neutral.
Completely neutral vectors exhibit some interesting properties, one of which leads us to a
generalization of the Dirichlet distribution. In particular, P1   Pk is a completely neutral
random vector if and only if Z1   Zk are mutually independent, where Z1 = P1Zi =
Pi/1 −P1 −P2 −··· −Pi−1i =1   k, and Zk =1 is degenerate (cf. Theorem 9.2 of Connor
and Mossiman, 1969). Note that 0≤Zi ≤1. To obtain a generalization of the Dirichlet, we assume
that the Zis, i = 1   k −1, which are independent, have a univariate beta distribution on (0,1)
with parameters 1i and 2i; that is, each Zi is 1i2i, i = 1   k −1. Then, it can be shown
(Connor and Mossiman, 1969, or Lochner, 1975) that the joint distribution of P1   Pk−1
has density at p1   pk−1 of the form
k−1

i=1
	1i + 2i
	1i	2ip1i−1
i
1 −p1 −p2 −··· −pk−1i
(9.5)
where i = 2i −1i+1 −2i+1, for i = 12   k −2 and k−1 = 2k−1 −1.
Equation (9.5) is a generalization of the Dirichlet distribution – a generalization because
setting 1 = 2 = ··· = k−2 = 0 gives us a Dirichlet distribution. A consequence is that a vector
of proportions following the standard Dirichlet distribution of (9.2) is completely neutral. Our
motivation for discussing this generalization of the Dirichlet distribution is prompted by two
considerations: one is to introduce the notion of neutrality, and the other is that Lochner (1975)
has proposed a use of this distribution for a Bayesian analysis of life-test data (section 9.4). The
notion of neutrality, which was extended by Doksum (1974) for stochastic processes, plays a
role in the context of priors for the cumulative hazard rate functions and also for the construction
of priors on the cumulative distribution functions (sections 9.5 and 9.6).
9.3
A NON-PARAMETRIC BAYES APPROACH TO BIOASSAY
A parametric Bayes approach to the bioassay problem based on the Weibull survival function
as a model for the response curve was presented in section 5.8, under the label of dose–
response testing or damage assessment studies. The focus there was on a use of filtering
techniques with the double lognormal as the underlying distribution. In this section, I describe
a non-parametric Bayes approach pioneered by Kraft and Van Eeden (1964), and developed by
Ramsey (1972).
Adhering to the notation of section 5.8, we let X denote the level of a dose, and suppose that
X takes values x, 0≤x ≤. Let Yx denote the response of a subject to a dose x, with Yx=1,
if the subject survives a dose x, and Yx = 0, otherwise (i.e. the subject responds to dose x).
It makes sense to suppose that Yx is non-increasing in x, with Y0 = 1 and Y = 0. It is
common to administer a dose xi to ni subjects, i = 1   m, where ni, m and xi are pre-chosen.
The ni ≥1 subjects experiencing dose xi are assumed to be exchangeable. Let Px=PYx=0;
i.e. Px is the probability that a subject responds to the dose x. We suppose that Px, the
response probability function, or the potency curve, increases in x so that Px behaves like a
distribution function with P0=0 and P=1. Recall that in section 5.8.1 a prior probabilistic
structure was imposed on Yx via the model of (5.69). By contrast, in this section we endow a
probabilistic structure on Px via an ordered Dirichlet distribution. But before doing so we first
write out a likelihood for the Pxis given the pair nisi, i = 1   m, where si denotes the

248
NON-PARAMETRIC BAYES METHODS IN RELIABILITY
total number of subjects that do produce a response out of the ni subjects that were administered
the dose xi. That is, si is the total number of Yxis that take the value 0. Clearly , the likelihood
of Px1   Pxm with nisi, i = 1   m fixed and known, is
 ∝
m
i=1
Pxisi1 −Pxini−si
(9.6)
we assume that given the Pxis the responses Yxi are independent.
Our aim is to assess the function Px, x ≥0, based on prior information about Px and the
data nisi, i = 1   m. The reasons for doing so could be many, one of which is to know
Px∗ – the probability of a response at some x∗̸= xii = 1   m.
9.3.1
A Prior for Potency
Ramsey (1972) has proposed a version of the ordered Dirichlet as a prior for Px1   Pxm,
and has given a constructive mechanism that lead to this choice. His prior boils down to the
supposition that the differences in potency at the observational doses have a Dirichlet distribution
whose density, say , is of the form
 ∝

m+1

i=1

Pxi −Pxi−1i


(9.7)
with Px0 = 0 and Pxm+1 = 1. The constants  and ii = 1   m + 1 are non-negative and
m+1
i=1 i = 1.
The density  given above can be seen to be identical to that described by (9.4), provided
that when averaging with , we integrate with respect to
m
i=1
dPxi
m+1

i=1

Pxi −Pxi−1

instead of m
i=1 dPxi, which is what we would do were we to integrate with respect to (9.4).
Thus Ramsey’s (1972) choice for a prior on Pxis, i = 1   m, is said to be a version of
the ordered Dirichlet. To motivate this choice Ramsey (1972) gives the construction described
below; but first I need the following.
Some Preliminaries
For i =1   m, let Ai =i
j=1 j, and ai =1 −Ai =m+1
j=i+1 j; recall that j’s are non-negative
constants that sum to one, for j = 1   m + 1. Consider a random variable Y whose density at
y is the following version of the beta density on (0,1), with parameters 1 and 2:
	1 + 2
	1	2y11 −y2
0 < y < 1
(9.8)
with 1, 2≥0. When averaging with respect to (9.8) we integrate with respect to dy/y1−y.
I denote this density by Beta 1201.
If Z =a+b −aY, and Y is as defined by (9.8), then Z will have a translated beta distribution
over ab denoted Beta 12ab.

A NON-PARAMETRIC BAYES APPROACH TO BIOASSAY
249
With the above preliminaries in place, we start by supposing that the distribution of Px1
is Beta1a101, and continue by assuming that for i > 1, the distribution of Pxi given
Px1   Pxi−1 depends only on Pxi−1, and is BetaiaiPxi−11. That is, the Pxis,
i > 1 have a Markov character, with the distribution of Pxi being a translated beta over
Pxi−11. A consequence of the above construction is that the potencies Px1   Pxm have
a joint distribution, this joint distribution being identical to that which would result from , the
assumed Dirichlet of the differences. We denote this joint distribution by m1   m+1.
This joint distribution has the following three attractive properties:
(a)
If Px1   Pxm has the distribution m1   m+1 then Px1   Pxm−1
will have the distribution m−1′
1   ′
m where ′
i = i for i = 1   m −1 and
′
m = m + m+1.
(b)
Under a above, the distribution of Pxi for any ii = 1   m, is Ai1 −Ai01;
the parameter Ai is both the mean and the mode. Also, A1   Am is the mode of the
joint density .
Thus if P∗x is our best guess of Px, then our choices for the i’s would be: 1 =
P∗x1i = P∗xi −P∗xi−1i = 2   m, and m+1 = 1 −P∗xm.
(c)
If Pxi−1 = p1 and Pxi+1 = p2, then given p1 and p2, the distribution of Pxi is
Betaii+1p1p2.
A consequence of the above is that as  ↓0, the beta conditional density of Pxi becomes
uniform over p1p2, and it becomes concentrated within this interval around a point determined
by i and i+1, as  increases. In other words,  controls the probability that Pxi is close
to Pxi−1 or Pxi+1, and in so doing controls the smoothness in the prior/posterior process.
Alternatively viewed,  controls an assessor’s strength of belief about the prior guess P∗x.
9.3.2
The Posterior Potency
The joint density of the posterior is given by the product of the likelihood (equation (9.6))
and the prior (equation (9.7)). A Bayes estimate of the potency curve is the mode of the
joint posterior. That is, the k-dimensional point 	Px1   	Pxm which maximizes the pos-
terior density of Px1   Pxm. For values of  ∈0, Ramsey (1972) has argued
that the posterior density is convex and unimodal, so that a unique modal function exists.
Also outlined by Ramsey (1972) are numerical and optimization-based approaches for obtain-
ing the modal function. The details of these are not pursued here, because the main point
of this section is to show how the Dirichlet and the ordered Dirichlet enter the arena of
non-parametric Bayes in the context of reliability and survival analysis via the scenarios of
bioassay and damage assessment. The use of the Dirichlet as a prior distribution was further
developed and extended by Ferguson (1973) who formally introduced the Dirichlet process as
a prior for the response function Px. This and related developments will be discussed in
section 9.6.
Before closing this section it may be useful to add that the Dirichlet specification mentioned
here does not capture features of the dose–response curve that may be known a priori. For
example, it may be felt that Px is either concave, convex or ogive (i.e. changes from convex to
concave). Priors that capture such features were developed by Singpurwalla and Shaked (1990),
and further extended by Ramgopal, Laud and Smith (1993). Smythe (2004) gives a recent
overview.

250
NON-PARAMETRIC BAYES METHODS IN RELIABILITY
9.4
PRIOR DISTRIBUTIONS ON THE HAZARD FUNCTION
To set the stage for the material of this section, as well as the following two sections, we start
with some preliminaries.
Suppose that PT ≥t the predictive survival function of T, the lifelength of an item, is
1 −Ft; thus Ft = PT < t is the distribution function of T. Our aim is to assess Ft using
prior information and life-history data of n items judged exchangeable with the item of interest.
We start by partioning the time axis into k + 1 intervals 0 < t1 < t2 < ··· < tk < , and let
p1 = Ft1pi = Fti −Fti−1i = 2   k. Since T is a lifelength, F0 = 0 and F = 1.
Let the vector p = p1   pk, and let ni denote the number of observed lifetimes in the
interval ti−1ti, with n1 denoting the number of observed lifetimes less than t1 and nk+1, the
number ≥tk; thus n = k+1
i=1 ni. Given p, the vector d = n1   nk+1 has a multinomial
distribution
n!
n1!···nk+1!pn1
1 ···pnk
k 1 −p1 −p2 −··· −pknk+1
(9.9)
If we were to assign a prior distribution to the vector p, then this prior and the above likelihood
would yield the posterior of p from which I could assess Ft.
The scenario here is not unlike that of section 9.3 on bioassay, since the behavior of Fx
is identical to that of the response curve Px. The key difference was that in section 9.3 our
data was quantal (response or no response), whereas here we look at the number of failures in
different intervals. In section 9.3, a Dirichlet prior distribution was assigned to the differences in
potency (equation (9.7)) and in principle, one could proceed here along similar lines using the
multinomial of (9.9) as a likelihood instead of the Bernoulli. One could also justify a use of the
Dirichlet prior following the constructive scheme of Ramsey (1972). However, the priors that
we discuss in this section will be different. Different, because a disadvantage of the Dirichlet
distribution is that its covariance dose not account for proximity, so that the relationship between
pi and pj is not a function of how close i and j are to each other. Thus the priors that we consider
here are the generalized Dirichlet of section 9.2.2, and a generalization of the gamma process
(introduced in section 4.9.1). The generalized Dirichlet, motivated by Connor and Mossiman’s
(1969) construction of completely neutral vectors, is obtained by assuming that the piecewise
constant segments of the hazard rate function have independent beta distributions. Thus it is the
piecewise constant hazard rate function that is endowed with a generalized Dirichlet distribution;
this is described in section 9.4.1. By contrast, the material of section 9.4.2 pertains to endowing
a continuous non-decreasing hazard rate function with the generalized gamma as a prior.
9.4.1
Independent Beta Priors on Piecewise Constant Hazards
Let Z1 =p1 and Zi =pi/1 −p1 −p2 −··· −pi−1, for i =2   k. Then Zi is the failure rate of
Ft over the interval i −1i, and the concatenated collection of Zis, i=1   k constitute the
piecewise constant hazard rate function of Ft over the interval 0tk. The Zis would be between
0 and 1. Since the hazard rate function cannot be observed, we treat it as a random function, or
a stochastic process, and assign probabilities to its sample paths. One such strategy is to assume
that the Zis are independent, with Zi having a beta distribution Beta1i2ii =1   k. Then,
the vector p will have as its prior distribution a generalized Dirichlet, with density at p1   pk
of the form
k
i=1
	1i + 2i
	1i	2ip1i−1
i
1 −p1 −p2 −··· −pki
(9.10)
where i = 2i −1i+1 −2i+1, for i = 12   k −1 and k = 2k −1; see equation (9.5).

PRIOR DISTRIBUTIONS ON THE HAZARD FUNCTION
251
Given the counts data d, the prior of (9.10) when combined with the likelihood of (9.9) yields
the posterior distribution of p, with density (cf. Lochner, 1975)

k
i=1
	1i + ni + 2i + ni+1 + ··· + nk+1
	1i + ni	2i + ni+1 + ··· + nk+1p1i+ni−1
i
1 −p1 −··· −pii

·
1 −p1 −p2 −··· −pknk+1
(9.11)
Properties of this posterior distribution and approaches for using it to obtain an assessment
of Fx are given by Lochner (1975). A disadvantage in using the generalized Dirichlet as a
prior for p is the excessive number of parameters that one needs to specify. Some strategies for
simplifying this task are also given by Lochner (1975). However, a key drawback is that the
generalized Dirichlet lacks the additive property that a Dirichlet has. That is if p = p1   pk
has the generalized Dirichlet distribution, then p1p2 +p3p4   pk will not be a generalized
Dirichlet. This leads to an inconsistency with respect to inference. Specifically, our inferential
conclusions will be dependent on whether we combine cells at the prior stage or at the posterior
stage. Another disadvantage is that in using count data we sacrifice information that the actual
failure times provide.
Because of the above obstacles, one is motivated to consider other families of stochastic
processes as prior distributions for the hazard rate function. The need for seeking alternatives
becomes particularly germane if one has additional information about the behavior of the haz-
ard rate function, such as its monotonicity, that needs to be incorporated into the analyses.
The assumption of complete neutrality upon which the generalized Dirichlet is based upon
is unable to account for any structural patterns in the hazard rate function. Of the alter-
natives proposed, the ones by Padgett and Wei (1981) and by Arjas and Gasbarra (1994)
take the prior on the hazard rate function to be a (non-decreasing) jump process, a Pois-
son process with a constant jump size, and the one by Mazzuchi and Singpurwalla (1985)
takes the prior on a function of the hazard rate function to be an ordered Dirichlet. In all
the above cases the hazard rate function is assumed to be non-decreasing (actually mono-
tone in the case considered by Mazzuchi and Singpurwalla (1985)). Two other alternatives
are the use of an extended gamma process, introduced by Dykstra and Laud (1981), and the
Markov Beta and Markov Gamma processes considered by Nieto-Barajas and Walker (2002).
In what follows, I overview the first of the above two developments; I focus on the extended
gamma case because the extended gamma process possesses features that could be of a broader
interest.
9.4.2
The Extended Gamma Process as a Prior
Suppose that rt, the hazard rate function of Ft is non-decreasing in t ≥0. My aim here
is to specify a prior probability distribution over the collection of all possible non-decreasing
hazard rate functions. This is done by choosing an appropriate stochastic process whose sample
paths are non-decreasing functions over 0. Dykstra and Laud (1981) have introduced and
proposed the extended gamma process for doing so. To define this process, we start by recalling
(section 4.9.1) that a stochastic process 
Mtt ≥0 is a gamma process with a shape function
at and a scale parameter 1, if for any t ≥s ≥0 and M0=0Mt has independent increments
and Mt −Ms has a gamma distribution with a scale parameter 1 and a shape parameter
at−as. The function at is non-decreasing, left-continuous and real-valued, with a0=0.
Ferguson (1973) shows that such a process exists, and that the process has non-decreasing,
left-continuous sample paths.

252
NON-PARAMETRIC BAYES METHODS IN RELIABILITY
Suppose now that tt ≥0 is a positive, right-continuous and real-valued function that is
bounded away from zero, and which has left-hand limits. Then, the stochastic process 
M∗tt ≥
0 is an extended gamma process where M∗t is defined as the integral
M∗t =

 t
0 sdMs
we denote such a process as 	att.
Dykstra and Laud (1981) show that the extended gamma process 	att has independent
increments with
EM∗t =

 t
0 sdas
and
VarM∗t =

 t
0 2sdas
Both the gamma process and the extended gamma process are jump processes; i.e. they increase
only by taking jumps. Finally, in the spirit of the material of section 7.2, if the hazard rate
process is taken to be an extended gamma process 	att, then the survival function is
(cf. Theorem 3.1 of Dykstra and Laud (1981)) of the form
PT ≥t = exp

−

 t
0 log1 + st −sdas


(9.12)
this equation complements the likes of (7.13).
Equation (9.12), besides being useful as a modeling tool, also facilitates one to obtain the joint
survival probability of n observations T1   Tn from Ft. Specifically,
PT1 ≥t1   Tn ≥tn = exp

−

 
0
log

1 + s
n
i=1
s −ti∗

das


(9.13)
where a∗= maxa0.
The above enables us to write out the likelihood of n observations truncated to the right at
t1   tn. This likelihood, when used in conjunction with 	ass as a prior on the hazard
rate process yields 	as	s as an extended gamma process for the posterior of the hazard
rate process. Here
	s =
s
1 + sn
i=1ti −s∗
The posterior of the hazard rate process when t1   tn are the actual times to failure is a
mixture of extended gamma processes whose form is cumbersome to write out (Theorem 3.3 of
Dykstra and Laud (1981)). However, Laud, Smith and Damien (1996) approximate the posterior
hazard rate process by approximating its random independent increments via a Monté Carlo
method involving the Gibbs sampler. Once the posterior hazard rate process is obtained by
approximation, one can obtain an approximation for the survival function. A use of the Gibbs
sampler for estimating the posterior hazard rate process has also been considered by Arjas and
Gasbarra (1994), who, we recall, assume a jump process structure as a prior for the hazard rate
process.

PRIOR DISTRIBUTIONS FOR THE CUMULATIVE HAZARD FUNCTION
253
9.5
PRIOR DISTRIBUTIONS FOR THE CUMULATIVE HAZARD
FUNCTION
Section 9.4 was devoted to a consideration of prior distributions for the hazard rate function,
assumed to be a piecewise constant function in section 9.4.1, and continuous and non-decreasing
in section 9.4.2. In the first case, the prior was assumed to be a collection of independent beta
distributions, and in the second case an extended gamma process. The generalized Dirichlet on
the increments of Ft was a consequence of the independent beta assumption. In this section,
we consider prior distributions on the cumulative hazard rate function Rt =
 t
0 rudu, for
t ≥0. A consideration of priors for the cumulative hazard is attractive because the cumulative
hazard can be defined even when F has no density, as Rt =
 t
0 dFu/1 −Fu. Here again,
since Rtt ≥0, cannot be observed, we treat it as a random function (or a stochastic process)
and assign probabilities to its sample paths. I describe here two constructions, one due to
Kalbfleisch (1978) involving the gamma process, and the other by Hjort (1990), who introduces
a new process, which he calls the beta process. Kalbfleisch’s (1978) construction entails the
assumption that the piecewise constant segments of the hazard rate function have independent
gamma distributions (section 9.5.1). In this sense it parallels the construction of Lochner (1975)
discussed in section 9.4.1. By contrast, Hjort’s (1990) beta process construction, which will be
discussed in section 9.5.2, proceeds by discretizing the time axis and assuming that the resulting
point mass hazard rates have independent beta distributions.
9.5.1
Neutral to the Right Probabilities and Gamma Process Priors
As a preamble to our discussion of a gamma process prior for the cumulative hazard functions,
I need to introduce the notion of a neutral to the right-random probability. To do so, I follow the
notation and set-up laid out at the start of section 9.4, by partitioning the time axis into a finite
number k of disjoint intervals 0 ≡t0t1t1t2   ti−1ti   tk−1tk = , and letting
Zi = PT ∈ti−1tiT ≥ti−1i = 1   k, be the hazard rate of Ft over the i-th interval. Thus
the concatenated collection of Zis constitutes the piecewise constant hazard rate function of Ft
over 0tk.
Since 1 −Ft = exp−Rt, it can be seen that
Rti =
i
j=1
−log1 −Zj
def=
i
j=1
rj
(9.14)
where ri = −log1 −Zii = 1   k and Rt0 = 0.
If for every partition of the type ti−1tii = 1   k, a joint distribution for the collective
Z1   Zk, or equivalently the collective r1   rk, can be specified, subject to consistency
conditions, then a probability distribution is also specified for the set of all cumulative hazard
functions 
Rt, where Rt is non-decreasing in t ≥0. When the Zis (or equivalently the ri’s) are
judged independent, then 
Rtt ≥0 is a non-decreasing stochastic process with independent
increments. Under these circumstances, the random distribution function F and its probability
law will have the property of being neutral to the right. The notion of neutral to the right random
probabilities was introduced by Doksum (1974); it can be seen as an extension of Connor and
Mossiman’s (1969) notion of complete neutrality of random probability vectors, to stochastic
processes. When F is neutral to the right and the process 
Rtt ≥0 such that Rt has no
non-random part (i.e. the  of (7.9) and the t of (7.17) are zero), then F is necessarily a
discrete distribution function (Doksum, 1974, Corollary 3.2). Futhermore, if the independent
increments process 
Rtt ≥0 has stationary increments (i.e. when the Zis or the ri’s are
independent and identically distributed), then the process 
Rtt ≥0 is referred to by Kingman
(1975) as a subordinator.

254
NON-PARAMETRIC BAYES METHODS IN RELIABILITY
On Neutral to the Right (Left) Probabilities
Neutral to the right-random probabilities are of interest in Bayesian inference because of their
closure properties. Specifically, the posterior distribution of a random probability neutral to the
right, is also neutral to the right (Doksum, 1974, Theorem 4.2). A consequence is that is if the
cumulative hazard rate function is, a priori, a non-decreasing function with independent incre-
ments, then it will also be, a posteriori, a non-decreasing function with independent increments.
This feature is made more explicit via the example of a gamma process that will be discussed in
the sub-section that follows; but first, a definition of neutral to the right distribution.
We say that a random distribution function F is neutral to the right if its normalized
increments are independent. That is, for t1 < t2 < ··· < tk,
Ft1 Ft2 −Ft1
1 −Ft1
    Ftk −Ftk−1
1 −Ftk−1

are independent. Observe that the above definition parallels that of a completely neutral vector
P1   Pk (section 9.2.2) If I was to set P1 = Ft1Pi = Fti −Fti−1, and Zi = Pi/1 −
P1 −P2 −   −Pi−1, for i = 2   k. Thus the claim that the notion of neutral to the right-
random probabilities is an extension of the notion of completely neutral vectors to the case of
processes. Doksum (1974) has also introduced the notion of neutral to the left. Here, for any
t1 < t2 < ··· < tk, the proportional increments
Ftk Ftk −Ftk−1
Ftk
    Ft2 −Ft1
Ft2

are independent.
With the above as a background on neutral to the right (and left) probabilities, we are now
ready to introduce the gamma process prior for the cumulative hazard function as an example of
a neutral to the right probability. Additional material on neutral to the right processes is given
later in section 9.6.2.
Gamma Process Priors for the Cumulative Hazard
Reverting to the scenario leading to (9.14), Kalbfleisch (1978) has proposed a gamma process
as a prior for 
Rtt ≥0 by assuming that the ri’s are independent with ri having a gamma
distribution with shape i −i−1 and scale c, where i = cR∗tii = 1   k. The function
R∗tt ≥0, is interpreted as one’s best guess of Rtt ≥0; equivalently, one may interpret
exp−R∗t as one’s best guess about 1 −Ft. The constant c is a measure of one’s strength of
conviction (or credibility) about the guess R∗t. Large values of c indicate a strong conviction.
The assignment of independent gammas to the ri’s is akin to Lochner’s (1975) choice of
independent beta distributions for the Zis.
The structure of the gamma distribution given above satisfies the requirement of consistency,
in the sense that the distribution assigned to ri + ri+1 for the concatenated interval ti−1ti+1
will be the same as that deduced from the gamma distributions assumed for ri and ri+1. A
consideration of the partition 0tt shows that the aforementioned construction results in
a gamma process as a prior for Rt; its shape function is cR∗t and scale c. Consequently, for
any t ≥0, ERt = R∗t and VarRt = R∗t/c.
Since the gamma process for 
Rtt ≥0 has independent increments, the random probability
Ft that it induces is neutral to the right. Consequently, given n failure times, say 1   n,
the posterior cumulative hazard function will also be a process with independent increments.
Kalbfleisch (1978) has shown that the increment at i of the posterior cumulative hazard rate

PRIOR DISTRIBUTIONS FOR THE CUMULATIVE HAZARD FUNCTION
255
function has a distribution with density Ac + Aic + Ai+1 at u, where Ai = n −ii = 1   n,
and Aab is of the form
u−1
exp−bu −expau
loga/b

Between i−1 and i, the increments are prescribed by a gamma process with shape function
cR∗• and scale c + Ai. The survival function 1 −Ft can be recovered from the cumulative
hazard rate process either via simulation or by approximation using the expected value of the
process. However, one can foresee the following concerns about using the gamma process prior
on the cumulative hazard function.
The first concern pertains to motivation. In particular, assuming a gamma distribution on
ri =−log1−Zi, where Zi is the failure rate of Ft over the interval ti−1ti lacks intuition. The
second concern could stem from the fact that the independent increments property of 
Rtt ≥0
may not be meaningful. Under aging and wear, the successive Zis would be judged to be
increasing and thus interdependent. By contrast, the extended gamma process of section 9.4.2 on
the hazard rate function would lead to a process for the cumulative hazard function that will not
have independent increments and would thus be more desirable. Finally, since Ft being neutral
to the right would result in the feature that any realization of the process 
Rtt ≥0 will be
discrete, difficulties will be encountered when ties are present in the failure time data, and such
ties will occur with a non-zero probability. The nature of such difficulties and how they can be
overcome is described by Kalbfleisch (1978) in section 5.5 of his paper.
9.5.2
Beta Process Priors for the Cumulative Hazard
Hjort (1990) has introduced a new class of stochastic processes for the analysis of life-history
data; he calls such processes ‘beta processes’. These processes, which constitute a large and
flexible family, are also of value for inference connected with time inhomogeneous Markov
chains. When used as priors on the cumulative hazard function they exhibit the property of
conjugacy and enable one to obtain easy-to-interpret and easy-to-compute Bayes estimators of
the cumulative hazard. Hjort’s (1990) development proceeds by starting with the discrete time
scenario and then taking appropriate limits. In doing so, Hjort (1990) also develops a discrete
time framework for the analysis of failure data.
By way of preliminaries and notation, suppose that a lifetime T is discrete, taking values
0b2b   , for some b>0. Later on, we let b go to zero so that the discrete time results can be
extended to the continuous case. For j = 01   , let pjb = PT = jb, Fjb = PT ≤jb =
j
i=0 pib, rjb = PT = jbT ≥jb = pjb/Fjb, where Fjb = 1 −Fj −1b, and
Rjb = j
i=0 rib. Note that rjb and Rjb are the point mass hazard rate and the point mass
cumulative hazard rate of F at jb, respectively. Also, (cf. (4.3) and (4.1)), F and p can be
recovered from a knowledge of r via the relationships:
Fjb = 1 −
j
i=0
1 −rib
and
pjb = rjb

j−1

i=0
1 −rib


(9.15)
The aim here is to construct a class of priors for the cumulative hazard function R such
that given failure time data T1   Tn (with or without censoring) one can conveniently obtain
the posterior distribution of R, and thence a non-parametric Bayes estimate of F. Hjort (1990)
motivates his class of priors by looking at the likelihood of the data in terms of the point
mass hazard function. To do so, he considers the observables Xiii = 1   n, where
Xi =minTici, ci being the right censoring time of Ti, and i =1 if Ti ≤ci; i =0 if Ti >ci. Thus

256
NON-PARAMETRIC BAYES METHODS IN RELIABILITY
i = 1 corresponds to a failure at or before ci, the convention here being that at ci failure takes
precedence over censorship. The set-up described above gives rise to two counting processes,

Njbj = 012    and 
Yjbj = 012   , where
Njb =
n
i=1
Xi ≤jb and i = 1
Yjb =
n
i=1
Xi ≥jb
a, the identity function, is such that a = 10 if the event a occurs (does not occur). The
process 
Njbj =01    counts the number of failures at or before time jb, and the process

Yjbj = 01    counts the number of items at risk of failure at time jb. The increment in
the 
Njbj = 01    process at time jb, namely Njb −Nj −1b, will be denoted as
dNjb.
Then it is easy to verify that given the observables xi and i, i = 1   n, the likelihood of
p (or F) is


ii=1
pxi


ii=0
Fxi


(9.16)
where Fxi = PT > xi.
Invoking the relationship of (9.15), and then simplifying the resulting algebra, the likelihood
becomes:
n
i=1

j=0

1 −rjbj<xi or j=xi and i=0
rjbj=xi and i=1
=

j=0


1 −rjbYjb−dNjb
rjbdNjb

(9.17)
Note that we now have the likelihood of r with the data xiii = 1   n, as being fixed.
Suppose now that the point mass hazard rates rjb, j = 01   , are assumed to be inde-
pendent with rjb having a prior density hjbs, for 0 ≤s ≤1. Then given the data xiii =
1   n, the rjb’s will continue to be independent with rjb having a posterior density h∗
jbs
where
h∗
jbs ∝sdNjb1 −sYjb−dNjbhjbs
(9.18)
This result is a consequence of (9.17).
With the above in place, let
R ∼BetacRo
(9.19)
denote the feature that the cumulative hazard function when viewed as a stochastic pro-
cess 
Rjbj = 01    has independent increments rjb where, following the notation of
section 9.2,
rjb ∼Betacjbr0jbcjb1 −r0jb
(9.20)
i.e. rjb has a beta density with the parameters cjb and r0jb.

PRIOR DISTRIBUTIONS FOR THE CUMULATIVE HAZARD FUNCTION
257
Clearly, since Erjb = r0jb = dR0jb, I have ERjb = R0jb; similarly, Varrjb =
r0jb1−r0jb/cjb+1. Consequently, given data, the posterior cumulative hazard process
has the feature [cf. Equation (9.18)] that
Rdata ∼Beta

c + Y
 cdR0 + dN
c + Y


(9.21)
in notation that should be obvious. Thus a conjugacy of the process of (9.19). The mean of the
posterior cumulative hazard process, say 	Rjb = ERjbdata, is of the form
	Rjb =
j
i=0
cibr0ib + dNib
cib + Yib

(9.22)
which in compact notation can be written as
	Rjb =
jb

0
cdR0 + dN
c + Y

its variance is jb
0 d	R1 −d	R/c + Y + 1.
The quantity 	Rjb can be seen as a non-parametric Bayes estimate of the cumulative hazard
function.
Relationship to the Kaplan–Meier and Nelson–Aalen Estimators
The parameters cjbj = 01   , can be interpreted as those reflecting a strength of belief
in the prior guess R0. This is because, in (9.22), the weight given to r0ib decreases in cib,
to the extent that as cib tends to zero, 	Rjb = j
i=0 dNib/Yib – the ‘Nelson–Aalen’
(non-Bayesian) estimator of Rjb. As cib grows large, 	Rjb becomes R0ib, the prior guess.
An easy spin-off of the above is the development of a non-parametric Bayes estimator of the
distribution function of F. A consequence of (9.15) and (9.22) is that
EFjb data
def= 	Fjb = 1 −
j
0
1 −Erib data = 1 −
jb
0

1 −cdR0 + dN
c + Y


(9.23)
which when c• tends to zero becomes the ‘Kaplan–Meier’ non-parametric Bayes estimator of
F, namely
F ∗jb = 1 −
jb
0

1 −dN
Y


When c• increases to infinity, the non-parametric Bayes estimator of Fjb is simply 1 −
j
i=01 −r0ib, the prior guess.
Thus to conclude, large values of c• imply a strong belief about the prior guess r0•, and
vice-versa for small values of c•.
Extension to the Continuous Case: Beta Processes
Suppose now that T can take values in 0, with Ft = PT ≤t, and F0 = 0. We will
allow F• to have jumps, the effect of which is that the well-known exponentiation formula of
reliability and survival analysis (equation (4.9)) will not hold. The cumulative hazard function
of F is a non-negative, non-decreasing and right-continuous function F on 0, which by

258
NON-PARAMETRIC BAYES METHODS IN RELIABILITY
analogy with the case of T discrete should satisfy the requirement that dRs = dFs/Fs.
Consequently, we define
Rab =

ab dFs/Fs
as the cumulative hazard rate of F. With Rab as defined above, it is immediate that
Fab =

ab FsdRs
0 ≤a ≤b < 
A solution of the above equation is the product integral formula (section 4.3.1)
Ft = 1 −

0t

1 −dRs
t ≥0
(9.24)
thus F is uniquely determined by R.
The quantity 
ab
1 −dRs = exp−Rab, if and only if R is continuous, and
thus −log1 −F = R, only under the assumption of the said continuity. In general, since
1 −x ≤e−x, we may claim that −log1 −Ft ≥Rt.
With the above as background we turn to the construction of prior distributions for R, but
require that the class of all cumulative hazard rates be such that for any R in this class, (9.24)
would lead to an F on 0, with F0 = 0. I denote this class by . Since the class of priors
for Rjb in the discrete case has paths that lie in , and whose independent increments are
governed by (9.20), we are motivated to consider a process on 0 with paths in  whose
infinitesimal independent increments are governed by
dRs ∼BetacsdR0scs1 −dR0s
(9.25)
The existence of such a process has been established by Hjort (1990) in his Theorem 3.1 which
goes as follows:
Theorem 9.1 (Hjort (1990)).
Let R0 in  be continuous and let c0 be a piecewise continuous
non-negative function. Then there exists a Lévy process R• whose paths fall in  and whose
Lévy representation
Eexp−Rt = exp

−

 1
0 1 −e−sdLts


has Lévy measure dLts of the form
dLts =

 t
0 czs−11 −scz−1dR0z

dst ≥00 < s < 1
The process R given above is called a beta process with parameters c• and R0•, and like
(9.19) for the discrete case denoted R ∼BetacR0.
The beta process defined above conforms to the requirement of (9.25) in a certain sense and
preserves some of the beta characteristics. Specifically, E
Rab = R0ab, making R0 the
prior guess, and (cf. Hjort, 1990, p. 1272)
Var
Rab =

ab dR0s1 −dR0s/cs + 1
=

ab dR0s/cs + 1

PRIORS FOR THE CUMULATIVE DISTRIBUTION FUNCTION
259
An extension of the beta process defined above consists in allowing R0 to have a finite number
of jumps. This is necessitated by the fact that when considering life-history data, the posterior
distribution of R will have jumps at times of observation. The specifics of this extension are
at the end of section 3.3 of Hjort (1990); they will not be stated here because the results to be
given below are not affected by the extension.
With the beta process as a prior for R, the posterior of R given the life-history data
X11   Xnn is also a beta process of the form
Rdata ∼Beta

c• + Y•

 •
0
c dR0 + dN
c + Y


see Corollary 4.1 of Hjort (1990).
The Bayes estimator of Rt is the mean of the above posterior, and is given as:
	Rt =

 t
0
c dR0 + dN
c + Y

(9.26)
and its variance is
 t
0
d	R1−d	R
c+Y+1 ; (9.26) is the continuous time analogue of the expression following
(9.22). Finally, as a parallel to (9.23), a non-parametric Bayes estimator of F is:
	Ft = 1 −

0t

1 −c dR0 + dN
c + Y


see Theorem 4.3 of Hjort (1990).
As before, as c• decreases to zero, 	R and 	F tend to the non-parametric Nelson–Aalen and
Kaplan–Meier estimators of R and F, respectively.
9.6
PRIORS FOR THE CUMULATIVE DISTRIBUTION FUNCTION
Chronologically, the material here should precede that of the previous two sections. This is
because much of what is said in sections 9.4 and 9.5 has its roots in the material of this section.
In what follows, I overview some key aspects of Ferguson’s (1973) Dirichlet processes, and
Doksum’s (1974) processes neutral to the right (NTR). The NTR processes were introduced in
section 9.5.1, but within the context of prior distributions for the cumulative hazard function. The
intent now is to cast these processes in their original setting. However, to do so, it is desirable to
use the framework of measure theoretic probability. This I do, but with some hesitation. Readers
not at ease with the abstractions of measure theoretic probability may choose to concentrate only
on the essence of the theorems given below. But before doing so, the following preamble may
be useful vis-à-vis an overall perspective.
There appear to be two general approaches through which the problem of making infer-
ences about an unknown survival function F = 1 −F have been explored. The first one, best
summarized in Ferguson and Phadia (1979), starts by noting that any absolutely continuous
survival function Ft can always be written as F = exp−Bt, where Bt is some non-
negative, non-decreasing and continuous function on 0 with B0 = 0. One then supposes
that 
Btt ≥0 is a Lévy process with non-negative increments and the property that B0=0.
With the above in place, it can be shown that given the data, 
Btt ≥0 continues to be a Lévy
process and that the expectation of exp−Bt provides inference about Ft. The Dirichlet and
the NTR processes discussed in sections 9.6.1 and 9.6.2 below are in conformance with this
approach.

260
NON-PARAMETRIC BAYES METHODS IN RELIABILITY
The second approach centers around viewing the cumulative hazard rate function as a stochastic
process 
Rtt ≥0. But when F is not absolutely continuous, one is not free to choose any
stochastic process for 
Rtt ≥0. For example, we cannot choose a gamma process (which is
a special Lévy process), when F is not absolutely continuous, because doing so will not produce
a proper cumulative distribution function F (cf. Hjort, 1990, p. 1269). Thus every Lévy process
cannot be used as a prior process for 
Rtt ≥0 unless of course F is absolutely continuous in
which case Bt = Rt. It is because of this line of reasoning that Hjort (1990) has introduced
the ‘beta process’ of section 9.5.2. For such processes given the failure data the posterior process
continues to be a beta process.
9.6.1
The Dirichlet Process Prior
To discuss the Dirichlet process, we find it helpful to adopt a framework prescribed by
Sethuraman (1994) in his famous paper on a constructive definition of Dirichlet processes.
Accordingly, suppose that T is a random variable that generates ‘data’ t. Assume that T takes
values in a measurable space , and let P be an unknown probability measure on .
By ‘measure’ we mean non-negative, ‘-additive’ function. In the kind of applications that are
of interest to us here,  will be the real line 	, and  the -algebra of Borel subsets of 	.
Suppose that the unknown P takes values in 
 , where 
 is the collection (or space) of all
probability measures on . Let  be the smallest -algebra generated by sets of the form

P  PA < , where A ∈ and  ∈01. Let  be a probability measure on 
 . Such a
probability measure can be seen as a prior distribution of P. The Bayesian solution is to obtain
a posterior distribution of P given the data t; we denote this posterior distribution by t.
When the sample space  is a finite set, say  =
12   k, then every probability measure
P on  will be given by the vector p1 = P1p2 = P2   pk = Pk. This vector takes
values in the simplex k =

p1   pk  0 ≤p1 ≤1   0 ≤pk ≤1k
j=1 pj = 1

, and k is
a subset of 	k. In such cases a natural choice for P would be the k −1 variate Dirichlet
distribution 1   k, where the parameters of this distribution are such that i ≥0i =
1   k and k
i=1 i >0 (equation (9.2)). Thus defining probability measures on k is relatively
straightforward. When  is countably infinite the situation becomes much trickier because now
we need to construct probability measures on  ⊆	, with the requirement that pi ≥0 and

i=1 pi = 1. This scenario and the attending difficulties that it creates have been discussed by
Kingman (1975).
When  is some arbitrary measurable space, Bayesian non-parametrics becomes feasible only
if one can define a large class of prior distributions on 
  for which the posterior distributions
can be easily obtained. One such family of prior distributions is the Dirichlet process prior. There
are a large number of Dirichlet processes on , one for each  ∈, where  is the class of
all non-zero finite measures on . Specifically,
Definition 9.1.
A probability measure  on 
  is said to be a Dirichlet process with
parameter , if for every measurable partition 
B1   Bk of  (i.e. the Bis are disjoint and
k
i=1 Bi = ), the distribution of PB1   PBk under  is the finite dimensional Dirichlet
distribution B1   Bk.
In particular, when  is 	, every B∈ will be such that PB is Betab	−B, and
so EPB = B/	. The distribution B1   Bk, when it can be demonstrated
to exist, will be denoted . Since the measure  is indexed by the elements of , it is a
stochastic process; and  is the parameter space of the process.
Apart from the fact that the marginals of the Dirichlet measures have finite dimensional
Dirichlet distributions, the Dirichlet measures have other properties that make them attractive
in Bayesian non-parametrics. The most important of these properties is that of conjugacy. This
property, plus much of what has been said above can be best articulated by

PRIORS FOR THE CUMULATIVE DISTRIBUTION FUNCTION
261
Theorem 9.2 (Ferguson (1973)).
Let X1   Xn be a sample from P, where P ∈
 , and the
space 
  is (a priori) endowed with a probability measure  that is a Dirichlet process .
Then given X1   Xn, the posterior probability measure on 
  will also be a Dirichlet
process with parameter  + n
i=1 Xi, where X is a probability measure that is degenerate
at X.
Ferguson (1973) gives two proofs for the existence of the Dirichlet process  on 
 ,
one using Kolmogorov consistency conditions and the other a constructive one showing that 
is the sum of countable number of point masses, whatever be the value of . Sethuraman and
Tiwari (1982) give an alternative construction of the Dirichlet process which is simpler than
that of Ferguson (1973) and which has been advantageously used by several authors to obtain
new results involving the Dirichlet measure. Because of its simplicity and intuitive import, this
constructive definition of the Dirichlet distribution is given below:
Theorem 9.3 (Sethuraman and Tiwari (1982)).
Let Y1Y2   , be independent and identi-
cally distributed with Yi having a BetaM1 distribution, where M > 0. Let Z1Z2   , be
independent and identically distributed with Zi having a distribution F0. Suppose that the
sequences 
Yi and 
Zi are independent. Define P1 = 1 −Y1 and Pn = Y1Y2 ···Yn−11 −Yn
for n ≥2. Then P = PjZj is a Dirichlet process with parameter  = MF0.
To gain a better feel of this constructive definition, we write the  given above as MF0,
and call M the ‘coarseness’ parameter. Then the construction of P can be conceptualized via the
following steps:
(a)
Choose F0 in a manner that reflects our best guess about the distribution P that generates
the data we wish to analyze.
(b)
Draw an observation Z1 from F0.
(c)
Draw an observation Y1 from a BetaM1 distribution on (0,1).
(d)
Assign the probability mass Y1 to the observation Z1.
(e)
Now draw another observation Z2 from F0, and an observation Y2 from a BetaM1
distribution on 01 −Y1. Assign the probability mass Y2 to Z2.
(f)
Repeat step (e) m times, with Yi drawn from a BetaM1 distribution on 01 −Y1 −
Y2 −   −Yi−1, and Zi assigned mass Yi. Observe that the Yis, i = 1   m, sum to one
and that their joint distribution is a Dirichlet. Hence
(g)
We may construct an empirical distribution ZiYii = 1   m, with jumps of size Yi
at Zi. The empirical distribution so constructed will be the Dirichlet process MF0
(Figure 9.1).
Note that a small M would result in small values of Yi, and small Yis would yield a finer
approximation of F0 by the empirical distribution. Thus, the parameter M controls the coarseness
of the approximation of F0 by the Dirichlet process, where F0 encapsulates one’s best prior
guess of P. Note that there is some parallel between the constructive steps described above
and Ramsey’s (1972) construction of a prior distribution for the potency curve mentioned in
section 9.3.1.
There is one other noteworthy point about the Dirichlet measures discussed here. This pertains
to the fact that  gives probability one to the subset of all discrete probability measures on
the sample space . This point seems to have been first noticed by Blackwell (1973). The
implication of this property is that we would expect to see some observations repeated exactly,
and this in some scenarios may not be true. To avoid such limitations one tries to find workable
priors that choose continuous distributions with probability one. One such choice is the class of
processes that are neutral to the right. These will be discussed later in the section that follows,

262
NON-PARAMETRIC BAYES METHODS IN RELIABILITY
Z3
Z6
Z1
Z4
Z2
Z5
1
F0
Y3
Y6
Y1
Y4
Y2
Y5
Figure 9.1
Constructing a Dirichlet process.
but first we shall illustrate how Theorem 9.2 given above can be put to work for addressing
some standard statistical problems like estimating means, variances and distribution functions.
Example 9.1.
Suppose that F is an unknown life distribution function whose estimate is
desired. Let 	F be a (Bayes) estimate of F based on the Bayes’ risk which is taken to be a squared
error loss function
 
0 EFt −	Ft2dWt, where Wt is some specified non-random weight
function. If we assume that F ∈
, where 
 is endowed with a probability measure , and
that  is , then Ftt ≥0, has distribution Betat	+ −t; here t is a shorthand
for 0t. Consequently, our Bayes estimate of Ft based on no data will be
	Ft = EFt = t
	+
def=F0t
see Definition 9.1. We may interpret F0t as out prior guess about Ft.
Suppose now that T1   Tn are observations generated by F, and our aim is to update F0t
using T1   Tn. Then, our Bayes estimate would be EFtT1   Tn
def= 	Fnt, which by
virtue of Theorem 9.2 will be
	Fnt = t + n
i=1 Tit
	+ + n
= pnF0t + 1 −pnFnt
(9.27)
where pn =	+/	++n, and Fnt=n
i=1 Tit/n is the empirical distribution func-
tion of the sample.
The Bayes estimate (equation (9.27)) is therefore a mixture of the prior guess F0t and the
sample distribution function Fnt. The mixing coefficient pnt gives a large weight to the prior
guess F0t if 	+ is large compared to n. When 	+ is small compared to n, it is the
empirical distribution function that receives a large weight. When 	+ tends to zero, the case
of the ‘non-informative’ Dirichlet process prior, 	F, is simply the empirical distribution function.
Thus 	+ encapsulates one’s strength of belief in the prior guess F0t measured in units of
the sample size n. Note that the parameter M of Theorem 9.3 corresponds to the 	+ of this
example. More generally, we may let M correspond to x. Hence, to put Theorem 9.2 to work
a user need specify only two quantities, F0 and 	+, one’s best guess about F, and a measure
of the strength of belief in the guess F0.

PRIORS FOR THE CUMULATIVE DISTRIBUTION FUNCTION
263
Filtering Under the Dirichlet Process
Whereas estimating the unknown distribution function F would encapsulate as assessment of all
the uncertainty that is inherent in the scenario that generates the data T1   Tn, sometimes one
may be satisfied with an assessment of only the mean and the variance of the unknown F. This
is particularly so in the context of filtering wherein one endeavors to update the mean and the
variance of F in the light of evolving information that comes in the form of data generated over
time. In such scenarios, F is generally assumed to be a Gaussian distribution when the context
of application is signal processing for target tracking, or F is the double lognormal distribution
that was discussed in section 5.8.3. With F so specified, filtering will be parametric. But what if
one chooses not to specify F and prefers to do filtering in a non-parametric Bayes framework?
The methods of this section offer the necessary mechanism for doing so.
With the above in mind, consider the scenario of Example 1 and let
0 =

 
0
tdF0t =

 
0
tdt
	+
(9.28)
be the mean of our prior guess F0 of F. The prior guess F0 could be one of the standard
distributions used in filtering. Ferguson (1973), in his Theorem 9.3, claims that under the Dirichlet
process framework for F described before, the mean of F exists. Then, given the sample mean
T n = n
i=1 Ti/n, the Bayes estimate of the mean of F, again assuming a squared error loss, is of
the form
pn0 + 1 −pnT n
(9.29)
which is a weighted combination of the prior guess 0 of the mean F (indeed in the absence of
data, the mean of F0 is also the mean of F) and the sample mean of F, T n.
A Bayes estimate of the variance of the unknown F is slightly more complicated to obtain.
To see why, we first note that the variance of F,
VarF =

 
0
t2 dFt −

 
0
t dFt
2

is a random variable whose expectation is the Bayes estimate of VarF, when there is no data.
This is given as
EVarF = E

 
0
t2 dFt

−E

 
0
t dFt
2
=
	+
	+ + 12
0
(9.30)
where 2
0 is the variance of our prior guess F0. It is given as (cf. Ferguson (1973))
2
0 =
1
	+

 
0
t2 dt −2
0
Given a sample of size n with mean T n and variance s2
n, the Bayes estimate of VarF is
	+ + n
	+ + n + 1

pn2
0 + 1 −pns2
n

+ pn1 −pn0 −T n2

264
NON-PARAMETRIC BAYES METHODS IN RELIABILITY
The above can also be written as a mixture of three different estimates of the variance (cf.
Ferguson, 1973) as
	+ + n
	+ + n + 1

pn2
0 + 1 −pn

pn
n
n
i=1
Ti −02 + 1 −pns2
n


(9.31)
recall that, as before, pn = 	+/	+ + 1.
Thus filtering the mean and variance of the unknown F, under the Dirichlet process structure,
starts with (9.28) and (9.30), and would get updated sequentially (upon receipt of new data) via
(9.29) and (9.30).
The Case of Censored Data
The problem of using a Dirichlet process prior to obtain a non-parametric Bayes estimator of the
F of Example 1, when the observed data consists of a right-censored sample, was considered by
Susarla and Van Ryzin (1976). Under censoring the Dirichlet process prior loses its property of
conjugacy and the results become cumbersome. These are given below.
Following the notation of section 9.5.2, let Xiii = 1   n, be the observables with
Xi = minTici, ci being the right-censoring time of Ti; i = 1 if Ti ≤ci and i = 0, if Ti > ci.
Censoring is said to be exclusive (inclusive) censoring when the information given is of the
form Ti > ≥ci.
Let u1 < u2 < ··· < uk be the distinct values among X1   Xn, and let j be the number of
censored observations at uj. Let kt denote the number of uj’s that are less than or equal to t
and hk, the number of Xjs greater than uk. Then given the exclusive right-censored data, and
supposing that F ∈
 , where 
  is endowed with a probability measure  that is , the
Bayes estimator of the survival function 1 −Ft is, for M = 	+ and t = t, of
the form (Susarla and Van Ryzin, 1976):
t + hkt
M + n
kt

j=1
uj + hj + j
uj + hj

(9.32)
this Bayes estimator is the expectation of the posterior survival function. This estimator reduces
to the estimator of (9.27) for F when there is no censoring; the product term vanishes. As M
goes to zero, the estimator reduces to the Kaplan–Meier estimator.
Ferguson, Phadia and Tiwari (1992) describe several other scenarios wherein the Dirichlet
process priors have played a useful role for addressing several practical problems in statistics.
Also noteworthy is a paper by Kumar and Tiwari (1989) wherein reliability estimation for an item
operating in a random environment that is governed by a Dirichlet process has been discussed.
This work can be seen as a way to generalize the model of section 4.7.5 on the bivariate Pareto.
9.6.2
Neutral to the Right-prior Processes
There are two limitations of the Dirichlet process priors. One is that such priors always choose
discrete distributions with probability one. The other is that Dirichlet process priors are not well
suited for the treatment of right-censored data as the material leading up to (9.32) indicates. To
avoid these limitations one endeavors to find workable prior processes that choose continuous
distributions with probability one. One such choice is the class of prior measures that are neutral
to the right (NTR). These measures generalize the Dirichlet process priors and fit well with
right-censored data, both exclusive and inclusive. Specifically (cf. Doksum, 1974) if the prior is
NTR, then so is the posterior, irrespective of whether the data is a complete sample or a censored
sample (exclusive or inclusive). By contrast, under censoring, a Dirichlet process prior will not
lead to a Dirichlet process posterior; rather the posterior will be NTR.

PRIORS FOR THE CUMULATIVE DISTRIBUTION FUNCTION
265
Constructive Definition of NTR Distributions
We have stated before (in section 9.5.1) that a random distribution function F is NTR if for
t1 < t2 < ··· < tk, the following are independent:
Ft1 Ft2 −Ft1
1 −Ft1
    Ftk −Ftk−1
1 −Ftk−1

Because of the possibility that the denominator terms could be zero, an alternative definition of
NTR is preferred. Accordingly,
Definition 9.2.
A random distribution function on the real line is said to be NTR, if for
every m and t1 < t2 < ··· < tk, there exist independent random variables V1   Vm, such
that the vector 1 −Ft11 −Ft2   1 −Ftm has the same distribution as the vector
V1V1V2   m
i=1 Vi.
Different choices for the distributions of the Vis lead to different NTR distributions F. For
example, if Vi has a ii distribution for i=1   m, with i =m−1
j=i+1 j, then F will be a
Dirichlet process (cf. Doksum, 1974). The NTR family of distributions is therefore more general
than the Dirichlet process family. Indeed, a characterization of the Dirichlet process is that it is
both neutral to the right and also neutral to the left (cf. James and Mosimann, 1980). Besides
avoiding the possibility of division by zero, Definition 9.2 has the virtue of being a constructive
device. It gives us the ability to generate several families of NTR processes, depending on our
choice for the distributions of the Vis.
Characterization of NTR and Relationship with Lévy Processes
Some properties of the NTR family of distributions have been given before, in section 9.5.1. In
what follows, I elaborate on these properties, and give a few additional ones as well.
A key property of the NTR family of distributions is that if F is NTR, then the cumulative
hazard function Rt = −log1 −Ft, when viewed as a stochastic process, will have inde-
pendent increments. This feature is true even when Ft has discrete components, in which case
the cumulative hazard function will be defined as R∗t =
 t
0 dFs/1 −Fs; (Dey, Erickson
and Ramamoorthi, 2003). Note that Rt and R∗t will be identical when F has no discrete
components. The converse of the above property forms the basis for a simple characterization of
NTR processes. Specifically, if a stochastic process, say Yt, has independent increments, is non-
decreasing and is right-continuous, then Ft = 1 −exp−Yt is a random distribution function
that is NTR (Doksum, 1974).
The connection between the NTR property of F and the non-decreasing, right-continuous and
independent increments property of Yt is fortuitous. This is because we can import results from
the theory of increasing Lévy processes (sections 7.2.2 and 7.3.2) to obtain features about the
NTR class of distributions. One such feature would be the Lévy–Khinchin formula of (7.17),
which would give us PT > t when F, the distribution of T, is NTR. Another consequence
of the aforementioned connection stems from the fact that when the t of (7.17) is zero, the
independent increments process Yt will have non-random parts and thus Yt will increase only by
jumps. This means that Ft will also increase by jumps alone, and so with t equal to zero,
a neutral to the right Ft will be discrete with probability one.
Finally, the Lévy representation of Yt also enables us to classify the NTR family of distributions
into two classes; the homogenous and the non-homogenous NTR processes. If the Lévy measure
of a right-continuous, non-decreasing, independent increments process Yt is independent of t,
then F is a homogenous NTR process; if the Lévy measure depends on t, then the corresponding
NTR process is non-homogenous. Accordingly, a gamma process is a homogenous NTR process,
whereas the Dirichlet process is a non-homogenous NTR (as well as neutral to the left) process.

266
NON-PARAMETRIC BAYES METHODS IN RELIABILITY
Homogenous NTR processes have an advantage in that expressions for the posterior expectation
of F given the data simplify; this is exemplified via (9.33) below.
The Posterior Distribution and Conjugacy of NTR Processes
We have stated before (in section 9.5.1) that NTR random probabilities are attractive from a
Bayesian point of view because of Doksum’s (1974) main result that if X1   Xn is a sample
from F, and if F is neutral to the right, then the posterior distribution of F given the sample is
also neutral to the right. Thus the NTR family of random distributions is closed under a prior
to posterior transformation; this is their property of conjugacy. In what follows, we describe the
nature of the posterior distribution, first considering an uncensored sample of size one, and then
the cases of inclusive and exclusive right censoring.
Theorem 9.4 (Doksum (1974)) .
Let F be a random distribution function that is NTR, and let
X be a sample of size one from F. Then the posterior distribution of F given X = x is NTR. The
posterior distribution of an increment in Yt

def= −log1 −Ft to the right of x is the same as its
prior distribution. The posterior distribution of an increment in Yt to the left of x is obtained by
multiplying the prior density of the increment by e−y and then renormalizing.
Thus, for example, if the increment Yt −Ys, for s < t < x, has prior density dGy, then
the posterior density of the increment given X = x is e−y dGy/
 
0 e−y dGy. To complete a
description of the posterior distribution, let S = Yx −Yx denote the jump in Yt at x, and let Hxs
denote the distribution function of S at s. Then, if Yt is a homogenous NTR process with Lévy
measure dy,
Hxs =
 s
0 1 −e−ydy
 
0 1 −e−ydy
(9.33)
observe that Hxs is independent of x (cf. Ferguson and Phadia (1979), Theorem 5). This result
suggest that even if the prior process is free from fixed points of discontinuity, the posterior will
contain jumps at those points on the time axis where data are observed.
When X is censored at x, the following theorem describes the behavior of the posterior.
Theorem 9.5 (Ferguson and Phadia (1979), Theorem 3).
Let F be an NTR distribution func-
tion and let X be a sample of size one from F; let x be a real number.
(a)
Given X > x, the posterior distribution of X is also NTR. The posterior distribution of
an increment to the right of x is the same as the prior; the posterior distribution of an
increment to the left of x, or including x, is found by multiplying the prior density by e−y
and renormalizing, as in Theorem 9.4.
(b)
Given that X ≥x, the posterior distribution of F is also NTR. The posterior distribution
of an increment to the right of x or including x is the same as the prior distribution; the
posterior distribution of an increment to the left of x is the prior density multiplied by e−y
and then normalized as in Theorem 9.4.
In both the Theorems 9.4 and 9.5 it is assumed that at x there is no a-priori assumption of
discontinuity of F. The censored case is simpler to treat than the uncensored case because the
jump at x does not have to be treated separately. In the case of exclusive (inclusive) censoring,
the increment at x is treated as if it were to the left (right) of x. The general case of arbitrary
sample sizes can, in principle, be treated by a repeated application of the above two theorems. The
mechanics of implementing the above developments for practical applications gets cumbersome,

PRIORS FOR THE CUMULATIVE DISTRIBUTION FUNCTION
267
and the best that one is able to achieve is the expected value of the posterior distribution expressed
in terms of the moment-generating function (Theorem 4 of Ferguson and Phadia (1979)).
Simulation based approaches for a full Bayesian analysis involving the NTR processes have
been proposed by Damien, Laud and Smith (1995) and by Walker and Damien (1998). The
former exploit the structure of Lévy processes to generate (approximate) samples from ‘infinitely
divisible distributions’. The latter approach entails a hybrid of sampling methods and draws
upon the Beta-Stacy process introduced by Walker and Muliere (1997). The Beta-Stacy process
is an NTR process; it is a generalization of the Dirichlet process. Indeed, under censoring, the
posterior distribution spawned by a Dirichlet process prior is a Beta-Stacy process.


Chapter 10
Survivability of Co-operative,
Competing and Vague Systems
Euclid: His spirit is gone but here lie his elements.
10.1
INTRODUCTION: NOTION OF SYSTEMS AND THEIR
COMPONENTS
A point of view that dates back to Greek philosophers is that, at a microscopic level, every item is
an ensemble of smaller items that are linked together in some ordained manner. This hierarchical
view of matter is carried further to smaller and smaller items, so that on an atomic scale every
item is a collection of other items. However, such a regression to the infinitesimal must stop at
some point, and the level at which this happens leads us to the notion of an element (a component
or unit) of a system. The collection of elements constitutes a system, and the manner in which the
elements get linked goes to define the structure (or the architecture) of the system. The simplest
architectures are those of series and parallel systems, also known as competing and co-operative
systems, respectively. Such architectures have already been touched upon in sections 4.7.3, 4.7.4
and 7.4. The architecture of networks, which can be seen as a combination of co-operative
and competing systems, tends to be more intricate and therefore poses issues that could be
challenging to analyze. The aim of this chapter is to describe how the survivability of each item
and the manner in which they are connected translate to the survivability of the structure. System
survivability analysis is therefore a study of the behavior of its parts, the metric for behavior here
being survival. But there is more to this topic than merely the passive act of studying behavior.
One is also interested in matters pertaining to making decisions that optimize behavior. Thus
what is also germane here is the efficient design of system’s architecture and the apportionment
of reliability to each of its elements in order to achieve this optimum.
10.1.1
Overview of the Chapter
An overview of this chapter is given below; it provides a roadmap to a wide spectrum of issues that
I endeavor to address. In section 10.2, I introduce our notation, state some preliminaries, describe
the structure of some commonly encountered systems and provide some results pertaining to the
Reliability and Risk: A Bayesian Perspective
N.D. Singpurwalla
© 2006 John Wiley & Sons, Ltd

270
SURVIVABILITY OF CO-OPERATIVE, COMPETING AND VAGUE SYSTEMS
reliability of systems in relationship to the reliability of their components. Much of the material
of section 10.2 is old and honorable; it has been admirably covered in books such as those by
Barlow and Proschan (1975), Aven and Jensen (1999), and Hoyland and Rausand (2004). The
purpose of introducing section 10.2 is mainly to set the stage for describing the more recent
material of subsequent sections, though in section 10.2.1, I give some new material on the nature
of challenges posed by interdependencies, and families of multivariate Bernoulli distributions
for modeling them. Section 10.3 constitutes the bulk of this chapter. It articulates on the nature
of system survivability and introduces a framework for its formal treatment. Sections 10.3.2 and
10.3.3 describe the hierarchical nature of interdependencies and dependencies that our proposed
framework for system survivability spawns. Section 10.3.3 concludes with a brief discussion of
Monté Carlo integration that is useful for addressing the computational issues that the material
of the above sections generates. Sections 10.3.4 and 10.3.5 can be seen as a coupling of two
parts. In section 10.3.4, the first part, I introduce several continuous distributions on the unit
hypercube. These are used in section 10.3.5 to address the inferential issues that arise when
failure data on components and systems becomes available. Such issues are treated from a
Bayesian point of view and involve an extensive use of the Markov Chain Monté Carlo (MCMC)
method. In essence, the material of sections 10.3.4 and 10.3.5 constitutes a package for the
commonly encountered practical problem of assessing a system’s performance using data on the
performance of its individual units and on the system itself; the material of these sections is based
on Lynn, Singpurwalla and Smith (1998). Associated with section 10.3.4 is Appendix C, which
points out circumstances in system survivability assessment wherein Borel’s paradox can arise.
The focus of section 10.4 is on using techniques that are purely classified as ‘machine
learning’ – like neural nets. These can be seen as a way to bypass the several challenges and
difficulties of sections 10.2 and 10.3 that one encounters with modeling and computation in
the context of large networks with layers of interdependencies. Sections 10.5 and 10.6 have a
decision theoretic flavor. In section 10.5, I set up a framework for optimizing system reliability
subject to cost constraints via a judicious allocation of reliability to each of its components.
Motivated by the fact that when it comes to the matter of reliability, some individuals tend to
be risk averse so that cost alone is not the driving criterion for making decisions, we discuss
in section 10.6 the matter of the utility of reliability. Section 10.6 can be seen as a companion
to section 10.5, since the material here is germane to making decisions about choosing between
alternate system designs. Finally, in section 10.7 we discuss some recent work on characterizing
the behavior of components and systems that can simultaneously exist in multiple states. The
material here, motivated by concerns of realism, signals a change in the paradigm of how one
may look at the relationship between a system and its components. In effect, this material takes
an outward excursion from the foundational material of section 10.2, upon which the current
theory of system reliability is based.
10.2
COHERENT SYSTEMS AND THEIR QUALITATIVE PROPERTIES
By way of preliminaries, let us freeze (i.e. fix) time at some value  > 0, and consider the state
of each component of an n-component system. Define an indicator variable Xi = 10, if the i-th
component is functioning (failed) at . I suppose here that at any time , every component can
be declared to exist in only one of two states, functioning or failed. In actuality components can
be declared to exist in one of several states, such as perfect, degraded or failed. Furthermore,
it is sometimes difficult to classify an item as being in any one of the two states so that the
item is declared to simultaneously exist in multiple states. Issues of this kind are taken up in
section 10.7.
Corresponding to the indicator variables Xii = 1   n, for each component, we also define
an indicator variable X for the entire system, where X = 10 if the system is surviving (failed)

COHERENT SYSTEMS AND THEIR QUALITATIVE PROPERTIES
271
at . Knowing the disposition of each Xii = 1   n, we can determine the disposition of
X if we know the architecture of the system. In other words, X is a function, say , of the
Xis. The function  is called the structure function of the system. In what follows, I let
X ≡X1   Xn, so that X = X = 1 or 0. When X = n
i=1 Xi = mini Xi, the architecture
of the system is said to be a series system. In a series system, the system survives only when
all its n components survive. The system fails as soon as one of its n components fails; thus one
may say that the n components compete with each other to bring about a failure of the system
(section 7.4.1). Series systems are therefore also known as ‘competing systems’. When X =
1 −n
i=1 Xi
def= n
i=1 Xi = maxi Xi, the system’s architecture is said to be parallel redundant.
The system fails only when all of its n components fail. Parallel systems are also known as
‘co-operative systems’. This is because the system has, upon inception, n −1 components in
redundancy, and these redundant components can be seen as co-operating with each other to
keep the system afloat.
There is another aspect of systems with redundant components that needs mention. This has
to do with what is known as standby redundancy. Under parallel redundancy, all the surviving
components of the system are made to function (i.e. put to use) even though all that may be
needed is a single functioning component. An example of parallel redundancy is an airplane that
requires only two engines to fly, but which for added security has four engines, all of which
are turned on during flight. Under standby redundancy, the redundant components are waiting
to be turned on, until the failure of the active component at which time one of the surviving
redundant component is commissioned for use. An electric lamp with n −1 spare light bulbs
is an example of standby redundancy. Upon the failure of the first bulb, one of the n −1
spare surviving bulbs is put into service, and this process is repeated until all the n bulbs fail
and darkness transcends. The mathematics governing the behavior of systems in standby and
parallel redundancy is different. In the former case ‘convolutions’ of distribution functions come
into play; in the latter it is the distribution of the ‘n-th order statistic’ that matters. Therefore a
distinction between the two types of redundancies is germane.
When the structure function  is such that X = 10 if n
i=1 Xi ≥<k, for 1 ≤k ≤n,
the system is said to be a k-out-of-n system. Its special case is the series (parallel redundant)
system with k = n1. If an airplane with four engines needs at least any two of the four
engines to function, then its underlying architecture is a two-out-of-four system; i.e. k = 2 and
n = 4. In actuality many systems are a combination of series and parallel redundant systems.
In Figure 10.1, we illustrate such a mixed system which is a series connection of two systems
in parallel and two solo components. One of the parallel systems (also known as modules) has
three components, and the other has two components in series that are connected in parallel with
a single component.
It is evident that the structure function of this mixed system is of the form
X = X1 ⨿X2 ⨿X3 · X4 · X5 · X6 · X7 ⨿X8	
1
2
3
4
5
6
7
8
Figure 10.1
A mixed (series-parallel) system.

272
SURVIVABILITY OF CO-OPERATIVE, COMPETING AND VAGUE SYSTEMS
where X ≡X1   X8. Upon expansion, the above expression becomes
X = 1 −1 −X11 −X21 −X3	X4 · X51 −1 −X6 · X71 −X8	
The above example underscores the fact that the writing out the structure of mixed systems
is relatively straightforward using the  and the ⨿operators, so long as the components and
the system are assumed to exist in binary [0,1] states. As a further support for this claim of
simplicity, consider the bridge structure network of Figure 10.2.
The network of Figure 10.2 has a source and a sink; it is designed to transport material
(or communicate information) from the source to the sink. The arrows in the figure show the
direction of flow; it is unidirectional save for the link containing component (or node) 3, which
is bi-directional. The bridge structure network can also be represented as a parallel connection of
series systems (Figure 10.3) or as a series connection of parallel systems. Verify that its structure
function can be written as:
X =
X1 · X2 ⨿X4 · X5 ⨿X1 · X3 · X4 ⨿X4 · X3 · X2 or
X1 ⨿X4 · X2 ⨿X5 · X1 ⨿X3 ⨿X5 · X4 ⨿X3 ⨿X2
(10.1)
The components labelled (1 and 2), (4 and 5), (1 and 3 and 5), and (4 and 3 and 2) constitute
what are known as the min. path sets of the network. These are the smallest set of components
that need to function for the network to function (assuming that the remaining components have
failed). If any component in a min. path set fails, the system fails.
What distinguishes the structure function of the system of Figure 10.1 from that of Figure 10.2
is that in the latter there is a replication of indicator functions in each of the four terms. Thus,
with respect to the first equation above, the indicator variable X1 appears in the term X1 · X2
as well as the term X1 · X3 · X4; similarly, X4 appears in X4 · X5 as well as X4 · X3 · X2.
This replication, though it may seem innocuous, will create an obstacle when we wish to assess
the reliability of the network. But before getting into the nature of such obstacles, we need to
articulate the notion of a coherent system and point out some inequalities connected with the
behavior of such systems.
Loosely speaking, a coherent system is one wherein the structure function  is non-decreasing
in each of its arguments and in which every component exists because it has a role to play. That
is, the system does not contain components that are not essential (i.e. irrelevant). For example,
with respect to mobility, the radio in an automobile is an irrelevant component. Similarly, seat
belts are irrelevant vis-à-vis the automobile’s ability to provide transportation, but are relevant
if transportation with safety is a matter of interest.
1
4
3
2
5
Source
Sink
Figure 10.2
Bridge structure network.

COHERENT SYSTEMS AND THEIR QUALITATIVE PROPERTIES
273
With the Xis taking binary values 1 or 0, it can be seen that for any n-component coherent
system

Xi ≤X ≤

Xi
(10.2)
This result suggests that any coherent system cannot be weaker (stronger) than a series (parallel)
connection of its components.
There are two other aspects of coherent systems that warrant mention: duality and pivoting.
The first defines DX, the dual of a coherent system X as
DX = 1 −1 −X
where 1 −X = 1 −X1   1 −Xn. Verify that the dual of a series (parallel) system is a
parallel (series) system and the dual of a k-out-of-n system is a n −k + 1-out-of-n system.
Dimension Reduction by Pivoting
Pivoting pertains to decomposing a coherent system of n components in terms of a coherent
system of n −1 components by pivoting on component i. Specifically, we can always write,
that for any i = 1   n,
X = Xi1iX + 1 −Xi0iX
(10.3)
where
1iX = X1   Xi−11iXi+1   Xn
and
0iX = X1   Xi−10iXi+1   Xn
Here 1iX represents the structure of a system for which Xi is fixed at 1, and the remaining
n −1Xis are free to take the values 0 or 1; similarly with 0iX.
Decomposition by pivoting is a useful tool for assessing the structure function of large and
complex networks with many nodes. The main caveat here is picking the right node to pivot
upon. One starts by pivoting on node i to create a structure function involving n −1 nodes,
and then one pivots on node j of the n −1 component system to create a structure function
involving n −2 nodes, and so on until one arrives upon 11   1 and 00   0
whose values are 1 and 0, respectively. In actuality, it may not be necessary to keep pivoting until
one arrives at 1 and 0; one may be able to specify the indicator function of a structure
function at hand early on. I illustrate these issues by considering the bridge structure network of
Figure 10.2 with pivoting on component 3. We have
X = X313X + 1 −X303X
Clearly, 03X = X1 · X2 ⨿X4 · X5 and 13X = X1 ⨿X4 · X2 ⨿X5. Hence
X = X3X1 ⨿X4 · X2 ⨿X5	 + 1 −X3X1 · X2 ⨿X4 · X5	
(10.4)
and there is no need to further decompose 13X and 03X.

274
SURVIVABILITY OF CO-OPERATIVE, COMPETING AND VAGUE SYSTEMS
It now follows from (10.1) and (10.4) that the structure function of the bridge structure network
of Figure 10.2 has three different versions, the two of (10.1) and the one of (10.4). The last
equation has the virtue that there is no replication of any indicator variable in the ensuing terms.
By contrast, there is a replication of indicator variables in several terms that go to constitute
the two versions of X in (10.1). The absence of replication is a consequence of pivoting on
component 3. Another advantage of pivoting on component 3 is the ease with which we arrive
upon (10.4). Had we started by pivoting on component 1, we would have had to pivot several
times before which an expression for the structure function could be written out. Thus choosing
the right component to pivot upon is an important task.
Time and ‘Importance’ Considerations
In our development thus far, the effect of time has been frozen, and I have focussed attention
only on the Xis. The element of time may be introduced by noting that if t1   tn denote the
actual times to failure of the n components, and if t denotes the time to failure of the system,
then for a series system t =mini ti, and for a parallel redundant system t =maxi ti. Consequently,
by virtue of (10.2), we have the result that for any coherent system
min
i
ti ≤t ≤max
i
ti
The case of random times to failure will be treated in sections 10.2.1 and 10.3.
A final point that I wish to discuss here pertains to the ‘relative importance’ of each component
in a system. In any given system some components are more important (crucial) for the system’s
functioning than others. For example, with reference to the system of Figure 10.1, components
4 and 5 are more important than the remaining components because the failure of either would
cause the system to immediately fail, even if all the other remaining components are functioning.
With the above in mind, we would consider component i to be more important when 1iX −
0iX = 1 than when 1iX = 0iX = 1 or when 1iX = 0iX = 0; i.e. when
component i becomes critical. Motivated by this observation, let
ni =

XXi=1
1iX −0iX	
and define the importance of component i as Ii = ni/2n−1. The quantity ni represents the
number of times that component i can become critical to the system, and Ii is the proportion
of times the component becomes critical. The notion of importance enables one to rank the
components of a system. The notion of system signature, introduced by Samaniego (1985),
enables one to rank entire systems from a structural point of view. Essentially, the signature of
a system is a probability vector S = S1   Sn, where Si is the probability of system failure
upon the occurence of the i-th component failure, i = 1,    , n.
10.2.1
The Reliability of Coherent Systems
Reliability considerations come into play when Ti, the time to failure of the i-th component, is
random (i.e. an unknown quantity). In what follows, we assume that all the Tis, i = 1   n,
are uncertain and that given ‘chance’ pi, PTi ≥pi = 1 −Fpi = pi, where pi is assumed
known. The case of pi uncertain is taken up in section 10.3. Note that if pi is the reliability
of the i-th component for a mission of duration ; it is also the expected value of Xi, since
PTi ≥pi = PXi = 1pi. Similarly, let T denote the (uncertain) time to failure of the system,
with P T ≥p = p, where p is the reliability of the system. Note that p = EXp	, since
P T ≥p = PX = 1p. Knowing p = p1   pn, and the structure function of the

COHERENT SYSTEMS AND THEIR QUALITATIVE PROPERTIES
275
system , we can, in many cases, easily find p – provided the Xis are conditionally (given p)
independent. Specifically, for a series system, using multiplication rule of probability, we see that
PX = 1p = PX1 = 1   Xn = 1p =
n
i=1
PXi = 1pi =
n
i=1
pi
a function of the ‘chances’ pi’s alone. Similarly for a parallel system, we can verify that
PX = 1p = n
i=1 PXi = 1pi = n
i=1 pi, which again is a function of the pi’s alone.
As a consequence of the above relationships, plus (10.2), we have
n
i=1
pi ≤PX = 1p ≤
n
i=1
pi
the implication of which is that the reliability of any coherent system whose lifetimes are
independent is bounded from below (above) by reliability of a series (parallel) system.
When the system is a k-out-of-n parallel redundant systems, and when the known p is such
that p1 = p2 = ··· = pn = p0, then
PX = 1p =
n
j=k
	n
j

p0j1 −p0n−j
Thus for a series [parallel] system of three components each having component reliability p0,
p=p03 1−1−p03	, whereas p=3p021−p0+p03, if the system is a two-out-of-three
system. In the remainder of this section we shall drop the conditioning arguments pi, i=1   n
and p, since they are assumed known.
The pivotal decomposition of (10.3) leads us to an analogous formula for reliability, provided
that the Xis are conditionally independent (given the pi’s). To see how, note that for any coherent
system with structure function X
p = EX	 = EXi	E1iX	 + 1 −EXi	E0iX	
(10.5)
= piE1iX	 + 1 −piE0iX	
It follows from (10.5) that the reliability of the system is linear in each pi – the reliability
of component i – for i = 1   n. Furthermore, when p1 = p2 = ··· = pn = p0, p will be a
polynomial in p0. This polynomial is referred to as the reliability polynomial; its behavior
has attracted the attention of computer scientists and network theorists; for example, Chari and
Colbourn (1998).
In (10.5), if we consider the derivative of p with respect to pi, we have
d
dpi
p = E1iX −0iX	
since 1iX −0iX	 ≥0 with strict inequality holding for some vector, say X0, we see
that the reliability of any coherent system is a strictly increasing function of each pi.
To explore the shape of the system reliability function we start by considering a series [parallel]
system of n components with pi =p0, for all i. Here p =p0n 1−1−p0n	 lies entirely below
[above] the diagonal connecting the points 00 and 11. However, for coherent systems that
are mixtures of series and parallel systems, p as a function of p0 starts off at zero crossing
the diagonal mentioned above from below, and then culminates at one. In effect, p is like an
S-shaped function of p0.

276
SURVIVABILITY OF CO-OPERATIVE, COMPETING AND VAGUE SYSTEMS
We have seen that when the Xis are (conditionally) independent, therefore it is a straightforward
issue to calculate the reliability of series, parallel, or any combination of series and parallel
systems. The matter could get complicated in the case of networks, and this is even true when
the Xis are assumed independent. To appreciate this point consider the bridge structure network
of Figure 10.2, and focus attention on its structure function as given by the first equality of
(10.1). Pictorially, this structure function can be depicted via Figure 10.3 below.
The bridge structure functions as long as any one of the four series-system branches of
Figure 10.3 function. The nodes in each branch are the min. path sets. To facilitate calculation
of the reliability of the bridge system, I define the indicator variables Y1 = X1 · X2, Y2 = X4 · X5,
Y3 = X1 · X3 · X5, and Y4 = X2 · X3 · X4; then X = 4
j=1 Yj.
Suppose that the Xis are conditionally (given the pi’s) independent, where pi = PXi = 1i =
1   5. Then PY1 =1=p1p2, PY2 =1=p4p5, PY3 =1=p1p3p5, and PY4 =1=p2p3p4.
However, to obtain p = EX	, we need to know P4
j=1 Yj = 1, and this will not be given
by 4
j=1 j, where j = PYj = 1j = 1   4. The reason is that the Yjs are not independent
even though the Xis are. For instance, since X1 is common to both Y1 and Y3, Y1 and Y3 cannot
be judged independent; similarly with the other Yjs. Thus in this formulation of X, it is the
dependence between the Yjs that poses an obstacle for assessing the network’s reliability.
There is a way to overcome the above obstacle, and this is via a judicious choice of pivoting.
To get a sense for this consider (10.4), which is the structure function of the network obtained
by pivoting on X3; it was given as
X = X3X1 ⨿X4 · X2 ⨿X5	 + 1 −X3X1 · X2 ⨿X4 · X5	
If we let Z1 = X1 ⨿X4 · X2 ⨿X5, then PZ1 = 1 = p1 ⨿p4 · p2 ⨿p5; similarly if Z2 =
X1 · X2 ⨿X4 · X5, then PZ2 = 1 = p1 ⨿p2 · p4 ⨿p5. I may now invoke the relationship
of 10.5 to obtain the network’s reliability as
p = PX = 1 = p3p1 ⨿p4 · p2 ⨿p5	 + 1 −p3p1 · p2 ⨿p4 · p5	
(10.6)
Thus we see that pivoting is a way to circumvent the effect of dependencies caused by appearance
of common nodes in the branches, the branches being determined by the min. path sets. But pivoting
can also be seen as a way of computing network reliability by taking conditional expectations. This
1
2
4
5
1
3
5
2
3
4
Y1
Y2
Y3
Y4
Figure 10.3
Series-parallel representation of the bridge structure of Figure 10.2.

COHERENT SYSTEMS AND THEIR QUALITATIVE PROPERTIES
277
X1
X4
X2
X5
X1
X2
X4
X5
Figure 10.4
Decomposition of the bridge structure network of Figure 10.2 by pivoting on X3.
is because (10.5) is, de facto, a consequence of conditioning on Xi and then taking expectations.
Another way to look at pivoting is to examine (10.6) and to note that p is a p3 weighted mixture of
the reliability of two systems, one whose architecture is X1 ⨿X4 · X2 ⨿X5, and the other whose
architecture is X1 · X2 ⨿X4 · X5 (Figure 10.4).
Pivoting therefore breaks down a network’s architecture into two sub-architectures and obtains
the network’s reliability as a mixture of the sub-architecture reliabilities. Thus, from a probabilis-
tic point of view, a network can be seen as a mixture of co-operative and competing systems. In
actual practice networks have interconnections that are more intricate than the one of Figure 10.2,
and generally the size of a network tends to be large. This makes the task of identifying the right
node to pivot upon challenging.
But the key matter that we need to come to terms with pertains to the issue of the assumed
independence of the Xis (given the pi’s). This assumption is idealistic. Commonalities in manu-
facture, environment and operational policies would suggest that the lifetimes Tii=1   n be
judged dependent (section 4.7). This in turn would suggest that the Xis are also dependent, at least
for certain sub-sets of 12   n. In what follows I outline some strategies for incorporating
dependence between the Xis and approaches for describing the nature of such dependencies.
The Challenge of Dependent Indicator Variables
We start with a reference to the system of Figure 10.1, and suppose that its eight indicator
variables X1   X8 are interdependent. In order to assess the reliability of this system incorpo-
rating the above interdependencies, the most direct and natural thing to do would be to introduce
an eight-variate Bernoulli model. However, such high dimensional multivariate Bernoulli models
are difficult to meaningfully specify, and when specified, can become cumbersome to work with
(cf. Teugels (1990), whose use of the matrix calculus for representing multivariate Bernoullis is
noteworthy). The main obstacle here is that the models are not parsimonious in the number of
parameters, three in the bivariate case and seven in trivariate case.
In view of the above, it seems necessary to consider approximations to system reliability
by reducing the dimensionality of dependence to say, two or at best three. One possibility
would be to assume that dependence exists only among those components in each module of a
system. Thus, for example, the system of Figure 10.3, which can be seen to have three modules
comprising of components 123, components 45, and components 678, would have
X1 ▽X2 ▽X3, X4 ▽X5, and X6 ▽X7 ▽X8; here ▽denotes ‘dependence’. Once this is done, I
may use a bivariate Bernoulli model to describe the joint behavior of X4X5, and trivariate
Bernoulli models for X1X2X3 and X6X7X8. The particular form that these two- and
three-dimensional Bernoulli models could take will be given in the sub-section that follows.
Whereas the strategy of restricting dependence to only the components in a module may get us
going for modules with three or fewer components, the problem of high-dimensional dependency
will continue to persist for modules having several components. Thus we seek the next level
of approximation and one possibility would be to consider Bernoulli variables with Markov
dependence. But to do this in a meaningful way, we need to label the components according

278
SURVIVABILITY OF CO-OPERATIVE, COMPETING AND VAGUE SYSTEMS
to some logical order, and proximity seems like a meaningful way to proceed. In the case of a
transportation or communication network, the direction of flow seems like a sensible thing to
do. The labeling of components in Figure 10.1 for each of the three modules is already in order
of proximity and thus no re-labelling is warranted. However, for the bridge structure network,
the components in the branch labelled Y4 of Figure 10.3 should be re-labelled as 432 to
correspond to the direction of the flow.
Under Markov dependence, given a collection of indicator variables X1   Xk, labeled
according to some meaningful order, we assume that any Xi depends only on its predecessor
Xi−1, for i = 2   k. That is, dependence exists only among the adjoining indicator variables.
A consequence is that
PX1   Xk = PXkXk−1PXk−1Xk−2···PX2X1PX1
Now all that one needs to proceed further are a collection of bivariate Bernoulli distributions,
each corresponding to the pair XiXi−1, i = 23   k.
When it comes to the bridge structure of Figure 10.2, with all the five nodes interdependent,
issues do not become easy. We see here two possibilities, each carrying its own baggage. The
first would be to start with a suitable five-variate Bernoulli distribution for X1   X5 and
use it to obtain the network’s reliability via the inclusion-exclusion formula of probability (cf.
Feller, 1968, p. 89), on the event 4
j=1 Yj = 1 of Figure 10.3. Accordingly,
P

4
j=1
Yj = 1

=
4
j=1
PYj = 1 −

i̸=j
PYi · Yj = 1 +

i̸=j̸=k
PYi · Yj · Yk = 1 −P

4
1
Yj = 1


(10.7)
The five-variate Bernoulli distribution will enable us to obtain each of the above four proba-
bilities. The cumbersome nature of such an assessment is obvious. A full five-variant Bernoulli
distribution will entail 26 parameters, and assessing terms such as P4
j=1 Yj = 1 = PX1 =
X2 = X3 = X4 = X5 = 1 will require of us a consideration of all the five variates. Simplification
using Bonferroni’s inequalities (Feller, 1957, p. 100), wherein P4
j=1 Yj =1≥4
j=1 PYj =1−

i̸=j PYi ·Yj =1 will not help, because to assess PY1 ·Y3 =1, PY2 ·Y4 =1 and PY3 ·Y4 =1,
I still need to specify P5
j=1 Xi = 1.
Dimension reduction by assuming interdependence only among the components in each of the
four min path sets 12, 45, 135 and 234 is again not possible because component
replication relates the min. path sets to each other, and this in turn results in the need to consider
interdependency between all the five Xis. Similarly, with an assumption of Markov dependence
within each min. path set. Thus, the dimension reduction strategies that enabled us to approximate
system reliability in the non-network scenario of Figure 10.1 do not work when it comes to the
likes of networked systems.
Our proposed second strategy for assessing the reliability of the bridge structure network is to
approximate the reliability by exploiting the pivotal decomposition shown in Figure 10.4. But
to invoke this decomposition we need to assume that X3 is independent of the remaining four
Xis, and this may not be meaningful. Furthermore, doing so will reduce the dimensionality of
dependence only by one; I will still need a four-variate Bernoulli model for X1X2X4X5 to
obtain the network’s reliability.
To conclude, the scenario of network reliability underscores the need to entertain multivariate
Bernoulli distributions that are parsimonious and meaningful. In what follows I give examples
of some possible choices.

COHERENT SYSTEMS AND THEIR QUALITATIVE PROPERTIES
279
Modelling Interdependence Using Multivariate Bernoullis
A bivariate Bernoulli for X1X2 is the simplest case to start with. The model has three
natural parameters that characterize it. These are: EXi = pi, i = 12 and 12 = CovX1X2 =
EX1 −p1X2 −p2. The joint probabilities p00 = PX1 = 0X2 = 0, p10 = PX1 = 1X2 = 0,
p01 = PX1 = 0X2 = 1 and p11 = PX1 = 1X2 = 1, with p00 + p10 + p01 + p11 = 1, can all be
expressed in terms of the three natural parameters. To see how, let 12 = EX1X2 = 12 + p1p2;
then 12 = p11. Writing qi = 1 −pi, i = 12, and solving for p00, p10 and p01, we obtain:
p00 = q1q2 + 12, p10 = p1q2 −12, and p01 = q1p2 −12. With p11 = 12 + p1p2, the above
representations separate the independence components from the dependence ones; this is because
12 = 0, when X1 and X2 are independent.
To fully specify the bivariate Bernoulli model we need to pin down on the natural parameters
p1, p2 and 12. One way of streamlining the process for doing so would be to consider any
suitable bivariate distribution of the lifetimes T1 and T2 discussed in section 4.1, and to associate
T1 and T2 with X1 and X2, respectively. We can then deduce the required parameters from
the parameters of the bivariate distribution of T1 and T2 via the relationship PX1 = 1X2 =
1 = PT1 ≥T2 ≥ for any  > 0. Thus, for example, if the joint distribution of T1 and
T2 is the BVE of section 4.7.4 with PT1 ≥T2 ≥1212 = exp−1 −2 −12
(equation (4.37)) then pi = exp−i + 12, i = 12, and 12 = 12/1 + 122 + 12	,
where  = 1 + 2 + 12. Similarly with the other choices of T1 and T2.
The trivariate Bernoulli for X1X2X3 will have seven natural parameters EXi = pii =
123ij = EXi −piXj −pjij = 121323, and 123 = EX1 −p1X2 −
p2X3 −p3. Whereas the structural import of a quantity such as 123 is not clear, other than
the sense that it encapsulates some form of dependence between X1, X2 and X3, it can be seen
(cf. Teugels, 1990) that quantities such as p000, p100, p010, p001, p110, p101, p011 and p111 can be
expressed in terms of the seven natural parameters; here p000 = PX1 = 0X2 = 0X3 = 0 and so
on. Thus, for example, with qi =1 −pii =123, I can see that p000 =q1q2q3 + q312 + q213 +
q123 −123, and this representation separates the independence part, namely q1q2q3, from the
two- and three-way dependence as reflected by 12, 13, 23 and 123, respectively. Dropping
the three-way dependence by setting 123 =0 would make the model more parsimonious but still
would require of us a consideration of six natural parameters. The representation of p000 given
above not only separates the dependence and the independence parts, but it also shows how each
dependent part contributes to the probabilities at hand.
It is clear from our discussion of the trivariate case described above that a consideration
of higher order Bernoulli cases would become quiet cumbersome. Consequently, this line of
multivariate Bernoulli model development will not be attractive from an applications point of
view. Thus, we now turn attention to the case of Bernoulli models with Markov dependence.
Consider a sequence of n Bernoulli random variables X1   Xn, and assume that the suc-
cessive quantities experience a Markovian dependence of the form:
P Xi = 1 = 1 −PXi = 0 = p > 0
i = 12   n
and
P Xi = 1Xi−1 = 1 = 
i = 23   n
It is evident that PXi = 0Xi−1 = 1 = 1 −, PXi = 1Xi−1 = 0 = 1 −p/q, and that PXi =
0Xi−1 = 0 = 1 −2p + p/q, where q = 1 −p. When  = p, the model reduces to a collection
of independent Bernoulli variables, and when  > p there will be a clustering among the ones
and among the zeroes because of the Markov assumption for xi = 1 or 0,
PX1 = x1   Xn = xn = PX1 = x1PX2 = x2X1 = x1···PXn = xnXn−1 = xn−1

280
SURVIVABILITY OF CO-OPERATIVE, COMPETING AND VAGUE SYSTEMS
from which it follows that (cf. Klotz, 1973) that
PX1 = x1   Xn = xn = c1nr
1s
2t
3
(10.8)
where for r = n
i=2 xi−1xi, s = n
i=1 xi and t = x1 + xm,
c1n =1 −2p + pn−1/qn−2
1 =1 −2p + p/p1 −2
2 =1 −2pq/1 −2p + p2and
3 =1 −2p + p/q1 −
This multivariate Bernoulli model is parsimonious in the sense that it entails only two param-
eters p and . The simple functional form of (10.8) makes this model attractive from the
point of view of applications. Its main negatives are the fact the variables X1   Xn
need to be such that their indices reflect some meaningful order, and that the relation-
ship between the successive variables turns out to be the same; specifically, CovXiXj =
p −p, for all i ̸= j. Whereas the multivariate Bernoulli distributions introduced thus
far are based on the modeling of pairwise and three-way dependencies, there remains the
possibility of generating multivariate Bernoulli distributions via mixtures of independent
Bernoullis. This approach to generating dependent lifelengths was considered by us before
(section 4.7.5) in the context of items operating in a common environment. The bivari-
ate Pareto distribution was motivated by arguments of this type. Thus in order to encap-
sulate interdependence among the Xis that are the consequence of systems and networks
operating in a common environment, it seems natural to consider p-mixtures of indepen-
dent (given p) identically distributed Bernoullis with P Xi = 1p = p, for i = 1   n.
Consequently,
P X1 = x1X2 = x2   Xn = xn =
1

0
ps1 −pn−spdp
(10.9)
where s = n
i=1 xi, and  p is the probability density function of p.
Note that (10.9) is in essence the infinite form of de Finetti’s Theorem on exchangeable
sequences (Theorem 3.2 of section 3.1.3). Different choices for p would result in different
versions of the bivariate Bernoulli distribution for the sequence X1   Xn. Parsimony is
assured because p would not contain an excessive number of parameters – two in the case
of the beta distribution, the natural choice.
Suppose then that p is taken to be the beta distribution of (5.11) with parameters  and .
Then, in the bivariate case, (10.9) reduces to the form
PX1 = x1X2 = x2 =   +   + x1 + x2  −x1 −x2 + 2
  +  + 2  

with marginals for Xi, i = 12 given as
PXi = xi =   +   + xi  −xi + 2
  +  + 2  


THE SURVIVABILITY OF COHERENT SYSTEMS
281
Since E Xi = EpExiXip	 = Epp, i = 12 and
CovX1X2 =EX1X2 −EXi2
=EpEX1X2X1X2p	 −Epp	2
=Epp2 −Epp2
=Varpp
it follows that E Xi = / +  and that the dependence between X1 and X2 is encapsulated
by CovX1X2 = / + 2 +  + 1	. The above arguments generalize to the n-variate
case, giving us a mechanism to generate higher order expectations such as E n
i=1 Xi	 = Ep pn
that are needed for system reliability assessment. The issue therefore boils down to obtaining
Ep pn which, when p is a beta distribution, turns out to be
Ep pn =   +   + n
  +  + n 
Since the nature of dependence between any two Xis, as encapsulated by Cov

XiXj

, i ̸= j, is
the same over all i and j, this could be seen as a limitation of the bivariate Bernoulli model
of (10.9). This limitation is not unlike that of the Markov dependent Bernoulli model of (10.8)
wherein Cov

XiXj

=p −p for all i ̸=j. In either case, both the Markov dependent and the
mixture-based Bernoulli models offer a convenient way to compute the reliability of networks and
systems whose indicator variables X1   Xn can be assumed interdependent in the manner
prescribed by (10.8) or (10.9).
10.3
THE SURVIVABILITY OF COHERENT SYSTEMS
Preamble and Overview: Reliability and Survivability
What do I mean by the term ‘system survivability’ and how does it differ from ‘system reliability’?
After all, the current literature in reliability theory does not make any such distinctions. To
answer the above question I start by noting that the material of section 10.2.1 was centered around
an assessment of p, a system’s reliability, given its structure function  and assuming that the
component reliabilities pii = 1   n are known. We emphasize that p and the pi’s represent
chance – not probabilities. As mentioned before (in section 4.4), by probabilities we would mean
our personal uncertainties about the pi’s, the p, and also T, a system’s lifetime. By the term
‘System Survivability’ we mean an assessment of T incorporating our uncertainties about the pi’s
(and when appropriate p) as well. In actuality, the pi’s and the p are not known and are unlikely
to be ever known, and thus the distinction between ‘system reliability’ and ‘system survivability’
is important and needs to be emphasized. Essentially, the former pertains to assessing uncertainty
about T assuming the pi’s fixed and known; the latter assesses T incorporating uncertainties about
the pi’s. By and large computer scientists and network analysts have focused attention on system
reliability alone, leaving aside the matter of system survivability. In this section, I draw upon the
former to address issues spawned by the latter. In so doing I provide a more complete picture
about the assessment of a system’s lifetime. I start by proposing (in section 10.3.1) a general
architecture for looking into the issue of system survivability and follow this up by exploring
survivability under the two scenarios of independence and interdependence – sections 10.3.2 and
10.3.3, respectively. In section 10.3.4, I describe some models on the unit hypercube that help
implement the material of section 10.3.3. In section 10.3.5, I address, from a Bayesian point of
view, the inferential issues that arise when failure data are available.

282
SURVIVABILITY OF CO-OPERATIVE, COMPETING AND VAGUE SYSTEMS
10.3.1
Performance Processes and their Driving Processes
We will continue to work with the framework and notation of section 10.2 but will slightly
expand the latter to incorporate the additional generalities that we need to consider here. We
start by replacing the pi’s and the p, by pi and p, respectively, for i = 1   n. Since
 ≥0, pi will be a decreasing (i.e. non-increasing) function of , with pi0 = 1 and pi ↓
0 as  ↑, for i = 1   n; similarly with p. We assume that for any  ≥0, pi is
unknown, and that our uncertainty about is described via our (personal) probability  pi.
Similarly,  p1   pn would encapsulate our joint uncertainty about the collective
p1   pn. But regarding pi unknown for all  ≥0, tantamounts to making pi ≥
0 a decreasing stochastic process with state space 01	 and parameter space 0, for
i = 1   n. This in turn would make p1   pn ≥0 a joint stochastic process
with state space 01	n and parameter space 0. The components of this joint stochastic
process could be assumed independent or not depending on one’s subjective assessment of the
pis. Similarly, p ≥0 is also a stochastic process with state space 01	 and parameter
space 0.
Analogous to what we did with the pi’s and p, we expand our notation to write Xi = 10,
if the i-th component is functioning (failed) at ,  ≥0. We assume that Xi0 = 1; thus, like
pi, Xi is a decreasing (non-increasing) function of . Similarly X = 10, if the system
is functioning (failed) at . We now assume that PXi = 1piss ≤ = pi; i.e. the state
of Xi depends only on the state of pi• at time , and not on the past history of the process
piss ≤. We continue to interpret pi as the reliability of the i-th component at time
. Furthermore, with the disposition of Xi uncertain over all , we look at Xi ≥0
as a stochastic process that is driven by the process pi ≥0, and whose sample path
is a decreasing step-function. We call the process Xi ≥0 the performance process of
the i-th component, i = 1   n. Similarly, X ≥0 is the performance process of the
system, and X1   Xn ≥0 the joint performance process of the n-components.
With PX = 1pss ≤ = p, the reliability of the system can be interpreted as p.
Let Pi=PXi=1 denote the survivability of the i-th component to time , i=1   n,
and P=PX=1 the survivability of the system to . Then, by the law of total probability
Pi =
1

0
PXi = 1pipidpi
=
1

0
pipidpi = E pi
Similarly, if p encapsulates the uncertainty about p for any  ≥0, then
P = E p
Under certain circumstances (namely, the assumption of ‘hierarchical independence’, described
in section 10.3.2), P will be a function, say h, of P1   Pn alone. The form of h will
depend on the design of the system: series, parallel, or a mixture of series and parallel systems.
When such is the case system survivability assessment is quite straightforward. Otherwise the
issue becomes complicated and we then need to resort to approximations and simulations.
To summarize, our architecture for assessing system survivability analysis entails a consider-
ation of two stochastic processes, a joint performance process X1   Xn ≥0, and its
driving process p1   pn ≥0. Note that the initial specification of the driving pro-
cess is a subjective exercise, since each component of the process represents a chance, which is

THE SURVIVABILITY OF COHERENT SYSTEMS
283
1
0
Performance
process
Driving
process
{X1(τ); τ ≥ 0}
{p1(τ); τ ≥ 0}
Time τ
Figure 10.5
Sample paths of a performance process and its driving process.
unknown; the driving process can get updated when data is available. My process-based architec-
ture is motivated by the fact that we have made a distinction between reliability and survivability
and that we have not frozen time at some fixed , as is typically being done. In Figure 10.5
I illustrate, for the case n = 1, the sample paths of the performance process X1 ≥0 and
its driving process p1 ≥0.
Given the driving process, the performance process can be fully specified. Thus an issue that
needs to be addressed pertains to some meaningful choices for the driving processes. But before
getting into that matter, I first illustrate the workings of our framework by looking at the simple
cases of n component series, parallel and other coherent systems; this is done below.
10.3.2
System Survivability Under Hierarchical Independence
Let Ps denote the survivability of a series system of n components. We start by considering
the case n = 2. Then
Ps = P X1  = 1 and X2  = 1
which by the law of total probability can also be written as
Ps =

P
PX1  = 1X2  = 1p1p2 p1p2 dp1dp2
where  p1p2 encapsulates our joint uncertainty about the component reliabilities p1
and p2, and P is the set of values that p1 and p2 can take; it is a subset of the
unit square.
What should  p1p2 be? This is an important question that needs to be meaningfully
addressed. A question like this has not been raised before because a consideration of uncertainty
about chances has not been a part of the toolkit of system reliability theory. A convenient
starting point would be to assume that p1 and p2 are independent so that  p1p2=
 p1 p2. The case of dependence between p1 and p2 will be considered next,
in section 10.3.3. But assuming p1 and p2 independent tantamounts to the claim that a
knowledge of the chance of failure of one component does not change our disposition about
the chance of failure of the second; this may not be realistic because the components may

284
SURVIVABILITY OF CO-OPERATIVE, COMPETING AND VAGUE SYSTEMS
have commonalities in their hazard potentials. Putting aside for now this matter of realism, the
aforementioned independence assumptions lead us to the result that
Ps =

P
PX1  = 1X2  = 1p1p2 p1p2 dp1dp2
=

P
p1p2 p1p2 dp1dp2
provided that we also make the following additional independence assumptions:
(i)
Given p1 and p2, X1 X2 are independent;
(ii)
Given p1, X1  is independent of p2; and
(iii)
Given p2, X2  is independent of p1.
We now have in place a hierarchy of independence assumptions, (i), (ii) and (iii) above,
constituting the first stage of hierarchy, and the independence of p1 and p2, being the
second stage of the hierarchy. This is what we mean by the term hierarchal independence; first,
the independence of Xi s given the pi ’s, and then the independence of pi ’s themselves.
Independence of the Xis is assured only when the pi’s are also independent. A consequence
of the hierarchical independence is that now Ps can be written as
Ps = P1P2
where Pi is the expected reliability of component i, i = 12. Generalizing to the case of
n components in series, we would have Ps = n
i=1 Pi. Thus, under the assumption of
hierarchical independence, the survivability of a series system is the product of the expected
reliabilities of its components. Alternatively, the survivability of the system is also the expected
value of its reliability.
The case of a parallel redundant system proceeds along similar lines. Here, if Pp denotes
the survivability of n components in parallel redundancy then
Pp = 1 −
n
i=1
1 −Pi =
n
i=1
Pi
The expressions for Ps and Pp parallel those for the reliability of series and parallel
systems, respectively, save for the fact that the component reliabilities get replaced by their
expected values.
In general, for any coherent system of order n, for which the kind of assumptions of hierarchical
independence described above can be made, it can be seen that the system’s survivability is of
the form
P = hP1   Pn
where h is some function of the component expected reliabilities.
10.3.3
System Survivability Under Interdependence
Note that by independence or interdependence, we are alluding to the behavior of the Xis.
Unlike independence which had to be induced hierarchically, namely, independence of the Xis

THE SURVIVABILITY OF COHERENT SYSTEMS
285
given the pis and then an independence of the pis themselves, interdependence can be
brought into play at either or both stages of the hierarchy. This requires that we consider two
scenarios: (a) independence of the Xis given the pis and then dependence of the pis;
(b) dependence of the Xis irrespective of the disposition of the pis. This is because under
(a) dependence of the pis induces a dependence of the Xis, even when the latter are
conditionally (given the pis) independent. We start with scenario (a).
Conditionally Independent Lifetimes with Dependent Reliabilities
Consider a coherent system of n components whose lifetimes X1   Xn are con-
ditionally independent given their respective reliabilities p1   pn. We assume that
p1   pn are dependent with p1   pn encapsulating our joint uncertainty
about them; since 0≤pi≤1i=1   np1   pn resides on the unit hypercube.
Section 10.3.4 is devoted to a discussion of some specific versions of •.
With the above set-up in place, it is possible to verify – via a repeated use of the pivotal
decomposition formula – that the survivability of the system P will be of the form
P =

hp1   pnp1   pndp1···dpn
(10.10)
where h is some function of the pis. For example, in the case of series [parallel] systems
hp1   pn =
n
i=1
pi

n
i=1
pi


The Case of Conditionally Dependent Lifetimes
We now turn attention to scenario (b) wherein the Xis are conditionally (given their respective
pis) dependent, and p1   pn is arbitrary. When such is the case a probabilistic
model for the Xis given the pis needs to be specified. Possible choices are the multivariate
Bernoullis given before or the multivariate failure models given in section 4.7, and depending
on the scenario at hand any one of these can be selected. As an illustration, consider the case of
a series system with two components discussed in section 10.3.2. Recall that the survivability of
such a system is
Ps =

P
PX1 = 1X2 = 1p1p2p1p2dp1dp2
With the Xis assumed (conditionally) dependent, we need to specify a probability model for
the first term on the right-hand side of the above, and a possible choice is the BVE of (4.39).
Under this choice pi = exp−i + 12i = 12, and PX1 = 1X2 = 1p1p2
becomes PX1=1X2=11212=exp−, where =1 +2 +12. Consequently
p1p2 would get replace by 1212. Thus Ps would become
Ps =

1212
exp−1212d1 d2 d12
(10.11)
Similarly for parallel redundant systems and with other choices for PX1 = 1X2 =
1p1p2.

286
SURVIVABILITY OF CO-OPERATIVE, COMPETING AND VAGUE SYSTEMS
Computing Survivability by Monté Carlo Integrals
The two scenarios of interdependence considered here result in the need to evaluate integrals of
the type given by (10.10) and (10.11). Often these cannot be analytically evaluated because of
the complex and high-dimensional nature of the underlying •. One approach to bypassing
such difficulties would be via a (crude) Monté Carlo integral wherein, in the case of (10.10), we
approximate P by
P = 1
M
M

j=1
hpj
(10.12)
where pj=pj
1   pj
nj =1   M, are M independent vector-valued samples gen-
erated from •. The ease with which such samples can be generated depends on the functional
form of •. With a judicious choice of •, the samples can be straightforwardly generated
via an MCMC-based simulation. Thus a task that remains to be addressed is the specification of
•, and this is the topic of the next section. The matter of generating samples from • will
be taken up in section 10.3.5. The treatment of the relationship of (10.11) will proceed along
similar lines.
Since P represents our personal probability that the system survives to , it connotes the
amount that we are willing to bet on the event X = 1. Thus, should we be able to calculate
P exactly, then the matter of assessing survivability will have been fully addressed once P
is specified. However, when P is approximated by P, it is P that represents the amount
we are prepared to stake as our bet. But since P is obtained via a simulated set of data, it is
subject to sampling error, and so it would make sense to specify upper and lower limits on it.
More generally, the upper and lower probability paradigm for quantifying uncertainty, advocated
by some such as Walley (1991), would now become germane.
A way to obtain the aforementioned probability limits would be to construct a histogram of the
hpjs, j = 1   M, where each hpj ∈01, and to pick two points on the histogram,
say PL and PU, such that the area of the histogram between these points is 1 −, for some
 ∈01. The PU and the PL would represent the upper and lower betting probabilities. In
the frequentist paradigm the upper and lower 1001−% confidence limits on system reliability
would be the analogues of PU and PL, respectively.
10.3.4
Prior Distributions on the Unit Hypercube
The need for having at hand multivariate distributions on the unit hypercube has been pointed
out in section 10.3.3, wherein it was understood that p1   pn encapsulates our joint
uncertainty about the component reliabilities pii = 1   n. Furthermore, since • is a
personal probability, it needs to be specified by taking into account subjectivistic considerations.
The purpose of this section is to propose several possible candidates for •. The proposed
candidates should not only be intuitively meaningful, but should also be such that their choice
facilitates a Bayesian updating (when failure data are available) via Monté Carlo methods such as
MCMC. The material of section 10.3.5 will be devoted to a discussion of the updating technology
using MCMC, and survivability assessment via the Monté Carlo integral.
The construction of joint distributions on the unit hypercube has been of interest to statisticians
concerned with a Bayesian analysis of Bernoulli data from similar but non-identical sources;
see, for example, Danaher and Hardie (2005). Indeed, the method of copulas (discussed in
section 4.7.1) is popular because it is able to fulfill such needs. Recall that a copula is a
multivariate distribution on a unit hypercube whose marginal distributions are uniform. Thus
one way to construct joint distributions on the unit hypercube with marginals having any general
distribution could be via the method of copulas. But such methods tend to be mechanistic and

THE SURVIVABILITY OF COHERENT SYSTEMS
287
lack the intuitive import that a subjectivistic specification of • would mandate. We therefore
need to consider approaches that are more fundamental and possess features that appear to
be ‘constructive’. One such approach has already been proposed in section 6.2.2 wherein we
were interested in assessing the composite reliability of ultra reliable items. This resulted in the
model of (6.6). In the subsections that follow, I revisit this construction and then propose a few
additional ones that satisfy our requirements of meaningfulness and computability. Associated
with the material of this section is the material in Appendix C on Borel’s paradox in reliability
assessment which interested readers may wish to visit.
Joint Priors for Highly Reliable and Related Units
There are many scenarios wherein it is reasonable to hold the belief that the pis are related
to each other but that the holder of such beliefs is unable to be specific about the nature of the
relationship. One way to capture such scenarios is via the notion of exchangeability of the pis,
which to some such as Howson and Urbach (1989) is philosophically objectionable. Putting aside
such objections we shall, in what follows, assume that the pis are exchangeable. Furthermore,
we shall also assume that the units are highly reliable, so that each pi is in the vicinity of 1.
The following two-stage construction, which parallels that given in section 6.2.2, yields a joint
prior for pis that encapsulates the features of similarity and high reliability.
To start off, suppose that given the parameters  and , the pis, henceforth pi if we suppress
, are independent and have a beta distribution on 1 with parameters  ∈01 and 1, so
that
1pi = 1 −pi−1
1 −

 < pi < 1
 is a threshold on pi.
For the second stage of our prior construction, we suppose that  itself has a beta distribution
on (0, 1) with parameters  + 1 and 1; i.e.
2 =  + 11 −
0 <  < 1
It can now be seen that pi has a beta distribution on (0,1) with parameters  and 2; i.e. for
i = 1   n
1pi =  + 1pi1 −pi−1
0 < pi < 1
To obtain the joint distribution of the pi’s, namely p1   pn, I need to bring into the
picture the smallest order statistic p1 = minp1   pn. Then it can be shown (cf. Chen and
Singpurwalla, 1996) that
p1   pn =
⎧
⎪⎨
⎪⎩
−n
n
i=1
1 −pi−1 ln1 −p1
if  = n −1−1
n
n
i=1
1 −pi−1 1−1−p11−n−1
1−n−1

otherwise
(10.13)
The attractiveness of this construction is that generating random samples from • above is
relatively straightforward. This matter will be taken up in section 10.3.5.
Joint Priors for Almost Identical Components
Many networks, especially those embedded in microcircuits, are made up of identical or almost
identical units. This means that the pi’s should be nearly the same. Thus any joint distribution

288
SURVIVABILITY OF CO-OPERATIVE, COMPETING AND VAGUE SYSTEMS
on the unit hypercube with its mass concentrated on the diagonal will capture the above feature.
One such distribution, proposed by de Finetti (1972), takes, for n = 2, the form
p1p212 ∝exp
	
−1
212p1 −p22


(10.14)
where 12 dictates the nature of the marginal distributions of pi, i = 12, and the correlation
between p1 and p2. Specifically, when 12 > 0, (10.14) is a truncated normal distribution on
p1 −p2, and its marginal densities have an inverted U-shape. For 12 < 0, the bivariate density
is cup-shaped and the marginals are U-shaped. Figures 4 and 5 of Lynn, Singpurwalla and Smith
(1998) illustrate these shapes. A large positive correlation between p1 and p2 can be accounted
for by letting 12 ↑+. With 12 < 0, the correlation between p1 and p2 is negative.
In the trivariate case, (10.14) enlarges as
p1p2p3• ∝exp
	
−1
2

12p1 −p22 + 13p1 −p32 + 23p2 −p32

with 1213 and 23 positive and large. Similarly, in the n-variate case we have
p1   pn• ∝exp
	
−1
2Q


(10.15)
where Q is a polynomial of degree two in p1   pn. The approximate multivariate normality
of the above form makes the generation of random samples from it relatively straightforward
and so is its updating in the presence of failure data (section 10.3.5).
Joint Priors when Components are Ranked by Reliability
There could be circumstances wherein the components of a system can be ranked by their
reliabilities. That is, it is possible to suppose that the components are labeled in such a way that
0 ≡p0 ≤p1 ≤p2 ≤··· ≤pn ≤pn+1 ≡1
When such is the case we may resort to the strategy discussed in section 9.3 on bioassay, and
arrive upon the ordered Dirichlet as a joint distribution for p1   pn. Specifically, given the
parameters i > 0, with n+1
i=1 i = 1, we would have
p1   pn =

n+1

i=1
i
n+1
i=1 pi −pi−1i−1
(10.16)
where  = 1   n+1. The essence of (10.16) is the assumption that pi −pi−1i =
1   n + 1, has a Dirichlet distribution.
It can be seen (cf. Mazzuchi and Soyer, 1993) that with ∗
i = i
j=1 ji = 1   n, the
marginal distribution of pi is a beta distribution on (0, 1) of the form
pi ∝p
∗
i −1
i
1 −pi1−∗
i −1
(10.17)
Since Epi• = ∗
i and Vpi• = ∗
i 1 −∗
i / + 1,  and  can be elicited via an elicitation
of the mean and the variance of each pi.
Generating samples from the p1   pn of (10.16) is straightforward because of
the constructive manner in which •• is developed (section 9.3.1). More about this is said

THE SURVIVABILITY OF COHERENT SYSTEMS
289
later in the section 10.3.5. Some other possible choices for p1   pn are given in Lynn,
Singpurwalla and Smith (1998). We now have at hand the necessary ingredients to assess system
survivability with or without the incorporation of failure data on the system and its components.
In the absence of data the arguments leading up to (10.12) provide a strategy. The details of how
survivability can be assessed when data are available is given below in section 10.3.5. However,
before doing so, it may be helpful to point out that there are circumstances wherein the scenario
of assessing system reliability via multivariate distributions on the unit hypercube could lead to
results that are paradoxical. This is because Borel’s paradox could come into play here, with
the consequence that we will end up with more than one answer for system survivability, all of
them correct. A detailed discussion of this matter is in Singpurwalla and Swift (2001); for the
sake of completeness, an overview is given in Appendix C.
Survivability Assessment Using Component and System Data
Perhaps one of the most commonly occurring practical problems in reliability and risk analysis is the
assessment of system survivability given life test data on the components of the system, and some-
times the system itself. This problem has a long history, and it arises frequently in contexts such as
thesafetyofnuclearpowerplants,weaponscertificationundertestbantreaties,assessingtechnolog-
ical risks of complex engineering systems, etc. Frequentist approaches for addressing this problem
have often resulted in technical difficulties whose nature has been alluded to by Crowder et al.
(1991). Bayesian approaches, proposed as early as the late 1970s (Mastran and Singpurwalla, 1978),
have been hampered by the computational difficulties that high-dimensional posterior distributions
pose. More important, the Bayesian methodology has not been based on the holistic architecture
of section 10.3.1 described here. A consequence of this limited perspective is that the need to use
one of the several multivariate distributions on the unit hypercube given in section 10.3.4 has not
been necessitated. In what follows, we build on the material of the previous sections to provide
a more complete answer to the problem of system survivability assessment. We start with some
preliminaries and introduce an overall plan and conclude with a consideration of some special cases.
Preliminaries and the Overall Plan
Suppose that failure data on the system and its components is of the form nx and
nixii=1,…,n, respectively. Here ni denotes the number of copies of the i-th component that
are tested for time , and xi the number of copies that survive the test; similarly with n and
x for the system as a whole. It is important to note that the nixi are not the result of a
postmortem of nx. Let d = n1x1   nnxn. If for any particular component there are
no test data available, then its corresponding ni and xi will be zero; similarly with n and x. With
d = 00   00 and n = 0x = 0, system survivability is given by the P of (10.12),
where P is the crude Monté Carlo integral of P.
When the elements of d are not all (0, 0), we need to update the p1   pn•s of section 10.3.4
via Bayes’ law to obtain p1   pn•d; this can be done analytically or by MCMC. The
specifics would depend on the form chosen for p1   pn•. Once p1   pn•d is
obtained we would generate M random samples from it to obtain, via the likes of (10.10), an updated
version of P, say Pd.
If in addition to the d discussed above, failure data in the form of nx is available on the
system itself, then Pd needs to be updated to Pdnx. This can be done numerically,
using Bayes’ law, as follows:
(a)
Let
pjdj = 1   M,
denote
M
vector
valued
samples
generated
from
p1   pn•d.
(b)
Let hpjd denote the quantity obtained by plugging pjd in hp1   pn
of (10.10); note that 0 ≤hpjd ≤1.

290
SURVIVABILITY OF CO-OPERATIVE, COMPETING AND VAGUE SYSTEMS
(c)
Let • denote a histogram of the hpjds, and let pk be the value of the
histogram at pk, where 0 ≤pk ≤1, and k = 1   H.
(d)
Update pk to ∗pk in the light of nk via Bayes’ law as
∗pk ∝pkx1 −pkn−xpkk = 1   H
(e)
Obtain Pdnx as
Pdnx =
H
k=1
pk∗pk
Upper and lower betting probabilities can be constructed following the strategy outlined in
the last part of section 10.3.3, save for the fact that the histogram frequencies will be prescribed
by ∗pk as obtained in (d) above.
This completes our discussion on how to assess system survivability using failure data on
the system and its components via a Bayesian approach. The key to implementing the plan
proposed here is an ability to generate random vector valued samples from •, the joint
distributions of section 10.3.4 on unit hypercubes, or its updated version. Strategies for doing
this are discussed next.
Generating Random Samples from Distributions on Unit Hypercubes
We start with a consideration of the case of highly reliable and related units discussed in
section 10.3.4. It resulted in the joint distribution p1   pn of (10.13) with  known.
To generate samples from p1   pn we generate samples from p1   pn and
ignore the values of  so generated. For doing so, we use the Gibbs sampling algorithm
discussed in Appendix A. This requires that we have a knowledge of the full conditionals
p1   pn and p1   pn. The former is given as
p1   pn =
n
i=11pi
=
n
i=1
1 −pi−1
1 −

 < pi < 1
and since  is a lower threshold, the latter is simply
p1   pn = p1
which by Bayes’ law (details omitted) is given as
p1 =
⎧
⎪⎪⎨
⎪⎪⎩
−
1
1 −ln1 −p1
if  = n −1−1
1 −n −1

1 −1 −p11−n−1
1 −n−1 
otherwise
When failure data d are available, we generate samples from p1   pnd, and this
exercise follows the lines given above save for the fact that p1   pn gets replaced by
p1   pnd where
p1   pnd ∝
n
i=1
pni−xi
i
1 −pi+xi−1

MACHINE LEARNING METHODS IN SURVIVABILITY ASSESSMENT
291
for  < pi < 1. Also, p1   pnd is simply p1 since d has no effect on 
once p1 is assumed known.
Moving on to the case of de Finetti’s multivariate distribution that was deemed suitable for
components that are almost identical, we first note that this distribution possesses nice closure
properties. Specifically, under d with N = n1 + ··· + nn large, (10.15) becomes
p1   pn•d ∝exp
	
−1
2Q + NR


(10.18)
where R = n
i=1pi −pi/i	2, with pi = xi/ni and i = pi1 −pi/niN1/2i = 1   n. The
approximate multivariate normal form of (10.18) makes the task of generating samples from
p1   pn•d straightforward.
In the case of an ordered Dirichlet suitable for components ranked by reliability, the construc-
tive nature of (10.16) makes the generation of random samples from it relatively straightforward.
Specifically, we start by generating an observation, say p1
1, from p1 given by (10.17)
using the techniques prescribed in Atkinson (1979) for random number generation from a beta
distribution. Then, given p1
1, we generate an observation, say p1
2, from a shifted beta distribution
on p1
11, and so on, until we generate n observations p1
1p1
2   p1
n. We repeat this cycle M
times.
When failure data in the form of d are available, we need to generate samples from
p1   pnd where
p1   pnd
n
i=1
pxi
i 1 −pini−xip1   pn
Generating samples from p1   pnd turns out to be an onerous task, the details of
which are given in Appendix B of Lynn, Singpurwalla and Smith (1998). The approach of these
authors is based on the adaptation of an ingenious strategy proposed by Gelfand and Kuo (1991)
in the context of Bayesian biassay.
10.4
MACHINE LEARNING METHODS IN SURVIVABILITY
ASSESSMENT
By ‘machine learning methods’ we have in mind computationally intensive methods that appear
to bypass probabilistic modeling and simulation requirements of sections 10.2 and 10.3, respec-
tively. Recall that to analytically assess system survivability, we are required to prescribe three
essentials: the structure function of the system; the uncertainties associated with the components’
reliabilities; and probability models that encapsulate interdependencies between the component
lifetimes. With large and complex systems, each of these becomes a onerous task. Furthermore,
systems in actual use almost always experience maintenance (i.e. repairs and replacements), the
effect of which is an enhancement of system survivability. Analytical approaches for the treat-
ment of replacement and repair have not been discussed by me. Results from such approaches
generally tend to be qualitative or at best asymptotic (i.e. long-run averages). Machine learning
methods, like ‘neural nets’, circumvent the caveats and requirements mentioned above, and offer
a user a viable alternative for assessing system survivability. As an aside, the useful role that
machine learning methods can also play in statistical practice has recently been articulated by
Brieman (2001) in a lively discussion article.
In what follows, our focus will be on neural net technology. In using this technology, one
substitutes modeling and analysis with observed data. Thus one’s ability to use neural nets

292
SURVIVABILITY OF CO-OPERATIVE, COMPETING AND VAGUE SYSTEMS
depends on the availability of data. To gather such data, one needs to monitor a system for a
modest period of time and this could be a drawback. In principle, survivability assessment using
machine learning is only retrospectively feasible; i.e. for systems that are on and running. Thus,
neural net-based methods cannot be used for systems that are under design and development, or
systems that have yet to experience use. With machine learning one adopts an attitude that is
akin to that taken by statisticians doing ‘data analysis’. Here one tries to extract information out
of data using specialized graphical and computational techniques, but without the benefit of an
underlying stochastic model.
In what follows, I shall give an overview of the general architecture of a single-phased neural
net with one or more hidden layers. For system survivability assessment we need a two-phased
neural net. Once ‘trained’ (section 10.4.1) the first phase is designed to generate the binary
states that a system’s components will take in the future. The second phase uses as an input the
output of the first phase, and generates the state of the system. In essence, the second phase of
the neural net is necessitated by the feature that specifying the structure function of large and
complex systems is too onerous a task for one to embark upon.
10.4.1
An Overview of the Neural Net Methodology
An artificial neural net (ANN) is a construct that is modeled after the human brain. Its building
block is an idealized representation of a single nerve cell called the ‘neuron’, or in neural net
terminology, a ‘computational unit’. McCulloch and Pitts (1943) conceptualized the functioning
of a neuron via the following construct.
A neuron receives as inputs x1   xp from p other neurons; each xi is a binary, taking the
values +1 or −1. The p inputs get transmitted to the neuron by links, called ‘synapses’. The
neuron transforms its p inputs to a binary output y, with y = +1 or −1 via the relationship
y =
⎧
⎨
⎩
+1
if
p
i=1
wixi + w0 ≥0
−1
otherwise
the constants w1   wp are called the ‘synaptic weights’, and the constant w0 is called the
‘bias’. The output y now becomes an input to another neuron. The synaptic weights are the
unknowns of the set-up, and the neural net methodology is centered around determining the wi’s
via an iterative process that matches a neuron’s output with an actual (observed) output. The
synaptic weights encapsulate the importance of the input that gets passed from one neuron to the
next. The iterative process, also known as the ‘training process’, is an empirical exercise about
which much has been written and for which there is available an abundance of software; see
for example, Lefevbre and Principe (1999). My aim here is not to dwell into the details of the
training process; for this, see for example, the book by Haykin (1999). Rather, our purpose is
to highlight the essence of an approach that is able to address an important practical problem in
survival analysis. But before doing so, some additional details about the architecture of a neural
net may be useful to know; these are given below.
In a multilayer net, the nodes are organized into layers; Figure 10.6 shows a neural net with
a single layer – called the ‘hidden layer’. In a feedforward net all the nodes send their output
only to those nodes in the next layer, and not vice versa. In a fully connected net, every node is
connected to each node in its adjacent layer. Figure 10.6 portrays a fully connected, feedforward
net with one intermediate layer. In designing a neural net for any particular application, the
key issues that need to be addressed are: the nature of interconnectivity (fully connected or
otherwise), the direction of connectivity (feedforward or feedback) and the number of hidden
layers. Computer scientists grapple with these issues, their aim being the approximation of a
well-behaved function via a neural net methodology; see, for example, Funahashi (1989). Like

MACHINE LEARNING METHODS IN SURVIVABILITY ASSESSMENT
293
Input layer
Output layer
Hidden layer
Figure 10.6
A fully connected feedforward net with one hidden layer.
the matter of training a neural net, a discussion on designing a neural net is beyond the scope
of what we have in mind here, namely, how to use the neural net technology for assessing
system survivability. Designing an efficient neural net, and training it for the purpose of system
reliability assessment, is an open problem that warrants careful attention.
10.4.2
A Two-phased Neural Net for System Survivability
A two-phased neural net architecture is one wherein two separate neural nets are linked together
in tandem so that the output of one net becomes an input to the second. Each net is designed to
perform a different function. In this context, the first-phase net (henceforth ANN1) is designed
to generate the binary states of the components of a multi-component system. The second-
phase net (henceforth ANN2) takes as its input the output of ANN1 and generates the state
of the system. To generate training data for ANN1 and ANN2, one observes a system of
interest for a moderate amount of time, recording at some equally spaced time intervals the
states of the components of the system and also the state of the system. For purposes of
discussion, consider an n component system that is monitored at k equispaced time points
0 < 1 < 2 < ··· < i < ··· < k. Let Xi = X1i   Xni and Xi denote the states of
the components and the system, respectively at time i, for i = 1   k, with X0 = 1   1
and X0 = 1. That is, at time 0 all the n components of the system and the system itself are
are supposed to be in the functioning state. The effects of component unreliabilities and their
uncertainties, interdependence, and maintenance will be encapsulated in the manner in which
Xis change over i. The purpose ANN1 is to capture this change by learning about it; i.e.
ANN1 trains itself by successively using X0X1   Xk as data. Once trained, ANN1
is able to predict Xk+jj = 12   , the states of the components at the equispaced future
times k+1k+2    and so on. By the same token, ANN2 trains itself by learning about the
relationship between the Xi and Xi, i = 1   k, and is then able to predict Xk+j,
using Xk+j, j = 12   . Knowing the Xk+j, j = 12   J (say), we can assess system
survivability via its ‘availability’; i.e. the proportion of times out of J that Xk+j takes the
value one.
Whereas the design of ANN1 and its training are two major issues that need to be carefully
addressed, one way to proceed would be to assume that ANN1 is a multi-layered, fully connected,
feedforward net which generates its first set of synaptic weights w1 using X0 = 1   1
as input data and X1 as observed data. The synaptic weights w1 get updated to w2 with

294
SURVIVABILITY OF CO-OPERATIVE, COMPETING AND VAGUE SYSTEMS
X1 now serving as input data and X2 as observed data, and so on until we obtain wk.
The wk are then used to obtain Xk+1 as a prediction of Xk+1 via Xk as input to
ANN1. Similarly, Xk+2 is obtained as prediction of Xk+2 via ANN1 with Xk as input,
and so on.
Analogously, we may suppose that ANN2 is a multi-layered, fully connected, feedforward
neural net which starts off with X0 = 1 as input and X1 as data and successively uses
Xi and Xi+1, i = 1   k −1, as input and data, respectively, to obtain Xk+j as a
predictor of Xk+j, j = 12   Here again, to obtain Xk+2 I use Xk+1 as an input.
Once the Xk+jj = 12   J (say) are obtained the survivability of the system over the
time period

k+1k+J

is the proportion of times out of J that Xk+j, j = 12   J
takes the value 1. This completes our discussion on using machine learning for survivability
assessment.
10.5
RELIABILITY ALLOCATION: OPTIMAL SYSTEM DESIGN
A key aspect of system design is the attainment of high survivability. For networks and systems
with several inter-connected components, high survivability is achieved in one of two ways: by
introducing redundant components, or by increasing the survivability of each component (i.e.
strengthening the components). Either strategy increases costs and thus one feature of engineer-
ing design is to increase survivability subject to cost constraints. This tantamounts to making
decisions in the face of uncertainty (or risk). When survivability is enhanced by redundancy,
the decision problem boils down to determining the location of redundancies and the number
of redundant components to install at each location. This class of problems has been studied
under the label ‘redundancy allocation’, about which much has been written; see, for example,
Barlow and Proschan (1975, p. 209) and the references therein, or the recent overview by Kuo
and Prasad (2000). In this section, we consider the issue of enhancing survivability by strength-
ening. The problem boils down to a determination of which components to strengthen and by
how much. This class of problems is labeled ‘reliability allocation’ or ‘reliability apportionment’
about which there has been some, but not much, of a discourse. As of this writing the most
recent addition to this literature is a paper by Falk, Singpurwalla and Vladimirsky (2006) upon
which the material that follows is based. Our purpose here is not to dwell on the optimization
details contained in the above paper. Rather, our focus is on the decision theoretic set-up that
the work entails, and a roadmap to the key results obtained.
Because enhanced reliability is a proxy for enhanced survivability, our discussion will be
centered on reliability and its apportionment. Thus in what follows, we use the material of
section 10.2.1 as an anchor, and follow the notation therein. Specifically, pi will denote the
reliability of the i-th component, i = 1   n, and p the reliability of the system, for some
specified mission time  > 0. Under the assumption of independence, p will be a function, say
h, of only the pi’s; i.e. p =hp, where p=p1   pn. With dependence, p will be a function
of p as well as some dependency parameters; we denote this as hp•, where • stands for the
dependency parameters.
10.5.1
The Decision Theoretic Formulation
Our aim here is to determine an optimum p for any specified system architecture  and a mission
time . Associated with each pipi ∈01	, is a cost function cipii = 1   n. This is the
cost of producing a component i, whose reliability for mission time  is pi. It is reasonable to
suppose that cipi is non-decreasing in pi, with ci0 = 0 and ci1 = . Let cp = n
i=1 cipi
be the cost associated with building a system whose component reliabilities are pii = 1   n;
we have assumed that the costs are additive, though it need not be so, and most likely it is not so.

RELIABILITY ALLOCATION: OPTIMAL SYSTEM DESIGN
295
Suppose that at time X=1, where X=X1   Xn with Xi =10, if the i-th component
is surviving (failed) at . With X = 10, the system survives (fails) by time . Suppose that
when X = 10, the builder/operator of the system receives a monetary reward (penalty) of
+−, where + and −are both non-negative constants. Then with X = 1, the utility to
the builder/operator is + −cp; similarly, with X = 0, the utility is −−+ cp	. It is of
course possible that + < cp so that + −cp	 < 0; that is, the system is not profitable to
operate even when it is perfectly functional.
With the above in place, the normative approach to deciding upon what p should be, boils
down to finding that p with maximizes the total expected utility Up, where
Up = hp•+ −cp	 −1 −hp•	−+ cp	
(10.19)
and 0≤pi <1 (section 2.8.2). With Up being a function of +−, and cp, we are considering
the utility of money and assuming that it is linear. Several plausible forms for the cost function
cp have been proposed in the literature. Some examples are: cp = alogp/b + 1, where
ab > 0 are constants – considered by Lloyd and Lipow (1962); cp = apw, for 0 < w < 1 and
a > 0, a constant – considered by Tillman et al. (1970); cp = aexpb/1 −p – considered
by Misra and Ljubojevic (1973); cp = bp/1 −p	a – considered by Majumdar, Pal and
Chaudhuri (1976), and cp = −alog1 −p with p ∈01 considered by Fratta and Montanari
(1976). Dale and Winterbottom (1986) have articulated several desirable features that cost
functions should possess, and of the cost functions mentioned above, the one by Fratta and
Montanari (1976) possesses these features. Thus, in what follows, we take cipi = −ai log1 −
pi, for pi ∈01i = 1   n. With this choice, the optimization problem of (10.19) simplifies
as maximizing
Up = hp• −−+ cp	
(10.20)
with respect to p, under the constraint that 0 ≤pi < 1i = 1   n, with 
def= + + −	, and
cp=n
i=1 −ai log1−pi; ai >0 is specified for all i. Since −is a specified constant, (10.20)
written out explicitly boils down to finding p with 0 ≤pi < 1i = 1   n, such that
Up =
n
i=1
ai log1 −pi + hp•
(10.21)
is maximized; recall that cp = −n
i=1 ai log1 −pi.
General Solution to the Decision Problem
Falk, Singpurwalla and Vladimirsky (2006) in their Theorem 4.1 show that if hp• is continuous
on p  0 ≤pi < 1i = 1   n, and if there exists an M > 0 such that hp• ≥M for all p with
0 ≤p < 1, then a solution to the optimization problem of (10.21) does exist. Furthermore, they
also show, via their Theorem 4.2, that when any of the inequalities
pi ≤max

01 −ai



i = 1   n
(10.22)
get violated, the expected utility of the system (so constructed) is not maximized. Thus the
inequality of (10.22) provides, in the case of any coherent system, an upper bound on the
component reliabilities. This upper bound is crude; to obtain sharper results we consider, in the
subsection below, specific forms for hp•.

296
SURVIVABILITY OF CO-OPERATIVE, COMPETING AND VAGUE SYSTEMS
10.5.2
Reliability Apportionment for Series Systems
The simplest special case to consider is that of a series system with independent lifelengths. Here
hp• = hp = n
i=1 pi, so that given  > 0 and the constants ai > 0i = 1   n, we need to
find a p such that
Up =
n
i=1
ai log1 −pi + 
n
i=1
pi
(10.23)
gets maximized subject to the constraints 0 ≤pi < 1i = 1   n.
Falk, Singpurwalla and Vladimirsky (2006) show, via their Theorem 5.1, that the optimization
problem of (10.23) always has a solution, say p∗. Either all the components of p∗are positive, or all
are zero. When p∗= p∗
1   p∗
n > 0 = 0   0, the necessary conditions for the optimality of
(10.23) boil down to finding the p∗
i i = 1   n, such that
P = FP
(10.24)
where P = n
i=1 p∗
i , and FP = n
i=1 P/ai + P.
Clearly FP∈01 and since P ∈01, the function F maps [0,1) into [0,1). Thus in solving
(10.24) we are seeking a fixed point, say P of F. Once P is found, we can find p∗
i i = 1   n,
via
p∗
i =
P
ai + P

Since P is a solution to (10.24), namely
P =
n
i=1
P
ai + P
P is a root of the following polynomial in P of degree n,
n
i=1
ai + P −nPn−1 = 0
(10.25)
This polynomial can have at most two roots or no roots. In the latter case, we set each p∗
i =
0i = 1   n. When (10.25) has two roots, it is the larger root that leads to the maximization
of (10.23). The roots, when they exist, will be positive; the detailed arguments that justify the
above claims are given in Falk, Singpurwalla and Vladimirsky (2006).
Thus to summarize, in the case of a series system with independent component lifelengths and
for which cpi= −n
i=1 ai log1 −pi with ai > 0 specified for all i, p∗
i , the optimally allocated
reliability of component i, i = 1   n, is given by
p∗
i =
P
ai + P

(10.26)
where P is a solution to the polynomial in P
n
i=1
ai + P −nPn−1 = 0

RELIABILITY ALLOCATION: OPTIMAL SYSTEM DESIGN
297
If the polynomial above has no roots then we set each p∗
i = 0i = 1   n. If the polynomial
has two roots, we choose the larger of the two roots. If the polynomial has positive roots, but if
the roots yield p∗
i ’s which when plugged into the expected utility Up result in negative values
of Up, we again set p∗= 0.
When n is small, say 2 or 3, the polynomial of (10.25) can be analytically solved without much
difficulty. When n is large we may choose to numerically solve for the fixed point of P =FP using
an iterative approach. A proof of convergence of this approach, and details about its implementation
aregiveninsection5.1andAppendixBofFalk,SingpurwallaandVladimirsky(2006).Theexamples
below illustrate the workings of the procedure summarized above.
Example 10.1.
Suppose that n = 2 with a1 = 1a2 = 2, and  = 3. The polynomial equation
is 9P2 + 2 = 0; it has no real solution. Thus we set p∗
1 = p∗
2 = 0. That is, we do not build and
operate the series system.
Example 10.2.
Suppose that in Example 10.1 above,  = 6. Then the solution to the ensuing
polynomial 36P2 −18P + 2 = 0 is P1 = 1/3 and P2 = 1/6. These roots yield, via (10.26),
p∗
1 = 2/3p∗
2 = 1/2 and p∗
1 = 1/2p∗
2 = 1/3 as choices for p1 and p2. However, these choices
when plugged into (10.23) for Up yield −0
4849 and −0
5041 as expected utilities. Since the
expected utilities are negative, we again must set p∗
1 = p∗
2 = 0, and not build the system.
Example 10.3.
Suppose now that in Examples 10.1 and 10.2 above,  = 10. Then the ensuing
polynomial equation 100P2 −70P + 2 = 0 has P1 = 2
9844 × 10−2 and P2 = 0
67106 as its roots.
These roots yield p∗
1 = 0
22985p∗
2 = 0
12984 and p∗
1 = 0
87016p∗
2 = 0
77016 as a pair of
choices for p1 and p2. Plugging this pair into the expression for Up yields −0
24089 and 1.7194
as values for the expected utility, respectively. We therefore choose the pair p∗
1 = 0
87016p∗
2 =
0
77016 as an optimal reliability allocation.
10.5.3
Reliability Apportionment for Parallel Redundant Systems
The case of a parallel system with independent lifelengths is most easily described by considering
the dual of the normative formulation given in section 10.5.1. Specifically, let qi = 1 −pii =
1   n, and let hq = 1 −hp, where q = q1   qn. Note that hq is the unreliability
of the system, which in the case of a parallel-redundant system is hq = n
i=1 qi. Following
arguments that parallel those leading us to (10.19) we can see that the total expected utility,
written in terms of q, is
Uq = 1 −hq	+ −cq	 −hq−+ cq	
where ciqi = ci1 −pi and cq = n
i=1 ciqi. Setting ciqi = −ai logqii = 1   n, with
ai > 0hq = n
i=1 qi and as before  = + + −	, the ensuing optimization problem boils
down to finding q1   qn that maximize
Uq = −
n
i=1
qi +
n
i=1
ai logqi
(10.27)
subject to the constraint that 0 < qi ≤1.
The solution to this problem is encapsulated in Theorem 5.4 of Falk, Singpurwalla and
Vladimirsky (2006), which says that if aj = minaii = 1   n is unique, then:
(i)
When  ≤aj, the optimal allocation would be to set p∗= 0, i.e. the parallel redundant
system should not be built and operated.

298
SURVIVABILITY OF CO-OPERATIVE, COMPETING AND VAGUE SYSTEMS
(ii)
When  > ajp∗
j = 1 −aj/ and p∗
i = 0 for all i ̸= j; in this case the expected utility is
aj logaj/ −aj + +.
The essential import of (ii) above is that the parallel redundant system of n components (with
independent lifelengths) should be collapsed to a single component system, namely, the compo-
nent that is the least expensive to build, and the allocated reliability of this component should
be 1 −aj/. That is, it is only the cheapest to build components that should be strengthened –
under the cost structure assumed by us here.
10.5.4
Apportioning Node Reliabilities in Networks
In the case of a network, such as say that of Figure 10.2, hp takes a cumbersome form,
even when the node lifetimes are assumed independent (equation (10.6)). As a consequence, an
analytical solution to the optimization problem of (10.21) becomes difficult. One way out of this
difficulty would be to consider optimization algorithms, such as the ‘branch and bound’ of Falk
and Soland (1969). The use of this algorithm for the optimum allocation of node reliability for the
network of Figure 10.2 is described in Falk, Singpurwalla and Vladimirsky (2006). The essential
idea here is to set each pi as pi = 1 −exp−wi for some wi ≥0i = 1   n, and to consider
the resulting expression for Up in terms of the wi’s. This expression turns out to be the sum of
exponential terms upon which the branch and bound algorithm with linear constraints is invoked;
the specifics are in section 5.3 of Falk, Singpurwalla and Vladimirsky (2006). With a1   a5
chosen as 3,2,2,3 and 2, respectively, and  = 30
15, the optimum allocation of node reliabilities
turns out to be p∗
1 = 0
892p∗
2 = 0
928, and p∗
3 = p∗
4 = p∗
5 = 0. This tantamounts to allocating all
the resources to only one min. path set of the network, namely the set (1,2). Alternatively put,
the five-node network gets replaced by a two-node series system. This example illustrates how
the reliability allocation problem facilitates system design.
10.5.5
Apportioning Reliability Under Interdependence
For systems with interdependent lifetimes an optimal allocation of component reliability requires
that one be willing to specify the dependency parameter. Thus, for example, in the case of a
two component series system with dependent lifetimes whose stochastic behavior is described
by the bivariate exponential of Marshall and Olkin (1967) (section 4.7.4) – it can be seen that
the reliability of the system (the hp• of section 10.5.1) can be written as
R5 = R1R2exp12
where Ri is the marginal reliability of the i-th component, i = 12,  is the mission time, and
12 is the dependency parameter. With 12 specified, we may replace the n
i=1 pi of (10.23) with
exp122
i=1 Ri, and then invoke the material of section 10.5.2 to obtain optimum values
for Rii = 12. With n > 2 components in series, we need to specify several dependency
parameters and follow the above line of reasoning. However, now we may have to use the fixed
point iterative approach of section 10.5.2 to solve the ensuing optimization problem.
Because the model for interdependency prescribed by the BVE of Marshall and Olkin (1967)
is not parsimonious in the number of dependency parameters, one may prefer to work with
alternate, more parsimonious, models for dependency. One such possibility is the bivariate Pareto
of Lindley and Singpurwalla (1986) (section 4.7.5) for which it can be seen that for a series
system of n components, the reliability for a mission time  can be written as
R5 =

n
i=1
Ri−1/a+1 + n −1
−a+1

(10.28)

THE UTILITY OF RELIABILITY: OPTIMUM SYSTEM SELECTION
299
where a > −1 is a dependency parameter that characterizes the nature of the environment in
which the system operates, and
Ri =
	
b
b + i

a+1

(10.29)
is the marginal reliability of the i-th component, i = 1   n.
Replacing the n
i=1 pi term of (10.23) by R5 given above, and the pi’s in the terms
n
i=1 ai ln1 −pi by the Ris given above, it can be shown (Falk, Singpurwalla and
Vladimirsky, 2006) that solving the ensuing expected utility maximization problem boils down
to finding the fixed points of P = F ∗P, where
F ∗P =

n
i=1

G−1
i P
−1/w −n + 1
−w

(10.30)
here w = a + 1 and P is a function of Ri, say P = GiRi, i = 1   n.
With w = a + 1 specified, I may, via the fixed points of P = F ∗P, find the optimum values
of i and b, i = 1   n. These tantamount to finding the optimal values Ri – the marginal
component reliabilities – i = 1   n, under an operating environment characterized by w.
Denote these optimal values by Rw
i
, i = 1   n. The Rw
i
s when plugged into the
expression
n
i=1
ai log

1 −Rw
i


+ 

n
i=1

Rw
i

−1/w
+ n −1
−w

(10.31)
give us the expected utility yielded by Rw
i
s for the specified w. Repeating the above exercise
for different values of w enables us to chose that w, say w∗, for which the expected utility of
(10.31) is a maximum.
Thus the schemata described above enables us to not only allocate component reliabilities
Rw∗
i , i=1   n, in an optimal manner, but also determine an optimal operating environment
for the system. In Falk, Singpurwalla and Vladimirsky (2006), this schemata is illustrated via
a numerical example that entails a range of values of w. The general observation therein, is
that the assumption of independence does not result in a cost-effective allocation of component
reliabilities for series systems operating in a common environment. Accounting for positive
dependence leads us to build systems that are cost effective.
Thus to conclude this section, one may claim that the principle of maximization of expected
utility when invoked in the context of designing systems for maximum survivability, compels
one to incorporate, when appropriate, interdependence. It also enables one to simplify design
by eliminating components whose allocated reliability turns out to be zero. In the context of
networks this latter feature is known as ‘network collapsibility’.
10.6
THE UTILITY OF RELIABILITY: OPTIMUM SYSTEM SELECTION
This section can be viewed as a companion to section 10.5 because it to pertains to decision
making in system reliability considerations. However, its scope is more general. In section 10.5
we were interested in optimal system design, an issue that is relevant to designers and makers
of systems. Here we consider the matter of optimally choosing one among several competing
designs, a matter that is of concern to system procurers or those who select a particular system

300
SURVIVABILITY OF CO-OPERATIVE, COMPETING AND VAGUE SYSTEMS
to perform a specified task. In these latter circumstances, what matters is the utility of reliability,
a notion that is a topic of this section. But first some background and perspective.
Recall, that in section 10.5, utilities were simply costs and that the decision variables were the
component reliabilities. In actuality, such decisions cannot be executed with precision, because
reliabilities are not tangible quantities; i.e. they cannot be directly observed. The material of
section 10.5 therefore suffers from a drawback, because it can merely provide guidance on the
proportion in which resources can be allocated. In real-life decision making, actions have to
be executable, and utilities must also incorporate behavioristic considerations. In the context of
reliability, behavioristic considerations generally manifest themselves in the form of risk aversion.
For example, many individuals prefer driving long distances to flying, and many societies choose
to avoid the generation of nuclear power. In such scenarios cost alone is not the driving criterion.
What also matters here is the subjectivistic notion of utility as seen by behavioral scientists,
economists, and preference theorists. In the context of system procurement, a question may also
arise as to how much more should be paid for a unit improvement in reliability.
To address issues of the kind mentioned above, we need to do two things:
(a)
Formally introduce the notion of the utility of reliability and specify its functional form; and
(b)
Embed this notion within the broader framework of decision under uncertainty as is
described in section 1.4 and Figure 1.1.
We are able to come to terms with (b) because of our claim (section 4.4) that ‘reliability is
a chance’ and that ‘probability is our uncertainty about this chance’. Without this distinction
between chance and probability it is not possible to prescribe a coherent decision-making proce-
dure that entails the utility of reliability. The scenario described below, in section 10.6.1, clarifies
the schemata for doing the above.
10.6.1
Decision-making for System Selection
The following archetypal problem arises in the context of system procurement and selection.
A decision maker  needs to acquire a system that is able to perform a certain task. The task
takes  time units to be performed; i.e.  is the mission time, assumed known and fixed.  has a
choice between (say) two systems S1 and S2. Let d1d2 denote ’s action when system S1 S2 is
chosen (Figure 10.7). Let T1T2 denote the time to failure of S1S2, and R1  and R2  their
respective reliabilities (or chances) for mission time . Finally, let  Ri , i = 12, denote a
probability density at Ri , that encapsulates ’s uncertainty about Ri , 0 < Ri  < 1.
As an example of the above, suppose that Ti has an exponential distribution with scale
parameter i >0, i=12, where i is unknown. Then Ri =exp−i, and if ’s uncertainty
about i is described by a gamma distribution with scale parameter i and shape parameter i,
’s actions
1
R1(τ)
π(R1(τ))
U(R1(τ))
d1
d2
2
R2(τ)
π(R2(τ))
U(R2(τ))
Figure 10.7
Decision tree for system selection.

THE UTILITY OF RELIABILITY: OPTIMUM SYSTEM SELECTION
301
then ’s uncertainty about Ri  will be described by a distribution whose probability density
at Ri  will be of the form (cf. equation (5.12))
Ri i/−1
 i
	i


i 	
log
	
1
Ri 


i−1

this then is the essence of ’s  Ri , i=12. ’s decision tree for choosing between S1 and
S2 is given in Figure 10.7. For  to invoke the principle of maximization of expected utility,
one additional ingredient is required, namely, U Ri , the utility of Ri , i = 12. Some
plausible forms that U Ri  can have will be discussed in section 10.6.2. Ignoring (for now)
the costs of building S1 and S2,  will take action d1, i.e. choose system S1, if
U R1  · 1 ≥U R2  · 2
(10.32)
otherwise  will take action d2. The crux of the problem therefore is a meaningful specification
of URi , i = 12. In writing out the above inequalities we have taken the point of view
that when decision di is chosen, Ri  is the unknown state of nature, and that  Ri 
is ’s uncertainty about Ri , i = 12. This then is the basis of our claim that without the
distinction between reliability as a chance, and that probability as our uncertainty about chance,
it is not possible to formally specify a paradigm for decision-making that involves the utility of
reliability.
10.6.2
The Utility of Reliability
In principle the utilities of any decision maker have to be assessed via gambles of the kind
described in utility theory (section 2.8.1). Furthermore, their coherence has to be ensured using
methods such as those prescribed by Novick and Lindley (1979). This could be laborious, time
consuming, and a one of a kind exercise from which general strategies may be hard to deduce.
However, in some cases it may be meaningful to propose some prototype forms for the utility
function, and the utility of reliability is one such instance. Another scenario is the utility of
money which is often assumed to be concave, such as a logarithmic function with an upper
bound. We need only limit our discussion here to bounded utilities.
With the above as a preamble, consider the case of a fixed mission time , for which the
reliability of a unit is R, with 0 ≤R ≤1. Let U R denote the utility of R; clearly,
U R = 0 = 0 and set U R = 1 = 1. Also, U R must be non-decreasing in R;
the bigger the reliability, the more valuable the unit. Our conjecture is that for large mission
times, U R will be a concave function of R; U R will be convex for small mission
times. With that in mind we assume that for some tuning parameter  ∈0,
U R = R/ 
(10.33)
When  > <, the utility function is convex (concave) in R; it is linear when  = . Thus
once a mission time is specified,  encapsulates a decision maker’s attitude towards risk. If
the decision maker is risk neutral then  = ; if the decision maker is risk averse (prone) then
 > <. In general, when it comes to matters of reliability, most individuals tend to be risk
averse and so their utilities for reliability are most likely to be convex (Figure 10.8).
Incorporating Disutilities Due to Costs
When making decisions about choosing between competing systems, as was described in
section 10.6.1, one also needs to incorporate into one’s analyses, the cost of building each system.

302
SURVIVABILITY OF CO-OPERATIVE, COMPETING AND VAGUE SYSTEMS
β = τ (Risk neutral)
β > τ
β < τ
U(R(τ))
Reliability, R(τ)
Utility
1
0
1
Risk proneness
Risk aversion
Figure 10.8
Concave and convex utilities of reliability.
Such costs tantamount to a disutuility to a decision maker; their effect is to lower the utility.
Generally, the more reliable a system, the higher its costs and thus the greater its disutility. In
making decisions about system choice, the decision maker trades off between the rewards of
higher value versus the penalty of higher costs. To do so, we first need to propose a disutility
function. The disutility function should map on the same scale as the utility function so that the
two can be combined by addition.
Suppose that C R denotes the cost of producing a unit whose reliability for mission time
 is R. It is reasonable to suppose that C R increases in R, taking the value 0 when
R = 0 and infinity when R goes to 1; it certainty is prohibitively expensive to have! The
above features are encapsulated by the function
C R = R
1 −R
(10.34)
where the scaling constant  ∈0	 is chosen so that the cost of manufacturing to R is
meaningfully reflected. Figure 10.9 illustrates the behavior of C R for  = 1.
Now, it is well accepted that for most individuals the utility of money is concave; indeed
the logarithmic function is often assumed. With that in mind we may suppose that the disutility
inflicted on the decision maker due to C R, the cost of producing to R, is of the
logarithmic form
−U C R = log1 + CR
However this form is unbounded for R = 1. An alternative functional form that retains the
concavity of the disutility of R, and is bounded above by one, would be
−U C R = 1 −exp
	
−R
1 −R


(10.35)
Combining the utility and the disutility of R, (10.33) and (10.35), we have the net utility
provided by a unit that has been produced to deliver R as
U R = R/ −
	
1 −exp
	
−R
1 −R



(10.36)

MULTI-STATE AND VAGUE STOCHASTIC SYSTEMS
303
0
0.25
0.5
0.75
1
Reliability, R(τ)
C(R(τ))
Cost
0.33
1
3
Figure 10.9
Cost of producing to R.
In the context of scenario of section 10.6.1,  will replace U Ri  with U Ri  in (10.32).
That is, system S1 will be chosen if
U R1  · 1 ≥U R2  · 2
(10.37)
otherwise system S2 will be chosen.  will chose neither system if both U R1  and U R2 
turn out to be zero or negative. In such cases the cost of acquisition does not justify the value
received.
10.7
MULTI-STATE AND VAGUE STOCHASTIC SYSTEMS
The elements of the theory of coherent systems have been overviewed by us in section 10.2. This
theory has been driven by two assertions, both limiting. The first is that a unit (i.e. the system
or its components) can exist at any point in time t, in one of only two possible states: failed or
functioning, good or bad, etc. With only two states to consider, the calculus of the theory can be
based on binary logic. In actuality, units can exist in more than two states, such as functioning,
degraded, or failed. More generally, a system with n components can exist in n + 1 states if the
state of the system at t is defined as the number of its surviving components. Systems that can
exist in more than two states are called multi-state systems (cf. Natvig, 1982). They have been
studied by several authors, who in one way or other have continued to lean on binary logic for
their study. El-Neweihi and Proschan (1984) give a survey. Thus, in effect, attempts to alleviate
the first limitation have been made, albeit in a manner that is not radically novel.
The second limitation of coherent structure theory is that at any time t, each item can exist
in only one of the two states. This assertion is not problematic when the states can be sharply
delineated, such as functioning or failed, or the number of surviving components at t. When the
states cannot be precisely delineated, one is unable to classify the state of an item. When such
is the case, it is possible for one to declare that an item simultaneously exists in more than one
state. Thus, for example, since it is difficult to delineate the boundary between good and bad, or
the boundary between degraded and bad, it is possible to declare that an item is good and bad,
or degraded and bad, at the same time. This matter calls for more discussion, but in general,

304
SURVIVABILITY OF CO-OPERATIVE, COMPETING AND VAGUE SYSTEMS
whenever the subsets of a set of states are difficult to define, classifying the state of an item
becomes an issue. Sets whose subsets cannot be sharply defined are called vague, and vague
systems are those whose state space is vague.
The aim of this section is to propose a calculus for the study of multi-state and vague systems.
Our view is that many-valued logic provides a common platform for doing the above (Sellers and
Singpurwalla, 2006) for the multi-state system scenario. But before dwelling into many-valued
logic, it is desirable to articulate more on the matter of vagueness, especially as it relates to the
topic of this chapter.
10.7.1
Vagueness or Imprecision
Consider a system with n components. The system and its components exist in a set of states
 ⊆01	. In the case of binary state systems,  = 01. Consider a generic element, say x, of
. Suppose that at some point in time, we inspect the system and declare that its state is x. If we
are able to place this x in a well-defined subset of , then we claim that the states of the system
can be classified with precision. However, there can be scenarios wherein the identification of
a state can be done unambiguously, but the classification of this state cannot; this is the case
of classification with vagueness. Classification with vagueness typically arises when one uses
natural language (Zadeh, 1965) to describe the system, and to make decisions about it based on
verbal descriptions. Here is an illustration.
Suppose that  =01   10, with each element representing the state of the system at any
time. Suppose that 10 denotes the ideal state and 0 the most undesirable state. Now suppose that
for the purpose of natural language processing I need to partition  into the subsets of ‘good
states’ and ‘bad states’. What then is the subset of good states? For example, is 7 a good state?
What about 5; is it a good state or a bad state? Clearly, the subset of good and bad states cannot
be sharply defined. As a consequence 5 is simultaneously a good state and a bad state. Thus,
if at any point in time the state of the system is 5, then the system can simultaneously exist
in multiple states. As another example, should an automobile with, say, 1250 miles on it be
classified as a ‘new car’ or as a ‘used car’? Classifications of this kind become germane when
setting insurance rates, honoring warranties, or levying taxes. In actuality many decisions are
often made on the basis of vague classifications. This is especially true in the health sciences
where treatment options are based on classifications that are imprecise, such as ‘high blood
pressure’, or ‘bad cholesterol levels’. In the context of reliability, decisions based on imprecise
classifications often occur in the arena of maintenance management wherein classifying the state
of a system, such as a vehicle, as ‘good’, ‘bad’ or ‘acceptable’ is common. The decision tree
of Figure 10.10 illustrates this point. Similarly with the decisions pertaining to quality-of-life
considerations (Cox et al., 1992) wherein the responses always tend to be imprecise.
Maintenance
actions
1
2
3
Monitor
Repair
Replace
Acceptable
Good
Bad
~
~
~
~
~
Figure 10.10
Maintenance decisions in a vague environment.

MULTI-STATE AND VAGUE STOCHASTIC SYSTEMS
305
Motivated by the above scenarios, the need to consider a theory of coherent systems based
on vague classifications seems appropriate. The existing theory for both binary and multi-state
systems, with precise classification as an underlying premise, is unable to deal with the types of
scenarios mentioned above. Related concerns have also been voiced by Marshall (1994).
10.7.2
Many-valued Logic: A Synopsis
Binary logic, upon whose foundation the theory of coherent structures has been developed,
pertains to propositions that adhere to the Law of Bivalence (or the Law of the Excluded
Middle): i.e. all propositions are true or false. Lukasiewicz (1930) recognized the existence of
propositions that can be both true and false simultaneously, and thus modified the calculus of
binary propositions to develop a calculus of three-valued propositions. His proposal considers
two propositions Y and Z, each taking the values 0, 1
2 and 1. The negation of Y is Y ′ = 1 −Y.
When the proposition Y takes the value 1(0) in a truth table, it signals the fact that the proposition
is true (false) with certainty. Values of Y intermediate to 1 and 0 signal an uncertainty about the
truth or the falsity of Y. The value 1
2 is chosen arbitrarily, for convenience; any value between
0 and 1 could have been chosen. The other logical connectives in the three-valued logic of
Lukasiewicz are conjunction, disjunction, implication and equivalence, denoted Y ∧Z, Y ∨Z,
Y →Z and Y ≡Z, respectively. The truth tables for the first two are given in Tables 10.1
and 10.2, respectively.
10.7.3
Consistency Profiles and Probabilities of Vague Sets
The philosopher Black (1939) recognized the inability of binary logic to represent propositions
that are neither perfectly true nor false. However, unlike Lukasiewicz (1930), Black did not
introduce three-valued propositions. Rather, he defined a vague proposition as one where the
possible states of the proposition are not clearly defined with respect to inclusion, and introduced
the mechanism of consistency profiles as a way of treating vagueness. Black’s consistency
profile is a graphical portrayal of the degree of membership of some proposition in a set of
imprecisely defined states, with 1 representing absolute membership in a state and 0 an absolute
lack of membership. The consistency profile of precise propositions is a step function, and that
Table 10.1
Truth table for Lukasiewicz’s Y ∧Z
Y ∧Z
Values of proposition Z
0
1/2
1
Values of
proposition Y
0
0
0
0
1/2
0
1/2
1/2
1
0
1/2
1
Table 10.2
Truth table for Lukasiewicz’s Y ∨Z
Y ∨Z
Values of proposition Z
0
1/2
1
Values of
proposition Y
0
0
1/2
1
1/2
1/2
1/2
1
1
1
1
1

306
SURVIVABILITY OF CO-OPERATIVE, COMPETING AND VAGUE SYSTEMS
Values of x
x*
0
1
μA(x)
μA(x)
x* Values of x
0
1
(a)
(b)
Figure 10.11
Illustration of consistency profiles of (a) a precise set; (b) a vague set.
of vague propositions is a gracefully decreasing function of the kind shown in Figure 10.11(b).
The scaling between 0 and 1 is arbitrary; consistency profiles are personal to an individual, or a
group, and therefore need not be unique.
For each x, a normalized consistency profile is a function Ax, where Ax describes the
degree of containment of x in a set A; 0 ≤Ax ≤1. When Ax = 1 or 0, A is a precise
set; when 0 ≤Ax ≤1, A is a vague set. Black’s (1939) consistency profile is Zadeh’s (1965)
membership function, and his vague set is Zadeh’s (1965) fuzzy set. For two vague sets A and B
with consistency profiles A x and B x, respectively, Zadeh (1965) defined the operations:
(a)
A∪B x = maxA xB x,
(b)
A∩B x = min A xB x, and
(c)
A′ x = 1 −A x.
Thus the union of A and B is a vague set A ∪B whose consistency profile is
maxA xB x; similarly the intersection. The important point here is that there is a par-
allel between the above vague set operations and the conjunction and disjunctive connectives of
Lukasiewicz (1930). Later on, in section 10.7.5, I shall use the above operations to define struc-
ture functions of vague binary state systems. Thus Lukasiewicz’s logic provides a framework
for studying vague coherent systems.
Probability Measures of Vague Sets
A strategy for endowing probability measures to vague sets using consistency profiles has been
outlined by Singpurwalla and Booker (2004). Their strategy is best explained by conceptualizing
an assessor of probabilities (or a decision maker) , who wants to quantify the uncertainty about
any outcome x (of an unknown quantity X) belonging to a vague set A. ’s prior probability that
x belongs to A is x ∈A; the prior probability here reflects ’s perception as to how nature
would classify x. To update this prior probability,  consults an expert , and elicits from  a
consistency profile A x for A; that is, the degree to which x can belong to A. Assuming X to
be discrete, ’s probability measure on the vague set A is
PX ∈AA x =

x
 
1 −
	
1 −
1
A x

 x  A
x ∈A
!−1
PX
(10.38)
where PX is ’s probability that outcome x will occur. The detailed arguments leading upto
(10.38) are in Singpurwalla and Booker (2004).

MULTI-STATE AND VAGUE STOCHASTIC SYSTEMS
307
10.7.4
Reliability of Components in Vague Binary States
To invoke the material of the previous section in the context of component reliability, suppose
that X denotes the state of a component taking values in  =x0≤x≤1, with x=1 representing
the perfectly functioning state. Let  ⊂, where  = x  x is a ‘desirable’ state; interest centers
around . If we are unable to specify an x∗such that x ≥x∗implies that x ∈, and otherwise
when x<x∗, then  is a vague set. Let  x be the consistency profile of . Interest may center
around  for several reasons, one being the need to use ‘natural language’ for communication
with others on matters of repair and replacement, the other being that it may not be possible to
observe the actual value of x, but it may be possible to make a statement about the general state
of the component. The complement of , say c, is the vague set whose consistency profile is
1 − x.
With the above in place, we define the reliability of a component with a vague state space as
PX ∈ x
and use (10.38) to evaluate it.
For the unreliability of a component with a vague state space we may use PX ∈c x.
Alternatively, we could define a vague set , where  = x  x is an ‘undesired’ state, and
specify  x, the consistency profile of . Then the unreliability of the component could be
defined as PX ∈ x. With either choice as a definition of unreliability, unreliability is
not the complement of reliability! This result is in contrast to that for binary state systems and
components.
Note that  x need not bear any relationship to  x. For example, in Figure 10.12(a),
 x and  x are symmetric, whereas in Figure 10.12(b), they are not.
10.7.5
Reliability of Systems in Vague Binary States
In this section, I extend the development of the previous section on binary state components
with imprecise classification, to the case of binary state n-component systems with imprecise
classification. However, to do so, I first need to define structure functions that relate the vague
component states to the vague system states. Motivated by the feature that the structure functions
of binary state systems with precise classification (i.e. those overviewed in section 10.2) are
the consistency profiles of certain precise sets, I propose the logical connectives of Lukasiewicz
(1930) as providing the basis for the required structure functions. The specifics, abstracted from
Sellers and Singpurwalla (2006), are outlined below.
Suppose that Xi, the state of the component i, takes values xi, where xi ∈ = x  0 ≤x ≤1,
i = 1   n. Consider a subset i of , where i is the vague set i = xi  xi is an ‘desirable’
1
x
0
1
1
x
0
1
(a)
(b)
μ (x)
μ (x)
μ  (x) = 1 – μ  (x)
μ  (x)
Figure 10.12
Symmetric and asymmetric consistency profiles of vague sets  and .

308
SURVIVABILITY OF CO-OPERATIVE, COMPETING AND VAGUE SYSTEMS
state. Let i xi be the consistency profile of i. If X = X1   Xn, and X is a structure
function, then for a series system we define
SX = min
i
i Xi	
(10.39)
and for a parallel system
PX = max
i
i Xi	
(10.40)
Assuming that the Xis are independent, the notion of independence when Xis takes values in a
vague set being articulated in Sellers and Singpurwalla (2006), the reliability of a series system
whose component states are vague will be
n
i=1
PXi ∈ii xi
(10.41)
and that of a corresponding parallel redundant system will be
P

n"
i=1
Xi ∈ii xii = 1   n


(10.42)
an expression that can be evaluated by the inclusion-exclusion formula (Feller, 1968). The
quantities PXi ∈Gii xi can be evaluated via (10.38).
10.7.6
Concluding Comments on Vague Stochastic Systems
As a closing comment, I emphasize that the notion of vague component and system states is
new and the need for it remains to be more convincingly argued. From a philosophical point
of view the matter of making a case for vagueness may be moot, because as stated by Russell
(1923), ‘all language is more or less vague’ so that the law of the excluded middle ‘is true
when precise symbols are employed but it is not true when symbols are vague, as, in fact, all
symbols are’. Furthermore, even if vagueness about the states of components and systems is
taken as a given, our approach for assessing the reliability of such components and systems
needs to be carefully scrutinized. Are the relationships of (10.39) and (10.40) meaningful? What
about (10.41) and (10.42), which are based on the premise that the Xis are independent? Is
independence meaningful when the Xis take vales in vague sets? These and several other related
issues need to be vetted out. Perhaps what has been described here merely scratches the surface
and hopefully does not do a poor job of it. I leave this for the reader to decide. The purpose of
including section 10.7 in this chapter is to whet the reader’s appetite as to what else is possible
when it comes to the survivability of stochastic systems and to give it a more modern twist in
the sense that natural language processing could be a wave of the future.

Chapter 11
Reliability and Survival in
Econometrics and Finance
Here lies Laplace: His remains are transformed.
11.1
INTRODUCTION AND OVERVIEW
The purpose of this chapter is to describe a platform that develops an interface between the notions
and techniques of reliability theory and survival analysis, and the mathematics of economics
and finance. This has been made possible because of three features. The first is that there exist
relationships between some metrics of reliability and some measures of income inequality such as
the Gini index, the Lorenz curve and the Bonferroni index of concentration. The second is that the
survival function of reliability bears an isomorphic relationship with the asset pricing formula of a
fixed income investment, like a riskless bond. The third feature is motivated by the possibility that
the non-parametric methods of survival data analysis can, with some caveats and modifications, be
used for the actual pricing of a bond in a competitive environment. Given that risk-free bonds do
not fail, whereas the survival function comes into play in the context of failure, the isomorphism
mentioned above raises the possibility that the exponentiation formula of (4.9) be re-interpreted
from a broader perspective. This we are able to do, so now we may see the exponentiation formula
as the law of a diminishing resource. In the context of reliability, the resource is an item’s hazard
potential (section 4.6); in the context of finance, the resource is a bond’s present value. The
three features mentioned above enable us to expand the scope of mathematical economics and
finance by importing ideas and techniques from reliability and survival analysis to econometrics
and financial risk, and vice versa. In what follows we make our case by elaborating on the above
claim by specific scenarios and examples. The overall message of this chapter is that some of
the material described in the previous chapters may have relevance to the economic and social
sciences as well. Its relevance to the actuarial sciences is historical, whereas its relevance to the
assurance sciences in the legal context is relatively new; see Singpurwalla (2000b), (2004) for an
overview.
Reliability and Risk: A Bayesian Perspective
N.D. Singpurwalla
© 2006 John Wiley & Sons, Ltd

310
RELIABILITY AND SURVIVAL IN ECONOMETRICS AND FINANCE
11.2
RELATING METRICS OF RELIABILITY TO THOSE OF INCOME
INEQUALITY
We start with some preliminaries. Let T denote a non-negative random variable having dis-
tribution function Ft = PT ≤t; for convenience we have suppressed , the background
information. Let the mean of Ft be , where  < . Assume that the survival function
Ft = PT ≥t = 1 −Ft has a well-defined inverse F
−1t = infxx  Fx ≥t. Let T0 ≡
0 ≤T1 ≤··· ≤Tn <  be the order statistics generated by a sample of size n from F•
(section 5.4.4). Then, the total time on test to the i-th order statistic is
Tni =
i
j=1
n −j + 1Tj −Tj−1
We have seen before, in section 5.4.1, that the total time on test statistic plays a key role in
life-testing and failure analysis. There are two other quantities of interest that have been spawned
by Tni; these quantities have played a role in testing for exponentiality – within the frequentist
framework. These are: the scaled total time on test statistic
Wn
 i
n

=
Tni
n
i=1 Tj
	
and the cumulative total time on test statistic
Vn =
1
n −1
n−1

i=1
Wn
 i
n


note that Wn i/n is always between 0 and 1. For further discussion on the properties of Vn, see
Bergman (1977).
11.2.1
Some Metrics of Reliability and Survival
In reliability theory and survival analysis, the theoretical analogues of Tn•	Wn• and Vn are
of interest. These are: the total time on test transform
H−1
F t
def=
F −1t

0
Fudu
the scaled total time on test transform
WFt
def= H−1
F t
H−1
F 1
0 ≤t ≤1	
and the cumulative total time on test transform:
VF
def=
1

0
WFtdu = 1

1

0
H−1
F udu
Also of relevance to us here is the mean residual life, introduced in section 4.2, namely,
Ft =
 
t Fudu
Ft


RELATING METRICS OF RELIABILITY TO THOSE OF INCOME INEQUALITY
311
Verify (cf. Chandra and Singpurwalla, 1981) that
Ft = 1 −WFFt
Ft

11.2.2
Metrics of Income Inequality
Analogous to the metrics introduced above are some metrics of income inequality used by
econometricians. These have been motivated by the sample Lorenz curve, which for p∈0	1, is
Lnp =
np
i=1 Ti
n
i=1 Ti
	
and the Gini statistic
Gn =
n−1
i=1 in −iTi+1 −Ti
n −1n
i=1 Ti

here np is the greatest integer in np.
The theoretical analogs of Lnp and Gn are: the Lorenz curve of T
LFp
def= 1

p

0
F −1udu	
0 < p < 1	
and the Gini index
GF
def=1 −2
1

0
LFpdp
The Lorenz curve, introduced by Lorenz (1905), has been used by social scientists to char-
acterize income size distributions. Specifically, LFp encapsulates the fraction of total income
that the poorest p proportion of the population possesses. Note that since LFp increases in p,
with LF0=0 and LF1=1, the Lorenz curve behaves like a distribution function with support
on [0,1]. The case LFp = p, 0 < p < 1, is called the ‘egalitarian line’. When LFp = p, the
Gini index GF is zero; this situation describes an absence of income inequality. Large positive
values of GF connote an inequality of income, the larger the GF the greater the disparity. Thus
the Gini index has come to be a useful device for assessing the concentration of wealth in a
population. As an aside, the Gini index and the Lorenz curve have also been used by Gail and
Gastwirth (1978a,b) for the testing of exponentiality.
Another quantity that is also of interest to us here is the cumulative Lorenz curve
CLF
def=
1

0
LFpdp = 1

1

0
p

0
F −1ududp
this is the area under the Lorenz curve and can be seen as a measure of the extent of poverty in
a population.
More recently, the Bonferroni curve and the Bonferroni index have begun to gain some
popularity as measures of income inequality (cf. Giorgi, 1998). Their proponents claim that
the Bonferroni index is more sensitive that the Gini index to low levels of income distribution

312
RELIABILITY AND SURVIVAL IN ECONOMETRICS AND FINANCE
(cf. Giorgi and Mondani, 1995). The Bonferroni index B, motivated by a comparison of the
partial means with the general mean, was proposed by Bonferroni in 1930. Assuming that Ft
is absolutely continuous with a probability density ft at t, Giorgi and Crescenzi (2001) define
the ‘first incomplete moment’, and the ‘partial mean’ of Ft as
F1t = 1

t
0
ufudu
and
t = F1x
Fx 	
respectively, and set BFt = t/. The Bonferroni curve is a plot of Ft versus BFt; it
lies within the unit square (Figure 11.1). If we let Ft = p, then the parametric form of the
Bonferroni Curve is, for p ∈0	1,
Bp = 1
p
p

0
F −1udu
Note that since Bp is undefined when p ↓0, one may not claim that the Bonferroni curve
necessarily starts from the origin of the Ft	BFt plane. Also, since dBp/dp > 0, Bp
is strictly increasing in p; it can be convex in some parts and concave in others (cf. Giorgi
and Crescenzi, 2001). The egalitarian line is the line joining the points (0,1) and (1,1), and B,
the Bonferroni index of the income concentration is the area between the Bonferroni curve, the
egalitarian line, and the ordinate. That is
B =
1

0
1 −Bpdp
clearly, B ∈0	1 grows as the inequality of income increases. When the concentration of income
is a maximum, the Bonferroni curve Bp becomes ‘J-shaped’; i.e. the lines joining the points
(0,0) and (0,1), and (0,1) and (1,1). Finally, as is shown in Proposition 3 of Giorgi and Crescenzi
(2001), the Bonferroni curve always lies above the Lorenz curve.
Bonferroni
index
Bonferroni
curve
0
1
1
1
F(t) = p
B(F(t))
= B(p) 
Egalitarian
line
Figure 11.1
The Bonferroni curve and the Bonferroni index.

RELATING METRICS OF RELIABILITY TO THOSE OF INCOME INEQUALITY
313
11.2.3
Relating the Metrics
In the theorems that follow, I show how the metrics of sections 11.2.1 and 11.2.2 relate to each
other in a manner that is made precise by the statements of the theorems given below. This
enables me to import ideas from reliability theory and survival analysis to the income disparity
aspects of economic studies. To keep our exposition short, I refrain from giving proofs of all the
results given below, pointing out instead to their original sources.
Theorem 11.1 (Chandra and Singpurwalla (1981), Theorem 2.1).
Wn
 i
n

= Ln
 i
n

+ n −1Ti
n
i=1 Tj
	
(a)
Vn = 1 −Gn	
(b)
WFt = LFt + 1
1 −tF −1t	
(c)
VF = 2CLF	
(d)
GF = 1 −VF	
(e)
LFFt = 1 −1
FtFt + t
(f )
With Theorem 11.1 in place, it is easy to obtain some relationships between some of the
metrics of reliability and the Bonferroni metrics. These are summarized in Theorem 11.2 below.
Theorem 11.2
BFt =
1
Ft −1

Ft
Ft Ft + t	
(a)
which relates the Bonferroni curve and the mean residual life, and
B ≤1 −VF
2 	
(b)
which gives an upper bound on the Bonferroni index in terms of the cumulative total time on
test.
Proof.
The proof of a above follows from part f of Theorem 1 and by setting Ft = p in
the parametric form of the Bonferroni curve.
To prove part b, we start by noting that since the Lorenz curve always lies below the
Bonferroni curve (Proposition 3 of Giorgi and Crescenzi (2001)), we have
LFp ≤Bp
Thus
1 −
1

0
LFpdp ≥1 −
1

0
Bpdp	

314
RELIABILITY AND SURVIVAL IN ECONOMETRICS AND FINANCE
from which it follows, using the definition of the Gini index, that
B ≤1 + GF
2

The required upper bound is now a consequence of part e of Theorem 1.
Besides facilitating a proof of Theorem 2, an important role served by Theorem 1 is that
is suggests the use of some ideas in reliability for obtaining some interesting inequalities in
economics. To see how, we first need to introduce some notions of partial ordering of distribution
functions that have proved to be useful in reliability theory. These notions will also be useful in
the context of the material of section 11.3.3 on asset pricing. To introduce these notions we start
with
Definition 11.1.
Let  be the class of all continuous distribution functions on 0	; let
F1	F2 ∈ . Then F1 is said to be convex ordered with respect to F2, denoted F1<cF2, if F −1
2 F1t
is convex on the support of F1, assumed to be an interval of 0	. Similarly, F1 is said to be
star ordered with respect to F2, denoted F1<∗F2, if F −1
2 F1t/t is non-decreasing on the support
of F1. A generalization of star ordering, denoted F1
<
∗TF2 occurs if F −1
2 t/F −1
1 t is increasing
for 0 < t < 1 (Klefsjo, 1984, Definition 2.2).
The following are some of the consequences of Definition 1 (cf. Barlow and Proschan 1975,
p. 107 and Klefsjo, 1984).
(i)
F1<cF2 ⇒F1<∗F2 ⇒F1
<
∗TF2
(ii)
F1<cF2F1<∗F2 and F2 is an exponential distribution ⇒F1 has a failure rate function that is
increasing (increasing on the average).
It is conventional to denote distributions whose failure rate is increasing (decreasing) by IFR
(DFR), and those whose failure rate in increasing (decreasing) on the average by IFRA (DFRA).
Also, if Ft is such that if for each  ≥0	 FT +  ≥≤FTF, then F is said to be NBU
(NWU); NBU (NWU) stands for ‘new better (worse) than used’. We may now state the third
consequence of Definition 11.1 as
(iii)
F IFR (DFR) ⇒F IFRA (DFRA) ⇒F NBU (NWU).
When F1 and F2 represent distribution functions of lifetimes, the notions of IFR, IFRA and
NBU describe the ageing and wear-out features of the items in question; see, for example,
Durham, Lynch and Padgett (1989). Similarly with the notions of DFR, DFRA and NWU. The
exponential distribution enjoys the special feature that is sits at the boundary, in the sense that
the exponential distribution is both IFR and DFR, IFRA and DFRA, and NBU and NWU. This
feature facilitates a comparison between any distribution that belongs to one of these classes (i.e.
IFR, DFR, etc.) and the exponential distribution, and also between and two distributions within
a class. Such comparisons can be translated to a comparison between two Lorenz curves and
inequalities between Gini indices as Theorem 3 below shows. They also enable us to establish
a type of preservation property inherited by the Lorenz curve, as Theorem 4 will show.
Theorem 11.3 (Chandra and Singpurwalla (1981), Theorem 4.2).
If F1
<∗F2 and if F1 and F2
have a common mean, then for all p ∈0	1:
(i)
LF1p ≥LF2p, and
(ii)
GF1 ≤GF2

RELATING METRICS OF RELIABILITY TO THOSE OF INCOME INEQUALITY
315
The inequality between the Lorenz curves given above suggests that F1 represents a more
equitable distribution of income than does F2. Economists call this feature ‘Lorenz domination’.
Similarly with the Gini indices.
The preservation properties mentioned above are summarized in Theorem 4, i and ii. Part
i of the theorem is due to Chandra and Singpurwalla (1981), Theorem 4.2; part ii is due to
Klefsjo (1984), Theorem 2.1. Before stating Theorem 11.4, it may be useful to remark that L−1
F ,
the inverse of a Lorenz curve is a concave function that behaves like a distribution function with
support on [0, 1]. We now state
Theorem 11.4.
(i)
F1<cF2 ⇒L−1
F1
<cL−1
F2 , and
(ii)
F1<∗TF2 ⇒L−1
F1
<∗TL−1
F2 
Thus, it is not the Lorenz curves that are preserved under convex and star-T orderings, but it
is their inverses that inherit the preservation proprties.
11.2.4
The Entropy of Income Shares
In addition to the Gini and Bonferroni indices there is another measure of income inequality that
is motivated by the notion of entropy. Specifically, if Yi denotes the fraction of the total income
in a population earned by the i-th individual, i = 1	   	N, then Hy, the entropy of income
shares is defined (section 4.6) as
Hy =
N
i=1
Yi log 1
Yi

The maximum value that Hy can take is logN. Accordingly, a measure of income inequality,
called the redundancy, is logN −Hy. Thiel (1967, p. 96) has proposed a theoretical analogue
of the redundancy as
RF = 1



0
x log x
fxdx	
where F, the distribution function (of income), has density f and mean .
Verify that for a Weibull distribution with shape parameter >1, RF decreases as  increases.
Similarly for the Pareto distribution Fx = 1 −x−, with  > 1 and x ≥1. In both cases an
increase in  signals a decrease in the DFR-ness of the distributions. Motivated by this feature,
we have the following inequality property of the redundancy.
Theorem 11.5 Chandra and Singpurwalla (1981), Theorem 4.5).
If F1 and F2 have a common
mean , and if F1<∗F2, then RF1 ≤RF2.
11.2.5
Lorenz Curve Analysis of Failure Data
The role of the total time on test in life-testing and failure data analysis has been mentioned by
before at the beginning of this section. In part (d) of Theorem 1, we have seen a relationship
between the total time on test and the cumulative Lorenz Curve. This relationship motivates
us to explore the potential usefulness of using the Lorenz curve for analyzing and interpreting
lifetime data. With that in mind we seen, in Figures 11.2 and 11.3, the Lorenz curves of some
data reported by Bryson and Siddiqui (1969) and by Doksum (1974), respectively. The former

316
RELIABILITY AND SURVIVAL IN ECONOMETRICS AND FINANCE
1.0
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
Proportion of patients
Sample Lorenz curve
Figure 11.2
Sample Lorenz curve versus proportion of leukemia patients.
1.0
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
Proportion of guinea figs
Sample Lorenz curves
Control Group
Treated Group
Figure 11.3
Sample Lorenz curves versus proportion of guniea pigs.
consists of survival times of patients suffering from leukemia, and the latter the survival times
of a treated and a control group of guinea pigs.
The sample Lorenz curve Lnp of Figure 11.2 represents the proportion of the total lifetime
contributed by the least fortunate of the p100 percent of the patients. It is instructive to note,
from this figure, that 50% of the patients contribute only 20% of the total lifetime.

INVOKING RELIABILITY THEORY IN FINANCIAL RISK ASSESSMENT
317
The sample Lorenz curves of Figure 11.3 serve an additional purpose from that of Figure 11.2.
They enable us to compare the heterogeneity of the survival pattern of the teated and the control
group of guinea pigs. For p < 08, the Lorenz curve for the control group lies below the Lorenz
curve for the treated group. This behavior suggests that the treated group is initially at least
less heterogenous than the control group. Qualitative results of this type may be insightful with
respect to assessing the efficacy of treatments.
11.3
INVOKING RELIABILITY THEORY IN FINANCIAL RISK
ASSESSMENT
In the financial risk community, the word ‘risk’ generally equates with the volatility of an asset’s
price. By volatility we mean deviation from a benchmark. Is volatility a satisfactory measure
of risk? I think not, because the true concern of an investor is loss due to downside volatility.
The dictionary definition of risk is the possibility of suffering a harm or a loss; thus the concern
of investor loss mentioned above is more in keeping with the dictionary definition of risk.
Volatility could encapsulate a temporary divergence of opinions about an asset’s price, a state
of nervousness, but not necessarily risk itself. By contrast, a survival function does capture the
essence of risk in the literal sense of the word, because it describes the degradation (or loss)
of survival probability over time. The survival function could therefore be a more meaningful
indicator of potential loss. But survival functions are not entities that are natural in finance, save
for the case of defaults (i.e. an inability to pay). With this in mind we need to look for ways
by which a survival function like behavior can be invoked in the context of finance. This we
are able to do via the scenario of a risk-free fixed income asset like a bond. To see how, we
start with a review of the pricing of risk-free bonds and conclude with the observation that the
present value function of such bonds behaves like the survival function of an item. Once this is
recognized we are able to import results from reliability and survival into the arena of finance.
The material which follows is exclusively based on Singpurwalla (2006c).
11.3.1
Asset Pricing of Risk-free Bonds: An Overview
A risk-free zero coupon bond pays, with certainty, the bondholder (i.e. the buyer of the bond)
$1 at time T after the time of the purchase of the bond; T is known as the holding period of the
bond. The bond is said to mature when the holding period ends. Suppose that the bond holder
purchases the bond at some calendar time t, t ≥0, with the intent of holding the bond until time
t + T; let Pt	T be the purchase price of this bond. Then, Pt	T is known as the present value
of this bond at time t. Clearly, Pt	0 = 1 and Pt	T decreases in T. Also, Pt	T will depend
on what the bond holder and the bond issuer think (or speculate) the interest rate will be during
the time period t	t + T.
We assume that the interest rate rs, s ≥0, changes with time continuously. Consequently,
an amount x invested at time s will become (approximately) x + xrsh = x1 + rsh at time
s + h, assuming that h is small. Let DT denote the amount that one has at time T, assuming
$1 is invested at time 0. Then, for small h and rs, 0 ≤s ≤T,
Ds + h ≈Ds1 + rsh	
or that the rate of change of the amount at time s is
D s + h −D s
h
≈D sr s

318
RELIABILITY AND SURVIVAL IN ECONOMETRICS AND FINANCE
In the limit, as h ↓0, we have
r s = D′s
Ds 	
where D′s is the derivative of D s at time s.
Integrating over s from 0	T, the above becomes
T

0
r sds = logD T −logD 0
Since D 0 = 1, we have
D T−1 = exp
⎡
⎣−
T

0
r sds
⎤
⎦
But D T−1 is P 0	T, the present value at time 0 of a bond that pays $1 at time T Thus,
in general, we have the following relationship
Pt	T = exp
⎡
⎣−
t+T

t
r sds
⎤
⎦	
(11.1)
where Pt	T is the present value at time t of a zero-coupon risk-free bond yielding $1 at
time t + T.
Isomorphism with the Survival Function
Equation (11.1) parallels (4.9), the exponentiation formula of reliability and survival, once we
look at rs as a failure rate function, and P t	T as a survival function. Observe that P t	0=1
and P t	T asymptotes to 0 as T increases to infinity. In the same vein, if the exponent of the
right-hand side of (11.1) is labeled as Rt	T, that is, if
Rt	T
def=
t+T

t
r sds	
then Rt	T can be identified with the cumulative hazard function. Also, the yield curve of
finance,
Rt	T
def= 1
T
t+T

t
r sds	
can be identified with the failure rate average. Recall that the failure rate average was alluded to
in section 11.2.3 in the context of introducing the IFRA (DFRA) class of distribution functions.
We now seem to have an isomorphic relationship between the survival function of an item
and the present value function of a zero-coupon risk-free bond. But to claim an isomorphism I
need to show that the two entities in question have a common genesis. This we do next, in the
section which follows. A consequence of the common genesis is that the exponentiation formula
of (4.9) represents a phenomenon that is broader in scope than that of ageing and failure.

INVOKING RELIABILITY THEORY IN FINANCIAL RISK ASSESSMENT
319
11.3.2
Re-interpreting the Exponentiation Formula
Suppose that in (11.1), we set t = 0, with P0	T = PT, R0	T = RT, and R0	T =RT.
With the above in place (11.1), when seen in the context of reliability and survival analysis, would
imply that PT is the survival function and rs is the failure rate function. This interpretation
of PT and rs would have an intuitive import that is grounded in the notion of ageing and
failure. Since risk-free bonds cannot (by definition) default, one is hard pressed to look at the
present value function in the same vein as a survival function. This dilemma motivates us to
seek an alternative, more encompassing, way to look at the survival function. This we are able
to do by examining the derivation of the exponentiation formula from the first principles.
Suppose then, that X denotes the lifetime of an item, and suppose that Fx = PX ≤x is
absolutely continuous with derivative F ′x = fx for (almost) all x ≥0. Consider the quantity
Px < X ≤x + dxX > x = Fx + dx −Fx
Fx
	
where Fx = 1 −Fx. Dividing the above by dx gives us the rate at which Fx increases at x,
multiplied by

Fx
−1. Taking the limit as dx ↓0, gives us
lim
dx↓0
Fx + dx −Fx
Fxdx
= fx
Fx
def= hx	
where hx is the failure rate. The qualifier ‘failure’ is added because the function Fx whose
rate of failure is being discussed represents the probability of failure by x. Thus hx reflects
the rate at which Fx increases in x. The exponentiation formula of (11.1) is a consequence of
the relationship hx = fx/Fx.
It is important to note that the development above is not contingent on the fact that Fx be a
distribution function. All that has mattered is that Fx be absolutely continuous and Fx be non-
decreasing. These features enable us to claim that the exponentiation formula is ubiqutious in any
scenario involving an absolutely continuous monotonically decreasing function, the interpretation
of the function being context dependent. In reliability, the said function is a survival function;
in finance it is the present value function.
The Exponentiation Formula as the Law of a Diminishing Resource
The discussion above enables us to remark that when PT denotes the present value at time T,
and rs is the interest rate, then rsds would represent the proportion of loss in present value
at time s, during the time interval s	s + ds. Thus one may liken the interest rate as a form of
a hazard or risk posed to the present value function vis-à-vis its failure to maintain a particular
value at any time. We now have a point of view that connects the interest rate and the failure
rate from a common perspective.
Our theme of interpreting the interest rate as the agent for causing a proportion loss in present
value has a systematic effect in reliability. Specifically, since Fx decreases in x from F0=1,
the exponentiation formula of (11.1) can be seen as a law which prescribes a lifetime as the
consequence of some diminishing resource, with F0 = 1 reflecting the item’s initial resource.
The resource gets depleted over time, with the proportion depleted at x being given as hxdx.
The notion of a hazard potential, discussed in Section 4.6, provides support for this point of view.
Thus to summarize, the well-known exponentiation formula which arises in the contexts of
reliability, survival analysis and the asset pricing of risk-free instruments, can be seen as a
law that governs the depletion of a resource, with the proportion loss at x governed by the
failure (interest) rate at x. This interpretation is the basis of our claimed isomorphism between

320
RELIABILITY AND SURVIVAL IN ECONOMETRICS AND FINANCE
the present value function and the survival function. We have now established a platform for
assessing financial risk using the more traditional tools of risk analysis, namely, reliability theory
and survival analysis. In what follows, I describe how this common platform enables us to import
some ideas and notions from reliability to finance and vice versa.
11.3.3
A Characterization of Present Value Functions
In this section, I endeavor to describe the qualitative behavior of PT, the present value function,
when the underlying interest rate rs, 0<s≤T, or the yield curve RT, are monotone (increasing
or decreasing) in their respective arguments. The idea here is that when a bond is issued, the
precise nature of the interest rate that will prevail during the life of the bond will not be known,
but one may speculate upon its general nature as being moving upwards or downwards. A
characterization of the present value function enables us to compare present value functions
under different forms of interest rate functions, assumed monotonic, and also enable us to obtain
bounds and inequalities for different investment horizons. The exercise here parallels that which
is done in reliability theory wherein comparison with the exponential survival function has
proved to be valuable.
Non-parametric Classes of Present Value Functions
By a non-parametric class of present value functions, we mean a class of functions whose
precise form is unknown (i.e. they are not parametrically defined) but about which some general
features can be specified. The material which follows parallels that of section 11.2.3 wherein
non-parametric classes of life distributions such as IFR (DFR), IFRA (DFRA) and NBU (NWU)
were introduced and their consequences explored. We start with
Definition 11.2.
The present value function P(T) is defined to be IIR (DIR), for increasing
(decreasing) interest rate – if for each  ≥0, PT + /PT is decreasing (increasing) in
T ≥0.
A consequence of Definition 11.2 is that when PT is absolutely continuous, the interest rate
function rT is increasing (decreasing) in T. Conversely, when rT is increasing (decreasing)
in T, PT is IIR (DIR) (cf. Barlow and Proschan, 1975, p. 54). When rt=, a constant greater
than 0, PT = exp−T, which is both IIR and DIR. All present value functions that display
the IIR (DIR) property constitute a class that we label ‘IIR (DIR) class’.
Interest rate functions are generally not monotonic even though they may reflect a tendency
to edge upwards. They often contain aberrations (or kinks) that are not too severe, in the sense
that their average is monotone. In other words, whereas rT is not monotone, the yield curve
RT is. To bring this feature into play we introduce
Definition 11.3.
The present value function PT is defined to be IAIR (DAIR), for increasing
(decreasing) average interest rate, if −logPT/T is increasing (decreasing) in T ≥0.
A consequence of Definition 11.3 is that PT IAIR (DAIR) is tantamount to RT increasing
(decreasing) in T ≥0 (cf. Barlow and Proschan, 1975, p. 84). Analogous to IIR (DIR) class, we
define the IAIR (DAIR) class as a collection of functions PT that display the IAIR (DAIR)
property. Verify that the IAIR class, denoted IAIR, encompass the IIR class, denoted IIR,
so that IIR ⊆IAIR. Similarly DIR ⊆DAIR.
A further generalization of Definitions 11.2 and 11.3, a generalization whose merits will be
pointed out later, is given by Definition 11.4 below.
Definition 11.4.
The present value function P(T) is said to display a NWO (NBO), for new
worse (better) than old, property if for each , T ≥0, PT +  ≤≥PTP.

INVOKING RELIABILITY THEORY IN FINANCIAL RISK ASSESSMENT
321
It can be shown, details omitted (cf. Barlow and Proschan, 1975, p. 159), that
IIR ⊆IAIR ⊆NWO	
and
DIR ⊆DAIR ⊆NBO	
where the NWO and the NBO classes contain all present value functions that display the
NWO and NBO property, respectively.
Financial Interpretation of the NBO (NWO) Feature
Consider the case of equality in Definition11.4. Now
PT +  = PTP	
(11.2)
and the above relationship holds if and only if PT = exp−T, for some  ≥0 and T ≥0. The
interest rate function underlying this form of the present value function is rs=. Equation (11.2)
also implies that
PT −PT + 
PT
= 1 −P	
and since P0 = 1, the above relationship can also be written as
PT −PT + 
PT
= P0 −P
P0

(11.3)
Because PT is a decreasing function of T, the left-hand side of (11.3) describes the proportion
loss in present value during a time interval 0	 at the time T, whereas the right-hand side
describes the proportion loss in the same time interval, but at time 0. This is an analogue of
the memoryless property of the exponential distribution in the context of finance. Its practical
consequence is that under a constant interest rate function, there is no reason to prefer one
investment horizon over another, so long as the holding period is the same.
Now consider the case of strict inequality. Suppose that PT is NWO, so that
PT +  < PTP	
and as a consequence
PT −PT + 
PT
< P0 −P
P0

(11.4)
This means that under (11.4) the proportion loss in present value at some time T>0 is always
less than the proportion loss at time 0. Vice-versa when PT is NBO and the inequality above is
reversed. To a bondholder, the greater the drop in present value, the more attractive is the bond.
Consequently, for PTs that are NWO, an investment for any fixed holding period that is made
early on in the life of the bond is more attractive than one (for the same holding period) that is
made later on. In the IIR or the IAIR case, the above claim makes intuitive sense because the
aforementioned properties are a manifestation of increasing interest rates and increasing yield

322
RELIABILITY AND SURVIVAL IN ECONOMETRICS AND FINANCE
curves, and IIR ⊆IAIR ⊆NWO. A similar claim can be made in the case of PT that
is NBO.
It is of interest to note that our definition of NWO and NBO is a reverse of that used in
reliability theory, namely, the NBU and NWU classes. This makes sense because a decrease of
the present value function is a consequence of an earned resource (namely interest) whereas the
decrease of the survival function is a consequence of a depleted resource.
Present Value Functions that are Log Concave and PF2
Suppose that the present value function PT belong to one of the several non-parametric classes
introduced before, and suppose that the interest rate at time of issue of bond is >0; i.e. r0=.
Were the interest rate over the investment horizon T to remain a constant at , then the present
value function should be of the form exp−T, T ≥0. The purpose of this section is to compare
PT and exp−T. Such a comparison could provide new insights about desirable asset pricing
investment horizons. To do so, we need to introduce the notions of log concavity and Polya
Frequency Functions of Order 2 PF2. These notions have turned out to be useful in reliability
theory.
Definition 11.5.
A function hx, −<x< is said to be PF2 if: hx≥0 for −<x<, and

hx1 −y1 hx1 −y2
hx2 −y1 hx2 −y2
 ≥0
for all − < x1 < x2 <  and − < y1 < y2 < , or equivalently loghx is concave on
−	+, or equivalently for fixed  > 0, hx + /hx is decreasing in x for a ≤x ≤b,
where
a = inf
hy>0y
and
b = sup
hy>0
y
The above equivalencies are given in Barlow and Proschan (1975, p. 76). Log concavity and
PF2 enable us to establish crossing properties of the present value function.
To start with, suppose that P• is IIR (DIR). Then, from Definition 11.2 we have that for
each  ≥0, PT + /PT is decreasing (increasing) in T ≥0. As a consequence we have
Claim 11.1.
P• IIR is equivalent to P• being both log-concave and PF2.
Since P• IIR is equivalent to an increasing interest rate function r•, and vice-versa, the
essence of Claim 11.1 is that increasing interest rate functions lead to log-concave present value
functions. What is the behavior of P• if instead of the interest rate function being increasing it
is the yield curve that is increasing? More generally, suppose that P• is IAIR (DAIR). Then,
P1/T ↓↑T, for T ≥0 (Definition 11.3). Consequently we have
Claim 11.2.
P• IAIR (DAIR) implies that for all T ≥0 and any 	0 <  < 1,
PT ≥≤PT
(11.5)
To interpret (11.5), let QT = 1/PT. Then QT is the amount received at time T for every
unit of money invested at time T = 0. Consequently, taking reciprocals in (11.5), we have
QT/2 ≤≥QT1/2

INVOKING RELIABILITY THEORY IN FINANCIAL RISK ASSESSMENT
323
Thus, here again, long investment horizons yield more bang for a buck than short horizons
when the yield curve is monotonic increasing, and vice-versa when the yield curve is monotone
decreasing. Claim 11.2 prescribes how the investment horizon scales.
To explore the crossing properties of present value functions that are IAIR (DAIR), we
introduce
Definition 11.6.
A function hx, 0≤x≤ is said to be star-shaped if hx/x is increasing in x.
Otherwise, it is said to be anti star-shaped. Equivalently, hx is star-shaped (anti-star-shaped),
if for all , 0 ≤ ≤1,
hx ≤≥hx
It is easy to verify that any convex function passing through the origin is star-shaped (cf.
Barlow and Proschan, 1975, p. 90).
Since P• IAIR (DAIR) implies (Definition 11.3) that −logPT/T is increasing (decreas-
ing) in T ≥0, it now follows that
Claim 11.3.
P• IAIR (DAIR) implies that TRT is star-shaped (anti-star-shaped).
Recall that RT is the yield curve. The star-shapedness property, illustrated above, is useful
for establishing Theorem 6 which gives bounds on P•. The essence of the star-shapedness
property is that there exists a point from which a ray of light can be drawn to all points of the
star-shaped function TRT =
 T
0 rudu, with the origin as the point from which the rays of
light can be drawn.
It is clear from an examination of Figure 11.4, that a star-shaped function can cross a straight
line from the origin at most once, and that if it does so, it will do it from below. Thus we have
Theorem 11.6
The present value function P• is IAIR (DAIR) iff for T ≥0 and each  > 0,
PT −exp−T, has at most one change of sign, and if a change of sign actually occurs, it
occurs from + to −(from −to +).
A formal proof of this theorem is in Barlow and Proschan (1975, p. 90). Its import is that the
present value function under a monotonically increasing yield curve will cross the present value
function under a constant interest rate , namely exp−T, at most once, and that if it does
cross it will do so from above. The reverse is true when the yield curve decreases monotonically.
T(R(T))
Rays of
light
Time T 
Figure 11.4
Star-shapedness of TRT when P· is IAIR.

324
RELIABILITY AND SURVIVAL IN ECONOMETRICS AND FINANCE
T *
Investment
horizon T 
P(⋅)
exp(−λT)
Present
value
Figure 11.5
Crossing properties of an IAIR present value function.
Figure 11.5 illustrates the aforementioned crossing feature for the case of P• IAIR, showing
a crossing at some time T ∗. In general, T ∗is unknown; it will be known only when a specific
functional form is assumed for P•.
The essence of Figure 11.5 is that when the yield curve is predicted to be monotone increasing,
and having a spot interest rate  > 0 at T = 0, then the investment horizon should be at least T ∗.
Investment horizons smaller than T ∗will result in smaller total yields than those greater than
T ∗. The investment horizon of T ∗is an equilibrium point.
The illustration of Figure 11.5 assumes that PT and exp−T cross, whereas Theorem 6
asserts that there is at most one crossing. Thus we need to explore the conditions under which
a crossing necessarily occurs and the point at which the crossing occurs. That is, we need to
find T ∗, assuming that T ∗< . The result is summarized in Theorem 7. This theorem uses the
notion of star ordering which was introduced in Definition 11.1. Theorem 7 is compiled from a
collection of results in Barlow and Proschan (1975, p. 107–110).
Theorem 11.7
Let F <∗G. Then
i
P• is IAIR, and
ii
PT crosses exp−T at most once, and from above, as T ↑, for each  > 0. Further-
more if
 
0 Pudu = 1/, then
iii
A single crossing must occur, and T ∗, the point at which the crossing occurs is greater
than 1/. Finally a crossing will necessarily occur at T ∗= 1/, if
iv
Pu is DIR and


0
Pudu = 1/
Under (iv) above, the interest rate is monotonically decreasing; in this case the investment
horizon should be no more than T ∗.
In parts (ii) and (iv) of Theorem 7, we have imposed the requirement that


0
Pudu = 1/
(11.6)
How must we interpret the condition of (11.6)? To do so, we appeal to the isomorphism of
section 11.3.1. Since Pu behaves like a survival function, with P0 = 1 and PT decreasing
in T, we may regard T as a random variable with distribution function 1−P•. Consequently,

INVOKING RELIABILITY THEORY IN FINANCIAL RISK ASSESSMENT
325
the left-hand side of (11.6) is the expected value of T. With this as an interpretation, we may
regard the investment horizon as an unknown quantity whose distribution is prescribed by the
present value function, and whose mean is 1/.
11.3.4
Present Value Functions Under Stochastic Interest Rates
The material of section 11.3.3 was based on the premise that whereas the interest rate over the
holding period of a bond is unknown, its general nature, a monotonic increase or decrease, can be
speculated. Such speculations may be meaningful for small investment horizons; over the long
run interest rates cannot be assumed to be monotonic. In any case, the scenario of section 11.3.3
pertains to the case of deterministic but partially specified interest rates. In this section, we
consider the scenario of interest rate functions that are specified up to some unknown constants,
or are the realization of a stochastic process. An analogue of these scenarios in reliability theory
is a consideration of hazard functions that are stochastic (section 7.1).
Interest Rate Functions with Random Coefficients
Recall (equation (11.1)) the exponentiation formula for the present value function under a
specified interest rate function rs, s ≥0, with t = 0, as
PT = exp−RT	
(11.7)
where RT is the cumulative interest rate function. Suppose now that rs, s ≥0 cannot be
precisely specified. Then the RT of (11.7) becomes a random quantity. Let RT describe
our uncertainty about RT for any fixed T ≥0. We require that • be assessed and specified.
Thus our attention now centers around assessing PT
, the present value function when
RT can be specified for any desired value of T. In other words, PT
 refers to the fact
that the present value function depends on . In what follows I argue that
PT
 = Eexp−RT	
(11.8)
where E denotes the expectation with respect to •. To see why, we may use a strategy used
in reliability theory which which begins by noting that
exp−RT = PrX ≥RT	
where X is a random variable whose distribution function is a unit exponential. Consequently
when RT is random
PT
 =


0
PrX ≥RTRTRTdRT
=


0
exp−RTRTdRT
=Eexp−RT	
a result that has appeared before as (7.2).
Thus, to obtain the present value function for any investment horizon T, when we are uncertain
about interest rate function over the horizon 0	T, all we need do is specify our uncertainty about

326
RELIABILITY AND SURVIVAL IN ECONOMETRICS AND FINANCE
the cumulative interest rate at T, via RT. What is noteworthy here is that the functional
form of Rt, t ≥0 does not matter. All that matters is the value of RT.
As an illustration of how we may put (11.8) to work, suppose that rs = , s ≥0, but that 
is unknown. This means that at time 0+, the interest rate is to take some value ,  ≥0 that is
unknown and is to remain constant over the life of the bond.
Suppose further that our uncertainty about  is described by a gamma distribution with scale
parameter  and a shape parameter . Then U
def= T has a density at u of the form
u
	 = exp−uu−1
T 
	
from which it follows that the present value function is
PT
	 =


T + 

	
(11.9)
which is of the same form as the survival function of a Pareto distribution.
It can be verified that the present value function of (11.9) belongs to the DIR class of functions
of Definition 11.2. For this class we are able to provide an upper bound on PT (Theorem 8).
The implication for this theorem is that for scenarios of the type considered here, short investment
horizons are to be preferred over long ones.
Theorem 11.8 (Barlow and Proschan (1975), Theorem 5.1).
If PT is DIR with mean ,
then
PT
 ≤

exp−T/	
for T ≤	

T e−1	
for T ≥
(11.10)
this bound is sharp.
The dark line of Figure 11.6 illustrates the behavior of this bound. It shows that the decay in
present value for time horizons smaller than  is greater than the decay in present value for time
horizons greater than .
The dotted line of Figure 11.6 shows the behavior of the upper bound had its decay been of
the form exp−T/ for all values of T. Clearly investment horizons greater than  would not
be of advantage to a holder of the bond.
μ
1
P(T)
Time T 
Figure 11.6
Upper bound on PT when PT is DIR.

INVOKING RELIABILITY THEORY IN FINANCIAL RISK ASSESSMENT
327
For the special case considered here, namely  unknown with its uncertainty described by

		PT
	 = /T + . Were PT
	 be interpreted as a survival function,
then the  of Theorem 8 would be given as
 =
 
0


T + 

dT =

 −1
 exists if  > 1. Consequently, under this PT
	 the investment horizon should not exceed
/ −1.
Recall that were  to be known with certainty, PT would be exp−T,  > 0	 T ≥0, and
that there would be no restrictions on the investment horizon so that a bond holder could choose
any value of T as an investment horizon. With  unknown, the net effect is to choose shorter
investment horizons, namely those that are at most / −1. A similar conclusion can also be
drawn in the case wherein 
	 be a uniform over 	. It can be verified that in the
uniform case
PT
	 = e−T −e−T
T − 	
and that PT
	 is again DIR.
Whereas the above conclusions regarding uncertainty about rs	s ≥0 causing a lowering of
the investment horizon, have been made based on a consideration of a special case, namely
rs=	>0	s ≥0, the question arises about the validity of this claim, were rs to be any other
function of s, say rs = s−1, for some  > 0, and  > 0. When  is assumed known, and
uncertainty about  is described by 
•, then (11.7) would be a scale mixture of exponentials
and by Theorem 4.7 of Barlow and Proschan (1975, p. 103), it can be seen that PT
• is DIR,
so that Theorem 8 comes into play and the inequalities of (11.10) continue to hold. Thus once
again, uncertainty about  causes a lowering of the investment horizon. Indeed, the essence of
Theorem 8 will always hold if the cumulative interest rate RT is such that any function of T
does not entail unknown parameters.
Interest Rates as the Realization of a Stochastic Process
We now consider the case of interest rates that are the realization of a stochastic process.
A consideration of stochastic processes for describing interest rate function is not new to the
literature in mathematical finance. Indeed much has been written and developed therein. Our
focus here, however, is a consideration of a shot-noise process for modeling interest rates and
to explore its consequences on the present value function. A use of the shot-noise process for
describing the failure rate function has been considered in section 7.2.1. Given below is the
adaptation of this process for describing the interest rate function and some justification as to
why this could be a meaningful thing to do.
Our rationale for using the shot noise for describing the interest rate function is that interest
rates take an upward jump when certain deleterious economic events occur. Subsequent to their
upward jump, the interest rates tend to come down, or even remain constant, until the next
deleterious event occurs. In Figure 4.16, the deleterious events are shown to occur at times
T1	T2	T3	   Such events are assumed to occur at random and are governed by say a
Poisson process with rate m	m>0. The amount by which the interest rate jumps upward at time
Ti is supposed to be random; let this be denoted by a random variable Xi. Finally, suppose that
the rate at which the interest rate decays is governed by the attenuation function, hs	s ≥0.
Then, it is easy to see that at any time T ≥0,
rT =


i=1
XihT −Ti	

328
RELIABILITY AND SURVIVAL IN ECONOMETRICS AND FINANCE
with hu = 0 whenever u < 0.
In what follows, we suppose that the Tis and the Xis are serially and contemporaneously
independent. We also suppose that the Xis are identically distributed as a random variable X.
If X = d, a constant, and if the attenuation function is of the form hu = 1 + u−1 – i.e. the
interest rate decays slowly, then it can be seen (cf. equation (7.7)) that the present value function
takes the form
PT
m = exp−mT1 + Tm
(11.11)
If, to the contrary, X has an exponential distribution with scale parameter b, and hu =
exp−au – that is, the interest rate decays exponentially, then (cf. equation (7.8))
PT
m	a	b = exp

−mbT
1 + ab
1 + ab −exp−aT
ab
mb/1+ab

(11.12)
The PT of (11.11) is the survival function of a Pareto distribution. If in (11.12) we set
a = b = 1, and m = 2, then a change of time scale from T to expT would result in the present
value function having the form of the survival function of a beta distribution on (0, 1) with
parameters 1 and 2.
Summary and Conclusions: Future Work
Equations (11.9) through (11.12) were originally obtained in the context of reliability under
dynamic environments. The isomorphism of section 11.3.1 has enabled us to invoke them in the
context of finance, and what is given in this section scratches the surface. Much more can be
done along these lines. For example, a hierarchical modeling of interest rate is one possibility.
Another possibility, and one that is motivated by work of Dykstra and Laud (1981), is to describe
the cumulative interest rate by a gamma process or to look at the present value functions as
Dirichlet or neutral to the right processes. Another possibility, and one that is motivated by the
enormous literature in survival analysis, is to model interest rates as a function of covariates and
markers. The purpose of this chapter has been mainly to open the door to other possibilities by
creating a suitable platform, which I feel has now been done.
11.4
INFERENTIAL ISSUES IN ASSET PRICING
The statistical analyses of failure and survival time data almost always entail the treatment of
observables that are supposed to be generated by some stochastic mechanism that characterizes
the lifetimes of a biological or a physical unit. The methods described in Chapters 5 and 9 assume
the availability of such data. Can some of these methods be used in the context of inferential
issues that arise in the context of asset pricing? If so, what are the inferential issues, and how can
the said methods be used? The aim of this section is to address the above and related questions.
My answer to the first question is in the affirmative but there is a caveat to it. The caveat
is a consequence of the fact that the available information on asset pricing is generated by
behavioristic phenomena that are rooted in the socio-economic principles of uncertainty and
utility, not the product of biological or physical mechanisms. Thus, for example, the information
at hand could be the declared present value functions over a range of investment horizons, by
several institutions like banks and investment houses. When such is the case, the inferential
issue boils down to how an individual must pool the several declared present value functions in
a coherent manner. Thus the answer to the first part of the second question. An answer to the
second part of the question is our claim that the non-parametric Bayes methods of Chapter 9 are

INFERENTIAL ISSUES IN ASSET PRICING
329
a suitable way to achieve the desired pooling. However, in order to do so, we need to transform
the socio-economic information of a declared present value function so that it mimics observed
data from some probability distribution. An approach for doing so is described in section 11.4.2,
but first we need to set up a framework for formulating the inferential problem at hand. Our
framework is in the spirit of a decision maker eliciting expert testimonies to update his/her prior
beliefs (section 5.3).
11.4.1
Formulating the Inferential Problem
Consider a bond issuer  who needs to come up with a present value function over a range of
investment horizons. The bond issuer has at his/her disposal the following quantities.
(a)
PT	T ≥0, the bond issuer’s present value function, as assessed at the ‘now time’ t = 0,
based on s prediction of the future interest rate function rs	0 < s ≤T.
(b)
PiTj the i-th bond issuer’s present value function, specified over a collection of investment
horizons Tj	j =1	   	mi	i =1	   	n. We have assumed that there are n bond issuers, in
addition to , and that each of the n bond issuers has his/her maximum investment horizon,
namely, Tmi for bond issuer i. We also assume that all the n bond issuers use the same time
intervals for their investment horizons. That is, the Tjs are fixed time points, such as one
year two years and so on (Figure 11.7).
The problem faced by  is how to pool the PiTjs with ’s PT to arrive upon a P∗
T
that can be used by  as an investment strategy. Since all the n + 1 bond issuers compete with
each other to dominate the investment market for bonds, it is quite possible that once  declares
his/her P∗
T to the public, the n other bond issuers will update their respective PiTjs causing
 to update P∗
T, and this process of all the n + 1 bond issuers constantly revising their present
values can go on indefinitely. We do not model here this matter of an ‘infinite regress’. Instead,
we assume that after a few cycles of updating, each bond issuer stays put at his/her present value
function.
11.4.2
A Strategy for Pooling Present Value Functions
A coherent approach for pooling the n+1 present value functions mentioned above is via Bayes’
law. Since it is ’s whose actions that we need to prescribe, PT would form the basis of ’s
prior. How must  update PT using the PiTjs, j = 1	   	mi	i = 1	   	n? My proposal
is to use the non-parametric Bayes method of section 9.6.1 for doing the above. This material
0
T1
T2
T3
Tj
Tj+1
Holding
period
Present
value
Pi(Tj)
1
Figure 11.7
Present value function of i-th bond Issuer.

330
RELIABILITY AND SURVIVAL IN ECONOMETRICS AND FINANCE
entails the Dirichlet process prior, and data that are assumed to be generated by an underlying
distribution which prescribes their stochastic nature. Whereas PT	T ≥0 could form the basis
of a prior, we need a way to obtain the required data. Our proposal here is to generate the said
data by a simulation from the PiTjs, i =1	   	n, and j =1	   	mi. Our strategy of obtaining
the data via a simulation is not unlike that which one does in a bootstrap (Efron, 1979).
Generating Random Samples from Present Value Functions
A justification for generating the required data via a simulation from the present value functions
is provided by the feature that the present value function bears an isomorphic relationship with
a survival function (section 11.3.1). Consequently, we can see the likes of Figure 11.7 given
below as a proxy for the survival function from which random observations can be generated.
Figure 11.7 portrays PiTj, the present value function of the i-th bond issuer for investment
horizons T1	T2	   	Tmi. It is assumed to be a step-function, since investment horizons for bonds
are specified for fixed time intervals such as one year, three years, etc.
Suppose that a random variable of size ni is generated from PiTj	j =1	   	mi. Denote this
random sample by Xi =Xi1	   	Xini, and repeat this exercise for each of the nPiTjs to obtain
X1	   	Xn as data. We then update PT	T ≥0, using X1	   	Xn via Bayes’ law. The
updating procedure is straightforward if the Xis, i =1	   	n, are independent. When such is the
case, the updating can be done either sequentially using one Xi at a time, or simultaneously using
the entire set of X1	   	Xn. However, the assumption of independence needs to be evaluated
with scrutiny. This is because it is reasonable to suppose that P1Tj	   	PnTj will, for each
j, bear a relationship to each other. All bond issuers design their investment strategies using
common public information. Thus if a common seed (i.e. the set of uniform [0, 1] deviates used
to generate a random sample) is used to generate all the n sample vectors, then X1	   	Xn will
necessarily be dependent. Independence of the Xis can be better achieved by using a different
seed for each sample.
Prior to Posterior Analysis Using the Dirichlet Process Prior
A pooling by  of the n present value functions PiTj, i = 1	   	n and j = 1	   	mi, with
the aim of updating ’s PT, T ≥0, tantamounts to a prior to posterior analysis using Bayes’
law. Here PT would form the basis of the prior, and the simulated Xis, i = 1	   	n, as
the data. Our proposed strategy for doing the above is based on the Dirichlet process prior
based methodology of section 9.6.1, with PT serving as the ‘best guess’, and Theorem 9.2
as providing a mechanism for the prior to posterior transformation. The strategy can best be
described if the updating proceeds sequentially, first updating PT using X1, and then updating
the updated present value function using X2, and so on, invoking Theorem 9.2 at each step. The
specifics are described below.
To start the process,  focuses attention on some value of the investment horizon, say T ∗≥0,
and per the dictates of Theorem 9.2 supposes that
PT ∗ ∼Beta1 0	T ∗	1  −1 0	T ∗
Consequently, the expectation of PT ∗ is 1T ∗/1 , and its variance is
1T ∗1 −1T ∗
1T ∗ + 12 1 + 1
	
(11.13)
where 1T ∗ is shorthand for 1 0	T ∗. Setting 1T ∗/1 = PT ∗ and assigning a
number, say 2, to the variance (equation (11.13))  is able to obtain 1T ∗ and 1 in terms
of PT ∗ and 2.

INFERENTIAL ISSUES IN ASSET PRICING
331
With the above in place,  updates PT via the likes of (9.27) as
P1
 T = 1 −
1T +
n1
j=1
IX1j	T
1 + n1
	
(11.14)
where IAt is the indicator of set A, and T > 0.
For the second iteration, the 1T of the first iteration becomes 2T = 1T +
n1
j=1 IX1j	T, and 1 becomes 1 + n1. These, when plugged into (11.14), will give
P2
 T. Note that when obtaining P2
 T, the summation term in the numerator of (11.14) will
be n2
j=1 IX2j	T.
Repeating the above n times we obtain Pn
 T, T ≥0; Pn
 T is the pooled present value
function of , the pooling being done in a coherent manner. We may now set Pn
 T = P∗
T,
T ≥0;  will use P∗
T, T ≥0, to prescribe an investment strategy. An illustrative example
showing the workings of this approach is given in section 11.4.3.
Some General Comments on the Pooling Procedure
The pooling procedure described above need not be restricted to the pooling (or fusion) of present
value functions. In general, it can be used to pool distribution (survival) functions as well. The
pooling of distribution functions is a common exercise that is often performed in the context
of decision analysis wherein the fusing of expert testimonies is germane. Some more modern
applications of pooling distribution functions occur in the arenas of ‘target tracking’ and ‘sensor
fusion’. These activities occur in civilian, military and medical contexts.
As was mentioned before (section 9.6.1) a possible disadvantage of pooling distributions using
the Dirichlet process prior is that the pooled distribution is discrete with probability one. A
consequence is that the pooled present value function P∗
T, T ≥0, is not a smooth continuous
function of the investment horizon. This may not be a too serious a limitation in the context
of asset pricing. It could, in the contexts of target tracking and sensor fusion, be a limitation.
To overcome this limitation, one may consider pooling using the neutral to the right (NTR)
processes discussed in section 9.6.2. Their disadvantage, however, is an absence of closed form
results of the type that the Dirichlet process priors provide.
11.4.3
Illustrative Example: Pooling Present Value Functions
As an illustration of the workings of the material of section 11.4.2, suppose that PT is of
the form PT = exp−02T, with T ≥0; this is an exponential survival function. We focus
attention on T ∗= 1, so that P T ∗ = exp−02 = 0818, and suppose that 2, ’s measure of
uncertainty in specifying P T ∗ is 2 =001. These specifications would result in 1=1384
and 1T ∗ = 11332. With 1 known, we obtain 1T as 1T = exp−02T1.
Now suppose that P1Tj, the present value function of another bond issuer, is the piecewise
constant function of Figure 11.8. Here Tj = 1	3	5 and 6.
We generate a sample of size 5 from the P1T of Figure 11.8 regarding the same as a survival
function. Denote these as X11 = 1, X12 = 1, X13 = 3, X14 = 5, and X15 = 5. We then plug these
values into (11.14) to obtain
P1
 T = 1 −
1T +
5
j=1
IX1j	T
1 + 5
	
for T = 05	1	15	2	   	9	95 and 10. In Figure 11.9, I illustrate the behavior of PT and
P1
 T to show the effect of the other bond issuer’s present value function on ’s updated

332
RELIABILITY AND SURVIVAL IN ECONOMETRICS AND FINANCE
0
1
3
5
0.1
0.2
0.5
0.9
1
Holding period
Present value
6
Figure 11.8
P1T, a Bond issuer’s present value function.
0
10
7.5
5
2.5
0.2
0.4
0.6
0.8
1
Present value
P
(1)(T)
P(1)(T)
Holding period T 
Figure 11.9
’s Initial and updated present value functions
present value function. The smoothness of P1
 T will depend on the granularity of T that has
been chosen by us. We have chosen the granularity to be 0.5 and n1, the number of observations
to be simulated from P1 T, to be 5.
11.5
CONCLUDING COMMENTS
Investigators working in reliability and survival analysis are unlikely to view the material given
in this chapter as being mainstream vis-à-vis the above topics. Indeed one is hard pressed to
name other books in reliability and survival analysis that venture into topics such as economics,
finance and other social sciences such as gerontology and longevity. However, if a subject is
to thrive then its connections with other subjects should be attractive features. It is with this in
mind that I have chosen to include this chapter among the other more subject-related chapters.
All the same, what I have presented here is limited to my experience and exposures; i.e. I may

CONCLUDING COMMENTS
333
have only scratched the surface. Similarly, there may be other topics in physical, social and
the mathematical sciences wherein ideas and notions that are unique to reliability and survival
analysis may have a role to play. But there is also another side to this coin, namely, that ideas
and notions from other disciplines could enhance the state-of-the-art in reliability and survival
analysis as well. We have seen a few examples of these, such as the notion of a hazard potential
from physics, a use of the Lorenz curve for survival analysis from econometrics, and the hitting
times of stochastic hazard rates from finance. Connections with other disciplines also enable
us to re-think the conventional ideas from our own discipline. For example, the isomorphism
between the survival function and the present value function has enabled us to shed new light on
the exponentiation formula. We may now look at this stalwart formula of reliability and survival
analysis in the broader framework, as the law of a diminishing resource.


Appendix A
Markov Chain Monté Carlo
Simulation
Simulation techniques whose credibility is asserted by the theory of Markov Chains are termed
Markov Chain Monté Carlo methods, abbreviated MCMC. Such techniques have proved to be
very valuable for implementing Bayesian solutions to many standard statistical problems, includ-
ing those encountered in reliability and life-testing. MCMC techniques are easily implemented so
that Bayesian analyses can be made routinely available for addressing many commonly encoun-
tered problems. During the past several years, so much has been written about them and from so
many perspectives and points of view that what is given here can be aptly labeled elementary.
We shall focus on one algorithm, the ‘Gibbs sampling algorithm’.
A.1
THE GIBBS SAMPLING ALGORITHM
This is a Markovian updating scheme which can be used for estimating marginal distributions
from a joint distribution and for drawing inferences about non-linear functions of parameters of
chance distributions.
To illustrate the workings of this algorithm, suppose that px denotes the posterior density
of  = 1   k given data x. Suppose that px can be written out up to a constant of
proportionality, as is the case in a Bayesian analysis; i.e. px ∝xp, where  is the
likelihood and p the prior. Let pi−ix denote the conditional posterior density of i,
conditioned on the remaining elements of . Implicit to what follows is the assumption that the
above conditionals are able to specify the joint posterior px. This may not always be true;
Gelman and Speed (1993) give conditions under which the above is true. The Gibbs sampling
algorithm proceeds as follows:
Suppose that 0 = 0
1   0
k is some arbitrary (starting) value of . Then, 1
1 is a random
drawing from p10
2   0
kx – assuming that this can be done (and here lies the catch),
1
2 a drawing from p21
10
3   0
kx, 1
3 a drawing from p31
11
20
4   0
kx, and so
on, so that k is a draw from pk1
−kx. This process of substituting and drawing completes
a transition of  from 0 to 1 = 1
1   1
k. After t such transitions we arrive upon t =
t
1   t
k. The claim (cf. Smith and Roberts, 1993) is that the transitions 01   t
Reliability and Risk: A Bayesian Perspective
N.D. Singpurwalla
© 2006 John Wiley & Sons, Ltd

336
APPENDIX A
constitute a Markov Chain (for example, Çinlar, 1975), which for large values of t has a stationary
distribution that is precisely px. Consequently, for t large, t converges in distribution to a
random vector whose distribution is px, and the elements of t converge in distribution to
random variables whose distributions are the marginal distributions of px. Some regularity
conditions are involved, and these are discussed by Roberts and Smith (1993) (also see Athreya,
Doss and Sethuraman, 1996). Repeating the above procedure m times, making sure that the
starting values, like our 0, are independently chosen, yields m k-tuples t
1   t
m. These
m k-tuples can be regarded as a sample of size m from the k-variate posterior distribution
px. Furthermore, with t
i =t
1it
2i   t
ki, i =12   m, the vector t
j1t
j2   t
jm
is a sample of size m from the marginal posterior distribution jj = 1   k. For m large
this latter sample can be used to empirically construct the marginal posterior distribution of
j. Furthermore, if  is any function of j, then
1
m
m
r=1 t
jr is a consistent estimator of
E	jx
. This completes our discussion of the Gibbs sampling algorithm; some more details
can be found in the excellent tutorial article by Casella and George (1992). However, there is
some irony to the above scheme. It appears that in empirically estimating posterior distributions,
and in appealing to the consistency property of estimates of functions of unknown parameters, a
Bayesian uses perfectly honorable frequentist procedures for easing the computational burdens
that his/her paradigm imposes. But to conclude this topic, we need discuss two issues, one a
matter of concern and the other a virtue.
The first is that it may not be always possible to generate random samples from the conditional
distributions pi−ix. The nature of the likelihood and the prior could be such that their
product does not result in a form that is standard. A consequence is that the choice of priors could
be influenced by ones ability to generate the required samples. The second matter pertains to
the matter of censoring. This could result in a likelihood function that contains integrals. When
such is the case, one is unable to generate samples from pi−ix. To overcome this obstacle,
Gelfand, Smith and Lee (1992) propose an ingenious scheme, namely, treating the random
variables that are censored as unknowns, just like the unknown , and then invoking the Gibbs
sampling algorithm. This idea is best illustrated via a specific example.
Suppose that n items are subjected to a life-test and r of these are observed to fail at x =
x1   xr, and the remaining n −r are censored so that Cj ≤Xj ≤Dj, for j = r + 1   n.
The Cj and the Dj are assumed known and the lifetimes of the items have a distribution whose
density at x is fx; the prior on  is . Then, the posterior of , in the light of the available
information is
pCDx ∝
r
i=1
fxi
r
j=r+1
Di

Ci
fsjdsj
where C = Cr+1   Cn and D = Dr+1   Dn
If the second product term of the likelihood cannot be obtained in closed form, we will not
be able to sample from the conditionals, and the Gibbs sampling algorithm cannot be invoked.
However, since X′ = Xr+1   Xn have not been observed they are unknown, just like , and
can therefore be augmented with  in the Gibbs sampling algorithm. This process is called data
augmentation, an example of which also appears in section 5.4.7. Thus we need to consider the
conditionals of pX′CDx, namely pX′CDx and pX′CDx. But
pX′CDx =pX′x
and
pX′CDx =p
⎛
⎝X′CD =
n
j=r+1
Di

Ci
fsjdsj
⎞
⎠

THE GIBBS SAMPLING ALGORITHM
337
since  need not depend on C and D, and X′ need not depend on x. A striking feature of the
above is that pX′x is just the posterior distribution of  had there been no censoring, so that
random variate generation from pX′x proceeds along the same lines as in the case of a full
sample. Random variate generation from pX′CDx is simple, since it entails independent
draws from the truncated chance distribution fx. This would boil down to generating random
variates from the untruncated distribution, and retaining only those variates that fall within the
Cj and the Djj = r + 1   n. Thus we see that in treating the censored observations as
unknowns, we have uncoupled the complications in the likelihood into constituents that are more
manageable.


Appendix B
Fourier Series Models and the Power
Spectrum
B.1
PRELIMINARIES: TRIGONOMETRIC FUNCTIONS
The functions sin t and cost are periodic with period 2, i.e. sint +2=sin t, and cost +2=
cost, for t ≥0. Thus for any kk=0±1±2   , sint +2k=sin t, and cost +2k=cost.
It is easy to verify that for any constant  > 0, sin t and cost are also periodic with period
2/. The effect of the scalar  is to expand or contract the scale. The reciprocal of the period is
called the frequency; it represents the number of periods per unit of time. The largest (smallest)
value that sin t can take is +1−1; these occur at /2 and 3/2, respectively. Similarly, the
largest (smallest) value that cost can take is +1−1, but they occur at 0 (and 2) and ,
respectively.
A translation of the entire sine or cosine curve is achieved by introducing a shift parameter ,
called the phase. Specifically, sint + 2 − = sint −, and cost + 2 − = cost −
. Since cost has maxima at 2
 k, for k = 0±1±2   cost − will have maxima at
2k + /. Because cost − = cost · cos + sin t · sin 	cost − can be written as

cost + sin t, where 
 = 	cos and  = 	sin . Thus a translated cosine (or sine) curve
is a linear combination of a sine and a cosine function. Furthermore, since cos2  + sin2  =
1
2 + 2 = 	2cos2  + sin2  = 	2. Finally,  = tan−1/
, and the maximum value that
	cost − can take is 	; 	 is called the amplitude of 	cost −.
The foregoing material forms the basis of much that is to follow. It makes the key point
that by a judicious choice of 	,  and , I can obtain any desired shape of the sine and
cosine curves. Such curves enables me to approximate each number in a sequence of numbers
by a linear combination of a finite number of sines and cosines with varying amplitudes and
frequencies. How this can be done is described later in section B.3, but first an illustration
of the cost curve with  = 1/2, 1 and 2, and the cos2t − curve with  = /2 could be
helpful. This is done in Figure B.1 with the dotted curve showing the effect of the phase 
on cos2t.
Reliability and Risk: A Bayesian Perspective
N.D. Singpurwalla
© 2006 John Wiley & Sons, Ltd

340
APPENDIX B
π
2π
–1
1
t
0
cos t
cos 2t
cos   t
π
2π
–1
1
t
0
2
1 –
Figure B.1
A plot of cost, for  = 12 and 1/2, and of cos2t −/2.
B.2
ORTHOGONALITY OF TRIGONOMETRIC FUNCTIONS
Trigonometric functions possess an attractive property called orthogonality. This property is
stated in (a), (b) and (c) below; a proof can be found in Anderson (1971, p. 94).
Consider an integer, say T, where T>0. Let  T
2 =T/2 if T is even; otherwise  T
2 =T −1/2.
Then:
(a)
T
t=1
cos 2j
T t · cos 2k
T t =
⎧
⎪⎪⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎪⎪⎩
0 0 ≤k ̸= j ≤
T
2


T
2  0 < k = j < T
2 
T k = j = 0 or T
2 
(b)
T
t=1
cos 2j
T t · sin 2k
T t = 0kj = 01   
T
2

;
(c)
T
t=1
sin 2j
T t · sin 2k
T t =
⎧
⎪⎪⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎪⎪⎩
0 0 ≤k ̸= j ≤
T
2


T
2  0 < k = j < T
2 
0 k = j = 0 or T
2 

THE FOURIER REPRESENTATION OF A FINITE SEQUENCE OF NUMBERS
341
In (a), (b) and (c) above, the cosine and sine functions have periods T/j and frequencies j/T,
for j = 01    T
2 . The orthogonality property is advantageously exploited for representing
each of a set of T numbers as a finite sum of sines and cosines. This is described next.
B.3
THE FOURIER REPRESENTATION OF A FINITE SEQUENCE
OF NUMBERS
Consider a sequence of T numbers, y1   yT, and suppose that T is even. Let M be the
following T × T matrix:
M =
	
2
T
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
1
√
2
cos 2
T
sin 2
T
cos 4
T
···
sin 2
T
T
2 −1

−1
√
2
1
√
2
cos 2
T 2
sin 2
T 2
cos 4
T 2
···
sin 2
T
T
2 −1

2
1
√
2






1
√
2
1
0
1
···
0
1
√
2
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦

The orthogonality property ensures that M′M = I, where M′ is the transpose of M, and I is
the identity matrix; i.e. all the elements of I are zero, save the diagonal elements, which are one.
Let y = y1   yT′, and x = x1   xT′, where x = M′y. Since M′M = Iy = Mx. From
x = M′y, I have:
x1 = 1
√
T
T
t=1
yt
x2k =
	
2
T
T
t=1
yt cos 2k
T t
k = 12    T
2 −1
x2k+1 =
	
2
T
T
t=1
yt sin 2k
T t
k = 12    T
2 −1 and
xT = 1
√
T
T
t=1
yt−1t
The x1   xT given above are known as Fourier coefficients. Since y = Mx, we may write
ytt = 1   T as
yt =
	
2
T
 x1
√
2
+ x2 cos 2
T t + x3 sin 2
T t + ··· + xT−1 sin 2
T
T
2 −1

+ xT
−1t
√
2


(B.1)
The above representation of yt is known as the Fourier representation with Fourier coeffi-
cients x1   xT. The essence of (B.1) is that each yt can be written as a linear combination
of trigonometric functions, the trigonometric functions having the periods TT/2T/3    and
T/T/2 −1. Since T/T/2 −1>2, the smallest period is greater than 2; the largest period is T.
The Fourier coefficients can be interpreted as weights assigned to the trigonometric functions.

342
APPENDIX B
When T is odd, the development proceeds along similar lines, save for the fact that the last
column of M consisting of the 1/
√
2 terms is deleted. In this case
yt =
	
2
T
 x1
√
2
+ x2 cos 2
T t + x3 sin 2
T t + ··· + xT−1 sin 2
T
T
2 −1


(B.2)
In (B.1) and (B.2) above, let
Hkt = X2k cos 2
T kt + X2k+1 sin 2
T kt
for k = 12    T
2 −1 in the case of equation (B.1), and k = 12    T−1
2 , in the case of
equation (B.2). Observe that Hkt is a linear combination of a cosine and a sine curve with periods
T/k and frequency k/T. Let
	k = X2
2k + X2
2k+11/2 and k = tan−1X2k+1/X2k
then
Hkt = 	kcos
2
T kt + k


The quantity Hkt is called the k-th harmonic and 	k is called the amplitude of the k-th
harmonic. The first harmonic, namely H1t, is called the fundamental harmonic and its frequency
1/T is called the fundamental frequency; it is the smallest frequency. Multiples of 1/T – the
fundamental frequency – are known as harmonics of the fundamental frequency. Observe that
Hkt has frequency k/T.
B.4
FOURIER SERIES MODELS FOR TIME SERIES DATA
Suppose that y1   yT represent the observed values of a time series, and our aim is to propose
a model that generates these values. More importantly, we need to know if there are (hidden)
periodicities in these data, because, in the context of reliability and survival analysis, such
periodicities are indicators of possible defeats. To do so, we propose the following model for
describing the observations:
yt = ft + ut
t = 1   T
where ft is an unknown function of t and ut is a sequence of independent normally distributed
random variables with mean 0 and variance 2. If ft is periodic with some known period that
divides T, then ft can be expressed as a linear combination of sines and cosines via either
(B.1) or (B.2) depending on whether T is even or odd. However, to do so we need to know
the Fourier coefficients x1   xT−1; these we do not know, because ft is itself unknown.
However, the data y1   yT can be used to assess the unknowns, and to do so we proceed as
follows.
Suppose that T is odd, and consider the set of integers  = 12   T −1/2. Let
k1   kq be a subset of , i.e. q ≤T −1/2. For estimation and inference using a non-
Bayesian approach, like least squares, it is necessary that k1   kq be a proper subset of
, i.e. q < T −1/2. With k1   kq chosen, we consider functions of the form sin 2
T kjt

FOURIER SERIES MODELS FOR TIME SERIES DATA
343
and cos 2
T kjt, for j = 1   q. These functions have period T/kj and frequency kj/T; for
j = 1   q. Once this is done, we may – inspired by (B.2) – write ft as
ft = 
0 +
q
j=1


kjcos 2
T kjt + kjsin 2
T kjt


(B.3)
where 
0, 
kj and kjj =1   q are unknown constants, the latter pair being reminiscent
of Fourier coefficients.
If we let 	kj = 
2kj + 2kj1/2, and kj = tan−1kj/
kj, then

kj = 	kjcoskj and kj = 	kjsin kj
Consequently, (B.3) can also be written as:
ft = 
0 +
q
j=1
	kjcos
2
T kjt −kj


(B.4)
With (B.3) and (B.4) in place, assessing ft boils down to assessing 
0 and the 
kjs and
kjs, j = 1   q.
Note that in the above representations of ft, the trigonometric terms having period 2 do not
appear. To include such terms T needs to be even. When such is the case, I consider proper
subsets of 12   T/2, and now ft takes the form
ft = 
0 +
q
j=1
	kjcos
2
T kjt −kj

+ 
T/2−1t
(B.5)
the details are given in Anderson (1971), upon which this Appendix is almost exclusively based.
The representation of ft via (B.3)–(B.5) is known as a Fourier Series model.
As was stated before, the main reason for considering such models is to discover ‘hidden
periodicities’ that may be present in y1   yT. This is because the coefficient 	kj is a measure
of how closely the trigonometric function having frequency kj/T describes ft. In particular, if
a series of length T has a period, say , then the value 	kj corresponding to kj =T/ will tend
to be the largest among all the other 	kjs. Thus, for example, the choice q = 1 with k1 = 1,
reflects the belief that there are no hidden periodicities. In this case
ft = 
0 + 
1cos 2
T t + 1sin 2
T t
this is known as the simple one-harmonic model.
B.4.1
The Spectrum and the Periodgram of ft
A plot of 	2kj=
2kj+2kj versus the frequency kj/Tj =1   q is called the spectrum
(or the power spectrum) of ft. A plot of 	2kj versus T/kj, the period, is called a periodgram.
When T is odd, the largest value that q can take is T −1/2. Thus the smallest value of the
period T/kq is 2T/T −1 > 2. When T is even, the largest value that q can take is T/2. Thus
the smallest value of the period is 2. Thus in either case, the periodgram is defined as for periods
≥2. Similarly, the spectrum is defined for frequencies ≤2. The spectrum has an advantage over
the periodgram in the sense that it is evenly spaced over the frequencies. Thus it is the power
spectrum, rather than the periodgram, that is often used by engineers as a working tool. It is
often the case that in engineering applications, Hertz (Hz) is used as the unit for expressing
frequencies. A Hz is the smallest frequency of the spectrum, and it represents the number of
cycles (revolutions) per second of rotating machinery.


Appendix C
Network Survivability and Borel’s
Paradox
C.1
PREAMBLE
The material of this appendix supplements that of section 10.3.4 on prior distributions on the
unit hypercube and becomes relevant under certain circumstances. These circumstances will
be outlined here. Borel’s paradox is a paradox in probability theory which has implications in
modeling and inference. The paradox arises when probabilities from a high dimensional non-
discrete space get induced to its lower dimensional subspace using conditional arguments that
are ill-defined. There are circumstances in system survivability assessment wherein we may
be required to induce probabilities from high dimensional spaces to their lower dimensional
subspaces. When such is the case, one should be cognizant of encountering Borel’s paradox,
because in so doing we will be lead to results that are counter to common belief.
To set the stage for the material that follows, we look at (10.10) of Section 10.3.3 for the
survivability of the system. Writing p for p1   pn and dp for dp1   dpn,
we have
P =

p
hppdp
(C.1)
as our expression for system survivability. Recall that p encapsulates our uncertainty about
p, and is a probability distribution on the unit hypercube. The matter I wish to focus on here
pertains to an assessment of p via expert testimonies and some nuances that such testimonies
can create.
C.2
RE-ASSESSING TESTIMONIES OF EXPERTS WHO HAVE
VANISHED
To set the stage for motivating a scenario wherein Borel’s paradox can come into play, let us
consider the situation wherein an expert  (or a collection of experts acting as one) is consulted,
and p, a prior for p, elicited as the expert’s testimony about p. Suppose that once p
has been elicited  is no longer available; i.e.  has ‘vanished’. This type of situation is not
Reliability and Risk: A Bayesian Perspective
N.D. Singpurwalla
© 2006 John Wiley & Sons, Ltd

346
APPENDIX C
fictitious and occurs in the context of thermonuclear weapons systems. The original physicists
who witnessed actual detonations (which can now not be conducted due to test-ban treaties)
have played key roles in specifying the likes of p, but are no longer alive. Suppose further
that much after p gets specified, we receive now unanticipated information which suggests
that all the nodes of the networked system are identical so that p1 = p2 =    = pn = p,
say. How must we update p in light of this new additional information? We assume that
p is credible, and so is the new information. Since  has vanished we are unable to elicit a
re-assessed p from .
The strategy we propose here is called retrospective conditioning (cf. Diaconis and Zabell,
1982); it goes as follows. Since p is defined on a unit hypercube of dimension n ≥2,
and since the new information says that all the pi’s be equal to p, we need to induce a
one dimensional prior from p. Since p is continuous, the diagonal joining the points
00   0 and 11   1 has an n-dimensional Lebesgue measure zero. Consequently, to
induce a one-dimensional prior from p we need to condition on a set of measure zero.
But conditioning on sets of measure zero entails a limiting argument, which in this case is
not unique. Consequently, we obtain different answers for the induced one dimensional prior,
and thus different assessments of system survivability. This is known as the Borel–Kolmogorov
Paradox (DeGroot 1989, pp. 171–174). An example in two dimensions illustrates this point.
C.3
THE PARADOX IN TWO DIMENSIONS
Let P be a point described by its Cartesian coordinates X and Y, 0 ≤X ≤1 and 0 ≤Y ≤1; X
and Y are random. Suppose that P has a uniform distribution on the unit square. What is the
distribution of X were we to be told that P lies on the diagonal; i.e. we are to condition on
X = Y?
It turns out that our answer depends on how we parameterize the diagonal; by Z = X/Y = 1
or by W = X −Y = 0. More specifically, if fXZ=1x denotes the probability density of X at
x, conditional on Z = 1, and fXW=0x the density conditional on W = 0, then fXZ=1x = 2x
whereas fXW=0x = 1. There are two answers to the same question and both are correct. The
details are given in Appendix A of Singpurwalla and Swift (2001). An intuitive explanation as
to why we obtain two answers to the same question is based on geometrical considerations. It
can be appreciated by an examination of Figures C.1 and C.2. These figures illustrate the feature
that the conditioning set X = Y can involve two different limiting operations, each leading to a
different probability. The shaded regions of these figures indicate the limiting operations. The
paradox will not arise if the limiting operation were to be unique or be specified as a protocol.
0
1
1
Y
X
Figure C.1
Diagonal parameterized as W = X −Y = 0.

THE PARADOX IN NETWORK SURVIVABILITY ASSESSMENT
347
0
1
1
Y
X
Figure C.2
Diagonal parameterized as Z = X/Y = 1
In Figure C.1, values of W in the vicinity of 0 can be described by W ≤, where  is
small. This means that X and Y must satisfy the relationship X − ≤X ≤X + , and since
XY ∈01, we must have max0Y −≤X ≤min1Y + . The parallel lines of Figure C.1
enveloping the diagonal imply that all values of X (save those at the ends of the diagonal) can be
judged equally likely, and so the distribution of X, given that X = Y, is uniform; consequently
fXW=0x = 1. By contrast, suppose that in Figure C.2 values of Z in the vicinity of 1 are
described by 1 − ≤Z ≤1 + , where  is small. Then X and Y must satisfy the inequalities
max0Y −Y ≤X ≤min0Y + Y; see the shaded region of Figure C.2. The geometry of
the cone in the shaded region suggests that values of X in the vicinity of 1 are more likely than
those in the vicinity of zero; as a consequence fXZ=1x = 2x.
The moral of the story here is that conditioning arguments involving limiting operations that
are not uniquely specified lead to a paradox. Thus the cause of the paradox is the freedom (or
flexibility) given to us in defining the diagonal and characterizing its vicinity. The paradox will
not arise if the manner in which we need to partition the sample space is specified in advance as a
protocol. The importance of protocols in conditional probability assessment has been emphasized
by Shafer (1985) (also Lindley, 1982a).
C.4
THE PARADOX IN NETWORK SURVIVABILITY ASSESSMENT
To appreciate the effect of Borel’s paradox in the context of system survivability assessment,
consider a two component series system with component i having reliability pi, i = 12, and
p1p2 = 10 ≤pi ≤1. Here (C.1) takes the form
P =

p1p2
p1p2 dp1 dp2	
Suppose now that subsequent to the specification of p1p2 we are told that the two com-
ponents are identical. This statement can be mathematically cast in one of two possible ways,
namely, that
Pp1 ≤p = Pp2 ≤p
for all p ∈01
(C.2)
or that for some p ∈
01,
Pp1 ∈pp + dpp2 ∈pp + dp →1
as dp ↓0

348
APPENDIX C
and also that
Pp2 ∈pp + dpp1 ∈pp + dp →1
as dp ↓0
(C.3)
i.e. p1 = p2 = p, say.
When (C.2) is invoked, the paradox will not arise. The paradox will arise when (C.3) is
invoked. With p1 =p2 =p used as a conditioning argument, the induced probability pp1 =p2
has its mass concentrated on the diagonal so that now
P =

p
p2pp1 = p2dp =
⎧
⎪⎨
⎪⎩
1
3
if p1 = p2 is represented as p1 −p2 = 0
1
2
if p1 = p2 is represented as p1/p2 = 1	
Similarly, in the case of a parallel-redundant system,
P =

p
2p −p2pp1 = p2dp =
⎧
⎪⎨
⎪⎩
2
3
if p1 = p2 is represented as p1 −p2 = 0
5
6
if p1 = p2 is represented as p1/p2 = 1	
Generalizing to the case of n components in series, the survivability of the system can be shown
to be (see Appendix B of Singpurwalla and Swift (2001)) 1/n + 1 or
1
2 depending on how
we represent p1 = p2 = ··· = pn. In the parallel redundant case the corresponding answers are
n/n + 1 and 1 −n!2/2n!, respectively. As n ↑	, the survivability of the parallel system
goes to one, as is expected, though at different rates. However, in the case of a series system, the
survivability of the system can stay put at 1
2, irrespective of how large n becomes, were we to
represent p1 =p2 =···=pn via pi/pj =1∀i̸=j. This result is counter to common belief, namely
that the survivability of a series system should decrease to zero as the number of components
increases.

Bibliography
Aalen, O.O. (1987) Dynamic modelling and causality. Scandinavian Actuarial Journal, 177–90.
Aalen, O.O. (1989) A linear regression model for analysis of life times. Statistics in Medicine, 8, 907–25.
Aalen, O.O. and Gjessing H.K. (2001) Understanding the shape of the hazard rate: A process point of view.
Statistical Science, 16 (1), 1–13.
Aalen, O.O. and Huseby, E. (1991) statistical analysis of repeated events forming renewal processes.
Statistics in Medicine, 10, 1227–240.
Abel, P.S. and N.D. Singpurwalla (1993) To survive or to fail: That is the question. American Statistician,
48 (1), 18–21.
Al-Mutairi, D., Y. Chen and N.D. Singpurwalla (1998) An adaptive concatenated failure rate model for
software reliability. Journal of the American Statistical Association, 93 (443), 1150–63.
Andersen, P.K., O. Borgan, R.D. Gill and N. Keiding (1993) Statistical Models Based on Counting Processes.
Springer-Verlag, New York, NY.
Anderson, T.W. (1958) An Introduction to Multivariate Statistical Analysis, John Wiley, New York, NY.
Anderson, T.W. (1971) The Statistical Analysis of Time Series, John Wiley, New York, NY.
Antelman, G. and Savage, I.R. (1965) Characteristic functions of stochastic integrals and reliability problems.
Naval Res. Logist. Quart., 12, 199–22.
Arjas, E. (1981) The failure and hazard processes in multivariate reliability systems. Math. Oper. Res., 6,
551–62.
Arjas, E. and M. Bhattacharjee (2004) Modeling heterogeneity in repeated failure time data: A hierarchical
Bayesian approach, In Mathematical Reliability (eds R. Soyer, T. Mazzuchi and N.D. Singpurwalla),
Kluwer Academic Publishers, Norwell, MA.
Arjas, E. and Gasbarra, D. (1994) Nonparametric Bayesian inference from right censored survival data,
using the Gibbs sampler. Statistica Sinica, 4, 505–24.
Arnauld, A. and P. Nicole (1662) l’Art de Penser, Paris.
Arnold, B., E. Castillo, and J.M. Sarabia (1992) Conditionally specified distributions, Lecture Notes in
Statistics, Springer-Verlag.
Ascher, H. and H. Fiengold (1984) Repairable systems reliability, Dekker, New York, NY.
Athreya, K.B., H. Doss and J. Sethuraman (1996) On the convergence of the Markov chain simulation
method. The Annals of Statistics, 24 (1), 69–100.
Atkinson, A.C. (1979) A family of switching algorithms for the computer generation of Beta Random
Variables. Biometrika, 66, 141–45.
Aven, T. and U. Jensen (1999) Stochastic Models in Reliability, Springer-Verlag, New York, NY.
Bagdonavicius, V. and M. Nikulin (2001) Accelerated Life Models: Modeling and Statistical Analysis,
Chapman and Hall/CRC, London.
Barlow, R.E. (1985) A Bayes explanation of an apparent failure rate paradox. IEEE Transactions on
Reliability, R-34, 107–8.
Barlow, R.E. (1988) Using influence diagrams. In Accelerated Life Testing and Experts’ Opinions in
Reliability (eds C.A. Clarotti and D.V. Lindley), Elsevier, New York, NY, pp. 145–57.
Reliability and Risk: A Bayesian Perspective
N.D. Singpurwalla
© 2006 John Wiley & Sons, Ltd

350
BIBLIOGRAPHY
Barlow, R.E. and R. Campo (1975) Total time on a test process and applications to failure data analysis.
In Reliability and Fault Tree Analysis: Theoretical and Applied Aspects of System Reliability and Safety
Assessment (eds R.E. Barlow, H.B. Fussell and N.D. Singpurwalla), SIAM, Philadelphia, PA.
Barlow, R.E., C.A. Clarotti and F. Spizzichino (eds) (1993) Reliability and Decision Making, Elsevier,
New York, NY.
Barlow, R.E., H.B. Fussell and N.D. Singpurwalla (eds) (1975) Reliability and Fault Tree Analysis:
Theoretical and Applied Aspects of System Reliability and Safety Assessment, SIAM, Philadelphia, PA.
Barlow, R.E. and J.H. Hsiung (1983) Expected information from a life test experiment. Statistician, 32,
35–45.
Barlow, R.E. and M.B. Mendel (1992) de Finetti-type representations for life distributions. Journal of the
American Statistical Association, 87, 1116–22.
Barlow, R.E. and C.A.B. Pereira (1990) Conditional independence and probabilistic influence diagrams.
In Topics in Statistical Dependence, IMS Lecture Notes-Monograph Series 16 (eds. H.W. Block, A.R.
Sampson and T.H. Savits), 19–33.
Barlow, R.E. and F. Proschan (1965) Mathematical Theory of Reliability, John Wiley, New York, NY.
Barlow, R.E. and F. Proschan (1975) Statistical Theory of Reliability and Life Testing. Holt, Rinehart, and
Winston, Inc., New York.
Barlow, R.E. and F. Proschan (1981) Statistical Theory of Reliability and Life Testing: Probability Models,
TO BEGIN WITH, Silver Spring, MD.
Barndorff-Nielsen, O., Blaesid, P. and Halgreen, C. (1978) First hitting time models for the generalized
inverse Gaussian distribution. Stochastic Processes aand their Applications, 7, 49–54.
Basu, A.P. (1971) Bivariate Failure Rate. Journal of the American Statistical Association, 66, 103–4.
Basu, D. (1975) Statistical information and likelihood (with discussion). Sankhyä, A (37), 1–71.
Bayes, T. (1763) An essay towards solving a problem in the doctrine of chances. The Philosophical
Transactions of the Royal Society, 53, 370–418. (Reprinted by Biometrika, 45, 293–315).
Bement, T.A., J.A. Booker, and N.D. Singpurwalla (2002) Testing the Untestable: Reliability in the 21st
Century. Technical Report GWU/IRRA Serial TR-99/6. The George Washington University.
Bemis, B.M., L.J. Bain, and J.J. Higgins (1972) Estimation and hypotheses testing for the parameters of a
bivariate exponential distribution. Journal of the Royal Statistical Association, 67, 927–29.
Bement, T.R., J.M. Booker, S. Keller-McNulty, and N.D. Singapurwalla (2003) Testing the untestable:
Reliability in the 21st century. IEEE Trans. On Reliability, 52 (1): 118–24.
Berger, J.O. (1985) Statistical Decision Theory and Bayesian Analysis, 2nd edn, Springer-Verlag,
New York, NY.
Berger, J.O. and J.M. Bernardo (1992) On the Development of Reference Priors. In Bayesian Statistics
4 (eds, Bernardo, J.M., Berger, J.O., Dawid, A.P., Smith, A.F.M.) Oxford University Press, Oxford,
pp. 35–60 (with discussion).
Berger, J.O. and D.A. Berry (1988) Statistical analysis and the illusion of objectivity. American Scientist,
March–April, 159–65.
Berger, J.O. and M. Delampady (1987) Testing of precise hypotheses. Statistical Science, 2, 317–52.
Berger, J.O. and L.R. Pericchi (1996) The intrinsic Bayes factor for model selection and prediction. Journal
of the American Statistical Association, 91, 109–22.
Berger, J.O. and R. Wolpert (1988) The Likelihood Principle, IMS Lecture Notes-Monograph Series 6, 2nd
edn. Institute of Mathematical Statistics, Hayward, CA.
Bergman, B. (1977) Crossings in the total time on test plot. Scandinavian Journal of Statistics, 4, 171–77.
Bernardo, J.M. (1979a) Reference posterior distributions for Bayesian inference. Journal of the Royal
Statistical Society, Ser. B (41), 113–47.
Bernardo, J.M. (1979b) Expected information as expected utility. Annals of Statistics, 7 (3), 686–90.
Bernardo, J.M. (1997) Non-informative priors do not exist: A dialogue with José Bernardo. Journal Statistical
Planning and Inference, 65, 158–89.
Bernardo, J.M. and A.F.M. Smith (1994) Bayesian Theory, Wiley, Chichester.
Betró, B. and R. Rotondi (1991) On Bayesian inference for the inverse Gaussian distribution, Statistics and
Probability Letters, 11 (3), 219–24.
Bhattacharyya, G.K. and R.A. Johnson (1973) On a test of independence in a bivariate exponential distri-
bution. Journal of the American Statistical Association, 68, 704–06.

BIBLIOGRAPHY
351
Birnbaum, Z.W. and Saunders, S.C. (1969) A new family of life distributions. Journal of Applied Probability,
6, 319–27.
Black, M. (1939) Vagueness: An exercise in logical analysis. Philosophy of Science, 427–55.
Blackwell, D. (1973) Discreteness of ferguson selections. Annals of Statistics, 1, 356–58.
Blackwell, L.M. and N.D. Singpurwalla (1988) Inference from accelerated life tests using filtering in colored
noise. Journal of the Royal Statistical Society, Series B, 50 (2), 281–92.
Block, H.W. and A.P. Basu (1974) A continuous bivariate exponential extension. Journal of the American
Statistical Association, 69 (348), 1031–37.
Block, H.W. and T.H. Savits (1997) Burn-In. Statistical Science, 12 (1), 1–13.
Block, H.W., T. Savits and H. Singh (1998) The reversed hazard rate function. Probability in the Engineering
and Information Sciences, 12, 69–90.
Blumenthal, R.M., Getoor, R.K. and McKean. H.P. (1962) Markov process with identical hitting distribu-
tions. Illinois Journal of Mathematics, 6, 402–20.
Bogdanoff, J.L. and Kozin, F. (1985) Probabilistic Models of Cumulative Damage. John Wiley & Sons,
New York, NY.
Boland, P.J. and F.J. Samaniego (2004) The signature of a coherent system. In Mathematical Reliability:
An Expository Perspective, (eds Soyer, Mazzuchi and Singpurwalla), Kluwer Academic Press, Norwell,
MA, pp. 3–30.
Borel, E. (1914) Introduction geometrique a quelques theories physiques, Gauthier-Villars, Paris.
Box, G.E. and G.C. Tiao (1992) Bayesian Inference in Statistical Analysis, John Wiley, New York, NY.
Brieman, L. (2001) Statistical modeling: The two cultures. Statistical Science, 16 (3), 199–231.
Brooks R.J. (1982) On the loss of information through censoring. Biometrika, 69, 137–44.
Brown, M. and Proschan, F. (1982). Imperfect Repair. Journal of Applied Probability, 20, 851–59.
Bryson, M.C. and Siddiqui, M.M. (1969) Some criteria for ageing. Journal of American Statistical Associ-
ation, 64, 1472–85.
Cameron, R. and Martin, W. (1944) The Wiener measure of Hilbert neighborhoods in the space of real
continuous functions. Journal of Mathematical physics, 23, 195–209.
Campodónico, S. (1993) Bayes analysis of survival times and reliability data: A software package. In
Proceedings of the Annual Reilability and Maintainability Symposium, Atlanta, GA, pp. 163–166.
Campodónico, S. and N.D. Singpurwalla (1994a) A Bayesian analysis of the logarithmic-Poisson execution
time model based on expert opinion and failure data. IEEE Transactions on Software Engineering, 20,
677–83.
Campodónico, S. and N.D. Singpurwalla (1994b) The signature as a covariate in reliability and biometry.
In Aspects of Uncertainty, (eds. P.R. Freedman and A.F.M. Smith), New York, NY, John Wiley, 119–47.
Campodónico, S. and N.D. Singpurwalla (1995) Inference and predictions from Poisson point processes
incorporating expert knowledge, Journal of the American Statistical Association, 90 (429), 220–6.
Carnap, R. (1950) Logical Foundations of Probability, University of Chicago Press, Chicago, IL.
Casella, G. (1996) Statistical inference and Monte Carlo algorithms. Test, 5, 249–340 (with discussion).
Casella, G. and E.I. George (1992) Explaining the Gibbs sampler. The American Statistician, 46 (3), 167–74.
Chaloner, K.M. and G.T. Duncan (1983) Assessment of a beta distribution: PM elicitation. The Statistician
32, 174–80.
Chandra, N.K. and D. Roy (2001) Some results on reversed hazard rate. Probability in the Engineering and
Informational Sciences, 15, 95–102.
Chandra, M. and N.D. Singpurwalla (1981) Relationships between notions which are common to reliability
theory and economics. Mathematics of Operations Research, 6 (1), 113–21.
Chandra, M., N.D. Singpurwalla and M.A. Stephens (1981) Kolmogorov statistics for tests of fit for
the extreme-value and Weibull distributions. Journal of the American Statistical Association, 76 (375),
729–31.
Chari, M.K. and Colbourn, C.J. (1998) Reliability polynomials: A survey. Journal of Combinatorics,
Information and System Sciences.
Chaudhuri, G. and J. Sarkar (1998). “On the Crossing Property of the Reliability Functions of a Coherent
System in a Random Environment”. Technical Report. Department of Mathematical Sciences, Indiana
University – Purdue University, Indianapolis.
Chen, J. and Singpurwalla, N.D. (1994a) The notion of ‘composite reliability’ and its hierarchical Bayes
estimation. JASA, 91, 1474–484.

352
BIBLIOGRAPHY
Chen, Y. and N.D. Singpurwalla (1994b) A non-Gaussian Kalman filter model for tracking software
reliability. Statistica Sinica, 4 (2), 535–48.
Chen, J. and N.D. Singpurwalla (1996) Composite reliability and its hierarchical Bayes estimation. Journal
of the American Statistical Association, 91 (436), 1474–484.
Chen, Y. and N.D. Singpurwalla (1997) Unification of software reliability models via self-exciting point
processes. Advances in Applied Probabilitiy, 29 (2), 337–52.
Chernoff, H. (1954) Rational selection of decision functions. Econometrica, 22, 422–43.
Chhikara, R.S. and Folks, J.L. (1977) The inverse Gaussian distribution as a lifetime model. Technometrics,
19, 461–68.
Chipman, H., E.I. George and R.E. McCulloch (2001) The practical implementation of Bayesian model
selection. In Model Selection, IMS Lecture Notes – Monograph Series, Vol. 38.
Çinlar, E. (1972) Markov additive processes II. Z. Wahrsch. Verw. Gebiete, 24, 94–121.
Çinlar, E. (1975) Introduction to Stochastic Processes, Prentice-Hall, Inc, Englewood Cliffs, NJ.
Çinlar, E. (1977) Shock and wear models and Markov additive processes. The Theory and Applications of
Reliability, Academic, New York, NY.
Çinlar, E. (1979) On increasing continuous processes. Applied Stochastic Processes, 9, 147–54.
Çinlar, E. and S. Ozekici (1987) Reliability of complex devices in random environments. Probability in the
Engineering and Informational Sciences, 1, 97–115.
Clarotti, C.A. and F. Spizzichino (1990) Bayes burn-in decision procedures. Probability in the Engineering
and Informational Sciences, 4, 437–45.
Clemen, R.T. (1991) Making Hard Decisions, PWS-Kent, Boston, MA.
Connor, R.J. and Mosimann, J.E. (1969) Concepts of independence for proportions with a generalization of
the Dirichlet distribution. American Statistical Association Journal, 194–206.
Cornfield, J. (1957) The estimation of probability of developing a disease in the presence of competing
risks. American Journal of Public Health, 47, 601–07.
Cornfield, J. (1969) The Bayesian outlook and its application. Biometrics, 25, 617–41.
Cowell, R.G., A.P. Dawid, S.L. Lauritzen and D.J. Spiegelhalter (1999) Probabilistic Networks and Expert
Systems, Springer-Verlag, New York, NY.
Cox, D.R. (1972) Regression models and life tables (with discussion). Journal of the Royal Statistical
Society, B 34: 187–220.
Cox, D.R., Fitzpatrick, R., Fletcher, A.E., Gore, S.M., Spiegelhalter, D.J. and Jones, D.R. (1992) Quality-
of-life assessment: Can we keep it simple?. Journal of the Royal Statistical Society, Series A, 155,
353–93.
Cox, D.R. and V. Isham (1980) Point Processes, Chapman & Hall, London.
Crowder, M.J., A.C. Kimber, R.L. Smith, and T.J. Sweeting (1991) Statistical Analysis of Reliabilitiy Data,
Chapman & Hall, New York, NY.
Cui, Y., C. W. Kong and N.D. Singpurwalla (2002) Information fusion for damage prediction. In Case
Studies in Reliability and Maintenance, (eds, W. Blischke, and D.N.P. Murthy), John Wiley & Sons, Inc,
New York, NY, 251–65.
Currit, A. and N.D. Singpurwalla (1988). “On the Reliability Function of a System of Components Sharing
a Common Environment”. Journal of Applied Probability, 25, 4, 763–771.
Dale, C.J. and Winterbottom, A. (1986) Optimal allocations of effort to improve system reliability. IEEE
Transactions on Reliability, R-35 (2), 188–91.
Damien, P., Laud, P.W. and Smith, A.F.M. (1995) Approximate random variate generation from infinitely
divisible distributions with applications to Bayesian inference. JRSS B, 57 (3), 547–63.
Danaher, P.J. and Hardie, B.G.S. (2005). “Bacon With Your Eggs? Applications of a New Bivariate
Beta-Binomial Distribution”. The American Statistician, 59, 4, 287–291.
Dawid, A.P. (1997) Comments on ‘non-informative priors do not exist’. Journal of Statistical Planning and
Inference, 65, 159–89.
de Finetti, B. (1937) La prevision: ses lois logiques, ses sources subjectives. Annales de l’Institut Henri
Poincare, 7, 1–68.
de Finetti, B. (1938) Sur la condition d’equivalence partielle. Actualites Scientifiques et Industrielles, 739,
pp. 5–18. Herman, Paris, (Translated in Studies in Inductive Logic and Probability II (ed. R. Jeffrey)
University of California, Berkeley, CA.)
de Finetti, B. (1972) Probability, Induction and Statistics, Wiley, New York.

BIBLIOGRAPHY
353
de Finetti, B. (1974) Theory of Probability, John Wiley, New York, NY.
de Finetti, B. (1976) Probability: beware of falsification!. Scientia, 111, 283–303.
DeGroot, M.H. (1970) Optimal Statistical Decisions, McGraw-Hill, New York, NY.
DeGroot, M.H. (1984) Changes in utility as information. Theory Decision, 17, 287–303.
DeGroot, M.H. (1989). Probability and Statistics. Addison-Wesley.
De Moivre, A. (1718) The Doctrine of Chances, London.
Dempster, A.P. (1968) A generalization of Bayesian inference. Journal of the Royal Statistical Society, B
30, 205– 47.
Dey, J., Erickson, R.V. and R.V. Ramamoorthi (2003) Some aspects of neutral to right priors. International
Statistical Review, 71 (2), 383–401.
Diaconis, P. (1988) Recent progress on de Finetti’s notions of exchangeability. In Bayesian Statistics 3,
(eds J.M. Bernardo, M.H. DeGroot, D.V. Lindley and A.F.M. Smith), Clarendon, Oxford, 111–25.
Diaconis, P. and D. Freedman (1979) de Finetti’s generalization of exchangeability. In Foundations of
Subjective Probabilities, (ed. R. Jeffrey), University of California Press, Los Angeles, CA, 233–49.
Diaconis, P. and D. Freedman (1980) Finite exchangeable sequences. The Annals of Probability, 8, 745–64.
Diaconis, P. and D. Freedman (1981) Partial exchangeability and sufficiency. In Statistics: Applications and
New Directions, (eds. J.K. Ghosh and J. Roy), Indian Statistical Institute, Calcutta, India, 205–36.
Diaconis, P. and D. Freedman (1987) A dozen de Finetti-style results in search of a theory. Annales de
l’Institut Henri Poincare Probabilities et Statistiques, 23, 397–423.
Diaconis, P. and S.L. Zabell (1982) Updating subjective probability. Journal of the American Statistical
Association, 77, 822–30.
Doksum, K. (1974) Tailfree and neutral random probabilities and their posterior distributions. The Annals
of Probability, 2 (2), 183–201.
Doksum, K.A. (1991) Degradation models for failure time and survival data. CWI Quarterly, Amsterdam,
4, 195–203.
Downton, F. (1970) Bivariate exponential distributions in reliability theory. Journal of the Royal Statstical
Society, Series B, 33 (3), 408–17.
Durham, S.D. and W.J. Padgett (1997) A cumulative damage model for system failure with application to
carbon fibers and composites. Technometrics, 39, 34–44.
Durham, S.D., Lynch J. and W.J. Padgett (1989) A theoretical justification for an increasing failure rate
average distribution in fibrous composites. Naval Research Logistics, 36, 655–61.
Dykstra, R.L. and Laud, P. (1981) A Bayesian Approach to Reliability. The Annals of Statistics, 9 (2),
356–67.
Ebrahimi, N. and E.S. Soofi (1990) Relative information loss under Type II censored exponential data.
Biometrika, 77 (2), 429–35.
Efron, B. (1978) Controversies in the foundation of statistics. American Mathematical Monthly, 85, 231–46.
Efron, B. (1979) Bootstrap methods: another look at the Jackknife. The Annals of Statistics, 7 (1): 1–26.
Efron, B. (1986) Why isn’t everyone a Bayesian? The American Statistician, 40, 1–5.
El-Neweihi, E. and Proschan, F. (1984) Degradable systems: A survey of multistate system theory.
Communications in Statistics: Theory and Methods, 13, 405–32.
El-Sayyad, G.M. (1969) Information and sampling from the exponential distribution. Technometrics,
11 (1): 41–5.
Esary, J.D., Marshall, A.W. and Proschan, F. (1973) Shock models and wear processes. Annals of Probability,
1, 627–49.
Esary, J.D., F. Proschan, and D.W. Walkup (1967) Association of random variables, with applications The
Annals of Mathematical Statistics, 38 (5): 1466–1474.
Falk, J.E., Singpurwalla, N.D. and Vladimirsky, Y.Y. (2006) Reliability allocations for networks and
systems. Siam Review, 48, 43–65.
Falk, J.E. and Soland, R.M. (1969) An algorithm for separable nonconvex programming problems.
Management Science, 15 (9), 550–69.
Fratta, L. and Montanari, U.G. (1976) Synthesis of available networks. IEEE Transactions on Reliability,
R-25, 81–7.
Feller, W. (1968). An Introduction to Probability Theory and Its Applications I. John Wiley & Sons, Inc,
New York.

354
BIBLIOGRAPHY
Feller, W. (1966) An Introduction to Probability Theory and Its Applications II, John Wiley & Sons, Inc,
New York.
Feller, W. (1968) An Introduction to Probability Theory and Its Applications, 3rd edn. Vol. 1. John Wiley
& Sons, Inc, New York.
Ferguson, T.S. (1973) A Bayesian analysis of some nonparametric problems. The Annals of Statistics, 1 (2),
209–30.
Ferguson, T.S. (1974) Prior distributions on spaces of probability measures. The Annals of Statistics, 2,
615–29.
Ferguson, T.S. and Phadia, E.G. (1979) Bayesian nonparametric estimation based on censored data. The
Annals of Statistics, 7 (1), 163–76.
Ferguson, T.S., Phadia, E.G. and Tiwari, R.C. (1992) Bayesian nonparametric inference. Current Issues in
Statistical Inference: Essays in Honor of D. Basu, 127–50.
Forman, E.H. and R.F. Dyer (1991) An Analytical Approach to Marketing Decisions, Prentice Hall,
Englewood Cliffs, NJ.
Fréchet, M. (1951) Sur une application de la statistique mathematique a la biology Biometrics, 7 (2), 180–84.
Fréchet, M. (1974) Sur les tableaux de correlation dont les marges sont donnés. Annales de l’Université de
Lyon, Series 3, 14, 53–77.
Freedman, D. (1962) Invariants under mixing which generalize de Finetti’s theorem. The Annals of Mathe-
matical Statistics, 33, 916–23.
Freund, J.E. (1961) A bivariate extension of the exponential distribution. Journal of the American Statistical
Association, 56, 971–77.
Funahashi, K. (1989). “On the Approximate Realization of Continuous Mappings by Neural Networks”.
Neural Networks, 2, 183–192.
Gail, M. and J.L. Gastwirth (1978a) A scale-free goodness-of-fit test for the exponential distribution based
on the Lorenz curve. Journal of the American Statistical Association, 73, 787–93.
Gail, M. and J.L. Gastwirth (1978b) A scale-free goodness-of-fit test for the exponential distribution based
on the Gini statistic. Journal of the Royal Statistical Society B, 40, 350–57.
Gallager, R.G. (1968) Information Theory and Reliable Communication, John Wiley, New York, NY.
Gaver, D.P. (1963) Random hazards in reliability problems. Technometrics, 5, 211–26.
Gavrilov L.A. and Gavrilova N.S. (2001) The reliability theory of aging and longevity. Journal of Theoretical
Biology, 213 (4), 527–45.
Geisser, S. (1984) On prior distributions for binary trials. The American Statistician, 38 (4), 244–51.
Geisser, S. (1993) Predictive Inference: An Introduction, Chapman & Hall, New York, NY.
Gelfland, A.E. and Kuo, L. (1991) Nonparametric Bayesian bioassay including ordered polytomous
responses. Biometrika, 71, 657–66.
Gelfand, A.E., A.F.M. Smith and T.M. Lee (1992) Bayesian analysis of constrained parameter and truncated
data problems using gibbs sampling. Journal of the American Statistical Association, 87, 523–32.
Gelman, A., J.B. Carlin, H.S. Stern and D.B. Rubin (1995). Bayesian Data Analysis. Chapman & Hall.
Gelman, A. and T.P. Speed (1993) Characterizing a joint probability distribution by conditionals. Journal
of the Royal Statistical Society B, 55 (1), 185–88.
Genest, C. and J. MacKay (1986) The joy of copulas: Bivariate distributions with uniform marginals.
American Statistician, 40, 280–85.
Gertsbakh, I.B. and Kh.B. Kordonsky (1969) Models of Failure, Springer-Verlag, New York, NY.
Ghosh, J.K. and Samanta, T. (2002) Towards a nonsubjective Bayesian paradigm. Golden Jubilee Volume
for Mathematics, I.I.T Kharagpur (editor J. Misra).
Gilks, W.R. and P. Wild (1992) Adaptive rejection sampling for the Gibbs model. Applied Statistics, 41,
337–48.
Gill, R.D. (1984) Understanding Cox’s regression model: A martingale approach. Journal of the American
Statistical Association, 79 (386), 441–47.
Giorgi, G.M. (1998) Concentration index, Bonferroni. Encyclopedia of Statistical Sciences, Update 2, Wiley,
N.Y. 141–46.
Giorgi, G.M. and Crescenzi, M. (2001) A look at the Bonferroni inequality measure in the reliability
framework. Statistica, anno LXI, 4, 571–81.
Giorgi, G.M. and Mondani, R. (1995) Sampling distribution of the Bonferroni inequality index from
exponential population. Sankhya Series B, 57 (1), 10–8.

BIBLIOGRAPHY
355
Gjessing, H.K., Aalen, O.O. and Hjort, N.L. (2003) Frailty models based on Levy processes. Advanced
Applied Probability, 35, 532–50.
Gnedenko, B.V. (1993) Probability Theory and Mathematical Statistics from Medieval to Modern Time,
Technical Report of SOTAS. SOTAS, Inc., Rockville, MD.
Gnedenko, B.V., Yu.K. Belyaev and A.D. Soloyev (1969) Mathematical Methods of Reliability Theory,
Academic Press, New York, NY.
Good, I.J. (1950) Probability and the Weighing of Evidence, Griffin, London.
Good, I.J. (1961) A casual calculus I. British Journal of Philosophical Science, 11, 305–18; and A casual
calculus II. British Journal of Philosophical Science, 12, 43–51.
Good, I.J. (1965) The Estimation of Probabilities, The MIT Press, Cambridge, MA.
Good I.J. (1966) A derivation of the probabilistic explication of information. Journal of the Royal Statistical
Society, Series B, 28, 578–81.
Good, I.J. (1969) What is the use of a distribution?. In Multivariate Analysis, (ed. Krishnaiah), Academic
Press, New York, pp. 183–203.
Green, E.J., F.A. Roesch, A.F.M. Smith and W.E. Strawderman (1994) Bayesian estimation for a three-
parameter Weibull distribution with tree diameter data. Biometrics, 50, 254–69.
Gumbel, E.J. (1958) Statistics of Extremes, Columbia University Press.
Gumbel, E.J. (1960) Bivariate exponential distributions. Journal of the American Statistical Association,
50, 698–707.
Gupta, R.D. and D. Kundu (1998) Hybrid censoring schemes with exponential failure distribution. Commu-
nications in Statistics: Theory and Methods, 27 (12), 3065–083.
Gurland, J. and J. Sethuraman (1995) How pooling data may reverse increasing failure rates. Journal of the
American Statistical Association, 90, 1416–423.
Hacking, I. (1975) The Emergency of Probability, Cambridge University Press, London.
Harris, C.M. and Singpurwalla, N.D. (1967) Life distribution derived from stochastic hazard functions.
IEEE Transactions on Reliability, R-17 2, 70–9.
Hartigan, J.A. (1983) Bayes Theory, Springer-Verlag, New York, NY.
Hawkes, A.G. (1972) A bivariate exponential distribution with applications to reliability theory. Journal of
the Royal Statistical Society, Series B, 34 (1), 129–31.
Haykin, S. (1999) Neural Networks: A Comprehensive Foundation, Prentice-Hall, New Jersey.
Heath, D. and W. Sudderth (1976) de Finetti’s theorem on exchangeable variables. The American Statistician,
30, 188–89.
Hesslow, G. (1976). “Two Notes on the Probabilistic Approach to Causality”. Philosophy of Science,
43, 290–292.
Hesslow, G. (1981). “Causality and Determinism”. Philosophy of Science, 48, 591–605.
Hill, B.M. (1978) Decision theory. In Studies in Statistics, 19, (ed. R.V. Hogg), 168–209. The Mathematical
Association of America.
Hill, B.M. (1982) Comment on Lindley’s paradox by G. Shafer. Journal of the American Statistical
Association, 77, 344–47.
Hill, B.M. (1993) Dutch books, the Jeffreys-Savage theory of hypothesis testing and Bayesian reliability.
In Reliability and Decision Making, (eds. R.E. Barlow, C.A. Clarotti and F. Spizzichino), Chapman &
Hall, New York, NY, 31–85.
Hjort, N.L. (1990) Nonparametric Bayes estimators based on beta processes in models for life history data.
The Annals of Statistics, 18 (3), 1259–294.
Hogarth, R.M. (1975) Cognitive processes and the assessment of subjective probability distributions. Journal
of the American Statistician, 83 (401), 43–51.
Hollander, M. and D.A. Wolfe (1972) Nonparametric Statistical Methods, John Wiley & Sons,
New York, NY.
Howard, R.A. and J.E. Matheson (1984) Influence diagrams. In Readings in the Principles and Applications
of Decisions Analysis, 2, (eds. R.A. Howard and J.E. Matheson). Strategic Decision Group, Menlo
Park, CA.
Howson, C. and P. Urbach (1989) Scientific Reasoning: The Bayesian Approach, Open Co, La Salle, IL.
Hoyland, A. and Rausand, M. (2004) System Reliability Theory: Models and Statistical Methods,
Wiley-Interscience.

356
BIBLIOGRAPHY
Iglesias, P.L.Z., C.A.B. Pereira and N.I. Tanka (1994) Finite forms of de Finetti’s type theorem for univariate
uniform distributions. Unpublished paper of Institute de Matematica e Estatistica, Universidade de São
Paulo, São Paulo, Brazil.
IMS Lecture Notes on Topics in Statistical Dependence (1991) Edited by Block, Sampson, and Savits.
Itô, K. (1969) Stochastic Processes, Matematisk Institut, Aarhus University.
James, I.R. and Mosimann, J.E. (1980) A new characterization of the Dirichlet distribution through
Neutrality. Annals of Statistics, 8, 183–89.
Jeffreys, H. (1946) An invariant form for the prior probability in estimation problems. Proceedings of the
Royal Statistical Society of London, Ser. A, 186, 453–61.
Jeffreys, H. (1961) Theory of Probability, 3rd edn. Clarendon, Oxford.
Jeffreys, H. (1980) Some general points in probability theory. In Bayesian Analysis in Econometrics and
Statistics: Essays in Honor of Harold Jeffreys, (ed. A. Zellner), Amsterdam: North-Holland.
Jeffrey, R. (1965) The Logic of Decision, McGraw-Hill, New York, NY.
Jewell, N.P. and Kalbfleisch, J.D. (1996) Marker processes in survival analysis. Lifetime Data Analysis, 2,
15–29.
Johnson, A.L. and S. Kotz (1970) Distributions in statistics: continuous multivariate distributions, John
Wiley & Sons, Inc, New York, NY.
Johnson, A.L. and S. Kotz (1975) A vector multivariate hazard rate. Journal of Multivariate Analysis, 5,
53–66.
Kadane, J.B. and N. Sedransk. (1979) Towards a more ethical trial. In Bayesian Statistics, (eds.
J.M. Bernardo, M.H. DeGroot, D.V. Lindley and A.F.M. Smith), Valentia, Spain, pp. 329–38.
Kalbfleisch, J.D. (1978) Non-parametric Bayesian analysis of survival time data. JRSS B, 40 (2), 214–21.
Kalbfleisch, J.D. and R.L. Prentice (1980) The Statistical Analysis of Failure Time Data, John Wiley,
New York, NY.
Karlin, S. and Taylor, H.M. (1981) A second course in stochastic processes, Academic, New York. NY.
Kashyap, R.L. (1971) Prior probability and uncertainty. IEEE Transactions on Information Theory, IT-14,
641–50.
Kass, R.E. and A.E. Raftery (1995) Bayes factors. Journal of the American Statistical Association, 90 (430),
773–95.
Kass, R.E. and L. Wasserman (1996) The selection of prior distributions by formal rules. Journal of the
American Statistical Association, 91 (435), 1343–370.
Kebir, Y. (1991) On hazard rate processes. Naval Res. Logist.; 38, 865–76.
Keeney, R.L. and H. Raiffa (1976) Decisions with Multiple Objectives : Preferences and Value Tradeoffs,
John Wiley & Sons, New York.
Keynes, J.M. (1921) A Treatise on Probability, Macmillan, London.
Kingman, J.F.C. (1972) On random sequences with spherical symmetry. Biometrika, 59, 492–94.
Kingman, J.F.C. (1975) Random discrete distributions. JRSS B, 37 (1), 1–22.
Kingman, J.F.C. (1978) Use of exchangeability. The Annals of Probability, 6, 183–97.
Klefsjo, B. (1984) Reliability interpretations of some concepts from economics. Naval Research Logistics
Quarterly, 31, 301–08.
Klotz, J. (1973) Statistical inference in Bernoulli trials with dependence. Annals of Statistics, 1 (2), 373–79.
Kraft, C.H. and van Eeden, C. (1964). “Bayesian Bioassay”. Annals of Mathematical Statistics, 35, 886–890.
Kolmogorov, A.N. (1963). “On Tables of Random Numbers”. Sankhya, Series A, 25, 369–376.
Kolmogorov, A.N. and S.V. Fomin (1970) Introductory real analysis (Revised English edition translated
and edited by R.A. Silverman), Dover, New York, NY.
Kordonsky, K.B. and I. Gertsbakh (1997) Multiple time scales and the lifetime coefficient of variation:
Engineering applications. Lifetime Data Analysis, 2, 139–56.
Kotz, S. and N.D. Singpurwalla (1999) On a bivariate distribution with exponential marginals. Scandinavian
Journal of Statistics, 26, 451–64.
Kotz, S., N. Balakrishnan and N.L. Johnson (2000). Continuous Multivariate Distributions. Vol. 1: Models
and Applications. Wiley, New York.
Kumar Joag-Dev (1983) Independence via uncorrelatedness under certain dependence structures The Annals
of Probability, 11 (4), 1037–1041.
Kumar, S. and Tiwari, R.C. (1989) Bayes estimation of reliability under a random environment governed
by a Dirichlet prior. IEEE Transactions in Reliability, 38 (2), 218–23.

BIBLIOGRAPHY
357
Kuo, W. and R. Prasad (2000) An annotated overview of system reliability optimization. IEEE Transactions
in Reliability, R 49 (2), 176–87.
Kyburg, Jr, H.E. and H.E. Smokler (1964) Studies in Subjective Probability, John Wiley, New York, NY.
Lane, D.A. (1987) An epistemic justification of the law of total probability. In Probability Theory and
Applications, Proceedings of the 1st World Congress of the Bernoulli Society, Eds. Y.A. Prokhorov and
V.V. Sazonov, 1, VNU Science Press, Utrecht. pp. 155–67.
Laplace, P.S. (1774) Mémoire sur la probabilité des causes par les évenemens. Mémoires de mathématique
et de physique presentés à l’Académie royale des sciences, par divers savans, & lûs dans ses assemblées,
6, 621–56.
Laplace, P.S. (1795) Essai de Philosophique sur les Probabilités. Paris.
Laplace, P.S. (1812) Théorie Analytique des Probabilités. Courcier, Paris.
Laud, P.W., Smith, A.F.M. and Damien, P. (1996) Monte Carlo methods for approximating a posterior
hazard rate process. Statistics and Computing, 6, 77–83.
Lauritzen, S.L. and D.J. Spiegelhalter (1988) Local computations with probabilities on graphical structures
and their application to expert systems (with discussion). Journal of the Royal Statistical Society, B 50,
157–224.
Lavine, Michael and M.J. Schervish (1999) Bayes factors: what they are and what they are not. The American
Statistician. 53 (2), 119–22.
Lawless,J.F.(1998)Statisticalanalysisofproductwarrantydata.InternationalStatisticalReview,66(1),41–60.
Lee, L. and S.K. Lee (1978) Some results on inference for the Weibull process. Technometrics, 20 (1), 41–5.
Lee, L. (1979). “Multivariate Distributions Having Weibull Properties”. Journal of Mulitvariate Analysis,
9, 267–277.
Lee, P.M. (1989) Bayesian Statistics: An Introduction, Oxford, New York, NY.
Lee, M._L.T. and G.A. Whitmore (2006). “Threshold Regression for Survival Analysis”. Statistical Science.
To appear.
Lefebvre, C. and Principe, J. (1999) Neurosolution, Wiley, New York.
Lehmann, E.L. (1950) Some principles of the theory of testing hypotheses. Annals of Mathematical Statistics,
21, 1–26.
Lemoine, A.J. and Wenocur, M.L. (1985) On failure modeling. Naval Res. Logist. Quart., 32, 497–508.
Lemoine, A.J. and M.L. Wenocur (1986) A note on shot-noise and reliability modeling. Operations Research,
34, 320–23.
Lindley, D.V. (1956) On a measure of the information provided by an experiment. Annals of Mathematical
Statistics, 27, 986–1005.
Lindley, D.V. (1957a) A statistical paradox. Biometrika, 44, 187–92.
Lindley, D.V. (1957b) Binomial sampling schemes and the concept of information. Biometrika, 44, 179–86.
Lindley, D.V. (1978) Making Decisions, Wiley-Interscience, London and New York.
Lindley, D.V. (1982a) The Bayesian approach to statistics. In Some Recent Advances in Statistics, (eds. J.T.
de Oliveria and B. Epstein), Academic Press, London. 65–87.
Lindley, D.V. (1982b) Scoring rules and the inevitability of probability. International Statistical Review,
50, 1–26
Lindley, D.V. (1983) Reconciliation of probability distributions. Operatoins Research, 31, 866–80.
Lindley, D.V. (1985) Making Decisions, 2nd edn, John Wiley, New York, NY.
Lindley, D.V. (1997a) Some comments on Bayes factors. Journal of Statistical Planning and Inference, 61,
181–89.
Lindley, D.V. (1997b) The choice of sample size. The Statistician, 46 (2), 129–38.
Lindley, D.V. (2002) Seeing and doing: The concept of causation International Statistical Review, 70 (2),
191–214.
Lindley, D.V. and M.R. Novick (1981) The role of exchangeability in inference. The Annals of Statistics,
9, 45–58.
Lindley, D.V. and L.D. Phillips (1976) Inference for a Bernoulli process (a Bayesian view). The American
Statistician, 30, 112–19.
Lindley, D.V. and N.D. Singpurwalla (1986) Reliability (and fault tree) analysis using expert opinions.
Journal of the American Statistical Association, 81, 87–90.
Lindley, D.V. and N.D. Singpurwalla (1991) On the evidence needed to reach agreed action between
adversaries, with application to acceptance sampling. Journal of the Royal Statistical Association, 86
(416), 933–37.

358
BIBLIOGRAPHY
Lindley, D.V. and N.D. Singpurwalla (1993) Adversarial life testing. Journal of the Royal Statistical Society,
Series B, 55 (4), 837–47.
Lindley, D.V. and N.D. Singpurwalla (2002) On exchangeable, causal and cascading failures. Statistical
Science, vol. 17, No. 2. pp. 209–219.
Lloyd, D.K. and M. Lipow (1962). Reliability: Management, Methods, and Mathematics, Prentice Hall,
Englewood Cliffs, New Jersey.
Lochner, R.H. (1975) A generalized Dirichlet distribution in Bayesian life testing. JRSS B, 37, 103–13.
Lorenz, M.O. (1905) Methods of measuring the concentration of wealth. Publication of the American
Statistical Association, 9, 209–19.
Lu, C.J., Meeker, W.Q., Escobar, L.A. (1996) Using degradation measurements to estimate a Time-to-Failure
distribution. Statistica Sinica, 6, 531–46.
Lukasiewicz, J. (1930) Philosophische bemerkungen zu mehrwertigen systemen des aus-sageenkalkuls.
english tr. Philosophical remarks on many valued systems of propositional logic. Polish Logic 1920–1939
(ed. S McCall), Clarendon Press, Oxford. pp. 40–1965, 1967.
Lynn, N.J. and N.D. Singpurwalla (1997) ‘Burn-In’ makes us feel good. Statistical Science, 12 (1), 13–9.
Lynn, N., Singpurwalla, N.D. and Smith, A. (1998) Bayesian assessment of network reliability. SIAM
Review, 40 (2), 202–27.
Majumdar, D.D., Pal, S.K. and Chaudhuri, B.B. (1976) Fast algorithm for reliability and cost of a complex
network. IEEE Transactions on Reliability, R-25 (4), 258.
Makeham, W.M. (1873) On an application of the theory of composition of decremental forces. Institue of
Actuaries Journal, 18, 317–22.
Mann, N.R., R.E. Schafer and N.D. Sinpurwalla (1974) Methods for Statistical Analysis of Reliability and
Life Data, John Wiley, New York, NY.
Marshall, A.W. (1975) Some comments on the hazard gradient. Stochastic Processes and their Applications,
3, 293–300.
Marshall, A.W. (1994) A systems model for reliability studies. Statistica Sinica, 4, 549–65.
Marshall, A.W. and I. Olkin (1967) A multivariate exponential distribution. Journal of the American
Statistical Association, 62, 30–44.
Martz, H.F. and R.A. Waller (1982) Bayesian Reliability Analysis, John Wiley, New York, NY.
Mastran, D.V. and Singpurwalla, N.D. (1978) A Bayesian estimation of reliability of coherent structures,
Operations Research, 26, 633–72.
Mazzuchi, T.A. and Singpurwalla, N.D. (1985) A Bayesian approach to inference for monotone failure
rates. Statistics and Probability Letters, 3 (3), 135–42.
Mazzuchi, T.A. and Soyer, R. (1993) A Bayes method for assessing product-reliability during development
testing. IEEE Transactions on Reliability, 42, 503–10.
McCulloch, W.S. and Pitts, W. (1943) A logical calculus of ideas imminent in nervous activity. Bulletin of
Mathematical Biophysics, 5, 115–33.
Meeker, W.Q. and L.A. Escobar (1998) Statistical methods for reliability data. John Wiley, New York, NY.
Meinhold, R.J. and N.D. Singpurwalla (1983) Understanding the Kalman filter. The American Statistician,
37 (2), 123–27.
Meinhold, R.J. and N.D. Singpurwalla (1987) A Kalman-filter approach for extrapolations in certain
dose-response, damage assessment, and accelerated-life-testing studies. The American Statistician, 41 (2),
101–06.
Meinhold, R.J. and N.D. Singpurwalla (1989) Robustification of Kalman filter models. Journal of the
American Statistical Association, 84 (406), 479–86.
MIL-STD-105D (1963) Sampling Procedures and Tables for Inspection by Attributes, U.S. Government
Printing Office, Washington, DC.
MIL-STD-781C (1977) Reliability Design Qualification and Production Acceptance Tests: Exponential
Distribution, U.S. Government Printing Office, Washington, DC.
Misra, K.B. and M.D. Ljubojevic (1973) Optimal reliability design of a system – A new look. IEEE
Transactions on Reliability, R-22, 256–58.
Montagne, E.R. and N.D. Singpurwalla (1985) Robustness of sequential exponential life testing procedures.
Journal of the American Statistical Association, 80 (391), 715–19.
Morgenstern, D. (1956) Einfache Beispiele zweidimensionaler Verteilungen. Mittelungsblatt für Mathema-
tische Statistik, 8, 234–35.

BIBLIOGRAPHY
359
Myers, L.E. (1981) Survival functions induced by stochastic covariate processes. Journal of Applied Prob-
ability, 18, 523–29.
Nair, V.N. (1998) Discussion of Estimation of reliability in field performance studies by J.D. Kalbfleisch
and J.F. Lawless. Technometrics, 30, 379–83.
National Research Council (1998) Improving the Continued Airworthiness of Civil Aircraft, National
Academy Press, Washington, DC.
Natvig, B. (1982) Two suggestions of how to define a multistate coherent system. Advances in Applied
Probability, 14, 434–55.
Nelson, R.B. (1995) Copulas, characterization, correlation and counterexamples. Mathematics Magazine 68
(3), 193–98.
Nelson, R.B. (1999) An Introduction to Copulas, Springer-Verlag.
Nelson, W. (1982) Applied Life Data Analysis, John Wiley, New York, NY.
Neyman, J. and Pearson, E.S. (1967) Joint Statistical Papers of J. Neyman and E.S. Pearson, University of
California Press, Berkeley, CA.
Nieto-Barajas, L.E. and Walker, S.G. (2002) Markov beta and gamma processes for modelling hazard rates.
Scandinavian Journal of Statistics, 29, 413–24.
Novick, M.R. and W.J. Hall (1965) A Bayesian indifference procedure. Journal of the American Statistical
Association, 60, 1104–17.
Novick, M.R. and D.V. Lindley (1979) Fixed-state assessment of utility functions. Journal of the American
Statistical Association, 74 (366), 306–10.
Oakes, D. (1995). “Multiple Time Scales in Survival Analysis”. Lifetime Data Analysis, 1, 7–20.
O’Hagan, A. (1995) Fractional Bayes factors for model comparison. Journal of the Royal Statistical Society.
Series B (Methodological), 57 (1), 99–138.
Padgett, W.J. and Wei, L.J. (1981) A Bayesian nonparametric estimator of survival probability assuming
increasing failure rate. Communications in Statistics – Theory and Methods, A10 (1), 49–63.
Pearl, J. (2000). Causality: Models, Reasoning, and Inference. Cambridge University Press, Cambridge.
Peña, E.A. and A.K. Gupta (1990) Bayes estimation for the Marshall-Olkin exponential distribution. Journal
of the Royal Statistical Society, Series B, 52, 379–89.
Peña, E.A. and Hollander, M. (2004) Models for recurrent events in reliability and survival analysis.
In Mathematical Reliability: An Expository Perspective (eds Soyer. IEEE Transactions on Reliability.
R-34, 69–72.
Peterson, C.R. and L.R. Beach (1967) Man as an intuitive statistician. Psychological Bulletin, 68, 29–64.
Pierce, D.L., Easley, A.R., Windle, J.R. and T.R. Engel (1989) Fast fourier transformation of the entire
low amplitude late QRS potential to predict ventricular tachycardia. Journal of the American College of
Cardiology, 14 (7), 1731–740.
Pitman, J.W. and Speed, T.P. (1973) A note on random times. Stochastic Processes and their applications,
1, 369–74.
Polson, N.G. (1992). “On the Expected Amount of Information from a Non-Linear Model”. Journal of the
Royal Statistical Society, Series B, 54, 3, 889–895.
Press, S.J. (1996) The di Finetti transform. In Proceedings of the Fifteenth International Workshop on
Maximum Entropy and Bayesian Methods, Kluwer Academic Press, Boston.
Proschan, F. and P. Sullo (1974) Estimating the parameters of a bivariate exponential distribution in several
sampling situations. In Reliability and Biometry (eds F. Proschan and R.J. Serfling), SIAM.
Puri, P.S. and H. Rubin (1974) On a characterization of the family of distributions with constant multivariate
failure rates. Annals of Probability, 2, 738–40.
Raiffa, H. and R. Schaifer (1961) Applied Statistical Decision Theory. Harvard University, Graduate School
of Business Administration, Division of Research, Boston.
Ramgopal, P., Laud, P.W. and Smith, A.F.M. (1993) Nonparametric Bayesian bioassay with prior constraints
on the shape of the potency curve. Biometrika, 80, 82–6.
Ramsey, F.L. (1972) A Bayesian approach to bioassay. Biometrics, 28, 841–58.
Ramsey, F.P. (1926) Truth and probability. Reprinted in Studies in Subjective Probability, (eds.
H.E. Kyburg, Jr. and H.E. Smokler), John Wiley, 1964, New York, NY, 61–92.
Rissanen, J. (1983) A universal prior for integers and estimation by minimum description length. The Annals
of Statistics, ii, 416–31.

360
BIBLIOGRAPHY
Roberts, G.O. and A.F.M. Smith (1993) Simple conditions for the convergence of the Gibbs sampler and
the metropolis – Hastings algorithms. Stochastic Processes and their Applications, 49, 207–16.
Roberts, H.V. (1967) Informative stopping rules and inferences about population size. Journal of the
American Statistical Association, 62 (319), 763–75.
Ross, S.M. (1996). Stochastic Processes. John Wiley & Sons, Inc., New York.
Rosen, D.A. (1978). “In Defense of a Probabilistic Theory of Causality”. Philosophy of Science, 45, 604–613.
Royal Society Study Group (1992) Risk: Analysis, Perception and Management, The Royal Society, London.
Royden H.L. (1968) Real Analysis, MacMillan Publishing Co., Inc., NewYork.
Rubin, H. (1987) A weak system of axioms for ‘rational’ behavior and the nonseparability of utility from
prior. Statistics and Decisions, 5, 47–58.
Russell, B. (1923) Vagueness. Australasian Journal of Philosophy, 1, 88.
Ryu, K. (1993) An extension of Marshall and Olkin’s bivariate exponential distribution. Journal of the
American Statistical Association, 88 (424), 1458–465.
Salmon, W. (1980). “Probabilistic Causality”. Pacific Philosophical Quarterly, 61, 50–74.
Samaniego, F.J. (1985). On closure of IFR class under formation of coherent systems. IEEE Transactions
on Reliablity, R-34, 69–72.
San Martini, A. and F. Spezzaferri (1984) A predictive model selection criterion. Journal of the Royal
Statistical Society, Series B, 46, 296–303.
Sarkar, S.K. (1987) A continuous bivariate exponential distribution. Journal of the American Statistical
Association, 82, 667–75.
Savage, L.J. (1954) The Foundations of Statistics, 1st edn. John Wiley, New York, NY.
Savage, L.J. (1971) Elicitation of personal probabilities and expectations. Journal of the American Statistical
Association, 66, 783–801.
Savage, L.J. (1972) The Foundations of Statistics, 2nd edn. Dover, New York, NY.
Schoenberg, I.J. (1938) Metric spaces and positive definite functions. Transactions of the American
Mathematical Society, 44, 522–36.
Schrodinger, E. (1947) The foundation of the theory of probability-I. Proceedings of the Royal Irish
Academy, 51 A (5), 51–66.
Sellers, K.F. and Singpurwalla, N.D. (2006) Many-valued Logic in Multistate and Vague Stochastic Systems.
Technical Report, The George Washington University. Under review.
Sethuraman, J. (1994) A constructive definition of Dirichlet priors. Statistica Sinica, 4 (2), 639–50.
Sethuraman, J. and Tiwari, R.C. (1982) Convergence of Dirichlet measures and the interpretations of their
parameters. Statistical Decision Theory and Related Topics, III. Academic Press.
Shafer, G. (1976) A Mathematical Theory of Evidence, Princeton University Press, Princeton, NJ.
Shafer, G. (1981) Jeffrey’s rule of conditioning. Philosophy of Science, 48, 337–62.
Shafer, G. (1982a) Lindley’s paradox. Journal of the American Statistical Association, 77, 325–51.
Shafer, G. (1982b) Bayes’s two arguments for the rule of conditioning. The Annals of Statistics, 10 (4),
1075–089.
Shafer, G. (1985) Conditional probability. International Statistical Review, 53 (3), 261–77.
Shafer, G. (1986) The combination of evidence. International Journal of Intelligent Systems, 1, 155–79.
Shafer, G. (1990) The unity and diversity of probability. Statistical Science, 5, 435–62.
Shafer, G. (1991) What Is Probability? Working Paper No. 229. School of Business, The University of
Kansas, Lawrence, KS.
Shafer, G. (1996) The significance of Jacob Bernoulli’s Ars Conjectandi for the philosophy of probability
today. Journal of Econometrics, 75, 15–32.
Shaked, M. (1977) A concept of positive dependence for exchangeable random variables. The Annals of
Statistics, 5, 505–15.
Shamseldin, A.A. and S.J. Press (1984) Bayesian parameter and reliability estimation for a bivariate expo-
nential distribution. Journal of Econometrics, 24, 363–78.
Shannon, C.E. (1948) A mathematical theory of communication. Bell Systems Tech Journal, 27, 379–423
and 623–56.
Singpurwalla, N.D. (1983) A unifying perspective on statistical modeling. SIAM Review, 31 (4), 560–64.
Singpurwalla, N.D. (1988a) Foundational issues in reliability and risk analysis. SIAM Review, 30, 264–82.
Singpurwalla, N.D. (1988b) An interactive PC-based procedure for reliability assessment incorporating
expert opinion and survival data. Journal of the American Statisticial Association, 83 (401), 43–51.

BIBLIOGRAPHY
361
Singpurwalla, N.D. (1989) A unifying perspective on statistical modeling. SIAM Review, 31 (4), 560–64.
Singpurwalla, N.D. (1993) Comments on statistical analysis of reliability data by Crowder, M.J.,
Kimber, A.C., Smith, R.L. and Sweeting T.J. (1991), Chapman Hall, in SIAM Review, 35, 535–38.
Singpurwalla, N.D. (1995a) The failure rate of software: does it exist?. The IEEE Transitions in Reliability,
44 (3), 463–69.
Singpurwalla, N.D. (1995b) Survival in dynamic environments. Statistical Science, 10 (1), 86–113.
Singpurwalla, N.D. (1996) Entropy and information in reliability. In Bayesian Analysis in Statistics and
Econometrics, (eds. D.A. Berry, K.M. Chaloner, and J.K. Geweke). John Wiley, New York, NY,
pp. 459–69.
Singpurwalla N.D. (1997). “Gamma Processes and their Generalizations: An Overview”. In Engineering
Probabilistic Design and Maintenance for Flood Protection (R. Cooke., M. Medel and H. Vrijling, eds.),
67–75. Kluwer Academic Publishers, Dordrecht.
Singpurwalla, N.D. (1998) A paradigm for modeling and checking reliability growth. In reliability growth
modeling (eds, K.J. Farquar and A. Mosleh), 121–25.
Singpurwalla, N.D. (2000a) The point process paradox: Where should we extend the conversation?. The
American Statistician, 54 (2), 119–20.
Singpurwalla, N.D. (2000b). “Contract Warranties and Equilibrium Probabilities”. In Statistical Sciences in
the Courtroom (J.L. Gastwirth, ed.), 363–377. Springer-Verlag, New York.
Singpurwalla, N.D. (2001) Cracks in the empire of chance: flaws in the foundations of reliability. Interna-
tional Statistical Review, 10 (1), 53–78.
Singpurwalla, N.D. (2002) On causality and causal mechanisms. International Statistical Review, 10 (2),
198–206.
Singpurwalla, N.D. (2004) Warranty: A surrogate of reliability. Mathematical Reliability – An Expository
Perspective (eds, Soyer, Mazzuchi, and Singpurwalla), Kluwer Academic Publishers.
Singpurwalla, N.D. (2005) Decelerated testing: A hierarchical Bayesian approach. Technometrics, 47 (4),
468–77.
Singpurwalla, N.D. (2006a) The hazard potential: Introduction and overview. Journal of the American
Statistical Associtation. To appear (Dec. 2006).
Singpurwalla, N.D. (2006b) On competing risk and degradation processes. The second Erich Lehmann
Symposium – Optimality. Institute of Mathematical Statistics – Monograph Series, Vol. 49 (ed. J. Rojo)
pp. 289–304.
Singpurwalla, N.D. (2006c) Reliability and survival in financial risk. In Advances in statistical Modeling
and Inference – Essays in Honor of Kjell Doksum (ed. V. Nair), World Scientific Publications. To appear.
Singpurwalla, N.D. and Booker J. (2004) Membership functions and probability measures of fuzzy sets.
Journal of the American Statistical Association, 99, 867–77.
Singpurwalla, N.D., J. Eliashberg and S. Wilson (1996) Calculating the reserve for a time and usage indexed
warranty. Management Science. 43 (7), 966–75.
Singpurwalla, N.D. and C. Kong (2004) Specifying interdependence in networked systems. IEEE Trans. On
Reliability, 53 (3), 401–05.
Singpurwalla, N.D. and Shaked, M. (1990) A Bayesian approach for quantile and response probability
estimation with applications to reliability. Annals of the Institute of Statistical Mathematics, 42 (1), 1–19.
Singpurwalla, N.D. and Song, M.S. (1986) An analysis of Weibull lifetime data incorporating expert opinion.
In Probability and Bayesian Statistics (ed. R. Viertl), New York: Plenum: 431–42.
Singpurwalla, N.D. and R. Soyer (1992) Nonhomogeneous autoregressive processes for tracking (software)
reliability growth, and their Bayesian analysis. Journal of the Royal Statistical Society, B 54, 145–56.
Singpurwalla, N.D. and A. Swift (2001) Network reliability and Borel’s paradox. The American Statistician,
53 (3), 213–18.
Singpurwalla, N.D. and S. Wilson (1993). “Warranties: Their Statistical and Game Theoretic Aspects”.
SIAM Review, 35, 1, 17–42.
Singpurwalla, N.D. and S.P. Wilson (1995) The exponentiation formula of reliability and survival: does it
always hold? Life Data Analysis, Kluwer Academic Publishers, 1, 187–94.
Singpurwalla, N.D. and S.P. Wilson (1998) Failure models indexed by two scales. Advanced Applied
Probability, 30, 1058–72.
Singpurwalla, N.D. and S.P. Wilson (1999) Statistical methods in software engineering. Springer,
New York, NY.

362
BIBLIOGRAPHY
Singpurwalla, N.D. and P. Wilson (2004) When can finite testing ensure infinite trustworthiness?. Journal
of the Iranian Statistical Society. 3 (1), 1–37.
Singpurwalla, N.D. and P. Wilson (2006) Item response models for coherent utility assessments. Technical
Report, The George Washington University.
Singpurwalla, N.D. and M.A. Youngren (1993) Multivariate distributions induced by dynamic environments.
Scandinavian Journal of Statistics, 20, 251–61.
Sinha, S.K. and J.A. Sloan (1988) Bayes estimation of the parameters and reliability function of the three
parameter Weibull distribution. IEEE Transactions on Reliability, 37, 364–69.
Sklar, A. (1959) Fonctions de répartition à n dimensions et leurs marges. Publications de l’Institut Statistique
de l’Université de Paris, 8, 229–31.
Smith, A.F.M. (1981) On random sequences with centered spherical symmetry. Journal of the Royal
Statistical Society, B 43, 208–09.
Smith, A.F.M. and G.O. Roberts (1993) Bayesian computation via the Gibbs sampler and related Markov
Chain Monté Carlo methods. Journal of the Royal Statistical Society, Series B, 55, 2–23.
Smith, C.A.B. (1961) Consistency in statistical inference and decision. Journal of the Royal Statistical
Society, B 23, 213–20.
Smythe, R.T. (2004) Beta distribution in bioassay. Handbook of Beta Distribution and its Applications,
Marcell Dekker.
Sobczyk, K. (1987) Stochastic models for fatigue damage of materials. Advanced Applied Probability, 19,
652–73.
Soland, R.M. (1969). “Bayesian Analysis of the Weibull Process with Unknown Scale and Shape
Parameters”. IEEE Transactions in Reliability, 18, 181–184.
Soofi, E.S. (2000) Principal information theoretic approaches. Journal of the American Statistical
Association, 95, (452), 1349–353.
Spizzichino, F. (1988) Symmetry conditions on opinion assessment leading to time-transformed exponen-
tial models. In Accelerated Life Testing and Expert’s Opinions in Reliability, (eds. C.A. Clarotti and
D.V. Lindley), Elsevier, New York, NY. 83–97.
Statistical Software Engineering (1996) National Academy Press, Washington, DC 20055.
Stigler, S.M. (1982) Thomas Bayes’s Bayesian inference. Journal of Royal Statistics, A 145 (2), 250–58.
Stigler, S.M. (1983) Who discovered Bayes’s theorem? The American Statistician, 37, 290–96.
Stigler, S.M. (1986) Laplace’s 1774 memoir on inverse probability. Statistical Science, 1 (3), 359–78.
Sun, D. (1997) A note on noninformative priors for Weibull distributions. Journal of Statistical Planning
and Inference, 61, 319–38.
Suppes, P. (1970) A Probabilistic Theory of Causality, North-Holland, Amsterdam.
Susarla, V. and Van Ryzin, J. (1976) Nonparametric Bayesian estimation of survival curves from incomplete
observations. Journal of American Statistical Society, 71, 740–54.
Swift, A. (2001) Stochastic models of cascading failures. PhD Thesis, The George Washington University.
Teugels, J.L. (1990) Some representations of multivariate Bernoulli and binomial distributions. Journal of
Multivariate Analysis, 32, 256–68.
Tillman, F.A., Hwang, C.L., Fan, L.T. and Lai, K.C. (1970) Optimal reliability of a complex system. IEEE
Transactions on Reliability, R-19 (3), 95–100.
Thiel, H. (1967). Economics and Information Theory. Nort-Holland, Amsterdam.
Tversky, A. and D. Kahneman (1986) Rational choice and the framing of decisions. Journal of Business,
59, S251–278.
Upadhyay, S.K. and A.F.M. Smith (1994) Modeling complexities in reliability, and the role of simulation
in Bayesian computation. International Journal of Continuing Education, 4, 93–104.
Upadhyay, S.K., N. Vasishta and A.F.M. Smith (2001) Bayes inference in life testing and reliability via
Markov Chain Monté Carlo simulation. Sankhya: The Indian Journal of Statistics, 63, A, Part 1: 15–40.
van der Weide H. (1997). “Gamma Processes”. In Engineering Probabilistic Design and Maintenance for
Flood Protection (R. Cooke., M. Medel and H. Vrijling, eds.), 77-83. Kluwer Academic Publishers,
Dordrecht.
Venn, J. (1866) The Logic of Chance, Macmillan, London, UK.
Verdinelli, I., N. Polson and N.D. Singpurwalla (1993) Shannon information, Bayesian design in accelerated
life-testing. In Reliability and Decision Making, (eds. R.E. Barlow, C.A. Clarotti, and F. Spizzichino),
Chapman and Hall, London: pp. 247–256.

BIBLIOGRAPHY
363
von Mises, R. (1939) Probability Statistics and Truth, Hodge, London, UK. German original 1928.
von Neumann, J. and O. Morgenstern (1944) Theory of Games and Economic Behavior, Princeton University
Press, Princeton, NJ.
Wald, A. (1950) Statistical Decision Functions, John Wiley & Sons, New York, NY.
Walker, S. and Damien, P. (1998) A full Bayesian non-parametric analysis involving a neutral to the right
process. Scandinavian Journal of Statistics, 25, 669–80.
Walker, S. and Muliere, P. (1997) Beta-Stacy processes and a generalization of the Polya-Urn Scheme. The
Annals of Statistics, 25 (4), 1762–780.
Walley, P. (1991) Statistical Reasoning with Imprecise Probabilities, Chapman and Hall.
Wenocur, M.L. (1989) A reliability model based on gamma process and its analytic theory. Advances in
Applied Probability, 21, 899–918.
West, M. and J. Harrison (1989). Bayesian Forecasting and Dynamic Models. Springer-Verlag, New York.
Whitmore, G.A. (1995) Estimating degradation by a Wiener diffusion process subject to measurement error.
Lifetime Data Analysis, I, 307–19.
Whitmore, G.A., Crowder, M.J. and Lawless, J.F. (1998) Failure inference from a marker process based on
a bivariate Wiener process. Lifetime Data Analysis, 4, 229–51.
Wilks, S.S. (1962) Mathematical Statistics, John Wiley & Sons, Inc., New York, NY.
Woodbury, M. and Manton, K. (1977) A random walk model for human mortality and aging. Theoretical
Population Biology, 11, 37–48.
Yang, Y. and Klutke, G.A. (2000) Lifetime-characteristics and inspection-schemes for Levy degradation
processes. IEEE Transactions on Reliability, 49 (4) 377–282.
Yashin, A. and E. Arjas (1998) A note on random intensities and conditional survival functions. Journal of
Applied Probability, 25, 630–35.
Yashin, A.I. and Manton, K.G. (1997) Effects of unobserved and partially observed covariate processes on
system failure: a review of models and estimation strategies. Statistical Science, 12, 20–34.
Yor, M. (1992) On some exponential functionals of Brownian motion. Advanced Applied Probability, 24,
509–31.
Zacks, S. (1992) Introduction to Reliability Analysis: Probability Models and Statistical Methods, Springer-
Verlag, New York, NY.
Zadeh, L. (1979) Possibility theory and soft data analysis, memo. Technical Report UCB/ERL M79/66.
University of California, Berkeley, CA.
Zadeh, L. (1965) Fuzzy sets. Information and Control, 8, 338–53.
Zellner, A. (1977) Maximal data information prior distributions. In New Developmentsin the Application of
Bayesian Methods. (eds, A. Aykac and C. Brumat), Amsterdam: North-Holland.
Zellner, A. (1991) Bayesian methods and entropy in economics and econometrics. In Maximum Entropy
and Bayesian Methods. (eds. W.T. Grandy, Jr. and L.H. Schick). Boston: Kluwer, pp. 17–31.
Zellner, A. and C. Min (1993) Bayesian analysis, model selection and prediction. In Physics and Probability:
Essays in Honor of Edwin T. Jaynes, (eds. W.T. Grandy, Jr. and P.W. Milonni), Cambridge University
Press, Cambridge, UK, pp. 585–647.


Index
Absolutely continuous distribution
75,
81, 106
Absorbing state
227
Accelerated life model
200–1
Accelerated life tests
175–85
Accelerated stress
175, 183, 185
Accelerated test
179–83
Additive hazards model
122, 224
Additive processes
208, 215–18
Additivity
countable
12
finite
12
Ageing
314, 319
Ageing Processes
314
Alternate hypothesis
28
Amplitude
193, 194, 339
Anti star-shaped
323
Arc reversal
39, 42
Artificial neural net
292
Asset pricing formula
317–18, 328–32
Attenuation function
208, 327–8
Autocovariance function
210
Availability
233, 292, 293
Background knowledge
10, 11, 13
Backwards recursion equations
179
Baseline failure rate
122
Baseline intensity
229
Bathtub curve
69–74
Bayes factor
27–32
Bayes’ decision
164
Bayes’ law
19–22, 42
Bayesian decision theory
162
Bayesian inference
23, 147, 149, 254
Bayesian statistics
22, 27, 52, 162
Bernoulli distribution
47, 270, 278, 280
Bernoulli trials
47, 50, 145, 147, 157
Bernoulli’s theorem
15, 16
Beta binomial distribution
158
Beta distribution
130, 182, 253
Beta process
255–8
Beta-Stacy process
267
Bias
137, 292
Binary logic
303, 305
Binomial distribution
158, 161, 245
Bioassay
247–9
Bivariate Bernoulli
277, 278, 279
Bivariate exponential
89–106, 110–16
bivariate exponential of Marshall and
Olkin
93
Bivariate failure rate
77
Bivariate Pareto
107–10, 115
Bond issuer
329, 332
Bonferroni index
311–12, 313
Bootstrap
330
Borel–Kolmogorov Paradox
346
Borel’s paradox
345
Bounded utilities
301
Branching processes
237
Bridge structure network
Brier score
13
Brownian motion process
210, 211, 214
Brownian maximum process
212
geometric Brownian motion
214
squared Brownian motion
211
standard Brownian motion process
211
Burn-in
71
BVE
88, 95–106, 159–61
Calculus of probability
12, 13, 23, 39
Cameron–Martin formula
211, 215
Cascading failure
117–20
Causal failure
117–18
Censoring
146, 165–6, 234
censored data
264
Reliability and Risk: A Bayesian Perspective
N.D. Singpurwalla
© 2006 John Wiley & Sons, Ltd

366
INDEX
Chance
15, 33, 50, 68, 129, 132, 133, 135, 136–44
Channel capacity
163
Characteristic life
67
Classification with precision
196
Classification with vagueness
304
Clinical trials
145
Coefficient of correlation
88, 97
Coefficient of variation
61
Coherence
19, 21
Coherent system
270–91
Compensator
238
Competing risk processes
218–22
dependent competing risk process
220,
221, 222
Competing risks
218–22, 229–31
deterministic competing risks
219
stochastic competing risks
220
Competing system
271, 277
Completely neutral vector
246, 250, 254
Component
91, 99, 119, 269–70, 289, 307
Composite reliability
187–203
Composite unreliability
191
Compound Poisson process
121, 213
Computational unit
292
Condition monitoring
227
Conditional failure rate functions
78
Conditional hazard potential
83
Conditional independence
126, 132
Conditional mean
87, 90
Conditional probability
12, 40, 63, 215
Conditional probability assessment
347
Conditional survival function
87, 98, 99, 113
Conditional value of sample information
164
Conglomerability
13, 23
Conjunction
189, 252
Consistency profile
305–6, 307
Constant stress tests
145
Convex ordered
314
Convexity
11
Co-operative system
269, 271
Copula
86, 115
Covariance
88
covariance matrix
52, 185, 196
Covariate
193–203
Cox Model
239
Cox Process
134, 234
Credibility
16, 69, 254
Critical time
118
Cumulative hazard
221
cumulative hazard function
65, 80, 253–9
cumulative hazard process
206, 211–18
Damage
177
Data augmentation
160
de Finetti’s theorem
45–55
Decision node
34, 35
Decision tree
5, 34–43, 167, 170
Decreasing failure rate
69–74
Decreasing interest rate
320
decreasing average interest rate
320
Degradation
231
degradation data
222, 224
degradation modeling
223
degradation process
222–5
Density
11, 47
Dependent lifelengths
81–3, 85–116
Deterioration
63, 66, 73, 231
Diffusion
210
Diffusion processes
210
Dirichlet distribution
244–7, 288
Dirichlet process
244, 260–4, 330–1
Discontinuous
60, 61
Disjunction
305
Distribution function
11, 49, 59–62, 259–67
Disutuility
302
Doob decomposition
237
Doob–Kolmogorov inequality
237
Doob–Meyer decomposition
238
Doob’s convergence theorem
237
Dormant life
76
Double lognormal distribution
180, 263
Doubly stochastic Poisson process (or Cox Process)
134, 206
Drift rate
208, 209
Driving process
282–3
Duality
273
Dynamic processes
236–40
Dynamic statistical model
238
Dynamic stress tests
145
Econometrics
309–33
Economics
5, 150, 314
Effects analysis, see FMEA
Egalitarian line
311, 312
Electrocardiogram (ECG)
193
Element of a system
269
Entropy
161–2
entropy of income shares
315
Equivalence
51, 305
Event history
227–9, 232, 234
Event tree
5
Exchangeability
45–57, 188–93
Exchangeable sequences
24, 49–50, 51, 189
Exclusive censoring
264
Expectation
32–4, 35
Expected utility
32–4, 35, 171
Expert testimonies
137–41
Explanatory variables
229
Exponential distribution
54, 89, 91, 95

INDEX
367
Exponentiation formula
319
exponentiation formula of reliability and
survival
211–12, 318
Extended gamma process
251–2
Extreme value distribution
67
Failure data analysis
125–85
Failure mode and effects analysis (FMEA)
230
Failure model
107–9, 123
failure mode and effects analysis (FMEA)
230
Failure modes
229–31
Failure rate
63, 64, 66–76, 119, 122, 166
deterministic failure rate function
209
failure rate function
62–79, 91, 99, 103, 113
Fault tree
5, 34, 35
Feedforward net
292, 293
Feynman–Kac equation
222
Filtering
176, 180–3, 263
filtering in colored noise
182
Finance
309–33
Fixed income investment
309
Fixed point
266, 296, 297, 299
Force of mortality
62
Forward recursive equations
179
Fourier coefficients
341
Fourier representation
341
Fourier series model
195, 339–43
Frechet bounds
86, 87
Frequency
50, 339
Frequentist
17, 24, 34, 47, 336
Freund’s bivariate exponential distribution
91
Fully connected net
292
Fundamental harmonic
342
Fuzzy set
306
Gamma distribution
102, 128, 168
Gamma process
111, 122, 214, 251–2, 253, 254
Gaussian distribution
51, 52
Generalized Dirichlet
246
Genuine cause
117
Geometric distribution
54
Gibbs sampling
160, 335–7
Gini index
311, 314
Gompertz law
67
Gumbel’s distribution
67
Gumbel’s bivariate exponential distribution
89, 90
Harmonic
343
harmonics of the fundamental frequency
196, 342
Hazard function
65, 205, 250
cumulative hazard function
75, 76, 80, 253
Hazard gradient
76, 83
Hazard potential
79, 81, 83
Hazard rate
3, 207, 208, 210
Hazard rate process
206–11
Hertz
343
Hidden layer
292, 293
Hidden Markov model
134, 218
Hidden periodicities
195, 196, 343
Hierarchical Bayes model
200
Hierarchical independence
283
Hierarchical model
187
History
14, 227
Holding period
317, 321
Homogenous NTR processes
266
Hybrid testing
150, 153
Hyperparameter
187
Hypothesis testing
22, 28
Identifiability
102, 160
Identity function
256
IFR (DFR)
314, 320
IFRA (DFRA)
314, 318
Implication
326
Imprecise
304, 307
Improper probability
13, 23
Impropriety
131, 141, 142, 144
Inadmissibility
17
Inclusion–exclusion formula
278, 308
Inclusive censoring
264
Income inequality
310–17
Increasing average interest rate
320
Increasing interest rate
321, 322
Independence
46–8, 283–4
Independent increments
94, 252, 265
Independent increments property
228, 238,
255, 265
Independent lifelengths
85, 120, 296, 297, 298
Indifference
24, 45–57
Indifference principle of survival
81
Indifference priors
25, 144
Influence diagram
34–43
Information
38, 143, 161–70, 184
Innovations
238
Instantaneous failure rate
64
Intensity function
94, 206, 207, 229
Intensity process
134, 234–6
Interval of support
75
Invariance
51
Inverse Gaussian distribution
68, 157, 212
Item censoring (or Type II censoring)
146
Itô decomposition
208
Jeffreys’ prior
141, 142, 143, 144
Joint density
11, 108, 249
Joint performance process
282
Jump process
252

368
INDEX
k-out-of-n system
271, 273
Kac functional
222
Kalman filter model (KF)
177–9
Kalman filter smoothing
177–9
Kalman filtering (or Dynamic Linear Model
or State Space Model)
176
Kaplan–Meier estimator
259, 264
Kendall’s Tau
89
Kolmogorov axioms
12, 19, 23
Kolmogorov consistency
261
Kullback–Leibler distance
143
Lack of memory property
81, 93, 97
Laplace transform
107, 213, 217
Law of a diminishing resource
319
Law of Bivalence
305
Law of inverse probability
21
Law of large numbers
49–50
Law of the Excluded Middle
305, 308
Law of total probability
19–22
Lebesgue decomposition formula
60
Lebesgue measure
100, 160, 346
Lévy measure
208, 209, 213, 258
Lévy process
122, 208, 213, 258, 265
increasing Lévy processes (or subordinators)
208, 265
Lévy–Khinchin formula
213
Life history
227, 231, 250
Life-table analysis
228
Life-testing
145, 150, 155, 156, 157, 159, 166,
170, 173, 175, 229, 233
Lifelength model
24, 59, 66, 81, 85–116
Likelihood
20, 137
Likelihood principle
22, 28, 34
Likelihood ratios
237
Lip1 condition
222
Log concavity
322
Log-linear model
201
Logical probability
16, 18
Lognormal distribution
67, 180
Lorenz curve
311, 315–17
Lorenz domination
315
Lower probability
286
Machine learning
291–4
Maintenance (or Repair)
231–3, 304
Many-valued logic
305
Marginal distribution
89, 96
Marker processes
205, 223, 224
Markers
205
Markov additive process (MAP)
122, 215–18
Markov beta process
251
Markov chain
155, 193, 243, 270, 335
Markov Chain Monte Carlo (MCMC)
155, 270
Markov dependence
277, 278, 279
Markov gamma process
251
Markov property
211, 215
Markovian
231, 235, 279
Martingales
236–40
Martingale central limit theorem
239
Martingale differences
237, 238
Mean
87, 94, 134–5
Mean residual life
61, 310
Mean time to failure
61, 164, 165
Median
61, 128, 137, 138
Membership function
306
Memoryless property
321
Method of copulas
86
Min. path set
272, 276, 278
Mission time
68, 109, 294
Mode
61, 129, 201
Model failure rate
66–76, 113
Modulating function
110
Modules
271
Multi-indexed distribution
59–62
Multi-stage hierarchical models
187–8
Multi-state systems
303
Multilayer net
292
Multinomial distribution
244
Multiplicative formula of reliability and
survival
63
Multiplicative intensity
234–6
multiplicative intensity model
229
Multiplicative proportional hazards
model
229
Multivariate Bernoulli
279
Multivariate counting
234–6
Multivariate cumulative hazard function
76
Multivariate Gaussian distribution
52
Multivariate Student’s t distribution
197
Mutual information
183, 184–5
Mutually exclusive events
11, 12, 244
Mutually independent
12, 62, 112
Natural language
304, 307
NBU (NWU)
314, 320
Negative binomial distribution
142, 143, 147
Nelson–Aalen estimator
257
Net utility
302
Networks
network collapsibility
299
network reliability
276, 278
Neural nets
292–4
Neuron
292
Neutral
neutral to the left process
265
neutral to the right process
254, 328
New better than old
314
New worse than old
320

INDEX
369
Node
merging
41, 42
splitting
41, 42
Nominal (or use conditions)
stress
175, 177
Non-parametric Bayes
243–67
Nonhomogenous NTR processes
94, 206
Normal distribution (or Gaussian distribution)
51–3, 68, 140, 180, 196, 212, 263
Null hypothesis
28, 30, 31, 141
Observation equation
177, 181, 182
Observed information (or observed change in
utility)
163
Odds on (against)
18, 28
Odds ratio
28, 29, 30
Order statistics
151, 271, 287, 310
Ordered Dirichlet distribution
246
Orthogonal increments property
238
Orthogonal processes
239
Orthogonality
340
Parallel-redundant system
91, 107,
114, 271
Parameter
23–7, 112, 113, 169, 229, 261,
346, 347
Pareto distribution
70, 107, 207,
326, 328
Partially exchangeable sequences
189
Performance process
282–3
Period
73, 195, 317
Periodgram
343
Periodicity
195, 343
Personal beliefs
144
Phase
72, 293
Physical probability
17
Pivoting
273
Point process
multivariate point process
234–6
Poisson distribution
53, 94, 133, 134, 208
Poisson process
compound Poisson process
121,
209, 213
Poisson counting process
94, 110
Polya Frequency Functions of Order
2, 322
Pooling
329, 331
Positive quadrant dependence
89
Posterior
27–31, 197, 200, 249, 266, 330
Posterior hazard rate process
252
Posterior odds
27–31
Potency
177, 248, 249
Power law model
176
Power spectrum (or signature)
193, 195, 196,
197, 198, 200, 339–43
Precision
137, 196
Predictable covariance process
239
Predictable process
238
Predictable variation process
238
Predictive distribution
26, 127–36, 144–61
Predictive failure rate
62–6, 72, 75
Preposterior analyses
162
Present value
215, 317, 319, 320, 322, 325,
329–32
Principle of indifference
24, 45, 59
Principle of maximization of expected utility
33,
174, 299, 301
Prior
134, 136–44, 158, 196, 248, 250–67, 286,
287, 300
Prior odds
28, 29, 31
Probabilistic modeling
45, 59
Probability
10–22, 23–7, 32, 62–6, 85–116
Probability density function
11, 121, 280
Probability model
23–7, 85–116
Product integral formula
66, 258
Product moment
88
Progressively censored
150
Propensity
50, 122
Proportional hazards model
224
Quality of life
61, 304
Random censoring
150, 152
Random events
10, 11, 20, 46
Random hazard function
205, 250–9
Random node
34, 37, 167
Random quantities
50–7
continuous
10
discrete
10
Random threshold
79, 212
Random usage
216
Rayleigh distribution
67
Redundancy
redundancy allocation
294
redundant components
271, 294
Reference posterior
143, 144
Reference priors
143
Regression
regression model
195, 197
Re-labelling
278
Relative frequency
15, 17–18, 50
Reliability
reliability allocation
294–9
reliability apportionment
296–7
reliability function
66, 68, 120, 275
reliability growth
69, 70
reliability polynomial
275
Repeatable experiments
17
Residual life
61, 76, 313
Retrospective conditioning
346

370
INDEX
Retrospective failure data
145, 233
Retrospective failure rate
74–6
Riccati equation
211
Right-censored (or time truncated)
146, 173,
233, 264
Risk averse
34, 270
Risk management
4–6
Risk neutral
34, 301
Risk prone
34, 302
Risk seeking
34
Riskless bond
309
Rotational symmetry
52, 56
Rules of probability
11–13, 19–22
Scoring rule argument
12, 13
Screening test
71
Semi-Markovian
231, 232
Series system
132–3, 271, 296–7
Shannon information
162, 164, 165
Shock
94, 95, 102
Shot noise process
110–15, 207–8, 327
Signature
signature analysis
193–203
signature data
193
Simulation
46, 131, 172, 189, 330, 335–7
Single-phased neural net
292
Singular
60, 61, 100
Sojourn times
215, 218
Spearman’s Rho
89
Spectral weights
201, 202
Spurious cause
82, 117, 118
Squared correlation ratio
88
Stable processes
209, 213
Stand-by redundancy
129
Standard deviation
61, 140
Star ordered
314
Star-shaped
323
State of nature
162, 178, 181
Stationary distribution
336
Statistical inference
21, 26–7
Statistical models
236–40
Steady model
181, 182
Stochastic hazard functions
205
Stochastic integrals
239
Stochastic interest rates
325
Stochastic process
dynamic stochastic process models
227, 236
multivariate stochastic process
234, 327
stochastic process models
8, 111, 205, 210,
220, 223, 227, 236
Stopping probability
148
Stopping rule
informative
147, 149, 152
non-informative
149, 157
Strong Markov property
211
Structure
structure function
271, 276
Subjective probability
18
Subordinator
208, 253
Survivability assessment
289, 291–4,
347–8
Survival analysis
6–7, 22–3
Survival copula
87, 97
Survival function
60, 68, 87, 99–100, 318
Suspended animation
217
Synapses
292
Synaptic weights
292
System
102, 114, 269–308
System equation (or state equation)
178,
181, 198
System reliability
91, 93, 119, 281
System survivability
270, 283–5, 293–4
Time homogenous
215, 231, 232
Time on test
time on test transform
310
Time series
179, 342–3
Time transformation function
175, 176, 181
Time truncated life test (or Type II censoring)
146, 147, 150
Total time on test
149–50, 310
Total variation
56
Trained
4, 7, 292, 293
Training process
292
Transformation functions
175, 179
Transition function
215
Trigonometric functions
339–41
Two-phased neural net
293–4
Two-sided bet
18
Uncertainty
uncertain events
9
uncertain quantities
9–10
Uniform distribution
53
Unit
68–9, 190–2, 231–3, 286, 287, 290
Unit hypercube
270, 286–91
Unreliability
192, 193
Upper and lower probability paradigm
286
Upper probability
12, 286
Urn schemes
237
Usage process
121
Utile
32, 168, 169
Utility
utility functions
34, 162
utility of money
33
utility of reliability
299–303
Vague set
305, 306, 307
Vague systems
269–308

INDEX
371
Variance
61, 90
Volatility
317
Weibull distribution
54, 67, 137
Weibull survival function
247
Weight of evidence
28
Weighted likelihood
30
Weighted mixture
277
Wiener process
210
standard Wiener process
210–12, 214
Withdrawals
233
Yield curve
318, 323–4
Zero coupon bond
317


WILEY SERIES IN PROBABILITY AND STATISTICS
ESTABLISHED BY WALTER A. SHEWHART AND SAMUEL S. WILKS
Editors
David J. Balding, Peter Bloomfield, Noel A.C. Cressie, Nicholas I. Fisher, Iain M. Johnstone, J.B.
Kadane, Geert Molenberghs, Louise M. Ryan, David W. Scott, Adrian F.M. Smith
Editors Emeriti
Vic Barnett, J. Stuart Hunter, David G. Kendall, Jozef L. Teugels
The Wiley Series in Probability and Statistics is well established and authoritative. It covers many topics
of current research interest in both pure and applied statistics and probability theory. Written by leading
statisticians and institutions, the titles span both state-of-the-art developments in the field and classical
methods.
Reflecting the wide range of current research in statistics, the series encompasses applied, methodological
and theoretical statistics, ranging from applications and new techniques made possible by advances in
computerized practice to rigorous treatment of theoretical approaches.
This series provides essential and invaluable reading for all statisticians, whether in academia, industry,
government, or research.
ABRAHAM and LEDOLTER. Statistical Methods for Forecasting
AGRESTI. Analysis of Ordinal Categorical Data
AGRESTI. An Introduction to Categorical Data Analysis
AGRESTI. Categorical Data Analysis, Second Edition
ALTMAN, GILL, and McDONALD. Numerical Issues in Statistical Computing for the Social Scientist
AMARATUNGA and CABRERA. Exploration and Analysis of DNA Microarray and Protein Array Data
ANDˇEL. Mathematics of Chance
ANDERSON. An Introduction to Multivariate Statistical Analysis, Third Edition
*ANDERSON. The Statistical Analysis of Time Series
ANDERSON, AUQUIER, HAUCK, OAKES, VANDAELE, and WEISBERG. Statistical Methods for
Comparative Studies
ANDERSON and LOYNES. The Teaching of Practical Statistics
ARMITAGE and DAVID (editors). Advances in Biometry
ARNOLD, BALAKRISHNAN, and NAGARAJA. Records
*ARTHANARI and DODGE. Mathematical Programming in Statistics
*BAILEY. The Elements of Stochastic Processes with Applications to the Natural Sciences
BALAKRISHNAN and KOUTRAS. Runs and Scans with Applications
BARNETT. Comparative Statistical Inference, Third Edition
BARNETT. Environmental Statistics: Methods & Applications
BARNETT and LEWIS. Outliers in Statistical Data, Third Edition
BARTOSZYNSKI and NIEWIADOMSKA-BUGAJ. Probability and Statistical Inference
BASILEVSKY. Statistical Factor Analysis and Related Methods: Theory and Applications
BASU and RIGDON. Statistical Methods for the Reliability of Repairable Systems
BATES and WATTS. Nonlinear Regression Analysis and Its Applications
BECHHOFER, SANTNER, and GOLDSMAN. Design and Analysis of Experiments for Statistical Selection,
Screening, and Multiple Comparisons
BELSLEY. Conditioning Diagnostics: Collinearity and Weak Data in Regression
BELSLEY, KUH, and WELSCH. Regression Diagnostics: Identifying Influential Data and Sources of
Collinearity
BENDAT and PIERSOL. Random Data: Analysis and Measurement Procedures, Third Edition
BERNARDO and SMITH. Bayesian Theory
BERRY, CHALONER, and GEWEKE. Bayesian Analysis in Statistics and Econometrics: Essays in Honor
of Arnold Zellner
BHAT and MILLER. Elements of Applied Stochastic Processes, Third Edition
* Now available in a lower priced paperback edition in the Wiley Classics Library.

BHATTACHARYA and JOHNSON. Statistical Concepts and Methods
BHATTACHARYA and WAYMIRE. Stochastic Processes with Applications
BIEMER, GROVES, LYBERG, MATHIOWETZ and SUDMAN. Measurement Errors in Surveys
BILLINGSLEY. Convergence of Probability Measures, Second Edition
BILLINGSLEY. Probability and Measure, Third Edition
BIRKES and DODGE. Alternative Methods of Regression
BLISCHKE and MURTHY (editors). Case Studies in Reliability and Maintenance
BLISCHKE and MURTHY. Reliability: Modeling, Prediction, and Optimization
BLOOMFIELD. Fourier Analysis of Time Series: An Introduction, Second Edition
BOLLEN. Structural Equations with Latent Variables
BOLLEN and CURRAN. Latent Curve Models: A Structural Equation Perspective
BOROVKOV. Ergodicity and Stability of Stochastic Processes
BOULEAU. Numerical Methods for Stochastic Processes
BOX. Bayesian Inference in Statistical Analysis
BOX. R. A. Fisher, the Life of a Scientist
BOX and DRAPER. Empirical Model-Building and Response Surfaces
*BOX and DRAPER. Evolutionary Operation: A Statistical Method for Process Improvement
BOX, HUNTER, and HUNTER. Statistics for Experimenters: An Introduction to Design, Data Analysis,
and Model Building
BOX, HUNTER, and HUNTER. Statistics for Experimenters: Design, Innovation and Discovery, Second
Edition
BOX and LUCE ˜NO. Statistical Control by Monitoring and Feedback Adjustment
BRANDIMARTE. Numerical Methods in Finance: A MATLAB-Based Introduction
BROWN and HOLLANDER. Statistics: A Biomedical Introduction
BRUNNER, DOMHOF, and LANGER. Nonparametric Analysis of Longitudinal Data in Factorial
Experiments
BUCKLEW. Large Deviation Techniques in Decision, Simulation, and Estimation
CAIROLI and DALANG. Sequential Stochastic Optimization
CASTILLO, HADI, BALAKRISHNAN and SARABIA. Extreme Value and Related Models with
Applications in Engineering and Science
CHAN. Time Series: Applications to Finance
CHATTERJEE and HADI. Sensitivity Analysis in Linear Regression
CHATTERJEE and PRICE. Regression Analysis by Example, Third Edition
CHERNICK. Bootstrap Methods: A Practitioner’s Guide
CHERNICK and FRIIS. Introductory Biostatistics for the Health Sciences
CHIL`ES and DELFINER. Geostatistics: Modeling Spatial Uncertainty
CHOW and LIU. Design and Analysis of Clinical Trials: Concepts and Methodologies, Second Edition
CLARKE and DISNEY. Probability and Random Processes: A First Course with Applications, Second
Edition
*COCHRAN and COX. Experimental Designs, Second Edition
CONGDON. Applied Bayesian Modelling
CONGDON. Bayesian Statistical Modelling
CONGDON. Bayesian Models for Categorical Data
CONOVER. Practical Nonparametric Statistics, Second Edition
COOK. Regression Graphics
COOK and WEISBERG. Applied Regression Including Computing and Graphics
COOK and WEISBERG. An Introduction to Regression Graphics
CORNELL. Experiments with Mixtures, Designs, Models, and the Analysis of Mixture Data,
Third Edition
COVER and THOMAS. Elements of Information Theory
COX. A Handbook of Introductory Statistical Methods
*COX. Planning of Experiments
CRESSIE. Statistics for Spatial Data, Revised Edition
* Now available in a lower priced paperback edition in the Wiley Classics Library.

CS ¨ORG ¨O and HORV ´ATH. Limit Theorems in Change Point Analysis
DANIEL. Applications of Statistics to Industrial Experimentation
DANIEL. Biostatistics: A Foundation for Analysis in the Health Sciences, Sixth Edition
*DANIEL. Fitting Equations to Data: Computer Analysis of Multifactor Data, Second Edition
DASU and JOHNSON. Exploratory Data Mining and Data Cleaning
DAVID and NAGARAJA. Order Statistics, Third Edition
*DEGROOT, FIENBERG, and KADANE. Statistics and the Law
DEL CASTILLO. Statistical Process Adjustment for Quality Control
DEMARIS. Regression with Social Data: Modeling Continuous and Limited Response Variables
DEMIDENKO. Mixed Models: Theory and Applications
DENISON, HOLMES, MALLICK, and SMITH. Bayesian Methods for Nonlinear Classification and
Regression
DETTE and STUDDEN. The Theory of Canonical Moments with Applications in Statistics, Probability,
and Analysis
DEY and MUKERJEE. Fractional Factorial Plans
DILLON and GOLDSTEIN. Multivariate Analysis: Methods and Applications
DODGE. Alternative Methods of Regression
*DODGE and ROMIG. Sampling Inspection Tables, Second Edition
*DOOB. Stochastic Processes
DOWDY and WEARDEN, and CHILKO. Statistics for Research, Third Edition
DRAPER and SMITH. Applied Regression Analysis, Third Edition
DRYDEN and MARDIA. Statistical Shape Analysis
DUDEWICZ and MISHRA. Modern Mathematical Statistics
DUNN and CLARK. Applied Statistics: Analysis of Variance and Regression, Second Edition
DUNN and CLARK. Basic Statistics: A Primer for the Biomedical Sciences, Third Edition
DUPUIS and ELLIS. A Weak Convergence Approach to the Theory of Large Deviations
EDLER and KITSOS (editors). Recent Advances in Quantitative Methods in Cancer and Human Health
Risk Assessment
*ELANDT-JOHNSON and JOHNSON. Survival Models and Data Analysis
ENDERS. Applied Econometric Time Series
ETHIER and KURTZ. Markov Processes: Characterization and Convergence
EVANS, HASTINGS, and PEACOCK. Statistical Distributions, Third Edition
FELLER. An Introduction to Probability Theory and Its Applications, Volume I, Third Edition, Revised;
Volume II, Second Edition
FISHER and VAN BELLE. Biostatistics: A Methodology for the Health Sciences
FITZMAURICE, LAIRD, and WARE. Applied Longitudinal Analysis
*FLEISS. The Design and Analysis of Clinical Experiments
FLEISS. Statistical Methods for Rates and Proportions, Second Edition
FLEMING and HARRINGTON. Counting Processes and Survival Analysis
FULLER. Introduction to Statistical Time Series, Second Edition
FULLER. Measurement Error Models
GALLANT. Nonlinear Statistical Models.
GELMAN and MENG (editors): Applied Bayesian Modeling and Casual Inference from Incomplete-data
Perspectives
GEWEKE. Contemporary Bayesian Econometrics and Statistics
GHOSH, MUKHOPADHYAY, and SEN. Sequential Estimation
GIESBRECHT and GUMPERTZ. Planning, Construction, and Statistical Analysis of Comparative
Experiments
GIFI. Nonlinear Multivariate Analysis
GIVENS and HOETING. Computational Statistics
GLASSERMAN and YAO. Monotone Structure in Discrete-Event Systems
GNANADESIKAN. Methods for Statistical Data Analysis of Multivariate Observations,Second Edition
* Now available in a lower priced paperback edition in the Wiley Classics Library.

GOLDSTEIN and LEWIS. Assessment: Problems, Development, and Statistical Issues
GREENWOOD and NIKULIN. A Guide to Chi-Squared Testing
GROSS and HARRIS. Fundamentals of Queueing Theory, Third Edition
*HAHN and SHAPIRO. Statistical Models in Engineering
HAHN and MEEKER. Statistical Intervals: A Guide for Practitioners
HALD. A History of Probability and Statistics and their Applications Before 1750
HALD. A History of Mathematical Statistics from 1750 to 1930
HAMPEL. Robust Statistics: The Approach Based on Influence Functions
HANNAN and DEISTLER. The Statistical Theory of Linear Systems
HEIBERGER. Computation for the Analysis of Designed Experiments
HEDAYAT and SINHA. Design and Inference in Finite Population Sampling
HELLER. MACSYMA for Statisticians
HINKELMAN and KEMPTHORNE:. Design and Analysis of Experiments, Volume 1: Introduction to
Experimental Design
HINKELMANN and KEMPTHORNE. Design and analysis of experiments, Volume 2: Advanced
Experimental Design
HOAGLIN, MOSTELLER, and TUKEY. Exploratory Approach to Analysis of Variance
HOAGLIN, MOSTELLER, and TUKEY. Exploring Data Tables, Trends and Shapes
*HOAGLIN, MOSTELLER, and TUKEY. Understanding Robust and Exploratory Data Analysis
HOCHBERG and TAMHANE. Multiple Comparison Procedures
HOCKING. Methods and Applications of Linear Models: Regression and the Analysis of Variance, Second
Edition
HOEL. Introduction to Mathematical Statistics, Fifth Edition
HOGG and KLUGMAN. Loss Distributions
HOLLANDER and WOLFE. Nonparametric Statistical Methods, Second Edition
HOSMER and LEMESHOW. Applied Logistic Regression, Second Edition
HOSMER and LEMESHOW. Applied Survival Analysis: Regression Modeling of Time to Event Data
HUBER. Robust Statistics
HUBERTY. Applied Discriminant Analysis
HUNT and KENNEDY. Financial Derivatives in Theory and Practice, Revised Edition
HUSKOVA, BERAN, and DUPAC. Collected Works of Jaroslav Hajek—with Commentary
HUZURBAZAR. Flowgraph Models for Multistate Time-to-Event Data
IMAN and CONOVER. A Modern Approach to Statistics
JACKSON. A User’s Guide to Principle Components
JOHN. Statistical Methods in Engineering and Quality Assurance
JOHNSON. Multivariate Statistical Simulation
JOHNSON and BALAKRISHNAN. Advances in the Theory and Practice of Statistics: A Volume in Honor
of Samuel Kotz
JOHNSON and BHATTACHARYYA. Statistics: Principles and Methods, Fifth Edition
JUDGE, GRIFFITHS, HILL, LU TKEPOHL, and LEE. The Theory and Practice of Econometrics, Second
Edition
JOHNSON and KOTZ. Distributions in Statistics
JOHNSON and KOTZ (editors). Leading Personalities in Statistical Sciences: From the Seventeenth Century
to the Present
JOHNSON, KOTZ, and BALAKRISHNAN. Continuous Univariate Distributions, Volume 1, Second Edition
JOHNSON, KOTZ, and BALAKRISHNAN. Continuous Univariate Distributions, Volume 2, Second Edition
JOHNSON, KOTZ, and BALAKRISHNAN. Discrete Multivariate Distributions
JOHNSON, KOTZ, and KEMP. Univariate Discrete Distributions, Second Edition
JURE ˇCKOV ´A and SEN. Robust Statistical Procedures: Asymptotics and Interrelations
JUREK and MASON. Operator-Limit Distributions in Probability Theory
KADANE. Bayesian Methods and Ethics in a Clinical Trial Design
KADANE and SCHUM. A Probabilistic Analysis of the Sacco and Vanzetti Evidence
* Now available in a lower priced paperback edition in the Wiley Classics Library.

KALBFLEISCH and PRENTICE. The Statistical Analysis of Failure Time Data, Second Edition
KARIYA and KURATA. Generalized Least Squares
KASS and VOS. Geometrical Foundations of Asymptotic Inference
KAUFMAN and ROUSSEEUW. Finding Groups in Data: An Introduction to Cluster Analysis
KEDEM and FOKIANOS. Regression Models for Time Series Analysis
KENDALL, BARDEN, CARNE, and LE. Shape and Shape Theory
KHURI. Advanced Calculus with Applications in Statistics, Second Edition
KHURI, MATHEW, and SINHA. Statistical Tests for Mixed Linear Models
*KISH. Statistical Design for Research
KLEIBER and KOTZ. Statistical Size Distributions in Economics and Actuarial Sciences
KLUGMAN, PANJER, and WILLMOT. Loss Models: From Data to Decisions
KLUGMAN, PANJER, and WILLMOT. Solutions Manual to Accompany Loss Models: From Data to
Decisions
KOTZ, BALAKRISHNAN, and JOHNSON. Continuous Multivariate Distributions, Volume 1, Second
Edition
KOTZ and JOHNSON (editors). Encyclopedia of Statistical Sciences: Volumes 1 to 9 with Index
KOTZ and JOHNSON (editors). Encyclopedia of Statistical Sciences: Supplement Volume
KOTZ, READ, and BANKS (editors). Encyclopedia of Statistical Sciences: Update Volume 1
KOTZ, READ, and BANKS (editors). Encyclopedia of Statistical Sciences: Update Volume 2
KOVALENKO, KUZNETZOV, and PEGG. Mathematical Theory of Reliability of Time-Dependent
Systems with Practical Applications
KUROWICKA and COOKE. Uncertainty Analysis with High Dimensional Dependence Modelling
LACHIN. Biostatistical Methods: The Assessment of Relative Risks
LAD. Operational Subjective Statistical Methods: A Mathematical, Philosophical, and Historical Introduction
LAMPERTI. Probability: A Survey of the Mathematical Theory, Second Edition
LANGE, RYAN, BILLARD, BRILLINGER, CONQUEST, and GREENHOUSE. Case Studies in Biometry
LARSON. Introduction to Probability Theory and Statistical Inference, Third Edition
LAWLESS. Statistical Models and Methods for Lifetime Data, Second Edition
LAWSON. Statistical Methods in Spatial Epidemiology, Second Edition
LE. Applied Categorical Data Analysis
LE. Applied Survival Analysis
LEE and WANG. Statistical Methods for Survival Data Analysis, Third Edition
LEPAGE and BILLARD. Exploring the Limits of Bootstrap
LEYLAND and GOLDSTEIN (editors). Multilevel Modelling of Health Statistics
LIAO. Statistical Group Comparison
LINDVALL. Lectures on the Coupling Method
LINHART and ZUCCHINI. Model Selection
LITTLE and RUBIN. Statistical Analysis with Missing Data, Second Edition
LLOYD. The Statistical Analysis of Categorical Data
LOWEN and TEICH. Fractal-Based Point Processes
MAGNUS and NEUDECKER. Matrix Differential Calculus with Applications in Statistics and Economet-
rics, Revised Edition
MALLER and ZHOU. Survival Analysis with Long Term Survivors
MALLOWS. Design, Data, and Analysis by Some Friends of Cuthbert Daniel
MANN, SCHAFER, and SINGPURWALLA. Methods for Statistical Analysis of Reliability and Life Data
MANTON, WOODBURY, and TOLLEY. Statistical Applications Using Fuzzy Sets
MARCHETTE. Random Graphs for Statistical Pattern Recognition
MARDIA and JUPP. Directional Statistics
MARONNA, MARTIN, and YOHAI. Robust Statistics: Theory and Methods
MASON, GUNST, and HESS. Statistical Design and Analysis of Experiments with Applications to Engi-
neering and Science, Second Edition
MCCULLOCH and SEARLE. Generalized, Linear, and Mixed Models
* Now available in a lower priced paperback edition in the Wiley Classics Library.

MCFADDEN. Management of Data in Clinical Trials
MCLACHLAN. Discriminant Analysis and Statistical Pattern Recognition
MCLACHLAN, DO, and AMBROISE. Analyzing Microarray Gene Expression Data
MCLACHLAN and KRISHNAN. The EM Algorithm and Extensions
MCLACHLAN and PEEL. Finite Mixture Models
MCNEIL. Epidemiological Research Methods
MEEKER and ESCOBAR. Statistical Methods for Reliability Data
MEERSCHAERT and SCHEFFLER. Limit Distributions for Sums of Independent Random Vectors: Heavy
Tails in Theory and Practice
MICKEY, DUNN and CLARK. Applied Statistics: Analysis of Variance and Regression, Third Edition
*MILLER. Survival Analysis, Second Edition
MONTGOMERY, PECK, and VINING. Introduction to Linear Regression Analysis, Third Edition
MORGENTHALER and TUKEY. Configural Polysampling: A Route to Practical Robustness
MUIRHEAD. Aspects of Multivariate Statistical Theory
MURRAY. X-STAT 2.0 Statistical Experimentation, Design Data Analysis, and Nonlinear Optimization
MURTHY, XIE, and JIANG. Weibull Models
MYERS and MONTGOMERY. Response Surface Methodology: Process and Product Optimization Using
Designed Experiments, Second Edition
MYERS, MONTGOMERY, and VINING. Generalized Linear Models. With Applications in Engineering
and the Sciences
†NELSON. Accelerated Testing, Statistical Models, Test Plans, and Data Analyses
†NELSON. Applied Life Data Analysis
NEWMAN. Biostatistical Methods in Epidemiology
OCHI. Applied Probability and Stochastic Processes in Engineering and Physical Sciences
OKABE, BOOTS, SUGIHARA, and CHIU. Spatial Tesselations: Concepts and Applications of Voronoi
Diagrams, Second Edition
OLIVER and SMITH. Influence Diagrams, Belief Nets and Decision Analysis
PALTA. Quantitative Methods in Population Health: Extensions of Ordinary Regressions
PANKRATZ. Forecasting with Dynamic Regression Models
PANKRATZ. Forecasting with Univariate Box-Jenkins Models: Concepts and Cases
*PARZEN. Modern Probability Theory and It’s Applications
PE ˜NA, TIAO, and TSAY. A Course in Time Series Analysis
PIANTADOSI. Clinical Trials: A Methodologic Perspective
PORT. Theoretical Probability for Applications
POURAHMADI. Foundations of Time Series Analysis and Prediction Theory
PRESS. Bayesian Statistics: Principles, Models, and Applications
PRESS. Subjective and Objective Bayesian Statistics, Second Edition
PRESS and TANUR. The Subjectivity of Scientists and the Bayesian Approach
PUKELSHEIM. Optimal Experimental Design
PURI, VILAPLANA, and WERTZ. New Perspectives in Theoretical and Applied Statistics
PUTERMAN. Markov Decision Processes: Discrete Stochastic Dynamic Programming
QIU. Image Processing and Jump Regression Analysis
*RAO. Linear Statistical Inference and Its Applications, Second Edition
RAUSAND and HØYLAND. System Reliability Theory: Models, Statistical Methods and Applications,
Second Edition
RENCHER. Linear Models in Statistics
RENCHER. Methods of Multivariate Analysis, Second Edition
RENCHER. Multivariate Statistical Inference with Applications
RIPLEY. Spatial Statistics
RIPLEY. Stochastic Simulation
ROBINSON. Practical Strategies for Experimenting
* Now available in a lower priced paperback edition in the Wiley Classics Library.
† Now available in a lower priced paperback edition in the Wiley - Interscience Paperback Series.

ROHATGI and SALEH. An Introduction to Probability and Statistics, Second Edition
ROLSKI, SCHMIDLI, SCHMIDT, and TEUGELS. Stochastic Processes for Insurance and Finance
ROSENBERGER and LACHIN. Randomization in Clinical Trials: Theory and Practice
ROSS. Introduction to Probability and Statistics for Engineers and Scientists
ROSSI, ALLENBY and MCCULLOCH. Bayesian Statistics and Marketing
ROUSSEEUW and LEROY. Robust Regression and Outlier Detection
RUBIN. Multiple Imputation for Nonresponse in Surveys
RUBINSTEIN. Simulation and the Monte Carlo Method
RUBINSTEIN and MELAMED. Modern Simulation and Modeling
RYAN. Modern Regression Methods
RYAN. Statistical Methods for Quality Improvement, Second Edition
SALTELLI, CHAN, and SCOTT (editors). Sensitivity Analysis
*SCHEFFE. The Analysis of Variance
SCHIMEK. Smoothing and Regression: Approaches, Computation, and Application
SCHOTT. Matrix Analysis for Statistics
SCHOUTENS. Levy Processes in Finance: Pricing Financial Derivatives
SCHUSS. Theory and Applications of Stochastic Differential Equations
SCOTT. Multivariate Density Estimation: Theory, Practice, and Visualization
*SEARLE. Linear Models
SEARLE. Linear Models for Unbalanced Data
SEARLE. Matrix Algebra Useful for Statistics
SEARLE, CASELLA, and McCULLOCH. Variance Components
SEARLE and WILLETT. Matrix Algebra for Applied Economics
SEBER. Multivariate Observations
SEBER and LEE. Linear Regression Analysis, Second Edition
SEBER and WILD. Nonlinear Regression
SENNOTT. Stochastic Dynamic Programming and the Control of Queueing Systems
*SERFLING. Approximation Theorems of Mathematical Statistics
SHAFER and VOVK. Probability and Finance: Its Only a Game!
SILVAPULLE and SEN. Constrained Statistical Inference: Inequality, Order, and Shape Restrictions
SINGPURWALLA. Reliability and Risk: A Bayesian Perspective
SMALL and MCLEISH. Hilbert Space Methods in Probability and Statistical Inference
SRIVASTAVA. Methods of Multivariate Statistics
STAPLETON. Linear Statistical Models
STAUDTE and SHEATHER. Robust Estimation and Testing
STOYAN, KENDALL, and MECKE. Stochastic Geometry and Its Applications, Second Edition
STOYAN and STOYAN. Fractals, Random Shapes and Point Fields: Methods of Geometrical Statistics
STYAN. The Collected Papers of T. W. Anderson: 1943–1985
SUTTON, ABRAMS, JONES, SHELDON, and SONG. Methods for Meta-Analysis in Medical Research
TANAKA. Time Series Analysis: Nonstationary and Noninvertible Distribution Theory
THOMPSON. Empirical Model Building
THOMPSON. Sampling, Second Edition
THOMPSON. Simulation: A Modeler’s Approach
THOMPSON and SEBER. Adaptive Sampling
THOMPSON, WILLIAMS, and FINDLAY. Models for Investors in Real World Markets
TIAO, BISGAARD, HILL, PE ˜NA, and STIGLER (editors). Box on Quality and Discovery: with Design,
Control, and Robustness
TIERNEY. LISP-STAT: An Object-Oriented Environment for Statistical Computing and Dynamic Graphics
TSAY. Analysis of Financial Time Series
UPTON and FINGLETON. Spatial Data Analysis by Example, Volume II: Categorical and Directional Data
VAN BELLE. Statistical Rules of Thumb
* Now available in a lower priced paperback edition in the Wiley Classics Library.

VAN BELLE, FISHER, HEAGERTY, and LUMLEY. Biostatistics: A Methodology for the Health Sciences,
Second Edition
VESTRUP. The Theory of Measures and Integration
VIDAKOVIC. Statistical Modeling by Wavelets
VINOD and REAGLE. Preparing for the Worst: Incorporating Downside Risk in Stock Market Investments
WALLER and GOTWAY. Applied Spatial Statistics for Public Health Data
WEERAHANDI. Generalized Inference in Repeated Measures: Exact Methods in MANOVA and Mixed
Models
WEISBERG. Applied Linear Regression, Second Edition
WELSH. Aspects of Statistical Inference
WESTFALL and YOUNG. Resampling-Based Multiple Testing: Examples and Methods for p-Value
Adjustment
WHITTAKER. Graphical Models in Applied Multivariate Statistics
WINKER. Optimization Heuristics in Economics: Applications of Threshold Accepting
WONNACOTT and WONNACOTT. Econometrics, Second Edition
WOODING. Planning Pharmaceutical Clinical Trials: Basic Statistical Principles
WOOLSON and CLARKE. Statistical Methods for the Analysis of Biomedical Data, Second Edition
WU and HAMADA. Experiments: Planning, Analysis, and Parameter Design Optimization
YANG. The Construction Theory of Denumerable Markov Processes
*ZELLNER. An Introduction to Bayesian Inference in Econometrics
ZELTERMAN. Discrete Distributions: Applications in the Health Sciences
ZHOU, OBUCHOWSKI, and McCLISH. Statistical Methods in Diagnostic Medicine
* Now available in a lower priced paperback edition in the Wiley Classics Library.

