

FUNDAMENTALS OF MATHEMATICS 
VOLUME I 
Foundations of Mathematics 
The Real Number System and Algebra 

Fundamentals of Mathematics 
Volume I 
Foundations of Mathematics 
The Real Number System and Algebra 
Volume n 
Geometry 
Volume III 
Analysis 

FUNDAMENTALS OF MATHEMATICS 
VOLUME I 
Foundations of Mathematics 
The Real Number System and Algebra 
Edited by 
H. Behnke 
F. Bachmann 
K. Fladt 
w. Suss 
with the assistance 9f 
H. Gerike 
F. Hohenberg 
G. Pickert 
H. Rau 
Translated by 
S. H. Gould 
The MIT Press Cambridge, Massachusetts, and London, England 

Originally published by Vandenhoeck & Ruprecht, Gottingen, Germany, under the title 
Grundzuge der Mathematik. The publication was sponsored by the German section of the 
International Commission for Mathematical Instruction. The translation of this volume 
is based upon the second German edition of 1962. 
Third printing, 1986 
First MIT Press paperback edition, 1983 
English translation copyright © 1974 by 
The Massachusetts Institute of Technology. 
Printed and bound in the United States of America. 
All rights reserved. No part of this book may be reproduced in any form or by any 
means, electronic or mechanical, including photocopying, recording, or by any informa-
tion storage and retrieval system, without permission in writing from the publisher. 
ISBN 0-262-02048-3 (hardcover) 
0-262-52093-1 (paperback) 
Library of Congress catalog card number: 68-14446 

Translator's Foreword 
From the Preface (to the 1958 Edition), 
Heinrich Behnke and Kuno Fladt 
PART A 
FOUNDATIONS OF MATHEMATICS 
H. Hermes and W. Markwald 
Contents 
ix 
x 
1. Conceptions of the Nature of Mathematics 
3 
2. Logical Analysis of Propositions 
9 
3. The Concept of a Consequence 
20 
4. Axiomatization 
26 
5. The Conc~pt of an Algorithm 
32 
6. Proofs 
41 
7. Theory of Sets 
50 
8. Theory of Relations 
61 
9. Boolean Algebra 
66 
10. Axiomatization of the Natural Numbers 
71 
1 I. Antinomies 
80 
Bibliography 
86 
PART B 
89 
ARITHMETIC AND ALGEBRA 
Introduction, W. Grobner 
91 
CHAPTER I 
Construction of the System of Real Numbers, G. Pickert and L. 
Gorke 
93 
1. The Natural Numbers 
93 
v 

vi 
2. The Integers 
3. The Rational Numbers 
4. The Real Numbers 
Appendix: Ordinal Numbers, D. Kurepa and A. Aymanns 
CHAPTER 2 
Groups, W. Gaschutz and H. Noack 
1. Axioms and Examples 
2. Immediate Consequences of the Axioms for a Group 
3. Methods of Investigating the Structure of Groups 
4. Isomorphisms 
5. Cyclic Groups 
6. Normal Subgroups and Factor Groups 
7. The Commutator Group 
8. Direct Products 
9. Abelian Groups 
10. The Homomorphism Theorem 
11. The Isomorphism Theorem 
12. Composition Series, Jordan-HOlder Theorem 
13. Normalizer, Centralizer, Center 
14. p-Groups 
15. Permutation Groups 
16. Some Remarks on More General Infinite Groups 
CHAPTER 3 
Linear Algebra, H. Gericke and H. Wasche 
1. The Concept of a Vector Space 
2. Linear Transformations of Vector Spaces 
3. Products of Vectors 
CHAPTER 4 
Polynomials, G. Pickert and W. Ruckert 
1. Entire Rational Functions 
2. Polynomials 
3. The Use of Indeterminates as a Method of Proof 
CHAPTER 5 
Rings and Ideals, W. Grobner and P. Lesky 
1. Rings, Integral Domains, Fields 
CONTENTS 
105 
121 
129 
153 
166 
]67 
178 
182 
188 
19) 
194 
197 
198 
]99 
212 
214 
215 
217 
219 
220 
230 
233 
235 
246 
266 
291 
291 
296 
312 
316 
316 

CONTENTS 
vii 
2. Divisibility in Integral Domains 
327 
3. Ideals in Commutative Rings, Principal Ideal Rings, Residue 
Class Rings 
338 
4. Divisibility in Polynomial Rings Elimination 
346 
CHAPTER 6 
Theory of Numbers, H.-H. Ostmann and H. Liermann 
355 
1. Introduction 
355 
2. Divisibility Theory 
355 
3. Continued Fractions 
372 
4. Congruences 
380 
5. Some Number-Theoretic Functions; The Mobius Inversion 
Formula 
388 
6. The Chinese Remainder Theorem; Direct Decomposition of 
(f,/{m) 
391 
7. Diophantine Equations; Algebraic Congruences 
395 
8. Algebraic Numbers 
401 
9. Additive Number Theory 
405 
CHAPTER 7 
Algebraic Extensions of a Field, O. Haupt and P. Sengenhorst 
409 
1. The Splitting Field of a Polynomial 
410 
2. Finite Extensions 
418 
3. Normal Extensions 
420 
4. Separable Extensions 
422 
5. Roots of Unity 
425 
6. Isomorphic Mappings of Separable Finite Extensions 
431 
7. Normal Fields and the A utomorphism Group ( Galois Group) 
433 
8. Finite Fields 
438 
9. Irreducibility of the Cyclotomic Polynomial and Structure of 
the Galois Group of the Cyclotomic Field over the Field of 
Rational Numbers 
448 
10. Solvability by Radicals. Equations of the Third and Fourth 
Degree 
452 
CHAPTER 8 
Complex Numbers and Quaternions, G. Pickert and H.-G. 
Steiner 
456 
1. The Complex Numbers 
456 

viii 
CONTENTS 
2. Algebraic Closedness of the Field of Complex Numbers 
3. Quaternions 
CHAPTER 9 
Lattices, H. Gericke and H. Martens 
I. Properties of the Power Set 
2. Examples 
3. Lattices of Finite Length 
4. Distributive Lattices 
5. Modular Lattices 
6. Projective Geometry 
CHAPTER 10 
Some Basic Concepts for a Theory of Structure, H. Gericke and 
462 
467 
483 
485 
490 
495 
497 
501 
505 
H. Martens 
508 
I. Configurations 
509 
2. Structure 
515 
CHAPTER II 
Zorn's Lemma and the High Chain Principle, H. Wolff and H. 
Noack 
522 
I. Ordered Sets 
522 
2. Zorn's Lemma 
524 
3. Examples of the Application of Zorn's Lemma 
525 
4. Proof of Zorn's Lemma from the Axiom of Choice 
529 
5. Questions Concerning the Foundations of Mathematics 
534 
Bibliography 
536 
Index 
537 

Translator's Foreword 
The pleasant task of translating this unique work has now extended 
over several years, in the course of which I have received invaluable as-
sistance from many sources. Fortunately I had the opportunity, in personal 
conversation or in correspondence, of discussing the entire translation 
with the original authors, many of whom suggested improvements, sup-
plied exercises, or made changes and additions in the German text, 
wherever they seemed desirable to bring the discussion up to date, for 
example, on the continuum hypothesis, Zorn's lemma, or groups of odd 
order. To· all these authors I express my gratitude. 
For technical and clerical help I am especially indebted to Linda Shepard, 
of the Law School at the University of Utah, for her expert typing and 
discriminating knowledge of English; to Diane Houle, supervisor of the 
Varitype Section of the American Mathematical Society, for her unrivaled 
skill and experience in the typing of mathematical translations; to Linda 
Rinaldi and Ingeborg Menz, secretaries, respectively, of the Translations 
Department of the Society and the firm Vandenhoeck and Ruprecht, for 
keeping straight a long and complicated correspondence; to the staff of 
The MIT Press for their customary technical ex~ertness; and to my wife, 
Katherine Gould, for help too varied and too substantial to be readily 
described. 
S. H. Gould 
Institute of Mathematics 
Academia Sinica 
Tai pei, T ai wan 
Repu bJic of China 
Septem her 1973 
Ix 

From the Preface 
Volume One was begun as the first contribution, by the German section 
of the International Commission for Mathematical Instruction, to the 
topic of the scientific foundations of instruction in mathematics, which 
was one of the topics chosen by the Commission, at a meeting in Paris in 
October 1954, in preparation for the International Congress of Mathe-
maticians in Edinburgh in 1958. Originally we kept chiefly in mind the 
needs and interests of the instructor in mathematics, but as our cooperative 
effort continued from year to year, it became clear that the material in our 
book was equally important for mathematicians in science, government, 
and industry. For the best realization of our general purposes, each 
chapter has been written by two authors, one of them a university pro-
fessor, the other an instructor with long experience in teaching. In addition 
to these specifically named authors, of whom there will eventually be more 
than one hundred, from Germany, Yugoslavia, the Netherlands, Austria, 
and Switzerland, important contributions have been made to each chapter, 
in joint semiannual sessions, by the other members of our large group of 
coworkers. 
H. Behnke 
K. Fladt 
x 

PART A 
FOUNDATIONS OF MATHEMATICS 


1. Conceptions of the Nature of Mathematics 
1.1. 
Mathematics and Its Foundations 
In this section, which is an introduction to the work as a whole, we shall 
be discussing the foundations of mathematics. In other words, we are 
not doing mathematics here; we are talking about mathematics. We are 
engaged in a scientific activity that has received the appropriate name of 
metamathematics. 
Metamathematics forms a bridge between mathematics and philosophy. 
Some of its investigations can be carried out by mathematical methods, 
and to this extent the subject shares the exactness of mathematics, the 
most precise of all sciences. But other parts of metamathematics, among 
them the most fundamental, are not of a mathematical nature, so that we 
cannot expect them to have the absolute clarity of mathematics. As in 
all other branches of philosophy, the answers to many questions are to 
some extent a matter of subjective attitude and even of faith, and in any 
given period the attitude predominantly adopted is determined in part 
by the general spirit of the age. Fundamental philosophical concepts, 
such as idealism, realism, and nominalism, which for centuries have 
contended with one another with varying success, are reflected in the 
different views about the nature of mathematics. Apparently there is no 
hope of progress in an attempt to refute anyone of these views scien-
tdically: rather we try to characterize them as precisely and clearly as 
possible and in this way keep them apart. 
Studies about the foundations of mathematics have experienced a 
tremendous upsurge during the past hundred years, especially since the 
turn of the century. The chief impetus for these investigations was provided 
by the discovery of contradictions in the theory of sets, a mathematical 
3 

4 
PART A FOUNDATIONS OF MATHEMATICS 
discipline created during the nineteenth century in connection with 
eventually successful attempts to clear up the nature of the real numbers. 
Since many of these paradoxes had already become apparent in antiquity, 
it is natural to ask why we are now able to deal with them successfully, 
whereas the ancients found them completely intractable. The answer is 
that the paradoxes necessarily remained intractable as long as J:hey were 
expressed in one of the natural languages, such as English. On the shaky 
ground of such an imprecise language it is impossible to deal with questions 
of great subtlety, and our present-day successes are entirely due to a 
new instrument, the thoroughgoing formalization of mathematics. With 
this new tool it has at last become possible to construct meta mathematical 
theories (for example, that of "classical" logic) which are just as exact 
as the theories of ordinary mathematics. These new meta mathematical 
theories are regarded by many mathematicians as the essential hallmark 
of present-day mathematics. 
In the following pages we shall describe some of the various conceptions 
of the nature of mathematics, but it must be remembered that they are 
only ex post facto idealizations of the nature of mathematics. All idealiza-
tions are extreme in one direction or another, so that scarcely any mathe-
matician will agree with every detail of any of the positions that we 
shall describe. Mathematics as it exists today is in fact the creation 
of scientists whose inspiration has come from the most varied sources. 
It is to this variety that mathematics owes its immense vitality. 
1.2. 
The Genetic Conception of Mathematics 
We first describe a conception of mathematics in which the central role 
is played by the human being and his capabilities, so that mathematics 
may almost be said to be a branch of psychology. For example, let us 
consider the subject of geometry. It is certainly true that the earliest 
knowledge of geometry, say among the Babylonians, depended on the 
empirical results of practical surveyors; it is easy to imagine, for instance, 
how the Pythagorean theorem could arise from individual observations. 
Yet at this stage the theorem can hardly be called mathematical, since the 
characteristic difference between a natural science and the purely abstract 
science of mathematics is considered to be that the statements of a natural 
science can be tested (directly or indirectly) by observation, whereas for 
mathematical statements such a test is regarded (for widely varying 
reasons), as meaningless; mathematics is an a priori science in the sense 
of Kant. Consequently, geometry was in its origins a natural science, 
and was not "raised" to the position of an abstract, and therefore mathe-
matical, science until the time of the Greeks. It was they who under 
the influence of Plato distinguished between axioms and the theorems 
derived from them. In their view the axioms were self-evident (cf. §1.3), 

1 Conceptions of the Nature of Mathematics 
5 
and the theorems were derived by the process of logical deduction. 
It is probable that the Greek mathematicians took the same attitude 
toward logic as is taken today by most "naive" mathematicians: in 
principle, the ability to reason logically is inborn but can be improved 
with practice. 
Arithmetic and many other branches of mathematics may well have 
begun like geometry as a collection of empirical facts, which was gradually 
raised to the status of a mathematical science. 
But mathematical sciences can arise in another way, which may be 
called intramathematical, to distinguish it from the natural sciences. 
One of the strongest impulses here is the inborn urge, experienced by 
most mathematicians and particularly well-developed among the Greeks, 
toward the sort of beauty that manifests itself in simplicity and symmetry. 
The mathematician feels compelled, while continuing to observe the 
demands of logic, to do away with exceptions. The desire to make the 
operations of subtraction and division 
univ~rsally applicable led to 
the rational numbers. Exceptions in the operation of passing to the limit 
no longer arose in the field of real numbers. The exceptional case of 
parallel lines was removed by the introduction of "infinitely distant" 
points, and in recent times the many exceptional cases arising from the 
existence of nondifferentiable functions have been avoided by the introduc-
tion of distributions (cf. Vol. III, chap. 3, §3), which had already turned 
up among the physicists, in the form of the Dirac S-function. 
Most of these new mathematical entities, created to avoid the necessity 
for exceptional cases, were in the first place introduced more or less 
uncritically to meet the demands of each given case. But subsequently 
there arose a desire to establish the actual existence of such entities. 
A powerful tool here is the process of abstraction, which may be described 
as follows. Let there be given a set of entities which agree in many of 
their properties but differ in others. By an act that is in essence arbitrary, 
we shall declare that some of these properties, depending on the context 
in which we make the decision, are essential while all others are not 
essential. The act of "abstraction" from the nonessential properties 
consists of identifying (i.e., regarding as identical) those entities that differ 
only in nonessential properties. A set of such entities thus becomes a 
single unit and in this way a new entity is created (cf. §8.5). This act 
of creation, familar to every present-day mathematician" may be regarded 
as a general human capability. Here we shall only remark that in 
modern mathematics the process of abstraction, in conjunction with 
the search for simplicity, has led to the general structures that are 
to be found, for example, in the theory of groups (cf. §4.3, and Vol. IB, 
chap. 2). 

6 
PART A FOUNDATIONS OF MATHEMATICS 
1.3. 
The Extent to Which Mathematical Propositions Are Self-Evident 
As mentioned before, the Greeks divided valid mathematical propo-
sitions into axioms and theorems derived therefrom. The axioms were 
considered self-evident, immediately obvious to everyone, "neither in 
need of proof nor admitting proof." The theorems, on the other hand, 
were not immediately obvious in themselves but became evident by being 
derived from the axioms through a series of arguments, each of which 
was obviously valid. But today, as a result of the discovery of non-
Euclidean geometries, hardly any mathematician holds to the obviousness 
of Euclidean geometry. The axioms of group theory, field theory, lattice 
theory, and so forth are no longer considered obvious. At most, the 
theorems of arithmetic, logic, and perhaps the theory of sets may appear 
evident (either directly or indirectly) to certain mathematicians. For 
example, the intuitionists, following L. E. J. Brouwer, require that every 
mathematical construction shall be so immediately apparent to the 
human mind, and the result so clear, that no further proof is necessary. 
In §4.7 we shalt discuss the attempts that have been made to show that 
mathematics is free of inconsistencies. Clearly such a proof of con-
sistency will be more widely accepted if it can be based on concepts 
intuitively apparent to everyone. 
To clarify these remarks, let us give an example of a statement that 
will be considered self-evident by many readers. Let there be given two 
distinct symbols, neither of which can be divided into meaningful parts. 
Then it will be considered self-evident that the two "words" obtained by 
writing these symbols, first in the one order and then in the other, are 
distinct from each other. 
1.4. 
The Meaning of Mathematical Propositions 
In general, mathematicians are convinced that their propositions are 
meaningful, the extreme position in this respect being that of the so-called 
formalists, who consider mathematics to be a mere game with symbols, 
the rules of which, in the last analysis, are chosen arbitrarily (conven-
tionalism). Formalism was introduced by Hilbert as a methodological 
principle whereby the concept of a proof of consistency' could be clearly 
stated. The formalistic point of view can also be applied to physics if 
with H. Hertzl we define the task of theoretical physics as follows: 
"Within our OWfl minds we create images or symbols of the external 
objects, and we construct them in such a way that the logically necessary 
consequences of the images are again the images of the physically 
necessary consequences of the objects." In other words, we construct a 
process parallel to the process of nature. But the essential feature here 
1 Die Prinzipien der Mechanik, Ambrosius Barth, Leipzig (1894), Introduction. 

1 Conceptions of the Nature of Mathematics 
7 
is not that this process involves "logical thought" but rather that it runs 
parallel to the process of nature. Thus we could equally well have chosen 
a purely formalistic process, which of course would have to be suitably 
constructed. 
Although, as was stated before, the majority of mathematicians hold 
to the belief that mathematical propositions are not meaningless, they 
hold widely different opinions about their meaning. It is impossible to go 
into details here about these varied opinions,and we shall content ourselves 
with discussing a fundamental dividing line among them, having to do 
with the concept of infinity. If we adopt the concept of actual (completed) 
infinity, we may speak of the totality of all natural numbers just as readily, 
for example, as of the totality of natural numbers between 10 and 100. 
But those who hold to the concept of potential infinity emphasize that 
the infinite totality of all natural numbers as a set is not immediately 
available to us, and that we can only approach it step by step, by means of 
successive constructions, such as are indicated by 
I, II, III, .... 
This is the so-called constructive point of view; compare the concept of an 
algorithm described in §5. 
If we examine these concepts further, certain other differences come 
to light, one of which we will now illustrate by an example. For any given 
natural number, we can determine in a finite number of steps whether 
the number is perfect or not. 2 The proposition: 
(1.1) 
either there exists an odd perfect number between 10 and 100, or 
else there exists no odd perfect number between 10 and 100 
is acceptable from either the actual or the potential point of view. But 
matters are quite different for the proposition: 
(1.2) 
either there exists an odd perfect number, or else there exists no 
odd perfect number. 
From the actual point of view, there is no essential difference between 
these two propositions. In each case the argument runs as follows: either 
there exists an odd perfect number between 10 and 100 (or in the set of 
all natural numbers), in which case (1.1) and (1.2) are correct, or else 
there is no such number, and in this case also (1.1) and (1.2) are correct. 
But in case (1.2) an adherent of the constructivist school will argue as 
follows: the assertion that an odd perfect number exists is meaningful 
only if such a number has been found (constructed). On the other hand, 
the assertion that no odd perfect number exists is meaningful only after 
2 A natural number is called perfect if it is equal to half the sum of its divisors; 
for example, 6 is perfect. It is not known whether an odd perfect number exists. 

8 
PART A FOUNDATIONS OF MATHEMATICS 
we have shown that the assumption of the existence of such a number 
leads to a contradiction (i.e., that we can construct a contradiction on 
the basis of this assumption). But in the present state of our knowledge 
we cannot make either of these assertions and thus we have no reason to 
conclude that case (1.2) is true. 
Propositions like (1.1) and (1.2) are special cases of the so-called 
law of the excluded middle (tertium non datur). The actual point of view, 
in contrast to the potential, accepts this law in every case. 
The constructive mathematician is an inventor; by means of his con-
structions he creates new entities. On the other hand, the classical mathe-
matician, who regards the infinite as given, is a discoverer. The only 
entities he can find are those that already exist. 
It is customary nowadays to give the name classical to the actual point 
of view, although the potential attitude can also be traced back to 
antiquity. 
1.5. 
Remarks on the Following Sections 
These and other differences in the various conceptions of mathematics 
have given rise to a great diversity of opinion about the foundations and 
nature of mathematics, particularly with regard to where the boundary 
should be drawn between mathematics and logic. Within the space at 
our disposal it is impossible to discuss all these questions from every 
point of view. In the following sections we give preference to the classical 
position, with an occasional reference to the constructivist point of view, 
when the difference between them is important. Our reasons for giving 
preference to the classical position are as follows: (1) the greater part of 
established present-day mathematics is based more or less on the classical 
conception, whereas many parts of constructive mathematics are still 
in the process of being built up; (2) the constructive mathematics appears 
to be far more complicated than the classical. For example, it is not 
possible to speak simply of the real numbers. These numbers fall into 
various "levels," and for each level there exist still more complicated 
numbers. 
In the present chapter we have no intention of giving an encyclopedic 
survey. We have given priority to such questions as are naturally related 
to college instruction. In some cases the treatment is more detailed 
because the authors believe that the subject is suitable for discussion by 
undergraduates in a mathematics club. 
The material has been arranged as follows: mathematical proof depends 
on the fact that propositions have a certain structure (§2); from the 
classical point of view the basic concept of logic and mathematics is that 
of a consequence (§3), which plays a fundamental role in the axiomatic 
method (§4); in practice, the mathematician obtains consequences by 

2 Logical Analysis of Propositions 
9 
carrying out proofs (§6), a process which has been analyzed in a profound 
way in the theory of calculi (§5). The next three sections deal with the 
theory of sets (§7), Boolean algebra (§8), and the theory of relations (§9). 
A system of axioms of great importance for the mathematician is the 
Peano system for the natural numbers (§10). Finally, we give an analysis 
of some of the best-known antinomies (§11). 
Bib liography 
The bibliography at the end of the present chapter contains several textbooks 
of mathematical logic dealing with the various problems discussed in the 
following sections. Let us mention here, once and for all: Beth [1], Curry [1], 
Kneebone [1], Novikov [1], Rosser [1], Wang, [1], and the article on "Logic" 
by Church [2] in the Encyclopaedia Britannica. On intuitionism see Heyting 
[1] and Lorenzen [1], and on the history of logic see Kneale [1]. 
2. Logical Analysis of Propositions 
2.1. 
The Language of Mathematics 
The results of mathematics, like those of any other science, must be 
comrilUnicable. The communication may take place in either spoken or 
written form, but for mathematics the difference between them is of no 
great importance. In studying the foundations of mathematics it is 
customary to use written symbols. 
Communication is ordinarily carried on in one of the natural languages, 
such as English. But a natural language decays and renews itself like an 
organism, so that we are engaged in a rather risky business if we wish to 
entrust "eternal, unchanging truths" of mathematics to such a changing 
language. Everyone knows how easily misunderstandings arise in the 
ordinary spoken language. So to attain clarity in his science, the mathe-
matician must try to eliminate the ambiguities of such a language, although 
the attempt involves a laborious process of evolution. and cannot be 
completely successful. One method of producing greater clarity lies in 
formalization. In the ordinary mathematical literature this process is only 
partly carried out, as can be seen by a glance at any mathematical text, 
but in studies of the foundations of mathematics, ordinary speech has 
been completely replaced by formalized languages. To some extent these 
artificial languages have been abstracted from ordinary language by a 
process of analyzing the statements of the latter and retaining only what 
is logically important. Let us now undertake this process of logical analysis. 
The reader will note a certain resemblance to grammatical analysis, but 
many of the distinctions made in grammar have no significance in logic. 
As a result, technical terms common to logic and grammar do not 

10 
PART A FOUNDATIONS OF MATHEMATICS 
necessarily have the same meaning. Finally, let us emphasize once and for 
all that the process of logical analysis is not uniquely determined and could 
just as well be undertaken in a manner different from the one adopted here. 
2.2. 
Propositions 
Many combinations of letters are called propositions. For example: 
(2.1) 
Every even number is the sum of two odd numbers. 
(2.2) 
Every odd number is the sum of two even numbers. 
(2.3) 
Every positive even number, with the exception of the number two, 
is the sum of two prime numbers. 
In classical logic, which goes back to Aristotle, propositions are divided 
into true propositions and false propositions. The principle of two-valuedness 
states that every proposition is either true or false, although it is not 
required that we should always be able to decide which is the -case. For 
example, it remains unknown at the present time whether the Goldbach 
conjecture (2.3) is true or false, but in classical logic it is assumed that 
statement (2.3) is in fact either true or false. 
Thus the classical logic recognizes two truth values, true and false (often 
represented by T and F). Today attention is also paid to many-valued 
logics, and attempts are being made to apply them in quantum mechanics. 
The classical point of view has often been criticized (cf. §1.4). But even 
if we adopt a different attitude, we still accept certain propositions, for 
example (2.1) and reject others, for example (2.2); and in general there 
will be propositions which, at least up to now, have been neither accepted 
nor rejected, for example proposition (2.3). 
It must be emphasized that in the terminology adopted here, which is 
customary in modern researches in the foundations of mathematics, 
a proposition is simply a set of written symbols, so that it becomes essential 
to distinguish between the proposition itself and the state of affairs which 
it describes. Since this distinction will be of importance in the following 
sections, let us point out that one of the most profound thinkers in modern 
logic, G. Frege (1848-1925), distinguishes between the sense (Sinn) and 
the denotation (Bedeutung) of a proposition. By the denotation of a 
proposition, Frege means its truth value. Thus the propositions 
"1 + 1 = 2" and "2 + 2 = 4" have the same denotation, namely 
true.3 But these propositions have different senses. Similarly, the desig-
3 One must distinguish between a proposition and a name for the proposition, and 
when we speak of an object, we must have a name for it. Thus we shall make frequent 
use of the following convention: we obtain a name for a proposition (or more generally 
for a set of written symbols) if we enclose the proposition (the set of written symbols) 
in quotation marks. In the present section we shall strictly observe this convention, but 
later it will be convenient, as frequently in mathematics, to let a set of written symbols 
stand as a name for itself (autonomous notation). 

2 Logical Analysis of Propositions 
11 
nations (not propositions) "2 . 2" and "22" have the same denotation, 
namely the number four, but they too have different senses. 
2.3. 
Propositional Forms 
In mathematics, we frequently encounter, in addition to the propo-
sitions, sets of symbols of the following sort: 
(2.4) 
x + 3 = y, 
(2.6) f(x, y) = z, 
(2.5) f(2,3) = 5, 
(2.7) 
P2. 
We are not dealing here with propositions, since it is obviously meaningless 
to ask, for example, whether (2.4) is true or false. The characteristic feature 
of these new formations is that they contain variables, namely "x," "y," 
''f,'' "P." Variables are letters that do not refer to any definite entity but 
rather to a definite range of entities, whose names can be substituted for 
these variables; the range of the variables must be determined in each case. 
Thus in (2.4) and (2.6) the "x," "y," and "z" are number variables; 
for the "x," "y," "z" we may substitute the names of numbers, e.g., "3" or 
"Tr." In examples (2.5) and (2.6) the ''/'' is a function variable, for which 
we may, for example, substitute "+" and in this way4 convert (2.5) into 
the proposition "2 + 3 = 5." In particular, the range to which the 
variable refers may consist of sets of linguistic expressions, when we 
may allow the enti.ties themselves (and not their names) to be substituted 
for the variables. A case of this sort occurs in (2.7), where "P" is a predicate 
variable, referring to predicates. An example of a predicate is the set of 
written symbols "is a prime number." When this predicate is substituted 
for "P," the expression (2.7) becomes the proposition "2 is a prime 
number." Written symbols like "2" are called subjects (cf. 2.5), so that 
"x," "y," "z" are subject variables. 
In order to indicate that a variable "x" has the real numbers for its 
range, mathematicians often say that x is an indeterminate real number, 
but phrases of this sort are misleading and should be avoided. 
After replacement of the variables by objects in their specified ranges, 
expressions (2.4) through (2.6) become propositions. Consequently, 
such sets of symbols are called propositional forms (formulas).5 If we 
agree, as is often done, to extend the meaning of a propositional form to 
include the propositions themselves, then the latter are propositional 
forms without free variables. 
When a proposition is analyzed logically step by step, we usually 
encounter intermediate forms that are no longer propositions but are 
still propositional forms. For example, consider the Fermat conjecture: 
4 Strictly speaking, of course, this proposition should read "+ (2,3) = 5," but we 
will permit ourselves to make such changes tacitly. 
1\ See the footnote in §4.1. 

12 
PART A FOUNDATIONS OF MATHEMATICS 
(2.8) 
There do not exist natural numbers x, y, z, n,jor which x . y . Z -=I=- 0 
and 2 < nand xn + yn = zn, 
where it is natural to regard the propositional form 
(2.9) 
x . y . z -=I=- 0 and 2 < nand xn + yn = zn, 
as a logically important part of (2.8). 
Let us therefore examine propositions and propositional forms simul-
taneously. In the analysis of propositional forms we find, in addition to 
the variables, two types of elements. First there are such frequently 
repeated words (or groups of words) as "not," "and," "or," "for all," 
which in a certain sense are the logical framework of a proposition. 
The most important of these are the propositional constants (§2.4) and 
the quantifiers (§2.6). Secondly there are the words (or groups of words) 
that are characteristic of the mathematical theory under examination at 
the moment and do not occur, in general, in other theories. Examples are 
"2," "11'," "is a prime number," "lies on," "+." The most important 
types here are subjects, predicates, and function signs (§2.5). 
In the following sections we shall examine these elements more closely. 
They should be compared with the operator of set formation in §7.7, 
the notation for functions in §8.4, and the description operator in §2.7. 
2.4. 
The Propositional Constants 
These serve the purpose of combining propositional forms in order to 
construct new propositional forms. A simple example is "and." 
The two propositional forms 
(2.10) 2 divides x 
(2.11) 3 divides x 
are combined by "and" into the one propositional form 
(2.12) 
2 divides x and 3 divides x. 
The propositional form (2.12) is called the conjunction of (2.10) and (2.11). 
The conjunction of two propositions is again a proposition, which is true 
(accepted) if and only if both the components united by the "and" are 
true (accepted). This fact is expressed by the 
Truth table (logical matrix) 
jor conjunction 
T F 
---
T 
T F 
FIF F 
For example, the conjunction of a false proposition (the "F" in the left 
column of the above table) with a true proposition (the "T" of the top 

2 Logical Analysis of Propositions 
13 
row) is a false proposition (the "F" at the intersection of the given row 
and column). 
Another propositional constant is "not," as in 
(2.13) 
8 is not a perfect square. 
In a logical systematization of the language it is customary to put the 
"not" at the beginning and to write: 
(2.13') 
Not 8 is a perfect square. 
The proposition (2.13') is called the negation of "8 is a perfect square." 
In the nonclassical schools of logic, negation is either completely banned 
or, if admitted, it is variously interpreted by the various schools. One 
possibility consists of accepting the negation of a proposition a if from a 
we can derive a contradiction (i.e., a proposition that is always rejected). 
If negation is admitted at all, it is always subject to the condition that no 
proposition is accepted together with its negative. In the classical two-
valued logic it follows that "not" reverses the truth value. Thus we have: 
Truth table (logical matrix) 
for negation 
T I F 
F 
T 
Another important propositional constant is "or." The word "or," 
which in everyday English has several different meanings, is almost always 
used in mathematics in the nonexclusive sense of the Latin "vel," for 
example: 
(2.14) 
Every natural number greater than two is a prime number or has 
a prime factor. 
The combination of two propositions by the nonexclusive "or" is called 
an alternative (or also a disjunction, although it would be more correct to 
reserve the word "disjunction" for the combination of propositions 
expressed by "either-or"). An alternative is true (accepted) if and only 
if at least one of its components is true (accepted): 
Truth table (logical matrix) 
for the alternative (disjunction) 
T F 
T T 
T 
FIT F 
The "either-or" is used like the Latin "aut," as indicated in the following 
table: 
Truth table (logical matrix) r 
for the strict disjunction 
IT F 
Tip-:;. 
FIT F 
j 

14 
PART A FOUNDATIONS OF MATHEMATICS 
Among the other constants of the propositional calculus we shall 
mention here only implication (and its consequence equivalence), which in 
the English language is represented by the words "if-then." For the 
"if-then" of ordinary spoken language, the logicians have distinguished, 
in the course of the centuries, several essentially different meanings. 
We shall restrict ourselves here to describing the one which appears most 
often in classical logic and mathematics and can be traced back to the 
Stoics (Philon, ca. 300 B.C.). If a reader feels that he cannot reconcile the 
"if-then" of the following truth table with his everyday spoken language, 
he is referred to §3. 
Let us now' take up the task of constructing a truth table for "if-then." 
[The four entries will be determined as soon as we have fixed on the truth 
value of the following four propositions: 
(2.15) 
If I + I = 2, 
then 
I + I = 2. 
(2.16) 
If I + I = 2, 
then 
I + I = 3. 
(2.17) 
If 
-2 = 2, 
then 
(_2)2 = 22. 
(2.18) 
If 1 + 1 = 3, 
then 
1 + 1 = 3.] 
We regard (2.15) and (2.18) as true, and (2.16) as false. As for (2.17), 
we can argue as follows: The proposition 
(2.17') 
For arbitrary real numbers x, y it is true that, if x = y, then 
x2 = y2 
is true. A statement that holds for arbitrary real numbers x, y, holds in 
particular for x = -2 and y = 2. Thus we recognize (2.17) as a true 
proposition. Consequently we have the 
Truth table (logical matrix) 
for implication 
T F 
T T F 
F 
T 
T 
We establish the convention that in discussing the classical logic we shall 
use "if-then" in the above sense. It should be noted that there is no 
inherent connection between the two parts of an implication defined in 
this way. For example, the following proposition is true: "if7 + 4 = 11, 
then a friangle with three equal angles has three equal sides." 
An equivalence ("if and only if") may be defined as a conjunction of 
reciprocal implications (see below). Thus we have the 
Truth table (logical matrix) 
for equivalence 
I
T F 
T T F 
FIF T 

2 Logical Analysis of Propositions 
15 
The propositional constants "not," "and," "or," "if-then," "if and 
only if" occur so frequently in mathematics that it is worthwhile to 
introduce symbols for them. Usage in present-day logic is not yet uniform. 
In the following table the symbol given first is the one used in this article. 
Connective 
Negation 
Conjunction 
Alternative 
Implication 
Equivalence 
List of Propositional Symbols 
Everyday English 
not 
and 
or 
if-then 
if and only if 
Symbol 
-, (suggests "-"), over-lining 
1\ (dual to "v"), &, .. , immediate 
juxtaposition 
v (suggests "vel") 
---+, :J 
~ (combination of 
"---+" 
and 
"+---"), == 
As already mentioned, we may consider an equivalence as the con-
junction of two reciprocal implications. But then we may also say that the 
equivalence is defined by this conjunction. If we introduce the propositional 
variables "p," "q," it is easy to calculate from the tables that we may put 
"p ~ q" in place of "(p ---+ q) 1\ (q ---+ p)," as may be seen by calculating 
the four cases p, q = T, T; T, F; F, T; F, F. To state a definition we use 
the sign "<=>," thus, in ~he present case: 
(2.19) 
Similarly, we can justify the following definitions 
(2.20) 
(2.21) 
(2.22) 
p ---+ q <=> -, p v q, 
p v q <=> -, (-, P 1\ -, q), 
P 1\ q <=> -, (-, p v -, q). 
2.5. Subjects, Predicates, and Function Signs 
If we examine the following propositions and propositional forms: 
(2.23) 4 is a prime number, 
(2.25) 3 < x, 
(2.24) 
x lies between 2 and 9, 
(2.26) 
2 + 4 = 8, 
we see that in addition to the variable "x" they contain the following 
elements: 
the subjects "2," "3," "4," "8," "9," 
the predicates "is a prime number," "lies between-and," "<," "=," 
the function sign "+." 

16 
PART A FOUNDATIONS OF MATHEMATICS 
In the proposition "6 exceeds 3," it is true that from the grammatical 
point of view "6" is the subject and "3" is the object, but in logic both 
the "6" and the "3" are subjects. 
The above predicates are successively I, 3,2, 2-place predicates, and 
the function sign" +-" is a two-place predicate. 
Higher-place predicates also occur in mathematics: e.g., the four-place 
predicate in the propositional form "the point-pair A, B separates the 
point-pair C, D." A k-place predicate becomes a proposition through the 
adjunction of k subjects, and in agreement with this manner of speaking 
we shall sometimes say that the propositions are O-place predicates. 
In principle, function signs can be dispensed with entirely, being 
replaced by predicates. For example, the "+-" is superfluous if we 
introduce the three-place predicate "is the sum of ... and." For then in (2.26) 
we may write: "8 is the sum of 2 and 4." Since function signs can be 
eliminated in this way, it is a common practice in purely logical investi-
gations to confine oneself to predicates, and in §3 we will take advantage 
of this simplification. But mathematicians would be unwilling to give up 
the functional notation, which is a very suggestive one. 
The importance of subjects and predicates will be discussed below 
in §3.3. 
2.6. 
Operators in the Calculus of Predicates; Bound Variables 
The proposition 
(2.27) 
All positive numbers are squares 
contains the operator (or quantifier) "all" of predicate logic, which we 
may analyze in the following way (although there are other possibilities): 
we are dealing here with the one-place predicates "is a positive number" 
and "is a square," which we may make more prominent by reformulating 
the proposition: 
(2.27') For all entities: If an entity is a positive number, then this entity 
is a square. 
Here the repeated word "entity" obviously has the task of indicating 
the places to which the operator "all" shall refer. The same task may be 
performed in a clear and simple way if we insert one and the same sign 
in each of these places; for example, the letter"z."Thus we "get the standard 
form: 
(2.27") For all z: If z is a positive number, then z is a square. 
The letter "z" serves only to mark the place; instead we could use any 
other letter, e.g., "y." It must be noted that "z" is not a variable of the 

2 Logical Analysis of Propositions 
17 
kind considered in §2.5, since (2.27") is a genuine propositibn, as distinct 
from a propositional form. If "z" is replaced in (2.27") by the name of a 
number, e.g., "2," we do not obtain a proposition, but rather the linguistic 
gibberish: "for all 2: If 2 is a .... " 
It is customary to call the letter "z," as used in (2.27"), a bound variable, 
whereas the variables considered earlier are free variables. In the propo-
sitional form 
(2.28) If z is a positive number, then z is a square 
the letter "z" is a free variable, and (2.27") is obtained from (2.28) by 
binding the "z" with the quantifier "all." In this way, a free variable 
becomes bound. 
Bound variables refer, in the same way as free variables, to a given 
range; in the present case, for example, to the set of real numbers. 
The quantifier "all" is called the universal quantifier, and (2.27") is the 
universal quantification of (2.28). A synonym for "all" is, e.g., "every," 
and a phrase like "for no z" means "for all z not." 
A second operator in the calculus of predicates is the existential quantifier 
"there exists" or "there exist" or "for some," as in the following example. 
(2.29) , There exist prime numbers. 
(2.29") For some x: x is a 
prime number. 
(2.29') 
There exists a y, such that 
y is a prime number. 
(2.30) 
x is a prime number. 
The propositions (2.29') and (2.29") are variants of (2.29). The existential 
quantifier can also be used to bind variables. In this connection (2.29) is 
called an existential quantification of (2.30). 
If the range of the variable is finite (for example, the natural numbers 
from 1 to 9), then the universal and existential quantifiers are, respectively, 
equivalent to a multiple conjunction and a multiple alternative. Thus if 
"P" stands for "is a prime number," then "Every number is a prime 
number" is equivalent to "P 1 1\ P2 1\ ... 1\ P9" and "There exists a prime 
number" is equivalent to "PI v P2 v ... v P9." Consequently we speak 
of a generalized conjunction or alternative and introduce the symbols 
"1\" for the universal quantifier and "V" for the existential. Then the 
familiar Cauchy definition of the continuity of a function/in an interval I 
takes the following easily understood form: 6 
(2.31) 
1\ 1\ (x E I -- V 1\ (y E I 1\ I x -
y I < 8 --Ij(x) - /(y)1 < €». 
x 
£ 
8 
Y 
8 Here the variables x, y refer to real numbers, and the variables E, cS to positive real 
numbers. Without the latter convention, the statement of (2.31) would be somewhat 
more complicated. 

18 
PART A FOUNDATIONS OF MATHEMATICS 
For every x and every € there exists, if x is an element of the interval I, 
a 8 such that for every element y of the interval I whose distance from x 
is less than 8 the difference between the functional valuesf(x) andf(y) is 
less than €. 
It is essential to note that if, as in the present case, several quantifiers 
appear in the same proposition (or propositional form), then the bound 
variables used (here x, y, €, 8) must be distinct from one another. 
In classical logic (but only there!) either of the above quantifiers can be 
defined in terms of the other. For if H is an arbitrary propositional form, 
we can write: 
(2.32) 
(2.33) 
A H <:> ---, V ---, H , 
x 
x 
V H <:> ---, A ---, H. 
x 
x 
These definitions indicate a certain "duality" between A and V, which 
corresponds to a duality between 1\ and v (cf. also §9.2). 
The following notations are to be found in the literature: 
Universal quantifier: AH, (x)H, 'v'xH, TIH, 
x 
a: 
Existential quantifier: VH, (3x)H, (Ex)H, 3xH, IH. 
x 
a: 
2.7. 
Identity and Description 
The notation x = y (x = y) means that x and yare the same entity. 
With this sign for identity we can formulate the statement that the property 
denoted by a given predicate is possessed by exactly one entity. If 
we let "~" stand for the predicate "is an even prime number," then the 
fact that there exists exactly one even prime number can be represented 
by the proposition: 
V ~x 1\ A A (~x 1\ ~ Y ---. x = y). 
x 
x 
" 
If the property indicated by a predicate holds for exactly one entity, 
we may speak of the entity which has this property. Here we need the 
description operator, represented in ordinary English by some such words 
as "that-which" and usually denoted in logic by the symbol (LX). Thus 
(LX) ~x is a name for the number 2, in which x occurs as a bound variable 
(cf. §2.6). If we are given an arbitrary predicate .0, e.g., "is divisible by 2," 
then .Q(,x) 'l1x means that the property indicated by .Q is possessed by 
that unique entity for which ~x holds. The expression .Q(LX) ~x is often 
used by Russell as an abbreviation for the proposition: There exists 
exactly one entity which possesses the property indicated by ~, and all 

2 Logical Analysis of Propositions 
19 
entities which have this property also have the property indicated by .0; 
or, expressed in symbols: 
v ~x 1\ 1\ 1\ (~x 1\ ~ Y ---. x = y) 1\ 1\ (~x ---. .ox). 
x 
x 
Y 
x 
This proposition is still meaningful (though false), if the property indicated 
by ~ does not hold for exactly one entity. 
Exercises for §2 
1. Set up the truth table for "neither-nor." Represent this connective 
in terms of 
(a) --, and 1\, 
(b) --, and v. 
2. Calculate the truth tables for the propositional forms: 
(a) (p 1\ q) ---. --, p 
(b) (p ---. q) ---. ( --, p ---. --, q) 
(c) (p v --, q) 1\ --, (q ---. p) 
(d) [(p ---. q) 1\ (q ---. r)] ---. (p ---. r) 
3. Express (2.14) in formal language, with the following definitions: 
Nx -¢? x is a natural number, 
Px -¢? x is a prime number, 
Gxy -¢? x is greater than y, 
Rxy -¢? x divides y. 
4. Translate into English: 
V (Nx 1\ 1\ (Gxy 1\ Ny ---. (Ryx v Py))). 
x 
y 
5. What does 
Vx (31 < x 1\ --, R2x 1\ --, R3x 1\ x < 37) 
mean? 
6. Formulate the axioms of a system of axioms for geometry in the 
symbolism of the predicate logic. 
Bibliography 
On the technical use of symbols see Carnap [2]. Information on the use of 
symbols can also be found in many textbooks of mathematical logic (see the 
bibliographies for §I and §6). Especially interesting to mathematicians are 
Tarski [I] and Frege [2]. 

20 
PART A FOUNDATIONS OF MATHEMATICS 
3. The Concept of a Consequence 
3.1. 
Semantics 
In this section we discuss a concept which must be considered as basic in 
the classical treatment of mathematics and particularly ofaxiomatization. 
We wish to investigate the connection that exists between, for example, 
the Euclidean axioms and the theorem of Pythagoras, a connection 
which is usually expressed in the form: the theorem of Pythagoras is a 
consequence of the Euclidean axioms. In the present section we think of 
this connection as being static: if the Euclidean axioms are given, then 
the Pythagorean theorem is in some sense given at the same time. But we 
may also think of the situation as a dynamic one: given the Euclidean 
axioms, how can we proceed, step by step, to derive the theorem from 
them. We will return to this question in §6. 
The connection between the theorem and the axioms established by 
saying that the theorem is a consequence of the axioms, can be described 
as follows: the language in which we formulate our mathematical theorems 
stands in a certain relation to the actual "world," which is to some 
extent' described by the language. In other words, the actual world 
provides an interpretation of the language. The science that deals with 
such questions is today called semantics. Some of the concepts of semantics 
can be traced as far back as Aristotle and were important in the work 
of Bolzano, which remained to a great extent unrecognized in his time. 
The modern science of semantics is due to A. Tarski. 
In contrast to semantics, investigations of a language that have nothing 
to do with any interpretation of it are called syntax. 
3.2. 
Definitions7 
In the construction of a mathematical theory we not only formulate 
and prove theorems but also make definitions. A definition is an abbre-
viation. For example, "x is a prime number" stands for "x is a natural 
number which is different from 1 and has no factor other than 1 and 
itself." Although the importance of definitions is largely a practical one, 
it must not be underestimated. If it were not for such abbreviations, the 
majority of mathematical theorems would be so cumbersome as to be 
completely unintelligible. 
[n our study of the concept of a consequence, we must take the defini-
tions into account. It would be simplest, of course, to eliminate them 
entirely by replacing them with the expressions for which they stand. 
In the Pythagorean theorem, for example, the expression "is a right-
angled triangle" would be replaced by some expression involving only 
the fundamental concepts of geometry. If, for convenience, we allow the 
7 For the so-called recursive definitions see §7.4. 

3 The Concept of Q Consequence 
21 
definitions to stand as they are, it would be more precise to say: the 
theorem of Pythagoras is a consequence of the Euclidean axioms and 
the definitions that are used in the formulation of the theorem. 
3.3. 
The Ontological Assumptions of Semantics 
Let us examine more carefully the ideas underlying this attempt to 
define a consequence more precisely, since in the semantic construction 
of mathematics it is assumed that such ideas are "understood." If we 
ask for the meaning of the linguistic expressions we have called subjects 
and predicates, we see that a subject is a name for an individual, and a 
predicate is a name for an attribute (a property). Subjects in ordinary 
speech, such as "Lincoln" or "New York," name individuals that have 
a "real existence." Many mathematicians hold the view that individuals 
such as those named by the subjects "2" and "17" have an "ideal existence," 
being of different kinds according to the branch of mathematics under 
consideration. In real analysis, for example, they are the real numbers; 
and in the theory of functions of a complex variable they are the complex 
numbers. The individuals investigated in any given context are regarded 
as forming a domain of individuals: for example, the domain of natural 
numbers. The domain of individuals may have finitely or infinitely many 
elements but is assumed to have at least one element. 
It is also assumed that together with any given domain of individuals 
the totality of all relevant properties is also given. In this connection a 
property is relevant if for each individual in the domain the answer to 
the question whether or not the individual possesses the property is in 
the nature of things well defined, even though we may not be able to decide 
whether it is "yes" or "no." This is the ontological basis of the Aristotelian 
principle of two-valuedness (cf. §2.2). In addition to the one-place 
properties, such as the one described by the predicate "is a prime number," 
we also consider many-place properties, e.g., the two-place property 
(or relation) denoted by "<." For an n-place property (or relation), it is 
assumed that for every ordered n-tuple of individuals from the domain 
under consideration it is determined in the nature of things whether the 
individuals in the given order stand in the given relation or not. 
3.4. 
Mathematical Axioms as Propositional Forms 
The concept of a mathematical consequence has been developed chiefly 
in connection with geometry, above all in researches on the independence 
of the parallel postulate. We shall therefore take geometry as the starting 
point for our discussion. The modern attitude toward the axioms of 
geometry was described in a drastic way by Hilbert when he said: "We 
must always be able to replace the words 'point,' 'line,' and 'plane' by 
'table,' 'chair,' and 'beer-mug.' " 

22 
PART A FOUNDATIONS OF MATHEMATICS 
Of course, Hilbert does not mean that the theorems of geometry will 
remain true if we make the suggested change, but only thatfor mathematics, 
which has the problem of determining consequences of the axioms of 
geometry, it is of no importance whether we speak of points, etc., or of 
tables, etc. In other words: if a geometrical proposition is a consequence 
of the Euclidean axioms, then the proposition that arises from it through 
Hilbert's suggested change in terminology is a consequence of the cor-
responding axioms arising from the change. In the epigrammatic phrase 
of Bertrand Russell, "a mathematician does not need to know what he is 
talking about, or whether what he says is true." 
Since in geometry (as in any purely mathematical science; cf. §1.2) 
we have no interest in the meaning of the predicate "is a point," we may 
replace it (and correspondingly the other geometric predicates) by a 
predicate variable, thereby concentrating our attention on what is 
mathematically essential and doing away with everything else. If we write 
"P" for "is a point," "G" for "is a line," and "L" for "lies on," the first 
Euclidean axiom (in Hilbert's formulation) 
(3.1) 
Given any two points A, B, there exists a line a which corresponds 
to each of the two points A, B. 
Given two points A, B, there is not more than one line which corre-
sponds to each of the given points A, B, 
becomes, in the logical symbols introduced in our earlier sections: 
(3.2) 
1\ 1\ «Px " P y " x -=I=- y) -- V (Gg " Lxg " Lyg) 
x 
y 
g 
1\ 1\ 1\ 1\ (Px " P y " x -=I=- y " Gg " Gh " Lxg 
x 
y 
g 
h 
" Lxh " Lyg " Lyh -- g = h). 
Thus we see that for the pure mathematician it is more precise to regard 
the geometric axioms as propositional forms [like (3.2)] than as proposi-
tions [like (3.1)]. The so-called fundamental concepts of a given mathe-
matical theory, i.e., the subjects and predicates appearing in its axioms, 
are in this sense simply linguistic paraphrases for subject variables and 
predicate variables. When the axioms are regarded as propositional 
forms, they cannot be said to be either true or false. They become true 
or false only after the variables occurring in them (i.e., the fundamental 
concepts of the given mathematical theory) have been given an inter-
pretation; that is, only when to each (free) subject variable we have 
:assigned an individual of the underlying domain of individuals and to 
each predicate variable a property (with the same number of places) of 
the elements of the domain. When propositional variables occur, they are 

3 The Concept of Q Consequence 
23 
to be interpreted by means of propositions. Then it becomes meaningful 
to say that a given propositional form is true or false in this interpretation. 
The fact that a propositional form H is true in the interpretation Xl is 
expressed by saying: Xl satisfies H, Xl is a model of H, Xl verifies H, or H 
is true in Xl. As an example let us choose the domain of natural numbers 
and consider the propositional forms 
(3.3) 
Px 
(3.5) 
Px 1\ Qx 
(3.7) 
Px 1\ ----, Px 
(3.9) 
V (Px 1\ Qx y) 
x 
(3.4) 
----, Px 
(3.6) 
Px v Qx 
(3.8) 
(3.10) 
Px v ----, Px 
1\ Px ~ 1\ P y. 
x 
Y 
The form (3.3) is true in the interpretation which to the variable x assigns 
the number 4, and to the variable P the property of being even; in other 
words, 4 has this property. The form (3.3) is not true if P is interpreted 
as before while x is interpreted as 5. The form (3.4) is the opposite of (3.3). 
The form (3.6) is true, and (3.5) is not true, if x is interpreted as 4, while 
P is interpreted as the property of being prime, and Q as that of being a 
perfect square. The form (3.8) is true for any interpretation, and (3.7) 
for none. Consequently, (3.8) is said to be t'alid or a tautology, and (3.7) 
is contradictory or a contradiction. In (3.9) only the P, Q, y require 
interpretation and in (3.10) only the P, since the other variables are bound 
(cf. §2.6). The form (3.9) is true if y is interpreted as 10, P as the property 
of being prime, and Q as the relation of "smaller than," since there 
exists at least one number which is both prime and smaller than 10. The 
form (3.10) is a tautology, expressing the fact that a bound variable may 
be renamed at will. See also the examples in §3.8. 
3.5. 
The Artificial Language of the Predicate Logic 
The propositional forms (3.2), (3.3), ... (3.10) contain, apart from 
brackets, only logical symbols and subject and predicate variables. 
These propositional forms are called expressions in the predicate logic. 
Here it is important that only the subject variables, and not the predicate 
varia bles, can be bound by quantifiers.8 The language of this predica te logic 
is an artificial language capable of expressing a great part of mathematics. 
As soon as we have chosen a domain of individuals, we can interpret the 
subject variables and the predicate variables and can then give an exact 
definition of what it means to say that a proposition is true in this inter-
pretation. It is most convenient to construct a definition inductively by 
8 If we also allow the predicate variables to be bound, we are in the so-called "logic 
of the second order," or "extended predicate logic," cf. §1O.2. 

24 
PART A FOUNDATIONS OF MATHEMATICS 
proceeding from simpler to more complicated expressions. Through lack 
of space we must content ourselves with this remark and with the above 
examples. 
3.6. 
The Concept of a Consequence 
Now let~Ibe the set of axioms and H a theorem in a mathematical theory, 
e.g., in Euclidean geometry. We then say that H is a consequence of ~l. 
If we now take H and the elements of ~( to be propositional forms and 
interpret the fundamental concepts in such a way that all the axioms are 
true, it is reasonable to expect that in the given interpretation H will 
also be true. Thus we have a necessary condition which the concept 
of a consequence must satisfy. In order to give the widest possible meaning 
to the concept, we agree to regard this necessary condition as being also 
sufficient. In this way we arrive at the following 
Definition of a Conseq uence: The propositional form H follows from the 
set ~( of propositional forms (H is a consequence of ~I) if every model 
common to all the propositional forms of ~( is also a model of H. 
Examples: Py, and also Qy follow from Py 1\ Qy; and V x Px follows 
from Ax Px (here it must be noted that by §3.3 a domain of individuals 
contains at least one element). Also, Ay Py follows from Ax Px and 
conversely. Every propositional form follows from a contradictory prop-
ositional form. A tautology follows from any propositional form. 
3.7. 
Consequence and Tautology 
If the number of axioms is finite, we can reduce the concept of a con-
sequence to that of a tautology. For this purpose we first form the 
conjunction e of all the axioms in ~I. Then we have the important theorem: 
H folloH's from ~( ~t and only if e -- H is a tautology. 
This theorem expresses the relation between "follows from" and "if-
then." The theorem is proved as follows: 
(a) We first assume that H follows from 21. Then we must show that 
e -- H is a tautology, i.e., that e -- H is true for every interpretation over 
an arbitrary domain of individuals. To this end we make an arbitrary 
interpretation Xl of the given domain. In case e is false in Xl, then e -- H 
is certainly true in 3) (cf. the logical matrix in §2.4); and in case e is true 
in 3), then H must also be true in 3), in view of the hypothesis that H is 
a consequence of Xl; thus in this case also e -- H is true in 3). 
(b) We now assume that e -- H is a tautology and must show that 
H follows from ~L But if this were not the case, then there would be an 
interpretation Xl for which all the propositional forms in 21 (and there-

3 The Concept of a Consequence 
25 
fore e) would be true but H would be false. Then Xl falsifies e -- H, 
in contradiction to the hypothesis that e -- H is a tautology. 
3.8. 
Examples of Tautologies 
(3.tt) 
(3.12) 
(3.13) 
(3.14) 
(3.15) 
(3.16) 
(3.t7) 
----,----,p~p, 
----, (p 1\ p) ~ 
(----, p v ----, q), 
----, (p v q) ~ 
(----, P 1\ ----, q), 
----, (p -- q) ~ (p 1\ ----, q), 
----, (p ~ q) ~ (p ~ 
----, q), 
----, /\ H ~ V ----, H, 
x 
x 
----, V H ~ /\ ----, H. 
x 
x 
These tautologies form the basis for the technique of negation. We 
obtain a simple application of the theorem in 3.7 if we weaken (3.14) to 
(3.14') 
----, (p -- q) -- (p 1\ ----, q). 
Then p 1\ ----, q follows from ----, (p -- q). 
Exercises for §3 
I. Which of the following propositional forms are tautologies and 
which are contradictions? 
(a) V Px v /\ --, Px, 
x 
x 
(b) /\ Px v V Px, 
x 
x 
(c) --, /\ Px 1\ --, V --, Px, 
x 
x 
(d) V --, Px -- V (Py -- Qy), 
x 
y 
(e) /\/\ (Rxy 1\ Ryx -- x = y). 
xy 
2. H1( =) /\ /\ (Rxy 1\ Ryz -- Rxz) 
x 
Y 
H2 (=) /\ /\ (Rxy v Ryx) 
x 
y 
Over the domain of individuals {I, 2, ... , lO} give interpretations 
which will falsify, or verify, 
(a) HI 
(b) H2 
(c) HI 1\ H2 

16 
PART A FOUNDATIONS OF MATHEMATICS 
3. HI ( =) V 1\ Rxy 
y x 
H2 (=) 1\ 1\ Rxy 
x 
y 
Hs (=) 1\ 1\ Rxy 
x 
y 
H,(=) V V Rxy 
x 
y 
He (=) V V Rxy 
y x 
Which expressions follow from which? In the cases in which Hi does 
not follow from Hk give a counterexample, i.e., a model of Hi which 
is not a model of Hk . 
Bibliography 
On the foundations of geometry see Borsuk-Szmielew [1], and on modern 
semantics see Carnap [1], Linsky [1] and Tarski [2]. 
4. Axiomatization 
4.1. 
The Origin of Systems of Axioms 
It is today customary to construct a mathematical science axiomatically, 
that is, by first choosing a set of propositions9 as the axioms and then 
drawing consequences from them. The subjects and predicates that occur 
in the axioms are called the fundamental concepts of the system of axioms. 
From the modern point of view these axioms are considered to be variables, 
as explained in §3.4. In general, the number of axioms is finite, although 
infinite systems of axioms are sometimes admitted if their structure is 
immediately clear. For example, we might take for axioms all the propo-
sitions of a certain form. In this case we sometimes speak of an axiom 
schema (for examples, see §lO.3 and §11.2). 
If the fundamental concepts occurring in the axioms are taken to be 
variables, so that the axioms themselves become propositional forms, we 
can no longer regard them as "self-evident." Moreover, if two systems 
of axioms are equivalent (that is, if each of them is a consequence of the 
other), then in principle they are on an equal footing, even though one 
of them may be preferred on more or less subjective grounds, e.g., because 
of its greater logical clarity .. 
Theoretically, we could use any propositions at all to form our set of 
axioms, but it turns out that in modem mathematics relatively few systems 
9 By the arguments in §3.4 we should really say "propositional forms" instead of 
"propositions," but here we wish to conform to the ordinary mathematical usage, in 
which axioms and theorems are called "propositions." 

4 
Axiomatization 
27 
are in actual use. So it is natural to ask about the motives for choosing 
these particular systems. We shall confine ourselves to a discussion of 
this question from the following point of view: It is an established fact 
that in many cases the theory had a prior existence (at least to a great 
extent) and the axioms for it were chosen later. But in many cases the 
axioms are primary; and the theory is to a certain extent secondary, 
since it has been created and defined by the axioms themselves. We shall 
distinguish the two cases by speaking of an heteronomous and an auton-
omous system of axioms, but it must be emphasized that these concepts 
are idealizations; in fact, it is often very hard to decide how a given 
system of axioms actually arose. 
4.2. 
Heteronomous Systems of Axioms (Subsequent Choice of Axioms) 
In general, we are dealing here with the following problem: we are 
given a set ~, usually large, of preassigned propositions and we must 
find a system of axioms (as simple and clear as possible) from which all 
these propositions follow. 10 
A characteristic example is provided by any theory in physics, or in 
any other science based on observation. Here the preassigned set ~ 
consists of a large number of empirical facts, perhaps accompanied by 
certain hypotheses, and it is our task to find a system of axioms ~( that 
will provide an economical description of the whole relevant body of 
knowledge ~. Assuming that we have found such a system of axioms 21, 
we obtain a mathematical science if we ask what are the consequences that 
follow from 21; but if we then proceed to ask whether these consequences 
(so far as they can be tested) are in agreement with observation, we are 
in the domain of theoretical physics. Here again the distinction is clear 
between a natural science (cf. §1.2) and mathematics as a purely abstract 
science. When a mathematical system of axioms ~( has arisen in this way, 
we shall say that the theory determined by ~( has a physical (or, more 
generally, an empirical) origin. It seems reasonable to believe that 
Euclidean geometry is such a science. Basic geometrical concepts, like 
point and line, originated from the need to describe physical data, and 
consequently the first geometrical propositions were of a physical nature. 
An example is the theorem of Pythagoras, already well known to the 
Babylonians in 1700 B.C. This physical origin of geometry becomes 
particularly clear when we reflect that "experiments" are often made in 
school to convince the students that the sum of the angles in a triangle is 
180°. The axiomatization of geometry was begun by the Greeks, who 
from the time of Thales (about 590 B.C.) showed that certain geometrical 
propositions could be made to depend upon others. In relinquishing all 
10 The system of axioms must, of course, be consistent. See *4.7. 

28 
PART A FOUNDATIONS OF MATHEMATICS 
recourse to experience, they became the creators of mathematics in the 
strict sense of the word. The name of Euclid (about 300 B.C.) marks 
the completion (for the time being) of the axiomatization of geometry. 
It is also reasonable to suppose that arithmetic and, to take a modern 
example, the theory of sets have an empirical origin. The axiomatization 
of these sciences will be discussed in § 1 0 and §7. 
4.3. 
Autonomous Systems of Axioms (Systems of Axioms 
as Sources of New Theories) 
The mathematical theories discussed above were already in existence, at 
least in a certain sense, long before the corresponding systems of axioms, 
as becomes quite clear when we recall that in the schoolroom these 
sciences are often presented without reference to any system of axioms 
at all; for example, Euclidean geometry in the secondary school and the 
infinitesimal calculus or naive set theory in the university are often 
taught in this way. But the situation is completely different in modern 
mathematical sciences like group theory, ring theory, or lattice theory. 
These theories cannot be separated from their axioms, since it is only 
through the axioms that they have come into existence at all. A typical 
example is the theory of groups. In the development of mathematics it 
has often happened that widely diverse subjects have been seen to depend 
on lines of argument that are surprisingly similar to one another; e.g., 
the period of the decimal expansion of a given rational number compared 
with the number of times a dodecahedron must be rotated in order to 
bring it back to its original position. It would clearly be more economical 
not to repeat such arguments at every new occasion but to present them 
once and for all in such a form that they are immediately applicable to 
every special case. But an even more important advantage is the fact 
that by proceeding in this way we concentrate on the essential features 
of the situation, thereby gaining a deeper insight into the connections 
among its various parts. In group theory such a program has been carried 
out. It is possible to formulate a small number of axioms with only one 
fundamental concept, namely group multiplication, such that the theory 
is defined, or so to speak created, by the axioms themselves. The con-
sequences of these axioms are called the theorems of group theory. Then by 
interpreting the group multiplication in various ways, each of which must 
satisfy the axioms, we at once obtain the original theorems in the various 
branches of mathematics that led us originally to create the theory of 
groups. The whole of modern mathematics is characterized (cf. 11114) by 
the attempt to give an increasingly central role to such systems of axioms 
as those of group theory. 
Several of the more modern studies of geometry consist of examining 
the consequences of a part of the Euclidean axioms, e.g., the axioms of 

4 
Axiomatization 
29 
connection or the axioms of order. Systems of axioms of this sort can 
also be called autonomous. Similarly, the autonomous systems for algebra 
are to be considered as arising from the heteronomous system for arith-
metic. 
4.4. 
Independence of a System of Axioms 
A system of axioms is said to be independent if no axiom is a consequence 
of the others. In general, independence is desirable but not altogether 
necessary; often it is an advantage that can be obtained only at the cost 
of great complication. 
The independence of a given system of axioms is most simply demon-
strated by finding for each axiom H an interpretation in which H is false 
but all the other axioms are true. As a simple example let us consider the 
three axioms that define an equivalence relation R: 
(4.1) 
1\ Rxx 
(reflexivity) 
x 
(4.2) 
1\ 1\ (Rxy -- Ryx) 
(symmetry) 
x 
Y 
(4.3) 
1\ 1\ 1\ «Rxy 1\ Ryz) -- Rxz) 
(transitivity) 
x 
y 
z 
In each case let us choose as domain of individuals the set of three natural 
numbers {I, 2, 3}. 
Independence of (I): we interpret R as the empty relation (i.e., the 
relation that holds for no pair). 
Independence of (2): we interpret- R as the ~ relation. 
Independence of (3): we iflterpret R as the relation that holds between 
two elements x, y of the domain of individuals if and only if 
Ix-yl~1. 
The fact that the parallel axiom is independent of the other Euclidean 
axioms can also be proved by this method (see 112, §2). 
4.5. 
Completeness of a System of Axioms 
Let there be given an axiom system ~L A proposition that contains 
only subjects and predicates already occurring in ~( will be called a 
relevant proposition and ~( is said to be completell if for every relevant 
proposition H, either H follows from ~( or ---, H follows from ~I. This 
is of course, different from saying that H v ---, H follows from ~(; the latter 
proposition is always true, since H v ---, H is a tautology (tertium non 
datur). 
11 Other definitions of completeness can also be found in the literature; cf. §6.2. 

30 
PART A FOUNDATIONS OF MATHEMATICS 
Autonomous systems of axioms are in general incomplete as a result 
of their inherent nature (cf. §4.6). E.g., from the system of axioms for 
group theory it is impossible, as can be easily shown by examples, to 
deduce either 
(4.3) 
1\ x = X-I 
:I: 
or 
(4.4) 
--, 1\ x = X-I 
:I: 
On the other hand it is natural to expect, in general, that heteronomous 
systems of axioms will be complete in view of their physical origin. 
For suppose we have a relevant proposition H such that neither H nor 
---, H follows from the axioms. Then the physicist will at once attempt to 
obtain experimental evidence of the correctness or falsity of this propo-
sition and, if successful, will add either H or ---, H to the set of axioms. 
Thus, physicists are always striving to complete their systems of axioms, 
so that it is natural to expect completeness in a well developed 
theory. 
Examples of a complete system of axioms are the system for Euclidean 
geometry or the Peano system for the natural numbers (cf. §10.2). 
4.6. 
Monomorphy of a System of Axioms 
The concept of isomorphy, familiar to every mathematician from 
group theory (see, e.g., IB2, §4.2), can be generalized (we omit the 
definition here; cf. IB10, §1.3) in such a way that one may speak of 
isomorphic interpretations of a system of axioms. To take an example 
from geometry: The "natural" interpretation of the Euclidean system of 
axioms, in which the points are "idealized actual points" and the lines are 
"idealized actual lines," etc. is isomorphic to the interpretation provided 
by analytical geometry, in which the points are triples of numbers, the 
lines are the coefficients of the Hesse normal form, etc. 
If a given system of axioms is valid in one interpretation, it is also 
valid in any isomorphic interpretation. For example, if a given structure 
is a group, then every isomorphic structure is also a group. 
Consequently, it is impossible to characterize a given model completely 
by means of a system of axioms. The most that can be attained in this 
direction is to characterize the model "up to isomorphism." A system of 
axioms is said to be monomorphic (categorical) if any two models are 
isomorphic. 
Autonomous systems of axioms are intended to have a wide range of 
application and therefore, in general, they are not monomorphic; in fact, 
there exist nonisomorphic groups, nonisomorphic rings, etc. On the 
other hand, the heteronomous systems of Euclidean geometry and 
arithmetic (cf. § 1 0) are monomorphic. 

4 
Axiomatization 
31 
Every monomorphic system of axioms 'Jr is complete: Let H be a relevant 
proposition. Then we must show that H or 
I H follows from 'JL We 
proceed indirectly by assuming that neither H nor ----. H follows from 'JL 
By the definition of a consequence given in §3, there exists an interpretation 
XlI in which, since H does not follow from 'Jr, all the axioms of 'Jr are 
true but H is false. In the same way, there exists an interpretation Xl2 
in which, since ----. H does not follow from 'Jr, all the axioms of 'Jr are 
true but ~ 1 H is false, and therefore (by the tertium non datur) H is true. 
On account of the assumed monomorphy of 'Jr, the two interpretations 
XlI and :D2 are isomorphic, and since H is true in :D2, it follows that 
H must also be true in XlI. But this contradiction refutes the assumption. 
4.7. 
Consistency of a System of Axioms 
Here we discuss the concept of semantic consistency, to be distinguished 
from syntactic consistency (see §5.7), which is another extremely important 
concept in modern studies in the foundations of mathematics. A system 
of axioms is said to be (semantically) consistent if it has at least one model. 
In view of the physical origin of many heteronomous systems of axioms, 
it is natural to regard them as being consistent. But it must always be 
kept in mind that the consistency of a system of axioms is not, in general, 
an established fact but only a belief based on confidence in our intuitions. 
Particularly problematical is the consistency of a set of axioms that can 
only be interpreted in a domain with infinitely many individuals. 
The question of the consistency of a given system of axioms can often 
be reduced to the 'Same question for another system, in which case we 
speak of a proof of relative consistency. Thus, by means of analytical 
geometry we can show that the system of axioms for Euclidean geometry 
is consistent if the system for real analysis is consistent. The most 
interesting proof of relative consistency is due to Godel, who proved that 
a system of axioms for set theory which includes the axiom of choice 
and the continuum hypothesis (see §7) is consistent relative to the same 
system without these axioms. 
In fact it is well known that belief in the existence of a suitable inter-
pretation can be quite mistaken, for example, in naive set theory (see 
§7 and §11). 
A system of axioms ~( is inconsistent (self-contradictory) if and only if 
the proposition H 1\ ----. H follows from ~(for every relevant proposition H. 
For if m: is inconsistent, then ~l has no model. Thus, every model of ~( 
is also a model of any arbitrary relevant proposition H, and in particular 
of H 1\ ----, H; that is, H 1\ ----. H folIows from ~I. On the other hand, if 
H 1\ ----, H follows from ~r, every model of ~( must also be a model of 
H 1\ ----, H; but H 1\ ----, H is unrealizable, and therefore 
~r has no 
model. 

32 
PART A FOUNDATIONS OF MATHEMATICS 
Exercises for §4 
1. The order and the successor relation for the natural numbers .can be 
described by the following axioms (Peano-Hilbert-Bernays): 
x(-x<x) 
X!/% «x < y 1\ Y < z) ----+ x < z) 
xX < x' 
x -x' = 0 
XII (x' = y' ----+ X = y) 
Show by means of suitable models that this system of axioms IS 
111-
dependent. 
Bibliography 
See the textbooks listed in the other sections. 
5. The Concept of an Algorithm 
5.1. 
Examples of Algorithms 
Mathematicians are interested not only in theoretical insight and 
profound theorems but also in general methods for solving problems, 
methods whereby certain classes of problems can be handled in such a 
systematic way that the actual process of solution becomes, so to speak, 
automatic. Every newly discovered method represents an advance in 
mathematics, although the problems that are solvable by this method 
thereby become trivial and cease to form an interesting part of creative 
mathematics. 
A general method of this sort is often called a calculus, the name being 
derived from the small stones or calculi formerly used in computation. 
Another word with the same meaning is algorithm, derived from the 
name of the Arabic mathematician al-Khuwarizmi (about A.D. 800). 
Let us give some examples of algorithms: (a) the usual methods of 
addition, subtraction, multiplication, and division of integers in the 
decimal notation; (b) the Euclidean algorithm for the highest common 
factor of two integers; (c) the well-known procedures for solving linear 
and quadratic equations with integral coefficients; (d) the method of 
extracting a square root by computing successive decimal places; (e) 
integration of rational functions by means of partial fractions. 
The essential feature of an algorithm is that it requires no inspiration 
or inventiveness but on1y the abi1ity to recognize sets of symbols and to 
combine them and break them up according to rules prescribed in advance; 

5 
The Concept of an Algorithm 
33 
in other words, to carry out elementary procedures that can in principle 
be entrusted to a machine. 
An algorithm proceeds step by step. Some algorithms, when applied 
to a concrete problem, break off after a finite number of steps, as in the 
above examples (a), (b), (c), (e). Others do not come to an end but can 
be carried out as far as we like, as in the extraction of a square root, 
example (d). In the above examples every step is, in general, uniquely 
determined. But in other algorithms it may happen that each step depends 
upon a free choice among several (finitely many) possibilities. For example, 
consider the algorithm (f) which, when applied to two prescribed integers 
a, b (in decimal notation), leaves open at each step a free choice 
between two possibilities: when two numbers (including a and b) are 
already found, we may take (I) their sum or (2) their difference. This 
algorithm enables us to find all the numbers in the module (a, b) 
generated12 by the two numbers a and b. 
A set of numbers (i.e., a row of symbols) which, as in this example, 
can be determined by an algorithm, is said to be recursively enumerable. 
Of course as long as the word "algorithm" is being used in an intuitive 
way, the meaning of "recursively enumerable" also remains intuitive; 
precise definitions are given in §5.5. 
Algorithm (f) has two initial "formulas," a and b, to be thought of 
as given in their decimal notation, since an algorithm is restricted by its 
very definition to operating with rows of symbols (or equivalent objects). 
The above possibilities (I) and (2) for proceeding from one step to the 
next are called the rules of the algorithm. 
The initial formulas of an algorithm are sometimes called axioms and 
its rules are rules of inference. A finite sequence of formulas, in which 
each formula is an axiom or arises from the preceding formulas by 
application of one of the rules, is called a derivation or a proof. These 
terms are borrowed from logic but are used here in a much more general 
sense. 
5.2. 
Examples of "Arithmetical" Algorithms 
An algorithm for the enumeration of finite sets of strokes (or, as we 
may say, "of natural numbers") can be described by one axiom 
(5.1 ) 
I, 
and one rule 
(5.2) 
e ero 
12 For the concept of a module, see IBl, §2.3. 

34 
PART A FOUNDATIONS OF MATHEMATICS 
(Here alb is to be read: from a we may proceed to b.) This rule contains 
a proper variable e, to be interpreted as follows: any expression already 
derived may be substituted for e, and then a stroke may be added to the 
right of it. For example, in the algorithm defined by (5.1) and (5.2), the 
following expressions are derivable: I (as an axiom), II, III, 1111. 
For the expressions derived in a given algorithm, we may use variables, 
say n, m, p, q, for the rows of symbols in the algorithm just described, 
and then these variables can be used to describe further algorithms. 
For example, we can define an algorithm for the addition of natural 
numbers (sequences of strokes). As an axiom we take 
(5.3) 
n + 1= nl, 
which is more precisely an axiom schema. Then n can be replaced by any 
one of the rows of symbols, e.g., II, that are derivable in the algorithm 
defined by (5.1) and (5.2). As a specialization of (5.3), we obtain the axiom: 
(5.3') 
11+1= III· 
As the only rule in the new algorithm we take 
(5.4) 
n+m=p 
n+ml=pl' 
By setting II for n, I for m, and III for p, we obtain from (5.3') the formula 
(5.4') 
11+11 = 1111· 
In order to construct an algorithm for multiplication, we adjoin the 
further axiom (axiom schema): 
(5.5) 
n X 1= n, 
and the rule (now with two "premisses"): 
(5.6) 
n X m = p, 
p+n=q 
nxml=q" 
As a special case of (5.5) we obtain 
(5.5') 
II X I = II. 
If we apply the rule (5.6) to (5.4') and (5.5'), we have 
(5.6') 
"x II = 1111. 

5 
The Concept of an Algorithm 
35 
5.3. 
Recursively Enumerable and Decidable Sets 
Although it has been possible to set up algorithms for the solution of 
many mathematical problems, others have continued to resist every attack 
of this kind, a prominent example being the "word problem" in group 
theory (cf. IB2, §16.1). As a result, mathematicians finally began to 
suspect that certain problems cannot be solved by any algorithm whatever. 
It is obvious that a theorem of this sort will become meaningful, and we 
can proceed to demonstrate it, only when we have given an exact definition 
of the concept of an algorithm. 
More precisely, we need only know what we mean by saying that a 
given set of rows of symbols is recursively enumerable, i.e., can be found 
by means of an algorithm. Here we must realize that more is expected 
from such a definition than, for example, from the definition of continuity 
of a function. In the latter case we are quite satisfied with the simple, 
well-known definition of Cauchy, since it is to a great extent in agreement 
with our intuition, although everyone knows, from certain striking 
examples, that this agreement is byno means complete. But for a recursively 
enumerable set, where we are dealing with the question of what can or 
cannot be accomplished in an actual computation, the definition must 
agree to the greatest possible extent with our basic intuitive notion of 
what is meant by effective calculation of the answer to a given problem. 
The assertion that a given set is not recursively enumerable, i.e., that it 
is impossible to construct an algorithm for finding the elements of the 
set, is of interest only to the extent to which our formal definition of 
an algorithm is in agreement with our intuitive notion of a process of 
computation. 
Several different definitions have been suggested for enumerability (the 
first one of them by Church in 1936), but in spite of the fact that they 
originated in very different settings, they are all equivalent to one another. 
Consequently, many logicians and mathematicians are convinced that 
these definitions correspond completely to our intuitive notion of 
computability. They are to be considered from the classical point of view, 
since they make use of the nonconstructive phrase "there exists." If they 
have been criticized, it is usually by mathematicians who do not share the 
classical point of view and therefore assert that the definitions include 
more than our original intuitive notions. However, a proof of nOI1-
enumerability based on too broad a definition retains its validity when the 
definition is restricted. 
After a preparatory section, we shall give in §5.5 a definition of algorithm 
(or alternatively of recursive enumcrability) which is based on the concept 
of a recursive function. We could set up an alternative defInition by 
generalizing the procedure in §5.2: and a third method stems from the 
fact that, in principle, every algorithm can be entrusted to a machine 

36 
PART A FOUNDATIONS OF MATHEMATICS 
(Turing). There are further possibilities but we omit them here for lack 
of space. 
A property ij; of formulas is said to be decidable if the set of formulas 
that have the property ij; and also the set of formulas that do not have it 
are recursively enumerable. The decidabi.lity of several-place properties 
(relations) is defined correspondingly. In the case of a decidable property 
we can decide, by any of the three methods of recursive enumeration 
mentioned above, whether a given formula, has the property or not. 
5.4. 
Godelization 
The formulas that can be written in a given finite or countably infinite 
alphabet can be characterized in various ways by natural numbers (or 
by the sequences of strokes that correspond to them). We now describe 
one such method, taking as an example the formulas (words) that can 
be written with the twenty-six letters of the Latin alphabet. We first 
enumerate the letters; e.g., 1. a, 2. b, ... , 26. z. Now consider a given 
n-Ietter word (i.e., a formula) in the alphabet, and let the numerals assigned 
to the successive letters of this word be VI , ... , Vn . Also let PI = 2, P2 = 3, 
P3 = 5, ... be the sequence of prime numbers. Then the given word can 
be characterized by the number (Godel index) 
(5.7) 
For example, the word "cab" will receive the number 600 = 23 . 31 . 52. 
Distinct words correspond to distinct numbers but not every number 
corresponds to a word. If the number of a word is known, the word 
itself can be recovered. 
A transition of this sort from the words to the corresponding numbers 
is called arithmetization or Godelization. In all questions concerning 
algorithms, it makes no difference whether we discuss the original 
formulas or their Godel numbers. 
A recursively enumerable set of words is transformed in this way into 
a recursively enumerable set of natural numbers and vice versa. It therefore 
makes no difference, in principle, whether the desired exact definition of 
recursive enumerability is expressed in terms of words or of natural 
numbers. Since the natural numbers have a somewhat simpler structure 
and are more familiar to mathematicians, we will now proceed to define 
the concept of recursive enumerability for a set of natural numbers. 
5.5. 
Computable Functions and Recursively Enumerable Sets 
Instead of giving a direct definition of a recursively enumerable set, 
we shall first define the concept of a computable function, to which the 
concept of recursive enumerability can be reduced. 

5 
The Concept of an Algorithm 
37 
We consider functions, with one or more arguments ranging over the 
entire set of natural numbers, whose values are also natural numbers. 
Such a function is said to be computable (in the intuitive sense) if, for 
arbitrarily preassigned arguments, there exists a procedure for calculating 
the value of the function in a finite number of steps. Examples of com-
putable functions are the sum of two numbers, and their product. The 
folIowing example defines a function f about which we do not know at 
the present time whether it is computable or not: 
1
0, in case there exist natural numbers x, y, z such that 
(5.8) f(n) = 
X· Y . z "* 0 
and 
XU + yn = zn, 
1 otherwise. 
At present we know only a few of the values of this function, e.g., 
f(l) = f(2) = 0, 
f(3) = f(4) = ... = f(lOO) = I. 
If the Fermat conjecture is true, then f(n) = 1 for n ~ 3. 
The folIowing argument shows that the computable functions are 
exceptional. There cannot exist a greater number of computable functions 
than there are methods for computing them. Every method of com-
putation must be capable of being described. A description consists of a 
finite number of symbols. It folIows that there are only countably many 
possible descriptions, and therefore only countably many computable 
functions. On the other hand, the total of number of functions is un-
countable, as may be proved by the same diagonal procedure as the 
uncountability of the continuum (see §7). 
The concept of a recursively enumerable set can be reduced to that of a 
computable function. For we have the theorem: 
A nOll-empty set of natural numbers is recursively enumerable (f and only 
if it is the range of l'alues of a computable function. 13 
To prove this theorem we argue as folIows: A set which is the range 
of values of a computable function.f can be recursively enumerated by 
calculating the successive values f(O), f(1), f(2), ... , as may be done in 
each case in a finite number of steps. We thus obtain an algorithm that 
produces all the elements of the set (in general, of course, they wilI not 
be obtained in order of magnitude, but that is not necessary). 
On the other hand, let there be given a non-empty, recursively 
enumerable set M, so that M contains at least one element no . Now the 
successive steps of an algorithm for the recursive enumeration of M can 
be arranged (if necessary by the adjunction of certain rules) in a unique 
13 It is customary to say that the empty set is also recursively enumerable. 

38 
PART A FOUNDATIONS OF MATHEMATICS 
sequence, with a zeroth, first, second step, etc. Every step produces an 
element of M, or at least an intermediate stage toward the production of 
such an element. We now define a function/ as follows: 
/(n) = 
no , in case the nth step provides only an 
intermediate stage, 
k, in case the nth step provides an element of M 
and this element is k. 
From the definition of/it is clear that/is computable and that the range 
of values of/coincides with the set M. 
Thus it is only necessary to give a precise definition of the concept of a 
computable function. This precise definition is provided by the recursive 
functions as defined in the next section. 
5.6. 
Recursive Functions 
In the domain of natural numbers the sum function is determined by 
two equations (cf. §5.2): 
(5.9) 
(5.10) 
x + 0 = x, 
x + y' = (x + y)" 
where the successor of y is denoted by y'. These equations enable us to 
calculate the sum u + v of any pair of natural numbers u, v in a purely 
formal way. For this purpose we require only two rules: (a) for the 
variables occurring in (5.9) and (5.10) we may substitute numerals 
(0,0'(=1),0"(=2), ... ), and (b) if for these numerals we have already 
derived the result Zl + Z2 = zs, then on the right-hand side of any 
subsequently derived equation we may replace Zl + Z2 by Zs. Corre-
sponding rules hold for the product function, except that in this case the 
set of two equations (5.9) and (5.10) must be augmented by two further 
equations 
(5.11) 
(5.12) 
x'O = 0, 
x . y' = x . y + x. 
Thus the sum plays the role of an auxiliary function for the product. 
The concept of a recursive function, as defined by Herbrand and Godel, 
is based on a generalization of the above procedure. An n-place function rP 
is said to be recursive if there exists a finite system of equations L con-
taining a function symbol/corresponding to c/> and also in general, 
containing function symbols g, h, ... for auxiliary functions, such that for 

5 
The Concept of an Algorithm 
39 
every choice of n + 1 numbers kl , .", kn ,k we have the following result:14 
if ZI , •.. , Zn , Z are the numerals corresponding to the numbers kl , ... kn , k, 
then the equation f(zl , ... , zn) = z can be derived from L if and only if 
4>(k1 , ••• , kn ) = k. In the process of derivation we may make use of two 
rules corresponding to the ones given above: (a) in every equation of L 
we may substitute numerals for the variables; (b) if for any given numerals 
ZI , ... , Zn , Z and function symbol F we have already derived an equation 
F(ZI , ... , Zn) = Z, then on the right-hand side of any subsequently 
derived equation we may replace F(ZI , ... , ZlI) by Z. 
The precise concept of a recursive function is to be regarded as cor-
responding to the intuitive concept ofa computable function. In particular, 
the functions x1l, x!, 1 x -
y 1 are recursive. 
5.7. 
Consistency of an Algorithm and Consistency of Mathematics 
The formulas that can be derived by an algorithm consist of rows of 
single symbols (not necessarily letters in the ordinary sense of the word) 
from a given alphabet. In general, it will not be possible to derive all the 
various formulas that could be constructed from this alphabet. There will 
be at least one formula A whose derivability is "undesirable." Such a 
formuLmight, for example, be Px" ---, Px (cf. §4.7), or x :$ x, or 
1 == 11.15 An algorithm K is called consistent with respect to a formula A 
of this sort if A is not derivable. We are speaking here of the syntactical 
consistency already mentioned in §4. A consistency proof for K consists 
in a demonstration that A is not derivable. A consistency proof in the 
constructive sense must employ only self-evident assertions and must 
avoid all ideas that are problematical from the semantic point of view, 
e.g., the idea of the actual-infinite, since such ideas are not accepted by all 
mathematicians. On the other hand, it is considered acceptable to make 
use of inductive proofs concerning the structure of an algorithm. Let us 
give a simple example: the alphabet of the algorithm K consists of the 
two letters 0 and I. There is a single axiom 
(5.13) 
o. 
As a rule of inference (with the proper variable e) we take 
(5.14) 
14 Let us note the difference between numbers and numerals. It is customary to 
regard numbers as some sort of ideal entities that are represented in writing by symbols 
called numerals. In order to make the discussion more systematic, it is better here not 
to use the ordinary Arabic numerals for the numbers but, as was mentioned above, 
to represent the number 4, for example, by the numeral 0"". Numbers cannot be 
written down, but numerals can. 
15 x == y means that x and yare the same formulas. 

40 
PART A FOUNDATIONS OF MATHEMATICS 
In this algorithm the formula 
is not derivable: that is, K is consistent 
with respect to I. The proof is inductive: we cannot derive 1 from (5.13), 
since 1 is different from o. Also, we cannot derive 1 from (5.14) since 
every formula that can be derived from (5.14) must consist of more than 
a single letter. 
For many of the important algorithms in mathematics, it has been 
possible to derive their consistency by "acceptable" methods of this sort, 
sometimes called "finitary." Moreover, the researches of Hilbert, Gentzen, 
Ackermann, Schutte, Lorenzen, and others have proved the consistency 
of the so-called ramified analysis closely connected with constructive 
mathematics (cf. § I, N r. 4 and 5). On the other hand, no one has yet 
succeeded in proving the consistency of classical analysis. 
Even though algorithms are of great importance for mathematics, it is 
still the opinion of many researchers that the whole of mathematics itself 
cannot be regarded as an algorithm (cf. "Incompleteness of Arithmetic," 
§ I 0.5). In this case it makes no sense to speak of the syntactical consistency 
of mathematics as a whole. 
For the cOl1structillist school of mathematics, as represented, for 
example, by Curry and Lorenzen (§I.4, 5), all mathematical theorems 
are evident in the above sense. For the adherents of this school the whole 
of mathematics is a priori as reliable as a consistent algorithm. 
Exercises for §5 
I. From the functional equations 
(5.9) 
(5.10) 
(5.11 ) 
(5.12) 
and the rules given in the text prove that 
0'" . 0" == 0"
1111 
(3 ·2 = 6). 
2. Give recursion equations for the function Xli. From them prove that 
(0")0" = 0'11' 
3. Introduce the functions 
x! 
(22 = 4). 
~(x) (predecessor of X; 0 if x = 0) 
a ~ b (difference; 0 if a < b) 
by recursion equations. Assume a + b, a· b and functions already 
defined. 

6 Proofs 
41 
4. Show that the calculus determined by the equations (5.9), (5.10), 
together with the rules (a) and (b) given for them in the text, is syn-
tactically consistent. 
5. If a set of natural numbers arranged in order of increasing magnitude 
is recursively enumerable, then it is also decidable. 
Bibliography 
For recursive functions and the concepts related to them see Davis [f], 
Hermes [f], and Kleene [f]. 
6. 
Proofs 
6.1. 
Rules of Inference and Proofs 
Let there be given a system of axioms, say the axioms of Euclidean 
geometry. The theorem of Pythagoras is a consequence of these axioms, 
but that fact is not immediately obvious; it becomes so only step by step. 
Each step consists of the application of a rule of inference. A rule of 
inference is an instruction concerning a possible transition from certain 
preceding formulas (the premisses) to a subsequent formula (the con-
clusion). A simple example with two premisses is the modus ponens (the 
rule of separation) 
(6.1) 
H 
This rule enables us to make the transition from the two premisses 
H ---+ e and H to the conclusion e. An inference is a transition in accord-
ance with a rule of inference. A proof (derivation, deduction) is a finite 
sequence of expressions each of which (unless it is an axiom) can be 
derived from the preceding expressions by means of the rules of inference. 
6.2. 
A Complete System of Inference 
Although it is clear that there exist an infinite number of different rules 
of inference, in actual practice the mathematician makes use of only a very 
few of them, which recur again and again in many different arrangements. 
So we naturalIy ask whether it is possible to find afinite system of rules of 
inference by means of which we can deduce all the consequences of an 
arbitrary system of axioms. Such a system may be calIed a complete system 
of rules of inference, and it is one of the basic discoveries of modern logic 
that, within certain limitations, complete systems of rules of inference 
actualIy exist. The limitations in each case depend on how much the given 
system of logic is able to express. For example, a complete system can be 

42 
PART A FOUNDATIONS OF MATHEMATICS 
found if we confine ourselves to axioms and to consequences expressible in 
the language of predicate logic, which is sufficient for many parts of 
mathematics. But the situation is different if we admit quantification of 
predicate variables. See the "Incompleteness of the Extended Predicate 
Logic" (§10). 
The fact that within the framework of predicate logic every consequence 
can be derived by a finite system of rules of inference is described by 
saying that the predicate calculus determined by these rules is complete. 
The existence of such a calculus was foreseen by Leibniz in his demand 
for an ars inveniendi; to a certain extent it was experimentally verified by 
Whitehead and Russell in their monumental work Principia M athematica 
(1910-1913) (based on the preliminary work of various logicians; in 
particular, Boole's Algebra of Logic, 1847), and finally, in 1930, it was 
proved by Godel in his famous Godel completeness theorem. 
In the terminology of the foregoing section the Godel completeness 
theorem asserts the existence of an algorithm for recursively enumerating 
all consequences of an arbitrary system of axioms that can be stated in 
the language of predicate logic. 
6.3. 
The Complete System of Rules of Inference of Gentzen 
(1934) and Quine (1950) 
Several different complete systems of rules of inference are known today 
but here we must restrict ourselves to the one which, since it is closely 
related to the ordinary reasoning of mathematicians, is called the "system 
of natural inference." The advantage of close relationship with ordinary 
mathematical practice is gained at the expense of unnecessary loss of 
symmetry and formal elegance, so that in purely logical investigations it 
is customary to use other systems. 
For a greater clarity let us make some preliminary remarks. A charac-
teristic feature of mathematical reasoning is the use of assumptions. 
Among the assumptions introduced during the course of a proof in any 
given mathematical theory we must include the axioms of the theory, 
or at any rate those axioms that are referred to in the proof. But in 
addition to the axioms, a mathematician will often introduce further 
(unproved) assumptions, on the basis of which the proof then proceeds. 
Of course, all assumptions that are made in this way must later be 
eliminated. 
A special case of the introduction of assumptions occurs in an indirect 
proof Here we arbitrarily assume the negative of the theorem to be 
proved.16 Then in the course of the proof we try to reduce this assumption 
18 In case we wish to prove --, H, we arbitrarily assume the proposition H (cr. the last 
example in §6.6). 

6 Proofs 
43 
ad absurdum, that is, we try to deduce from it two mutually contradictory 
results. It should be emphasized that, at least from the point of view of 
the classical logic under discussion here, an indirect proof is just as good 
as any other (although the situation is different for other schools of logic; 
see §6.7). 
Another characteristic feature of mathematical reasoning is the 
introduction of variables for entities whose existence is already known. 
Consider, for example, two nonparallel lines g and h in a plane. We know 
that g and h have at least one point in common (in particular if the two 
lines coincide), and then the mathematician will say something like, 
"let a be a point common to the two lines." But the variable a here has 
no independent significance; it is meaningful only with respect to the 
proposition asserting its existence, a fact that must be kept in mind during 
the course of the proof. Variables of this sort also occur in the system of 
Gentzen and Quine, where they are called flagged variables. In order to 
avoid the danger of misunderstanding and consequent mistakes, it is not 
permissible to introduce the same variable for different entities during the 
course of a proof; this restriction is called the restriction against flagging 
the same variable twice. In general, a flagged variable will "depend" on 
other variables that have already appeared in the proof (in our example, 
a depends on g and h), in which case we stipulate that no variable may 
depend (even indirectly) on a second variable which in turn depends on 
the first; this restriction is called the restriction against circularity. 
6.4. 
List of the Rules of Gentzen and Quine 
For an explanation of these rules see §6.5, and the example of §6.6. 
Most of the rules have to do with the introduction or the elimination of a 
logical constant. 
Two further rules without premisses (cf. §6.5): 
a. the rule for introduction of assumptions, 
b. the rule of tertium non datur. 
6.5. 
Explanation of the Rules 
By a proof we shall mean, here and in the rest of this section, a finite 
sequence of expressions that follow one another according to these two 
rules. Here it must be emphasized that this precise definition of a proof is 
altogether necessary in studies of the foundations of mathematics, in 
contrast to the situation in ordinary unformalized mathematics, where it 
is not customary to state the rules of inference being used. The lines in a 
given proof can now be numbered. Each line consists of finitely many 
assumptions (perhaps none) and an assertion. As a typical example we 
take the rule for 1\ -induction. This rule allows us to proceed from a line 

44 
PART A FOUNDATIONS OF MATHEMATICS 
numbered i and a line numbered k (i ~ k) to a line numbered I (with 
I > i, I > k), whose assertion is the conjunction of the assertions of the 
ith and kth lines, and whose assumptions consist of the "juxtaposition" 
of the assumptions of the ith and kth lines; i.e., an expression is an 
The Rules of Gentzen and Quine for the Predicate Calculus 
Logical Constant 
v 
---, 
v 
Introduction 
H 
e 
Hl\e 
e 17 
VH 
x 
e 18 
1\ H 
x 
Elimination 
Hve 
H--Z 
e--z 
Z 
H~e H~e 
H--e e--H 
V H 17 
x 
1\ H 18 
x 
17 Assumption: H becomes e by free renaming of x to a variable y, and conversely e 
becomes H by the reverse renaming of y to x. The variable y must be /fagged with respect 
to the free variables occurring in /I." H and V" H. 
18 Assumption: H becomes e by free renaming of the variable x to a variable y. (An 
exact definition of free renaming cannot be given here. We shall merely give a typical 
example: H = (/I." PXU A Qxy) becomes e = (/I." Pyu A Qyy) by free renaming of 
x to y.) Here), may also coincide with x. 

6 Proofs 
45 
assumption of the lth line if it is an assumption of the ith or of the kth 
line (the order in which the assumptions are written is of no importance, 
and an assumption which occurs several times may be written only once); 
schematically: 
Line Number 
Assumptions 
Assertion 
H 
k 
Bl , ... , Bs 
H"e 
When use is made of the rules of V-elimination (elimination of the 
existential 
quantifier) 
or of V-introduction 
(introduction of the 
universal quantifier), it is mandatory to flag a variable with a statement of 
the variables on which it depends. For example, if U1 , "', Un are the free 
variables in V;r H, then in making use of the rule of V-elimination we 
must write the new line I as follows: 
Line 
Flagged Variables 
y(u1 , ... , un) 
Assumptions 
Assertion 
e. 
The procedure for the rule of A-introduction is analogous.19 
The rule for ---+-introduction may also be called assurnption-elimination; 
for if H is an arbitrary assumption of the initial line (see the list of rules), 
then H will no longer occur as an assumption in the final line of the proof. 
In contrast to the rules described up to now, which allow us to pass from 
one, two, or three lines of the proof to a new line, the two rules of 
assumption-introduction and tertium non datur allow us to write down a 
line in the proof without making use of any preceding line. The rule of 
assumption-introduction consists simply of writing down an arbitrary 
proposition both as assumption and as assertion: 
Line Number 
Assumptions 
Assertion 
H 
H 
19 In this rule the necessity for flagging is perhaps not immediately obvious; let us 
motivate it by the remark that the rule for A-introduction is dual to the rule for 
V-elimination. 

46 
PART A FOUNDATIONS OF MATHEMATICS 
The rule of tertium non datur allows us to write down any particular case 
of tertium non datur without assumptions: 
Line Number 
Assumptions 
Assertion 
I 
H v -, H 
The last line of a finished proof must not contain any flagged variable 
as a free variable, since such a variable has no independent significance. 
Also, after constructing such a proof, we must verify that we have observed 
the restrictions against flagging a variable twice and against circularity.20 
It can be proved that the assertion of the last line of a finished proof is a 
consequence (in the sense of §3.6) of the assumptions of the last line of the 
proof Conversely, if e is a consequence of HI , ... , Hn , then there always 
exists a finished proof with a last line whose assumptions are HI' ... , Hn 
and whose assertion is e. 
In the present sense of the word, a proof is analogous to a schematic procedure 
for making a computation. Thus the process of proof has all the advantages 
and disadvantages of other schematic procedures that have been developed 
in mathematics. The advantage lies in the fact that in a mechanical procedure 
of this sort it is no longer necessary to do any thinking, or at least not as much 
as before, although this advantage can only be gained at the cost of considerable 
training in the art of carrying out the procedure. The disadvantage of a schematic 
procedure is that the rules which are simplest from the formal point of view 
are not always the ones that are most immediately obvious to the human mind. 
On the other hand, if we wish to explain why exactly these formal rules 
were chosen, and no others, our explanation must be based on arguments 
whose meaning is intuitively clear. For lack of space we cannot give a detailed 
explanation here and will merely make a few remarks: the rules for V -introduction 
express the fact that if we have proved an assertion H under certain assumptions, 
then under the same assumptions we may make the weaker assertion H v e 
or e v H. This rule is used in arithmetic, for example, in making approxima-
tions where we proceed from an already proved assertion of the form x < 1 
to the weaker assertion x ~ 1 (Le., x < 1 v x = 1). The rule for ,-elimination 
expresses the following fact: if the assertion H follows from certain assumptions, 
and the assertion , H from certain other assumptions, then the two sets of 
assumptions taken together form an inconsistent system from which an arbitrary 
proposition e follows trivially. The rule for --introduction means only that 
if a proposition e follows from certain assumptions, including in particular 
the assumption H, then the proposition if H then e follows from the same set 
of assumptions excluding H. 
We now give two examples of proofs. The reader is advised to direct his 
attention less to the actual meaning of the steps in the proof than to the question 
20 The restriction against flagging a variable twice prevents us from proceeding from 
V z H through H to Az H, since x would have to be flagged twice; and even if we introduce 
a new variable y, we cannot pass from V z H to Az H without double flagging. 

6 Proofs 
47 
whether the above formal rules have been correctly applied. Of course, th is 
will cost him some effort, comparable to the effort required when one undertakes 
for the first time to solve a quadratic equation by some formal procedure. 
6.6. 
Two Examples of Proofs21 
We begin with a proof that H follows from ---, ---, H. This fact, which is 
valid only in classical logic, makes use of the tertium non datur. In the 
right-hand column we indicate the rule and the preceding lines that 
justify the step taken in each line. 
Line Number 
Assumptions 
Assertion 
Rule Used 
"H 
" 
H 
introduction of assumption 
2 
,H 
,H 
introduction of assumption 
3 
"H" 
H 
H 
,-elimination (2, 1) 
4 
"H 
,H-+H 
elimination of assumption (3) 
5 
H 
H 
introduction of assumption 
6 
H-+H 
elimination of assumption (5) 
7 
H v, H 
tertium non datur 
8 
"H 
H 
V-elimination (7,6,4) 
Since we have used only rules from the propositional calculus, there has 
been no need to flag variables. 
In the same way we can prove the four rules of contraposition, by which 
we mean the following steps: (1) from H -- e to ---, e -- ---, H, (2) from 
H -- ---, e to e -- ---, H, (3) from ---, H -- e to ---, e -- H, (4) from 
---, H -- ---, e to e __ H.22 
As a second example (see page 48) we wish to give part of an indirect 
proof and choose for this purpose the proof of the irrationality of v2. 
We use the variables p, q, r, s, t, U, x, y, z for positive integers and take 
advantage of the fact that a rational number can be represented as the 
quotient of two natural numbers which have no factor in common and 
thus, in particular, are not both even. Then our problem is to prove the 
proposition 
(6.2) 
---, V V (2q2 = p2 1\ ---, (2 I p 1\ 2 I q». 
P 
Q 
Since 2 I p is only an abbreviation for V s2s = p, we may rewrite (6.2) 
in the form 
(6.3) 
---, V V (2q2 = p2 1\ ---, (V 2s = P 1\ V 2s = q), 
P 
Q 
S 
S 
21 A further example is given in § 11.2. 
22 The last two rules are not valid in the logic of intuitionism, which also rejects the 
step from" 
H to H. 

Line Number 
I 
2 
3 
4 
S 
6 
7 
8 
9 
IO 
II 
12 
13 
14 
IS 
16 
17 
18 
19 
20 
21 
22 
23 
24 
Flagged Variables 
p 
q(p) 
s(p) 
Assumptions 
Ho 
Ho 
Ho 
Ho 
Ho 
AI, ... , An 
AI, ... , An 
Ho, AI, ... , An 
Ho, AI, ... , An 
Ho, AI, ... , An 
AI, ... , An 
AI, ... , An 
AI, ... , An 
AI, ... , An 
Ho, AI, ... , An 
Ho, AI, ... , An 
AI, ... , An 
Ho, AI, ... , An 
Ho, AI, ... , An 
Ho 
Ho, AI, ... , An 
AI, ... , An 
AI, ... , An 
Assertion 
VV (2q2 = p2 A , (V 205 = P A V 205 = q» 
p q 
s 
s 
V (2q2 = p2 A , 
(V 205 = P A V 205 = q» 
q 
s 
s 
2q2 = p2 A 
, 
(~ 205 = P A ~ 205 = q) 
2q 2 = p2 
Y 2t = p2(23) 
A (V 21 = u2 --+ V 205 = II) 
u 
t 
R 
V 2t = p2 --+ V 205 = P 
t 
• 
y 205 = P 
25 = P 
2q2 = p2 A 205 = P 
AAA (2x = )'2 A 2z = y --+ 2z = x) 
r 1/ 
Z 
A A (2q2 = )'2 A 2z = y ----+ 2Z2 = q2)2(24) 
II % 
~ (2q2 = p2 A 2z = p --+ 2Z2 = q2) 
2q2 = p2 A 205 = P _ 
2052 = q2 
2052 = q2 
Y 2t = q2 
V 2t = q2 --+ V 205 = q 
t 
s 
~ 205 = q 
y 205 = pAY 205 = q 
, (y 205 = P A ~ 2v = q) 
, 
Ho 
Ho ----+ ", Ho 
Ho --+ Ho 
", Ho 
Rule Used 
introduction of assumption 
V-elimination (I) 
V-elimination (2) 
A-elimination (3) 
V-introduction (4) 
(arithmetic) 
A-elimination (6) 
-~-elimination (7, S) 
V-elimination (8) 
A-introduction (4,9) 
(arithmetic) 
A-elimination (II) 
A-elimination (12) 
A-elimination (13) 
-~-elimination (14, 10) 
V-introduction (IS) 
A-elimination (6) 
- ~-elimination (17, 16) 
A-introduction (8, 18) 
A-elimination (3) 
,-introduction (19, 20) 
elimination of assumption (21) 
elimination of assumption (I) 
,-introduction (23, 22) 
23 Strictly interpreted, the rule of existence-introduction in §6.4 allows us to go from V t 2t = p2 to 2q2 = p2 by introducing a suitable 
variable for the variable t. But that is not exactly what we are doing here, since we must replace t by q2, and q2 is not a variable. The 
difficulty lies in !he-fact that for simplicity in the above example, and for" consistency with the nomenclature of ordinary mathematics, 
we have used the functional notation, which, in principle, we could have avoided, as we have seen in §2.S. 
24 Here we have replaced x by q2. Cf. the preceding note. 
~ 
~ 
:;lO 
-t 
). 
(S 
c: z 
~ 
:j 
o 
~ 
o 
~ 
~ 
). 
~ 
I'T1 
~ 
). 
:j 
~ 

6 Proofs 
49 
which we shall now abbreviate to ---, Ho . Here the axioms of arithmetic are 
indicated simply by AI' ... , An. From AI' ... , An it follows that an 
arbitrary positive integer u is even if its square is even. We have made use 
of this fact in the second line and, strictly speaking, we should give a 
complete proof of it. The same remark applies to line 11, which expresses 
an elementary result from arithmetic. 
It is easy to verify that we have now constructed a finished proof in 
which we have respected the restrictions against flagging the variable 
twice and against circularity. 
From this example it is clear that proofs in the precise sense in which 
we are now using the word are generally much longer than the "proofs" 
of ordinary mathematics. This fact should cause no surprise, since we 
are employing only a few rules of inference of a very elementary character. 
6.7. 
Recllrsil'c Enumerability and Decidability in the Predicate Logic 
The calculus discussed above has provided us with a procedure (an 
ars inl'eniendi) for recursively enumerating the theorems of any theory 
that is axiomatized in the language of the predicate logic. The verification 
of the correctness of any proof can be carried out, at least in principle, 
by a machine, since we are dealing here only with simple formal 
relationships among rows of symbols. Thus, it is a decidable question 
whether or not a given sequence of expressions is a proof. 
But it must be emphasized that such a calculus does not enable us, for 
an arbitrary finite system of axioms '1( and an arbitrarily given expression 
H, to decide whether or not H follows from '1I. To decide such a question 
would require an ars iudicandi in the sense of Leibniz, and since 1936 
it is known (Church) that for the predicate logic such a decision procedure 
cannot exist. 
6.8. 
Nonclassical Systems of Rules 
As was pointed out in §6.5, the rules given in §6.4 for the predicate logic 
can be established semantically. But the nonclassical conceptions of logic 
can lead to corresponding systems of rules that are not necessarily 
equivalent to the system described here. For example, the rule of tertiwl1 
non datur is not valid for a potential interpretation of infinity (cf. § 1.4). 
Exercise for *6 
Let the axioms for a group be given in the following form: 
M (Multiplication) 
1\ 1\ V xy = z 
x 
Y 
z 
A (Associative law) 
1\ 1\ 1\ x(yz) = (xy)z 
x 
Y 
;: 
U (Unity) 
1\ xe = z 
x 

50 
J 
(Inverse) 
El (Equality) 
Ea (Equality) 
PART A FOUNDATIONS OF MATHEMATICS 
A A xy = 0 
x Y 
T=T 
H(T J 1\ Tl = Ta ---. H(Ta) 
Here T, T1 , T2 denote terms, e.g., ab, (ab)c and so forth, and H(T1) is 
an arbitrary term-equation containing the term Tl . Also, El and E2 are 
axiom-schemes (4.1). The axiom E2 can be represented more conveniently, 
and equivalently, by the additional rule of inference 
H(T1), Tl -
Ta 
H(Ta) 
From these axioms construct a proof for the propositional form 
A V ba = e 
a b 
(existence of a left inverse). 
Bibliography 
The following textbooks of logic discuss the methods of proof for the predicate 
logic, but on the basis of rules of inference quite different from those described 
in the present section: Church [1], Hilbert-Ackermann [1], Kalish-Montague 
[1], Kleene [1], Quine [1], Quine [2], Rosenbloom [1]. 
7. Theory of Sets 
7.1. 
Introductory Remarks 
Many definitions and theorems contain such expressions as set, totality, 
class, domain, and so forth. For example, in the definition of a real number 
by means of a Dedekind cut (see IBl, §4.3) the totality of the rational 
numbers is divided into two non-empty classes, a first or lower and a 
second or upper class. An ordered set (cf. §7.2) is said to be well-ordered 
if every non-empty subset contains a smallest element. Again, we may 
visualize a real function as the set of points of a curve and may speak of 
its domain and range (§8.3). Finally, we have already spoken of a domain 
of individuals in our definition of the concept of a mathematical con-
sequence (§3.6). 
The concept of a set, which is thus seen to be of fundamental importance, 
was for a long time regarded as being so intuitively clear as to need no 
further discussion. Cantor (1845-1918) was the first to subject it to 
systematic study. His definition of a set (not a definition in the strict 
mathematical sense of the word but only a useful hint in the right direction) 
runs as follows: A "set" is any assemblage, regarded as one entity M, of 
definite and separate objects m of our perception or thought. 

7 Theory of Sets 
51 
The Cantor theory of sets developed rapidly and soon exercised a 
great influence on many branches of mathematics, the theory of point 
sets, real functions, topology, and so forth. 
But with the discovery of contradictions-the so-called antinomies of 
the theory of sets (cf. §7.2 and §l1)-the foundations of the theory, and 
therewith of the whole of classical mathematics, were placed in jeopardy. 
The discussion of this problem, which is still continuing, has contributed 
in an essential way to the development of modern research on the foun-
dations of mathematics. The various schools of thought have made 
several suggestions for the construction of a theory of sets; let us 
mention a few of the most important. 
The naive or intuitive theory of sets simply attempts to avoid the 
introduction of contradictory concepts. Frege and Russell tried (logicism) 
to reduce the theory of sets to logic. Zermelo, von Neumann, and others 
have introduced systems of axioms for the theory of sets from which it is 
possible to deduce many of the theorems of the naive theory. The con-
sistency of these systems of axioms remains an open question (cf. §4.7). 
Still other authors insist that a set must be explicitly definable by a 
linguistic expression (a propositional form with a free variable), which 
must then satisfy certain additional conditions, depending on the school 
of thought to which the author belongs. 
In Sections 7, 8, and 9 we deal chiefly with the naive theory of sets; 
as for the axiomatic theory, we confine ourselves to a brief description 
of one of the various systems in use. The three sections are closely related 
to one another in subject matter and are separated here only for 
convenience. 
7.2. 
Naive Theory of Sets 
The Cantor definition of a set makes it natural for us to gather into 
one set all the entities that have a given property; for example: (1) the set 
of chairs in the room (these are objects of our perception), or (2) the set 
of even numbers (objects of our thought). To denote variables for sets 
and their elements we use the Latin letters a, b, c, ... M, N, ... , and so 
forth. To express the fact that y is an element of x we write y E x, and for 
----, y E X we also write y $ x. It is possible for one set to be an element of 
another set. Sets that contain the same elements are regarded as being 
equal, i.e., 
(7.1) 
/\ (x E a ~ x E b) -- a = b. 
x 
This requirement is called the principle of extensionality. Thus a set is 
determined by the elements "contained" in it, by its content or extension. 
The property of being a prime number between eight and ten defines 
a set that contains no element. By the principle of extensionality there can 

52 
PART A FOUNDATIONS OF MATHEMATICS 
be only one such set, which is called the empty set, and is here denoted by 0, 
although some authors use the special symbol 0. 
Let us now define the simplest set-theoretic concepts: A set a is called a 
subset of b (a is contained in b, a c: b) if Ax (x E a -- x E b). If a"* b, then 
a is a proper subset of b or is properly contained in b(a C b). The set cis 
called the union of a and b(c = a U b) if Ax (x E C ~ 
X E a v x E b). The 
set c is the intersection of a and b(c = a n b) if Ax (x E C ~ 
X E a 1\ x E b). 
Two sets a, b are disjoint if they have no element in common, i.e., 
an b = O. The complement X25 of a set x is the set of all elements which 
are not elements of x. But here we must be careful, since the complement 
of the empty set is then the "universal set," which easily leads to contra-
dictions (cf. §7.5). These contradictions can be avoided if we consider 
only subsets of a certain fixed set M. Then x is the set of y with 
y E M 1\ Y rt x. 
It is convenient to illustrate these concepts with sets of points in the 
plane: 
~ 
[ a (f3 
CD 
C£J 8J 
"-v------' 
acb 
aUb 
a and b disjoint 
M 
Fig. 1 
Fig. 2 
Fig. 3 
Fig. 4 
By the power set ~a of a set a we mean the set of all subsets of a: 
Ax (x E ~a ~ x c: a). The set that contains x as its single element is 
written {X},26 and correspondingly {x, y} is the set containing exactly the 
two elements x and y, and so forth. For example, {O} contains exactly 
one element, namely the empty set, whereas 0 contains no element at all. 
In a set-theoretic treatment of functions (cf. §8) an important role is 
played by the ordered pairs <x, y),27 defined by 
(7.2) 
<x, y) = {{x}, {x, y}}. 
From <x, y) = <u, v) follows x = u 1\ Y = v. Thus the order of the 
components in an ordered pair is significant. 28 
26 The complement of x is often denoted by "x'." 
26 {x} and x differ from each other, since in general x does not have x as its only 
element. Nevertheless, in cases where no confusion can arise, it is customary to write 
x for {x}. 
27 Ordered pairs are also denoted by (x, y). 
28 For sequences of symbols the construction of ordered pairs may be carried out 
simply by means of juxtaposition and a suitable symbol for separation. 

7 Theory of Sets 
53 
It is easy to prove the following rules, which lead us to speak of an 
algebra of sets (cf. §9) or of a field of sets. 
Laws for nand U: 
(1) 
The commutative laws: 
an b = b n a, 
(2) 
The associative laws: 
a n (b n c) = (a n b) n c, 
(3) 
The absorption laws: 
a n (a U b) = a, 
(4) 
The distributive laws: 
aU b = b u a. 
a U (b u c) = (a U b) u c. 
a U (a n b) = a. 
a n (b U c) = (a n b) u (a n c), 
a U (b n c) = (a U b) n (a U c). 
Lawsfor C: 
(1) 
The reflexive law: 
aC a. 
(2) 
The identitive law: 
a C b 1\ b C a -- a = b. 
(3) 
The transitive law: 
a C b 1\ b C c -- a C c. 
Thus, the relation C is a partial ordering (in the sense of §8.3). 
Laws for C, n, U: 
(1) 
(2) 
a C b~a n b = a, 
a C b n c ~ a C b 1\ a C c, 
a C b~b U a = b, 
a U b C c ~ a C c 1\ b C c. 
Laws for complementation (a, b are subsets of m): 
(1) 
a = b ~ ti = b, 
(3) a C b ~ b C ti, 
(5) (a n b) = ti U b, 
(6) 
a C b~ an b = 0, 
Laws for ° and m (a is a subset of m): 
(1) 
(2) 
aU ° = a, 
an ° 
= 0, 
(2) 
(ti) = a, 
(4) 0= m, 
iii = 0, 
(a U b) = ti n b, 
a C b ~ ti U b = m. 
anm = a, 
aUm = m. 

54 
PART A FOUNDATIONS OF MATHEMATICS 
Up to now we have introduced the concept of union for two sets only, 
but it is often necessary to consider the union of arbitrarily many sets. 
Let M be a set of sets. Then by UXEM x we denote the set of elements y 
belonging to at least one x in M. Correspondingly, as a generalization of 
the intersection of two sets, we write nxeM x for the set of those elements 
of y which belong to every x in M. 
7.3. 
Cardinal Numbers in the Naive Theory of Sets 
One of the most important concepts introduced by Cantor is t.hat of the 
power or cardinality of a set. It represents an extension to infinite sets of 
the number of objects in a finite set. Two sets x, yare said to be equivalent 
(x ,...,." y) if a one-to-one correspondence can be set up between the elements 
of x and those of y. For example, the set {I, 2, 3} and {O, {O}, {{O}}} are 
equivalent; moreover, the set of natural numbers and the set of squares are 
equivalent, as is shown by the following correspondence between them: 
o 1 2 3 
4 
! ! ! ! ! 
o 1 4 9 
16 .... 
This example shows that an "infinite" set a can be equivalent to a proper 
part of itself, a property which is usually taken as the definition of infinity 
( Dedekind definition of infinity). The cardinal number X29 of a set x is then 
regarded as representing "that which is common" to all sets that are 
equivalent to x. Thus, we might say that the cardinal number of x is simply 
the set of all sets that are equivalent to x, although such a definition is 
problematical on account of its relationship to the universal set. On the 
other hand, among all the sets that are equivalent to x we could choose 
one definite set as a representative of x and then say that this set is the 
cardinal number of x. But the problematical feature of such a definition 
is that we do not know how to decide which set should be chosen as the 
representative. In any case we have 
(7.3) 
x ,...,." Y <:?- X = y. 
The cardinal number of a finite set can simply be identified with the number 
of elements in the set. 
For all sets, finite or infinite, we have the Bernstein equivalence theorem: 
If x ~ y 
and y ~ z and 
x,...,." z, 
then 
y,...,." z. 
An ordering ~ for the cardinal numbers (cf. §8.3) can be defined by 
setting x ~ Z <:?- Vll (y ~ Z 1\ X ,...,." y), x < z <:?- X ~ Z 1\ x"* z (cf. §7.4). 
211 Cardinal numbers are also often denoted by "x." 

7 Theory of Sets 
55 
The cardinal number of the set of natural numbers is denoted by No 
(pronounced aleph-zero). If x < No, the cardinal number x is said to be 
finite, but if .i :? No, then x is transfinite. If x = No, then x is countable, 
and if.i ~ No, then x is at most countable.30 A transfinite cardinal number 
that is not countable is said to be uncountable. A set is called countable, 
at most countable, or uncountable if its cardinal number has the corre-
sponding property. Finite cardinal numbers correspond to finite sets, and 
transfinite cardinal numbers to infinite sets. 
The set of rational numbers is countable. The truth of this assertion is 
evident from the following schema in which every "positive" rational 
number occurs at least once (first Cantor diagonal procedure): 
0---1 
2---3 
4---5··· 
J, 
!/'i/l/'t /Q ... 
2 
4 
"4 
Q ••• 
3 
Q ••• 
4 
The existence of uncountable sets was first proved by Cantor by his 
second diagonal procedure: the set of real numbers (X with 0 < (X < 1 is 
uncountable. Proof: let us assume that we have set up a one-to-one 
correspondence between these numbers and the positive integers: 
(Xl = o. allal2al3 .. . 
(X2 = o. a21 a22a23 .. . 
(X3 = o. a3la32a33 .. . 
Here the real numbers have been written as infinite decimals, so that 
o ~ aik ~ 9. Now let us form the number (x' = 0, a~a;a; ... , where a; = 1 
if aii *- I, and a; = 2 if aii = I. Then (x' differs from every number 
listed above in at least one decimal place, since it differs from (Xn in the 
nth place, and thus (x' is not included in the list. Since 0 < (X' < I, our 
assumption is wrong and the theorem is proved. 
The correspondence set up in Figure 5 shows that the set of all real 
numbers, often called the continuum, has the same power as the set of 
real numbers in the interval just considered. 
30 The terms countable and countably infinite are often used in the sense of our 
"at most countable" and "countable," respectively. 

56 
PART A FOUNDATIONS OF MATHEMATICS 
Fig. 5 
-7 
o 
z 
7.4. 
Ordinal Numbers in the Naive Theory of Sets 
A set x for which an order (cf.§8)has been defined is called an ordered set. 
Two ordered sets that can be put into one-to-one correspondence with 
each other with preservation of the order (so that they are isomorphic 
in the sense of §8.4) are said to be similar. By the order type 1 x 1 we mean 
"that which is common" to all sets similar to the given ordered set x 
(cf. the remarks on the concept of a cardinal number in §7.3). If the 
ordering of x is a well-ordering in the sense of §8.3, then I x 1 is an ordinal 
number. For the ordinal numbers we can define an ordering>, which turns 
out to be a well-ordering, by setting 1 x I < 1 y 1 <=> V z (z C y " 1 x I = 
I z I) 
" 1 x 1 "* I y I. For every ordinal number f3 the set of ordinal numbers 
with <X < f3 in the ordering < is itself a representative of f3. The well-
ordering theorem, which can be proved on the basis of the axiom of 
choice (cf. §7.6), states that every set can be well-ordered. Only by means 
of this theorem can we prove that the relation ~ defined for the cardinal 
numbers in §7.3 is an ordering and in fact a well-ordering. 
A non-empty set S of ordinal numbers is called a number class if (I) any 
two members of the set are equivalent (§7.3), and (2) every ordinal that is 
equivalent to S belongs to S. Thus, every cardinal number determines a 
number class. To every finite cardinal number corresponds exactly one 
ordinal number, so that the corresponding class has only one element. 
But the number classes corresponding to transfinite cardinal numbers have 
infinitely many elements. 
The natural numbers can be identified with the finite ordinal numbers, 
or also with the finite cardinal numbers. Then the empty set 0 corresponds 
to the number 0, the class of sets with a single element to the number I, 
and so forth. The cardinal number of the set {O, ... , n -
I} is n. In this way we 
can construct a theory of natural numbers on the basis of the theory of 
sets; and in particular, we obtain a model for the Peano axioms (cf. §IO). 
If to a representative a of a given ordinal number we adjoin another 
element x, which thus becomes the "last" element in the sense of the 
ordering, the set b = a u {x} thus created represents an ordinal number 
1 b I, which is called the successor of I a I and is denoted by I a 1'. Thus 
there is no ordinal number between I a I and I a I'. Ordinal numbers 
(except 0) which, unlike I b I, have no immediate predecessor are called 
limit numbers. 

7 Theory of Sets 
57 
Every non-empty set of ordinal numbers contains a smallest element 
(since the ordinal numbers are well-ordered). Thus we may state the 
principle of transfinite induction [a generalization of induction for the 
natural numbers (cf. §10.2)]: if w is a well-ordering for a set a, then a 
property H holds for all x E a if it satisfies the following conditions: 
(I) 
H holds for the w-smallest element of a. 
(2) If H holds for all x that are w-smaller than y(y E a), then H also 
holds for y. 
The ordinal number of the set of natural numbers, well-ordered in the 
usual way, is denoted by w, which is thus the smallest transfinite ordinal 
number. For a general discussion of the transfinite ordinal numbers, 
cf. I BI, Appendix. 
Functions whose domain is a transfinite set of ordinal numbers are 
often defined inductively by means of three conditions; for example, 
as follows (a, f3 are arbitrary ordinal numbers, A is an arbitrary 
limit number and limflEAf(a, (3) is the smallest ordinal number y with 
f(a, (3) E Y for all f3 E A): 
(I) 
f( a, 0) = a, 
(2) f( a, f3') = f( a, f3Y, 
(3) 
f(a, A) = limf(a, (3). 
/3E,\ 
This is not an explicit definition, since in (2) and (3) the symbol "f" 
to be defined occurs on the right-hand side, but by transfinite induction 
we can show that there exists exactly one function f with the properties 
(I), (2), (3), and then we can write a + f3 for f(a, (3). A schema of the 
form (I), (2), (3) is called a transfinite inductive definition. If condition (3) 
is omitted, the result is a recursive definition, for functions whose argu-
ments are natural numbers. For the justification of such a recursive 
definition we need only the usual complete induction (cf. §IO.2). 
7.5. 
Antinomies in the Naiz'e Theory of Sets 
It is easy to show that the power set of any set x has a greater cardinal 
number than x itself: oX < ~. For finite sets x we have ~ 
= 
2-X, which 
leads us to write 2x for ~ 
in the case of infinite sets as well. The power 
of the continuum is 2No• If we form the set A of all sets (the so-called 
universal set), we first of all have A < ~A. On the other hand ~A is 
certainly equivalent to a subset of A, in view of the definition of A; thus 
~ 
~ A, in contradiction to the fact that ~ is an ordering. This is the 
antinomy of the universal set. 
Another example of a contradictory concept is the set Q of all ordinal 
numbers (antinomy of Burali-Forti). Like every set of ordinal numbers, 

58 
PART A FOUNDATIONS OF MATHEMATICS 
this set is well-ordered by <, and thus it has an ordinal number I [J I. 
By the definition of a successor we have I [J I < I [J I', but by the definition 
of [J we also have I [J I' ::::;; I [J I, in contradiction to the fact that < is a 
well-ordering. 
These examples show that caution must be exercised in the formation 
of sets. (Cf. also the Russell antinomy in §ll.) 
7.6. 
Axiomatic Theory of Sets 
The antinomies of the naive-set theory mostly arise from the fact that 
arbitrary properties, described by propositional forms H (x), are admitted 
for the definition of sets. Thus the trouble arises from assuming that for 
every propositional form H (x) there exists a set a described by the axiom 
schema I\x (x E a ~ H(x). In the axiomatization of von Neumann, 
Bernays, and others, to which we now turn, this axiom scheme (axiom 
of comprehension) is suitably restricted. 
The system deals with objects x, y, z, ... , called classes, between which 
a two-place relation E can exist. Thus x E y is read: class x is an element 
of class y. There is no formal distinction between classes and elements. 
Certain classes are called sets: namely those which are elements of at 
least one class 
(7.4) 
Mx <=> V X E u. 
" 
Our first task is to define equality of classes. It is clear that two classes 
may be regarded as identical if (1) they contain the same elements and if 
(2) whenever either one of them is an element of a class, the other is an 
element of the same class. 
(7.5) 
a = b <=> 1\ (x E a ~ x E b) " 1\ (a E x ~ b EX). 
x 
x 
For our first axiom we may take the principle of extensionality (7.1) from 
the naive theory of sets: 
(7.6) 
1\ (x E a ~ x E b) -- a = b. 
x 
Thus a class is completely determined by its elements. 
Now let H (x) be a relevant propositional form (see §4.5); for example, 
x = x or x E y V X E z. The restricted axiom of comprehension is 
(7.7) 
1\ (H(x) -- Mx) -- V 1\ (x E U ~ H(x), 
x 
" x 
where H(x) does not contain u as a free variable. 
Thus a property H (x) can be used as the definition of a class only if it 
refers exclusively to sets, that is to classes which can be an element of 

7 Theory of Sets 
59 
some class [ef. also (7.9)]. Then the class defined by H (x) is uniquely 
determined by (7.6) and can be given a name appropriate to its definition. 
Let us now try to prove, for example, the Russell antinomy (see §1l) 
by setting x $ x for H(x), so that from (7.7) we obtain 
A (x $ x -- Mx) -- V A (x E U ~ 
X $ x). 
x 
u x 
In particular, for x = 
U 
(7.8) 
A (x $ x -- Mx) -- V (u E U ~ 
U $ u). 
x 
u 
The right-hand side is obviously false, and therefore, by logical rules the 
left-hand side is also false. Thus -, Ax (x $ x -- Mx), and consequently 
(7.9) 
V (x $ x " -, Mx). 
x 
Instead of a contradiction we have obtained the (acceptable) proposition 
that there exists a class x (with x $ x) which is not a set. 
Let us now examine certain properties to see whether they are suitable 
for the definition of a class. 
(I) Mx for H(x). The premiss for (7.7) then reads Ax (Mx-- Mx)and 
thus is satisfied. Consequently, there exists a class A which includes all sets 
and which we therefore call the universal class: 
(7.10) 
x E A<=> Mx. 
(2) 
x = x for 
H(x). 
Because of Ax x = x, the proposition 
Ax (x = x -- Mx) would then lead to Ax Mx, which contradicts (7.9). 
Thus there is no class that includes all classes as its elements, and in this 
way we have avoided the antinomy of the universal set. 
(3) x"* x for H(x). This expression is always false, so that we always 
have H(x) -- Mx. Thus x "* x defines a class which obviously contains 
no element: it is the empty class O. 
(4) 
x E y V X E Z for H(x). Here Mx follows from x E y and also 
from x E Z, so that the premiss of (7.7) is satisfied. Thus H(x) defines a 
class that depends only on y and z, namely their union y u z. 
Other classes can now be defined as in the naive theory of sets; for 
example, the intersection a n b of two sets a and b, the class containing 
one element {a}, and the class of pairs {a, b} and <a, b). The theorems in 
the algebra of classes can then be proved in the same way as in the naive 
theory of sets and, to a great extent, the theory of cardinal and ordinal 
numbers can be developed analogously. For this purpose we must 
introduce step by step the following axioms, which for the most part 
require that certain classes shall be sets. 

60 
PART A FOUNDATIONS OF MATHEMATICS 
The axiom for the empty set: MO. 
The axiom for sets with one element: Mx ----+ M{x}. 
Thefirst axiomfor unions: Mx " My ----+ M(x u y). 
The axiom of infinity: MNz (where Nz is the class of natural numbers). 
The second axiom for unions: Mx ----+ M U x (U x is the union of all the 
elements of x). 
The replacement axiom: If the domain of a function (8.3) is a set, then its 
range is also a set. This axiom enables us to prove that for every set a 
there exists a power class ~a. 
The power set axiom: M x ----+ M~x. 
The axiom of choice: If a is a class of non-empty sets x, there exists a 
function (§8.3) f such that f(x) E x for all x E a. (Thus from every set 
x E a the function f "chooses" an element f(x).) Here also the axiom 
of choice is an essential instrument in the proof of the well-ordering 
theorem. 
The continuum hypothesis: Between the cardinal number of an infinite 
set x and the cardinal number of its power set ~x there is no other cardinal 
number. The particular case x = No is the special continuum hypothesis. 
From the special hypothesis it follows that every uncountable subset of 
the set of real numbers has the power of the continuum. 
7.7. 
Independence of the Axiom of Choice and the Continuum Hypothesis 
In §4.7 we have mentioned the Godel proof of relative consistency. 
GodeI's result can be formulated as follows: let ~{ be the system of axioms 
for set theory as stated just above (§7.6), but without the axiom of choice A 
and the continuum hypothesis K. Let it be assumed that 21 is consistent 
(although it is still unknown today whether this assumption is true). 
Then -, A cannot be deduced from ~l nor K from ~ u {A}. 
In 1963 Cohen proved further that (if~( is consistent) it is also impossible 
to deduce A from ~( or K from ~1 U {A}. Thus we have shown (see also 
§4.4) that A is independent of ~( and K is independent of ~( U {A}. 
7.8. 
Symbols for Sets 
If we are given a propositional form "'X"', it is convenient to have a 
symbol for the set of those x which possess the property corresponding to 
this propositional form. Several notations are customary in the literature: 
x(···x···), 
{x; ···x··,}' 
{x I ···x···}, 
alI of which are read: the set of x with the property ···X··· Let us note that 
the set in question could be denoted just as welI by Y(···y···); in other 
words, we are dealing here with a bound variable (cf. §2.6). 

8 Theory of Relations 
61 
Exercises for §7 
1. Let (n) be the set of rational integers divisible by n. Illustrate the sets 
(3), (6), (9), (15) by point sets in the plane (as in figures 1-4) in such a 
way that the proper inclusions are correctly represented. What is the 
number-theoretic significance of the various intersections and unions? 
2. Show by dual representations that the set of real numbers x with 
o < x < 1 has the same power as the set of points <x, y) of the square 
(0 < x < 1; 0 < y < I). 
3. Let x' be defined by xu {x} (cf. 7.4); also let 
(*) n E N ~ 1\ [(0 EX rCr EX -- r' EX)) -- n EX]. 
x 
Assume the principle of extensionality, the restricted axiom of com-
prehension, the axiom of the empty set, the axiom for sets with one 
element, and the first axiom for unions. 
Prove: 
(a) The right-hand side of (*) defines a class N. 
(b) 0 EN 
(c) 0' E N 
(d) 1\ (x E N -- x' E N) 
x 
(e) 1\ (x' EN -- X E N) 
x 
(/) 1\ (x' E N -- 0 E x') 
x 
Bibliography 
Relatively elementary is Kleene [1]. Let us also mention Bernays [1], Fraenkel 
[1], Fraenkel and Bar-Hillel [1], Halmos [1], Sierpinski [1] and Suppes [1]. 
8. Theory of Relations 
8.1. 
The Concept of a Relation 
We may consider relations as properties of ordered pairs (§7.2). For 
example, 3 < 4 (3 stands in the <-relation to 4) states that the property 
"smaller than" holds for the ordered pair <3,4). Or: the point A lies on 
the line g states that the pair <A, g) has the property described by the 
predicate lies on. 
Analogously, we may regard an n-place relation as a property of ordered 
n-tuples. For example, the expression x + y = z defines a three-place 
relation for the natural numbers. Except when otherwise noted, we shall 
always take the word relation to mean a two-place relation. 

62 
PART A FOUNDATIONS OF MATHEMATICS 
Relations have the same fundamental importance in mathematics as sets. 
Many of the basic concepts of mathematics are to be defined by relations 
(e.g., function, congruence, order) or at least can be understood in terms 
of relations (e.g., group, lattice, factor group, cf. §8.5). 
F or simplicity we here take the naive point of view (cf. §7.1), so that 
relations may simply be regarded as sets of ordered pairs. Thus instead of 
saying: x is in the relation r to y (abbreviated xry), we can equally well 
say: the ordered pair <x, y) is an element of the set r: 
(8.1) 
xry <=> <x, y) E r. 
The elements of the pairs are assumed to belong to a fixed ground set M 
in which the relations are defined, and r, s, t, J, g, h, ... are variables 
for them. For example, if M is the set Nz of natural numbers, then <m, n) 
belongs to the relation ~ if and only if m ~ n. Thus ~ consists of the 
pairs <0,0), <0, I), ... , <1, I), (1, 2), ... and so forth. By the first domain 
(}l (r) of a relation r we mean the set defined by V 11 xry, and by the second 
domain (}2(r) we mean the set defined by V 11 yrx. For example, (}l( <) = 
{O, 1,2, ... }, ()2«) = {l, 2, 3, ... }. The set (}l(r) U (}2(r) is called the domain 
of the relation r. 
An important relation is the identity /, defined by x/y <=> x = y. For 
the class of natural numbers it consists of the pairs <0, 0), < 1, 1), and so 
forth. The empty or void relation, which contains no pair at all, will be 
denoted here by O. It is identical with the empty set ° 
(§7.2). The universal 
relation, which contains every pair with elements from M, will be denoted 
by L It is to be distinguished from the "universal set." Obviously we have 
I\~ 1\11 -, xOy, I\x 1\11 xiy. 
8.2. 
Combination of Relations (Algebra of Relations) 
Since the relations are defined as sets, it is clear what we mean by the 
intersection r (\ s, the union r U s, and the complement i: 
(8.2) 
x(r (\ s) y <=> xry " xsy, 
x(r U s) y .~ xry v xsy, 
xr y <=> -, xr y. 
Similarly, the inclusion r ~ s is defined by I\x 1\11 (xry -- xsy). 
In addition to these purely set-theoretic constructions, there are two 
other important ways of combining relations: the converse relation rand 
the relative product rs. The converse relation is defined by: 
(8.3) 
v 
xry <=> yrx. 
Thus the converse r of r arises from r through "reversal" of all the pairs. 

8 Theory of Relations 
63 
The relative product is defined by: 
(8.4) 
x(rs) y <=> V (xrz " zsy). 
z 
Thus the relative product rs of rand s arises, roughly speaking, from 
"juxtaposition" of rand s. As may be shown by simple examples, this 
operation is not commutative. For rr it is customary to write r2. Thus, 
if M is the class of natural numbers, we have: IC.:s;;, < n I = 6, 
rI = Ir = r for every r, <: = >, 12 = I. A set of relations which is 
closed (cf. I B I 0, §2.2) with respect to alI these operations is called a 
field of relations. For computation with relations we have the same rules 
as for the algebra of sets (§7.2), and also certain other rules, which are 
easily proved directly from the definitions; for example, 
(r n st = r n S, 
(rust=rus, 
v 
v r = r, 
(8.5) 
res U t) = (rs) U (rt), 
r(s n t) C (rs) n (rt). 
8.3. 
Special Properties of Relations 
A relation r is symmetric if Ax Ay (xry --- yrx), a requirement which by 
(8.3) may also be written in the shorter form r C r. Definitions like this 
last one, which make no reference to the elements of the ground set, are 
often more concise. In what folIows we shalI give the definitions, wherever 
possible, in both forms, leaving to the reader the task of proving that they 
are equivalent. In the examples, M is the class of natural numbers, unless 
otherwise noted. 
If xrx for alI x, the relation r is rejiexiue (I C r). Example: x ~ y. 
A transitive relation is defined by Ax Ay Az «(xry " yrz) --- xrz). (Alter-
natively written r2 Cr.) Example: x < y. 
A relation is identitive if Ax Ay «(xry " yrx) --- x = y). (In the shorter 
form, r nrC /.) Example: x is a factor of y. 
A relation is connex if Ax A y (xry v yrx). (In the shorter form, r u r = i.) 
Example: x .:s;; y. 
Relations which are transitive, identitive, and connex are called 
orderings in the sense of.:s;; (example: x .:s;; y). For orderings in the sense of < 
the requirements of identitivity and connexity are replaced by Ax ---, xrx 
and Ax A y (x *- y --- xry v yrx) (example: x < y). 
If we discard connexity altogether, we obtain the so-calIed partial 
orderings (in the sense of.:s;; or in the sense of <), which are sometimes 
calIed semi-orderings. Examples are: inclusion, and strict inclusion 
(cf. §7.2), for the set of all subsets of a given set. In more recent literature, 
partial orderings in the above sense are sometimes called orderings, and 
orderings are called total or complete orderings. 

64 
PART A FOUNDATIONS OF MATHEMATICS 
If an ordering < contains no infinite "decreasing" sequence 
... < Xs < X2 < Xl (Xi+! "* Xi), 
it is called a lI'ell-ordering (of M), 
where a distinction is to be made between well-orderings in the sense 
of < and well-orderings in the sense of ~. Thus an ordering is a well-
ordering if and only if every non-empty subset MI of its field has a minimal 
element in the sense of the ordering, i.e., an element for which there is no 
smaller element in MI' By discarding the requirement of connexity, 
we obtain the partial well-orderings. 
A set M is said to be directed with respect to a relation r if r is transitive 
and if for every X, y E M there exists a z E M such that xrz and yrz. 
8.4. 
Functions 
An important class of relations consists of the functions, defined by the 
requirement of uniqueness /\x /\11 /\z «xry 1\ xrz) -- y = z). (In the shorter 
form, rr ~ I.) For functions it is customary to write f(x) = y in place of 
xfy. The functionf is a mapping of the first domain ()l(f) onto the second 
domain ()If); if ()2(f) is contained in a set A, we say thatf is a mapping 
into A. [f (f)x = y, wJ say that y is the image of ~ (under f) and that X is 
the pre-image of y. Iffis also a function (that is,ff~ 1), then f is a one-to-
one (invertible) mapping of ()l(f) onto ()2(f), and J is called the inverse 
function off Functions whose domain is the set of natural numbers are 
also called sequences. On the basis of the definition (7.1) for equality 
of sets, two functions are equal (or identical) if they have the same domain 
and if for every element in that domain the two functions have the same 
values. 
As an example, let us formulate the Dedekind definition of an infinite 
set (§7.3) in the language of the theory of relations: 
v 
v 
Infinite 
a <=> V (II ~ 1 1\ II ~ 1 1\ ()1(/) = a 1\ ()ll) C a). 
f 
In words: There exists a one-to-one mapping of a onto a proper subset of a. 
Two relations r, s are said to be isomorphic if there exists a one-to-one 
mapping foftheir fields onto each other such that /\x /\ y(xry ~ 
f(x) sf(y). 
In mathematical literature a functionfis often written in the form f(x), 
but this notation is essentially incorrect, since it appears to mean that the 
variable X is free. If we wish to use the variable X as part of the notation 
for a function, we must indicate that this variable is bound. Acceptable 
notations are Axf(x) or X __ f(X)I).SI 
31 The second of these is more common in recent literature, but it is to be noted that 
the arrow here has nothing to do with the symbol for implication in §2.4. 

8 Theory of Relations 
65 
8.5. 
Equivalence and Congruence Relations 
Relations which are symmetric, reflexive, and transltlve are called 
equivalence relations (e.g., the identity I), cf. §4.4. They play an important 
role in mathematics, especially in algebra. 
If we assume reflexivity, we may replace the requirement of transitivity 
and symmetry by that of comparativity: x ~ 
Z 1\ Y ~ z -- x ~ y. 
Let ~ be an equivalence relation in M, and let z denote the set defined 
by x E Z <=> X ~ z. This set is called the equivalence class generated by z 
or corresponding to z. We have 
(8.6) 
(8.7) 
(8.8) 
Z E Z, 
(x E Z 1\ Y E z) -- X ~ y, 
(u E X 1\ U E Y) -- X = Y. 
All the elements of an equivalence class are thus equivalent to one 
another, i.e., they are related by ~. Two equivalence classes are either 
identical or without common element, so that every equivalence relation 
generates a partition of its field M into disjoint classes. Conversely, every 
such partition of M into classes generates an equivalence relation in M; 
for if M is the union of disjoint subclasses, we define: x ~ y <=> (x and y 
lie in the same subclass). 
An equivalence relation defined in a ground set M gives rise to a 
process of abstraction (cf. §1.2), which means that elements of the same 
equivalence class are regarded as indistinguishable; in other words, we 
abstract from their distinguishing features. Conversely, every process of 
abstraction in M gives rise to an equivalence relation in the field M. 
If for a ground set M there are given finitely many k-place functions 
II ···,fn with values in M, then <M,II , ... ,In> is called an abstract algebra 
(cf. IB10, §1.2). For example, let there be given a two-place function j~ 
whose value for the arguments x, y we shall write in the form x . y. 
Then it is clear that we shall usually be interested in those abstractions 
that preserve the operation x . y; that is, if we denote the new equality 
by ~, we must be able to define x . y as G. This will be possible if 
In this case the equivalence relation ~ is called a congruence relation 
(with respect to the operation x . y). The situation can also be described 
in the following way: a congruence relation is an equivalence relation 
that is consistent with the operations of the abstract algebra. For example, 
in the ring of rational integers, x == y (mod 6) is a congruence with 
respect to addition and multiplication (cf. IB6, §4.1). 

66 
PART A FOUNDATIONS OF MATHEMATICS 
If the algebra has a unit element e such that I\~ (x . e = x), then the 
set of x with x f"'Oo..J e forms a subalgebra N, since from x f"'Oo..J e, y f"'Oo..J e it 
follows that x . y f"'Oo..J e . e = e. Let x . N be the set of products of x with 
arbitrary elements of N. For every x we have x . N r;;,. x. The congruence 
classes (complete classes of mutually congruent elements) form an algebra 
of the same "type." If I\te x . N = X, then N is a "normal factor." In this 
way many algebraic concepts and theorems (e.g., the theorem of Jordan-
Holder; see IB2, §I2.I) can be interpreted as concepts and theorems in 
the theory of relations. 
Exercises for §8 
1. Prove (cf. §§8.3 and 8.4) that 
r is reflexive 
r is transitive 
r is identitive 
r is connex 
r is a function 
~Ir;;,.r, 
~r2r;;,.r, 
~r(\~r;;,.I, 
~ru~ =1, 
~r~r;;,.I, 
r is a one-to-one mapping ~ 
~r U rr r;;,. I. 
2. State the axiom of choice and the well-ordering theorem in the symbolic 
language developed in §§7 and 8. 
Bibliography 
For the concepts and applications of the theory of relations see Carnap [2]. 
9. Boolean Algebra 
9.1. 
Preliminary Remarks 
In the present section we are interested in certain phenomena that first 
came to light in the study of the propositional calculus (§2); the fact that 
they are essentially algebraic in nature was first recognized by G. Boole 
(1847). 
Let us consider the one-place predicates P, Q, ... for a fixed domain of 
individuals M (cf. §3). These predicates can be put in one-to-one corre-
spondence with the subsets p, q, ... of M by assigning x to p if and only if P 
holds for x; that is, 
(9.1) 
XEp~PX. 

9 Boolean Algebra 
67 
The conjunction of two predicates obviously corresponds to the inter-
section of two sets; similarly, the alternative corresponds to their union: 
(9.2) 
X E P n q ~ Px 1\ QX, 
X E P u q ~ Px v QX. 
The distributive, associative, and other laws for nand u correspond to 
the same laws for 1\ and v. Negation corresponds to complementation 
(x E P ~ 
----, Px), where (cf. §2.2): 
(9.3) 
pup = M, 
p n p = 0, 
Pxv----,Px~w, 
Px 1\ ----, Px~F. 
Logical implication corresponds to set-theoretic inclusion: 
(9.4) 
p ~ q ~ 1\ (Px -- Qx). 
x 
We see that the domain of predicates for M has the same "structure" 
as the domain of subsets of M; the two domains are isomorphic. For the 
general study of such domains it is therefore natural to introduce an 
abstract algebra by means of axioms. The system of axioms will be 
autonomous in the sense of §4. 
9.2. 
Boolean Lattices 
A set M of elements a, b, ... with operations n, u, - is called a Boolean 
lattice if the following axioms are satisfied: 
BO. an b, aU b, ii are defined for all elements of M and are themselves 
elements of M. 
Bl1. anb=bna t 
B12. a U b = b U a \ 
B21. a n (b n c) = (a n b) n c t 
B22. 
a U (b U c) = (a u b) u c \ 
B31. 
B32. 
B41. 
B42. 
a n (a u b) = a t 
a u (a n b) = a \ 
a n (b u c) = (a n b) u (a n c) 
a u (b n c) = (a u b) n (a u c) 
(Commutative laws) 
(Associative laws) 
(Absorption laws) 
(Distributive laws) 
There exist elements 0 and 1 in M such that for every a in M 
B51. a n ii = 0 t 
B52. a u ii = 1 \ 
(Complementation laws) 
In the set-theoretic interpretation, a n b and a u b are read as inter-
section of a and b and union of a and b, respectively, and in the logical 
interpretation, as a and b and a or b. This system of axioms is denoted by B. 

68 
PART A FOUNDATIONS OF MATHEMATICS 
Looking through the list of axioms in B, we see that for every axiom 
there exists a dual axiom, formed by interchanging (\ with u and 0 with 1. 
Thus for every theorem there is also a dual theorem, whose statement 
and proof arise from the given theorem by these interchanges (principle 
of duality for Boolean algebra). A corresponding principle of duality 
holds for the predicate logic, if we interchange T and F. For example, 
the theorem Ax Px v V x ---, Px ~ T is dual to V x Px 1\ Ax ---, Px ~ 
F. 
Let us state a few easily proved theorems for Boolean lattices: 
(9.5) 
a (\ a = a, 
a U a = a, 
a (\ 0 = 0, 
a U 1 = 1, 
a U 0 = a, 
a (\ 1 = a, 
a U b = b ---+ a (\ b = a, 
a (\ b = b ---+ a U b = a, 
0=1, T = O. 
A domain with operations (\ and u, for which only the axioms BO 
(without complementation), Bl, B2, and B3 are required, is called a lattice. 
Boolean lattices are distributive and complemented (cf. IB9, §l). 
9.3. 
Inclusion in Boolean Lattices 
Inclusion can be defined by 
(9.6) 
a k b <=> a = a (\ b, 
which corresponds to the set-relation, or equivalently by (§7.2) b k a <=> a = 
a ub. 
Let a C b signify that a ~ b and a "* b. It is easy to show that the 
relation ~ is reflexive, transitive, and identitive, and is thus a partial 
ordering in the sense of ~ (cf. §8.3). Also, 
(9.7) 
(9.8) 
a (\ b ~ a, 
a~ aU b, 
(a ~ b 1\ a k c) ---+ a k b (\ c, 
a ~ 1, 
O~a, 
(b k a 1\ c ~ a) ---+ b u c k a. 
From (9.8) it follows that b (\ c and b u c may serve as greatest lower 
bound and least upper bound of band c with respect to C Every element 
that is contained in band c is also contained in the greatest lower bound 
b c, and every element that contains band c also contains the least upper 
bound b u c of band c. The greatest lower bound of all the elements is 0, 
and their least upper bound is 1. Thus every lattice is partially ordered, 
with a least upper bound and a greatest lower bound for arbitrary a and b. 
Conversely, the above properties of inclusion may be used to construct 
a lattice from a partial ordering with least upper bound and greatest lower 
bound. For example, we may define x = a (\ b by 
(9.9) 
x = a (\ b <=> A «(z k a 1\ z C b) ~ z ~ x). 

9 Boolean Algebra 
69 
If we note that for a n b = cud we may also write V x (x = a n b 1\ X = 
cud), we see that the axioms of ~ may be at once translated into axioms 
for c:. For a = 0 we write Ax (a c: x); for a = 1 we write Ax (x c: a); 
and for a = b we write Ax (x c: a u b) 1\ Ax (a nbC: x). 
9.4. 
Boolean Rings 
A third possibility for the description of Boolean algebra lies in the 
theory of rings. We define 
(9.10) 
a . b <:> an b, 
a + b <:> (a n b') u (a' n b). 
Then we can easily show 
a . b = b . a, 
(a . b) . c = a . (b . c), 
a + b = b + a, 
(9.11) 
a + (b + c) = (a + b) + c, 
a . (b + c) = a . b + a . c, 
a·l = a, 
a + 0 = a. 
(9.12) 
a'a = a, 
a + a = O. 
These are the axioms for a commutative idempotent ring with unity 
element.32 Such a ring is called a Boolean ring. Conversely, from a Boolean 
ring we can form a Boolean lattice by setting 
(9.13) an b<:>a· b, 
au b <:> a + b + a' b, 
a <:> 1 + a. 
9.5. Finite Boolean Lattices 
The subsets of a finite set M form a finite Boolean lattice with respect 
to the set-theoretic operations. Here the empty set represents the element 0 
and the whole set M represents the element 1. If M has n elements, then 
the lattice has 2n elements (cf. §7.2). Thus every finite Boolean lattice has 
2n elements (n = 0, 1, 2, ... ), since we can show that every finite Boolean 
lattice is isomorphic to a lattice of subsets. The proof of this theorem 
rests on the fact that every element of a finite Boolean lattice is the union 
of atoms in the lattice, where an element a is called an atom if a -:I=- 0 
and if from x C a it follows that x = O. The atoms of a lattice of subsets 
are the sets with one element {x} (see §7.2). The finite Boolean lattices 
can be very clearly illustrated by diagrams in which the elements are 
represented by points in a plane in such a way that if a C band 
----, V c (a C c 1\ C C b), then a lies below b and is joined to b by a line 
segment. Thus if the number of elements is 2°, 21, 22, 23, we obtain 
the following figures: 
32 For the concept of rings see 185, §1.5 fT.; a ring is idempotent if a . a = a for 
each of its element. 

70 
PART A FOUNDATIONS OF MATHEMATICS 
• 
o • 1 
Fig. 6 
1 
I 
0 
Fig. 7 
{a,b,c} 
1 
{b, c} 
<> 
{c} 
0 
0 
Fig. 8 
Fig. 9 
The diagram for the lattice with 23 elements shows the subsets of the 
3-element set M = {a, b, c}. 
Exercises for §9 
1. Prove 
(a) (9.5) from the system of axioms ~, 
(b) (9.7) and (9.8) from m and (9.6), 
(c) (9.11) and (9.12) from ~ and (9.10). 
2. Consider propositional forms constructed from countably many 
(cf. 7.3) propositional variables p, q, ... (cf. 2.4) by the connectives 
-', A, v, --+, ~ (cf. 2.4) of the propositional calculus. Define 
H '" e <:> H ~ e is a tautology (3.4). 
Now prove 
(a) '" is an equivalence relation 
(b) '" is consistent with the functions K, A, N defined on the set of 
propositional forms as follows: 
K(H,e) = H A e 
A(H, e) = H v e 
N(H) = ,H. 
(c) The equivalence classes form a Boolean algebra under the following 
definitions: 
(I) Hn8 = H ~e 
(2) Hu8=~ 
(3) Ii = ~ 
(4) 0 = p A -,p 
(5) 1 = p v -,p 

10 Axiomatization of the Natural Numbers 
71 
By b) the definitions (1)-(3) are independent of the representatives of 
the equivalence classes. Show that in (4) and (5) the definitions are 
independent of the choice of the propositional variable p. 
(d) If the number of propositional variables is finite, then the Boolean 
algebra is also finite. If n is the number of variables, then the 
number of elements in the Boolean algebra is 22n. 
Bibliography 
For Boolean algebra, see Goodstein [1 J. 
10. Axiomatization of the Natural Numbers 
10.1. 
Preliminary Remarks 
The theory of natural numbers occupies an especially important place 
in studies in the foundations of mathematics. In the first place, the 
arithmetic of natural numbers offers a simple and important example of 
a theory with an infinite domain of individuals, in which the problems 
connected with the concept of infinity can be studied. Secondly, it has 
turned out that many other interesting metamathematical questions can 
be reduced to arithmetic (cf. the arithmetization in §5.4). Finally, the 
results of Godel on arithmetical algorithms have had a lasting influence 
on the whole program of metamathematics. Let us discuss these remarks 
in greater detail. 
The "leap to infinity" involved in recognizing the domain of the natural 
numbers is already adequate for all the ontological needs of the predicate 
logic (cf. §3); this is the meaning of the fundamental theorem of Lowenheim 
and Skolem, which essentially states that in order to investigate the 
concept of a consequence there is no need to use any domain of individuals 
other than the natural numbers. 
Since in a system of axioms 6 the means of expression (variables, 
logical symbols, and so forth), are obviously countable, it is clear that the 
obtainable expressions are also countable. Thus the expressions can be 
"numbered" constructively (see §5.4). For every expression the resulting 
index is computable and, conversely, for every number we can decide 
whether or not it is the index of an expression; if it is, then the expression 
can be recovered. As a result, certain metamathematical properties 
like ... is an expression, ... is the conjunction of .. and ...... is true are 
transformed into number-theoretical properties. Thus all questions of 
decidability can be translated into the corresponding questions for 
arithmetic. Moreover, if the system 6 includes an arithmetical system of 
axioms, many of the metamathematical propositions about 6 can be 

n 
PART A FOUNDATIONS OF MATHEMATICS 
formulated in 6 itself, and in this way it is possible to obtain extremely 
general theorems about mathematical systems of axioms (cf. §10.5). 
For a long time the concept of the (infinite!) totality of natural numbers 
was held to be intuitively clear, and indeed quite self-evident [cf. the similar 
situation for the concept of a set (§7.1)]. It was Frege (1884) who first 
pointed out the necessity for an exact definition of a natural number. 
In his attempt to reduce arithmetic to logic he defined the number 1, 
for example, as the totality of all one-place predicates that hold for 
exactly one individual. This definition is closely related to the set-
theoretical introduction of the natural numbers and leads to the same kind 
of difficulties as the naive theory of sets (§7.3). Thus we naturally seek, 
as in that theory, to characterize the natural numbers by a system of 
axioms. The best-known system of axioms for the natural numbers is due 
to Dedekind (1888) but is named after Peano (1889). In §10.3 we shall 
discuss a somewhat modified system, formulated in the language of 
predicate logic. The question of ax iomati zing the whole of arithmetic 
(§10A) then leads us to the well-known Incompleteness Theorem of Godel 
(§10.5). The present section closes with some remarks on the operational 
construction of arithmetic recently proposed by Lorenzen. 
10.2. 
The Peano Axioms 
The Peano axioms (with unimportant changes): 
(a) 0 is a natural number.33 
(b) If n is a natural number, then so is n'. 
(c) If m' = n', then m = n. 
(d) There is no number n for which n' = O. 
(e) 
Axiom of complete induction: 
If a property P of the natural numbers satisfies the following two 
conditions, then P holds for every natural number: 
(1) P holds for o. 
(2) For every natural number n, if P holds for n, then P holds for n'. 
These axioms can be stated in a formal language consisting, as before, of 
formulas or rows of symbols, but now, in view of the fact that the axiom (e) 
speaks of an arbitrary property, we must make use of a generalized 
predicate variable; that is, a predicate variable bound by the universal 
quantifier. Expressions with quantified predicate variables are regarded 
as belonging to logic of the second order, or to the extended predicate logic. 
Expressions in which only subject variables are quantified are said to 
33 The sequence of natural numbers is often taken to begin with 1. 

10 Axiomatization of the Natural Numbers 
73 
belong to logic of the first order, or to elementary predicate logic. For the 
extended predicate logic, as well as for the elementary (§3), it is possible 
to give a semantic definition of the concept of a consequence. 
Except for axiom (e) we will continue to confine our arithmetical 
expressions to the elementary logic. In particular, in questions of com-
pleteness and decidability we shall consider only relevant expressions of 
the first order. The fundamental concepts of our system of axioms are: 
(1) an individual variable for zero; as such we take the traditional symbol 0; 
(2) a predicate variable for the relation of successor; we make use of the 
functional notation and denote the successor of x by x' (cf. §2.5); (3) a 
predicate variable for identity; as such we use the traditional symbol =. 
There is no need to mention the axioms (a) and (b), since we do not admit 
any individuals other than the natural numbers. In a supplementary axiom 
we express the conditions that must be satisfied by the identity. 
The Peano system of axioms ~ in the extended predicate logic. 34 
(PI) 
(P2) 
(Ind) 
(G) 
x' = y' --- X = y, 
----, x' = 0, 
1\ (PO 1\ 1\ (Py --- Py') --- 1\ Px), 
P y X  
x = y ~ 1\ (Px --- Py). 
P 
The semantic consistency (cf. §4.7) of ~ is obvious for anyone who feels 
convinced of the "existence" of the natural numbers. But for the extended 
predicate logic we have not yet defined a concept of deducibility, so that 
for the time being the question of syntactical consistency (cf. §5.7) does not 
arise. 
The system ~ is monomorphic (§4.6) and thus, as desired, it characterizes 
the natural numbers. Let us outline the proof. 
Let M and M be arbitrary models (cf. §3) of ~. Then M contains a 
domain of individuals J, a function f (for x') defined on J and a fixed 
element n (representing 0) in J. We denote the corresponding objects for 
M by J, /, fl. We must now show that M and M are isomorphic (§8.4); 
that is, we must demonstrate the existence of a mapping (/> of J onto J 
with the properties of an isomorphism. 
(10.1) 
(10.2) 
(/>(n) = fl, 
(/>(f(x) = /«(/>(x). 
34 For clarity, we have emphasized here that P is generalized, i.e., bound by the 
universal quantifier. Of course, x and yare also to be considered as generalized. 

74 
PART A FOUNDATIONS OF MATHEMATICS 
First we define inductively a relation 4J by 
(10.3) 
(10.4) 
n4Jn, 
A A «x E J 1\ Y E J) ---. (x4Jv ---. f(x) 4J/(y)', 
x 
y 
• 
(10.5) 
Let x4Jy hold only as required by (10.3) or (10.4). 
We now prove step by step [with tacit use of the axiom of equality (G)]. 
(I) The first domain of 4J is J (proof by the axiom of induction for 
the model M). 
(2) The second domain of 4J is J (proof by the induction axiom for the 
model M). 
(3) There is no x in J with n = f(x) [proof by the axiom (P2) for M]. 
(4) There is no x in J withf(x) 4Jn [proof by (3) and (10.3, 4, 5)]. 
(5) If x4Jn and y4Jn, then x = y [proof by (4) and (I)]. 
(6) If x4Jz and y4Jz, then x = y; that is, i> is a function (8.3) [proof by 
induction for M, (5) and (PI)]. 
(7) 
4J is a function [proof analogous to (6)]. 
Thus we have shown that 4J is a one-to-one mapping of J onto J, from 
which the properties of an isomorphism follow immediately by (10.3) 
and (10.4). 
We must note, however, that this proof can be attacked on the ground 
that it is based in an essential way on semantic ideas that are closely 
associated with the naive theory of sets. For in fact the "totality of all 
properties" referred to in (G) and (lnd) is uncountable. From the mono-
morphy of ~ it follows that ~ is complete (cf. §4.5). 
10.3. 
The Peano Axiom with Restricted Axiom of Induction 
We now turn to an axiom system ~1' which completely avoids the 
extended predicate logic. In order to exclude quantification of predicate 
variables, we must first make some change in the axiom of equality (G). 
Let us replace it by the two axioms 
(Gl) 
(G2) 
x = x, 
x = y ---. (H(x) ---. H(y). 
Since for H(x) we may write any expression of the elementary predicate 
logic, it follows that, strictly speaking, (G2) is not an axiom but an axiom 
schema (§4) which in an obvious way represents countably many axioms. 

10 Axiomatization of the Natural Numbers 
75 
The axioms (PI) and (P2) remain unchanged, but for (lnd) we must also 
introduce an axiom schema: 
H(O) 1\ 1\ (H(y) -- H(y') -- H(x) (induction schema). 
y 
The system (GI, G2, PI, P2, Ind1) will be denoted by ~1 • Like ~, the 
system ~1 is of course semantically consistent. On the other hand, 
monomorphy is lost in the transition from ~ to ~1 • For we see that the 
proof of monomorphy for P cannot simply be repeated for ~1 , since the 
properties to which (lnd) was applied in that proof are not necessarily 
capable of formulation (and in fact cannot be formulated) in the elementary 
predicate logic (cf. §10.2). In §10.5 we shall see that PI actually admits 
nonisomorphic models. It can be shown that the set of deductions from 
~1 or from ~ is decidable.35 These systems are therefore complete and 
their theorems can be obtained by algorithms. 
10.4. Systems 3 and 31 for Arithmetic 
For the construction of arithmetic it is clear that the successor function 
alone is not enough. We also need addition and multiplication. These 
functions, as we know, can be defined recursively (§5.6), and the equations 
defining them can be adjoined to the axioms. Let us first state the axioms 
for addition: 
(10.6) 
(10.7) 
x + 0 = x, 
x + n' = (x + n)'. 
From ~ and ~1 we thus obtain axiom systems Xl and XlI , respectively, 
to which the properties of monomorphy and nonmonomorphy, of 
completeness and decidability, are transferred. But these advantages are 
offset by a certain poverty in our means of expression. To be sure, we can 
still express such number-theoretical concepts as x < y or 3 is afactor of x: 
(10.8) 
(10.9) 
x < y ~ V (z *- 0 1\ X + z = y), 
z 
3 I x ~ V (z + z + z = x). 
z 
But it can be shown that other important concepts like x I y or x is a prime 
number cannot be defined, so that many interesting number-theoretical 
problems cannot be formulated and thus cannot be decided within the 
framework of these theories. 
35 It must be noted that in these formal systems multiplication does not occur and 
cannot be (explicitly) defined. 

76 
PART A FOUNDATIONS OF MATHEMATICS 
In order to enrich our means of expression we adjoin the recursive 
definition of multiplication to the axioms of Xl and XlI : 
(10.10) 
(10.11) 
x'O = 0, 
x . (n') = (x . n) + x. 
The resulting systems will be denoted by 3 and 31 . In these systems we 
can define, for example, the following arithmetical concepts: 
(10.12) 
x I y <=> V (y = x . z), 
z 
(10.13) Prime x <=> x*-O 1\ X *- 0' 1\ 1\ (z I x ---. (z = 0' v z = x». 
z 
Godel has shown, although we have no space for his proof here, that all 
decidable properties and relations (§5.4), e.g., Z = xy, are now definable: 
The system 3 (or 31) includes the complete recursive theory of numbers. 
The (syntactical) consistency of 31 was proved by Gentzen in 1936. 
In comparison with the preceding systems, the investigation of 3 and 31 
gives rise to considerably greater difficulties. Consider, for example, the 
existence of such unsolved number-theoretical problems as the Goldbach 
conjecture: 
(10.14) 
1\ (2 I Z 1\ Z *- 2 -- V (Prime x 1\ Prime y 1\ Z = 
X + y). 
z 
x,Y 
Such problems make it plausible, as is in fact the case, that in these 
systems the set of consequences is not decidable. The truth of this statement 
results from the following theorem of Godel, which is one of the most 
important discoveries in the whole theory of the foundations of mathe-
matics. 
10.5. 
The Godel Incompleteness Theorem: 31 Is Incomplete (Even 
Essentially Incomplete; cf. End of the Present Subsection) 
Although it will be impossible to include many of the details, we wish 
to give an outline here of the proof of this theorem, partly on account of 
its great importance, but also in order that the reader may see how an 
argument which in a natural language leads to a contradiction (namely 
to the Antinomy of the Liar described in §11.3) can in a formal language 
be put to good use, namely, to prove the incompleteness of 31 . 
An important instrument in the proof is the arithmetization described 
in §5.4, where we have shown that a procedure can be set up whereby 
the formulas of the language are characterized by their so-called Godel 
numbers. Since it is decidable whether or not a given formula is a relevant 
expression,36 it is also decidable whether a given natural number is the 
36 A relevant expression here is the same as a relevant proposition in §4.S. 

10 Axiomatlzation of the Natural Numbers 
n 
G6del number of some relevant expression. Since we have shown in §10A 
that all decidable properties can be defined in 31 , there exists a relevant 
expression A(x) which in the natural interpretation (i.e., the interpretation 
in which 0 corresponds to zero, and so forth) holds for a natural number 
if and only if this number is the G6del number of an expression in 31 . 
Finite sequences of relevant expressions can be represented by numbers 
in the same way as the expressions themselves, so that, in particular, 
proofs can be expressed by numbers, since they are merely special 
sequences of expressions. Since it is decidable whether a given rule of 
inference has been correctly used, we can now find a relevant expression 
C(p, q) which in the natural interpretation is true for p and q if and only if p 
is the number of a relevant expression Hand q is the number of a proof 
of H in 31 . 
We now proceed to construct a relevant expression E, containing no 
free variables, which in the natural interpretation states that E (in other 
words, the expression itself) is unprovable (cf. the Paradox of the Liar 
in §11.3). If we assume that E is provable, we then have the following 
situation: Every model of 31 , and consequently also the natural inter-
pretation, satisfies E and therefore states, in contradiction to our 
assumption, that E is unprovable. On the other hand, if we assume that 
----, E is provable, the natural model will satisfy ----, E, and therefore falsify E; 
that is, E is provable, a result which, taken together with the provability 
of ----, E, contradicts the consistency of 31 . Thus neither E nor ----, E is 
provable. 
This syntactical result, when reformulated in semantic language, states 
that neither E nor ----, E is a consequence of 31 . In other words, 31 is 
incom plete, as asserted. 
The expression E, which asserts its own unprovability, is constructed as 
follows: If n is the G6del number of an expression with exactly one free 
variable x, let us denote this expression by An(x) and call n an A number. 
We construct the propositional form 
(10.15) 
x is an A number and y is the Godel number of a proof of Ax(x). 
By means of the arithmetization, this propositional form can be 
represented by an expression B(x, y) in 31 with the two free variables 
x and y. Now let p be the G6del number of the expression Ay ----, B(x, y). 
We form the expression A1J(p) obtained by replacing x with p in Aix). 
By (10.15) this expression states: for every y, the number y is not the Godel 
number of a proof of A1J(p), Thus A1J(p) is a proposition E of the desired 
kind. 
This theorem can obviously be extended to all axiomatic theories that 
have constructive definitions for their expressions and rules of inference, 
and that include a sufficiently large part of arithmetic. 

78 
PART A FOUNDATIONS OF MATHEMATICS 
The incompleteness theorem has some remarkable consequences: 
(1) There exist arithmetical propositions (e.g., E) that are true for 
the natural numbers but are not provable in 31 . It is conceivable, for 
example, that the Fermat conjecture or the proposition (10.14) is true 
but cannot be deduced by means of the familiar rules of inference in 31 . 
(2) From the incompleteness of 31 it follows by §4.6 that 31 is not 
monomorphic. For example, the proposition E is true for the model of 
the natural numbers but certainly untrue for some other model of 31' 
since E is not a consequence of 31 . 
(3) If we introduce into 3 certain natural rules of inference (it is to be 
noted that the language in which 3 is formulated goes beyond the means 
of expression available in the predicate logic), we can prove, just as for 31 , 
that there exists in 3 a proposition E such that neither E nor ---, E is 
deducible. Then we could proceed, again just as for 31 (see above), to 
prove that 3 is incomplete, provided we were allowed, as is the case in 31 , 
to replace the concept of provability by the concept of a consequence. 
But we know that 3 is complete, as may be proved in exactly the same 
way as for ~ in §10.2. Thus we have the important result that in 3, and 
more generally in the logics of higher order as contrasted with the predicate 
logic, the concept of a consequence cannot be reduced to an algorithm. 
One might think that the incompleteness of 31 could be removed by 
the introduction of further axioms that would leave the system consistent. 
But so long as we are dealing with finitely many axioms (or more generally 
with a decidable schema of axioms ), the concept of provability remains 
decidable, so that the above argument can be applied to the enlarged 
system of axioms. Thus we are dealing here with an essential, nonremovable 
incompleteness. 
These results for 31 and 32 can also be obtained in the following way. 
We can show that in any sufficiently expressive arithmetical language 
there always exists, for any given recursively enumerable set (§5.3) M of 
arithmetical theorems [Le., arithmetical propositions that are valid in the 
natural interpretation (§10.5)], an arithmetical proposition E which, 
together with its negation, does not belong to M. Thus we have: 
(a) Since the set of deductions in 31 is recursively enumerable (§6.2), 
the system 31 is incomplete; 
(b) The system 3, like ~, is monomorphic and therefore complete 
(§10.2). Thus the set of deductions in 3 is not recursively enumerable, 
and therefore certainly not decidable. 
For a system of axioms 6 that includes arithmetic we can also construct, 
by means of our arithmetization, a proposition W expressing the syn-
tactical consistency of 6. Then the Gt>del theorem leads to the result that W 

10 Axiomatization of the Natural Numbers 
79 
is not deducible in 6, provided 6 is consistent. Consequently, in order to 
prove the consistency of 6 we must make use of methods that lie outside 6. 
10.6. 
The Operational Construction of Arithmetic 
In this construction the theorems of arithmetic and of other branches 
of mathematics are regarded, without reference to any possible semantic 
interpretation, as statements concerning the application of certain rules 
of operation with finite systems, which may consist of numerals or of 
concrete objects of any kind. If we study these systems (which are made up 
of finitely many "atoms" or indivisible systems), we can distinguish them 
according to their "length," and in this way we necessarily arrive at the 
conception of a number. By "abstraction" from systems of the same 
length we obtain the fundamental numbers, which can be uniquely 
represented by systems such as I, II, III, ... (Lorenzen). Propositions, rules 
of inference, sets, and so forth are again merely systems or "terms" 
(possibly with certain rules of transition from one system to another). 
The fundamental rules of operation are given in the form of algorithms, 
on the basis of which further systems and rules can be "deduced." How-
ever, this "deducibility" must be of an obviously "constructive" nature; 
in his "protologic," Lorenzen gives a number of principles of deduction 
that can be considered constructive. 
The operative construction of arithmetic can only be briefly indicated 
here (see also §5.2). The system for generating the numerals is defined 
by an algorithm with one axiom and one nile, involving the proper 
variable e (cf. §5.2): 
(10.16) 
(10.17) 
I, 
e er· 
Equality is defined by the following algorithm (k, I are variables for 
numerals): 
(10.18) 
I = I, 
(10.19) 
k=1 
k I = II· 
By various principles of deduction we now realize that: 
(10.20) 
(10.21) 
k I = II --. k = I, 
kl*k, 
(10.22) 
k = 1/\ A(k) --. A (I) 
(so-called principle of equality). 
(10.23) 
A(I) /\ ~ (A(k) --. A(k I) --. A(/) 
(so-called principle of 
induction ). 

80 
PART A FOUNDATIONS OF MATHEMATICS 
The significance of (10.20) is that the rule 
(10.24) 
k I = II 
k=1 
is superfluous, i.e., in the algorithm for equality nothing can be deduced 
with this rule that cannot be deduced without it, as follows from the 
so-called principle of inversion: since k I = II can be obtained only from 
k = I, it follows that k = I must also be deducible. 
The atom A is introduced by a rule which is identica1 with the rule 
for A-introduction in §6.4, but the rules in §6.4 for the elimination of A 
are not required here, since the princip1e of inversion shows that they 
are superfluous. 
The systems (10.20)-(10.23) correspond to the Peano axioms; but in 
the present case they are not "postulated" but follow from certain 
"proto logical" theorems applied to the arithmetical algorithm. 
One advantage of this construction of mathematics lies in the fact that 
by its very nature it leads only to propositions that can be seen intuitively 
to be true and therefore cannot involve contradictions. 
Exercises for §IO 
1. On the basis of the axioms (PI), (P2), (lnd) and (G) prove the following 
theorem 
1\ (PO 1\ PO' A 1\ (Px -- Px") -- 1\ Px). 
p 
x 
x 
2. To (PI), (P2), (Ind), (G), 10.6 and 10.7 
adjoin the axioms 
02 = 0 
(X')2 = x 2 + X + X + 0'. 
Then show that in the resulting system it is possible to define the relation 
that holds for x, y and z if and only if x . y = z. 
Bibliography 
Elementary problems in the foundations of arithmetic are discussed in Tarski 
[1]. For the theory of the systems Z and Zl see Russell [1]. On the concept 
of arithmetic itself see Frege [11. 
11. Antinomies 
11.1. 
Classification of the Antinomies 
A proposition (or a propositional form) together with its negation form 
a contradiction. By an antinomy or paradox we mean an argument that 
leads to a contradiction. 

11 
Antinomies 
81 
It is natural to ask what could be the nature of such an argument. 
This question is most easily answered if we are dealing with an algorithm, 
since an antinomy then consists in the deduction of a proposition and of 
its negation. Since only formal processes are involved here, we speak of 
a syntactic antinomy (for the concepts of syntax and semantics cf. §3.1). 
But it can also be the case that an argument which leads to a contra-
diction is not truly formal but depends on the meaning of the propositions 
(or of parts of them) that are used in the argument. In this case we speak 
of a semantic antinomy. 
Since algorithms in the strict sense of the word are very recent inventions, 
it is not surprising that syntactic antinomies have been known for a 
relatively short time. On the other hand, many semantic antinomies were 
already discussed in antiquity. 
If we can deduce a proposition and its negation, then by the rule of 
,-elimination (see §6.4) we can deduce any proposition. But if we can 
deduce everything, there is no interest in constructing arguments. As a 
result, we reject any algorithm that leads to a syntactic antinomy. As for 
semantic arguments leading to a semantic contradiction, we must make 
up our minds to revise at least one detail of the intuitive truths "inserted" 
into the argument, but it is often very difficult to accomplish this change 
in a convincing way. 
Syntactic antinomies can also lead, at least indirectly, to a revision of 
our intuitive ideas. In general, an algorithm is not set up arbitrarily but 
is based on certain of our intuitive conceptions, which it presents in a 
concentrated form. Thus, if we find an antinomy in such an algorithm, 
we must realize either that the conceptions are not adequately represented 
in the algorithm, or else that they must be rejected, at least to some extent. 
We confine ourselves here to a detailed description of two antinomies: 
the Russell Antinomy, as a characteristic example of a syntactic antinomy, 
and the Antinomy of the Liar, as a characteristic example of a semantic 
antinomy. 
11.2. 
The Russell Antinomy 
We are dealing here with a system of axioms in the language of predicate 
logic, so that the deductions can be obtained by means of an algorithm. 
The intuitive conceptions at the basis of this system of axioms are of a set-
theoretical nature (cf. §7). Let us describe them briefly: there exists a 
property defined by the predicate "x is an element of the set y." We 
represent this predicate by the symbol Exy (that is, we use the symbol 
Exy of predicate logic to mean x E y). Sets are represented by propositional 
forms with one variable; for example, the set of even numbers is repre-
sented by the propositional form 
(11.1) 
21 x, 

82 
PART A FOUNDATIONS OF MATHEMATICS 
and the set of prime numbers by the propositional form 
(11.2) 
x > 1 1\ 1\ (y I x -+ y = I v y = x). 
y 
Now if we assume, as seems natural, that every propositional form H 
with a variable x corresponds to a set y containing exactly those objects 
which satisfy H, we are led to require as part of our system of axioms that 
(11.3) 
V 1\ (Exy +-+ H). 
y 
x 
It is to be noted that this requirement is not a single axiom but an axiom 
schema (cf. §4.1), since (11.3) is a prerequisite for every propositional 
form H containing x (but not y) as a free variable. 
The Russell Antinomy now consists of showing that this schema of 
axioms, within the framework of predicate calculus, leads to a contra-
diction. 
The contradiction is obtained by taking for H the propositional form 
---, Exx. Then the set y, whose existence is required by (11.3) (and whose 
uniqueness, unimportant here, follows from the principle of extension-
ality), is the set consisting of every set that does not contain itself as an 
element. But this set y gives rise to a contradiction if we ask whether 
or not y is a member of itself. For if y is an element of itself, then y, 
precisely because it is an element of itself, cannot, by definition, be an 
element of itself. On the other hand, if y is not an element of itself, then, 
again by the definition of y, it must be an element of itself. Let us deduce 
the contradiction by a formal argument. In addition to the rules in §6, 
our set of axioms now includes all the special cases of (11.3) (see the 
following table). 
Line 
Flagged Assump-
Number Variable 
tions 
Assertion 
Rule Used 
1 
VII Az (Exy +-+ , Exx) 
axiom 
2 
y 
A. (Exy <-+ -. Exx) I V-elimination (I) 
3 
Eyy +-+ ,Eyy 
A-elimination (2) 
4 
Eyy -
,Eyy 
+-+-elimination (3) 
5 
--, Eyy -
Eyy 
+-+-elimination (3) 
6 
Eyy 
Eyy 
introduction of assumption 
7 
Eyy -Eyy 
elimination of assumption (6) 
8 
, Eyy 
, Eyy 
introduction of assumption 
9 
,Eyy -, Eyy 
elimination of assumption (8) 
10 
Eyy v ,Eyy 
excluded middle 
11 
Eyy 
v-elimination (5, 7, to) 
12 
, 
Eyy 
v-elimination (4,9, 10) 
13 
Ezz 
,-elimination (11, 12) 
14 
--, Ezz 
,-elimination (11, 12) 

11 
Antinomies 
83 
Lines 1-13 provide a finished proof for Ezz, and lines 1-14 for ---, Ezz, 
so that the contradiction is proved.37 
This antinomy indicates that we must in some way revise the set-
theoretical conceptions underlying the axioms (11.3). As a result, it is 
no longer assumed today that every propositional form defines a set 
(cf. §7.6). 
11.3. 
The Antinomy of the Liar 
This antinomy, already well known in antiquity, makes use of the 
concept of truth (cf. also §3) and is thus a semantic antinomy. We begin 
with the stipulation already stated in precise form by Aristotle, that a 
proposition is true if and only if it describes an actual state of affairs. 
As a concrete example, let us consider the proposition "it is snowing." 
Then we can say: 
(11.4) "it is snowing" is true if and only if it is snowing. 
But this proposition, consisting of the whole of line (11.4), remains true 
if we replace the proposition "it is snowing" by any other proposition. 
Thus we are led to recognize the validity of all propositions of the following 
form: 
(11.5) 
; .. is true if and only if - --
where in place of "- - -" we may put an arbitrary proposition, provided 
that at the same time we put a name of this proposition in place of " ... ". 
In order to obtain the Antinomy of the Liar we consider the particular 
proposition: 
(11.6) The proposition that follows "(11.6)" is not true. 
In other words, the proposition asserts its own falsity. We now insert 
this proposition in (11.5) in place of "- - -" and at the same time we insert 
a name for this proposition in place 0(" ... ". For such a name we choose: 
"the proposition that follows '(11.6)'." Then as a special case of (11.5) 
we obtain: 
(11.7) The proposition that follows "(11.6)" is true if and only if the 
proposition that follows "(11.6)" is not true. 
But from (11.7) it is easy to obtain a contradiction (cf. the Russell 
Antinomy starting from line 3 of the proof). 
This contradiction cannot be avoided as long as we agree to the following 
conditions: we accept the Aristotelian criterion of truth (11.5), we admit 
37 We could not stop with line It or 12, since they still contain a free occurrence of 
the flagged variable y. 

84 
PART A FOUNDATIONS OF MATHEMATICS 
that what is contained in the line (11.6) is a proposition and that "the 
proposition that follows '(11.6)' " is a name for this proposition, and 
finally we accept the elementary logical deductions that lead from (11.7) 
to an actual contradiction. 
If now, faced with this contradiction, we ask at what stage we should 
change our point of view, it would be natural to look first at the Aristo-
telian criterion of truth (11.5). Yet it must be admitted that propo-
sition (11.5) seems almost self-evident and that we would never have felt 
any doubt about it if the antinomy had not been brought to our attention. 
Moreover, we must take note of the fact that in a certain respect we have 
already made use of this criterion in §3.4, where we discussed the validity, 
in a certain interpretation, of an elementary propositional form PXl' 
•.. , Xn • For we can express the Aristotelian criterion, as applied to that 
special case, in the form: 
(11.8) If we replace x by 3 and P by the property of being a prime 
number, then Px is true if and only if 3 has the property of being 
a prime number. 
The similarity with (11.5) is unmistakable. 
But this comparison indicates how we can attack the Antinomy of the 
Liar. In (11.8) the problem at issue is to define what is meant by saying 
that a given propositional form is true in a given interpretation. Now the 
propositional form Px belongs to the language of predicate logic but the 
desired definition will be given, not in the language of predicate logic, but 
in some other language, namely whatever language we use for talking about 
predicate logic. Our choice for such a language is everyday English, 
cautiously used in a somewhat refined form. The predicate "is true" 
introduced in (11.8) belongs to this everyday language but refers not to 
propositions of everyday language, but to propositional forms in the 
language of predicate logic (in conjunction with the given interpretations). 
Thus the difference between (11.5) and (11.8) is essentially as follows: 
in (11.8) we are dealing not only with a given language (the language of 
predicate logic) but also with a metalanguage (everyday English), in 
which we speak about the first language. The predicate "is true" in (11.8) 
is a predicate in the metalanguage. But it refers not to propositions in 
the metalanguage, but to expressions in the first language. In (11.5), 
on the other hand, there is only one language, namely everyday English. 
The predicate "is true" occurring there belongs to this everyday language 
and also refers to propositions in the same language. 
Now it is easy to see that in (11.8) no antinomy is to be feared (or at any 
rate we cannot so easily construct one as in the Antinomy of the Liar). 
For the Antinomy of the Liar is based on a proposition that states its 
own falsity. But such a situation is not possible (or at any rate not 

11 
Antinomies 
85 
immediately possible) if we distinguish between language and metalan-
guage. For in that case we cannot form a proposition that states its own 
falsity. Such a proposition, call it <x, must belong to the metalanguage, since 
it contains the word "true" (or "false"); but the word "true" in the 
metalanguage refers to propositions of the initial language and therefore 
cannot refer to <x. 
In summary, we may say: we can escape from the Antinomy of the 
Liar by distinguishing between language and metalanguage and by 
speaking about the truth of the propositions in a given language-not 
in that language itself but in a metalanguage. Such distinctions between 
a formal language and a metalanguage, or a meta-metalanguage and so 
forth, are common in modern logical investigations. Since the natural 
languages of the world are "universal" and fail to make this distinction, 
in the sense that they use the word "true" for arbitrary propositions 
expressible in them, many investigators consider these natural languages 
to be inevitably self-contradictory. 
As a final remark, let us point out that the other semantic antinomies 
can be avoided when we make the distinction between language and 
metalanguage. Consider, for example, the antinomy of the smallest 
natural number that cannot be described in English in fewer than a 
hundred words. The antinomy arises from the fact that, precisely in the 
definition just given, this number has nevertheless been described in 
fewer than a hundred words. But the above definition refers to all possible 
descriptions and thus, since it speaks of these descriptions, it must belong 
to a language that is a metalanguage with respect to the language to 
which the descriptions belong. Consequently, we obtain in the metalan-
guage a description for the number which is shorter than any possible 
description in the initial language. But this result is not a contradiction. 
Exercises for § 11 
1. An adjective A is said to be autologic if A has the property described 
by A, and otherwise A is heterologic. Examples of autologic adjectives 
are: "seventeenlettered," "English," "pentasyllabic." Consider the 
word "heterologic." Is it heterologic or autologic? Explain and 
resolve the antinomy (Grelling's antinomy). 
2. If the definition of an object or element m depends on a set M and if 
m is then assigned to M as an element, the definition of m is said to 
be impredicative. 
(a) Show that the antinomies mentioned in the text make use of 
impredicative definitions. 
(b) Show that the definition of the least upper bound of a set M of 
real numbers, as given in real analysis, is impredicative. 

86 
PART A FOUNDATIONS OF MATHEMATICS 
Bibliography 
On the antinomies in the theory of sets see Beth [1] and Linsky [1]. 
Bibliography 
Bemays, R.: [1] Axiomatic Set Theory. With a historical introduction by Abraham 
A. Fraenkel. North-Holland Publishing Company, Amsterdam, 1958, 
VllI + 226 pp. 
Beth, E.'W.: [1] The Foundations of Mathematics. North-Holland Publishing 
Company, Amsterdam, 1965, XXVIII + 741 pp. 
Bochenski, J. M., [1] A Precis of Mathematical Logic. Translated from the 
French and German Editions by Otto Bird. D. Reidel, Dordrecht, 
Holland; Gordon and Breach, New York, VII + 100 pp. 
Borsuk, K. and W. Szmielew: [1] Foundations of Geometry. North-Holland 
Publishing Company, Amsterdam, 1960, XIV + 444 pp. 
Camap, R.: [1] Introduction to Semantics. Harvard University Press, Cambridge, 
Mass., 1946, 2. Druck, XII + 263 pp. 
Carnap, R.: [2] Introduction to Symbolic Logic and its Applications. Dover 
Publications, Inc., New York, 1958, XIV + 241 pp. 
Church, A.: [1] Introduction to Mathematical Logic. Princeton University 
Press, Princeton, N.J., 1956, IX + 376 pp. 
Church, A.: [2] Logic. Article in Encyclopaedia Britannica, Vol. 14. Encyclopae-
dia Britannica, Ltd., London, Chicago, 1963, pp. 295-305. 
Cohen, P. J.: [1] The Independence of the Continuum Hypothesis. Proceedings 
of the National Academy of Sciences, Vol. SO, pp. 1143-1148 (1963) 
and Vol. 5t, pp. 105-110 (1964). 
Cohen, P. J.: [2] Set Theory and the Continuum Hypothesis. W. A. Benjamin, 
Inc., New York, 1966, VI + 154 pp. 
Curry, H. B.: [1] Outlines of a Formalist Philosophy of Mathematics. North-
Holland Publishing Company, Amsterdam, 1951, VII + 75 pp. 
Curry, H. B.: [2] Foundations of Mathematical Logic. McGraw-Hill Book 
Company, Inc., New York, 1963, XII + 408 pp. 
Davis, M.: [1] Computability and Unsolvability. McGraw-Hill Book Company, 
Inc., New York, Toronto, London, 1958, xxv + 210 pp. 
Fraenkel, A. A.: [1] Abstract Set Theory. North-Holland Publishing Company, 
Amsterdam, 1953, XII + 479 pp. 
Fraenkel, A. A. and Y. Bar-Hillel: [1] Foundations of Set Theory. North-
Holland Publishing Company, Amsterdam, 1958, X + 415 pp. 
Frege, G.: [1] The Foundations of Arithmetic. Transl. by J. L. Austin. Basil 
Blackwell, Oxford, 1950, xii + xiie + XI + Xle + 119 + 11ge pp. 
Frege, G.: [2] Translations from the Philosophical Writings of Gottlob Frege. 
Edited by P. Geach and M. Black. Basil Blackwell, Oxford, 1952, 
X + 244 pp. 
Goodstein, R. L.: [1] Boolean Algebra. The Macmillan Company, New York, 
1963, VI + 140 pp. 
tialmos, P. R.: [1] Naive Set Theory. D. Van Nostrand Company, Inc., Princeton 
N.J., 1960, VII + 104 pp. 
Hermes, H.: [1] Enumerability, Decidability, Computability. Springer-Verlag, 
Berlin, Heidelberg, New York, 1965, IX + 245 pp. 
Heyting, A.: [11 Intuitionism. North-Holland Publishing Company, Amsterdam, 
1956, VIII +- 132 pp. 

Bibliography 
87 
Hilbert, D. and W. Ackermann: [1] Principles of Mathematical Logic. Chelsea 
Publishing Co., New York, 1950, XII + 172 pp. 
Kalish, D. and R. Montague: [1] Logic. Techniques of Formal Reasoning. 
Harcourt, Brace & World, Inc., New York, 1964, X + 350 pp. 
Keene, G. B.: [1] Abstract Sets and Finite Ordinals. Pergamon Press, Oxford, 
1961, X + 106 pp. 
Kleene, S. c.: [1] Introduction to Metamathematics. D. Van Nostrand Company, 
Inc., Princeton, N.J., 1952, X + 550 pp. 
Kleene, S. c.: [2] Mathematical Logic. John Wiley & Sons, Inc., New York, 
1967, XIII + 398 pp. 
Kneale, W. and M. Kneale: [1] The Development of Logic. Clarendon Press, 
Oxford, 1962, VIII + 761 pp. 
Kneebone, G. T.: [1] Mathematical Logic and the Foundations of Mathematics. 
D. Van Nostrand Company Limited, Princeton, N. J., 1963, XIV + 435 pp. 
Kreisel, G.: [1] Mathematical Logic. Lectures on Modern Mathematics, Vol. III 
(edited by T. L. Saaty), pp. 95-195. John Wiley & Sons, Inc., New York, 
1965. 
Linsky, L. (editor): [1] Semantics and the Philosophy of Language. The University 
of Illinois Press, Urbana, 1952, IX + 289 pp. 
Lorenzen, P.: [1] Formal Logic. D. Reidel Publishing Company, Dordrecht, 
1965, VIII + 123 pp. 
Nagel, E., and J. R. Newman: [1] Godel's Proof. New York University Press, 
New York, 1958, IX + 118 pp. 
Novikov, P. S.: [1] Elements of Mathematical Logic. Oliver & Boyd, Edinburgh, 
1964, XI + 296 pp. 
Quine, W. V.: [1] Elementary Logic. Ginn and Company, Boston, 1941, VI + 170pp. 
Quine, W. V.: [2] Mathematical Logic. Harper & Row, New York, 1962, 
XII + 346 pp. 
Robinson, A.: [1] Introduction to Model Theory and to the Metamathematics 
of Algebra. North-Holland Publishing Company, Amsterdam, 1963, 
IX + 284 pp. 
Rosenbloom, P. c.: [1] The Elements of Mathematical Logic. Dover Publica-
tions, Inc., New York, 1950, IV + 214 pp. 
Rosser, J. B.: [1] Logic for Mathematicians. McGraw-Hili Book Company, 
Inc., New York, 1953, XIV + 530 pp. 
Russell, B.: [1] Introduction to Mathematical Philosophy. The Macmillan Co., 
New York, 1924, VIII + 208 pp. 
Sierpinski, W.: [1] Cardinal and Ordinal Numbers. Panstwowe Wydawnictwo 
Naukowe, Warsaw, 1958, 487 pp. 
Suppes, P.: [1] Introduction to Logic. D. Van Nostrand Company, Inc., 
Princeton, N.J., 1957, XVIII + 312 pp. 
Suppes, P.: [2] Axiomatic Set Theory. D. Van Nostrand Company, Inc., 
Princeton, N.J., 1960, XII + 265 pp. 
Tarski, A.: [l] Introduction to Logic and to the Methodology of Deductive 
Sciences. Oxford University Press, New York, 1941, XVIII + 239 pp. 
Tarski, A.: [2] Logic, Semantics, Metamathematics. Clarendon Press, Oxford, 
1956, XIV + 471 pp. 
Wang, H.: [1] A Survey of Mathematical Logic. North-Holland Publishing 
Company, Amsterdam, 1964, X + 651 pp. 
Wilder, R. L.: [1] Introduction to the Foundations of Mathematics. Second 
edition. John Wiley & Sons, Inc., New York, 1965, XII + 327 pp. 


PART B 
ARITHMETIC AND ALGEBRA 


Introduction 
The development of modern algebra since the beginning of the present 
century has been a process of continually increasing abstraction, so that 
the subject was often called abstract algebra. It was realized that important 
simplifications could be gained, both in concept and in method, if for 
the various fields of arithmetic, the theory of numbers, algebraic equations, 
functions of a complex variable, and so forth we establish as clearly as 
possible what is common to these subjects and then present it in a form 
that is valid for all of them. For it often happens that theorems that have 
been discovered and proved in widely different fields of mathematics 
are found to be identical from the logical point of view, so that the proof 
can be carried out quite independently of the various interpretations in 
one field or another. In fact, the proof is generally much simpler and 
clearer when these particular interpretations are set aside; moreover, 
we can spare ourselves the trouble of proving the same theorem over and 
over again, since the general "abstract" proof is valid for all the "concrete" 
cases. 
Since mathematics is in itself a very abstract science, the reader may feel 
surprised that certain branches of it are described as "abstract." Let us 
examine the situation. 
The concept of a natural number is already the result of a complicated 
process of abstraction by no means easy to retrace (cf. I A, § 10.1, and 
IBI, §I.I), and we are scarcely conscious of it in everyday calculations. 
But the immense intellectual effort involved in first making this abstraction 
has been richly rewarded by our being able to apply the simple rules of 
arithmetic to problems dealing with any kind of objects-stones, trees, 
lengths, weights, and so forth. 
91 

92 
PART B ARITHMETIC AND ALGEBRA 
The same remark can be made about geometry. The concept of a 
triangle, which underlies the theorems of geometry, is already extremely 
abstract; it means only that we are dealing with a figure consisting of 
three points and the lines that join them. But then the theorems we deduce, 
e.g., that the sum of the angles of a triangle is equal to two right angles 
or that the sum of two sides is greater! than the third side, are valid for 
all possible triangles, regardless of their size, shape, or origin. The task 
of setting up the abstract geometric concept of a triangle demands a 
massive intellectual effort, but this effort is far more than offset by the 
simplicity and generality of the resulting theorems, which can now be" 
applied to all possible triangles. 
Now it is reasonable to expect a similar advantage from what we may 
call a second stage of abstraction, namely, from the fact that certain 
concepts and methods in the various branches of present-day mathematics 
can be identified with one another if we make an abstraction from their 
interpretations in various special fields. 
The objects of study in abstract algebra are sets of an extremely general 
nature; their elements may be numbers, polynomials, functions, vectors, 
transformations, or any conceivable entities, whose meaning in any 
particular branch of mathematics is quite irrelevant. These sets have an 
algebraic structure consisting in certain relations or laws of combination 
among the elements within the set, in the existence of certain distinguished 
subsets, and so forth (see also IBIO). Examples are groups (IB2) together 
with their subgroups, modules (IBl, §2.3), and lattices (IB9); Chapter IB5 
will deal with general (commutative) rings and integral domains, whose 
structure is characterized by the presence of certain distinguished subrings, 
namely, the ideals. Special rings also occur in other chapters; for example, 
the ring or integral domain of rational integers (IB 1, IB6), the field of 
rational numbers (IBl, IB6), rings of algebraic numbers and the field of 
algebraic numbers (lB6, IB7), rings of polynomials (IB4), rings of matrices 
(lB3), rings of groups (IB2), rings of endomorph isms (IBl,2.4),and so forth. 
1 Or at most equal, if we allow the three vertices to lie on one line. , 

CHAPTER 1 
Construction of the System of Real Numbers 
1. The Natural Numbers 
1.1. 
The Peano System of Axioms 
The simplest approach to the natural numbers (in the present section 
they are simply called numbers) is provided by the common practice of 
counting objects by making marks on paper, so that the number of 
objects is represented by a row of marks, for example 1111. This procedure 
suggests that we define the natural numbers as the diagrams obtained by 
writing vertical strokes one after the other. The number I is also written 
in the form 1 and is called "one." The number formed by writing a 
vertical stroke to the right of the number a is called the successor of a; 
in the present § I (but only here) we write this number! in the form a'. 
Equality of two numbers is defined as follows: beginning from the right-
hand end (many other procedures would also be possible), we attempt 
to make a one-to-one correspondence between the two sets of strokes. 
If such a correspondence can be set up (as in the diagram) we say that 
the numbers are equal; otherwise they are unequal. 
We see at once that the logical requirements for 
a definition of equality (see §2.2) are satisfied 
I i I i 
I i I i here, that a' *- 1 for every natural number a, 
LL-..--.:====='t""""'---' 
and finally that a' = b' is equivalent to a = b. 
Every number can be formed from the number 1 
by repeated construction of a successor. Conse-
quently, any property that belongs to the number 1 and is hereditary, 
i.e., is bequeathed by each number to its successor, belongs to every 
1 The symbol a I would be quite adequate but we do not adopt it here, partly for 
typographical reasons and partly because we want to keep our notation independent 
of any particular method of introducing the natural numbers. 
93 

94 
PART B ARITHMETIC AND ALGEBRA 
number. Let us summarize this information in the following system of 
axioms: 
I. 
1 is a number. 
II. 
To every number a there corresponds a unique number a', called its 
successor. 
III. If a' = b', then a = b. 
IV. a'"* 1 for every number a. 
V. 
Let A(x) be a proposition containing2 the variable x. If A(1) holds 
and if A (n') follows from A (n) for every number n, then A (x) holds 
for every number x. 
From this system of axioms (which is usually named after Peano; 
cf. lA, § 10) we shall see that by logical reasoning we can derive any 
theorem about the natural numbers without further reference to the way 
in which they were introduced. Thus a reader who for any reason is 
dissatisfied with our definition of natural numbers may adopt any other 
definition that leads again to I-V, and then he can follow our further 
developments. Our reason for setting up a system of axioms is not that 
there is anything inexact about the procedure3 using vertical strokes; the 
system of axioms simply sets us free from this particular procedure. For 
example, we could define cardinal numbers as classes of equivalent sets 
(see lA, §7.3) whereupon4 we would quickly arrive at I-IV; then axiom V 
serves to distinguish the natural numbers among all the cardinal numbers: a 
cardinal number is a natural number if and only if it possesses every 
hereditary property that belongs to the number 1. 
Axiom V is called the axiom of induction, or the principle of complete 
(or mathematical) induction (on n) or also the argument from n to n + 1. 
The "complete" induction of mathematics is thus in sharp contrast with 
the "incomplete" induction of the experimental sciences, where a general 
law is derived from (finitely many) individual cases. This unfortunate 
choice of name must not be allowed to obscure the fact that in complete 
induction we are dealing with a deductive principle and not with the 
verification of a proposition A (x) for a finite number of x values; for in 
fact, in applying the principle, we are required to show that for an arbitrary 
2 Thus A(n) is the proposition that is formed when x is replaced by n. Strictly speaking, 
A(x) is a propositional form (see LA, §2.3). 
8 Any apparent inexactness is due to the brevity of these introductory remarks. 
A complete description of the operational method of introducing numbers can be 
found in P. Lorenzen [1]. See also LA, §10.6. 
, The number 1 is now the class of those sets that contain only one element; and if 
a is the class of sets that are equivalent to a given set M, its successor a' is the class of 
sets equivalent to M', where M' is formed from M by adjoining an element not yet in M. 

1 Construction of the System of Real Numbers 
95 
n the proposition A (n') ahrays follows from A (n), and such a proof can 
only depend on some general procedure, not on any special knowledge 
for a given number n. We refer to A (I) as the initial case, to the argument 
from A (n) to A (n') as the induction step, and to A (n) as the induction 
hypothesis. If N is the set of natural numbers, axiom V can also be 
expressed as a proposition about an arbitrary set M: 
If 1 E M and if n' E M follows from n E M for el'ery natural numher n, 
then N C M;5 for we may write any proposition A (x) in the form x E M, 
where M is the set of those elements x that have the property A (x). 
It should also be mentioned that the choice of axioms is to a great 
extent arbitrary; it is only necessary that they imply exactly the same 
consequences as can be deduced from I-V; that is, they must imply the 
axioms I-V and be implied by them. Instead of "one" and "successor" 
we may introduce other fundamental concepts, e.g., the ordering defined 
later in § 1.4 (the relation of "smaller than").5a 
In the lower grades at school the natural numbers occur in the form of 
cardinal numbers; in other words, the number 3 is introduced by abstraction 
from sets of three objects (persons, marks, points or the like). The essential 
identity of (finite) cardinal and ordinal numbers is brought out by arranging 
objects in rows. Addition arises as the mathematical expression for putting 
sets of objects together (forming their union) or by extending the rows of 
objects (this process is recognizable in the recursive definition of addition 
in §1.3). The other rules for calculating with natural numbers are based on 
addition. Further work with natural numbers depends on the familiar rules 
of calculation (commutative and associative laws of addition and multiplication, 
distributive law, monotone laws), which in the following pages are derived 
from axioms I-V but in early school years are learned by experience without 
any explicit formulation. Thus, in early instruction these rules play the role 
of axioms; much later, in the more advanced grades, they are supplemented 
by the principle of complete induction. 
1.2. 
Recursil'e Definitions 
In order that the sum of the numbers of elements in two disjoint finite 
sets (for these concepts see §I .5) may be equal to the number of elements 
in the union of the two sets, the following equations must obviously be 
satisfied: 
(1) 
(2) 
a + I = a', 
a + b' = (a + b)'. 
5 The notation M C M' means that x E M' follows from x EM but M i= M'. 
In this case M is called a proper subset of M', but in the case M C M' (that is, if equality 
is also possible) M is simply called a subset of M' (cf. lA, §7.2). 
Sa See, e.g., Feigl and Rohrbach [\]. 

96 
PART B ARITHMETIC AND ALGEBRA 
So we have the task of introducing for every a E N a function f which 
is defined in N and has the properties 
(3) 
f(l) = 0', 
f(x') = f(X)' 
for all 
x EN; 
for then we can simply define a + b asf(b). The fact that for every number 
a there exists exactly one function f with the properties (3) is a special 
case of the following general theorem: 
Let c be a number and let F be a function of two arguments defined in N 
and with values in N. Then there exists exactly one function f defined in N 
such that 
(4) 
f(l) = c, 
f(x') = F(x,f(x» 
for all x EN. 
It is clear that (3) is obtained from (4) by setting c = a' and F(x, y) = y'. 
The definition of a function f by the conditions (4), which is possible in 
view of the general theorem, is called a recursive definition, since the 
determination of f(x') is reduced to that of f(x) and thereby finally to that 
of f(I). 
To prove this theorem, which is also called the principle of recursion,7 
we first replace the concept of the function f by that of the set of pairs 
(x, y) with y = f(X).8 Then (4) requires the construction of a set P of 
pairs (x, y) with the properties 
(5) 
(I, c) E P; 
from (x, y) E P 
follows 
(x', F(x, y» E P. 
Here it will be prudent to take the smallest such set P, namely the set that 
is formed from the pair (1, c) by repeated application of the step from 
(x, y) to (x', F(x, y».9 In order to define a functionfby means of this set, 
we must prove that for every number x E N there exists exactly one 
number y with (x, y) E P. But by complete induction we see from (5) that 
such a y exists and is unique. For if we use (5) to construct the elements 
of P, we obtain, apart from the pair (I, c), only pairs of the form (x'. z), 
and thus, since x' "* 1, it follows from (I, y) E P that y = c. If we now 
assume the desired assertion for x, and if (x', Zl)' (x', Z2) E P, then 
Zl , Z2 must be of the form F(x, Yl), F(x, Y2), with (x, Yl), (x, Y2) E P, since 
7 The same name is given to certain generalizations of Eq. (4), one of which is con-
sidered on p. 97. 
8 In lA, §8.4, the functions were directly defined as such sets of pairs. But the concept 
of a function can also be defined in other ways, independently of the concept of a relation 
(see, e.g., Lorenzen [J]). 
II If we wish to proceed here on the basis of set theory, which is not altogether 
necessary, we will define P as the intersection of all sets P satisfying (5) and must then 
show, for example, that: if we had (x', z) E P, Z -=1= F(x, y) for all y, then the deletion 
of (x', z) from P would produce a set s~tisfying (5), in contradiction to the definition of P. 

1 Construction of the System of Real Numbers 
97 
otherwise the pairs could not be constructed; then Yl = Y2 by the induction 
hypothesis and therefore 
21 = F(x, Yl) = F(x, Y2) = 2 2 • Thus there 
exists a function/satisfying (4). 
In order to prove that this function / is unique, we now assume that g 
is a function satisfying (4), so that g(l) = c, g(x') = F(x, g(x». Then 
we have g(l) = /(1), and under the hypothesis that g(x) = f(x) we also 
have g(x') = F(x, g(x» = F(x,/(x» = /(x'). Thus by complete induction 
g(x) = f(x) for alI x E N, so that g = f 
From the proof we see that the theorem is valid under the following weaker 
hypothesis: the values for the second argument of F need not be numbers 
but may form an arbitrary set, quite independent of the values for the first 
argument: this set contains c and the values of F. Of course, we then obtain a 
function 1 whose values are no longer necessarily numbers but belong to the 
arbitrary set. 
Our principle of recursion can be made more general if we replace (4) by 
(4') 
[(I) = c, 
[(x') = Fx([(I), ... , [(x» 
for all 
x E N, 
where Fx is a function of x arguments for every natural number X.lO But this 
more general principle can be reduced to (4) by a simple transformation: 
namely, with the number x we associate the x-tuplell (/(1), ... ,/(x» and denote 
this mapping by 1 *, so that 
[*(x) = ([(I), ... ,/(x». 
It is clear that the function 1 is uniquely determined by 1*. Consequently, 
in order to show the existence and uniqueness of a function 1 satisfying (4') 
we need only transform (4') into conditions on 1* that are of the form (4) and 
are therefore satisfied by the mapping f*. For this purpose, in (4) we replace 1 
by 1* and c by the I-tuple (c) and define the function F as follows: 
for 
y = 
(Z1 , ••• , zn). 
Then 
F(x,[*(x» = [[(I), ... ,[(x), Fx(j'( I), ... ,/(x»], 
so that after these changes the conditions in (4) become identical with those 
of (4'), in view of the fact that 
f*(x') = (f( I), .'., /(x),/(x'». 
But now we must have recourse to the above-mentioned possibility of weakening 
the hypotheses in our original principle of recursion: the arbitrary set in question 
now consists of all n-tuples (Z1' ... , zn), where n is any natural number and 
the Z1 , ••• , Zn are no longer required to be numbers but only members of a set 
containing the arguments and the values of the functions Fx . 
10 For the concept of the number of elements of a set, see §1.5; in the formulation 
of (4') we naturally require the concept of a segment as defined in § 1.5. 
11 An x-tuple is a mapping of the segment Ax (see §1.5); thus the x-tuple in question 
is obtained by restricting the domain of [to Ax . 

98 
PART B ARITHMETIC AND ALGEBRA 
1.3. 
Addition 
By the principle of recursion and the remarks at the beginning of 
§1.2, there exists exactly one operation, to be denoted by +- and called 
addition, which is a function of two arguments, with arguments and 
values in N such that (1), (2) are satisfied for all a, bEN. In other words, 
(1), (2) constitute the recursive definition of addition.12 Addition is 
associative: 
(6) 
(a +- b) +- c = a +- (b +- c). 
The proof is based on the argument from c to c': (a +- b) +- 1 = 
(a +- b)' = a +- (b +- 1); if (6), then (a +- b) +- c' = «a +- b) +- c)' = 
(a +- (b +- c», = a +- (b +- c)' = a +- (b +- c'). Addition is also com-
mutative: 
(7) 
a+- b = b +- a. 
For b = 1 the proof is by the argument from a to a': 1 +- 1 = 1 +- 1; 
if 1 +- a = a+-l, then 1 +- a' = (1 +- a)' = (a +- 1)' = (a +- 1)' = 
(a +- 1) +- 1 = a' +- 1. The proof of the general assertion is by the 
argument from b to b' by means of (6) under the induction hypothesis 
of (7): 
a +- b' = (a +- b)' = (b +- a)' = b +- a' = b +- (a +- 1) 
= b +- 1 +- a) = (b +- 1) +- a = b' +- a. 
By (6) we may therefore omit the parentheses in a sum with three 
terms. In order to be able to omit them in sums with more than three 
terms, we first define the expression 1:f=1 ai for a given sequence13 
(ai)i=I.2 .... of numbers ai recursively by setting 
n+l 
n 
(8) 
L ai = L ai +- an+! ; 
i=1 
i=1 
for this purpose we need only set c = a1 and F(x, y) = y +- ax+! in (4). 
In particular, we have 1:~=1 ai = (al +- a2) +- a3 = a1 +- a2 +- a3 and 
1::=1 ai = (a1 +- a2 +- a3) +- a4, for which again we naturally write 
12 The recursive definition of addition, in particular (1) and (2), is suitable for in-
struction at the end of the secondary school, where it could be presented in a course 
on the axiomatization of the natural numbers. In such a course the proofs given in 
the present section would be appropriate examples. 
13 A sequence of this sort (infinite) is simply a function i -- ai, defined on N, whose 
values in this case are also in N. 

1 Construction of the System of Real Numbers 
99 
a1 + a2 + a3 + a4 • Moreover, no parentheses are needed to express 
addition of such sums, as is shown by the equation 
n 
m 
n+m 
(9) 
L ai + L an+i = L ai · 
i=1 
i=1 
i=1 
The proof of this equation is by the argument from m to m': for m = 1, 
Eq. (9) becomes the second of the equations in (8); and from (9) we see 
by (8) and (6) that 
n 
m' 
n 
m 
L ai + L an+i = L ai + ( L an+i + an+m,) 
i=1 
i=1 
i=1 
i=1 
= ( f ai + f a1H1 ) + an +m ' 
i=1 
i=1 
n+m 
(n+m)' 
n+m' 
= L ai + a(n+m)' = L ai = L ai' 
i=1 
i=1 
i=1 
We note that none of the properties of the numbers (except where they are 
used as indices) is needed here except property (6). The extension of (7) 
to sums of more than two terms will be proved in §1.5. 
We now prove by means of (9) that any meaningful expression A 
constructed from numbers ai' ... , ak (in this order), and from + signs 
and parentheses has a value, namely = 2::=1 ai , which is independent of the 
distribution of the parentheses (for k = 1 the expression A is to be taken 
equal to a1). For the proof we make use of induction on k in the altered 
form of §1.414 (with k instead of m and with M as the set of numbers k 
for which the assertion is true). By the construction of A there must exist 
natural numbers n, m with n + m = k (k "* 1) such that for expressions 
B, C formed from a1 , •.• , an and an +1 , ... , an+m under appropriate distribu-
tion of parentheses, we have the equation A = B + C. Since n, m < k, 
the induction hypothesis means that B = 
2:~=1 ai, C -== 2:~I~1 an+i' so 
that the desired assertion A = 
2::=1 ai , follows from (9). For k = I, the 
assertion is immediately obvious. 
If all aj = a, the sum 2:~=1 ai = 
2:~=1 a is called the nth multiple na of a. 
For this multiplication, (9) gives at once the distributire lalt' 
(10) 
na + ma = (11 + m) a. 
The commutative law for multiplication is dealt with in §1.5, and the 
14 This anticipation of theorems on order relations (which we have already used in 
speaking of "the numbers al , "', all") is permissible here, since the present result is 
not used in § 104. 

100 
PART B ARITHMETIC AND ALGEBRA 
associative law in §2.4. From (8), by the argument from n to n + 1 it 
follows directly that nl =' n. 
Finally, by the argument from c to c' we prove the rule: 
(11) 
a = b, 
if a + c = b + c. 
For by (1) the case c = 1 is already dealt with by axiom III; and from 
a + c' = b + c' it follows from (2) that (a + c)' = (b + c)' and 
therefore a + c = b + c; thus, by the induction hypothesis we have 
a = b, as desired. 
1.4. 
Order 
If for the numbers a, b there exists a number c with a + c = b, we 
write a < b (a isl ess than b), or alternatively b > a (b is greater than a).15 
For the relation < defined in this way we have the following theorems: 
(12) if a < b, then a *- b 
(13) if a < band b < c, then a < c 
(antireflexivity); 
(transitivity); 
(14) if a < b, then (a + d) < (b + d) (monotonicity oj aadition); 
(15) if a *- b, then a < b or b < a. 
Rule (12), which states that a + c *- a for all a, c, is proved by complete 
induction on a, for we have 1 + c *- 1 by (1), (7) and axiom IV; and 
if we had a' + c = a', it would follow that (a +- c)' = a', and thus 
a + c = a. For the proof of (13), (14) we set a + u = b, b + v = c and 
thus 
get 
c = (a + u) + v = a + (u + v), 
b + d = (a + u) + d = 
a + (u + d) = a + (d + u) = (a + d) + u. Complete induction on a 
is again used to prove (15), as fol1ows. The case a = 
] is first dealt with 
by complete induction16 on b: 1 = 1; 1 < ] + b = b + 1 = b'. Then from 
(15) (for all b) the same statement with a' instead of a (thus for all b: 
a' < b or a' = b or b < a') is derived by complete induction on b: 
1 < a'; a' < b' or a' = b' or b' < a' by (15) and (14); here again the 
induction hypothesis (a' < b or a' = b or b < a') is not used. 
From (12), (13) it is easy to see that no two of the statements 
a < b, a = b, b < a can be valid at the same time; thus in (15) we 'can 
insert the exclusive "either." With ~ as an abbreviation for" < or =" 
it follows that a ~ b is the negation of b < a. From 1 < a' we see, by 
complete induction16 on a, that 
(16) 
1 ~ a, 
15 Note that by numbers we here mean the natural numbers 1, 2, 3, ... , not including 
zero. 
18 In this case the induction hypothesis is not used at all, a fact which may make the 
proof somewhat harder to follow. 

1 Construction of the System of Real Numbers 
101 
and thus a < 1 is impossible for any number a. Also 
(17) 
a<b+I 
if and only if a::( b. 
For from a < b or a = b it follows by (13) that a < b + 1. 
On the other hand, if a + c = b + 1, it follows from (16) that we need 
consider only the cases c = 1 and c > 1 (that is, c = u + 1 for a certain 
u). In the first case we have a = b by (11), and in the second (a + u)' = b' 
and thus a + u = b, or a < b. 
From the principle of induction we can now derive the following 
modified principle of induction: If the number m is contained in the number 
set M whenever n E M for all numbers n < m, then M = N. The induction 
hypothesis now reads: "n E Ml for all numbers n < mil; and there is no 
special initial case. For the proof we consider the set M* of numbers m 
with n E M for all n < m. Then the hypothesis of our new principle 
simply states that M* C M. Since n < 1 is not valid for any number n, 
we get 1 E M*. By (17), any number n < m' is <m or =m. If we now 
assume that m E M*, then n lies in M not only in the first case but also, 
since M* E M, in the second case as well. Thus we have derived m' E M* 
from m E M*, so that by the argument from m to m' we have M* = N 
and thus also M = N. 
With the new principle of induction, it is very easy to prove the theorem 
of well-ordering of the natural numbers: every non-empty set of natural 
numbers contains a smallest number. For the proof we reformulate the 
assertion thus: if the set of numbers M contains the number n, then M 
contains a smallest number. If this statement is assumed for all numbers 
n < m and if m E M, then M contains a smallest number provided it 
contains a number <m. But otherwise m is itself the smallest number in 
M. As another method of proving the same theorem, we note that, 
if we replace M by the set N - M of the numbers not in M, our modified 
principle of induction can be transformed, by contraposition (see lA, §6.6) 
and other purely logical operations, into the desired theorem of well-
ordering of the natural numbers. 
The principle of induction can also be generalized to complete induction 
starting from k, as follows: 
If the set M contains the number k and if n' E M for every number n ~ k 
such that n E M, then M contains all the natural numbers ~k. 
For the proof we may assume k > 1. We set k = h + 1 and consider 
the mapping x -- x + h, which maps the set N into the set of natural 
numbers >h and thus ~k. The inverse mapping [which exists on account 
of (11)] takes M into a set for which we may prove, by the ordinary 
principle of induction, that it contains the set N. Thus M does in fact 

102 
PART B ARITHMETIC AND ALGEBRA 
contain all numbers ';?:-k. After we have introduced the integers (see the 
next section), this proof obviously holds for any arbitrary integer k. 
1.5. 
Segments 
The set of numbers ~n is called the segment An. By (12) and (13) 
we see that Am C An means the same as m < n. A set M (whose elements 
are not necessarily numbers) is said to be finite if it can be mapped 
one-to-one onto a segment An; that is, if there exists a one-to-one 
(invertible)17 mappingf of M ontol8 An . The number n is then uniquely 
determined and may therefore be called the number of elements in M. 
In order to prove the uniqueness of n, we consider a one-to-one mapping 
f of M onto An and also a one-to-one mapping g of M onto Am . By (15) 
there is no loss of generality in assuming m ~ n. If we carry out the 
inversion off and then the mapping g, we obviously obtain a one-to-one 
mapping of An onto the subset Am . Our assertion then follows from the 
theorem: 
A one-to-one mapping f of An into itselfl9 is a mapping onto An . 
We prove this theorem by the argument from n to n'. For n = 1 the 
assertion is clear, since I is the only element of Al . Now letfbe a one-to-
one mapping of An' into itself. If n' "* f(x) for all x ~ n, then f induces 
to a one-to-one mapping of An into itself, so that by the induction 
hypothesis f(An) = An. But then we can only have fen') = n', and 
consequently f(An') = An' . But if n' = f(k) for a number k ~ n, then 
by setting 
~f(x) 
g(x) = ~f(n') 
for k"* x ~ n 
for k = x 
we define a mapping g of An into itself, since fen') "* n' = f(k) follows 
from n' "* k. The one-to-one character of g follows easily from that off, 
so that by the induction hypothesis we have g(An) = An, and conse-
quently f(An') = An' . 
If a set M with n elements is mapped onto a set M' with m elements, 
then m ~ n, as is easily shown by complete induction on n. But if m < n, 
the mapping cannot be one-to-one; for a one-to-one mapping of M onto 
M' followed by a one-to-one mapping of M' onto Am would show that m 
is the number of elements of M. The application of this fact is often called 
the Dirichlet pigeonhole principle: the "pigeonholes" are the elements of 
M', into which the "objects" (namely the elements of M) are "inserted" 
17 "One-to-one" or "invertible" means: if f(x) = f(x*), then x = x*. (Cf. lA, §8.4.) 
18 "Onto" means: for YEAn there exists an x EM with Y = f(x). (Cf. LA, §8.4.) 
19 That is, the set f(An) of the images f(x) (x E An) is a subset of An . (Cf. lA, §8.4.) 

1 Construction of the System of Real Numbers 
103 
by the mapping; if there are more objects than pigeonholes, then at least 
one pigeonhole must contain two different objects. 
In general, two sets are said to be equira/ent (cf. lA, §7.3) ifeither of them 
can be mapped one-to-one onto the other. Thus the finite sets are defined 
as those sets that are equivalent to the segments All. For convenience, 
the empty set 0, which contains no element at all, is also said to be a 
finite set. In an infinite set M, namely a set which is not finite, it is easy to 
determine a subset which is equivalent to the set N of all natural numbers: 
for if f is a mapping which to each non-empty subset X of the set M 
assigns20 an element of f(X) of the subset X, the sets M 1 , M 2 , ••• 
can be defined recursively by Ml = {f(M)}, Mn' = Mn U {f(M -
Mn)}, 
and then the union of the Mll provides us with the desired subset N*. 
Thus, since x ----+ x + 1 is a one-to-one mapping of N onto a proper 
subset of N, there also exists a one-to-one mapping g of N*(CM) onto 
a proper subset of N*. I f each element of M -
N* is assigned to itself, 
the mapping g is thereby extended to a one-to-one mapping of M onto 
a proper subset of M. In view of the preceding theorem and the fact 
that 0 has no proper subset, we have the result: 21 
A set M is finite if and only if there exists no proper subset of 
M equivalent to M. 
As a counterpart to the above theorem on the mappings of An we 
prove: 
From f(An) = An itfollows that f is olle-to-olle. For x ~ 11 we determine 
the smallest number y with f(y) = x and denote by g the mapping of An 
into itself thus defined, so that we have y = g(x). From g(x) = g(x*) it 
follows that x = f(g(x» = f(g(x*» = x*, so that g is one-to-one and 
therefore g(An) = An (by the first theorem in §1.5). Thus for y with 
y* ~ n we can always find an x with x* ~ n such that y = g(x), 
y* = g(x*). Then f(y) = f(y*) implies x = f(y) = f(y*) = x* and thus 
y = y*. 
1.6. 
Commutativity in Sums with More Than Two Terms 
By making use of segments, we can now prove the commutative law, 
stated above in §1.3, for sums with more than two terms: for every one-to-
one mappingf of An onto itself we have 
n 
n 
(I 8) 
L a/(d = L ai . 
i=l 
i=l 
20 The existence of such a mapping follows from the axiom of choice in the theory 
of sets (see lA, §7.6). Here and below, MuM' denotes the union of the sets M, M' 
(that is, the set of elements which lie in M or M') and {a} denotes the set consisting of 
the element a alone (cf. lA, §7.2). 
21 Taken by Dedekind as the definition of "finite set." 

104 
PART B ARITHMETIC AND ALGEBRA 
The proof by induction on n will only be indicated here; we confine 
ourselves to the case22 f(k') = 11', k + h = n: 
n' 
If' 
h 
If 
h 
I af(i) = I afCi) + I afUe' +0 = I af(i) + an' + I af(k' +0 
i=l 
i=l 
i=l 
i=l 
i=l 
/; 
h 
I a.r(i) + I afU;,' +0 + an' 
i=l 
i=l 
11 
n 
n' 
I aflCi> + an' = I ai + an' = I ai , 
i=l 
i=l 
i=l 
where the one-to-one mapping g of An onto itself is defined by 
g(i) = f(i) 
for 
i ~ k, 
g(k + i) = f(k' + i) 
for 
i < h. 
For any finite index set 1"* 0, any sequence of numbers23 (ai)ief and 
any one-to-one mapping f of An onto I, it is easy to see from (18) 
that L7=1 af{i) does not depend on f but only on the given sequence, so 
that we can write this sum in the shorter form Lief ai . From (9) we have 
in this notation24 
(19) 
I ai + I ai = I ai , 
if I = /' u r, /' (\ r = 0. 
iel' 
ier 
ief 
For the case /' = 0 we define Lief' ai as 0, where 0 is the neutral element 
of addition (as defined below in §2.3); then it is obvious that (19) still 
holds. 
By complete induction on n we further obtain from (19) 
n 
(20) 
if I = U hand Ik (\ Ih = 0 for k "* h. 
k=l 
22 The casesf(1) = n' andf(n') = n' require only slight changes. 
28 That is, a mapping of I into N. The indices are not necessarily natural numbers; 
for example, we could also use pairs of numbers (i, k), in which case (provided there 
is no danger of misunderstanding) we may write aik instead of a(uc> , and correspond-
ingly for triples or n-tuples. 
In school one often introduces sequences without any mention of their connection 
with functions. But the concept of a function would be more clearly understood if 
infinite sequences were presented as mappings of N into N or into some set of numbers. 
2' M (1 M' denotes the intersection of the sets M, M', namely, the set of elements 
that belong to M and to M'; for the definition of v see footnote 20, page 103. (Cf. also 
lA, §7.2.) 

1 Construction of the System of Real Numbers 
105 
If for I we take the set of pairs (i, k) with i ~ m, k ~ n, and for h we 
first take the set of (i, k) with i ~ m, and then the set of (k, i) with i ~ n, 
we have 
n 
m 
m 
n 
(21) 
L L aik = L aik = L L aki . 
k=l i=l 
k=l i=l 
Setting aik = I gives us (in view of ml = m, nl = n) nm = mn, the 
commutative law of multiplication. Of course, this law could also be 
proved by complete induction (first on n with m = I and then on m) 
but its derivation from the general equation (21) is shorter and corre-
sponds exactly to the usual intuitive argument for the commutative law 
of multiplication: namely, the nm summands I are arranged in m lines 
and n columns and then added line by line. 
2. The Integers 
2.1. 
Properties Required in an Extension of the Concept of Number 
From now on the symbol a' will no longer be used, as in §I, to denote the 
successor of a, which will always be written in the form a + 1. If a, a' 
are arbitrary natural numbers, then in the case a ~ a' there exists no 
natural n umber x with 
(22) 
x + a' = a. 
But now we wish to proceed to a domain of numbers in which an equation 
(22) always has a solution. 25 Let us assume that we have already succeeded 
in finding an extension of the domain of natural numbers in which addition 
is defined in such a way as to satisfy the laws (6), (7), (11) and, when 
applied to the natural numbers, to agree with the addition already defined 
for them. Of course, it will be necessary to prove later that this assumption 
is justified. But first let us reflect a little on the properties that such an 
extended domain must have, since in this way we will obtain valuable 
hints for the construction of the domain. 
Whenever we extend a domain of numbers, here and in similar situations 
below, we shall always require that certain rules of calculation remain 
valid, a requirement called the principle of permanence. 26 But this label 
should not mislead us into thinking that the principle of permanence 
justifies once and for all the assumption that such extensions exist. 
Moreover, it fails to tell us which rules of calculation are to be "preserved." 
2S In school it is usual to begin with the requirement that the equation xa' = a has 
a solution. For this procedure see the end of §3.2. 
26 Often associated with the name of H. Hankel. 

106 
PART B ARITHMETIC AND ALGEBRA 
It merely confirms the fact of experience that, in making the extensions of 
the concept of number which from time to time have become necessary, 
mathematicians have found it convenient to preserve the most important 
rules of calculation; whether this is possible, and to what extent, must be 
investigated in each special case. The principle of permanence gives us 
only a very weak indication of how we ought to proceed, and it by no 
means deserves the key position it has often been given, without any 
logical justification. 
If we denote by27 a -
a' the solution of (22) in the extended domain, 
then 
(23) 
(a, 0') -+ a -
a' 
is a mapping of the set of all pairs of natural numbers onto the extended 
domain, and we must ask: when do two pairs (a, a'), (b, b') have the same 
image in this mapping? From the equations (a -
0') + a' = a and 
(b -
b') + b' = b, which characterize a -
a' and b -
b', it follows that 
(b -
b') + b' + a = b + (a -
a') + a', 
so that 
(24) 
a + b' = a' + b 
means the same as b -
b' = a -
a'. By (22) we must also set 
(25) 
c = (c + a') -
a'. 
Finally, we have 
a' + b' + (a -
a') + (b -
b') = a + b, 
and therefore 
(26) 
(a -
0') + (b -
b') = (a + b) -
(a' + b'). 
If now in the set of pairs we define addition by the (clearly associative 
and commutative) rule 
(a, a') + (b, b') = (a + b, a' + b') 
and denote the mapping (23) by J, we can write (26) in the form 
(27) 
f(A) + f(B) = f(A + B), 
where we have used capital letters for the pairs. 
27 This symbol is still completely at our disposal, since we have not used it before. 

Construction of the System of Real Numbers 
107 
A mapping f with the property (27) (for all elements A, B of the set 
of preimages, consisting here of all pairs of natural numbers) is called a 
homomorphism (with respect to addition). 
Concerning the homomorphism (23), we have the following fact, which 
can be expressed in terms of the natural numbers alone: the pairs 
A = (a, a'), B = (b, b') have the same image under f if and only if (24) 
holds. For (24) we also write A == B, since we shall see below that the 
relation == defined in this way has many properties in common with 
equality. 
2.2 
Construction of the Extended Domain 
After these preliminary remarks we can see that the first part of our 
task consists of constructing, together with its set of images, a homomor-
phism f of the set of pairs of natural n umbers in such a way that pairs A, B 
have the same image if and only if A == B, with == defined as above. The 
image of the pair A = (a, a') is created by simply setting between the 
numbers a, a' a horizontal stroke: a -
a'. For the moment this stroke, 
which is now introd uced for the first time, does not have the meaning 
of a minus sign, although it will naturally acquire that meaning later, 
when we have made the necessary definitions: at present a -
a' is nothing 
but a symbol formed from the two numbers a, a'.28 But now the real work 
begins, since the symbols a -
a' are completely useless until we have 
introd uced for them the concepts of equality and addition. 
These concepts must be introd uced in such a way that every statement 
about a -
a', b -
b', ... , formed with the symbols = 
and +, is an 
abbreviation for a statement about the natural numbers a, a', b, b', ... , and 
in view of the fact that we shall be interested only in statements that could 
finally be reduced to = and +, the new symbols are in principle super-
fluous, since they could be eliminated from every statement. But they 
provide us with a much more convenient notation, so that their use is to be 
recommended on practical grounds. 29 As statements about the new 
symbols a -
a', b -
b', ... we shall admit only statements about the 
natural numbers a, a', b, b', ... that remain unchanged in truth-value 
(cf. the corresponding remarks in §3.1) when the a -
a', b -
b', ... are 
28 It makes no difference here whether we regard the natural numbers as complicated 
logical expressions (sets of equivalent sets) or simply as symbols like: (see § 1.1). 
29 Of course, we could dispense with these new symbols altogether and work merely 
with the pairs (a, a'), which would then be called integers and for which we would 
introduce == as the new relation of equality. But then there is the difficulty that we 
would like to use the ordinary symbol of equality, introduced before for the natural 
numbers, for the integers also; for pairs this symbol has already been used in a different 
sense (see lA, §7.2). The use of classes of pairs of numbers instead of the symbols 
a - a' is discussed on p. 109. 

108 
PART B ARITHMETIC AND ALGEBRA 
replaced by any other symbols equal to them (in the sense of equality 
defined immediately below). 
It is to be noted that for the following developments we require only the 
properties (6), (7), (11) of the natural numbers and their addition. This fact 
will become important in §3.1, where the procedure described here is applied 
to mUltiplication instead of addition (with a/a' instead of a - a'), Since 
in that section we shall be introducing only pairs (a, a') with a' #- 0, we make 
the further remark here that in what follows (as can easily be seen from the 
proofs) the rule (11) is needed only for natural numbers c restricted to a proper 
subset C, provided that the pairs (a, a') are restricted to a' e C and for a', b' e C 
we have a' + b' e C; the only exception is the proof of the existence of the 
inverse element at the beginning of §2.3, where we must also require a e C. 
It is now clear how equality is to be defined, in view of the requirement 
that if f is the mapping (23), then f(A) = f(B) must mean the same as 
A == B. This requirement is met if we stipulate that a -
a' = b -
b' 
means the same as (24). But now, if we wish to calculate with the new 
concept of equality in the same way as with equality for natural numbers, 
we must show that the two fundamental rules for equality are satisfied: 
namely, every expression must be equal to itself (reflexivity); and if 
each of two expressions is equal to a third, they must be equal to each 
other (comparativity). For the relation ==, to which we have reduced our 
definition of equality, these fundamental rules mean that 
(28) 
(29) 
A == A; 
if A == C 
and 
B == C, 
then A == B. 
But (28) follows immediately from the fact that (24) holds for a = b, 
a' = b'. As for the proof of (29), we see that by adding b' to 
a + c' = a' + c and a' to b' + c = b + c' we obtain the equation 
a + b' + c' = a' + b + c', so that (24) now follows from (11). Only 
after (28) has been proved is it clear that (23) is actually a mapping: from 
(a, a') = (b, b') it follows that a -
a' = b -
b', 
We further note that from the definition of equality we have 
(a + d) -
(a' + d) = a -
a'. 
A relation == which satisfies (28) and (29) is called an equivalence 
relation (see also lA, §8.5). Such a relation is necessarily symmetric and 
transitive; for if C = A we see from (29) and (28) that B == A implies 
A == B; and if on the basis of this symmetry we replace B == C by 
C == Bin (29), we obtain the desired transitivity. From A == B, C ..::: A, 
and B == D we obtain C == D by a twofold application of transitivity. By 
symmetry and by the definition of eq uality this result can also be expressed 
in the form: A statement a -
a' = b -
b' is not changed in truth value 
if a -
a' and b -
b' are replaced by their eq uals c -
c' and d - d', 

Construction of the System of Real Numbers 
109 
If to every A we assign the set A of all X with X == A, then A = B means 
the same as A == Jj; for by (28) we have A E A, so that A = Jj immediately 
implies A == B; and conversely, if A == B, then X E A implies X E 13 by transitivity 
and X E Jj implies X E A by (29). Thus, instead of the a -
a' we could simply 
use the A, which are called residue30 classes with respect to the equivalence 
relation. A special definition of equality is no longer required, since we have 
already given a general definition for equality of sets (see lA, §7.2). 
Under certain systems of logic the latter possibility appears to be of essential 
importance, but this fact does not permit us to conclude that the integers 
must be considered as sets of pairs. In fact, our construction of the symbols 
a -
a' corresponds more closely to the way in which the integers are actually 
used in daily life; when faced with an expression like 2 -
3, we seldom think 
of the set of all pairs (x, x') such that (x, x') == (2, 3). Moreover, such a set 
of pairs of natural numbers is in no sense "more real" than our symbols: for 
this set of pairs can only be defined by the propositional form (x, x') == (2, 3), 
where the variables x, x' are quantified by some prefixed symbol (see lA, §7.7); 
in other words the set of pairs can only be defined by a symbol that is considerably 
more complicated than 2 -
3. The question "What is an integer?" has no 
absolute significance; it can be meaningfully asked only in the framework 
of a given system for the foundations of mathematics. The unconditionally 
meaningful question is: "How do we obtain mathematical objects that behave 
in such and such a way?" And to this question it is possible to give the most 
varied answers. 
In the domain of our new symbols a -
a', which henceforth we shall 
call integers, it is now our task to introduce addition in such a way that 
(27) is valid. At first glance (26) seems to constitute such a definition: 
(30) 
(a -
a') + (b -
b') = (a + b) -
(a' + b'). 
But the sum must actually depend only on the summands, whereas here 
it seems to depend on a, a', b, b'; in other words: equals added to equals 
must give equals, or expressed still otherwise: the truth value of (30) must 
not be altered if the numbers occurring there are replaced by other 
numbers equal to them. Thus we must prove that A == C, B == D always 
implies A + B == C + D;31 this condition, which alone makes the 
definition (30) useful, is called consistency of == with addition. For 
the proof it will be sufficient, on account of commutativity, to prove the 
simpler condition 
(31) 
A+B==C+B, 
if A == C; 
for then from B == D we will have C + B == C + D, and therefore, by 
transitivity, 
A + B == C + D. 
But 
now 
addition 
of b + b' 
to 
30 The name comes from the use of this concept in the theory of divisibility (lB5, 
§3.6 and IB6, §4.I). For general information on equivalence relations and their sets of 
residue classes, see IBIO, §1.5. 
31 Cf. lA, §S.5, and particularly IA (S.9). 

110 
PART B ARITHMETIC AND ALGEBRA 
a + c' = a' + c gives (a + b) + (c' + b') = (a' + b') + (c + b), which 
proves (31). The addition of integers defined by (30) is obviously commu-
tative and associative. 
Now we must see to it that certain integers are equal to natural numbers. 
To do this we define equality between integers and natural numbers, 
in accordance with (25), by setting:32 
(32) 
(c + a') -
a' = c, 
c = (c + a') -
a', 
with the stipulation that these equations, and only these, are to hold 
between natural numbers and integers. We must now verify that the two 
fundamental laws for equality are still valid. Reflexivity remains unaffected 
by (32), but for the comparativity "if a = y and fl = y, then a = fl," 
we must distinguish the various cases arising from the fact that each of the 
letters a, fl, y may represent either a natural number or an integer. Of the 
eight possible cases we no longer need to examine those in which a, fl, yare 
of the same kind. In view of the symmetry (32) of equality, we can also 
strike out those cases that arise from others if a is replaced by fl. Thus the 
following four cases remain: 
1. fl, yare the integers b -
b', c - c', and a is the natural number a. 
The assumption a = y can be satisfied only on the basis of (32) arid thus 
implies c = a + c'. Consequently, fl = y implies b +- c' = b' +- a + c' 
and also, by (11), b = b' + a, which finally, by (32), gives a = b -
b', 
and therefore a = fl. 
2. a, fl are the integers a - a', b -
b', and y is the natural number c. 
Then by (32), a = y, fl = y imply a = c + a', b = c +- b', from which 
follows a + b' = a' + b, and therefore a = fl. 
3. a, fl are the natural numbers a, b, and y is the integer c. Then a = y, 
fl = y imply by (32) that c = a + c', c = b + c', from which we see 
that a +- c' = b + c', so that finally, by (II), we have a = b and therefore 
a = fl. 
4. a, yare the natural numbers a, c, and fl is the integer b -
b'. Then 
by (32), fl = y implies b = c + b' and therefore, since a = y, we have 
b = a + b', which by (32) gives a = b -
b' and therefore a = fl. 
' 
Thus we may in fact consider the domain of the integers as an extension 
of the domain of the natural numbers, since every natural number is 
actually equal to an integer. But now a new difficulty arises: the sum of 
two natural numbers a, b can be determined in two different ways, namely, 
first as a + b and secondly as the integer «a + c) -
c) + «b + d) -
d). 
32 In (32) it is necessary to adjoin the second equation in order that equality may be 
symmetric. 

1 Construction of the System of Real Numbers 
111 
But by (30) the latter number is equal to (a + b + c + d) -
(c + d), and 
therefore again to a + b. Thus everything is in order. 
In the domain of the integers it is now true that every equation (22) has 
a solution, namely the integer a -
a': 
(a -
0') + a' = (a -
a') + «a' + c) - c) = (a + a' + c) - (a' --+-- c) = a. 
In §2.3 we shall see that addition of integers actually has the property (II). 
2.3. 
The Module o/the Integers 
_ 
From the definition of equality (24) for the integers it follows at once 
that all integers of the form a - a are equal. If for 1 -
I we introduce 
the abbreviation 0, then 
(33) 
a - a = 0, 
and therefore 0 + a = a for every natural number a. But this last result 
also holds for every integer a -
a'; for by (30) we have 
(a -
0') + 0 = (a -
0') + (I -
1) = (a + 1) -
(a' + 1) = a -
a'. 
Thus w~ have introduced the number zero and have established its most 
important property. From (30), (33) we also have 
(a -
a') + (a' -
a) = (a + a') -
(a' + a) = O. 
Now a given set, together with an operation defined in it (see IBIO, 
§1.2.2), is called a module33 if (the operation being denoted by +) the 
following conditions are satisfied: 
1. The operation is associative and commutative; i.e., we have the 
equations (a + fl) + y = a + (fl + y) and a + fl = fl + a for all ele-
ments a, fl, y of the set. 
2. There exists in the set a neutral element for the operation,. namely 
an element 0 with a + 0 = a for every element a of the set. 
3. For every element a of the set there exists an inverse element,34 
i.e., an element -a of the set with a + (-a) = O. 
The set is said to be a module with respect to the operation (which is here 
written as addition). 
33 Or also a commutative (or Abelian) group; (cf. IB2, §1.1). 
34 Or also simply an inverse; the name comes from the fact that the effect of adding 
-~ reverses that of adding 
~: (fJ + ~) + (-~) = fJ + (~ + (-~» = fJ. The con-
nection between the notation -~ and the use of the "minus" stroke in a -
a' will be 
explained later. 

112 
PART B ARITHMETIC AND ALGEBRA 
Consequently, the integers form a module under the operation of 
addition, namely, the module of integers. The following remarks are 
vaJid for every module;35 here we may, of course, keep in mind the module 
of integers that has just been constructed, but we must be careful not to 
make use of any of its properties that are not common to all modules, 
since we wish to apply our results to other modules. 
For given elements a, f3 in a module there exists exactly one element g 
with g + a = f3. 
g = g + 0 = g + (a + (-a)) = (g + a) + (-a) = f3 + (-a), 
so that at most one element g, namely f3 + (-a), can satisfy the equation; 
on the other hand, for g = f3 + (-a) we have 
g + a = (f3 + (-a) + a = f3 + « -a) + a) = f3 + 0 = f3. 
Thus rule (11) holds for every module: from a + y = f3 + Y it follows 
that a = (3. For the unique solution g = f3 + (-a) of the equation 
g + a = f3 we write f3 -
a, which agrees with the notation for the integers, 
since a -
a' is the solution of equation (22). Conversely, this abbreviation 
can be used to define the inverse: -a = 0 -
a (=0 + (-a). Thus the 
minus sign is used in two closely related senses; first in f3 -
a as a connec-
tive, i.e., as a notation for a function of two arguments; and second in 
-a for a function of one argument, namely the function which to each 
element assigns its inverse. 
From the uniqueness of the solution of g + a = f3 it also follows that 
-a is already completely determined by a and that the equation a + 
(-a) = 0 [as well as (-a) + a = 0] is established. Thus we have at once 
(34) 
-(-a) = a 
and also, since (a + (3) + « -(3) + (-a) = a + f3 + (-f3) + (-a) = 
a + 0 + (-a) = a + (-a) = 0, we may write36 
(35) 
-(a + (3) = (-f3) + (-a). 
Setting -f3 for f3 we have, by (34), 
(36) 
-( a -
(3) = f3 -
a. 
Let us now return to the integers. If a' < a, there exists a natural 
number b with a = a' + b, so that by (32) we have a -
a' = b and as 
86 In fact, for every group (cf. IB2, §2). 
86 The order of the summands on the right-hand side is so chosen that this result is 
obviously valid without the assumption of commutativity. 

1 Construction of the System of Real Numbers 
113 
a result we may simply say: a -
a' is a natural number. If a' = a, then 
a -
a' = 0, and in the only remaining case, namely a < a' [see (15)], 
it follows from (36) that a -
a' is the inverse -b of a natural number b. 
For natural numbers b, b' we have b "* 0, -b"* 0 (since b + 0 "* 0), 
and b "* -b' (since b + b' "* 0). Consequently, there exist exactly three 
kinds of integers: the natural numbers, zero, and the inverses of the 
natural numbers. The latter are called negative integers (or numbers of 
negative sign37) , and then, in contrast, the natural numbers are called 
positive integers. 
In view of the above remarks, it would also be possible to extend the set of 
natural numbers to the module of integers in the following way: For every 
natural number n we introduce a new symbol -n, and also the new symbol 0, 
for which -n = -m is defined as n = m and there are no other equalities 
except 0 = O. Addition is then defined as follows: 
0+0 = 0, 
0+ m = m + 0 = m, 
o + ( - n) = (- n) + 0 = - n, 
(-m) + (-n) = -(m + n), 
111 + (-n) = (--n) + m = k, 
with 
n + k = m 
for 
n < m, 
m + (-n) = (-n) + m = -k, 
with 
m+k=n 
for 
m < n, 
m + (-m) = (-m) + m = O. 
This procedure is conceptually much simpler but has two serious disadvantages: 
proofs of the rules for calculation must be divided up into many special cases 
and thus become much lengthier, and addition must be required to satisfy 
not only (6), (7), (11) but also (12), (15), which, in contrast to (13), (14), cannot 
be deduced 38 from (6), (7), (11) alone. 
2.4. 
Multiplication 
In order to define multiplication, we adopt a plan which may at first 
sight seem like a detour but has essential advantages over other methods.39 
Our task is to define multiplication of integers in such a way that it 
satisfies the distributive law and, in the subdomain of the natural numbers, 
agrees with multiplication as already defined. The distributive law 
a(x + y) = ax + ay will be regarded as a property of multiplication 
by a; that is, as a property of the mapping x ---+ ax. So let us first examine 
mappings with this property [see (38)]. We begin with a discussion of 
multiplication of the natural numbers from this point of view. 
37 But this terminology readily gives rise to the common error that -a (for an arbitrary 
integer a) is always a negative integer. 
38 Thus we cannot use this procedure in §3.1. 
39 Two other possible procedures are described on p. 119 (in small print). 

114 
PART B ARITHMETIC AND ALGEBRA 
By the distributive law (10) and the commutative law as proved in §1.6, 
the mappingf of the set of natural numbers into itself defined by 
(37) 
f(x) = ax 
has the property 
(38) 
f(x + y) = f(x) + f(y) 
and is therefore a homomorphism with respect to addition. Iff and g are 
two such homomorphisms, it follows from f(1) = g(1) that f(x) = g(x) 
holds for all natural numbers40 x, and thusf = g; for f(x) = g(x) implies, 
since (38) holds for g in place of J, that f(x + 1) = f(x) + f(1) = 
g(x) + g(1) = g(x + 1). Thus 
(39) 
f -. f(1) 
is a one-to-one mapping of the set of homomorphisms in question onto 
the set of natural numbers, so that in particular each of these homomor-
phisms has the form (37): 
(40) 
f(x) = f(1) x. 
Thus we have obtained a description of multiplication which is very 
suitable for extension to the domain of integers. In what follows, lower-
case italic letters will refer to arbitrary integers or, when the argument is 
applicable to modules in general, to arbitrary elements of a given module. 
Homomorphisms (with respect to addition) of a module M into itself 
are called endomorphisms of the module. Since we wish to use these 
endomorphisms, as suggested by (40), in defining multiplication for the 
module of integers, let us first examine in a general way the set of 
endomorphisms of a module. 
If f and g are endomorphisms of the module M" the mapping 
x -. f(x) + g(x) is also an endomorphism: for 
f(x + y) + g(x + y) = f(x) + f(y) + g(x) + g(y) 
= <f(x) + g(x) + <f(y) + f(y)· 
This mapping is called the sum f + g of the endomorphisms. We now 
show that with this definition of addition the endomorphisms themselves 
form a module. To begin with, associativity and commutativity are clear 
at once. The neutral element is the endomorphism x -. 0, which we 
denote by Q(f + Q)(x) = f(x) + Q(x) = f(x) + 0 = f(X).41 When there 
'0 No use is made here of the fact that [(x) and g(x) are natural numbers. 
U Of course, an expression like ([ + g)(x) does not denote any sort of product but 
rather the value of the function [ + g for the argument x. 

1 Construction of the System of Real Numbers 
115 
is no danger of confusion with the number 0, we may write 0 instead of Q. 
Finally, iff is an endomorphism, then by (35) the mapping x -- -f(x) 
is also an endomorphism, which is denoted by -f and is the inverse off: 
(f + (-f))(x) = f(x) + (-f)(x) = f(x) + (-f(x) = 0 = Q(x).n 
But now, given two endomorphisms, it is possible to define not only 
their addition but also another operation on them, namely, successive 
application: the mapping denoted 42 by fog and defined by 
(f 0 g)(x) = f(g(x) 
for alI 
x EM 
is again an endomorphism for given endomorphismsfand g; for we have 
(fo g)(x + y) = f(g(x + y» = f(g(x) + g(y) 
= f(g(x) + f(g(y) = (fo g) (x) 
+ (fo g)(x) + (fo g)(y). 
The operation 0 wiII be called multiplication. Like every case of successive 
application of two mappings (cf. 182, §1.2.5) this multiplication IS 
associative: 
«fo g) 0 h) (x) = (fo g)(h(x) = f[g(h(x)], 
(fo (g 0 h)(x) = f«g 0 h)(x) = f[g(h(x)] 
for all x and thus 
(f 0 g) 0 h = f 0 (g 0 h). 
But it also satisfies the tw043 distributive laws with respect to addition 
f 0 (g + h) = fog + f 0 h, 
(f + g) 0 h = f 0 h + g 0 h; 
since 
(fo (g + h)(x) = f«g + h) (x) = f(g(x) + h(x» 
= (fo g)(x) + (fo h)(x) = (fo g + fo h)(x), 
«f + g) 0 h)(x) = (f + g)(h(x) = (fo h)(x) + (g 0 h) (x) 
= (f 0 h + g 0 h)(x). 
42 The symbol [0 g may be read as "[ after g" or also "[times g." The small circle 
is often omitted but we will retain it here in order to emphasize the difference between 
this operation and the operation defined by ([g)(x) = [(x) g(x) in case a multiplication 
has been defined in the set of images. If, as is often done, we write the mapping to the 
right of the object to be mapped, namely, x[ or Xl instead of [(x), then the definition 
of successive application is changed, to the effect that [0 g denotes the application first 
of [and then of g [see 182, §1.2.5 (4)]. 
43 Since multiplication of endomorphisms of an arbitrary module is not necessarily 
commutative (the noncommutative linear mappings in 183, §2.2 are endomorph isms), 
these two laws must here be proved separately. 

116 
PART B ARITHMETIC AND ALGEBRA 
By a ring we mean a set of elements with a pair of operations that 
have the following properties: 
1. With respect to the first operation, called addition, the ring is a 
module. 
2. The second operation, called multiplication, obeys the associative 
law, and also the two distributive laws with respect to addition. 
Thus the above results on the endomorphisms of a module can be 
summarized in words: the set of endomorphisms of a module forms a ring 
with respect to addition and multiplication. This ring is called the ring of 
endomorphisms of the module. It has a neutral element for multiplication, 
namely the identity mapping x ---. x, which we shall denote by 1:44 
(10 f)(x) = I(f(x)} = f(x), 
(f 0 I)(x) = f(l(x)} = f(x). 
A neutral element for multiplication in a ring (there exists at most one 
such element; see IB5, §1.6) is called the unit element of the ring. 
Let us now return to the module of integers. The mapping (39) is seen 
to be a one-to-one mapping of the set of endomorphisms onto this module. 
For, as was proved at the beginning of this section, the equation 
f(x) = g(x) follows from f(1) = g(1) for all natural numbers x. But 
from (38) we have f(O) = f(O) + f(O), and thus f(O) = 0 and further 
f(x) + f( -x) = f(O) = 0; 
consequently, f( -x) = -f(x) and also 
g(O) = 0, g( -x) = -g(x), so that f(x) = g(x) holds for all integers. 
Thus the endomorphism f is already completely determined by the value 
of f(1): the mapping (39) is one-to-one and can therefore be inverted. 
The set of images in (39) or, in other words, the set of numbers f(1) 
for all endomorph isms f, includes the number 1 (as the image of 1 in I). 
If it includes f(1), it also includes f(1) + 1 = (f + 1)(1); therefore it 
includes all the natural numbers. In fact, 0 = Q(1) and -f(1) = (-f)(1); 
this set includes all the integers. Consequently, (39) is in fact a mapping 
onto the module of integers. 
Thus we may use\ (40) to define multiplication for all integers in such 
a way that for the domain of natural numbers it agrees with the multipli-
cation already defined at the beginning of this section: the product ax is 
defined as the image of x under that endomorphism which takes 1 into a. 
The rules for calculating with multiplication can now be obtained very 
simply from the properties of the ring of endomorph isms; since (39) is a 
homomorphism with respect to addition and multiplication, f + g 
becomes (f + g)(1) = f(1) + g(1) andfo g becomes (fo g)(1) = f(1) g(1). 
U If there is no danger of confusion with the number 1, we may also write 1 instead 
of I. 

1 Construction of the System of Real Numbers 
117 
Thus the associative law and the two distributive laws45 carryover to the 
integers: 
f(1)(g(1) h(1) = f(1)«g 0 h)(1) = (f 0 (g 0 h)(1) = «f 0 g) 0 h)(1) 
= «fo g)(1) h(1) = (f(1) g(1) h(1), 
(f(1) + g(1) h(1) = «f + g)(1) h(1) = «f + g) 0 h)(1) 
= (f 0 h + g 0 h)( I) 
= (fo h)(1) + (g 0 h)(1) = f(1) h(1) + g(1) h(1). 
Thus the integers form a ring with respect to addition and multiplication. 
Since by (39) the endomorphism / corresponds to the number I, this 
number I is the unit element of the ring of integers: 
If(1) = /(1)f(1) = (/0/)(1) = f(1)· 
f(1)1 = f(1) /(1) = (fo /)(1) = f(1)· 
By an isomorphism we mean a one-to-one homomorphism with respect 
to the operations in question (for a ring, addition and multiplication). 
Since (39) was shown to be one-to-one, we have the theorem: the mapping 
(39) is an isomorphism of the ring of endomorphisms of the module of 
integers onto the ring of integers. 
In order to prove the commutativity of multiplication, we must note 
that by the second distributive law x ----+ xa is an endomorphism: for in 
fact, the image (x + y)a = xa + ya of x + y is the sum of the images 
of x andy. Application of(40) to this endomorphism givesxa = (1a)x = ax, 
so that the ring of integers is a commutative ring. 
In an arbitrary ring (for which we denote multiplication in the same 
way as for the numbers) complete induction on n enables us to generalize 
the distributive laws to 
n 
n 
a L bi = L abi , 
i=1 
i=1 
from which we have 
m 
n 
L L aibk , 
i=1 k=1 
4S Because of the commutative law (to be proved later) only the second of the two 
distributive laws needs to be proved for the integers. In any case, the first distributive 
law is a simple consequence of (30) and (40). 

118 
PART B ARITHMETIC AND ALGEBRA 
and thus by (21) 
m 
n 
(41) 
L ai L bk = L aibk . 
i=1 
k=l 
l~i~m 
I~k~n 
By complete induction we readily obtain46 from (41) 
m 
nt 
m 
(41') 
n L aik = 
L n aikt; 
i=1 k=l 
l~kt~nt i-I 
(i=I •••• ,m) 
where the index set for the summation on the right-hand side is the set of 
m-tuples (kl , "', km ), with I :S; k i :S; ni (i = I, "', m). 
From the distributive law we further have 
a( e -
d) + ad = a « e -
d) + d) = ae, 
(a -
b)e + be = «a -
b) + b)e = ae 
and thus, 
(42) 
(42') 
a(e -
d) = ae -
ad, 
(a -
b)e = ae -
be. 
Replacing a by a -
b in (42), we see from (42') that 
(a -
b)(e -
d) = (a -
b)e -
(a -
b)d = ae -
be + (-(ad -
bd), 
and therefore by (36) and (35) 
(43) (a -
b)(e -
d) = ae -
be + bd -
ad = (ae + bd) -
(ad + be). 
Setting e = d and a = b in (42) and (42') respectively, we obtain 
aO = 0 = Oe, so that (42), (42'), (43) give 
(43') 
a(-d) = -ad, 
(-b)e = -be, 
(-b)( -d) = bd. 
In particular, we have -a = (-I)a = a( -I) if the ring has a unit 
element, which for simplicity we have here denoted by I. 
Since the product of two natural numbers is always a natural number, 
the equations (43'), when applied to the ring of integers, show that the 
product of a positive with a negative number is a negative number and 
that the product of two negative numbers is a positive number. But an 
'" The definition of a product of several factors is given at the beginning of §3.3. 

1 Construction of the System of Real Numbers 
119 
integer *0 is always either positive or negative; thus ab * 0, if a, b * 0; 
or in other words: 
!Jab = 0, 
then 
a = 0 
or b = O. 
A ring with this property is said to have no dirisors of zero. Thus the ring 
of integers is recognized as a commutative ring with unit element that has no 
divisors of zero. 47 
Of course, we could also define multiplication of integers by setting, from (43'), 
(-n)m = m( -n) = -mn, 
(-m)( -n) = mn, 
mO =-= Om = 0, 
(-n)O = O(-n) = 0, 
00 ~ 0, 
for the natural numbers m, n. But then the proof of the rules for calculation 
involves many special cases. 
Multiplication for the integers (in the form in which they have been introduced 
here) could also be defined by setting, from (43), 
(a, a')(b, b') = (ab + a'b', ab' + a'b) 
as a multiplication for the pairs of natural numbers and then transferring this 
multiplication to the integers by means of the mapping (a, a') -- a -
a'. 
Of course, it would then be necessary to show that mUltiplication of pairs is 
consistent with the equivalence relation 
="-c (of p. t07), but at least we would 
escape the disadvantage of having many special cases. 
In comparison with these two possibilities, the procedure adopted 
above has the advantage of being independent of the sequence in which 
the integers are introduced, and secondly of not assuming that multiplica-
tion of the natural numbers has already been defined; it is true that we used 
this multiplication to give us a hint (40) on how to proceed, but the 
subsequent proofs were independent of it.48 The endomorphisms by 
means of which we have introduced multiplication for the integers will be 
useful to us again in §4.6 for the mUltiplication of real numbers. Finally, 
let us remark that from a general point of view the concept of the ring of 
endomorph isms of a module is of great importance in algebra. 
2.5. 
Order 
For the time being we denote the set N of natural numbers by P. Then 
by what has been proved before we have 
O$P; 
47 A commutative ring without divisors of zero is also called an integral domain; cf. 
also IB5, §1.9. 
48 Except for the fact that the product of two natural numbers is again a natural 
number; but this fact could easily have been proved by complete induction on the basis 
of the definition (40) (see p. 116). 

120 
if 0 *- a ~ P, 
if 
if 
a, bE P, 
a, bEP, 
PART B ARITHMETIC AND ALGEBRA 
then 
-aEP; 
then a + bE P; 
then 
abE P. 
In general, in a module (with the operation +) a subset P with the 
properties (441- 3) is called a domain of positivity; in a ring a domain of 
positivity must satisfy the additional condition (444), From (441.3) it 
follows at once that a, -a E P is impossible. 
The ring of integers has the set N of natural numbers as its only domain 
of positivity. For -I E P would imply from (444) that 1 = (- 1)( - I) E P, 
which is inconsistent with -1 E P; thus, by (442) we have 1 = -(-1) E P. 
Then complete induction shows at once from (443) that N c: P. Now if 
there were an a E P with a ~ N, then [since a*-O by (441)] we would have 
-a E N, and thus -a E P, which is again impossible; thus we have 
proved that N = P. On the other hand, the module of integers has exactly 
one other domain of positivity; for by what we have just proved, the 
domain of positivity of the module must be equal to N if it includes 1, 
and otherwise it must include -I and therefore all the negative numbers, 
from which we conclude as before that it must coincide with the set of 
negative num bers. 
The existence of a domain of positivity P enables us to define an 
ordering in a module: for we may set a < b (or equivalently, b > a) if 
and only if b - a E P. For the module of integers with P = N this order 
obviously agrees with the order defined for the natural numbers in §1.4. 
Thus a module or ring with a domain of positivity is called an ordered 
module or ring. In an ordered module we can again prove (12)-(15): for 
(12) follows from (441) since a -
a = 0; and (13) from (443) since 
c -
a = (c -
b) + (b -
a); also (15) follows from (442) because of (36); 
and finally, (14) from (b + d) -
(a + d) = b + d -
d -
a = b -
a. 
Since a < b means the same as b -
aE P and b -
a = (-a) - (-b), 
it follows from a < b that -b < -a; in other words, in an ordered 
module the mapping x ---. -x [which by (35) is an endo'morphism) is 
monotone decreasing. In an ordered ring we also have, by (42') and (444), 
the monotonic law for multiplication:49 
(45) 
ac < bc, 
if a < b 
and 0 < c. 
Conversely, a module or a ring in which a relation < is defined becomes 
an ordered module or ring if the conditions (12) to (15) (and for a ring 
also (45)) are satisfied by the relation. For the proof of this statement we 
'" If the multiplication is not commutative, there is a second law of the same sort, 
with the factor c on the left. 

1 Construction of the System of Real Numbers 
121 
define P as the set of x with 0 < x. For then (441) follows from (12), and 
(442) is proved as follows: 0 '* a ~ P implies by (15) that a < 0, and thus 
by (14) we have 0 = a + (-a) < -a, and therefore -a E P. As for 
(443), we see that 0 < a, 0 < b imply by (14) that a < a + band 
consequently by (13) that 0 < a + b. Finally (444) is obtained from (45) 
with a = O. Since by (14) a < b means the same as 0 < b -
a, the relation 
< actually results in this way from P and is therefore the ordering that 
corresponds to the domain of positivity P. 
The assumption 0 < c in (45) is essential; for if c < 0, then 0 < -c, 
so that -ac = a( -c) < b( -c) = -bc and therefore bc < ac; of course 
for c = 0 we have ac = bc (=0). This argument shows that for c '* 0 
the endomorphism x -- xc of the module of integers (by §2.4 every 
endomorphism is of this form) is a monotone and therefore one-to-
one mapping50 (monotone increasing for c > 0 and monotone decreasing 
for c < 0), whereas for c = 0 the endomorphism is not one-to-one. 
A twofold application of the monotonic law (14) for addition shows that 
if a < band c < d, then a + c < b + c, b + c < b + d and therefore 
by (13) a + c < b + d; thus, inequalities of the same kind may be added. 
To obtain the same result for multiplication, we must make the additional 
assumption that b, c > 0 or a, d > 0; since otherwise (45) would not be 
applicable. 
3. The Rational Numbers 
3.1. 
Introduction of the Rational Numbers 
But now the integers are incomplete with respect to multiplication in the 
same way as the natural numbers were incomplete with respect to addition: 
not every equation xa' = a has a solution. However, multiplication is 
associative and commutative in exactly the same way as addition, and 
as a substitute for (11) we at least have: if ac = bc and c '* 0, then a = b, 
as follows from ac -
bc = (a -
b)c because of the absence of divisors 
of zero51 (see §2.4). By the remark in small print at the beginning of §2.2 
(for C we take the set of integers ,*0) these properties permit us to follow 
the construction given there for extending a domain, provided we restrict 
ourselves to pairs (a, a') with a' '* O. Instead of a -
a' we naturally use 
the symbol a/a' and replace addition by mUltiplication. Essential for our 
present purpose is the following fact: in the product (a, a')(b, b') = (ab, a' b'), 
defined in analogy with (30), the second number a' b' of the pair is also 
50 Of course, unless c = 1 or c = -1, not every integer wiII be an image in this 
mapping; we will have an isomorphism of the module onto a submodule. 
51 Consequently, the procedure we are about to describe may be carried out for any 
arbitrary commutative ring that has no divisors of zero. 

122 
PART B ARITHMETIC AND ALGEBRA 
*0 because of the absence of divisors of zero. For the rational numbers 
a/a' obtained in this way (they are also called fractions) the equation 
a/a' = bIb' means the same as ab' = a'b, so that in particular 
ac/a' c = a/a' for c * O. 
Just as for the integers in §2.2, we now admit as statements about the 
rational numbers a/a', bIb', ... only such statements about the integers 
a, a', b, b', ... as do not change their truth values when a/a', bIb' are 
replaced by rational numbers that are equal to them (in the sense of 
equality just defined). If, as is customary, we call a' the denominator of the 
symbol a/a', then the statement "a/a' has the denominator a'" is not an 
admissible statement about the rational numbers since, for example, 2/3 
has the denominator 3 but 4/6 does not. Of course, there is no serious 
objection to such statements, even though they are not "equality-invariant," 
provided we clearly understand their special position. But since it is 
possible to avoid them altogether in mathematics, we will find it safer 
and more convenient to exclude them on principle. If we do this, we can 
still speak about the denominator a' of the rational number a/a' if we 
assume, for example, that a' > 0, a * 0 and a, a' are relatively prime 
(see IB6, §2.6). 
On the other hand, it is customary to speak in school about the numerator 
and the denominator of a fraction a/a' even when a and a' have common factors. 
In this case (on account of the order in which the extensions are usually made in 
school) a and a' are natural numbers. Moreover, it is a common habit to say 
that fractions are equal only if they have the same numerator and the same 
denominator. In this terminology the fractions are actually the pairs of numbers 
(a, a').62 Then to obtain the rational numbers one says that the fractions a/a', 
bib' are equal in value if ab' = a'b. This equality of value is our equivalence 
relation (denoted by == in the analogous developments in §2.2). For the rational 
numbers one then uses the same symbol a/a' as for fractions, but equality is 
taken in the sense of equality of value. In contrast to our procedure, in which 
pairs of numbers are denoted by symbols different from those for rational 
numbers, the distinction between fractions and rational numbers is now taken 
into account only in the different concepts of equality. This procedure, which is 
permissible enough in itself, is obscured by the fact that only equality of value 
actually appears in the formulas, so that the symbol "=" always means equality 
of value, whereas the "original" equality of fractions (equality of numerator 
and denominator) occurs only in informal statements. Here again (in analogy 
with the use of residue classes or of the equivalence relation == mentioned 
on p. 109) we may consider a rational number as the set of fractions that are 
equal in value to a given fraction a/a'; then the rational number is represented 
by the fraction a/a' (or by any other fraction with the same value), and equality 
of value of fractions means exactly the same as equality of the rational numbers 
represented by them (in the sense of the definition of equality for sets; 
see lA, §7.2). 
62 See also Vogel [1]. 

Construction of the System of Real Numbers 
123 
The equations (32) now become ca'/a' = c, c = ca'/a', and we have 
(a/a')(b/b') = ab/a'b'. Instead of the 0 in §2.3 we obtain for any number 
a '* 0 the fraction a/a as the neutral element for the multiplication of 
rational numbers; but now, since a/a = I, this element is not a newly 
adjoined element but simply the number I, namely the unit element of 
the ring of integers. If a, a' '* 0, then a'/a is the inverse of a/a'; it is also 
written (a/a')-1 and is called the reciprocal of a/a'. Thus the rational 
numbers ,*0 form a module53 with respect to multiplication, and for 
given rational numbers a, fl with a '* 0 there exists exactly one rational 
number g with ga = fl. In agreement with our use up to now of the 
solidus /, this number is denoted by fl/a. In analogy with (34), (35), (36) 
we have the equations (a-1)-1 = a, (afl)-1 = fl-1a-1, (a/fl)-1 = fl/a for 
all a, fl '* O. 
It must be noted that the remarks at the end of §2.3 have no analogy 
in the theory of mUltiplication: it is not true that every noninteger is the 
reciprocal of an integer. The explanation is that at that time (end of §2.3) 
we made use of the properties (12), (13) of the relation <. In analogy with 
< we now define the relation I (to be read: factor of) in the domain of 
integers: a I b if and only if there exists an integer c with ac = b. Then 
the statements analogous to (13), (14) are valid: from a I b, b I c follows 
a I c; from a I b follows ad I bd. But in contrast to (12) we always have 
a I a, and in contrast to (15) neither 2 I 3 nor 2 = 3 nor 3 I 2.54 
3.2. 
The Field of Rational Numbers 
But how shall we define addition for the rational numbers introduced 
above? It is natural to lay down the following three requirements: when 
applied to the integers, the new addition gives the same results as the old; 
under the new addition the rational numbers form a module; and finally, 
multiplication is distributive with respect to addition. If we examine the 
equations ga' = a, 7]b' = b (where a, b are integers, and g, 7] are rational 
numbers), it follows from these requirements that: 
(g + 7]) a'b' = ab' + ba'. 
For the pairs A = (a, a'), B = (b, b') it will be natural in the present 
context (in contrast to §2.2) to define addition as follows: 
A + B = (ab' + a'b, a'b'). 
53 When speaking of multiplication, it is customary to use the term "commutative 
group" rather than "module." 
54 In the terminology introduced in lA, §8.3 the relation ~ is an ordering, whereas I is 
only a partial ordering, and even then only under the restriction to natural numbers 
(see IB6, §2.2). The relation I is defined in any commutative ring without divisors of 
zero (cf. IB5, §2.1). 

124 
PART B ARITHMETIC AND ALGEBRA 
This addition is applicable to all pairs and is commutative. In order to 
carry it over to the rational numbers by means of the mapping (a, a') -+ a/a' 
we must show, in accordance with the remarks in §2.2, that the equivalence 
relation == is consistent with it, where A == B now means ab' = a' h. 
To do this, we prove (31) with the new meaning of ==, namely that from 
A == C, or in other words from ae' = a' e, it follows that (ab' + a' b) b' e' 
= (eb' + e'b) a'b', so that A + B == C + B. After this proof of con-
sistency we may define addition of the rational numbers by 
(46) 
a/a' + bIb' = (ab' + a'b)/a'b'. 
Since a = a/I, the new addition agrees with the old for integers. 
Commutativity of the new addition is clear, and its associativity is easily 
shown as follows: 
(a/a' + bIb') + e/e' = (ab' + a'b)/a'b' + e/e' 
= (ab'e' + a'be' + a'b'e)/a'b'e', 
a/a' + (b/b' + e/e') = a/a' + (be' + b' e)/b' e' 
= (ab'e' + a'be' + a'b'e)/a'b'e'. 
Since a/a' + 0 = a/a' + O/a' = (a + O)/a' = a/a' and a/a' + (-a)/a' = 
(a + (-a)/a' = O/a' = 0, the rational numbers form a module with 
respect to addition. Furthermore, 
(a/a')(e/e') + (b/b')(e/e') = ae/a'e' + be/b'e' = (ab'e + a'be)e'/a'b'e'e' 
= (ab' + a'b)e/a'b'e' = (a/a' + b/b')(e/e'). 
Consequently, the distributive law holds and therefore the rational 
numbers form a commutative ring with respect to addition and multi-
plication. But this ring has the special property that the nonzero elements 
in it form a module with respect to multiplication, so that every equation 
ga = fl (a "* 0) has a solution. 
Now afield is defined as a ring with the following properties: 
1. For arbitrary elements a, fl of the ring with a "* 0, there exists an 
element g in the ring with ga = fl. 
2. Multiplication is commutative. 
Thus by what has just been proved the rational numbers form a field, the 
field of rational numbers. The only property of the integers used in the 
construction of this field is that they form a commutative ring without 
divisors of zero. 55 Every such ring R can therefore be extended to a field 
66 The occasional use of the unit element 1 in the ring of integers could easily have 
been avoided. 

1 Construction of the System of Real Numbers 
125 
that consists, as in the case of the rational numbers, of the symbols a/a' 
with a, a' E R, a' "* 0; here the a/a' are called quotients and the field is 
called the quotient field of R. A field cannot have divisors of zero, since it 
follows from af3 = 0 and a"* 0 that f3 = (a-1a)f3 = a-l (af3) = a-10 = O. 
We could have obtained the field of rational numbers by introducing 
subtraction and division in the opposite order; beginning with the natural 
numbers we would then have defined the positive rational numbers (cf. §3.4) 
in the form a/a' (a, a' being natural numbers); in this domain we would introduce 
addition as before and then apply to it the procedure which led from the natural 
numbers to the integers. In this case the rational numbers appear in the 
form a/a' - bib'. 
Our chief reason for not adopting this procedure is that then the ring of 
integers, which is of great importance in algebra, does not appear as an inter-
mediate stage. Of course, such an objection does not mean that the procedure 
may not be otherwise convenient. For example, it is usually adopted in school. 
3.3. 
Powers 
In the present section, except where otherwise mentioned, lower-case 
italicized letters denote the elements of an arbitrary field. 56 With multi-
plication in place of addition and f1 in place of L we can again use the 
definition (8): 
n+l 
n 
n ai = (n ai) an+! 
(n a natural number). 
i-I 
i-I 
Since the properties of addition used in §1.3 also hold for multiplication, 
we have the result corresponding to (9): 
n 
m 
n+m 
n ai n an+i = n ai (n, m natural numbers). 
i=l 
i-I 
i=l 
Now we shall call f1~=1 a the nth power an of a. From (10) we have for 
natural m, n 
(47) 
We may also take over (18) and thus introduce flier ai. Corresponding 
to (21) we get the equation 
n 
m 
m 
n 
(48) n n aik = n aik = n n aik (m, n natural numbers). 
k=l i-I 
i.;;;m 
i-I k-l 
k';;;n 
58 As far as positive exponents are concerned, the developments are valid in an 
arbitrary commutative ring, or even in an arbitrary (multiplicatively written) Abelian 
group, where commutativity is needed only for the proof of (48) and (50). 

126 
PART B ARITHMETIC AND ALGEBRA 
With aik = a we have 
(49) 
(m, n natural numbers) 
since from (21), with aZ·k = I, there exist exactly mn pairs of natural 
numbers (i, k) with i ~ m, k ~ n. For m = 2 and a1k = a, a2k = b we 
have from (48) 
(50) 
This definition of a power is now extended by the convention aO = I, 
where it is often assumed that a "* O. The value of aO for a "* 0 must be 
defined in exactly this way if (47) is to remain valid: namely, alaO = a1 and 
thus aao = a. Then it is easy to show by calculation that not only (47) but also 
(49), (50) hold for all integers m, n ~ O. If we wish to define a-n for every 
natural number n in such a way that (47) remains valid, we must have 
ana-n = aO = I, which shows that a "* 0 is a necessary restriction. Thus 
a-n = (an)-1 for every natural number n > I; and of course this equation 
also holds for n = I. In the proof of (47) for this extended case we may 
restrict ourselves, on account of the commutativity of multiplication and 
addition, to replacing n by -no For every nonnegative integer m we then 
obtain 
for m > n, 
for m = n, 
for 
m < n; 
for we have am-nan = am for m > nand an-mam = an for m < n. 
Since for natural numbers m, n we also have a-na-m = (an)-1 (am)-1 = 
(an+m)-1 = a-(n+m) = a(-n)+(-m), we see that (47) has now been proved 
for arbitrary exponents. In order to make the corresponding extension of 
(49), we need the rule 
(n a natural number), . 
which follows at once from the equation (a-1)n an = I [see (50)]. For 
natural numbers m, n we now obtain 
(a-m)n = «am)-I)n = «am)n)-1 = (amn)-1 = a-mn = a(-m)n, 
(am)-n = «am)n)-1 = (amn)-1 = a-mn = am(-n), 
(a-m)-n = «(am)-I)n)-1 = «(am)n)-I)-1 = (am)n = amn = a(-m)(-n). 
Finally, it is also easy to prove (50) for negative exponents: 

1 Construction of the System of Real Numbers 
127 
3.4. 
Order 
With a view to extending the ordering of the integers to the rational 
numbers, let us first examine the properties which a domain of positivity 
P of the field of rational numbers must have, in case such a domain 
exists. The set of integers contained in P is obviously a domain of positivity 
for the ring of integers, so that in particular N C P. But from (442 •4 ) and 
a2 = (-a)2 it follows that a domain of positivity of a ring must contain 
all squares *0. Thus for a, bEN it follows from a/b = ab(b-1)2 that 
a/b E P. But if P contained a rational number that is not of this form, 
then by (441) it would also contain natural numbers a, b with (-a)/b E P, 
which contradicts (443), since a/b + (-a)/b = ° 
$ P and a/b E P. Thus P 
consists precisely of the quotients of natural numbers. But these quotients 
do in fact form a domain of positivity, since a rational number *0 which 
is distinct from these quotients has the form (--a)/b (a, bEN), which 
means that (442) is valid, while (441.3.4) obviously hold. Thus the field of 
rational numbers can be ordered in exactly one way. Since 
b/b' -
a/a' = b/b' + (-a)/a' = (ba' + b'( -a»/a'b' = (ba' -
b'a)/a'b', 
we have for integers a, a', b, b': a/a' < b/b' for a', b' > 0, if and only if 
ab' < a'b. Since c > ° implies c-1 = C(C-1)2 > ° for every rational 
number c, this result can easily be extended by (45) to arbitrary rational 
numbers a, a', b, b'. 
The ordering of the rational numbers is Archimedean; that is, for every 
a, b > ° 
there exists a natural number n with na > b. 57 For the proof we 
first restrict ourselves to integers a, b. Then from b + I > b and a ~ I 
it follows by the monotonic law that (b + I)a > ba ~ b I = b, so that 
na > b with n = b + 1. But then for the rational numbers a/a', b/b' > ° 
(a, a', b, b' natural numbers) we have a/a' = ab'/a'b', b/b' = a'b/a'b', so 
that if we choose a natural number n with nab' > a'b, it follows by 
multiplication with the positive number (a'b')-1 that n(a/a') > bib', as 
desired. In an arbitrary module, which may not contain the natural 
numbers, we can always define na as being equal to L~=1 a, so that the 
definition of "Archimedean" is applicable to any ordered module. At the 
end of §4.3 we give an example of an ordered module in which the ordering 
is not Archimedean. 
The ordering of a field 58 is Archimedean if and only if ° 
~ a < n-I, 
for all natural numbers n implies a = 0. For if a > ° 
in an Archimedean 
57 This statement is often called the "axiom of Archimedes" since it occurs as an 
axiom in geometry (cf. lI2, §1.2). 
58 If the field does not contain the natural numbers, then in the following inequality 
(and in the proof) the natural number n must be replaced by the nth multiple of the unit 
element 1 of the field. 

128 
PART B ARITHMETIC AND ALGEBRA 
ordering, then there exists a natural number n with na > 1, so that 
a > n-1• The same argument obviously holds for an ordered ring that 
contains n-1 for every natural number n. Conversely, if ° 
~ a ~ n-1 
implies a = 0, and if a, b > 0, so that alb > 0, then the inequality 
na ~ b cannot hold for every natural number n, since it would imply 
alb ~ n-1• 
The absolute value 1 a 1 of the rational number a is defined as follows: 
(51) 
1 a 1 = max(a, -a); 
where by max(a, b) we mean the number b if a < b and the number a if 
a ~ b. Thus 1 a 1 = a or = -a and 1 a 1 ~ 0, and these properties 
obviously characterize the number 1 a I. Then we can at once derive 
(52) 
1 ab 1 = 1 all b I. 
Since ±a ~ 1 a 1 for all a, we have ± (a + b) ~ 1 a 1 + 1 bland therefore 
(53) 
1 a + b 1 ~ 1 a 1 + 1 b I. 
Replacingbby-b,wesee,sincel-b 1 = 1 b I,thatl a -
b 1 ~ 1 a 1 + 1 b I, 
and if we replace a -
b by a, and a by a + b, we have 
1 a 1 ~ 1 a + b 1 + I b /, 
and therefore 
1 a 1 -
1 b 1 ~ 1 a + b I. 
Since the right-hand side is not altered by the interchange of a and b, 
it follows that 
(54) 
\Ial-Ibl\ ~ la+bl· 
As in (53), we may replace a + b by a-b. Of course, the definition (51) 
of absolute value, and with it the consequences (52), (53), (54), are valid 
for any ordered ring. 
3.5. 
Endomorphisms 
In view of the distributive law, the mapping x -+ ex for any rational 
number e is an endomorphism of the module (with respect to addition) 
of the rational numbers. As in §2.4, we can show that for two endomor-
ph isms f, g of this module, the equality f(1) = g(1) implies f(x) = g(x) 
for all integers. From (38) it is easy to prove frE.:=1 Xi) = L~=lf(Xi) by 
complete induction. Thus for a rational a/a' (a, a' integers, a' > 0) and 
two endomorphismsf, g withf(I) = g(l) we have: 
a' 
o'/(a/o') = L /(a/a') = /(a'(a/o'» = /(a) = g(a) = a'g(a/a'). 
i=1 

1 Construction of the System of Real Numbers 
129 
But then it follows that I(a/a') = g(a/a'), so that an endomorphism 1 
is completely determined by the value of 1(1). Since the image of 1 under 
the endomorphism x -+ cx is the number c, the mapping 1 -+/(1) is a 
one-to-one mapping of the ring of endomorphisms onto the field of rational 
numbers. In fact, this mapping is even an isomorphism, as can be proved in 
exactly the same way as the corresponding statement in §2.4. As in the 
corresponding case for the integers, the ring of endomorphisms of the 
additive module of the rational numbers is isomorphic to the field of 
rational numbers. 
Furthermore, as in §2.5, the endomorphisms *0 are monotone 
mappings: x -+ cx is monotone increasing for c > 0 and monotone 
decreasing for c < O. 
It is obvious that the endomorphism x -+ cx is also a homomorphism 
with respect to mUltiplication if and only if c(x, y) = (cx)(cy) for all 
x, y, or in other words, if and only if c2 = c. But in view of the absence of 
divisors of zero, the equation c2 -
c = c(c -
1) shows that c2 = conly 
for c = 0 or c = 1. Thus the field of rational numbers has exactly two 
homomorphisms (with respect to addition and multiplication) into 
itself, namely the zero mapping x -+ 0 and the identity mapping x -+ x. 
4. The Real Numbers 
4.1. 
Decimal Fractions 
In the present section we denote by g a fixed integer g > 1, which we 
caIl a base. For any given positive rational number r we now use g to 
determine59 the sequence of integers an (n = 0, 1, 2, ... ) by recursion in 
the following way: ao is the greatest integer ~r; an+1 (n ~ 0) is the greatest 
integer ~(r - L?=o aig-i) gn+1. With the abbreviation rn = L?=o aig-i, 
we then have an+! ~ (r - r n) gn+1 < an+1 + 1, an+1g-<n+l) = r n+1 -
r n 
and consequently (with n in place of n + 1) 
(55) 
(n = 0, 1,2, ... ). 
It follows that 0 ~ r -
rn < g-n and thus 0 ~ an+1 < g, so that 
o ~ On < g (n = 1,2, ... ). In view of (55) we can also describe rn as the 
greatest integral multiple of g-n which is ~r. The sequence of the an 
determines r uniquely; for if (55) holds for r' as well as for r, then 
- g-n < r -
r' < g-n 
for all natural numbers n. 
59 The principle of recursion at the end of §1.2 shows that the function n -
an is 
uniquely determined by the above requirements; the fact that in the present case n may 
take the value 0 represents only an insignificant change from §1.2. 

130 
PART B ARITHMETIC AND ALGEBRA 
Since g -
1 > 0, we have by the binomial theorem (see IB4, §1.3) 
gn = (l + (g -
1)n > n (g -
1) 
and thus g-n < (g -
1)-1 n-1 < n-l, so that no positive number can be 
~g-n for all natural numbers n. Thus r' < r or r < r' would lead to a 
contradiction, so that we must have r' = r. 
In accordance with the usual practice for the base 10 we write the 
sequence of the an in the form aO.a1a2aa ... and call it an infinite decimal. 60 
Since this sequence can be regarded as a complete substitute for the number 
r, we write 
(56) 
But we now encounter the following extremely significant fact: although 
every rational number gives rise in this way to an infinite sequence of 
nonnegative integers <g, it is not true that every such sequence can be 
obtained from some rational number (for an example see §4.8). In order 
to extend the field of rational numbers, it therefore seems appropriate to 
consider all infinite sequences of nonnegative integers an(n = 0, 1,2, ... ) 
with an < g for n > 0; these sequences are to be taken as the elements of a 
domain of numbers which in view of (56) contain61 the rational numbers 
~O. Then for these new numbers we must define equality, order, and 
addition in such a way that when applied to the rational numbers in 
accordance with (56) they will yield the same results as the corresponding 
concepts already defined for rational numbers. For the definition of 
equality it is natural to set 
if and only if On = bn for all n = 0, 1,2, .... As an ordering we take the 
natural lexicographic ordering:62 aO.a1a2aa ... < bo.b1b2ba ... if and only 
if there exists a nonnegative integer n with ai = bi for "all i < nand 
an < bn . The definition of addition is necessarily somewhat lengthy, 
80 Of course, from the etymological point of view the word "decimal" ought to be 
replaced by some other word corresponding to the value of g; for g = 2 the phrase 
dyadic fractions is also used. 
III For brevity we restrict ourselves here to the numbers;> O. For a negative number r 
we define the an as the numbers corresponding to -r in the above procedure and then 
we set r = -(aO.ala:aaa ... ). 
82 So-called because the words in a lexicon are arranged by this principle; the letters 
in alphabetic order correspond here to the nonnegative numbers in the order introduced 
above. Of course, lexicons do not normally contain words with infinitely many letters. 

1 Construction of the System of Real Numbers 
131 
so that we shall content ourselves here with defining the sum 
aO.a1a2aa ... +- g-k = bo.b1b2ba ... : 
If a
k "* g -
I 
or k = 0, 
we set 
bn = an 
for n"* k, 
bk = ak +- I, 
but if an = g -
I, then for h < n ~ k and (if h > 0) ah "* g -
I, we set 
for n < h 
and n > k, 
bn = 0 
for h < n ~ k, 
bh = ah +- 1. 
One reason for choosing this definition is that for infinite decimals (56) 
that are equal to rational numbers it is a readily provable rule. 
But now there is a difficulty. In the case an = g -
I for n > k, 
ak "* g -
I or k = 0 our definitions (of order and addition) give for all 
n >k: 
k 
aO.a1a2aa ... +- g-n L aig-i +- g-k = ao , a1 ••• ak- 1(ak +- 1)000 '" . 
i=O 
If the monotonic law is to hold for addition and if subtraction is to be 
possible (for the case when the subtrahend is smaller than the minuend), 
we have the following inequality (cf. the calculation given above) for the 
difference d = L:=o aig-i +- g-k -
ao • a1a2aa ... : 
d < g-n < (g -
I)-I n-1 
for all n > k. 
Butd > O,sothatthereexists a positive rational number <d < (g -
l)-n n-1 
for all n > k, in contradiction to the fact that the ordering of the rational 
numbers is Archimedean. The solution of the difficulty lies, of course, in 
excluding the sequences with On = g -
I for all n > k. In fact, such 
sequences do not occur in the decimal expansions of rational numbers. 
For if an = g -
I for all n > k, it follows that 
n 
n-k-l 
'n -
'k = (g -
I) L g-i = (g -
I) g-n L gh 
i=k+l 
h=O 
= g-n(gn-k _ I) = g-k _ g-n, 
so that'n +- g-n = 'k +- g-k; but then from (55) we would have 
o < ('k +- g-k) - , ~ g-n < (g -
I)-I n-1 
for all n > k 
in contradiction to the fact that the ordering of the rational numbers is 
Archimedean. 

132 
PART B ARITHMETIC AND ALGEBRA 
In this way the real numb~rs can be introduced as infinite decimals, 
and it can be shown that they do in fact form an ordered module (with 
Archimedean ordering) that includes the module of the rational numbers. 
Let us now consider the following theorem, which is of basic importance 
in analysis: every non-empty set of real numbers which is bounded below63 
has an infimum, or greatest lower bound. This theorem is now very easy to 
prove. For by the addition of a sufficiently large number (namely -s, 
if s is a negative lower bound) the set M becomes a set of nonnegative 
numbers, and then rn is defined, in accordance with (55), as that integral 
multiple of g-n with rn ~ x for all x E M such that there exists a number 
x E M with x < rn + g-n. As in (55), there then exist integers 
an (n = 0, 1,2, ... ) with rn = L~=o aig-i and 0 ~ On < g (n = 1,2, ... ). 
From rn ~ x < rk + g-k it then follows as before that On = g -
1 for 
n > k is impossible, so that aO.a1a2a3 ••• is actually a real number, which 
is easily recognized as the greatest lower bound of M. 
4.2. 
A Survey of Various Possible Procedures 
From the point of view of practical calculation the introduction of the real 
numbers by means of decimal expansions as described above in §4.1 is very 
natural and has the advantage that the concepts involved in it are relatively 
simple. A further advantage is that if we use decimal expansions, we can 
introduce the real numbers immediately after adjoining zero to the natural 
numbers without first introducing the integers and then the rational 
numbers.64 It is convenient to introduce only the nonnegative real numbers 
at first and then to apply to them the method of extension described in 
§2.3. 
But these advantages are obtained at high cost; addition can only be 
defined in a very lengthy waY,65 and the rules for calculation are not very 
convenient to prove. These disadvantages obviously arise from the special 
form of the rn. In order to avoid them, it will be convenient to replace 
these rn by more general entities, for which we shall naturally wish to 
preserve certain properties of the rn. To do this we may start from either 
of two facts: 
1) aO·a1a2a3 ••• is the least upper bound of the set of rn . 
2) aO.a1a2a3 ••• is the limit of the sequence of rn; for we have 
83 A non-empty set that is bounded above can be reduced to the present case by the 
mapping x -
-x and is thus shown to have a supremum, or least upper bound. 
84 Since the intermediate stages will be important to us later, we have not followed 
this plan here. 
86 To say nothing of multiplication, which we shall discuss in a separate section. 
See, for example, F. A. Behrend, A contribution to the theory of magnitudes and the 
foundations of analysis, Math. Zeitschr. 63, 345-362 (1956). 

1 Construction of the System of Real Numbers 
133 
o ~ aO.a1a2a3 ... -rn < g-n < (g -
1)-1 n-1, and for every real number 
£ > 0 we can find a natural number no with no(g -
1) ~ £-1, where-
upon I aO.a1a2a3 ... -rn I < £ for all n ~ no. 
The first of these two facts suggests that, in a completely general way, 
we may take as our starting point all non-empty sets of rational numbers 
bounded from above.66 This procedure, discussed in §4.3, is essentially 
the method of Dedekind for defining the real numbers by Dedekind cuts. 
It has the advantage that it defines the real numbers and their order without 
making any use of addition, so that it can be applied to more general 
systems in which only an order is defined.67 
On the other hand, the second of the above listed facts is used as our 
starting point in §4.4 to introduce the real numbers by means of the 
fundamental sequences of Cantor; that is, sequences of rational numbers 
which satisfy the Cauchy criterion for convergence. Since the definition 
of this quite general class of sequences does not require the ordering of the 
rational numbers but only of their absolute values, it too can be extended 
to a more general class of modules than the ordered ones.68 In this case, 
however, the addition of rational numbers is already employed in the very 
definition of real numbers. 
The ~ntroduction of the real numbers by means of nested intervals is to 
a certain extent a mixed procedure. Here we employ pairs of sequences 
of rational numbers (an)n=1.2 .... ' (a~)n=1.2 .... with an ~ an+! ~ a:n+l ~ a:n 
for all m, nand limn .... oo(a' -
an) = 0.69 Since both order and addition 
are required here, the usefulness of this procedure for more general 
systems is considerably reduced, so that we shall not deal with it in detail 
in the following sections but shall content ourselves with the following 
remarks. The nests of intervals ex and f3 arising from the pairs of sequences 
with terms an , a~ and b" , b~ are said to be equal if and only if for every 
index pair m, n there exists a rational number x with am ~ x ~ a:n , 
bn ~ X ~ b~. The number ex is set equal to the rational number r if 
an ~ r ~ a~ for all n. By the sum ex + fl we mean the nest of intervals 
defined by the sequences (an + bn)n=1.2 .... , (a~ + b~)n-1.2 .... , where it 
remains to be proved that when equality is defined as above, this sum 
depends only on ex, fl. If we add to ex the nest of intervals defined by the 
sequences with terms -a~ , -On the sum is equal to the rational number 
0, which is easily seen to be a neutral element for the addition defined 
88 Of course, we could just as well consider the non-empty sets bounded from below. 
67 To a certain extent (see §4.3) we only require a partial order. 
88 See, for example, van der Waerden [2], §§74, 75. In topology the same procedure 
is followed with even greater generality for metric spaces. 
89 Here an and a~ are regarded as the endpoints of an interval, which may reduce to 
a single point. Such intervals are said to be nested within one another. 

134 
PART B ARITHMETIC AND ALGEBRA 
in this way. Since associativity and commutativity are obvious, the real 
numbers defined as nests of intervals form a module, for which the set of 
ex "* 0 with a~ > 0 is seen to be a domain of positivity. The least upper 
bound of a non-empty set of real numbers bounded from above is most 
easily constructed by the principle of nesting of intervals: let us first choose 
an interval with rational endpoints containing an upper bound and at 
least one number of the set; we then carry out a sequence of bisections, 
where after each bisection we choose the subinterval as far as possible to 
the right still containing numbers of the set. The resulting sequence of 
intervals is then seen to be a nested set which is the desired least upper 
bound. 
We have now indicated various methods for introducing the "real 
numbers"; for that matter, the decimal procedure already provides us 
with infinitely many methods, since we have free choice of a base. So it 
is natural to ask: to what extent do all these methods lead to the same 
result? Certainly it is true that the entities we have called real numbers are 
quite different from case to case; for example, an infinite decimal 0.2 ... 
cannot occur if 2 is the base. But even if certain objects can occur in 
several different methods, it is by no means necessary for them to have the 
same meaning in the different methods; for base 3, for example, the 
infinite "decimal" 1.111. .. = 3/2, whereas for base 10 it is = 10/9. 
But in §4.5 we will show that all the domains obtained in this way can be 
mapped onto one another by isomorphisms that preserve the order (with 
respect to addition), so that in this sense there is no essential difference 
among the various systems. 
4.3. 
Dedekind Cuts 
Our purpose is to extend the module of rational numbers in such a way 
that every non-empty set of rational numbers bounded from above has a 
least upper bound. This problem is very similar to the requirement that led 
us to the integers, namely that every equation (22) should have a solution. 
In §2.2 we took pairs of numbers as our starting point. Analogously, we 
now consider all non-empty sets of rational numbers that are bounded 
from above and to each such set we assign a new symbol fin M.70 Since 
the least upper bound of a set M is determined by the set of upper bounds 
70 For the time being "fin" has no meaning whatever; only after we have introduced 
an ordering will fin M actually tum out to be the least upper bound (finis superior, or 
supremum) of the set M. The construction of such symbols as fin M is permissible only 
if we take the constructive or operational attitude toward the foundations of mathe-
matics (see lA, §§1.4 and 10.6), in which the sets themselves are symbols. From other 
points of view we must proceed somewhat differently; for example, in order to have an 
entity which is distinct from M but naturally associated with it, we might consider the 
pairs (0, M), for which we could then introduce the abbreviation fin M. 

1 Construction of the System of Real Numbers 
135 
of M, we will define the equality fin M = fin M' as identity of the sets of 
upper bounds of M and M'. For abbreviation we let S(M) denote the set 
of upper bounds of M or, in other words, the set of rational numbers x 
with x ~ y for all y E M. By a Dedekind cut we mean the pair consisting 
of the set S(M) and the set of rational numbers not included in S(M). 
It is easy to show that a pair of sets M', Mil of rational numbers is a 
Dedekind cut if and only if it has the following three properties: (i) every 
rational number x belongs to exactly one of the two sets M', Mil; (ii) if 
x' EM', x" E Mil, then x" < x'; (iii) the least upper bound of Mil, provided 
it exists (in the set of rational numbers), belongs to M'. These three 
properties are often taken as the definition of a Dedekind cut, although 
usually the third one is omitted, since it is quite unimportant. In fact, 
such a definition may be taken as the starting point for introducing 
the real numbers, but to us it seems more natural to start from the sets 
M.71 An order for Dedekind cuts is immediately available if we note that 
"pushing up" the least upper bound has the effect of decreasing the set 
of upper bounds: thus by fin M < fin M' we shall mean simply 
S(M') C S(M). We see at once that this is actually a relation between fin M 
and fin M' and not only between the sets M and M'; for if fin M = fin Ml 
and fin M' = fin M~, then fin M < fin M' obviously means the same as 
fin Ml < fin M~ . For this relation < the properties (12), (13) are at once 
clear. Thus in order to prove that we have actually defined an ordering,72 
it only remains to prove (15). To verify (15) for the new symbols (or 
equivalently, for Dedekind cuts), we now assume that for two sets M, M' 
neither fin M' = fin M nor fin M' < fin M; that is, it is not true that 
S(M) ~ S(M'). Then there exists an upper bound s of M which is not an 
upper bound of M': that is, there exists x' E M' with x' > s, and for all 
x EM we have x ~ s. Thus x' > x for all x EM. For every upper bound 
s' of M' it is a fortiori true that s' > x for all x E M, and therefore 
s' E S(M). Consequently S(M') ~ S(M), so that fin M < fin M', as 
desired, since fin M == fin M' was excluded. 
The symbol fin M (which we may, if we wish, regard as the set of upper 
bounds of M, or alternatively as the corresponding Dedekind cut) will 
now be called a real number. Relaxing the restriction that M must be 
bounded from above leads to exactly one new "real number." For if the 
sets M', Mil are not bounded from above, then S(M'), S(M") are empty 
71 Moreover, the definition of Dedekind cuts as pairs of sets with the above properties 
requires a total ordering, whereas our procedure can also be used in the case of a partial 
ordering; see the next footnote. 
72 That is: ~ is an order (in the notation of lA, §8.3). Since we have not yet defined 
addition, (14) requires no attention. Moreover, as long as addition is not yet introduced, 
the property (15) of the rational numbers is required only here, namely in the proof 
of (15) for the newly introduced symbols. 

136 
PART B ARITHMETIC AND ALGEBRA 
and thus equal to each other, so that fin M' = fin Mil. If for this improper 
real number we introduce the usual abbreviation 00, then fin M < 00 
for every other real number fin M, since the empty set is a proper subset 
of any non-empty set. If we also admit the empty set 0, we obtain exactly 
one new improper real number fin 0, which is usually written -
00. Since 
S(0) contains all the rational numbers,73 we have -00 < fin M for every 
non-empty set M. Thus the improper real numbers 00, -
00 have some 
importance in the ordering of the real numbers, but they play no role in 
addition, as defined below. In what follows we shall disregard them 
altogether. 
It remains to answer the following question: when is a rational number 
a equal to a real number fin M? Letting S(a) denote the set of x ~ a we 
have the obvious requirement S(M) = S(a), which we shall take as a 
definition of fin M = a as well as of a = fin M. As in §2.2, we show by 
simple verification of the four possible cases that comparativity is not 
destroyed by this definition. It remains to show that the meaning of 
a ~ a' and of a < a' is unchanged if a, a' are replaced by real numbers 
fin M, fin M' equal to them: but fin M ~ fin M' means S(M') ~ S(M), 
and therefore S(a') ~ S(a), or a ~ a', as desired. Now fin M is actually 
the least upper bound of the set M. For x EM we have in every case 
S(M) ~ S(x), so that x ~ fin M. On the other hand, if fin M' ~ x for all 
x E M, then S(M') ~ S(x) for all x EM. Thus Y E S(M') implies y ~ x 
for all x E M and therefore Y E S(M). Consequently, S(M') ~ S(M) and 
thus fin M ~ fin M', so that fin M is actually the least upper bound. 
But so far we have shown only that every non-empty set of rational 
numbers bounded from above has a least upper bound; now we must 
demonstrate the same property for any such set of real numbers. In order 
to describe a set M of real numbers we require a set 9J1 of non-empty sets 
of rational numbers that are bounded from above: the real numbers in M 
are then the fin M with ME 9J1. We now let fin Mo be an upper bound of 
M, so that fin M ~ fin Mo , which means that S(Mo) C S(M) for all 
ME M. Then we form the (non-empty) set74 M* = UMe!lJl M or, in other 
words, the set of elements x with x E M for at least one set M E 9J1, and 
73 From x E 0 (always false!) it follows that x < y for every number y. 
74 Here we have a difficulty related to the foundations of mathematics. If we adopt 
a theory of sets in which the union of any set of sets can always be formed, we must 
accept the disadvantage that such a theory, at least if it is to satisfy the other demands 
of mathematics, has not yet been shown to be free of contradictions (see lA, §7.1). On 
the other hand, we may say that a set of sets is to be formed only in a second language 
layer, and then, under certain circumstances, we can form a union of sets only in this 
second layer; in order to preserve our theorem about the least upper bound, we must 
form a language layer corresponding to every natural number and then distinguish real 
numbers of the 1 st, 2nd, 3rd,... layer (see Lorenzen [1 D. A corresponding difficulty 
arises in the other methods of introducing real numbers. 

1 Construction of the System of Real Numbers 
137 
prove that fin M* is the least upper bound of M. In order to show that 
fin M* is a real number at all, we must first prove that M* is bounded 
from above: but in view of S(Mo) C; S(M), an upper bound for Mo is also 
an upper bound for every set M E 9J1 and therefore also an upper bound 
for M*. We now investigate the upper bounds fin M' of M (where M' is a 
non-empty set of rational numbers bounded from above, so that fin M' 
is a real number). The inequality fin M' ~ fin M for all ME 9J1 means that 
S(M') C; S(M) for all ME 9J1, so that every upper bound of M' is an upper 
bound of every set M E 9J1. But this simply means that every upper bound 
of M' is an upper bound of M*; in other words, S(M') C; S(M*) and 
therefore fin M' ~ fin M*. Consequently, fin M* is the least upper 
bound of M, as desired. 
We come now to the introduction of addition. For the sets M of 
rational numbers it is obvious what we should do: M + M' is to be defined 
as the set of all x + x' with x E M, x' E M'; this set is non-empty and 
bounded from above if the sets M, M' have those properties, and addition 
defined in this way is clearly associative and commutative. But now again 
we must define addition in the set of real numbers in such a way that 
M -+ fin M is a homomorphism. To this end we must show (as in §2.2) 
that == is consistent with addition, where now M == M' simply means 
S(M) ~ S(M'). So by (31) we must show that S(M') = S(M") implies 
S(M + M') = S(M + M"). Or instead, we may show that 
(57) 
S(M + M') C; S(M + Mil), 
if S(M') C; S(M"); 
since the desired result immediately follows from the fact that C; and J 
together mean =. In order to prove (57) we let z be an upper bound of 
M + M', so that z ~ x + x' for x E M, x' E M'. Then z -
x ~ x' for 
all x' EM', so that z -
x E S(M'), and thus, in view of our hypothesis 
that S(M') C; S(M"), we have z -
x E S(M"), so that z -
x ~ x" for all 
x" EM". Consequently, z ~ x + x" for x EM, x" E M" or, in other 
words, z E S(M + M"). 
The addition of real numbers is now defined by 
(58) 
fin M + fin M' = fin(M + M'). 
When applied to rational numbers, this definition of addition agrees with 
the former one, since75 a = fin{a}, a' = fin{a'}, a + a = fin{a + a'} by 
(58), and {a} + {a'} = {a + a'}. The number 0 is also the neutral element 
for addition of real numbers, since fin M + 0 = fin M + fin{O} = 
fin(M + {O}) = fin M. Since addition of the sets M is associative and 
75 {a} is the set consisting of the single element a. 

138 
PART B ARITHMETIC AND ALGEBRA 
commutative, as was pointed out before, addition of the real numbers 
by the definition (58) has the same properties. Thus, in order to prove that 
the set of real numbers is a module, it only remains to show that every 
real number fin M has an inverse. For this purpose we consider the set 
M' of x' with -x' E S(M) and show that S(O) ~ S(M + M') and also 
S(M + M') ~ S(O), 
so 
that 
S(O) = S(M + M'), 
and 
therefore 
fin M + fin M' = 0, as desired. For the proof of the first inclusion we 
assume z E S(O), so that z ~ O. From x ~ - x' for all x E M, x' E M' 
it follows that x + x' ~ Z, so that Z E S(M + M'). Thus we have shown 
that S(O) ~ S(M + M'). For the proof of the second inclusion we assume 
Z E S(M + M'), so that Z ~ x + x' for all x EM, x' EM', from which it 
follows that Z -
x' ~ x, so that z -
x' E S(M). Since -x' is an arbitrary 
number from S(M), we can prove. by complete induction that 
(n + 1) z -
x' = z + (nz -
x') implies nz -
x' E S(M) for all natural 
numbersn,andthenforxE Mwe obtain the resultthatn(-z) ~ -(x + x') 
for all n. Since the order is Archimedean, it is therefore impossible that 
-z > O. 
Thus z ~ 0, and we have completed the 
proof that 
S(M + M') ~ S(O). 
We have already shown on page 135 that the relation < is an ordering 
of the real numbers. The monotonic law of addition now follows at once 
from (57), (58) and the definition of <. Consequently, by §2.5 the module 
of real numbers is an ordered module. 
An ordered module in which every non-empty set bounded from above 
has a least upper bound is called a complete ordered module. In such a 
module every non-empty set bounded from below has a greatest lower 
bound;76 as can be seen at once, since the inequality x < y, i.e., 0 < y -
x, 
implies -y < -x in view of the fact that y -
x = (-x) -
(-y), 
-y < -x, the mapping x -+ -x takes a non-empty set M bounded from 
below into a non-empty set bounded from above and takes its least upper 
bound into the greatest lower bound of M. 
Our results can now be expressed as follows: there exists a complete 
module which includes the module of the rational number~, where by 
inclusion we mean not only that all the rational numbers occur in the 
new module but also that in it the addition and order for rational numbers 
are defined in exactly the same way as in the module of rational numbers.77 
The above proofs show that the module of rational numbers, which formed 
our starting point, could be replaced by any module with an Archimedean 
78 Thus the concept of completeness here is closely related to completeness in lattices 
(see IB9, §1), with the difference that in a complete lattice every set has a greatest lower 
and a least upper bound; strictly speaking, we ought to say that the module of real 
numbers is "conditionally complete." 
77 Compare the concept of a subgroup in IB2, §3.2. 

1 Construction of the System of Real Numbers 
139 
ordering. 78 But it is essential that the ordering be Archimedean, as is 
shown by the theorem: 
If an ordered module is complete, its order is Archimedean. 
For in a module whose ordering is non-Archimedean there exist elements 
a, b > 0 such that na ~ b for all natural numbers n. Thus the set of 
numbers of the form na is bounded from above, and for every upper 
bound s of this set there exists a smaller one, namely s -
a, since 
(n + l)a = na + a ~ s and therefore na ~ s -
a for all natural 
numbers n. Thus the set of numbers na has no least upper bound, so that 
the module is not complete. 
Finally, let us give a simple example of an ordered module in which the 
ordering is not Archimedean. We form the pairs (a, a') of integers (or of 
rational or real numbers) and define (a, a') + (b, b') = (a + b, a' + b'). 
Then it is easy to see that the pairs (a, a') for which either a > 0 or else 
a = 0 and a' > 0 form a domain of positivity. Thus (a, a') < (b, b') 
if and only if a < b or else a = b and a' < b'.79 Since n(O, 1) = 
L~=1 (0, 1) = (0, n), we have n(O, 1) < (1, 0) for every natural number n. 
Thus the element (0, 1) in this ordering is said to be infinitesimalso in 
comparison with (1,0). In IB4, §2.5 we will give an example of an ordered 
field in· which the ordering is not Archimedean. 
4.4. 
Fundamental Sequences 
We consider sequences (an)n=1.2 •.•• , which for brevity we shall denote81 
simply by a, of rational numbers an satisfying the Cauchy criterion for 
convergence: 
For each rational number € > 0 there exists a natural number no such 
that I On -
am I < € for all n, m ~ no . 
These sequences are called fundamental sequences or Cauchy sequences. 
If addition and multiplication are defined by 
(59) 
78 To be sure, we sometimes mention products of the form nz (where n is a natural 
number and z is an element of the module); but these products could always be con-
sidered as sums (of n summands), so that there is no need of a multiplication for the 
elements of the module. 
79 The ordering here is lexicographic (see page 130, footnote 62). 
80 Of course, the concept defined here has nothing whatever to do with the incorrect 
use of this expression in analysis. 
81 In (an)n_1.2 •... the n is a bound variable (cf. lA, §8.4, §2.6), as is indicated by the 
sign of equality after it; another possible notation is n -
an , but then we must indicate 
in some way that in the symbol an the n is to be replaced by the natural numbers and by 
nothing else. The abbreviation a is to be understood as follows: an is the value of the 
function a for the argument n, or in other words an is the nth term of the sequence. 

140 
PART B ARITHMETIC AND ALGEBRA 
the set of fundamental sequences becomes a commutative ring 9t with 
unit element. Of course, we must first of all show that the sequences 
a + b, ab defined in this way are again fundamental sequences. For a + b 
this result follows immediately from the inequality [cf. (53)] 
I(an + bn) -
(am + bm)1 = I(an -
am) + (bn -
bm)1 
~ I an -
am I + I bn - bm I· 
In order to prove the same result for ab, we require the following theorem: 
For every fundamental sequence there exists a rational number s with 
I an I ~ s for all n. To prove this theorem we first determine no in such a 
way that I an -
am I < 1 for all n, m ~ no and then set m = no. For 
n ~ no it follows from (53) that I an I = I On + (an -
an)1 < I an I + 1. 
o 
0 
0 
So it is sufficient to take s ~ 1 ai I (i = 1, ... , no -
1) and ~ IOn I + 1, 
o 
as is always possible. 
Thus we may consider s (>0) to have been so chosen that IOn I, I bn I ~ s 
for all n, and then from 
I Onbn -
ambm I = I On(bn - bm) + (On -
am) bm I 
~ s I bn - bm I + s I On -
am I 
we readily obtain the desired result that ab is a fundamental sequence. 
The ring properties and the commutativity of multiplication follow 
readily from (59). It is obvious that the sequences (0)n-1.2 .... and (l)n-l.2 .... 
are the zero element and the unit element respectively, so that we shall 
denote them simply by 0 and 1. 
Now for every fundamental sequence we construct a new symbol lim a. 
Since this symbol is to mean the limit of the sequence, we shall set 
lim a = lim b if and only if c = a - b is a zero sequence; that is, if for 
every rational number £ > 0 there exists a natural number no with 
I Cn I < £ for all n ~ no . In other words, if we let 91 denote the set of zero 
sequences, we are introducing into 9t a relation == by setting a == b if and 
only if a - bE 91; in the mapping a -+ lim a two fundamental sequences 
have the same image if and only if the relation == holds b~tween them. 
In order that we may set 
(60) 
lim a + lim b = lim(a + b), 
lim a . lim b = lim ab, 
and thus make the mapping a -+ lim a into a homomorphism of the ring 
9t onto the ring with elements lim a, it merely remains to prove that == is 
an equivalence relation which is consistent with addition and multiplication. 
For this purpose we require only the following three properties82 of 91: 
82 The proof of these properties can be omitted here, since it is exactly the same as 
for the corresponding theorems in analysis; in (613) we require the fact, proved just 
above, that every fundamental sequence is bounded. 

1 Construction of the System of Real Numbers 
a - bE 91, 
ab Em, 
OEm. 
if a, b Em. 
if a E 91, b E 9t. 
141 
For a == a follows from (61 1), and from a == e, b == e it follows by 
(61 2) that a -
b = (a -
e) -
(b -
e) Em, so that a == b, which means 
that == is an equivalence relation. Since a == b (or in other words, 
a -
bE 91) implies not only (a + e) -
(b + e) E 91 but by (61:J also 
ae -
be = (a -
b)e E 91, the equivalence == is in fact consistent with 
addition and multiplication.83 
Under definition (60) the set of symbols lim a becomes a commutative 
ring,84 since the homomorphism a ---+ lim a naturally preserves the ring 
properties of 9t. We now wish to make this ring into an extension of the 
field of rational numbers. Although the problem here is of exactly the same 
kind as those already solved in §§2.2 and 4.3, we will now solve it in a 
different way, which can be extended more easily to other cases. We first 
show85 that 
(62) 
u ---+ lim(u)n=1.2 .... 
is an isomorphism, or in other words, a one-to-one homomorphism of 
the field of rational numbers: for it follows from (U)n=1.2 .... == (V)n=1.2 .... 
that u = v, because by the definition of == we have I u -
v I < lin for 
every natural number n, so that I u -
v I > 0 is impossible. The fact that 
(62) is a homomorphism then follows at once from (59) and (60). Conse-
quently, in the following argument we no longer require the special 
properties of lim a: we simply set lim a = u, u = lim a if and only if 
lim a = lim(u)n=1.2 .... . Since (62) is a one-to-one mapping, the compara-
tivity of equality is thereby preserved, as is easily shown by separate 
consideration of four cases, as in §2.2. Finally, the fact that (62) is a 
homomorphism shows that addition and mUltiplication as defined in 
(60) are identical, when applied to rational numbers, with the earlier 
addition and multiplication. 
The commutative ring with unit element that has thus been formed as an 
extension of the field of rational numbers is in fact a field, known as the 
field oj real numbers. In §4.6 this assertion will be proved very simply by 
83 This proof is obviously valid for any commutative ring 9t containing a subset 91 
with the properties (61) (see the concept of an ideal in 185, §3). 
8' Namely, the ring of residue classes of 9t mod 9t (see ID5, §3.6). 
85 The u, v here are rational numbers and not sequences. The sequence (u)n-1.I .... has 
all its elements = u; it is obviously a fundamental sequence. 

142 
PART B ARITHMETIC AND ALGEBRA 
a general argument, but we wish to prove it here also,86 to which end it 
only remains to show that every real number lim a "* 0 has an inverse. 
But since a is not a zero sequence, there exists an s > 0 such that for 
every natural number n we can find a natural number m ~ n with 
I am I ~ s. On the other hand, since a is a fundamental sequence, there 
exists a natural number no with I an -
am I < s/2 for n, m ~ no. Since 
I an I = I am + (an -
am) I ~ I am I - I an -
am I [see (54)], we thus have 
I an I ~ s/2, so that an "* 0 for n ~ no . The sequence a' defined by a~ = 1 
for n < no , a~ = a;;1 for n ~ no is easily seen to be a fundamental 
sequence, in view of 
and since (aa' -
l)n = 0 for n ~ no, we have lim a . lim a' = 1. 
A slight extension of the argument shows that for I an I ~ s/2 we can 
also make the following statement: if lim a "* 0, then either there exists 
an no such that an > 0 for all n ~ no , or else there exists an no such that 
an < 0 for all n ~ no. For if there exists an s > 0 such that for every 
natural number n we can find a natural number m ~ n with am ~ s, 
then we have an = am + (an - am) ~ s/2 > 0 for n ~ no; and if not, 
then for arbitrary s > 0 there exists a natural number nl with an < s/2 
for all n ~ nl' Since for suitable s, no we have already proved that 
I an I ~ s/2 for all n ~ no, we now have an ~ -s/2 for all n ~ max (no, nl)' 
But the two cases are inconsistent with each other. Thus the argument also 
shows that in the first case we can choose c > 0 such that an ~ c for all 
n ~ no, and in the second case we can arrange that an ~ -c ( <0) for n~ no. 
So we see that the addition of a zero sequence to a produces no change in 
these two cases: the decision as to which of the two cases occurs depends 
only on lim a. The set of elements lim a for which a satisfies the require-
ment of the first case is easily seen to form a domain of positivity. In the 
resulting ordering of the field of real numbers lim a < lim b now means 
that lim a "* lim b, and that there exists a natural number no with 
an ~ bn for all n ~ no. To be consistent with the above .formulation, 
we really ought to have written an < bn , but the argument shows at once 
that we can also write an ~ bn. It is to be noted that an < bn for all 
n ~ no does not imply lim a < lim b but merely that lim a ~ lim b, a 
result which follows equally well from an ~ bn for all n ~ no . 
We now prove that in the field of real numbers every non-empty set M 
bounded from below has a greatest lower bound, and consequently that 
every non-empty set bounded from above has a least upper bound. For 
88 Especially because the proof given here requires an ordering for the absolute 
values only, and thus remains valid for more general systems; cf. van der Waerden [2], 
§§74,75. 

1 Construction of the System of Real Numbers 
143 
every real number lim a there certainly exists a rational number not 
greater than lim a and also a rational number not smaller than lim a, for 
it was proved above that for a suitably chosen rational number s we have 
I an I ::s;; s for all n, so that -s ~ an ~ s for all n and consequently 
-s ~ lim a ~ s. Thus the set M has a rational lower bound. After 
choice of any integer g > 1 we now denote by , n , as in §4.1, the greatest 
integral multiple of g-n (n = 0, 1,2, ... ) that is still a lower bound of M. 
In view of the fact that the ordering of the rational numbers is Archime-
dean, the existence of, n implies that every number less than a lower bound 
of M is again a lower bound and every lower bound lies below some 
rational number, which may simply be any number that is not smaller 
than some number in M. For m > n the number g-n is an integral multiple 
of g-m because g-n = gm-ng-m, and thus we have 
(63) 
for 
m;?: n. 
It follows that I'm - , n I g-no for m, n ;?: no , and since §4.1 shows that 
g-no can be made smaller than any given positive number, the sequence 
, = (, n)n=1.2 .... is a fundamental sequence. Furthermore, it follows from 
(63) that 
(64) 
for all n. 
Now if lim a is a number such that lim a < lim " or in other words if 
d = lim, -
lim a > 0, let us determine a natural number n with gn > d-1 
(as is possible, since there exists a rational number ;?:d-1) and therefore 
with lim a - lim, < _g-n. By (64) we then have lim a < 'n, so that 
lim a cannot be a member of M and consequently lim' is a lower bound 
of M. On the other hand, if lim a is such that lim, < lim a, then in the 
same way g-n < lim a -
lim,. But , n + g-n is certainly not a lower 
bound of M; i.e., there exists a real number lim b with lim b E M and 
lim b < 'n + g-n. Thus we have lim b < lim a + 'n - lim, and there-
fore, by (64), lim b < lim a. Consequently, no real number > lim, is a 
lower bound of M, so that lim, is the greatest lower bound of M, as 
desired. 
Asin§4.1, we see that an = ('n -
'n-l) gn (n = 1,2, ... ) isa nonnegative 
integer <g, that with '0 = ao we have 'n = L;=o aig-i, which shows how 
our present development is connected with decimal expansions. In general, 
it is easy to see that for every fundamental sequence a the real number 
lim a is in fact the limit of the sequence, so that in our case we may write 
lim, = limn -+oo 'n = L~=o ang-n in the usual notation. 
It is also easy to prove directly that the Cauchy criterion for convergence 
is valid for a sequence of real numbers lim a(n) (n = I, 2, ... ). For let us 
determine, corresponding to each value of n, a natural number n' such that 

144 
PART B ARITHMETIC AND ALGEBRA 
I a~'!) -
lim a(n) I < 1 In. Then, from the hypothesis of the Cauchy 
criterion that for 
€ > 0 there exists a natural number no such that 
I lim a(n) -
lim a(m) I < € for n, m ~ no, we see that the sequence 
b of bn = 
a~'!) is fundamental and that lim b is the limit of the sequence 
of the numbers lim a(n). Since this proof makes use of the ordering only 
for absolute values, it is more general than the usual theorem for the 
Cauchy criterion, which is based on the existence of a greatest lower and 
a least upper bound. 
4.5. 
Isomorphisms 
In §4.1 and also in §4.3 and §4.4 we have constructed complete ordered 
modules containing the module for the rational numbers. We now wish 
to show that any two such modules can be mapped onto each other by an 
order-preserving isomorphism leaving all the rational numbers fixed, 
where by an order-preserving mapping f (which may, in particular, be 
an isomorphism) we mean a mapping that is monotone increasing; that is, 
if x < y, then f(x) <f(y) for all x, y. To do this we first show that the 
completeness of a module is equivalent in the following sense to a certain 
maximal property. 
A module with Archimedean ordering that contains the rational numbers 
is complete if and only if it is not contained in a larger module with Archime-
dean ordering. 
For if such a module 9)1 is not complete, then it can be extended by the 
procedure of §4.3 to a module with Archimedean ordering. Consequently, 
if 9)1 is not contained in a larger module with Archimedean ordering, then 
9)1 is complete. On the other hand, if 9)1 is complete, and if 9)1' is a module 
with Archimedean ordering that contains 9Jl, then 9)1 and 9Jl' coincide, as 
can be proved in the following way: 
Let a' be an element of 9)1', let M be the set of rational numbers <a' 
and let a be the least upper bound of M, which is certainly in 9)1. 
We now require the following lemma: if x, y with x < yare elements 
of a module with Archimedean ordering that contains' the rational 
numbers, then the module also contains a rational number r = min with 
x < r < y. For the proof we simply determine the natural number n and then 
the natural number m such that lin < y -
x and (m -
1)ln ~ x < min; 
for then we have 
min = (m -
1)ln + lin < x + (y -
x) = y. 
Thus for every element x < a' in 9)1 we can find a rational number r 
with x < r < a', so that x is not an upper bound of M and therefore 
x "* a. On the other hand, if x is an element of 9)1 with x > a', there 
exists a rational number r with a' < r < x, so that r is a smaller upper 

1 Construction of the System of Real Numbers 
145 
bound of M than x, and thus again x"* a. But since x "* a' implies 
either x < a' or a' < x, we have shown that a' "* a is impossible; in 
other words, a' = a, and th us every element of 9)1' also belongs to 9)1, 
which completes the proof of the stated maximal property. 
We now let 9)1 denote any complete ordered module that contains the 
rational numbers, and we map 9)1 in the following way onto the complete 
module, now denoted by 9)10' that was constructed in §4.3: 
(65) 
x -- fin M x , 
where M x is the set of rational numbers <x. If x < y, then, as already 
~hown, there exists a rational number r with x < r < y and also a 
rational number s with r < s < y, so that r is in S(Mx) but not 
in S(M1/)' On the other hand, since it is obvious that 
Mx ~ M1/ 
and thus S(M 1/) ~ S(Mx), we see that S(M1/) C S(Mx). Consequently, 
x < y 
implies fin 
Mx < fin M1/' 
so that the mapping (65) 
is 
monotone increasing, and therefore one-to-one. That (65) is an 
isomorphism (with respect to addition) can be seen as follows: 
Since r < x, s < y implies the inequality r + s < x + y, we have 
Mx + M1/ ~ MX+1l' Now in order to show MX+1l ~ Mx + M1/ , we choose 
a rational number t < x + y and then a rational t' with 0 < t' ~ X + y - t 
so that t ~ x + y -
t'. But there exist rational numbers r, s with 
x - t' /2 ~ r < x, y -
t' /2 ~ s < y, which implies that x + y -
t' ~ 
r + s. Taking these inequalities together we see that t ~ r + s, r < x, 
s < y. Thus for r' = r -
(r + s -
t)/2, S' = s -
(r + s - t)/2 we have 
r' E Mx , S' E M1/ , t = r' + S' and therefore t E Mx + M1/ . Consequently, 
MX+1l ~ Mx + M1/ and thus MX+1l = Mx + M1/ . In view of (58) we have 
therefore proved that fin Mx + fin M1/ = fin MX+1/' which means that 
(65) is actually an isomorphism with respect to addition. Thus the entire 
set of numbers fin Mx (with x E 9)1) also forms a complete ordered module 
9)1'. But this module contains all the rational numbers, since for a rational 
number r we have S(Mr) = S(r) and therefore fin Mr = r. By the 
maximal property proved at the beginning of this section, it follows that 
9Jlo = 9)10, so that the mapping (65) of 9)1 onto the module 9)10 is an 
order-preserving isomorphism which leaves the rational numbers fixed. 
Now if 9)11 ,9)12 are two complete ordered modules that contain the 
rational numbers, we can first map 9)11 by (65) onto 9)10 and then map 
Wlo onto 9)12 by the inverse of the mapping (65) from 9)12 into 9)10' Thus 
we have the following important result: 
Two complete ordered modules that contain the rational numbers can be 
mapped onto each other by a mapping which is isomorphic and order-
preserving and leaves the rational numbers fixed. 
Moreover, there can be only one such mapping; for (65) is the only 

146 
PART B ARITHMETIC AND ALGEBRA 
order-preserving mapping of 9J1 onto 9J10 that leaves the rational numbers 
fixed. To show this we need only note that by §4.3 the set Mx has the least 
upper bound fin Mx in 9J10 , and, on the other hand, has the least upper 
bound x in 9J1, since 'by the lemma at the beginning of this section there 
exists a rational number r E Mx such that y < r for every element y E 9J1 
with y < x. But an order-preserving mapping of 9J1 onto 9J10 must map 
the least upper bound of Mx in 9J1 onto the least upper bound of Mx in 
9J10 , and must therefore map the element x of 9J1 onto the real number 
fin Mx. 
This result shows that it makes no difference which of the above modules 
(all of them are ordered and complete and contain the rational numbers) 
is called the module of the real numbers. For any two of them there is a 
uniquely determined mapping of one onto the other which leaves the 
rational numbers fixed and preserves order and addition. 
4.6. 
Multiplication 
In §4.4 we have already defined multiplication for the real numbers, but 
we now wish to define multiplication independently of the particular 
construction chosen there for the module of real numbers. Such a definition 
is made possible by the existence of monotone endomorphisms. If c "* 0, 
the mapping x -- cx is a monotone endomorphism (as in §2.5). On the 
other hand, any monotone endomorphismfis already uniquely determined 
by f(1); for if g is another monotone endomorphism with f(1) = g(1), 
then by §3.5 it follows thatf(x) = g(x) for all rational numbers.s7 But then 
f(x) = g(x) for every real number x; for let Mx again denote the set of 
rational numbers <x, so that x is the least upper bound of Mx. Then 
if the mapping f is monotone increasing, f(x) must be the least upper 
bound of f(Mx) (= the set of f(r) with r E M x), and if f is monotone 
decreasing, then f(x) must be the greatest lower bound of f(Mx). Conse-
quently, just as in §3.5 for the rational numbers, the mappings x -- cx 
are the only monotone endomorphisms of the module of real numbers.ss 
Thus, in exactly the same way as by (40) for the integers, we can define 
multiplication for the real numbers by settingf(x) = f(1)x: where f is a 
monotone endomorphism or is the zero mapping (x -- 0). This definition 
involves only the concepts of addition (since f is an endomorphism) an'" 
order (sincefis monotone) and the number 1, so that the isomorphisms of 
87 Of course, we cannot merely cite the above theorem but must prove it anew by 
the same method, since now f(x), g(x) are no longer required to be rational numbers. 
88 As G. Hamel has shown ("Eine Basis alter Zahlen und die unstetigen Losungen der 
Funktionalgleichungf(x + y) = f(x) + f(y)," Math., Ann. 60, 459~62, 1905), there 
exist other (non monotone) endomorphisms; these are all discontinuous and even 
unbounded in every neighborhood of any number, so that in fact they are extremely 
strange functions. 

1 Construction of the System of Real Numbers 
147 
the complete ordered modules considered in §4.5 remain isomorphisms with 
respect to mUltiplication. The field of real numbers is uniquely determined, 
up to order-preserving isomorphic mappings, by the requirement that it be 
a complete ordered field containing the rational numbers, completeness for 
an ordered field being defined in exactly the same way as for an ordered 
module. 
By making use of endomorphisms, it is very easy to prove the fact, 
already proved in §4.4, that every real number *0 has an inverse with 
respect to multiplication; in other words, that we are actually dealing here 
with a field. Since the endomorphism x -- cx (c * O)is monotone and there-
fore one-to-one, it maps the module of real numbers isomorphically onto a 
module 9)1, which is also ordered and complete. But then the module 
of the rational numbers is mapped onto an isomorphic module which has 
all the properties of the module of the rational numbers and therefore 
differs from it only in the names given to the elements. Thus by the theorem 
of maximality in §4.5, the set 9)1 contains all the real numbers, including 1 
in particular, so that there exists a number x with cx = 1. 
Up to now the proof of the existence of a monotone endomorphism f 
with f(1) = c (*0) has been taken over from §4.4. But we can give an 
independent proof on the basis of the following definition: for c, x > ° 
we 
define f(x) as the least upper bound of the set of all products rs of positive 
rational numbers with r < c, s < x and then setf(O) = O,f( -x) = -f(x); 
then the mapping -f is seen to be a monotone endomorphism with 
(-/)(1) = -c. Since zero and the positive and negative numbers must 
now be treated as separate cases, the proofs for the rules of calculation will 
be considerably longer than our earlier proofs. Of course, this difficulty 
can be avoided if we first construct only the positive rational numbers 
(see the end of §3.2), proceed from these to the positive real numbers, 
and then construct the real numbers in the form a -
a' as in §2.2. Then 
the multiplication of positive real numbers is defined as in the present 
section, and the simplest subsequent procedure is to define the multipli-
cation of real numbers in accordance with (43), by the method indicated 
at the end of §2.4. 
It is obvious that the monotone endomorphism x -- cx is also a 
homomorphism with respect to multiplication if and only if c(xy) = cxcy 
for all x, y; that is, if c2 = c or, since c * 0, if c = 1. Thus there is only 
one monotone isomorphism of the field of real numbers into itself, namely, 
the identical mapping. Now any isomorphism of the field of real numbers 
into itself must be order-preserving, since we shall see in §4.7 that every 
positive real number is a square (i.e., is of the form X2), while on the other 
hand a number x 2 * ° must be positive in an ordered ring. Thus the 
domain of positivity must consist exactly of the elements x 2 * ° 
and will 
therefore, in view of the equation f(x2) = f(X)2, be mapped into itself 

148 
PART B ARITHMETIC AND ALGEBRA 
by any isomorphism f of the field of real numbers; but if x < y, or in 
other words 0 < y -
x, then 0 <f(y -
x) = f(y) - f(x), or f(x) <f(y), 
so that the isomorphism is order-preserving as stated. An isomorphism 
of a field onto itself is called an automorphism of the field. Thus, like the 
field of rational numbers, the field of real numbers admits exactly one 
automorphism, namely the identical mapping. In IB7, §6, and IB8, §1.2 we 
will find examples of fields that admit other automorphisms as well. 
4.7. 
Roots 
We shall show that after choice of any natural number n in the field 
of real numbers any number a ~ 0 is the nth power of exactly one real 
number x ~ 0; in other words, there exists exactly one number x with 
xn = a, x ~ O. For if 0 ~ x < y, complete induction on n shows that 
xn < yn by the monotone law of multiplication, which proves the unique-
ness. The existence follows from the mean-value theorem (IB8, §2.1), 
since on the one hand On ~ a and on the other (1 + a/n)n > a. The 
number x, uniquely determined in this way by xn = a, x ~ 0, is denoted 
by '\'Yo and is called the nth root of a; for n = 2 we write Va instead of {'a. 
For n = 2k (k a natural number) the assumption a ~ 0 is necessary, 
since X 2k = (Xk)2 ~ 0; and discarding the requirement x ~ 0 would 
mean that the uniqueness of the solution of xn = a is lost, since both 
\Ya and - \Ya satisfy the equation. The fact that solutions of an algebraic 
equation are also called roots of the equation seems to have led to 
misunderstanding and to the undesirable practice (for n = 2k) of calling 
both \Ya and - '\'Yo the nth root of a, or even of writing both V4 = 2 
and V4 = -2, without taking into account the fact that if we are to 
allow many-valued expressions of this sort, the comparativity of equality 
is lost (since otherwise V4 = 2, V4 = - 2 would imply 2 = - 2). 
Let us again illustrate the language adopted here (which is quite common): 
the equation x 2 -
4 = 0 has the two roots 2 and - 2; but the square root 
of 4 is 2 and not ±2. Let us note the equation 
(66) 
~k/~ 
va2k = 1 a I, 
in which the sign for the absolute value is often quite wrongly omitted; 
the proof of this equation follows at once from I a I ~ 0 and I a 12k = a2k• 
This use of the root sign in the field of real numbers is to be distinguished 
from its frequent use (as in IB7, §2) in algebraic extensions of fields. For a 
rational number a the symbol \Y a denotes an element (X of an extension of the 
field of rational numbers which satisfies the equation (Xft = a. But even in a 
prescribed extension the value of (X is in general not uniquely determined by 
the equation (Xft = a: thus by \ya we mean an arbitrary one of these elements, 
which is to remain fixed during a given investigation. The results obtained 
for Vfii remain valid if we replace Vfii by any of the other elements (X (from 

1 Construction of the System of Real Numbers 
149 
the extension in question) with (Xft = a. For example, for V - 3 we may take 
either the complex number iV~ (see IBS, §1) or the complex number -iV~, 
provided the extension in question is contained in the field of complex numbres 
(which is not necessarily the case). 
If n = 2k -
1 (k a natural number) we may allow a < 0 in the definition 
of the nth root, provided the restriction x ~ 0 is also discarded; for 
x ---+ xn now takes positive numbers into positive numbers and negative 
numbers into negative numbers, and (_x)n = -a means the same 
. 
2k-:lr-t 
~k~ • 
as xn = a. In partIcular, we have 
v -1 = -1, while v -1 IS not 
defined. In contrast to (66), we have 
(67) 
2k-:1.f"9i:::1 
va2k- 1 = a, 
the proof of which is an obvious consequence of the identity a2k- 1 = a2k- 1• 
In view of the general validity (provided a is nonnegative for even n) 
of the equation (\Yo l)n = a, we are led by (66) and (67) to conjecture 
that more generally 
(68) 
for odd n 
for even n with am ~ 0 ' 
where m is an integer and a "* 0 for m ::s;; O. Since in the second case the 
expression on the right side is obviously ~O, we need only prove that 
in both cases the nth power of the right expression is = am, which is 
easily proved from (49). 
Further rules for calculation with roots are 
(69) 
V"Cib = \Ya\Yb, 
if n is odd or a, b ~ 0, 
(70) 
mV'a = V \Yo, 
if m, n are odd or, a ~ O. 
Since the right sides are obviously ~O for even n, we need only show, 
from (50) and (49), that the nth power of the right side of (69) is = ab and 
the mnth power of the right side of (70) is = a. 
For a > 0 we also obtain from (70), for natural numbers n, hand 
arbitrary integer m, that 
(71) 
For mIn = m'ln' with integers m, m' and natural numbers n, n' we obtain 
from (71) that 

150 
PART B ARITHMETIC AND ALGEBRA 
Thus, the expression (\Ya)m depends only on a and on the fraction min 
and may therefore be denoted by am /n (to be read as a to the mlnth power); 
since «0 = a, tHis definition agrees with the definition of powers for 
integral exponents. In particular, for a > 0 we can write \Yo in the 
form al/n. It is easy to show that the rules (47), (49), (50) hold for arbitrary 
rational exponents, provided we assume that the real numbers a, bare 
positive. 
The validity of (47) for arbitrary rational exponents r, s, i.e., 
means that the mapping r ---+ ar, defined by the positive real number a (and 
denoted below by f) is a homomorphic mapping of the group of rational 
numbers under addition (more concisely, the additive group of the rational 
numbers) into the group of positive real numbers under multiplication (the 
multiplicative group of the positive real numbers). The fact that the positive 
real numbers form a group under multiplication is merely a special case of the 
more general fact that the domain P of positivity of an ordered field is a group 
with respect to multiplication: for if a, bE P, then ab E P by (444); and if a E P, 
then a-I = a(a-I)2 E P by (444), since (a-I)2 E P by a remark near the beginning 
of §3.4. 
We now assume a > 1. For natural numbers n, m we then have am/n > 1; 
for if am/n ~ 1, it would follow from the monotonic law of multiplication 
that am ~ 1, whereas in fact am > 1 follows from a > 1 by the same monotonic 
law. Setting r -
s = min, we again obtain from this monotonic law 
that ar = amIna' > a' if r > s. Thus if ar = a', both r < sand r > s are 
impossible, so that r = 
S. Consequently the mapping is one-to-one and is 
even an order-preserving isomorphism: namely, the real numbers ar are in 
one-to-one correspondence with the rational numbers r, and act in exactly 
the same way with respect to order and multiplication as the rational numbers 
with respect to order and addition. Thus in view of the monotonic law of 
multiplicatiOl~ and the fact that a set of positive numbers can have only positive 
upper bounds, the multiplicative group of positive real numbers is a complete 
ordered module. To be sure, this module does not contain all the rational 
numbers, but (by what has just been proved) the ar do constitute a set of numbers 
which acts exactly like the entire set of rational numbers with respect to order 
and to the given operation (which is now multiplication instead of addition). 
Thus the method of proof in §4.5 can be used to extend the isomorphism f 
to an isomorphism of the additive group of all the real numbers onto the 
multiplicative group of the positive real numbers: to do this, given any real 
number x, we merely define f(x) in accordance with (65), namely as the least 
upper bOWld of the~set of all numbersf(r) = ar (with rational r < x). Writing aX 
instead of f(x) , we have 
for all real numbers x, y. The fWlction x ---+ aX thus defined is called the 
exponential function with base a; as an order-preserving isomorphism it is 
monotone increasing and thus determines an inverse function on the set of 

1 Construction of the System of Real Numbers 
151 
positive real numbers; this inverse function is called the /ogarithm 89 to the base a 
(abbreviated: alog or also alog). Of course, this function is again an (order-
preserving) endomorphism of the multiplicative group of the positive real 
numbers onto the additive group of the real numbers; that is, 
alog xy = alog x + alog y. 
In making a computation we may therefore replace multiplication by addition, 
a fact which explains the practical importance of logarithms. 
If for a we choose a positive real number < 1, the foregoing results remain 
valid, except that now the exponential function and the logarithm (to the base a) 
are monotone decreasing rather than increasing. 
4.8. 
Un coun tability 
A set is said to be countable (cf. lA, §7.3) if either it is finite or else is 
equivalent to the set N of natural numbers90 (see §I.5); otherwise the set 
is said to be uncountable. A non-empty set is countable if and only if its 
elements can be represented as the terms of an (infinite) sequence. For if M 
is infinite, then a one-to-one mapping of N onto M provides such a 
sequence, and if M is finite and is therefore the image under the mapping 
n -- On of the segment Am (see §1.5), then after choice of any a E M the 
mapping n -- bn , with bn = On for n ~ m and bn = a for n > m, has the 
desired property. On the other hand, if we assume that M consists of all 
the terms On (n = 
1, 2, ... ) of a sequence and is not finite, then we can 
define a mappingf of N into M recursively as follows [cf. (4') !]: 
f(1) = al ,f(n + 1) = ak, where k is the smallest natural number91 
with ak *- f(1), ···,f(n). 
This mapping is obviously one-to-one, since f(m) *- f(n + 1) for 
m < n + 1. By complete induction on m we now show that every element 
am in M occurs as an image in the mappingf; for by the definition off it 
follows from am = f(n) that each of the terms al , ... , am-l has one of the 
values f(1), ··.,f(n -
1) and thus if am+l *- f(1), ···,f(n), the equation 
am +1 = f(n + 1) musr hold, which completes the proof that M is 
equivalent to N. 
The set of rational numbers is countable. For the proof we first represent 
all the positive rational numbers as terms of a sequence by writing them 
in the order 
1/1,1/2,2/1, 1/3,2/2,3/1,1/4,2/3,3/2,4/1, ... , 
89 It is preferable to use the word "logarithm" for the function rather than for the 
value of the function. The "logarithm of x" is in fact the value of the logarithm function 
for the argument x. 
9(' Thus a set is wuntably infinite if and only if it is equivalent to N. 
91 If there were no such number, M would consist only of the elementsf( I), ... ,f(n) 
and would thus be finite. 

152 
PART B ARITHMETIC AND ALGEBRA 
so that the nth term of the sequence is defined by al = 1, an = i/(m -
i) 
for n > 1, if 
m-2 
m-l 
m-2 
L k < n ~ L k, 
n = L k + i. 
1.:=1 
1.:=1 
k=1 
The sequence n -- a~ with a~ = 0, a;k = ak, a;k+l = -ak then comprises 
the entire set of rationaJ numbers, so that by the above argument the set 
of rational numbers is countable. 
But in contrast to the rational numbers, the set of real numbers is 
uncountable;92 in other words: given any sequence of real numbers, there 
exists a real number which is not a term of the sequence. 
To prove this, we represent the nth term (n = 0, I, 2, ... ) of the given 
sequence of real numbers as the sum of an integer ano and a proper decimal 
fraction with the digits anm «g, ~O), where g > 2 is any chosen base: 
(72) 
here, as in §4.1, we exclude the case that a number mo exists with 
anm = g -
1 for all m ~ mo . Then it is obvious that the anm are uniquely 
determined by the an . For the sequences m -- anm we now consider the 
diagonal sequence n -- ann and form the sequence n -- bn with 
b = ~O, 
n 
/1, 
if ann "* O. 
if ann = O. 
Since bn < g -
1, the number b = bo + 0.b1b2ba ... is of the same form 
as (72), so that bn "* ann (n = 0, 1,2, ... ) implies the inequality b "* an 
(n = 0, 1, 2, ... ). Thus the real number b is not a term of the given 
sequence of real numbers. 
The procedure by which b is determined from the sequence n--anis called 
the (second) Cantor diagonal procedure (see also lA, §7.3). The uncounta-
bility of the set of real numbers proved in this way appears paradoxical, 
since it is certainly true that every real number must be d~fined in some 
way, and such a definition employs only finitely many letters of the 
alphabet, together with finitely many special symbols (such as I, by repeated 
use of which we can express all the natural numbers). So if we add the 
special symbols to the alphabet in any definite arrangement, the definitions 
of all the real numbers can be arranged in lexicographic order, in contra-
diction to the fact that the set of real numbers is uncountable. It seems that 
92 It follows that irrational numbers (that is, real numbers that are not rational) 
must exist. It is easy to give some examples directly: from the theorem in IB5, §4.4, it 
follows at once that Vii is irrational for every natural number n which is not the square 
of a natural number; in particular, v2 is irrational. 

1 Construction of the System of Real Numbers 
153 
this paradox, which is really a serious one, can be resolved only by assum-
ing that any natural language is so inexact as to lead inevitably, in extreme 
cases, to a contradiction. But if we use a formal language, whose formulas 
(propositions) are constructed according to exact rules prescribed in 
advance, then any mapping, and in particular a mapping that might 
possibly map the natural numbers onto all the real numbers, would 
necessarily be constructed in terms of this formal language. Then the 
uncountability of the set of real numbers would simply mean that in this 
formal language no such enumeration of them can be constructed. But if 
we make a suitable extension of the formal language, then all the expres-
sions in it, and in particular all the real numbers that can be described in 
it, can in fact be enumerated in the new language. The concept of 
countability is thus dependent on the linguistic expressions93 at our 
disposal. 
This explanation of the paradox is available only from the constructive 
(lA, §1.5) or the operational (lA, §10.6) point of view. From the classical 
point of view (lA, §1.5) the real numbers (or the mathematical entities 
used to define them, such as the sets of rational numbers in §4.3), exist 
independently of the way we construct them. But now there is no longer 
any paradox; we must simply recognize that it is impossible to find any 
procedure for setting down in succession the definitions of all the real 
numbers. 
Appendix to Chapter 1 
Ordinal Numbers 
The basic property of the set N of natural numbers, namely that every 
non-empty subset has a first element, i.e., a smallest element; cf. IBl, §1.3) 
leads us to consider arbitrary well-ordered sets and to interpret them as 
ordinal numbers. The principal purpose of the ordinal numbers is, in fact, 
to determine the "rank" of each element in a set of elements, and for that 
purpose the well-ordered sets are exactly suited. After the sequence of 
finite ordinal numbers 0, 1,2, ... , n, n + 1, '" come the countable infinite 
ordinal numbers w, w + 1, ... ; these ordinal numbers form a well-
defined set Q, which has taken its place in mathematics alongside the set 
R of real numbers. 
93 In §1.5 we defined the concept of finiteness by means of a mapping; but it can be 
shown that this concept is independent of the linguistic expressions employed (see 
Lorenzen [1 D. 

154 
PART 8 
ARITHMETIC AND ALGE8RA 
1. Atomization of the Continuum as an 
Introductory Example 
Let S = [0, 1] denote the set of real numbers in the closed interval 
o to 1. We divide the interval into two subintervals with one point in 
common, and then divide these subintervals similarly and so forth, each 
time dividing a closed interval I into two closed subintervals I I. Thus IS 
denotes the set of the two subintervals of S,fIS = 12S denotes the set of 
the four subintervals, ISS the set of the eight subintervals, and so forth. 
From the interval S we obtain by the first division the subintervals So , Sl 
with So ~ Sl' from So by the second division the intervals SOO' SOl 
with Soo ~ SOl and from S] the subintervals SlO and S11 . In general, for 
any Si' where the subscript i stands for a dyadic sequence of integers 
already assigned, we denote by SiO and Sil the left and right subinterval, 
respectively, of the interval Si . 
For example, we determine in this way the sequence of intervals 
So, SOl' SOlO' SOlOl, SOlOlO' ... in which 0 and 1 appear alternately. 
The intersection of the intervals in this sequence, to be denoted 
by SOlOlO ... , is either a point or a closed interval. In the latter case we can 
continue the subdivision and consider the intervals Sao and Sal, where a 
denotes the infinite sequence of numbers 01010 .... 
In other words, we have here a "well-ordered" set of processes PI' P2 , ... , 
where Pn leads to the 2" intervals SU"'i with il , ... , in E {O, I}. After all 
these processes Pn there comes a proce;s P l •2•S .... , which we shall call 
P" , where v cannot be a natural number since these have all been used. In 
P" we consider the set of "remainders" 
(1) 
il , l~ , ... , in , ... E {O, I}. 
If this set contains at least one interval consisting of more than a single 
point, we consider the next process; that is, we subdivide into I I all the 
intervals I of the form (1) that consist of more than a single point; this is 
the process PII+1 • Then follow the processes PII+2 , PII+S ... : After all these 
processes PII+n with n E N comes PII+II
• In this process we consider all 
intersections nF, where F is any system of comparable intervals that 
contains an interval from each of the preceding processes. If the elements 
of F are denoted by Si ,Si i , ... , Si • 
•• 
, it is natural to denote this 
o 
0 1 
0°1 ... °"°"+1 ... 
intersection by 
where the index represents a "double sequence" (that is, a juxtaposition 
of two sequences, one after the other). In this way we can continue the 
subdivision until there is nothing more to divide, namely, until we have 

1 Construction of the System of Real Numbers 
155 
arrived at all the isolated points of the reduced continuum [0, 1]. For 
example, if the subdivision is always a bisection, the process PI) is the last 
one, since every set then consists of a single point. It is worth noting that 
the result is the same if the subdivision f X of X is carried out uniformly; 
that is, in such a way that the ratio of the lengths of the subintervals is 
constant.1 In other cases the "height" of the subdivision can become very 
great; that is, the necessary number of divisions is "extremely great." If 
the subdivision of 0, 1 is undertaken in such a way that whenever possible 
the half-segment [0, !] lies in one of the subintervals, then the "height" 
is at least equal to v + v. At any rate, we see that the set of processes 
Po , P 1 , P 2 , ... is well-ordered and that the finite ordinal numbers are not 
sufficient to deal with irregular atomizations. 
2. 
Fundamental Concepts 
2.1. 
A set that is ordered by a relation (cf. lA, §8.3 and §7.4) has a first 
element x if no element of the set precedes x or, in other words, if there 
is no element z in the set such that z < x; and similarly y is a last element 
if no element of the set follows y or, in other words, if there is no element 
z such that y < z. An ordered set M is said to be well-ordered if the set M 
itself and each of its non-empty subsets has a first element in the prescribed 
ordering of M. By definition, the empty set 0 is also well-ordered, and the 
same remark holds for every set consisting of a single element. 
The set N of natural numbers in the usual order is well-ordered, which 
is one of its fundamental properties. Here the ordering is the usual < 
(smaller than) relation. If we order the set N by putting all the odd natural 
numbers first and then all the even ones 
(2) 
1,3, 5, ... ; 
2,4,6, ... , 
it is still well-ordered, where by the ordering we mean the relation that 
holds for the pair of numbers (m, n) if and only if m is odd and n is even 
or else, if m, n are both even or both odd, then m < n. The corresponding 
remarks hold for the sequences 
(3) 
1,3, 5, ... ; 
2'1,2'3,2'5, ... ; 
22 . 1, 22 . 3, 22 . 5, ... , 
2n • 1, 2n • 3, 2n • 5, '" . 
On the other hand, the set of natural numbers in the order 
... , n, n -
1, ... , 3, 2, 1 
is not well-ordered. The sets Q and R of all rational and all real numbers in 
order of magnitude are not well-ordered; for example, neither of them 
1 Since limn ... oo qn = 0 for every q with -1 < q < + 1. 

156 
PART 8 ARITHMETIC AND ALGE8RA 
has a first element. However, it is easy to well-order Q.2 On the other 
hand, no one has yet succeeded in well-ordering the set R of all real 
numbers, although this problem is closely related to many other interesting 
problems; for example, the question whether for every subset M of R we 
can define a permutation PM of M such that PM(X) "* x for every x EM. 
For if it is possible to well-order R, and therewith every M with Me: R, 
this question can be answered in the affirmative. 
2.2. 
Among the subsets of an ordered set M the initial segments are 
particularly important. A subset A of M is called a segment if for every 
element a of A the set A also contains every element b that precedes the 
element a in M, or in other words if a E A and b < a imply bE A. The empty 
set and the entire set M are also called segments; all other segments are 
proper segments of M. 
It is important to note that if A is a proper segment of a well-ordered 
set M, then the set M -
A has a first element. 
If we denote by ( . , X)M and ( . , X]M the sets of all y EM such that 
y < x and y ~ x, respectively, then for every x EM the sets ( . , X)M and 
( . , X]M are segments of M; they are sometimes called initial intervals of M, 
or the segments determined by x. 
2.3. 
For ordered sets we define similarity or isomorphism as follows. 
An ordered set M is said to be similar or isomorphic to an ordered set M' 
if there exists a one-to-one mapping f of M onto M' such that for every 
pair m1 ,m2 of e1ements of M we have ml < m2 if and only iffml <fm2 .3 
3. Simple Properties of Well-Ordered Sets 
3.1. 
Let W Be a Well-Ordered Set 
Theorem 1. 
Every subset of the well-ordered set W is well-ordered. 
This theorem follows immediately from the definition of a well-ordered 
set. 
2 lf n is a natural number (n ~ 1), let Qn be the well-ordered set of rational fractions 
2 
2 
n-l 
n -1 n 
n 
~' -
~ , n -
1 ' -
n - 1 ' ... , -2-' - -2- , l' - -
(note that they are not in the natural order). By forming the sequence 0, Ql , Q2 ... and 
striking out the terms that have already occurred, we obtain the well-ordered set 
0; -}, - ·L L - L -}, - f ; 1. - i, ~, - I ; L - L i, - i ; L - -g., 1 ; - t , ." 
of all rational numbers. This ordering of Q is obviously different from the natural order, 
since smaller elements may precede larger ones. 
3 The symbol fa or f(a) denotes the f image of a. 

Construction of the System of Real Numbers 
157 
Theorem 2. 
A set W is well-ordered if and only if it contains no infinite 
"decreasing sequences" (regressions). 
Proof: If W has an infinite decreasing sequence ao' a1 , a2 , ••• with 
ao > al > a2 > ... , then the set of these elements, which is a subset of W, 
has no first element and therefore Wis not well-ordered. Conversely, if W 
is not well-ordered, we let A c: W denote a non-empty subset with no 
first element. Then for ao E A there is an a1 E A with a1 < ao , and similarly 
a2 E A with a2 < a1 , and so forth, which leads to the infinite decreasing 
sequence ao , a1 , a2 , .... 
Theorem 3. 
The well-ordered set W is not similar to any of its proper 
segments. 
Proof: Assuming that W is similar to a proper segment A of W, we 
letf denote a mapping of Wonto A. Now let a be the first element of 
W -
A; then fa < a; but then also ffa = f 2a <fa,f3a <f2a and so 
forth, which leads to the infinite decreasing sequence fna with n in N, in 
contradiction to Theorem 2. 
3.2. 
The Principle of Induction for Well-Ordered Sets 
Theorem 4. 
Let W be a non-empty well-ordered set. Let the set M be 
such that 
(1) M contains the first element of W. 
(2) if x E Wand ( . , x)w c: M, then x E M (for the notation here see 2.2). 
Then MJ W. 
Proof: If the assertion M J W were false, the set W -
M would not 
be empty. As a non-empty subset of W it would have a first element, call 
it x. Then we would have ( . , x)w c: M and thus by the induction hypothe-
sis (2) also x E M, in contradiction to the fact that x E W -
M. 
For W = Nthe principle of induction for well-ordered sets reduces to the 
ordinary principle of complete induction. 
3.3. 
Comparison of Well-Ordered Sets 
Theorem 5. If the well-ordered set A is similar to a segment of the 
well-ordered set B, then there exists exactly one similar mapping of A such 
that fA is a segment of B. 
Proof: 
Let f and g be two distinct similar mappings of A such that fA 
and gA are segments of B. Let Ao be the maximal segment in whichfand g 
coincide. Then we must show that Ao = A. Otherwise we would have 
Ao C A. Let x be the first element of A -
Ao , so that fx and gx are the 
first elements of B - fAo and B -
gAo. Now fAo = gAo, so that 

158 
PART 8 
ARITHMETIC AND ALGE8RA 
fx = gx, since fx and gx are the first element in one and the same set. 
Consequently, f and g coincide in a larger segment of A, namely, in 
Ao u {x}. But this is a contradiction, so that Ao = A. 
Theorem 6. 
(Fundamental theorem on well-ordered sets.) If A, Bare 
well-ordered sets, then either A is similar to a segment of B, or B is similar 
to a proper segment of A. 
Proof: Let us assume that A is not similar to any segment of B, and 
then prove that B is similar to a proper segment of A. Let bo be the first 
point of Band fbo the first point of A. Let us then assume that X is a 
segment of B which is mapped isomorphically by fx onto a segment of A; 
let x be the first element of B -
X andf~ the first element of A - fxX; 
then we have an isomorphic mappingfx of ( . ,X]B onto a segment of A. 
Let M be the set of all elements x E B with the property that ( . , X]B is 
isomorphic to a segment of A. We see at once that the requirements (1) 
and (2) of the theorem on induction are satisfied for B = Wand thus 
M d B. This means that every segment X of B is isomorphic to a segment 
fxX of A, where fx is the corresponding isomorphic mapping of X. If 
XC Y C B, then fxz = fyz for Z E X, since otherwise the restriction of 
f y to X and the mapping fx would be two distinct isomorphic mappings 
of X onto a segment of A, in contradiction to Theorem 5. Thusfz = fxz for 
every z E X and every segment X of B defines an isomorphism, and 
thereforefB is a segment of A. 
But the setfB is a proper segment of A; for if we hadfB = A, then A 
would be isomorphic to B, in contradiction to the assumption that A 
is not isomorphic to any segment of B. 
4. 
Definition and Simple Properties of Ordinal Numbers 
4.1. 
Definition 
By the fundamental theorem on well-ordered sets, tw,o distinct well-
ordered sets A and B are comparable to each other in the following sense. 
Either A and B are similar, or A is similar to a proper segment of B, or B is 
similar to a proper segment of A. Thus it is natural to regard the well-
ordered sets as ordinal numbers. 
Every well-ordered set W represents an ordinal number (0 W)4 under the 
following conventions concerning equality and order (§4.2) and computation 
with well-ordered sets (§4.3). 
4.2. 
Equality and Order of Ordinal Numbers 
If A and B are two well-ordered sets, their ordinal numbers OA and OB 
, Following Cantor, many authors write W instead of OW. 

1 Construction of the System of Real Numbers 
159 
are equal if and only if A and B are similar. Thus any two similar well-
ordered sets determine one and the same ordinal number. 
The order-relation OA < OB or OB > OA means that A is similar 
to a proper segment of B, and OA ~ OB means either OA < OB or 
OA = OB. 
It is easy to prove the transitivity of equality and order: from 
OA ~ OB ~ oc follows OA ~ OC, where we have OA < OC if the 
symbol ~ actually means < at least once. 
4.3. 
Computation with Ordinal Numbers 
4.3.1. 
Sum of Ordinal Numbers. If A and B are two disjoint 5 well-
ordered sets, then A + B denotes the union A U B so ordered that the 
orders of A and B are preserved and all the elements of A precede those 
of B. Then the well-ordered sum A + B determines the sum of the ordinal 
numbers OA + OB. It is easy to show that the sum is independent of the 
special representatives of the two ordinal numbers: for if OA = OAI and 
OB = OBI and also Al n Bl = 0, then we have OA + OB = OAI + OBI' 
More generally, let X be a well-ordered set and for every x EX letf(x) be a 
well-ordered set; then if 
f(x) nf(x') = 0 
for 
x, x' E X, 
x"* x', 
let Lxexf(x) be the union Uxexf(x), so ordered that f(x) precedes f(x') 
if and only if x < x' in X. 
In case the sets A and B are not disjoint, we proceed as follows. If 
(A, B) is the ordered pair of well-ordered sets A and B, let {l} x A be the 
set of all ordered pairs (1, a) with a E A and let {2} x B be the set of all 
pairs (2, b) with bE B. If we now let the union {l} X A U {2} x B be 
lexicographically ordered, the result is the ordered sum 
{l} X A + {2} X B. 
This sum represents a well-ordered set which we may consider as an ordinal 
number and denote by OA + OB. 
More generally, if B is a well-ordered set and if to every bE B there 
corresponds a well-ordered setf(b), then {b} X f(b) is the set of all ordered 
pairs (b, x) with x Ef(b). If the union UbeB {b} X f(b) is lexicographically 
ordered, it represents a well-ordered set whose ordinal number is called 
the sum of the ordinal numbers Of (b) taken over the ordinal number OB; 
this sum is denoted by LbeB Of (b). Of course, there is no need for the f(b) 
to be distinct. 
5 That is, A (') B = 0. 

160 
PART 8 
ARITHMETIC AND ALGE8RA 
4.3.2. 
Multiplication of Ordinal Numbers. If Band C are well-ordered 
sets with the ordinal numbers OB and OC, then the product OB . OC of 
their ordinal numbers is defined as the sum LbEB Oc. In this case f(b) = C 
for every bE B in the preceding definition of this sum. 
4.4. 
Special Symbols 
If we write 0(0) = 0, where 0 is the empty set, and then set 
O{O} = I, 
O{O, I} = 2, 
O{O, I, 2} = 3, ... , 
we obtain the well-ordered set of ordinal numbers 
0, 1,2,3, ... , n, 
n + I, .... 
This set determines the ordinal number O{O, I, 2, ... , n, n + I, ... }, which 
is denoted by w or Wo • 
4.5. 
Arithmetic of the Ordinal Numbers 
4.5.1. 
Addition and Multiplication. For example, 2 + 3 = 5, and 
a + ° = a for every ordinal number a. 
Since the well-ordered sets 
0, 1,2,3, ... ,n,n+ I, ... 
(4) 
1, 2, 3, 4, ... , n + I, n + 2, ... 
are similar under the mapping n -- n + 1, we have 1 + w = w. On the 
other hand w + 1 > w, since the ordinal number w + 1 may be repre-
sented by the well-ordered set 
(5) 
1 2 
11 
0, 2' "3' ... , ""I"l"+T' ... , 1, 
which is not similar to any segment of (4). For if there existed a similar 
mapping f of (5) onto a segment of (4), then (4) would contain f(l) in 
particular, and in front of f(l) would come the infinite set of elements 
f[nJ(n + I)], which is impossible, since no proper segment of (4) can be 
infinite, and therefore we must have w + 1 > w. 
Consequently, 1 + w = w < w + 1, so that 1 + w < w + I, which 
shows that addition of ordinal numbers is not always commutative. 
The same remark holds for multiplication; for example, w . 2 = w, 
2 . w = w + w > w, so that w . 2 "* 2 . w. However, it is easy to show 
that addition and multiplication are associative: 
(6) 
(7) 
(a + (3) + y = a + (f3 + y), 
(af3) y = a (f3y). 

1 Construction of the System of Real Numbers 
161 
We also have 
(8) 
(a + fl) y = ay + fly; 
but in some cases 
a(fl + y) *- afl + ay, 
for example, w(l + 1) *- w . 1 + w . 1, since w ·2 = w, w + w > w. 
In exactly the same way as for ordinary ordinal numbers <w, we can 
prove the following fundamental theorem: 
For every ordered pair (a, fl), fl *- 0 of ordinal numbers there exists a 
unique ordered pair (K, p) of ordinal numbers such that a = Kfl + P with 
o ~ P < fl. 
For example, if fl = 2, then every ordinal number is either of the form 
K • 2 (an even ordinal number) or of the form K2 + 1 (an odd ordinal 
number). 
4.5.2. 
Subtraction. If a ~ fl, the equation a + g = fl has exactly one 
solution, which is denoted by -a + fl. The number -a + fl is the ordinal 
number O(B -
A) of the set B -
A if OB = fl and A is a segment of B 
with OA = a. 
For example, -1 + w = wand in general -1 + a = a for every 
a ~ w. 
Retaining the assumption a ~ fl, let us now investigate fl -
a; that 
is, the solution of the equation g + a = fl. 
For example, fl - 0 = fl. But consider fl -
1, and in particular 
w -
1. The number w -
1 does not exist, since the equation g + 1 = w 
cannot have a solution, in view of the fact that g + 1 has a last element, 
whereas w has no last element. 
Thus we have the following result: if fl ~ a, then the "left difference" 
-a + fl is a uniquely determined ordinal number; on the other hand, the 
"right difference" fl -
a does not ahvays exist, and when it does exist it 
may have more than one value. 
For example, -w + w = 0, but w -
w may be any ordinal number 
<w. 
Definition. 
An ordinal number fl is said to be of the first kind (or to be 
isolated) if fl -
1 exists, and to be of the second kind if fl -
1 does not 
exist. An ordinal number of the second kind, other than zero, is also 
called a limit number. 
For example, 5 and w + 1 are isolated, whereas wand 2w are limit 
numbers. 
Every number of the second kind is of the form KW. 

162 
PART 8 
ARITHMETIC AND ALGE8RA 
4.5.3. 
Exponentiation. 
We can 
make 
the 
following 
inductive 
definitions: 
for every ordinal number 
ex = 0, 
ex" = SUPe<,\ CXe 6 for every non-isolated ordinal number ex =I=- 0. 
For example, 2w = sUPn<w 2n = w, and similarly nW = w for every n 
with ° < n < w. 
I t is easy to prove that 
(9) 
(10) 
But in general it is not true that (exfl)" = ex"{tt. 
For example: (2w)w =I=- 2www, since (2w)w < 2www; for we have 
4.5.4. 
(2w)w = sup(2w)n = WW < ww+1 = w . WW = 2w . wW. 
n 
Monotonic Laws. 
The following monotonic laws (inequalities, 
cancellations) are valid: 
If y > 0, 
then 
ex + y > ex, 
and conversely. 
If ex < fl, 
then y + ex < y + fl, 
and conversely. 
If ex = fl, 
then y + ex = y + fl, 
and conversely. 
If ex ~ fl, 
then 
ex + y ~ fl + y, 
and conversely, 
but the relation ~ cannot be replaced by <. 
For example: although 2 < 3, nevertheless 2 + w = 3 + w = w. 
If 
ex = fl, 
then 
exy = fly. 
If exy = fly, y > 0, 
then 
ex = fl. 
If 
ex < fl, y > 0, 
then 
exy < fly, 
and 
If exy < fly, y > 0, 
then 
ex < fl. 
If 
ex < fl, y > 0, 
then 
yex ~ yfl, 
but not necessarily yex < yfl because, for example, 2 < 3, w . 2 = w . 3. 
5. Enumeration by Means of the Ordinal Numb~rs 
Definition. 
For each ordinal number ex we let /(ex) denote the set of all 
ordinal numbers that are smaller than ex; for example, /(2) = {O, I}. ,:rhen 
II For a set M of ordinal numbers we denote by sup M or SUPzeM x the smallest 
ordinal number (X for which M ~ (X (that is, x ~ (X for every x EM). 

1 Construction of the System of Real Numbers 
163 
1(0) is empty and I(w) = {O, 1,2 ... }, so that the set I(w) has no last 
element. 
Theorem 7. 
For every ordinal number ex the set I(ex) is well-ordered, 
and OI(ex) = ex; that is, the set I(ex) regarded as an ordinal number is equal 
to ex. In other words: every set A oj type ex is similar to I(ex). 
The proof of this theorem is immediate, since the ordinal numbers <ex 
are represented by the segments ( . , X)A of the set A, and the mapping 
x -+ O( . , X)A provides an isomorphism between A and I(ex). But instead 
of this mapping it is often more convenient to consider the inverse mapping 
g -+ exe ' g < ex, which indicates how the elements exe of A are represented 
by "indices" from [(ex). For example, in ftn. 2, p. 156, we have considered 
an enumeration rn (n < w) of the set Q of all rational numbers. 
The rest of the present section is devoted to the following important 
question: does there exist an ordinal number !p with the property that the 
entire set R of real numbers can be put into one-to-one correspondence 
with a: sequence ae (g < !p) of length !p? 
Cantor'sJundamental theorem (theorem of the uncountability of the set 
R; cf. lA, §7.3) states that !p -=I=- w. 
We first prove the following theorem. 
Theorem 8. 
Every set M oj ordinal numbers arranged in order oj 
magnitude is well-ordered. 
We must show that every non-empty set XC M has a least element 
inf X. 7 But if f3 E X, the set I(f3) is well-ordered, and thus also the set 
I(f3) n X. It is obvious that inf (I(f3) n X) = inf X. 
Now let Q denote the set of all ordinal numbers ex such that the segment 
I(ex) (namely, the set of all ordinal numbers <ex) is countable.s Then Q is 
a well-defined set,9 which by Theorem 8 is well-ordered and thus defines 
an ordinal number, denoted by WI • Then I(wI) = Q. 
Theorem 9. 
The set Q has no last element. 
For if ex < WI' then also ex + 1 < WI' since the addition of one 
element to a countable well-ordered set of ordinal numbers produces a set 
of the same kind. 
The special continuum hypothesis of Cantor (cf. lA, §7.6) is that 
!p = WI' 
In other words, this conjecture states that the cardinal numbers of R 
and I(wI) are equal to each other; thus there must exist a one-to-one 
7 For a set M of ordinal numbers inf M or infzEM x denotes the largest number (X 
for which (X < x for every x EM. 
8 Countable means: empty (zero), finite, or equivalent to the set N of all natural 
numbers. 
9 In contrast, for example, to the "set" of all ordinal numbers, which is meaningless 
(cf. the Burali-Forti paradox, lA, §7.5). 

164 
PART 8 
ARITHMETIC AND ALGE8RA 
mapping f of l(wI ) onto R. This mapping f enables us to consider, in 
addition to the natural ordering of the set R, the following well-
ordering <, : 
f(O) <, f(l) <, f(2) <, ... <, f(g) <, ... for every g < WI . 
The statement" Every set can be well-ordered" (the well-ordering axiom) 
is equivalent to either of the following two statements:IO 
For every non-empty set S of non-empty sets there exists a set which 
contains exactly one element from each XES (Zermelo axiom of choice). 
Every inductive, partially ordered set contains at least one maximal 
element (Zorn lemma, cf lBll). 
Here we have the following definitions: A set M partially ordered by < is 
called inductive if every subset K of M that is linearly ordered (not only partially 
ordered) has a least upper bound in M; that is, an element a E M with x ~ a 
for all x E K and such that a ~ a' for every element a' E M satisfying the 
condition x ~ a' for all x E K. By a maximal element m of M we mean an 
element for which there is no element x E M with m < x. An ordered set can 
have at most one maximal element, which in §2.1 we have called its last element. 
In order to continue our comparison of the set Q with the continuum 
R of real numbers let us prove the following theorem: 
Theorem 10. If an < WI , (n EN), then supn an < WI . 
In particular, if an (n < w) is a strictly increasing sequence of ordinal 
numbers <wI' then also supn an < WI . 
The corresponding statement is not valid for the linear continuum. 
Proof: If An is an ordered set of type an for every n < w, then the set 
Un<w {n} X An is countable, since it is the union of countably many 
countable sets. If we order this set lexicographically, we obtain a well-
ordered set of type a = a o + al + a2 + ... , so that a < WI and an < a. 
The set X of numbers g ~ a such that g > an (n < w) is a well-defined 
subset of the well-ordered set [(a +- 1). Thus inf X exists; and we have 
inf X ~ a < WI with inf X = supn an , as was to be proved. 
Theorem 11. 
The set Q is not countable. 
The same statement holds for R. 
If Q = [(WI) were countable, we would have WI E [(WI), so that 
WI < WI , which is a contradiction. 
As mentioned earlier, the famous Cantor continuum hypothesis states 
10 For proofs of the equivalence see, for example, Birkhotf [1], pp. 42-44. The weIl-
ordering axiom has recently been proved to be independent of the other axioms of set 
theory (See lA, §7.6). 

1 Construction of the System of Real Numbers 
165 
that the sets Q and R have the same power. This hypothesis represents a 
postulate independent (see lA, §7.6) of the other axioms of set theory: 
The negation of the continuum hypothesis is also a possibility. 
Theorem 12. 
For every a E R the sets ( . , a)R , (a, . )R are isomorphic 
to each other and to R. 
The mapping x ~ l/(a -
x) + a represents an isomorphism between 
( . , a)R , and (a, . )R . 
On the other hand: for every a E Q the set ( . , a).Q is countable, and the 
set (a, . ).0 is not countable. 
Proof: Since O/(a) = a by Theorem 7, we see that /(a) is countable. 
But if the set (a, . ).0 were also countable, Q itself would be countable, 
since Q = /(a) U {a} U (a, . ).0, in contradiction to Theorem 11. 

CHAPTER 2 
Groups 
Introduction 
The concept of a group is a creation of modern mathematics. Some 
notion of it is to be found in the rich ornamentation of classical art and 
architecture, but its fundamental importance and varied applications were 
not recognized until the nineteenth century. 
The theory of groups originated in the study of algebraic equations, 
where its central importance was recognized by E. Galois, who introduced 
the name "group." The work of A. Cauchy, C. Jordan, A. Cayley, L. Sylow, 
O. Holder, G. Frobenius, I. Schur, and W. Burnside freed the theory 
from this subsidiary position and transformed it into an independent 
branch of mathematics, concerned with algebraic operations on sets of 
finitely or infinitely many elements. 
The late appearance of groups in science shows that a theory based on 
them could only have resulted from the modern mathematical method of 
generalization and abstraction, the method of thinking in terms of 
"systems." With such concepts as "set," "group," "ring," "field," mathe-
matics has reached a stage of great generality. The object of-its study is no 
longer the special character of certain magnitudes but the structure of whole 
domains. In this way it becomes possible to make statements that are 
valid for many different fields. For an over-all summary or synthesis of 
widely varied parts of mathematics, the notion of a group becomes indis-
pensable. 
For the theory of groups, as for all branches of modern science, the 
axiomatic method is characteristic. In this method it becomes unmistakably 
clear that the axioms and basic theorems are not necessarily "self-evident" ; 
in laying the foundations of a logically constructed science we have the 
complete "freedom of spirit" that G. Cantor called the very essence of 
mathematics. Choice of the axioms is restricted by only one condition: 
166 

2 Groups 
167 
freedom from self-contradiction. Whether we have made a useful choice is 
determined solely by the applications, which in group theory are especially 
numerous. Not only does this theory have many applications in other 
branches of mathematics, for example in Galois theory or in the founda-
tions and development of geometry, but its effectiveness and esthetic appeal 
make it an important instrument in other branches of science and art as 
well: in quantum theory, in crystallography, and in the theory of artistic 
form. 
1. 
Axioms and Examples 
1.1. 
Axioms 
Let (fj be a non-empty set and v a (binary) operation (often also called a 
product) on 6>, that is, a function on the set of ordered pairs (G, H) of 
elements G, HE (fj (cf. IBI0, § 1.2; in particular, 1.2.5). Then (fj is said to be 
a group with respect to v if the following four axioms are satisfied: 
(V) The values of v lie in (fj: 
v (G, H) E (fj for all G, HE (fj. 
(A) v is associative; that is, 
v (G, v (H, J» = v (v (G, H), J) for all G, H, J E (fj. 
(N) There exists a so-called neutral, or unit, or identity element N in (fj, 
with 
v(N, G) = v(G, N) = G for all G E (fj.l 
(I) Every element of (fj has an inverse; that is, for every element G E (fj 
there exists an element C, such that 
v(G, C) = N.2 
When there can be no doubt about the operation in question, the phrase 
"with respect to ... " is ordinarily omitted in the above definition of a 
group. 
From the axioms, as we shall see, it does not follow that 
(K) v (G, H) = v (H, G) for all G, HE (fj, 
1 It would be enough to require v (G, N) = G for all G E (fj, since (N) could then be 
derived from the other axioms, but we are not interested here in independence or 
other refined questions of axiomatic theory. 
2 An element with this property should really be called a right inverse; but we shall 
show later, on the basis of the other axioms, that it is also a left inverse [that is, that 
it satisfies v(G, G) = N]; and then it is simply called an inverse. 

168 
PART B ARITHMETIC AND ALGEBRA 
but if a group does satisfy (K), it is said to be Abelian or commutative. If 
v (G, H) = v (H, G) for the special elements G, HE (ij, then G and Hare 
said to be permutable. For example, by(N) the element N is permutable with 
all the elements of (r,. 
For simplicity, we shall generally write GHorG + Hin placeofv(G, H) 
and shall speak of the operation vas multiplication or addition. The additive 
notation is usually restricted to Abelian groups. 
The power \ (ij \ of the set (fj (see lA, §7.3) is called the order of (fj. If the 
order is finite, the group (fj is also said to be finite, and its order is simply 
the finite number of elements in (ij. 
1.2. 
Examples 
1.2.1. 
Let r+ be the set of rational integers 0, ± 1, ± 2, ... and let 
v (G, H) = G + H be the sum of the numbers G and H in the usual sense. 
Then (V) is certainly satisfied, and (A) holds because addition is associative, 
as is shown in the foundations of the theory of numbers (see IBI, §1.3, 
§2.2). Thus, 
(G + H) + J = G + (H + J). 
The number 0 has the properties of a neutral element: G + 0 = 0 + G = 
G, and -G is inverse to G: G + (-G) = O. Thus r+ is a group, and is 
Abelian because (K) holds. Its order is No. 
1.2.2. 
Let P+, R+, and e+ be the set of rational, real, and complex 
numbers, respectively, and again let v (G, H) = G + H be addition in the 
usual sense. Then the axioms (V) through (I) hold as in 1.2.1, so that each 
of these sets is an Abelian group with respect to addition. The order of P+ 
is No , and the order of R+ and e+ is the power of the continuum. 
1.2.3. 
Let Px, RX, ex be the set of nonzero rational, real, and complex 
numbers, respectively, and let v (G, H) = GH be multiplication in the 
ordinary sense. Since multiplication of nonzero numbers is associative and 
the product is also nonzero, axioms (V) and (A) are satisfied. The number 
1 has the properties of a neutral element, and G-l is inverse to G. Since (K) 
holds, the groups Px, RX, and ex are all Abelian. Their orders coincide 
with the corresponding orders in example 1.2.2. 
1.2.4. 
Let ~ be the following set of quotients of polynomials in x: 
~ 
1 
x-I 
I 
x 
I 
~ = x, -, I -
x, ---, -1--' 
I /. 
x 
x 
-x x-
, 
For G, H E ~ let v (G, H) consist of the substitution of G into H. In other 
words, the operation v (G, H) consists of replacing the symbol x in H by the 
element G. For example, if 
x 
G = g(x) = --, 
x-I 
H = h(x) = 1 -
x, 

2 Groups 
then 
1 
v(G, H) = -1--' 
-x 
169 
Bya finite number of trials we see that the result of this operation is always 
one of the six functions, so that (V) is satisfied. In order to show that the 
operation is associative, we could in principle test the validity of (A) for 
all the finitely many triples of elements. Less rigorously, we see that in 
performing the operation v(G, v (H, K» we first replace x in K = k(x) by 
H = h(x); and then, in the expression v (H, K) = k(h(x» thus obtained, 
we replace x by G = g(x), with the final result k[h(g(x»]. But it is clear 
that the same result will be obtained if we first construct the expression 
v (G, H) = h(g(x» and then replace k(x) by x, so as to obtain v (v(G, H), K). 
In this group x serves as neutral element, the elements x, I/x, 
I -
x, x/ex -
I) are their own inverses, (x -
l)/x is inverse to 1/(1 -
x), 
and 1/(1 -
x) is inverse to (x -
l)/x, as can easily be verified. Thus ~ is 
a group of order 6 and is not Abelian; for example, 
( I 
) 
x-I 
1 
( 
1) 
v -
I-x =----::1---= v l-x-. 
x' 
x 
I-x 
'x 
1.2.5. 
Let 9l be a set, which we shall now call a space in order to distin-
guish it from other sets to be considered later; and correspondingly, its 
elements P, Q, R, ... will be called points. Let em be the set of permuta-
tions on 9l; that is, the set of one-to-one mappings of 9l onto itself. If 
a E e 9l, we denote by Pa the image of the point P E 9l under the mapping 
a. Then a has the following properties: 
(1) 
(2) 
Pa E9l for all P E9l, 
More generally, if for a subset ,0 C 9l and a subset Sl C em we denote by 
.QSl the set of elements Pa, PEn, a E Sl, then the fact that a is a mapping 
onto 9l is equivalent t03 
(3) 
9la = 9l. 
Thus (1), (2), and (3) characterize the permutations a among all the 
mappings of 9l. In em we now introduce the following product: for 
a, TEem we define the mapping aT (see Figure 1) by 
(4) 
peaT) = (Pa)T. 
3 No distinction is made here between an element and the set containing it as sole 
member. Thus a in (3) in fact represents {a}, the set consisting only of a. 

170 
PART B ARITHMETIC AND ALGEBRA 
Thus aT is the mapping of9t which results from successive applications of 
the mappings a and T. We now show that with this operation e9t is a group. 
Fig. 1 
",~fG 
",'" 
1\ 
",G.,,'" 
: \~ 
'" 
I 
\ 
o~~--------~--~~r 
P 
(ST 
I 
I 
I 
/ 
Fig. 2 
Tr\ /f 
I, 
'/ 
'If Pffiiflf • Petr;J 
(V): We must show that aT has the properties (1), (2), (3). 
(1): 
Since Pa E9t and PT E9t for all P E9t, we have P(aT) = (Pa)T E9t 
for all P E9t. 
(2): 
If P1(aT) = P2(aT), then (P1a)T = (P2a)T, and thus PIa = P2a 
and PI = P2, since (2) holds for a and T. 
(3): 
Since 9ta = 9tT = 9t, it follows that 9t(aT) = (9ta)T = 9tT = 9t. 
(A): 
On the one hand, we have 
P[(aT)p] = [P(aT)]p = [(Pa)T]p, 
for all P E 9t and a, '1', p E e 9t, and on the other hand 
P[a(Tp)] = (Pa) (Tp) = [(Pa)T]p, 
as follows (see Figure 2) from (4). 
(N): The mapping 1 defined by P1 = P for all P E 9t is a permutation, 
the so-called identical permutation. For this permutation we have 
P(1a) = (P1)a = Pa 
and 
P(a1) = (Pa)1 = Pa, 
so that 1 a = a1 = a; and therefore 1 has the properties ,of a neutral 
element. 
(I): 
In order to prove the existence of an inverse for a E e9t, it must be 
remembered that since P runs through all the elements of 9t exactly once, 
so will Pa, by (2) and (3). Thus, 
(5) 
(Pa)a = P 

2 Groups 
171 
defines a mapping U of9t for which (1), (2), and (3) are satisfied. From (5) 
we see at once that au = 1, so that u is an inverse of a and therefore (I) 
is satisfied. 
The group 69t is called the symmetric group on 9t. When we examine it 
more closely, as we shall do below, we see that for finite 9t the order is 
I 9t I !, where I 9t I is the power of 9t. 
In order to be able to deal more conveniently with multiplication in 6 9t, . 
we identify each of its elements a with a symbol consisting of two rows: 
the first row contains every point of 9t exactly once and, directly under-
neath, the second row contains the images of these points: 
( P 
Q 
R 
... ) 
a = 
Pa 
Qa Ra ... . 
Two such symbols represent the same permutation if and only if they can 
be transformed into each other by a permutation of the columns. Since a 
is a permutation, the second row also contains every element of 9t exactly 
once. 
If we denote by (n) the set of natural numbers 1, 2, ... , n, then the six 
elements 
-c 
2 ;), 
a= G 
2 i), 
~= G 
2 ;), 
-1 2 
3 
1 
y= G 
2 ;), 
8 = G 
2 i), 
€ = G 
2 ;) 
3 
2 
1 
comprise all the permutations of 6(3). The mUltiplication of ~ and 8, 
for example, leads to 
~8 = G 
2 ;)G 
2 i) = (~ 
2 ;), 
1 
2 
3 
which may be read as follows: 1 in ~ into 3, 3 in 8 into 1, therefore 1 in ~8 
into 1, and so forth. On the other hand, the product 8~ produces 
Thus the group 6(3) is not Abelian. 
For computation in the space 9t with 19t I = n this standard model of 
6(n) is very convenient.4 
1.2.6. 
Let E2 be the Euclidean plane and let (P, Q) be the distance 
between two of its points P, Q. Also, let B2 denote the set of permutations 
, The symbol 6 n is often written in place of 6 In). 

172 
PART B ARITHMETIC AND ALGEBRA 
a on E2 (regarded as a set of points) which leave invariant the distance 
between every pair of points: 
(Pa, Qa) = (P, Q). 
Then B2 is a group under the same operation as for the permutations in 
1.2.5; for now 
(V): If a, '1' E B2, then 
(P(aT), Q(aT) = «Pa)T, (Qa)T) 
= (Pa, Qa), 
= (P, Q), 
since 
'1' E B2, 
since 
a E B2• 
Thus the product aT also leaves invariant the distance between every pair 
of points. 
(A) was already proved in §1.2.5 for the product of any two permuta-
tions. 
(N): 
The identical permutation 1 (see §1.2.5) is an element of B2: 
(P1, Q1) = (P, Q). 
(I): 
We shall show that if a is in B2 , then the permutation a defined in 
§ 1.2.5 is also in B2: for let P, Q E E2 and in accordance with (3) let 
P = P*a, Q = Q*a with P*, Q* E E2 ; then 
(Pa, Qa) = «P*a)a, (Q*a)a) 
= (P*(aa), Q*(aa) 
= (P*, Q*) 
= (P*a, Q*a) 
= (P, Q), 
so that a E B2. But it was shown in § 1.2.5 that aa = 1, so that B2 is in fact 
a group. If we think of E2 as a rigid plate, the elements of B2 are represented 
by those motions of the plate which bring it into coincidence with itself 
without distortion. Thus the elements of B2 are called the motions5 of E2 
and B2 is the group of motions of E2 . 
1.2.7. 
A subset F of the set of points of the Euclidean plane E2 is 
called afigure. For a given figure Fwe consider the set B 2•F of motions a in 
B2 which map F onto itself; that is, those motions for which, in the notation 
introduced for permutations in § 1.2.5, we have 
(6) 
Fa= F. 
II They are also called rigid mappings. 

2 Groups 
173 
If the elements of B2,F are combined in the same way as in the preceding 
examples, then B2,F is a group: for we have 
(V): If Fa = F, F-r = F, then also F(a'T) = (Fa)'T = F'T = F, so 
that a'T E B2,F • 
(A) holds for arbitrary permutations, as was shown in § 1.2.5. 
(N): 
The mapping 1 defined in § 1.2.5 is in B2,F since F1 = F. Since 
1 a = a1 = 1 for arbitrary permutations a on E2 , the mapping 1 is 
certainly a neutral element for B2,F • 
(I): If a belongs to B2,F, then so does the element 6 defined in §1.2.5; 
for if P E F and, in accordance with (6), P = P*a, p* E F, 
then 
P6 = (P*a)6 = p* E F, so that every a has an inverse in B2,F • 
The group B2,F is called the group of the figure F. As an example let us 
consider the group of the four corners of a square in E2 • It is easy to see 
that this group is the same as the group B2,o of the entire square deter-
mined by these four corners. 
A motion a of this group is completely characterized by the correspond-
ing permutation of the four corners, since every point of E2 is determined 
by its distances from three noncollinear fixed points. 
If we denote the corners by 1,2,3,4 (see Figure 3), we 
see that not all permutations of the corners can result 
from a rigid motion; for example, 
( I 
2 
3 4) 
124 3 
'0 
1 
2 
FIG. 3 
cannot represent a motion, since the distance is (1 a, 4a) = (1, 3) -=I=- (1, 4). 
The permutations induced by B2,o are obviously 
G 
2 
3 :), G 
2 
3 
~), G 
2 
3 
~), 
(! 
2 
3 
~), 
2 
3 
3 4 
4 
1 
I 
2 
(! 
2 
3 
~), G 
2 
3 
~), 
G 
2 
3 
~), G 
2 
3 :). 
3 2 
I 
4 
4 
3 
2 
The order of the group B2,o is therefore 8. This group is not Abelian, as 
the reader can easily verify. 
The developments of §1.2.6 and §1.2.7 are independent of the dimension 
2 of E2• Thus for the n-dimensional Euclidean space En , with arbitrary 
natural number n, we can define the group of motions Bn as the set of 
permutations on En which leave invariant the distance between any two 
points; and the corresponding remark holds for the group Bn,F . 

174 
PART B ARITHMETIC AND ALGEBRA 
1.2.8. 
Let m be a set and let ~m be the set6 of all its subsets, including 
the empty set 0. For a, b E ~m we now define an operation (written addi-
tively) as follows (cf. lA, 9.10): 
q U 1) -
q n 1) = q + 1). 
Thus a + b consists of those elements of m which belong to exactly one of 
the sets a, b (see Figure 4). Then the set ~m with this multiplication is a 
group. For we have (V): a + b is a 
subset (possibly 0) of m. (A): Let us 
determine which elements lie in 
(a + b) + c, a, b, c E ~m. For this 
purpose we think of the elements of a 
as being marked with a cross, and 
proceed in the same way for the ele-
ments of b. Then a + b consists of 
those elements that have been marked 
with exactly one cross. If we now 
mark the elements of c with a cross, 
then (a + b) + c contains exactly 
those elements ofm which have been 
FiG. 4 
marked with either one cross or three 
crosses. If we construct a + (b + c) 
in the same way, the elements of this subset also receive either one 
cross or three crosses. But since the number of crosses depends only on 
the sets a, b, c and not on the parentheses, the result is the same in both 
cases. Thus (a + b) + c = a + (b + c). 
(N): The empty set 0 has the properties of a neutral element. 
(I): The element a is its own inverse for all a E ~m, since a + a = 0. 
The group ~m is obviously Abelian and has the order 21ml, where Iml is the 
power ofm. 
1.2.9. 
If n is a natural number, it is shown in the theory of numbers 
(see IB6, §2.10) that every rational integer g can be represented in the form 
(7) 
g = nh + r, 
where the rational integers h, r are uniquely determined by g, and r is a 
reduced remainder for n; that is, 0 ~ r < n. Such remainders are often said 
to be reduced modulo n. 
In the set {O, 1, ... , n -
I} of reduced remainders for n, we define an 
additively written operation as follows. In order to distinguish this 
II The notation here is intended to suggest the name of G. Boole, who was the first 
to consider this definition for the multiplication of subsets. 

2 Groups 
175 
operation from the usual addition + for rational integers, we denote it by 
EE> and set 
s EE> 1 = r, 
where s, 1 are reduced remainders for n, and r is the reduced remainder 
uniquely determined by (7), of g = s + 1 (in the ordinary sense of addi-
tion). We now show that the set of reduced remainders for n thus becomes 
a group: 
(V) 
is obvious. 
(A): 
We must prove that (s EE> 1) EE> u = s EE> (1 EE> u). For this purpose 
we set, as in (7), 
(8) 
s + 1 = nh + r, 
r + u = ni + p. 
Thus (s EE> 1) EE> u = p. Similarly, if we set 
1 + u = nj + q, 
s + q = nk + 0, 
(9) 
then s EB (1 EE> u) = o. From (8) it follows that 
s + 1 + u = n(h + i) + p, 
and thus from (9) that 
s + 1 + u = n(j + k) + o. 
Thus p = 0, since by (7) these representations are unique. 
(N): 
The number 0 has the properties of a neutral element. 
(I): The inverse for r is n -
r if r -=I=- 0 and is 0 if r = O. 
We denote this group by r<n)+; it is Abelian and its order is n. 
1.2.10. 
In order to construct the corresponding group of reduced 
remainders with mUltiplication as the operation instead of addition, we 
restrict ourselves to those remainders that are prime to n (i.e., have no 
factor in common with n (see IB6, §2.6), and then we denote the operation 
(in order to distinguish it from ordinary multiplication of rational integers) 
by O. We now set 
sOl = r, 
where r is the reduced remainder of g = s . 1 (under multiplication in the 
ordinary sense) and is therefore uniquely defined by (7). With this opera-
tion the reduced remainders prime to n form a group. For we have 

176 
PART B ARITHMETIC AND ALGEBRA 
(V): 
If (s, n) = (t, n) = I and, by (7), 
st = nh +- r, 
then also (r, n) = (st -
nh, n) = I. 
(A): 
Let s, t, u be reduced remainders and, as in (7), let 
st = nh +- r, 
(10) 
and 
(11) 
ru = ni +- P 
tu = nj +- q, 
qs = nk +- o. 
Then (s 0 t) 0 u = p, s 0 (t 0 u) = o. From (10) it then follows that 
stu = n(hu +- i) +- p, 
and from (11) that 
stu = n(js +- k) +- o. 
By the uniqueness of (7) we therefore have P = o. 
(N): The number I has the properties of a neutral element. 
(I): 
In order to show that every element r has an inverse, we determine 
rational integers r, Ii (see IB6, §2.9) such that 
rr +- nli = I, 0 < r < n. 
Then (r, n) = I and rr = n . (-Ii) +- I, so that r 0 r = I, as desired. 
We denote this group by r(n)x; it is Abelian and (see IB6, §4.2, §5) has the 
order 
where n = PI 1 ... p~r, with distinct primes PI, ... , Pro 
1.2.11. We consider the set (f(3) of real numbers 
g +- h Y3, 
where g, h are rational integers and (g +- h y3) (g -
h y3) = g2 -
3h2 = I. 
The set (f(3) forms a group under ordinary multiplication .of real num-
bers. For we have 
(V): If 
(12) 
then 

2 Groups 
is a number in (f(3), since it follows from (12) that 
(glg2 +- 3h1h2)2 -
3(glh2 +- g2hl)2 = I. 
(A) holds for all real numbers. 
177 
(N): The number I = I+-O y3 has the properties of a neutral 
element. 
(I): 
Since 
(g +- h Y3)(g -
h Y3) = g2 -
3h2 = I, 
the number g -
h y3 is inverse to g +- h Y3. The group (f(3) is Abelian, 
and by the theory of sets (see lA, §7.3) it has the order No, since if 2 + y3 
is in the group, then by (V) the numbers (2 +- y3)r, y = I, 2, ... are also 
in (f(3); but these numbers are all distinct since 2 +- y3 > I and the one-to-
one mapping (g, h) ---. g +- h y3 puts (f(3) in correspondence with a sub-
set of the countable set of all integral lattice points of a coordinate plane. 
In this proof of the properties of a group the number 3 has played no 
particular role; the reader should consider how the group (f(n) is to be 
defined in a corresponding way for every natural number n. 
1.2.12. 
Let K be a field and let K; be the set of square matrices (see 
IB3, §2.2, §3.4) 
(13) 
of order n with nonzero determinant. This set forms a group under the 
operation of matrix multiplication. For we have 
(V): If A, B E K;, and if we let 1 X 1 denote the determinant of a 
matrix X, then by the rule for the mUltiplication of determinants 
IA·BI=IAI·IBI; 
thus, if 1 A I, 1 Blare nonzero, so is 1 AB I· 
(A): The associativity of matrix multiplication will be proved in IB3, 
§2.2. 
(N): 
The unit matrix 
(: 
:) 
has the properties of a neutral element. 

178 
PART B ARITHMETIC AND ALGEBRA 
(I): Inverse to A is the matrix (Aki/I A I), where Aki is the algebraic 
complement of aki, as is discussed in detail in IB3, §3.5. 
1.3. 
Examples of Systems That Are Not Groups 
After the numerous examples of groups in the preceding section, the 
reader may possibly feel that it is difficult to avoid satisfying the axioms 
for a group. For greater clarity we shall now give some examples of sets 
with an operation that does not make the set into a group. 
1.3.1. 
Let N be the set of all natural numbers (excluding 0), and for 
n, mEN let 
v(n, m) = nm 
(with multiplication in the ordinary sense). Then (V), (A), and (N) are 
satisfied but no n -=I=- 1 has an inverse. 
1.3.2. 
For r, s E R, where R is the set of real numbers, let the operation 
consist of taking the maximum 
v (r, s) = max (r, s). 
Then (V) and (A) are satisfied, but there is no neutral element and therefore 
the concept of an inverse remains undefined. 
1.3.3. 
Let I' be the set of rational integers excluding the two numbers 
+2, -2. For g, h E f'let 
v(g, h) = g + h 
(with addition in the ordinary sense). Then (A) is satisfied, 0 has the 
properties of a neu tral element, - g is inverse to g and is contained in 1', 
but (V) is not satisfied since v (1, 1) ~ 1'. 
1.3.4. 
Let N* be a set of all natural numbers including O. For n, mE N* 
set 
v (n, m) = I n -
m I 
(where the vertical bars denote absolute value). Then (V) is satisfied, 0 has 
the properties .of a neutral element, n is its own inverse, but (A) is not 
satisfied, since 
v (l, v (2, 3) = I 1 - I 2 -
3 I I = 0, 
v (v (1, 2), 3) = I I 1 -
2 I -
3 I = 2. 
2. 
Immediate Consequences of the Axioms for.a Group 
To simplify the notation, we shall henceforth write the group operation 
multiplicatively, except where otherwise noted. 

2 Groups 
179 
2.1. 
As was proved in IBl, §1.3 for an additively written operation, it 
follows from the associative law (A) that the value of a product of more 
than three factors depends only on the order of the factors and not on the 
way in which they are combined in parentheses. For example, 
and so forth. Thus we can omit the parentheses and for an ordered system 
of elements C1 , ... , Cr simply write 
Then 
2.2. 
In (N) it was not assumed that a group has only one neutral ele-
ment. But if N' is also an element with the properties required by (N), then 
NN'=N, 
NN'=N', 
and therefore N = N'. Thus the neutral element in a group is uniquely 
defined; if the group is written multiplicatively, we call the neutral element 
a unit element 1 ; but if additively written, a zero element O. 
2.3. 
Again, in (I) it was not required that an element G E (fj should 
have only one inverse. But it follows from the other axioms that if C is an 
inverse of G and 0 is an inverse of C, then 
GCO = 1 ·0 
= G· 1, 
and so 
(1) 
o = G 
and 
(2) 
CG = CO = I. 
Now if 0 is also an inverse of G, we have GO = I, and by multiplication 
on the left with C, 
CGO = C. 

180 
PART B ARITHMETIC AND ALGEBRA 
From (2) it follows that C = C, so that the inverse of G is uniquely 
determined; in the multiplicative notation we denote this inverse by G-I. 
Then by (1) and (2) we have 
(G-I)-l = G, 
(3) 
GG-I = G-IG = 1, 
so that G is permutable with its inverse. In the additive notation we write 
- G in place of G-I. Then the rules (3) read 
-
(-G) = G, 
G + (-G) = (- G) + G = o. 
In place of G + (-H) we may also write the shorter form G -
H, but 
then, in contrast to the situation for the group operation +, we must pay 
attention to parentheses. For example, in r+ (§1.2.1), 
(3 -
4) -
5 -=I=- 3 -
(4 -
5). 
It is easy to prove the following important rule for the formation of in-
verses: 
(4) 
2.4 From the uniqueness of inverses it follows that a group (fj allows 
unique two-sided division. More precisely: if G, H are arbitrary elements of 
(fj, there exist uniquely determined elements X, Y E (fj, for which 
(5) 
GX=H, 
YG= H. 
In fact, the elements X = G-IH and Y = HG-I have the desired property: 
GG-IH = 1 . H = H, 
HG-IG = H· 1 = H, 
and from GXI = GX2 , and YIG = Y2G, it follows after multiplication by 
G-I on the left and on the right, respectively, that G-I GXI = G-I GX2 , 
and YI G G-I = Y2G G-l, so that Xl = X 2 and YI = Y2 , which proves 
the desired uniqueness. 
We now show that in the definition of a group we may replace the axioms 
(N) and (I) by two axioms symmetrically constructed with respect to 
multiplication on the left and on the right: 

2 Groups 
For every ordered pair (G, H), G E (fj, HE (fj we have 
(Dr) an element X E (fj with GX = H, and 
(D.) an element Y E (fj with YG = H. 
181 
Thus we must prove that (N) and (I) follow from (V), (A), (Dr), and (D.). 
To this end, for a fixed G E (fj, we determine R by (Dr) from the equation 
GR= G, 
R E (fj. 
If H is an arbitrary element of (fj and Y is determined by (D.) from the 
equation YO = H, then 
HR = (YG)R = Y(GR) = YG = H, 
and so 
H R = H for all HE (fj. 
In the same way, for the element L E (fj determined by (D.) from LG = G, 
it follows that 
LH = H for all HE (fj. 
Thus, in particular, LR = Land LR = R, so that L = R = N is the 
neutral element. Then (I) follows at once from (Dr)' if we set H = N. 
Since we have already shown that (Dr) and (D.) follow from (V), (A), (N), 
(I), we see that the two systems of axioms (V), (A), (N), (I), and (V), (A), 
(Dr), (D.) are equivalent, as desired. 
For a finite group (fj, the axioms (Dr) and (D.) can be replaced by the 
following axioms of cancellation: 
(Kr): If GXl = GX2 , then Xl = X 2• 
(K.): If YlG = Y2G, then Yl = Y 2• 
To prove this we consider, for an arbitrary but fixed G E (fj, the map-
pings 
X ---+ GX, 
X E (fj, 
Y ---+ YG, 
Y E (fj 
of(fj into (fj. By (Kr) and (K.) these two mappings are one-to-one and thus, 
since (fj is of finite order, they are mappings onto (fj (see IBl, §1.5). 
Consequently, every element HE (fj has the form H = GX and H = YG, 
so that (Dr) and (D.) are satisfied. Since we have already proved for arbi-
trary groups that (Kr) and (K.) are satisfied, it is clear that for a finite set 
(ij the system of axioms (V), (A), (N), (I) is equivalent to the system 
(V), (A),(Kr),(K.). But,as is shown by the example in§1.3.1, this equivalence 
does not necessarily hold for infinite sets (fj. 

182 
PART B ARITHMETIC AND ALGEBRA 
3. 
Methods of Investigating the Structure of Groups 
The great importance of group theory is due to the fact that a few simple 
axioms give rise to a great wealth of theorems. Because of the simplicity 
and naturalness of its axioms, the theory of groups has penetrated deeply, 
as the above examples show, into many parts of mathematics, so that its 
theorems may be interpreted, according to the fields to which they are 
applied, as theorems about numbers, permutations, motions, residues, and 
so forth. 
Consequently, if we wish to describe these theorems in a natural way, 
we cannot remain satisfied with the meager vocabulary of the axioms. In 
the theory of numbers, for example, it is impossible to give any reasonably 
concise description of the results without introducing such terms as "divis-
ible," "prime number," and so forth; and we must now turn to the con-
struction of a corresponding set of instruments for the analysis of groups. 
3.1. 
Calculq,tion with Complexes 
Let us consider a fixed group 6) and subsets Sl, including the empty set 
0, of its set of elements. Such subsets will be called complexes of 6). As 
is customary in the theory of sets, we can give a precise description of a set 
by enclosing its elements in braces { }. For example, in the notation of §1.2.5 
we have 
(n) = {I, 2, ... , n}. 
If the elements of a set are defined by certain properties, these properties 
are written to the right of a vertical stroke; for example (see §1.2.3) 
{a I a E RX, a-I = a} 
is the set of numbers in RX for which a-I = a; that is, the set {I, -I}. 
Since the complexes of a group are subsets of a set, we have already 
defined for them the set-theoretic concepts (see lA, §7.2) "equal" =, 
"contained in" C, "properly contained in"· C, "intersection" (\ and 
"union" u; the last two are applicable to an arbitrary set K of complexes; 
for them we write n!ReKSl and U!ReKSl. 
If Sl and £? are complexes of 6), we define the complex-product Sl£? as the 
complex consisting of all elements representable in the form KL with 
K ESl, L E £?: 
Sl£? = {KL IKE Sl, L E £?}. 
For example, in §1.2.3 for 6) = px and Sl = {I, !, l}, £? = {-2, 1, l} we 
have 
Sl2 = {-2, t, i, -I, ·h, -~-, 1;-, -h}; 

2 Groups 
183 
and in §1.2.5, for (fj = 6(3) and Sl = {I, ~}, £? = {I, y, cx}, 
Sl£? = {I, y, cx,~, €}. 
If(fj is written additively, we writeSl + £? in place ofSl£? For (fj = r+ and 
Sl = {g I g E r+, 2 divides g}, £? = {g I g E r+, 4 divides g} we thus have 
Sl + £? = {g I g E r+, 2 divides g}. 
This multiplication of the complexes of a fixed group is associative, as 
follows from the associativity of the operation of the group, and can thus 
be extended to more than two factors without use of parentheses. In 
general, multiplication of complexes is not commutative, as can be seen by 
calculating the elements of £?Sl in the above example for the group 6(3). 
By Sl-l we denote the complex consisting of the inverses of the elements 
of the complexSl: thusSl-1 = {G-l I G E Sl}. Then we have (Sl£?)-l = £?-l Sl-l 
by §2.3.(4). 
For unions of complexes the following distributive law holds for com-
plex multiplication: 
(1) 
Sl (£? u 9J1) = Sl£? u Sl9J1, (£? u 9J1) Sl = £?Sl u 9J1Sl, 
but for intersections only a weaker form of distributivity is valid: 
But if Sl = G contains only one element, then here also we have the 
equality: 
(3) 
G (£? (\ 9J1) = G£? (\ G9Jl, (£? (\ 9J1)G = £?G (\ 9J1G. 
The laws (1) and (2) will not be needed below; the proof of (3) is as 
follows: since HE G(£? (\ 9J1) is equivalent to G-IH E £? (\ 9J1, it follows that 
H E G£? and H E G9J1. 
For a given complex Sl the complexes of the form G-lSlG, G E (fj are 
called the conjugates or transforms of Sl (under (fj). If Sl is conjugate only 
to itself, then Sl is said to be normal or invariant in (fj. For example, I is 
normal in (fj. Furthermore, the whole group (fj is a normal complex, since 
for G E (fj we have: 
(4) 
(fjG = G(fj = (fj, 
or 
G-l(fjG = (fj, 
since the equations §2.4(5) have solutions for every pair G, HE (fj. Also, it 
is clear that 
(5) 
(fj(fj = (fj, 

184 
PART B ARITHMETIC AND ALGEBRA 
and finally we note that since (G-l)-1 = G, we have: 
(6) 
m-l = m. 
3.2. 
Subgroups 
We now turn our attention to a concept, already used in the examples in 
§§1.2.6 and 1.2.7, which is of great importance in studying the structure of 
groups. IfU is a complex from a group m, it may happen that the complex 
U forms a group with respect to the operation of group m. Examples are 
provided by the set B2 of motions on £2 regarded as a complex from the 
group of all permutations on £2 , and also by the set of motions which map 
a figure onto itself, regarded as a complex in the set of motions B2 • We 
describe this situation by saying that U is a subgroupofm, by which we mean 
that under the operation v defined for m the set U satisfies axioms (V), (A), 
(N), and (I). Thus B2 and B2,F are subgroups of 6 E2 and B2, respectively. 
The complex 51 = {I, -1} is not a subgroup of r+; it is true that Sl is a 
group with respect to multiplication of numbers, but that is not the opera-
tion with respect to which r+ is defined as a group. The sets 1 and mare 
subgroups of every group m. Subgroups other than these trivial (improper) 
subgroups 1 and (f> are called proper subgroups. 
If U is a subgroup of (f), the unit element 1 of (fj must be contained in U 
and must also be the unit element of U. For if V E U and I u is the unit 
element ofU, so that 1 u U = U, then this equation for 1 u must also hold in 
(fj and, by the uniqueness of division in (fj, its solution 1 u = 1 is unique. 
Similarly, we can easily show that the inverse of V in U is equal to its inverse 
V-I in m. 
In order to test whether a given complex is actually a subgroup it would 
be necessary, from a formal point of view, to examine all the four axioms 
for a group. But as is shown by the examples in §§1.2.6 and 1.2.7, this proc-
ess can be shortened: for example, if the axiom (A) of associativity holds 
for m, then it certainly holds for the elements of a subset of m. We now 
prove the following criterion for subgroups, whereby the process can be 
still further shortened: 
A non-empty complex U c: m is a subgroup ofm if and only if 
(7) 
UU-l c: U. 
The necessity of this condition (7) is clear at once from (5), (6), and the 
properties of inverses in U. 
In order to prove that the criterion is also sufficient, we let U be a complex 
in m which satisfies (7). For arbitrary U E U we then have 1 = UU-l EU, 
so that (N) is satisfied by the neutral element 1 in m. Moreover, 
1 U-l = U-l E U, so that (I) is satisfied. Also, for U1 , U2 E U, we have 
U1( U;I)-1 = U1 U2 E U, so that (V) is satisfied. Also, we have just seen that 

2 Groups 
185 
(A) holds in U because it holds in (fj. Thus U is a subgroup of (fj, as was to 
be proved. 
3.3. 
By means of this criterion for subgroups it is easy to show that the 
following examples are subgroups: 
3.3.1. 
Complex of even numbers in r+. 
3.3.2. 
Complex {I, -I} in px, RX, and ex. 
3.3.3. 
Complex U(3) = {I, cx, {J} in 6(3) (§1.2.5). 
3.3.4. 
Complex 6~ of permutations in 6 IR (§1.2.5) that leave fixed a 
given point P E 9l. 
The reader will readily verify §3.3.1-3; and in order to show §3.3.4 we 
need only point out, in view of the criterion for subgroups, that if a and T 
leave the point P fixed, then so does aT-I: 
3.4. 
IfU is a subgroup of (fj, the conjugate complexes (fj-l G, G E (fj are 
also subgroups of (fj. For by §2(4), §3(5), (6) we have 
G-IUG(G-IUG)-1 = G-IUGG-IUG = G-IUG, 
so that (7) is satisfied with G-IUG in place of U. 
IfU is a subgroup of(fjandID is a subgroup ofU,thenID is also a subgroup 
of (fj, as follows immediately from the criterion for subgroups. Thus the 
property of being a subgroup is transitive. 
If Olt is a set of subgroups of (fj, the intersection Xl = nUe'1lU is also a 
subgroup of (fj; for if U1 , U2 are in every U E Olt, then by (7) it follows that 
U1 U;:1 is in every U E Olt. On the other hand, the condition (7) is sufficient, 
and therefore Xl is a subgroup. 
Thus for every complex Sl ~ (fj there exists, as the intersection of all 
subgroups U J Sl, a smallest subgroup <Sl) of (fj containing Sl: 
<Sl) = () U. 
5l~U 
This subgroup is said to be generated by Sl, since <Sl) consists of all the 
finite products Sl~l ... Sl;r , €i = ± 1; in other words, of all the products 
that can be "generated" by the elements Kl , ... , Kr E Sl: for we see at once 
from (V) and (I) that all such products must lie in <Sl) and, on the other 
hand, the criterion for subgroups shows the complex of these elements is 
a subgroup of (fj containing Sl. A complex Sl for which (fj = <Sl) is called 
a system of generators of (fj, and (fj is said to be generated by Sl. If there 
exists a finite complex Sl = {El , ... , En} with this property, then (fj is said 
to have afinite system 0.( generators, or to be finitely generated. The mini-
mum number n of such generators is called the number of generators of (fj. 

186 
PART B ARITHMETIC AND ALGEBRA 
The set of subgroups U, m of a group forms a lattice (see IB9, 2.1) with 
respect to the operations (U, m) ---. U (\ m and (U, m) ---. <U u m). This 
lattice provides us with an easily visualized method for studying the con-
struction of a group. We give the graphs (also called diagrams; see lA, 
§9.5) of the lattices of subgroups for some of our examples: r(6l+, §1.2.9 
(Figure 5); 6(3), §1.2.5 (Figure 6); B2 •Q , §1.2.7 (Figure 7); ~{I.2.3}, §1.2.8 
(Figure 8). In Figure 7 the elements are written in the form of cycles; see 
§15.2.1. 
For many purposes it is preferable, for easier visualization, to consider 
only sublattices and their graphs; for example, any two subgroups U, m of 
a group (fj provide a finite sublattice with the graph represented in Figure 
9. In this case several of the subgroups may coincide. 
A subgroup U -=I=- (fj is said to be maximal in (fj if there exists no subgroup 
m -=I=- (fj of (fj containing U as a proper subgroup. Similarly, a subgroup 
U -=I=- 1 of (fj is minimal if U has no proper subgroup m -=I=- 1. 
3.5. 
Residue Classes or Cosets 
IfU is a subgroup of(fj, the complexes of the form UG and GU, G E (fj, are 
called right residue classes and left residue classes (or left eosets and right 
eosets), respectively. In this section we shall consider only right cosets. If 
H E UG, then UG = UH, since H has the form H = UG, U E U, so that 
U-IH = G and UG = UU-IH = UH, by (4). Thus: 
Either UG1 = UG2 or UG1 (\ UG2 = 0 for arbitrary cosets UG1 , UG2 • Since 
every element of(fj lies in some right coset ofU (becauseG = 1 . GEUG)the 
right cosets generate a division into classes (see lA, §8.5) of the set (fj. The 
power of the set of right cosets is called the index of U (under (fj) and is 
denoted by (fj : U. Since for U E U the mapping U ---. UG ofU onto UG is 
one-to-one because of the uniqueness of division, all the right cosets of U 
have the same power as U. Thus, 
(8) 
1 (fj 1 = «(fj : U) . 1 U I· 
For finite groups this fact was first proved by Lagrange. As a corollary, 
the order of a subgroup of a finite group (fj is always a factor of the order 
of (fj. 
' 
The right cosets of the subgroup 1 consist of the individual elements of 
(fj. Thus in place of 1 (fj 1 we may also write (fj : 1. Then (8) takes the form 
(fj : 1 = «(fj : U)(U : 1). 
Since the property of being a subgroup is transitive, it follows more gener-
ally from (8) that for any sequence of subgroups 
U1 JU2 J '" JUr 

2 Groups 
187 
of (fj we have: 
U1 : Ur = (U1 : UJ ... (Ur - 1 : Ur). 
The reader may verify these results in the graphs of Figures 5 through 9. 
A similar discussion of left cosets does not lead to any new results, since 
UG ---. G-IU is a one-to-one mapping of the set of right cosets onto the set of 
left cosets: every left coset is an image, and from G1
1U = G;lU it follows by 
taking inverses that UG1 = UG2 • The natural assumption that the set of 
right cosets is the same as the set of left cosets is false. Consider, for exam-
ple, 6(3) (§1.2.5) and 
u=~G ; ;),G 
~ ;)~={I,y}. 
In this case the set of right cosets is 
and the set of left cosets is 
Order 
3 
Fig. 5 
Order 
6 
Order 
It 
Order 
2 
{{I, y}, {ex, €}, {P,8}}, 
{{I, y}, {ex, 8}, {P, €}}. 
Order 
Order 
3 
Fig. 6 
6 
Order 
2 

188 
Order 
* 
Order 
2 
PART B ARITHMETIC AND ALGEBRA 
u 
Fig. 9 
Subgroups for which these two sets of cosets are the same (as would 
always be the case, for example, with Abelian groups) are extremely im-
portant, and we shall pay a good deal of attention to them later; they are 
called normal subgroups (see §6). 
4. 
Isomorphisms 
If we wish to illustrate the addition of numbers, it makes absolutely no 
difference what objects (fingers, apples) we use. Obviously, the important 
element in the situation is not what we add, but how. This phenomenon, 
which also occurs in group theory and elsewhere, will now be described as 
clearly as possible and given a mathematical formulation. 
4.1. It is obvious that the operation of a group is completely described 
by the following table: 
G 
H 
I 
G 
GG 
GH GI .. 
H 
HG HH HI .. 
I 
IG 
IH 
II 
The elements of (fj are entered in the left-hand column and in the top row 
and then the product GH is entered at the intersection of the G row and the 
H column. This table is called the multiplication table for (fj. 

2 Groups 
189 
For some of our earlier examples it will have the form: 
r(2)+ 
~m,m = {m} 
10 
10 m 
010 1 
010 m 
1 I 1 0 
mlm 0 
r(S)X 
6(3) 
I 1 3 5 7 
I 1 
ex 
f3 
y 8 
€ 
1 
1 3 5 7 
ex 
f3 
y 8 
€ 
3 3 1 7 5 
ex 
ex 
f3 
1 8 
€ 
Y 
5 
5 7 
1 3 
f3 
f3 
1 
ex 
€ 
y 8 
7 
7 5 3 1 
Y 
Y 
€ 
8 
f3 
ex 
8 8 y 
€ 
ex 
1 f3 
€ 
€ 
8 y f3 
ex 
1 
r+ 
0 
2 3 
-1 -2 -3 
0 
0 
1 2 3 
-1 -2 -3 
1 
1 
2 3 4 
0 -1 -2 
2 
2 
3 4 5 
1 
0 -1 
3 
3 
4 5 6 
2 
1 
0 
-1 
-1 
0 1 2 
-2 -3 -4 
-2 -2 -1 0 1 
-3 -4 -5 
-3 -3 -2 1 0 
-4 -5 -6 
The two-sidedness and uniqueness of division means that every element of 
the group will occur exactly once in each column and in each row. The 
reader should consider how the axioms (N) and (I), and such properties as 
the commutativity of multiplication, are reflected in these tables. 
If we look again at the multiplication table for the "group r(S)X, it is 
obvious that the operation of the group will be equally well described if 
we replace the Arabic numerals by Roman numerals, so that the table 
becomes: 
I 
I 
I 
III 
III 
V 
i 
V 
VII ! VII 
III 
V 
VII 
III 
V 
VII 
I 
VII 
V 
VII 
I 
III 
V 
III 
I 

190 
PART B ARITHMETIC AND ALGEBRA 
If in the example for ~m we had replaced 0 and m by the numbers 0 and 1, 
we would have obtained the multiplication table for our example r(2l+. 
The phenomenon arising in this way from the renaming of elements can be 
described mathematically as follows. 
4.2. 
If (fj is a group and A is a one-to-one mapping of (fj onto a group 
~ such that the image of each product is equal to the product of the images, 
or in other words if 
(1) 
then A is said to be an isomorphism of (fj onto~. If such an isomorphism 
exists, we say that (fj and ~ are isomorphic, or that they are of the same 
type, or the same structure, and write (fj r'-I ~. 
As an exercise, the reader may set up an isomorphism between the group 
~ (§1.2.4) and 6(3). 
If(fj and~ are isomorphic, they obviously have the same order, and from 
the definition it is clear that an isomorphism A also has the following 
properties: 
4.2.1. 
The image of the unit element is the unit element. 
4.2.2. 
If G-l is the inverse of G E (fj, then (G-l)A = (GA)-l, which we 
abbreviate to G-A. 
4.2.3. The image of a subgroup is a subgroup. 
4.2.4. 
The image of a normal complex is normal. 
4.2.5. 
If(fj is Abelian, then every group isomorphic to (fj is also Abelian. 
The reader will readily prove §4.2.2, 3, 5; as examples let us show: 
4.2.1. 
Since P . P = (1 . I)A = 1\ it follows that P is the unit ele-
ment of~. 
4.2.4. 
Since every element of ~ is an image under the isomorphism, 
the statement follows from the fact that GASVG-A = (GSlG-l)A for all 
H = 
GAE~. 
An isomorphism determines a partition into classes; that is, it is a re-
flexive, symmetric, and transitive relation: 7 the identical mapping of (fj onto 
(fj is obviously an isomorphism, so that we may write (fj r'-I (fj. If A is an iso-
morphism of (fj onto ~, the inverse mapping A-I is an isomorphism of ~ 
onto (fj; for from (1) we have 
(2) 
(G~G0A-l = [(G1GJA]A-
1 = G1G2 = (G~)rl(G0rl. 
Also, if,." is an isomorphism of ~ onto 3, then the mapping AI-' is one-to-one 
and is an isomorphism of (fj onto 3; 
(3) 
7 The partition into classes also determines the equivalence relation; see lA, §8.5. 

2 Groups 
191 
Thus, (fj r'-I ~ and ~ r'-I 3 imply (fj r'-I.3, so that the set of all groups falls 
into classes of isomorphic groups such that no group belongs to more than 
one class. 
Now the fundamental problem, the so-called type or structure problem, 
of the theory of groups is to select, from each class of isomorphic groups, 
a representative, or model, which is to be described as precisely as possible. 
What is meant here by "as precisely as possible" is to a great extent a 
matter of taste. In general, we shall look for a description in terms of con-
cepts that lie closest to our intuition; for example, numbers, diagrams, and 
so forth. If we can find a model of this sort in every class, we have given a 
complete description of all groups, since any group arises from such a 
model by a mere renaming of the elements. At the present time we are still 
far from such a goal. Only for certain rather small, special classes of 
groups, e.g., the finite Abelian groups and a few others, has a satisfactory 
solution of this problem been found. In the next section we shall carry it 
through for a very simple class of groups, namely, the cyclic groups. 
If we wish to give a complete account of the isomorphisms A of (f) onto 
~, it is enough to consider the case ~ = (fj. For if Al ,A2 are two isomor-
phisms of (fj onto ~, the mapping ex = A2A1- 1 is an isomorphism of(fj onto 
itself. On the other hand, if ex is an isomorphism of (fj onto itself, and Al is 
an isomorphism of (fj onto ~, then exAI = A2 is also an isomorphism of (fj 
onto ~. Thus two isomorphisms of (fj onto ~ differ from each other only 
by an isomorphism of (fj onto itself. An isomorphism of (fj onto itself is 
called an automorphism of (fj. If ex, fJ are two automorphisms of (fj, the 
mapping exfJ-l is also an automorphism of (fj, as is easily seen from (2) and 
(3). Since automorphisms are .combined in the same way as permutations, 
the set of automorphisms of (fj is a subset of e ffi , the so-called group of 
automorphisms of (fj. 
For example, r(3)+ has two automorphisms: 
I = (~ 
Thus for any group (fj isomorphic to r(3)+ there exist two isomorphisms 
of r(3)+ onto (fj. 
5. 
Cyclic Groups 
Corresponding to any element G of a group there exists the subgroup 
<G) (§3.4). The structure of such groups is particularly simple. In general, 
a group of the form (fj = <G) is called cyclic. For example, every group (fj 
of prime order p is cyclic, since for G E (fj the theorem of Lagrange §3 (8) 
shows that <G) : 1 must be equal either to 1 or to p, so that for G *- 1 we 
have <G) = (fj. Let us examine the cyclic groups a little more closely. 

192 
PART B ARITHMETIC AND ALGEBRA 
5.1. 
For an arbitrary group (fj and G E (fj we define the nth power of G 
as the product 
G . G .... G, with G written n times, 
and denote it by Gn. Obviously we have 
so that (Gn)-l = (G-l)n; and thus we can write G-n for the inverse of Gn. 
Finally we set GO = 1. Then for every rational integer g the gth power GO 
is uniquely defined. Here 
and 
(1) 
as follows8 at once from the definition for the various cases g ~ 0, h ~ 0; 
g < 0, h ~ 0; g ~ 0, h < 0; g < 0, h < o. 
By the criterion for subgroups, it follows from (1) that the set of powers 
of G E (fj is a subgroup, which is obviously equal to <G). 
5.2. 
As a special case of the fundamental problem for the theory of 
groups we now reduce the description of the structure of cyclic groups to 
calculation with rational integers. In other words, we prove the following 
fundamental theorem for cyclic groups. 
Let the (ij = <G) be cyclic. If (fj is of finite order n, then (fj r'-I r(n)+. 
If(fj is of infinite order, then (fj r'-I r+. 
In particular, we have the following corollaries. Every cyclic group is 
Abelian. For every finite order there exists a cyclic group which is uniquely 
determined up to isomorphism. There are no cyclic groups of power higher 
than No. 
For the proof, we consider the various powers of G. By the remark at 
the end of §5.1 we have (fj = {Go I g = 0, ±1, ... }. If GOl *- G02, for all 
gl *- g2, the mapping g -- GO is one-to-one and is therefore, by (1), an 
isomorphism of r+ onto (fj; thus in this case the order of(fj is equal to that 
of r+. On the other hand, if GOl = G02, gl < g2, so that GOl-02 = 1, let 
n > 0 be the smallest positive integer with the property that Gn = 1. Let 
g be a 
rational integer with g = nh + r, 
0 ~ r < n, 
so that 
GO = Gnh+r = (Gn)h Gr = Gr. From Gr = GS, 0 ~ r < s < n it follows 
that Gs-r = 1, so that s = r by the minimal property of n. Thus r -- Gr is 
a one-to-one mapping of r(n)+ onto (fj. Then by (1) this mapping is an 
8 See also IBt, §3.3. 

2 Groups 
193 
isomorphism of r(n)+ onto (fj, which completes the proof of the fundamen-
tal theorem for cyclic groups. 
5.3. 
For an arbitrary group (fj and G E (fj the number 1 <G) I, which 
has been defined above as the order of the group <G), is also called the 
order of the element G. From the proof in §5.2 it follows that the order of 
G, provided it is finite, can be characterized as the smallest natural number 
n for which Gn = 1. The same proof shows that divisibility of g by 1 <G) 1 
is equivalent to Gg = 1. Since the order of G is equal to the order of the 
subgroup <G), the theorem of Lagrange shows that the order of G is a 
factor of the order of (fj. The least common multiple of the orders of all the 
elements of (fj, provided it exists, is called the exponent of (fj. Thus the 
exponent of a group (fj is the smallest natural number e for which Ge = 1 
for all G E (fj. 
For example, the exponent of 6(3) is 6. A group with the exponent 2 is 
Abelian: for in general we have (§2 (4) (G1G2)-1 = G;lG1\ so that if 
G2 = 1 and therefore G-l = G for all G E (fj, it follows for all su~h (fj that 
G1G2 = G2G1 · 
5.4. 
We now examine the subgroupsU of a cyclic group <G). To this 
end we choose Gd in such a way that d is the least positive integer with the 
property Gd E U, d ~ 1, as is always possible, since the subgroup U contains 
the inverse of every element in U. Then U contains the powers (Gd)a; a = 0, 
± 1, .... But these powers already exhaust all the elements of U; for if we 
had Gg E U, g = hd + r, 0 < r < d, it would follow that Gg(Ghd)-l = 
Gr EU, in contradiction to the choice of d. Thus Uis cyclic of the form <Gd). 
It remains to decide when <Gd1) = <Gd2 ) with 1 ~ d1 , d2 • A necessary 
and sufficient condition is obviously the existence of rational integers 
a, b with 
that is, 
(2) 
d1 = ad2 , d2 = bd1 , if 1 <G) 1 is infinite, 
(3) 
d1 == ad2 , d2 == bd1 mod n, if 1 <G) 1 = n is finite. 
Now (2) is equivalent to d1 = abd1 , so that ab = 1 and d1 = d2 ; and 
(3) is equivalent, by IB6, §4.l, to 
nidI -
ad2 , n 1 d2 -
bdl· 

194 
PART B ARITHMETIC AND ALGEBRA 
But these conditions of divisibility can hold if and only if 
(n, d2) I d1 , (n, d1) I d2 
or 
or 
We thus obtain the following result: 
The subgroups of a cyclic group (G) are cyclic of the form (Gd), 1 ~ d. 
Under the mapping d -+ (Gd) they are in one-to-one correspondence with the 
natural numbers d = 1, 2, ... , if I (G) I is infinite and to the positive divisors 
d ofn ifl (G) I = n isfinite. 
Here d is the index of the subgroup U = (Gd), since for every Gd E (G) 
there exists exactly one r, 0 ~ r < d with g = hd + r; thus 
and the complexes UG" generate each coset of U exactly once. 
As an application of these results the reader may prove the following 
theorem: every minimal subgroup is of prime order. 
6. 
Normal Subgroups and Factor Groups 
6.1. 
In §3.5 we saw that a right coset for a subgroup of (fj is not neces-
sarilya left coset. We now examine those subgroups of a group for which 
every right coset is also a left coset, a property which, though at first glance 
it seems insignificant, has several very important consequences. Such 
subgroups 91 are given the special name of normal subgroups or, correspond-
ing to the terminology of §3.1, invariant subgroups. By §3.5 they are char-
acterized by the fact that 
(1) 
9lG = G91 
or 
G91G-l = 91 
for all 
G E (fj. 
The second identity means that 91 coincides with all its conjugates in (fj. 
6.2. 
In an Abelian group every subgroup is a normal subgroup, as we 
have already seen. But the Abelian groups are not the only groups with 
this property. There exist non-Abelian groups in which every subgroup is 
invariant. For such groups, called Hamiltonian groups, the type problem 
has been satisfactorily solved. We shall content ourselves here with an 
example of order 8, the so-called quaternion groupn. Its elements are the 

2 Groups 
195 
following matrices with coefficients from the field of complex numbers, and 
its operation is matrix multiplication (cf. IB8, §3.l): 
I = (~ ~), 
(-I -~), 
. 
(0 
~), 
-j = ( ? 
-1= 
} = 
. 
0 
1 
-I 
k = ( 0 
-I ~), 
-k = (~ -I) 
o ' 
1= (-i 
0 
~), 
-I = (~ 
The lattice of subgroups of.Q has the form shown in Figure 10. 
If a subgroup U of (fj has the index 2, 
it is a normal subgroup, since in this 
case the coset distinct from U contains 
exactly those elements of(fjthat are not 
Order 
(J 
in U. For example, the subgroup 
Order 
{I, cx, {J} (§3.3.3) is a normal subgroup 
t-
of 6(3). But the fact that a subgroup 
of index 3 need not be a normal sub-
group is shown by the example U = 
{I, y} ~ (fj(3). 
6.3. . The fundamental role of nor-
mal subgroups is indicated by the 
following theorem: 
Fig. 10 
-i) 
o ' 
~). 
-l 
A subgroup of (fj is normal in (fj if and only if the set of its right cosets 
(or alternatively, of its left cosets) is a group with respect to complex 
multiplication. 
For the proof we first let 91 be a normal subgroup of (fj. From (1) it then 
follows that 
(2) 
91G91H = 9191GH = 91GH, 
so that (V) is satisfied. The associativity of complex multiplication was 
already shown in §3.1. The neutral element is 91: 
91G91 = 9191G = 91G; 
the inverse of91G is 91G-l, since 91G91G-l = 9191 = 91. Thus the cosets of 
91 form a group. 
Conversely, let 91 be a subgroup of (fj whose right cosets form a group, 
so that in particular the product 91G91G-l is a right coset for all G E (fj. 
Since I = IGIG-l E91G91G-l, we have by §3.5 
91G91G-l = 91 . I = 91, 

196 
PART B ARITHMETIC AND ALGEBRA 
and thus 
G91G-l = 1 . G91G-l em, 
and 
91 C G-l91G; 
consequently, 91 = G91G-l, since if G runs through all elements of (fj, so 
does G-l. Thus 91 is a normal subgroup of (fj. 
Similarly we could have shown that 91 is a normal subgroup if an only if 
its left cosets form a group. 
The group of cosets of91 is denoted by (fj/91 and is called the/actor group 
0/91 (under (fj) or the/actor group (fj by 91. The order of(fj/91 is equal to the 
index (fj : 91. 
6.4. 
In an Abelian group every factor group is also Abelian. If 
(fj = (G) is cyclic, every factor group (G)/(Gd) is also cyclic, namely 
equal to «Gd)G). 
If 91 is a normal subgroup with 91 *- 1, the group (fj is split by 91 into two 
groups (fj/91 and 91. These groups are usually simpler in structure than (fj 
itself (for example, in the finite case they are of smaller order) so that by 
examining them separately we can gain insight into the structure of (fj. 
Especially interesting from this point of view are the groups that do not 
allow any splitting in this sense; in other words, groups which have no 
normal subgroups except 1 and (fj. Such groups are called simple. Simple 
Abelian groups are o/prime order. Conversely, every group o/prime order is 
simple and Abelian. As we shall see later, there exist simple groups (some-
times called properly simple) that are not Abelian. Their existence offers a 
serious obstacle to the solution of the structure problem. 
It is easy to show that the intersection of a set of normal subgroups is 
again a normal subgroup. 
If91 is a normal subgroup and U is any subgroup of (fj, the complex 91U 
is a subgroup of (fj and is obviously equal to the group 91 U U generated by 
(91 u U). For with N1, N2 Em; VI, V2 E U it follows from (1) that 
Nl V1(N2V2)-1 = Nl VI V;lN;l 
= Nl(VlV;l) N;l(VIV;l)-lVIV;l 
Emu, 
so that the criterion for subgroups is satisfied for 91U. In particular, if 
U = 9Jl is also a normal subgroup of (fj, then 
G919J1G-l = G91G-IG9J1G-l = 919J1, 
so that 919Jl is a normal subgroup of (fj. 

2 Groups 
197 
A normal subgroup 91 of (fj is also a normal subgroup of every subgroup 
U ~ (fj that is contained in 91. The subgroups of U that contain 91 are in 
one-to-one correspondence under the mapping 
(3) 
U --. U/91 
with the subgroups U/91 of (fj/91. More precisely, we have here a lattice 
isomorphism (see IB9, §2.1) of the lattice of subgroups of (fj containing 91 
onto the lattice of subgroups of (fj/91. Moreover, the normal subgroups of 
the two groups are in one-to-one correspondence. 
If (fjis generated by 5\, then (fj/91 is generated by {91K IKE 5\}; for if91G 
is a coset of91 and G = K{l ... K;", Ki E 5\, then 91G can be represented as 
7. The Commutator Group 
For any given group it is possible, by using the concept of a factor 
group, to define a certain subgroup which, roughly speaking, measures 
the extent to which the group departs from being Abelian. For this 
purpose we consider a set 91 of normal subgroups 91 of (fj whose factor 
groups are all Abelian. Let Xl be the intersection of all the normal 
subgroups in 91, so that Xl is a normal subgroup of (fj. We will now show 
that (fj/Xl is also Abelian: for we have 91G91H = 91H91G, that is, 
91GH = 91HG or 91GHG-IH-l = 91 for all 91 E 91 and G, HE (fj. Thus 
every element GHG-IH-l lies in all the 91 Em: 
GHG-IH-l E Xl 
and thus XlGHG-IH-l = Xl. 
Consequently, 
XlGH = XlHG, 
XlGXlH = XlHXlG, 
so that (fj/Xl is commutative. If 91 is the set of all normal subgroups 
of (fj with Abelian factor group, it follows that: 
In every group there exists a normal subgroup, with Abelian factor group, 
which is contained in every normal subgroup with Abelian factor group and 
is the intersection of all such normal subgroups. It is called the commutator 
group of (fj and is denoted by (fj'. 
It is easy to see that the commutator group is generated by the set of 
all elements GHG-IH-l, the so-called commutators of (fj. To say that 
(fj' = 1 is equivalent to saying that (fj is Abelian. In the other extreme 

198 
PART B ARITHMETIC AND ALGEBRA 
case, (fj = (fj', the group (fj is called perfect. A properly simple group is 
perfect, since 1 and (fj are its only normal subgroups and therefore 
(fj = (fj'. The commutator group of 6(3) is the subgroup m:(3) (§3.3.3); 
the factor group 6(3)/21(3) is Abelian and 1 is the only proper subgroup 
of 21(3); however, 6(3)/1 ,.-...J 6(3) is not Abelian. 
8. Di rect Products 
8.1. 
Let IDl and 91 be normal subgroups of (fj, with 
(1) 
9Jl91 = (fj, 
If MINI = M2N2 , MI , M2 E 9J1, N1 , N2 E 91, then M;l MI = N2Nli = 1 
and MI = M 2, NI = N2. Thus if the elements G E (fj are represented 
in the form 
(2) 
G=MN; 
M E 9J1, 
N E 91, 
the M, N are uniquely determined by the G. 
Now consider a product MN = NMM-IN-IMN. Since 9J1 and 91 are 
normal subgroups, we have 
and thus 
M-IN-I M E 91, 
N-IMNEIDl, 
so that every element of IDl permutes with every element of 91. 
Thus the operation of the group (fj is completely determined by the 
products of elements from 9Jl and 91: 
(3) 
We describe this special case by saying that (fj is decomposable into the 
direct product of9Jl and 91. It is customary to write (1) in the shorter form: 
(fj = 9J1 X 91. 
The mapping u, with (9J1N)a = N, is an isomorphism of (fj/IDl onto 91: 
For by (1) the requirement §4(1) is satisfied, and the mapping u is onto 91 
and is one-to-one, since every coset of IDl contains its image. 
8.2. 
More generally, we say that (fj is the direct product of IDli ; 
i = 1, ... , r, and write 
(fj = 9J11 X ... X 9J1,., 

2 Groups 
199 
if the 9Jli are normal subgroups of (fj, with MiMk = MkMi for Mi E 9J1i , 
M k E 9J1k , i -:/=- k, and if every element G E (fj can be written as the product 
(4) 
G = MI." Mr 
with uniquely determined Mi E 9J1i . This extension of our notation is 
justified by the fact that the direct product as now defined can be obtained 
by iteration from the earlier definition. For if 
(fj = 9J1 X 91, 
91 = £? X 5\, 
we have 
in the generalized notation. 
From the uniqueness of the representation (4) it follows that the order 
of a direct product is given by 
1 (fj 1 = 1 9Jl1 1 ... 1 9Jlr I· 
If (fj is the direct product of Abelian groups, then (fj itself is Abelian, 
as follows directly from (3). Every group can be decomposed into the 
direct product (fj = 1 X (fj. A group which allows no other decomposition 
into a direct product is said to be indecomposable. For example, the group 
6(3) is indecomposable, since it has only one normal subgroup -:/=-1. 
8.3. 
An exact knowledge of the indecomposable groups would be very 
desirable; in a certain sense they represent an analogue in the theory of 
groups to prime numbers in the theory of numbers. For a very extensive 
class of groups, which includes for example the finite groups and the 
finitely generated Abelian groups, we have the following theorem, in 
analogy with unique decomposition into prime numbers. 
If 
with 9J1i91k indecomposable; i = 1, ... , r; k = 1, ... , s, then r = s, and there 
exists a permutation a of the indices such that 9J1i r'-I 91ia • 
In the following section we shall determine the indecomposable groups 
in the class of all finite Abelian groups, and the direct product will provide 
us with a suitable solution of the type problem for this class of groups. 
9. Abelian Groups 
In §9.1 we state certain elementary but basic properties of Abelian 
groups which will be useful in what follows. 

200 
PART B ARITHMETIC AND ALGEBRA 
9.1. 
As mentioned before, every subgroup of an Abelian group (fj 
is a normal subgroup, and for two such groups <U u m> = um. Also, in 
Abelian groups we have the following power rule: 
G, HE (fj. 
From this rule it follows that for every g the complex (fjo =,{Go ) G E (fj} 
is a subgroup of (fj: Go H-g = (GH-l)O; and dually, for fixed g, the set 
of elements G E (fj for which Go = 1 is a subgroup (fjg: for if G1 , G2 E (fj, 
then (G1G"2g = GrG"2g = 1. 
If G, HE (fj are of finite order and GO = 1, Hh = 1, then (GH-l)gh = l. 
Thus the elements of finite order in (fj form a subgroup l:, the 
so-called torsion group of (fj. For example, the torsion group of px (§1.2.3) 
is the subgroup {I, -I}. The torsion group l: itself is not necessarily of 
finite order, as is shown by the example p+lr+ (§1.2.2): for if glh E P+, 
g, h E r+, then for h summands we have 
(r+ +!) + ... + (r+ + t) = r+ + g = r+. P+ I r+, 
so that P+ I r+ is identical with its torsion group. But P+ I r+ is not of finite 
order, since the elements 1, !, 1, ... lie in distinct cosets of r+. 
Abelian groups in which only the unit element is of finite order are 
said to be torsion-free. Thus the cyclic group of infinite order is torsion-
free, and so are all direct products of torsion-free groups. Furthermore, 
for an arbitrary Abelian group the factor group by its torsion group is torsion-
free: for if (l:G)m = l:, then Gm = TEl:; and if Tt = 1, then Gmt = 1, 
so that GEl:. Thus l: is the only element of (fj/l: that is of finite order. 
9.2. 
Finite and Finitely Generated Abelian Groups 
The purpose of the present section is as follows: by making use of the 
direct product we reduce the type problem for finite Abelian groups to 
the same problem for cyclic groups, for which it was already solved in 
§5.2. In speaking of direct products we include the case that the 
product has only one factor. 
9.2.1. We now prove the fundamental theorem on finite Abelian groups: 
a finite Abelian group (fj is the direct product of cyclic groups of prime power 
order: 
(1) 
Pi = prime. 
To prove this theorem we first prove the following two lemmas: 
9.2.2. If the exponent of a finite Abelian group is not a prime power, 
the group is decomposable. 

2 Groups 
201 
9.2.3. If the exponent of a finite Abelian group (fj is a prime power and 
if M is an element of maximal order in (fj, then there exists a direct decom-
position 
(fj = (9)1) X ffi 
with a suitable subgroup m 
~ (fj. 
From these two lemmas it is clear that an Abelian group which is not 
cyclic of prime power exponent must allow a proper decomposition 
(fj = ~ X 3; 
Since by the theorems on cyclic groups the exponent of such a group is 
equal to the order of the group, the fundamental theorem now follows 
immediately by complete induction on the order of the group and iterated 
construction of the direct product. 
Proof of §9.2.2. We assume that the exponent e of (fj is the product of 
mutually prime positive integers =1=1: 
e = ab, 
(a, b) = 1, 
and then show that 
(2) 
For this purpose we determine a, b such that ali + bb = 1. Then 
G = (Ga)ii(Gbi' for all G E (fj, and thus 
(fj = (fja(fjb. 
Let G~ = Gg E (fja (\ (fjb; G1 , G2 E (fj. Then 
(G~)ii = (Gg)ii, 
G~-b5 = Ggii, 
G1 = 
(G~G1)b. 
Since e = ab, it follows that G~ = 
(G~G~)ab = 1 and (fja (\ (fjb = 1, 
so that we are dealing here with a direct product (2). But a and bare =1=1, 
so that by definition of the exponent (fja, (fjb =1= 1. 
Proof of §9.2.3. If (fj is cyclic, there is nothing to prove. If not, we 
first construct a subgroup ~ =1= 1 whose intersection with <M) is 1. 
To do this, we let the exponent of (fj be a power of the prime p. The 
theorems on the subgroups of cyclic groups show that for G ~ <M), 
so that 
<G) (\ <M) = <GP') = <MP), 
p8 . I<GP')I = I<G)I, 
pr . I<MP)I = I<M)I 

202 
PART B ARITHMETIC AND ALGEBRA 
with, let us say, GP' = Mapr. By the maximality of M we then have 
s ~ r. For the element H = GM-apr-" 
which is different from 1, 
it follows that Hn E (M) is equivalent to Gn E M, so that 
(H) (\ (M) = (HP'). 
But 
HP' = GP'M-ap = 1, 
and therefore 
(H) (\ (M) = 1. 
Consequently, ~ = (H) has the desired property. 
The factor group (jj/~ is also of prime power exponent, so that each of 
its elements is of prime power order. Also, ~M is of maximal order in 
(jj/~; for if (~M)pt = ~, (~M*)pt *- ~, M* E (jj, it would follow that 
Mpt E ~, so that by the construction of ~ 
Mpt = 1 
and 
so that M*P *- 1 and M* would be of greater order than M, in contra-
diction to the choice of M. But now the fundamental theorem follows 
immediately by complete induction on the order of (jj, since the theorem 
holds trivially for I (jj I = 1, and since (jj/~ is of smaller order than (jj, 
there exists a direct decomposition 
with a subgroup ffi of (jj. In other words, (~M)ffi = (jj, (~M) (\ ffi = 
~. 
But from (~M) = ~(M) and ~ ~ ffi we then have (M) ffi = (jj and 
(M) (\ ffi ~ ~. Thus it follows from the choice of ~ that (M) (\ ~ = 1. 
Thus the proof of the fundamental theorem is complete. 
9.2.4. 
The fundamental theorem provides the complete decomposition 
of a given group, as can be seen from the following fact: every cyclic 
group (G) of prime power order plY. is indecomposable. For if (G) were 
decomposable, each of the factors would contain a minimal subgroup of 
order p, in contradiction to the fact that a cyclic group cannot have more 
than one subgroup of a given order. 
9.2.5. The cyclic groups allow us to solve the type problem for a more 
general class of groups, in view of the theorem: 

2 Groups 
203 
If (fj is a finitely generated Abelian group, then (fj is a direct product of 
finite cyclic groups, whose orders are prime powers, and of infinite cyclic 
groups: 
I(Gi>1 = Pj', Pi prime, 
i = 1, ... , r; 
I(Hk>1 = No, 
k = 1, ... , s. 
It is obvious that the torsion group of (fj is given by 
which is finite. 
We shall omit the proof of this more general theorem, since it does not 
require the introduction of any essentially new ideas. The chief difficulty 
lies in replacing the complete induction on the order of the group by 
complete induction on the number of generators, which may become 
laborious, since it is not always easy to see whether a proper subgroup 
has a smaller number of generators than the group itself. 
9.2.6. 
By means of the theorem on the subgroups of a cyclic group it 
is easy to prove that an infinite cyclic group is indecomposable. Then the 
theorem in §8.3 on the uniqueness of direct decompositions states that 
for finitely generated Abelian groups the numbers p~l, ... , p~r and s in (3) 
are uniquely determined by (fj. On account of their importance in com-
binatorial topology, these numbers 
p~l, ... , p~r are called the torsion 
numbers of (fj, and s is the Betti number of (fj. 
9.2.7. 
From the decomposition (1) it is clear that we can determine 
the exponent e of (fj as follows: for every prime p that divides (fj : 1 we 
determine the group (Gi> of highest p-power order p; then 
(4) 
e= n p. 
Plffi;l 
9.2.8. 
Examples. The reader may consIder for himself how the general 
finite cyclic groups are included in the preceding theorems and how they 
are to be decomposed into direct products of cyclic groups of prime power 
order. 
The expression (4) for the exponent enables us to give a complete 
description of the structure of finite groups with exponent 2. As pointed 
out in §5.3, these groups are Abelian, so that they must be direct products 
of cyclic groups of order 2. Thus, for example, the type of all groups ~m 
with finite I m I has been satisfactorily described. 
As a further example of the preceding theorems we shall show how they 
apply to the group §1.2.ll. The torsion group l: of (f(3) consists of the 
elements 1, -l,since these are the only real numbers for which some power 
is equal to 1. If we denote by (t(3) the set of positive numbers in (f(3), 

204 
PART B ARITHMETIC AND ALGEBRA 
then (t(3) is obviously a subgroup of (f(3). Since every number in (f(3) can 
be written in the form 1 . € or (-1) . € with an element € E (t(3) and since 
l: (\ (t(3) = 1, we have the direct product decomposition (f(3) = l: X (t(3). 
Let us investigate the group (t(3). 
To every real number g + h -yl3 
with integral g, h we assign the 
lattice point (g, h) in a Cartesian 
coordinate system. Then the ele-
ments of (f(3) correspond to the 
lattice points of the hyperb.olax2 -
3y2 = 1. We now consider the set 
9 of parallel lines 
x + y-yl3 = p, 
p real ~ 1. 
Fig. 11 
As can be seen at once from 
Figure 11, 9 consists of the lines 
that are parallel to the line x + y -yl3 = 1 and lie above it to the right. 
Thus there exists a line x + y -yl3 = €o in g, with €o > 1, that passes through 
a lattice point of the hyperbola and has the minimal €o for all such lines. 
Then €o is an element of (t(3), and we can show that the elements € E (t(3) 
are the powers of €o • For let us choose an integer m such that 
Then 
Now, €/€"; = i is an element of (f(3), so that the line x + y -yl3 = i 
passes through a lattice point of the hyperbola. From the minimal property 
of €o it follows that € = 1 and €"; = €. Since the powers €n form an 
infinite set of numbers, the group (t(3) is a cyclic group of infinite order. 
9.3. 
Group Properties of Ornaments 
We shall now give an example to show how the symmetry of ornaments 
can be analyzed by means of group concepts. The characteristic feature 
of the ornaments of interest to us is "infinite repetition," by which we 
mean the repetition of a definite pattern, the "elementary ornament," 
at equal distances. This repetition, or translation, can take place in one, 
two, or three noncoplanar directions, with the corresponding classification 
of ornaments into linear (that is, occurring on a band or strip), planar, 
and spatial types, the last two of which play an important role in crystal-
lography. Whether there exist other symmetry operations, in addition to 
these pure translations, depends on the nature of the given ornament. 

2 Groups 
205 
In illustration of these remarks let us consider the classical decoration 
shown in Figure 12. If we interpret this ornamental strip as a sequence of 
partially overlapping discs situated in three-dimensional space, then the 
I 
I 
I 
I 
I 
I 
I 
I 
I 
I 
: i : i : i : i : i : 
_.+.+.+.+.+.+.+.+.+.+.+.-
: i : i : iii 
: 
I iii Iii 
i 
I 
Fig. 12 
strip can be mapped onto itself by the following, simple or composite, 
operations: 
Translations by distances that are multiples of a certain elementary vector; 
in the direction of the axis of the ornament. 
Reflection in the plane perpendicular to the strip and through the axis, 
with or without simultaneous translation by a multiple of the 
elementary vector (longitudinal reflections). 
Reflections in planes that are perpendicular to the axis of the ornament 
and are at a distance from one another of half the elementary 
distance e (transverse reflections; in the figure the traces of these 
planes are marked by dots and dashes). 
Rotations by 180
0 about transverse axes in the plane of the strip, where 
the axes are again at a distance from one another of half the 
elementary distance (half-turns around a transverse axis; in the 
figure the axes are marked by dashes). 
Rotations around centers at a distance from one another of half the 
elementary distance (in the figure these centers are indicated by small 
circles). 
Translations by an odd multiple of half the elementary vector with 
simultaneous reflection in the plane of the ornament, so that the 
overlappings of the circles are reversed (planar glide reflections). 
Translations by an odd multiple of half the elementary vector with 
simultaneous rotation of 180
0 around the longitudinal axis (spiral 
motions). 

206 
PART B ARITHMETIC AND ALGEBRA 
Rotations around points separated by half the elementary ~istance 
(marked in the figure by small black circles) with simultaneous 
reflection in the plane of the ornament (rotatory reflections). 
The schematic representation in Figure 13 shows the structure of the 
ornament. 
~
I~I~I~I~I~I 
I~I 
:-+-:-+- :-+ -;-+- :-+--:-+-: 
r 
1/ 
I 
I 
I 
I 
I 
I 
I 
r 
I 
I 
I 
I~o(---e 
~I 
! 
I 1" 
2" I J" 
I 
¥" I 1 
r 
2 I J 
Ij. I l' 
2' I J' 
I 
¥' I 
~.-.+.-.+.-.+.- +.-.+.-.+.-.+.-.-~.-.+.-.+.-.+.-. ..} 
i 5" : 6" i 7- : 8" i 5 
6 i 7 
I 8 i 5' I 
6' i 7' : 8' i 
i 
i 
FIG. 13 
It is obvious that these mappings are the elements of an infinite non-
Abelian group. We divide them into the complexes listed in the above 
classification; among these complexes the translations, including the 
identity, clearly form a normal subgroup. We can gain insight into the 
structure of the ornament by forming the factor group with respect to 
translations. 
In order to investigate this factor group, we make use again of the above 
schema, consisting of overlapping triangles with the same structure as 
the ornament. We consider each elementary part of the ornament as being 
divided into eight fields, each of which contains a figure consisting of two 
overlapping triangles; this figure can be mapped onto the other figures by 
an operation of the group, indicated below by primes. 
1. 
The translations 
Biol : 1 -- 1 
B11l : 1 -- l' 
Bi2l : 1 -- 1" 
(the identity mapping), 
(translation by;), 
(translation by -e), and so forth 
form the normal subgroup and the unit element of the corresponding 
factor group is ~1 = 
{B~nl In = 0, 1,2, ... }. 

2 Groups 
2. 
The mappings 
B~O) : 1 ----+ 2, 
B~l) : 1 ----+ 2', 
B~2) : 1 ----+ 2", 
and so forth 
207 
represent half-turns. All these motions arise from a single B2 by 
complex-multiplication with the group of translations: 
~2 = 
{B~n)} = 
B2~1 . 
3. 
The mappings 
B~O) : 1 ----+ 3, 
B~l) : 1 ----+ 3', 
B~2) : 1 ----+ 3", 
and so forth 
characterize the complex of planar glide reflections. This complex 
arises from one element B3 as follows: ~3 = {B~n)} = B3~1 . 
4. 
The mappings 
Bt): 1----+ 4, 
B~l) : 1 ----+ 4', 
Bl2) : 1 ----+ 4", 
and so forth 
are reflections in transverse axes; they may be written as cosets of ~1 
with arbitrary B4: ~4 = {B~n)} = B4~1 . 
5. 
Reflections and glide reflections in the longitudinal axis 
B~O) : 1 ----+ 5, 
B~l) : 1 ----+ 5', 
B~2) : 1 ----+ 5", 
and so forth 
are elements of a complex which may be represented by ~5 = 
{B~n)} = B5~1' 
6. 
From 
B~O) : 1 ----+ 6, 
B~l) : 1 ----+ 6', 
B~2) : 1 ----+ 6", 
and so forth 
we obtain the rotatory reflections. Here ~6 = {B~n)} = B6~1 . 

208 
PART B ARITHMETIC AND ALGEBRA 
7. 
The helical motions 
B~O) : 1 ----+ 7, 
B~l) : 1 ----+ 7', 
B~2) : 1 ----+ 7", 
and so forth 
8. 
Finally, the simple rotations around centers 
B~O) : 1 ----+ 8, 
B~l) : 1 ----+ 8', 
B~2) : 1 ----+ 8", 
and so forth 
may be represented in the form ~8 = 
{B~n)} = 
B8~1 . 
The symmetry of the ornament is now characterized by the structure 
of the factor group in the following way: if (fj is an infinite non-Abelian 
group of mappings of the ornamental strip onto itself, then the factor 
group with respect to the translations 
(fj/~1 = 
{~1 , ~2 , ~3' ~4' ~5 , ~6' ~7' ~8} 
is Abelian. The element ~1 is the unit element, and every element is 
inverse to itself (involution). The multiplication table is as follows: 
~1 ~2 ~3 ~4 ~5 ~6 ~7 ~8 
~1 
~1 ~2 ~3 ~4 ~5 ~6 ~7 ~8 
~2 
~2 ~1 ~4 ~3 ~6 ~5 ~8 ~7 
~3 
~3 ~4 ~1 ~2 ~7 ~8 ~5 ~6 
~4 
~4 ~3 ~2 ~1 ~8 ~7 ~6 ~5 
~5 
~5 ~6 ~7 ~8 ~1 ~2 ~3 ~4 
~6 
~6 ~5 ~8 ~7 ~2 ~1 ~4 ~3 
~7 
~7 ~8 ~5 ~6 ~3 ~4 ~1 ~2 
~8 
~8 ~7 ~6 ~5 ~4 ~3 ~2 ~1 
The group belongs to the type dealt with in the second paragraph of 
§9.2.8. Since it is of order 8, the theorem of Lagrange suggests that 
we look for subgroups of order 4 and 2. Such subgroups are to be 
found in the table, or more simply by a glance at the schematic figure 
(Figure 14). 

2 Groups 
209 
The full ornament (occupying eight fields) has the structure of the 
group (fj/~1 (holohedrism). 
If we reduce the number of fields to four, we obtain seven different 
possibilities, corresponding to suitable choices of the occupied fields, for 
ornaments with the structure of the subgroups of order 4 (hemihedrism). 
/ 
/ 
11' 
IJ' 
lIE 
e 
~I 
Fig. 14 
If we restrict ourselves to two fields, we can find seven further arrange-
ments, which have the structure of the subgroups IDi of order 2 (tetarto-
hedrism). 
Finally, if only one field is occupied, we have the unit element of the 
factor group. 
In Figures 15 through 29 we give examples of ornaments with the 
structure of the various subgroups. 
In addition to the eight symmetry operations described above, there 
exist three others that can appear in ornaments. The number of possible 
holohedrisms is thereby increased to four; they contain sixteen hemi-
hedrisms and ten tetartohedrisms, the unit element in each case being the 
group of translations. 

210 
PART B ARITHMETIC AND ALGEBRA 
Groups of the same order are isomorphic to one another. Figure 30 
shows the lattice of subgroups of the holohedrism. 
FIG. 15 
Group Ux = {m1 , ma , ms , m,} 
FIG. 16 
Group Ua = {m1 , ma , mil , me} 
FIG. 17 
Group Us = {m1 , ma , m7 , m8} 
FIG. 18 
Group U, = {m1 , ma , mil , m7} 
FIG. 19 
Group U
II = {m1 , ma , ms , m
8} 
FIG. 20 
Group Ue = {m1 , m" mil' m8} 
FIG. 21 
Group U
7 = {m1 , m, , me , m7} 

2 Groups 
211 
FIG. 29 
Group m1 

212 
PART B ARITHMETIC AND ALGEBRA 
Order 
¥ 
Fig. 30 
10. The Homomorphism Theorem 
10.1. 
In §4.2 we considered one-to-one mappings A of a group (fj for 
which 
(1) 
The following important generalization is obtained by dropping the 
requirement that the mapping be one-to-one. A mapping A of a group (fj 
into a group ~ that satisfies (I) is called a homo-
morphism of (fj into ~. The set of elements of (fj 
that are mapped onto the unit element I f> of ~ is 
denoted by (fj A and is called the kernel of A: (fj A = 
{G I G E (fj, GA = If>};the set (fjA = {GA I G E (fj}is called 
the image of (fj under the mapping A, or simply 
the image under A (see Figure 31). 
The rules §4.2.1-5 are proved for homomorphisms 
in the same way as for isomorphisms. 
The following homomorphism theorem shows that 
homomorphisms offer a very useful means of finding 
normal subgroups in a group and of investigatin~ 
their factor groups: 
Fig. 31 
The kernel of a homormorphism A of (fj into ~ is a normal subgroup of(fj, 
and the image of (fj under A is a subgroup of~. Moreover, (fj/(fjA r'-I (fjA. 
Proof. 
From G~ = 
(fj~ = If> it follows that If> = G~G;A = (G1G;1)\ 
so that (fjA is a subgroup of (fj. Also, for every X E (fj and G E (fjA 
(XGX-l)A = XAGAX-A = XAX-A = If>, 

2 Groups 
213 
so that (fj,l is a normal subgroup of (fj. For arbitrary X, Y E (fj we have 
X,\(Y,\)-l = (XY-I)\ so that (fj'\ is a subgroup of~. In order to show that 
(fj/(fj,\ ~ (fj'\ we consider the mapping induced by A on the set of cosets 
of (fj/(fjA' This mapping is in fact a mapping onto (fj\ since 
«(fj,\X)'\ = 
(fj~X'\ = X,\ 
for 
X E (fj. 
The mapping is one-to-one, since «(fj,\X1),\ = «(fj,\X2),\ implies X,\ = X~, 
which means that (XIX21)'\ = If>, XIX;1 E (fj,\ and (fj,\X1 = (fj,\X2 •
IFinally, 
«(fj,\X1(fj,\X2),\ = «(fj,\X1X2),\ 
= (X1X2),\ 
= 
X:X~ 
= «(fjX1),\ «(fjX2),\· 
Thus we have shown that the induced mapping is an isomorphism of 
ffi/(fj,\ onto (fj,\. 
In order to complete the homomorphism theorem we note that every 
normal subgroup 91 of a group (fj is the kernel of a homomorphism of (fj, 
since the mapping G -- G91 is a homomorphism onto (fj/91, as is easily 
seen from §6(2), and its kernel is obviously 91. 
10.2. . Let us consider two applications of the homomorphism theorem. 
For the first example let (fj = K; (i.e., the set of n X n matrices over a 
field K; see § 1.2.12) and let a mapping A from Kn into the multiplication 
group KX of the field K be defined as follows: to every matrix the mapping 
A assigns the value of its determinant: 
A,\= IA I, 
Then, by the rule for multiplication of determinants, A is a homomorphism 
and its kernel is the group of matrices with determinant I. Thus the latter 
group is a normal subgroup of K; . But every element of KX is an image 
under A, since k E KX is the image of 
(: 
:) 
Thus the factor group of this normal subgroup is isomorphic to KX. 
For the next example we take (fj = B2 (§1.2.6). If for a E B2 we set 
Eo = + I or Eo = -I, according to whether the orientation of a triangle 
in £2 is preserved or changed by the motion a (that is, whether a involve~ 
or does not involve a half-turn of the plane), then obviously Eo Eo = 
Eo 0 
• 
1 
2 
1 2 
Thus the mapping a -- Eo is a homomorphism of B2 onto the cyclic 

214 
PART 8 
ARITHMETIC AND ALGE8RA 
group of order 2. By the homomorphism theorem its kernel is a normal 
subgroup of B2 whose cyclic factor group is of order 2. This group is 
called the group of proper motions in E2 and is denoted by Bt . 
In B2 we can also construct a normal subgroup. For this purpose we 
first note that in a proper motion the angle between a line and its image is 
the same for all lines. If to each element U E Bt we assign this angle Wa 
in radian measure, the product of two proper motions U 1U2 corresponds 
to the angle Wa + Wa ,as follows from the theorem on the exterior angles 
1 
2 
of a triangle. Since two angles are equal if and only if their radian measure 
differs by a multiple of 217, the mapping U -- Wa is a homomorphism of 
Bt onto the factor group R+j(217), the so-called planar rotation group. 
The kernel of this homomorphism is the group T2 of translations; that is, of 
proper motions in which the image gu of every line g is parallel to g. By the 
homomorphism theorem the factor group B+jT2 is isomorphic to R+j(217). 
Our examination of the structure of B2 can now be brought to an end 
with the remark that T2 is isomorphic to the direct product of two groups 
of type R+ (§1.2.2), a fact whose proof we leave to the reader. The structure 
of B1 may be examined in the same way. 
11. The Isomorphism Theorem 
II. t. 
In our discussion of direct products (fj = 9J1 X 91 we noted that 
(fjj91 ~ 9J1 and (fjj9J1 ~ 91. We now prove an important generalization 
of this fact. 
Isomorphism theorem: if 91 is a normal subgroup and U is a subgroup of 
(fj, then 91 (\ U is a normal subgroup of U, and 
91Uj91 r'-I Uj91 (\ U. 
The above statement about direct products corresponds to the special 
case that U is also a normal subgroup of (fj and (fj = 91U, 91 (\ U = I. 
Proof. Let X E U, U Em (\ U; then XUX-1 E U since U is a group, and 
XUX-1 E 91 since 91 is a normal subgroup, so that the subgroup 91 (\ U is 
a normal subgroup of U. The elements of 91Uj91 are the co sets of the form 
91U, U E U. For U1 , U2 E U the two statements 91U1 = 91U2 and 
(91 (\ U) U1 = (91 (\ U) U2 are equivalent to each other. Thus (91U)'\ = 
(91 (\ U)U defines a one-to-one mapping A of 91Uj91 onto Uj91 (\ U. Since 
(91Ul 91U2),\ = (91U1 U2),\ 
= (91 (\ U) U1U2 
= (91 (\ U) U1 (91 (\ U) U2 
= (91U1),\(91U2)\ 
the mapping A is an isomorphism of 91Uj91 onto Uj91 (\ 11 

2 Groups 
215 
The various interrelations involved in the isomorphism theorem can be 
represented very clearly in a diagram if in the graph of the corresponding 
lattice we draw the line segments 91U -
91 and U -
91 (\ U parallel to 
each other and of equal length (see Figure 32). 
Then the geometric fact that the segments 
91U -
91 and U -
91 (\ U are necessarily parallel 
and equal finds its group-theoretic expression 
in the fact that 
91 : 91 (\ U = 91U : U, 
U 
which follows at once from 91U: 91 (\ U = 91 (\ U 
(91U : 91)(91: 91 (\ U) = 
(91U: U)(U: 91 (\ U) 
1 
and the isomorphism theorem. 
91U 
Fig. 32 
11.2. 
In the next section we shall use the isomorphism theorem to 
prove an important result in the general theory of groups, but first let us 
illustrate the theorem for the above group Bi (§IO.2) of proper motions 
in E2 . It is easy to show, as in §3.3.4, that the set Bip of elements of B2 
leaving a point P fixed is a subgroup of Bi. Obviously, this subgroup 
consists of the planar rotations around the point P, so that like the factor 
group Bi IT2 it is isomorphic to the group R+ 1<2rr). This fact also follows 
from the isomorphism theorem, since every proper motion can be obtained 
as the result of a translation followed by a rotation around P, which means 
in group-theoretic language that Bi = T2Bip. Since Bip and T2 have only 
the mapping 1 in common, it follows from the isomorphism theorem that 
12. Composition Series, Jordan-Holder Theorem 
In dealing with the type problem we naturally try to divide up every 
group into its simplest possible components, as was done above for the 
case of Abelian groups. In the section on direct products we remarked 
that although the theorem on unique decomposition into a direct product 
is valid for an extensive class of groups, the indecomposable groups 
themselves are still too complicated to provide an acceptable survey of 
all types of groups. In the present section we undertake an analysis leading 
to a simpler class of basic components, though now there is the disad-
vantage, not found in the direct product, that the given group is no longer 
uniquely determined by its components. 
12.1. 
We consider a group (fj -=1= 1 for which there exists a finite 
sequence of subgroups 
(1) 
K: 

216 
PART 8 
ARITHMETIC AND ALGE8RA 
such that 91i is a maximal normal subgroup of 91i - 1 for i = 1, .", I. 
Here I is called the length of the composition series K. The minimum of 
the lengths of all composition series of (\j is called the length of 63. There 
exist groups, for example r+, that have no composition series, but such 
groups are always of infinite order. If (\j is simple, then I = 1, since 
63 => 1 is the only composition series of 63. 
From the lattice isomorphism §6(3) it follows that if 
(2) 
K1 : 
and 
are composition series of 63/91 and 91, respectively, then 
is a composition series of 63. Thus for any subgroup of 91 it is possible to 
construct a composition series of 63 that includes the subgroup 91, provided 
63/91 and 91 themselves have composition series. The part of K that lies 
in 91i is a composition series for 91i . 
The factor groups 91i- 1/91i occurring in (1) are called composition factors 
of K. Since 91i is a maximal normal subgroup of 91i - 1 , these composition 
factors are simple groups. If all the composition factors of a composition 
series are Abelian or if they are all simple groups of prime power order, 
the group 63 is said to be solvable, a term which arises from the applications 
of groups to the theory of fields (see 187, §1O). A solvable group 63 is 
necessarily finite. 
Now it is natural to ask whether a solvable group may not have other 
composition series with non-Abelian composition factors. The answer to 
this question is part of the following, more general, theorem. 
Jordan-Holder theorem: if I is the length of 63 and 
K: 
and 
L: 
are composition series of 63, then s = 1, and there exists a permutation (J 
of the indices such that 91i - 1/91i ~ 9J1ia-l/9J1ia . 
Proof. 
From each class of isomorphic simple groups we choose a fixed 
representative (t and denote by n~ and ni the number of composition 
factors of K and L that are isomorphic to (t. In (4) it is clear that 

2 Groups 
217 
Our theorem is proved if n~ = n& for every (t; that is, if n~ = n& = n~ 
depends only on (fj and not on the particular composition series. If (fj 
is simple, the theorem is obvious. Arguing by complete induction on the 
length I of (fj, we now assume that I*- 1 and that the theorem is already 
proved for all groups of smaller length than (fj. Then, if 911 = 
9)11, we 
have 
since (fj/911 = (fj/9Jl1 and 911 = 
9)11 are of smaller length than (fj. Otherwise 
we must have (fj = 9119)11 , since 911 and 9)11 are maximal normal subgroups 
of (fj. By the isomorphism theorem we then have (fj/911 r'-I 9)11/911 (\ 9)11 
and (fj/9)11 r'-I 911/9)11 (\ 911 ' But (fj/911 , (fj/9)11 , and Xl = 9)11 (\ 911 are of 
smaller length than (fj, so that 
Thus n~ = n& = n~ depend only on (fj, as was to be proved. 
12.2. 
The great importance of simple groups in the general theory 
of groups becomes even clearer from the Jordan-Holder theorem than 
from the remark in §6.4. Thus it is natural to ask whether we can find 
a satisfactory solution of the type problem for simple groups. But here 
the situation is as follows. In addition to the simple groups of prime order, 
research has uncovered many non-Abelian simple groups of finite and 
infinite order, but even the proof of such a basic statement as every finite 
non-Abelian simple group is of even order (conjectured by W. Burnside 
in the nineteenth century) seems to require almost all the immense 
apparatus of the present-day theory of finite groups.9 So we shall content 
ourselves here with the proof, given in § 15.4.3, that there exist infinitely 
many of these finite non-Abelian simple groups. 
13. 
Normalizer, Centralizer, Center 
In order to acquire insight into the structure of non-Abelian (i.e., 
noncommutative) groups, we must first introduce certain concepts, such 
as the commutator group, which measure the extent to which a group 
departs from being commutative. 
13.1. 
For a given complex Sl of the group (fj let us enumerate the com-
plexes conjugate to Sl. For this purpose we note that the elements G E (fj 
for which G-lSlG = Sl form a subgroup, since from G11SlGI = G;ISlG2 = Sl 
it follows that G2SlG;1 = Sl and (G1G;I)-ISl(G1G;I) = G2G11SlG1G;1 = Sl. 
9 For the proof of this theorem, see: Feit, W., and Thompson, J. G., Solvability of 
groups of odd order, Pacific J. of Math. 13 (1963), pp. 775-1029. 

218 
PART 8 
ARITHMETIC AND ALGE8RA 
This subgroup is denoted by Nil and is called the normalizer of 5\ (in (fj). 
Then the statement 
G-l5\G = H-l5\H 
or 
is equivalent to 
HG-l E Nil 
or 
HE NilG. 
Thus the number of complexes conjugate to 5\ is equal to (fj: Nil . 
If U is a subgroup of (fj, it follows from the definition of Nu that Nu 
is the largest subgroup of (fj in which U is a normal subgroup. If the 
complex in question consists of the single element G, then N G is called 
the centralizer of G, and more generally 
Zil = n NG 
Geil 
is the centralizer of the complex 5\. This centralizer consists of all the 
elements of (fj that commute with every element of 5\. If (fj is Abt!lian, 
then Zil = (fj for every complex 5\ ~ (fj. The complex Zil is a subgroup 
of (fj, since it is the intersection of certain subgroups. The centralizer Zm 
of the whole group (fj is called the center of (fj. The center Z(jj is Abelian, 
and every subgroup of it is a normal subgroup of (fj. 
13.2. If the factor group (fj/3 of a subgroup 3 in the center of (fj is 
cyclic, then (fj is Abelian: for if (fj/3 = (3(fj), then every element (fj E (fj 
can be written in the form 
G=ZG", 
with Z E 3. But for two elements G1 = ZlG"l, G2 = Z2G"·, Zl , Z2 E 3 we 
then have 
G1G2 = ZlG"lZ2G"· = Z2Z1G"2G"l = Z2G"IZ1G"l = G2G1 · 
13.3. The relation of conjugacy is easily seen to produce a partition into 
classes for the elements of (fj. The single-element classes are exactly the 
elements of the center of (fj. If K1 , ••• , K" are representatives of the 
remaining classes, the result of §13.1 shows that the following equation 
must hold for the number of elements in 
(1) 
with ZK "* (fj; i = I, ... , r. This equation is called the class equation of(fj . 
• 

2 Groups 
219 
For 6(3) there exist three classes of conjugate elements: 
{l}, 
{a, ,8}, 
{y, 8, €}. 
Thus the class equation is 
6 = 1 + 2 + 3. 
14. p-Groups 
14.1. 
A finite group (fj of prime power order plY. is called a p-group. 
From the results of the preceding section we can show that p-groups are 
solvable. For this purpose we require the following lemma: 
If (fj is a p-group, then ZeD -=1= 1. 
Proof. 
The indices (fj : Zi on the right side of the class equation for (fj 
are -=1= 1, and since they are factors of the order of the group, they must be 
powers of p. The left side is plY.; therefore p must be a factor of Zm : 1. 
From this lemma we see at once that every p-group is solvable. 
Proof. The theorem is true if (fj is Abelian. For (fj : 1 -=1= p it then follows 
by complete induction on the order, first for (fjjZm and Zm and then for (fj, 
if we construct a composition series for (fj that passes through Zm . 
We leave to the reader the proof that every maximal subgroup of a 
p-group is a normal subgroup, as well as the verification of these theorems 
for the examples B2•0 and .Q (§1.2.7, §6.2). 
14.2. 
Since the foregoing theorems show that the order of the center 
of a group of order p2 is either p or p2, the factor group with respect to 
the center of such a group is either of order p or of order 1, and thus is 
cyclic in every case. As was shown in §13.2, it follows that a group of 
order p2 must be Abelian. The existence of non-Abelian groups of order p3 
is shown by the examples B2•0 and .Q (§§1.2.7, 6.1). 
14.3. 
The great importance of p-groups for the general theory of 
finite groups rests on the fact that the order of a subgroup is a factor 
of the order of the group (§3.5). But the example 6(4) shows that the 
converse is not necessarily true; i.e., there exists a factor d of 6(4) : 1 for 
which there is no subgroup of order d. However, we do have the theorem of 
Sylow: if plY. is the highest power of the prime p which is a factor of (fj : 1, 
then there exists in (fj a subgroup of order plY.. Thus every group contains 
at least one subgroup whose order is the highest possible power of p 
permitted by the theorem of Lagrange (§3.3(8). The proof proceeds by 
induction on the order of (fj, as follows. For (fj = 1 the theorem is obvious. 
Now let us first suppose that there exists a proper subgroup U of (fj, 
whose index (fj : U is not divisible by p. Then p is a factor of U : 1. If 

no 
PART 8 
ARITHMETIC AND ALGE8RA 
we now assume that the theorem has already been proved for all groups 
of order smaller than (fj : 1, then U contains a subgroup of order P'\ 
which as a subgroup of (fj provides the desired result. If p is a factor 
of the indices of all the subgroups, then p must be a factor of 
Z(jj : 1 in the class equation §13(1) for (fj, since (fj: 1 and all the 
(fj : ZK are divisible by p. By the fundamental theorem on finite 
, 
Abelian groups, there exists in Z(jj a subgroup ~o -=I=- 1 whose order is a 
power of p, say ptY.o• This subgroup is a normal subgroup of (fj and the 
group (fj/~ is of smaller order than (fj. The greatest power of p that divides 
(fj : ~o is pl%-tY.o• Thus by the induction hypothesis there exists in (fj/~o a 
subgroup ~/~o of order pl%-I%o. Then the subgroup ~ of (fj has the order po, 
as was to be proved. 
The p-subgroups whose existence has just been proved are called 
Sylow p-groups of (fj, in honor of their discoverer. The theorem does not 
state that there exists only one Sylow p-group for every prime p, but 
Sylow did prove that every p-subgroup of (fj has a conjugate in an 
arbitrarily preassigned Sylow p-group of (fj, so that, in particular, all 
Sylow p-groups of (fj for a fixed prime p are conjugate to one another. 
The p-groups are incl uded in a larger class of groups, the so-called 
nilpotent groups, which are defined as the direct products of groups of 
prime power order. They are of particular interest because for them we 
can prove the converses of the theorems given above for p-groups. For 
example: a finite group is nilpotent if and only if every factor group has the 
property that its center is not merely the unit element. Or: a finite group is 
nilpotent if and only if every maximal subgroup is a normal subgroup. 
For lack of space the proofs must be omitted. 
15. 
Permutation Groups 
15.1. 
Representations 
In the example of groups of motions we have seen that a group may be 
much easier to investigate if it is not defined abstractly, say by its multi-
plication table, but in some geometric way. One simple but effective 
method (see the examples below) for getting a clearer picture of the 
concept of a group is to investigate the possibilities of representing the 
group as a permutation group, that is as a subgroup of SIR for a suitable 
space 9t. Let us examine these possibilities. 
15.1.1. 
For an arbitrary group (fj let u be a homomorphism of (fj into 
SIR. Then u is called a permutation representation of (fj in 9t or simply a 
representation. The number 19t I of elements in 9t is called the degree of 
the representation. 
If Ul , U2 are representations of (fj in 9t1 and 9t2 , respectively, and if th. 

2 Groups 
n1 
two permutations differ only by a renaming of the permuted points, 
i.e., if there exists a one-to-one mapping T of 9t1 onto 9t2 such that 
(1) 
for all 
G E (fj and P E 9t1 , 
then we say that Ul and U 2 are similar. The relation of similarity obviously 
produces a partition into classes and, as we have done up to now for 
isomorphic groups, we shall consider similar representations as essentially 
not distinct. For example, the two representations U 1 , U 2 of the cyclic 
group (fj = {I, G} of order 2 in 9t1 = {a, b, c} and 9t2 = {A, B, C} are 
similar: 
10 1 = (a b C) 
abc' 
(A B C) 
1
0
2 = ABC' 
Gal = (a b C) 
b a c ' 
(A B C) 
G
0
2 = 
B A C' 
Here the relation (1) is established by the mapping T with 
(If = A, 
15.1.2. 
When a fixed representation U of (fj in 9t is being considered, 
we shall for brevity set 
PGo = PG, 
PE9t. 
For every P E 9t the elements G E (fj leaving P fixed form a subgroup 
(fjp = {G I PG = P}, as we have seen in §3.3.4. We shall call it the fix-
group of P. 
Subspaces of 9t of the form P(fj are called domains of transitivity of u. 
Every element P E 9t is contained in exactly one domain of transitivity, 
SInce 
i.e., 
implies 
and 
P1(fj = P 2(fj· 
Thus the domains of transitivity 9t(i) of 9t produce a partition into classes 
of 9t: 
9t = 9t(1) U ... U 9t(,.), 
9t(i) (\ 9t(k) = 0 
for 
i -=F k. 

ill 
PART 8 
ARITHMETIC AND ALGE8RA 
For every i = I, ... , r the representation a induces a representation at 
of (fj in m(i), which is related to a in the following way: 
Thus it is sufficient to consider representations a of (fj in 9t for which 
9t itself is a domain of transitivity. Such representations a are said to be 
transitive. 
Transitive representations of (fj can be obtained in the following way: 
choose a subgroup U of (fj and then in the set 9t of cosets UH of U define 
the permutation Gau by 
Since 
(UH)Gal( = UHG. 
(UH)(G1G2)au = UHG1G2 
= (UHG1) G2 
= «UH) G~U) G~u 
= (UH) G~uG~u, 
it follows that au is a representation of (fj. Every coset has the form 
UG, G E (fj, so that the representation is transitive. We call it the 
representation of (fj induced by U. It is clear that U is the fix-group of U 
(as a point of 9t) and (fj : U is the degree of au . 
Then the following theorem shows that, up to similarity, we have thus 
obtained all the transitive representations of (fj: if a is any transitive 
permutation representation of (fj in 9t and if P E 9t, then a is similar to 
the representation au of (fj induced by U = (fjp • 
Proof. Since 
PH~ = PH~ 
is equivalent to 
and to 
or 
the mapping T defined by 
is a one-to-one mapping of m into the set of right cosets of (fjp , and the 

2 Groups 
n3 
transitivity means that every coset of (fjp is an image under T. Finally, 
for Q = PHa we have 
so that (1) is satisfied for a 1 = au , a2 = a. 
For transitive representations of (fj in 91 the preceding theorem implies 
in particular that 
(2) 
(fj : I = «(fjp : I) . 1 91 I. 
Consequently, the degree of a transitive representation is a factor of the 
order of the group. 
We remark without proof that the representations induced by two 
subgroups U, ~ are similar if and only if the subgroups are conjugate 
under (fj. 
15.1.3. 
Of particular importance is the representation of (fj induced 
by the subgroup I, the so-called regular representation of (fj. It plays an 
especial role in the history of the subject, since it was used by Cayley to 
show that every abstractly defined finite group can also be defined 
"concretely," namely, as a permutation group. 
15.1.4. 
We now wish to determine the kernel (fja for a transitive 
representation a of (6. For this purpose we first note that if PG = Q, 
G E (fj, P E 91, and Q E 91, then (fjQ = G-l(fjpG, as is clear from the fact 
that Q = QH is equivalent to 
and 
so that 
PG = PGH 
P = PGHG-l, 
GHG-l E (fjp, 
H = G-l(fj pG. 
Thus it follows from the transitivity of a that for an arbitrary but fixed 
point P E 91 the subgroup 
leaves every point of9t fixed and is the kernel of a. It is the greatest normal 
subgroup of (fj in (fj p , as is easily shown. 
15.2. 
The Symmetric Group of Permutations 
In the preceding section we have discussed group representations as 
subgroups of the symmetric group. This discussion can be made more 

n4 
PART 8 
ARITHMETIC AND ALGE8RA 
useful for the general theory of groups through a closer study of the 
structure of e;IR, to which we shall devote the next two sections. By 
regarding e;IR and its subgroups as being represented by the identical 
representation of themselves we can make use of the results of the 
preceding section, for which purpose it is convenient to apply the concept 
of transitivity not to the representation but to the group itself. We assume 
throughout that 9t is finite. 
15.2.1. 
The group e;IR is obviously transitive, and for P E 9t we have 
e;!R-p r'-I e;~, since 
e;~ contains all permutations of the points in 
9t -
P. Thus by (2) 
e;IR : 1 = (e;IR-p : 1) . I 9t I. 
Since e;IR : 1 = I for I 9t I = I, it follows by complete induction on the 
power I 9t I that 
e;IR : 1 = I 9t I ! 
Now let a be an element of e;IR. The domains of transitivity of (a) 
have the form 
{P, Pa, ... , Pan-I}, 
where n is the smallest positive integer with the property Pan = P. Then 
a can be written as 
(3) 
(
p Pa ... Pan-1Q 
... ) 
a = PaPa2 ... P 
Qa ... ' 
where P, Q, ... are representatives of the various domains of transitivity 
of (a). If the points of 9t, except for P(a), are left unchanged by a, we 
write simply 
a = (P, Pa, ... , Pan-I) 
and call a a cycle of length n. For example, 
( I 2 3 4 5 6) 
a = I 6 3 2 4 5 = (2 6 5 4) 
is a cycle in e;(6). 
Cycles are of special importance, since every element a E e;IR is the 
product of pointwise disjoint cycles. As can be calculated at once, the 
element (3) may be written in the form 
(4) 
a = (P, Pa, ... , Pan-I)(Q, Qa, ... )( ... ) ... , 

2 Groups 
which is called the canonical decomposition of a into cycles. Thus for 
this decomposition is 
(5) 
(1 2 3 4 5 6 7) 
a= 3415672 
a = (1 3)(2 4 5 6 7). 
115 
In order to include the identical permutation 1 in this form of writing 
we set 
1 = (P) 
with an arbitrary P E e;9i. 
15.2.2. The advantage of the cycle notation lies not only in its greater 
conciseness but also in its convenience for determining the order and 
conjugacy of permutations. 
Thus we see at once that for a single cycle the order is equal to the 
degree: 
for 
1 ~ m < n. 
Since pqintwise disjoint cycles are permutable, we have 
a = (Pn ... Pln1)(P21 ••• P2n2) ... (PSI'" Psn,): 
(6) 
am = (Pu ... Pln1)m(P21 ••• P2n2)m ••• (PSI'" psn,)m, 
so that am is equal to the identical permutation if and only if 
mInI' ... , mIn, . 
Thus the order of a is equal to the least common multiple of the length 
of the cycles in the canonical decomposition of a. 
For example, the element a in (5) has the order 10. 
We now wish to determine which elements are conjugate in e;9i to the 
permutation whose canonical decomposition is given by (6). Let f1 E e;9i. 
We see that 
is the canonical decomposition of {3-la{3, since 
(Pn {3) {3-1 = Pn , 
so that 
and so forth. 

n6 
PART 8 
ARITHMETIC AND ALGE8RA 
For example, 
~ = 
(~ i ;), 
a = (1 3) 
~-la~ = (2 3). 
We shall say that a and a* = ~-la~ are similar, by which we mean that 
the cycles in the canonical representation of a and a * can be put into 
one-to-one correspondence with each other in such a way that corre-
sponding cycles have the same length. Then our problem is already 
solved: Two elements of e;9i are conjugate in e;9i if and only if they are 
similar. 
For the proof we need only show that two similar permutations 
a = (Pn ... Plnl) '" (PSI'" Psn,), 
a* = (Pil ... Pt;) ... (Psi ... P:n) 
are conjugate to each other. But with 
~ = (P~ ... P~n.), 
PII ... P sn, 
it is easy to calculate that ~-la~ = a*, as required. 
15.2.3. 
From this result a permutation g E e;9i in which ga = ag for 
all a E e;9i cannot be similar to any other permutation in e;9i. For if 
g = I, the statement is certainly true for an arbitrary 9t, and for I 9t I = 2 
it is true for the permutations distinct from 1. For I 9t I ~ 3 we see 
that 
and 
are similar and that a -=1= a', since Pna -=1= Pn~'. Thus for 19t I ~ 3 the 
center of e;9i consists only of the identical permutation 1. For I 9t I = I, 2 
the group e;9i is obviously Abelian. 
15.3. 
The Alternating Group 
15.3.1. 
A cycle of degree 2 is calIed a transposition. Every finite cycle 
is a product of transpositions: 

2 Groups 
n7 
Since every permutation can be written as a product of cycles, it follows 
that all permutations are also products of transpositions. However, the 
transpositions are not necessarily pointwise disjoint. For example, 
( I 2 3 4 5) 
2 3 I 5 4 
= (1 2 3)(4 5) = (2 3)(1 2)(4 5). 
Thus the group e;\R is generated by the transpositions in 91. 
15.3.2. 
The elements of e;\R that can be written as the product of an 
even number of transpositions are called even transpositions. They form 
a normal subgroup of e;\R, since for 
a = (PIQI) ... (P2kQ2k), 
f3 = (RISI) ... (R2lS2a 
the element af3-1 = (PIQI) ... (P2kQ2k)(R2lS2l) ... (RISI) is also the prod-
uct of an even number of transpositions, and conjugate permutations 
are similar to each other. This normal subgroup is called the alternating 
group in 91 and is denoted by ~(\R. We now wish to prove: for 191 1 *- I, 
the alternating group ~(\R has index 2 in e;\R, so that ~(\R has the order 
191 1 !/2. 
For the proof we take 91 = (n). Then for an arbitrary polynomial 
[(Xl' ... , xn) in the indeterminates Xl , ... , Xn a E 6\R we define 
jrx(XI , ... , xn) = f(xlrx , ... , xnrx), 
so that 
As a particular polynomial let us consider the difference product 
i.k=l ..... n 
i<k 
Apart from a change of sign, the application of a to L1 merely permutes 
the factors of the right-hand side: 
so that 
E",BL1 = L1rx,B = E"L1,B = E"E,BL1. 
The mapping E : C"\: ----+ E" is therefore a homomorphism of e;\R into the 
cyclic group of order 2. The desired theorem now follows from the 
homomorphism theorem if we show that E is a homomorphism onto 
this group and that its kernel is ~(H. But it is easy to show that 
L1(12) = -L1, 

228 
PART B ARITHMETIC AN 0 ALGEBRA 
so that E'(12) = -1. Also, since every transposition (ab) in 6(n) is 
conjugate to (12), say 
~-1(1 2) ~ = (a b), 
we have 
E'(4b) = E'1J-IE'(12)E'1J = (E'1J)-1E'(12)E'1J = E'(12) • 
The product of an even number of transpositions is thus mapped by 
E' onto I, and the product of an odd number onto -I, so that the proof 
of the theorem is complete. 
15.3.3. 
For I 9t I = I we have 21(1) = 6(1), and for n = 2, 3 the 
order of 21(n) is I, 3, respectively. For n = 4 the permutations 
(1 2)(3 4), 
(1 3)(2 4), 
(1 4)(2 3), 
together with the unit element 1 form a normal subgroup of21(~U of order 4, 
the so-called four-group. The lattice of subgroups of 21(~U is given in 
Figure 33. In all other cases 21(n) is simple (and non-Abelian), as we shall 
show in the next section for n = 5. 
Order 
Z 
Order 
I,. 
Order 
12 
Fig. 33 
15.4. 
Applications of the Theory of Permutation Groups 
to the General Theory of Groups 
Let us now give some examples to show how our results on permutation 
groups can be applied to the general theory of groups. They are all 
concerned with the important question of finding conditions under 
which a group is simple. 
15.4.1. 
For a representation a of (fj in 9t the index (fj : (fjo is always 
a factor of I 9t I!, since the homomorphism theorem shows that (fj/(fjo is 
isomorphic to a subgroup of ffiIR. Thus for the representation induced 
by a subgroup U of (6, the index of the greatest normal subgroup of (fj 

2 Groups 
n9 
contained in U is a factor of ((fj : U)!' If (fj is simple, there is no subgroup 
U in (fj for which ((fj : U)! < (fj : 1. Since the group 21(5) is shown below to 
be simple, it contains no subgroup with index 2, 3, or 4. 
15.4.2. If (fj is a group of order 2u with odd u, then (fj contains a normal 
subgroup 91 with index 2. For let a be the regular representation of (fj 
in 9t (= (fj). Then G E (fj, G * 1 leaves no point of 9t fixed, since 1 is the 
fix-group for all points of 9t. Now let G be an element of order 2, which 
must exist by the theorem of Sylow for p = 2. The canonical decom-
position of Ga into cycles consists of u transpositions. Thus Ga is not an 
element of 219i, so that the intersection (fja (') 219i is * (fja. Also, since 
219i is a maximal subgroup of e;9i, we have 2191(fja = 
e;9i. By the iso-
morphism theorem it follows that 91a = 219i (') (fja is a normal subgroup 
of (fja and 
Consequently, 91 is a normal subgroup of (fj. Since the Burnside conjecture 
is now known to be true (§ 12.2), we have the result: 
The order of every non-Abelian simple group is divisible by 4. 
15.4.3. 
From the results of the preceding sections we now prove the 
existence, as stated above, of infinitely many non-Abelian simple groups, 
by showing that if (fj is a permutation group in 9t with 19t I = r a prime, 
and if (fj is generated by cycles of length r, then (fj is simple. 
Proof. The group (fj is transitive, since P(Z) = 9t for each of the 
generating cycles Z and P E 9t. Let 91 be a normal subgroup *1 of (fj. 
By (2) the fix-group (fjp has prime index r in (fj and is thus a maximal 
su bgroup of (fj. By § 15.1. 5 the normal subgroup 91 is not in (fj p , since 1 
is the only permutation in (fj that leaves fixed all points of 9t. Thus 
91o)p = (fj and by the isomorphism theorem 
Now only the first power of the prime r is a factor of (fj : 1, since (fj is a 
subgroup of e;9i and e;9i has the order r!. Thus (fjp : 1 and (fj : 9t are 
prime to r. If one of the generating cycles Z were not in 91, then 91(Z) 
would be greater than 91, and on the other hand it would follow from the 
theorem of isomorphism that 
91(Z) : 91 = (Z) : 91 (') (Z), 
so that 91(Z) : 91 would be a factor of (Z) : 1 = r and would thus be =r, 
in contradiction to the fact that (fj : 91 is not divisible by r. Consequently, 
all the generating cycles lie in 91, so that 0) = 91, and 0) is therefore 
simple. 

230 
PART B ARITHMETIC AN 0 ALGEBRA 
If in this theorem we choose the generating cycles in such a way that 
they are not all powers of a fixed element, as is always possible for r ~ 5, 
then the group generated by them is simple (and non-Abelian). Thus 
there exist infinitely many (nonisomorphic) non-Abelian simple groups. 
15.4.4. 
For example, the (non-Abelian) group generated by the two 
cycles 
(1 2 3 4 5 6 7), 
(2 I 3 4 5 6 7) 
is simple. 
For r = 5 there are 4! = 24 distinct cycles of degree 5. By §15.3.1 they 
are all products of r -
I transpositions and thus lie in ~(5). Since 
(a bed e)(c bad e) = (c e d), 
the 10 cycles of degree 3 also lie in the subgroup of 21(5) generated by the 
24 cycles of degree 5. But since 21(5) : I = 60 has no factor ~24 + 10, 
the theorem of Lagrange shows that this subgroup must be equal to 21(5). 
Thus the above theorem shows that 21(5) is simple. Let us state here 
without proof that there are no non-Abelian simple groups of order less 
than 60. 
16. 
Some Remarks on More General Infinite Groups 
The nature of the present work has restricted us to a discussion of the 
simplest and most general results concerning groups, although we have 
given some special theorems about groups of finite order. This preference 
for finite groups is justified by the fact that, both historically and in their 
importance for the whole of mathematics, finite groups have formed the 
backbone of group theory. Moreover, the general theory of infinite 
groups is not yet very well developed. Of greatest importance here are the 
finitely generated groups and the topological groups. To conclude the 
present chapter, we give one striking example for each of these two classes 
of groups. 
16.1. 
Free Groups with Finitely Many Generators 
Let {El , ... , En} be a finite set of distinct elements, Ei *- Ek for i *- k. 
We consider words W of the form 
(1) 
I ::::; il , ... , ir ::::; n, 
E"JJ = ±I, 
for 

2 Groups 
231 
A word of this sort is to be combined with another such word 
V=E~l ... Ef.' 
1 
., 
by the following rule: 
if 
i = 
r 
kl 
and 
E = 
r 
-01 
and 
ir- 1 = k2 
Er -l =c: -02 
and 
ir- n = kn+l 
Er-n = -On tl' 
but 
ir- n-1 "* kn+2 
or 
Er-n-1 "* -On~ 2 . 
Then WV is again a word of the form (I) if we consider the empty set 0 
as a word (the so-called empty word). If we now define W0 = 0 W = 
W 
for all words W, the set of words with the operation defined in this way 
forms a group fYn ,called the/ree group o/rank n. Its unit element is 0 = I, 
and W-l = E;'r ... E;'l is the inverse of (I). Clearly the structure of this 
r 
1 
group depends only on the number n and not on the special set {El , ... , En}; 
moreover, fYn = <El , ... , En). The group fYn may be considered as the 
most general group that can be generated by n elements. More precisely, 
every group ffi that can be generated by n elements G1 , .•• , Gn is isomorphic 
to a factor group of fYn . For example, an isomorphism of this sort results, 
by the homomorphism theorem, from the mapping 
which is easily seen to be an homomorphism. On the other hand, it is 
clear from §6.4 that every factor group of trn can be generated by n 
elements. 
If a system R1 , ••• , R t of elements of fYn' taken together with their 
conjugates under fYn , generates the kernel of a homomorphism" of fYn 
onto ffi, then the set of elements 
is said to define ffi. This term comes from the fact that if a product of 
elements in the system of generators {E;, ... , E~} of ffi is equal to I, 
then it can be obtained by constructing the inverses, transforms, and 
products of the elements R i , i = 
I, ... , t, and then modifying them by 
replacing Ei by E; , i = I, ... , n. 

232 
PART B ARITHMETIC AND ALGEBRA 
For example, 
or 
define the group 6(3). 
For a given Rl
, ... , Rf E 3'n, the question whether an element WE tJ'n 
lies in the normal subgroup generated by the Ri and their conjugates is 
usually very difficult. It is the so-called word problem; cf. lA, §5.3. 
16.2. 
Topological Groups 
If a topology is defined on a group (6 regarded as a set of elements 
the group (6 is said to be a topological group, provided the topology 
is consistent with the operation of the group; more precisely, if the 
mapping (G, H-l) -+ GH-l, G, HE ffi, of the product space (fj X (6 is 
continuous on (6. 
For example, the group R+ is a topological group if for every £ > 0 
the set of numbers Ua,E = {a* I a* E R+, I a -
a* I < £} is taken as a 
neighborhood of a. The continuity of addition is seen as follows: if 
Ua-b" is a neighborhood of a -
b, then a* -
b* E Ua- b•, for a* E Ua,'/2 , 
b* E Ub,,12, as is easily shown. Thus the image of the neighborhood 
V = Ua•,12 X Ub•,/2 of (a, b) under the mapping (a, b) -+ a -
b lies in 
UQ.+b", so that the mapping is continuous. 
More picturesquely, though perhaps somewhat less precisely, we may 
say that a topological group is defined if the product G* H*-1 "approaches" 
GH-l as G* and H* "approach" G and H. Then we may exploit the 
resources of topology, in much the same way as permutations were used 
above for finite groups, to investigate the structure of a group in which a 
topology is defined. 

CHAPTER 3 
Linear Aigebra* 
Outline 
The statements in this outline are not intended to be complete or rigorous 
and they sometimes refer to concepts that are not explained until later in the 
chapter. 
The solutions of a system of linear equations consist of n-tuples of 
numbers: I = (xl, ... , xn);l it may be that there is no solution, exactly 
one solution, or infinitely many. We are interested here in the existence 
of solutions, and particularly in how many of them there are. It turns 
out that the set of solutions (of a homogeneous system of equations, to 
which a nonhomogeneous system can be reduced) has a definite algebraic 
structure: in it we can perform the operations of addition and of 
multiplication by a number; in short, we can construct linear combinations. 
Such a structure is called a vector space and its elements are vectors. The 
name is to be explained by the historical association with geometry and 
physics, but here we are discussing a purely algebraic situation. The theory 
of solutions of systems of linear equations is part of the more inclusive theory 
of a certain algebraic structure, a "vector space." 
Starting from the n-tuples of numbers, we arrive at this structure by 
defining the two operations mentioned above and then working out the 
rules of computation that hold for these operations, whereupon the rules 
of computation become axioms for the "vector space" thus defined. To 
* The authors of this chapter are deeply indebted to G. Pickert for his valuable advice 
and assistance. 
1 As is customary in tensor analysis, we make use of subscripts and superscripts in 
such a way as to indicate the behavior of the magnitude in question under a transforma-
tion of coordinates. Except for -1 and for the exponents in (3) on page 286 there are 
no exponents in the present chapter. 
233 

234 
PART B ARITHMETIC AND ALGEBRA 
begin with, the n-tuples of numbers are merely examples or models of 
vector spaces, but it turns out that the vectors of any vector space can be 
represented by n-tuples of numbers (coordinates), though only after a 
(largely arbitrary) choice of n vectors as basis vectors. 
Thus, in the theory of vector spaces there are two points of view to be 
distinguished: either we base the development solely on the rules of 
computation (the axioms of the vector space) and produce a coordinate-
free theory, or else we introduce coordinates, in which case we must 
subsequently make our theory independent of the special choice of basis; 
that is, we must investigate the invariants of a transformation of basis or 
at least ask what happens under such a transformation. In any case, any 
concrete representation of vectors will usually be in the form of 
coordinates. 
The two points of view will be presented here side by side. In §I the 
foundations of the theory are developed. In §2 we investigate linear 
mappings of a vector space Vn of dimension n into a vector space Vk of 
dimension k. Generally speaking, these mappings will themselves form 
a vector space of dimension n . k. In the coordinates of the vector spaces 
Vn and Vk the mappings or transformations are represented by matrices. 
For the mappings of Vn into itself (Vk = Vn) it is possible, beside the 
operations of the vector space, to introduce a multiplication, namely 
successive application of mappings. The resulting structure is a ring, and 
we obtain the foundations of the theory of matrices. 
A change of basis in Vn and Vk results in a certain transformation of 
the matrix of the mapping. In this way a given matrix can be transformed 
into a diagonal matrix, and one of the applications of this particular 
transformation is the solution of a system of linear equations, the problem 
from which we started out. 
Linear mappings of the vectors of Vn onto numbers (i.e., those linear 
mappings for which Vk is a vector space of dimension I; in particular, the 
domain of scalars) are linear forms. They constitute the vector space dual 
to Vn , which is important in applications to geometry and elsewhere 
(cf. JI8, §4). 
In §3 we set ourselves the problem of introducing products of vectors. 
It turns out that we cannot satisfy all the rules for computation with 
numbers. After making a suitable choice of these rules we can state the 
requirements for such a product as follows: the taking of a product is to 
be a bilinear mapping of the pairs of vectors of V onto the vectors of a new 
vector space W. The various kinds of products result from various choices 
of W. If W is the domain of scalars, we obtain the inner or scalar product; 
then it is natural to investigate those changes of basis that leave the factors 
of the inner product invariant (of course, the inner product itself is 
invariant by definition); and thus we are led to the orthogonal transforma-

3 Linear Algebra 
235 
tions. In the applications an important role is played by the reduction 
of symmetric matrices to diagonal form by means of orthogonal trans-
formations. We shall deal with this problem in the complex plane; i.e., 
we investigate unitary ·transformations of Hermitian forms, since the 
proofs are the same as in the real field; but we must first develop the 
theory of determinants. 
If for W we choose a vector space of dimension n . n, we obtain the 
tensor product, and as its alternating part, so to speak, the outer or 
alternating product. The outer product of several factors leads to the 
determinant. The vanishing of the outer product characterizes the linear 
dependence of vectors. Since a system of (homogeneous) linear equations 
can be regarded as a query concerning the linear dependence of certain 
vectors (the column vectors of the coefficient matrix), we again obtain 
an insight into the theory of such systems of equations. 
1. The Concept of a Vector Space 
1.1. 
Introduction 
We start with the problem of finding the solutions of a system of linear 
equations 
n 
(I) 
" a KX" = bK 
~ " 
, 
(K = I, "', k). 
,,=1 
In the applications the a,,\ b
K are generally real or complex numbers. 
For the present we need only assume that they are elements of a field, 
which we call the domain of scalars S. Up to §3.2 we may even dispense 
with the commutative law. A system of elements that satisfies all the 
axioms for a field (cf. IB I, §3.2) except commutativity of multiplication, 
is called a skew field. Thus fields are themselves skew fields; an example 
of a noncommutative skew field, i.e., of a skew field that is not a field, 
is given by the quaternions (see IB8, §3). 
Thus we assume that the domain of scalars S is a skew field, and we call 
its elements scalars. The set of equations 
n 
(II) 
" a KX" = ° 
~" 
, 
(K = I, ''', k) 
,,=1 
is called the homogeneous system corresponding to (I). We shall nowhere 
need to assume that (I) is strictly nonhomogeneous, i.e., that at least one 
bi *,0. 

236 
PART B ARITHMETIC AND ALGEBRA 
The solutions of such a system of equations are n-tuples of elements of 
S, which we write in the form: 
or more briefly, if n is known, as (xv). 
Now our chief questions are whether such a system of equations has 
solutions and, if so, how many. Methods for numerical calculation of the 
solutions will turn up incidentally, but they are not the object of our 
investigation. 
We see at once that if (I) has two solutions 
then 3 = (Xl - yl, ... , xn - yn) is also a solution of (II). 
If (II) has several solutions x,\ = (X,\l, .. ', x,\n), ,\ = I, ... , I, then all 
linear combinations 
l 
3 = I x,\c'\ = (I x/c\ ... , I x,\nc,\) 
,\-1 
,\ 
,\ 
with arbitrary c,\ in S are solutions of (II). Thus it is natural to introduce 
an addition for n-tuples and a multiplication by scalars, and then to 
investigate the algebraic structure of the resulting configuration (for the 
definition of this word see IBIO). 
1.2. 
Calculation with n-tuples 
Two n-tuples are equal if the corresponding scalars are equal; in other 
words, 
(G) 
(xv) = (yv) if and only if 
XV = yv for every v. 
Of course, this definition of equality is part of the definition of an n-tuple 
as a mapping of the numbers I, ... , n into the set of scalars. 
It is easy to show that equality as thus defined is reflexive, symmetric, 
·and transitive and is therefore an equivalence (see lA, §8.3 and 5). 
Addition can be introduced as follows: to the n-tuples x = (xv), 1) = (yv) 
we assign the n-tuple (xv + Y') as their sum. The sum defined in this way 
clearly has the following properties: 
(A I) Existence and uniqueness: two n-tuples x, 1), have exactly one 
n-tuple as their sum, which we denote by x + 1); 
(A2) Consistency with equality: from x = u and 1) = D it follows that 
x + 1) = U + D. 

3 Linear Algebra 
237 
(A2) is a special case of the general principle of equality in logic: if A (I. 1). 3) 
is a statement about I. 1). 3. then A (I. 1). 3) and I = U. 1) = 0. 3 = w imply 
A (u. 0. w). In our case A (1.1). 3) is the statement I + 1) = 3. Only this special 
case. and the corresponding case (M2) for multiplication. will be needed below. 
On the basis of (AI) and (A2) our addition is an operation defined on 
the set of n-tuples. and the corresponding statement holds below for (M I). 
(M2). We write 
(A) 
x + 1) = (xv) + (Y") = (xv + yv). 
By (G). (A). and the rules for a skew field we have the 
(A3) associative law: 
x + (1) + 3) = (x + u) + 3; 
(A4) commutative law: 
x + 1) = 
1) + x; 
(A5) 
neutral element: there exists an n-tuple 0 such that x + 0 = x for 
every x. namely 0 = (0 •...• 0). It follows that there can be only one 
neutral element. for if 0 and 0' were two such elements. we would have 
0' + 0 = 0' and 0 + 0' = o. so that by (A4) and the transitivity of 
equality 0' = o. 
(A6) 
inverse elements: for every x = (xv) there exists an x' with 
x + x' = o. namely x' = (-xv). We write x' = -x and 1) + (-x) = 1) -
x. 
From (A I) to (A6) follows (A5'): for every pair of n-tuples u. 0 there 
exists exactly one n-tuple with u + x = o. namely x = 0 -
u. 
On the other hand. (A5) and (A6) follow from (A I) to (A4) and(A5'), 
if we postulate the existence of at least one element. (Cf. also IB I. §2.3 
and IB2. §2.4.) 
Multiplication by scalars is introduced as follows. Since we shall 
naturally wish to be able. for example. to write x + x = x . 2. i.e .• 
(Xv) . 2 = (xv) + (xv) = (xv + xv) = (xv. 2). 
we define right-multiplication of an n-tuple (xv) by an element s of S 
(S-multiplication on the right; the scalar s is written to the right of the 
vector x) by setting 
(S-M) 
x . s = (Xl, ... , xn) . S = (Xl. S • ••• , Xn . S). 
or, more concisely, 
(xv) . S = (Xv. S). 
This scalar product. as well as the product in S and later the product of 
two matrices. will be denoted by writing one factor after the other with or 
without an intervening dot. depending on whether or not the dot seems conducive 
to clarity. Since these three kinds of products will be distinguished from one 
another by the notation for their factors. they can all be written in the same way. 

238 
PART B ARITHMETIC AND ALGEBRA 
It must be pointed out that s . x is not yet defined, even when S is 
commutative. For the time being we shall not require this left-multiplica-
tion; when it is needed later, we shall define it by setting s . (xv) = (s . xv). 
If S is commutative, then s . x = x . s. 
This definition (of scalar multiplication on the right) implies 
(M 1) the existence and uniqueness of the S product: for every n-tuple x 
and every s in S there exists exactly one n-tuple 1) = X • s. 
In the same way as for addition, it is easy to show that 
(M2) the S-multiplication is consistent with the equality: x = 
1) and 
s = t implies x . s = 1) • t; 
(M3) the associative law: x . (s . t) = (x . s) . t; the distributive laws 
(M 4) (x + 1») . s = x . s + 1) • s, 
(MS) x· (s + t) = x . s + x . t; 
and further, 
(M6) if I is the unit element of the skew field S, then x . I = x. 
A set of elements (here n-tuples) in which these rules for computation 
are defined, is called a vector space. Abstractly we make the following 
definition: 
Let V be a set in which there is defined an addition satisfying the laws 
(axioms) (AI) to (A6); let S be a skew field, and let there be defined an 
S-multiplication satisfying the laws (M I) to (M6). Then V is called a vector 
space over S, and its elements are called vectors. 
Thus, V is a commutative group with respect to addition. The skew field S 
is a skew subfield (up to isomorphism) of the ring of endomorphisms of this 
group. For if to each element s of S we assign a mapping a : I ---+ I . s, then 
(M4) means that a is an endomorphism, (M3) states that the product of two 
endomorph isms is defined by successive application of the mapping, and 
(MS) is the usual definition of the sum of two endomorph isms. (See IB1, §2.4 
or B. L. van der Waerden [2], page 148). Consequently, from a given 
commutative group we can construct a vector space by selecting a skew field 
from the ring of endomorph isms of the group. 
Consequences from the axioms of a vector space are: 
1) If 0 is the zero element of S, then x ·0 = 0 for every x. 
Proof: Since 
x . 0 = x . (0 + 0) = x . 0 + x . 0, 
therefore, by (AS'), 
x . 0 = x . 0 - x . 0 = o. 

3 Linear Algebra 
239 
2) For every s in S we have 0 . s = o. The proof is analogous to that 
of (I). 
3) Conversely, if x . s = 0, then s = 0 or x = o. 
Proof. Let x . s = 
0 and s"* O. Then 
x . I = x . s . (lIs) = 0 . (lIs) = o. 
4) -x = x . (-I). 
Proof. x + x . (-1) = x . (I -
1) = o. 
Often (for example, in IB6, §8) we speak of a vector space over S even when S 
is not a skew field but only a ring (with unit element). But then, besides 
(AI to A6) and (MI to M6) it is necessary to postulate the existence of a basis 
(see §1.3); for if S is not a skew field, it is no longer possible (as in §1.3) to 
deduce the existence of a basis from (AI to A6) and (MI to M6). 
1.3. 
Linear Dependence. Basis 
Addition and S-multiplication can be combined into the concept of a 
"linear combination." A vector c is said to be a linear combination of the 
vectors a.1 , ... , an , or to be linearly dependent on these vectors, if there 
exist cl, ... , cn in S such that 
n 
C = al c1 + ... + ancn = I a"c". 
,,=1 
With regard to the notation, we shall usually omit the sign L by agreeing 
once and for all (with Einstein) that summation is to be taken over equal Greek 
superscripts or Greek subscripts. Of course, it must be clear from the context 
what values the indices are to assume. 
We use Greek letters (as variables) for the indices when we mean that all 
possible values of these indices are to be assumed successively (in the language 
of logic, a Greek letter denotes a bound index variable; in our notation for 
n-tuples the binding can be expressed by (XIl)II=l •... ,"). If we are referring to a 
definite value of the index, we use a Latin letter. Consequently, summation 
is not to be taken over Latin indices. 
Thus, a vector space over S is a set in which it is always possible to form 
linear combinations of its elements with the elements of S. It is to this 
characteristic feature that the concept "vector space" owes its importance. 
Preliminary discussion. If e1 , ... , en are given vectors, then the set of 
linear combinations x = e"x", x" E S, forms a vector space, as is easily 
shown. Conversely, we shall obtain a good picture of a given vector space 
V if we succeed in finding a set (presumably finite) of vectors e1 , ... , en 
such that every vector x in V is representable (as far as possible, uniquely) 

240 
PART B ARITHMETIC AND ALGEBRA 
as a linear combination I = e.,x", and we shall see that in fact this is 
always possible. But then the vector is determined by the n-tuple (X"), so 
that the vector space V is characterized by the n-tuples of S. Thus a set of 
n-tuples is not only a particular example of a vector space, but every 
vector space is representable as the set of n-tuples in S; the various vector 
spaces over S are distinguished from one another only by the number n. 
Development. To carry out these ideas precisely we shall need the 
following concepts: the vectors a1 , "', an are said to be linearly dependent 
if there exist scalars cl, ... , cn, not all 0, such that a"c" = 0; but if a"c" = 0 
implies that all c" = 0, the given vectors are said to be linearly independent. 
The following theorems are immediate consequences of the definition: 
Theorem la: if for some i (1 ~ i ~ n) we have ai = 0, then a1 , "', an 
are linearly dependent. 
Theorem Ib: if the vectors a1 , ••• , an are linearly dependent, then so 
are the vectors a1 , ••• , an , an+1 , ••• , an+JI • 
Theorem 1 c: if the vectors a1 , ••• , an , an+1 , ••• , an+JI are linearly 
independent, then so are the vectors a1 , ••• , an . 
Note. The order of the vectors has no effect on linear dependence. 
The system e1 , •.• , en is called a basis of V if for every vector a in V there 
exist n elements a" in S such that 
1) a = evO" (reminder to the reader: summation over v is from 1 to n), 
2) a = evO" = ejJ" implies a" = b" for all v; in other words, the 
representation is unique. 
The a" are called the coordinates of a with respect to the basis 
(e,,). Condition (2) is equivalent to 
2') e1 , ••• , en are linearly independent. 
Proof. 
(a) Assume (2) and e"c" = o. Since L" ell . 0 = 0, it follows from 
(2) that c" = 0 for all v. 
. 
(b) assume (2') and evO" = e"b". 
Then it follows that e,,(a" -
b") = 0, so that by (2') we have a" -
b" = 0 
for all v. 
A vector space can have various bases; but we shall see that the number 
(n) of basis elements is always the same. This number is called the dimension 
of the vector space, which we then denote by Vn . 
The above assertion follows easily from the next theorem. 

3 Linear Algebra 
241 
Theorem 2: If the n + 1 vectors a1 , •.. , an+1 are linear combinations of 
n vectors e1 , •.• , en , 
v = 1, ... , n, 
K = 1, ... , n + 1, 
then ai' ... , an+1 are linearly dependent. 
The proof is by complete induction. 
Initial step: 
for n = 1 we have a1 = e1a1!, a2 = e1al. If all = ° or 
a21 = 0, then the assertion is correct by Theorem la. Otherwise, 
al . (a11)-1 - a2(al)-1 = o. 
Completion of the induction: 
let 
a 1 = e1a11 + e~12 + ... + ena1n 
a2 = e1al + e2a22 + ... + ena2n 
If all a1" = 0, the assertion is correct by Theorem la. We may assume 
all -=1= 0, since for all = 0, ali -=I=-° the proof is exactly the same. Then 
the n vectors 
are linear combinations of the n -
1 vectors e1 , ... , en , so that they are 
linearly independent by the induction hypothesis; that is, there exist 
X2, ... , xn+1 E S, not all = 0, such that 
Substitution of the above expressions for the b" gives 
where at least one of the coefficients of a2 , ••• , an+! is -=1=0. 
From Theorem 2 follows 
Theorem 3: if V has a basis of n elements C1 , ••• , Cn , then: 
a) Every n + 1 elements of V are linearly dependent. 
b) Consequently, no basis of V has more than n elements. 
c) No basis can consist of fewer than n elements; for otherwise C1, ••• , en 
would be linearly dependent. 

242 
PART B ARITHMETIC AND ALGEBRA 
d) Every n linearly independent vectors °1 , ••• , On of V form a basis. For 
if a is an arbitrary element of V, then by (a) the vectors 01 , ... , On , a are 
linearly dependent; that is, there exist a" (v = 0, I, ... , n), not all = 0, 
such that 
Here a O *- 0, since otherwise °1 , ... , On would be linearly independent, 
and therefore a is representable as a linear combination of 01 , ... , On • 
Thus the dimension n of V can also be characterized by the fact that 
there exist n linearly independent vectors in V and every n + 1 vectors are 
linearly dependent. If and only if it has this property, does the vector 
space V have a basis of n elements. But this characterization of dimension is 
independent of the choice of basis. 
The concept of a "basis" was first introduced by Dedekind for modules 
(supplement XI to Dirichlet's Zahlentheorie, 3rd ed., 1879, §165) and was 
used for ideals. He did not require that the representation be unique, and he 
allowed the domain of coefficients to be a ring. The concept of a "basis" in 
this sense occurs in Chapter 5, §3.2. 
The dimension of a vector space over S determines the vector space 
uniquely up to isomorphism; in other words, we have the isomorphism 
theorem: two vector spaces V, V' over the same domain of scalars S are 
isomorphic if they have the same dimension. 
The proof is almost trivial when we consider what is to be proved. 
Vector spaces Vand V' are said to be isomorphic if there exists a one-to-one 
mapping of V onto V' (x -- x') with the property that 
(x + 1»)' = X I + 1) I 
and 
(x . s)' = x' . s. 
But if C1 , ... , Cn is a basis of V, and c~, ... , c~ is a basis of V', then 
c"x" -- <X" is a mapping with the required properties. 
In analysis, an important role is played by vector spaces of infinitely 
many dimensions; for example, the real functions that can be represented 
as a Fourier polynomial in the interval (-7T, + 7T) form a vector space 
over the field of real numbers; for this vector space the functions 1, 
cos (vx), sin (vx), (v = 1, ... ) are a basis. More generally, the representation 
of functions in an orthogonal series may be regarded as a representation 
of the vector space formed by the functions (cf. III, II). But in the present 
chapter we consider only 'cector spaces offinite dimension. (For the existence 
of a basis in a vector space that is not necessarily finite-dimensional, see 
IBII, §3, Theorem 2.) 
When we consider the sets of n-tuples of elements of S as a vector space, 
as we did in § 1.2, we are representing the space in terms of the special 
basis C1 = (1,0, ... ,0), C2 = (0, 1,0, ... ,0) ... , Cn = (0,0, ... ,0, 1). 
It is easy to see that S itself is a vector space of dimension lover S. 

3 Linear Algebra 
243 
1.4. 
Vector Subspaces 
A subset V of a vector space V over S is called a ['ector subspace if V 
itself is a vector space over S and if the addition and the S-product in U 
are the same as in V. 
If V is a vector subspace of V, we have: 
I) if ° E U and b E U, then ° + b E U; 
2) if ° E V and s E S, then ° . s E V. 
These two conditions are also sufficient for a non-empty subset V to be 
a vector subspace of V. To prove the sufficiency, we must verify the laws 
(A), (M) for V. The associative law 
(x + 1») + 3 = x + (1) + 3) 
holds for arbitrary elements of V, and thus in particular when x, 1), 3 are 
elements of V. The same remark holds for all those laws in which the words 
"there exists" do not occur. The existence of the sum and the S-product 
in V is guaranteed by (I) and (2). It remains to verify (AS) and (A6). As 
for (AS), for an arbitrary x E V we have x . 0 E V and from § 1.2, corollary I, 
it follows that x . 0 = o. As for (A6), if x is an element of V, then so is 
X· (-I) (see §1.2, corollary 4). 
The intersection of two or arbitrarily many vector subspaces is again 
a vector subspace. For the proof we need only verify (I), (2). The 
necessary definitions are: 
X E VI n V 2 
if and only if x E VI 
and 
x E V 2 • 
If 9Jl is a non-empty set of vector subspaces, then x E nUEml V if and 
only if x E V for all V E 9Jl. 
If 01 , "', Ok are arbitrarily given elements of Vn , the smallest subspace 
V of Vn containing 01 , ... , Ok is called the subspace spanned or generated 
by 01 , ... , Ok • The word "smallest" here means that V is the intersection 
of all subspaces containing °1 , ... , Ok, so that the existence of V is 
guaranteed. Of course, it may happen that V = 
V. 
A basis for the subspace spanned by the vectors 01 , "', Ok can be found 
by writing the 01 , ... , Ok in any order and then striking out every Ok that 
is linearly dependent on its predecessors. 
To prove this statement we enumerate the vectors in such a way that each 
of the first 1 vectors 01 , ... , 0l is linearly independent of its predecessors 
but the vectors 0lll ' ... , Ok are linearly dependent on 01 ' ... , 0l , and then 
show that 
I) 01 , ... , 0l are linearly independent. 
The proof is by induction on I. For 1 --= I the statement is correct, since 
we may assume that 01 7- o. We now assume that 01 , "', 0l-1 are linearly 

244 
PART B ARITHMETIC AND ALGEBRA 
independent. If aI' ... , az were linearly dependent, there would exist 
scalars xl, ... , xZ, not all 0, such that a1x1 + ... + azxz = 0. If XZ = 0, 
then aI, ... , aZ_1 would be linearly dependent, and if xz"* 0, then az would 
be linearly dependent on a1 , ..• , aZ-1 • 
2) Every subspace U, even a smallest one, which contains a1 , •.. , ak , 
certainly contains a1 , ... , az and all linear combinations a1x1 + ... + azxz. 
But the totality of these linear combinations is a subspace containing 
a1 , •.• , ak , and is thus the desired subspace. 
The basis a1 , ••• , az of a subspace can be extended to a basis of Vn . For, 
either the a1 , .•• , az already span Vn or else there exists a vector az+1, 
linearly independent of them, that can then be adjoined as a further basis 
vector for Vn • Since the dimension of V is finite, this procedure comes to 
an end after finitely many steps. 
1.5. 
Change to a New Basis 
After choice of a basis the vectors in Vn can be represented as n-tuples from S. 
In the applications where it is natural to choose some special basis, the vectors 
are often given in this way. 
Thus it is important to determine how the coordinates of a vector behave 
under a change of basis or, as is often said, of coordinate system. 
Let e1 , ..• , en and e1, , ••• , en' be two bases of the vector space Vn , where 
for greater uniformity in our subsequent notation the primes have been 
written not on the e but on the indices. Thus I', ... , n' are simply marks to 
identify the elements of the second (the "primed") basis; of course, there 
are n of them. 
Every vector of one basis can be expressed as a linear combination of 
the vectors of the other basis. The coordinates of the basis vectors will be 
denoted by t:, and t~', respectively (later also, cf. §2.3, by s:, and s~' 
respectively): 
(la) 
(lb) 
The t with primed superscripts and the t with primed subscripts are to be 
carefully distinguished. They are defined in completely different ways. 
The purpose of using the same letter t in these two cases is to make the 
equations for transformation of coordinates easy to remember. One only needs 
to recall that summation is taken over any index appearing both as superscript 
and subscript and that the indices over which summation is not taken occur 
either only as subscripts or only as superscripts. It was for this reason that we 
put the primes on the indices rather than on the e. 

3 Linear Algebra 
245 
The relations between the t:, and the t{ are found by substituting (1a) 
into (lb): 
(summation for K is from 1 to n, and for /-,' it is from }' to n'). 
Since the e,\ are linearly independent, it follows that 
(2a) 
for 
K = A, 
for 
K *- A. 
In the same way, by substitution of (1 b) into (Ia) we obtain 
(2b) 
, 
~, 
q 
tl-' {K = oil-
= 
1 
K 
II' 
II' 
10 
for 
/-,' = v', 
for 
/-,' -=F v'. 
The Kronecker symbols 8 with ht-'o indices, which may also occur either 
both as superscripts or both as subscripts, will always be used in this sense. 
The equations (2) show that not every arbitrary system of n . n elements 
t:, of S can occur as the schema of coefficients for a transformation of 
basis: corresponding to a system t:, there must exist a second system t{ 
such that equations (2) are satisfied. But this condition is also sufficient. 
For we a.ssert that, if for the system t:, there exists a system t{ such that 
the equations (2) are satisfied, and if e1 , ... , Cn is a basis of Vn , then 
the vectors ell' = eKt;, also form a basis of Vn . 
For the proof of this assertion, it is only necessary, since vectors of Vn 
form a basis, to show that the ell' are linearly independent; that is, that 
cv'c"' = 0 implies CII' = 0 for all v'. 
Now we have e",c"' = eKt:,c"'. Since the eK are linearly independent, the 
right-hand can be = 0 only if t;,c"' = 0 for every K. Multiplying the 
Kth of these equations with t~' (where /-,' is arbitrary) and summing, we 
obtain: 
From (2b) it follows that cl-" = 0 and, of course, this procedure can be 
carried out for every /-,'. 
The reader is advised to make the computation for a few simple examples 
(say for n = 2). In the case n = 2 the determination of the tf for a given t~, 
requires the solution of four linear equations which for commutative S can be 
solved if and only if t~/t:, -
t~/t~, -=1= o. 
Let us now ask how the coordinates of a vector I are transformed under 
the change of basis (1). Let the coordinates of I with respect to the basis 
(c,\) be xA, and with respect to the basis (ell') let them be X"', so that we have 
(3) 

246 
PART B ARITHMETIC AND ALGEBRA 
Substitution of (I b) in (3) gives 
so that, since the ~ /1: are linearly independent, 
(4a) 
The solution of this system of equations for the x A is obtained either by 
substituting (Ia) in (3) or by multiplying (4a) with t and using (2): 
(4b) 
Here the XK and xv' are coordinates of the same vector with respect to 
different bases. The "kernel letter" x denotes the (fixed) vector, and the 
change of basis is expressed in the index. This "kernel-index notation" is 
due to Schouten. 
2. 
Linear Transformations of Vector Spaces 
2.1. 
General Properties of Linear Tran~(ormatiol1s 
In the equations §1.5 (4) we could also interpret x A and xv' as coordinates 
of different vectors with respect to the same basis. In the kernel-index 
notation such a transformation has the form 
(1) 
that is, we use different kernel letters for the two vectors and do not use 
any primed ind ices. 
By (I) there is assigned to each vector x exactly one vector 11, which we 
denote by 11 = Ax (A is to be read: alph<!) and 
(Lv) 
from x = 1) 
follows 
Ax =--= A1). 
Thus we have a mapping or tran~(ormation Q( Vn into itself, with the 
following properties: 
(La) 
(Lm) 
A(x +- 1» = Ax +- A1) 
A (x . s) = (Ax) . s. 
Transformations with these properties are said to be linear. They are 
simply the homorphisms of Vn . Since it will be necessary for us to consider 
them in various forms, we will in general take A, B, ... to be linear 
transformations of Vn(S) into a f7k(S). Thus the dimensions of the two 

3 Linear Algebra 
247 
vector spaces are not required to be the same. We shall be particularly 
interested in the cases Vk = 
Vn and Vk =- VI = S, and when it is desirable 
to indicate the dimensions, we shall speak of an n X k transformation. 
We do not assume that every vector in V k is the image of a vector in Vn . 
The set of vectors in Vk which are images of vectors in Vn is denoted by 
A(Vn ) and is called the image domain (cf. lA, §8.4) or the image space 
of the transformation A. We first note that A(Vn) is a vector space over S 
and is thus a vector subspace of Vk . 
To prove this we must show that i E A(Vn)' 1) E A(Vn), s E S implies 
We outline the proof for (2) and leave the proof of (1) to the reader. Since 
i E A(Vn) means that there exists an x E Vn such that Ax = i, it follows 
from (Lm) that IS = (Ax) s = A (xs) E A( VrJ 
The dimension r of the image space of A(Vn) = Vr is called the rank of 
the transformation A. It is obvious that r :s:;: n. 
We now turn our attention to the set of n x k transformations them-
selves. In this set we can introduce an algebraic structure as follows: 
two transformations are said to be equal, A = B, if the equation Ax = Bx 
holds (cf. lA, §8.4) for all x in V1/ . This equality is reflexive, symmetric, and 
transitive. 
An addition is defined by 
(2) 
(A + B) x = Ax + Bx, 
and an S-rnultiplication on the left by 
(3) 
(s . A) x = s . ( Ax). 
For this purpose it is necessary that Vk be not only a right-space but also 
a left-space over S. This situation certainly holds if Vk = S; and if S is 
commutative (cf. § 1.2), it can easily be brought about by defining sx = xs. 
Our applications will be confined to these two cases. 
Theorem I: 
With respect to these operations the n x k transformations 
form a [lector space L1/'" of dimension n . k. 
What we must prove is: 
I) A + B is a linear transformation. To show this we must verify 
(Lv), (La), and (Lm). As an example, we shall give the proof for (La), 
leaving the other proofs here and below to the reader. 
(A + B)(x + 1») = A(x + 1») + B(x + 1») 
by (2) 
= Ax + A1) + Bx + B1) 
by (La), applied to A and B, 
= (A + B) x + (A + B) x 

248 
PART B ARITHMETIC AND ALGEBRA 
on the basis of the associative and commutative law for addition in t:\ 
and (2). 
2) The sum A + B satisfies the condition (AI-A6). As an example, let 
us prove (A2). The assertion is that if for every I we have AI = BI and 
rI = Ill, then for every I it follows that 
(A + r) I = (B + Il) I. 
But 
(A + r) I = AI + r I 
by (2) 
= BI + III 
by (A2), applied in P k , 
= (B + Il) I 
by (2). 
The zero element is the transformation OI = 0, where 0 is the zero element 
of Pk • 
3) sA is a linear transformation. 
4) The S-multiplication satisfies (MI-M6), but with left s-factors. 
The theorem further states that the dimension of L depends on the 
dimensions of V and P. To prove this statement we shall require a 
representation of the transformations in terms of a basis (e,,) of Vn and 
(eK ) of P k • Therefore we shall postpone this proof until we have completed 
our discussion of coordinate-free theorems. 
The multiplication of one transformation by another is defined in the 
usual way as successive application of the two transformations: 
(4) 
(AB) I = A (BI). 
Here B is a transformation of Vn into P k , and A is a transformation of 
P k into a new vector space Wz , and in the product of several transforma-
tions additional vector spaces are introduced in the same way. It is 
permitted, but not required, that these vector spaces be distinct from one 
another. 
The product of two transformations is defined only if the image space 
of the first transformation is contained in the preimage space of the 
second. Moreover we have defined the sum of two transformations' only 
for transformations from the same Vn into the same P k • But so far as the 
sums and products exist, they satisfy the conditions for a ring. Beside those 
already stated for addition, these conditions are: 
5) Consistency of multiplication with equality: if for all I we have 
AI = BI and rI = Ill, then for all I we also have ArI = Bill. 
Proof. 
By hypothesis rI = Ill. Thus it follows from (Lv) that 
A(rI) = A(IlI) and then from AI = BI that A(IlI) = B(IlI) for all I, 
so that the assertion is true by transitivity of equality. 

3 Linear Algebra 
249 
6) The associative law: 
A(Br) = (AB) r. 
This law holds generally for transformations with successive application 
as the rule for multiplication (see IB2, §1.2.5.). 
7) The distributive laws: 
A(B + r) = AB + Ar; 
(A + B) r = Ar + Br. 
The proofs always depend on the same fundamental idea. 
The existence of sum and product is in every case guaranteed if we 
consider only the set of linear transformations of Vn into itself: 
Theorem 2: 
The linear transformations of a vector space Vn into 
itself form a ring with respect to the addition (2) and the multiplication (4). 
Corollary: This ring has a unit element (for rings, also called unity 
element), namely the transformation E with Ex = x. (For the concept 
of a ring see IBl, §2.4, and IB5, §1.2.) 
Under what circumstances does there exist, for a transformation with 
A(Vn) = Pr C; Pk , an inverse transformation A such that A(P,.) = Vn ? 
Since the dimension of A(Pr) is smaller than or equal to r, and on the 
other hand r ~ n, we must have r = n. 
But this necessary condition is also sufficient, as can be shown, for 
example, in the following way: Let (eJ be a basis of Vn , so that the images 
Ae" = a" form a basis of Pn • The desired inverse transformation is then 
given by Aa" = e", as the reader may easily show. (The argument is 
similar to the one at the beginning of §2.2; cf. also the end of §2.3.) 
By the definition of A it follows that AA = E, so that A is a left inverse 
of A. But if we start from the basis (a,,) in Pn , we see that AA = E, so that 
A is also a right inverse of A. 
But A is uniquely determined by A; for if AA = E and SA = E, then 
by mUltiplying the second equation on the right with A we see that A = S. 
Thus we may call A the inverse mapping for A, and denote it by A-I. The 
transformation A-I itself has an inverse (since it is of rank n) and in fact 
(A-I)-l = A. 
Thus, a transformation A is invertible (i.e., has an inverse) if and only if 
its rank, i.e., the dimension of the image space, is equal to the dimension of 
the original space. 
2.2. 
Matrices 
Let us now consider the representation of linear transformations in 
terms of a basis (ev) of Vn and a basis (e K ) of tlk • From (La) and (Lm) it 
follows that 

250 
PART B ARITHMETIC AND ALGEBRA 
Consequently, after choice of a basis (ev) of Vn the transformation A is 
completely determined if the images of basis elements 
are given. 
In terms of a basis of P k we have Ov = eKa/. 
After choice of a basis (eJ of Vn and a basis (e K ) of Pk the transformation 
A is completely determined by the "rectangular array" of n . k elements of S 
An array of this sort is called an n X k (n by k) matrix. 
Here the superscript outside the bracket indicates the row, and the 
subscript indicates the column. The notation (aKv)K=l ..... k:v=l ..... n for 
matrices is also common; in this case the first index indicates the row. 
If the position and range of values of K, v are clear, we write 21 = (a/). 
The expression "rectangular array" means simply that to every pair of 
numbers (K, v) there is assigned an element a/ of the domain of scalars. 
Thus the matrix is a mapping of the pairs of numbers into the domain of 
scalars. By the general definition for equality of mappings (see lA, §8.4) 
we thus have 
(1) 
21 = ~ if and only if a/ = b/ for all 
K, v. 
Since the Ck are linearly independent, the transformation can also be 
represented by the system of equations 
(2) 
It was from such a system that we started out in the first place, and now 
we have shown that every linear transformation of Vn can be represented 
in this way. 
Let us now examine the question of uniqueness. Let 21 = (a/) and 
~ = (bv
K
) be the matrices assigned in a given coordinate system to the 
transformations A, B. It is obvious that if a/ = b/ for all K, v, then 
AI = BI for all I; that is, A = B. 
Conversely, for a pair of indices i,jassume a/ =F- bj i ; then there certainly 

3 Linear Algebra 
251 
exists a vector I for which AI =F- BI, for example, the vector ei with 
coordinates 8/. By (2) its image vectors have the coordinates 
which differ from one another in the ith coordinate. 
Thus A = B if and only if a,/ = b,/ for all K, v. Then (1) shows that 
A = B if and only if 21 = ~. 
For matrices we now wish to introduce the rules of computation which 
will correspond to those already introduced for transformations in such 
a way that the resulting "configurations" (cf. IBIO, §1.2) for the matrices 
are isomorphic to the corresponding configurations for the trans-
formations. 
So we ask: which matrix will correspond to the sum A +- B = r? By 
§2.1 (2) we have rI = AI +- BI, so that, if matrices are denoted by the 
corresponding letters: 
This system of equations is satisfied for all possible vectors (X") if and 
only if 
for all 
K, v. 
Thus we define the addition of two matrices by 
(3) 
By an analogous argument we are led to define left-multiplication of a 
matrix by an element of S by setting 
(4) 
s . (a/) = (s . a/). 
Then the n x k matrices form a vector space isomorphic to Ln \ whose 
zero element is given by the matrix .0 with a/ = 0 for all K, v. For this 
vector space it is easy to assign a basis, namely, the matrices (fi with 1 
in the position x/ (note that the indices are interchanged) and zero 
elsewhere. Then every matrix ~( can be represented in the form 
where the 
(fit are linearly independent, since (1) implies that 
a"K(fK" = (a"K) = .0 if and only if a/ = O. Thus the remaining part of 
Theorem I, Ln k has dimension n . k, is proved if we show that isomorphic 
vector spaces have the same dimension, a detail which we leave to the 
reader. 

252 
PART B ARITHMETIC AND ALGEBRA 
It is also possible to show without the use of matrices that the trans-
formations Eji (corresponding to the matrices <fji) form a basis, where the 
E/ are defined by 
for 1"* i; 
note that summation is not taken over the Latin index i. 
Matrix multiplication: the transformation A(BI) is represented in the 
matrix notation by yA = a/(b,/xv). Thus the matrix product 2HB = (t 
is to be defined by 
(5) 
The element evA is formed by mUltiplying the elements of the Ath row of m 
(as left factors) with those of the vth column of~ and adding the products. 
Thus the product exists only if the number of elements in a row (Le., the 
number of columns) of m is the same as the number of elements in a 
column (Le., the number of rows) of~. 
The isomorphism between matrices and transformations shows that 
. the same rules of calculation hold here as for transformations. 
The following example shows that multiplication of matrices, and 
therefore multiplication of transformations, is not commutative: 
(_ 0, 
1)(_ 0, -I) :: (-I, 0) 
I, ° I, ° -
0, 
1 
( 0, -1)( 0, 
I) = ( I, 
0) 
-I, ° -I, ° = 
0, -I . 
But calculation with matrices can be also defined by (1), (3), (4), (5) 
independently of the linear transformations, whereupon the rules for 
calculation can be verified by direct computation. Then the right of (2) 
can be interpreted as a product of matrices, where (xv) = I and (yK) = ij 
are matrices consisting of a single column. In place of (2) we then write 
(2') 
ij = mI. 
Thus the equation §1.5, (4a) would be written in the form I' = l:I. Here 
of course the kernel-index notation must be given up. 
' 
Since the matrices corresponding to transformations of Vn into itself 
are the square n X n matrices, they form a ring, a fact which again can be 
verified by actual computation without any reference to the theory of 
linear transformations. The unit element in this ring is the unit matrix 
(
I, 0, ... , 0) 
0, 
1, ... , ° 
. " 
" 
" 
" 
0, ... , 0, I 

3 
Linear Algebra 
253 
If the transformation A has an inverse transformation A, then the matrix 21 
has an inverse matrix m, which by the remarks at the end of §2.1 is seen 
to be both a left and a right inverse. A matrix 21 of this sort, for which 
there exists an m with 2-(m = m21 = <f, is called regular. Comparison with 
the equations §1.5, (2) shows that a given matrix can be the matrix of 
coefficients of a transformation of basis if and only if it is regular. 
Not every matrix is regular; for example, 
(I, O)'U, V) = (U, V) 
0, 0 \x, y 
0, 0 
is certainly different from the unit matrix, no matter how the u, V, x, yare 
chosen. 
If we set u = V = 0 and say x = y = I, we see that the matrices 
(~' ~) and (~' ~) are divisors of zero. (Their product is zero, but neither 
fa~tor is equ~l to zero.) 
2.3. 
Rank and Transformation of Basis for Matrices 
Now that we have laid the foundations for calculation with matrices, 
let us d~scuss the following question: 
I) How is the rank of the transformation indicated in the matrix? We 
return to the beginning of §2.2. Every vector of Vn is a linear combination 
of the eJ)' so that every vector of Vr is a linear combination of the OJ) , 
which means that Pr is spanned by the OJ) . Thus by § 1.4 a suitably chosen 
set of r of the vectors OJ) forms a basis of Pr ; in other words: among the 
OJ) there exist r linearly independent vectors and every r + I of these 
vectors are linearly dependent. Now the coordinates of the OJ) form the 
columns of the matrix ~l. The maximal number of linearly independent 
column vectors is called the column rank of 21, so that we have the theorem: 
the column rank of the matrix 2-( is equal to the rank of the transformation A. 
2) How does the matrix 21 representing a transformation A change with 
a change of basis? 
Let the transformation A be represented with respect to the bases 
(eJ))' (e K ) by the matrix 21 = (a/), and let the image of the vector I be 
AI = 1). 
(We write 1) here instead of i in order to avoid having too many diacritical 
marks on the same letter.} 
By §2.1, (1) the coordinates of this image vector are 
(1) 
or in matrix notation: 
1) = mI. 

254 
PART B ARITHMETIC AND ALGEBRA 
Here we consider a vector as a matrix with one column, whose elements are 
the coordinates of the vector with respect to the given basis. 
We now make a transformation of basis in the two vector spaces: 
or x = ;!x', 
or 
1) = 61). 
Then from (1), by multiplication with (s~') = 6-1, we obtain 
or 
1)' = 
6-1~(;!X'. 
Thus, the transformation A is now represented, in terms of the new bases, by 
the matrix 
(2) 
~(' = 
6-1~(;!, 
where 6 and;! are regular matrices. 
Definition: two matrices ~(, ~(' that stand in the relation (2) to each 
other are said to be equivalent: ~( r-....J ~('. 
Thus we have the result: if two matrices represent the same transforma-
tion, they are equivalent to each other. The converse is also true; let us 
state it in detail: if ~( and ~(' are equivalent matrices and if 21 represents 
the transformation A with respect to the bases (ell), (c K ), then there exist 
bases (c~), (c,\) with respect to which the matrix ~(' represents the trans-
formation A. 
It follows that equivalence of matrices is reflexive, symmetric and 
transitive, and is thus an equivalence relation (lA, §8.3 and 5), as can also 
be shown by actual computation from (2). 
3) Is it possible, by a suitable choice of bases, to represent a given 
transformation in a particularly illuminating way? 
We had ACII = all' By reindexing (if necessary) we can arrange that the 
a1 , ... , ar are linearly independent and that ar+1' ... , an are linearly 
dependent on these first r vectors. Thus by §1.4 we can choose a basis of 
Pk such that Cl = a1 , ''', cr = ar (and of course Cr+1 , ... , Ck are linearly 
dependent on them). Then for all all the coordinates a/ = 0 for K, > r; 
thus 21 has the form 
a1 , ... , ar , ar+1 , ... , an 
-
-
-
-
-
-
-
-
-
-
-' -
-
-
-
-
-
0 
a~+1 
anI 
0 
I 
a~+1 
an
r 
0 
0 
0 
0 
0 
0 
0 
0 

3 Linear Algebra 
255 
We now introduce a new basis for Vn as follows: if a~+l "* 0, we set 
e, = e 
JJ 
JJ 
for v"* r + 1. 
Then 
and thus 
It is clear that repetition of this procedure must lead to a new basis in Vn 
with respect to which the transformation A is represented by the following 
matrix: 
r 
Thus we have obtained the theorem: every matrix of rank r is equivalent 
to the matrix (fr . Consequently, if two matrices have the same rank, they 
are equivalent. Conversely, it is obvious that equivalent matrices have the 
same ra:nk. Thus equivalent matrices are characterized by their rank alone. 
In saying "rank" here instead of "column rank" we are anticipating a result 
at the end of §2.4. 
With respect to the new bases the transformation A is represented by 
the following equations: 
(3) 
yr+l = 0, ... ,yn = 0. 
If necessary, we may also consider a transformation of Pr into Vn by means 
of c1 ----+ e1 , ... , er ----+ er and then say (for the moment, simply for the sake 
of visualization) that the transformation represented by (3) is a projection. 
Then every linear transformation of a vector space Vn into a vector space 
is a projection of Vn onto an r-dimensional vector subspace, where r is the 
rank of A. Conversely, it can be shown immediately that every projection 
is a linear transformation. 
From (3) we see at once what was already proved in §2.1: if r = n, then 
the transformation is invertible. 
2.4. Systems of Linear Equations 
In the system of equations 
(I) 
(K = 1, ... , k) 

256 
PART B ARITHMETIC AND ALGEBRA 
we consider, for every v, the k-tuples (a}, ... , all
k ) = all and (bI, ... , bk ) = b 
as vectors in a space Vk • In other words, for these k-tuples we introduce 
addition and S-multiplication as in §1.2. Then (I) can be written: 
(I') 
a.,x" = b, 
and the question of solutions becomes simply whether, and in how many 
ways, the vector b can be represented as a linear combination of the vectors 
all . The solutions, i.e., the n-tuples (xv), can be regarded in their turn as 
vectors of a (different) linear vector space Wn • 
The following preliminary discussion is expressed in geometric terms, the 
a1, ... , an, b being thought of as vectors in a k-dimensional affine space. In this 
case, however, the Wn cannot be interpreted geometrically. 
If the a1 , ... , an already span the whole VA: , then every b E VA: can be represented 
as a linear combination of the all' If the av form a basis, i.e., if n = k, this 
representation is unique, but if n > k, then it may be possible to choose a basis 
for VA: in various ways from the a1, ... , an, so that the representation of b 
will no longer be unique. 
If the a1 , ... , an span a proper subspace V1 < VA:, I < k, then only those b 
are representable that belong to this subspace. Thus the possibility of a solution 
and the total number of solutions will depend on the dimension I of the subspace 
V; spanned by the a1 , ... , an . 
We now repeat the theorems in § I: 
If I = (Xv), 1) = (yv) are solutions of (I), then I -
1) is a solution of 
(II) 
or a.,xll = o. 
Thus we can find all solutions of (I) by adding to a particular solution of (1) 
all solutions of (II). 
If I, 1) are solutions of (II), then I + 1) and I . S (s E 8), are also solutions 
of (II). 
Thus the solutions of (II) form a vector space W' which is a subspace of 
Wn . The question of the number of solutions of (II), and thus of (I), 
becomes a question of the dimension of W'. By the above preliminary 
discussion this dimension will depend on the dimension I of V; , so, that 
we must now bring this latter space into play. 
We assume that the aI' ... , a, are linearly independent and that 
a'+l , ... , On are linearly dependent on them. Of course, this assumption 
requires a reindexing of the all and the X", which can easily be reversed 
at the end of the calculation. Thus we assume that 

3 Linear Algebra 
257 
If these equations are substituted into (II), we obtain 
(1) 
l 
n 
L a,\ (x'\ + L c/x~) = 
O. 
,\-1 
~-l+1 
Since the a,\ (,\ = 1, ... , I) are linearly independent, the system (1), and 
with it (II), is satisfied if and only if for every ,\ the system 
n 
(2) 
X,\ + L c/x~ = ° 
~-l+1 
is satisfied. But from the latter system we can at once read off all possible 
solutions as follows. If for xl+I, ... , xn we insert arbitrary elements from 
S, the corresponding Xl, ... , Xl can be calculated uniquely from (2), We 
thus obtain as a solution n - I linearly independent vectors II , "', In-l 
and therewith a basis for W', if we set 
(x~~~ , x~~~ , '''' x~_) = (0, .. ,' 0, 1) 
and then in each case calculate the corresponding x/' ... , xpn from (2). 
A solution with arbitrary values Xl+I, ... , xn is obtained as a linear 
combination IIXl+1 + I2Xl+2 + ... + In_lXn. 
In this way we obtain the theorem: if the vectors al , ... , an span an 
I-dimensional subspace V; C Vk , then the solutions of (II) form an (n -
1)-
dimensional vector space W~_l . 
Thus the concept of a vector space is seen to be well adapted to the theory 
of systems of linear equations. 
A basis of W~-l is called a system of fundamental solutions, or more 
briefly a fundamental system. The number I of linearly independent vectors 
among the ai, ... , an is the column rank of the matrix (av
lC). 
But how do we determine the I and the c /? By § 1.4 we must decide 
which of the av are linearly dependent on their predecessors. Of course, 
this actually means that we must solve systems of linear equations; thus 
we would simply be going around in circles, if it were not possible to 
determine the rank of a system of vectors in some other way. We shall 
return to this question in §3.6, but at present we follow another path: we 
recast the system of equations (I); i.e., we set up another system whose 
solutions are the same as those of (I) but are much easier to perceive. 

258 
PART B ARITHMETIC AND ALGEBRA 
What is wanted, of course, is a system of the form 
Xl 
= 
q1 
X2 
= q2 
xr = qr; 
that is, a system whose coefficient matrix has the form (fr . In §2.2 we have 
already spoken about transforming a matrix into such a form; let us now 
examine this question somewhat more closely from our present point of 
view. We must see what such transformations mean for our system of 
equations. 
If all "* 0, let us subtract a suitable multiple of the first equation from 
the other equations, so that Xl no longer occurs in them, repeating the 
same process with the second equation and with x2, if a22 "* 0, and so 
forth. In order to have all "* 0 we change the order of the equations, if 
necessary, or else change the numbering of the xv. In order to obtain a/"* 0 
at a later stage, it may sometimes be necessary to take both these steps. 
We now wish to interpret these operations in our vector space. It is a 
matter of showing that they do not change the linear dependence or 
independence of the vectors Ov , b. 
1) Renumbering the Xv means renumbering the Ov, which produces 
no change in the relation of linear dependence. 
2) Moreover, this relation is not changed by a change of basis. For 
example, the transformation of basis (for arbitrary fixed i, j) 
for v"* i, j 
merely interchanges the ith and jth equations. 
3) Let us now suppose that a11"* 0 has been brought about by (1) or (2). 
Actually we should here write ar or a~; , and in each of the successive steps 
we should adjoin one more prime, but the reader will allow us in each case 
to write only the prime arising from the next step and then, in the final equations, 
to write only one prime on the superscript and on the subscript. 
By the transformation 
we obtain 
Ov = e1,a} + e2,(av2 -
a12(a11)-1 a}) + e3,av3 + 
i.e., 
for K"* 2, 
so that in particular ai' = O. 

3 
Linear Algebra 
259 
With respect to the coefficient matrix 21 = (av
K
) , or to the extended 
matrix 
the operations admitted up to now consist of an interchange of columns, 
an interchange of rows, and the addition of a multiple of one row to 
another row. By repeated application of these rules we can, as a first step, 
bring the matrix 21 into a matrix of the form 
21'= 
l' 
aI' , 
0, 
0, 
0, . 
0, 
.... 
l' 
0, al', .... 
. .0, 
. 0, 
called an echelon matrix. It is characterized by the fact that in the main 
diagonal a~: , ... , ar "* 0, whereas to the left of this diagonal and in the 
rows beginning with the (I + 1 )th there occur only zeros. The other 
elements may be arbitrary. 
From this matrix, or the corresponding system of equations 
(3) 
2' 2' 
2' 
, 
a2,x + ... + an'xn = ° 
l' l' 
l' 
, 
al'x +. + an'xn = 0, 
it is easy to see that the solutions can be calculated for an arbitrary choice 
of X(l+l)', ... , xn'. Also, we can at once read off the column rank of the 
transformed matrix (a:;) = 21', since it is equal to the number of nonzero 
elements in the main diagonal. Since our transformations have made no 
change in linear dependence, this number is also the column rank of 21. 
If we carry out the same operations on the extended matrix ~, leaving 
the column (b
K
) unchanged, then instead of (3) we have a system of equa-
tions of the form 
arxl + ... + a~'xn = bl' 
° 
= b(l+l)' 
° 
= b
k', 

260 
PART B ARITHMETIC AND ALGEBRA 
which is solvable if and only if b(l+l)' = ... = b k ' = O. In this case the 
rank of ~', and thus also of~, is equal to the rank of 21, since otherwise 
the column of the b
K
' would provide, after an interchange of columns, 
a nonzero element in the main diagonal. Thus we have the theorem: 
the system (I) is solvable if and only if the rank of the extended matrix is 
equal to the rank of the coefficient matrix. 
The above proof of this theorem contains at the same time a procedure for 
the numerical solution of a given system of equations which is more convenient 
in practice than, for example, the method of solution by means of determinants. 
It remains to justify our use here of the word "rank" instead of "column 
rank" of a matrix. Among the admissible operations for the transformation 
of a matrix we have made no mention of the addition of a multiple of one 
column to another column. But here also the number of linearly 
independent column vectors remains unchanged, as is shown by the 
theorem: if ai' ... , an are linearly dependent or linearly independent, then 
the same is true for a1 , a2 + a1s, a3 , "', an . The proof is left to the reader. 
Since it is clear that rows and columns of a matrix are on an equal 
footing with each other, we can also regard the rows as coordinates of 
vectors (in a space other than that of the column vectors), in which case 
the S-multiplication will be on the left. To determine the number of 
linearly independent row vectors we make use of the same operations as 
for the column vectors. Thus the resulting echelon matrix has the same 
number of nonzero elements in the main diagonal. This method shows 
that the row rank of a matrix is equal to the column rank, so that we may 
speak simply of the rank of the matrix. 
2.5. 
Transformation of a Matrix into Diagonal Form 
By the addition of multiples of columns to other columns we can bring 
the echelon matrix 21' into the diagonal form 
d1 
0 
d2 
1)= 
dr 
0 
0 
0 
(with zeros everywhere except on the main diagonal). In fact, exactly this 
process is carried out, in a somewhat indirect way, in the ordinary method 

3 
Linear Algebra 
261 
of solution of a system of linear equations corresponding to an echelon 
matrix. A more important interpretation of the process is described in 
§2.2. 
Our first remark is that the operations used above to transform the 
matrix 2-I, namely: 
interchange of two rows or columns, 
addition of a multiple of a row or column to another row, or column, 
can be effected by multiplication of m with suitably chosen regular 
matrices. 
For let Ui •j be the matrix that arises from (f by interchange of the ith 
and jth rows (or what amounts to the same thing, of the ith and jth 
columns). Then the matrix mUi •j arises from 2-( by interchange of the ith 
and jth column, and Ut' .1m arises by interchange of the ith and jth rows. 
If IDji(q) is the matrix that arises from (f by adding the element q in 
the position Xji, then mID/(q) arises from m by addition of the qth 
multiple of the ith column to the jth column, and ID/(q) m arises by 
addition of the qth multiple of the jth row to the ith row. 
The matrices U, ID are square, whereas 21 may be rectangular, in which 
case the matrices used for right multiplication will not have the same 
number of rows as those used for left multiplication. 
The matrices U, ID are regular, since they represent transformations of 
basis. Since the product of regular matrices is regular, we obtain the 
theorem: a matrix m can be transformed by multiplication with suitably 
chosen regular matrices 6, l: into a diagonal matrix 
Then by multiplication with regular matrices Xl can be further trans-
formed into (fr, by left-multiplication with (f and right-multiplication 
with the matrix that arises from (f through replacement of the first r 
diagonal element by ljd! , ... , ljdr • 
Since the inverse 6-1 of an arbitrary regular matrix 6 is regular, we 
have obtained another proof for the theorem: every matrix of rank r is 
equivalent to the matrix (fr . 
This partition into equivalence classes is rather coarse, since the possi-
bilities for transforming matrices into one another are still extremely 
numerous. In what follows we shall restrict the transformations in various 
ways, examining only the simplest case in detail. 
One restriction consists of regarding the vectors I and 1) as elements of 
the same space, so that the same transformation is applied to both of them. 
Matrices that are in the relation 
(1) 

262 
PART B ARITHMETIC AND ALGEBRA 
are said to be similar, in which case the matrix 21 must be square. In §3.7 
we shall examine some invariants under similarity. 
A further specialization refers to the admissible transformations. For 
example, the orthogonal transformations (see the following section and 
11.7) are important for geometry. We shall discuss a question of this sort in 
§3.7. 
2.6. 
Linear Forms 
In our discussion of systems of linear equations we have encountered 
three vector spaces: the space of solutions, the space of column vectors, and 
the space of row vectors. Multiplication with elements of S was on the left 
for row vectors, and on the right for column and solution vectors. Let us 
now examine the relationship between solution vectors and row vectors in 
the case of a single equation, 
Here we regard the XV as coordinates of a vector I in a space Vn . If 
ai' ... , an are given elements of S, the mapping 
(1) 
assigns to every element I of Vn an element <a, I) of S. This mapping a 
has the properties: 
(Lv) 
(La) 
(Lm) 
From 
I = 1) 
follows <a, I) = <a, 1), 
<a, I + 1» 
= <a, I) + <a, 1), 
<a, IS) = <a, I) . s, 
and is thus a linear mapping of Vn into S, a special case of the mappings 
considered in §2.1. Here k = I and I is regarded as a basis of S (as a VI)' 
The matrix corresponding to the mapping a consists of a single row 
(a}) = (av); this matrix will also be denoted by the letter a. 
The sign of equality in (X = (all) and in I = (X") refers to the representation 
of (X and I with respect to a given basis. As a sign of equality that is valid only 
with respect to a given basis, Schouten uses the symbol ~. We consider it 
unnecessary to introduce any special symbol in our present context. 
By §2.l every linear mapping of Vn into S can be represented in the 
form (1). Such mappings are called linear forms. 2 They constitute an 
2 In IB5, §3.9, on the other hand, a linear form will mean a linear homogeneous 
polynomial. 

3 Linear Algebra 
263 
n-dimensional vector space Ln with S as the domain of left multipliers, 
namely, the space of linear forms or the dual space of Vn , also called a 
module of linear forms. 
For vectors as "one-dimensional" matrices we have used lower-case letters; 
so now in the same way we use lower-case (instead of capital) letters for the 
linear mappings of Vn into S. The notation <<X, x) is intended to emphasize the 
symmetry of the two "factors." 
After choice of a basis (ev) for Vn and el 
= 1 for S, the linear forms €p 
defined by < 
€p, ell) = 8~ constitute a basis for Ln. These linear forms 
correspond to the mappings E~ (for k = 1). 
Since the bases of Vn and Ln have been put in correspondence with each' 
other in this way, a transformation of basis in Vn corresponds to a 
transformation in Ln . Let us examine the effect of such a transformation 
on the coordinates. 
Let the image of I under the linear mapping a be represented in terms of 
one basis of Vn by <a, I) = avxv, and in terms of another by <a, I) = av' xv'. 
Then, since the linear transformation is independent of the choice of 
basis, it follows that for a transformation which takes XV into 
(2) 
the av must be transformed in such a way that 
By substituting the inverse transformation XV = 
t;,x~1 of (2) into this 
equation we obtain: 
(3) 
Thus the transformation 
(4) 
produces the desired result, and no other transformation can do so, as is 
clear from the fact that (3) must hold for every vector I and therefore in 
particular for Xl' = 1, x 2' = ... = xn' = 0, and so forth. 
[n order to obtain the transformation matrix in (4) from the matrix 
in (2), we must first form the inverse matrix (t;,) and then sum over the 
superscripts on the t's rather than over the subscripts. 
The equations of the transformation (4) are the same as for the basis 
vectors: 
(5) 

264 
PART B ARITHMETIC AND ALGEBRA 
so that the a" are said to transform cogrediently with the basis vectors, 
whereas the xv transform contragrediently; thus the linear forms ex = (aJ 
are called covariant vectors and the I = (Xv) contravariant. 
The advantage of using superscripts and subscripts is now clear, and the 
convention of summing over equal superscripts and subscripts is convenient 
because it takes an expression involving a covariant and a contravariant vector 
into a magnitude that is invariant (under transformation of coordinates). 
The mapping ex ---. (ex, I) may be regarded as a mapping, defined by I, 
of the dual vector space into the domain of scalars. More generally, we 
also consider mappings of Vn X Vn X ... or Ln X Ln X "', and so forth, 
into the domain of scalars. Let us describe the next simplest case. A 
mapping of the set of pairs of contravariant vectors into the domain of 
scalars 
I, 1) ---. c = r(I, 1)) 
is called a bilinear form (cf. page 268) if it is linear in each variable; in 
other words, 
(La) 
(Lm) 
r(Il + I 2 , 1)) = r(Il , 1)) + r(I2' 1)); 
r(I, 1)1 + 1)2) = r(I, 1)1) + r(I, 1)2), 
r(SI, 1)) = S . r(I, 1)); 
r(I,1)S) = r(I, 1)) • S. 
Here we assume that SI = IS and that S is commutative, although for 
the time being it would be sufficient to assume that V is both a left and 
right vector space. From (La), (Lm) it follows that for I = xKeK, 1) = e\y'\: 
(6) 
(7) 
Under a transformation of coordinates §1.5 (I) the transformed values 
of the gK'\ will be such that 
g,..,v' = r(e,.., , ev') = t:,gdt;, . 
The bilinear form r is also called a covariant tensor of second order and 
the gd are its coordinates. 
In general, tensors can be defined as multilinear forms, i.e., as mappings 
of systems of covariant and contravariant vectors into the domain of 
scalars (cf. page 268) linear in each of the variables. For example, 
L1 (I ex 1)) = d ,\ xKa y'" 
" 
K.,..,\ 

3 
Linear Algebra 
265 
defines a tensor of the third order which is covariant with respect to two 
indices and contravariant with respect to one. The coordinates of a tensor 
are the coefficients of a multilinear form; for example, under a transforma-
tion of coordinates we have 
d Y , = tK,tA't"',d A • 
K 
.,.. 
K 
A ,.. 
K.,.. 
Let us now raise the question: do there exist transformations under 
which the coordinates of a covariant vector are transformed in the same 
way as those of a contravariant vector? Under such a transformation 
we must have for every vector I = (IK) not only 
(8) 
but also 
(9) 
If we solve (8) for the x'" and substitute in (9), we obtain 
x'" = t~,XK' = L L t~,t;,XA. 
K' 
A 
By setting (XA) = (1, 0, ... , 0), (1, 1, 0, ... , 0), and so forth we obtain the 
conditions of orthogonality 
and of normality 
or taken together 
(01) 
In the same way 
(02) 
for 1-'"* A 
" t"',tA, = 8,..A. 
L...-
K 
K 
K' 
Conversely, let us assume (0) and (8). Then 
X A = t~,x"" 
[solution of (8)], 
L t;,xA = L L t;,t~,x"" = XK' 
by (0), so that (9) holds. 
A 
A ,..' 

266 
PART B ARITHMETIC AND ALGEBRA 
Thus we have the theorem: for transformations satisfying the conditions 
(0), and only for such transformations, it is unnecessary to distinguish 
between covariant and contravariant vectors. 
These transformations are called orthogonal. 
Let us repeat the argument in matrix notation. For this purpose we must 
first define the transpose 21T = (~KV) of a given matrix 21 = (avK) , which 
is formed by interchanging rows and columns ~/ = av
K in 21. In more 
detailed notation the transpose of the matrix (avK)::t:::~ is represented by 
(avK)~:l·.::::~ . 
We leave to the reader the proof that 
(10) 
21TT = 21, 
and if S is commutative, 
Then we interpret avxv as the matrix product aT . I, where I and a each 
consist of one column, so that aT consists of one row. 
Now if I is transformed into I' = l:I, and if we are to have 
then we must have aT = a'Tl:, so that we must set a' = (l:-1)T a; that is, 
a must be transformed by the inverse transposed matrix, corresponding to 
the passage from (2) to (4) on page 263. 
In order that the transformation for a be the same as for I, we must have 
a' = l:a, so that (l:-1)T = l:, or l:-l = l:T. The equations 
are the same as (0). Thus the conditions of orthogonality and normality 
state that the inverse matrix is the same as the transpose. 
3. Products of Vectors 
3.1. 
General requirements 
The reader is already acquainted with several different products of 
vectors. We define, with respect to a given basis, 
a) the inner or scalar product by 
I . 1) = X1yl +- ... +- xnyn, 
b) in a V3 the vector product of two vectors by 
I X 1) = (X2y3 -
X3y2, X3yl -
X1y3, X1y2 -
x2yl), 
c) in a V2 the complex product by (cf. 188, § 1) 
I 0 1) = (X1yl -
x2y2, X1y2 +- x2yl); 

3 Linear Algebra 
267 
that is, if I = Xl + iX2, 1) = yl + iy2, then 
I 0 1) = Xlyl -
x2y2 + i(Xly2 + x2yl). 
It is not customary to use any special symbol, like the 0 here, since this 
product does not usually occur in the same context with the others. 
Only the complex product satisfies all the rules for computation familiar 
from the multiplication of real numbers; but this complex product is 
possible only in a two-dimensional vector space. 
In (a) the product of two vectors is not itself a vector; in (b) it is true 
that for every system of coordinates I x 1) is defined as a vector, but this 
product is not independent of the coordinate system. The desired independ-
ence can be attained only if we restrict ourselves to coordinate systems 
that arise from the original system by orthogonal transformations (see 
§2.6 and II, 7), or if we consider the product not as a vector but as a tensor 
of second order with the 9 coordinates x~yv -
XI'Y~ (I-', v = 1, 2, 3). 
Neither (a) nor (b) satisfies the associative law, and in both cases a product 
can be equal to zero even though neither of the factors is equal to zero. 
We now consider the problem of defining for vectors one or several 
operations that can reasonably be called "multiplication." What must be 
required of such an operation? 
1) Multiplication will assign to two vectors a "product." We cannot 
require that the product belong to the same vector space as the factors, 
but we will require that it belong to some vector space over the same 
domain of scalars S; this requirement means only that for the objects 
which turn up as products of two vectors there is defined, or can be 
defined, an addition and an S-multiplication. 
On the other hand, the "factors" may come from different vector 
spaces, although they must be over the same domain of scalars. 
(PI) By multiplication we shall mean a procedure which to each vector 
a E Vk(S) and each vector bE Vt(S) assigns exactly one vector 
c :::,-:: nCo, b) E Wr(S), provided certain further requirements are met. 
Thus, a multiplication is a mapping of the set V x V into W, where 
V x V is the set of pairs (a, b) with a E Vk(S), bE Vz(S). Included in this 
statement is the consistency of multiplication with equality: 
(P2) 
From a = a' and b = b' it follows that n(a, b) = n(a', b'). 
2) If the product does not belong to the same vector space as the factors, 
we can hardly expect a straightforward associative law. Next in importance 
come the distributive laws: 
IT(al + a2 , b) = H(al , b) + n(a2 , b), 
IT(o, bl + &2) = n(a, bl ) + n(a, b2), 
(La) 
which we shall require from a multiplication. 

268 
PART B ARITHMETIC AND ALGEBRA 
3) If in (La) we set al = a2 and bl = b2 , we obtain 
TI (2a, b) = 2TI (a, b), 
II (a, b2) = TI (a, b) 2, 
provided we assume that V is a left vector space, V a right vector space, 
and W both a left and right vector space over S. This assumption is 
satisfied if, for example, S is commutative and sa = as is defined in all 
three vector spaces; the assumption with respect to W is also satisfied for 
noncom mutative S if r = I and W = S, which is sufficient for our 
present purposes. Thus we demand from a "multiplication" that the two 
rules written above for (2) shall hold for arbitrary s in S: 
(Lm) 
TI(sa, b) = sTI(a, b), 
TI(a, bs) = TI(a, b) s. 
Then by (P), (La), (Lm) the multiplication is a mapping of V x V 
into W which is linear with respect to each of the two factors; such 
a mapping is called bilinear, or in the case of several factors multilinear, 
and if W = S is the domain of scalars, it is also called a bilinear form or a 
multilinear form. 
For later use let us note that if tT = V, then to the bilinear form II we can 
assign a quadratic form, namely the mapping a -- II (a, a). 
Thus we have set up the requirements that must be satisfied by an 
operation if it is to be called a "multiplication." But how are we to give a 
concrete definition of such a multiplication? We must state some rule for 
assigning a product to every pair of vectors. Now, a given vector can, 
on the one hand, be defined geometrically, and in this case we must give 
a geometric definition of multiplication. This problem will be dealt with 
in 11,7. 
On the other hand, a vector can also be defined by its coordinates, after 
choice of a basis. Then the rule for multiplication will determine the 
coordinates of the product from those of the factors and we must insure 
that the result is independent of the special choice of basis. 
If we let (t), K = 1, ... , k be a basis of Vk and (eA), ,\ = 1, "', I a basis 
of Vz , it follows from (La) and (Lm), exactly as for linear mappings, that 
Thus, a multiplication is completely defined by the products of the basis 
vectors. For abbreviation we write 

3 Linear Algebra 
269 
These products belong to W, but this fact is not very helpful, at least not 
yet, because up to now we have said nothing about the space W. In fact, 
it will be necessary, at least to some extent, to construct W. But to do this 
in a suitable way we must first investigate the behavior of products under 
a transformation ,of basis. 
For a given transformation 
(1) 
e = j".'e , 
K 
K". 
in which the coordinates a\ bl. become 
(2) 
it will be necessary to define a transformation of the TIKI. into TI".' v' in such 
a way that the product remains invariant; that is, for all vectors (a
K ), (bl.) 
we must have 
(3) 
From (2) and (3) it follows that 
(T) 
TI " 
= 
jK, TI ,t~ • 
". v 
". 
KII V 
In order for the product to remain invariant under transformation of 
basis, we must assign to the transformations (1) of Vand Va transforma-
tion of the form (T) in W. In the following two sections we shall describe 
two possibilities, and in each case the existence of a "multiplication" 
with the required properties will be proved by our giving an explicit 
statement (in coordinates) of what the products are. 
3.2. 
The Inner or Scalar Product 
Let V = V, and W = S, so that r = 1. If we write gK}. in place of TIKI. , 
then (T) states that the gK}. must be the coordinates of a covariant tensor 
of second order. Thus to define this multiplication we must first choose a 
basis (eJ in V and then choose arbitrary numbers gK}. . With respect to this 
basis the inner or scalar product is defined by 
(1) 
If we make a transformation of basis, then instead of the gK}. we must use 
the numbers 
(2) 
in order to form the product; that is, we must have 
ab = a".'g".'v,bv'. 
It is obvious that the requirements (P), (La), (Lm) are satisfied by the 
product defined in (1). 

270 
PART B ARITHMETIC AND ALGEBRA 
If in a given vector space we have defined a covariant tensor of second 
order, namely a bilinear form, as the "fundamental tensor" or "funda-
mental form" and have thereby defined an inner product, we say that the 
vector space has a metric structure, or that it is a metric space, a name that 
is explained by the fact that the inner product can be used for the intro-
duction of a metric. For if S is the field of real numbers and if the quadratic 
form XlCglCAXA is positive definite, then the mapping d, defined by 
satisfies the requirements for a distance function. 
Let us now suppose that for a given basis an inner product has been 
defined by the coordinates glCA of the fundamental tensor. We ask whether 
it is possible to choose a new basis in such a way that the representation 
of this product will become especially simple; for example, the matrix 
(g",'v') resulting from the transformation (2) will be a diagonal matrix, 
or if possible the unit matrix. 
In matrix notation, (2) becomes 
(2') 
Two matrices (fj, (fj' related to each other in this way are said to be 
congruent. The difference between similarity (§2.5 (I» and congruence 
consists in the fact that for similarity the matrix ~{ represents a mixed 
tensor, covariant with respect to one index and contravariant with respect 
to the other, whereas for congruence the matrix represents a doubly 
covariant tensor. 
If (fj' is to be a diagonal matrix, then it must at least be symmetric; i.e., 
(fj'T = (fj'. If S is commutative, as we shall assume from now on, then 
(cf. §2.6 (10». 
By multiplication with (:17)-1 and :I-I we see that (fj'T = (fj' if and only if 
(fjT = OJ; in other words, the symmetry of a matrix remains unchanged 
by transformation to a congruent matrix. 
We now assume that (fj is symmetric. Then the transformation to a 
diagonal matrix can be effected, exactly as in §2.5, by multiplication with 
matrices U, ID; for by right-multiplication with U and ID, or by left-
multiplication with UT and IDT, we perform exactly the same operations 
on the rows as on the columns, as the reader may easily verify. 
If S is the field of complex numbers, it is appropriate to introduce 
another concept: for the matrix (fj = (gd) we define the conjugate 
transposed matrix (fj * = 
(g~) by 
g~ = gAIC; 
(fj * = ffiT = &T, 

3 Linear Algebra 
271 
where the bars denote complex conjugates. From the one-column matrix I 
we obtain the one-row matrix I* with the elements X*A = x A• 
A matrix with the property 
(fj* = (fj, 
is called a Hermitian matrix. The diagonal elements of a Hermitian matrix 
are real (glClC = glClC)' 
If (fj is a Hermitian matrix, the mapping (I, 1)) ---+- I*(fj1) = XlCglCAy A is 
called a Hermitian bilinear form, and the mapping I---+- I*(fjI is a Hermitian 
form. 
Under the coordinate transformation I = ::tI', the matrix (fj becomes 
0)' = ::t*(fj::t, so that a Hermitian matrix goes into a Hermitian matrix 
«(\j' * = (fj' if and only if (fj * = (fj). Thus the property of being Hermitian 
is independent of the choice of basis. 
If in a Hermitian bilinear form we take the basis vectors as arguments, 
we obtain, in view of ei = (8/,), 
or in other words exactly the coefficients of the bilinear form. This result 
holds fot any basis. 
The values of a Hermitian form are real; for if iT(fjI = W, then 
w = IT~i. Now ii; is a number, i.e., a one-row matrix, so that 
w = ii;T = iT~TI, and therefore, since ~T = (fj, we have ii; = w. 
This statement does not hold for quadratic forms with complex argument, 
a fact which explains why Hermitian forms are the appropriate ones in our 
present discussion. 
We now define an inner product by 
(3) 
I n order that this definition may be independent of the choice of basis, 
the matrix (fj must be transformed according to the rule 
(4) 
(fj' = ::t * (fj::t 
If we restrict S to the field of real numbers, we obtain our earlier 
result: a real Hermitian matrix is a symmetric matrix, and a real 
Hermitian form is a quadratic form, so that (3), (4) become (1), (2). 
A Hermitian matrix is taken into a Hermitian matrix by the transfor-
mation (4), and can be transformed, in the same way as a real symmetric 
matrix, into a (real) diagonal matrix. We omit the proof here, since the 
next section proves a sharper result. 

PART B ARITHMETIC AND ALGEBRA 
Moreover, by transformations of the form 
(5) 
1)' = 6*1)6 
with regular matrix 6, the diagonal elements of a real diagonal matrix can 
be transformed into ± 1; for example: 
1 
V/d/ 
1 
d 
1 
V/d/ 
1 
d 
/d/ 
But there are other possibilities; for instance, we could also make the 
transformation 
It is an important fact that for all such transformations the number of 
positive and negative terms remains the same (Sylvester's law of inertia). 
The proof of this law is as follows. Transformation (5) does not change 
the rank r of the matrix (in view of this invariance, r is also called the rank 
of the form represented by the matrix), so that the number of nonzero 
diagonal elements remains the same in every diagonal representation. 
So let us assume that the Hermitian form has been brought by two 
transformations (5) into the forms 
(6) 
XIXI + ... + xPxP -
Xp+IXP+1 -
••• -
xrxr 
= ylyl + ... + yaya _ ya+1ya+1 _ ... _ yryr, 
where the x.\ and yll are related by yll = s/x\ and we shall suppose that 
p > q. Then the system of equations 
y' = s),'x)' = 0 
Xi = 0 
i = 1, ... , q 
j = p + 1, ... , r 
has a nontrivial solution. If we substitute this solution in (6), then, since 
not all x' are 0, the left side is > 0, and the right side is ~ O. Since a 
corresponding contradiction can be derived from p < q, it follows that 
p = q, as desired. 
For real quadratic forms the theorem and the proof are the same with 
restriction to real transformations (s)"). 
The difference between the number of positive and the number of 
negative terms is called the signature of the form. We have shown that the 

3 Linear Algebra 
273 
rank and signature of a Hermitian form or of a real quadratic form are 
invariant under the transforrrzations (5). They are also the only such 
invariants, since every such form can be transformed by (5) into a form 
with diagonal matrix and with diagonal terms ± 1. 
If and only if the signature is equal to the rank, will all the values of the 
Hermitian form I*ffiI be nonnegative; and if, in addition, the rank is 
equal to the dimension of V, then the form will assume the value 0 only for 
I = o. Such a form is said to be positive definite. 
Our discussion has now led to the result: if an inner product with respect 
to a given basis is represented by a positive definite Hermitian form, then 
with respect to a suitably chosen basis it can be represented in the form 
i.e., by the unit matrix. 
We now ask which transformations will leave this form of the represen-
tation unchanged. By (4) it will be those transformations for which 
:! *(f:! = (f, or 
:! *:! = (f; 
such transformations are called unitary. If S is restricted to the field of 
real numbers, we obtain :!T:! = (f, or in other words the orthogonal 
transformations. The corresponding matrices are also called unitary, or 
orthogonal. 
The set of unitary (or if real, orthogonal) transformations is already 
sufficient to transform any Hermitian (or if real, symmetric) matrix into 
a diagonal matrix. We shall prove this statement in §3.7, after we have 
introduced the concept of a determinant. 
3.3. 
The Tensor Product and the Outer Product 
A second possibility for introducing a multiplication with the properties 
(P), (La), (Lm), (T) consists of regarding II/(A as the basis vectors of a 
vector space Wr , whose dimension is therefore r = kl. More precisely: 
let Wr be a vector space of dimension r = kl with the basis €/(A • Then we 
define the tensor product by 
(I) 
where it must be remembered that S is assumed to be commutative; moreover, 
we assume that as = sa is defined in P", V and W. 
The mapping defined by (1) is in general not a mapping of P" x V onto 
W; for the images of the elements of P" x V are a/(bA€/(A , but the elements 
of Ware the qd€/(A • 

274 
PART B ARITHMETIC AND ALGEBRA 
The product will be invariant under basis transformations (l;,) in P-
and (til A) in V, if in W we make the corresponding transformation 
(T) 
We must still verify that (T) is a basis transformation, i.e., that the 
€/-,'II' are linearly independent. But if we assume that 
then from (T) and from the fact that the €d are linearly independent it 
follows that 
for all K, A. 
If (with arbitrary pi, a') we multiply by i~' ,tf and add, we obtain 
By a transformation (T), the coordinates qd of an element of Ware 
transformed according to 
If V = V, so that i~' = t~', comparison with §2.6 shows that the elements 
of W (if V = V) are contravariant tensors of second order with respect 
to V. If V and V are dual to each other, then the elements of Ware 
mixed tensors. 
The tensor product is denoted by 
a @ b = aKbA(eK @ eA)' 
We have retained the distinction between the vector spaces V and V in 
order to make it easier to define the tensor product of several factors, 
since we need only use W in place of V or V, although then, of course, the 
vector space to which the products belong is a new one. 
We obtain 
The product of arbitrarily many factors is now defined by induction. 
However, we are in fact chiefly interested in the case in which all the 
factors come from the same vector space V = V, when we may write 
(a @ b) @ c = aKbAcl-'«eK @ eA) @ e/-,), 
a @ (b @ c) = aKbAcl-'(eK @ (eA @ e/-,), 

3 Linear Algebra 
275 
To begin with, the vectors (el( @ eA) @ e~ and el( @ (eA @ e~) are to be 
regarded as basis elements of two distinct vector spaces. But since these 
spaces have the same dimension 13, we can set up an isomorphism between 
them by an arbitrary one-to-one correspondence of their basis elements, 
whereupon we regard the basis elements assigned to each other by 
(el( @ eA) @ e~ ---+- el( @ (eA @ e~) as being "the same." But now the tensor 
product is obviously associative, and we can write 
(2) 
The tensor product is not the only bilinear mapping of P- x V in Wr • 
Like the linear mappings (see above), the bilinear and multilinear mappings 
form a vector space under appropriately defined S-multiplication. We 
shall consider only the following special case: 
If (a, b) ---+- a @ b, and consequently also (a, b) ---+- b @ a, are bilinear 
mappings, then so are 
(3) 
(4) 
(a, b) ---+- a v b = a @ b + b @ a, 
(a, b) ---+- a A b = a @ b -
b @ a,3 
so that these two mappings may be regarded as products. Since 
a v b = b v a, 
the first of these products could be called the symmetric product. More 
important is the second one, which because of 
a A b = -b A a 
is called the alternating product or, by Grassmann, the outer product. In 
the present section we consider only this product. 
As an element of W the alternating product is a contravariant tensor of 
second order. After choice of a basis (el() for V and a corresponding basis 
for W, the coordinates of this product are to be obtained from (4). If 
we set 
we obtain from (4) 
(5) 
From (5) follows pd = _pAl(, and in particular pl(l( = O. Thus the k2 
coordinates pl(A are completely determined by the values of a suitably 
3 In the present context the symbols 1\, v are defined by (3) and (4), and do not 
mean "and" and "or." 

276 
PART B ARITHMETIC AND ALGEBRA 
chosen set of k(k -
1)/2 of these coordinates. In this sense we can say 
that a A b has only k(k -
1)/2 essentially distinct coordinates. 
Furthermore, we can show that every skew-symmetric tensor 
p = (PIC).) with pM: = _pd, has this property; i.e., for the representation 
of such a tensor it is sufficient to know k(k -
1)/2 basis vectors, namely 
(K < A). 
For if in 
we make a change of summation indices in the second sum, we obtain 
from which, since p).1C = _pd, it follows that 
P = L pd( elC (8) e). -
e). (8) elC) = L plC).( elC A e).). 
IC<). 
It is to be noted that for the alternating product we have 
k 
k 
a A b = L L alCb).( elC A e).) = L (alCb). -
a).b
lC
) ( elC A e).). 
IC-l ),-1 
IC<). 
Another important property is that the alternating product is equal to 0 
if and only if a, b are linearly dependent. 
Proof. (a) If a, b are linearly dependent, so that pa + qb = 
0 and 
say q -=I=- 0, then b = -(p/q) a, and from (4) or (5) it follows that 
a A b = o. 
(b) If a A b = 0, then 
(6) 
for all 
K, A; 
so we wish to find two numbers p and q, not both = 0, such that 
for all K. 
But we may assume a' -=I=- 0 (since if a = 0, then a, b are linearly dependent) 
and therefore, by (6) we may take p = -b', q = a'. 
The alternating product of more than two factors could also be regarded 
as defined by (4). Then we would have 
(7) 
(a A b) A C = (a (8) b -
b (8) a) (8) C -
C (8) (a (8) b -
b (8) a) 
= a (8) b (8) C -
b (8) a (8) c -
c (8) a (8) b + c (8) b (8) a. 

3 
Linear Algebra 
277 
On the other hand, 
a A (b A c) = a (8) b (8) c -
a (8) c (8) b -
b (8) c (8) a + c (8) b (8) a; 
so that the operation A would not be associative. Of course, it would 
satisfy the following law: 
(a A b) A C + (b A c) A a + (C A a) A b = O. 
This law holds for the vector product in a three-dimensional orthogonal 
space (cf. II, 7, §1.9): 
(a x b) x c + (b x c) x a + (c x a) x b = o. 
Thus the definition by (7) is suitable if we wish to interpret the alternating 
product as a vector product. But this interpretation is restricted to the 
three-dimensional orthogonal space, and we also wish to preserve the 
associative law. With this in mind, we argue as follows: on the right-hand 
side of (7) the three vectors a, b, c are not all on the same footing, since 
only four of the six permutations of a, b, c actually appear. Thus we simply 
write down all the permutations, with a plus sign for the even permutations 
and a minus sign for the odd ones, and replace (7) by the new definition: 
a A b A C = (a A b) A C = a A (b A c) 
=a(8)b(8)c+b(8)c(8)a+c(8)a(8)b 
-
a (8) c (8) b -
c (8) b (8) a -
b (8) a (8) c. 
More generally: let 7TI, .•• , 7Tn be a permutation of the numbers I, •.• , n, and 
let (-I)'" = ±I according as 7T is an even or an odd permutation (cf. 
IB2, §IS.3.2), then we define 
11' 
This sum is to be taken over all permutations of the numbers I, ... , n. 
In the case n = 2 we again obtain the definition (4), but (4) must be 
restricted to the case that the two vectors a, b belong to the vector space 
V; then and only then do we have the freedom to define 
(a A b) A C = a A (b A c) = a A b A C. 
The alternating product is also denoted by square brackets: 
Q1 A a2 A ••• A an = [ai, a2 , ... , 0,.]. 
If we interpret a A b as a vector product in a three-dimensional 
orthogonal space, the expression a A b A C now corresponds to (a x b) c. 

278 
PART B ARITHMETIC AND ALGEBRA 
3.4. 
The determinant 
On the basis of the definition §3.3 (7) the alternating product has the 
following properties: 
(La) 
[ ... , a; + a; ... ] = 
[ ... , a; , ... ] + [ ... , a; , ... ]. 
(The vectors represented here by the dots remain unchanged in each of 
the successive steps of the summation.) 
(Lm) 
(a) 
[ ... , aiS, ... ] = [ ... , ai , ... ] S 
[ ... ai ... a; ... ] = 0, 
and i -=I=- j. 
From (a) and (La) it follows that 
(a') 
[ ... ai ... aJ ... ] = -[ ... al ... ai ... ], 
since 
If the characteristic of S (cf. IB5, § 1.11) is not equal to 2, so that 1 + 1 =1= 0, 
then (a) also follows from (a'). 
From these properties it follows that if al , ... , an are linearly dependent, 
then [al ... an] = o. For then one of the vectors, sayan, is a linear combi-
nation of the others, and we have 
[al ... an-I, alcl + .. , + an_ICn-l] 
= [al ... an-I, al] cl + ... + [al ... an-I, an-I] cn- l 
= 0 
by (a). 
We shall see later that [al ... an] = 
0 only if the aI, ... , an are linearly 
dependent, a fact closely related to the solvability of the system of 
homogeneous equations 
(K = 1, ... , n, v = 1, ... , n). 
It is an important fact that the alternating product is determined in an 
essentially unique way by the properties (La), (Lm), (a). We shall prove 
this statement here only for the case k = n, by actually computing the 
coordinates of [aI' ... , an] on the basis of these properties alone. 
Let el , ... , en be a basis of Vn , although it would be sufficient that all 
a., are expressible as linear combinations 
in other words the eA need not be linearly independent. 

3 
Linear Algebra 
279 
Then by (La), (Lm) we have 
From (a) it follows that the product [ell ... ell ] = 0 if two indices are 
1 
n 
equal. Thus for the VI , ••• , Vn we need to consider only the permutations 
7TI, ... , 7Tn of the numbers I, ... , n: 
By (a) we have [ed' ... , ewn] = (-1)" [el , ... , en], so that 
(0) 
Thus [aI' ... , an] is determined up to the "factor" [el , ... , en]. This factor 
is a vector in Wr (r = nn). 
To a great extent, the present discussion can be made independent of 
the preceding section. Given a system of vectors aI, ... , an in a space Vk , 
let us set ourselves the problem of assigning to it a vector [al ... an], in 
another space W, which is to be equal to zero if and only if the al , ... , an 
are linearly dependent. Such a mapping must in any case satisfy condition 
(a). Furthermore, it is reasonable, though unnecessary, to demand (La) 
and (Lm). For if, for example, both a~ and a~ are linearly dependent on 
a2, ... , an, then 
a~ + a~ , a2 , ... , an are linearly dependent. But then 
[a~ , a2 , ... , an] = [a~ ,a2 , ... , an] = 0 implies [a; + a~ , a2 , ... , an] = 0, 
which is exactly the case if (La) holds. 
Furthermore, if al .,. an are linearly dependent, so are als, a2 , ... , an , 
and then [aI' ... , an] = 0 implies [als, a2 , ... , an] = 0, which is exactly 
the case if (Lm) holds. Thus (La) and (Lm) are not proved (that would be 
impossible) but they are motivated. 
From the definition of a mapping we have the requirement: 
(Lv) 
From a; = a; follows [ ... , a; , ... ] = [ ... , a; , ... ]. 
Now by the argument of the present section alone we see that if a mapping 
with the desired properties exists at all, then for k = n it can only be the 
mapping represented by (D). The numerical factor will be denoted by 
and will be called the determinant of the matrix m. 

280 
PART B ARlTHMETIC AND ALGEBRA 
If we wish, we may normalize the mapping (D) by choosing a basis (e,J 
such that 
(n) 
In this sense we also speak of the determinant of the vector system aI, ... , an 
with respect to the given basis. The determinant is then a number, but 
under a change of basis it is transformed like the system of coordinates of 
an n-order tensor whose coordinates either all vanish or are all alike except 
for sign. Because of the alternation, we may simplify the transformation 
as follows: 
Let all = e,!llll( = eA,a~' with 
(2) 
Then 
[aI' ... , an] = [el , ... , en] . 1 aliI( 1 
= [el' , ... , en'] . 1 a;' I. 
(3) 
in other words, under a transformation of basis the given determinant is 
multiplied by the determinant of the matrix of the transformation. 
From (3) we can draw an important conclusion: (2) states (among other 
things) that the matrix m = (aliI() is the product of the matrices l: = (t;,) 
and m' = (aA.), and therefore (3) means that 
(4) 
Il: . m' 1 = Il: 1 . 1 m' I. 
This relation is called the law of multiplication of determinants. We seem 
to have proved it here only under the assumption that l: is a regular matrix, 
but in (2) we may in fact consider an arbitrary matrix. In this case the 
eA' will not necessarily be linearly independent, but it was pointed out at the 
time that the equation (D), the only equation used here, does not require 
the vectors eA, to be linearly independent. Thus (4) is valid for arbitrary 
matrices l:, mi. 
Our argument shows that if there exists a mapping which is multilinear 
(Lv, a, m) and alternating (a) and has the normalization (n), then it can 
only be represented by the determinant (1). But does A actually have the 
property of vanishing if and only if al , ... , an are linearly dependent? 
At the beginning of the present section we proved: 
If al , ... , an are linearly dependent, then [aI' ... , ~] = O. 

3 Linear Algebra 
281 
On the other hand, if the 01 , ... , On are linearly independent, they can be 
chosen as a basis, and the original basis vectors can be represented in the 
form eK = 0lle/. But then by (D) we have 
1 = [e1 , ... , en] = [01 , ... , On] / e/ /, 
so that 
[01 , "', On] *- O. 
So the vanishing or nonvanishing of the determinant provides a 
criterion for the linear dependence of a given system of n vectors in Vn ; 
in other words, it determines whether a system of n homogeneous linear 
equations in n unknowns has a nontrivial sol uti on or only the sol ution 
Xl = .,. = xn. = O. Thus the most important step in the theory of systems 
of linear eq uations has been taken. In order to provide a complete answer 
to the question whether an arbitrary system of k linear equations in n 
unknowns has a solution and, if so, how many solutions, we need only 
introduce certain refinements, to be described in the next two sections. 
For this purpose we require from the present section only the definition 
of the determinant of a matrix given by (1) above. The preceding discussion 
has motivated this definition, but if we are willing to adopt it without 
motivation, the theory of systems of linear equations can be developed 
independently of the theory of vector spaces. 
3.5. 
Rules for Calculation with Determinants 
1. In order to emphasize that we are taking over almost nothing from 
the foregoing discussion, we repeat the definition of a determinant: the 
determinant of the quadratic matrix ~ = 
(aIJK)~:L:::~ is the number 
(D!) 
2. Interchange of rows and columns. The transpose ~{T = 
(~IJ) of the 
matrix ~ is defined by ~IJ = 
a~ . Its determinant is 
K 
K 
/ ~T / = 
" (-I)'TT a1 
••• an . 
L.. 
'TTl 
'TTn 
In each of these summands let us make the permutation 7T-1 in the factors. 
Then 
But since 7T-1 is even or odd together with 7T, and since 7T-1 also runs 
through all possible permutations, we have the result 
(D2) 
/ ~{T / = 
/ ~ /. 

282 
PART B ARITHMETIC AND ALGEBRA 
Consequently, any rule for calculation that concerns the columns of a 
matrix is also valid for the rows, and conversely. 
3. Expansion of a determinant by the elements of a column (or of a row). 
If in (Dl) we combine all the summands containing all and then all those 
containing a1
2, and so forth, we obtain the determinant in the form 
Here, for example, 
where 'TT" runs through all permutations of the numbers 2, ... , n. But this 
expression is exactly the determinant of the matrix obtained from ~ by 
deleting the first row and the first column. We speak here of an (n -
1)-
rowed subdeterminant of ~ or of A, and we shall later use the expression 
"r-rowed subdeterminant" in the corresponding sense for rectangular 
matrices. If we denote by U,c" the subdeterminant obtained from A by 
striking out the Kth row and the vth column, we have: A,c" = (_1)II+K U,c". 
We leave it to the reader to verify this rule, and the following equations, 
by actual calculation: 
n 
A = ~ a.KA i 
i.J 
~ 
K 
K-1 
(for every i; no summation over i) 
(for every j; no summation over j). 
By forming the sum LK a/AKi, we obtain the determinant of the matrix 
formed from ~ by deleting the jth column and replacing it by the ith 
column. But this matrix contains two equal columns, so that its 
determinant is 0, a fact which we can either take from §3.4 (a) or derive 
directly from (1). We thus obtain, together with the above equations, 
(D3) 
a/A/ = 8/· A; 
Here again we take summation over equal indices. 
4. The Laplace expansion. The result (03) can be generalized in the 
following way: instead of the I-rowed subdeterminant (a/) consisting of 
the elements of a fixed column, we can consider the q-rowed subdeter-
minants formed from q fixed columns. Let these columns be numbered 
i1 , ... , i q , let the rows of such a subdeterminant be numbered K1 , ••• , K q , 
and denote the subdeterminant itself by 

3 Linear Algebra 
283 
By the algebraic complement of this subdeterminant we mean the subdeter-
minant (with suitable sign) formed from A by deleting the columns 
il , ... , iq and the rows Kl , ... , Kq . If we denote its columns by iq+1 , ... , in 
and its rows by Kq+1' ... , Kn , then ii' ... , iq , iq+1 , ... , in and K1 , ••• , Kq, 
Kq+1 , ... , Kn are permutations of 1, ... , n, and the desired algebraic comple-
ment is given by 
The generalization of (D3) is now given by the Laplace expansion: if we 
choose q arbitrary columns (or rows) and hold them fixed, and then 
multiply every q-rowed subdeterminant that can be formed from them by 
its algebraic complement and sum up, we obtain the determinant A: 
F or a fixed permutation i the summation here is to be taken over all 
possible choices of q numbers Kl , ... , Kq from among the numbers 1, ... , n. 
For the proof we may either write out the subdeterminants in full and 
verify that exactly the same products a;1 ... a:n occur as in A, or we may 
verify (La), (Lm), (a), (n) and make use of the fact that the determinant is 
the only function with these properties. 
5. The inverse matrix. From (D3) it follows, if A -=I=- 0, that the matrix 
~ = (A/fA) satisfies the equations 
~~ = ~~ = (t, 
and is thus both a right and a left inverse. 
If A = 0, then ~ has no inverse, since it follows from ~~ = (t by 
the theorem for multiplication of determinants that 
I~II~I = 1, 
so that I ~ I -=I=- 0. 
The multiplication theorem for determinants can also be proved by direct 
calculation without use of the earlier theory. 
3.6. 
Applications of Determinants to Systems of Linear Equations 
1. If in 
(I) 
(K = I ... k) 
we have k = n, then for each A = 1, ... , n we multiply the Kth equation 
by AI( A (see §3.5.3) and add: 

284 
From (D3) it follows that 
(1) 
PART B ARITHMETIC AND ALGEBRA 
Every solution of (I) is a solution of (1). If A * 0, then (1) can have only 
the solution 
(2) 
(A = 1 ... n). 
By actual substitution it is easy to see that this system (xA) is actually a 
solution of (I). Thus (I) has the unique solution (2). The same remark holds 
for the case with all bl( = 0, when the unique solution is the so-called 
trivial solution: all x A = 0. 
2. If A = 0, and also if k * n, let us find the "largest possible" 
subdeterminant * ° 
that can be formed by striking out rows and columns. 
Let there exist an r-rowed subdeterminant * 0, whereas all (r + I)-rowed 
subdeterminants = 0. From §3.5 (D4) it follows that all subdeterminants 
with more than r + 1 rows are equal to zero. 
By renumbering, if necessary, the equations and the x's, we may assume 
that 
*0. 
a{'" a/ 
Then we must solve the first r equations 
for the Xl, ... , x T , 
where the solution will contain x T+I , ... , xn as 
"parameters" whose values may be chosen arbitrarily. We can then show 
that these solutions, for arbitrary values of Xr+l, ... , x", are also solutions 
of the remaining equations of the original system, provided this system_ 
has any solutions at all. The details are to be found in any textbook. 
-
From this result it follows that the rank of a matrix (cf. §2.3) is the 
number r characterized by the following property: there exists at least 
one r-rowed subdeterminant * 0, but all (r + 1 )-rowed subdeterminants 
are = 0. 
3.7. 
Unitary Transformations of Hermitian Forms 
We now come to the proof of the assertion at the end of §3.2. 
In the present context S is the field of complex numbers, a basis (ell) 

3 
Linear Algebra 
285 
is given in Vn , and only unitary transformations are admissible. For the 
given basis, and consequently for all admissible bases, i.e., all bases 
arising from unitary transformations, let there be an inner product 
defined by 
I*1) 
(in the real case: IT1)). 
We call I a unit vector if I*I = 1, and we say that the vectors I, 1) are 
orthogonal if I *1) = O. This definition satisfies all the customary require-
ments for orthogonality (cf. II, 7, §2.5): namely, (I) 0 is orthogonal to 
every vector; (2) if a is orthogonal to b, then b is orthogonal to a; (3) the 
vectors orthogonal to a given vector a form an (n -
I)-dimensional vector 
space. With this definition the given basis and all other admissible bases 
consist of orthogonal unit vectors. 
We wish to show that a Hermitian form represented for the given basis 
by I *~I (i.e., by the Hermitian matrix ~) can be reduced by unitary 
transformations to the form 1)*1)1) with diagonal matrix 1); in other words, 
there exists a unitary matrix :I such that 
(1) 
is a diagonal matrix. 
In the real field this matrix produces the orthogonal transformation of a 
quadratic form into a sum of squares; but the proofs in the complex field 
are exactly the same, so that here we discuss the more general case. 
By §1.5 the columns of:I are the coordinates of the new basis vectors 
with respect to the old basis. So these coordinates are precisely what we 
are looking for; i.e., we seek a suitable system of orthogonal unit vectors. 
Since :I* = :I-I, it follows from (1) that ~:I = :I1). In this matrix 
equation let us consider the ith column. If ei' is the ith column of :I, and 
di is the ith diagonal element of 1), we obtain 
(no summation over i). 
Thus the desired vectors of the new basis are the solutions of the equation 
(2) 
~o = do. 
This analysis of the problem shows that we must find n mutually orthog-
onal vectors which are solutions of (2), where d may have various values 
s~ill to be suitably determined. 
If 0 is a solution of (2), then so is so, so that for each solution we may 
arrange that 0 *0 = 1. 
I t is easy to verify that the matrix :I formed from n such vectors provides 
the desired transformation of~. 

286 
PART B ARITHMETIC AND ALGEBRA 
The trivial solution of (2) is not a solution of our problem. A nontrivial 
solution exists only if 
all - d, a1
2, ••• , anI 
(Ch) 
I ~ - d<f I = 
. . . . . . . . . . 
= o. 
anI, ... , ann - d 
This equation is called the characteristic equation of the matrix ~, and its 
solutions are the eigenvalues of 21. 
In some contexts it is customary to define the eigenvalues as the solutions 
of I d~ -
(f I = o. 
To each eigenvalue there correspond nontrivial solutions of (2), which 
are called eigenvectors of the matrix ~. The equation (Ch) is of the nth 
degree in d: 
(3) 
Ao -
AId + ... + (_1)n-1 An_1dn-1 + (-1)" d" = o. 
The coefficients are sums of principal subdeterminants, formed by striking 
out rows and columns with the same indices. In particular, 
Ao = A = I ~ I 
n 
An-1 = L aii = tr ~, the trace of ~. 
i-I 
The characteristic equation has the following invariant property. If;:r is an 
arbitrary regular matrix, then 
I ~ -
d<f I = I ;:r-1 II ~ -
d<f II ;:r I = I ;:r-1(~ -
d<f);:r I 
= I ;:r-1~;:r -
d<f I. 
Consequently, similar matrices have the same characteristic equation and 
thus also the same eigenvalues. Since the All are the elementary symmetric 
functions of the eigenvalues, they also, and in particular the determinant 
and the trace, are invariant under similarity transformations (in the sense 
of equation (1) in §2.5). 
For the problem of finding n mutually orthogonal eigenvectors of the 
Hermitian matrix ~ the following two theorems are fundamental: 
1) The eigenvalues of a Hermitian matrix, and thus of a real symmetric 
matrix, are real. 
Proof: 
Let d be a complex eigenvalue and 0 a corresponding 
eigenvector, so that ~o = do and thus also ~o = do. Multiplying by 
OT and OT respectively, we obtain 
(4) 
(5) 
OT~O = dOTO, 
OT~O = doro. 

3 Linear Algebra 
In (5) we form the transposes: 
(6) 
Since ~T = ~, it follows from (4) and (6) that 
(d -
d)OTO = 0. 
But 
n 
OTO = L V"V" -=I=- 0, 
so that d = d, 
11-1 
as desired. 
287 
2) Eigenvectors belonging to distinct eigenvalues are mutually orthogonal. 
Proof: let ~01 = d10 1 , and ~02 = d20 2 • Then 
(7.1) 
(7.2) 
0:~01 = d1o:01 , 
Oi~02 = d20i02 • 
In (7.2) we form the conjugate transposes. Since d2 is real and ~* = ~, we 
obtain 
Comparison with (7.1) gives 
(d1 -
d2) 0:01 = 0, 
so that if d1 -=I=- d2 , then 0:01 = 0, as desired. 
If the equation (Ch) has n distinct zeros, these theorems show that our 
problem is completely solved. The zeros of (Ch) are themselves the 
elements of the desired diagonal matrix. If we are interested only in this 
matrix or, in other words, in the result of the transformation, the eigen-
vectors do not need to be calculated at all. 
Let us give a simple example to show what may happen if (Ch) has 
multiple roots. Consider the real quadratic form 
(8) 
The fact that the matrix is already in diagonal form will make the calcula-
tion shorter. The characteristic equation is 
(9) 
(1 -
d)2 (c -
d) = 0. 
The system of equations (2) becomes 
(1 -
d) Xl 
= 0, 
(10) 
(1 -
d) x 2 
= 0, 
(c -
d)x3 = 0. 

288 
PART B ARITHMETIC AND ALGEBRA 
For the double root d = 1 of (9) the matrix in (10) has the rank n -
2, so 
that the solutions of (10) form a two-dimensional vector space, in which 
we can find two mutually orthogonal solution vectors (as eigenvectors), 
one of which may be chosen arbitrarily. In our case the eigenvectors 
(normalized by ° *0 = I) comprise all the following vectors with arbitrary cp: 
01 = (cos cp, sin cp, 0), 
02 = (-€ sin cp, € cos cp, 0), 
0 3 = (0,0, I). 
€ = ±I, 
In geometric language this result means that in an ellipsoid of rotation the 
principal axes are not all uniquely determined. 
In general, we can prove the existence of n orthogonal eigenvectors in 
a totally different manner, which depends on the property of a quadric 
that its principal axes are of extremal (more precisely: of stationary) 
length. A quadric is defined by 
and the length of a vector is measured by V I*I. Let us ask the question: 
When does I*I assume a stationary value under the subsidiary condition 
I*~I = lor, what amounts to the same thing, when does I*~I assume 
a stationary value under the subsidiary condition I*I = I? Introducing 
the Lagrange multiplier k, we see that the partial derivatives of 
must be set equal to zero. The calculation is slightly different for the real 
and the complex case. In the real field we must form the equations (for the 
meaning of the SKt\ see §1.5) 
o 
oxi [xlC(aKt\ -
kS IC).) x).] = (ai). -
kSi).) x). + xlC(alCi -
kSKi) = o. 
Since ai). = a).i, it follows that 
(ai). -
kSi ).) x). = 0 
or 
(~{ - k'.t) I = O. 
In the complex case we may consider Xi and Ii as independent variables 
and then construct the equations 
(a) 
(b) 

3 Linear Algebra 
289 
In matrix notation we have 
(a) 
x*(~ -
k'.t) = 0, 
(b) 
(~- k'.t) x = O. 
Since ~* = 
~, these two equations have exactly the same meaning, 
namely (2). The existence of the desired solution-vectors now follows 
from a theorem of analysis. Since the "points" for which x*x = I form 
a closed set, and since x *~x is continuous, there exists a vector x = 0 1 , 
for which x*~x assumes an extreme value with x*x = 1. Next we 
determine a vector O2 such that 0:~02 assumes an extreme value under 
the subsidiary conditions 0:02 = I, 0:01 = O. We proceed in this way 
until the equations OtOi = 0 for all i < k can no longer be sati~fied, i.e., 
until we have n such vectors. 
We shall omit the proof that the matrix ::r = (VI/I() constructed in this 
way actually has the desired properties. 
Thus we have reached the desired result that every Hermitian matrix can 
be transformed into a diagonal matrix by a unitary matrix ::r with 
., 
The elements of 1) are the eigenvalues of the matrix ~; i.e., they are the 
solutions 'of the equation 
I ~ - d'.t 1= O. 
The number of nonzero di is equal to the rank of 1), and thus also to the 
rank of~. 
If in addition to transformations with unitary matrices we allow 
transformations 
with arbitrary regular matrices 6, then, as was shown in §3.2, we can 
reduce the terms of a real diagonal matrix to ± I. 
List of Formulas 
I 
II 
G 
A 
AI-A6 
S-M 
MI-M6 
System of linear equations §1.1 
§2.4, §3.6 
System of homogeneous linear equations § 1.1, §2.4 
Equality of n-tuples §1.2 
Addition of n-tuples §1.2 
Laws of addition §1.2 
Multiplication of an n-tuple with a scalar §1.2 
Laws of S-multiplication §1.2 

290 
Lv, La, Lm 
1,2 
PI, P2 
T 
a 
D 
n 
01-D4 
Ch 
PART B ARITHMETIC AND ALGEBRA 
Properties of linear transformations §2.1 
§2.6 §3.1 
§3.4 
Orthogonality and normalization of matrices §2.6 
Postulates for products of vectors §3.1 
Transformation of nd §3.1 
Alternation (for the outer product) §3.4 
Determinant §3.4 
Normalization of the determinant §3.4 
Rules for calculation with determinants §3.5 
Characteristic equation §3.7 

CHAPTER 4 
Polynom ials 
1. Entire Rational Functions 
1.1. 
Definition and Standard Notation 
By an entire rational function we mean a function (defined, let us say, 
for all real numbers and assuming real values) that can be constructed 
by addition and multiplication alone. Of course, we must make this remark 
more precise, and in doing so we shall free ourselves from any definite 
domain of numbers, considering instead an arbitrary commutative ring 
R with unitl element 1 (see IBI, §2.4). Thus in what follows we may take 
R to be the field of real numbers, or of rational numbers, or also' the ring 
of integers, but in each case we must take care to use only the properties 
implied by the definition of a "commutative ring with unit element." 
We now consider a function of one argument, defined in R and with 
values in R; in other words, we consider mappings of R into itself. Two of 
these mappings have a particularly simple character; namely, for every 
c E R the constant function x ---+ c (which to every argument x E R assigns 
the value c) and the identical function x ---+ x. For every pair f, g 
of mappings of the ring R into itself we can form the further mappings 
x ---+ f(x) + g(x), 
x ---+ f(x) g(x). 
We denote these by f + g andfg, so that 
(f + g) (x) = f(x) + g(x), 
(fg)(x) = f(x) g(x). 
It is obvious that these mappings again take R into itself. In the set of 
mappings of R into itself we have thus defined an addition and a multi-
1 For this element we use the symbol 1 from "force of habit" without implying 
thereby that the natural numbers are contained in R. 
291 

292 
PART B ARITHMETIC AND ALGEBRA 
plication.2 By an entire rationalfunction of one argument in R we now mean 
the constant functions, the identity function, and every mapping of R 
into itself that can be formed from these functions by repeated application 
of addition and multiplication (a finite number of times). Entire rational 
functions of several arguments can be defined in the same way, but we 
shall introduce them in a different manner in §2.3, so that for the present 
we restrict ourselves, without special mention of the fact, to functions of 
one argument. 
As a result of the rules for computation in R, the set of entire rational 
functions can be characterized very simply: 
A mapping f of R into itself is an entire rational function in R if and 
only if there exist elements ao , ... , an E R such that for all x E R we have 
the equation3 
n 
(1) 
I(x) = L aixi. 
i=O 
To show that every functionf defined by (1) (for all x E R) is an entire 
rational function, we introduce the notation f for the constant function 
x ~ c and I for the identical function x ~ x. Then (if we set 10 = 1), 
it is obvious that x ~ aixi is the function {lJi and thus from (1) it follows 
that f = 'Lf-o {liP; that is, f can be formed from I and the {li by addition 
and multiplication. In order to show, on the other hand, that every entire 
rational functionf can be represented in the form (1), it is only necessary 
to prove that this statement holds for f and I and that it holds for f + g 
andfg if it holds for fand g. For f we need only set ao = c, n = 0 in (1), 
and for I we set ao = 0, a1 = 1, n = 1; if, besides the representation (1), 
we also have g(x) = 'L?!'o bixi, then we define ai = 0, bk = 0 for 
i > n, k > m and obtain,4 with I = max (m, n), 
l 
(2) 
(I + g)(x) = I(x) + g(x) = L (ai + bi) Xi, 
i=O 
n+m 
h 
(3) (/g)(x) = I(x) g(x) = 
~. ~ L ~ 
~ aibkxi+k = L (~aibh-i) xh, 
O~t~n.O~k~m 
h=O 
t=O 
which completes the proof. 
Iff-=/=- Q, then in (1) we may obviously assume an -=/=- O. But are n and the 
ai already uniquely determined by f? Since in (2) we may obviously replace 
+ by - on both sides, we see that the answer to this question is affirmative 
2 It is easy to see that with these operations the mappings form a, commutative ring 
with unit element. 
S In order that this notation may be applicable to the case x = 0 we must define 
0° = 1, as we shall do throughout the present chapter. 
40 In (3) we must apply IBl, (41) (20). 

4 Polynomials 
293 
if and only if f = Q in (1) implies ao = ... = an = O. In §1.2 we shall see 
that this is certainly the case if R has no divisors of zero and contains 
infinitely many elements. But in the theory of numbers it will often be 
necessary to consider rings with only finitely many elements. One example 
is the ring containing only two elements, namely the zero element 0 and 
the unit element 1, with 1 + 1 = 0 (the residue class ring G/2 in IB5, §3.7), 
which has x2 + x = 0 for all x; in other words, the entire rational function 
x ---+ x 2 + x is the constant function Q, even though it has the representation 
(1) with ao = 0, a1 = a2 = I, n = 2. 
1.2. 
Zeros 
In this subsection we let R be a commutative ring with unit element and 
without divisors of zero. By a zero of the entire rational function f in R 
we mean an element ex E R such thatf(ex) = O. If not every element of R 
is a zero off, thenfhas only finitely many zeros.5 More precisely, we prove 
the following theorem: 
If f admits a representation (1) with an -=I=- 0, then the number of zeros 
off is at most n. 
In the first place, we deduce from (1), and from the fact that 
i-I 
i-I 
i-I 
(x -
ex) L xkexi- 1- k = L Xk+lexi - 1- k - L xkexi- k 
k=O 
k=O 
k=O 
i 
i-I 
= L xkexi- k - L xkexi- k = Xi -
exi 
k=1 
k=O 
for n > 0, the equation 
(4) 
f(x) - f(ex) = (x -
ex) II (x), 
with 
n-l 
(5) 
fl(X) = L a~xk, 
k=O 
The theorem can now be proved by complete induction on n. For n = 0 
the function f has no zeros, since ao -=I=- 0, so that the assertion is true. 
For n > 0, the induction hypothesis can be applied to fl' since 
a~-1 = an ; in other words, II has at most n -
1 zeros. Now if ex is a zero 
off, then (4) gives us the equationf(x) = (x -
ex)fl(X). For a zero x -=I=- ex 
of f we thus have (x -
ex) II (x) = 0, and therefore II (x) = 0, since 
x -
ex -=I=- 0 and R has no divisors of zero. Thus f has at most6 one zero 
more thanfl and therefore at most n zeros. 
5 Since by IBl, §1.5, the empty set is to be considered as a finite set, the case wherel 
has no zero is included here. 
6 It may happen that ~ is also a zero of 11 ; cf. §2.2. 

294 
PART B ARITHMETIC AND ALGEBRA 
From this theorem itJollows that (1) holds with an -=I=- 0 and/(x) = 0 for 
all x E R only if R has at most n elements. It follows at once that if R has 
infinitely many elements and if I(x) = 0 for all x E R, then (I) implies 
ao = ... = an = o. 
1.3. 
Horner's Rule 
From the definition of the ak in (5) it follows at once that a~_1 = an , 
a~_1 = a~ex +- ak (k = 1, ... , n -
1), I(ex) = ex~ex +- ao. These equations 
lead to the following simple rule, due to Horner, for calculating7 /(ex): 
an 
an- 1 
... 
al 
ao 
I a~_lex' 
... aiex I a~ex ! 
a' 
... 
n-2 
a~ I f(ex) 
The vertical arrows denote addition, and the diagonal ones multiplication 
with ex. This procedure produces not only I(ex) but also the a~ and therefore 
11 . If we apply the the same procedure to II in the case n > 1, we obtain, 
corresponding to (4), (5), the values of 11 (ex), the a~ withJ;(x) = L~:~ a~xk, 
and II (x) = 11 (ex) +- (x -
ex)J;(x), so that after substituting these values 
in (4) we have 
I(x) = I(ex) +-II (ex)(x -
ex) +- (x -
ex) 2 J;(x). 
Continuing this way, we obtain recursively Ih , the a~ (k = 0, ... , n -
h) 
for h = 1, ... , n with Ih(X) = L~:: a~ Xk, and Ih-l(X) = Ih-l(ex) +-
(x -
ex)lh(X), where we have set fo = f, a1°) = ak. By complete 
induction on h we have 
h-l 
(6) 
f(x) = L ft(ex)(x -
ex)i +- (x -
ex)h fh(X) 
for h ~ n. 
i-O 
Since In is obviously a constant, so that In (x) = In(ex), we further obtain 
from (6) 
n 
(7) 
f(x) = L fi(ex)(X -
exY, 
i-O 
which converts the representation (1) from x to x -
ex. By complete 
induction on h it is easy to show that 
a~~h = an and thus8 
In(ex) = a~n) = an. 
7 The rule is particularly convenient for use with a slide rule, since the only multi-
plications are with the constant factor ~. 

4 Polynomials 
295 
Applied to f(x) = 2X4 -
3x3 + X2 -
1 and 
ex = 1, Horner's rule 
gives: 
2 -3 
1 0 -1 
2 -1 0 -0 
2 -1 
0 01-1 
211 
2 
21 
31 11 
f(x) 
= 2(x -
1)4 + 5(x -
1)3 + 4(x -
1)2 + (x -
1) -
1 
2 
; I 4 
2 I 5 
2 
We can also use the rule to transform the expression (1 + z)n by setting 
f(x) = xn, ex = 1, and z = x-I; if, for simplicity, we omit the inter-
mediate rows (with the aih)ex), we obtain: 
o 
. . If 
~ 
I 
Ifwe strike out the first row, number the remaining rows and columns from 
o to n, and denote by Cik the number in the ith row and kth column, then 
by Horner's rule (as indicated by the two small arrows) we have 
(8) 
COk = CiO = 1, 
Ci+1.k+l = Ci+1.k + Ci.k+1 
for 0 ~ i + k ~ n -
2 
and 
(9) 
n 
(1 + z)n = L Ci.n_iZi. 
k-O 
The Cik thus recursively determined by (8) are called the binomial 
coefficients. By complete induction on n it is easy to show from (8) that 
'+k 
Cik = e i 
), where as usual we have set 
(10) 
(~) = ( Ii k)/n k = "( n! ')' . 
1 
k-n-i+l 
k-l 
I. n -
1 . 
If we multiply (9) by an and set az = b, we obtain the binomial theorem 
(11) 
8 Since the method of comparison of coefficients (see §2.1) is not yet at our disposal, 
we cannot simply deduce this fact from (7). 

296 
PART B ARITHMETIC AND ALGEBRA 
The table for the Cik is usually turned through 45° and called the Pascal 
triangle: 
2 
3 
3 
4 
6 
4 
Since we are working here in an arbitrary commutative ring R with unit 
element 1, the Cik are not to be considered as natural numbers but rather 
as elements Lj':"l 1 of R. But then we could have 1 + 1 = 0, for example 
(cf. §l.I), so that the quotients in (10) would cause trouble, which may 
be avoided by regarding the Cik as natural numbers and interpreting an 
expression like mr (m a natural number, r E R) in (9) and (11) as Lj':"l r. 
With this precaution the result (11) holds in any commutative ring with 
unit element.9 
2. 
Polynomials 
2.1. 
Formation of a Ring of Polynomials 
In §l.I we have already seen that in general the function x ~ Lf=o aixi 
does not uniquely determine the ai' But for calculation with such 
expressions as Lf=o aixi it would be very convenient to be able to assume 
that the coefficients ai are uniquely determined by the values of the 
expression. This will unquestionably be the case (for an element x with 
certain properties) if in R or in a suitable extension of R we can find an 
element x 
such that an equation Lf=o aixi = 0 always implies 
ao = ... = an = 0; for then we can recognize, as in §l.I, that 
Lf=o aixi = Lf_o bixi implies (comparison of coefficients) the equations 
ai = bi (i = 0, ... , n). An element x with this property will be called a 
transcendent over R. If R is the field of rational numbers, then in agreement 
with the definition in IB6, §8.I, any transcendental number may be chosen 
as a transcendent over R in the present sense. Since a transcendent x 
cannot satisfy any algebraic equation Lf=o aixi = 0 with an -=I=- 0, it 
cannot be characterized (i.e., determined) by statements involving only 
x, elements of R, and equality, addition, and multiplication in R. Thus 
9 Of course, the proof could have been carried out independently of Homer's rule. 
We can also dispense with the existence of a unit element in R if we agree that in (11) 
anbo, oObn are to be interpreted simply as an, bn. 

4 Polynomials 
297 
the transcendents are also called indeterminates.1o But a name of this sort 
must not be allowed to conceal the fact that a transcendent must be a 
definite element (of an extension ring of R) and that the existence of such 
elements must in every case be proved. As an indeterminate over the field 
of rational numbers we may, as remarked above, choose any transcen-
dental number (such as e or 7T). 
Thus it becomes our ta~ to extend the commutative ring R with unit 
element 1 to a commutative ring R' containing a transcendent x over R. 
By saying that R' arises from extension of R and may thus be called an 
extension ring we mean that the elements of R are all contained in R', 
and that addition and mUltiplication of these elements leads to the same 
result in R' as in R; we express the same idea by saying that R is a subring 
of R'.l1 Throughout the present chapter we shall make the tacit assumption 
that the unit element of R is also the unit element of R', and we shall also 
assume that all the rings in question are commutative. 
Such a ring R' certainly contains all the expressions L~o aixi. But by 
the definition of a transcendent these expressions are in one-to-one 
correspondence with the sequences (an)n=o.1. ... , if from the sequence 
ao , '.', am we construct an infinite sequence by setting an = 0 for n > m. 
So let us see what will happen if for R' we simply take the set of sequences12 
a = (an)n=o.l .... with the property that there exists a natural number m, 
such that an = 0 for n > m. Motivated by (2) and (3), we now define 
addition and multiplication in R' by 
(12) 
n 
(ab)n = L aibn-i, 
i=O 
from which it is easy to see that the sequences a + b, ab are again 
contained in R'. With respect to this addition the set R' is obviously a 
module, and we see at once that the multiplication is commutative and 
distributive. Finally, associativity is shown thus: 
n k 
n 
n 
«ab) cn) = L L aibk-iCn-k = L ai L bk-iCn-k 
k=O i=O 
i=O 
k=i 
n 
n-i 
= L ai L bhcn-i-h = (a(bc)n . 
i=O 
h=O 
10 In §§2 and 3 the symbol x will almost always denote an indeterminate; more 
precisely, x is a variable for which only indeterminates can be substituted. On the other 
hand, in §l the variable x (provided it is not bound) may be replaced by any of the 
elements of a ring. 
11 If R' or R is a field, we speak of an extension field or sub/ield, respectively. 
12 For the notation see IBl, §4.4. Instead of simply writing a we shall sometimes use 
the more complete symbol (ao, ... , an , 0, ... ). 

298 
PART B ARITHMETIC AND ALGEBRA 
Consequently, R' is a commutative ring. Also, it is easy to show that 
a ~ (a, 0, ... ) is an isomorphism of the ring R into the ring R'. Thus we 
may extend the equality (cf. IB1, §4.4), which up to now has been defined 
only between elements of R and elements of R', by setting 
(13) 
a = (a, 0, ... ) 
and (a, 0, ... ) = a 
for 
a E R. 
Then R is a subring of R', and the unit element 1 of R is also the unit 
element of R'; moreover, the zero element of R is also the zero element 
of R', as follows at once from (12), (13). 
Then R' certainly contains a transcendent over R, namely z = (0, 1, 0, ... ). 
To prove this we derive the equation 
(14) 
n 
(ao , ... , an , 0, ... ) = L aizi 
i-O 
by complete induction on n. For n = ° 
the equation follows from (13). 
From (14) for an integer n ~ ° 
we have 
n 
(ao , ... , an+1 , 0, ... ) = L aizi + (bo , ... , bn+1 , 0, ... ), 
i-O 
if bi = ° for i = 0, ... , nand bn+1 = an+1' For the case ao = 
an-l = 0, an = On+1 , we further obtain from (14) 
On+lZn = (co, ... , Cn , 0, ... ), 
with Ci = ° 
for i = 0, ... , n -
1 and Cn = an+l . From the definition of 
bi , Ci , z it now follows at once from (12) that 
(On+1Zn) Z = (bo , ... , bn+1 ,0, ... ), 
and thus 
n 
n+l 
(ao, ''', an+1 , 0, ... ) = L aizi + an+1Zn+1 = L aizi, 
i=O 
i=O 
which completes the proof by induction. If we now have Li=O aizi = 0, 
it follows from (14) that (ao , ... , an , 0, ... ) = 0; but since (13) are the 
only equations holding between an element of R and an element of R', we 
thus have ao = ... = an = 0, so that z is a transcendent. As a generaliza-
tion of the concepts in 183, §1.3, we may now state the content of (14) 
in the following way: the Xi (i = 0, 1, ... ) form a basis of R'; that is, R' 
is a vector space (of infinite dimension) over a domain of scalars that is 
not necessarily a skew field but only a commutative13 ring. 
13 The commutativity is required only for the multiplication. Compare the mUltiplica-
tion in a vector space R' with the multiplication in an algebra of finite order (185, §3.9). 

4 Polynomials 
299 
Any commutative ring which, like the ring R' just constructed, contains 
the ring R and also a transcendent x with respect to R, and also consists 
only of elements of the form L~-o aixi (ai E R), is called a polynomial ring 
in the indeterminate (or also in the generator) x over R and its elements are 
called polynomials in x over R. The above discussion shows that a 
polynomial y = L~=o aixi determines the sequence (ao, ... , an , 0, ... ) 
uniquely. The terms of this sequence are called the coefficients of y (more 
precisely: ai = coefficient of Xi in y). For y -=I=- 0 it is obvious that there exists 
exactly one greatest integer n ~ 0 with y = Lf-o aixi, ai E R and an -=I=- O. 
This number is called the degree of y, and an is the leading coefficient. To 
the polynomial 0 we shall assign the degree 0, although this is not usually 
done. Then the set of polynomials of degree ~ n (or also < n in case 
n > 0) is a module with respect to addition, as is easily shown. In 
particular, the set of polynomials of degree 0 is equal to R itself. 
The ring R' thus defined is not the only polynomial ring in an indeter-
minate x over R, although it is the easiest to construct; but every such 
polynomial ring is mapped isomorphically onto R' by the correspondence 
n L aixi ---+ (ao , "', an , 0, ... ), 
i-O 
where the elements of R remain fixed and x is mapped onto 
z = (0, 1,0, ... ). The calculations given above in (2), (3) remain valid here, 
so that with 1 = max(n, m), ai = 0 = bk for i > n, k > m we have 
n 
m 
l 
L aixi + L bixi = L (ai + bi) Xi 
( 15) 
Moreover, it is easy to show that this is the only isomorphism with the 
desired properties. The various methods of construction are therefore 
completely equivalent to one another, so that we may speak of the 
polynomial ring in x over R. To denote this ring we shall use the symbol 
R[x]. 
[f S is an arbitrary extension ring of R (the simplest case would be 
S = R), then every polynomial L~=o atxi E R[x] defines an entire rational 
function 
(16) 

300 
PART B ARITHMETIC AND ALGEBRA 
in S; for it follows from L~-o aixi = L~o bixi that (ao, ... , an , 0, ... ) = 
(bo, ... , bm , 0, ... ) and thus 
L~=o aiui = L~o biui , so that in fact the 
mapping (16) is uniquely defined by the polynomial alone. Moreover, the 
definition of addition and multiplication of polynomials is such that for 
every u E S the mapping L~=o aixi ~ 
L~=o aiui is a homomorphism of 
the ring R[x] into the ring S, as is easily shown. The homomorphism 
determined by u in this way is often referred to as substitution of u (for the 
indeterminate x). In particular, if S is an extension ring of R[x] and if the 
function (16) is denoted by f, we have L~-o aixi = f(x): the polynomial 
is the value, for the argument x, of the function corresponding to it, and 
therefore it is uniquely determined by f In this way we obtain a one-to-one 
correspondence between the polynomials and all functions defined14 in 
an extension ring of R[x] (which may be R[x] itself) by the ao , ... , On E R 
as in (16). Consequently, polynomials in x will be written below in the 
formf(x), wherefis the function so defined. Then the results of §1.2, §1.3 
also hold for polynomials. The value f(u) of the function f (i.e., of the 
function corresponding to the polynomial f(x) for an argument u) in an 
extension ring of R[x] will be called, concisely though inexactly, the value 
of the polynomial f(x) at the point u. But this abbreviated way of speaking 
must not be allowed to conceal the fact that a polynomial over R is not 
necessarily a function defined in R (or in an extension ring of R). In any 
case, the above polynomials (ao , ... , an, 0, ... ) by means of which we 
demonstrated the existence of polynomial rings, are not functions of this 
sort. Of course, it is possible that polynomials over R may also be functions 
in R. For example, in an infinite ring R without divisors of zero we may, 
by § 1.1, § 1.2, define the polynomial ring over R as the ring of entire 
rational functions in R with the identity function [ as generator, provided 
we set the constant function f equal to c. But in many cases (though not 
in the case just mentioned) we must even then distinguish between the 
polynomial as a function in R and the function (16) corresponding to it. 
Under the assumptions just mentioned for R and the f, not only [but also 
[2 is a transcendent over R in R[[], so that we can form the ring R[[2] of 
polynomials in [2 over R, and then of course the elements of this ring are 
entire rational functions in R. The polynomial 1 + [2 is then the function 
u ~ 1 + u2, whereas (16) assigns to it the function u ~ 1 + u, since we 
may set ao = al = 1, n = 1. 
This sharp distinction between a polynomial and an entire rational 
function is a necessary one from the logical point of view, but it is often 
l40 If the domain of definition of the function (16) is restricted to R, then in general 
the uniqueness of this correspondence is lost and can be restored only under certain 
special assumptions, e.g., that R has infinitely many elements and no divisors of zero 
(see §1.1, §1.2). 

4 Polynomials 
301 
disregarded in the various branches of mathematics; in many cases only 
one of the two concepts is actually needed but both names are used for it. 
There are historical reasons for this practice. Originally the word 
"polynomial" denoted any expression with several terms, and then more 
particularly an expression of the form ao + a1x + ... + anxn in powers of 
a variable x. Now it is common practice in analysis to use the word 
"function" not only for the function (= mapping) but also for its value 
at the point x (and similarly for the case of several arguments). Thus it 
became customary in analysis to use "polynomial" and "entire rational 
function" as synonyms, and this practice can be justified on the basis of 
our definitions, provided we make a strict distinction between a function 
and its value; for in analysis the coefficients are taken either from the field 
of real numbers or of complex numbers, and thus, since each of these fields 
contains infinitely many elements, every entire rational function can be 
interpreted, as remarked above, as a polynomial in I, where I is the 
identical mapping x---+- x. 
It was Steinitz, in his fundamental work [Ia] of the year 1910, who 
first introduced the precise concept of an indeterminate as an element that 
is transcendental over the domain of coefficients. What we call a "poly-
nomial" is called by him an "entire rational function of the transcendent 
x"; in our present language it would have been more precise to call it the 
"value of an entire rational function at the point x." In a textbook [1] 
published in 1926, H. Hasse distinguishes between an "entire rational 
function in the sense of analysis" and an "entire rational function in the 
sense of algebra" (i.e., polynomials in our nomenclature). In the later 
textbooks on algebra (e.g., van der Waerden [1], Haupt [ID the word 
"polynomial" is used exclusively for expressions ao + ... + anxn in a 
transcendent x (over the ring containing the at), but with the remark, 
in concession to the older usage, that the words "entire rational function" 
are also used. Finally, in Bourbaki [3] a polynomial is clearly distinguished 
from an entire rational function by the notation itself, although a function 
of this sort is given the name fonction polynome which emphasizes the 
close connection between the two concepts. 
2.2. 
Zeros 
In this section R is a commutative ring with unit element 1 and without 
divisors of zero. Then for an -=I=- 0, bm -=I=-° 
it follows at once from (15) that 
anbm (-=1=-0) is the coefficient of xn+m and is at the same time the leading 
coefficient of L~=o atx' L~o btxt. Consequently, the product of two poly-
nomials -=I=-° 
is also -=I=- 0, and its degree is the sum of the degrees of the two 
polynomials. In particular, R[x] has no divisors of zero. By complete 
induction on the number of factors it is easy to extend this theorem to 
products of several polynomials. 

302 
PART B ARITHME.TIC AND ALGE.BRA 
By a zero15 of the polynomial f(x) E R[x] we mean a zero of f in any 
extension ring of R[X].16 For a zero a of f(x) it follows from (4) that 
f(x) = (x -
a).f~(x). This equation naturally raises the question: for 
which natural numbers m do we have 
(17) 
f(x) = (x -
a)m g(x) 
for a g(x) (dependent on m) with g(x) E R[x] ? If f(x) = 0, then m may of 
course have any value, but if f(x) -=I=- 0, our discussion shows that the 
degree of f(x) must be equal to the sum of m and the degree of g(x), so 
that m ~ degree of f(x). Thus, for f(x) -=I=-° 
there exists a greatest natural 
number m with an equation (I7); this number is called the multiplicity of 
the zero a. It can also be characterized by (17) and g(a) -=I=- 0. For on the 
one hand, if g(a) = 0, it follows from (4) that g(x) = (x -
a) gl(X) and 
thus by (17) that f(x) = (x -
a)m+l gl (x); and on the other hand, from 
(I 7) and f(x) = (x -
a)m' h(x) with m' > m we have 
(x -
a)m (g(x) -
(x -
a)m'-m h(x» = 0, 
and also from x -
a -=I=-° and the absence of divisors of zero, 17 
g(x) = (x -
a)m'-m h(x) and consequently g(a) = 0. Thus: 
If the nonzero polynomial f(x) has s distinct zeros al , ... , as with multipli-
cities ml , ... , m s , then there exists a polynomial h(x) with 
s 
(18) 
f(x) = h(x) n (x -
ai)mi. 
i-I 
The proof is by complete induction on s. For s = 1 the result (18) follows 
at once from the definition of ml . Now let us assume (18) and let a be 
another zero (-=I=- aI' ... , as) of f(x). Since R has no divisors of zero, it 
follows that a is then a zero of h(x), so that h(x) = (x -
a)m g(x), 
g(a) -=I=- 0, m ~ 1. Setting g*(x) = g(x) nt=l (x -
ai)m;, we then have 
f(x) = (x -
a)m g*(x), g*(a) -=I=- 0, so that m is the multiplicity of a as 
a zero of f(x). Substitution of (x -
a)m g(x) for h(x) in (18) then provides 
the statement necessary for the induction. By comparing the degrees on 
both sides of (I 8) we obtain a sharpening of the theorem in §1.2: 
15 Instead of "zero" the word "root" is often used. This meaning of "root" is of 
course different from the concept of an nth root in the field of real numbers (lBI, §4.7). 
The connection between the two concepts lies in the fact that the nth root of Q is a root 
of the polynomial xft -
Q. 
16 We could write R here in place of R[x], but then we would have to change our 
notation, since then the function (16) formed for a polynomial in an extension ring of R 
no longer determines the polynomial uniquely in every case. 
17 Here and in the preceding discussion we could dispense with the postulate of 
absence of divisors of zero, since the highest coefficient of x -
Q is equal to 1. 

4 Polynomials 
303 
The sum of the multiplicities of the zeros of a nonzero polynomial is not 
greater than its degree. 
In the notation of §1.3 it follows readily from (7) that the mUltiplicity 
m of a zero 
0: is characterized by the equations h(O:) = 0 for 
o ~ i < m, fm(O:) -=I=- O. In particular, 0: is a multiple zero (i.e., m > I), 
if and only if f( 0:) = f1 (0:) = O. Instead of f1 (x) it is often more convenient 
to make use of the derivative f' (x) of f(x) , defined as foIlows: 18 
(19) 
n 
f'(x) = L iaixi-1; 
i=l 
of course (since R does not necessarily contain the natural numbers), iai 
is to be interpreted here as L~=l ai (i.e., as the sum of i summands, each of 
which is =ai)' If in the definition (5) of f1 (x) we now replace 0: by x, then 
f1 (x) becomesf' (x), as is easily shown by changing the order of summation 
in (5); in particular, we thus havef1(0:) =/'(0:). It is obvious from (19) 
that the derivative of a sum of polynomials is equal to the sum of their 
derivatives. The rule for the derivative of a product, namely 
(20) 
h'(x) =f'(x)g(x) +/(x)g'(x), 
if h(x) = f(x) g(x), 
can of course be proved from (19), but we shall give a simpler proof in 
§3. I. By complete induction on n we then obtain from (20) 
n 
n 
(20') 
f'(x) = L (g~(x) n gi(X) , 
if f(x) = n gi(X). 
k=l 
i-I 
In particular, if we set gi(X) = x -
O:i, then from (20') we have 
n 
f'(x) = L n (x -
O:i)' 
k=l ii=k 
If R, and thus also R[x], has no divisors of zero, we can form (x.- O:k)-l 
in the quotient field R(x) (see §2.3) and then obtain 
n 
f'(x) = f(x) L (x -
O:k)-l. 
k-1 
2.3. 
Polynomials in Several Indeterminates 
We again let R be a commutative ring with unit element 1. As a 
generalization of the concepts in §2.1, the elements Xl, ... , Xn of an 
18 In this definition of the derivative no use is made of the concept of a limit, but if R 
is the field of real numbers, then the definition of J'(x) by the usual limiting process 
produces exactly the same result as here. 

304 
PART B ARITHME.TIC AND ALGE.BRA 
extension ring R' of R are now called independent transcendents, or also 
indeterminates, if an equationl9 of the form 
(21) 
(a. 
. E R) 
~l"'~n 
implies ail ... i
n = 0 for all indices. Every subring of R' which contains R 
and all the Xi also contains all expressions of the form on the left-hand 
side of (21), and it is easy to show that these expressions again form a ring. 
This ring is called the polynomial ring R[XI , ••• , xn] in the indeterminates 
Xl , .•• , Xn over R and its elements are called polynomials20 in the Xl , ... , Xn 
over R. For n = 1 this is obviously the definition in §2.1. For n > 1 we 
have 
(22) 
To prove this statement we denote R[XI , •.. , x n- l ] by S, and R[XI , ... , xn] 
by T. Then obviously SeT. From L:'o UiX~ = 0 (Ui E S), if we express 
the Ui in terms of the Xl, ••. , Xn-l , we obtain an equation of the form (21), 
whose coefficients are thus all = 0, which means that Ui = O. Consequently, 
Xn is an indeterminate over S, so that in T we can form the polynomial 
ring S[xn]. Conversely, for 
(i = 0, ... , m) 
we at once obtain 
n 
a. 
. XiI ••• Xin = 
" 
U X i 
~l'''~n I 
n 
L... 
in' 
O<ik<m 
i-O 
and therefore T C S[xn], which completes the proof of (22). 
By (22) we have reduced the construction of a polynomial ring in several 
indeterminates to the successive construction of polynomial rings in one 
indeterminate. Thus for every R and for every natural number n there 
exists a polynomial ring over R in n indeterminates. 
The ail ... i n in 
(23) 
y= 
are called the coefficients of the polynomial y. They are uniquely deter-
mined by y, since a second representation (23) would lead, when subtracted 
19 Strictly speaking, we should also write k = 1, ... , n below the sign of summation; 
this summation is taken over all n-tuples (iI' ... , in) with 0 < ik < m (k = 1, ... , n). 
20 The same term is sometimes used (see, e.g., IB5, §3.9) even when the Xi are not 
independent transcendents. 

4 Polynomials 
305 
from the first one, to an equation of the form (21). For each coefficient 
ai1 ... in -=I=- 0 in y the number i l + .. , + in is called the degree of the term 
ail ... inX~1 ... x~n. For y -=I=- 0 the maximum of the degrees of the individual 
terms (with coefficient -=I=- 0) is the degree of y in the Xl , ... , Xn . This degree 
is to be distinguished from the degree of y in Xi , which is defined as the 
degree of y as a polynomial in Xi over the ring of polynomials in the other 
indeterminates. Thus XIX: + X2 is of degree 3 in Xl , X2 , Xs , of degree 2 
in Xs , and of degree 1 in Xl and X2 • If all the terms of y (with coefficient 
-=I=- 0) have the same degree, then y is said to be homogeneous. Thus the 
homogeneous polynomials of degree 1 have the form L~=l aixi . 
As in §2.l for the case n = I, we now assign to each polynomial 
y E R[XI , ... , xn] a function f of n arguments in an extension S of 
R[XI' ... , xn] by defining f(ul , ... , un) for UI , ... , Un E S as the element that 
arises on the right side of (23) by substitution21 of Ui for Xi . In particular, 
we then have y = f(x i , ... , xn), so that this correspondence is one-to-one. 
If UI , ... , Un E R, then f(ul , ... , un) is also in R, so that if we restrict the 
domain of definition, f becomes a function of n arguments in R. The 
functions defined in this way are called the entire rational functions of n 
arguments in R. 
By complete induction on n it follows from (22), in view of the theorem 
at the beginning of §2.2, that if R has no divisors of zero, then R[XI , ... , xn] 
has none either. Thus if R has no divisors of zero, then by IBI, §3.2 we 
can form the quotient field of R[XI , ... , xn], whose elements are therefore 
of the form y/z with y, Z E R[XI , ... , xn], Z -=I=- O. A quotient field of this 
sort is denoted by R(XI , ... , xn). In view of the close connection between 
polynomials and entire rational functions, this field is usually called the 
field of rational functions over R, although its elements, being defined as 
quotients of polynomials, are in general not functions. But of course, to 
every elementf(xi , ... , xn)/g(xi , ... , xn) of R(XI , ... , xn) there corresponds 
a rational function R, 
its domain of definition consists of the n-tuples (UI' ... , Un) with 
UI , ... , Un E R, g(UI , ... , un) -=I=- 0, and its values are in the quotient field 
of R. 
The remarks at the end of §2.1 about the terminology "polynomial" 
and "entire rational function" apply equally well here to the case of 
several transcendents and to the terms "polynomial quotient" and 
"rational function," which again are often used synonymously, as is clear 
from the choice of name for the quotient field of a polynomial ring. A 
21 As in the case n = 1, this substitution is possible even if S is only an extension of R 
and not necessarily of R[x1 , "', xn]. 

306 
PART B ARITHME.TIC AND ALGE.BRA 
striking result of this practice is the fact that the elements of an algebraic 
extension field (see IB7, §2) over R(XI' ... , xn), where R is a field, are 
called algebraic functions over R. Of course, these functions in the sense 
of algebra are not necessarily functions at all; in particular, they are 
certainly not algebraic functions in the sense of the theory of functions of a 
complex variable (see 1116, §5). On the other hand, the latter functions can 
always be regarde~ as algebraic functions in the sense of algebra. 
2.4. 
Symmetric Polynomials 
An important special case of (18) arises when h(x) E R. Comparison of 
degrees then shows that L:-I mi = n, where n is the degree of f(x). Since 
mUltiplicities will play no role in what follows, we index the zeros from 1 to 
n in such a way that the number of times each zero appears is equal to its 
mUltiplicity; we then have 
(24) 
By multiplying out on the right-hand side [see IB 1, (41 ')] we see that the 
coefficient an-i of xn- i in f(x), with an = c, satisfies the equation 
(25) 
an _ i = (-I)i C 
L 
(i = 1, ... , n). 
O<kl < .. , <k,<n 
The notation under the summation sign indicates that the summation 
is to be taken over the set of all i-tuples (kl , ... , k t ) with positive integers 
kh ~ n (h = 1, ... , i) and kh < kh+l (h = 1, ... , i-I). This relationship 
between the coefficients and the zeros of a polynomial in the case (24) 
suggests that in the polynomial ring R[XI , ... , xn] (where R is an arbitrary 
commutative ring with unit element) we should pay special attention to 
the polynomials 
(26) 
(i = 1, ... , n), 
where in particular 
Then (25) can be written in the form an-t = (-I)tGi(cxI , ... , cxn). Obviously 
Gt(XI, ... , xn) is homogeneous of degree i, and has the further property, 
immediately obvious from (26), that it is left unchanged by an arbitrary 
permutation of the Xl , ••• , Xn • Polynomials with this property are called 
symmetric. From the uniqueness of the coefficients it follows that a 
polynomial is symmetric if and only if each coefficient is left unchanged 
by an arbitrary permutation of the indices. Now the polynomials 

4 Polynomials 
307 
ai(X1, .. " Xn) are of basic importance for all symmetric polynomials, in 
the following sense: 
For every symmetric polynomial f(Xl , .. " xn) from R[X1' .. ,' xn] there 
exists22 a polynomial F(X1 , .. " xn) in R[X1 , .. " xn], such that 
For this reason the ai(x1, .. " xn) are called the elementary symmetric 
polynomials23 in the Xl, .. " Xn , and the above theorem is called the 
fundamental theorem of the elementary symmetric polynomials; this theorem 
states that every symmetric polynomial can be expressed as an entire 
rational expression in the elementary symmetric polynomials, 
For the proof we choose a natural number g > 1 and confine our 
attention to the symmetric polynomials f(x1 , .. ,' xn) -=I=- 0 of degree < g, 
As indices for the coefficients we will then have only n-tuples (ii, .. " in) 
with 0 ~ i k < g (k = I, .. " n), By the mapping 
n 
( ' 
, ) 
", n k 
11 , .. " In ----+ L.. I~ -
k-1 
this set' of n-tuples is put into one-to-one correspondence with the set of 
non-negative integers < gn; the image of an n-tuple will be called its 
numeral. 24 Let the greatest numeral of an n-tuple (i1 , .. ,' in) with ail'" in -=I=- 0 
in f(Xl , .. " xn) be denoted by h. By the principle of complete induction 
(see IBI, §1.4) it is sufficient to prove the assertion for f(x1 , ... , xn) under 
the assumption that it is already known to be correct for all symmetric 
polynomials whose nonzero coefficients have an index numeral < h. 
If (ii, ... , in) is the n-tuple with numeral h, it follows that ik ~ ik+1 
(k = I, ... , n -
I), for if ik < ik+1 , then the n-tuple arising from (ii, ... , in) 
by interchange of ik with ik+1 would have a numeral > h, so that its 
coefficient would necessarily be zero, whereas in view of the symmetry of 
f(x1 , ... , Xn) this coefficient is = atl ... in -=I=- O. Abbreviating at(x1 , ... , xn) 
to at , we now write down the obviously symmetric polynomial 
n-1 
(27) 
f*(x1, ... , xn) = f(x1 ' ... , xn) -
ail'''in n a~k-ik+lain. 
k-1 
22 It can be proved that there is "exactly one" such polynomial. See, e.g., 
van der Waerden [2], §29. 
23 The entire functions corresponding to them (see the end of §2.3) are called the 
elementary symmetric junctions. 
24 It is obvious that in this enumeration the n-tuples are arranged in lexicographic 
order (see IBJ, §4.1). 

308 
PART B ARITHME.TIC AND ALGE.BRA 
Since ak is of degree k and 
n-l 
n 
L k(ik -
ik+l ) + nin = L ik < g, 
k-l 
k=l 
the polynomial J*(XI , ... , xn) is also of degree < g. In a product of 
arfactors we can find the term '* 0 with greatest index numeral by 
choosing, for each factor ai in (26), the summand with least indices 
kl , ... , ki (in other words, Xl ... Xi) and then multiplying these summands 
together. For the product subtracted in (27) this rule gives 
or, in other words, in view of L~:: Uk -
ik+1)' precisely the term 
ail ... inX~l ... x~n. Thus every coefficient '* 0 in J*(XI , ... , xn) has an index 
numeral < h, so that the induction hypothesis can be applied to this 
polynomial: J*(XI , ... , xn) = F*(ai , ... , an). Then from (27) the desired 
result follows at once for J(xi , ... , xn). The proof provides a method for 
actually calculating the F, for example:25 
Y=X~+X:+X:, 
y -
a~ 
= -3X~X2 -
3x:xs -
3X:XI -
3xlx: -
3x2x: -
3xsx~ -
6XIX2XS = Z, 
Z + 3ala2 = 3XlX2XS = 3as , 
y = a~ -
3ala2 + 3as . 
This procedure also enables us to solve the following problem: under 
the assumption (24) with c = 1 and with a given entire rational function 
g of one argument in R it is required to calculate the coefficients of the 
polynomial f1f-l (x -
g(CXi) in terms of those of J(x). For this purpose 
we represent the symmetric polynomial ai(g(xI), ... , g(xn) in the form 
Fi(al , ... , an) and then obtain the desired coefficient of xn-i in the form 
(-I)iFi(-an_I' ... , (-l)nao)· 
2.5. 
Power Series 
In analysis, an important role is played by power series (or sums of 
power series) in the variable X; that is, by expressions of the form L%'=o akxk. 
25 A simpler method for this case is given at the end of §2.S. 

4 Polynomials 
309 
Their addition and mUltiplication proceeds, provided x lies inside the 
circle of convergence, according to the formulas: 
00 
00 
00 
L akXli: + L bkxlc = L (ak + bk) X'c, 
k=O 
k=O 
k=O 
(28) 
00 
00 
00 
k 
L akxk L bkx'C = L ( L aibk- i ) xli:. 
k=O 
k=O 
k=O 
i =0 
A power series is determined by its sequence of coefficients, i.e., by the 
mapping k ----+ ak, and conversely the sequence of coefficients is deter-
mined by the power series (more precisely, by the corresponding function) 
if the radius of convergence is -=I=- 0 (cf. 1117, §1.3). But in algebraic applica-
tions of power series we are often interested, not in the numerical values 
obtained by inserting some x-value (from the circle of convergence), 
but only in the sequences of coefficients and their combinations according 
to (28). Then the restriction to real or complex numbers and the 
consideration of questions of convergence is not only superfluous but 
even troublesome, since it is frequently convenient to deal with a sequence 
as though it were the sequence of coefficients of a power series in a ring 
that is not a subring of the field of complex numbers. Just as in the 
construction of the polynomial ring in §2.1, it is desirable here to calculate 
with the sequences themselves. In order to be able to divide by power 
series, we must also consider series of the form L~=h akxk (with negative 
integer h), for which the equations (28) must be slightly generalized. 
These remarks suggest the following definitions. Let R be a commutative 
ring with unit element I. We consider the mappings a of the set of integers 
into R (with ak as the image of k in R26) and confine our attention to 
mappings a with the property that there exists an integer h with ak = 0 
for k < h. In the set R* of these mappings we can define an addition and 
multiplication, corresponding to (12), as follows: 
k-h 
(29) 
(abh = L Qibk-t, 
t=h 
if az = bz = 0 for alII < h. Then (cf. IBI, §1.6) for h > k -
h, or k > 2h 
the sum = 0, and, in general, this sum is independent of h, provided only 
az = bz = 0 for all I < h. Now, exactly as for R' in §2.1, it is easy to see 
that R* is a commutative ring. To each a E R we assign the mapping 
ii with ao = a, ak = 0 for k -=I=- 0, so that R is mapped isomorphically 
into R*. Thus we may set a = a and a = a, whereby R* becomes an 
26 We shall use this notation below, even when the mapping is not denoted by a single 
letter. 

310 
PART B ARITHME.TIC AND ALGE.BRA 
extension ring of R. Letting x denote the mapping which sends 1 into 1 
and all other integers into 0, we see that Xi (i > 0) is the mapping which 
sends i into 1 and all other integers into O. Then it is clear that Lf=o aixih , 
(i.e., the image of k under the mapping Lf=o atxi where it is to be noted 
that ai = tli) is equal to ak for k = 0, ... , n and is otherwise O. In particular, 
Lf-o aixi = 0 implies ai = 0, so that x is a transcendent over R. Thus 
we can construct the polynomial ring R[x] as a subring of R*. 
In the particular case that R is a field, the extension ring R* also contains 
the quotient field R(x) and is thus itself a field. For the proof of this 
assertion we first note that the mapping which sends -1 into I and other 
integers into 0 is the inverse X-I of x with respect to mUltiplication. Now 
for a -=I=- 0 in R* there exists by assumption an integer h such that an -=I=- 0, 
ak = 0 for k < h. With b = ax-h we then have bo = ah , bk = 0 for 
k < O. Thus it remains only to construct an inverse C for b. But by (29) 
we obtain such an inverse if we set Ck = 0 for k < 0 and calculate the 
remaining Ck from the equations 
i.e., for k = 0, 1, 2, '" 
boco = 1, 
for k = 0 
for k > 0' 
bOcl + blCO = 0, 
bOc2 + bici + b2cO = 0, 
Since bo -=I=- 0, it is obvious that this system of equations can be satisfied 
with elements Co , CI , ... E R, which completes the proof that R* is a field. 
To every element a of R* we now assign a rational number, which we 
ca1l27 the value I a I of a: I 0 I = 0, I a I = 2-\ if ah -=I=- 0 and ak = 0 for 
all k < h. Since 
for all k ~ n and for every a E R*, we have 
I a - .± aixt I < 2-n• 
~=h 
27 This valuation has nothing to do with an ordering, as is the case, say, for the 
absolute value of the rational and the real numbers (cf. IBl, §3.4). We are only 
interested in the fact that the value here has the properties IBl, (52), (53), as is 
easily shown; see also van der Waerden [2], §§74, 75. 

4 Polynomials 
311 
If now by means of this valuation we define the concept of a limit in the 
usual way, then a = limn-+<Xl L~-k aixi. Thus, as is customary in the 
theory of infinite series, we write 
and call R* the power-series ring in x over R, or the power-series field, if R 
(and therefore R*) is a field. 
As a result of this construction of R*, the purely algebraic properties 
of power series (addition, multiplication, formation of inverses) can be 
investigated in a purely algebraic way, i.e., independently of the special 
properties of the field of real (or complex) numbers of analysis. But it must 
be pointed out that the above concept of a limit for R* does not coincide 
with the concept of a limit for real (or complex) numbers if the ai are 
such numbers and x is replaced by such a number. 
If R is ordered, the power series ring R* can be ordered in a very simple 
way. As domain of positivity we take the set of all power series a -=I=- 0 for 
which the leading coefficient ak (i.e., ak -=I=- 0, ak = 0 for k < h) is 
positive.28 The properties of a domain of positivity [IBI, (44)] are easily 
verified. Since all the positive elements of R obviously belong to the 
domain of positivity just defined, the order in R* determines the same 
order for the elements of R as tpey are assumed to have in the first place. 
In view of the fact that for every natural number n the element Xi -
nxk, 
with i < k, has the leading coefficient I, so that Xi > nxk, we see that the 
ordering is non-Archimedean (cf. IBI, §4.3), since Xk is infinitesimal with 
respect to Xi. 
As an example of the usefulness of these power series which we have just 
introduced in a purely algebraic way, we shall consider the problem 
(see §2.4) of expressing the power sums Si = L~-1 x~ (i = I, 2, ... ) as 
entire rational functions of the elementary symmetric polynomials 
ai(X1, ... , xn), for which we again write simply ai' For an arbitrary 
commutative ring R with unit element I, we construct the power-series 
ring in x over the polynomial ring R[XI , ... , xn ]. By the definition of the ai 
the polynomial f(x) = nf-l (I -
XiX) over R[XI , ... , xn ] can be written 
in the form (with ao = I): 
n 
n 
(30) 
f(x) = 1 + L (-1)1 ai(xx1 , ... , xXn) = L (-I)i aixi. 
i=1 
i=O 
I n the power-series ring we can now prove 
<Xl 
(31) 
- f'(x) = f(x) L Si+1Xi. 
i=O 
28 Of course, this ordering does not lead (by IB 1, (51) to the valuation introduced above. 

312 
PART B ARITHME.TIC AND ALGE.BRA 
For by the definition of f(x) , of the Si+l and of addition as in (29), the 
right side of (31) is 
= t (xiI -
xkx) I x!xi I1 (l -
XiX)). 
k-l 
i-O 
i¥-k 
By (29) we have 
00 
00 
00 
(1 -
X kX) L X~Xi = L x1Xi -
X kX L X1 Xi = 1, 
i-O 
i-O 
i-O 
so that for the right side of (31) we obtain the expression 
L~-l Xk D;¥-k (1 -
XiX) which is seen at once from (20') to be equal to 
-I' (x). Then comparison of coefficients in (30) and (31) leads to 
(32) 
m 
mam + L (-I)k a m-kSk = 0 
k-l 
m L (-I)kam_ksk=O 
k-m-n 
for m = 1, ... , n, 
for m > n. 
In particular, for m = 1,2,3 and n ~ 3: 
a l -
Sl = 0, 
2a2 -
alsl + S2 = 0, 
3a3 -
a2s1 + als2 -
S3 = 0, 
so that Sl = al , S2 = 
a~ -
2a2 , S3 = 
a~ -
3al a2 + 3a3 . 
For n = 2, m = 3 the equation (32) becomes 
3. The Use of Indeterminates as a Method of Proof 
3.1. 
The Derivative of a Product 
The rules for the derivative of a product (20) can be proved most 
conveniently in the following way. Over the polynomial ring R[x] we 
construct the polynomial ring R[x] [u] (=R[x, un. Then by the calculations 
leading to (4), (5) we can obviously arrive at an equation 
(33) 
f(x) - f(u) = (x -
u) F(x, u), 

4 Polynomials 
313 
with F(x, u) E R[x, u], such that 
(34) 
I' (x) = F(x, x). 
Now F(x, u) is uniquely determined by (33) (even without the assumption 
that R has no divisors of zero). For if F*(x, u) in R[x, u], considered as a 
polynomial in u over R[x], has the leading coefficient c, then -c is the 
leading coefficient of (x -
u) F*(x, u), so that the latter polynomial is 
#- 0, if F*(x, u) -=I=- O. Thus/'(x) is characterized by (33) and (34). From 
the equation 
g(x) -
g(u) = (x -
u) G(x, u) 
with g' (x) = G(x, x) 
corresponding to (33) a short calculation now leads to 
h(x) -
h(u) = (x -
u)(F(x, u) g(x) + f(u) G(x, u». 
For h(x) = f(x) g(x), this is the equation for h(x) corresponding to (33), 
so that the equation corresponding to (34) gives us the desired result 
h' (x) = F(x, x) g(x) + f(x) G(x, x) = I' (x) g(x) + f(x) g' (x). 
It is to. be noted that by use of the indeterminate u we have created an 
exact proof out of the well-known faulty argument in which the difference 
quotient (f(x) - f(a»/(x -
a) is first calculated as an entire rational 
expression in x and a under the assumption that x -=I=- a and then x = a is 
substituted into this expression. For the field of real numbers our definition 
of the derivative of an entire rational function leads to the same result as 
the usual definition of analysis by means of the limiting value of the 
difference quotient, a fact which follows at once from the continuity of 
the entire rational function Fin (33). 
3.2. 
Determinant of a Skew-Symmetric Matrix 
Let 
be a skew-symmetric matrix, i.e., 
(35) 
(i, k = 1, ... , n). 
For the transpose29 AT = (aktkk=l ..... n we thus have AT = -A. Formation 
of determinants then leads to 1 AT 1 = (_l)n 1 A I. For odd n we have 
I AT 1 = -
1 A I, so that 2 1 A 1 = 0 in view of the fact that 1 AT 1 = 1 A I. 
29 cr. IB3, §2.6. 

314 
PART B ARITHME.TIC AND ALGE.BRA 
Thus, if the aik are numbers, it follows that I A I = O. But in an arbitrary 
ring we may have 2a = 0 even for a -=I=- 0; for example, in §1.1 we have 
noted that 1 + 1 = 0 -=I=- 1. Nevertheless, we can prove that even in an 
arbitrary commutative ring the determinant of a skew-symmetric matrix 
with an odd number of rows and columns is = 0, provided that in the 
definition of skew-symmetric we further require30 that 
(36) 
au = 0 
(i = 1, ... , n). 
For the proof we construct over the ring of integers the polynomial ring 
in the n(n -
1)/2 indeterminates Xik (1 ~ i < k ~ n) for an odd number 
n > 1. With 
(37) 
Xii = 0 (i = 1, ... , n), 
Xik = -Xki (1 ~ k < i ~ n) 
the matrix X = (Xtk)i.k=I ..... n then satisfies the condition corresponding 
to (35), so that 2 I X I = O. From the fact that the polynomial ring has no 
divisors of zero and that in the ring of integers 1 + 1 -=I=- 0, it follows that 
I X I = O. But by the definition of a determinant I X I is a polynomial in 
the Xik (1 ~ i < k ~ n). Thus the coefficients of this polynomial are all 
= O. If in an arbitrary ring R we have a matrix A satisfying (35), (36) and 
if we replace the indeterminates Xik (1 ~ i < k ~ n) by the aik with the 
same indices, then X is transformed into A, in view of (35), (36), (37). 
But what happens to the polynomial I X I? In order to answer this 
question, we consider a polynomialf(x1 , ... , xn) = LO~ik~m Ctl" .. inx~1 ... x~n 
over the ring of integers and elements ai' ... , an from an arbitrary 
commutative ring R. For any natural number c and any a E R we shall let 
c . a denote the sum Lf-l a (i.e., the c-fold multiple of a); also we set 
O· a = 0 and (-c)· a = -c' a.31 We then define 
Now f(XI , ... , xn) ----+ f(a 1 , •.. , an) (for fixed al , ... , an) is a homomorphism 
of the polynomial ring into the ring R; that is,f(x1 , ••• , xn) + g(XI , ... , xn) 
goes into f(a1 , ••• , an) + g(a1 , ••• , an) [and therefore f(x1 , ••. , xn) -
g(Xl' "" xn) intof(a1 , •• " an) - g(al' '." an)], andf(x1 , ••• , xn) g(Xl' .'" xn) 
30 In Bourbaki [2] a skew-symmetric matrix with this further property is said to be 
"alternating," although etymologically speaking this word again refers only to the 
change of sign under interchange of indices. If R is such that 2a = 0 implies a = 0, then 
(36) is obviously a consequence of (35), since by (35) we have ait = -ait, so that 
2ait = O. 
31 If R contains the ring of integers, then obviously c . a = ca. Otherwise ca is not 
defined and as a substitute for it we simply take c . a. The only purpose of the dot is 
to call attention to this distinction, 

4 Polynomials 
315 
goes into f(a 1 , ••• , an) g(a1 , ••• , an), as is easily proved from the formulas 
e . a + e' . a = (e + e') . a, (e' a)(e' . a') = ee' . aa'. The proof of the 
first formula, exactly as in IBI, (47), is based on the associativity of 
addition. The second formula is easily reduced to the case e, e' > 0, when 
it can proved by simply multiplying out the factors [IBI, (41)]. 
If we now apply this homomorphism to I X I, we obtain I A I (since all 
additive-multiplicative relations remain unchanged), and on the other 
hand we also obtain 0, since the coefficients of I X I are all =0. Thus 
I A I = 0, as desired. 
3.3. 
Determinant of the Adjoint Matrix 
For the matrix A = (aik)i.k=I ..... n (n > I) we denote the subdeterminant 
belonging to aik by Atk or - Aik , according as i + k is even or odd (this is 
the usual notation; cf. IB3, §3.5.3). Then the adjoint A * = (Aik)i.k-l ..... n 
of A is such that AT A * is a diagonal matrix with every diagonal element 
=1 A I. Formation of determinants leads to 
(38) 
If the atk are the elements of a commutative32 ring without divisors of zero 
(e.g., numbers) and if I A I -=I=- 0, then by (38) we have 
(39) 
I A * I = I A In-I. 
But we can also prove this equation even when the aik come from an 
arbitrary commutative ring and the case I A I = 0 is not excluded. For 
just as in §3.2, let us construct the polynomial ring in the n2 indeterminates 
Xik (i, k = I, ... , n) over the ring of integers. For X = (Xik)t.k_l ..... n the 
determinant I X I is then a polynomial whose coefficients are not all 
= O. Thus I X I -=I=- O. But because the polynomial ring has no divisors of 
zero, the above discussion shows that I X* I = I X In-I, which means 
that all the coefficients of the polynomial I X* I - I X In-l are = O. As 
in §3.2, if we replace X by A, we obtain the equation (39) for an arbitrary 
matrix A with elements from an arbitrary commutative ring. 
32 For noncommutative rings the concept of a determinant is of very restricted 
usefulness. 

CHAPTER 5 
Rings and Ideals 
1. 
Rings, Integral Domains, Fields 
1.1. 
The simplest example of a ring is the set of rational integers 
(lBI, §2) 
(G) 
0, 
±I, ±2, .... 
This set is closed with respect to addition, subtraction, and multiplication, 
by which we mean that the sum, difference, and product of two rational 
integers is always a rational integer. Furthermore, there are certain 
rules for calculation with these numbers, e.g., the familiar rules for the 
removal of parentheses and for the sign of a product. 
On the other hand, this ring is not closed with respect to division, since 
the quotient of two rational integers is not always a rational integer. 
There are many other examples of rings, e.g., the ring G[i] of Gaussian 
integers (IB6) consisting of all numbers a + bi, where i is the imaginary 
unit (see IB8, §I) and a, b are rational integers. The set of Gaussian 
integers is easily seen to be closed with respect to addition, subtraction, 
and multiplication, and the general rules for calculation with them are 
the same as for the rational numbers (lBI). 
Another important ring is the ring G[x] of the polynomials 
of all possible degrees n = 0, 1, 2, ... , where the coefficients ao , al , ... , an 
are rational integers (IB4, §2.l). Since we shall be dealing below with 
many other examples of rings, let us first give an exact definition. 
316 

5 
Rings and Ideals 
317 
1.2. 
Definition of a Commutativel Ring 
A (commutative) ring m is a non-empty set of elements a, b, c, d, ... , for 
which two operations, namely an addition and a multiplication, are defined; 
in other words, for any two elements a, b E m there exists a uniquely 
determined element c E m which is the result of the addition 
a + b = c, 
and also a uniquely determined element dE m which is the result of the 
multiplication2 
ab = d. 
These operations must satisfy the following laws (also called "axioms" or 
"postulates "): 
I. The associative law for addition and multiplication: for arbitrary 
elements a, b, c E m we have the equations 
(Ia) 
(Ib) 
(a + b) + c = a + (b + c), 
(ab) c = a(bc); 
II. Th'e commutative law for addition and multiplication: for arbitrary 
elements a, b E m we have the equations 
(lIa) 
(I rb) 
a + b = b + a, 
ab = ba; 
Ill. Invertibility of addition; i.e., subtraction is always possible: if a, b 
are any two elements of the ring m, there exists a uniquely determined 
solution x of the equation 
(Ill) 
a + x = b. 
This operation, inverse to addition, is usually called subtraction, and the 
solution of (III) is written in the form 
(1) 
x = b -
a, 
1 In the present chapter we confine ourselves to commutative rings, usually without 
explicit mention of the fact. If all the axioms except (lIb) are satisfied, the ring is said 
to be "noncommutative." Important examples of noncommutative rings are the quater-
nions (IB8, §3) and the general matrix rings (ID3, §2.2). The definition of a ring in IBI, 
§2.4 is formulated somewhat differently from the one given here, yet it is easy to see 
from the following discussion that the two definitions (apart from the assumption here 
that mUltiplication is commutative) are equivalent to each other (see also IB2, §2.4). 
2 Multiplication is usually denoted, not by any special sign such as a dot, but merely 
by juxtaposition of the two elements. 

318 
PART B ARITHMETIC AND ALGEBRA 
so that for arbitrary elements a, b we have the identity 
(2) 
a + (b -
a) = b; 
IV. The distributive law: for arbitrary elements a, b, c Em we have3 
(IV) 
a(b + c) = ab + ac. 
It is easy to verify that all these postulates are satisfied by the examples 
given above. On the other hand, we must also show that these laws, which 
have been reduced to the simplest possible form, imply all the usual rules 
for calculation (I B 1, §2A). 
1.3. 
Remark on the Associative Law 
Up to now we have defined the sum of two elements only, so that if 
three or more elements a, b, c, ... , d are to be added, we may, for example, 
begin by adding the first two elements, and then the third and the fourth, 
and so on, and the order in which these operations are to be performed 
may be indicated by parentheses. But (Ia) states that in a sum of three 
terms it makes no difference how we place the parentheses, and thus we 
may simply omit them. The same result may be deduced for a sum of any 
number of terms, the proof being the same as in IBI, §1.3. Thus for such 
sums it is customary to omit the parentheses and simply to write 
a+b+c+···+d. 
Furthermore, the commutative law (lla) shows that in a sum of 
this sort we may permute the terms at will, without affecting the result 
(IBI, §IA). 
From (Ib) and (lIb) it follows that the same remarks may be made for 
products of three or more factors. 
The distributive law can also be extended by induction to more than 
two summands and to products of factors in parentheses (cf. IBI, §2 (41»: 
(3) 
a(b + c + ... + d) = ab + ac + ... + ad, 
(4) 
(a + b)(c + d) = a(c + d) + b(c + d) = ac + ad + bc + bd. 
104. 
The postulates (la), (IIa) and (Ill) state that the element of a ring m 
form an Abelian group with respect to addition; this is the so-called "additive 
group" of the ring (lB2, §2A and IBI, §2.3).4 
3 In noncommutative rings, for which (lib) is not postulated, we must make the 
separate postulate 
(b + c)a = ba + ca. 
40 With respect to addition the ring is thus a module, by which we mean an additively 
written Abelian group (IBl, §2.3). 

5 Rings and Ideals 
319 
In view of the uniqueness (1) of its solution the equation 
(5) 
a+b=a+c 
implies b = c; in other words, we may cancel equal summands on both 
sides of an equation (first rule of cancellation). 
By III the equation 
(6) 
a + x = a, 
where a is any element of the ring, also has a unique solution 
(6') 
x=a-a. 
Now if b is any other element of the same ring, we may add the element 
b -
a to both sides of (6), which in view of the identity (2) gives 
(6") 
b + x = b, 
so that the same element x is the solution of (6) and of (6"). This element 
(7) 
a-a=b-b=O 
is called the zero element of the ring m. For the time being we shall denote 
it by the letter 0, but later we shall also uses the customary symbol O. Then 
we have the identities 
(8) 
(8') 
a+o=o+a=a, 
a -
0 = a, 
where (8') follows from (2) and (8), if in (2) we put 0 for a and a for b. 
Thus the zero element is the "identity element" or "neutral element" of 
the additive group of the ring. 
By (III) the equation 
a+x=o 
also has a uniquely determined solution 0 -
a, which we abbreviate to -a: 
x = 0 -
a = -a. 
Thus every ring element a has an inverse element -a satisfying the identity 
(9) 
a + (-a) = 0; 
5 The set consisting of the zero element alone satisfies all the postulates for a ring, 
but in general we shall assume that besides the zero element, which is always present, 
every ring contains at least one further element. 

320 
PART B ARITHMETIC AND ALGEBRA 
but since a -
a = 0, we may abbreviate a + (-a) to a-a. More 
generally, 
(10) 
b + (-a) = b -
a, 
since it follows from (Ia), (lIa), (9) and (8) that 
a + [b + (-a)] = a + (-a) + b = 0 + b = b, 
which implies the assertion (10) on account of the uniqueness of 
subtraction. 6 
If to both sides of the equation (III) we add the element -x, it follows 
from (9) and (8) that 
b + (-x) = a, 
so that in view of (I) and the uniqueness of subtraction: 
(11) 
- (b -
a) = a-b. 
1.5. 
We have 
(120) 
b - a = d - c 
if and only if 
(12b) 
a + d = b + c. 
It follows from the identity (2) and the equation (12a) that 
a + d = a + [c + (d -
c)] = a + c + (b -
a) = b + c; 
and conversely from (12b) and again from (2) that 
a + c + (b -
a) = b + c = a + d, 
so that by the rule of cancellation (5) 
c + (b -
a) = d, 
from which (12a) follows by the uniqueness of subtraction. 
We note the easily proved formulas 
(13) 
(b -
a) + (d -
c) = (b + d) -
(a + c), 
(14) 
(b -
a) -
(d -
c) = (b -
a) + (c -
d) = (b + c) -
(a + d), 
• In mI, §2.3, the equation (9) is taken as the definition of -a and (10) as the definition 
of b -
a, and equation ill, which is here taken as the definition of b -
a (=x), is 
proved there as a theorem. The present equation (11) is proved there as equation (36). 

5 Rings and Ideals 
321 
which contain the usual ruIes for a change of sign under the removal of 
parentheses; since these rules are logical consequences of the postuIates 
(I) through (III), they are valid in every ring. 7 Furthermore, if we muItiply 
the equation 
e + (b -
e) = b 
on both sides by a and apply the distributive law (IV), we have 
ae + a( b -
e) = ab, 
from which by subtraction we obtain the following complement to (IV): 
(15) 
a(b -
e) = ab -
ae; 
finally, by repeated application of this formula 
(15') 
(b -
a)(d -
e) = (ae + bd) -
(ad + be). 
1.6. 
Unity Element 
An element e of the ring ffi, satisfying the relation 
(16) 
ea = ae = a 
for every element a E ffi, is called a unity element (or a unit element, or an 
identity). In particular, 
e2 = ee = e. 
Not every ring contains a unity element; e.g., the ring of even integers 
0, ±2, ±4, ... satisfies all the postulates for a ring but contains no unity 
element. But if a ring does contain a unity element, it cannot contain 
more than one; for if e' were a second unity element, then by (16) we wouId 
have ee' = e and also ee' = e', so that e = e'. In most cases we shall 
denote the unity element by the usual symbol 1. 
1.7. 
Divisors of Zero 
If 0 denotes the (always present) zero element of the ring ffi, we have 
(17) 
oa = ao = 0 
for every element a E ffi, as follows immediately from (7) and (15). But in 
7 In lBI, §2.1, the equation (13) for the natural numbers Q, b, c, d occurs in the defini-
tion of addition of integers in the form (26), and (12b) occurs in the form (24) in the 
definition of equality of integers; in the present context we are chiefly interested in 
showing that these rules can be deduced from the axioms for a ring. 

3n 
PART B ARITHMETIC AND ALGEBRA 
certain rings it can happen that a product is equal to zero even though 
neither factor is zero: 
ab = 0, 
with 
a -=I=- 0 
and b -=I=- o. 
In this case the two elements a, b are called divisors of zero. 
Examples of rings with divisors of zero are provided by the residue class 
rings Gin, with composite n (cf. §3.7 and IB6, §4.1). Another example is the 
set of two-rowed matrices (lB3, §2.2): 
with 
a,bEG. 
By the rules for calculation with matrices, these matrices form a commutative 
ring whose zero element is the zero matrix 
and whose unity element is the unit matrix 
(1 0) 
o l' 
This ring contains divisors of zero, e.g., the two matrices 
and 
whose product is the zero matrix. 
1.8. 
A subset 6 of a ring m that is closed with respect to addition, 
subtraction, and multiplication satisfies all the ring postulates as a part of 
m and is thus called a subring of m; e.g., the set of all integers divisible by 
by 3, 0, ±3, ±6, ... , forms a subring of the ring G of all the rational 
integers. 
As the following example shows, it can happen that the unity element of the 
subring 6 is different from that of 9t Let 9t be the ring of all two-rowed diagonal 
matrices (~~) with Q, bEG, and let 6 consist of all such matrices with b = O. 
The unity element of 9t is (~ ~), and that of 6 is (~~). Like G, the subring 6 
has no divisors of zero, but 9t does have such divisors. 
1.9. 
Integral Domains 
The feature of greatest importance for the structure of a ring is the 
presence or absence of divisors of zero; in order to emphasize this feature 
with a special name, (commutative) rings without divisors of zero are 

5 Rings and 'dea's 
323 
also called integral domains8 (or domains of integrity). Most of the rings 
in the present chapter have no divisors of zero and are therefore integral 
domains, e.g., all the polynomial rings G[x], G[x, y], G[x, y, z], ... (cf. 
IB4, §2). 
In an integral domain we may cancel any nonzero factor that appears 
on both sides of an equation; that is, we have the second rule of cancellation: 
(18) 
ab = ac 
and a -=I=- 0 
imply b = c.D 
The above rule can also be stated: An integral domain ,3 is a ring in which 
the solution of an equation 
(19) 
ax = b, 
a, b E,3, 
a =1= 0, 
is unique, provided it exists at all. For if there were two distinct solutions 
Xl and XI, we would have aXI = aXI = b, so that a(xi -
x.J = 0, which 
would imply the existence of two divisors of zero a =1= ° and Xl -
XI =1= 0. 
On the other hand, if a ring has divisors of zero: ab = 0, a =1= 0, b =1= 0, then 
ax = a(x + b) for every element x. 
1.10. Fields 
It may happen that in the given ring ~ every equation (19) is uniquely 
solvable' without exception; such a ring is called afield (see also IBl, §3.2). 
In a field, division (with the exception of division by zero) is unique and 
always possible. In other words, we may define a field as a set of elements 
in which besides the above listed postulates for a ring (1.2), the following 
postulate holds: 
Postulate for a field: In a field R every equation ax = b with a -=I=- 0 10 but 
with otherwise arbitrary elements a, b E R has a uniquely determined 
solution. 
It follows that every field isfree of divisors of zero and has a unity element. 
The freedom from divisors of zero is proved in exactly the same way as 
for integral domains (§1.9), and the existence of a unity element follows 
from the solvability of the equation 
ax = a. 
For if x = e is a solution for some definite element a -=I=- 0, so that ae = a, 
and if b is any other element of the field, then by the postulate for a field 
there exists an element c satisfying the equation ca = b. If we multiply 
8 In analysis they are usually called integral rings, since the word "domain" could 
easily lead to ambiguity. 
9 Since a(b -
c) = 0 and a is neither zero nor a divisor of zero, it follows that 
b - c = 0, so that b = C. 
10 If a = 0, it follows from (17) that b = 0, and then every element x is a solution of 
the equation ax = b. 

324 
PART B ARITHMETIC AND ALGEBRA 
by c on both sides of the equation ae = a, we obtain be = b, for every 
element b E R; in other words e is the unity element (1.6). 
By postulates (lb), (lIb) and the field postulate, the elements of a field, 
excluding the zero element, form an Abelian group with respect to 
multiplication; this group is called the multiplicative group of the field 
(for the concept of a group see IB2). Conversely, the field postulate is a 
consequence of this property. Thus we have the following important 
resu1t:ll Every integral domain with finitely many elements is a field; for 
example, every residue class ring G/p modulo a prime (p) is a field (lB6, 
§4.3). 
For the proof let Xl, X2 , ... , Xn be the finitely many elements of the 
integral domain 3 and multiply them one after another by the element 
a(a -=I=- 0). By the rule of cancellation (18), the products aXI , aX2 , ... , aXn 
are distinct and therefore represent all the elements of 3, including the 
element b; thus we have a solution for the equation ax = b. 
If we do not postulate the commutativity of multiplication, then in order 
to obtain the analogue of a field, we must postulate that every equation ax = b 
and also every equation ya = b is solvable, provided only a =1= o. (It is sufficient 
to postulate the existence of the solutions, since their uniqueness can then be 
proved.) The resulting system of elements is called a skew field. From the 
postulates it follows again that the elements of a skew field, excluding the 
zero element, form a group; so that the existence of an identity element and 
inverse elements a-I, the absence of divisors of zero in a skew field, and the 
uniqueness of the postulated solutions can then be proved exactly as in group 
theory (IB2, §2.4). We can also show that every finite skew field (Le., every 
skew field containing only finitely many elements) is necessarily commutative 
and is therefore a field. 
1.11. 
Prime Fields and the Characteristic of a Field 
The simplest and best known field is the field R of all rational numbers 
(lBI, §3.2). Next in simplicity are the above-mentioned residue class rings 
G/p, i.e., fields with finitely many (namely p) elements. Since these fields 
contain no proper subfields, we call them prime fields. The residue class 
rings are prime fields "of characteristic p" (§3.7), and the field R of rational 
numbers is a prime field of "characteristic 0." 
We already know that every field R contains both a zero element 0 and 
a unity element e; but then R also contains the element e + e, e + e + e, 
and so forth, which we abbreviate to 2e, 3e ... (ne is the sum of n summands 
e). Now it may happen that these elements are not all distinct but that 
some of the me being the same as some earlier ne: 
ne = me, 
so that (n -
m) e = o. 
11 Cf. IB2, §2.4, where it is proved that a finite set with an associative operation (V), 
(A) and rules for cancellation (Kr), (K,) is a group. 

5 
Rings and Ideals 
325 
Then if p is the smallest natural number for which pe = 0, it follows that 
p must be prime12 and the elements 0, e, 2e, ... , (p -
l)e are distinct. In 
this case we say that the field R has "characteristic p"; and otherwise, if 
all the elements e, 2e, ... , ne, ... are distinct, we assign to R the 
"characteristic 0." 
The characteristic of an integral domain .3 with unity element e is defined 
in exactly the same way. 
It can be shown that every field R which is not a prime field contains as 
its smallest subfield a prime field of the above type with the same 
characteristic as R. 
1.12 
Quotient Fields 
For every integral domain .3 that is not a field we can construct a field, 
the quotient field, that contains 3 and is constructed from 3 in exactly the 
same way as the field R of rational numbers is constructed from the integral 
domain G of rational integers IB1, §3.2). We first construct the set of all 
formal fractions alb, where a, b are arbitrary elements of 3 with b -=I=- o. 
In this set of fractions we introduce a partition into classes by means of the 
equality: 
alb = cld 
if and only if ad = bc. 
An element a in 3 is identified with the class of fractions ablb. Computation 
with these fractions follows the well-known rules. The proof of these 
statements is to be found in IB1, §3.1-3.2; the argument given there, as 
was remarked at that time, can be transferred verbatim to the present case, 
since the only necessary postulate is that the domain 3 be a commutative 
ring without divisors of zero, i.e., an integral domain. 
The domain R constructed in this way is a field, the quotient field 13 of 3; 
this field contains .3 as a subdomain, and the results of any computation 
in 3 remain valid for R. 
The most important quotient fields are the field R of rational numbers, 
as quotient field of the integral domain G of rational integers, and the 
field R(x) of all polynomial quotients in one indeterminate x with rational 
coefficients. The field R(x) is a quotient field not only of G[x] but also of 
R[x]. 
12 For if p were 6, say, there would be divisors of zero, since we would then have 
(2e)(3e) = (e + e)(e + e + e) = 6e = 0, 
and the minimal property of p would mean that 2e =1= 0, 3e =1= o. 
13 Two different integral domains may belong to the same (or isomorphic) quotient 
fields; e.g., the rational field R can also be obtained as the quotient field of the integral 
domain of all even numbers. 

326 
PART B ARITHMETIC AND ALGEBRA 
1.13. 
Isomorphism 
The concepts of isomorphism and homomorphism are defined (see also 
IB1, §2.4) for rings in the same way as for groups (182, §4.2 and §10.1). 
Two rings m and m * are said to be isomorphic, in symbols m H m *, if 
the elements a, b, c, ... of m are in one-to-one correspondence with the 
elements a*, b*, c*, ... of m*: 
a~a*, 
c~c* 
in such a way that this correspondence is consistent with addition and 
multiplication; i.e., if for all a, b we have 
a + b~a* + b*, 
ab~a*b*. 
Since the postulates (§1.2) are satisfied in both rings, it follows that the 
correspondence is also consistent for subtraction and for more complicated 
expressions, e.g., 
a -
b~a* -
b*, 
a(b + c) ~ a*(b* + c*), 
etc. 
Thus, the zero element 0 of m corresponds to the zero element 0* of 
m *, the inverse element -a corresponds to the inverse element -a*, 
a divisor of zero in m corresponds to a divisor of zero in m*, the unity 
element of m (if its exists) corresponds to the unity element of m *. If m 
contains a unity element, m * also necessarily contains one, and if m 
contains divisors of zero, then so does m *; if m is an integral domain 
or a field, then so is m *, and conversely. 
If m1 is a subring (that is, a subset closed with respect to addition and 
multiplication; see also 184, §2.1) of m, then the corresponding elements 
in m* form a subring mt isomorphic to m1 : m1 H mt. 
Isomorphism between rings is an equivalence relation (cf. lA, §8.5 and 
IB 1, §2.2); every ring is trivially isomorphic to itself, and if two rings are 
isomorphic to a third, then they are isomorphic to each other. As far 
as their algebraic structure as rings is concerned, two isomorphic rings can 
differ only in the notation, so that we can identify them by disregarding 
all the properties of their elements that do not affect their structure as 
rings.14 
If the rings m and m * contain a common subring mo , then m is said 
to be "isomorphic to m * with respect to mo" if every element of the 
subring mo corresponds to itself. 
If the mapping of the ring m onto the ring m* is (possibly) many-to-one, 
so that each of the elements a, b, ... of m has a unique image a*, b*, ... 
in m*: 
a---+a*, 
b---+b*, ... , 
l40 In the example of §1.8 the two rings 6 and G are isomorphic. 

5 Rings and Ideals 
327 
and if every element d* in 9l* has at least one (and perhaps more than one) 
preimage d in 9l: d -+ d*, and if further the mapping is consistent with 
the operations of addition and multiplication: 
a + b -+ a* + b*, 
ab -+ a*b*, 
then 9l * is said to be a homomorphic image of 9l, or in symbols 9l ~ 9l * 
(cf. §3.6). 
2. 
Divisibility in Integral Domains 
2.1 
In the present section we consider integral domains .3 with a unity 
element I; in particular, the integral domain G of all rational integers, 
the polynomial rings G[x] and R[x] of all polynomials in x with 
coefficients in G or R, and the field of rational numbers (lB4, §2). In an 
integral domain 3 the field postulate (§1.10) is not satisfied, in general; 
i.e., the equation ax = b for given a, b generally has solution in 3; but 
in the special cases in which this equation does have a solutionIS we say 
that b is divisible by a and write 
(19') 
alb, 
or: "a divides b." 
We also say that a is a divisor, or a factor, of b. 
The relation of divisibility is transitive; i.e., from (19') and blc it 
follows that alc. For by hypothesis there exist in 3 elements x and y 
such that 
ax =b 
and by = c, 
but then z = xy is a solution of the equation az = c, so that alc. 
Since la = a, every element a in 3 has the so-called "trivial" divisors 
1 and a.16 
2.2. 
Units 
In the theory of divisibility in an integral domain 3 an important role is 
played by the so-called units, defined as divisors of the unity element; for 
example, the elements el and e2 are units if 
(20) 
In G, and also in G[x], the only units are 1 and -I; in R[x] on the other 
hand, every polynomial of zero degree, i.e., all the rational numbers, are 
III If the solution exists, it is unique (§1.9). By (17) every element a E .3 is a divisor of 
the zero element: a I o. But by a "divisor of zero" we mean only the elements defined 
in §1.7. Divisors of zero do not occur in integral domains. 
16 Concerning the properties of divisibility in an integral domain compare the 
discussion in IB6, § 1. 

328 
PART B ARITHMETIC AND ALGEBRA 
units.17 In the integral domain G[i] of the Gaussian numbers there are 
four units: 1, -1, i, -i, and similar remarks hold for other rings of 
algebraic numbers (IB6, §S). 
Thus the units are characterized by the property that they have a 
reciprocal element in 3; for it follows from (20), in the usual notation, that 
1 
e-l = -
= e E 3 
I 
el 
2 
and conversely. The product of two or more units is again a unit; for it 
follows from (20) and ese. = 1 that (e1eS)(e2e.) = 1, so that e1eS and e2e. 
are also units. Thus the units of an integral domain form an Abelian group 
(IB2, §l.I) with respect to multiplication. 
Two elements a and a' = ae of an integral domain 3 are called 
associatesl8 if each is the product of the other by a unit of 3. Associate 
elements a, a' are characterized by the divisibility relations 
(21) 
ala' 
and a'la, 
the secOlid of which follows from a' e-l = a. Thus each of two associates is 
divisible by the other, and conversely. For by (21) there exist two elements 
x, y in 3 such that 
ax = a' 
and a'y = a, 
from which we have a(xy) = a, and by the rule (IS) of cancellation 
xy = 1; thus x and y = X-I are units, so that a and a' are associates, 
as was to be proved. 
Every element a-=/=-O in 3 has as its trivial factors all the units and all 
its associates; by a proper factor of a we mean a factor which is not an 
associate of a.19 
2.3. Irreducible and Prime Elements 
An element a(-=/=-O) in 3 irreducible if it has only trivial factors, i.e., if a 
factorization a = bc into two factors is possible only when one of the 
factors is a unit and the other is an associate of a. Otherwise a is said to be 
reducible. 
Examples of irreducible elements are: all the prime numbers in G, and 
all the irreducible polynomials in G[x]. But we must not confuse 
"irreducible" with "prime," even though in certain integral domains, 
17 In a field every element is divisible by every other element (except 0). Since this 
statement is true in particular for 1, every nonzero element of a field is a unit. 
18 In particular, every element a is an associate of itself. 
19 It is convenient to include the units among the proper factors. 

5 Rings and Ideals 
329 
including the most important ones (namely G, G[x], and R[x]) , every 
irreducible element is prime and conversely, as will be proved below. 
An element p in 3 is said to be prime if plab implies at least one of the 
two relations pia, plb;20 i.e., a product is divisible by a prime element p 
if and only if at least one of its factors is divisible by p. 21 We now prove the 
following theorem. 
2.4. 
Every prime element is irreducible, but the converse is 
not necessarily true. 
For let p = ab be a factorization of the prime element p, so that p lab; 
then one of the factors, say a, must be divisible by p. Writing a = pc, 
we obtain p = pbc, or 1 = bc, by cancellation (18). Therefore b is a unit 
and a is an associate of p, so that p = ab is a trivial factorization of p. 
Thus p has no nontrivial factorization, which means that p is irreducible. 
On the other hand, it may happen in certain integral domains that an element 
is irreducible but not prime. For example, in the integral domain G[v'-~3] of 
all numbers a + b v' -3 with a, b E G22 the number 2 is irreducible, because 
the Diophantine equation (IB6, §7) 
2 = (a + b v' -3)(a - b v' -3) = a2 + 3b2 
clearly has no solution in integers. 
On the other hand, the number 2 is not prime in G[v' - 3], since the product 
is divisible by 2, although neither of the factors 1 + v' - 3 and 1 -
v' - 3 has 
this property. 
However, we shall prove below that in the integral domains of greatest 
importance to us, in particular in G, G[x] and R[x], every irreducible 
element is also prime, so that in these domains the two concepts may be 
identified. 
20 In the language of the theory of ideals (§3) we may say: an element p is prime if 
the ideal (p) generated by p is a prime ideal (§3.6). 
21 The zero element of an integral domain .3 is not regarded as a prime element 
although, formally speaking, it is both irreducible and prime. 
22 We can construct a simpler example in an integral domain without unity element. 
For example, let G2 be the integral domain of all even numbers; then the number 30 is 
irreducible, because every product of two even numbers is divisible by 4. On the other 
hand, 30 is not prime in G2 , since the product 6 . 10 = 60 is divisible by 30, although 
neither factor has this property. 

330 
PART B ARITHMETIC AND ALGEBRA 
2.5. 
Divisor Chain Theorem 
This important theorem, valid for all the integral domains considered 
here, will be needed in several places below. It states that a proper divisor 
chain 
(22) 
(ai '* 0, ai+l I ai, i = 1, 2, ... ), 
i.e., a sequence of elements ai in the given integral domain such that each 
ai is a proper divisor of its predecessor ai-I, contains23 only finitely many 
terms. 
The divisor chain condition holds in G, because the sequence of absolute 
values I a1 I, I a2 I, .. ' corresponding to a divisor chain (22) consists of 
monotonically decreasing natural numbers, so that the smallest number 1 
must be reached after a finite number of steps. 
The same result can be proved for a divisor chain (22) in the polynomial 
ring R[x] by considering, instead of the absolute value, the degree of the 
successive polynomials in x. To prove the result for G[x], we may consider 
the sum of the degree of the polynomial and the absolute value of its first 
coefficient. 24 
If the divisor chain condition holds in an integral domain ~, every 
element a('* 0) in ~ can be written in at least one way as the product of 
(finitely many) irreducible elements Ui : 
(23) 
For if a = U is irreducible, we already have a representation (23) with 
s = 1; but if a is reducible, we can split up each factor into irreducible 
terms, which must be reached after finitely many steps, since otherwise 
we would have a nonterminating proper divisor chain, in contradiction to 
the hypothesis. 
In general, the representation (23) is not unique, even apart from associate 
elements and the order of the factors. For example, in G[V -3] (see also §2.4) 
the number 4 can be represented in two essentially different ways as the product 
of irreducible numbers (in G[V -3]): 
4 = 2 . 2 = (1 + V -3)(1 - V -3). 
23 Thus G contains, among others. the following divisor chains beginning with 100: 
100, 50, 10,2, 1 and 100,20,4, 2, 1. 
2' It is not easy to construct examples of integral domains without the divisor chain 
condition; one example is the integral domain of all algebraic integers, containing the 
infinite proper divisor chain: 
'\12, {f2, {f2, ... , \/2, .... 

5 Rings and Ideals 
331 
But if in a given integral domain ~ every representation (23) is unique in the 
above sense, then every irreducible element in ~ is prime, so that the concepts 
"irreducible" and "prime" coincide. For if ~ were to contain an irreducible 
element u that is not prime (§2.3), we could find an equation ua = bc with 
elements a, b, c in ~ such that u is not a divisor of b nor of c. But now we could 
derive a contradiction by splitting up the elements a, b, c into their irreducible 
factors and noting that both sides of the equation must yield the same factoriza-
tion, for then the irreducible element u must be an associate of an irreducible 
factor in the right-hand side, arising either from b or from c. 
2.6. 
Unique Factorization (u.f) Rings 
Of great importance are the integral domains ~ in which every 
factorization (23) is unique. Such rings are called u.f rings; in them we 
have the u.f theorem (unique factorization theorem):25 Every element 
a( *0) of a u. f. ring ~ can be expressed uniquely as the product of prime 
elements Pi :26 
(24) 
a = PIP2 ... Ps, 
where uniqueness means that the prime elements Pi in (24) are uniquely 
determined up to order and unit factors. 
We now prove the theorem: an integral domain ~ with unity element 
satisfying the divisor chain condition and the condition that every irreducible 
element is prime is a u.f ring. 
Since the existence of at least one factorization (24) has just been shown 
to follow from the divisor chain condition, only the uniqueness remains 
to be proved. Let us assume that 
(24') 
is a second factorization with prime elements qi; since the product 
qIq2 .,. qt is divisible by the prime element PI , at least one factor must be 
divisible by PI . We may assume that the order of factors in (24') is such 
that PI I qi ; since qi is also prime, it follows that PI and qi are associates: 
qi = epi with a suitably chosen unit e. By setting (24) and (24') equal to 
each other and cancelling withpi we obtain the result: P2Pa ... P s = eq2qa .... qt. 
Proceeding in this way we find successively that q2 is an associate of 
P2 , qa of Pa , ... , qs of Ps , and also that t = s, which completes the proof. 
In the quotient field of a u.f. ring, every fraction alb can be written "in 
lowest terms," i.e., in such a way that the numerator and the denominator 
have no prime factor in common; the reduction to lowest terms is 
211 If the factorization (23) is unique every irreducible element is also prime, as has 
just been shown, so that here the two concepts coincide. 
26 Of course, two or more of the prime factors PI may be equal. 

332 
PART B ARITHMETIC AND ALGEBRA 
essentially unique, since it can be altered only by the adjunction of the 
same unit factor to numerator and denominator: alb = ealeb. 
2.7. 
Let a, b be two arbitrary elements in the integral domain 3. 
An element dE 3 which is a divisor of a and also of b is called a common 
divisor of a, b. We say that a, b are coprime if they have only the units 
as common divisors. 
An element d is called the greatest common divisor of a, b, or in symbols 
(25) 
GCD(a, b) = d, 
if d is a common divisor of a, b and every other common divisor d' of 
a, b is a divisor of d: d'id. The GCD(a, b, c, ... , d) of the elements 
a, b, c, ... , d is defined analogously. 
It is obvious that if the greatest common divisor of two or more elements 
exists, it is determined only up to a unit factor. 
2.8. 
Euclidean Rings 
In a u.f. ring it is easy (cf. IB6, §2.6) to read off the GCD(a, b) from the 
"canonical factorization" (24) of a and b; but often these factorizations 
are not immediately known, and generally it is a very time-consuming 
task to determine them. Thus it is advantageous to have another procedure 
for finding the GCD, namely, the Euclidean algorithm, which can be 
carried out in certain rings, the so-called Euclidean rings, and leads very 
quickly to the GCD(a, b). Let us now discuss these concepts. 
An integral domain 327 is called a Euclidean ring if the division algorithm 
is available, i.e., if to every element a(::j:: 0) in 3 it is possible to assign 
a nonnegative integer H(a) such that 
(26') 
H(ab) ~ H(a) 
for all 
a, b(::j:: 0) in 3 
and for any two given elements a, b(::j:: 0) in 3 we can find elements q and r 
in 3 such that 
(26") 
a = bq + r with 
H(b) > H(r) or r = O. 
The integral domains G and R[x] are Euclidean rings, since in G the 
correspondence H(a) = I a I, and in R[x] the correspondence H(a) = "the 
degree of the polynomial a," satisfy the conditions (26') and (26") (see 
IB6, §2.10); and for the same reason every polynomial ring 5l[x] over a 
field 5l of coefficients is a Euclidean ring.28 
27 We need not assume the existence of a unity element in ,3, because its existence, as 
we shall show in §2.1 0, follows from (26') and (26
H ). 
28 Certain rings of algebraic numbers, e.g., the rings G[iJ, G[V -2J, G[{J with 
, = (-1 + V -3)/2, are Euclidean (see IB6, §2.10). 

5 Rings and Ideals 
333 
2.9. 
In a Euclidean ring it is possible to carry out the Euclidean algorithm, 
which consists of a certain repetition of the division algorithm (26"). 
Applied to two elements a, be::/=- 0) of a Euclidean ring .3 this algorithm 
leads, as will be shown in detail in 186, §2.1 0, to the result: 
(I) 
The last nonzero remainder is the GCD(a, b); 
(II) There exist in.3 two (coprime) elements x, y satisfying the equation 
(27) 
ax + by = GCD (a, b).29 
In particular, if the elements a, b are coprime, then GCD (a, b) = 1, 
and there exist two elements x, y E.3 satisfying the equation 
(28) 
ax + by = I; 
conversely, it follows from such an equation that a, b are coprime. The 
elements x, y can be calculated by the Euclidean algorithm, and every 
pair of the form 
x' = x + bc, 
y' = y -
ac 
with arbitrary c E .3 is then a solution of (27) or (28). 
2.10 (I) Every Euclidean ring contains a unity element. 
(II) In a Euclidean ring the divisor chain condition (§2.5) is satisfied. 
(III) In a Euclidean ring irreducible elements and prime elements coincide 
(§2.3). 
Finally, it follows (§2.6) that every Euclidean ring is a u.f. ring.30 
Proof of (I). Let a(::j::. 0) be an element of the Euclidean ring .3 (§2.8) 
for which H(a) has the smallest possible value, and let b E.3 be arbitrary. 
Then the division algorithm (26") applied to the pair b, a gives: 
b = aq + r; 
but here we must have r = 0, since otherwise H(r) < H(a), contrary to 
assumption. Thus b = aq; that is, every element b E.3 is divisible by 
a. In particular, for b = a we have the equation a = ae or, after multi-
plication by q, also b = be, so that e is the unity element in .3 (§1.6). 
Proof of (II). The fact that ~ cannot contain a proper divisor chain 
(§2.5) with infinitely many terms follows immediately from the lemma: 
if b is a proper divisor of a, then H(b) < H(a). 
29 If we expand alb in a regular continued fraction (IB6, §3.1), the numerator and the 
denominator of the second-to-Iast approximating fraction, taken with suitable signs, 
form a solution y, x of equation (27). 
80 This theorem is also a consequence of the idealtheorett'e theorems §3.3 and 3.4. 

334 
PART B ARITHMETIC AND ALGEBRA 
To prove the lemma, let a = bc and let the division algorithm (26"), 
when applied to b, a, give 
b = aq + r, 
where we must have r -=I=- 0, since otherwise a and b would be divisible 
by each other and would therefore be associates, contrary to assumption. 
Thus H(r) < H(a); on the other hand, it follows from 
r = b -
aq = b (l -
cq) 
and from 
I -
cq -=I=- 0 (since by assumption c is not a unit) 
that H(b) ~ H(r), by (26') and therefore H(b) < H(a), as was to be 
proved. 
Proof of (II I). Now letp denote an irreducible element of.3 and assume 
that the product ab is divisible by p, so that pq = abo If pia, then the 
criterion in §2.3 for p to be a prime is already satisfied; thus we assume 
that a is not divisible by p and then prove that we must have p I b. But 
p, a are now coprime, since the irreducible element p has only associates 
and units as its divisors, and therefore by (28) there exist elements x, y in 
.3 such that 
px + ay = I. 
If we multiply this equation by b and the equation 
pq -
ab = 0 
by y and add, we obtainp(bx + qy) = b, so thatp I b, as was to be proved. 
Since the important integral domains G and R[x] have already been 
proved to be Euclidean rings (§2.8),it now follows that they are also u.f 
rings. The same result follows for all polynomial rings 5l[x] over afield 5l of 
coefficients. 
But the converse is not true, since there exist u.f. rings that are not Euclidean. 
An example is the ring G[x] of all integral polynomials in x which, as we shall 
prove in §2.14, is a u.f. ring but is not Euclidean, for if it were, we -could apply 
the Euclidean algorithm to the coprime elements x and 2 and obtain an 
equation (28): 
xh(x) + 2k(x) = 1 
with 
hex), k(x) E G[x], 
which leads to a contradiction, as is clear at once if we set x = O. 
2.11. 
The Polynomial Ring 3 [x] 
Let us now discuss, somewhat more generally, the polynomial ring 3[x] 
consisting of all the polynomials 
(29) 

5 
Rings and Ideals 
335 
of degree n = 0, I, 2, ... , with coefficients ai E 3,31 where we shall assume 
that ~ is a u.f. ring. For example, G[x] is a polynomial ring of this kind. 
Since ~ is a u.f. ring, the greatest common divisor 
(30) 
GCD(ao , a1 , ... , tln) = d 
is uniquely determined up to a unit. To determine its value we carry out 
the canonical factorization (24) of the coefficients ai in the usual way and 
selec t all the common prime factors. If we then set 
,. = 0, 1, ... , n, 
we have 
(31) f(x) = df*(x) 
with f*(x) = a: + aix + a:x2 + ... + a:xn 
and 
(31') 
A polynomial in 3[x] whose coefficients, like those of f*(x), have no 
common factors except the units is said to be primitive. Thus we have the 
result that every polynomialf(x) in 3[x] can be written uniquely (apart from 
units) as the product (31) of the GCD of its coefficients (30) and a primitive 
polynomial f* (x). 32 
Along with 3[x] we now consider the polynomial ring 5l[x] over the 
quotient field (cf. § 1.12 and §2.6) 5l of the u.f. ring 3. By the analogous 
argument we see that every polynomialf(x) in 5l[x] can be written uniquely 
(apart from units) as the product 
(32) 
a 
f(x) = b f*(x), 
where a, b are coprime elements of 3 and f*(x) is a primitive polynomial in 
3[x]. 
31 For degree 0 we thus obtain all the elements of ,3, so that ,3 is a subring of ,3[x). 
Under our present convention the zero element of the ring ,3, like every other element 
in the same ring, has the degree O. In certain other contexts, which we shall not discuss 
here, it is convenient to leave the degree of the zero element undetermined. If we wish 
to preserve the formula 
degree f(x) . g(x) = degree f(x) + degree g(x) 
for identically vanishing factors, we may set degree 0 = 
-
00 (cf., p. 361, ftn. 7). 
32 If n = 0, we setf*(x) = 1. 

336 
PART B ARITHMETIC AND ALGEBRA 
2.12. 
Theorem of Gauss for Primitive Polynomials 
The product of two primitive polynomials is again a primitive polynomial. 
For if the polynomial f(x) in (29) is primitive, and if g(x) is another 
primitive polynomial 
g(x) = bo + b1x + b2x2 + ... + bmxm, 
then their product is a polynomial 
h(x) = f(x) g(x) = Co + c1x + C2X2 + ... + cn+mxn+m 
with coefficients formed as follows:33 
Co = aobo , 
Cl = aObl + a1bo , 
Now let it be assumed that 'T1' is a prime divisor of all the coefficients 
Co, C1 , ••• , cn+m ; then since the polynomials f(x) and g(x) are both 
primitive, there exist indices j and k(O ~ j ~ n, 0 ~ k ~ m) such that 'T1' 
is not a divisor of a; or bk but is a divisor of all the preceding ao , •.• , a;-l 
and bo , ... , bk - 1 • Then, in contradiction to our assumption, the coefficient 
C;+k = aOb;+k + a1b;+k-l + ... + a;bk + '" + a;+k-lbl + a;+kbO , 
is certainly not divisible by 'T1', since all the terms in this sum are divisible 
by 'T1', with the single exception of the term a;bk • Thus h(x) is primitive. 
2.13. 
The Polynomial Ring 3[x] Satisfies the Divisor Chain Condition(§2.5) 
For if an elementf(x) = df*(x) written in the form (31) has a proper 
divisor g(x) = bg*(x), then b I dandg*(x) If*(x), where the polynomials 
g* (x) and f* (x) are primitive and at least one of the divisions is proper. 
But the element d of the u.f. ring 3 has only finitely many divisors b, and 
the proper divisor g*(x) must be of lower degree thanf*(x). Thus every 
proper divisor chain (22) in 3[x] is finite. 
2.14. 
A polynomial ring 3[x] is a u.f ring if and only if the domain of 
coefficients 3 is a u.f ring. In particular, G[x] is a u.f ring.34 
The condition is obviously necessary; in order to show that it is also 
sufficient, we need only prove, in view of §2.6 and §2.13, that every irredu-
cible element in 3[x] is prime. Now an irreducible element in 3[x] is 
88 In order to avoid a troublesome listing of various cases, we shall assume that 
all al with index j > n and all bk with index k > m are set equal to zero. 
8' Note that G[x] is not a Euclidean ring (§2.1O). 

5 Rings and Ideals 
337 
either independent of x (i.e., the representation (29) has the degree n = 0), 
when it is an irreducible and therefore prime element 'T1' of the u.f. ring 3, 
or else it is an irreducible and therefore primitive polynomial p*(x). 
In the first case, if the productf(x) g(x) of two polynomials in 3[x] is 
divisible by 'T1', i.e., if in the notation of §2.13 
'T1' If(x) g(x) 
or also 
'T1' I bdJ*(x) g*(x), 
it follows that 'T1'lbd. But 'T1' is prime in ~, so that one of the two factors 
b, d, say d, is divisible by 'T1': 'T1' I d I f(x). Thus 'T1' is also prime in ~[x]. 
In the second case it follows from 
p*(x) \ f(x) g(x) 
or p*(x) \ bdJ*(x)g*(x), 
in view of the fact that p*(x) and also the product f*(x) g*(x) are 
primitive (§2.12), that 
p*(x) \J*(x) g*(x). 
If we examine these divisibility relations (see §2.11) in 5l[x], which is a 
u.f. ring (§2.10), we see that one of the two factors, say f*(x), is divisible 
by the prime element35 p*(x): 
f*(x) = p*(x) h(x) 
with h(x) E 5l[x]. 
By §2.11 we can write h(x) = alb h*(x), with h*(x) primitive in 3[x], 
so that the above equation, after multiplication by b, gives: 
bJ*(x) = ap * (x) h*(x); 
thus we see from the theorem of Gauss (§2.12) that a = eb and 
f*(x) = ep*(x) h*(x), where e is a unit, so thatf(x) = dJ*(x) is in fact 
divisible by p*(x) with a quotient in 3[x], as was to be proved. 
A slight generalization of this theorem leads to the result: not only the 
polynomial rings R[x] and G[x] in one indeterminate, but also the rings 
8li The polynomial p*(x) is prime, since it too is irreducible in Sl[x]. For if p*(x) were 
reducible in Sl[x]: 
with a, b, c, dE.3 and primitive polynomials pi(x), p:(x) in .3[x] of degree less than 
the degree of p*(x), we would have 
bdp*(x) = acpi'(x) p:(x); 
but then by the theorem of Gauss (§2.12) we could write ac = ebd with a unit e E.3 
and p*(x) = ePi(x) p:(x), in contradiction to the assumed irreducibility of p*(x) in 
3[x]. 

338 
PART B ARITHMETIC AND ALGEBRA 
R[x, y], G[X, y], R[x, y, Z], G[X, y, z] ... in several indeterminates are u.f 
rings. The same result holds for all polynomial rings ~[x, y], ~[x, y, z] ... , 
provided ~ is a u.fring. The proof follows at once from the remark that the 
polynomial ring 3[x, y] can also be regarded as a polynomial 3*[y] if we 
set 3* = 3[x]. But 3* is a u.f. ring, so that 3*[y] = 3[x, y] is also such 
a ring, and so forth. 
3. 
Ideals in Commutative Rings, Principal Ideal Rings, 
Residue Class Rings 
3.1. 
In IB2, §3 we saw that the inner structure of a group can best be 
determined by a study of its subgroups, particularly of its invariant 
subgroups; thus it is natural, in investigating the inner structure36 of a ring 
m, to examine its subrings. Here also subrings of a certain type will be 
distinguished, namely the ideals. 
Definition of an ideal. 
A non-empty subset a of a ring m is called an 
"ideal" if it has the following properties: 
(I) the module property 
(33) 
a, b E a 
implies a - b E a; 
(II) the ideal property 
(34) 
aEa 
and rEm 
imply ra Ea. 
The module property (I) implies that every ideal of a ring is a subgroup 
of the additive group of the ring (§1.4). To see this, we note that every 
ideal a contains the zero element a -
a = 0 and thus by (33) contains 
the inverse -a = 0 -
a of every element a in the ideal. But then, from 
a - (-b) = a + b it follows37 by (33) that 
(33') 
a, bE a 
implies 
a + bE a. 
Similarly the ideal property (II) implies that a is a subring of m; that is, 
a is closed not only with respect to addition (33') and subtraction (33), 
but also under multiplication; for from a, b E a it follows by (34) that 
ab E a. But (34) makes a stronger demand, namely that the product ab 
shall still lie in a even though only one of the two factors lies in a. Our 
reason for confining attention to the subrings distinguished in this way will 
become clear in our discussion of congruences and residue class rings (§3.6). 
The zero element by itself forms an ideal, the zero ideal, denoted by 
(0); in the same way the ring m is itself an ideal, the unit ideal. These two 
36 By the inner structure of a ring we chiefly mean the divisibility relations in the ring. 
37 Thus we can derive (33') from (33), but not conversely. 

5 Rings and Ideals 
339 
ideals occur in every ring, and in a field they are the only ideals; for in a 
field 5l any ideal a containing a nonzero element must contain all 
the elements of 5l, by the field postulate (§ 1.1 0) and the ideal property (34). 
From (33') and (34) we can now derive the following important property 
of an ideal a in a ring m: 
(35) 
a, bE a 
and r, s E m 
imply ra + sb E a. 
3.2. 
More generally we can say: If an ideal a contains the elements 
a1 , a2 , ... , as, then it contains all the linear combinations 
(36) 
with r1 , r2 , ... , r s E m. 
Conversely, the set of all elements (36) forms an ideal, call it b, as can be 
verified at once from the conditions (33) and (34). The ideal b38 is said to 
be generated by the elements al , a2 , ... , as and is written: 
(37) 
The elements al , a2 , ... , as are said to form a basis/or the ideal b, although 
it is not thereby asserted that the basis cannot be shortened, i.e., that the 
same ideal cannot be generated by fewer basis elements. 
A priori it is not clear whether every ideal in an arbitrary ring has a 
finite basis or not; nevertheless, in all the rings considered here it is true 
that every ideal has a finite basis. Such rings are said to satisfy the basis 
condition and are called Noetherian rings. 
Particularly important are the rings in which every ideal a has a basis 
consisting of a single element a = (a). In this case a is the set of all 
multiples ra(r E m) of a; in other words, the ideal comprizes the set of all 
elements in the ring m that are divisible by a. Such ideals are called 
principal ideals, and if all the ideals of a ring are principal, the ring is 
called a principal ideal ring. 
3.3. 
Every Euclidean Ring is a Principal Ideal Ring 
For if ~ is a Euclidean ring (§2.8) and a is an arbitrary ideal (* (0) in~, 
let a(* 0) be an element in a such that the function H(a) defined in §2.8 
assumes its smallest value. Then for any b in a the division algorithm 
(26"), applied to b and a, produces an equation b = aq + r. By (35) the 
element r is contained in a and, if it is not zero, satisfies the condition 
H(r) < H(a), in contradiction to the assumption. Thus r = 0 and 
b = aq with q E ~. Consequently, a = (a) is a principal ideal, as was to be 
proved. 
38 It is assumed here that th~ring 9t contains a unity element. The ideal b is a sub ideal 
of n, which may coincide with n; in symbols: 
n :! b 
or 
ben. 

340 
PART B ARITHMETIC AND ALGEBRA 
In particular, the rings G and R[x], which are Euclidean rings by §2.8, are 
principal ideal rings.39 
We already know (§2.IO) that every Euclidean ring is a u.f. ring; 
somewhat more generally, we have· the following theorem. 
3.4. 
Every Principal Ideal Ring Is a V.F. Ring 
For let ~ be a principal ideal ring, i.e., an integral domain with unity 
element, in which every ideal has a basis consisting of a single element; 
then by §2.6 we must prove that every irreducible element in ~ is prime 
and that ~ satisfies the divisor chain condition. 
The greatest common divisor (§2.7) 
(38) 
of two or more elements is always a well-defined40 element of ~, and d is 
the basis element of the principal ideal generated by the ai , 
(38') 
For on the one hand all the at are divisible by d, and on the other d is a 
linear combination (36) of the ai and is thus divisible by each of their 
common factors; consequently, d is their greatest common factor. 
In particular, if two elements a, b in 
~ are coprime, i.e., if 
GCD(a, b) = I, then the principal ideal (a, b) = (I) generated by them 
is the unit ideal, so that there exist elements x, y in ~ satisfying the equation 
ax+~y=l. 
It follows, exactly as in §2.l0 (III), that in a principal ideal ring 3 every 
irreducible element is prime. 
Now let a1 , a2 , ... , ai , ... be a divisor chain (22) in 3, and form the 
set m of all elements of 3 that are divisible by any of the ai .41 This set m 
is an ideal in 3; for if a, b are any two elements of a set m, then there 
exists a first ai in the divisor chain that is a divisor of a, and also a first a; 
that is a divisor of b. Let us assume that j ~ i; then a; is a common divisor 
of a and b and thus a divisor of a -
b, so that a -
b E m, and m has the 
module property (33). The condition (34) is obviously satisfied, since 
together with a all elements ra(r E 3) are divisible by at and therefore are 
contained in m. 
89 On the other hand, the integral polynomial ring Glx) is a Noetherian ring but not 
a principal ideal ring. 
'0 Defined up to a unit factor; in (38) and (38') d can be replaced by any of its asso-
ciates. 
f.1 An element that is divisible by a, is also, of course, divisible by each of the 
subsequent aHl , .... 

5 Rings and Ideals 
341 
By hypothesis this ideal tn has a one-element basis: tn = (m). Since the 
basis element m is an element of tn, it must be divisible by a first ak : aklm. 
If I > k, then az I ak, and since az E tn = (m), we also have m I az, so 
that aklmlaz, or ak I az ; in other words, ak is an associate of every 
subsequent element of the divisor chain. Thus a proper divisor chain in 3 
cannot have infinitely many terms; in other words, the divisor chain 
condition holds in 3, which completes the proof that 3 is a u.f. ring. 
But the converse of this theorem does not hold; for example, the integral 
polynomial ring G[x] is a u.f. ring (§2.14) but not a principal ideal ring; for it is 
easy to see (cf. §2.l0) that the ideal (x, 2) in G[x] is not a principal ideal. 
3.5. 
Congruences Modulo a 
Two elements a and a' of a ring m are said to be "congruent modulo a," 
or in symbols: a == a' (a), if their difference a -
a' is contained in the 
ideal a: 
(39) 
a==a'(a) 
means the same as 
a -
a' E a. 
In particular, the congruence a == O(a) means that the element a itself 
is in the ideal a. 
With these congruences we can compute in exactly the same way as 
with equations: for it follows from a == a' (a) and b == b' (a) that 
(40) 
a + b == a' + b', 
a -
b == a' -
b', 
ab == a'b' (a). 
To prove the first of these three congruences we note (cf. (13) that: 
(a + b) -
(a' + b') = (a -
a') + (b -
b') E a. 
The proof of the second is analogous, and by (35) the third follows from: 
ab -
a'b' = (a -
a') b + a'(b -
b') E a. 
The fact that this last conclusion requires the ideal property (34) explains 
the peculiar importance of ideals in the class of all subrings (cf. §3.l). 
3.6. 
Residue Classes 
The congruence relation just defined is an equivalence relation42 (lA, 
§8.5, and IBI, §2.2) for the elements of the ring m and therefore generates 
a partition of these elements into classes, called "residue classes" modulo a. 
Every residue class is uniquely determined by any element a contained in it, 
since together with a it contains all the elements a' satisfying (39).43 In 
f.2 It is easily shown that congruence is reflexive, symmetric, and transitive (cf. lA, 
§8.3 and IBl, §2.2). 
U Every element of the ring lies in exactly one residue class; two distinct residue 
classes have no element in common. 

342 
PART B ARITHMETIC AND ALGEBRA 
particular, the residue class containing the zero element coincides with 
the ideal a. 
By [a] we denote the residue class modulo a containing the element a and 
say that a is a representative of this class; any other element a' of the same 
class will serve equally well as a representative. 
We now consider these residue classes [a], [b], [c], ... as new elements, 
for which addition and mUltiplication can be defined in accordance with 
the postulates in §1.2 for a ring, with the result that the residue classes 
form a new ring, the residue class ring mja.44 The sum and the product of 
two residue classes [a] and [b] are naturally defined by 
(41) 
[a] + [b] = [a + b], 
[a] [b] = [ab]. 
This definition is unique, since the result remains the same (cf. (40) for 
all other choices a' and b' of the representatives for the two classes. 
Computation with residue classes modulo a is essentially the same as 
with the congruences modulo a described in §3.5, where two elements 
congruent modulo a are regarded as equal to each other. Consequently, 
all the ring postulates (§1.2) are satisfied in the residue class ring, since they 
are valid for the elements of the orginal ring m. 
If to every element a in 9t we assign the residue class [a] of the residue class 
ring 9t/a, we have a homomorphism 9t ::; 9t/a in the sense of §1.13, in which 
all the elements of the ideal a are mapped onto the zero element of the residue 
class ring 9t/a. Thus every residue class ring 9t/a is a homomorphic image of 
the ring 9t. 
Conversely, if a ring 9t * is the homomorphic image of 9t : 9t ~ 9t * there 
exists an ideal a in 9t such that the residue class ring 9t/a is isomorphic to 
9t* : 9t/a ~ 9t* (the homomorphism theorem for rings). The ideal a consists 
of the set of all elements of 9t mapped by the homomorphism 9t ~ 9t * onto 
the zero element of 9t *, where it is clear that this set is actually an ideal, since 
addition and multiplication are preserved under a homomorphism; i.e., if 
a and b are mapped onto the zero element in 9t *, then so is ra + sb, r, s E 9t. 
We see that the elements of the residue class ring 9t/a are in one-to-one 
correspondence with the elements of 9t * . 
An ideal l' whose residue class ring mjl' has no divisors of zero is called 
a prime ideal; thus a prime ideal is characterized by the property that a 
product ab is contained in l' if and only if at least one factor a, b lies in l' 
(cf. p. 340, ftn. 2). 
A primary ideal q is an ideal whose residue class ring 9t/q contains only 
nilpotent divisors of zero, i.e., elements which become equal to zero when raised 
" The residue class ring corresponds to the concept in group theory (IB2, §3.3) of 
a factor group with respect to a normal subgroup. 

5 
Rings and Ideals 
343 
to a certain power. Thus we can characterize a primary ideal q by the following 
condition: 
(42) 
abEq 
and 
a¢q 
imply 
bP Eq 
for a natural number p. Setting p = 1, we have the condition for a prime ideal, 
so that prime ideals are special cases of primary ideals. To every primary 
ideal q there corresponds a prime ideal p consisting of all the elements of 9t 
that lie in nilpotent residue classes modulo q. 
In Noetherian rings (§3.2) we have the general factorization theorem: every 
ideal can be represented (in an essentially unique way) as the intersection of 
finitely many primary ideals corresponding to distinct prime ideals. To a certain 
extent, this factorization theorem for ideals takes the place of the (no longer 
valid) u.f. theorem. Somewhat more special are the rings occurring in the 
theory of algebraic numbers; in these rings of the "classical ideal theory" 
we have the following factorization theorem: every ideal can be represented 
(uniquely, apart from the order of the factors) as a product of prime ideals 
(cf. also IB6, §8.2). 
The reader should compare the discussion in IBll, §3. 
3.7. 
Residue Class Rings Gln45 
The integral domain G of rational integers is a principal ideal ring 
(§3.3); every ideal (in this context often called a "module") can thus be 
written as the principal ideal a = (n) consisting of all the multiples in G 
of the natural number n. In every residue class there is exactly one number 
between 0 and n -
I (inclusive); this number may be chosen as the 
representative of the class. Thus there are exactly n residue classes 
[0], [I], [2], ... , [n -
1]. 
With these classes we compute exactly as with integers, except that the 
result of a computation modulo n must be reduced to the smallest 
nonnegative remainder (cf. 186, §4.I). 
The residue class ring Gin is finite46 and has no divisors of zero if and 
only if n = p is a prime; as a finite integral domain (§ 1.1 0) it is then a 
field, namely the prime field of characteristic p (§I.Il). 
3.8. 
The Integral Domain of the Gaussian Numbers G[i] 
as Residue Class Ring G[x]/p 
In the polynomial ring G[x] we now consider the principal ideal47 
(43) 
P = (x2 + 1); 
'5 The notation G/n is often used in place of the more exact G/(n). 
f.6 A "finite" ring is a ring with only finitely many elements. 
'7 This ideal p is a prime ideal, since the basis polynomial x 2 + 1 is irreducible in 
G[x] and is therefore prime (§2.14). In other words, a product I(x) g(x) of two poly-
nomials in G[x] is contained in p (Le., is divisible by x 2 + 1) if and only if at least one of 
the factors is already contained in p. 

344 
PART B ARITHMETIC AND ALGEBRA 
if p(x) is any polynomial in G[x], division of p(x) by x2 + 1 gives the 
equation 
(43') 
p(x) = (x2 + I) q(x) + (ax + b). 
with 
q(x) E G[x], 
a, bEG, 
so that 
(43") 
p(x) = ax + b(p). 
So in every residue class modulo p there exists exactly one integral 
polynomial ax + b of degree ~ I; and, of course, we may choose this 
particular polynomial as representative of its class. Computation with 
these classes, i.e., with congruences modulo p follows the rules: 
(ax + b) ± (a'x + b') = (a ± a') x + (b ± b')(p), 
(ax + b)(a'x + b') = (ab' + a'b) x + (bb' -
aa')(p); 
but exactly the same rules must be followed if we replace x by the 
imaginary unit i and write ordinary equations instead of the congruences 
modulo (p). Consequently, except for the somewhat different notation, 
the residue class ring G[x]jp is identical with the integral domain G[i] of 
Gaussian integers (§1.1); in other words we have the isomorphism: 
(44) 
G[i] ~ 
G[x]j(x2 + I). 
In exactly the same way we can show that the field C of complex numbers 
is isomorphic to the residue class ring K[x]j(x2 + I), where K is the field 
of real numbers (see also IB8, §1.2). 
3.9. 
Residue Class Rings R[x]jf(x) 
Now let f(x) be any polynomial of degree ~ 1 in the polynomial ring 
R[x] over an arbitrary base field R, and consider the residue class ring 
R[x]ja of R[x] with respect to the principal ideal a = (f(x) , for which 
we also write R[x]jf(x). 
If f(x) is of degree n in x, every polynomial p(x) in R[x] can be 
reduced, if necessary by the division algorithm (26"), to a polynomial of 
degree ~ n -
I: 
(45) 
p(x) = f(x) q(x) + r(x), 
so that 
(45') 
p(x) = r(x)(a), 
with r(x) = 
C1 + c~ + caX2 + ... + cnxn- 1• So in every residue class 
modulo a there is exactly one polynomial rex) of degree ~ n -
1 with 

5 Rings and Ideals 
345 
coefficients in R. The residue classes can be put in one-to-one 
correspondence with these polynomials. 
Computation with the residue classes is the same as ordinary 
computation with the polynomials r(x), except that the result must be 
reduced modulo f(x) whenever the degree exceeds n -
1. The calculations 
become simpler if we introduce the following notation for the residue 
classes 
(46) 
[1] = e1 , 
[x] = e2, 
Then the residue class represented by the polynomial 
can be written as a linear form 48 in the ei 
(46') 
It is clear how such linear forms are to be added, but for multiplication 
we need a multiplication table, which must be constructed by computing 
congruences modulo f(x). It is sufficient to calculate the result49 for all 
products etej : 
(46") 
i, j = 1, ... , n. 
When the coefficients y~j have been determined, it is easy to carry out 
all the operations (except division) on the linear forms (46'), and in each 
case the result is a linear form denoting the same residue class as would 
result from the same operations applied to residue classes. 
A ring consisting of linear forms (46') provided with a multiplication 
table (46") is called an algebra or a hypercomplex system. Thus we can 
now say: every residue class ring R[x]l/ (x) is a (commutative) algebra over 
the base field R. 
3.10. 
Residue Class Rings as Field Extensions 
If 
(47) 
(n ~ 1) 
is an irreducible polynomial in R[x], the residue class ring R[x]I/(x) is a 
field, which we shall denote by Q. 
'8 A form is a homogeneous polynomial, a linear form is a linear homogeneous 
polynomial. 
foB By (46) the residue class eiei contains X Hi- 2 ; if i + j -
2 ~ n -
1, we have 
simplye,ei = eHI-l; otherwise, we must reduce X Hi- 2 by (45) and express the resulting 
r(x) by (46) as a linear form. 

346 
PART B ARITHMETIC AND ALGEBRA 
For if the polynomialp(x) is not divisible by f(x) , i.e., if the irreducibility 
off(x) implies thatp(x) andf(x) are coprime, then by (28) the Euclidean 
ring R[x] contains two polynomials h(x) and k(x) with 
p(x) h(x) + f(x) k(x) = 1; 
and therefore, since [f(x)] = [0], 
[P(x)][h(x)] = [1], 
which means that every nonzero element in Q is a unit (§2.2), so that Q is a 
field. 
The field Q contains a subfield R * isomorphic to R, where R * consists 
of all the residue classes that contain an element of R. Letting the element 
a E R50 represent its residue class [a], we see that the correspondence 
a~ [a] is an isomorphism (§1.13), so that we can identify the isomorphic 
fields Rand R* by setting their elements equal to each other. For the 
residue classes [a] in R* we write simply a, as may be done without fear 
of ambiguity . 
. Ifwe now denote by f(X) the polynomial (47) in the new indeterminate X 
(47') 
it is easy to see that in the field Q this polynomial has the zero [x], since in 
the residue class ring Q 
f([xD = ao + a1[x] + ... + an[x]n = [ao + a1x + ... + anxn] 
= [f(x)] = [0]. 
To sum up: a polynomial f(X) irreducible51 over the field R has at least 
one zero in the residue class field R[x]lf(x), which may be regarded as an 
extension field of R. 
4. Divisibility in Polynomial Rings Elimination 
4.1. 
The process of deciding whether a given element in a u.f. ring is 
reducible or irreducible is usually very time-consuming, if it is possible 
at all. Even in the very simple u.f. ring G of rational integers the only 
practical way of deciding whether a given number is prime or not is to 
consult a table of primes (provided the given number lies within the range 
of the table). 52 So we must expect that in complicated u.f. rings, partic-
50 Two distinct elements in Sl cannot be contained in the same residue class modulo 
f(x). 
51 "Irreducible over Sl" means "irreducible in Sl[x)." 
52 A famous example for the difficulty of recognizing a prime is the number 
232 + 1 = 4294967297, which Fermat (1601-1665) considered to be prime; but 
Euler (1707-1783) discovered that in fact it is composite: 641 . 6700417. 

5 
Rings and Ideals 
347 
ularly in the polynomial rings G[x], R[x], G[x, y], ... , this question 
will not be a simple one. Of course, we can show, just as for the ring G, that 
in principle the question can be decided in finitely many steps, which it 
may be possible to simplify by more or less ingenious devices; but even 
then the actual process will usually require far more time than can be 
devoted to it. So we must content ourselves here with some useful lemmas 
and a few special criteria for irreducibility. 
4.2. 
A polynomial p(x) is irreducible in R[x] ("irreducible over R") 
if and only if the corresponding primitive polynomial p*(x) (see §2.11) is 
irreducible in G[x]. 
For if the primitive polynomialp*(x) is reducible in G[x], then certainly 
it remains so in R[x]; if it is prime in G[x], then it remains prime in R[x], 
as was shown in §2.l4 (ftn. 35). 
4.3. If 3 is an integral domain with unity element (~ may be a field), 
then a polynomial p(x) in 3[x] is divisible by a linear polynomial x -
ex 
(ex E~) if and only if ex is a zero ofp(x), i.e., (p(ex) = 0). 
For if p(x) = (x -
ex) q(x), q(x) E 3[x], it follows at once thatp(ex) = 0. 
Conversely, if p(ex) = 0, then by the division algorithm53 we can set up 
the identity 
p(x) = (x -
ex) q(x) + r, 
q(x) E 3[x], 
and replace the indeterminate x by ex; since p(ex) = 0, it follows that 
r = 0, so that (x -
ex)lp(x), as was to be proved. 
4.4. 
For a primitive polynomial in G[x]: 
(48) 
it is clear that a linear polynomial ao + alx can be a divisor of p(x) only 
if GCD(ao , al) = 1, aolco, allcn • 
In particular, if Cn = 1, 
then 
necessarily al = ± 1: a rational zero of an integral polynomial with 1 as 
highest coefficient is necessarily an integer. 
4.5. 
The Irreducibility Criterion of Eisenstein 
A polynomial p(x) E G[x] is irreducible in G[x] if there exists a prime 
number 'T1' such that all the coefficients Ci (i = 0, 1, ... , n -
1) with the 
exception of Cn are divisible by 'T1' and and the first coefficient Co is not 
divisible by 'T1'2. 
53 Cf. IB4, §1 (4); the division algorithm (26") can also be carried out in the non-
Euclidean ring ~[x] if the "divisor" has a unit for its highest coefficient. 

348 
PART B ARITHMETIC AND ALGEBRA 
For if we examine the factorization p(x) = f(x) g(x) we see that 
'TT'I Co, 
'TT'2 l' Co, and 
Co = aobo imply 
'TT' I ao, 'TT'1' bo ,54 where the 
notation is the same as in §2.12. From the remaining conditions 
'TT' I C1, 'TT' I C2, and so forth, it follows that 'TT' I aI, 'TT' I a2 , ... , up to 
'TT' Illn-l ; from 'TT'1' Cn it follows that 'TT'1' an, so that lln -=I=- O. Thusf(x) has 
the same degree as p(x), so thatf(x) is not a proper divisor.55 
4.6. 
The greatest divisor GCD(f(x), g(x), of two polynomials f(x) 
and g(x) in a polynomial ring R[X]56 can be calculated by the Euclidean 
algorithm (§2.9). But we now give another criterion, usually much easier 
to apply, for deciding whether two polynomials are coprime or not. Here 
it is convenient to write the polynomials in the following way: 
The polynomials f(x) and g(x) have a nontrivial common divisor 
GCD(f(x), g(x) = d(x) if and only if there exist in R[x] a polynomial h(x) 
of degree ~ n -
1 and a polynomial k(x) of degree ~ m -
1 satisfying the 
identity 
(50) 
h(x)f(x) + k(x) g(x) = 0 
(h(x), k(x) -=I=- 0). 
For if f(x) and g(x) are coprime, an equation of the form (50) would 
imply (since R[x] is a u.f. ring) thatf(x) I k(x) and g(x) I h(x), which is 
impossible since k(x) is of lower degree than f(x), and h(x) is of lower 
degree than g(x). Conversely, if the GCD(f(x), g(x) = d(x) is a 
polynomial of positive degree, the polynomials h(x) = g(x)/d(x) and 
k(x) = -f(x)/d(x) satisfy all the conditions of the theorem. 
4.7. 
A Criterion Based on the Resultant 
From the preceding section we can at once deduce that the polynomials 
f(x) and g(x) in R[x] are coprime if and only if the following m + n 
polynomials 
(51) 
xn-lJ(x), 
xn-2f(x), .. ·,f(x), 
xm-1g(x), 
xm- 2g(x), ... , g(x) 
are linearly independent57 over R. 
640 Of course there is no loss of generality in assuming 7T I 00 rather than 7T I bo • The 
notation 7T1' bo means "7T is not a divisor of bo ." 
lill In this proof we have used only the u.f. theorem; so the Eisenstein criterion is 
valid in any polynomial ring ~[x] over a u.f. ring ~. 
66 Here st can be an entirely arbitrary field; in particular, one of the polynomial 
quotient fields R(y), R(y, z), .... 
li7 For linear dependence see IB3, §1.3. 

5 
Rings and Ideals 
349 
For equation (50) simply expresses the linear dependence over R of the 
polynomials (51); and conversely, this linear dependence implies the 
existence in R of elements (Xi and f3; (not all zero) such that 
(XoXn-y(x) + (XIXn-~(X) + ... + (Xn-lf(x) 
+ f3oXm-1g(x) + f31xm- 2g(x) + ... + f3m-lg(X) = 0 
is an identity in x, and this identity is of the form (50) with 
h(x) = (XoXn-1 + (XIXn-2 + ... + (Xn-l , 
k(x) = f3oXm-1 + f31xm- 2 + ... + f3m-l . 
If we now consider the polynomials (51) as linear forms in the m + n 
magnitudes xm+n-1, xm+n-2, ... , x, 1, the question oftheirlinear dependence 
or independence can be decided (183, §3.4) by constructing the determinant 
of their coefficient matrix. For the polynomials (49) this determinant, 
which is called the Sylvester determinant, has the following form: 
ao a1 
am 
l 
n rom 
ao a1 
am 
ao a1 
am 
bo b1 
bn 
l 
m rows. 
bo b1 
bn 
bo b1 
bn 
The first row contains the coefficients ao , a1 , ... , am of f(x) followed by 
zeros; the second row begins with a zero and is otherwise equal to the first 
row shifted one place to the right, and so on; and the second half of the 
determinant is constructed analogously. It is easy to see that in this way 
we will obtain exactly m + n columns. 
The Sylvester determinant is called the resultant R(f, g) of the polynomials 
(49). The vanishing of the resultant is a necessary and sufficient condition 
for the polynomialsf(x) and g(x) to have a nontrivial commonfactor. 
F or in fact the vanishing of R (f, g) is a necessary and sufficient condition 
for the linear dependence of the polynomials (51). 
4.8. The resultant R/, g) is homogeneous 0/ degree n in the a, and 0/ degree m 
in the bi ; and it is isobaric o/weight mn in the two sets 0/ coefficients; its leading 
term is a:b:' (with the coefficient + 1). Also 
(53) 
R(g,!) = (-l)mnR(j,g). 
For it is easy to see, 1i8 by developing the determinant (52) (see IB3, §3.4), that 
li8 The indices il
, ... , in and jl , ... ,jm in (54) are not necessarily distinct. 

350 
PART 8 
ARITHMETIC AND ALGEBRA 
the individual terms of the resultant consist of n factors ai and m factors bi : 
(54) 
with rational integers for coefficients. The sum of all the indices in (54) is mn 
(i.e., the resultant is "isobaric of weight mn"): 
(54') 
The proof of (54') is as follows. In the determinant (52) we make the substitution 
then we multiply the successive rows of (52) by 1, p, p2, ... , p,,-I, 1, p, p2, ... , pm-I, 
and divide the successive columns by the factors 1, p, p2, ... , pm+n-l. We thus 
obtain the original determinantll9 multiplied by the factor pm"; but in the above 
substitution each individual term (54) is multiplied by the factor 
which completes the proof of (54'). 
The formula (53) is a simple consequence of a well-known theorem on 
determinants (IB3, §3.4(a') and §3.5. 2). Note that the determinant on the 
right arises from the one on the left by mn interchanges of rows (each of the 
m lower rows is interchanged with each of the n upper rows), which produce 
the factor (- 1 )mn. 
The leading term a~b:: , by means of which the resultant may be normalized, 
is the product of the elements in the leading diagonal in (52). 
For example, if m = n = 2, the resultant is given by 
ao a1 a2 0 
0 
ao a1 a2 
R(j,g) = 
bo b1 b2 0 
0 
bo b1 b2 
= a02b22 + a22b02 -
aoa1b1b2 -
a1a2bObi + aOa2b12 + a1
2bob2 -
2ao02bob2 
= (aOb2 - a2bo)2 -
(aObl - a1bo)(a1b2 -
a2bl)' 
4.9. 
The Resultant as a Function of the Zeros or Roots 
We shall denote the zeros60 of the polynomial f(x) in (49) by 
(Xl , (X2 , ... , (Xm, and the zeros of g(x) by f31' f32 , ... , f3n' and consider 
these zeros as independent transcendents in the sense of IB4, §2.3, which 
59 By the well-known formula for the sum of an arithmetic progression, 
1 + 2 + 3 + ... + (n -
1) = !n(n -
1), 
we here obtain 
1 + 2 + ... + (m + n -
1) -
1 -
2 -
... -
(m - 1) -
1 -
2 -
... -
(n -
1) = mn. 
60 Cf. IB4, §2.2. 

5 Rings and Ideals 
351 
must be adjoined 61 to the base field R of the polynomial ring R[x]. Then 
f(x) and g(x) can be factored into linear factors (IB4, §2.2): 
(55') 
(55") 
f(x) = ao(x -
(Xl)(X -
(X2) ... (x -
(Xm), 
g(x) = bo(x -
f31)(X -
f32) ... (x -
f3n). 
Apart from sign, the quotients adao , b;/bo of the polynomial coefficients 
(49) are the elementary symmetric polynomials (IB4, §2.4) of the (Xi and f3; ; 
so a;nb;m R(f, g) is an entire rational function of the elementary symmetric 
polynomials and is therefore a symmetric polynomial in the indeterminates 
(Xi and in the f3; : 
Considered as a polynomial in the (Xi, the expression P has the zeros 
f3; (j = 1, ... , n), since substitution of f3; for (Xi is necessary and sufficient 
for the polynomials f(x) and g(x) to acquire a common factor x -
f3; , 
whereupon the resultant R(f, g) becomes equal to zero. By §4.3, it follows 
that P is divisible by every linear factor (Xi -
f3; , so that we may write 
m 
n 
ar;nbr;mR(f, g) = C n n «(Xt -
f3i), 
i=1 i-I 
with a factor C still to be determined. From (55") we have 
m 
m 
ar;nbr;mR(f, g) = Cbr;m n g«(Xi) = Cbum n (bo(Xt + ... + bn), 
i=1 
so that the leading term aonbn min R(f, g) (see §4.8) corresponds to Cb;mbn m, 
which gives C = 1 and finally: 
m 
n 
(56) 
R(f, g) = aonbom n n «(Xt -
f3;). 
i=l ;=1 
This relation is an identity in the indeterminates (Xi and f3; if the 
adao, b;/bo are replaced by the elementary symmetric polynomials; thus 
the relation continues to hold if the zeros (Xi,f3;are no longer indeterminates 
but are arbitrary elements of the field R or of an extension field of R. 
From (56) we can at once read off the characteristic property of the 
resultant: namely, the resultant of two polynomials vanishes if and only if 
the two polynomials have a common root. 
61 The original base field Sl is thus replaced by the transcendental extension 
Sl(CXI , ... , CXm , III , ... , Iln). 

352 
PART B ARITHMETIC AND ALGEBRA 
The above discussion also leads at once to the two expressions for the 
resultant: 
m 
(56') 
R(f, g) = aon n g(OI.,) = (-l)mnbom TI 1(/31)' 
Furthermore if g(x) = gl(X) g.(x) is the product of two polynomials of (positive) 
degree n1 ,n.(n1 + n. = n), it is easy to show that 
R(f, g) = a: Ii gl(OI.,) g2(0I.,) = ~a:l Ii gl(01.,)~ ~OI.:' Ii g.(OI.,)~, 
'-1 
'-1 
'-1 
which gives the important formula 
4.10. 
The discriminant D(f) of a polynomial f(x) in R[x] is defined, 
up to a numerical factor, as the resultant of the polynomial f(x) and its 
derivative62 f' (x): 
(57) 
( _l)m(m-l) /2 
, 
D(f) = 
R(f, f ). 
ao 
From (56') and (58)62 we find 
m 
m 
m, 
D(f) = (_l)m(m-I)/2 a~-2 TI f'«(x) = (_l)m(m-I)/2 a~m-2 TI TI (ai -
aj ). 
i-I 
i-I ;-1 
In the double product on the right every factor (ai -
ai) occurs twice, 
the second time with opposite sign; taking these factors together and 
noting the sign, we have 
(59) 
D(f) = a~m-2 TI (ai -
a;)2. 
i<i 
The vanishing of the discriminant D(f) of a polynomial f(x) in R[x] is 
a necessary and sufficient condition for f(x) and f' (x) to have a common 
zero, or in other words for f(x) to have a multiple zero (cf. IB4, §2.2). 
6. For the derivative of a polynomial see IB4, §2.2. From the formula proved there, 
it follows that 
(58) 
f'(x) = 
I(x) + I(x) + ... + I(x) , 
X-OI.l 
X-OI.. 
X-OI.m 
m 
f'(OI.J = ao TI' (01., -
OI.i)' 
i-I 
where the prime on the product means that the term with j = i is to be omitted. 

5 
Rings and Ideals 
353 
4.11. 
Elimination Theory 
The problem of solving a system of algebraic equations in several 
unknowns, i.e., of finding their common zeros, is part of the theory of 
elimination. The case of systems of linear equations has already been 
handled in IB3, §§2.4 and 3.6; the solutions there can be found by means 
of determinants. For nonlinear systems of equations we adopt the method 
of elimination; i.e., from the given system of equations we deduce another 
system containing one fewer unknowns (from which one unknown has 
been eliminated), and we repeat this elimination until we reach a single 
equation with one unknown. 
Provided we have taken certain precautions, every solution of the system 
of equations obtained by elimination can be extended, in at least one way, 
to a solution of the original system. Here we take for granted that we 
know how to solve an algebraic equation in one unknown. 
We must be content with illustrating the method for the case of two 
equations63 in two unknowns 
(60) 
f(x,y) = 0, 
g(x, y) = O. 
If f(x, y) and g(x, y) are polynomials in the polynomial ring R[x, y], we 
first consider them as polynomials in R*[x] with R* = R(y). Then the 
polynomials f and g have the form (49), where the coefficients ai, bi are 
now polynomials in y. In order to apply the following theory we must first 
insure that the leading coefficients ao and bo (which may depend on y) 
are elements (* 0) in the base field R. This condition can always be satisfied 
by means of a sufficiently general linear transformation. 
Then the necessary and sufficient condition for the polynomials (60) 
to have a common zero is the vanishing of the resultant R(f, g), which is 
here (cf. (52) a polynomial in y. For the complete solution of the system 
(60) we must determine64 the zeros f31 , ... , f3t and substitute them into (60); 
the resulting polynomialsf(x, f3i) and g(x, f3i) have a GCD of degree ~ 1, 
which can be calculated by the Euclidean algorithm; let its zeros be denoted 
by (XiI' ... , (Xi.81 • Then the common solutions of (62) are given by 
x = 
(Xjk, 
y = f3i' 
j = 1, .. " t; 
k = 1, ... , Sj. 
A completely satisfactory theory of elimination can be given only in terms 
of the theory of ideals in polynomial rings Pn = Sl[x1 , ... , Xn]. The left-hand 
sides of a given system of algebraic equations are polynomials PI , ... , P, in P n ; 
they generate an ideal a = (PI, ... , p,) in Pn , and our task is to determine the 
63 Strictly speaking, these are not equations but problems, namely, to find all the 
common zeros of the polynomials on the left-hand sides. 
6' These zeros are finite in number, unless R(f, g) vanishes identically, which would 
mean that the polynomials I(x, y) and g(x, y) are not coprime. 

354 
PART B ARITHMETIC AND ALGEBRA 
manifold of the zeros of this ideal. We eliminate Xn by forming the elimination 
ideal al = a (l Pn- l in61l Pn- l = Sl[xi , ... , xn- l ], and then form the second 
elimination ideal a2 = a (l Pn- 2 in Pn- 2 = Sl[XI , ... , Xn-2], and so forth. The 
last nonzero elimination ideal is a principal ideal. If it is the unit ideal (the 
entire ring P n), then there are no zeros at all, otherwise its manifold of zeros 
is a sum of algebraic manifolds. 
The investigation becomes even more difficult if the multiplicity of the zeros 
is to be taken into account. The concept of multiplicity plays an important role 
in theorems of enumeration, modeled after the theorem that a polynomial f(x) 
of degree n has exactly n zeros, counting mUltiplicities. The most important 
theorem of this kind is the theorem of Bezout: 
If multiplicities are taken into account, n homogeneous polynomials in 
Sl[xo, Xl , ... , Xn] have either infinitely many zeros or a number of zeros equal 
to the product of their degrees. 
In view of the homogeneity here, the trivial zero {O, 0, ... , O} is excluded and 
two zeros {so, Sl , "', Sn} and {PSo, PSI, ... , PSn}, with P =F 0 and S, in Sl or in 
an algebraic extension of Sl, are regarded as identical. The multiplicity of 
an individual zero can also be defined, in terms of the theory of ideals, as 
the length (see below) of a corresponding primary ideal, which arises as the 
intersection of primary ideals (§3.6) in the factorization of the ideal generated 
by the n forms. 
The length I of a primary ideal q is defined as the length of a composition 
series (cf. the corresponding concept for groups in IB2, §12.1), extending 
from the primary ideal q to the aSs.!lciated (§3.6, p. 355) prime ideal p: 
q = ql C q2 C ... C ql = p. 
Here it is assumed that all the terms qi(j = I, ... , I) are primary ideals associated 
with the same prime ideal p, that qi is a proper sub ideal (i.e., a proper subSet) of 
qi+l, and that the Iseries cannot be made longer by the insertion of further 
terms. In particular, every prime ideal is of length I. The theorems here are 
similar to those for the composition series of a group: e.g., in a Noetherian 
ring (§3.2) every primary ideal q has at least one composition series of finite 
length I; and every other composition series for the same primary ideal q has 
the same length I (Jordan-HOlder theorem, IB2, §12.1). 
In algebraic geometry still other definitions, some of them quite complicated, 
have been introduced for the multiplicity of points of intersection, but as long 
as we are dealing with applications of the concept as it occurs in the simple 
theorem of Bezout, the various definitions of multiplicity are all equivalent 
to the idealtheoretic one given here. 
65 Thus al contains all those polynomials in a which are independent of x,. . 

CHAPTER 6 
Theory of Numbers 
1. Introduction 
The theory of the natural numbers may be regarded as number theory 
in the narrower sense (see IBI, §l), but no matter how far we may wish to 
set the boundaries, it remains one of the most attractive parts of 
mathematics; for the most part its problems can be understood without 
extensive preparation, and they range from questions that can easily be 
answered to famous unsolved conjectures. 
The modern theory of numbers includes the study of so-called algebraic 
numbers, i.e., the roots (zeros) of polynomials with coefficients that are 
integers in the ordinary sense (rational integers). Under the influence of 
the structure-theoretic methods of present-day mathematics, certain parts 
of number theory have become more abstract. The advantages of such a 
treatment of the subject are particularly clear in the theory of divisibility, 
described in §2. The concepts and theorems of that section are equally 
valid for the ring of Gaussian integers (see IB5, §l.l), i.e., the numbers 
a + bi with rational integers a and b, for the polynomial ring in one 
indeterminate (see IB4, §2.1) with coefficients from a field, and for many 
other rings. Thus it is unnecessary to begin the argument afresh for each 
new application. 
2. Divisibility Theory 
2.1. 
For the time being we consider an arbitrary commutativel ring 
9t Let a and b be two elements of 9l; then a is said to be a divisor of b, 
in symbols a I b, if b = ac with c E 9l. To denote the opposite, we write 
1 Throughout Chapter 6, except where otherwise noted, we shall be dealing with 
commutative rings. so that the word "commutative" will ordinarily be omitted. 
355 

356 
PART B ARITHMETIC AND ALGEBRA 
a l' b. This divisibility relation is obviously transitive: from a I band b I c 
follows a I c. For all x E 9l we have x I 0, and thus in particular 0 I O. If 9l 
has a unity element, we have the reflexive law: x I x for all x E 9l, and also 
1 I x. In the relation b = ac the element c is said to be complementary to 
the divisor a. 
2.2. The relation of divisibility defined in this way can be regarded as a 
weakening of the order relation (see lA, §8.3). In an order relation "~" it 
follows from a ~ band b ~ a that a = b, but in the ring <r of integers2 the 
fact that (-2)1( +2) and (+2)1(-2) are both true shows that the divisibility 
relation is certainly not an ordering, not even a partial ordering (see lA, §8.3). 
If 1 E 9t, such a relation is called a quasi-ordering, i.e., a reflexive and transitive 
relation (to be denoted, say, by "~" for which there may exist unrelated 
elements, i.e., elements a and b such that neither a ~ b nor a = b nor b ~ a. 
2.3. 
Now let 9l be a ring with unity element. An element £ E 9l is 
called a unit if there exist an 7J E 9l, such that £7J = I. Then 7J is an inverse 
of £ in sense of IBI, §3.I, so that 7J = £-1 is also a unit. The unity element 
is obviously a unit, and so is the product of two units. Thus the units 
form a group with respect to multiplication, so that the inverse of a unit 
is uniquely determined (see IB2, §2.3). 
For example, in the ring of Gaussian integers the numbers I, -I, i and 
-i are the only units, as is easily seen. In a field all the nonzero elements 
are obviously units. 
If c = ab is a factorization of c, then so is c = (£a) . (£-lb), where £ is 
a unit; thus it is clear that, as far as factorization is concerned, the elements 
a and a£ are not essentially distinct. Such elements a and a£ are said to be 
associates: a"" a£. The relation of "associate" is obviously reflexive, 
symmetric, and transitive and is thus an equivalence (see lA, §8.5). The 
corresponding equivalence classes are the classes of associated elements. 
2.4. In general, in a quasi-ordered set two elements a and b are said to be 
associates if a ~ b and also b ~ a. It is easy to show that the quasi-ordering 
induces (see lA, §8.3) a partial ordering in the set of corresponding equivalence 
classes. 
2.5. 
Now let a, band t be elements of a ring 9l (with unity element) 
such that t I a and t I b. Then it is clear that t is also a divisor of any 
linear combination xa + yb({x, y} k 9l). The set m(a, b) = m of all 
linear combinations of a and b has certain remarkable properties: 
I From {VI' V2} k m it follows that VI ± V2 E m. 
II If V E m and r E 9l, then rv E m. 
2 The symbol <r will be used throughout Chapter 6 to denote the ring of rational 
integers. 

6 Theory of Numbers 
357 
The first property states that m is a module (i.e., an Abelian group 
with additively written operation; see also 182, § 1.1); more precisely: m 
is a submodule of the additive group m+ of m. 3 Ifwe take rEm in (II), we 
see at once that m is a subring of m; but the condition (II) is much 
stronger, since we may take rEm. By 185, §3.1 the conditions (I) and (II) 
are precisely the definition of an ideal in m, so that in the notation of 
IB5, §3.2 we see that m is the ideal (a, b). 
If 9t is a not necessarily commutative ring, we have left ideals and right ideals, 
and also two-sided ideals, according to whether in II we may 'set r on the left, 
on the right, or on both sides. 4-
From a""'" b it obviously follows that the principal ideals (a) and (b) coincide, 
and from a I b follows (b) C; (a) and conversely. 
2.6. 
Any element of a ring is obviously divisible not only by its 
associates but also by every unit in the ring. The associates and the units 
are said to be trivial divisors of a. A divisor d of a which is not an associate 
of a is said to be a proper divisor of a, which we shall occasionally denote 
by d I pra. An element a E m is said to be reducible if there exists at least 
one factorization a = ala2 ... an in which all the ai are proper divisors 
of a; otherwise a is irreducible. If a is irreducible and a = ab, then either 
b = I or I -
b is a nontrivial divisor of zero (see 185, § I. 7), since 
a(l - 'b) = O. In an integral domain (i.e., a commutative ring without 
divisors of zero; see IB5, §1.9) the nonzero irreducible elements are identical 
with the elements that have only trivial divisors of zero. 
In the ring (£: the positive irreducible numbers are called prime numbers. 5 
We now say that a ring m with unity element admits a theory of 
divisibility if it satisfies the following condition: 
8 With respect to addition alone, every ring 9t is obviously an Abelian group, the 
so-called additive group of the ring, in symbols 9t+. With respect to mUltiplication the 
set 9t -
{O} is a semigroup, the so-called multiplicative semigroup of9t, in symbols 9tx • 
If 9t is a field, or only a skew field, then 9tx is obviously a group, the multiplicative group 
of the "skew" field. In this case the mUltiplicative group is obviously identical with the 
group of units. It was merely to preserve this group property for the special case of 
a field that we excluded the zero element from 9tx• 
" If 9t has no unity element, the conditions (I) and (II) still define an ideal. By (I) the 
left ideal (al ,a2, ... , an) consists of all expressions of the form 
with 
{gl , g2 , ... , gn} C [, 
{Xl' X2 , ... , Xn} ~ 9t, 
where for positive integer g the product ga is defined by E!_l a, and (-g)a = -ega). 
In a ring with unity element we have g . a = g . ea = (ge) . a(g E <r), so that in view 
of ge E 9t we may omit the expression glal + ... + gnan . 
5 This definition is not universally accepted. For many authors the zero element and 
the unity element are not prime numbers. By the above definition the zero element and 
all the units in an integral domain are irreducible. 

358 
PART B ARITHMETIC AND ALGEBRA 
Fundamental condition of the theory of divisibility: let ~ be a system of 
representatives of the classes of associated irreducible elements, excluding 
the class of units. Then for every a '* 0 there exists a representation of the 
form 
8 
(I) 
a = 
£ n p~", 
(XA > 0 (£ a unit), 
,1=1 
for 
K '* A, 
(A = I, ... , s), 
which is unique apart from the order of the factors, i.e., for two representa-
tions of the form (l) 
s 
t 
£ 1 n p~" = 
£2 n q~P 
,1=1 
p=1 
it follows that s = t ~ 0 and with a suitable arrangement of the factors, 
PA = qA, (XA = f3Afor all A = I, ... , sand £1 = £2' 
In rings satisfying this condition the irreducible elements are also called 
prime elements (for the general definition of a prime element in rings see 
§8.2 and 185, §2.3), the rings themselves are called u.f rings (unique 
factorization rings), the above fundamental condition is called the u.f 
condition and the factorization (I) is said to be canonical. 
If m has nontrivial divisors of zero, so that ab = 0, a '* 0, b '* 0, and 
iffor a = a + ab we construct the factorization (I), then for a = a(l + b) 
we obtain a second factorization (since b '* 0) by factoring 1 + b 
canonically: for if 1 + b is not a unit, then the exponents are not identical, 
but if 1 + b = 
£ is a unit, it follows from the assumed u.f. condition that 
£1 = £1£, and thus, since the units form a group, we have at once £ = I, 
or in other words b = 0, in contradiction to our assumption concerning b. 
From this contradiction of the theorem of unique factorization we have: 
Every u . .f. ring is an integral domain. 
The above definition of a u.f. ring is identical with the definition in IB5, §2.6, 
as follows at once from the discussion of prime elements in §8.2. 
It is convenient to introduce the 'following definitions: a prime element 
p is called a prime divisor of a if p I a, p ~ 1 and p '* O. If a and bare 
arbitrary elements of the ring and d I a, d I b, so that d is a common divisor, 
then the greatest common divisor (GCD), which we denote by (a, b), is 
defined, provided it exists, as a common divisor g such that dig holds for 
all common divisors d. Similarly, a v with a I v and b I v is a common 
6 Here we are adopting the convention that an empty product (e.g., n~_l av) always 
has the value 1. Similarly, an empty sum has the value O. 

6 Theory of Numbers 
359 
multiple of a and b, and a k with a I k, b I k, k I v for all common multiples 
v is the least common multiple (LCM), in symbols [a, b]. For the general 
case n ~ I, the GCD (ai, a2 , ... , an) and the LCM [ai' a2 , ... , an] are 
defined correspondingly. If all all -=I=- 0 and if we set bll = ala2 ... an/all 
(v = 1,2, ... , n), it is easy to show that 
(ai' a2 , ... , an) . [b1 , b2 , ... , bn] = ala2 ... an . 
In the special case n = 2 this relation becomes the simpler (a, b) . [a, b] = abo 
For a -=I=- 0 and b if- 0, if in (I) we allow zero as an exponent, we may 
write a = 
£1 TI~=1 PAA and b = £2 TI~=1 pfA; so that in u.f. rings we have 
the formulas 
(2) 
8 
(a. b) = n pT10(CXA.,BA) 
A=1 
and 
8 
[a, b] = n pTaX(CX)..,BA). 
A=1 
Thus the (a, b) and [a, b] necessarily exist, but as long as we make no 
convention about normalization, they are determined only up to associates, 
so that it would be more correct to regard the symbols as denoting the 
corresponding equivalence classes in the sense of §2.3. 
If (a, b) = I, we say that a and b are coprime. 
Finally, from the u.f. condition we obtain the so-called fundamental 
lemma oj the theory of divisibility: 
If p is irreducible, it follows from p I ab that p I a or p I b. 
As examples of u.f. rings that do not fall under the special headings of 
§2.9 and §2.l0 let us mention the polynomial rings 9l[Xl' X2 , ... , xn] 
(see 184, §2.3) in n indeterminates, where 9l itself is assumed to be a u.f. 
ring (see also §2.10, next-to-Iast paragraph). 
The prime elements in polynomial rings are called irreducible 
polynomials, and the other polynomials are said to be reducible. 
Concerning the number of prime elements in a ring we have the 
following generalization of the classical theorem on the infinitude 
of primes. 
Theorem of Euclid: If9l is a u.f. ring, which is not afield and which has 
the property that for every nonunit a -=I=- 0 there exists a unit £ such that 
a + £ + I, there exist infinitely many prime elements, no two of which are 
associates. (See also the last paragraph of §2.l0.) 
Proof: No prime divisor of a + £ is an associate of a prime divisor of a. 
Since ill is not a field, there exist non-unit elements a, and by hypothesis 
there also exist prime divisors of a + £; consequently, in the canonical 
factorization of a there cannot appear a complete system of representatives 
of the classes of associated prime elements. 
For u.f. rings with only finitely many nonassociated prime elements see 
the end of §2. 10. 

360 
PART B ARITHMETIC AND ALGEBRA . 
2.7. On the basis of §2.2 and §2.4 we now regard the classes of associated 
elements in a u.f. ring as a partially ordered set. If we let a and b denote the 
/"-.... 
equivalence classes defined by a and b, then the GCD class (a, b) is the greatest 
common predecessor of the classes a and b with the property that every common 
/"-.... 
predecessor J of a and b is also a predecessor of (a, b), from which it follows 
that there exists exactly one greatest common predecessor. Similarly, the 
/"-.... 
LCM class [a, b] is the unique least common successor of a and b in the sense 
that is precedes every common successor. A partially ordered set of this sort, 
in which every two elements have a greatest common predecessor and a least 
common successor in the above sense, is called a lattice (see IB9, §l). Thus 
the classes of associated elements in a u.f. ring form a lattice. 
/"-.... 
/"-.... 
If the construction of (a, b) and [a, b] is regarded as two operations, in 
/"-.... 
/"-.... 
symbols (a, b) = aU b, [a, b] = a (l b, it is easy to verify the associative law; 
and the commutative law is trivial. 
2.8. 
Since every u.f. ring 9l is an integral domain, it can be embedded, 
by IBI, §3.2, in a quotient field .Q(9l). If we write the elements K E .Q(9l) 
in the form K = alb with {a, b} E 9l and apply (I) to a and b, we obtain, 
for all K * 0, a representation of the form (I) (allowing negative exponents) 
with the corresponding uniqueness properties. We thus arrive at a theory 
ofdivisibilityfor.Q(9l)relative to 9lbydefiningKlI K2with{Kl' K2} C .Q(9l), 
to mean that K2/Kl E 9l. Then by (2) we can define the GCD and LCM for 
all K E .Q(9l). If (a, b) = I, the fraction alb for K is said to be in lowest 
terms, and it follows from the u.f. condition applied to .Q(9l) that this 
representation is unique up to associates. The significance of cancellation 
in fractions becomes clear from this discussion. 
By the lowest common denominator of al/bl ,a2/b2, ... , an/bn we mean 
the LCM [bl , b2 , ... , bnl. 
2.9. 
Principal Ideal Rings 
It is natural now to ask for sufficient conditions that a given ring should 
be a u.f. ring. Here we may refer to the result already proved in IB5, §3.4 
on principal ideal rings: 
Theorem I: 
Every principal ideal ring is a u.f. ring. 
The part of the proof that there exists at least one factorization into 
prime elements depended on the so-called divisor-chain condition (lB5, 
§2.5). For later use let us state an equivalent condition in ideal-theoretic 
terms. Let a2 I al , a3 I a2, ... , an+1 I an,'" be a divisor chain. By §2.5 
the condition an+1 I an is equivalent to (an+1) d (On). Now, for an arbitrary 
ring we say that the maximal condition is satisfied if in every ascending 
sequence of ideals: al C a2 C ... C an C an+1 C ... , from some place onward 
all the ideals are equal to one another. The theorem proved in IB5, §3.4 

6 Theory of Numbers 
361 
to the effect that the divisor-chain condition holds for principal ideal rings 
can thus be formulated as follows: 
Theorem 2: 
The maximal condition is satisfied in every principal ideal 
ring. 
In §8.2 we shall return to rings with the maximal condition that are not 
necessarily principal ideal rings. 
In theorem 1 we now have an important sufficient condition for a ring 
to be a u.f. ring. Our next aim is to find sufficient conditions for a ring 
to be a principal ideal ring. 
2.10. 
Euclidean Rings 
As models for the following concepts we may consider the ring (£: of 
rational integers and the polynomial ring R[x] in one indeterminate 
(where R is a field) (see IB4, §2.1), 7 since in each of these two rings there 
exists a division algorithm (see below). 
Definition: 
A ring (t without divisors of zero is said to be Euclidean if 
the following conditions are satisfied: 
(I) 
In (f -
{O} there is defined a nonnegative integer-valuedfunction w(x), 
the so-called (absolute) value function, or valuation. 
(II) For every pair of elements a and b in (t with b -=I=- 0 there exist elements 
q and r in (t such that a = qb + rand w(r) < web) or r = 0 (division 
algorithm). 
Lemma: In a Euclidean ring (f every ideal a is a principal ideal (a) in 
the sense that all x E a are multiples qa of a.8 
Proof: 
Let a be an element with the smallest possible value w(a) in a; 
by (I) there exists at least one such element, if (t -=I=- {O}. Then for arbitrary 
b E a there exists by (II) a representation in the form b = qa + r (r = 0 
or w(r) < w(a). By the module property of an ideal it follows that 
r = b -
qa E a. Thus the minimal property of a implies r = O. 
If we apply the lemma to the unit ideal (185, §3.1) (t, it follows that 
(f = (€), so that for every x E (f there exists a q( =q(x), with x = €q; in 
particular, for x = € let € = €e. Then 
(3) 
x = q€ = q€e = q€ . e = xe 
for all x E (t; 
that is, e is the unity element in (t. To sum up, we have 
7 Since in general the degree (ao + a1x + ... + anxn = n if an =1= 0, it is customary 
not to assign any degree, or possibly the degree -
00 to the "0" (the zero polynomial) 
(in IB4, §2.1 and IBS, §2.11, on the other hand, we set degree 0 = 0). From the definition 
of a unit it also follows that all a E Sl, a =1= 0, and only these are units of Sl[x). 
8 Note that the existence of a unity element in (f is not postulated. Cf. §2.S, footnote 4. 

362 
PART B ARITHMETIC AND ALGEBRA 
Theorem 3: 
Every Euclidean ring is a principal ideal ring and thus a 
u.f. ring. 
In order to show that the ring (£: of of integers is Euclidean, we 
set w(x) = 1 x I, so that (I) is satisfied. As for (II), let us first assume 
o ::::;; a < 1 b I. Then a = 0 . b +- a is a division formula (II). Now let 
a ~ 1 b 1 > 0; then a and 1 blare natural numbers with the Archimedean 
property (see IBI, §3.4) that there exists a natural number n such that 
nib 1 > a. But the set of natural numbers is well-ordered by the" <" 
relation (see IBI, §1.4), so that the subset of all n with nib 1 > a contains 
a smallest number, say ql +- I; then (ql +- I) . 1 b 1 > a ~ ql . 1 b I. 
Setting q = ql . sgn band r = a -
qlb and subtracting ql 1 b, we obtain 
(4) 
0 ::::;; a -
ql 1 b 1 = r = 1 r 1 < 1 b I, 
d.h. 
a = (ql . sgn b) b +- r 
= qb +- r, 
so that (II) is again satisfied. Finally, if a < 0, then by (4) (-a) = ql 1 b 1 +- r, 
o ::::;; r < 1 b I, so that a = (-ql . sgn b) b -
r, and 
(5) 
a = qb +- (-r), 
I-rl < 1 b 1 
(q = -ql . sgn b), 
and therefore II holds in every case. In (4) the remainder is nonnegative, so 
that (4) represents a division with smallest positive remainder. We can also 
bring (5) into the same form: a = -qll b 1 -
r = -(ql +- I) 1 b 1 +-
1 b 1 -
r, where 0 ::::;; 1 b 1 -
r < 1 b 1 for r -=I=- O. 
On the other hand, we could have put (4) in a form with a negative 
remainder, and then by choosing the remainder, positive or negative, with 
smaller absolute value we obtain the division with smallest absolute 
remainder. Except when "2 1 band 1 r 1 = 
1 b/2 I", where the two possibili-
ties provide the same absolute value for the remainder, it is easy to show 
that the q and r are uniquely determined in every case. 
In the polynomial ring R[x] in one indeterminate over a field R it is 
obvious that w(f(x) = degreef(x) (f(x) E R[x], f(x) -=I=- 0) is a valuation 
satisfying (I). But the division algorithm (II) also holds, so that R[x] is a 
Euclidean ring. In order to prove (II), we must first show that for two 
polynomialsf(x) = aoxn +- ... +- an and g(x) = boxk +- ... +- bk , bo -=I=- 0 
with degree f(x) ~ degree g(x) there exists a q(x) E R[x], such that 
degree (f(x) -
q(x) g(x) < degreef(x); but it is at once clear that 
q(x) = (ao/bo) xn- k is satisfactory for the purpose. Now letf(x) and g(x) 
be arbitrary with g(x) -=I=- 0; then in the case degree f(x) < degree g(x) 
we can at once satisfy (II) with q(x) = 0, r(x) = f(x), and if degree 
f(x) ~ degree g(x), then let q(x) be so chosen that degree (f(x) -
q(x)g(x) 
is minimal, provided we do not already have the trivial case g(x) I f(x). 
If we set r(x) = f(x) -
q(x) g(x) and assume that degree r(x) ~ degree 

6 Theory of Numbers 
363 
g(x), we have already shown that there exists a ql(X) E R[x], such that 
degree (r(x) -
ql(X) g(x) < degree r(x). But then 
degree r(x) > degree (r(x) -
ql (x) g(x) 
= degree (f(x) -
(q(x) + ql(X) g(x)), 
in contradiction with our having chosen q(x) so as to minimize degree r(x). 
Thus for f(x) = q(x) g(x) + r(x) we have degree r(x) < degree g(x). 
The ring R[x] has the further property that in the division formula 
f(x) = q(x) g(x) + r(x) in (II) the polynomials q(x) and r(x) are uniquely 
determined, as can easily be shown by an indirect proof based on their 
degrees. 
The ring G:[i] of Gaussian integers (lB5, § 1.1) is also Euclidean. For 
w(a + f3i) = (a + f3i)(a -
f3i) = a 2 + f32 obviously satisfies (I) and if the 
norm (see §8.I and 188, §1.2) N(z) = zz of a complex number z = a + f3i 
is chosen as its absolute value (so that the distributivity W(ZlZ2) = 
W(Zl) . W(Z2) (188, (10) is immediately clear), then (II) is proved as follows. 
In order to find, for given Zl and Z2 -=1= 0, the q and r demanded by (II), we 
first determine a (perhaps fractional) complex number q', such that 
Zl -
Z2q' = 0, and then in q' = y' + 8' i we replace the rational numbers 
y' and 8' by the nearest integers, say y and 8. With q = y + 8i and 
Zl = qZ2 + r we then have 
N(r) = N(ZI -
qZ2) = N(ZI -
q'Z2 + (q' -
q) Z2) = N«q' - q) Z2) 
= N(q' -
q) N(Z2), 
N(q' -
q) = (y' -
y)2 + (8' -
8)2 ~ (!)2 + (l)2 < I, 
so that N(r) = N(q' -
q) N(Z2) < N(Z2), which satisfies (II). 
In the same way it can be shown that the set of numbers a + f3v2, 
{a, f3} C G:, is a Euclidean ring if we put 
w(a + f3V2) = I(a + f3V2)(a -
f3v2) I = I a2 -
2f32 I. 
In general, the set of numbers a -+- f3V S, {a, f3} C G:, where 8 E G: is not 
a perfect square, forms a ring, as is easily proved; but in general this ring 
is not Euclidean, as may be shown by the examples 8 = - 5, - 3, + 10, 
and so forth. For 8 = -5, for example, 
21 = (4 + V -5)(4 - V -5) = 3 . 7 
shows two essentially different factorizations into irreducible factors.9 
9 For details see, e.g., Hasse [3], §16. 

364 
PART B ARITHMETIC AND ALGEBRA 
A subring of a Euclidean ring is not necessarily even a u.f. ring, as may 
be seen from the ring of even numbers; it is clear that all numbers of the 
form 2u with odd u, and only these, are irreducible, and for 60 we have the 
two factorizations, 2 . 30 and 6 . 10. 
The valuation w(x) is not uniquely determined; in fact, for every fixed 
integer A > 0 the function AW(X) is easily seen to be another valuation. 
In general, it is possible to construct valuations that are not connected with 
one another in such a simple way, and for some of them it is necessary, 
in order to preserve Axiom II, to use other magnitudes in place of q and r 
in the division formula a = qb + r. Thus it is natural to ask how we can 
normalize the valuations so as to restrict them to convenient forms. In 
this direction we have10 the following theorem. 
Theorem 4: 
For a Euclidean ring <f there exist valuations w(x) such that 
associate elements have the same values; and this property is equivalent to 
the property that w(x, y) ~ w(x)/or x -=1= 0, y -=1= O. 
Proof: Let x*(x) be any valuation for which <f is Euclidean. Let a 
denote the class of all associates ofain <f. Setw(a) = w(a) = min:z:edw*(x). 
Since w*(x) is an integer, there exists an am E a such that w(a) = w*(am), 
and therefore 
(6) 
for all a"" am . 
Here Axiom I and the additional condition are obviously satisfied. Now 
let a -=1= 0 and let b be arbitrary, define am = €a (where € is a unit) as 
before and let b = qam + r be a division formula with respect to w*(x). 
If r = 0, then Axiom II with respect to a and b is satisfied 
for all valuations, since b = qam = q€ . a. For r -=1= 0 it follows from 
(6) that w(b ~ qam) ~ w*(b -
qam) = w*(r) < w*(am) = w(a); thus 
w(a) > w(b -
qam) = w(b -
q€€-lam) = w(b -
qla)(ql = q€), so that 
b = qla + r, and Axiom II is again satisfied. Only the last part of the 
theorem now remains to be proved. Let us first assume that w(x, y) ~ w(x). 
If € is a unit, we have 
w(a€) ~ w(a) = w(a€ . €-1) ~ w(a€), and therefore 
w(a€) = w(a). 
For the proof of the converse it is sufficient to show that w(ab) > w(a) 
for nonunits. Let us assume to the contrary that w(ab) ~ w(a). In the 
division formula a = q . ab + r we then have r -=1= 0, since b + I, and 
therefore w(a) ~ w(ab) > w(r) = w«1 -
qb) a); but then the strict 
inequality shows that 1 -
qb = b1 is not a unit. The same procedure 
10 H. J. Claus, Ober die Partiaibruchzeriegung in nicht notwendig kommutativen 
Ringen. Joum. f. reine u. angew. Math. (Crelle) 194, (1955), 88-100. 

6 Theory of Numbers 
365 
applied to ab1 and a in place of ab and a leads to a nonunit element b2 , 
and thus to the inequality w(a) ~ w(ab) > w(ab1) > w(ab2). Continuation 
of the procedure produces a nonterminating, strictly monotone decreasing 
series of values w(abll), in contradiction to Axiom J. 
On the basis of this theorem we may now adjoin to the Axioms I and II 
the following axiom: 
(Ill) From a ~ b it follows that w(a) = w(b), from which we may also 
assume w(ab) ~ w(a) for all a -=I=- 0, b -=I=- 0, whereby we have reached 
agreement with IB5, §2.8. 
We can state the further result: if a is a proper factor of b, i.e., a Iprb, 
then w(a) < w(b), and if w(a) = w(l), then a ~ I and conversely. 
Proof: Since b l' a, we have r -=I=-° 
in every division formlJla a = qb + r. 
If we set b = ac, then 
w(b) > w(r) = w(a -
qb) = w(a(l -- qc) ~ w(a), 
as desired. The second statement follows immediately. 
The above development of the theory of divisibility is based on the 
theory of principal ideal rings and may thus be regarded as an ideal-
theoretic- method. If we begin with a Euclidean ring <f in the first place, 
we can reach the same results by a different method, which is more 
elementary and has the advantage of being constructive, namely, by 
explicitly calculating the GCD rather than by proving its existence from 
the properties of a principal ideal. For this calculation we use the Euclidean 
algorithm in the following way. Let a and b, b -=I=- 0, be arbitrary elements 
of<f; then Axiom II allows us to set up in succession the division formulas: 
(7) 
a = qlb + r1 , 
b = q2rl + r2, 
r1 = qar2 + ra, 
rn-2 = qnrn-l + rn , 
rn-l = qn+lrn + rn+1 , 
w(r1) < w(b), 
w(r 2) < w(r 1), 
w(ra) < w(r2), 
w(rn) < w(rn_1), 
w(rn+l) < w(rn) 
The sequence is to be regarded as terminating as soon as a zero 
remainder occurs. Since w(b) > w(rl) > w(r2) > "', it follows from 
Axiom I that such a remainder must eventually occur. If we run through 
the algorithm (7) from the first line down to the last, we see that every 
common divisor of a and b is a divisor of all the rll (l ~ v ~ n + I), 
and on the other hand, if we run through (7) from the last line up to the 
first, assuming rn+1 = 0, we have rn I rn-l' rn I rn-2, ... , rn! b, rn I a. 
Taken together, these results show that the last nonzero remainder rn 
is the common divisor of greatest absolute value, a property which, on the 

366 
PART B ARITHMETIC AND ALGEBRA 
basis of Axiom III, can be used as a definition of the GCD, for which 
we now have the following theorem. 
GCD Theorem: Every common divisor is a divisor of the GCD. 
It is easy to prove that (ai, a2 , ... , an) = «ai, a2 , ... , an-I), an) and also 
that the GCD theorem holds for arbitrary n ~ 1 (cf. the last paragraph 
of §2.7). 
Finally, if we begin at the next-to-Iast equation in (7) and work 
backwards, we obtain a representation of the form (a, b) = rn = axo + byo. 
Then the fundamental lemma, and with it the u.f. theorem, can be proved 
in exactly the same way as for principal ideal rings. 
In analogy with the GCD, we can now define an LCM [ai, a2 , ... , an] 
as a common nonzero mUltiple ofleast absolute value, for which we obtain 
the following theorem: . 
Theorem of the LCM: For every common multiple VI we have 
v = [ai' a2 , ... , an] I VI . In particular, all the LCM's are associates. 
Proof: 
We apply the Euclidean algorithm to V, VI and obtain the 
GCD (v, VI) = d. From the minimal property of w(v) and from d I V it 
follows that w(d) = w(v), so that d 1'prv; that is, d ~ v, and thus, in view 
of d I VI , we have at once V I VI' 
Finally, we must mention a third way of constructing the theory of 
divisibility in Euclidean rings, namely by first proving the u.f. theorem, 
i.e., without using the concept of the GCD, and then defining the GCD and 
LCM by (2). But in order to obtain the important representation of the 
GCD (ai' a2 , ... , an) as a sum of multiples alxl + a2x2 + ... + anXn , 
we must then proceed either by way of the principal-ideal-property (if we 
are satisfied with proving the existence of the desired representation) or 
else by way of the Euclidean algorithm. 
In order to prove the u.f. theorem directly (i.e, without using the GCD) 
we require a sharpening of. the above Axiom III, 11 which will also be 
necessary for the discussion of partial fractions in 2.11 below. In place of 
Axiom III we now require the following axiom: 
(III') From w(a) < w(b) it follows that w(ac) < w(bc) for all c *- 0, and 
conversely. 
Corollary 1: from w(a) = w(b) it follows that w(ac) = w(bc) for all 
c *- 0, and conversely. 
11 No immediate proof of the u.f. theorem is known at present without this sharpening 
of Axiom III. It is possible that all Euclidean rings are no longer included; however, up 
to the present no known Euclidean rings fail to satisfy the new requirement. Thus it 
would be of interest to know whether a theorem analogous to Theorem 4 is valid. 

6 Theory of Numbers 
367 
Corollary 2: from III' follows III. 
Corollary 3: from w(a) < w(b) andw(c) < w(d)follows w(ac) < w(bd). 
Proof: 
Corollary 1 is easy to prove indirectly. As for corollary 2, it is 
sufficient by theorem 4 to prove that w(ab) ~ w(a). But if we had 
w(ab) < w(a) = w(a . I), it would follow that w(l) > w(b) and thus 
w(b) = w(l . b) > w(b2), and then w(b2) > w(b3), and so forth; but the 
chain w(l) > w(b) > w(b2) > ... would be in contradiction to I. Corollary 
3 follows from w(ac) < w(bc) < w(bd). 
Proof of the u.f. theorem in Euclidean rings under the assumptions I, II 
and IlI.12 We make the induction hypothesis that the theorem is true for 
all x with w(x) < w(a) and assume the existence of an a contradicting 
the assertion. Now let p ~ 1 be a divisor of a with the smallest possible 
value, from which it follows that p is irreducible. Let a = bp. Since p ~ 1, 
we have b ipra, and thus w(b) < w(a), so that b has a canonical factori-
zation, and a has at least one factorization (I). Let q ~ 1 be an irreducible 
factor of the second (assumed) factorization (I) of a, with a = qc. The 
two factorizations cannot have associated irreducible factors, since by 
cancellation of such factors we would obtain an element of smaller value 
than w(a), which would therefore, by the induction hypothesis, have a 
unique factorization (I). Consequently, the original factorizations of a 
cannot, after all, be different from each other. In a = pb = qc we now 
insert the division formulas q = qlP + rl and c = q2P + r2, with 
r1 -=I=- 0 and r2 -=I=- 0, since p ~ q and p l' c. We thus obtain: 
From the minimal property of p it follows for the division remainders that 
and thus by Corollary 3: 
w(rl) < w(P) ~ w(q), 
w(r2) < w(P) ~ w(c), 
so that r1r2 has a unique factorization. Since w(ri) < w(p) (i = 1, 2), the 
factor p cannot occur in this factorization, but by (8) we have p I rlr2 , 
which provides the desired contradiction.13 
12 See H. Klappauf, Beweis des Fundamentalsatzes der Zahlentheorie. Jahres-
bericht DMV 45, 130 Kursiv. The first proof was given by Zermelo. 
13 In this form of proof by induction it is unnecessary to prove the initial statement 
(although its correctness for all a -- 1, i.e., w(a) = wet), is obvious, since units are 

368 
PART B ARITHMETIC AND ALGEBRA 
If 9l is merely a u.f. ring, then on the basis of the fact that .Q(9l)[x] is 
Euclidean and is thus a u.f. ring, it can be shown (see IB5, §2.14) that 
9l[x1] = 911 is also a u.f. ring (Gauss). By successive application of this 
theorem, the same result follows for 9l1[x21 = 9l[Xl' x2], 9l[Xl , X2 , xs], •.. , 
as was mentioned at the end of §2.6 (see also IB5, §2.14). 
If now in the field P of rational numbers we consider the set IDl of all 
fractions sit, {s, t} k <r:, 3 l' t, it is easy to show that IDl is a ring, a so-called 
quotient ring. All sit with (s,3) = (t,3) = 1 form the group of units. 
Apart from associates, the only prime element is 3, and it is clear that every 
number in IDl can be represented uniquely in the form dOl (where £ is a 
unit) and ex ~ 0 is an integer. With the definition w( £3(1) = ex, it is 
easy to show that IDl is Euclidean, and to generalize to the case of more 
than one prime element. On the other hand, it is clear that the assumptions 
for the Euclidean theorem (see §2.6) hold for the rings <r:, <r:[i], R[x] (where 
R is a field). 
2.11. 
Decomposition into Partial Fractions in Euclidean Rings 
We now assume that <f satisfies the Axioms I, II and III'. Let.Q = .Q(<f) 
be the quotient field of <f. Those elements u E .Q that are also in <f are called 
integers. Also, u = alb ({a, b} k <f) is said to be a proper fraction if 
a = 0 or w(a) < w(b). It is a consequence of III' that the property of being 
a "proper fraction" is invariant14 under cancellation or under multiplication 
of numerator and denominator by the same number. 
If a and b are integers with (a, b) = I, then alb is called a partial 
fraction if and only if b = 1 or w(a) < w(b). 
If sand t are integers with (s, t) = I, and if t = f1~=o qp, where the qp are 
coprime integers, and qo = I, then 
(9) 
(ap integers) 
is called a decomposition into partial fractions (abbreviated DPF) of the 
always irreducible): for if the correctness of the statement A(x) for all x < n implies 
the correctness of A(n) (n;> 1), then A(n) holds for all natural numbers n, since the 
correctness of A(1) is now included in the proof: i.e., the induction hypothesis is true 
because it consists of the (empty) statement" A (x) holds for all a < 1," which is certainly 
not false (cf. IBl, §1.4). But if for the argument by induction it is necessary that there 
should exist an Xo < n for which A(xo) is correct, then the above form of proof by 
induction cannot be applied. 
U Under Axioms I, II, III alone it is easy to construct valuations in <r for which this 
invariance no longer holds (see Ostmann, Euklidische Ringe mit eindeutiger Partial-
bruchzerlegung, Joum. f. reine u. angew. Math. (Crelle) 188 (1950) 150-161. 

6 Theory of Numbers 
369 
firstform, if all the ap/qp are partial fractions. If t = f1~=1 P~P is a canonical 
factorization, then 
(10) 
with all the ap« integers, w(apK) < w(Pp) or apK = 0, is called a DPF of the 
second form. 
Theorem: Every K E .Q(<f) has DPF's of both forms. 
Proof: As for (9), it is sufficient to consider the case r = 2. 
Since (ql' q2) = 1, there exist in <f two elements Xo and Yo such 
that 1 = qlXO + q2YO ; thus 
~ = SqlXO + Sq2YO = sXo + syo . 
t 
qlq2 
q2 
ql 
But now from the division formulas syo = a~ql + a1 , sXo = a~q2 + a2 , 
with a~ + a~ = ao, we deduce (9) as follows: from (s, t) = 1 we have 
(sxo , q2) = (sYo, ql) = 1, since otherwise qlq2 = t would not be the least 
common denominator; thus we must also have (ai, qi) = 1 (i = 1,2). To 
obtain (10) we start from (9) with qp = 
p~P. If in ap/p~p we insert the 
division formula ap = bppp + ap). ,we have 
p 
where ap). /p~p is already a partial fraction. By successive application of 
this pro~dure to the first summands on the right, we finally obtain (10). 
For example, 1/12 = 1/3 . 4 has four DPF's of the first form: 
-h = 1 -
1- = -1 + 1 + ! = 1 - i -
1- = -1 + ! ; 
on the other hand, it is easy to show that for <f = R[x] both these DPF's 
are unique in .Q = R(x), if we take w(f(x) = degreef(x).15 
The DPF's in Sl(x) have a well-known application to the integration of 
rational functions. As a geometric application of the DPF's in the field 
.0([:) = P of the rational numbers, let us mention the construction of a regular 
n-polygon with composite n of the form n = 2a.Qlq2 .•• q. , 0: ~ 0, where the qi 
are odd and pairwise coprime, and the regular q.-polygon is assumed to be 
15 On the existence of a division algorithm in .R[x] with respect to other valuations 
and for OPF's in general, see the references in footnotes 10 and 14. 

370 
PART B ARITHMETIC AND ALGEBRA 
constructible with rules and compass (e.g., the I5-polygon). In order to construct 
the angle 21T/n = 21T[1/(2exql ... q.)] we construct the DPF of the first form lin: 
(11) 
21T 
( ao 
al 
a. ) 
21Tao 
21Tal 
21Ta. 
-=21T -+-+ ... +- =-+-+ ... +-. 
n 
2ex 
ql 
q. 
2ex 
ql 
q. 
Since the au (a = 0, 1, ... , s) are integers, the angles 21T/Qu I au I (a = 0, 1, ... , s; 
qo = 2ex) are constructible by hypothesis, and thus we can also construct the 
angle 21T/n (see also the last paragraph of §2.12.). 
2.12. 
Number of Divisors, Sum of Divisors; 
Certain Special Types of Numbers 
Let m be a u.f. ring and let ~ be a system of representatives of the 
classes of associate prime elements, excluding the class of units. If n E m 
has the canonical factorization n = €nt=l pC;;, Pi E~, then the divisors 
of n obviously have the form 7J nt=l pfi, 0 ~ f3t ~ (Xi, where 7J is a unit. 
By a normalized factor d of n with respect to ~ we mean ad = nt=l pTi, 
o ~ f3i ~ (Xi , and the symbol Ld/n means that d runs only through the 
normalized factors. In the ring <r:, unless otherwise noted, the set of prime 
numbers > 1 (see §2.6) will always be taken for ~, so that in this case 
d runs through all the positive divisors of n. 
We now define the function 
(12) 
Gk(n) = L dk 
(k real). 
din 
For k = 0 we obtain the number of divisors Go(n) = T(n), and for k = 1 
the sum of the divisors G1 (n) = G(n). The values of these functions are 
given by 
s 
(13) 
T(n) = n «(Xi + 1), 
(k *- 0). 
i-I 
Proof: 
Since there are exactly 
(Xi + 1 possibilities for the f3i in 
d = nt=l pfi the stated value of T(n) follows at once by complete induction. 
Furthermore, 
exl 
ex2 
ex. 
L dk = 
L 
p~{Jlp~{J2 ... p~{JB = L L ... L p~{Jl ... p~{J. 
din 
{Jl=O ..... exl 
{Jl=O {J2=O 
{J.=O 
= n f p~{Ji = n (l + Pik + (Pik)2 + ... + (Pik)ex;) 
i=l {Ji=O 
i=l 
as the sum of a geometric progression if k *- O. 

6 Theory of Numbers 
371 
By (13) we have at once: 
(14) 
From 
(Ul ' U2) = Ifollows 
ak(UIU2) = ak(U1) • ak(U2) 
(k real). 
In general, a function f(x) is called multiplicative if (x, y) = 1 implies 
f(xy) = f(x)f(y), and distributive if this functional equation holds for 
arbitrary x, y. Thus the function ak(n) is multiplicative. 
Also, a function F(x) is called the summatory function of f(x) if 
F(x) = Lal:cf(d). 
It is easy to see that if f(x) is multiplicative, then so is F(x). 
In (£: a positive number is said to be K-perfect if a(n) = Kn, K-deficient 
if a(n) < Kn, and K-abundant if a(n) ~ Kn; and for K = 2 the given 
number is simply called perfect, deficient, and abundant, respectively. For 
example, 6, 28, 996, and 8128 are perfect, 4 is deficient, and 12 is abundant. 
For K-perfect numbers K is necessarily rational. 
Since a(l) = 1 < 2 and a(p) = p + 1 < 2p, the prime numbers 
p(p > 1) are deficient; and since 1 is the sole I-perfect number, only the 
case K > 1 is of interest. It is easy to show that every multiple of a K-
abundant number is K-abundant. 
Theorem 5 (Euclid-Euler): Ifn is even andperfect, then n = 2P(2 p+1 -
1), 
p > 0, and 2p+1 -
1 = p is a prime number (Euler), and conversely every 
such number is an even perfect number. 
Proof: 
Since n is even, we may set n = 2pu (with u odd). Then if n is 
perfect, 
a(n) = a(2pu) = a(2p) a(u) = (2p+1 -
1) a(u) = 2n = 2p+1u, 
so that 2p+1 I a(u), and thus a(u) = 2P+IA, A ~ 1. Consequently, 
2p+1u = (2p+1 -
1) a(u) = (2p+1 -
1) 2p+IA, 
i.e., u = (2p+1 -
1) A, 
and thus, since p > 0, we have a(u) ~ (2p+1 -
1) A + A = 2p+IA = a(u), 
so that the equality sign must hold, and u has exactly two factors; there-
fore u is prime and A = 1; i.e., u = 2p+1 -
1. The converse follows at 
once from 
a(n) = a(2pp) = a(2P) a(p) = (2P+1 -
I)(P + 1) 
= p . 2p+1 = 2 . 2p • p = 2n. 
(since p > 0) 
Numbers of the form 2n -
1 are called Mersenne numbers. Since 
2ab -
1 = (2a)b -
1 = (2a -
1)(1 + 2a + ... + 2a(b-I»), 
we have the 
following theorem: 
Theorem 6: 
A number 2p -
1 can be a Mersenne prime only ifp is prime. 

372 
PART B ARITHMETIC AND ALGEBRA 
Thus the search for even perfect numbers is reduced to the search for 
Mersenne primes. It is still an open question whether odd perfect numbers 
exist and also whether there are infinitely many Mersenne primes. 
Still less is known about amicable numbers,16 i.e., pairs a, b with 
a(a) = a(b) = a + b, or in other words Ldla,d<a d = b, Ldlb,d<b d = a. 
Example: 220, 284. 
From the factorization 
aU + bu = (a + b)(aU-1 - au- 2b + ... - abu- 2 + bU-1) 
for odd u we have at once the following theorem: 
Theorem 7: 
The number 2n + 1 can be prime only if n = 211 (v ~ 0). 
Numbers of the form 22" + 1 are called Fermat numbers or Gauss numbers 
or, if prime, Fermat (or Gauss) primes. For v = 0, 1,2, 3,4 we have the 
primes 3,5, 17,257,65537, but no further primes of this form are known. 
At least v = 5 is not a prime, in view of the fact that 641 I 225 + 1 (Euler). 
In any case, (22" + 1, 221£ + 1) = 1 for v -=I=- 1-'. 
As a supplement to the last paragraph in §2.11, let us mention the following 
theorem of Gauss: a regular p-polygon, where p is a prime number, is constructible 
with ruler and compass if and only if p is a Gauss prime; and all constructible 
n-gons are obtained by replacing the q, in (11) with Gauss primes. 
3. 
Continued Fractions 
3.1. 
By the Euclidean algorithm §2 (7) the fraction alb admits the 
representation: 
(15) 
16 For a detailed account of amicable numbers, see A. Wulf: Die befreundeten Zahlen 
nebst einem Ausblick auf die vollkommenen und aliquoten Zahlen. Gottingen, 1950, 
hectographed. 

6 Theory of Numbers 
373 
In general, a fraction of the form 
(16) 
bo + ____ 
a...=.I ___ = bo + ~ + ~ + ... 
b 
a2 
I b1 
I b2 
1 + -----=-
b 
as 
2 + bs + 
is called a continued fraction, the ai are the partial numerators, the bi the 
partial denominators, and bo is the first term. If all ai = 1, all bi are 
rational integers, and bi > ° for i > 0, then (16) is called a regular 
continued fraction. Such a fraction can obviously be normalized so as to 
make the last partial denominator greater than unity. In the present 
section we shall always assume that this has been done. The notation 
1 
bo + -b
1-+---- = [bo , b1 , ••• , bnl 
+1. 
bn 
is in common use. For convenience in the statement of proofs, it is often 
desirable to arrange that the b" are real and positive and to include this 
property in the definition of the symbol. Then we can show at once that 
for n ~ I 
I 
(17) 
[bo , bI , ... , bnl = bo + [b
1
, ••• , bnl = [bo , [b1 , ••• , bnll, 
[bo , b1 , ••• , bnl = [bo , ••• , bn- 1 + -i-] (recursion formula). 
n 
From the fact that 
[bo + b~ , b1 ' ••• , bnl = b~ + [bo ' b1 ' ••• , bnl 
we see that without loss of generality we can confine our attention to 
continued fractions for which bo ~ 0, as will be assumed throughout the 
present section. The reduced fraction 
(18) 
~ = [bo , b1 , ••• , bJ, 
" 
v = 0, 1, 2, ... , n, 
is called the vth convergent, A" is the vth partial numerator, and B" is the 
vth partial denominator. Obviously Ao = bo , Bo = I. For convenience we 
also introduce 
(19) 

374 
PART B ARITHMETIC AND ALGEBRA 
Then we have the fundamental linear recursion formulas: 
(20) 
(v ~ 0) 
and the identity 
(21) 
(v ~ -1). 
Proof: For v = 0 the formulas (20) follow from (19). If (20) holds for 
v-I (v ~ 1), then by the second equation (17), again assuming that the 
bi are real and positive, 
_ b,lb,,-IA"-2 + A,,-3) + A,,-2 _ b"A,,_1 + A,,-2 
-
b,,(b"_IB,,_2 + B"-3) + B,,-2 -
b"B,,_1 + B,,-2 ' 
where the last equation follows from the induction hypothesis. In order 
to show that for integral bi the last fraction is already reduced, we consider 
the A" , B" as defined recursively by (20) and (19). Again the last equation 
holds, and (18) follows from it by induction; so it remains to prove (21). 
But for v = -1, (21) follows from (19), and by complete induction 
which is (21), as desired. For integral bi we at once have (A", B,,) = 1, 
so that the fractions (A"IB,,) are reduced. 
As an estimate for the B", it follows from Bo > 0, BI = bl ~ 1, 
B2 = b2bl + I ~ 2, by complete induction for v ~ 3, that 
B" = b"B"_1 + B,,-2 ~ V -
I + v -
2 = v + (v -
3) ~ v, 
and thus 
(22) 
for all 
v ~ O. 
If we now define the nonterminating regular continued fraction 
[bo , bl , b2 , ... J as the sequence of partial quotients (Ani Bn) = [bo, bl , ... , bn], 
we have the following theorem. 
Convergence theorem: 
Every non terminating regular continued fraction 
is convergent. 

6 Theory of Numbers 
375 
Proof: Since 
it follows that L:I [(AJBII) -
(AII-1/BII-1)] is absolutely convergent, and 
thus also convergent. 
For the proof of the following theorem we need a slight generalization 
of the Euclidean algorithm for real numbers. For every real number p we 
let [p] denote the greatest integer g ~ p, g = [P] ~ p < [p] + 1. Such a 
g always exists, since the field of real numbers has an Archimedean 
ordering (see IBI, §4.I), which means that for every real p ~ 0 there 
exists a natural number n such that n . I > p. In the set of all such n there 
is a smallest, which we put equal to g + 1. Then obviously g = [Pl. For 
a negative nonintegral p we have [p] = -([ -p] + I) with the desired 
properties; for an integer p it is clear that [p] = p. In the division with 
smallest positive remainder for the ring G:, say a = qb + r with 
p = alb = q + rib, we have q = [p], since 0 ~ rib = 8 < I, and 
therefore p = [p] + 8, 0 ~ 8 < I. From the definition of [P] it 
is clear that every real p admits such a formula, which is the desired 
generalization. 
Expansion theorem: 
Every real number can be expanded in exactly one 
way as a regular continued fraction. 
Proof: Set bo = [p] and p = bo + IITJI; thus TJI > I if p is not 
already an integer. Furthermore, let TJo = p, bl = [TJI], TJI = bl + IITJ2' 
so that 
proceeding in this way we obtain a sequence, terminating or nontermi-
nating, of integers bll such that 
(23) 

376 
PART B ARITHMETIC AND ALGEBRA 
From (20) and (21) for v > 1 it follows in the nonterminating case 
from which we see at once that lim_tO A,,-I/ B,,-1 = p, so that 
p = [bo , b1 , ... ]. With respect to the uniqueness, we note that for (23) 
we have in the terminating case 
o ~ v ~ n, 
and in the nonterminating case 1}" = [b" , b,,+1 , ... ], v ~ 0, so that 1}" > 1 
for all v ~ 1 (where in the terminating case we must take account of the 
normalization bn > 1). Thus in 1}" = [b", 1}"+1] = b" + 1/1}"+1(v ~ 0) we 
necessarily have b" = [1},,], so that b" is uniquely determined by 1}" ; in 
particular, bo is uniquely determined by the value 1}o = p. If we now 
assume the uniqueness of the numbers bo , b1 , ... , b,,-1 , then by (23) 1}" is 
also uniquely determined and thus, as we have just seen, so is b" . 
Since by (15) rational numbers have a terminating continued fraction, 
the preceding theorem gives us this result: terminating regular continued 
fractions represent rational numbers, and non terminating continuedfractions 
represent irrational numbers. 
From (21) it follows from division by B"_IB for v ~ 1 that 
A" 
A,,-1 _ (_1)11-1 
B" -
BII-l -
B.,B,,-1 ' 
so that the sequence of first differences of the sequence A) B" is 
alternating; taking into account the inequalities 
for 
v ~ 2 
and 
v = 0, 
for all 
v ~ 0, 
which show that I/B"_IB,, is strictly decreasing, we see from 
~: = bo < [bo , b1 , ... ] = k 
that 

6 Theory of Numbers 
377 
The recursion formulas (20) provide us with a simple setup for practical 
calculation of the partial quotients (A)B,,) of [bo , bl , ... ]: 
v I -2 I -1 I 0 I 
Iv-2Iv-1\ 
v 
~, -;;! -;- I !: I 
B.. 
1 I 0 
I 
1 
The last two lines are calculated, independently of each other, by the same 
rule (see the last column). For example, if we wish to calculate 
'T1' ~ 3.14159265358, the Euclidean algorithm gives 'T1' = [3, 7, IS, I, 292, 
I, I, I, ... ]; and the corresponding setup is: 
v 1-21-11 
0 
I 
2 
3 
4 
b" -1-
3 
7 
I 
15 
1 
292 
A" o I 1 
3 
I 
22 
333 
355 
103993 
BII 
~I~ 
7 
106 
113 
33102 
I 
I 
Error: ti" 
+ 1,4 . 10-1 
I -10-8 I +0,8 . 10-' 
-2,7 . 10-7 
+0,6' 10-9 
Here the well-known approximations 3, ¥ ... stand one under the other. 
It is remarkable that the slight increase from A2 to A3 and B2 to B3 produces 
a considerable improvement in the accuracy, whereas the far greater 
increase involved in passing from v = I to v = 2 and from v = 3 to 
v = 4 fails to produce any correspondingly great improvement in the 
approximation. This phenomenon finds its general explanation in the 
formula (24). With the increase of TJ" and therefore of b" , the approxima-
tion A"-l/ B,,_l is improved. 
3.2. One of the essential properties of the above partial quotients of a 
number k rests on the fact that among all rational numbers these partial 
quotients best approximate the number k, in the sense of the following 
definition: p/q is called a best approximation to k if from 
and 
it follows that b > q. 
In other words, in order to make a better approximation than the above-
defined best approximation, we must have recourse to larger denomina-
tors.17 Now we can show that all the partial quotients AJB" are best 
approximations to k. In order to find all the best approximations to k, we 
17 The problem of finding best approximations is of practical importance in the 
technology of power machinery, where the. gears should approximate a given trans-
mission ratio as closely as possible, but with the smallest possible number of cogs. 

378 
PART B ARITHMETIC AND ALGEBRA 
must also consider the so-called subsidiary partial quotients (the AJ B" 
are then called the AJB" principal partial quotients) 
N 
-
AA-2 + pAA-l 
A,p -
BA-2 + pBA- 1 ' 
p = 1, 2, "" bA- 1 ' 
It is easy to show that the NA,p lie in the open interval [(AA-2/BA-2), (AA/BA)] 
and change monotonically for p = 1, 2, .. " bA- 1 (A ~ I), Then those NA,p 
for which 
I k -
AA-2 ! > I k -
NA,p I > I k -
AA-l I 
BA- 2 
BA- 1 
are certainly not best approximations, since the AA-l/BA-l are better 
approximations and have a smaller denominator, More precisely, it can 
be shown (see Perron [3]) that we obtain 
for p < .J;;bA no best approximations, 
for p > !bA best approximations, 
and for p = i-bA a best approximation if and only if 
[b,\ , bA- 1 , .. " b1] > [bA , bA+1 , .. ,]. 
3.3, 
A continued fraction k = 
[bo, b1 , .. ,] is said to be periodic if 
there exist two numbers nand p such that bnH'P+K = bn+K for all A ~ 0 
and all K = 0, 1, p -
1; in analogy with the notation for periodic decimals 
we then write k = [bo, ... , bn- 1 , bn , .. " bn+p- 1], If the choice of p and n is 
minimal, p is called the (primitive) period and [bo, b1 , .. " bn- 1] the 
preperiodic part; if this latter part is missing, we speak of a purely 
periodic (or simply periodic) continued fraction. The following theorem 
is due to Euler: 
If the continued fraction expansion of a number k is periodic, then k is the 
solution of a quadratic equation which is irreducible in P[X]18 and has integral 
coefficients (in other words, k is a quadratic irrationality, i.e" an algebraic 
number of second degree). 
Proof: Every real quadratic irrationality has the form (a + Vb)/c 
(a, b, c integers, b > 0, b not a perfect square), and conversely every 
number of this form is a quadratic irrationality. Thus it is sufficient to 
show that a purely periodic continued fraction 'YJn = [bn , ... , bn+p- 1] is a 
quadratic irrationality; in other words, we assume n = O. But then 
'YJp = [bp, ... , b2P- 1] = [bo, .. " bp- 1] = 'YJo = k 
[b 
b 
] 
'YJpAp-l + Ap-2 
kA p_1 + Ap-2 
= 
0 , ... , p-l' 'YJp = 
B 
+ B 
= kB 
f- B 
' 
'YJp p-l 
p-2 
p-l -
p-2 
18 P is the field of rational numbers. 

6 Theory of Numbers 
379 
so that k is the solution of the equation 
B p_ 1X 2 + (Bp_2 -
Ap- 1) x -
A p- 2 = O. 
Of great importance is the converse of this theorem, due to Lagrange 
(see Perron [2], [3]): 
Every quadratic irrationality has a periodic continued fraction expansion. 
3.4. A generalization of periodic partial fractions is due to Hurwitz. 
Let each of the I rows 
a~l), a~l), .. . 
a~2), a~2), .. . 
(25) 
be an arithmetic progression of arbitrary order. Then 
[b 
b 
b 
(1) 
(2) 
W]OO 
0' l' ... , n-1' ap ,ap ,"" ap p-1 
is called a Hurwitz continued fraction. If all the sequences in (25) have the 
order zero, in other words, if they are sequences of constants, the result is 
obviously a periodic partial fraction. The following theorem is due to 
Hurwitz (see Perron [2], [3]): 
For numbers 7J and ~ related by 
a~ + b 
7J = c~ + d' 
ad -
bc -=I=- 0; 
a, b, c, d rational,19 
if ~ is a Hurwitz partial fraction, so also is 7J and conversely; moreover, the 
number of arithmetic progressions of nth order for every n > 0 is the same 
in both cases. 20 
As an example of a Hurwitz continued fraction let us consider 
k = [(2n + 1) b]:=l = [b, 3b, 5b, ... ]; 
here we have 
19 By taking the fractions over a least common denominator, we may confine ourselves 
to rational integers a, b, c, d. 
20 Here it may be necessary to break up a sequence al , a2 , "', say into a1 , a8 , ar. , ... 
and a2 , a, , a6 , ... and so forth. Constant sequences may be inserted or removed. 

380 
PART B ARITHME.TIC AND ALGE.BRA 
taking b = 2, we see from the preceding theorem that e also has an 
expansion in Hurwitz continued fractions; we have 
e = [2, 1, 2n, 1]:-1 = [2, 1, 2, 1, 1, 4, 1, 1, 6, 1, ... J. 
The regular continued fraction expansion for 'TT' is unknown. On the other 
hand, 
or 
21 
2·31 
1'21 
4·51 
3'41 
6'71 
5'61 
'TT' = 2-------------------- - ... 
13 
11 
13 
1 1 
13 
11 
13 
are expansions in the form (16) (see Perron [3]). 
4. ,Congruences 
4.1. 
Let ffi be an Abelian group (see IB2, §1.1), and let U be a subgroup 
of ffi. As was shown in IB2, §3.5, every group ffi can be represented as the 
union of disjoint co sets (residue classes) gUo The property of two elements 
gl , g2 of belonging to the same coset is obviously an equivalence relation. 21 
This relation is called a congruence and is written 
(26) 
in words: gl is congruent to g2 modulo U. From gl E g2U follows the 
existence of a u E U such that gl = g2U, and therefore K";lgl = u, or in 
other words K";lgl E U; and conversely, g;lgl E U implies that gl == g2(U) 
or, in other words, if e is the unity of ffi, we have g;lgl == e(U). Since ffi 
is Abelian, it follows from g;lgl E U and g"41gs E U that g;lgl . g"41gs = 
(g2g,)-1 gIgS E U, i.e., gIgS == g2g,(U); in other words: congruences 
gl == g2(U) and gs == g,(U) may be multiplied, and naturally also divided. 
If the operation of the group is written as addition, i.e., if ffi is a module, 
then (26) is obviously equivalent to gl -
g2 E U or gl -
g2 = 0 (U), and 
then the congruences can be added and subtracted. 
If ffi is the additive group of a ring 9l, ffi = 9l+, and if the sub module 
U is an ideal a in 9l+, we have the following theorem: 
Theorem 1: 
Congruences mod a may be added, subtracted, and 
multiplied. 
21 That is, it is reflexive, symmetric, and transitive (cr. lA, §8.3 and §8.5). 

6 Theory of Numbers 
381 
Proof: Let a1 == a2(a) and as == a4(a); from a1 -
a2 E a and as Emit 
follows [see §2.5. (II)] that (a1 -
a2) as E a, so that alaS == a2aS(a); 
similarly, a2aS == a2a4 (a) and therefore, by the transitivity, alaS == a2a4 (a). 
If a = (m) is a principal ideal, we also write a == b (mod m), or a == b (m). 
In this case, assuming again that m has a unity element, the congruence 
is also equivalent to m I (a -
b), or in other words to the existence of a 
" E m with a = b + Am. In particular, if m is Euclidean (see §2.10), the 
division formula a = qm + r shows that a == r(m), so that numbers are 
congruent if and only if they leave the same remainder when divided by the 
modulus. From the equality of the ideals (m) = (€m) for every unit € it 
follows that the congruences a == b(m1) and a = b(m2) are equivalent if 
m1 "" m2' Finally, a == b (mod 1) is trivially true for arbitrary a, b. If 
a = (0) is the zero ideal, then a == b(O) is equivalent to a = b, as can be 
seen at once. 
Theorem 1 can be interpreted in another way. If we consider the residue 
classes mod a as elements of a new set, to be denoted by m/a (read m with 
respect to a), then m/a is a ring, for which we can define the sum of two 
............... 
A. 
residue classes a, b as a + b = a + b, and the product by ab = ab, with 
a E a, bE b. Then theorem 1 states that these definitions are independent 
of the choice of the elements a and b from a and b. The axioms for a ring 
can be verified at once (cf. IB5, §3.6). In the terminology of group theory, 
the additive group m/a+ is precisely the factor group (or factor 
module) m+/a (see IB2;,§6.3). The ring m/a is called the residue class ring 
modulo a. The mapping a ---+- a is a ring homomorphism (see IB5, §3.6). 
Ifwe choose one element from each residue class, the set of these represen-
tatives is called a complete residue system mod a. For example, 
{O, I, ... , m -
I} and {O, -I, -2, -3, ... , -(m -
I)} are complete residue 
systems mod m in the ring <£:, the former being called the smallest positive 
residue system. In general, residue class rings have divisors of zero; for 
example, ~,~ are divisors of zero in <£:/(6), since 2· 3 == 0(6), i.e., 
~ . ~ = 0. Below we shall also write a mod m instead of a. 
4.2. 
Let m be a principal ideal ring (see IB5, §3.4). Then: 
From a == b(m)follows (a, m) = (b, m). 
Proof: As was shown in 4.1, the congruence a == b(m) is equivalent to 
an equation of the form a = b + Am. It follows that (a, m) I band 
(a, m) I m, so that (a, m) I (b, m); similarly, (b, m) I (a, m) and thus 
(a, m) = (b, m). 
The element (a, m) = d is called the greatest divisor of the residue class 
a = a mod m. If d = I, the class a mod m is called a (relatively) prime 
residue class mod m. A system o/representatives of the prime residue classes 
mod m is called a reduced residue system mod m. 

382 
PART B ARITHMETIC AND ALGEBRA 
If m is a prime element, the nonzero residue classes coincide with the 
prime residue classes. 
Theorem 2: 
In a principal ideal ring b the prime residue classes mod m, 
with arbitrary m, form a group ffim , the prime residue class group mod m. 
Proof: If a mod m and b mod m are prime residue classes, then 
(a, m) = (b, m) = I, so that (ab, m) = I, i.e., ab mod m is also a prime 
residue class. Thus we need only show the existence of a residue class 
inverse to a mod m. From (a, m) = 1 follows the existence of elements 
Xo ,Yo in b such that axo + myo = I, and thus axo == 1 (m), so that 
Xo mod m is the desired inverse residue class. 
In (£: the group ffim obviously has finitely many elements; the order 
I ffim I of this group is denoted by cp(m) and is called the Euler function. 
Theorem 2 states only that the congruence ax == b(m) is solvable for a 
and b prime to m. But if(a, m) = I, the congruence ax == b(m) is uniquely 
solvable for arbitrary b; for it is obvious that bxo mod m is a solution if 
Xo mod m is inverse to a mod m, and from aXI == aX2 == b (m) follows 
a(xi -
X2) == O(m), so that m I (Xl -
X2), i.e., Xl mod m = X2 mod m 
(see also §7.2). 
If the order I ffim I of the prime residue class group ffim is finite, the 
group-theoretic theorem that the order of a subgroup is a factor of the 
order of the group (see 182, §3.5) provides us with the (generalized) lesser 
Fermat theorem: 
From (a, m) = 1 follows a llDml == 1 (m). 
Proof: The element a mod m = 0 E ffim generates the cyclic subgroup 
(0) = {o, 02, ... , Ok-I, Ok = T}; for its order k we have k II ffim I, so that 
O/lDm / = i or, written as a congruence, a/lDm / == 1 (m). 
The number k is also called the order of the element 0, or of a mod m.22 
We have just now, and also earlier, made use of the obvious but essential 
fact that congruences between numbers of the original ring b are equivalent 
to equations between residue classes. When we are passing from equations to 
congruences, we may choose arbitrary representatives of any given residue 
class, in view of the fact that by theorem 1 the sum, and product of residue 
classes are independent of the choice of representatives; in other words: 
in a congruence any element of the ring may be replaced by any element 
congruent to it (when speaking of a power an we must of course consider 
n not as an element of the ring but as an operator). 
In the ring (£: the Fermat theorem obviously has the form 
ttP(m) == 1 (m), 
if (a, m) = 1. 
22 Instead of "a has the order k mod m," it was customary in the older literature on 
the ring (£: of integers to say "a belongs mod m to the exponent k." 

6 
Theory of Numbers 
383 
In particular, if m = p -=I=- 0 is a prime, we have all- l == 1 (P) for p l' a; and 
thus for all a without restriction, 
aP == a(p), 
a an arbitrary integer, 
which for p l' a is equivalent to aP- l == 1 (P), since in a congruence we may 
always cancel any number prime to the modulus (i.e., the inverse residue 
class exists). 
If a mod m is a nonprime residue class, so that (a, m) = d tf.; 1, and if 
we set a = aId, m = mId, we have 
i.e., every nonprime residue class is a divisor of zero in Sj/(m) and thus has 
no inverse. Since the prime residue classes coincide with the elements of 
Sj/(m) that are not divisors of zero, we have the result: 
In Sj/(m) an element has an inverse if and only if it is not a divisor of zero. 
4.3. 
Now let the module be a prime element p in Sj. Then the zero class 
is obviously the only divisor of zero in Sj/(P), so that Sj/(P) is an integral 
domain, and in fact a field, since all nonzero elements have inverses. 
Theorem 3: If p -=I=- 0 is a prime element in the principal ideal ring Sj, 
the residue class ring Sj/(P) is a field,23 the so-called residue class field 
modulo p. 
Furthermore (see §2.l0) we have: 
Theorem 4: 
The polynomial ring Sj/(P)[x],p -=I=- 0 andprime,is Euclidean. 
In the following discussion (leading up to the Wilson theorem) it must 
be remembered that a polynomial over a field cannot have a number of 
zeros greater than its degree, and that in the canonical factorization the 
factor (x -
ex)m necessarily appears if ex is a zero of mth order (see IB4, 
§2.2). The fact, emphasized in §4.2, that congruences are interchangeable 
with equations in the residue class ring means for polynomials 
f(x) = Lf=o OiXi and g(x) = L!=o hixi in Sj/(m)[x]24 that the identity 
f(x) = g(x), i.e., the equations 0i = hi (i = 0, 1, ... , n), for the coefficients 
with n = s, has exactly the same significance as f(x) == g(x)(m), which 
means in turn that n = sand ai == bi(m), i = 0, 1, ... , n25 (comparison of 
coefficients mod m). 
28 If p is a unit, $5/(p)( = $5/0» consists of the zero class alone. Depending on whether 
we wish to consider the ring consisting of zero alone as a (trivial) field (the zero field) we 
will include or omit values for p that are units. The polynomial ring $5/0)[x] also consists 
solely of the zero element. 
If, This result also holds in general for liR/a, where a is an arbitrary ideal in a ring 1iR. 
2& See IB4, §2.1 for the difference in meaning between the statement "/(x) = g (x)" 
expressing the fact that I(x) and g(x) are the same elements (polynomials) in a 

384 
PART B ARITHMETIC AND ALGEBRA 
Now let p > 1 be a prime number. We consider the polynomial 
x v- 1 - i E G:j(p)[x]. By the Fermat theorem all the prime residue classes, 
which in the present case means all the nonzero residue classes, are zeros 
of this polynomial; if we ask how many of them there are, the answer is 
given by 
cp(p) = p -
1 = degree (X V - 1 -
1). Thus x v- 1 -
1 mod p 
splits into linear factors: 
21-1 
(27) 
x v- 1 -
1 = Il (x -
v)(mod p). 
Comparison of coefficients mod p in the absolute term shows that 
21-1 
21-1 
(28) -1 == Il (-v) == (_1)v-l . Il v = (_1)v-l(p -
I)! (mod p). 
v-l 
For p > 2, we have p -
1 == 0(2), so that (_I)V-l == +1; if p = 2, we 
still have (_I)V-l == + 1 (2), since + 1 == -1 (2); thus (28) gives us the 
following theorem: 
Wilson's theorem: If p is a prime, then (P-l)! == -1(P), and 
conversely. 
For if n is reducible, then n I (n -
I)! + 1 is obviously impossible. 
But if in (27) we compare the other coefficients (the coefficients on the 
right are the elementary symmetric polynomials of the zeros 1, 2, ... , p -
1) 
(cf. IB4, §2.4), we see that they are all =O(p), which gives the desired result. 
It is easy to generalize the Wilson theorem to principal ideal rings and 
groups 63v of finite order (p -=I=- 0, ",,1 and prime). 
4.4. 
Prime Fields, the Characteristics of a Field 
Now let us suppose that there exists a nontrivial subfield R of G:j(P) 
(p > 1 a prime); then certainly {a, i} k R, and therefore 
...... 
.......... 
...... 
...... 
...... 
............... 
V-I", 
~ = 1 + 1, 3 = 1 + 1 + 1, ... , p -
1 = L 1 
v-I 
are also in R, so that R = G:j(P) , in contradiction to the assumption. 
Thus G:j(P) has no nontrivial subfield. 
A field ~ is called a prime field if it has no nontrivial subfield. If for a 
given field R there exists a positive integer n such that 
(1 Em, n E G:), 
polynomial ring and the statement that I(x) = g(x) for all x in a given set. For 
example, Xl + 1 and x + 1, regarded as polynomials in [,/(2) [x], are distinct, although 
.r + 1 and x + 1 have the same values for all x E [,/(2). The identity theorem which 
is valid in the real (or in the rational or complex) field is not valid in general. 

6 Theory of Numbers 
385 
then the smallest such number n = X(R) is called the characteristic of R. 
If there is no such positive n, then the characteristic X (R) = O. The character-
istic of an integral domain with unity element is defined in the same way. 
The following theorem is now obvious: 
Theorem 4: 
<f./(P) is a prime field of characteristic p. The field P of 
rational numbers is a prime field and X(P) = o. 
As was pointed out in IB5, §l.ll, the fields in theorem 4 are, up to 
isomorphism (cf. IB5, §l.I3), the only possible prime fields, since a 
composite characteristic would imply the existence of divisors of zero. If 
x(R) = p -=I=- 0, 
then 
for 
arbitrary 
ex E R 
we 
obviously 
have 
p . ex( = L~=1 ex) = O. It is also immediately obvious that the number of 
elements of a prime field ~ is equal to X(~), if X(~) -=I=- O. 
In an arbitrary field of prime characteristic p it is clear, since 
p I (~), v = 1, 2, ... , p -
1, that the binomial theorem takes the following 
simple form 
(29) 
(a + b)lI = all + bll• 
4.5. 
Te#s for Divisibility 
As can be shown by the division algorithm (§2.l0), for every integer 
g > 1 a natural n has the uniquely determined digital representation 
k 
n = I aigi = akak-l ... alaO , 
i-O 
k = [ log n ] 
logg , 
(i = 0, 1, ... , k). 
ai integral, 
Here q = q(n) = L~=o ai is called the digital sum of n, and a = a(n) = 
ao -
al + a2 - + ... + (-I)k ak is called the alternating digital sum. If 
we choose the decimal representation, i.e., g = 10, we have the following 
criteria for divisibility: 
1) 3 I n implies 3 I q and conversely, 
2) 9 In" 
9 I q" 
" 
3) 11 I n 
" 
IlIa" 
" 
4) 2"!n 
" 
2" I a"-la"-2 ... ao and conversely. 
Proof: Since 10 == 1(3), we have 1011 == 1 (3) for all integers v ~ O. 
Thus L~=o aiIOi == L~=o at (3), which implies 1). In the same way 1011 = 1 (9) 
for all integers v ~ O. As for 3), we have 10 == -1 (11), 102 == + 1 (11) 
so that 10211+1 == -1(11), 10211 == + 1(11) for v ~ 0, from which it follows 
at once that a(n) = n(ll). Finally, 2 110, i.e., 10 == 0(2), and since a con-

386 
PART B ARITHMETIC AND ALGEBRA 
gruence remains correct if both sides and the modulus are multiplied by the 
same number, we obtain 5 . 2" == 0(2"), and thus also 5" . 2" == 10" == 0(2") 
for" ~ 0, so that akak-1 ... a . 10" == 0(2"), which implies the criterion 4. 
Supplementary remarks: 
By combining one of the first three with the 
fourth of the criteria just given, we can obtain other tests, e.g.: from 6 I n 
follow 3 I nand 2 I n, and conversely, etc. 
In general, the first three criteria are based on the following lemma, 
which can easily be proved. 
Criterion: Let (d, 10) = I, and let h be the order of 10 mod d. Also let 
10i == gi(d) for i = 0, 1,2, ... , h -
1. If 
qh(n) = aogo + algI + ... + ah-1gh-1 + ahgo + ah+1g1 + ... 
is the generalized digital sum, then din implies d I qh(n) and conversely. 
For d = 11 we have go = I, gl = -I, where the gi is chosen to have the 
least possible absolute value. 
4.6. 
Periodic Decimal Fractions 
The following remarks for the base g = 10 are equally valid for an 
arbitrary integer g > 1. By IBI §4.I, every real number can be expanded 
in a unique way as a decimal fraction 
a-la-l+1 ... a-laO, a1a2 ... 
(=a-l' 10l + a_l+1 . 10l-1 + ... + ao + a1 . 10-1 + ... ), 
o ~ all ~ 9 for all v ~ -I, 
if we agree on the normalization that a = 9 for all large v is not permitted 
(i.e., there does not exist an N such that all = 9 for all v ~ N). If we start 
from a rational number r = alb ~ 0 (a ~ 0, b > 0, {a, b} C G:) and 
employ the division algorithm to obtain the successive digits all , the fact 
that only the numbers 0, I, ... , b -
I can occur as nonnegative remainders 
means that after at most b + I divisions two or more of the remainders 
must be equal to each other;26 thus the sequence of digits must be repeated 
from a certain position on, so that we have a periodic decimal fraction: 
r = a_l .. , ao , a1a2 ... asaS+1 ... as+p, 
where 
as 
usual 
the periodic 
part is denoted by overlining. The number P is called a period, and every 
multiple of P is also a period. The smallest P ~ I is called the primitive 
period, and in the present section the word "period" always means the 
primitive period. If we choose s ~ 0 as small as possible, then 0 . a1 ... as 
is called the non periodic fractional part and s is its length. The digits 
28 The division 5 : 2 shows that the number of steps b + 1 (= 3) can actually assume 
its maximum value. In the present discussion we regard terminating decimals as having 
the periodic part "0." 

6 Theory of Numbers 
387 
a-l ... ao. al ... as are called the pre period, and s + I + I is its length. 
Also, O. al .,. asaS+1 .•• as+p is called the fractional part, which is said 
to be pure periodic if s = 0, but otherwise mixed periodic.27 In view 
of the normalization, the fractional part is smaller than I, so that 
[r] = a_l ... ao ; here [r] is called the integral part, k = I + I is the 
number of digits before the decimal point, and r is an (l + I)-place 
number. 
From 10l ~ r < 10l+1 it follows that I ~ log rllog 10 < I + I, 
so that k = [(log r)/(log 10)] + 1. Our main result is now as follows: 
A necessary and sufficient condition for the pure periodicity of (alb) is 
(b, 10) = 1. The period P is then equal to the order of 10 mod b. 
Proof: If alb = 0 . ala2 ... all , we obtain 
a 
OC' (a1 
a2 
ap 
) 
b = L 
10AP+1 + IOAP+2 + ... + 10AP+P 
A=O 
= 
00 _1_ (a1 . 10P-l + a2. IOP-2 + ... + ap) 
L 10AP 
lOP 
A-O 
A .00 
I 
A 
lOP 
A 
= lOP L 10AP = lOP' lOP _ I = IQP _ I (A = al . 10P-l + ... + ap). 
A-O 
Since alb was assumed to be in its lowest terms, we have b I lOP -
I, 
so that (b, 10) = I, and from lOP = I (b) it follows that P is a multiple 
of the order P' of 10 mod b. But if P' < P, then IQP' == I (b), i.e., 
b I lOP' -
I, would imply that alb can be brought into the form 
alb = A'/(IQP' -
I), and, since A' < IQP' -
I, the numerator A' would 
then have the form A' = a~IOP'-1 + ... + a~" so that we would have 
alb = 0 , a1a2 ... ap', in contradiction to the assumption that P is a 
primitive period. Conversely, if we assume (b, 10) = I, then the order of 
10 mod b, call it P, is such that b I lOP -
I. But then, as has just been 
shown, alb is periodic with period P. For an arbitrary fraction alb 
(a ~ 0; b > 0, a and b integers) the length s of the pure periodic fractional 
part can be determined at once from the above theorem: s(~O) is the 
smallest integer such that the denominator of the fraction a . losib in its 
lowest terms is coprime to 10. For then the fractional part of a . 10sib 
is pure periodic. 
The greatest possible value of P is b -
I, and this value is actually 
assumed, for example, for l = 0.142857 (P = 6), whereas for n = 0.09 
we have P = 2 < 10 (=b -
I). 
27 These terms are sometimes applied to r itself. 

388 
PART B ARITHMETIC AND ALGEBRA 
5. Some Number-Theoretic Functions; 
The M6bius Inversion Formula 
A functionf(x) is called a number-theoretic function if it is defined on 
a subset of<£:, e.g., for all natural numbers. The functions T(n), a(n), ak(n), 
defined in §2.I2, and also the Euler function cp (n), are number-theoretic 
functions; the summatory function of f(n) is a number-theoretic function 
iff(n) is such a function. A frequently occurring number-theoretic function 
is the Mobius function JL(n), defined by 
! 
Iforn = 1, 
JL(n) = 
(-1)'1, ifn = PIP2 ... PA is square-free (PI, ... , PAprimes), 
o otherwise. 
In general, an integer g is said to be k-free (k ~ 2 integral) if pk l' g for 
every prime number P > 1; for k = 2 the number g is also said to be 
square..Jree. Let us also mention the unity function €(n) defined by 
for n = 1 
for n > 1. 
For JL(n) we have the following theorem. 
Theorem 5: 
The function JL(n) is multiplicative (see §2.I2), andfor the 
summatory function of JL(n) we have 
(31) 
L JL(d) = €(n). 
din 
Proof: If one of the numbers nl , n2 is not square-free, then neither is 
n1n2, so that JL(n1n2) = 0 = JL(nl ) JL(n2). If both nl ,n2 are square-free 
and coprime, then the multiplicativity is evident. As for n = 1, the formula 
(33) is obvious; for n > 1 let n = P'il ••• p~. be the canonical factorization; 
a number din then has the form d = PI ... Ps, 
0'::::;;; Ki .::::;;; (Xt 
(i = 1, 2, ... , s). Thus 
s 
JL(d) = JL(PII ... p;.) = n JL(p~'), 
i-I 
and therefore 
ex. 
S 
exl 
l'(l! 
ex. 
L Il JL(p~') = L JL(P'J.l) L JL(p22) ... L JL(p;,) 
din 
S 
ex, 
S 
= Il L JL(P't') = Il «JL(I) + JL(p) + JL(pl) + ... + JL(p;') 
i-I IC,-O 
i-I 
S 
S 
= Il (JL{l) + JL(Pt) = Il (1 -
1) = O. 
t-l 
i-I 

6 Theory of Numbers 
389 
The Mobius function enables us to prove an important relation between 
a function and its summatory function. 
Theorem 6: 
Every function F(x) defined on the set 3 of all natural 
numbers n > 0 is the summa tory function of a uniquely determined function 
f(x) defined on 3, if the values of the function are the elements of an Abelian 
group ffi (e.g., (£:+ or PX). 
Proof: Let ffi be a module. For every g E ffi we then have /L(n) g = 0, 
+g or -g, according as /L(n) = 0, + 1, or -1. 28 For all integers k > 0 
we now set 
(32) 
f(k) = L /L (;) F(d) (= L /L(d)F(;)); 
alk 
alk 
thusf(k) is an element of ffi. For the summatory function off(k) we have 
L fed) = L f (S) = L L /L ( d~' ) F(d') = L /L (d~' ) F(d') 
aln 
aln 
aln a'l!!. 
d,a' 
a 
aa'in 
= L L fL ( cZt, ) F(d') = L F(d') L /L ( d~' ) 
a'in al.!!.. 
a'in 
a I..!!. 
a' 
a' 
= L F(d') € ( ;, ) = F(n). 
a'in 
It remains to prove the uniqueness. Let g(x) be an arbitrary function such 
that Ldln g(d) = F(n). It follows from (32) that 
fen) = L /L(d) F (S) = L /L(d) L g(d') = L /L(d) g(d') 
din 
aln 
a'l~ 
aa'in 
= L g(d') L /L(d) = L g(d') € ( ;,) = g(n). 
a' In 
al~ 
a'in 
a' 
Theorem 6, together with (32), is called the Mobius inversion formula: 
From F(n) = Ldlnf(d) it follows that fen) = Ldln /L(n/d) F(d) and 
conversely. 
28 For every module.Q the ring <r may be regarded as an operator domain; we then 
define 
n'1 = L '1, 
if 
n ~ 0, n E <r, 
'1 E .Q 
v-l 
and (-n)'1 = -(n'1)(n > 0), which is obviously in agreement with the above text. 
Compare also footnote 4, §2.S. 

390 
PART B ARITHMETIC AND ALGEBRA 
If the operation in <» is written multiplicatively, the formulas are as 
follows: 
F(n) = n f(d), 
and 
f(n) = n F(dr(~). 
aln 
aln 
Let us now use these formulas to prove the following theorem for the 
Euler cp-function: 
Theorem 7: 
The junction cp(x) is multiplicative, and Lain cp(d) = n; 
moreover, 
1 
s 
cp(n) = n Il (I - -) = Il Pii-1(Pi -
I) 
pin 
P 
i=l 
(n = n 
Pi; canonical). 
~=l 
Proof: Let Wla be the set of all integers x with I ~ x ~ n and (x, n) = d. 
Then obviously 
n 
(33) U 9Jla = U 9Jla = {I, 2, ... , n} and 9Jlal (') 9Jla2 = 0 for d1 -=I=- d2 , 
a=l 
aln 
and 9Jla consists of exactly those multiples Ad of d for which (A, n) = 1 
and 1 ~ A ~ njd. The 9Jla with din thus contains cp(njd) numbers. 
From (33) it follows at once that: 
Thus from the Mobius inversion formula for n = ab, (a, b) = I, we have 
cp(ab) = cp(n) = L JL(d) S = 
L 
aln 
ald21ab 
(dl'a2)=1 
= L L JL(d1) JL(d2) :~ 
alia a21b 
1 2 
= L JL(d1); L JL(d2) : 
= cp(a) cp(b). 
alia 
1 a21b 
2 
In view of this multiplicativity, for n = nt=l pi; (canonical) we have at 
once 
s 
cp(n) = n cp(Pii). 
i=l 

6 Theory of Numbers 
391 
The numbers that are not prime to pri are 2Pi, 3Pi , , .. , p't,lPi '. so that 
6. The Chinese Remainder Theorem; 
Direct Decomposition of <t/(m) 
We now seek to find all solutions x of the simultaneous system of 
congruences x == ai(mi) (i = 1, 2, .. " s), where the mi are pairwise 
coprime; in other words, every solution must satisfy s congruences 
simultaneously, 
The Chinese remainder theorem (fundamental theorem on simultaneous 
congruences) reads as follows: the set of solutions of the simultaneous 
system of congruences x = ai(mi) (i = 1, 2, .. " s) with (ml( , m".) = 1 for 
K -=/= " consists of all the numbers in a uniquely determined residue class 
mod mlm2 .. , ms ' 
Proof: If Xo is a fixed solution and Xl an arbitrary solution, it follows 
that Xo = Xl = ai(mi) for i = 1, 2, .. " s, so that mi I (Xl -
xo), and in 
view of the pairwise coprimality we also have m = n:=l mt I (Xl -
xo), 
i.e" Xl '= xo(m); conversely, since any congruence remains correct when 
the module is replaced by any of its factors, x' == xo(m) implies x' = xO(mi) 
for all i, Thus there can be at most one residue class mod m in which all the 
solutions are contained, and every number belonging to such a residue class 
is necessarily a solution, In order to prove the existence of solutions, we 
set Mi = mimi (i = 1, 2, .. " s); then obviously (Ml' M 2, .. " Ms) = 1; 
thus there exist numbers Yl , Y2 , .. " Ys such that MlYl + .. , + MsYs = 1. 
Let us suppose that also ei = MiYi (i = 1, .. " s); then for all i we have 
the congruences: 
(34) 
and thus 
(35) 
for j -=/= i, 
s L aiei = aiei = almi), 
i=l 
and 
so that aIel + .. , + ases is a solution of the system of simultaneous 
congruences, 
The ei have the important property that 
(36) 
i-=/=j, 
i = j, 

392 
PART B ARITHMETIC AND ALGEBRA 
Proof: From (34) it follows that e,ei = o (mk) for i -=I=- j and k = 1, ... , s, 
so that we also have m I eiei (i -=I=- j). But this is exactly the first relation 
(36), and thus from 1 = e1 + ... + es it follows by multiplication with 
ei that 
, 
ei = L ejei = ei2(m). 
i=1 
An element a of an arbitrary ring 9l such that a2 = a is called 
idempotent. Then (36) states that in <f./(m) the residue classes e1 , ... , es 
form a system of orthogonal idempotents (i.e., idempotents such that the 
product of any two of them is equal to zero). 
For an arbitrary commutative ring we define the concept of direct sum 
as follows. 
A ring 9l is the direct sum of the ideals 9li (in 9l) (i = 1, ... , s), or in 
symbols: 
s 
9l = 911 EB 912 EB ... EB 9ls = L EB 9li , 
t-l 
if it has the following property: 
Every r E 9l can be represented in exactly one way in the form 
(37) 
ri E 9li (i = 1, ... , s). 
For an r E 9li (') 9li (i -=I=- j) it follows, since r = r + 0 = 0 + r 
cannot be two different representations, that r = 0, i.e., 9li (l 9li = {O} 
(i -=I=- j). For arbitrary rj E 9li , ri E 9li (i -=I=- j) the fact that all the 9lk are 
ideals implies at once that rirj E 9li (') 9li , so that riri = O. If for. {a, b} k 9l 
we have the representations a = r; + ... + r;, b = r; + ... + r; in the 
form (37), it follows that 
, 
ab = L r;r;, 
i-I 
so that the two elements may be multiplied componentwise. Since rtri = 0 
for ri E 9li , rj E 9li , i -=I=- j, the binomial theorem is valid in the simple 
form: 
(38) 
(k ~ 0 integral). 
This decomposition of a ring is analogous to the direct product decomposition 
of a group or the direct sum decomposition of a module (see IB2, §8). If we 
do not insist on uniqueness in (37), we have simply the sum: 
9t = 9t1 + ... + 9t, . 

6 Theory of Numbers 
393 
If the ring 9l has a unity element e and if e = el + ... + e s is the 
representation (37), then by squaring we obtain 
and thus, in view of ei2 E 9li and the uniqueness of (37), we have the analog 
of (36) 
e.e. = 
~O, 
~ , 
?ei , 
i#-j, 
i = J. 
Conversely, if we begin with a decomposition of the unity element 
e = L:=l ei into a sum of orthogonal idempotents, then for an arbitrary 
r E 9l, if we denote the principal ideals (ei) by 9li , we have 
s 
s 
r = re = L rei = L ri 
i = 1,2, ... , s) 
i-I 
i-I 
and for an arbitrary representation r = L:=l r; , r; = rt ei E 9li , 
so that ri = r; for all i; that is, the representation is unique, so that 
9l = L:=l EB 9li · Thus (36) provides a direct decomposition of (f,j(m). 
Furthermore, we have the following theorem. 
Theorem 8: 
The residue class ring{f,j(m)admits the direct decomposition 
(f,j(m) = (el) EB (e2) EB ... EB (es) (m = mlm2 ... m s), (mi' mj) = 1 for 
i = j), and for the principal ideals (ei) we have the ring isomorphism 
(ei) "-' (f,j(mi). 
Proof: It remains only to prove the isomorphism. For an Pi E (ei) 
the congruence ri == aiei == biet(m) obviously implies mod m that 
ri == aiei == ai == biei == bi(mi); thus the correspondence ri mod m---+ 
ai mod mi is a one-valued mapping. In this correspondence every 
at E (f,j(mt) occurs as an image, since a;;;E (ei mod (m) (= (ei) 
has 
precisely this image. Thus the number of images is equal to mi. We now 
show that the principal ideal (ei mod m) contains at most mi residue 
classes, and thus, since the number of images is precisely equal to mi , this 
principal ideal contains exactly mi residue classes, so that the mapping is 
one-to-one. From x == z(mi) it follows by the definition of ei that 
xei == xMiYi == zei == zMiYi(mi), and in view of the fact that mjmi = M i , 
this congruence also holds mod m, so that the principal ideal (ei) consists 
of the residue classes (possibly not distinct, so far as we have shown up to 
now) 0, ei , 2et, ... , (mi -
1) ei mod m, which already proves our assertion. 

394 
PART B ARITHMETIC AND ALGEBRA 
It is easy to show that this mapping preserves addition and multiplication, 
i.e., the images of the sum and the product of two residue classes are equal 
to the sum and the product, respectively, of the images. But these proper-
ties of one-to-oneness and the preservation of addition and multiplication 
are exactly the properties of a ring isomorphism. 
By componentwise multiplication it follows from 
(39) 
(ri mod m) C (ei mod m), 
that the mapping (r mod m) ~ (ri mod m) is a (ring) endomorphism 
(i.e., a homomorphism of a ring into itself), and thus the mapping 
(r mod m) ~ (ri mod mi) (=ai mod mi) is a homomorphism, in view of 
the fact that (ei) "'-' <lj(mi)' 
If for m we choose the canonical decomposition, so that the mi are now 
prime powers, then the structure of the residue class ring <lj(m) is already 
known if we know the structure of <lj(pa.) (p a prime), as follows immedi-
ately from the fact that not only addition (trivially), but also multiplication, 
as we have shown, can be carried out componentwise. A similar special 
case occurs, of course, for the direct product of a group (see 182, §8), 
a fact which is of interest in the present context for the prime residue 
class group (fjm. For we see, first of all, that if (r, m) = 1 and 
r == r1 + r2 ... + rs(m) is a decomposition mod m in accordance with 
(37), then r == ri(mi) and (r, mi) = 1, so that we also have (ri' mi) = 1. 
Conversely, if (ri' mi) = 1 for all i = 1, ... , s, then it follows from 
r == ri(mi) that (r, mi) = 1 for all i; thus also (r, m) = 1. If we now 
denote by Um the set of residue classes r E <lj(m) for which 
r == e1 + ... + ei-l + Aiei + ei+l + ... + es(mod m), 
(Ai, mi) = 1, 
it follows at once by componentwise multiplication that U~) is a subgroup29 
in (fjm . Thus we have the following theorem: 
Theorem 9: 
(fjm is the direct product ofU~): 
(40) 
s 
(fj = U(1) X U(2) X ... X U(s) = Q U(i) . 
m 
m 
m 
m 
Yl 
m' 
i=1 
and we have the group isomorphism U~) -
(fjm . 
i 
Proof: Since 
(e1 + ... + ei-l + Aiei + ei+1 + ... + eS)(el + '" + ei-l + /Liei 
+ ei+1 + ... + e.9) == e1 + ... + ei-l + Ai/Liei + ei+1 + ... + es 
(mod m) == Ai/Liei == Ai/Li (mod mi), 
29 In order to prove that a subset 'X of a finite group ffi is a subgroup it is sufficient to 
show that the product of every two elements in 'X belongs to 'X; and the ffim in the text 
is certainly finite. 

6 Theory of Numbers 
395 
the mapping 
preserves addition and multiplication and is therefore a homomorphism 
of U~) ont030 ffim ; thus U~) has at least m(mi) (= 1 ffim I) elements. The 
, 
..,-; 
one-to-oneness follows from the above result that, as in the proof of 
theorem 8, (r, m) = 1 is equivalent to (rj, mj) = 1 for all j = 1, 2, ... , s 
(in the present case rj = 1 for j -=1= i, ri = Ai), and thus the homomorphism 
in question here is actually an isomorphism. By componentwise multipli-
cation we further see that 
s 
s 
L Aiei == n (el + ... + et- l + Aiet + ei+1 + ... + es)(mod m), 
i-I 
t=l 
where the factors on the right-hand side belong successively to U!!), ... , 
U~), so that ffim = U!!) . U!!) ... U~). Since cp(m) = n:-l cp(mt) = 1 ffim 1 = 
n:=l 1 U~) I, the representation of the elements of ffim' as products of 
elements in U!!), U~), ... , U~) must be unique, so that the product de-
composition of ffim is direct. 
If we again choose for m the canonical decomposition, we see that the 
structure of the groups ffim is known if we know the structure of the prime 
residue classes for moduli which are powers of primes. Regarding the 
structure of these groups (see, e.g., Hasse [3], [4], Scholz-Schoneberg [1]) 
we have the following theorem: 
Theorem 10: 
For all primes p > 2 and all A ~ 1 the groups ffi2lA are 
cyclic of order cp(PA) = pA-I(p -
1), and the same statement is true (though 
trivial)for ffi2 and ffi22 . For A ~ 3 the group ffi2'\ is the direct product of two 
cyclic groups, one of which is always of order 2; e.g., ffi2'\ = (-1) X (3). 
It is also easy to show that every finite cyclic group can be represented 
as the direct product of cyclic groups of prime power order. This fact, taken 
together with theorem 10, shows that in theorem 9 we have a decomposi-
tion of the group ffim in the sense of the fundamental theorem for finite 
Abelian groups (see 182, §9.2). 
7. Diophantine Equations; Algebraic Congruences 
7.1. If y = f(x1 , X2 , ... , xn) is an arbitrary function which is defined 
at least for all integers Xi, thenf(x1 , X2 , ... , xn) = 0 is called a Diophantine 
80 A mapping "onto" means that every element of ffim; appears as an image; in the 
present case this property, together with the uniqueness of the correspondence, is 
proved in the same way as in theorem 8. 

396 
PART B ARITHMETIC AND ALGEBRA 
equation, provided we are seeking all integral solutions (Xl, ... , Xn). 
Closely related is the concept of an algebraic congruence, by which we 
mean the problem of determining all (integral) solutions of the congruences 
g(XI , X2 , ... , xn) ~ O(m), where g(xi , X2 , ... ,xn) is a polynomial in the 
indeterminates Xl , X2 , ... , Xn with integral coefficients. This congruence is 
obviously equivalent to the Diophantine equation g(XI' X2, ... , xn) + ym = 0 
in the unknowns Xl, X2 , ... , Xn ,y. Since congruences can be added, 
subtracted, and multiplied, or in other words since <lj(m) is a ring, it 
follows 
from 
Xi ~ Yi(m) 
(i = 1, ... , n) 
that 
g(XI' X2 , ... , xn) ~ 
g(Yl, ... , Yn)(m), so that every solution of an algebraic congruence (also 
called a root of the congruence) is an n-tuple of residue classes mod m. 
The definition of systems of Diophantine equations or algebraic congruences 
is similar. If S!,(fl , ... ,fk ; m) = l(m) is the number of solutions of the 
system of congruences It. (Xl , ... , Xn) ~ O(m) (i = 1, ... , k), it is obvious, 
from the trivial estimate 0 ~ l(m) ~ mn, that l(m) exists. Furthermore, 
for fixed It. (Xl , ... , Xn) (i = 1, ... , k) we have the following theorem: 
Theorem 11: 
l(m) is a multiplicative function. 
Proof: Let m = mlm2, (ml' m2) = 1, and let (f,j(m) = 911 (f) 912 be 
the corresponding representation as a direct sum, so that 9li "'-' (f,j(mi) 
(i = 1, 2). If we decompose a solution XlO, ... , xno(mod m) in the sense 
/". 
/". 
of(37): XiO ~ x~o + x;o(m), (x~o) E 911 ,(x;o) E 9l2) (i = 1, ... , n), we obtain 
f( 
) - f( , + " ... ) ( 
d 
) -lfi(X~o' ... ) ~ O(mod ml), 
i x lO ' ... , xnO = 
i x lO 
XIO , 
mo m = 
I' (" 
) = O( 
d 
) 
J i x lO ,... -
mo m2' 
Conversely, if we start from solutions x~o , ... of It. ~ O(ml) and x:o , ... of 
It. ~ O(m2), i = 1,2, ... , m, we see that x~Oel + x:oe2 , .. , is a solution of 
the systemlt. ~ O(m), since it follows from (34) and (35) that 
1'(' +" 
) -lfi(X~o' ... ) ~ O(m1) 
J i xlOel 
x lOe2 ,... = 
I' (" 
) = O( 
) 
Ji xIO '''. -
m2 
(i = 1, 2, ... , n), 
so that from (ml ,m2) = 1 we have 
m I f~(x~Oel + x;oe2 , ... ). 
Summing up, we see that the solutions mod m are in one-to-one corre-
spondence with the pairs of solutions mod ml , mod m2, so that 
l(m) = l(ml) l(m2)' 
Thus it is sufficient to determine I(PA) for primes p. For a polynomial 
f(x) in one indeterminate, it is well known, since (f,j(P) is a field, that 
1 (P) ~ degreef(x) 
(see 
IB4, 
§1.2). 
For 
normalized polynomials 
f(x) = L:-o avXn- lI
, i.e., with ao = 1, we have the general theorem: if 

6 Theory of Numbers 
397 
f(x) = xn + alXn-l + ... + an == O(P) has no multiple zeros, then neither 
hasf(x) == O(PA), (A ~ I), and 1(P) = l(pA);for f(x) == O(m) (m = n:=l p;i 
canonical) we thus have l(m) = O:=ll(p;i) < nB (see Scholz-Schoneberg 
[I D. The equality is possible. 
7.2. 
The fact that the linear congruence ax == b(m) with (a, m) = I is 
uniquely solvable was already proved in §4.2. If (a, m) = d, then d 1 b is 
obviously necessary for solvability and if we divide the result by d, 
producing the congruence aid == b/d(m/d), we can easily show that the 
entire set of solutions consists of exactly d distinct residue classes. Thus it 
remains only to find a particular solution Xo of ax == b(m) with (a, m) = 
1. 
But Xo = bafP(m)-l is a solution, by the Fermat theorem. Another method of 
finding such a solution is as follows. By the Euclidean algorithm we 
calculate Xl ,Yl such that (a, m) = I = aXl + my 1 . Then it is obvious 
that xlb is also a solution. By §3.1 the Euclidean algorithm is 
closely connected with the expansion into a continued fraction; let 
aim = [bo, bl , ... , bnl = An/Bn; then certainly a = An, m = Bn in 
view of the fact that (a, m) = (An' Bn) = I, and thus §3.2 (21) gives for 
v = n the result that a = An , m = Bn 
so that Xl = (_I)n-l Bn-l , Yl = (-l)n An-l is a solution of ax 1 + my! = l. 
Since the congruence ax == b(m) is equivalent to the Diophantine 
equation ax + my = b, we see at once that for (a, b) = 1 the entire set of 
solutions can be obtained in the form X = Xo + Am, Y = Yo -
Aa, as soon 
as we have a particular solution Xo , Yo , and that Xo can be determined in 
either of the two ways described above. 
7.3. 
A quadratic Diophantine equation that occurs in many mathe-
matical contexts is the Pell equation x2 -
dy2 = h (see Weber [I]), 
especially with h = 1 and h = 4. If d = a2, where a is an integer, and we 
set ay = z, we arrive at the easily solved equation x 2 -
Z2 = h = 
(x -
z)(x + z). For if h = hlh2 is an arbitrary factorization of h, then 
from X -
z = hI , X + z = h2 we obtain at once all possible solutions; 
thus if hI , h2 are either both even or both odd we already have all the 
integral solutions, and if 2 I h but 4 l' h, then the problem is insoluble. 
In general, it is easy to see that we may confine our attention to square-
free d and coprime solutions x, y; if h is square-free, it is obvious that only 
coprime solutions exist. Then we can state an interesting connection with 
the theory of (regular) continued fractions (see Perron [2]): 
For every solution X > 0, y > 0, (x, y) = 1 of x2 -
dy2 = h with 
o < 1 h 1 < 1 Vd I, d > 1 square-free, the fraction x/y is a partial quotient 
o/the (periodic) continuedfraction expansion ofVd, and there exist infinitely 

398 
PART B ARITHMETIC AND ALGEBRA 
many solutions. If h = I and v'd = [bo , bl , ... , bs = 2bo],31 then from 
x/y = Aps-l/Bps-l we obtain the entire set of coprime solutions by letting p 
run through all the integers 0, 1,2, ... ,for even s and through all the even 
integers 0, 2, 4, ... for odd s; moreover, the partial quotients satisfy the 
(Lagrange) relation 
A pS- 1 + B OS- 1 v'd = (A S- 1 + BS- 1 Vd)p, 
from which by expanding the right-hand side we obtain formulas for 
Ap.~-l , Bp.~-l in terms of the smallest positive solutions AS-I, BS- 1 . 
7.4. 
The question of the solvability of the Diophantine equation 
xn + yn = zn, n > 2 has remained unanswered up to the present day, 
although the famous Fermat conjecture states that it is unsolvable. Clearly, 
we may consider only (x, y, z) = I and prime exponents n = p > 2, and 
it has become customary to divide the problem into the two cases; first 
case: p -t xyz; second case: p I xyz. In the first case the unsolvability is 
known for all p < 253747889, and with the help of electronic computers 
the second case has been settled up to p < 4003 (for some further remarks 
see §8.3). 
For n = 2 it is obvious that 
(41) 
x = A(U2 -
v2), Y = 2AUV, 
z = A(U2 + V2); 
U, v, A integers, 
namely, the so-called Pythagorean triples, are solutions of x 2 + y2 = Z2 
and it can be shown in various ways that they are the only solutions, e.g., 
as follows. If we set g = x/z, TJ = y/z, we obtain the equation of the unit 
circle g2 + TJ2 = I, for which the parameter representation 
I -
t 2 
g = cos cp = I +- t2 ' 
. 
2t 
( 
32 
t = tg i) 
TJ = SIn cp = I + t2 ' 
sets up a one-to-one correspondence, since t = TJ/I + g, between rational 
t and the rational points of the circumference (i.e., points with rational 
coordinates). If we now introduce the homogeneous parameters: t = v/u 
(u, v integers), we have 
(42) 
-!:: = TJ = 
2uv 
Z 
u2 + v2 • 
31 It can be shown that for a square-free d the continued fraction expansion of v'd 
necessarily has the above form. 
32 This representation of the trigonometric functions as rational functions of the 
tangent of the half angle is useful in a well-known way for the integration of 
f(sin x, cos x, tg x, ctg x) with rationalf(half angle method). 

6 Theory of Numbers 
399 
From now on we may confine our attention to coprime x, y, z. Then, in 
view of the fact that (2y)2 = (2a + 1)2 + (2{3 + 1)2 == 2(4), exactly one 
of the two integers x, y must be even, and without loss of generality we 
may say that y is even; furthermore, we may assume that (u, v) = I, since 
otherwise we could cancel (u, V)2. For a common prime divisor p of 
u2 -
v2 and u2 + v2 we have p I u2 -
v2 ± (u2 + v2), and thus p I 2u, 
p I 2v, so that from (u, v) = 1 it follows thatp = 2; i.e., u, v are both odd, 
since otherwise u2 ± v2 could not be even in view of the fact that (u, v) = 1. 
If we now cancel 2 from 2uvj(u2 + v2), the denominator of the reduced 
fraction must be odd, whereas we must have y == 0(2). Thus a prime 
divisor p of this sort cannot exist, so that in (42) we must have 
x = u2 -
v2, Y = 2uv, z = u2 + v2, as desired. 
Parameter prepresentations other than (41) are obtained by unimodular 
transformations of u, v, 
u = au' + {3v' . 
v = yu' + Sv' , 
I;~I=±I; 
a, {3, y. S integral,33 
and only from such transformations, since only then is it true that the 
u', v' can also be expressed as integral linear forms in the u, v. 
7.5. 
Of particular importance among the algebraic congruences are 
the pure congruences xn == a(m), since the solution of such a congruence 
is equivalent to the determination of the nth roots in <lj(m). If 
(a, m) = 
d = 
d1nd2 with n-free d2 , it is easy to show by setting x = 
d1y 
that we may restrict our attention to the case (a, m) = 1. If xn == a(m), 
(a, m) = 1 is solvable, a is called an nth power residue, and otherwise an 
nth power nonresidue; in particular, for n = 2 we speak of quadratic 
residues, denoted by QR, and quadratic nonresidues, denoted by N R. 
For the pure congruences with (a, m) = I it is obvious that (xo , m) = I 
for every solution Xo ; thus by the Fermat theorem n can always be reduced 
modulo the order cp(m) of the prime residue class group ffim, so that we 
may restrict attention to I ~ n ~ cp(m). Then xq>(m) -
1 == O(m) has 
exactly all the cp(m) prime residue classes as its solutions. If ffim is cyclic 
and g is a generating element (see §6, theorem 10), then every generating 
element of ffim is a primitive root of the congruence. In gP with (p, cp(m) = 1 
we obtain, as is easily shown, all the primitive roots of the congruence 
and the number of them is obviously equal to cp(cp(m). 
For cyclic ffim it is obvious that the exponential congruence b'" == a(m), 
(a, m) = (b, m) = 1 is always solvable and the solution is unique mod cp(m). 
In analogy with logarithms, we write x mod(m) = ~d a (to be read: index of a 
33 A matrix over an arbitrary ring 9t, 1 E 9t, is called unimodular if its determinant 
is a unit, so that in <r the determinant must be equal to ± 1. 

400 
PART B ARITHMETIC AND ALGEBRA 
to the base b). It is easy to show that the rules for calculation are the same 
as for logarithms. 
For quadratic congruences x2 == a(p), p > 2 a prime, (a,p) = I, we 
define the Legendre symbol (ajp) (read: a by p) by setting 
if a is a QR, 
if a is an NR. 
If g is a primitive root of the congruence mod p, then I == g2)-I(p), 
so that (g(2)-I)/2 -
1)(g(2)-I)/2 + I) == O(P), but g(2)-I)/2 =*= I(p), so that 
g(2)-I)/2 + I == O(P). Since ffi2) is cyclic (see §6, theorem 10), there exists 
a " such that g>' == a(p). Thus we have 
2)-1 
2)-1 
a-2-
== g>'-2- == (-I )>'(p). 
For ,,= 2p. it follows that a == g>' == (g~)2 (p), i.e., (ajp) = 
I and 
012)-1)/2 == I (P). For odd" we have a(2)-I)/2 == -I (P), and a == g2~+I(p) 
is an NR for the following reason. From xo2 == g2~+I(p) it follows, if we 
set Xo == ga(p), that g2a -
g2~+I(P) so that 2a == 2p. + I (mod cp(p) = 
p -
1), and thus it would follow from 2(P -
I) that 2 I (2 + I), which is 
impossible. Summing up, we have the Euler criterion: 
2)-1 
a~ == ~) (mod p). 
Since for even" we obtain the QR, and for odd" the NR, it follows that 
there are exactly as many QR as NR. 
For p > 2 and q > 2 prime, we have the Gauss law of quadratic 
reciprocity (see e.g., Hasse [3], [4], Scholz-Schoneberg [I]): 
2)-1 
>.-1 
(~) = (_I)~· -2 ~). 
Since (ajp) is distributive (over ffim), we see from the Euler criterion that 
as soon as we know the values of the symbols (-Ijp) and (2jp) we can 
use the reciprocity law to reduce either of the following two questions to 
the other: "whichp are QR mod q?" and "for which moduli q isp a QR ?". 
It is also convenient to introduce the Jacobi symbol 
8 
m = n pA, canonical, 
i-I 
then we have the generalized law of reciprocity: 
(2, m) = I; 
(43) 
(~) = (-I) a;1 . b;1 (~), 
if (ab, 2) = I, 
a > 0, 
b > o. 

6 Theory of Numbers 
401 
The definition (43) enables us to calculate the Legendre symbols in a 
practical way, since it is easily seen that the numerators in the symbols 
may be altered at will modulo the denominators (for the further theory 
see, e.g., Hasse [3], [4]). 
8. Algebraic Numbers 
8.1. 
Letf(x) be an irreducible polynomial (see §2.6) in P[x] (where P 
is the field of rational numbers). Then in the field R of complex numbers, 
f(x) has exactly n zeros {}t (i = I, ... , n), where n = degreef(x), provided 
i that ~every zero is counted according to its multiplicity (= exponent of 
x -
(}i in the canonical factorization with respect to R[x]). Since the 
GCD(I(x), /' (x» E P[x], it follows from the irreducibility of f that 
(1,/') = I, so that multiple zeros are impossible. If f(x) is reducible and 
f( (}i) = 0 ({}i E R), then (}i is also a zero of an irreducible factor of f(x). 
Thus it is sufficient to consider only the zeros of irreducible polynomials; 
they are called algebraic numbers,' the non algebraic numbers in Rare 
'called transcendental. If for f(x) = L~=o aixt we set h = n + L~=o 1 ai I, 
then for a given h there exist only finitely many f(x) with integral ai 
(which is. obviously no restriction of generality) and thus only finitely 
many: algebraic numbers. Thus for h = I, 2, ... we obtain all algebraic 
numbers in a countable sequence. Since R itself is not countable (see 
IBl, §4.8), it follows that there exist uncountably many transcendental 
numbers (for further details see III 13, §2). 
If {} is a zero of the irreducible polynomial f(x) with degree f(x) = n, 
then f(x) is called the defining polynomial of {}, and {} is an algebraic 
number of nth degree. 34 It"is easy to see that the defining polynomial is 
uniquely determined up to associates. If f(x) is a normalized integral 
polynomial (Le., all coefficients ai are rational integers with an = l), then 
the zeros are called algebraic integers, or simply integers. 
Let P( (}), where {} is algebraic, denote the intersection of all those 
extension fields of P in R that contain (}.35 Then P( (}) is said to be an 
algebraic number field of degree n, if degree {} = n. For example, P(v2) 
consists of all numbers 
ex + f3v2, {ex, f3} C P; and the numbers 
a + bV2, {a, b} C G:, are the algebraic integers in P(V2). In §2.IO this 
set of integers was given as an example of a (Euclidean) ring. In 187, §2 
we will prove in general that every number in P( (}) is algebraic of not 
more than the nth degree and that P( (}) is identical with the totality of all 
numbers of the form L~::l Pi{}i (all Pi E P). It is even true that this 
3f, For the interesting continued fraction expansion of the algebraic numbers of 
second degree see §3.3. 
3& Thus P( 8-) is the smallest subfield of Sl that contains P and 8-. 

402 
PART B ARITHMETIC AND ALGEBRA 
representation is unique, since from 'L.f~l pl}i = 'L.f~l I-'J}i it would 
otherwise follow that {} is a zero of'L.f::l (Pi -
I-'i) Xi and consequently of 
degree smaller than n. Thus in the sense of IB3, §1.3 the ring P( (}) is an 
n-dimensional vector space with {I, {}, (}2, ... , {}n-l} as basis, and we can 
pass to other bases by linear transformations with rational coefficients and 
nonzero determinant. If f(x) = 'L.f=o aixi = 0 is the defining equation 
of {}, then 'Y} = an {} is an algebraic integer, since it is a zero of the normalized 
polynomial a~-Y(x) = yn + anan-l yn-l + ... (y = anx), so that, besides 
the rational integers, P( (}) even contains algebraic integers of nth degree, 
and it also follows from {} = 'Y}/an that every algebraic number can be 
represented as the quotient of two algebraic integers, where the denominator 
is an arbitrary rational integer. Then it can be shown 
(se~ Hasse [3], 
van der Waerden [3]), that the integers in P({})form a ring. For the theory 
of numbers in algebraic number fields the following theorem is of funda-
mental importance. In P( (}) there exist bases which consist entirely of 
integers and have the property that every integer can be represented as a 
linear combination with rational integers as coefficients; and conversely, 
every such linear combination is an algebraic integer. Such a basis is called 
an integer basis. If WI, W2, ... , Wn 
is an integer basis and if 
Wi, W;, W;, ... , w~n-l) (i = I, ... , n) are the systems ofnumbers36 conjugate 
to the Wi , the determinant 
WIW~ , ... , win-I) 2 
.J= W2W; , ... , w~n-l) 
is called the (field) discriminant ofP( {f). Since integer bases can be obtained 
from one another only by unimodular transformations, the value of d, 
as follows from the rule for multiplication of determinants, has the same 
value for all integer bases and is thus afield invariant: the value of .J is a 
rational integer, as can be shown from the developments of 187, §7. 
The existence of an integer basis for the ring of integers in P( (}) shows 
that we are dealing here with a vector space, in symbols G:[WI , W2 , ... , wnl 
Since we have also defined mUltiplication for "vectors," the P( (}) and 
G:[WI , W2 , ... , wn] are algebras,37 and P( (}) is also a division algebra. 
38 By a system of conjugates we mean the zeros of the defining polynomial, if its degree 
is equal to the degree of the field. If ~ E PCD-) is of smaller degree, say k, it can be proved 
(see IB7, §6) that kin, and then the system of conjugates is obtained by writing each 
zero nJk times. 
37 By an algebra we mean a vector space for which there has also been defined an 
associative and distributive multiplication; thus an algebra is a ring. It is clear that the 
multiplication is fully determined if we can write the products of the basis vectors as 

6 Theory of Numbers 
403 
Concerning the zeros of a polynomial with algebraic numbers as 
coefficients, it can be shown (by the fundamental theorem on symmetric 
polynomials) that there exist polynomials with rational integers as 
coefficients which have at least the same zeros. Furthermore, the zeros of 
a normalized polynomial with (algebraic) integers for its coefficients are 
again integers. 
The product ex ex , ••• ex(n-l) or, what is obviously the same, the absolute 
term mUltiplied by (_l)n, of the normalized defining polynomial of ex, 
is called the norm of ex and is denoted by N(ex). If ex is an algebraic integer, 
then obviously N(ex) is a rational integer (see also IB8, §1.2). 
8.2. As is shown by the example P(V -5) in §2.l0, the integers in 
P(V -5) do not from a u.f. ring. It was one of the greatest advances in the 
theory of numbers that Kummer found a substitute for the u.f. theorem by 
introducing the so-called ideal numbers. As an equivalent concept, 
Dedekind introduced the ideals defined in IB5, §3.1 (see also §2.5). But 
before we can formulate the theorem which takes the place of the u.f. 
theorem, we must make some preliminary remarks. 
By the product of the ideals a and b of a ring m we mean the ideal 
generated by all the products ab (a E a, b E b) or, in other words, the set of 
all finite sums Li aibi (ai E a, bi E b). As in IB5, §3.6, an ideal l' is called 
a prime ideal if mil' has no divisors of zero; if the prime ideal is a principal 
ideal, l' = (p), then p is called a prime element. Prime elements are 
irreducible as is easily shown (cf. IB5, §2.3), but the converse is not 
necessarily true; for example, in the ring (fj of all even numbers, 30 is 
irreducible but not prime, since 6 . 10 == 0 (mod 30). On the other hand, 
in a u.f. ring the irreducible elements are also prime, which is in fact the 
fundamental lemma of the theory of divisibility (see §2.6). Thus our 
terminology is in agreement with that of §2.6 and IB5, §2.6. Furthermore, 
calling an ideal a maximal if no ideal b exists with a C b C m (= (I ), we 
have the theorem that every maximal ideal is prime (see van der Waerden 
[2]); but then again the converse is not necessarily true. However, in the 
number rings G:[WI , ... , wn ] this converse does hold for prime ideals p that 
are distinct from the zero ideal and the unit ideal. 
If we now consider all numbers of the form a + bv --3, {a, b} C G:, i.e., 
the ring G:(v=-3), we do not obtain all the integers in P(Y=3); for 
example, the zero ! + iv - 3 of x 2 + x + 1 is an integer but is not 
contained in G:[v -3]. A ring (fj of integers that is contained in P( &) is 
said to be integrally closed in its quotient field P( &) if all the zeros of a 
normalized polynomial (with coefficients in (fj) that are contained in P( &) 
linear combinations of these basis vectors: W,WI = !::-l CHKWK ; that is, if we know the 
structllre constants C'IK (cf. IB5, §3.9). If an algebra is a field, it is called a division algebra 
(cf. lB8, §3.4). 

404 
PART B ARITHMETIC AND ALGEBRA 
are already contained in G> itself.38 Then by definition <£:[W1 , W2 , ..• , wn] 
is integrally closed in P( &). Finally, it is of especial importance that in 
<£:[W1' ..• , wn] the maximal condition for ideals (see §2.9) is satisfied. 
In a ring m we say that the theorem of unique factorization into prime 
ideals, the u.f.p.i. theorem, is valid if every ideal can be represented in a 
unique way (apart from the order of the factors) as the product of powers 
of prime ideals; an integral domain is called a u.f.p.i. ring if the u.f.p.i. 
theorem holds and if a C b (a, b ideals) implies the existence of an ideal 
e with a = be. We then have the following fundamental theorem (see 
van der Waerden [3 D. 
An integral domain is a u.fp.i. ring if and only if the following conditions 
are satisfied. 
I. m is integrally closed in its quotient field. 39 
II. In m the maximal condition (see §2.9) is satisfied. 
Ill. Every prime ideal p -=/=- (0), -=/=-m is maximal. 
Consequently, all rings <£:[W1 , ... , wn], (where WI , ... , Wn is an integral 
basis) are u.f.p.i. rings. It is not true that every u.f.p.i. ring is a u.f. ring, 
as was shown by the example of the ring <£:[v=5] at the beginning of§8.2; 
and conversely, not every u.f. ring is a u.f.p.i. ring, as is shown by the 
example of the polynomial ring R[x, y], where R is a field, since in this 
field the prime ideal (x) is properly contained in the prime ideal (x, y) and 
therefore cannot be maximal. 
8.3. If a is an ideal in (t[Wl , ... , wn] and a E a, then obviously 
{awl' aW2, ... , aWn} C a, and the aWi (i = 1, ... , n) are linearly dependent 
over P, and therefore also over <£:, since the Wi are linearly dependent over 
<£:. It can be shown (see van der Waerden [3D that a is a vector space over 
<£:, which we have just seen to be n-dimensional. 
Two ideals a = <£:[a1 , ... , an] and b = <£:[,81 , ... , ,8n] are equivalent, 
a ~ b, if there exists an algebraic p such that ai = P{3i for all i = 1, ... , n. 
This relation is seen at once to be reflexive, symmetric, and transitive. Thus 
the set of all ideals falls into classes of equivalent ideals, the so-called 
ideal classes. It can be shown that the number h of ideal classes, the 
so-called class number, is finite (see Hasse [4], Landau [1], Vol. 3). 
If , is a primitive nth root of unity, or in other words if , is of the form 
88 If (D has no unity element, then in place of ordinary polynomials we have expressions 
of the form aIxl:-1 + a,xI:-2 + ... + ak_Ix + xl: + nIxl:-1 + ... + nk-lx + nle , aA E (D, 
nA E (t. 
39 The property of being "integrally closed" is defined for rings of integers in P( 8-) 
in the same way as before. In the text algebraic numbers and the number field P(8-) were 
defined as certain subsets of the field of all complex numbers, but now they are to be 
defined as elements of certain algebraic extension fields in the sense of IB7, §1. 

6 Theory of Numbers 
405 
e21rik/n with (k, n) = 1, then pa) is called the nth cyclotomic field. We 
shall examine the special case that n = p > 2 is a prime. 
A prime number p > 2 is said to be regular if p l' h, where h is the class 
number of the pth cyclotomic field pa). Kummer was led to the study of 
these fields by his investigations into the Fermat conjecture; he proved that 
x 21 + y21 = z21 cannot be solved in integral quantities pa) if p is regular 
(see Landau [1], Vol. 3). 
Remark on §8. 
The theory of numbers in algebraic number fields can be 
developed in a way quite different from the ideal-theoretic discussion 
given here, namely, on the basis of the theory of valuations (see Hasse [3], 
[4]. 
9. Additive Number Theory 
In our discussion up to now the foreground has been occupied by 
questions of divisibility, like the u.f. theorem and the u.f.p.i. theorem, 
which are sometimes called questions of the mUltiplicative theory of 
numbers. By additive number theory we mean questions that can be 
reduced to the following fundamental problems. Let there be given n sets 
~l , ~2 , ••• , ~n whose elements are non-negative integers. By the sum 
G: = 
~l + ~2 + ... + ~n = Lf=l ~i we mean the set of numbers 
c = Lf-l ai (ai E ~i) (Schnirelmann). If ~l = ~12 = ... = ~n = ~, we 
also write Lf=l ~i = n~. Let ~(i(X) (i = 1, 2, ... , n) and C(x) denote, 
respectively, 
the 
number of positive 
numbers 
ai::::; x 
(ai E ~i) 
(or 1 ::::; c ::::; x (c E G:). The investigation of C(x) is our first fundamental 
problem; the second consists of deciding in how many ways aCE G: can 
be represented in the above form. It is easy to see that the definition of a 
sum can be extended to the case n = 00; then if ° 
¢ ~i for every i, the 
sum Li..l ~i is empty. 
Let ~(2) = {O, 1,3, 5, ... , p, ... } be the set of all primes p ~ 0, p -=I=- 2; 
then the (unsolved) Goldbach conjecture states that 3~(2) = 3, where 
3 = {O, 1, 2, ... } is the set of all non-negative integers. This conjecture is 
obviously equivalent to the conjecture that every positive even number 
can be expressed as the sum of two primes. If we agree to say that two sets 
~ and m are asymptotically equal, ~ ~~, if they coincide from some 
point on, i.e., if for a sufficiently large N they are identical in the interval 
(N, (0), then it is known at the present time only that 4~(2) ~ 3 
(Vinogradov). 
A set ~ is called a basis of kth order if k~ = Z, (k -
1) ~ -=I=- 3, and ~ 
is called an asymptotic basis of kth order if k~ ~ 3, (k -
1) ~ + 3. 
Thus ~(2) is an asymptotic basis of not more than fourth order and the 
Goldbach conjecture states that it is a basis of third order. 

406 
PART B ARITHMETIC AND ALGEBRA 
If we set 3(n) = {O, In, 2n, ... , xn, ... }, the Waring problem (solved by 
Hilbert) states that 3(n) is a basis. A special case is the theorem of 
Lagrange: 3(2) is a basis o.ffourth order. 
The number k(m; ~(l , ... , ~(n) of representations of m in the form 
m = ali "+ a2i + ... + ani 
(a,\i E ~(A' ,\ = 1,2, ... , n) is called the 
1 
2 
n 
A 
composition number of m, and every such representation is called a 
composition. It is to be noted that under certain circumstances represen-
tations with the same summands but in different orders are to be counted 
a corresponding number of times in k(m; ~(l , ... ); for example, if 
'111 = to, 3, 5}, ~(2 = {3, 5}, ~(3 = {2}, we have 
10 = 3 + 5 + 2; 
= 5 + 3 + 2; 
3 E ~(l , 
5 E ~l' 
5 E ~2' 
3 E ~(2 , 
so that k(l 0; ~(l , ~(2 , ~3) =-= 2. If the order of the summands is explicitly 
disregarded, 
we 
use 
the 
term 
partition 
or partition function 
p(n; ~l , ••• , ~(n)' The difference is particularly noticeable in the case 
~(l = ~(2 = ... = 
~rn = ~l. If n = 00 and ~( = 3, thenp(m; 3, 3, ... ) = 
p(m) is simply called the number of partitions. The composition function 
k(m; 3, 3, ... ) is in finite for all m and therefore meaningless; thus in 
general k(m; ~(, ~(, ... ) = k(m, ~() is the number of representations of 
m with positive summands from ~(, account being taken of the order 
of the summands. 
It is only in the rarest cases that the partition function or composition 
function can be explicitly calculated. For the most part we simply try to 
discover the asymptotic behavior of these functions for m ---+ 00. Similarly, 
the question of the structure of the set of numbers represented by a sum 
can be answered in general only to the extent of finding the asymptotic 
behavior of C(x) for x ---+ 00, especially since for the most part we know 
nothing mort about the summands than the asymptotic behavior of the 
functions ~(i(x)defined above. For example, the prime number theorem states 
that n (x) '"" x/log x, where n (x) is the number of prime numbers ~ x. 
For the great majority of special problems it is necessary to employ the 
methods of analysis, in which case we speak of analytic number theory 
both for mUltiplicative and for additive problems. 
A generalization of the prime number theorem should be mentioned 
here. Let ~m,k be the set of prime numbers p == k(m), (k, m) = 1; then 
x 
n (x) '"" cp(m) log x 
k,m 
(cp(m) Euler function). 
It follows that every residue class mod m whose elements are coprime to m 
contains infinitely many prime numbers (Dirichlet). 
For a further discussion see also 11113, §1. 

6 Theory of Numbers 
407 
The function A (x) defined as the number of numbers ~x in a set ~ is 
often described by means of comparison functions tP(x), a practice which 
has led to the introduction of the following concepts: 
A (x) 
8(~, tP(x» = x-~~,., tP(x) 
A(x) + 1 
8v(~'(, tP(x» = x=~~'" tP(x + 1) 
8*(~, tP(x) 
= !~~ 1&; 
~ *(or ./,( » _ -t' A (x) 
o 
:u, 'f' X 
-
L~ tP(x) 
(tP(x)-density of ~)40 
(varied tP(x)-density,41 
if 0 E ~), 
(asymptotic tP(x)-density), 
(upper asymptotic tP(x)-density). 
If 8* = S*, we speak of the natural tP(x) density 8*(~, tP(x». Of particular 
importance is the case tP(x) = x, for which we simply write 8(~), 8v(~), 
and so forth. Then we have the following theorem, which is relatively 
simple and easy to prove. 
Schnirelmann basis theorem: If 8(~) > 0 and 0 E ~l (or equivalently 
8(~) > 0 and 1 E ~l), then ~ is a basis. 
Proof: From 
8(~) > 0 it follows that 1 E~, and so we set 
~l = {ao = 0, al = 1, a2, ... }, al < a2 < ... ; if all E~, then all all + ap 
with all < all + ap ~ all+l -
1 belong to 2~; from ap ~ all+l -
all -
1 
it follows that the number of these all + ap is equal to A (all+1 -
all -
1). 
If we define n by an ~ x < an+l, so that A (x) = n, and let (2A)(x) 
denote the number of elements of 2~ ~ x, we obviously have 
n-l 
(2A)(x) ~ A(x) + L A(all+1 -
all -
1) + A(x -
an) 
11-0 
n-l 
~ A(x) + L 8(~)(all+l -
all -
1) + 8(~)(x -
On) 
n-l 
= A(x) -
n8(~) + 8(~) L (all+1 -
all) + 8(~)(x -
an) 
= A(x) -
A(x) 8(~) + 8(~)(lln -
ao) + 8(2I)(x -
an) 
'0 fin denotes the limes inferior. It is generally assumed that "'(x) > 0 for x ~ 0, 
limz .... -:-"'(x) = 
00 and "'(x) = O(x); the last condition is obviously a natural one, 
since every function A (x) must be such that A(x) ~ x, so that A(x) = o (x). 
'1 The function A(x) + 1 = A( -1, x) enumerates all the a E ~ with 0 ~ a ~ x, 
provided 0 E ~{, whereas A (x) enumerates only the positive a ~ x. 

408 
and thus 
= A(x)(l -
8(~» + x8(~) 
~ x8(~)(l -
8(~» + x8(~) 
= 28(~) X -
82(~) x, 
PART B ARITHMETIC AND ALGEBRA 
Applying this formula to 2~ instead of~, we obtain 
8(4~) ~ 1 -
(1 -
8{2~»2 ~ 1 -
(1 -
8(~»4, 
and thus in general by iteration 
The case 8(~) = 1 may be disregarded, since in this case ~ = 3; thus, 
since 0 < 8(~) < 1, there exists a k such that (1 -
8t~»21: ~ i, and 
therefore 8(2k~) ~ i. From the following theorem we then have at once 
8(2k+I~) = 1; that is, 2k+l~ = 3, as desired. 
From A (x) + B(x) ~ x for all x ~ 0 (as follows, for example, from 
8(~) + 8(~) ~ 1) and 0 E ~ (') ~ it follows that ~ + ~ = 3. 
Proof: Assuming that there exists an x such that x ¢: ~ + ~, let us set 
~ = {bo = 0, bl , b2 , ... } and determine n from bn < x < bn+1; such 
an n certainly exists since it follows from x ¢: ~ + ~ and ~ U ~ C ~ + ~ 
that x ¢: ~. Since x ¢: ~ + ~, none of the n numbers x -
bt (i = 1, 2, ... ) 
can belong to ~, so that A (x -
1) + n ~ x-I, and thus, since 
n = B(x -
1) = B(x), we have 
x-I ~ A(x -
1) + B(x -
1) = A(x) + B(x), 
in contradiction to the assumption. 
Now in order to prove the basis property for a set ~ with vanishing 
density, it is sufficient, in view of the basis theorem, to prove the existence 
of a number s such that 8(s~) > O. It was in this way that Schnirelmann 
succeeded in proving for the first time the basis property of the set of 
prime numbers ~, and in solving the Waring problem in a new way. By 
means of this method of Schnirelmann the additive theory of numbers 
has made great progress in recent times (see Ostmann [1]). 

CHAPTER 7 
Algebraic Extensions of a Field 
Summary 
The original problem of algebra was to find the "solution" of an algebraic 
equation by means of "roots" or, in modern terms, to represent the zeros 
of a given polynomial by "rational expressions" in the zeros of (irre-
ducible) binomials xn - a. After it had been recognized (Abel) that 
for the general polynomial (of higher than the fourth degree) such a 
representation is impossible, the problem took the form of representing 
the zeros of a given polynomial in such terms as are natural or unavoidable 
for the given case. For this new and more profound problem the Galois 
theory provides a completely satisfactory solution; it shows that the 
natural instruments for the representation of the zeros of a polynomial 
are determined by the structure, in terms of its subfields, of the smallest 
field (a splitting field) that contains all the coefficients and zeros of the 
polynomial. This structure (of the splitting field in terms of its subfields) 
is completely revealed by the structure of a finite group (the Galois group) 
uniquely determined by the polynomial; the Galois group consists of all 
those automorphisms of the splitting field (the isomorphisms of the 
field onto itself) that leave fixed all the elements of the coefficient field 
of the polynomial. From the properties of this group we can deduce 
the natural means of expression for the "solution" of the equation. 
For example, by examining the group alone we can decide whether a 
splitting field which belongs to this group can be constructed by means of 
"radicals" or, in other words, whether a polynomial that corresponds to 
such a splitting field is solvable "by radicals" (binomials). Thus in the 
present chapter we first prove for every polynomial the existence of 
a splitting field and its uniqueness up to isomorphism. Then the properties 
of such splitting fields are described and, more generally, the properties 
of a finite extension K' of an arbitrary field K, i.e. a field K' which arises 
409 

410 
PART B ARITHMETIC AND ALGEBRA 
from K by adjunction of (some or all) of the zeros of finitely many 
polynomials in K[x]. Every finite extension is seen to be a vector space 
of finite dimension over K. On the basis of these results we can construct 
the Galois group of a polynomial and set up the one-to-one correspondence 
of the intermediate fields (intermediate between K and a smallest splitting 
field) with the subgroups of the Galois group, and in particular the 
correspondence of the so-called conjugate subfields with the conjugate 
subgroups. By means of this correspondence we can then set up the 
above-mentioned group-theoretic criterion for "solvability by radicals" 
(cf. § 10.1). 
In classical algebra the coefficients are usually assumed to be complex 
numbers, a restriction which does not correspond to the algebraic nature 
of the problem; thus we shall drop this restriction here and shall almost 
always consider polynomials with coefficients from an arbitrary field. 
Since we do not restrict ourselves to number fields it is clear that in the 
present chapter we are nowhere discussing the numerical "solution," 
or the numerical calculation of the zeros; our discussion is purely algebraic. 
Exercises 
1. Determine the zeros of the polynomial x 2 -
5x + 3 and express them 
rationally in terms of a zero of the binomial x 2 -
13. 
2. If the polynomial is x 2 -
7 x -
3, what binomial can then be chosen? 
3. Let the polynomial be x 2 + 0.8x + 5, and the binomial x 2 + I. 
4. Let the polynomial be x 2 + 2x + 8, and the binomial x 2 + 7. 
5. Let the polynomial x2 + x + 1, and then what binomial? 
6. If a is a zero of the binomialr -
z and f3 of x 2 + 3, show that the poly-
nomialr -
3x2 + 3x + 17 has the zeros 2a + 1, 2a . (-i + i(3) + 1, 
2a' (-~ -
l(3) + 1. 
(Hint. If x is replaced by y + 1 in the given polynomial, a simpler 
polynomial is obtained.) 
7. Letting a and f3 have the same meaning as in ex. 6, show that the 
polynomial x3 + 6x + 2 has the zeros 
a - a2, -l' (a -
( 2) + if3 . (a + (2), 
-lea -
( 2) -
lf3(a + (2). 
8. Let f3 be a zero of x 2 + 3 and 'Ya zero of x3 - l . (f3 -
1). Show that 
'Y + II'Y is a zero of x 3 -
3x + 1. 
1. 
The Splitting Field of a Polynomial 
1.1 
Adjunction 
As before (cf. 185, § 1.9), we let J[x] denote the integral domain of the 
polynomials in the indeterminate x over the integral domain J, i.e. of 

7 Algebraic Extensions of a Field 
411 
the polynomials in x with coefficients in J, where J may, in particular, 
be a field K; and by K(x) we denote the quotient field of K[x]. Also, 
in IB5, §3.10, we have proved the existence of (at least) one zero a of 
a polynomial g(x) E K[x] irreducible in K[x]; for we extended the field K 
to an extension field K(a) by the adjunction of a zero a of g(x). In general, 
we speak of the adjunction of a system S of (arbitrarily many new) 
elements a, b, c, ... to a given field K if we have constructed an extension 
field of K which includes S, i.e. all the elements of S; and in fact we have 
in mind the "smallest" such extension field, and we denote it by 
K(S) = K(a, b, c, ... ). As a fundamental domain in which the adjunction 
is carried out we assume the existence of a (fundamental) field K* 
which is an extension field of K and contains S; thus the existence of 
such a K* must be guaranteed in one way or another. Then the 
"smallest" extension field of K that contains S is to be defined as 
the (set-theoretic) intersection of all extension fields of K in K* that 
contain S; since the intersection of arbitrarily many extension fields of 
K always exists and is again an extension field of K, the desired field K(S) 
must exist. An element W E K* belongs to K(S) if and only if W can be 
represented as the value of a rational function (determined by w, though 
not uniquely) over K with arguments in S; for we see that every such 
element w belongs to every extension field K' of K that contains S; and 
the totality of such w, since it forms an extension field of K that contains S 
and is therefore contained in every K ', must be the smallest field that 
contains both K and S. In particular: if the system S contains infinitely 
many elements, then for arbitrary Z E K(S) there exists ajinite subsystem S' 
of S such that Z E K(S'). Similarly, J[S] denotes the intersection of all 
integral domains (in K*) that contain J and S. 
Example. The field K' = n(O)(i, v'2, v''l, ... , v'p, ... ) is the smallest 
extension field of the field n(O) of rational numbers that contains i and the 
square root of every prime p. As a fundamental field K* here we may take 
the field of complex numbers. 
Exercises 
9. Let K = n<O) and let K* be either the field of all real numbers or the 
field of all real algebraic numbers. Show that the zeros of x2 -
5x + 3 
lie in a field which may be denoted by K(VI3). (Cf. ex. 1.) 
10. Let K = n<O) and let K* be either the field of all complex numbers or 
the field of all complex algebraic numbers. Show that the zeros of 
x2 + 0.8x + 5 lie in K(i). (Cf. ex. 3.) 
II. Let K and K* be as in ex. 10. Show that the zeros of x 2 + x + I 
lie in K(i . yl3). (Cf. ex. 5.) 

412 
PART B ARITHMETIC AND ALGEBRA 
12. Let K and K* be as in the two preceding exercises. The binomial 
XS -
2 has a real zero, denoted by -{Y2. Show that all its zeros lie in 
K( -{Y2, i . Y3). Show that this field also contains all the zeros of 
XS -
3x2 + 3x -
17 (cf. ex. 6) and of x3 + 6x + 2 (cf. ex. 7). 
13. Let g(x) = x3 -
3x + 1 and let K and K* be as in ex. 10. 
(a) Compute g( -2), g(O), g(I), g(2) and show that the polynomial g 
has three distinct zeros gl , g2 , gs . 
(b) Let (3 and y be as in ex. 8. Show that gl , g2 , gs are in K+ = K({3, y). 
(c) Set K = K(gl , g2 ,gs). Show that K = K(gl) = K(g2) = K(gs) 
and that K is a proper subfield of K+. (Hint. K contains only real 
numbers). 
14. Let n be a positive integer with n > 1. Set K = n<O) and let K* be the 
field of real algebraic numbers. Set Pn(x) = xn -
2 and let the positive 
zero of Pn(x) be denoted by gn (thus gn = '\'Y2). Let S be the set of 
all gn with n ~ 2 and S the set of all gn with n ~ 10. Show that 
K(S) = k(S). 
1.2. 
Isomorphisms 
Two fields are said to be isomorphic to each other if they differ only 
in the notation (and meaning) for their elements and their "operations" 
(addition, multiplication); in other words, with a suitable change of the 
notation (and meaning) for the elements and the operations, a change 
which amounts to a one-to-one mapping (cf. IB 1, §2.4 and IB5, § 1.13), 
isomorphic fields may be identified. Thus "isomorphism" is an equivalence 
relation. From these remarks it is also clear what is meant by isomorphism 
of groups, integral domains, vector spaces, and so forth. The term 
isomorphism is synonymous with isomorphic mapping. 
An isomorphism of a field K onto itself is called an automorphism of K. 
If U is a subfield common to K' and K", and if f is an isomorphism of 
K' onto K" in which each element of U remains fixed (u = f(u) for 
every u E U), then f is called an isomorphism of K' onto K" over U or 
with respect to (or relative to) U. 
Example. In ll(O)(i) (see the example in §1.1) let us map i onto -i and 
every r E ll(O) onto itself, so that rl + irs is mapped onto rl -
irs; then we 
obtain an automorphism of ll(O) (i) over ll(O). 
Exercises 
15. Let K = n<O) and let K* be the field of complex numbers, or else the 
field of all complex algebraic numbers. Denote the zeros of XS -
2 by 
gl' g2, gs and let Ki = K(gt) for 1::::;; i ::::;; 3, K = K(gl , g2) = 
K(gl , g2 , gs). Prove 

7 Algebraic E.xtensions of a Field 
413 
a) there exists an isomorphism from Kl onto K2 taking every rational 
number into itself 
b) there exists an automorphism of K taking gl into g2 and every 
rational number into itself. 
16. Let gl , g2' gs and K be as in ex. 13. Prove that there exists an auto-
morphism of K taking gl into g2 and every rational number into itself. 
1.3. 
Irreducible Polynomials. Existence of a Zero 
Let K be a field and let g(x) = bnxn + ... + bo E K[xJ, where K[x] 
is the integral domain of the polynomials in the indeterminate x with 
coefficients b" in K. The problem of finding the zeros of g(x) then becomes 
the following extension problem: it is required to adjoin to K (one or more) 
zeros al , a2 , ... of g(x); that is, to adjoin elements ai such that g(ai) = O. 
Essentially the same problem is solved if we construct an extension 
K' of K such that g(x) has a linear factor (or several linear factors) in 
K'[xJ. It turns out that such fields K' can be constructed in a purely 
algebraic way, i.e., essentially by computation with polynomials over K. 
. With respect to adjunction of a single zero of g(x), where g(x) is irre-
ducible in K[x], we have already (see IB5, §3.l0) proved the following 
theorem. 
Theorem 1. Hypothesis. Let K be afield and let p(x) E K[xJ be irreducible 
in K[ x J and be of degree n ~ 2. 
Conclusions. (1) There exists (at least) one extension field L of K in which 
p(x) has (at least) one zero a. The extension field K(a) determined by the 
adjunction to K of a zero a of p(x) is uniquely determined up to isomorphisms 
over K and is isomorphic to the field K[x]jp(x) of the residue classes of 
K[x] with respect to p(x). 
(2) Moreover, K(a) = K[a], i.e., every bE K(a) is uniquely representable 
in the form b = 
Co + cIa + ... + cn_lan-l, C" E K. The field K(a) is a 
vector space over K of dimension n with the basis aO, aI, ... , an-I. 
Examples. Every rational-complex number g can be represented in exactly 
one way in the form g = 
Co + cli, where Co , CI are rational numbers. If ll(O) is 
the field of rational numbers, then every g E ll(O)( v'2) can be represented in 
the form g = 
Co + CI • v'2, where Co , CI E ll(O) are uniquely determined by g. 
1.4. 
Arbitrary Polynomials. Existence of a Splitting Field 
By a splitting field in the wider sense (abbreviated: i.w.s.) of g(x) E K[x] 
we mean an extension Z of K such that in Z[xJ the polynomial g(x) splits 
completely into linear factors. By a smallest splitting field Z' of g(x) 
we then mean a splitting field i. W.s. such that none of its proper sub-
fields are splitting fields i. W.s. of g(x). In §1.3 we constructed, for a 

414 
PART B ARITHMETC AND ALGEBRA 
polynomial p(x) irreducible in K[xJ, an extension field K' = K(a) such 
that p(x) = (x -
a) PI (x) with PI (x) E K'[x]. Now if g(x) E K[x] is an 
arbitrary polynomial, and thus perhaps reducible in K[x], any factor p(x) of 
g(x) that is irreducible in K[x] has a zero a such that g(x) = (x -
a) gl (x) 
with gl(X) E K'[x], where K' = K(a).l Then gl(X) is of degree n -
1, 
if g(x) was of degree n ~ 2. For n -
1 = 1 the field K' is already a 
splitting field i.w.s. of g(x). For n -
1 ~ 2 we can apply the same proce-
dure to KI = K' and to gl (x) E K1[x] as was just now applied to K and 
g(x). After at most n -
I repetitions of this procedure we obtain a 
splitting field i.w.s., call it Z, of g(x). But the intersection of all splitting 
fields i. w.s. of g(x) that are subfields of Z is a smallest splitting field 
of g(x), which gives us the following theorem. 
Theorem 2: Existence theorem. For arbitrary g(x) E K[x] with arbitrary 
K there exists at least one smallest splitting field Z. If g(x) can already be 
factored completely into linear factors in K[x], then K = Z. 
We must now ask whether the factorization of g(x) into linear factors 
is the "same" for all smallest splitting fields of g(x); here the word 
"same" is meant in the sense that the number of different linear factors, 
i.e., the number of distinct zeros, is always the same, and the multiplicities 
are the same in every case. That this is so is the content of the uniqueness 
theorem proved below; the proof depends essentially on the following 
isomorphism theorem, which is also useful in other ways: 
Theorem 3: Isomorphism theorem. 
Hypotheses. 
(1) Let f be an 
isomorphic mapping ofthefield K' onto thefield K", and let/be the (uniquely 
determined) extension2 off to an isomorphic mapping of K'[x'] onto K"[x"J. 
where x" = /(x'). 
(2) Let p'(x:) E K'[x'] be irreducible in K'[x'], so that 
plt(xlt) = /(p'(x') E KIt[xlt] 
is irreducible in K"[x"]. 
Conclusion. If a' and a" are zeros of p'(x') and p"(x"), respectively, 
then there exists a uniquely determined isomorphism f* of K' (a') onto 
K"(a") which is an extension off such that a" = f*(o'). 
Remark. 
If g' (x') = a~ + a~x' + a~x'2 + ... + a~x'n E K'[x'J, then 
/(g' (x'» = f(a~) + f(a~) x" + f(a~) X"2 + ... + f(a~) x"n E KIt[xlt]. 
1 The case a E K is included. 
I A mapping J of .A into (onto) E is called an extension of the mapping f of A into 
(onto) B, where A C A, BeE, if J(a) = lea) for every a E A. 

7 Algebraic Extensions of a Field 
415 
Proof. 
Let p'(x') be of degree n, so that p"(x") =.f(p'(x') is also 
of degree n. Every element b' E K' (a') can be represented in the form 
b' = g' (0'), where the polynomial 
g'(x') = 
a~ + a~x' + ... + a~_I(X')n-l E K'[x'] 
is in one-to-one correspondence with the b'; in particular, b' = a' is 
equivalent to g' (x') = a', and the same remarks hold for b" E K" (a"). 
Thus in order thatf* be an isomorphism of K'(o') onto K"(a") and also 
be an extension of f, or, in other words, in order that f*(b') = f(b') for 
every b' E K' and f*(a') = a", it is necessary that b" = f*(b'), where 
b' = g' (a') and b" = g" (a") if and only if J(g' (x') = g" (x"). For we have 
b" = f*(b') = f*(a~ + a~a' + ... + a~_1 (a')n-l) 
= f(a~) + f(a~) a" + ... + f(a~_I)(a")n-l; 
and since g" (x") is uniquely determined by b" = g" (a"), we get 
g" (x") = f(a~) + f(a~) x" + ... + f(a~_I)(X")n-l = /(g' (x'). But this 
necessary condition for an isomorphism f* is also sufficient; i.e., if in 
/(g' (x') = g" (x") we replace x' and x" by a' and a", respectively, we obtain 
an isomorphismfo such thatfo(g'(a') = g"(a") and such thatfo is anf*. 
For if/is a one-to-one mapping, then so isfo; also,/(g'(x') + /(h'(x') = 
/(g' (x') + h' (x'), so that fo(g' (0') + fo(h' (0') = fo(g' (a') + h' (0'), 
where h' (x') is also of degree not greater than n -
1, and the corresponding 
remarks hold for multip1ication; finally, fo(b') = f(b') for every b' E K' 
withfo(o') = a". 
From this isomorphism theorem we now deduce the following unique-
ness theorem. 
Theorem 4: uniqueness theorem for smallest splitting fields. 
All 
smallest splitting fields for an arbitrarily preassigned polynomial g(x) 
over K are isomorphic relative to K. More precisely: 
(I) If K* is a splitting field i. w.S. of polynomial g(x) of degree n ~ 2 
and if g(x) has the zeros a1 , ... , an in K*, then Z = K(a1 , ... , an) is the 
unique smallest splitting field of g(x) contained in K*. 
(2) If Z' = 
K(a~ , ... , a~) and Z" = K(a~ , ... , a~) are two smallest 
splitting fields of g(x), with g(a~) = g(a:) = 0, v = 1, ... , n, there exists 
an isomorphismf of Z' onto Z" over K such that a: = 
f(a~), v = 1, ... , n, 
under suitable indexing of the a~ , a:; thus in particular, every element 
of K remains fixed under f. 
Corollary. 
The factorization of g(x) into linear factors is essentially 
the same in all splittingfields (i.w.s.) ofg(x); in other words: ifin a splitting 
field T' of g(x) we have the factorization g(x) = fI~=1 (x -
b~)k; , where 

416 
PART B ARITHMETIC AND ALGEBRA 
all the b~ are distinct and the k~ are natural (positive) numbers, and if in the 
splitting field Til of g(x) we have the factorization g(x) = D!=1 (x -
b~)k;, 
where again all the 
b~ are distinct, then necessarily r = t and, 
with a suitable indexing of the b~, also k~ = k; , p = 1, ... , r. (Here 
n = k; + ... + k; = k: + ... + k;.) If T', Til are smallest splitting 
fields, there exists an isomorphismf of T' onto Til over K withf(b~) = b;. 
Proof: Proof of conclusion (1). 
The field Z is contained in every 
splitting field (i.w.s.) of g(x) that is a subfield of K*. As for conclusion (2), 
let g(x) = gll (x) ... gU
l (x) be the factorization of g(x) in K[x] into 
irreducible factors. Among these factors let gll (x) be of the highest degree 
n1 ::::;; n. We index the a~ and the a; in such a way that gll (a~) = gll (a;) = O. 
On account of the isomorphism between K; = K(a~) and K; = K(a:) 
over K (cf. § 1.4, Theorem 3), with a; corresponding to a~, the factor-
izations of g(x) in K;[x] and 
K~[x] into irreducible factors differ 
only in the notation; thus g(x) = g21(X; a~) ... g2t/X; a~) in K;[x] and 
g(x) = g21(X; a:) ... g2t (x; an in Kax] (see §1.4, remark on Theorem 3). 
2 
Again let g21 (x; a~), and therefore also g21 (x; a:), be a factor of the highest 
degree n2, so that n2 ::::;; n -
1. Furthermore, let a~ and a; be zeros of 
g21 (x; a~) and g21 (x; a:), respectively. From the isomorphism of K; and K: 
over K it follows that K; = K;(a~) and K; = K;(a;) are isomorphic 
over K, where a1 and a2 correspond, respectively, to al and a2' Thus we 
can repeat the above procedure for the factorization of g(x) in K~[x] 
and K;[x], and after at most n steps we arrive at K(a~, ... , a~) and 
K(a; , ... , a~), which are therefore isomorphic over K. 
Exercises 
17. Let K = ll<O) and let g be a zero of the binomial x 2 -
13. Then 
K(~ is a smallest splitting field of this binomial, and also of the 
polynomial x2 -
5x + 3. (cf. ex. 1). 
18. On the analogy of ex. 17, construct other exericses from exs. 2 to 5. 
19. Let K = ll<O) and let ex, f3 as in exs. 6 and 7. Prove that K(ex, (3) is a 
sma1lest splitting field both for x3 -
3x2 + 3x -
17 and also for 
x3 + 6x + 2 (cf. exs. 6, 7). 
20. Let K = ll<O) and let g be a zero of x 3 -
3x + 1. Then K(g) is already 
a splitting field. Prove that the other two zeros are ~ -
2 and 
-~ - g + 2. 
1.5. 
Application to Equations of the Third Degree 
We now assume that K is of characteristic zero or p > 2, and that 
g(x) = x 3 + b2x2 + b1x + bo E K[x], where K is not a splitting field of 
g(x). 

7 Algebraic Extensions of a Field 
417 
Theorem 5. 
(1) Ifg(x) is irreducible over K, then g(x) is also irreducible 
over every extension K' of K which arises from K by adjunction of finitely 
many square roots. 
(2) If g(x) is reducible over K without being completely reducible to 
linear factors over K, then every smallest splitting field of g(x) can be 
obtained by the adjunction of a suitable square root. Here "square root" 
means a zero of a binomial of second degree that is irreducible over K, 
say x 2 + c with c E K. 
Proof If g(x) is reducible over K without being completely reduc-
ible, then g(x) contains exactly one prime factor of second degree 
q(x) = ax2 + bx + c with a -=I=- 0, which by completing the square we can 
write in the form ofa binomial: q(x) = a(x + (2a)-lb)2 + (c - (2a)-2 b2 a); 
then (2a)-1 exists (2a -=I=- 0, since p -=I=- 2). But if g(x) is irreducible over K, 
though already reducible over K1 = K(a1), where a12 + C1 = 0 with 
C1 E K, then g(x) = (x -
(d1 + a1d2) g2(X; a1) with d1 , d2 E K; and thus 
the polynomial r(x) = (x - (d1 + a1d2)(X - (d1 - a1d2) = (x - d1)2 + c1d22 
belongs to K[x], is of second degree, and has the linear factor 
x - (d1 + a1d2) in common with g(x), a fact which is inconsistent with 
the irreducibility of g(x) over K, since the GCD is already determined 
in K[x] by the Euclidean algorithm (IB5, §2.9 and IB6, §2.10). Now let Kn 
be obtained from K by successive adjunction of finitely many "square 
roots" ai' ... , an, where all is a square root over KII- 1 = K(a1 , ... , all-I) 
and Ko = K, v = I, ... , n; in other words, all2 + CII = 0 with CII E KII- 1 
and x2 + CII is irreducible over KII _ 1 . Then if g(x) is reducible over Kn 
(but irreducible over Ko), there exists a k with 0 ~ k ~ n -
I such that 
g(x) is irreducible over Kk but reducible over Kk+1 . Thus in the preceding 
argument we can replace K by Kk and a1 by ak+1, and finally K1 by 
Kk+1 = Kk(ak+1), and in this way again arrive at a contradiction. 
Examples. 
Problem of the duplication of the cube. The problem of con-
structing the edge of a cube with twice the volume of a given cube is not solvable 
with ruler and compass (such a construction corresponds algebraically to the 
solution of equations of the first and second degree). For this problem leads to 
the equation a3 -
2 = 0; and x 3 -
2 is irreducible in K[x], where K is the field 
of rational numbers (in general, if the polynomial r + b2x2 + b1x + bo has 
integral coefficients and is reducible over K, then it has an integral zero (cf. 
IB5, §4.4) which is a factor of bo; but none of the numbers ± 1 and ± 2 is a zero 
of x 3 -
2). 
Problem of the trisection of an angle. The problem of dividing a given angle 
into three equal parts cannot be solved for every angle with ruler and compass. 
For the problem leads to an equation a3 -
3a + s = 0, where s is the length 
of the chord subtending the given angle, so that 0 < s < 2. But for rational s 
the polynomial x 3 -
3x + s is in general irreducible over the field K for rational 
numbers, e.g., for s = 1. 

418 
PART B ARITHMETIC AND ALGEBRA 
Exercises 
21. Prove 
(a) the polynomial x3 + 6x + 2 is irreducible over Il<O) 
(b) if gl and g2 are two distinct zeros, then Il<O)(gl , g2) is a smallest 
splitting field (cf. ex. 7). 
22. Solve ex. 21 for the following polynomials: 
(a) x3 -
3x2 + 3x -
17, 
(b) x3 -
2, 
(c) x3 -
3x + 1. 
Prove in case (c) that Il<O)(gl , g2) = Il(O)(gl). (cf. ex. 13). 
23. Determine whether each of the following polynomials is irreducible 
over Il<O), and for the reducible ones determine the smallest splitting 
field: 
x3 -
5x2 + 3x + 1, 
x3 -
2x + 1, 
x3 -
x2 -
8x + 12, 
x3 -
5x2 -
2x + 7. 
2. 
Finite Extensions 
For the Galois theory, to be developed in the following sections, 
certain other properties of the smallest extension fields of polynomials 
are of essential importance. In describing these properties we begin with 
the fact (cf. §1.3, theorem 1) that the extension K(a) of K generated by 
the adjunction of a single zero a of a polynomial over K is a yector space 
over K with dimension n equal to the degree of the irreducible polynomial 
in K[x] that has a for a zero. However, not only a but every b E K(a) 
is a zero of an (irreducible) polynomial in K[x]; in other words, every 
bE K(a) is algebraic over (or with respect to, or relative to) the field K. 
For the fact that K(a) is a ring (and even a field) means that bl = b E K(a) 
implies b" E K(a) for v = 1,2, ... , and also bO = 1 EKe K(a). Since K(a) 
is of dimension n over K, the n + 1 elements bl-', JL = 0, 1, ... , n, are 
1inearly independent over K (cf. §1.3, Theorem 1); thus there exist elements 
cl-' E K, not all equal to zero, for which cobo + c1bl + ... + cnbn = o. 
Thus b is a zero of a polynomial in K[x] of degree not greater than n 
(the case b = 0 is included). For brevity we shall say that an extension 
K' of K is algebraic over K if every element bE K' is algebraic over K. 
If K' is algebraic over K, then every intermediate field T between K and K', 
i.e., every field T with K eTC K', is also algebraic over K; and K' is 
itself algebraic over T. Finally, we shall say that an extension E of K is 
finite over K if E is a vector space of finite dimension over K. We now 
observe that our proof of the fact that b E K(a) is algebraic over K if a is 
algebraic over K made no use of any of the properties of K(a) except 

7 Algebraic Extensions of a Field 
419 
that it is a vector space of finite dimension over K. We thus have the 
following theorem. 
Theorem 1. 
Every extension E of K that is finite over K is algebraic 
over K. In particular, K(a) is algebraic over K if a is algebraic over K. 
Remark. 
An extension of K that is algebraic over K is not necessarily 
of finite dimension. For example, the field A of all algebraic numbers 
(over the field Il<O) of rational numbers) is not of finite dimension, since 
Il<O)[x] contains irreducible polynomials of arbitrarily high degree, e.g., 
cI>,,(x) = x p - 1 + ... + x + 1, for prime p (cf. §9.2), so that A cannot 
have a basis of finitely many elements over Il<o). 
Examples of finite extensions are provided by the following theorem: 
Theorem 2. 
(1) Every extension of an arbitrary field K that can be 
generated by the adjunction of finitely many elements algebraic over K 
is finite (and therefore algebraic) over K. Conversely, every finite extension 
can be generated by the adjunction of finitely many elements algebraic 
over K. 
(2) If the arguments of a rational function over K are algebraic over K, 
then the values of the function are also algebraic over K. 
Proof. 
(1) Let K (ai, ... , ak) be the given extension, where the aK are 
algebraic over K, K = 1, ... , k. For k = 1 the assertion is true by the 
preceding theorem. We now argue by complete induction on k. Assume 
that the assertion is already proved for all k = 1, ... , m (m ~ 1). 
Then it is also true for k = m + 1, since by the induction hypothesis 
K' = K(a1, ... , am) has a basis 'YJl , ... , 'YJr and, if we set am+1 = a, then for 
the case K' (a) = K' there is nothing to prove; and otherwise the element a, 
since it is algebraic over K, is a zero of the polynomial z(x) E K[x] C K'[X] 
and is thus algebraic over K'. By the preceding theorem K" = K'(a) 
has a basis over K', say (Jl' ... , (Jt. For every bE K" we thus have 
b = C1(J1 + ... + Ct(Jt with c., E K'. Moreover, c., = d.,I'YJl + ... + d.,r'YJr 
with d.,p E K, so that b = L.,.p d.,p'YJp(J.,. Here the r . t elements 'YJp(J., are 
linearly independent over K, since b = 0 implies c., = 0 and thus d.,p = O. 
Since the bE K" were arbitrary, the elements 'YJp(J., form a basis for K" 
over K. 
The converse assertion follows from the fact that every finite extension, 
since it is algebraic, can be generated by the adjunction of the algebraic 
basis elements. 
(2) Since ai' ... , an are algebraic over K, it follows that K" = K(a1, ... , an) 
is algebraic over K (assertion (1) and therefore contains all values of 
rational functions as described in assertion (2). 
From the proof of assertion (1) of the preceding theorem it also follows 
that if rand t are the dimensions of K' over Kand K" over K', respectively, 

420 
PART B ARITHMETIC AND ALGEBRA 
then K" has the dimension r . t over K. The dimension mover K of a 
finite extension E of K is also called the degree of E over K, or in symbols: 
m = degree (E: K). Thus we have the following theorem: 
Theorem 3. 
(I) If E' or E" is afinite extension of K or of E', respectively, 
then E" is also a finite extension of K. 
(II) Furthermore, deg (E" : K) = deg (E" : E') . deg (E' : K). 
1. Remark. If K' is algebraic over K, and K" is algebraic over K', 
then K" is also algebraic over K. Proof: Every element of K" is a zero 
of a polynomial with coefficients in K', and each of these finitely many 
coefficients is algebraic over K and thus belongs to a finite extension of K, 
so that the assertion follows from theorem 3 of §2. 
2. Remark. If K is of characteristic p = 0 or p > 2 and if degree 
(E: K) = 2, then E = K(a), where a is a zero of a polynomial of second 
degree x 2 + c (c E K) that is irreducible over K. 
Exercises 
24. Let K = Il(O) and let gl and g2 be two distinct zeros of r + 6x + 2. 
Set K(gl) = Kl and Kl(g2) = K. Determine deg(Kl : K), deg(K : Kl), 
deg(K : K). Now let TJ be a zero of x 2 + 3 and show that TJ can be 
chosen in K, so that K+ = K(TJ) is thus a subfield of K. Determine 
deg(K : K+) and deg(K+ : K). (cf. exs. 7, 21.) 
25. Again let K = Il(O). The polynomial x6 + IOxs + 125 has six distinct 
zeros (in a suitable extension). Let K = K(gl , g2 , gs , g4 , g5 , g6) and 
determine deg(K : K). Prove that the zeros £1 and £2 = £12 of the 
polynomial x2 + x + 1 can be chosen in K and that we may set 
g2 = £lgl , gs = £12gl , g4 = 5jgl, g5 = £lg4' g6 = £12g4· Determine 
deg(K: K(gl))' deg(K(gl) : K), deg(K : K(£l)), deg(K(£l) : K) and show 
that K = K(gl £1). 
3. 
Normal Extensions 
A smallest splitting field Z of an irreducible polynomial in K[x] has 
the further property that it is normal over K, or is a normal (or Galois) 
extension of K. Here an extensionN of K is said to be normal over K if (a) N 
is algebraic over K and (b) every polynomial g(x) that is irreducible in 
K[x] can be factored completely into linear factors in N[x] provided that N 
contains (at least) one zero of g(x). The above assertion concerning Z 
is then a special case of the following theorem. 
Theorem 1. 
Criterion for normal (not necessarily finite) extensions. 

7 Algebraic Extensions of a Field 
421 
The extension P of K is normal over K if and only if P can be generated 
by the adjunction of all the zeros of (arbitrarily many) polynomials in K[x]. 
1. Corollary. 
In particular, every smallest splitting field of a polynomial 
in K[x] is normal over K. 
Proof. (A) Sufficiency. (a) The field P is algebraic over K; for every 
a E P is contained (cf. §l.l) in an extension K(b1 , ••• , bk ) of K, where 
the bl( are zeros of polynomials in K[xJ, and therefore (§2, Theorem 2) 
the element a, and with it the whole field P, is algebraic over K. 
(b) Let g(x) be irreducible in K[x] with g(a) = 0 and a E P. Then 
we must show that g(x) falls into linear factors in P[x]. But by (a) 
the field P contains elements b~, ... , b'm algebraic over K, such that 
a E K(b~ , ... , b~) and such that the irreducible polynomial hl-'(x) E K[x] 
determined by hl-'(b~) = 0 falls into linear factors (x -
bl-'T) in P[xJ, 
'T = I, ... , tl-' ; JL = 1, ... , m. (For by the definition of P, if the bl-' are in P, 
then so are all the zeros of those irreducible polynomials in K[x] for 
which the b~ are zeros.) Now let h(x) E K[x] be the product of all the 
hl-'(x), and let C1 , ••• , Cn be all the zeros of h(x). Since 
a E K(b~ , ... , b'm) C K(c1 , ••• , cn) C P 
we have a = r(c1 , ... , cn), where r denotes a rational entire function of 
n arguments with coefficients in K (§1.3, Theorem 1). If we permute the 
C1 , ... , Cn in all n! ways, we obtain n! elements ap E P from r(c1 , ... , cn). 
The coefficients of the polynomial f(x) = (x -
al) .. , (x -
an!) are 
symmetric in the CII and thus belong to K (since h(x) E K[x]) (see IB4, §2.4), 
where we agree to set a1 = a. Since g(a) = f(a) = 0 and since g(x) is 
irreducible in K[x], it follows that g(x) is a divisor of f(x) , so that the 
zeros of g(x) are included among the ap and consequently belong to P; 
but this means that g(x) falls into linear factors in P[x]. 
(B) Necessity. 
Let K' be a normal extension of K, so that K' is 
algebraic over K by definition. Then every a E K' is a zero of an irreducible 
polynomial q(x) E K[x] and all the zeros of q(x) belong to K' (since K' 
is normal). Thus every a E K ', and therefore the entire field K' itself, 
is obtained by adjunction of all the zeros of all the q(x). 
2. Corollary. If K' is a finite normal extension of K, then K' can be 
obtained from K by the adjunction of all the zeros of a single polynomial. 
Consequence. Every finite extension E of K is contained in a normal 
extension N* of K. For if b1 , ••• , br is a basis of E over K and if hp(bp) = 0 
with hp(x) E K[x] irreducible in K[x], p = I, ... , r, let us adjoin all the 
zeros of all the polynomials hp(x). By theorem I, §3 the extension N* of 
K obtained in this way is normal over K (and also over E), and furthermore 
ECN*. 

422 
PART B ARITHMETIC AND ALGEBRA 
Consequently we make the following convention: 
Convention. 
Whenever in any of the following sections we are dealing 
with a finite extension, we shall agree, even without explicit mention of 
this fact, that we are operating in a normal extension field N* of the 
given finite extension. 
Remark. 
In the sufficiency part §3(A) of the proof for theorem 1 the use 
of the theory of symmetric functions in (b) can be avoided if we have recourse 
instead to the theory of isomorphic mappings in §6, as follows. Let g(x) be 
irreducible in K[x] and let g(a) = 0 with a E K' = K(Cl, ... , Cn) (see the 
proof (A), (b)). Also let there exist a b not belonging to K', for which g(b) = O. 
But K(a) and K(b) are isomorphic over K (see§6) and thus K'(a) = K(a, C1 , ••• , Cn) 
and K/(b) = K(b, C1 , ••• , Cn) are also isomorphic over K. In the isomorphic 
mapping of K' (a) onto K' (b) over K the elements Cl , ••• , Cn are only permuted 
among themselves. Also, since a = r(c1 , ••• , Cn), where r is a rational function 
in n arguments with coefficients in K, it follows that b = f(Cl , .. " Cn) with 
f rational over K, so that bE K ', which contradicts the assumption. 
Exercises 
26. In exs. 19 to 25 determine which of the fields are norma] extensions 
of Il<O). 
4. Separable Extensions 
For what follows it is often important to know under what conditions 
we may conclude that if a polynomial is irreducible in K[x] all its zeros 
are distinct. If the zeros of an irreducible polynomial in K[x] are all 
distinct (so that the number of distinct zeros of the polynomial is equal 
to its degree), the polynomial is said to be separable over K. (Examples 
of nonseparable polynomials will be given below.) If g(x) is separable 
over K and if K' is an arbitrary extension of K, then the factors of g(x) 
which are irreducible over K' are likewise separable (over K '). Every 
zero of a polynomial that is separable over K is also said to be separable 
over K, and similarly every extension of K whose elements are all separable 
over K is said to be separable over K; and every a E K is said to be separable 
over K. Separable elements and extensions are algebraic (over K) by 
definition. Moreover, every finite separable extension K' of K is a simple 
extension, i.e., can be represented in the form K' = K(a), as will be proved 
below (cf. §6, theorem 3). We also make the following remark. The 
extension K(al' ... , an) is separable over K if (and only if) each of the 
elements al , ... , an is separable over K. (The proof, which will not be 
given here, depends on the fact that only for separable extensions is the 
number of isomorphisms of L = K(al' ... , an) over K (cf. §6) equal to 
degree (L : K).) 

7 Algebraic Extensions of a Field 
423 
4.1. 
Preliminary Remark. 
Computation in Integral Domains J with 
Characteristic p > 0 
(1) For every a E J the sum a + ... + a = p . a = 0 if the left-hand 
side has p summands a. In particular, it follows for p = 2 that a = -a. 
(2) For arbitrary a1 , ••• , ak E J and an arbitrary integer f > 0 we have 
(al + ... + ak)' = aIr + '" + akr, if r = pl. 
Proof. 
In view of (1) the desired assertion follows for k = 2 and 
f = 1 from the binomial theorem (lB4, §1.3) and the fact that the binomial 
coefficients are divisible by p (cf. IB6, §4.4 (29). But if the assertion holds 
for k = 2 and for f, then it also holds for k = 2 and f + 1, since for 
r' = pl+l we have (a1 + a2)" = «a1 + a2),)p = (a{ + a{)p = ar + u~'. 
Finally, if the assertion holds for a given k and (arbitrary)f, then it holds 
for k + 1 andf, since 
(a1 + .. , + ak+1)' = «al + ... + ak) + ak+1>' 
Furthermore, 
(2a) 
For it follows from (2) that a{ = «a1 -
a2) + a2Y = (al -
a2)' + a{ . 
(3) For a E K we have aP = a if (and only if) a belongs to the prime field 
Il(p) of K. 
(Since every a E Il(p) can be written as the sum of unit elements, 
it follows from (2) that aP = (1 + ... + l)p = I + ... + 1 = a. Con-
versely, if a P = a, then a is a zero of x P -
x; but this polynomial can 
have at most p distinct zeros, and by what has just been proved the 
a E Il(p) already account for exactly p distinct zeros. 
(4) The derivative h'(x) ~r a polynomial h(x) E J[x] of at least the first 
degree is the identically vanishing function if and only if J is of characteristic 
p > 0 and h(x) is a polynomial in x P with coefficients in J; in other words, 
h(x) = g(x P) with g(x) E J[x). 
Proof. 
Let h(x) = ao + alx + ... + anxn, n ~ 1, with all E J and 
an -=I=- O. 
Then 
h' (x) = al + 2a2x + '" + nllnxn- 1• 
If p = 0, 
then 
nan -=I=- 0, so that h'(x) -=I=- O. For p > 0, on the other hand, h'(x) = 0 
if and only if vall = 0, v = 1, ... , n. But this condition is automatically 
fulfilled for v == 0 (mod p), so that all = 0 for v =1= 0 (mod p) is a sufficient 
condition for h' (x) = O. But then h(x) = L;=o appx/, from which the 
assertion follows. 
4.2. 
If K is of characteristic zero, then every irreducible polynomial 
is separable, as follows from the next theorem. 

424 
PART B ARITHMETIC AND ALGEBRA 
Theorem I. 
Criterion for separability. (I) An irreducible polynomial 
g(x) in K[x] is separable over K if and only if either (a) the field K is of 
characteristic 0 or else (b) the field K is of characteristic p > 0 and g(x) 
cannot be written as a polynomial in x'P over K. 
(II) All the zeros of an irreducible polynomial n(x) in K[x] have the same 
multiplicity. For p > 0 and nonseparable n(x) this multiplicity is a power 
q = p'\ e ~ I, of the characteristic p of K. Moreover, n(x) = h(xq), 
where h(y) E K[y] is irreducible and separable over K. 
Proof. 
By IB4, §2.2 the polynomial g(x) has at least one nonsimple 
zero a if and only if g(x) and g' (x) have a common zero and therefore 
are not coprime* (IB5, §2.9, especially (27). Since g' (x) E K[x] and g' (x) 
is of lower degree than g(x) (in case g' (x) -=I=- 0), and since g(x) is assumed 
to be irreducible in K[x], we must have g' (x) = 0 if g(x) has multiple 
zeros. But then the assertion (I) follows from §4.I, (4). 
We now assume that p > 0 and that, if g(x) = 
L~=o a.,xll has multiple 
roots, then q = pe, with e ~ I, is the highest power of p that divides all those 
pp for which ap'P -=I=- O. Then we haveg(x) = (xq - bl ) ... (xq -
bt) = h(xq). 
Here the zeros bl , ... , bt of h(y) are distinct, since otherwise h(y) would 
have multiple zeros and it would follow from (I) that h(y) = k(y'P) and 
g(x) = m(x'Pq), in contradiction to the definition of q. But now if dT 
is a zero of x q -
bT
, we have g(x) = [(x -
dl ) .•• (x -
dt)]q, where all 
the dT are distinct, which proves the first part of (II). But h(y) is irreducible 
over K, since h(y) = hI (y) . h2(y) implies g(x) = hI (xq) . h2(xq), which 
means that if h(y) is irreducible, then so is g(x). But then, since the zeros 
bl , ... , bt of h(y) are distinct, h(y) is separable. 
Example of a nonseparable polynomial. 
Let K'P be of characteristic 
p > 0, and let z be an indeterminate over K'P. Then the polynomial 
x'P -
z is irreducible over K'P(z) (for the proof see, for example, Haupt [I], 
13.3, theorem 3); on the other hand, it follows from a'P -
z = 0 that 
x'P -
z = x'P -
a'P = (x -
a)'P, so that x'P -
z has a zero of multiplicity p 
withp ~ 2. 
Exercises 
27. Let z be an indeterminate over Il(5), K = Il(5)(z). Prove that the 
polynomials x 2 + x + z and x lO + x 5 + z are both irreducible over 
K, but only the first one is separable. 
'" Two polynomials are said to be coprime if they have no common factor of positive 
degree. 

7 Algebraic Extensions of a Field 
425 
5. Roots of Unity 
5.1. 
Definition of the hth Roots of Unity 
Introductory Remarks. As the coefficient domain we take an arbitrary 
field K. Then by an hth root of unity we mean a zer03 of the polynomial 
(1) 
where 1 is the unit element of K (h is a natural number). 
The coefficients of fh(x) belong to the prime field II of K, for which 
in the case of characteristic 0 we take the field II<O) of rational numbers 
and in the case of characteristic p4 the field II<p) of residue classes mod p 
(in the ring of integers see IB5, §3.7 and IB6, §4.1). 
From the algebraic point of view it is then natural to ask the following 
important questions: 
1. To what extent canfh(x) befactored over II (and over K)? 
2. Starting from II (or from K), how do we obtain a smallest splitting 
field for fh(x)? What can be said about the structure of this field? 
In sections 5, 8, and 9 we shall obtain far-reaching answers to these 
questions. 
The roots of unity are of great importance for many problems in 
arithmetic and algebra. It is obvious that they are closely connected with 
the theory of "pure equations," i.e., with the problem of determining 
the zeros of the polynomial 
(2) 
If a -=I=- 0,5 we have the following theorem. 
Theorem 1. If (X is a zer06 of (2), and if , is an hth root of unity, then 
ex • , is also a zero of (2). Moreover, if (Xl and (X2 are two (not necessarily 
distinct) zeros of (2), then (X2/(Xl is an hth root of unity. Thus we can obtain 
all the distinct zeros of(2) by multiplying anyone of them with all the distinct 
hth roots of unity. 
In §5.2 we shall discuss the conditions under which the polynomial (1) 
has multiple zeros; the reader will have no difficulty in deriving the 
corresponding results for the polynomial (2). 
3 Belonging to K or to a suitable extension of K. 
" In sections 5, 8, and 9 the number p is always a positive prime. 
r; The case a = 0 is of no interest. 
S Belonging to K or to a suitable extension of K. 

426 
PART B ARITHMETIC AND ALGEBRA 
Note. It is well known that in the field of complex numbers the hth 
roots of unity can be represented in the following form (cf. IB8, (5): 
i'k'~ 
27T 
27T 
(3) 
'h,k = e 
h = cos k . h + i . sin k . h 
(k = 0, I, ... , h -
I). 
In the Gaussian plane they are represented by the vertices of a regular 
h-gon with its center at the origin and one of its vertices at the intersection 
of the postive real axis with the unit circle. Although this representation 
is advantageous for many purposes, we shall not make use of it here 
(in sections 5, 8 and 9), even for the case of characteristic 0, but shall 
develop a purely algebraic theory of the hth roots of unity. 
5.2. 
Multiplicity of the Zeros of fh(X) 
As indicated above, we shall now undertake to find out when the 
polynomial (I) has mUltiple zeros. As a criterion for this purpose we make 
use of the following well-known theorem (cf. §4.2, beginning of the proof). 
The polynomial f(x) in K[x] has multiple zeros7 if and only if f(x) has 
a common factor of positive degree with f' (x); in other words, f(x) has no 
multiple zero if and only if it is coprime with f' (x). 
We form the derivative 
(4) 
It is obvious that in general this derivative has no common zero with (I) 
and is therefore coprime with (I). An exception occurs only if K is of 
prime characteristic p and p is a factor of h. Before dealing with this 
exceptional case we here present the main result. 
Theorem 2. If K is of characteristic 0, then fh (x) has only simple zeros. 
The same situation holds if K is o/prime characteristic p but p is not afactor 
ofh. 
If either one of the hypotheses of theorem 2 is satisfied, i.e., if the 
characteristic is equal to ° 
or if the positive characteristic p is not a factor 
of h, we speak of the principal case. 
Now let us turn to the exceptional case: the characteristic is p and p I h. 
Let the highest power of p that is a factor of h be pI, so that h = pI . ii 
and p l' ii (withf ~ I). Then, as we shall show in §8,8 we have 
(5) 
Since by theorem 2 the polynomial f" (x) has only simple zeros, it follows 
thatfh(x) has the same zeros asf,,(x), but each of them is of mUltiplicity pl. 
7 In K or in a suitable extension. 
S Independently, of course, of the present section. 

7 Algebraic Extensions of a Field 
427 
Exercises 
28. Let K = Il(3) and show that in K[x] we have 
f4(X) = (x -
1) . (x + 1) . (x2 + 1) 
and 
f36(X) = 
[.I~(X)]9. 
5.3. 
The Group ffih of hth Roots of Unity 
In this subsection we confine ourselves to the principal case, so that 
by theorem 2 fh(X) has only simple zeros. Thus if both '1 and '2 are 
hth roots of unity (possibly with '1 = '2), then '1/'2 is also an hth 
root of unity, from which it readily follows that under multiplication 
the set of hth roots of unity forms an Abelian group of order h. We shall 
denote this group by ffiA • Now let d be a (positive) factor of h. We first 
note that if (as we are now assuming)fh(x) comes under the principal case, 
then the same is true of fa(x). Thus we can speak of the group ffia . Also, 
since ,a = 1 implies ,h = 1, the group ffia is a subgroup of ffih . The 
order of each element of ffih is a factor of h. An hth root of unity, is 
called a primitive hth root of unity if it is of order h or, in other words, 
if no positive integer g < h exists such that ,g = 1. We shall denote the 
number of primitive hth roots of unity by !/J(h).9 Then, since the order 
of each element ffih is a factor of h and every primitive dth root of unity 
(with d I h) is an hth root of unity, we have 
(6) 
L !/J(d) = h. 
alh 
We now show that this result implies 
(7) 
!/J(h) = cp(h), 
where cp(h) is the Euler function (see IB6, §4.2). The proof of (7) is by 
complete induction, which we first carry through for characteristic zero. 
I. It is obvious that there is exactly one primitive first root of unity, 
namely 1. Thus !/J(l) = cp(l) = 1. 
II. Now assume that h > 1 and (7) is true for all smaller numbers. 
Then it follows from (6) that 
(8) 
!/J(h) = h -
L 
!/J(d) = h -
L cp(d). 
alh,a*h 
alh,a*h 
But the Euler function (see IB6, §5, theorem 7) satisfies the well-known 
equality, corresponding to (6), 
(9) 
L cp(d) = h, 
alh 
9 It will turn out that this number (for the principal case) does not depend on K and 
is thus independent, in particular, of the characteristic of K. 

428 
PART B ARITHMETIC AND ALGEBRA 
from which we obtain 
(10) 
cp(h) = h -
L 
cp(d) , 
alh.a*h 
so that the desired assertion follows directly from a comparison of (8) 
and (10). 
It is easy to see that this method of proof is also valid for a prime 
characteristic p, provided (principal case) that h is not divisible10 by p. 
Thus (7) is completely proved for the principal case. From (7) it follows 
in particular that I/J(h) > 0, so that ffih is a cyclic group (see IB2, §5) of 
order h. Thus the structure of the group ffi h is completely determined, 
and we' have the following theorem. 
I 
Theorem 3. 
The multiplicative group ffih of the hth roots of unity is a 
cyclic group of order h. Thus it is isomorphic to the additive group (the 
module) of residue classes of the ring of integers mod h. 
Exercises 
29. Let K be of characteristic *2. Prove that there exist two primitive 
fourth roots of unity and that they are the zeros of the polynomial 
x 2 + 1. Construct ffi 4 . 
30. Let K be of characteristic *2, *3. Prove that there exist four 
primitive twelfth roots of unity and that they are the zeros of the 
polynomial xi -
x 2 + 1. Construct ffi12 . Prove that if g is a primitive 
twelfth root of unity, then g2 is a primitive sixth roots and gs is a 
primitive fourth root. 
5.4. 
The Cyclotomic Polynomial tPh (x). 
In this subsection we again restrict ourselves to the principal case. 
We now introduce the polynomial, called a cyclotomic polynomial, 
whose zeros are the primitive hth roots of unity (each with multiplicity 1) 
and whose leading coefficient is 1. We shall denote this polynomial by 
tPh(x) or also, in order to emphasize its dependence on the characteristic 
of the field K, by tPhO) (x) or tPhP) (x). We now prove the following theorem. 
Theorem 4. 
The coefficients oftPh(x) belong to the prime field II of K. 
We first note that the argument leading to (6) indicates the following 
connection between the polynomialsfh(x) and the cyclotomic polynomials: 
(11) 
Il tPa(x) = fh(X). 
alh 
10 If h is divisible by p, we can set !fJ(h) = o. 

7 Algebraic Extensions of a Field 
429 
It is easy to see that each of the factors in the product on the left-hand 
side of (11) is a factor of fh(X), that any two of these factors are coprime, 
and finally that every zero of fh(X) is a zero of one of these factors. 
The proof of theorem 4 now follows by complete induction, where 
again in the case of characteristic p we must restrict ourselves to integers h 
that are not divisible by p.ll 
I. We have 4">l(X) =fl(X) = x -
I, so that the coefficients of 4">l(X) 
belong to II. 
II. Now assume that h > 1 and that the assertion is true for all smaller 
numbers. For characteristic p we again restrict ourselves to the case p l' h. 
From (11) we have 
(12) 
4">h(X) . n 4">aCx) = fh(X). 
dlh 
d-:f-h 
For abbreviation, we set the second factor on the left-hand side of (12) 
equal Ph(x), so that (12) becomes 
(13) 
From the induction hypothesis it is easy to see that all the coefficients 
of Ph (x) belong to II and that the same is true for fh (x), and consequently 
(for example, by the division algorithm) the desired statement is also 
true for 4">h(X). Thus the proof of theorem 4 is complete. 
For characteristic 0 this theorem can be sharpened as follows. 
Theorem 5. If K is a field of characteristic 0, then 4">h (x) has integral 
coefficients. 
It is only necessary to repeat the steps of the above proof and to note 
that in the application of the division algorithm the coefficient of the 
highest power of x in Ph(x) is 1. 
We now investigate the relationship between 4">kO)(X) and 4">kP ) (x). 
Of fundamental importance here is the fact that there exists exactly one 
homomorphism H(p) of the ring of integers G onto II(p). The homo-
morphism H(p) is obtained by setting the integer g in correspondence 
with the residue class mod p determined by g. It is easy to show that (with 
respect to addition and multiplication) this correspondence is a homo-
morphism (cf. IB5, §3.7, and IB6, §4.I) and that no other homomorphism 
can exist (the image of the number I, which must be the unit element 
of II(p), already determines the image of every integer). We now have 
the following theorem. 
11 For h divisible by p we can set <I),,(x) = 1.' 

430 
PART B ARITHMETIC AND ALGEBRA 
Theorem 6. If the homomorphism H(p) is applied to the coefficients of 
C/>~O) (x), the polynomial C/>~O) (x) becomes C/>~P) (x). 
For the proof it is only necessary to repeat the steps of the proof of 
theorem 4. 
5.5. 
Computation of the Cye/otomic Polynomials. We note that this proof, 
in particular the steps (12) and (13), actually enables us to calculate the 
cyclotomic polynomials. As an example we calculate the case h = 12, where 
we must avoid the characteristics 2 and 3. Since 12 has the factors 1, 2, 3, 4, 6, 12, 
the individual steps are as follows (we leave the multiplication and division 
to the reader). 
I. 
<PI(x) = hl(x) = x-I 
II. 
P2(x) = <PI(x) = x-I; <P2(x) = x + 1 
III. 
P3(x) = <PI(x) = x-I; <P3(x) = x2 + X + 1 
IV. 
Pix) = <PI (x) • <P2(x) = x2 -
I; 
<Pix) = X2 + 1 
V. 
P6(x) = <PI(x) • <P2(x) • <P3(x) = X4 + x 3 - x-I; <P6(x) = x 2 -
X + 1 
VI. 
PI2(X) = <PI(x) • cJ'>2(X) • <P3(x) • <Pix) • <P6(x) = x 8 + x 6 -
x2 -
1; 
<P12(X) = X4 -
x2 + 1 
These relations hold for all characteristics other than 2 and 3. The reader 
may illustrate theorem 6 for the case h = 12, p = 7. 
For characteristic 2 every twelfth root of unity' is also a third root, and for 
characteristic 3 every twelfth root is also a fourth root, so that in the first case 
we may use formulas I and III, and in the second, I, II, and IV. 
The following representation, in terms of the Mobius function I-'(n) (cf. IB6, §5) 
also holds for the principal case: 
(14) 
<P1l(x) = n [/,'(X)tG), 
di" 
but we shall make no further use of it. For comparison we calculate <P12(x) 
from (14). Since (j.L(1) = 1-'(6) = 1,1-'(2) = 1-'(3) = -1, and 1-'(4) = 1-'(12) = 0, 
we have 
Exercises 
<P12(X) = [(XI2 -
I) . (x2 -
I)] : [(x6 -
I) . (x4 -
1)] 
= (xU. -
Xl2 -
x 2 + I) : (xiO -
x6 -
x' + I) 
= x' - x 2 + I. 
31. Let K be of characteristic *2, *3. Determine C/>2ix). How is C/>2ix) 
related to C/>12(X) and C/>6(X)? (cf. ex. 30.) Prove that 
(X24 -
1) . (xi -
1) 
tP24(X) = (X12 _ 1) . (x8 -
1) . 

7 Algebraic Extensions of a Field 
431 
5.6. 
Concluding Remark 
We return to the two questions raised in §5.1. Let, be a primitive hth 
root of unity (in a suitable extension of K); then K<') is obviously the 
smallest splitting field not only of the polynomial/hex) but also of cJ>h(X). 
Thus if '1 and '2 are two primitive hth roots of unity, then K<'I) = K<'2)' 
As a result, cJ>h(X) is either irreducible over K or splits into irreducible 
polynomials, all of which are of the same degree. In §8 we deal with the 
case that K is a finite field. In §9 it will be shown that cJ>h(X) is irreducible 
over the field Il<O) of the rational numbers. 
6. 
Isomorphic Mappings of Separable Finite Extensions 
The Galois theory of separable polynomials is based on a study of the 
isomorphic mappings I relative to K (or over K) of a separable finite 
extension E of K in a separable normal extension field N* of K (cf. the 
end of §3, convention). Thus I leaves every element of K fixed, while 
every element of E is mapped onto an element of N*; so we may write I 
more explicitly in the form I(E: K; N*) or .T(E: K). The images a' of 
an element a E E under the mappings I(E: K) are called the conjugates 
0/ a with respect to E over K; or in symbols, a' = conj (a; E : K). By the 
number. of conj(a; E : K) we mean the number of mappings I(E: K), even 
if the conj(a; E : K) are not all distinct (compare the following examples). 
Examples. 
(1) If E = K(a) is separable over K, it follows from §1.4, 
theorem 3, that all the mappings J(E: K) are obtained by replacing a with 
each of the zeros (in N*) of the irreducible (in K[xD polynomial g(x) for 
which g(a) = O. The number n of the J(E: K) is thus equal to degree (E: K), 
or to the maximal number n for which the aO, ... , an - 1 are linearly independent 
over K, or finally to the degree n of g(x). For since E is separable over K, the 
number n is equal to the number of zeros of g(x), in view of the fact that these 
zeros, and thus also the conj (a; E : K), are all distinct. But if, for example, 
bE K, then the conj(b; E: K) are all equal, since they are all equal to b. 
(2) Now let K' = K(a), or E = K" = K'(b), be separable over K or over K' 
respectively, where n' = degree(K': K) ~ 2 and nil = degree(K" : K) ~ 2. 
The number of the J(E: K) is again equal to degree(E: K) = n' . nil = n 
(cf. §2, theorem 3). But among the conj(a; E: K) there are only n' distinct 
elements; for under each of the mappings J(E: K) the polynomial g(x) with 
g(a) = 0 (cf. example (1) is mapped onto itself, so that a is mapped onto 
one of the n' zeros of g(x), or in other words onto one of the conj (a; E : K). 
Thus the conj(a; E: K), the number of which is equal to n = n' . nil, fall into 
n' classes of nil equal elements each. 
From the isomorphism theorem (§1.4, theorem 3), we obtain the 
following generalization of the results in example (2). 
Theorem 1. 
Hypothesis. 
The 
element 
all+1 
is 
algebraic over 
KII = K(ao, ... , all), v = 0, ... , n -
1, ao E K, Ko = K. Moreover, all has 
exactly kll distinct conj(all ; KII : KII- 1), v = 1, ... , n. 

432 
PART B ARITHMETIC AND ALGEBRA 
Conclusion. 
(1) There exist exactly k = kl ... kn isomorphic mappings 
J(Kn: K; N*).12 Thus for every bE Kn the number of (not always distinct) 
conj(b; Kn : K) is equal to k. 
Conclusion. (2) If Kn is separable over K, then k = degree(KII : KII- 1), 
so that k = degree(Kn : K). 
If E is an extension of K with E = K(a), then a is said to be a primitive 
element of E (over K). We then have the following theorem. 
Theorem 2. If E is a finite separable extension of K, then bEE is a 
primitive element of E over Kif and only if all the conj (b; E : K) are distinct. 
Proof. 
Necessity. If b is primitive, the assertion follows from the 
preceding theorem or from example (1). 
Sufficiency. If the conj (b; E: K) are all distinct, then the number n of 
them is equal to degree(E: K) (compare the preceding theorem, con-
clusion (2). On the other hand, the number of distinct conj (b; E: K) 
is not greater than the degree k of the irreducible (in K[x]) polynomial g(x) 
for which g(b) = O. Thus n ~ k. But n = degree(E : K) is equal to the 
dimension of E over K. Thus k ~ n = degree(E: K), from which k = n. 
Thus bO, ... , bn- 1 is a basis of E, so that E = K(b), as was to be proved. 
Furthermore, we have the following important theorem. 
Theorem 3. 
Every separable finite extension E of K has primitive 
elements and can thus be represented as a simple extension E = K(b) of K. 
Proof. (A) If K is afinite field, then E is also finite. Thus the assertion 
follows from §8.2. 
(B) If K contains infinitely many elements, then by §2, theorem 2, 
we have E = K(al' ... , an) for (finitely many) suitably chosen elements 
a1 , ... , On E E algebraic over K. For n = 1 the assertion is true with 
b = a1 • Arguing by complete induction on n, we now assume that 
the assertion is true for n = 1, ... , k, and that E = K(al' ... , ak , ak+1) 
or E = Ek(C) for Ek = K(a1 , ... , ak) and c = ak+1' By the induction 
assumption we may set Ek = K(b), so that it only remains to prove the 
assertion for K(b, c). If b1 = b, ... , br , or C1 = C, ... , Ct , form the complete 
set of conj(b; K(b) : K) or conj(c; K(c) : K) respectively, then (because 
of the separability of E over K) all the bi(i = 1, ... , r are distinct from 
one another, and similarly all the c;(j = 1, ... , t (compare theorem 1, 
conclusion (2). If we set ap.,. = bp + dc.,. with dE K, and a = au , then 
the conj (a; E : K) are included among the ap.,., since every J(E: K) 
maps b or c onto a bp or c.,. , respectively, and maps d onto itself; further-
more, to every J(E: K) there corresponds exactly one p and exactly 
one T (since the conj(b; K(b) : K) and also the conj(c; K(c) : K) are all 
12 In this conclusion (1) it is not necessary for N* to be separable. 

7 Algebraic Extensions of a Field 
433 
distinct), so that the mappings J(E : K) correspond in an one-to-one way 
with certain pairs (p, 7). Thus if there exists a dE K for which apT -=I=- a",11 , 
provided p -=I=- /L or 7 -=I=- v, then all the conj(a; E : K) are distinct, and 
the assertion follows from theorem 2. The existence of such a d E K 
follows from the fact that on the one hand the finitely many equations 
apT = a",11 in the unknown d for all p, 7, /L, v with p -=I=- /L or 7 -=I=- v are at 
most of first degree in d and thus each of them has at most one solution, 
and on the other hand K is infinite. 
Corollary. If K" is a finite separable extension of K, and if K' is an 
extension field of K contained in K", or, in other words, if K is a so-called 
intermediate field, then there exist a', a" E K" such that K' = K(a') and 
K" = K'(a"); since K' and K" are finite and separable over K and K' 
respectively. 
As an extension of this result we have the following theorem. 
Theorem 4. 
Hypothesis. 
Let E be a finite separable extension of K, 
and for a E E assume that the set of conj(a; E : K) contains r distinct 
elements. 
Conclusion (1). 
It follows that r = degree(K(a) : K) and r' t = 
degree(E: K), where t = degree(E : K(a). 
Conclusion (2). 
Moreover, a E K if and only if all the conj(a; (E : K) 
are equal. 
Proof. For (I). This conclusion follows from theorem 1. For (2). 
Necessity. The necessity is clear. Sufficiency. By conclusion (1) we have 
r = degree(K(a) : K) = I, from which it follows that a E K. 
Exercises 
32. Let K = ll<O). Let gl be a zero of x 6 + lOr + 125 and El a zero of 
x 2 + x + I (cf. ex. 25). Set K+ = K(El), K = K(El' gl), Kl = K(gl) and 
determine deg(K+: K), deg(K : K), deg(K : K+), deg(Kl: K), deg(K: Kl)' 
In each case, determine the relative isomorphisms, i.e. the J(K+ : K), 
J(K : K), J(K : K+), J(KI : K), J(K : Kl), and the number of these 
isomorphisms. What are the images a) of gl , b) of £1 under the 
isomorphisms J(K : K). Prove that K = K( £1 + gl) so that El + gl 
is a primitive element of K (over K). 
7. 
Normal Fields and the Automorphism Group 
(Galois Group) 
Summary of the argument in §7. 
In the introduction to the present 
chapter we have seen that the "solution of an algebraic equation" corre-

434 
PART B ARITHMETIC AND ALGEBRA 
sponds to the construction of a smallest splitting field N for the polynomial 
over K that defines the equation. The field N is obtained by adjunction 
of finitely many aI(' K = 1, ... , k, such that 
KC K(a1) C··· C K(a1 , ... , ak) = N. 
Now instead of asking for such elements al( it is obvious that we can 
also seek an increasing chain of (suitable) intermediate fields ZI(' for 
example ZI( = K(ao, ... , al()' with degree (ZI( : ZI(-I) > 1 (Zo = K). The 
decisive feature of this change in the form of what we are seeking is the 
fact that (cf. theorem 2) the total number of all the intermediate fields 
between Nand K is finite (whereas, in general, there are infinitely many 
possibilities for the choice of the elements a1 , ... , ak E N -
K). The same 
theorem (theorem 2 below) also states that under the isomorphic mappings 
l(N : K) the field N is mapped onto itself and the entire set of mappings 
l(N: K) constitute a finite group G(N: K) of order degree(N: K) 
Moreover, the intermediate fields between Nand K and the subgroups 
of G(N : K) are in one-to-one correspondence with each other in such 
a way that a larger intermediate field corresponds to a smaller subgroup. 
Finally (cf. theorem 3), conjugate subgroups correspond to conjugate 
intermediate fields (i.e., to fields that are mapped onto each other by 
one of the l(N : K); thus, in particular, the normal subgroups of the 
group correspond to intermediate fields that are normal over K. The 
increasing chains of intermediate fields ZI( that provide the desired solution 
are then seen to be chains for which the corresponding subgroups UI( 
are "maximal" relative normal subgroups, i.e., such that UI( C UI(-1 
and UI( is a "maximal" normal subgroup of UI(-1 , so that ZI( is thus a 
"minimal" normal field over (relative to) ZI(-I' The fact that UI( is a 
maximal normal subgroup of UI(-1 and thus that ZI( is a minimal normal 
field over ZI(-1 has the following significance: the chain of subgroups, 
and of corresponding intermediate fields, cannot be refined by the insertion 
of additional relative normal subgroups and relative normal intermediate 
fields. It may be said that such a chain provides all the successive adjunc-
tions that are indispensable for the solution of the problem. 
Details of the argument. 
We now proceed to the detailed proofs. 
Again we consider only finite separable normal extensions N of an 
(arbitrary) field K, so that we may set N* = N (cf. end of §3, convention). 
In view of the existence of a primitive element a of N over K, we set 
N = K(a). We first prove the following theorem. 
Theorem 1. 
(1) The isomorphisms l(N: K) of N relative to K map 
N onto itself and are thus automorphisms of N over K. 
(2) These automorphismsform afinite group of order n = degree(N : K), 
the Galois group G (N : K) of N over K. 

7 Algebraic Extensions of a Field 
435 
Proof. 
(I) Assertion (1). Since N is normal over K, all the conj (a; N : K) 
lie in N and (for primitive a) are distinct, and the number of them is 
n = degree(N : K). We now set J = J(N: K) and let N' = J(N) and 
a' = J(a) be the images of N and a respectively under J. Since J is an 
isomorphism, it follows that N' = K(a') and N' is normal over K; thus, 
in view of the fact that a' E N, it follows that N' ~ N. Since we also have 
N ~ N', it follows that N = N'. 
(II) Assertion (2). 
By (I) the number of mappings J(N: K) is 
n = degree(N : K). Furthermore, the converse mapping of a J(N: K) 
is again a J(N: K), and the identical mapping, and also the product of 
two J(N : K) (i.e., the result of their successive application) is again a 
J(N: K), as was to be proved. 
We now turn to the correspondence between the subgroups of G(N : K) 
and the intermediate fields Z between K and N. For abbreviation, the 
system of all those automorphisms J(N : K) under which a Z remains 
elementwise fixed will be denoted by U(Z), so that U(Z) is a subgroup 
of G(N : K), and to every Z there corresponds a unique U(Z). Similarly, 
the system of all those elements of N that remain fixed under all the 
automorphisms of a subgroup V of G(N : K) will be denoted by T(V), 
so tha~ T( V) is an intermediate field and to every V there corresponds 
a unique T(V). Then U(Z) produces a unique correspondence between 
the intermediate fields Z and certain subgroups U(Z), and similarly T(V) 
produces a unique correspondence between the subgroups V and certain 
intermediate fields T(V). We now show that this set of subgroups U(Z) 
contains all the subgroups, and similarly the set of intermediate fields 
T( V) contains all the intermediate fields. In fact, we have the following 
fundamental theorem. 
Theorem 2. 
Hypothesis. 
Let N be a finite separable normal extension 
ofK. 
Conclusion. 
The correspondence U = U(Z) assigns, in a one-to-one way, 
to every intermediate field Z a subgroup U, and similarly T = T( V) 
assigns, in a one-to-one way, to every subgroup V (of G(N : K) an inter-
mediate field T. These two correspondences are inverse to each other: 
Z = T(U(Z) and V = U(T(V) for all Z and all V. Thus the set of 
intermediate fields is mapped in a one-to-one way onto the set of subgroups. 
To every subgroup U there corresponds the greatest intermediate field Z 
that remains elementwisefixed under the automorphisms of U(U = U(Z) 
and V is the greatest subgroup whose automorphisms leave T( V) elementwise 
fixed. Thus Vis the Galois group of N over T(V); that is, V = G(N : T(V). 
The group G(N : K) is finite, and thus N contains only finitely many fields 
between K and N. 

436 
PART B ARITHMETIC AND ALGEBRA 
Proof. For Z = T(U(Z) with arbitrary Z. By definition, U(Z) is 
the (greatest) subgroup of G(N: K) that leaves Z elementwise fixed. 
Since N is also normal over Z, the group U(Z) must be the Galois group 
G(N : Z). But G(N: Z) leaves exactly the elements of Z fixed (§6, 
theorem 4). 
For 
V = U(T(V) 
with 
arbitrary 
V. 
In any case 
we 
have 
V~ G(N : T(V) = U(T(V). Thus if we denote by v the order of V 
and by g the order of G(N : T(V), then v ~ g. But now we shall also 
prove that g ~ v. To this end we set degree(N : K) = k and N = K(a). 
The k elements conj (a; N : K) are all distinct; let us denote them by 
a1 = a, ... , ak , so that N = K(al()' K = 1, ... , k. (Compare §6, theorem 2.) 
If J1 , ... , Jv are the automorphisms of V, then (with a suitable 
enumeration of the a,,) we have ar = Jr(al), r = 1, ... , v ~ k. But the 
ar are only interchanged among themselves by the mappings Jr , since 
Jt(ar) = Jt(Jr(a1) = (JtJr)(a1) and JtJr E V, in view of the fact that V 
is a group. Thus the coefficients of p(x) = (x -
al) ... (x -
av) are 
invariant under the mappings Jr E V and consequently belong to T( V), 
so that p(x) E T(V)[x]. Since v is the degree of p(x), it follows that 
degree(K(a) : T(V) = degree(N : T(V) ~ v. But by theorem 1 we have 
g = degree(N : T(V), so thatg ~ v. Consequently g = v and V~ U(T(V) 
implies V = U(T(V). Thus the U(Z) and T(V) each give rise to a 
one-to-one mapping of the set of all the Z onto the set of all the V, as 
follows from the uniqueness of the U(Z) and T(V) and from the fact 
that Z = T(U(Z) and V = U(T(V). 
In continuation of the outline at the beginning of the present section, 
we now proceed as follows: we show that the one-to-one correspondence 
just proved between the subgroups and the intermediate fields allows 
us to deduce the structure of the normal field N over K from the structure 
of the Galois group. For this purpose we first introduce some terminology: 
by the intersection of given subgroups or given intermediate fields we 
mean the greatest subgroup, or the greatest intermediate field, that is 
contained in all the given groups, or fields; by the union (compositum) 
of a given set of groups or of intermediate fields we mean the smallest 
subgroup, or the smallest intermediate field, in which all the given sub-
groups, or fields, are contained. (We note that the intersection is at the 
same time the set of all mappings, or field elements respectively, that 
belong to everyone of the given subgroups, or to everyone of the given 
intermediate fields. We now have the following theorem. 
Theorem 3. 
(1) In the correspondence (given by the preceding theorem) 
V = U(Z) or Z = Z(V) the intersection, or the union, of a set of subgroups 
corresponds to the union or the intersection, respectively, of the corresponding 
intermediate fields, and conversely. 

7 Algebraic Extensions of a Field 
437 
(2) The intermediate field Z' is isomorphic over K to the intermediate 
field Z" if and only if U(Z') is conjugate in G(N : K) to U(Z"). 
(2a) Thus in particular every normal subgroup of G(N : K) is the image 
of an intermediate field that is normal over K, and conversely. 
In accordance with (2), we say that two intermediate fields Z', Z" 
isomorphic over K are conjugate in N over (with respect to) K; or in 
symbols, Z" = conj (Z'; N : K). 
Proof. For (I). We denote the compositum and the intersection of 
the subgroups V', V" by V' v V" and V' 1\ V", respectively (in IB2 we 
wrote < V' u V") and V' n V") and correspondingly for the intermediate 
fields. From the definition of V' = U(Z'), V" = U(Z") we have the 
result: to Z = Z' v Z" the correspondence V = U(Z) assigns the greatest 
subgroup V under which both Z' and Z" remain elementwise fixed, so 
that V ~ V' 1\ V". On the other hand, both Z' and Z" remain elementwise 
fixed under every subgroup contained in V' 1\ V", so that V = V' 1\ V". 
In the same way, Z' 1\ Z" = T( V' v V"). 
For (2). The subgroups V', V" are conjugate (in G) if and only if 
there exists a JE G with V" = J-1V'J, and thus V' = JV"J-1, where 
the symbol J-1 J' J with J' E V' means that J' is to be carried out after 
J and J-1 after J', or in other words that the operations are to be read 
from right to left. 
We now let V' = U(Z'), V" = U(Z") and Z' = J(Z), V = U(Z) so 
that, for example, Z" = T(V"), Z = J-1(Z'). Then we must show that 
Z = Z". The proof proceeds as follows. Let J' E V' be arbitrary. Under J 
the field Z is mapped onto Z'; under J' the field Z' remains fixed and 
under J-1 it is mapped back onto Z, in such a way that Z remains element-
wise fixed under J-1J'J. Thus J-1V'J~ V. If we now interchange J with 
J-1 and correspondingly Z' with Z and V' with V, we likewise have 
JV J-1 ~ V', so that V ~ J-1 V' J. Thus V = J-1 V' J and thus V" = V, 
and therefore Z = T(V) = T(V") = Z". Conversely, it now follows 
from the one-to-oneness of V = U(Z) that if V" = U(Z") and V' = U(Z'), 
and also Z' = J(Z"), then V" = J-1V'J. 
Remark. 
Under the operations of formation of the compositum and 
the intersection, the system v of all the subgroups, and similarly the 
system z of all·the intermediate fields, becomes a lattice (not necessarily 
distributive). Then und~r the correspondence V = U(Z) it follows from 
the first conclusion of the above theorem that v and z correspond dually 
to each other (cf. IB9, §I). 
From the above results we now have the following two theorems. 
Theorem 4. 
Let Z' ~ N be normal over Z", and write G' = G(N : Z') 
and G" = G(N : Z"). Then G' is a normal subgroup of G" and the factor 
group G"IG' is isomorphic to G(Z' : Z"). 

438 
PART B ARITHMETIC AND ALGEBRA 
For we see that the residue classes of Gil with respect to G' consist 
of exactly those J E Gil which generate the same automorphism A of Z' 
over Z", and the product of two residue classes corresponds to the product 
of the corresponding A. 
Theorem 5. 
Every composition series of G(N: K) (cf.182, §12) 
corresponds to a "composition series" of N over K, namely to an increasing 
sequence of intermediate fields Zo = K C Zl C ... C Zk = N in such a 
way that ZK is a smallest (in N) normal field over ZK-I , K = 1, ... , k, and 
conversely. All these composition series of N have the same length, and the 
groups G(ZK : ZK-I) are simple (they have no proper normal subgroups). 
Exercises 
33. Let K, KI,K, K+, gl, g2, 7J be as in ex. 24. Also let gs be the third zero 
of XS + 6x + 2 and set K(g2) = K2 and K(gs) = Ks. Prove that 
K+ and K are normal over K. Consider the Galois groups G(K : K), 
G(K: K+) and G(K+ : K). Prove that G(K: K) is isomorphic to Ss 
(the symmetric group on three elements). Determine the fields into 
which KI is taken by the automorphisms in G(K : K). 
34. Let K, K+ and K be as in ex. 32, and (for 1 ~ i ~ 6) set K(gi) = Ki 
(the gi as in ex. 25). Show that K+ and K are normal over K. Inves-
tigate the structure of G(K : K), G(K : K+) and G(K+ : K). 
Prove 
(a) G(K : K+) is isomorphic to Ss , 
(b) the zeros 7JI, 7J2, 7Js of the polynomial XS -
15x + 10 can be 
chosen in K, 
(c) the binomial x 2 -
3 is also reducible over K. 
35. In exs. 33, 34 determine 
(a) the subgroups of G(K : K), 
(b) the intermediate fields in Kover K 
(c) the correspondence between the subgroups and the intermedIate 
fields. 
36. In exs. 33, 34 construct a composition series in each case (in ex. 34 
there are several possibilities) and determine the corresponding 
sequence of intermediate fields. 
8. 
Finite Fields 
8.1. 
Preliminary Remark. Simple Relations in Fields of Characteristic p 
Some remarks on the importance and the historical development of 
finite fields are to be found at the end of the present section. The discussion 
in the section itself is given in modern form, corresponding to the general 
contents of the present volume on algebra. 

7 Algebraic Extensions of a Field 
439 
Every finite field has a positive characteristic, so that we are now in a 
position to assemble some relations that hold in fields in characteristic p.13 
In the first place, it is well known that in integral domains (in particular, 
in fields) of characteristic p we have 
(1) 
By repeatedly raising this equation to the pth power we readily obtain 
(2) 
(/ = 1, 2, 3, ... ). 
Setting a = c -
d and b = d in (2) gives (c -
d)r! = cr! -
dr!, or, 
changing the letters, 
(3) 
From (2) we have 
By complete induction on n it follows that 
By nIP) we again denote the prime field of characteristic p. Then 
(5) 
aP = a, 
since for integral n > 0 we have 
nP == (1 + 1 + ... + I)p == Ip + Ip + ... + Ip == n (modp). 
Now let g(x) be a polynomial over nIP), say 
g(x) = bmxm + bm_Ixm- 1 + ... + bo, 
where all the blJ. belong to nIp). Then from (5) and from the application 
of (4) for f = 1 to the integral domain n(p)[x] we have 
[g(x)]P = bmxpm + bm_Ixp(m-l) + ... + bo 
= bm(xp)m + bm_l(xp)m-l + ... + bo = g(xp), 
and thus 
(6) 
[g(x)]P = g(xp), if g(x) is a polynomial over nIP). 
13 cr. also §4.1. 

440 
PART B ARITHMETIC AND ALGEBRA 
If we apply (3) to the integral domain n(p)[x], we obtain 
(Xli -
l)pI' = xiipi' -
1, 
which is exactly the equality used in §5 and denoted there by (5). 
Exercises 
37. Give the decomposition over n(3) of: 
(a) x36 -
1, (b) X 72 -
1. 
38. Decompose the following polynomials into linear factors over 
nIp): (a) x P -
x, (b) x p- l -
1, (c) xP'+l -
xP', (d) X(p-l)'pf -
1. 
8.2. 
Fundamental Theorems on Finite Fields 
By afinite field we mean a field that contains only finitely many elements. 
The number of elements will be denoted by q, where we assume q > 1. 
The finite field with q elements will be denoted by F/4 and the charac-
teristic, which must of course be positive, will be denoted by p. Obviously 
Fa is afinitel5 and therefore algebraicl6 extension of nIp). We now prove 
the following theorem. 
Theorem 1. 
The field Fa is separablel6 over n(p), and therefore separable 
over every intermediate field Z. 
For if ex is an element of Fa and h(x) is the irreducible polynomial in 
n(p)[x] for which ex is a zero, then if h(x) were inseparable it could be 
represented in the form h(x) = g(xp), where g(x) is a polynomial in 
n(p)[x], and it would follow from (6) that h(x) = [g(x)]p, so that h(x) 
would be reducible, which completes the proof of the theorem. 
Theorem 2. 
The field Fa can be represented as a simple extension of 
the prime field n(p), and therefore of any intermediate field Z. The multi-
plicative group of the field Fa is cyclic. 
For the proof we consider the multiplicative group of the field Fa' 
consisting of all the nonzero elements of Fa . Since its order is s = q -
1. 
for every nonzero element g of Fa we have 
(7) 
g. - 1 = o. 
l' The notation is reasonable, since we shall see that the structure of the field depends 
only on q. The letter F is used to suggest the word "field." In the literature a finite field 
is often called a "Galois field" and is denoted by GF(q) instead of Fa. 
1& Cf. §2. 
18 Cf. §4. 

7 Algebraic Extensions of a Field 
441 
The polynomiaP7 
(8) 
thus has exactly s distinct zeros in Fa . But these zeros are precisely the s 
roots of unity, and since they are distinct from one another it follows, 
as was proved in §5, that s is coprime to p and that (at least) one primitive 
sth root of unity' exists. Consequently Fa = nIp) <'), since the element 0 
already belongs to nIp) and every nonzero element g can be represented 
in the form 'k. Then it follows easily that Fa = Z<'), which completes 
the proof not only of theorem 2 but also of the fact that every primitive 
sth root of unity' is a generating element of Fa . 
Theorem 3. 
There exists a natural number v such that 
(9) 
q = p". 
In other words: the number q of elements of a finite field is a power of the 
characteristic. 
For we again let' be a primitive sth root of unity and let the corre-
sponding irreducible polynomial in n<p)[x] have the degree v; then every ex 
in Fa can be represented uniquely in the form 
(10) 
where the coefficients belong to n<p). Conversely, every such expression 
with coefficients in nIP) is obviously an element of Fa . Since there are p 
possible values for each of the coefficients, the result (9) follows at once. 
Exercises 
39. Investigate the polynomial x 9 -
x corresponding to F3[x]. Show: 
a) it falls into linear factors in F9[x]; b) its zeros (except for zero) are 
the eighth roots of unity; c) it falls into linear and quadratic factors 
in F3[x]; d) two of its quadratic factors (let them be denoted by g(x) 
and h(x)) have the primitive eighth roots of unity for their zeros; 
e) if gl is a zero of g(x) (in F9), then g13 is the other zero; also, g15 and 
g17 are the zeros of h(x). 
40. (Cf. ex. 39). Every element of F9 can be represented in the form 
ag1 + b, where a and b are elements of F3 . Set up the multiplication 
table. E.g., what is (gl + 2) . (2g1 + I)? (Hint. Use one of the 
polynomials g(x) and h(x) in ex. 39.) 
11 cr. §5(1). 

442 
PART B ARITHMETIC AND ALGEBRA 
41. (a) Determine the pOlynomials of third degree in Fa[x] which are 
irreducible over Fa (the coefficient of xa is always to be taken equal 
to unity). (Hint. There are eight of them; every polynomial of 
third degree in Fa [x ] which is reducible over Fa has a zero in Fa . 
(b) Compute (/>~~) and (/>~:) and factor these polynomials into their 
irreducible (over Fa) factors. (Hint. The irreducible factors are 
the irreducible polynomials determined in a)). 
(c) Factor the polynomial X 27 -
x into its irreducible (over Fa) factors. 
(d) Investigate the structure of F27 with the aid of one of the irreducible 
polynomials determined in a). 
8.3. 
Existence and Uniqueness ofF 'IJ" for Arbitrary p and Arbitrary v 
Theorem 4. 
Let there be given an arbitrary prime p and an arbitrary 
natural number v. Then there exists (at least) one finite field with PI) elements. 
All finite fields with the same number of elements are isomorphic to one 
another. 
We set q = Pl). The proof depends on the remark that if the field Fa 
exists, its nonzero elements are exactly the zeros of xa- l -
1, from which 
it follows at once that the polynomial xa -
x has all the elements of Fa 
for its zeros, and only these. Thus we have proved (for the time being 
under the hypothesis that the field Fa exists) that: 
A. The polynomial 
(11) 
(q = PI)) 
has only distinct zeros, namely all the elements of the field Fa . 
B. The field Fa is the smallest splitting field of ga(x). 
We now discard the hypothesis that the field Fa exists, since we wish 
to prove its existence. Since g~(x) = -1, the polynomial gq(x) has no zero 
in common with its derivative, and thus gq(x) has only distinct zeros. 
We now show that the zeros of ga(x) already form a field. For let ex and f3 
be two zeros of g' a(x), so that exa = ex and f3a = f3. Then from (2) and (3) 
it follows that (ex + f3)a = ex + f3 and (ex -
f3)a = ex -
f3, and then also 
that (ex • f3)a = 
ex • f3 and, if f3 -=I=- 0, then (ex/ f3)a = ex/ f3. 
Thus the proof of theorem 4 is complete and at the same time we have 
shown the general validity of the theorems A and B. Since Fa is the smallest 
splitting field of ga(x), it is uniquely determined up to isomorphisms. 18 
More precisely: the field Fa (with q = PI)) admits, as we shall show in §8.5, 
exactly v automorphisms, i.e., isomorphic mappings onto itself. It follows 
that if Fa and Fa are two finite fields with the same number of elements, 
18 cr. §l. 

7 Algebraic Extensions of a Field 
443 
then an isomorphic mapping of one onto the other is possible in exactly 
v different ways. 
8.4. 
The Subfields of the Field Fa 
Let Fa be a subfield of Fa. Since Fa is a finite field with the same 
1 
1 
characteristic p, it follows from theorem 3 that there exists a natural 
number VI such that 
(12) 
On the other hand, by theorem 2 the field Fa is a simple extension of Fa , 
1 
SO that, if k is the degree of Fa with respect to Fa1 ' then the same proof 
as in theorem 3 gives 
(13) 
From (12) and (13) it follows, since q = p", that 
(14) 
V = k . VI' 
Conversely, let VI be an arbitrary factor of v, so that (14) holds. We 
now set 
(15) 
s = q -
I and SI = ql -
I, with ql = p"l. 
Then SI is a factor of s, from which it follows that the polynomial 
fs (x) = X S1 -
I is a factor of the polynomial fs(x) = x 8 -
1. Since 
1 
gq(x) = 
X • fs(x), and correspondingly gal (x) = 
X • fSl (x), it follows that 
gq(x) is divisible by gal (x). The set of q elements of the field Fa, which 
constitute all the zeros of gq(x), thus contains all the ql zeros of gal (x), 
which (cf. §8.3, theorem B) form a field of ql elements. It is also clear 
that Fa can contain only one subfield with the fixed number of elements ql • 
Thus we have proved the following theorem. 
Theorem 5. 
Let Fa be a finite field with q = P" elements. Then if VI 
is an arbitrary factor of v, the field Fa contains exactly one subfield with 
ql = p"l elements. If VI runs through all the factors of v, we obtain all the 
subfields of Fa. 
Example. 
Let us take q = 36 = 729. Then, apart from itself, the 
field Fa contains the following subfields: one with 31 = 3 elements, one 
with 32 = 9 elements, one with 33 = 27 elements, and no other subfield. 
8.5. 
The Automorphism Group of the Field Fa 
By theorem I the field Fa is separable. Moreover, by theorem B (§8.3), 
Fa is the smallest splitting field of ga(x), from which it follows that Fa 

444 
PART B ARITHMETIC AND ALGEBRA 
is a normal extension of nIP) .19 Since the finite fields have a particularly 
simple structure, their Galois groups are also particularly easy to describe. 
We first note that the prime field nIP) obviously admits only one 
automorphism, namely the identity,20 and that nIP) remains elementwise 
fixed under every automorphism of Fa. Thus the Galois group G(Fa : nIP»~ 
includes all the possible automorphisms of Fa. Since Fa is of degree v 
with respect to n<p), there are exactly v of these automorphisms, so that 
the order of the Galois group is v. We may now state the following 
theorem. 
Theorem 6. 
The Galois group G(Fa : nIP»~ is a cyclic group of order v. 
As a generating automorphism we may take the mapping a ---+ a P• 
We first show that this mapping is one-to-one. For by (3) it follows 
from aP = f3P that (a -
f3)p = aP -
f3P = 0, so that a = f3. Furthermore, 
it follows from (1) and from (af3)p = aPf3P that this mapping is an iso-
morphism, and therefore an automorphism. Since the order of the group 
is obvious, it is only necessary to prove that this mapping actually is of 
order v in the Galois group. But its ith power is obviously the mapping 
a ---+ a pi and since the equation Xpi = x has at most pi solutions, v is the 
smallest positive integral value of i for which the mapping a ---+ a pi 
becomes the identity. 
The correspondence between the subfields of Fa and the subgroups 
of the Galois group is now obvious: the subgroup G(Fa : Fa) corresponding 
to the subfield Fa (with q1 = p"l, V = k . VI) contains the k automorphisms 
a ---+ aa
i
l (i = 0,11, ... , k -
1), which are exactly those automorphisms 
of G(Fa : nIp»~ that leave all the elements of Fa1 individually fixed. 
In the proof of theorem 6 we have incidentally shown that in every 
finite field of characteristic p the pth root of every element exists and is 
unique; and then the same remark readily follows for the pnth root 
(n a natural number). The uniqueness of the pth root is obvious for an 
arbitrary field K of characteristic p, even when K is not finite. But in the 
case of an infinite field we cannot always conclude from a E K that 
Va E K. 
Exercises 
42. Prove 
(a) the polynomial x 2 + x + 2 falls into linear factors over F9 but is 
irreducible over F27 ; 
(b) the polynomial r + 2X2 + 1 falls into linear factors over F27 but 
is irreducible over F9 ; 
19 cr. §3. 
20 Cf. the remarks at the end of §S.3. 

7 Algebraic Extensions of a Field 
445 
(c) consequently, both polynomials fall into linear factors over 
F729 , so that their zeros may be chosen in F729 ; 
(d) if the zeros of the polynomial in (a) are denoted by gl , g2 , and 
those of the polynomial in (b) by 7Jl , 7J2 , 7Ja , then F9 = Fa(gl), 
F27 = Fa(gl), F729 = Fa(gl , 7Jl)' 
43. With the notation of ex. 42 investigate the structure of the five Galois 
groups G1 = G(F9 : Fa), G2 = G(F27 : Fa), Ga = G(F729 : Fa), G4 = 
G(F729: F9), Gs = G(F729 : F27). In particular, determine how the 
automorphisms in G1, Ga , G 4, Gs act on gl, g2 and how the 
automorphisms in G2 , Ga , G4 , Gs act on 7Jl , 7J2 , 7Ja • 
8.6. 
Decomposition of the Cyclotomic Polynomial tPh (x) over Finite Fields 
The particularly simple structure of the finite fields depends partly 
on the fact that Fa is a normal extension of its prime field nIP) and of 
every intermediate field (cf. beginning of §8.5). If Fa is a subfield of Fa' 
1 
the degree k of Fa with respect to Fal is equal to the order of the Galois 
group G(Fa : Fal) (see the next-to-Iast paragraph of §8.5). 
We now turn to the problem of factoring the cyclotomic polynomial 
tPh (x). 21 Obviously we must assume that h is coprime to p. We let 7J 
denote a primitive hth root of unity. Since the elements of Fa' apart 
from its zero element, consist of all the (q -
l)th roots of unity, the 
element 7J will belong to Fa if and only if h is a factor of q -
1. But 
(cf. IB6, §4.2) we also have 
p<p(h) == 1 
modh. 
Now let e be the exact exponent to which p belongs mod h, namely the 
smallest positive integer satisfying the congruence 
modh; 
then 7J is obviously contained in Fpe but not in any proper subfield of FpB . 
Thus 7J is of degree e with respect to nIp). Since this statement is true 
for every primitive hth root of unity, we have the following theorem. 
Theorem 7. 
Let (h, p) = 1 and let p belong to the exponent e modulo h. 
Then tPh (x) splits into irreducible polynomials of degree e over n(p). 
In order to answer the question how tPh (x) splits over an arbitrary Fa , 
we need only investigate how a polynomial that is irreducible over a 
given finite field splits in a finite extension field. Here we have the following 
theorem. 
21 cr. §5.4. 

446 
PART B ARITHMETIC AND ALGEBRA 
Theorem 8. 
Let Fa be an extension field of Fal ' let q = p", and assume 
(12) and (14). Let f(x) be a polynomial of degree n irreducible over Fal . Let 
the greatest common factor of nand k be d, and 
finally let n = d· ft. Then f(x) splits over Fa into 
d irreducible polynomials of degree ft. 
Proof. 
Let ex be a zero off(x) in anextension 
field of Fa. Then we consider the four fields 
Fal ' Fa, Fal (ex), and Fa(ex). In the diagram these 
fields are represented by circles. Where two fields 
are joined by a straight line in the diagram, the 
upper is an extension field of the lower, and 
the relative degree is written beside the line. In 
particular, n* denotes the degree of Fa (ex) with 
respect to Fa. Then we must show that n* = ft. 
We set k = d· k. From (n, k) = d it then follows that (ft, k) = 1. 
The number of elements in Fal (ex) is p"ln and the number in Fa(ex) is p"n*. 
Since Fal (ex) is a subfield of Fa(ex), it follows from §8.4 that VI • n I.v . n*. 
But n = d . ft, V = 
VI • k = 
VI • d . k, so that VI • d . ft I VI • d . k . n * and 
therefore ft I k . n*. But then from (ft, k) = I we have ft I n*, so that we 
can set n * = c . ft. 
Now Fa(ex) is obviously the smallest common extension field of Fa (ex) 
* 
R 
I 
and Fa. But Fa(ex) has P"c = pvc elements. Thus by §8.4 the field Fa(ex) 
contains a subfield K with pvR elements. Then, since V I vft, it follows 
from §8.4 that the field K contains a subfield with P" elements, which 
must therefore be a subfield of Fa (ex). But by §8.4 the field Fa(ex) cannot 
contain any field other than Fa with P" elements. Consequently Fa is a 
subfield of K. In the same way we show that Fa (ex) is a subfield of K. 
I 
To this end we must first show that VI • n I V • ft. But this fact is immediately 
obvious, since n = d· ft and V = VI • d· k. Since Fa(ex) cannot contain 
any field other than Fa (ex) with p"ln, it follows that Fa (ex) is also a subfield 
I 
I 
of K. On the other hand, Fa(ex) is the smallest common extension field of 
Fa and Fal (ex); thus we must have c = I and therefore n* = ft. Since 
this result holds for every zero ex off(x), the proof of theorem 8 is complete. 
The results of theorems 7 and 8 provide the solution of the problem dealt 
with in the present section. By Theorem 7 (with the same notation as in 
that theorem) the polynomial tPh(x) splits over the prime field nIP) = F'IJ 
into irreducible polynomials of degree e. From Theorem 8 we see that 
we must set VI = I, n = e. Thus k = V and d = (e, v). We thus have 
the following theorem. 
Theorem 9. 
Let (h,p) = I, let p belong mod h to the exponent e, 
let q = p", and finally let (e, v) = d. Then tPh(x) splits over Fa into irre-
ducible polynomials of degree e/d. 

7 Algebraic Extensions of a Field 
447 
Remark. It is easy to see that the number e/d in theorem 9 is the 
exact exponent to which q belongs mod h. 
Examples. 
1. 
We set h = 12 throughout, so that we must exclude the 
characteristics 2 and 3. By §5.5 of the present chapter <l)12(x) = x' -
x 2 + 1. 
For every number a coprime to 12 we have a2 == 1 mod 12; thus the prime 
numbers different from 2 and 3 can be divided into two classes, those belonging 
to the exponent 1 mod 12 and those belonging to the exponent 2. If p is in the 
first class (p = 13, p = 37, ... ), then cJ'>12(x) splits into linear factors in n(I/)[x]; 
if p belongs to the second class (p = 5, 7, 11, ... ), then <l)12(x) splits in n(I/)[x] 
into irreducible polynomials of the second degree, and if v is even these latter 
polynomials split over FI/v into linear factors, whereas for odd v they remain 
irreducible. 
2. We now set q = 38 = 729 throughout. Then we have the factorization 
q -
1 = 728 = 23 • 7 . 13. If h 1728, then 38 == 1 mod h, so that e 1 6 and 
(e,6) = e. In the case h 1728 the polynomial <l)h(X) splits into linear factors 
over F729 , a result which can also be obtained from the fact that F729 contains 
all 728th roots of unity and consequently all the hth roots of unity with h 1 728. 
We now choose h = 65. Since 3 belongs to the exponent 4 mod 5 and to the 
exponent 3 mod 13, it therefore belongs to the exponent 12 mod 65. Thus 
d = (12,6) = 6, so that by theorem 9 the polynomial <l)8Il(X) splits over F729 into 
irreducible polynomials of degree l.l = 2. 
Theorem 10. 
There exist irreducible polynomials of arbitrary degree n 
in Fa[x]. Every such polynomial splits completely in Fa,,[x] and is thus a 
divisor of xa
n 
-
x and, apart from the single irreducible polynomial x 
(for n = 1), every such polynomial is even a divisor of fs(x) = XS -
1, 
wherefor abbreviation we have set S = qn -
1. Conversely, the polynomials 
xa" -
x andfs(x) split in Fa[x] into irreducible polynomials whose degrees 
are divisors of n. 
We give the proof of the first assertion. By theorem 4 (§8.3) there exists 
a field K with qn = p"n elements; by theorem 5 (§8.4) this field K contains 
a subfield L with q = P" elements. If K = L(ex) (cf. §8.2, theorem 2), 
then the irreducible polynomial in L[x] corresponding to ex is of degree n. 
Since Fa is isomorphic to L by theorem 4 of §8.3, it follows that Fa[x] also 
contains an irreducible polynomial of degree n. The other assertions of 
theorem 10 can then be derived without difficulty from the results of §8. 
Exercises 
44. What is the degree of the cyclotomic polynomial (/>g~? Into what 
factors does it split over FSII (1 ~ v ~ 12)? 
8.7. 
Closing Remarks 
Our knowledge of finite fields is due to the genius of Galois. 22 Galois 
22 Evariste Galois, bom in 1811, met his death in a duel in 1832. 

448 
PART B ARITHM£TIC AND ALGEBRA 
obtained the finite field with p" elements by starting from a polynomial 
f(x), irreducible mod p, with integral coefficients and of degree v mod p, 
and then adjoining an "imaginary" zero of f(x) to the field of residue 
classes mod p.23 The reader will realize from §8.5 how closely this procedure 
is associated with the revolutionary ideas that are now called the "Galois 
theory." 
The original Galois procedure of symbolic adjunction of an "imaginary" 
naturally gave rise to the idea of altering his method by considering 
congruences with respect to the double modulus p and f(x) in the domain 
of polynomials with integral coefficients. It is easy to see that this method, 
which was developed by R. Dedekind in 1857,24 also leads to the Galois 
field GF (Pll). 
Dedekind also made use of the finite fields (or in other words, of the 
theory of higher congruences) for the investigation of algebraic number 
fields. In this connection we may point out that in the ring of integers 
of an algebraic number field (186, §8) the residue classes with respect 
to a prime ideal constitute a finite field. 
The importance of the finite fields for the study of groups of linear 
substitutions was made clear by L. E. Dickson in a pUblication of funda-
mental importance.25 
If an indeterminate t is adjoined to a finite field Fa, the resulting field 
Fa(t) shows far-reaching analogies with the field of rational numbers 
but its arithmetical structure is simpler in many respects, and by algebraic 
extension of Fa(t) we obtain fields that correspond to the algebraic number 
fields. The study of these fields has led to the development of a general 
theory26 of fields and ideals, and they have proved very useful for illus-
trating the abstract theorems of such theories with simple but nontrivial 
examples. 
9. Irreducibility of the Cyclotomic Polynomial and Structure 
of the Galois Group of the Cyclotomic Field 
over the Field of Rational Numbers 
9.1. 
Lemmas on the Connection between 
the Polynomial Rings G[x] and ll<O)[x] 
Again we let ll(O) be the field of rational numbers and G the integral 
domain of integers. Then ll<o)[x] contains the polynomials with rational 
28 <Euvres mathematiques, published by E. Picard, Paris, 1897. 
26 Abriss einer Theorie der hoheren Kongruenzen in Bezug auf einen reellen Prirnzahl-
Modulus. Journal f. d. reine u. ang. Math., Vol. 54, pp. 1-26. 
211 Linear groups with an exposition of the Galois field theory, Leipzig, 1901. 
26 Cf. the important work of E. Steinitz [1 J. 

7 Algebraic Extensions of a Field 
449 
coefficients and G[x] contains the polynomials with integral coefficients, 
so that G[x] is contained in ll(O)[x]. (The ideas and theorems developed 
in §9.1 apply only to nonzero polynomials, as will be tacitly assumed 
throughout.) A polynomial in G[x] is said to be primitive if there is no 
factor (except 1 and -I) common to all its coefficients; moreover, if the 
coefficient of the highest power of x is positive, the polynomial is said 
to be normed.27 Then we have the well-known theorem of Gauss:28 the 
product of two primitive polynomials is primitive, from which it readily 
follows that the product of two normed polynomials is normed. If g(x) is a 
polynomial in ll(O)[x], there exists exactly one representation 
(I) 
a 
g(x) = b g+(x), 
where g+(x) is a normed polynomial and a and b are coprime integers, with 
b positive. When we speak of normed polynomials, we shall always mean 
polynomials from G[x]. 
Theorem 1. 
Let f+(x) be a normed polynomial which admits the 
factorization 
(2) 
f+(x) = g(x) . hex) . k(x) "', 
where g(x), hex), k(x), are finitely many polynomials of positive degree 
in ll(O)[x]. Thenf+(x) also admits the factorization 
f+(x) = g+(x) . h+(x) . k+(x) "', 
where g+(x), h+(x), k+(x),... are the normed polynomials corresponding 
to g(x), hex), k(x), ... , respectively. If the coefficient of the highest degree 
of x inf+(x) is equal to I, then the same is true for g+(x), h+(x), k+(x) .... 
We give the proof for the case of two factors g(x) and hex). By (I) 
we have 
a 
g(x) = b g+(x), 
c 
hex) = Jh+(x), 
and thus 
ac 
f+(x) = bd g+(x) . h+(x). 
But if g+(x) and h+(x) are normed, then by the theorem of Gauss the 
polynomial g+(x) . h+(x) is also normed, from which it easily follows that 
f+(x) = g+(x) . h+(x). 
21 For brevity we say "normed" for "normed and primitive." 
28 Cf. IB5, §2.11 and 12. 

450 
PART B ARITHMETIC AND ALGEBRA 
If we now set 
h+(x) = C,.xr + .", 
we have am = bn • Cr. If am = 1, it follows that bn = Cr = 1. 
The generalization to the case of more than two factors offers no 
difficulty. 
9.2. 
Proof of the Irreducibility of 4">n(x) over n(O) 
In §5.4 of the present chapter we introduced 4">n (x) as that polynomial 
(with leading coefficient 1) which has exactly the primitive nth roots 
of unity as its zeros. Since in §9 the characteristic is always taken to be 0, 
the polynomial 4">n (x) has integral coefficients (§5, theorem 5), and since 
the coefficient of the highest power of x is equal to 1, the polynomial 
4">a;(x) is normed. By theorem 1 of§9.1. it then follows: if4">n(x) is reducible 
at all, there must exist a factorization of the form 
I 
(3) 
where gl«x) (for K = 1, 2, ... , k) is a normed29 polynomial, irreducible 
over n W), with leading coefficient L On the other hand, if 4">n (x) is irre-
ducible, then in the representation (3) we must obviously take k = 1. 
Thus the purpose of the present section is to prove that k = 1. This 
purpose is almost completely attained by the following lemma. 
Lemma. If' is a zero of gl (x) and p is a prime number that does not 
divide n, then ,p is also a zero of gl (x). 
Proof. Since p does not divide n, the element ,P is also a primitive 
nth root of unity; thus there exists an i such that ,P is a zero of gi(X). 
(Our assertion is equivalent to the statement that i = 1.) We set 
(4) 
Since ,P is a zero of gi(X), it follows that 
(5) 
But this equation means that the polynomial 
(6) 
has' as a zero. Since gl (x) is the irreducible polynomial corresponding 
to " it follows that 
(7) 
29 From now on the superscript + for normed polynomials will be omitted. 

7 Algebraic Extensions of a Field 
451 
and thus 
(8) 
where q(x) is also a normed polynomial in G[x] with leading coefficient 1. 
Again letting H<P) denote the homomorphism of G onto nIP) (cf. §5.4), 
so that the number g in G is mapped onto the corresponding residue 
class g mod p, we now extend H<p) to the homomorphism H<p) of G[x] 
onto n<p)[x] by agre'eing that f(x) = arxr + ... + ao is to be mapped 
onto f(x) = arxr + ... + ao . As a result of H<p) it follows from (8) that 
(9) 
Moreover, from (3) and .§5, theorem 6, we have 
(10) 
where the polynomials gl (x), ... , gk(X) are not necessarily irreducible. 
Then by formula §8(6) we have 
(11) 
From (9) it thus follows that 
(12) 
Now let ~ be a zero of gl (x) (in an extension field of nIP»). Then (12) shows 
that' is also a zero of [gi(X)]P and consequently of gi(X). Since P f n, 
it follows from §5 that f/>~P) (x) can have no multiple zeros, from which 
we see that i = I, so that the proof of the lemma is complete. 
Now it is easy to prove the following theorem. 
Theorem 2. 
f/>n(x) is reducible over n(O). 
Proof. 
Let 7J be a primitive nth root of unity and let , be a zero of 
gl (x). Then 7J = ,r, with r coprime to n. Let 
(13) 
r = PI . P2 ... Pm 
be the factorization of r into prime numbers. Every PI-' is coprime to n. 
We now set 
(14) 
Then by an m-fold application of the lemma we see that 7JI is a zero of 
gl (x), and that 7J2 , ... , 7J = 7Jm are also zeros of gl (x). Since every primitive 
nth root of unity is thus a zero of gl (x), it is clear that k = I in (3), or 
in other words that f/>n (x) is irreducible. 

452 
PART B ARITHMETIC AND ALGEBRA 
9.3. Structure of the Galois Group of the Field ll(O)<') 
Since C/>n(x) is irreducible by §9.2, it follows that the field ll(O)<') is of 
degree cp(n) over ll(O), where' again denotes a primitive nth root of unity, 
and since ll(O) <') contains all the zeros of C/>n (x), it is necessarily a normal 
field. Let TJl , TJ2 , ... , TJu (with u = cp(n)) be the entire set of primitive 
nth roots of unity, including ,. Then the u automorphisms of the Galois 
group ffi of the field ll(O)<') with respect to ll(O) can be represented in 
the following way: 
(15) 
'~TJ2 ; ... ; 
Here TJi = ,a" where the number ai coprime to n is determined only mod n. 
Theorem 3. 
The Galois group ffi of the field ll(O)<') with respect to 
ll(O) is isomorphic to the multiplicative group of the relatively prime residue 
classes mod n (for this group see IB2, §1.2.10). 
Proof. For' ~ 
TJi we can write ,~,ai. If '~TJ; is also an auto-
morphism of ffi, we..can write it correspondingly in the form ,~,al. 
If we apply the two automorphisms successively, we obviously obtain 
the automorphism ,~ ,a;al • Thus the theorem is proved. 
It follows that ffi is an Abelian group. If p is an odd prime, then in the 
cases n = pk and n = 2pk it even follows that the group ffi is cyclic, and 
similarly for n = 4. On the other hand, for example, the group ffi is no 
longer cyclic for n = 8 and n = 15. 
As will be shown in the following section, the possibility of dividing a 
given circle into n equal parts by means of ruler and compass depends 
on the structure of the Galois group ffi of the field ll(O) <,). It turns out 
that this construction is possible if and only if the order cp(n) of ffi is a 
power of 2. 
Exercises 
45. Let g be a primitive nth root of unity. Investigate in detail the structure 
of the Galois group of the field ll(O)(g) with respect to ll(O) for the 
following values of n: 8, 9, 12, 18, 24, 36, 72, 35, 175. 
10. Solvability by Radicals. Equations of the Third and Fourth 
Degree 
10.1. 
By means of the Galois theory (§7) we can answer the question 
of the solvability of "an equation by radicals" or better of "a polynomial 
by radicals." By a radical of degree k over the field T we mean a zero of 
a binomial Xk + c of degree k which is irreducible over T. Also, we shall 

7 Algebraic Extensions of a Field 
453 
say that a polynomial g(x) irreducible over K is solvable by radicals 
(over K) ifthere exists a splitting field in the wider sense ZR = K(bl , ••• , bm) 
such that blJ. is a radical over KIJ.-I = K(bl , ••• , blJ.-I); here Ko = K and 
JL = I, ... , m. We then have the following theorem (which will not be 
proved here; see e.g., Haupt [2], p. 515). 
Theorem I. 
Let K be a field which (for simplicity) we take to be of 
characteristic zero. A polynomial g(x) E K[x] is solvable by radicals if and 
only if the (simple) factor groups of a composition series (cf. 182, §12) 
of the Galois group G (N : K) are all of prime order; here N denotes the 
smallest splitting field of g(x) over K. 
Thus in the case of solvability by radicals the smallest splitting field N 
(which of course is contained in ZR) can be generated by successive 
adjunction of zeros of normapo polynomials of prime degree with cyclic 
group; each of these zeros can then itself be represented by radicals. 
Since in general N is a proper subfield of ZR , the solution by radicals is 
in general not a "natural" process of solution; in other words, it is not 
a process which corresponds to the structure of N. 
10.2. 
By means of §IO.I we can decide, for example in the case of 
characteristic zero, for which degrees n a "general" polynomial g(x) 
is solvable in radicals; here a polynomial g(x) = xn + an_1xn- 1 + ... + ao 
is said to be a general polynomial (over K) if the coefficients a" are also 
indeterminates over K.31 The zeros of a general polynomial g(x) over K are 
indeterminates over K (see Haupt [2], p. 177), and thus are distinct; on 
the other hand, since g(x) is irreducible over K(ao , ... , an-I) (see Haupt [2], 
p. 256) the polynomial g(x) is separable. The group of the normal field of 
a general polynomial is the "largest possible"; in other words (see Haupt [2], 
p. 556), it is isomorphic to the symmetric group Sn of degree n (see 1B2, 
§1.2.5 and §15.2), and is thus of order nL But for n ~ 5 the only possible 
composition series consists of Sn , An , E, where E is the subgroup con-
sisting of the unit element alone and An is the so-called alternating group, 
with order 2-l n! (for n = 5, cf. IB2, §15.4; in general, see e.g., Haupt [2], 
p. 560 ff.). For n ~ 5 the orders of the factor groups are therefore 2 and 
2-l n!, the latter of which is not a prime number. 
For n = 4 a composition series of the group Sn = S4 consists of 
S4, A4 , N4 , Zl, E, where A4 is again the alternating group, N4 is the 
Abelian subgroup of 4th order, which is generated by the 3 products P; of 
two transpositions without common element, and Zl is the cyclic group 
80 A polynomial h(x) E K[x] is said to be normal over K if there exists a zero ex of 
h(x) such that h(x) splits completely into linear factors in K(ex)[x]. 
81 Thus in a general polynomial g(x) the ao, ... , an-I, x are indeterminates over K. 
For this concept see IB4, §2.3. 

454 
PART B ARITHMETIC AND ALGEBRA 
of 2nd order generated, say, by PI . Thus for n = 4 the orders of the 
factor groups are 2, 3, 2, 2. Finally, for n = 3 a composition series 
consists of Ss , As and E with 2 and 3 as the orders of the factor groups. 
Thus we have the result: the general polynomial of nth degree is solvable 
in radicals if and only if n = 2, 3, or 4. 
10.3. 
From §IO.l we also obtain a necessary and sufficient condition 
that a regular n-gon Pn , inscribed in a circle (of radius 1), is constructible 
with ruler and compass. If we represent Pn in the complex plane, the 
problem is seen to be equivalent to expressing the zeros of the poly-
nomial xn -
lover the field ll(O) of rational numbers by means of radicals 
of the 2nd degree; for the vertices of Pn are the images of the nth roots 
of unity, which are representable as powers of a primitive nth root of 
unity, say'; and therefore N = ll<o)a) must be normal over ll.(O) , 
since it is the smallest splitting field of the irreducible (over ll(O») cyclotomic 
polynomial cI>n(x) of degree cp(n). Since the Galois group Gn = G(N : ll<O») 
(§9, theorem 3) is Abelian, the number' can be represented by radicals, 
in view of the fact that the factor groups of a composition series of an 
Abelian group are all (cyclic) of prime order (cf. IB2, §I2.l). The product 
of these prime orders is equal to the order of Gn , and is thus equal to 
cp(n). For cI>n(x) to be solvable in radicals of the 2nd degree it is therefore 
necessary that cp(n) = 2k. But this condition is also sufficient for solvability 
by radicals of the 2nd degree. For if cp(n) = 2k, the increasing sequence 
of relative normal fields Kr corresponding to a composition series 
of Gn has the following property: Kr+1 is of 2nd degree over Kr, so that 
Kr+l = Kr(a), where a is a radical of 2nd degree over Kr . We now let 
n = 
2rp~1 ... p;r:a, with r ~ 0, t", ~ 1, P", > 2, where the P", (and also the 
number 2 in the case r > 0) are the only prime numbers dividing n; 
then, since cp(n) = 2qp~CI ... p!:-I(PI -
1) ... (Pm -
1) (see IB6, §5), 
with q = 0 for r ~ 1, it follows from cp(n) = 2k that t", = 1 and 
P", = 28", + 1, JL = 1, ... , m. We thus have the result: the n-gon Pn is 
constructible with ruler and compass if and only if n = 2t with t ~ 1, 
or else n = 2kpi ... Pm, where k ~ 0, m ~ 1 and p", is a prime with the 
property that P", = 28", + 1, JL = 1, ... , m. (Not every number 28 + 1 is a 
prime number.) Examples: the 4 smallest primes p", with this property 
are 3, 5, 17, 257. Thus for an n that contains, for example, one of the 
factors, 7, 11, 13, 19, the corresponding Pn cannot be constructed with 
ruler and compass. 
Exercises 
46. Take K = ll(O, and 
(a) g(x) = r - 3x2 + 3x + 17 (cf. exs. 6, 12, 19,22), 
(b) g(x) = XS + 6x + 2 (cf. exs. 7, 12, 19, 24, 33), 

7 Algebraic Extensions of a Field 
(c) g(x) = 
X 3 -
3x + I (cf. exs. 8, 13, 16, 20, 22), 
(d) g(x) = r - 2 (cf. exs. 15, 22), 
(e) g(x) = x6 + lOr + 125 (cf. exs. 25, 32, 34), 
([) g(x) = xl -
x2 + I (cf. ex. 30), 
(g) g(x) = tP24(X) (cf. exs. 31, 45). 
455 

CHAPTER 8 
Complex Numbers and Quaternions 
1. The Complex Numbers 
1.1. 
Geometric Representation 
Given a Cartesian coordinate system in the real Euclidean plane, the 
entire set of real numbers can be put in one-to-one correspondence 
with the dilatations of the plane, with the origin as center, in such 
a way that the real number a corresponds to the mapping 
(1) 
x' = ax, 
y' = ay. 
Here (x, y), (x', y') are the coordinates of a point and its image, and 
(though often excluded in other contexts) the zero dilatation with a = 0 
is here included. This mapping of the set of real numbers onto the set of 
dilatations is an isomorphism with respect to multiplication; for it is 
obvious that the product of two real numbers is mapped onto the product, 
i.e., the successive application, of the corresponding dilatations. 
For a = -1 the mapping (1) represents a rotation through 180 degrees. 
If we now wish to extend the domain of real numbers in such a way as 
to include an element i with i 2 = -1, it is natural to define; as the rotation 
through 90 degrees, since its square (repeated application) is exactly a 
rotation through 180 degrees. l Thus it is appropriate for us to include 
the rotations (again with origin as center), or in other words the mappings 
(2) 
x' = ax -
by, 
y' = bx + ay 
with a2 + b2 = 1; here the angle of rotation cp is determined by a = cos cp, 
b = sin cpo Then in order to have unrestricted multiplication we must 
1 Of course, the same remark also holds for the rotation through 270 degrees, which 
could just as well be taken as the definition of i. 
456 

8 Complex Numbers and Quaternlons 
457 
also include arbitrary products of a dilatation with a rotation, i.e., the 
dilative rotations, which are obtained by simply dropping the restriction 
a2 + b2 = 1 in (2). 
By (2) the dilative rotations are set in one-to-one correspondence with 
the vectors cIa + c2b, where C1 , C2 are the basis vectors of the coordinate 
system, i.e., the vectors with coordinates (1, 0), (0, 1). It is obvious that 
the relationship between a dilative rotation and the corresponding vector 
can also be described in the following way: the dilative rotation takes 
the vector C1 into the vector corresponding to the rotation. Thus the 
complex numbers we are seeking may be defined either as the dilative 
rotations or as the vectors. A plane in which the complex numbers are 
so represented is called the Gauss plane. If we choose the first possibility, 
mUltiplication of the dilative rotations at once defines mUltiplication 
of complex numbers and shows that the nonzero complex numbers form 
a commutative group with respect to multiplication. Addition of complex 
numbers is simply defined as the addition of the corresponding vectors: 
if the complex numbers z, z' correspond to the vectors 3, 3', then that 
dilative rotation which takes C1 into 3 + 3' is denoted by z + z'. Thus 
the complex numbers also form a commutative group with respect to 
addition. In order to show that the set of complex numbers with these de-
finitions of addition and multiplication constitutes a field, it only remains 
to prove the distributive law of multiplication. For the proof we first 
note that if 
(3) 
z' = exz, 
then the complex number (the dilative rotation) ex takes the vector 
corresponding to z into the vector corresponding to z', as can be seen 
at once by applying exz (first z, and then ex) to C1 . Thus (3) represents 
the dilative rotation ex as a left-multiplication z ~ exz in the domain of 
complex numbers. Now if 31, 32 are the vectors corresponding to the 
complex numbers ZI, Z2, then the vectors corresponding to exz1 , exz2 , 
ex(ZI + Z2) are given by the images of 31, 32, 31 + 32 under ex. But the 
sum of the images of 31 , 32 under the affine mapping ex is the image of 
the sum 31 + 32 and by the definition of addition the vector corresponding 
to exz1 + exz2 is the sum of the vectors for exz1 , exz2 , and it follows that 
ex(ZI + Z2) and exZl + exZ2 have the same corresponding vector: in other 
words, ex(ZI + Z2) = exZl + exZ2 , so that multiplication is distributive. 
The correspondence between the dilatation (1) and the real number a 
is obviously an isomorphism of the field of real numbers onto the set of 
dilatations. Thus we may equate the real number a with the dilatation (1), 
or in other words with that complex number to which the vector cIa 
is in correspondence (cf. the procedure in 181, §4.4 in (62). The dilative 
rotation corresponding to the vector C2 , i.e., the rotation through 

458 
PART B ARITHMETIC AND ALGEBRA 
90 degrees has already been denoted by i. Then the dilative rotation ib is 
the image of C2 under the dilatation with the factor b, so that the dilative 
rotation ib corresponds to C2b and the dilative rotation a + ib therefore 
corresponds to the vector cIa + C2b. Thus the complex number a + ib is 
precisely the dilative rotation represented by (2). In this complex number 
ex = a + ib the real part a = Re ex and the imaginary part b = 1m ex of 
ex are, of course, uniquely determined. In polar coordinates a = r cos cp, 
b = r sin cp (r ~ 0) where the angle cp is the oriented angle between 
CI and cIa + C2b and is thus the angle of rotation of the dilative rotation 
a + ib = r (cos cp + i sin cp). The fact that under successive rotations the 
angles of rotation are simply added is now expressed by the equation 
(4) 
(cos cp + i sin cp)(cos cp' + i sin cp') = cos(cp + cp') + i sin(cp + cp'); 
mUltiplying out on the left and comparing real and imaginary parts on 
both sides, we see that this equation is merely a combination of the 
theorems of addition for cosines and sines. Complete induction on n 
yields from (4) the de Moivre formula 
(5) 
(cos cp + i sin cp)n = cos ncp + i sin ncp 
for all natural numbers n. In view of the fact that (cos ncp + i sin ncp)-l = 
cos ncp -
i sin ncp = cos( -n) cp + i sin( -n) cp this formula also holds 
for negative integers n. 
The number r = va2 +172 in polar coordinates is the length, or 
modulus, of the vector cIa + C2b and is thus also called the modulus I ex I 
(or the absolute value) of the complex number ex. Since va? = I a I 
(see IBl, (66), this definition is in agreement for real numbers a with 
the definition of absolute value in 181, §3.4. The triangle inequality in 
vector algebra shows that the modulus of complex numbers also satisfies 
the inequality 181, (53), and thus we also have the following consequence 
(IBl, (54): 
II ex I - I f3 II ~ I ex + f3 I ~ I ex I + I f3 I. 
Since I ex I is obviously the dilatation factor for the dilative rotation ex, we 
also obtain (in agreement with 181, (52) the equation I exf31 = I ex II f31. 
The addition of complex numbers was defined above as the addition 
of the corresponding vectors. Thus the vector space of complex numbers 
is isomorphic to the two-dimensional (geometric) vector space (cf. IB3, 
§3.1). We will now derive the relations that hold between the multiplication 
of complex numbers and the two familiar vector multiplications. 
From the above isomorphism 
z = a -/-- bi ---+ 3 = cIa + c2b 

8 Complex Numbers and Quaternions 
459 
we see that for the vectors x = elxl + e2x2 , 1) = elYI + e2Y2 we have 
the following relation between the inner product x . 1) = xIY! + X2Y2 
(see IB3, §3.2) and the outer (or exterior) product (see IB3, §3.3) 
[x,1)] = XIY2 -
X2YI (with x as the complex conjugate of x) 
x1) = x . 1) + i[x, 1)]. 
Taking complex conjugates on both sides of this equation (§1.2), we have 
xij = x . 1) -
i[x, 1)]. From these two equations we obtain 
x . 1) = i(x1) + xij), 
[x, 1)] = ;i (x1) -
xij). 
Thus the inner and the outer product of vectors in the plane have been 
reduced to the mUltiplication of complex numbers. 
1.2. 
Algebraic Methods of Introducing the Complex Numbers 
The geometric introduction of the complex numbers has the advantage 
that th~ operations of addition and mUltiplication for complex numbers 
are reduced to well-known geometric operations (addition of vectors, 
mUltiplication of mappings), but this procedure takes no account of the 
fact that the construction of the complex numbers is a purely algebraic 
question. To realize the truth of this statement, we have only to replace 
the dilative rotations by the corresponding matrices 
(6) 
This set of matrices is closed with respect to addition, subtraction, and 
mUltiplication of matrices (see IB3, §2.2) and thus forms a ring under 
these operations. The commutativity of multiplication is easily shown. 
Since the determinant of (6) has the value a2 + b2, such a matrix (unless 
it is the zero matrix) has the inverse 
( 
ac-l be-I) 
-bc-l ac-l , 
with 
c = a2 + b2• 
Thus the matrices (6) even form a field. Essential for the proof of this 
latter statement is the following property of the real numbers: 
(7) 
If a*-O or b *- 0, then a2 + b2 *- 0, 
which follows immediately from the order properties of the real numbers 
(see IBI, §3.4). 

460 
PART B ARITHME.TlC AND ALGE.BRA 
In order to regard every real number as a complex number, it is only 
necessary to identify a with (~ ~). If we then define i = d -~), the matrix (6) 
can also be written in the form a + ib: 
The determinant c = a2 + b2 = 1 a + ib 12 of (6) is called the norm 
N(a + ib) of a + ib. 
This purely algebraic definition of complex numbers shows at the 
same time that the only property required of the real numbers, apart 
from the fact that they form a field, is the property (7). Now for a field K 
the property (7) is equivalent to 
(8) 
c2 -=I=- -I for all c E K; 
for if a = c, b = I, then (8) follows at once from (7), and conversely, 
given (8) and, let us say, a -=I=- 0, we may set c = .ba-l , from which 
a2 + b2 -=I=- 0 from c2 -=I=- -I. Thus the complex numbers can be introduced 
for any field K with property (8): the result is an extension field of K 
whose elements can all be expressed rationally (and even linearly) in 
terms of i and the elements of K, so that this extension field (by IB7, §1.1) 
can be denoted by K(i). 
The field K(i) is a vector space of dimension 2 over K with the basis {I, i}, 
since a + ib uniquely determines the pair (a, b). Thus in forming K(i) 
we can dispense with the matrices; we simply take a two-dimensional 
vector space over K; for example, the space of pairs (a, b) with a, bE K 
(cf. IB3, §1.2). If {el , e2} is a basis of this vector space with, let us say, 
el = (I, 0), e2 = (0, I), we then seek to introduce a distributive multiplica-
tion in such a way that el is the unit element and e22 = -el . If we also 
require that (eaP)(e~b) = (elle~)(ab) for v, JL = I, 2 and for all a, b E K, 
the multiplication must be as follows: 
(9) 
(elal + e2a2)(elbl + e2b2) = el(albl -
a2b2) + e2(alb2 + a2bl ). 
In particular, if we have constructed the vector space of the pairs (ai, a2) 
and have taken el = (I, 0), e2 = (0, I), then (9) can be written more 
simply as 
(ai, a2)(bl , b2) = (albl -
a2b2 , al b2 + a~l)' 
We must now show that under the mUltiplication defined by (9) the vector 
space is actually a field. The calculations necessary for this purpose become 
considerably more concise if we introduce matrices, so that it is not 
desirable to dispense with them entirely. Finally we must still show that 
x ---+ elx is an isomorphism of the field K onto the set of mUltiples of el , 
so that we may set x = elx = x without giving rise to difficulties as a 

8 Complex Numbers and Quaternions 
461 
result of this identification of the operations in K and in the new field. 
There is a further danger consisting in the fact that (c1al + c2a2) b is 
already defined in the vector space, namely as cI(a1b) + c2(a2b). But 
since exactly the same value is determined by (9) when b is replaced by 
c1b, everything is in order. 
Finally the introduction of complex numbers can be subsumed under 
the procedure described in IB5, §3.10: in the polynomial ring K[x] we 
we compute mod x2 + I; that is, we form the residue classes2 f(x) of 
f(x) E K[x]. Again, it is not altogether necessary to define f(x) as the set 
of polynomials == lex) mod x2 + I; alternatively, in accordance with the 
procedure described in another connection in IBl, §2.2, we may consider 
f(x) as a new symbol formed from a polynomialf(x) with the conventions: 
](x) = g(X) if and only if f(x) == g(x) mod x 2 + I; f(x) + g(x) = 
f(x) + g(x), f(x) g(x) = f(x) g(x). Then the f(x) form a commutative 
ring, namely the ring of residue classes of K[x] with respect to x 2 + 1. 
Since x 2 + I, by (8), has no zero in K, this polynomial is irreducible and 
the ring of residue classes is thus a field (see 
IB5, §3.10). If 
f(x) == a mod x 2 + 1 with a E K, we set a = f(x) = a. The division 
algorithm (1B6, §2.10) shows that to every f(x) E K[x] there correspond 
uniquely determined elements a, b E K with f(x) == a + bx mod x 2 + I, 
so that f(x) = a + bi. Thus we need only set i = i (then i2 = -I, 
since x 2 == -I mod x 2 + 1) in order to write the field of residue classes 
in the form K(i). 
We now investigate the automorphisms of K(i) with respect to K 
(cf.IB7, §1.2). If a is such an automorphism, then i 2 = -I naturally 
implies a(i)2 = -I. Thus, since x 2 + 1 = (x -
i)(x + i), we must have 
either a(i) = i or a(i) = -i. Since a(a + ib) = a + a(i) b we have 
in the first case the identical automorphism and in the second case the 
mapping a + ib ~ a -
ib. The fact that this mapping is also an auto-
morphism of K(i) with respect to K follows either from the general theory 
(lB7, §6) or from the fact that in calculations involving the sum and 
product of complex numbers only the special property i 2 = -1 is utilized 
(beyond the general rules for addition and multiplication) and this property 
holds for -i, since (_i)2 = -1. The element a -
ib is called the complex 
conjugate a + ib of a + ib. Obviously 0: E K is equivalent to 0: = a, and 
in general 0: + a = 2 Re 0:, 0: - a = 2i 1m ex. Since the passage to complex 
conjugates is an automorphism and N(a + ib) = (a + ib)(a -
ib), it 
follows that 
(10) 
N(o:f3) = N(o:) N(f3); 
2 Of course, the overbar here has nothing to do with the notation for a complex 
conjugate. 

462 
PART B ARITHME.TIC AND ALGE.BRA 
for we have N(exf3) = exf3iXP = exiXf3P. Incidentally, the equation (10) 
enables us to write the product of sums of two squares again as the sum 
of two squares; for example, (12 + 22)(32 + 42) = 52 + 102. Finally, we 
remark that for ex -:F 0 the equation exiX = N(ex) implies ex-I = N(ex)-liX. 
2. 
Algebraic Closedness of the Field of Complex Numbers 
2.1. 
The Intermediate Value Theorem 
A real function (i.e., a mapping of a set of real numbers; namely of 
the domain of definition off, into the set of real numbers) is said to be 
continuous at the point x if for every real number € > 0 there exists a 
real number 8 > 0 such that for all x' in the domain of definition of 
f with I x -
x' I < 8 we have I f(x) - f(x') I < €. It is shown in analysis 
(see 1I2, § 1) that the rational entire functions (for their definition see IB4, 
§1.1) are everywhere (i.e., at every point) continuous in the field of real 
numbers. 
The intermediate value theorem now states: if the real function f 
is defined and continuous at every point x with a ~ x ~ b (a < b) and if3 
f(a) < C < f(b), then there exists a value c with a < c < b such that 
f(c) = C. 
Proof. 
Let M be the set of x with a ~ x ~ band f(x) < C. Since 
f(a) < C, the set M is not empty. Thus there exists a real number c, 
with a ~ c ~ b, which is the least upper bound of M. If f(c) < C, and 
thus in particular c < b, we set C - f(c) = 
€ and then, in view of the 
continuity of f, we can determine 8 with c < c + 8 ~ b such that 
I f(x) - f(c) I < € for all x with c ~ x < c + 8. For these values of 
x we would then have f(x) = f(c) + f(x) - f(c) < C, in contradiction 
to the fact that c is an upper bound of M. On the other hand, if f( c) > C, 
and thus in particular a < c, we set f(c) -
C = 
€ and determine 8 with 
a ~ c -
8 < csuch that If(x) - f(c) I < € for all x with c -
8 < x ~ c. 
For these values of x we would then havef(x) = f(c) + f(x) - f(c) < C, 
so that c -
8 «c) would be an upper bound of M, in contradiction to 
the definition of c as the least upper bound of M. 
In view of the above-mentioned continuity of the rational entire 
functions, we have thus proved the intermediate value theorem for 
polynomials over the field of real numbers, a theorem which for greater 
simplicity we now write in the form of a theorem on the zeros of a 
polynomial:4 
8 We could also assumef(a) > C > f(b), which would amount to the above case if 
we replace J, C by - J, - C. 
& By applying this theorem to the polynomial f(x) -
C we obtain the general inter-
mediate value theorem (for polynomials). 

8 Complex Numbers and Quaternions 
463 
If the polynomialf(x) satisfies the inequality f(a) < ° < f(b) with a < b, 
then f(x) has a zero c with a < c < b. 
This theorem holds not only for the field of real numbers but also for 
certain other ordered fields. For example, we obtain such a field if we 
restrict ourselves to the real algebraic numbers. These numbers actually 
form a field A; for it was shown in IB7, §2 that for two elements that 
are algebraic over a field K (here the field R of rational numbers) the 
difference and the quotient of the two elements are also algebraic over K. 
If L:~o a"c" = 0, a" E A, an *- 0, the real number c is algebraic over 
R(ao , ... , an) and thus (by IB7, §2) also over R, and is therefore an algebraic 
number. Consequently, we have also proved the intermediate value 
theorem for polynomials over A. If the intermediate value theorem holds 
for polynomials over a field K, we shall say for brevity: the intermediate 
value theorem holds in K. 
From the intermediate value theorem for polynomials we have the 
Sturm theorem, which allows us in general to state the number of distinct 
zeros c with a < c < b: for if we are given the polynomial f(x) E K[x], 
let us form the Sturm chain (f(x) , {,(X),fl(X), ... ,fr(x), where the fk(X) 
are determined by fk-l (x) = qk(x)fk(X) - fk+l (x) (k = 0, ... , r -
1), 
f-l(X) = f(x),fo(x) = ('(X),fr-l(X) = qr(x)fr(x), with polynomials qk(X) 
and degreefk(x) < degreefk-l(x) (k = 1, ... r); and if now for u E K we 
denote the number of changes of sign in the sequence 
(f(u),f' (U),fl (u), ... ,fr(u) 
by w(u), where zeros are disregarded, it follows that iff(a),f(b) *- 0, a < b, 
then f(x) has exactly w(a) -
w(b) distinct zeros c with a < c < b. 
We shall not prove this theorem heres but will merely illustrate it for 
the polynomial X2 -
1. Here the Sturm chain is (X2 -
1, 2x, 1), and we 
have w(u) = 2 for u < -1, w(u) = 1 for -1 ~ u ~ 1, w(u) = ° for 
u > 1. Thus the assertion of the Sturm theorem actually follows for 
the polynomial X2 -
1. 
2.2. 
Real-Closed Fields 
A field K is. said to be real-closed if it can be ordered in such a way 
that the intermediate value theorem (for polynomials) is valid. We now 
wish to deduce for real-closed fields a certain characterization in which 
there is no mention of the order. By IB1, §3.4 we know that in every 
ordered field K, and thus in every real-closed field, we have 
(11) 
if ai, ... , an E K. 
Ii A proof is to be found, e.g., in van der Waerden [2J, §69. 

464 
PART B ARITHME.TIC AND ALGE.BRA 
We also have, in every real-closed field: 
(12) If a E K and a -=I=- b2 for all b E K, there exists aCE K with =--a = c2. 
For the proof we assume that K is ordered in such a way that the inter-
mediate value theorem holds in K. If a ~ 0, there exists an element b E K 
with a = b2, as was already deduced in IBI, §4.7 from the intermediate 
value theorem. Thus, under the hypothesis in (12), we must have a < ° 
and therefore -a > 0, so that, as we have just remarked, there must 
exist an element C E K with -a = c2• 
Finally, we have the following theorem for a real-closed field K: 
(13) 
Every polynomial of odd degree in K[x] has a zero in K. 
For the proof we may restrict our attention to a polynomial 
f(x) = xn + L~:~ akxk (ak E K). If we let b denote the maximum of 
1, 1 -
ao , .•• , 1 -
an-I, we have bk > 0, ak ~ -(b -
1) and thus 
f(b) ~ bn -
(b -
1) L~:~ bk = 1. Applying the same procedure to the 
polynomial -f( -x), whose leading term must also be xn in view of the 
fact that n is odd, we obtain an a ~ -1 with f(a) ~ -1. By the inter-
mediate value theorem there must exist a zero C of f(x) with a < C < b. 
But we have herewith obtained the desired characterizing properties: 
afield K is real-closed if and only if it has the properties (11), (12), (13). 
It remains only to prove that (11), (12), (13) imply that K can in fact 
be ordered in such a way that the intermediate value theorem holds in K. 
We first show that on the basis of (11), (12) the field K can be ordered 
in exactly one way. By IB 1, §3.4 we know that a domain of positivity in K 
will in any case contain all the squares a2 with a -=I=- 0, a E K. Thus the 
desired result will follow if for the set P of these squares we can deduce 
the characterizing properties IBI, (44) of a domain of positivity. The 
relations IBI, (441•4) are obvious and IBI, (442) follows at once from (12). 
But if a2 + b2 were not a square (so that in particular a, b -=I=- 0), then 
by (12) there would exist an element C E K with -(a2 + b2) = c2, which 
would imply -1 = (a/c)2 + (b/a)2 in contradiction to (11). Since (11) 
also implies the impossibility of a2 + b2 = ° for a -=I=- 0, we have thus 
completed the proof of IBI, (443). The proof that under the ordering 
defined by this domain of positivity (in which every positive element is a 
square) the intermediate value theorem follows from (13) will be postponed 
to §2.3, where the investigation of real-closed fields will be based not 
on the original definition of this concept but only on the properties (II), 
(12), (13). 
As was proved in IB 11, §3, the field K can be ordered if and only if 
(11) holds; in this case the field is said to be formally real. A field K is 

8 Complex Numbers and Quaternions 
465 
real-closed if and only if K itself is formally real but no proper algebraic 
extension of K has this property. We shall not give a proof of this fact, 
which is often used as a definition of real-closed fields. Likewise without 
proof we mention that every real-closed algebraic extension of the field 
of rational numbers is isomorphic to the field A of real algebraic numbers 
introduced in §2.I; in this way the latter field is characterized (up to 
isomorphism) in a purely algebraic way, and thus in particular without 
any use of the field of real numbers. For the proofs of these statements 
we refer the reader to van der Waerden [2], §71. 
2.3. 
Algebraic Closure of a Real-Closed Field 
Let the field K.have the properties (11), (12), (13). Since (1 I) implies (8), 
we can form the extension field K(i), as was done in §1.2. We now prove 
the followjng basic theorem. 
A polynomial of positive degree in K[x] has a zero in K(i). Let us write 
the degree n of the polynomial f(x) in the form n = 2lm (m odd) and 
prove the assertion by complete induction on I. For I = 0 the polynomial 
f(x) has a zero in K itself, by (13). Thus we need only prove the assertion 
for I > 0 under the induction hypothesis, i.e., under the assumption 
that the assertion holds for polynomjals whose degree is divisible by 2l - l 
but not by 2l. By IB7, §1.5 there exists an extension L = K{i, (Xl , ••• , (Xn) 
with f(x) = c n:=l (x -
(XII) (c E 
K). We now set N = n(n -
1)/2 and 
form the polynomials of degree N in L[x]: 
fh(X) = 
Il 
(x -
«(XII(X~ + h«(X1I + (X~)) 
for 
h = 0, ... , N. 
b;;:II<~<n 
Since the coefficients of these polynomials are obviously the values of 
symmetric polynomials (in n indeterminates with rational integers as 
coefficients) for the arguments (Xl , ... , (Xn , it follows from the fundamental 
theorem on the elementary symmetric polynomials (see IB4, §2.4) and 
from the equations IB4, (25), (26) that these coefficients are already 
contained in K. Since N = 2l- lm(n -
I) and m(n -
1) is odd, we can 
apply the induction hypothesis toj~(x): one of the zeros of fh(X) is already 
contained in K(i). Thus for every value of h( = 0, ... , N) there exists a 
pair of numbers (Vh ,ILh) with I ~ Vh < ILh ~ N and a pair of elements 
ah , bh E K such that 
But by the Dirichlet pigeonhole principle (see IBI, §1.5) the mapping 
h ---+ (Vh ,ILh) cannot be invertible, since the set of preimages contains 
N + 1 elements but the set of images contains at most N elements. Thus 

466 
PART B ARITHME.TIC AND ALGE.BRA 
there exist two distinct values h, k with Vh = Vk = V, fl-h = fl-k ,= fI-. 
A simple calculation then shows6 
alla~ = (h -
k)-l(h(ak + ibk) -
k(ah + ibh), 
all + a~ = (h -
k)-l«ah + ibh) -
(ak + ibk). 
Consequently, the coefficients of the polynomial x2 -
(all + a~) X + alla~ , 
which has the zeros all , a~ , are contained in K(i). Thus in order to show 
all , a~ E K(i) it only remains to prove that every element a + ib of K(i), 
and in particular the discriminant of the above polynomial, is a square 
in K(i). But from the ordering of K (which by §2.2 is unique) we have 
a2 + b2 ~ 0, and thus there exists aCE K with a2 + b2 = c2. Since 
C or -
C ~ 0, we may also assume C ~ O. Then C + 1 a 1 ~ 0, and 
from 
(c + 1 a I)(c - 1 a I) = b2 ~ 0 it follows 
that 
c -
1 a 1 ~ 0, 
so that c + a, c -
a ~ O. Thus there exist elements u, v E K with 
u2 = (c + a)/2, v2 = (c -
a)/2, uvb ~ 0, and then in view of (2UV)2 = b2 
we have 2uv = b and therefore (u + iV)2 = (u2 -
v2) + 2uvi = a + ib. 
On the basis of the theorem that has just been proved, we can show 
that K(i) is algebraically closed, i.e., every polynomial f(x) of positive 
degree in K(i)[x] has a zero in K(i). For ifby /(x) we denote the polynomial 
whose coefficients are the complex conjugates of the corresponding 
coefficients of f(x), a short calculation shows that the coefficients of 
g(x) = f(x)/(x) are identical with their complex conjugates and are thus 
contained in K. Consequently there exists an a E K(i) with g(a) = 0, 
so thatf(a) = 0 or /(a) = O. In the second case the passage to complex 
conjugates shows at once that f( ci) = 0, so that the proof of the theorem 
is complete. 
From the fact that the field L is algebraically closed it follows in general 
that every polynomial of positive degree L[x] splits into linear factors 
in this ring; that is, the polynomial is the product of linear polynomials. 
For if a l , ... , as are the distinct zeros of f(x) in L with mUltiplicities 
ml , ... , rns , then by JB4, §2.2 there exists a polynomial h(x) E L[x] with 
f(x) = h(x) 0:=1 (X -
ak)mk • By the definition of the mUltiplicity of a 
zero (see IB4, §2.2) we have h(ak) -=I=- 0, so that h(x) has no zero in K and 
must therefore, since L is algebraically closed, be of degree 0; in other 
words, h(x) lies in L, which completes the desired factorization. 
If the coefficients of f(x) are already contained in K, then passage to 
complex conjugates shows that the equation f(a) = 0 with a E K(i) 
implies f(ci) = 0: in other words, if the zero a of f(x) is in K(i) but not 
8 Since K can be ordered, it follows that if the integers h, k are distinct, then h -
k 
as element of the field (which for h > k is a sum of h -
k summands, each equal to the 
unit element of K) is actually #- O. 

8 Complex Numbers and Quaternions 
467 
in K, then ci is another zero of f(x). If in the linear factorization of f(x) 
we combine the factors x -
ex, X -
ci, then in view of 
(x -
ex)(x -
ci) = x 2 -
2(Re ex) x + N(ex), 
we obtain a factorization of f(x) into two factors in K[x], one of which 
is quadratic. By complete induction on the degree of f(x) it follows that 
every polynomial of positive degree in K[x] can be factored into linear 
and quadratic factors. But now we can make good the omission in §2.2, 
by proving the intermediate value theorem: for iff(a),f(b) are of different 
sign, then at least one of the factors in the factorization of f(x) must be 
of different sign for the values a and b; but for a quadratic factor this is 
impossible in view of 
(x -
ex)(x -
ci) = (x -
Re X)2 + (1m ex)2, 
and for the linear factor x -
c it means that a -
c < 0 < b -
c; in 
other words, f(x) actually has a zero c E K with a < c < b. 
If for K we now take the field of real numbers and then the field of 
complex numbers, we have the following result: 
In the ring of polynomials in one indeterminate7 over the field of real 
numbers every polynomial of positive degree can be factored into linear and 
quadratic factors; and over the field of complex numbers every such poly-
nomial can be factored into linear factors. 
This theorem is often called the fundamental theorem of algebra. 
The name was justified as long as algebra was confined to the study of 
the field of complex numbers and the fields and rings contained in it. 
But today the field of complex numbers has lost its central importance 
for algebra. It would be better to call this theorem the fundamental 
algebraic theorem for complex numbers. 8 
3. 
Quaternions 
In § I we have constructed the field of complex numbers as an extension 
of the field of real numbers. It is now natural to ask whether we can 
proceed in the same way beyond the complex numbers. Such an extension 
is possible, as we shall show below~ if we abandon the commutativity 
of multiplication; in §3.4 we shall discover to what extent such a weakening 
of the axioms is in fact necessary. 
7 Even for only two indeterminates the theorem is no longer true; the quadratic 
polynomial 1 + xy in the indeterminates x, y cannot be factored into linear factors over 
any field. 
S As the fundamental topological theorem for complex numbers we could consider the 
Cauchy convergence criterion, i.e., the fact that every fundamental sequence (see IBl, 
§4.4) of complex numbers has a limit. 

468 
PART B ARITHME.TlC AND ALGE.BRA 
3.1. 
Quaternions as Hermitian Dilative Rotations 
In order to repeat for the complex numbers the step which in §I led us 
to them from the real numbers we now introduce into the affine complex 
plane a Hermitian metric; in other words the length of a vector with the 
complex coordinates Zl , Z2 (in a given coordinate system) is now defined 
as the square root of the positive real number Zl'a<l + Zza'2 . By Hermitian 
rotations about the origin we now mean affine length-preserving mappings 
with determinant9 1, leaving the origin fixed. Then how are these mappings 
to be expressed? An affine mapping with the origin as fixed point is 
given by 
(14) 
zi = exZl + yZ2 
z~ = f3Z1 + SZ2 , 
and the fact that lengths are preserved means that 
(15) 
ZlZl + Z~2 = (exci + f3p) ZlZl + (exy + f38) ZlZ2 + (ciy + pS) ZlZ2 
+ (yY + S8) Z~2 • 
If in (15) we set Zl = 1, Z2 = 0 and then Zl = 0, Z2 = 1, we obtain the 
following equations 
(16) 
exci + f3p = 1, 
yy + S8 = 1. 
For Zl = Z2 = 1 and Zl = 1, Z2 = i the equations (15) and (16) imply 
from which it follows that 
(17) 
Conversely, the preservation of length, or in other words (15), follows 
from (16), (17). Taken together with the requirement on the determinant 
f3y -
exS = -1 and the first equation (16), the equation (17) means that 
y = -p, S = -ci, so that by (14) the Hermitian rotations have the 
form 
(18) 
zi = exZl - PZ2 , 
z~ = 
f3Z1 + ciz2 , 
with exci + f3p = 1. If after a mapping of this sort we apply a dilatation 
with a real factor (which may = 0), we again obtain a mapping of the 
form (18), but now without the requirement exci + f3P = 1. Conversely, 
9 It would actually be enough to require that the determinant be real and positive. 

8 Complex Numbers and Quaternions 
469 
it is obvious that every mapping (I8) can be produced by the successive 
application of a Hermitian rotation and a dilatation (with the real dilata-
tion factor (XeX + f3p). Thus the mappings (I 8) are called Hermitian dilative 
rotations. 
But for the sake of simplicity we shall operate below not with these 
mappings but with the matrices 
(19) 
(
(X -iJ) 
A = 
f3 
eX' 
which (if the coordinate system is fixed) are in one-to-one correspondence 
with such mappings. As can easily be seen, these matrices form a subring 
of the ring of all two-rowed square matrices; in other words, the sum, 
difference, and product of two matrices (19) are again of the same form. 
Then the mapping 
is seen at once to be an isomorphism of the field of real numbers into 
the ring of matrices, so that without fear of misunderstanding we may set 
(20) 
a = 
(~ ~) 
for all real numbers. In this manner our subring of the ring of matrices 
becomes an extension ring Q of the field of real numbers. For A -=I=- 0 
we have I A I = (XeX + f3P -=I=- 0, in view of the fact that (XeX + f3P, as the 
sum of four squares, can be equal to zero only if all four summands, 
and thus also (x, f3, are equal to zero. Since I A I is real, it is easy to show 
that A-I again lies in Q. Thus Q is actually a skew field (see the definition 
in IB3, § 1.1). If we setlO 
(21) 
. (0 i) 
] = 
i 0 ' 
(0 -1) 
k = 
1 
0' 
(22) 
(X = ao + ias, 
it follows from (19) and (20) that 
(23) 
10 It is customary to write i,j, k instead of j, k, I but we have intentionally avoided 
this notation, since the square of each of the quaternions j, k, I is equal to -I; thus, 
if we wish, we may take anyone of these quaternions to be the complex number i, if 
on the basis of an isomorphism of the field of complex numbers into the skew field of 
quaternions we set the complex numbers equal to certain quaternions. 

470 
PART B ARITHME.TIC AND ALGE.BRA 
Since ao + ja1 + ka2 + las = 0 (ao , aI, a2, as real) implies (X = f3 = 0 
and thus ao = a1 = a2 = as = 0, the I ,j, k, 1 are linearly independent 
over the field of real numbers, so that Q is a vector space of dimension 4 
over this field. It is for this reason that Q is called the skeH'jield of quater-
nions and its elements are called quaternions (Latin quaternio = set of 
four). 
By (20) the real number I is to be replaced in the multiplication of 
quaternions by the unit matrix, and thus it is the unit element of Q. 
From (19), (22) and A* = (_~~) we have 
s 
AA* = A*A = 
(Xci + f3/J = L a,,2, 
,,=0 
The number L~=o a,,2 is called the norm N(A) of A, and A * the quaternion 
conjugate of A. Since A * arises from A by transposition (see IB3, §2.6) 
and passage to complex conjugates, the invertible mapping A ~ A * of Q 
onto itself is an antiautomorphism; i.e., (A + B)* = A * + B* as in the 
case of an automorphism, but now (AB)* = B* A *. In exact analogy 
with the equation (10) we have* 
N(AB) = AB(AB)* = ABB*A* = AA*N(B) = N(A) N(B). 
Thus we can express the product of sums of four squares as the sum of 
four squares; for example, 
For A '* 0 we obtain, in the same way as for complex numbers: 
A-I = N(A)-IA*. 
From (21) it follows that 
(24) 
p = k2 = 12 = -I, 
jk = I, 
kl = j, 
lj = k, 
kj = -I, 
Ik = -j, 
jl = --k. 
Thus mUltiplication is not commutative, so that the quaternions do not 
form a field. However, by (20) we have aA = Aa for every real number a 
and A E Q. Thus, exactly as in §1.2, we can construct the skew field Q 
by choosing a four-dimensional vector space with a basis {eo, el , e2 , es} 
and defining for it a distributive mUltiplication in such a way that 
(e"a)(e~b) = (e"e~)(ab) for v, JL = 0, 1,2, 3 and arbitrary a, b, where eo is 
the unit element and equations (24) hold for eo, e1 , e2 , es in place of 
I,j, k, I. 
* The third equality follows from the fact that aA = Aa for every quaternion A and 
every real number a, and N(B) is real. 

8 Complex Numbers and Quaternions 
471 
In the preceding discussion we could equally well replace the field 
of real numbers by any other field K in which L~=o a,,2 = 0 implies 
a" = 0 (v = 0, I, 2, 3); for in order to show that Q is a ring we do not 
need to impose any conditions on the field K, and Q is a skew field if 
and only if N(A) = I A I = L~=o a,,2 = 0 implies A = 0, so that 
ao = al = a2 = as = O. The above condition on K is equivalent to the 
condition that -I is not a sum of two squares of elements from K. 
For on the one hand the equation I + a2 + b2 = 0 (a, bE K) obviously 
violates the given condition, and on the other hand if -1 is not the sum 
of the squares of two elements from K and if a" (v = 0, ... , 3) in K are 
not all = 0, then in order to prove L~=o a" 2 -=I=- 0 we may without loss 
of generality take a2 -=I=- O. In view of the fact that (a1/a2)2 -=I=- -I we then 
have a1 + a2 -=I=- 0, so that (a02 + as2)(aI2 + a22)-1 = N( exf3-1) by (22). 
Since a norm, as the sum of the squares of two elements in K, must always 
be -=I=- -I, we thus have L~=o a,,2 -=I=- O. 
Let us also remark that the concept of the quaternion skew field can be 
generalized in the following way: in a field K let there exist elements c, d 
with c -=I=- 0 and -d -=I=- x 2 + y 2c for all x, y E K; the construction of Q, 
starting with a four-dimensional vector space over K, is now altered by 
replacingll (24) with 
p= -c, 
k 2 = -d, 
kj = -I, 
12 = -cd, 
Ik = -jd, 
jk = I, 
kl = jd, 
jl = -kc 
lj = kc, 
These generalized quaternion skew fields arise if we ask for those skew 
extensions of K in which every element u satisfies the equation ua = au 
for all a E K and for every element u there exist certain b, b' E K with 
u2 + bu + b' = 0.12 It is easy to see that the generalized quaternion skew 
fields just defined possess this property: for u = ao + ja1 + ka2 ~ las we 
must set b = -2ao , b' = a02 + a12c + a22d + as2cd. If K satisfies the 
conditions (II), (12), then the general case can be reduced to the special 
case c = d = I; in fact, there then exists (up to isomorphism) exactly one 
(generalized) quaternion skew field over K. 
3.2. 
Quaternions and Space Rotations 
From the complex affine plane in which in §3.I we considered the 
Hermitian dilative rotations we now turn to the complex projective line; 
i.e., we consider ZI , Z2 as the homogeneous coordinates of a point, with 
ZI/Z2 = Z as the inhomogeneous coordinate in the case Z2 -=I=- 0, while 
Z2 = 0 (with ZI -=I=- 0) gives the ideal point. In this way the complex 
11 If K has characteristic 2, then the definition is somewhat different; in this case the 
above definition provides only a field. 
12 For details see e.g. Pickert [3J, Section 6.3. 

PART B ARITHME.TIC AND ALGE.BRA 
numbers correspond in one-to-one fashion with the proper points of the 
complex projective line. We extend the set of complex numbers by a new 
element 00, which we put in correspondence with the ideal point 
and use as its coordinate. For convenience we sometimes identify the 
points with their coordinates Zl/Z2 or 00. The mapping (18) then becomes 
the projectivity on the projective line described as follows, with z, z' as 
the coordinates of a point and its image: 
, 
(Xz-fJ 
z = {3z + a ' 
if {3z + a * 0, 
z * 00; 
(25) 
z' = 00, 
if {3z + a = 0, 
z * 00; 
z' = (X/{3, 
if z =00, 
{3 * O;lS 
z' = 00, 
if z = 00, 
{3 = 0. 
Since a common real factor for (x, {3 is here of no importance, we may 
restrict ourselves to the case (Xa + {3P = I. 
We now map the complex projective line onto a sphere of radius 1/2 in 
the following way: to the proper point z = x + iy we first assign the 
point in space with the coordinates (x, y, -i) (in a given Cartesian 
coordinate system) and then project this point (stereographically) from 
the point (O,O,!) onto the sphere with the equation L~-l x} = ! for 
the coordinates Xl , X2 , Xs of its points. To the point 00 we assign the 
point (0,0, l) on the sphere, which is not an image under the stereographic 
projection. A sphere used in this way for the representation of the complex 
numbers is called a Riemann sphere. The equations connecting z(* 00) 
and the corresponding point of the sphere (with the coordinates Xl , X 2 , xs) 
are easily calculated to be 
(26) 
Xl + iX2 = z(zz + 1)-1, 
Xl -
iX2 = z(zz + 1)-1, 
2xs = (zz -
I)(zz + 1)-1. 
We now assert that under this mapping the projectivities (25) (with 
(Xa + (3P = I) become the entire set of rotations of the sphere.14 
We first consider the special case {3 = 0. If we set p = (X/a, the projectivity 
(25) becomes z' = pz with the fixed point 00. Since (Xa = I, we may set 
(X = cos cp/2 + i sin cp/2 and thus obtain p = cos cp + i sin cpo We then 
have z'z' = zz, so that (26) leads to 
xi + ix; = (cos cp + i sin cp )(Xl + ix2), 
X~ = 
Xs 
18 As follows from (14) if we set Z2 = 0, and similarly for the second and fourth cases. 
u. In fact, it was the study of rotations in space that led Hamilton (1844) to the 
definition of the mUltiplication of quaternions. 

8 Complex Numbers and Quaternlons 
473 
for the coordinates x: of the point on the sphere corresponding to z'. 
But this equation represents the rotation of the sphere through the 
angle cp around the axis oriented by the vector es , where we consider 
the whole space as oriented by the triple (e1 , e2 , es) of basis vectors of 
the coordinate system. 
We next consider the special case in which a, f3 are real and f3 -=I=- O. 
Multiplication by the complex conjugate of the denominator in (25) 
leads, for z -=I=- -a/f3, 00 with z' = x' + iy' and the abbreviation 
d = (f3z + a)(f3z + a) = f32zz + 2af3x + a2, 
to the equations 
x'd = (a2 -
(32) X + af3(zz -
1), 
y'd= y, 
z'z'd = (az - (3)(az -
(3) = a2zz -
2af3x + f32. 
From (26) we thus have 
and the same equations can easily be shown to hold for the two cases 
excluded above, namely, z = -a/f3 and z = 00. Since we may set 
a = cos cp/2, f3 = sin cp/2, we here obtain the rotations about the axis 
oriented by the vector e2 • 
We now consider the general case, where we may assume f3 -=I=- O. 
Then the projectivity a defined by (25) does not leave the point 00 fixed. 
Consequently, its fixed points ~ are obtained from the quadratic equation 
(27) 
f3~2 + (ci -
a) ~ + P = O. 
But this equation may be written (by passage to complex conjugates) 
in the form 
f3( - t-1)2 + (ci -
a)( - t-1) + p = 0 
and thus, if ~ is a fixed point, so also is -t-1 (-=I=-
~). Thus (25) has two 
distinct fixed points, and by (26) they give two diametrically opposite 
points of the sphere. The line joining these two points can now be brought 
into the plane X2 = 0 by a rotation about the Xs axis and then, by rotation 
about the X2 axis, can be made to coincide with the Xs axis. These two 
rotations taken together produce a rotation 8 which, by the special cases 
dealt with above, corresponds to a projectivity T taking the fixed points of 
a into 0 and 00. Thus the projectivity ao = TaT-1 (first T-1, then a, then T) 
has the fixed points 0, 00; in other words, it belongs to the case f3 = O. 
Thus it corresponds to a rotation 80 about the Xs axis, and therefore the 
projectivity a = T- l aoT corresponds to the rotation 81 = 8-1808. 

474 
PART B ARITHMETIC AND ALGEBRA 
Conversely, every rotation is obtained in this way. For let 0 = L~=l e"d" 
with 
L~=l d,,2 = 1 be the vector orienting the axis of rotation, 
where we may exclude the cases 0 = ± es . Then the fixed points of 
the rotation on the sphere have the coordinates (d1/2, d2/2, ds/2) and 
(-d1/2, -d2/2, -ds/2), so that by the equation 
z = (2X1 + 2x2i)(1 -
2XS)-1, 
which follows from (26), the corresponding complex numbers are 
If in (25) we set n: = (l + '2t2)-1, f3 = t2(l + '2t2)-1, we obviously 
obtain a projectivity T taking '2 into 0 and (since t2 = 
- '11) taking 
'1 into 00. Thus the corresponding rotation 8 takes the vector 0 into es , 
so that 80 = 88'8-1 is a rotation about the axis defined byes with the 
same angle of rotation as 8' and therefore corresponds to a projectivity ao . 
Consequently, the rotation 8' = 8-1808 corresponds, as desired, to the 
projectivity a = 
T-l aoT. 
On the basis of these results we can now express the n:, f3 for a in terms 
of the 0" and the angle of rotation of 8'. Since the projectivity ao has 
the fixed points 0, 00, it takes z into pz with a fixed factor p of absolute 
value I. If we now apply Ta = aoT to the point 00, we obtain, assuming 
f3 -=I=- 0 (and thus '2 -=I=- 0) 
(n: -
f3'2)(n:~2 + f3r1 = 
P~21, 
so that 
(29) 
From (27), (28) we obtain 
2ds(d1 -
id2)-1 = '1 + '2 = (n: -
&) f3-1, 
or, in the notation of (22), 
Thus there exists a real number c with a" = cd" (v = I, 2, 3) and therefore 
(since n:& + f3/J = 1, L~=l d} = I) with ao + c2 = I, so that we may set 
(30) 
ao = cos cp/2, 
a" = d" sin cp/2 
(v = 1,2,3). 
From (29), (30) a short calculation shows that 
p = cos cp + i sin cpo 

8 Complex Numbers and Quaternions 
475 
In view of the significance of p for ao and the earlier discussion of the 
special case f3 = 0, it follows that cp is the angle of rotation of 80 and thus 
also of 8', Consequently, the equation (30), which obviously holds for 
the special case f3 = 0, represents the desired connection between quater-
nions and rotations in space. We note that to every rotation the equation 
(30) associates exactly two quaternions with norm 1; for if we replace cp 
by cp + 27T or 0 by -0 and cp by -cp the numbers all (v = 0, 1,2,3) 
become -all' 
3.3. 
Quaternions and Vector Algebra 
F or a fixed Cartesian coordinate system with the basis vectors e1 , e2 , es 
the mapping 
s L ellxlI ---+- jXl + kX2 + lxs 
11=1 
is obviously an isomorphism of the three-dimensional vector space into 
the four-dimensional vector space of quaternions. So we may make the 
identification 
s L CIiXII = jXl + kX2 + lxs . 
11=1 
With a = 
L~=1 ellall the quaternion 
can then be written in the simple form ao + a. Thus ao is called the 
scalar part and a the vector part of A. A simple calculation on the basis 
of (24) then shows that 
(31) 
ab = 
- a . b + a x b; 
here ab denotes the product of the vectors regarded as quaternions, and 
a . b and a x b are the inner (scalar) and vector products, respectively. 
If we pass to the conjugate quaternions on both sides of (31) (whereby 
the scalar part is not changed and the vector part is mUltiplied by -I) 
and note that such a passage is an antiautomorphism, we see that 
ba = -a . b -
a x b. Together with (31) this result shows that: 
(32) 
(33) 
a . b = -~(ab + ba), 
a x b = l(ab -
ba). 
Thus (in analogy to the equations at the end of§l.l for the two-dimensional 

476 
PART B ARITHMETIC AND ALGEBRA 
case) we may express the scalar and the vector products in terms of 
quaternion mUltiplication. IS 
By means of (32), (33) the rules for calculation with these two vector 
products can easily be proved. For example, for the rule 
(34) 
(a x b) x c = b(a . c) -
a(b . c) 
we have by (33) 
4(a x b) x c = abc -
bac -
cab + cba = (abc -
cab) -
(bac -
cba). 
By (32) we also have 
abc -
cab = (abc + acb) -
(acb + cab) = 2b(a . c) -
2a(b . c), 
and by interchange of a with b we obtain 
bac -
cba = 2a(b . c) -
2b(a . c). 
These three equations taken together lead, after division by 4, directly 
to (34). 
If we regard the unit vector 0 as a quaternion, the corresponding 
rotation is, by §3.2, the rotation 8 .. around the axis determined by 0 
through the angle 1T. Now let 8 be an arbitrary rotation (with the origin 
as fixed point) and let A be the corresponding quaternion. Then the 
quaternion AoA-l corresponds to the rotation 8: = 88 .. 8-1. But the 
latter is a rotation through the angle 1T and its axis is determined by the 
image 0' of 0 under 8, since 8:8 = 88 .. implies that the metric relations 
valid for 0, I, 8 .. (I) also hold for 0', 8(I), 8;(8 (I). Thus AOA-l is again 
a quaternion with scalar part 0 and vector part 0' or -0'. For an arbitrary 
vector I (which may always be written as a scalar multiple of a unit 
vector 0) and its image vector I' = 8(I) we thus have 
(35) 
I' = ± AlA-I. 
But the sign here cannot depend on I, since from 
and II , 12 -=I=- 0 it follows that 
I~ + I~ = A(II -
1 2) A-I = ±(Il -
1 2)' = ±(I~ -
I~), 
15 Originally the scalar part and the vector part of the quatemion product were 
actually used in place of these vector products. Gibbs (1884) was the first to introduce 
vector products in modem notation, independently of quaternion mUltiplication. The 
concept of inner product had already occurred in the works of Grassmann (1844), 
whose exterior product (see IB3, §3.3) is also in close relationship with the above vector 
product. 

8 Complex Numbers and Quaternions 
477 
which is impossible for any choice of sign. With a minus sign the equation 
(35) does not represent a rotation. For if we write A = a + a, the condi-
tion x' = x becomes x(a + a) = - (a --f- a) x, or in other words ax = 0, 
a . x = 0, and for a '* 0 these equations are correct only for x = 0, 
whereas for a = 0 they are correct for all x .-l a(,* 0), while for a rotation 
('* I) the fixed vectors form a one-dimensional subspace.16 So we have 
(36) 
Since N(A) = I, we could of course replace A-I by the quaternion A* 
conjugate to A. But we let A-I stand here, because (36) then represents 
a rotation for an arbitrary quaternion A '* 0: we need only write 
A = VN(A) Ao, so that x' = AoxAi)I, N(Ao) = l. 
If b = L~=1 e"d" is the orienting vector of the axis of rotation and cp 
is the angle of rotation in (36), then by (30) we may write 
A = cos cp/2 + b sin cp/2, 
A * = cos cp/2 -
b sin cp/2. 
If we now transform (36) by means of (31) and note that (b x x) . b = 0 
and also, as follows from (34), (b x x) x b = x -
b(x . b), we have the 
Rodrigues formula for rotations: 
(37) 
x' = x cos cp + b(x . b)(1 - cos cp) + (b x x) sin cpo 
This equation provides another proof of the fact that the b, cp appearing 
in (30) actually have the significance assigned to them above: for we need 
only prove that b' = b, x . b = x' . b and also, with the abbreviations 
1) = x -
b(x . b), 1)' = x' -
b(x . b), 
that 
11) I = 11)' I, 
1) . 1)' = 11) 12 cos cp, 
(1) X 1)') b = 11) 12 sin cpo 
3.4. 
The Theorem of Frobenius 
From §1.2 and §3.1 we now see that the two extensions of K, namely, the 
quaternion skew field and the field K(i) (with i 2 = -I) have the following 
properties in common: each of them is a skew field with K as subfield; 
also az = za for every element z and all a E K; and finally, they are both 
vector spaces of finite dimension over K. We are thus led to the concept 
of a division algebra of rank n over K, namely, a skew extension field L of K 
with aex. = ex.a for all a E K, 
ex. E L, which is of dimension n regarded 
as a vector space over K (see IB3, §l.2). The latter property requires the 
existence of elements PI, ... , Pn E L such that for every ex. E L there is 
exactly one n-tuple (aI' ... , an) with a" E K(v = 1, ... , n) and a = L:=1 {3"a". 
16 Thus (35) with the minus sign gives the reflections (a = 0) and the rotatory 
reflections (a =F- 0). 

478 
PART B ARITHMETIC AND ALGEBRA 
The field K itself is, of course, a division algebra of rank lover K, where 
for the basis element f31 we may take any element *- 0 of K. When the 
rank of the division algebra is not stated, we speak of a division algebra 
offiniterank. 17 
. 
The outstanding algebraic importance of the field of complex numbers 
and of the quaternion skew field now depends on the fact that they are 
the only division algebras of finite rank> lover the field of real numbers, 
a result that follows from the theorem of Frobenius: 
A division algebra L of finite rank over a real-closed field K is either K 
itself or else (up to isomorphism) is the field K(i) (with i2 = -I) or the 
quaternion skelv field over K. 
For the proof we first deduce the following property of L:18 for every 
a: E L there exist r, s E K with 
(38) 
a:2 = ra: + s. 
Since L is of dimension n over K, the elements I, a:, ... , a:n are linearly 
dependent; in other words, there exist all E K, not all zero, such that 
L:=o alla:1I = O. Thus the polynomial f(x) = L:=o allxll is of positive degree 
and can therefore, by §2.3, be split into linear and quadratic factors. 
Since f(a:) = 0 and L has no divisors of zero, one of these factors* will 
become 0 when x is replaced by a:. If this factor is quadratic, we already 
have the desired equation (38). But otherwise a: E K and we have (38) with 
r = a:, S = O. 
Now by (II) we see that 1 *- -I, so that 1 + 1 *- 0, and thus we may 
divide by 2 (= 1 + I), so that (38) becomes 
(39) 
(a: -
r/2)2 = r2/4 + s. 
Since we may assume L *- K, there exists an element in L that is not in K. 
For this element the right-hand side of (39) cannot be the square of an 
element t E K, since otherwise we would have a: = r/2 + t or a: = r/2 -
t. 
Thus by (12) there exists atE K with r 2/4 + s = -t 2 = 0, so that 
from (39) we obtain j2 = -I for j = (a: -
r/2) t-1. If K is not already 
exhausted by the adjunction to K of a zero of x 2 -+- I, there must exist a 
17 Such an algebra is seen at once to be an algebra in the sense of IB5, §3.9. By the 
words "division algebra" alone we mean a skew extension field L of K with ao: = cxa 
for all a E K, 0: E L. In some investigations the concept "division algebra" is defined 
more generally; i.e., so as to include the alternative fields of §3.5, in which case the 
division algebras defined here must be called "associative division algebras." 
18 It is only here that any use is made of the hypothesis of finite rank. 
* What we need here is the fact that replacement of x by 0: gives a homomorphism 
of K[x], but by IB4, §2.1, this follows from the easily proved fact that, for every given 0:, 
the g(o:) with g(x) E K[x] are the elements of a commutative subring of L. 

8 Complex Numbers and Quaternions 
479 
f3 E L that is not of the form a + jb (a, b, E K). We now make the following 
assertion, which will also be useful later on: for g, 'YJ E L there exist 
a, b,c E K with 
(40) 
For the proof of this assertion we need only write the equations corre-
sponding to (38) for g, 'YJ, g + 'YJ and take account of the fact that 
g'YJ + 'YJg = (g + 'YJ)2 -
g2 -
'YJ2• In particular, we now use (40) with 
g = j, 'YJ = f3: 
(41) 
jf3 + f3j = aj + bf3 + c. 
Then for arbitrary u, v E K we have 
(uj + V(3)2 = -u2 + uvc + uvaj + uVbf3 + V2f32. 
From the equations corresponding to (38) 
f32 = r'f3 + S' 
(r', S' E K), 
(42) 
(uj + v(3)2 = r"(uj + v(3) + s" 
(r", s" E K), 
we further have 
r"uj + r"vf3 + s" = uvaj + (uvb + v2r') f3 + (-u2 + UVC + V2S ' ). 
Since (3 is not a linear combination of I, j with coefficients from K, the 
elements i, j, f3 are linearly independent over K, so that comparison of 
coefficients in the last equation gives 
r"u = uva, 
r"v = uvb + v2r'. 
For u, v '* 0 we thus have 
ub = v(a - r'). 
If in this equation we first set u = v = 1 and then u = 1, v = -1, 
it follows, since a, b, r' do not depend on u, v, that 
(43) 
b = 0, 
a = r'. 
With x, y, Z E K we now write k = xf3 - yj - z, and from (41), (42), 
(43) we calculate 
k2 = X2S' - y2 + Z2 -
xyc + (xa - 2z)(xf3 - yj), 
jk + kj = (xc + 2y) + (xa - 2z)j. 

480 
PART B ARITHMETIC AND ALGEBRA 
These equations suggest that we should require 
xc + 2y = 0, 
xa -
2z = 0, 
as may obviously be done for arbitrary x -=I=- 0, so that k 2 E K and 
jk + kj = 0. But since x -=I=-° and I, j, f3 are linearly independent, the 
element k cannot lie in K, so that k 2 is not the square of an element of K, 
and thus by (12) the element -k2 is such a square. Thus we can choose x 
in such a way that k 2 = -I. But then the elements j, k satisfy those 
equations (24) in which I does not occur. If we now set I = jk, we have 
12 = jkjk = -jkkj = jj = -I, 
kl = -kkj = j, 
Ik = jkk = -j, 
lj = jkj = -kjj = k,jl = jjk = -k, so that (24) is completely satisfied. 
From I = a + jb + ke with a, b, e E K it would follow, by left-
multiplication withj that -k = ja -
b + Ie, so that 
- k = j( a + eb) + (ae -
b) + ke2 
and thus, on account of the linear independence of I,j, k, we would 
have e2 = -I, which is impossible by (11). Thus I,j, k, I are linearly 
independent. In order to show that L is the quaternion skew field over K, 
we need only express every element g E K as a linear combination of 
I,j, k, I with coefficients from K. For this purpose we note that, under 
the single condition j2 = -I, we have from (41), (43) the formula 
jf3 + f3j = aj + e with a, e E K; it is true that in the proof of (43) we 
made the further assumption that f3 is linearly independent of I, j, but if 
this is not the case our assertion follows at once from (41) (though with 
other values of a, c). We thus have the equations 
and consequently 
jg + ~ = aj + e, 
kg + gk = a'k + e', 
Ig + gl = a"1 + e", 
lUg + ~) k-k(kg + gk)-I(lg + g/) = (-a + a' + a")-je-ke'-Ie". 
Since the left-hand side of this equation is equal to 2~, the desired represen-
tation for g is thereby obtained. 
3.5. 
Cayley Numbers 
In the theorem of Frobenius the only one of the "usual rules for calcula-
tion" that is given up is the commutativity of multiplication, and as 
a result we obtain, together with the field of complex numbers, the 
quaternion skew field. It is now natural to ask what new structures we 
could obtain by giving up further rules of calculation, or perhaps by 
only weakening them. A complete answer to this question can be given 

8 Complex Numbers and Quaternions 
481 
in the following special case: the associative law for multiplication, which 
is required in skew fields, is replaced by the rules 
(44) 
a(ab) = (aa) b, 
(ab) b = a(bb). 
Algebraic structures of this kind are called alternative fields, a name 
which is explained by the fact that if the other rules (for example the 
distributive laws) are retained, the rules (44) have the following con-
sequence: the associator (ab) c - a(bc) is changed to - (ab) c + a(bc) when 
any two of the elements a, b, c are interchanged. If in the definition of 
"division algebra" we replace "skew field" by "alternative field," the 
theorem of Frobenius must now be extended, to the effect that (up to 
isomorphism) there exists exactly one further division algebra, which 
is of rank 8.19 It is called a Cayley algebra, and its elements are called 
Cayley numbers or octaves. 20 We can obtain these numbers most con-
veniently if we start from the quaternion skew field Q over K and in the 
set of pairs (A, B) with A, BE Q we define addition and mUltiplication in 
the following way, where the conjugate quaternion is again denoted by 
an asterisk:2l 
(45) 
(AI' Bl) + (A2 , B2) = (AI + A2 , Bl + B2), 
(AI' Bl)(A2 , B2) = (AlA2 -
B2Bi, A2Bl + Ai B2)' 
Since A ---+- (A, 0) is then an isomorphism of Q, we may set A = (A, 0), 
so that we actually have an extension of K, and even of Q. The fact that 
multiplication is not associative is seen from the following example, 
in which for abbreviation we have set (0, I) = E: 
(Ej) k = (0, -I), E(jk) = (0, I). 
By (45) it is easy to see that the mapping (A, B) ---+- (A *, - B) is an antiauto-
morphism of the Cayley algebra. Then r* = (A *, - B) is called the 
conjugate Cayley number of r = (A, B). The real number 
rr* = r*r = N(A) + N(B) 
is called the norm N(r) of r. In the same way as for complex numbers 
and quaternions, we have N(rl r2) = N(rl ) N(r2), so that we may write 
19 The fact that only the ranks 1, 2,4, 8 are possible can be proved without (44). For 
the case that K is the field of real numbers, this proof was already given by J. Milnor 
(Ann. of Math. 68, 444-449, 1958). From this fact, by using a result of A. Tarski 
(A Decision Method for Elementary Algebra and Geometry, 2nd ed., Univ. of California 
Press, 1951) we can then prove, for every natural number n i= J, 2,4,8, that the rank n 
is impossible for an arbitrary real-closed K. 
20 In analogy with the quaternions (of rank 4, whereas here the rank is 8). 
21 For details see, e.g., Pickert [3], Section 6.3. 

482 
PART B ARITHMETIC AND ALGEBRA 
the product of sums of 8 squares again in form of 8 squares. 22 Since 
multiplication is no longer associative, we cannot prove this assertion 
in the same way as for quaternions, namely, from the fact that passage 
to conjugates is an antiautomorphism. Nevertheless, it is easy to show 
from (45) that 
N(r1r 2) = N(r1) N(r2) -
(CBi + (CBi)*) + (B:C + (B:C)*) 
with C = AIA2Bl , and since the scalar part of the product of two quater-
nions is independent of the order of the factors, we thus have the desired 
assertion. 
Let us note that the passage from quaternions to Cayley numbers is 
quite analogous to the procedure described in §3.1 for passing from the 
complex numbers to the quaternions; in order to display this analogy 
we have only to replace the quaternion A in (19) by the pair (n:, {3), 
whereupon the matrix mUltiplication becomes 
The concept of a Cayley algebra can be generalized in the following 
way. We take for Q a generalized quaternion skew field, choose an element 
C E K that is not the norm of an element of Q, and in the second equation 
(45) replace the term - B2Bi by CB2Bt. These (generalized) Cayley 
algebras are again alternative fields. Their great importance lies in the 
fact, not discovered until 1950/51, that every alternative field which is 
not already a skew field must be such a Cayley algebra. 23 The alternative 
fields play an important role in the study of projective planes: just as 
the incidence axioms for the projective plane and the theorem of Desargues 
allow us to construct a plane coordinate geometry over a skew field, 
so the little Desargues theorem, i.e., the special case with incidence of 
center and axis, and the incidence axioms for plane projective geometry 
allow us to construct a coordinate geometry over an alternative field 
(R. Moufang, 1933). One can also say (in a sense that can be made quite 
precise): in exactly the same way as the Desargues theorem corresponds 
to the associative law for multiplication, the little Desargues theorem 
corresponds to the alternative law (44).24 
22 Numerical example: 
(P+22+32+42+52+62+72+82)(92+ 102 + IP+ 122+ 132 + 142+ 152 + 162) 
= 362 + 382 + 542 + 622 + 722 + 1082 + 1122 + 4742. 
23 For details see, e.g., Pickert [3], Section 6.3. 
2' See, e.g., Pickert [3], p. 134 (theorem 27), and p. 187 (footnote 1). 

CHAPTER 9 
Lattices 
Introduction 
For the connectives" (and) and v (or) between statements and the 
connectives n (intersection) and u (union) between sets we have the 
following rules (see lA, §§2, 7, 9): 
Commutative laws: a n b = b n a; a u b = b u a; 
Associative laws: an (b n c) = (a n b) n c; a u (b u c) = (a u b) u c; 
Absorption laws: a n (a u b) = a; a u (a n b) = a. 
Here the symbols n, u are intended to suggest ", v and n, U but to be 
distinct from them. 
If a, b, c are subgroups of a group and if a n b is the greatest subgroup 
common to a and b, and a u b is the smallest one of the subgroups 
containing both a and b, then the rules listed above still hold, but the 
further rules for ", v and n, U (see lA, loco cit.) are in general no longer 
valid. The same remark holds for the normal subgroups of a group, 
the subrings of a ring, the ideals of a ring, the subfields of a field, the 
sublattices of a lattice, and in general (cf. IBIO) for the subconfigurations 
of an (algebraic) configuration with respect to a given structlN"e. The 
concepts and theories of the present chapter are thus of importance for a 
general theory of structure, the basic features of which will be discussed 
in the next chapter. 
A set with two connectives satisfying the above laws was called a 
dual group by Dedekind (1897); today it is customary to use the name 
lattice introduced by G. Birkhoff in 1933; (the corresponding French 
name treillis is due to Chatelet (1945) and the German Verband to Fritz 
Klein-Barmen (1932); the reason for the choice of such a name is given 
on page 487. 
483 

484 
PART B ARITHMETIC AND ALGEBRA 
Quite apart from its importance for the general theory of structure, 
there is a certain attractiveness in studying an algebraic structure in which 
the convenient rules of commutativity and associativity are satisfied and 
there is complete duality between the two connectives; moreover, this 
structure is of quite different character from other well-known structures; 
e.g., neither of the two connectives is uniquely invertible. The study of 
Boolean lattices is even of practical importance for the construction of 
electric circuits (circuit algebra). 
In §1 we make use of the lattice Pe of all subsets of a given set e to 
introduce the fundamental concepts of the theory of lattices, in §2 we give 
examples, the large number of which indicates the importance of the 
theory, and then in the following sections we describe some of the charac-
teristic properties of a few particular kinds of lattices. 
In the present chapter we can give only a first introduction to the theory. 
For further study we recommend the outstanding textbook: 
G. Birkhoff, Lattice Theory, Amer. Math. Soc. ColI. Publ., 2nd ed., 
1948, supplemented by the later work of the same author: 
Proceedings in Pure Mathematics, Vol. II, Lattice Theory, Amer. Math. 
Soc., Providence, R.I., 1961. 
Other important textbooks are: 
M.L. Dubreil-Jacotin, L. Lesieur, R. Croisot, Le~ons sur fa theorie des 
treillis, des structures afgebriques ordonnees et des treillis geometriques, 
Paris 1953. 
H. Hermes, Einfohrung in die Verbandstheorie, VerI. Springer, Berlin, 
Gottingen and Heidelberg, 1955. 
G. Szasz, Einfuhrung in die Verbandstheorie, Budapest, 1962. 
In many respects our discussion is based directly on the book of Hermes, 
to which we shall often refer below. 
The first comprehensive account was given in the encyclopedia 
article. 
H. Hermes and G. Kothe, Theorie der Verbiinde, Enz. d. Math. Wiss., 
2nd ed., I, 13, 1939. 
This article also includes important historical information. 
Since the theory of lattices is closely related to structure theory and 
consequently to mathematical logic, we use the logical symbols introduced 
in IA: 
--, not 
/\8 for all s 
---+- if ... then 
" and 
v or 
V 8 there exists an s such that 
~ if and only if 

9 Lattices 
485 
1. Properties of the Power Set 
Let e be a set with elements denoted by lower-case Greek letters and 
subsets by lower-case italic letters. Let Pe be the set of subsets of e, 
the so-called power set. It is with this power set that the discussion in 
the present section deals almost exclusively; the reader should keep in 
mind that the elements of Pe are the subsets of e. 
Pe has the following properties (cf. lA, §9): 
I. In Pe there is defined a two-place relation, namely inclusion ~. 
This relation is 
(Ir) 
reflexive: 
a~a, 
(It) 
transitive: 
a ~ b " b ~ c ----+ a ~ c, 
(Ii) 
identitive: 
a ~ b " b ~ a ----+ a = b, 
and is thus an order (in the sense of ~). We use the word order here 
instead of "semiorder" or "partial order." If it is also true, which generally 
will not be the case in the present section, that 
(11) 
then we will speak of a linear order (cf. lA, §8.3). 
Problem: For which sets e is Pe linearly ordered by inclusion? 
Definition: A set in which an order is defined is called an ordered set, 
and a linearly ordered set is also called a chain. 
In general, we shall denote an order relation by ~ (read "smaller 
than or equal to"), reserving ~ for inclusion of sets. The relation "smaller 
than or equal to" for real numbers will be denoted by ~z. By a < b we 
mean a ~ b " a -=I=- b, and by a ~ b we mean b ~ a. 
To describe an ordered set, or (later) a lattice, it is necessary to state 
the ordering relation, so that such a set is completely described by symbol 
like (M, ~). But where no misunderstanding can arise, we shall speak 
simply of the "ordered set M" or of the "lattice M." 
The order of a finite set M can be described by an order diagram, 
also called a Hasse diagram. For such a diagram we first make the following 
definition. 
Definition: a is said to be a lower neighbor of b if a < b and there is 
no element of M between a and b; in other words, if -, V c (a < c " c < b); 
i.e., 
a ~ c ~ b ----+ c = a v c = b. 
The elements of M are then denoted by points in a plane in such a way 
that if a is a 10wer neighbor of b, the point a is lower on the page than 

486 
PART B ARITHMETIC AND ALGEBRA 
the point b and is joined to b by a straight line. For example, Figure 1 
blJcI. 
indicates an ordered set with the following relations and no 
others: 
a. 
c 
1'1. 
n ~ n, 
a ~ a, 
n ~ a, 
a ~ b, 
n ~ b, 
b ~ b, 
11 ~ c, 
c ~ c, 
n ~ d, 
c ~ d, 
d ~d. 
Fig. 1 
II. In Pe we have defined two connectives, which to a 
pair (a, b) of subsets assign the intersection a n b and the 
union a u b, respectively. In terms of the elements of e these connectives 
can be defined as follows (cf. lA, §7): 
gEanb~gEa"gEb 
g E a u b ~ g E a v g E b, 
but they can also be defined by the order alone without reference to the 
elements of e; namely, an b is the greatest common lower element, or 
the greatest lower bound, and a u b is the least common upper element, or 
least upper bound. In place of the pair of elements Pe, namely the two 
subsets a, b of e, we now consider an arbitrary subset N of an ordered 
set M. 
Definition: s is called an upper bound of N if /\xeN x ~ s; and v is called 
the least upper bound of N if 
(2v, I) v is an upper bound of N, so that /\ x ~ v, and 
xeN 
(2v,2) v is smaller than or equal to every upper bound of N: 
/\8(/\ x~s---+-v~s). 
. xeN 
. 
Not every subset of an ordered set has a least upper bound or even an 
upper bound; for example, in the set with the order diagram of Figure 1 
the subset consisting of the elements a, n, c has no upper bound, and in 
the set of positive rational numbers ordered by ~z the subset of numbers 
with x 2 ~z 2 has upper bounds, but no least upper bound. 
From (2v, 2) it follows that a set N cannot have more than one least 
upper bound. (If v and ware least upper bounds, then v ~ wand w ~ v.) 
It is this fact that justifies our speaking of the least upper bound of N. 
It is also called the smallest common upper element or the join and is 
denoted by U xeN X or UN x. In case N contains only two elements, we 
write v = a u b. For this case let us write out the definition once again: 
(3v) 
v = a u b ~ a ~ v " b ~ v " /\ [(a ~ s " b ~ s) ---+- v ~ s], 
8 
in other words: a u b is characterized by the following relations: 
(3v') a ~ a u b " b ~ a u b " /\ [(a ~ s " b ~ s) ---+- a u b ~ sJ. 
8 

9 Lattices 
487 
Correspondingly, the least upper bound (greatest common lower element, 
intersection, or meet) is defined as follows: 
(2d) 
d = n x ~ /\ d ~ x " /\t( /\ t ~ x ---+- t ~ d), 
xeN 
xeN 
xeN 
or for two elements: 
(3d) 
d = a n b ~ d ~ a " d :::;; b " /\ [(t :::;; a " t :::;; b) ---+- t :::;; d], 
t 
or 
(3d') 
a n b :::;; a " a n b :::;; b " /\[(t :::;; a " t :::;; b) ---+- t :::;; a n b]. 
t 
Definition: An ordered set in which a meet and a join exist for every 
pair of elements is called a lattice; if for every subset of the ordered set 
there exists a meet and a join (in this case it is more usual to say "greatest 
lower bound" and "least upper bound"), the lattice is said to be complete. 
If only one of the two elements "meet" and "join" is known to exist, 
we speak of a semi/attice. 
The name lattice is explained by the order diagrams (e.g., Figures 2 to 4, 
p. 492), in which each of the elements is joined by a straight line segment after 
the manner of a latticework for vines. 
The lattice Pe is complete, since in this case the join and meet are simply 
the union and intersection respectively of the subsets. The set-theoretic 
connectives will be denoted by round signs to distinguish them from the 
lattice-theoretic connectives with rectangular signs, and the logical 
connectives with acute-angled signs. 
From the definition of join and meet we have the following rules: 
The commutative laws: 
(4, 1, d) a n b = b n a, 
(4, 1, v) a u b = b u a, 
the associative laws: 
(4,2, d) a n (b n c) = (a n b) n c, 
(4,2, v) a u (b u c) = ta u b) u c, 
the absorption laws: 
(4, 3, d) 
a n (a u b) = a, 
(4, 3, v) 
a u (a n b) = a. 
Remarks: 1. 
On the basis of the associative laws we may omit the 
brackets when the connectives are applied to finitely many elements 
(cf. IBl, §1.3). 
2. The definitions and these rules for calculation are dual in the following 
sense: if in a valid theorem involving :::;;, n. u we interchange:::;; with ~ 

488 
PART B ARITHMETIC AND ALGEBRA 
and n with u, the resulting theorem is also valid. The principle of duality 
in projective geometry is a special case (cf. §2.2). 
Instead of using an order relation, we may also define a lattice by means 
of two connectives with the properties (4, 1-3). In order to make this 
statement completely clear, we introduce a new symbol: a set M in which 
two connectives T,.1 are defined,l satisfying the rules a T b = b T a and so 
forth, as in (4), is called (after Dedekind) a dual group. The above remarks 
(if the proofs for the rules (4) are carried out) show that every lattice is 
a dual group. We now assert conversely: every dual group is a lattice. 
For the proof we must show that in every dual group we can introduce 
an order with the property that for every two elements a, b there exists 
a least common upper element a U b and a greatest common lower 
element a n b. In fact, we can arrange matters so that a u b = a.1 band 
an b = aT b. 
From (4) we first deduce two further relations: 
(5d) aTa = a, 
(6) 
(5v) 
a.1 a = a; 
a.1 b = b ~ a T b = a. 
Here we shall give only the proof for (5d): 
In (4, 3, v) we set b = a: 
(i) 
a.1 (a T a) = a. 
In (4, 3, d) we set b = a T a: 
(ii) 
a T (a .1 (a T a) = a. 
Then (i) and (ii) imply (5d). 
We now define 
(7) 
a ~ b +-~ a T b = a. 
In order to preserve the duality we also define 
(7') 
From (6) we then have: a ~ b ~ b ~ a. 
We must now prove: 
a) ~ is an order relation; i.e., we have (Ir), (l t), (Ii). As an example, 
we give the proof of (l t). In view of (7) the assertion reads: 
(a T b = a " b T C = b) ~ a T c = a. 
1 We here allow ourselves a temporary misuse (in the present subsection only) of the 
symbols T, .1, introduced by Bourbaki in a different sense (in which they are used below 
in ml0). 

9 Lattices 
489 
Proof: aT c = (a T b) T C = aT (b T c) = aT b = a. 
b) With T instead of n we have (3d') and thus a T b = a n b. 
c) With.L in place of u we have (3v') and thus a.L b = a u b. 
(For b) it is convenient to use (7), and for c) to use (7').) 
It is interesting to note that a given algebraic configuration can be 
defined either on the basis of an order relation or on the basis of con-
nectives (cf. IBIO, §l). 
Ill. In Pe we have the distributive laws 
(8d) 
(8v) 
a n (b u c) = (a n b) u (a n c), 
a u (b n c) = (a u b) n (a u c). 
These laws do not follow from the above laws. For example, they do 
not hold in the lattice (d) with the order diagram in Figure 2 (page 492). 
Here we have 
a n (b u c) = a , 
(a n b) u (a n c) = nun = n. 
However, either of the two laws (8) follows from the other; for example, 
(8v) from 8d): 
(a u b) n (a u c) = [(a u b) n a] u [(a u b) n c] 
by (8d) 
= a u [(a u b) n c] 
= a u (a n c) u (b n c) 
= a u (b n c). 
by (4, 3, d) 
by (8d) and (4,2, v) 
Furthermore, in every lattice we have the distributive inequality 
(8d') 
(a n b) u (a n c) ~ a n (b u c) 
since 
an b ~ a 
and 
anb~b~b~buc 
and 
an c ~ a 
and 
an c ~ c ~ b u c. 
In order to prove (8d) we thus need only prove that 
(8d") 
a n (b u c) ~ (a n b) u (a n c). 
Definition: a lattice in which the distributive laws hold is called a 
distributive lattice. 

490 
PART B ARITHMETIC AND ALGEBRA 
We cannot enter here upon the subject of infinite distributive laws 
in complete lattices, although they are of fundamental importance for 
the representability of a lattice as the lattice of subsets of a set (cf. Hermes 
[1], and in particular §24.) 
IV. 
The set Pe has a least and a greatest element, namely the empty 
set and e. 
Definition: an element of an ordered set is called a 
least element or zero element (n), 
if 
/\ n ~ X, 
a; eM 
greatest element or unit element (e), 
if 
/\ x ~ e. 
a; eM 
V. 
Definition: If a is an element of the lattice M with zero element n 
and unit element e, then a' is the complement of a if 
(9) 
a n a' = n 
and 
a u a' = e. 
A lattice in which every element has a complement is said to be com-
plemented. 
A distributive complemented lattice is called a Boolean lattice. For 
example, Pe is a Boolean lattice. Boolean lattices are discussed in lA, §9, 
so that we shall not deal with them here. 
VI. 
The set Pe has a class of distinguished elements, namely the 
subsets of e that consist of exactly one element g. In the lattice, they are 
the upper neighbors of the zero element. Every element of Pe is a union 
of such elements. 
In general, in an ordered set with zero element n the upper neighbors 
of the zero element are called atoms (occasionally also points). A lattice 
is called atomic if every element other than n is an upper bound for at 
least one atom. 
Thus Pe is a complete atomic Boolean lattice, and these properties 
characterize Pe in the following sense: 
Theorem. 
Every complete atomic Boolean lattice is isomorphic to the 
lattice of subsets of a set (namely the set of its atoms). 
For the proof we must refer again to Hermes [1]. 
2. 
Examples 
2.1. 
Lattices of Subgroups 
In the set e let there be defined a connective (to be denoted by simple 
juxtaposition) with respect to which e forms a group. Instead of Pe we 

9 Lattices 
491 
now consider the set Ue of all subgroups of the group e. In Ue also there 
is an order defined by (set-theoretic) inclusion, and it is well known that 
in this case the symbols a ~ b or a ~ b can be read as "a is a subgroup 
of b." Also it is well known that the intersection a n b is likewise a 
subgroup of e and is thus in Ue, and in fact a n b is the greatest subgroup 
of e contained in both a and b; thus 
an b = an b. 
But the set-theoretical union a u b is not always a subgroup of e, and 
thus is not always contained in Ue. Nevertheless, for two subgroups, 
or even for arbitrarily many subgroups, there always exists a smallest 
subgroup of e that contains them all, a U b or UN a. Thus Ue forms a 
complete lattice. 2 
It is also true that the set of subrings or the set of ideals of a ring e 
or the set of subfields of a field e form a complete lattice. A general state-
ment in this direction is given in IBIO, §2.3. 
The existence of the join in Ue is a consequence of the following general 
theorem. 
Theorem on the least upper bound. If an ordered set M has thefollowing 
two properties: 
1. every non-empty subset of M has a greatest lower bound, and 
2. the subset N ~ M has an upper bound, 
then N has a least upper bound v, and in fact v is the greatest lower bound 
of all the upper bounds of N. 
Proof. Let S be the set of upper bounds of N. By property 2, the set S 
is not empty, and thus by property 1 the greatest lower bound v of Sexists. 
For v we have by definition 
(VI) 
/\ v ~ s 
seS 
and 
(V2) 
/\ w ~ s ----+ w ~ V. 
seS 
The assertion is that v is the least upper bound of N; or in other words 
(BI) 
/\ x ~ V 
XeN 
and 
/\ x ~ t ----+ v ~ t. 
XeN 
Proof for (BI). 
For every x EN we have /\seS x ~ s, so that x ~ v 
follows from (V2). 
Proof for (B2). 
If /\xeN x ~ t, then t E S, so that v ~ t by (VI). 
The lattice of subgroups of a group is not necessarily distributive. 
For example, if e is the Klein four-group (see IB2, §I5.3.3), then Ue has 
the orde~-diagram (d), Figure 2. 
2 In IB2, §3.4, we wrote <a v b) for a u band <Sl) for UN a, with Sl = UaeN a. 

492 
PART B ARITHMETIC AND ALGEBRA 
If e is the commutative group with generators ex, f3 and relations ex4 = 
€, 
f32 = € (where € is the neutral element of e), and is thus the direct product 
of two cyclic groups of orders 2 and 4, then the subgroups are 
n = {€}, a = {€, ex2}, b = {€, f3}, p = {€, ex, ex2, ex3}, q = {€, ex2, f3, ex2f3}, e. 
The order-diagram is given in Figure 3. The juxtaposed numbers will be 
Fig. 2. (d) 
Fig. 4 
explained in §2.4. This lattice is distributive but not complemented, 
since a and q have no complements. 
Thus we see that various types of lattices can occur as lattices of sub-
groups. At the present time it is not known what properties a lattice V 
must have in order that there may exist a group e for which Ue is iso-
morphic to V, or in other words, under what conditions is V representable 
as a lattice of subgroups (cf. M. Suzuki, "Structure of a Group and the 
Structure of its Lattice of Subgroups." Ergebnisse d. Math. Neue Folge, 
Heft 10. Springer Verlag, Berlin, Gottingen and Heidelberg, 1956.) 
For a group e we have Ue ~ Pe. The order relation in Ue is same as in Pe. 
But, although Ue thus forms a lattice under the same ordering as Pe, 
we do not call Ue a sub/attice but only as ubband (from the German 
name Teilbund, introduced by Schwan). 
For the concept of a sublattice we do not use the definition of a lattice 
in terms of order but in terms of the connectives (in other words, we make 
use of the definition of a dual group); if M is a lattice (dual group) with 
the connectives n, u and N is a subset of M, then N is called a sub/attice 
of M if N forms a lattice with respect to the same connectives. 
A further example is given in Figure 4. If we omit the two points that 
are twice circled, we obtain a sublattice, but if we omit only the central 
point, we obtain only a subband. 
The reader is invited to prove: 
1. N is a sub lattice of M if and only if N is closed with respect to n 
and u; in other words, if and only if N contains a n b and a u b for 
every a, bEN. 
2. Every sublattice is a subband. 

9 Lattices 
493 
2.2. 
Vector Spaces. Projective Geometry 
The vector subspaces of a vector space can be interpreted geometrically 
as the linear subspaces of a projective space. 
Let the set e consist of the points of the (for convenience, three-
dimensional) projective space, and let Le be the set of its linear subspaces, 
so that Le consists of the empty set n, the points, lines, planes, and e itself. 
Let the order be defined by inclusion. Then a n b is the set of elements 
common to a and b, or in other words the intersection of these subspaces, 
and a u b is the smallest linear space which includes a and b, or in other 
words it is the subspace spanned by a and b. 
This lattice is complemented: for every subspace a of e there exists a 
disjoint subspace a' (a n a' = n) which together with a spans the whole 
space e (a u a' = e). Every element has infinitely many complements. 
The set Le is not distributive. For example, if a is a plane and b, care 
two points not on a, then a n (b u c) is the point of intersection of 
the plane a with the line determined by band c, but, on the other hand, 
(a n b) u (a n c) = nun = n. 
2.3. 
Every Linearly Ordered Set is a Lattice, with a n b as the smaller, 
and a u b as the greater of the two elements a and b. We write a n b = min 
(a, b), a u b = max(a, b). 
Every such lattice is distributive, since 
a n (b u c) = min (a, max (b, c), 
(a n b) u (a n c) = max (min (a, b), min (a, c). 
In verifying this statement the reader may assume b ~ c (since band c 
occur symmetrically) and may therefore confine his attention to the 
three cases a ~ b ~ c, b ~ a ~ c, b ~ c ~ a. 
A special case is the set Z of natural numbers (with or without 0) 
with f as the order: (Z, f). 
In preparation for the next example we introduce the general concept 
of a direct product: let (Ml , ~), (M2' ~) be two lattices. (Whether the 
ordering is "the same" in both, and in fact just what such a question would 
mean, is of no importance to us here.) We form the set M = Ml X M2 ; 
its elements are the pairs (ai' a2), al E Ml , a2 E M2 . In M we define an 
order by 
(ai, a2) ~ (b1 , b2) ~ a1 ~ b1 A a2 ~ b2 . 
Then M is a lattice with 
(ai' a2) n (b1 , b2) = (a1 n b1 , a2 n b2), 
(ai' a2) u (b1 , b2) = (al u b1 , a2 u b2). 

494 
PART B ARITHMETIC AND ALGEBRA 
It is easy to see that the direct product of two distributive lattices is a 
distributive lattice. 
We may allow the case that Ml and M2 are the same lattice. Further-
more, we can form the direct product of arbitrarily many factors. 
2.4. 
Divisibility 
Let M = Z be the set of natural numbers, not including O. The relation 
alb (a divides b) is an order, a n b is the greatest common divisor, 
and a u b is the smallest common mUltiple of a and b. Then (Z, I) is a 
lattice, which is distributive. The distributivity is closely connected with 
the unique factorization of a number into prime factors. Let PI , P2, ... 
be the prime numbers in their natural sequence, and let 
a = IT P~v, 
b = IT P~v, 
c = IT P~v; 
for exll , f311 , ')'11 the value 0 is also allowed; the product is to be extended 
only up to the highest prime dividing a, b, c. Then b n c = 
nIlP~ln(~II'YII), 
a u b = nil p~ln(CXII'~II) and the assertion reads: for every v 
The proof is the same as in §2.3. By assigning a to the system (exl' ex2, ... ) 
we map the lattice (Z, I) isomorphically onto the direct product of infinitely 
many factors (Z, =f). 
A finite sublattice of (Z, I) is formed, for example, by the factors of 
the number 12. Its order diagram is presented in Figure 3. It has a zero 
element n = 1 and a unit element e = 12. It is not complemented. 
2.5. 
Circuit Algebra 
An electric circuit consists of conductors to which, by neglecting 
resistance, we may assign the conductivity 1 or 0 according to whether 
or not a current can flow between their endpoints. The conductivity 
of a circuit in which conductors with conductivity a, b are joined in series 
or in parallel is denoted by a n b and by a u b, respectively. The values 
of a n b and a u b are determined from those of a and b according to 
the following tables: 
anb: a= 1 11 
0 
0100 
1 I 1 1 
aub: a=oll 0 

9 Lattices 
495 
which are the same as the truth tables for logical conjunction and alter-
native (lA, §2.4). We are dealing here with a Boolean lattice. 
These examples show that various types of lattices play an important 
role in various parts of mathematics. In the following sections we give 
some important theorems for a few types of lattices. 
3. 
Lattices of Finite Length 
In algebra an important role is played by a certain finiteness condition, 
namely, the factor chain condition. 3 In the simplest case this condition 
refers to the natural numbers as follows: if, beginning with a natural 
number Zo , we form a chain of factors, i.e., a sequence Zo , Zl , Z2 , ... with 
ZII+1 I ZII' the chain contains only finitely many distinct elements, a fact 
which is the basis, for example, for the factorization of every natural 
number into prime factors (though not of the uniqueness of this factoriza-
tion). 
The factor chain condition can be formulated as a lattice property 
in the following way: 
Definition: a lattice (M, ~) is said to be of finite descending length if 
every descending chain a = 
Xo ~ Xl ~ X2 ~ ... contains at most finitely 
many distinct elements. The concept of finite ascending length is defined 
analogously. If a lattice is of finite length both ascending and descending, 
it is said to be of finite length. 4 
The lattice (Z, I) is of finite descending length but not of finite asceuding 
length. The lattice of linear subspaces of a projective space is of finite 
length if the dimension of the space is finite. But one of the advantages of 
a lattice-theoretic treatment of projective geometry is that it includes 
spaces of infinite dimension. 
In Xo ~ Xl ~ ••• ~ Xl, the number I is called the length of the chain. 
Statements about the length of chains are generally of 
interest only for proper chains, i.e., for chains containing 
only distinct elements. 
If a lattice is of finite length, it does not necessarily 
follow that the lengths of the proper chains have an 
upper bound. For example, in the lattice with the 
order diagram of Figure 5 the kth chain is of length k. 
3 Cf. IB6, §2.9. Maximality condition for ideals. 
Fig. 5 
" For our present purposes we have given a stronger (or more restrictive) meaning to 
"of finite length" than the one given in Hermes ([1], page 73). A lattIce is there said to 
be of finite length if every chain joining any two elements is of finite length. Every 
lattice of finite length in our sense is of finite length in the sense of Hermes, but not 
conversely. 

496 
PART B ARITHMETIC AND ALGEBRA 
Theorem. 
Every non-empty lattice M that is of finite descending length 
contains a zero element. 
Proof. Let Xo be an arbitrary element of M. Then we have 
either 
AreXo ~ x; here Xo is the zero element; 
or 
V x --, (xo ~ x). Here it is not necessarily true that x < xo , but 
then we have Xl = X n Xo < Xo. We then proceed with Xl in exactly 
the same way as with Xo. In this way we obtain a descending proper 
chain, which by hypothesis has only finitely many elements, breaking off 
say with the element Xn • But this means that for Xn we have AreXn ~ X, 
so that Xn is the desired zero element. 
Thus it is easy to see that every lattice of finite descending length is 
atomic (definition in §l, VI). But an atomic lattice is not necessarily of 
finite descending length; for example, if e is infinite, then Pe is atomic 
but is not of finite descending length. Thus atomicity represents a 
weakening of finiteness of length, just as finiteness of length is a 
weakening of finiteness. The fact that important consequences can be 
drawn from the property of atomicity is clear from §l, VI. 
For lattices of finite descending length there is an analogue to the 
factorization of a number into prime factors. We first replace the concept 
of product, which is foreign to the lattice (Z, I), by the concept of least 
common mUltiple: every number can be represented as the least common 
mUltiple of finitely many prime powers. The prime powers can be 
characterized (in a lattice-theoretic way) by the property that they cannot 
be represented as the least common mUltiples of other elements. Then 
the factorization theorem can be expressed as follows for lattices: 
Definition. An element q of a lattice M is said to be u-irreducible, 
or primary (the latter term being due to a certain analogy with the con-
cept of "primary ideal" in rings (IB5, §3.6), if q cannot be represented 
as the join of two other elements, or in other words if 
q = X U Y ---+ q = X V q = y. 
It may happen that a lattice M consists entirely of primary elements, 
as will be the case, for example, if M is linearly ordered. It can also 
happen that a lattice has no primary elements at all; for example, the 
lattice of the pairs of rational numbers (ai, a2) with 0 ~ ai ~ 1 under the 
ordering 
in which for every given pair (ai' a2) there exist pairs (b1, b2) with 
b1 < a1 , b2 < a2 , and (ai' a2) = (b1 , aJ u (ai' b2)· 
II 
• 
Under what conditions is it true that every element in a lattice can be 
represented as the join of primary elements (or as we shall also say, 

9 Lattices 
497 
can be factored into primary elements)? Here we shall discuss only 
representation as the join of finitely many primary elements and not 
the question of representation as the least upper bound of arbitrarily 
many elements. 
If a itself is a primary element, we shall regard it as a factorization. 
Lemma. If a is an element that cannot be represented as the join 
of finitely many primary elements, then there exists an a1 < a with the 
same property. 
For since a is not a primary element, there exists a factorization 
a = a1 u b1 with al < a and b1 < a. But then at least one of the two 
elements a1 , b1 cannot be factored into finitely many primary elements, 
since otherwise there would exist such a factorization for a itself. 
Thus if there is an element a in M that cannot be factored into finitely 
many primary elements, there is a descending chain a > al > ... of 
infinite length. So we have the following theorem. 
In a lattice of finite descending length every element can be represented 
as the join of finitely many primary elements (u-irreducible elements). 
The fact that the condition "of finite descending length" is sufficient but 
not necessary is shown by the example of an infinite linearly ordered set. 
Such a factorization is not necessarily unique, as can be seen from the 
nondistributive lattice (d), Figure 2. In the next section we shall see that 
in a distributive lattice the factorization is unique. 
4. Distributive Lattices 
In the preceding section we described the effect of a finiteness condition; 
in the present section and the next one we discuss the effect of certain 
special rules of calculation. 
We have already mentioned the theorem: in a distributive lattice every 
element can be represented in at most one way as the join of finitely many 
primary elements without superfluous elements. 
The phrase "without superfluous elements" is necessary, since, e.g., 
in the lattice of the divisors of 12 we have 
12 = 4 u 3 = 2 u 4 u 3. 
We define: in a representation a = ql U ... U qk the factor qi is said 
to be superfluous if the representation contains a factor qj with qi ~ qj, 
i*-j. 
The proof is exactly analogous to the proof for the uniqueness of the 
factorization of natural numbers into prime factors. In the latter proof 

498 
PART B ARITHMETIC AND ALGEBRA 
an important role was played by the lemma:5 if P is a prime number, 
then P I ab implies P I a or P I b. We here prove the following lemma. 
Lemma 1. If M is a distributive lattice and P is primary, then 
P ~ a u b ~ 
P ~ a v P ~ b. 
Proof. The relation P ~ a u b 
means that P = P n (a u b) = 
(p n a) u (p n b) (by the distributive law). Since P is primary, it follows 
that P = P n a or P = P n b, or in other words p ~ a or p ~ b. 
Successive application of the lemma gives: if p is primary and 
p ~ Xl U X2 U '" 
U Xk , then there exists an Xj with p ~ Xj . 
Now if 
a = PI u ... U Pr = ql U ... U qs 
are two decompositions of a into primary elements without superfluous 
elements, then for every Pi there exists at least one qj with Pi ~ qj and for 
this qj again a Pk with qk ~ Pk' But from Pi ~ qj ~ Pk it follows that 
i = k, since otherwise Pi would be superfluous. Thus Pi = qj . For every 
Pi there exists an equal qj and conversely. 
We now have the following converse. If every element in M can be 
factored into finitely many primary elements without superfluous elements, 
then M is distributive. 
For the proof we make use of an analogue to lemma 1. 
Lemma 2. If every element in M is uniquely decomposable into primary 
elements (up to superfluous elements) and if P is a primary element, then 
P ~ a u b ~ 
P ~ a v P ~ b. 
Proof. If a = ql U .•• U qr , b = 
q~ u .. , u q; are the unique decom-
positions of a and b, then 
a u b = ql U .. , U qr U q~ U ... u q~ 
is the unique decomposition, after cancellation of superfluous elements, 
of a u b. From P ~ a u b it follows that 
P u a u b = a u b = P U ql U ..• u q r U q~ U .,. u q; , 
which fails to be a second decomposition of a u b only if P is superfluous, 
or in other words if P ~ qi or P ~ q; . 
In order to show the distributivity we must prove 
a n (b u c) ~ (a n b) u (a n c). 
5 Fundamental lemma of the theory of divisibility. 1B6, §2.5. 

9 Lattices 
499 
If a n (b u c) = ql u ... U qt , then for each of these elements q we have 
q ~ a A q ~ b u c, 
i.e. 
q ~ a A (q ~ b v q ~ c), 
(q ~ a A q ~ b) v (q ~ a A q ~ c), 
q ~ a n b v q ~ a n c, 
and therefore 
q ~ (a n b) u (a n c). 
Thus distributivity (in lattices of finite descending length) is charac-
teristic for the uniqueness of decomposition into primary elements. 
In complemented lattices it is also characteristic for the uniqueness of 
the complement. 
Theorem. 
In a distributive lattice every element has at most one 
complement. 
We prove somewhat more, namely: 
From a u u = a u v and a n u = a n v it follows that u = v. 
Proof. 
u = (a u u) n u = (a u v) n u = (a n u) u (v n u) 
= (a n v) u (u n v) = (a u u) n v = (a u v) n v ~ v. 
What we have proved here can be expressed somewhat differently if 
we introduce a new concept, as follows. 
It is easy to prove that if a ~ b, then the elements x with a ~ x ~ b 
form a sublattice, which is called the closed interval bla (to be read: 
b over a). An element x' with x u x' = b, x n x' = a is called the relative 
complement of x in bla. A lattice is said to be relatively complemented 
if every interval is complemented. 
We have proved: in a distributive lattice every interval contains at most 
one relative complement for a given element. 
Conversely: if in a relatively complemented lattice M every relative 
complement is uniquely determined, then M is distributive. 
The last result follows from the fact that every nondistributive lattice 
contains a sublattice of type (d) or (m) (see §5). We shall not give the 
proof here. 
We have now made the first approach to a question of fundamental 
importance, namely the representation of a lattice as a set-lattice. In many 
applications the elements of a given lattice V are subsets of a set e: V ~ Pe. 
Often the order in V coincides with inclusion in Pe, so that V is a subband 
of Pe. It is natural to ask: when is Va sublattice of Pe? A sublattice of 
Pe is called a set-lattice because in this case the meet is the intersection-set 
and the join is the union-set. For an arbitrary lattice V, whose elements 

500 
PART B ARITHME.TIC AND ALGE.BRA 
are not assumed in advance to be subsets of a set e, the question at issue 
can be stated precisely as follows: what conditions must V satisfy in order 
that there may exist a set e such that V is isomorphic to a sublattice of Pe? 
"Isomorphic" here means: there exists an invertible (i.e., one-to-one) 
mapping cp of V onto a subset cp V of Pe which satisfies the homomorphism 
conditions: 
(HI) cp(a n b) = cpa (') cpb, 
(H2) 
cp(a u b) = cpa u cpb. 
A necessary condition can be stated at once: every sublattice of Pe is 
distributive, since the distributive law holds for all elements of Pe and 
thus also for the elements that form part of a subset of Pe (cf. IBIO, §2.3). 
Consequently, V must be distributive. This necessary condition is also 
sufficient, although the proof requires methods that we do not develop 
here. 6 However, our present methods enable us to prove the theorem 
in the special case that V is of finite descending length, so that every 
element is uniquely decomposable into primary elements. 
As the desired set e it is natural to consider the set of primary elements 
of V, which we denote by Q. It is also natural to assign to every element 
a of V the set cpa of primary elements P ~ a: 
P E cpa ~ 
P E Q A P ~ a. 
The set cpa is not empty, since a is decomposable into primary elements. 
The proof of (H 1) is very simple: 
P E cp(a n b) ~ 
P ~ a n b ~ 
P ~ a A p ~ b, 
i.e., p E cpa ApE cpb. 
For the proof of (H2) we require lemma 1: 
P E cp(a u b) ~ p ~ a u b ~ p ~ a v p ~ b, 
i.e., p E cpa v p E cpb. 
(by lemma 1) 
In the opposite direction we have at once the following result: 
P E cpa u cpb ~ p ~ a v p ~ b ~ p ~ a u b, 
i.e., p E cp(a u b). 
Thus the set of images cp V forms a sublattice of PQ. We assert that 
the mapping of V onto cp V is one-to-one and is thus an isomorphism, 
and in fact we obtain the inverse mapping by assigning to cpa the element 
U2IEqla P. We must then prove: 
Up = a. 
rpa 
a) For all p E cpa we have p ~ a, so that UqlaP ~ a. 
6 Hermes [1]. page 106 ff. 

9 Lattices 
501 
b) The element a can be represented as the join of primary elements: 
k 
a = PI U ••• U Pk = U pl(. 
IC-l 
Here every PIC ::::; a, so that PIC E cpa, and therefore a = U~=1 PIC ::::; Uqla p. 
The assertion then follows from a) and b). 
Thus V has been mapped isomorphically onto a sublattice of PQ. 
Consequently we have the theorem: every distributive lattice of finite 
descending length is isomorphic to a set-lattice: or as we may also say, 
can be represented as a set-lattice. 
In a certain sense we have thus made a survey of all possible distributive 
lattices of finite descending length. 
From the above theorem we have: every distributive lattice of finite 
descending length is isomorphic to a sub lattice of a Boolean lattice, or in 
other words: can be imbedded in a Boolean lattice. 
5. Modular Lattices 
5.1. 
In the lattice Le of linear subspaces of the (three-dimensional) 
projective space the distributive law does not hold; for example, 
a n (b U c) > (a n b) U (a n c), if a is a plane and b, c are two points 
not on the plane. But if c lies in the plane a, then a n (b u c) = c, 
(a n b) u (a n c) = n u c = c. Thus in this case the distributive law is 
satisfied under the additional assumption c ::::; a. The law in this weakened 
form 
(10) c::::; a ~ a n (b u c) = (a n b) u c 
(note that a n c = c) 
is called the modular identity, and a lattice whose elements satisfy the 
modular identity is said to be a modular lattice. 
The modular identity is self-dual, which means that if n is exchanged 
with u and ::::; with ~ the result is the same as before 
(with interchange of the letters a and c, which is of 
no importance). 
The modular identity does not hold in every lattice, 
C1 
as is seen from the example (m), Figure 6. 
b 
However, in every lattice we do have the inequality 
(10') 
c ::::; a ~ a n (b u c) ~ (a n b) u c, 
II. 
so that for the proof of (10) we need only show that 
Fig. 6. (fit) 
(10") 
c ~ a ~ a n (b u c) ::::; (a n b) u c. 

502 
PART B ARITHME.TIC AND ALGE.BRA 
5.2. 
An important class of modular lattices is characterized by the 
following theorem. 
Theorem. 
The normal subgroups of a group form a modular lattice 
with the ordering ~: "subgroup of" 
For the proof we must determine the meaning of a n b and a u b in 
this case. 
If a, b are normal subgroups of e, then a (\ b is also a normal subgroup 
of e and is thus the largest subgroup of e contained in a and b; or in other 
words: 
an b = a (\ b. 
As for a u b, which is the smallest normal subgroup of e that contains 
a and b, it consists exactly of those elements g of e that can be represented 
in the form 
g = ex{3, 
ex E a, 
(see Part B, Chapter 2, §6.4). 
For the proof of the theorem we must now prove (10
1t
), or in other words 
c ~ a -+ [g E a n (b u c) -+ g E (a n b) u c]. 
But g E a n (b u c) means that there exist ex E a, {3 E b, y E c such that 
g = ex = {3y. 
Since c ~ a, we have yEa, so that {3 = exy-l E a, or in other words 
{3 E a n b. Thus g is represented' as the product of an element {3 E a n b 
and an element y E C, so that g E (a n b) u c. 
A commutative group is also caned a module. By the above theorem the 
lattice of submodules of a module is a modular lattice, which explains the 
choice of the word "modular". 
Club 
b 
Fig. 7 
5.3. 
The example of the nonmodular lattice (m) 
is characteristic in the following sense. 
Theorem. 
Every nonmodular lattice contains 
a sublattice (m). 
Proof. If M is nonmodular, it follows from 
(10') that M contains at least three elements 
a, b, c with c ~ a and (a n b) u c < an (b u c). 
Thus M also contains the following necessarily 
distinct elements: a n b, a u b, c n b, cub, 
an (b u c), (a n b) u c. Their order relations are 
represented in Figure 7. This order diagram 

9 Lattices 
503 
provides us with a sublattice T of type (m), so that it only remains to 
prove that if two elements of Twere equal, we would have a n (b u c) ~ 
(a n b) u c. From symmetry we need consider only the following cases: 
a) a n (b u c) = b u c. Then it follows that 
a n (b u c) n b = (b u c) n b, 
and thus by the absorption law 
an b = b, 
(a n b) u c = b u c = a n (b u c). 
b) b u c = b. Then it follows that 1. a n (b u c) = a n b; 
2. c ~ b; 
and from c ~ a, we have c ~ a n b and therefore (a n b) u c = a n b. 
c) a n (b u c) = b. Then it follows that 
(a n b) u c = [a n (a n (b u c)] u c = [a n (b u c)] u c ~ a n (b u c). 
5.4. 
By §S.3 a modular lattice is characterized by the fact that it con-
tains no sublattice of type (m). This fact can be interpreted in the following 
way. If in a modular lattice two elements a, b have an upper neighbor in 
common (which is then of course a u b), they also have a lower neighbor 
in common (a n b). 
Proof. If c is an element between a u b and a: a n b ~ c ~ a, then 
we assert that c = a n b or c = a. 
We form cub. From the definition of u and c ~ a it follows that 
b ~ cub ~ a u b, so that, since a u b is an upper neighbor of b, 
we have only the two possibilities: first cub = b; 
then c ~ b, and since also c ~ a, therefore c ~ an b; 
and on the other hand, we had a n b ~ c, so that 
c ::::: a n b; second cub = a u b; then it follows 
from (10), under the additional assumption a n b ~ c, 
that a n (b u c) = (a n b) u c = c, so that 
c = a n (a u b) = a. 
Definition. A lattice in which every two elements 
that have a common upper neighbor also have a 
common lower neighbor is said to be semimodular 
below. The concept of semimodular above is defined dually. 
Fig. 8 
Every modular lattice is semimodular below and above. Figure 4 
(page 492) shows a lattice that is semimodular below but not above, 
so that it is not modular. If we omit the twice-circled points we obtain 
a sublattice (m). If a lattice is semimodular below and above, we cannot 
at once conclude that it is also modular. For example, it may happen 
that no element has a neighbor, in which case the lattice is to be considered 

504 
PART B ARITHME.TIC AND ALGE.BRA 
as semimodular, although trivially so. The additional condition "of finite 
length" is sufficient, but we do not give the proof here. 
5.5. 
The theorem on semimodularity can be extended to larger 
complexes of elements by the chain theorem of Dedekind, as follows. 
Definition. A proper chain between a and b 
a = Xo < Xl < ... < Xl = b 
is called a maximal chain if it cannot be properly refined, i.e., if 
Xi :::::; Y :::::; Xi+! implies either Y = Xi or Y = Xi+! • 
The chain theorem states: if in a lattice that is semimodular either above 
or below there exists a maximal chain of length I joining a and b, then every 
maximal chain between a and b is of length I. 
We give here an outline of the proof (see Figure 9). Let 
a = Xo < Xl < ... < Xl = b 
and 
a = Yo < YI < ... < Ym = b 
be two maximal chains between a and b. The assertion is that m = I. 
b 
11"'2 
I 
,!Jm'2 
, 
I 
I 
I 
I 
I 
I 
I 
I 
I 
I 
I 
I 
' 
I 
I 
I 
~ 
I 
,J 
" 
I 
, 
, 
I 
,,' 
''cY' 
a 
Fig. 9 
For I = 1 this assertion is correct, and 
also for I = 2 on account of the semimodu-
larity. We now argue by complete induction. 
If Xl-I = Ym-l , the proof is clear. Otherwise 
the two elements have the common upper 
neighbor b, and thus, if we assume semi-
modularity below, they have the common 
lower neighbor Zl-2 (which may coincide 
with Xl-2 or with Yl-2, or with both of 
them). In any case the maximal chain 
a < ... < Xl-2 < Xl-I is of length I -
I, 
so that by the induction hypothesis the 
maximal chain a < ... < Zl-2 < Xl-I is of 
the same length, and thus a < ... < Zl-2 is 
of length I -
2. But then 
a < ... < Zl-2 < Ym-l, and therefore a < ... < Ym-2 < Ym-] , 
is also of length I -
I. 
The chain theorem stands in close analogy with the Jordan-HOlder 
theorem (IB2, §12), but for the latter theorem we have the peculiar 
difficulty that it is based on the relation "normal subgroup of," which 
is not transitive and thus is not an ordering. For details we refer again to 
Hermes [11. 

9 Lattices 
505 
5.6. 
For lattices of finite length the chain theorem allows us to 
introduce the concept of dimension: to every element a we may assign 
as its dimension Sa the length of a maximal chain from n to a. (The 
reader will see that there must exist at least one such maximal chain.) 
In the lattice Le the geometric dimension is given by Sa -
1. In arguments 
involving this concept an important role is played by the following 
dimensional equation 
S (a u b) + S (a n b) = Sa + Sb, 
which is a consequence of the isomorphism theorem: in a modular lattice 
the interval a u bja is isomorphic to the interval bja n b. 
Let us give the main part of the proof of this theorem. 
To every element x in a u bja the mapping cp with cpx = x n b assigns 
an element in bja n b, since a ~ x ~ a u b implies 
a n b ~ x n b ~ (a u b) n b = b. 
This mapping is one-to-one. Every element y in bja n b is the image of 
exactly one element in a u bja, namely y u a. So we now prove the 
following three statements: 
1) a .~ y u a ~ a u b; 
the first part is clear, and the second follows from y ~ b. 
2) cp(y u a) = y; 
by the modular identity, we have cp(y u a) = (y u a) n b = y u (a n b), 
which is equal to y, since a n b ~ y. 
3) If x, z are elements of a u bja and if cpx = cpz, then x = z; 
but from x n b = z n b it follows that (x n b) u a = (z n b) u a, so that 
by the modular identity we have x n (b u a) = z n (b u a), and thus 
x = z, since both are ~ b u a. 
The remainder of the proof of the isomorphism theorem is left to the 
reader, as well as the proof of the dimensional equation, which is now 
easy. 
By means of the isomorphism theorem it can also be shown that two 
finite chains between the same elements have isomorphic refinements. 
It must be emphasized that a rigorous proof of the theorems in §§5.5 
and 5.6, for which we have only given outlines, depends upon a con-
siderable number of details left unmentioned here. 
6. Projective Geometry 
In a k-dimensional projective space e the lattice Le of the linear sub-
spaces is modular, complemented, and of finite length; in fact, the length 

506 
PART B ARITHME.TIC AND ALGE.BRA 
of the chains is even bounded, namely, ~ k + 1. Thus Le is also atomic. 
The atoms are the points. 
Z 
Conversely, let M be a modular complemented lattice of finite length 
which is not empty and does not consist of the zero element n alone. 
We assert that it can be interpreted as the lattice of the linear subspaces 
of a projective space. 
Since M is of finite length, there exist upper neighbors of zero, which 
we shall call points. Then it is possible that M consists of n and one point p. 
But if M contains other elements (at least one), we assert that there exist 
at least two points. For p must have at least one complement p'. From p' 
there is a maximal chain leading to n; this chain contains a point q, and 
if we had q = p, it would follow that p n p' = p -=I=- n. 
Two distinct points p, q have n as common lower neighbor, and thus 
they have a commo~ upper neighbor g = p u q. Consequently there 
exist elements (at least one) of dimension 2; we call them lines. Through 
two points there passes at least one line. 
a 
Fig. 10 
Let h be a second line through p, q 
(p ~ h, q ~ h). Then from the definition 
of u it follows that g ~ h. But 8g = 8h, 
so that g = h. Thus we have 
(PI) Through two points there passes 
exactly one line. 
We further assert: 
(P2) If a, b, c, d are distinct points and 
if the lines a u band cud have exactly 
one point (s) in common, then the lines 
a u c and bud have a point (t) in common 
(Figure 10). 
For the proof we use the dimensional equation: 
8«a u C) n (b u d) = 8(a u C) + 8(b u d) -
8(a u cub u d) 
4 
-
8(a u cub u d). 
On the other hand, 
8(a u b u cud) = 8(a u b) + 8(c u d) -
8«a u b) n (c u d) 
4 
-
I = 3, 
since we have assumed the existence of a point of intersection of a u b 
and cud. Thus 8«a u c) n (b u d» = 1, as was to be proved. 
If the four points are not all distinct, the theorem must be formulated 
somewhat differently, as follows: if the five points a, b, c, d, s have the 
property that a, b, s are collinear (Le., lie on one line) and c, d, s are also 

9 Lattices 
507 
collinear, then there exists a point t for which a, c, t are collinear and 
also b, d, t. In the proof it is necessary to discuss the various cases. 
Finally we show: 
(P3) On a line g there lie at least two distinct points. 
In the first place there certainly exists at least one point p on g. A second 
point is provided by a complement p' of p. Naturally we will expect that 
p' n g = q is a second point on g. We have q ~ g. Furthermore, 
p u q = p u (p' n g) 
is equal, by the modular identity, to 
g n (p u p') = g. 
Thus q -=I=- nand q -=I=- p, since g -=I=- p; and also q -=I=- g, since otherwise 
we would have p ~ q ~ p'. Consequently, q is a point ong distinct fromp. 
In geometry we usually require a sharpening of (P3) which is not a 
consequence of (PIHP3), namely: on every line there lie at least three 
distinct points. In lattice-theoretic language this axiom corresponds to 
the property that the lattice M cannot be represented as a direct product. 
In this way statements about modular complemented lattices of finite 
length are translated into incidence axioms of projective geometry. 
Further details of the lattice-theoretic interpretation of geometry, including 
geometries of infinite dimension, cannot be given here. 
Let us close with a remark about the significance of lattice theory. 
It is the task of the theory to formulate and prove general statements 
in the generality appropriate to them, without any unnecessary special 
assumptions. Thus the chain theorem does not depend on whether we 
are dealing with normal subgroups of a group, with the factors of a number 
or with other objects; it depends only on the existence of an ordering 
and of nand u, and on the modular identity and the concept of finite 
length. 

CHAPTER 10 
Some Basic Concepts for a Theory of Structure 
Introduction 
1. The theory of lattices, as described in the preceding chapter, is 
one of the technical means at our disposal for giving the full appropriate 
generality to statements of general import in mathematics. But if we 
wish to approach this problem systematically, we must first construct 
and investigate the necessary general concepts. We must not base our 
study on any special branch of mathematics, even though well-known 
mathematical facts will serve as guidelines for the construction of concepts; 
however, it will be necessary to make use of logic, and in fact the theory 
of structure is exactly the place where the importance of mathematical 
logic for mathematics as a whole is most clearly seen. 
2. Let us begin with the example of a group, i.e., of a set in which 
there is defined an operation (or composition, as we shall call it in the 
more general setting below) satisfying certain rules, known as the axioms 
of the group. Here the particular concrete group is defined by its actual 
elements, together with the operation. In this sense we speak of a con-
figuration (or mathematical system; in German, Gebi/de). But abstractly 
considered, it is characterized as a group by the existence of an operation 
and by the axioms, a characterization which has nothing whatever to do 
with the special set of elements defining the concrete group. In this sense 
we speak of structure. We now wish to describe these concepts in the 
greatest possible generality. Our discussion will be based on the work 
ofP. Lorenzen [1]. 
508 

10 Some Basic Concepts for a Theory of Structure 
509 
1. Configurations 
1.1. 
Definition 
A set M for whose elements (denoted by lower-case italic letters) there 
is defined a finite sequence P of relations R I , ... , Rn (upper-case italic 
letters, with or without indices) is called a configuration (M, P). 
Note. This terminology has nothing to do with the concept of an "analytic 
configuration" in the theory of functions of a complex variable. 
Examples. A set of points with the three-place relation: "the points 
x, y, z are collinear." The set of natural numbers with the two-place 
relation: "x is smaller than y." The same set with the three-place relation: 
"z is the sum of x and y." 
One may ask how a relation can be "given" in a concrete case. Here are 
two examples. 
1) In a finite set a multiplication, for instance, can be 
defined by setting down the product of any two elements in a table; 
and similarly, for any two-place relation in a finite set we can write down 
the pairs of elements for which the relation holds and the pairs for which 
it does not hold. 
2) For the natural numbers addition and multiplication, 
for instance, are defined recursively (see IBI, §I, and lA, §IO). 
1.2. The following kinds of relation are of particular importance: 
1) Correspondences between elements of two sets NI , N2 : 
R(XI , x2) cannot hold unless Xl E NI , X2 E N2 • 
In the sense of our definition we must take M J NI U N2 if we are to 
interpret the whole system as a configuration, which is not always desirable. 
The correspondence is called a mapping (also a function; see lA, §8.4) if 
it is unique with respect to the second element, i.e., if 
(U) 
In general we speak of a mapping from NI into N2 • If every element of 
NI has an image, we speak of a mapping of NI , and if every element of 
N2 is the image of an element of NI , we speak of a mapping onto N2 • 
In the present chapter we shall usually' denote mappings ·by lower-case 
Greek letters, and the existence of a correspondence cp between Xl and X2 
will then be written in the form CPXl = X2 (cf. also lA, §8.4). 
We note that by definition a mapping is always one-valued, so that 
there will be no need to mention this fact from now on. Thus for a mapping 
rp we always have 
AeAfI(X = y -+ fPX = fPy)· 

510 
PART B ARITHME.TIC AND ALGE.BRA 
Of course, it can happen that cpx = cpy and x -=I=- y. If this situation does 
not occur, i.e., if 
we see that the passage from cpx to x is also a mapping. As the inverse 
mapping of cp we denote it by cp-l and say that in this case cp is invertible, 
or one-to-one. 
2) An (n + I)-place relation is called an n-place inner composition 
(German Verknupfung, French composition) if for every n-tuple Xl , ... , Xn 
of elements in M there exists exactly one element z in M for which 
R(XI , ... , Xn , z) holds, i.e., if 
(E) 
(U) 
In other words: a composition is a mapping of M X M X .,. X M = Mn 
into M. Thus we may write z = P(XI , ... , xn) instead of R(XI , ... , Xn , z). 
For example, addition and multiplication are two-place compositions. 
As a general symbol for a two-place inner composition it is customary 
to adopt the Bourbaki symbol T, and to' write this symbol between the 
arguments to which it applies: X T Y = z. 
3) According to this definition the formation of the least upper bound, 
or of the greatest lower bound, in a complete lattice is not a composition; 
for instead of the n-tuple Xl , ... , xn we are dealing here with an arbitrary 
subset of M, and the mapping in question is from the power set PM 
into M. But for the purposes of the present chapter we shall include 
mapping of PM into M among the compositions, calling it a nonelementary 
composition (since formation of the power set is not part of elementary 
logic). 
4) Another extension is necessary if we wish to include, for example, 
the S-multipHcation in vector spaces (multiplication of a vector with a 
scalar) (IB3, §1.2). In addition to the set M (the vector space) we now 
have a domain of scalars S (in general we may speak of it as a domain 
of operators 0) and to each pair (w, x), wE 0, X E M there is assigned 
an element z of M. Under the relevant assumptions (E) and (U) a corre-
spondence of this sort is called an outer operation, and for it we use 
the symbol .L: w .L X = z, again following Bourbaki. In place of x we could 
also have an n-tuple or a subset of M. The domain 0 may also coincide 
with M. 
5) Finally, for all these compositions we could allow the set of images 
to be not M but some other set, as is the case, for example, with the tensor 

10 Some Basic Concepts for a Theory of Structure 
511 
product and the outer product of vectors (lB3, §3.3). But in the present 
chapter we shall exclude this generalization of the concept of a com-
position. 
Definition. If all the defining relations of a configuration are composi-
tions, the configuration is called a composition-configuration or an abstract 
algebra (lA, §8.5). 
Configurations of other kinds are, for example, the ordered sets (defined 
by an ordering), and the topological spaces, defined by a relation" U is a 
neighborhood of x" between an element x of X and an element U of a 
subset U of PX (M = Xu U, cf. 1.2, §1); in this case X may, for example, 
be the set of points of a plane, where U is the set of open circular disks. 
It is remarkable that a dual group (IB9, §1) is a composition-configura-
tion, whereas a lattice is not. 
1.3. 
Homomorphism and Isomorphism 
Some of the most usual (algebraic) concepts have to do with configura-
tions, and others with the notion of structure defined below. In particular 
the concepts of homomorphism, isomorphism, and congruence have to do 
with configurations. The first two of these deal with mappings of a con-
figuration (M, P) into another configuration (M', P'). Here it is not 
only the elements of M that are mapped but also the defining relations. 
For the latter it is assumed that every relation R; in P corresponds to 
exactly one relation R; in P' and conversely. We then say that the con-
figurations are homologous. For the most part we shall be interested only 
in the subset of M that actually undergoes a mapping; in other words, 
we usually deal with a mapping of (M, P) into (M', P'). 
A mapping cp of (M, P) into (M', P') is called a homomorphism if for 
every relation 
For a two-place inner composition T this condition means that 
x T y = Z ---+ cpx T' cpy = cpz 
or 
cpx T' cpy = cp(x T y). 
For an outer composition we must take account of the domain of 
operators, which is done in the same way as for the set of relations: 
we assume that there exists a one-to-one correspondence between the 
elements of 0 and those of 0', or we may at once assume that the two 
configurations have the same operator domains. The condition for cp to 
be a homomorphism is, in the simplest case: 
cp(W.L x) = W.L' cpx. 

512 
PART B ARITHME.TIC AND ALGE.BRA 
Definition. If cp is a one-to-one mapping of (M, P) onto (M', P') such 
that its inverse is also a homomorphism, then cp is called an isomorphism. 
This last condition (namely that the inverse 
r 
• 
mapping must also be a homomorphism) does 
<> ! 
e 
not follow, in general, from the other condi-
a 
11. 
b 
:
b',. 
tions, as may be shown by the example of the 
mapping of an ordered set with the order 
diagram I (Figure 1) onto the set with the order 
diagram II. But for compositions the latter 
I. 
Fig. 1 
II. 
condition can be deduced from the others, since 
if we are given elements x', y', there must 
exist x, y with x' = cpx, y' = cpy, and thus we have 
cp-l(X' T y') = cp-l(cpX T cpy) 
= cp-l(cp(X T y) 
= X T Y = cp-1x' T cp-ly'. 
Definition. A homomorphism of Minto M itself is called an endo-
morphism, and an isomorphism of M onto M itself is called an auto-
morphism. 
1.4. 
The Automorphism Group 
Successive application of two automorphisms produces a uniquely 
determined automorphism and is thus a composition. It is easy to see 
that the automorphisms of a configuration form a group under this 
composition, the automorphism group of the configuration. 
Conversely, we have the theorem: For every group G there exists a 
configuration (M, P), and in fact a composition-configuration, whose 
automorphism group is isomorphic to G. 
Birkhoff's proof. 1 
Let the elements of G be denoted by lower-case 
Latin letters. The set M will consist of the elements of G and the pairs 
of elements of G: 
M=GU(GxG). 
Lei the defining relations be: an outer composition with G as operator 
domain, defined by 
Cl.a = C, 
C J. ( a, b) = a, 
10n the structure of abstract algebras. Proc. Cambridge Phil. Soc. 31, 1935, 
pp. 434-454. 

10 Some Basic Concepts for a Theory of Structure 
513 
and an inner composition T, defined by 
(a, b) T (a', b') = b . b'- I, 
a T a' = a T (a', b') = (a', b') T b = I, 
or in words: when T is applied to two pairs of elements, it produces the 
quotient of the two second elements, and otherwise T always produces 1 
(the neutral element of G). 
Assertion. 
The automorphism group of the configuration defined in 
this way is isomorphic to G. For the proof we must put every auto-
morphism cp into one-to-one correspondence with an element of G in 
-such a way that the correspondence is an isomorphism. To this end 
we examine the effect of an automorphism cp on the elements of M. 
I) If c E G, then for every automorphism cp we have: cpc = c. (G is 
elementwise fixed under every automorphism.) 
Proof. 
From C.L a = a it follows that 
cpc = cp(C.L a) = C.L cpa = c, 
if cpa = a' E G; 
= a', 
if cpa = (a',b')EG X G. 
In each case we have cpc E G; since this statement holds for every element 
of G, the second case does not arise. 
2) cp(a, b) = (a', b'), or in words: the image of a pair is again a pair. 
For if we had cp(a, b) = c, then for the inverse mapping we would have 
cp-Ic = (a, b), in contradiction to I). 
More precisely we have: cp(a, b) = (a, b'); i.e., an automorphism leaves 
the first element of a pair unchanged. 
Proof. 
Let cp(a, b) = (a', b'). 
From C.L (a, b) = a and cpa = a it follows that 
a = cpa = cp(C.L (a, b) = C.L cp(a, b) = C.L (a', b') = a'. 
3) By cp(l, I) = (I, c) an element c in G is assigned to each automorphism. 
We must show that conversely the automorphism is uniquely defined 
by c. For this purpose we need only express the b' in cp(a, b) = (a, b') 
in terms of a, b, and c. 
From (a, b) T (I, I) = b it follows that 
b = cpb = cp(a, b) T cp(l, I) = (a, b') T (I, c) = b' . c-1, 
so that b' = bc. 
Up to now we do not know whether any automorphism of our con-
figuration actually exists. We have only shown: if cp is an automorphism, 

514 
PART B ARITHMETIC AND ALGEBRA 
then cp determines an element c E G by the equation cp(1, 1) = (1, c), 
and for arbitrary a, b 
(*) 
cpa = a, 
cp(a, b) = (a, bc). 
But it is easy to verify that: 
1) For every c E G the mapping of M into itself defined by (*) is an 
automorphism. 
2) The correspondence between cp and c is one-to-one. 
3) If the group elements Cl , C2 correspond to two given automorphisms, 
then the group element C1 , C2 corresponds to the automorphism deter-
mined by successive application of the given automorphisms. 
1.5. 
Congruence Relations 
A congruence relation == is an equivalence relation that is consistent 
with the defining relations R of the configuration; that is, for a con-
gruence relation we have 
If R is an inner composition, so that R(XI , ... , Xn , z) can be written in 
the form 
z = P(XI , ... , xn), 
then the condition for consistency can be written: 
and in the case of an outer two-place composition: 
x == y ----+ w .1 X == W.1 y. 
A congruence relation gives rise, as an equivalence relation, to a 
partition into classes. Let the class defined by x be denoted by KX. From 
the set KM of classes we construct a configuration homologous to (M, P) 
by defining 
R(KXl' ... , KXn) ~ R(XI , ... , xn) 
or for compositions p(KXl , ... , KXn) = K(P(XI , ... , xn). 
It is possible to make these definitions only because the right-hand 
sides depend, in view of the condition for consistency, only on the classes 
and not on our choice of representatives; that is, if we choose other 
representatives from the same classes, we obtain the same results. It is 
easy to see that the mapping x into KX is a homomorphism. Thus every 
congruence relation corresponds to a homomorphism. 

10 Some Basic Concepts for a Theory of Structure 
515 
For a composition-configuration we can prove the converse. To every 
homomorphism cp of(M, P) into the configuration (M', P) there corresponds a 
congruence relation, namely, the relation == defined by a == b ~ cpa = cpb. 
For we need only prove that such a relation is reflexive, transitive, and 
symmetric and is consistent with the compositions. As an example, 
we will demonstrate the consistency for the case of a two-place inner 
composition: 
Hypothesis: 
x = x', i.e., 
cpx = cpx'; 
y == y', i.e., 
cpy = cpy'. 
Assertion: 
x T y == x' T y', i.e., 
cp(x T y) = cp(x' T y'). 
Proof: 
cp(x T y) = cpx T cpy = cpx' T cpy' = cp(x' T y'). 
We have seen that to every congruence relation for groups there corre-
sponds a normal subgroup, and for rings an ideal; the corresponding 
question for configurations, namely, whether to every congruence relation 
there corresponds a subconfiguration, is a question of an entirely different 
sort, to be answered affirmatively only for certain very special configura-
tions. 
2. Structure 
2.1. 
Definition 
A set -is made into a configuration by means of defining relations; 
and we then say that the set carries a structure. Our present purpose is 
to give a definition of structure. Certainly this concept must be independent 
of the particular set under consideration, much in the same way as the 
concept of an architectural "style" is independent of any particular 
edifice erected in the given style. The concept of "structure" will refer 
to the properties of the defining relations. 
For example, let us consider a defining relation R which is three-place 
and has the following four properties: 
(1) 
(2) 
A A V R(x, y, z), 
x 
y 
z 
A A A A (R(x, y, z) A R(x, y, z') --+- Z = z'); 
x 
y 
z z' 
so that R is a composition. We write xy = Z for R(x, y, z). 
(3) 
(4) 
A A A «xy) z = x(yz», 
x 
y 
z 
V A (ex = x A V xx = e). 
e x 
R 
(In other words, R defines the concept of a group, cf. IB2, §l.l.) 

516 
PART B ARITHMETIC AND ALGEBRA 
These formulas are constructed from individual variables and the 
relation symbols (of which there is here only one) with the logical particles 
A, V, ----+ and the quantifiers A, v., where the quantifiers are applied only 
to the individual variables, not to the relation symbols, and all the 
individual variables are bound by the quantifiers. These formulas become 
statements when the individual variables are replaced by the elements 
of a set M and the relation symbols by the defining relations of a con-
figuration. Such a system of formulas is called an axiom system. (In this 
choice of terminology there is no reference to the philosophical meaning 
of the word "axiom" or to the question of self-evidence.) 
If the formulas of an axiom system 1: become valid statements when 
a configuration (M, P) is inserted in the way just described, the con-
figuration (M, P) is said to be a model of the axiom system 1:. We say 
that (M, P) has a structure, which is described by 1:. 
If an axiom system 1:' is logically equivalent to an axiom system 1: 
(that is, if 1:' follows from 1: and conversely) we say that 1:' describes 
the same structure as 1:, and thus we define a structure as a class oflogically 
equivalent axiom systems. 
In general, a configuration will carry various structures; for example, 
a configuration of the rational numbers with the compositions of addition 
and multiplication carries the structures of a ring, an integral domain, 
and a field. One might be tempted to try to find a "comprehensive" 
structure, from which would follow all valid statements about this 
configuration. But it is a consequence of the incompleteness theorem of 
G5del (lA, §10.5) that for the configuration of the rational numbers 
there cannot exist an axiom system of this sort that is finite or recursively 
enumerable. 
Another kind of similarity between structures is illustrated by the 
concepts of lattice and dual group (IB9, §1). Here we have two types of 
defining relations, on the one hand the order ~, and on the other the 
compositions n, w. These relations can be defined in terms of each other, 
as follows. 
On the one hand: a ~ b~a n b = a, 
on the other: 
d = a n b ~ d ~ a A d ~ b A 
A,,:«d' ~ a A d' ~ b) ----+ d' ~ d). 
With these definitions the two systems of axioms are seen to be equivalent. 
Every model of either of them is also a model of the other. In the present 
chapter we cannot enter upon a precise general description of this situation. 
Two structures that are similar in this way are said to belong to the same 
structure type. 

10 Some Basic Concepts for a Theory of Structure 
517 
2.2. Subconfigurations 
In our discussion of lattice theory (lB9, §l, II) we at first used the two 
names "dual group" and "lattice" to distinguish the two structures 
defined in different ways, namely, the dual group by the two (dual) 
compositions and the lattice by the order relation, and it is desirable 
to have these two distinct names. Then, as is customary, we have used 
the name "lattice" for the structure type to which both the structures 
belong. 
But now the subsets which under the given compositions form a dual 
group (they are usually called sublattices) are not always the same as 
the subsets (called subbands) that form a lattice (in the sense of the 
structure) with respect to the given order. Thus we must define the concept 
Hsubconfiguration" in terms of the structure and not in terms of the 
structure type. 
Definition. Let (M, P) be a configuration carrying the structure 1:. 
Assume that under the same relations as for M and under outer composi-
tions with the same operator domains a given subset N satisfies the axiom 
system 1:; then (N, P) is said to be a subconfiguration of (M, P) with 
respect to 1:. 
Remarks. 
1) The phrase "with respect to 1:" is omitted if no misunder-
standing can arise. 
2) The conditions (E), (U) that characterize a relation as a composition, 
belong to 1:. If the condition (U) is satisfied in M for a given relation R, 
it is also satisfied in any subset N of lyf. If the condition (E) is satisfied 
in N with respect to R, then N is said to be closed with respect to the 
composition R; e.g., for a two-place inner composition T the subset N 
is closed if a, bEN implies aT bEN. For a composition-configuration 
the closedness of a subset N is a necessary but not sufficient condition 
for N to be a subconfiguration; for example, the integers with addition 
as the composition form a group for which the set of positive integers 
is closed with respect to addition but is not a subgroup. 
3) Every two-place inner composition in a set M can be regarded as 
an outer composition with M as the operator domain, and this may be 
done in two ways, depending on whether we regard the left or the right 
factor as an operator. Corresponding possibilities exist for many-place 
compositions, which we need not discuss here. If we interpret multiplica-
tion in a ring as an outer composition in this sense, then the subconfigura-
tions of this structure are not the subrings but the left and right ideals, 
respectively (cf. IB6, §2.S). 
4) In a group (G, .) the forming of inner automorphisms can be regarded 
as an outer composition with G as operator domain: g.1 X = g-lxg. 

518 
PART B ARITHMETIC AND ALGEBRA 
In this case, and more generally for any set of operators that give rise 
to endomorphisms, we speak of a group with operators. The subcon-
figurations are called admissible subgroups. In the present case these are 
exactly the normal subgroups (I82, §6.1). 
Vector spaces are also groups with operators. Here the group composition 
is addition; the S-multiplication gives rise to endomorph isms (cf. IB3, §1.2); the 
admissible subgroups are the vector subspaces. Since the theorem in IB9, §5.2 
also holds for admissible subgroups of a group with operators, and since in a 
commutative group every subgroup is a normal subgroup, it follows that the 
lattice of vector subs paces of a vector space is modular. 
The importance of the remarks 3) and 4) lies in the fact that they 
illustrate the great generality of the theorem of §2.3 (that the subcon-
figurations ... form a complete lattice). 
In each case where we have used the names "group," "ring," "field" 
the reader should consider whether we have been referring to a structure 
or to a structure type. The answer may be different from case to case, 
and it appears that up to the present no one has given an interpretation 
of the situation that will command universal assent. 
2.3. 
The Lattice of Subconfigurations 
In the set U(G) of subconfigurations of a configuration (G, P) an order 
is defined by inclusion. If the intersection of arbitrarily many subcon-
figurations is again a subconfiguration, it follows from the theorem 
on the least upper bound (IB9, §2.1) that U is a complete lattice. A structure 
which is "bequeathed" by any set of subconfigurations to their meet 
is said to be meet-hereditary, and we then have the following theorem. 
Theorem. 
The subconfigurations of a configuration with meet-hereditary 
structure form a complete lattice. 
We now ask: which structures, or in other words which sets of axioms, 
are meet-hereditary? Here the answer depends on the logical form of 
the axioms. For example, the following are meet-hereditary: 
1) Axioms in which only A-quantifiers occur; for if such an axiom holds 
for G, then it holds for every subset of G. 
Here it must be assumed that the axiom has already been brought 
into the so-called prenex normal form, in which all the quantifiers appear 
in non-negative form at the beginning of the formula and apply throughout 
up to the end of the formula, a situation that can always be attained by 
logical transformations. (Otherwise we could always arrange to have 
only A-quantifiers by replacing V zA(x) with -, Ax -, A(x). 

10 Some 8asic Concepts for a Theory of Structure 
519 
2) Axioms in whose prenex normal form the quantifiers appear in the 
successive order 
(E') 
A V A A (x, y, z), 
x 
y 
z 
A (x, y, z) 
free of quantifiers, 
only if the uniqueness statement 
is valid, i.e., is either an axiom or a consequence of the axioms. 
Thus we are asserting that if Nl ,N2 are subsets of M with Nl (l N2 = D 
and if (E') holds when the domains of the variables are restricted to Nl or to N2 , 
then (E') also holds when the domains of variables are restricted to D, i.e., 
A V A A(x,y, z). 
lI:eD yeO leD 
Proof. If we assume XED, we have 
V 
A A(X,Yl, z) 
and 
YleNl leNl 
If for z we choose an element in D, it follows that 
A(x, Yl , z) 1\ A(x, Y2 , z), 
so that (U') implies Yl = Y2 E Nl (l N2 . 
The proof is also valid if the x, y, z are replaced by systems Xl, ••• , X" ; 
Yl , ... , yq ; tl , ... , tr . 
The proof becomes simpler if z and the corresponding quantifier do not occur. 
For then in place of (E'), (U') we have exactly (E), (U) as on page 510, and thus 
we obtain: closed ness with respect to operations is meet-hereditary. 
If X and the corresponding quantifier do not occur, we must take account 
of the possibility that D is empty, and then the proof runs somewhat differently. 
From (E') and (U') we have: there exists exactly one yin M with the property 
AleM A(y, z). The restriction of (E') to N" 
(i = 1, 2), 
means that 
vyeN AzeN . A(Yi' z). Thus Ni is not empty; consequently there exists a Zi in N, 
with ~(y, ~i) and A(Yi' z,). So by (U') we have Y = Yi for Y = 1,2, and thus 
Y E D, which completes the proof of (E') for D. This result shows, for example, 
that the existence of the neutral element of a group is meet-hereditary. 
Groups, rings, fields, and lattices are examples of meet-hereditary 
structures. So it is natural to ask what properties of a configuration 
correspond to given properties of the lattice of its subconfigurations. 
For the particular case of groups, this question has been the subject of 
many profound investigations, of which M. Suzuki has recently given a 
connected account. 2 
The above theorem admits the following converse: if V is a complete 
lattice, there exists a configuration with meet-hereditary structure whose 
subconfigurations form q lattice isomorphic to V. 
2 Structure of a group and the structure of its lattice of subgroups. Ergebnisse d. 
Math., Neue Folge, Heft to. 1956. 

520 
PART B ARITHMETIC AND ALGEBRA 
Birkhoff's proof.3 ' We take M = V and define an outer composition, 
with V as operator domain, which to an element a of V( = Q) and a 
subset B ~ V assigns an element x E V: 
a.L B = a nUb. 
B 
Since V is a complete lattice, this correspondence is actually a composition, 
i.e., the conditions (E) and (U) are satisfied for the corresponding three-
place relation. We now take 1: to consist of these axioms alone. Then 
the configuration (M,.L) has a meet-hereditary structure, so that its 
subconfigurations form a complete lattice. We assert that this lattice is 
isomorphic to V.' The proof runs as follows. 
The subset N ~ M is a subconfiguration if 
a E V A B ~ N ---+- a nUb E N. 
B 
We consider UN Y = c. Since V is complete, there exists an element c in V. 
In fact, c even belongs to N, since c = c n c = c nUN y, and N ~ N. 
By the definition of the least upper bound, x EN---+- x ~ c; and conversely, 
x ~ c ---+- X E N since 
x = x n c = x n U y. 
N 
Consequently: for every subconfiguration N there exists an element c 
with the property that N consists exactly of the elements x ~ c. This set 
Ac is called the segment of c. 
Conversely, every segment Ac is also a subconfiguration. For if B ~ Ac , 
we have: b E B ---+- b ~ c, so that for every a E V: 
a nUb ~ c, 
B 
i.e., E Ac . 
Obviously there exists a one-to-one correspondence between the 
segments A c and the elements c of V such that 
Ac~Ad~C ~ d. 
It follows that the segments, and consequently also the subconfigurations, 
form a lattice isomorphic to V, so that the proof is complete. 
In the present chapter we have not been able to give more than the 
first steps in a theory of structure. In the theorems on the automorphism 
group and the lattice of subconfigurations we have tried to prove some 
of the first results. They illustrate the importance of the concepts of 
group and lattice. 
l"On the Combinations of Subalgebras," Proc. Cambritlge Phil. Soc. 29, 1933, 
pp.441-464. 

10 Some Basic Concepts for a Theory of Structure 
521 
Let us mention some other questions without attempting to answer 
them here. 
How can other configurations be constructed from a given configura-
tion? For example, how should subconfigurations be constructed; or 
direct products? (On the same question for lattices see IB9, §2.3.) Which 
of the properties of a configuration are preserved in passing to a sub-
configuration or a direct product; or to a homomorphic configuration? 
How can we classify systems of axioms, i.e., structures, on the basis 
of the parts of logic that are employed? For example, Lorenzen distin-
guishes pure-elementary structures (essentially those that we have used 
here, but not including the nonelementary compositions), elementary-
arithmetical, in which arithmetic is used, e.g., in the Archimedean axiom 
for the calculus of line segments "'11>0 "roo V nn . X > y, (n a natural 
number), and further: elementary-logical and non-elementary, which are 
characterized by the fact that the relation symbols occur as variables 
(e.g., in the induction axiom for the Peano system). The last two types 
are distinguished by the linguistic-logical means employed, in a way 
which cannot be described here for lack of space. 
Can it happen that a system of axioms uniquely characterizes a con-
figuration up to isomorphism, such a structure being called monomorphic? 
The answer here is affirmative, as is shown by the example of a vector 
space of given dimension over the field of rational numbers (which is an 
elementary-arithmetical structure); but the most important algebraic 
structures, such as group, ring, field, and lattice, are not monomorphic. 
Here we have tried to give some indication of possible questions in a 
theory of structure. What we have said is perhaps enough to show that 
we are dealing here with new points of view, from which an attempt is 
made to survey the whole of mathematics. 

CHAPTER 11 
Zorn's Lemma and the High Chain Principle 
The present chapter deals with two maximal principles in the theory of 
sets: Zorn's lemma, which has been used very frequently in recent times, since 
it simplifies many former proofs; and the high chain principle (cf. §4), which, 
although trivially equivalent to Zorn's lemma, has the advantage of being 
intuitively plausible. The key position of the high chain principle in this type 
of argument appears to have remained unnoticed up to now. l 
1. 0 rdered Sets 
We first give some definitions and a few of their immediate consequences 
(cf. also IB9, §l; lA, §8.3). 
By an ordered set, or an order, we mean a set M = {a, b, c, ... } together 
with a two-place relation ~ defined on it, with the following properties: 
Reflexivity: 
Identivity: 
Transitivity: 
a ~ afor all a. 
a ~ band b ~ a imply a = b. 
a ~ band b ~ c imply a ~ c. 
An ordered set is said to be totally (or linearly) ordered, or to be a chain, 
if it has the following additional property: 
Comparability, or connexity: for any two elements a, b we have 
a~b 
or 
b ~ a. 
The terminology varies in the literature. It is also common to refer to our 
ordered set as a "partially ordered set," and to restrict the term "ordered set" 
1 For other set-theoretic maximal principles and their equivalence to the axiom of 
choice see §4, exercise 12, and, for example [12], [1], [6], in the bibliography at the end 
of the chapter. 
522 

11 
Zorn's Lemma and the High Chain Principle 
523 
to chains. Moreover, a distinction is often made between an ordered set and 
an order, the latter term being used to refer only to the relation defined on an 
ordered set. 
Examples of orders are given by the "set-orders": if S is an arbitrary 
system of subsets of a set A, then S becomes an ordered set under the 
relation of inclusion (~). This class of examples already includes, up to 
isomorphism, all possible orders: every order M is isomorphic to a 
set-order. For if a E M and we let g be the set of elements x EM with 
x ~ a, then the mapping a ~ g is an isomorphism of M onto a set-order. 
In an ordered set we write a ~ b to mean "a ~ b with a'* b," and 
a ~ b or a > b to mean b ~ a or b < a, respectively. 
Let T be a subset of an ordered set M. Then T itself is an ordered set 
under the same relation ~. In particular, a subset of a chain is also a 
chain. The statement "x ~ a (or x < a) for all x E T" is abbreviated 
to T ~ a (or T < a). We now make the following definitions: 
To say that s is an upper bound of T means that T ~ s. 
If here s ¢ T (i.e., T < s), then s is a proper upper bound of T. 
To say that g is a greatest element of T means that gET and T ~ g 
(Le., g is an upper bound of T contained in n. Thus an upper bound of 
T is either a proper upper bound of T or a greatest element of T. 
To say that m is a maximal element of T means that mET and that there 
exists no x E T with x > m. 
A subset T need not necessarily have an upper bound or a greatest 
element or a maximal element. But obviously T can have at most one 
greatest element, though it may have several maximal elements, and 
also, of course, several upper bounds. A greatest element is always a 
maximal element, but the converse is in general false, although the two 
concepts coincide if T is a chain. 
The concepts lower bound, least element, minimal element of Tare 
defined dually (i.e., with ~ in place of ~). 
Exercises 
1. Every finite ordered set has at least one maximal element. 
2. (a) If M is an ordered set in which every two elements have an upper 
bound, then every maximal element of M is also a greatest element 
of M. 
(b) If M is finite, the converse of (a) also holds (cf. ex. I), 
3. If a < b and there exists no X with a < X < b, then a is called a lower 
neighbor of b, and b is an upper neighbor of a. Does there exist a chain 
in which every element has an upper neighbor but infinitely many 
elements have no lower neighbor? 

524 
PART B ARITHMETIC AND ALGEBRA 
4. Prove that in every infinite chain in which every nonempty subset has 
a smallest element there exists "an ascending sequence, i.e. a sequence 
a1 , a2 , as ... with a1 < a2 < as .... 
5. An ordered set in which every nonempty subset has a least and a 
greatest element must be a finite chain (and conversely). 
6. In every ordered set M the following statements are equivalent: 
I. Every nonempty subset of M has at least one maximal element. 
II. Every nonempty chain has a greatest element. 
III. ("Ascending chain condition.") There exists no ascending 
sequence, i.e. for every a1 ~ a2 ~ as ~ ... there exists an n with 
An = An+1 = An+2 = .... 
III'. Every "finite-below" chain is also "finite-above;" i.e., if for every 
element a in a given chain there are only finitely many elements 
below a, then for every element b in the chain there are only 
finitely many elements above b. 
III". Every finite-below chain is finite. 
(;, 
7. Construct (e.g. by drawing their "order diagrams" as in the chapter on 
lattices) all the ordered sets with fewer than five elements. (There are 
exactly 25 such sets, apart from isomorphism; five with 3 elements, 
and sixteen with 4.) 
8. Let a set M = {a, b, c, ... } be said to be ordered if there is given on M 
a two-place relation < with the two properties: 
lrreflexivity: a < a for all a. 
Transitivity: a < band b < c imply a < c. 
Prove that this definition of order is equivalent to the one given above, 
in the following sense: if a given relation < is reflexive, identive and 
transitive, then the relation <, defined by a < b if a < b and a = b, 
is irreflexive and transitive, and conversely, if a given relation < is 
irreflexive and transitive, then the relation ~, defined by a ~ b if 
a < b or a = b, is reflexive, identive and transitive. 
2. Zorn's Lemma 
After these preliminary remarks we now formulate Zorn's lemma. 2 
Z. 
An ordered set in which every chain has an upper bound contains a 
maximal element. 
The role of Zorn's lemma may be described as follows: in arguments 
involving infinite sets, the older proofs often made use of the well-ordering 
2 The name Kuratowski's lemma would be more correct (cr. [8] 1922, statement (42). 
[21] 1935. 

11 
Zorn's Lemma and the High Chain Principle 
525 
theorem and transfinite induction (for these concepts see lA, §7.4, appendix 
to IB I, §§2, 3, 5 and for example, [6], [12], [16]). In general, the well-
ordering used in the proof has nothing to do with the underlying structure 
of the set or with the theorem to be proved; the well-ordering theorem 
merely provides a proof that the set in question admits at least one well-
ordering, the particular nature of which is unknown and irrelevant, 
and this well-ordering is made the basis of a transfinite induction. But 
in spite of its correctness such a procedure is usually f~lt to be unsatis-
factory. In many cases Zorn's lemma allows us to avoid these unsatis-
factory arguments and to replace them by a more natural method of proof; 
for the most part, the proofs become much clearer and shorter. 
Some examples of proofs by Zorn's lemma will be given in the next 
section. The proof of the lemma itself is given in §4. 
In most applications Zorn's lemma is used in the following special form, 
which refers to set-orders and makes a sharper assumption on the upper 
bound: 
Z'. Let S be a nonempty system3 of subsets of a set A which with every 
nonempty chain contains its union. Then S contains a maximal element 
(i.e., a subset of A that is maximal in S). 
It is to be noted that in Z (and thus also in Z') the assertion can be 
sharpened: 
Sharpened form of Z or of Z': under the same assumptions as in Z or 
Z', for every element there exists a maximal element over it. 
For let M be an ordered set satisfying the assumptions of Z, let a EM 
and let N be the subset of x E M with x ~ a. Then it is obvious that 
N is also an ordered set satisfying the assumptions of Z and the assertion 
follows by the application of Z to N. 
3. 
Examples of the Application of Zorn's Lemma 
We shall now prove three algebraic theorems by means of Zorn's lemma. 
Further examples of proofs based on Zorn's lemma are easy to find in 
the recent literature on topics in algebra or topology. 
Theorem I. In a commutative ring R with unit element every ideal 
distinct from R is contained in a maximal ideal. 4 
An ideal M in R is said to be maximal if M -=I=- R and there is no other 
ideal between M and R (in other words, if M is a maximal element in 
the set-order of the ideals -=1= R). 
I The word "system" will be used as a synonym of "set." 
40 For the definitions of "ring" and "ideal of a ring" see IB5, §1.2, §3.l. 

526 
PART B ARITHMETIC AND ALGEBRA 
Proof of theorem I. 
Let 10 be an ideal in the given ring R with 
10 -=I=- R. Let S be the set of ideals I with I J 10 , I -=I=- R. 
We show that S satisfies the assumptions of Zf (with A = R). The 
assertion then follows by application of Zf to S. 
Since 10 E S we see that S is nonempty. Let K be a nonempty chain in S 
and let V be the union of K (i.e., the set-theoretic union of all the ideals 
in K). Then we must show that V E S; that is to say, 
a) 
V is an ideal in R, 
b) 
VJ 10 , 
c) 
V-=I=- R. 
As for a): arguments similar to the proof about to be given for a) occur 
everywhere in the applications of Zorn's lemma; we give such an argument 
in detail here once for all: if a, bE V and if r E R, then there exist I, If E K 
with a E I, b E If, and since K is a chain, we have I ~ If or If ~ 1. Without 
loss of generality we may assume If ~ 1. Then a, b E I, and therefore 
a -
b, ra E I (since I is an ideal) and thus also E V, so that V is an ideal. 
As for b): since K is nonempty, there exists a IE K, and for this I we 
have 10 ~ I ~ V, from which it follows that V J 10 . 
As for c): for the ideals I of a ring R with unit element it is clear that 
I = R if and only if lEI. 
From V = R it would follow that I E V, so that there would exist a 
IE K with I E I and then for this I we would have IE S and I = R, 
in contradiction to the definition of S. 
Remark on theorem l. For a not necessarily commutative ring R 
with unit element it is obvious that the corresponding statements for 
left ideals, right ideals, and two-sided ideals can be proved in exactly 
the same way. 
Theorem 2. 
Every vector space has a basis. 
More precisely, we show that every (not necessarily finite-dimensional) 
vector space V over a skew field K has a basis.5 
A (not necessarily finite) subset T of V (more precisely, an indexed 
subset) is said to be linearly independent if each of its finite subsets is linearly 
independent (in the usual sense). The set T is called a generating system 
for V if T is not contained in any proper subspace of V. By a basis of 
V we mean a linearly independent generating system of V. 
Proof of Theorem 2. 
We may assume that V does not consist of the 
zero vector alone (otherwise the empty set is a basis of V). Let S be the 
r; For the definitions of "skew field," "vector space," "subspace (vector subspace)" 
and "linearly independent (for finite sets of vectors)" see IB3, §1.1-1.4. 

11 
Zorn's Lemma and the High Chain Principle 
527 
aggregate of all linearly independent subsets of V. Then S obviously 
satisfies the assumptions of Z', with A = V (cf. the remarks under a) 
in the proof of theorem I), so that by Z' there exists a maximal linearly 
independent subset of V6. Thus it only remains to show: 
Every maximal linearly independent subset B of V is a generating 
system of V (and thus also a basis of V). 
If we assume that there exists a subspace T of V with T -=I=- V and 
B k T, then T -=I=- V would mean that there exists a vector n E V with 
nET. Let B' = B u {n}. Then it is easy to see that B' would also be 
linearly independent, so that B would not be a maximal linearly inde-
pendent subset. 
Theorem 3 (Theorem of Artin-Schreier). 
Every formally real field can 
be ordered (is orderable).7 
By a domain of positivity of a field K we mean a subset P of K with 
the following properties (here - P denotes the set of all -x with x E P): 
I) 
a, bE P imply a + b, ab E P, 
2) 0 i P, 
3) 
- P u {O} u P = K. 
Not every field has a domain of positivity; for example, a field of 
characteristic -=I=- 0 cannot have one; on the other hand, there exist fields 
that have several. 
A field K with at least one domain of positivity is said to be orderable. 
If one of the domains of positivity in an orderable field is distinguished, 
we speak of an ordered field. More precisely: an orderedfield is a pair K, P 
consisting of a field K and a domain of positivity P in K. 
In an ordered field K, P a relation a < b is defined by b -
a E P. 
For a = 0 it follows from this definition of < that P is the set of elements 
> 0, a fact which explains the name "domain of positivity" for P. 
If in an ordered field K, P we set R = P u {O}, then a, b E R imply 
a + b, ab E R, and we have -R (') R = {O} and -R u R = K; and if 
the relation a ~ b (i.e., a < b or a = b) is defined by b -
a E R, 
then ~ is a total order on K which is compatible with addition and 
multiplication in K (i.e., a ~ b implies a + c ~ b + c for all c and 
implies ac ~ bc for all c with 0 ~ c. These facts enable us to provide 
equivalent definitions of an ordered field, in the following way: 
A field is said to be formally real if -I cannot be represented as the 
8 From the sharpened form of Z' we see that every linearly independent subset of V 
can be extended to a maximal linearly independent subset of V. 
7 For theorem 3 see also IBl, §2.5. §3.4 and IB8, §2.2. 

528 
PART B ARITHMETIC AND ALGEBRA 
sum of squares; or equivalently, if a12 + a22 + '" + an 2 = 0 implies 
a1 = a2 = ... = an = O. 
We note that the converse of theorem 3 is trivial; for in an ordered 
field every square, and consequently every sum of squares, is ~ 0, but 
-1 is < O. Theorem 3 thus gives an "algebraic" characterization (i.e., 
a characterization in terms of the operations + and . alone) of the 
orderable fields: a field is orderable if and only if it is formally real. 
Proof of theorem 3. 
Let K be a formally real field. Let Q be the set 
of all nonzero sums of squares of elements in K. Let S be the set of all 
those subsets T of K that contain Q and have the properties 1), 2). 
It is obviously enough to show: 
a) S satisfies the assumptions of Z', with A = K. 
b) Every maximal element of S has the property 3). 
As for a): since K is formally real, Q is exactly the set of all Lf-1 a,2 
with ai E K, ai * 0, n ~ I. Thus Q E S, so that S is not empty. The fact 
that with every nonempty chain the set S also contains its union is proved 
in the same way as under a) in the proof of theorem I. 
As for b): for TE S let To = {O} u T. Then b) is a consequence of the 
following lemma .. 
Lemma. If TE Sand r ¢ -Tu {O} u T, then T' = T + rTo (the set 
of all a + rbo with a E T, bo E To) is an element of S properly 
containing T. (Thus T is not maximal). 
Proof of the lemma. Obviously T ~ T' (we may choose bo = 0), and 
thus Q ~ T implies Q ~ T'. 
Since 1 E Q ~ T and -r E T (for otherwise r E - T) we have -r * I, 
so that r + 1 * O. Thus 
( 2r)2 
(r - 1)2 
r= r+l +r r+l' 
so that Q ~ T implies rET'. Since r ¢ T, it follows that T' * T, so that 
T C T'. Thus we need only verify the properties 1), 2) for T'. 
1) For any two elements a + rbo , c + rdo E T' it follows from Q ~ To 
and from the additive and multiplicative closedness of T and To that 
(a + rbo) + (c + rdo) = (a + c) + r(bo + do) E T' 
and 
2) 0 E T' would imply 0 = a + rbo with a E T, bo E To; a = -rbo ; 
bo #= 0 (since a * 0), so that bo = b with bET; and thus -r = alb = (llb)1 

11 
Zorn's Lemma and the High Chain Principle 
529 
ab with a, bET; -r E T (since Q ~ T and T is multiplicatively closed); 
consequently r E - T, in contradiction to the assumption of the lemma. 
4. 
Proof of Zorn's Lemma from the Axiom of Choice 
In this section we introduce the high chain principle mentioned in the 
introduction. Zorn's lemma at once turns out to be nothing but a more 
complicated form of the high chain principle. In the rest of this section, a 
simple proof of the high chain principle (and thus of Zorn's lemma) from 
the axiom of choice is given in full detail. 
Let us first give the definition and some trivial properties of the operation 
"roof" (denoted by A), on which this section will depend. 
Let M be an ordered set. Here and below the word "chain" will 
always refer to a subchain of M. The elements of M will be denoted by 
a, b, c, ... , x, y, the subsets of M by A, B, the chains by C, K, L and the 
empty set by 0. 
For every subset A of M let A be the set of all elements x with A < x. 
Thus A is the set of all proper upper bounds of A. 
Obviously A (') A = 
~, and A C B implies ~ CA. 
(1) If A, B are arbitrary subsets of M, at least one of the two sets A (') ~,A (') B 
is empty. 
For otherwise there would exist elements a, b, with a E A, B < a and b E B, 
A < b, which would imply b < a and a < b, in contradiction to the identivity. 
(2) If A, B are subsets of M with A C B u ~ and BC A uA, then A C B 
or BC A. 
For by (1) we have A (') ~ = ~, so that A C B, or A (') B = ~, so that BC A. 
(3) If K is a chain and C C K, then: C = k is equivalent to C (') K = ~. 
Proof. C = k implies C (') K = k (') K = ~. Conversely, from C (') K = ~ 
we have, in succession: for every x E K it is untrue that C < x; for every x E K 
there exists aCE C with c < x untrue, i.e., with x ~ c (since c, x are comparable, 
being elements of the same chain K); C C k; C = k (for C C K always 
implies C :.1 k). 
We say that a chain K is high, and we call it a high chain (with respect 
to M) if K is empty. Thus a high chain is a chain that has no proper 
upper bound, i.e., a chain with no element properly over it, a chain that 
cannot be continued upward. 
Note that a high chain need not be a maximal chain, i.e. maximal in the 
set-order consisting of the chains of M (although, of course, every maximal 
chain is a high chain). For example, if m is a maximal element of M, the chain 
constisting of m alone is a high chain, but in general it will not, of course, be a 
maximal chain. 

530 
PART B ARITHMETIC AND ALGEBRA 
This difference between the concept of high chain and maximal chain marks 
the difference between the high chain principle and the Hausdorff-Birkhoff 
maximal chain principle. 
Let us now formulate the 
High Chain Principle. 
Every Ordered Set Contains a High Chain. 8 
This maximal principle makes no hypothesis about the given ordered set, 
and it has an intuitive acceptability which is independent of any proof -
both in contrast to Zorn's lemma. Nevertheless, it is in fact identical with 
Zorn's lemma, as we shall now see. 
There are two kinds of high chains: high chains without upper bound, 
and high chains with upper bound. The high chains without upper bound 
are precisely the chains without upper bound. The upper' bounds of high 
chains are precisely the greatest elements of high chains, and so precisely 
the maximal elements of M. Thus the high chains with upper bound are 
precisely the chains that contain a maximal element (of M). These remarks 
show at once that: 
Zorn's Lemma and the High Chain Principle are Equivalent. 
For in an arbitrary ordered set Mthe following statements are equivalent 
(the first one being Zorn's lemma and the last one the high chain 
principle): 
If every chain has an upper bound, there exists a maximal element. 
There exists a chain without upper bound or there exists a maximal 
element. 
There exists a high chain without upper bound, or there exists a high 
chain with upper bound. 
There exists a high chain. 
The proof of the high chain principle from the axiom of choice, which 
we now give, is the last step in a gradual development beginning with 
Zermelo's first proof of the well-ordering theorem ([19], 1904). For 
example, Kneser's proof of Zorn's lemma ([7], 1950), and Weston's 
outline of a proof ([17], 1957), which forms the basis of the proof to be 
given here, are steps in this development toward simplicity. 
The proof makes use of the so-called Axiom of Choice (cf. lA, §7.6, 
supplement to IB1, §5): 
8 Of course, the high chain principle can be sharpened to the statement that in an 
ordered set every chain K is an initial segment of a high chain (it is only necessary to 
apply the high chain principle to the ordered set i(). 

11 
Zorn's Lemma and the High Chain Principle 
531 
Axiom of Choice. For every system S of nonempty sets there exists 
a choice function, i.e., a function f which to every set N E S assigns an 
element of N: thusf(N) E N. 
Proof of the high chain principle. Let M be an ordered set. By the 
axiom of choice there exists a choice function defined on the system of 
all nonempty sets C (where C is a chain). Let f be such a function. Then 
C"* 0 impliesf(C) E C. 
The proof depends on the concept of an f-chain. A chain K is called 
an f-chain if it has the following property: 
(*) 
C ~ K and C (\ K"* 0 imply that f(C) is the least element of C (\ K, 
i.e., thatf(C) E C (\ K andf(C) ~ C (\ K. 
In other words: If C is a subchain of K with proper upper bound in K, 
thenf(C) is the least of these proper upper bounds.9 
In view of (3) andf(C) E C the property (*) is equivalent to 
(**) 
C ~ K and C"* K imply thatf(C) E K andf(C) ~ C (\ K. 
The proof consists in deriving two rules for the creation of f-chains 
«i), (ii» and applying them to the set-theoretic union of all f-chains. 
(i) 
Continuation of f-chains: if K is an f-chain with K *- 0, then 
K* = K u f(K) is anf-chain (and, of course, K* (j;, K). 
Proof. 
K < f(K) implies that K* is a chain with greatest element 
f(K), and K* (j;, K. 
Assume that C ~ K* and that C (\ K* is nonempty. Let SEC (\ K*. 
Then it follows successively that C < s ~f(K);f(K)¢ C; C~ K. 
If now C = K, thenf(C) = f(K) and C (\ K* = K (\ K* = f(K). 
On the other hand, if C "* K, it follows from (**) thatf(C) E K (so that 
f(C) < K and thereforef(C) <f(K» andf(C) ~ C (\ K. 
Thus in every casef(C) E K* andf(C) ~ C (\ K*. 
The crucial point in the proof of (ii) is the following lemma. 
Lemma. If K, L are f-chains, then L ~ K uK (and, of course, also 
K~ L uL). 
Proof of lemma. 
For L ~ K there is nothing to prove. Consequently, 
assume L (j;, K and let y be an arbitrary element with y E L, y ¢ K. The 
assertion is that y E K. 
9 The function 1 provides us with a "rule for climbing" that not only allows us to 
climb from a given element to a greater element but also to surmount, with one jump, 
a whole infinite chain; and the l-chains are the "upward paths" created in this way. 
T,!king C =F- ~ we see, in particular, from (*) that every nonempty l-chain begins with 
1(0). 

532 
PART B ARITHMETIC AND ALGEBRA 
Let C be the set of all x with x E L (') K and x ~ y.IO Then C ~ )' and 
(in view of y ¢ K) y ¢ C, so that C < y, i.e., y EC. 
Since C ~ L, y E C (') L we have from (*): f(C) E L andf(C) ~ y. 
Since C ~ K, the hypothesis C' -=I=- f( would (by (**» imply f(C) E K 
and therefore (by the definition of C)f(C) E c. So C = K and thus y E K 
(since y E C). 
From this lemma and (2) we get the comparability off-chains: if K, L 
are f-chains, then K ~ L or L ~ K. 
(ii) 
Union off-chains: the union F of an arbitrary set off-chains is also 
anf-chain. 
Proof. The comparability of f-chains shows that F is a chain. From 
the lemma it follows further that F ~ K u K for every f-chain K. 
Now let C ~ F and C (') F be nonempty. Let x be an arbitrary element 
of C (') F. Then, since x E F, there exists an f-chain K with x E K ~ F, 
and it follows that x E C (') K, so that C (') K -=I=- 0. 
Since C ~ F, and F ~ K u K, we have C ~ K u K. Since C (') K -=I=- 0, 
it follows from (1) that c (') K = 0, so that C ~ K. 
Since K is anf-chain, it follows from C ~ K, C (') K -=I=- 0 thatf(C) E K 
andf(C) ~ C (') K, so thatf(C) EF andf(C) ~ x. 
Now let V be the union of allf-chains. By (ii) we see that Vis anf-chain 
and consequently by (i) that P- = 0, i.e., V is a high chain. For if we had 
P- = 0, then by (i) there would exist an f-chain V* with V* (j;, V, in 
contradiction to the definition of V. 
Remark. Let us denote the axiom of choice by A and the high chain 
principle by H. A trivial application of Z' gives A, so that we have proved 
the implications A ~ H ~ Z ~ Z' ~ A. Thus, the set-theoretic maximal 
principles A, H, Z, Z' are equivalent. 
Exercises 
We first give 3 definitions. 
(i) A subset A of an ordered set M is called an initial segment of M if 
for every x ~ a that xA. 
(ii) ~or every subset S of an ordered set M the corresponding set S of 
lower elements is defined as the set of elements xM for which there 
exists an element sS with x ~ s. 
(iii) An ordered set M is said to be well-ordered if every subset of M has 
a least element. 
1. The relation of being an initial segment is transitive; i.e. every initial 
segment of an initial segment of an initial segment of an ordered set M 
is an initial segment of M. 
10 In fact, C = K. 

11 
Zorn's Lemma and the High Chain Principle 
533 
2. The intersection, and also the union, of an arbitrary number of initial 
segments of an ordered set M is an initial segment of M. 
3. Prove that for every subset S of an ordered set M: 
(a) § is the initial segment of M generated by S; namely, § is an 
initial segment of M that contains S, and § is the intersection of 
all initial segments of M that contain S. 
(b) From (a) it follows that S is an initial segment of M if and only 
ifS= §. 
(c) § is an initial segment A of M with S ~ A and S = A. (Thus, 
in the definition of an f-chain we could take C to be an initial 
segment.) 
(d) § (\ S = cpo 
4. In every subset S of a totally ordered set K we have § u S = K, and 
therefore the following three statements are pairwise equivalent 
(cf. 3(b), (d)): S is an initial segment of K; S = §; SuS = K. 
5. A subset L of a chain K of an ordered set M is an initial segment of K 
if and only if K ~ L u L. 
6. (a) Every well-ordered set is totally ordered. 
(b), For finite sets the converse also holds. 
In exs. 7 to II below, the assumptions are the same as in the proof of the 
high chain principle; i.e., M is an ordered set and f is a choice function 
on the system of all nonempty sets t (where C is a subchain of M). Then 
M has the following properties (7-11): 
7. The intersection of arbitrarily many f-chains is anf-chain. 
8. The set of all f-chains is well-ordered with respect to inclusion. 
9. Every f-chain is well-ordered. 
10. A subset L of an f-chain K is an f-chain if and only if it is an initial 
segment of K (use ex. 5 and the lemma of §4). 
II. The f-chains are precisely the initial segments of the union V of all 
f-chains. 
12. Consider the following statements: 
(a) axiom of choice A 
(b) high chain principle H (cf. §2) 
(c) Zorn lemma Z 
(d) special case Z' of the Zorn lemma (cf. §2) 
(e) weB-ordering theorem W: "every set can be well-ordered" 
(f) Hausdorff-Birkhoff maximal chain principle M: "in every ordered 
set there exists a maximal (with respect to inclusion) chain" 
i.e. a chain which ceases to be a chain if any further element of 
the ordered set is adjoined to it. 

534 
PART B ARITHMETIC AND ALGEBRA 
Prove the following implications: 
A----+H----+Z----+W----+A 
and 
H----+Z----+Z'----+M----+H. 
In other words, the statements A, H,Z,Z', W,M are pairwise equivalent. 
Hints for the proofs. 
For A ----+ Hand H ----+ Z cf. §4. 
The implications Z ----+ Z' and M ----+ H are specializations W ----+ A: 
the union V of the given system S of nonempty sets can, by W, 
be well-ordered; for a fixed well-ordering of V choose the smallest 
element from each set of S. Z' ----+ M: the entire aggregate of chains of 
an ordered set M forms a system S satisfying the assumptions of Z' 
(with A = M). Z ----+ W: for an arbitrary set M let Q be the set of all 
well-ordering relations defined on subsets of M. For WI , W2 E Q let 
WI ~ W2 be defined as follows: the domain of definition TI of WI is 
contained in the domain of definition T2 of W2 , on TI the two relations 
WI and W2 coincide, and TI is an initial segment of T2 with respect 
to W2 • With this relation ~ the set Q is an ordered set in which every 
subchain has an upper bound. Then Z states that Q has a maxi mal 
element. But every maximal element W of Q must be defined on the 
whole of M, since an element of M not contained in the domain of 
definition of W could be "adjoined to W from above," thereby 
producing an w' > w. 
13. In the proofs of §3 it is possible, of course, to use the high chain 
principle instead of the Zorn lemma. For the proof of Theorem 2, 
for example, one may first prove (without the Zorn lemma and thus 
independently of the axiom of choice): the union of a high chain in 
the ordering of all linearly independent subsets of vector space V 
is a basis of V. Then Theorem 2 follows immediately from this theorem 
and the high chain principle. What is the corresponding "quintessence" 
(i.e., formulation independent of the axiom of choice) of Theorem I 
(of Theorem 3)? 
5. 
Questions Concerning the Foundations of Mathematics 
In the present chapter we have up to now taken the so-called "naive 
point of view" concerning sets. (cf. lA, §1.4, §7.1, §7.2). But everything 
we have said here, and in particular the proof we have given for the high 
chain principle, could also be formulated in the usual axiomatic set 
theories (cf. lA, §7.1 and §7.6). In this sense the proof we have given 
in §4 for Z is correct and can be verified even by an intuitionist or a 
constructivist. 
But a constructivist would regard an axiomatic (formalistic) inter-

11 
Zorn's Lemmo and the High Chain Principle 
535 
pretation of the concept of "set" as meaningless and therefore without 
interest;13 he would admit only constructive interpretations, and from 
this point of view (cf. lA, §1.4, §1.5) he would find two mistakes, or at 
least gaps, in the proof given above in §4: 
I) In one place in the proof we made use of the axiom of choice without 
actually constructing a choice function (on this question see, for example, 
[4], Chapter II, §4). 
2) The set V was defined as the union of all I-chains, but it turned 
out later that V is itself an f-chain. Thus we have defined an object (the 
set V) by means of a concept (f-chain) under which the object itself is 
included. 
More precisely, from the constructive point of view the situation is 
somewhat as follows: the I-chains are (in general, infinite) subsets. 
The only possibility of constructing an infinite subset is to construct a 
"representing property" for it (namely, a propositional form in a suitable 
language). Every construction of representing properties for sets must be 
carried out by means of certain linguistic tools, which must either be given 
or constructed in advance. With more linguistic tools at our disposal 
we can construct more properties and thus represent more sets. But the 
totality of all linguistic tools can never have been constructed (for if we 
were to assume that this is the case, we could proceed to use these linguistic 
tools in order to create further ones), and thus, in a constructive inter-
pretation, the expression "all f-chains" can never have an absolute 
meaning but only a relative one; it can only be understood in the sense 
of all I-chains "representable in a given language S." If we now form the 
union V of this relative totality of I-chains, we do not know whether a 
representing property of V can be found in the language S, i.e., whether V 
itself belongs to this totality. But precisely this fact was used in the above 
proof, namely when we said: "if P' -=I=- 0, then V* = V u {f(P')} is an 
f-chain, and thus V* ~ V." For in order to draw the conclusion that 
V* ~. V, we must know that V* is an I-chain representable in 5. Since 
it is obvious that V* is representable in S if and only if V is representable 
in S (the two sets differ only by a single element), we see that a constructive 
interpretation of our proof in a language S is correct only if the union V 
of all I-chains that are representable in S is itself representable in S. 
"Impredicative definitions," like this definition of V, occur in many 
places in mathematics in its usual form, e.g., in the introduction of the 
real numbers (cf. IBI, §4.3 and [18]). An objection of the type 2) above 
was already raised by Poincare against Zermelo's first proof of the well-
ordering theorem (cf. [11], [19], and Russell's "vicious circle princip1e" in 
18 Even if it were proved that the underlying formalized set theory is free of contra- ' 
dictions. 

536 
PART B ARITHMETIC AND ALGEBRA 
the introduction to [13]; see also [4] and the literature given there). 
A more precise examination of the whole question in the framework of 
P. Lorenzen's operational mathematics is given in [10] (cf. lA, §10.6 and 
[9]). 
In operational mathematics every set is countable in a suitable language 
level. So let us note here that, for a countable ordered set, a constructive 
proof of the high chain principle can easily be given by complete induction. 
Bibliography 
[1] Becker, 0.: Grundlagen der Mathematik in geschichtlicher Entwicklung. 
Freiburg, Miinchen 1954. 
[2] Bourbaki, N.: Theorie des ensembles, chap. III. Paris 1956. 
[3] Bourbaki, N.: Sur Ie theoreme de Zorn. Arch. Math. 2 (1951), pp. 434-437. 
[4] Fraenkel, A. A. and Bar-Hillel, Y.: Foundations of set theory. Amsterdam 
1958. 
[5] Hermes, H.: Einfiihrung in die Verbandstheorie. Berlin-Gottingen-
Heidelberg 1955. 
[6] Kamke, E.: Mengenlehre. Third ed., Berlin 1955. 
[7] Kneser, H.: Eine direkte Ableitung des Zornschen Lemmas aus dem 
Auswahlaxiom. Math. Z. 53 (1950), pp. 110-113. 
[8] Kuratowski, C.: Une methode d'elimination des nombres transfinis des 
raisonnements mathematiques. Fund. Math. 3 (1922), pp. 76-108. 
[9] Lorenzen, P.: Einflihrung in die operative Logik und Mathematik. Berlin-
Gottingen-Heidelberg 1955. 
[10] Lorenzen, P.: Dber den Kettensatz der Mengenlehre. Arch. Math. 9 
(1958), pp. 1-6. 
[11] Poincare, H.: Les mathematiques et la logique. Revue de Metaphysique 
et de Morale 14 (1906), pp. 307-317. 
[12] Redei, L.: Algebra. Part I, Leipzig 1959. 
[13] Russell, B. and Whitehead, A. N.: Principia mathematica, Vol. 1. Cam-
bridge 1910. 
[14] Teichmiiller, 0.: Braucht der Algebraiker das Auswahlaxiom? Deutsche 
Math. 4 (1939), pp. 567-577. 
[15] Tukey, J. W.: Convergence and uniformity in topology. Ann. Math. 
Studies, Princeton 1940. 
[16] van der Waerden, B. L.: Algebra. Part I, Fifth ed., Berlin-Gottingen-
Heidelberg 1960. 
[17] Weston, J. D.: A short proof of Zorn's Lemma. Arch. Math. 8 (1957), 
p.279. 
[18] Weyl, H.: Das Kontinuum. Leipzig 1918. 
[19] Zermelo, E.: Neuer Beweis flir die Moglichkeit einer Wohlordnung. Math. 
Ann. 65 (1908), pp. 107-128. 
[20] Zorn, M.: A remark on method in transfinite algebra. Bull. Amer. Math. 
Soc. 41 (1935), pp. 667-670. 

A number, an, 77 
Abelian group, 111 n33, 168 
Absolute values, 128, 31On27, 458 
Absorption laws, 53 
Abstract algebra, 65, 91, 92, 511 
Abstract science, 27 
Abstraction, 5, 65 
Abundant number, 371 
Addition, 98; algorithm for, 34; of 
integers, 111 ; of matrices, 251 ; 
monotonicity of, 100; recursive 
definition of, 98n12; 
of transformations, 247 
Additive group of a ring, 318, 357 
Adjoint, 315 
Adjunction, 411 
Admissible subgroups, 518 
Affine complex plane, 468 
Aleph-zero, 55 
Algebra(s), 345, 402-403n37; abstract, 
65,91,92,511; associative, 402-403n37; 
Boolean, 9; Cayley, 481; circuit, 484, 
494; division, 402-403n37, 478n17; 
entire rational function in the sense of, 
301 ; of finite rank, 478; fundamental 
theorem of, 467; of sets, 53 
Algebra of Logic (Boole's), 42 
Algebraic: complement of a 
subdeterminant, 283; congruence, 396; 
elements, conjugate, 431 ; extension, 
418,420; functions, 306; integers, 
330,401; manifold, 354; number, 401 
Algorithm, 7, 32, 79; for addition, 34; 
consistent, 39; Euclidean, 32, 332, 
365; for multiplication, 34; rule of an, 
33 
Algorithmic: derivation, 33; proof, 33 
Alphabet, 39 
Index 
Alternating, 314n30; group, 227; 
product, 235, 275 
Alternative, 13 
Amicable numbers, 372 
Analysis: entire rational function in the 
sense of, 301 ; ramified, 40 
Analytic number theory, 406 
"And," 12,67,483 
Angle, trisection of, 417 
Antiautomorphism, 470 
Antinomy(ies), 9, 51, 80; of Burali-
Forte, 57; Grelling's, 85; of the Liar, 
76, 81; Russell's, 59, 81; semantic, 81 ; 
syntactic, 81 ; of the universal set, 57 
Antireflexivity, 100 
Application, successive, 115 
Approximation, best, 377 
ARCHIMEDES, axiom of, 127n57 
Archmidean ordering, 127 
Argument(s): entire rational function of 
n, 305; from n to n + 1,94 
ARISTOTLE, 10, 20, 83 
Arithmetic, 5; incompleteness of, 40 
Arithmetization, 36 
Ars indicandi, 49 
Ars inveniendi, 42, 49 
ARTIN-SCHREIER, theorem of, 527 
Ascending chain condition, 524 
Assertion, 43 
Associate(s), 328, 356 
Associative, 98; division algebras, 
478n17; laws, 53 
Associator, 481 
Assumption(s), 42, 43; -elimination, 45; 
-introduction, 45 
At most countable, 55 
Atom(s), 69, 79, 80, 490 
Atomic, 490 

538 
Attribute, 21 
Aut, 13 
Autologic, 85 
Automorphism, 148, 191,412, 512; 
group, 191 ; group, of the 
configuration, 512 
Autonomous: notation, IOn; system of 
axioms, 27, 29, 67 
Axiom(s), 4-5; of Archimedes, 127n57; 
autonomous system of, 27, 29. 67; of 
cancellation, 181; categorical system 
of, 30; of choice, 60, 103n20, 164, 
530, 534; complete system of, 29; of 
comprehension, 58; dual, 68; for the 
empty set, 60; heteronomous system 
of, 27; of induction, 94; of infinity, 60; 
monomorphic system of, 30; 
Peano system of, 93; power set, 60; 
replacement, 60; schema, 26, 34; 
self-contradictory system of, 31; for 
sets with one element, 60; system, 
5J6; for unions (first and second), 60; 
well-ordering, 164; Zermelo's (of 
choice), 164 
Babylonians, 4, 27 
Base, 129 
Basis, 242, 526; condition, 339; of an 
ideal, 339; integer, 402; of kth order, 
405; theorem (Schnirelmann's), 407; 
vectors, 234 
BERNAYS, R., 58 
BERNSTEIN, equivalence theorem of, 54 
Best approximation, 377 
BETTI number, 303 
BEZOUT, theorem of, 354 
Bilinear: form, 264, 268; form, 
Hermitian, 271 ; mapping, 234 
Binary operation, 167 
Binomial: coefficients, 295; theorem, 295 
BIRKHOFF, G., 483, 520; Hausdorff-, 
maximal chain principle, 530, 533 
BOLZANO, BERNARD, 20 
BOOLE, GEORGE, 174n; Algebra of Logic, 42 
Boolean: algebra, 9; lattice(s), 67, 484, 
490, 495: ring, 69 
Bound: greatest lower, 68, 132,486; 
least upper, 68,486; lower, 523; 
proper upper, 523; upper, 486, 523; 
variable, 17, 23, 60 
BOURBAKI, N., 510 
BROUWER, L. E. J., 6 
BURALI-FoRTE, antinomy of, 57 
BURNSIDE, W., 217 
Calculus(i), 9, 32 
Cancellation: axioms of, 181; first rule, 
319; second rule, 323 
Canonical: decomposition, 225; 
factorization, 332 
INDEX 
CANTOR: diagonal procedure, 152; 
diagonal procedure (first and second), 
55; fundamental sequences, 133; 
fundamental theorem, 163 
Cardinal number(s), 54,94 
Cardinality (of a set), 54 
Categorical system of axioms, 30 
CAUCHY: convergence criterion of, 
467n81; sequences, 139 
CAYLEY, 223; algebra, 481; conjugate 
number, 481; numbers, 481; octaves, 
481 
Center, 218, 226 
Centralizer, 218 
Chain(s), 485, 522, 529; divisor, 330; 
f-, 531; above and below, 524; 
length of a, 495; maximal, 504; 
principle, Hausdorff-Birkhoff 
maximal, 530, 533; proper, 495; 
Sturm, 463; theorem (Dedekind), 504 
Chain condition: ascending, 524; divisor, 
360; factor, 495; high, 529; principle, 
522, 530; principle, sharpened, 530n 
Characteristic: equation of a matrix, 
286; of a field, 324 
CHATELET, 483 
Chinese remainder theorem, 391 
Choice: axiom of, 60, 103n20, 530, 535; 
axiom of Zermelo, 164; function, 535 
CHURCH, A., 49 
Circle principle (Russell), vicious, 535 
Circuit algebra, 484, 494 
Circularity, restriction against, 43 
Class(es): equality of, 58; equation, 
218; equivalence, 65; ideal, 404; 
number, 56,404; in set theory, 58; 
universal, 59 
Class residue, 109, 34J, 461; 
left and right, 186; ring, 342, 381 
Classical: ideal theory, 343; logic, 4 
Closed, 517; interval, 499 
Coefficients, 299, 304; binomial, 295; 
comparison of, 296; leading, 299 
Cogredient, 264 
Column rank of a matrix, 253 
Combination, linear, 239 
Common divisor, 358; greatest, 332, 358 
Communication, 9 
Commutative, 98; group, 111 n33, 168; 
laws, 53; ring, 117, 317 
Commutator group(s), 197, 217 
Comparability, 522 
Comparable, 158 
Comparativity, 65 

INDEX 
Comparison of coefficients, 296 
Complement, 52, 62, 490; relative, 499 
Complementary divisor, 356 
Complementation, laws for, 53 
Complemented, 490; lattice, 68; 
relatively, 499 
Complete, 487; induction, 57, 94, 117; 
induction starting from k, 101 ; 
lattice, 138n76, 491 ; ordered module, 
138; residue system, 381; system of 
axioms, 29; system of rules of 
inference, 41 
Completeness: of predicate logic, 42; 
theorem (G6del), 42 
Complex: conjugate, 461 ; plane, affine, 
468; -product, 182, 266; projective 
line, 471 
Complex numbers: fundamental algebraic 
theorem for, 467; fundamental 
topological theorem for, 467n8; left-
mUltiplication in the domain of, 457 
Complexes of a group, 182 
Componentwise multiplication, 392 
Composition, 406; configuration, 511; 
factors, 216; of fields, 436; of groups, 
436; inner, 510; nonelementary, 510 
Composition series, 216, 354; of fields, 
438; of groups, 438 
Comprehension, axiom of, 58 
Computable function, 36 
Concepts, fundamental, 22, 26 
Condition(s): ascending chain, 524; 
basis, 339; divisor-chain, 360; factor 
chain, 495; maximal, 360; normality, 
265; orthogonality, 265 
Configuration(s), 251, 508, 509; 
automorphism group of the, 512; 
composition-, 511 
Congruence(s); algebraic, 396; pure, 
399; relation, 65, 514; modulo an 
ideal, 341; a subgroup, 380 
Congruent, 270 
Conjecture: Fermat, 11-12, 37, 398; 
Goldbach, 10, 76,405 
Conjugate(s), 183; algebraic elements, 431 ; 
Cayley number, 481; complex, 461; 
fields, 437; quaternion, 475; system of, 
402n36; transposed matrix, 270 
Conjunction, 12 
Connectives: lattice-theoretic, 487; 
logical, 487; set-theoretic, 487 
Connex,63 
Connexity, 522 
Consequence, 8, 20, 24, 46 
Consistency, 6, 109; relative, 31 ; 
semantic, 31; syntactic, 31 
Consistent algorithm, 39 
Constant function, 291 
Constants: propositional, 12; 
structure, 402-403n37 
539 
Constructibility of a regular polygon, 454 
Constructive (point of view), 7 
Constructivist, 534-535; school, 7-8, 40 
Continuous function, 462 
Continuum, 55; hypothesis, 60; 
hypothesis, special, 60 
Contradiction, 23, 80 
Contragredient, 264 
Contraposition,47 
Contravariant vector, 264 
Convention, Einstein summation, 239 
Conventionalism, 6 
Convergence criterion (Cauchy), 467n8 
Convergent of a continued fraction, 373 
Converse relation, 62 
Coordinates, 240 
Coprime, 332 
Coset: left, 186; right, 186 
Countable, 55, 151 ; at most, 55 
Countably infinite, 151n9O 
Covariant: tensor, 264; vectors, 264 
Criterion(a): convergence (Cauchy), 
467n8; for divisibility, 385; 
irreducibility (Eisenstein), 347; for 
mUltiplicity of zeros, 426; for a 
quadratic residue function (Euler), 
400; for separability, 424; for 
subgroups, 184 
Crystallography, 204 
Cube, duplication doubling of, 417 
CURRY, 40 
Cut, Dedekind, 50, 133, 135 
Cycle, 224 
Cyclic, 191; groups, 191; groups, 
fundamental theorem for, 192 
Cyclotomic: field, 405; polynomial, 
428,430 
DE MOIVRE, formula of, 458 
Decidable, 36 
Decimal, infinite, 130 
Decomposition: canonical, 225; into 
partial fractions, 368 
DEDEKIND, RICHARD, 72, 403, 448, 483, 
488; chain theorem of, 504; cut, 50, 
133, 135; definition of infinity, 54 
Deduction, 41 
Deficient number, 371 
Definite, positive, 273 
Definition, 20-21 
Degree, 299; of an algebraic extension, 
420; of a representation, 220 
Denominator, 122; lowest common, 360 
Denotation (bedeutung), 10 

540 
Density, 407 
Dependent, linearly, 240 
Derivation, 41; algorithmic, 53 
Derivative, 303; of a polynomial, 423 
DESARGUES, little theorem of, 482 
Description operator, 12, 18 
Determinant(s), 235, 279; expansion 
of a, 282; mUltiplication of, 280; 
Sylvester, 349 
Diagonal: form of a matrix, 260; 
procedure (Cantor's), 152; procedure 
(Cantor's), first and second, 55; 
sequence, 152 
Diagram(s), 186; of Hesse, 485; order, 485 
DICKSON, L. E., 448 
Difference: left, 161; right, .161 
Division algebra(s), 402-403n37, 477; 
associative, 478n17; of finite rank, 478 
Digital sum, 385; alternating, 385; 
generalized, 385 
Dilatation(s): of the plane, 456; zero, 456 
Dilative rotations, 457; Hermitian, 469 
Dimension, 240, 505 
Dimensional equation, 505 
DIRAC, b-function, 5 
Direct: product, 198, 493; product of 
groups, 394; sum of (the ideals), 392 
Directed, 64; set, 64 
DIRICHLET, 406; pigeon-hole principle, 
102,463 
Discriminant, 352, 402 
Disjoint, 52 
Disjunction, 1 3 
Distributions, 5 
Distributive: lattice, 68,489; laws, 53, 
99, 115; laws, infinite, 490 
Divisibility: criteria for, 385; fundamental 
lemma of the theory of, 359 
Division: two-sided, 180 
Divisor(s): common, 358; 
complementary, 356; greatest 
common, 332, 358; prime, 358; 
proper, 357; trivial, 357; of zero, 119, 
293, 322; of zero, nilpotent, 342 
Divisor-chain, 330; condition, 360; 
proper, 330 
Domain(s), 62; first, 62; of a function, 
50; fundamental, 411; image, 247; of 
individuals, 21; integral, 119n47, 323; 
of integrity, 323; operator, 511 ; of 
positivity, 120, 464, 527; of scalars, 
235; second, 62; of transitivity, 221 
Dual, 487; axiom, 68; group, 483, 488, 
517; self-, 501 ; space, 263; vector 
space, 234 
Duality, principle of, 68 
Duplication doubling of the cube, 417 
Dyadic fractions, 130n6O 
Echelon matrix, 259 
Eigenvalues, 286 
Eigenvectors, 286 
INDEX 
EINSTEIN, summation convention of, 239 
EISENSTEIN, irreducibility criterion of, 347 
"Either-or," 13 
Element(s), 50; axiom for sets with one, 
60; conjugate algebraic, 431; exponent 
of a group, 193; G, order of the, 193; 
greatest, 490, 523; greatest common 
lower, 486; identity, 167; 
"imaginary," 448; inverse, 111; least, 
490, 523; least common upper, 486; 
maximal, 164, 523; minimal, 523; 
neutral, 11 1, 167,237; order of a 
group, 193; permutable, 168; prime, 
403; of a set, 51 ; superfluous, 497; 
unit, 66, 116, 167, 179,321,490; unity, 
321; zero, 179,490 
Elementary: -arithmetical structure, 521 ; 
-logical structure, 521 : ornament, 204; 
predicate logic, 73: symmetric 
functions, 302n23; symmetric 
polynomials, 307 
Elimination, 353; assumption-, 45; 
ideal, 354 
Empty: relation, 62; set, 52, 103; set, 
axiom for, 60; word, 231 
Endomorphism(s), 114, 128, 512; 
monotone, 146; multiplication of, 115; 
ring of, 116; sum of, 114 
Entire rational function, 292; in the 
sense of algebra, 301; in the sense of 
analysis, 301 ; of n arguments, 305 
Enumerable, recursively, 33, 35 
EnumerabiIity, 35 
Equality, 108; of classes, 58; of value, 122 
Equation(s): characteristic, of a matrix, 
286; class, 218; dimensional, 505; 
PeU, 397 
Equivalence, 14; class, 65; of matrices, 
254; relations, 29, 65, 108; of sets, 
103; theorem (Bernstein), 54 
Equivalent, 54 
EUCLID, 28 
Euclidean: algorithm, 32, 332, 365; 
rings, 332, 361 
EULER: criterion for a quadratic 
residue, 400; function, 382 
Even transpositions, 227 
Excluded middle, law of, 8 
Existence-introduction, 48n23 
Existential quantifier, 17, 18 
Expansion: of a determinant, 282; 
Laplace, 283 

INDEX 
Exponent, 445; of a group element, 
193; of a root of unity, 445 
Exponential function, 150 
Expression, relevant, 76n 
Extended: matrix, 259; predicate logic, 
23n,42,72 
Extension(s), 51; algebraic, 418; 
algebraic, degree of an, 420; Galois, 
420; field, 297n11 , 413; finite, 418; 
normal, 420; problem, 413; ring, 297; 
of a set, 51; separable, 422 
Extensionality, principle of, 51, 58 
F-chain, 531 
Factor, 75; chain condition, 495; 
composition, 216; group, 196; 
proper, 328 
Factorization: canonical, 332; rings, 
theorem for, 343; rings, unique, 331 
False, 10, 23 
FERMAT: conjecture, 11-12, 37, 398; 
number, 372; theorem, 382 
Field(s), 124, 323; alternative, 481 ; 
characteristic of a, 324; 
composition of, 436; composition 
series of, 438; conjugate, 437; 
cyclotomic, 405; extension (or 
subfield), 297n11 , 413; finite, 440; 
formally real, 464, 527; 
intersection of, 436; invariant, 402; 
skew, 235, 324, 526n; skew, of 
quaternions, 470; multiplicative group 
of a, 324, 357; ordered, 527; power 
series, 311; prime, 324; quotient, 125, 
325; radical over a, 452; of rational 
numbers, 124; real-closed, 464; of 
real numbers, 141; of relations, 63; 
of sets, 53; union of, 436 
Field splitting, 413; smallest, 413; 
uniqueness theorem for smallest, 415; 
in the wider sense, 413 
Figure, 172; group of a, 173 
Fin, symbol, 134 
Finis superior (or supremum), 134n 
Finished proof, 46 
Finitary, 40 
Finite, 55, 102; ascending length, 495; 
above and below chain, 524; 
descending length, 495; extension, 
418; field, 440; ~oup, 168; length, 
495; rank, division algebra of, 478; 
set, Dedekind definition of, 103021; 
system of generators, 185 
Hnitely generated, 185 
First: axiom for unions, 60; Cantor 
diagonal procedure, 55; domain, 62 
Fix-group, 221 
Flagged variables, 43 
Fonction polynome, 301 
"for all," 12,96 
541 
Form(s): bilinear, 264, 268, 271 ; 
diagonal, of a matrix, 260; 
fundamental, 270; Hermitean, 271; 
Hesse normal, 30; linear, 234, 262, 
263, 345n48; multilinear, 264, 268; 
prenex normal, 518; propositional, 11, 
22, 94n2, 535; quadratic, 268; 
signature of a, 272 
Formalists, 6 
Formalization, 9 
Formally real (field), 464, 527 
Formula: of de Moivre, 458; 
inversion, of Mobius, 389; for 
rotations, Rodrigues', 477 
Fraction(s), 122, 325; dyadic, 130n6O; 
partial, 368; partial, decomposition 
into, 368; proper, 368 
continued, 333n29, 373; convergent of a, 
373; Hurwitz, 379; regular, 333n29, 373 
Free: group, 231 ; square-, 388; 
torsion-, 200; variables, 17; renaming 
of variables, 44n18 
FREGE, G., 10, 51, 72 
FROBENIUS, theorem of, 478 
Function, 64, 509; algebraic, 306; . 
choice, 535; computable, 36; constant, 
291 ; continuous, 462; Dirac b-, 5; 
of a domain, 50; elementary 
symmetric, 307n23; Euler, 382; 
exponential, 150; identical, 291 ; 
inverse, 64; Mobius, 288; partition, 
406; product, 38; range of a, 50; 
recursive, 35, 38; signs, 12, 15; sum, 
38; summatory, 371, 388; unity, 388; 
unity, 388; zero of a, 293. See also 
Entire rational function 
Fundamental: concepts, 22, 26; domain, 
411 ; form, 270; lemma of the theory 
of divisibility, 359; sequences, 139; 
sequences of Cantor, 133; system of 
solutions, 257; tensor, 270; theorem 
for cyclic groups, 192 
G, element, order of a group, 193 
GALOIS, 447; extension, 420; group, 
409, 434; theory, 409 
GAUSS: number, 372; plane, 457 
Gaussian integers, 316 
Gebikk,50S 
General polynomial, 453 
Generalization of the prime number 
theorem, 406 
Generalized: digital sum, 386; predicate 
variable, 72 

542 
Generated, 185; finitely, 185 
Generating system, 526 
Generators, 185; finite system of, 185 
GENTZEN, 43, 76; and QUINE, rules of 
inference, 43 
GIBBS, JOSIAH WILLARD, 476n 
Glide reflections, 205 
GODEL, 31, 38; completeness theorem, 
42; incompleteness theorem, 72; 
index, 36; numbers, 76 
Godelization, 36 
GOLDBACH, conjecture of, 10, 76, 405 
Graphs, 186 
GRASSMAN, 275 
Greatest: common divisor, 332, 358; 
common lower element, 486; element, 
490, 523; lower bound, 68, 132, 486 
GRELLlNG, antinomy of, 85 
Ground set, 62 
Group(s), 167; Abelian, 111n33, 168; 
additive, of a ring, 318, 357; 
alternating, 227; automorphism, 
191 ; automorphism, of the 
configuration, 512; commutative, 
111 n33, 168 ; commutator, 197, 
217; complexes of a, 182; 
composition of, 436; composition 
series of, 438; cyclic, 191; cyclic, 
fundamental theorem for, 192; direct 
product of, 394; dual, 483, 488,517; 
factor, 196; of a figure, 173; fix-, 
221; free, 231; Galois, 409, 434; 
Hamiltonian, 194; Klein four-, 491; 
length of a, 216; of motions, 172; 
multiplication, 28; multiplication table 
for a, 188; multiplicative, of a field, 324, 
357; nilpotent, 220; with operators, 
518; order of a, 168; P-, 219, 220; 
planar rotation, 214; power of a, 192; 
quaternion, 194; simple, 196; 
structure problem for, 191; symmetric, 
171; theory, 28; topological, 232; 
torsion, 200; type problems for, 191; 
union of, 436 
Group element: exponent of a, 193; 
order of a, 193 
Half-turns, 205 
HAMEL, G., 146n88 
Hamiltonian groups, 194 
HANKEL, permanence principle of, 105n26 
HAUSDORFF-BIRKHOFF, maximal chain 
principle, 530, 533 
Hemihedrism, 209 
HERBRAND, 38 
Hereditary, 93; meet-, 518 
HERMES, H., 484 
INDEX 
Hermitian (HERMITE): bilinear form, 
271 ; dilative rotations, 469; form, 
271 ; matrix, 271; metric, 468; 
rotations, 468 
HERTZ, H., 6 
HESSE: diagram, 485; normal form, 30 
Heterologic, 85 
Heteronomous system of axioms, 27 
High, 529. See also Chain, high 
HILBERT, D .• 6, 21,406 
HOLDER (and JORDAN), theorem of, 216, 
354, 504 
Holohedrism, 209 
Homogeneous, 305; system, 235 
Homologous, 511 
Homomorphism, 107, 212, 511 ; theorem, 
212; theorem, for rings, 342 
HORNER, rule of, 294, 295 
HURWITZ, continued fraction of, 379 
Hypercomplex system, 345 
Hypothesis: continuum, 60; 
continuum, special, 60; induction, 95 
Ideal(s), 338 ~ basis of an, 339; classes, 
404; congruence modulo an, 341; 
direct sum of, 392; elimination, 354; 
left and right, 357; manifold of zeros 
of an, 354; maximal, 403; primary, 
342; prime, 342, 403; principal, 339; 
principal, ring, 339; theory, classical, 
343; two-sided, 357; unit, 338; zero, 
338 
Idealism, 3 
Idempotent, 69n, 392; ring, 69 
Identical: function, 291 ; permutation, 170 
Identification, 5 
Identitive, 63; law, 53 
Identity, 62, 321 ; element, 167; 
modular, 501 
"If and only if," 14 
"If-then" 14 
Image, 64, 212; domain, 247; pre-, 64; 
space, 247 
"Imaginary" element, 448 
Imaginary part, 458 
Implication, 14 
Impredicative, 85; definitions, 535 
Improper: real number, 136; subgroup, 
184 
Inclusion, 62 
Incompleteness: of aritHmetic, 40; of 
extended predicate logic, 42; 
theorem of Godel, 72 
Indecomposable, 199 
Independent: indeterminates, 304; 
linearly, 240, 526; transcendents, 304 
Indeterminates, 297; independent, 304 

INDE.X 
Index: Godel, 36; kernel-, notation, 
246; of a subgroup, 186 
Indirect proof, 42-43 
Individual(s), 21; domain of, 21 
Induction: A-, 43; axiom of, 94; 
complete, 57, 94, 117; complete 
starting from k, 101; hypothesis, 95; 
mathematical, 94; modified principle 
of, 101; schema, 75; step, 95; 
transfinite, 57 
Inductive set, 164 
Inertia, Sylvester's law of, 272 
Inference, 41; system of natural, 42 
Inference, rules of, 41 ; complete system 
of, 41; of Gentzen and Quine, 43 
Infimum (or greatest lower bound), 132 
Infinite: countably, 151n9O; decimal, 
130; distributive laws, 490 
Infinitely distant points, 5 
Infinitesimal, 139 
Infinity: actual, 7; axiom of, 60; 
Dedekind definition of, 54; potential, 7 
Initial: case, 95; intervals, 156; segments, 
156, 532 
Inner: composition, 510; product, 234, 
266,269 
Integer(s), 109, 368; addition of, 111; 
algebraic, 401; algebraic, integral 
domain of, 330; basis, 402; Gaussian, 
316; module of, 112, 120; negative, 
113; positive, 113; ring of, 120 
Integral domain(s), 119n47, 323; of 
algebraic integers, 330 
Integrally closed ring, 403 
Intermediate value theorem, 462 
Interpretation(s), 20, 22; isomorphic, 30 
Intersection, 52, 59, 62, 483, 486, 487; 
of fields, 436; of subgroups, 436 . 
Interval(s): closed, 499; initial, 156; 
nested, 133 
Into, 64, 509, 510 
Intramathematical, 5 
Introduction: assumption-, 43, 45; 
existence-, 48n23 
Intuitionist(s), 6, 534 
Intuitive theory of sets, 51 
Invariant, 183; field, 402; subgroups, 194 
Inverse, 111 n34, 123, 167; element, 111; 
function, 64; left, 167n2; mapping, 
510; right, 167n2 
Inversion formula of Mobius, 389 
Inverti ble, 510; mapping, 64; mapping, 
one-to-one, 64; transformation, 249 
Irrational numbers, 152n 
Irrationality of V'2, 47 
Irreducible, 328, 357 
Irreducibility criterion of Eisenstein, 347 
Isobaric, 350 
Isolated (ordinal number), 161 
Isomorphic: interpretations, 30; 
relations, 64 
543 
Isomorphism, 117, J56, J90, 412,512; 
order-preserving, 144; theorem, 214 
JACOBI, symbol, 400 
Join, the, 486, 49J 
JORDAN-HoLDER, theorem of, 2J 6, 354, 
504 
k-place predicate, 16 
KANT, IMMANUEL, 4 
Kernel, 212; -index notation, 246 
KLEIN-BARMEN, FRITZ, 483; (Klein) 
four-group, 491 
KNESER, H., 530 
KRONECKER, symbols of, 245 
KUMMER,403 
KURATOWSKI, lemma of, 524 
LAGRANGE, JOSEPH LOUIS, 186,406; 
(Lagrange) relation, 398 
A-introduction, 80 
Language(s): layer, second, 136n74; 
natural, 4, 9, 85 
LAPLACE, expansion, 283 
Lattice(s), 68, 360, 483, 487, 517; 
Boolean, 67, 484, 490, 495; 
complemented, 68; complete, 138n76, 
491 ; distributive, 68, 489; modular, 
501; points, 204; semi-, 487; set-, 
499; sub-, 492, 517; -theoretic 
connectives, 487; theory, 28 
Law: of the excluded middle, 8; of 
inertia (Sylvester), 272; reflexive, 53 
Leading coefficients, 299 
Least: common multiple, 359; common 
upper element, 486; element, 490, 
523; upper bound, 68, 486 
Left: cosets, 186; difference, 161; 
ideals, 357; inverse, 167n2; 
-multiplication in the domain of complex 
numbers, 457; residue classes, 186 
LEIBNIZ, GOTTFRIED WILHELM, 42 
Lemma: fundamental, of the theory of 
divisibility, 359; Kuratowski's, 524; 
Zorn's, 164, 522, 525 
Length: of a chain, 216; finite, 495; 
finite ascending, 495; finite 
descending, 495; of a group, 216 
Levels of real numbers, 8 
Lexicographic ordering, 130 
Lexicographically ordered, 159 
Liar: Antinomy of the, 76, 81; 
Paradox of the, 77 

544 
Limit: number(s), 56, 161 ; of a sequence, 
132 
Line(s), 506; complex projective, 471 
Linear: combination, 239; mappings, 
234; order, 485; transformation, 246; 
transformation, ring of, 249 
Linear form(s), 234, 262, 345n48; module 
of, 263: multi-, 264, 268 
Linearly: dependent, 240; independent, 
240, 526: ordered, 522 
Little Desargues theorem, 482 
Logarithm, 151 
Logic: Algebra of Logic (Boole), 42; 
classical, 4; of the first order, 73; 
history of, 9; operator in, 16; of the 
second order, 23n72. See also 
Predicate, logic 
Logical: connectives, 487; matrix 
(truth table), 12; symbols, 484 
Logicism, 51 
Logics, many valued, 10 
Longitudinal reflections, 205 
LORENZEN, P., 40, 72, 79, 94n3, 536 
LOWENHEIM, and SKOLEM, theorem of, 71 
Lower: bound, 523; bound, greatest, 
68; element, greatest common, 486; 
neighbor, 485, 523 
Lowest: common denominator, 360; 
terms, 360 
Manifold(s): 'algebraic, 354; of zeros of 
an ideal, 354 
Many-place properties, 21 
Mapping(s),64, 509; bilinear, 234; 
inverse, 510; invertible, 64; invertible, 
one-to-one, 64; linear, 234; 
normalization of a, 280; onto, 395n; 
rigid, 172n 
Mathematical: induction, 94; system, 508 
Matrix(ces), 234; addition of, 251 ; 
characteristic equation of a, 286; 
coefficient, 259; conjugate transposed, 
270; diagonal form of a, 260; echelon, 
259; equivalence of, 254; extended, 
259; Hermitian, 271 ; logical, 12; 
multiplication of, 177, 252; rank of a, 
255, 260, 284; column rank of a, 
253; skew-symmetric, 314; square, 
177; of a transformation, 250; unit, 
273 
Maximal, 525; condition, 360; element, 
164, 523; ideal, 403; segment, 157; 
subgroup, 186 
Maximal chain, 504; principle, Hausdorff-
Birkhoff, 530, 533 
Mechanics, quantum, 10 
Meet, 487; -hereditary, 518 
MERSENNE numbers, 371 
Meta-metalanguage, 85 
Metalanguage, 84 
Metamathematics, 3-4 
INDE.X 
Metric: Hermitian, 468; space, 270; 
structure, 270 
Minimal: element, 523: subgroup, 186 
MOBIUS: function, 388; inversion 
formula, 389 
Model, 23, 516 
Modified principle of induction, 101 
Modular: identity, 501: lattice, 501; 
semi-, 503; semi-, above, 503; semi-, 
below, 503 
Module, 11 1, 31 8n4; of integers, 112, 
120; of linear forms, 263; ordered, 
120; complete ordered, 138; property, 
338 
Modulo, congruence, an ideal, 341; a 
subgroup, 380 
Modulo n, reduced, 174 
Modulus, 458 
Modus ponens, 41 
Monomorphic, 73, 521 ; system of 
axioms, 30 
Monotone endomorphism, 146 
Monotonic law for multiplication, 120 
Monotonicity of addition, 100 
Motions: group of, 172; proper, 214; 
spiral,205 
MOUFANG, R., 482 
Multilinear forms, 264, 268 
Multiple: least common, 359; zero, 303 
Multiplication, 99; algorithm for, 34; 
component wise, 392; of 
determinants, 280; of 
endomorphisms, 115; group, 28; 
left-, in the domain of complex 
numbers, 457; of matrices, 177, 252; 
monotonic law for, 120; of ordinal 
numbers, 160; of real numbers, 146; 
table, 345; table, for a group, 188; of 
transformations, 248; of vectors, 267 
Multiplicative: group of a field, 324, 
357; semigroup of a ring, 357 
Multiplicity of a zero, 302; criterion for, 
426 
Naive set theory, 51, 534 
Natural: inference, system of, 42; 
languages, 4,9,85; number, 72; 
numbers, totality of, 72; science, 27 
Negation, 13 
Negative integers, 113 
Neighbor: lower, 485, 523; upper, 523 
Nested intervals, 133 
Neutral element, 111, 167,237 

INDE.X 
Nilpotent: divisor of zero, 342; groups, 
220 
Noetherian rings, 339 
Nominalism, 3 
Nonelementary: composition, 510; 
structure, 521 
Nonseparable polynomial, 424 
Norm, 403, 460, 470, 481 
Normal, 183; extensions, 420; form, 
prenex, 518; polynomial, 453; 
subgroups, 188, 194, 518 
Normality conditions, 265 
Normalization of a mapping, 280 
Normalized, 370 
Normalizer, 218 
Normed,449 
"not," 12, 13 
Notation: autonomous, IOn; kernel-
index, 246 
nth root, 148 
Number(s): A, 77: abundant, 371; 
algebraic, 401 ; amicable, 372; Betti, 
203; cardinal, 54,94; Cayley, 481; 
Cayley conjugate, 481 ; class, 56, 404; 
deficient, 371; Fermat, 372; Gauss, 372; 
Godel, 76; irrational, 152n; limit, 56, 
) 61 ; Mersenne, 371; natural, 72; 
natural, totality of, 72; and numerals, 
39n14; perfect, 7, 371; sequence of, 
104; sum of, 95; theory, analytic, 406; 
torsion, 203; transcendental, 401 
Number, rational, 122; field of, 124; 
positive, 125 
See also Complex, numbers; 
Ordinal number(s); Prime, number; 
Real, number(s) 
Numerals, and numbers, 39n14 
Numerator, 122 
O-place predicates, 16 
Octaves, Cayley, 481 
One-to-one, 510; (invertible) mapping, 64 
Onto, 64, 509; mapping, 395n 
Operation: binary, 167; outer, 510 
Operator(s): description, 12, 18; 
domains, 511; group with, 518; in 
logic, 16; of set formation, 12 
"Or," 12, 13, 67, 483 
Order(s), 32, 485, 522; basis of kth, 
405; diagram, 485; of element G, 
193; of a group, 168; of a group 
element, 193; linear, 485; -preserving 
isomorphism, 144; set-, 523; type, 56 
Orderable, 527 
Ordered, 524; field, 527; linearly, 522; 
module, 120; module, complete, 138; 
pairs, 52; ring, 120. See also Sets, 
ordered 
Ordering(s), 63; Archmidean, 127; 
lexicographic, 130; partial, 63; 
quasi-, 356; semi-, 63. See also 
Well-ordering(s) 
545 
Ordinal number(s), 56, 153, 158; 
isolated, 161; multiplication of, 160; 
of the first kind, 161 ; of the second 
kind, 16); sum of, 159 
Ornament(s), 204; elementary, 204 
Orthogonal, 273, 285; transformations, 
273 
Orthogonality conditions, 265 
Outer: operation, 510; product, 235, 275 
P-group(s), 219; Sylow, 220 
Pairs, ordered, 52 
Paradox, 80; of the Liar, 77 
Part: imaginary, 458; preperiodic, 378; 
real, 458; scalar, 475; vector, 475 
Partial: fractions, 368; orderings, 63; 
well-orderings, 64 
Partition function, 406 
PASCAL, triangle, 296 
PEANO, GIUSEPPE, 72, 94; system, 9, 30; 
system of axioms, 93 
PELL, equation, 397 
Perfect, 198; number, 7, 371 
Period, primitive, 378 
Permanence principle of Hankel, 105n26 
Permutable element, 168 
Permutation(s), 169; identical, 170 
PHILON,14 
Pigeon-hole principle, 102, 465 
Planar rotation group, 214 
Plane: affine complex, 468; 
dilatations of the, 456; Gauss, 457; 
rotation of the, 456 
PLATO, 4 
POINCARE, H., 535 
Point(s), 169,490, 506; infinitely distant, 
5; lattice, 204 
Polygon, constructibility of a regular, 454 
Polynomial(s), 299, 304; cyclotomic, 
428, 430; derivative of a, 423; 
nonseparable, 424; elementary 
symmetric, 307; general, 453; normal, 
453; primitive, 335, 449; ring, 299, 
304; separable, 422; value of a, 300; 
zero of a, 302 
Positive: definite, 273; integers, 113; 
rational numbers, 125 
Positivity, domain of, 120, 464, 527 
Potential infinity, 7 
Power, 125; of a group, 192; rule, 200; 
set, 52, 54, 485; -series, 308; -series field, 
311; -series ring, 311; set axiom, 60 

546 
Pre-image, 64 
Predicate(s), 12, 15-16,21; k-place, 16; 
O-place, 16; two-place, 16; variable, 11, 
22; variable, generalized, 72 
Predicate logic: completeness of, 42; 
elementary, 73; extended, 23n, 72; 
incompleteness of extended, 42 
Prenex normal form, 518 
Preperiod, 387 
Preperiodic part, 378 
Primary, 496; ideal, 342 
Prime, 329; divisor, 358; element, 403; 
field, 324; ideal, 342,403; number, 
75; number theorem, generalization 
of, 406; regular, 405 
Primitive: period, 378; polynomial, 335, 
449; root, 399; root of unity, 427 
Principal ideal(s), 339; ring, 339 
Principia Mathematica (Whitehead and 
Russell), 42 
Principle: of duality, 68; of 
extensionality, 51, 58; Hausdorff-
Birkhoff maximal chain, 530, 533; 
high chain, 522, 530; high chain, 
sharpened, 530n; permanence 
(Hankel), 105; pigeonhole, 102, 465; 
of recursion, 96; Russell's vicious 
circle, 535; of two-valuedness, 10, 21 
Problem(s): type and structure, for 
groups, 191 ; Waring, 406; word, 35, 232 
Product(s), 167; alternating, 235, 275; 
complex-, 182, 266; direct, 198, 493; 
direct, of groups, 394; function, 38; 
inner, 234, 266, 269; outer, 235, 275; 
quaternion, 475; relative, 62; scalar, 
234, 266, 269; tensor, 235, 273; 
vector, 266 
Projection, 255 
Projective line, complex, 471 
Proof, 41, 43; algorithmic, 33; 
finished, 46; indirect, 42-43 
Proper: chains, 495; divisor, 357; 
divisor chain, 330; factor, 328; 
fraction, 368; motions, 214; segments, 
156; subset, 52, 95n5; upper bound, 
523; variable, 34 
Properly simple, 196 
Property(ies), 21; many-place, 21; 
module, 338; representing, 535; 
two-place, 21 
Proposition, relevant, 29 
Propositional: constants, 12; form(s), 
11,22, 94n2, 535; variables, 15 
Propositions, 10, 11 
"Protologic," 79 
Pure: congruences, 399; -elementary 
structures, 521 
INDE.X 
Pythagorean: theorem, 4, 27; triples, 398 
Quadratic: form, 268: reciprocity, 400; 
residues, 399; residue, Euler criterion 
for a, 400 
Quantifier(s), 12, 16; existential, 17, 18; 
universal, 17, 18 
Quantum mechanics, 10 
Quasi-ordering, 356 
Quaternion(s), 317nl, 470; conjugate, 
470; group, 194; product, 475; 
skew field of, 470 
QUINE, W. V., and GENTZEN, 43 
Quotient(s), 125; field, 125, 325; ring, 368 
Radical(s): over a field, 452; 
solvability by, 452 
Ramified analysis, 40 
Range (of a function), 50 
Rank: of a matrix, 255, 260, 284; 
column, of a matrix, 253; of a 
transformation, 247 
Rational numbers, 122; field of, 124; 
positive, 125 
Real: -closed, 463; part, 458 
Real number(s), 134, 135; field of, 141; 
improper, 136; levels of, 8; 
multiplication of, 146 
Realism, 3 
Reciprocal, 123 
Reciprocity. quadratic, 400; 
generalized law of, 400 
"Rectangular array," 250 
Recursion, principle of, 96 
Recursive: definition, 96; definition of 
addition, 98n12; function, 35, 38 
Recursively enumerable, 33, 35 
Reduced: modulo n, 174; remainder, 
174 
Reducible, 328 
Reflection(s), 205; glide, 205; 
longitudinal, 205; rotatory, 206; 
transverse, 205 
Reflexive, 63; law, 53 
Reflexivity, 29 
Regressions, 157 
Regular, 253; continued fraction, 
333n29, 373; prime, 405; 
representation, 223 
Relation(s), 21, 509; congruence, 65, 
514; connex, 63; converse, 62; 
empty, 62; equivalence, 29, 65, 108; 
field of, 63; identitive, 63; 
isomorphic, 64; Lagrange, 398; 
reflexive, 63; successor, 32; symmetric, 
63; theory of, 9, 61; transitive, 63; 
universal, 62; void, 62 

INDE.X 
Relative: complement, 499; 
consistency, 31; product, 62 
Relatively complemented, 499 
Relevant: expression, 76n; proposition, 29 
Remainder: reduced, 174; theorem 
(Chinese), 391 
Replacement axiom, 60 
Representation, 220; degree of a, 220; 
regular, 223; transitive, 222 
Representing property; 535 
Residue(s): class ring, 342, 381; 
classes, 109, 186, 341,461; quadratic, 
399; quadratic, Euler criterion for a, 
400; system, complete, 381 
Restriction against circularity, 43 
Resultant, 349 
RIEMANN, sphere, 472 
Right: cosets, 186; difference, 161 ; 
ideals, 357; inverse, 167n2; residue 
classes, 186 
Rigid mapping, 172n 
Ring(s), 116; additive group of a, 318, 
357; Boolean, 69; commuta.tive, 117, 
317; of endomorphisms. 116; 
Euclidean, 332, 361; extension, 297; 
factorization theorem for, 343; 
homomorphism theorem for, 342; of 
integers, 120; integrally closed, 403; 
of linear transformations, 249; 
multiplicative semigroup of a, 357; 
Noetherian, 339; ordered, 120; 
polynomial, 299, 304; power-series, 
311; principal ideal, 339; quotient, 
368; residue class, 342, 381; theory, 
28; unique factorization, 331 
RODRIGUES, formula for rotations, 477 
Roof,529 
Root, 302n15; nth, 148; primitive, 399; 
square, 148; of unity, 425; exponent 
of a, 445; primitive, 427 
Rotation(s), 205; dilative, 457; dilative, 
Hermitian, 469; Hermitian, 468; 
of the plane, 456; Rodrigues formula 
for, 477; of the sphere, 472 
Rotatory reflections, 206 
Rule(s): of an algorithm, 33; Horner's, 
294,295; of inference, 41, 43; power, 
200; of separation, 41 
RUSSELL, BERTRAND, 22, 51; antimony, 
59, 81; vicious circle principle, 535; 
and A. N. Whitehead, 42 
Scalar(s): domain of, 235; part, 475; 
product, 234, 266, 269 
Schema: axiom, 26, 34; induction, 75 
SCHNIRELMANN, 405; basis theorem of, 
407 
547 
SCHOUTEN, 246, 262 
SCHREIER, ARTIN-, theorem of, 527 
Science: abstract, 27; natural, 27 
Second: axiom for unions, 60; Cantor 
diagonal procedure, 55, domain, 62; 
language layer, 136n74 
Segment(s), 102, 156, 520; initial, 156, 
532; maximal, 157; proper, 156 
Self-contradictory system of axioms, 31 
Self-dual, 501 
Semantic(s), 20; antinomy, 81 ; 
consistency, 31 
Semi-orderings, 63 
Semilattice, 487 
Semimodular: above, 503; below, 503 
Sense (Sinn), 10 
Separability, criterion for, 424 
Separable: extensions, 422; 
polynomial, 422 
Separation, rule of, 41 
Sequence(s), 64; fundamental, of Cantor, 
133; Cauchy or fundamental, 139; 
diagonal, 152; limit of a, 132; of 
numbers, 104; zero, 140 
Series: composition, 216, 354; of fields 
and groups, 438; power-, 308; power-, 
field and ring, 311 
Set(s), 50; algebra of, 53; axiom for, 
with one element, 60; cardinality of a, 
54; directed, 64; element of a, 51; 
empty, 52, 103; empty, axiom for the, 
60; equivalence of, 103; extension of 
a, 51; field of, 53; finite (Dedekind 
definition), 103n21; formation, 
operator of, 12; ground, 62; 
-lattice, 499; -orders, 523; power, 
52, 54,485; power, axiom, 60; 
-theoretic connectives, 487; universal, 
52, 57; universal, antinomy of the, 57 
Sets, ordered, 50, 56, 522; linearly, 522; 
totally, 522, 533; well-, 153, 155, 532 
Sets, theory of, 3-4, 9; class in, 58; 
naive or intuitive, 51, 534 
Sharpened high chain principle, 530n 
Signature of a form, 272 
Signs, function, 12, 15 
Similar, 56, 221, 226, 262 
Similarity, 156 
Simple, 228; group, 196; properly, 196 
Skew field, 235, 324, 526n; of 
quaternions, 470 
Skew-symmetric: matrix, 314; tensor, 276 
SKOLEM, and L5wENHElM, theorem of, 71 
Smallest splitting field, 413; 
uniqueness theorem for, 415 
Solutions, fundamental system of, 257 
Solvability, by radicals, 452 

S48 
Solvable, 216 
Space, 169; dual, 263; image, 247; 
metric, 270; vector, 233, 238, 526n; 
vector, dual, 234 
Spanned subspace, 243 
Special continuum hypothesis, 60 
Sphere: Riemann, 472; rotations of 
the, 472 
Spiral motions, 205 
Splitting field, 413; smallest, 413; 
smallest, uniqueness theorem for, 415; 
in the wider sense, 413 
Square: -free, 388; matrix, 177; root, 148 
Statements, valid, 516 
Stoics, 14 
Structure(s), 5, 508, 515, 516; 
constants, 402-403n37; elementary-
arithmetical, 521; elementary-logical, 
521; metric, 270; nonelementary, 521; 
problem for groups, 191; 
pure-elementary, 521; type, 516 
STURM: chain, 463; theorem, 463 
Subband(s), 492, 517 
Subconfiguration, 517 
Subdeterminant, algebraic complement 
of a, 283 
Subfield, 297nll 
Subgroup(s), 184; admissible, 518; 
criterion for, 184; congruence 
modulo a, 380; improper, 184; index 
of a, 186; intersection of, 436; 
invariant, 194; maximal, 186; 
minimal, 186; normal, 188, 194, 518; 
proper, 184; trivial, 184 
Subideal, 339n 
SUbject(s), 12, 15, 21; variables, 11 
Sublattice, 492, 517 
Subring, 322, 338 
Subset, 52; proper, 52, 95n5 
Subspace, 526n; spanned, 243; vector, 
243,526n 
Substitution, 168, 300 
Successive application, 115 
Successor, 38, 56,93, 94; relation, 32 
Sum, 133; digital, 385, 386; direct, of 
the ideals, 392; of endomorphisms, 
114; function, 38; of numbers, 95; 
of ordinal numbers, 159 
Summation convention, Einstein, 239 
Summatory function, 371, 388 
Superfluous elements, 497 
SUZUKI, M., 519 
SYLOW: p-groups, 220; theorem, 219 
SYLVESTER: determinant, 349; law of 
inertia, 272 
Symbol(s): fin, 134; Jacobi, 400; 
Kronecker, 245; logical, 485 
INDE.X 
Symmetric, 63, 108,270, 306; group, 
171; skew-, matrix, 314; skew-, 
tensor, 267 
elementary: functions, 307n23; 
polynomials, 307 
Symmetry, 29 
Syntactic: antinomy, 81; 
consistency, 31 
Syntax, 20 
TARSKI, A., 20 
Tautology, 23, 24-25 
Tensor: covariant, 264; fundamental, 270; 
product, 235, 273; skew-symmetric, 276 
Terms, lowest, 360 
Tertium non datur, 43, 47, 49 
Tetartohedrism, 209 
THALES,27 
Theorem: fundamental, of algebra, 467; 
Artin-Schreier, 527; Bernstein 
equivalence, 54; Bezout, 354; 
binomial, 295; Cantor fundamental, 
163; chain, of Dedekind, 504; 
Chinese remainder, 391; 
completeness, of Godel, 42; for 
complex numbers, fundamental 
algebraic, 467; for complex numbers, 
fundamental topological, 467n8; 
fundamental, for cyclic groups, 192; 
little, of Desargues, 482; 
factorization, for rings, 343; 
Fermat, 382; of Frobenius, 478; 
incompleteness (Godel), 72; 
intermediate value, 462; isomorphism, 
214; Jordan-Holder, 216, 354, 504; 
of Lowenheim and Skolem, 71; 
prime number, 406; Pythagorean, 
4, 27; Schnirelmann basis, 407; 
Sturm, 463; Sylow, 219; Uniqueness, 
for smallest splitting fields, 415; 
well-ordering, 56, 525; Wilson's, 384 
Topological: group, 232; theorem for 
complex numbers, fundamental, 467n8 
Torsion: -free, 200; group, 200; 
numbers, 203 
Totality of natural numbers, 72 
Totally ordered, 522, 533 
Trace, 286 
Transcendent(s), 296; independent, 304 
Transcendental number, 401 
Transfinite, 55; induction, 57; 
inductive definition, 57 
Transformation(s): addition of, 247; 
invertible, 249; linear, 246; linear, 
ring of, 249; matrix of a, 250; 
multiplication of, 248; orthogonal, 
273; rank of a, 247 

INDE.X 
Transforms, 183 
Transitive, 63, 108; law, 53; 
representation, 222 
Transitivity, 29, J 00; domain of, 221 
Translations, 205 
Transposition(s), 226 ~ even, 227 
Transverse reflections, 205 
Treillis, 483 
Triangle, 92; Pascal, 296 
Triples, Pythagorean, 398 
Trisection of an angle, 417 
Trivial: divisors, 357; subgroup, 184 
True, 10,23 
Truth: table (logical matrix), 12; 
-value, 107, 109 
TURING,36 
Two-place: predicate, 16; property, 21 
Two-sided: division, 180; ideals, 357 
Two-valuedness, principle of, 10, 21 
Type: order, 56; problems for groups, 
191; structure, 516 
Uncountable, 55, 151 
Unimodular, 399n 
Union(s), 52, 62,483,486; first and 
second axioms for, 60; of fields, 436; 
of groups, 436 
Unique factorization rings, 331 
Uniqueness theorem for smallest 
splitting fields, 415 
Unit(s), 327, 356; element, 66, 116, 167, 
179,321,490; ideal, 338; matrix, 273; 
vector, 285 
Unitary, 273 
Unity: element, 321 ; function, 388 
root of, 425; exponent of a, 445; 
primitive, 437 
Universal: class, 59; quantifier, 17, 18; 
relation, 62; set, 52, 57; set, 
antinomy of, 57 
Upper: bound, 486, 523; bound, least 
and proper, 68, 486, 523; neighbor, 
523 
Valid statements, 516 
Valuation, 31On, 405 
Value: absolute, 128, 31On, 458; 
equality of, 122; of a polynomial, 
300; theorem, intermediate, 462; 
truth-, 107, 109 
Variable(s), 11; bound, 17, 23, 60; 
flagged, 43; free, 17; free renaming 
of a, 44n18; predicate, 11,22; 
predicate, generalized, 72; proper, 
34; propositional, 15; subject, 11 
Vector(s), 233; basis, 234; 
contravariant, 264; covariant, 264; 
549 
mUltiplication of, 267; part, 475; 
product, 266; space, 233, 238, 526n; 
space, dual, 234; subspace 243 526n' 
unit, 285 
' 
, 
, 
Vel, 13 
Verband,483 
Verknupfung, 510 
Vicious circle principle (Russell's), 535 
VINOGRADOV,405 
Void relation, 62 
VON NEUMANN, 51, 58 
WARING, problem, 406 
Well-ordered sets, 153, 155, 532 
Well-ordering(s), 64, 101; axiom, 164; 
partial, 64; theorem, 56, 525 
WESTON, J. D., 530 
WHITEHEAD, A. N., and RUSSELL, 42 
WILSON, theorem of, 384 
Word(s), 6, 230; empty, 231; problem, 
35, 232 
ZERMELO, E., 51, 535; axiom of choice, 
164 
Zero(s), 111; aleph-, 55; divisors of, 
119, 293, 322; nilpotent divisor of, 
342; element, 179,490; of a function, 
293; ideal, 338 ~ manifold of, of an 
ideal, 354; multiple, 303; mUltiplicity 
of a, 302,426; of a polynomial, 302; 
sequence, 140 
ZORN, lemma of, 164, 522; sharpened 
form of, 525 

