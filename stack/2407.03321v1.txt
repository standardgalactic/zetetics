Planetariumü™ê: A Rigorous Benchmark for
Translating Text to Structured Planning Languages
Max Zuo‚àó
Francisco Piedrahita Velez‚àó
Xiaochen Li
Michael L. Littman
Stephen H. Bach
Department of Computer Science
Brown University
{zuo, francisco, xiaochen_li, mlittman, sbach}@cs.brown.edu
Abstract
Many recent works have explored using language models for planning problems.
One line of research focuses on translating natural language descriptions of plan-
ning tasks into structured planning languages, such as the planning domain defini-
tion language (PDDL). While this approach is promising, accurately measuring
the quality of generated PDDL code continues to pose significant challenges. First,
generated PDDL code is typically evaluated using planning validators that check
whether the problem can be solved with a planner. This method is insufficient
because a language model might generate valid PDDL code that does not align
with the natural language description of the task. Second, existing evaluation sets
often have natural language descriptions of the planning task that closely resemble
the ground truth PDDL, reducing the challenge of the task. To bridge this gap, we
introduce Planetarium, a benchmark designed to evaluate language models‚Äô ability
to generate PDDL code from natural language descriptions of planning tasks. We
begin by creating a PDDL equivalence algorithm that rigorously evaluates the
correctness of PDDL code generated by language models by flexibly comparing it
against a ground truth PDDL. Then, we present a dataset of 132, 037 text-to-PDDL
pairs across 13 different tasks, with varying levels of difficulty. Finally, we eval-
uate several API-access and open-weight language models that reveal this task‚Äôs
complexity. For example, 87.6% of the PDDL problem descriptions generated
by GPT-4o are syntactically parseable, 82.2% are valid, solve-able problems, but
only 35.1% are semantically correct, highlighting the need for a more rigorous
benchmark for this problem.
1
Introduction
Recently, there has been growing interest in using large language models (LLMs) to solve planning
problems. Some research has focused on generating plans directly with LLMs Valmeekam et al.
[2023a, 2022, 2023b], Silver et al. [2022, 2023]. However, this approach has shown limited success;
GPT-4 only achieves 35% accuracy on simple planning problems Valmeekam et al. [2023a]. Another
line of research uses LLMs to convert natural language prompts into structured planning languages,
such as the planning domain definition language (PDDL) Liu et al. [2023], Xie et al. [2023b], Guan
et al. [2023], Chalvatzaki et al. [2023], Yang et al. [2023b]. Early evidence suggests this method
performs better than generating plans directly with LLMs Liu et al. [2023]. Despite its promise, there
is a lack of rigorous techniques and benchmarks for evaluating the translation of natural language
planning descriptions to PDDL.
‚àóEqual contribution.
Preprint. Under review.
arXiv:2407.03321v1  [cs.CL]  3 Jul 2024

BLOCK
BLOCK
Initial 
State
BLOCK
BLOCK
Goal 
State
(:objects a b) 
(:init (clear a)  
       (clear b)  
       (on-table a)  
       (on-table b) 
       (arm-empty)) 
(:goal (and (on a b) 
            (on-table b) 
            (clear a) 
            (arm-empty)))
(:objects a b) 
(:init (clear a)  
       (clear b)  
       (on-table a)  
       (on-table b) 
       (arm-empty)) 
(:goal (and (on a b) 
            (on-table b) 
            (clear a) 
            (arm-empty)))
(:objects a b) 
(:init (clear a)  
       (clear b)  
       (on-table a)  
       (on-table b) 
       (arm-empty)) 
(:goal (and (on a b) 
            (on-table b) 
            (clear a) 
            (arm-empty)))
(:objects a b) 
(:init (clear a)  
       (clear b)  
       (on-table a)  
       (on-table b) 
       (arm-empty)) 
(:goal (and (on a b) 
            (on-table b) 
            (clear a) 
            (arm-empty)))
Figure 1: An illustration of how multiple PDDL problem descriptions can describe the same planning
problem. All four PDDL problem descriptions represent the planning problem of stacking one block
onto another.
Translating natural language to PDDL enables a hybrid, best-of-both-worlds approach. The LLM
is responsible for interpreting natural language, and the resulting PDDL can be given to traditional,
symbolic planners that have been developed over decades Fikes and Nilsson [1971], McDermott et al.
[1998], Helmert [2006], Baier et al. [2009], Vidal and Geffner [2006]. These traditional planners are
efficient and ensure the correctness of their solutions. In contrast, leaving the planning to LLMs does
not guarantee correctness, making them unreliable for critical applications. Despite this shortcoming,
LLMs are an enticing approach, as using traditional planners requires domain expertise and expertise
in modeling planning problems. By using LLMs to translate natural language into PDDL, we can
better leverage the strengths of existing planners.
Using LLMs to translate natural language to PDDL is an instance of a code generation task. Evaluating
code generation tasks in general is highly challenging. Some benchmarks for code generation use
match-based metrics that look for segments that overlap with ground truth code Papineni et al. [2002],
Lin [2004], Ren et al. [2020], but match-based metrics cannot cover the vast space of equivalent
programs Chen et al. [2021]. Therefore, benchmarks often test functional correctness using a suite of
unit tests Roziere et al. [2020], Kulal et al. [2019]. For planning problems, existing works use ‚Äúplan
validators‚Äù to check if the generated code can be solved with a traditional planner Liu et al. [2023],
Silver et al. [2022, 2023], Guan et al. [2023]. We argue that these validators alone are insufficient to
determine if PDDL generation is correct. This is because the LLM can generate valid PDDL that has
nothing to do with the user‚Äôs instructions and still be considered correct.
A rigorous evaluation of LLMs as generators of structured planning languages requires a precise
definition of what it means for generated code to be correct, and an efficient, automatic way of
checking it. This requirement is hard because many instances of PDDL can represent the same
planning problem, but it is not always obvious when they are equivalent (Figure 1). Properly checking
PDDL equivalence requires symbolic interpretation.
To address this challenge, we introduce Planetarium, a benchmark to evaluate LLMs on translating
natural language descriptions of planning problems into PDDL. Our contributions are as follows:
‚Ä¢ Rigorous Evaluation of PDDL Equivalence. We formally define planning problem
equivalence and create an algorithm for checking whether two PDDL problems satisfy
this definition. This algorithm transforms the PDDL code into scene graphs, computes
an expansion of the goal states for both PDDL problems, and then performs isomorphism
checks between the graphs. Our method ensures two PDDL problems match if and only
if they represent the same underlying planning problem. Further, we show how to make
this algorithm practically efficient for two domains: Blocks World and Gripper McDermott
[2000] (Appendix C).
‚Ä¢ Benchmark Data for PDDL Generation. We present a dataset based on the International
Planning Competition (IPC) McDermott [2000], Vallati et al. [2015], Taitler et al. [2024],
Seipp et al. [2022], crafting 132, 037 ground truth PDDL problems and corresponding text
2

descriptions capturing a range of planning problems. Each task varies in two dimensions to
assess the difficulty of the PDDL generation task: abstraction and size.
‚Ä¢ Broad Evaluation of Current LLMs. Finally, we evaluate a range of API-access and
open-access LLMs on Planetarium. We evaluate in both a zero-shot setting and after fine-
tuning. We find that this task is very challenging. GPT-4o in a zero-shot setting gets only
35.1% correct. Instances with abstract descriptions or many propositions are particularly
challenging. Planetarium can therefore serve as a benchmark of progress on this important
problem. To enable future development and evaluation of LLMs we release all the code and
data for Planetarium at https://github.com/BatsResearch/planetarium.
2
Related Work
LLMs as Planners.
There is growing interest in using LLMs for solving planning problems.
Several works have demonstrated the potential of using LLMs for decision making processes Sharma
et al. [2022], Ren et al. [2023], Ichter et al. [2022], Singh et al. [2022]. Some techniques that enable
the use of LLMs as planners involve decomposing abstract tasks into concrete, atomic executable
actions for an agent to perform Huang et al. [2022b,a], Sharma et al. [2022]. Other approaches
generate plan actions by scoring the possible next steps in a sequence of actions Ichter et al. [2022],
Ren et al. [2023]. When using LLMs to generate plans directly, the LLM is given a natural language
representation of a planning problem with the goal of generating a plan. We refer to this line of work
as ‚ÄúLLMs as planners.‚Äù One of the main findings is that LLMs have limited ability to generate and
validate plans on their own, even for simple planning tasks Valmeekam et al. [2022], Silver et al.
[2022], Valmeekam et al. [2023b].
Planner-Augmented LLMs. Given LLMs‚Äô poor performance in classical planning tasks Valmeekam
et al. [2023a, 2022], Silver et al. [2022], new approaches extend LLMs by incorporating classical
planning techniques Liu et al. [2023], Guan et al. [2023]. Some techniques frame the problem as
a machine translation task, transforming a natural language text description of a planning problem
into PDDL to use with classical planners Liu et al. [2023], Guan et al. [2023], Xie et al. [2023a]. We
refer to this line of work as ‚ÄúPlanner-Augmented LLMs.‚Äù Other similar approaches translate natural
language into alternative representations of the planning problem, such as finite state automata Yang
et al. [2023a] or logic programming Yang et al. [2023b], to solve them.
Benchmarking LLMs on Planning Tasks. Significant efforts have been made to develop benchmarks
to assess the use of ‚ÄúLLMs as Planners.‚Äù PlanBench Valmeekam et al. [2023a] evaluates LLMs on
various planning-related tasks, including plan generation, cost-optimal planning, plan verification,
and other properties. Their work focuses on evaluating LLMs on their ability to generate plans.
In contrast Planetarium focuses on evaluating ‚ÄúPlanner-Augmented LLMs‚Äù. Here, the goal is to
determine if an LLM can successfully translate natural language descriptions of planning problems
into the correct PDDL representations of those problems.
3
Preliminaries
To present Planetarium, we first introduce planning, PDDL, and scene graphs.
3.1
Classical Planning Problems
In a classical planning problem, states are fully observable, there is a finite set of actions, and
transitions are deterministic. The goal is to transition from the initial state to the goal state following
a transition function. We use the set-theoretic definition of classical planning problems Ghallab et al.
[2004].
Definition 1. A planning problem P is denoted by the tuple (L, S, A, Œ≥, si, g), where:
‚Ä¢ L is a finite set of proposition symbols representing different facts about the world.
‚Ä¢ S ‚äÜ2L is a set of states. Each state s ‚äÜL is the set of true propositions in that state.
3

‚Ä¢ A represents the set of actions, where each action a consists of a set of preconditions that
must hold for it to be applicable and a set of effects that modify the propositions that are
true after its execution.
‚Ä¢ The transition function Œ≥ : S √ó A ‚Üí2S models how the world changes by an action.
‚Ä¢ si is the initial state of the world from which the problem begins.
‚Ä¢ g ‚äÜL represents the goal propositions, indicating which propositions must be true for a
state to be considered a goal state. The set of goal states is Sg = {s ‚ààS | g ‚äÜs}.
A plan œÄ =< a1, an, . . . , an > is a sequence of actions that leads from si to any state in Sg following
Œ≥. This plan is the solution to a planning problem P.
3.2
Planning Domain Definition Language
The Planning Domain Definition Language (PDDL) is a specialized language designed to provide
a unified way to represent planning problems. It can represent various types of planning problems,
including classical planning problems McDermott [2000], Gerevini and Long [2006]. A PDDL
planning problem consists of two files: the domain file, which describes the constant parts of the
world model, and a problem file, which specifies particular planning scenarios using the world model
outlined in the domain file.
In the domain file, we specify the set of possible actions A and their preconditions and effects, which
collectively define the transition function Œ≥. The problem file defines the initial state si and the goal
propositions g. Finally, the set of proposition symbols L is created by combining the predicates from
the domain file with the objects defined in the problem file.
Planetarium focuses on classical planning problems within the STRIPS subset of PDDL McDermott
et al. [1998], Fikes and Nilsson [1971]. STRIPS provides the basic grammar for describing actions
by specifying a set of preconditions that must be met for an action to be applicable and a set of effects
that modify the propositions that are true after the action‚Äôs execution. The expressiveness of problems
defined in STRIPS is equivalent to those characterized by the set-theoretic definition (Definition 1) of
classical planning problems Ghallab et al. [2004].
3.3
Scene Graphs
To compare different planning problems, we use scene graphs. A scene graph is a data structure
commonly used in fields such as computer vision and graphics Johnson et al. [2015], Chang et al.
[2023], rearrangement Ramachandruni et al. [2023], and planning to represent objects, their attributes,
and the relationships among them. In our work, we define scene graphs as directed graphs with types
and attributes for both nodes and edges. We represent a PDDL problem file with scene graphs as
follows. We create one scene graph (the initial scene) for the initial state and another for the set of
goal propositions (the goal scene). For every object, we create a node with an object type. Then for
every proposition that is listed in the problem file, we create a node with a proposition type. That
node is given an attribute with the name of its predicate. Then, for each argument to the predicate
in that proposition, we add an edge from the proposition node to the corresponding object. Each
such edge is given three attributes: the name of the predicate, the position of the argument (first,
second, etc.), and whether it is defined in the initial state or the goal propositions. A scene graph
is thus ({O ‚à™P}, E), where O is the set of nodes with object type, P is the set of nodes with
Proposition type, and E is the set of edges.
We further define a problem graph as the combination of an initial scene and goal scene. Given
SceneGraphinit = ({O ‚à™Pinit}, Einit) and SceneGraphgoal = ({O ‚à™Pgoal}, Egoal), then a
problem graph merges the scene graphs such that ProblemGraph = ({O ‚à™Pinit ‚à™Pgoal}, {Einit ‚à™
Egoal}). We define graph isomorphism on any of these graphs as an edge and type-preserving
bijection between nodes, meaning that two graphs share a connectivity structure where all types and
attributes match. See Appendix B for diagrams of scene and problem graphs.
4

4
Evaluation Framework
In this section, we describe the design of Planetarium. Our goal is to systematically evaluate how
well LLMs can translate natural language descriptions of planning tasks into structured planning
languages. Planetarium consists of two components: an algorithm that validates whether a ground
truth PDDL problem file and an LLM-generated PDDL problem file are equivalent, and a curated
dataset of planning tasks against which an LLM can be evaluated.
4.1
Planning Problem Equivalence
The first step to benchmarking PDDL generation is determining how to decide whether the generated
code matches ground truth code. One might assume that checking if two PDDL problem files are
equivalent is straightforward. However, the same initial state, goal state pair could be represented by
many PDDL problem files, as shown in Figure 1.
Given these difficulties, we propose a definition of equivalence in terms of classical planning problems.
The main idea is to find a bijective function between the sets of proposition symbols L of each problem,
such that when applied to the other elements, this function makes both problems equal. This definition
assumes that the set of actions A and the transition function Œ≥ are shared between the two problems.
Our formal definition of equivalence between two planning problems is:
Definition 2. Two planning problems P1 = (L1, S1, A, Œ≥, s1
i , g1) and P2 = (L2, S2, A, Œ≥, s2
i , g2)
with the same actions A and transition function Œ≥ are equivalent if there exists a bijective function
f : L1 ‚ÜíL2 such that:
1. S2 = {{f(p) : p ‚ààs} : s ‚ààS1}
2. s2
i = {f(p) : p ‚ààs1
i }
3. Sg2 = {{f(p) : p ‚ààs} : s ‚ààSg1}
This definition is not directly usable for checking equivalence between two PDDL problem files. This
is because our definition relies on finding a bijection between the sets L of each problem, and PDDL
does not define these sets directly. To build the set L with PDDL, one needs to use the predicates
in the domain file and the objects in the problem file, instantiating each predicate with all possible
objects they might take. Since the set of actions A and the transition function Œ≥ are defined in the
PDDL domain file, and since the equivalence definition assumes they are shared, we can assume
the entire PDDL domain is shared. This fact entails that the predicates will be shared, making it
necessary to look for bijective functions for PDDL only over the objects. The challenge is that each
PDDL problem file can correspond to many pairs of initial and goal states because the set of goal
propositions makes an open-world assumption. That set can leave implicit trivial propositions that
are necessarily true and therefore do not change the underlying planning problem. We must therefore
fully specify the goal, meaning that we identify all propositions that are true in all reachable goal
states when starting from the initial state.
Our algorithm for checking equivalence is summarized in Algorithm 1. First, we transform each set
of initial state and goal state propositions into scene graphs. Second, we fully specify the goal scene
graphs by adding all trivially true edges. Finally, we join the initial state scene graph with each goal
state graph to create problem graphs and look for a bijection between objects such that the problem
graphs are isomorphic. We now discuss these components in more detail.
Transform to Scene Graphs. From each PDDL problem file, we generate two scene graphs: one
for the initial state and another for the goal state (lines 2‚Äì3). For each transformation, we first
create an object node for each object. Then, for each proposition in the collection, we create a
new proposition node and create edges between the proposition node and the objects it takes as
arguments. Edge attributes denote argument order, predicate type, and whether the proposition is in
an initial or goal scene. See Section 3.3 for further details.
Check Easy Cases. For speed, we check several cases and return early if we can (lines 5‚Äì7). First, if
the number of object nodes in each graph is not equal, the problems cannot be equivalent. Second, if
the initial scenes are not isomorphic, then the problems cannot be equivalent. Finally, if the problem
graphs, composed of the initial and goal scenes, are isomorphic, then the problems are equivalent.
5

Algorithm 1 Planning Problem Equivalence
1: function ISEQUIVALENT(Pa, Pb, isPlaceholder)
2:
si,a, ga ‚ÜêtoSceneGraph(Pa)
3:
si,a, ga ‚ÜêtoSceneGraph(Pb)
4:
5:
if canFastEquivalence(si,a, ga, si,b, gb) then
6:
return fastEquivalence(si,b, ga, si,a, gb)
7:
end if
8:
9:
g‚ãÜ
a ‚ÜêfullySpecify(si,a, ga)
10:
g‚ãÜ
b ‚ÜêfullySpecify(si,b, gb)
11:
12:
if isPlaceholder then
13:
return isIsomorphic(si,a, si,b) ‚àßisIsomorphic(g‚ãÜ
a, g‚ãÜ
b)
14:
else
15:
pa ‚Üêjoin(si,a, g‚ãÜ
a)
16:
pb ‚Üêjoin(si,b, g‚ãÜ
b)
17:
18:
return isIsomorphic(pa, pb)
19:
end if
20: end function
Fully Specify the Goal Scenes. If the input is not an easy case, then we have to reason about
the sets of goal states defined by the goal scenes. Condition 3 of Definition 2 requires that the
sets of goal states that are consistent with the given goal propositions be equal after substituting
matching propositions. Since PDDL uses the open-world assumption for goals, we have to identify
all propositions that are true in all reachable goal states when starting from the initial state for each
problem. The function fullySpecify finds all such propositions and adds them to the goal scenes as
additional proposition nodes with the corresponding edges and attributes (lines 9‚Äì10). We show
how to implement fullySpecify efficiently for Blocks World and Gripper in Appendix C.
PDDL without Object Identity. Our algorithm runs in two modes, depending on the type of problem
we are checking. Sometimes we want to compare a generated PDDL problem file with many ground
truth problem files and see if the generated file matches any one of them. For example, if the natural
language description says to ‚Äúmake a tower of height 3,‚Äù the specific blocks to use are unspecified, and
any permutation of blocks that builds a tower of height 3 should be considered correct. Concretely,
we want to treat the objects in the PDDL goal states as placeholders and accept any permutation of
them. We check this condition when isPlaceholder is True (determined by the problem type) simply
by checking isomorphism between initial and goal scenes separately rather than combining them into
problem graphs (line 13).
PDDL with Object Identity. If isPlaceholder is False then we want to check whether the problem
files are precisely equivalent under Defintion 2, meaning that the objects in the initial scenes corre-
spond to the same objects in the goal scenes as well. We first join the corresponding initial and scene
graphs into problem graphs as described in Section 3.3 (lines 15‚Äì16). Then we check whether the
two problem graphs are isomorphic (line 18).
We illustrate Algorithm 1 with examples in Appendix B. We also formally state its correctness, with
the proof in Appendix A.
Theorem 1. isEquivalent(Pa, Pb, False) returns True if and only if the PDDL problem files Pa and
Pb represent equivalent planning problems under Definition 2. isEquivalent(Pa, Pb, True) returns
True if and only if Pa represents a planning problem that is equivalent to some planning problem
represented by Pb after a permutation of the objects in its goal state.
4.2
The Dataset
The Planetarium dataset includes 132,037 text-to-PDDL pairs across 13 tasks, derived from the
Blocks World and Gripper domains Seipp et al. [2022], McDermott [2000].
6

Table 1: A breakdown of the Planetarium dataset by the level of abstractness of the text description
and number of propositions in the ground truth PDDL problem (size). Each instance is a ground truth
PDDL problem description and text description pair.
Domain
Total
Abstractness
Num. of Ground Truth Propositions (Size)
Explicit to
Abstract to
Explicit
Abstract
Explicit
Abstract
1-20
21-40
41-60
61-80
>80
Blocks World
92,350
23,033
23,087
23,086
23,144
1,012
10,765
50,793
26,316
3,464
Gripper
39,687
10,632
9,518
10,313
9,224
379
2,112
9,412
25,346
2,438
Dataset Construction.
We focus on these two domains as they are commonly used in other works
Valmeekam et al. [2023a], Liu et al. [2023], but are nevertheless challenging. Each text-to-PDDL
pair consists of a prompt detailing the initial and goal states, along with the corresponding ground
truth PDDL. (See Appendix D for examples.) Table 1 shows a breakdown of the Planetarium data
by text description abstractness and number of propositions. Each instance is a ground truth PDDL
problem description and text description pair.
We vary the data along two dimensions: abstractness (explicit vs abstract) and size. Explicit planning
problem text descriptions correspond directly to propositions found in the problem PDDL (e.g.,
‚Äúblock 1 is on block 2‚Äù). Abstract text descriptions instead summarize a state (e.g., ‚Äúall blocks are in a
single tower‚Äù). Since our text descriptions describe both initial and goal states, each can be either
an abstract or explicit description, leading to four possible categories: explicit to explicit, explicit
to abstract, abstract to explicit, and abstract to abstract. We measure the size of a problem by the
number of propositions listed in the ground truth problem PDDL. Larger problems typically pose
greater challenges for LLMs.
To obtain interesting problems for each domain, we crafted a set of tasks instead of randomly
generating instances. Below are descriptions of each domain and their corresponding tasks.
Blocks World. This domain involves using a robotic hand to manipulate a set of blocks arranged in
various configurations on a table. We have designed the following tasks for this domain:
‚Ä¢ Stack: Arrange all the blocks into a single tower.
‚Ä¢ Unstack: Dismantle any tower so that all blocks are separately placed on the table.
‚Ä¢ Holding a Block: Similar to unstacking, but one block remains held by the robot.
‚Ä¢ Staircase: Create stacks of increasing sizes from one upwards until no blocks are left.
‚Ä¢ Equal Towers: Arrange the blocks into towers of equal height.
‚Ä¢ Swap: With two towers, swap the base blocks and leave the rest of the structure unchanged.
‚Ä¢ Invert: Invert each stack so the entire sequence of blocks is reversed.
‚Ä¢ Towers: Build towers to match a specified list of heights.
Gripper. This domain features a robot equipped with grippers, tasked with transporting balls from
one room to another. We have designed the following tasks for this domain:
‚Ä¢ Single Room: Move all balls to one room.
‚Ä¢ Evenly Distribute: Position the balls so each room has the same number of balls.
‚Ä¢ Arbitrarily Distribute: Move the balls according to a predefined list that specifies the
number of balls per room.
‚Ä¢ Swap Rooms: Exchange the balls between two rooms.
‚Ä¢ Move to Max: Move all balls to the room currently containing the most balls.
‚Ä¢ Move to Min: Move all balls to the room with the least number of balls.
5
Evaluating LLMs on Planetarium
As an initial snapshot of the field‚Äôs current state, we evaluate several API-access and open-weight
language models on Planetarium in both zero-shot and fine-tuned settings. We find that while
7

powerful models like GPT-4o can often generate valid PDDL problems (in the sense that some plan
solves them), they are rarely correct. This result underscores the need for Planetarium‚Äôs rigorous
approach to evaluation of PDDL generation. The code to recreate the entire evaluation is available at
https://github.com/BatsResearch/planetarium.
Models. We evaluate one API-access model (GPT-4o) and three open-weight models (Mistral v0.3
7B Instruct Jiang et al. [2023], and Gemma 1.1 IT 2B & 7B Team et al. [2024]).
Evaluation Protocol.
We evaluate models on the Planetarium test set, which we built by randomly splitting the Planetarium
dataset with an 80/20 train/test split. Models are prompted with the natural language description
of the task along with the respective domain PDDL. We measure three metrics: the number of
syntactically parseable problems generated, the number of solve-able problems, and the number of
semantically correct problems. We say a model output is parseable if a PDDL parser supporting
:strips can parse a valid PDDL problem from a substring in the output and if it can be converted
into our graph representation. A problem is solve-able if it is parseable and there exists a plan that can
be applied to the initial scene that results in the goal scene. Due to the size and complexity of some
of the problems in our dataset, a generalized classical planner cannot always reliably and quickly
return solutions. Therefore, we write specialized planners that work for all problems in our dataset,
and generally, all validly defined blocksworld and gripper domain problems, except a few invalid
edge cases (e.g., one block on top of two blocks at a time, holding two blocks, etc.). To evaluate the
correctness of model outputs, they must be first parseable and solve-able. Then, we use our PDDL
equivalence algorithm to verify equivalence to our ground truth PDDL. We found our equivalence
algorithm to take on average 12ms per example to compute on an M2 Apple Silicon laptop with batch
parallelization.
Fine-Tuning. We fine-tuned the open-weight models using QLoRA with a rank of 16, adhering to
the hyperparameter recommendations for small models provided by the original authors Dettmers
et al. [2023]. Models were loaded in 4-bit precision and were trained over the training set for a
single epoch. Fine-tuning for each model used either two NVIDIA GeForce RTX 3090 GPUs or two
NVIDIA A6000 GPUs, operating with data parallelization for approximately 15 hours. We truncate
the longest 5% of our training dataset due to GPU memory constraints. Experiments were conducted
using a GPU cluster at the Center for Computation and Visualization, Brown University. Additional
experiment details are provided in Appendix F.
Results.
The performance of GPT-4o, Mistral v0.3 7B Instruct, and Gemma 1.1 IT 2B & 7B on
the Planetarium test set is shown in Figure 2. We report the percentage of generated plans that were
parseable and correct and report results from zero-shot and fine-tuned settings.
Analysis and Discussion. All models exhibited poor zero-shot performance, with GPT-4o achieving
the highest accuracy. A breakdown of GPT-4o‚Äôs zero-shot performance, the only model to achieve
significant zero-shot performance, shows abstract task descriptions are harder to translate than explicit
ones, and fully explicit task descriptions make generating parseable PDDL code easier (Figure 3).
Gemma 1.1 IT 2B
Gemma 1.1 IT 7B
Mistral v0.3 Instruct 7B
GPT-4o
Zero-shot
Fine-tuned
Zero-shot
Fine-tuned
Zero-shot
Fine-tuned
Zero-shot
0%
25%
50%
75%
100%
Problems (%)
0%
99.38%
0%
98.40%
0%
94.21%
2.26%
99.73%
< 0.01%
99.22%
0%
98.79%
0.80%
99.89%
0.52%
99.39%
< 0.01%
99.00%
89.14%
82.22%
35.12%
Parseable
Solve-able*
Correct
Figure 2: Performance of various models on the Planetarium test set.
8

Fine-tuning improved performance across all open-weight models, with Mistral v0.3 7B Instruct
achieving the highest accuracy. More experiments and analyses are shown in Appendix G.
6
Conclusion, Limitations, and Future Work
Planetarium is a new benchmark for assessing the ability of LLMs to translate natural language
descriptions of planning problems into PDDL. A potential societal impact of this research is ensuring
the correctness of translating natural language into structured planning languages. If this translation
method becomes widespread but its evaluation remains inaccurate, systems could produce misleading
or misaligned results that could cause harm if acted upon. Planetarium highlights the importance of
assessing the correctness of translations. We achieve this by reasoning about PDDL semantics and
the inherent structure of classical planning problems.
Planetarium has a few important limitations: Planetarium currently only supports the Blocks World
and Gripper domains. While these domains have been popular for studying LLMs and their relation
to planning, incorporating more expressive domains in the future will widen the scope of Planetarium.
This benchmark is also currently restricted to the STRIPS subset of PDDL. Extending it to support
more expressive subsets of PDDL will allow us to evaluate more complex, real-world planning
problems such as non-deterministic, temporal, and numeric domains. Our work reveals generating
semantically correct structured planning language descriptions to be a challenging task for language
models, with models like GPT-4o achieving 35.1% zero-shot accuracy but producing valid, seemingly
correct descriptions 82.2% of the time. We hope that Planetarium will drive progress on hybrid
approaches combining LLMs and classic planners, setting a standard for the evaluation of such tasks.
Acknowledgments and Disclosure of Funding
This research is supported in part by the Office of Naval Research (ONR) award N00014-20-1-2115.
We gratefully acknowledge support from Cisco, Cognex, and the Brown Computer Science Faculty
Innovators Fund. Disclosure: Stephen Bach is an advisor to Snorkel AI, a company that provides
software and services for data-centric artificial intelligence.
References
Jorge A. Baier, Fahiem Bacchus, and Sheila A. McIlraith. A heuristic search approach to planning
with temporally extended preferences. Artificial Intelligence, 173(5):593‚Äì618, 2009. ISSN 0004-
3702. doi: https://doi.org/10.1016/j.artint.2008.11.011. URL https://www.sciencedirect.
com/science/article/pii/S0004370208001975. Advances in Automated Plan Generation.
Georgia Chalvatzaki, Ali Younes, Daljeet Nandha, An Thai Le, Leonardo FR Ribeiro, and Iryna
Gurevych. Learning to reason over scene graphs: a case study of finetuning gpt-2 into a robot
language model for grounded task planning. Frontiers in Robotics and AI, 10, 2023.
to
Abstract Goal Scene
to
Explicit Goal Scene
Abstract Initial Scene
Explicit Initial Scene
Abstract Initial Scene
Explicit Initial Scene
0%
25%
50%
75%
100%
Problems (%)
83.15%
75.88%
19.84%
74.33%
63.44%
27.45%
99.80%
94.31%
30.71%
99.98%
96.08%
63.28%
Parseable
Solve-able*
Correct
Figure 3: Breakdown of GPT-4o zero-shot performance at varying levels of abstraction.
9

Xiaojun Chang, Pengzhen Ren, Pengfei Xu, Zhihui Li, Xiaojiang Chen, and Alex Hauptmann. A
comprehensive survey of scene graphs: Generation and application. IEEE Transactions on Pattern
Analysis and Machine Intelligence, 45(1):1‚Äì26, 2023. doi: 10.1109/TPAMI.2021.3137605.
Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Pond√© de Oliveira Pinto, Jared
Kaplan, Harrison Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri,
Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan,
Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian,
Clemens Winter, Philippe Tillet, Felipe Petroski Such, Dave Cummings, Matthias Plappert, Fotios
Chantzis, Elizabeth Barnes, Ariel Herbert-Voss, William Hebgen Guss, Alex Nichol, Alex Paino,
Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders,
Christopher Hesse, Andrew N. Carr, Jan Leike, Joshua Achiam, Vedant Misra, Evan Morikawa,
Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder, Bob
McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, and Wojciech Zaremba. Evaluating
large language models trained on code. CoRR, abs/2107.03374, 2021. URL https://arxiv.
org/abs/2107.03374.
Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, and Luke Zettlemoyer. Qlora: Efficient finetuning
of quantized llms, 2023.
Richard E. Fikes and Nils J. Nilsson. Strips: A new approach to the application of theorem proving
to problem solving. Artificial Intelligence, 2(3):189‚Äì208, 1971. ISSN 0004-3702. doi: https:
//doi.org/10.1016/0004-3702(71)90010-5. URL https://www.sciencedirect.com/science/
article/pii/0004370271900105.
A. Gerevini and D. Long. Plan constraints and preferences in pddl3. In ICAPS Workshop on Soft
Constraints and Preferences in Planning, 2006.
Malik Ghallab, Dana Nau, and Paolo Traverso. Automated planning. The Morgan Kaufmann Series
in Artificial Intelligence. Morgan Kaufmann, Oxford, England, 2004.
Lin Guan, Karthik Valmeekam, Sarath Sreedharan, and Subbarao Kambhampati. Leveraging pre-
trained large language models to construct and utilize world models for model-based task planning.
arXiv preprint arXiv:2305.14909, 2023.
Malte Helmert. The fast downward planning system. J. Artif. Int. Res., 26(1):191‚Äì246, jul 2006.
ISSN 1076-9757.
Wenlong Huang, Pieter Abbeel, Deepak Pathak, and Igor Mordatch. Language models as zero-
shot planners: Extracting actionable knowledge for embodied agents, 2022a.
URL https:
//openreview.net/forum?id=6NT1a56mNim.
Wenlong Huang, Fei Xia, Ted Xiao, Harris Chan, Jacky Liang, Pete Florence, Andy Zeng, Jonathan
Tompson, Igor Mordatch, Yevgen Chebotar, Pierre Sermanet, Tomas Jackson, Noah Brown, Linda
Luu, Sergey Levine, Karol Hausman, and brian ichter. Inner monologue: Embodied reasoning
through planning with language models. In 6th Annual Conference on Robot Learning, 2022b.
URL https://openreview.net/forum?id=3R3Pz5i0tye.
Brian Ichter, Anthony Brohan, Yevgen Chebotar, Chelsea Finn, Karol Hausman, Alexander Herzog,
Daniel Ho, Julian Ibarz, Alex Irpan, Eric Jang, Ryan Julian, Dmitry Kalashnikov, Sergey Levine,
Yao Lu, Carolina Parada, Kanishka Rao, Pierre Sermanet, Alexander Toshev, Vincent Vanhoucke,
Fei Xia, Ted Xiao, Peng Xu, Mengyuan Yan, Noah Brown, Michael Ahn, Omar Cortes, Nicolas
Sievers, Clayton Tan, Sichun Xu, Diego Reyes, Jarek Rettinghouse, Jornell Quiambao, Peter
Pastor, Linda Luu, Kuang-Huei Lee, Yuheng Kuang, Sally Jesmonth, Nikhil J. Joshi, Kyle Jeffrey,
Rosario Jauregui Ruano, Jasmine Hsu, Keerthana Gopalakrishnan, Byron David, Andy Zeng, and
Chuyuan Kelly Fu. Do as i can, not as i say: Grounding language in robotic affordances. In CoRL,
pages 287‚Äì318, 2022. URL https://proceedings.mlr.press/v205/ichter23a.html.
Albert Q Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot,
Diego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, et al.
Mistral 7b. arXiv preprint arXiv:2310.06825, 2023.
10

Justin Johnson, Ranjay Krishna, Michael Stark, Li-Jia Li, David A. Shamma, Michael S. Bernstein,
and Li Fei-Fei. Image retrieval using scene graphs. In 2015 IEEE Conference on Computer Vision
and Pattern Recognition (CVPR), pages 3668‚Äì3678, 2015. doi: 10.1109/CVPR.2015.7298990.
Sumith Kulal, Panupong Pasupat, Kartik Chandra, Mina Lee, Oded Padon, Alex Aiken, and Percy S
Liang. Spoc: Search-based pseudocode to code. In H. Wallach, H. Larochelle, A. Beygelzimer,
F. d'Alch√©-Buc, E. Fox, and R. Garnett, editors, Advances in Neural Information Processing
Systems, volume 32. Curran Associates, Inc., 2019. URL https://proceedings.neurips.cc/
paper_files/paper/2019/file/7298332f04ac004a0ca44cc69ecf6f6b-Paper.pdf.
Chin-Yew Lin. ROUGE: A package for automatic evaluation of summaries. In Text Summariza-
tion Branches Out, pages 74‚Äì81, Barcelona, Spain, July 2004. Association for Computational
Linguistics. URL https://aclanthology.org/W04-1013.
Bo Liu, Yuqian Jiang, Xiaohan Zhang, Qiang Liu, Shiqi Zhang, Joydeep Biswas, and Peter Stone.
Llm+ p: Empowering large language models with optimal planning proficiency. arXiv preprint
arXiv:2304.11477, 2023.
Drew McDermott, Malik Ghallab, Adele Howe, Craig Knoblock, Ashwin Ram, Manuela Veloso,
Daniel Weld, and David Wilkins. Pddl-the planning domain definition language. Technical Report,
Tech. Rep., 1998.
Drew M. McDermott. The 1998 ai planning systems competition. AI Magazine, 21(2):35, Jun.
2000. doi: 10.1609/aimag.v21i2.1506. URL https://ojs.aaai.org/aimagazine/index.
php/aimagazine/article/view/1506.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. Bleu: a method for automatic
evaluation of machine translation. In Proceedings of the 40th annual meeting of the Association for
Computational Linguistics, ACL ‚Äô02, page 311‚Äì318, USA, 2002. Association for Computational
Linguistics.
doi: 10.3115/1073083.1073135.
URL https://doi.org/10.3115/1073083.
1073135.
Kartik Ramachandruni, Max Zuo, and Sonia Chernova. Consor: A context-aware semantic object
rearrangement framework for partially arranged scenes, 2023.
Allen Z. Ren, Anushri Dixit, Alexandra Bodrova, Sumeet Singh, Stephen Tu, Noah Brown, Peng
Xu, Leila Takayama, Fei Xia, Jake Varley, Zhenjia Xu, Dorsa Sadigh, Andy Zeng, and Anirudha
Majumdar. Robots that ask for help: Uncertainty alignment for large language model planners. In
7th Annual Conference on Robot Learning, 2023. URL https://openreview.net/forum?id=
4ZK8ODNyFXx.
Shuo Ren, Daya Guo, Shuai Lu, Long Zhou, Shujie Liu, Duyu Tang, Neel Sundaresan, Ming Zhou,
Ambrosio Blanco, and Shuai Ma. Codebleu: a method for automatic evaluation of code synthesis,
2020.
Baptiste Roziere, Marie-Anne Lachaux, Lowik Chanussot, and Guillaume Lample. Unsupervised
translation of programming languages. In Proceedings of the 34th International Conference on
Neural Information Processing Systems, NIPS ‚Äô20, Red Hook, NY, USA, 2020. Curran Associates
Inc. ISBN 9781713829546.
Jendrik Seipp, √Ålvaro Torralba, and J√∂rg Hoffmann. PDDL generators. https://doi.org/10.
5281/zenodo.6382173, 2022.
Pratyusha Sharma, Antonio Torralba, and Jacob Andreas. Skill induction and planning with latent
language. In Smaranda Muresan, Preslav Nakov, and Aline Villavicencio, editors, Proceedings of
the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),
pages 1713‚Äì1726, Dublin, Ireland, May 2022. Association for Computational Linguistics. doi:
10.18653/v1/2022.acl-long.120. URL https://aclanthology.org/2022.acl-long.120.
Tom Silver, Varun Hariprasad, Reece S Shuttleworth, Nishanth Kumar, Tom√°s Lozano-P√©rez, and
Leslie Pack Kaelbling. Pddl planning with pretrained large language models. In NeurIPS 2022
Foundation Models for Decision Making Workshop, 2022. URL https://openreview.net/
forum?id=1QMMUB4zfl.
11

Tom Silver, Soham Dan, Kavitha Srinivas, Joshua B. Tenenbaum, Leslie Pack Kaelbling, and Michael
Katz. Generalized planning in pddl domains with pretrained large language models. In PRL
Workshop Series ‚Äì Bridging the Gap Between AI Planning and Reinforcement Learning, 2023.
URL https://openreview.net/forum?id=ilHDGs2clY.
Ishika Singh, Valts Blukis, Arsalan Mousavian, Ankit Goyal, Danfei Xu, Jonathan Tremblay, Dieter
Fox, Jesse Thomason, and Animesh Garg. Progprompt: Generating situated robot task plans using
large language models. CoRR, abs/2209.11302, 2022. URL https://doi.org/10.48550/
arXiv.2209.11302.
Ayal Taitler, Ron Alford, Joan Espasa, Gregor Behnke, Daniel Fi≈°er, Michael Gimelfarb, Florian
Pommerening, Scott Sanner, Enrico Scala, Dominik Schreiber, Javier Segovia-Aguas, and Jendrik
Seipp. The 2023 international planning competition. AI Magazine, April 2024. ISSN 2371-9621.
doi: 10.1002/aaai.12169. URL http://dx.doi.org/10.1002/aaai.12169.
Gemma Team, Thomas Mesnard, Cassidy Hardin, Robert Dadashi, Surya Bhupatiraju, Shreya Pathak,
Laurent Sifre, Morgane Rivi√®re, Mihir Sanjay Kale, Juliette Love, et al. Gemma: Open models
based on gemini research and technology. arXiv preprint arXiv:2403.08295, 2024.
Mauro Vallati, Lukas Chrpa, Marek Grze¬¥s, Thomas Leo McCluskey, Mark Roberts, Scott Sanner,
and Managing Editor. The 2014 international planning competition: Progress and trends. AI
Magazine, 36(3):90‚Äì98, Sep. 2015. doi: 10.1609/aimag.v36i3.2571. URL https://ojs.aaai.
org/aimagazine/index.php/aimagazine/article/view/2571.
Karthik Valmeekam, Alberto Olmo, Sarath Sreedharan, and Subbarao Kambhampati. Large language
models still can‚Äôt plan (a benchmark for llms on planning and reasoning about change). arXiv
preprint arXiv:2206.10498, 2022.
Karthik Valmeekam, Matthew Marquez, Alberto Olmo, Sarath Sreedharan, and Subbarao Kamb-
hampati. Planbench: An extensible benchmark for evaluating large language models on planning
and reasoning about change. In Thirty-seventh Conference on Neural Information Processing
Systems Datasets and Benchmarks Track, 2023a. URL https://openreview.net/forum?id=
YXogl4uQUO.
Karthik Valmeekam, Matthew Marquez, Sarath Sreedharan, and Subbarao Kambhampati. On the
planning abilities of large language models - a critical investigation. In Thirty-seventh Conference
on Neural Information Processing Systems, 2023b. URL https://openreview.net/forum?
id=X6dEqXIsEW.
Vincent Vidal and H√©ctor Geffner. Branching and pruning: An optimal temporal pocl planner based
on constraint programming. Artificial Intelligence, 170(3):298‚Äì335, 2006. ISSN 0004-3702.
doi: https://doi.org/10.1016/j.artint.2005.08.004. URL https://www.sciencedirect.com/
science/article/pii/S0004370205001281.
Yaqi Xie, Chen Yu, Tongyao Zhu, Jinbin Bai, Ze Gong, and Harold Soh. Translating natural language
to planning goals with large-language models. arXiv preprint arXiv:2302.05128, 2023a.
Yaqi Xie, Chen Yu, Tongyao Zhu, Jinbin Bai, Ze Gong, and Harold Soh. Translating natural language
to planning goals with large-language models. arXiv preprint arXiv:2302.05128, 2023b.
Yunhao Yang, Jean-Raphael Gaglione, Cyrus Neary, and ufuk topcu. Large language models for
verifiable sequential decision-making in autonomous systems. In 2nd Workshop on Language and
Robot Learning: Language as Grounding, 2023a. URL https://openreview.net/forum?id=
3IDdNlRbwk.
Zhun Yang, Adam Ishay, and Joohyung Lee. Coupling large language models with logic programming
for robust and general reasoning from text. arXiv preprint arXiv:2307.07696, 2023b.
12

A
Proof of Theorem 1
Proposition 1. isEquivalent(Pa, Pb, False) returns True if and only if the PDDL problem files
Pa and Pb represent equivalent planning problems under Definition 2.
Proof. To prove this proposition, we need to prove each direction of the biconditional. First, we will
prove the forward implication. There are two possible ways the algorithm can return True: Either in
the isIsomorphic check (line 18) or in fastEquivalence (line 6).
Case 1: When isIsomorphic(pa, pb) returns True, we know that there exists a bijection œÜ from
vertices Vpa to vertices Vpb. Since œÜ is a type-preserving bijection, it means the two graphs
share a connectivity structure where all types and attributes match.
By using Lemma 1, we can build a new bijection f from œÜ. Instead of mapping vertices in
the scene graph, f maps propositions from La in planning problem Pa to propositions in
Lb in planning problem Pb. Given that œÜ is a type-preserving bijection, we know that the
bijection f derived from œÜ also maps objects to objects, predicates to predicates, vertices in
the initial scene si,a to vertices in si,b, and vertices in the goal scene g‚àó
a to vertices in g‚àó
b.
To prove Property 1, we can build the set La for each planning problem by taking each
predicate in the PDDL domain and instantiating it with all possible combinations of objects
from the problem PDDL Pa. Then, we can construct the set of all possible states of the
problem by taking the power set Sa = 2La. For each proposition p ‚ààs in each state s ‚ààSa,
we apply the bijection f to show that we get Sb.
S = {{f(p) : p ‚ààs} : s ‚ààSa}
(1)
S = {{‚ü®œÜ(qa), œÜ(oa
1), œÜ(oa
2), . . . , œÜ(oa
k)‚ü©: p ‚ààs} : s ‚ààSa}
(2)
S = {{‚ü®qb, ob
1, ob
2, . . . ob
k‚ü©: p ‚ààs} : s ‚ààSa}
(3)
S = {{pb : p ‚ààs} : s ‚ààSa}
(4)
S = Sb
(5)
To prove Property 2, we go through each proposition p in the initial state sa
i of the problem
PDDL Pa, and apply the bijection f to show that we get sb
i.
si = {f(pa) : pa ‚ààsa
i }
(6)
si = {‚ü®œÜ(qa), œÜ(oa
1), œÜ(oa
2), . . . , œÜ(oa
k)‚ü©: pa ‚ààsa
i }
(7)
si = {‚ü®qb, ob
1, ob
2, . . . ob
k‚ü©: pa ‚ààsa
i }
(8)
si = {pb : pa ‚ààsa
i }
(9)
si = sb
i
(10)
To prove Property 3, we first observe that the fullySpecify function adds all possible
trivial propositions to the goal scene graph. By definition, trivial propositions are those that
are known not to change the underlying planning problem when added or removed. We can
use the same bijection f constructed from œÜ. We don‚Äôt need to add or remove non-trivial
predicates, as doing so would change the planning problem by definition. This implies that
the augmented goal state represents any other possible goal state in Sg. With this, we can
use the bijection f built from œÜ to apply it to any state in Sga and show that we get Sgb.
Sg = {{f(p) : p ‚ààs} : s ‚ààSga}
(11)
Sg = {{‚ü®œÜ(qa), œÜ(oa
1), œÜ(oa
2), . . . , œÜ(oa
k)‚ü©: p ‚ààs} : s ‚ààSga}
(12)
Sg = {‚ü®qb, ob
1, ob
2, . . . ob
k‚ü©: p ‚ààs} : s ‚ààSga}
(13)
Sg = {{pb : p ‚ààs} : s ‚ààSga}
(14)
Sg = Sgb
(15)
13

Case 2: We can use the same arguments from Case A with one slight modification.
Here,
fastEquivalence returns True only if isIsomorphic(join(si,a, ga), join(si,b, gb))
returns True. The difference with Case 1 is that we join the initial states with the goal
propositions scene graph g instead of the fully specified scene graph g‚ãÜ.
In Case 1 we have proven that when isIsomorphic(pa, pb) returns True, the planning
problems Pa and Pb are equivalent under the bijection f. Since pa = join(si,a, g‚ãÜ
a) and
pb = join(si,b, g‚ãÜ
b), we can let g‚ãÜ
a = ga and g‚ãÜ
b = gb. This is because, by definition, trivial
propositions do not change the underlying planning problem when added or removed, and
in this case, we are only removing trivial propositions. Hence, by the proof of Case A we
conclude that this case has also to be true.
Now, we will prove the backward implication. In this case, we will assume that there exists a bijection
f that follows properties 1, 2, and 3 of Definition 2. By Lemma 1, we know that f comes from œÜ,
and since both are bijections, we can recover œÜ by doing the inverse process. We need to prove that
these conditions lead to isIsomorphic (line 18) or fastEquivalence (line 6) returning True.
Since there exists a bijection œÜ that comes from f, the number of objects must be the same for
planning problems Pa and Pb, as stated in Property 1. With Property 2, we know that this bijection
œÜ must also make the initial scenes isomorphic. Assume that the sets of goal propositions have the
same size. By using Property 3, we know that the bijection œÜ would make fastEquivalence (line
6) return True.
Conversely, assume that the sets of goal propositions have different sizes.
In this case,
canFastEquivalence would not allow fastEquivalence to execute.
In the case of
isIsomorphic (line 18), we know that pa = join(si,ag‚ãÜ
a) and pb = join(si,b, g‚ãÜ
b). Since
we know that we can construct the bijection œÜ that maps vertices from the bijection f, we also
know that since œÜ comes from f, this bijection respects initial states (Property 2) and goal states
(Property 3). Therefore, isIsomorphic(pa, pb) must return True.
With this, we have proven that if two problems are equivalent under Definition 2, then the equivalence
algorithm must return True.
Since we have proven both directions of the biconditional, Proposition 1 is true.
Proposition 2. isEquivalent(Pa, Pb, True) returns True if and only if Pa represents a planning
problem that is equivalent (under Definition 2) to some planning problem represented by Pb after a
permutation of the objects in its goal state.
Proof. To prove this proposition, we need to prove each direction of the biconditional. First, we will
prove the forward implication. There are two possible ways the algorithm can return True: Either in
fastEquivalence (line 6) or in isIsomorphic(si,a, si,b) ‚àßisIsomorphic(g‚ãÜ
a, g‚ãÜ
b).
To prove the case where fastEquivalence (line 6) returns True, we can use the same argument as
in Case A of the forward implication in the proof of Proposition 1. This is because the placeholder
being True does not affect the fastEquivalence function.
Now, assume that isIsomorphic(si,a, si,b) ‚àßisIsomorphic(g‚ãÜ
a, g‚ãÜ
b) is True. This implies that
there exist two bijections: one œÜ on the vertices Vsi,a to Vsi,b, and another œà between vertices Vg‚ãÜ
a
to Vg‚ãÜ
b . Now, by using Lemma 1, we can build two new bijections, f and h, that map between
propositions in L instead of nodes in the scene graph, as œÜ and œà do.
Since the underlying mappings of f and h can be different, we need a way to combine them into a
single bijection. One way to construct this bijection is to permute the mappings of f until they fit the
mappings of h. This implies that there are many pairs of f and h, and each pair can be combined
into a global bijection using function composition f ‚ó¶h. For each of these permutations, we can
then use the arguments in Case A of the proof of Proposition 1 to show that these pairs hold all three
properties of Definition 2.
Now, we will prove the backward implication. First, since fastEquivalence remains the same, we
do not need to prove anything new about it; we can simply reuse the previous results.
Assume Pa represents a planning problem that is equivalent to some planning problem represented by
Pb after a permutation of the objects in its goal state. This implies that there are several bijections f
14

from the predicates in Pa to the predicates in Pb. For each of these bijections f, we can use Lemma 1
to transform it into œÜ. Since we know by Property2 that œÜ maps initial states, there is an isomorphism
between the initial states. By Property 3, we know that œÜ maps any goal state of Pa to any other
possible state in Pb. Hence, s‚ãÜ
a has to be isomorphic with s‚ãÜ
b since œÜ is a bijection between their
nodes.
Since we have proven both directions of Proposition 2, we know it is true.
Proof of Theorem 1. Having the proof of Proposition 1 and the proof of Proposition 2, we know that
the theorem, which is just the conjunction of these propositions, must be true.
Lemma 1. Let œÜ be an isomorphic bijection between nodes in two scene graphs (propositions or
objects). There exists a bijection f over the propositions in L such that for any proposition p ‚ààL,
f(p) = ‚ü®œÜ(q), œÜ(o1), œÜ(o2), . . . , œÜ(ok)‚ü©, where q is the predicate and O = {o1, o2, . . . , ok} is a set
of objects.
Proof. Take any proposition p ‚ààL and identify its predicate q and the ordered set of objects it
acts on, O = ‚ü®o1, o2, . . . , ok‚ü©. Then, we can transform the proposition p into the ordered tuple
p = ‚ü®q, o1, o2, . . . , ok‚ü©. Finally, we can build f(p) = ‚ü®œÜ(q), œÜ(o1), œÜ(o2), . . . , œÜ(ok)‚ü©, which is a
bijection over the propositions in L.
B
Examples of Algorithm 1
(:objects a b) 
(:init (clear a)  
       (clear b)  
       (on-table a)  
       (on-table b) 
       (arm-empty))
(:objects d e) 
(:init (clear d)  
       (clear e)  
       (on-table d)  
       (on-table e) 
       (arm-empty))
A
B
?
A
B
D
E
D
E
?
?
?
A
B
table
clear
arm
table
arm
(:goal (and 
        (on a b) 
        (clear a) 
        (arm-empty)))
(:goal (and 
        (on d e)))
E
D
table
clear
arm
PDDL
Scene
Graph*
Problem Definition 1
Problem Definition 2
D
E
table
clear
arm
PDDL
Scene
Graph*
*Simplified graph representation used for clarity
A
B
table
clear
arm
D
E
table
clear
arm
Fully Specify
Fully Specify
Placeholder Equivalence
A
B
table
clear
arm
B
A
table
clear
arm
B
A
table
clear
arm
Check 
isomorphism
Check 
isomorphism
E
D
table
clear
arm
D
E
table
clear
arm
A
B
table
clear
arm
B
A
table
clear
arm
Check 
isomorphism
E
D
table
clear
arm
D
E
table
clear
arm
P1 Init
P2 Init
P1 Goal
P2 Goal
P1 Goal
P2 Goal
P1 Init
P2 Init
&
P1 Goal
P2 Goal
E
D
table
clear
arm
P2 Init
B
A
table
clear
arm
P1 Init
Non-Placeholder¬†(Strict) Equivalence
Figure 4: An illustration of the algorithm to check if two PDDL problems are equivalent. It shows each
of the stages of the algorithm: transforming to scene graphs, fully specifying the goal propositions,
and checking for graph isomorphism.
C
Implementation of fullySpecify
The fullySpecify function adds trivial edges (edges that must exist but are not currently present) to
our scene graphs. We build the fullySpecify function using our domain knowledge of the Blocks
World and Gripper domains.
15

Blocks World
The following helpful facts are true about Blocks World:
‚Ä¢ If all blocks have its behavior above it defined (they are either clear, have something on
top of it, or is being held), then any block that does not have its bottom behavior specified,
must be on the table (on-table).
‚Ä¢ If all blocks have its behavior beneath it defined (they are either on top of something else, are
on the table (on-table), or are being held), then any block that does not have its behavior
above it defined must be clear.
‚Ä¢ Following the last two facts: if there is a block A which has its behavior above it unspecified
and block B which has its behavior below it unspecified, then the only way that (on B A)
can exist is if there isn‚Äôt already a chain of predicates that leads A to B or vice versa. If
there already exists a chain connecting these two blocks, that means A and B are already
connected by being in the same tower, and that they are the top and bottom of the tower they
are a part of.
‚Ä¢ If there are no ‚Äúfloating‚Äù blocks (blocks that have both its top and bottom behavior defined),
and the arm‚Äôs behavior is undefined (neither arm-empty nor holding) is present, then the
arm must be empty. This is because there is no block that the arm could possibly hold here.
Using these rules, we can add all possible trivial edges, until no more trivial edges can be found.
Further, these facts will discover all possible trivial edges in Blocks World, meaning the fully specified
scene graph will be in its canonical form after fullySpecify.
Gripper
Similarly, we can build a set of facts that operate on the Gripper domain:
‚Ä¢ If all balls are assigned a room (at ball room), then all unassigned grippers (no (free
gripper) or (carry ball gripper)) must be free.
‚Ä¢ If there is only one room, and if all grippers are already specified (either (free) or (carry
ball gripper)), then any unspecified balls must be in the only room that exists.
‚Ä¢ If there is only one room, the robby must be in it (at-robby onlyRoom).
These are the only rules we can find. This is because, if a ball‚Äôs position is unspecified, it can always
be assigned to any arbitrary room. If the robby is unspecified (no at-robby), then it too, can always
be specified to any arbitrary room.
16

D
Text-to-PDDL Pair Example
BLOCKSWORLD
Ground Truth PDDL
( d e f i n e
( problem
equal_towers_to_equal_towers_5 )
( : domain
blocksworld )
( : r e q u i r e m e n t s
: s t r i p s )
( : o b j e c t s
b1 b2 b3 b4 b5 )
( : i n i t
( arm‚àíempty )
( c l e a r
b5 )
( on b2 b1 )
( on b3 b2 )
( on b4 b3 )
( on b5 b4 )
( on‚àít a b l e
b1 ) )
( : goal
( and
( arm‚àíempty )
( on‚àít a b l e
b1 )
( on b2 b1 )
( on b3 b2 )
( on b4 b3 )
( on b5 b4 )
( c l e a r
b5 ) ) )
)
Natural Language Description
(objects: You have 5 blocks, b1 through b5, stacked into 1 towers of equal heights, and your
arm is empty. ) (abstract init: stacked into 1 towers of equal heights, and your arm is empty. |
explicit init: Your arm is empty. b1 is on the table. b2 is on b1. b3 is on b2. b4 is on b3. b5 is
on b4. b5 is clear. ) Your goal is to have the following: (abstract goal: stack the blocks into 1
towers of equal heights. | explicit goal: Your arm should be empty. b1 should be on the table.
b2 should be on b1. b3 should be on b2. b4 should be on b3. b5 should be on b4. b5 should
be clear. )
E
License Information
The data for Planetarium is available at https://huggingface.co/datasets/BatsResearch/planetarium
and
released
under
a
Creative
Commons
CC-BY-4.0
license.
In
addition,
all
code
to
create
the
dataset
and
evaluate
models
on
the
benchmark
is
available
at
https://github.com/BatsResearch/planetarium and released under a BSD 3 license.
The authors are responsible for the content of the dataset.
In our study, we use the Blocksworld and Gripper domains, both of which are sourced from
the IPC McDermott [2000]. The specific domain files used in our research are obtained from
pddl-generators Seipp et al. [2022], which is distributed under the GNU General Public License.
F
Additional Experiment Details
Table 2 displays the the hyperparameters used for fine-tuning across all models. In addition, models
are loaded using 4-bit NF4 quantization with double quantization to reduce the average memory
footprint. We also use bfloat16 compute data type for faster training.
17

Hyperparameters
Value
Optimizer
adamw_torch
Learning rate
2e-5
Batch Size
1
Betas
(0.9, 0.999)
Epsilon
1e-8
Weight Decay
0.01
Max Sequence Length
1500
LoRA rank
16
LoRA alpha
32
LoRA Dropout
0.05
Table 2: Training hyperparameters when fine-tuning all models included in the paper. The hyperpa-
rameters are seperated in three parts: supervised fine-tuning related, generation related, and LoRA
related.
G
Additional Experiments and Analysis
Random Split
Heldout Split
Invert
Focus (max)
Focus (min)
Invert
Focus (max)
Focus (min)
0%
25%
50%
75%
100%
Problems (%)
100%
99.70%
97.22%
100%
100%
95.03%
100%
100%
93.62%
99.89%
72.96%
5.20%
99.79%
95.59%
46.54%
99.52%
78.63%
43.30%
Parseable
Solve-able*
Correct
Figure 5: (Left) Gemma 1.1 IT 2B, fine-tuned on the random train split and evaluated on certain
tasks. Most tasks are performed extremely well. (evaluated tasks were seen during training). (Right)
Gemma 1.1 IT 2B, fine-tuned on all examples except for the tasks listed above, along with one_room
in the initial state and n_room_distributed in the initial state. (tasks not seen during training)
H
Dataset Documentation
To see the most up-to-date documentation, go to the following URL:
https://datanutrition.org/labels/v3/?id=f2b30848-2b93-4f2d-b7e0-926604a02c12
I
Maintenance Plan
The BATS research group at Brown University, will maintain the Planetarium dataset and benchmark
with an open GitHub repository and issue submission system, and the dataset hosted on HuggingFace.
The maintenance plan includes regular issue tracking, with reviews and categorization of issues,
aiming to resolve high-priority issues within a week and scheduling minor updates quarterly. Com-
prehensive documentation and automated testing will ensure quality and compatibility. Francisco
Piedrahita Velez and Max Zuo will lead the maintenance efforts, supported by the BATS research
group.
18

