FedDM: Iterative Distribution Matching
for Communication-Efficient Federated Learning
Yuanhao Xiong1*
Ruochen Wang1*
Minhao Cheng2
Felix Yu3
Cho-Jui Hsieh1
1UCLA
2HKUST
3Google Research
Abstract
Federated learning (FL) has recently attracted increas-
ing attention from academia and industry, with the ultimate
goal of achieving collaborative training under privacy and
communication constraints.
Existing iterative model av-
eraging based FL algorithms require a large number of
communication rounds to obtain a well-performed model
due to extremely unbalanced and non-i.i.d data partitioning
among different clients. Thus, we propose FedDM to build
the global training objective from multiple local surrogate
functions, which enables the server to gain a more global
view of the loss landscape.
In detail, we construct syn-
thetic sets of data on each client to locally match the loss
landscape from original data through distribution match-
ing. FedDM reduces communication rounds and improves
model quality by transmitting more informative and smaller
synthesized data compared with unwieldy model weights.
We conduct extensive experiments on three image classifica-
tion datasets, and show that our method outperforms other
FL counterparts in terms of efficiency and model perfor-
mance given a limited number of communication rounds.
Moreover, we demonstrate that FedDM can be adapted to
preserve differential privacy with Gaussian mechanism and
train a better model under the same privacy budget.
1. Introduction
Traditional machine learning methods are designed with
the assumption that all training data can be accessed from
a central location. However, due to the growing data size
together with the model complexity [10,23,26], distributed
optimization [7,8,43] is necessary over different machines.
This leads to the problem of Federated Learning [32] (FL) –
multiple clients (e.g. mobile devices or local organizations)
collaboratively train a global model under the orchestration
of a central server (e.g. service provider) while the training
*Equal contribution.
data are kept decentralized and private. Such a practical set-
ting poses two primary challenges [20,24,29,31,32]: train-
ing data of the FL system are highly unbalanced and
non-i.i.d. across downstream clients and more efficient
communication with fewer costs is expected because of
unreliable devices with limited transmission bandwidth.
Most of the existing FL methods [22,28,31,32,48] adopt
an iterative training procedure from FedAvg [32], in which
each round takes the following steps: 1) The global model
is synchronized with a selected subset of clients; 2) Each
client trains the model locally and sends its weight or gra-
dient back to the server; 3) The server updates the global
model by aggregating messages from selected clients. This
framework works effectively for generic distributed opti-
mization while the difficult and challenging setting of FL,
unbalanced data partition in particular, would result in sta-
tistical heterogeneity in the whole system [30] and make
the gradient from each client inconsistent. It poses a great
challenge to the training of the shared model, which re-
quires a substantial number of communication rounds to
converge [28].
Although some improvements have been
made over FedAvg [32] including modifying loss func-
tions [31], correcting client-shift with control variates [22]
and the like, the reduced number of communication round
is still considerable and even the amount of information re-
quired by the server rises [56].
In our paper, we propose a different iterative surrogate
minimization based method, FedDM, referred to Federated
Learning with iterative Distribution Matching. Instead of
the commonly-used scheme where each client maintains
a locally trained model respectively and sends its gradi-
ent/weight to the server for aggregation, we take a distinct
perspective at the client’s side and attempt to build a lo-
cal surrogate function to approximate the local training ob-
jective. By sending those local surrogate functions to the
server, the server can then build a global surrogate function
around the current solution and conduct the update by min-
imizing this surrogate. The question is then how to build
local surrogate functions that are informative and with a rel-
This CVPR paper is the Open Access version, provided by the Computer Vision Foundation.
Except for this watermark, it is identical to the accepted version;
the final published version of the proceedings is available on IEEE Xplore.
16323

ative succinct representation. Inspired by recent progresses
in data condensation [54,55] we build local surrogate func-
tions by learning a synthetic dataset to replace the origi-
nal one to approximate the objective. It can be achieved
by matching the original data distribution in the embed-
ding space [16]. After the optimization of synthesized data,
the client can transmit them to the server, which can then
leverage the synthetic dataset to recover the global objec-
tive function for training. Our method enables the server
to have implicit access to the global objective defined by
the whole balanced dataset from all clients, and thus out-
performs previous algorithms involved in training a local
model with unbalanced data in terms of communication ef-
ficiency and effectiveness. We also demonstrate that our
method can be adapted to preserve differential privacy un-
der, an important factor to the deployment of FL systems.
Our contributions are primarily summarized as follows:
• We propose FedDM, which is based on iterative distri-
bution matching to learn a surrogate function. It sends
synthesized data to the server rather than commonly-
used local model updates and improves communica-
tion efficiency and effectiveness significantly.
• We analyze how to protect privacy of client’s data for
our method and show that it is able to guarantee (ϵ, δ)-
differential privacy with the Gaussian mechanism and
train a better model under the same privacy budget.
• We conduct comprehensive experiments on three tasks
and demonstrate that FedDM is better than its FL
counterparts in communication efficiency and the final
model performance.
2. Related Work
Federated Learning.
Federated learning [20, 32] has
aroused heated discussion nowadays from both research and
applied areas. With the goal to train the model collabo-
ratively, it incorporates the principles of focused data col-
lection and minimization [20]. FedAvg [32] was proposed
along with the concept of FL as the first effective method
to train the global model under the coordination of multi-
ple devices. Since it is based on iterative model averaging,
FedAvg suffers from heterogeneity in the FL system, espe-
cially the non-i.i.d. data partitioning, which degrades the
performance of the global model and adds to the burden of
communication [30]. To mitigate the issue, some variants
have been developed upon FedAvg including [22, 31, 48].
For instance, FedProx [31] modifies the loss function while
FedNova [48] and SCAFFOLD [22] leverage auxiliary in-
formation to balance the distribution shift. Apart from bet-
ter learning algorithms with faster convergence rate, another
perspective at improving efficiency is to reduce communi-
cation costs explicitly [5, 6, 40, 42, 51]. An intuitive ap-
proach is to quantize and sparsify the uploaded weights di-
rectly [40]. Efforts have also been made towards one-shot
federated learning [17,41,44,56], expecting to obtain a sat-
isfactory model through only one communication round.
Differential Privacy. To measure and quantify information
disclosure about individuals, researchers usually adopt the
state-of-the-art model, differential privacy (DP) [11,14,15].
DP describes the patterns of groups while withholding in-
formation about individuals in the dataset. There are many
scenarios in which DP guarantee is necessary [1, 2, 12, 13,
21,34,38]. For example, Abadi et.al [1] developed differen-
tially private SGD (DP-SGD) which enabled training deep
neural networks with non-convex objectives under a certain
privacy budget. It was further extended to settings of feder-
ated learning, where various techniques have been designed
to guarantee client-level or instance-level differential pri-
vacy [33,37,52]. Recently, DP has been taken into account
for hyperparameter tuning [38].
Dataset Distillation. With the explosive growing of the size
of training data, it becomes much more challenging and
costly to acquire large datasets and train a neural network
within moderate time [35, 36]. Thus, constructing smaller
but still informative datasets is of vital importance. The
traditional way to reduce the size is through coreset selec-
tion [3], which select samples based on particular heuris-
tic criteria. However, this kind of method has to deal with
a trade-off between performance and data size [35, 55].
To improve the expressiveness of the smaller dataset, re-
cent approaches consider learning a synthetic set of data
from the original set, or data distillation for simplicity.
Along this line, different methods are proposed using meta-
learning [46, 50], gradient matching [53, 55], distribution
matching [49,54], neural kernels [35,36] or generative mod-
els [45].
These methods demonstrate great potentials in
datasets such as CIFAR10 but face challenges in scaling up
to larger ones like ImageNet. Besides, a recent work [9] has
analyzed the privacy property of dataset distillation meth-
ods, focusing on membership inference attacks. It provides
a complementary prospective to (ϵ, δ)-differential privacy
discussed in our paper.
3. Methodology
In this part, we first present the iterative surrogate mini-
mization framework in Section 3.1, and then expand on the
details of our implementation of FedDM in Section 3.2. In
addition, we discuss preserving differential privacy of our
method through Gaussian mechanism in Section 3.3.
3.1. Iterative surrogate minimization framework
for federated learning
Neural network training can be formulated as solving the
finite sum minimization problem:
  \
l abel  {
eq:mi
n} \ mi n  
_
{
w
} f
(\mat hca l {D};w) \quad \text {where} \quad f(\mathcal {D};w) = \frac {1}{n}\sum _{i=1}^{n}\ell (x_i, y_i; w), 
(1)
16324

where w ∈Rd is the parameter to be optimized, D is
the dataset and ℓ(xi, yi; w) is the loss of the prediction on
sample (xi, yi) ∈D w.r.t. w such as cross entropy. We
will abbreviate these terms as f(w) and ℓi(w) for simplic-
ity. Equation 1 is typically solved by stochastic optimizers
when training data are gathered in a single machine. How-
ever, the scenario is different under the setting of federated
learning with K clients. In detail, each client k has access
to its local dataset of the size nk with the set of indices Ik
(nk = |Ik|), and we can rewrite the objective as
  f( w
)
 
= \
su
m  _{k=
1}^{K
}\fra c  
{n
_
k}{n
}f_k(w) \quad \text {where} \quad f_k(w) = \frac {1}{n_k}\sum _{i\in \mathcal {I}_k}l_i(w). \label {eq:decomposition} 
(2)
6
4
2
0
2
4
6
Weight
1
0
1
2
3
4
Loss
Original
Surrogate
Tangent
Figure 1. A 1-D example showing advantages of minimizing the
surrogate function.
Since information can only be communicated between
the server and clients, previous methods [22,31,32,48] train
the global model by aggregation of local model updates, as
introduced in Section 1. However, as each client only sees
local data which could be biased and skewed, the local up-
dates is often insufficient to capture the global information.
Further, since local weight update consists limited informa-
tion, it is hard for the server to obtain better joint update
direction by considering higher order interactions between
different clients. We are motivated to leverage the surro-
gate function by the example in Figure 1. Specifically, we
synthesize a 1-D binary classification problem and learn a
surrogate for the objective function. We learn the surrogate
function via distribution matching introduced in Section 3.2
around the weight of 0. Compared with the tangent line
computed by the gradient, the surrogate function in orange
matches the original one accurately and minimizing it leads
to a satisfactory solution. More details can be checked in
Appendix B.Thus, we hope to develop a novel scheme such
that each client can send a local surrogate function instead
of a single gradient or weight update to the server, so the
server has a more global view to loss landscape to obtain a
better update instead of pure averaging.
To achieve this goal, we propose to conduct federated
learning with an iterative surrogate minimization frame-
work. At each round, let wr be the current solution, we
build a surrogate training objective ˆfr(·) to approximate the
original training objective in the local area around wr, and
then update the model by minimizing the local surrogate
function. The update rule can be written as
  w_ {
r+1
} = \min
 _{w\in B_{\rho }(w_r)} \hat {f}_r(w), \label {eq:surrogate} 
(3)
where ˆfr(w) ≈f(w), ∀w ∈Bρ(wr) and Bρ(wr) is a ρ-
radius ball around wr. We do not expect to build a good
surrogate function in the entire parameter space; instead,
we only construct it near wr and obtain the update by mini-
mizing the surrogate function within this space. Many opti-
mization algorithms can be described under this framework.
For instance, if ˆfr(w) = ∇f(wr)T (w −wr) (based on the
first-order Taylor expansion), then Equation 3 leads to the
gradient descent update where ρ controls the step size.
To apply this framework in the federated learning set-
ting, we consider the decomposition of Equation 2 and try
to build surrogate functions to approximate each fk(w) on
each client. More specifically, each client aims to find
  \hat { f }_{r, k} ( w) \approx f_k(w), \ \ \forall w\in B_\rho (w_t) 
(4)
and send the local surrogate function ˆfr,k(·) instead of
gradient or weights to the server. The server then form the
aggregated surrogate function
  \hat  {f}_r(w)  =  \ h at {f}_{r, 1}(w) + \dots + \hat {f}_{r, K}(w) 
(5)
and then use Equation 3 to obtain the update. Again, if
each ˆfr,k is the Taylor expansion based on local data, it is
sufficient for the client to send local gradient to the server,
and the update will be equivalent to (large batch) gradient
descent. However, we will show that there exists other ways
to build local approximations to make federated learning
more communication efficient.
3.2. Local distribution matching
Inspired by recent progresses in data distillation [35,36,
53–55], it is possible to learn a set of synthesized data for
each client to represent original data in terms of the objec-
tive function. Therefore, we propose to build local surro-
gate models based on the following approximation for the
r-th round:
  \la b e
l 
{
e
q:ap
p
ro} f_k (w) \a p prox \fr ac {1 } {n_k^s}\sum _{j\in {\mathcal {I}_k^\mathcal {S}}} \ell _j(\Tilde {x}_j, \Tilde {y}_j; w) = \hat {f}_{r,k}(\mathcal {S};w), \ \ \forall w\in B_\rho (w_r), 
(6)
where S denotes the set of synthesized data and IS
k is the
corresponding set of indices. Note that we aim to approxi-
mate fk only in a local region around wr instead of finding
the approximation globally, which is hard as demonstrated
16325

in [54, 55]. To form the approximation function in Equa-
tion 6, we solve the following minimization problem:
  \
l abel {eq:ms e } \min _ {\mathcal {S}} \mathbb {E}_{w\sim \mathcal {P}_w} \lVert f_k(w) - \hat {f}_{r,k}(\mathcal {S};w) \rVert ^2 
(7)
where w is sampled from distribution Pw, which is a
Gaussian distribution truncated at radius ρ.
A differ-
ent perspective at Equation 7 is that we can just match
the distribution between the real data and synthesized
ones given fk(w) and ˆfr,k(S; w) are just empirical risks.
A common way to achieve this is to estimate the real
data distribution in the latent space with a lower dimen-
sion by maximum mean discrepancy (MMD) [49, 54]:
sup∥hw∥H≤1 (E[hw(D)] −E[hw(S)]). Here H is reproduc-
ing kernel Hilbert space and hw is the embedding function
that maps the input into the hidden representation. We use
the empirical estimate of MMD in [54] since the underly-
ing distribution is inaccessible. To make our approximation
more accurate and effective, we match the outputs of the
logit layer which corresponds with the Equation 7, together
with the preceding embedding layer:
  \ l abel {eq:o b
j} 
\
resizeb
ox {0 . 9
\hs
i
ze }{!}{ 
$ \begin
 {split} \m a
thc
a
l {L}_\
text { D
M} 
=
 \E _{w\i
n B_\rho (w_r)}& \lVert \frac {1}{|\mathcal {D}|}\sum _{(x,y)\in \mathcal {D}} h_w(x) - \frac {1}{|\mathcal {S}|}\sum _{(\Tilde {x},\Tilde {y})\in \mathcal {S}} h_w(\Tilde {x})\rVert ^2 \\ + \E _{w\in B_\rho (w_r)}&\lVert \frac {1}{|\mathcal {D}|}\sum _{(x,y)\in \mathcal {D}} z_w(x) - \frac {1}{|\mathcal {S}|}\sum _{(\Tilde {x},\Tilde {y})\in \mathcal {S}} z_w(\Tilde {x})\rVert ^2, \end {split} $ } 
(8)
where hw(x) again denotes intermediate features of the in-
put while zw(x) ∈RC represents the output of the final
logit layer. It should be emphasized that we learn synthe-
sized data for each class respectively, which means samples
in D and S belong to the same class. For training, we adopt
mini-batch based optimizers to make it more efficiently.
Specifically, a batch of real data and a batch of synthetic
data are sampled randomly for each class independently by
BDk
c
∼Dk and BSk
c
∼Sk. We plug these two batches into
Equation 8 to compute Lc and L = PC−1
c=0 Lc. Sk can be
updated with SGD by minimizing L for each client.
Then we aggregate all synthesized data from K clients at
the server’s side to approximate the global objective func-
tion, which is computed as
  \l a
b
e
l {
eq
: aggre }
 
f
(w)
 =
 
\
sum _{k=1 }^{ K} \ frac {n_k}{n}f_k(w) \approx \sum _{k=1}^{K}\frac {n_k^{\mathcal {S}}}{n}\hat {f}_{r,k}(\mathcal {S}_k;w), \ \ \forall w\in B_\rho (w_r). 
(9)
Moreover, since synthesized data are trained based on
a specific distribution around the current value of w, we
need to iteratively synchronize the global weights with all
the clients and obtain proper S according to the latest w for
the next communication round.
Therefore, instead of transmitting information such as
parameters or gradients in previous FL algorithms, we pro-
pose federated learning with iterative distribution match-
ing (FedDM) in Algorithm 1 following the steps below to
train the global model:
(a) At each communication round, for each client, we
adopt Equation 8 as the objective function to train syn-
thesized data for each class.
(b) The server receives synthesized data and leverages
them to update the global model.
(c) The current weight is then synchronized with all the
clients and a new communication round starts by re-
peating step (a) and (b).
It should be noticed that through estimating the local ob-
jective, FedDM extracts richer information than existing
model averaging based methods, and enables the server to
explore the loss landscape from a more global view. It re-
duces communication rounds significantly. On the other
hand, the explicit message uploaded to the server, or the
number of float parameters, is relatively smaller. This is
especially true when training large neural network models,
where the size of neural network parameters (and there-
fore gradient update) is much larger than the size of the
input. Take CIFAR10 as an example, when training data
are distributed obeying Dir10(0.5), the average number of
classes per client (cpc) is 9.
When we adopt the num-
ber of images per class (ipc) of 10 for the synthetic set,
the total number of float parameters uploaded to the server
is: the number of clients × cpc × ipc × image size
=
10 × 9 × 10 × 3 × 32 × 32 ≈2.8 × 106. For those iter-
ative model averaging model methods, the number of float
parameters is equal to the product of weight size and the
number of clients, which is 320010 × 10 ≈3.2 × 106 for
ConvNet [55] and comparably larger than FedDM. An ex-
tensive comparison is presented in Appendix C.
3.3. Differential privacy of FedDM
An important factor to evaluate a federated learning algo-
rithm is whether it can preserve differential privacy. Before
analyzing our method, we first review some fundamentals
of differential privacy.
Definition 3.1 (Differential Privacy [12]). A randomized
mechanism M : D →R with domain D and range R
satisfies (ϵ, δ)-differential privacy if for any two adjacent
datasets D1, D2 and any measurable subset S ⊆R,
  \text { Pr } (\mathcal { M} ( D_1)\in S) \leq e^{\epsilon }\text {Pr}(\mathcal {M}(D_2)\in S) + \delta . 
(10)
In this paper, we focus on instance-level differential pri-
vacy, which indicates that D1 and D2 differ on a single
element. Typically, the randomized mechanism is applied
to a query function of the dataset, f : D →X. With-
out loss of generality, we assume that the output spaces
R, X ⊆Rm. A key quantity in characterizing differen-
tial privacy for various mechanisms is the sensitivity of a
query [15] f : D →Rm in a given norm ℓp. Formally this
is defined as
  
\D elta _p \stackrel {\Delta }{=} \max _{D_1, D_2} \lVert f(D_1)-f(D_2)\rVert _p. x
(11)
16326

Algorithm 1 FedDM: Federated Learning with Iterative
Distribution Matching
1: Input: Training set D, set of synthetic samples S, deep
neural network parameterized with w, probability dis-
tribution over parameters Pw, training iterations of dis-
tribution matching T, learning rate ηc and ηs.
2: Server executes:
3: for each round r = 1, . . . , R do
4:
for client k = 1, . . . , K do
5:
Sk ←ClientUpdate(k, wr)
6:
Transmit Sk to the server
7:
end for
8:
Aggregate synthesized data from each client and
build the surrogate function by Equation 9
9:
Update weights to wr+1 on S by SGD with the learn-
ing rate ηs
10: end for
11: ClientUpdate(k, wr):
12: Initialize Sk from random noise or real examples.
13: for t = 0, · · · , T −1 do
14:
Sample w ∼Pw(wr)
15:
Sample mini-batch pairs BDk
c
∼Dk and BSk
c
∼Sk
for each class c
16:
Compute Lc based on Equation 8, L ←PC−1
c=0 Lc
17:
Update Sk ←Sk −ηc∇SkL
18: end for
Gaussian mechanism [15] is one simple and effective
method to achieve (ϵ, δ)-differential privacy:
  \m
at hcal  {M
}(D) 
\ s tack rel 
{\Delta }{=} f(D) + Z, \quad \text {where} \quad Z \sim \mathcal {N}(0, \sigma ^2\Delta _p^2\mathbf {I}). (12)
It has been proved that under Gaussian mechanism, (ϵ, δ)-
differential privacy is satisfied for the function f of sensitiv-
ity ∆p if we choose σ ≥
q
2 log 1.25
δ /ϵ [15]. Differentially
private SGD (DP-SGD) [1] then applies Gaussian mecha-
nism to deep learning optimization with hundreds of steps
and demonstrates the following theorem:
Theorem 3.1 (Differential Privacy of DP-SGD). There
exist constants c1 and c2 so that given the sampling prob-
ability q and the number of steps T, for any ϵ < c1q2T,
DP-SGD is (ϵ, δ)-differentially private for any δ > 0 if
  \label {eq:sigma} \sigma \geq c_2\frac {q\sqrt {T\log (1/\delta )}}{\epsilon }. 
q
(13)
We then prove that by leveraging DP-SGD to update the
synthetic dataset which is initialized from random Gaussian
noise, FedDM can preserve differential privacy of the orig-
inal dataset. We present this DP guarantee of FedDM in the
theorem below:
Theorem 3.2 (Differential privacy of FedDM.). Given
the synthetic dataset S is initialized from random noise,
FedDM trained with DP-SGD can guarantee (ϵ, δ)-
differential privacy in a K-client federated learning system,
with σ ≥
q
log(δ)
T q2−ϵ or σ ≥
q
2 log(1/δ)
ϵ
if Tq2 ≤ϵ/2 in
each communication round.
A complete proof and an initial analysis of differential
privacy for R communication rounds are included in Ap-
pendix D.We also present the whole procedure of FedDM
integrated with DP-SGD in Appendix E.
4. Experiments
4.1. Experimental setup
Datasets.
In this paper, we focus on image classifi-
cation tasks, and select three commonly-used datasets:
MNIST [27], CIFAR10 [25], and CIFAR100 [25].
We
adopt the standard training and testing split.
Following
commonly-used scheme [47], we simulate non-i.i.d. data
partitioning with Dirichlet distribution DirK(α), where K
is the number of clients and α determines the non-i.i.d.
level, and allocate divided subsets to clients respectively.
A smaller value of α leads to more unbalanced data distri-
bution. The default data partitioning is based on Dir10(0.5)
with 10 clients. Furthermore, we also take into account dif-
ferent scenarios of data distribution, including Dir10(0.1),
Dir10(0.01). Results of Dir50(0.5) and Dir10(50) (i.i.d. sce-
nario) can be found in Appendix F.1. We evaluate a realistic
dataset CelebA as well, following splits in the LEAF bench-
mark [4] in Appendix F.1.
Baseline methods.
We compare FedDM with four rep-
resentative iterative model averaging based methods: Fe-
dAvg [32], FedProx [31], FedNova [48], and SCAF-
FOLD [22]. We summarize the action of the client and
the server, and the transmitted message for all methods
in Table 1.
Two stronger methods, FedAvgM [19] and
FedAdam [39], are compared in Appendix F.1.
Hyperparameters.
For FedDM, following [54], we se-
lect the batch size as 256 for real images, and update the
synthetic set Sk for T = 1, 000 iterations with ηc = 1
for each client in each communication round, and tune the
number of images per class (ipc) within [3, 5, 10].
Syn-
thetic images are initialized as randomly sampled real im-
ages with corresponding labels suggested by [54, 55], and
random noise initialization is leveraged when differential
privacy is required. Considering the trade-off between com-
munication efficiency and model performance, we choose
ipc to be 10 for MNIST and CIFAR10, 5 for CIFAR100
when there are 10 clients. The choice of radius ρ = 5 is
discussed in Section 4.5. On the server’s side, the global
model is trained with the batch size 256 for 500 epochs by
16327

Method
Client
Message
Server
FedAvg [32]
min fk(w)
∆w*
model averaging
FedProx [31]
min fk(w) + µ∥w −wr∥/2
∆w
model averaging
FedNova [48]
min fk(w)
d and a*
normalized model averaging
SCAFFOLD [22]
min fk(w, c)
∆w and ∆c*
model averaging for both w and c
FedDM(Ours)
min Equation 8
S
model updating on S
* ∆w denotes the model update, d is the aggregated gradient and a is the coefficient vector, ∆c is the change of
control variates. Refer to original papers for more details.
Table 1. Summary of different FL methods.
0
5
10
15
20
Communication Round
84
86
88
90
92
94
96
98
100
Test Accuracy (%)
MNIST
FedAvg
FedProx
FedNova
SCAFFOLD
FedDM
(a) MNIST; rounds
0
5
10
15
20
Communication Round
30
35
40
45
50
55
60
65
70
Test Accuracy (%)
CIFAR10
FedAvg
FedProx
FedNova
SCAFFOLD
FedDM
(b) CIFAR10; rounds
0
5
10
15
20
Communication Round
5
10
15
20
25
30
35
40
Test Accuracy (%)
CIFAR100
FedAvg
FedProx
FedNova
SCAFFOLD
FedDM
(c) CIFAR100; rounds
0
2
4
6
8
10
12
14
# of float parameters(×106)
84
86
88
90
92
94
96
98
100
Test Accuracy (%)
MNIST
FedAvg
FedProx
FedNova
SCAFFOLD
FedDM
(d) MNIST; message size
0
10
20
30
40
50
# of float parameters(×106)
30
35
40
45
50
55
60
65
70
Test Accuracy (%)
CIFAR10
FedAvg
FedProx
FedNova
SCAFFOLD
FedDM
(e) CIFAR10; message size
0
20
40
60
80
100
# of float parameters(×106)
5
10
15
20
25
30
35
40
Test Accuracy (%)
CIFAR100
FedAvg
FedProx
FedNova
SCAFFOLD
FedDM
(f) CIFAR100; message size
Figure 2. Test accuracy along with the number of communication rounds and the message size. Within the limited communication budget,
FedDM performs the best in all three datasets, in terms of efficiency and final test accuracy.
SGD of ηs = 0.01. For baseline methods1, we choose the
same batch size of 256 for local training. We tune the learn-
ing rate at the client from [0.001, 0.01, 0.1] and at the server
from [0.01, 0.1, 1], and local epoch from [1, 2, 5, 10, 15, 20].
In particular, we tune µ for FedProx in [0.01, 0.1, 1]. For
a fair comparison, all methods share the fixed number of
communication rounds as 20, and the same model struc-
ture ConvNet [55] by default.
We consider 40 commu-
nication rounds in Appendix F.1 and a different network
ResNet-18 [18] in Section 4.5 as well. All experiments are
run for three times with different random seeds with one
NVIDIA 2080Ti GPU and the average performance is re-
ported. More implementation details and experimental re-
1We use implementations from https://github.com/Xtra-
Computing/NIID-Bench in [28].
sults can be found in Appendix F.1.
4.2. Communication efficiency & convergence rate
We first evaluate our method in terms of communication
efficiency and convergence rate on all three datasets on the
default data partitioning Dir10(0.5). As we can see in Fig-
ure 2(a)-(c), our method FedDM performs the best among
all considered algorithms by a large margin on MNIST,
CIFAR10, and CIFAR100.
Specifically, for CIFAR10,
FedDM achieves 69.66 ± 0.13% on test accuracy while the
best baseline SCAFFOLD only has 66.12 ± 0.17% after 20
communication rounds. FedDM also has the best conver-
gence rate and it significantly outperforms baseline meth-
ods within the initial few rounds. Advantages of FedDM
are more evident when we evaluate convergence as a func-
tion of the message size. As mentioned in 3.2, FedDM re-
16328

Method
α = 0.1
α = 0.01
MNIST
CIFAR10
CIFAR100
MNIST
CIFAR10
CIFAR100
FedAvg
96.92 ± 0.09
57.32 ± 0.04
32.00 ± 0.50
91.04 ± 0.80
39.28 ± 0.25
27.05 ± 0.45
FedProx
96.72 ± 0.04
56.92 ± 0.30
30.77 ± 0.52
91.18 ± 0.16
40.30 ± 0.15
25.88 ± 0.39
FedNova
98.04 ± 0.03
60.76 ± 0.14
31.92 ± 0.42
90.27 ± 0.49
36.46 ± 0.42
27.52 ± 0.43
SCAFFOLD
98.32 ± 0.06
60.96 ± 1.20
34.39 ± 0.25
88.37 ± 0.25
32.42 ± 1.13
31.14 ± 0.20
FedDM
98.67 ± 0.01
67.38 ± 0.32
37.58 ± 0.27
98.21 ± 0.23
63.82 ± 0.17
34.98 ± 0.17
Table 2. Test accuracy of FL methods with different level of non-uniform data partitioning.
0
5
10
15
20
Communication Round
30
35
40
45
50
55
60
65
Test Accuracy (%)
CIFAR10, small noise
FedAvg
FedProx
FedNova
SCAFFOLD
FedDM
(a) Small noise (ϵ = 12.25).
0
5
10
15
20
Communication Round
30
35
40
45
50
55
60
Test Accuracy (%)
CIFAR10, medium noise
FedAvg
FedProx
FedNova
SCAFFOLD
FedDM
(b) Medium noise (ϵ = 2.46).
0
5
10
15
20
Communication Round
30
35
40
45
50
55
60
Test Accuracy (%)
CIFAR10, large noise
FedAvg
FedProx
FedNova
SCAFFOLD
FedDM
(c) Large noise (ϵ = 1.35).
Figure 3. Performance of FL methods with different levels of noise. To preserve differential privacy, FedDM initializes the synthetic data
from random Gaussian noise.
quires less information per round. Therefore, we can ob-
serve in Figure 2(d)-(e) that FedDM converges the fastest
along with the message size. Details of the message size of
each method for different tasks are provided in Appendix C.
4.3. Evaluation on different data partitioning
In real-world applications, there are various extreme
data distributions among clients. To synthesize such non-
i.i.d.
partitioning, we consider two more scenarios with
Dir10(0.1) and Dir10(0.01). As mentioned, α →0 implies
each client holds examples from only one random class. It
can be seen in Table 2 that previous methods based on it-
erative model averaging are insufficient to handle these two
challenging scenarios and their performance degrades dras-
tically compared with Dir10(0.5). In contrast, FedDM per-
forms consistently better and more robustly, since distribu-
tion matching enables it to approximate the global training
objective more accurately.
4.4. Performance with DP guarantee
As discussed in Section 3.3, if the synthetic dataset is
initialized from random noise, using DP-SGD in local train-
ing of FedDM can satisfy (ϵ, δ)-differential privacy, with
σ ≥
q
2 log(1/δ)
ϵ
for any Tq2 ≤ϵ/2, a relatively loose
bound independent of training steps T. To make a fair com-
parison, we use tensorflow privacy to compute ϵ with a tight
bound given the number of examples, batch size, training
steps, δ = 10−5 under σ ∈1, 3, 5 for FedDM, and ob-
tain noise levels for baseline methods accordingly which
are [0.44, 0.76, 0.95] respectively. We tune clipping norm
C ∈[1, 3, 5, 10]. S is initialized from N(0, 1) to guar-
antee differential privacy. We notice in Figure 3 that un-
der the same DP guarantee, FedDM outperforms other FL
counterparts in terms of convergence rate and final perfor-
mance. Moreover, the accuracy of FedDM does not drop
significantly compared with all considered methods when
the noise level increases, indicating that FedDM is most re-
sistant to the perturbed optimization. Visualization of the
synthetic dataset can be found in Appendix F.2.
4.5. Analysis of FedDM
In this section, we analyze FedDM to investigate effects
of hyperparameters including the initialization of the syn-
thetic dataset, image-per-class (ipc), network structure and
selection of ρ–radius ball. Besides, we compare our method
with a strong baseline of sending real images with the same
size. Extensive results are reported in Appendix F.1.
Initialization of the synthetic dataset.
We conduct an
ablation study on the initialization of the synthetic dataset S
on CIFAR10 with the default partition Dir10(0.5). In detail,
random initialize S based on the standard normal distribu-
tion N(0, 1) while real samples instances from the original
dataset to be distilled. It can be observed in Table 3 that
real performs consistently better than random, which con-
curs with the conclusion in [54] and justifies the choice of
real in our experiments. Note that even random can out-
perform model averaging methods compared with results in
Figure 2 and Table 2. In addition, random with DP-SGD
16329

helps preserve differential privacy of FedDM, and still im-
proves the efficiency and accuracy significantly in Figure 3.
Partitioning
random
real
α = 0.5
64.12 ± 0.15
69.66 ± 0.13
α = 0.1
62.75 ± 0.24
67.38 ± 0.32
α = 0.01
59.00 ± 0.26
63.82 ± 0.17
Table 3. Test accuracy of FedDM with random and real S initial-
ization on CIFAR10. Three data partitionings are evaluated.
Effects of ipc.
Experiments are conducted on CIFAR10
with the distribution Dir10(0.5) with three different ipc val-
ues from [3, 5, 10]. As the ipc increases, the performance
gradually get better from 53.64 ± 0.35%, 62.24 ± 0.04% to
69.62±0.14%. On the other hand, more images per class in-
dicates a heavier communication burden in the meanwhile.
We need to trade off the model performance against the
communication cost, and thus choose an appropriate ipc
value based on the task.
0
5
10
15
20
Communication Round
30
35
40
45
50
55
60
65
70
Test Accuracy (%)
CIFAR10
FedAvg
FedProx
FedNova
SCAFFOLD
FedDM(ipc=10)
FedDM(ipc=5)
FedDM(ipc=3)
Figure 4. Performance under different ipc values.
Different network structures.
Besides ConvNet, we
evaluate FedDM under the default CIFAR10 setting on
ResNet-18. It can be observed that our method works well
even for this more complicated and larger model in Figure
5. It should also be emphasized that for FL baseline meth-
ods, they have to transmit a larger amount of message while
FedDM maintains the original size. This makes FedDM
more efficient in larger networks.
0
5
10
15
20
Communication Round
10
20
30
40
50
60
70
Test Accuracy (%)
CIFAR10
FedAvg
FedProx
FedNova
SCAFFOLD
FedDM
Figure 5. Test accuracy on ResNet-18.
Selection of ρ-radius ball.
It has been discussed in Sec-
tion 3.1 that Bρ(wr) is a ρ-radius ball around wr:
  B_\r h o (w_ r ) = \ {w|\|w - w_r \|_2 \leq \rho \}. 
(14)
In FedDM, we sample w based on a truncated Gaussian dis-
tribution below:
  P_w( w _r) = \tex t { Clip}(\mathcal {N}(w_r, 1), \rho ), 
(15)
where we clip the sampled weight to guarantee that ∥w −
wr∥2 ≤ρ. At the server’s side, when training the global
model, we also clip the weight to the ρ-radius ball. We con-
duct experiments to choose ρ from [3, 5, 10] and present the
test accuracy after 20 communication rounds on CIFAR10
under the default Dir10(0.5) setting in Table 4. We find that
performance is similar and FedDM is not very sensitive to
the choice of ρ. ρ = 5 performs relatively the best and
we hypothesize that a too small weight restricts the opti-
mization to a limited range and a too big one adds to the
difficulty of learning a surrogate function. Based on results
in Table 4, we select ρ = 5 for all our experiments.
ρ
Test accuracy (%)
ρ = 3
69.15 ± 0.09
ρ = 5
69.66 ± 0.13
ρ = 10
69.32 ± 0.24
Table 4. Test accuracy of FedDM under different ρ.
Comparison
with
transmitting
real
images.
Our
method is compared with REAL, which sends real images
of the same size as FedDM (ipc = 10). In particular, REAL
achieves test acccuracy of 68.66 ± 0.08% on CIFAR10
with the default setting, but cannot beat FedDM with
69.62 ± 0.14%. It indicates that our learned synthetic set
can capture richer information of the whole dataset rather
than just a few images.
5. Conclusions and Limitations
In this paper we propose an iterative distribution
matching
based
method,
FedDM,
to
achieve
more
communication-efficient federated learning. By learning a
synthetic dataset for each client to approximate the local ob-
jective function, the server can obtain a global view of the
loss landscape better than aggregating local model updates.
We also show that FedDM can preserve differential privacy
with Gaussian mechanism. However, there is still a trade-
off between the size of the synthetic set and the final perfor-
mance, especially for classification tasks with hundreds of
clients or classes. How to reduce the synthetic set to save
communication costs can be a future direction.
Acknowledgements.
This work is supported by NSF un-
der IIS-2008173, IIS-2048280, an Okawa research grant, a
Cisco research grant and Google.
16330

References
[1] Martin Abadi, Andy Chu, Ian Goodfellow, H Brendan
McMahan, Ilya Mironov, Kunal Talwar, and Li Zhang. Deep
learning with differential privacy. In Proceedings of the 2016
ACM SIGSAC conference on computer and communications
security, pages 308–318, 2016. 2, 5
[2] Naman Agarwal, Ananda Theertha Suresh, Felix Xin-
nan
X
Yu,
Sanjiv
Kumar,
and
Brendan
McMahan.
cpsgd: Communication-efficient and differentially-private
distributed sgd. Advances in Neural Information Processing
Systems, 31, 2018. 2
[3] Zal´an Borsos, Mojmir Mutny, and Andreas Krause. Coresets
via bilevel optimization for continual learning and stream-
ing. Advances in Neural Information Processing Systems,
33:14879–14890, 2020. 2
[4] Sebastian Caldas, Sai Meher Karthik Duddu, Peter Wu, Tian
Li, Jakub Koneˇcn`y, H Brendan McMahan, Virginia Smith,
and Ameet Talwalkar. Leaf: A benchmark for federated set-
tings. arXiv preprint arXiv:1812.01097, 2018. 5
[5] Mingzhe Chen, Nir Shlezinger, H Vincent Poor, Yonina C
Eldar, and Shuguang Cui. Communication-efficient feder-
ated learning. Proceedings of the National Academy of Sci-
ences, 118(17), 2021. 2
[6] Yang Chen, Xiaoyan Sun, and Yaochu Jin. Communication-
efficient federated deep learning with layerwise asyn-
chronous model update and temporally weighted aggrega-
tion.
IEEE transactions on neural networks and learning
systems, 31(10):4229–4238, 2019. 2
[7] Trishul Chilimbi, Yutaka Suzue, Johnson Apacible, and
Karthik Kalyanaraman. Project adam: Building an efficient
and scalable deep learning training system. In 11th USENIX
Symposium on Operating Systems Design and Implementa-
tion (OSDI 14), pages 571–582, 2014. 1
[8] Jeffrey Dean, Greg Corrado, Rajat Monga, Kai Chen,
Matthieu Devin, Mark Mao, Marc’aurelio Ranzato, Andrew
Senior, Paul Tucker, Ke Yang, et al. Large scale distributed
deep networks. Advances in neural information processing
systems, 25, 2012. 1
[9] Tian Dong, Bo Zhao, and Lingjuan Lyu. Privacy for free:
How does dataset condensation help privacy? arXiv preprint
arXiv:2206.00240, 2022. 2
[10] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov,
Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner,
Mostafa Dehghani, Matthias Minderer, Georg Heigold, Syl-
vain Gelly, et al. An image is worth 16x16 words: Trans-
formers for image recognition at scale. In International Con-
ference on Learning Representations, 2020. 1
[11] Cynthia Dwork. A firm foundation for private data analysis.
Communications of the ACM, 54(1):86–95, 2011. 2
[12] Cynthia Dwork, Krishnaram Kenthapadi, Frank McSherry,
Ilya Mironov, and Moni Naor. Our data, ourselves: Privacy
via distributed noise generation.
In Annual international
conference on the theory and applications of cryptographic
techniques, pages 486–503. Springer, 2006. 2, 4
[13] Cynthia Dwork and Jing Lei. Differential privacy and ro-
bust statistics. In Proceedings of the forty-first annual ACM
symposium on Theory of computing, pages 371–380, 2009.
2
[14] Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam
Smith. Calibrating noise to sensitivity in private data analy-
sis. In Theory of cryptography conference, pages 265–284.
Springer, 2006. 2
[15] Cynthia Dwork, Aaron Roth, et al. The algorithmic founda-
tions of differential privacy. Found. Trends Theor. Comput.
Sci., 9(3-4):211–407, 2014. 2, 4, 5
[16] Arthur Gretton, Karsten M Borgwardt, Malte J Rasch, Bern-
hard Sch¨olkopf, and Alexander Smola. A kernel two-sample
test. The Journal of Machine Learning Research, 13(1):723–
773, 2012. 2
[17] Neel Guha, Ameet Talwalkar, and Virginia Smith. One-shot
federated learning. arXiv preprint arXiv:1902.11175, 2019.
2
[18] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
Deep residual learning for image recognition. In Proceed-
ings of the IEEE conference on computer vision and pattern
recognition, pages 770–778, 2016. 6
[19] Tzu-Ming Harry Hsu, Hang Qi, and Matthew Brown. Mea-
suring the effects of non-identical data distribution for feder-
ated visual classification. arXiv preprint arXiv:1909.06335,
2019. 5
[20] Peter Kairouz, H Brendan McMahan, Brendan Avent,
Aur´elien Bellet, Mehdi Bennis, Arjun Nitin Bhagoji, Kallista
Bonawitz, Zachary Charles, Graham Cormode, Rachel Cum-
mings, et al. Advances and open problems in federated learn-
ing. Foundations and Trends® in Machine Learning, 14(1–
2):1–210, 2021. 1, 2
[21] Peter Kairouz, Sewoong Oh, and Pramod Viswanath. The
composition theorem for differential privacy.
In Interna-
tional conference on machine learning, pages 1376–1385.
PMLR, 2015. 2
[22] Sai Praneeth Karimireddy, Satyen Kale, Mehryar Mohri,
Sashank Reddi, Sebastian Stich, and Ananda Theertha
Suresh. Scaffold: Stochastic controlled averaging for fed-
erated learning.
In International Conference on Machine
Learning, pages 5132–5143. PMLR, 2020. 1, 2, 3, 5, 6
[23] Jacob Devlin Ming-Wei Chang Kenton and Lee Kristina
Toutanova. Bert: Pre-training of deep bidirectional trans-
formers for language understanding.
In Proceedings of
NAACL-HLT, pages 4171–4186, 2019. 1
[24] Jakub Koneˇcn`y, H Brendan McMahan, Felix X Yu, Peter
Richt´arik, Ananda Theertha Suresh, and Dave Bacon. Fed-
erated learning: Strategies for improving communication ef-
ficiency. arXiv preprint arXiv:1610.05492, 2016. 1
[25] Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple
layers of features from tiny images. 2009. 5
[26] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton.
Imagenet classification with deep convolutional neural net-
works. Advances in neural information processing systems,
25, 2012. 1
[27] Yann LeCun.
The mnist database of handwritten digits.
http://yann. lecun. com/exdb/mnist/, 1998. 5
[28] Qinbin Li, Yiqun Diao, Quan Chen, and Bingsheng He.
Federated learning on non-iid data silos: An experimental
16331

study. In IEEE International Conference on Data Engineer-
ing, 2022. 1, 6
[29] Qinbin Li, Zeyi Wen, Zhaomin Wu, Sixu Hu, Naibo Wang,
Yuan Li, Xu Liu, and Bingsheng He. A survey on federated
learning systems: vision, hype and reality for data privacy
and protection. IEEE Transactions on Knowledge and Data
Engineering, 2021. 1
[30] Tian Li, Anit Kumar Sahu, Ameet Talwalkar, and Virginia
Smith. Federated learning: Challenges, methods, and future
directions. IEEE Signal Processing Magazine, 37(3):50–60,
2020. 1, 2
[31] Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi,
Ameet Talwalkar, and Virginia Smith. Federated optimiza-
tion in heterogeneous networks.
Proceedings of Machine
Learning and Systems, 2:429–450, 2020. 1, 2, 3, 5, 6
[32] Brendan McMahan, Eider Moore, Daniel Ramage, Seth
Hampson, and Blaise Aguera y Arcas.
Communication-
efficient learning of deep networks from decentralized data.
In Artificial intelligence and statistics, pages 1273–1282.
PMLR, 2017. 1, 2, 3, 5, 6
[33] H Brendan McMahan, Daniel Ramage, Kunal Talwar, and
Li Zhang. Learning differentially private recurrent language
models. arXiv preprint arXiv:1710.06963, 2017. 2
[34] Frank D McSherry. Privacy integrated queries: an extensible
platform for privacy-preserving data analysis. In Proceed-
ings of the 2009 ACM SIGMOD International Conference
on Management of data, pages 19–30, 2009. 2
[35] Timothy Nguyen, Zhourong Chen, and Jaehoon Lee. Dataset
meta-learning from kernel ridge-regression. In International
Conference on Learning Representations, 2020. 2, 3
[36] Timothy Nguyen, Roman Novak, Lechao Xiao, and Jaehoon
Lee. Dataset distillation with infinitely wide convolutional
networks. Advances in Neural Information Processing Sys-
tems, 34, 2021. 2, 3
[37] Nicolas Papernot, Mart´ın Abadi, Ulfar Erlingsson, Ian Good-
fellow, and Kunal Talwar. Semi-supervised knowledge trans-
fer for deep learning from private training data.
arXiv
preprint arXiv:1610.05755, 2016. 2
[38] Nicolas Papernot and Thomas Steinke.
Hyperparame-
ter tuning with renyi differential privacy.
arXiv preprint
arXiv:2110.03620, 2021. 2
[39] Sashank J Reddi, Zachary Charles, Manzil Zaheer, Zachary
Garrett, Keith Rush, Jakub Koneˇcn`y, Sanjiv Kumar, and
Hugh Brendan McMahan. Adaptive federated optimization.
In International Conference on Learning Representations. 5
[40] Amirhossein Reisizadeh, Aryan Mokhtari, Hamed Has-
sani, Ali Jadbabaie, and Ramtin Pedarsani.
Fedpaq: A
communication-efficient federated learning method with pe-
riodic averaging and quantization. In International Confer-
ence on Artificial Intelligence and Statistics, pages 2021–
2031. PMLR, 2020. 2
[41] Saber Salehkaleybar, Arsalan Sharifnassab, and S Jamalod-
din Golestani. One-shot federated learning: theoretical limits
and algorithms to achieve them. Journal of Machine Learn-
ing Research, 22(189):1–47, 2021. 2
[42] Felix Sattler, Simon Wiedemann, Klaus-Robert M¨uller, and
Wojciech Samek. Robust and communication-efficient fed-
erated learning from non-iid data. IEEE transactions on neu-
ral networks and learning systems, 31(9):3400–3413, 2019.
2
[43] Ohad
Shamir,
Nati
Srebro,
and
Tong
Zhang.
Communication-efficient
distributed
optimization
using
an approximate newton-type method.
In International
conference on machine learning, pages 1000–1008. PMLR,
2014. 1
[44] Arsalan Sharifnassab, Saber Salehkaleybar, and S Jamalod-
din Golestani.
Order optimal one-shot distributed learn-
ing. Advances in Neural Information Processing Systems,
32, 2019. 2
[45] Felipe Petroski Such, Aditya Rawal, Joel Lehman, Kenneth
Stanley, and Jeffrey Clune. Generative teaching networks:
Accelerating neural architecture search by learning to gener-
ate synthetic training data. In International Conference on
Machine Learning, pages 9206–9216. PMLR, 2020. 2
[46] Ilia Sucholutsky and Matthias Schonlau. Soft-label dataset
distillation and text dataset distillation. In 2021 International
Joint Conference on Neural Networks (IJCNN), pages 1–8.
IEEE, 2021. 2
[47] Hongyi Wang, Mikhail Yurochkin, Yuekai Sun, Dimitris Pa-
pailiopoulos, and Yasaman Khazaeni.
Federated learning
with matched averaging.
In International Conference on
Learning Representations, 2019. 5
[48] Jianyu Wang, Qinghua Liu, Hao Liang, Gauri Joshi, and
H Vincent Poor. Tackling the objective inconsistency prob-
lem in heterogeneous federated optimization.
Advances
in neural information processing systems, 33:7611–7623,
2020. 1, 2, 3, 5, 6
[49] Kai Wang, Bo Zhao, Xiangyu Peng, Zheng Zhu, Shuo Yang,
Shuo Wang, Guan Huang, Hakan Bilen, Xinchao Wang, and
Yang You. Cafe: Learning to condense dataset by aligning
features. arXiv preprint arXiv:2203.01531, 2022. 2, 4
[50] Tongzhou Wang, Jun-Yan Zhu, Antonio Torralba, and
Alexei A Efros.
Dataset distillation.
arXiv preprint
arXiv:1811.10959, 2018. 2
[51] Cong Xie, Sanmi Koyejo, and Indranil Gupta. Asynchronous
federated optimization.
arXiv preprint arXiv:1903.03934,
2019. 2
[52] Xiang Yue, Huseyin A Inan, Xuechen Li, Girish Kumar, Ju-
lia McAnallen, Huan Sun, David Levitan, and Robert Sim.
Synthetic text generation with differential privacy: A simple
and practical recipe. arXiv preprint arXiv:2210.14348, 2022.
2
[53] Bo Zhao and Hakan Bilen. Dataset condensation with differ-
entiable siamese augmentation. In International Conference
on Machine Learning, pages 12674–12685. PMLR, 2021. 2,
3
[54] Bo Zhao and Hakan Bilen. Dataset condensation with distri-
bution matching. arXiv preprint arXiv:2110.04181, 2021. 2,
3, 4, 5, 7
[55] Bo Zhao, Konda Reddy Mopuri, and Hakan Bilen. Dataset
condensation with gradient matching.
arXiv preprint
arXiv:2006.05929, 2020. 2, 3, 4, 5, 6
[56] Yanlin Zhou, George Pu, Xiyao Ma, Xiaolin Li, and Dapeng
Wu. Distilled one-shot federated learning. arXiv preprint
arXiv:2009.07999, 2020. 1, 2
16332

