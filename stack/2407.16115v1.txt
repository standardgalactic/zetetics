Transformer-based Graph Neural Networks for
Battery Range Prediction in AIoT
Battery-Swap Services
Zhao Li††∥¶, Yang Liu†¶, Chuan Zhou†‡‡∗, Xuanwu Liu∥Xuming Pan∥Buqing Cao‡∗and Xindong Wu§
††Zhejiang Lab, Hangzhou, China
∥Hangzhou Yugu Technology Co., Ltd, Hangzhou, China
†Academy of Mathematics and Systems Science, Chinese Academy of Sciences, Beijing, China
‡‡School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China
‡Hunan University of Science and Technology, Xiangtan, China
§Hefei University of Technology, Hefei, China
Email: lzjoey@gmail.com, {liuyang2020, zhouchuan}@amss.ac.cn, {liuxuanwu, panxm}@yugu.net.cn,
buqingcao@gmail.com, xwu@hfut.edu.cn
Abstract—The concept of the sharing economy has gained
broad recognition, and within this context, Sharing E-Bike Battery
(SEB) have emerged as a focal point of societal interest. Despite
the popularity, a notable discrepancy remains between user
expectations regarding the remaining battery range of SEBs
and the reality, leading to a pronounced inclination among
users to find an available SEB during emergency situations. In
response to this challenge, the integration of Artificial Intelligence
of Things (AIoT) and battery-swap services has surfaced as a
viable solution. In this paper, we propose a novel structural
Transformer-based model, referred to as the SEB-Transformer,
designed specifically for predicting the battery range of SEBs.
The scenario is conceptualized as a dynamic heterogeneous graph
that encapsulates the interactions between users and bicycles,
providing a comprehensive framework for analysis. Furthermore,
we incorporate the graph structure into the SEB-Transformer to
facilitate the estimation of the remaining e-bike battery range,
in conjunction with mean structural similarity, enhancing the
prediction accuracy. By employing the predictions made by our
model, we are able to dynamically adjust the optimal cycling routes
for users in real-time, while also considering the strategic locations
of charging stations, thereby optimizing the user experience.
Empirically our results on real-world datasets demonstrate the
superiority of our model against nine competitive baselines. These
innovations, powered by AIoT, not only bridge the gap between
user expectations and the physical limitations of battery range
but also significantly improve the operational efficiency and
sustainability of SEB services. Through these advancements, the
shared electric bicycle ecosystem is evolving, making strides
towards a more reliable, user-friendly, and sustainable mode of
transportation.
Index Terms—Transformer, Graph Neural Networks, AIoT
Battery-Swap Service
I. INTRODUCTION
The emergence of the sharing economy has become ubiq-
uitous across diverse facets of modern society [1]–[3], spot-
lighting Sharing E-Bike Battery (SEB) [4] as a focal point of
attention. Furthermore, the sharing battery assumes a central
¶Equal contribution.
∗Corresponding author.
role in numerous intelligent systems, particularly in the context
of AIoT with battery-swap services. As an illustration, in e-
bike battery-swap services , range prediction functions as the
primary propulsion source, delivering the necessary driving
force for the entire vehicle’s operation. The performance of SEB
plays a pivotal role in determining critical factors, including
driving range [5], fuel efficiency [6], and safety standards [7]
within the realm of electric vehicles. Additionally, a noticeable
disparity persists between user expectations and the actual
remaining range of SEBs. This discrepancy is particularly
evident when users urgently require access to available SEBs,
a situation that carries significant implications for alleviating
range-related concerns during their journeys. The provision of
accurate range prediction and strategically optimal placement of
exchange stations can greatly aid users in their route planning
endeavors [8]–[10], thereby enhancing operational efficiency
and promoting energy conservation initiatives.
Range anxiety of riders need to swap batteries primarily
due to insufficient battery range, as e-bikes can only travel a
limited distance on a single charge. This necessitates swapping
when the battery depletes. Additionally, long charging times
contribute to the need for swapping, as waiting for a battery
to recharge is often impractical, especially for riders using e-
bikes for delivery services or commuting. Battery degradation
over time also means batteries hold less charge, requiring
more frequent swaps. Operational efficiency, particularly for
commercial use, favors swapping over recharging to ensure
continuous operation. Convenience plays a significant role,
as swapping stations offer a quick solution compared to the
lengthy recharging process. In areas with inadequate charging
infrastructure, swapping becomes a practical necessity. Lastly,
range anxiety—the fear of running out of power without access
to charging—prompts riders to prefer battery swapping to
ensure their e-bikes are always ready for use. This study
focuses primarily on this aspect, with a specific emphasis on
the refinement and enhancement of range prediction accuracy.
arXiv:2407.16115v1  [cs.LG]  23 Jul 2024

Fig. 1. AIoT Battery-Swap Services. The workflow involves riders interacting with AIoT systems through an app, accessing battery-swap
services designed for efficiency and convenience. AIoT system integration includes three key aspects: signal and sensor interfacing for
real-time data stream, cloud center and transformer-based model for advanced processing and analytics, and finally, services seamlessly
connecting with the app to deliver user-centric solutions.
AIoT Battery-Swap Services denote a sophisticated system
integrating Artificial Intelligence of Things (AIoT) technology
with battery-swapping facilities tailored for e-bike, marking
the advent of a revolutionary phase in energy management
and mobility solutions (see Fig.1). The primary objective of
this service is to augment the efficiency and convenience of
electric e-bike usage. This is achieved through the utilization
of smart sensors, connectivity solutions, and advanced AI algo-
rithms, all geared towards optimizing battery management and
exchange processes. These processes encompass battery usage
monitoring, demand pattern prediction, and the streamlining
of the swapping procedure. A key focal point of AIoT battery-
swapping services lies in the enhancement of battery range and
longevity. Through the utilization of real-time data analytics
and predictive algorithms, AIoT systems possess the capability
to accurately evaluate battery health, forecast remaining range,
and suggest optimal intervals for battery swapping. Such a
proactive approach plays a pivotal role in mitigating range
anxiety among e-bike riders, guaranteeing timely access to
fully charged batteries whenever required. Consequently, this
fosters the widespread adoption of batteries, thus contributing to
the acceleration of sustainable transportation solutions. Through
the integration of AIoT Battery-Swap Services outlined in our
paper, we overcome the constraints associated with traditional
charging infrastructure. This results in an array of benefits,
including heightened convenience [11], scalability [11], and
sustainability, laying the groundwork for a more sustainable
and efficient transportation network [12]. This innovative
technology not only expedites the adoption of batteries but also
lays the groundwork for a smarter, interconnected ecosystem
poised to revolutionize the future of transportation and energy
consumption, ushering in an era of sustainable and efficient
mobility solutions.
Considering the complex characteristics inherent in this
dynamic prediction task, our research focus is increasingly
oriented towards the utilization of Transformers, which are
currently recognized extensively in the academic community.
The Transformer architecture, a groundbreaking development in
neural network design, has significantly transformed the fields
of natural language processing and sequential learning. Its in-
novative attention mechanism has established new benchmarks
for state-of-the-art performance across a multitude of domains.
Interest in investigating data-driven approaches is growing
rapidly [13]–[17], particularly those leveraging Transformer-
based models, for the prediction of battery range. However,
the exclusive reliance on Transformers or alternative models
to address the complexities of dynamic graph sequence tasks
is inadequate. This approach fails to account for structural
information and the critical interactions between the graph ele-
ments and sequences. Transforming non-Euclidean interactive
networks [18] into Euclidean space represents a significant
challenge for traditional machine learning methodologies.
Through the adoption of a graph structure, Transformers are
adept at capturing the intricate relationships and interactions
that exist between batteries and users efficiently. Summarily, our
research endeavors to address the following pivotal question:
“How can an advanced neural network architecture be developed
to more effectively incorporate structural information for the
prediction of battery range, through the innovative application
of Transformers?"
In this study, we delve deeply into the pivotal issue of
predicting the remaining range in Sharing E-Bike Battery

(SEB), with a specific focus on applications within the Artificial
Intelligence of Things (AIoT) domain. This concern is of
utmost importance for end-users, influencing both usability
and service satisfaction. We propose a novel, task-oriented
model termed as SEB-Transformer, which employs a structural
Transformer-based methodology specifically devised for the
accurate prediction of battery range in SEBs. We envision
the scenario as a dynamic, heterogeneous graph, meticulously
crafted to encapsulate the intricate interplay and connections
between users and bicycles. Additionally, we seamlessly inte-
grate this graph structure into the SEB-Transformer framework.
This integration facilitates the concurrent estimation of not
only the remaining range of e-bike battery but also the average
structural similarity across the system, providing a holistic view
of the network’s dynamics. By leveraging the insights obtained
from our model, we dynamically optimize cycling routes for
users in real time. This optimization process considers the
spatial distribution of charging stations, thereby enhancing user
experience by ensuring efficient energy use and reducing the
likelihood of battery depletion during trips.
Our contributions are summarized as follows:
• AIoT Battery-Swap Services. We delineate the scenario
of Sharing E-Bike Battery (SEB) as a dynamic hetero-
geneous graph, a conceptual framework that allows for
the representation of complex relationships and attributes.
Furthermore, we elucidate the introduction of structural
information into this framework, thereby leveraging
GNN’s powerful capability to process and analyze graph-
structured data.
• Transformer-based Structual GNNs. We propose the
SEB-Transformer model, a novel structural Transformer-
based framework designed specifically for the prediction
of sharing e-bike battery range. This model leverages
the advanced capabilities of Transformer architectures to
analyze and predict battery usage patterns, incorporating a
structural perspective that enhances its predictive accuracy
and reliability for applications in e-bike.
• Real-world Evaluation. In our empirical analysis, the
SEB-Transformer model was evaluated using a dataset
derived from real-world scenarios, alongside a comparison
against nine other competitive baseline models. The results
of this evaluation unequivocally illustrate the enhanced
performance of our model. Notably, it outperforms the
traditional vanilla Transformer model by a significant
margin, achieving an improvement of over 36.7%. This
notable enhancement underscores the effectiveness of the
SEB-Transformer in addressing the complexities of range
prediction in sharing e-bike battery.
Outline. Section II provides an overview of related works,
encompassing GNNs, Transformer, and their applications in
prediction tasks. Section III offers an introduction to the
fundamentals of Transformers and GNNs. Subsequently, we
present our proposed framework and discuss the scenario
involving shared e-bike battery. Section VI delves into various
applications linked with web services. Finally, Section V
presents a comprehensive experimental study conducted on a
real-world dataset.
II. RELATED WORKS
This section provides an overview of related works, including
models utilized in SEB-Transformer, such as GNNs and
Transformer. Additionally, we will discuss the connection to
our work.
a) GNNs and Transformer: The fusion of graph neural
networks (GNNs) [19] and Transformers marks a pivotal
development in machine learning, with GNNs excelling in
graph data analysis and Transformers advancing sequence tasks.
Prior to Transformers [20]–[23], RNNs, including LSTMs
[24] and GRUs [21], dominated sequence processing but fell
short in distributed computing. The advent of the attention
mechanism, epitomized by Google’s BERT [25], revolutionized
NLP by enhancing focus on relevant data segments during
processing. This synergy between GNNs for local structure
and Transformers for global dependencies is now under active
investigation, aiming to unify their strengths for improved
performance across tasks.
b) Transformer for prediction task: Deep neural networks
have increasingly become the foundational framework for
prediction tasks [26], paralleled by the substantial development
of the Transformer model. Transformer model is optimally
utilized in scenarios where it can simultaneously generate
predictions for interrelated tasks. Research into employing
Transformers for prediction tasks has become a critical focus
within the machine learning domain. Originally designed for
natural language processing tasks [20], [21], Transformers have
showcased exceptional ability in identifying complex sequential
patterns and managing long-range dependencies. Expanding
the use of Transformers [26]–[28] beyond traditional sequence-
based applications to include a variety of domains like time-
series forecasting, image classification, and financial prediction
has broadened their applicability. This study delves into the
use of Transformers in predictive modeling, highlighting their
strengths in deciphering complex data relationships.
c) Transformer for combinatorial task:
Beyond the
widespread adoption of the simulated annealing technique
for a range of combinatorial optimization challenges [29]–
[31], recent scholarly efforts have explored the integration
of RNNs in this sphere. Although RNNs have not uniformly
achieved error rates as minimal as those attained through an-
nealing methods, the findings have been promising, showcasing
significant improvements in solution speed. This suggests a
strategic equilibrium between precision and high efficiency, a
compromise that might be particularly appealing to stakeholders
like Google Maps users and crew schedulers seeking to refine
their scheduling processes. The exploration of Transformer
models for combinatorial tasks has become a focal point in
contemporary machine learning research. Initially conceived
for natural language processing tasks, Transformers have
demonstrated exceptional proficiency in identifying complex
dependencies and patterns, prompting their adoption in a
variety of fields, such as combinatorial optimization challenges.

TABLE I
NOTATION TABLE.
Name
Description
t
time step
HG(t) = (V (t), E(t))
heterogeneous graph at time t
V (t) = {v(t)
i }N
i=1
set of nodes at time t
E(t) = {e(t)
i
= (v(t)
i,1, v(t)
i,2)}M
i=1
set of edges at time t
T = {ti}T
i=1
set of node’s type
R = {ri}R
i=1
set of edge’s type
W, B
parameters in GNNs
Q, K, V
query/key/value matrix in atten-
tion mechanism
Combinatorial tasks fundamentally involve choosing the best
solutions from a set of discrete options, making them prevalent
in areas like logistics [32], operations research [33], and
network design [34].
III. PRELIMINARIES
Notation. We denote a graph as G and its edges and nodes as
E and V respectively. We represent an ordinary graph as a set
of edges E = {(vi, vj) | vi, vj ∈V}, where n is the number
of observed edges. For each node v and edge e, we use their
bold version v and e to denote their embeddings. We use bold
capital letters. e.g., A, B, W to denote matrices and use ∥·∥to
denote the Euclidean norm of vectors or the Frobenius norm of
matrices. Due to space limitations, we summarize this paper’s
main symbols and notations in Table I.
A. Scenario of SEBs
The scenario involving Sharing E-Bike Battery (SEB) with
shared battery presents a complex landscape, requiring a
detailed representation of the dynamic interactions between
riders and e-bike batteries within the framework of a temporal
graph. When users replace batteries, it becomes feasible for
the same battery to appear at multiple exchange stations,
thus enabling its reuse by a succession of different users
across the system. In order to accurately capture the system’s
diverse characteristics, we utilize the notation HG = V, E,
representing the heterogeneous graph input that encompasses
the intricate relationships within the SEB ecosystem. Within
this framework, the set of nodes is comprehensive, including
both user nodes and battery nodes, which are defined as
V
= VU ∪VB, illustrating the system’s dual aspects of
interaction and utility. By interlinking users and batteries
through edges, the structure of HG naturally conforms to the
characteristics of a bipartite graph, reflecting the two distinct
but interconnected groups within the system. For clarity and
further understanding, we present a simplified illustration of
the SEB system in Fig.2, which visualizes the conceptual
framework discussed.
B. Graph Neural Networks
Most Graph Neural Networks (GNNs) [19] conform to the
messing passing between neighboring nodes, which can be
described as the following iteration functions:
ml+1
v
= f l
θ(hl
v, {hl
u|u ∈Nv})
(1)
hl+1
v
= σl(gl(hl
v, ml+1
v
)),
(2)
where f l
θ, σl, gl denote parametric functions, i.e., neighborhood
aggregation function, activation function (e.g. sigmoid, ReLU),
and combination function (e.g. summation, mean), at the l-layer
messaging passing on graphs. Nv denotes the neighborhood
for node v and hl
v denotes the hidden embedding for v. Such
message passing in Eq.1 will repeat L times (l ∈{1, 2, . . . , L})
until converge. For the combinatorial optimization task in this
paper, the information will only pass across the entire graph.
Taking GCN for example, the message-passing function in
graph convolutional network [19] is explicitly written as:
hl+1
v
= σ
 
Wl X
u∈Nv
hl
u
|Nv| + Blhl
v
!
,
(3)
where Wl and Bl are learnable parameters in l-layer.
C. Transformer
Transformer [21], [35] signifies a notable achievement in
the realm of natural language processing (NLP) and machine
learning. Departing from traditional recurrent or convolutional
architectures, the Transformer leverages a self-attention mecha-
nism to capture contextual dependencies across input sequences,
enabling it to excel in tasks such as language translation, sum-
marization, and question-answering. The model’s innovative
architecture eliminates sequential dependencies, allowing for
parallelization during training and significantly accelerating
processing times.
For a given input vector X = [x1, x2, . . . , xN] ∈RN×D,
where xi ∈RD, transform embeds X into the output H in the
following two steps:
Step 1: We project X into three matrices: Q (query matrix),
K (key matrix), V (value matrix) via linear transformation as
follows:
Q = XWT
Q, K = XWT
K, V = XWT
V
(4)
Q = [q(1), q(2), . . . , q(N)]
(5)
K = [k(1), k(2), . . . , k(N)]
(6)
V = [v(1), v(2), . . . , v(N)]
(7)
where WQ, WK ∈RDqk×D and WV ∈RD.
Step 2: The output vector H = [h(1), h(2), . . . , h(N)] ∈
RN×Dqk is then computed as follows:
H = Softmax
 
QKT
p
Dqk
!
V.
(8)
Our work refers to a Transformer that uses the classical softmax
attention.

IV. FRAMEWORK
A. Dynamic SEB scenario
The scenario of sharing e-bike battery is complex and
we describe the interaction between users and batteries as
a temporary graph at time t. When users replace the battery,
the same battery may appear at different exchange stations
and subsequently be utilized by different users. We use
HG(t) = {V (t), E(t)} to represent the input heterogeneous
graph at time t. The set of nodes includes user nodes and battery
nodes as V (t) = V (t)
U
∪V (t)
B . Thus, graph neural networks (see
Section III-B) can readily embed HG(t). Edges are connected
by users and batteries, and then HG(t) can be described as a
bipartite graph.
B. SEB-Transformer
Here, we introduce the details of SEB-Transformer. Initially,
the dataset is bifurcated into two classifications: the first
comprises standard time series Euclidean data, while the
second encompasses non-Euclidean data representing the
temporal dynamic graph (see Section IV-A). Then we use
SEB-Transformer to update the features on edges and nodes.
We update the embeddings of edge features by GNNs as Eq.3.
Also, we use a Transformer to update the original features to
predict the range of e-bike battery. The above process can be
formulated as follows:
X(t)
1
= GNN(V (t)
U , V (t)
B , HG(t))
(9)
X(t)
2
= Transformer(V (t)
U , V (t)
B , X(t)
0 )
(10)
Then, we can obtain the predicted labels as:
bY(t) = MLP

ˆX(t)
(11)
where ˆX(t) = X(t)
0
L ˆX(t)
1
L ˆX(t)
2 .
C. S3IM
We give a genetic form for the strong structural similarity
index on graph S3IM: Rn × Rn →R as follows:
S3IM(x, y) = f(r1(x, y), r2(x, y), r3(x, y))
(12)
f(r1, r2, r3) = [r1]α · [r2]β · [r3]γ
(13)
where α, β, γ are parameters used to adjust the relative
importance of the three terms.
The S3IM term contains three components which will be
presented in the next subsection with details. As the previous
paper [36] says, the similarity measure should obey the
following conditions:
• Symmetric: S3IM(x, y) = S3IM(y, x).
• Boundedness: S3IM(x, y) ≤M
• Unique maximization: S3IM(x, y) = M if and only if
x = y in element wise (xi = yi, i ∈[n]).
Next, we will introduce the details of each component
r1, r2, r3 shown in Eq.12 and we call them (1) luminance
term, (2) contrast term, and (3) structure term, respectively.
...
Sharing E-bike Battery Scenario
A
SEB-Transformer
B
C

regularization Term
...
...
...
GNN
Transformer
LSTM
...
...
+
MLP
Fig. 2. Illustration of SEB scenario and SEB-Transformer.
(1) luminance term r1. As the first term, we can define the
luminance as follows
r1(x, y) = 2µxµy + C1
µ2x + µ2y + C1
(14)
where C1 > 0 is a constant to avoid the denominator being
zero. Usually, we choose C1 = (K1L), L is the length of the
output and K1 ≪1 is a pretty small constant.
(2) contrast term r2. The second term, we can define the
contrast function as
r2(x, y) = 2σxσy + C2
σ2x + σ2y + C2
(15)
where C2 = (K2L)2 and K2 ≪1.
(3) structure term r3. The third term, we can refer to the
following form
r3(x, y) = σxy + C3
σxσy + C3
(16)
where
σxy =
1
n −1
n
X
i=1
(xi −µx)(yi −µy)
(17)
Overview. The primary aim of this section is to furnish a com-
prehensive overview of the SEB-Transformer, delineating its
core principles and operational framework. Prior to embarking
on the prediction of battery range, we precisely define the
dynamic scenario of Sharing E-Bike Battery (SEB) as a hetero-
geneous graph, which effectively captures the intricate web of
interactions occurring between users and batteries. Following
this, we proceed to develop a structural Transformer model that
meticulously incorporates topological information, achieving
a seamless integration of both graph-based and sequential
data, thereby enriching the model’s predictive capabilities.
Furthermore, to augment the model’s ability to recognize
global structural information, we implement the advanced
regularization technique S3IM, which significantly improves the

Fig. 3. Statistical visualization.
precision of our predictions. Throughout the training phase, our
objective shifts towards minimizing the discrepancy between
the actual battery range Y(t) and its predicted counterpart bY(t),
over the entirety of the temporal spectrum under consideration.
The optimization strategy employed for our model is delineated
as follows, encompassing a detailed methodology aimed at
refining the accuracy of our predictive framework:
min
T
X
t=1
 
∥bY(t) −Y(t)∥2
|Y(t)|
+ S3IM( bY(t), Y(t))
!
.
(18)
V. EXPERIMENTS
This section provides a detailed exposition of our experi-
ments. Section V-A presents a real-world dataset collected by
our team, accompanied by an in-depth analysis of its statistical
information from various perspectives. Section V-B outlines
several competitive baselines that serve as benchmarks for
comparison, aiming to surpass their performance. Section V-C
highlights the main results assessed by our model.
A. Dataset
For our experimental investigations, we utilize a real-world
dataset that has been meticulously collected by our team. Our
dedicated engineering team meticulously curated a dataset
comprising 16,000 order samples, each enriched with 64 distinct
timing data points. Subsequently, we provide an overview of
statistical information pertaining to our dataset. In Fig.3, we
provided visualizations depicting sequence length information.
Observation of the dataset reveals that it approximates a normal
distribution, with an average value of 275, thereby suggesting
that the data we gathered is both reasonable and reflective of
societal dynamics.
B. Baseline
Within this section, we present an overview of the com-
petitive baseline methods utilized in our study, namely SVR,
LR, XGBoost, MLP, and the vanilla Transformer model. These
methods are implemented for our task.
• Support Vector Regression (SVR) [37], [38] stands
out as a robust machine learning method for regression
challenges, especially adept at managing datasets where
the variables exhibit intricate interconnections.
• Linear Regression (LR) [39] is a fundamental statistical
method utilized in machine learning and data analysis for
establishing a connection between a dependent variable
and one or more independent variables. LR presupposes
a direct linear connection between the input factors and
the outcome, depicted as a straight line within a multi-
dimensional space. The model calculates the coefficients
for the linear equation that most closely aligns with the
observed data points, by reducing the sum of the squared
differences (residuals).
• eXtreme Gradient Boosting [40] is an effective and
robust machine learning technique renowned for its effec-
tiveness in predictive modeling and classification tasks.
It belongs to the ensemble learning family, specifically
boosting algorithms, which sequentially combine weak
learners to create a robust and accurate model. XGBoost
utilizes a gradient boosting framework, employing deci-
sion trees as base learners. It excels in handling structured
data and is known for its speed, scalability, and accuracy.
XGBoost incorporates regularization techniques to prevent
overfitting and provides features for fine-tuning model
performance, such as cross-validation and early stopping.
• Multilayer Perceptron (MLP) [13] represents a basic
artificial neural network structure, featuring several layers
of linked neurons, including an input layer, at least one
hidden layer, and an output layer.
• Transformer [21] is a groundbreaking architecture in
deep learning that has notably propelled advancements in
natural language processing (NLP) and related sequence-
dependent tasks. Unlike previous recurrent or convolu-
tional models, the Transformer relies entirely on self-
attention mechanisms to capture dependencies between
input and output tokens in parallel.
C. Main Results
The experimental results have been succinctly summarized
in Table II. The last two models represent variants of the
SEB-Transformer architecture. An additional regularization
term, denoted as S3IM, has been incorporated into the SEB-
Transformer∗architecture. The aforementioned models serve
as ten competitive baselines, providing a robust benchmark for
evaluation. Remarkably, our model surpasses these baselines
by a substantial margin. Furthermore, Fig.6 has been included
to visually illustrate the effects of each improvement. This
visual representation effectively demonstrates the impact of
individual improvements. Additionally, the Fig.5 showcases
the best MAE achieved by our model. This presentation serves
to underscore that our model consistently outperforms others
even in dynamic stream conditions.
Fig.7 presents a visual depiction of the loss curve as observed
throughout the training and validation phases, providing a
graphical representation of the model’s performance over
these periods. When compared to the baseline models, our
framework demonstrates a decrease in loss, indicating its

Fig. 4. Analysis of the outliers in our data.
Fig. 5. Illustration of MAE for the best performance.
MAE
+LSTM
Transformer based Model
+GNN
+SSIM
Framework
2.38
2.22
1.86
1.45
Fig. 6. Demonstration of framework improvements.
superior performance in reducing the discrepancy between
predicted outcomes and actual values. This improvement
underscores the framework’s superior efficacy in aligning
predictions closely with real-world data.
VI. APPLICATION WITH WEB SERVICE
Within Sharing E-Bike Battery (SEB), the app and web
service are key to user experience and system efficiency.
Future improvements promise to enhance SEB functionality
and accessibility, fostering wider use and greater satisfaction.
By addressing these application perspectives, SEB have the
opportunity to enhance user satisfaction, optimize system
efficiency, and contribute to the widespread adoption of
sustainable transportation solutions.
• User Interface Design. Prioritizing user-centric design
principles [41] in mobile applications is essential for
TABLE II
MAE ON THE BATTERY RANGE PREDICTION TASK
Model
MAE ↓
SVR
4.7564 ± 2.0711
LR
4.7645 ± 1.9910
XGBoost
5.1529 ± 4.2586
Auto-Encoder
5.3849 ± 4.2582
MLP
4.3606 ± 2.0636
LSTM
3.1380 ± 1.7353
Transfomer
2.3772 ± 1.4306
TEConv+LSTM
2.2240 ± 1.5272
TEConv+Transformer
1.9908 ± 1.7498
LSTM+Transfomer
1.8642 ± 1.3228
SEB-Transformer
1.5020 ± 1.2281
SEB-Transformer∗
1.4552 ± 1.0332
offering intuitive interfaces that enable users to access
battery status information, locate nearby SEB stations,
and plan routes based on predicted battery ranges. Adding
features like interactive maps, customizable ride options,
and live updates could greatly improve the user experience
and encourage more frequent use of SEB services. These
enhancements can contribute to a more engaging and
satisfying experience for users, thereby promoting greater
adoption and usage of SEB services.
• Predictive Range Estimation. The integration of battery
range prediction algorithms [42] directly into the applica-
tion interface aims to empower users by providing them
with accurate estimations of remaining battery life for
their planned journeys. This integration could involve the
display of estimated range, considering factors such as
user weight, terrain, and historical usage patterns.
• Ride Optimization Features. The implementation of
ride optimization features within the application aims to
improve user convenience and system efficiency. These
features may encompass smart routing algorithms capable
of suggesting optimal paths based on available battery
range and user preferences. Additionally, real-time alerts
and notifications will be integrated to remind users to
recharge or swap batteries as needed, further enhancing

Fig. 7. Training loss among various models: (top line) auto-encoder, lstm, mlp, and (bottom line) Transformer, Transformer plus lstm,
SEB-Transformer.
the overall user experience and system efficiency.
• Data Visualization and Analytics. Utilizing data visual-
ization techniques [43] within the application interface to
present battery usage statistics, ride history, and system
performance metrics in a clear and comprehensible manner
is essential. By providing users with insights into their
usage patterns, environmental impact, and potential cost
savings, we can foster greater awareness and engagement
with SEB services.
• Integration with Urban Mobility Ecosystem. Facili-
tating seamless integration with existing urban mobility
ecosystems involves ensuring interoperability with public
transit systems, ride-sharing platforms, and navigation
services. This may entail the provision of multi-modal
trip planning capabilities, integration of payment systems
for seamless fare integration, and enabling cross-platform
connectivity to enhance overall transportation accessibility
and convenience.
VII. DISCUSSION AND CONCLUSION
Why We Need Sharing E-Bike Battery.
(1) Bridging
Expectation Gaps: A notable discrepancy exists between user
expectations and the actual remaining battery range of SEBs,
especially in urgent needs for accessible SEBs. (2) Operational
Efficiency and Energy Conservation: Accurate battery range
prediction and strategic placement of exchange stations can
significantly enhance route planning, operational efficiency, and
energy conservation. (3) Promoting Sustainable Transportation:
By overcoming limitations associated with traditional charging
infrastructure, sharing e-bike batteries can lead to a more
efficient and environmentally friendly transportation ecosystem.
Conclusion. In this paper, we have conceptualized the scenario
involving Sharing E-Bike Battery (SEB) as a dynamic hetero-
geneous graph. Concurrently, we introduce the innovative SEB-
Transformer, which is specifically designed for the purpose of
battery range prediction. Furthermore, it is noteworthy that our
model significantly outperforms the conventional Transformer
models, indicating a substantial improvement in predictive
performance. The contributions of our work represent a notable
advancement within the domain of web services, characterized
by a dual achievement: the reduction of carbon emissions
and the enhancement of user satisfaction, thereby marking a
pivotal step forward in sustainable urban mobility. We propose
a novel, task-oriented model termed as SEB-Transformer,
which employs a structural Transformer-based methodology
specifically devised for the accurate prediction of battery range
in SEBs. Utilizing the prediction, we can dynamically modify
optimal cycling routes for users in real-time, taking into account
the locations of charging stations. Experimental results shows
that our model outperforms nine other competitive baseline
models on real-world datasets, with a significant reduction in
the MAE (Mean Absolute Error) metric compared to the basic
Transformer model.
ACKNOWLEDGMENT
This work was partially supported by the National Key
R&D Program of China (2023YFB4502400), the Strategic
Priority Research Program of the Chinese Academy of Sciences
(XDB0680101), the NSFC (62376064, U2336202), and the
CAS Project for Young Scientists in Basic Research (YSBR-
008).

REFERENCES
[1] M. Cheng, “Sharing economy: A review and agenda for future research,”
International Journal of Hospitality Management, vol. 57, pp. 60–70,
2016.
[2] M. Hossain, “Sharing economy: A comprehensive literature review,”
International Journal of Hospitality Management, vol. 87, p. 102470,
2020.
[3] Z. Li, G. Ren, Y. Gu, S. Zhou, X. Liu, J. Huang, and M. Li, “Real-time
e-bike route planning with battery range prediction,” in Proceedings of
the 17th ACM International Conference on Web Search and Data Mining,
2024, pp. 1070–1073.
[4] J. Li, J. Shen, and B. Jia, “Exploring intention to use shared electric
bicycles by the extended theory of planned behavior,” Sustainability,
vol. 13, no. 8, p. 4137, 2021.
[5] Z. Lu, Q. Zhang, Y. Yuan, and W. Tong, “Optimal driving range for
battery electric vehicles based on modeling users’ driving and charging
behavior,” Journal of Advanced Transportation, vol. 2020, pp. 1–10,
2020.
[6] V. Kiray, M. Orhan, and J. N. Chijioke, “Significant increase in fuel
efficiency of diesel generators with lithium-ion batteries documented by
economic analysis,” Energies, vol. 14, no. 21, p. 6904, 2021.
[7] Q. Yu, Y. Nie, S. Peng, Y. Miao, C. Zhai, R. Zhang, J. Han, S. Zhao, and
M. Pecht, “Evaluation of the safety standards system of power batteries
for electric vehicles in china,” Applied Energy, vol. 349, p. 121674, 2023.
[8] H. Bast, D. Delling, A. Goldberg, M. Müller-Hannemann, T. Pajor,
P. Sanders, D. Wagner, and R. F. Werneck, “Route planning in
transportation networks,” Algorithm engineering: Selected results and
surveys, pp. 19–80, 2016.
[9] D. S. Alberts and R. E. Hayes, Planning: complex endeavors.
CCRP
publications Washington, DC, 2007.
[10] R. krishna Vaddy, “Ai and ml for transportation route optimization,”
International Transactions in Machine Learning, vol. 5, no. 5, pp. 1–19,
2023.
[11] Z. Chang, S. Liu, X. Xiong, Z. Cai, and G. Tu, “A survey of recent
advances in edge-computing-powered artificial intelligence of things,”
IEEE Internet of Things Journal, vol. 8, no. 18, pp. 13 849–13 875, 2021.
[12] F. A. Alaba, A. Oluwadare, U. Sani, A. A. Oriyomi, A. O. Lucy, and
O. Najeem, “Enabling sustainable transportation through iot and aiot
innovations,” in Artificial Intelligence of Things for Achieving Sustainable
Development Goals.
Springer, 2024, pp. 273–291.
[13] S. A. Hasib, D. K. Saha, S. Islam, M. Tanvir, and M. S. Alam, “Driving
range prediction of electric vehicles: A machine learning approach,”
in 2021 5th International Conference on Electrical Engineering and
Information Communication Technology (ICEEICT).
IEEE, 2021, pp.
1–6.
[14] J. Gallardo-Lozano, E. Romero-Cadaval, M. I. Milanes-Montero, and
M. A. Guerrero-Martinez, “Battery equalization active methods,” Journal
of Power Sources, vol. 246, pp. 934–949, 2014.
[15] C. Hu, B. D. Youn, and J. Chung, “A multiscale framework with extended
kalman filter for lithium-ion battery soc and capacity estimation,” Applied
Energy, vol. 92, pp. 694–704, 2012.
[16] J. Li, K. Adewuyi, N. Lotfi, R. G. Landers, and J. Park, “A single particle
model with chemical/mechanical degradation physics for lithium ion
battery state of health (soh) estimation,” Applied energy, vol. 212, pp.
1178–1190, 2018.
[17] Y. Li, K. Liu, A. M. Foley, A. Zülke, M. Berecibar, E. Nanini-Maury,
J. Van Mierlo, and H. E. Hoster, “Data-driven health estimation and
lifetime prediction of lithium-ion batteries: A review,” Renewable and
sustainable energy reviews, vol. 113, p. 109254, 2019.
[18] N. A. Asif, Y. Sarker, R. K. Chakrabortty, M. J. Ryan, M. H. Ahamed,
D. K. Saha, F. R. Badal, S. K. Das, M. F. Ali, S. I. Moyeen et al.,
“Graph neural network: A comprehensive review on non-euclidean space,”
IEEE Access, vol. 9, pp. 60 588–60 606, 2021.
[19] T. N. Kipf and M. Welling, “Semi-supervised classification with graph
convolutional networks,” in International Conference on Learning
Representations (ICLR), 2017.
[20] E. Min, R. Chen, Y. Bian, T. Xu, K. Zhao, W. Huang, P. Zhao, J. Huang,
S. Ananiadou, and Y. Rong, “Transformer for graphs: An overview from
architecture perspective,” arXiv preprint arXiv:2202.08455, 2022.
[21] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,
Ł. Kaiser, and I. Polosukhin, “Attention is all you need,” Advances in
neural information processing systems, vol. 30, 2017.
[22] V. P. Dwivedi and X. Bresson, “A generalization of transformer networks
to graphs,” arXiv preprint arXiv:2012.09699, 2020.
[23] C. Ying, T. Cai, S. Luo, S. Zheng, G. Ke, D. He, Y. Shen, and T.-Y.
Liu, “Do transformers really perform badly for graph representation?”
Advances in Neural Information Processing Systems, vol. 34, pp. 28 877–
28 888, 2021.
[24] A. Sherstinsky, “Fundamentals of recurrent neural network (rnn) and long
short-term memory (lstm) network,” Physica D: Nonlinear Phenomena,
vol. 404, p. 132306, 2020.
[25] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, “Bert: Pre-training
of deep bidirectional transformers for language understanding,” arXiv
preprint arXiv:1810.04805, 2018.
[26] Y. Xu, X. Li, H. Yuan, Y. Yang, and L. Zhang, “Multi-task learning
with multi-query transformer for dense prediction,” IEEE Transactions
on Circuits and Systems for Video Technology, 2023.
[27] A. Nambiar, M. Heflin, S. Liu, S. Maslov, M. Hopkins, and A. Ritz,
“Transforming the language of life: transformer neural networks for
protein prediction tasks,” in Proceedings of the 11th ACM international
conference on bioinformatics, computational biology and health infor-
matics, 2020, pp. 1–8.
[28] L. Yang, T. L. J. Ng, B. Smyth, and R. Dong, “Html: Hierarchical
transformer-based multi-task learning for volatility prediction,” in Pro-
ceedings of The Web Conference 2020, 2020, pp. 441–451.
[29] Q. Wang, K. H. Lai, and C. Tang, “Solving combinatorial optimization
problems over graphs with bert-based deep reinforcement learning,”
Information Sciences, vol. 619, pp. 930–946, 2023.
[30] B. Yildiz, “Reinforcement learning using fully connected, attention, and
transformer models in knapsack problem solving,” Concurrency and
Computation: Practice and Experience, vol. 34, no. 9, p. e6509, 2022.
[31] T. Wang, A. H. Payberah, and V. Vlassov, “Graph representation
learning with graph transformers in neural combinatorial optimization,”
in 2023 International Conference on Machine Learning and Applications
(ICMLA).
IEEE, 2023, pp. 488–495.
[32] Y. Ren, X. Lu, H. Guo, Z. Xie, H. Zhang, and C. Zhang, “A
review of combinatorial optimization problems in reverse logistics and
remanufacturing for end-of-life products,” Mathematics, vol. 11, no. 2,
p. 298, 2023.
[33] N. Mazyavkina, S. Sviridov, S. Ivanov, and E. Burnaev, “Reinforcement
learning for combinatorial optimization: A survey,” Computers &
Operations Research, vol. 134, p. 105400, 2021.
[34] M. Chen, S. C. Liew, Z. Shao, and C. Kai, “Markov approximation for
combinatorial network optimization,” IEEE transactions on information
theory, vol. 59, no. 10, pp. 6301–6327, 2013.
[35] T. Nguyen, T. M. Nguyen, and R. G. Baraniuk, “Mitigating over-
smoothing in transformers via regularized nonlocal functionals,” in Thirty-
seventh Conference on Neural Information Processing Systems, 2023.
[36] Z. Wang, A. C. Bovik, H. R. Sheikh, and E. P. Simoncelli, “Image
quality assessment: from error visibility to structural similarity,” IEEE
transactions on image processing, vol. 13, no. 4, pp. 600–612, 2004.
[37] J. Cervantes, F. Garcia-Lamont, L. Rodríguez-Mazahua, and A. Lopez,
“A comprehensive survey on support vector machine classification:
Applications, challenges and trends,” Neurocomputing, vol. 408, pp.
189–215, 2020.
[38] Y. Zhang, “Support vector machine classification algorithm and its
application,” in Information Computing and Applications: Third Inter-
national Conference, ICICA 2012, Chengde, China, September 14-16,
2012. Proceedings, Part II 3.
Springer, 2012, pp. 179–186.
[39] M. Ahmed, Z. Mao, Y. Zheng, T. Chen, and Z. Chen, “Electric vehicle
range estimation using regression techniques,” World Electric Vehicle
Journal, vol. 13, no. 6, p. 105, 2022.
[40] T. Chen and C. Guestrin, “Xgboost: A scalable tree boosting system,”
in Proceedings of the 22nd acm sigkdd international conference on
knowledge discovery and data mining, 2016, pp. 785–794.
[41] D. Stone, C. Jarrett, M. Woodroffe, and S. Minocha, User interface
design and evaluation.
Elsevier, 2005.
[42] A. Enthaler and F. Gauterin, “Method for reducing uncertainties of
predictive range estimation algorithms in electric vehicles,” in 2015
IEEE 82nd vehicular technology conference (VTC2015-Fall).
IEEE,
2015, pp. 1–5.
[43] G. Andrienko, N. Andrienko, S. Drucker, J.-D. Fekete, D. Fisher, S. Idreos,
T. Kraska, G. Li, K.-L. Ma, J. Mackinlay et al., “Big data visualization
and analytics: Future research challenges and emerging applications,” in
BigVis 2020-3rd International Workshop on Big Data Visual Exploration
and Analytics, 2020.

