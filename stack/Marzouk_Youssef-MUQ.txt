MUQ (MIT Uncertainty Quantiﬁcation):
Flexible Software for Connecting Algorithms and Applications
Matthew Parno, Andrew Davis, Patrick Conrad, and Youssef Marzouk
Center for Computational Engineering
Massachusetts Institute of Technology
Motivation
MUQ (pronounced “muck”) is a collection of C++ and Python libraries for accelerating both the
application of existing uncertainty quantiﬁcation (UQ) algorithms and the development of new
approaches. To facilitate these tasks, MUQ provides interfaces for deﬁning and coupling models with
UQ-related algorithms. Throughout our code, we use well-founded software engineering techniques
and stable external libraries. Our goal is to provide an eﬃcient and stable platform to help users
“MUQ” about—and much more—in UQ.
C A P A B I L I T I E S
Modelling Module
Graph-based model construction
Random variables
Probability densities
Diﬀerentiation
θ
f
g1
g2
h
Model
output
Model
input
Inference Module
Markov chain Monte Carlo
Point estimates (MAP)
Transport maps
Importance sampling
DRAM
AMALA
NUTS (via STAN)
sMMALA
and more. . .
π(θ)
Prior
π(θ|d)
Posterior MAP
Posterior Samples
Approximation Module
Polynomial chaos expansions
Regression
Incremental approximation
h(θ)
True model
˜h(θ)
Approximation
Optimization Module
Constrained nonlinear programs
Assignment problems
Links to external optimizers
Geostatistics Module
Covariance kernels
Karhunen-Lo`eve (KL) decompositions
Utilities Module and Development Tools
Tools for HDF5 i/o
Vector type translation
Random number generation
Multi-indices
Linear solver and eigensolvers
Separating models from algorithms
It is challenging to provide a ﬂexible interface between scientiﬁc models and a wide variety of
algorithms. This is because diﬀerent algorithms exploit diﬀerent aspects of model structure, and
models can provide varying levels of information (e.g., gradients, Hessians, block structure). In MUQ,
we have generally adopted a three-component system to deﬁne the model-algorithm interface.
Algorithm
Metropolis-Hastings
Nelder-Mead
etc. . .
Problem
Optimization objective
Bayesian posterior
etc. . .
Model
Physical PDE or ODE
Statistical
etc. . .
Beneﬁts of this approach:
Models are independent of algorithms, which allows greater ﬂexibility on both sides.
Problems can extract algorithm-speciﬁc structure from models and provide meaningful defaults.
Model/problem approximations can be employed without changing algorithms.
Inheritance and extendability
A good software library will allow a user to complete complicated tasks with a minimal amount of
code. In MUQ, we try to achieve this using abstract classes. Users implement a few member
functions that deﬁne core functionality, and code from the parent class provides additional
functionality. This type of object orientated programming makes it easy to extend MUQ with new
models and new algorithms.
Example implementation: MCMC
There are 3 key components to
most MCMC algorithms:
1. The chain.
2. The kernel.
3. The proposal.
MUQ deﬁnes each component
through an abstract base class.
Typical MCMC algorithms:
Chain Kernel Proposal
Other conﬁgurations are also
possible. Hybrid methods might
use more than one kernel and/or
several proposals
AMALA
AM
RW
smMALA
MH
DR
TM
IA
Single
Multi
C O D E
E X A M P L E S
Combining model components
Assume we want to create a Bayesian posterior density, π(θ|d) ∝π(d|θ)π(θ), where
π(θ) = N(µ, Γ), d = f (θ) + ϵ, and ϵ ∼N(0, 1). The graphical model for the posterior and
the corresponding code are given below.
Parameter
θ
Model
f (θ)
Prior
π(θ)
Likelihood
π(d|θ)
Posterior
π(θ|d)
Python Code:
# Create the model components
para
= VectorPassthroughModel ()
p r i o r
= GaussianDensity (mu,gamma)
mod
= ForwardModel ()
l i k e l y = GaussianDensity ()
# Combine the components
graph = ModGraph ()
graph . AddNode( para , "Parameter")
graph . AddNode( prior , "Prior")
graph . AddNode( l i k e l y , "Likelihood")
graph . AddNode(mod, "Model")
graph . AddNode( DensityProduct () , "Posterior")
graph . AddEdge ("Parameter" ,"Prior" ,0)
graph . AddEdge ("Parameter" ,"Model" ,0)
graph . AddEdge ("Model" ,"Likelihood" ,0)
graph . AddEdge ("Prior" ,"Posterior" ,0)
graph . AddEdge ("Likelihood" ,"Posterior" ,1)
Deﬁning a new MCMC proposal
A fundamental quantity in Markov chain Monte Carlo (MCMC) algorithms is the proposal
density. In code, the proposal does two things: (1) generates a random sample of the
proposal, and (2) evaluates the proposal density. The code below shows an implementation
of a simple Gaussian random walk proposal.
C++ Code:
class MyPropoposal
: public MCMCProposal {
public :
/** Construct the proposal using information in props
*/
MyProposal ( shared ptr <AbstractSamplingProblem> prob ,
ptree& props )
:
MCMCProposal( prob , props ){
// extract the proposal variance from the parameters
propVar = props . get ("MCMC.MyProposal.Var" , 1 . 0 ) ;
// tell the problem what information this proposal needs
prob−>SetStateComputations (false , false , false ) ;
};
virtual ˜MyProposal () = default ;
/** This function generates a sample of the proposal */
virtual shared ptr <MCMCState> DrawProposal ( shared ptr <MCMCState> currentState ,
shared ptr <HDF5LogEntry> logEntry ){
Eigen : : VectorXd propState = currentState −>s t a t e ;
propState += s qr t ( propVar )∗RandomGenerator : : GetNormalRandomVector ( dim ) ;
return prob−>ConstructState ( propState ,0 , logEntry ) ;
};
/** This function evaluates the log proposal density for a pair of points. */
virtual double ProposalDensity ( shared ptr <MCMCState> currentState ,
shared ptr <MCMCState> proposedState ){
auto d i f f = proposedState−>state −currentState −>s t a t e ;
return −0.5∗d i f f . squaredNorm ()/ propVar ;
};
private : and/or
double propVar ;
};
Property tree parameters
Nearly all algorithms have tunable parameters. In MUQ, these are deﬁned through either a boost property tree (in
C++) or a dictionary (in Python). In either case, parameter names are matched with parameter values. These pairs
can also be easily store in structured xml ﬁles.
C++ code:
boost : : p r o p e r t y t r e e : : ptree params ;
params . put ("MCMC.Kernel" ,"DR" ) ;
params . put ("MCMC.Verbosity" ,3);
params . put ("Dummy" ,100.0);
Python code:
params = d i c t ()
params [ ’MCMC.Kernel’ ] = DR
params [ ’MCMC.Verbosity’]=3
params [ ’Dummy’]=100.0
XML ﬁle:
<MCMC>
<Kernel>DR</ Kernel>
<Verbosity>3</ Verbosity>
</MCMC>
<Dummy>100.0</Dummy>
U S E
I N
R E S E A R C H
Map-accelerated MCMC
Idea:
Use nonlinear variable
transformations to “precondition”
target density.
Apply any MCMC kernel to
transformed problem.
The exchangeability of MCMC kernels
and proposals makes testing many
methods easy.
reference proposal
qr(r ′|r) = N(r, σ2I)
mapped proposal
qθ(θ′|θ) = qr

˜T(θ′)| ˜T(θ)
 detD ˜T(θ′)

Pseudo marginal MCMC with local approximations
Idea:
Focus MCMC on parameters of interest
Marginalize unneeded parameters with
importance sampling
Approximating noisy likelihood dramatically
reduces model evaluations.
Performing marginalization in a problem class
allows the algorithm and model to be
independent of pseudo-marginal application.
Adaptive non-intrusive polynomial chaos
Idea:
Approximate forward model with polynomial
expansion.
Adaptively choose expansion terms and quadrature
points to minimize number of necessary model
evaluations.
The polynomial approximation has the same interface
as the original model, making it easy to swap with the
original model in any graph.
0
5
10
15
0
5
10
15
Order of x polynomial
Order of y polynomial
 
 
0
5
10
15
0
5
10
15
Order of x polynomial
 
 
Robust optimization of pumping rates
Idea:
Use posterior samples to evaluate expected head.
Control pumping rates to restrict contaminant
movement.
Optimization performed with sample average
approximation (SAA) or stochastic approximation (SA).
The same model implementation can be used for both
optimization and inference (just in diﬀerent graphs),
reducing repeated code.
Robust
solution
Deterministic
solution
Where can I get MUQ?
Want more? Download MUQ and ﬁnd links to our documentation at
bitbucket.org/mituq/muq
uqgroup.mit.edu
Supported by the US Department of Energy, Oﬃce of Advanced Scientiﬁc Computing Research (ASCR), part of the SciDAC Institute for the Quantiﬁcation of Uncertainty in Extreme Scale CompuTations (QUEST).
Email contacts:
ymarz@mit.edu, mparno@mit.edu

