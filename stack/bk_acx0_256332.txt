CODE LISTINGS AND FIGURES

CHAPTER 1
Figure 1.1 Typical graph of a stock price over time
Figure 1.2 Using linear regression to identify a trend in changing stock prices

Figure 1.3 Buying and selling according to our rules-based software to make a proØt
Figure 1.4 A graph of price vs. mileage for used Priuses from CarGraph.com

Figure 1.5 Fitting an exponential decline curve to price vs. mileage data for used Toyota
Priuses
Figure 1.6 Finding the mileage I should expect on a used Prius for my $10,000 budget
Figure 1.7 Labeling a point in 3D with a vector of three numbers, x, y, and z

Figure 1.8 Building a 3D triangle using a triple of Ùoat values for each of its corners
Figure 1.9 Three-dimensional (3D) spheres built out of the speciØed number of
triangles.
triangle = [(2.3,1.1,0.9), (4.5,3.3,2.0), (1.0,3.5,3.9)]

Figure 1.10 The position vector of the projectile changes over time due to its initial
speed and the pull of gravity.
Figure 1.11  A schematic diagram of an oilØeld
Figure 1.12 Darcy’s law annotated for a physics equation, governing how Ùuid Ùows
within a porous rock.

Figure 1.13 The positive gradient points uphill, while the negative gradient points
downhill.
Figure 1.14 A calculator for students learning to count
x = 5 
5 = x
>>> class A(): pass 
... 
>>> A() == A() 
False

Figure 1.15 A calculator capable of writing whole numbers and adding them
Figure 1.16 A function as a machine with an input slot and an output slot
def greet(name): 
    print("Hello %s!" % name)
>>> for name in ["John","Paul","George","Ringo"]: 
...     greet(name) 
... 
Hello John! 
Hello Paul! 
Hello George! 
Hello Ringo!

CHAPTER 2
Figure 2.1 Locating one of several points in the plane, relative to the origin
Figure 2.2 Superimposing an arrow on the plane indicates a point relative to the origin.

Figure 2.3 Connecting points in the plane to draw a shape
Figure 2.4 The dinosaur drawn with an x-axis and a y-axis.

Figure 2.5 Grid lines let us measure the location of points relative to the axes.
Figure 2.6 Three mental models describing the same vector.

Table 2.1 Some Python classes representing geometric Øgures, usable with the draw
function.
Class
Constructor example
Description
Polygon
Polygon(*vectors)
Draws a polygon whose vertices (corners) are
represented by a list of vectors
Points
Points(*vectors)
Represents a list of points (dots) to draw, one
at each of the input vectors
Arrow
Arrow(tip)
Arrow(tip, tail)
Draws an arrow from the origin to the tip
vector or from the tail  vector to the head
vector if a tail is specied
Segment
Segment(start,end)
Draws a line segment from the start to the
vector end
1
2
3
4
5
6
7
8
from vector_drawing import * 
dino_vectors = [(6,4), (3,1), (1,2), (−1,5), (−2,5), (−3,4), (−4,4), 
     # insert 16 remaining vectors here 
] 
  
draw( 
    Points(*dino_vectors) 
)

Figure 2.7 Plotting the dinosaur’s points with the draw  function in Python
1
2
3
4
draw( 
    Points(*dino_vectors), 
    Segment((6,4),(3,1)) 
)

Figure 2.8 The dinosaur’s points with a line segment connecting the Ørst two points (6,
4) and (3, 1)
Figure 2.9 A total of 21 function calls give us 21 line segments, completing the outline
of the dinosaur.

Exercise 2.1: What are the x- and y-coordinates of the point at the tip of the
dinosaur’s toe?
Solution: (−1, −4)
Exercise 2.2: Draw the point in the plane and the arrow corresponding to the point
(2, −2).
Solution: Represented as a point on the plane and an arrow, (2, −2) looks like this:
The point and arrow representing (2, −2)

Exercise 2.3: By looking at the locations of the dinosaur’s points, infer the
remaining vectors not included in the dino_vectors  list. For instance, I already
included (6, 4), which is the tip of the dinosaur’s tail, but I didn’t include the point
(−5, 3), which is a point on the dinosaur’s nose. When you’re done, dino_vectors
should be a list of 21 vectors represented as coordinate pairs.
Solution: The complete set of vectors outlining the dinosaur is as follows:
dino_vectors = [(6,4), (3,1), (1,2), (−1,5), (−2,5), (−3,4), (−4,4),  
    (−5,3), (−5,2), (−2,2), (−5,1), (−4,0), (−2,1), (−1,0), (0,−3),  
    (−1,−4), (1,−4), (2,−3), (1,−2), (3,−1), (5,1) 
]
Exercise 2.4: Draw the dinosaur with the dots connected by constructing a
Polygon  object with the dino_vectors  as its vertices.
Solution:
draw( 
    Points(*dino_vectors), 
    Polygon(*dino_vectors) 
)
The dinosaur drawn as a polygon.

Exercise 2.5: Draw the vectors (x,x**2)  for x in the range from x = −10 to x = 11) as
points (dots) using the draw  function. What is the result?
Solution: The pairs draw the graph for the function y = x2, plotted for the integers
from 10 to 10:
Points on the graph for y = x2
To make this graph, I used two keyword arguments for the draw  function. The
grid  keyword argument of (1, 10) draws vertical grid lines every one unit and
horizontal grid lines every ten units. The nice_aspect_ratio  keyword argument
set to False  tells the graph it doesn’t have to keep the x -axis and the y-axis scales
the same:
draw( 
    Points(*[(x,x**2) for x in range(−10,11)]), 
    grid=(1,10), 
    nice_aspect_ratio=False 
)
1
2
def add(v1,v2): 
    return (v1[0] + v2[0], v1[1] + v2[1])

Figure 2.10 Picturing the vector sum of (4, 3) and (−1, 1)
Figure 2.11 Tip-to-tail addition of vectors
Figure 2.12 The vector sum as an overall distance and direction traveled in the plane.

Figure 2.13 The original dinosaur (blue) and the translated copy (red). Each point on the
translated dinosaur is moved by (−1.5, −2.5) down and to the left from its location on the
original dinosaur.
1 dino_vectors2 = [add((−1.5,−2.5), v) for v  in dino_vectors]
1
2
3
4
5
6
draw( 
    Points(*dino_vectors, color=blue), 
    Polygon(*dino_vectors, color=blue), 
    Points(*dino_vectors2, color=red), 
    Polygon(*dino_vectors2, color=red) 
)

Figure 2.14 Breaking the vector (4, 3) into the sum (4, 0) + (0, 3)
Figure 2.15 Using the Pythagorean theorem to Ønd the length of a vector from the
lengths of its x- and y- components

Figure 2.16 Repeated addition of the vector v = (2, 1) with itself
Figure 2.17 Scalar multi-plication of a vector v by 2.5
1
2
3
from math import sqrt 
def length(v): 
    return sqrt(v[0]**2 + v[1]**2)

Figure 2.18 Scalar multiplication of a vector scales both components by the same
factor.
Figure 2.19 Scalar multiplication of a vector by a negative number, −½

Figure 2.20 The vector v = (−4, 3) and its opposite −v = (4, −3).
Figure 2.21 The result of subtracting v − w is an arrow from the tip of w to the tip of v.

Figure 2.22 The distance between two points in the plane
1
2
3
4
draw( 
    Points((2,2), (−1,3)), 
    Segment((2,2), (−1,3), color=red) 
)

Figure 2.23 Several points equidistant from w = (2, 2)
Exercise 2.6: If the vector u = (−2, 0), the vector v = (1.5, 1.5), and the vector w = (4,
1), what are the results of u + v, v + w, and u + w? What is the result of u + v + w?
Solution: With the vector z = (−2, 0), the vector v = (1.5, 1.5), and the vector w =
(4, 1), the results are as follows:
u + v = (−0.5, 1.5)
v + w = (5.5, 2.5)
u + w = (2, 1)
u + v + w = (3.5, 2.5)

Exercise 2.7-Mini Project: You can add any number of vectors together by
summing all of their x-coordinates and all of their y-coordinates. For instance, the
fourfold sum (1, 2) + (2, 4) + (3, 6) + (4, 8) has x component 1 + 2 + 3 + 4 = 10 and y
component 2 + 4 + 6 + 8 = 20, making the result (10, 20). Implement a revised add
function that takes any number of vectors as arguments.
Solution:
def add(*vectors): 
    return (sum([v[0] for v  in vectors]), sum([v[1] for v  in vectors]))
Exercise 2.8: Write a function translate(translation,  vectors)  that takes a
translation vector and a list of input vectors, and returns a list of the input vectors
all translated by the translation vector. For instance, translate ((1,1),
[(0,0),  (0,1,),  (−3,−3)])  should return [(1,1),(1,2),(−2, −2)] .
Solution:
def translate(translation, vectors): 
    return [add(translation, v) for v  in vectors]
Exercise 2.9−Mini Project: Any sum of vectors v + w gives the same result as w + v.
Explain why this is true using the denition of the vector sum on coordinates. Also,
draw a picture to show why it is true geometrically.
Solution: If you add two vectors z = (a, b) and v = (c, d), the coordinates a, b, c, and d
are all real numbers. The result of the vector addition is z + v = (a + c, b + d). The

result of v + z is (c + a, d + b), which is the same pair of coordinates because order
doesn’t matter when adding real numbers. Tip-to-tail addition in either order yields
the same sum vector. Visually, we can see this by adding an example pair of vectors
tip-to-tail:
Tip-to-tail addition in either order yields the same sum vector.
It doesn’t matter whether you add z + v or v + z(dashed lines), you get the same
result vector (solid line). In geometric terms, u and v dene a parallelogram, and the
vector sum is the length of the diagonal.

Exercise 2.10: Among the following three arrow vectors (labeled u, v, and w), which
pair has the sum that gives the longest arrow? Which pair sums to give the shortest
arrow?
Which pair sums to the longest or shortest arrow?
Solution: We can measure each of the vector sums by placing the vectors tip-to-
tail:
Tip-to-tail addition of the vectors in question
Inspecting the results, we can see that v + z is the shortest vector (u and v are in
nearly opposite directions and come close to canceling each other out). The longest
vector is v + w.

Exercise 2.11-Mini Project: Write a Python function using vector addition to show
100 simultaneous and non-overlapping copies of the dinosaur. This shows the power
of computer graphics; imagine how tedious it would be to specify all 2,100
coordinate pairs by hand!
Solution: With some trial and error, you can translate the dinosaurs in the vertical
and horizontal direction so that they don’t overlap, and set the boundaries
appropriately. I decided to leave out the grid lines, axes, origin, and points to make
the drawing clearer. My code looks like this:
def hundred_dinos(): 
    translations = [(12*x,10*y)  
                    for x in range(−5,5)  
                    for y in range(−5,5)] 
    dinos = [Polygon(*translate(t, dino_vectors),color=blue) 
                for t in translations] 
    draw(*dinos, grid=None, axes=None, origin=None) 
  
hundred_dinos()
The result is as follows:
100 dinosaurs. Run for your life!

Exercise 2.12: Which is longer, the x or y component of (3, −2) + (1, 1) + (−2, −2)?
Solution: The result of the vector sum (3, −2) + (1, 1) + (−2, −2) is (2, −3). The x
component is (2, 0) and the y component is (0, −3). The x component has a length of
2 units (to the right), while the y component has a length of 3 units (downward
because it is negative). This makes the y component longer.
Exercise 2.13: What are the components and lengths of the vectors (−6, −6) and (5,
−12)?
Solution: The components of (−6, −6) are (−6, 0) and (0, −6), both having length 6.
The length of (−6, −6) is the square root of 62 + 62, which is approximately 8.485.
The components of (5, −12) are (5, 0) and (0, −12), having lengths of 5 and 12,
respectively. The length of (5, −12) is given by the square root of 52 + 122 = 25 + 144
= 169. The result of the square root is exactly 13.
Exercise 2.14: Suppose I have a vector v that has a length of 6 and an x component
(1, 0). What are the possible coordinates of v ?
Solution: The x component of (1, 0) has length 1 and the total length is 6, so the
length b of the y component must satisfy the equation 12 + b2 = 62, or 1 + b2 = 36.
Then b2 = 35 and the length of the y component is approximately 5.916. This doesn’t
tell us the direction of the y component, however. The vector v could either be (1,
5.916) or (1, −5.916).
Exercise 2.15: What vector in the dino_vectors  list has the longest length? Use
the length  function we wrote to compute the answer quickly.
Solution:
>>> max(dino_vectors, key=length) 
(6, 4)

Exercise 2.16: Suppose a vector w has the coordinates (√2, √3). What are the
approximate coordinates of the scalar multiple π · w? Draw an approximation of the
original vector and the new vector.
Solution: The value of (√2, √3) is approximately
(1.4142135623730951, 1.7320508075688772)
Scaling each coordinate by a factor of π(pi), we get
(4.442882938158366, 5.441398092702653)
The scaled vector is longer than the original as shown here:
The original vector (shorter) and its scaled version (longer)
 

Exercise 2.17: Write a Python function scale(s,v)  that multiplies the input vector
v by the input scalar s.
Solution:
def scale(scalar,v): 
    return (scalar * v[0], scalar * v[1])
Exercise 2.18−Mini Project: Convince yourself algebraically that scaling the
coordinates by a factor also scales the length of the vector by the same factor.
Suppose a vector of length c has the coordinates (a, b). Show that for any non-
negative real number s, the length of (s · a, s · b) is s · c. (This can’t work for a negative
value of s because a vector can’t have a negative length.)
Solution: We use the notation |(a, b)| to denote the length of a vector (a, b). So, the
premise of the exercise tells us:
From that, we can compute the length of (sa, sb):
As long as s isn’t negative, it’s the same as its absolute value: s = |s|. Then the
length of the scaled vector is sc as we hoped to show.

Exercise 2.19−Mini Project: Suppose z = (−1, 1) and v = (1, 1), and suppose r and s are
real numbers. Specically, let’s assume −3 < r < 3 and −1 < s < 1. Where are the
possible points on the plane where the vector r · z + s · v could end up?
Note that the order of operations is the same for vectors as it is for numbers. We
assume scalar multiplication is carried out rst and then vector addition (unless
parentheses specify otherwise).
Solution: If r = 0, the possibilities lie on the line segment from (−1, −1) to (1, 1). If r is
not zero, the possibilities can leave that line segment in the direction of (−1, 1) or −
(−1, 1) by up to three units. The region of possible results is the parallelogram with
vertices at (2, 4), (4, 2), (2, −4), and (4, −2). We can test many random, allowable
values of r and s to validate this:
from random import uniform 
u = (−1,1) 
v = (1,1) 
def random_r(): 
    return uniform(−3,3) 
def random_s():  
    return uniform(−1,1) 
 
possibilities = [add(scale(random_r(), u), scale(random_s(), v)) 
                 for i in range(0,500)] 
draw( 
    Points(*possibilities) 
)
If you run this code, you get a picture like the following, showing the possible points
where r • z + s • v could end up given the constraints:
Location of possible points for r ∙ u + s ∙ v given the constraints.

Exercise 2.20: Show algebraically why a vector and its opposite have the same
length.
Hint: Plug the coordinates and their opposites into the Pythagorean theorem.
Solution: The opposite vector of (a, b) has coordinates (− a, − b), but this doesn’t
a|ect the length:
The vector (−a, −b) has the same length as (a, b).
Exercise 2.21: Of the following seven vectors, represented as arrows, which two are a
pair of opposite vectors?
Solution: Vectors v3 and v7 are the pair of opposite vectors.
Exercise 2.22: Suppose z is any 2D vector. What are the coordinates of z + -u?
Solution: A 2D vector z has some coordinates (a, b). Its opposite has coordinates (−
a, − b), so:
u + (−u) = (a, b) + (− a, − b) = (a − a, b − b) = (0, 0)
The answer is (0, 0). Geometrically, this means that if you follow a vector and then
its opposite, you end up back at the origin, (0, 0).

Exercise 2.23: For vectors u = (−2, 0), v = (1.5, 1.5), and w = (4, 1), what are the
results of the vector subtractions v − w, z − v, and w − v?
Solution: With z = (−2, 0), v = (1.5, 1.5), and w = (4, 1), we have
v − w = (−2.5, 0.5)
u − v = (−3.5, −1.5)
w − v = (2.5, -0.5)
Exercise 2.24: Write a Python function subtract(v1,v2)  that returns the result of
v1   -  v2 , taking two 2D vectors as inputs and returning a 2D vector as an output.
Solution:
def subtract(v1,v2): 
    return (v1[0] − v2[0], v1[1] − v2[1])

Exercise 2.25: Write a Python function distance(v1,v2)  that returns the distance
between two input vectors. (Note that the subtract  function from the previous
exercise already gives the displacement.)
Write another Python function perimeter(vectors)  that takes a list of vectors as
an argument and returns the sum of distances from each vector to the next,
including the distance from the last vector to the rst. What is the perimeter of the
dinosaur dened by dino_vectors  ?
Solution: The distance is just the length of the di|erence of the two input vectors:
def distance(v1,v2): 
    return length(subtract(v1,v2))
For the perimeter, we sum the distances of every pair of subsequent vectors in the
list, as well as the pair of the rst and the last vectors:
def perimeter(vectors): 
    distances = [distance(vectors[i], vectors[(i+1)%len(vectors)]) 
                 for i in range(0,len(vectors))] 
    return sum(distances)
We can use a square with side length of one as a sanity check:
>>> perimeter([(1,0),(1,1),(0,1),(0,0)]) 
4.0
Then we can calculate the perimeter of the dinosaur:
>>> perimeter(dino_vectors) 
44.77115093694563
Exercise 2.26−Mini Project: Let z be the vector (1, −1). Suppose there is another
vector v with positive integer coordinates (n, m) such that n > xm and has a distance
of 13 from u. What is the displacement from z to v?
Hint: You can use Python to search for the vector v.
Solution: We only need to search possible integer pairs (n, m) where n is within 13
units of 1 and m is within 13 units of −1:
for n in range(−12,15): 
    for m in range(−14, 13): 
        if distance((n,m), (1,−1)) == 13 and n > m > 0: 
            print((n,m))
There is one result: (13, 4). It is 12 units to the right and 5 units up from (1, −1), so
the displacement is (12, 5).

Figure 2.24 Using a protractor to measure the angle at which a vector points
Figure 2.25 Measuring 116.57° from the positive x-axis using a protractor

Figure 2.26 Using a ruler to measure the coordinates of the point that is three units
from the origin
Figure 2.27 Traveling in the direction of 116.57°, you travel two units up for every unit
you travel to the left.

Figure 2.28 How much vertical distance is covered per unit of horizontal distance at
different angles?
Figure 2.29 Schematic of distances and angles for a given vector

Figure 2.30 Measuring the angle to the point (4, 3) with a protractor
Figure 2.31 Picturing the conversion from polar coordinates to Cartesian coordinates
for a right triangle
1
2
3
>>> from math import tan 
>>> tan(45) 
1.6197751905438615

Figure 2.32 A half revolution is π radians, while a whole revolution is 2π radians.
1
2
3
>>> from math import tan, pi 
>>> tan(pi/4) 
0.9999999999999999
1
2
3
4
from math import sin, cos 
def to_cartesian(polar_vector): 
    length, angle = polar_vector[0], polar_vector[1] 
    return (length*cos(angle), length*sin(angle))
1
2
3
4
>>> from math import pi 
>>> angle = 37*pi/180 
>>> to_cartesian((5,angle)) 
(3.993177550236464, 3.0090751157602416)

Figure 2.33 In what angle does the vector (−2, 3) point?
1
2
3
4
5
>>> from math import asin 
>>> sin(1) 
0.8414709848078965 
>>> asin(0.8414709848078965) 
1.0
1
2
3
>>> from math import sqrt 
>>> asin(3/sqrt(13)) 
0.9827937232473292

Figure 2.34 Python’s math.asin  function appears to give us the wrong angle.
1
2
3
>>> from math import acos 
>>> acos(−2/sqrt(13)) 
2.1587989303424644
1
2
3
4
5
6
7
8
>> cos(2.1587989303424644) 
-0.5547001962252293 
>>> −2/sqrt(13) 
-0.5547001962252291 
>>> sin(2.1587989303424644) 
0.8320502943378435 
>>> 3/sqrt(13) 
0.8320502943378437
1
2
3
>>> from math import atan2 
>>> atan2(3,−2) 
2.158798930342464

Exercise 2.27: Conrm that the vector given by Cartesian coordinates (−1.34, 2.68)
has a length of approximately 3 as expected.
Solution:
>>> length((−1.34,2.68)) 
2.9963310898497184
Close enough!
1
2
3
4
def to_polar(vector): 
    x, y = vector[0], vector[1] 
    angle = atan2(y,x) 
    return (length(vector), angle)
1
2
>>> to_polar((1,0)) 
(1.0, 0.0)
1
2
>>> to_polar((−2,3)) 
(3.605551275463989, 2.158798930342464)

Exercise 2.28: The gure shows a line that makes a 22° angle in the
counterclockwise direction from the positive x-axis. Based on the following picture,
what is the approximate value of tan(22°)?
Solution: The line passes close to the point (10, 4), so 4 / 10 = 0.4 is a reasonable
approximation of tan(22°) as shown here:

Exercise 2.29: Turning the question around, suppose we know the length and
direction of a vector and want to nd its components. What are the x and y
components of a vector with length 15 pointing at a 37° angle?
Solution
The sine of 37° is roughly 3/5,which tells us that every 5 units of distance covered at
this angle takes us 3 units upward. So, 15 units of distance give us a vertical
component of 3/5· 15, or 9.
The cosine of 37° is roughly 4/5,which tells us that each 5 units of distance in this
direction take us 4 units to the right, so the horizontal component is 4/5· 15 or 12. In
summary, the polar coordinates (15, 37°) correspond approximately to the Cartesian
coordinates (12, 9).

Exercise 2.30: Suppose I travel 8.5 units from the origin at an angle of 125°,
measured counterclockwise from the positive x-axis. Given that sin(125°) = 0.819
and cos(125°) = -0.574, what are my nal coordinates? Draw a picture to show the
angle and path traveled.
Solution
x = r · cos(θ) = 8.5 · -0.574 = −4.879
y = r · sin(θ) = 8.5 · 0.819 = 6.962
The following gure shows the nal position, (−4.879, 6.962):

Exercise 2.31: What are the sine and cosine of 0°? Of 90°? Of 180°? In other words,
how many vertical and horizontal units are covered per unit distance in any of these
directions?
Solution: At 0°, no vertical distance is covered, so sin(0°) = 0; rather, every unit of
distance traveled is a unit of horizontal distance, so cos(0°) = 1.
For 90° (a quarter turn counterclockwise), every unit traveled is a positive vertical
unit, so sin(90°) = 1, while cos(90°) = 0.
Finally, at 180°, every unit of distance traveled is a negative unit in the x direction, so
cos(180°) = −1 and sin(180°) = 0.

Exercise 2.32: The following diagram gives some exact measurements for a right
triangle:
First, conrm that these lengths are valid for a right triangle because they satisfy
the Pythagorean theorem. Then, calculate the values of sin(30°), cos(30°), and
tan(30°) to three decimal places using the measurements in the diagram.
Solution: These side lengths indeed satisfy the Pythagorean theorem:
Plugging the side lengths into the Pythagorean theorem
The trigonometric function values are given by the appropriate ratios of side
lengths:
Calculating the sine, cosine, and tangent by their denitions

Exercise 2.33: Looking at the triangle from the previous exercise from a di|erent
perspective, use it to calculate the values of sin(60°), cos(60°), and tan(60°) to three
decimal places.
Solution: Rotating and reecting the triangle from the previous exercise has no
e|ect on its side lengths or angles.
A rotated copy of the triangle from the previous exercise
The ratios of the side lengths give the trigonometric function values for 60°:
Calculating the dening ratios when horizontal and vertical components have
switched
 

Exercise 2.34: The cosine of 50° is 0.643. What is sin(50°) and what is tan(50°)?
Draw a picture to help you calculate the answer.
Solution: Given that the cosine of 50° is 0.643, the following triangle is valid:
That is, it has the right ratio of the two known side lengths: 0.643 / 1 = 0.643. To nd
the unknown side length, we can use the Pythagorean theorem:
With the known side lengths, sin(50°) = 0.766/1 = 0.766. Also, tan(50°) =
0.766/0.643 = 1.192.
Exercise 2.35: What is 116.57° in radians? Use Python to compute the tangent of this
angle and conrm that it is close to −2 as we saw previously.
Solution: 116.57° · (1 radian/57.296°) = 2.035 radians:
>>> from math import tan 
>>> tan(2.035) 
−1.9972227673316139

Exercise 2.36: Locate the angle 10π/6. Do you expect the values of cos(10π/6) and
sin(10π/6) to be positive or negative? Use Python to calculate their values and
conrm.
Solution: A whole circle is 2π radians, so the angle π/6 is one twelfth of a circle. You
can picture cutting a pizza in 12 slices, and counting counterclockwise from the
positive x-axis; the angle 10π/6 is two slices short of a full rotation. This means that
it points down and to the right. The cosine should be positive, and the sine should be
negative because the distance in this direction corresponds with a positive
horizontal displacement and a negative vertical displacement:
>>> from math import pi, cos, sin 
>>> sin(10*pi/6) 
-0.8660254037844386 
>>> cos(10*pi/6) 
0.5000000000000001

Exercise 2.37: The following list comprehension creates 1,000 points in polar
coordinates:
[(cos(5*x*pi/500.0), 2*pi*x/1000.0) for x in range(0,1000)]
In Python code, convert these to Cartesian coordinates and connect them in a closed
loop with line segments to draw a picture.
Solution: Including the setup and the original list of data, the code is as follows:
polar_coords = [(cos(x*pi/100.0), 2*pi*x/1000.0) for x in range(0,1000)] 
vectors = [to_cartesian(p) for p in polar_coords] 
draw(Polygon(*vectors, color=green))
And the result is a ve-leafed ower:
The plot of the 1,000 connected points is a ower shape.

Exercise 2.38: Find the angle to get to the point (−2, 3) by “guess-and-check.”
What is the angle to get to the point (−2, 3)?
 
Hint: We can tell visually that the answer is between π/2 and π. On that interval, the
values of sine and cosine always decrease as the angle increases.
Solution: Here’s an example of guessing and checking between π/2 and π, looking
for an angle with tangent close to −3/2 = −1.5:
>>> from math import tan, pi 
>>> pi, pi/2 
(3.141592653589793, 1.5707963267948966) 
>>> tan(1.8) 
−4.286261674628062 
>>> tan(2.5) 
-0.7470222972386603 
>>> tan(2.2) 
−1.3738230567687946 
>>> tan(2.1) 
−1.7098465429045073 
>>> tan(2.15) 
−1.5289797578045665 
>>> tan(2.16) 
−1.496103541616277 
>>> tan(2.155) 
−1.5124173422757465 
>>> tan(2.156) 
−1.5091348993879299 
>>> tan(2.157) 
−1.5058623488727219 
>>> tan(2.158) 
−1.5025996395625054 
>>> tan(2.159) 
−1.4993467206361923
The value must be between 2.158 and 2.159.

Exercise 2.39: Find another point in the plane with the same tangent as θ, namely
−3/2. Use Python’s implementation of the arctangent function, math.atan , to nd
the value of this angle.
Solution: Another point with tangent −3/2 is (3, −2). Python’s math.atan  nds the
angle to this point:
>>> from math import atan 
>>> atan(−3/2) 
-0.982793723247329
This is slightly less than a quarter turn in the clockwise direction.
Exercise 2.40: Without using Python, what are the polar coordinates corresponding
to the Cartesian coordinates (1, 1) and (1, −1)? Once you’ve found the answers, use
to_polar  to check your work.
Solution: In polar coordinates, (1, 1) becomes (√2, π/4) and (1, −1) becomes (√2,
-π/4).
With some care, you can nd any angle on a shape made up of known vectors. The
angle between two vectors is either a sum or di|erence of angles these make with
the x-axis. You measure some trickier angles in the next mini-project.

Exercise 2.41-Mini Project: What is the angle of the Dinosaur’s mouth? What is the
angle of the dinosaur’s toe? Of the point of its tail?
Some angles we can measure or calculate on our dinosaur.
Figure 2.35 Adding or subtracting from the angle rotates the vector about the origin.

Figure 2.36 The original dinosaur in gray and a rotated copy in red
1
2
3
4
5
6
7
8
rotation_angle = pi/4 
dino_polar = [to_polar(v) for v  in dino_vectors] 
dino_rotated_polar = [(l,angle + rotation_angle) for l,angle in dino_polar] 
dino_rotated = [to_cartesian(p) for p in dino_rotated_polar] 
draw( 
    Polygon(*dino_vectors, color=gray), 
    Polygon(*dino_rotated, color=red) 
)
1 new_dino = translate((8,8), rotate(5 * pi/3, dino_vectors))

Figure 2.37 The original dinosaur in gray and a red copy that’s rotated and then
translated
Exercise 2.42: Create a rotate(angle,  vectors)  function that takes an array of
input vectors in Cartesian coordinates and rotates those by the specied angle
(counterclockwise or clockwise, according to whether the angle is positive or
negative).
Solution
def rotate(angle, vectors): 
    polars = [to_polar(v) for v  in vectors] 
    return [to_cartesian((l, a+angle)) for l,a in polars]

Exercise 2.43: Create a function regular_polygon(n)  that returns Cartesian
coordinates for the vertices of a regular n -sided polygon (that is, having all angles
and side lengths equal). For instance, polygon(7)  produces vectors dening the
following heptagon:
A regular heptagon with points at seven evenly-spaced angles around the origin
Hint: In this picture, I used the vector (1, 0) and copies that are rotated by seven
evenly-spaced angles about the origin.
Solution
def regular_polygon(n): 
    return [to_cartesian((1, 2*pi*k/n)) for k in range(0,n)]

Exercise 2.44: What is the result of rst translating the dinosaur by the vector (8, 8)
and then rotating it by 5π/3? Is the result the same as rotating and then translating?
Solution
First translating and then rotating the dinosaur
The result is not the same. In general, applying rotations and translations in
di|erent orders yields di|erent results.
1
2
3
import matplotlib 
from matplotlib.patches import Polygon 
from matplotlib.collections import PatchCollection
1
2
3
4
class Points(): 
    def __init__(self, *vectors, color=black): 
        self.vectors = list(vectors) 
        self.color = color

1
2
3
4
5
6
7
8
9
def draw(*objects, ... 
    # ... 
    for object in objects: 
    # ...  
        elif type(object) == Points: 
            xs = [v[0] for v  in object.vectors] 
            ys = [v[1] for v  in object.vectors] 
            plt.scatter(xs, ys, color=object.color) 
        # ...
1
2
3

CHAPTER 3
Figure 3.1 Shading on a 2D circle makes it look like a 3D sphere.
Figure 3.2 Drawing a shaded sphere using many small, solid-colored triangles
 

Figure 3.3 The height and width of a small segment of the 2D plane
Fogure 3.4 A small Ønite box of 3D space has a width (x), a height (y), and a depth (z).

Figure 3.5 The 2D world and inhabitant vector (4, 3) contained in the 3D world
Figure 3.6 A vector extending into the third dimension as compared to the 2D world
and its inhabitant vector (4, 3) of Øgure 3.5

Figure 3.7 Several vectors with the same x- and y-coordinates but with different z-
coordinates
Figure 3.8 The three coordinates (4, 3, 5) give us directions to a point in 3D.

Figure 3.9 Drawing an empty 3D region with Matplotlib’s draw3d()
Figure 3.10 Drawing the points (2, 2, 2) and (1, −2, −2)
1
2
3
draw3d( 
    Points3D((2,2,2),(1,−2,−2)) 
)

Figure 3.11 Drawing 3D arrows
1
2
3
4
5
6
draw3d( 
    Points3D((2,2,2),(1,−2,−2)), 
    Arrow3D((2,2,2)), 
    Arrow3D((1,−2,−2)), 
    Segment3D((2,2,2), (1,−2,−2)) 
)
Fogire 3.12 Drawing boxes to make our arrows look 3D
1
2
3
4
5
6
7
8
draw3d( 
    Points3D((2,2,2),(1,−2,−2)), 
    Arrow3D((2,2,2)), 
    Arrow3D((1,−2,−2)), 
    Segment3D((2,2,2), (1,−2,−2)), 
    Box3D(2,2,2), 
    Box3D(1,−2,−2) 
)

Exercise 3.1: Draw the 3D arrow and point representing the coordinates (−1, −2, 2)
as well as the dashed box that makes the arrow look 3D. Do this drawing by hand for
practice, but from now on, we’ll use Python to draw for us.
Solution:
The vector (−1, −2, 2) and the box that makes it look 3D

Exercise 3.2-Mini Project: There are exactly eight 3D vectors whose coordinates are
all either +1 or −1. For instance, (1, −1, 1) is one of these. Plot all of these eight
vectors as points. Then gure out how to connect them with line segments using
Segment3D  objects to form the outline of a cube.
Hint: You’ll need 12 segments in total.
Solution: Because there are only 8 vertices and 12 edges, it’s not too tedious to list
them all, but I decided to enumerate them with a list comprehension. For the
vertices, I let x, y, and z range over the list of two possible values [1,−1]  and
collected the eight results. For the edges, I grouped them into three sets of four that
point in each coordinate direction. For instance, there are four edges that go from x
= −1 to x = 1, while their y − and z-coordinates are the same at both endpoints:
pm1 = [1,−1] 
vertices = [(x,y,z) for x in pm1 for y in pm1 for z in pm1] 
edges = [((−1,y,z),(1,y,z)) for y in pm1 for z in pm1] +\ 
            [((x,−1,z),(x,1,z)) for x in pm1 for z in pm1] +\ 
            [((x,y,−1),(x,y,1)) for x in pm1 for y in pm1] 
draw3d( 
    Points3D(*vertices,color=blue), 
    *[Segment3D(*edge) for edge in edges] 
)
The cube with all vertex coordinates equal to +1 or −1

Figure 3.13 Two visual examples of vector addition in 3D
Figure 3.14 Adding three vectors tip-to-tail in 3D

Figure 3.15 Scalar multiplication by 2 returns a vector pointing in the same direction,
which is twice as long as the original vector.
1
2
3
4
def add(*vectors): 
    by_coordinate = zip(*vectors) 
    coordinate_sums = [sum(coords) for coords in by_coordinate] 
    return tuple(coordinate_sums)

1
2
>>> list(zip(*[(1,1,3),(2,4,−4),(4,2,−2)])) 
[(1, 2, 4), (1, 4, 2), (3, −4, −2)]
1
2
[sum(coords) for coords in [(1, 2, 4), (1, 4, 2), (3, −4, −2)]] 
[7, 7, −3]
1
2
def add(*vectors): 
    return tuple(map(sum,zip(*vectors)))

Figure 3.16 Subtracting the vector w from the vector v gives the displacement from w
to v.
Figure 3.17 Applying the Pythagorean theorem to Ønd the length of a hypotenuse in the
x,y plane

Figure 3.18 A second application of the Pythagorean theorem gives us the length of the
3D vector.
 
1
2
3
from math import sqrt 
def length(v): 
    return sqrt(sum([coord ** 2 for coord in v]))

Figure 3.19 Two angles that together measure the direction of a 3D vector

Exercise 3.3: Draw (4, 0, 3) and (−1, 0, 1) as Arrow3D  objects, such that they are
placed tip-to-tail in both orders in 3D. What is their vector sum?
Solution: We can nd the vector sum using the add  function we built:
>>> add((4,0,3),(−1,0,1)) 
(3, 0, 4)
Then to draw these tip-to-tail, we draw arrows from the origin to each point and
from each point to the vector sum (3, 0, 4). Like the 2D Arrow  object, Arrow3D
takes the tip vector of the arrow rst and then, optionally, the tail vector if it is not
the origin:
draw3d( 
    Arrow3D((4,0,3),color=red), 
    Arrow3D((−1,0,1),color=blue), 
    Arrow3D((3,0,4),(4,0,3),color=blue), 
    Arrow3D((−1,0,1),(3,0,4),color=red), 
    Arrow3D((3,0,4),color=purple) 
)
Tip-to-tail addition shows (4, 0, 3) + (−1, 0, 1) = (−1, 0, 1) + (4, 0, 3) = (3, 0, 4).
Exercise 3.4: Suppose we set vectors1=[(1,2,3,4,5),(6,7,8,9,10)]  and
vectors2=[(1,2),(3,4),(5,6)] . Without evaluating in Python, what are the
lengths of zip(*vectors1)  and zip(*vectors2)  ?
Solution: The rst zip  has length 5. Because there are ve coordinates in each of
the two input vectors, zip(*vectors1)  contains ve tuples, having two elements
each. Likewise, zip(*vectors2)  has length 2; the two entries of zip(*vectors2)
are tuples containing all of the x components and all of the y components,
respectively.

Exercise 3.5−Mini Project: The following comprehension creates a list of 24 Python
vectors:
from math import sin, cos, pi 
vs = [(sin(pi*t/6), cos(pi*t/6), 1.0/3) for t in range(0,24)]
What is the sum of the 24 vectors? Draw all 24 of them tip-to-tail as Arrow3D
objects.
Solution: Drawing these vectors tip-to-tail ends up producing a helix shape:
from math import sin, cos, pi 
vs = [(sin(pi*t/6), cos(pi*t/6), 1.0/3) for t in range(0,24)] 
 
running_sum = (0,0,0)                            ❶ 
arrows = [] 
for v  in vs: 
    next_sum = add(running_sum, v)               ❷ 
    arrows.append(Arrow3D(next_sum, running_sum))  
    running_sum = next_sum 
print(running_sum) 
draw3d(*arrows)
❶ Begins a running sum at (0, 0, 0), where the tip-to-tail addition starts
❷ To draw each subsequent vector tip-to-tail, we add it to the running sum. The
latest arrow connects the previous running sum to the next.
Finding the vector sum of 24 vectors in 3D
The sum is
(−4.440892098500626e−16, −7.771561172376096e−16, 7.9999999999999964)
which is approximately (0, 0, 8).

Exercise 3.6: Write a function scale(scalar,vector)  that returns the input
scalar times the input vector. Specically, write it so it works on 2D or 3D vectors, or
vectors of any number of coordinates.
Solution: With a comprehension, we multiply each coordinate in the vector by the
scalar. This is a generator comprehension that is converted to a tuple:
def scale(scalar,v): 
    return tuple(scalar * coord for coord in v)
Exercise 3.7: Let u = (1, −1, −1) and v = (0, 0, 2). What is the result of u + ½ · (v − u)?
Solution: With u = (1, −1, −1) and v = (0, 0, 2), we can rst compute (v − u) = (0 − 1, 0
− (−1), 2 − (−1)) = (−1, 1, 3). Then ½ · (v − u) is (−½, ½, 3/2). The nal desired result
of u + ½ · (v − u) is then (½, −½, ½). Incidentally, this is the point exactly halfway
between the point u and the point v.
Exercise 3.8: Try to nd the answers for this exercise without using code and then
check your work. What is the length of the 2D vector (1, 1)? What is the length of the
3D vector (1, 1, 1)? We haven’t yet talked about 4D vectors, but these have four
coordinates instead of two or three. If you had to guess, what is the length of the 4D
vector with coordinates (1, 1, 1, 1)?
Solution: The length of (1, 1) is   
. The length of (1, 1, 1) is 
. As you might guess, we use the same distance formula for
higher dimensional vectors as well. The length of (1, 1, 1, 1) follows the same pattern:
it is 
, which is 2.

Exercise 3.9−Mini Project: The coordinates 3, 4, 12 in any order create a vector of
length 13, a whole number. This is unusual because most numbers are not perfect
squares, so the square root in the length formula typically returns an irrational
number. Find a di|erent triple of whole numbers that dene coordinates of a vector
with a whole number length.
Solution: The following code searches for triples of descending whole numbers less
than 100 (an arbitrary choice):
def vectors_with_whole_number_length(max_coord=100): 
    for x in range(1,max_coord): 
        for y in range(1,x+1): 
          for z in range(1,y+1): 
                if length((x,y,z)).is_integer(): 
                    yield (x,y,z)
It nds 869 vectors with whole number coordinates and whole number lengths. The
shortest of these is (2, 2, 1) with length exactly 3, and the longest is (99, 90, 70) with
length exactly 150.
Exercise 3.10: Find a vector in the same direction as (−1, −1, 2) but which has length
1.
Hint: Find the appropriate scalar to multiply the original vector to change its length
appropriately.
Solution: The length of (−1, −1, 2) is about 2.45, so we’ll have to take a scalar
multiple of this vector by (1/2.45) to make its length 1:
>>> length((−1,−1,2)) 
2.449489742783178 
>>> s = 1/length((−1,−1,2)) 
>>> scale(s,(−1,−1,2)) 
(−0.4082482904638631, -0.4082482904638631, 0.8164965809277261) 
>>> length(scale(s,(−1,−1,2))) 
1.0
Rounding to the nearest hundredth in each coordinate, the vector is (−0.41, -0.41,
0.82).

Figure 3.20 Two vectors that are relatively aligned give a large positive dot product.
Figure 3.21 Two shorter vectors pointing in similar directions give a smaller but still
positive dot product.
Figure 3.22 Vectors pointing in opposing directions have a negative dot product.

Figure 3.23 Shorter vectors pointing in opposing directions have a smaller but still
negative dot product.
Figure 3.24 Perpendicular vectors always have a dot product of zero.

Figure 3.25 Two vectors with a dot product of zero are indeed perpendicular in 3D.

Figure 3.26 Another example of computing a dot product
1
2
def dot(u,v): 
    return sum([coord1 * coord2 for coord1,coord2 in zip(u,v)])

Figure 3.27 Vectors of the same length have different dot products with the vector (4,
3), depending on their direction.
1
2
3
4
>>> dot((1,0),(0,2)) 
0  
>>> dot((0,3,0),(0,0,−5))
0
1
2
3
4
5
6
>>> dot((3,4),(2,3)) 
18  
>>> dot(scale(2,(3,4)),(2,3)) 
36  
>>> dot((3,4),scale(2,(2,3))) 
36
1
2
>>> dot((4,3),(8,6)) 
50

Figure 3.28 Two vectors of lengths 3 and 2, respectively, at 75° apart
1
2
3
>>> from math import cos,pi 
>>> 3 * 2 * cos(75 * pi / 180) 
1.5529142706151244
1
2
3
4
5
def angle_between(v1,v2): 
    return acos( 
                dot(v1,v2) / 
                (length(v1) * length(v2)) 
            )

Exercise 3.11: Based on the following picture, rank u · v, u · w, and v · w from largest to
smallest:
Solution: The product u · v is the only positive dot product because u and v are the
only pair with less than a right angle between them. Further, u · w is smaller (more
negative) than v · w because u is both bigger and further from w, so u · v > xv · w > xu ·
w.
Exercise 3.12: What is the dot product of (−1, −1, 1) and (1, 2, 1)? Are these two 3D
vectors separated by more than 90°, less than 90°, or exactly 90°?
Solution: (−1, −1, 1) and (1, 2, 1) have the dot product −1 · 1 + −1 · 2 + 1 · 1 = −2. Because
this is a negative number, the two vectors are more than 90° apart.
Exercise 3.13-Mini Project: For two 3D vectors u and v, the values of (2u) · v and u ·
(2v) are both equal to 2(u · v). In this case, u · v = 18 and both (2u) · v and u · (2v) are
36, twice the original result. Show that this works for any real number s, not just 2.
In other words, show that for any s the values of (s u) · v and u · (s v) are both equal to
s(u · v).

Solution: Let’s name the coordinates of u and v, say u = (a, b, c) and v = (d, e, f ).
Then u · v = ad + be + cf. Because s u = (sa, sb, sc) and s v = (sd, se, sf), we can show both
of the results by expanding the dot products:
Proving that scalar multiplication scales the result of the dot product accordingly
And the other product works the same way:
 
Proving the same fact holds for the second vector input to the dot product.
Exercise 3.14-Mini Project: Explain algebraically why the dot product of a vector
with itself is the square of its length.
Solution: If a vector has coordinates (a, b, c), then the dot product with itself is a · a
+ b · b + c · c. Its length is  
, so this is indeed the square.

Exercise 3.15-Mini Project: Find a vector u of length 3 and a vector v of length 7
such that u · v = 21. Find another pair of vectors u and v such that u · v = −21. Finally,
nd three more pairs of vectors of respective lengths 3 and 7 and show that all of
their lengths lie between −21 and 21.
Solution: Two vectors in the same direction (for instance, along the positive x-axis)
will have the highest possible dot product:
>>> dot((3,0),(7,0)) 
21
Two vectors in the opposite direction (for instance, the positive and negative y
directions) will have the lowest possible dot product:
>>> dot((0,3),(0,−7)) 
−21
Using polar coordinates, we can easily generate some more vectors of length 3 and 7
with random angles:
from vectors import to_cartesian 
from random import random 
from math import pi 
 
def random_vector_of_length(l): 
    return to_cartesian((l, 2 *pi*random())) 
 
pairs = [(random_vector_of_length(3), random_vector_of_length(7)) 
            for i in range(0,3)] 
for u,v in pairs: 
    print("u = %s, v  = %s" % (u,v)) 
    print("length of u: %f, length of v: %f, dot product :%f" % 
                (length(u), length(v), dot(u,v)))
Exercise 3.16: Let u and v be vectors, with |u| = 3.61 and |v| = 1.44. If the angle
between u and v is 101.3°, what is u · v ?
5.198
5.098
−1.019
1.019
Solution: Again, we can plug these values into the new dot product formula and,
with the appropriate conversion to radians, evaluate the result in Python:
>>> 3.61 * 1.44 * cos(101.3 * pi / 180) 
−1.0186064362303022
Rounding to three decimal places, the answer agrees with c.

Exercise 3.17-Mini Project: Find the angle between (3, 4) and (4, 3) by converting
them to polar coordinates and taking the di|erence of the angles. The answer is
1.569
0.927
0.643
0.284
Hint: The result should agree with the value from the dot product formula.
Solution: The vector (3, 4) is further from the positive x-axis counterclockwise, so
we subtract the angle of (4, 3) from the angle of (3, 4) to get our answer. It matches
answer d exactly:
>>> from vectors import to_polar 
>>> r1,t1 = to_polar((4,3)) 
>>> r2,t2 = to_polar((3,4)) 
>>> t1-t2 
-0.2837941092083278  
>>> t2-t1 
0.2837941092083278 
Exercise 3.18: What is the angle between (1, 1, 1) and (−1, −1, 1) in degrees?
180°
120°
109.5°
90°
Solution: The lengths of both vectors are √3 or approximately 1.732. Their dot
product is 1 · (−1) + 1 · (−1) + 1 · 1 = −1, so −1 = √3 · √3 · cos(θ). Therefore, cos(θ) = −1/3.
This makes the angle approximately 1.911 radians or 109.5° (answer c).

Figure 3.29 Positioning ourselves in 3D to see the x,y plane as we saw it in chapter 2.
When looking at the x,y plane, we chose the positive z-axis to point toward us as
opposed to away from us.

Figure 3.30 A mug with no image is the same object as its mirror image. A mug with an
image on one side is not the same as its mirror image.
Figure 3.31 Is this a right or left hand?
Figure 3.32 The right-hand rule helps us remember the orientation we’ve chosen.
Figure 3.33 The cross product of z = (1, 0, 0) and v = (0, 1, 0)

Figure 3.34 The cross product of any two vectors in the x,y plane lies on the z-axis.
Figure 3.35 The cross product always returns a vector that is perpendicular to both
inputs.

Figure 3.36 The right-hand rule tells us which perpendicular direction the cross product
points toward.
Figure 3.37 The length of the cross product is equal to the area of a parallelogram.

Figure 3.38 Pairs of vectors in the x,y plane have cross products of different sizes based
on the area of the parallelogram these span.

Figure 3.39 The cross product can indicate whether a polygon is visible to an observer.
1
2
3
4
def cross(u, v): 
    ux,uy,uz = u 
    vx,vy,vz = v 
    return (uy*vz − uz*vy, uz*vx − ux*vz, ux*vy − uy*vx)

Exercise 3.19: Each of the following diagrams show three mutually perpendicular
arrows indicating positive x, y, and z directions. A 3D box is shown for perspective
with the back of the box colored gray. Which of the four diagrams is compatible with
the one we chose? That is, which shows the x-, y-, and z-axes as we’ve drawn them,
even if from a di|erent perspective?
Which of these axes agrees with our orientation convention?
Solution: Looking down on diagram a from above, we’d see the x- and y-axis as
usual, with the z-axis pointing toward us. The diagram that agrees with our
orientation is a.
In diagram b, the z-axis is coming toward us, while the +y direction is 90° clockwise
from the +x direction. This does not agree with our orientation.
If we looked at diagram c from a point in the positive z direction (from the left side
of the box), we would see the +y direction 90° counterclockwise from the +x
direction. Diagram c also agrees with our orientation.
Looking at diagram d from the left of the box, the +z direction would be toward us
and the +y direction would again be counterclockwise from the +x direction. This
agrees with our orientation as well.

Exercise 3.20: If you held up three coordinate axes in front of a mirror, would the
image in the mirror have the same orientation or a di|erent one?
Solution: The mirror image has reversed orientation. From this perspective, the z-
and y-axes stay pointing in the same directions. The x-axis is clockwise from the y-
axis in the original, but in the mirror image, it moves to counterclockwise:
The x-, y-, and z-axes and their mirror image
Exercise 3.21: In what direction does the result of (0, 0, 3) × (0, −2, 0) point?
Solution: If we point our right index nger in the direction of (0, 0, 3), the positive z
direction, and curl our other ngers in the direction of (0, −2, 0), the negative y
direction, our thumb points in the positive x direction. Therefore, (0, 0, 3) × (0, −2,
0) points in the positive x direction.
Exercise 3.22: What are the coordinates of the cross product of (1, −2, 1) and (−6, 12,
−6)?
Solution: As negative scalar multiples of one another, these vectors point in
opposite directions and don’t span any area. The length of the cross product is,
therefore, zero. The only vector of length zero is (0, 0, 0), so that is the answer.

Exercise 3.23-Mini Project: The area of a parallelogram is equal to the length of its
base times its height as shown here:
Given that, explain why the formula
|u| · |v| · sin(φ) makes sense.
Solution: In the diagram, the vector u denes the base, so the base length is |u|.
From the tip of v to the base, we can draw a right triangle. The length of v is the
hypotenuse, and the vertical leg of the triangle is the height we are looking for. By
the denition of the sine function, the height is |v| · sin(φ).
The formula for the area of a parallelogram in terms of the sine of one of its angles
Because the base length is |u| and the height is |v| · sin(φ), the area of the
parallelogram is indeed |u| · |v| · sin(φ).

Exercise 3.24: What is the result of the cross product (1, 0, 1) × (−1, 0, 0)?
(0, 1, 0)
(0, −1, 0)
(0, −1, −1)
(0, 1, −1)
Solution: These vectors lie in the x,z plane, so their cross product lies on the y-axis.
Pointing our right index nger in the direction of (1, 0, 1) and curling our ngers
toward (−1, 0, 0) requires our thumb to point in the − y direction.
 
Computing the cross product of (1, 0, 1) and (−1, 0, 0) geometrically
We could nd the lengths of the vectors and the angle between them to get the size
of the cross product, but we already have the base and height from the coordinates.
These are both 1, so the length is 1. The cross product is, therefore, (0, −1, 0), a
vector of length 1 in the − y direction; the answer is b.

Exercise 3.25: Use the Python cross  function to compute (0, 0, 1) × v for a few
di|erent values of a second vector v. What is the z-coordinate of each result, and
why?
Solution: No matter what vector v is chosen, the z-coordinate is zero:
>>> cross((0,0,1),(1,2,3)) 
(−2, 1, 0) 
>>> cross((0,0,1),(−1,−1,0)) 
(1, −1, 0) 
>>> cross((0,0,1),(1,−1,5)) 
(1, 1, 0)
Because u = (0,0,1), both u x and u y are zero. This means the term u x vy − uyvx in the
cross product formula is zero, regardless of the values v x and vy. Geometrically this
makes sense: the cross product should be perpendicular to both inputs, and to be
perpendicular to (0, 0, 1), the z component must be zero.
Exercise 3.26−Mini Project: Show algebraically that u × v is perpendicular to both u
and v regardless of the coordinates of u and v.
Hint: Show (u × v) · u and (u × v) · v by expanding these into coordinates.
Solution: Let u = (ux, uy, uz) and v = (vx, vy, vz) in the following equations. We can
write (u × v) · u in terms of coordinates as follows:
u× v = (uyvz − uzvy, uzvx − uxvz, uxvy − uyvx) · (ux, uy, uz)
Expanding the dot product of a cross product
After we expand the dot product, we see that there are 6 terms. Each of these
cancels out with one of the others.
= (uyvz − uzvy)ux + (uzvx − uxvz)uy + (uxvy − uyvx)uz
= uyvzux − uzvyux + uzvxuy − uxvzuy + uxvyuz − uyvxuz
After fully expanding, all the terms cancel out.
Because all of the terms cancel out, the result is zero. To save “ink,” I won’t show
the result of (u × v) · v, but the same thing happens: six terms appear and cancel each
other out, resulting in zero. This means that (u × v) is perpendicular to both u and v.

Figure 3.40 The skeleton of an octahedron, a shape with eight faces and six vertices.
The dotted lines show the edges of the octahedron on the opposite side from us.
Figure 3.41 Four numbered faces of the octahedron that are visible to us in its current
position
Figure 3.42 Vertices of an octahedron

Figure 3.43 Four edges of the octahedron indicated by arrows
Figure 3.44 A face of the octahedron. The three points deØning the face are ordered so
that (v2 − v1) × (v3 − v1) points outside of the octahedron.
1
2
3
4
5
6
7
8
9
10
octahedron = [ 
    [(1,0,0), (0,1,0), (0,0,1)], 
    [(1,0,0), (0,0,−1), (0,1,0)], 
    [(1,0,0), (0,0,1), (0,−1,0)], 
    [(1,0,0), (0,−1,0), (0,0,−1)], 
    [(−1,0,0), (0,0,1), (0,1,0)], 
    [(−1,0,0), (0,1,0), (0,0,−1)], 
    [(−1,0,0), (0,−1,0), (0,0,1)], 
    [(−1,0,0), (0,0,−1), (0,−1,0)], 
]

Figure 3.45 Deleting the z component of a 3D vector Ùattens it into the x,y plane.
1
2
def vertices(faces): 
    return list(set([vertex for face in faces for vertex in face]))
1
2
def component(v,direction): 
    return (dot(v,direction) / length(direction))
1
2
def vector_to_2d(v): 
    return (component(v,(1,0,0)), component(v,(0,1,0)))
1
2
def face_to_2d(face): 
    return [vector_to_2d(vertex) for vertex in face]
1 blues = matplotlib.cm.get_cmap('Blues')

1
2
def unit(v): 
    return scale(1./length(v), v)
1
2
def normal(face): 
    return(cross(subtract(face[1 ], face[0 ]), subtract(face[2 ], face[0 ])))
1
2
3
4
5
6
7
8
9
10
11
def render(faces, light=(1,2,3), color_map=blues, lines=None): 
    polygons = [] 
    for face in faces: 
        unit_normal = unit(normal(face)) 
        if unit_normal[2 ] > 0 : 
            c = color_map(1 − dot(unit(normal(face)),  
                          unit(light))) 
            p = Polygon2D(*face_to_2d(face),  
                          fill=c, color=lines) 
            polygons.append(p) 
    draw2d(*polygons,axes=False, origin=False, grid=None)
1
2
3
4
1 render(octahedron, color_map=matplotlib.cm.get_cmap('Blues'), lines=black)

Figure 3.46 Four visible faces of the octahedron in shades of blue
Figure 3.47 A 3D shape with many triangular sides. The effect of the shading is more
apparent.

Exercise 3.27-Mini Project: Find pairs of vectors dening each of the 12 edges of
the octahedron and draw all of the edges in Python.
Solution: The top of the octahedron is (0, 0, 1). It connects to all four points in the
x,y plane via four edges. Likewise, the bottom of the octahedron is (0, 0, −1) and it
also connects to all four points in the x,y plane. Finally, the four points in the x,y
plane connect to each other in a square:
top = (0,0,1) 
bottom = (0,0,−1) 
xy_plane = [(1,0,0),(0,1,0),(−1,0,0),(0,−1,0)] 
edges = [Segment3D(top,p) for p in xy_plane] +\ 
            [Segment3D(bottom, p) for p in xy_plane] +\ 
            [Segment3D(xy_plane[i],xy_plane[(i+1)%4 ]) for i in range(0,4)]  
draw3d(*edges)
The resulting edges of the octahedron
Exercise 3.28: The rst face of the octahedron is [(1, 0, 0), (0, 1, 0), (0, 0, 1)]. Is that
the only valid order to write the vertices for this face?
Solution: No, for instance [(0, 1, 0), (0, 0, 1), (1, 0, 0)] is the same set of three points,
and the cross product still points in the same direction in this order.

CHAPTER 4
Figure 4.1 Picturing a vector function as a machine with an input slot and output slot
Figure 4.2 A transformation can be applied to every vector making up a 3D model,
thereby transforming the whole model in the same geometric way.

Figure 4.3 Rotating the teapot by 1° at a time, 45 times in a row, beginning with the
upper left-hand corner
1
2
3
4
def transform(v): 
    old_x, old_y, old_z = v 
    # ... do some computation here ... 
    return (new_x, new_y, new_z)

Figure 4.4 The result of running draw_teapot.py
1
2
3
from vectors import scale 
def scale2(v): 
    return scale(2.0, v)
1
2
3
4
5
original_triangles = load_triangles() 
scaled_triangles = [ 
    [scale2(vertex) for vertex in triangle] 
    for triangle in original_triangles 
]
1
2
3

Figure 4.5 Applying scale2  to each vertex of each triangle gives us a teapot that is
twice as big.
1
2
3
from vectors import add 
def translate1left(v): 
    return add((−1,0,0), v)
1
2
3
4
5
scaled_translated_triangles = [ 
    [translate1left(scale2(vertex)) for vertex in triangle] 
    for triangle in original_triangles 
] 
draw_model(scaled_translated_triangles)

Figure 4.6 The teapot is bigger and moved to the left as we hoped!
Figure 4.7 Calling scale2  and then translate1left  on a teapot to output a
transformed version
1
2
def scale2_then_translate1left(v): 
    return translate1left(scale2(v))

Figure 4.8 Welding the two function machines together to get a new one, which
performs both transformations in one step
1
2
3
4
def compose(f1,f2): 
    def new_function(input): 
        return f1(f2(input)) 
    return new_function
1 scale2_then_translate1left = compose(translate1left, scale2)
1
2
3
4
5
def polygon_map(transformation, polygons): 
    return [ 
        [transformation(vertex) for vertex in triangle] 
        for triangle in polygons 
    ]
1 draw_model(polygon_map(scale2, load_triangles()))

Figure 4.9 A function machine that takes numbers as inputs and produces new function
machines as outputs
Figure 4.10 Rotating a point around the z-axis
1
2
3
4
def scale_by(scalar): 
    def new_function(v): 
        return scale(scalar, v) 
    return new_function
1
2
3
def rotate2d(angle, vector): 
    l,a = to_polar(vector) 
    return to_cartesian((l, a+angle))
1
2
3
4
def rotate_z(angle, vector): 
    x,y,z = vector 
    new_x, new_y = rotate2d(angle, (x,y)) 
    return new_x, new_y, z

Figure 4.11 The teapot is rotated 45° counterclockwise about the z-axis.
1
2
3
4
def rotate_z_by(angle): 
    def new_function(v): 
        return rotate_z(angle,v) 
    return new_function
1 draw_model(polygon_map(rotate_z_by(pi/4.), load_triangles()))
1
2
3
4
5
6
7
8
def rotate_x(angle, vector): 
    x,y,z = vector 
    new_y, new_z = rotate2d(angle, (y,z)) 
    return x, new_y, new_z 
def rotate_x_by(angle): 
    def new_function(v): 
        return rotate_x(angle,v) 
    return new_function

Figure 4.12 The teapot rotated by π/2 about the x-axis.
1 draw_model(polygon_map(rotate_x_by(pi/2.), load_triangles()))
1
2
3
def stretch_x(vector): 
    x,y,z = vector 
    return (4.*x, y, z)

Figure 4.13 A teapot stretched along the x-axis.
1
2
3
def cube_stretch_z(vector): 
    x,y,z = vector 
    return (x, y*y*y, z)

Figure 4.14 Stretching the teapot in the y direction instead
Figure 4.15 Cubing the vertical dimension of the teapot

Figure 4.16 Adding the y-coordinate to the existing x-coordinate causes the teapot to
slant in the x direction.
Exercise 4.1: Implement a translate_by  function (referred to in section 4.1.2),
taking a translation vector as input and returning a translation function as output.
Solution:
def translate_by(translation): 
    def new_function(v):
        return add(translation,v) 
    return new_function
1
2
3
def slant_xy(vector): 
    x,y,z = vector 
    return (x+y, y, z)

Exercise 4.2: Render the teapot translated by 20 units in the negative z direction.
What does the resulting image look like?
Solution: We can accomplish this by applying translate_by((0,0,−20))  to every
vector of every polygon with polgyon_map  :
draw_model(polygon_map(translate_by((0,0,−20)), load_triangles()))
Remember, we are looking at the teapot from ve units up the z-axis. This
transformation brings the teapot 20 units further from us, so it looks much smaller
than the original. You can nd the complete implementation in
translate_teapot_down_z.py in the source code.
The teapot translated 20 units down the z-axis. It appears smaller because it is
further from the viewpoint.

Exercise 4.3-Mini Project: What happens to the teapot when you scale every vector
by a scalar between 0 and 1? What happens when you scale it by a factor of −1?
Solution: We can apply scale_by(0.5)  and scale_by(−1)  to see the results:
draw_model(polygon_map(scale_by(0.5), load_triangles())) 
draw_model(polygon_map(scale_by(−1), load_triangles()))
Left-to-right, the original teapot, the teapot scaled by 0.5, and the teapot scaled by
−1.
As you can see, scale_by(0.5)  shrinks the teapot to half its original size. The
action of scale_by(−1)  seems to rotate the teapot by 180°, but the situation is a
bit more complicated. It’s actually turned inside-out as well! Each triangle has been
reected, so each normal vector now points into the teapot rather than outward
from its surface.
Reection changes the orientation of a triangle. The indexed vertices are in
counterclockwise order on the left and clockwise order in the reection on the right.
The normal vectors to these triangles point in opposite directions.
Rotating the teapot, you can see that it is not quite rendering correctly as a result.
We should be careful with reections of our graphics for this reason!

The rotated, reected teapot does not look quite right. Some features appear but
should be concealed. For instance, we can see both the lid and the hollow bottom in
the bottom right frame.
 
Exercise 4.4: First apply translate1left  to the teapot and then apply scale2 .
How is the result di|erent from the opposite order of composition? Why?
Solution: We can compose these two functions in the specied order and then apply
them with polygon_map:
draw_model(polygon_map(compose(scale2, translate1left), load_triangles()))
The result is that the teapot is still twice as large as the original, but this one is
translated further to the left. This is because when a scaling factor of 2 is applied
after a translation, the distance of the translation doubles as well. You can convince
yourself by running the source les scale_translate _teapot.py and
translate_scale_teapot .py and comparing the results.
Scaling and then translating the teapot (left) vs. translating and then scaling (right)
Exercise 4.5: What is the e|ect of the transformation compose(scale_by (0.4),
scale_by(1.5))  ?
Solution: Applying this to a vector scales it by 1.5 and then by 0.4 for a net scaling
factor of 0.6. The resulting gure will be 60% of the size of the original.

Exercise 4.6: Modify the compose(f,g)  function to compose(*args) , which takes
several functions as arguments and returns a new function that is their composition.
Solution:
def compose(*args): 
    def new_function(input):         ❶ 
        state = input                ❷ 
        for f in reversed(args):     ❸ 
            state = f(state)         ❹ 
        return state 
    return new_function
❶ Starts dening the function that compose returns
❷ Sets the current state equal to the input
❸ Iterates over the input functions in reverse order because the inner functions of a
composition are applied rst. For example, compose(f,g,h)(x) should equal
f(g(h(x))), so the rst function to apply is h.
❹ At each step, updates the state by applying the next function. The nal state has
all the
To check our work, we can build some functions and compose them:
def prepend(string): 
    def new_function(input): 
        return string + input 
    return new_function 
 
f = compose(prepend("P"), prepend("y"), prepend("t"))
Then running f(“hon”)  returns the string “Python” . In general, the constructed
function f  appends the string “Pyt”  to whatever string it is given.

Exercise 4.7: Write a curry2(f)  function that takes a Python function f(x,y)
with two arguments and returns a curried version. For instance, once you write g =
curry2(f) , the two expressions f(x,y)  and g(x)(y)  should return the same
result.
Solution: The return value should be a new function that, in turn, produces a new
function when called:
def curry2(f): 
    def g(x): 
        def new_function(y):
            return f(x,y) 
        return new_function 
    return g
As an example, we could have built the scale_by  function like this:
>>> scale_by = curry2(scale) 
>>> scale_by(2)((1,2,3)) 
 
(2, 4, 6)
Exercise 4.8: Without running it, what is the result of applying the transformation
compose(rotate_z_by(pi/2),rotate_x_by(pi/2))  ? What if you switch the
order of the composition?
Solution: This composition is equivalent to a clockwise rotation by π/2 about the y-
axis. Reversing the order gives a counterclockwise rotation by π/2 about the y-axis.
Exercise 4.9: Write a function stretch_x(scalar,vector)  that scales the target
vector by the given factor but only in the x direction. Also write a curried version
stretch_x_by  so that stretch_x_by(scalar)(vector)  returns the same result.
Solution:
def stretch_x(scalar,vector): 
    x,y,z = vector 
    return (scalar*x, y, z) 
 
def stretch_x_by(scalar): 
    def new_function(vector): 
        return stretch_x(scalar,vector) 
    return new_function

Figure 4.17 Geometric demonstration of the vector sum z + v = w
Figure 4.18 After rotating u, v, and w by the same rotation R, the sum still holds.

Figure 4.19 Scalar multiplication is preserved by rotation.
Linear transformation
A linear transformation is a vector transformation T that preserves vector addition
and scalar multiplication. That is, for any input vectors u and v, we have
T(u) + T(v) = T(u + v)
and for any pair of a scalar s and a vector v, we have
T(sv) = sT(v)
Figure 4.20 Picturing the vector sum of z = (2, 3) and v = (1, −1), z + v = (3, 2)

Figure 4.21 S does not respect sums! S(u) + S(v) is far from S(u + v).
Figure 4.22 Doubling the lengths of vectors preserves their sums: if z + v = w, then D(u) +
D(v) = D(w)

Figure 4.23 The translation transformation B does not preserve a vector sum because
B(u) + B(v) is not equal to B(u + v).
Figure 4.24 The midpoint between the tips of two vectors z and v can be found as the
linear combination ½ z + ½ v = ½ (u + v).

Figure 4.25 Because the midpoint between two vectors is a linear combination of the
vectors, the linear transformation T sets the midpoint between z and v to the midpoint
between T(u) and T(v).
Figure 4.26 The point 0.25u + 0.75v lies on the line segment connecting z and v, 75% of
the way from z to v. You can see this concretely with u = (−2, 2) and v = (6, 6).

Figure 4.27 Plotting various weighted averages of (−1, 1) and (3, 4) with 10 values of s
between 0 and 1 (left) and 100 values of s between 0 and 1 (right)
Figure 4.28 A linear transformation T transforms a weighted average of z and v to a
weighted average of T(u) and T(v). The original weighted average lies on the segment
connecting z and v, and the transformed one lies on the segment connecting T(u) and
T(v).

Figure 4.29 Applying a linear transformation (rotation by 60°) to points making up a
triangle. The result is a rotated triangle (on the left).
Figure 4.30 Applying the non-linear transformation S does not preserve the
straightness of edges of the triangle.

Figure 4.31 The 3D vector (4, 3, 5) as a linear combination of (1, 0, 0), (0, 1, 0), and (0, 0, 1)
Figure 4.32 The 2D vector (7, −4) as a linear combination of the standard basis vectors
e1 and e2

Figure 4.33 When a linear transformation acts on the two standard basis vectors in 2D,
we get two new vectors as a result.
Figure 4.34 We can compute T(v) for any vector v as a linear combination of T(e1) and
T(e2).

Figure 4.35 In this rotated, skewed conØguration, we see that the teapot does not have
a bottom!
1
2
3
4
5
6
7
8
9
10
11
12
Ae1 = (1,1,1) 
Ae2 = (1,0,−1) 
Ae3 = (0,1,1) 
 
def apply_A(v): 
    return add( 
        scale(v[0], Ae1), 
        scale(v[1], Ae2), 
        scale(v[2], Ae3) 
    ) 
  
draw_model(polygon_map(apply_A, load_triangles()))
1
2
3
4

Exercise 4.10: Considering S again, the vector transformation that squares all
coordinates, show algebraically that S(sv) = sS(v) does not hold for all choices of
scalars s and 2D vectors v.
Solution: Let v = (x, y). Then s v = (sx, sy) and S(sv) = (s2 x2, s2 y2) = s2 · (x2, y2) = s2 ·
S(v). For most values of s and most vectors v, S(sv) = s2 · S(v) won’t equal s · S(v). A
specic counterexample is s = 2 and v = (1, 1, 1), where S(sv) = (4, 4, 4) while s · S(v) =
(2, 2, 2). This counterexample shows that S is not linear.
Exercise 4.11: Suppose T is a vector transformation and T(0) ≠ 0, where 0 represents
the vector with all coordinates equal to zero. Why is T not linear according to the
denition?
Solution: For any vector v, v + 0 = v. For T to preserve vector addition, it should be
that T(v + 0) = T(v) + T(0). Because T(v + 0) = T(v), this requires that T(v) = T(v) +
T(0) or 0 = T(0). Given that this is not the case, T cannot be linear.
Exercise 4.12: The identity transformation is the vector transformation that returns
the same vector it is passed. It is denoted with a capital I, so we could write its
denition as I(v) = v for all vectors v. Explain why I is a linear transformation.
Solution: For any vectors v and w, I(v + w) = v + w = I(v) + I(w), and for any scalar s,
I(sv) = s v = s · I(v). These equalities show that the identity transformation preserves
vector sums and scalar multiples.

Exercise 4.13: What is the midpoint between (5, 3) and (−2, 1)? Plot all three of these
points to see that you are correct.
Solution: The midpoint is ½ (5, 3) + ½ (−2, 1) or (5/2, 3/2) + (−1, ½), which equals
(3/2, 2). This is seen to be correct when drawn to scale in the diagram that follows:
The midpoint of the segment connecting (5, 3) and (−2, 1) is (3/2, 2).

Exercise 4.14: Consider again the non-linear transformation S(v) sending v = (x, y)
to (x2, y2). Plot all 36 vectors v with integer coordinates 0 to 5 as points using the
drawing code from chapter 2 and then plot S(v) for each of them. What happens
geometrically to vectors under the action of S ?
Solution: The space between points is uniform to begin with, but in the transformed
picture, the spacing increases in the horizontal and vertical directions as the x − and
y-coordinates increase, respectively.
 
 
The grid of points is initially uniformly spaced, but after applying the
transformation S, the spacing varies between points, even on the same lines.

Exercise 4.15-Mini Project: Property-based testing is a type of unit testing that
involves inventing arbitrary input data for a program and then checking that the
outputs satisfy desired conditions. There are popular Python libraries like
Hypothesis (available through pip) that make it easy to set this up. Using your
library of choice, implement property-based tests that check if a vector
transformation is linear.
Specically, given a vector transformation T implemented as a Python function,
generate a large number of pairs of random vectors and assert for all of those that
their sum is preserved by T. Then, do the same thing for pairs of a scalar and a
vector, and ensure that T preserves scalar multiples. You should nd that linear
transformations like rotate_x_by(pi/2)  pass the test, but non-linear
transformations like the coordinate-squaring transformation do not pass.
Exercise 4.16: One 2D vector transformation is reection across the x -axis. This
transformation takes a vector and returns another one, which is the mirror image
with respect to the x-axis. Its x-coordinate should be unchanged, and its y-
coordinate should change its sign. Denoting this transformation Sx, here is an image
of a vector v = (3, 2) and the transformed vector Sx(v).
A vector v = (3, 2) and its reection over the x-axis (3, −2)
Draw two vectors and their sum, as well as the reection of these three vectors to
demonstrate that this transformation preserves vector addition. Draw another
diagram to show similarly that scalar multiplication is preserved, thereby
demonstrating both criteria for linearity.

Solution: Here’s an example of reection over the x-axis that preserves a vector
sum:
For z + v = w as shown, reection over the x-axis preserves the sum; that is, Sx(u) +
Sx(v) = Sx(w).
Here’s an example showing reection preserving a scalar multiple: Sx(sv) lies where
sSx(v) is expected to be.
To prove that Sx is linear, you would need to show that you can draw analogous
pictures for every vector sum and every scalar multiple. There are innitely many of
these, so it’s better to use an algebraic proof. (Can you gure out how to show these
two facts algebraically?)

Reection across the x-axis preserves this scalar multiple.
Exercise 4.17-Mini Project: Suppose S and T are both linear transformations.
Explain why the composition of S and T is also linear.
Solution: The composition S(T(v)) is linear if for any vector sum u + v = w, we have
S(T(u)) + S(T(v)) = S(T(w)), and for any scalar multiple s v, we have S(T(sv)) = s ·
S(T(v)). This is only a statement of the denition that must be satised.
Now let’s see why it’s true. Suppose rst that u + v = w for any given input vectors u
and v. Then by the linearity of T, we also know that T(u) + T(v) = T(w). Because this
sum holds, the linearity of S tells us that the sum is preserved under S : S(T(u)) +
S(T(v)) = S(T(w)). That means that S(T(v)) preserves vector sums.
Similarly, for any scalar multiple s v, the linearity of T tells us that s · T(v) = T(sv). By
linearity of S, s · S(T(v)) = S(T(sv)) as well. This means S(T(v)) preserves scalar
multiplication and, therefore, that S(T(v)) satises the full denition of linearity as
previously stated. We can conclude that the composition of two linear
transformations is linear.

Exercise 4.18: Let T be the linear transformation done by the Python function
rotate_x_by(pi/2) , what are T(e1), T(e2), and T(e3)?
Solution: Any rotation about an axis leaves points on the axis una|ected, so because
T(e1) is on the x-axis, T(e1) = e1 = (1, 0, 0). A counterclockwise rotation of e2 = (0, 1, 0)
in the y,z plane takes this vector from the point one unit in the
positive y direction to the point one unit in the positive z direction, so T(e2) = e3 = (0,
0, 1). Likewise, e3 is rotated counterclockwise from the positive z direction to the
negative y direction. T(e3) still has length one in this direction, so it is -e2 or (0, −1,
0).
A quarter-turn counterclockwise in the y,z plane sends e2 to e3 and e3 to − e2.
Exercise 4.19: Write a linear_combination(scalars,  *vectors)  that takes a
list of scalars and the same number of vectors, and returns a single vector. For
example, linear_combination([1,2,3],  (1,0,0),  (0,1,0),  (0,0, 1))
should return 1 · (1, 0, 0) + 2 · (0, 1, 0) + 3 · (0, 0, 1) or (1, 2, 3).
Solution:
from vectors import * 
def linear_combination(scalars,*vectors): 
    scaled = [scale(s,v) for s,v in zip(scalars,vectors)] 
    return add(*scaled)
We can conrm this gives the expected result as previously described:
>>> linear_combination([1,2,3], (1,0,0), (0,1,0), (0,0,1)) 
(1, 2, 3)

Exercise 4.20: Write a function transform_standard_basis(transform)  that
takes a 3D vector transformation as an input and outputs the e|ect it has on the
standard basis. It should output a tuple of 3 vectors that are the results of
transform  acting on e1, e2, and e3, respectively.
Solution: As suggested, we just need to apply transform  to each standard basis
vector:
def transform_standard_basis(transform): 
    return transform((1,0,0)), transform((0,1,0)), transform((0,0,1))
It conrms (within the oating-point error) our solution to a previous exercise,
where we sought this output for rotate_x_by(pi/2)  :
>>> from math import * 
>>> transform_standard_basis(rotate_x_by(pi/2)) 
((1, 0.0, 0.0), (0, 6.123233995736766e−17, 1.0), (0, −1.0, 
    1.2246467991473532e−16))
These vectors are approximately (1, 0, 0), (0, 0, 1), and (0, −1, 0).
Exercise 4.21: Suppose B is a linear transformation, with B(e1) = (0, 0, 1), B(e2) = (2,
1, 0), B(e3) = (−1, 0, −1), and v = (−1, 1, 2). What is B(v)?
Solution: Because v = (−1, 1, 2) = -e1 + e2 + 2e3, B(v) = B(−e1 + e2 + 2e3). Because B is
linear, it preserves this linear combination: B(v) = − B(e1) + B(e2) + 2 · B(e3). Now we
have all the information we need: B(v) = −(0, 0, 1) + (2, 1, 0) + 2 · (−1, 0, −1) = (0, 1,
−3).

Exercise 4.22: Suppose a and B are both linear transformations with a(e1) = (1, 1, 1),
a(e2) = (1, 0, −1), and a(e3) = (0, 1, 1), and B(e1) = (0, 0, 1), B(e2) = (2, 1, 0), and B(e3) =
(−1, 0, −1). What is a(B(e1)), a(B(e2)), and a(B(e3))?
Solution: a(B(e1)) is a applied to B(e1) = (0, 0, 1) = e3. We already know a(e3) = (0, 1,
1), so B(a(e1)) = (0, 1, 1).
a(B(e2)) is a applied to B(e2) = (2, 1, 0). This is a linear combination of a(e1), a(e2),
and a(e3) with scalars (2, 1, 0): 2 · (1, 1, 1) + 1 · (1, 0, −1) + 0 · (0, 1, 1) = (3, 2, 1).
Finally, a(B(e3)) is a applied to B(e3) = (−1, 0, −1). This is the linear combination −1 ·
(1, 1, 1) + 0 · (1, 0, −1) + −1 · (0, 1, 1) = (−1, −2, −2).
Note that now we know the result of the composition of a and B for all of the
standard basis vectors, so we can calculate a(B(v)) for any vector v.

CHAPTER 5
Figure 5.1 Two machines that do the same linear transformation. Geometric reasoning
powers the machine on the top, while nine numbers power the one on the bottom.

1
2
3
4
5
6
7
B = ( 
    (0,2,1), 
    (0,1,0), 
    (1,0,−1) 
) 
 
v = (3,−2,5)
1
2
>>> list(zip(*B)) 
[(0, 0, 1), (2, 1, 0), (1, 0, −1)]

1
2
def multiply_matrix_vector(matrix, vector): 
    return linear_combination(vector, *zip(*matrix))
1
2
>>> multiply_matrix_vector(B,v) 
(1, −2, −2)

Figure 5.2 Each entry of a product matrix is a dot product of a row of the Ørst matrix
with a column of the second matrix.

Figure 5.3 Thinking of matrix entries as functions of time allows the overall matrix to
change as time passes.
1
2
3
4
5
6
7
from vectors import * 
 
def matrix_multiply(a,b): 
    return tuple( 
        tuple(dot(row,col) for col in zip(*b)) 
        for row in a 
    )
1
2
3
4
5
6
7
8
>>> xa = ((1,1,0),(1,0,1),(1,−1,1)) 
>>> b = ((0,2,1),(0,1,0),(1,0,−1)) 
>>> matrix_multiply(a,b) 
((0, 3, 1), (1, 2, 0), (1, 1, 0)) 
>>> xc = ((1,2),(3,4)) 
>>> d = ((0,−1),(1,0)) 
>>> matrix_multiply(c,d) 
((2, −1), (4, −3))

Figure 5.4 The teapot is transformed by a new matrix in every frame, depending on the
elapsed time when the frame is drawn.
1
2
3
4
5
6
7
8
9
10
11
12
13
from teapot import load_triangles 
from draw_model import draw_model 
from math import sin,cos 
  
def get_rotation_matrix(t): 
    seconds = t/1000 
    return ( 
        (cos(seconds),0,−sin(seconds)), 
        (0,1,0), 
        (sin(seconds),0,cos(seconds)) 
    ) 
draw_model(load_triangles(),  
           get_matrix=get_rotation_matrix)
1
2
3
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
def draw_model(faces, color_map=blues, light=(1,2,3), 
               camera=Camera("default_camera",[]), 
               glRotatefArgs=None, 
               get_matrix=None): 
        #... 
        def do_matrix_transform(v): 
            if get_matrix: 
               m = get_matrix(pygame.time.get_ticks()) 
               return multiply_matrix_vector(m, v) 
            else: 
               return v 
        transformed_faces = polygon_map(do_matrix_transform,  
                                        faces) 
        for face in transformed_faces: 
        #...
1
2
3
4
5
6

Exercise 5.1: Write a function infer_matrix(n, transformation)  that takes a
dimension (like 2 or 3) and a function that is a vector transformation assumed to be
linear. It should return an n -by- n square matrix (an n -tuple of n -tuples of
numbers, which is the matrix representing the linear transformation). Of course, the
output is only meaningful if the input transformation is linear. Otherwise, it
represents an entirely di|erent function!
Solution:
def infer_matrix(n, transformation): 
    def standard_basis_vector(i): 
        return tuple(1 if i==j else 0 for j in range(1,n+1))         ❶ 
    standard_basis = [standard_basis_vector(i) for i in range(1,n+1)]❷ 
    cols = [transformation(v) for v  in standard_basis]               ❸ 
    return tuple(zip(*cols))                                         ❹
❶ Creates the ith standard basis vector as a tuple containing a one in the ith
coordinate and zeroes in all other coordinates
❷ Creates the standard basis as a list of n vectors
❸ Denes the columns of a matrix to be the result of applying the corresponding
linear transformation to the standard basis vectors
❹ Reshapes the matrix to be a tuple of rows instead of a list of columns, following
our convention
We can test this on a linear transformation like rotate_z_by(pi/2)  :
>>> from transforms import rotate_z_by 
>>> from math import pi 
>>> infer_matrix(3,rotate_z_by(pi/2)) 
((6.123233995736766e−17, −1.0, 0.0), (1.0, 1.2246467991473532e−16, 0.0), (0, 0, 1))
Exercise 5.2: What is the result of the following product of a 2-by−2 matrix with a
2D vector?
Solution: The dot product of the vector with the rst row of the matrix is −2.5 · 1.3 +
0.3 · -0.7 = −3.46. The dot product of the vector with the second row of the matrix is
−2.5 · 6.5 + 0.3 · 3.2 = −15.29. These are the coordinates of the output vector, so the
result is:

Exercise 5.3-Mini Project: Write a random_matrix  function that generates
matrices of a specied size with random whole number entries. Use the function to
generate ve pairs of 3-by−3 matrices. Multiply each of the pairs together by hand
(for practice) and then check your work with the matrix_multiply  function.
Solution: First, we give the random_matrix  function arguments to specify the
number of rows, the number of columns, and the minimum and maximum values for
entries:
from random import randint 
def random_matrix(rows,cols,min=−2,max=2): 
    return tuple( 
        tuple( 
        randint(min,max) for j in range(0,cols)) 
        for i in range(0,rows) 
    )
Next, we can generate a random 3-by−3 matrix with entries between 0 and 10 as
follows:
>>> random_matrix(3,3,0,10) 
((3, 4, 9), (7, 10, 2), (0, 7, 4))
Exercise 5.4: For each of your pairs of matrices from the previous exercise, multiply
them in the opposite order. Do you get the same result?
Solution: Unless you get very lucky, your results will all be di|erent. Most pairs of
matrices give di|erent results when multiplied in di|erent orders. In math jargon,
we say an operation is commutative if it gives the same result regardless of the order
of inputs. For instance, multiplying numbers is a commutative operation because xy
= yx for any choice of numbers x and y. However, matrix multiplication is not
commutative because for two square matrices a and B, AB does not always equal BA.
Exercise 5.5: In either 2D or 3D, there is a boring but important vector
transformation called the identity transformation that takes in a vector and returns
the same vector as output. This transformation is linear because it takes any input
vector sum, scalar multiple, or linear combination and returns the same thing as
output. What are the matrices representing the identity transformation in 2D and
3D, respectively?

Solution: In 2D or 3D, the identity transformation acts on the standard basis vectors
and leaves them unchanged. Therefore, in either dimension, the matrix for this
transformation has the standard basis vectors as its columns. In 2D and 3D, these
identity matrices are denoted by I2 and I3, respectively, and look like this:

Exercise 5.6: Apply the matrix ((2,1,1),(1,2,1),(1,1,2))  to all the vectors
dening the teapot. What happens to the teapot and why?
Solution: The following function is included in the source le matrix_transform
_teapot.py:
def transform(v): 
    m = ((2,1,1),(1,2,1),(1,1,2)) 
    return multiply_matrix_vector(m,v) 
draw_model(polygon_map(transform, load_triangles()))
Running the code, we see that the front of the teapot is stretched out into the region
where x, y, and z are all positive.
Applying the given matrix to all vertices of the teapot
This is because all of the standard basis vectors are transformed to vectors with
positive coordinates: (2, 1, 1), (1, 2, 1), and (1, 1, 2), respectively.

How the linear transformation dened by this matrix a|ects the standard basis
vectors.
A linear combination of these new vectors with positive scalars is stretched further
in the +x, +y, and +z directions than the same linear combination of the standard
basis.
Exercise 5.7: Implement multiply_matrix_vector  in a di|erent way by using
two nested comprehensions: one traversing the rows of the matrix and one
traversing the entries of each row.
Solution:
def multiply_matrix_vector(matrix,vector): 
    return tuple( 
        sum(vector_entry * matrix_entry 
            for vector_entry, matrix_entry in zip(row,vector)) 
        for row in matrix 
    )

Exercise 5.8: Implement multiply_matrix_vector  yet another way using the fact
that the output coordinates are the dot products of the input matrix rows with the
input vector.
Solution: This is a simplied version of the previous exercise solution:
def multiply_matrix_vector(matrix,vector): 
    return tuple( 
        dot(row,vector) 
        for row in matrix 
    )

Exercise 5.9−Mini Project: I rst told you what a linear transformation was and
then showed you that any linear transformation can be represented by a matrix.
Let’s prove the converse fact now: all matrices represent linear transformations.
Starting with the explicit formulas for multiplying a 2D vector by a 2-by−2 matrix or
multiplying a 3D vector by a 3-by−3 matrix, prove that algebraically. That is, show
that matrix multiplication preserves sums and scalar multiples.
Solution: I’ll show the proof for 2D; the 3D proof has the same structure but with a
bit more writing. Suppose we have a 2-by−2 matrix called a with any four numbers
a, b, c, and d as its entries. Let’s see how a operates on two vectors u and v :
You can do the matrix multiplications explicitly to nd a u and a v :
And then we can compute a u + a v and a(u + v) and see that the results match:
This tells us that the 2D vector transformation dened by multiplying any 2-by−2
matrix preserves vector sums. Likewise, for any number s, we have
So s · (a v) and a(s v) give the same results, and we see that multiplying by the matrix
a preserves scalar multiples as well. These two facts mean that multiplying by any
2-by−2 matrix is a linear transformation of 2D vectors.

Exercise 5.10: Once again, let’s use the two matrices from section 5.1.3:
Write a function compose_a_b  that executes the composition of the linear
transformation for a and the linear transformation for B. Then use the infer
_matrix  function from a previous exercise in this section to show that
infer_matrix(3, compose_a_b)  is the same as the matrix product AB.
Solution: First, we implement two functions transform_a  and transform_b  that
do the linear transformations dened by the matrices a and B. Then, we combine
these using our compose  function:
from transforms import compose 
 
a = ((1,1,0),(1,0,1),(1,−1,1)) 
b = ((0,2,1),(0,1,0),(1,0,−1)) 
 
def transform_a(v):
    return multiply_matrix_vector(a,v) 
 
def transform_b(v):
    return multiply_matrix_vector(b,v) 
 
compose_a_b = compose(transform_a, transform_b)
Now we can use our infer_matrix  function to nd the matrix corresponding to
this composition of linear transformations and compare it to the matrix product AB
:
>>> infer_matrix(3, compose_a_b) 
((0, 3, 1), (1, 2, 0), (1, 1, 0)) 
>>> matrix_multiply(a,b) 
((0, 3, 1), (1, 2, 0), (1, 1, 0))

Exercise 5.11-Mini Project: Find two, 2-by−2 matrices, neither of which is the
identity matrix I2, but whose product is the identity matrix.
Solution: One way to do this is to write two matrices and play with their entries until
you get the identity matrix as a product. Another way is to think of the problem in
terms of linear transformations. If two matrices multiplied together produce the
identity matrix, then the composition of their corresponding linear transformations
should produce the identity transformation.
With that in mind, what are two 2D linear transformations whose composition is the
identity transformation? When applied in sequence to a given 2D vector, these linear
transformations should return the original vector as output. One such pair of
transformations is rotation by 90° clockwise, then rotation by 270° clockwise.
Applying both of these executes a 360° rotation that brings any vector back to its
original position. The matrices for a 270° rotation and a 90° rotation are as follows,
and their product is the identity matrix:
Exercise 5.12: We can multiply a square matrix by itself any number of times. We
can then think of successive matrix multiplications as “raising a matrix to a power.”
For a square matrix a, we can write AA as a2 ; we can write AAA as a3 ; and so on.
Write a matrix_power(power,matrix)  function that raises a matrix to the
specied (whole number) power.
Solution: Here is an implementation that works for whole number powers greater
than or equal to 1:
def matrix_power(power,matrix): 
    result = matrix 
    for _ in range(1,power): 
        result = matrix_multiply(result,matrix) 
    return result

Figure 5.5 The dot product of a row of the Ørst matrix with a column of the second
matrix produces one entry of the matrix product.
1
2
3
4
5
6
7
>>> xa = ((−1, 0, −1, −2, −2), (0, 0, 2, −2, 1), (−2, −1, −2, 0, 1), (0, 2, −2, 
−1, 0), (1, 1, −1, −1, 0)) 
>>> b = ((−1, 0, −1, −2, −2), (0, 0, 2, −2, 1), (−2, −1, −2, 0, 1), (0, 2, −2, 
−1, 0), (1, 1, −1, −1, 0)) 
>>> matrix_multiply(a,b) 
((−10, −1, 2, −7, 4), (−2, 5, 5, 4, −6), (−1, 1, −4, 2, −2), (−4, −5, −5, -9, 
4), (−1, −2, −2, −6, 4))
1
2
3
4
>>> xc = ((−1, −1, 0), (−2, 1, 2), (1, 0, −1)) 
>>> d = ((1,),(1,),(1,)) 
>>> matrix_multiply(c,d) 
((−2,), (1,), (0,))

Figure 5.6 An entry of the resulting vector computed as a dot product
Table 5.1 Comparison of mathematical notations for vectors with corresponding
Python representations
Representation
In math notation
In Python
Ordered triple (ordered tuple)
v = (−2,1,0)
Column vector
v = ((−2,),(1,),(0,))
Row vector
v = ((−2,1,0),)
Figure 5.7 Two matrices that cannot be multiplied together
1
2
>>> multiply_matrix_vector(c,(1,1,1)) 
(−2, 1, 0)

Figure 5.8 Finding the Ørst entry of the product matrix
Figure 5.9 Finding another entry of the product matrix
Figure 5.10 Each column of the result is a linear combination of the columns of the Ørst
matrix.

Figure 5.11 Each of the Øve rows of the Ørst matrix can be paired with one of the ten
columns of the second matrix to produce one of the 5 × 10 = 50 entries of the product
matrix. I used stars instead of numbers to show you that any matrices of these sizes are
compatible.
Figure 5.12 Visualizing a matrix as a machine that takes vectors as inputs and produces
vectors as outputs
Figure 5.13 ReØning our mental model by redrawing the machine’s input and output
slots to indicate that its inputs and outputs are pairs of numbers

Figure 5.14 A linear transformation machine powered by a 3×3 matrix takes in 3D
vectors and outputs 3D vectors.
Figure 5.15 A machine that takes in 3D vectors and outputs 2D vectors, powered by a
2×3 matrix

Figure 5.16 Only 1 · a contributes to the Ørst entry of the product, and only 1 · b
contributes to the second entry. The other entries are zeroed out (in gray in the Øgure).
Figure 5.17 A vector sum of two arbitrary vectors z and v in 3D
Figure 5.18 Visualizing where u, v, and z + v end up after projection to the x,y plane
Figure 5.19 The projected vectors form a sum: P(v) + P(v) = P(u + v).

Figure 5.20 Four linear functions represented as machines with input and output slots.
The shape of a slot tells us what dimension of vector it accepts or produces.
Figure 5.21 The composition of P and M. A vector is passed into the input slot of M, the
output M(v) passes invisibly through the plumbing and into P, and the output P(M(v))
emerges from the other end.
Figure 5.22 The composition of N and M is not possible because outputs of N are 2D
vectors, while inputs to M are 3D vectors.
Figure 5.23 Applying M and then P is equivalent to applying the composition PM. We
consolidate the composition into a single matrix by doing the matrix multiplication.

Exercise 5.13: What are the dimensions of this matrix?
5×3
3×5
Solution: This is a 3×5 matrix because it has three rows and ve columns.
Exercise 5.14: What are the dimensions of a 2D column vector considered as a
matrix? What about a 2D row vector? A 3D column vector? A 3D row vector?
Solution: A 2D column vector has two rows and one column, so it is a 2×1 matrix. A
2D row vector has one row with two columns, so it is a 1×2 matrix. Likewise, a 3D
column and row vector have the dimensions 3×1 and 1×3 as matrices, respectively.
Exercise 5.15-Mini Project: Many of our vector and matrix operations make use of
the Python zip  function. When given input lists of di|erent sizes, this function
truncates the longer of the two rather than failing. This means that when we pass
invalid inputs, we get meaningless results back. For instance, there is no such thing
as a dot product between a 2D vector and a 3D vector, but our dot  function returns
something anyway:
>>> from vectors import dot 
>>> dot((1,1),(1,1,1)) 
2
Add safeguards to all of the vector arithmetic functions so that they throw
exceptions rather than returning values for vectors of invalid sizes. Once you’ve
done that, show that matrix_multiply  no longer accepts a product of a 3×2 and a
4×5 matrix.

Exercise 5.16: Which of the following are valid matrix products? For those that are
valid, what dimension is the product matrix?
A.
B.
C.
D.
Solution:
A. This product of a 2×2 matrix and a 4×4 matrix is not valid; the rst matrix has
two columns but the second matrix has four rows.
B. This product of a 2×4 matrix and a 4×2 matrix is valid; the four columns of the
rst matrix match the four rows of the second matrix. The result is a 2×2 matrix.
C. This product of a 3×1 matrix and a 1×8 matrix is valid; the single column of the
rst matrix matches the single row of the second. The result is a 3×8 matrix.
D. This product of a 3×3 matrix and a 2×3 matrix is not valid; the three columns of
the rst matrix do not match the two rows of the second.

Exercise 5.17: A matrix with 15 total entries is multiplied by a matrix with 6 total
entries. What are the dimensions of the two matrices, and what is the dimension of
the product matrix?
Solution: Let’s call the dimensions of the matrices m -by- n and n -by- k because
the number of columns of the rst matrix has to match the number of rows of the
second. Then mn = 15 and nk = 6. There are actually two possibilities:
The rst possibility is that m = 5, n = 3, and k = 2. Then this
would be a 5×3 matrix multiplied by a 3×2 matrix resulting in a
5×2 matrix.
The second possibility is that m = 15, n = 1, and k = 6. Then this
would be a 15×1 matrix times a 1×6 matrix, resulting in a 15×6
matrix.
Exercise 5.18: Write a function that turns a column vector into a row vector, or vice
versa. Flipping a matrix on its side like this is called transposition and the resulting
matrix is called the transpose of the original.
Solution:
def transpose(matrix): 
    return tuple(zip(*matrix))
The call to zip(*matrix)  returns a list of columns of the matrix and then we tuple
them. This has the e|ect of swapping rows and columns of any input matrix,
specically turning column vectors into row vectors and vice versa:
>>> transpose(((1,),(2,),(3,))) 
((1, 2, 3),) 
>>> transpose(((1, 2, 3),)) 
((1,), (2,), (3,))

Exercise 5.19: Draw a picture that shows that a 10×8 and a 5×8 matrix can’t be
multiplied in that order.
Solution:
The rows of the rst matrix have ten entries but the columns of the second have
ve, meaning we can’t evaluate this matrix product.
Exercise 5.20: We want to multiply three matrices together: a is 5×7, B is 2×3, and C
is 3×5. What order can they be multiplied in and what is the size of the result?
Solution: One valid product is BC, a 2x3 times a 3×5 matrix yielding a 2×5 matrix.
Another is CA, a 3×5 matrix times a 5×7 matrix yielding a 3×7 matrix. The product of
three matrices, BCA, is valid regardless of the order you use. (BC) a is a 2×5 matrix
times a 5×7 matrix, while B(CA) is a 2×3 matrix times a 3×7 matrix. Each yields the
same 2×7 matrix as a result.
Multiplying three matrices in di|erent orders

Exercise 5.21: Projection onto the y,z plane and onto the x,z plane are also linear
maps from 3D to 2D. What are their matrices?
Solution: Projection onto the y,z plane deletes the x-coordinate. The matrix for this
operation is
Likewise, projection onto the x,z plane deletes the y-coordinate:
For example,
Exercise 5.22: Show by example that the infer_matrix  function from a previous
exercise can create matrices for linear functions whose inputs and outputs have
di|erent dimensions.
Solution: One function we could test would be projection onto the x,y plane, which
takes in 3D vectors and returns 2D vectors. We can implement this linear
transformation as a Python function and then infer its 2×3 matrix:
>>> def project_xy(v):
...     x,y,z = v 
...     return (x,y) 
... 
>>> infer_matrix(3,project_xy) 
((1, 0, 0), (0, 1, 0))
Note that we had to supply the dimension of input vectors as an argument, so that
we can build the correct standard basis vectors to test under the action of
project_xy . Once project_xy  is passed the 3D standard basis vectors, it
automatically outputs 2D vectors to supply the columns of the matrix.

Exercise 5.23: Write a 4×5 matrix that acts on a 5D vector by deleting the third of its
ve entries, thereby producing a 4D vector. For instance, multiplying it with the
column vector form of (1, 2, 3, 4, 5) should return (1, 2, 4, 5).
Solution: The matrix is
You can see that the rst, second, fourth, and fth coordinates of an input vector
form the four coordinates of the output vector:
The 1s in the matrix indicate where coordinates of the input vector end up in the
output vector.

Exercise 5.24−Mini Project: Consider the vector of six variables (l, e, m, o, n, s). Find
the matrix for the linear transformation that acts on this vector to produce the
vector (s, o, l, e, m, n) as a result.
Hint: The third coordinate of the output equals the rst coordinate of the input, so
the transformation must send the standard basis vector (1, 0, 0, 0, 0, 0) to (0, 0, 1, 0,
0, 0).
Solution:
This matrix reorders the entries of a 6D vector in the specied way.
Exercise 5.25: What valid products can be made from the matrices M, N, P, and Q
from section 5.2.5? Include in your consideration the products of matrices with
themselves. For those products that are valid, what are the dimensions of the matrix
products?
Solution: M is 3×3, N is 2×2, and P and Q are both 2×3. The product of M with itself,
MM = M2 is valid and a 3×3 matrix, so is NN = N2 which is a 2×2 matrix. Apart from
that, PM, QM, NP, and NQ are all 3×2 matrices.

Figure 5.24 The familiar 2D dinosaur from chapter 2
1
2
3
4
5
6
7
8
9
10
11
from vector_drawing import * 
  
dino_vectors = [(6,4), (3,1), (1,2), (−1,5), (−2,5), (−3,4), (−4,4), 
    (−5,3), (−5,2), (−2,2), (−5,1), (−4,0), (−2,1), (−1,0), (0,−3), 
    (−1,−4), (1,−4), (2,−3), (1,−2), (3,−1), (5,1) 
] 
  
draw( 
    Points(*dino_vectors), 
    Polygon(*dino_vectors) 
)
1
2
3
4
5
6
7
8
9
10
11
from draw3d import * 
def polygon_segments_3d(points,color='blue'): 
   count = len(points) 
   return [Segment3D(points[i], points[(i+1) % count],color=color) for i in range(0
dino_3d = [(x,y,1) for x,y in dino_vectors] 
draw3d( 
   Points3D(*dino_3d, color='blue'), 
   *polygon_segments_3d(dino_3d) 
)

Figure 5.25 The same dinosaur with each of its vertices given a z-coordinate of 1
Figure 5.26 A magic matrix that moves the plane z = 1 by +3 in the x direction and by +1
in the y direction
Figure 5.27 Applying the matrix to every point keeps the dinosaur in the same plane,
but translates it within the plane by (3, 1)..

Figure 5.28 Dropping the translated dinosaur back into 2D
Figure 5.29 This matrix doesn’t move e1 or e2, but it does move e3.
1
2
3
4
5
6
magic_matrix = ( 
    (1,0,3), 
    (0,1,1), 
    (0,0,1)) 
 
translated = [multiply_matrix_vector(magic_matrix, v) for v  in dino_vectors_3d]

Figure 5.30 Let’s see what happens when we move T(e1) and T(e2) in the x,y plane.
Figure 5.31 A matrix that rotates e1 and e3 by 90° and translates e3 by (3, 1). Any Øgure
in the plane where z = 1 experiences both transformations.
1
2
3
4
rotate_and_translate = ((0,−1,3),(1,0,1),(0,0,1)) 
rotated_translated_dino = [ 
    multiply_matrix_vector(rotate_and_translate, v)  
    for v  in dino_vectors_3d]

Figure 5.32 The original dinosaur (left) and a second dinosaur (right) that is both rotated
and translated by a single matrix
Figure 5.33 Building 3D space out of a stack of parallel planes, each looking like the x,y
plane but at different z-coordinates

Figure 5.34 An illustration of 4D spacetime, similar to how a slice of 3D space at a given
z value is a 2D plane and a slice of 4D spacetime at a given t value is a 3D space
Figure 5.35 Giving the vector (x, y, z) a fourth coordinate of 1, we can translate the
vector by (a, b, c) using this matrix.
1
2
3
4
5
6
7
8
9
10
11
12
13
def translate_3d(translation): 
    def new_function(target): 
        a,b,c = translation 
        x,y,z = target 
        matrix = ((1,0,0,a), 
            0,1,0,b), 
            (0,0,1,c), 
            (0,0,0,1)) 
        vector = (x,y,z,1) 
        x_out, y_out, z_out, _ =\ 
          multiply_matrix_vector(matrix,vector) 
        return (x_out,y_out,z_out) 
    return new_function
1
2
3

Figure 5.36 The untranslated teapot (left) and a translated teapot (right). As expected,
the translated teapot moves up and to the right, and away from our viewpoint.

Exercise 5.26: Show that the 3D “magic” matrix transformation does not work if
you move a 2D gure such as the dinosaur we have been using to the plane z = 2.
What happens instead?
Solution: Using [(x,y,2) for x,y in dino_vectors]  and applying the same
3×3 matrix, the dinosaur is translated twice as far by the vector (6, 2) instead of (3,
1). This is because the vector (0, 0, 1) is translated by (3, 1), and the transformation is
linear.
A dinosaur in the plane where z = 2 is translated twice as far by the same matrix.

Exercise 5.27: Come up with a matrix to translate the dinosaur by −2 units in the x
direction and −2 units in the y direction. Execute the transformation and show the
result.
Solution: Replacing the values 3 and 1 in the original matrix with −2 and −2, we get
The dinosaur, indeed, translates down and to the left by the vector (−2, −2).

Exercise 5.28: Show that any matrix of the form
doesn’t a|ect the z-coordinate of a 3D column vector it is multiplied by.
Solution: If the initial z-coordinate of a 3D vector is a number z, this matrix leaves
that coordinate unchanged:

Exercise 5.29−Mini Project: Find a 3×3 matrix that rotates a 2D gure in the plane z
= 1 by 45°, decreases its size by a factor of 2, and translates it by the vector (2, 2).
Demonstrate that it works by applying it to the vertices of the dinosaur.
Solution: First, let’s nd a 2×2 matrix for rotating a 2D vector by 45°:
>>> from vectors import rotate2d 
>>> from transforms import * 
>>> from math import pi 
>>> rotate_45_degrees = curry2(rotate2d)(pi/4)          ❶ 
>>> rotation_matrix = infer_matrix(2,rotate_45_degrees) 
>>> rotation_matrix 
((0.7071067811865476, -0.7071067811865475), (0.7071067811865475, 0.7071067811865476))
❶ Builds a function that executes rotate2d with an angle of 45° (or with 4 radians)
for an input 2D vector
This matrix is approximately:
Similarly, we can nd a matrix to scale by a factor of ½:
Multiplying these matrices together, we accomplish both transformations at once
with this code:
>>> from matrices import * 
>>> scale_matrix = ((0.5,0),(0,0.5)) 
>>> rotate_and_scale = matrix_multiply(scale_matrix,rotation_matrix) 
>>> rotate_and_scale 
((0.3535533905932738, -0.35355339059327373), (0.35355339059327373, 0.3535533905932738))
And this is a 3×3 matrix that translates the dinosaur by (2, 2) in the plane where z =
1:
We can plug our 2×2 rotation and scaling matrix into the top left of this matrix,
giving us the nal matrix that we want:
>>> ((a,b),(c,d)) = rotate_and_scale 
>>> final_matrix = ((a,b,2),(c,d,2),(0,0,1)) 
>>> final_matrix 
((0.3535533905932738, -0.35355339059327373, 2), (0.35355339059327373, 0.3535533905932738, 2), (0, 0, 1))
Moving the dinosaur to the plane z = 1, applying this matrix in 3D, and then
projecting back to 2D gives us the rotated, scaled, and translated dinosaur, using
only one matrix multiplication as shown here:

Exercise 5.30: The matrix in the preceding exercise rotates the dinosaur by 45° and
then translates it by (3, 1). Using matrix multiplication, build a matrix that does this
in the opposite order.
Solution: If the dinosaur is in the plane where z = 1, then the following matrix does a
rotation by 90° with no translation:
We want to translate rst and then rotate, so we multiply this rotation matrix by the
translation matrix:
This is di|erent from the other matrix, which rotates before the translation. In this
case, we see that the translation vector (3, 1) is a|ected by the 90° rotation. The new
e|ective translation is (−1, 3).

Exercise 5.31: Write a function analogous to translate_3d  called translate_4d
that uses a 5×5 matrix to translate a 4D vector by another 4D vector. Run an example
to show that the coordinates are translated.
Solution: The setup is the same, except that we lift the 4D vector to 5D by giving it a
fth coordinate of 1:
def translate_4d(translation): 
    def new_function(target): 
        a,b,c,d = translation 
        x,y,z,w = target 
        matrix = ( 
            (1,0,0,0,a), 
            (0,1,0,0,b), 
            (0,0,1,0,c), 
            (0,0,0,1,d), 
            (0,0,0,0,1)) 
        vector = (x,y,z,w,1) 
        x_out,y_out,z_out,w_out,_ = multiply_matrix_vector(matrix,vector) 
        return (x_out,y_out,z_out,w_out) 
    return new_function
We can see that the translation works (the e|ect is the same as adding the two
vectors):
>>> translate_4d((1,2,3,4))((10,20,30,40)) 
(11, 22, 33, 44)

CHAPTER 6
Figure 6.1 A linear combination of two pictures produces a new picture.
Figure 6.2 Treating 2D vectors, 3D vectors, and other objects as special cases of
vectors using inheritance
1
2
3
4
class Vec2(): 
    def __init__(self,x,y): 
        self.x = x 
        self.y = y
1
2
3
4
class Vec2(): 
    ... 
    def add(self, v2): 
        return Vec2(self.x + v2.x, self.y + v2.y)
1

1
2
3
v = Vec2(3,4) 
w = v.add(Vec2(−2,6)) 
print(w.x)
1
1
2
3
4
class Vec2(): 
    ... 
    def scale(self, scalar): 
        return Vec2(scalar * self.x, scalar * self.y)
1
2
3
4
class Vec2(): 
    ... 
    def __eq__(self,other): 
        return self.x == other.x and self.y == other.y
class Vec2(): 
    ... 
    def __add__(self, v2): 
        return self.add(v2) 
    def __mul__(self, scalar):     #1 
        return self.scale(scalar) 
    def __rmul__(self,scalar):  
        return self.scale(scalar)
>>> 3.0 * Vec2(1,0) + 4.0 * Vec2(0,1) 
<__main__.Vec2 at 0x1cef56d6390>

1
2
3
4
class Vec2(): 
    ... 
    def __repr__(self): 
        return "Vec2({},{})".format(self.x,self.y)
1
2
>>> 3.0 * Vec2(1,0) + 4.0 * Vec2(0,1) 
Vec2(3.0,4.0)
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
class Vec3(): 
    def __init__(self,x,y,z): 
        self.x = x 
        self.y = y 
        self.z = z 
    def add(self, other): 
        return Vec3(self.x + other.x, self.y + other.y, self.z + other.z) 
    def scale(self, scalar): 
        return Vec3(scalar * self.x, scalar * self.y, scalar * self.z) 
    def __eq__(self,other): 
        return (self.x == other.x  
                and self.y == other.y  
                and self.z == other.z) 
    def __add__(self, other): 
        return self.add(other) 
    def __mul__(self, scalar): 
        return self.scale(scalar) 
    def __rmul__(self,scalar): 
        return self.scale(scalar) 
    def __repr__(self): 
        return "Vec3({},{},{})".format(self.x,self.y, self.z)
1
1
2
>>> 2.0 * (Vec3(1,0,0) + Vec3(0,1,0)) 
Vec3(2.0,2.0,0.0)

1
2
def average(v1,v2): 
    return 0.5 * v1 + 0.5 * v2
1
2
3
4
5
6
7
8
9
from abc import ABCMeta, abstractmethod 
 
class Vector(metaclass=ABCMeta): 
    @abstractmethod 
    def scale(self,scalar): 
        pass 
    @abstractmethod 
    def add(self,other): 
        pass
1 TypeError: Can't instantiate abstract class Vector with abstract methods add, scale
1
2
3
4
5
6
7
8
class Vector(metaclass=ABCMeta): 
    ... 
    def __mul__(self, scalar): 
        return self.scale(scalar) 
    def __rmul__(self, scalar): 
        return self.scale(scalar) 
    def __add__(self,other): 
        return self.add(other)

1
2
3
4
5
6
7
8
9
10
11
12
class Vec2(Vector): 
    def __init__(self,x,y): 
        self.x = x 
        self.y = y 
    def add(self,other): 
        return Vec2(self.x + other.x, self.y + other.y) 
    def scale(self,scalar): 
        return Vec2(scalar * self.x, scalar * self.y) 
    def __eq__(self,other): 
        return self.x == other.x and self.y == other.y 
    def __repr__(self): 
        return "Vec2({},{})".format(self.x, self.y)
1
2
3
4
5
6
class Vector(metaclass=ABCMeta): 
    ... 
    def subtract(self,other): 
        return self.add(−1 * other) 
    def __sub__(self,other): 
        return self.subtract(other)
1
2
>>> Vec2(1,3) − Vec2(5,1) 
Vec2(−4,2)
1
2
3
4
>>> s = −3 
>>> xu, v  = Vec2(42,−10), Vec2(1.5, 8) 
>>> s * (u + v) == s * v  + s * u 
True

1
2
3
4
5
6
7
8
9
10
11
from random import uniform 
 
def random_scalar(): 
    return uniform(−10,10) 
 
def random_vec2(): 
    return Vec2(random_scalar(),random_scalar()) 
 
a = random_scalar() 
u, v  = random_vec2(), random_vec2() 
assert a * (u + v) == a * v  + a * u
1
2
3
4
>>> a, u, v 
(0.17952747449930084, 
 Vec2(0.8353326458605844,0.2632539730989293), 
 Vec2(0.555146137477196,0.34288853317521084))
1
2
3
>>> a * (u + v), a * z + a * v
(Vec2(0.24962914431749222,0.10881923333807299), 
 Vec2(0.24962914431749225,0.108819233338073))
1
2
3
4
5
6
7
8
9
10
from math import isclose 
 
def approx_equal_vec2(v,w): 
    return isclose(v.x,w.x) and isclose(v.y,w.y) 
 
for _ in range(0,100): 
    a = random_scalar() 
    u, v  = random_vec2(), random_vec2() 
    assert approx_equal_vec2(a * (u + v),  
                             a * v + a * u)
1
2
3

Exercise 6.1: Implement a Vec3  class inheriting from Vector .
Solution:
class Vec3(Vector): 
    def __init__(self,x,y,z): 
        self.x = x 
        self.y = y 
        self.z = z 
    def add(self,other): 
        return Vec3(self.x + other.x,  
                    self.y + other.y,  
                    self.z + other.z) 
    def scale(self,scalar): 
        return Vec3(scalar * self.x,  
                    scalar * self.y,  
                    scalar * self.z) 
    def __eq__(self,other): 
        return (self.x == other.x  
                and self.y == other.y  
                and self.z == other.z) 
    def __repr__(self): 
        return "Vec3({},{},{})".format(self.x, self.y, self.z)
1
2
3
4
5
6
7
8
9
10
11
12
def test(eq, a, b, u, v, w): 
    assert eq(u + v, v  + u) 
    assert eq(u + (v + w), (u + v) + w) 
    assert eq(a * (b * v), (a * b) * v) 
    assert eq(1 * v, v) 
    assert eq((a + b) * v, a * v  + b * v) 
    assert eq(a * v  + a * w, a * (v + w)) 
 
for i in range(0,100): 
    a,b = random_scalar(), random_scalar() 
    u,v,w = random_vec2(), random_vec2(), random_vec2() 
    test(approx_equal_vec2,a,b,u,v,w)
1

Exercise 6.2-Mini Project: Implement a CoordinateVector  class inheriting from
Vector  with an abstract property representing the dimension. This should save
repetitious work when implementing specic coordinate vector classes. Inheriting
from CoordinateVector  and setting the dimension to 6  should be all you need to
do to implement a Vec6  class.
Solution: We can use the dimension-independent operations add  and scale  from
chapters 2 and 3. The only thing not implemented in the following class is the
dimension, and not knowing how many dimensions we’re working with prevents us
from instantiating a CoordinateVector  :
from abc import abstractproperty 
from vectors import add, scale 
 
class CoordinateVector(Vector): 
    @abstractproperty 
    def dimension(self): 
        pass 
    def __init__(self,*coordinates): 
        self.coordinates = tuple(x for x in coordinates) 
    def add(self,other): 
        return self.__class__(*add(self.coordinates, other.coordinates)) 
    def scale(self,scalar): 
        return self.__class__(*scale(scalar, self.coordinates)) 
    def __repr__(self): 
        return "{}{}".format(self.__class__.__qualname__, self.coordinates)
Once we pick a dimension (say 6), we have a concrete class that we can instantiate:
class Vec6(CoordinateVector): 
    def dimension(self): 
        return 6
The denitions of addition, scalar multiplication, and so on are picked up from the
CoordinateVector  base class:
>>> Vec6(1,2,3,4,5,6) + Vec6(1, 2, 3, 4, 5, 6) 
Vec6(2, 4, 6, 8, 10, 12)

Exercise 6.3: Add a zero  abstract method to the Vector  class to return the zero
vector in a given vector space, as well as an implementation for the negation
operator. These are useful because we’re required to have a zero vector and
negations of any vector in a vector space.
Solution
from abc import ABCMeta, abstractmethod, abstractproperty 
 
class Vector(metaclass=ABCMeta): 
    ... 
    @classmethod             ❶ 
    @abstractproperty        ❷ 
    def zero(): 
        pass 
     
    def __neg__(self):       ❸ 
        return self.scale(−1)
❶ zero is a class method because there’s only one zero value for any vector space.
❷ It’s also an abstract property because we haven’t said what zero is yet.
❸ Special method name for overloading negation
We don’t need to implement __neg__  for any child class because its denition is
included in the parent class, based only on scalar multiplication. We do, however,
need to implement zero  for each class:
class Vec2(Vector): 
    ... 
    def zero(): 
        return Vec2(0,0)
Exercise 6.4: Write unit tests to show that the addition and scalar multiplication
operations for Vec3  satisfy the vector space properties.
Solution: Because the test function is general, we only need to supply a new equality
function for Vec3  objects and 100 random sets of inputs:
def random_vec3(): 
    return Vec3(random_scalar(),random_scalar(),random_scalar()) 
  
def approx_equal_vec3(v,w): 
    return isclose(v.x,w.x) and isclose(v.y,w.y) and isclose(v.z, w.z) 
     
for i in range(0,100): 
    a,b = random_scalar(), random_scalar() 
    u,v,w = random_vec3(), random_vec3(), random_vec3() 
    test(approx_equal_vec3,a,b,u,v,w)

Exercise 6.5: Add unit tests to check that 0 + v = v, 0 · v = 0, and -v + v = 0 for any
vector v, where again 0 is the number zero and 0 is the zero vector.
Solution: Because the zero vector is di|erent, depending on which class we’re
testing, we need to pass it in as an argument to the function:
def test(zero,eq,a,b,u,v,w): 
    ... 
    assert eq(zero + v, v)
    assert eq(0 * v, zero) 
    assert eq(−v + v, zero)
We can test any vector class with a zero  method implemented (see exercise 6.3):
for i in range(0,100): 
    a,b = random_scalar(), random_scalar() 
    u,v,w = random_vec2(), random_vec2(), random_vec2() 
    test(Vec2.zero(), approx_equal_vec2, a,b,u,v,w)
Exercise 6.6: As equality is implemented for Vec2  and Vec3 , it turns out that
Vec2(1,2) == Vec3(1,2,3)  returns True . Python’s duck typing is too forgiving
for its own good! Fix this by adding a check that classes must match before testing
vector equality.
Solution: It turns out, we need to do the check for addition as well!
class Vec2(Vector): 
    ... 
    def add(self,other): 
        assert self.__class__ == other.__class__ 
        return Vec2(self.x + other.x, self.y + other.y) 
    ... 
    def __eq__(self,other): 
        return (self.__class__ == other.__class__ 
            and self.x == other.x and self.y == other.y)
To be safe, you can add checks like this to other child classes of Vector  as well.
Exercise 6.7: Implement a __truediv__  function on Vector  that allows you to
divide vectors by scalars. You can divide vectors by a non-zero scalar by multiplying
them by the reciprocal of the scalar (1.0/scalar).
Solution:
class Vector(metaclass=ABCMeta): 
    ... 
    def __truediv__(self, scalar): 
        return self.scale(1.0/scalar)
With this implemented, you can do division like Vec2(1,2)/2 , getting back
Vec2(0.5,1.0) .

1
2
3
4
5
6
7
8
9
10
11
12
13
14
class Vec1(Vector): 
    def __init__(self,x): 
        self.x = x 
    def add(self,other): 
        return Vec1(self.x + other.x) 
    def scale(self,scalar): 
        return Vec1(scalar * self.x) 
    @classmethod 
    def zero(cls): 
        return Vec1(0) 
    def __eq__(self,other): 
        return self.x == other.x 
    def __repr__(self): 
        return "Vec1({})".format(self.x)
1
2
3
4
>>> Vec1(2) + Vec1(2) 
Vec1(4) 
>>> 3 * Vec1(1) 
Vec1(3)
1
2
3
4
5
6
7
8
9
10
11
12
13
14
class Vec0(Vector): 
    def __init__(self): 
        pass 
    def add(self,other): 
        return Vec0() 
    def scale(self,scalar): 
        return Vec0() 
    @classmethod 
    def zero(cls): 
        return Vec0() 
    def __eq__(self,other): 
        return self.__class__ == other.__class__ == Vec0 
    def __repr__(self): 
        return "Vec0()"
1
2
3
4
>>> − 3.14 * Vec0() 
Vec0() 
>>> Vec0() + Vec0() + Vec0() + Vec0() 
Vec0()

Figure 6.3 Timeline of cars posted for sale
1
2
3
4
5
6
7
8
9
10
11
class CarForSale(): 
    def __init__(self, model_year, mileage, price, posted_datetime,  
                 model, source, location, description): 
        self.model_year = model_year 
        self.mileage = mileage 
        self.price = price 
        self.posted_datetime = posted_datetime 
        self.model = model 
        self.source = source 
        self.location = location 
        self.description = description

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
from datetime import datetime 
  
class CarForSale(Vector): 
    retrieved_date = datetime(2018,11,30,12) 
    def __init__(self, model_year, mileage, price, posted_datetime,  
                 model="(virtual)",  
                         source="(virtual)", 
                 location="(virtual)", description="(virtual)"): 
        self.model_year = model_year 
        self.mileage = mileage 
        self.price = price 
        self.posted_datetime = posted_datetime 
        self.model = model 
        self.source = source 
        self.location = location 
        self.description = description 
    def add(self, other): 
        def add_dates(d1, d2): 
            age1 = CarForSale.retrieved_date − d1 
            age2 = CarForSale.retrieved_date − d2 
            sum_age = age1 + age2 
            return CarForSale.retrieved_date − sum_age 
        return CarForSale( 
            self.model_year + other.model_year, 
            self.mileage + other.mileage, 
            self.price + other.price, 
            add_dates(self.posted_datetime, other.posted_datetime) 
        ) 
    def scale(self,scalar): 
        def scale_date(d): 
            age = CarForSale.retrieved_date − d 
            return CarForSale.retrieved_date − (scalar * age) 
        return CarForSale( 
            scalar * self.model_year, 
            scalar * self.mileage, 
            scalar * self.price, 
            scale_date(self.posted_datetime) 
        ) 
    @classmethod 
    def zero(cls): 
        return CarForSale(0, 0, 0, CarForSale.retrieved_date)
1
2
3
4
5
1
2
3
4
5
6
7
8
9
>>> (cars[0] + cars[1]).__dict__ 
{'model_year': 4012, 
 'mileage': 306000.0, 
 'price': 6100.0, 
 'posted_datetime': datetime.datetime(2018, 11, 30, 3, 59), 
 'model': '(virtual)', 
 'source': '(virtual)', 
 'location': '(virtual)', 
 'description': '(virtual)'}

Figure 6.4 Graph of the functions f(x) = 0.5 · x + 3 and g(x) = sin(x)
1
2
3
4
5
6
7
8
9
10
11
>>> average_prius = sum(cars, CarForSale.zero()) * (1.0/len(cars)) 
>>> average_prius.__dict__ 
 
{'model_year': 2012.5365853658536, 
 'mileage': 87731.63414634147, 
 'price': 12574.731707317074, 
 'posted_datetime': datetime.datetime(2018, 11, 30, 9, 0, 49, 756098), 
 'model': '(virtual)', 
 'source': '(virtual)', 
 'location': '(virtual)', 
 'description': '(virtual)'}
1
2
3
4
5
def f(x): 
    return 0.5 * x + 3 
def g(x): 
    return sin(x) 
plot([f,g],−10,10)

Figure 6.5 Visualizing the sum of two functions on a graph
Figure 6.6 The function (3g) looks like the function g stretched by a factor of 3 in the y
direction.
1
2
3
4
def add_functions(f,g): 
    def new_function(x): 
        return f(x) + g(x) 
    return new_function

Figure 6.7 Adding two 5×3 matrices by adding their corresponding entries
Figure 6.8 Zooming in on a picture of my dog, Melba, until we can pick out one pixel with
red, green, and blue content (230, 105, 166, respectively)
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
class Matrix5_by_3(Vector): 
    rows = 5 
    columns = 3 
    def __init__(self, matrix): 
        self.matrix = matrix 
    def add(self, other): 
        return Matrix5_by_3(tuple( 
            tuple(a + b for a,b in zip(row1, row2)) 
            for (row1, row2) in zip(self.matrix, other.matrix) 
        )) 
    def scale(self,scalar): 
        return Matrix5_by_3(tuple( 
            tuple(scalar * x for x in row) 
            for row in self.matrix 
        )) 
    @classmethod 
    def zero(cls): 
        return Matrix5_by_3(tuple( 
            tuple(0 for j in range(0, cls.columns)) 
            for i in range(0, cls.rows) 
        ))
1
2

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
from PIL import Image 
class ImageVector(Vector): 
    size = (300,300) 
    def __init__(self,input): 
        try: 
            img = Image.open(input).\ 
                  resize(ImageVector.size) 
            self.pixels = img.getdata() 
        except: 
            self.pixels = input 
    def image(self): 
        img = Image.new('RGB', ImageVector.size) 
        img.putdata([(int(r), int(g), int(b))  
                     for (r,g,b) in self.pixels]) 
        return img 
    def add(self,img2): 
        return ImageVector([(r1+r2,g1+g2,b1+b2)  
                            for ((r1,g1,b1),(r2,g2,b2))  
                            in zip(self.pixels,img2.pixels)]) 
    def scale(self,scalar): 
        return ImageVector([(scalar*r,scalar*g,scalar*b)  
                      for (r,g,b) in self.pixels]) 
    @classmethod 
    def zero(cls): 
        total_pixels = cls.size[0] * cls.size[1] 
        return ImageVector([(0,0,0) for _ in range(0,total_pixels)]) 
    def _repr_png_(self): 
        return self.image()._repr_png_()
1
2
3
4
5
6
7
8
1 0.5 * ImageVector("inside.JPG") + 0.5 * ImageVector("outside.JPG")

Figure 6.9 The average of two images of Melba as a linear combination
Figure 6.10 Negation and scalar multiplication of an image
1 white = ImageVector([(255,255,255) for _ in range(0,300*300)])

Figure 6.11 Reversing the color of an image by subtracting it from a plain, white image
Exercise 6.8: Run the vector space unit tests with oat values for u , v , and w ,
rather than with objects inheriting from the Vector  class. This demonstrates that
real numbers are indeed vectors.
Solution: With vectors as random scalars, the number zero as the zero vector, and
math.isclose  as the equality test, the 100 random tests pass:
for i in range(0,100): 
    a,b = random_scalar(), random_scalar() 
    u,v,w = random_scalar(), random_scalar(), random_scalar() 
    test(0, isclose, a,b,u,v,w)
Exercise 6.9−Mini Project: Run the vector space unit tests for CarForSale  to
show its objects form a vector space (ignoring their textual attributes).
Solution: Most of the work is generating random data and building an approximate
equality test that handles datetimes as shown here:
from math import isclose 
from random import uniform, random, randint 
from datetime import datetime, timedelta 
 
def random_time(): 
    return CarForSale.retrieved_date − timedelta(days=uniform(0,10)) 
 
def approx_equal_time(t1, t2): 
    test = datetime.now() 
    return isclose((test-t1).total_seconds(), (test-t2).total_seconds()) 
 
def random_car(): 
    return CarForSale(randint(1990,2019), randint(0,250000),  
              27000. * random(), random_time()) 
 
def approx_equal_car(c1,c2): 
    return (isclose(c1.model_year,c2.model_year)  
            and isclose(c1.mileage,c2.mileage)  
            and isclose(c1.price, c2.price) 
            and approx_equal_time(c1.posted_datetime, c2.posted_datetime)) 
     
for i in range(0,100): 
    a,b = random_scalar(), random_scalar() 
    u,v,w = random_car(), random_car(), random_car() 
    test(CarForSale.zero(), approx_equal_car, a,b,u,v,w)

Exercise 6.10: Implement the class Function(Vector)  that takes a function of one
variable as an argument to its constructor and implement a __call__  method so
you can treat it as a function. You should be able to run plot([f,g,f+g,3*g],
−10,10) .
Solution:
class Function(Vector): 
    def __init__(self, f): 
        self.function = f 
    def add(self, other): 
        return Function(lambda x: self.function(x) + other.function(x)) 
    def scale(self, scalar): 
        return Function(lambda x: scalar * self.function(x)) 
    @classmethod 
    def zero(cls): 
        return Function(lambda x: 0) 
    def __call__(self, arg): 
        return self.function(arg) 
     
f = Function(lambda x: 0.5 * x + 3)
g = Function(sin) 
 
plot([f, g, f+g, 3*g], −10, 10)
The result of the last line is shown in this plot:
Our objects f  and g  behave like vectors, so we can add and scalar multiply them.
Because they also behave like functions, we can plot them.

Exercise 6.11-Mini Project: Testing equality of functions is di}cult. Do your best to
write a function to test whether two functions are equal.
Solution: Because we’re usually interested in well-behaved, continuous functions, it
might be enough to check that their values are close for a few random input values
as shown here:
def approx_equal_function(f,g): 
    results = [] 
    for _ in range(0,10): 
        x = uniform(−10,10) 
        results.append(isclose(f(x),g(x))) 
    return all(results)
Unfortunately, this can give us misleading results. The following returns True ,
even though the functions cannot be equal to zero:
approx_equal_function(lambda x: (x*x)/x, lambda x: x)
It turns out that computing equality of functions is an undecidable problem. That is,
it has been proved there is no algorithm that can guarantee whether any two
functions are equal.
Exercise 6.12-Mini Project: Unit test your Function  class to demonstrate that
functions satisfy the vector space properties.
Solution: It’s di}cult to test function equality, and it’s also di}cult to generate
random functions. Here, I used a Polynomial  class (that you’ll meet in the next
section) to generate some random polynomial functions. Using approx_equal
_function  from the previous mini-project, we can get the test to pass:
def random_function(): 
    degree = randint(0,5) 
    p = Polynomial(*[uniform(−10,10) for _ in range(0,degree)]) 
    return Function(lambda x: p(x)) 
 
for i in range(0,100): 
    a,b = random_scalar(), random_scalar() 
    u,v,w = random_function(), random_function(), random_function() 
    test(Function.zero(), approx_equal_function, a,b,u,v,w)

Exercise 6.13-Mini Project: Implement a class Function2(Vector)  that stores a
function of two variables like f(x, y) = x + y.
Solution: The denition is not much di|erent than the Function  class, but all
functions are given two arguments:
class Function(Vector): 
    def __init__(self, f): 
        self.function = f 
    def add(self, other): 
        return Function(lambda x,y: self.function(x,y) + other.function(x,y)) 
    def scale(self, scalar): 
        return Function(lambda x,y: scalar * self.function(x,y)) 
    @classmethod 
    def zero(cls): 
        return Function(lambda x,y: 0) 
    def __call__(self, *args): 
        return self.function(*args)
For instance, the sum of f(x, y) = x + y and g(x, y) = x − y +1 should be 2x + 1. We can
conrm this:
>>> f = Function(lambda x,y:x+y) 
>>> g = Function(lambda x,y: x-y+1) 
>>> (f+g)(3,10) 
7
Exercise 6.14: What is the dimension of the vector space of 9×9 matrices?
1. 9
2. 18
3. 27
4. 81
Solution: A 9×9 matrix has 81 entries, so there are 81 independent numbers (or
coordinates) that determine it. It, therefore, is an 81-dimensional vector space and
answer d is correct.

Exercise 6.15-Mini Project: Implement a Matrix  class inheriting from Vector
with abstract properties representing the number of rows and number of columns.
You should not be able to instantiate a Matrix  class, but you could make a
Matrix5_by_3  class by inheriting from Matrix  and explicitly specifying the
number of rows and columns.
Solution:
class Matrix(Vector): 
    @abstractproperty 
    def rows(self): 
        pass 
    @abstractproperty 
    def columns(self): 
        pass 
    def __init__(self,entries): 
        self.entries = entries 
    def add(self,other): 
        return self.__class__( 
            tuple( 
                tuple(self.entries[i][j] + other.entries[i][j] 
                        for j in range(0,self.columns())) 
                for i in range(0,self.rows()))) 
    def scale(self,scalar): 
        return self.__class__( 
            tuple( 
                tuple(scalar * e for e in row)  
                for row in self.entries)) 
    def __repr__(self): 
        return "%s%r" % (self.__class__.__qualname__, self.entries) 
    def zero(self): 
        return self.__class__( 
            tuple( 
                tuple(0 for i in range(0,self.columns()))  
                for j in range(0,self.rows())))
We can now quickly implement any class representing a vector space of matrices of
xed size, for instance, 2×2:
class Matrix2_by_2(Matrix): 
    def rows(self): 
        return 2 
    def columns(self): 
        return 2  
Then we can compute with 2×2 matrices as vectors:
>>> 2 * Matrix2_by_2(((1,2),(3,4))) + Matrix2_by_2(((1,2),(3,4))) 
Matrix2_by_2((3, 6), (9, 12))

Exercise 6.16: Unit test the Matrix5_by_3  class to demonstrate that it obeys the
dening properties of a vector space.
Solution:
def random_matrix(rows, columns): 
    return tuple( 
        tuple(uniform(−10,10) for j in range(0,columns)) 
        for i in range(0,rows) 
    ) 
 
def random_5_by_3(): 
    return Matrix5_by_3(random_matrix(5,3)) 
     
def approx_equal_matrix_5_by_3(m1,m2): 
    return all([ 
        isclose(m1.matrix[i][j],m2.matrix[i][j])  
        for j in range(0,3) 
        for i in range(0,5) 
    ]) 
     
for i in range(0,100): 
    a,b = random_scalar(), random_scalar() 
    u,v,w = random_5_by_3(), random_5_by_3(), random_5_by_3() 
    test(Matrix5_by_3.zero(), approx_equal_matrix_5_by_3, a,b,u,v,w)
Exercise 6.17-Mini Project: Write a LinearMap3d_to_5d  class inheriting from
Vector  that uses a 5×3 matrix as its data but implements __call__  to act as a
linear map from ℝ3 to ℝ5. Show that it agrees with Matrix5_by_3  in its underlying
computations and that it independently passes the dening properties of a vector
space.
Exercise 6.18−Mini Project: Write a Python function enabling you to multiply
Matrix5_by_3  objects by Vec3  objects in the sense of matrix multiplication.
Update your overloading of the *  operator for the vector and matrix classes so you
can multiply vectors on their left by either scalars or matrices.
Exercise 6.19: Convince yourself that the zero vector for the ImageVector  class
doesn’t visibly alter any image when it is added.
Solution: For any image of your choice, look at the result of ImageVector ("my_
image.jpg") + ImageVector.zero() .

Exercise 6.20: Pick two images and display 10 di|erent weighted averages of them.
These will be points on a line segment connecting the images in 270,000-
dimensional space!
Solution: I ran the following code with s = 0.1, 0.2, 0.3, ..., 0.9, 1.0:
s * ImageVector("inside.JPG") + (1-s) * ImageVector("outside.JPG")
When you put your images side-by-side, you’ll get something like this:
Several di|erent weighted averages of two images
Exercise 6.21: Adapt the vector space unit tests to images and run them. What do
your randomized unit tests look like as images?
Solution: One way to generate random images is to put random red, green, and blue
values at every pixel, for example,
def random_image(): 
    return ImageVector([(randint(0,255), randint(0,255), randint(0,255)) 
                            for i in range(0,300 * 300)])

The result is a fuzzy mess, but that doesn’t matter to us. The unit tests compare
each pixel. With an approximate equality test such as the following, we can run the
tests:
def approx_equal_image(i1,i2): 
    return all([isclose(c1,c2) 
        for p1,p2 in zip(i1.pixels,i2.pixels) 
        for c1,c2 in zip(p1,p2)]) 
 
for i in range(0,100): 
    a,b = random_scalar(), random_scalar() 
    u,v,w = random_image(), random_image(), random_image() 
    test(ImageVector.zero(), approx_equal_image, a,b,u,v,w)
Figure 6.12 Converting from an image speciØed by 270,000 numbers (left) to another
one speciØed by 900 numbers (right)

Figure 6.13 S is a subset of points (vectors) in the plane ℝ2. Is S a subspace of ℝ2?
Figure 6.14 Linear combinations of two vectors in S give us an “escape route” from S. It
cannot be a subspace of the plane.
Figure 6.15 Focusing on the line where y = 0. This is a vector space, containing all linear
combinations of its points.
Figure 6.16 Two different vectors with dotted lines, showing where all of their scalar
multiples will lie.

Figure 6.17 The span of two non-parallel vectors. Each individual vector spans a line,
but together they span more points, for instance, v + w lies on neither line.
Figure 6.18 Getting to an arbitrary point (4, 3) by a linear combination of (1, 0) and (1, 1)

Figure 6.19 A plane spanned by two 3D vectors
Figure 6.20 Three non-parallel vectors that only span a 2D space
Figure 6.21 A linear combination of z and w returns v, so the span of u, v, and w should be
no bigger than the span of z and w.

Figure 6.22 The graph of LinearFunction(−2,2)  representing f(x) = −2x + 2
1
2
3
4
5
6
7
8
9
10
11
12
13
class LinearFunction(Vector): 
    def __init__(self,a,b): 
        self.a = a 
        self.b = b 
    def add(self,v): 
        return LinearFunction(self.a + v.a, self.b + v.b) 
    def scale(self,scalar): 
        return LinearFunction(scalar * self.a, scalar * self.b) 
    def __call__(self,x): 
        return self.a * x + self.b 
    @classmethod 
    def zero(cls): 
        return LinearFunction(0,0,0)
1
2
3
4
5
ImageVector([ 
    (1,0,0), (0,0,0), (0,0,0), ..., (0,0,0), 
    (0,0,0), (0,0,0), (0,0,0), ..., (0,0,0), 
    ... 
])
1
2
3

Figure 6.23 Some of the vectors in the 1D subspace of images spanned by the gray
instance of ImageVector .
Figure 6.24 Gray pixels of varying brightness on a line. The gray pixels form a 1D
subspace of the 3D vector space of pixel values.
1
2
3
4
5
gray = ImageVector([ 
    (1,1,1), (1,1,1), (1,1,1), ..., (1,1,1), 
    (1,1,1), (1,1,1), (1,1,1), ..., (1,1,1), 
    ... 
])
1 gray = ImageVector([(1,1,1) for _ in range(0,300*300)])

Figure 6.25 A low resolution grayscale image. Each 10×10 block of pixels has the same
value.
Figure 6.26 A linear map takes any image (left) and returns a new one (right) that lies in a
900-dimensional subspace.
1
2
3
4
5
ImageVector([ 
    (r,g,b), (r,g,b), (r,g,b), ..., (r,g,b), 
    (r,g,b), (r,g,b), (r,g,b), ..., (r,g,b), 
    ... 
])

Exercise 6.22: Give a geometric argument for why the following region S of the
plane can’t be a vector subspace of the plane.
Solution: There are many linear combinations of points in this region that don’t end
up in the region. More obviously, this region cannot be a vector space because it
doesn’t include the zero vector. The zero vector is a scalar multiple of any vector (by
the scalar zero), so it must be included in any vector space or subspace.
Exercise 6.23: Show that the region of the plane where x = 0 forms a 1D vector space.
Solution: These are the vectors that lie on the y-axis and have the form (0, y) for a
real number y. Addition and scalar multiplication of vectors of the form (0, y) is the
same as for real numbers; there just happens to be an extra 0 along for the ride. We
can conclude that this is ℝ in disguise and, therefore, a 1D vector space. If you want
to be more rigorous, you can check all of the vector space properties explicitly.
Exercise 6.24: Show that three vectors (1, 0), (1, 1), and (−1, 1) are linearly
dependent by writing each one as a linear combination of the other two.
Solution:
(1, 0) = ½ · (1, 1) − ½ · (−1, 1)
(1, 1) = 2 · (1, 0) + (−1, 1)
(−1, 1) = (1, 1) − 2 · (1, 0)

Exercise 6.25: Show that you can get any vector (x, y) as a linear combination of (1,
0) and (1, 1).
Solution: We know that (1, 0) can’t contribute to the y-coordinate, so we need y
times (1, 1) as part of the linear combination. To make the algebra work, we need (x
− y) units of (1, 0):
(x, y) = (x − y) · (1, 0) + y(1, 1)
Exercise 6.26: Given a single vector v, explain why the set of all linear combinations
of v is the same as the set of all scalar multiples of v.
Solution: Linear combinations of a vector and itself reduce to scalar multiples
according to one of the vector space laws. For instance, the linear combination a · v +
b · v is equal to (a + b) · v.
Exercise 6.27: From a geometric perspective, explain why a line that doesn’t pass
through the origin is not a vector subspace (of the plane or of the 3D space).
Solution: One simple reason this cannot be a subspace is that it doesn’t contain the
origin (the zero vector). Another reason is that such a line will have two non-parallel
vectors. Their span would be the whole plane, which is much bigger than the line.
Exercise 6.28: Any two of {e1, e2, e3 } will fail to span all of ℝ3 and will instead span
2D subspaces of a 3D space. What are these subspaces?
Solution: The span of the set {e1, e2 } consists of all linear combinations a · e1 + b · e2,
or a · (1, 0, 0) + b · (0, 1, 0) = (a, b, 0). Depending on the choice of a and b, this can be
any point in the plane where z = 0, often called the x,y plane. By the same argument,
the vectors {e2, e3 } span the plane where x = 0, called the y,z plane, and the vectors
{e1, e3 } span the plane where y = 0, called the x,z plane.

Exercise 6.29: Write the vector (−5, 4) as a linear combination of (0, 3) and (−2, 1).
Solution: Only (−2, 1) can contribute to the x-coordinate, so we need to have 2.5 ·
(−2, 1) in the sum. That gets us to (−5, 2.5), so we need an additional 1.5 units on the
x-coordinate or 0.5 · (0, 3). The linear combination is
(−5, 4) = 0.5 · (0, 3) + 2.5 · (−2, 1)
Exercise 6.30−Mini Project: Are (1, 2, 0), (5, 0, 5), and (2, −6, 5) linearly
independent or linearly dependent vectors?
Solution: It’s not easy to nd, but there is a linear combination of the rst two
vectors that yields the third:
−3 · (1, 2, 0) + (5, 0, 5) = (2, −6, 5)
This means that the third vector is redundant, and the vectors are linearly
dependent. They only span a 2D subspace of 3D rather than all of 3D space.
Exercise 6.31: Explain why the linear function f(x) = ax + b is not a linear map from
the vector space ℝ to itself unless b = 0.
Solution: We can turn directly to the denition: a linear map must preserve linear
combinations. We see that f doesn’t preserve linear combinations of real numbers.
For instance, f(1+1) = 2a + b while f(1) + f(1) = (a + b) + (a + b) = 2a + 2b. This won’t
hold unless b = 0.
As an alternative explanation, we know that linear functions ℝ: → ℝ should be
representable as 1-by−1 matrices. Matrix multiplication of a 1D column vector [x ] by
a 1-by−1 matrix [ a ] gives you [ ax ]. This is an unusual case of matrix multiplication,
but your implementation from chapter 5 conrms this result. If a function ℝ: → ℝ is
going to be linear, it must agree with 1-by−1 matrix multiplication and, therefore,
be multiplication by a scalar.

Exercise 6.32: Rebuild the LinearFunction  class by inheriting from Vec2  and
implementing the __call__  method.
Solution: The data of a Vec2  are called x and y instead of a and b ; otherwise, the
functionality is the same. All you need to do is implement __call__  :
class LinearFunction(Vec2): 
    def __call__(self,input): 
        return self.x * input + self.y
Exercise 6.33: Prove (algebraically!) that the linear functions of the form f(x) = ax +
b make up a vector subspace of the vector space of all functions.
Solution: To prove this, you need to be sure a linear combination of two linear
functions is another linear function. If f(x) = ax + b and g(x) = cx + d, then r · f + s · g
returns
r · f + s · g = r · (ax + b) + s · (cx + d) = rax + b + scx + d = (ra + sc) · x + (b + d)
Because (ra + sc) and (b + d) are scalars, this has the form we want. We can conclude
that linear functions are closed under linear combinations and, therefore, that they
form a subspace.

Exercise 6.34: Find a basis for the set of 3-by−3 matrices. What is the dimension of
this vector space?
Solution: Here’s a basis consisting of nine, 3-by−3 matrices:
They are linearly independent; each contributes a unique entry to any linear
combination. They also span the space because any matrix can be constructed as a
linear combination of these; the coe}cient on any particular matrix decides one
entry of the result. Because these nine vectors provide a basis for the space of 3-
by−3 matrices, the space has nine dimensions.
Exercise 6.35−Mini Project: Implement a class QuadraticFunction(Vector)  that
represents the vector subspace of functions of the form ax2 + bx + c. What is a basis
for this subspace?
Solution: The implementation looks a lot like LinearFunction , except there are
three coe}cients instead of two, and the __call__  function has a square term:
class QuadraticFunction(Vector): 
    def __init__(self,a,b,c): 
        self.a = a 
        self.b = b 
        self.c = c 
    def add(self,v): 
        return QuadraticFunction(self.a + v.a,  
                                 self.b + v.b,  
                                 self.c + v.c) 
    def scale(self,scalar): 
        return QuadraticFunction(scalar * self.a,  
                                 scalar * self.b,  
                                 scalar * self.c) 
    def __call__(self,x): 
        return self.a * x * x + self.b * x + self.c 
    @classmethod 
    def zero(cls): 
        return QuadraticFunction(0,0,0)

We can take note that ax2 + bx + c looks like a linear combination of the set {x2, x, 1}.
Indeed, these three functions span the space, and none of these three can be written
as a linear combination of the others. There’s no way to get a x2 term by adding
together linear functions, for example. Therefore, this is a basis. Because there are
three vectors, we can conclude that this is a 3D subspace of the space of functions.
Exercise 6.36−Mini Project: I claimed that {4 x + 1, x − 2} are a basis for the set of
linear functions. Show that you can write −2x + 5 as a linear combination of these
two functions.
Solution: (1/9) · (4x + 1) − (22/9) · (x − 2) = −2x + 5. If your algebra skills aren’t too
rusty, you can gure this out by hand. Otherwise, don’t worry; we cover how to solve
tricky problems like this in the next chapter.
Exercise 6.37-Mini Project: The vector space of all polynomials is an innite-
dimensional subspace. Implement that vector space as a class and describe a basis
(which must be an innite set!).
Solution:
class Polynomial(Vector): 
    def __init__(self, *coefficients): 
        self.coefficients = coefficients 
    def __call__(self,x): 
        return sum(coefficient * x ** power  
                   for (power,coefficient)  
                   in enumerate(self.coefficients)) 
    def add(self,p): 
        return Polynomial([a + b  
                          for a,b  
                          in zip(self.coefficients,  
                                 p.coefficients)]) 
    def scale(self,scalar): 
        return Polynomial([scalar * a   
                           for a in self.coefficients]) 
        return "$ %s $" % (" + ".join(monomials)) 
    @classmethod 
    def zero(cls): 
        return Polynomial(0)
A basis for the set of all polynomials is the innite set {1, x, x2, x3, x4, ...}. Given all of
the possible powers of x at your disposal, you can build any polynomial as a linear
combination.

Exercise 6.38: I showed you pseudocode for a basis vector for the 270,000
dimensional space of images. What would the second basis vector look like?
Solution: The second basis vector could be given by putting a one in the next
possible place. It would yield a dim green pixel in the very top left of the image:
ImageVector([ 
    (0,1,0), (0,0,0), (0,0,0), ..., (0,0,0),  ❶ 
    (0,0,0), (0,0,0), (0,0,0), ..., (0,0,0),  ❷ 
    ... 
])
❶ For the second basis vector, the 1 has moved to the second possible slot.
❷ All other rows remain empty
Exercise 6.39: Write a function solid_color(r,g,b)  that returns a solid color
ImageVector  with the given red, green, and blue content at every pixel.
Solution:
def solid_color(r,g,b): 
    return ImageVector([(r,g,b) for _ in range(0,300*300)])

Exercise 6.40−Mini Project: Write a linear map that generates an ImageVector
from a 30×30 grayscale image, implemented as a 30×30 matrix of brightness values.
Then, implement the linear map that takes a 300×300 image to a 30×30 grayscale
image by averaging the brightness (average of red, green, and blue) at each pixel.
Solution:
image_size = (300,300) 
total_pixels = image_size[0] * image_size[1] 
square_count = 30                                ❶ 
square_width = 10 
  
def ij(n): 
    return (n // image_size[0], n % image_size[1]) 
  
def to_lowres_grayscale(img):                    ❷ 
  
    matrix = [ 
        [0 for i in range(0,square_count)] 
        for j in range(0,square_count) 
    ] 
    for (n,p) in enumerate(img.pixels): 
        i,j = ij(n) 
        weight = 1.0 / (3 * square_width * square_width) 
        matrix[i // square_width][ j // square_width] += (sum(p) * weight) 
    return matrix 
def from_lowres_grayscale(matrix):            ❸ 
    def lowres(pixels, ij): 
        i,j = ij 
        return pixels[i // square_width][ j // square_width] 
    def make_highres(limg): 
        pixels = list(matrix) 
        triple = lambda x: (x,x,x) 
        return ImageVector([triple(lowres(matrix, ij(n))) for n in range(0,total_pixels)]) 
    return make_highres(matrix)
❶ Indicates that we’re breaking the picture into a 30×30 grid
❷ The function takes an ImageVector and returns an array of 30 arrays of 30 values
each, giving grayscale values square by square.
❸ The second function takes a 30×30 matrix and returns an image built from 10×10
pixel blocks, having a brightness given by the matrix values.
Calling from_lowres_grayscale(to_lowres_grayscale(img))  transforms the
image img  in the way I showed in the chapter.

CHAPTER 7
Figure 7.1 Setup of the classic Asteroids arcade game
Figure 7.2 An eight-sided polygon representing an asteroid
1
2
3
4
5
6
class PolygonModel(): 
    def __init__(self,points): 
        self.points = points 
        self.rotation_angle = 0 
        self.x = 0 
        self.y = 0

Figure 7.3 The to_pixels  function maps an object from the center of our coordinate
system to the center of the PyGame screen.
1
2
3
class Ship(PolygonModel): 
    def __init__(self): 
        super().__init__([(0.5,0), (−0.25,0.25), (−0.25,-0.25)])
1
2
3
4
5
6
class Asteroid(PolygonModel): 
    def __init__(self): 
        sides = randint(5,9) 
        vs = [vectors.to_cartesian((uniform(0.5,1.0), 2*pi*i/sides))  
                for i in range(0,sides)] 
        super().__init__(vs)
1
2
1
2
3
4
5
6
7
8
ship = Ship() 
 
asteroid_count = 10 
asteroids = [Asteroid() for _ in range(0,asteroid_count)] 
 
for ast in asteroids: 
    ast.x = randint(−9,9) 
    ast.y = randint(−9,9)
1
2

Figure 7.4 The game rendered in a PyGame window
1
2
3
4
GREEN = (0, 255, 0) 
def draw_poly(screen, polygon_model, color=GREEN): 
    pixel_points = [to_pixels(x,y) for x,y in polygon_model.transformed()] 
    pygame.draw.aalines(screen, color, True, pixel_points, 10)
1
1
2
3
4
5
6
7
8
class Ship(PolygonModel): 
    ... 
   def laser_segment(self): 
        dist = 20. * sqrt(2) 
        x,y = self.transformed()[0] 
        return ((x,y),  
            (x + dist * cos(self.rotation_angle),  
             y + dist*sin(self.rotation_angle)))
1
2
3

Figure 7.5 Using trigonometry to Ønd the off-screen point where the laser beam ends
Exercise 7.1: Implement a transformed()  method on the PolygonModel  that
returns the points of the model translated by the object’s x and y attributes and
rotated by its rotation_angle  attribute.
Solution: Make sure to apply the rotation rst; otherwise, the translation vector is
rotated by the angle as well; for example,
class PolygonModel(): 
    ... 
    def transformed(self): 
        rotated = [vectors.rotate2d(self.rotation_angle, v) for v  in self.points] 
        return [vectors.add((self.x,self.y),v) for v  in rotated]
1
2
3
4
5
6
7
8
laser = ship.laser_segment() 
keys = pygame.key.get_pressed() 
    if keys[pygame.K_SPACE]: 
    draw_segment(*laser) 
 
    for asteroid in asteroids: 
        if asteroid.does_intersect(laser): 
            asteroids.remove(asteroid)
1
2
3

Exercise 7.2: Write a function to_pixels(x,y)  that takes a pair of x − and y-
coordinates in the square where −10 < x < 10 and −10 < y < 10 and maps them to the
corresponding PyGame x and y pixel coordinates, each ranging from 0 to 400.
Solution:
width, height = 400, 400 
def to_pixels(x,y): 
    return (width/2 + width * x/ 20, height/2 − height * y / 20)
Figure 7.6 The laser hitting an edge of an asteroid (left) and the corresponding system of
linear equations (right)
Figure 7.7 Vectors z = (2, 3) and v = (2, −1). Points of the form z + t · v lie on a straight line.

Figure 7.8 Given z and w, the line that connects them is r(t) = z + t · (w − u).
Figure 7.9 All (x, y) points on the line satisfy x + 2y = 8.
Figure 7.10 The points (1, 5) and (2, 3) deØne a second segment of the asteroid.

Figure 7.11 The general problem of Ønding the equation of the line that passes through
two known points
Figure 7.12 The laser passes through the points (2, 2) and (4, 4).
Figure 7.13 The laser hits the asteroid where the lines x − y = 0 and x + 2y = 8 intersect.

Figure 7.14 Framing the problem as Ønding an input vector that yields the desired
output vector
1
2
3
4
5
6
>>> import numpy as np 
>>> matrix = np.array(((1,−1),(1,2))) 
>>> output = np.array((0,8)) 
 
>>> np.linalg.solve(matrix,output) 
array([2.66666667, 2.66666667])

Figure 7.15 The vector (8/3, 8/3) when passed to the linear transformation produces
the desired output (0, 8).
Figure 7.16 The numpy.linalg.solve  function takes a matrix and a vector and
outputs the solution vector to the linear system they represent.
Figure 7.17 One segment connects u1 and u2 and the other connects points v1 and v2.
The lines extending the segments intersect, but the segments themselves don’t.
1
2
3
4
5
6
def intersection(u1,u2,v1,v2): 
    a1, b1, c1 = standard_form(u1,u2) 
    a2, b2, c2 = standard_form(v1,v2) 
    m = np.array(((a1,b1),(a2,b2))) 
    c = np.array((c1,c2)) 
    return np.linalg.solve(m,c)

Figure 7.18 Two lines that are not quite parallel intersect somewhere in the distance.
1
2
3
4
5
6
7
8
9
def do_segments_intersect(s1,s2): 
    u1,u2 = s1 
    v1,v2 = s2 
    d1, d2 = distance(*s1), distance(*s2) 
    x,y = intersection(u1,u2,v1,v2) 
    return (distance(u1, (x,y)) <= d1 and 
            distance(u2, (x,y)) <= d1 and 
            distance(v1, (x,y)) <= d2 and 
            distance(v2, (x,y)) <= d2)
1
2
3
1
2
3
4
5
6
7
class PolygonModel(): 
    ... 
    def does_intersect(self, other_segment): 
        for segment in self.segments(): 
            if do_segments_intersect(other_segment,segment): 
                return True 
        return False
1

Figure 7.19 A pair of parallel lines that never intersect and a pair of parallel lines that
are, in fact, the same line despite having different equations
1
2
3
4
5
6
7
8
>>> import numpy as np 
>>> m = np.array(((2,1),(4,2))) 
>>> v  = np.array((6,4)) 
>>> np.linalg.solve(m,v) 
Traceback (most recent call last): 
  File "<stdin>", line 1, in <module> 
... 
numpy.linalg.linalg.LinAlgError: Singular matrix

Exercise 7.3: It’s possible that u + t · v can be a line through the origin. In this case,
what can you say about the vectors u and v ?
Solution: One possibility is that u = 0 = (0, 0); in which case, the line automatically
passes through the origin. The point u + 0 · v is the origin in this case, regardless of
what v is. Otherwise, if u and v are scalar multiples, say u = s · v, then the line passes
through the origin as well because u − s · v = 0 is on the line.
Exercise 7.4: If v = 0 = (0, 0), do points of the form u + t · v represent a line?
Solution: No, regardless of the value of t, we have u + t · v = u + t · (0, 0) = u. Every
point of this form is equal to u.
Exercise 7.5: It turns out that the formula u + t · v is not unique; that is, you can pick
di|erent values of u and v to represent the same line. What is another line
representing (2, 2) + t · (−1, 3)?
Solution: One possibility is to replace v = (−1, 3) with a scalar multiple of itself such
as (2, −6). The points of the form (2, 2) + t · (−1, 3) agree with the points (2, 2) + s ·
(2, −6) when t = −2 · s. You can also replace u with any point on the line. Because (2,
2) + 1 · (−1, 3) = (1, 5) is on the line, (1, 5) + t · (2, −6) is a valid equation for the same
line as well.
1
2
3
4
5
6
7
8
9
10
11
12
def do_segments_intersect(s1,s2): 
    u1,u2 = s1 
    v1,v2 = s2 
    l1, l2 = distance(*s1), distance(*s2) 
    try: 
        x,y = intersection(u1,u2,v1,v2) 
        return (distance(u1, (x,y)) <= l1 and 
                distance(u2, (x,y)) <= l1 and 
                distance(v1, (x,y)) <= l2 and 
                distance(v2, (x,y)) <= l2) 
    except np.linalg.linalg.LinAlgError: 
        return False

Exercise 7.6: Does a · x + b · y = c represent a line for any values of a, b, and c ?
Solution: No, if both a and b are zero, the equation does not describe a line. In that
case, the formula would be 0 · x + 0 · y = c. If c = 0, this would always be true, and if c ≠
0, it would never be true. Either way, it establishes no relationship between x and y
and, therefore, it would not describe a line.
Exercise 7.7: Find another equation for the line 2x + y = 3, showing that the choices
of a, b, and c are not unique.
Solution: One example of another equation is 6x + 3y = 9. In fact, multiplying both
sides of the equation by the same non-zero number gives you a di|erent equation
for the same line.
Exercise 7.8: The equation ax + by = c is equivalent to an equation involving a dot
product of two 2D vectors: (a, b) · (x, y) = c. You could, therefore, say that a line is a
set of vectors whose dot product with a given vector is constant. What is the
geometric interpretation of this statement?
Solution: See the discussion in section 7.3.1.
Exercise 7.9: Conrm that the vectors (0, 7) and (3.5, 0) both satisfy the equation 2x
+ y = 7.
Solution: 2 · 0 + 7 = 7 and 2 · (3.5) + 0 = 7.

Exercise 7.10: Draw a graph for (3, 0) + t · (0, 1) and convert it to the standard form
using the formula.
Solution: (3, 0) + t · (0, 1) yields a vertical line, where x = 3:
The formula x = 3 is already the equation of a line in standard form, but we can
conrm this with the formulas. The rst point on our line is already given: (x1, y1) =
(3, 0). A second point on the line is (3, 0) + (0, 1) = (3, 1) = (x2, y2). We have a = y2 − y1
= 1, b = x1 − x2 = 0, and c = x1 y2 − x2y1 = 3 · 1 − 1 · 0 = 3. This gives us 1 · x + 0 · y = 3 or
simply x = 3.
Exercise 7.11: Write a Python function standard_form  that takes two vectors v 1
and v 2 and nds the line ax + by = c passing through both of them. Specically, it
should output the tuple of constants (a, b, c).
Solution: All you need to do is translate the formulas you wrote in Python:
def standard_form(v1, v2): 
    x1, y1 = v1 
    x2, y2 = v2 
    a = y2 − y1 
    b = x1 − x2 
    c = x1 * y2 − y1 * x2 
    return a,b,c

Exercise 7.12-Mini Project: For each of the four distance checks in do
_segments_intersect , nd a pair of line segments that fail one of the checks but
pass the other three checks.
Solution: To make it easier to run experiments, we can create a modied version of
do_segments_intersect  that returns a list of the True/False values returned by
each of the four checks:
def segment_checks(s1,s2): 
    u1,u2 = s1 
    v1,v2 = s2 
    l1, l2 = distance(*s1), distance(*s2) 
    x,y = intersection(u1,u2,v1,v2) 
    return [ 
        distance(u1, (x,y)) <= l1, 
        distance(u2, (x,y)) <= l1, 
        distance(v1, (x,y)) <= l2, 
        distance(v2, (x,y)) <= l2 
    ]
In general, these checks fail when one endpoint of a segment is closer to the other
endpoint than to the intersection point.
Here are some other solutions I found using segments on the lines y = 0 and x = 0,
which intersect at the origin. Each of these fails exactly one of the four checks. If in
doubt, draw them yourself to see what’s going on.
>>> segment_checks(((−3,0),(−1,0)),((0,−1),(0,1))) 
[False, True, True, True] 
>>> segment_checks(((1,0),(3,0)),((0,−1),(0,1))) 
[True, False, True, True] 
>>> segment_checks(((−1,0),(1,0)),((0,−3),(0,−1))) 
[True, True, False, True] 
>>> segment_checks(((−1,0),(1,0)),((0,1),(0,3))) 
[True, True, True, False]

Exercise 7.13: For the example laser line and asteroid, conrm the
does_intersect  function returns True . (Hint: use grid lines to nd the vertices
of the asteroid and build a PolygonModel  object representing it.)
The laser hits the asteroid.
Solution: In counterclockwise order, starting with the topmost point, the vertices
are (2, 7), (1, 5), (2, 3), (4, 2), (6, 2), (7, 4), (6, 6), and (4, 6). We can assume the
endpoints of the laser beam are (1, 1) and (7, 7):
>>> from asteroids import PolygonModel 
>>> asteroid = PolygonModel([(2,7), (1,5), (2,3), (4,2), (6,2), (7,4), (6,6), (4,6)]) 
>>> asteroid.does_intersect([(0,0),(7,7)]) 
True
This conrms the laser hits the asteroid! By contrast, a shot directly up the y-axis
from (0, 0) to (0, 7) does not hit:
>>> asteroid.does_intersect([(0,0),(0,7)]) 
False

Exercise 7.14: Write a does_collide(other_polygon)  method to decide whether
the current PolygonModel  object collides with another other_polygon  by
checking whether any of the segments that dene the two are intersecting. This
could help us decide whether an asteroid has hit the ship or another asteroid.
Solution: First, it’s convenient to add a segments()  method to PolygonModel  to
avoid duplication of the work of returning the (transformed) line segments that
constitute the polygon. Then, we can check every segment of the other polygon to
see if it returns true for does_intersect  with the current one:
class PolygonModel(): 
    ... 
    def segments(self): 
        point_count = len(self.points) 
        points = self.transformed() 
        return [(points[i], points[(i+1)%point_count]) 
                for i in range(0,point_count)] 
 
    def does_collide(self, other_poly): 
        for other_segment in other_poly.segments(): 
            if self.does_intersect(other_segment): 
                return True 
        return False
We can test this by building some squares that should and shouldn’t overlap, and
seeing whether the does_collide  method correctly detects which is which.
Indeed, it does:
>>> square1 = PolygonModel([(0,0), (3,0), (3,3), (0,3)]) 
>>> square2 = PolygonModel([(1,1), (4,1), (4,4), (1,4)]) 
>>> square1.does_collide(square2) 
True 
>>> square3 = PolygonModel([(−3,−3),(−2,−3),(−2,−2),(−3,−2)]) 
>>> square1.does_collide(square3) 
False

Exercise 7.15-Mini Project: We can’t pick a vector w so that the following system
has a unique solution v.
Find a vector w such that there are innitely many solutions to the system; that is,
innitely many values of v that satisfy the equation.
Solution: If w = (0, 0), for example, the two lines represented by the system are
identical. (Graph them if you are skeptical!) The solutions have the form v = (a, −2a)
for any real number a. Here are some of the innite possibilities for v when w = (0,
0):
Figure 7.20 A unique line passing through a given point and perpendicular to a given
vector

Figure 7.21 The vector (x − x0, y − y0) is parallel to the line and, therefore, perpendicular
to (a, b).
Figure 7.22 A plane parallel to the vector (a, b, c) passes through the point (x0, y0, z0 ).
Figure 7.23 Two non-parallel planes intersect along a line.

Figure 7.24 Two non-parallel planes intersect along a line.
Figure 7.25 Three planes plotted in Matplotlib

Figure 7.26 A system of m linear equations with n unknowns written in matrix form
1
2
3
4
>>> matrix = np.array(((1,1,−1),(0,2,−1),(1,0,1)))
>>> vector = np.array((−1,3,2)) 
>>> np.linalg.solve(matrix,vector) 
array([−1., 3., 3.])

Exercise 7.16: What’s the equation for a line that passes through (5, 4) and that is
perpendicular to (−3, 3)?
Solution: Here’s the set up:
For every point (x, y) on the line, the vector (x − 5, y − 4) is parallel to the line and,
therefore, perpendicular to (−3, 3). That means that the dot product (x − 5, y − 4) ·
(−3, 3) is zero for any (x, y) on the line. This equation expands to −3x + 15 + 3y − 12 =
0, which rearranges to give −3x + 3y = −3. We can divide both sides by −3 to get a
simpler, equivalent equation: x − y = 1.

Exercise 7.17-Mini Project: Consider a system of two linear equations in 4D:
x1 + 2x2 + 2x3 + x4 = 0
x1 − x4 = 0
Explain algebraically (rather than geometrically) why the solutions form a vector
subspace of 4D.
Solution: We can show that if (a1, a2, a3, a4) and (b1, b2, b3, b4) are two solutions,
then a linear combination of those is a solution as well. That would imply that the
solution set contains all linear combinations of its vectors, making it a vector
subspace.
Let’s start with the assumption that (a1, a2, a3, a4) and (b1, b2, b3, b4) are solutions to
both linear equations, which explicitly means:
a1 + 2a2 + 2a3 + a4 = 0
b1 + 2b2 + 2b3 + b4 = 0
a1 − a4 = 0
b1 − b4 = 0
Picking scalars c and d, the linear combination c(a1, a2, a3, a4) + d(b1, b2, b3, b4) is
equal to (ca1 + db1, ca2 + db2, ca3 + db3, ca4 + db4). Is this a solution to the two
equations? We can nd out by plugging the four coordinates in for x1, x2, x3, and x4.
In the rst equation,
x1 + 2x2 + 2x3 + x4
becomes
(ca1 + db1) + 2(ca2 + db2) + 2(ca3 + db3) + (ca4 + db4)
That expands to give us
ca1 + db1 + 2ca2 + 2db2 + 2ca3 + 2db3 + ca4 + db4
which rearranges to
c(a1 + 2a2 +2a3 + a4) + d(b1 + 2b2 + 2b3 + b4)

Because a1 + 2a2 + 2a3 + a4 and b1 + 2b2 + 2b3 + b4 are both zero, this expression is
zero:
c(a1 + 2a2 + 2a3 + a4) + d(b1 + 2b2 + 2b3 + b4) = c · 0 + d · 0 = 0
That means the linear combination is a solution to the rst equation. Similarly,
plugging the linear combination into the second equation, we see it’s a solution to
that equation as well:
(ca1 + db1) − (ca4 + db4) = c(a1 − a4) + d(b1 − b4) = c · 0 + d · 0 = 0
Any linear combination of any two solutions is also a solution, so the solution set
contains all of its linear combinations. That means the solution set is a vector
subspace of 4D.
Exercise 7.18: What is the standard form equation for a plane that passes through
the point (1, 1, 1) and is perpendicular to the vector (1, 1, 1)?
Solution: For any point (x, y, z) in the plane, the vector (x − 1, y − 1, z − 1) is
perpendicular to (1, 1, 1). That means that the dot product (x − 1, y − 1, z − 1) · (1, 1, 1)
is zero for any x, y, and z values giving a point in the plane. This expands to give us (x
− 1) + (y − 1) + (z − 1) = 0 or x + y + z = 3, the standard form equation for the plane.

Exercise 7.19−Mini Project: Write a Python function that takes three 3D points as
inputs and returns the standard form equation of the plane that they lie in. For
instance, if the standard form equation is ax + by + cz = d, the function could return
the tuple (a, b, c, d).
Hint: Di|erences of any pairs of the three vectors are parallel to the plane, so cross
products of the di|erences are perpendicular.
Solution: If the points given are p1, p2, and p3, then the vector di|erences like p3 − p1
and p2 − p1 are parallel to the plane. The cross product (p2 − p1) × (p3 − p1) is then
perpendicular to the plane. (All is well as long as the points p1, p2, and p3 form a
triangle, so the di|erences are not parallel.) With a point in the plane (for instance,
p1) and a perpendicular vector, we can repeat the process of nding the standard
form of the solution as in the previous two exercises:
from vectors import * 
 
def plane_equation(p1,p2,p3): 
    parallel1 = subtract(p2,p1) 
    parallel2 = subtract(p3,p1) 
    a,b,c = cross(parallel1, parallel2) 
    d = dot((a,b,c), p1) 
    return a,b,c,d
For example, these are three points from the plane x + y + z = 3 from the preceding
exercise:
>>> plane_equation((1,1,1), (3,0,0), (0,3,0)) 
(3, 3, 3, 9)
The result is (3, 3, 3, 9), meaning 3x + 3y + 3z = 9, which is equivalent to x + y + z = 3.
That means we got it right!

Exercise 7.20: How many total constants aij are in the following matrix equation?
How many equations are there? How many unknowns? Write the full matrix
equation (no dots) and the full system of linear equations (no dots).
An abbreviated system of linear equations in matrix form
Solution: To be clear, we can write out the full matrix equation rst:
The unabbreviated version of the matrix equation
In total, there are 5 · 7 = 35 entries in this matrix and 35 aij constants on the left-
hand side of the equations in the linear system. There are 7 unknown variables: x1,
x2, ..., x7 and 5 equations (one per row of the matrix). You can get the full linear
system by carrying out the matrix multiplication:
a11x1 + a12x2 + a13x3 + a14x4 + a15x5 + a16x6 + a17x7 = b1
a21x1 + a22x2 + a23x3 + a24x4 + a25x5 + a26x6 + a27x7 = b2
a31x1 + a32x2 + a33x3 + a34x4 + a35x5 + a36x6 + a37x7 = b3
a41x1 + a42x2 + a43x3 + a44x4 + a45x5 + a46x6 + a47x7 = b4
a51x1 + a52x2 + a53x3 + a54x4 + a55x5 + a56x6 + a57x7 = b5
The full system of linear equations represented by this matrix equation
You can see why we avoid this tedious writing with abbreviations!

Exercise 7.21: Write the following linear equation without summation shorthand.
Geometrically, what does the set of solutions look like?
Solution: The left-hand side of this equation is a sum of terms of the form xi for i,
ranging from 1 to 3. That gives us x1 + x2 + x3 = 1. This is the standard form of a linear
equation in three variables, so its solutions form a plane in 3D space.
Exercise 7.22: Sketch three planes, none of which are parallel and do not have a
single point of intersection. (Better yet, nd their equations and graph them!)
Solution: Here are three planes: z + y = 0, z − y = 0, and z = 3 and the graph:
Three non-parallel planes that don’t share an intersection point
I’ve drawn the intersections of the three pairs of planes, which are parallel lines.
Because these lines never meet, there is no single point of intersection for all three
planes. This is like the example you saw in chapter 6: three vectors can be linearly
dependent even when no pair among them is parallel.

Exercise 7.23: Suppose we have m linear equations and n unknown variables. What
do the following values of m and n say about whether there is a unique solution?
1. m = 2, n = 2
2. m = 2, n = 7
3. m = 5, n = 5
4. m = 3, n = 2
Solution:
1. With two linear equations and two unknowns, there can be a unique
solution. The two equations represent lines in the plane, and they
will intersect at a unique point unless they are parallel.
2. With two linear equations and seven unknowns, there cannot be a
unique solution. Assuming the 6D hyperplanes dened by these
equations are not parallel, there will be a 5D space of solutions.
3. With ve linear equations and ve unknowns, there can be a unique
solution, as long as the equations are independent.
4. With three linear equations and two unknowns, there can be a
unique solution, but it requires some luck. This would mean that
the third line happens to pass through the intersection point of the
rst two lines, which is unlikely but possible.
Three lines in the plane that happen to intersect at a point

Exercise 7.24: Find 3 planes whose intersection is a single point, 3 planes whose
intersection is a line, and 3 planes whose intersection is a plane.
Solution: The planes z − y = 0, z + y = 0, and z + x = 0 intersect at the single point (0,
0, 0). Most randomly selected planes will intersect at a unique point like this.
Three planes intersecting at a single point

The planes z − y = 0, z + y = 0, and z = 0 intersect on a line, specically the x-axis. If
you play with these equations, you’ll nd both y and z are constrained to be zero,
but x doesn’t even appear, so it has no constraints. Any vector (x, 0, 0) on the x-axis
is, therefore, a solution.
Three planes whose intersection points form a line
Finally, if all three equations represent the same plane, then that whole plane is a set
of solutions. For instance, z − y = 0, 2z − 2y = 0, and 3z − 3y = 0 all represent the same
plane.
Three identical planes overlaid; their set of solutions is the whole plane.

Exercise 7.25: Without using Python, what is the solution of the system of linear
equations in 5D? x5 = 3, x2 = 1, x4 = −1, x1 = 0, and x1 + x2 + x3 = −2? Conrm the
answer with NumPy.
Solution: Because four of these linear equations specify the value of a coordinate,
we know the solution has the form (0,1, x3, −1,3). We need to do some algebra using
the nal equation to nd out the value of x3. Because x1 + x2 + x3 = −2, we know 0 + 1
+ x3 = −2, and x3 must be −3. The unique solution point is, therefore, (0, 1, −3, −1, 3).
Converting this system to matrix form, we can solve it with NumPy to conrm we
got it right:
>>> matrix = np.array(((0,0,0,0,1),(0,1,0,0,0),(0,0,0,1,0),(1,0,0,0,0),(1,1,1,0,0))) 
>>> vector = np.array((3,1,−1,0,−2)) 
>>> np.linalg.solve(matrix,vector) 
array([ 0., 1., −3., −1., 3.])
Exercise 7.26−Mini Project: In any number of dimensions, there is an identity
matrix that acts as the identity map. That is, when you multiply the n -dimensional
identity matrix I by any vector v, you get the same vector v as a result; therefore, I v
= v .
This means that I v = w is an easy system of linear equations to solve: one possible
answer for v is v = w. The idea of this mini-project is that you can start with a system
of linear equations, a v = w, and multiply both sides by another matrix B such that
(BA) = I. If that is the case, then you have (BA)v = B w and I v = B w or v = B w. In other
words, if you have a system a v = w, and a suitable matrix B, then B w is the solution
to your system. This matrix B is called the inverse matrix of a.
Let’s look again at the system of equations we solved in section 7.3.2:
Use the NumPy function numpy.linalg.inv(matrix) , which returns the inverse of
the matrix it is given to nd the inverse of the matrix on the left-hand side of the
equation. Then, multiply both sides by this matrix to nd the solution to the linear
system. Compare your results with the results we got from NumPy’s solver.
Hint: You might also want to use NumPy’s built-in matrix multiplication routine,
numpy.matmul , to make computations simpler.

Solution: First, we can compute the inverse of the matrix using NumPy:
>>> matrix = np.array(((1,1,−1),(0,2,−1),(1,0,1))) 
>>> vector = np.array((−1,3,2)) 
>>> inverse = np.linalg.inv(matrix) 
>>> inverse 
array([[ 0.66666667, -0.33333333,  0.33333333], 
       [-0.33333333,  0.66666667,  0.33333333], 
       [-0.66666667,  0.33333333,  0.66666667]])
The product of the inverse matrix with the original matrix gives us the identity
matrix, having 1’s on the diagonal and 0’s elsewhere, albeit with some numerical
error:
>>> np.matmul(inverse,matrix) 
array([[ 1.00000000e+00,  1.11022302e−16, −1.11022302e−16], 
       [ 0.00000000e+00,  1.00000000e+00,  0.00000000e+00], 
       [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00]])
The trick is to multiply both sides of the matrix equation by this inverse matrix.
Here I’ve rounded the values in the inverse matrix for the sake of readability. We
already know that the rst product on the left is a matrix and its inverse, so we can
simplify accordingly:
Multiplying both sides of the system by the inverse matrix and simplifying
This gives us an explicit formula for the solution (x, y, z); all we need to do is to carry
out the matrix multiplication. It turns out numpy.matmul  also works for matrix
vector multiplication:
>>> np.matmul(inverse, vector) 
array([−1., 3., 3.])
This is the same as the solution we got earlier from the solver.

Figure 7.27 Writing (4, 2) as a linear combination of u1 = (1, 1) and u2 = (−1, 1)
Figure 7.28 There is a 2D space of values (c, d), where (c, d) = (3, 1) and yields the linear
combination 3u1 + 1u2 = (2, 4).
Figure 7.29 The point (c, d) = (3, −1) satisØes both c + d = 2 and c − d = 4. Therefore, it
describes the linear combination we were looking for.

1
2
3
4
5
>>> import numpy as np 
>>> xw = np.array((1,3,−7)) 
>>> xa = np.array(((1,−1,0),(0,−1,−1),(1,0,2))) 
>>> np.linalg.solve(a,w) 
array([ 3., 2., −5.])

Exercise 7.27: How can you write the vector (5, 5) as a linear combination of (10, 1)
(3, 2)?
Solution: This is equivalent to asking what numbers a and b satisfy the equation
or what vector (a, b) satises the matrix equation:
We can nd a solution with NumPy:
>>> matrix = np.array(((10,3),(1,2))) 
>>> vector = np.array((5,5)) 
>>> np.linalg.solve(matrix,vector) 
array([-0.29411765, 2.64705882])
This means the linear combination (which you can check!) is as follows:

Exercise 7.28: Write the vector (3, 0, 6, 9) as a linear combination of the vectors (0,
0, 1, 1), (0, −2, −1, −1), (1, −2, 0, 2), and (0, 0, −2, 1).
Solution: The linear system to solve is
where the columns of the 4-by−4 matrix are the vectors we want to build the linear
combination from. NumPy gives us the solution to this system:
>>> matrix = np.array(((0, 0, 1, 0), (0, −2, −2, 0), (1, −1, 0, −2), (1, −1, 2, 1))) 
>>> vector = np.array((3,0,6,9)) 
>>> np.linalg.solve(matrix,vector) 
array([ 1., −3., 3., −1.])
This means that the linear combination is

CHAPTER 8
Figure 8.1 Schematic diagram of a pump lifting oil from a well and pumping it into a tank
Figure 8.2 Finding the Ùow rate over time from the volume using the derivative and
then Ønding the volume over time from the Ùow rate using the integral

Figure 8.3 A plot of the volume  function shows the volume of oil in the tank over time.
1
2
def average_flow_rate(v,t1,t2): 
    return (v(t2) - v(t1))/(t2 - t1)
>>> volume(4) 
3.3 
>>> volume(9) 
5.253125

Figure 8.4 A secant line connects the starting and ending points on the volume graph.
Figure 8.5 We calculate the slope of a secant line in the same way as the average rate of
change of the volume  function.
>>> average_flow_rate(volume,4,9) 
0.390625

Figure 8.6 A different volume  function shows that the volume in the tank decreases
over time.
Figure 8.7 Two points on a graph that deØne a secant line with a negative slope
1
2
>>> average_flow_rate(decreasing_volume,0,4) 
-0.8

Exercise 8.1: Suppose you start a road trip at noon when your odometer reads 77,641
miles, and you end your road trip at 4:30 in the afternoon with your odometer
reading 77,905 miles. What was your average speed during the trip?
Solution: The total distance traveled is 77,905 − 77,641 = 264 miles covered over 4.5
hrs. The average speed is 264 mi / 4.5 hr or about 58.7 mph.
Exercise 8.2: Write a Python function secant_line(f,x1,x2)  that takes a
function f(x)  and two values, x1  and x2 , and that returns a new function
representing a secant line over time. For instance, if you ran line  =  secant_line
(f,x1,x2) , then line(3)  would give you the y value of the secant line at x = 3.
Solution:
def secant_line(f,x1,x2): 
    def line(x): 
        return f(x1) + (x-x1) * (f(x2)-f(x1))/(x2-x1) 
    return line
Exercise 8.3: Write a function that uses the code from the previous exercise to plot a
secant line of a function f  between two given points.
Solution:
def plot_secant(f,x1,x2,color='k'): 
    line = secant_line(f,x1,x2) 
    plot_function(line,x1,x2,c=color) 
    plt.scatter([x1,x2],[f(x1),f(x2)],c=color)

Figure 8.8 Different secant lines on the volume graph have different slopes, indicating
that the Ùow rate is changing.
1
2
[(0,...), (1,...), (2,...), (3,...), (4,...), (5,...), (6,...), (7,...), 
     (8,...), (9,...)]
1
2
3
4
>>> import numpy as np 
>>> np.arange(0,10,0.5) 
array([0. , 0.5, 1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5, 5. , 5.5, 6. , 
       6.5, 7. , 7.5, 8. , 8.5, 9. , 9.5])
1
2
3
def interval_flow_rates(v,t1,t2,dt): 
    return [(t,average_flow_rate(v,t,t+dt)) 
                for t in np.arange(t1,t2,dt)]
1

Figure 8.9 A plot of the average Ùow rate in each hour
1
2
3
4
5
6
7
8
9
10
11
>>> interval_flow_rates(volume,0,10,1) 
[(0, 0.578125), 
 (1, 0.296875), 
 (2, 0.109375), 
 (3, 0.015625), 
 (4, 0.015625), 
 (5, 0.109375), 
 (6, 0.296875), 
 (7, 0.578125), 
 (8, 0.953125), 
 (9, 1.421875)]
1
2
3
4
5
def plot_interval_flow_rates(volume,t1,t2,dt): 
    series = interval_flow_rates(volume,t1,t2,dt) 
    times = [t for (t,_) in series] 
    rates = [q for (_,q) in series] 
    plt.scatter(times,rates)

Figure 8.10 A plot of the average Ùow rate in each hour (dots) and the actual Ùow rate
(smooth curve) per hour
Figure 8.11 The graph of the Ùow rate over time compared with the average Ùow rates
at 20-min intervals

Exercise 8.4: Plot the decreasing_volume  ow rates over time at 0.5-hr intervals.
When is its ow rate the lowest? That is, when is oil leaving the tank at the fastest
rate?
Solution: Running plot_interval_flow_rates(decreasing_volume,0,
10,0.5) , we can see that the rate is the lowest (most negative) just before the 5-hr
mark.

Exercise 8.5: Write a linear_volume_function  and plot the ow rate over time to
show that it is constant.
Solution: A linear_volume_function(t)  has the form V(t) = at + b for the
constants a and b. For instance,
def linear_volume_function(t): 
    return 5*t + 3 
 
plot_interval_flow_rates(linear_volume_function,0,10,0.25)
This graph shows that for a linear volume function, the ow rate is constant over
time.

Figure 8.12 Zooming in on the 1-hr window around t = 1 hr
Figure 8.13 Two secant lines around t = 1 hr have similar slopes, meaning that the Ùow
rate doesn’t change much during this time interval.

Figure 8.14 The volume graph looks nearly straight at a smaller interval around t = 1 hr.
Figure 8.15 Zooming in even closer, the volume graph is visually indistinguishable from
a straight line.

Figure 8.16 A line with slope 0.421875 is the best approximation of the volume function
at time t = 1 hr.
1
2
3
4
5
6
7
8
9
10
11
12
>>> average_flow_rate(volume,0.5,1.5) 
0.42578125 
>>> average_flow_rate(volume,0.9,1.1) 
0.4220312499999988 
>>> average_flow_rate(volume,0.99,1.01) 
0.42187656249998945 
>>> average_flow_rate(volume,0.999,1.001) 
0.42187501562509583 
>>> average_flow_rate(volume,0.9999,1.0001) 
0.42187500015393936 
>>> average_flow_rate(volume,0.99999,1.00001) 
0.4218750000002602
1
2
>>> flow_rate(1) 
0.421875

Secant line interval
Secant line slope
0.5 to 1.5
0.42578125
0.9 to 1.1
0.4220312499999988
0.99 to 1.01
0.42187656249998945
0.999 to 1.001
0.42187501562509583
1
2
3
4
5
6
7
8
9
10
11
12
def instantaneous_flow_rate(v,t,digits=6): 
    tolerance = 10 ** (−digits) 
    h = 1 
    approx = average_flow_rate(v,t-h,t+h) 
    for i in range(0,2*digits): 
        h = h / 10 
        next_approx = average_flow_rate(v,t-h,t+h) 
        if abs(next_approx − approx) < tolerance: 
            return round(next_approx,digits) 
        else: 
            approx = next_approx 
    raise Exception("Derivative did not converge")
1
2
>>> instantaneous_flow_rate(volume,1) 
0.421875
1
2
3
4
def get_flow_rate_function(v): 
    def flow_rate_function(t): 
        instantaneous_flow_rate(v,t) 
    return flow_rate_function

Figure 8.17 Plotting the flow_rate  function alongside the get_flow_rate
function shows that the graphs are indistinguishable.
Figure 8.18 You can think of the derivative as a machine that takes a function and
returns another function, measuring the rate of change of the input function.
1
2
plot_function(flow_rate,0,10) 
plot_function(get_flow_rate_function(volume),0,10)

Figure 8.19 The “derivative with respect to x” as an operation that takes a function and
returns a new function
Exercise 8.6: Conrm that the graph of the volume  function is not a straight line on
the interval from 0.999 hrs to 1.001 hrs.
Solution: If it were a straight line, it would equal its secant line at every point.
However, the secant line from 0.999 hrs to 1.001 hrs has a di|erent value than the
volume  function at t = 1 hr:
>>> volume(1) 
2.878125 
>>> secant_line(volume,0.999,1.001)(1) 
2.8781248593749997
Exercise 8.7: Approximate the slope of a tangent line to the volume graph at t = 8 by
computing the slopes of smaller and smaller secant lines around t = 8.
Solution:
>>> average_flow_rate(volume,7.9,8.1) 
0.7501562500000007 
>>> average_flow_rate(volume,7.99,8.01) 
0.750001562499996 
>>> average_flow_rate(volume,7.999,8.001) 
0.7500000156249458 
>>> average_flow_rate(volume,7.9999,8.0001) 
0.7500000001554312
It appears that the instantaneous rate of change at t = 8 is 0.75 bbl/hr.

Exercise 8.8: For the sign  function dened in Python, convince yourself that it
doesn’t have a derivative at x = 0:
def sign(x): 
    return x/ abs(x)
Solution: On smaller and smaller intervals, the slope of a secant line gets bigger and
bigger rather than converging on a single number:
>>> average_flow_rate(sign,-0.1,0.1) 
10.0 
>>> average_flow_rate(sign,-0.01,0.01) 
100.0 
>>> average_flow_rate(sign,-0.001,0.001) 
1000.0 
>>> average_flow_rate(sign,−0.000001,0.000001) 
1000000.0
This is because the sign  function jumps from −1 to 1 immediately at x = 0, and it
doesn’t look like a straight line when you zoom in on it.
1
2
def small_volume_change(q,t,dt): 
    return q(t) * dt
1
2
3
4
>>> small_volume_change(flow_rate,2,1) 
0.1875 
>>> volume(3) − volume(2) 
0.109375

1
2
3
4
>>> small_volume_change(flow_rate,2,0.01) 
0.001875 
>>> volume(2.01) − volume(2) 
0.0018656406250001645
1
2
3
def volume_change(q,t1,t2,dt): 
    return sum(small_volume_change(q,t,dt) 
               for t in np.arange(t1,t2,dt))
1
2
3
4
>>> volume_change(flow_rate,0,10,0.1) 
4.32890625 
>>> volume(10) − volume(0) 
4.375
1
2
>>> volume_change(flow_rate,0,10,0.0001) 
4.3749531257812455

Figure 8.20 Plotting the points used to calculate
volume_change(flow_rate,0,10,1)
Figure 8.21 If we assumed Ùow rate were constant on each interval, its graph would
look like a staircase going down and back up.

Figure 8.22 The overall change in volume as a sum of the areas of 10 rectangles

Figure 8.23 The volume as a sum of the area of 30 rectangles (top) or 100 rectangles
(bottom) under the Ùow rate graph (Øgure 8.20)
Exercise 8.9: Approximately how much oil is added to the tank in the rst 6 hrs? In
the last 4 hrs? During which time interval is more added?
Solution: In the rst 6 hrs, about 1.13 bbls of oil are pumped into the tank, which is
less than the roughly 3.24 bbls pumped into the tank in the last 4 hrs:
>>> volume_change(flow_rate,0,6,0.01) 
1.1278171874999996 
>>> volume_change(flow_rate,6,10,0.01) 
3.2425031249999257

Figure 8.24 A plot of the output of approximate _volume_function (jagged line)
alongside the original volume  function (smooth line)
1
2
def approximate_volume(q,v0,dt,T): 
    return v0 + volume_change(q,0,T,dt)
1
2
3
4
def approximate_volume_function(q,v0,dt): 
    def volume_function(T): 
        return approximate_volume(q,v0,dt,T) 
    return volume_function
1
2
plot_function(approximate_volume_function(flow_rate,2.3,0.5),0,10) 
plot_function(volume,0,10)

Figure 8.25 The volume in the tank at 4 hrs using a Riemann sum
Figure 8.26 The volume in the tank at 8 hrs using a Riemann sum

Figure 8.27 The two previous results shown on the approximate volume graph
1
2
>>> np.arange(0,3.9,0.5) 
array([0. , 0.5, 1. , 1.5, 2. , 2.5, 3. , 3.5])
1
2
plot_function(approximate_volume_function(flow_rate,2.3,0.1),0,10) 
plot_function(volume,0,10)

Figure 8.28 With dt = 0.1 hr, the graphs nearly match.
Figure 8.29 With 0.01-hr timesteps, the graph of the approximate volume  function is
indistinguishable from the actual volume  function.
1
2
plot_function(approximate_volume_function(flow_rate,2.3,0.01),0,10) 
plot_function(volume,0,10)

Figure 8.30 The deØnite integral takes the rate of change (derivative) of a function and a
speciØed interval and recovers the cumulative change in the function on that interval.
1
2
3
4
5
6
7
8
9
10
11
12
13
14
def get_volume_function(q,v0,digits=6): 
    def volume_function(T): 
        tolerance = 10 ** (−digits) 
        dt = 1 
        approx = v0 + volume_change(q,0,T,dt) 
        for i in range(0,digits*2): 
            dt = dt / 10 
            next_approx = v0 + volume_change(q,0,T,dt) 
            if abs(next_approx − approx) < tolerance: 
                return round(next_approx,digits) 
            else: 
                approx = next_approx 
        raise Exception("Did not converge!") 
    return volume_function
1
2
3
>>> xv  = get_volume_function(flow_rate,2.3,digits=3) 
>>> v(1) 
2.878
1
2
3
>>> xv  = get_volume_function(flow_rate,2.3,digits=6) 
>>> v(1) 
2.878125


CHAPTER 9
1
2
3
4
5
6
7
8
class PolygonModel(): 
    def __init__(self,points): 
        self.points = points 
        self.angle = 0 
        self.x = 0 
        self.y = 0 
        self.vx = 0 
        self.vy = 0
1
2
1
2
3
4
5
6
7
8
class Asteroid(PolygonModel): 
    def __init__(self): 
        sides = randint(5,9) 
        vs = [vectors.to_cartesian((uniform(0.5,1.0), 2 * pi * i / sides)) 
                for i in range(0,sides)] 
        super().__init__(vs) 
        self.vx = uniform(−1,1) 
        self.vy = uniform(−1,1)
1
1
2
3
4
5
6
7
class PolygonModel(): 
    ... 
    def move(self, milliseconds): 
        dx, dy = (self.vx * milliseconds / 1000.0,  
                  self.vy * milliseconds / 1000.0 
        self.x, self.y = vectors.add((self.x,self.y),  
                                     (dx,dy))
1
2

Figure 9.1 Keeping all objects’ coordinates between −10 and 10 by “teleporting” the
objects across the screen when they are about to leave it
class PolygonModel(): 
    ... 
    def move(self, milliseconds): 
        dx, dy = (self.vx * milliseconds / 1000.0,  
                  self.vy * milliseconds / 1000.0) 
        self.x, self.y = vectors.add((self.x,self.y),  
                                     (dx,dy)) 
        if self.x < −10: 
            self.x += 20      #1 
        if self.y < −10:      #2 
            self.y += 20 
        if self.x > 10: 
            self.x -= 20 
        if self.y > 10: 
            self.y -=20
milliseconds = clock.get_time()   #1 
for ast in asteroids: 
    ast.move(milliseconds)        #2

Figure 9.2 With the preceding code included, each asteroid moves with a random,
constant velocity.
Exercise 9.1: An asteroid has the velocity vector v = (vx, vy) = (−3, 1). Which direction
is it moving on the screen?
Up and to the right
Up and to the left
Down and to the left
Down and to the right
Solution: Because x'(t) = vx = −3 at this moment in time, the asteroid is moving in
the negative x direction, or to the left. Because y'(t) = vy = 1, the asteroid is moving in
the positive y direction at this moment, which is upward. Therefore, answer b is
correct.

Figure 9.3 Schematic of how a rocket propels itself
Figure 9.4 Using trigonometry to Ønd the components of acceleration from its
magnitude and direction
1 acceleration = 3
1
2
3
4
5
6
7
8
9
while not done: 
    ... 
        if keys[pygame.K_UP]: 
            ax = acceleration * cos(ship.rotation_angle) 
            ay = acceleration * sin(ship.rotation_angle) 
            ship.vx += ax * milliseconds/1000 
            ship.vy += ay * milliseconds/1000 
 
        ship.move(milliseconds)
1
2
3
4


1
2
3
4
t = 0 
s = (0,0) 
v = (1,0) 
a = (0,0.2)
1
2
dt = 2 
steps = 5
1
2
3
4
5
6
7
8
from vectors import add, scale 
positions = [s] 
for _ in range(0,5): 
    t += 2 
    s = add(s, scale(dt,v)) 
 
    v  = add(v, scale(dt,a)) 
    positions.append(s)
1
2
1
2
from draw2d import * 
draw2d(Points2D(*positions))

Figure 9.5 Points on the object’s trajectory according to our calculation with Euler’s
method
Figure 9.6 The Øve displacement vectors connecting the points on the trajectory by
straight lines.

Figure 9.7 Euler’s method produces different results with the same initial values and
different numbers of steps.

Figure 9.8 With 100 steps instead of 5 or 10, we get yet another trajectory. Dots are
omitted for this trajectory because there are so many of them.
Figure 9.9 Looking closely at the Ørst two segments, the 100-step approximation is the
largest because its velocity updates most frequently.
1 (9.99999999999998, 9.900000000000006)

Exercise 9.2-Mini Project: Create a function that carries out Euler’s method
automatically for a constantly accelerating object. You need to provide the function
with an acceleration vector, initial velocity vector, initial position vector, and
perhaps other parameters.
Solution: I also included the total time and number of steps as parameters to make
it easy to test various answers in the solution.
def eulers_method(s0,v0,a,total_time,step_count): 
    trajectory = [s0] 
    s = s0 
    v  = v0 
    dt = total_time/step_count     ❶ 
    for _ in range(0,step_count): 
        s = add(s,scale(dt,v))     ❷ 
        v  = add(v,scale(dt,a)) 
        trajectory.append(s) 
    return trajectory
❶ The duration of each time step dt is the total time elapsed divided by the number
of time steps.
❷ For each step, updates the position and velocity and adds the latest position as
the next position in the trajectory (list of positions)
1 (9.999999999990033, 9.999899999993497)

Exercise 9.3-Mini Project: In the calculation of section 9.4, we under approximated
the y-coordinate of position because we updated the y component of the velocity at
the end of each time interval. Update the velocity at the beginning of each time
interval and show that you over approximate the y position over time.
Solution: We can tweak our implementation of the eulers_method  function from
mini-project 9.2 with the only modication being switching the update order of s
and v  :
def eulers_method_overapprox(s0,v0,a,total_time,step_count): 
    trajectory = [s0] 
    s = s0 
    v  = v0 
    dt = total_time/step_count 
    for _ in range(0,step_count): 
        v  = add(v,scale(dt,a)) 
        s = add(s,scale(dt,v)) 
        trajectory.append(s) 
    return trajectory
With the same inputs, this indeed gives a higher approximation of the y-coordinate
than the original implementation. If you look closely at the trajectory in the
following gure, you can see it is already moving in the y direction in the rst time
step.
eulers_method_overapprox((0,0),(1,0),(0,0.2),10,10) 
 
The original Euler’s method trajectory and the new one. The exact trajectory is
shown in black for comparison.

Exercise 9.4−Mini Project: Any projectile like a thrown baseball, a bullet, or an
airborne snowboarder experiences the same acceleration vector: 9.81 m/s/s toward
the earth. If we think of the x-axis of the plane as at ground with the positive y-
axis pointing upward, that amounts to an acceleration vector of (0, 9.81). If a
baseball is thrown from shoulder height at x = 0, we could say its initial position is
(0, 1.5). Assume it’s thrown at an initial speed of 30 m/s at an angle of 20° up from
the positive x direction and simulate its trajectory with Euler’s method.
Approximately how far does the baseball go in the x direction before hitting the
ground?
Solution: The initial velocity is (30 · cos(20°), 30 · sin(20°)). We can use the
eulers_method  function from mini-project 9.2 to simulate the baseball’s motion
over a few seconds:
from math import pi,sin,cos 
angle = 20 * pi/180 
s0 = (0,1.5) 
v0 = (30*cos(angle),30*sin(angle)) 
a = (0,−9.81) 
 
result = eulers_method(s0,v0,a,3,100)
Plotting the resulting trajectory, this gure shows that the baseball makes an arc in
the air before returning to the earth at about the 67-meter mark on the x-axis. The
trajectory continues underground because we didn’t tell it to stop.

Exercise 9.5−Mini Project: Rerun the Euler’s method simulation from the previous
mini-project with the same initial speed of 30 but using an initial position of (0, 0)
and trying various angles for the initial velocity. What angle makes the baseball go
the farthest before hitting the ground?
Solution: To simulate di|erent angles, you can package this code as a function.
Using a new starting position of (0, 0), you can see various trajectories in the
following gure. It turns out that the baseball makes it the farthest at an angle of
45°. (Notice that I’ve ltered out the points on the trajectory with negative y
components to consider only the motion before the baseball hits the ground.)
def baseball_trajectory(degrees): 
    radians = degrees * pi/180 
    s0 = (0,0) 
    v0 = (30*cos(radians),30*sin(radians)) 
    a = (0,−9.81) 
    return [(x,y) for (x,y) in eulers_method(s0,v0,a,10,1000) if y>=0]
Throwing a baseball at 30 m/s at various angles

Exercise 9.6−Mini Project: An object moving in 3D space has an initial velocity of (1,
2, 0) and has a constant acceleration vector of (0, −1, 1). If it starts at the origin,
where is it after 10 seconds? Plot its trajectory in 3D using the drawing functions
from chapter 3.
Solution: It turns out our eulers_method  implementation can already handle 3D
vectors! The gure following the code snippet shows the trajectory in 3D.
from draw3d import * 
traj3d = eulers_method((0,0,0), (1,2,0), (0,−1,1), 10, 10) 
draw3d( 
    Points3D(*traj3d) 
)
Running with 1,000 steps for improved accuracy, we can nd the last position:
>>> eulers_method((0,0,0), (1,2,0), (0,−1,1), 10, 1000)[−1] 
(9.999999999999831, −29.949999999999644, 49.94999999999933)
It’s close to (10, −30, 50), which turns out to be the exact position.

CHAPTER 10
Figure 10.1 The derivative of the function f(x) = x3 has an exact formula, namely f'(x) =
3x2.
Figure 10.2 Entering a function in the input box at wolframalpha.com
Figure 10.3 Wolfram Alpha reports a formula for the derivative of the function.
1
2
3
from math import sin 
def f(x): 
    return (3*x**2 + x) * sin(x)

Figure 10.4 Because (3x2+x) sin(x) is a product of a sum, it can be expanded.
Figure 10.5 A goal is to write a derivative function in Python that takes an expression
for a function and returns an expression for its derivative.
Figure 10.6 A meaningful way to break up an algebraic expression into two smaller
expressions
Figure 10.7 It doesn’t make sense to split the expression up around the plus sign
because the original expression is not the sum of 3x2 and x · sin(x).
Figure 10.8 Combining x and 2 with the power combinator to represent the bigger
expression x2

Figure 10.9 Combining the number 3 with a power to model the product 3x2
Figure 10.10 Combining the expression 3x2 with the element x and the sum combinator
to get 3x2 + x
Figure 10.11 A completed picture showing how to build (3x2 + x) sin(x) from elements
and combinators
1
2
3
4
class Power(): 
    def __init__(self,base,exponent): 
        self.base = base 
        self.exponent = exponent

1
2
3
4
5
6
7
class Number(): 
    def __init__(self,number): 
        self.number = number 
 
class Variable(): 
    def __init__(self,symbol): 
        self.symbol = symbol
1 Power(Variable("x"),Number(2))
1
2
3
4
class Product(): 
    def __init__(self, exp1, exp2): 
        self.exp1 = exp1 
        self.exp2 = exp2
1 Product(Number(3),Power(Variable("x"),Number(2)))

Exercise 10.1: You may have met the natural logarithm, a special mathematical
function written ln(x). Draw the expression ln(yz) as a tree built from the elements
and combinators described in the previous section.
Solution: The outermost combinator is an Apply. The function being applied is ln,
the natural logarithm, and the argument is yz. In turn, yz is a power with base y and
exponent z. The result looks like this:
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
class Sum(): 
    def __init__(self, *exps): 
        self.exps = exps 
 
class Function(): 
    def __init__(self,name): 
        self.name = name 
 
class Apply(): 
    def __init__(self,function,argument): 
        self.function = function 
        self.argument = argument 
 
f_expression = Product(> 
               Sum( 
                   Product( 
                       Number(3), 
                       Power( 
                           Variable("x"), 
                           Number(2))),  
                   Variable("x")),  
               Apply( 
                   Function("sin"), 
                   Variable("x")))
1
2
3
4
1 Apply(Function("cos"),Sum(Power(Variable("x"),Number("3")), Number(−5)))

Exercise 10.2: Translate the expression from the previous exercise to Python code,
given that the natural logarithm is calculated by the Python function math.log .
Write it both as a Python function and as a data structure built from elements and
combinators.
Solution: You can think of ln(yz) as a function of two variables y and z. It translates
directly to Python, where ln is called log  :
from math import log 
def f(y,z): 
    return log(y**z)
The expression tree is built like this:
Apply(Function("ln"), Power(Variable("y"), Variable("z")))
Exercise 10.3: What is the expression represented by Product(Number(3),
Sum(Variable("y"),Variable("z")))  ?
Solution: This expression represents 3 · (y + z). Notice that the parentheses are
necessary because of the order of operations.
Exercise 10.4: Implement a Quotient  combinator representing one expression
divided by another. How do you represent the following expression?
Solution: A Quotient  combinator needs to store two expressions: the top
expression is called the numerator and the bottom is called the denominator :
class Quotient(): 
    def __init__(self,numerator,denominator): 
        self.numerator = numerator 
        self.denominator = denominator
The sample expression is the quotient of the sum a + b with the number 2:
Quotient(Sum(Variable("a"),Variable("b")),Number(2))

Exercise 10.5: Implement a Difference  combinator representing one expression
subtracted from another. How can you represent the expression b2 − 4 ac ?
Solution: The Difference  combinator needs to store two expressions, and it
represents the second subtracted from the rst:
class Difference(): 
    def __init__(self,exp1,exp2): 
        self.exp1 = exp1 
        self.exp2 = exp2
The expression b2 − 4 ac is the di|erence of the expressions b2 and 4 ac and is
represented as follows:
Difference( 
    Power(Variable('b'),Number(2)), 
    Product(Number(4),Product(Variable('a'), Variable('c'))))
Exercise 10.6: Implement a Negative  combinator representing the negation of an
expression. For example, the negation of x2 + y is −(x2 + y). Represent the latter
expression in code using your new combinator.
Solution: The Negative  combinator is a class that holds one expression:
class Negative(): 
    def __init__(self,exp): 
        self.exp = exp
To negate x2 + y, we pass it to the Negative  constructor:
Negative(Sum(Power(Variable("x"),Number(2)),Variable("y")))

Exercise 10.7: Add a function called Sqrt  that represents a square root and use it
to encode the following formula:
 
Solution: To save some typing, we can name our variables and square root function
up front:
A = Variable('a') 
B = Variable('b') 
C = Variable('c') 
Sqrt = Function('sqrt')
Then it’s just a matter of translating the algebraic expression into the appropriate
structure of elements and combinators. At the highest level, you can see this is a
quotient of a sum (on top) and a product (on the bottom):
Quotient( 
    Sum( 
        Negative(B), 
        Apply( 
            Sqrt,  
            Difference( 
                Power(B,Number(2)), 
                Product(Number(4), Product(A,C))))), 
    Product(Number(2), A))
Exercise 10.8−Mini Project: Create an abstract base class called Expression  and make all
of the elements and combinators inherit from it. For instance, class Variable()  would
become class Variable(Expression) . Then overload the Python arithmetic operations
+ , -, * , and /  so that they produce Expression  objects. For instance, the code
2*Variable("x")+3  should yield
cos(x)%20%5C%2C%20dx%250">Sum(Product(Number(2),Variable("x")),Number(3)) .
Solution: See the le expressions.py in the source code for this chapter.
1
2
def f(x): 
    return (3*x**2 + x)*sin(x)

1
2
3
4
>>> distinct_variables(Variable("z")) 
{'z'} 
>>> distinct_variables(Number(3)) 
set()
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
def distinct_variables(exp): 
   if isinstance(exp, Variable): 
       return set(exp.symbol) 
   elif isinstance(exp, Number): 
       return set() 
   elif isinstance(exp, Sum): 
       return set().union(*[distinct_variables(exp) for exp in exp.exps]) 
   elif isinstance(exp, Product): 
       return distinct_variables(exp.exp1).union(distinct_variables(exp.exp2)) 
   elif isinstance(exp, Power): 
       return distinct_variables(exp.base).union(distinct_variables(exp.exponent)) 
   elif isinstance(exp, Apply): 
       return distinct_variables(exp.argument) 
   else: 
       raise TypeError("Not a valid expression.")
1
2
>>> distinct_variables(f_expression) 
{'x'}
1
2
3
4
5
6
from abc import ABC, abstractmethod 
 
class Expression(ABC): 
    @abstractmethod 
    def evaluate(self, **bindings): 
        pass
1
2
>>> z.evaluate(x=3,y=2) 
48

1
2
3
4
5
class Number(Expression): 
    def __init__(self,number): 
        self.number = number 
    def evaluate(self, **bindings): 
        return self.number
1
2
3
4
5
6
7
8
class Variable(Expression): 
    def __init__(self,symbol): 
        self.symbol = symbol 
    def evaluate(self, **bindings): 
        try: 
            return bindings[self.symbol] 
        except: 
            raise KeyError("Variable '{}' is not bound.".format(self.symbol))
1
2
3
4
5
6
class Product(Expression): 
    def __init__(self, exp1, exp2): 
        self.exp1 = exp1 
        self.exp2 = exp2 
    def evaluate(self, **bindings): 
        return self.exp1.evaluate(**bindings) * self.exp2.evaluate(**bindings)
1
2
>>> Product(Variable("x"), Variable("y")).evaluate(x=2,y=5) 
10

1
2
3
4
5
6
7
8
9
10
11
_function_bindings = { 
   "sin": math.sin, 
   "cos": math.cos, 
   "ln": math.log 
} 
class Apply(Expression): 
   def __init__(self,function,argument): 
       self.function = function 
       self.argument = argument 
   def evaluate(self, **bindings): 
       return _function_bindings[self.function.name](self.argument.evaluate(**bindi
1
2
>>>  f_expression.evaluate(x=5) 
−76.71394197305108
1
2
>>> xf(5) 
−76.71394197305108
1
2
3
4
5
class Expression(ABC): 
    ... 
    @abstractmethod 
    def expand(self): 
        pass
1
2
3
4
class Number(Expression): 
    ... 
    def expand(self): 
        return self

1
2
3
4
class Sum(Expression): 
    ... 
    def expand(self): 
        return Sum(*[exp.expand() for exp in self.exps])
1
2
3
4
class Apply(Expression): 
    ... 
    def expand(self): 
        return Apply(self.function, self.argument.expand())
1
2
3
4
5
6
7
8
9
10
11
12
13
class Product(Expression): 
    ... 
    def expand(self): 
        expanded1 = self.exp1.expand() 
        expanded2 = self.exp2.expand() 
        if isinstance(expanded1, Sum): 
            return Sum(*[Product(e,expanded2).expand()  
                         for e in expanded1.exps]) 
        elif isinstance(expanded2, Sum): 
            return Sum(*[Product(expanded1,e)  
                         for e in expanded2.exps]) 
        else: 
            return Product(expanded1,expanded2)
1
2
3
4
1
2
3
4
5
6
7
8
9
10
Y = Variable('y') 
Z = Variable('z') 
A = Variable('a') 
B = Variable('b') 
>>> Product(Sum(A,B),Sum(Y,Z)) 
Product(Sum(Variable("a"),Variable("b")),Sum(Variable("x"),Variable("y"))) 
>>> Product(Sum(A,B),Sum(Y,Z)).expand() 
Sum(Sum(Product(Variable("a"),Variable("y")),Product(Variable("a"), 
Variable("z"))),Sum(Product(Variable("b"),Variable("y")), 
Product(Variable("b"),Variable("z"))))

Exercise 10.9: Write a function contains(expression,  variable)  that checks
whether the given expression contains any occurrence of the specied variable.
Solution: You could easily check whether the variable appears in the result of
distinct_variables , but here’s the implementation from scratch:
def contains(exp, var): 
    if isinstance(exp, Variable): 
        return exp.symbol == var.symbol 
    elif isinstance(exp, Number): 
        return False 
    elif isinstance(exp, Sum): 
        return any([contains(e,var) for e in exp.exps]) 
    elif isinstance(exp, Product): 
        return contains(exp.exp1,var) or contains(exp.exp2,var) 
    elif isinstance(exp, Power): 
        return contains(exp.base, var) or contains(exp.exponent, var) 
    elif isinstance(exp, Apply): 
        return contains(exp.argument, var) 
    else: 
        raise TypeError("Not a valid expression.")
Exercise 10.10: Write a distinct_functions  function that takes an expression as
an argument and returns the distinct, named functions (like sin or ln) that appear in
the expression.
Solution: The implementation looks a lot like the distinct_variables  function
from section 10.3.1:
def distinct_functions(exp): 
    if isinstance(exp, Variable): 
        return set() 
    elif isinstance(exp, Number): 
        return set() 
    elif isinstance(exp, Sum): 
        return set().union(*[distinct_functions(exp) for exp in exp.exps]) 
    elif isinstance(exp, Product): 
        return distinct_functions(exp.exp1).union(distinct_functions(exp.exp2)) 
    elif isinstance(exp, Power): 
        return distinct_functions(exp.base).union(distinct_functions(exp.exponent)) 
    elif isinstance(exp, Apply): 
        return set([exp.function.name]).union(distinct_functions(exp.argument)) 
    else: 
        raise TypeError("Not a valid expression.")
1
2
>>> f_expression.expand() 
Sum(Product(Product(3,Power(Variable("x"),2)),Apply(Function("sin"),Variable("x"))),P

Exercise 10.11: Write a function contains_sum  that takes an expression and
returns True  if it contains a Sum , and False  otherwise.
Solution:
def contains_sum(exp): 
    if isinstance(exp, Variable): 
        return False 
    elif isinstance(exp, Number): 
        return False 
    elif isinstance(exp, Sum): 
        return True 
    elif isinstance(exp, Product): 
        return contains_sum(exp.exp1) or contains_sum(exp.exp2) 
    elif isinstance(exp, Power): 
        return contains_sum(exp.base) or contains_sum(exp.exponent) 
    elif isinstance(exp, Apply): 
        return contains_sum(exp.argument) 
    else: 
        raise TypeError("Not a valid expression.")
Exercise 10.12-Mini Project: Write a __repr__  method on the Expression
classes so that they appear legibly in an interactive session.
Solution: See the walk-through notebook for chapter 10 or see appendix B for a
discussion of __repr__  and other special methods on Python classes.
Exercise 10.13-Mini Project: If you know how to encode equations using the LaTeX
language, write a _repr_latex_  method on the Expression  classes that returns
LaTeX code representing the given expression. You should see nicely typeset
renderings of your expressions in Jupyter after adding the method:
Adding a _repr_latex_  method causes Jupyter to render equations nicely in the
REPL.
Solution: See the walk-through notebook for chapter 10.

Exercise 10.14-Mini Project: Write a method to generate the Python code
representing an expression. Use the Python eval  function to turn this into an
executable Python function. Compare the result with the evaluate method. For
instance, Power(Variable("x"),Number(2))  represents the expression x2. This
should produce the Python code x**2 . Then use Python’s eval  function to
execute this code and show how it matches the result of the evaluate method.
Solution: See the walk-through notebook for implementation. When complete, you
can run the following:
>>> Power(Variable("x"),Number(2))._python_expr() 
'(x) ** (2)' 
>>> Power(Variable("x"),Number(2)).python_function(x=3) 
9
Figure 10.12 The derivative of a linear function is a constant function.
Figure 10.13 A general rule for derivatives of powers: taking the derivative of a
function f(x), a power of x, returns a function that is one power lower.

Figure 10.14 For any secant line on f(x), the secant line on the same x interval of -f(x) has
the opposite slope.
Figure 10.15 Multiplying a function by 4 makes every secant line four times steeper.

Figure 10.16 The vertical change in f(x) on some x interval is the sum of the vertical
change in f(x) and in g(x) on that interval.
Table 10.1 Some basic derivatives (continued)
Function name
Formula
Derivative
Sine
sin(x)
cos(x)
Cosine
cos(x)
−sin(x)
Exponential
ex
ex
Exponential (any base)
ax
ln(a) · ax
Natural logarithm
ln(x)
1/x
Logarithm (any base)
loga x
1/ln(a) · x

Exercise 10.15: Show that the derivative of f(x) = x5 is indeed f'(x) = 5x4 by plotting
the numerical derivative (using the derivative function from chapter 8) alongside
the symbolic derivative f'(x) = 5x4.
Solution:
def p(x): 
    return x**5 
plot_function(derivative(p), 0, 1) 
plot_function(lambda x: 5*x**4, 0, 1)
The two graphs overlap exactly.
The graph of 5x4 and the (numerical) derivative of x5

Exercise 10.16-Mini Project: Let’s think again of the functions of one variable as a
vector space as we did in chapter 6. Explain why the rules for taking derivatives
mean the derivative is a linear transformation of this vector space. (To be specic,
you have to restrict your attention to the functions that have derivatives
everywhere.)
Solution: Thinking of functions f and g as vectors, we can add and multiply them by
scalars. Remember that (f + g)(x) = f(x) + g(x) and (c · f )(x) = c · f(x). A linear
transformation is one that preserves vector sums and scalar multiples.
If we write the derivative as a function D, we can think of it as taking a function as an
input and returning its derivative as an output. For instance, Df = f'. The derivative of
a sum of two functions is the sum of the derivatives
D(f + g) = Df + Dg
The derivative of a function multiplied by a number c is c times the derivative of the
original function:
D(c · f ) = c · Df
These two rules mean that D is a linear transformation. Note, in particular, that the
derivative of a linear combination of functions is the same linear combination of
their derivatives:
D(a · f + b · g) = a · Df + b · Dg

Exercise 10.17-Mini Project: Find a formula for the derivative of a quotient: f(x) /
g(x).
Hint: Use the fact that
The power law holds for negative exponents; for instance, x−1 has the derivative −
x−2 = −1/x2.
Solution: The derivative of g(x)−1 is − g(x)−2 · g'(x) by the chain rule or
With this information, the derivative of the quotient f(x)/ g(x) is equal to the
derivative of the product f(x)/ g(x)−1, which is given by the product rule:
Multiplying the rst term by g(x)/ g(x) gives both terms the same denominator, so
we can add them:

Exercise 10.18: What is the derivative of sin(x) · cos(x) · ln(x)?
Solution: There are two products here, and fortunately, we can take the product rule
in any order and get the same result. The derivative of sin(x) · cos(x) is sin(x) · −sin(x)
+ cos(x) · cos(x) = cos(x)2 − sin(x)2. The derivative of ln(x) is 1/x, so the product rule
tells us that the derivative of the whole product is
Exercise 10.19: Assume we know the derivatives of three functions f , g, and h, which
are written f', g ', and h '. What is the derivative of f(g(h(x))) with respect to x ?
Solution: We need to apply the chain rule twice here. One term is f'(g(h(x))), but we
need to multiply it by the derivative of g(h(x)). That derivative is g'(h(x)) times the
derivative of the inside function h(x). Because the derivative of g(h(x)) is h'(x) ·
g'(h(x)), the derivative of f(g(h(x))) is f'(x) · g'(h(x)) · f'(g(h(x))).
1
2
3
4
5
class Expression(ABC): 
    ... 
    @abstractmethod 
    def derivative(self,var): 
        pass
1
2
3
4
class Number(Expression): 
    ... 
    def derivative(self,var): 
        return Number(0)

1
2
3
4
5
6
7
class Variable(Expression): 
    ... 
    def derivative(self, var): 
        if self.symbol == var.symbol: 
            return Number(1) 
        else: 
            return Number(0)
1
2
3
4
class Sum(Expression): 
    ... 
    def derivative(self, var): 
        return Sum(*[exp.derivative(var) for exp in self.exps])
1
2
>>> Sum(Variable("x"),Variable("c"),Number(1)).derivative(Variable("x")) 
Sum(Number(1),Number(0),Number(0))
1
2
3
4
5
6
class Product(Expression): 
    ... 
    def derivative(self,var): 
        return Sum( 
            Product(self.exp1.derivative(var), self.exp2), 
            Product(self.exp1, self.exp2.derivative(var)))
1
2
>>> Product(Variable("c"),Variable("x")).derivative(Variable("x")) 
Sum(Product(Number(0),Variable("x")),Product(Variable("c"),Number(1)))

1
2
3
4
5
6
7
_var = Variable('placeholder variable') 
 
_derivatives = { 
    "sin": Apply(Function("cos"), _var), 
    "cos": Product(Number(−1), Apply(Function("sin"), _var)), 
    "ln": Quotient(Number(1), _var) 
}
1
2
1
2
3
4
5
6
class Apply(Expression): 
    ... 
    def derivative(self, var): 
        return Product( 
                self.argument.derivative(var), 
                _derivatives[self.function.name].substitute(_var, self.argument))
1
2
1
2
>>> Apply(Function("sin"),Power(Variable("x"),Number(2))).derivative(x) 
Product(Product(Number(2),Power(Variable("x"),Number(1))),Apply(Function("cos"),Power
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
class Power(Expression): 
    ... 
    def derivative(self,var): 
        if isinstance(self.exponent, Number): 
            power_rule = Product( 
                    Number(self.exponent.number),  
                    Power(self.base, Number(self.exponent.number − 1))) 
            return Product(self.base.derivative(var),power_rule) 
        elif isinstance(self.base, Number): 
            exponential_rule = Product( 
                Apply(Function("ln"), 
                Number(self.base.number) 
            ),  
            self) 
            return Product( 
                self.exponent.derivative(var),  
                exponential_rule) 
        else: 
            raise Exception( 
            "can't take derivative of power {}".format( 
            self.display()))
1
2
3
4

Exercise 10.20: Our code already handles the case where one expression making up a
product is constant, meaning a product of the form c · f(x) or f(x) · c for some
expression f(x). Either way, the derivative is c · f'(x). You don’t need the second term
of the product rule, which is f(x) · 0 = 0. Update the code taking the derivative of a
product to handle this case directly, rather than expanding the product rule and
including a zero term.
Solution: We could check whether either expression in a product is an instance of
the Number  class. The more general approach is to see whether either term of the
product contains the variable we’re taking the derivative with respect to. For
instance, the derivative of (3 + sin(5a)) f(x) with respect to x doesn’t require the
product rule because the rst term contains no appearance of x. Therefore, its
derivative (with respect to x) is 0. We can use the contains(expression,
variable)  function from a previous exercise to do the check for us:
class Product(Expression): 
    ... 
    def derivative(self,var): 
        if not contains(self.exp1, var):                         ❶ 
            return Product(self.exp1, self.exp2.derivative(var)) 
        elif not contains(self.exp2, var):                       ❷ 
            return Product(self.exp1.derivative(var), self.exp2) 
        else:                                                    ❸ 
            return Sum( 
                Product(self.exp1.derivative(var), self.exp2), 
                Product(self.exp1, self.exp2.derivative(var)))
❶ If the rst expression has no dependence on the variable, returns the rst
expression times the derivative of the second
❷ Otherwise, if the second expression has no dependence on the variable, returns
the derivative of the rst expression times the unmodied second expression
❸ Otherwise, uses the general form of the product rule
Exercise 10.21: Add the square root function to the dictionary of known functions
and take its derivative automatically.
Hint: The square root of x is equal to x1/2.
Solution: Using the power law, the derivative of the square root of x with respect to
x is ½ · x−1/2, which can also be written as:

We can encode that derivative formula as an expression like so:
_function_bindings = { 
    ... 
    "sqrt": math.sqrt 
} 
 
_derivatives = { 
    ... 
    "sqrt": Quotient(Number(1), Product(Number(2), Apply(Function("sqrt"), _var))) 
}
1
2
3
4
>>> from sympy import * 
>>> from sympy.core.core import * 
>>> Mul(Symbol('y'),Add(3,Symbol('x'))) 
y*(x + 3)
1
2
3
4
>>> y = Symbol('y') 
>>> xx = Symbol('x') 
>>> y*(3+x) 
y*(x + 3)
1
2
3
4
>>> y*(3+x).subs(x,1) 
4*y 
>>> (x**2).diff(x) 
2*x
1
2
>>> (3*x**2).integrate(x) 
x**3

Exercise 10.22: What is the integral of f(x) = 0? Conrm your answer with SymPy,
remembering that SymPy does not automatically include a constant of integration.
Solution: Another way of asking this question is what function has a derivative zero?
Any constant valued function has a zero slope everywhere, so it has a derivative
zero. The integral is
∫ f(x)dx = ∫ dx = C
In SymPy, the code Integer(0)  gives you the number 0 as an expression, so the
integral with respect to a variable x is
>>> Integer(0).integrate(x)
0
Zero, as a function, is one antiderivative of zero. Adding a constant of integration,
we get 0 + C or just C, matching what we came up with. Any constant function is an
antiderivative of the constant, zero function.
Exercise 10.23: What is the integral of x cos(x)?
Hint: Look at the derivative of x sin(x). Conrm your answer with SymPy.
Solution: Let’s start with the hint−the derivative of x sin(x) is sin(x) + x cos(x) by the
product rule. That’s almost what we want, but for an extra sin(x) term. If we had a
−sin(x) term appearing in the derivative, it would cancel this extra sin(x) out, and
the derivative of cos(x) is −sin(x). That is, the derivative of x sin(x) + cos(x) is sin(x)
+ x cos(x) − sin(x) = x cos(x). This was the result we are looking for, so the integral is
∫ x cos(x)dx = x sin(x) + cos(x) + C
Our answer checks out in SymPy:
>>> (x*cos(x)).integrate(x) 
x*sin(x) + cos(x)
This approach of reverse engineering the derivative as one term of a product is
called integration by parts and is a favorite trick of calculus teachers everywhere.

Exercise 10.24: What is the integral of x2 ? Conrm your answer with SymPy.
Solution: If f'(x) = x2 then f(x) probably contains x3 because the power law reduces
powers by one. The derivative of x3 is 3x2, so we want a function that gives us a third
of that result. What we want is x3/3, which has derivative x2. In other words,
∫ x2dx = x3/3 + C
SymPy conrms this:
>>> (x**2).integrate(x) 
x**3/3

CHAPTER 11
Figure 11.1 Oh no, a black hole!

Figure 11.2 Picturing the gravitational Øeld created by the black hole in our asteroid
game
Figure 11.3 On the left, the bow has no potential energy. On the right, it has a lot of
potential energy, ready to be spent to put the arrow in motion.

Figure 11.4 A heatmap of potential energy, using brighter colors to represent higher
potential energy values
Figure 11.5 Potential energy function plotted as a heatmap with its gradient, a vector
Øeld, superimposed. The gradient points in the direction of increasing potential energy.

Figure 11.6 The black hole in our asteroid game is a black circle with every object in the
game feeling the pull of a force toward it.
Figure 11.7 The vector Øeld F(x, y) = (−2y, x) takes the point (3, 1) as input and produces
the arrow (−2, 3) as output.
Figure 11.8 Attaching the vector (−2, 3) to the point (3, 1)

Figure 11.9 Arrows attached to points, representing more values of the vector Øeld F(x,
y) = (−2y, x)
Figure 11.10 A plot of F(x, y) as vectors emanating from (x, y) points that are generated
by Matplotlib
1
2
3
4
def f(x,y): 
    return (−2*y, x) 
 
plot_vector_field(f, −5,5,−5,5)

Figure 11.11 A visualization of the vector Øeld F(x, y) = (−x, -y)
1
2
3
4
def f(x,y): 
    return (−x,-y) 
 
plot_vector_field(f,−5,5,−5,5)
1
2
3
4
5
6
class BlackHole(PolygonModel): 
    def __init__(self,gravity): 
        vs = [vectors.to_cartesian((0.5, 2 * pi * i / 20)) 
                for i in range(0,20)] 
        super().__init__(vs) 
        self.gravity = gravity #<2>
1
1 black_hole = BlackHole(0.1)

Figure 11.12 Making the black hole show up in the center of our game screen
1 draw_poly(screen, black_hole, fill=True)
1
2
3
def gravitational_field(source, x, y): 
    relative_position = (x − source.x, y − source.y) 
    return vectors.scale(− source.gravity, relative_position)

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
def move(self, milliseconds,  
         thrust_vector, gravity_source): 
    tx, ty = thrust_vector 
    gx, gy = gravitational_field(src, self.x, self.y) 
    ax = tx + gx 
    ay = ty + gy 
    self.vx += ax * milliseconds/1000 
    self.vy += ay * milliseconds/1000 
 
    self.x += self.vx * milliseconds / 1000.0 
    self.y += self.vy * milliseconds / 1000.0 
 
    if bounce: 
        if self.x < −10 or self.x > 10: 
            self.vx = − self.vx 
        if self.y < −10 or self.y > 10: 
            self.vy = − self.vy 
    else: 
        if self.x < −10: 
            self.x += 20 
        if self.y < −10: 
            self.y += 20 
        if self.x > 10: 
            self.x -= 20 
        if self.y > 10: 
            self.y -=20
1
2
3
4
5
6
1
2
3
4
5
6
7
8
9
10
11
12
13
14
while not done: 
    ... 
    for ast in asteroids: 
        ast.move(milliseconds, (0,0), black_hole) 
 
    thrust_vector = (0,0) 
 
    if keys[pygame.K_UP]: 
        thrust_vector=vectors.to_cartesian((thrust, ship.rotation_angle)) 
 
    elif keys[pygame.K_DOWN]: 
        thrust_vector=vectors.to_cartesian((−thrust, ship.rotation_angle)) 
 
    ship.move(milliseconds, thrust_vector, black_hole)
1
2
3
4

Figure 11.13 With no initial velocity, the spaceship falls into the black hole.
Figure 11.14 With some initial velocity perpendicular to the black hole, the spaceship
begins an elliptical orbit.

Figure 11.15 An asteroid in another elliptical orbit around our black hole

Exercise 11.1: Where do all of the vectors in the vector eld (−2 − x, 4 − y) point? Plot
the vector eld to conrm your answer.
Solution: This vector eld is the same as the displacement vector (−2, 4) − (x, y),
which is a vector pointing from a point (x, y) to (−2, 4). Therefore, we expect every
vector in this vector eld to point toward (−2, 4). Drawing this vector eld conrms
this.

Exercise 11.2-Mini Project: Suppose we have two black holes, both having gravity
0.1, and positioned at (−3, 4) and (2, 1), respectively. The gravitational elds are g
1(x, y) = 0.1 · (−3 − x, 4 − y) and g 2(x, y) = 0.1 · (2 − x, 1 − y). Calculate a formula for the
total gravitational eld g(x, y) due to both black holes. Is it equivalent to a single
black hole? If so, why?
Solution: At every position (x, y), an object with mass m feels two gravitational
forces: m · g 1(x, y) and m · g 2(x, y). The vector sum of these forces is m(g 1(x, y) + g
2(x, y)). Per unit of mass, the force felt will be g 1(x, y) + g 2(x, y), which conrms
that the total gravitational eld vector is the sum of the gravitational eld vectors
due to each of the black holes. This total gravitational eld is
g(x, y) = g1(x, y) + g2(x, y)
            = 0.1 · (−3 − x, 4 − y) + 0.1 · (2 − x, 1 − y)
We can divide out a factor of 2 and rewrite as
g(x, y) = 0.1 · 2 · (0.5 − x, 2.5 − y)
            = 0.2 · (0.5 − x, 2.5 − y)
This is the same as a single black hole with gravity 0.2, positioned at (0.5, 2.5).
Exercise 11.3-Mini Project: In the asteroid game, add two black holes and allow
these to feel each other’s gravity. Then move while these both also exert gravity on
the asteroids and the spaceship.
Solution: For a full implementation, see the source code. The key addition calls the
move  method for each black hole in each iteration of the game loop, passing it the
list of all other black holes as sources of gravity:
for bh in black_holes: 
    others = [other for other in black_holes if other != bh] 
    bh.move(milliseconds, (0,0), others)

Figure 11.16 Three pictures of a scalar Øeld: a heatmap, a graph, and a contour map
Figure 11.17 As a function, a scalar Øeld takes a point in the plane and produces a
corresponding number. In this case, where (x, y) = (3, 1), the value of U(x, y) is ½ · (32 + 12)
= 5.

Figure 11.18 To plot one point of U(x, y) = ½(x2 + y2), use (x, y) = (3, 1), then use U(3, 1) = 5
as the z-coordinate.
Figure 11.19 A graph of the potential energy scalar Øeld U(x, y) = ½(x2 + y2)
1
2
3
4
def u(x,y): 
    return 0.5 * (x**2 + y**2) 
     
plot_scalar_field(u, −5, 5, −5, 5)

Figure 11.20 A heatmap of the function U(x, y)
Figure 11.21 A contour map of U(x, y), showing curves where the value of U(x, y) is
constant

Figure 11.22 Exploring the value of U(x, y) in the +x and +y directions from (−5, 2)

Figure 11.23 The cross section of U(x, y) at x = −5
Figure 11.24 The cross section of U(x, y) at y = 2

Figure 11.25 Cross sections show us that U(x, y) is increasing in the +y direction and
decreasing in the +x direction.

Figure 11.26 Up close, the region of the graph of U(x, y) near (x, y) = (−5, 2) looks like a
plane.

Figure 11.27 Walking along the graph of U(x, y) from (x, y) = (−5,2) in the direction of (2,5),
you won’t gain or lose elevation.

Figure 11.28 The gradient ∇U is a vector Øeld telling us the magnitude and direction of
steepest ascent on the graph of U at any point (x, y).
Figure 11.29 The potential energy function V(x, y) shown in 3D

Figure 11.30 A plot of the vector Øeld -∇V(x, y), the force Øeld associated with the
potential energy function V(x, y). This is an attractive force toward the two points
shown.

Exercise 11.4: Plot the cross section of h(x, y) = ey sin(x), where y = 1. Then plot the
cross section of h(x, y), where x = π/6.
Solution: The cross section of h(x, y) where y = 1 is a function of only x : h(x, 1) = e1
sin(x) = e · sin(x) as shown here:
Where x = π/6, the value of h(x, y) depends only on y. That is, h(π/6, y) = ey sin(π/6)
= ey/2. The graph is

Exercise 11.5: What are the partial derivatives of the function h(x, y) from the rst
exercise? What is the gradient? What is the value of the gradient at (x, y) = (π/6, 1)?
Solution: The partial derivative of ey sin(x) with respect to x is obtained by treating y
as a constant. ey is therefore treated as a constant as well. The result is
Likewise, we get the partial derivative with respect to y by treating x and, therefore,
sin(x) as constants:
The gradient ∇h(x, y) is the vector eld whose components are the partial
derivatives:
At (x, y) = (π/6, 1), this vector eld evaluates as follows:
Exercise 11.6: Prove (−5, 2) is perpendicular to (2, 5).
Solution: This is a review from chapter 2. These two vectors are perpendicular
because their dot product is zero: (−5, 2) · (2, 5) = −10 + 10 = 0.

Exercise 11.7-Mini Project: Let z = p(x, y) be the equation of the plane that best
approximates U(x, y) at (−5, 2). Figure out (from scratch!) an equation for p(x, y) and
the line contained in p and passing through (−5, 2), which is parallel to the x, y plane.
This line should be parallel to the vector (2, 5, 0) as I claimed in the previous
exercise.
Solution: Remember that the formula for U(x, y) is ½(x2 + y2). The value of U(−5, 2)
is 14.5, so the point (x, y, z) = (−5, 2, 14.5) is on the graph of U(x, y) in 3D.
Before we think about the formula for the plane of best approximation for U(x, y),
let’s review how we got the line of best approximation for a function f(x). The line
that best approximates a function f(x) at a point x0 is the line that passes through
the point (x0, f(x0)) and has a slope f'(x0). Those two facts ensure that both the value
and the derivative of f(x) agree with the line that approximates it.
Following this model, let’s look for the plane p(x, y), whose value and both partial
derivatives match at (x, y) = (−5, 2). That means we must have p(−5, 2) = 14.5, while
∂p/∂x = −5 and ∂p/∂y = 2. As a plane, p(x, y) has the form p(x, y) = ax + by + c for some
numbers a and b(do you remember why?). The partial derivatives are
To make them match, the formula must be p(x, y) = −5x + 2y + c, and to satisfy p(−5,
2) = 14.5, it must be that c = −14.5. Therefore, the formula for the plane of best
approximation is p(x, y) = −5x + 2y − 14.5.
Now, let’s look for the line in the plane p(x, y) passing through (−5, 2), which is
parallel to the x,y plane. This is the set of points (x, y) such that p(x, y) = p(−5, 2),
meaning that there is no elevation change between (−5, 2) and (x, y).
If p(x, y) = p(−5, 2), then −5x + 2y − 14.5 = −5 · −5 + 2 · 2 − 14.5. That simplies to the
equation of a line: −5x + 2y = 29. This line is equivalent to the set of vectors (−5, 2,
14.5) + r · (2, 5, 0), where r is a real number, so it is indeed parallel to (2, 5, 0).

CHAPTER 12
Figure 12.1 Trajectories for a cannonball Øred at four different launch angles
Figure 12.2 Computing the range of a projectile using a simulator

Figure 12.3 Looking at a plot of range vs. launch angle, we can see the approximate
value of the launch angle that produces the longest range.
Figure 12.4 With uneven terrain, the direction we Øre the cannon can affect the range
of the cannonball as well.

Figure 12.5 The variables in our projectile simulation
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
def trajectory(theta,speed=20,height=0, 
               dt=0.01,g=−9.81): 
    vx = speed * cos(pi * theta / 180) 
    vz = speed * sin(pi * theta / 180) 
    t,x,z = 0, 0, height 
    ts, xs, zs = [t], [x], [z] 
    while z >= 0: 
        t += dt 
        vz += g * dt 
        x += vx * dt 
        z += vz * dt 
        ts.append(t) 
        xs.append(x) 
        zs.append(z) 
    return ts, xs, zs
1
2
3
plot_trajectories(  
    trajectory(45), 
    trajectory(60))

Figure 12.6 An output of the plot_trajectories  function showing the results of a
45° and 60° launch angle.
Figure 12.7 Landing position as a function of the launch angle
1
2
def landing_position(traj): 
    return traj[1][−1]
1
2
3
4
def hang_time(traj): 
    return traj[0][−1] 
def max_height(traj): 
    return max(traj[2])
1
2
3
4
5
import matplotlib.pyplot as plt 
angles = range(0,90,5) 
landing_positions = [landing_position(trajectory(theta))  
                     for theta in angles] 
plt.scatter(angles,landing_positions)

Figure 12.8 A plot of the landing position vs. the launch angle for the cannon for several
different values of the launch angle
Exercise 12.1: How far does the cannonball go when red at an angle of 50° from an
initial height of zero? How about if it is red at an angle of 130°?
Solution: At 50°, the cannonball goes about 40.1 meters in the positive direction,
while at 130°, it goes 40.1 meters in the negative direction:
>>> landing_position(trajectory(50)) 
40.10994684444007 
>>> landing_position(trajectory(130)) 
−40.10994684444007
This is because 130° from the positive x-axis is the same as 50° from the negative x-
axis.

Exercise 12.2-Mini Project: Enhance the plot_trajectories  function to draw a
large dot on the trajectory graph at each passing second so we can see the passing of
time on the plot.
Solution: Here are the updates to the function. It looks for the index of the nearest
time after each whole second and makes a scatter plot of (x, z) values at each of
these indices:
def plot_trajectories(*trajs,show_seconds=False): 
    for traj in trajs: 
        xs, zs = traj[1], traj[2] 
        plt.plot(xs,zs) 
        if show_seconds: 
            second_indices = [] 
            second = 0 
            for i,t in enumerate(traj[0]): 
                if t>= second: 
                    second_indices.append(i) 
                    second += 1 
            plt.scatter([xs[i] for i in second_indices],  
                        [zs[i] for i in second_indices]) 
      ...
As a result, you can picture the elapsed time for each of the trajectories you plot; for
example,
plot_trajectories( 
    trajectory(20),  
    trajectory(45), 
    trajectory(60), 
    trajectory(80),  
    show_seconds=True)
Plots of four trajectories with dots showing their positions at each whole number of
seconds.

Exercise 12.3: Make a scatter plot of hang time versus angle for angles between 0
and 180°. Which launch angle produces the maximum hang time?
Solution:
test_angles = range(0,181,5) 
hang_times = [hang_time(trajectory(theta)) for theta in test_angles] 
plt.scatter(test_angles, hang_times) 
 
A plot of the hang time of the cannonball as a function of the launch angle
It appears that a launch angle of roughly 90° yields the longest hang time of just
about 4 seconds. This makes sense because θ = 90° yields the initial velocity with the
largest vertical component.

Exercise 12.4−Mini Project: Write a function plot_trajectory_metric  that plots
the result of any metric we want over a given set of theta (θ) values. For instance,
plot_trajectory_metric(landing_position,[10,20,30]) 
makes a scatter plot of landing positions versus launch angle for the launch angles
10°, 20°, and 30°.
As a bonus, pass the keyword arguments from plot_trajectory_metric  to the
internal calls of the trajectory  function, so you can rerun the test with a di|erent
simulation parameter. For instance, this code makes the same plot but simulated
with a 10-meter initial launch height:
plot_trajectory_metric(landing_position,[10,20,30], height=10)
Solution:
def plot_trajectory_metric(metric,thetas,**settings): 
    plt.scatter(thetas, 
                [metric(trajectory(theta,**settings))  
                 for theta in thetas])
We can make the plot from the previous exercise by running the following:
plot_trajectory_metric(hang_time, range(0,181,5))

Exercise 12.5−Mini Project: What is the approximate launch angle that yields the
greatest range for the cannonball with a 10-meter initial launch height?
Solution: Using the plot_trajectory_metric  function from the preceding mini-
project, we can simply run
plot_trajectory_metric(landing_position,range(0,90,5), height=10)
A plot of range of the cannonball vs. launch angle with a 10 meter launch height
The optimal launch angle from a height of 10 meters is about 40°.
1
2
3
trj = trajectory(45) 
ts, zs = trj[0], trj[2] 
plt.plot(ts,zs)

Figure 12.9 A plot of z(t) for the projectile showing the launching and landing times
where z = 0. We can see from the graph that the elapsed time is about 2.9 seconds.
1
2
3
4
def z(t): 
    return 20*sin(45*pi/180)*t + (−9.81/2)*t**2 
 
plot_function(z,0,2.9)
1

Figure 12.10 Plotting the exact function z(t) on top of the simulated values
1
2
3
4
def r(theta): 
    return (−2*20*20/−9.81)*sin(theta*pi/180)*cos(theta*pi/180) 
 
plot_function(r,0,90)

Figure 12.11 Our calculation of projectile range as a function of the launch angle r(θ),
which matches our simulated landing positions
Figure 12.12 The graph of r(θ) hits its maximum when the derivative is zero and,
therefore, the slope of the graph is zero.

Figure 12.13 In our model, shooting the cannonball at 135° is like shooting at 45° in the
opposite direction.
Figure 12.14 The angles θ = 45° and θ = 135° are the two values between 0 and 180
where r'(θ) = 0.
1
2
3
4
>>> r(45) 
40.774719673802245 
>>> r(135) 
−40.77471967380224

Figure 12.15 Two points that are a local minimum and local maximum, but neither is the
minimum or maximum value for the function
Figure 12.16 For y = x3, the derivative is zero at x = 0, but this is not a minimum or
maximum value.

Exercise 12.6: Use the formula for elapsed time, Δt, in terms of the launch angle θ to
nd the angle that maximizes the hang time of the cannonball.
Solution: The time in the air is t = 2vz/g = 2v sin(θ)/g where the initial speed of the
cannonball is v = |v|. This is maximized when sin(θ) is maximized. We don’t need
calculus for this; the maximum value of sin(θ) for 0 ≤ θ ≤ 180° occurs at θ = 90°. In
other words, with all other parameters constant, the cannonball stays in the air
longest when red directly upward.
Exercise 12.7: Conrm that the derivative of sin(x) is zero at x = 11π/2. Is this a
maximum or minimum value of sin(x)?
Solution: The derivative of sin(x) is cos(x), and
so the derivative of sin(x) is indeed zero at x = 11π/2. Because sin(11π/2) = sin(3π/2) =
−1 and the sine function ranges between −1 and 1, we can be sure this is a local
maximum. Here’s a plot of sin(x) to conrm that:

Exercise 12.8: Where does f(x) = x3 − x have its local maximum and minimum values?
What are the values?
Solution: You can see from plotting the function that f(x) hits a local minimum value
at some x > 0 and a local maximum value at some x < 0. Let’s nd these two points.
The derivative is f'(x) = 3x2 − 1, so we want to nd where 3x2 − 1 = 0. We could use the
quadratic formula to solve for x, but it’s simple enough to eyeball a solution. If 3x2 −
1 = 0 then x2 = 1/3, so x = −1/ or x = 1/. These are the x values where f(x) hits its local
minimum and maximum values.
The local maximum value is
and the local minimum value is
Exercise 12.9−Mini Project: The graph of a quadratic function q(x) = ax2 + bx + c
with a ≠ 0 is a parabola, an arch shape that either has a single maximum value or a
single minimum value. Based on the numbers a, b, and c, what is the x value where
q(x) is maximized or minimized? How can you tell if this point is a minimum or
maximum?
Solution: The derivative q'(x) is given by 2ax + b. This is zero when x =- b/2a.
If a is positive, the derivative starts negative at some low x value, then hits zero at x
= − b/2a and is positive from then on. That means q is decreasing before x = − b/2a
and increasing thereafter; this describes a minimum value of q(x).
You can tell the opposite story if a is negative. Therefore, x = − b/2a is a minimum
value of q(x) if a is positive and a maximum value if a is negative.

Figure 12.17 Picturing the cannon Øring in 3D. Two angles θ and ϕ determine the
direction the cannon is Øred.
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
def trajectory3d(theta,phi,speed=20, 
                 height=0,dt=0.01,g=−9.81): 
    vx = speed * cos(pi*theta/180)*cos(pi*phi/180) 
    vy = speed * cos(pi*theta/180)*sin(pi*phi/180) 
    vz = speed * sin(pi*theta/180) 
    t,x,y,z = 0, 0, 0, height 
    ts, xs, ys, zs = [t], [x], [y], [z] 
    while z >= 0: 
        t += dt 
        vz += g * dt 
        x += vx * dt 
        y += vy * dt 
        z += vz * dt 
        ts.append(t) 
        xs.append(x) 
        ys.append(y) 
        zs.append(z) 
    return ts, xs, ys, zs
1
2
def flat_ground(x,y): 
    return 0

Figure 12.18 A projectile Øred downhill lands below z = 0 and a projectile Øred uphill
lands above z = 0.
1
2
def ridge(x,y): 
    return (x**2 − 5*y**2) / 2500
1
2
3
4
5
def trajectory3d(theta,phi,speed=20,height=0,dt=0.01,g=−9.81, 
                    elevation=flat_ground): 
    ... 
    while z >= elevation(x,y): 
       ...
1
2
3
4
5
plot_trajectories_3d( 
    trajectory3d(20,0,elevation=ridge), 
    trajectory3d(20,270,elevation=ridge), 
    bounds=[0,40,−40,0], 
    elevation=ridge)

Figure 12.19 We only need to think about the elevation of the terrain in the plane
where the projectile is Øred. This is where the shadow of the trajectory is cast.

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
B = 0.0004 
C = 0.005 
v = 20 
g = −9.81 
 
def velocity_components(v,theta,phi): 
    vx = v  * cos(theta*pi/180) * cos(phi*pi/180) 
    vy = v  * cos(theta*pi/180) * sin(phi*pi/180) 
    vz = v  * sin(theta*pi/180) 
    return vx,vy,vz 
     
def landing_distance(theta,phi): 
    vx, vy, vz = velocity_components(v, theta, phi) 
    v_xy = sqrt(vx**2 + vy**2) 
    a = (g/2) − B * vx**2 + C * vy**2 
    b = vz 
    landing_time = -b/a 
    landing_distance = v_xy * landing_time 
    return landing_distance
1
2
3

Figure 12.20 Comparing the calculated landing point with the result of the simulation
for θ = 30° and ϕ = 240°
Exercise 12.10: If |v| = v is the initial speed of the cannonball, verify that the initial
velocity vector has a magnitude equal to v. In other words, show that the vector (v
cos θ cos φ, v cos θ sin φ, v sin θ) has length v.
Hint: By the denitions of sine and cosine and the Pythagorean theorem, sin2 x +
cos2 x = 0 for any value of x.
Solution: The magnitude of (v cos θ cos φ, v cos θ sin φ, v sin θ) is given by

Exercise 12.11: Explicitly write out the formula for the range of the cannonball on the
ridge with elevation Bx2 − Cy2 as a function of θ and φ. The constants that appear are
B and C, as well as the initial launch speed v and the acceleration due to gravity g.
Solution: Starting with the formula
we can plug in vz = v sin θ, vxy = v cos θ, vy = v cos θ sin φ, and vx = v cos θ cos φ to get
With a little simplication in the denominator, this becomes

Exercise 12.12-Mini Project: When an object like a cannonball moves quickly
through the air, it experiences frictional force from the air, called drag, which pushes
it in the opposite direction it’s moving. The drag force depends on a lot of factors,
including the size and shape of the cannonball and the density of the air, but for
simplicity, let’s assume it works as follows. If v is the cannonball’s velocity vector at
any point, the drag force, Fd, is
Fd = −αv
whereα (the Greek letter alpha) is a number giving the magnitude of drag felt by a
particular object in the air. The fact that the drag force is proportional to the velocity
means that as an object speeds up, it feels more and more drag. Figure out how to
add a drag parameter to the cannonball simulation and show that drag causes the
cannonball to slow down.
Solution: We want to add to our simulation is an acceleration based on drag. The
force will be -αv, so the acceleration it causes is -αv/m. Because we’re not varying
the mass of the cannonball, we can use a single drag constant, which isα/ m. The
components of the acceleration due to drag is vxα/ m, vyα/ m and vzα/ m. Here’s the
updated section of the code:
def trajectory3d(theta,phi,speed=20,height=0,dt=0.01,g=−9.81, 
                 elevation=flat_ground, drag=0): 
    ... 
    while z >= elevation(x,y): 
        t += dt 
        vx -= (drag * vx) * dt         ❶ 
        vy -= (drag * vy) * dt 
        vz += (g − (drag * vz)) * dt   ❷ 
        ... 
    return ts, xs, ys, zs
❶ Reduces both vx and vy in proportion to the drag force
❷ Changes the z velocity (vz) by the e|ects of gravity and drag
You can see that a small drag constant of 0.1 slows down the cannonball noticeably,
causing it to fall short of the trajectory without drag.

Trajectories of the cannonball with drag  =  0  and drag  =  0.1
Figure 12.21 A heatmap of the range of the cannon as a function of the launch angles θ
and ϕ

Figure 12.22 The brightest spots occur when the range of the projectile is maximized.
Figure 12.23 The graph of r(θ, ϕ) is Ùat at its maximum points.

Figure 12.24 A point (θ, ϕ) where the graph of r(θ, ϕ) is Ùat. The gradient is zero, but the
function does not attain a maximum value.
1
2
3
4
5
def secant_slope(f,xmin,xmax): 
    return (f(xmax) − f(xmin)) / (xmax − xmin) 
 
def approx_derivative(f,x,dx=1e−6): 
    return secant_slope(f,x-dx,x+dx)
1
1
2
3
4
def approx_gradient(f,x0,y0,dx=1e−6): 
    partial_x = approx_derivative(lambda x: f(x,y0), x0, dx=dx) 
    partial_y = approx_derivative(lambda y: f(x0,y), y0, dx=dx) 
    return (partial_x,partial_y)
1
2
def landing_distance_gradient(theta,phi): 
    return approx_gradient(landing_distance_gradient, theta, phi)

Figure 12.25 A plot of the gradient vector Øeld ∇r(θ, ϕ) on top of the heatmap of the
function r(θ, ϕ). The arrows point in the direction of increase in r, toward brighter spots
on the heatmap.

Figure 12.26 The same plot as in Øgure 12.25 near (θ, ϕ) = (37.5°, 90°), which is the
approximate location of one of the maxima
1
2
3
4
5
6
7
8
9
def gradient_ascent(f,xstart,ystart,tolerance=1e−6): 
    x = xstart 
    y = ystart 
    grad = approx_gradient(f,x,y) 
    while length(grad) > tolerance: 
        x += grad[0] 
        y += grad[1] 
        grad = approx_gradient(f,x,y) 
    return x,y
1
2
3
4
5
6
1
2
>>> gradient_ascent(landing_distance,36,83) 
(37.58114751557887, 89.99992616039857)

Figure 12.27 The starting and ending points for the gradient ascent
1
2
3
4
5
6
7
8
9
10
11
12
def gradient_ascent_points(f,xstart,ystart,tolerance=1e−6): 
    x = xstart 
    y = ystart 
    xs, ys = [x], [y] 
    grad = approx_gradient(f,x,y) 
    while length(grad) > tolerance: 
        x += grad[0] 
        y += grad[1] 
        grad = approx_gradient(f,x,y) 
        xs.append(x) 
        ys.append(y) 
    return xs, ys
1 gradient_ascent_points(landing_distance,36,83)

Figure 12.28 The path that the gradient ascent algorithm takes to reach the maximum
value of the range function

Figure 12.29 Starting at different points, the gradient ascent algorithm can Ønd
different maximum values.
1
2
>>> landing_distance(37.58114751557887, 89.99992616039857) 
52.98310689354378

Figure 12.30 The trajectories for the cannon having maximum range

Exercise 12.13: On the heatmap, simultaneously plot the paths of gradient ascent
from 20 randomly chosen points. All of the paths should end up at one of the two
maxima.
Solution: With a heatmap already plotted, we can run the following to execute and
plot 20 random gradient ascents:
from random import uniform 
for x in range(0,20):
    gap = gradient_ascent_points(landing_distance,  
                                 uniform(0,90),  
                                 uniform(0,360)) 
    plt.plot(*gap,c='k')
The result shows that all of the paths lead to the same places.
The paths of gradient ascents from 20 random initial points
Exercise 12.14-Mini Project: Find the partial derivatives ∂r/∂θ and ∂r/∂φ
symbolically and write a formula for the gradient ∇r(θ, φ).

Exercise 12.15: Find the point on r(θ, φ) where the gradient is zero, but the function
is not maximized.
Solution: We can trick the gradient ascent by starting it with φ = 180°. By the
symmetry of the setup, we can see that ∂r/∂φ = 0 wherever φ = 180°, so the gradient
ascent never has a reason to leave the line where φ = 0:
>>> gradient_ascent(landing_distance,0,180) 
(46.122613357930206, 180.0)
This is the optimal launch angle if you x φ = 0 or φ = 180°, which is the worst angle
because you’re ring uphill.
Tricking gradient ascent by initializing it on a cross section where ∂r/∂ϕ = 0

Exercise 12.16: How many steps does it take for gradient ascent to reach the origin
from (36, 83)? Instead of jumping one gradient, jump 1.5 gradients. Show that you
get there in fewer steps. What happens if you jump even further in each step?
Solution: Let’s introduce a parameter rate  to the gradient ascent calculation,
which indicates how fast the ascent tries to go. The higher the rate, the more we
trust the current calculated gradient and jump in that direction:
def gradient_ascent_points(f,xstart,ystart,rate=1,tolerance=1e−6): 
    ... 
    while length(grad) > tolerance: 
        x += rate * grad[0]
        y += rate * grad[1] 
        ... 
    return xs, ys
Here’s a function that counts the number of steps that a gradient ascent process
takes to converge:
def count_ascent_steps(f,x,y,rate=1): 
    gap = gradient_ascent_points(f,x,y,rate=rate) 
    print(gap[0][−1],gap[1][−1]) 
    return len(gap[0])
It takes 855 steps to perform our original ascent, with the rate  parameter equal to
1:
>>> count_ascent_steps(landing_distance,36,83) 
855
With rate=1.5 , we jump one and a half gradients in each step. Not surprisingly, we
get to the maximum faster, in only 568 steps:
>>> count_ascent_steps(landing_distance,36,83,rate=1.5) 
568
Trying some more values, we see that increasing the rate gets us to the solution in
even fewer steps:
>>> count_ascent_steps(landing_distance,36,83,rate=3) 
282 
>>> count_ascent_steps(landing_distance,36,83,rate=10) 
81 
>>> count_ascent_steps(landing_distance,36,83,rate=20) 
38
Don’t get too greedy though! When we use a rate of 20, we get the answer in fewer
steps, but some steps appear to overshoot the answer and the next step doubles
back. If you set the rate too high, the algorithm can get further and further from the
solution; in which case, it is said to diverge rather than converge.

A gradient ascent with a rate of 20. The algorithm initially overshoots the maximum
θ value and has to double back.
If you up the rate to 40, your gradient ascent won’t converge. Each jump overshoots
further than the last, and the exploration of the parameter space runs o| into
innity.

Exercise 12.17: What happens when you try to run gradient_ascent  directly using
simulated results for r as a function of θ and φ instead of calculated results?
Solution: The result is not pretty. This is because the simulated results depend on
numerical estimations (like deciding when the projectile hits the ground), so these
uctuate rapidly for small changes in the launch angles. Here’s a plot of the cross
section r(θ, 270°) that our derivative approximator would consider when calculating
the partial derivative ∂r/∂θ:
A cross section of simulated trajectories shows that our simulator doesn’t produce a
smooth function r(θ, ϕ).
The value of the derivative uctuates wildly, so the gradient ascent moves in
random directions.

CHAPTER 13
Figure 13.1 Schematic diagram of the sound of a violin reaching an eardrum
Figure 13.2 Thinking of sound waves as functions, loosely interpreted as representing
pressure over time

Figure 13.3 Starting with the graph of a function f(t) (top) and sampling some of the y
values (bottom) to send to an audio library

Figure 13.4 Decomposing a sound wave function into a combination of simpler ones
using a Fourier series
Figure 13.5 Sampled values from a sound wave (left) vs. our random values (right)
>>> import pygame, pygame.sndarray 
>>> pygame.mixer.init(frequency=44100,  
                      size=−16,          #1 
                      channels=1)
1
2
3
4
>>> import numpy as np 
>>> arr = np.random.randint(−32768, 32767, size=44100) 
>>> arr 
array([−16280, 30700, −12229, ..., 2134, 11403, 13338])

Figure 13.6 The Ørst 100 values (top) and the Ørst 441 values (bottom) connected to
deØne a function
1
2
sound = pygame.sndarray.make_sound(arr) 
sound.play()
1
2
3
arr = np.random.randint(−10000, 10000, size=44100) 
sound = pygame.sndarray.make_sound(arr) 
sound.play()

Figure 13.7 A plot of the sequence, consisting of the number 10,000 repeated 50 times
followed by the number −10,000 repeated 50 times.
Figure 13.8 A plot of the Ørst 1,000 of 44,100 numbers shows the repeating pattern.
1
2
form = np.repeat([10000,−10000],50) 
plot_sequence(form)
1 arr = np.tile(form,441)

Exercise 13.1: Our musical note A was a pattern that repeated 441 times in one
second. Create a similar pattern that repeats 350 times in one second, which
produces the musical note F.
Solution: Fortunately, the frequency of 44,100 Hz is divisible by 350: 44,100 / 350 =
126. With 63 values of 10,000 and 63 values of −10,000, we can repeat that sequence
350 times to create one second of audio. The resulting note sounds lower than the A
and is indeed an F:
form = np.repeat([10000,−10000],63) 
arr = np.tile(form,350) 
sound = pygame.sndarray.make_sound(arr) 
sound.play()
Figure 13.9 Every 2π units, the function sin(t) repeats the same value.
1
2
sound = pygame.sndarray.make_sound(arr) 
sound.play()

Figure 13.10 Because the sine function is periodic with period 2π, its graph has the
same shape over every 2π interval.
Figure 13.11 The graph of the cosine function has the same shape as the graph of the
sine function, but it is shifted to the left. It also repeats itself every 2π units.

Figure 13.12 The sine function repeats itself twice between t = 0 and t = 4π.
Figure 13.13 The graph of sin(4πt) is sinusoidal, repeating itself twice in every unit of t
for a frequency of 2.
1
2
3
4
def make_sinusoid(frequency,amplitude): 
    def f(t): 
        return amplitude * sin(2*pi*frequency*t) 
    return f
1
2

Figure 13.14 The graph of make_sinusoid(5,4)  has a height (amplitude) of 4 and
repeats itself 5 times from t = 0 to t = 5, so it has a frequency of 5.
1 >>> plot_function(make_sinusoid(5,4),0,1)
1 sinusoid = make_sinusoid(441,8000)
1
2
>>> np.arange(0,1,0.1) 
array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])
1
2
3
>>> np.arange(0,1,1/44100) 
array([0.00000000e+00, 2.26757370e-05, 4.53514739e-05, ..., 
       9.99931973e-01, 9.99954649e-01, 9.99977324e-01])

Exercise 13.2: Plot the tangent function tan(t) = sin(t)/cos(t). What is its period?
Solution: The tangent function gets innitely big in every period, so it helps to plot
it with a restricted range of y values:
from math import tan 
plot_function(tan,0,5*pi) 
plt.ylim(−10,10)            ❶
❶ Limits the graph window to a y range of −10 < y < 10
A graph of tan(x), which is periodic, looks like this:
Because tan(t) depends only on the values of cos(t) and sin(t), it should repeat itself
at least every 2π units. In fact, it repeats itself twice every 2π units; we can see on
the graph that its period is π.
1
2
3
4
5
def sample(f,start,end,count): 
    mapf = np.vectorize(f) 
    ts = np.arange(start,end,(end-start)/count) 
    values = mapf(ts) 
    return values.astype(np.int16)
1
2
3
4
5
1
2
3
4
sinusoid = make_sinusoid(441,8000) 
arr = sample(sinusoid, 0, 1, 44100) 
sound = pygame.sndarray.make_sound(arr) 
sound.play()

Exercise 13.3: What is the frequency of sin(3πt)? What is the period?
Solution: The frequency of sin(t) is 1/(2π) and multiplying the argument by 3π
increases this frequency by a factor of 3π. The resulting frequency is (3π)/(2π) = 3/2.
The period is the reciprocal of this value, which is 2/3.
Exercise 13.4: Find the value of k such that cos(kt) has a frequency of 5. Plot the
resulting function cos(kt) from zero to one and show that it repeats itself 5 times.
Solution: The default frequency of cos(t) is 1/2π, so cos(kt) has a frequency of k/2π.
If we want this value to equal 5, we need to have k = 10π. The resulting function is
cos(10πt):
>>> plot_function(lambda t: cos(10*pi*t),0,1)
Here is its graph, where it repeats itself ve times between the values t = 0 to t = 1.
1
2
>>> np.array([1,2,3]) + np.array([4,5,6]) 
array([5, 7, 9])

Figure 13.15 Plotting the Ørst 400 points of sample1  and sample2
1
2
sample1 = sample(make_sinusoid(441,8000),0,1,44100) 
sample2 = sample(make_sinusoid(551,8000),0,1,44100)
1
2
3
4
sound1 = pygame.sndarray.make_sound(sample1) 
sound2 = pygame.sndarray.make_sound(sample2) 
sound1.play() 
sound2.play()
1
2
chord = pygame.sndarray.make_sound(sample1 + sample2) 
chord.play()

Figure 13.16 Plotting the sum of the two waves, sample1 + sample2

Figure 13.17 The absolute value of the sum wave is large where there is constructive
interference and small where there is destructive interference.
Figure 13.18 The sine and cosine functions in our linear combination

Figure 13.19 The graph of the Fourier series sin(8πt) + sin(10πt)
1
2
3
4
5
6
7
8
9
10
11
12
def const(n): 
    return 1 
 
def fourier_series(a0,a,b): 
    def result(t): 
        cos_terms = [an*cos(2*pi*(n+1)*t)  
            for (n,an) in enumerate(a)] 
        sin_terms = [bn*sin(2*pi*(n+1)*t) 
            for (n,bn) in enumerate(b)] 
        return a0*const(t) + \ 
            sum(cos_terms) + sum(sin_terms) 
    return result
1
2
3
4
1
2
>>> f = fourier_series(0,[0,0,0,0,0],[0,0,0,1,1]) 
>>> plot_function(f,0,1)

Figure 13.20 A plot of the Ørst term and then the Ørst two terms of the Fourier series
1
2
3
4
>>> f1 = fourier_series(0,[],[4/pi]) 
>>> f3 = fourier_series(0,[],[4/pi,0,4/(3*pi)]) 
>>> plot_function(f1,0,1) 
>>> plot_function(f3,0,1)

Figure 13.20 A plot of the Ørst term and then the Ørst two terms of the Fourier series
Figure 13.21 A sum of the Ørst 5 non-zero terms of the Fourier series
1
2
3
b = [4/(n * pi)  
    if n%2 != 0 else 0 for n in range(1,10)] 
f = fourier_series(0,[],b)
1
1
2
>>> b = [4/(n * pi) if n%2 != 0 else 0 for n in range(1,20)] 
>>> f = fourier_series(0,[],b)

Figure 13.22 The Ørst 10 non-zero terms of the Fourier series
Figure 13.23 With 99 terms, the graph of the Fourier series is nearly Ùat, apart from big
steps at 0, 0.5, and 1.0.
1
2
>>> b = [4/(n * pi) if n%2 != 0 else 0 for n in range(1,100)] 
>>> f = fourier_series(0,[],b)

Figure 13.24 The Ørst 50 non-zero terms of the Fourier series are close to a square
wave, like the Ørst function we met in this chapter.
Exercise 13.5−Mini Project: Create a manipulated version of the square wave
Fourier series so that its frequency is 441 Hz, then sample it and conrm that it
doesn’t just look like the square wave. It should sound like the square wave as well.
Figure 13.25 You can think of the square wave as a vector in the space of functions with
a component length of 4/π in the sin(2πt) direction and component length of 4/3π in
the sin(6πt) direction. The square wave has inØnitely many more components beyond
these two.

1
2
3
4
def inner_product(f,g,N=1000): 
    dt = 1/N 
    return 2*sum([f(t)*g(t)*dt  
                  for t in np.arange(0,1,dt)])
1
2
1
2
3
4
5
6
7
8
9
def s(n): 
    def f(t): 
        return sin(2*pi*n*t) 
    return f 
 
def c(n): 
    def f(t): 
        return cos(2*pi*n*t) 
    return f
1
2
1
2
3
4
5
6
>>> inner_product(s(1),c(1)) 
4.2197487366314734e−17 
>>> inner_product(s(1),s(2)) 
−1.4176155163484784e−18 
>>> inner_product(c(3),s(10)) 
−1.7092447249233977e−16
1
2
3
4
5
6
>>> inner_product(s(1),s(1)) 
1.0000000000000002 
>>> inner_product(c(1),c(1)) 
0.9999999999999999 
>>> inner_product(c(3),c(3)) 
1.0

1
2
3
4
from math import sqrt 
 
def const(n): 
    return 1 /sqrt(2)
1
2
3
4
5
6
>>> inner_product(const,s(1)) 
−2.2580204307905138e−17 
>>> inner_product(const,c(1)) 
−3.404394821604484e−17 
>>> inner_product(const,const) 
1.0000000000000007
1
2
3
4
5
6
7
def fourier_coefficients(f,N): 
    a0 = inner_product(f,const) 
    an = [inner_product(f,c(n))  
          for n in range(1,N+1)] 
    bn = [inner_product(f,s(n))  
          for n in range(1,N+1)] 
    return a0, an, bn
1
2
3
1
2
3
4
5
>>> f = fourier_series(0,[2,3,4],[5,6,7]) 
>>> fourier_coefficients(f,3) 
(−3.812922200197022e−15, 
 [1.9999999999999887, 2.999999999999999, 4.0], 
 [5.000000000000002, 6.000000000000001, 7.0000000000000036])
1
2
def square(t): 
    return 1 if (t%1) < 0.5 else −1

Figure 13.26 A sawtooth wave plotted over Øve periods
1 a0, a, b = fourier_coefficients(square,10)
1
2
3
4
5
6
>>> b[0], 4/pi 
(1.273235355942202, 1.2732395447351628) 
>>> b[2], 4/(3*pi) 
(0.4244006151333577, 0.4244131815783876) 
>>> b[4], 4/(5*pi) 
(0.2546269646514865, 0.25464790894703254)
1
2
def sawtooth(t): 
    return t%1
1
2
3
>>> approx = fourier_series(*fourier_coefficients(sawtooth,10)) 
>>> plot_function(sawtooth,0,5) 
>>> plot_function(approx,0,5)

Figure 13.27 The original sawtooth wave from Øgure 13.26 with its Fourier series
approximation
Figure 13.28 The speedbumps(t)  function that alternates between Ùat stretches
and round bumps
Figure 13.29 The constant term and Ørst 10 cosine terms for the Fourier series of the
speedbumps(t)  function

Exercise 13.6: The vectors u1 = (2, 0, 0), u2 = (0, 1, 1), and u3 = (1, 0, −1) form a basis
for ℝ3. For a vector v = (3, 4, 5), compute three dot products a1 = v · u1, a2 = v · u2, and
a3 = v · u3. Show that v is not equal to a1 u1 + a2 u2 + a3 u3. Why aren’t they equal?
Solution: The dot products are
a1 = v · u1 = (3, 4, 5) · (2, 0, 0) = 6
a2 = v · u2 = (3, 4, 5) · (0, 1, 1) = 9
a3 = v · u3 = (3, 4, 5) · (1, 0,−1) = −2
That makes the linear combination 6 · (2, 0, 0) + 9 · (0, 1, 1) − 2 · (1, 0, −1) = (16, 9, 2),
which is not equal to (3, 4, 5). This approach does not give the correct result because
these basis vectors do not have length 1 and are not perpendicular to each other.
Exercise 13.7-Mini Project: Suppose f(t) is constant, meaning f(t) = k. Use the
integral formula for the inner product to nd a value k making <f , f > = 1. (Yes, I’ve
already told you that k =1/√2 but see if you can get to that value yourself!)
Solution: If f(t) = k, then <f , f > is given by the integral:
(The area under the constant function k2 from 0 to 1 is k2.) If we want 2 k2 to equal 1,
then k2 = and k = √1/2 = 1/√2.

Exercise 13.8: Update the fourier_series  function to use f(t) = 1/√2 for the
constant function instead of f(t) = 1.
Solution:
def fourier_series(a0,a,b): 
    def result(t): 
        cos_terms = [an*cos(2*pi*(n+1)*t) for (n,an) in enumerate(a)] 
        sin_terms = [bn*sin(2*pi*(n+1)*t) for (n,bn) in enumerate(b)] 
        return a0/sqrt(2) + sum(cos_terms) + sum(sin_terms)          ❶ 
    return result
❶ Multiplies the coe}cient a0 by the constant function f(t) = 1/√2 to the Fourier
series result regardless of the value of t
Exercise 13.9−Mini Project: Play a sawtooth wave at 441 Hz and compare it with the
square and sinusoidal waves you played at that frequency.
Solution: We can create a modied sawtooth wave function with amplitude 8,000
and frequency 441 and then sample it to pass to PyGame:
def modified_sawtooth(t): 
    return 8000 * sawtooth(441*t) 
arr = sample(modified_sawtooth,0,1,44100) 
sound = pygame.sndarray.make_sound(arr) 
sound.play()
People often compare the sound of a sawtooth wave to that of a string instrument,
like a violin.

CHAPTER 14
Figure 14.1 A plot of price vs. mileage for used Toyota Priuses listed for sale on
CarGraph.com
Figure 14.2 A schematic of a linear function predicting price p from mileage x
Figure 14.3 Predicting the price of a Prius based on the mileage, using a function of the
form p(x) = ax + b with a = −0.05 and b = 20,000

Figure 14.4 A pair of numbers (a, b) deØne a linear function that we can plot on a graph as
a line. For positive values of a, the graph slopes upward.
Figure 14.5 A set of randomly generated data that intentionally stays close to the line
f(x) = 2x

Figure 14.6 The error values are the differences between the function f(x) and the
actual y values.
Figure 14.7 Picturing a function with larger error values
1
2
3
def sum_error(f,data): 
    errors = [abs(f(x) − y) for (x,y) in data] 
    return sum(errors)

Figure 14.8 The graph of y = |x| is not smooth at x = 0, but the graph of y = x2 is.
1
2
3
4
5
def f(x):  
    return 2*x 
 
def g(x):  
    return 1-x
1
2
3
4
>>> sum_error(f,test_data) 
5.021727176394801 
>>> sum_error(g,test_data) 
38.47711311130152
1
2
3
def sum_squared_error(f,data): 
    squared_errors = [(f(x) − y)**2 for (x,y) in data] 
    return sum(squared_errors)

Figure 14.9 Picturing the sum of the squared error between a function and a data set
Figure 14.10 Picturing the sum_squared_error  for h(x) = 3x relative to the test data
1
2
3
4
>>> sum_squared_error(f,test_data) 
2.105175107540148 
>>> sum_squared_error(g,test_data) 
97.1078879283203

Figure 14.11 The scatter plot of price and mileage for used Priuses with my
hypothetical depreciation function
Figure 14.12 Plotting a different function that assumes a depreciation of $0.10 per mile

Figure 14.13 Testing a starting value of $22,500 for used Toyota Priuses
1
2
3
4
5
6
7
8
def p1(x): 
    return 25000 − 0.2 * x 
 
def p2(x): 
    return 25000 − 0.1 * x 
 
def p3(x): 
    return 22500 − 0.1 * x
1 prius_mileage_price = [(p.mileage, p.price) for p in priuses]
1
2
3
4
5
6
>>> sum_squared_error(p1, prius_mileage_price) 
88782506640.24002 
>>> sum_squared_error(p2, prius_mileage_price) 
34723507681.56001 
>>> sum_squared_error(p3, prius_mileage_price) 
22997230681.560013

Exercise 14.1: Create a set of data points lying on a line and demonstrate that the
sum_error  and sum_squared_error  cost functions both return exactly zero for
the appropriate linear function.
Solution: Here is a linear function and some points that lie on its graph:
def line(x): 
    return 3*x−2 
points = [(x,line(x)) for x in range(0,10)]
Both sum_error(line,points)  and sum_squared_error(line,points)  return
zero because there is no distance from any of the points to the line.
Exercise 14.2: Calculate the value of the cost for the two linear functions, x + 0.5 and
2x − 1. Which one produces a lower sum squared error relative to test_data , and
what does that say about the quality of the ts?
Solution:
>>> sum_squared_error(lambda x:2*x−1,test_data) 
23.1942461283472 
>>> sum_squared_error(lambda x:x+0.5,test_data) 
16.607900877665685
The function x + 0.5 produces a lower value for sum_squared_error , so it is a
better t to the test_data .

Exercise 14.3: Find a linear function p4  that ts the data even better than p1 , p2 ,
or p3 . Demonstrate that it is a better t by showing the cost function is lower than
for p1 , p2 , or p3 .
Solution: The best t we found so far is p3 , represented by p(x) = 22,500 − 0.1 · x.
To get an even better t, you can try tweaking the constants in this formula until the
cost is reduced. One observation that you might make is that p3  was a better t
because we reduced the b value from 25,000 to 22,500. If we reduce it slightly
further, the t gets even better. If we dene a new function p4  with a b value of
20,000
def p4(x): 
    return 20000 − 0.1 * x
it turns out the sum_squared_error  is even lower:
>>> sum_squared_error(p4, prius_mileage_price) 
18958453681.560005
This is lower than the values for any of the three previous functions, demonstrating
that it is a better t to the data.
Figure 14.14 A pair of numbers, (a, b), deØne a linear function. Comparing it to the Øxed
actual data produces the cost as a single number.

Figure 14.15 Costs for various values of the slope a and the lines represented by each
Figure 14.16 A graph of cost vs. the slope a, showing the quality of Øt for different slope
values
1
2
3
4
def test_data_coefficient_cost(a): 
    def f(x): 
        return a * x 
    return sum_squared_error(f,test_data)

Figure 14.17 Different pairs of numbers (a, b) correspond to different price functions
Figure 14.18 Cost for the linear function as a heatmap over values of a and b
1
2
3
4
def coefficient_cost(a,b): 
    def p(x): 
        return a * x + b 
    return sum_squared_error(p,prius_mileage_price)

Exercise 14.4: Find the exact formula for a line through the origin that passes
through one point (3, 4). Do this by nding the function f(x) = ax, which minimizes
the sum squared error relative to this one-point data set.
Solution: There is one coe}cient we need to nd, which is a. The sum of squared
error is the squared di|erence between f(3) = a · 3 and 4. This is (3 a − 4)2, which
expands to 9 a2 − 24 a + 16. We can think of this as a cost function in terms of a, that
is, c(a) = 9 a2 − 24 a + 16.
The best value of a is the one that minimizes this cost. That value of a causes the
derivative of the cost function to be zero. Using the derivative rules from chapter 10,
we nd c'(a) = 18 a − 24. This is solved when a = 4/3, meaning our line of best t is
This clearly contains the origin and the point (4, 3).
Exercise 14.5: Suppose we use a linear function to model the price of a sports car
with respect to its mileage with coe}cients (a, b) = (−0.4, 80000). In English, what
does that say about how the car depreciates over time?
Solution: The value of ax + b when x = 0 is just b = 80,000. That means that at a
mileage of 0, we can expect the car to sell for $80,000. The value a of −0.4 means
that the function value ax + b decreases at a rate of 0.4 units for every one unit
increase in x. That means that the car’s value decreases, on average, by 40 cents for
every one mile it is driven.
1
2
def scaled_cost_function(c,d): 
    return coefficient_cost(0.5*c,50000*d)/1e13

Figure 14.19 The line of best Øt for the car price data
1 c,d = gradient_descent(scaled_cost_function,0,0)
1
2
>>> (c,d) 
(−0.12111901781176426, 0.31495422888049895)
1
2
3
4
>>> xa = 0.5*c 
>>> b = 50000*d 
>>> (a,b) 
(−0.06055950890588213, 15747.711444024948)
1
2
>>> coefficient_cost(a,b) 
14536218169.403479

Exercise 14.6: Use gradient descent to nd the linear function that best ts the test
data. Your resulting function should be close to 2x + 0, but not exactly, because the
data was randomly generated around that line.
Solution: First, we need to write a function that computes the cost of f(x) = ax + b
relative to the test data in terms of the coe}cients a and b :
def test_data_linear_cost(a,b): 
    def f(x): 
        return a*x+b 
    return sum_squared_error(f,test_data)
The values of a and b that minimize this function give us the linear function of best
t. We expect a and b to be close to 2 and 0, respectively, so we can plot a heat map
around those points to understand the function we’re minimizing:
scalar_field_heatmap(test_data_linear_cost,-0,4,−2,2)
The cost of ax + b relative to the test data as a function of a and b
It looks like there’s a minimum to this cost function in the vicinity of (a, b) = (2,0),
as expected. Using gradient descent to minimize this function, we can nd the exact
values:
>>> gradient_descent(test_data_linear_cost,1,1) 
(2.103718204728344, 0.0021207385859157535)
This means the line of best t to the test data is approximately 2.10372 · x + 0.00212.

Table 14.1 Values of the familiar exponential function 2x
x
0
1
2
3
4
5
6
7
8
9
2x
1
2
4
8
16
32
64
128
256
512
Table 14.2 Values of the decreasing exponential function (½)x
x
0
1
2
3
4
5
6
7
8
9
(½)x
1
0.5
0.25
0.125
~0.06
~0.03
~0.015
~0.008
~0.004
~0.002

Figure 14.20 A linear model predicts negative values for Priuses, as compared with an
exponential model that shows a positive value at any mileage.
1
2
3
4
def exp_coefficient_cost(q,r): 
    def f(x): 
        return q*exp(r*x) 
    return sum_squared_error(f,prius_mileage_price)
1

Figure 14.21 Cost as a function of the rescaled values of q and r, called s and t,
respectively
1
2
3
4
def scaled_exp_coefficient_cost(s,t): 
    return exp_coefficient_cost(30000*s,1e−4*t) / 1e11 
 
scalar_field_heatmap(scaled_exp_coefficient_cost,0,1,−1,0)
1
2
3
4
5
6
>>> s,t = gradient_descent(scaled_exp_coefficient_cost,0,0) 
>>> (s,t) 
(0.6235404892859356, -0.07686877731125034) 
>>> q,r = 30000*s,1e−4*t 
>>> (q,r) 
(18706.214678578068, −7.686877731125035e-06)

Figure 14.22 The exponential function of best Øt for a Prius and its mileage
Exercise 14.7: Conrm by choosing a sample value of r that e−rx decreases by a
factor of e every time x increases by 1/r units.
Solution: Let’s take r = 3, so our test function is e−3x. We want to conrm that this
function decreases by a factor of e every time x increases by ⅓ units. Dening the
function in Python as follows
def test(x): 
    return exp(−3*x)
we can see that it starts at a value of 1 at x = 0 and decreases by a factor of e for every
⅓ we add to x :
>>> test(0) 
1.0 
>>> from math import e 
>>> test(1/3), test(0)/e 
(0.36787944117144233, 0.36787944117144233) 
>>> test(2/3), test(1/3)/e 
(0.1353352832366127, 0.1353352832366127) 
>>> test(1), test(2/3)/e 
(0.049787068367863944, 0.04978706836786395)
In each of these cases, adding ⅓ to the input of test  yields the same result as
dividing the previous result by e.
1
2
>>> exp_coefficient_cost(q,r) 
14071654468.28084

Exercise 14.8: According to the exponential function of best t, what percentage of
the value of a Prius is lost every 10,000 miles?
Solution: The price function is p(x) = 18,700 · e−0.00000768 · x, where the value q =
$18,700, which represents the initial price and not how fast the price is decreasing.
We can focus on the term erx = e−0.00000768 · x and see how much it changes over
10,000 miles. For x = 0, the value of this expression is 1, and for x = 10,000, the value
is
>>> exp(r * 10000) 
0.9422186306357088
This means that after 10,000 miles, the Prius is worth only 94.2% of its original
price, a decrease of 5.8%. Given how the exponential function behaves, this will be
the case over any 10,000-mile increase in the mileage.

Exercise 14.9: Asserting that the retail price (the price at zero miles) is $25,000,
what is the exponential function that best ts the data? In other words, xing q =
25,000, what is the value of r yielding the best t for qerx ?
Solution: We can write a separate function that gives the cost of the exponential
function in terms of the single unknown coe}cient r :
def exponential_cost2(r): 
    def f(x): 
        return 25000 * exp(r*x) 
    return sum_squared_error(f,prius_mileage_price)
The following plot conrms that there’s a value of r between −10−4 and 0, which
minimizes the cost function:
plot_function(exponential_cost2,−1e−4,0)
It looks like an approximate value of r = −10−5 minimizes the cost function. To
automatically minimize this function, we need to write a one-dimensional version
of the gradient descent or use another minimization algorithm. You can try
that approach if you like, but because there’s only one parameter, we can simply
guess and check to see that r = −1.12 · 10−5 is approximately the r value yielding the
minimum cost. This implies the best t function is p(x) = 25,000 · e−0.0000112 · x.
Here’s the graph of the new exponential t, plotted with the raw price data:


CHAPTER 15
Figure 15.1 Our classiØer takes a vector of two numbers, the mileage and price of a used
car, and returns a number representing its conØdence that the car is a BMW.
Table 15.1 Sample data points used to train the algorithm
Mileage (mi)
Price ($)
Is BMW?
110,890.0
13,995.00
1
94,133.0
13,982.00
1
70,000.0
9,900.00
0
46,778.0
14,599.00
1
84,507.0
14,998.00
0
. . .
. . .
. . .
1
2
3
4
5
def bmw_finder(mileage,price): 
    if price > 25000: 
        return 1 
    else: 
        return 0

1 from car_data import bmws, priuses
[('bmw', '5', 2013.0, 93404.0, 13999.0, 22.09145859494213), 
 ('bmw', '5', 2013.0, 110890.0, 13995.0, 22.216458611342592), 
 ('bmw', '5', 2013.0, 94133.0, 13982.0, 22.09145862741898), 
 ...
all_car_data = [] 
for bmw in bmws: 
    all_car_data.append((bmw.mileage,bmw.price,1)) 
for prius in priuses: 
    all_car_data.append((prius.mileage,prius.price,0))
>>> all_car_data 
[(93404.0, 13999.0, 1), 
 (110890.0, 13995.0, 1), 
 (94133.0, 13982.0, 1), 
 (46778.0, 14599.0, 1), 
 .... 
(45000.0, 16900.0, 0), 
(38000.0, 13500.0, 0), 
(71000.0, 12500.0, 0)]
1
2
3
4
5
6
7
8
9
def test_classifier(classifier, data): 
    trues = 0 
    falses = 0 
    for mileage, price, is_bmw in data: 
        if classifier(mileage, price) == is_bmw: 
            trues += 1 
        else: 
            falses += 1 
    return trues / (trues + falses)
1
2

1
2
>>> test_classifier(bmw_finder, all_car_data) 
0.59

Exercise 15.1: Update the test_classifier  function to print the number of true
positives, true negatives, false positives, and false negatives. Printing these for the
bmw_finder  classier, what can you tell about the performance of the classier?
Solution: Rather than just keeping track of correct and incorrect predictions, we can
track true and false positives and negatives separately:
def test_classifier(classifier, data, verbose=False):   ❶ 
    true_positives = 0                                  ❷ 
    true_negatives = 0 
    false_positives = 0 
    false_negatives = 0 
    for mileage, price, is_bmw in data: 
        predicted = classifier(mileage,price) 
        if predicted and is_bmw:                       ❸ 
            true_positives += 1 
        elif predicted: 
            false_positives += 1 
        elif is_bmw: 
            false_negatives += 1 
        else: 
            true_negatives += 1 
             
    if verbose:         
        print("true positives %f" % true_positives)    ❹ 
        print("true negatives %f" % true_negatives) 
        print("false positives %f" % false_positives) 
        print("false negatives %f" % false_negatives) 
     
    total = true_positives + true_negatives 
             
    return total / len(data)                           ❺
❶ We now have 4 counters to keep track of.
❷ Species whether to print the data (we might not want to print it every time).
❸ Depending on whether the car is a Prius or BMW and whether it’s classied
correctly, increments 1 of 4 counters
❹ Prints the results of each counter
❺ Returns the number of correct classications (true positives or negatives) divided
by the length of the data set
For the bmw_finder  function, this prints the following text:
true positives 18.000000 
true negatives 100.000000 
false positives 0.000000 
false negatives 82.000000
Because the classier returns no false positives, this tells us it always correctly
identies when the car is not a BMW. But we can’t be too proud of our function yet,
because it says most of the cars are not BMWs, including many that are! In the next
exercise, you can relax the constraint to get a higher overall success rate.

Exercise 15.2: Find a way to update the bmw_finder  function to improve its
performance and use the test_classifier  function to conrm that your
improved function has better than 59% accuracy.
Solution: If you solved the last exercise, you saw that bmw_finder  was too
aggressive in saying that cars were not BMWs. We can lower the price threshold to
$20,000 and see if it makes a di|erence:
def bmw_finder2(mileage,price): 
    if price > 20000: 
        return 1 
    else: 
        return 0
Indeed, by lowering this threshold, bmw_finder  improved the success rate to
73.5%:
>>> test_classifier(bmw_finder2, all_car_data) 
0.735
Figure 15.2 A plot of price vs. mileage for all cars in the data set with each BMW
represented by an X and each Prius represented with a circle
1 >>> plot_data(all_car_data)

Figure 15.3 Shows the decision line with car data plotted
Figure 15.4 Lowering the decision boundary line appears to increase our accuracy.

Figure 15.5 Using a downward-sloping decision boundary
1
2
3
4
5
def decision_boundary_classify(mileage,price): 
    if price > 21000 − 0.07 * mileage: 
        return 1 
    else: 
        return 0
1
2
>>> test_classifier(decision_boundary_classify, all_car_data) 
0.805

Exercise 15.3-Mini Project: What is the decision boundary of the form p = constant
that gives the best classication accuracy on the test data set?
Solution: The following function builds a classier function for any specied,
constant cut-o| price. In other words, the resulting classier returns true if the test
car has price above the cuto| and false otherwise:
def constant_price_classifier(cutoff_price): 
    def c(x,p): 
        if p > cutoff_price: 
            return 1 
        else: 
            return 0 
    return c
The accuracy of this function can be measured by passing the resulting classier to
the test_classify  function. Here’s a helper function to automate this check for
any price we want to test as a cut-o| value:
def cutoff_accuracy(cutoff_price): 
    c = constant_price_classifier(cutoff_price) 
    return test_classifier(c,all_car_data)
The best cut-o| price is between two of the prices in our list. It’s su}cient to check
each price and see if it is the best cut-o| price. We can do that quickly in Python
using the max  function. The keyword argument key  lets us choose what function
we want to maximize by. In this case, we want to nd the price in the list that is the
best cut-o|, so we can maximize by the cutoff_accuracy  function:
>>> max(all_prices,key=cutoff_accuracy) 
17998.0
This tells us that according to our data set, $17,998 is the best price to use as a cut-
o| when deciding whether a car is a BMW 5 series or a Prius. It turns out to be quite
accurate for our data set, with 79.5% accuracy:
>>> test_classifier(constant_price_classifier(17998.0), all_car_data) 
0.795

Figure 15.6 The concept of “BMWness” describes how much like a BMW a point in the
plane is.
1
2
3
4
5
6
7
8
9
10
11
12
13
def make_scale(data): 
    min_val = min(data) 
    max_val = max(data) 
    def scale(x): 
        return (x-min_val) / (max_val − min_val) 
    def unscale(y): 
        return y * (max_val − min_val) + min_val 
    return scale, unscale 
 
price_scale, price_unscale =\  
    make_scale([x[1] for x in all_car_data]) 
mileage_scale, mileage_unscale =\ 
    make_scale([x[0] for x in all_car_data])
1
2
3
4
5
1
2
scaled_car_data = [(mileage_scale(mileage), price_scale(price), is_bmw)  
                    for mileage,price,is_bmw in all_car_data]

Figure 15.7 The mileage and price data scaled so that all values are between zero and
one. The plot looks the same as before, but our risk of numerical error has decreased.
Figure 15.8 The decision boundary p(x) = 0.56 − 0.35 · x on the scaled data set
Table 15.2 Summary of the possible cases (view table Øgure)
(x, p) above decision boundary
p − ax − b > 0
Likely to be a BMW
(x, p) on decision boundary
p − ax − b = 0
Could be either car model
(x, p) below decision boundary
p − ax − b < 0
Likely to be a Prius

Figure 15.9 A plot of the heatmap and decision boundary showing that the bright values
(positive “BMWness”) are above the decision boundary and dark values (negative
“BMWness”) occur below the decision boundary
1
2
3
from math import exp 
def sigmoid(x): 
    return 1 / (1+exp(−x))

Figure 15.10 The graph of the sigmoid function σ(x)
Figure 15.11 Schematic diagram of composing the “BMWness” function f(x, p) with the
sigmoid function σ(x)
Figure 15.12 The heatmaps look basically the same, but the values of the function are
slightly different.

Figure 15.13 While f(x, p) slopes upward linearly, L(x, p) curves up from a minimum value
of 0 to a maximum value of 1.
Figure 15.14 The graph of a linear function in 3D can’t come as close to the data points
as the graph of a logistic function.

Exercise 15.4: Find a function h(x) such that large positive values of x cause h(x) to
be close to 0, large negative values of x cause h(x) to be close to 1, and h(3) = 0.5.
Solution: The function y(x) = 3 − x has y(3) = 0 and it goes o| to positive innity
when x is large and negative and o| to negative innity when x is large and posi-
tive. That means passing the result of y(x) into our sigmoid function gives us a
function with the desired properties. Specically, h(x) = σ(y(x)) = σ(3 − x) works, and
its graph is shown here to convince you:
Exercise 15.5−Mini Project: There is actually a lower bound on the result of f(x, p)
because x and p are not allowed to be negative (negative mileages and prices don’t
make sense, after all). Can you gure out the lowest value of f that a car could
produce?
Solution: According to the heatmap, the function f(x, p) gets smaller as we go down
and to the left. The equation conrms this as well; if we decrease x or p, the value of f
= p − ax − b = p + 0.35 · x − 0.56 gets smaller. Therefore, the minimum value of f(x, p)
occurs at (x, p) = (0, 0), and it’s f(0, 0) = -0.056.

Figure 15.15 Exploring a 3D space of parameter values (a, b, c) to deØne a function L(x, p)
Figure 15.16 A vertical decision boundary might make sense, but it can’t be
represented in the form p = ax + b.
1
2
3
4
def make_logistic(a,b,c): 
    def l(x,p): 
        return sigmoid(a*x + b*p − c) 
    return l
1
2
3
4
5
def simple_logistic_cost(a,b,c): 
    l = make_logistic(a,b,c) 
    errors = [abs(is_bmw-l(x,p))  
              for x,p,is_bmw in scaled_car_data] 
    return sum(errors)

Figure 15.17 The function -log(x) returns big values for small inputs, and −log(1) = 0.
1
2
3
4
5
from math import log 
>>> −log(0.01) 
4.605170185988091 
>>> −log(0.001) 
6.907755278982137
1
2
3
4
5
6
7
8
9
def point_cost(l,x,p,is_bmw): 
    wrong = 1 − is_bmw 
    return −log(abs(wrong − l(x,p))) 
 
def logistic_cost(a,b,c): 
    l = make_logistic(a,b,c) 
    errors = [point_cost(l,x,p,is_bmw) 
              for x,p,is_bmw in scaled_car_data] 
    return sum(errors)
1
2
1
2
3
plot_data(scaled_car_data) 
plot_line(0.35,1,0.56) 
plot_line(1,1,1)

Figure 15.18 The graphs of two decision boundary lines. One is clearly better than the
other at separating Priuses from BMWs.
Exercise 15.6: Implement the function plot_line(a,b,c)  referenced in section
15.4.3 that plots the line ax + by = c, where 0 ≤ x ≤ 1 and 0 ≤ y ≤ 1.
Solution: Note that I used di|erent names other than a, b, and c for the function
arguments because c  is a keyword argument that sets the color of the plotted line
for Matplotlib’s plot  function, which I commonly make use of:
def plot_line(acoeff,bcoeff,ccoeff,**kwargs): 
    a,b,c = acoeff, bcoeff, ccoeff
    if b == 0: 
        plt.plot([c/a,c/a],[0,1]) 
    else: 
        def y(x): 
            return (c-a*x)/b 
        plt.plot([0,1],[y(0),y(1)],**kwargs)
1
2
3
4
>>> logistic_cost(0.35,1,0.56) 
130.92490748700456 
>>> logistic_cost(1,1,1) 
135.56446830870456

Exercise 15.7: Use the formula for the sigmoid function σ to write an expanded
formula for σ(ax + by − c).
Solution: Given that
we can write

Exercise 15.8−Mini Project: What does the graph of k(x, y) = σ(x2 + y2 − 1) look like?
What does the decision boundary look like, meaning the set of points where k(x, y) =
0.5?
Solution: We know that σ(x2 + y2 − 1) = 0.5, wherever x2 + y2 − 1 = 0 or where x2 + y2
= 1. You can recognize the solutions to this equation as the points of distance one
from the origin or a circle of radius 1. Inside the circle, the distance from the origin is
smaller, so x2 + y2 < 1 and σ(x2 + y2) < 0.5, while outside the circle x2 + y2 > 1, so σ(x2
+ y2 − 1) > 0.5. The graph of this function approaches 1
as we move further away from the origin in any direction, while it decreases inside
the circle to a minimum value of about 0.27 at the origin. Here’s the graph:
A graph of σ(x2 + y2 − 1). Its value is less than 0.5 inside the circle of a radius of 1, and
it increases to a value of 1 in every direction outside that circle.

Exercise 15.9−Mini Project: Two equations, 2x + y = 1 and 4x + 2y = 2, dene the
same line and, therefore, the same decision boundary. Are the logistic functions σ(2x
+ y − 1) and σ(4x + 2y − 2) the same?
Solution: No, they aren’t the same function. The quantity 4x + 2y − 2 increases more
rapidly with respect to increases in x and y, so the graph of the latter function is
steeper:
The graph of the second logistic function is steeper than the graph of the rst.
Exercise 15.10-Mini Project: Given a line ax + by = c, it’s not as easy to dene what
is above that line and what is below. Can you describe which side of the line the
function z(x, y) = ax + by − c returns positive values?
Solution: The line ax + by = c is the set of points where z(x, y) = ax + by − c = 0. As we
saw for equations of this form in chapter 7, the graph of z(x, y) = ax + by − c is a
plane, so it increases in one direction from the line and decreases in the other
direction. The gradient of z(x, y) is ∇z(x, y) = (a, b), so z(x, y) increases most rapidly
in the direction of the vector (a, b) and decreases most rapidly in the opposite
direction (− a, − b). Both of these directions are perpendicular to the direction of the
line.

1
2
3
4
def approx_gradient(f,x0,y0,dx=1e-6): 
    partial_x = approx_derivative(lambda x:f(x,y0),x0,dx=dx) 
    partial_y = approx_derivative(lambda y:f(x0,y),y0,dx=dx) 
    return (partial_x,partial_y)
1
2
3
4
5
def approx_gradient3(f,x0,y0,z0,dx=1e-6): 
    partial_x = approx_derivative(lambda x:f(x,y0,z0),x0,dx=dx) 
    partial_y = approx_derivative(lambda y:f(x0,y,z0),y0,dx=dx) 
    partial_z = approx_derivative(lambda z:f(x0,y0,z),z0,dx=dx) 
    return (partial_x,partial_y,partial_z)
1
2
3
4
5
6
7
8
9
10
11
12
13
14
def gradient_descent3(f,xstart,ystart,zstart, 
                      tolerance=1e-6,max_steps=1000): 
    x = xstart 
    y = ystart 
    z = zstart 
    grad = approx_gradient3(f,x,y,z) 
    steps = 0 
    while length(grad) > tolerance and steps < max_steps: 
        x -= 0.01 * grad[0] 
        y -= 0.01 * grad[1] 
        z -= 0.01 * grad[2] 
        grad = approx_gradient3(f,x,y,z) 
        steps += 1 
    return x,y,z
1
2
>>> gradient_descent3(logistic_cost,1,1,1,max_steps=100) 
(0.21114493546399946, 5.04543972557848, 2.1260122558655405)
1
2
>>> gradient_descent3(logistic_cost,1,1,1,max_steps=200) 
(0.884571531298388, 6.657543188981642, 2.955057286988365)

Figure 15.19 With more and more steps, the values of (a, b, c) returned by gradient
descent seem to be settling on a clear decision boundary.
Figure 15.20 Comparing our previous best-guess decision boundary to the one implied
by the result of gradient descent
1
2
>>> gradient_descent3(logistic_cost,1,1,1,max_steps=8000) 
(3.7167003153580045, 11.422062409195114, 5.596878367305919)
1
2
3
plot_data(scaled_car_data) 
plot_line(0.35,1,0.56) 
plot_line(3.7167003153580045, 11.422062409195114, 5.596878367305919)

Figure 15.21 The optimized logistic function is much steeper, meaning its certainty that
a car is a BMW rather than a Prius increases rapidly as you cross the decision boundary.
1
2
3
4
5
6
def best_logistic_classifier(x,p): 
    l = make_logistic(3.7167003153580045, 11.422062409195114, 5.596878367305919) 
    if l(x,p) > 0.5: 
        return 1 
    else: 
        return 0
1
2
>>> test_classifier(best_logistic_classifier,scaled_car_data) 
0.8

Exercise 15.11: Modify the gradient_descent3  function to print the total number
of steps taken before it returns its result. How many steps does the gradient descent
take to converge for logistic_cost  ?
Solution: All you need to do is add the line print(steps)  right before
gradient_descent3  to return its result:
def gradient_descent3(f,xstart,ystart,zstart,tolerance=1e−6,max_steps=1000): 
    ... 
    print(steps) 
    return x,y,z
Running the following gradient descent
gradient_descent3(logistic_cost,1,1,1,max_steps=8000)
the number printed is 7244 , meaning the algorithm converges in 7,244 steps.

Exercise 15.12-Mini Project: Write an approx_gradient  function that calculates
the gradient of a function in any number of dimensions. Then write a
gradient_descent  function that works in any number of dimensions. To test your
gradient_descent  on an n -dimensional function, you can try a function like f(x1,
x2, ... , xn ) = (x1 − 1)2 + (x2 − 1)2 + ... + (xn − 1)2, where x1, x2, ... , xn are the n input
variables to the function f . The minimum of this function should be (1, 1, ..., 1), an n -
dimensional vector with the number 1 in every entry.
Solution: Let’s model our vectors of arbitrary dimension as lists of numbers. To
take partial derivatives in the ith coordinate at a vector v = (v1, v2, ... , vn), we want to
take the ordinary derivative of the ith coordinate xi. That is, we want to look at the
function:
f(v1, v2, ..., vi−1, xi, vi+1, ..., vn)
that is, in other words, every coordinate of v plugged in to f , except the ith entry,
which is left as a variable xi. This gives us a function of a single variable xi, and its
ordinary derivative is the ith partial derivative. The code for partial derivatives looks
like this:
def partial_derivative(f,i,v,**kwargs): 
    def cross_section(x):
        arg = [(vj if j != i else x) for j,vj in enumerate(v)] 
        return f(*arg) 
    return approx_derivative(cross_section, v[i], **kwargs)
Note that our coordinates are zero-indexed, and the dimension of input to f is
inferred from the length of v.
The rest of the work is easy by comparison. To build the gradient, we just take the n
partial derivatives and put them in order in a list:
def approx_gradient(f,v,dx=1e−6): 
    return [partial_derivative(f,i,v) for i in range(0,len(v))]
To do the gradient descent, we replace all of the manipulations of named coordinate
variables, like x, y, and z, with list operations on the list vector of coordinates called v
:
def gradient_descent(f,vstart,tolerance=1e−6,max_steps=1000): 
    v  = vstart 
    grad = approx_gradient(f,v) 
    steps = 0 
    while length(grad) > tolerance and steps < max_steps: 
        v  = [(vi − 0.01 * dvi) for vi,dvi in zip(v,grad)] 
        grad = approx_gradient(f,v) 
        steps += 1 
    return v

To implement the suggested test function, we can write a generalized version of it
that takes any number of inputs and returns the sum of their squared di|erence
from one:
def sum_squares(*v): 
    return sum([(x−1)**2 for x in v])
This function can’t be lower than zero because it’s a sum of squares, and a square
cannot be less than zero. The value zero is obtained if every entry of the input vector
v is one, so that’s the minimum. Our gradient descent conrms this (with only a
small numerical error), so everything looks good! Note that because the starting
vector v is 5D, all vectors in the computation are automatically 5D.
>>> xv  = [2,2,2,2,2] 
>>> gradient_descent(sum_squares,v) 
[1.0000002235452137, 
 1.0000002235452137, 
 1.0000002235452137, 
 1.0000002235452137, 
 1.0000002235452137]
Exercise 15.13-Mini Project: Attempt to run the gradient descent with the
simple_logistic_cost  cost function. What happens?
Solution: It does not appear to converge. The values of a, b, and c continue
increasing without bound even though the decision boundary stabilizes. This means
as the gradient descent explores more and more logistic functions, these are staying
oriented in the same direction but becoming innitely steep. It is incentivized to
become closer and closer to most of the points, while neglecting the ones it has
already mislabeled. As I mentioned, this can be solved by penalizing the incorrect
classications for which the logistic function is the most condent, and our
logistic_cost  function does that well.

CHAPTER 16
Figure 16.1 Different kinds of brain activity cause different neurons to electrically
activate, showing bright areas in a brain scan.
Figure 16.2 Picturing neuron activation as a mathematical function, where a1 , a2 , a3 ,
and a4 are the activation values applied to the function f.

Figure 16.3 Low resolution images of some handwritten digits
Figure 16.4 How our Python neural network function classiØes images of digits.
from sklearn import datasets 
digits = datasets.load_digits()
>>> digits.images[0] 
array([[ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.], 
       [ 0.,  0., 13., 15., 10., 15.,  5.,  0.], 
       [ 0.,  3., 15.,  2.,  0., 11.,  8.,  0.], 
       [ 0.,  4., 12.,  0.,  0.,  8.,  8.,  0.], 
       [ 0.,  5.,  8.,  0.,  0.,  9.,  8.,  0.], 
       [ 0.,  4., 11.,  0.,  1., 12.,  7.,  0.], 
       [ 0.,  2., 14.,  5., 10., 12.,  0.,  0.], 
       [ 0.,  0.,  6., 13., 10.,  0.,  0.,  0.]])

Figure 16.5 The Ørst image in sklearn’s digit data set, which looks like a zero
Figure 16.6 An image from the digit data set with brightness values overlaid on each
pixel.
1
2
import matplotlib.pyplot as plt 
plt.imshow(digits.images[0], cmap=plt.cm.gray_r)

1
2
3
4
5
6
7
>>> import numpy as np 
>>> np.matrix.flatten(digits.images[0]) 
array([ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.,  0.,  0., 13., 15., 10., 
       15.,  5.,  0.,  0.,  3., 15.,  2.,  0., 11.,  8.,  0.,  0.,  4., 
       12.,  0.,  0.,  8.,  8.,  0.,  0.,  5.,  8.,  0.,  0.,  9.,  8., 
        0.,  0.,  4., 11.,  0.,  1., 12.,  7.,  0.,  0.,  2., 14.,  5., 
       10., 12.,  0.,  0.,  0.,  0.,  6., 13., 10.,  0.,  0.,  0.])
1 np.matrix.flatten(digits.images[0]) / 15
1
2
def random_classifier(input_vector): 
    return np.random.rand(10)
1
2
3
4
5
>>> xv  = np.matrix.flatten(digits.images[0]) / 15. 
>>> result = random_classifier(v) 
>>> result 
array([0.78426486, 0.42120868, 0.47890909, 0.53200335, 0.91508751, 
       0.1227552 , 0.73501115, 0.71711834, 0.38744159, 0.73556909])
1
2
>>> list(result).index(max(result)) 
4
1
2
>>> digits.target[0] 
0

Exercise 16.1: Suppose a digit classier function outputs the following NumPy array.
What digit has it concluded is in the image?
array([5.00512567e-06, 3.94168539e-05, 5.57124430e-09, 9.31981207e-09, 
       9.98060276e-01, 9.10328786e-07, 1.56262695e-03, 1.82976466e-04, 
       1.48519455e-04, 2.54354113e-07])
Solution: The largest number in this array is 9.98060276e-01  , or approximately
0.998, which appears fth, or in index 4. Therefore, this output says the image is
classied as a 4.
1
2
3
4
5
6
7
8
9
10
def test_digit_classify(classifier,test_count=1000): 
    correct = 0 
    for img, target in zip(digits.images[:test_count],  
digits.target[:test_count]): 
        v  = np.matrix.flatten(img) / 15. 
        output = classifier(v) 
        answer = list(output).index(max(output)) 
        if answer == target: 
            correct += 1 
    return (correct/test_count)
1
2
3
4
5
6
7
1
2
>>> test_digit_classify(random_classifier) 
0.107

Exercise 16.2-Mini Project: Find the average of all the images of 9’s in the data set
in the same way we took averages of the images in chapter 6. Plot the resulting
image. What does it look like?
Solution: This code takes an integer i and averages the images in the data set that
represent the digit i. Because the digit images are represented as NumPy arrays,
which support addition and scalar multiplication, we can average them using the
ordinary Python sum  function and division operator:
def average_img(i): 
    imgs = [img for img,target in zip(digits.images[1000:], digits.target[1000:]) if target==i] 
    return sum(imgs) / len(imgs)
With this code, average_img(9)  computes an 8-by-8 matrix representing the
average of all the images of 9’s, and it looks like this:
Exercise 16.3-Mini Project: Build a better classier than the random one by nding
the average image of each kind of digit in the test data set and comparing a target
image with all of the averages. Specically, return a vector of the dot products of the
target image with each average digit image.
Solution:
avg_digits = [np.matrix.flatten(average_img(i)) for i in range(10)] 
def compare_to_avg(v):
    return [np.dot(v,avg_digits[i]) for i in range(10)]
Testing this classier, we get 85% of the digits correct in the test data set. Not bad!
>>> test_digit_classify(compare_to_avg) 
0.853

Figure 16.7 A schematic of a multilayer perceptron (MLP), consisting of several layers
of neurons
Figure 16.8 Setting the input layer activations to the entries of the input vector (left)

Figure 16.9 Calculating an activation in layer one as some function of the activations in
layer zero
Figure 16.10 Calculating another activation in layer one with another function of the
input layer activations

Figure 16.11 Two layers of activations for our multilayer perceptron (MLP) calculated.
Figure 16.12 An example of an MLP with all activations calculated

Figure 16.13 The general form of the function to calculate a11as a function of the input
layer activations
Figure 16.14 Showing the connections corresponding to weights w111 and w321

Exercise 16.4: What neuron and layer is represented by the activation a23 ? What
value does this activation have in the following image? (Neurons and layers are
indexed as throughout the previous sections.)
Solution: The superscript indicates the layer, and the subscript indicates the neuron
within the layer. The activation a23 ,therefore, corresponds to the second neuron in
layer 3. In the image, it has an activation value of 0.9.
Exercise 16.5: If layer 5 of a neural network has 10 neurons and layer 6 has 12
neurons, how many total connections are there between neurons in layers 5 and 6?
Solution: Each of the 10 neurons in layer 5 is connected to each of the 12 neurons in
layer 6. That’s 120 total connections.

Exercise 16.6: Suppose we have an MLP with 12 layers. What are the indices l, i, and j
of the weight wijl ,connecting the third neuron of layer 4 to the seventh neuron of
layer 5?
Solution: Remember that l is the destination layer of the connection, so l = 5 in this
case. The indices i and j refer to the neurons in layers l and l − 1, respectively, so i = 7
and j = 3. The weight is labeled w735 .
Exercise 16.7: Where is the weight w313 in the network used throughout the section?
Solution: There is no such weight. This would connect to a third neuron in layer
three, the output layer, but there are only two neurons in this layer.
Exercise 16.8: In the neural network from this section, what’s a formula for a13 in
terms of the activations of layer 2 and the weights and biases?
Solution: The previous layer activations are a12 , a22 ,and a23 ,and the weights
connecting them to a13 are w113 ,w123 ,and w13 3.The bias for activation a13 is denoted
b13 ,so the formula is as follows:
Exercise 16.9−Mini Project: Write a Python function sketch_mlp(*layer
_sizes)  that takes layer sizes of a neural network and outputs a diagram like the
ones used throughout this section. Show all of the neurons with labels and draw
their connections with straight lines. Calling sketch_mlp(3,4,3,2)  should
produce the example from the diagram we have used to represent the neural net
throughout.
Solution: See the source code for this book for an implementation.

Figure 16.15 The weight matrix connecting a four neuron layer to a three neuron layer
is a 3-by−4 matrix.
1
2
3
4
5
6
7
8
9
10
class MLP(): 
    def __init__(self,layer_sizes): 
        self.layer_sizes = layer_sizes 
        self.weights = [ 
            np.random.rand(n,m) 
            for m,n in zip(layer_sizes[:−1], 
                           layer_sizes[1:]) 
        ] 
        self.biases = [np.random.rand(n)  
                       for n in layer_sizes[1:]]
1
2
3
4
1
2
3
4
5
6
7
>>> nn = MLP([2,3]) 
>>> nn.weights 
[array([[0.45390063, 0.02891635], 
        [0.15418494, 0.70165829], 
        [0.88135556, 0.50607624]])] 
>>> nn.biases 
[array([0.08668222, 0.35470513, 0.98076987])]

Figure 16.16 An MLP with three layers of 64, 16, and 10 neurons, respectively

Exercise 16.10-Mini Project: Rewrite the feedforward  method using explicit
loops over the layers and weights rather than using NumPy matrix multiplication.
Conrm that your result matches exactly with the previous implementation.
1
2
3
4
5
6
7
8
9
10
11
class MLP(): 
    ... 
    def feedforward(self,v): 
        activations = [] 
        a = v 
        activations.append(a) 
        for w,b in zip(self.weights, self.biases): 
            z = w @ a + b 
            a = [sigmoid(x) for x in z] 
            activations.append(a) 
        return activations
1
2
3
4
5
6
1
2
3
4
class MLP(): 
    ... 
    def evaluate(self,v): 
        return np.array(self.feedforward(v)[−1])
1
2
3
4
5
>>> nn = MLP([64,16,10]) 
>>> xv  = np.matrix.flatten(digits.images[0]) / 15. 
>>> nn.evaluate(v) 
array([0.99990572, 0.9987683 , 0.99994929, 0.99978464, 0.99989691, 
       0.99983505, 0.99991699, 0.99931011, 0.99988506, 0.99939445])
1
2
>>> test_digit_classify(nn.evaluate) 
0.1

Figure 16.17 Ideal output from a neural network: 1.0 in the correct index and 0.0
elsewhere

1
2
x = np.array([np.matrix.flatten(img) for img in digits.images[:1000]]) / 15.0 
y = digits.target[:1000]
1
2
3
4
5
6
7
8
from sklearn.neural_network import MLPClassifier 
 
mlp = MLPClassifier(hidden_layer_sizes=(16,), 
                    activation='logistic', 
                    max_iter=100, 
                    verbose=10, 
                    random_state=1, 
                    learning_rate_init=.1)
1
2
3
4
5
6
1 mlp.fit(x,y)
1
2
3
4
5
6
7
8
Iteration 1, loss = 2.21958598 
Iteration 2, loss = 1.56912978 
Iteration 3, loss = 0.98970277 
... 
Iteration 58, loss = 0.00336792 
Iteration 59, loss = 0.00330330 
Iteration 60, loss = 0.00321734 
Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stop
1
2
3
4
>>> mlp._predict(x)[0] 
array([9.99766643e-01, 8.43331208e−11, 3.47867059e-06, 1.49956270e-07, 
       1.88677660e-06, 3.44652605e-05, 6.23829017e-06, 1.09043503e-04, 
       1.11195821e-07, 7.79837557e-05])

Exercise 16.11: Modify the test_digit_classify  function to work on a custom
range of examples in the test set. How does it do on the next 500 examples after the
1,000 training examples?
Solution: Here I’ve added a start  keyword argument to indicate which test
example to start with. The test_count  keyword argument still indicates the
number of examples to test:
def test_digit_classify(classifier,start=0,test_count=1000): 
    correct = 0 
    end = start + test_count                           ❶ 
    for img, target in zip(digits.images[start:end],  
digits.target[start:end]):                             ❷ 
        v  = np.matrix.flatten(img) / 15 
        output = classifier(v)
        answer = list(output).index(max(output)) 
        if answer == target: 
            correct += 1 
    return (correct/test_count)
❶ Calculates the end index for test data we want to consider
❷ Loops only over the test data between the start and end indices
My trained MLP identies 96.2% of these fresh digit images correctly:
>>> test_digit_classify(sklearn_trained_classify,start=1000,test_count=500) 
0.962
1
2
def sklearn_trained_classify(v): 
    return mlp._predict([v])[0]
1
2
>>> test_digit_classify(sklearn_trained_classify) 
1.0

Exercise 16.12: Using the squared distance cost function, what is the cost of your
randomly generated MLP for the rst 1,000 training examples? What is the cost of
the scikit-learn MLP?
Solution: First, we can write a function to give us the ideal output vector for a given
digit. For instance, for the digit 5, we’d like an output vector y, which is all zeros
except for a one in the fth index.
def y_vec(digit): 
    return np.array([1 if i == digit else 0 for i in range(0,10)])
The cost of one test example is the sum of squared distance from what the classier
outputs to the ideal result. That’s the sum of squared di|erences in the coordinates
added up:
def cost_one(classifier,x,i): 
    return sum([(classifier(x)[j] − y_vec(i)[j])**2 for j in range(10)])
The total cost for a classier is the average cost over all of the 1,000 training
examples:
def total_cost(classifier): 
    return sum([cost_one(classifier,x[j],y[j]) for j in range(1000)])/1000.
As expected, a randomly initialized MLP with only 10% predictive accuracy has a
much higher cost than a 100% accurate MLP produced by scikit-learn:
>>> total_cost(nn.evaluate) 
8.995371023185067 
>>> total_cost(sklearn_trained_classify) 
5.670512721637246e-05

Exercise 16.13-Mini Project: Extract the MLPClassifier  weights and biases using
its properties coefs_  and intercepts_ , respectively. Plug these weights and
biases into the MLP  class we built from scratch earlier in this chapter and show that
your resulting MLP performs well on digit classication.
Solution: If you try this, you’ll notice one problem; where we expect the weight
matrices to be 16-by−64 and 10-by−16, the coefs_  property of MLPClassifier
gives a 64-by−16 matrix and a 16-by−10 matrix. It looks like scikit-learn uses a
convention that stores columns of the weight matrices versus our convention that
stores rows. There’s a quick way to x this.
NumPy arrays have a T  property returning the transpose of a matrix (a matrix
obtained by pivoting the matrix so that the rows become the columns of the result).
With this trick in mind, we can plug the weights and biases into our neural network
and test it:
>>> nn = MLP([64,16,10]) 
>>> nn.weights = [w.T for w in mlp.coefs_]       ❶ 
>>> nn.biases = mlp.intercepts_                  ❷ 
>>> test_digit_classify(nn.evaluate, 
                        start=1000, 
                        test_count=500) 0.962    ❸
❶ Sets our weight matrices to the ones from the scikit-learn MLP, after transposing
them to agree with our convention
❷ Sets our network’s biases to the ones from the scikit-learn MLP
❸ Tests the performance of our neural network at the classication task with new
weights and biases
This is 96.2% accurate on the 500 images after the training data set, just like the
MLP produced by scikit-learn directly.



Exercise 16.14-Mini Project: Use SymPy or your own code from chapter 10 to
automatically nd the derivative of the sigmoid function
Show that the answer you get is equal to σ(x)(1 − σ(x)).
Solution: In SymPy, we can quickly get a formula for the derivative:
>>> from sympy import * 
>>> X = symbols('x') 
>>> diff(1 / (1+exp(-X)),X) 
exp(-x)/(1 + exp(-x))**2
In math notation, that’s
The computation to show this expression equals σ(x)(1 − σ(x)) and requires a bit of
rote algebra, but it’s worth it to convince yourself that this formula is valid.
Multiplying the top and bottom by ex and noting that ex · e−x = 1, we get

