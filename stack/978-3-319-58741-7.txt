Jarkko Kari · Florin Manea
Ion Petre (Eds.)
 123
LNCS 10307
13th Conference on Computability in Europe, CiE 2017
Turku, Finland, June 12–16, 2017
Proceedings
Unveiling Dynamics
and Complexity

Lecture Notes in Computer Science
10307
Commenced Publication in 1973
Founding and Former Series Editors:
Gerhard Goos, Juris Hartmanis, and Jan van Leeuwen
Editorial Board
David Hutchison
Lancaster University, Lancaster, UK
Takeo Kanade
Carnegie Mellon University, Pittsburgh, PA, USA
Josef Kittler
University of Surrey, Guildford, UK
Jon M. Kleinberg
Cornell University, Ithaca, NY, USA
Friedemann Mattern
ETH Zurich, Zurich, Switzerland
John C. Mitchell
Stanford University, Stanford, CA, USA
Moni Naor
Weizmann Institute of Science, Rehovot, Israel
C. Pandu Rangan
Indian Institute of Technology, Madras, India
Bernhard Steffen
TU Dortmund University, Dortmund, Germany
Demetri Terzopoulos
University of California, Los Angeles, CA, USA
Doug Tygar
University of California, Berkeley, CA, USA
Gerhard Weikum
Max Planck Institute for Informatics, Saarbrücken, Germany

More information about this series at http://www.springer.com/series/7407

Jarkko Kari
• Florin Manea
Ion Petre (Eds.)
Unveiling Dynamics
and Complexity
13th Conference on Computability in Europe, CiE 2017
Turku, Finland, June 12–16, 2017
Proceedings
123

Editors
Jarkko Kari
University of Turku
Turku
Finland
Florin Manea
Christian-Albrechts-University of Kiel
Kiel
Germany
Ion Petre
Åbo Akademi University
Turku
Finland
ISSN 0302-9743
ISSN 1611-3349
(electronic)
Lecture Notes in Computer Science
ISBN 978-3-319-58740-0
ISBN 978-3-319-58741-7
(eBook)
DOI 10.1007/978-3-319-58741-7
Library of Congress Control Number: 2017940625
LNCS Sublibrary: SL1 – Theoretical Computer Science and General Issues
© Springer International Publishing AG 2017
This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part of the
material is concerned, speciﬁcally the rights of translation, reprinting, reuse of illustrations, recitation,
broadcasting, reproduction on microﬁlms or in any other physical way, and transmission or information
storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar methodology now
known or hereafter developed.
The use of general descriptive names, registered names, trademarks, service marks, etc. in this publication
does not imply, even in the absence of a speciﬁc statement, that such names are exempt from the relevant
protective laws and regulations and therefore free for general use.
The publisher, the authors and the editors are safe to assume that the advice and information in this book are
believed to be true and accurate at the date of publication. Neither the publisher nor the authors or the editors
give a warranty, express or implied, with respect to the material contained herein or for any errors or
omissions that may have been made. The publisher remains neutral with regard to jurisdictional claims in
published maps and institutional afﬁliations.
Printed on acid-free paper
This Springer imprint is published by Springer Nature
The registered company is Springer International Publishing AG
The registered company address is: Gewerbestrasse 11, 6330 Cham, Switzerland

Preface
CiE 2017: Unveiling Dynamics and Complexity
Turku, Finland, June 12–16, 2017
The conference Computability in Europe (CiE) is organized yearly under the auspices
of the Association CiE, a European association of mathematicians, logicians, computer
scientists, philosophers, physicists, and others interested in new developments in
computability and their underlying signiﬁcance for the real world. CiE promotes the
development of computability-related science, ranging from mathematics, computer
science, and applications in various natural and engineering sciences, such as physics
and biology, as well as related ﬁelds, such as philosophy and history of computing. CiE
2017 had as motto “Unveiling Dynamics and Complexity,” emphasizing in this way
two important broad research directions within the CiE community.
CiE 2017 was the 13th conference in the series, and the ﬁrst one to take place in
Finland, in the city of Turku. The conference was jointly organized by the Department
of Mathematics and Statistics, University of Turku, and the Department of Computer
Science, Åbo Akademi University. The 12 previous CiE conferences were held in
Amsterdam (The Netherlands) in 2005, Swansea (Wales) in 2006, Siena (Italy) in
2007, Athens (Greece) in 2008, Heidelberg (Germany) in 2009, Ponta Delgada
(Portugal) in 2010, Soﬁa (Bulgaria) in 2011, Cambridge (UK) in 2012, Milan (Italy) in
2013, Budapest (Hungary) in 2014, Bucharest (Romania) in 2015, and Paris (France) in
2016. CiE 2018 will be held in Kiel, Germany. Currently, the annual CiE conference is
the largest international meeting focused on computability theoretic issues. The pro-
ceedings containing the best submitted papers as well as extended abstracts of invited,
tutorial, and special session speakers, for the CiE conferences are published in the
Springer series Lecture Notes in Computer Science.
The CiE conference series is coordinated by the CiE Conference Series Steering
Committee consisting of: Arnold Beckmann (Swansea), Alessandra Carbone (Paris),
Natasha Jonoska (Tampa FL), Benedikt Löwe (Amsterdam), Florin Manea (Kiel,
chair), Klaus Meer (Cottbus), Mariya Soskova (Soﬁa), Susan Stepney (York), and
ex-ofﬁcio members Paola Bonizzoni (Milan, president of the Association CiE) and Dag
Normann (Oslo).
The Program Committee of CiE 2017 was chaired by Jarkko Kari (University of
Turku) and Ion Petre (Åbo Akademi University, Turku). The committee selected the

invited and tutorial speakers and the special session organizers, and coordinated the
reviewing process of all submitted contributions.
The Program Committee invited six speakers to give plenary lectures:
– Scott Aaronson (University of Texas at Austin)
– Karen Lange (Wellesley College)
– Ludovic Patey (Université Paris Diderot)
– Nicole Schweikardt (Humboldt-Universität zu Berlin)
– Alexander Shen (Université de Montpellier)
– Moshe Vardi (Rice University)
The conference also had two plenary tutorials by
– Denis R. Hirschfeldt (University of Chicago)
– Daniel M. Gusﬁeld (University of California, Davis)
CiE 2017 had six special sessions, listed here. Speakers in these special sessions
were selected by the respective special session organizers and were invited to con-
tribute a paper to this volume. The History and Philosophy of Computing session was
focused on a special topic this year: history and foundations of recursion, in memory of
Rósza Péter (1905–1977).
Algorithmics for Biology
Organizers: Paola Bonizzoni and Veli Mäkinen
Speakers: Tobias Marschall (Max-Planck-Institut für Informatik), Fabio Vandin
(University of Padova), Gregory Kucherov (University Paris-Est Marne-la-Vallée),
Gianluca Della Vedova (University of Milano-Bicocca)
Combinatorics and Algorithmics on Words
Organizers: Tero Harju and Dirk Nowotka
Speakers: Stepan Holub (Charles University in Prague), Pascal Ochem (Université
de Montpellier), Svetlana Puzynina (Sobolev Institute of Mathematics and École
Normale Supérieure de Lyon), Narad Rampersad (University of Winnipeg)
Computability in Analysis, Algebra, and Geometry
Organizers: Julia Knight and Andrey Morozov
Speakers: Saugata Basu (Purdue University), Margarita Korovina (University of
Aarhus), Alexander Melnikov (University of California, Berkeley), Russell Miller
(Queens College, City University of New York)
Cryptography and Information Theory
Organizers: Delaram Kahrobaei and Helger Lipmaa
Speakers: Jean-Charles Faugère (Université Pierre et Marie Curie), Elham Kasheﬁ
(University of Edinburgh, Université Pierre et Marie Curie), Aggelos Kiayias
(University of Edinburgh), Ivan Visconti (Università degli Studi di Salerno)
VI
Preface

Formal Languages and Automata Theory
Organizers: Juhani Karhumäki and Alexander Okhotin
Speakers:
Kai
Salomaa
(Queen’s
University
at
Kingston),
Matrin
Kutrib
(Justus-Liebig-Universität Gießen), Thomas Colcombet (Université Paris Diderot),
Artur Jez (University of Wrocław)
History and Philosophy of Computing
Organizers: Liesbeth De Mol and Giuseppe Primiero
Speakers: Juliette Kennedy (University of Helsinki), Jan von Plato (University
of Helsinki), Giovanni Sommaruga (Université de Fribourg), Hector Zenil
(University of Oxford and Karolinska Institute)
The members of the Program Committee of CiE 2017 selected for publication in this
volume and for presentation at the conference 25 of the 52 non-invited submitted
papers. Each paper received at least three reviews by the Program Committee and their
subreviewers. In addition to the accepted contributed papers, this volume contains 12
invited full papers. The production of the volume would have been impossible without
the diligent work of our expert referees, both Program Committee members or sub-
reviewers. We would like to thank all of them for their excellent work.
Springer generously funded this year a Best Student Paper Award, awarded to a
paper authored solely by students. The winner of this award was the paper “Towards
Computable Analysis on the Generalized Real Line,” by Lorenzo Galeotti and Hugo
Nobrega. All authors who contributed to this conference were encouraged to submit
signiﬁcantly extended versions of their papers, with additional unpublished research
content, to Computability. The Journal of the Association CiE.
The Steering Committee of the conference series CiE is concerned about the rep-
resentation of female researchers in the ﬁeld of computability. In order to increase
female participation, the series started the Women in Computability (WiC) program in
2007. In 2016, after the new constitution of the Association CiE allowed for the
possibility of creating special interest groups, the Special Interest Group Women in
Computability was established. Also since 2016, the WiC program has been sponsored
by ACM’s Women in Computing. This program includes a workshop, the annual WiC
diner, the mentorship program, and a grant program for young female researchers. In
2017, the Women in Computability Workshop, coordinated by Liesbeth De Mol,
invited the following speakers: Juliette Kennedy (University of Helsinki, Finland),
Karen Lange (Wellesley College, USA), Ursula Martin (University of Oxford, UK)
The symposium Magic in Science was co-located with CiE 2017. It took place
immediately after the conference and celebrated the 75th birthday of Grzegorz
Rozenberg (University of Leiden, The Netherlands and University of Colorado at
Boulder, USA), one of the world leaders in research on theoretical computer science
and natural computing.
The organizers of CiE 2017 would like to acknowledge and thank the following
entities for their ﬁnancial support (in alphabetical order): the Academy of Finland, the
Association for Symbolic Logic (ASL), the City of Turku, the European Association
for Theoretical Computer Science (EATCS), Federation of Finnish Learned Societies,
Finnish Academy of Science and Letters, Springer, Turku Centre for Computer
Preface
VII

Science, Turku Complex Systems Institute, Turku University Foundation, University
of Turku, Åbo Akademi University, Åbo Akademi University Foundation. We would
also like to acknowledge the support of our non-ﬁnancial sponsor, the Association
Computability in Europe (CiE).
March 2017
Jarkko Kari
Florin Manea
Ion Petre
VIII
Preface

Organization
Program Committee
Andrew Arana
University of Illinois at Urbana-Champaign, USA
Arnold Beckmann
Swansea University, UK
Paola Bonizzoni
University of Milano-Bicocca, Italy
Olivier Bournez
LIX and Ecole Polytechnique, France
Vasco Brattka
Universität der Bundeswehr München, Germany
Cristian S. Calude
University of Auckland, New Zealand
Ann Copestake
University of Cambridge, UK
Liesbeth De Mol
CNRS UMR8163 Savoirs, Textes, Language Université
de Lille 3, France
Ekaterina Fokina
Vienna University of Technology, Austria
Tero Harju
University of Turku, Finland
Emmanuel Jeandel
Laboratoire Lorrain de Recherche en Informatique
et ses Applications (LORIA), France
Emil Jebek
Institute of Mathematics of the Czech Academy
of Sciences, Czech Republic
Natasha Jonoska
University of South Florida, USA
Jarkko Kari
University of Turku (Co-chair), Finland
Viv Kendon
Durham University, UK
Takayuki Kihara
University of California, Berkeley
Florin Manea
Institut für Informatik, Christian-Albrechts-Universität
Klaus Meer
Brandenburgische Technische Universität Cottbus
Senftenberg, Germany
Russell Miller
Queens College and The Graduate Center, CUNY, USA
Bernard Moret
EPFL, Switzerland
Rolf Niedermeier
TU Berlin, Germany
Dag Normann
University of Oslo, Norway
Dirk Nowotka
Christian-Albrechts-Universität zu Kiel, Germany
Isabel Oitavem
CMAF
Ion Petre
Abo Akademi (Co-chair), Finland
Kai Salomaa
Queens University
Reed Solomon
University of Connecticut, USA
Mariya Soskova
Soﬁa University, Bulgaria
Susan Stepney
University of York, UK
Peter Van Emde Boas
ILLC-FNWI-Universiteit van Amsterdam (Emeritus),
The Netherlands
Philip Welch
University of Bristol, UK
Damien Woods
California Institute of Technology, USA

Additional Reviewers
Alten, Clint Van
Atanasiu, Adrian
Azimi, Sepinoud
Berger, Ulrich
Beyersdorff, Olaf
Bollig, Beate
Bonizzoni, Paola
Calvert, Wesley
Carl, Merlin
Carroy, Raphael
Cho, Da-Jung
Csima, Barbara
Darwiche, Adnan
Day, Adam
Diener, Hannes
Durand-Lose, Jérôme
Dzhafarov, Damir
Filmus, Yuval
Franklin, Johanna
Georgiev, Ivan
Gibbons, Jeremy
Golovnev, Alexander
Gregoriades, Vassilios
Hansen, Kristoffer
Arnsfelt
Hamkins, Joel David
Hirschfeldt, Denis
Hoyrup, Mathieu
Hlzl, Rupert
Ikegami, Daisuke
Ishmukhametov, Shamil
Jalonen, Joonatan
Kahle, Reinhard
Kilinç, Görkem
Knight, Julia
Ko, Sang-Ki
Komusiewicz, Christian
Kopra, Johan
Lecomte, Dominique
Lempp, Steffen
Lenzi, Giacomo
Löwe, Benedikt
Marcone, Alberto
Martin, Barnaby
Mauro, Luca San
Mercas, Robert
Metcalfe, George
Michel, Pascal
Mol, Liesbeth de
Morozov, Andrey
Mundhenk, Martin
Mäkinen, Veli
Ng, Timothy
Niwinski, Damian
Patey, Ludovic
Patterson, Murray
Pich, Ján
Porreca, Antonio E.
Porter, Chris
Poulsen, Bøgsted Danny
Previtali, Marco
Primiero, Giuseppe
Quinn, Sara
Rojas, Cristobal
Rossegger, Dino
Salo, Ville
Schmid, Markus L.
Schweber, Noah
Stephenson, Jonny
Thapen, Neil
Toth, David
Tzameret, Iddo
Törmä, Ilkka
Verlan, Sergey
Vikas, Narayan
Vink, Erik De
Zenil, Hector
Zetzsche, Georg
Zizza, Rosalba
Local Organization
Mikhail Barash
Minna Carla
Christel Engblom
Joonatan Jalonen
Jarkko Kari
Ion Petre
Susanne Ramstedt
Ville Salo
X
Organization

Contents
Invited Papers
Character-Based Phylogeny Construction and Its Application
to Tumor Evolution. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3
Gianluca Della Vedova, Murray Patterson, Raffaella Rizzi,
and Mauricio Soto
Is there any Real Substance to the Claims for a ‘New Computationalism’?. . .
14
Alberto Hernández-Espinosa, Francisco Hernández-Quiroz,
and Héctor Zenil
Formalizing a Fragment of Combinatorics on Words . . . . . . . . . . . . . . . . . .
24
Štěpán Holub and Robert Veroff
Turing’s 1949 Paper in Context . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
32
Cliff B. Jones
Gödel’s Reception of Turing’s Model of Computability: The “Shift
of Perception” in 1934. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
42
Juliette Kennedy
A Guided Tour to Computational Haplotyping . . . . . . . . . . . . . . . . . . . . . .
50
Gunnar W. Klau and Tobias Marschall
Outline of Partial Computability in Computable Topology . . . . . . . . . . . . . .
64
Margarita Korovina and Oleg Kudinov
Eliminating Unbounded Search in Computable Algebra . . . . . . . . . . . . . . . .
77
Alexander G. Melnikov
Computable Transformations of Structures . . . . . . . . . . . . . . . . . . . . . . . . .
88
Russell Miller
Formulas with Reversal . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
98
Narad Rampersad
Compressibility and Probabilistic Proofs . . . . . . . . . . . . . . . . . . . . . . . . . .
101
Alexander Shen
Delayed-Input Cryptographic Protocols . . . . . . . . . . . . . . . . . . . . . . . . . . .
112
Ivan Visconti

Contributed Papers
A Deterministic Algorithm for Testing the Equivalence of Read-Once
Branching Programs with Small Discrepancy . . . . . . . . . . . . . . . . . . . . . . .
119
Stefan Arnold and Jacobo Torán
Counting Substrate Cycles in Topologically Restricted Metabolic Networks . . .
129
Robert D. Barish and Akira Suyama
Turing Computable Embeddings, Computable Infinitary Equivalence,
and Linear Orders . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
141
Nikolay Bazhenov
Degrees of Categoricity of Rigid Structures . . . . . . . . . . . . . . . . . . . . . . . .
152
Nikolay A. Bazhenov and Mars M. Yamaleev
Flexible Indexing of Repetitive Collections . . . . . . . . . . . . . . . . . . . . . . . .
162
Djamal Belazzougui, Fabio Cunial, Travis Gagie, Nicola Prezza,
and Mathieu Raffinot
Admissibles in Gaps . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
175
Merlin Carl, Bruno Durand, Grégory Lafitte, and Sabrina Ouazzani
Koepke Machines and Satisfiability for Infinitary Propositional Languages. . .
187
Merlin Carl, Benedikt Löwe, and Benjamin G. Rin
The Recognizability Strength of Infinite Time Turing Machines
with Ordinal Parameters. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
198
Merlin Carl and Philipp Schlicht
New Bounds on the Strength of Some Restrictions
of Hindman’s Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
210
Lorenzo Carlucci, Leszek Aleksander Kołodziejczyk, Francesco Lepore,
and Konrad Zdanowski
Infinite Time Busy Beavers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
221
Oscar Defrain, Bruno Durand, and Grégory Lafitte
Permutive One-Way Cellular Automata and the Finiteness Problem
for Automaton Groups. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
234
Martin Delacourt and Nicolas Ollinger
Towards Computable Analysis on the Generalised Real Line . . . . . . . . . . . .
246
Lorenzo Galeotti and Hugo Nobrega
Finite Language Forbidding-Enforcing Systems. . . . . . . . . . . . . . . . . . . . . .
258
Daniela Genova and Hendrik Jan Hoogeboom
XII
Contents

Surjective H-Colouring: New Hardness Results. . . . . . . . . . . . . . . . . . . . . .
270
Petr A. Golovach, Matthew Johnson, Barnaby Martin, Daniël Paulusma,
and Anthony Stewart
On Higher Effective Descriptive Set Theory . . . . . . . . . . . . . . . . . . . . . . . .
282
Margarita Korovina and Oleg Kudinov
Rl
2 is decidable for Pl
2. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
292
Karoliina Lehtinen and Sandra Quickert
Dimension Spectra of Lines . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
304
Neil Lutz and D.M. Stull
A Universal Oracle for Signal Machines . . . . . . . . . . . . . . . . . . . . . . . . . .
315
Thierry Monteil
Game Characterizations and Lower Cones in the Weihrauch Degrees . . . . . .
327
Hugo Nobrega and Arno Pauly
Randomness Deficiencies. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
338
Gleb Novikov
McShane-Whitney Pairs. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
351
Iosif Petrakis
Total Nondeterministic Turing Machines and a p-optimal Proof System
for SAT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
364
Zenon Sadowski
A One-Dimensional Physically Universal Cellular Automaton. . . . . . . . . . . .
375
Ville Salo and Ilkka Törmä
Extending Wadge Theory to k-Partitions . . . . . . . . . . . . . . . . . . . . . . . . . .
387
Victor L. Selivanov
Erratum to: Counting Substrate Cycles in Topologically
Restricted Metabolic Networks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
E1
Robert D. Barish and Akira Suyama
Author Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
401
Contents
XIII

Invited Papers

Character-Based Phylogeny Construction
and Its Application to Tumor Evolution
Gianluca Della Vedova(B), Murray Patterson, Raﬀaella Rizzi,
and Mauricio Soto
DISCo, University of Milano–Bicocca, Milan, Italy
gianluca.dellavedova@unimib.it
Abstract. Character-based Phylogeny Construction is a well-known
combinatorial problem whose input is a matrix M and we want to com-
pute a phylogeny that is compatible with the actual species encoded
by M.
In this paper we survey some of the known formulations and algorithms
for some variants of this problem. Finally, we present the connections
between these problems and tumor evolution, and we discuss some of
the most important open problems.
1
Introduction
A phylogeny is a common representation of any evolutionary history: a labeled
tree whose leaves are the extant species or taxa, or individuals, or simply bio-
logical data that we are currently able to analyze [16]. The construction of a
phylogeny by character-based methods have always found a wide interest among
the most theoretically inclined researchers, thanks to its connections with com-
binatorics (and graph theory in particular). In this paper we will survey some
of the main known results on character-based phylogenies, as well as its recent
application in cancer genomics.
In this context the main units of study are the species and the characters:
each species is described by a set of attributes, called characters, where each
character is inherited independently and can assume one of a ﬁnite set of values,
called states. Notice that species must not be interpreted literally, as they can
also be single individuals or entire populations: the only relevant fact is that they
can be thought of as a set of characters. Recent applications, indeed, show that
such models can be applied to analyze the evolution of data related to various
genomic information, such as haplotyping [2,5,13] protein domains [33], markers
in tumors [24] or single-nucleotide variants (SNV) [34].
In the following we will denote by C, S, and Q respectively the characters,
the species and the possible states that we are considering. Moreover, we will
denote by n, m, and k respectively the number of such characters, species and
possible states. Without loss of generality, we can assume that there is a special
state, represented by 0, the initial state of each character. In this paper we will
consider only rooted trees, where the root has this initial state for all characters.
c
⃝Springer International Publishing AG 2017
J. Kari et al. (Eds.): CiE 2017, LNCS 10307, pp. 3–13, 2017.
DOI: 10.1007/978-3-319-58741-7 1

4
G.D. Vedova et al.
In a character-based (rooted) tree T, each edge e = (x, y) of T represents an
evolutionary event (or mutation) and is labeled by some character-state pairs
(c, q), where c is a character of M and q is a possible state for c. More precisely,
if the edge e is labeled by (c, q), then the mutation occurring in e is the change
of state of character c, which assumes state q. This notion allows to extend the
idea of state from characters to nodes of the tree T. Let (x, y) be an edge of T.
Then the state of y for the character c, denoted by ly(c) is equal to q if the pair
(c, q) labels the edge (x, y), while ly(c) = lx(c) otherwise.
Given an n × m matrix M and a tree T, we will say that T explains M
(or that M is consistent with T) if, for each row s of M, there exists a node
x of T whose state lx(·) is equal to the row s. These notions lead to a natural
computational problem where the input is a matrix M, while the output is a
tree T whose root r has state 0 for each character, and T explains the matrix
M — this problem corresponds to computing a putative evolutionary history
consistent with the available data (the matrix M). We will call such problem
the Character Compatibility (CC) problem.
Restricting the set of possible mutations that appear in a tree T results in
diﬀerent variants of CC, each corresponding to diﬀerent models of evolution, and
hence with diﬀerent possible biological applications.
2
Perfect Phylogeny and Variants
Classically, the most widely studied CC version is Perfect Phylogeny, where
no character-state pair (c, q) can label two edges of T. Since the Perfect Phy-
logeny problem is NP-hard [4], we need to focus on restrictions: for example on
the number of possible states, that is, bounding the value of k.
Binary Perfect Phylogeny considers the case when Q contains only two
states, 0 and 1. In this case, state 1 represents the fact that a species possesses a
character (for example that a species has wings, or an individual has blood type
A). In this problem, not only are there only two states, but each character can
label only one edge of the tree T. More formally, given the matrix M, we want
to compute a rooted tree T with vertices VT such that:
(1) For each species s ∈S there is a vertex vs of T with lvs(·) = s.
(2) For every c ∈C and q ∈q, the set {v ∈VT | lv(c) = q} induces a connected
component of T.
This formulation implies that the inﬁnite sites assumption holds: in fact no
mutation can involve twice the same character. While this assumption is very
restrictive (in fact it is too restrictive to be applied in several contexts), there
are some applications where it is a useful model, such as haplotyping [2] or
tumoral phylogeny [14]. From a combinatorial point of view, there is a rich
literature, starting from [11], with a simple characterization of the matrices that
can be explained by a tree T. Let M be a binary matrix. Then there exists
a tree T explaining M if and only if there does not exist two characters c1
and c2 and three species s01, s10, s11 such that M[s01, c1] = M[s10, c2] = 0

Character-Based Phylogeny Construction and Its Application
5
and M[s01, c2] = M[s10, c1] = M[s11, c1] = M[s11, c2] = 1. Such condition is
also called the 4-gamete test, since it consists of ﬁnding two characters c1 and
c2 inducing all four possible pairs (0, 0), (0, 1), (1, 0), and (1, 1) in any tree
explaining M — notice that the previous deﬁnition does not check for the pair
(0, 0) since the root of T must have state 0 for all characters.
The Binary Perfect Phylogeny problem has a well-known linear-time algo-
rithm [21,22], as well as an O(nm log2(n + m))-time algorithm when the matrix
M has missing entries [32]. While the ﬁrst algorithm frames the problem as sort-
ing the rows of M, the latter paper describes the problem in a graph-theoretic
framework, by introducing a bipartite graph G associated to M. More precisely
the vertex set of G is C ∪S and an edge of G connects the species s and the
character c iﬀM[s, c] = 1 — with a slight abuse of notation we consider the
graph G and the matrix M equivalent. In this context, the 4-gamete test is a
forbidden subgraph test (i.e., G can be explained by a tree T iﬀG does not
contain a certain induced subgraph).
Whenever the number k of states is larger than 2, the problem becomes more
complex. There have been several papers presenting polynomial-time algorithms
for k ∈{3, 4}, culminating with a polynomial-time algorithm for any constant
k [1], later improved in [25].
Generalizing the model. A missing entry M[s, c] in a binary matrix M means
that we do not know if the species s possesses the character c. As soon as we move
away from binary matrices, we can have partial uncertainty on the states that
can be assumed by species s and character c, that is, some states are possible
but others are not. To model this situation, we can introduce the notion of
generalized character [3], where each entry M[s, c] is a subset of the set Q of all
possible states.
Another form of partial information regards the possible transitions between
the states of characters, that is, for each edge (x, y) labeled by (c, q), the relation
between the states of c in x and in y. For example, in the case of Binary Perfect
Phylogeny, the only possible transition is 0 →1, but for Perfect Phylogeny in
general, only the transitions ending in 0 are forbidden — all other transitions
are allowed. Therefore we can model the possible transitions as a directed graph
GQ with vertices Q (Fig. 1).
c1 c2 c3 c4 c5 c
M
6
s1 0 0 1 0 0 1
s2 0 1 1 1 1 0
s3 0 1 1 0 0 0
s4 0 0 1 0 0 0
s5 1 1 1 1 0 0
s4
s3
s2
(c5, 1)
s5
(c1, 1)
(c4, 1)
(c2, 1)
s1
(c6, 1)
(c3, 1)
Fig. 1. A 5 × 6 binary matrix M that is explained by a perfect phylogeny.

6
G.D. Vedova et al.
These observations lead to the Generalized Character Compatibility
(GCC) problem [3] which is to ﬁnd a perfect phylogeny for a set S of species on a
set C of generalised characters, that is, to ﬁnd a rooted tree T = (VT , E) that is
a perfect phylogeny and, additionally, for every c ∈C, that the graph G(c) is an
induced subgraph of GQ, where G(c) is the graph obtained from T by contracting
all edges that are not labeled by c. Essentially, this new condition means that the
state transitions for each character c must respect GQ. Note that in [3], where
the idea of restricting the transitions has originated, they focused on the case
when GQ is a tree. In Binary Perfect Phylogeny with missing entries [32], for
example, Q = {0, 1} and GQ = 0 →1, where missing entries correspond to the
subset {0, 1} of Q.
From a biological point of view, the most interesting case is when Q =
{0, 1, 2} and GQ consists of the two arcs 0 →1, 1 →2 — representing the
progression from absent to present to dormant [3] — the case that spurred this
study [3] to begin with. Unfortunately, this case is NP-complete [3], motivating
the search for diﬀerent variants of the problem. The ﬁrst algorithmic results in
this context is a polynomial-time algorithm for the case when the set of states
in each entry of M induces a directed path on GQ [3]. Note that Binary Perfect
Phylogeny with missing entries is such a case, and so the above result (also)
implies that it is polynomial-time solvable.
A subcase of this case of the GCC has also been studied under the name of
the Persistent Phylogeny problem [6,7,23]. This problem allows exactly one
edge to be labeled by (c, 1) or (c, 0), for each character c. The edge labeled by
(c, 1) represents the loss (or the transition to the dormant state) of the character
c, which is deemed to be possible exactly once in the entire tree T.
Recently there have been some important advances on the Persistent Phy-
logeny problem, most notably an exhaustive combinatorial algorithm [6], an ILP
algorithm [23], and a polynomial-time algorithm [9]. All these algorithms are
based on the notions of extended matrix.
The extended matrix Me associated to the input matrix M, is obtained by
replacing each column c of M with two columns (c+, c−). Moreover for each
row s of M, Me[s, c+] = 1 and Me[s, c−] = 0 whenever M[s, c] = 1, while
Me[s, c+] = Me[s, c−] = ? otherwise. Solving the instance M corresponds to
completing the extended matrix Me [6], that is, replacing the question marks
with 0 or 1, obtaining a new matrix Mf which is equal to Me for all species s
and characters c such that Me[s, c] ̸= ?, while Mf[s, c+] = Mf[s, c−] whenever
Me[s, c] = ?. The idea of completing a matrix with missing data in order to
obtain a perfect phylogeny has been introduced in [32] (Fig. 2).
In [28,29], the authors began a systematic study of this case of the GCC
problem when Q = {0, 1, 2}, GQ is 0 →1 →2 and generalized characters
are chosen from the collection {{0}, {1}, {2}, {0, 2}, {0, 1, 2}}. Additionally, the
study involved restricting the topology of the phylogeny that is a solution to
the problem to (a) a branch phylogeny (i.e., no node is branching, even the
root) and (b) a path phylogeny (only the root has 2 branches) and (c) the tree
(the general case). See Fig. 3 for examples of a branch and a path phylogeny.

Character-Based Phylogeny Construction and Its Application
7
Table 1. Complexity of all cases of the GCC Problem when Q = {0, 1, 2}, GQ is 0 →
1 →2 and set of states chosen from the collection Q ⊆{{0}, {1}, {2}, {0, 2}, {0, 1, 2}}.
A ? means that the case remains open.
Q\soln
Branch
Path
Tree
1
Q ⊆{{0}, {1}, {2}}
P [1]
P [1]
P [1,3]
2
{{0, 1, 2}} ⊆Q ⊆{{0}, {1}, {2}, {0, 1, 2}}; |Q| ≤2
trivial
trivial
trivial
3
{{0, 1, 2}} ⊆Q ⊆{{0}, {1}, {2}, {0, 1, 2}}; |Q| ≥3
P [29]
NP-c [29]
P [3]
4
Q ⊆{{0}, {0, 2}, {0, 1, 2}} ∨Q ⊆{{2}, {0, 2}, {0, 1, 2}}
trivial
trivial
trivial
5
{{1}, {0, 2}}
P [28]
P [28]
P [9]
6
{{0}, {1}, {0, 2}}
P [28]
NP-c [29]
?
7
{{0}, {2}, {0, 2}}(∪{{0, 1, 2}})
P [29]
NP-c [29]
P [3]
8
{{1}, {2}, {0, 2}}
P [28]
P [29]
?
9
{{0}, {1}, {2}, {0, 2}}
P [28]
NP-c [29]
?
10
{{1}, {0, 2}, {0, 1, 2}} ⊆Q
NP-c [28]
NP-c [29]
NP-c [3]
c1 c2 c3 c4 c5 c6 c7 c
M
8
s1 0 0 0 1 0 0 0 1
s2 0 0 1 1 1 1 0 0
s3 0 1 1 0 0 0 0 0
s4 1 1 0 0 0 0 0 0
s5 1 1 1 0 1 0 1 0
s6 0 1 1 1 1 0 0 0
s2
(c6, 1)
s6
s3
(c1, 0)
s4
(c3, 0)
(c5, 0)
s5
(c7, 1)
(c1, 1), (c4, 1)
(c2, 1)
(c3, 1), (c5, 1)
s1
(c8, 1)
(c4, 1)
Fig. 2. A binary matrix M of size 6 × 8 that is explained by the persistent phylogeny
on the right. The boldfaced entries of M correspond to two characters (c2 and c4)
inducing the states (0, 1) (1, 0) and (1, 1), hence M cannot be explained by a perfect
phylogeny.
The reason for studying the restrictions to branch and path phylogies is that
70% of real instances of human genotype data that admit a tree phylogeny also
admit a path phylogeny [19]. The results of this study are summarized in Table 1.
The tractable cases of Table 1 can be summarized as follows. First of all,
1(branch–tree) are cases of [1] — 1(tree) also implied by the algorithm in [3].
In [28], the authors show that 5(branch–path) are equivalent to the linear-time
solvable Consecutive-Ones Property (C1P) problem [10]. The C1P problem is,
given an n×m binary matrix M, to decide if there is an ordering of the columns
of M in such a way that for each row, the set of columns that are 1 in the row
appear consecutively — such an ordering is called a consecutive-ones ordering.

8
G.D. Vedova et al.
The C1P can be solved in time O(n+m+f) [10], where f is the number of non-
zero entries in M, by giving an algorithm that builds a so-called PQ-tree [10], a
structure that encodes all consecutive-ones orderings of M. In fact, 6(branch),
8(branch) and 9(branch) are based on algorithm that uses the PQ-tree that runs
in time O(nm4 + f). Then, in [29], the follow-up to [28], the authors show that
8(path) can be reduced to solving case 8(branch). While 3(tree) and 7(tree) are
tractable given the algorithm of [3], in [29], the authors give an algorithm based
on this one for the case where the solution must be a branch and the set of states
in each entry of M induces a directed path on GQ. Problem 6(tree) has also been
called Constrained Persistent Phylogeny [8].
For completeness, 10(tree) was shown to be NP-complete in [3]. The remain-
ing cases in Table 1 have been shown to be NP-complete [28,29] by reduction
from diﬀerent versions of the NP-complete Path Triple Consistency (PTC) prob-
lem of [28]. The PTC problem is, given a set V = {1, . . . , n} and a collection of
triples {a, b, c} from V , does there exist a path P = (V, E) (an ordering) on the
elements of V such that for each triple, there exists an edge e ∈E of P whose
removal separates {a, b} from c in P.
After this study, the case 9(tree), which motivated [3] remains open. The most
recent development in Table 1 is a polynomial-time algorithm for 5(tree) [9],
which we have previously introduced as the Persistent Phylogeny problem.
Finally, it remains to complete this study for all possible inputs to the GCC
problem when GQ = 0 →1 →2, i.e., generalized characters can be chosen from
any subset of {0, 1, 2}.
A diﬀerent way to generalize the CC problem is to allow each character-state
pair (c, q) to induce more than one connected component of T. The notion of ℓ-
phylogeny [18] has been introduced for this purpose. Without loss of generality,
we can assume that the set Q of states is the set of integers between 0 and
|L| −1. Let (ℓ0, . . . , ℓ|L|−1) be a sequence of |L| integers. Then, given a matrix
M, an (ℓ0, . . . , ℓ|L|−1)-phylogeny explaining M is a tree T explaining M such
that for each state q ∈Q and for each character c ∈C the subgraph induced
s3
s1
s2
s2
s1
s3
Fig. 3. Examples of a branch phylogeny (left), and a path phylogeny (right) on some
set S = {s1, s2, s3} of species

Character-Based Phylogeny Construction and Its Application
9
by the set l−1
c (q) has at most at most ℓq connected components, where l−1
c (q)
is the set of nodes of T where the character c has state q. In other words, for
each character each state q can be acquired at most ℓq times in the tree T.
Unfortunately, this direction has led mostly to NP-complete problems, such as
ﬁnding an (ℓ, . . . , ℓ)-phylogeny when ℓ> 1 [18].
Two cases that have been left open in [18] are ﬁnding a (2, 1)-phylogeny and
a (2, 2)-phylogeny. Notice that the Persistent Phylogeny problem is equivalent
to ﬁnding a (2, 1)-phylogeny [36], hence that problem has been settled [9].
3
Tumor Evolution
An important application of phylogenetic trees is the evolutionary reconstruction
of the history of tumor cells. Cancer can be seen as an uncontrolled evolution-
ary process of somatic mutations of tumor cells from a single founder cell [20]
creating a diverse set of subpopulations [12,27,37]. From this point of view, rep-
resenting tumor progression could be stated as a phylogeny reconstruction prob-
lem by considering a particular subpopulation of mutated cells as the species
and mutations as characters. Nowadays, single cell sequencing is still a daunt-
ing process [31]. Instead, the most common procedure in cancer patients is to
extract and sequence multiples samples of the tumor tissue. Each of these sam-
ples contains millions of cells which come from multiple tumor subpopulations
called clones. From sequencing data we can obtain the variant allele frequency
(VAF) which corresponds to the proportion of cells in the sample containing a
somatic mutation.
The natural problem in this framework is to infer, only from VAF data,
the mutations present in the clone subpopulations and their history, that is,
a phylogeny that can explain the input VAF data. Formally speaking, VAF
information for p samples and m somatic mutations can be stored in a p × m
(frequency) matrix F where F[t, j] represents the proportion of cells in sample t
that have the mutation j. If n clones are supposed to be present in the samples,
they can be described by a binary n × m matrix B where M[i, j] represents the
presence or absence of mutation j in the i-th clone: hence B is a matrix that can
be explained by a perfect phylogeny. Finally, the p×n (usage) matrix U describes
the relative proportion of clones in each sample, that is, U[t, i] corresponds to
the proportion of the cells in the sample belonging to the subpopulation i. From
these deﬁnitions, given the frequency matrix F, our problem can be stated as the
following matrix factorization problem F = 1
2UB [14], where clonal matrix B
respects a phylogenetic evolutionary model (usually a perfect phylogeny) — the
1
2 is a technical consequence of the fact that each human being has two copies of
each chromosome and a mutation aﬀects only one of these two copies. Figure 4
presents an instance of the problem and a solution.
Many works have been proposed under diﬀerent assumptions like a single
sample [30,35] or considering diﬀerent underlying evolutionary processes. From
a theoretical perspective, the problem of the reconstruction of a perfect phyloge-
netic history for multiple samples is NP-complete [14] even for binary trees [24].

10
G.D. Vedova et al.
Normal
Sample 1
Sample 2
F =
0.1 0.3 0.3 0.2 0.1 0
0 0.2 0.5 0
0 0.4

F = 1
2
 0 0.2 0.2 0 0.2
0.4 0 0.4 0.2 0




U
⎡
⎢⎢⎢⎢⎣
0 0 1 0 0 1
0 1 1 1 1 0
0 1 1 0 0 0
0 0 1 0 0 0
1 1 1 1 0 0
⎤
⎥⎥⎥⎥⎦



B
c3
c6
c2
c4
c5
c1
Sample 1
Sample 2
Fig. 4. Example of the phylogenetic clonal reconstruction for the tumor composition
problem. On the top, we have (on the left) the actual unknown evolutionary history
and the actual unknown clonal subpopulations, where each colored dot is a mutation;
(center) the cells in the tumor tissue and in the samples; (on the right) the resulting
VAF matrix that is the instance of our problem. On the bottom, we have (on the left)
the solution of the instance expressed as the matrices U and B; (on the right) the
solution of the instance expressed as the perfect phylogeny.
Nevertheless, the authors of [14] propose a mixed tools strategy of combinatorial
and integer linear programming approaches to ﬁnd a feasible solution for the
reconstruction problem. The multi-state generalization [17] of the binary model
is studied in [15] where the authors provided an algorithm to enumerate all pos-
sible evolutionary trees explaining the observed proportion under the multi-state
perfect phylogenetic model.
4
Conclusions
In this survey we have brieﬂy introduced the current status of character-based
phylogeny. We conclude the paper with a short discussion on the open problems.
In Table 1 we have classiﬁed several problems, describing only if they are NP-
complete or if they have a polynomial-time algorithm. Some of the known algo-
rithms are not optimal, hence designing faster algorithms is a possible direction.

Character-Based Phylogeny Construction and Its Application
11
The study of approximation or ﬁxed-parameter algorithms in this ﬁeld is
only in its infancy. Since all problems presented here are decision problems, the
best choice of an objective function is not clear.
Finally, we leave the reader two problems that have been left open from [18] —
more than two decades ago — on a matrix M: (1) ﬁnding an (ℓ, ℓ, . . . , ℓ)-
phylogeny explaining M when k > 2 is a constant and ℓ> 1, and (2) ﬁnding a
(2, 2)-phylogeny explaining M.
Acknowledgments. We acknowledge the support of the MIUR PRIN 2010–
2011 grant “Automi e Linguaggi Formali: Aspetti Matematici e Applicativi” code
2010LYA9RH, of the Cariplo Foundation grant 2013–0955 (Modulation of anti cancer
immune response by regulatory non-coding RNAs), of the FA grants 2013-ATE-0281,
2014-ATE-0382, and 2015-ATE-0113.
References
1. Agarwala, R., Fern´andez-Baca, D.: A polynomial-time algorithm for the perfect
phylogeny problem when the number of character states is ﬁxed. SIAM J. Comput.
23(6), 1216–1224 (1994)
2. Bafna, V., Gusﬁeld, D., Lancia, G., Yooseph, S.: Haplotyping as perfect phylogeny:
a direct approach. J. Comput. Biol. 10(3–4), 323–340 (2003)
3. Benham, C., Kannan, S., Paterson, M., Warnow, T.: Hen’s teeth and whale’s feet:
generalized characters and their compatibility. J. Comp. Biol. 2(4), 515–525 (1995)
4. Bodlaender, H.L., Fellows, M.R., Warnow, T.J.: Two strikes against perfect phy-
logeny. In: Kuich, W. (ed.) ICALP 1992. LNCS, vol. 623, pp. 273–283. Springer,
Heidelberg (1992). doi:10.1007/3-540-55719-9 80
5. Bonizzoni, P.: A linear-time algorithm for the perfect phylogeny haplotype prob-
lem. Algorithmica 48(3), 267–285 (2007)
6. Bonizzoni, P., Braghin, C., Dondi, R., Trucco, G.: The binary perfect phylogeny
with persistent characters. Theor. Comput. Sci. 454, 51–63 (2012)
7. Bonizzoni, P., Carrieri, A.P., Della Vedova, G., Rizzi, R., Trucco, G.: A colored
graph approach to perfect phylogeny with persistent characters. Theor. Comput.
Sci. 658, 60–73 (2016)
8. Bonizzoni, P., Carrieri, A.P., Della Vedova, G., Trucco, G.: Explaining evolution
via constrained persistent perfect phylogeny. BMC Genomics 15(6), S10 (2014)
9. Bonizzoni, P., Della Vedova, G., Trucco, G.: Solving the persistent phylogeny prob-
lem in polynomial time. CoRR, abs/1611.01017 (2016)
10. Booth, K.S., Lueker, G.S.: Testing for the consecutive ones property, interval
graphs, and graph planarity using PQ-tree algorithms. J. Comput. Syst. Sci. 13(3),
335–379 (1976)
11. Buneman, P.: The recovery of trees from measures of dissimilarity. In: Hodson,
F.R., Kendall, D.G., Tautu, P. (eds.) Mathematics in the Archaelogical and His-
torical Sciences. Edinburgh University Press, Edinburgh (1971)
12. Ding, L., Raphael, B.J., Chen, F., Wendl, M.C.: Advances for studying clonal
evolution in cancer. Cancer Lett. 340(2), 212–219 (2013)
13. Ding, Z., Filkov, V., Gusﬁeld, D.: A linear-time algorithm for the perfect phylogeny
haplotyping (PPH) problem. J. Comput. Biol. 13(2), 522–553 (2006)

12
G.D. Vedova et al.
14. El-Kebir, M., Oesper, L., Acheson-Field, H., Raphael, B.J.: Reconstruction of
clonal trees and tumor composition from multi-sample sequencing data. Bioin-
formatics 31(12), i62–i70 (2015)
15. El-Kebir, M., Satas, G., Oesper, L., Raphael, B.: Inferring the mutational history
of a tumor using multi-state perfect phylogeny mixtures. Cell Syst. 3(1), 43–53
(2016)
16. Felsenstein, J.: Inferring Phylogenies. Sinauer Associates, Sunderland (2004)
17. Fernandez-Baca, D.: The perfect phylogeny problem. In: Du, D.Z., Cheng, X. (eds.)
Steiner Trees in Industries. Kluwer Academic Publishers, Dordrecht (2000)
18. Goldberg, L.A., Goldberg, P.W., Phillips, C.A., Sweedyk, E., Warnow, T.: Mini-
mizing phylogenetic number to ﬁnd good evolutionary trees. Discrete Appl. Math.
71(1–3), 111–136 (1996)
19. Gramm, J., Nierhoﬀ, T., Sharan, R., Tantau, T.: Haplotyping with missing data
via perfect path phylogenies. Discrete Appl. Math. 155, 788–805 (2007)
20. Greaves, M., Maley, C.C.: Clonal evolution in cancer. Nature 481(7381), 306–313
(2012)
21. Gusﬁeld, D.: Eﬃcient algorithms for inferring evolutionary trees. Networks 21,
19–28 (1991)
22. Gusﬁeld, D.: Algorithms on Strings, Trees and Sequences: Computer Science and
Computational Biology. Cambridge University Press, Cambridge (1997)
23. Gusﬁeld, D.: Persistent phylogeny: a galled-tree and integer linear programming
approach. In: Proceedings of the 6th ACM BCB Conference, pp. 443–451 (2015)
24. Hajirasouliha, I., Mahmoody, A., Raphael, B.J.: A combinatorial approach for ana-
lyzing intra-tumor heterogeneity from high-throughput sequencing data. Bioinfor-
matics 30(12), i78–i86 (2014)
25. Kannan, S., Warnow, T.: A fast algorithm for the computation and enumeration
of perfect phylogenies. SIAM J. Comput. 26(6), 1749–1763 (1997)
26. Kollar, E., Fisher, C.: Tooth induction in chick epithelium: expression of quiescent
genes for enamel synthesis. Science 207, 993–995 (1980)
27. Lawrence, M.S., Stojanov, P., et al.: Mutational heterogeneity in cancer and the
search for new cancer-associated genes. Nature 499(7457), 214–218 (2013)
28. Maˇnuch, J., Patterson, M., Gupta, A.: On the generalised character compatibil-
ity problem for non-branching character trees. In: Ngo, H.Q. (ed.) COCOON
2009. LNCS, vol. 5609, pp. 268–276. Springer, Heidelberg (2009). doi:10.1007/
978-3-642-02882-3 27
29. Maˇnuch, J., Patterson, M., Gupta, A.: Towards a characterisation of the gener-
alised cladistic character compatibility problem for non-branching character trees.
In: Chen, J., Wang, J., Zelikovsky, A. (eds.) ISBRA 2011. LNCS, vol. 6674,
pp. 440–451. Springer, Heidelberg (2011). doi:10.1007/978-3-642-21260-4 41
30. Miller, C.A., et al.: Sciclone: inferring clonal architecture and tracking the spatial
and temporal patterns of tumor evolution. PLoS Comput. Biol. 10(8), e1003665
(2014)
31. Navin, N.E.: Cancer genomics: one cell at a time. Genome Biol. 15(8), 452 (2014)
32. Pe’er, I., Pupko, T., Shamir, R., Sharan, R.: Incomplete directed perfect phylogeny.
Siam J. Comput. 33(3), 590–607 (2004)
33. Przytycka, T., Davis, G., Song, N., Durand, D.: Graph theoretical insights into
evolution of multidomain proteins. J. Comput. Biol. 13(2), 351–363 (2006)
34. van Rens, K.E., M¨akinen, V., Tomescu, A.I.: SNV-PPILP: reﬁned SNV calling for
tumor data using perfect phylogenies and ILP. Bioinf. 31(7), 1133–1135 (2015)
35. Roth, A., Khattra, J., et al.: Pyclone: statistical inference of clonal population
structure in cancer. Nat. Methods 11(4), 396–398 (2014)

Character-Based Phylogeny Construction and Its Application
13
36. Steel, M.A.: Phylogeny: Discrete and Random Processes in Evolution. CBMS-NSF
Regional Conference Series in Applied Mathematics. SIAM, Philadelphia (2016)
37. Vogelstein, B., Papadopoulos, N., Velculescu, V.E., Zhou, S., Diaz, L.A., Kinzler,
K.W.: Cancer genome landscapes. Science 339(6127), 1546–1558 (2013)

Is there any Real Substance to the Claims
for a ‘New Computationalism’?
Alberto Hern´andez-Espinosa1, Francisco Hern´andez-Quiroz1,
and H´ector Zenil2,3,4(B)
1 Departamento de Matem´aticas, Facultad de Ciencias, UNAM, Mexico City, Mexico
albertohernandezespinosa@gmail.com, fhq@ciencias.unam.mx
2 Department of Computer Science, University of Oxford, Oxford, UK
3 Information Dynamics Lab, Karolinska Institutet, Stockholm, Sweden
4 Algorithmic Nature Group, LABORES, Paris, France
hector.zenil@algorithmicnaturelab.org
Abstract. Computationalism is a relatively vague term used to describe
attempts to apply Turing’s model of computation to phenomena outside
its original purview: in modelling the human mind, in physics, mathe-
matics, etc. Early versions of computationalism faced strong objections
from many (and varied) quarters, from philosophers to practitioners of
the aforementioned disciplines. Here we will not address the fundamental
question of whether computational models are appropriate for describing
some or all of the wide range of processes that they have been applied
to, but will focus instead on whether ‘renovated’ versions of the new
computationalism shed any new light on or resolve previous tensions
between proponents and skeptics. We ﬁnd this, however, not to be the
case, because the new computationalism falls short by using limited ver-
sions of “traditional computation”, or proposing computational models
that easily fall within the scope of Turing’s original model, or else prof-
fering versions of hypercomputation with its many pitfalls.
Keywords: Computationalism ·
Classical
computation ·
Natural
computation · Computability · Turing machine model
1
Classical vs. Non-classical Computation
The simplest view of the Turing machine model (TM) construes it as a decision
problem solver, tackling such questions as whether a certain string represents a
prime number or whether a certain other string belongs to a context-free lan-
guage. Of course, this view is rather restrictive, as there are many interesting
questions that cannot be answered with a simple “yes” or “no”. But TMs can be
viewed as mechanisms for calculating functions, with the input string represent-
ing the argument(s) of the function and the string left on the tape at halting time
Invited contribution to Computability in Europe (CiE) 2017 – ‘Unveiling Dynamics
and Complexity’.
c
⃝Springer International Publishing AG 2017
J. Kari et al. (Eds.): CiE 2017, LNCS 10307, pp. 14–23, 2017.
DOI: 10.1007/978-3-319-58741-7 2

New Computationalism?
15
representing the result. Given the easy correspondence between natural numbers
and ﬁnite strings in an alphabet, a TM can be said to calculate a function from
natural numbers to natural numbers. Decision problems can be viewed as special
cases of functions from natural numbers to natural numbers.
A basic set-theoretical argument tells us that there are many more functions
from natural numbers to natural numbers than there are possible TMs and, ergo,
that most functions cannot be computed by TMs. The halting problem is one
such function.
Within the ﬁeld of classical computation, and indeed coeval with the intro-
duction of classical computation, certain forms of non-classical computation were
devised, such as the oracle machine, which was introduced by Turing himself [31].
Here we do not aim to add to the already lengthy list of possible objec-
tions to hypercomputation, which claims the feasibility of computational models
that may go beyond the Turing limit in theory but not in practice. Instead we
oﬀer an analysis and criticism of supposedly new models of computation that
claim to be diﬀerent from and even to exceed (regardless of whether or not they
can be classiﬁed as hypercomputation) the classical Turing model in their abil-
ity to describe how nature works and–so it is claimed–compute in radical or
innovative ways.
2
A Brief Roadmap to Computationalism
While there is no current consensus as to the validity of attacks on classical
computationalism, nowadays many researchers in diﬀerent ﬁelds seem to agree
that new models of computation are needed in order to overcome such objections
(for a summary of which see [12]).
In this paper we will refer to the former type of computationalism as classical
computationalism and to the latter type as new computationalism. The new
computationalist wave is a highly varied mix which encompasses both rejections
of Turing’s model and appeals to “natural” computation.
In the decades following Turing’s introduction of his formalization of eﬀec-
tive procedure (as deﬁned in [14]) in his seminal paper [30,31], and especially
after the widespread and profound success of electronic computers in science
and engineering (now universally regarded as incarnations of Turing’s mathe-
matical model), there was a strong impulse to not only use computers in every
ﬁeld within sight but also to view them as models of how things really are, the
computational model of the human mind being quite probably one of the most,
if not the most, iconic instance of this tendency [24]. The process of encoding
(or rewriting/or reinterpreting) a problem as a ﬁnite sequence of symbols which
could be manipulated mechanically by Turing machines in order to solve it is
what came to be referred to as classical computationalism.
Very soon dissenting voices raised objections based on (controversial) inter-
pretations of G¨odel’s theorems [17,23], failures to close the gap between mechan-
ical processing of information and real understanding of it [25,26], and the obvi-
ous diﬀerences between the way brains process information and the particular

16
A. Hern´andez-Espinosa et al.
operation of a Turing machine. The crisis in Artiﬁcial Intelligence in the 1980s [4]
did not help to advance the cause of computationalism, as some early eﬀorts to
apply computers to (seemingly) not very complex human abilities like language
translation or vision failed miserably. That the objectors to computationalism
were not able to present better models of the human mind did not lead them to
demur.
The time was ripe for bold proposals to overcome the impasse. Among the
most popular were hypercomputation and some forms of natural computing,
together with what we will classify as ‘other models of computation’ based upon
variations of the operation of classical models.
3
The Uninstantiation of Hypercomputation
A mechanism more powerful than any TM must be able to compute more func-
tions than a TM can. If it merely calculates what a TM does, only (ﬁnitely)
faster, or more intuitively or with less hassle for its creator, then we cannot say
it is computationally more powerful, as it can be simulated by a TM. The Church-
Turing thesis states that any formalism capturing what an eﬀective procedure
is will be equivalent to a TM [15]. The Church-Turing thesis is much maligned
among neo- and hyper-computationalists, but as Sieg [27] has shown (following
ideas ﬁrst advanced by Gandy [9]), it can be reduced to two very basic princi-
ples: boundedness and locality conditions. The former implies that a computing
device can immediately recognize only a bounded number of conﬁgurations, the
latter that a computing device can change only immediately recognizable con-
ﬁgurations. In (perhaps) oversimpliﬁed terms, in order to overcome the TM’s
limits, the device must be able to either access an inﬁnite amount of information
or must act upon places that are not immediately accessible in a ﬁnite num-
ber of operations. Sieg’s formulation does not imply a proof of Church’s thesis,
but instead establishes a mathematical baseline for the kind of device needed to
violate the so-called Turing limit.
Such devices may exist or may eventually be created, but they must act very
diﬀerently from our current computers and cannot be based on trivial variations
of classical models.
Some models for hypercomputation include the Oracle Turing Machine
model [32], analog recurrent neural networks [29], and analog computation [22].
However, these models are just theoretical constructs, and not only are there
no actual devices based on them or physical processes which correspond to them
(as far as we know), but there is no prospect of turning them into concrete,
viable tools for research in the foreseeable future (even Turing did not have such
an eventuality in mind). See Davis’ paper on hypercomputation [5] for a critique
of those who think otherwise. As we consider Davis’ analysis quite complete and
well founded, we shall dwell no further on this issue and we will conclude this
section by saying that non-existence and breach of physical laws (mainly the
2nd. law of thermodynamics) are good reasons to overlook hypercomputation as
a meaningful alternative to computation.

New Computationalism?
17
More recently, Maldonado [18,19] has oﬀered a defense of a form of biological
hypercomputation, claiming that: “[...] life is not a standard Turing Machine”,
but rather that living systems hypercompute, and that an understanding of life
is reached not by grasping what life is but what it does.
It has even been suggested that phenomena such as death can be sources of a
sort of uncomputability, due to the alleged incapability of information theory to
describe death or to have it programmed into a system as a desirable property
so as to provide meaning to artiﬁcial life–just as it does in the case of natural
life [8]. Molecular biology, however, can explain death, using straightforward
analogies to computation and reprogramming contextualized within information
theory [37].
However, that science has not yet fully explained life and death, among other
things, does not mean that it will not do so in the future. Thus we consider the
claim that neither computationalism nor information theory can explain death
(and hence life, according to [8]) shortsighted, if not simply incorrect. Since the
discovery of DNA we have known that developmental and molecular biology
(and thus biology) are mostly information theoretic, and the more we explore
these ﬁelds the more we ﬁnd to conﬁrm our sense that this is indeed the case.
4
Natural Computation
Nature is a rich source of ideas and there has lately been a turn toward natural
computation in the literal sense. Of course, there is nothing wrong with looking
to natural phenomena for inspiration. Wolfram takes a very pragmatic approach
in his epistemological treatise, a non-classical exploration of the classical compu-
tational universe, ﬁnding qualitative parallels between nature and computation,
with nature harnessing the power of classical computation as a natural source
of algorithmic creativity [35].
Others, however, have gone further, oﬀering a divergent notion of computa-
tion by attacking classical computation, alleging that a set of constraints that
have been in place from the inception of the classical model of computation have
handicapped not only the model but the scientiﬁc and technological progress of
computation as such. The common idea behind most, if not all of these objections
to the classical model is that nature does not operate like a Turing machine–
because, e.g., nature works in parallel over analog information [7], because nature
does more than solve problems [18], and because, it is claimed, there is no way
to construct a machine with an inﬁnite tape [7].
Perhaps the most puzzling aspect of the arguments of a group of researchers
looking for new notions or types of computation is that while openly accepting
that (natural) computing is about information processing (as is classical compu-
tation) [6], and also that nature certainly computes (because computers exist in
and within nature), they posit a diﬀerent kind of computation than the classi-
cal one [19] while using nature as evidence for non-Turing computation. At the
same time none of them speciﬁes exactly what makes this kind of computation
distinctive, beyond stressing its diﬀerence from a Turing machine (or a trivial

18
A. Hern´andez-Espinosa et al.
modiﬁcation of a Turing machine, e.g., a non-terminating one, such as a cellu-
lar automaton, which can hardly be classiﬁed as non-classical). Such a line of
reasoning eventuates in a trivialized natural computation thesis.
Another objection to this view is that by generalizing the notion of compu-
tation to any process that transforms its environment, it renders the concept
vacuous. The speciﬁcity of symbolically encoding problems and solving them
by a set of ﬁnite, formal rules is then lost. Mechanics, process, transformation
and computation are all synonyms. Again there is nothing wrong with this per
se, but in practical terms this trend does not point out how to attack prob-
lems with our current computers, which happen to be (less than ideal) Turing
machines. In other words, an extension of the concept of computation should
require an enhancement of computers. At present it is highly debatable where
this enhancement will come from, but this line of thought deﬁnitely takes us
back to hypercomputational ground.
5
Not More but Equally Powerful
Finally there is an abundance of computational models that have sometimes
been touted as more powerful alternatives to Turing machines, but on inspec-
tion turn out to be mathematically equivalent to Turing’s model. Of course, a
diﬀerent model may give us a new, powerful insight into an aspect of computa-
tion obscured by the rigidity of Turing machines (mind you, they were supposed
to be rigid in the extreme). This is the case with numerous models of concurrent
and distributed computation [21]. But this does not mean that these models
solve problems a Turing machine cannot. Being the good theoreticians they are,
the people behind concurrent or distributed models have not made any such
claim.
Of course, the mathematical equivalence between the TM model and many
others (programming languages, concurrent computation, etc.) does not mean
that the latter are superﬂuous. They were introduced to solve real, important
problems for which TMs did not provide a clear or manageable way of expressing
the actual questions. If, for instance, you are trying to capture the fundamental
issues of communication and synchronization dealt with by the π-calculus [20]
you will not get very far by encoding them as a string to be manipulated by
a sequential TM with its mind-boggling (and mostly irrelevant) details, even if
this were theoretically possible. In other words, we are not challenging the utility
of alternatives to the TM, only the claim that some models can do what no TM
can in principle.
Among other models is the Interaction machine model that “extend[s] the
Turing Machine model by allowing interaction, i.e. input and output actions
(read and write statements) determined by the environment at each step of the
computation” [33,34], π-calculus, “a mathematical model of processes whose
interconnections change as they interact” [20,21]. Scott Aaronson oﬀers a whim-
sical characterization of the Interactive model [1]. It is puzzling that interactive
computations cannot simply be viewed as independent classical computations.

New Computationalism?
19
Moreover, software such as operating systems are implementations of highly
interactive programs. They were introduced early in the development of the ﬁrst
computers, and concurrent computation is an active area of research where these
kinds of questions are addressed within a very classical–so to speak–framework.
Nothing in Turing’s model prevents an external observer or machine from inter-
acting with the working tape of the original machine, thus eﬀectively interacting
with the machine itself.
Another model is the Inductive computing model in the context of what the
author has called ‘super-recursive algorithms [2]. In many respects, the induc-
tive machine model is not comparable to classical computation, but there is one
respect in which it is not that far removed from a certain form of such compu-
tation. Inductive computation does not produce a deﬁnitive output and is thus
similar to transducers, and like cellular automata they do not terminate, sug-
gesting a transducer or cellular automaton-type of computation that supposedly
generalizes the classical Turing machine model.
Many of the objections based upon models such as that of Gurevich [10], even
when deployed with intent to disprove the Church-Turing Thesis [11]–in what
constitutes a clear misunderstanding of the philosophical basis and content of
said thesis [28]–are based upon, for instance, the argument that Turing machines
cannot deal with structures other than strings on tapes, even when trivial mod-
iﬁcations that preserve all of their classical properties have been made, modiﬁ-
cations that in no way imply the invalidity of the original TM model [16] (for
example, models of Turing machines operating on grids preserving, say, algorith-
mic information properties [36]. This does not mean, however, that such models
cannot be useful, a case in point being high-level descriptions of classical com-
putation, with Gurevich’s [10] model being put to very practical use nowadays
in software engineering, as a tool for software modelling.
6
Old Dogs, New Tricks
A standard for surpassing the Turing model and disproving the Church-Turing
thesis must entail something far more stringent than trivial modiﬁcations of
classical computation. Of course, the main question is what constitutes a non-
trivial modiﬁcation of the classical model, a modiﬁcation that does more than
simply introduce an inﬁnite element which merely takes the purportedly feasible
new model into the hypercomputation category.
We consider the use of the expression “more powerful” as merely metaphor-
ical unless speciﬁcs are provided as regards what makes a given model more
powerful. Likewise, if as soon as such a model is instantiated it merely becomes
as powerful as or else not comparable to classical computation.
An example of a trivial modiﬁcation (to modern eyes) that has been accepted
as not leading to more computational power other than speed-up is the use of
additional machine tapes.
In the same fashion then, when it is claimed that concurrent computation
is more powerful than TMs as TMs are crippled by their ‘sequentiality’ (bear-
ing in mind that though concurrency can be properly simulated in sequential

20
A. Hern´andez-Espinosa et al.
TMs, doing so is very cumbersome), we do not consider such an objection to
be an objection in principle, as it is not related to the inability of the model
to undergo minor changes without changing anything more than the details of
its operation. Or that object oriented programming is more powerful because
it is heuristically superior to clumsy TMs (although again TMs can simulate
object oriented programming—with overhead). Similarly, objections concerning
speed, illustrated by, e.g., quantum computing, do not fall into the category of
fundamental challenges to the model, having to do only with its operation.
A model claimed to be more powerful than classical models is the so-called
‘actor’ model that, according to its originator, was inspired by physics, includ-
ing general relativity and quantum mechanics. It was also inﬂuenced by the
programming languages Lisp, Simula and early versions of Smalltalk, as well as
capability-based systems and packet switching. Its development was “motivated
by the prospect of highly parallel computing machines consisting of dozens, hun-
dreds, or even thousands of independent microprocessors, each with its own local
memory and communications processor, communicating via a high-performance
communications network.” [3]
According to Hewitt [13], “concurrency extends computation beyond the con-
ceptual framework of Church, Gandy, G¨odel, Herbrand, Kleene, Post, Rosser,
Sieg, Turing, etc. because there are eﬀective computations that cannot be per-
formed by Turing Machines. . . . [and where] computation is conceived as distrib-
uted in space where computational devices communicate asynchronously and the
entire computation is not in any well-deﬁned state. (An actor can have stable
information about what it was like when it received a message.) Turing’s Model
is a special case of the Actor Model.” [13]
It appears trivial to most computer scientists that these models can be simu-
lated by classical models (e.g. by dovetailing on parallel computations on diﬀer-
ent inputs stored in diﬀerent tapes) as long as there are not an inﬁnite number of
interactions or an inﬁnite number of actors acting at the same time that would
violate the boundedness and locality principles of feasible models [27,28].
7
Conclusion
This paper does not attempt to disprove the existence of ways of overcoming
the limitations of the traditional Turing machine model or to provide a survey
of models of computation purported to go beyond the Turing model (whether
claiming the status of hypercomputation or not). Instead, it attempts to be a
reminder of what those limitations are and how far some claims have gone in
trying to establish a new type of computationalism, claims that are often, if not
always, (mistakenly) predicated on the apparent weakness of classical models,
weaknesses that are in fact only weaknesses of orthodox interpretations of their
operating details.
There are very good theoretical models of what life looks like that purport
to surpass the Turing machine model, but we are still far from being able to
put any of these models into practice, assuming it will ever be possible to do so.

New Computationalism?
21
Every few years we see a claim of this sort, and its technical merits should be
assessed in order to (most improbably) accept it or (as has been usual hitherto)
debunk it.
Clearly we have not gone in for clever new theorems or innovations attempt-
ing to analyze speciﬁc proposals that have been ﬂoated, which you may ﬁnd dis-
appointing (just good old theory). For our part we are even more disappointed
at not being able to acknowledge the appearance of novel and more solid ideas
and have not felt compelled to spend time producing a theorem to show that
a classical Turing machine can, for example, simply be extended to operate on
grids and other structures and still preserve its classical nature by virtue of pre-
serving all the theory of computation derived for it, respecting hierarchies and
at most achieving speed-up gains.
The common denominator of all these attacks on classical computation,
including Church’s thesis, is the impression they create of refuting an oppo-
nent’s argument though the arguments refuted are not ones that have actually
been advanced by anyone– what is called a straw man fallacy. In eﬀect disputes
are generated where there are none. For example, no serious researcher has ever
suggested that the mind, nature or the universe operates or is a mechanical
incarnation of a (universal) Turing machine.
In order to build sound objections against classical computation and com-
putationalism, we conclude that it is thus necessary to represent it in its full
spectrum, and not to adopt an old, abstract, symbol- manipulation view of com-
putation that is out of date or else has been oversimpliﬁed for other purposes.
References
1. Aaronson, S.: The Toaster-Enhanced Turing Machine, Blog entry. http://www.
scottaaronson.com/blog/?p=1121. Accessed 11 Feb 2017
2. Burgin, M.: Super-Recursive Algorithms. Monographs in Computer Science.
Springer, New York (2005)
3. Clinger, W.D.: Foundations of actor semantics. AITR-633 (1981)
4. Crevier, D.: AI: The Tumultuous History of the Search for Artiﬁcial Intelligence.
Basic Books, New York (1993)
5. Davis, M.: The myth of hypercomputation. In: Teuscher, C. (ed.) Alan Turing:
Life and Legacy of a Great Thinker, pp. 195–211. Springer, Heidelberg (2004)
6. Dodig-Crnkovic, G.: Signiﬁcance of models of computation, from turing model to
natural computation. Minds Mach. 21(2), 301–322 (2011)
7. Fresco, N.: Physical Computation and Cognitive Science. Studies in Applied Phi-
losophy, Epistemology and Rational Ethics, vol. 12. Springer, Heildeberg (2014)
8. Froese, T.: Life is precious because it is precarious: Individuality, mortality, and the
problem of meaning. In: Dodig-Crnkovic, G., Giovagnoli, R. (eds.) Representation
and Reality: Humans, Animals and Machines, Springer (in press)
9. Gandy, R.: Church’s thesis and the principles for mechanisms. In: Barwise, H.J.,
Keisler, H.J., Kunen, K. (eds.) The Kleene Symposium, pp. 123–148. North-
Holland Publishing Company (1980)
10. Gurevich, Y.: Sequential abstract state machines capture sequential algorithms.
ACM Trans. Comput. Log. 1(1), 77–111 (2000)

22
A. Hern´andez-Espinosa et al.
11. Gurevich, Y., Dershowitz, N.: A natural axiomatization of computatbility and
proof of the church’s thesis. Bull. Symbolic Logic. 14(3), 299–350 (2008)
12. Hern´andez-Espinosa, A., Hern´andez-Quiroz, F.: Does the principle of com-
putational equivalence overcome the objections against computationalism? In:
Dodig-Crnkovic, G., Giovagnoli, R. (eds.) Computing Nature Turing Centenary
Perspective. Studies in Applied Philosophy, Epistemology and Rational Ethics,
pp. 225–233. Springer, Heidelberg (2013)
13. Hewitt, C.: What is computation? Actor model versus turing’s model. In: A Com-
putable Universe, Understanding Computation and Exploring Nature as Compu-
tation. World Scientiﬁc Publishing Company/Imperial College Press, Singapore
(2013)
14. Hilbert, D.: Neubegrndung der Mathematik: Erste Mitteilung. Abhandlungen
ausdem Seminar der Hamburgischen Universit¨at 1, 157–177 (1922)
15. Kleene, S.C.: Introduction to Metamathematics. North-Holland, Amsterdam
(1952)
16. Langton, C.G.: Studying artiﬁcial life with cellular automata. Physica D: Nonlinear
Phenom. 22(1–3), 120–149 (1986)
17. Lucas, J.R.: Minds, machines and G¨odel. Philosophy 36(137), 112–127 (1961)
18. Maldonado, C.E., G´omez-Cruz, N.A.: Biological hypercomputation: A concept is
introduced (2012). arXiv preprint arXiv:1210.4819
19. Maldonado, C.E., G´omez-Cruz, N.A.: Biological hypercomputation: A new
research problem in complexity theory. Complexity 20(4), 8–18 (2015)
20. Milner, R.: Communicating, Mobile Systems: The Pi Calculus. Cambridge
University Press, Cambridge (1999)
21. Milner, R., Parrow, J., Walker, D.: A calculus of mobile processes. Inf. Comput.
100(1), 1–40 (1992)
22. Mycka, J., Costa, J.F.: A new conceptual framework for analog computation. The-
oret. Comput. Sci. 374(1–3), 277–290 (2007)
23. Penrose, R., Mermin, D.: The emperor’s new mind: Concerning computers, minds,
and the laws of physics. Am. J. Phys. 58(12), 1214–1216 (1990)
24. Putnam, H.: Representation and Reality. A Bradford Book, Cambridge (1988)
25. Searle, J.R.: Minds, brains, and programs. Behav. Brain Sci. 3(3), 417–424 (1980)
26. Searle, J.R.: Is the brain a digital computer? Proc. Addresses Am. Philos. Assoc.
64(3), 21–37 (1990). American Philosophical Association
27. Sieg, W.: Church without dogma: Axioms for computability. In: Cooper, S.B.,
L¨owe, B., Sorbi, A. (eds.) New Computational Paradigms, pp. 139–152. Springer,
New York (2008)
28. Sieg, W.: Axioms for computability: Do they allow a proof of church’s thesis? In:
Zenil, H. (ed.) A Computable Universe: Understanding and Exploring Nature as
Computation. World Scientiﬁc Publishing Press, Singapore (2013)
29. Siegelmann, H.T.: Recurrent neural networks and ﬁnite automata. Comput. Intell.
12(4), 567–574 (1996)
30. Turing, A.M.: On Computable Numbers, with an Application to the Entscheidung-
sproblem. Proc. London Math. Soc. 2(42), 230–265 (1936)
31. Turing, A.M.: On Computable Numbers, with an application to the Entscheidung-
sproblem: A correction. Proc. London Math. Soc. vol. 2 (published 1937). 43(6),
544–546 (1938)
32. Turing, A.M.: Systems of logic based on ordinals. Proc. London Math. Soc. 2(1),
161–228 (1939)
33. Wegner, P.: Why interaction is more powerful than algorithms. Commun. ACM
40(5), 80–91 (1997)

New Computationalism?
23
34. Wegner, P.: Interactive foundations of computing. Theoret. Comput. Sci. 192(2),
315–351 (1998)
35. Wolfram, S.: A New Kind of Science. Wolfram Media, Champaign (2002)
36. Zenil, H., Soler-Toscano, F., Delahaye, J.P., Gauvrit, N.: Two-dimensional
kolmogorov complexity and validation of the coding theorem method by com-
pressibility. Peer J. Comput. Sci. 1, 23 (2015)
37. Zenil, H., Schmidt, A., Tegn´er, J.: Causality, information and biological computa-
tion. In: Walker, S.I., Davies, P.C.W., Ellis, G. (eds.) Information and Causality:
From Matter to Life. Cambridge University Press (in press)

Formalizing a Fragment
of Combinatorics on Words
ˇStˇep´an Holub1(B) and Robert Veroﬀ2
1 Department of Algebra, Charles University, Prague, Czech Republic
holub@karlin.mff.cuni.cz
2 Computer Science Department, University of New Mexico, Albuquerque, USA
veroff@cs.unm.edu
Abstract. We describe an attempt to formalize some tasks in combina-
torics on words using the assistance of Prover9, an automated theorem
prover for ﬁrst-order and equational logic.
Keywords: Formalization · Periodicity · Combinatorics on words ·
Automated theorem proving
1
Motivation
In this paper we discuss a formalized approach to some tasks in combinatorics on
ﬁnite words. Formalization of mathematical knowledge classically has two rather
diﬀerent motivations. One is Automated Theorem Proving, where one hopes to
develop methods to ﬁnd (possibly diﬃcult, or just tedious) proofs automatically.
The second motivation is Formalization of Mathematics, that aims at human-
assisted computer veriﬁcation of (human originated) parts of mathematics.
A prominent example of the formalization approach has evolved around the
proof of Kepler’s conjecture announced by Thomas Hales in 1998 and subse-
quently reviewed by 13 reviewers of Annals of Mathematics for three years with-
out a conclusive verdict [10]. The situation in combinatorics on words is certainly
less dramatic, but there are some similar features. As an illustrative example, we
are looking at the classiﬁcation of binary equality words [2,3,5,7,8]. In addition
to important concepts, this project requires a lot of detailed case analysis which
is arduous to make, tedious and unrewarding to read and check, and therefore
possibly unreliable as to its correctness and/or completeness. Many of the argu-
ments are repetitious. All of this leads to a conclusion that formalization might
be a good idea. Moreover, the project is not yet completed, including more than
two hundred undecided cases that may have to be dealt with separately. In view
of this example, we want to keep in mind both possible goals of the formalization.
One also can point out that artiﬁcial intelligence may blur the sharp distinction
between them [14].
A third, tangential interest in this paper is to see what assumptions are
needed in order to prove certain results. Looking at words through the lens of a
limited set of tools yields interesting insights.
ˇS. Holub—Supported by the Czech Science Foundation grant number 13-01832S.
c
⃝Springer International Publishing AG 2017
J. Kari et al. (Eds.): CiE 2017, LNCS 10307, pp. 24–31, 2017.
DOI: 10.1007/978-3-319-58741-7 3

Formalizing a Fragment of Combinatorics on Words
25
2
Formalization
The proofs presented in this paper were found with the assistance of Prover9 [12],
an automated theorem prover for ﬁrst-order and equational logic. Problems are
represented with a set of ﬁrst-order formulas in clause form [1] that includes a
set of axioms and a problem statement posed for proof by contradiction. Prover9
searches for a proof by applying inference rules to clauses until either a contra-
diction is found or some processing limit is reached. The search is guided by
heuristics for selecting clauses, applying inference rules, and managing the grow-
ing set of derived clauses. Full details for the computation are accessible on the
support web page [9].
Our formalization is based on several decisions that are motivated partly by
theoretical considerations and partly by features of Prover9.
2.1
Semigroup
We consider words as semigroup elements. There is no explicit use of the fact
that the semigroup is free; in particular, words are not seen as sequences. This
is partly motivated by the fact that formal representations of lists typically are
not handled well by theorem provers such as Prover9. Moreover, we are mainly
interested in proofs showing that a certain relation on words forces periodicity,
which is a property rather algebraic in nature. Nevertheless, the combinatorial
complexity reappears in a nontrivial use of associativity; there are an exponential
number of ways to associate any given expression.
We do not allow the empty word. Existence of the empty word has both
advantages and disadvantages, and we decided to avoid it to simplify the
language and theory.
2.2
No Arithmetic
We do not use natural numbers; in particular, we have no strong concept of
length. The main reason for this is that we want to avoid computation and
reasoning about inductively deﬁned objects. Here too, the motivation is to avoid
weaknesses of the theorem prover. An important consequence is that there is no
uniform way to deal with arguments that typically would be inductive in nature.
Length is partly substituted with a weaker length comparison compatible with
the semigroup operation.
2.3
Equidivisibility
We assume the equidivisibility property of the semigroup: if xy = uv, then there
is an element w such that either x = uw and v = wy, or u = xw and y = wv.
This is a property of a free semigroup, also called Levi’s lemma. Levi [11] proved
that an equidivisible semigroup S is free if and only if it is graded, that is, if it
is endowed with a semigroup homomorphism ϕ : S →(N+, +) (see also [13, p.
26]). Levi’s lemma is thus a kind of measure of the distance of our axioms from
the free semigroup.

26
ˇS. Holub and R. Veroﬀ
2.4
Power
In addition to semigroup multiplication and length comparison, we use power as
a primitive concept. The choice stresses that the main feature of words we are
interested in is periodicity. Note that the concept of power becomes a nontrivial
extension of multiplication precisely in the absence of natural numbers, since the
expression wn, understood as w · w · · · · · w, is an expression in a meta-language.
The properties of power that we formalized can be seen in the list of axioms
below. We want to stress the axiom claiming that if both y and uyv are powers
of x, then all the words u, y and v are powers of some common z. This is
in a sense the only nontrivial fact about powers that we are using for now.
(cf. Sect. 3).
Axioms
The above decisions lead to the following formal theory. The logical symbols in
Prover9 notation are & for the logical and, | for the logical or, the minus sign for
negation, and != for non-equal. The existential quantiﬁer is explicitly stated as
∃(it has a verbal form exists in the computer code); non-quantiﬁed variables
are implicitly universally quantiﬁed.
The non-logical symbols are
– binary operation *
– binary relations Power and Shorter
The standard interpretation of Power(y,x) is that y is a power of x; that is,
y ∈x+. The standard interpretation of Shorter(x,y) is that x is shorter than
y; that is, |x| < |y|.
The axioms are as follows:
(x * y) * z = x * (y * z).
(associativity)
(x * y = x * z) -> y = z.
(left cancellation)
(x * y = z * y) -> x = z.
(right cancellation)
x * y != x.
(no right unit)
x * y != y.
(no left unit)
x * y = u * v -> (x = u | ∃w (x * w = u | w * y = v)).
(equidivisibility)
-Shorter(x,x).
(non-reﬂexive)
Shorter(x,y) -> -Shorter(y,x).
(anti-symmetric)
Shorter(x,y) & Shorter(y,z) -> Shorter(x,z).
(transitive)
Shorter(x,x * y).
(compatible with *)
Shorter(x,y * x).
Shorter(x,y) <-> Shorter(x * z,y * z).
(cancelation of length)
Shorter(x,y) <-> Shorter(z * x,z * y).
Shorter(x,y) <-> Shorter(x * z,z * y).
Shorter(x,y) <-> Shorter(z * x,y * z).

Formalizing a Fragment of Combinatorics on Words
27
Power(x,x).
(reﬂexivity of power)
Power(x,y) & Power(y,z) -> Power(x,z).
(transitivity of power)
Power(y,x) & Power(z,x) -> Power(y * z,x).
(compatibility with *)
Power(y,x) & Power(z,x) -> ( y = z |
∃u ( Power(u,x) &
( (y = z * u & y = u * z)|(z = y * u & z = u * y) ) ) )
(cancellation of powers)
Power(y * z,x) -> (Power(y,x) & Power(z,x)) |
(∃u ∃v ( u * v = x &
(y = u | ∃y1 (y = y1 * u & Power(y1,x)) &
(z = v | ∃z1 (z = v * z1 & Power(z1,x)) ) )(breaking a power)
(Power(y,x) & Power(u * (y * v), x)) ->
∃z (Power(y,z) & Power(u,z) & Power(v,z)). (no nontrivial shift)
3
Commutation
In combinatorics on words, the fact that two words commute if and only if they
are powers of the same root is probably the most elementary fact (up to consider-
ing the existence of the common root to be the very deﬁnition of commutation).
In our formalization, however, the formula
x * y = y * x -> ∃z ( Power(x,z) & Power(y,z) ).
is not an axiom but the ﬁrst fact we would like to prove (let us call it the
“Commutation lemma”). It turns out that this is an easy task for Prover9, hence
we witness maybe the very ﬁrst theorem in this ﬁeld ever obtained by Automated
Theorem Proving. Its “diﬃculty” at best corresponds to the characterization
oﬀered by Thomas Hales in 2008 [6, p. 1377]:
Overall, the level today of fully automated computer proof [. . . ] remains
that of undergraduate homework exercises. . .
The proof output from Prover9 is given in Fig. 1. The constants c1 and c2
appearing in the proof are Skolem constants [1] coming from the existentially
quantiﬁed variables in the negation of the theorem (for proof by contradiction).
The proof consists of a unique (humanly) nontrivial observation implied by
the commutativity of x and y: (xy)(xy) = x(yx)y = x(xy)y. Now the consequent
follows from the (no nontrivial shift) axiom.
4
Conjugation and Missing Induction
An obvious candidate claim to be proven next is the following theorem, actually
just a part of a well known characterization of conjugate words.
Theorem 1. If xz = zy, then there are words u and v such that x = uv and
y = vu.

28
ˇS. Holub and R. Veroﬀ
Fig. 1. Proof of the Commutation lemma
Consider the following simple classical proof.
Proof. Proceed by induction on |z|. If |z| ≤|x|, then there is a word v such that
x = zv and y = vz. Therefore, we are done with u = z.
Assume that |z| > |x|. Then z = xz′ = z′y with |z′| < |z|, and the proof is
completed by induction.
This proof cannot be formalized with our current axioms, since we do not
have induction. Speciﬁcally, Shorter is not a well-founded relation.
In fact, the problem is not just with this proof, since the formula
x * z = z * y -> (x = y) | ∃u ∃v (x = u * v
&
y = v * u)
(conj.)
cannot be proven with our axioms. This follows from the following semigroup
in which all axioms hold, but Theorem 1 does not.
Let ⟨A⟩be a semigroup generated by A = {a, b}∪{ci | i ∈N} and deﬁned by
the set of relations ci = aci+1 = ci+1b, i ∈N. The Power relation is interpreted
in the natural way as in A∗. We deﬁne the “length” semigroup homomorphism
ℓ: ⟨A⟩→(Q, +) by ℓ(a) = ℓ(b) = 1 and ℓ(ci) = 2−i. The relation Shorter(x, y)
is interpreted as ℓ(x) < ℓ(y). Note that by Levi’s lemma (see above), there
cannot exist any semigroup homomorphism ⟨A⟩→(N, +).

Formalizing a Fragment of Combinatorics on Words
29
This example shows that our rudimentary axiomatic system must be
extended by the (conj.) formula if we wish to prove anything about conjugate
words.
5
Periodicity Lemma
The Periodicity lemma, often called the Fine and Wilf theorem [4], is a funda-
mental tool when dealing with periodicity. It states when a word can have two
diﬀerent periods p and q in a nontrivial way, where nontrivial means not having a
period dividing both p and q. This formulation of the claim apparently depends
strongly on arithmetical properties of periods, namely divisibility. Nevertheless,
in this case we are able to prove the following version of the Periodicity lemma
that is only slightly weaker than the full version:
Theorem 2. Let u with |u| ≥|xy| be a preﬁx of both xω and yω. Then x and y
commute.
For the sake of completeness, we recall that the full version of the Periodicity
lemma has a weaker assumption |u| ≥|xy|−gcd(|x|, |y|), and moreover, it claims
that the bound is optimal.
We have formulated Theorem 2 in a way that ﬁts our formalization. Namely,
periods of u are deﬁned by its periodic roots x and y. Moreover, the inﬁnite
power is used, reminding us that we do not care about the exponent (since we
haven’t got the means needed). In order to make our formulas more intuitive,
it may be convenient to enrich our language with binary relations Prefix and
Period, deﬁned by axioms
Prefix(x,y) <-> ∃z
(x * z = y).
Period(x,y) <-> ∃z
( Power(z,x)
&
Prefix(y,z) ).
Theorem 2 now has the following simple form:
(Period (x,u) & Period(y,u) & -Shorter(u,x * y)) -> x * y = y * x.
An “informal” proof of Theorem 2 using only accepted axioms is the following.
Proof. Let uu1 be a power of x and let uu2 be a power of y. Then uu1 = xx1 and
uu2 = yy1 with x1 ∈x+ and y1 ∈y+. Then u = xu3 = yu4, where u3u1 ∈x+ and
u4u2 ∈y+. Since uu1, u3u1x ∈x+ and |uu1| = |u3u1x|, we deduce uu1 = u3u1x.
Now,
uu1x = xu3u1x = xuu1 = xyu4u1,
and xy is a preﬁx of u. Similarly, we obtain that yx is a preﬁx of u, which
concludes the proof.

30
ˇS. Holub and R. Veroﬀ
This is a typical example of a very simple proof which is at the same time
quite unpleasant to read and verify. Of course, the same argument can be made
with an appeal to the intuition of the character of the periodicity. However, such
an intuition is hardly preserved throughout more complex proofs.
To date, Prover9 has not found a proof entirely on its own. To get a fully
formalized proof, we split the argument into several steps. Speciﬁcally, we ﬁrst
proved four auxiliary lemmas:
(x * y = u * v) -> (Prefix(x,u) | Prefix(u,x) | x = u).
(L1)
Prefix(x,y) -> Shorter(x,y) .
(L2)
-Shorter(u, x * y) -> (u * z != x * y) .
(L3)
((u * u1 = x * x1) & -Shorter(u,x * y)) -> (∃u3
(u = x * u3)) .
(L4)
They are just tiny, humanly natural reformulations of existing axioms and
deﬁnitions which nevertheless help to point the Prover9 search in the right direc-
tion. The use of (L4) is clear from the reformulation of Theorem 2 below. Note
that the lemma says: if u and x are preﬁxes of the same word and |u| ≥|xy|
(for an arbitrary y), then x is a preﬁx of u. The lemma would be more nat-
ural if |x| < |u|, that is Shorter(x,u), were used instead of |u| ≥|xy| (that
is -Shorter(u,x * y)). However, the latter being an explicit assumption of
Theorem 2, the present form is one more little hint for the automated proof.
We then reformulated the task as
(Power(u * u1, x) & u = x * u3 &
Power(u * u2, y) & u = y * u4 &
-Shorter(u,x * y) )
-> x * y = y * x.
Here ∃u1 Power(u * u1, x) can be proved, or it can be considered as a
diﬀerent deﬁnition of Period(x,u) (similarly for Period(y,u)). The claims ∃u3
u = x * u3 and ∃u4 u = y * u4 were proved separately.
The proof of Theorem 2 now splits into two cases. (1) u = xy or u = yx; (2)
u ̸= xy and u ̸= yx. By symmetry of x and y, the ﬁrst case can be reduced to
u = xy. Note that this is a meta-argument sparing us one of two formal proofs
identical up to exchange of x and y.
The case u = xy was proved automatically when we suggested (L1) and
(L2) to Prover9. For the case u ̸= xy and u ̸= yx, we let Prover9 ﬁrst prove
intermediate conclusions (identical up to symmetry of x and y):
∃u5 (u = (x * y) * u5).
∃u5 (u = (y * x) * u6).

Formalizing a Fragment of Combinatorics on Words
31
6
Conclusion
A text in combinatorics on words usually contains three dots (like a1 · · · an)
somewhere on the ﬁrst few lines. Experts on automated theorem proving quickly
become skeptical when seeing those dots, since computers refuse to understand
what they mean. The original intention of our research was therefore to break
this skepticism and to show the very possibility of a formal approach to words.
As in practically all other areas of mathematics, there is little hope (or fear)
that computers will replace mathematicians in the near future. From our recent
experience reported in this text, the realm of fully automated proving ends
somewhere between the Commutation lemma and the Periodicity lemma. On
the other hand, a vision of a computer assisted proof veriﬁcation or search for
individual steps in proofs seems more realistic. We wish to leave open for a
further enquiry whether this or some modiﬁed formalization attempt can bring
about something substantial.
References
1. Chang, C.-L., Lee, R.C.-T.: Symbolic Logic and Mechanical Theorem Proving.
Academic Press, New York (1973)
2. Culik II, K., Karhum¨aki, J.: On the equality sets for homomorphisms on free
monoids with two generators. RAIRO ITA 14(4), 349–369 (1980)
3. Czeizler, E., Holub, ˇS., Karhum¨aki, J., Laine, M.: Intricacies of simple word equa-
tions: An example. Int. J. Found. Comput. Sci. 18(6), 1167–1175 (2007)
4. Fine, N.J., Wilf, H.S.: Uniqueness theorems for periodic functions. Proc. Am. Math.
Soc. 16(1), 109–109 (1965)
5. Hadravov´a, J.: Structure of equality sets. Ph.D. thesis, Charles University (2007)
6. Hales, T.C.: Formal proof. Not. AMS 55(11), 1370–1380 (2008)
7. Holub, ˇS.: Binary equality sets are generated by two words. J. Algebra 259(1),
1–42 (2003)
8. Holub, ˇS.: A unique structure of two-generated binary equality sets. In: Ito, M.,
Toyama, M. (eds.) DLT 2002. LNCS, vol. 2450, pp. 245–257. Springer, Heidelberg
(2003). doi:10.1007/3-540-45005-X 21
9. Holub, ˇS., Veroﬀ, R.: Formalizing a fragment of combinatorics on words (web
support) (2017). http://www.cs.unm.edu/veroﬀ/CiE2017/
10. Lagarias, J.C.: The Kepler Conjecture: The Hales-Ferguson Proof. Springer, New
York (2011)
11. Levi, F.W.: On semigroups. Bull. Calcutta Math. Soc. 36, 141–146 (1944)
12. McCune, W.: Prover9, version 02a (2009). http://www.cs.unm.edu/mccune/
prover9/
13. Sakarovitch, J.: Elements of Automata Theory. Cambridge University Press, New
York (2009)
14. Urban, J., Vyskoˇcil, J.: Theorem proving in large formal mathematics as an emerg-
ing AI ﬁeld. In: Bonacina, M.P., Stickel, M.E. (eds.) Automated Reasoning and
Mathematics. LNCS, vol. 7788, pp. 240–257. Springer, Heidelberg (2013). doi:10.
1007/978-3-642-36675-8 13

Turing’s 1949 Paper in Context
CliﬀB. Jones(B)
School of Computing Science, Newcastle University, Newcastle upon Tyne, UK
cliff.jones@ncl.ac.uk
Abstract. Anyone who has written one knows how frustratingly dif-
ﬁcult it can be to perfect a computer program. Some of the founding
fathers of computing set out ideas for reasoning about software — one
would say today ‘techniques for proving that a program satisﬁes its spec-
iﬁcation’. Alan Turing presented a paper entitled Checking a Large Rou-
tine that laid out a workable method for reasoning about programs. Sadly
his paper had little impact. Understanding the problem faced, Turing’s
proposal and what followed provides insight into how ideas evolve. Com-
paring three contributions from the 1940s with the current state of the
art clariﬁes a problem that still costs society a fortune each year.
1
Introduction
In the 1940s, there were at least three published outlines of how it might be
possible to reason about computer programs; Herman Goldstine and John von
Neumann [GvN47], Alan Turing [Tur49] and Haskell Curry [Cur49]. Frustrat-
ingly these early insights appear to have then lain dormant only to be reinvented
(and developed enormously) starting two decades later.1 It is interesting to spec-
ulate why the early papers were only studied after the work of Bob Floyd, Tony
Hoare and others had been published.
It is Alan Turing’s 1949 paper that has the clearest similarity with what fol-
lowed, for example in Floyd’s [Flo67], and Sect. 3 gives enough detail of Turing’s
1949 paper to support comparisons. Here, briefer comments are made on the
other two contributions.
The report [GvN47] contains a long account of the process of designing pro-
grams that achieve a mathematical task. Looked at today, it is even tempting to
say that the account is somewhat rambling but it must be remembered that in
1947 no one had any experience of writing computer programs. A distinction is
made between parameters to a program which are likened to free variables and
those locations whose values change during a computation that are compared to
1 Connections other than the citations between these three pioneering pieces of work
are diﬃcult to trace. The current author has tried to determine whether there is a
direct link between von Neumann’s assertion boxes and Turing’s annotations. It is
known that Turing visited the US during the war but there is no evidence that the
urgent business of cryptography left any time to discuss program development ideas.
c
⃝Springer International Publishing AG 2017
J. Kari et al. (Eds.): CiE 2017, LNCS 10307, pp. 32–41, 2017.
DOI: 10.1007/978-3-319-58741-7 4

Turing’s 1949 Paper in Context
33
bound variables. The notion of constructing a ﬂowchart is, from today’s stand-
point, handled in a rather pedestrian description. However, crucially, a distinc-
tion is made between operation boxes (that change the values of bound variables)
and assertion boxes that can be used to describe logical relations between values.
Haskell Curry’s [Cur49] cites, and is clearly inﬂuenced by, [GvN47]. Curry
however puts more emphasis on constructing programs from components or
transformations. In a subsequent paper from 1950, Curry applies his proposals
to constructing a program for inverse interpolation. Curry’s emphasis on topics
such as (homomorphic) transformations is not surprising given his background
in combinatory logic.2
2
The Problem
Users of computers have to endure the situation that most software has bugs;
those who purchase software are frustrated by the fact that it comes, not only
without guarantees, but with explicit exclusions of any liabilities on the provider
for losses incurred by the purchaser. It was claimed in a 2002 NIST report that
software ‘maintenance’ cost US industry over $50Bn per year.
The problem for the programmer is the literal nature of the indefatigable
servant called hardware. If one told a human servant to do anything nonsensical,
there is at least a chance that the instruction would be queried. If, however, a
computer program is written that continues to subtract one from a variable until
it reaches zero, it will do just that — and starting the variable with a negative
value is unlikely to yield a useful result.
A simpliﬁed expression of the question that has occupied many years of
research – and which is of vital importance – is ‘how can one be sure that a
program is correct?’. In fact, this form of the question is imprecise. A better
formulation is ‘how can we be sure that a program satisﬁes an agreed speciﬁca-
tion?’.
Once one is clear that this property must apply to ‘all possible inputs’, a
natural idea is to look at mathematical proof. The position argued in [Jon03] is
that the desirability of reasoning about correctness was clear to the early pioneers
and a key impediment to adoption has been a search for tractable methods of
decomposing the reasoning so as to deal with large programs.
3
The Paper Checking a Large Routine
Alan Turing made seminal contributions related to software. In fact, it can be
argued that ‘Turing Machines’ provide the ﬁrst thought-through idea of what
constitutes ‘software’. Turing’s way of showing that the Entscheidungsproblem
was unsolvable was to propose an imaginary universal computer and then to
2 Acknowledgements to Curry’s inﬂuence are present in both the choice of name for
the Haskell (functional) programming language and the term Curry-Howard corre-
spondence (for proofs as programs).

34
C.B. Jones
prove that there were results which no program could compute. The Turing
machine language was minimal but just rich enough to describe any step-by-
step process that could be envisaged.
In 1949 the EDSAC computer in Cambridge became the world’s second ‘elec-
tronic stored program computer’ to execute a program.3 A conference to mark
this event was held in Cambridge from 22–25 June 1949. Many people who
became famous in the early history of European computing attended the event;
among those who gave papers was Alan Turing. His paper [Tur49] is remarkable
in several ways. Firstly, it is only three (foolscap) pages long. Secondly, much of
the ﬁrst page is taken up with one of the best motivations ever given for program
veriﬁcation ideas. Most interestingly, Turing presents the germ of an idea that
was to lay dormant for almost 20 years; a comparison with Bob Floyd’s 1967
paper – which became the seed of an important area of modern computer science
research – is made below.
It is worth beginning, as does the 1949 paper, with motivation. The overall
task of proving that a program satisﬁes its speciﬁcation is, like most mathemat-
ical theorems, in need of decomposition. Turing made the point that checking
the addition of a long series of numbers is a monolithic task that can be split
into separate sub-tasks by recording the carry digits. His paper displays ﬁve
(four-digit) numbers whose sum is to be computed and he makes the point that
checking the four columns can be conducted separately if the carry digits are
recorded (and a ﬁnal addition including carries is another separable task). Thus
the overall check can be decomposed into ﬁve independent tasks that could even
be conducted in parallel.
Turing’s insight was that annotating the ﬂow chart of a program with claims
that should be true at each point in the execution can also break up the task of
recording an argument that the complete program satisﬁes its speciﬁcation (a
claim written at the exit point of the ﬂowchart).
A program correctness argument is in several respects more diﬃcult than the
arithmetic addition: these, and how the 1949 paper tackled them, are considered
one by one. Turing’s example program computes factorial (n!); it was presented
as a ﬂowchart in which elementary assignments to variables were written in
boxes; the sequential execution of two statements was indicated by linking the
boxes with a (directed) line. In the original, test instructions were also written
in rectangular boxes (they are enclosed diamond shaped boxes in Fig. 1) with
the outgoing lines indicating the results of the tests and thus the dynamic choice
of the next instruction.
Suppose a ‘decorating claim’ is that the values of the variables are such that
r < n and u = (r + 1) ∗r!. Consider the eﬀect if the next assignment to be
executed changes r to have a value one greater than the previous value of that
same variable (in some programming languages this would be written r := r+1).
Then it is easy to check that after this assignment a valid decoration is r ≤n and
u = r!. Reasoning about tests is similar. Suppose that the decorating assertion
3 The world’s ﬁrst embodiment of an ‘electronic stored-program computer’ to run was
the Manchester ‘Baby’ that executed its ﬁrst program on midsummer’s day 1948.

Turing’s 1949 Paper in Context
35
before a test is s −1 ≤r < n and u = s ∗r!; if the execution of the test indicates
that the current values of the variables are such that (s −1) ≥r then, on the
positive path out of the test, a valid decoration is r < n and u = (r + 1) ∗r!
(which expression can be recognised from above).
The ﬂowchart in the 1949 paper represented what today would be written as
assignments (e.g. r := r+1 from above) by r′ = r+1. Furthermore, Turing chose
to mark where decorating claims applied by a letter in a circle and to record the
decorations in a separate table. There is the additional historical complication
that his decorations were associated with numerical machine addresses. For these
reasons – and those of space – the actual 1949 ﬁgures are not given here but
exactly the same annotated program is presented in Fig. 1 in a modern form.
In today’s terms, it could be said that Turing’s programming language was
so restricted that the meaning (semantics) of its constructs was obvious. This
point is also addressed when subsequent developments are described below.
By decorating ﬂowcharts, Turing – and some subsequent researchers –
ﬁnessed some delicate issues about loops which are just represented by the lay-
out of the ﬂowchart.4 In the case of Turing’s example, factorial is computed by
successive multiplication; and, in fact, the envisaged machine was so limited that
even multiplication was not in the instruction set and the actual program has a
nested inner loop that computes multiplication by successive addition.
There is a delicate and important issue about loops that Turing addressed
formally: the need to argue about their termination. When a computer locks
up (and probably has to be restarted) one possible cause is that a program
is in a loop that never terminates. The 1949 paper contains a suggestion that
loop termination can be justiﬁed by showing the reduction of an ordinal number
which Turing commented would be a natural argument for a mathematician;
he added however that a ‘less highbrow’ argument could use the fact that the
largest number representable on the machine he was considering was 240.
The fascinating thing about the 1949 paper was the early recognition of
the need for something more mathematical than the execution of test cases
to support the claim that a program satisﬁes its speciﬁcation. Of course, the
example given in a (very short) paper is small but it is clear from the title of
the paper that the intention was to apply the proposal to ‘large routines’.
Turing gave a workable method for recording such reasoning. Lockwood Mor-
ris and the current author had a debate with Maurice Wilkes about the compar-
ison with Floyd’s approach but it should be clear that a major intellectual step
had been made beyond the acceptance that ‘write then debug’ was the only way
to achieve correct software.
4 In fact, some form of looping concept is central to the power of general purpose
programs. One could say that they make it possible to compute properties that are
not in the basic instructions of the programming language. This point is illustrated
with recursive functions in [P´et66, Chap. 1] and applied to interesting data struc-
tures in the appendix of R´ozsa P´eter’s book. It is interesting to recall Tony Hoare’s
comment that he couldn’t write Quicksort as a program until he learned a language
that provided recursive procedures.

36
C.B. Jones
4
The Floyd/Hoare Approach
Turing’s wonderfully brief and clear 1949 paper both identiﬁes the issue of rea-
soning about programs and contains a clear proposal as to how it might be
undertaken for numerical examples. Considering this early recognition of the
issue, it is remarkable that the key paper on which so much subsequent research
on program reasoning is based did not appear until the late 1960s. The landmark
talk by Bob Floyd in 1967 (published as [Flo67]) appears to have been written
in complete ignorance of Turing’s 1949 paper. Some possible reasons for this
are put forward in Sect. 6. The similarities might indicate the degree to which
the idea of separating complex arguments into smaller steps is inevitable; the
diﬀerences between Turing’s and Floyd’s approaches are more interesting.
Floyd also annotated ﬂowcharts and Turing’s factorial example can be pre-
sented in Floyd’s style as in Fig. 1 (the two deduction steps traced in the previous
section appear in the lower part of this ﬂowchart). For Turing’s example, arith-
metic relations suﬃce for the decorating assertions; Floyd explicitly moved to
the formal language of ﬁrst-order predicate calculus for his assertion language.
This decision made it possible for Floyd to be precise about what constitutes
a valid argument. In fact, Floyd explored what were later called ‘healthiness
conditions’ by Edsger Dijkstra.
Like Turing, Floyd oﬀered formal ways of reasoning about termination.
Not all later authors achieved this. The idea of showing that a program com-
putes some desirable result if it terminates is sometimes misnamed ‘partial
r := 1
u := 1
v := u
s := 1
u := u+v
s := s+1
r - n
(s -1) - r
r := r+1
0 < n
r  n
u = r!
r  n
u = r!
v = r!
s  r < n
u = sr!
v = r!
s  r < n
u = (s+1)r!
v = r!
(s - 1)  r < n
u = sr!
v = r!
r < n
u = (r+1)r!
 0
< 0
< 0
 0
v = n!
Fig. 1. A presentation of Turing’s example in the Floyd style

Turing’s 1949 Paper in Context
37
correctness’; one can however take the view that, if a program is expected to ter-
minate, this requirement is a part of its speciﬁcation and needs to be justiﬁed.5
A crucial further step – still in ignorance of Turing’s 1949 paper – was
made by Tony Hoare who proposed an ‘axiomatic’ view of program semantics.
In [Hoa69], he separated program reasoning from the ﬂowchart view by propos-
ing – what have come to be called – ‘Hoare triples’ as terms in an extended
logic containing pre conditions, program constructs and post conditions. Both
pre and post conditions are logical expressions that characterise sets of states.
Valid triples record that, for all states satisfying the pre condition, the execution
of the program text will result in states satisfying the post condition. What is
important about this change of viewpoint is that it moves the programmer away
from thinking in terms of program tracing and prompts viewing programs and
assertions as combined terms in an extended logical system. A further advan-
tage became clear in a second paper [Hoa71] by Hoare. The title of Proof of a
Program: FIND betrays the fact that Hoare initially wrote a paper to provide a
post facto proof of the correctness of a non-trivial sorting program (of his own
invention). A ﬁrst version of this proof was sent to referees one of whom was
the current author. In the absence of the sort of mechanical theorem provers
that are in use today, it was diﬃcult to build conﬁdence in the long and detailed
proof. Hoare realised this and rewrote the paper (but did not change the title) to
embody a stepwise development of the program with layers of abstraction that
were much easier to grasp and reason about. Hoare’s axiomatic approach became
the foundation of a huge ﬁeld of research on the formal design of software.
Hoare’s original paper did not formalise termination arguments; of course, he
was aware of the importance of showing that programs always terminated in any
state satisfying the pre condition but the topic was not included in the initial
set of rules. Hoare reasoned about termination (and in fact the relationship to
the initial states) separately and informally.
Because of its importance below, it is worth recording that Hoare was gener-
ous in his credits to earlier researchers mentioning Floyd, Naur6 and van Wijn-
gaarden (whose role is explored in Sect. 6).
5 John McCarthy – who did much to promote formal methods – used the following
imaginary scenario to highlight the need for termination arguments ‘an algorithm
that might appear to ensure that someone becomes a millionaire: the person should
walk along the street picking up any piece of paper — if it is a cheque made out to
that person for one million dollars, take it to the bank; if not, discard the piece of
paper and resume the process’.
6 Peter Naur proposed in a paper in the journal BIT ‘general snapshots’ as a way
of annotating a program text to reason about its correctness. Naur’s system was
based on comments in a program and was less formal than Floyd’s but it is another
indication that the idea of decomposing an argument about correctness had reached
its moment in time.

38
C.B. Jones
5
Current Situation
Research on reasoning about programs (and designs of complex hardware) has
not only been a major topic for academic research, it is now an essential approach
used by industry in cases where life or business is at risk.
Jim King was one of Floyd’s students and built Eﬃgy [Kin71] which was an
early system in which programs could be annotated with assertions (using ﬁrst-
order predicate calculus as in Floyd’s paper). Today, powerful theorem proving
assistant software such as Isabelle, PVS and Coq use heuristics from research on
Artiﬁcial Intelligence and greatly reduce the human eﬀort in creating completely
formal proofs. Several notations have been developed for specifying both over-
all systems and components that arise during design. Integrated systems that
generate ‘proof obligations’ from design steps link to theorem proving assistants.
Perhaps the development that would cause the founding ﬁgures most surprise
is today’s emphasis on using abstract forms of data in speciﬁcation and design.
With the limited store sizes of the early machines, vectors – or perhaps multi-
dimensional arrays – constituted the extent of data abstraction. Now computer
software manipulates huge and interlinked data structures whose representation
is itself a major design challenge. Fortunately, the ideas of data abstraction and
reiﬁcation are also handled in many modern design support systems.
The use of ‘formal methods’ for hardware design accelerated after Intel
reportedly took a $475M loss because of an undetected design ﬂaw in the Pen-
tium chip. Many researchers emphasise a ‘stack’ of veriﬁed components from
programs, through compilers to the hardware designs themselves. As mentioned,
the earliest uses of formal methods were for ‘safety critical’ software in which
errors could put lives at risk. In some ways, the more interesting development is
that some organisations use formal methods even where there is no requirement
to do so, the argument being that they provide a cost-eﬀective way of creating
predictable and maintainable software. A useful review of the current state of
deployment of formal methods is [WLBF09] (which is currently being updated).
Even where completely formal (machine checked) proofs are not considered
necessary, an approach sometimes called ‘formal methods light’ oﬀers an engi-
neering approach founded on mathematics.
One area of research that is of strong interest today concerns ‘concurrency’.
This is important because hardware designers are putting ever more processors
on a single chip in order to continue to provide the exponential speed increases
that have revolutionised computing. Of particular interest here is the develop-
ment of special logics such as Temporal Logic or Separation Logic to reason
about concurrency.
6
Why Did Turing’s Paper Not Have Immediate Impact?
Reasoning about programs is today seen as the only way to ensure the correctness
of so-called ‘safety critical’ software and as a cost-eﬀective way of achieving high
quality software in a predictable process. It is, therefore, interesting to try to

Turing’s 1949 Paper in Context
39
understand the lack of impact of Turing’s 1949 gem on what has become such
an important area of computing science.
First, it is worth noting that Turing was not careful in the production of
printed materials especially for what he might have seen as a rather minor con-
tribution. The reproduced version of the 1949 paper is a nightmare to interpret.7
The identiﬁers used in the program could hardly have been more badly chosen
for someone with unclear handwriting and little time for proofreading: u, v, n
and r are mistyped 10 times. This is compounded by the fact that Turing chose –
rather than n! – to write factorial as a box around n; a perfectly acceptable nota-
tion but in the printed paper this symbol is missing in several places presumably
because it should have been added by hand but was not.8
The ‘typos’ were, however, certainly not the main reason for the lack of
impact. Neither Floyd nor Hoare were old enough to have attended the 1949
conference. It would also appear that few people who were at that meeting were
inclined to follow Turing’s rigorous approach to reasoning about software. There
was one tantalising attendee: Aad van Wijngaarden is listed as a participant
in the Cambridge meeting. He went on to publish an important paper [vW66]
entitled Numerical Analysis as an Independent Science. The contribution of this
paper was to provide axioms of ﬁnite computer arithmetic in which, for example,
adding one to the largest number representable in a single word might yield
a negative result. As mentioned above, Hoare acknowledges this contribution
because it is one aspect of his 1969 ‘axiomatic’ approach. In some sense then,
van Wijngaarden had in his hands all of the pieces of Hoare’s approach but failed
to put them together.9 The current author had the good fortune to know many
of the main players (but not Turing). In particular, Aad van Wijngaarden was
always a charming and interesting dinner companion; it is most unfortunate that
Turing’s 1949 paper only came to hand after van Wijngaarden’s death. Neither
ﬁrst hand questions, nor recollections from closer colleagues have exposed any
record of what van Wijngaarden thought of Turing’s paper.10
Another consideration when looking for paths to impact is the language in
which Turing’s programs were written. Programs are inevitably written in a
language. The intended meaning of that formal language (its ‘semantics’) is an
essential assumption for any reasoning about programs. Typically, a program-
ming language is translated into the machine code of a speciﬁc type of hardware.
Were the translation not to reﬂect the intended semantics, any eﬀort to reason
about programs would be undermined. Fortunately this can be seen as decom-
posing the overall challenge of ‘program correctness’: ways are needed, on the
7 A full review of Turing’s 1949 paper with indications of the necessary typographical
corrections is contained in [MJ84].
8 For example: ‘with n in line 29 we shall ﬁnd a quantity in line 31 when the machine
stops which is n’.
9 More detail on the history of reasoning about programs can be found in [Jon03].
10 Gerard Alberts has however made two important points (private communication
March 2017): it is important to remember that van Wijngaarden’s background was
numerical analysis rather than logic; furthermore, Alberts has evidence that van
Wijngaarden ‘had little aﬃnity’ with Turing and his work.

40
C.B. Jones
one hand, for reasoning about programs written in a speciﬁc ‘high level’ language
and, on the other hand, for showing that the translation of that language into
machine code is correct. One suggestion for the lack of progress over almost two
decades (1949–1967) is that programmers were so preoccupied with the many
other developments their attention was diverted from the crucial issue of whether
programs satisﬁed their speciﬁcations. Those 18 years also saw the development
from machine code to (‘high level’) programming languages in which large pro-
grams can be written.
Another possible explanation is one that still plagues the software industry:
to mathematicians like Turing and von Neumann the notion of proof was bread
and butter, but many who took up the role of programmer were not conscious
of the certainty to be gained from presenting careful logical arguments.
It is tempting to speculate what might have happened had Turing’s paper
been more widely read and understood at an earlier point in time. The story
about van Wijngaarden ought give pause to anyone who suggests that, had
Turing’s paper been more widely known, the subject of program reasoning would
have been automatically advanced by two decades. Who knows when someone
of Tony Hoare’s disposition and ability would have come along to make the
crucial step to an axiomatic presentation? It is interesting to note that Hoare
was actually looking for ways to record the meaning of programming languages
when he proposed his axiomatic approach; so there is the initial requirement that
the sought after person might have needed to have struggled with the speciﬁc
thorny question of how to describe the semantics of a language precisely but to
leave some aspects ‘under determined’.
A more compelling avenue for speculation is to wonder what inﬂuence aware-
ness of Turing’s paper might have had on Bob Floyd. Floyd’s paper, like Hoare’s,
is generous in its acknowledgement of previous work. In fact, Don Knuth’s obit-
uary note suggests excessive modesty in Floyd’s statement that ‘These modes of
proof of correctness and termination are not original; they are based on ideas of
Perlis and Gorn, and may have had their earliest appearance in an unpublished
paper by Gorn.’11
The facts are simple: Turing’s [Tur49] is another example of a paper from a
brilliant mind; the paper was ahead of its time; sadly, this contribution appears
to have gone unrecognised until after Floyd’s independent invention of a scheme
that went beyond Turing’s had been published and taken up by other researchers.
Ideas have their time and independent inventions are not unusual; one part
of the question of timing is that receptiveness can depend on people having
struggled with preparatory problems;12 for many years Turing’s contributions
were somewhat undervalued (a state of aﬀairs that has recently been handsomely
redressed); however his Checking a large routine had regrettably little impact. It
is also important not to go too far in explaining scientiﬁc progress as a sequence
of landmark papers.
11 Repeated attempts to track down this elusive paper have so far yielded noth-
ing: [Gor61] does not appear to be the missing document and [Gor68] is too late.
12 A similar conclusion is drawn in Priestly’s interesting book [Pri11, p. 302].

Turing’s 1949 Paper in Context
41
Acknowledgements. I should like to dedicate this paper to Lockwood Morris (1943–
2014) who was a great but under-appreciated scientist. We worked together on [MJ84]
when we were both in Oxford and he subsequently spent his sabbatical with me in
Manchester. As well as many happy memories, Lockwood did me a great personal
favour in December 2013 which was sadly the last time we met.
I am extremely grateful to Liesbeth de Mol for bringing Curry’s work to my atten-
tion and to Gerard Alberts for interesting input on van Wijngaarden. Comments from
anonymous referees have also helped improve the paper although some of their sug-
gestions will not ﬁt in the page ration. My funding for this research comes from the
EPSRC Strata Platform Grant.
References
[Cur49] Curry, H.B.: On the composition of programs for automatic computing.
Naval Ordnance Laboratory Memorandum 9806, 19-8, 52 pp. (1949)
[Flo67] Floyd, R.W.: Assigning meanings to programs. In: Proceedings of Sympo-
sium in Applied Mathematics. Mathematical Aspects of Computer Science,
vol. 19, pp. 19–32. American Mathematical Society (1967)
[Gor61] Gorn, S.: Speciﬁcation languages for mechanical languages and their proces-
sors a baker’s dozen: a set of examples presented to ASA x3.4 subcommit-
tee. Commun. ACM 4(12), 532–542 (1961)
[Gor68] Gorn, S.: The identiﬁcation of the computer, information sciences: their
fundamental semiotic concepts and relationships. Found. Lang. 4, 339–372
(1968)
[GvN47] Goldstine, H.H., von Neuman, J.: Planning and coding of problems for an
electronic computing instrument. Technical report, Institute of Advanced
Studies, Princeton (1947)
[Hoa69] Hoare, C.A.R.: An axiomatic basis for computer programming. Commun.
ACM 12(10), 576–580, 583 (1969)
[Hoa71] Hoare, C.A.R.: Proof of a program: FIND. Commun. ACM 14, 39–45 (1971)
[Jon03] Jones, C.B.: The early search for tractable ways of reasoning about pro-
grams. IEEE Ann. Hist. Comput. 25(2), 26–49 (2003)
[Kin71] King, J.C.: A program veriﬁer. In: Freiman, C.V. (ed.) Proceedings of the
Information Processing, IFIP 1971, pp. 234–249. North-Holland (1971)
[MJ84] Morris, F.L., Jones, C.B.: An early program proof by Alan Turing. Ann.
Hist. Comput. 6(2), 139–143 (1984)
[P´et66] P´eter, R.: Recursive Functions. Academic Press, New York (1966)
[Pri11] Priestley, M.: A Science of Operations: Machines, Logic and the Invention
of Programming. Springer Science & Business Media, London (2011)
[Tur49] Turing, A.M.: Checking a large routine. In: Report of a Conference on High
Speed Automatic Calculating Machines, pp. 67–69. University Mathemat-
ical Laboratory, Cambridge, June 1949
[vW66] Wijngaarden, A.: Numerical analysis as an independent science. BIT 6,
66–81 (1966)
[WLBF09] Woodcock, J., Larsen, P.G., Bicarregui, J., Fitzgerald, J.: Formal methods:
practice and experience. ACM Comput. Surv. 41(4), 1–36 (2009)

G¨odel’s Reception of Turing’s
Model of Computability:
The “Shift of Perception” in 1934
Juliette Kennedy(B)
University of Helsinki, Helsinki, Finland
juliette.kennedy@helsinki.fi
1
Introduction
The emergence of the mathematical concept of computability in the 1930 s was
marked by an interesting shift of perspective, from viewing the intuitive concept,
“human calculability following a ﬁxed routine” in terms of calculability in a logic,
to viewing the concept as more adequately expressed by Turing’s model.1 This
happened in spite of, or in parallel with, conﬂuence, as Gandy called it in his
[1], namely the proven extensional equivalence of the models of computability
which had been given prior to Turing’s model.
In this talk we consider this shift—one in which G¨odel was a key ﬁgure—
in relation to G¨odel’s philosophical outlook subsequently. On the way we con-
sider a question that Kripke has asked recently [2]: why did G¨odel not see that
the Entscheidingsproblem is an immediate consequence of the Completeness and
Incompleteness Theorems? Kripke’s analysis depends upon viewing computabil-
ity in terms of calculability in a logic. We thus suggest that Kripke’s own expla-
nation for G¨odel’s purported blindness to the fact of having solved what was
arguably viewed as the single most important problem in logic remaining open
at the time,2 be complemented by the story of the diﬃculties logicians had with
viewing computability in this sense.
In particular we will suggest that the inherent circularity which characterises
such a conception, may have contributed to a sense of reluctance on the part of
the Princeton group of logicians at the time to embrace it: for if computability
is understood in terms of calculability in a logic, then it must be the case that
not any logic will serve, rather the logic in question must be given eﬀectively.
But then, how to understand the concept “given eﬀectively”, as applied to the
logic in question?
What follows is an abbreviated history of the development of computability
in the 1930 s, from the point of view of this shift in perspective.3
Juliette Kennedy: I thank Liesbeth de Mol for the invitation to address a special
session of CiE2017, and to contribute this extended abstract to its proceedings.
1 Gandy quote. See below.
2 See, e.g. Sieg [3], p. 387.
3 Some of the text below is adapted from the author’s [4].
c
⃝Springer International Publishing AG 2017
J. Kari et al. (Eds.): CiE 2017, LNCS 10307, pp. 42–49, 2017.
DOI: 10.1007/978-3-319-58741-7 5

G¨odel’s Reception of Turing’s Model of Computability
43
2
Isolating the Concept of “Computable Function”
G¨odel deﬁned the class of primitive recursive functions in his 1931 [5], while
Church at the same time had developed the λ-calculus together with Kleene.
Church’s ﬁrst presentation of the λ-calculus in 1932 [6], which embeds that
calculus in a deductive formalism, in the Hilbert/Bernays terminology, was found
to be inconsistent in 1934. Two years later Church published a, in Gandy’s
words, logic-free deﬁnition of the λ-calculus, based on the primitives “function”
and “iteration”:4
When it began to appear that the full system is inconsistent, Church spoke
out on the signiﬁcance of λ-deﬁnability, abstracted from any formal system
of logic, as a notion of number theory.5
In the period between these two versions of the λ-calculus Church suggested
his thesis, namely the suggestion to identify the λ-deﬁnable functions with those
which are eﬀectively computable.6 The plausibility of the thesis became espe-
cially clear when Church, Kleene and Rosser established conﬂuence, proving the
equivalence of λ-deﬁnability with computability in the sense of the Herbrand-
G¨odel equational calculus, in 1935.7
Interestingly, G¨odel was not persuaded of its adequacy, when he was told
of Church’s suggestion to view intuitive or eﬀective computability in terms of
λ-deﬁnability in early 1934, ﬁnding the proposal “thoroughly unsatisfactory.”8
Church described G¨odel’s then suggestion to instead take an axiomatic approach
to the problem, in a letter to Kleene:
His [G¨odel’s ] only idea at the time was that it might be possible, in terms
of eﬀective calculability as an undeﬁned notion, to state a set of axioms
which would embody the generally accepted properties of this notion, and
to do something on that basis. . . . At that time he did speciﬁcally raise the
question of the connection between recursiveness in this new sense and
eﬀective calculability, but said he did not think that the two ideas could
be satisfactorily identiﬁed “except heuristically.”9
Church may have been inﬂuenced by G¨odel’s negative view of the adequacy of
λ-calculus, as in his lecture on his Thesis to the American Mathematical Society
in 1935, Church used the Herbrand-G¨odel equational calculus as a model of
4 [1], Sect. 14.8. Following Gandy we use the term “eﬀectively computable,” or just
“eﬀective,”to mean “intuitively computable.”.
5 See [7], which relies on Church’s [8]. See also [9]. Emphasis the author’s.
6 The phrase “Church’s Thesis” was coined by Kleene in 1943. See his [10].
7 The proof of the equivalence developed in stages. See Davis, [11] and Sieg, [12].
8 Church, letter to Kleene November 29, 1935. Quoted in Sieg, op. cit., and in Davis
[11].
9 Church, op.cit. In this talk and elsewhere we distinguish the axiomatic from the
logical method, viewing the former as an informal notion, and the latter as involving
a formalism.

44
J. Kennedy
eﬀective computation, i.e. recursiveness in the “new sense,” rather than the λ-
calculus.
In fact Church presented two approaches to computability in the AMS lec-
tures and in his subsequent 1936 [13], based on the lectures: Firstly algorithmic,
based still on what is now known as the untyped λ-calculus, i.e. the evaluation of
the value fm of a function by the step-by-step application of an algorithm—and
secondly logical, based on the idea of calculability in a logic:
And let us call a function F of one positive integer calculable within the
logic if there exists an expression f in the logic such that f(μ) = ν is
a theorem when and only when F(m) = n is true, μ and ν being the
expressions which stand for the positive integers m and n.10
In order to view computability in terms of calculability in a logic, one must
ﬁrst restrict the class of formal systems representing those computable functions.
As we noted, not just any formalism will serve! For Church this meant that the
theorems of the formal system should be recursively enumerable.11 A number-
theoretic function is taken to be eﬀective, then, if its values can be computed in
such an eﬀectively given formalism.
The argument appears to be circular.12 In Hilbert and Bernays’ 1939 Grund-
lagen der Mathematik II, the computable functions are also presented in terms
of a logical calculus, but here eﬀectivity is now reduced to primitive recursion.
In his [14], Sieg has this to say about Hilbert and Bernays’ improvement of
Church’s system:
In this way they provided the mathematical underpinnings for . . . Church’s
argument, but only relative to the recursiveness conditions: the crucial one
requires the proof predicate of deductive formalisms, and thus the steps
informal calculations, to be primitive recursive!
We now come to one of the topics of this note, the shift in perspective in
1934 noted by Gandy, writing: “. . . in 1934 the interest of the group shifted from
systems of logic to the λ-calculus and certain mild extensions of it: the λ −κ
and the λ −δ calculi.”13 Gandy does not speculate on the deeper reasons for
this shift; and indeed it is interesting that there are so few direct references to
10 [13], p. 357.
11 In detail, recursive enumerability would be guaranteed here by the so-called step-by-
step argument: if each step is recursive then f will be recursive; and three conditions:
(i) each rule must be a recursive operation, (ii) the set of rules and axioms must be
recursively enumerable, (iii) the relation between a positive integer and the expres-
sion which stands for it must be recursive. Conditions i-iii are Sieg’s formulation of
Church’s conditions. See Sieg, [12], p. 165. For Gandy’s formulation of the step-by-
step argument, see [1], p. 77.
12 See also Sieg’s discussion of the “semi-circularity” of the step-by-step argument in
his [12].
13 [1], p. 71. Of course this shift presaged a much more dramatic shift of perspective
in 1936, inaugurated by the work of Turing together with Post’s earlier work.

G¨odel’s Reception of Turing’s Model of Computability
45
the circularity problem in the writings of logicians working on computability at
the time. However it seems plausible that the circularity problem was at least
partly responsible for this shift away from logical systems, especially given the
initial inconsistency of the λ-calculus.
2.1
The “Scope Problem”: How General Are the Incompleteness
Theorems?
We turn now to G¨odel’s role in these developments. G¨odel was perhaps the ﬁrst
to suggest isolating the concept of eﬀective computability.14 His interest was
driven, at least in part, by an important piece of unﬁnished business as far as
the Incompleteness Theorems are concerned, in that it was not clear at the time
to which formal systems the theorems apply, outside of the fragment of the type
theory of Principia Mathematica he used.
In short, solving the scope problem depends on articulating a precise and
adequate notion of eﬀective computability, because the formal systems at issue
in the Incompleteness Theorems, are to be given eﬀectively.15
To this end, that is, with a wish to “make the incompleteness results less
dependent on particular formalisms,”17 G¨odel introduced in 1934 the general
recursive, or Herbrand-G¨odel recursive functions. It is striking from the point
of view of this note that he begins the section introducing those functions thus:
“Now we turn to some considerations which for the present have nothing to
do with a formal system.”, and deﬁnes the notion of “formal system” in the
next section as consisting of “symbols and mechanical rules relating to them.”18
G¨odel seems here to have all the elements behind the Turing conception of
computability in place. What is missing of course, is the model itself.
The Herbrand-G¨odel calculus allows for forms of recursions that go beyond
primitive recursion, however it was not clear to G¨odel at the time, that the
schema captured all recursions.19
G¨odel gave, in the same presentation, a precise deﬁnition of the conditions
a formal system must satisfy so that the incompleteness theorems apply to it.
These included the restriction that:
14 See Gandy’s [1], p. 72.
15 G¨odel was careful not to claim complete generality for the Second Incompleteness
Theorem in his 1931 paper:
For this [formalist JK] viewpoint presupposes only the existence of a consis-
tency proof in which nothing but ﬁnitary means of proof is used, and it is
conceivable that there exist ﬁnitary proofs that cannot be expressed in the
formalism of P (or of M and A).16
16 [15], p. 195. P is a variant of Principia Mathematica.
17 Sieg [16], p. 554.
18 [15], p. 346 and 349, resp. Emphasis added.
19 As G¨odel would later write to Martin Davis, “. . . I was, at the time of these lectures,
not at all convinced that my concept of recursion comprises all possible recursions.”
Quoted in [15], p. 341.

46
J. Kennedy
Supposing the symbols and formulas to be numbered in a manner similar
to that used for the particular system considered above, then the class of
axioms and the relation of immediate consequence shall be [primitive JK]
recursive.20
By 1935, G¨odel’s reﬂections on computability in the higher order context
began to point towards the possibility of a deﬁnitive notion of formal system.
Nevertheless, an, in G¨odel’s terminology now, absolute deﬁnition of eﬀective
computability was still missing at that point.21
3
Turing’s Analysis of Computability
In 1936, Turing gave a self-standing analysis of human eﬀective computability
and used it to solve the Entscheidungsproblem.
Rather than calculability in a logic, Turing analyzed eﬀectivity informally but
exactly, via the concept of a Turing Machine—a machine model of computability,
consisting of a tape scanned by a reader, together with a set of simple instructions
in the form of quadruples.23
We alluded to circularity in connection with approaches to computability
that are centered on the idea of calculability in a logic.24 The crucial point here
is that Turing’s analysis does not require the speciﬁcation of a logic at all.
The reaction to Turing’s work among the Princeton logicians was immedi-
ately positive. As Kleene would write in 1981, “Turing’s computability is intrin-
sically persuasive but λ-deﬁnability is not intrinsically persuasive and general
recursiveness scarcely so (its author G¨odel being at the time not at all per-
suaded).”
For G¨odel, as he would later explain to Hao Wang, Turing’s model of human
eﬀective calculability is, in some sense, perfect:
20 [15], p. 361.
21 As G¨odel wrote to Kreisel in 1965:
That my [incompleteness] results were valid for all possible formal systems
began to be plausible for me (that is since 1935) only because of the Remark
printed on p. 83 of ‘The Undecidable’ . . . But I was completely convinced only
by Turing’s paper.22
22 Quoted in Sieg [17], in turn quoting from an unpublished manuscript of Odifreddi,
p. 65.
23 Or quintuples, in Turing’s original presentation.
24 As Sieg puts it [14], “The work of G¨odel, Church, Kleene, and Hilbert and Bernays
had intimate historical connections and is still of deep interest. It explicated calcula-
bility of functions by exactly one core notion, namely calculability of their values in
logical calculi via (a ﬁnite number of) elementary steps. But no one gave convincing
and non-circular reasons for the proposed rigorous restrictions on the steps that are
permitted in calculations.”.

G¨odel’s Reception of Turing’s Model of Computability
47
The resulting deﬁnition of the concept of mechanical by the sharp con-
cept of “performable by a Turing machine” is both correct and unique
. . . Moreover it is absolutely impossible that anybody who understands the
question and knows Turing’s deﬁnition should decide for a diﬀerent con-
cept.25
And Turing’s analysis led to the complete solution of the scope problem:
In consequence of later advances, in particular of the fact that, due to
A. M. Turing’s work, a precise and unquestionably adequate deﬁnition of
the general concept of formal system can now be given, the existence of
undecidable arithmetical propositions and the non-demonstrability of the
consistency of a system in the same system can now be proved rigorously
for every consistent formal system containing a certain amount of ﬁnitary
number theory.
Turing’s analysis thus settled deﬁnitively the adequacy question for com-
putability. For G¨odel, and for the logicians of the time, the Turing Machine was
not just another in the list of acceptable notions of computability—it is the
grounding of all of them.
We suggested that the issue of circularity was in the background of the shift
away from a logical orientation to the problem of isolating and precisifying the
notion of intuitive computability. Once again this is the problem of how to spell
out the concept of eﬀectivity of a logical system that embeds one’s notion of
computability, without invoking that very notion. How did the Turing model of
computation solve this problem for G¨odel? We explain it thus: Turing’s model
of computation allows for an autonomous logical perspective, because it is itself
logic free.
What was the role of conﬂuence? Church’s Thesis identiﬁed eﬀective calcu-
lability with λ-calculability, and then with Herbrand-G¨odel calculability, after
the equivalence between the two was established. Prior to Turing’s work, the
available conﬂuence was seen as justifying adequacy in a weak sense only. Once
one has a grounding example in hand this changes—conﬂuence now plays an
epistemologically important evidentiary role.
It is striking that Emil Post, who called for the return to meaning and truth
in the opening of his [19], and the downplaying of what he called “postula-
tional thinking,” aligns him both ideologically and mathematically with these
developments. As it turns out, Post’s recommendation to develop recursion the-
ory mathematically, by stripping oﬀthe formalism with which the theory was
encumbered, led to the formalism free development of recursion theory just along
the lines he advocated. It also gave rise to the development of Post Systems, a
model of computability very similar to Turing’s.
The project of developing an autonomous logical perspective permeated
G¨odel’s outlook from then on. G¨odel alludes to it a number of times in his
Princeton Bicentennial Lecture, in connection with ﬁnding absolute notions of
25 Remark to Hao Wang, [18], p. 203. Emphasis added.

48
J. Kennedy
decidability and provability. One can also read the perspective into G¨odel’s over-
arching goal of attaining decidability in set theory—for how else to achieve decid-
ability in set theory, except by remaining, as we have called it, formalism free?
4
Kripke and the Entscheidungsproblem
Kripke advocates a, as he calls it, logical orientation to the problem of isolating
the notion of eﬀective computability.
My main point is this: a computation is a special form of mathematical
argument.26
He then asks, given that such an approach would have been very easily within
reach of G¨odel and other logicians working in the period immediately after the
1931 Incompleteness Theorems, why wasn’t it noticed that a negative solution
to the Entscheidungsproblem follows immediately?
Suppose we had taken derivability by a computation expressible in a ﬁrst-
order language as one’s basic deﬁnition of computability. Then given the
G¨odel Completeness Theorem, any conventional formalism for ﬁrst-order
logic will be suﬃcient to formalise such derivability. . . . It will be a short
and direct step to conclude the undecidability in this sense of the Entschei-
dungsproblem.27
Kripke gives the argument, which necessarily includes the notion of validity.
He concludes, very reasonably in our view, that G¨odel would have been reluctant
to invoke a notion of truth in the proof, had he arrived at that proof. Indeed it
is well known that G¨odel’s initial proof of the Incompleteness Theorem followed
from the undeﬁnability of truth together with the observation that ﬁrst order
provability is not only deﬁnable, but r.e.28
We suggest in this talk that the evidence in the record regarding G¨odel’s
response to the Turing model, together with the developments leading up to
it (as recounted here), might also be taken into account in explaining G¨odel’s
so-called blindness. It just might be that for G¨odel, grounding the notion of
computability required an altogether new mathematical idea, and not a logical
one. We saw how close he came to Turing’s conception in 1934, just before he
turned his attention to the continuum problem in set theory.
References
1. Gandy, R.: The conﬂuence of ideas in 1936. In: The universal turing machine: A
half-century survey, pp. 55–111. Oxford Science Publications, Oxford University
Press, New York (1988)
26 [2], p. 80.
27 ibid, p. 85.
28 See G¨odel’s letter to van Heijenoort of February 22, 1964, in [20].

G¨odel’s Reception of Turing’s Model of Computability
49
2. Kripke, S.: The church-turing “Thesis” as a special corollary of g¨odel’s complete-
ness theorem. In: Copeland, B.J., Posy, C.J., Shagrir, O. (eds.) Computability:
G¨odel, Church, and Beyond. MIT Press, Cambridge (2013)
3. Sieg, W.: Hilbert’s Programs and Beyond. Oxford University Press, Oxford (2013)
4. Kennedy, J.: Turing, G¨odel and the “Bright Abyss”. In: Philosophical Explorations
of the Legacy of Alan Turing, vol. 324 of Boston Studies in Philosophy (Springer)
5. G¨odel, K.: ¨Uber formal unentscheidbare S¨atze der Principia Mathematica und
verwandter Systeme I. Monatsh. Math. Phys. 38, 173–198 (1931)
6. Church, A.: A set of postulates for the foundation of logic I, II. Ann. Math. 33(2),
346–366 (1932)
7. Kleene, S.C., Rosser, J.B.: The inconsistency of certain formal logics. Ann. Math.
36(2), 630–636 (1935)
8. Church, A.: The richard paradox. Amer. Math. Monthly 41, 356–361 (1934)
9. Kleene, S.C.: Origins of recursive function theory. Ann. Hist. Comput. 3, 52–67
(1981)
10. Kleene, S.C.: Recursive predicates and quantiﬁers. Trans. Am. Math. Soc. 53,
41–73 (1943)
11. Davis, M.: Why G¨odel didn’t have church’s thesis. Inf. Control 54, 3–24 (1982)
12. Sieg, W.: Step by recursive step: Church’s analysis of eﬀective calculability. Bull.
Symbolic Log. 3, 154–180 (1997)
13. Church, A.: A note on the Entscheidungsproblem. J. Symbolic Log. 1(1), 40–41
(1936). (Correction 1:101–102)
14. Sieg, W.: Church without dogma: Axioms for computability. In: Cooper, S.B.,
L¨owe, B., Sorbi, A. (eds.) New Computational Paradigms, pp. 139–152. Springer,
New York (2008)
15. G¨odel, K.: Collected works. Vol. I. The University Press, New York (1986). Pub-
lications 1929–1936, Edited and with a preface by Solomon Feferman. Clarendon
Press, Oxford
16. Sieg, W.: On computability. In: Philosophy of Mathematics. Handbook of the
Philosophy of Science, pp. 535–630. Elsevier/North-Holland, Amsterdam (2009)
17. Sieg, W.: G¨odel on computability. Philos. Math. 14(3), 189–207 (2006)
18. Wang, H.: A Logical Journey. Representation and Mind. MIT Press, Cambridge
(1996)
19. Post, E.L.: Recursively enumerable sets of positive integers and their decision prob-
lems. Bull. Am. Math. Soc. 50, 284–316 (1944)
20. G¨odel, K.: Collected Works. V: Correspondence H-Z. Oxford University Press,
Oxford (2003). Feferman, S., et al. (eds.)

A Guided Tour to Computational Haplotyping
Gunnar W. Klau1 and Tobias Marschall2,3(B)
1 Heinrich Heine University, D¨usseldorf, Germany
2 Center for Bioinformatics, Saarland University, Saarbr¨ucken, Germany
3 Max Planck Institute for Informatics, Saarbr¨ucken, Germany
marschal@mpi-inf.mpg.de
Abstract. Human genomes come in pairs: every individual inherits
one version of the genome from the mother and another version from
the father. Hence, every chromosome exists in two similar yet dis-
tinct “copies”, called haplotypes. The problem of determining the full
sequences of both haplotypes is known as phasing or haplotyping. In
this paper, we review diﬀerent approaches for haplotyping and point out
how they are formalized as optimization problems. We survey diﬀerent
technologies and, in this way, provide guidance on the characteristics of
problem instances resulting from present day technologies. Furthermore,
we highlight open algorithmic challenges.
1
Haplotyping
Humans and many other species are diploid. That is, every individual inherits
two versions of each autosomal chromosome, one from its mother and one from its
father. We refer to these two versions of a chromosome’s DNA sequence as hap-
lotypes. The two haplotypes inherited by mother and father are very similar but
not identical, reﬂecting the genetic diﬀerences between the parents. Determining
the two alleles present at a particular genetic locus is known as genotyping, and
can be achieved using various technologies including microarrays and short-read
sequencing.
In contrast to genotyping, haplotyping aims to reconstruct the full sequences
of the two haplotypes (Fig. 1). Moving from (sequences of) genotypes to haplo-
types is known as phasing. We use the terms haplotyping and phasing inter-
changeably in the following. The knowledge of haplotypes is important for
fundamental and clinical research. On the one hand, haplotype information
allows addressing questions in population genetics, for instance to study demo-
graphic history [1] and selection [2]. On the other hand, haplotype-speciﬁc phe-
notypes arise when two variants interact [3], e.g. when a disruptive variant in a
coding region is combined with a silencing variant in an associated regulatory
element. In particular, the interaction between variants in coding regions and
enhancers is currently gaining attention [4]. All of this highlights the pressing
need for techniques to reliably phase human genomes along whole chromosomes.
In this paper, we review diﬀerent approaches to reconstruct haplotypes from
various data sources. It is meant as an introduction to the topic for computer
c
⃝Springer International Publishing AG 2017
J. Kari et al. (Eds.): CiE 2017, LNCS 10307, pp. 50–63, 2017.
DOI: 10.1007/978-3-319-58741-7 6

A Guided Tour to Computational Haplotyping
51
Fig. 1. Diﬀerence between genotype and haplotype data. Gray bars represent the two
homologous chromosomes, i.e. the two versions of a chromosome inherited by the
mother (marked M) and the father (marked P). Genotype data (top) tells which pair
of alleles is present at a site (white circles). Haplotype data (bottom) gives the full
sequence of both chromosomal copies. All four possible haplotypes compatible with
the genotypes above are shown.
scientists, who want to learn which problem formulations are relevant and how
practical problem instances look like.
We start by motivating the relevance of haplotype phasing in more detail in
Sect. 2. Then, in Sect. 3, we introduce three paradigms for haplotyping based on
three diﬀerent data sources: genotype data from populations, genotype data from
families, and sequencing reads. From there on, we mainly focus on read-based
phasing and introduce its most common formalization (the Minimum Error Cor-
rection Problem) in Sect. 4. Section 5 gives an overview of current technologies
and hence provides insights into the problem instances encountered in practice.
We brieﬂy survey techniques to optimally solve the Minimum Error Correction
problem in Sect. 6. Latest developments on using family information and read
information in a uniﬁed way are presented in Sect. 7. We conclude the paper by
pointing out some important open challenges in Sect. 8.
2
Relevance of Phasing
To illustrate the importance of phasing, consider two alleles “A” and “a” for a
variant in a regulatory region, where the allele A strongly downregulates expres-
sion of a target gene; and two alleles “B” and “b” for a variant in the coding
region of that gene, where the allele B is so disruptive that the resulting protein
cannot perform its function. If a person is heterozygous in both variants, i.e. has
genotypes A/a and B/b, four haplotype conﬁgurations are possible, as shown in
Fig. 1. The two haplotypes can either be AB and ab or they are Ab and aB. For
the former combination, suﬃcient amounts of functional protein might still be
produced from haplotype ab. The latter combination can lead to strong phe-
notypic consequences because haplotype Ab hardly expresses the gene product

52
G.W. Klau and T. Marschall
(due to the silencing allele A) while haplotype aB expresses the non-functional
protein (due to the disruptive allele B).
Enhancers are sequence elements that regulate the expression of their tar-
get genes. Unlike promotor regions, enhancers can be distant from their targets,
which is made possible by the formation of DNA loops: although distant on the
chromosome sequence, promotor and enhancer are brought into proximity in 3D
space [5]. Single-nucleotide polymorphisms (SNPs) which have been linked to
phenotypic traits by genome-wide association studies (GWAS) predominantly
reside in enhancers and are even more strongly enriched in super enhancers [6],
which are clusters of enhancers that often play key roles in cell diﬀerentiation
[7]. It is hypothesized that multiple variants in linkage disequilibrium (LD) on a
super enhancer often collectively bring forward the phenotype changes underly-
ing GWAS hits [8]. That means, many variants located on the same haplotype
are needed to explain the phenotype. Again, a likely explanation is physical
interaction between diﬀerent variant sites, and the proteins that bind to them,
in three dimensional space.
Beyond that, latest ﬁndings show that combinatorial eﬀects between (some-
times distant) regulatory variants that are not in LD with the respective GWAS
hit SNP could substantially contribute to the observed phenotypes [4]. That is,
variants that are not correlated with each other often interact to bring forward
an eﬀect, for instant when a change in an enhancer is reinforced by a change
in the corresponding promotor. Such interactions have the potential to explain
parts of the “missing heritability” [4,9], i.e. the gap between epidemiologically
observed genetic contribution to a disease and known genetic variants explain-
ing it. Note that all these short- and long-range interactions (within enhancers
and between enhancer, promoter and coding sequence) take place on one copy
of the two homologous chromosomes, that is, on single haplotypes. To study
(common and rare) genomic diseases from this promising new angle, we hence
urgently need tools to obtain haplotype-resolved genomes. We refer to [3,10] for
further reading on the relevance of haplotype-resolved genomes, including many
examples of haplotype-speciﬁc clinical conditions.
3
Phasing Approaches
There are three diﬀerent paradigms for haplotyping, which we brieﬂy review in
the following.
3.1
Population-Based Haplotyping
Population-based haplotyping takes genotypes from many individuals as input
and infers haplotypes by exploiting shared haplotype tracts that exist due to
common ancestry and limited recombination [11]. Prominent examples of soft-
ware systems for population-based phasing are Beagle [12], ShapeIt [13–15] and
Eagle [16,17]. They have been successfully employed in population-scale sequenc-
ing eﬀorts such as the 1000 Genomes [18] and the Genome of the Netherlands

A Guided Tour to Computational Haplotyping
53
[19,20] projects. In regions of strong linkage disequilibrium, this approach yields
highly accurate haplotypes. A main advantage of this technique lies in its applica-
bility when only genotype data from a large cohort are available. This is often
the case, as such data are comparatively cheap to obtain. Its main limitation
lies in the fact that only variants that are common enough to allow for robust
statistical inference can be reliably phased, which exclude low-frequency variants
and de novo variants, which are private to one individual, although these types
of variants are of particular medical interest.
Once a (large) set of haplotypes, known as reference panel, exists, additional
samples can be phased with respect to this panel. To do this, one seeks to ﬁnd
two paths through the panel that explain the genotypes of the additional sample.
This problem is known as parsing genotypes with respect to a founder set and
admits a polynomial-time solution by dynamic programming [21].
3.2
Genetic Haplotyping
Genetic haplotyping takes genotype data for related individuals with a known
pedigree as input and determines haplotypes based on the constraints imposed by
Mendelian segregation. This approach is very successful when a large pedigree
and high-quality genotypes are available. Examples of corresponding software
tools include Merlin [22], HaploScribe [23], and Hapi [24]. However, genetic hap-
lotyping has the intrinsic limitation of not being able to phase variants that are
heterozygous in all individuals in the pedigree.
To illustrate the idea, consider a case where, at a given locus, the mother has
a genotype of B/b, the father has genotype B/B and the child has B/b. The b allele
in the child can only have been inherited from the mother and hence b is on the
maternal haplotype. Likewise, the b allele in the mother is on the transmitted
haplotype. By applying the same reasoning to all variants, one can construct
chromosome-length haplotypes. That is, at every heterozygous site in the child
the alleles are determined to be on the maternal or paternal haplotype and, for
each parent, we determine whether an allele is on the transmitted haplotype or
on the non-transmitted haplotype. Note, however, that recombination events,
i.e. changes of which haplotype in a parent is transmitted, cannot be detected
from trio data, but requires larger pedigrees.
3.3
Molecular Haplotyping
Molecular haplotyping experimentally observes individual haplotypes or frag-
ments thereof in a single individual [10]. The most prominent technique to
directly determine the sequence of haplotype fragments is next-generation
sequencing (NGS). Each read generated by an NGS platform represents a piece
of one of the two haplotypes. Stitching together these pieces (after mapping them
to a reference) into longer haplotype fragments is known as read-based phasing.
The ability to reconstruct haplotypes is limited by the length of the sequencing
reads in comparison to the distance between heterozygous sites. Only reads that
cover two or more heterozygous sites are helpful for read-based phasing and,

54
G.W. Klau and T. Marschall
to achieve a full-chromosome phasing, all pairs of variants must be (directly or
indirectly) connected by sequencing reads. Therefore, data from third-generation
technologies that deliver comparatively long reads, such as those marketed by
PacBio or Oxford Nanopore, are better suited for this task than standard Illu-
mina data. Most recently, the even more challenging task of de novo assembly
(i.e., not using a reference genome) of both haplotypes of a diploid individual has
been attempted, for instance using PacBio [25] or 10X Genomics [26] technol-
ogy. Beyond next-generation sequencing, a number of specialized experimental
protocols to determine haplotypes exist, as reviewed in [27].
3.4
Hybrid Approaches
Combinations of the above approaches have also been explored: Population-
based haplotyping tools can make use of pedigree information [28,29] and
sequencing data [30] and the combined use of sequencing data and pedigree
information has been shown to yield markedly better result than sequencing
data alone [31].
4
Minimum Error Correction (MEC)
The key challenge in molecular haplotyping is to distinguish true genetic vari-
ability from sequencing errors. Among the computational models addressing this
task, the Minimum Error Correction problem (MEC) [32] is the most accepted
and relevant model in practice. MEC asks for a minimum cost correction of
the sequencing data to allow a conﬂict-free bipartition of the reads to the two
chromosomal copies.
The input for MEC is a fragment matrix F ∈{0, 1, ‘−’}m×n, where the rows
1 ≤i ≤m correspond to the fragments and the columns 1 ≤j ≤n correspond
to the variant positions. A non-gap entry F(i, j) ̸= ‘−’ speciﬁes that read i
covers variant j and gives evidence for the reference allele when F(i, j) = 0 or
the alternative allele when F(i, j) = 1.
Two rows i1 and i2 of F are in conﬂict if there is a position j such that
F(i1, j) ̸= ‘−’ and F(i2, j) ̸= ‘−’ but F(i1, j) ̸= F(i2, j). A set of rows is
conﬂict-free if it does not contain conﬂicting row pairs.
A fragment matrix F is feasible if there exists a bipartition (I0, I1) of its
rows such that both I0 and I1 are conﬂict-free. Such a bipartition determines
the two haplotypes h0, h1 ∈{0, 1, ‘−’}n in the following, natural way:
h0(j) =
⎧
⎪
⎨
⎪
⎩
0
if F(i, j) = 0 for some i ∈I0
1
if F(i, j) = 1 for some i ∈I0
−
otherwise,
h1(j) =
⎧
⎪
⎨
⎪
⎩
0
if F(i, j) = 0 for some i ∈I1
1
if F(i, j) = 1 for some i ∈I1
−
otherwise.

A Guided Tour to Computational Haplotyping
55
In practice, the entries in a fragment matrix are associated with phred-
scaled base qualities Q ∈Nm×n that correspond to estimated probabilities of
10−Q(i,j)/10 that entry F(i, j) has been wrongly sequenced. These phred scores
serve as costs of ﬂipping entries and allow less conﬁdent base calls to be cor-
rected at lower cost compared to high conﬁdence ones. The error distance of
two fragment matrices F and F ′ is
dQ(F, F ′) =
m

i=1
n

j=1

0
F(i, j) = F ′(i, j)
Q(i, j)
F(i, j) ̸= F ′(i, j).
We can now state the weighted Minimum Error Correction problem formally.
Problem 1 (wMEC). Given fragment matrix F and quality matrix Q, ﬁnd a
conﬂict-free fragment matrix F ′ with minimum error distance dQ(F, F ′).
Solving the wMEC problem corresponds to minimizing the sum of phred-
scaled probabilities and is therefore equivalent to ﬁnding a maximum likelihood
bipartition of reads. MEC and its weighted variant wMEC are NP-hard [32],
even if there are no internal gaps in the fragments [33,34], and do not admit a
constant-factor approximation [35].
5
Relevant Technologies
We now brieﬂy review the most relevant sources of haplotype information and
explain their characteristics with respect to the MEC problem. To put read
lengths into perspective, we note that, for human genomes, one observes around
one heterozygous single-nucleotide variant (SNV) every 1 kbp on average. Read-
based phasing requires reads that cover at least two heterozygous sites. Refer
to Fig. 2 for an illustration of how the diﬀerent data sources (surveyed in the
following) give rise to rows in the fragment matrix used as input for MEC. This
exempliﬁes the diﬀerences in number and distribution of non-dash characters
between technologies.
5.1
Illumina Sequencing
Illumina instruments constitute the most common sequencing platform today.
The standard mode of operation yields paired-end reads, where one DNA frag-
ment (of usually 300–1000 bp) is sequenced from both ends. Each of these read
ends typically have a length of 100–150 bp for HiSeq instruments and of 250–
300 bp for MiSeq instruments. Given these characteristics, standard Illumina
data are of limited use for read-based phasing since rather few read pairs cover
two or more heterozygous variants.

56
G.W. Klau and T. Marschall
Fig. 2. Illustration of how diﬀerent technologies contribute to the fragment matrix
F which is the input to the MEC problem. For human chromsomes, the number of
heterozygous variants n is usally on the order of 105. Weights are shown in subscripts
(red). This toy example shows qualitative diﬀerences in terms of read length and span
(i.e. distance from ﬁrst to last non-dash variant in a row) between data types. (Color
ﬁgure online)
5.2
Mate-Pair or Jumping Libraries
Mate-pair or jumping libraries are created by circularizing longer DNA frag-
ments, followed by paired-end Illumina sequencing across the fusion site [36].
As a result, one obtains pairs of reads that are further apart than for regular
paired-end sequencing. Typical insert sizes of mate pair libraries are between
3 kbp and 5 kbp. Mate pair reads do not cover more sequence than paired-end
reads, but span longer chromosomal distances. Therefore the fraction of mate
pairs usable for phasing is equally low (as for paired ends), but those pairs that
do cover two heterozygous sites establish a phase connection over a longer dis-
tance. Combining several mate-pair libraries with diﬀerent insert size increases
the utility of these data for phasing.
5.3
Linked-Read Sequencing
10X Genomics markets a technology to perform linked-read sequencing of high-
molecular weight DNA [37]. Long DNA fragments of up to 100 kbp are used as
input and separated using micro-ﬂuidics techniques. Each of these fragments is
labeled with a barcode such that the probability of assigning the same barcode

A Guided Tour to Computational Haplotyping
57
to diﬀerent fragments is very low. Long fragments are broken into (barcoded)
short fragments that are then subject to standard Illumina sequencing. Since
short reads with the same barcode are highly likely to have originated from the
same long fragment and hence from the same haplotype, this data type is by far
more powerful for phasing than Illumina sequencing alone [37]. 10X data can be
used in two diﬀerent forms, either the mapped and barcoded reads can be used
directly to form one row in the allele matrix per bar-code, or the phased blocks
output by 10X’ proprietary Long Ranger software can be taken as input rows.
These blocks are typically several Mbp long.
5.4
Third-Generation Sequencing Technologies
The PacBio and Oxford Nanopore sequencing platforms both deliver long but
error-prone reads. Although read lengths and error rates diﬀer for the speciﬁc
instrument and chemistry versions, error rates are typically around 10% and
average read-lengths on the order of magnitude of 10 kbp. In contrast to Illumina
sequencing, both platforms are prone also to indel errors. The resulting long reads
usually contain multiple heterozygous sites and are hence phase informative,
which is a key advantage for the purpose of reconstructing haplotypes. As an
additional advantage, the read-mapping ambiguity in repetitive areas of the
genome is reduced compared to short reads, because long reads are more likely
to be longer than a repeat unit. This translates into the ability to resolve many
diﬃcult regions inaccessible to Illumina sequencing [38].
5.5
StrandSeq
StrandSeq is a specialized protocol for haplotype-resolved single-cell sequencing
[39]. A single cell undergoes one cell division in the presence of bromodeoxyuri-
dine (BrdU), which is incorporated instead of thymine during DNA replication,
followed by selective degradation of the newly synthesized strands and library
preparation. As a result, one can determine the haplotype of origin of each indi-
vidual read based on its directionality. We refer to [39] for full details. Below
0.1-fold coverage is obtained from one single cell, so that many cells need to
be processed to cover the full genome. While this technique is labor and cost
intensive, it delivers chromosome-length resolution of haplotypes. Each single
cell results in two rows (for two haplotypes) in our allele matrix. These two rows
span the full chromosome but are rather sparse.
5.6
Chromsome Conformation Capturing
Hi-C is an experimental protocol to capture the three-dimensional conformation
of a chromosome in the nucleus [40]. It is based on cross-linking DNA stretches
that are in close proximity in space, which includes pieces of DNA that are
far apart in terms of (one dimensional) chromosomal coordinates or are even
located on diﬀerent chromosomes. The cross-linked DNA fragments can then be

58
G.W. Klau and T. Marschall
sequenced, resulting in paired-end reads where each read-end comes from one of
the fragments that have been in physical contact. Contacts between segments of
the same copy of a chromosome are much more likely than between a chromosome
and its homolog, because each chromosome is located in its own “territory”. In
other words, Hi-C read pairs that both map to the same chromosome are likely
to have originated from the same haplotype. Hi-C data is hence valuable for
phasing [40] and each read pair translates into one row in our allele matrix.
6
Solving the MEC Problem
Many exact and heuristic approaches exist to solve the MEC and wMEC prob-
lems. We refer to the review [41] for heuristic approaches and focus on exact
methods, which are guaranteed to ﬁnd an optimal solution, in the following.
The currently best exact approaches for MEC and wMEC are ﬁxed-parameter
tractable (FPT) algorithms and integer linear programming (ILP) based algo-
rithms.
He et al. [42] proposed an exact dynamic programming algorithm with a run-
time of O(2Lmn), where m is the number of reads, n is the number of variants (as
in Sect. 4), and L is the maximum number of variants covered by any read. Due
to being exponential in L, a quantity proportional to the read length in practice,
the algorithm is only suitable for short-read data. Deng et al. [43] suggested a
diﬀerent dynamic programming algorithm for MEC, which is exponential in the
maximum coverage of a SNP, but is linear in the number of variants. Its runtime
is O(2cnc), where c is the maximum coverage across all columns. In particu-
lar, the running time of this DP does not depend on the read length, which
is beneﬁcial for upcoming long-read sequencing data. In our previous approach
WhatsHap [44,45], we independently arrived at a similar DP as [43] to solve
wMEC (where [43] consider unweighted MEC), but achieve a better runtime of
O(2cn) due to enumerating read bipartitions in Gray code order. The algorithm
by Kuleshov [46] approached the weighted MEC problem in a message-passing
framework and arrived at the same DP used in [43,45]. Pirola et al. [47] consid-
ered a restricted variant of MEC, in which up to k corrections are allowed per
SNP position, and presented an FPT algorithm that runs in time O(ckLn).
These DP-based algorithms work well for maximum coverage values up to
20 or 25. Instances with higher coverage cannot be solved to optimality in rea-
sonable computing time with these methods. Note in this context that each row
contributes to the “coverage” from its ﬁrst to its last non-dash position, regard-
less of intermediate dash positions. That means that the presence of many sparse
rows, such as generated by StrandSeq or Hi-C, lead to diﬃculties for these solvers
and, in particular, instances arising from combining diﬀerent technologies as out-
lined above can often not be solved anymore.
The ﬁrst ILP formulation for MEC was given by Fouilhoux and Mahjoub
[48] and is based on a reduction to the maximum bipartite induced subgraph
problem. Chen et al. [49] introduced a linearization of a simple quadratic pro-
gram for MEC, which they later adapted to wMEC [50]. This approach shows

A Guided Tour to Computational Haplotyping
59
promising running times due to strong pre-processing rules, which are, however,
only eﬀective in the all-heterozygous case.
7
Minimum Error Correction on Pedigrees (PedMEC)
The information inherent to genotypes from a whole family and inherent to
sequencing reads are orthogonal and complement each other. Hence, genetic
phasing and read-based phasing can and should be treated in a uniﬁed frame-
work. The Minimum Error Correction on Pedigrees (PedMEC) problem is such a
generalization [31]. The input for PedMEC consists of multiple fragment matri-
ces and genotypes for a whole pedigree of individuals. Consider three frag-
ment/quality matrix pairs (Fm, Qm), (Ff, Qf), and (Fc, Qc), for mother, father,
and child, respectively, and per-site phred-scaled recombination costs X ∈Nn.
Solving the PedMEC problem for this mother-father-child trio requires to deter-
mine which entries to ﬂip to make the fragment matrices feasible and to compute
two transmission vectors tm→c, tf→c ∈{0, 1}n such that the sum of phred-scaled
ﬂipping and transmission costs are minimal. The feasible fragment matrices give
rise to haplotypes (h0
m, h1
m), (h0
f, h1
f), (h0
c, h1
c), for mother, father, and child,
respectively.
The transmission vectors formalize Mendelian inheritance. The values
tm→c(j) and tf→c(j) specify which allele at site j is transmitted from mother to
child and from father to child, respectively, in the following way:
h0
c(j) =

h0
m(j)
tm→c(j) = 0
h1
m(j)
tm→c(j) = 1
and
h1
c(j) =

h0
f(j)
tf→c(j) = 0
h1
f(j)
tf→c(j) = 1.
The notation can be extended in a straightforward manner to large pedigrees
that contain many such relationships. We refer the reader to [31] for full details. It
is demonstrated in [31] that a 2-fold sequencing coverage on each indvidual from
a trio yields better results than 15-fold coverage when phasing each individual
separately, highlighting the power of this uniﬁed approach.
8
Discussion and Future Challenges
In this paper, we review diﬀerent paradigms for haplotyping and particularly
emphasized read-based phasing and its formalization as the Minimum Error
Correction (MEC) problem. We choose this emphasis because we argue that
haplotyping based on direct evidence (such as long reads) will become the stan-
dard mode of operation once long read technologies have gained widespread
adoption.
From our point of view, the most pressing challenges to be addressed by the
bioinformatics community are:
1. Solvers for the MEC problem have predominantly been engineered to be eﬃ-
cient on consecutive reads; that is, on data where each row in the fragment

60
G.W. Klau and T. Marschall
matrix contains exactly one block of consecutive non-dash characters. With
the advent of technologies like Hi-C and StrandSeq, it is important to develop
practically eﬃcient solvers for these data types and, in particular, for frag-
ment matrices constructed from a mix of diﬀerent data sources.
2. Developing practically eﬃcient algorithms for solving the PedMEC problem
for higher coverages. The only available solver [31] is based on a dynamic
programming algorithm that scales exponentially in the cumulative coverage
across individuals. While this already allows to obtain high-quality haplo-
types for small pedigrees, it does not scale well to larger pedigrees and higher
coverages.
3. While the problem formulations for pedigree-based and read-based phasing
have been uniﬁed in the PedMEC problem, a generalization that incorporates
population-based phasing is missing. Such a generalization would allow to
handle all available data sources in a uniﬁed way.
4. Phasing polyploid genomes is even more challenging in theory [35] and prac-
tice. Exact solvers for the k-ploid case do not exist yet, but are needed to
resolve, for example, plant genomes.
References
1. Lawson, D.J., Hellenthal, G., Myers, S., Falush, D.: Inference of population struc-
ture using dense haplotype data. PLoS Genet. 8(1), e1002453 (2012)
2. Sabeti, P.C., Varilly, P., Fry, B., et al.: Genome-wide detection and characterization
of positive selection in human populations. Nature 449(7164), 913–918 (2007)
3. Tewhey, R., Bansal, V., Torkamani, A., Topol, E.J., Schork, N.J.: The importance
of phase information for human genomics. Nat. Rev. Genet. 12(3), 215–223 (2011)
4. Corradin, O., Cohen, A.J., Luppino, J.M., Bayles, I.M., Schumacher, F.R.,
Scacheri, P.C.: Modeling disease risk through analysis of physical interactions
between genetic variants within chromatin regulatory circuitry. Nat. Genet. 48(11),
1313–1320 (2016)
5. Shlyueva, D., Stampfel, G., Stark, A.: Transcriptional enhancers: from properties
to genome-wide predictions. Nat. Rev. Genet. 15(4), 272–286 (2014)
6. Hnisz, D., Abraham, B.J., Lee, T.I., Lau, A., Saint-Andr, V., Sigova, A.A., Hoke,
H.A., Young, R.A.: Super-enhancers in the control of cell identity and disease. Cell
155(4), 934–947 (2013)
7. Whyte, W.A., Orlando, D.A., Hnisz, D., Abraham, B.J., Lin, C.Y., Kagey, M.H.,
Rahl, P.B., Lee, T.I., Young, R.A.: Master transcription factors and mediator
establish super-enhancers at key cell identity genes. Cell 153(2), 307–319 (2013)
8. Corradin, O., Saiakhova, A., Akhtar-Zaidi, B., Myeroﬀ, L., Willis, J., Cowper-
Sallari, R., Lupien, M., Markowitz, S., Scacheri, P.C.: Combinatorial eﬀects of
multiple enhancer variants in linkage disequilibrium dictate levels of gene expres-
sion to confer susceptibility to common traits. Genome Res. 24(1), 1–13 (2014)
9. Eskin, E.: Discovering genes involved in disease and the mystery of missing heri-
tability. Commun. ACM 58(10), 80–87 (2015)
10. Glusman, G., Cox, H.C., Roach, J.C.: Whole-genome haplotyping approaches and
genomic medicine. Genome Med. 6(9), 73 (2014)
11. Browning, S.R., Browning, B.L.: Haplotype phasing: existing methods and new
developments. Nat. Rev. Genet. 12(10), 703–714 (2011)

A Guided Tour to Computational Haplotyping
61
12. Browning, S.R., Browning, B.L.: Rapid and accurate haplotype phasing and
missing-data inference for whole-genome association studies by use of localized
haplotype clustering. Am. J. Hum. Genet. 81(5), 1084–1097 (2007)
13. Delaneau, O., Marchini, J., Zagury, J.F.: A linear complexity phasing method for
thousands of genomes. Nat. Meth. 9(2), 179–181 (2012)
14. Delaneau, O., Zagury, J.F., Marchini, J.: Improved whole-chromosome phasing for
disease and population genetic studies. Nat. Meth. 10(1), 5–6 (2013)
15. O’Connell, J., Sharp, K., Shrine, N., Wain, L., Hall, I., Tobin, M., Zagury, J.F.,
Delaneau, O., Marchini, J.: Haplotype estimation for biobank-scale data sets. Nat.
Genet. 48(7), 817–820 (2016)
16. Loh, P.R., Palamara, P.F., Price, A.L.: Fast and accurate long-range phasing in a
UK Biobank cohort. Nat. Genet. 48(7), 811–816 (2016)
17. Loh, P.R., Danecek, P., Palamara, P.F., Fuchsberger, C., Reshef, Y.A., Finucane,
H.K., Schoenherr, S., Forer, L., McCarthy, S., Abecasis, G.R., Durbin, R., Price,
A.L.: Reference-based phasing using the Haplotype Reference Consortium panel.
Nat. Genet. 48(11), 1443–1448 (2016)
18. The 1000 Genomes Project Consortium: A global reference for human genetic
variation. Nature 526(7571), 68–74 (2015)
19. The Genome of the Netherlands Consortium: Whole-genome sequence variation,
population structure and demographic history of the dutch population. Nat. Genet.
46, 818–825 (2014)
20. Hehir-Kwa, J.Y., Marschall, T., Kloosterman, W.P., et al.: A high-quality human
reference panel reveals the complexity and distribution of genomic structural vari-
ants. Nat. Commun. 7, 12989 (2016)
21. Rastas, P., Ukkonen, E.: Haplotype inference via hierarchical genotype parsing.
In: Giancarlo, R., Hannenhalli, S. (eds.) WABI 2007. LNCS, vol. 4645, pp. 85–97.
Springer, Heidelberg (2007). doi:10.1007/978-3-540-74126-8 9
22. Abecasis, G.R., Cherny, S.S., Cookson, W.O., Cardon, L.R.: Merlin–rapid analysis
of dense genetic maps using sparse gene ﬂow trees. Nat. Genet. 30(1), 97–101
(2002)
23. Roach, J.C., Glusman, G., Hubley, R., Montsaroﬀ, S.Z., Holloway, A.K., Mauldin,
D.E., Srivastava, D., Garg, V., Pollard, K.S., Galas, D.J., Hood, L., Smit, A.F.A.:
Chromosomal haplotypes by genetic phasing of human families. Am. J. Hum.
Genet. 89(3), 382–397 (2011)
24. Williams, A.L., Housman, D.E., Rinard, M.C., Giﬀord, D.K.: Rapid haplotype
inference for nuclear families. Genome Biol. 11, R108 (2010)
25. Chin, C.S., Peluso, P., Sedlazeck, F.J., Nattestad, M., Concepcion, G.T., Clum,
A., Dunn, C., O’Malley, R., Figueroa-Balderas, R., Morales-Cruz, A., Cramer,
G.R., Delledonne, M., Luo, C., Ecker, J.R., Cantu, D., Rank, D.R., Schatz, M.C.:
Phased diploid genome assembly with single-molecule real-time sequencing. Nat.
Meth. 13(12), 1050–1054 (2016). Advance online publication
26. Weisenfeld, N.I., Kumar, V., Shah, P., Church, D., Jae, D.B.: Direct determination
of diploid genome sequences. bioRxiv, 070425 (2016)
27. Snyder, M.W., Adey, A., Kitzman, J.O., Shendure, J.: Haplotype-resolved genome
sequencing: experimental methods and applications. Nat. Rev. Genet. 16(6), 344–
358 (2015)
28. Marchini, J., Cutler, D., Patterson, N., Stephens, M., Eskin, E., Halperin, E., Lin,
S., Qin, Z.S., Munro, H.M., Abecasis, G.R., Donnelly, P.: A comparison of phasing
algorithms for trios and unrelated individuals. Am. J. Hum. Genet. 78(3), 437–450
(2006)

62
G.W. Klau and T. Marschall
29. Chen, W., Li, B., Zeng, Z., Sanna, S., Sidore, C., Busonero, F., Kang, H.M., Li,
Y., Abecasis, G.R.: Genotype calling and haplotyping in parent-oﬀspring trios.
Genome Res. 23(1), 142–151 (2013)
30. Delaneau, O., Howie, B., Cox, A.J., Zagury, J.F., Marchini, J.: Haplotype estima-
tion using sequencing reads. Am. J. Hum. Genet. 93(4), 687–696 (2013)
31. Garg, S., Martin, M., Marschall, T.: Read-based phasing of related individuals.
Bioinformatics (Oxford, England) 32(12), i234–i242 (2016)
32. Lippert, R., Schwartz, R., Lancia, G., Istrail, S.: Algorithmic strategies for the
single nucleotide polymorphism haplotype assembly problem. Brieﬁngs Bioinform.
3(1), 23–31 (2002)
33. Cilibrasi, R., Iersel, L., Kelk, S., Tromp, J.: On the complexity of several haplo-
typing problems. In: Casadio, R., Myers, G. (eds.) WABI 2005. LNCS, vol. 3692,
pp. 128–139. Springer, Heidelberg (2005). doi:10.1007/11557067 11
34. Zhao, Y.Y., Wu, L.Y., Zhang, J.H., Wang, R.S., Zhang, X.S.: Haplotype assembly
from aligned weighted SNP fragments. Comput. Biol. Chem. 29(4), 281–287 (2005)
35. Bonizzoni, P., Dondi, R., Klau, G.W., Pirola, Y., Pisanti, N., Zaccaria, S.: On the
minimum error correction problem for haplotype assembly in diploid and polyploid
genomes. J. Comput. Biol. 23(9), 718–736 (2016). A journal of computational
molecular cell biology
36. Hanscom, C., Talkowski, M.: Design of large-insert jumping libraries for structural
variant detection using illumina sequencing. Curr. Protoc. Hum. Genet. 80, 7.22.1–
7.22.9 (2014)
37. Zheng, G.X.Y., Lau, B.T., Schnall-Levin, M., et al.: Haplotyping germline and can-
cer genomes with high-throughput linked-read sequencing. Nat. Biotechnol. 34(3),
303–311 (2016)
38. Chaisson, M.J.P., Huddleston, J., Dennis, M.Y., Sudmant, P.H., Malig, M., Hor-
mozdiari, F., Antonacci, F., Surti, U., Sandstrom, R., Boitano, M., Landolin, J.M.,
Stamatoyannopoulos, J.A., Hunkapiller, M.W., Korlach, J., Eichler, E.E.: Resolv-
ing the complexity of the human genome using single-molecule sequencing. Nature
517(7536), 608–611 (2015)
39. Porubsk´y, D., Sanders, A.D., van Wietmarschen, N., Falconer, E., Hills, M., Spier-
ings, D.C.J., Bevova, M.R., Guryev, V., Lansdorp, P.M.: Direct chromosome-length
haplotyping by single-cell sequencing. Genome Res. 26(11), 1565–1574 (2016)
40. Lieberman-Aiden, E., van Berkum, N.L., Williams, L., Imakaev, M., Ragoczy, T.,
Telling, A., Amit, I., Lajoie, B.R., Sabo, P.J., Dorschner, M.O., Sandstrom, R.,
Bernstein, B., Bender, M.A., Groudine, M., Gnirke, A., Stamatoyannopoulos, J.,
Mirny, L.A., Lander, E.S., Dekker, J.: Comprehensive mapping of long-range inter-
actions reveals folding principles of the human genome. Science 326(5950), 289–293
(2009)
41. Rhee, J.K., Li, H., Joung, J.G., Hwang, K.B., Zhang, B.T., Shin, S.Y.: Survey
of computational haplotype determination methods for single individual. Genes
Genomics 38(1), 1–12 (2015)
42. He, D., Choi, A., Pipatsrisawat, K., Darwiche, A., Eskin, E.: Optimal algorithms
for haplotype assembly from whole-genome sequence data. Bioinformatics 26(12),
i183–i190 (2010)
43. Deng, F., Cui, W., Wang, L.: A highly accurate heuristic algorithm for the haplo-
type assembly problem. BMC Genom. 14(Suppl 2), S2 (2013)
44. Patterson, M., Marschall, T., Pisanti, N., Iersel, L., Stougie, L., Klau, G.W.,
Sch¨onhuth, A.: WhatsHap: haplotype assembly for future-generation sequencing
reads. In: Sharan, R. (ed.) RECOMB 2014. LNCS, vol. 8394, pp. 237–249. Springer,
Cham (2014). doi:10.1007/978-3-319-05269-4 19

A Guided Tour to Computational Haplotyping
63
45. Patterson, M., Marschall, T., Pisanti, N., van Iersel, L., Stougie, L., Klau, G.W.,
Sch¨onhuth, A.: WhatsHap: weighted haplotype assembly for future-generation
sequencing reads. J. Comput. Biol. 22(6), 498–509 (2015)
46. Kuleshov, V.: Probabilistic single-individual haplotyping. Bioinformatics (Oxford,
England) 30(17), i379–i385 (2014)
47. Pirola, Y., Zaccaria, S., Dondi, R., Klau, G.W., Pisanti, N., Bonizzoni, P.: HapCol:
accurate and memory-eﬃcient haplotype assembly from long reads. Bioinformatics
32(11), 1610–1617 (2015)
48. Fouilhoux, P., Mahjoub, A.R.: Solving VLSI design and DNA sequencing problems
using bipartization of graphs. Comput. Optim. Appl. 51(2), 749–781 (2012)
49. Chen, Z.Z., Deng, F., Wang, L.: Exact algorithms for haplotype assembly from
whole-genome sequence data. Bioinformatics (Oxford, England) 29(16), 1938–1945
(2013)
50. Chen, Z.Z., Deng, F., Shen, C., Wang, Y., Wang, L.: Better ILP-based approaches
to haplotype assembly. J. Comput. Biol. 23(7), 537–552 (2016)

Outline of Partial Computability
in Computable Topology
Margarita Korovina1(B) and Oleg Kudinov2
1 A.P. Ershov Institute of Informatics Systems, SbRAS, Novosibirsk, Russia
rita.korovina@gmail.com
2 Sobolev Institute of Mathematics, SbRAS, Novosibirsk, Russia
kud@math.nsc.ru
Abstract. In the framework of computable topology we investigate
properties of partial computable functions, in particular complexity of
various problems in computable analysis in terms of index sets, the eﬀec-
tive Borel and Lusin hierarchies.
1
Introduction
Classical computability theory has a long term tradition to study partial com-
putable functions [16,17]. While the class of eﬀective topological spaces, in par-
ticular computable Polish spaces, is one of the main objects for investigation
in the Eﬀective Descriptive Set Theory (EDST) [3,14,19] the class of partial
computable functions over eﬀective topological spaces has not been deeply inves-
tigated yet. In this paper we address natural problems related to partial com-
putable functions.
The paper is organised as follows. Sections 2 and 3 contain preliminaries
and basic background. In Sect. 3.2 we introduce the class of eﬀectively enumer-
able T0–spaces with point recovering which contains computable Polish spaces
among others and plays an important role in the description of the images of
surjective partial computable functions. In Sect. 4 we recall the deﬁnition of a
partial computable function in the settings of eﬀectively enumerable spaces that
is motivated by the following observations. It is well-known that in the domain–
theoretic framework a partial computable real function is eﬀectively continuous
on its domain [2] and the domain is a Π0
2[R] in the eﬀective Borel hierarchy
[13] (see also [6]). On the computable Polish spaces this deﬁnition agrees with
several known approaches to partial computability [4,5,21]. We show that the
class PCF of partial computable functions over eﬀectively enumerable spaces
is closed under composition. In Sect. 5 we work with computable Polish spaces.
After showing the correspondence between the partial computable functions and
the classical enumeration operators [16] we prove the existence of the principal
computable numbering of PCF for computable Polish spaces. This allows us to
The research has been partially supported by the DFG grants CAVER BE 1267/14-1
and WERA MU 1801/5-1.
c
⃝Springer International Publishing AG 2017
J. Kari et al. (Eds.): CiE 2017, LNCS 10307, pp. 64–76, 2017.
DOI: 10.1007/978-3-319-58741-7 7

Outline of Partial Computability in Computable Topology
65
study the complexity of index sets of important problems in computable analysis
such as function equality and root veriﬁcation. Then we turn to an investiga-
tion of images of partial computable functions. First we show the existence of
a partial computable surjection between any computable Polish space and any
eﬀectively enumerable topological space with point recovering. Using this result
we prove that for any computable Polish spaces X and Y, the images of a partial
computable functions f : X →Y are exactly Σ1
1–subsets of Y .
2
Preliminaries
We refer the reader to [16,17] for basic deﬁnitions and fundamental concepts of
recursion theory, to [3,7,14] for basic deﬁnitions and fundamental concepts of
DST and EDST, in particular, for the deﬁnitions of the eﬀective Borel and Lusin
hierarchies. In the major part of our paper we work with the following notion of
a computable Polish space. A computable Polish space is a complete separable
metric space X without isolated points and with a metric d such that there is a
countable dense set B = {b1, b2, . . . } called a basis of X that makes the following
two relations {(n, m, i) | d(bn, bm) < qi, qi ∈Q} {(n, m, i) | d(bn, bm) > qi, qi ∈
Q} computably enumerable (c.f. [4,15,21]). The standard notations B(x, y) and
B(x, y) are used for open and closed balls with the center x and the radius
y. We consider this concept in the framework of eﬀectively enumerable spaces
(see Sect. 3.1). We work with the Baire space N = (ωω, αN ), the Cantor space
C = (2ω, αC) with the standard topologies and numberings of the bases.
3
Basic Background
3.1
Eﬀectively Enumerable Topological Spaces
Now we recall the notion of an eﬀectively enumerable topological space. Let
(X, τ, α) be a topological space, where X is a non-empty set, Bτ ⊆2X is a base
of the topology τ and α : ω →Bτ is a numbering.
Deﬁnition 1 [11]. A topological space (X, τ, α) is eﬀectively enumerable if the
following conditions hold.
(1) There exists a computable function g : ω × ω × ω →ω such that
α(i) ∩α(j) =

n∈ω
α(g(i, j, n)).
(2) The set {i|α(i) ̸= ∅} is computably enumerable.
For a computable Polish space (X, B, d) in a naturale way we deﬁne the num-
bering of the base of the standard topology as follows. First we ﬁx a computable
numbering α∗: ω \ {0} →(ω \ {0}) × Q+. Then,
α(0) = ∅,
α(i) = B(bn, r) if i > 0 and α∗(i) = (n, r).

66
M. Korovina and O. Kudinov
For α∗(i) = (n, r) later we use notation n = u(i) and r = ri.
It is easy to see that (X, τ, α) is an eﬀectively enumerable topological space.
Therefore we consider the computable Polish spaces as a proper subclass of
the eﬀectively enumerable topological spaces. For details we refer to [11]. In
this paper for such eﬀectively enumerable topological space (X, τ, α) we use the
standard relations on the indices of basic balls deﬁned as follows:
i ≺X j ⇋d(bu(i), bu(j)) + ri < rj,
i |X j ⇋d(bu(i), bu(j)) > ri + rj,
for details see, e.g., [18]. The relation ≺X is irreﬂexive and transitive and if
i ≺X j then cl(α(i)) ⊆α(j). It is easy to see that these relations are computably
enumerable on the indices of basic balls. We recall the notion of an eﬀectively
open set.
Deﬁnition 2. Let (X, τ, α) be an eﬀectively enumerable topological space. A set
A ⊆X is eﬀectively open if there exists a computably enumerable set V ⊆ω
such that A = 
n∈V α(n).
It is worth noting the set of all eﬀectively open subsets of X is closed under
intersection and union since the class of eﬀectively enumerable sets is a lattice.
3.2
Eﬀectively Enumerable T0–spaces with Point Recovering
In this section we introduce eﬀectively enumerable T0–spaces with point recov-
ering. Further on we will see that they play an important role in the description
of images of surjective partial computable functions.
Deﬁnition 3. Let Y = (Y, λ, β) be an eﬀectively enumerable T0–space. We say
that Y admits point recovering if {Ax | x ∈Y } is a Σ1
1-subset of P(ω), where
Ax = {n | x ∈β(n)}. Here P(ω) is considered as the Cantor space C.
Theorem 1. Every computable Polish space X = (X, τ, α) admits point recov-
ering. Moreover, {Ax | x ∈X} is a Π0
2–subset of C.
Proof. For a computable Polish space X = (X, τ, α), to prove that the set {Ax |
x ∈X} is a Π0
2-set in the eﬀective Borel hierarchy on C let us observe that, for
I ⊆ω, (∃x ∈X) I = Ax if and only if the following conditions hold.
Cond 1: (∀k ∈ω)(∃m ∈ω)(∃n ∈ω)(∃r ∈Q+)(∃l ∈ω)(∃r′ ∈Q+)

k ∈I →

α∗(k) = (n, r) ∧α∗(m) = (l, r′) ∧r′ < r
2 ∧m ≺X k ∧m ∈I

where α∗is deﬁned as on the page 2.
Cond 2: (∀k ∈ω)(∀m ∈ω)

k ∈I ∧m ∈I

→α(k) ∩α(m) ̸= ∅

.
Cond 3: I ̸= ∅.
Cond 4: (∀k ∈ω)(∀m ∈ω)

k ∈I ∧k ≺X m

→m ∈I

.

Outline of Partial Computability in Computable Topology
67
Let us denote Ψ(I) = Cond 1(I) ∧Cond 2(I) ∧Cond 3(I) ∧Cond 4(I). By deﬁ-
nition, Ψ is in Π0
2-form.
⊓⊔
Remark 1. It is easy to see that the conditions Cond 1(I) −Cond 4(I) in The-
orem 1 can be rewritten in the special form
∀¯k

η(¯k, I) ∨Φ(¯k, I)

,
where η is a disjunction of formulas of the kind ki ̸∈I and Φ is a computable
disjunction (possible inﬁnite) of ∃–formulas with positive occurrences of I i.e. Φ
does not contain formulas of the kind ki ̸∈I. Indeed, for example, Cond 4(I)
can be rewritten as follows:
(∀k ∈ω)(∀m ∈ω)

k ̸∈I ∨m ∈I ∨¬ k ≺X m

.
Since ¬ k ≺X m ⇋(∀l ∈ω) Q(m, k, l), where Q(m, k, l) deﬁnes computable
subset of ω3, we have
Cond 4 (I) ↔(∀k ∈ω)(∀m ∈ω)(∀l ∈ω)

k ̸∈I ∨m ∈I ∨Q(m, k, l)

.
Later we use this form in the proof of Theorem 2.
Proposition 1. There exists eﬀectively enumerable topological space that does
not admit point recovering.
Proof. Let us consider C as a subset of R and take Y ⊆C such that {Ax | x ∈Y }
is non-analytic. It is possible to do since the number of subsets Y ⊆C such that
{Ax | x ∈Y } is analytic is no more than continuum. Then put X = R \ Y and
X = (X, τX), where the topology τX is induced by τR.
It is clear that X is an eﬀectively enumerable topological space since C is
nowhere dense in R. Taking into account that {Ax | x ∈X} = {Ax | x ∈
R} \ {Ax | x ∈Y } we conclude that X does not admit point recovering.
⊓⊔
4
PCF over Eﬀectively Enumerable Topological Spaces
In this section we recall the notion of a partial computable function f : X →Y,
where X = (X, τX, α) is an eﬀectively enumerable topological space and Y =
(Y, τY , β) is an eﬀectively enumerable T0–space.
Deﬁnition 4 [8]. Let X = (X, τX, α) be an eﬀectively enumerable topological
space and Y = (Y, τY , β) be an eﬀectively enumerable T0–space. A function f :
X →Y is called partial computable (pcf) if there exist a computable sequence of
eﬀectively open sets {On}n∈ω and a computable function H : ω2 →ω such that
1. dom(f) = 
n∈ω On and
2. f −1(β(m)) = 
i∈ω α(H(m, i)) ∩dom(f).

68
M. Korovina and O. Kudinov
In the following if a partial computable function f is everywhere deﬁned
we say f is a total computable function. For eﬀectively enumerable topological
spaces X and eﬀectively enumerable T0–space Y we denote the set of partial
computable functions f : X →Y as PCF XY.
Remark 2. It is worth noting that for computable Polish spaces, Deﬁnition 4
corresponds to the results in [5], where partial TTE–computable functions have
been described via eﬀective continuity and Π0
2-domains. Moreover, for partial
real functions, the classes of PCF RR, the TTE–computable [20], the domain-
computable [2] and the majorant–computable functions [9,12] coincide.
The following proposition is a straightforward corollary of Deﬁnition 4.
Proposition 2. Let X = (X, τ, α) be an eﬀectively enumerable topological space
and Y = (Y, λ, β) be an eﬀectively enumerable T0-space.
1. If f : X →Y is a pcf, then f is continuous at every points of dom(f).
2. A total function f : X →Y is computable if and only if it is eﬀectively
continuous.
Proposition 3 [8]. Over eﬀectively enumerable T0–spaces, PCF is closed under
composition.
5
PCF over Computable Polish Spaces
In this section we consider partial computable functions over the subclass of
eﬀectively enumerable topological spaces which is the class of computable Polish
spaces. We give a characterisation of partial computability in terms of classi-
cal enumeration operators (see e.g. [16]). Then based on this characterisation
we show the existence of the principal computable numbering of PCF XY and
compute the complexity of some problems such as function equality and root
veriﬁcation.
5.1
Characterisation of PCF XY
Deﬁnition 5 [16]. A function Γe : P(ω) →P(ω) is called an
enumeration
operator if
Γe(A) = B ↔B = {j | ∃i c(i, j) ∈We, Di ⊆A},
where We is the e-th computably enumerable set, and Di is the i-th ﬁnite set.
A function Γe : P(ω) →P(ω) is called a reduced enumeration operator if
Γe(A) = B ↔B = {j | (∃i ∈A) c(i, j) ∈We},
where We is the e-th computably enumerable set.
Now we recall the notion of a computable function introduced in [11].

Outline of Partial Computability in Computable Topology
69
Deﬁnition 6 [11]. Let X = (X, τ, α) be an eﬀectively enumerable topological
space and Y = (Y, λ, β) be an eﬀectively enumerable T0-space.
A partial function f : X →Y is called computable if there exists an enumeration
operator Γe : P(ω) →P(ω) such that, for every x ∈X,
1. If x ∈dom(f) then
Γe({i ∈ω|x ∈α(i)}) = {j ∈ω | f(x) ∈β(j)}.
2. If x ̸∈dom(f) then, for all y ∈Y ,
	
j∈ω
{β(j)|j ∈Γe(Ax)} ̸=
	
j∈ω
{β(j)|j ∈By},
where Ax = {i ∈ω|x ∈α(i)}, By = {j ∈ω|y ∈β(j)}.
In this case we say that Γe completely deﬁnes the function f.
Remark 3. It is worth noting that if we work with eﬀectively enumerable topo-
logical spaces then a function is computable if and only if there exists a reduced
enumeration operator satisfying the requirements of Deﬁnition 6.
Proposition 4. Let Γe be an enumeration operator, X = (X, τ, α) and Y =
(Y, λ, β) be computable Polish spaces. Then E = {x | Ψ(Γe(Ax))} is a Π0
2-
subset of X, where Ψ is a Π0
2-condition from Theorem 1. Moreover, the function
f : X →Y deﬁned as follows: dom(f) = E and, for x ∈dom(f), f(x) = y ↔
Γe(Ax) = By is a partial computable function.
Proof. Let us show that the condition Ψ(Γe(Ax)) deﬁnes a Π0
2-subset of X. From
Remark 1 it follows that Ψ(I) is a conjunction of Π0
2-formulas in the form
∀¯k
 
i∈D
ki ̸∈I ∨Φ(¯k, I)

,
where D is a ﬁnite subset of the indices of ¯k and Φ is a computable disjunction
of ∃–formulas with positive occurrences of I. Therefore, for i = 1, . . . , 4 every
Cond i(Γe(Ax)) deﬁnes the set
{x | ∀¯k x ∈Ai
¯k}, where
Ai
¯k = {x |

j∈D
kj ̸∈Γe(Ax) ∨Φi(¯k, Γe(Ax))}
= {x |

j∈D
kj ̸∈Γe(Ax)} ∪{x | Φi(¯k, Γe(Ax))}.
Let us make a close look at Ai
¯k. The ﬁrst element of the union is a Π0
1-
subset of X and the second one is a Σ0
1-subset of X according to the following
observation.

70
M. Korovina and O. Kudinov
By the deﬁnition of the enumeration operator Γe,
{x | k ∈Γe(Ax)} =

<k,j>∈We
	
j∈Dk
α(j).
Therefore it is eﬀectively open and its complement is co-eﬀectively closed. As
corollary every set {x | Cond i(Γe(Ax))} is a Π0
2-subset of X.
Let us show that f is a partial computable function. It is worth noting that
x ∈dom(f) ↔Γe(Ax) ∈{By | y ∈Y } ↔Ψ(Γe(Ax)). So dom(f) is a Π0
2-subset
of X. For x ∈dom(f),
x ∈f −1(β(j)) ↔f(x) ∈β(j) ↔∃k (k ∈{i|x ∈α(i)} ∧c(k, j) ∈We)
↔

c(k,j)∈We
x ∈α(k) ↔x ∈

m∈ω
α(H(j, m))
for a computable function H : ω × ω →ω. Therefore f is a partial computable
function.
⊓⊔
Further on if Γe and f satisfy the conditions of Proposition 4 we say that Γe
deﬁnes f.
Theorem 2. Let X = (X, τ, α) and Y = (Y, λ, β) be computable Polish spaces.
A function f : X →Y is computable if and only if it is partial computable.
Proof.
(→)The claim follows from Proposition 4.
(←) Now suppose, dom(f) = 
n∈ω On and, for x ∈dom(f), f(x) ∈β(n) ↔x ∈

i∈ω α(H(n, i)), where {On}n∈ω is a computable sequence of eﬀectively open
sets such that On+1 ⊆On and H : ω2 →ω is a computable function. It is worth
noting that, for all n ∈ω and i ∈ω, On ∩α(H(n, i)) is an eﬀectively open
set. So, On ∩α(H(n, i)) = 
t∈Tni α(t), where n ∈ω, i ∈ω and {Tni}n, i∈ω is a
computable sequence of c.e. sets. Put
We = {c(t, n) | (∃i ∈ω) t ∈Tni}.
Let Γe be a reduced enumeration operator that corresponds to We. By
Proposition 4 this operator deﬁnes a function fΓe. Let us show that f = fΓe.
We ﬁrst prove that dom(f) = dom(fΓe). If x ∈
n∈ω On then, by construc-
tion, Γe(Ax) = Bf(x). Indeed, let n ∈ω be such that f(x) ∈β(n). By deﬁni-
tion, (∃i ∈ω) x ∈α(H(n, i)). This means that x ∈α(t) for t ∈Tni, therefore
n ∈Γe(Ax). Conversely, if n ∈Γe(Ax) then (∃i ∈ω)(∃t ∈Tni) f(x) ∈β(n). So
Γe(Ax) = Bf(x) and x ∈dom(fΓ ). So dom(f) ⊆dom(fΓe).
If x ̸∈
n∈ω On then there exists k ∈ω such that x ̸∈On for all n ≥k.
In other words, x ̸∈
t∈Tni α(t) for all n ≥k. This means that, for all n ≥k,
¬(∃t ∈Tni) x ∈α(t), i.e., n ̸∈Γe(Ax). Therefore Γe(Ax) is ﬁnite and B =
∩{β(j) | j ∈Γe(Ax)} is a ﬁnite intersection of basic open balls. Since we consider
spaces without isolated points, B ̸= ∩{β(j) | j ∈By} = {y} for any y ∈Y . In
particular, x ̸∈dom(fΓe).

Outline of Partial Computability in Computable Topology
71
Now if x ∈dom(f) = dom(fΓe) then, by the deﬁnitions of f and Γ,
Γ(Ax) = {j|∃s H(j, s) ∈Ax} = {j|x ∈f −1(β(j)} = {j|f(x) ∈β(j)}.
Therefore Bf(x) = BfΓ (x). Since any point y is uniquely deﬁned by the set of
basic neighborhoods, f(x) = fΓ (x). So Γe completely deﬁnes f.
⊓⊔
5.2
Index Sets for PCF XY
In this section we show that there exists a principal computable numbering of
PCF XY for computable Polish spaces X and Y. With respect to this principal
computable numbering we investigate complexity of important problems such
as totality and root veriﬁcation. It turns out that for some problems the cor-
responding complexity does not depend on the choice of a computable Polish
space while for other ones the corresponding choice plays a crucial role.
A function γ : ω →PCF XY is called a numbering of PCF XY if {γ(n) |
n ∈ω} = PCF XY. A numbering γ : ω →PCF XY is called computableif Γ :
ω × X →Y such that Γ(n, x) = γ(n)(x) is a partial computable function.
The numbering γ is called principal computable if it is computable and every
computable numbering ξ is computably reducible to γ. It is worth noting that
these deﬁnitions agree with the notions of computable and principal computable
numberings of A ⊆P(ω) [1]. The following proposition is a straightforward
corollary of Proposition 4 and Theorem 2.
Proposition 5. There exists the principal computable numbering γ of PCF XY.
In fact, γ(e) is a pcf deﬁned by Γe.
Let ⊥XY denote the nowhere deﬁned function.
Proposition 6. The index set Ix({(f ∈PCF XY | f ̸= ⊥XY}) is Σ1
1-complete.
Proof. Let us ﬁx computable Polish spaces X and Y. Our proof is based on the
following lemmas.
Lemma 6.1 [8]. There exists an eﬀective procedure which given any computable
sequence {An}n∈ω of eﬀectively open subsets of N produces a computable
sequence {En}n∈ω of eﬀectively open subsets of X such that 
n∈ω An = ∅↔

n∈ω En = ∅.
Lemma 6.2. Let {En}n∈ω be a computable sequence of eﬀectively open subsets
of lX. There is an algorithm producing a partial computable function f : X →Y
such that dom(f) = 
n∈ω En.
Lemma 6.3 [8]. Let us ﬁx a Σ1
1–complete I ⊆ω. Then there exists an eﬀective
procedure which generates a computable sequence {Am
n }m, n∈ω of eﬀectively open
subsets of N such that 
n∈ω Am
n ̸= ∅↔m ∈I.
In order to prove Proposition 6 ﬁrst let us note that the standard Kleene-
Addison algorithm [16] shows that Ix({f|f ̸= ⊥} ∈Σ1
1. Our goal is to show

72
M. Korovina and O. Kudinov
that I ≤m Ix({f|f ̸= ⊥}). For that, we construct a computable sequence
F = {fm}m∈ω of partial computable functions such that m ∈I ↔fm ̸= ⊥.
Using Lemmas 6.3 and 6.1 we construct a computable sequence {Am
n }m, n∈ω of
eﬀectively open subsets of N and a computable sequence {Em
n }m, n∈ω of eﬀec-
tively open subsets of X such that 
n∈ω Am
n ̸= ∅↔m ∈I and 
n∈ω Am
n =
∅↔
n∈ω Em
n
= ∅. Using Lemma 6.2 we can eﬀectively construct a partial
computable function fm such that dom(fm) = 
n∈ω Em
n . So, there exists a
computable function χ : ω →ω such that fm = γ(χ(m)). The function χ is a
reduction, since m ∈I ↔γ(χ(m)) ̸= ⊥.
⊓⊔
Corollary 1. For PCF XY, the problem of function equality is Π1
1-complete.
Theorem 3 [10]. For partial computable real functions f : IR →IR, totality is
Π0
2-complete.
Theorem 4 [8]. For partial computable functions f : N →IR, totality is Π1
1-
complete.
For X = R (or N) and Y = R, complexity of other important problems such as
root veriﬁcation can be found in [8].
Proposition 7. Let K ⊆PCF XY. If K ̸= ∅and ⊥̸∈K then Ix(K) is Π0
2–
hard.
Proof. The proof is based on the following observation. Suppose A ∈Π0
2, f ∈
PCF XY and f ̸= ⊥XY . Then there exists a computable function g : ω →ω such
that
n ∈A →g(n) ∈Ix({f}) and n ̸∈A →g(n) ∈Ix(⊥XY ).
The existence of g for a computable Polish space Y can be proven in a similar
way as for Y = R (see [10]).
⊓⊔
Corollary 2 (Generalised Rice’s Theorem). Let K ⊂PCF XY. Then K ̸=
∅if and only if Ix(K) ̸∈Δ0
2.
5.3
Complexity of Images of Partial Computable Functions
First we propose a characterisation of eﬀectively enumerable topological spaces
that are images of partial computable surjections from computable Polish spaces.
Proposition 8. Let X = (X, τ, α) be a computable Polish space and Y =
(Y, λ, β) be an eﬀectively enumerable T0-space. Then the following assertions
are equivalent.
1. There exists a partial computable surjection f : X ↠Y.
2. The space Y admits point recovering.

Outline of Partial Computability in Computable Topology
73
Proof. (1) →(2). Assume f : X ↠Y is a partial computable surjection. It
means that dom(f) = 
n∈ω On = 
n∈ω

s∈ω α(g(n, s)) and for all x ∈dom(f),
f(x) ∈β(n) ↔x ∈
i∈ω α(H(n, i)), where g : ω2 →ω and H : ω2 →ω
are computable functions. Recall that Ax = {n | x ∈α(n)} and By = {m | y ∈
β(m)}. In order to show that Y admits recovering let us prove that {By | y ∈Y }
is a Σ1
1-subset of P(ω) considered as the Cantor space. Since f is a surjection,
for I ⊆ω, (∃y ∈Y ) I = By if and only if (∃x ∈dom(f)) I = Bf(x). Let us make
analysis. If I = Bf(x) then
n ∈I ↔
(∃x ∈dom(f))f(x) ∈β(n) ↔(∃x ∈dom(f)) x ∈

i∈ω
β(H(n, i))
↔(∃x ∈dom(f))(∃i ∈ω) H(n, i) ∈Ax.
From Theorem 1 it follows that J ∈{Ax | x ∈X} ↔Ψ(J), where Ψ(J) is
a Π0
2-subset of C. It is easy to see that x ∈dom(f) ↔(∀n ∈ω) x ∈On ↔(∀n ∈
ω)(∃s ∈ω)g(n, s) ∈Ax. Finally, we have
(∃y ∈Y )I = By ↔(∃J ⊆ω)

Ψ(J) ∧(∀n ∈ω)

n ∈I ↔

(∃i ∈ω) H(n, i) ∈J∧
(∀m ∈ω)(∃s ∈ω) g(n, s) ∈J

.
Now we can see that {By | y ∈Y } is a Σ1
1-subset of C.
(2) →(1). Let Y admit point recovering. We construct a required partial com-
putable surjection in few steps:X ↠N ↠C ↠C2 ↠Y .
Step 1. It is known (see e.g. [9,14,19]) that there exists a homeomorphism
F : N →X such that F −1 : X →N is a partial computable surjection.
Step 2. A partial computable surjection g : N ↠C is deﬁned in a standard way
g(f) = λn.f(n) mod 2.
Step 3. A partial computable bijection λ : C2 ↠C is deﬁned in a standard way
λ(I, J) = {2n | n ∈I} ∪{2n + 1 | n ∈J}.
Step 4. Let us construct a partial computable surjection h : C2 ↠Y. Assume Θ
is a Σ1
1-condition that certiﬁes point recovering of Y i.e. I = By for some y ∈Y
iﬀΘ(I) ⇋(∃J ⊆ω)Φ(I, J), where Φ(I, J) is a Π0
2-condition (see e.g. [14]). Put
D = {(I, J) | Φ(I, J)} ⊆C2.
If (I, J) ∈D then I = By for some y ∈Y . Since Y is a T0-space, this y is
uniquely deﬁned by I. Deﬁne h(I, J) = y. We have (I, J) ∈h−1(β(n)) ↔I =
Bz for some z ∈β(n) ↔Φ(I, J) ∧n ∈I. So, dom(h) = D is a Π0
2-subset of C2
and h−1(β(n)) = D ∩({I ⊆ω | n ∈I} × C). Therefore h is a partial computable
surjection.
Step 5. A required partial computable surjection is the composition f = h ◦
λ−1 ◦g ◦F −1, i.e.,
F −1
g
λ−1
h
X
↠N ↠C ↠C2 ↠Y.
The construction is complete.
⊓⊔

74
M. Korovina and O. Kudinov
In order to study the complexity of images of partial computable functions
we use the eﬀective Borel and Lusin hierarchies on computable Polish spaces
[14,19]. In particular our proofs are based on the following properties of Borel
and analytic subsets of a computable Polish space X:
– A set B is a Π0
2–set in the eﬀective Borel hierarchy on X (a Π0
2–subset of
X) if and only if B = 
n∈ω An for a computable sequence of eﬀectively open
sets {An}n∈ω.
– A set A ∈is a Σ1
1–set in the eﬀective Lusin hierarchy on X (a Σ1
1–subset of
X) if and only if A = {y | (∃x ∈X)B(x, y)}, where B is a Π0
2–subset of X.
Theorem 5. Let X be a computable Polish space, Y be an eﬀectively enumer-
able T0-space and Y0 ⊆Y . Then the following assertions are equivalent.
1. Y0 is the image of a partial computable function f : X →Y.
2. {By | y ∈Y0} is a Σ1
1–subset of C.
Proof. 1) →2). Assume Y0 is the image of a partial computable function f :
X →Y. For x ∈dom(f) and y = f(x) ∈Y0, we have
n ∈Bf(x) ↔f(x) ∈β(n) ↔x ∈

i∈ω
α(H(n, i)) ↔{H(n, i) | i ∈ω} ∩Ax ̸= ∅.
Then, for I ⊆ω,
I ∈{By | y ∈Y0}
↔∃J ∈{Ax | x ∈dom(f)}(∀n ∈ω)

n ∈I ↔{H(n, i) | i ∈ω} ∩Ax ̸= ∅

.
This is a Σ1
1-condition since
J ∈{Ax | x ∈dom(f)} ↔(∀m ∈ω)J ∩Jm ̸= ∅,
where {Jm}m∈ω is a computable sequence of c.e. sets such that dom(f) =

m∈ω Om and Om = 
i∈Jm α(i).
2) →1). Let {By | y ∈Y0} ∈Σ1
1. This means that J ∈{By | y ∈Y0} ↔
(∃I ⊆ω) Q(I, J), where Q(I, J) is a Π0
2–condition on C (see e.g. [14]). Let us
construct a partial computable function h : C2 ↠Y such that dom(h) = D and
im(h) = Y0. Put D = {(I, J) | Q(I, J)} ⊆C2. If Q(I, J) then J = By for some
y ∈Y . Since Y is a T0-space, y is uniquely deﬁned by I. Deﬁne h(I, J) = y. We
have (I, J) ∈h−1(β(n)) ↔J = Bz for some z ∈β(n) ↔Q(I, J) ∧n ∈J. So,
dom(h) = D is a Π0
2-subset of C2 and h−1(β(n)) = D ∩({I ⊆ω | n ∈I} × C).
Therefore h is a partial computable function. Using Theorem 8 we construct the
composition of partial computable surjections f, g and h as follows:
f
g
h
X ↠C ↠C2 →Y.
This is a required function.

Outline of Partial Computability in Computable Topology
75
Proposition 9. Let Y be a computable Polish space, Y0 ⊆Y and Y0 = {By |
y ∈Y0}. Then Y0 is a Σ1
1–subset of Y if and only if Y0 is a Σ1
1–subset of C.
Theorem 6. Let X and Y be computable Polish spaces and Y0 ⊆Y . Then the
following assertions are equivalent.
1. Y0 is the image of a partial computable function f : X →Y.
2. Y0 is a Σ1
1–subset of Y .
Proof. The claim follows from Theorem 5 and Proposition 9.
⊓⊔
References
1. Ershov, Y.L.: Theory of numberings. In: Griﬀor, E.R. (ed.) Handbook of Com-
putability Theory, pp. 473–503. Elsevier Science B.V., Amsterdam (1999)
2. Edalat, A.: Domains for computation in mathematics, physics and exact real arith-
metic. Bull. Symbolic Log. 3(4), 401–452 (1997)
3. Gao, S.: Invariant Descriptive Set Theory. CRC Press, New York (2009)
4. Gregoriades, V., Kispeter, T., Pauly, A.: A comparison of concepts from com-
putable analysis and eﬀective descriptive set theory. Math. Struct. Comput. Sci. 1–
23(2016). https://doi.org/10.1017/S0960129516000128. (Published online: 23 June
2016)
5. Hemmerling, A.: Eﬀective metric spaces and representations of the reals. Theor.
Comput. Sci. 284(2), 347–372 (2002)
6. Hemmerling, A.: On approximate and algebraic computability over the real num-
bers. Theor. Comput. Sci. 219(1–2), 185–223 (1999)
7. Kechris, A.S.: Classical Descriptive Set Theory. Springer, New York (1995)
8. Korovina, M., Kudinov, O.: Complexity for partial computable functions over
computable Polish spaces. Math. Struct. Comput. Sci. (2016). doi:10.1017/
S0960129516000438. (Published online: 19 December 2016)
9. Korovina, M., Kudinov, O.: Computable elements and functions in eﬀectively enu-
merable topological spaces. Mathematical structure in Computer Science (2016).
doi:10.1017/S0960129516000141. (Published online: 23 June 2016)
10. Korovina, M., Kudinov, O.: Index sets as a measure of continuous constraint com-
plexity. In: Voronkov, A., Virbitskaite, I. (eds.) PSI 2014. LNCS, vol. 8974, pp.
201–215. Springer, Heidelberg (2015). doi:10.1007/978-3-662-46823-4 17
11. Korovina, M., Kudinov, O.: Towards computability over eﬀectively enumerable
topological spaces. Electr. Notes Theor. Comput. Sci. 221, 115–125 (2008)
12. Korovina, M., Kudinov, O.: Towards computability of higher type continuous data.
In: Cooper, S.B., L¨owe, B., Torenvliet, L. (eds.) CiE 2005. LNCS, vol. 3526, pp.
235–241. Springer, Heidelberg (2005). doi:10.1007/11494645 30
13. Korovina, M., Kudinov, O.: Characteristic properties of majorant-computability
over the reals. In: Gottlob, G., Grandjean, E., Seyr, K. (eds.) CSL 1998. LNCS,
vol. 1584, pp. 188–203. Springer, Heidelberg (1999). doi:10.1007/10703163 14
14. Moschovakis, Y.N.: Descriptive set theory. North-Holland, Amsterdam (2009)
15. Moschovakis, Y.N.: Recursive metric spaces. Fund. Math. 55, 215–238 (1964)
16. Rogers, H.: Theory of Recursive Functions and Eﬀective Computability. McGraw-
Hill, New York (1967)

76
M. Korovina and O. Kudinov
17. Soare, R.I.: Recursively Enumerable Sets and Degrees: A Study of Computable
Functions and Computably Generated Sets. Springer Science and Business Media,
Heidelberg (1987)
18. Spreen, D.: On eﬀective topological spaces. J. Symb. Log. 63(1), 185–221 (1998)
19. Selivanov, V.: Towards the eﬀective descriptive set theory. In: Beckmann, A.,
Mitrana, V., Soskova, M. (eds.) CiE 2015. LNCS, vol. 9136, pp. 324–333. Springer,
Cham (2015). doi:10.1007/978-3-319-20028-6 33
20. Weihrauch, K.: Computable Analysis. Springer, New York (2000)
21. Weihrauch, K.: Computability on computable metric spaces. Theor. Comput. Sci.
113(1), 191–210 (1993)

Eliminating Unbounded Search
in Computable Algebra
Alexander G. Melnikov(B)
Massey University, Auckland, New Zealand
alexander.g.melnikov@gmail.com
Abstract. Klaimullin, Melnikov and Ng [KMNa] have recently sug-
gested a new systematic approach to algorithms in algebra which is
intermediate between computationally feasible algebra [CR91,KNRS07]
and abstract computable structure theory [AK00,EG00]. In this short
survey we discuss some of the key results and ideas of this new
topic [KMNa,KMNc,KMNb]. We also suggest several open problems.
1
Introduction
What does it mean for an inﬁnite algebraic structure to be computable? Which
algebraic structures admit an algorithmic presentation? These questions are cen-
tral to computable structure theory [AK00,EG00]. The main objects of com-
putable structure theory are countably inﬁnite cby a Turing machine:
Deﬁnition 1 (Mal’cev, Rabin). An algebraic structure Ais constructive or
computable if its universe is the set of natural numbers N, and the operations
and relations on A are (Turing) computable.
For example, every ﬁnitely generated group with algorithmically solvable
Word Problem [Hig61] has a computable isomorphic copy. In both combinatorial
group theory [Hig61] and computable structure theory [AK00,EG00] algorithms
are allowed to be computationally ineﬃcient. It often does not make any diﬀer-
ence, since one of the main aims of such studies is to show that some problems –
such as the Word Problem for a f.g. group – have no algorithmic solution at all,
let alone a computationally feasible solution [Nov55,Boo59,Hig61]. Also, Turing
computability can be viewed as a formalisation of one’s constructive approach to
algebra [EG00]. Algorithmic investigations in algebra are related to other seem-
ingly distant areas of pure mathematics such as topological group theory and
model theory (e.g., [MM,Mon13]).
In contrast with (Turing) computable structure theory, automatic and
polynomial-time algebra put resource bounds and other restrictions on algo-
rithms representing algebraic structures. Automatic algebra studies algebraic
structures that are presented by (typically ﬁnite) automata [KN94,KN08,
KNRS07,ECH+92,NT08,BS11,NS07] Automatic structures have a number of
nice properties including quick computational characteristics, but automatic
c
⃝Springer International Publishing AG 2017
J. Kari et al. (Eds.): CiE 2017, LNCS 10307, pp. 77–87, 2017.
DOI: 10.1007/978-3-319-58741-7 8

78
A.G. Melnikov
structures tend to be rare (e.g.,[Tsa11]). A countably inﬁnite algebraic struc-
ture is polynomial-time if the operations and relations polynomial time com-
putable (in the length of the input, see survey [CR91]). As we will discuss later,
in many cases one can show that a (Turing) computable algebraic structure has
a polynomial copy (e.g., [CDRU09,CR,Gri90]), but this phenomenon is not yet
understood.
One would expect that computable structure theory and computationally
feasible algebra should have signiﬁcant overlaps, but it is not quite the case.
Kalimullin, Melnikov and Ng [KMNa,KMNc,KMNb] have initiated a system-
atic development of a theory the main purpose of which is to ﬁll this gap.
(Independently, Alaev [Ala] has suggested an alternate approach.) In this
brief survey we explain the key ideas and results from these recent works
[KMNa,KMNc,KMNb,Ala]. An expert working in computable structure the-
ory may ﬁnd some of the key results discussed below rather counter-intuitive.
Although the new topic is in its infancy, it already has technical depth and oﬀers
seemingly challenging problems, some of which will be posed below.
2
Primitive Recursion and Computability Without Delay
We open this section with two elementary examples illustrating the power of
unbounded search.
Example 2. Clearly, there exists a (Turing) computable 2-colouring of any com-
putable inﬁnite tree. Simply wait for a node v to get path-connected to the root.
If we put any (computable and total) restriction on the waiting time, then we
will need inﬁnitely many colours in general.
Example 3. Suppose (G, ·) is a (Turing) computable group. Then the operation
a →a−1 is also Turing computable. We simply search through the domain of G
until we ﬁnd a g such that a · g = e. Note this elementary fact no longer holds
if we cannot use the unbounded search.
Eliminating all unbounded loops from Turing computability gives us the
notion of a primitive recursive function. In several common algebraic classes
we can show that every computable structure has a polynomial-time com-
putable copy. As was noted in [KMNa], many known proofs of this sort (e.g.,
[CR91,CR92,CDRU09,Gri90]) are essentially focused on making the operations
and relations on the structure primitive recursive, and then observing that the
presentation that we obtain is polynomial-time. It appears that primitive recur-
sion plays a rather important intermediate role in transforming (Turing) com-
putable structures into feasible structures. This thesis is also supported by a
number of negative results in the literature. Indeed, to illustrate that a struc-
ture has no polynomial time copy, it is sometimes easiest to argue that it does
not even have a copy with primitive recursive operations, see e.g. [CR92]. It is
thus natural to investigate into those structures that admit a presentation with
primitive recursive operations:

Eliminating Unbounded Search in Computable Algebra
79
Deﬁnition 4 ([KMNa]). A countable structure is fully primitive recursive
(fpr) if its domain is N and the operations and predicates of the structure are
(uniformly) primitive recursive1.
One may ask whether the domain of a fpr A could be a primitive recursive
subset of N as in [CR91], not the whole N. This means that the structure could
reveal its domain with an arbitrary delay. Such presentations upon a primitive
recursive subset of N are called primitive recursive [CR92]. It follows from [Ala]
(see [KMNa]) that there exist primitive recursive structures that have no fully
primitive recursive presentation.
Our main goal is the complete elimination of all unbounded loops from
algorithmic presentations of structures. In particular, we should not allow the
domain to be revealed with an unbounded delay. Thus, a “truly primitive recur-
sive” algebraic structure should (minimally) satisfy Deﬁnition 4 of a fpr struc-
ture. Note that one might impose further restrictions on fpr presentations. We
will brieﬂy discuss one such possible strengthening of Deﬁnition 4 in the next
section.
The notion of a fpr structure is intermediate between computable structures
and polynomial-time structures. It usually takes some work to produce a fpr
copy of a computable structure (if it exists at all), and there are enough natural
examples of computable structures that do not have a fpr copy. Similarly, not all
fpr structures admit polynomial-time copies, but a good portion of our results
can be extended to polynomial-time structures. The rest of the survey is focused
on the systematic development of the theory of fpr structures.
3
Existence of a fpr Copy
Which computable structures admit fpr presentations?
Theorem 5. In each of the following classes, every computable structure has a
fully primitive recursive presentation:
1. Equivalence structures [CR91].
2. Linear orders [Gri90].
3. Torsion-free abelian groups [KMNa].
4. Boolean algebras [KMNa].
5. Abelian p-groups [KMNa].
Proof (Proof idea). We use various structural properties speciﬁc to the class
to predict the behaviour of the structure in certain locations even before the
structure has revealed itself there. For example, in (3) we ﬁrst produce a com-
putable presentation of the group with a computable maximal linearly indepen-
dent set [Dob,Nur74], and then we use the maximal free subgroup upon this set
as a “safe” location. The case of Boolean algebras (4) is more interesting. The
proof is not uniform and it goes through several cases. In the case of an atomic
algebra we use a priority construction, the old theorem of Remmel [Rem81], and
tree-presentations of BA’s [Gon97] to produce a Π0
3-isomorphic fpr copy.
1 We also agree that all ﬁnite structures are fpr.

80
A.G. Melnikov
The reader perhaps thinks that most common classes will have the nice prop-
erty from Theorem 5, but this is not the case.
Theorem 6. In each of the following classes, there exists a computable structure
that does not admit a fpr presentation
1. Torsion abelian groups [CR92].
2. Archimedean ordered abelian groups [KMNa].
3. Undirected graphs [KMNa].
Proof (Proof idea). In (2) we produce an Archimedean group of rank 2 that
(essentially) encodes a computable real which does not have a primitive recur-
sive rapid approximation. The proof uses that every such group is computably
categorical, so we need to diagonalise only against computable isomorphisms.
The proofs of (1) and (3) are brute-force diagonalisation arguments, but (3) is a
lot more subtle. In the proof we need to monitor all potential fpr copies at once
and force them to reveal themselves at certain locations used for diagonalisation.
Parts (1) and (2) of Theorem 6 contrast with (3) and (5) of Theorem 5,
and (3) of Theorem 6 refutes the (natural) conjecture that every relational com-
putable structure has a fpr copy. Note that Theorems 5 and 6 (combined) con-
ﬁrm the intermediate nature of fpr structures. Although there are some observ-
able patterns in the proofs of Theorems 6 and 5, it is not clear whether there is
any meaningful and general enough suﬃcient condition for a computable struc-
ture to have (or not have) a fpr copy. We leave open:
Question 7. Fix the listing M0, M1, . . . of all partial computable structures.
What is the complexity of the index set {e : Me has a fpr copy}?
3.1
Strongly fpr Structures
In this subsection we brieﬂy discuss one possible strengthening of the notion of
a fpr structure. We say that a fpr structure is strongly primitive recursive of it
possesses a primitive recursive Skolem function [KMNa].
We note that this approach resembles the earlier notion of a honest wit-
ness due to Cenzer and Remmel [CR91]. The following structures have strongly
primitive recursive copies:
– The additive groups Z and Q and their direct sums.
– The countable atomless Boolean algebra.
– The order-type ω.
There exist 1-decidable fpr structures that are not strongly fpr, see [KMNa]
for a proof. (See also [Ala] for a similar approach.)

Eliminating Unbounded Search in Computable Algebra
81
4
Uniqueness of a fpr Copy
Recall that a structure is computably categorical or autostable if it has a unique
computable copy up to computable isomorphism [AK00,EG00]. There has been
a lot of work on computably categorical structures [KS99,EG00,Gon80,Smi81,
LaR77,Nur74,HKS03]. A function f : ω →onto ω is fully primitive recursive (fpr)
if f and f −1 are both primitive recursive.
Deﬁnition 8. ([KMNa]).A fully primitive recursive structure A is fpr categor-
ical if it has a unique fully primitive recursive presentation up to fully primitive
recursive isomorphism.
Example 9. [KMNa]
1. The additive group Vp ∼= 
i∈ω Zp is fpr-categorical
2. The dense linear order (Q, <) without end points is not fpr-categorical
3. The successor structure S = (ω, S), where S(x) = x+1, is not fpr-categorical
Even though Theorem 5 typically produces the most “boring” fpr presenta-
tions in each class, Theorem 10 below says that almost all structures in these
classes have complex (“irregular”, “unpredictable”) fpr presentations.
Theorem 10. ([KMNa]).
1. An equivalence structure S is fpr-categorical iﬀit is either of the form F ∪E,
where F is ﬁnite and E has only classes of size 1, or S has ﬁnitely many
classes at most one of which is inﬁnite.
2. A linear order is fpr-categorical iﬀit is ﬁnite.
3. A Boolean algebra is fpr-categorical iﬀit is ﬁnite.
4. An abelian p-group is fpr-categorical iﬀit has the form F ⊕V, where pV = 0
and F is ﬁnite.
5. A torsion-free abelian group is fpr-categorical iﬀit is the trivial group 0.
Proof (Informal Discussion). In some simple cases we can appeal to Theorem 5
and combine it with known facts from computable structure theory. For exam-
ple, suppose a Boolean algebra B has an atomless element and is not computably
categorical. Although Theorem 5 is not uniform in general, it is uniformly com-
putable for such BAs. It follows that we can produce two fpr copies of B that
are not even computably isomorphic. Nonetheless, some cases require a direct
proof. For instance, in the case of an atomic BA we cannot appeal to Theorem 5
directly since the isomorphism between B and its fpr copy is not even 0′′ in
general. Instead, in this case we need to simultaneously build two fpr copies of
B and diagonalise against all potential fpr-isomorphisms. Although the proof is
not hard, it does require some care.
Note that Theorem 10 resembles the following result of Khoussainov and
Nerode [KN94]: A structure is automatically categorical iﬀit is ﬁnite.
According to Deﬁnition 8, every fpr-categorical structure must have a fully
primitive recursive (thus, computable) copy. Theorem 10 suggests that fpr-
categorical structures are necessarily computably categorical. Surprisingly, this
is not the case:

82
A.G. Melnikov
Theorem 11 ([KMNa]). There exists a fpr-categorical structure which is not
computably categorical.
Proof (Informal Discussion). The proof of Theorem 11 is quite combinatorially
involved. We build the structure A carefully and force any fpr isomorphic copy
to be fpr-isomorphic to it. The rigidity helps to make the inverse of each such
isomorphism primitive recursive. Also, for this purpose we introduce a “local
coordinate system” that will allow us to recognise a local part of the structure
without looking through the whole structure. Finally, we combine these strategies
with a diagonalisation strategy. For that, we produce a computable copy B of
A and kill oﬀall φe : A ∼= B. We heavily rely on the fact that we can delay the
computation in B.
Question 12. Which of the common algebraic classes (such that groups, ﬁelds,
integral domains, . . .) contain examples of fpr-categorical but not computably
categorical structures?
5
The fpr-Degrees of a Structure
Note that the inverse of a primitive recursive function does not have to be prim-
itive recursive. It leads to a reduction [KMNc]. Let FPR(A) be the collection of
all fpr presentations of a countably inﬁnite structure A. For A1, A2 ∈FPR(A),
write A1 ≤pr A2 if there exists a primitive recursive isomorphism from A1 onto
A2. Clearly, ≤pr is reﬂexive and transitive. We write A1 ≃pr A2 if A1 ≤pr A2
and A2 ≤pr A1. In particular, we can look at the fpr-degrees of a given countably
inﬁnite structure A.
Deﬁnition 13 ([KMNc]). The fully primitive recursive degrees of a count-
ably inﬁnite algebraic structure A is the quotient structure FPR(A) =
(FPR(A), ≤pr)/ ≃pr.
The fpr-degrees FPR(A) is a computability-theoretic invariant of A
that encodes/reﬂects the non-primitive recursive content of the isomorphism
type of A2.
Question 14. Does |FPR(A)| = 1 imply that A is fpr-categorical?
As strange as it may sound, we still don’t know the answer to the question
above. It takes quite a bit of eﬀort to prove the rather satisfying:
Theorem 15 (M. and Ng, to appear). For every undirected graph G,
|FPR(G)| = 1 implies that G is fpr-categorical.
2 If A is fpr-categorical then FPR(A) contains a unique degree. Nonetheless, A ≃pr B
does not necessarily imply that there exists a fpr isomorphism A →B (it is easy to
construct a counter-example).

Eliminating Unbounded Search in Computable Algebra
83
Proof (Informal discussion). In fact, we have proved more. TFAE:
(1) |FPR(G)| = 1.
(2) G is fpr-categorical.
(3) Given any two f.p.r. copies A ∼= B of G, there exist primitive recursive
isomorphisms f : A 	→B and g : B 	→A, and a primitive recursive function
t : N 	→N such that given a ∈A, either Orb(a) = {(gf)n(a) : n ∈ω} has size at
most t(a), or every permutation u of Orb(a) can be extended to an automorphism
of G.
Note that given (3) we can run a primitive recursive back-and-forth construc-
tion to produce a fpr isomorphism between two fpr copies. First, check whether
Orb(a) has size ≤t(a). If “yes” then match Orb(a) with Orb(f(a)). Otherwise, if
Orb(a) has not yet closed after t(a) steps, then do the back-and-forth on Orb(a)
and Orb(f(a)) essentially ignoring the rest of the structure. Unfortunately, the
implication (1) →(2) is quite non-trivial.
Question 16. Is there a structure A such that 1 < |FPR(A)| < ∞?
6
A Sub-hierarchy of Computable Categoricity
In this section we discuss fpr-degrees of computably categorical structures (see
Deﬁnition 13).
A total computable function is honest if its graph is primitive recur-
sive [Kri96] This means that we can see whether f(x) = y for a given (x, y)
without any unbounded delay. Thus, is some sense this is a non-deterministic
version of primitive recursion. Clearly, if f is honest then so is f −1, but the
composition of two honest functions does not have to be honest.
In Theorem 10, all computably categorical fpr structures satisfy at least one
of the properties deﬁned below. (Let A be a fpr structure.)
– A is bottom-categorical if FPR(A) has the ≤pr-least element.
– A is top-categorical if FPR(A) has the ≤pr-greatest element.
– A is honestly categorical if for each A1, A2 ∈FPR(A) there exists a honest
isomorphism from A1 onto A2.
– A is relatively fpr categorical if there exists a pair of (oracle) primitive
recursive schemata P+ and P−such that for any isomorphic copy B (upon
N) of the fpr
structure A the maps PB
+ : A →B and PB
−: B →A are
isomorphisms that are inverses of each other.
For example, every ﬁnitely generated structure in a ﬁnite functional language
is bottom-categorical. Every computably categorical linear order or Boolean alge-
bra is top-categorical. In many standard classes (including e.g. linear orders)
honest categoricity is equivalent to the usual computable categoricity. All
algebraically natural examples of fpr categorical structures are relatively fpr-
categorical [KMNa] (see also (1) of Example 9). We summarise all these notions
in the diagram below.

84
A.G. Melnikov
bottom-categoricity
honest categoricity
top-categoricity

fpr-categoricity
















relative fpr-categoricity

Theorem 17 ([KMNc]). The diagram above is proper 3.
Proof (Informal Discussion). All implications are straightforward. Note that
every relatively fpr-categorical structure is (relatively) computably categorical.
It follows from Theorem 11 that fpr-categoricity does not imply relative fpr-
categoricity. The failures of the other missing implications are witnessed by pri-
ority constructions.
An alternate way to compare computably categorical fpr structures uses rel-
ative computation and the primitive recursive jump 0′
P R
4. Then a structure A is
0(n)
P R-categorical if it has a unique fpr-presentation, up to fully 0(n)
P R-isomorphism.
Theorem 18 ([KMNc]). For every n > 0 there exists a fully primitive recur-
sive structure which is fully 0(n)
P R-categorical but not fully 0(n−1)
P R
-categorical.
Proof (Informal Discussion). In [KMNc], Kalimllin, M. and Ng have proved
more than is stated in Theorem 18. The PR-degree any honest function can
be realized as the fpr-degree of categoricity of some structure (we omit formal
deﬁnitions). Remarkably, for any n, the PR-degree of 0(n)
P R is honest.
It is unclear whether there is any interesting relationship between full 0(n)
P R-
categoricity and any of the properties from Theorem 17.
3 This means that all implications that are shown at the diagram above are proper.
Furthermore, these implications (and their transitive closures) are the only implica-
tions that hold.
4 A total function g is primitively recursively reducible to a function f (g ≤P R f) if
g = Φf for some f-primitive recursive schema Φf. This leads to the deﬁnitions of
g ≡P R f and g <P R f as well as the notion of primitive recursive (PR-) degree.
For a total function f let {Φf
n} be the G¨odel numbering of all f-primitive recursive
schemata for functions with one variable. Deﬁne the primitive recursive jump f ′
P R to
be the function f ′
P R(n, x) = Φf
n(x). It is easy to check that f ≤P R g =⇒f ′
P R ≤P R
g′
P R and f <P R f ′
P R.

Eliminating Unbounded Search in Computable Algebra
85
7
Cantor’s Back-and-Forth Method Revisited
As we know from Example 9 (2), η = (Q, <) has two fpr copies that are not fpr
isomorphic. This means that Cantor’s back-and-forth proof is no longer “eﬀec-
tive” in absence of unbounded search.
Recall that a structure X is homogeneous if every isomorphism f : F1 →F2
between any two ﬁnitely generated substructures F1, F2 ⊆X is extendable to an
automorphism of X. See [Mac11] for a survey on homogeneous structures. The
following structures are homogeneous:
– η, the dense linear order without end-points.
– R, the Random Graph.
– P ∼= 
i∈ω Z∞
p , the universal divisible abelian p-group.
– B ∼= I(η), the countable atomless Boolean algebra.
Apart from homogeneity, there is little in common between the three homo-
geneous structures η, R, P. Nonetheless, they do share essentially the same
back-and-forth proof of their uniqueness up to isomorphism. The (Turing) com-
putable construction of an isomorphism for these structures has only one poten-
tially unbounded search at every substage. Recently Klamullin, M. and Ng have
announced the following rather counterintuitive result.
Theorem 19 ([KMNb]). The fpr-degree structures of the dense linear order η,
the random graph R, and the universal divisible abelian p-group P are pairwise
non-isomorphic.
Proof (Proof idea). It follows that both FPR(R) and FPR(P) have no greatest
element, while FPR(η) does. Also, FPR(P) has no maximal elements, while
FPR(R) does. Some these facts require a non-trivial proof.
Let B be the atomless Boolean algebra. Recall that B ∼= I(η), the interval
Boolean algebra of η. The reader might ﬁnd the question below a bit strange:
Question 20. Is FPR(B) ∼= FPR(η)?
In fact, we suspect that FPR(B) ̸∼= FPR(η). In spite of the diﬀerences in their
fpr-degree structure, there is at least one fundamental property that is common
for FPR(η), FPR(B), FPR(P), and FPR(R). Kalimullin, M. and Ng have
announced:
Theorem 21 ([KMNb]). For each of the structures η, B, P, R, the fpr-degrees
are not linearly ordered under ≤pr.
Although the proof of the theorem above requires some work, the result is
somewhat unsatisfying since we don’t know the answer to the following:
Question 22. Is there a structure A for which FPR(A) is linearly ordered and
|FPR(A)| > 1? Can A be chosen homogeneous?
We also conjecture that the fpr-degrees of the above structures enjoy some
density properties, but this is still work in progress.

86
A.G. Melnikov
References
[AK00] Ash, C., Knight, J.: Computable Structures and the Hyperarithmetical
Hierarchy. Studies in Logic and the Foundations of Mathematics, vol. 144.
North-Holland Publishing Co., Amsterdam (2000)
[Ala] Alaev, P.E.: Existence and uniqueness of structures computable in poly-
nomial time. Algebra Log. 55(1), 72–76 (2016)
[Boo59] Boone, W.: The word problem. Ann. Math 70, 207–265 (1959)
[BS11] Braun, G., Str¨ungmann, L.: Breaking up ﬁnite automata presentable
torsion-free abelian groups. Internat. J. Algebra Comput. 21(8), 1463–
1472 (2011)
[CDRU09] Cenzer, D., Downey, R.G., Remmel, J.B., Uddin, Z.: Space complexity of
abelian groups. Arch. Math. Log. 48(1), 115–140 (2009)
[CR] Cenzer, D., Remmel, J.B.: Polynomial time versus computable boolean
algebras. In: Arslanov, M., Lempp, S. (eds.) Recursion Theory and Com-
plexity, Proceedings 1997 Kazan Workshop, pp. 15–53. de Gruyter, Berlin
(1999)
[CR91] Cenzer, D.A., Remmel, J.B.: Polynomial-time versus recursive models.
Ann. Pure Appl. Logic 54(1), 17–58 (1991)
[CR92] Cenzer, D.A., Remmel, J.B.: Polynomial-time abelian groups. Ann. Pure
Appl. Logic 56(1–3), 313–363 (1992)
[Dob] Dobritsa, V.: Some constructivizations of abelian groups. Siberian J.
Math. 793(24), 167–173 (1983). (in Russian)
[ECH+92] Epstein, D.B.A., Cannon, J.W., Holt, D.F., Levy, S.V.F., Paterson, M.S.,
Thurston, W.P.: Word Processing in Groups. Jones and Bartlett Publish-
ers, Boston (1992)
[EG00] Ershov, Y., Goncharov, S.: Constructive Models. Siberian School of Alge-
bra and Logic. Consultants Bureau, New York (2000)
[Gon80] Goncharov, S.: The problem of the number of non auto equivalent construc
tivizations. Algebra i Logika 19(6), 621–639, 745 (1980)
[Gon97] Goncharov, S.: Countable Boolean Algebras and Decidability. Siberian
School of Algebra and Logic. Consultants Bureau, New York (1997)
[Gri90] Grigorieﬀ, S.: Every recursive linear ordering has a copy in dtime-space(n,
log(n)). J. Symb. Log. 55(1), 260–276 (1990)
[Hig61] Higman, G.: Subgroups of ﬁnitely presented groups. Proc. Roy. Soc. Ser.
A 262, 455–475 (1961)
[HKS03] Hirschfeldt, D.R., Khoussainov, B., Shore, R.A.: A computably categorical
structure whose expansion by a constant has inﬁnite computable dimen-
sion. J. Symbolic Log. 68(4), 1199–1241 (2003)
[KMNa] Kalimullin, I., Melnikov, A., Ng, K.M.: Algebraic structures computable
without delay (Submitted)
[KMNb] Kalimullin, I., Melnikov, A., Ng, K.M.: Cantor’s back-and-forth method
and computability without delay (to appear)
[KMNc] Kalimullin, I., Melnikov, A., Ng, K.M.: The diversity of categoricity with-
out delay. Algebra i Logika (to appear)
[KN94] Khoussainov, B., Nerode, A.: Automatic presentations of structures. In:
Leivant, D. (ed.) LCC 1994. LNCS, vol. 960, pp. 367–392. Springer, Hei-
delberg (1995). doi:10.1007/3-540-60178-3 93
[KN08] Khoussainov, B., Nerode, A.: Open questions in the theory of automatic
structures. Bull. EATCS 94, 181–204 (2008)

Eliminating Unbounded Search in Computable Algebra
87
[KNRS07] Khoussainov, B., Nies, A., Rubin, S., Stephan, F.: Automatic structures:
richness and limitations. Log. Methods Comput. Sci. 3(2:2), 1–18 (2007)
[Kri96] Kristiansen, L.: Papers on Subrecursion Theory, Dr Scient Thesis,
Research report 217. Ph.D. thesis, University of Oslo (1996)
[KS99] Khoussainov, B., Shore, R.A.: Eﬀective model theory: the number of
models and their complexity. In: Cooper, S.B., Truss, J.K. (eds.) Mod-
els and Computability (Leeds, 1997). London Mathematical Society Lec-
ture Notes, vol. 259, pp. 193–239. Cambridge University Press, Cambridge
(1999)
[LaR77] LaRoche, P.: Recursively presented boolean algebras. Notices AMS 24,
552–553 (1977)
[Mac11] Macpherson, D.: A survey of homogeneous structures. Discrete Math.
311(15), 1599–1634 (2011)
[MM] Melnikov, A., Montalban, A.: Computable polish group actions (to
appear)
[Mon13] Montalb´an, A.: A computability theoretic equivalent to Vaught’s conjec-
ture. Adv. Math. 235, 56–73 (2013)
[Nov55] Novikov, P.: On the algorithmic unsolvability of the word problem in group
theory. Trudy Mat. Inst. Steklov 44, 1–143 (1955)
[NS07] Nies, A., Semukhin, P.: Finite automata presentable abelian groups. In:
Artemov, S.N., Nerode, A. (eds.) LFCS 2007. LNCS, vol. 4514, pp. 422–
436. Springer, Heidelberg (2007). doi:10.1007/978-3-540-72734-7 29
[NT08] Nies, A., Thomas, R.M.: FA-presentable groups and rings. J. Algebra
320(2), 569–585 (2008)
[Nur74] Nurtazin, A.: Computable classes and algebraic criteria of autostabil-
ity. Math. Inst. SB USSRAS, Novosibirsk, Summary of Scientiﬁc Schools
(1974)
[Rem81] Remmel, J.B.: Recursive boolean algebras with recursive atoms. J. Symb.
Log. 46(3), 595–616 (1981)
[Smi81] Smith, R.L.: Two theorems on autostability in p-Groups. In: Lerman, M.,
Schmerl, J.H., Soare, R.I. (eds.) Logic Year 1979–80. LNM, vol. 859, pp.
302–311. Springer, Heidelberg (1981). doi:10.1007/BFb0090954
[Tsa11] Tsankov, T.: The additive group of the rationals does not have an auto-
matic presentation. J. Symbolic Log. 76(4), 1341–1351 (2011)

Computable Transformations of Structures
Russell Miller1,2(B)
1 Queens College – C.U.N.Y., 65-30 Kissena Blvd., Queens, NY 11367, USA
Russell.Miller@qc.cuny.edu
2 Graduate Center of C.U.N.Y., 365 Fifth Avenue, New York, NY 10016, USA
http://qcpages.qc.cuny.edu/∼rmiller
Abstract. The isomorphism problem, for a class of structures, is the
set of pairs of structures within that class which are isomorphic to each
other. Isomorphism problems have been well studied for many classes
of computable structures. Here we consider isomorphism problems for
broader classes of countable structures, using Turing functionals and
applying the notions of ﬁnitary and countable computable reductions
which have been developed for equivalence relations more generally.
1
Introduction
In much of mathematics, two ﬁrst-order structures which are isomorphic to each
other are treated as being exactly the same for all purposes: the objects of study
are really the equivalence classes under isomorphism, rather than the structures
themselves. Computable structure theory addresses this situation at a deeper
level. It is well known that two isomorphic structures may have substantially
diﬀerent algorithmic properties, and therefore, when we consider questions of
computability for ﬁrst-order structures, isomorphism is far too coarse an equiva-
lence relation to be ignored. The fundamental equivalence relation in this disci-
pline is computable isomorphism: two structures (both countable, with domain
ω) are computably isomorphic if some Turing-computable function on ω is in fact
an isomorphism between them. In this case, essentially all known computability-
theoretic properties transfer from either structure to the other. In theoretical
computer science, complexity theory would go deeper yet, but we will not focus
on those questions here.
Of course, the question of whether two structures are isomorphic remains
extremely important in computable structure theory. Instead of being so low-
level as to be ignored (as in much of model theory), it becomes an object of
serious study. The statement that structures A and B are isomorphic is on its
face a Σ1
1 sentence about A and B. (For the rest of this article, all structures
are countable with domain ω.) In speciﬁc cases, however, it may be not be
a Σ1
1-complete question, but may lie at various levels in the hyperarithmeti-
cal hierarchy instead. For example, for algebraically closed ﬁelds, isomorphism
The author was supported by Grant # DMS – 1362206 from the N.S.F., and by
grants from the PSC-CUNY Research Award Program and the Queens College
Research Enhancement Fund.
c
⃝Springer International Publishing AG 2017
J. Kari et al. (Eds.): CiE 2017, LNCS 10307, pp. 88–97, 2017.
DOI: 10.1007/978-3-319-58741-7 9

Computable Transformations of Structures
89
depends solely on the characteristic of the ﬁeld and its transcendence degree
over its prime subﬁeld, both of which can be expressed with just a few ﬁrst-
order quantiﬁers. Vector spaces over Q are quite similar: for both, the question
of whether two computable models of the given theory are isomorphic is a Π0
3-
complete question. The study of isomorphism problems often turns into a search
for invariants, such as the characterstic and the transcendence degree, which
determine isomorphism.
On the other hand, it is known that for computable graphs (which sim-
ply means computable symmetric irreﬂexive subsets of ω2), the isomorphism
problem is Σ1
1-complete. In [5], Friedman and Stanley created a framework for
showing other isomorphism problems to be equally diﬃcult. They showed, for
example, that given any two computable graphs G0 and G1, one can produce
computable linear orders L0 and L1 such that
G0 ∼= G1 ⇐⇒L0 ∼= L1.
The “production” of these linear orders is a hyperarithmetic procedure – indeed,
a computable procedure – and therefore the isomorphism problem for com-
putable linear orders must also be Σ1
1-complete.
However, if one knows that the isomorphism problem for computable alge-
braically closed ﬁelds is Π0
3-complete and wishes to show the same for com-
putable rational vector spaces, a hyperarithmetic procedure in general is insuﬃ-
cient. For classiﬁcation at these levels, eﬀective procedures are required, and have
been examined in [2–4,8], by Calvert, Cummins, Knight, S. Miller, and Vanden
Boom, in various combinations. The results in [2, Sect. 4] yield a computable
function f which accepts as input the indices (e0, e1) of any two computable
algebraically closed ﬁelds and computes the indices (i0, i1) = f(e0, e1) of two
computable rational vector spaces which are isomorphic if and only if the origi-
nal two algebraically closed ﬁelds were. (By an index e for a computable structure
A, we mean a number such that the e-th partial computable function ϕe is the
characteristic function of the atomic diagram of A, under a ﬁxed coding into ω
of atomic sentences in the language of A with constants from ω.)
The method here works well for computable structures, but the results are
sometimes surprising. For example, the isomorphism problem for computable
algebraic ﬁelds of characteristic 0 (that is, subﬁelds of the algebraic closure Q)
turns out to be only Π0
2-complete. It does reduce to the isomorphism problem
for algebraically closed ﬁelds, but not vice versa – which is puzzling, since ACF0
has straightforward invariants determining the isomorphism type, while no such
invariants are known for the class of algebraic ﬁelds.
2
Equivalence Relations on Cantor Space
Our purpose here is to bring to this situation methods from the study of Borel
reductions on equivalence relations. We begin by introducing that topic, which
has been well studied in descriptive set theory with a focus on equivalence rela-
tions on Cantor space 2ω, and more recently has been extended by many authors
to the context of equivalence relations on ω itself.

90
R. Miller
Let E and F be equivalence relations on domains S and T, respectively. A
reduction of E to F is a function g : S →T such that:
(∀x0, x1 ∈S) [x0 E x1 ⇐⇒g(x0) F g(x1)].
If this holds, then by computing g and deciding the relation F, one can decide E
as well. Thus E is “no harder to decide” than F, at least modulo the diﬃculty
of computing g.
The next deﬁnition was given in [10].
Deﬁnition 1. Let E and F be equivalence relations on subsets C and D of 2ω,
respectively. A computable reduction of E to F is a reduction g : C →D given
by a computable function Φ (that is, an oracle Turing functional) on the reals
involved:
(∀A ∈C)(∀x ∈ω) χg(A)(x) = ΦA(x).
If such a reduction exists, then E is computably reducible to F, denoted E ≤0 F.
Descriptive set theorists usually eschew this deﬁnition in favor of the more gen-
eral concept of a Borel reduction, which is to say, a reduction that happens to be
a Borel function. This is the context in which Friedman and Stanley developed
their work. More recently, computability theorists have taken to considering
computable functions (from ω to ω) as reductions, in the context of equiva-
lence relations on ω. The term “computable reduction” therefore often refers
to that context, but we will use it here as well for the reductions described in
Deﬁnition 1, trusting the reader to distinguish the two concepts based on the
equivalence relations in question.
Another reﬁnement of reducibilities on equivalence relations was introduced
by Ng and the author in [11]. Studying equivalence relations on ω, they deﬁned
ﬁnitary reducibilities. In the context of Cantor space, it is natural to extend their
notion to all cardinals μ < 2ω (as indeed was suggested in their article), yielding
the following deﬁnitions, which also appeared in [10].
Deﬁnition 2. For equivalence relations E and F on domains S and T, and for
any cardinal μ < |S|, we say that a function g : Sμ →T μ is a μ-ary reduction
of E to F if, for every x = (xα)α∈μ ∈Sμ, we have
(∀α < β < μ) [xα E xβ ⇐⇒gα(x) F gβ(x)],
where gα : Sμ →T are the component functions of g = (gα)α<μ. For limit
cardinals μ, a related notion applies with <μ in place of μ: a function g : S<μ →
T <μ which restricts to a ν-ary reduction of E to F for every cardinal ν < μ
is called a (<μ)-ary reduction. (For μ = ω, an ω-ary reduction is a countable
reduction, and a (<ω)-ary reduction is a ﬁnitary reduction.)
When S ⊆2ω and T ⊆2ω and the μ-ary reduction g is computable, we
write E ≤μ
0 F, with the natural adaptation E ≤μ
α F for α-jump μ-ary reduc-
tions. Likewise, when a (< μ)-ary reduction g is α-jump computable, we write
E ≤<μ
α
F, When α > 0, it is important to note that Φ((x)(α)) is required to equal
g(x); this allows more information in the oracle than it would if we had required
Φ((x(α)
0
⊕x(α)
1
⊕··· ) = g(x), with the jumps of the individual inputs taken separately.

Computable Transformations of Structures
91
In our context for applying these notions, the domains S and T will be subsets
of Cantor space, deﬁned by
S = {A ⊆ω : A codes the atomic diagram of a structure in C},
for some class C of countable structures with domain ω, with T likewise deﬁned
by D. For us the equivalence relation on each of these domains will be iso-
morphism on the structures coded. One could explore further, of course, using
elementary equivalence of those structures, or bi-embeddability, or other equiv-
alence relations on structures.
3
Early Examples
To begin with, we consider the situation described in the introduction. The mod-
els of ACF0 form a particularly simple class of structures, with isomorphism
equivalent to having the same transcendence degree (since we have restricted
here to characteristic 0; similar remarks apply to any other ﬁxed characteristic).
Isomorphism between algebraic ﬁelds of characteristic 0 – that is, the subﬁelds
of Q – seems a more challenging problem. However, analysis of computable mod-
els in these classes yields the opposite conclusion: isomorphism of computable
models of ACF0 is Π0
3-complete, whereas isomorphism of computable algebraic
ﬁelds is only Π0
2 (and is complete at this level). The latter remark follows from
a lemma which appears as [13, Corollary 3.9].
Lemma 1. Two algebraic ﬁeld extensions E and F of Q are isomorphic if and
only if every ﬁnitely generated subﬁeld of each one embeds into the other.
⊓⊔
By the Primitive Element Theorem, the condition here can be expressed by
saying that, for every irreducible polynomial q ∈Q[X], E possesses a root of
q if and only if F does. For computable ﬁelds E and F, this is clearly a Π0
2
condition.
When we broaden our analysis to the classes C of all models of ACF0 with
domain ω and D of all algebraic ﬁeld extensions of Q with domain ω, we gain a
richer view of the situation. Write ACF and Alg for the sets of atomic diagrams
of elements of C and D, respectively, and ∼=ACF and ∼=Alg for the isomorphism
relations on these sets of reals. First of all, it is clear that ∼=Alg̸≤0∼=ACF , as
a full computable reduction would require every one of the continuum-many
isomorphism classes in Alg to map to a distinct isomorphism class in ACF,
and ACF has only countably many isomorphism classes in all. (To see that Alg
has uncountably many, write pn for the n-th prime and notice that for every
A ̸= B ⊆ω, the ﬁelds Q[√pn
:
n ∈A] and Q[√pn
:
n ∈B] cannot be
isomorphic, as no ﬁnite set of square roots of primes generates the square root
of any other prime.)
On the other hand, it is not diﬃcult to give a binary computable reduction
of Alg to ACF. Such a reduction is simply a Turing functional which, given the
atomic diagrams of two algebraic ﬁelds F0 and F1, computes the diagrams of
algebraically closed ﬁelds K0 and K1 as follows. Fix an enumeration q0, q1, . . . of

92
R. Miller
all irreducible polynomials in Q[X]. (We use here the fact that Q has a splitting
algorithm, which was proven by Kronecker in [9].) At stage 0 we start with Q as
K0 and Q(t) as K1 (with t transcendental).
Now for each s, compute the greatest number ns ≤s such that
(∀n ≤ns)(∀i < deg(qn)) [(∃roots x0 < . . . < xi ≤s of qn(X) in F0)
⇐⇒(∃roots y0 < . . . < yi ≤s of qn(X) in F1)].
(Here x0 < . . . < xi ≤s refers to the order of the xj in ω, not in F0, which is not
an ordered ﬁeld. Hence this statement is decidable from the atomic diagrams of
F0 and F1.) At stage s + 1, if (∀t ≤s) nt < ns+1, we adjoin a new element to
each of K0 and K1, independent over all previous elements. If not, we adjoin no
new independent elements. In either case, we also take one more step towards
making K0 and K1 into models of ACF0.
At the end of this process, K0 and K1 will be models of ACF0. If F0 ∼= F1,
then new transcendentals were adjoined to each at inﬁnitely many stages, so
both have inﬁnite transcendence degree, yielding K0 ∼= K1 as desired. Otherwise,
Lemma 1 yields some (least) n for which qn has more roots in F0 than in F1
(without loss of generality). In this case, once all the roots in F0 have appeared,
ns will never exceed n, and so no further transcendentals will ever again be added
to either ﬁeld. But at every ﬁnite stage, K1 has larger transcendence degree than
K0, since we started that way at stage 0, and so K0 ̸∼= K1 as desired.
The process above can be converted into a countable reduction, yielding the
next result.
Proposition 1. Alg ≤ω
0 ACF.
We sketch the construction of a countable computable reduction. Let dn be the
degree of the polynomial qn. For each F, deﬁne the path pF ∈ωω by
pF (n) = |{x ∈F : qn(x) = 0}|.
Each such path is conﬁned to the possible nodes satisfying pF (n) ≤dn for all
n, which form a ﬁnite-branching subtree. We assign numbers to these nodes:
those at level 1 are numbered 0, . . . , d0; those at the next level are numbered
d0 + 1, d0 + 2, . . . , d0 + (d0 + 1)(d1 + 1), and so on. The only important aspect
of this computable numbering is that each node has a label greater than its
predecessor’s label.
Given the atomic diagrams of algebraic ﬁelds F0, F1, . . ., we construct models
K0, K1, . . . of ACF0 to satisfy, for each i:
– If there exists j < i such that pFi = pFj, then Ki has the same transcendence
degree (over Q) as Kj.
– Otherwise, there exists some least n such that (∀j < i) pFi↾n ̸= pFj↾n. Let d
be the label of the node pF↾n. Then Ki will have transcendence degree d.
Clearly, satisfying these conditions will ensure that we have a countable
reduction from Alg to ACF. To satisfy them, we guess eﬀectively at the path

Computable Transformations of Structures
93
pFi for each i, at each stage s, with the guesses converging to the actual path
pFi. If our guesses produce an n as described in the second item, then Ki at
this stage has transcendence degree n; if not, then it is isomorphic to Kj at this
stage.
This is not really a generalization of the binary reduction constructed above.
Here we use the fact that transcendentals can be destroyed as well as created
in the construction of a computable ﬁeld: we build only ﬁnitely much of Ki at
any stage, and therefore any element previously considered transcendental in
Ki can consistently be turned into a large rational number at the next stage.
(The 1-type of a transcendental element is a nonprincipal type.) For a given Ki,
once the guesses stabilize on the true value n (if one exists), the transcendentals
in Ki at that stage remain independent forever, and any more transcendentals
subsequently added to Ki are later destroyed this way. On the other hand, if
Fi ∼= Fj for some smaller j, then for the n belonging to the least such j, there
is some stage after which we always have the same guess pFi ↾n = pFj ↾n for
both paths. From then on, the independent elements in Ki corresponding to
those in Fj will stay independent forever, and any subsequent ones will later be
destroyed. (Notice that this means that every Ki will have ﬁnite transcendence
degree. So we have actually given a countable reduction of Alg to a slightly
smaller class than ACF.)
On the other hand, there is no computable reduction, not even a binary
reduction, from ACF to Alg. This follows from the Π0
3-completeness of the
isomorphism problem for the set of indices for computable algebraically closed
ﬁelds of characteristic 0: any such reduction would show this Π0
3-complete set to
be Π0
2, by Lemma 1. Thus the non-reducibility result for computable structures
carries over to the general case.
4
ACF0 and Equivalence Structures
For further insights about ACF0, we consider another class of structures: the
class E of countable equivalence structures with no inﬁnite equivalence classes.
(An equivalence structure consists of a single equivalence relation R on the
domain, with equality also in the language.) For computable members of E,
the isomorphism problem is Π0
3-complete, the same level of complexity as for
ACF0. (If we had allowed inﬁnite equivalence classes, the complexity level would
be Π0
4 instead.) However, there are 2ω-many nonisomorphic structures in E. Our
goal is to distinguish these two classes using the new notions of this article. First,
we show that the class C of countable models of ACF0 is no harder than E.
Proposition 2. ACF ≤0 Eq, where Eq is the isomorphism relation on the reals
in the class E.
Proof. Given an algebraically closed ﬁeld K as oracle, our reduction Φ builds
an equivalence relation R, beginning by creating a single R-equivalence class of
size (2n −1) and inﬁnitely many R-equivalence classes of size 2n for each n > 0.

94
R. Miller
Then it begins to guess (separately for each n > 0) whether K has transcendence
degree ≥n.
At each stage s + 1, for each n ≤s, we ﬁnd the least n-tuple x ∈K with all
xi ≤s such that, for all i ≤s, qn,i(x) ̸= 0 in K. (Here we use a ﬁxed ordering
of ωn and a ﬁxed list {qn,i}i∈ω of Q[X1, . . . , Xn].) If this is the same tuple as at
stage s, we do nothing. If it is a new tuple, then we take the unique equivalence
class of size 2n −1 currently in R, add one more element to it, and create a new
R-equivalence class of size (2n −1) to replace it. This is the entire construction.
Now if K has transcendence degree < n, then every R-class of size (2n −1)
ever created will eventually become a class of size 2n. On the other hand, if
K has transcendence degree ≥n, then eventually an independent n-tuple will
be found in K, and from that stage on, the unique R-class of size (2n −1)
will never have another element added to it. Thus R has exactly one class of
size (2n −1) for each n ≤the transcendence degree of K, along with inﬁnitely
many classes of each even size. Thus we have a computable full reduction from
ACF to Eq.
⊓⊔
The next proposition is also not surprising. In fact, given that isomorphism
on computable models of ACF0 is Π0
3-complete as a set (and that isomorphism
on computable sturctures in E is Π0
3, the proposition holds immediately for
computable structures. This is because a computable binary reduction from E
to F (where these are equivalence relations on ω) is in fact simply a many-one
reduction from the set E to the set F. Since we wish to establish it for all of E
and C, rather than just for computable structures, we give the entire proof.
Proposition 3. Eq ≤2
0 ACF. That is, there is a computable binary reduction
from Eq to ACF.
Proof. Given two equivalence relations R0 and R1, we must produce alge-
braically closed ﬁelds K0 and K1, isomorphic if and only if R0 and R1 are.
To do so, we wish to test, for each k and n, whether
R0 has ≥k classes of size exactly n ⇐⇒R1 has ≥k classes of size exactly n.
A pair ⟨k, n⟩for which this may fail will be assigned a number tn,k. If R0
turns out to have k classes of size n while R1 does not, then K0 will have
transcendence degree ≥tk,n and K1 will not. If no such k and n exist, then both
ﬁelds will have inﬁnite transcendence degree. To determine what to do, we will
search ﬁrst for a ﬁnite subset Xk,n forming k-many R0-classes of size n, and then
for a corresponding subset ˜Yk,n of R1-classes. If the R1-classes appear ﬁrst, then
they will form Yk,n and we will then search for ˜Xk,n instead.
At stage 0 we begin with Q as both K0 and K1. At each stage, ﬁnitely
many steps are taken so that each ﬁeld will be algebraically closed at the end
of the construction, but at no stage will Q yet be a subﬁeld of either K0 or K1.
Thus, putative transcendentals can always be “destroyed,” by being turned into
elements algebraic over Q. We write Ri,s for the restriction of Ri to {0, . . . , s}.

Computable Transformations of Structures
95
At stage s+1 we ﬁrst address that pair ⟨k, n⟩≤s for which tk,n,s is smallest;
then that for which tk,n,s is second-smallest, and so on. If none of these steps
ends the stage, we will subsequently address those ⟨k, n⟩with tk,n,s undeﬁned.
If tk,n,s is deﬁned, then so is one (but not both) of the ﬁnite subsets Xk,n,s
(⊆R0,s) or Yk,n,s (⊆R1,s). The instructions are symmetric; we give them here
with Xk,n,s deﬁned, in which case its elements formed k distinct R0-classes of
size n when it was ﬁrst chosen.
1. If any of these k R0-classes contains more than n elements in R0,s+1, then
Xk,n,s+1 and tk,n,s+1 become undeﬁned, and we destroy enough transcen-
dentals in both K0 and K1 to ensure that both have transcendence degree
tk′,n′,s+1, for that pair ⟨k′, n′⟩with the greatest tk′,n′,s+1 < tk,n,s (If there is
no such ⟨k′, n′⟩, then K0 and K1 both get transcendence degree 0.) The stage
ends here, with all remaining values becoming undeﬁned as well. Otherwise,
Xk,n,s+1 = Xk,n,s and K0 remains the same, and we consider (2)–(5) below.
2. Otherwise, if ˜Yk,n,s was undeﬁned, and R1,s+1 contains k distinct classes of
size exactly n, then the elements of the ﬁrst k of these classes are deﬁned to
form ˜Yk,n,s+1, and we add just as many transcendentals to K1 as needed to
make its transcendence degree ≥tk,n,s.
3. If ˜Yk,n,s was undeﬁned, but (2) does not apply, then nothing changes.
4. If ˜Yk,n,s was deﬁned, then its elements formed k distinct R1-classes. If all
these classes still have size exactly n in R1,s+1, then nothing changes.
5. Otherwise ˜Yk,n,s was deﬁned, but one of its R1-classes now has size > n. In
this case ˜Yk,n,s+1 is undeﬁned, and we destroy just enough transcendentals
in K1 to make its transcendence degree < tk,n,s+1 = tk,n,s. (K0 still has
trancendence degree ≥tk,n,s.)
If either (1), (2), (3), or (5) applies, then the stage ends here. If (4) applies, then
we continue to the pair ⟨k, n⟩with the next-smallest tk,n,s. If no more pairs have
tk,n,s deﬁned, then we now go in order through those pairs ⟨k, n⟩≤s for which
tk,n,s is undeﬁned. For the least pair ⟨k, n⟩(if any) among these such that either
R0,s+1 or R1,s+1 contains at least k distinct classes of size exactly n, we deﬁne
tk,n,s+1 = s + 1, and either
– let Xk,n,s+1 contain the (kn) elements of R0,s+1 forming those R0-classes,
and add transcendentals to K0 so that it has transcendence degree tk,n,s+1;
or else
– let Yk,n,s+1 contain the (kn) elements of R1,s+1 forming those R1-classes, and
add transcendentals to K1 so that it has transcendence degree tk,n,s+1.
This completes the stage.
If R0 ̸∼= R1, then ﬁx the least stage s0 at which, for some ⟨k, n⟩, we have
found k classes truly of size n in R0,s0 (WLOG) and set them to equal Xk,n,s0,
and R1 does not possess k classes of this this size, and for all ⟨k′, n′⟩with
tk′,n′,s0 < tk,n,s0, Xk′,n′,s0 and ˜Yk′,n′,s0 are deﬁned and have stabilized. Such
an s0 must exist, since some ⟨k, n⟩do exist. At this stage, K0 will be given
transcendence degree tk,n,s0, which will equal tk,n = lims tk,n,s, while K1 will

96
R. Miller
have lesser transcendence degree at that stage. Moreover, every ˜Yk,n,s ever sub-
sequently found will later become undeﬁned, with the transcendence degree of
K1 threrefore dropping back below tk,n inﬁnitely often, and so K1 ̸∼= K0.
However, if R0 ∼= R1, then for every ⟨k, n⟩for which tk,n,s stabilizes, both
K0 and K1 will have transcendence degree ≥lims tk,n,s. Moreover, there will be
inﬁnitely many such pairs ⟨k, n⟩, since every element of R0 lies in a ﬁnite R0-class,
and likewise for R1. Therefore, both K0 and K1 will have inﬁnite transcendence
degree, leaving them isomorphic.
⊓⊔
Proposition 4. Eq ≤3
0 ACF, but Eq ̸≤4
0 ACF. That is, there is a computable
ternary reduction from Eq to ACF, but no 4-ary computable reduction.
The details of the proof are too extensive to present here; they will be
described in the author’s talk at the C.i.E. meeting.
In light of the Π0
3-completeness of isomorphism for computable algebraic
ﬁelds, this proposition seems like a surprise. Section 4.2 of [11] makes it more
plausible. The discussion there centers on the fact that, since isomorphism on
models of ACF0 is given by transcendence degree, it is essentially just a matter
(for a computable model K) of counting the elements in the following Σ0
2 basis
for K:
{x ∈K : (∀nonzero h ∈Z[X0, . . . , Xx]) h(0, 1, . . . , x) ̸= 0 in K}.
It is shown in [11] that, if E∅′
card is the relation (on indices e of Σ0
2 sets W ∅′
e ) of
having the same cardinality, then E∅′
card is complete under ternary reducibility
among Π0
3 equivalence relations on ω, but not complete among them under 4-
ary reducibility. Since the relation (for indices of computable ﬁelds in general)
of having the same transcendence degree over the prime subﬁeld is computably
reducible to E∅′
card, it is not so surprising that isomorphism on ACF in general
loses its power at the same speciﬁc ﬁnitary level of reduction.
The arguments in [11] do prove the following, using the notion of jump-
reduction from [10], with a functional whose oracle is the jump of the inputs.
Lemma 2. Eq ≤3
1 ACF. That is, there is a Turing functional Γ such that
Γ (E0⊕E1⊕E2)′ = K0 ⊕K1 ⊕K2 is a ternary reduction from Eq to ACF.
In light of Proposition 4, it is natural to enquire into other theories admitting
similar notions of dimension. Baldwin and Lachlan showed in [1] that, if T is an
ω1-categorical theory that is not ω-categorical (such as ACF0), the countable
models of T form an (ω+1)-sequence under elementary embedding. One suspects,
therefore, that the class of such models might be complete among Π0
α-deﬁnable
equivalence relations on 2ω under ternary computable reducibility but not under
4-ary computable reducibility, just as holds for models of ACF0 with α = 3.
5
Transformations and Functors
As a ﬁnal remark, we note that these computable transformations, as in
Deﬁnition 1, form part of the larger concept of a computable functor. These were

Computable Transformations of Structures
97
deﬁned by Poonen, Schoutens, Shlapentokh, and the author in [12], and subse-
quently, in [6,7], he and Harrison-Trainor, Melnikov, and Montalb´an broadened
their applicability. We give their deﬁnition here.
Deﬁnition 3. Let C and D be categories of structures with domain ω, for which
the morphisms from S to T are maps from the domain ω of S to the domain ω
of T . A computable functor is a functor F : C →D for which there exist Turing
functionals Φ and Φ∗such that
– for every S ∈C, the function ΦS computes (the atomic diagram of) the
structure F(S); and
– for every morphism g : S →T in C, we have ΦS⊕g⊕T
∗
= F(g) in D.
It would be natural to examine how close the computable transformations deﬁned
earlier in this article come to being computable as functors. The functional Φ∗
computing the functor on morphisms is likely to require one or more jumps of
S and T as oracle, but if not, then the conclusions in [6,12] about computable
functors would all apply here as well.
References
1. Baldwin, J.T., Lachlan, A.H.: On strongly minimal sets. J. Symb. Log. 36(1),
79–96 (1971)
2. Calvert, W.: The isomorphism problem for classes of computable ﬁelds. Arch.
Math. Log. 43, 327–336 (2004)
3. Calvert, W., Cummins, D., Knight, J.F., Miller, S.: Comparing classes of ﬁnite
structures. Algebra Log. 43, 365–373 (2004)
4. Calvert, W., Knight, J.F.: Classiﬁcation from a computable viewpoint. Bull. Symb.
Log. 12, 191–218 (2006)
5. Friedman, H., Stanley, L.: A Borel reducibility for classes of countable structures.
J. Symb. Log. 54, 894–914 (1989)
6. Harrison-Trainor, M., Melnikov, A., Miller, R., Montalb´an, A.: Computable func-
tors and eﬀective interpretability. J. Symb. Log. 82(1), 77–97 (2017)
7. Harrison-Trainor, M., Miller, R., Montalb´an, A.: Borel functors and inﬁnitary inter-
pretations (submitted for publication)
8. Knight, J.F., Miller, S., Vanden Boom, M.: Turing computable embeddings. J.
Symb. Log. 72(3), 901–918 (2007)
9. Kronecker, L.: Grundz¨uge einer arithmetischen Theorie der algebraischen Gr¨oßen.
J. Math. 92, 1–122 (1882)
10. Miller, R.: Computable reducibility for Cantor space (submitted for publication)
11. Miller, R., Ng, K.M.: Finitary reducibility on equivalence relations. J. Symb. Log.
81(4), 1225–1254 (2016)
12. Miller, R., Poonen, B., Schoutens, H., Shlapentokh, A.: A computable functor from
graphs to ﬁelds (submitted for publication)
13. Miller, R., Shlapentokh, A.: Computable categoricity for algebraic ﬁelds with split-
ting algorithms. Trans. Amer. Math. Soc. 367(6), 3981–4017 (2015)

Formulas with Reversal
Narad Rampersad(B)
Department of Mathematics and Statistics, University of Winnipeg,
515 Portage Avenue, Winnipeg, MB R3B 2E9, Canada
n.rampersad@uwinnipeg.ca
Abstract. We introduce the new concept of “formula with reversal”.
We show some simple formulas with reversal that have high index and
we give a partial characterization of unavoidable formulas with reversal.
One of the fundamental objects of study in combinatorics on words is the
pattern. A pattern is a word over an alphabet of variables and is meant to
describe some kind of repetitive structure. For instance the pattern XX over
the single variable X is meant to describe the repetition of the same word twice
in succession. A word x over an alphabet Σ encounters a pattern p over an
alphabet Δ if there is a non-erasing morphism h : Δ∗→Σ∗such that h(p) is
a factor of x. For example, the word waverers encounters the pattern XX via
the map X →er. If the word x does not encounter p then it avoids p.
The ﬁrst systematic analysis of the avoidability of patterns was done by Bean,
Ehrenfeucht, and McNulty [2], and, independently, by Zimin [14]. One of their
major results was a characterization of which patterns are avoidable on a ﬁnite
alphabet. The least k such that a pattern p is avoidable on a k-letter alphabet
is called the index of p. Baker, McNulty, and Taylor [1] produced an example of
a pattern with index 4 and left it as an open question whether or not there are
patterns of higher index. Clark [4] produced an example of a pattern of index 5
and at present no pattern is known to have index higher than 5.
Cassaigne [3] introduced the related concept of a formula. A formula is a set
of patterns {p1, . . . , ps}, usually written with “dots” as p1 · p2 · · · · · ps. The pi
are referred to as fragments of the formula. The formula is avoided by a word x
if there is no non-erasing morphism h : Δ∗→Σ∗such that h(pi) is a factor of x
for every i = 1, . . . , s. Clark used this notion of formula to produce his example
of a pattern of index 5.
Recently, there has been some interest in studying patterns with reversal,
such as XXXR. A word x encounters XXXR if there is a morphism h : {X}∗→
Σ∗such that h(X)h(X)(h(X))R is a factor of x, where (h(x))R denotes the
reversal of the word h(x). Du, Mousavi, Rowland, Schaeﬀer, and Shallit [10] and
Currie and Rampersad [8,9] examined the patterns XXXR and XXRX. Currie
and Lafrance [5] determined the index of every binary pattern with reversal. For
some recent algorithmic results, see [11–13].
Of course, one can generalize patterns with reversal to formulas with reversal
in the same way one generalizes patterns to formulas. The work we will present in
this talk is that of Currie, Mol, and Rampersad [6,7] on formulas with reversal.
c
⃝Springer International Publishing AG 2017
J. Kari et al. (Eds.): CiE 2017, LNCS 10307, pp. 98–100, 2017.
DOI: 10.1007/978-3-319-58741-7 10

Formulas with Reversal
99
The ﬁrst results [6] are a construction of some simple formulas with reversal
that have index 5. Clark’s example of a formula of index 5, which does not use
reversal, is quite complicated; with reversals, our examples are quite simple. For
each k ≥1, we deﬁne the formula
ψi = XY1Y2 · · · YkX · Y R
1 · Y R
2 · · · · · Y R
k .
Theorem 1. The formula ψ1 has index 4.
Theorem 2. The formula ψ2 has index 5.
Theorem 3. For k ≥1, the formula ψk has index ≥4.
Our next result is an attempt to generalize the so-called Zimin characteri-
zation of unavoidable formulas. Let X1, X2, . . . be variables. Deﬁne the Zimin
words recursively by Z0 = ϵ and for n ≥1 we have Zn = Zn−1XnZn−1. Zimin
showed that a formula (without reversal) on n variables is unavoidable if and
only if it is encountered by Zn.
We generalize this to formulas with reversal as follows. Let X1, X2, . . . and
Y1, Y2, . . . be variables. For any variable X deﬁne X♯= {X, XR}. For m ≥0
and n ≥0 we deﬁne the Zimin formula with reversal Zm,n by
Zm,0 = X♯
1 · · · X♯
m
and
Zm,n = Zm,n−1YnZm,n−1.
Given a formula with reversals φ, we say that a variable X is two-way in φ if
both X and XR occur in φ. Otherwise, we say that X is one-way. Note that in
Zm,n the Xi are two-way and the Yi are one-way. We have the following partial
result [7].
Theorem 4. Let φ be a formula with reversals with m ≥0 two-way variables
and n ≤2 one-way variables. Then φ is unavoidable if and only if it is encoun-
tered by Zm,n.
In this abstract we have been somewhat informal with our deﬁnitions. For full
details and proofs, please see the papers [6,7].
References
1. Baker, K., McNulty, G., Taylor, W.: Growth problems for avoidable words. Theo-
ret. Comput. Sci. 69, 319–345 (1989)
2. Bean, D.R., Ehrenfeucht, A., McNulty, G.F.: Avoidable patterns in strings of sym-
bols. Paciﬁc J. Math. 85, 261–294 (1979)
3. Cassaigne, J.: Motifs ´evitables et r´egularit´e dans les mots, Ph.D. thesis, Universit´e
Paris VI (1994)
4. Clark, R.J.: Avoidable formulas in combinatorics on words, Ph.D. thesis, University
of California, Los Angeles (2001)

100
N. Rampersad
5. Currie, J.D., Lafrance, P.: Avoidability index for binary patterns with reversal.
Electron. J. Combin. 23(1) (2016). Paper #P1.36
6. Currie, J., Mol, L., Rampersad, N.: A family of formulas with reversal of high
avoidability index (Submitted)
7. Currie, J., Mol, L., Rampersad, N.: On avoidability of formulas with reversal (Sub-
mitted)
8. Currie, J., Rampersad, N.: Binary words avoiding xxRx and strongly unimodal
sequences. J. Integer Seq. 15, Article 15.10.3 (2015)
9. Currie, J., Rampersad, N.: Growth rate of binary words avoiding xxxR. Theoret.
Comput. Sci. 609, 456–468 (2016)
10. Du, C.F., Mousavi, H., Rowland, E., Schaeﬀer, L., Shallit, J.: Decision algorithms
for Fibonacci-automatic words, II: related sequences and avoidability. Theoret.
Comput. Sci. 657, 146–162 (2017)
11. Gawrychowski, P., I, T., Inenaga, S., K¨oppl, D., Manea, F.: Eﬃciently ﬁnding
all maximal alpha-gapped repeats. In: Proceedings of the STACS, pp. 39:1–39:14
(2016)
12. Gawrychowski, P., Manea, F., Nowotka, D.: Testing generalised freeness of words.
In: Proceedings of the STACS, pp. 337–349 (2014)
13. Kosolobov, D., Manea, F., Nowotka, D.: Detecting unary patterns. ArXiv preprint:
https://arxiv.org/abs/1604.00054
14. Zimin, A.I.: Blocking sets of terms. Math. USSR Sbornik 47(2), 353–364 (1984).
(English translation)

Compressibility and Probabilistic Proofs
Alexander Shen(B)
LIRMM CNRS & University of Montpellier, Montpellier, France
alexander.shen@lirmm.fr
Abstract. We consider several examples of probabilistic existence
proofs using compressibility arguments, including some results that
involve Lov´asz local lemma.
1
Probabilistic Proofs: A Toy Example
There are many well known probabilistic proofs that objects with some proper-
ties exist. Such a proof estimates the probability for a random object to violate
the requirements and shows that it is small (or at least strictly less than 1). Let
us look at a toy example.
Consider a n × n Boolean matrix and its k × k minor (the intersection of k
rows and k columns chosen arbitrarily). We say that the minor is monochromatic
if all its elements are equal (either all zeros or all ones).
Proposition 1. For large enough n and for k = O(log n), there exists a (n×n)-
matrix that does not contain a monochromatic (k × k)-minor.
Proof. We repeat the same simple proof three times, in three diﬀerent languages.
(Probabilistic language) Let us choose matrix elements using independent tosses
of a fair coin. For a given k columns and k rows, the probability of getting a
monochromatic minor at their intersection in 2−k2+1. (Both zero-minor and one-
minor have probability 2−k2.) There are at most nk choices for columns and the
same number for rows, so by the union bound the probability of getting at least
one monochromatic minor is bounded by
nk × nk × 2−k2+1 = 22k log n−k2+1 = 2k(2 log n−k)+1
and the last expression is less then 1 if, say, k = 3 log n and n is suﬃciently large.
(Combinatorial language) Let us count the number of bad matrices. For a given
choice of columns and rows we have 2 possibilities for the minor and 2n2−k2
possibilities for the rest, and there is at most nk choices for raws and columns,
so the total number of matrices with monochromatic minor is
A. Shen—On leave from IITP RAS, Moscow, Russia.
Supported by ANR-15-CE40-0016-01 RaCAF grant.
c
⃝Springer International Publishing AG 2017
J. Kari et al. (Eds.): CiE 2017, LNCS 10307, pp. 101–111, 2017.
DOI: 10.1007/978-3-319-58741-7 11

102
A. Shen
nk × nk × 2 × 2n2−k2 = 2n2+2k log n−k2+1 = 2n2+k(2 log n−k)+1,
and this is less than 2n2, the total number of Boolean (n × n)-matrices.
(Compression language) To specify the matrix that has a monochromatic minor,
it is enough to specify 2k numbers between 1 and n (rows and column numbers),
the color of the monochromatic minor (0 or 1) and the remaining n2 −k2 bits
in the matrix (their positions are already known). So we save k2 bits (compared
to the straightforward list of all n2 bits) using 2k log n + 1 bits instead (each
number in the range 1 . . . n requires log n bits; to be exact, we may use ⌈log n⌉),
so we can compress the matrix with a monochromatic minor if 2k log n+1 ≪k2,
and not all matrices are compressible.
Of course, these three arguments are the same: in the second one we multiply
probabilities by 2n2, and in the third one we take logarithms. However, the
compression language provides some new viewpoint that may help our intuition.
2
A Bit More Interesting Example
In this example we want to put bits (zeros and ones) around the circle in a
“essentially asymmetric” way: each rotation of the circle should change at least
a ﬁxed percentage of bits. More precisely, we are interested in the following
statement (Fig. 1):
Proposition 2. There exists ε > 0 such for every suﬃciently large n there
exists a sequence x0x1 . . . xn−1 of bits such that for every k = 1, 2, . . . , n −1 the
cyclic shift by k positions produces a sequence
y0 = xk, y1 = xk+1, . . . , yn−1 = xk−1,
that diﬀers from x in at least εn positions (the Hamming distance between x and
y is at least εn).
x0 x1 x2
xk
xk+1
xk+2
xn−1
Fig. 1. A string x0 . . . xn−1 is bad if most of the dotted lines connect equal bits

Compressibility and Probabilistic Proofs
103
Proof. Assume that some rotation (cyclic shift by k positions) transforms x into
a string y that coincides almost everywhere with x. We may assume that k ≤n/2:
the cyclic shift by k positions changes as many bits as the cyclic shift by n −k
(the inverse one). Imagine that we dictate the string x from left to right. First k
bits we dictate normally. But then the bits start to repeat (mostly) the previous
ones (k positions before), so we can just say “the same” or “not the same”, and
if ε is small, we know that most of the time we say “the same”. Technically, we
have εn diﬀerent bits, and at least n−k ≥n/2 bits to dictate after the ﬁrst k, so
the fraction of “not the same” signals is at most 2ε. It is well known that strings
of symbols where some symbols appear more often than others can be encoded
eﬃciently. Shannon tells us that a string with two symbols with frequencies p
and q (so p + q = 1) can be encoded using
H(p, q) = p log 1
p + q log 1
q
bits per symbol and that H(p, q) = 1 only when p = q = 1/2. In our case, for
small ε, one of the frequencies is close to 0 (at most 2ε), and the other one is close
to 1, so H(p, q) is signiﬁcantly less than 1. So we get a signiﬁcant compression
for every string that is bad for the theorem, therefore most string are good (so
good string do exist).
More precisely, every string x0 . . . xn−1 that does not satisfy the requirements,
can be described by
– k
[log n bits]
– x0, . . . , xk−1
[k bits]
– xk ⊕x0, xk+1 ⊕x1, . . . , xn−1 ⊕xn−k−1
[n −k bits where the fraction of
1 s is at most 2ε, compressed to (n −k)H(2ε, 1 −2ε) bits]
For ε < 1/4 and for large enough n the economy in the third part (compared to
n −k) is more important than log n in the ﬁrst part.
Of course, this is essentially a counting argument: the number of strings
of length (n −k) where the fraction of 1 s is at most 2ε, is bounded by
2H(2ε,1−2ε)(n−k) and we show that the bound for the number of bad strings,
n/2

k=1
2k2H(2ε,1−2ε)(n−k)
is less than the total number of strings (2n). Still the compression metaphor
makes the proof more intuitive, at least for some readers.
3
Lov´asz Local Lemma and Moser–Tardos Algorithm
In our examples of probabilistic proofs we proved the existence of objects that
have some property by showing that most objects have this property (in other
words, that the probability of this property to be true is close to 1 under some

104
A. Shen
natural distribution). Not all probabilistic proofs go like that. One of the excep-
tions is the famous Lov´asz local lemma (see, e.g., [1]). It can be used in the
situations where the union bound does not work: we have too many bad events,
and the sum of their probabilities exceeds 1 even if probability of each one is
very small. Still Lov´asz local lemma shows that these bad events do not cover
the probability space entirely, assuming that the bad events are “mainly inde-
pendent”. The probability of avoiding these bad events is exponentially small,
still Lov´asz local lemma provides a positive lower bound for it.
This means, in particular, that we cannot hope to construct an object sat-
isfying the requirements by random trials, so the bound provided by Lov´asz
local lemma does not give us a randomized algorithm that constructs the object
with required properties with probability close to 1. Much later Moser and Tar-
dos [4,5] suggested such an algorithm — in fact a very simple one. In other
terms, they suggested a diﬀerent distribution under which good objects form a
majority.
We do not discuss the statement of Lov´asz local lemma and Moser–Tardos
algorithm in general (see [8]). Instead, we provide two examples when they can
be used, and the compression-language proofs that can be considered as ad hoc
versions of Moser–Tardos argument. They are (1) satisﬁability of formulas in
conjunctive normal form (CNF) and (2) strings without forbidden factors.
4
Satisﬁable CNF
A CNF (conjunctive normal form) is a propositional formula that is a conjuction
of clauses. Each clause is a disjunction of literals; a literal is a propositional
variable or its negation. For example, CNF
(¬p1 ∨p2 ∨p4) ∧(¬p2 ∨p3 ∨¬p4)
consists of two clauses. First one prohibits the case when p1 = true, p2 = false,
p4 = false; the second one prohibits the case when p2 = true, p3 = false,
p4 = true. A CNF is satisﬁable if it has a satisfying assigment (that makes all
clauses true, avoiding the prohibited combinations). In our example there are
many satisfying assignments. For example, if p1 = false and p3 = true, all
values of other variables are OK.
We will consider CNF where all clauses include n literals with n diﬀerent
variables (from some pool of variables that may contain much more than n
variables). For a random assignment (each variable is obtained by an independent
tossing of a fair coin) the probability to violate a clause of this type is 2−n (one of
2n combinations of values for n variables is forbidden). Therefore, if the number
of clauses of this type is less than 2n, then the formula is satisﬁable. This is
a tight bound: using 2n clauses with the same variables, we can forbid all the
combinations and get an unsatisﬁable CNF.
The following result says that we can guarantee the satisﬁability for formuli
with much more clauses. In fact, the total number of clauses may be arbitrary
(but still we consider ﬁnite formulas, of course). The only thing we need is the

Compressibility and Probabilistic Proofs
105
“limited dependence” of clauses. Let us say that two clauses are neighbors if
they have a common variable (or several common variables). The clauses that
are not neighbors correspond to independent events (for a random assignment).
The following statement says that if the number of neighbors of each clause is
bounded, then CNF is guaranteed to be satisﬁable.
Proposition 3. Assume that each clause in some CNF contains n literals with
diﬀerent variables and has at most 2n−3 neighbor clauses. Then the CNF is
satisﬁable.
Note that 2n−3 is a rather tight bound: to forbid all the combinations for
some n variables, we need only 2n clauses.
Proof. It is convenient to present a proof using the compression language, as
suggested by Lance Fortnow. Consider the following procedure Fix(C) whose
argument is a clause (from our CNF).
{ C is false }
Fix(C):
Resample(C)
for all C′ that are neighbors of C:
if C′ is false then Fix(C′)
{ C is true; other clauses that were true remain true }
Here Resample(C) is the procedure that assigns fresh random values to all
variables in C. The pre-condition (the ﬁrst line) says that the procedure is called
only in the situation where C is false. The post-condition (the last line) says that
if the procedure terminates, then C is true after termination, and, moreover, all
other clauses of our CNF that were true before the call remain true. (The ones
that were false may be true or false.)
Note that up to now we do not say anything about the termination: note that
the procedure is randomized and it may happen that it does not terminate (for
example, if all Resample calls are unlucky to choose the same old bad values).
Simple observation: if we have such a procedure, we may apply it to all clauses
one by one and after all calls (assuming they terminate and the procedure works
according to the speciﬁcation) we get a satisfying assignment.
Another simple observation: it is easy to prove the “conditional correctness”
of the procedure Fix(C). In other words, it achieves its goal assuming that (1) it
terminates; (2) all the recursive calls Fix(C′) achieve their goals. It is almost
obvious: the Resample(C) call may destroy (=make false) only clauses that are
neighbors to C, and all these clauses are Fix-ed after that. Note that C is its
own neighbor, so the for-loop includes also a recursive call Fix(C), so after all
these calls (that terminate and satisfy the post-condition by assumption) the
clause C and all its neighbors are true and no other clause is damaged.

106
A. Shen
Note that the last argument remains valid even if we delete the only line
that really changes something, i.e., the line Resample(C). In this case the pro-
cedure never changes anything but still is conditionally correct; it just does not
terminate if one of the clauses is false.
It remains to prove that the call Fix(C) terminates with high probability.
In fact, it terminates with probability 1 if there are no time limits and with
probability exponentially close to 1 in polynomial time. To prove this, one may
use a compression argument: we show that if the procedure works for a long
time without terminating, then the sequence of random bits used for resampling
is compressible. We assume that each call of Resample() uses n fresh bits from
the sequence. Finally, we note that this compressibility may happen only with
exponentially small probability.
Imagine that Fix(C) is called and during its recursive execution performs
many calls
Resample(C1), . . . , Resample(CN)
(in this order) but does not terminate (yet). We stop it at some moment and
examine the values of all the variables.
Lemma 1. Knowing the values of the variables after these calls and the sequence
C1, . . . , CN, we can reconstruct all the Nn random bits used for resampling.
Proof. Let us go backwards. By assumption we know the values of all variables
after the calls. The procedure Resample(CN) is called only when CN is false,
and there is only one n-tuple of values that makes CN false. Therefore we know
the values of all variables before the last call, and also know the random bits used
for the last resampling (since we know the values of variables after resampling).
The same argument shows that we can reconstruct the values of variables
before the preceding call Resample(CN−1), and random bits used for the resam-
pling in this call, etc.
Now we need to show that the sequence of clauses C1, . . . , CN used for resam-
pling can be described by less bits than nN (the number of random bits used).
Here we use the assumption saying each clause has at most 2n−3 neighbors and
that the clauses C′ for which Fix(C′) is called from Fix(C), are neighbors of C.
One could try to say that since Ci+1 is a neighbor of Ci, we need only n −3
bits to specify it (there are at most 2n−3 neighbors by assumption), so we save
3 bits per clause (compared to n random bits used by resampling). But this
argument is wrong: Ci+1 is not always the neighbor of Ci, since we may return
from a recursive call that causes resampling of Ci and then make a new recursive
call that resamples Ci+1.
To get a correct argument, we should look more closely at the tree of recursive
calls generated by one call Fix(C) (Fig. 2). In this tree the sons of each vertex
correspond to neighbor clauses of the father-clause. The sequence of calls is
determined by a walk in this tree, but we go up and down, not only up (as we
assumed in the wrong argument). How many bits we need to encode this walk
(and therefore the sequence of calls)? We use one bit to distinguish between steps

Compressibility and Probabilistic Proofs
107
C1
C2
C3
C4
C5
C6
C7
C8
C9
Fig. 2. The tree of recursive calls for Fix(C1) (up to some moment)
up and down. If we are going down, no other information is needed. If we are
going up (and resample a new clause), we need one bit to say that we are going
up, and n −3 bits for the number of neighbor we are going to. For accounting
purposes we combine these bits with a bit needed to encode the step back (this
may happen later or not happen at all), and we see that in total we need at
most (n −3) + 1 + 1 = n −1 bits per each resampling. This is still less than n,
so we save one bit for each resampling. If N is much bigger than the number of
variables, we indeed compress the sequence of random bits used for resampling,
and this happens with exponentially small probability.
This argument ﬁnishes the proof.
5
Tetris and Forbidden Factors
The next example is taken from word combinatorics. Assume that a list of binary
strings F1, . . . , Fk is given. These Fi are considered as “forbidden factors”: this
means that we want to construct a (long) string X that does not have any of
Fi as a factor (i.e., none of Fi is a substring of X). This may be possible or not
depending on the list. For example, if we consider two strings 0, 11 as forbidden
factors, every string of length 2 or more has a forbidden factor (we cannot use
zeros at all, and two ones are forbidden).
The more forbidden factors we have, the more chances that they block the
growth in the sense that every suﬃciently long string has a forbidden factor.
Of course, not only the number of factors matters: e.g., if we consider 0, 00 as
forbidden factors, then we have long strings of ones without forbidden factors.
However, now we are interested in quantitative results of the following type: if
the number of forbidden factors of length j is aj, and the numbers aj are “not
too big”, then there exists an arbitrarily long string without forbidden factors.

108
A. Shen
This question can be analyzed with many diﬀerent tools, including Lov´asz
local lemma (see [9]) and Kolmogorov complexity. Using a complexity argument,
Levin proved that if aj = 2αj for some constant α < 1, then there exists a
constant M and an inﬁnite sequence that does not contain forbidden factors of
length smaller than M. (See [10, Sect. 8.5] for Levin’s argument and other related
results.) A nice suﬃcient condition was suggested by Miller [3]: we formulate the
statement for the arbitrary alphabet size.
Proposition 4. Consider an alphabet with m letters. Assume that for each
j ≥2 we have aj “forbidden” strings of length j. Assume that there exist some
constant x > 0 such that

j≥2
ajxj < mx −1
Then there exist arbitrarily long strings that do not contain forbidden substrings.
Remarks. 1. We do not consider j = 1, since this means that some letters are
deleted from the alphabet.
2. By compactness the statement implies that there exists an inﬁnite sequence
with no forbidden factors.
3. The constant x should be at least 1/m, otherwise the right hand side is
negative. This means that aj/mj should be small, and this corresponds to our
intuition (aj should be signiﬁcantly less than mj, the total number of strings of
length j).
The original proof from [3] uses some ingenious potential function deﬁned on
strings: Miller shows that if its value is less than 1, then one can add some letter
preserving this property. It turned out (rather mysteriously) that exactly the
same condition can be obtained by a completely diﬀerent compression argument
(following [2,6]), so probably the inequality is more fundamental than it may
seem! (It appears once more in Golod – Shafarevich theorem that provides yet
another proof for the same statement; we do not go into details here, see, e.g., [7].)
Proof. Here is the idea of the compression argument. We start with an empty
string and add randomly chosen letters to its right end. If some forbidden string
appears as a suﬃx, it is immediately deleted. So forbidden strings may appear
only as suﬃxes, and only for a short time. After this “backtracking” we continue
adding new letters. (This resembles the famous “tetris game” when blocks fall
down and then disappear under some conditions.)
We want to show that if this process is unsuccessful in the sense that after
many steps we still have a short string, then the sequence of added random
letters is compressible, so this cannot happen always, and therefore a long string
without forbidden factors exists. Let us consider a “record” (log ﬁle) for this
process that is a sequence of symbols “+” and “+⟨deleted string⟩” (for each
forbidden string we have a symbol, plus one more symbol without a string).
If a letter was added and no forbidden string appears, we just add ‘+’ to the
record. If we have to delete some forbidden string s after a letter was added, we

Compressibility and Probabilistic Proofs
109
write this string in brackets after the + sign. Note that we do not record the
added letters, only the deleted substrings. (It may happen that several forbidden
suﬃxes appear; in this case we may choose any of them.)
Lemma 2. At every stage the current string and the record uniquely determine
the sequence of random letters used.
Proof. Having this information, we can reconstruct the conﬁguration going back-
wards. This reversed process has steps where a forbidden string is added (and
we know which one, since it is written in brackets in the record), and also steps
when a letter is deleted (and we know which letter is deleted, i.e., which random
letter was added when moving forwards).
If after many (say, T) steps we still have a short current string, then the
sequence of random letters can be described by the record (due to the Lemma;
we ignore the current string part since it is short). As we will see, the record
can be encoded with less bits than it should have been (i.e., less than T log m
bits). Let us describe this encoding and show that it is eﬃcient (assuming the
inequality  ajxj < mx −1).
We use arithmetic encoding for the lengths. Arithmetic encoding for M sym-
bols starts by choosing positive reals q1, . . . , qM such that q1 + . . . + qM = 1.
Then we split the interval [0, 1] into parts of length q1, . . . , qM that correspond
to these M symbols. Adding a new symbol corresponds to splitting the current
interval in the same proportion and choosing the right subinterval. For example,
the sequence (a, b) corresponds to bth subinterval of ath interval; this inter-
val has length qaqb. The sequence (a, b, . . . , c) corresponds to interval of length
qaqb . . . qc and can be reconstructed given any point of this interval (assuming
q1, . . . , qM are ﬁxed); to specify some binary fraction in this interval we need at
most −log(qaqb . . . qc)+O(1) bits, i.e., −log qa −log qb −. . .−log qc +O(1) bits.
Now let us apply this technique to our situation. For + without brackets we
use log(1/p0) bits, and for +⟨s⟩where s is of length j, we use log(1/pj) + log aj
bits. Here pj are some positive reals to be chosen later; we need p0 +  pj = 1.
Indeed, we may split pj into aj equal parts (of size pj/aj) and use these parts
as qs in the description of arithmetical coding above; splitting adds log aj to the
code length for strings of length j.
To bound the total number of bits used for encoding the record, we perform
amortised accounting and show that the average number of bits per letter is less
than log m. Note that the number of letters is equal to the number of + signs
in the record. Each + without brackets increases the length of the string by one
letter, and we want to use less that log m −c bits for its encoding, where c > 0
is some constant saying how much is saved as a reserve for amortized analysis.
And +⟨s⟩for a string s of length j decreases the length by j −1, so we want to
use less than log m + c(j −1) bits (using the reserve).
So we need:
log(1/p0) < log m −c;
log(1/pj) + log aj < log m + c(j −1)

110
A. Shen
together with
p0 +

j≥2
pj = 1.
Technically is it easier to use non-strict inequalities in the ﬁrst two cases and
a strict one in the last case (and then increase pi a bit):
log(1/p0) ≤log m −c; log(1/pj) + log aj ≤log m + c(j −1); p0 +

j≥2
pj < 1.
Then for a given c we take minimal possible pi:
p0 =
1
m2−c
pj = aj(2−c)j
m2−c
and it remains to show that the sum is less than 1 for a suitable choice of c. Let
x = 2−c, then the inequality can be rewritten as
1
mx +

j≥2
ajxj
mx < 1,
or

j≥2
ajxj < mx −1,
and this is our assumption.
Now we see the role of this mystical x in the condition: it is just a parameter
that determines the constant used for the amortised analysis.
Acknowledgement. Author thanks his LIRMM colleagues, in particular Pascal
Ochem and Daniel Gon¸calves, as well as the participants of Kolmogorov seminar in
Moscow.
References
1. Alon, N., Spencer, J.H.: The Probabilistic Method. Wiley, New York (2004)
2. Gon¸calves, D., Montassier, M., Pinlou, A.: Entropy compression method applied
to graph colorings. https://arxiv.org/pdf/1406.4380.pdf
3. Miller, J.: Two notes on subshifts. Proc. AMS 140, 1617–1622 (2012)
4. Moser, R.: A constructive proof of the Lov´asz local lemma. https://arxiv.org/abs/
0810.4812
5. Moser, R., Tardos, G.: A constructive proof of the general Lov´asz local lemma. J.
ACM 57(2), 11.1–11.15 (2010)
6. Ochem, P., Pinlou, A.: Application of entropy compression in pattern avoidance.
Electron. J. Comb. 21(2), paper P2.7 (2014)
7. Rampersad, N.: Further applications of a power series method for pattern avoid-
ance. https://arxiv.org/pdf/0907.4667.pdf
8. Rumyantsev, A., Shen, A.: Probabilistic constructions of computable objects and
a computable version of Lov´asz local lemma. Fundam. Informaticae 132, 1–14
(2013). https://arxiv.org/abs/1305.1535

Compressibility and Probabilistic Proofs
111
9. Rumyantsev, A.Y., Ushakov, M.A.: Forbidden substrings, Kolmogorov complex-
ity and almost periodic sequences. In: Durand, B., Thomas, W. (eds.) STACS
2006. LNCS, vol. 3884, pp. 396–407. Springer, Heidelberg (2006). doi:10.1007/
11672142 32
10. Shen, A., Uspensky, V.A., Vereshchagin, N.: Kolmogorov complexity and algo-
rithmic randomness, to be published by the AMS (2013). www.lirmm.fr/∼ashen/
kolmbook-eng.pdf. Russian version published by MCCME (Moscow)

Delayed-Input Cryptographic Protocols
Ivan Visconti(B)
DIEM, University of Salerno, Fisciano, Italy
visconti@unisa.it
Abstract. The delayed-input witness-indistinguishable proof of knowl-
edge of Lapidot and Shamir (LS) [CRYPTO 1989] is a powerful tool for
designing round-eﬃcient cryptographic protocols. Since LS was designed
for the language of Hamiltonian graphs, when used as subprotocol it
usually requires expensive NP reductions.
We ﬁrst overview how LS works, how it can be used to obtain round-
eﬃcient protocols as shown by Ostrovsky and Visconti [ECCC 2012] and
why it suﬀers of intrinsic eﬃciency limitations.
Then we will overview some recent advances on delayed-input crypto-
graphic protocols and their applications. We will in particular consider
the eﬃcient witness-indistinguishable proofs of knowledge of Ciampi,
Persiano, Scafuro, Siniscalchi and Visconti [TCC 2016a, Eurocrypt
2016], and the round-eﬃcient non-malleable commitments of Ciampi,
Ostrovsky, Siniscalchi and Visconti [Crypto 2016, Eprint 2016].
1
Introduction
Cryptographic protocols are designed to securely implement useful functionali-
ties with the goal of preserving data privacy against adversarial behaviors.
The traditional setting assumes that inputs that are relevant for the compu-
tation are already known to players when a cryptographic protocol starts. As
a consequence, external protocols require more communication rounds since the
task of obtaining data and the task of using the same data in a subprotocol are
not parallelizable.
Delayed-input cryptographic protocols. In contrast to the traditional paradigm,
Lapidot and Shamir (LS) [14] proposed a 3-round witness-indistinguishable proof
of knowledge (WIPoK) where the input is not needed until the last round is
played. Their approach works for the language of Hamiltonian Graphs and there-
fore can be used for any NP language at the cost of expensive NP reductions. The
security of LS is maintained even in case the adversarial veriﬁer (resp., prover)
chooses the inputs adaptively in the ﬁrst (resp., second) round.
2
Applications of LS
The delayed-input feature of LS has been used multiple times in literature.
Notable examples are [10,13] that were among the ﬁrst papers making crucial
c
⃝Springer International Publishing AG 2017
J. Kari et al. (Eds.): CiE 2017, LNCS 10307, pp. 112–115, 2017.
DOI: 10.1007/978-3-319-58741-7 12

Delayed-Input Cryptographic Protocols
113
use of the delayed-input property of LS to obtain some round-optimal construc-
tions. Whenever round eﬃciency was desired, LS has been critically used several
times in subsequent work (e.g., [2–4,9,11,12,15,17,18]).
A detailed description of LS is available in [16] where the use of LS allowed
to reduce to 6 the number of rounds of the public-coin non-black-box zero-
knowledge argument system of Barak [1], then obtaining a 7-round resettable
witness-indistinguishable argument system.
Round-eﬃcient non-malleable commitments.
Recently, Ciampi et al. in [4]
showed how to use LS to obtain a 3-round concurrent non-malleable commit-
ment scheme. The key idea in their construction consists of executing a regular
(i.e., potentially malleable) non-interactive commitment c and a 3-round (non-
concurrent) non-malleable commitment c′. Moreover the receiver sends a puzzle
in the second round. Then, LS is used to prove knowledge of either the message
committed in c or of a solution of the puzzle that is committed in c′. Notice
that since all the above protocols are played in parallel, c and c′ are well deﬁned
only during the 3rd round. As such, the delayed-input property of LS is cru-
cial in order to give the above proof of knowledge without penalizing the round
complexity.
While the above result relies on the use of superpolynomial hardness assump-
tions, more recently, Ciampi et al. have shown in [3] how to rely on standard
one-way functions only, at the price of adding one more round. LS is used again to
guarantee knowledge of inputs used in some other subprotocols that are played
in parallel. Therefore the delayed-input property is again essential.
3
Limits of LS and Recent Improvements
A major limit in the use of LS is that an NP reduction to the language of
Hamiltonian graphs is required in order to run LS. As such, the use of LS is
limited to feasibility results and has limited impact on practical constructions.
The limits of LS have been recently bypassed by new eﬃcient constructions
of 3-round WIPoKs for languages useful in practice. The ﬁrst construction was
given by Ciampi et al. in [5] and guarantees unconditionally some partial delayed-
input property. Instead, a more recent construction of Ciampi et al. [6] allows
to obtain 3-round delayed-input WIPoKs for languages useful in practice, at the
cost of relying on the standard Decisional Diﬃe-Hellman (DDH) assumption.
Both constructions make use of some special properties of Σ-protocols [8] and
propose some interesting new techniques that extend the applicability of the well
known OR-composition of Cramer et al. [7].
The unconditional construction of [5]. Ciampi et al. in [5] showed how to compose
two Σ-protocols for two inputs x0 and x1 so that the resulting Σ-protocol can be
run without requiring knowledge of both x0 and x1 in advance (knowledge of one
of them suﬃces to start the protocol). The key idea of their construction consists
in the following two main observations: (1) the commonly used Σ-protocols do

114
I. Visconti
not need the instance when the protocol starts; (2) one can get a instance-
dependent trapdoor commitment from a Σ-protocol. By carefully combining
these two observations they show (unconditionally) a Σ-protocol that is an OR-
composition of two Σ-protocols such that only one out of x0 and x1 is required
when the protocol starts. This property is not enjoyed by the well known OR-
composition techniques of Cramer et al. [7].
The DDH-based construction of [6]. Ciampi et al. in [6] showed delayed-input
eﬃcient WIPoKs by combining Σ-protocols with a speciﬁc instance-dependent
trapdoor commitment for the language of Diﬃe-Hellman tuples. The proposed
construction is extremely powerful since no input is required when the protocol
starts, and the prover can prove knowledge of witnesses for at least k instances
out of n instances. This result therefore matches in large part the composition
power of [7] giving however the delayed-input property, at the price of relying
on the standard DDH assumption.
Acknowledgments. I thank my coauthors Michele Ciampi, Rafail Ostrovsky,
Giuseppe Persiano, Alessandra Scafuro and Luisa Siniscalchi for the good time that
we have spent together working on delayed-input cryptographic protocols. I also thank
Helger Lipmaa for valuable comments on a preliminary version of this paper. This work
has been supported in part by “GNCS - INdAM”, in part by University of Salerno
through grants FARB-2014/2015 and in part by the EU COST Action IC1306.
References
1. Barak, B.: How to go beyond the black-box simulation barrier. In: 42nd Annual
Symposium on Foundations of Computer Science, FOCS 2001, 14–17 October, Las
Vegas, Nevada, USA, pp. 106–115. IEEE Computer Society (2001)
2. Chung, K.-M., Ostrovsky, R., Pass, R., Venkitasubramaniam, M., Visconti, I.: 4-
round resettably-sound zero knowledge. In: Lindell, Y. (ed.) TCC 2014. LNCS, vol.
8349, pp. 192–216. Springer, Heidelberg (2014). doi:10.1007/978-3-642-54242-8 9
3. Ciampi, M., Ostrovsky, R., Siniscalchi, L., Visconti, I.: 4-round concurrent non-
malleable commitments from one-way functions. IACR Cryptology ePrint Archive
2016, 621 (2016). http://eprint.iacr.org/2016/621
4. Ciampi, M., Ostrovsky, R., Siniscalchi, L., Visconti, I.: Concurrent non-malleable
commitments (and more) in 3 rounds. In: Robshaw, M., Katz, J. (eds.) CRYPTO
2016. LNCS, vol. 9816, pp. 270–299. Springer, Heidelberg (2016). doi:10.1007/
978-3-662-53015-3 10
5. Ciampi, M., Persiano, G., Scafuro, A., Siniscalchi, L., Visconti, I.: Improved
OR-composition of sigma-protocols. In: Kushilevitz, E., Malkin, T. (eds.) TCC
2016. LNCS, vol. 9563, pp. 112–141. Springer, Heidelberg (2016). doi:10.1007/
978-3-662-49099-0 5
6. Ciampi, M., Persiano, G., Scafuro, A., Siniscalchi, L., Visconti, I.: Online/
oﬄine OR composition of sigma protocols. In: Fischlin, M., Coron, J.-S. (eds.)
EUROCRYPT 2016. LNCS, vol. 9666, pp. 63–92. Springer, Heidelberg (2016).
doi:10.1007/978-3-662-49896-5 3

Delayed-Input Cryptographic Protocols
115
7. Cramer, R., Damg˚ard, I., Schoenmakers, B.: Proofs of partial knowledge and
simpliﬁed design of witness hiding protocols. In: Desmedt, Y.G. (ed.) CRYPTO
1994. LNCS, vol. 839, pp. 174–187. Springer, Heidelberg (1994). doi:10.1007/
3-540-48658-5 19
8. Damg˚ard, I.: On Σ-protocols (2010). http://www.cs.au.dk/∼ivan/Sigma.pdf
9. Crescenzo, G., Persiano, G., Visconti, I.: Constant-round resettable zero knowledge
with concurrent soundness in the bare public-key model. In: Franklin, M. (ed.)
CRYPTO 2004. LNCS, vol. 3152, pp. 237–253. Springer, Heidelberg (2004). doi:10.
1007/978-3-540-28628-8 15
10. Crescenzo, G., Persiano, G., Visconti, I.: Improved setup assumptions for 3-round
resettable zero knowledge. In: Lee, P.J. (ed.) ASIACRYPT 2004. LNCS, vol. 3329,
pp. 530–544. Springer, Heidelberg (2004). doi:10.1007/978-3-540-30539-2 37
11. Goyal, V., Richelson, S., Rosen, A., Vald, M.: An algebraic approach to non-
malleability. In: 55th IEEE Annual Symposium on Foundations of Computer Sci-
ence, FOCS 2014, Philadelphia, PA, USA, 18–21 October, pp. 41–50 (2014)
12. Hazay, C., Venkitasubramaniam, M.: On the power of secure two-party compu-
tation. In: Robshaw, M., Katz, J. (eds.) CRYPTO 2016. LNCS, vol. 9815, pp.
397–429. Springer, Heidelberg (2016). doi:10.1007/978-3-662-53008-5 14
13. Katz, J., Ostrovsky, R.: Round-optimal secure two-party computation. In:
Franklin, M. (ed.) CRYPTO 2004. LNCS, vol. 3152, pp. 335–354. Springer,
Heidelberg (2004). doi:10.1007/978-3-540-28628-8 21
14. Lapidot, D., Shamir, A.: Publicly veriﬁable non-interactive zero-knowledge proofs.
In: Menezes, A.J., Vanstone, S.A. (eds.) CRYPTO 1990. LNCS, vol. 537, pp. 353–
365. Springer, Heidelberg (1991). doi:10.1007/3-540-38424-3 26
15. Mittelbach, A., Venturi, D.: Fiat–shamir for highly sound protocols is instantiable.
In: Zikas, V., Prisco, R. (eds.) SCN 2016. LNCS, vol. 9841, pp. 198–215. Springer,
Cham (2016). doi:10.1007/978-3-319-44618-9 11
16. Ostrovsky, R., Visconti, I.: Simultaneous resettability from collision resistance.
Electronic Colloquium on Computational Complexity (ECCC) 19, 164 (2012)
17. Wee, H.: Black-box, round-eﬃcient secure computation via non-malleability ampli-
ﬁcation. In: 51th Annual IEEE Symposium on Foundations of Computer Science,
FOCS 2010, 23–26 October, Las Vegas, Nevada, USA, pp. 531–540. IEEE Com-
puter Society (2010)
18. Yung, M., Zhao, Y.: Generic and practical resettable zero-knowledge in the bare
public-key model. In: Naor, M. (ed.) EUROCRYPT 2007. LNCS, vol. 4515, pp.
129–147. Springer, Heidelberg (2007). doi:10.1007/978-3-540-72540-4 8

Contributed Papers

A Deterministic Algorithm for Testing
the Equivalence of Read-Once Branching
Programs with Small Discrepancy
Stefan Arnold and Jacobo Tor´an(B)
Institute of Theoretical Computer Science, University of Ulm, Ulm, Germany
{stefan.arnold,jacobo.toran}@uni-ulm.de
Abstract. The problem to test the equivalence of two given read-once
branching programs is a well-known problem in the class BPP that is not
known to be solvable in deterministic polynomial time. The standard
probabilistic algorithm to solve the problem reduces it to an instance
of Polynomial Identity Testing and then applies the Schwartz-Zippel
Lemma to test the equivalence. This method needs O(n log n) random
bits, where n is the number of variables in the branching programs. We
provide a new method for testing the equivalence of read-once branching
programs that uses O(log n + log |D|) random bits, where D is the set
of assignments for which the two branching programs compute diﬀerent
results. This means O(n) random bits in the worst case and a determin-
istic polynomial time algorithm when the discrepancy set D is at most
polynomial.
We also show that the equivalence test can be extended to the more
powerful model of deterministic, decomposable negation normal forms
(d-DNNFs).
1
Introduction
Branching programs (also known as binary decision diagrams, BDDs) are a well-
known model of computation used for the representation of Boolean functions.
A branching program consists of a directed acyclic graph with one start vertex
and two output vertices labeled by 0 and 1. All the inner vertices are labeled by
variables xi and have two outgoing edges, one for the case xi = 0 and the other
one for xi = 1. A branching program computes a Boolean function in a natural
way by starting at the start vertex, querying the variables that label the vertices
and following the edges according to the values of the queried variables until
the output-0 or the output-1 vertex is reached. Branching programs have many
applications in areas like computer-aided design, model checking, or formal ver-
iﬁcation. This is due to the fact that their expressive power lies between those
of formulas and Boolean circuits, which allows on one hand compact represen-
tations for many Boolean functions and on the other hand eﬀective algorithms
for several logical operations (see e.g. [19]). Certain fundamental problems on
this model, like testing the equivalence of two programs, are however intractable.
c
⃝Springer International Publishing AG 2017
J. Kari et al. (Eds.): CiE 2017, LNCS 10307, pp. 119–128, 2017.
DOI: 10.1007/978-3-319-58741-7 13

120
S. Arnold and J. Tor´an
Because of this fact more restricted models like read-once branching programs
(ROBPs; also called free BDDs) [13] and ordered binary decision diagrams
(OBDDs) [3] have been introduced. A ROBP is a branching program with the
additional property that in every path from the start vertex to an output vertex,
each variable is queried at most once. An OBDD is a restricted type of ROBP
in which for some permutation of the variables, in every path from start to out-
put, the variables are queried in a relative order consistent with the permutation.
There are explicit examples of Boolean functions for which the size of the ROBP
model is exponentially larger than that of a general branching program, or the
size of an OBDD is exponentially larger than that of a ROBP (see [19]). On
the other hand, the equivalence of two OBDDs [3] (and even the equivalence
of an OBDD and a ROBP [10]) can be tested deterministically in polynomial
time, while there is a randomized polynomial time algorithm for testing whether
two ROBPs are equivalent [2]. In fact, equivalence testing for read-once branch-
ing programs is one of the few natural problems solvable in BPP (bounded error
probabilistic polynomial time) but not known to be in P. As such a rare example
it is often mentioned in complexity theory courses and appears in introductory
books in the area [16,18]. Wegener conjectured that the problem is not in P ([19]
pg. 144).
The probabilistic algorithm for the equivalence of ROBPs from Blum, Chan-
dra, and Wegman [2] arithmetizes the branching programs, transforming them
into multilinear polynomials that coincide on all 0–1 inputs if and only if the
programs are equivalent. Since the polynomials are multilinear, evaluated over
any ﬁeld (not only over Fn
2) they coincide for any possible input exactly when the
branching programs compute the same function. To test equivalence one just has
to evaluate both polynomials over randomly chosen points from a large enough
ﬁeld, as shown by the Schwartz-Zippel Lemma [17,20]. In order to guarantee a
constant error probability the algorithm needs O(n log n) random bits, where n
is the number of variables of the branching programs.
In this paper we introduce a diﬀerent probabilistic algorithm for testing the
equivalence of ROBPs that uses less random bits than the algorithm in [2]. Our
algorithm can be seen as a partial derandomization. Let f and g: {0, 1}n →
{0, 1} be the functions computed by the two given branching programs, and let
D be the discrepancy of the programs: D = {x ∈{0, 1}n | f(x) ̸= g(x)}. Observe
that |D| can take any value between 0 and 2n. Our algorithm uses O(log n +
log |D|) random bits (if |D| is given). In the worst case, the number of random
bits needed is O(n). This also implies a deterministic polynomial equivalence
test when both branching programs compute functions that cannot be too far
from each other (at most polynomial size discrepancy). Similar derandomization
results for situations in which the search space is small have been obtained for
other problems. For example, for the perfect matching problem, which can be
computed in randomized NC but is not known to be in deterministic NC, there
are deterministic NC algorithms that solve the problem when the number of
perfect matchings is bounded by a polynomial [1,11].

Equivalence Test of Read-Once Branching Programs with Small Discrepancy
121
Our algorithm has two basic ingredients. First, it uses the fact that in the
ROBP model it is possible to compute eﬃciently the number of assignments that
lead to a certain vertex in the program. The second component needed to reduce
the number of probabilistic choices is the randomness-eﬃcient Isolating Lemma
from [4]. The algorithm randomly assigns weights in a restricted range to the
Boolean variables of a read-once branching program. It transforms this program
into a diﬀerent one which accepts only the assignments that are accepted by the
ﬁrst program and have a certain weight. If two input programs are equivalent,
then, for any weight function and for every possible weight, they must have the
same number of accepting assignments with such a weight. Using the Isolating
Lemma we show that with high probability there will be a unique element of
minimum weight in the discrepancy set D. This implies that the number of
accepting assignments having this weight in both programs has to be diﬀerent
if D ̸= ∅(the number of assignments with this weight that are not in D is the
same for both programs). This fact is then checked using the counting properties
of the ROBP model.
It has been observed in the literature that the equivalence test for ROBPs
from [2] can be extended to the more powerful computation model of determin-
istic decomposable negation normal forms (d-DNNFs) [9]. We show in Sect. 4
that this is also true for our algorithm, by proving that the same bounds for the
number of random bits can be achieved for testing the equivalence of d-DNNFs.
For this we show that as in the ROBP model, it is possible to count in poly-
nomial time the number of satisfying assignments having a certain weight for a
given d-DNNF.
2
Preliminaries
We denote by B = {0, 1} the set of Boolean values. For an arbitrary set S we
write P(S) for the power set of S. By δx,y we denote the Kronecker delta for
arbitrary numbers x and y, that is, we set δx,y = 1 if x = y and δx,y = 0
otherwise.
Deﬁnition 1 (Branching program [14,19]). A branching program (BP) on the
variable set Xn = {x1, . . . , xn} consists of a directed acyclic graph whose inner
nodes have outdegree 2, and a labeling of the nodes and edges. This graph has a
distinguished node, called the source, which has indegree 0, and two sinks with
outdegree 0, each one labeled with an element from B. The inner nodes get labels
from Xn. For each inner node, one of the outgoing edges gets the label 0 and the
other one gets the label 1.
A branching program computes a function f : Bn →B by following for each
input a = a1a2 . . . an ∈Bn a path from the source to a sink, taking at every
node labeled by xi the outgoing edge labeled by ai. The function value f(a) is
the label of the sink that is ﬁnally reached.
Input strings a ∈Bn will also be called assignments throughout this paper.
For a branching program A and an assignment a, A(a) denotes the result of
applying A on a. |A| is the number of nodes in program A.

122
S. Arnold and J. Tor´an
In the next section, we will consider an easy extension of the branching
program model that can be used for computing functions f : Bn →R for any
ﬁnite range R, by allowing a sink node for every element in R.
Read-once BPs are a restricted form of BPs introduced by Masek [13].
Deﬁnition 2 (Read-once BP). A read-once BP (ROBP) is a BP where, for
each i, each path from the input vertex to any of the output vertices contains at
most one node labeled by xi.
In a ROBP it is impossible to construct an inconsistent path from source
to sink, i.e., a path according to which a variable would get values 0 and 1
simultaneously. This fact makes it possible to test eﬃciently some properties in
the ROBP model. For example, the question of whether there is some assignment
for which the function computed by the program evaluates to 1 (satisﬁability
test) is just a reachability question between the source and the 1-labeled sink
in the graph of the ROBP. Also it is possible to count in polynomial time the
number of assignments for which the program evaluates to 1. This is a well-
known fact. For self-containedness and because this result plays an important
role in our algorithm, we sketch a proof of it.
Lemma 3. There is a polynomial time algorithm that on input a ROBP for a
function f : Bn →B computes the number |{a ∈Bn | f(a) = 1}| of assignments
for which the function evaluates to 1.
Proof. Observe that it is not suﬃcient to count the number of paths leading to
the output-1 vertex since a path does not have to include all the variables and
can therefore correspond to more than one assignment.
We describe an algorithm that computes for each vertex v of the ROBP the
number n(v) of assignments that lead to it. Note that for any inner node v of
the ROBP, exactly half of the assignments leading from the source to v will
follow the outgoing edge of v labeled by 0, and the remaining half will follow
the outgoing edge labeled by 1. The algorithm ﬁrst ﬁnds a topological ordering
v1, . . . , vn of the vertices in the graph. Clearly for the source v1, n(v1) = 2n. The
algorithms visits the remaining nodes according to the topological ordering, such
that a node vi is visited only after each of its parents has been visited. Suppose
that vi has k incoming edges and these edges come from nodes vi1, . . . , vik. Then
n(vi) is the sum of numbers assigned to vi1, . . . , vik, divided by two: n(vi) =
(n(vi1) + · · · + n(vik))/2. This is because for each predecessor vij of vi, only half
of the assignments reaching vij follow each edge leaving vij. (If a predecessor
has two edges leading to vi, then it is automatically counted twice in the sum).
The algorithm returns n(s1) for the sink vertex s1 labeled by 1.
It follows by induction that the algorithm correctly computes the number
of assignments leading to any node in the ROBP and consequently returns the
correct result. A topological ordering of the nodes can be found in time linear
in the number of nodes and edges. Note that the total number of operations to
compute all the numbers n(v) is also linear in the number of nodes and edges. ⊓⊔

Equivalence Test of Read-Once Branching Programs with Small Discrepancy
123
3
An Algorithm for Testing the Equivalence of ROBPs
The algorithm is based on the following well-known Isolation Lemma from [4],
which uses less randomness than the original one from [15]. Let S = {x1, . . . , xn}
be a ﬁnite set. A weight function w for S is a function that assigns nonnegative
integer weights in a certain range to the elements of S. Such a function can be
extended to any subset I ⊆S by deﬁning w(I) = 
xi∈I w(xi). Let F ⊆P(S) be
a family of subsets of S. We call the pair (S, F) a set system. The lemma states
that for any set system (S, F) there is a polynomial-time method for choosing
the weight function w randomness-eﬃciently such that with high probability
there is a unique subset of S in F with minimum weight under w.
Lemma 4. (Generalized Isolating Lemma [4]) There is a randomized scheme
that for a set system (S, F), with |S| = n and |F| bounded from above by t,
computes a weight function w: S →[0, n7] such that with probability at least 1/4
there is a unique minimum weight set under w in F. The input for the scheme
consists of the two numbers n and t. The scheme needs O(log n + log t) random
bits and runs in time polynomial in n and log t.
We next show that the following problem can eﬃciently be solved: Given a
ROBP computing a function f and a weight function assigning values within a
polynomial range to the variables of the program, count the number of assign-
ments a that have a certain weight and fulﬁll f(a) = 1. For this we consider a
variation on the ROBP model in which in addition to the 0 and 1 sink vertices,
more output vertices (taking care of the diﬀerent possible weights) are allowed.
For simplicity we will refer to this model also as a ROBP.
Lemma 5. There is an algorithm that on input a ROBP A with variables Xn =
{x1, . . . , xn}, computing a function f : Bn →B, and a weight function w: Xn →
{0, . . . , m} transforms A into a new ROBP Aw with output vertices 0 and 1k
for k ∈{0, . . . , mn} such that for any k, the set of assignments reaching vertex
1k in Aw is exactly the set of assignments x with f(x) = 1 and w(x) = k. The
running time of this algorithm is polynomial in |A| and m.
Proof. Observe that the set of possible weights under w that an assignment can
get is a subset of {0, . . . , mn}. The ROBP Aw is constructed from A in the
following way: For the start vertex s in A we provide one start vertex s′ in Aw.
For every vertex v ̸= s in A we provide mn + 1 vertices v0, . . . , vmn, one for
each possible weight. Later, some of these vertices might not be reachable and
can be deleted. For any inner node v in A labeled with a variable xi and any
edge e = (v, u), we include in Aw the set of edges {(vk, uk) | 0 ≤k ≤mn}
if e is labeled by 0; if it is labeled by 1, we include {(vk, uk+j) | 0 ≤k ≤
mn, j = w(xi) and k +j ≤mn}. In this way, the branching program Aw mirrors
the behavior of A but additionally the set of paths reaching a vertex vk in Aw
corresponds to partial assignments having weight exactly k under w. Observe
that in the deﬁnition of the edges in Aw we do not need to include any edge
leading to a vertex with weight more than mn because no assignment can have

124
S. Arnold and J. Tor´an
such a weight. Finally, for any k ∈{0, . . . , mn} the copy 1k in Aw of the output-
1 node in A corresponds to the set of assignments a ∈Bn with f(a) = 1 and
w(a) = k.
The number of vertices of the new branching program Aw is bounded by
mn|A|. By the same arguments as in Lemma 3, for any weight k it is possible
to count eﬃciently the number of assignments that lead from the start vertex in
Aw to the output vertex 1k.
⊓⊔
Let A1 and A2 be two ROBPs computing functions f, g: Bn →B with
f ̸= g and let D be the set of assignments that distinguish A1 from A2, that is,
D = {x ∈Bn | f(x) ̸= g(x)}. Suppose that there is a weight function w: Xn →
{0, . . . , m} under which there is a unique minimum weight element a ∈D, and
let k = w(a). Consider the two ROBPs Aw
1 and Aw
2 transformed according to
the previous lemma from A1 and A2 with respect to the weight function w. The
numbers of assignments leading to the output nodes 1k in Aw
1 and in Aw
2 are
not the same. This is because a is the only assignment in D that reaches either
the vertex 1k in Aw
1 or the vertex 1k Aw
2 . All the other assignments in D have
weight greater than k and therefore cannot reach vertex 1k. Moreover, the set of
assignments in Bn \ D that reach 1k in Aw
1 coincides with those that reach 1k in
Aw
2 because A1 and A2 agree on Bn \ D. Therefore by counting the number of
assignmets reaching the vertices 1k for all k ≤mn in the two branching programs
Aw
1 and Aw
2 , an algorithm detects that A1 and A2 are not equivalent. Observe
that for a ﬁxed weight function w: Xn →{0, . . . , m}, the described algorithm
is completely deterministic and has a running time polynomially bounded in
|A1|, |A2|, and m. Putting these thoughts together with Lemma 4, we get our
main result in this section.
Theorem 6. There is a randomized algorithm that, given as input two read-
once branching programs A1 and A2 over a set of variables Xn and an upper
bound t ≥|{x ∈Bn | A1(x) ̸= A2(x)}|, decides with constant error probability
whether A1 and A2 are equivalent. The algorithm uses O(log n + log t) random
bits. Its running time is polynomial in |A1|, |A2|, and log t.
By simulating the random bits deterministically we obtain:
Corollary 7. There is a deterministic algorithm that, given as input two read-
once branching programs A1 and A2 over a set of variables Xn and an upper
bound t ≥|{x ∈Bn | A1(x) ̸= A2(x)}|, decides whether A1 and A2 are equiva-
lent. The running time of the algorithm is polynomial in |A1|, |A2|, and t.
When t can be polynomially bounded in n, this means a deterministic poly-
nomial time algorithm.
4
An Extension to a Stronger Model
Our randomized equality test for ROBDs can also be extended to the more
powerful model of so-called deterministic decomposable negation normal form

Equivalence Test of Read-Once Branching Programs with Small Discrepancy
125
(d-DNNF) sentences. The decomposable normal form (DNNF) was introduced
by Darwiche [5,6]. Several restricted versions of DNNF have since been deﬁned
and studied (see, e.g., [8] for an overview).
Deﬁnition 8 (Negation normal form [8]). A sentence in negation normal form
(NNF) on the variable set Xn = {x1, . . . , xn} is a rooted, directed acyclic graph
where each leaf node is labeled with 0, 1, or by some literal (xi or ¬xi) from
Xn; and each internal node is labeled with ∧or ∨and can have arbitrary many
children. The size of a sentence in NNF is the number of its edges.
The model deﬁned is just that of unbounded fanin Boolean circuits, with
negations only allowed at the inputs. We call nodes labeled by ∧conjunctions
or and-nodes; nodes labeled by ∨will be called disjunctions or or-nodes. A NNF
A on Xn calculates a function f : Bn →B in the natural way: The function
computed at a leaf node is just the value of its label, the function computed at
an and-node or an or-node is the conjunction or disjunction, respectively, of the
functions computed at its child nodes, and the function f computed by A is the
function computed at the root node of A.
Two of the restricting properties considered by Darwiche are decomposability
[5,6] and determinisim [7].
A NNF A is called decomposable if for each conjunction C in A, the conjuncts
of C do not share variables. That is, for any two children Ci and Cj of and-node
C, the set of variables appearing in the subtree rooted at Ci and the set of
variables appearing in the subtree rooted at Cj are disjoint.
A NNF A is called deterministic if for each disjunction C in A, each two
disjuncts of C are logically contradictory. That is, for any two children Ci and
Cj of or-node C, we have Ci ∧Cj ⊨false.
Decomposable NNFs are called DNNF for short, whereas the abbreviation
d-DNNF denotes deterministic decomposable NNFs. It is known that every
ROBP can be transformed in polynomial time into a d-DNNF computing the
same function (see eg. [8]). When determinism is replaced in d-DNNF by an even
stronger property called decision, one obtains a model that is actually equivalent
to ROBPs. There are d-DNNF sentences that cannot be transformed to addi-
tionally satisfy the decision property with only a polynomial increase in size [6].
In this sense, d-DNNF is a strict generalization of ROBPs.
In order to generalize our algorithm for the equivalence of ROBPs in order
to test equivalence in the d-DNNF model we need to show that it is possible to
count in polynomial time the number of satisfying assignments a of a d-DNNF
with a particular weight w(a) = w0. We describe an algorithm fulﬁlling this.
Lemma 9. There is a polynomial time algorithm that on input a d-DNNF A
over variable set Xn, a weight function w: Xn →{0, . . . , m}, and a desired
weight value w0 outputs the number of assignments a that satisfy A and have
value w0 under w.
Proof. Let v be a node in A. We denote by Vars(v) the set of variables appearing
(negated or not) in the node labels of the subgraph rooted at v. Furthermore, for

126
S. Arnold and J. Tor´an
r ∈{0, . . . , mn} we denote by Cv[r] the number of assignments a to variables in
Vars(v) such that w(a) = r and a is satisfying for the function computed at v.
Our algorithm will visit each node v in A and determine Vars(v) as well as
the table entries Cv[0], . . . , Cv[mn]. Before visiting the nodes in A, the algorithm
determines a topological ordering of the nodes. Using this ordering, it will make
sure that node v is visited only after each child of v has been visited.
The operations performed while visiting node v depend on the type of v.
There are ﬁve possibilities:
1. v is labeled by a constant (either 0 or 1). In this case, the algorithm sets
Vars(v) = ∅and Cv[r] = δr,0 for r ∈{0, . . . , mn} if v is labeled by 1, otherwise
Cv[r] = 0 for r ∈{0, . . . , mn}.
2. v is labeled by a variable xi. In this case, the algorithm sets Vars(v) = {xi}
and Cv[r] = δr,w(xi) for r ∈{0, . . . , mn}.
3. v is labeled by a negated variable ¬xi. In this case, the algorithm sets
Vars(v) = {xi} and Cv[r] = δr,0 for r ∈{0, . . . , mn}.
4. v is labeled by ∧. Let v1, . . . , vk be the children of v. Note that Vars(vi) and
the table Cvi have already been computed for i ∈[k]. The algorithm sets
Vars(v) =

i∈[k]
Vars(vi).
For the computation of Cv, our algorithm will take into account the children
of v only one after the other, similar as if the and-node v with fan-in k had ﬁrst
been replaced by a binary tree of k −1 and-nodes with fan-in 2 each. To this
end, the algorithm determines the intermediate tables Cv⟨0⟩, . . . , Cv⟨k⟩where
v⟨i⟩is an imaginary and-node with children v1, . . . , vi. Note that v is equiva-
lent to v⟨k⟩. The computation starts with Cv⟨0⟩[r] = δr,0 for r ∈{0, . . . , mn}
and ﬁnally reaches Cv⟨k⟩[r] = Cv[r]. Let s be a number from {0, . . . , r}. Since
d-DNNF A satisﬁes the decomposability property, the combination of any
satsifying assignment of weight s for v⟨i −1⟩with any satisfying assignment
of weight r −s for vi yields a satisfying assignment of weight r for v⟨i⟩. Thus,
Cv⟨i⟩follows from Cv⟨i−1⟩and Cvi by the convolution formula
Cv⟨i⟩[r] =
r

s=0
Cv⟨i−1⟩[s] Cvi[r −s].
Using these steps, the algorithm obtains Cv in time polynomial in |A| and m.
5. v is labeled by ∨. Let v1, . . . , vk be the children of v. The algorithm sets
Vars(v) =

i∈[k]
Vars(vi).
Note that each combination of a satisfying assignment for the function repre-
sented by vi with an arbitrary assignment to the variables in Vars(v)\Vars(vi)
yields a satisfying assignment for v. Our algorithm uses this fact in the com-
putation of Cv. Let X ⊆Xn be a subset of the variables and denote by EX[r]

Equivalence Test of Read-Once Branching Programs with Small Discrepancy
127
the number of all assignments a to variables in X with w(a) = r. Suppose
for a moment that the table EX would be available to our algorithm. The
number of assignments to the variables in Vars(v) that satisfy the function
computed at child vi of v and have weight r is
r

s=0
Cvi[s] EVars(v)\Vars(vi)[r −s].
Since d-DNNF A satisﬁes the determinism property, we obtain Cv[r] by sum-
mation over all children vi:
Cv[r] =
k

i=1
r

s=0
Cvi[s] EVars(v)\Vars(vi)[r −s].
It remains to show that EX[r] can also be eﬃciently calculated for any set X
of variables. Again, we use dynamic programming to solve this problem. We
clearly have E∅[r] = δr,0. Now assume that EY [r] was already known for any
set Y of variables and let xi be a variable not in Y . Considering the two
possible cases xi = 0 and xi = 1, we can easily compute EY ∪{xi}[r]:
EY ∪{xi}[r] = EY [r] + EY [r −w(xi)].
(If r < w(xi), we simply have EY ∪{xi}[r] = EY [r].) Thus, starting with Y = ∅,
we can take the variables into account one after the other, until we obtain
the table EX.
By induction, the algorithm correctly computes Cv for all nodes v of A in poly-
nomial time. It returns C˜v[w0] from the table for the root node ˜v.
⊓⊔
The described algorithm can in fact compute for the output vertex v of the
d-DNNF A, a weight frequency tuple Cv[0], . . . , Cv[mn] with the number of sat-
isfying assignments with each possible weight between 0 and mn. If two given
d-DNNFs are not equivalent, and w is a weight function having a unique mini-
mum weight element in the discrepancy set of both forms, the above algorithm
can check that the weight frequency tuples corresponding to both programs are
not identical. As in the case of ROBPs, the randomnes needed for the equivalence
test is only needed for choosing the weight function, and we obtain:
Theorem 10. There is a randomized algorithm that, given as input two deter-
ministic decomposable normal forms A1 and A2 over a set of variables Xn and
an upper bound t ≥|{x ∈Bn | A1(x) ̸= A2(x)}|, decides with constant error
probability whether A1 and A2 are equivalent. The algorithm uses O(log n+log t)
random bits. Its running time is polynomial in |A1|, |A2|, and log t.

128
S. Arnold and J. Tor´an
References
1. Agrawal, M., Hoang, T.M., Thierauf, T.: The polynomially bounded perfect match-
ing problem is in NC2. In: Thomas, W., Weil, P. (eds.) STACS 2007. LNCS, vol.
4393, pp. 489–499. Springer, Heidelberg (2007). doi:10.1007/978-3-540-70918-3 42
2. Blum, M., Chandra, A.K., Wegman, M.N.: Equivalence of free boolean graphs can
be decided probabilistically in polynomial time. Inf. Process. Lett. 10, 80–82 (1980)
3. Randal, E.: Bryant: graph based algorithms for Boolean function manipulation.
IEEE Trans. Comput. 35, 677–691 (1986)
4. Chari, S., Rohatgi, P., Srinivasan, A.: Randomness-optimal unique element isola-
tion with applications to perfect matching and related problems. SIAM J. Comput.
24, 1036–1050 (1995)
5. Darwiche, A.: Compiling knowledge into decomposable negation normal form. In:
Proceedings of the 16th International Joint Conference on Artiﬁcal Intelligence
(IJCAI 1999), pp. 284–289 (1999)
6. Darwiche, A.: Decomposable negation normal form. J. ACM 48, 608–647 (2001)
7. Darwiche, A.: On the tractable counting of theory models and its application to
truth maintenance and belief revision. J. Appl. Non-Class. Logics 11, 11–34 (2001)
8. Darwiche, A., Marquis, P.: A knowledge compilation map. J. Artiﬁ. Intell. Res. 17,
229–264 (2002)
9. Darwiche, A., Huang, J.: Testing equivalence probabilistically. Technical report
D-123 Computer Science Department, UCLA (2002)
10. Fortune, S., Hopcroft, J., Schmidt, E.M.: The complexity of equivalence and con-
tainment for free single variable program schemes. In: Ausiello, G., B¨ohm, C. (eds.)
ICALP 1978. LNCS, vol. 62, pp. 227–240. Springer, Heidelberg (1978). doi:10.1007/
3-540-08860-1 17
11. Grigoriev, D., Karpinski, M.: The matching problem for bipartite graphs with
polynomially bounded permanents is in NC. In: 28th Annual Symposium on Foun-
dations of Computer Science (FOCS), pp. 166–172 (1987)
12. Lee, C.Y.: Representation of switching circuits by binary-decision programs. Bell
Syst. Tech. J. 38, 985–999 (1959)
13. Masek, W.J.: A fast algorithm for the string editing problem and decision graph
complexity. M.Sc. thesis, MIT, Cambridge MA (1976)
14. Meinel, C.: Modiﬁed Branching Programs and Their Computational Power. LNCS,
vol. 370. Springer, Heidelberg (1989)
15. Mulmuley, K., Vazirani, U.V., Vazirani, V.V.: Matching is as easy as matrix inver-
sion. Combinatorica 7, 105–113 (1987)
16. Sch¨oning, U., Pruim, R.: Gems of Theoretical Computer Science. Springer, Heidel-
berg (1998)
17. Jacob, T.: Schwartz: fast probabilistic algorithms for veriﬁcation of polynomial
identities. J. ACM 27, 701–717 (1980)
18. Sipser, M.: Introduction to the Theory of Computation. PWS Publishing Company,
Boston (1997)
19. Wegener, I.: Branching Programs and Binary Decision Diagrams. SIAM, Philadel-
phia (2000)
20. Zippel, R.: Probabilistic algorithms for sparse polynomials. In: Ng, E.W. (ed.)
Symbolic and Algebraic Computation. LNCS, vol. 72, pp. 216–226. Springer, Hei-
delberg (1979). doi:10.1007/3-540-09519-5 73

Counting Substrate Cycles in Topologically
Restricted Metabolic Networks
Robert D. Barish(B) and Akira Suyama
Graduate School of Arts and Sciences, University of Tokyo,
Meguro-ku Komaba 3-8-1, Tokyo 153-8902, Japan
rbarish@genta.c.u-tokyo.ac.jp
Abstract. Substrate cycles in metabolic networks play a role in var-
ious forms of homeostatic regulation, ranging from thermogenesis to
the buﬀering and redistribution of steady-state populations of metabo-
lites. While the general problem of enumerating these cycles is #P-
hard, it is unclear if this result holds for realistic networks where e.g.
pathological vertex degree distributions or minors may not exist. We
attempt to address this gap by showing that the problem of count-
ing directed substrate cycles (#DirectedCycle) remains #P-complete
(implying #P-hardness for enumeration) for any superclass of cubic
weakly-3-connected bipartite planar digraphs, and at the limit where
all reactions are reversible, that the problem of counting undirected sub-
strate cycles (#UndirectedCycle) is #P-complete for any superclass of
cubic 3-connected bipartite planar graphs where the problem of count-
ing Hamiltonian cycles is #P-complete. Lastly, we show that unless
NP = RP, no FPRAS can exist for either counting problem whenever
the Hamiltonian cycle decision problem is NP-complete.
1
Introduction
In graph theoretic terms, substrate cycles can be thought of as cycles in reaction-
centric graphs of metabolic networks, where vertices correspond to enzymes and
directed (resp. undirected) edges correspond to irreversible (resp. reversible)
ﬂows of metabolite species between enzymes. Cycles in reaction-centric graphs
are also known as cyclical Elementary Fundamental Modes (EFMs) [1], and may
correspond to special cases of these objects denoted extreme pathways [2], where
the former are minimal sets of reactions or enzymes that can maintain a partic-
ular steady-state reaction and the latter are the extreme rays of a ﬂux cone for
a given biochemical or metabolic network at steady state.
Substrate cycles have been linked to thermogenesis in the ﬂight muscles of
bumble bees [3] as well as in the brown adipose tissue of mammals [4,5], and
have also been shown to have an important role in buﬀering steady-state pop-
ulations [6], and in sensitizing regulatory mechanisms related to metabolism
The original version of this chapter was revised: Incorrect capitalization has been
corrected. The erratum to this chapter is available at 10.1007/978-3-319-58741-7 37
c
⃝Springer International Publishing AG 2017
J. Kari et al. (Eds.): CiE 2017, LNCS 10307, pp. 129–140, 2017.
DOI: 10.1007/978-3-319-58741-7 14

130
R.D. Barish and A. Suyama
[5,7]. However, despite their apparent importance to biochemists, the only hard-
ness results we are aware of for enumerating substrate cycles are an indirect
consequence of proofs regarding the NP-hardness of counting all simple (not
necessarily induced) cycles in digraphs (see e.g. (“Theorem 17.4”; pp. 343–344)
of Arora and Barak [8]) via reduction from the NP-complete Hamiltonian cycle
decision problem [9], where digraphs can correspond to reaction-centric graphs
where all reactions are irreversible, and the recent proof due to Yamamoto [10]
that the problem of counting simple (not necessarily induced) cycles in arbitrary
undirected graphs is #P-complete as well as polynomial time inapproximable
unless NP = RP, where undirected graphs can correspond to reaction-centric
graphs where all reactions are reversible. Moreover, the only complexity theo-
retic results we are aware of for enumerating EFMs is that counting EFMs in
substrate-centric graphs, where metabolites are represented as vertices and reac-
tions as edges, is #P-complete [11] via reduction from the #P-complete problem
of counting perfect matchings [12], and that no polynomial total-time algorithm
(see Johnson et al. [13] for a deﬁnition of this term) can exist for enumerating
EFMs containing a speciﬁed reaction unless P = NP [14].
However, a question arises as to the practical relevance of these hardness
results which were proven for general graphs. Consider substrate-centric graphs,
where both metabolites are encoded as vertices which are connected by edges
corresponding to enzymes. We can note that these graphs have been shown to
have e.g. bounded diameters and to exhibit P(k) ∝k−γ power law scaling for
their vertex degree distributions in a range of archaea, bacteria, and eukaryotic
organisms [15]. It could therefore arguably be the case that the aforementioned
hardness results are simply the consequence of pathological families or classes of
graphs that have little relevance to actual metabolic networks.
Motivated by these concerns, we attempt to sharpen known hardness results
for enumerating substrate cycles to apply to some family of hypothetical
reaction-centric graphs, F, that is simultaneously more constrained than any
realistic large scale metabolic network and “physical” in the sense that one would
expect the constraints deﬁning F to be satisﬁed individually by subgraphs com-
posed of some reasonable fraction of enzymes in any given metabolic pathway.
After examining the metabolic pathways in the Kyoto Encyclopedia of Genes
and Genomes (KEGG) database [16], we decided that some form of vertex degree
uniformity, vertex or edge connectivity, bipartiteness, and planarity constraints
would reasonably meet these dual criteria (see e.g. Figure 1). We then proceeded
to prove that the problem of counting substrate cycles remains #P-complete
( =⇒
enumeration is #P-hard) on reaction-centric graphs belonging to any
superclass of the highly restricted class of cubic weakly-3-connected bipartite
planar digraphs (Theorem 1), and on any superclass of cubic 3-connected bipar-
tite planar undirected graphs where the problem of counting Hamiltonian cycles
is #P-complete (Theorem 2).

Counting Substrate Cycles in Topologically Restricted Metabolic Networks
131
Fig. 1. Reaction-centric graph (1.a), simpliﬁed by not considering {ATP, NADP+,
NADPH} or other cofactors, for the largest set of Homo sapiens enzymes in the Kyoto
Encyclopedia of Genes and Genomes (KEGG) database [16] (Release 81.0, January 1st,
2017) assigned to the pentose phosphate pathway, carrying out distinct reactions, and
allowing for a weakly-connected reaction-centric graph. Enzyme’s names are followed by
their KEGG Orthology (KO) numbers, and may have a ‘ 1’ or ‘ 2’ postﬁx to indicate
reactions involving distinct metabolite inputs. Edges that are directed (undirected)
correspond to irreversible (reversible) ﬂows of metabolites. Undirected edges constitute
minimal substate cycles, e.g., the (dashed) undirected edge in (1.a) corresponds to a
substrate cycle for a pair of enzymes that, if unchecked and provided a pool of ATP for
to reduce to ADP, will continuously interconvert fructose-6-phosphate and fructose-1,
6-bisphosphate, releasing heat in the process. Maximal subgraphs of the (1.a) reaction-
centric graph (in terms of vertex/enzyme counts) are shown, which are: (1.b) cubic;
(1.c) weakly-3-connected; (1.d) bipartite; and (1.e) planar.

132
R.D. Barish and A. Suyama
2
Preliminaries
Clariﬁcations Regarding Graph Theoretic Terminology. Let G be an
arbitrary undirected graph or directed graph (digraph). Here, we refer to G as
a cubic graph iﬀthe number of edges incident to every vertex vi in the graph
is uniformly ρ(vi) = 3. If G is an undirected graph, we say that G is 3-edge-
connected (resp. 3-vertex-connected) iﬀthe minimum edge (resp. vertex) cut
necessary to disconnect the graph is of size ≥3, and note that the edge and
vertex connectivity are equivalent if G is cubic. If G is instead a digraph, we
say that G is weakly-k-edge-connected or weakly-k-vertex-connected, which are
equivalent concepts on cubic digraphs, iﬀk is the minimum edge (resp. vertex)
cut necessary to disconnect G if all of its directed edges are made undirected.
We call G as a bipartite iﬀit has a bipartition of its vertices into two sets
A and B such that all edges in the graph have one endpoint in each set, or
equivalently, iﬀG is free of odd cycles. Finally, we call G a planar graph iﬀthere
exists a connectivity-preserving embedding G →R2 with no edge crossings, or
equivalently, iﬀG contains no minors isomorphic to K5 or K3,3.
Valiant’s Counting Class #P. In 1979, Valiant deﬁned a class #P [12,17] of
counting problems as the set of integer function problems of the form f : Σ∗→N
where one is tasked with determining the number of accepting pathways f(xi)
for a nondeterministic Turing machine M running in polynomial time on all
input strings xi encoded over the alphabet Σ (where we typically have Σ =
{0, 1}), and where ∀xi we have that |xi| = poly(|f(xi)|). For all #P-completeness
results in this work, we make use of a special case of 1-Turing reductions known
as (many-one) counting reductions (which are sometimes referred to as weakly
parsimonious reductions), where, in reducing one integer function problem f to
another integer function problem h, one has two polynomial time compatible
functions R1 : Σ∗→Σ∗and R2 : N →N, such that f(x) = R2(h(R1(x))).
If R2 is the identity function we call the counting reduction a parsimonious
reduction, and as a further special case relevant to (Theorem 1), if R2 is an
integer division operation by an exponent of two, i.e. if f(x) = ⌊

h(R1(x))
2R3(x)

⌋
where R3(x) : Σ∗→N>0, then we refer to the counting reduction as a right-bit-
shift reduction [18].
Randomized approximation schemes and Approximation Preserving
reductions (AP-reductions). Let f : Σ∗→N be a counting problem in
the complexity class #P, let x ∈Σ∗be some appropriate input for f, and let
f(x) = N. Following Karp and Luby [19], we deﬁne a Randomized Approxima-
tion Scheme (RAS) as a randomized algorithm which takes f and x as input and
outputs some value ˆf(ϵ,δ) such that Pr

| ˆ
f (ϵ,δ)−f(x)|
f(x)

> ϵ

< δ, where we have
some error rate parameter 0 < ϵ < 1 and some accuracy parameter 0 < δ < 1.
A Fully Polynomial-time Randomized Approximation Scheme (FPRAS) is sim-
ply a RAS that has a running time polynomially bounded by |x|, ϵ−1, and δ−1.
Now let {f, h} : Σ∗→N be two counting problems in the complexity class #P.

Counting Substrate Cycles in Topologically Restricted Metabolic Networks
133
An Approximation Preserving reduction (AP-reduction) from f to h (denoted
f ≤AP h), as originally deﬁned by Dyer et al. [20], is a probabilistic oracle Turing
machine M, taking as input a string x ∈Σ∗and error parameter 0 < ϵ < 1, and
satisfying the following three conditions: (1) letting x be an instance of h and
0 < δ < 1 (where δ−1 is polynomially bounded by |x| and ϵ−1), we have that all
calls to M specify an input of the form {x, ϵ}; (2) we have that M is a RAS for
f if it is a RAS for g; (3) the time complexity for M is polynomially bounded by
|x| and ϵ−1. Here, if f ≤AP h and h ≤AP f, we call f and h AP-interreducible
and write f ≡AP h.
3
Hardness Results for Counting Cycles on Undirected
Graphs and Digraphs
Theorem 1. The problem of counting directed simple (not necessarily induced)
cycles on cubic weakly-3-connected bipartite planar digraphs having vertex in-
degree and out-degree at most two, #DirectedCycle(C3BP :: In2Out2), is #P-
complete.
We note that Theorem 1 is equivalent to the statement that counting sub-
strate cycles in reaction-centric graphs corresponding to cubic 3-connected bipar-
tite planar digraphs ( =⇒all reactions are irreversible) is #P-complete.
Claim 1.1. #DirectedCycle(C3BP :: In2Out2) ∈#P.
Consider a nondeterministic Turing machine that accepts an input string
encoding a cubic 3-connected bipartite planar digraph G and a directed edge-
wise (or vertex-wise) path P in G, and accepts this input if and only if P is
a simple directed cycle in G (i.e. a directed cycle which visits any given vertex
at most once). Here, we deﬁne #DirectedCycle(C3BP :: In2Out2) as an integer
function problem f : Σ∗→N, where one is tasked with determining the number
of accepting branches f(x) for such a nondeterministic Turing machine
=⇒
#DirectedCycle(C3BP :: In2Out2) ∈#P.
Claim 1.2. #DirectedCycle(C3BP :: In2Out2) is #P-hard.
We proceed with a strategy of creating some digraph H in polynomial time
from an arbitrary simple cubic 3-connected bipartite planar digraph having in-
degree and out-degree at most two, G, of order n, where via a gadget substitution
scheme we amplify the number of simple length L cycles in the graph by a factor
(2m)L allowing us to calculate the number of Hamiltonian cycles via a simple
integer division operation. However, in lieu of substituting this gadget in place
of the edges of G in the manner of the proof for (“Theorem 17.4”; pp. 343–344)
in Arora and Barak [8] and in the manner of Yamamoto [10], which precludes
H from being 3-connected, we instead replace each of the n vertices in G with
the gadget in such a manner as to ensure that H is a cubic weakly-3-connected
bipartite planar digraph having in-degree and out-degree at most two iﬀG is
cubic weakly-3-connected bipartite planar digraph having in-degree and out-
degree at most two. To do so we deﬁne a surgery for cubic graphs which we

134
R.D. Barish and A. Suyama
Fig. 2. Scheme for generating a family of cubic 3-connected bipartite planar Directed
Acyclic Graph (DAG) vertex substitution gadgets where the height q of the gadget
can be speciﬁed as desired. If the appropriate (in terms of matching in-degree and
out-degree counts) height q gadget is substituted in place of all vertices in some cubic
3-connected bipartite planar graph G, creating a new cubic 3-connected bipartite planar
graph H, this will multiply the number of length L cycles in G by the factor (4q)L.
denote tripole substitution wherein a selected vertex vi in a cubic graph G is
substituted with a target graph H having three degree ρ(vi) = 1 pole vertices
that are identiﬁed (via some bijection if necessary) as the vertices connected to
the vi vertex in G via an edge of identical orientation.
In Fig. 2 we illustrate the scheme for our height (using this term to satisfy
the visual metaphor of a tower) q gadget used for tripole substitution at all
vertices of G to create H. We can now make the following two observations: (1)

Counting Substrate Cycles in Topologically Restricted Metabolic Networks
135
that the gadget is a Directed Acyclic Graph (DAG), which implies that there
will be no gadget internal cycles; (2) that the substitution of a height q gadget
at every vertex in G to create H will amplify the number of simple length L
cycles in G by the factor (4q)L. We set q = ⌈n ∗log4(n)⌉, which implies a rate
of growth for q of O(n ∗ln(n)), and which correspondingly implies that we can
construct H in time polynomial in the number of vertices in G. Next, we note
there can be at most n(n−1) directed cycles of length at most (n−1) in a digraph
as this term corresponds to the number of distinct length (n −1) strings that
can be created from an alphabet Σ of size |Σ| = n. This then implies that if
the graph G is non-Hamiltonian we have an upperbound of (4q)(n−1) ∗n(n−1) =
(4⌈(n∗log4(n))⌉)
(n−1) ∗n(n−1) directed cycles. However, if the graph G has at least
one Hamiltonian cycle, H has at least (4q)n = (4⌈(n∗log4(n))⌉)
n directed cycles.
Here, if we remove the ceiling function in the expression for q, the lowerbound
number of cycles for Hamiltonian G is exactly a factor of n larger than the
upperbound R for the number of cycles for non-Hamiltonian G, and with the
ceiling function, at least a factor of n larger since ∀{n ∈R>0, q ∈R≥0} we have
that sgn

∂
∂q

(4q)n
(4q)(n−1)∗n(n−1)

= (4q ∗n(1−n) ∗ln(4))
	
= (+1).
Putting everything together, we have that the number of Hamiltonian cycles
in G is equal to ⌊

(# Directed Cycles in H)
(4⌈(n∗log4(n))⌉)n

⌋= ⌊

(# Directed Cycles in H)
2(2n∗⌈(n∗log4(n))⌉)

⌋. As
this closed-form expression is a polynomial time computable integer division
operation consistent with the requirements for a right-bit-shift reduction [18],
and as the problem of counting Hamiltonian cycles on cubic 3-connected bipartite
planar digraphs is #P-complete under parsimonious reductions (though unre-
marked upon by Plesn´ık, his construction in [21] is odd-cycle-free, and moreover
becomes a parsimonious counting reduction from a variant of #3SAT, and tran-
sitively #SAT, if one reorients one edge in his “OR” gadget (Barish and Suyama;
in preparation)), we have that #DirectedCycle(C3BP :: In2Out2) is #P-hard.
Claim 1.3. #DirectedCycle(C3BP :: In2Out2) is #P-complete under right-
bit-shift reductions.
As we have that the counting problem is in #P (Claim 1.1), is #P-hard
(Claim 1.2), and because the reduction described in the proof argument for
(Claim 1.2) is a right-bit-shift reduction [18], by deﬁnition we have that the
counting problem is #P-complete under right-bit-shift reductions.
Claim 1.4. Unless we have that NP = RP, there does not exist a FPRAS for
#DirectedCycle(C3BP :: In2Out2).
Let G be an arbitrary cubic 3-connected bipartite planar digraph of order n,
let H be the gadget substituted graph constructed as described in (Claim 1.2),
and let R represent an upperbound for the fraction of directed cycles in H
not corresponding to Hamiltonian cycles. Proceeding now in much the same
manner as Yamamoto [10], from the argument in (Claim 1.2) we have that
R
=
( (4⌈(n∗log4(n))⌉)
(n−1)∗n(n−1)
(4⌈(n∗log4(n))⌉)n
)
≤
1
n
=⇒
( (# Directed Cycles in H)
(4⌈(n∗log4(n))⌉)n
)
≤
⌊( (# Directed Cycles in H)
(4⌈(n∗log4(n))⌉)n
)⌋+ 1
4 for n ≥4. As the Hamiltonian cycle decision prob-
lem is NP-complete for cubic 3-connected bipartite planar digraphs (see again

136
R.D. Barish and A. Suyama
(Claim 1.2) regarding a discussion of this point), by the argument at the end
of “Theorem 3” in Dyer et al. [20], we have that #DirectedCycle(C3BP ::
In2Out2) ≡AP #SAT. Finally, we note that in Zuckerman [22] it is proven that
no FPRAS can exist for approximating #SAT unless NP = RP, and that this
holds for all counting problems in #P that are AP-interreducible in polynomial
time. Therefore, there can be no FPRAS for #DirectedCycle(C3BP :: In2Out2)
unless we have that NP = RP.
Theorem 2. The problem of counting undirected simple (not necessarily
induced) cycles on any superclass (superset) of cubic 3-connected bipartite pla-
nar graphs where the problem of counting Hamiltonian cycles is #P-complete,
#UndirectedCycle(Superclass C3BP :: #HC = #P), is #P-complete.
We note that Theorem 2 is equivalent to the statement that counting sub-
strate cycles in reaction-centric graphs corresponding to any superclass of cubic
3-connected bipartite planar undirected graphs ( =⇒all reactions are reversible)
is #P-complete whenever the problem of counting all Hamiltonian cycles is #P-
complete.
Claim 2.1. #UndirectedCycle(Superclass C3BP :: #HC = #P) ∈#P.
This follows straightforwardly from the method of argument in (Claim 1.1).
Claim 2.2. #UndirectedCycle(Superclass C3BP :: #HC = #P) is #P-hard.
Let G be an arbitrary simple undirected cubic 3-connected bipartite planar
graph of order n. In Fig. 3 we illustrate the scheme for our depth q gadget used
for tripole substitution at all vertices of G to create H. We can now make the
following three observations: (1) that H is an undirected cubic graph that is
3-connected iﬀG is 3-connected, bipartite iﬀG is bipartite, and planar iﬀG is
planar; (2) that n = |VG| depth q gadgets will imply the existence of some number
of undirected cycles internal to the set of gadgets; (3) that the substitution of
a height q gadget at every vertex in G to create H will amplify the number
of simple length L cycles in G by some gadget ampliﬁcation factor denoted
Ψ. Speciﬁcally, for cycles traversing a depth q gadget, we have the recurrence
relation a(q+1) = 2+5∗aq where a(1) = 7 =⇒aq = Ψ = 1
2(3∗5q−1), and for the
number of cycles internal to a depth q gadget, we have the recurrence relation
b(q+1) = (1+3∗2∗Ψ +bq) = (1+6∗1
2(3∗5q −1)+bq) where b(1) = 7 =⇒bq =
1
4(9∗5q −8q−9). We set q = ⌈log5( 1
3(1+2∗nn))⌉, which implies a rate of growth
for q of O(ln(nn)) = O(n ∗ln(n)), and which correspondingly implies that we
can construct H in time polynomial in the order of G. Noting as in (Claim 1.3)
that there can be at most n(n−1) undirected cycles of length at most (n−1) in a
graph, we have that if the graph G is non-Hamiltonian, post-ampliﬁcation there
are at most (( 1
2(3 ∗5q −1))
(n−1) ∗n(n−1) + n ∗( 1
4(9 ∗5q −8q −9))) undirected
cycles. However, if the graph G has at least one Hamiltonian cycle, H has at
least ( 1
2(3 ∗5q −1))
n + n ∗( 1
4(9 ∗5q −8q −9)) undirected cycles. Here, if we
remove the ceiling function in the expression for q, the lowerbound number of
cycles for Hamiltonian G is exactly a factor of n larger than the upperbound R
for the number of cycles for non-Hamiltonian G, and with the ceiling function,

Counting Substrate Cycles in Topologically Restricted Metabolic Networks
137
Fig. 3. Let a “BW 3 tripole” be a BW 3 graph modiﬁed to have pole vertices {Pole
1, Pole 2, Pole 3} joined by an edge to the degree ρ(vi) = 2 vertices in the original
BW 3 graph. Here we show a recursive BW 3 tripole substitution scheme for generating
a family of undirected cubic 3-connected bipartite planar vertex substitution gadgets
where the depth q of the gadget can be speciﬁed as desired. If a depth q gadget is
substituted in place of all vertices in some undirected cubic 3-connected bipartite planar
graph G, creating a new cubic 3-connected bipartite planar graph H, this will multiply
the number of length L cycles in G by Ψ L = ( 1
2(3 ∗5q −1))
L and generate (n ∗( 1
4(9 ∗
5q −8q −9))) total gadget internal undirected cycles.
at least a factor of n larger since ∀{n ∈R>0, q ∈R≥0} we have that:
sgn

∂
∂q

( 1
2(3 ∗5q −1))
n + n ∗( 1
4(9 ∗5q −8q −9))
( 1
2(3 ∗5q −1))
(n−1) ∗n(n−1) + n ∗( 1
4(9 ∗5q −8q −9))

= sgn

∂
∂q

( 1
2(3 ∗5q −1))
n
( 1
2(3 ∗5q −1))
(n−1) ∗n(n−1)

=
3
2(5q ∗n(1−n) ∗ln(5))

= (+1)
(1)
Now, setting q ≥log5( 1
3(1 + 2 ∗nn)), letting ϕ = n ∗( 1
4(9 ∗5q −8q −9))
be the number of cycles internal to the vertex substitution gadgets, and letting
Ω = ( 1
2(3 ∗5q −1))
n be the number of undirected cycles in H per Hamiltonian
cycle in G, we can write the relation:
(# Hamiltonian Cycles in G) = ⌊
(# Undirected Cycles in H) −ϕ
Ω

⌋
= ⌊

(# Undirected Cycles in H) −( 3n(nn−1)
2
) + 2n ∗log5( 2nn+1
3
)
(nn)n

⌋
(2)

138
R.D. Barish and A. Suyama
As this closed-form expression is polynomial time computable, we have that
#UndirectedCycle(Superclass C3BP :: #HC = #P) is #P-hard.
We brieﬂy remark that, letting R represent an upperbound for the fraction
of undirected cycles in H that are not Hamiltonian cycles, and again setting
q ≥log5( 1
3(1 + 2 ∗nn)), we have the bound:
R =

( 1
2(3 ∗5q −1))
(n−1) ∗n(n−1) + n ∗( 1
4(9 ∗5q −8q −9))
( 1
2(3 ∗5q −1))
n
)

=

( (nn)n
n
) + ( 3n(n+1)
2
) −( 3n
2 ) −2n ∗log5( 2nn+1
3
)
(nn)n

≈

( (nn)n
n
)
(nn)n

= 1
n
(3)
Thus, letting ||x|| be the nearest-integer function, for n > 2 (which holds
without the approximation shown in (Expr. 3)) we have that the number of
Hamiltonian cycles in G is equal to ||

(# Undirected Cycles in H)
(nn)n

||.
Claim 2.3. #UndirectedCycle(Superclass C3BP :: #HC
=
#P) is #P-
complete under weakly parsimonious reductions.
As we have that the counting problem is in #P (Claim 2.1) and is #P-hard
(Claim 2.2), by deﬁnition we have that the counting problem is #P-complete.
Claim 2.4. Unless we have that NP = RP, there does not exist a FPRAS for
#UndirectedCycle(Superclass C3BP :: #HC = #P) whenever we have that
the Hamiltonian cycle decision problem is NP-complete.
This claim follows straightforwardly from (Expr. 3) and the method of argu-
ment in (Claim 1.4).
Corollary 2.1. The problem of counting all undirected cycles on cubic 2-
connected planar graphs, #UndirectedCycle(C2P), is #P-complete.
This corollary follows from the proof argument for (Theorem 2) and the proof
by Liskiewicz, Ogihara, and Toda [18] that the problem of counting all Hamil-
tonian cycles in an input graph is #P-complete under right-bit-shift reductions
on cubic 2-connected planar graphs.
Corollary 2.2. The problem of counting all undirected cycles on cubic 3-
connected planar graphs (#UndirectedCycle(C3P)), and on cubic 2-connected
bipartite planar graphs (#UndirectedCycle(C2BP)), is NP-hard.
This corollary follows from the proof argument for (Theorem 2) and the NP-
completeness of the Hamiltonian cycle decision problem on cubic 3-connected
planar graphs [23], cubic 3-connected bipartite graphs [24], and cubic 2-
connected bipartite planar graphs [24].
4
Concluding Remarks
We note that substrate cycles in reaction-centric graphs corresponding to closed
systems (or, more appropriately, approximations thereof) such as individual cells,

Counting Substrate Cycles in Topologically Restricted Metabolic Networks
139
organelles like the mitochondria, or assuming some appropriate generalization
to arbitrary chemical reaction networks, the upper atmospheres of gas giants,
are equivalent to EFMs (see for example the proof argument for “Theorem 6”
in Acuna et al. [11]). Furthermore, if all reactions are irreversible, there is also a
one-to-one between substrate cycles and extreme pathways. Therefore, we have
that our hardness results concerning substrate cycles have the same implications
for counting and enumerating EFMs and, at the limit where all reactions are irre-
versible, extreme pathways in metabolic networks with the speciﬁed topological
restrictions.
References
1. Schuster, S., Hilgetag, C.: On elementary ﬂux modes in biochemical reaction sys-
tems at steady state. J. Biol. Syst. 2, 165–182 (1994)
2. Schilling, C.H., Letscher, D., Palsson, B.O.: Theory for the systemic deﬁnition
of metabolic pathways and their use in interpreting metabolic function from a
pathway-oriented perspective. J. Theor. Biol. 203, 229–248 (2000)
3. Clark, M.G., Bloxham, D.P., Holland, P.C., Lardy, H.A.: Estimation of the fructose
diphosphatase-phos-phofructokinase substrate cycle in the ﬂight muscle of Bombus
aﬃnis. Biochem. J. 134, 589–597 (1973)
4. Kazak, L., et al.: A Creatine-driven substrate cycle enhances energy expenditure
and thermogenesis in beige fat. Cell 163, 643–655 (2015)
5. Newsholme, E.A., Crabtree, B.: Substrate cycles in metabolic regulation and in
heat generation. Biochem. Soc. Symp. 41, 61–110 (1976)
6. Hervagault, J.F., Canu, S.: Bistability and irreversible transitions in a simple sub-
strate cycle. J. Theor. Biol. 127, 439–449 (1987)
7. Adolfsen, K.J., Brynildsen, M.P.: Futile cycling increases sensitivity toward oxida-
tive stress in Escherichia coli. Metab. Eng. 29, 26–35 (2015)
8. Arora, S., Barak, B.: Computational Complexity: A Modern Approach. Cambridge
University Press, New York (2009)
9. Karp, R.M.: Reducibility among combinatorial problems. In: Miller, R.E.,
Thatcher, J.W. (eds.) Complexity of Computer Computations, pp. 85–103 (1972)
10. Yamamoto, M.: Approximately counting paths and cycles in a graph. Discrete
Appl. Math. 217, 381–387 (2017)
11. Acuna, V., et al.: Modes and cuts in metabolic networks: complexity and algo-
rithms. BioSystems 95, 51–60 (2009)
12. Valiant, L.G.: The complexity of computing the permanent. Theor. Comput. Sci.
8, 189–201 (1979)
13. Johnson, D.S., Yannakakis, M., Papadimitriou, C.H.: On generating all maximal
independent sets. Inf. Process. Lett. 27, 119–123 (1988)
14. Acuna, V., et al.: A note on the complexity of ﬁnding and enumerating elementary
modes. BioSystems 99, 210–214 (2010)
15. Jeong, H., Tombor, B., Albert, R., Oltvai, Z.N., Barabasi, A.L.: The large-scale
organization of metabolic networks. Nature 407, 651–654 (2000)
16. Kanehisa, M., Goto, S.: KEGG: Kyoto encyclopedia of genes and genomes. Nucleic
Acids Res. 28, 27–30 (2000)
17. Valiant, L.G.: The complexity of enumeration and reliability problems. SIAM J.
Comput. 8, 410–421 (1979)

140
R.D. Barish and A. Suyama
18. Liskiewicz, M., Ogihara, M., Toda, S.: The complexity of counting self-avoiding
walks in subgraphs of two-dimensional grids and hypercubes. Theor. Comput. Sci.
304, 129–156 (2003)
19. Karp, R.M., Luby, M.: Monte-Carlo algorithms for enumeration and reliability
problems. In: Proceedings of the 24th Annual Symposium on Foundations of Com-
puter Science (FOCS), pp. 56–64 (1983)
20. Dyer, M., Greenhill, C., Goldberg, L.A., Jerrum, M.: On the relative complexity
of approximate counting problems. Algorithmica 38, 471–500 (2004)
21. Plesnik, J.: The NP-completeness of the Hamiltonian cycle problem in planar
digraphs with degree bound two. Inf. Process. Lett. 8, 199–201 (1979)
22. Zuckerman, D.: On unapproximable versions of NP-complete problems. SIAM J.
Comput. 25, 1293–1304 (1996)
23. Garey, M.R., Johnson, D.S., Tarjan, R.E.: The planar Hamiltonian circuit problem
is NP-complete. SIAM J. Comput. 5, 704–714 (1976)
24. Akiyama, T., Nishizeki, T., Saito, N.: NP-completeness of the Hamiltonian cycle
problem for bipartite graphs. J. Inf. Process. 3, 73–76 (1980)

Turing Computable Embeddings, Computable
Inﬁnitary Equivalence, and Linear Orders
Nikolay Bazhenov1,2(B)
1 Sobolev Institute of Mathematics, Novosibirsk, Russia
bazhenov@math.nsc.ru
2 Novosibirsk State University, Novosibirsk, Russia
Abstract. We study Turing computable embeddings for various classes
of linear orders. The concept of a Turing computable embedding (or tc-
embedding for short) was developed by Calvert, Cummins, Knight, and
Miller as an eﬀective counterpart for Borel embeddings. We are focused on
tc-embeddings for classes equipped with computable inﬁnitary Σα equiv-
alence, denoted by ∼c
α. In this paper, we isolate a natural subclass of
linear orders, denoted by WMB, such that (WMB, ∼=) is not universal
under tc-embeddings, but for any computable ordinal α ≥5, (WMB, ∼c
α)
is universal under tc-embeddings. Informally speaking, WMB is not tc-
universal, but it becomes tc-universal if one imposes some natural restric-
tions on the eﬀective complexity of the syntax. We also give a complete
syntactic characterization for classes (K, ∼=) that are Turing computably
embeddable into some speciﬁc classes (C, ∼=) of well-orders. This extends
the similar result of Knight, Miller, and Vanden Boom for the class of all
ﬁnite linear orders Cfin.
Keywords: Turing computable embedding · Linear order · Ordinal ·
Computable inﬁnitary equivalence · Computable structure
1
Introduction
In this paper we study computability-theoretic complexity for linear orders. One
approach to comparing diﬀerent classes of structures is to investigate certain
eﬀective properties that can be realized by a structure in the class. For exam-
ple, the categoricity spectrum of a computable structure S is the collection of all
Turing degrees capable of computing isomorphisms among arbitrary computable
copies of S. It is well-known that computable ordinals cannot realize every pos-
sible categoricity spectrum [1]. On the other hand, any categoricity spectrum
can be realized by a computable partial order [2]. Thus, one can say that partial
orders are computationally “harder” (with respect to categoricity spectra) than
well-orders. Nevertheless, there are several ways to compare computability-the-
oretic complexity of two classes of structures, see, e.g., [2–5].
Friedman and Stanley [6] introduced the notion of Borel embedding to com-
pare complexity of the classiﬁcation problems for classes of countable structures.
c
⃝Springer International Publishing AG 2017
J. Kari et al. (Eds.): CiE 2017, LNCS 10307, pp. 141–151, 2017.
DOI: 10.1007/978-3-319-58741-7 15

142
N. Bazhenov
Calvert, Cummins, Knight, and Miller [3] developed Turing computable embed-
dings as an eﬀective counterpart of Borel embeddings. The formal deﬁnition of
a Turing computable embedding (or tc-embedding for short) is given in Sect. 2.1.
TC-embeddings for familiar classes of structures have been further studied in [7–
11]. Note that these works study tc-embeddings only for classes equipped with
the relation of isomorphism.
VanDenDriessche [12] and Wright [13] began the investigation of Turing
computable embeddings for classes with equivalence relations other than isomor-
phism. Wright [13] considered computable isomorphism and some special rela-
tions on trees. VanDenDriessche [12] studied classes of abelian p-groups equipped
with computable inﬁnitary Σα equivalence.
Assume that A and B are structures in the same language, and α is a com-
putable ordinal. We say that A and B are computably inﬁnitarily Σα equivalent
(Σc
α equivalent), denoted by A ∼c
α B, if A and B satisfy the same computable
inﬁnitary Σα sentences. Recall that the computable dimension of a computable
structure S is the number of computable copies of S, up to computable isomor-
phism.
In [12], it was shown that for any computable α ≥2, the class of abelian p-
groups is universal for ∼c
α under tc-embeddings. In contrast, the class of abelian
p-groups is not universal for isomorphism under tc-embeddings (see, e.g., [9, pp.
852–853]). Moreover, Goncharov [14] proved that for a computable abelian group
G, the computable dimension of G is either 1 or ω. Thus, the class of abelian
p-groups is not universal in the sense of Hirschfeldt, Shore, Khoussainov, and
Slinko (see [2, Deﬁnition 1.21]).
The results above motivate the following:
Problem. Find classes of structures K such that:
– K is not universal for ∼= under tc-embeddings, and
– there is β0 < ωCK
1
such that for any computable α ≥β0, K is universal for
∼c
α under tc-embeddings.
We call such classes quasi-tc-universal. Informally speaking, a quasi-tc-univ-
ersal class is non-tc-universal, but it becomes tc-universal if we impose some
natural restrictions on the eﬀective complexity of our syntactic descriptions. For
the exact deﬁnition of a quasi-tc-universal class, see Sect. 2.1. The results of [12]
show that the class of abelian p-groups is quasi-tc-universal.
Here we focus on subclasses of linear orders. Friedman and Stanley [6] proved
that the class of all linear orders is universal for isomorphism under tc-embed-
dings. In this paper, we isolate a natural subclass of linear orders, denoted by
WMB, which is quasi-tc-universal.
Recall that for a linear order L, the block relation on L is the set
B(L) =

(a, b) : a, b ∈L and there are only ﬁnitely many x
with (a ≤L x ≤L b) ∨(b ≤L x ≤L a)

.

Turing Computable Embeddings
143
The relation B(L) is a congruence on L. We deﬁne the class WMB (“well-orders
modulo block relation”) as follows:
WMB = {L : L is a linear order, and L/B(L) is a well-order}.
The outline of the paper is as follows. Section 2 contains necessary prelim-
inaries. In Sect. 3, we prove that WMB is a quasi-tc-universal class. We leave
open whether the class of well-orders is quasi-tc-universal. In Sect. 4, we study
tc-embeddings for subclasses of computable ordinals, equipped with isomor-
phism. In particular, for a computable ordinal α, we obtain a necessary and
suﬃcient condition for a class (K, ∼=) to be Turing computably embeddable into
(Cα, ∼=) := ({ωα · (t + 1) : t ∈ω}, ∼=). This extends the result of Knight, Miller,
and Vanden Boom [7, Theorem 4.1], which provides the similar condition for the
class of all ﬁnite linear orders C0. Section 5 discusses some open questions and
consequences of our results.
2
Preliminaries
We consider only computable languages, and structures with universe contained
in ω. We assume that any considered class of structures K is closed under isomor-
phism, modulo the restriction on the universes. In addition, we assume that all
the structures from K have the same language. For a structure S, D(S) denotes
the atomic diagram of S. We identify formulas with their G¨odel numbers.
We treat linear orders as structures in the language {≤2}. If L is a linear
order and a ≤L b, then [a, b[ is the interval on the universe {x : a ≤L x <L b}.
For a language L, inﬁnitary formulas of L are formulas of the logic Lω1ω. For
a countable ordinal α, inﬁnitary Σα and Πα formulas are deﬁned in a standard
way (see, e.g., [15, Chap. 6]). We give a short informal description for the class
of computable inﬁnitary formulas of L. These formulas allow disjunctions and
conjunctions over computably enumerable (c.e.) sets of formulas. Let α be a
non-zero computable ordinal.
1. Computable Σ0 and Π0 formulas are quantiﬁer-free ﬁrst-order L-formulas.
2. A computable Σα formula (Σc
α formula) is a c.e. disjunction 
i∃¯uiψi(¯x, ¯ui),
where ψi is a computable Πβi formula for some βi < α.
3. A computable Πα formula (Πc
α formula) is a c.e. conjunction 
i∀¯uiψi(¯x, ¯ui),
where ψi is a computable Σβi formula for some βi < α.
For the exact deﬁnition of computable inﬁnitary formulas and their properties,
the reader is referred to Chap. 7 in [15].
For a computable non-zero ordinal α and a Turing degree d, let
d(α) =
d(α−1), if α < ω,
d(α),
if α ≥ω.
This notation is very convenient: e.g., a set X ⊆ω is Σ0
α if and only if X is c.e.
relative to 0(α).
A total function G: ω →ω is d-limitwise monotonic if there exists a d-com-
putable function g(x, s) with the following properties:

144
N. Bazhenov
1. g(x, s) ≤g(x, s + 1) for all x and s, and
2. G(x) = lims g(x, s) for all x.
2.1
Turing Computable Embeddings
Deﬁnition 2.1 ([12, Deﬁnition 1], after [3, Deﬁnition 2] and [7, Deﬁnition
1.3]). Suppose that K1 and K2 are classes of countable structures, and for i ∈
{1, 2}, Ei is an equivalence relation on Ki. A Turing computable embedding (tc-
embedding) of (K1, E1) into (K2, E2) is an operator Φ = ϕe with the following
properties:
1. for every A ∈K1, there exists B ∈K2 such that the characteristic function
χD(B) of the set D(B) is equal to ϕD(A)
e
(such a structure B is denoted by
Φ(A)),
2. for any A, A′ ∈K1, we have AE1A′ iﬀΦ(A)E2Φ(A′).
We write (K1, E1) ≤tc (K2, E2) if there is a tc-embedding from (K1, E1) into
(K2, E2). If (K1, E1) ≤tc (K2, E2) and (K2, E2) ≤tc (K1, E1), then we write
(K1, E1) ≡tc (K2, E2). Note that the relation ≤tc is a preorder.
One of important results in the theory of tc-embeddings is the following:
Pullback Theorem (Knight, Miller, and Vanden Boom [7]). Suppose
that (K1, ∼=) ≤tc (K2, ∼=) via Φ. Then for any computable inﬁnitary sentence
ψ in the language of K2, we can eﬀectively ﬁnd a computable inﬁnitary sentence
ψ∗in the language of K1 such that for all A ∈K1, we have A |= ψ∗if and only
if Φ(A) |= ψ. Moreover, for a non-zero α < ωCK
1
, if ψ is a Σc
α (Πc
α) formula,
then so is ψ∗.
Fokina, Knight, Melnikov, Quinn, and Safransky [9] obtained a suﬃcient
condition for not being universal for ∼= under tc-embeddings:
Theorem 2.1 ([9, Theorem 3.1]). Let K1 and K2 be classes of structures. Sup-
pose that K1 contains a pair of non-isomorphic structures A1 and A2 such that
ωD(A1)
1
= ωD(A2)
1
= ωCK
1
, and A1, A2 satisfy the same computable inﬁnitary
sentences. If K2 contains no such pair, then (K1, ∼=) ≰tc (K2, ∼=).
We now give a formal deﬁnition of a quasi-tc-universal class:
Deﬁnition 2.2 We say that a class of structures K is quasi-tc-universal if it
satisﬁes the following:
(i) there is a class of structures K∗such that (K∗, ∼=) ≰tc (K, ∼=), and
(ii) there is β0 < ωCK
1
such that for any computable α ≥β0 and any class K′,
we have (K′, ∼c
α) ≤tc (K, ∼c
α).
For more results on tc-embeddings, we refer the reader to [7,12,16].

Turing Computable Embeddings
145
2.2
Pairs of Computable Structures
The proof of our results uses the technique of pairs of computable structures
developed by Ash and Knight [15,17]. Here we give necessary preliminaries on
this technique.
Suppose that L is a language, A and B are L-structures, and α is a countable
ordinal. We say that A ≤α B if every inﬁnitary Πα sentence true in A is true
in B. The relations ≤α are called standard back-and-forth relations.
Let α be a computable ordinal. A family K = {Ai : i ∈I} of L-structures
is called α-friendly if the structures Ai are uniformly computable in i ∈I, and
the relations
Bβ =

(i, ¯a, j,¯b) : i, j ∈I, ¯a is from Ai, ¯b is from Aj, (Ai, ¯a) ≤β (Aj,¯b)

are computably enumerable uniformly in β < α.
Theorem 2.2 (Ash and Knight [17], see also [15, Theorem 18.6]). Let α be
a non-zero computable ordinal. Suppose that A and B are computable L-stru-
ctures such that B ≤α A and the family {A, B} is α-friendly. Then for any Π0
α
set S, there is a uniformly computable sequence of structures {Cn}n∈ω such that
Cn ∼=

A, if n ∈S,
B, otherwise.
The key feature of Theorem 2.2 is its uniformity: given a Kleene’s notation
of an ordinal α, computable indices of structures A, B, and a Π0
α index for
S, one can eﬀectively ﬁnd a computable index for the sequence {Cn}n∈ω. This
uniformity is very helpful: it was used, e.g., in the proof of [15, Theorem 18.9].
2.3
Back-and-Forth Relations for Ordinals
In order to use the technique of pairs of computable structures, we give a brief
overview on the standard back-and-forth relations for the class of ordinals. First,
we recall some inﬁnitary formulas from [15]. For a computable ordinal α, we
assume that μ=
α(x, y) is the inﬁnitary formula from [15, Proposition 7.2] which
satisﬁes the following:
– for any linear order L and any a, b ∈L, we have L |= μ=
α(a, b) iﬀa ≤L b and
the interval [a, b[ is isomorphic to ωα; and
– μ=
α is a Πc
2α+1 formula.
Using the proof of [15, Proposition 7.2], it is not diﬃcult to construct a formula
μ<
α (x, y) such that:
– for any linear order L and any a, b ∈L, we have L |= μ<
α (a, b) iﬀa ≤L b and
[a, b[ is isomorphic to some ordinal β < ωα; and
– μ<
α is a Σc
2α formula.

146
N. Bazhenov
Note that for an order L, the block relation B(L) is deﬁnable by the formula
B(x, y) := μ<
1 (x, y) ∨μ<
1 (y, x).
Ash [1] obtained a complete description of the standard back-and-forth rela-
tions for well-orders. Here we give only an excerpt from the description.
Lemma 2.1 (Ash [1], see also [15, Sect. 15.3.3]). For a countable ordinal β
and a non-zero t ∈ω, we have ωβ · (t + 1) ≤2β+1 ωβ · t and ωβ+1 + ωβ + 1 ≤2β+2
ωβ+1 + 1.
It is well-known that ordinals behave nicely with respect to α-friendliness:
Lemma 2.2 ([15, Proposition 15.11]). Suppose that α, β0, β1, . . . , βn are com-
putable ordinals. Then there exists an α-friendly family {L0, L1, . . . , Ln} such
that for i ≤n, Li is isomorphic to βi.
3
Quasi-T C-Universality of W MB
Theorem 3.1. The class WMB is quasi-tc-universal.
Proof. First, we show that WMB is not universal for isomorphism under tc-em-
beddings. In order to prove this, we need the following fact:
Proposition 3.1. Assume that A ∈WMB and ωD(A)
1
= ωCK
1
. Then there is a
computable inﬁnitary sentence ξ such that A |= ξ, and for any linear order B,
B |= ξ implies B ∼= A.
Proof. Assume that A1 = A/B(A). Since the block relation is deﬁnable by a Σc
2
formula, the well-order A1 has a D(A)(2)-computable copy. In particular, A1 is
hyperarithmetical relative to D(A). Therefore, A1 is isomorphic to some ordinal
β < ωD(A)
1
= ωCK
1
.
For an element a ∈A, let the block of a be the set [a]B = {x : (x, a) ∈B(A)}.
In other words, a block in A is just an element of the quotient structure A1.
Notice that every block in A is isomorphic to one of the following orders: ω, ω∗,
ζ, or some non-zero k < ω.
Now we are ready to deﬁne the sentence ξ. Here we give only an informal
description of ξ. The omitted details can be easily reconstructed from [15]. We
build ξ such that:
(a) ξ says that the quotient of an order (modulo the block relation) is isomorphic
to β, and
(b) for every block b ∈A1, ξ describes the isomorphism type of b (which is one
of ω, ω∗, ζ, or k).
Since β is computable, one can use the formulas μ=
α and μ<
α , α < ωCK
1
, to
ensure that ξ is a computable inﬁnitary sentence. Moreover, the deﬁnition of ξ
guarantees that for an order B, we have B |= ξ iﬀB is isomorphic to A.
⊓⊔

Turing Computable Embeddings
147
Corollary 3.1. Let UG be the class of symmetric irreﬂexive graphs. Then we
have (UG, ∼=) ≰tc (WMB, ∼=).
Proof. In [9, Theorem 3.17], it was proved that there is a family of graphs
{Gβ : β < 2ℵ0} such that all of the graphs satisfy the same computable inﬁnitary
sentences, ωD(Gβ)
1
= ωCK
1
, and Gβ ≇Gγ for all β < γ.
By Proposition 3.1, the class WMB contains no pair described in Theo-
rem 2.1. Thus, Theorem 2.1 implies that there is no tc-embedding from (UG, ∼=)
into (WMB, ∼=).
⊓⊔
The next two propositions prove that for any computable α ≥5, WMB is
universal for Σc
α equivalence under tc-embeddings.
Proposition 3.2. Let α be a computable ordinal such that α ≥4. For any class
K, we have (K, ∼c
α+1) ≤tc (WMB, ∼c
α+1).
Proof. We ﬁx an eﬀective enumeration {ψn}n∈ω of all Σc
α+1 sentences in the
language of K. Suppose that A is a structure from K.
We give the detailed proof for the case α = 2β. By Lemma 2.2, one can
choose a (2β + 1)-friendly family {L1, L2} such that L1 ∼= ωβ and L2 ∼= ωβ · 2.
Recall that by Lemma 2.1, we have ωβ · 2 ≤2β+1 ωβ. Therefore, one can apply
the relativized version of Theorem 2.2 and produce a D(A)-computable sequence
{CA
n }n∈ω such that
CA
n ∼=

ωβ,
ifA ̸|= ψn,
ωβ · 2, ifA |= ψn.
Let ζ denote the order type of the integers. We deﬁne the order Φ(A) ∈WMB
as follows:
Φ(A) =

n∈ω
(ζ + CA
n ).
Note that here we slightly abuse the notation and identify Φ(A) and its natural
D(A)-computable copy.
We now show that Φ is a tc-embedding from (K, ∼c
α+1) into (WMB, ∼c
α+1).
Let A1, A2 ∈K. Note that A1 ∼c
α+1 A2 implies Φ(A1) ∼= Φ(A2). We deﬁne two
auxiliary formulas:
1. the Πc
3 formula Z(x) saying that the block of x is isomorphic to ζ:
Z(x) := ∀y[B(x, y) →[∃u(u < y & B(x, u)) & ∃v(y < v & B(x, v))]];
2. for n ∈ω, the Σc
5 formula Z(x; n) saying that x belongs to the n-th ζ-block:
Z(x; n) := ∃z0∃z1 . . . ∃zn[B(zn, x) & &i≤n Z(zi) & &i<n (zi < zi+1) &
&i̸=j ¬B(zi, zj) & ∀u((u ≤zn & Z(u)) →∨i≤n B(zi, u))].

148
N. Bazhenov
Assume that for some n ∈ω, we have A1 |= ψn and A2 ̸|= ψn. Recall that
2β + 1 = α + 1 ≥5. Consider the following Σc
2β+1 sentence:
ξn := ∃x∃y∃u∃v[Z(u; n) & Z(v; n + 1) & (u < x < y < v) & ¬B(u, x) &
¬B(y, v) & ¬μ<
β (x, y)].
Since CA1
n
∼= ωβ · 2 and CA2
n
∼= ωβ, we obtain that Φ(A1) |= ξn and Φ(A2) ̸|= ξn.
Thus, Φ(A1) ̸∼c
2β+1 Φ(A2).
Using the uniformity of Theorem 2.2, it is not diﬃcult to show that Φ is a
computable operator (i.e., Φ = ϕe for some e). Therefore, Φ is a tc-embedding
from (K, ∼c
α+1) into (WMB, ∼c
α+1).
The proof for the case α = 2β+1 is essentially the same, modulo the following
modiﬁcations:
– we use the orders (ωβ+1 + 1) and (ωβ+1 + ωβ + 1) in place of ωβ and ωβ · 2,
respectively;
– the subformula ¬μ<
β (x, y) in the sentence ξn should be replaced with the Πc
2β+1
formula ∀w(y < w < v →B(v, w))&μ=
β (x, y).
⊓⊔
Proposition 3.3. Let δ be a computable limit ordinal. For any class K, we have
(K, ∼c
δ) ≤tc (WMB, ∼c
δ).
Proof. First, we ﬁnd a computable sequence {αn}n∈ω of computable ordinals
with limit δ. Without loss of generality, we may assume that for any n, we have
αn = 2βn + 1 ≥5. Fix an eﬀective enumeration {ψn,k}n,k∈ω such that for any
n, {ψn,k}k∈ω is an enumeration of all Σc
αn sentences in the language of K.
Using essentially the same argument as in Proposition 3.2, one can build a
D(A)-computable sequence {CA
n,k}n,k∈ω such that
CA
n,k ∼=
ωβn,
ifA ̸|= ψn,k,
ωβn · 2, ifA |= ψn,k.
The order Φ(A) is deﬁned as follows:
Φ(A) =

⟨n,k⟩∈ω
(ζ + CA
n,k),
where ⟨n, k⟩is the G¨odel number of the pair (n, k).
Assume that A1, A2 ∈K. Notice that A1 ∼c
δ A2 iﬀA1 ∼c
αn A2 for all
n. Therefore, one can follow the lines of the proof of Proposition 3.2 and show
that A1 ∼c
δ A2 iﬀΦ(A1) ∼c
δ Φ(A2). The computability of Φ follows from the
uniformity of Theorem 2.2. We note here that the more formal version of the
proof can be obtained by using [15, Theorem 18.9] in place of Theorem 2.2. This
concludes the proof of Proposition 3.3 and Theorem 3.1.
⊓⊔

Turing Computable Embeddings
149
4
T C-Embeddings for Ordinals
For a computable ordinal β, we consider the following classes:
K2β+1 = {L : L ∼= ωβ · (t + 1) for some t ∈ω},
K2β+2 = {L : L ∼= ωβ+1 + ωβ · (t + 1) for some t ∈ω}.
Notice that K1 is the class of all ﬁnite linear orders. In this section, we sketch
the proof of the following:
Theorem 4.1. Suppose that α is a computable successor ordinal. For a class
K, we have (K, ∼=) ≤tc (Kα, ∼=) if and only if there exists a computable sequence
{ψn}0<n<ω of Σc
α sentences in the language of K such that
1. for A ∈K and m < n, if A |= ψn, then A |= ψm,
2. for A, B ∈K, if A ≇B, then there is some n such that ψn is true in only
one of A, B, and
3. for each A ∈K, there exists some n such that A ̸|= ψn.
Proof. We note here that for α = 1, this result was proved by Knight, Miller,
and Vanden Boom [7, Theorem 4.4]. For reasons of space, we give the proof only
for α = 2β + 1.
(⇒). Assume that for a non-zero n ∈ω, ξn is the Σc
2β+1 sentence:
ξn := ∃x1∃x2 . . . ∃xn+1[x1 < x2 < . . . < xn+1 & &i≤n ¬μ<
β (xi, xi+1)].
Suppose that (K, ∼=) ≤tc (K2β+1, ∼=) via Φ. We apply Pullback Theorem and
obtain computable sequence {ξ∗
n}n∈ω of Σc
2β+1 sentences in the language of K.
It is straightforward to show that the sequence {ξ∗
n}n∈ω satisﬁes the three prop-
erties above.
(⇐). First, we obtain the following generalization of Theorem 2.2:
Theorem 4.2. Suppose that α is a non-zero computable ordinal and {Ak : k ∈
ω} is an α-friendly family of L-structures such that Ak+1 ≤α Ak for all k.
Then for any 0(α)-limitwise monotonic function G(x), there is a uniformly c.e.
sequence of structures {Cn}n∈ω such that for each n, we have Cn ∼= AG(n).
For reasons of space, the proof of Theorem 4.2 is omitted. We emphasize that
this proof is uniform. In addition, in Theorem 4.1 one essentially does not need
general limitwise monotonic functions G(x): every function G that is used here is
constant. Nevertheless, Theorem 4.2 may be useful for more intricate construc-
tions.
Suppose that A ∈K and d = degT (D(A)). We deﬁne the d(2β+1)-limitwise
monotonic function GA: for all x, we have GA(x) = 1 + card({n : A |= ψn}).
Proposition 15.11 from [15] implies that there is a (2β + 1)-friendly family
{Lk : 0 < k < ω} such that Lt ∼= ωβ · t for all t. In addition, by Lemma 2.1, we
have ωβ · (t + 1) ≤2β+1 ωβ · t. Recall that any c.e. linear order is computable.

150
N. Bazhenov
Thus, we apply the relativized Theorem 4.2 to the function GA and obtain a
D(A)-computable structure Φ(A) ∼= ωβ · GA(0).
It is not diﬃcult to show that for A1, A2 ∈K, we have A1 ∼= A2 iﬀΦ(A1) ∼=
Φ(A2). As in Theorem 3.1, the computability of operator Φ follows from the
uniformity of Theorem 4.2. This concludes the proof of Theorem 4.1.
⊓⊔
Corollary 4.1. Suppose that α and β are computable successor ordinals. Then
we have (Kα, ∼=) ≤tc (Kβ, ∼=) iﬀα ≤β.
5
Further Discussion
Our results on linear orders are connected with other classes of structures:
Corollary 5.1
1. Let V S be the class of Q-vector spaces, and let FV S be the class of ﬁnite-
dimensional Q-vector spaces. Then we have (K2, ∼=)
≡tc
(FV S, ∼=)
⪇tc
(V S, ∼=).
2. Let E be the class of equivalence structures, each containing exactly one class
of each ﬁnite size and any number of inﬁnite classes. Then (K3, ∼=)
⪇tc
(E, ∼=).
Proof. This is a consequence of Theorem 4.1, and Theorems 4.7, 4.13, Proposi-
tion 4.9 from [7].
⊓⊔
Following the lines of Theorem 4.1, it is not diﬃcult to prove:
Corollary 5.2. For a computable ordinal β, let SBAβ be the class of all super-
atomic Boolean algebras with the Fr´echet rank β. Then we have (SBAβ+1, ∼=) ≡tc
(K2β+1, ∼=).
In conclusion, we formulate two open questions:
Problem 5.1. Is the class of well-orders quasi-tc-universal?
Problem 5.2. For a computable limit ordinal α, ﬁnd natural classes Kα that
satisfy Theorem 4.1.
Acknowledgements. The author is grateful to Sergey Goncharov for fruitful discus-
sions on the subject. The author also thanks the anonymous reviewers for their helpful
suggestions. The reported study was funded by RFBR, according to the research project
No. 16-31-60058 mol a dk.

Turing Computable Embeddings
151
References
1. Ash, C.J.: Recursive labelling systems and stability of recursive structures in hyper-
arithmetical degrees. Trans. Am. Math. Soc. 298(2), 497–514 (1986). doi:10.1090/
S0002-9947-1986-0860377-7
2. Hirschfeldt, D.R., Khoussainov, B., Shore, R.A., Slinko, A.M.: Degree spectra and
computable dimensions in algebraic structures. Ann. Pure Appl. Logic 115(1–3),
71–113 (2002). doi:10.1016/S0168-0072(01)00087-2
3. Calvert, W., Cummins, D., Knight, J.F., Miller, S.: Comparing classes of ﬁnite
structures. Algebra Logic 43(6), 374–392 (2004). doi:10.1023/B:ALLO.0000048827.
30718.2c
4. Fokina, E.B., Friedman, S.-D.: On Σ1
1 equivalence relations over the natural num-
bers. Math. Log. Q. 58(1–2), 113–124 (2012). doi:10.1002/malq.201020063
5. Harrison-Trainor, M., Melnikov, A., Miller, R., Mont´alban, A.: Computable func-
tors and eﬀective interpretability. J. Symbolic Logic (to appear). doi:10.1017/jsl.
2016.12
6. Friedman, H., Stanley, L.: A Borel reducibility theory for classes of countable
structures. J. Symbolic Logic 54(3), 894–914 (1989). doi:10.2307/2274750
7. Knight, J.F., Miller, S., Vanden Boom, M.: Turing computable embeddings. J.
Symbolic Logic 72(3), 901–918 (2007). doi:10.2178/jsl/1191333847
8. Chisholm, J., Knight, J.F., Miller, S.: Computable embeddings and strongly
minimal theories. J. Symbolic Logic 72(3), 1031–1040 (2007). doi:10.2178/jsl/
1191333854
9. Fokina, E., Knight, J.F., Melnikov, A., Quinn, S.M., Safranski, C.: Classes of Ulm
type and coding rank-homogeneous trees in other structures. J. Symbolic Logic
76(3), 846–869 (2011). doi:10.2178/jsl/1309952523
10. Ocasio-Gonz´alez, V.A.: Turing computable embeddings and coding families of sets.
In: Cooper, S.B., Dawar, A., L¨owe, B. (eds.) CiE 2012. LNCS, vol. 7318, pp. 539–
548. Springer, Heidelberg (2012). doi:10.1007/978-3-642-30870-3 54
11. Andrews, U., Dushenin, D.I., Hill, C., Knight, J.F., Melnikov, A.G.: Compar-
ing classes of ﬁnite sums. Algebra Logic 54(6), 489–501 (2016). doi:10.1007/
s10469-016-9368-7
12. VanDenDriessche, S.M.: Embedding computable inﬁnitary equivalence into p-
groups. Ph.D. thesis, University of Notre Dame (2013)
13. Wright, M.: Turing computable embeddings of equivalences other than iso-
morphism.
Proc.
Am.
Math.
Soc.
142,
1795–1811
(2014).
doi:10.1090/
S0002-9939-2014-11878-8
14. Goncharov, S.S.: Groups with a ﬁnite number of constructivizations. Sov. Math.
Dokl. 23, 58–61 (1981)
15. Ash, C.J., Knight, J.F.: Computable structures and the hyperarithmetical hierar-
chy. In: Studies in Logic and the Foundations of Mathematics, vol. 144. Elsevier
Science B.V., Amsterdam (2000)
16. Knight, J.F.: Using computability to measure complexity of algebraic structures
and classes of structures. Lobachevskii J. Math. 35(4), 304–312 (2014). doi:10.
1134/S1995080214040192
17. Ash, C.J., Knight, J.F.: Pairs of recursive structures. Ann. Pure Appl. Logic 46(3),
211–234 (1990). doi:10.1016/0168-0072(90)90004-L

Degrees of Categoricity of Rigid Structures
Nikolay A. Bazhenov1,2(B)
and Mars M. Yamaleev3(B)
1 Sobolev Institute of Mathematics, Novosibirsk, Russia
2 Novosibirsk State University, Novosibirsk, Russia
bazhenov@math.nsc.ru
3 Kazan (Volga Region) Federal University, Kazan, Russia
Mars.Yamaleev@kpfu.ru
Abstract. We prove that there exists a properly 2-c.e. Turing degree d
which cannot be a degree of categoricity of a rigid structure.
Keywords: Categoricity spectrum · Strong degree of categoricity ·
Rigid structure · 2-c.e. Turing degrees
1
Introduction
The study of eﬀective categoricity for computable structures goes back to the
works of Fr¨ohlich and Shepherdson [1], and Mal’tsev [2,3]. In recent years, the
focus of the research in the area is on computable categoricity relative to Turing
degrees.
Deﬁnition 1. Let d be a Turing degree. A computable structure A is d-compu-
tably categorical if for every computable copy B of A, there is a d-computable
isomorphism from A onto B. The categoricity spectrum of A is the set
CatSpec(A) = {d : A is d-computably categorical}.
A Turing degree d is the degree of categoricity of A if d is the least degree in
the spectrum CatSpec(A).
Categoricity spectra and degrees of categoricity were introduced in [4]. Sup-
pose that n is a natural number and α is an inﬁnite computable ordinal. Fokina,
Kalimullin, and Miller [4] proved that each Turing degree d that is 2-c.e. in
and above 0(n) is the degree of categoricity for a computable structure. Csima,
Franklin, and Shore [5] extended this result to hyperarithmetical degrees. They
N.A.Bazhenov—Supported by RFBR project No. 16-31-60058 mol a dk.
M.M.Yamaleev—Supported by RFBR projects No. 15-01-08252, 16-31-50048, and
by the subsidy allocated to Kazan Federal University for the state assignment in the
sphere of scientiﬁc activity (No. 1.1515.2017/PCh). The work is performed accord-
ing to the Russian Government Program of Competitive Growth of Kazan Federal
University and by the research grant of Kazan Federal University.
c
⃝Springer International Publishing AG 2017
J. Kari et al. (Eds.): CiE 2017, LNCS 10307, pp. 152–161, 2017.
DOI: 10.1007/978-3-319-58741-7 16

Degrees of Categoricity of Rigid Structures
153
proved that each degree d that is 2-c.e. in and above 0(α+1) is a degree of cat-
egoricity. Anderson and Csima [6] investigated Turing degrees that cannot be
degrees of categoricity. In particular, they constructed a Σ0
2-set whose degree is
not a degree of categoricity. Miller [7] built the ﬁrst example of a computable
structure without a degree of categoricity. Much work has been done of late
in investigating categoricity spectra for structures in familiar classes: algebraic
ﬁelds [7,8], Boolean algebras [9–12], linear orderings [13,14], rigid structures [15],
decidable structures [16,17], etc.
Deﬁnition 2 ([4]). Assume that A is a computable structure. A Turing degree
d is the strong degree of categoricity of A if d is the degree of categoricity for A,
and there exist computable copies B and C of A such that for each isomorphism
f from B onto C, we have degT (f) ≥d.
Fokina, Frolov, and Kalimullin [15] proved that for each non-zero c.e. Turing
degree d, there is a d-computably categorical rigid structure with no degree of
categoricity. They also posed the following question.
Problem 1 ([15, Problem 3.2]).
Can a properly 2-c.e. degree be a degree of
categoricity of a rigid structure?
In this work, we make the ﬁrst step towards the solution of Problem 1.
Namely, we prove the following result.
Theorem 1. There exists a properly 2-c.e. degree d which cannot be a degree
of categoricity of a rigid structure.
In the next section, we give some special deﬁnitions which will be involved
in the proof. The third section will be devoted to the proof of the main result.
2
Preliminaries
By reducibility we always mean Turing reducibility, and we consider only Turing
degrees.
Now we recall the notion of spectral dimension. This notion allows to make a
distinction between “degree of categoricity” and “strong degree of categoricity”
using a quantitative characteristic.
Assume that A and B are isomorphic computable structures. The isomor-
phism spectrum of the pair (A, B) is the set
IsoSpec(A, B) = {d : there is a d-computable isomorphism from A onto B}.
Note that we always have CatSpec(A) ⊆IsoSpec(A, B).
Deﬁnition 3 ([18]). Let S be a computable structure. The spectral dimension
of S is the least ordinal k ≤ω such that there exists a sequence of pairs of
computable structures {(Ai, Bi)}0≤i<k with the following properties: Ai ∼= Bi ∼= S
for all i < k, and
CatSpec(S) =

i<k
IsoSpec(Ai, Bi).
Let SpecDim(S) denote the spectral dimension of S.

154
N.A. Bazhenov and M.M. Yamaleev
Suppose that d is the degree of categoricity of a structure S. It is easy
to see that d is the strong degree of categoricity of S if and only if S has
spectral dimension one. Furthermore, if we consider degrees of categoricity for
rigid structures (recall that a rigid structure has a single element in its group
of automorphisms), then we can work only with ﬁnite spectral dimensions (see
Theorem 2 below).
Theorem 2 ([18, Theorem 3.1]). Suppose that S is a computable structure
with ﬁnite automorphism group, and d is the degree of categoricity for S. Then
SpecDim(S) < ω.
3
Main Result
The next theorem shows that there is a properly 2-c.e. degree which cannot be
a strong degree of categoricity for a rigid structure. In the course of the proof
we will add comments in italicized parentheses. They are not properly part of
the formal proof and are intended to make the intuition clearer.
Theorem 3. There exists a 2-c.e. degree deg(D) that satisﬁes the following
condition: for any computable structures A, B and any Δ0
2 isomorphism g from
A onto B, the condition deg(g) = deg(D) implies that there exist a computable
structure N and an isomorphism f from A onto N with deg(f) ̸≤deg(D).
Note that if a computable structure A is rigid and deg(D) is its strong degree
of categoricity then the degrees of the isomorphisms between any computable
copies of A must be below deg(D). The left-hand side of this implication contra-
dicts Theorem 3 and we obtain the desired deg(D). In fact, Theorem 3 can be
easily generalized to the case of any ﬁnite spectral dimension. Now we present
the simplest version (for the case when the spectral dimension is equal to one)
since it describes ideas in a neat way. Then we will show how these ideas can
be transferred to the case of a ﬁnite spectral dimension. Finally, together with
Theorem 2 we obtain that there is a 2-c.e. degree which is not a degree of cat-
egoricity for a rigid structure. Recall that Fokina, Kalimullin, and Miller [4,
Theorem 2.1] proved that any c.e. degree is a strong degree of categoricity for
some rigid structure. Thus, the degree of D from Theorem 3 is automatically a
properly 2-c.e. degree.
Proof. First, we give some preliminary information regarding structures. During
the construction we need to eﬀectively enumerate all pairs of computable struc-
tures which are Δ0
2-isomorphic. Thus, we ﬁx a strongly computable sequence of
ﬁnite objects {Ae[s], Be[s], ge[s]}e,s∈ω such that the following conditions hold:
(A) For all e and s, we have:
(1) Ae[s] and Be[s] are ﬁnite graphs,
(2) Ae[s] ⊆Ae[s + 1],
(3) Be[s] ⊆Be[s + 1],

Degrees of Categoricity of Rigid Structures
155
(4) ge[s]: Ae[s] ∼= Be[s].
(Note that ge[s] can be taken as ΦK
e [s] in order to cover all Δ0
2 isomor-
phisms. However, some indices e can correspond to Σ0
2-functions).
(B) If A ∼= B are inﬁnite computable graphs and g: A ∼= B is Δ0
2, then there is
an index e such that:
(1) A = ∪sAe[s],
(2) B = ∪sBe[s],
(3) g = lims ge[s].
(Obviously, it is enough to consider only graphs, since the class of graphs
is universal relative to categoricity spectra [4, Proposition 4.1].)
Thus, in the course of the construction we enumerate all pairs of (partial)
computable graphs. If we suspect that the corresponding isomorphism is Turing
equivalent to D, then we build N and f for that particular tuple. Since our
suspicions will arise only at some kind of expansionary stages, we need to deﬁne
N and f only at those stages. Before the construction, we give some information
on stages.
Assume that t < s are two consecutive expansionary stages. At stage s we
have Ne[t], fe[t], Ae[t], Be[t], ge[t], Ae[s], Be[s], and ge[s]. Thus, we need to deﬁne
Ne[s] and fe[s]. Consider the following two functions: hg[s] = g−1
e [s] ◦idBe[t] ◦
ge[t] ◦f −1
e
[t] and hid[s] = idAe[t] ◦f −1
e
[t]. Each of the functions is an isomorphic
embedding of Ne[t] into Ae[s]. Clearly, we can extend the function hid[s] (the
function hg[s], respectively) to the isomorphism Hid (Hg, respectively) from
Ne[s] onto Ae[s], where Ne[s] is an initial segment of ω (this can be done if Ne[t]
is also an initial segment of ω). Thus, we have two ways to deﬁne fe[s]:
(1) If fe[s] = H−1
id , then we say that fe[s] is the id-extension of fe[t].
(2) If fe[s] = H−1
g , then we say that fe[s] is the g-extension of fe[t].
Note that if fe[s] is a g-extension and ge(y0)[t] ̸= ge(y0)[s] for some y0 ∈Ae[t]
then fe(y0)[s] = h−1
g (y0)[s] ̸= fe(y0)[t].
The purpose of the priority construction is to choose one of these two exten-
sions when we really need to extend the function (e.g., when a stage is expan-
sionary for the corresponding tuple).
We make some standard assumptions for the priority argument: e.g., we
assume that each functional is nondecreasing in each of its arguments, and the
standard notation P[s] means that all parameters in P use their approximations
at stage s. When we talk about a Turing reduction to a function g, we mean
the reduction to the graph Grg = {⟨x, y⟩: g(x) = y}. Recall that at stage s we
have ge[s] which is an isomorphism from Ae[s] onto Be[s]. Thus, if we want to
see that this isomorphism grew, then we can wait until {0, 1, . . . , x} ⊆Ae[s]; in
particular, this means that ge(0), . . . , ge(x) are deﬁned.
Requirements. We need to satisfy the following series of requirements:
Re : (ge : Ae ∼= Be) ∧(ge is Δ0
2) ∧(D = Φge
e ) ∧(ge = ΘD
e ) ⇒
∃fe, Ne such that fe : Ae ∼= Ne and fe ̸≤T D,

156
N.A. Bazhenov and M.M. Yamaleev
where the list {Ae, Be, ge, Φe, Θe}e∈ω eﬀectively enumerates all mentioned above
triples (Ae[s], Be[s], ge[s]) and p.c. functionals Φe and Θe. The subrequirement
fe ̸≤T D is transformed into an inﬁnite series (where {Ψi}i∈ω is an enumeration
of all p.c. functionals):
Pe,i : fe ̸= Ψ D
i .
For the sake of convenience and organizing the strategies, we will construct
a single copy of fe and Ne for each e ∈ω. Thus, it will be a global requirement.
However, if the condition (ge : Ae ∼= Be) ∧(ge is Δ0
2) ∧(D = Φge
e ) ∧(ge = ΘD
e ) is
not true, then we do not need to ensure that fe and Ne are correct. We construct
them according to the highest priority strategy Se,i with index e which requires
attention.
(Also note that we can alternatively use Re as the mother strategy with out-
comes ∞and fin on a tree of strategies, where below the ∞-outcome we arrange
its child strategies Pe,i and construct fe and Ne. However, in our particular case,
we can use a ﬁnite injury argument, and we do not need the power of the tree
construction.)
Henceforth, we will build a 2-c.e. set D and a sequence of pairs {fe, Ne}e∈ω.
We satisfy the inﬁnite series of the following requirements:
Se,i : (ge : Ae ∼= Be) ∧(ge is Δ0
2) ∧(D = Φge
e ) ∧(ge = ΘD
e ) ⇒fe ̸= Ψ D
i .
Intuition for a single strategy. In a standard manner, by lower-case Greek
letters we denote use-functions of the corresponding p.c. functionals. W.l.o.g, we
assume the following: if ΦX(x) ↓, then ΦX(y) ↓for all y < x and ϕ(y) < ϕ(x).
We deﬁne the length agreement functions as follows.
The major length agreement function of Se,i:
L(e)[s] = max

x : (∀y ≤x)

Φge
e (y)[s] = D(y)[s]

∧

∀z < ϕe(y)[s]

ΘD
e (z)[s] = ge(z)[s]

∧

{0, 1, . . . , ϕe(y)[s]} ⊆Ae[s]

.
The minor length agreement function of Se,i:
l(e, i)[s] = max
	
x : (∀y ≤x)

fe(y)[s] = Ψ D
i (y)[s]

.
Note that the major length agreement function of Se,i serves us similarly to
the usual length agreement function of the mother strategy Re and it plays a
global role for strategies Se,i. Thus, we proceed to considering the minor length
agreement function of Se,i only when we successfully pass its major length agree-
ment function. The minor length agreement function of Se,i plays a local role
and directly helps to satisfy Se,i.
Our intuition for the strategy Se,i in isolation is as follows. By a “big” num-
ber we mean an integer which is greater than all numbers mentioned in the
construction so far (in particular, it is greater than all use-functions which we
currently want to preserve). We omit indices if they are clear from the context.

Degrees of Categoricity of Rigid Structures
157
(1) Assign a “big” witness x = xe,i.
(2) Wait for a stage s0 such that x < L(e)[s0].
(Stage s0 can be considered as an analogue of usual expansionary stages.
However, it is a stage when we must deﬁne an extension of the current fe.)
(3) Deﬁne fe[s0] as the id-extension of fe[0].
(After seeing that ge grew enough, at least up to ϕe(x)[s0], we must extend
fe too.)
(4) Wait for a stage s1 > s0 such that ϕe(x)[s1] = ϕe(x)[s0] < l(e, i)[s1].
(Now we want to witness the equalities for fe[s0] in the parts where we
extended fe, note that x < L(e)[s1]. In fact, ϕe(x)[s1] < l(e, i)[s1] is a pretty
rough bound, but it is enough. The same roughness holds for functions ge[s]:
we need only ge(z)[s] = ΘD
e (z)[s] for all z such that ⟨z, ge(z)⟩< ϕe(x)[s]
(which is in Grge[s]) instead of all z < ϕe(x)[s]. Anyway, if Grge[s] changes
below ϕe(x)[s], then ge[s] also changes at some point below ϕe(x)[s].)
(5) Enumerate x into D.
(Thus, either the strategy is diagonalized forever or Grge changes at a later
stage at some number below ϕe(x)[s0]. Therefore, if Grge changes below
ϕe(x)[s0], then ge will also change at some y0 < ϕe(x)[s0], and this will
allow us to modify fe(y0) by deﬁning fe as the g-extension of fe[s0]. Note
that it is not necessary to extend fe here.)
(6) Wait for a stage s2 > s1 such that x < L(e)[s2].
(Similarly to item (2), at stage s2 it is time to deﬁne fe[s2]. We deﬁne
it as the g-extension of fe[s0]. This gives a new value for some y0 <
ϕe(x)[s0]. Moreover, this means that Ψ D
i (y0) could change and become equal
to fe(y0)[s1] again. Thus, we are forced to return D to its old state by
extracting x from D.)
(7) Extract x from D and deﬁne fe[s2] as the g-extension of fe[s0].
(Note that this extraction may allow ge(y0) to change back. Thus, the next g-
extension of fe can change it back too. However, in this case we deﬁne fe[s3]
as the id-extension of fe[s2], unless one of the higher priority strategies
does something diﬀerent. Note that fe(y0) can be changed only because of
g-extension and it can happen only due to the higher priority strategies.)
Notice that the strategy is pretty similar to the construction of a properly 2-
c.e. degree, but it has some additional features. We use the ﬁnite injury argument
and put all the S-requirements into a priority list. We say that Se,i has higher
priority than Se′,i′ if ⟨e′, i′⟩> ⟨e, i⟩.
When we initialize a strategy, we cancel its declaration about satisfaction
and we also cancel its witness. For each e ∈ω, we build only one copy of Ne
and fe. The auxiliary parameter s−
e denotes the previous expansionary stage
(namely, s−
e [s] = s′ is the previous stage at which we deﬁned Ne[s′] and fe[s′]).
If we do not redeﬁne s−
e explicitly, then its value is not changed. Recall that we
deﬁne fe[s] either as id-extension of fe[s′] or as g-extension of fe[s′], meanwhile
Ne[s] is deﬁned automatically as the corresponding initial segment.
We say that Se,i requires attention at stage s + 1 if it is not satisﬁed and one
of the following conditions holds (we choose ﬁrst case which applies):

158
N.A. Bazhenov and M.M. Yamaleev
(σ1) x[s] is not deﬁned.
(σ2) x[s] ̸∈D[s], x[s] < L(e)[s], and fe(y)[s−
e [s]] is undeﬁned for some y <
ϕe(x)[s].
(σ3) x[s] ̸∈D[s], x[s] < L(e)[s], and ϕe(x)[s] < l(e, i)[s].
(σ4) x[s] ∈D[s] and x[s] < L(e)[s].
(Note that we need to deﬁne fe and Ne only in cases (σ2) and (σ4).)
Construction. Stage 0. We deﬁne D[0] = ∅, s−
e [0] = −1, Ne[−1] = ∅, and
fe[−1] = ∅, for all e ∈ω. We initialize all strategies.
Stage s+1. Find the least ⟨e, i⟩such that Se,i requires attention at stage s+1.
Initialize all lower priority strategies. Consider cases in the following ordering,
and act according to ﬁrst case which applies, then proceed to the next stage
s + 2.
(1) If Se,i requires attention due to case (σ1), then deﬁne witness x[s + 1] as a
“big” number.
(2) If Se,i requires attention due to case (σ2), then deﬁne Ne[s] and fe[s] in
such a way that fe[s] is the id-extension of fe[s−], and fe[s]: Ae[s] ∼= Ne[s].
Deﬁne s−
e [s + 1] = s.
(Here s−= s−
e [s], and s−+1 is the previous stage such that a strategy Se,i0
(for some i0) required attention due to (σ2) or (σ4).)
(3) If Se,i requires attention due to case (σ3), then put x into D (in other words,
deﬁne D(x)[s + 1] = 1).
(4) If Se,i requires attention due to case (σ4), then extract x from D (in other
words, deﬁne D(x)[s + 1] = 0). Deﬁne Ne[s] and fe[s] in such a way that
fe[s] is the ge-extension of fe[s−], and fe[s]: Ae[s] ∼= Ne[s]. Set s−
e [s+1] = s
and declare that Se,i is satisﬁed.
(Again, here s−= s−
e [s], and s−+1 is the previous stage at which Se,i0 (for
some i0) required attention due to (σ2) or (σ4).)
Veriﬁcation. It is easy to see that D is a 2-c.e. set by construction. We prove
by induction that all S-requirements are satisﬁed, then we show that all R-
requirements are satisﬁed too.
Since the base step of the induction is a simpler case of an inductive step,
we only prove the latter. Assume that requirements Se′,i′ are satisﬁed for all
⟨e′, i′⟩< ⟨e, i⟩. We will prove that Se,i is also satisﬁed. By inductive assumption,
ﬁx a stage s0 such that all higher priority strategies are declared to be satisﬁed.
Thus, Se,i is not initialized after stage s0. So, assume that the ﬁnal witness
x = xe,i[s1] was chosen at stage s1 > s0.
If Se,i will not require attention after s1, then it is satisﬁed vacuously: either
ge is not a Δ0
2 isomorphism from Ae onto Be, or D ̸= Φge
e , or ge ̸= ΘD
e .
(Note also that ge can be Σ0
2: it is possible that for some z, ge(z)[s] changes
inﬁnitely often. This does not allow us to see the true state of the oracle of
computation Φge
e ; however, in this case, the requirements Se,j, j ∈ω , are obsolete
and they do not need to be satisﬁed.)

Degrees of Categoricity of Rigid Structures
159
Assume that the left-hand side of Se,i is true. Then the strategy can require
attention at most three times. If Se,i requires the next attention after s1, then
this must be due to case (σ2), say at stage s2 +1 > s1. Indeed, this is a corollary
of the following properties: x ̸∈D[s2] and fe cannot be deﬁned up to ϕe(x)[s2]
(recall that for each stage t at which a higher priority strategy required attention,
x was chosen as a “big” number after stage t; in particular, x is greater than
every number from the range of fe[s0]). Thus, at the stage s2 + 1 we extend
fe[s2] as an id-extension. Stages of this kind (for Se,j, j ∈ω) ensure that Ne is
an inﬁnite structure and fe is an isomorphism from Ae onto Ne (if the left-hand
side of the requirement Re is true). Moreover, the range of fe[s2 + 1] became
bigger than ϕe(x)[s2].
The next attention (at some stage s3 + 1 > s2 + 1) can appear if fe(y)[s3] =
Ψ D
i (y)[s3] for all y ≤ϕe(x)[s2]. If this attention does not happen, then Se,i is
satisﬁed by easy diagonalization. Thus, x goes into D at stage s3 + 1 by case (3)
of construction.
Since at stages s2 + 1 and s3 + 1 we initialized all lower priority strategies,
no number less than θe(ϕe(x))[s2] can enter D or exit D after stage s2 (except
x; also recall that now the higher priority strategies do not act and all the
lower priority strategies have witnesses > θe(ϕe(x))[s2]). Now assume that the
last attention happens at stage s4 + 1 > s3 + 1. Thus, we declare that our
requirement is satisﬁed and henceforth, Se,i does not initialize other strategies.
Moreover, the following situation is impossible: for some j > i, the strategy
Se,j requires attention due to one of cases (σ2) or (σ4) after stage s3 + 1 and
before stage s4 + 1 (since the truth of (σ2) for Se,j implies the truth of (σ4)
for Se,i). Thus, we have ge[s2] ↾ϕe(x)[s2] ̸= ge[s4] ↾ϕe(x)[s2] (otherwise, 0 =
D(x)[s2] = D(x)[s4] = 1). This allows us to deﬁne the ge-extension of fe[s2];
thus, fe[s2] ↾ϕe(x)[s2] ̸= fe[s4] ↾ϕe(x)[s2]. Also, by case (4) of the construction,
we deﬁne D(x)[s4 + 1] = 0.
However, another important point is that
D ↾(θe(ϕe(x))[s2]) = D[s4 + 1] ↾θe(ϕe(x))[s2] = D[s2] ↾θe(ϕe(x))[s2],
hence ge[s−
e [s]] ↾ϕe(x)[s2] = ge[s4] ↾ϕe(x)[s2] for all s > s4 + 1 and so
fe[s−
e [s]] ↾ϕe(x)[s2] = fe[s4] ↾ϕe(x)[s2].
Therefore,
fe ↾(ϕe(x)[s2]) = fe[s4] ↾ϕe(x)[s2] ̸= fe[s2] ↾ϕe(x)[s2] =
Ψ D
i [s2] ↾ϕe(x)[s2] = Ψ D
i
↾(ϕe(x)[s2]),
since D[s4+1] ↾ψi(ϕe(x))[s2] = D[s2] ↾ψi(ϕe(x))[s2] will not change after s4+1
(unless our Se,i is initialized). Thus, Se,i is satisﬁed.
(Recall also that all new witnesses will be greater than ψi(ϕe(x))[s2]. Hence,
the value of fe[s4] ↾ϕe(x)[s2] will not change after stage s4 + 1, since ge[s4] ↾
ϕe(x)[s2] will not change after stage s4 + 1 since all new witnesses for D will be
greater than θe(ϕe(x))[s2] too.)

160
N.A. Bazhenov and M.M. Yamaleev
We proceed to the R-requirements. Consider a requirement Re. Assume that
ge is an isomorphism from Ae onto Be, and the left-hand side of Re is true
(otherwise, Re is satisﬁed trivially). Since Se,i are satisﬁed for all i ∈ω, we have
fe ̸≤T D. Moreover, there is an inﬁnite series of stages s−
e [s] = s at which we
have fe[s]: Ae[s] ∼= Ne[s], by construction. Also, if ge is Δ0
2, then fe = lims fe[s].
Therefore, if ge : Ae ∼= Be, then fe : Ae ∼= Ne. Hence, all R-requirements are
satisﬁed. This ﬁnishes the veriﬁcation and the proof of Theorem 3.
Remark. Now we can sketch how to prove the result for any ﬁnite spectral
dimension. For each non-zero n, we consider n pairs of (partial) computable
graphs: (A0
e, B0
e), (A1
e, B1
e), . . . , (An
e , Bn
e ). We also consider ge = g0
e ⊕g1
e ⊕. . .⊕gn
e ,
where gi
e is a Δ0
2 isomorphism from Ai
e onto Bi
e. We construct fe = f 0
e ⊕f 1
e ⊕
. . . ⊕f n
e . For each Ai
e, we reserve its own N i
e. This means that whenever gi
e
changes, we have an opportunity to change f i
e. Thus, eventually we will ensure
that f 0
e ⊕f 1
e ⊕. . . ⊕f n
e ≰T D. From this we deduce that f i0
e
≰T D for some
i0 ≤n.
Assume that S is a rigid structure and deg(D) is the degree of categoricity
of S. By Theorem 2, one can ﬁnd a non-zero natural number N and a sequence
of computable structures (Ai, Bi)0≤i<N with the following properties:
1. Ai ∼= Bi ∼= S, and
2. if gi is the (unique) isomorphism from Ai onto Bi, then we have d = deg(g0 ⊕
g1 ⊕. . . ⊕gn).
On the other hand, the construction sketched above guarantees that there is
a computable copy N i such that the isomorphism from Ai onto N i is not D-
computable; a contradiction. Therefore, deg(D) cannot be a degree of categoric-
ity of a rigid structure.
References
1. Fr¨ohlich, A., Shepherdson, J.C.: Eﬀective procedures in ﬁeld theory. Phil. Trans.
R. Soc. Lond. A 248(950), 407–432 (1956)
2. Mal’tsev, A.I.: Constructive algebras. I. Russ. Math. Surv. 16(3), 77–129 (1961)
3. Mal’tsev, A.I.: On recursive abelian groups. Sov. Math. Dokl. 32, 1431–1434 (1962)
4. Fokina, E.B., Kalimullin, I., Miller, R.: Degrees of categoricity of computable struc-
tures. Arch. Math. Logic 49(1), 51–67 (2010)
5. Csima, B.F., Franklin, J.N.Y., Shore, R.A.: Degrees of categoricity and the hyper-
arithmetic hierarchy. Notre Dame J. Form. Logic 54(2), 215–231 (2013)
6. Anderson, B.A., Csima, B.F.: Degrees that are not degrees of categoricity. Notre
Dame J. Form. Logic 57(3), 389–398 (2016)
7. Miller, R.: d-computable categoricity for algebraic ﬁelds. J. Symb. Log. 74(4),
1325–1351 (2009)
8. Miller, R., Shlapentokh, A.: Computable categoricity for algebraic ﬁelds with split-
ting algorithms. Trans. Amer. Math. Soc. 367(6), 3955–3980 (2015)
9. Bazhenov, N.A.: Degrees of categoricity for superatomic Boolean algebras. Algebra
Logic 52(3), 179–187 (2013)

Degrees of Categoricity of Rigid Structures
161
10. Bazhenov, N.A.: Δ0
2-categoricity of Boolean algebras. J. Math. Sci. 203(4), 444–
454 (2014)
11. Bazhenov, N.A.: Autostability spectra for Boolean algebras. Algebra Logic 53(6),
502–505 (2015)
12. Bazhenov, N.A.: Degrees of autostability relative to strong constructivizations for
Boolean algebras. Algebra Logic 55(2), 87–102 (2016)
13. Frolov, A.N.: Eﬀective categoricity of computable linear orderings. Algebra Logic
54(5), 415–417 (2015)
14. Bazhenov, N.A.: Degrees of autostability for linear orders and linearly ordered
abelian groups. Algebra Logic 55(4), 257–273 (2016)
15. Fokina, E., Frolov, A., Kalimullin, I.: Categoricity spectra for rigid structures.
Notre Dame J. Form. Logic. 57(1), 45–57 (2016)
16. Goncharov, S.S.: Degrees of autostability relative to strong constructivizations.
Proc. Steklov Inst. Math. 274, 105–115 (2011)
17. Bazhenov, N.A.: Autostability spectra for decidable structures. Math. Struct. Com-
put. Sci. (to appear). doi:10.1017/S096012951600030X.
18. Bazhenov, N.A., Kalimullin, I., Yamaleev, M.M.: Degrees of categoricity vs. strong
degrees of categoricity. Algebra Logic 55(2), 173–177 (2016)

Flexible Indexing of Repetitive Collections
Djamal Belazzougui1, Fabio Cunial2(B), Travis Gagie3, Nicola Prezza4,
and Mathieu Raﬃnot5
1 DTISI-CERIST, Algiers, Algeria
dbelazzougui@cerist.dz
2 MPI-CBG, Dresden, Germany
cunial@mpi-cbg.de
3 UDP and CeBiB, Santiago, Chile
travis.gagie@mail.udp.cl
4 DTU, Copenhagen, Denmark
npre@dtu.dk
5 CNRS, Bordeaux, France
mathieu.raffinot@u-bordeaux.fr
Abstract. Highly repetitive strings are increasingly being amassed by
genome sequencing experiments, and by versioned archives of source code
and webpages. We describe practical data structures that support count-
ing and locating all the exact occurrences of a pattern in a repetitive
text, by combining the run-length encoded Burrows-Wheeler transform
(RLBWT) with the boundaries of Lempel-Ziv 77 factors. One such variant
uses an amount of space comparable to LZ77 indexes, but it answers count
queries between two and four orders of magnitude faster than all LZ77 and
hybrid index implementations, at the cost of slower locate queries. Com-
bining the RLBWT with the compact directed acyclic word graph answers
locate queries for short patterns between four and ten times faster than a
version of the run-length compressed suﬃx array (RLCSA) that uses com-
parable memory, and with very short patterns our index achieves speedups
even greater than ten with respect to RLCSA.
1
Introduction
Locating and counting all the exact occurrences of a pattern in a massive,
highly repetitive collection of similar texts is a fundamental primitive in the
post-genome era, in which genomes from multiple related species, from multiple
strains of the same species, or from multiple individuals, are being sequenced
at an increasing pace. Most data structures designed for such repetitive collec-
tions take space proportional to a speciﬁc measure of repetition, for example
the number z of factors in a Lempel-Ziv parsing [1,15], or the number r of runs
in a Burrows-Wheeler transform [17]. In previous work we achieved competitive
theoretical tradeoﬀs between space and time in locate queries, by combining
data structures that depend on multiple measures of repetition that all grow
sublinearly in the length of a repetitive string [3]. Speciﬁcally, we described
a data structure that takes approximately O(z + r) words of space, and that
c
⃝Springer International Publishing AG 2017
J. Kari et al. (Eds.): CiE 2017, LNCS 10307, pp. 162–174, 2017.
DOI: 10.1007/978-3-319-58741-7 17

Flexible Indexing of Repetitive Collections
163
reports all the occurrences of a pattern of length m in a text of length n in
O(m(log log n+log z)+pocc·logϵ z +socc·log log n) time, where pocc and socc
are the number of primary and of secondary occurrences, respectively (deﬁned in
Sect. 2). This compares favorably to the reporting time of Lempel-Ziv 77 (LZ77)
indexes [15], and to the space of solutions based on the run-length encoded
Burrows-Wheeler transform (RLBWT) and on suﬃx array samples [17]. We
also introduced a data structure whose size depends on the number of right-
extensions of maximal repeats, and that reports all the occ occurrences of a
pattern in O(m log log n + occ) time. The main component of our constructions
is the RLBWT, which we use for counting the number of occurrences of a pat-
tern, and which we combine with the compact directed acyclic word graph, and
with data structures from LZ indexes, rather than with suﬃx array samples, for
answering locate queries. In this paper we describe and implement a range of
practical variants of such theoretical approaches, and we compare their space-
time tradeoﬀs to a representative set of state-of-the-art indexes for repetitive
collections.
2
Preliminaries
Let Σ = [1..σ] be an integer alphabet, let # = 0 /∈Σ be a separator, and let
T ∈[1..σ]n−1 be a string. We denote by T the reverse of T, and by PT #(W) the
set of all starting positions of a string W ∈[0..σ]+ in the circular version of T#.
We set Σr
T #(W) = {a ∈[0..σ] : |PT #(Wa)| > 0} and Σℓ
T #(W) = {a ∈[0..σ] :
|PT #(aW)| > 0}. A repeat W ∈Σ+ is a string with |PT #(W)| > 1. A repeat
W is right-maximal (respectively, left-maximal) iﬀ|Σr
T #(W)| > 1 (respectively,
iﬀ|Σℓ
T #(W)| > 1). A maximal repeat is a repeat that is both left- and right-
maximal. We say that a maximal repeat W is rightmost (respectively, leftmost)
if no string WV with V ∈[0..σ]+ is left-maximal (respectively, if no string V W
with V ∈[0..σ]+ is right-maximal).
For reasons of space we assume the reader to be familiar with the notion of
suﬃx tree STT # = (V, E) of T#, i.e. the compact trie of all suﬃxes of T# (see
e.g. [12] for an introduction). We denote by ℓ(γ), or equivalently by ℓ(u, v), the
label of edge γ = (u, v) ∈E, and we denote by ℓ(v) the concatenation of all
edge labels in the path from the root to node v ∈V . It is well known that a
string W is right-maximal (respectively, left-maximal) in T# iﬀW = ℓ(v) for
some internal node v of STT # (respectively, iﬀW = ℓ(v) for some internal node
v of STT #). Since left-maximality is closed under preﬁx operation, there is a
bijection between the set of all maximal repeats of T# and the set of all nodes
of the suﬃx tree of T# that lie on paths that start from the root and that end at
nodes labelled by rightmost maximal repeats (a symmetrical observation holds
for the suﬃx tree of T#).
The compact directed acyclic word graph of T# (denoted by CDAWGT # in
what follows) is the minimal compact automaton that recognizes the set of suf-
ﬁxes of T# [4,7]. It can be seen as a minimization of STT # in which all leaves
are merged to the same node (the sink) that represents T# itself, and in which

164
D. Belazzougui et al.
all nodes except the sink are in one-to-one correspondence with the maximal
repeats of T# [20] (the source corresponds to the empty string). As in the suﬃx
tree, transitions are labelled by substrings of T#, and the subgraph of STT #
induced by maximal repeats is isomorphic to a spanning tree of CDAWGT #.
For reasons of space we assume the reader to be familiar with the notion
and uses of the Burrows-Wheeler transform (BWT) of T and of the FM index,
including the C array, LF mapping, and backward search (see e.g. [9]). In this
paper we use BWTT # to denote the BWT of T#, and we use range(W) =
[sp(W)..ep(W)] to denote the lexicographic interval of a string W in a BWT that
is implicit from the context. We say that BWTT #[i..j] is a run iﬀBWTT #[k] =
c ∈[0..σ] for all k ∈[i..j], and moreover if every substring BWTT #[i′..j′] such
that i′ ≤i, j′ ≥j, and either i′ ̸= i or j′ ̸= j, contains at least two distinct
characters. We denote by rT # the number of runs in BWTT #, and we call run-
length encoded BWT (denoted by RLBWTT #) any representation of BWTT #
that takes O(rT #) words of space, and that supports rank and select operations
(see e.g. [16,17,21]). Since the diﬀerence between rT # and rT # is negligible in
practice, we denote both of them by r when T is implicit from the context.
Repetition-aware string indexes. The run-length compressed suﬃx array of
T#, denoted by RLCSAT # in what follows, consists of a run-length compressed
rank data structure for BWTT #, and of a sampled suﬃx array, denoted by SSAT #
[17]. The average time for locating an occurrence is inversely proportional to the
size of SSAT #, and fast locating needs a large SSA regardless of the compress-
ibility of the dataset. M¨akinen et al. suggested ways to reduce the size of the
SSA [17], but they did not perform well enough in real repetitive datasets for
the authors to include them in the software they released.
The Lempel-Ziv 77 factorization of T [24], abbreviated with LZ77 in what fol-
lows, is the greedy decomposition of T into phrases or factors T1T2 · · · Tz deﬁned
as follows. Assume that T is virtually preceded by the set of distinct characters
in its alphabet, and assume that T1T2 · · · Ti has already been computed for some
preﬁx of length k of T: then, Ti+1 is the longest preﬁx of T[k + 1..n] such that
there is a j ≤k that satisﬁes T[j..j + |Ti+1| −1] = Ti+1. For reasons of space
we assume the reader to be familiar with LZ77 indexes: see e.g. [10,13]. Here we
just recall that a primary occurrence of a pattern P in T is one that crosses or
ends at a phrase boundary in the LZ77 factorization T1T2 · · · Tz of T. All other
occurrences are called secondary. Once we have computed primary occurrences,
locating all socc secondary occurrences reduces to two-sided range reporting,
and it takes O(socc·log log n) time with a data structure of O(z) words of space
[13]. To locate primary occurrences, we use a data structure for four-sided range
reporting on a z × z grid, with a marker at (x, y) if the x-th LZ factor in lex-
icographic order is preceded in the text by the lexicographically y-th reversed
preﬁx ending at a phrase boundary. This data structure takes O(z) words of
space, and it returns all the phrase boundaries that are immediately followed by
a factor in the speciﬁed range, and immediately preceded by a reversed preﬁx in
the speciﬁed range, in O((1 + k) logϵ z) time, where k is the number of phrase
boundaries reported [5]. K¨arkk¨ainen and Ukkonen used two PATRICIA trees

Flexible Indexing of Repetitive Collections
165
[18], one for the factors and the other for the reversed preﬁxes ending at phrase
boundaries [13]. Their approach takes O(m2) total time if T is not compressed.
Replacing the uncompressed text by an augmented compressed representation,
we can store T in O(z log n) space such that later, given P, we can ﬁnd all occ
occurrences of P in O(m log m + occ · log log n) time [10].
Alternatively, if all queried patterns are of length at most M, we could store
in a FM index the substrings of T that consist of characters within distance M
from the closest phrase boundary, and use that to ﬁnd primary occurrences (see
e.g. [22] and references therein). This approach is known as hybrid indexing.
Composite repetition-aware string indexes. Combining RLBWTT # with
the set of all starting positions p1, p2, . . . , pz of the LZ factors of T, yields a
data structure that takes O(z + r) words of space, and that reports all the
pocc primary occurrences of a pattern P ∈[1..σ]m in O(m(log log n + log z) +
pocc · logϵ z) time [3]. Since such data structure is at the core of this paper, we
summarize it in what follows. The same primary occurrence of P in T can cover
up to m factor boundaries. Thus, we consider every possible way of placing,
inside P, the rightmost boundary between two factors, i.e. every possible split
of P in two parts P[1..k −1] and P[k..m] for k ∈[2..m], such that P[k..m] is
either a factor or a proper preﬁx of a factor. For every such k, we use four-sided
range reporting queries to list all the occurrences of P in T that conform to
the split, as described before. We encode the sequence p1, p2, . . . , pz implicitly,
as follows: we use a bitvector last[1..n] such that last[i] = 1 iﬀSAT #[i] =
n −pj + 2 for some j ∈[1..z], i.e. iﬀSAT #[i] is the last position of a factor. We
represent such bitvector as a predecessor data structure with partial ranks, using
O(z) words of space [23]. Let STT # = (V, E) be the suﬃx tree of T#, and let
V ′ = {v1, v2, . . . , vz} ⊆V be the set of loci in STT # of all the LZ factors of T.
Consider the list of node labels L = ℓ(v1), ℓ(v2), . . . , ℓ(vz), sorted in lexicographic
order. It is easy to build a data structure that takes O(z) words of space, and
that implements in O(log z) time function I(W, V ′), which returns the (possibly
empty) interval of W in L (see e.g. [3]). Together with last, RLBWTT # and
RLBWTT #, this data structure is the output of our construction.
Given P, we ﬁrst perform a backward search in RLBWTT # to determine
the number of occurrences of P in T#: if this number is zero, we stop. Dur-
ing backward search, we store in a table the interval [ik..jk] of P[k..m] in
BWTT # for every k ∈[2..m]. Then, we compute the interval [i′
k−1..j′
k−1] of
P[1..k −1] in BWTT # for every k ∈[2..m], using backward search in RLBWTT #:
if rank1(last, j′
k−1) −rank1(last, i′
k−1 −1) = 0, then P[1..k −1] never ends at
the last position of a factor, and we can discard this value of k. Otherwise, we
convert [i′
k−1..j′
k−1] to the interval [rank1(last, i′
k−1 −1)+1..rank1(last, j′
k−1)]
of all the reversed preﬁxes of T that end at the last position of a factor. Rank
operations on last can be implemented in O(log log n) time using predecessor
queries. We get the lexicographic interval of P[k..m] in the list of all distinct fac-
tors of T, in O(log z) time, using operation I(P[k..m], V ′). We use such intervals
to query the four-sided range reporting data structure.
It is also possible to combine RLBWTT # with CDAWGT #, building a data
structure that takes O(eT #) words of space, and that reports all the occ

166
D. Belazzougui et al.
occurrences of P in O(m log log n + occ) time, where eT # is the number of
right-extensions of maximal repeats of T# [3]. Speciﬁcally, for every node v in
the CDAWG, we store |ℓ(v)| in a variable v.length. Recall that an arc (v, w)
in the CDAWG means that maximal repeat ℓ(w) can be obtained by extending
maximal repeat ℓ(v) to the right and to the left. Thus, for every arc γ = (v, w)
of the CDAWG, we store the ﬁrst character of ℓ(γ) in a variable γ.char, and
we store the length of the right extension implied by γ in a variable γ.right.
The length γ.left of the left extension implied by γ can be computed by
w.length −v.length −γ.right. For every arc of the CDAWG that connects
a maximal repeat W to the sink, we store just γ.char and the starting position
γ.pos of string W ·γ.char in T. The total space used by the CDAWG is O(eT #)
words, and the number of runs in BWTT # can be shown to be O(eT #) as well
[3] (an alternative construction could use CDAWGT # and RLBWTT #).
Once again, we use the RLBWT to count the number of occurrences of P in
T in O(m log log n) time: if this number is not zero, we use the CDAWG to report
all the occ occurrences of P in O(occ) time, using a technique already sketched in
[6]. Speciﬁcally, since we know that P occurs in T, we perform a blind search for P
in the CDAWG, as is typically done with PATRICIA trees. We keep a variable i,
initialized to zero, that stores the length of the preﬁx of P that we have matched
so far, and we keep a variable j, initialized to one, that stores the starting position
of P inside the last maximal repeat encountered during the search. For every node
v in the CDAWG, we choose the arc γ such that γ.char = P[i + 1] in constant
time using hashing, we increment i by γ.right, and we increment j by γ.left. If
the search leads to the sink by an arc γ, we report γ.pos + j and we stop. If the
search ends at a node v that is associated with a maximal repeat W, we determine
all the occurrences of W in T by performing a depth-ﬁrst traversal of all nodes
reachable from v in the CDAWG, updating variables i and j as described before,
and reporting γ.pos + j for every arc γ that leads to the sink. The total number
of nodes and arcs reachable from v is O(occ).
3
Combining RLBWT and LZ Factors in Practice
In this paper we implement1 a range of practical variants of the combination of
RLBWT and LZ factorization described in Sect. 2. Speciﬁcally, in addition to
the version described in Sect. 2 (which we call full in what follows), we design
a variant in which we drop RLBWTT #, simulating it with a bidirectional index,
in order to save space (we call this bidirectional in what follows); a variant in
which we drop RLBWTT #, the four-sided range reporting data structure, and
the subset of suﬃx tree nodes, in order to save even more space (we call this
variant light in what follows); and another variant in which, to reduce space even
further, we use a sparse version of the LZ parsing, i.e. we skip a ﬁxed number
of characters after each factor (we call this index sparse in what follows). In
addition, we design a number of optimizations to speed up locate queries in
practice: we will describe them in the full version of the paper.
1 Our source code is available at https://github.com/nicolaprezza/lz-rlbwt and
https://github.com/nicolaprezza/slz-rlbwt and it is based on SDSL [11].

Flexible Indexing of Repetitive Collections
167
Our representation of the RLBWT is based on the one described in [21], which
we summarize here for completeness, but is more space-eﬃcient. The authors of
[21] store one character per run in a string H ∈Σr, they mark with a one the
beginning of each run in a bitvector Vall[0..n−1], and for every c ∈Σ they store
the lengths of all runs of character c consecutively in a bit-vector Vc: speciﬁcally,
every c-run of length k is represented in Vc as 10k−1. This representation allows
one to map rank and access queries on BWTT # to rank, select and access queries
on H, Vall, and Vc. By gap-encoding the bitvectors, this representation takes
r(2 log(n/r) + log σ)(1 + o(1)) bits of space. We reduce the multiplicative factor
of the term log(n/r) by storing in Vall just one out of 1/ϵ ones, where 0 < ϵ ≤1
is a given constant (we set ϵ = 1/8 in all our experiments). Note that we are still
able to answer all queries on the RLBWT, by using the Vc vectors to reconstruct
the positions of the missing ones in Vall. However, query time gets multiplied by
1/ϵ. We represent H as a Huﬀman-encoded string (wt huff<> in SDSL), and we
gap-encode bitvectors with Elias-Fano (sd vector<> in SDSL).
Full index. Our ﬁrst variant is an engineered version of the data structure
described in Sect. 2. We store both RLBWTT # and RLBWTT #. A gap-encoded
bitvector end[0..n−1] of z log(n/z)(1+o(1)) bits marks the rank, among all the
suﬃxes of T#, of every suﬃx T[i..n−1]# such that n−i−2 is the last position
of an LZ factor of T. Symmetrically, a gap-encoded bitvector begin[0..n −1] of
z log(n/z)(1 + o(1)) bits marks the rank, among all the suﬃxes of T#, of every
suﬃx T[i..n −1]# such that i is the ﬁrst position of an LZ factor of T.
Geometric range data structures are implemented with wavelet trees (wt int
in SDSL). We manage to ﬁt the 4-sided data structure in 2z log z(1 + o(1)) bits,
and the 2-sided data structure in z(2 log n + 1)(1 + o(1)) bits: we will detail
such implementations in the full version of the paper. Finally, we need a way to
compute the lexicographic range of a string among all the LZ factors of T. We
implement a simpler and more space-eﬃcient strategy than the one proposed
in [3], which we will describe in the full version of the paper. In summary, the
full index takes

6z log n + 2(1 + ϵ)r log(n/r) + 2r log σ

· (1 + o(1)) bits of space,
and it supports count queries in O(m·(log(n/r)+log σ)) time and locate queries
in O((m + occ) · log n) time.
Bidirectional index. To save space we can drop RLBWTT # and simulate it
using just RLBWTT #, by applying the synchronization step performed in bidirec-
tional BWT indexes (see e.g. [2] and references therein). This strategy penalizes
the time complexity of locate queries, which becomes quadratic in the length
of the pattern. Moreover, since in our implementation we store run-lengths sep-
arately for each character, a synchronization step requires σ rank queries to
ﬁnd the number of characters smaller than a given character inside a BWT
interval. This operation could be performed in O(log σ) time if the string were
represented as a wavelet tree. In summary, the bidirectional variant of the index
takes

6z log n + (1 + ϵ)r log(n/r) + r log σ

· (1 + o(1)) bits of space, it supports
count queries in O(m · (log(n/r) + log σ)) time, and it supports locate queries in
O(m2σ log(n/r) + (m + occ) · log n) time.

168
D. Belazzougui et al.
Light index. Once we have computed the interval of the pattern in BWTT #,
we can locate all its primary occurrences by just forward-extracting at most m
characters for each occurrence inside the range: this is because every primary
occurrence of the pattern overlaps with the last position of an LZ factor. We
implement forward extraction by using select queries on RLBWTT #. This app-
roach requires just RLBWTT #, the 2-sided range data structure, a gap-encoded
bitvector endT that marks the last position of every LZ factor in the text, a
gap-encoded bitvector endBW T that marks the last position of every LZ factor
in BWTT #, and z integers of log z bits each, connecting corresponding ones in
endBW T and in endT : this array plays the role of the sparse suﬃx array sampling
in RLCSA.
Sparse index. We can reduce the size of the index even further by sparsifying
the LZ factorization. Intuitively, the factorization of a highly-repetitive collection
of strings T = T1T2 · · · Tk, where T2, . . . , Tk are similar to T1, is much denser
inside T1 than it is inside T2 · · · Tk. Thus, excluding long enough contiguous
regions from the factorization (i.e. not outputting factors inside such regions)
could reduce the number of factors in dense regions. Formally, let d > 0, and
consider the following generalization of LZ77, denoted here by LZ77-d: we factor
T as X1Y1X2Y2 · · · XzdYzd, where zd is the size of the factorization, Yi ∈Σd
for all i ∈[1..zd], and Xi is the longest preﬁx of XiYi · · · XzdYzd that starts
at least once inside the range of positions [1..|X1Y1 · · · Xi−1Yi−1|]. To make the
light index work with LZ77-d, we need to sample the suﬃx array of T# at the
lexicographic ranks that correspond to the last position of every Xi, and we need
to redeﬁne primary occurrences as those that are not fully contained inside an X
factor. To answer a locate query, we also need to extract d additional characters
before each occurrence of the pattern, in order to detect primary occurrences
that start inside a Y factor. Finally, the 2-sided range data structure needs to
be built on the sources of the X factors. The sparse index takes

zd(3 log n +
log(n/zd)) + (1 + ϵ)r log(n/r)

· (1 + o(1)) bits of space, it answers locate queries
in O((occ+1)·(m+d)·log n) time, and count queries in O(m(log(n/r)+log σ))
time. Setting d large enough makes zd up to three times smaller than the number
of LZ factors in realistic highly-repetitive collections.
4
Combining RLBWT and CDAWG in Practice
In this paper we also engineer2 the combination of RLBWT and CDAWG
described in Sect. 2, and in particular we study the eﬀects of two representa-
tions of the CDAWG. In the ﬁrst one, the graph is encoded as a sequence of
variable-length integers: every integer is represented as a sequence of bytes, in
which the seven least signiﬁcant bits of every byte are used to encode the integer,
and the most signiﬁcant bit ﬂags the last byte of the integer. Nodes are stored
in the sequence according to their topological order in the graph obtained from
the CDAWG by inverting the direction of all arcs: to encode a pointer from a
2 Our source code is available at https://github.com/mathieuraﬃnot/locate-cdawg.

Flexible Indexing of Repetitive Collections
169
node v to its successor w in the CDAWG, we store the diﬀerence between the
ﬁrst byte of v and the ﬁrst byte of w in the sequence. If w is the sink, such
diﬀerence is replaced by a shorter code. We choose to store the length of the
maximal repeat that corresponds to each node, rather than the oﬀset of ℓ(v)
inside ℓ(w) for every arc (v, w), since such lengths are short and their number is
smaller than the number of arcs in practice.
In the second encoding we exploit the fact that the subgraph of the suﬃx tree
of T# induced by maximal repeats is a spanning tree of CDAWGT #. Speciﬁcally,
we encode such spanning tree with the balanced parenthesis scheme described
in [19], and we resolve the arcs of the CDAWG that belong to the tree using
corresponding tree operations. Such operations work on node identiﬁers, thus
we need to convert a node identiﬁer to the corresponding ﬁrst byte in the byte
sequence of the CDAWG, and vice versa. We implement such translation by
encoding the monotone sequence of the ﬁrst byte of every node with the quasi-
succinct representation by Elias and Fano, which uses at most 2 + log(N/n) bits
per starting position, where N is the number of bytes in the byte sequence and
n is the number of nodes [8].
5
Experimental Results
We test our implementations on ﬁve DNA datasets from the Pizza&Chili repet-
itive corpus3, which include the whole genomes of approximately 36 strains of
the same eukaryotic species, a collection of 23 and approximately 78 thousand
substrings of the genome of the same bacterium, and an artiﬁcially repetitive
string obtained by concatenating 100 mutated copies of the same substring of
the human genome. We compare our results to the FM index implementation in
SDSL [11] with sampling rate 2i for i ∈[5..10], to an implementation of RLCSA4
with the same sampling rates, to the ﬁve variants in the implementation of the
LZ77 index described in [14], and to a recent implementation of the compressed
hybrid index [22]. The FM index uses RRR bitvectors in its wavelet tree. For
brevity, we call LZ1 the implementation of the LZ77 index that uses the suﬃx
trie and the reverse trie. For each process, and for each pattern length 2i for
i ∈[3..10], we measure the maximum resident set size and the number of CPU
seconds that the process spends in user mode5, both for locate and for count
queries, discarding the time for loading the indexes and averaging our measure-
ments over one thousand patterns6. We experiment with skipping 2i characters
before opening a new phrase in the sparse index, where i ∈[5..10].
3 http://pizzachili.dcc.uchile.cl/repcorpus.html.
4 We compile the sequential version of https://github.com/adamnovak/rlcsa with
PSI FLAGS and SA FLAGS turned oﬀ(in other words, we use a gap-encoded bitvector
rather than a succinct bitvector to mark sampled positions in the suﬃx array). The
block size of psi vectors (RLCSA BLOCK SIZE) is 32 bytes.
5 We perform all experiments on a single core of a 6-core, 2.50 GHz, Intel Xeon E5-
2640 processor, with access to 128 GiB of RAM and running CentOS 6.3. We measure
resources with GNU Time 1.7, and we compile with GCC 5.3.0.
6 We use as patterns random substrings of each dataset, containing just DNA bases,
generated with the genpatterns tool from the Pizza&Chili repetitive corpus.

170
D. Belazzougui et al.
-2.5
-2
-1.5
-1
-0.5
0
0.5
1
4.2 4.4 4.6 4.8
5
5.2 5.4 5.6
Avg locate time per occurrence (ms, log10)
-0.5
0
0.5
1
1.5
2
2.5
4.44.54.64.74.84.9 5 5.15.2
Avg locate time per occurrence (ms, log10)
Memory (KiB, log10)
-3
-2.5
-2
-1.5
-1
-0.5
0
0.5
1
1.5
4.2 4.4 4.6 4.8 5
5.2 5.4 5.6
-1
-0.5
0
0.5
1
1.5
2
4.44.54.64.74.84.9 5 5.15.2
Memory (KiB, log10)
-3.5
-3
-2.5
-2
-1.5
-1
-0.5
0
0.5
1
3.8
4
4.2 4.4 4.6 4.8
5
5.2
-2
-1.5
-1
-0.5
0
0.5
1
1.5
3.8
4
4.2 4.4 4.6 4.8
5
Memory (KiB, log10)
-3.5
-3
-2.5
-2
-1.5
-1
-0.5
0
0.5
1
3.8
4
4.2 4.4 4.6 4.8
5
5.2
-2
-1.5
-1
-0.5
0
0.5
1
1.5
4
4.2
4.4
4.6
4.8
5
Memory (KiB, log10)
-3
-2.5
-2
-1.5
-1
-0.5
0
0.5
1
4.4 4.6 4.8
5
5.2 5.4 5.6
-1
-0.5
0
0.5
1
1.5
2
4.54.64.74.84.9 5 5.15.25.3
Memory (KiB, log10)
FM
Light, bidirectional, full
CDAWG
Escherichia coli
Saccharomyces cerevisiae
Pseudo-real
Haemophilus inluenzae
Saccharomyces paradoxus
RLCSA
LZ77-index
Hybrid
Sparse
Fig. 1. Locate queries: space-time tradeoﬀs of our indexes (color) and of the state of
the art (black). Top row: patterns of length 16. Bottom row: patterns of length 512. The
full, bidirectional, and light indexes are shown with (red dots) and without (red circles)
speed optimizations. The CDAWG is shown in succinct (blue dots) and non-succinct
(blue circles) version. (Color ﬁgure online)
The ﬁrst key result of our experiments is that, in highly-repetitive strings,
the sparse index takes an amount of space that is comparable to LZ indexes, and
thus typically smaller than the space taken by RLCSA and by the FM index,
while supporting count operations that are approximately as fast as RLCSA and
as the FM index, and thus typically faster than LZ indexes. This new tradeoﬀ
comes at the cost of slower locate queries.
Speciﬁcally, the gap between sparse index and LZ variants in the running
time of count queries is large for short patterns: the sparse index is between
two and four orders of magnitude faster than all variants of the LZ index, with
the largest diﬀerence achieved by patterns of length 8 (Fig. 2, bottom). The
diﬀerence between the sparse index and variant LZ1 shrinks as pattern length
increases. Locate queries are between one and three orders of magnitude slower
in the sparse index than in LZ indexes, and comparable to RLCSA with sampling
rates equal to or greater than 2048 (Fig. 1, top). However, for patterns of length
approximately 64 or larger, the sparse index becomes between one and two orders
of magnitude faster than all variants of the LZ index, except LZ1. As a function
of pattern length, the running time per occurrence of the sparse index grows

Flexible Indexing of Repetitive Collections
171
-2
-1
0
1
2
3
4
3
4
5
6
7
8
9
10
Avg. locate time per occurrence (ms, log10)
Escherichia coli
-2
-1
0
1
2
3
3
4
5
6
7
8
9
10
Saccharomyces cerevisiae
-2
-1
0
1
2
3
3
4
5
6
7
8
9
10
Pseudo-real
-3
-2
-1
0
1
2
3
3
4
5
6
7
8
9
10
Haemophilus influenzae
-2
-1
0
1
2
3
3
4
5
6
7
8
9
10
Saccharomyces paradoxus
-2
-1
0
1
2
3
4
3
4
5
6
7
8
9
10
Avg. count time per pattern (ms, log10)
Pattern length (log2)
-2
-1
0
1
2
3
4
3
4
5
6
7
8
9
10
Pattern length (log2)
-2
-1
0
1
2
3
4
3
4
5
6
7
8
9
10
Pattern length (log2)
-2
-1
0
1
2
3
4
3
4
5
6
7
8
9
10
Pattern length (log2)
-2
-1
0
1
2
3
4
3
4
5
6
7
8
9
10
Pattern length (log2)
FM
RLCSA
LZ77-index
Hybrid
Sparse
Fig. 2. Locate time per occurrence (top) and count time per pattern (bottom), as a
function of pattern length, for the sparse index with skip rate 2i, i ∈[5..10], the LZ77
index, and the hybrid index. Count plots show also the FM index and RLCSA.
-4
-3.5
-3
-2.5
-2
4.6
4.8
5
5.2
5.4
5.6
Avg. locate time per occurrence (ms, log10)
Memory (KiB, log10)
-3.8
-3.6
-3.4
-3.2
-3
-2.8
-2.6
5
5.2
5.4
5.6
5.8
6
6.2
Memory (KiB, log10)
-3.8
-3.6
-3.4
-3.2
-3
-2.8
4.4
4.6
4.8
5
5.2
5.4
Memory (KiB, log10)
-3.8
-3.6
-3.4
-3.2
-3
-2.8
-2.6
4.6 4.8
5
5.2 5.4 5.6 5.8
6
Memory (KiB, log10)
-3.8
-3.6
-3.4
-3.2
-3
-2.8
-2.6
5
5.2
5.4
5.6
5.8
6
6.2
Memory (KiB, log10)
Escherichia coli
Saccharomyces cerevisiae
Pseudo-real
Haemophilus inluenzae
Saccharomyces paradoxus
Fig. 3. Space-time traeoﬀs of the CDAWG (blue) compared to RLCSA (triangles)
with sampling rate 2i, i ∈[3..5]. Patterns of length 8, 6, 4, 2 (from left to right). The
CDAWG is shown in succinct (blue dots) and non-succinct (blue circles) version. (Color
ﬁgure online)
more slowly than the running time of LZ1, suggesting that the sparse index might
even approach LZ1 for patterns of length between 1024 and 2048 (Fig. 2, top).
Compared to the hybrid index, the sparse index is again orders of magnitude
faster in count queries, especially for short patterns (Fig. 2, bottom). As with
LZ1, the diﬀerence shrinks as pattern length increases, but since the size of the
hybrid index depends on maximum pattern length, the hybrid index becomes

172
D. Belazzougui et al.
larger than the sparse index for patterns of length between 64 and 128, and
possibly even shorter (Fig. 4, top). As with LZ indexes, faster count queries
come at the expense of locate queries, which are approximately 1.5 orders of
magnitude slower in the sparse index than in the hybrid index (Fig. 2, top).
The second key result of our experiments is that the CDAWG is eﬃcient at
locating very short patterns, and in this regime it achieves the smallest query
time among all indexes. Speciﬁcally, the running time per occurrence of the
CDAWG is between 4 and 10 times smaller than the running time per occur-
rence of a version of RLCSA that uses comparable memory, and with patterns
of length two the CDAWG achieves speedups even greater than 10 (Fig. 3). Note
that short exact patterns are a frequent use case when searching large repet-
itive collections of versioned source code. The CDAWG does not achieve any
new useful tradeoﬀwith long patterns. Using the succinct representation of the
CDAWG saves between 20% and 30% of the disk size and resident set size of
the non-succinct representation, but using the non-succinct representation saves
between 20% and 80% of the query time of the succinct representation, depend-
ing on dataset and pattern length. Finally, our full, bidirectional and light index
implementations exhibit the same performance as the sparse index for count
queries, but it turns out that they take too much space in practice to achieve
any new useful tradeoﬀ(Fig. 1).
40
60
80
100
120
140
160
Disk size (MiB)
0
100
200
300
400
500
0
20
40
60
80
100
20
40
60
80
100
120
140
160
0
100
200
300
400
500
14
16
18
20
22
24
26
28
30
Disk size (MiB)
Escherichia coli
15
20
25
30
35
40
45
50
55
Saccharomyces cerevisiae
4
6
8
10
12
Pseudo-real
6
7
8
9
10
11
Haemophilus influenzae
20
25
30
35
40
45
50
55
60
Saccharomyces paradoxus
RLCSA
RLCSA
RLCSA
RLCSA
RLCSA
RLCSA
CDAWG
CDAWG
CDAWG
CDAWG
CDAWG
RLCSA
RLCSA
RLCSA
RLCSA
LZ77
LZ77
LZ77
LZ77
LZ77
Hybrid
Hybrid
Hybrid
Hybrid
Hybrid
Sparse
Sparse
Sparse
Sparse
Sparse
Fig. 4. Top) Disk size of the sparse index with skip rate 2i, i ∈[10..15], compared to the
hybrid index with maximum pattern length 2i, i ∈[3..10], the LZ77 index, and RLCSA
with sampling rate 2i, i ∈[10..15]. (Bottom) Disk size of the CDAWG compared to
RLCSA with sampling rate 2i, i ∈[2..5]. The CDAWG is shown in succinct (blue dots)
and non-succinct (blue circles) version. (Color ﬁgure online)

Flexible Indexing of Repetitive Collections
173
References
1. Arroyuelo, D., Navarro, G., Sadakane, K.: Stronger Lempel-Ziv based compressed
text indexing. Algorithmica 62, 54–101 (2012)
2. Belazzougui, D.: Linear time construction of compressed text indices in compact
space. In: Proceedings of the STOC, pp. 148–193 (2014)
3. Belazzougui, D., Cunial, F., Gagie, T., Prezza, N., Raﬃnot, M.: Composite
repetition-aware data structures. In: Cicalese, F., Porat, E., Vaccaro, U. (eds.)
CPM 2015. LNCS, vol. 9133, pp. 26–39. Springer, Cham (2015). doi:10.1007/
978-3-319-19929-0 3
4. Blumer, A., et al.: Complete inverted ﬁles for eﬃcient text retrieval and analysis.
JACM 34, 578–595 (1987)
5. Chan, T.M., Larsen, K.G., P˘atra¸scu, M.: Orthogonal range searching on the RAM,
revisited. In: Proceediings of the SoCG, pp. 1–10 (2011)
6. Crochemore, M., Hancart, C.: Automata for matching patterns. In: Rozenberg, G.,
et al. (eds.) Handbook of Formal Languages, pp. 399–462. Springer, Heidelberg
(1997)
7. Crochemore, M., V´erin, R.: Direct construction of compact directed acyclic word
graphs. In: Apostolico, A., Hein, J. (eds.) CPM 1997. LNCS, vol. 1264, pp. 116–129.
Springer, Heidelberg (1997). doi:10.1007/3-540-63220-4 55
8. Elias, P., Flower, R.A.: The complexity of some simple retrieval problems. JACM
22, 367–379 (1975)
9. Ferragina, P., Manzini, G.: Indexing compressed texts. JACM 52(4), 552–581
(2005)
10. Gagie, T., Gawrychowski, P., K¨arkk¨ainen, J., Nekrich, Y., Puglisi, S.J.: LZ77-
based self-indexing with faster pattern matching. In: Pardo, A., Viola, A. (eds.)
LATIN 2014. LNCS, vol. 8392, pp. 731–742. Springer, Heidelberg (2014). doi:10.
1007/978-3-642-54423-1 63
11. Gog, S., Beller, T., Moﬀat, A., Petri, M.: From theory to practice: plug and
play with succinct data structures. In: Gudmundsson, J., Katajainen, J. (eds.)
SEA 2014. LNCS, vol. 8504, pp. 326–337. Springer, Cham (2014). doi:10.1007/
978-3-319-07959-2 28
12. Gusﬁeld, D.: Algorithms on Strings, Trees and Sequences: Computer Science and
Computational Biology. Cambridge University Press, Cambridge (1997)
13. K¨arkk¨ainen, J., Ukkonen, E.: Lempel-Ziv parsing and sublinear-size index struc-
tures for string matching. In: Proceedings of the WSP, pp. 141–155 (1996)
14. Kreft, S.: Self-index based on LZ77. Master’s thesis, Department of Computer
Science, University of Chile (2010)
15. Kreft, S., Navarro, G.: On compressing and indexing repetitive sequences. TCS
483, 115–133 (2013)
16. M¨akinen, V., Navarro, G.: Succinct suﬃx arrays based on run-length encoding. In:
Apostolico, A., Crochemore, M., Park, K. (eds.) CPM 2005. LNCS, vol. 3537, pp.
45–56. Springer, Heidelberg (2005). doi:10.1007/11496656 5
17. M¨akinen, V., et al.: Storage and retrieval of highly repetitive sequence collections.
JCB 17, 281–308 (2010)
18. Morrison, D.R.: PATRICIA – practical algorithm to retrieve information coded in
alphanumeric. JACM 15, 514–534 (1968)
19. Munro, J.I., Raman, V.: Succinct representation of balanced parentheses and static
trees. SIAM J. Comput. 31, 762–776 (2002)
20. Raﬃnot, M.: On maximal repeats in strings. IPL 80, 165–169 (2001)

174
D. Belazzougui et al.
21. Sir´en, J., V¨alim¨aki, N., M¨akinen, V., Navarro, G.: Run-length compressed indexes
are superior for highly repetitive sequence collections. In: Amir, A., Turpin, A.,
Moﬀat, A. (eds.) SPIRE 2008. LNCS, vol. 5280, pp. 164–175. Springer, Heidelberg
(2008). doi:10.1007/978-3-540-89097-3 17
22. Valenzuela, D.: CHICO: a compressed hybrid index for repetitive collections. In:
Goldberg, A.V., Kulikov, A.S. (eds.) SEA 2016. LNCS, vol. 9685, pp. 326–338.
Springer, Cham (2016). doi:10.1007/978-3-319-38851-9 22
23. Willard, D.E.: Log-logarithmic worst-case range queries are possible in space θ(n).
IPL 17, 81–84 (1983)
24. Ziv, J., Lempel, A.: A universal algorithm for sequential data compression. IEEE
TIT 23, 337–343 (1977)

Admissibles in Gaps
Merlin Carl1,2(B), Bruno Durand3(B), Gr´egoryLaﬁtte3(B),
and Sabrina Ouazzani4
1 Fachbereich Mathematik und Statistik, Universit¨at Konstanz,
78457 Konstanz, Germany
merlin.carl@uni-konstanz.de
2 Lehrstuhl f¨ur Theoretische Informatik, Universit¨at Passau,
94032 Passau, Germany
3 LIRMM, CNRS, Universit´e de Montpellier,
161 Rue Ada, 34090 Montpellier, France
{bruno.durand,gregory.lafitte}@lirmm.fr
4 LACL, Universit´e Paris-Est,
61 Avenue du G´en´eral de Gaulle, 94010 Cr´eteil, France
sabrina.ouazzani@lacl.fr
Abstract. We consider clockable ordinals for Inﬁnite Time Turing
Machines (ITTMs), i.e., halting times of ITTMs on the empty input.
It is well-known that, in contrast to the writable ordinals, the set of
clockable ordinals has ‘gaps’. In this paper, we show several results on
gaps, mainly related to the admissible ordinals they may properly con-
tain. We prove that any writable ordinal can occur as the order type of
the sequence of admissible ordinals in such a gap. We give precise infor-
mation on their ending points. We also investigate higher rank ordinals
(recursively inaccessible, etc.). Moreover, we show that those gaps can
have any reasonably eﬀective length (in the sense of ITTMs) compared
to their starting point.
1
Introduction
Inﬁnite Time Turing Machines (ITTMs), invented by Hamkins and Kidder and
ﬁrst introduced in [3], are the historically ﬁrst of a number of machine models of
inﬁnitary computability. Among these various models, ITTMs have been most
extensively studied. A topic that has received particular attention is the issue of
clockability.
An ordinal α is called ‘clockable’ if and only if there is an ITTM-program P
such that P halts on the empty input after exactly α many steps. As there are
only countable many programs, there are only countable many halting times.
Moreover, a coﬁnality argument shows that all halting times of ITTMs must be
countable ordinals. There is thus a countable supremum of the ITTM-halting
times, called γ∞.
The authors would like to express their thanks to the anonymous referees, who made
numerous suggestions and interesting remarks.
c
⃝Springer International Publishing AG 2017
J. Kari et al. (Eds.): CiE 2017, LNCS 10307, pp. 175–186, 2017.
DOI: 10.1007/978-3-319-58741-7 18

176
M. Carl et al.
However, not every countable ordinal below γ∞is clockable: It was ﬁrst
observed and demonstrated in [3] that there are ‘gaps’ in the clockable ordinals,
i.e.,
ordinals α < β < δ < γ∞such that α and δ are clockable, but β is
not. Further information on those gaps and their distribution was obtained in
[3,5–7]: The length of a gap is always a limit ordinal, the ﬁrst gap is of length ω,
gaps are always started by admissible ordinals and admissible ordinals are never
clockable.
If one wants to obtain a characterization of those ordinals that start gaps, the
role of admissibility thus seems to be a good starting point. These aforementioned
results hence motivate a further study of the relation of admissible ordinals to
gaps. In particular, one may ask the questions whether admissible ordinals always
start gaps or whether they can also sit properly inside a gap, which order types
can appear as the order type of the sequence of admissible ordinals in a gap and
how long gaps can become relative to their starting point. In this paper, we deal
with these questions. We also investigate gaps related with admissible of high
rank and with rank-admissible (ﬁxed points of the rank function).
In particular, we show that every writable ordinal is the order type of the
sequence of admissible ordinals in some gap and that for any function f send-
ing countable ordinals to countable ordinals that is ITTM-computable in an
appropriate sense, there is an ordinal α starting a gap of length ≥f(α).
2
Preliminaries
Fix a natural enumeration (Pi : i ∈ω) of the ITTM-programs. An ordinal α is
clockable if and only if there is an ITTM-program P such that P halts on the
empty input after exactly α many steps. We denote by γ∞the supremum of the
clockable ordinals.
An ordinal α is writable if and only if there is an ITTM-program P such that
P halts on the empty input with a real number x on the output tape that codes
a well-ordering of length α. We denote by λ∞the supremum of the writable
ordinals.
A gap is a non-empty interval [α, β) of ordinals that has no clockable element.
The length of the gap [α, β) is the unique ordinal δ such that α + δ = β. The
length of a gap is always a limit ordinal (cf. [3, Section 3]).
An ordinal α is eventually writable if some ITTM working on empty input
has a code x for α on its output tape at a certain point and never changes it
again; it is accidentally writable if some ITTM working on empty input has x at
some point on its output tape, possibly changing it again later on.
Theorem 1 (Welch, λ −ζ −Σ Theorem [7]). There are countable ordinals
λ∞, ζ∞, Σ∞such that x ⊆ω is writable if and only if x ∈Lλ∞, x is eventually
writable if and only if x ∈Lζ∞and x is accidentally writable if and only if
x ∈LΣ∞. Here, λ∞is equal both to the supremum of the clockable and the
supremum of the writable ordinals. Moreover, (λ∞, ζ∞, Σ∞) is characterized as
the lexically minimal triple (α, β, δ) such that Lα ≺Σ1 Lβ ≺Σ2 Lδ.

Admissibles in Gaps
177
Theorem 2. (a) λ∞is an admissible limit of admissible ordinals and a limit
of such; in fact, we have ωCK
λ∞= λ∞
(b) ζ∞is Σ2-admissible; in particular, the claims about λ∞from (a) also
hold for ζ∞.
(c) λ∞= γ∞
Proof. (a) is the Indescribability Theorem of Hamkins and Lewis [3], (b) is
Lemma 23 from [7], we can see (c) as a corollary to Theorem 1.
Theorem 3. (a) No admissible ordinal is clockable.
(b) If α < λ∞starts a gap, then α is admissible.
Both statements relativise to arbitrary oracles.
Proof. For (a), see [3], for (b), see [5].
Corollary 1. For every x ⊆ω, the smallest ordinal not clockable in the oracle
x is ωCK,x
1
. Moreover, if x codes an ordinal α and β is the next admissible
ordinal > α such that x ∈Lβ, then β is the ﬁrst ordinal not clockable in the
oracle x. If α is ITTM-writable as x then ωCK,x
1
is the ﬁrst admissible ordinal
greater than α.
Proof. The ﬁrst two claims are immediate from Theorem 3. For the last claim,
note that, by Σ1-recursion in Lβ, any ITTM-computation of length < β is con-
tained in Lβ, hence so is its output.
Theorem 4 (Theorem 50 from [7]). Every ordinal < λ∞is writable. Thus
every clockable ordinal is writable. In fact, if α is clockable, then there is an
ITTM-program P that halts after at most α + ω many steps with a code for α
on the output tape.
Proposition 1. For every α < λ∞, there exists x ⊆ω that codes α such that
ωCK,x
1
is the ﬁrst admissible after the last gap such that its starting point is ≤α.
Note that if α is not in a gap (hence clockable), then the above proposition
tells us that ωCK,x
1
is the next admissible after α and thus starts the next gap
after α.
Proof. We use Corollary 1 and the fact that α is writable in time less than the
end of the gap that contains it, and Theorem 4 applied to α if clockable, or else
to the end of its gap.
Theorem 5. There is an ITTM-program U such that, for every x ⊆ω, Ux
simulates the computations of all ITTM-programs on ω many disjoint portions
of the working tape (and we may assume that the ith portion consists of the cells
with indices {p(i + 1, k) : k ∈ω}, where p is Cantor’s pairing function and the
‘+1’ creates space for scratch work necessary for the simulation). Moreover, U
can be chosen to almost work in ‘ω-real-time’, i.e., such that U simulates ω many
steps of each machine in ω many steps of simulation time.

178
M. Carl et al.
It will occasionally be important to use codes for ordinals as ‘stopwatches’.
For a better use, such a program should both verify that the input is a code for
a well-founded order, and halt in proper time.
Proposition 2 (Count-through program from [2]).
There is an ITTM-
program Pstopwatch such that, for every x ⊂ω given as input, always halt, accepts
x if and only if x codes a well-ordering. If the ordinal type of this well-ordering
is α, the halting time is:
– exactly α if α is a limit ordinal and α ≥ω · 2,
– α + n for some n < ω if α is a successor ordinal and α ≥ω · 2,
– ω · 2 if α < ω · 2.
In a few words, the idea of the program is to check that x codes an order
(requires ω time steps). In parallel it detects the smallest elements of the order
by runs of ω ordinals and ‘suppress’ them in the order in time ω (thus real-
time). The diﬃcult point is to discover that all the order has been erased, which
requires ω more steps in the literature’s algorithms. This last procedure is not
needed thanks to an ad hoc pre-treatment that uses ω ·2 steps, and a proper use
of ﬂashing cells.
Proposition 3. There is an ITTM-program Pgap that never halts but such that,
whenever α starts a gap, P produces a code for α on its output tape at time
exactly α and keeps it until the end of the gap. This also holds relative to arbitrary
oracles.
Remark that after λ∞, this program has a code for λ∞written on its output
tape and keeps it forever, but never halts. The existence of this program proves
that λ∞is eventually writable.
Proof. Let α start a gap. By Theorem 3, α is both admissible and a limit of
clockables. We remark that the ordinal type of clockables below α is exactly α.
Thus our program will construct a well-order that corresponds to those clock-
ables. For this, the simplest way is to denote a clockable δ by the index of one
of the machines that halts in time δ. Then if we have two integers i, j, in our
order, i < j if Pi halts before Pj. Of course, there are ω machines that halt
at a given time. Thus we consider only the ﬁrst program with a given halting
time that is discovered while running the chosen universal ω-real-time machine
(called U above).
Thus our program runs as follows: it simulates U and little by little constructs
an order such that i < j if i and j are considered and if Pi halts before Pj. The
representation of the order must be adjusted carefully: when we add an element
in this order, then ω values are changed, but we can propagate those changes
in parallel by runs of ω. Thus if α is a limit ordinal, we have on the tape a
representation of the order type of clockables < α and the proposition is proved.
Lemma 1. For the speciﬁc program Pgap deﬁned in the proof of Proposition 3, if
we start a run at any clockable δ, whenever α > δ starts a gap, then P produces
a code for α on its output tape at time exactly α and keeps it until the end of
the gap. This also holds relative to arbitrary oracles.

Admissibles in Gaps
179
Proof. Admissibles are well closed ordinal: the smallest ι such that δ + ι = α is
exactly α. This implies that the order type of clockables between δ and α is α.
Most of our notations are standard. For ι ∈On, x ⊆ω, ωCK,x
ι
denotes the
ιth admissible ordinal relative to x. We write P x(0) ↓= y to indicate that the
ITTM-program P halts on input 0 in the oracle x with y on its output tape.
For α < λ∞, writing(α) denotes the minimal writing time of α, i.e., the minimal
length of an ITTM-computation that halts with a code for α on its output
tape. For α ∈On, α+ denotes the smallest admissible ordinal > α; if ι ∈On,
then α+ι denotes the ιth admissible ordinal > α. We will frequently and tacitly
make use of the fact that admissible ordinals are closed under ordinal addition,
multiplication and exponentiation. We also make use of the equivalence of ITTMs
with any ﬁnite number of scratch tapes and ITTMs with exactly one scratch tape
without explicit mentioning.
3
Admissible Ordinals in Gaps
Theorem 6. Within the clockable ordinals, there exists a gap properly contain-
ing an admissible.
Proof. This theorem can be seen as a quite direct application of Theorem 1.
There are no clockable ordinals > λ∞= γ∞. However, as ζ∞is recursively
inaccessible, there are many admissible ordinals between λ∞and ζ∞< Σ. Thus,
LΣ |=“There are ordinals α, β, δ such that α < β < δ, β is admissible and Lδ
contains no ITTM-computation on input 0 whose length is contained in the
interval [α, β)” (i.e., [α, β) contains no clockable).
This statement is clearly Σ1; as Lλ∞≺Σ1 LΣ by Theorem 1, it holds in Lλ∞.
Let α, β, δ < λ∞witness this. So Lδ believes that β is an admissible ordinal
properly (because β is not clockable) inside a gap. However, by Σ1-recursion in
KP and admissibility of β, any ITTM-computation on the empty input of length
< β is already contained in Lβ; thus [α, β) is indeed inside a gap which properly
contains the admissible ordinal β.
To better understand Theorem 6, we give the sketch of an alternative (more
algorithmic) proof. We ﬁrst design an algorithm that checks if a real x given as
input is a code for an ordinal which is the beginning of a gap containing ωCK,x
1
.
The property “there exists an x such that x is accepted by the algorithm above”
is clearly Σ1. Now remark that this algorithm accepts any code for λ∞. Thus
by Theorem 1, we also have a witness of this property in Lλ∞, which has to be
the code of an admissible ordinal less than λ∞, and that begins a gap with an
admissible inside.
More care is required if one further wants to control the number of admissible
ordinals inside a gap.
Theorem 7. The ﬁrst gap with an admissible inside ends ω steps after this
admissible, thus there is exactly one admissible inside.

180
M. Carl et al.
Proof. We consider the following algorithm on input 0, which is a variation of
the algorithm explained in the second proof of Theorem 6, and we analyse its
halting time.
Run the algorithm Pgap from Proposition 3. Whenever Pgap writes a new code
c for an ordinal α starting a gap to its output tape, we continue to run Pgap,
while in parallel running1 the following routine R on some reserved portion of
the scratch tape:
Use Theorem 5 to simulate all ITTM-programs in the oracle c and wait for a
gap. By Corollary 1, the ﬁrst such gap will start at time ωCK,x
1
= α+ and it will
be detected at time α+ + ω. If one of the simulated programs in the execution
of Pgap halts, the execution of R is stopped, the reserved portion of the scratch
tape is erased and the execution of Pgap just continues. On the other hand, if
R detects a gap before any of the simulated programs in the execution of Pgap
halts, the whole program stops.
Let α be the minimal admissible ordinal such that [α, α+) is a preﬁx of a
gap (α starts a gap and no clockable can be found in the interval). Then the
algorithm just described will ﬁrst run for α many steps, at which point R will
be started with a code c for α in the oracle. By assumption on α, no simulated
program in the execution of Pgap will halt between times α and α+, so R will
run until the ﬁrst gap in the oracle c is detected at time α+ + ω, at which time
the whole program halts.
It follows that α+ is properly contained in the gap started by α. Moreover,
as the algorithm just described halts at time α+ + ω, α+ is the only admissible
ordinal properly contained in this gap. Finally, as gaps always have limit length,
no ITTM-program can halt between times α+ and α++ω, hence the gap starting
with α indeed ends exactly at α+ + ω.
Remark: The last proof also yields a direct proof of Theorem 7 that does not
use Theorem 1: indeed if no gap properly containing an admissible exists before
λ∞then the algorithm just described halts at time λ∞
+ +ω which is impossible
since it works on input 0 and λ∞is the supremum of the clockable ordinals.
It is rather easy to imagine how to modify the program in order to get 2,
3,. . . admissible ordinals in a gap. Our goal now is to extend this to arbitrary
writable order types, but there are some diﬃculties to deal with recursively
inaccessibles that may appear in limit cases.
Theorem 8. Let α be a writable ordinal. Let β > writing(α) be minimal such
that β starts a gap such that the set S of admissible ordinals properly contained
in this gap is of order type β ≥α. Then β = α.
In other terms, after the writing time for α, the ﬁrst gap with at least α
admissibles inside has exactly α admissibles inside (thus occurs before λ∞). We
ﬁrst give a proof when α is a limit ordinal, and then a more general and more
complex proof when α is a successor ordinal.
1 Here, by ‘parallel’, we mean that we alternately perform one step of the ﬁrst and
one of the second algorithm. After ω many steps of the parallel execution, we will
thus have performed ω many steps of both algorithms.

Admissibles in Gaps
181
Proof (Proof for limit cases). We assume here that α is a limit ordinal. First,
write a code d for α on some scratch tape. For ι < α, we denote by dι the natural
number coding ι in d. We consider two further scratch tapes, the ﬁrst of which
we organize into ω many disjoint portions. We also reserve a fourth scratch tape
for ‘bookkeeping’. Initially, this tape will be empty.
Now consider the following algorithm:
On a ﬁfth scratch tape, run the program Pgap from Proposition 3. When a
gap is detected starting at an ordinal α0 coded by c0, write c0 to the d(0)th
portion of the second tape and mark the d(0)th cell of the fourth tape.
We now use the third tape to carry out P c0
gap in parallel with Pgap. If any
program simulated in the execution of Pgap halts before P c0
gap detects a gap, we
erase the ﬁrst, second, third and fourth tape and continue running Pgap. On the
other hand, if none of these programs halts before P c0
gap detects a gap, P c0
gap will
write a code c1 for α+
0 . We then write c1 to the d(1)th portion of the second
tape and mark the d(1)th cell of the fourth tape.
We now proceed in ι phases for ι < α:
If ι = ¯ι + 1 is a successor ordinal, and if we have a code for c¯ι written on the
d(¯ι)th portion of the second tape, we can use the third tape to run P c¯ι
gap. If any
program simulated in the execution of Pgap halts before P c¯ι
gap detects an ordinal
αι starting a gap, we erase the ﬁrst four scratch tapes and continue with Pgap.
If not, we take the output cι of Pgap (which will code αι = α+
¯ι ), write it to the
d(ι)th portion of the second tape and mark the d(ι)th cell of the third tape.
On the other hand, if ι is a limit ordinal, then codes have been written to all
portions of the second tape with index < ι and no program simulated by Pgap
has halted so far. We compute in ω-real time the sum of all of these ordinals to
the δth portion.
Thus we get a representation of the supremum of all ι’s admissibles in the
gap.
Now let us deﬁne the halting case for this loop on ι, i.e., ι = α. As soon
as the α’s storage is ﬁlled, we halt. This is implemented by using an improved
version of the count-through algorithm Pstopwatch which does not use ω extra
time to check that α’s storage has been ﬁlled: we halt immediately after having
ﬁlled the α’s list. But in our program we could miss some admissibles: exactly
those that are limits of admissibles (supremum of ι’s admissibles in the gap for
all ι < α that are limit ordinals). We can ignore them because those recursively
inaccessible ordinals are rare enough: when α is a limit ordinal, if you consider
any sequence of consecutive α ordinals, the subsequence of those that are not
recursively inaccessible has the same ordinal type α.
Thus the halting time for the present algorithm is clockable and so is the
supremum of the α’s admissibles which is not admissible. Hence we have exactly
α admissibles in the gap.
To prove the case where α is a successor ordinal, we must be more precise: if
we denote by α the largest limit ordinal < α, then we have to check whether the
α’s ordinal of the gap is recursively inaccessible or not. Remark that for other

182
M. Carl et al.
admissibles of the list we do not need to check for recursive enumerability (as
explained above), but our program will take them into account anyway.
Thus, we need an algorithmic characterisation for recursively inaccessible
ordinals :
Lemma 2. Let β < λ∞be a limit of admissibles αi. Let xi be a code for αi in
Lβ. The ordinal β is admissible (hence recursively inaccessible) if and only if β
is in a gap for all computations with oracle xi.
Proof. Of course, if β is admissible, then it is not clockable for any xi-oracle
computation with xi ∈Lβ. Conversely, if β is not admissible, then there will be
a Σ1-deﬁnable surjection from ω to β, and this surjection can be computed by
an algorithm using as oracle some δ < β. Thus we can consider αi > δ, compute
this surjection from ω and halt.
Proof (Proof for successor cases). Now α is a successor ordinal. We explain below
how we improve the program deﬁned in the limit case above. The aim of our
improvement is to check when ι is a limit ordinal, whether the sup of the ﬁrst
ι admissibles is admissible or not. As soon as we introduce a new admissible in
the α list, then we start the machine U on this input, in order to check for gaps
with this admissible as oracle. Of course, what is subtle is to arrange all these
computations, both in space and in time so that it is realized in ω-real time. The
argument for space is that we can arrange an extra working tape as a ω2 data
structure, and for time, the argument is that making n more steps of the n ﬁrst
machines requires only a ﬁnite amount of time.
Now, we can use Lemma 2 directly and when ι is a limit ordinal determine
whether the sup of the ﬁrst ι admissibles is admissible after only ω steps by
ﬂashing a common cell when a halting program is discovered by one of the
oracle computations. When we thus ﬁnd a recursively inaccessible ordinal, we
introduce it in the α-storage.
The program halts as previously.
Corollary 2. If α is a writable ordinal, then there is a gap such that the set of
admissible ordinals properly contained in this gap has order type α.
Proof. By Theorem 8, this follows if there is a gap such that the set of ordinals
properly contained in it has order type ≥α.
However, if this is not the case, then the algorithm described in the proof
of Theorem 8 will run up to time λ∞, after which no further clockable ordinals
can appear; therefore, the algorithm will then continue by running until the
working time has passed through a set of admissible ordinals of order type α
and then stop.
Thus, we have found an ITTM-program that halts after more than λ∞many
steps on input 0, a contradiction.
Now we provide a lower bound on the ending points of those gaps with exactly
α admissibles.

Admissibles in Gaps
183
Corollary 3. Let α be a writable ordinal. After the writing time for α, the ﬁrst
gap with α admissibles inside ends
– if α is a limit ordinal, then exactly at the sup of those α admissibles in the
gap,
– if α is a successor ordinal, then exactly ω steps after the last admissible of
the gap.
Proof. The proof consists in checking carefully the halting time of our program
given in the proofs of Theorem 8. If α is a limit ordinal, then the situation is
clear: our algorithm halts immediately thanks to our use of an improved version
of the count through program and this result has been used to prove that the
supremum of the α admissibles is not admissible.
For the successor case, then there are two diﬀerent possible situations. Let
us denote by α the greatest limit ordinal < α. The easy situation is when the
supremum of the ﬁrst α’s admissibles of the gap is not admissible. Then before
halting our algorithm ﬁnds the last admissibles by the procedure of comput-
ing the next admissible through the computation of ωCK
1
relativised to the last
admissible found and the procedures halts ω steps after for the same reason that
we can ﬁnd in the proof that the gap starting at ωCK
1
is of size ω. If the supre-
mum of the ﬁrst α’s admissibles of the gap is admissible and α > α + 1, the last
admissible is found by the same procedure and the program halts ω steps after
it. But in this case, if α = α + 1, then we should ﬁnd the exact time when we
discover that the supremum is admissible. Our programs checks the hypothesis
of Lemma 2, all the parallel oracle computations look for a clockable but do not
ﬁnd any, thus we get this result just ω steps after the supremum, which is the
last admissible among the α’s.
We note that when we halt ω steps after an admissible, then we get directly
an optimal bound since ω is the minimal time between an admissible and the
end of its gap.
Remark that the previous theorems start with “After the writing time for α. . . ”
We can modify this as follows: “Let δ be any clockable such that δ ≥writing(α).
After the writing time for δ. . . ”. The proofs are slightly modiﬁed: we run the
programs as previously but start the gap detection only after having clocked δ.
3.1
Admissibles of Higher Rank
We deﬁne the rank rk(x) of an admissible ordinal α as follows:
– If α = β+ for some β, then rk(α) = 0.
– If β is maximal such that α is a limit of admissible ordinals of rank δ for
every δ < β, then rk(α) = β.
We call rank-admissible an admissible α of rank α, i.e., and admissible α with
rk(α) = α. Note that λ∞is a rank-admissible, but it is not the smallest one, as
follows quite easily from Theorem 2.

184
M. Carl et al.
Lemma 3. For any δ < λ∞, there is an admissible α with rk(α) = δ that starts
a gap. Moreover, there is an α with rk(α) = α that starts a gap (and more).
Proof. This follows as in the ﬁrst proof of Theorem 6: As λ∞has all of the
required rank properties and there are coﬁnally many clockable ordinals below
λ∞, these properties are Σ1-expressible and there are no clockable ordinals >
λ∞, Lζ∞believes in the existence of ordinals with the required rank properties
with coﬁnally many clockable ordinals below. This is then reﬂected to Lλ∞, thus
Lλ∞also contains such ordinals, but since λ∞is a limit of clockable ordinals,
these must start gaps.
Once again, we can have some more information on the size of the gap through
a more algorithmic version of this proof.
Theorem 9. Consider α < λ∞. Let δ be any clockable such that δ ≥writing(α).
Then after δ, the ﬁrst gap starting with an admissible of rank α is of size ω.
Proof. (Sketch) We start gap detection as usual, using Pgap. In parallel, we
write α and clock δ. Let x be a code for α, written to some scratch tape at time
writing(α). For ι < α, let d(ι) denote the natural number representing ι in the
sense of x.
We consider ω cells, each of them will correspond to a level in α’s represen-
tation, we call them “cells in α”. (This construction requires ω steps but it does
not matter since there is no admissible nearby). For each clockable discovered,
we ﬂash a special “clockable” cell thus at each limit ordinal, we know whether
it is a limit of clockable ordinals or not. For each limit ordinal that is a limit of
clockable ordinals, we test in parallel:
– whether it starts a gap (requires ω steps),
– what is the smallest (in the order of α) cell in α with value 0 (requires ω
steps).
If the limit does not start a gap, then it is clockable and we erase all the cells
in α. If it starts a gap, then we ﬂash the smallest cell in α order with value 0. If
there is no such cell, we halt.
Note: the algorithm halts exactly ω steps after the ﬁrst admissible of rank α
found after δ. We get some extra information: for each limit ordinal that is a
limit of clockable ordinals, its potential rank (if it is admissible) is exactly the
smallest cell at 0 in α.
Using the extra information provided by the program described in the pre-
vious proof we easily obtain the following result.
Proposition 4. There is an ITTM-program P such that, whenever x and y are
codes for ordinals α and β, then P(x, y) halts with output 1 if β is an admissible
of rank α and otherwise halts with output 0.
Proof. This is basically just a recursive algorithm, calling itself for parts of x
that code ordinals < α, combined with the admissibility checking with oracles
used in the proof of Theorem 8.

Admissibles in Gaps
185
As a special case, when we run P(x, x) we get the following result.
Corollary 4. There is an ITTM-program Q such that Q(x) halts with output 1
if and only if x codes a rank-admissible.
We then get an improved version of the existence of rank-admissibles by
combining this result with Theorem 9.
Corollary 5. The smallest admissible ordinal α with rk(α) = α starts a gap of
length ω.
Theorem 10. Let us call β0 the ﬁrst admissible that starts a gap of size equal
to its starting point. The ordinal β0 is a rank-admissible but not the ﬁrst rank-
admissible.
Proof. Assume that β0 is of rank α < β0, then writing(α) < β0. Remark that β0
is a limit of clockables as a starting point of a gap. Thus there exists a clockable
δ < β0 such that all admissibles in the interval [δ, β0] have rank < α (by the
deﬁnition of rank). Thus β0 is the ﬁrst ordinal of rank α after this clockable δ
which contradicts the size of its gap. Hence it is rank-admissible, but not the
ﬁrst one since its gap is too large by Corollary 5.
Please note that the same proof can be used for γ0 instead of β0, where γ0
is the ﬁrst admissible that starts a gap with as many admissible inside as its
starting point. This γ0 is a rank-admissible.
3.2
Long Gaps
We ﬁnish with a rather general theorem on the size of gaps relative to their
starting point. Let f : ω1 →ω1. Then f is called ITTM-computable if and only
if there is an ITTM-program P such that, whenever x is a code for α < ω1, then
P x(0) ↓= y, where y is a code for f(α).
If θ : ω1 →ω1 and f : ω1 →ω1 is an ITTM-computable function that is
computed by the program P, we say that θ is the running time of P if and only
if, for every α < ω1 and every code x for α, P x(0) halts in exactly θ(α) many
steps.
In general, an ITTM-program computing a function f : ω1 →ω1 need not
have a running time, as the computation time on α may turn out to depend
on the code for α. However, many functions on ordinals —such as the successor
function— can be computed in a way that does not depend on the code.
Theorem 11. Let f : ω1 →ω1 be ITTM-computable. Then there is an ordinal
α starting a gap of size ≥f(α).
Proof. Run Pgap as usual. When a code c for an ordinal α starting a gap is
written, use it to compute a code c′ for f(α), while continuing to run Pgap in
parallel. If any simulated program halts in the meantime, stop the computation
of f(α) and continue with Pgap. Otherwise, use P c′
stopwatch to run for another

186
M. Carl et al.
f(α) many steps in parallel with Pgap, again stopping if any simulated program
stops along the way. On the other hand, if P c′
stopwatch stops, we halt.
Clearly, this program halts when Pgap writes a code for an ordinal α such
that no clockable ordinal exists in the interval [α, f(α)). As such an α cannot
exist below γ∞, Pgap would halt after at least γ∞+ f(γ∞) > γ∞many steps,
which is a contradiction. Hence such a gap must exist.
With a bit more work, one can also control the exact sizes of such gaps:
Theorem 12. Let f : ω1 →ω1 be an ITTM-computable function, that maps
limit ordinals to limit ordinals, and denote by θ(α) the computation time of f on
α. Then there is some ordinal α starting a gap of size exactly θ(α) + f(α) + ω.
Proof. Using the fact that clockable ordinals are writable, it is not hard to see
that θ is computable. By Theorem 11, there is therefore an α starting a gap of
length at least θ(α) + f(α).
To see that there is gap of exactly the size in question, we consider the
following algorithm:
First, run Pgap; whenever Pgap outputs a real number x coding an ordinal
α that starts a gap, we run the following parallel to the further execution of
Pgap: First compute f(α), which takes θ(α) many steps. After this, a code c for
f(α) will be written. Then run P c
stopwatch. If any of the simulated programs in
Pgap halt in the course of this, we erase the tapes used for the computation of
f(α) and the run of P c
stopwatch and continue with Pgap. On the other hand, if
P c
stopwatch halts, the whole computation halts.
When this algorithm ﬁrst checks some ordinal β starting a gap, it has taken
β many steps. After encountering the ﬁrst α starting a gap of size ≥θ(α)+f(α),
the algorithm runs for another f(α) + ω many steps and then halts. Also, by
the deﬁnition of the algorithm, there are no halting times between α and θ(α) +
f(α) + ω. Thus α is as desired.
References
1. Barwise, J.: Admissible Sets and Structures: An Approach to Deﬁnability Theory.
Perspectives in Mathematical Logic, vol. 7. Springer, Heidelberg (1975)
2. Durand, B., Laﬁtte, G.: A constructive swiss knife for inﬁnite time turing machines
(2016)
3. Hamkins, J.D., Lewis, A.: Inﬁnite time turing machines. J. Symbolic Log. 65(2),
567–604 (2000)
4. Welch, P.D.: Eventually inﬁnite time turing degrees: Inﬁnite time decidable reals.
J. Symbolic Log. 65(3), 1193–1203 (2000)
5. Welch, P.D.: The length of inﬁnite time turing machine computations. Bull. London
Math. Soc. 32(2), 129–136 (2000)
6. Welch, P.D.: The transﬁnite action of 1 tape turing machines. In: Cooper, S.B.,
L¨owe, B., Torenvliet, L. (eds.) CiE 2005. LNCS, vol. 3526, pp. 532–539. Springer,
Heidelberg (2005). doi:10.1007/11494645 65
7. Welch, P.D.: Characteristics of discrete transﬁnite time turing machine models:
Halting times, stabilization times, and normal form theorems. Theoret. Comput.
Sci. 410, 426–442 (2009)

Koepke Machines and Satisﬁability for Inﬁnitary
Propositional Languages
Merlin Carl1,2, Benedikt L¨owe3,4,5(B), and Benjamin G. Rin6
1 Fachbereich Mathematik und Statistik,
Universit¨at Konstanz, 78457 Konstanz, Germany
merlin.carl@uni-konstanz.de
2 Fakult¨at f¨ur Informatik und Mathematik,
Universit¨at Passau, Innstraße 33, 94032 Passau, Germany
3 Institute for Logic, Language and Computation, Universiteit van Amsterdam,
Postbus 94242, 1090GE Amsterdam, The Netherlands
b.loewe@uva.nl
4 Fachbereich Mathematik, Universit¨at Hamburg,
Bundesstrasse 55, 20146 Hamburg, Germany
5 Christ’s College, Churchill College, and Faculty of Mathematics,
University of Cambridge, Wilberforce Road, Cambridge CB3 0WA, England
6 Departement Filosoﬁe En Religiewetenschap, Universiteit Utrecht,
Janskerkhof 13, 3512BL Utrecht, The Netherlands
b.g.rin@uu.nl
Abstract. We consider complexity theory for Koepke machines, also
known as Ordinal Turing Machines (OTMs), and deﬁne inﬁnitary com-
plexity classes ∞-P and ∞-NP and the OTM analogue of the satisﬁa-
bility problem, denoted by ∞-SAT. We show that ∞-SAT is in ∞-NP
and ∞-NP-hard (i.e., the problem is ∞-NP-complete), but not OTM
decidable.
1
Inﬁnitary Computation and Its Running Times
1.1
Introduction
Various versions of Turing machines for inﬁnitary computation have been pro-
posed. They all have in common that they have ordinal-indexed tapes on which
they can read and write symbols from a ﬁnite alphabet Σ, they run in ordinal-
indexed steps of time, and follow the usual instructions for Turing machines for
the successor ordinal steps. The ﬁrst such type of machines were the Hamkins-
Kidder machines or Inﬁnite Time Turing Machines (ITTMs) deﬁned in [5].
These machines have a regular tape of order type ω, but do not have to halt
in ﬁnite time: instead, they can run through transﬁnite ordinal time steps. This
results in an asymmetric situation between time and space as an ITTM can
run through the class of all ordinals, but only has ω many cells to write on.
In [10,11], Koepke symmetrised ITTMs and deﬁned what are now known as
Koepke machines or Ordinal Turing Machines (OTMs): OTMs have a class-
sized tape indexed by ordinals and run through ordinal time. Other machine
c
⃝Springer International Publishing AG 2017
J. Kari et al. (Eds.): CiE 2017, LNCS 10307, pp. 187–197, 2017.
DOI: 10.1007/978-3-319-58741-7 19

188
M. Carl et al.
concepts include machines that restrict the space to a given ordinal α but run
through arbitrary ordinal time and machines where both time and space are
symmetrically restricted to an ordinal α (cf. [3,12,14]).
The symmetry between space and time for Koepke machines reﬂects that
of ﬁnitary Turing machines. The ﬁrst author has argued in [1] that Koepke
machines are the natural inﬁnitary analogue for ﬁnitary computability theory.
In this paper, we shall study deterministic and nondeterministic polynomial time
computation for Koepke machines. In Sect. 1.2, we give the basic deﬁnitions of
our model of computation and its running time analysis. Complexity theory for
inﬁnitary computation was introduced by Schindler in [15] in the context of
Hamkins-Kidder machines; for Koepke machines, the deﬁnitions were discussed
by the second author and Winter [13,16,17]. We give precise deﬁnitions in this
tradition (introducing the complexity class ∞-NP) and discuss fundamental
diﬀerences between ﬁnitary and inﬁnitary computation in Sect. 2. In Sect. 3, we
introduce the OTM analogue of the satisﬁability problem ∞-SAT, show that it
is in ∞-NP and that every problem in ∞-NP polynomially reduces to it (i.e.,
∞-SAT is ∞-NP-hard). However, due to the phenomena discussed in Sect. 2.2,
being ∞-NP-complete does not necessarily imply that ∞-SAT is OTM decid-
able: in Sect. 4, we show that it is not (and discuss a notable diﬀerence between
the general decision problem ∞-SAT and its countable fragment).
1.2
Basic Deﬁnitions
In the following, we shall be working with Koepke machines, or OTMs, sometimes
allowing ordinal parameters in our computations. For detailed deﬁnitions, we
refer the reader to [10].
An OTM input is a function X : α →Σ where lh(X) := α is an ordinal called
the length of X. We assume that the tape alphabet Σ contains a blank symbol
that allows us to express shorter OTM inputs as longer ones: if lh(X) = α < β,
we consider X∗: β →Σ with X∗(γ) := X(γ) for γ < α and X∗(γ) =
for γ ≥α and identify X and X∗. A class of OTM inputs is called an OTM
decision problem. A Koepke machine M decides an OTM decision problem C in
parameter η if it halts with parameter η for every OTM input X and outputs
1 if and only if X ∈C; an OTM decision problem is called OTM decidable in
parameter η if there is a Koepke machine deciding it in parameter η. Parameter-
free computation is the special case where η is a recursive ordinal (e.g., 0). An
OTM decision problem is called bounded with bound λ if for every OTM input
X ∈C, we have that lh(X) < λ.
We emphasize that (as in the ﬁnitary case) most natural decision problems
do not occur as classes of OTM inputs, but have to be formally encoded as OTM
decision problems. Typically, they come in the form of some class D of objects of
some particular kind (e.g., formulas, trees, graphs, etc.) together with a coding
(class) function code such that for every (relevant) set Z, code(Z) is an OTM
input, and C := {code(Z) ; Z ∈D} is an OTM decision problem. We shall see
below that the choice of coding is crucial in the inﬁnitary case.

Koepke Machines and Satisﬁability for Inﬁnitary Propositional Languages
189
Let f : Ord →Ord be an increasing class function (in the following, we
shall refer to these as complexity functions). A class function f is a polynomial
function if there are ordinals αn ≥... ≥α0 such that for all γ, we have
f(γ) = γαn + γαn−1 + ... + γα0.
We say that a Koepke machine M is a time f machine if the machine halts for
every OTM input X in less than f(lh(X)) steps.
If C is an OTM decision problem, we write C ∈Time(f) if there is a time
f machine deciding C and C ∈∞-P if there is a polynomial function f such
that C ∈Time(f). In the latter case, we say that it is OTM polynomial time
decidable.
Similarly, if C and D are OTM decision problems, we say that C is reducible
to D in time f if there is a time f machine that takes an OTM input X and
produces an output Y such that X ∈C if and only if Y ∈D. We say that C is
reducible to D in polynomial time if there is a polynomial function f such that
C is reducible to D in time f.
Proposition 1. If C is a bounded OTM decision problem with bound λ ≥ω,
then exactly one of the following holds:
(i) The problem C is not OTM decidable in parameter λ; or
(ii) the problem C is decided by a time c machine in parameter λ, where c is the
constant function α →|λ|+.
Proof. Suppose that C is decidable by a Koepke machine M in parameter λ. In
particular, for every input X, the machine M halts. If lh(X) < λ, a standard
L¨owenheim-Skolem argument using the absoluteness of computations shows that
there is some α < |λ|+ such that the model Lα[X] is a model of “the computation
of M with input X and parameter λ halts”. But then the computation must halt
before α < |λ|+. Checking whether lh(X) < λ can be done in time λ using the
parameter λ.
⊓⊔
The proof of Proposition 1 has two immediate consequences for running times
of inﬁnitary computations:
First, while Koepke machines can in principle use the entire length of the
class of ordinals for their computation time, halting Koepke machines (and these
are the only ones that matter for decision problems) do not: they can never
substantially outrun the size of the input (in the sense that, if the input has
cardinality κ, then the computation will take less than (κ+)L many steps). This
is a marked diﬀerence to the ﬁnitary case.
This immediately implies that the relevant operations for running time analy-
sis of Koepke machines must necessarily be ordinal operations rather than cardi-
nal operations since any non-trivial cardinal operations on inﬁnite ordinals will
move beyond the bounds of Proposition 1.
This in turn yields a second important consequence: as in the ﬁnitary case,
inﬁnitary complexity theory is sensitive to the encoding of the input; the more

190
M. Carl et al.
eﬃcient the input encoding is, the harder it is to prove complexity bounds for
a decision problem. But every ordinal κ ≤α ≤κ+ can be encoded by a set of
order type κ, so there is a maximally eﬃcient encoding in terms of input length.
We illustrate this phenomenon by showing that any OTM decision problem
that is decidable in time f by a machine M has a re-coded version such that
the re-coded version of M is not a time f machine. Let κ be a cardinal and C
be an OTM decision problem that was obtained from some class D by means
of a coding function code such that C = {code(Z) ; Z ∈D}. Let f : Ord →
Ord be a complexity function and M a time f machine that decides C and
for the sake of non-triviality, assume that f(κ) < κ+. Now, if there is some
OTM input X = code(Z) with lh(X) < κ+ such that M takes more than f(κ)
many steps before halting. Then let λ := max{f(κ), lh(X)}, let π be a bijection
between κ and λ, and let code∗be the coding function corresponding to the
combination of code and π. In particular, code∗(Z) has length κ. If we write
C∗:= {code∗(Z) ; Z ∈D}, then the appropriately re-coded version of M does
not decide C∗in time f since it will run for more than f(lh(code∗(Z))) = f(κ)
many steps.
Consequently, in inﬁnitary computation, a suﬃciently eﬃcient coding for the
input can potentially destroy the complexity properties of any machine. Hence,
we need to assume that the encoding of the decision problem respects the natural
length of the objects being coded.
2
Complexity Theory for Koepke Machines
2.1
Deﬁnitions
Nondeterministic complexity classes for inﬁnitary computation were ﬁrst intro-
duced by Schindler in [15] for Hamkins-Kidder machines; Schindler’s deﬁnition
did not use nondeterministic Hamkins-Kidder machines, but deﬁned the class
NP in terms of checking a witness. This was linked in [13, Proposition 11] to
nondeterministic Hamkins-Kidder machines. Schindler exploited the asymmetry
between time and space for Hamkins-Kidder machines and showed that for his
deﬁnitions of P and NP for Hamkins-Kidder machines, we get P ⫋NP. His
results were later improved to P ⫋NP ∩co-NP in [4]; cf. also [6,13,16,17].
In the following, we give the corresponding deﬁnitions for Koepke machines
that were essentially ﬁrst developed by Winter in [16]. We call a class D of pairs
of OTM inputs a witnessed OTM decision problem. If C is an OTM decision
problem and D is a witnessed OTM decision problem, we say that C is the
projection of D if
X ∈C ⇐⇒∃W((W, X) ∈D);
i.e., if (W, X) ∈D, we interpret W as a witness for the membership of X in C.
As usual, if X is an OTM input of limit ordinal length λ, we can consider X
as a pair (X0, X1) of OTM inputs of length λ via X0(μ + n) := X(μ + 2n) and
X1(μ + n) := X(μ + 2n + 1) (for limit ordinals μ < λ). If f : Ord →Ord is a

Koepke Machines and Satisﬁability for Inﬁnitary Propositional Languages
191
complexity function, we say that a Koepke machine M is a ∗-time f machine if
the machine halts for every OTM input X in less than f(lh(X1)) steps.
If D is a witnessed OTM decision problem and M is a Koepke machine, we
say that M decides D if it halts on all OTM inputs and it outputs 1 on input
X if and only if (X0, X1) ∈D. If C is an OTM decision problem, we write
C ∈NTime(f) if there is a witnessed OTM decision problem D such that C
is the projection of D and there is a ∗-time f machine deciding D. We write
C ∈∞-NP if there is a polynomial function f such that C ∈NTime(f).
2.2
The Fundamental Diﬀerence Between Finitary and Inﬁnitary
Computation
In the case of ordinary Turing machines and complexity functions f : N →N,
we can recapture nondeterministic computation by deterministic computation:
suppose that you have some complexity function f : N →N and some decision
problem C that is decided by a ∗-time f machine M. This means that there is
a witnessed decision problem D such that C is the projection of D. On input
(W, X) with lh(X) = n, the machine halts in less than f(n) steps. In particular,
it reads at most the ﬁrst f(n) many digits of W, so we can ignore the rest of
the information in W. This allows us to run an exhaustive brute force algorithm
that checks all possible witnesses: there are Σf(n) many input sequences of length
f(n), so we can just run M on all of these in combination with X; if f(n) :=
f(n) · Σf(n) · k for a suﬃciently large k ∈N, then the brute force algorithm
checks in time f whether X ∈C. This argument breaks down for inﬁnitary
computation, as will be shown in Proposition 2.
Since the state of a Koepke machine is absolute between transitive models
of set theory, the content of the tape has to be constructible. Thus, for the
discussion of brute force algorithms, it is sensible to work under the assumption
of V=L.
In general, if M is any Koepke machine and f is any complexity function,
we say that a machine 
M is an exhaustive brute force machine associated to M
relative to f if at input Y with lh(Y ) = α, the machine 
M successively writes
all OTM inputs Z of length f(α) on the scratch tape and then runs the machine
M on input X with X0 = Z and X1 = Y . It gives the output 0 if all of the runs
of M produced output 0 and 1 if one of the runs of M produced 1. The above
argument shows for ﬁnitary computation that 
M is a time f-machine if M was
a ∗-time f machine.
Proposition 2. Assume V=L. Suppose that f is a complexity function such
that there is some α ≥ω with f(α) ≥|α| and that M is a ∗-time f machine and

M is an exhaustive brute force machine associated to M relative to f. Then 
M
does not halt for any OTM input of length α.
Proof. Let X be an OTM input of length α. The machine 
M runs for at least
2|α| ≥|α|+ many steps since the exhaustive brute force machine has to produce
all OTM inputs of length f(α) ≥|α|. But Proposition 1 tells us that no machine
can run for |α|+ many steps on input X and after that still halt.
⊓⊔

192
M. Carl et al.
The fact that for inﬁnitary computation, decision problems that are nonde-
terministically decidable can be deterministically undecidable has been observed
and used by Winter [16, p. 74]. We shall provide a concrete example for this in
Sect. 4.
3
An Inﬁnitary Analogue of SAT
In ﬁnitary computation, the decision problem SAT is the set of satisﬁable propo-
sitional formulas.
We deﬁne the natural analogue of SAT in the context of Koepke machines in
the style of inﬁnitary languages (cf. [9]). Let Var ⊆L be a class of propositional
variables. We form formulas of the inﬁnitary propositional language L∞,0 with
the unary operator ¬ corresponding to negation and the operator  that takes
a set of formulas and produces its conjunction.
1. Every element of Var is in L∞,0.
2. If ϕ ∈L∞,0, then so is ¬ϕ.
3. If Φ is a set of members of L∞,0, then  Φ is an element of L∞,0.
As usual, we abbreviate ¬ {¬ϕ ; ϕ ∈Φ} by  Φ. Formulas of the language
L∞,0 naturally correspond to labelled well-founded trees (T, ℓ) where each node
in T has a set of successors and ℓis a function from the set of leaves of T
to Var. We write Varϕ := ran(ℓ) for the set of variables occurring in ϕ. By a
simple Mostowski collapse argument, we may assume that Varϕ ⊆Lβ for some
β < |T|+. The width of the tree T, denoted by width(T) is the supremum
of the cardinalities of the sets of successors of branching nodes; the height of
the tree T, denoted by height(T) is deﬁned by the usual recursion on the well-
founded tree structure. By interpreting the leaves t of T as propositional variables
ℓ(t), its branching nodes as inﬁnite conjunctions, and its non-branching nodes
as negations, we can identify a formula with a labelled well-founded tree. A
function v : dom(v) →{0, 1} with dom(v) ⊆Var is called a valuation. As usual,
if ϕ = (T, ℓ) is a labelled well-founded tree, any valuation v with dom(v) ⊇Varϕ
uniquely extends to a map v : T →{0, 1} via the following recursive deﬁnition:
1. if t ∈T is a leaf, then v(t) := v(ℓ(t));
2. if t ∈T is a non-branching node and t′ is its unique successor in T, then
v(t) := 1 −v(t′);
3. if t ∈T is a branching node and X is the set of its successors in T, then
v(t) := min{v(x) ; x ∈X}.
We deﬁne v(T, ℓ) to be the value of v at the root of the tree T.
Deﬁnition 3. The problem ∞-SAT is to decide on input (T, ℓ) ∈L∞,0 whether
there is a valuation v such that v(T, ℓ) = 1.
Deﬁnition 3 does not deﬁne an OTM decision problem: in order to do so, we
still need to specify in which way the formula (T, ℓ) is encoded as an OTM input.

Koepke Machines and Satisﬁability for Inﬁnitary Propositional Languages
193
As emphasized before, it is crucial in the realm of inﬁnitary computation that
this encoding respects the natural length of the input. We shall not specify a
concrete encoding here (since it does not matter for anything that follows), but
insist that the encoding function has the property that
lh(code(T, ℓ)) = max(width(T), height(T)).
With this requirement, the following results are straightforward adaptations
of the classical arguments showing that SAT is NP-complete:
Theorem 4. The OTM decision problem ∞-SAT is in ∞-NP.
Theorem 5. Every problem in ∞-NP reduces in polynomial time to ∞-SAT.
Proof. The proof largely follows the same general structure as standard textbook
proofs of the ﬁnitary Cook-Levin theorem, but with an additional component to
accommodate the limit stages of machine computation.
⊓⊔
4
The Undecidability of ∞-SAT
In Sect. 3, we proved that ∞-SAT is ∞-NP-complete. However, as pointed out
in Sect. 2.2, in inﬁnitary computation, being nondeterministically decidable does
not imply deterministic decidability. In this section, we shall show that ∞-SAT
is not OTM decidable. In fact, the decidability behaviour of ∞-SAT restricted
to constructibly countable formulas is diﬀerent from the general behaviour; this
follows from a theorem by Jensen and Karp:
Theorem 6 (Jensen & Karp). If x is a real and α is a limit of x-admissible
ordinals, then Σ1(x)-sentences are absolute between Vα and Lα[x].
Proof. This is the relativised version of a theorem proved in [7, p. 162]. The
relativisation is discussed in [2, Appendix].
⊓⊔
Theorem 7. Let ϕ = (T, ℓ) ∈L be a constructibly countable formula, i.e., L |=
“ T is a countable tree”. Then there is an α < ωL
1 such that exactly one of the
following holds:
1. ϕ is not satisﬁable, or
2. there is a v ∈Lα such that v(ϕ) = 1.
Proof. Since ϕ is countable in L, ﬁnd a real c and some β < ωL
1 such that c ∈Lβ
and c encodes ϕ. Let α be a limit of c-admissibles above β. The sentence “there
is a valuation v such that v(ϕ) = 1” is Σ1(c) and hence by Theorem 6 absolute
between Vα and Lα[c] = Lα. So, if ϕ is satisﬁable, then a witness of this lies
in Lα.
⊓⊔
In contrast, the conclusion of Theorem 7 is consistently false if we allow for
formulas that are not countable in L:

194
M. Carl et al.
Theorem 8. There is a constructible formula ϕ ∈L∞,0 such that
1. for all constructible valuations v ∈L, we have that v(ϕ) = 0, and
2. if ωL
1 < ω1, then there is a valuation v such that v(ϕ) = 1.
Proof. For every i ∈N and α < ωL
1 , let Pi,α be a propositional letter. We deﬁne
Φ :=

i∈N

α<ωL
1

β<ωL
1
β̸=α
¬(Pi,α ∧Pi,β) ∧

α∈ωL
1

i∈N
Pi,α ∧

i∈N

α∈ωL
1
Pi,α.
If Φ is satisﬁable, then there is a surjection from N onto ωL
1 , so clearly, Φ is
satisﬁable if and only if ωL
1 < ω1.
⊓⊔
The formula ϕ of Theorem 8 has size ℵL
1 ; by Theorem 7, it is impossible to
have a smaller example. Theorem 8 allows us to reﬁne the argument of Proposi-
tion 2: in Proposition 2, it was the exhaustivity of the machine 
M that did not
allow it to stop (since it would run for too long); we can now see that sometimes,
even writing the witness itself can be too much to ask. If C is an OTM deci-
sion problem which is the projection of a witnessed OTM decision problem D,
then we say that a Koepke machine M decides C by producing a witness in D
if it halts on every input X and outputs either 0 or some sequence Z such that
(Z, X) ∈D. The following statement is a very weak version of our later main
result, Theorem 10:
Corollary 9. If ωL
1
< ω1, then ∞-SAT cannot be decided by producing a
witness.
Proof. By Theorem 8 and the assumption, we have a constructible satisﬁable
formula ϕ with no constructible witness. So, any machine that decides ∞-SAT
by producing a witness will write a non-constructible valuation on the tape. But
no Koepke machine can produce a non-constructible output on constructible
input. Contradiction!
⊓⊔
Theorem 10. The OTM decision problem ∞-SAT is OTM undecidable.
Proof. We shall describe a Koepke machine M that produces with parameter
ωL
1 on input i ∈ω a formula Ψi ∈L∞,0 that is satisﬁable if and only if the ith
Koepke machine halts with parameter ωL
1 .
The proof of the theorem will then proceed by contradiction: Assume that
there is a Koepke machine M ′ that decides ∞-SAT, then we can combine M
and M ′ to get a Koepke machine with parameter ωL
1 that decides the halting
problem for Koepke machines with parameter ωL
1 . But such a machine cannot
exist.
The main task in the proof is the construction of the formula Ψi; this requires
coding of L-structures. We recall that there is a sentence σ ∈L∈such that for
any transitive N, we have (N, ∈) |= σ if and only if N = Lγ for some limit
ordinal γ (cf., e.g., [8, Theorem 3.3]).

Koepke Machines and Satisﬁability for Inﬁnitary Propositional Languages
195
For every β, γ < ωL
1 , we ﬁx a propositional variable Pβ,γ. If v is a valuation,
we can deﬁne a binary relation Ev on ωL
1 by
Ev := {(β, γ) ; v(Pβ,γ) = 1}
and prove the following translation from ﬁrst-order logic into inﬁnitary logic:
Lemma 11. If ϕ ∈L∈, then there is Φϕ ∈L∞,0 such that for every valuation
v, we have v(Φϕ) = 1 if and only if (ωL
1 , Ev) |= ϕ.
Proof. This is an easy induction on the formula complexity of ϕ. The induction
steps are trivial for propositional connectives. Concerning the quantiﬁers, we use
inﬁnite conjunctions to express universal quantiﬁers and inﬁnite disjunctions for
existential quantiﬁers in the obvious way.
⊓⊔
We now add additional propositional variables Bβ,γ for every β, γ < ωL
1 to
encode an embedding from (ωL
1 + 1, ∈) into (ωL
1 , Ev). If v is any valuation, we
deﬁne a second binary relation
πv := {(β, γ) ; v(Bβ,γ) = 1}
similar to Ev, but based on the values of Bβ,γ instead of the values of Pβ,γ.
Lemma 12. There is a formula Ξ such that for all valuations v, we have have
ˆv(Ξ) = 1 if and only if πv is a structure-preserving embedding from (ωL
1 + 1, ∈)
into (ωL
1 , Ev).
Proof. Similar to the formula in the proof of Theorem 8.
⊓⊔
We write ψi for the formula expressing “the ith Koepke machine with para-
meter ωL
1 halts” and notice that this is ﬁrst-order expressible in all structures
Lη for η > ωL
1 (by condensation, in any such Lη, the ordinal ωL
1 is deﬁnable as
the smallest ordinal that does not have a real coding it).
Let S := {s ∈L ; s : ω →ωL
1 }. An easy condensation argument shows that
S ⊆LωL
1 . We now write
Ψi := Ξ ∧Φσ∧ψi ∧

s∈S

i∈ω
¬Ps(i+1),s(i).
Lemma 13. The formula Ψi is satisﬁable if and only if the ith Koepke machine
with parameter ωL
1 halts.
Proof. “⇐”. If the ith Koepke machine with parameter ωL
1 halts, then by the
proof of Proposition 1, it has halted at some time ωL
1 < η < ωL
2 . Find a bijection
j : ωL
1 →Lη. Since η > ωL
1 , we ﬁnd γβ ∈ωL
1 such that j(γβ) = β for every
β < ωL
1 +1. We deﬁne a valuation as follows: v(Pβ,γ) = 1 if and only if j(β) ∈j(γ)
and v(Bβ,γ) = 1 if and only if γ = γβ. It is easy to check that v(Ψi) = 1.

196
M. Carl et al.
“⇒”. If v(Ψi) = 1, then deﬁne Ev and πv as above. The structure (ωL
1 , Ev)
satisﬁes σ ∧ψi by Lemma 11 and is well-founded by 
s∈S

i∈ω ¬Ps(i+1),s(i)
(there are no descending Ev-sequences). So by Mostowski’s Collapsing Lemma,
it is isomorphic to a transitive structure (N, ∈) |= σ ∧ψi. This means that
N = Lη for some limit ordinal η. But Lemma 12 shows that ωL
1 + 1 embeds into
Lη, and hence, η > ωL
1 . Therefore, Lη sees that the ith Koepke machine with
parameter ωL
1 halts. Now the claim follows from absoluteness.
⊓⊔
Clearly, there is a Koepke machine that produces, with parameter ωL
1 , upon
input i ∈ω, the formula Ψi. As mentioned before, this ﬁnishes the proof of
Theorem 10 by contradiction.
⊓⊔
We note that the proof of Theorem 10 can be generalised to show that there is
no ordinal α such that ∞-SAT is OTM decidable in the ordinal parameter α.
We also mention that it is possible to deﬁne OTM analogues of other classical
NP-complete problems such as 3SAT and Subset Sum and prove their ∞-NP-
completeness as well as an OTM analogue of Ladner’s theorem (“there are OTM
decision problems that are in ∞-NP, but neither in ∞-P nor ∞-NP-complete”).
We shall describe these results in future work.
References
1. Carl, M.: Towards a Church-Turing-Thesis for inﬁnitary computation (2013)
preprint. arXiv:1307.6599
2. Carl, M.: Inﬁnite time recognizability from random oracles and the recognizable
jump operator. Computability (to appear)
3. Dawson, B.: Ordinal time Turing Computation. Ph.D. thesis, University of Bristol
(2009)
4. Deolalikar, V., Hamkins, J.D., Schindler, R.: P ̸= NP ∩co-NP for inﬁnite time
Turing machines. J. Log. Comput. 15(5), 577–592 (2005)
5. Hamkins, J.D., Lewis, A.: Inﬁnite time turing machines. J. Symb. Log. 65(2),
567–604 (2000)
6. Hamkins, J.D., Welch, P.D.: Pf ̸= NPf for almost all f. Math. Log. Q. 49(5),
536–540 (2003)
7. Jensen, R.B., Karp, C.: Primitive recursive set functions. In: Axiomatic Set Theory.
Proceedings of the Symposium in Pure Mathematics of the American Mathematical
Society held at the University of California, Los Angeles, California, 10 July–5
August, vol. XIII/I of Proceedings of Symposia in Pure Mathematics, pp. 143–
176. American Mathematical Society (1971)
8. Kanamori, A.: The Higher Inﬁnite. Large Cardinals in Set Theory from Their
Beginnings. Springer Monographs in Mathematics, 2nd edn. Springer, Heidelberg
(2003)
9. Karp,
C.:
Languages
with
Expressions
of
Inﬁnite
Length.
North-Holland,
Amsterdam (1964)
10. Koepke, P.: Turing computations on ordinals. Bull. Symb. Log. 11(3), 377–397
(2005)
11. Koepke, P.: Ordinal computability. In: Ambos-Spies, K., L¨owe, B., Merkle, W.
(eds.) CiE 2009. LNCS, vol. 5635, pp. 280–289. Springer, Heidelberg (2009). doi:10.
1007/978-3-642-03073-4 29

Koepke Machines and Satisﬁability for Inﬁnitary Propositional Languages
197
12. Koepke, P., Seyﬀerth, B.: Ordinal machines and admissible recursion theory. Ann.
Pure Appl. Log. 160, 310–318 (2009)
13. L¨owe, B.: Space bounds for inﬁnitary computation. In: Beckmann, A., Berger, U.,
L¨owe, B., Tucker, J.V. (eds.) CiE 2006. LNCS, vol. 3988, pp. 319–329. Springer,
Heidelberg (2006). doi:10.1007/11780342 34
14. Rin, B.: The computational strengths of α-tape inﬁnite time turing machines. Ann.
Pure Appl. Log. 165(9), 1501–1511 (2014)
15. Schindler, R.: P ̸= NP inﬁnite time turing machines. Monatsh. Math. 139, 335–
340 (2003)
16. Winter, J.: Space complexity in inﬁnite time Turing machines. Master’s thesis,
Universiteit van Amsterdam. ILLC Publications MoL-2007-14 (2007)
17. Winter, J.: Is P = PSPACE for Inﬁnite time turing machines? In: Archibald, M.,
Brattka, V., Goranko, V., L¨owe, B. (eds.) ILC 2007. LNCS, vol. 5489, pp. 126–137.
Springer, Heidelberg (2009). doi:10.1007/978-3-642-03092-5 10

The Recognizability Strength of Inﬁnite Time
Turing Machines with Ordinal Parameters
Merlin Carl1,2,3(B) and Philipp Schlicht1,2,3
1 Fachbereich Mathematik und Statistik, Universit¨at Konstanz, Konstanz, Germany
merlin.carl@uni-konstanz.de
2 Lehrstuhl f¨ur Theoretische Informatik, Universit¨at Passau, Passau, Germany
3 Mathematisches Institut, Universit¨at Bonn, Bonn, Germany
Abstract. We study inﬁnite time Turing machines that attain a spe-
cial state at a given class of ordinals during the computation. We prove
results about sets that can be recognized by these machines. For instance,
the recognizable sets of natural numbers with respect to the cardinal-
detecting inﬁnite time Turing machines introduced in [Hab13] are con-
tained in a countable level of the constructible hierarchy, and the recog-
nizable sets of natural numbers with respect to ﬁnitely many ordinal
parameters are constructible.
1
Introduction
Since the introduction of Inﬁnite Time Turing Machines in [HL00], a vari-
ety of machine models of inﬁnitary computability has been introduced: Turing
machines that work with time and space bounded by an ordinal α, or with tape
of length α but no time limit, or with tape and time both of length On; reg-
ister machines that work in transﬁnite time and can store natural numbers or
arbitrary ordinals in their registers; and so on.
A common feature to all these machine models of inﬁnitary computations
is that they are strongly linked to G¨odel’s constructible universe L. Since their
operations are absolute between V and L, all objects that are writable by such
machines are constructible. However, as was shown in [CSW], these machines
can in a sense deal with objects far beyond L when one considers recognizability
instead of computability, i.e. the ability of the machine to identify some real
number x given in the oracle instead of producing x on the empty input. The
model considered in [CSW] were Koepke’s ordinal Turing machines (OTMs) with
ordinal parameters.
A natural next step is then to determine how strong a machine type has to
be to allow the recognizability of non-constructible real numbers. This motivates
the question whether other of these models also have such strong properties.
It is relatively easy to deduce from Shoenﬁeld’s absoluteness theorem that,
without ordinal parameters, recognizability for all machine types is restricted to
a certain countable level Lσ of G¨odel’s constructible hierarchy L. The question
must hence be what happens when we equip the other models with ordinal
c
⃝Springer International Publishing AG 2017
J. Kari et al. (Eds.): CiE 2017, LNCS 10307, pp. 198–209, 2017.
DOI: 10.1007/978-3-319-58741-7 20

The Recognizability Strength of Inﬁnite Time Turing Machines
199
parameters. For OTMs, an ordinal parameter α is given to the machine by
simply marking the αth cell of the working tape.
For ITTMs with the tape length ω, ordinal parameters cannot be introduced
in this way. However, there is a rather natural way to make ITTMs work with
ordinal parameters, ﬁrst introduced in [Hab13]. Namely, we introduce a new
inner machine state that is assumed whenever the current time is an element
of a given class X of ordinals, and one hence marks one or several points of
time instead of tape cells. In this way, an ITTM can be made to work relative
to an arbitrary class of ordinals, where singletons correspond to single ordinal
parameters. In this case, we will speak of X-ITTMs or ordinal-detecting ITTMs.
For the class of cardinals X, these are the cardinal-detecting ITTMs studied in
[Hab13].
In this paper, we study the recognizability strength of cardinal detecting
ITTMs and more generally of ordinal-detecting ITTMs. We show that every
recognizable set of natural numbers with respect to cardinal-detecting ITTMs is
an element of Lσ, the ﬁrst level of the constructible hierarchy where every Σ1-
statement that is true in L is already true (Theorem 9). However, these machines
can recognize more real numbers than mere ITTMs (Lemma 12). Moreover, we
show that every recognizable set of natural numbers with respect to ITTMs
with ﬁnitely many ordinal parameters is constructible (Theorem 21). However,
these machines recognize some sets of natural numbers outside of Lσ for certain
ordinals α (Lemma 19). We conclude that even with ordinal parameters, ITTM -
recognizability does not lead out of L.
2
Basic Notions and Results
Inﬁnite Time Turing Machines, introduced by Hamkins and Kidder (see [HL00]),
generalize Turing computability to transﬁnite working time. Their computations
work like ordinary Turing computations at successor times, while the tape con-
tent at limit times is obtained as a cell-wise inferior limit of the sequence of
earlier contents and the inner state at limit times is a special limit state. For
details, we refer to [HL00].
There are various notions of computability associated with ITTMs.
Deﬁnition 1. Suppose that x and y are subsets of ω.
1. x is writable in the oracle y if and only if there is an ITTM -program P such
that P y ↓= x, i.e. P, run in the oracle y, halts with x on the output tape.
2. x is eventually writable in the oracle y if and only there is an ITTM -program
P such that P, when run in the oracle y on the empty input, eventually has
x on its output tape and never changes it again.
3. x is accidentally writable in the oracle y if and only there is an ITTM -program
P such that P, when run in the oracle y on the empty input, has x on its
output tape at some point, but may overwrite it later on.

200
M. Carl and P. Schlicht
The ITTM -recognizable sets are deﬁned as follows.
Deﬁnition 2. Suppose that x and y are subsets of ω.
1. x is ITTM-recognizable or simply recognizable relative to y if and only if there
is an ITTM -program P such that, for all subsets z of ω, P z⊕y ↓= δz,x, where
δ is the Kronecker symbol.
2. x is non-deterministically ITTM-recognizable if and only if there is a subset
y of ω such that x ⊕y is ITTM -recognizable.
3. The recognizable closure, denoted by R, is the closure of the empty set under
relativized recognizability.
We will call sets of natural numbers reals. The following alternative charac-
terization of the recognizable closure works rather generally for models of inﬁnite
computation.
Lemma 3. The non-deterministically ITTM -recognizable reals are exactly
those in R.
Proof. If x ⊕y is ITTM -recognizable, then clearly x ∈R. Suppose on the other
hand that x ∈R. Then there is a sequence ⟨x0, . . . , xn⟩with x = x0 such that
xn is ITTM -recognizable and xi is ITTM -recognizable relative to xi+1 for all
i < n. It is easy to see that the join 
i≤n xi is ITTM -recognizable by ﬁrst
identifying the last component and then successively the previous components.
It was observed in [CSW, Lemma 3.2] that R = Lσ ∩P(ω), where σ is least
with the property that Lσ ≺Σ1 L or equivalently least with the property that
every Σ1-statement that it true in L is already true in Lσ.
We will need the following results.
Theorem 4. Suppose that y is a subset of ω.
1. [Wel09, Fact 2.4 & Fact 2.5 & Fact 2.6] There are countable ordinals λy, ζy, Σy
with the following properties for all subsets x of ω.
(a) x is writable relative to y if and only if x ∈Lλy[y].
(b) x is eventually writable relative to y if and only if x ∈Lζy[y].
(c) x is accidentally writable relative to y if and only if x ∈LΣy[y].
2. [Wel14, p.11-12] An ITTM-program in the oracle y will either halt in strictly
less than λy many steps, or it will run into an ever-repeating loop, repeating
the sequence of conﬁgurations between ζy and Σy, which is of order-type Σy,
from Σy on.
3. [Wel09, Theorem 1 & Corollary 2] [Wel14, Theorem 3] The triple ⟨λy, ζy, Σy⟩
is the lexically least triple ⟨α, β, γ⟩of distinct ordinals with Lα[y] ≺Σ1
Lβ[y] ≺Σ2 Lγ[y].
Remark 5. An important result for ITTMs, and many other models of inﬁnite
computation, is the existence of lost melodies, i.e. real numbers that are ITTM -
recognizable, but not writable. The existence of lost melodies for ITTMs was
proved in [HL00]. For more on lost melodies for other machine types, see [Car14a,
Car14b,Car15,CSW].

The Recognizability Strength of Inﬁnite Time Turing Machines
201
We now deﬁne how an inﬁnite time Turing machine works relative to a class
of ordinals.
Deﬁnition 6. For classes X of ordinals, an X-ITTM works like an ITTM with
the modiﬁcation that whenever the running time is an element of X, the machine
state is set to a special reserved state. If an ITTM -program P is run relative to
a class X, we will write X-P instead of P. When X consists of the ordinals in
α = ⟨α0, . . . , αn⟩, we will write α-ITTM for the machine with special states at
times in α, and for α = ⟨α⟩simply α-ITTM.
We thus obtain the cardinal-detecting ITTMs of [Hab13], called cardinal-
recognizing ITTMs there, for the class of all cardinals. Note that there are several
variants of ITTMs, for instance the original deﬁnition in [HL00] with three tapes
of input, output and scratch, that we use here, its variant with only one tape,
and the variant where at limit times, the head is set to the inferior limit of the
previous head positions, instead of moving to the ﬁrst tape cell. All proofs in
this paper can be easily modiﬁed to work for each of these variants.
We take the opportunity to answer in the negative [Hab13, Question 10],
which asked whether every real number accidentally writable by a cardinal-
recognizing ITTM is also accidentally writable by a plain ITTM.
Theorem 7. There is a cardinal-recognizing ITTM -program that writes a code
for Σ.
Proof. Let U denote an ITTM -program that simulates all ITTM -programs
simultaneously. The conﬁguration c of U at time ω1, when the special state
is assumed for the ﬁrst time, is the same as at time Σ and at time ζ [Wel14,
p.11-12]. If c would occur prior to ζ, then U would start looping before time
ζ, contradicting the assumption that U simulates all ITTM -programs. Hence c
is accidentally writable, but not eventually writable. The L-least code for Σ is
ITTM -writable from every real that is accidentally writable, but not eventually
writable by the proof of [CH11, Proposition 4.6]. Hence there is an ITTM -
program P that computes a code for Σ from c. We now run P on the tape
content of U when the special state is assumed for the ﬁrst time. This program
will halt with a code for Σ on the output tape, as required.
3
Recognizable Reals Relative to Cardinals
In this section, we will determine the recognizable closure for cardinal-detecting
ITTMs. It is easy to see that the parameter ω does not add recognizability
strength. We begin by considering ITTMs with uncountable parameters.
Theorem 8. Every subset x of ω that is ω1α-recognized by P for some ordinal
α is an element of Lσ.

202
M. Carl and P. Schlicht
Proof. Suppose that P is a program that recognizes x and ω1α-P x halts with
the ﬁnal state s. For any subset y of ω, after time Σy, the computation repeats a
loop of length Σy by Theorem 4, and thus the state of P y at time Σy is the same
as at time ω1α. Consequently, the computation will continue exactly the same
whether the new inner state s is assumed at time Σy or at time ω1α. Since P
recognizes x, Σy-P y and ω1α-P y both halt with the same output and the same
ﬁnal state s.
Let cy,β denote the L[y]-least code for β, if β is countable in L[y]. We argue
that the halting time of Σy-P y is strictly less than λy⊕c for c = cy,Σy. The tape
content z of P y at time Σy is accidentally writable in y and hence z is an element
of LΣy[y]. Therefore z is writable from y ⊕c and λz ≤λy⊕c. Then the halting
time of Σy-P y is strictly less than λy⊕c.
We can thus characterize x as the unique real y with φ(y), where φ(y) is
the statement that Σy-P y ↓= 1 holds in Lλy⊕cy,Σy [y]. To see that φ(y) is a
Σ1-statement, we call a triple α = ⟨α0, α1, α2⟩a y-triple if α0 < α1 < α2 and
Lα0[y] ≺Σ1 Lα1[y] ≺Σ2 Lα2[y]. Then φ(y) is equivalent to the Σ1-statement that
there is some γ such that in Lγ, the lexically least y-triple α = ⟨α0, α1, α2⟩and
the lexically least y ⊕cy,α2-triple β = ⟨β0, β1, β2⟩exist and α2-P y ↓= 1 holds in
Lβ0[y].
Since φ(x) holds, there is some y ∈L such that φ(y) holds in L by Shoenﬁeld
absoluteness. Then there is some z in Lσ such that φ(z) holds. This implies that
ω1α −P z ↓= 1, so z = x and x ∈Lσ.
Theorem 9. If x is a subset of ω that is recognized by an X-ITTM, where X is
a closed class of ordinals of the form ω1α, then x ∈Lσ. In particular, this holds
for subsets of ω recognized by a cardinal-detecting ITTM.
Proof. The proof is a variation of the proof of Theorem 8. We ﬁrst assume that
X is a proper class.
Suppose that X-P recognizes x. A computation by P in the oracle x will
assume its special state at the times ⟨αi | i < γ⟩for some ordinal γ. Let xi
denote the tape contents at time αi. Between the times αi and αi+1, we have an
ordinary ITTM -computation in the oracle x with input xι on the tape. Such a
computation will either halt or cycle from the time Σx⊕xi with a loop of length
Σx⊕xi. Now any αi for i ≥1 is a multiple of Σy for all reals y. In particular, the
tape contents at time αi + Σx⊕xi will be the same as at time αi+1.
We can hence characterize x as the unique real y with φ(y), where φ(y) is the
following statement. There is an ordinal δ, a continuous sequence ⟨αi | i < δ⟩
of ordinals and a sequence ⟨yi | i < δ⟩of real numbers such that for all i with
i + 1 < δ, yi+1 is the tape contents of the computation of P with oracle y and
input yi at time Σy⊕yi, αi+1 = αi +Σy⊕yi and the computation P y with special
state at the elements of the sequence ⟨αi | i < δ⟩halts with output 1.
As in the proof of Theorem 8, φ(y) is a Σ1-statement. Since φ(x) is valid,
φ(y) holds for some real y in Lσ. Then y = x and x ∈Lσ.

The Recognizability Strength of Inﬁnite Time Turing Machines
203
We now assume that X is a set. Let γ be the supremum of halting times of
P(x) for all subsets x of ω and let Y be a closed proper class of ordinals of the
form ω1α with Y ∩γ = X. Then the claim follows from the previous argument
applied to Y .
The assumption that X is closed is necessary in the previous theorem, since
every subset of ω is recognizable by an X-ITTM for some set X of ordinals of
the form ω1α, as one can easily show.
Theorem 10. The recognizable closure both for ω1α-ITTMs for any ordinal α
and for cardinal-detecting ITTMs is Lσ ∩P(ω).
Proof. We ﬁrst argue that the recognizable closure is contained in Lσ. Sup-
pose that y is an element of Lσ and x is ITTM -recognizable from y in either
machine type. By a relativization of the proofs of Theorems 8 and 9, x has a Σ1-
characterization in the parameter y. Since y is an element of Lσ, it is Σ1-deﬁnable
in L without parameters and hence can be eliminated from the deﬁnition of x.
It follows that there is a Σ1-formula φ such that x is the only witness for φ in
L. Hence x ∈Lσ.
Moreover, Lσ ∩P(ω) is contained in the recognizable closure for plain ITTMs
by [CSW, Lemma 3.2] and hence recognizable closures for both machine types
are equal to Lσ ∩P(ω).
The recognizability strength of cardinal-detecting ITTMs is strictly higher
than that of ITTMs by the next results. The next lemma shows that not every
real in the recognizable closure for ITTMs is itself recognizable.
Lemma 11. If x ∈LΣ \ Lλ, then x is not ITTM -recognizable.
Proof. Suppose that x ∈LΣ and x is ITTM -recognizable. We consider an
ITTM -program P which writes every accidentally writable real at some time. If
x is ITTM -recognizable by a program Q, we can write x by letting P run and
checking in each step with Q whether the contents of the output tape is equal
to x, and in this case stop. Then x is writable and hence x ∈Lλ.
Lemma 12. There is a real number that is ITTM -recognizable by a cardinal-
detecting ITTM and by an α-ITTM for every α ≥λ, but not ITTM -
recognizable.
Proof. Let 0▽= {ϕ | ϕ(0) ↓} denote the halting problem or jump for ITTMs.
Since 0▽is Σ1-deﬁnable over Lλ, but certainly not ITTM -writable, we have
0▽∈LΣ \ Lλ and hence 0▽is not ITTM -recognizable. We now argue that
0▽is writable by a cardinal-detecting ITTM and α-ITTM -writable, hence it
is recognizable with respect to these machines. This was already observed in
[Hab13] for cardinal-detecting machines. We can simulate all ITTM -programs
simultaneously and write 1 in the n-th place of the output tape when the n-th
program has stopped. As all halting times are countable, the output tape will
contain 0▽at time α, and the special state at time α allows us to stop.

204
M. Carl and P. Schlicht
4
Recognizable Reals Relative to Finitely Many Ordinals
In this section, we consider what happens when we allow the machine to enter a
special state at an ordinal time α. We ﬁrst determine the writability strength of
such machines. The next result follows from [CH11, Proposition 4.6]. We give a
short proof from the λ-ζ-Σ theorem for the reader.
Lemma 13. Let λα denote the supremum of the halting times of α-ITTMs.
1. λx > Σ for every real x with λx ≥ζ.
2. λα > Σ for every α ≥ζ.
Proof. To prove the ﬁrst claim, we ﬁrst suppose that Σ = Σx. Since ζ ≤λx < ζx,
this implies Lζ ≺Σ2 Lζx ≺Σ2 LΣ and this contradicts the minimality of Σ.
Second, suppose that Σ < Σx. Then there is a triple ⟨α, β, γ⟩in LΣx with
Lα ≺Σ1 Lβ ≺Σ2 Lγ, namely ⟨λ, ζ, Σ⟩. Since Lλx[x] ≺Σ1 LΣx[x], we have
Lλx ≺Σ1 LΣx and therefore, there is such a triple in Lλx. Since Σ is the least
value for γ for such triples ⟨α, β, γ⟩, we have Σ ≤γ < λx.
The second claim is clear if α ≥Σ. If α < Σ, we can write an accidentally
writable, but not eventually writable real x with an α-ITTM. For instance, we
can write a code for an ordinal β ≥ζ by adding all ordinals written by a universal
machine at time α. Since we can search for an L-level containing x and halt, it
follows that λx ≥ζ. Hence λα ≥λx > Σ by the ﬁrst claim.
We remark that the assumption of Lemma 13 cannot be weakened to λx > λ
by the following counterexample. Let x be the L-minimal code for λ. Then
clearly λx > λ. On the other hand, x is eventually writable, the L-minimal code
for λx is eventually writable relative to x and the eventually writable reals are
closed under eventual writability. Hence the L-minimal code for λx is eventually
writable and therefore λx < ζ < Σ.
Lemma 14. The following statements are equivalent for a real x.
1. x is α-ITTM -writable for some ordinal α.
2. x is ITTM -writable from some accidentally writable real number.
3. x is ITTM -writable from every accidentally writable real number that is not
eventually writable.
4. x is an element of Lλz, where z is the L-least code for ζ.
Proof. Suppose that x is α-ITTM -writable for some ordinal α by a compu-
tation of a program P. Up to time α, this computation is just an ordinary
ITTM -computation and hence at time α, the tape will contain some accidentally
writable real number y. The rest of the computation will again be an ordinary
ITTM -computation with the input y and thus the output will be ITTM -writable
from y.
Every accidentally writable x that is not eventually writable has λx > ζ and
hence λx > Σ by Lemma 13, so every accidentally writable is writable from x.

The Recognizability Strength of Inﬁnite Time Turing Machines
205
Suppose that x is ITTM -writable by a program P from some accidentally
writable real number y. Suppose that Q is a program that has y on its tape at
time α. If we run Q up to time α and then run P, this will write x.
Since the L-least code z for ζ is accidentally writable, the remaining impli-
cations follow from Lemma 13.
We obtain the following generalization of Lemma 14.
Lemma 15. The following statements are equivalent for a real x.
1. x is α-ITTM -writable for some sequence α of length n.
2. x is ITTM -writable from xn−1 for some sequence x = ⟨x0, . . . , xn−1⟩, where
xj is accidentally writable from 
i<j xi for all j < n.
3. x is an element of Lλzn−1, where z0 = 0 and zi+1 is the L-least code for ζzi
for all i < n −1.
Proof. The implications follow by iterated application of Lemma 14.
To show that the recognizability strength of ITTMs with arbitrary ordinal para-
meters is beyond Lσ, we need the next deﬁnition and two well-known results.
For technical convenience, we work with Jensen’s J-hierarchy instead of G¨odel’s
L-hierarchy. Note that Jα = Lα if α takes one of the values λ, ζ, Σ or σ.
Deﬁnition 16. An ordinal α is an index if there is a real in Jα+1 \ Jα.
Lemma 17. (Jensen) If α is an index, then there is a surjection from ω onto
Jα that is deﬁnable over Jα and hence there is a code for Jα in Jα+1.
Proof. This follows from the fact that ⟨Jα | α ∈Ord⟩is acceptable by [Zem02,
Lemma 1.10.1].
Lemma 18 (folklore).
There are unboundedly many admissible indices α
below ωL
1 .
Proof. There are unboundedly many indices below ωL
1 , since there are ωL
1 many
reals in L. Suppose that α is an index. Let c denote the L-least code for α.
Since α is an index, c ∈Jα+1 by Lemma 17. Suppose that β = ωc
1 is the least
c-admissible ordinal. Then β is admissible and it remains to show that β is an
index. Since c ∈Jβ and Jβ is the Skolem hull of c in Jβ, there is a surjection
from ω onto Jβ that is deﬁnable over Jβ. There is a real x in Jβ+1 that codes
this surjection. Since Jβ is admissible, x cannot be an element of Jβ and hence
β is an index.
The next result shows that there are ITTM -recognizable reals with respect
to ordinal parameters beyond Lσ.
Lemma 19. Suppose that α = ωβ is an index and c is the L-least code for Jα
in Jα+1 \ Jα. Then c is α-ITTM -recognizable.

206
M. Carl and P. Schlicht
Proof. The claim is easy to see for α = ω, so we assume that α > ω. Suppose
that the input is x. We ﬁrst check whether x codes a set with an extensional
relation and otherwise reject x. We then count through the ordinals of the set
coded by x, i.e. in each step we search for the least next ordinal, while simul-
taneously searching for inﬁnite strictly decreasing sequences of ordinals above.
This is possible by keeping markers at all previous ordinals in every step. If we
have exhausted the ordinals or if we ﬁnd an inﬁnite strictly decreasing sequence
of ordinals in the structure coded by x before time α, then we reject x. This
algorithm is carried out up to time α. After time α, we check if the structure
coded by x is well-founded, and reject x if this is not the case. If the structure
is well-founded, we check whether it is isomorphic to some Jβ. In this case, we
write a code for Jβ+1 and check whether it contains a code for Jβ. If it does, we
determine the least such code in Jβ+1 \ Jβ and check if it is equal to c. If it is
equal to c, then we accept x, and otherwise reject x. There is a code for Jα in
Jα+1 \ Jα by Lemma 17. Therefore this algorithm accepts a real x if and only if
x = c.
To show that every real that is ITTM -recognizable relative to ﬁnitely many
ordinal parameters is in L, we need the following result.
Lemma 20. Suppose that x is a subset of ω that is ITTM -recognizable from
n ordinal parameters. Then x is ITTM -recognizable from ﬁnitely many ordinal
parameters strictly below ω1 · (n + 1).
Proof. Suppose that x is ITTM -recognizable from α = ⟨α0, . . . , αn−1⟩and α is
strictly increasing. We can assume that αn−1 is uncountable. Suppose that α∗
i is
the remainder of the division of αi by ω1 for i < n. Suppose that k = ⟨k0, . . . , kl⟩
is the unique sequence such that k0 < n is least such that αk0 is uncountable and
for all i < l, ki+1 < n is least such that the unique ordinal α with αki +α = αki+1
is uncountable. Let βi = αi for i < k0, βi = ω1j + α∗
i for kj ≤i < kj+1 and
j < l, and let βi = ω1l + α∗
i for kl ≤i < n.
Suppose that a program P recognizes x from the parameters α0 < · · · < αn.
For every input y, P y will cycle from time Σy between multiples of Σy and
hence of ω1 by [Wel09]. This implies that for every input y, P y will halt with the
same state for the parameters α0, . . . , αn and the parameters β0, . . . , βn. Hence
P recognizes x from the parameters β0, . . . , βn.
Theorem 21. Every subset of ω that is ITTM -recognizable from ﬁnitely many
ordinal parameters is an element of L.
Proof. Suppose that x is ITTM -recognizable from ﬁnitely many ordinal parame-
ters. Then x is recognized by a program P from ﬁnitely many ordinal parameters
strictly below ω1 · (n + 1) by Lemma 20.
We can assume that x is recognized by a single ordinal parameter δ with
ω1 ≤δ < ω12. The proof of the general case is analogous. Suppose that P x with
the special state at time δ halts at time η. Let δ = ω1 + δ∗and η = ω1 + η∗.
We consider the Σ1-statement ψ(¯x) stating that P ¯x with the special state at

The Recognizability Strength of Inﬁnite Time Turing Machines
207
time Σ ¯x + δ∗halts at time Σ ¯x + η∗and accepts ¯x. Since the program will cycle
from time Σ ¯x in intervals of length Σ ¯x by Theorem 4, ψ(¯x) is equivalent to
the statement that P ¯x with the special state at time Σ ¯x · α + δ∗halts at time
Σ ¯x · α + η∗for some α ≥1, or equivalently for all α ≥1.
The statement ψ(x) holds in V and in every generic extension of V . In par-
ticular, ψ(x) holds in every Col(ω, ζ)-generic extension V [G] of V , where ζ is a
countable ordinal with δ∗, η∗≤ζ and Col(ω, ζ) is the standard collapse forcing to
make ζ countable. Moreover ∃¯xψ(¯x) holds in L[G] by Shoenﬁeld absoluteness,
since ∃¯xψ(¯x) is a Σ1-statement and the parameters δ∗and η∗are countable
in L[G].
Suppose that θ is an L-cardinal such that Lθ is suﬃciently elementary in L.
Suppose that M ≺Lθ is countable with ζ + 1 ⊆M and ¯
M is the transitive
collapse of M. Suppose that g, h are mutually Col(ω, ζ)-generic over ¯
M in V .
The statement ∃¯xψ(¯x) is forced over Lθ and
¯
M and therefore holds in
¯
M[g]
and in ¯
M[h], witnessed by some reals xg and xh. Since P recognizes x with the
special state at time δ, the uniqueness of x implies that xg = xh = x. Since g
and h are mutually generic over ¯
M, we have ¯
M[g]∩¯
M[h] = ¯
M and hence x ∈¯
M.
Since ¯
M is a subset of L, this implies x ∈L.
This allows us to determine the recognizable closure with respect to ordinal
parameters.
Theorem 22. The recognizable closure for ITTMs with single ordinal parame-
ters and for ITTMs with ﬁnitely many ordinal parameters is P(ω)L.
Proof. This follows from Lemmas 18 and 19 and Theorem 21.
Note that Theorem 21 cannot be extended to countable sets of ordinal para-
meters, since it is easy to see that every real is writable from a countable set
of ordinal parameters. The previous results suggest the question whether the
number of ordinal parameters is relevant for the recognizability strength. The
next result shows that this is the case.
Theorem 23. For every n, there is a subset x of ω that is ITTM -recognizable
from n + 1 ordinals, but not from n ordinals.
Proof. We deﬁne xn = ⟨x0, . . . , xn⟩, λn = ⟨λ0, . . . λn⟩, ζn = ⟨ζ0, . . . ζn⟩, and
Σn = ⟨Σ0, . . . Σn⟩as follows for all n. Let ζ0 = ζ and ζi+1 = ζxi, where x0 is
the L-least code for ζ and xi+1 is the L[xi]-least code for ζi+1. Moreover, let
λ0 = λ, λi+1 = λxi, Σ0 = Σ and Σi+1 = Σxi. Then λxi > Σi+1 for all i by
the relativized version of Lemma 13. Moreover, let λy
n, ζy
n and Σy
n denote the
relatived versions of λn, ζn and Σn for any real y.
Claim 24. A Cohen real x over LΣn+1 is not ITTM -recognizable from n
ordinals.
Proof. Suppose that x is recognized by a program P in the parameter γ =
⟨γ0, . . . , γn−1⟩, where γ is strictly increasing. We deﬁne γ∗= ⟨γ∗
0, . . . , γ∗
n−1⟩

208
M. Carl and P. Schlicht
as follows. Let γ∗
0 = γ0 if γ0 < Σ and γ∗
0 = ζ0 + δ0 if γ0 ≥Σ, where δ0 is the
remainder of the division of γ0 by Σ. For all i with i + 1 < n, let γ∗
i+1 = γi+1 if
γi+1 < Σi+1 and γ∗
i+1 = ζi+1 + δi+1 if γi+1 ≥Σi+1, where δi+1 is the remainder
of the division of γi+1 by Σi+1.
A computation with input y cycles from ζy in intervals of length Σy by
Theorem 4. For every Cohen real y over LΣn+1, λy
n = λn, ζy
n = ζn and Σy
n = Σn
by the variant of [CS, Lemma 3.12] for Cohen forcing (see also [Wel99, p.11]).
Since P x with special states at γ accepts x, this implies that P x with special
states at γ∗accepts x as well.
Since LΣn[y] is a union of admissible sets by the variant of [CS, Lemma 2.11]
for Cohen forcing, the run of P y is an element of LΣn[y]. Let σ be a name in
LΣn for the run of P x with special states at γ∗. The statement that P x with
special states at γ∗accepts x is forced for σ by a condition p in Cohen forcing
over LΣn by the variant of [CS, Lemma 2.7] for Cohen forcing. Suppose that y
is a Cohen generic over LΣn+1 with x ̸= y that extends the condition p. Then
P y accepts y by the truth lemma in the variant of [CS, Lemma 2.8] for Cohen
forcing. This contradicts the uniqueness of x.
Claim 25. The L-least Cohen real over LΣn+1 is writable from ζn.
Proof. By the relativized version of Lemma 13 applied to x0, . . . , xn, we can
successively compute x0, . . . , xn from ζn. We can then compute codes for Σn,
LΣn, LΣn+1 and hence the L-least Cohen real over LΣn in LΣn+1 from xn.
Remark 26. For ﬁnitely many parameters, the writability and recognizability
strengths do not change if we allow more than one special state, since such a
program can be simulated with a single special state by coding the special states
into tape cells.
5
Conclusion and Open Questions
We have seen that equipping ITTMs with the power to recognize one partic-
ular or all uncountable cardinals increases the set of ITTM -recognizable real
numbers, but not the recognizable closure, which remains Lσ. Moreover, certain
ordinals parameters enable an ITTM to recognize real numbers outside of Lσ,
but ITTM -recognizability with ﬁnitely many ordinal parameters does not lead
out of the constructible universe.
We conclude with the following open questions. It is open whether the ordi-
nals in Lemma 20 can be chosen to be countable.
Question 27. Is every real x that is ITTM -recognizable from an ordinal already
ITTM -recognizable from a countable ordinal?
Let Rα denote the recognizable closure with respect to ITTMs with the
parameter α and let σ(α) denote the least ordinal γ > α with Lγ ≺Σ1 L. It is
open what is Rα and whether there is a relationship between Rα and Lσ(α).

The Recognizability Strength of Inﬁnite Time Turing Machines
209
Question 28. What is Rα for arbitrary ordinals α?
The notion of semi-recognizable reals is deﬁned by asking that the program
halts for some input x and diverges for all other inputs. The notion of anti-
recognizable reals is deﬁned by asking the program diverges for some input x
and halts for all other inputs. The following question seems fundamental.
Question 29. Are there semi-recognizable reals and anti-recognizable reals that
are not recognizable?
References
[Car14a] Carl, M.: The distribution of ITRM-recognizable reals. Ann. Pure Appl.
Logic 165(9), 1403–1417 (2014)
[Car14b] Carl, M.: The lost melody phenomenon. In: Inﬁnity, computability, and meta-
mathematics, vol. 23 of Tributes, pp. 49–70. College Publications, London
(2014)
[Car15] Carl, M.: Optimal results on recognizability for inﬁnite time register
machines. J. Symb. Log. 80(4), 1116–1130 (2015)
[CH11] Coskey, S., Hamkins, J.D.: Inﬁnite time decidable equivalence relation theory.
Notre Dame J. Formal Log. 52(2), 203–228 (2011)
[CS] Carl, M., Schlicht, P.: Randomness via inﬁnite time machines and eﬀective
descriptive set theory (2016). Submitted
[CSW] Carl, M., Schlicht, P., Welch, P.: Recognizable sets and Woodin cardinals
(2016). Submitted
[Hab13] Habiˇc, M.E.: Cardinal-recognizing inﬁnite time turing machines. In: Boniz-
zoni, P., Brattka, V., L¨owe, B. (eds.) CiE 2013. LNCS, vol. 7921, pp. 231–240.
Springer, Heidelberg (2013). doi:10.1007/978-3-642-39053-1 27
[HL00] Hamkins, J.D., Lewis, A.: Inﬁnite time turing machines. J. Symbolic Log.
65(2), 567–604 (2000)
[Wel99] Welch, P.D.: Minimality arguments for inﬁnite time turing degrees. In: Sets
and proofs (Leeds 1997). London Mathematical Society Lecture Note Series,
vol. 258, pp. 425–436. Cambridge University Press, Cambridge (1999)
[Wel09] Welch, P.D.: Characteristics of discrete transﬁnite time Turing machine mod-
els: halting times, stabilization times, and normal form theorems. Theoret.
Comput. Sci. 410(4–5), 426–442 (2009)
[Wel14] Welch, P.D.: Transﬁnite machine models. In: Turing’s Legacy: Developments
from Turing’s Ideas in Logic. Lecture Notes in Logic, vol. 42, pp. 493–529.
Association Symbolic Logic, La Jolla, CA (2014)
[Zem02] Zeman, M.: Inner Models and Large Cardinals. De Gruyter Series in Logic
and its Applications, vol. 5. Walter de Gruyter & Co., Berlin (2012)

New Bounds on the Strength of Some
Restrictions of Hindman’s Theorem
Lorenzo Carlucci1(B), Leszek Aleksander Kolodziejczyk2, Francesco Lepore1,
and Konrad Zdanowski3
1 Department of Computer Science, University of Rome I, Rome, Italy
carlucci@di.uniroma1.it, leporefc@gmail.com
2 Institute of Mathematics, University of Warsaw, Warsaw, Poland
lak@mimuw.edu.pl
3 Faculty of Mathematics and Natural Sciences, Cardinal Stefan Wyszy´nski
University in Warsaw, Warsaw, Poland
k.zdanowski@uksw.edu.pl
Abstract. We prove upper and lower bounds on the eﬀective content
and logical strength for a variety of natural restrictions of Hindman’s
Finite Sums Theorem. For example, we show that Hindman’s Theorem
for sums of length at most 2 and 4 colors implies ACA0. An emerging
leitmotiv is that the known lower bounds for Hindman’s Theorem and
for its restriction to sums of at most 2 elements are already valid for
a number of restricted versions which have simple proofs and better
computability- and proof-theoretic upper bounds than the known upper
bound for the full version of the theorem. We highlight the role of a
sparsity-like condition on the solution set, which we call apartness.
1
Introduction and Motivation
The Finite Sums Theorem by Neil Hindman [15] (henceforth denoted HT) is a
celebrated result in Ramsey Theory stating that for every ﬁnite coloring of the
positive integers there exists an inﬁnite set such that all the ﬁnite non-empty
sums of distinct elements from it have the same color. Thirty years ago Blass,
Hirst and Simpson proved in [2] that all computable instances of HT have some
solutions computable in ∅(ω+1) and that for some computable instances of HT
all solutions compute ∅′. In terms of Reverse Mathematics, they showed that
ACA+
0 ⊢HT and that RCA0 ⊢HT →ACA0 (see [17,20] for the deﬁnition of these
systems). Both bounds hold for the particular case of colorings in two colors.
Closing the gap between the upper and lower bound is one of the major open
problems in Computable and Reverse Mathematics (see, e.g., [19]).
Part of this work was done while the ﬁrst author was visiting the Institute for Mathe-
matical Sciences, National University of Singapore in 2016. The visit was supported
by the Institute. The second author was partially supported by Polish National
Science Centre grant no. 2013/09/B/ST1/04390. The fourth author was partially
supported by University Cardinal Stefan Wyszy´nski in Warsaw grant UmoPBM-
26/16.
c
⃝Springer International Publishing AG 2017
J. Kari et al. (Eds.): CiE 2017, LNCS 10307, pp. 210–220, 2017.
DOI: 10.1007/978-3-319-58741-7 21

New Bounds on the Strength of Some Restrictions of Hindman’s Theorem
211
Blass advocated the study of restrictions of Hindman’s Theorem in which
a bound is put on the length (i.e., number of distinct terms) of sums for
which monochromaticity is guaranteed [1], conjecturing that the complexity of
Hindman’s Theorem grows as a function of the length of sums. Recently Dzha-
farov, Jockusch, Solomon and Westrick showed (see Corollary 3.4 in [12]) that
the known ∅′ (ACA0) lower bound on Hindman’s Theorem holds for the restric-
tion to sums of at most 3 terms (with no repetitions, as is the case throughout
the paper), and 3 colors (henceforth denoted by HT≤3
3 ). They also established
that the restriction to sums of at most 2 terms, and 2 colors (denoted HT≤2
2 ),
is unprovable in RCA0 (Corollary 2.3 in [12]) and implies SRT2
2 (the Stable
Ramsey’s Theorem for pairs and 2 colors) over RCA0 + BΣ0
2 (Corollary 2.4
in [12]). This prompted the ﬁrst author to look into direct combinatorial reduc-
tions yielding, e.g., a direct implication from HT≤2
5
to the Increasing Polar-
ized Ramsey’s Theorem for pairs of Dzhafarov and Hirst [11], which is strictly
stronger than SRT2
2 (see Sect. 4 for details).
It should be stressed that no upper bound other than the ∅(ω+1) (ACA+
0 )
upper bound on the full Finite Sums Theorem is known to hold for the restric-
tions of the theorem to sums of length (i.e., number of terms) ≤2 or ≤3. It
is indeed a long-standing open question in Combinatorics whether the latter
restrictions admit a proof that does not establish the full Finite Sums Theorem
(see, e.g., [16], Question 12). On the other hand, Hirst investigated in [18] an
apparently slight variant of the Finite Sums Theorem and proved it equivalent to
BΣ2. This prompted the ﬁrst author to investigate versions of HT for which an
upper bound better than ∅(ω+1) (ACA+
0 ) could be established, while retaining as
strong a lower bound as possible. In [4] (resp. [3]) such restrictions were isolated
and proved to attain the known lower bounds for HT (resp. HT≤2
2 ), while being
provable from ACA0 (resp. RT2
2).
We present new results along these lines of research. In Sect. 3 we prove an
ACA0 lower bound for HT≤2
4 , and an equivalence with ACA0 for some principles
from [4]. In Sect. 4 we establish combinatorial implications from other restrictions
of Hindman’s Theorem to the Increasing Polarized Ramsey’s Theorem for Pairs.
These reductions imply unprovability-in-WKL0 results and also yield strong com-
putable reducibility of IPT2
2 to some Hindman-type theorem. We highlight the
role of a sparsity-like condition on the solution set which we call the apartness
condition, which is crucial in earlier work ([3,4,12,15]).
2
Restricted Hindman and the Apartness Condition
Let us ﬁx some notation. For technical convenience and to avoid trivial cases we
will deal with colorings of the positive integers. We use N to denote the positive
integers. If a ∈N and B is a set we denote by FS≤a(B) (resp. FS=a(B)) the
set of non-empty sums of at most (resp. exactly) a-many distinct elements from
B. More generally, if A and B are sets we denote by FSA(B) the set of all sums
of j-many distinct terms from B, for all j ∈A. By FS(B) we denote FSN(B).

212
L. Carlucci et al.
We use the notation X = {x1, x2, . . . }< to indicate that x1 < x2 < . . . . Let us
recall the statement of Hindman’s Finite Sums Theorem [15].
Deﬁnition 1 (Hindman’s Finite Sums Theorem). HT is the following
assertion: For every k ∈N, for every coloring f : N →k there exists an inﬁnite
set H ⊆N such that FS(H) is monochromatic for f.
We deﬁne below two restrictions of Hindman’s Theorem that will feature
prominently in the present paper. We then discuss a sparsity-like condition that
will be central to our results.
2.1
Hindman’s Theorem with Bounded-Length Sums
The following principles were discussed in [1] (albeit phrased in terms of ﬁnite
unions instead of sums) and ﬁrst studied from the perspective of Computable
and Reverse Mathematics in [12].
Deﬁnition 2 (Hindman’s Theorem with bounded-length sums). Fix
n, k ≥1.
1. HT≤n
k
is the following principle: For every coloring f : N →k there exists
an inﬁnite set H ⊆N such that FS≤n(H) is monochromatic for f.
2. HT=n
k
is the following principle: For every coloring f : N →k there exists
an inﬁnite set H ⊆N such that FS=n(H) is monochromatic for f.
The principle HT≤2
2
is the topic of a long-standing open question in Combina-
torics: Question 12 of [16] asks whether there exists a proof of HT≤2
2
that does not
also prove the full Finite Sums Theorem. On the other hand, the principle HT=2
2
easily follows from Ramsey’s Theorem for pairs: given an instance f : N →2 of
HT=2
2 , deﬁne g : [N]2 →2 by setting g(x, y) := f(x+y). A solution for Ramsey’s
Theorem for pairs for g is a solution for HT=2
2
for f.
Dzhafarov, Jockusch, Solomon and Westrick recently proved in [12] that
HT≤3
3
implies ACA0 over RCA0 (Corollary 3.4 of [12]) and that HT≤2
2
implies
SRT2
2 (the Stable Ramsey’s Theorem for pairs) over RCA0 + BΣ0
2 (Corollary 2.4
of [12]).1
The ﬁrst author proved that HT≤2
5
implies IPT2
2 (the Increasing Polarized
Ramsey’s Theorem for pairs) over RCA0 (see [5]).
2.2
The Apartness Condition
We discuss a property of the solution set – which we call the apartness condition –
that is crucial in Hindman’s original proof and in the proofs of the ∅′ (ACA0)
lower bounds in [2,4,12]. We use the following notation: Fix a base t ≥2. For
n ∈N we denote by λt(n) the least exponent of n written in base t, by μt(n) the
1 The principle BΣ0
2 is used in the proof of the implication Corollary 2.4 in [12], as
indicated in the ﬁnal version of Dzhafarov et al. paper – our reference [12].

New Bounds on the Strength of Some Restrictions of Hindman’s Theorem
213
largest exponent of n written in base t, and by it(n) the coeﬃcient of the least
term of n written in base t. Our results are in terms of 2-apartness except in one
case (Lemma 1 below) where we have to use 3-apartness for technical reasons.
We will drop the subscript when clear from context.
Deﬁnition 3 (Apartness Condition). Fix t ≥2. We say that a set X ⊆N
satisﬁes the t-apartness condition (or is t-apart) if for all x, x′ ∈X, if x < x′
then μt(x) < λt(x′).
Note that the apartness condition is inherited by subsets. In Hindman’s original
proof 2-apartness can be ensured (Lemma 2.2 in [15]) by a simple counting argu-
ment (Lemma 2.2 in [14]), under the assumption that we have a solution to the
Finite Sums Theorem, i.e. an inﬁnite H such that FS(H) is monochromatic. For
a Hindman-type principle P, let “P with t-apartness” denote the corresponding
version in which the solution set is required to satisfy the t-apartness condition.
As will be observed below, it is signiﬁcantly easier to prove lower bounds
on P with t-apartness than on P in all the cases we consider. Moreover, for
all restrictions of Hindman’s Theorem for which a proof is available that does
not also establish the full theorem, the t-apartness condition (for t > 1) can
be guaranteed by construction (see, e.g., [3,4]). This is the case, e.g., for the
principle HT=2
2 : the proof from Ramsey’s Theorem for pairs sketched above
yields t-apartness for any t > 1 simply by applying Ramsey’s Theorem relative
to an inﬁnite t-apart set. In some cases the apartness condition can be ensured at
the cost of increasing the number of colors. This is the case of HT≤n
k
as illustrated
by the next lemma. The idea of the proof is from the ﬁrst part of the proof of
Theorem 3.1 in [12], with some needed adjustments.
Lemma 1 (RCA0). For all n ≥2, for all d ≥1, HT≤n
2d
implies HT≤n
d
with
3-apartness.
Proof. We work in base 3. Let f : N →d be given. Deﬁne g : N →2d as follows.
g(n) :=

f(n)
if i(n) = 1,
d + f(n)
if i(n) = 2.
Let H be an inﬁnite set such that FS≤n(H) is homogeneous for g of color k.
For h, h′ ∈FS≤n(H) we have i(h) = i(h′). Then we claim that for each m ≥0
there is at most one h ∈H such that λ(h) = m. Suppose otherwise, by way of
contradiction, as witnessed by h, h′ ∈H. Then i(h) = i(h′) and λ(h) = λ(h′).
Therefore i(h + h′) ̸= i(h), but h + h′ ∈FS≤n(H). Contradiction. Therefore we
can computably obtain a 3-apart inﬁnite subset of H.
⊓⊔
3
Restricted Hindman and Arithmetical Comprehension
We prove a new ACA0 lower bound and a new ACA0 equivalence result for
restrictions of Hindman’s Theorem. The lower bound proof is in the spirit of the
proof by Blass, Hirst and Simpson that Hindman’s Theorem implies ACA0 – on
which the proof of Theorem 3.1 of [12] is also based – with extra care to work
with sums of length at most two. The upper bound proof is in the spirit of [4].

214
L. Carlucci et al.
3.1
HT≤2
4
implies ACA0
We show that HT≤2
4
implies ACA0 over RCA0. This is to be compared with
Corollary 2.3 and Corollary 3.4 of [12], showing, respectively, that RCA0 ⊬HT≤2
2
and that RCA0 ⊢HT≤3
3
→ACA0. Blass, towards the end of [1], states without
giving details that inspection of the proof of the ∅′ lower bound for HT in [2]
shows that these bounds are true for the restriction of the Finite Unions Theorem
to unions of at most two sets.2 Note that the Finite Unions Theorem has a built-
in apartness condition. Blass indicates in Remark 12 of [1] that things might be
diﬀerent for restrictions of the Finite Sums Theorem, as those considered in this
paper. Also note that the proof of Theorem 3.1 in [12], which stays relatively
close to the argument in [2], requires sums of length 3.
Proposition 1 (RCA0). For any ﬁxed t ≥2, HT≤2
2
with t-apartness implies
ACA0.
Proof. We write the proof for t = 2. Assume HT≤2
2
with 2-apartness and consider
f : N →N. We have to prove that the range of f exists.
For a number n, written as 2n0 + · · · + 2nr in base 2, with n0 < · · · < nr, we
call j ∈{0, . . . , r} important in n if some value of f↾[nj−1, nj) is below n0. Here
n−1 = 0. The coloring c: N →2 is deﬁned by
c(n) := card{j : j is important in n} mod 2.
By HT≤2
2
with 2-apartness, there exists an inﬁnite set H ⊆N such that H is
2-apart and FS≤2(H) is monochromatic w.r.t. c. We claim that for each n ∈H
and each x < λ(n), x ∈rg(f) if and only if x ∈rg(f↾μ(n)). This will give us a
Δ0
1 deﬁnition of rg(f): given x, ﬁnd the smallest n ∈H such that x < λ(n) and
check whether x is in rg(f↾μ(n)).
It remains to prove the claim. In order to do this, consider n ∈H and
assume that there is some element below n0 = λ(n) in rg(f)\rg(f↾μ(n)). By the
consequence of Σ0
1-induction known as strong Σ0
1-collection (see Exercise II.3.14
in [20], Theorem I.2.23 and Deﬁnition I.2.20 in [13]), there is a number ℓsuch
that for any x < λ(n), x ∈rg(f) if and only if x ∈rg(f↾ℓ). By 2-apartness, there
is m ∈H with λ(m) ≥ℓ> μ(n). Write n + m in base 2 notation,
n + m = 2n0 + · · · + 2nr + 2nr+1 + · · · + 2ns,
where n0 = λ(n) = λ(n + m), nr = μ(n), and nr+1 = λ(m). Clearly, j ≤s
is important in n + m if and only if either j ≤r and j is important in n
or j = r + 1; hence, c(n) ̸= c(n + m). This contradicts the assumption that
FS≤2(H) is monochromatic, thus proving the claim.
⊓⊔
2 The Finite Unions Theorem states that every coloring of the ﬁnite non-empty sets of
N admits an inﬁnite and pairwise unmeshed family H of ﬁnite non-empty sets (some-
times called a block sequence) such that every ﬁnite non-empty union of elements
of H is of the same color. Two ﬁnite non-empty subsets x, y of N are unmeshed if
either max x < min y or max y < min x. Note that Hindman’s Theorem is equivalent
to the Finite Unions Theorem only if the pairwise unmeshed condition is present.

New Bounds on the Strength of Some Restrictions of Hindman’s Theorem
215
Theorem 1 (RCA0). HT≤2
4
implies ACA0.
Proof. By Proposition 1 and Lemma 1.
⊓⊔
3.2
Equivalents of ACA0
In [4], a family of natural restrictions of Hindman’s Theorem was isolated such
that each of its members admits a simple combinatorial proof, yet each member
of a non-trivial sub-family implies ACA0. The weakest principle of the latter kind
considered in [4] is the following, called the Hindman-Brauer Theorem: Whenever
N is 2-colored there is an inﬁnite set H ⊆N and there exist positive integers
a, b such that FS{a,b,a+b,a+2b}(H) is monochromatic. It was proved in [4] that
the Hindman-Brauer Theorem with 2-apartness is equivalent to ACA0. We show
that the same holds for the following apparently weaker principle.
Deﬁnition 4. HT∃{a,b}
2
is the following principle: For every coloring f : N →2
there is an inﬁnite set H ⊆N and positive integers a < b such that FS{a,b}(H)
is monochromatic.
Theorem 2. HT∃{a,b}
2
with 2-apartness is equivalent to ACA0 over RCA0.
Proof. We ﬁrst prove the upper bound. Given c : N →2 let g : [N]3 →8 be
deﬁned as follows:
g(x1, x2, x3) := ⟨c(x1), c(x1 + x2), c(x1 + x2 + x3)⟩.
Fix an inﬁnite and 2-apart set H0 ⊆N. By RT3
8 relativized to H0 we get
an inﬁnite (and 2-apart) set H ⊆H0 monochromatic for g. Let the color be
σ = (c1, c2, c3), a binary sequence of length 3. Then, for each i ∈{1, 2, 3}, g
restricted to FS=i(H) is monochromatic of color ci. Obviously for some positive
integers a, b such that a < b ≤3 it must be that ca = cb. Then FS{a,b}(H) is
monochromatic of color ca.
The lower bound is proved by a minor adaptation of the proof of
Proposition 1. As the n in that proof take an a-term sum. Then take a (b −a)-
term sum as the m.
⊓⊔
The same proof yields that the following Hindman-Schur Theorem with 2-
apartness from [4] implies ACA0: Whenever N is 2-colored there is an inﬁnite
2-apart set H and there exist positive integers a, b such that FS{a,b,a+b}(H) is
monochromatic. It was shown in [4] to be provable in ACA0.
4
Restricted Hindman and Polarized Ramsey
In this section we establish new lower bounds for restricted versions of Hindman’s
Theorem, most of which do not imply ACA0 and are therefore provably weaker
than HT. Lower bounds are established by reduction to the Increasing Polarized
Ramsey’s Theorem for pairs [11]. In particular we obtain unprovability in WKL0.

216
L. Carlucci et al.
All proofs in the present section yield strongly computable reductions in the sense
of [10], not just implications. P is strongly computably reducible to Q, written
P ≤sc Q, if every instance X of P computes an instance X∗of Q, such that if
Y ∗is any solution to X∗then there is a solution Y to X computable from Y ∗.
Deﬁnition 5 (Increasing Polarized Ramsey’s Theorem). Fix n, k ≥1.
IPTn
k is the following principle: For every f : [N]n →k there exists a sequence
(H1, . . . , Hn) of inﬁnite sets such that all increasing tuples (x1, . . . , xn) in
H1 × · · · × Hn have the same color under f. The sequence (H1, . . . , Hn) is called
increasing polarized homogeneous (or increasing p-homogeneous) for f.
Note that IPT2
2 is strictly stronger than SRT2
2. On the one hand, RCA0 ⊢
IPT2
2 →D2
2 by Proposition 3.5 of [11], and RCA0 ⊢D2
2 →SRT2
2 by Theorem 1.4
of [8].3 However, RCA0 + SRT2
2 ⊬IPT2
2: Theorem 2.2 in [9] showed that there is
a non-standard model of SRT2
2 + BΣ0
2 having only low sets in the sense of the
model. Lemma 2.5 in [11] can be formalized in RCA0 and shows that no model
of IPT2
2 can contain only Δ0
2 sets.4
4.1
HT=2
2
with 2-apartness implies IPT2
2
We show that HT=2
2
with 2-apartness implies IPT2
2 by a combinatorial reduction.
This should be contrasted with the fact that no lower bounds on HT=2
2
without
apartness are known.
Theorem 3 (RCA0). HT=2
2
with 2-apartness implies IPT2
2.
Proof Let f : [N]2 →2 be given. Deﬁne g : N →2 as follows.
g(n) :=

0
if n = 2m,
f(λ(n), μ(n))
if n ̸= 2m.
Note that g is well-deﬁned since λ(n) < μ(n) if n is not a power of 2. Let
H = {h1, h2, . . . }< witness HT=2
2
with 2-apartness for g. Let the color be k < 2.
Let
H1 := {λ(h2i−1) : i ∈N}, H2 := {μ(h2i) : i ∈N}.
We claim that (H1, H2) is increasing p-homogeneous for f.
First observe that we have
λ(h1) < λ(h3) < λ(h5) < . . . ,
and
μ(h2) < μ(h4) < μ(h6) < . . . .
3 Note that the latter result is not present in the diagram in [11]. D2
2, deﬁned
in [7], is the following assertion: For every 0, 1-valued function f(x, s) for which
a lims→∞f(x, s) exists for each x, there is an inﬁnite set H and a k < 2 such that
for all h ∈H we have lims→∞f(h, s) = k.
4 We thank Ludovic Patey for pointing out to us the results implying strictness.

New Bounds on the Strength of Some Restrictions of Hindman’s Theorem
217
This is so because λ(h1) ≤μ(h1) < λ(h2) ≤μ(h2) < . . . by the 2-
apartness condition. Then we claim that f(x1, x2) = k for every increasing pair
(x1, x2) ∈H1 × H2. Note that (x1, x2) = (λ(hi), μ(hj)) for some i < j (the case
i = j is impossible by construction of H1 and H2). Then we have
k = g(hi + hj) = f(λ(hi + hj), μ(hi + hj)) = f(λ(hi), μ(hj)) = f(x1, x2),
since FS=2(H) is monochromatic for g with color k. This shows that (H1, H2)
is increasing p-homogeneous of color k for f.
⊓⊔
The proof of Theorem 3 yields that IPT2
2 ≤sc HT=2
2
with 2-apartness, and,
with minor adjustments, that IPT2
2 ≤sc HT≤2
4
(a self-contained proof appeared
in [5]).
4.2
IPT2
2 and the Increasing Polarized Hindman’s Theorem
We deﬁne an (increasing) polarized version of Hindman’s Theorem. We prove
that its version for pairs and 2 colors with an appropriately deﬁned notion of
2-apartness is equivalent to IPT2
2.
Deﬁnition 6 ((Increasing) Polarized Hindman’s Theorem). Fix n ≥1.
PHTn
2 (resp. IPHTn
2) is the following principle: For every f : N →2 there exists
a sequence (H1, . . . , Hn) of inﬁnite sets such that for some color k < 2, for all
(resp. increasing) (x1, . . . , xn) ∈H1 × · · · × Hn, f(x1 + · · · + xn) = k.
We impose a t-apartness condition on a solution (H1, . . . , Hn) of IPHTn
2 by
requiring that the union H1 ∪· · · ∪Hn is t-apart. We denote by “IPHTn
2 with
t-apartness” the principle IPHTn
2 with this t-apartness condition on the solu-
tion set.
Theorem 4. IPT2
2 and IPHT2
2 with 2-apartness are equivalent over RCA0.
Proof. We ﬁrst prove that IPT2
2 implies IPHT2
2 with 2-apartness. Given c : N →2
deﬁne f : [N]2 →2 in the obvious way setting f(x, y) := c(x + y). Fix two inﬁ-
nite disjoint sets S1, S2 such that S1 ∪S2 is 2-apart. By Lemma 4.3 of [11],
IPT2
2 implies over RCA0 its own relativization: there exists an increasing p-
homogeneous sequence (H1, H2) for f such that Hi ⊆Si. Therefore H1 ∪H2
is 2-apart by construction. Let the color be k < 2. Obviously we have that for
any increasing pair (x1, x2) ∈H1 × H2, c(x1 + x2) = f(x1, x2) = k. Therefore
(H1, H2) is an increasing p-homogeneous pair for c.
Next we prove that IPHT2
2 with 2-apartness implies IPT2
2. Let f : [N]2 →2
be given. Deﬁne as usual c : N →2 by setting c(n) := f(λ(n), μ(n)) if n is
not a power of 2 and c(n) := 0 otherwise. Let (H1, H2) be a 2-apart solu-
tion to IPHT2
2 for c, of color k < 2. By, possibly, recursively thinning out
H1 and H2 we can assume without loss of generality that H1 ∩H2 = ∅. Let
H1 = {h1, h2, . . . }< and H2 = {h′
1, h′
2, . . . }<. Then set H+
1 := {λ(h) : h ∈H1}
and H+
2 := {μ(h) : h ∈H2}. We claim that (H+
1 , H+
2 ) is a solution to IPT2
2 for f.

218
L. Carlucci et al.
Let (x1, x2) ∈H+
1 × H+
2
be an increasing pair. Then for some h ∈H1 and
h′ ∈H2, λ(h) = x1 and μ(h′) = x2. Also, since H1∪H2 is apart and H1∩H2 = ∅,
it must be the case that h < h′. Therefore (h, h′) is an increasing pair in H1 ×H2
and the following holds:
k = c(h + h′) = f(λ(h + h′), μ(h + h′)) = f(λ(h), μ(h′)) = f(x1, x2).
⊓⊔
4.3
Hindman’s Theorem for Exactly Large Sums
We present here some preliminary results on a restriction of Hindman’s Theorem
to exactly large sums. A ﬁnite set S ⊆N is exactly large, or !ω-large, if
|S|
=
min(S) + 1. We denote by [X]!ω the set of exactly large subsets of
X and by FS!ω(X) the set of positive integers that can be obtained as sums of
terms of an exactly large subset of X. We call sums of this type exactly large
sums (from X). Ramsey’s Theorem for exactly large sums (RT!ω
2 ) asserts that
every 2-coloring f of the exactly large subsets of an inﬁnite set X ⊆N admits
an inﬁnite set H ⊆X such that f is constant on [H]!ω. It was studied in [6]
and there proved equivalent to ACA+
0 . We introduce an analogue for Hindman’s
Theorem.
Deﬁnition 7 (Hindman’s Theorem for Large Sums). HT!ω
2
denotes the
following principle: For every coloring c : N →2 there exists an inﬁnite set
H ⊆N such that FS!ω(H) is monochromatic under c.
HT!ω
2
(with t-apartness, for any t > 1) is a consequence of HT, but also
admits an easy proof from RT!ω
2 . Given c : N →2 just set f(S) := c( S), for
S an exactly large set (to get t-apartness, restrict f to an inﬁnite t-apart set).
By results from [6] this reduction yields an upper bound of ∅(ω) on HT!ω
2 .
Proposition 2 (RCA0). HT!ω
2 with 2-apartness implies IPHT2
2 with 2-apartness.
Proof. Let f : N →2 be given, and let H = {h0, h1, h2, . . . }< be an inﬁnite
2-apart set such that FS!ω(H) is monochromatic for f of color k < 2. Let
Hs = {s1, s2, . . . }< be the 2-apart set whose elements are exactly large sums
of consecutive elements from H. Let Ht = {t1, t2, . . . }< be the set of elements
from Hs minus their largest term (when written as !ω-sums). Note that dis-
tinct elements of Hs share no term, because Hs is 2-apart. Let H1 := Ht and
let H2 := {si −ti : i ∈N}. Then (H1, H2) is a 2-apart solution for IPHT2
2:
⊓⊔
From Proposition 3 we get that HT!ω
2 with 2-apartness implies IPT2
2. In partic-
ular it is unprovable in WKL0. Other results on HT!ω
2 have been proved by the
third author in his BSc. Thesis. E.g., over RCA0, HT!ω
2 with 2-apartness implies
∀nHT=2n
2
, and HT!ω
2 implies ∀nPHTn
2 (see Deﬁnition 6).

New Bounds on the Strength of Some Restrictions of Hindman’s Theorem
219
5
Conclusion
We contributed to the study of restricted versions of Hindman’s Theorem
by proving implications from (and equivalence of) some such restrictions to
ACA0 and to the Increasing Polarized Ramsey’s Theorem for Pairs. Our results
improve and integrate the recent results by Dzhafarov, Jockusch, Solomon and
Westrick [12]. In many cases they conﬁrm that the known lower bounds on
Hindman’s Theorem hold for restricted versions of Hindman’s Theorem for which
— contrary to the restrictions studied in [12] — the upper bound lies strictly
below ∅(ω+1) (most being consequences of ACA0 or even of RT2
2). This also com-
plements the results of [3,4] and might be an indication that the known lower
bounds for Hindman’s Theorem are sub-optimal. We highlighted the role of the
apartness condition on the solution set (Table 1).
Table 1. Summary of results
Principles
Lower Bounds
Upper Bounds
HT≤2
2
RCA0 ⊬([12])
∅(ω+1), ACA+
0 ([2])
HT≤2
2
+ BΣ0
2
SRT2
2 ([12])
∅(ω+1), ACA+
0 ([2])
HT≤2
2
with 2-apartness
ACA0 (Proposition 1) ∅(ω+1), ACA+
0 ([2])
HT≤2
4
ACA0 (Theorem 1)
∅(ω+1), ACA+
0 ([2])
HT∃{a,b}
2
?
∅′, ACA0 ([4])
HT∃{a,b}
2
with 2-apartness ACA0 (Theorem 2)
∅′, ACA0 (Theorem 2)
HT=2
2
?
RT2
2 (folklore)
HT=2
2
with 2-apartness
IPT2
2 (Theorem 3)
RT2
2 (folklore)
IPHT2
2 with 2-apartness
IPT2
2 (Theorem 4)
IPT2
2 (Theorem 4)
HT!ω
2
?
∅(ω), ACA+
0 ([6])
HT!ω
2 with 2-apartness
IPT2
2 (Proposition 2)
∅(ω), ACA+
0 ([6])
Note: We have improved some of the above results and obtained some new
results. E.g., both HT=3
2
with 2-apartness and HT!ω
2
imply ACA0 over RCA0.
These and further results will be presented in an extended version of this paper.
References
1. Blass, A.: Some questions arising from Hindman’s theorem. Sci. Math. Japonicae
62, 331–334 (2005)
2. Blass, A.R., Hirst, J.L., Simpson, S.G.: Logical analysis of some theorems of com-
binatorics and topological dynamics. In: Logic and Combinatorics (Arcata, Cali-
fornia, 1985), Contemporary Mathematics, vol. 65, pp. 125–156. American Math-
ematical Society, Providence, RI (1987)
3. Carlucci, L.: A weak variant of Hindman’s Theorem stronger than Hilbert’s The-
orem. Preprint (2016). https://arxiv.org/abs/1610.05445

220
L. Carlucci et al.
4. Carlucci, L.: Weak yet strong restrictions of Hindman’s ﬁnite sums theorem. In:
Proceedings of the American Mathematical Society. Preprint (2016). https://arxiv.
org/abs/1610.07500. Accepted with minor revision for publication
5. Carlucci, L.: Bounded Hindman’s theorem and increasing polarized Ramsey’s the-
orem. In: Nies, A. (ed.) Logic Blog, Part 4, Section 9 (2016). https://arxiv.org/
abs/1703.01573
6. Carlucci, L., Zdanowski, K.: The strength of Ramsey’s theorem for coloring rela-
tively large sets. J. Symbolic Logic 79(1), 89–102 (2014)
7. Cholak, P.A., Jockusch, C.G., Slaman, T.A.: On the strength of Ramsey’s theorem
for pairs. J. Symbolic Logic 66(1), 1–55 (2001)
8. Chong, C.T., Lempp, S., Yang, Y.: On the role of the collection principle for Σ0
2
formulas in second-order reverse mathematics. Proc. Am. Math. Soc. 138, 1093–
1100 (2010)
9. Chong, C.T., Slaman, T.A., Yang, Y.: The metamathematics of the stable Ram-
sey’s theorem for pairs. J. Am. Math. Soc. 27, 863–892 (2014)
10. Dzhafarov, D.D.: Cohesive avoidance and strong reductions. Proc. Am. Math. Soc.
143, 869–876 (2015)
11. Dzhafarov, D.D., Hirst, J.L.: The polarized Ramsey’s theorem. Arch. Math. Logic
48(2), 141–157 (2011)
12. Dzhafarov, D.D., Jockusch, C.G., Solomon, R., Westrick, L.B.: Eﬀectiveness of
Hindman’s theorem for bounded sums. In: Day, A., Fellows, M., Greenberg, N.,
Khoussainov, B., Melnikov, A., Rosamond, F. (eds.) Computability and Com-
plexity. LNCS, vol. 10010, pp. 134–142. Springer, Cham (2017). doi:10.1007/
978-3-319-50062-1 11
13. H`ajek, P., Pudl`ak, P.: Metamathematics of First-Order Arithmetic. Perspectives
in Mathematical Logic. Springer, Heidelberg (1993)
14. Hindman, N.: The existence of certain ultraﬁlters on N and a conjecture of Graham
and Rothschild. Proc. Am. Math. Soc. 36(2), 341–346 (1972)
15. Hindman, N.: Finite sums from sequences within cells of a partition of N. J. Comb.
Theory Ser. A 17, 1–11 (1974)
16. Hindman, N., Leader, I., Strauss, D.: Open problems in partition regularity. Comb.
Probab. Comput. 12, 571–583 (2003)
17. Hirschfeldt, D.R.: Slicing the Truth (On the Computable and Reverse Mathematics
of Combinatorial Principles). Lecture Notes Series, vol. 28, Institute for Mathemat-
ical Sciences, National University of Singapore (2014)
18. Hirst, J.: Hilbert vs. Hindman. Arch. Math. Logic 51(1–2), 123–125 (2012)
19. Montalb´an, A.: Open questions in Reverse Mathematics. Bull. Symbolic Logic
17(3), 431–454 (2011)
20. Simpson, S.: Subsystems of Second Order Arithmetic, 2nd edn. Cambridge Uni-
versity Press, New York (2009). Association for Symbolic Logic

Inﬁnite Time Busy Beavers
Oscar Defrain, Bruno Durand(B), and Gr´egory Laﬁtte(B)
LIRMM, CNRS, Universit´e de Montpellier, 161 Rue Ada,
34095 Montpellier Cedex 5, France
{oscar.defrain,bruno.durand,gregory.lafitte}@lirmm.fr
Abstract. In 1962, Hungarian mathematician Tibor Rad´o introduced
in [8] the busy beaver competition for Turing machines: in a class of
machines, ﬁnd one which halts after the greatest number of steps when
started on the empty input. In this paper, we generalise the busy beaver
competition to the inﬁnite time Turing machines (ITTMs) introduced in
[6] by Hamkins and Lewis in 2000. We introduce two busy beaver func-
tions on ITTMs and show both theoretical and experimental results on
these functions. We give in particular a comprehensive study, with cham-
pions for the busy beaver competition, of the classes of ITTMs with one
or two states (in addition to the halt and limit states). The computation
power of ITTMs is humongous and thus makes the experimental study of
this generalisation of Rad´o’s competition and functions a daunting chal-
lenge. We end this paper with a characterisation of the power of those
machines when the use of the tape is restricted in various ways.
1
Introduction
Inﬁnite time Turing machines (ITTMs) were deﬁned by Hamkins and Kidder in
1989 and introduced in 2000 in a seminal paper [6] by Hamkins and Lewis. They
are a generalisation of classical Turing machines to inﬁnite ordinal time — the
only diﬀerence is the behaviour at limit ordinal stages: the head moves back to
the origin, the machine enters a special limit state, and each cell takes as value
the supremum limit (abbreviated to limsup) of its previous values.
The busy beaver competition for Turing machines was presented by
Hungarian mathematician Tibor Rad´o in 1962 [8]: in a class of machines, ﬁnd
one which halts after the greatest number of steps when started on the empty
input. Rad´o also considered other complexity criteria, e.g., the number of non-
zero cells.
In this paper, we generalise the busy beaver competition to ITTMs and
ordinal time. We introduce several busy beaver functions on ITTMs and show
both theoretical and experimental results on these functions. The research in
this paper is thus an original mixture of theoretical and experimental approaches,
The research for this paper has been done thanks to the support of the Agence
nationale de la recherche through the RaCAF ANR-15-CE40-0016-01 grant.
The authors would also like to express their thanks to the anonymous referees, who
made numerous suggestions and interesting remarks.
c
⃝Springer International Publishing AG 2017
J. Kari et al. (Eds.): CiE 2017, LNCS 10307, pp. 221–233, 2017.
DOI: 10.1007/978-3-319-58741-7 22

222
O. Defrain et al.
feeding each other. There are several subtle theoretical results helping the brute-
force experimentation and the experimental results point in the direction of
theoretical results which then need to be proved.
It is important to mention that the brute-force experimentation is very dif-
ferent from the kind of experimentation one comes across in the classical busy
beaver case. In the classical case, the busy beaver functions that we try to “com-
pute” are non-recursive. In the inﬁnite-time case, our functions are not only
non-recursive, they are not even arithmetic. We are able to go beyond this dif-
ﬁculty by inventing diﬀerent heuristics and by having the program ask the user
his analysis of the values of the cells for certain limit ordinal stages. In the clas-
sical case, if a machine halts, one just needs to run it for a long enough time
to end up witnessing that it halts. In the inﬁnite-time case, it is not obvious
to simulate the machine for an unbounded ordinal number of steps, one needs
to simulate the diﬀerent kinds of ordinal limits to go higher up in the ordinal
ladder. On the other hand, in the classical case, the number of steps reached are
very large numbers without a clear meaning, but in the inﬁnite-time case, the
ordinals reached speak a lot more for themselves.
As in the classical case, one of the busy beaver complexity criteria for our
inﬁnite-time case is the number of ordinal steps. ITTMs have the particular
property that every diverging machine eventually reaches a periodic behaviour,
a ﬁnal loop from which it will never escape. One of the other busy beaver com-
plexity criteria is thus the stage at which a diverging machine enters this ﬁnal
loop. Another one is the period of that ﬁnal loop. Each of these complexity
criteria give rise to a distinct busy beaver function.
In Sect. 3, we give a comprehensive study of these busy beaver functions for
classes of ITTMs with one or two states (in addition to the halt and limit states).
We analyse completely and in detail the behaviour of the machines of those two
classes when started with an empty input and classify those machines in diﬀerent
categories, similar to the study made by Allen H. Brady for the ﬁrst classes of
the classical case [3] in the 1970’s. The ITTM simulation itself is described at
the beginning of Sect. 3. The experimental simulation can be carried out and the
diﬀerent busy beaver functions are identiﬁed thanks to the theoretical results
from Sect. 2. By this experimental study, we obtain the champions for those two
classes of these various busy beaver competitions.
The busy beaver functions are also studied from a degree-theoretic point of
view in Sect. 2 and we end this paper with characterisations of the power of those
machines when the use of the tape is limited in various ways, characterisations
hinted by the experimental study.
2
ITTMs and Busy Beaver Functions
2.1
Inﬁnite Time Turing Machines
An inﬁnite time Turing machine (ITTM for short) is a three-tape (input, scratch,
output) Turing machine on alphabet {0, 1} with one halt state enhanced with a
special limit state.

Inﬁnite Time Busy Beavers
223
The machine halts when it has reached its halt state. The limit state makes
it possible for a Turing machine to carry on for an inﬁnite ordinal time. At
a limit ordinal stage, an ITTM enters the special limit state, moves its head
back to the ﬁrst cell, and updates its tapes such that each cell is equal to the
limsup of its previous values. After reaching this special limit state, it carries
on its computation as a classic Turing machine before entering again the special
limit state, and so on. We can thus let the machine run for an arbitrary large
ordinal time.
Fig. 1. ITTM loops
The limsup rule for the cells implies that if the value of
a cell at a limit stage is 0, then there must be some earlier
stage at which the cell had the value 0 and never subse-
quently changes. If the cell has the value 1 at a limit stage,
then there are two possibilities, either at some earlier
stage the cell obtained the value 1 and never subsequently
changed, or the value of the cell alternated unboundedly
often between the values 0 and 1 before that limit stage.
To summarize, at a limit stage, a cell has either stabilized
(to 0 or 1) or has value 1 because it ﬂashed, i.e., the cell
alternated unboundedly often between values 0 and 1.
The power of these machines can be grasped through
various ordinals. An ordinal α is clockable if there is an
ITTM halting at this stage α starting with an empty tape.1
An ordinal α is writable if there is an ITTM halting after
having written a real coding the characteristic sequence of
a well-order on ω of ordinal type α. The supremum of the clockable ordinals,
denoted by γ∞, and the supremum of the writable ordinals, denoted by λ∞, can
be shown to be equal and quite a large countable ordinal, well beyond ωCK
1
as it
is the λ∞th admissible ordinal, the λ∞th admissible limit of admissible ordinals
(recursively inaccessible), the λ∞th admissible limit of recursively inaccessibles,
and so on.2
Two other ordinals which play an important role for these machines are
ζ∞and Σ∞deﬁned respectively as the supremum of eventually3 writable and
accidentally(see Footnote 3) writable ordinals. Philip Welch gave in [10] the
characterisation for these ordinals: the triple λ∞, ζ∞, Σ∞is the lexicographically
least triple α, β, γ such that Lα ≺1 Lβ ≺2 Lγ.
For classical Turing machines, when a machine enters a loop, it can never
escape it. It is important to note that the behaviour of inﬁnite-time Turing
machines is completely diﬀerent in that respect: a machine can enter a loop and
1 The last transition is not counted to allow for clockable limit ordinals [6].
2 Concerning admissible sets and ordinals, the interested reader is referred to [1].
3 A real x is eventually writable if there is a non-halting inﬁnite time computation, on
input 0, which eventually writes x on the output tape and never changes again. A
real x is accidentally writable if it appears on one of the tapes during a computation,
possibly changing it again later on. An ordinal α is eventually (resp. accidentally)
writable if the real coding a well-order on ω of order-type α is eventually (resp.
accidentally) writable.

224
O. Defrain et al.
ﬁnally escape it thanks to the supremum limit rule of the cell values. A loop
from which a machine cannot escape will be called a ﬁnal loop. An example
of a machine escaping a ﬁrst loop and then being caught in an other loop,
which is ﬁnal, is given with parts of its space-time diagram 4 in Fig. 1. The
following theorem states that every diverging machine eventually enters a ﬁnal
loop. Moreover, every ITTM either halts or repeats itself in countably many steps
([6, Theorem 1.1]). It also gives some explanations on how an ITTM can diverge.
We sketch the proof of the ﬁrst part because it gives fundamental insights in the
workings of ITTMs and is essential to understand the rest of this paper.
Theorem 1 (Final Loop [6,10]). Any halting ITTM halts at a countable stage.
Moreover, any diverging ITTM eventually enters, at a countable stage, a ﬁnal
loop from which it will never escape. If the diverging machine runs on an empty
tape, its conﬁgurations at time ω1, Σ∞and ζ∞are equal. If the diverging
machine runs on input x, its conﬁgurations at time ω1, Σx
∞and ζx
∞are equal,
where the two latter ordinals represent the relativised versions.
The proof of the ﬁrst part of this theorem can be found in [6]. It considers the
conﬁguration5 C reached at stage ω1. This conﬁguration already appears at a
countable stage γ and will be repeated unboundedly often. It is important to
note that none of the cells which have stabilized to the value 0 at stage γ, and
thus also at stage ω1, will ever again turn to 1. So, the conﬁguration at a limit
stage before which the conﬁguration C was repeated unboundedly often will
again be the conﬁguration C. The computation will thus repeat endlessly this
ﬁnal loop which started at stage γ and never halt. We consider the supremum of
the enter-stages of these loops and using arguments from [10], we can show that
it is in fact equal to ζ∞. The supremum of the loop periods (and end-stages) of
ﬁnal loops can also be shown to be equal to Σ∞.
This bound is reached by a variant of a universal machine: a machine U
that simulates the computations of all ITTMs on the empty input, on ω many
disjoint portions of the scratch tape. Moreover, U can be chosen to almost work
in ‘ω-real-time’, i.e., such that U simulates ω many steps of each machine in ω
many steps of simulation time.
In the sequel, we say that an ordinal α is looping if there exists an ITTM
that enters its ﬁnal loop at stage exactly α. In other terms, the ω1-conﬁguration
of this machine appears for the ﬁrst time at stage α. A ﬁnal loop example is
given in Fig. 1, with a machine entering its ﬁnal loop at stage ω2, thus making
this ordinal looping.
Now we can formulate some remarks on ﬁnal loops that will be very useful
for our experimental study. Let us consider the conﬁguration of an ITTM when
4 ω00|10ω denotes a tape with its left part ﬁlled with 0’s and its right part ﬁlled with
a 1 (the origin) and then 0’s. In this notation, the origin is the ﬁrst cell on the right
of the symbol |, here a 1.
5 The conﬁguration of a computation at a given stage is a complete description of the
state of the machine at this stage. It comprises the state, the position of the head
and the complete content of the tapes.

Inﬁnite Time Busy Beavers
225
it is entering a ﬁnal loop. Its 0’s will remain at 0 forever while its 1’s may change.
Indeed, if a cell at 0 changes to 1 at least once during a ﬁnal loop, consider this
cell after ω loops. Its value is 1, which contradicts that the loop was chosen ﬁnal.
As a consequence, if two conﬁgurations at distinct limit stages α and β of an
ITTM M are the same and if none of the 0’s ever ﬂash between those two stages,
then M is diverging and the loop between α and β is ﬁnal. This property will
be used to decide divergence in our simulator.
2.2
Inﬁnite Time Busy Beaver Functions
We deﬁne here an inﬁnite time version of the well known busy beaver competition
introduced by Tibor Rad´o in 1962 [8] for classical Turing machines.
The model considered in [6] has three tapes. For a more natural deﬁnition of
busy beavers, we limit our model to one tape (with the supremum limit behaviour
for cell values at limit stages). It is easy to see that restricting our model to one
tape changes the clockable ordinal gaps, but that the supremums of clockable,
eventually writable and accidentally writable ordinals remain the same.
Informally, the inﬁnite time busy beaver competition consists, for a given n,
in selecting the machine among the ITTMs with n states in addition to the halt
and limit states (called the bb-category n of the competition) which produces the
greatest ordinal when run from an empty input. Several busy beaver functions
can be devised according to the diﬀerent ways these ordinals can be produced.
We deﬁne three natural generalisations of the classical case, derived from the
notions of clockable ordinals and ﬁnal loops.6
We ﬁrst deﬁne Γ : ω →γ∞, Λ : ω →ζ∞+ 1, and Π : ω →Σ∞+ 1 as
the functions that consider as input an ITTM and produce the ordinal stage at
which it reaches respectively the halt state (if it halts), its ﬁnal loop and the
period of its ﬁnal loop (if it diverges)7.
We now deﬁne the bb-functions Γbb, Λbb and Πbb as the functions which
maximize the functions Γ, Λ, and Π on each bb-category. The ﬁrst bb-function
Γbb : ω →γ∞maps a given bb-category n to the largest clockable ordinal
produced by an ITTM of that category, etc.
In order to compare the power of these functions and of related ordinals, we
use the ITTM-reduction8, denoted by ≼∞and deﬁned in [6], and assume that
the ordinals considered (also as output of these functions) are coded in reals with
an appropriate coding. For each ordinal α, there are continuum many possible
choices for rα, the real coding α. We would like to consider codes that do not
contain extra information, in particular with regards to ≼∞. rα is thus chosen
to be the L-least real coding a well-order on ω of order-type α. For the ordinals
considered in this paper, this means that the code rα considered for α will be
such that rα ∈Lα+1.
6 Loops can be considered as transient steps followed by an eventual ﬁnal loop, and it
is natural to measure the stage at which it appears and the length of that ﬁnal loop.
7 By Theorem 1, we know that the sup of looping ordinals, ζ∞, and periods, Σ∞, are
reached by the universal machine. Λ and Π can thus reach these maximum values.
8 A is ITTM computable from B, written A ≼∞B, if the characteristic function of A
is inﬁnite time computable with oracle B. Reals are seen here as subsets of ω.

226
O. Defrain et al.
Remark that the functions Λbb and Πbb (but not Γbb) will become eventually
constant when the bb-category reaches a level containing a universal machine.
Theorem 2. rγ∞≡∞0▽≡∞Γbb ≡∞Γ
(using the notations9 of [6])
≺∞Λbb ≡∞rζ∞≡∞rΣ∞≡∞Λ ≡∞Πbb ≡∞Π ≺∞0▼
Proof. Let’s ﬁrst prove that rγ∞≼∞0▽. The idea is to build an order such that
i < j if Mi halts before Mj. As ω machines halt at a given time, we consider only
the ﬁrst program with a given halting time that is discovered (while running
the chosen universal ω-real-time machine U). Our program runs as follows: it
simulates U and little by little constructs an order such that i < j if i and j
are considered and if Mi halts before Mj. The representation of the order must
be adjusted carefully : when we add an element in this order, then ω values
are changed, but we can propagate those changes in parallel by runs of ω. In
parallel we check whether all elements of 0▽have been observed halting in the
U-simulation. If yes, we halt (at time γ∞). We thus get x that codes γ∞, and by
minimality we get rγ∞≼∞x ≼∞0▽.
0▽≼∞rγ∞: We consider e as input, simulate the computation of Me on
0, and count-through rγ∞. Either we observe ﬁrst that Me(x) halts and then
e ∈0▽, or we observe that the count-through halts and then e ̸∈0▽.
0▽≼∞Γ is trivial since Γ contains 0▽and in addition, contains the halting
time for all machines which halt.
Γ ≼∞0▽corresponds to an important result of the literature [10]: any clock-
able ordinal is writable. In the proof of this theorem (see also [5] for an alterna-
tive construction) a single program transforms Me that halts in α steps into a
(minimal) code for α. We thus get the required inequality.
Γbb ≡∞Γ : the proof is analogous to the Turing case. To ITTM-compute
Γbb from Γ, one just needs to compute a maximum. In the other direction, one
simulates all machines of the same class up to the time given by Γbb and as
previously compute the ad hoc halting time if any.
We obviously have rγ∞≼∞rζ∞≼∞rΣ∞. rγ∞̸≽∞rζ∞since λrλ∞
∞
is eventu-
ally writable: we eventually compute rλ∞and in parallel, we simulate U. When
we observe that we are in a gap, we start computing U on the ordinal that starts
the gap (obtained while eventually-computing rλ∞). With this latter simulation
of U, we build the order-type of the set of its clockables as usual. This process
stabilizes when the input for U is rλ∞and eventually-computes λrλ∞
∞
.
rΣ∞≼∞rζ∞since once we have found the conﬁguration at stage ζ∞of U,
we just need to wait for the second occurrence to grasp Σ∞.10 Λbb ≡∞rζ∞is
rather trivial since Λbb consists of a ﬁnite number of ordinals < ζ∞followed by
rζ∞itself. The ﬁrst ones are just encoded as an integer in rζ∞thus we add only
a ﬁnite information that we can produce by a constant program.
⊓⊔
9 We denote by Me the eth ITTM in a standard recursive enumeration. The two jumps
are deﬁned as 0▽= {e | Me(0) ↓} and 0▼= {⟨e, x⟩| Me(x) ↓}.
10 A corollary is that Σ∞is not admissible, as is already proven in [9, Corollary 3.4].

Inﬁnite Time Busy Beavers
227
3
Experimental Study of the Busy Beaver Functions
3.1
Experimental Simulation of an Inﬁnite Time Turing Machine
The experimental simulation of an ITTM is based on three parts. The ﬁrst part
is the simulation of the machine for one step. It simulates the read-write-move
mechanism of the ITTM as any classical Turing machine simulator would do.
The second part consists in guessing when to stop the simulation on successor
ordinals, in order to jump to the next limit stage and devise the limit tape. It
is based on the number of steps of computation as well as the machine’s head
trajectory (a great number of steps can be needed to reach such a threshold).
The next limit stage itself is found by the simulator depending on current stages.
The last part of the simulation is the guessing of the cell values of the limit tape
considering the cells that have been ﬂashed at previous stages. It is based on
several criteria. A major one is cell stability, i.e., analysing for each cell the
number of times its value changed (till the last limit stage) and the number of
computation steps that has elapsed till the last value change. Other criteria are
the head trajectory for limits of successor ordinals, previous coﬁnal ﬂashes 11
for higher limit ordinals, areas of diﬀerences between consecutive limit stages,
etc.
All these elements together allow us to understand the behaviour of the
machine and to devise the limit tape. Finally, human intervention is possible and
sometimes necessary if the simulator cannot make a decision on how to move up
in the limit ordinal ladder or what values the cells of the limit tape should have.
As our simulation has obviously only ﬁnite means, there are many limits to
our simulation. Considering previous ﬂashing cells on the tape to build the cells’
values at a limit stage, the simulator could recognise a stable repetitive pattern
when in reality it would have changed a few thousand stages of computation
later. This is especially the case when dealing with machines that present a
chaotic behaviour (already present in the second category, bb-2). A solution is
to increase memory thresholds (number of steps, tape size, etc.), at the expense
of simulation speed. Finally, a lot of user double-checking by hand allowed us to
build quite a reliable simulator (at least for machines with few states).
Clockable ordinals are simply obtained when reading the halting transi-
tion. Diverging machines and looping ordinals are detected using the divergence
remark at the end of Sect. 2.1.
3.2
Study of Whole Classes of Machines
The study of a whole class of machines mixes enumeration and simulation. We
ﬁrst explain our enumeration of machines, and give a summary of the various
behaviours of these machines and largest clockable and looping ordinals found
during the simulation of these classes.
11 Finitely many ﬂashes that occur at successor ordinals do not aﬀect the next limit
stage but later ones of higher order (cf. coﬁnally ﬂashing behaviour in the sequel).

228
O. Defrain et al.
Enumerating a Class of Machines. We enumerate the machines by adding
transitions on the ﬂy, making sure that we only add a transition when needed (in
the simulation) and avoiding the diﬀerent symmetries that can arise in the tran-
sitions graph. When an ITTM halts or is found as diverging, we simply update
the transition that has been last set following a certain order on transitions. This
order allow us to simulate a class completely.
Fig. 2. ITTM speciﬁc ﬁlters
Moreover, ﬁlters are applied to get rid of non
connected machines (in a sense of graph connec-
tivity on the transitions graph), symmetric and
trivial machines. This is very similar to what
a classical Turing machine simulator would do.
However, there is yet another ﬁlter speciﬁc to
ITTMs which allows us to ignore patterns shown
in Fig. 2 that lead either to a loop or to a halt at
a stage that would not exceed 12 the limit ordinal ω · 2.
This enumeration on the ﬂy allows us to ﬁnd respectively 169 and 52189
distinct machines for the ﬁrst two classes, bb-1 and bb-2.
Experimental Results. Experimental simulations gave us more material to
appreciate how much ITTMs can be powerful even with only one or two states.
Typical computational behaviours such as counters and fractal space-time dia-
grams already appear in the ﬁrst and second categories, bb-1 and bb-2. More-
over, some behaviours of the classical busy beaver (such as Xmas trees, cf. [3])
appear with a smaller number of states in our ITTM competition, e.g., Xmas
trees with 1 state instead of 4.
We now give an overview of the ﬁrst two classes with a selection of represen-
tative machines for each typical behaviour and their variants.
BB-1. This little class possesses 4 typical distinct behaviours, summarized in
the following. The Xmas tree behaviour appears thanks to a previously written
ω0|1ω tape(see Footnote 4) after ω steps. The machine’s head goes unboundedly
often from left to right, drawing a Xmas tree (in its space-time diagram). The
coﬁnally ﬂashing behaviour is the ITTM’s most natural behaviour: the machine
ﬂashes ﬁnitely many times a 0 cell and ends up stabilizing it to 0 (and thus
without changing its value at the limit). Thus, if repeated on each limit, say ω,
ω · 2, . . . , these ﬁnitely many ﬂashes directly aﬀect the limit of limits, that is
ω2. The noise expanding behaviour consists in a machine generating noise at the
origin, due to multiple limit jumps (and the head going directly to the origin).
12 Indeed, suppose the machine did not halt for ω steps and reached the limit state.
Either the machine will loop indeﬁnitely on this limit state and is said to be diverging
or will eventually halt excluding the middle pattern. Suppose it will eventually halt
and go for more than ω steps taking the transition that loops on the limit state:
either it will halt on the tape, reading a diﬀerent symbol at a stage ω + c for an
integer c, or reach the next limit stage at ω · 2 by reading a uniform tape. At this
point, the machine halts if the looping transition modiﬁed the origin cell value, or
loops indeﬁnitely on the limit state.

Inﬁnite Time Busy Beavers
229
Fig. 3. Typical bb-1 behaviours (and their bb-2 extensions)
This noise grows and ends up taking all the tape at a higher limit. Finally, we
denote by counting behaviour a machine that launches a counting procedure
such as enumerating integers, in a certain order and written in binary, at limit
tapes. These integers in binary can be viewed as patterns and their alternation
aﬀects limits of higher order.
The largest clockable ordinal for this class is produced by the coﬁnally ﬂash-
ing behaviour. The largest looping ordinals are produced by coﬁnally ﬂashing,
noise expanding and counting behaviours. For this ﬁrst category bb-1, we get
Γbb(1) = Λbb(1) = ω2 witnessed by the halting machine 4a and the diverging
machines 2a (Π(·) = ω2) and 3 (Π(·) = ω) in Fig. 3.
BB-2. Many enriched behaviours such as moving or one-sided Xmas trees are
now possible, along with fractal counting, etc. Moreover, previous typical behav-
iours such as coﬁnally ﬂashing and counting behaviours are now improved. Exam-
ple machines for these enriched behaviours are given in Figs. 4 and 6. Improved
aforementioned behaviours are given in Fig. 3, e.g., the ‘enhanced’ counting and
coﬁnally ﬂashing behaviours.
Fig. 4. Xmas bb-2 variants
Fig. 5. New bb-2 behaviours

230
O. Defrain et al.
*
Fig. 6. Other bb-2 variants (*This halting machine ends up displaying a periodic tape
ω0|(1110)ω at stage ω2.)
Two new typical distinct behaviours appear in this class. The ﬁrst one draws
Sierpinski triangles when considering a history of all ﬂashes performed to reach
ω·c stages. We denote this phenomenon by the Sierpinski behaviour. The second
one is the chaotic behaviour that consists of a machine reducing or expanding
concatenated groups of same values on each limit stage ω · c for every integer c.
This procedure generates a lot of ﬂashes all over the tape. These ﬂashes appear
as being chaotic at a higher order limit stage and the machine promptly halts or
diverges. Representative machines for these two behaviours are given in Fig. 5.
The largest clockable ordinal for this class is once again produced by the
coﬁnally ﬂashing behaviour with Γbb(2) = ωω+ω·2+3 witnessed by the machine
4c in Fig. 3. The largest looping ordinal is produced by coﬁnally ﬂashing and
counting behaviours with Λbb(2) = ωω witnessed by the machine 4b (Π(·) = ω)
in Fig. 3.
4
Tape Use Restrictions
In this section, we investigate the consequences of several restrictions on the
kind of tape that the machines are allowed to use.
4.1
Finite Tape Restriction
We say that an ITTM M uses k cells on input x, if M halts on the entry x, and
if there exists a set of exactly k cells such that outside this set, the cells remain
at value 0 during all the computation.
Proposition 1 (Only one cell). The possible halting times for machines using
one cell on input 0 are exactly n, ω + n, ω · 2 + n, or ω2 + n where n is any ﬁnite
constant.
Proof. The halting times ω + n and ω · 2 + n are straightforward (to get the +n
term, we use n extra states). In Fig. 3 we present the winner of the class bb-1
that halts after exactly ω2 steps (and then add +n). The halting times ω · k,
k ≥3, and every α > ω2 +ω are impossible since there only two possible choices
for the value of the origin cell (when in the limit state).
⊓⊔
Theorem 3 (Finitely many cells). The ordinals clockable by machines using
ﬁnitely many cells are exactly the ordinals < ωω.

Inﬁnite Time Busy Beavers
231
Proof. We assume that there exists an ITTM M that halts in ωω or more steps
using k cells and obtain a contradiction. Consider the conﬁguration at stage ωω
and consider a window of ﬁnite size that contains all k cells touched by M.
There exists a stage γ after which all 0’s in the window (identiﬁed as the grey
cells) placed on the conﬁguration at stage ωω have stabilized. Between γ and ωω,
all limit conﬁgurations have the grey cells at 0. Among these limit conﬁgurations,
let us consider pairs of equal conﬁgurations. We observe their number of 1’s. It
has a supremum limit denoted by S. If S is exactly the number of 1’s of the
conﬁguration at stage ωω, then there exists a pair of conﬁgurations where all 0’s
from inside the window are grey cells. From the remarks at the end of Sect. 2.1,
we conclude that M diverges. Thus S is less than the number of 1’s of the
conﬁguration at stage ωω. Let us denote by β1 and β2 the stages corresponding
to such a pair with S 1’s. If all 0’s of the window remain unchanged between
stage β1 and β2, then again M diverges. Thus at least one non-grey 0 ﬂashes at
least once. Now let us consider ω times this (non-ﬁnal) loop between β1 and β2.
As β2 is bounded by ωa for some integer a, we get a limit conﬁguration with
at least S + 1 1’s before ωω. After this conﬁguration, we consider another pair
β′
1 and β′
2 with S 1’s. By the same argument we get another limit conﬁguration
with at least S + 1 1’s before ωω. We iterate this process, and, having only a
ﬁnite choice for these 1’s in the window, we get two equal limit conﬁgurations
with S + 1 1’s which contradicts the deﬁnition of S.
Fig. 7. Machine halting after ωn steps
We now construct a machine that
halts after time ωn for any inte-
ger n using only a ﬁnite num-
ber of cells. This machine is based
on the improved counting behav-
iour described in Sect. 3.2, and is
intentionally left unoptimized for a
better understanding. In the follow-
ing, we denote by the term ‘pattern’
a set of 3 consecutive cells described
in the tabular in Fig. 7. In the
sequel, we explain how this machine
uses them to iterate a counter up to
ωn.
First of all, a delimiter pattern m↓is written 3n cells away at left from
origin and the machine enters the D-state (cf. Fig. 7) that goes quietly to the ω
limit without ﬂashing any new cells. This is denoted by states (d1, . . . , d3n+3) in
Fig. 7. Then, a counting procedure is launched, based on pattern recognition and
alternation. If the machine recognises an empty pattern m∅(r1, r2, r3 states), it
remplaces it with a m1 pattern (i1, i2, i3) and jumps to the next limit. If one
of the standard patterns (m1 and m2) are recognised, the pattern is switched
from m1 to m2 or reciprocally (s1, s2, s3) and the machine loops to the next
limit. Although it is never written, a limit pattern mL will be found after ω
alternations of m1 and m2 and thus mL appears for the ﬁrst stage after ω2 steps
of computation. If mL is read, then the machine ignores it and seeks the next

232
O. Defrain et al.
pattern on the left (l0). Using one state (D-state), we erase all mL patterns
after next patterns incrementation. When a limit pattern mL is found for the
ﬁrst time in the kth pattern from the origin, the machine has computed ωk
steps. The whole counting procedure stops when the tape is full of mL patterns
between origin and m↓, which is discovered at stage ωn + 3n + 2 using 3n + 4
cells.
⊓⊔
4.2
Ultimately Periodic and Recursive Tape Restrictions
We focus on those machines whose tapes are ultimately periodic at any computa-
tion time. We can deﬁne those machines as those for which their conﬁgurations
at any limit stage is ultimately periodic.13 One reason for considering these
machines is that at any time, their tape can be ﬁnitely described.
Of course, the natural extension of these two tape-restriction notions is to
ask for the tape at any stage to be recursive. This is also a constraint that only
concerns limits stages: a point-to-point limit of those recursive tapes must be
recursive.14
We conjecture the following generalisation of Theorem 3.
Conjecture. Every ITTM which halts when started on the empty input and
whose tapes are ultimately periodic (resp. recursive) halts after less than ε0 (resp.
ωCK
1
) steps.
References
1. Barwise, J.: Admissible Sets and Structures: An Approach to Deﬁnability Theory.
Perspectives in Mathematical Logic, vol. 7. Springer, Heidelberg (1975)
2. Brady, A.H.: The conjectured highest scoring machines for Rad´o’s Σ(k) for the
value k = 4. IEEE Trans. Electron. Comput. EC 15(5), 802–803 (1966)
3. Brady, A.H.: The determination of the value of Rad´o’s noncomputable function
Σ(k) for four-state turing machines. Math. Comput. 40(162), 647–665 (1983)
4. Brady, A.H.: The busy beaver game and the meaning of life. In: Herken, R. (ed.)
The Universal Turing Machine: A Half-Century Survey, 2nd edn, pp. 237–254.
Springer, New York (1995)
5. Durand, B., Laﬁtte, G.: A constructive swissknife for inﬁnite time turing machines
(2016)
6. Hamkins, J.D., Lewis, A.: Inﬁnite time turing machines. J. Symbolic Log. 65(2),
567–604 (2000)
7. Laﬁtte, G., Papazian, C.: The fabric of small turing machines. In: Proceedings of
the Third Conference on Computability in Europe Computation and Logic in the
Real World, CiE 2007, Siena, Italy, 18–23 June 2007, pp. 219–227 (2007)
13 Note that knowing whether a machine has this property is not decidable. This was
also the case with the ﬁnite tape restriction.
14 The situation is not the same for stage ω than for compound limit ordinal stages,
e.g., ω2, since in the ﬁrst case we take the limit of a recursive sequence of recursive
tapes while in the latter, the sequence of tapes is not necessarily recursive.

Inﬁnite Time Busy Beavers
233
8. Rad´o, T.: On non-computable functions. Bell Syst. Tech. J. 41(3), 877–884 (1962)
9. Welch, P.D.: The length of inﬁnite time turing machine computations. Bull. London
Math. Soc. 32, 129–136 (2000)
10. Welch, P.D.: Characteristics of discrete transﬁnite time turing machine models:
Halting times, stabilization times, and normal form theorems. Theoret. Comput.
Sci. 410, 426–442 (2009)

Permutive One-Way Cellular Automata
and the Finiteness Problem
for Automaton Groups
Martin Delacourt(B) and Nicolas Ollinger
Univ. Orl´eans, LIFO EA 4022, 45067 Orl´eans, France
{martin.delacourt,nicolas.ollinger}@univ-orleans.fr
Abstract. The decidability of the ﬁniteness problem for automaton
groups is a well-studied open question on Mealy automata. We connect
this question of algebraic nature to the periodicity problem of one-way
cellular automata, a dynamical question known to be undecidable in the
general case. We provide a ﬁrst undecidability result on the dynamics of
one-way permutive cellular automata, arguing in favor of the undecid-
ability of the ﬁniteness problem for reset Mealy automata.
Keywords: Reset Mealy automata · One-sided cellular automata · Per-
mutive cellular automata · Periodicity problem · Reversible computation
1
Introduction
Finite-state automata provide a convenient ﬁnite description for diﬀerent kinds of
behavior generated by their computations. As such, Mealy automata [10] provide
a ﬁnite description for the family of automaton (semi)groups that has proven its
usefulness to generate interesting counter examples in the ﬁeld of group theory
[3]. Several decision problems inspired by algebraic questions have been studied
on automaton groups: the word problem is decidable whereas the conjugacy
problem is undecidable [16]. The general case of the ﬁniteness problem remains
open [1] although special cases have been solved: Gillibert [9] proved that the
problem is undecidable for semigroups and Klimann [15] that it is decidable for
reversible Mealy automata with two states. The status of the ﬁniteness problem
remains open for the class of reset Mealy automata.
Cellular automata [14] provide a ﬁnite description for a family of discrete
dynamical systems, the endomorphisms of the shift dynamical system [11]. Deci-
sion problems inspired by dynamical questions have been investigated on cellular
automata since the work of Amoroso and Patt [2]. The computation nature of
cellular automata lead to sophisticated construction techniques to establish the
undecidability of various decision problems like the nilpotency problem [13] or
more recently the periodicity problem [12]. The status of the periodicity problem
remains open for one-way cellular automata.
Without much surprise, cellular automata can be a valuable tool to establish
undecidability results on Mealy automata. Indeed, Gillibert’s result is inspired
by Kari’s proof of the undecidability of the nilpotency problem.
c
⃝Springer International Publishing AG 2017
J. Kari et al. (Eds.): CiE 2017, LNCS 10307, pp. 234–245, 2017.
DOI: 10.1007/978-3-319-58741-7 23

Permutive One-Way Cellular Automata and Automaton Groups
235
In this paper, we study the computational power of reversible permutive one-
way cellular automata [4,7]. Our ﬁrst contribution is a precise formalization of
the connection between both open problems: the ﬁniteness problem for reset
Mealy automata is decidable if and only if the periodicity problem for one-
way cellular automata is decidable. Our second contribution is a technique to
embed computation inside reversible one-way cellular automata using permutive
automata. The technique is applied to prove a ﬁrst undecidability result on these
objects.
2
Deﬁnitions
For a detailed introduction on Mealy automata, the reader is referred to
Bartholdi and Silva [3] and to Kari [14] for cellular automata.
2.1
Mealy Automata
A Mealy automaton is a deterministic complete 1-to-1 transducer (A, Σ, δ, ρ),
where A is a ﬁnite set of states, Σ a ﬁnite alphabet, δ = (δi : A →
A)i∈Σ is the set of transition functions and ρ = (ρx : Σ →Σ)x∈A the
set of production functions. The transition x
i|ρx(i)
−−−−→δi(x) is depicted by
x
δi(x)
i
ρx(i)
.
The production functions naturally extend to functions on the set of ﬁnite
words: ρ = (ρx : Σ∗→Σ∗)x∈A with ρx(au) = ρx(a)ρδa(x)(u). The semigroup
generated by the automaton is the set of all compositions of the production
functions H = ⟨ρx : x ∈A⟩. An automaton semigroup is a semigroup generated
by a Mealy automaton.
A Mealy automaton is invertible if ρx is a permutation of Σ for every x ∈
A. Note that it implies that every ρx is also a permutation on Σk for every k ∈N.
The group generated by a invertible Mealy automaton is G =

ρx, ρ−1
x
: x ∈A

.
An automaton group is a group generated by a Mealy automaton. An invertible
Mealy automaton generates a ﬁnite group if and only if it generates a ﬁnite
semigroup [1].
Finiteness problem. Given an invertible Mealy automaton, decide if the gen-
erated group is ﬁnite.
A Mealy automaton is reset if, for each transition x
i|ρx(i)
−−−−→δi(x), the output
state δi(x) depends only on the input letter i and not on the input state x, that
is δi(x) = f(i) for some letter-to-state map f : Σ →A. To simplify notations,
such an automaton will be denoted as (A, Σ, f, ρ).
When studying the decidability of the ﬁniteness problem restricted to reset
automata, one can focus on the case Σ = A and f = Id as stated below.

236
M. Delacourt and N. Ollinger
Lemma 1. The group generated by a reset Mealy automaton (A, Σ, f, ρ) is ﬁnite
if and only if it is the case for the automaton (Σ, Σ, 1, ρ′) with ρ′
x(i) = ρf(x)(i).
Proof. Let G be the group generated by (A, Σ, f, ρ) and H be the group gener-
ated by (Σ, Σ, 1, ρ′). As every generator ρ′
x of H is a generator ρf(x) of G then
H is a subgroup of G. A generator ρy of G with y ∈A \ f(Σ) is not a generator
of H, however as y can only be an initial state of a transition, it only impacts
the size of G by a factor n! where n is the size of Σ.
■
2.2
Cellular Automata
A one-way cellular automaton (OCA) F is a triple (X, r, δ) where X is the ﬁnite
set of states, r is the radius and δ : Xr+1 →X is the local rule of the OCA. A
conﬁguration c ∈XZ is a biinﬁnite word on X. The global function F : XZ →XZ
synchronously applies the local rule: F(c)i = δ(ci, . . . , ci+r) for every c ∈XZ
and i ∈Z. The spacetime diagram Δ : Z × N →X generated by an initial
conﬁguration c is obtained by iterating the global function: Δ(k, n) = Fn(c)k
for every k ∈Z and n ∈N. Following Hedlund [11] characterization of cellular
automata as endomorphisms of the shift, we assimilate an OCA, with minimal
radius, and its global function.
Notice that OCA are the restriction of classical cellular automata (CA) where
a cell only depends on other cells on the right side. The identity function Id, the
left shift map σl and the XOR rule are OCA, respectively encoded as (X, 0, 1),
(X, 1, (x, y) →y) and ({0, 1}, 1, ⊕), whereas the right shift map σr is not.
A state x ∈X is quiescent if δ(x, . . . , x) = x. A conﬁguration is ﬁnite if it
contains the same quiescent state x everywhere but on ﬁnitely many positions.
An OCA is (left) permutive if the map x →δ(x, x1, . . . , xr) is a permutation
of X for every (x1, . . . , xr) ∈Xr. An OCA is periodic of period T > 0 if FT = Id.
Periodicity problem. Given a cellular automaton, decide if it is periodic.
An OCA is reversible if its global function is bijective with an inverse that
is also an OCA. A periodic OCA F of period T is reversible of inverse FT −1.
Following Hedlund [11], the inverse of a bijective OCA is always a CA, how-
ever usually not one-sided. The following lemmas assert that this technical issue
disappears by considering only permutive OCA.
Lemma 2. Every reversible OCA is permutive.
Proof. Let F be a reversible OCA. As both F and F−1 are OCA, F is bijective
on XN too. Let (x, x′, x1, . . . , xr) ∈Xr+2 and c = x1 · · · xrxω
r . If x ̸= x′, as
F(xc) ̸= F(x′c), we have δ(x, x1, . . . , xr) ̸= δ(x′, x1, . . . , xr).
■
Lemma 3. Every bijective permutive OCA is reversible.
Proof. Let F be a bijective permutive OCA. By permittivity f : X × XN →X
deﬁned by f(y, c) = x where F(xc) = yF(c) is well deﬁned and permutive
in its ﬁrst argument. Let u, u′ ∈X−N and v′ ∈XN. Let w ∈X−N and v ∈
XN be such that F−1(u′v′) = wv. Let w′ ∈X−N be deﬁned recursively by

Permutive One-Way Cellular Automata and Automaton Groups
237
w′
i = f(ui, w′
i−1 · · · w′
0v). By construction F−1(uv′) = w′v. As F−1(uv′) and
F−1(u′v′) are equal on N for all u, u′, v′ the CA F−1 is an OCA.
■
Note that the inverse of a bijective permutive OCA can have a larger radius.
However, as bijectivity is decidable for cellular automata [2] and as bijectivity is
preserved by grouping cells [8], when studying the decidability of the periodicity
problem restricted to permutive OCA, one can focus on the case of reversible
permutive OCA with radius 1 and inverse radius 1 syntactically characterized
by the following lemma (already proven in [4]).
Lemma 4. An OCA (X, 1, δ) is reversible with inverse radius 1 if and only if
it is permutive and for all x, y, x′, y′ ∈X, if δ(x, y) = δ(x′, y′) then πx = πx′
where πy maps x to δ(x, y).
From now on, we only consider these OCA.
3
Linking Finiteness and Periodicity
Reset Mealy automata with Σ = A and f = Id and permutive OCA of radius 1
are essentially deterministic complete letter-to-letter transducers of a same kind,
as depicted on Fig. 1. The following proposition formalizes this link.
x
a
a
ρx(a)
b
b
ρa(b)
←→
b
a
ρa(b)
Fig. 1. Linking reset Mealy automata to permutive OCA
Proposition 1. The group generated by a reset automaton (Σ, Σ, 1, ρ) is ﬁnite
if and only if the permutive OCA (Σ, 1, δ), where δ(x, y) = ρy(x), is periodic.
Proof. First note that the following equations hold for all u0, u1, . . . , uk ∈Σ:
ρuk(uk−1, uk−2, . . . , u0) = ρuk(uk−1)ρuk−1(uk−2) . . . ρu1(u0)
δ(u0, u1, . . . , uk) = ρu1(u0)ρu2(u1) . . . ρuk(uk−1)
By extension, for all k > t > 0 and for all words u ∈Σt and v ∈Σk, the
following equation holds: ρu(v)k = δt(vk, vk−1, . . . , vk−t).
Suppose now the group generated by the reset Mealy automaton is ﬁnite.
Let a ∈Σ be any letter and let n be the order of ρa, then ρan = (ρa)n = Id thus
δn = Id, the OCA is periodic.
Conversely, let n be the period of the OCA. By previous remarks, for all
k > 0 and words u, v ∈Σn, w ∈Σk, the image ρu(vw) is v′w for some v′ ∈Σn.
The set of ρu generates a subgroup of permutations of Σn, which is ﬁnite, when
u takes all possible values in Σn. The automaton group is ﬁnite.
■

238
M. Delacourt and N. Ollinger
Corollary 1. The ﬁniteness problem restricted to reset Mealy automata is
decidable if and only if the periodicity problem restricted to OCA is decidable.
Notice that the situation described by this corollary is optimal: if the problem
is decidable, Mealy automata is the right setting to prove this result and the
decidability of the periodicity for OCA will be a consequence; if the problem is
undecidable, cellular automata is the right setting to prove this result and the
undecidability of the ﬁniteness problem will be a consequence. The remainder
of this paper is dedicated to prove that computational phenomena do appear
inside the dynamics of permutive OCA, advocating for the undecidability of the
problem.
Conjecture 1. The ﬁniteness problem is undecidable.
4
Computing with Permutive OCA
As shown in Fig. 1, the time goes up in every representation of this paper.
Given a permutive OCA, we show how to build a reversible OCA that can
simulate every spacetime diagram of the original. The idea is to slow down the
computation by delaying each state using a ﬁxed number of distinct copies per
state and perform a transition only after going through every copy. Adjacent
columns of states are then desynchronized to obtain reversibility as a conse-
quence of permittivity.
Deﬁnition 1. Let F be an OCA (X, 1, δ) and let 1 ≤k ≤n −1. The (n, k)-
embedding F′ of F is the OCA (X′, 1, δ′) where X′ = 
1≤i≤n{x(i) : x ∈X} and
such that:
∀x(α), y(β) ∈X′
δ′ 
x(α), y(β)
=

δ(x, y)(1)
if α = n and β = k
x(1+(α
mod n))
otherwise
Figure 2 illustrates the embedding.
Lemma 5. The (n, k)-embedding of a permutive OCA F is reversible.
Proof. The local rule of the inverse OCA τ can be deﬁned by
– τ(z(1), y(k+1)) = x(n) for all x, y ∈X such that δ(x, y) = z;
– τ(x(i), ∗) = x((i−1 mod n)+1) otherwise.
■
The idea of the embedding is to desynchronize adjacent columns by shifting
them vertically of some constant k between 1 and n −1. When two consecutive
columns are not correctly arranged, they do not interact.
Lemma 6. There exists an injective transformation of spacetime diagrams of
F (in XZ×N) into spacetime diagrams of F′ (in X′Z×Z): for every c ∈XZ, there
exists a unique conﬁguration c′ ∈X′Z for F′ with
∀m ∈Z, p ∈N, ∀1 ≤i ≤n, F′m(n−k)+pn+i−1(c′)m = (Fp(c)m)(i)

Permutive One-Way Cellular Automata and Automaton Groups
239
x
y
z
−→
x(1)
x(2)
x(3)
z(1)
z(2)
z(3)
y(1)
y(2)
y(3)
Fig. 2. The (3, 1)-embedding is given by the transformation of the local rule (to the
left). The space-time diagram of the XOR OCA with a unitary conﬁguration (at the
center) is transformed into a space-time diagram of a reversible OCA (to the right).
Remark 1. If the OCA has a particular state 0 such that δ(x, 0) = x for every
x ∈X, we can keep a unique version of state 0 by identifying the 0(i) as a unique
state 0 where
δ′(0, y(k)) = (δ(0, y))(1)
δ′(0, ∗) = 0 where ∗can be anything
δ′(x(i), 0) = x(1+(i
mod n))
This lemma allows to transfer results from F to F′, in the sequel we prove
the following result for permutive OCA and obtain it for reversible ones:
Reachability problem. Given a reversible OCA with a quiescent state 0 ∈X
and two states x, y ∈X, decide if y appears in the spacetime diagram generated
by the initial conﬁguration ω0.x0ω.
Theorem 1. The reachability problem is undecidable for reversible OCA.
5
Main Construction
To prove the theorem, we need to embed some Turing complete computation
into permutive OCA. This goal is achieved by simulating multi-head walking
automata. This section describes the simulation of these automata by permutive
OCA.
5.1
Multi-head Walking Automata
A multi-head walking automaton consists of a ﬁnite number of heads on the
discrete line, each one of them provided with a state out of a ﬁnite set. At each
step, they can only interact (read the state) with the heads that share the same
cell, update their state and move. Initially, all the heads are in position 0.

240
M. Delacourt and N. Ollinger
Deﬁnition 2. A k-head walking automaton is deﬁned by (Σ, I, F, (fi, gi)1≤i≤k)
where Σ is a ﬁnite alphabet that does not contain ⊥, I ∈Σ is the initial state,
F ⊆Σ is a set of ﬁnal states, ∀i, fi : (Σ ∪{⊥})k →Σ and ∀i, gi : (Σ ∪{⊥})k →
{−1, 0, 1} are the update functions for the state and the position.
A conﬁguration of this automaton is a k-tuple a = (ai, si)1≤i≤k ∈(Z × Σ)k
and its image conﬁguration is (ai + gi(bi), fi(bi))1≤i≤k where ∀1 ≤i ≤k, bi(j) =
sj if ai = aj and ⊥otherwise.
Starting from conﬁguration (0, I)k, the automaton computes the successive
images and stops only if the position of every head is 0 and their states are ﬁnal.
A multi-head walking automaton can mimic a counter with 2 heads. Turing
completeness is achieved by simulating 2-counter Minsky machines.
Proposition 2. The halting problem of 4-head walking automata is undecidable.
5.2
Finite Conﬁgurations
Every ﬁnite conﬁguration can be written c = ω0.u00ω for some u0 ∈Xn, n ∈N,
hence its successive images can only be Fk(c) = ω0vk.wk0ω for some vk ∈Xk,
wk ∈Xn, that is: the ﬁnite non-quiescent word extends to the left, one cell at
each step. We also have the following result.
Lemma 7 (Coven et al. [6]). In the spacetime diagram associated to a ﬁnite
conﬁguration, every column is periodic.
5.3
P-signals
Most cellular automata constructions use signals as elementary geometrical
building blocks. Unfortunately, it is not possible to embed a classical signal
in a permutive OCA nor is it possible to directly simulate multi-head automata.
We provide P-signals as a technique to replace signals of speed k by an (n, k)-
embedding of the front line of the spacetime diagram of the XOR with only
one non-zero cell. This will eﬀectively allow to send a signal through space in a
reversible permutive OCA.
For our construction, we ﬁx n = 7, hence we can use speeds from 1 to 6. Due
to Remark 1, the states of these signals will be denoted Z8 = {0, 1, 2, 3, 4, 5, 6, 7}.
Next lemma states that diﬀerent speeds induce similar spacetime diagrams up to
a vertical shift on each column.
Lemma 8. Denote Fk and Fk′ the OCA corresponding to signals of speeds k
and k′ and let c be the conﬁguration ω0.10ω then we have
∀m ≤0, ∀p ≥0, Fp
k(c)m = Fp−(k−k′)m
k′
(c)m.

Permutive One-Way Cellular Automata and Automaton Groups
241
5.4
2-recognizability
Our construction relies on the ability to identify some speciﬁc sets of spacetime
positions. We achieve this goal by considering products of independent P-signals.
To avoid boring calculations, we rely on the following lemma to assert some
regularity of P-signals and rely on the theory of p-recognizable sets of tuples of
integers [5] to characterize these positions.
Lemma 9. The spacetime sequence Δ : N2 →Zn+1 of the (n, k)-embedding F
of the XOR, where Δ(x, y) = Fy(ω0.10ω)−x, is 2-recognizable.
Proof. The spacetime sequence Δ of the (n, k)-embedding F is generated by the
2-substitution s : Zn+1 →Z2
n+1 uniquely deﬁned, as per Fig. 2, by
s(0) =

0 0
0 0
	
s
⎛
⎜
⎝
n
...
1
⎞
⎟
⎠=

n · · · (k + 1) k · · · 1 n · · · (k + 1) · · · 1
0 · · ·
0
n · · · · · · · · ·
1
0 · · · 0
	⊺
Indeed, the substitution rule is compatible with the local rule of the OCA.
■
5.5
Computation Windows
Let F denote the OCA we are constructing. We use 4 P-signals of speeds 2, 3, 5
and 6 as foundations of F — they allow us to build computation windows. Let c
be the initial conﬁguration which is null everywhere except for c(0) = (1, 1, 1, 1).
We use Lemma 9 twice for each of the following lemmas, that is, we have a
characterization of the set of positions where some speciﬁc state pairs appear.
Both lemmas are illustrated in Figs. 3, 4 and 5.
Lemma 10
∀m ≤0, p ≥0,

Fp(c)m = (1, 0, , )
Fp(c)m+1 = (0, 3, , ) ⇔

∃h ∈N∗, m = −8h
p ≡−3m −1[−14m]
Lemma 11
∀m ≤0, p ≥0,

Fp(c)m = ( , , 7, 6)
Fp(c)m+1 = ( , , 5, 0) ⇔

∃h ∈N∗, m = −8h
p ≡−12m −1[−14m]
Hence we add a ﬁfth layer using alphabet {0, 1} with the rule:
δ5 ((1, 0, , , x), (0, 3, , , )) = 1 −x
δ5 (( , , 7, 6, x), ( , , 5, 0, )) = 1 −x
δ5 (( , , , , x), ( , , , , )) = x
otherwise.
Actually, the same arguments work for columns −2·8h, h ∈N∗and −4·8h, h ∈
N∗, hence we use them all. We therefore call computation windows the vertical
segments in the spacetime diagram where the ﬁfth layer contains 1:
(m, p) in a computation window ⇔∃h ∈N∗, m = −2h, p′ ≡p[14 · 2h]
and 3 · 2h ≤p′ < 12 · 2h.

242
M. Delacourt and N. Ollinger
Fig. 3. Speeds 2 and 3
P-signals determine the
positions of the lower
points of the computa-
tion windows as stated
in Lemma 10.
Fig. 4. Speeds 5 and 6
P-signals determine the
positions of the upper
points of the computa-
tion windows as stated
in Lemma 11.
Fig. 5.
In
light
gray,
speeds 2, 3, 5 and 6 P-
signals together allow to
draw the whole compu-
tation windows.
5.6
Computing Heads
Every head of the walking automaton is simulated on a new layer. It is composed
of a support that is mainly a speed 4 P-signal, and an internal state that belongs
to the set of states Σ of the walking automaton. We need 4 heads, hence there
are 4 additional layers (6 to 9).
The idea is that the heads move like speed 4 P-signal carrying internal states
until they reach a computation window (as illustrated in Fig. 6). Then, depending
on the context, they update their internal state and eventually shift upward
or downward. Each shift corresponds to a move of the head of the walking
automaton. Hence its position is encoded by the global shift applied to it, call
it the height of the head.
More formally, each layer representing a head uses the alphabet ([1..7]×Σ)∪
(0, ⊥). Outside computation windows, the ﬁrst component follows the rule of
speed 4 signals, and the second component is maintained if possible or otherwise
taken from the right neighbor.
Suppose now that we compute the new state of cell m at time p with (m, p)
inside a computation window. Denote by x, y and z the states of cells (m, p),
(m + 1, p) and (m, p + 1) in the spacetime diagram. The following rules apply to
layer 6 (the same applies for other layers):
– if y6 = (0, ⊥), then apply standard rules.

Permutive One-Way Cellular Automata and Automaton Groups
243
Fig. 6. The heads are supported by speed
4 P-signals that pass through the com-
putation windows. The windows are large
enough so that this property remains even
after they are shifted up or down.
Fig. 7.
When
the
head
arrives
in
a
computation window, it is here shifted
upward, then upward again and down-
ward in the third window. The state also
changes then (red, later blue, orange and
blue again). In light gray, another head
whose position does not change. (Color
ﬁgure online)
– if y6 ̸= (0, ⊥), look at every other layer where the support state is the same
and apply f1 and g1, the update functions of the walking automaton, with
these states. If the result of g1 is −1 (resp. 0, 1), apply the rule of a speed 3
(resp. 4, 5) signal to the ﬁrst component. If the support of z6 is not 0, then
the internal state is given by f1.
5.7
Simulation
Finally, the OCA we build has 9 layers: 4 P-signals to determine the computation
windows on the ﬁfth layer, and 4 to simulate the 4 heads of the Turing universal
walking automaton. The initial conﬁguration is the ﬁnite conﬁguration c with
c(0) = (1, 1, 1, 1, 0, (1, I), (1, I), (1, I), (1, I))
c(m) = (0, 0, 0, 0, 0, (0, ⊥), (0, ⊥), (0, ⊥), (0, ⊥))
elsewhere.
First note that the height can vary of at most 1 each time the head crosses
a column −2h, h ∈N, hence:
Lemma 12. Given any simulating head, while its height is between −h and h
in column m = −2h, h ∈N, every non (0, ⊥) value of the layer in this column is
inside a computation window.

244
M. Delacourt and N. Ollinger
This means that each head has to apply the update rule when arriving in
column −2h, h ∈N. Now check that every time it does, one step of the com-
putation of the walking automaton is simulated. The main point is to ensure
that two heads of the walking automaton are on the same cell at step h if and
only if the support of their simulating heads coincide on column 2h −1. This is
true since, for any head whose height is s, its support takes value 1 exactly in
cells (2h −1, p) with p ≡

4 · (2h −1) + s

[7 · 2h]. This property is due to the
XOR rule, with the (7, 4)-embedding. Figure 7 illustrates this behaviour with
two heads (one does not move to simplify the representation). This completes
the simulation and the proof of Theorem 1.
6
One Step Further
Orbit periodicity problem. Given a reversible OCA with a quiescent state
0 ∈X and a state x ∈X, decide if the spacetime diagram generated by the
initial conﬁguration ω0.x0ω is periodic.
Theorem 2. The orbit periodicity problem is undecidable for reversible OCA.
If the computation halts, the windows and the 4 P-signals that help determine
the computation heads keep progressing eternally. To reach periodicity, it is
necessary (and enough thanks to Lemma 7) to kill them all. It is possible to do
so by giving killing orders to the heads. At the halting step h0, each head is
given the responsibility to kill one of the P-signals while sacriﬁcing itself. They
have to slow down or speed up to meet the corresponding P-signal. Again, we
use Lemma 9 to prove that the meeting can happen on column 2h0+1 with a local
context that does not happen elsewhere.
References
1. Akhavi, A., Klimann, I., Lombardy, S., Mairesse, J., Picantin, M.: On the ﬁniteness
problem for automaton (semi) groups. Int. J. Algebra Comput. 22(06), 1250052
(2012)
2. Amoroso, S., Patt, Y.N.: Decision procedures for surjectivity and injectivity of
parallel maps for tessellation structures. J. Comput. Syst. Sci. 6(5), 448–464 (1972)
3. Bartholdi, L., Silva, P.V.: Groups deﬁned by automata. In: AutoMathA Handbook
(to appear). https://arxiv.org/abs/1012.1531
4. Boyle, M., Maass, A., et al.: Expansive invertible onesided cellular automata. J.
Math. Soc. Jpn. 52(4), 725–740 (2000)
5. Bruyere, V., Hansel, G., Michaux, C., Villemaire, R.: Logic and p-recognizable sets
of integers. Bull. Belg. Math. Soc. Simon Stevin 1(2), 191–238 (1994)
6. Coven, E., Pivato, M., Yassawi, R.: Prevalence of odometers in cellular automata.
Proc. Am. Math. Soc. 135(3), 815–821 (2007)
7. Dartnell, P., Maass, A., Schwartz, F.: Combinatorial constructions associated to
the dynamics of onesided cellular automata. Theoret. Comput. Sci. 304(1–3),
485–497 (2003)

Permutive One-Way Cellular Automata and Automaton Groups
245
8. Delorme, M., Mazoyer, J., Ollinger, N., Theyssier, G.: Bulking II: classiﬁcations of
cellular automata. Theoret. Comput. Sci. 412(30), 3881–3905 (2011)
9. Gillibert, P.: The ﬁniteness problem for automaton semigroups is undecidable. Int.
J. Algebra Comput. 24(01), 1–9 (2014)
10. Glushkov, V.M.: The abstract theory of automata. Uspekhi Matematicheskikh
Nauk 16(5), 3–62 (1961)
11. Hedlund, G.A.: Endomorphisms and automorphisms of the shift dynamical sys-
tems. Math. Syst. Theory 3(4), 320–375 (1969)
12. Kari, J., Ollinger, N.: Periodicity and immortality in reversible computing. In:
Ochma´nski, E., Tyszkiewicz, J. (eds.) MFCS 2008. LNCS, vol. 5162, pp. 419–430.
Springer, Heidelberg (2008). doi:10.1007/978-3-540-85238-4 34
13. Kari, J.: The nilpotency problem of one-dimensional cellular automata. SIAM J.
Comput. 21(3), 571–586 (1992)
14. Kari, J.: Theory of cellular automata: a survey. Theoret. Comput. Sci. 334(1),
3–33 (2005)
15. Klimann, I.: Automaton semigroups: the two-state case. Theory Comput. Syst.
58(4), 664–680 (2016)
16. ˇSuni´c, Z., Ventura, E.: The conjugacy problem in automaton groups is not solvable.
J. Algebra 364, 148–154 (2012)

Towards Computable Analysis
on the Generalised Real Line
Lorenzo Galeotti1 and Hugo Nobrega2(B)
1 Fachbereich Mathematik, Universit¨at Hamburg,
Bundesstraße 55, 20146 Hamburg, Germany
lorenzo.galeotti@gmail.com
2 Institute for Logic, Language and Computation, Universiteit van Amsterdam,
Postbus 94242, 1090 Amsterdam, GE, The Netherlands
h.nobrega@uva.nl
Abstract. In this paper we use inﬁnitary Turing machines with tapes
of length κ and which run for time κ as presented, e.g., by Koepke &
Seyﬀerth, to generalise the notion of type two computability to 2κ, where
κ is an uncountable cardinal with κ<κ = κ. Then we start the study of
the computational properties of Rκ, a real closed ﬁeld extension of R
of cardinality 2κ, deﬁned by the ﬁrst author using surreal numbers and
proposed as the candidate for generalising real analysis. In particular we
introduce representations of Rκ under which the ﬁeld operations are com-
putable. Finally we show that this framework is suitable for generalising
the classical Weihrauch hierarchy. In particular we start the study of the
computational strength of the generalised version of the Intermediate
Value Theorem.
1
Introduction
The classical approach of computability theory is to deﬁne a notion of com-
putability over ω and then extend that notion to any countable space via coding.
A similar approach is taken in computable analysis, where one usually deﬁnes
a notion of computability over Cantor space 2ω or Baire space ωω by using the
so-called type two Turing machines (T2TMs), and then extends that notion to
spaces of cardinality at most the continuum via representations. Intuitively a
T2TM is a Turing machine in which a successful computation is one that runs
forever (i.e., for ω steps). Using these machines one can compute functions over
2ω, by stipulating that a function f : 2ω →2ω is computable if there is a T2TM
which, when given p ∈dom(f) as input, writes f(p) on the output tape in the
long run. As an example, it is a classical result of computable analysis that,
given the right representation of R, the ﬁeld operations are computable. For an
introduction to computable analysis we refer the reader to [17].
Another classical application of T2TMs is the Weihrauch theory of reducibil-
ity (see, e.g., [2] for an introduction). The main aim of this theory is the study
of the computational content of theorems of real analysis. Since many of these
theorems are of the form ∀x ∈X∃y ∈Y ϕ(x, y), with ϕ(x, y) a quantiﬁer free
c
⃝Springer International Publishing AG 2017
J. Kari et al. (Eds.): CiE 2017, LNCS 10307, pp. 246–257, 2017.
DOI: 10.1007/978-3-319-58741-7 24

Towards Computable Analysis on the Generalised Real Line
247
formula, they can be thought of as their own Skolem functions. Given represen-
tations of X and Y, Weihrauch reducibility provides a tool for comparing the
computational strength of such functions, and therefore of the theorems them-
selves. Using this framework, theorems from real analysis can be arranged in a
complexity hierarchy analogous to the hierarchy of problems one has in classical
computability theory.
Recently, the study of the descriptive set theory of the generalised Baire
spaces κκ and Cantor spaces 2κ for cardinals κ > ω has been of great interest
to set theorists. In [11] the second author provided the foundational basis for
the study of generalised computable analysis, namely the generalisation of com-
putable analysis to generalised Baire and Cantor spaces. In particular, in [11] the
second author introduced Rκ, a generalised version of the real line, and proved
a version of the intermediate value theorem (IVT) for that space.
This paper is a continuation of [10,11], strengthening their results and
answering in the positive the open question from [11] of whether a natural notion
of computability exists for 2κ. We generalise the framework of type two com-
putability to uncountable cardinals κ such that κ<κ = κ. Then we use this
framework to induce a notion of computability over the generalised real line
Rκ, showing that, as in the classical case, by using suitable representations, the
ﬁeld operations are computable. Finally we will generalise Weihrauch reducibil-
ity to spaces of cardinality 2κ and extend a classical result by showing that the
generalised version of the IVT introduced in [11] is Weihrauch equivalent to a
generalised version of the boundedness principle BI.
Throughout this paper κ will be a ﬁxed uncountable cardinal, as usual
assumed to satisfy κ<κ = κ, which in particular implies that κ is a regular cardi-
nal. The generalised Baire and Cantor spaces are equipped with their bounded
topologies, i.e., the ones generated by the sets of the form {x ∈λκ ; σ ⊂x} for
σ ∈λ<κ and λ = 2 or λ = κ, respectively.
2
The Surreal Numbers
The following deﬁnition as well as most of the results in this section are due to
Conway [6] and have also been deeply studied by Gonshor in [12].
A surreal number is a function from an ordinal α to {+, −}, i.e., a sequence
of pluses and minuses of ordinal length. We denote the class of surreal numbers
by No, and the set of surreal numbers of length strictly less than α by No<α. The
length of a surreal number x, denoted ℓ(x), is its domain. For surreal numbers x
and y, we deﬁne x < y if there exists α such that x(β) = y(β) for all β < α, and
(i) x(α) = −and either α = ℓ(y) or y(α) = +, or (ii) α = ℓ(x) and y(α) = +.
In Conway’s original idea, every surreal number is generated by ﬁlling some
gap between shorter numbers. The following theorem connects this intuition to
the surreal numbers as we have deﬁned them. First, given sets of surreal numbers
X and Y , we write X < Y if for all x ∈X and y ∈Y we have x < y.
Theorem 1 (Simplicity theorem). If L and R are two sets of surreal numbers
such that L < R, then there is a unique surreal x of minimal length such that

248
L. Galeotti and H. Nobrega
L < {x} < R, denoted by [ L | R ]. Furthermore, for every x ∈No we have
x = [ L | R ] for L = {y ∈No ; x > y∧y ⊂x} and R = {y ∈No ; x < y∧y ⊂x}.
The pair ⟨L, R⟩is called the canonical cut of x.
Using the simplicity theorem Conway deﬁned the ﬁeld operations +s, ·s, −s,
and the multiplicative inverse over No and proved that these operations satisfy
the axioms of real closed ﬁelds. These operations satisfy the following, where
for any operation ∗, surreal z, and sets X, Y of surreals we use the notations
z ∗X := {z ∗x ; x ∈X} and X ∗Y := {x ∗y ; x ∈X and y ∈Y }.
Theorem 2. Let x = [ Lx | Rx ], y = [ Ly | Ry ] be surreal numbers. We have
x +s y = [ Lx +s y, x +s Ly | Rx +s y, x +s Ry ]
−s x = [ −s Rx | −s Lx ] = [ {−s xR ; xR ∈Rx} | {−s xL ; xL ∈Lx} ]
x ·s y = [Lx ·s y +s x ·s Ly −s Lx ·s Ly, Rx ·s y +s x ·s Ry −s Rx ·s Ry
| Lx ·s y +s x ·s Ry −s Lx ·s Ry, Rx ·s y +s x ·s Ly −s Rx ·s Ly]
Now let z = [ Lz | Rz ] be a positive surreal number. Let r⟨⟩:= 0 and recursively
for every z0, . . . , zn ∈(Lz ∪Rz) \ {0} let r⟨z0,...,zn⟩be the solution for x of the
equation (z −s zn) ·s r⟨z0,...,zn−1⟩+s zn ·s x = 1. Then we have
1
z = [ L′ | R′ ],
where L′ = {r⟨z0,...,zn⟩; n ∈N and zi ∈Lz for even-many i ≤n} and R′ =
{r⟨z0,...,zn⟩; n ∈N and zi ∈Lz for odd-many i ≤n}.
On ordinals, the operations +s and ·s are the so-called natural or Hessenberg
operations. In particular, for any ordinal α and natural number n, we have
α +s n = α + n.
3
The Generalised Real Line
A crucial property of the real line is its Dedekind completeness, forming the
cornerstone of many theorems in real analysis. However, it is a classical theorem
that there are no real closed proper ﬁeld extensions of R which are Dedekind
complete (see, e.g., [5, Theorem 8.7.3]). We therefore need to replace Dedekind
completeness with a weaker property. This was done in [10,11], and we repeat
the central deﬁnitions here.
Let X be an ordered set and κ be a cardinal. We say that X is an ηκ-set if
whenever L, R ⊆X are such that L < R and |L ∪R| < κ, there is x ∈X such
that L < {x} < R. Let K be an ordered ﬁeld. We call ⟨L, R⟩a cut over K if
L, R ⊆K and L < R. Moreover we say that ⟨L, R⟩is a Veronese cut if it is a cut
and L has no maximum, R has no minimum and for each ε ∈K+ there are ℓ∈L
and r ∈R such that r < ℓ+ ε. We say that K is Veronese complete if for each
Veronese cut ⟨L, R⟩there is x ∈K such that L < {x} < R. Note that Veronese
completeness is a reformulation of Cauchy completeness in terms of cuts (see,
e.g., [8,9]), so we can deﬁne the Cauchy completion of No<κ as follows.
Deﬁnition 3. Rκ = No<κ ∪{[ L | R ] ; ⟨L, R⟩is a Veronese cut over No<κ}.

Towards Computable Analysis on the Generalised Real Line
249
Theorem 4 (Galeotti [11]). The ﬁeld Rκ is the unique Cauchy-complete real
closed ﬁeld extension of R which is an ηκ-set of cardinality 2κ, degree κ, and in
which No<κ can be densely embedded.
In view of the previous theorem from now on we will call No<κ the κ-rational
numbers and we use the symbol Qκ instead of No<κ.
The ﬁeld Rκ is a suitable setting for generalising results from classical analy-
sis. For example, a generalised version of the intermediate value theorem [11], a
generalised version of the extreme value theorem [10], and recently a generalised
version of the Bolzano-Weierstraß theorem (for κ weakly compact) [4] have been
proved to hold for Rκ. In this section we brieﬂy recall some of the deﬁnitions
from [11] which will be needed in the last part of this paper.
A κ-topology over a set X is a collection of subsets τ of X satisfying: ∅, X ∈τ;
for any α < κ, if {Ai}i∈α is a collection of sets in τ then 
i<α Ai ∈τ; and for all
A, B ∈τ, we have A ∩B ∈τ. With κ-topologies one can deﬁne direct analogues
of many topological notions. We refer to these with the preﬁx “κ-”; thus we
have κ-open sets, κ-continuous functions, κ-topologies generated by families of
subsets of a set, etc. Note that, unlike the classical case of the interval topology
over R, the interval κ-topologies over Rκ in which the intervals have endpoints in
Rκ ∪{−∞, +∞} or in Qκ ∪{−∞, +∞} are diﬀerent in general. In what follows
we will only consider the generalised real line Rκ equipped with the former.
Theorem 5 (IVTκ [11]). Let a, b ∈Rκ and f : [0, 1] →Rκ be a κ-continuous
function. Then for every r ∈[f(0), f(1)] there exists c ∈[0, 1] such that f(c) = r.
4
Generalised Type Two Turing Machines
In this section we deﬁne a generalised version of type two Turing machines
(T2TMs). We will only sketch the deﬁnition of κ-Turing machines, which were
developed by several people (e.g., [7,14,16]); we are going to follow the deﬁnition
of Koepke and Seyﬀerth [14, Sect. 2].
A κ-Turing machine has the following tapes of length κ: ﬁnitely many read-
only tapes for the input, ﬁnitely many read and write scratch tapes and one
write-only tape for the output. Each cell of each tape has either 0 or 1 written in
it at any given time, with the default value being 0. These machines can run for
inﬁnite time of ordinal type κ; at successor stages of a computation a κ-Turing
machine behaves exactly like a classical Turing Machine, while at limit stages
the contents of each cell of each tape and the positions of the heads is computed
using inferior limits.
As in the classical case κ = ω, the diﬀerence between κ-Turing machines
and type 2 κ-Turing machines is not on the machinery level, but rather on the
notion of what it means for a machine to compute a function. A partial function
f : 2<κ →2<κ is computed by a κ-Turing machine M if whenever M is given
x ∈dom(f) as input, its computation halts after fewer than κ steps with f(x)
written on the output tape. A partial function f : 2κ →2κ is type two-computed
by a κ-Turing machine M, or computed by the type 2 κ-Turing machine M, or

250
L. Galeotti and H. Nobrega
simply computed by M, if whenever M is given x ∈dom(f) as input, for every
α < κ there exists a stage β < κ of the computation at which f(x) ↾α is written
on the output tape. We abbreviate type 2 κ-Turing machine by T2κTM. An
oracle T2κTM is a T2κTM with an additional read-only input tape of length κ,
called its oracle tape. A partial function f : 2κ →2κ is computable with an oracle
if there exists an oracle T2κTM M and x ∈2κ such that M computes f when
x is written on the oracle tape. Note that by minor modiﬁcations of classical
proofs one can prove that T2κTMs are closed under recursion and composition,
and that there is a universal T2κTM. In what follows, the term computable will
mean computable by a T2κTM, unless speciﬁed otherwise.
Theorem 6. A partial function f : 2κ →2κ is continuous iﬀit is computable
with some oracle.
5
Represented Spaces
In this section we generalise the classical deﬁnitions of the theory of represented
spaces to 2κ (see, e.g., [15,17] for the classical case).
A represented space X is a pair (X, δX) where X is a set and δX : 2κ →X is a
partial surjective function. As usual a multi-valued function between represented
spaces is a multi-valued function between the underlying sets. Let f : X ⇒Y be
a partial multi-valued function between represented spaces. We call F : 2κ →2κ
a realizer of f, in symbols F ⊢f, if for every x ∈dom(δX) we have that
δY (F(x)) ∈f(δX(x)). Given a class Γ of functions between 2κ and 2κ, we say f
is (δX, δY )-Γ, or δX-Γ in case δX = δY , if f has a realizer in Γ. For example, a
function f : X →Y is (δX, δY )-computable if it has a computable realizer.
Let f and g be two multi-valued functions between represented spaces. Then
we say that f is strongly topologically-Weihrauch reducible to g, in symbols f ≤t
W
g, if there are two continuous functions H, K : 2κ →2κ such that H ◦G ◦K ⊢f
whenever G ⊢g. If the functions H, K above can be taken to be computable,
then we say f is strongly Weihrauch reducible to g, in symbols f ≤W g.1 As usual,
if f ≤t
W g and g ≤t
W f then we say that f is strongly topologically-Weihrauch
equivalent to g and write f ≡t
W g. The relation ≡W is deﬁned analogously.
Let δ : 2κ →X and δ′ : 2κ →X be two representations of a space X.
Then we say that δ continuously reduces to δ′, in symbols δ ≤t δ′, if there is
a continuous function h : 2κ →2κ such that for every p ∈dom(δ) we have
δ(p) = δ′(h(p)). Similarly we say that δ computably reduces to δ′, in symbols
δ ≤δ′, if h above can be taken computable. If δ ≤t δ′ and δ′ ≤t δ we say that
δ and δ′ are continuously equivalent and write δ ≡t δ′, and similarly for the
computable case. Note that as in classical computable analysis if δ ≤δ′ and f
1 Carl has also introduced a notion of generalized (strong) Weihrauch reducibility
in [3]. Because his goal is to investigate multi-valued (class) functions on V , the
space of codes he uses is the class of ordinal numbers, considered with the ordinal
Turing machines of Koepke [13]. Therefore his approach is signiﬁcantly diﬀerent from
ours, and we do not know of any connections between the two.

Towards Computable Analysis on the Generalised Real Line
251
is δ-computable then f is also δ′-computable. Finally, as in the classical case,
given two represented spaces X and Y, we can deﬁne canonical representations
for the product space X×Y, the union space X+Y and the space of continuous
functions [X →Y]. In particular, as in classical computable analysis [X →Y]
can be represented as follows: δ[X→Y ](p) = f iﬀp = 0n1p′ with p′ ∈2κ and
n ∈N is a code for an oracle T2κTM which (δX, δY )-computes f when given
the oracle p′.
Recall that the following relation is a well-ordering of the class of pairs of
ordinal numbers: ⟨α0, β0⟩≺⟨α1, β1⟩iﬀ⟨max(α0, β0), α0, β0⟩is lexicographically-
less than ⟨max(α1, β1), α1, β1⟩. The G¨odel pairing function is given by g(α, β) =
γ iﬀ⟨α, β⟩is the γth element in ≺. Given sequences ⟨wα⟩α<κ and ⟨pα⟩α<β of
elements in 2<κ and 2κ, respectively, we deﬁne elements q := [wα]α<κ and p :=
(pα)α<κ in 2κ by letting q be the concatenation of the wα and p(g(α, β)) = pα(β).
We ﬁx the following representations of κ and κκ: δκ(p) = α iﬀp = 0α10,
where 0 is the constant 0 κ-sequence, δκκ(p) = x iﬀp = [0αβ+11]β<κ and x =
⟨αβ⟩β<κ. It is straightforward to see that a function f : κ →κ is δκ-computable
iﬀit is computable by a κ-machine as in [14, Deﬁnition 2].
Lemma 7. The restriction of g to κ × κ is a δκ-computable bijection between
κ × κ and κ, and has a δκ-computable inverse.
Proposition 8. δκκ is ≤-maximal among the continuous representations of κκ.
6
Representing Rκ
In classical computable analysis one can show that many of the natural repre-
sentations of R are well behaved with respect to type two computability. In this
section we show that some of these results naturally extend to the uncountable
case. First we introduce representations for generalised rational numbers, which
will serve as a starting point to representing Rκ. As we have seen in the intro-
duction, surreal numbers can be expressed as binary sequences and, because of
the simplicity theorem, as cuts. It is then natural to introduce two represen-
tations which reﬂect this fact. Let p ∈2κ and q ∈Qκ. We deﬁne δQκ(p) = q
iﬀp = [wα]α<κ where wα := 00 if α ∈dom(q) and q(α) = −, wα := 01 if
α /∈dom(q), and ﬁnally wα := 11 if α ∈dom(q) and q(α) = +. It is not hard to
see that since every rational is a sequence of + and −of length less than κ the
function δQκ is indeed a representation of Qκ. Now we deﬁne a representation
based on cuts by recursion on the simplicity structure of the surreal numbers.
We deﬁne δ0
CutQκ(p) = 0 iﬀp = (pα)α<κ and pα = [10]β<κ for every α < κ. For
α > 0 we deﬁne δα
CutQκ(p) = [ L | R ] where p = (pα)α<κ and:
1. pα ∈dom(
γ<α δγ
Qκ) ∪{[10]β<κ} for every α < κ,
2. for all even2 α < κ, if pα = [10]β<κ then for all even β > α we have pβ =
[10]β<κ,
2 We call an ordinal α even if α = λ+2n for some limit λ and natural n, odd otherwise.

252
L. Galeotti and H. Nobrega
3. for all odd α < κ, if pα = [10]β<κ then for all odd β > α we have pβ = [10]β<κ,
4. ﬁnally: L = {δγ
CutQκ(pβ) ;
γ < α, β < κ is even and pβ ∈dom(δγ
CutQκ)} and
R = {δγ
CutQκ(pβ) ; γ < α, β < κ is odd and pβ ∈dom(δγ
CutQκ )}.
Then we deﬁne δCutQκ := 
γ<κ δγ
CutQκ.
Note that δCutQκ is surjective, since for every x ∈Qκ there exists p ∈
dom(δCutQκ) such that δCutQκ (p) is the canonical cut for x. Therefore δCutQκ
is indeed a representation of Qκ.
Lemma 9. δQκ ≡δCutQκ.
Proof. First we show that δQκ ≤δCutQκ. Let p ∈dom(δQκ). The conversion can
be done recursively. If p is a code for the empty sequence3 we just return a repre-
sentation for [ ∅| ∅]. Otherwise we compute two subsets Ls := {p′01 ; p′11 ⊂p}
and Rs := {p′01 ; p′00 ⊂p}. Then we compute recursively the cuts for the
elements of Ls and Rs and return them respectively as the left and right sets of
the cut representation of p. It easy to see that the algorithm computes a code
for the canonical cut of δQκ(p).
Now we will show that δCutQκ ≤δQκ. Let p ∈dom(δCutQκ ). If p is a code
for the cut [ ∅| ∅] we return a representation of the empty sequence. If p is the
code for the cut [ L | R ] ̸= [ ∅| ∅]. We ﬁrst recursively compute the sequences
for the element of L and R, call the sets of these sequences Ls and Rs. Now
suppose α < κ is even and we want to compute the value at α and α + 1 of
the output sequence. We ﬁrst compute ML and mR respectively the minimal
and maximal in {00, 01, 11} such that for every p′ ∈Ls and p′′ ∈Rs we have
p′(α)p′(α + 1) ≤ML and mR ≤p′′(α)p′′(α + 1). Then by a case distinction on
ML and mR we can decide the ith sign of the output. For example if the output
is already smaller than Rs, ML = 00 (i.e. −) and mR = 00 (i.e. −) then we
can output the sequence 01 (i.e. undeﬁned). All the other combinations can be
treated similarly.
Lemma 10. The operations +s, −s, ·s,
1
x
and the order < are δCutQκ-
computable.
Proof. We will only prove the lemma for +s. Given q, q′ ∈Qκ we want to δCutQκ-
compute q +s q′. The algorithm is given by recursion. If q = 0 (similarly for
q′ = 0)4 copy the code of q′ on the output tape. If neither q nor q′ are 0 then by
using Theorem 2 we compute a representation for q +s q′ (note that this involves
the computation of less than κ many rational sums of shorter length). Finally,
since the resulting code would not in general be in dom(δCutQκ), we use the
algorithms of the previous lemma to convert q +s q′ to a sign sequence code
and than we convert it back to an element in dom(δCutQκ). By using the second
3 Note that this can be checked just by looking at the ﬁrst two bits of p.
4 Note that this is easily computable, it is in fact enough to check that L and R are
empty, and this can be done just by checking the ﬁrst two bits of the ﬁrst sequence
in the left and in the ﬁrst sequence on the right.

Towards Computable Analysis on the Generalised Real Line
253
algorithm from the previous proof we can convert every element in Lq+sq′ and
in Rq+sq′ into a sequence (note that by induction the codes of these cuts are in
dom(δCutQκ) so we can use the algorithm). Then by the same method used in
the previous lemma, we can compute the code of the sequence representation for
q +s q′. Once we have the code of the sequence representation for q +s q′ we can
convert it to a code of the cut representation by using the ﬁrst algorithm from
the previous lemma.
Given that Rκ is the Cauchy completion of Qκ, the following is a natural
representation of Rκ. We let δRκ(p) = x iﬀp = (pα)α<κ, where for each α < κ
we have pα ∈dom(δQκ), δQκ(pα) < x +s
1
α+1, and x < δQκ(pα) +s
1
α+1. It is
routine to check the following.
Theorem 11. The ﬁeld operations +s, −s, ·s, and 1
x are δRκ-computable.
Proof. Let us do the proof for ·s, the others being similar. Given codes p =
(pα)α<κ and q = (qα)α<κ for x, y ∈Rκ respectively, let xα = δQκ(pα) and
yα = δQκ(qα). Note that for each α we can compute some α′ such that
1
α′+1(x0+s
y0 +s 3) ≤
1
α+1. We then output r = (rα)α<κ, where rα is a δQκ-name for xα′yα′.
We have xy −s xα′yα′ = x(y −s yα′)+s yα′(x−s xα′) < (x0 +s 1)
1
α′+1 +s (y0 +s
2)
1
α′+1 ≤
1
α+1, as desired, and likewise we can prove xα′yα′ −s xy <
1
α+1.
On the other hand, the following is suggested by the deﬁnition of Rκ as the
collection of Veronese cuts over Qκ. We let δV
Rκ(p) = x iﬀp = (pα)α<κ, where for
each α < κ we have pα ∈dom(δQκ) and x = [ L | R ], with L = {δQκ(pα) ; α <
κ is even}; R = {δQκ(pα) ; α < κ is odd}; and for each even α < κ we have
δQκ(pα+1) < δQκ(pα) +s
1
α+1.
Theorem 12. δRκ ≡δV
Rκ.
Proof. To reduce δV
Rκ to δRκ, given p = (pα)α<κ, we output q = (qα)α<κ by
making qα equal to pβ, where β is the αth even ordinal. It is now easy to see
that q is a δRκ-name for δV
Rκ(p).
For the converse reduction, given p = (pα)α<κ, we output q = (qα)α<κ where
for each even α we let qα be a δQκ-name for δQκ(p2·sα+2)−s
1
2·sα+3 and qα+1 be a
δQκ-name for δQκ(p2·sα+2)+s
1
2·sα+3. Then letting L := {δQκ(pα) ; α < κ is even}
and R := {δQκ(pα) ; α < κ is odd} we have L < {x} < R and for each even
α < κ we have δQκ(qα+1) = δQκ(p2·sα+2) +s
1
2·sα+3 = δQκ(qα) +s
2
2·sα+3 <
δQκ(qα) +s
1
α+1, as desired.
7
Generalised Boundedness Principles and the IVT
As shown in, e.g., [1,2], the so-called boundedness principles and choice principles
are important building blocks in characterizing the Weihrauch degrees of interest
in computable analysis. In this section we focus on the study of IVT and its
relationship with the boundedness principle BI. In particular we generalise a

254
L. Galeotti and H. Nobrega
classical result from Brattka and Gherardi [2], proving that IVTκ is Weihrauch
equivalent to a generalised version of BI. This strengthens a result from [11],
namely that BI is continuously reducible to IVTκ.
The theorem IVTκ as stated in Theorem 5 can be considered as the partial
multi-valued function IVTκ : C[0,1] ⇒[0, 1] deﬁned as follows: IVTκ(f) = {c ∈
[0, 1] ; f(c) = 0}, where [0, 1] is represented by δRκ↾[0, 1] and C[0,1] is endowed
with the standard representation of [[0, 1] →Rκ] restricted to C[0,1]. By lift-
ing the classical proof to κ it is easy to show that this version of IVTκ is not
continuous, and thus also not computable, relative to these representations.
To introduce the boundedness principle Bκ
I , we will need the following rep-
resented spaces. Let S↑
b be the space of bounded increasing sequences of κ-
rationals, represented by letting p be a name for ⟨xα⟩α<κ iﬀp = (pα)α<κ where
pα ∈domQκ and δQκ(pα) = xα for each α < κ. The represented space S↓
b
is deﬁned analogously, with bounded decreasing sequences of κ-rationals. Note
that, unlike the classical case of the real line, not all limits of bounded monotone
sequences of length κ exist in Rκ. Therefore, although for the real line the
spaces S↑
b and S↓
b naturally correspond to the spaces of lower reals R< and
upper reals R>, respectively, in our generalised setting the correspondence fails.
We deﬁne Bκ
I as the principle which, given an increasing sequence ⟨qα⟩α<κ and
decreasing sequence ⟨q′
α⟩α<κ in Qκ for which there exists x ∈Rκ such that
{qα ; α < κ} ≤{x} ≤{q′
α ; α < κ}, picks one such x. Formally we have
the partial multi-valued function Bκ
I : S↑
b × S↓
b ⇒Rκ with x ∈Bκ
I (s, s′) iﬀ
{s(α) ; α < κ} ≤{x} ≤{s′(α) ; α < κ}.
Lemma 13. Let f : [0, 1] →Rκ and x ∈Rκ. Suppose there exists a sequence
⟨xα⟩α<κ of pairwise distinct elements of [0, 1] such that f(xα) = x if α < κ is
even and f(xα) ̸= x otherwise, and such that for any odd α, β < κ there exists
an even γ < κ such that xγ is between xα and xβ. Then f is not κ-continuous.
Proof. If such a sequence exists, then either the preimage of the κ-open set
(x, +∞) or of the κ-open set (−∞, x) under f must contain xα for κ-many of
the odd α < κ, and thus cannot be κ-open.
Lemma 14. Let f : [0, 1] →Rκ be κ-continuous an let β, β′ < κ, y ∈Rκ and
let ⟨rα⟩α<β and ⟨r′
α⟩α<β′ be two sequences in [0, 1] such that {rα ; α < β} <
{r′
α ; α < β′} and {f(rα) ; α < β} < {y} < {f(r′
α) ; α < β′}. Then there is
x ∈[0, 1] such that {rα ; α < β} < {x} < {r′
α ; α < β′} and f(x) = y.
Proof. Assume not. Without loss of generality we can assume that for every x
such that {rα ; α < β} < {x} < {r′
α ; α < β′} we have f(x) > y (a similar
proof works for f(x) < y). Note that the set {rα ; α < β} has coﬁnality at most
β < κ and, since Rκ is an ηκ-set, it follows that R = {r ∈[0, 1] ; ∀α < β. rα < r}
has coinitiality κ. Therefore R is not κ-open. Now since f is κ-continuous we
have that f −1[(y, +∞)] is κ-open. Therefore f −1[(y, +∞)] = 
α∈γ(yα, bα) with
γ < κ and yα, bα ∈[0, 1] for every α < γ. Now consider the set I := {α ∈
γ ; (yα, bα) ∩R ̸= ∅}. We have that R ⊂
α∈I(yα, bα). Note that since R is
not κ-open we have R ̸= 
α∈I(yα, bα). Now assume r ∈
α∈I(yα, bα) \ R, so

Towards Computable Analysis on the Generalised Real Line
255
that there is α ∈I such that r ∈(yα, bα). Take r′ ∈(yα, bα) ∩R. By the fact
that r /∈R, there is α′ < β such that r < rα′ and by IVTκ there is a root of f
between rα′ and r′, but this is a contradiction because (yα, bα) ⊂f −1[(y, +∞)].
Corollary 15. Let f : [0, 1] →Rκ be κ-continuous, and let x ∈[0, 1], ⟨rα⟩α<κ
and ⟨r′
α⟩α<κ be respectively increasing and decreasing sequences in [0, 1] such
that for all α < κ we have f(rα) < x and f(r′
α) > x. Then there exists y ∈[0, 1]
such that f(y) = x and {rα ; α < κ} < {y} < {r′
α ; α < κ}.
Proof. Construct a sequence ⟨xα⟩α<γ for some γ ≤κ as follows. First let δ0 = 1.
Having constructed ⟨xβ⟩β<α for some even α < κ, by Lemma 14 there exists
xα ∈[0, 1] such that f(xα) = x and {rβ ; β < supν<α δν} < {xα} < {r′
β ; β <
supν<α δν}. If {rβ ; β < κ} < {xα} < {r′
β ; β < κ}, then we are done and γ = α.
Otherwise there exists β < κ such that rβ > x or r′
β < x, so we let xα+1 = rβ
or xα+1 = r′
β accordingly, and let δα = β + 1. If the construction goes on for κ
steps, then ⟨xα⟩α<κ is as in Lemma 13, a contradiction. Hence the construction
ends at some stage γ < κ, and therefore {rβ ; β < κ} < {xγ} < {r′
β ; β < κ}.
Theorem 16. 1. If there exists an eﬀective enumeration of a dense subset of
Rκ, then IVTκ ≤W Bκ
I .
2. We have Bκ
I ≤W IVTκ.
3. We have IVTκ ≤t
W Bκ
I , and therefore IVTκ ≡t
W Bκ
I .
Proof. For item 1, let the κ-continuous function f : [0, 1] →Rκ be given, D be a
dense subset of Rκ and ⟨dγ⟩γ<κ be an eﬀective enumeration of [0, 1]∩D. Without
loss of generality we can assume f(0) < 0 and f(1) > 0, and start setting r0 = 0
and r′
0 = 1. Now assume that for 0 < α < κ we have already deﬁned an increasing
sequence ⟨rβ⟩β<α and a decreasing sequence ⟨r′
β⟩β<α of elements of [0, 1]∩D with
{rβ ; β < α} < {r′
β ; β < α} and {f(rβ) ; β < α} < {0} < {f(r′
β) ; β < α}.
By Lemma 14 there is still a root of f between the two sequences. Note that,
since Rκ is an ηκ-set and again by applying Lemma 14, there exist rL, rR ∈D
such that {rβ ; β < α} < {rL} < {rR} < {r′
β ; β < α} and f(rL) < 0,
f(rR) > 0. Therefore, by searching in the sequence ⟨dγ⟩γ<κ and running the
corresponding algorithms in parallel, we can ﬁnd such a pair rL, rR in fewer
than κ computation steps. Let β, γ, δ be such that g(β, g(γ, δ)) = α, where g
is the G¨odel pairing function, which has a computable inverse by Lemma 7. If
rL < dγ < dδ < rR, f(dγ) < 0, and f(dδ) > 0, where the last two comparisons
are decided in fewer than β steps of computation, then let rα = dγ and r′
α = dδ;
otherwise let rα = rL and r′
α = rR.
By Corollary 15 we have that there exists x ∈[0, 1] such that {rα ; α < κ} <
{x} < {r′
α ; α < κ}. It remains to be proved that f(x) = 0 for any such x.
Suppose not, say f(x) > 0 for some such x. Then also f(y) > 0 for some y ∈D
such that {rα ; α < κ} < {y} < {r′
α ; α < κ}. Now let β, γ, δ < κ be such
that dγ = y, dδ = rν for some ν such that {y −s rν} < {r′
α −s rβ ; α, β < κ}
and f(y) < 0, f(rν) > 0 are decided in fewer than β computation steps. Then
at stage α = g(β, g(γ, δ)) of the computation we deﬁne a pair rα, r′
α such that
r′
α −s rα ≤y −s rν, a contradiction. This ends the proof of 1.

256
L. Galeotti and H. Nobrega
Item 2 can be proved by a straightforward generalisation of the proof of [2,
Theorem 6.2], and the proof of item 3 is the same as that of item 1 without the
requirement that the enumeration ⟨dγ⟩γ<κ of the dense subset of [0, 1] ∩D be
eﬀective.
Note that the antecedent of item 1 of Theorem 16 is satisﬁed, e.g., in the
constructible universe L. We leave for future work the task of investigating the
set-theoretic properties of that condition more deeply.
Acknowledgments. This research was partially done whilst the authors were visiting
fellows at the Isaac Newton Institute for Mathematical Sciences in the programme
Mathematical, Foundational and Computational Aspects of the Higher Inﬁnite. The
research beneﬁted from the Royal Society International Exchange Grant Inﬁnite games
in logic and Weihrauch degrees. The second author was also supported by the Capes
Science Without Borders grant number 9625/13-5. The authors are grateful to Benedikt
L¨owe and Arno Pauly for the many fruitful discussions and to the Institute for Logic,
Language and Computation for the hospitality oﬀered to the ﬁrst author. Finally, the
authors wish to thank the three anonymous referees for the helpful comments which
have improved the paper.
References
1. Brattka, V., de Brecht, M., Pauly, A.: Closed choice and a uniform low basis
theorem. Ann. Pure Appl. Log. 163(8), 986–1008 (2012)
2. Brattka, V., Gherardi, G.: Eﬀective choice and boundedness principles in com-
putable analysis. Bull. Symb. Log. 17(1), 73–117 (2011)
3. Carl, M.: Generalized eﬀective reducibility. In: Beckmann, A., Bienvenu, L.,
Jonoska, N. (eds.) CiE 2016. LNCS, vol. 9709, pp. 225–233. Springer, Cham (2016).
doi:10.1007/978-3-319-40189-8 23
4. Carl, M., Galeotti, L., L¨owe, B.: The Bolzano-Weierstraß theorem for the gener-
alised real line. In preparation
5. Cohn, P.M.: Basic Algebra. Groups, Rings and Fields. Springer, Heidelberg (2003)
6. Conway, J.H.: On Numbers and Games. Taylor & Francis, New York (2000)
7. Dawson, B.: Ordinal time Turing computation. Ph.D. thesis, University of Bristol
(2009)
8. Dales, H.G., Woodin, W.H.: Super-Real Fields: Totally Ordered Fields with Addi-
tional Structure. Clarendon Press, Oxford (1996)
9. Ehrlich, P.: Dedekind cuts of Archimedean complete ordered abelian groups. Alge-
bra Univers. 37(2), 223–234 (1997)
10. Galeotti, L.: Computable analysis over the generalized Baire space. Master’s thesis,
Universiteit van Amsterdam (2015)
11. Galeotti, L.: A candidate for the generalised real line. In: Beckmann, A., Bienvenu,
L., Jonoska, N. (eds.) CiE 2016. LNCS, vol. 9709, pp. 271–281. Springer, Cham
(2016). doi:10.1007/978-3-319-40189-8 28
12. Gonshor, H.: An Introduction to the Theory of Surreal Numbers. Cambridge Uni-
versity Press, Cambridge (1986)
13. Koepke, P.: Turing computations on ordinals. Bull. Symb. Logic 11(3), 377–397
(2005)

Towards Computable Analysis on the Generalised Real Line
257
14. Koepke, P., Seyﬀerth, B.: Ordinal machines and admissible recursion theory. Ann.
Pure Appl. Log. 160(3), 310–318 (2009)
15. Pauly, A.: On the topological aspects of the theory of represented spaces. Preprint,
(2015). arXiv:1204.3763v3
16. Rin, B.: The computational strengths of α-tape inﬁnite time Turing machines.
Ann. Pure Appl. Log. 165(9), 1501–1511 (2014)
17. Weihrauch, K.: Computable Analysis: An Introduction. Springer, Heidelberg
(2012)

Finite Language Forbidding-Enforcing Systems
Daniela Genova1(B) and Hendrik Jan Hoogeboom2
1 Department of Mathematics and Statistics, University of North Florida,
Jacksonville, FL 32224, USA
d.genova@unf.edu
2 LIACS, Leiden University, Leiden, The Netherlands
h.j.hoogeboom@liacs.leidenuniv.nl
Abstract. The forbidding and enforcing paradigm was introduced by
Ehrenfeucht and Rozenberg as a way to deﬁne families of languages based
on two sets of boundary conditions. Later, a variant of this paradigm was
considered where an fe-system deﬁnes a single language. We investigate
this variant further by studying fe-systems in which both the forbidding
and enforcing sets are ﬁnite and show that they deﬁne regular languages.
We prove that the class of languages deﬁned by ﬁnite fe-systems is strictly
between the strictly locally testable languages and the class of locally
testable languages.
Keywords: Fe-systems · Fe-languages · Regular languages · (Strictly)
locally testable · Natural computing · Biomolecular computing
1
Introduction
Many novel models of computation have been proposed in the ﬁeld of nat-
ural computing, such as, splicing, membrane, and reaction systems [7,14,15,17].
These models were inspired by the information-processing capabilities of mole-
cular interactions, the functioning of the living cell, cell-to-cell communication,
etc. The forbidding-enforcing paradigm, proposed by Ehrenfeucht and Rozen-
berg [4–6] was motivated by the non-determinism of molecular reactions. There,
forbidding-enforcing systems (fe-systems) were used to deﬁne classes of lan-
guages, fe-families, based on two sets of constraints. The idea behind using
constraints rather than rules to deﬁne classes of languages was that “every-
thing that is not forbidden is allowed”, which is orthogonal to the determinism
of grammars and automata where “everything that is not allowed is forbidden”.
Variants of fe-systems have been considered in the study of membrane sys-
tems [2] and to describe self-assembly of graphs [8]. They, also, have been for-
mulated to deﬁne classes of graphs [13] and abstracted to categories in [12].
In [9], a variant of fe-systems was introduced, in which one fe-system deﬁnes a
single language (fe-language) and in [11] it was shown how fe-languages charac-
terize DNA codes (conditions on words abstracted from unwanted hybridization
of DNA strands). Normal forms for forbidding sets of language fe-systems were
studied in [10].
c
⃝Springer International Publishing AG 2017
J. Kari et al. (Eds.): CiE 2017, LNCS 10307, pp. 258–269, 2017.
DOI: 10.1007/978-3-319-58741-7 25

Finite Language FE-Systems
259
Forbidding sets of words as subwords has been previously discussed in the
literature, although, before forbidding-enforcing systems, the discussions have
always been in the sense of “strict” forbidding. For example, local languages are
languages, for which subwords from a given ﬁnite set of words are strictly for-
bidden. In [3], the authors deﬁne the notion of subword avoidable (resp. subword
unavoidable) sets. A set of words is subword avoidable if there is an inﬁnite lan-
guage which does not have subwords from that set. Otherwise, a set of words is
subword unavoidable. The authors use subword unavoidable sets to characterize
regular languages. The model from [9] that we consider uses forbidding sets that
generalize the notion of sets of strictly forbidden words in the sense that if the
forbidders are ﬁnitely many and singletons, then the languages coincide with
local languages. If the forbidders are singletons but not necessarily ﬁnite, they
are still forbidding subwords in the strict sense and coincide with avoidable sets.
But in general, forbidders may be non-singletons and then they forbid the entire
combinations of subwords, while still allowing parts of them as subwords.
The enforcing constraint was originally motivated by the evolution of molec-
ular reactions, where if some molecules are present in a molecular system, then
this triggers the presence of other molecules, as well [6]. The enforcing set from
the model deﬁned in [9] requires that if certain subwords appear in a word,
they are enclosed in larger subwords from pre-speciﬁed ﬁnite sets. Since DNA
molecules can be modeled by strings, this enforcing condition was motivated by
imposing restrictions on strands of nucleotides to deﬁne, for example, restric-
tions imposed by DNA codewords [11] and capture the idea of linear splicing, as
deﬁned by Head [14] and constants [1].
This paper investigates fe-languages deﬁned by ﬁnite fe-systems. After the
deﬁnitions recalled in Sect. 2, we prove that such languages, as a class, are regular
(Sect. 3) and stand strictly between the strictly locally testable and the locally
testable languages (Theorem 9). Results showing that (separately and together)
ﬁnite forbidding sets and ﬁnite enforcing sets deﬁne locally testable languages
are included in Sect. 3 and reinforced in Sect. 4 using the Subword automata.
Automata are a natural tool for studying locally testable languages because their
ﬁnite state memory makes it easy to implement a sliding window that moves
over the string to inspects the consecutive substrings of the input string. For the
(strictly) locally testable languages membership is determined by the collection
of substrings of the string. Finally, Sect. 5 investigates how the classes of strictly
locally testable languages and the languages deﬁned by ﬁnite fe-systems are
related.
2
Forbidding-Enforcing Systems
We use standard formal language concepts and ﬁx our notation here. The length
of a word w is denoted by |w|. The empty word is denoted by λ, it has length 0.
The set of all nonempty words over the alphabet A is denoted by A+, the set of
all words is A∗, and Am is the set of all words of length m.
The word y is a subword of x ∈A∗, if there exist s, t ∈A∗, such that x = syt.
The set of subwords of a word x is denoted by sub(x) and sub(L) = 
x∈L sub(x)

260
D. Genova and H.J. Hoogeboom
is the set of subwords of a language L. Moreover, y is a preﬁx of x if x = yt, and
a suﬃx of x if x = sy. We denote by pref(x) and suﬀ(x) the sets of all preﬁxes
and suﬃxes of x. These notations are extended to languages.
Forbidding Systems, f -languages. As originally deﬁned [4–6], a forbidding-
enforcing system (fe-system) was used to deﬁne a family of languages, where the
conditions imposed by the system were required to hold for every language in
the family. Here, we consider the fe-systems model, introduced in [9], in which a
fe-system deﬁnes a single language. This means that the forbidding mechanism
is applied to every single word in that language, rather than to a language in
the family.
A forbidding set F is a family of ﬁnite nonempty subsets of A+, each element
of which is called a forbidder.
A word w is consistent with a forbidder F, if F ̸⊆sub(w). A word w is
consistent with a forbidding set F if w is consistent with all F ∈F. The set of all
words consistent with F deﬁnes the language L(F), which is called a forbidding
language or an f-language.
Note that L(F) = A∗if and only if F = ∅and that λ ∈L(F) for every F.
Example 1. Let F = {{aa, bb}, {ab, ba}}. A word w is consistent with the ﬁrst
forbidder {aa, bb} if and only if w does not contain both aa and bb as subwords.
Thus, words like ababa, baabaab, and abbbb are consistent with the ﬁrst forbidder
and words like aabb and bbaabbaa are not consistent with it. Similarly, the second
forbidder {ab, ba} disallows both ab and ba to be in the subwords of w, but either
one of them is allowed by itself. Thus, words like aaa, aabb, and bbbaa are allowed,
but aababa and bbab are forbidden by the second forbidder. The language deﬁned
by the entire forbidding set is the intersection of the sets of words consistent with
each forbidder. Thus, L(F) = {an, bn, abn, anb, ban, bna | n ≥0}.
Example 2. Let A = {a, b} and F = {{bakb} | k even}. Then, L(F) contains
words where any two b’s are separated by an odd number of a’s.
Enforcing Systems, e-languages. An enforcer is a pair (x, Y ) such that x ∈
A∗and Y is a ﬁnite nonempty subset of A+, where x is a proper subword of each
y ∈Y . The semantics of enforcers diﬀers depending on whether x is the empty
string or not. In the case that x ∈A+, a word w satisﬁes an enforcer (x, Y ),
if every occurrence of x in w is embedded in some word from Y . Formally, if
w = uxv for some u, v ∈A∗then there exists y ∈Y and u1, u2, v1, v2 ∈A∗such
that u = u1u2, v = v2v1, and y = u2xv2. If x ̸∈sub(w) then w satisﬁes the
enforcer (x, Y ) trivially. When x = λ, the enforcer (λ, Y ) is called brute. In this
case, a word w satisﬁes the enforcer if there exists a word y ∈Y such that y is
a subword of w.
An enforcing set E is a family of enforcers. A word w satisﬁes E if and only
if w satisﬁes every enforcer in that set. The language of all words that satisfy
E is denoted by L(E). Such a language is called an enforcing language or an
e-language.
Clearly, if y ∈Y then y satisﬁes (x, Y ) and x does not. Also, L(E) = A∗if
and only if E = ∅.

Finite Language FE-Systems
261
In part, this research is motivated by the fact that inﬁnite sets of enforcers
form a powerful tool. The next example from [9] shows how a context-sensitive
languages can be deﬁned. Basically, ‘unwanted’ strings are forced to be prolonged
indeﬁnitely. So, one might say that enforcers are, in a way, used as forbidders
here.
Example 3. Let A = {a} and L = {a2n | n ≥0}. Then, the enforcing set
E = {(λ, {a, aa})} ∪{(a2i+1, {a2i+1}) | i ≥1} deﬁnes L, i.e., L = L(E).
Forbidding-Enforcing Systems, fe-languages. Finally, the two components
are combined into a single system. A forbidding-enforcing system is an ordered
pair (F, E), such that F is a forbidding set and E is an enforcing set. The language
L(F, E) deﬁned by this system consists of all words that are both consistent
with F and satisfy E, i.e., L(F, E) = L(F) ∩L(E). Such a language L is called
a forbidding-enforcing language or an fe-language. To stress the fact that the
fe-system in question is of this kind and deﬁnes a single language, rather than a
family of languages, we use the term language forbidding-enforcing system.
Example 4. Let F = {{ba}} and E = {(λ, {a})} ∪{(ai, {ai+1, aibi}) | i ≥1}.
The forbidding set ensures the language is a subset of a∗b∗. The brute enforcer
ensures we have at least the symbol a in the strings. Consider the enforcer
(ai, {ai+1, aibi}) for the string anbm. For i < n, it is satisﬁed since ai+1 is a
subword of anbm. If i > n it is satisﬁed trivially; for i = n it is satisﬁed if m ≥n.
Then, L = L(F, E) = {anbm | n ≤m and n, m ≥1}.
3
Finite Fe-Systems and Regular Languages
Finite Forbidding Sets. Finite forbidding sets deﬁne regular languages. In
fact, given a ﬁnite forbidding set F, each forbidder F ∈F prohibits the combined
presence of all of its elements as subwords, so it deﬁnes the regular language
L({F}) = 
u∈F A∗\ A∗uA∗, a union of local languages. Then, by Proposition 1
(5) in [9], L(F) = 
F ∈F L({F}), which is a ﬁnite intersection of regular languages
and, hence, is regular.
Example 5. Consider
F
=
{{aa, bb}, {ab, ba}}
from
Example
1.
Then,
L(F) = (A∗\ A∗aaA∗∪A∗\ A∗bbA∗) ∩(A∗\ A∗abA∗∪A∗\ A∗baA∗) =
{an, bn, abn, ban, anb, bna | n ≥0}, as previously stated.
We show that ﬁnite forbidding sets, actually, deﬁne locally testable languages,
a subclass of regular languages. We recall the deﬁnitions for locally testable and
strictly locally testable languages from [18] below. For k ≥0 and w ∈A∗such
that |w| ≥k, i.e. for w ∈A⩾k, denote by prefk(w) and suﬀk(w), respectively,
the singleton sets containing the preﬁx and suﬃx of w of length k and by intk(w)
(interior subwords) the set of all subwords of w of length k that occur at other
than preﬁx or suﬃx positions.
The locally testable languages are those languages whose membership w ∈L
is determined by the triple prefk(w), suﬀk(w), and intk(w).

262
D. Genova and H.J. Hoogeboom
Deﬁnition 1. A language L ⊆A∗is called k-testable if and only if for any
words x, y ∈A∗, the conditions prefk(x) = prefk(y), suﬀk(x) = suﬀk(y), and
intk(x) = intk(y) imply that x ∈L if and only if y ∈L. A language is called
locally testable if it is k-testable for some integer k ≥1.
A language is strictly locally testable if we can specify sets P, S, I of “allowed”
preﬁxes, suﬃxes, and internal subwords, respectively, such that a string is in the
language if and only if its subwords are within these respective sets.
Deﬁnition 2. A language L ⊆A∗is called strictly k-testable if there exist ﬁnite
sets P, S, I ⊆A∗such that for all w ∈A⩾k, w ∈L if and only if prefk(w) ⊆P,
suﬀk(w) ⊆S, and intk(w) ⊆I. A language is called strictly locally testable if it
is strictly k-testable for some integer k ≥1.
Locally testable languages are the boolean closure of strictly locally testable
languages. There are languages that are locally testable but not strictly locally
testable, such as the language L from the following example.
Example 6. Let A = {a, b}. The language L = aaA∗aa∪bbA∗bb is 2-testable and
hence, locally testable. A word w belongs to L if and only if int2(w) ̸= ∅and
pref2(w) = suﬀ2(w) = {aa} or pref2(w) = suﬀ2(w) = {bb}. The language L,
however, is not strictly locally testable. Intuitively, the argument is as follows.
As both aauaa and bbvbb belong to L for any u, v ∈A∗, any triple P, S, I deﬁning
L must allow both aa and bb as preﬁx, as well as, suﬃx. So, P = S = {aa, bb}.
Also, I = A2 since any u, v ∈A∗are allowed. Thus, aazbb will be allowed, for
any z ∈A∗, contradicting the deﬁnition of L. This shows that L is not strictly
2-testable and similarly, it is not strictly k-testable for all k ≥2. This example
will be revisited in the proof of Lemma 1.
We show that ﬁnite forbidding sets deﬁne locally testable languages.
Theorem 1. Let F be a ﬁnite forbidding set. Then, L(F) is locally testable.
Proof. Let F be a ﬁnite forbidding set. If F = ∅then L(F) = A∗. The language
A∗is strictly locally testable, and hence, locally testable. Suppose F = {{u}},
i.e. F has only one forbidder F = {u}, which is a singleton. Then, L(F) =
A∗\ A∗uA∗. Let |u| = k and set P = S = I = Ak \ {u}. Since every word
w ∈L(F) with |w| ≥k has a k-length preﬁx and a k-length suﬃx that are
not u and none of its interior subwords are u, it follows that L(F) is strictly
locally testable. Consider now a nonempty ﬁnite F with not necessarily singleton
forbidders. It follows from the discussion at the beginning of this section that
L(F) = 
F ∈F(
u∈F A∗\A∗uA∗), i.e., L(F) is a ﬁnite intersection of ﬁnite unions
of strictly locally testable languages and, thus, it is locally testable.
⊓⊔
Remark 1. Note that if F contains a non-singleton forbidder F, the f-language
is not necessarily strictly locally testable, even if F is a singleton. Consider
F = {{aa, bb}}. Then, the words in L(F) either don’t have aa or don’t have bb (or
don’t have both) in their subwords. However, as the language L(F) contains all

Finite Language FE-Systems
263
possible preﬁxes, suﬃxes, and subwords, it is impossible to ﬁnd suitable P, S, I.
For example, both aa and bb should be in I, but then words with subwords aabb
will be in L, contradicting the deﬁnition of L(F).
Remark 2. Observe that this theorem conﬁrms the fact that local languages are
a subclass of the locally testable languages. Namely, if a language L is local,
then by Proposition 2 in [9] there exists a forbidding set F such that L = L(F)
and F = {{u1}, {u2}, . . . , {un}} where H = {u1, u2, . . . , un} such that L =
A∗\ A∗HA∗. By the proof of the above theorem, L({{ui}}) is strictly locally
testable for all i = 1, . . . , n and hence, L, which equals the intersection of these
languages is locally testable.
The converse of the above theorem does not hold, since there are languages
that are locally testable but cannot be deﬁned by a forbidding set only. The
fe-systems deﬁning such languages will need to have enforcers.
Theorem 2. There exists a locally testable language that is not an f-language.
Proof. By Theorem 2 in [9], f-languages are factorial (that is the language con-
tains all of its subwords) and vice versa. Consider L from Example 6. It is not
factorial, since ababab ∈sub(L) but ababab ̸∈L. Hence, there is no F (ﬁnite or
inﬁnite) such that L = L(F).
⊓⊔
Finite Enforcing Sets. It turns out that ﬁnite enforcing sets, also, deﬁne
locally testable languages.
Theorem 3. Let E be a ﬁnite enforcing set. Then L(E) is locally testable.
Proof. Assume that E is ﬁnite. If E = ∅then L(E) = A∗, which is strictly locally
testable and, hence, locally testable. Otherwise, E contains at least one enforcer
(x, Y ). Let k be twice the length of the longest string in any enforcer of E. Thus,
k = 2 · max{|y| | y ∈Y for some (x, Y ) ∈E}. As E is ﬁnite and nonempty, k is
well-deﬁned.
Consider w ∈A⩾k. We show that the sets prefk(w), suﬀk(w), and intk(w)
determine whether w ∈L(E), and thus, we show that L(E) is locally testable.
First, we consider enforcing sets without brute enforcers. For every (x, Y ) ∈E
we have to make sure that every occurrence of x in a word is embedded in some
y ∈Y . We prove that L(E) is strictly locally testable by specifying the sets P, S,
and I. The set I consists of all words of length k which either don’t have x in
the middle or every occurrence of x in the middle is enclosed by some y ∈Y .
The set P consists of all words that either don’t contain x in the ﬁrst half or
every occurrence of x in the ﬁrst half is in some y ∈Y . Symmetrically, S can be
deﬁned.
In the case that E contains brute enforcers, for every enforcer (λ, Y ), we
determine membership of w by considering the sets prefk(w), suﬀk(w), and
intk(w) and checking whether there is a word in any of these sets that has some
y ∈Y as a subword. Such a language is locally testable.
⊓⊔

264
D. Genova and H.J. Hoogeboom
Example 7. Consider the brute enforcer E = (λ, {aa, bb}). Since a word from
Y = {aa, bb} has to be in the subwords of any w that satisﬁes this enforcer, the
words that satisfy it will either have aa or bb or both in their subwords. This
enforcer speciﬁes the language L({E}) = A∗{aa, bb}A∗. That is, if the enforcing
set E = {E}, then L(E) = A∗{aa, bb}A∗, which is not strictly locally testable.
Indeed, it is not possible to ﬁnd suitable sets P, S, and I to deﬁne L(E), since for
any k ≥1, S, P, and I would have to equal Ak. But then, the word (ab)k ∈L,
for example, which would contradict the deﬁnition of L(E).
Lemma 1. There exists a locally testable language that cannot be deﬁned by a
ﬁnite enforcing set.
Proof. Consider the 2-testable language L = aaA∗aa ∪bbA∗bb from Example 6
and assume it can be deﬁned by a ﬁnite enforcing set E. Let ℓbe the length of
the longest word in Y among all enforcers (x, Y ) ∈E. Let z be any word that
contains all strings of length ℓat least once. By deﬁnition, L contains aazaa
and bbzbb, so they must satisfy any enforcer (x, Y ) ∈E. We argue that also
aaz4bb satisﬁes E. As z contains all words of length ℓ, the string aaz4bb satisﬁes
any brute enforcer (λ, Y ) in E. Otherwise, if x ̸= λ, consider any occurrence of
x in aaz4bb. It is either in the beginning aazz, which is a subword of aaz4aa,
or at the end zzbb ∈sub(bbz4bb), or in the middle zz ∈sub(aaz4aa). Since
aaz4aa, bbz4bb ∈L(E), x is embedded in a word in Y . But then, aaz4bb satisﬁes
(x, Y ) and, hence, is in L(E), which is a contradiction.
⊓⊔
Finite Fe-Systems. Following Theorems 1 and 3 above, we can conclude that
ﬁnite fe-systems deﬁne regular languages and, more speciﬁcally, they deﬁne
locally testable languages, as locally testable languages are closed under inter-
section.
Theorem 4. Let (F, E) be a fe-system where both F and E are ﬁnite sets. Then,
L(F, E) is a locally testable language.
Not all locally testable languages can be deﬁned by ﬁnite fe-systems.
Theorem 5. There exists a locally testable language that cannot be deﬁned by
a ﬁnite fe-system.
Proof. Let A = {a, b}. We consider again the 2-testable language L = aaA∗aa ∪
bbA∗bb from Example 6. We assume there exists a ﬁnite fe-system (F, E) which
deﬁnes L and derive a contradiction.
First note that int(L) = A∗, so we must have F = ∅. Otherwise, if F contains
forbidder F = {u1, . . . , un} then, for example, u1u2 . . . un /∈int(L). Then, there
should be a ﬁnite E that deﬁnes L. However, Lemma 1 shows that such E does
not exist, which is a contradiction.
⊓⊔

Finite Language FE-Systems
265
4
Automata Representation of Finite Fe-Systems
In this section we reconsider some of our results using an automata approach to
local testability. Locally testable languages can be recognized by a ﬁnite state
process which slides a window of ﬁxed size over the string. Acceptance is based
on the set of substrings that have been seen during the scan. In the case of strictly
locally testable languages we verify whether the preﬁx, interior subwords, and
the suﬃx of a word are within the sets of allowed subwords. For locally testable
languages, the exact triple (prefk(w), suﬀk(w), intk(w)) of subwords seen deter-
mines whether the word w is in the language, based on the set of allowed triples.
Subword automaton. The basis of automata for (strictly) locally testable lan-
guages is the subword automaton1, see Fig. 1. For a given k and an alphabet A,
the state set of the automaton equals Q = Ak, the words of length k over A.
The automaton, basically, keeps track of the last k-letters seen, so its transition
function equals δ(aw, b) = wb for |w| = k −1 and a, b ∈A. Note that this sub-
word automaton is not a proper ﬁnite state automaton, as it has no initial and
ﬁnal states. To a given string w, we associate a path, i.e. the automaton starts in
prefk(w), traces the remaining letters of w by visiting the successive subwords
in intk(w), and ends in suﬀk(w).
aaa
aab
aba
abb
baa
bab
bba
bbb
a
b
a
b
a
b
a
b
a
b
a
b
a
b
a
b
Fig. 1. Subword automaton for k = 3 and A = {a, b}
Strictly locally testable languages. For a speciﬁc combination of (P, S, I) in the
case of strictly k-testable languages we turn the subword automaton into a ﬁnite
state automaton by choosing initial and ﬁnal states, and by deleting transitions.
We mark the states of P and S as initial and ﬁnal, respectively. For states not
in P ∪I we delete the outgoing edges, while similarly, for states not in I ∪S we
delete the incoming edges, see Example 8 below.
Given a strictly locally testable language L with subsets P, S, I of Ak, the
automaton M, such that L(M) = L is speciﬁed as M = (Ak, A, δ, P, S), where
δ(aw, b) = wb for a, b ∈A such that aw ∈P ∪I and wb ∈I ∪S.
1 It is called the k-local universal automaton in [16].

266
D. Genova and H.J. Hoogeboom
This automaton may have several initial states, and also “jumps” to the
initial preﬁx of the input, rather than reading the initial letters one-by-one as
we are used to in ﬁnite state automata. This can be changed to a more classic
representation by adding all preﬁxes of the strings in P and adding transitions
δ(w, b) = wb for |w| < k and b ∈A. In this way, we build a tree from the new
initial state λ to the words of length k by reading the ﬁrst k symbols one-by-one.
Example 8. With P = {aaa, aab}, I = {aab, abb, baa, bba, bbb}, and S = {bab,
bbb} we obtain the automaton in Fig. 2. It has two initial states, the words in P.
aaa
aab
aba
abb
baa
bab
bba
bbb
b
b
a
b
b
a
b
a
b
Fig. 2. A strictly locally testable language, see Example 8
Locally testable languages. In the case of locally testable languages, acceptance is
determined by the actual combination of subwords (including preﬁx and suﬃx)
encountered by the subword automaton during the scan. This can be built from
the subword automaton by storing information about the states visited in the
form of a triple. For each word w ∈A⩾k, consider the path corresponding to w
in the subword automaton with Ak states. Tracing the path associated with w
begins with ﬁrst visiting the state corresponding to prefk(w) and then following
the transitions δ(aw, b) = wb, with a, b ∈A, to trace w until wb = suﬀk(w) is
reached. This is associated with a sequence of triples, where the ﬁrst component
is always the ﬁrst state visited (which is prefk(w)), the second component is the
current state visited (which at the end of the path is suﬀk(w)), and the third com-
ponent is the set of visited states (which at the end of the path is intk(w)). Thus,
the state set becomes Ak×Ak×2Ak. Hence, for every word w a sequence of triples
is recorded along the path tracing w ending in (prefk(w), suﬀk(w), intk(w)). The
word w is accepted, if and only if, the last triple is an accepting state, i.e. an
allowed triple for the locally testable language.
With this automata terminology it is possible to reconsider the result on
ﬁnite enforcers, Theorem 3.
Theorem 6. Finite enforcing sets deﬁne locally testable languages. If no
enforcer of the form (λ, Y ) is present, the language is strictly locally testable.

Finite Language FE-Systems
267
Proof. Suppose E is a singleton, i.e. E = {(x, Y )}. We show strict local testability
by constructing a ﬁnite state automaton that accepts the language based on the
subword automaton for certain sets (P, S, I).
We ﬁrst consider x ̸= λ. Whenever x is present in the string it must be
embedded in one of the strings in Y . This can be checked locally, as follows.
Choose ℓto be the length of the longest string in Y . When y in Y contains x,
the other letters of y can extend at most ℓ−|x| positions in either direction of x.
This means that we can check whether (x, Y ) is satisﬁed using a window of length
k = 2ℓ−|x|, but we will use k = 2ℓfor simplicity. Thus, I contains all those
subwords that, whenever x occurs in the middle of the window, it is covered by a
string in Y . For the preﬁx and suﬃx P, S, the initial and ﬁnal states, we similarly
consider strings such that all occurrences of x that are within ℓpositions from
the start (from the end, respectively) are covered by a string in Y .
When E consists of ﬁnitely many (more than one) non-brute enforcers, then
L(E) is the intersection of all L({(x, Y )}), that is the P, S, and I will be inter-
sections of all the others, and hence, L(E) will be strictly locally testable.
An enforcing set containing a brute enforcer (λ, Y ), due to its special seman-
tics, is not strictly locally testable, as we have seen in Example 7. We must
verify that at least one of the strings in Y is present as a substring. This is
locally testable: y ∈Y occurs as a subword when it occurs as a subword in
either prefk(w), suﬀk(w), or intk(w), for any k ≥ℓ.
⊓⊔
5
(Strictly) Locally Testable Languages and Fe-Systems
In Sect. 3 we showed that ﬁnite fe-systems deﬁne locally testable languages, but
the converse does not hold. Here, we investigate the relationship between strictly
locally testable languages and languages deﬁned by ﬁnite fe-systems.
Theorem 7. Let L be a strictly locally testable language, then there exists a
ﬁnite fe-system (F, E) such that L = L(F, E).
Proof. Assume that L is strictly locally testable. Then, there exists k ≥1 and
sets P, S, I ⊆Ak such that prefk(L) ⊆P, suﬀk(L) ⊆S, and intk(L) ⊆I. We
construct a ﬁnite fe-system (F, E) and show that L = L(F, E). The construction
below considers the various intersections and unions among the three sets. If
any k-letter word is not in any of the three sets, it must be a forbidden subword
(F1). The forbidders F2 ensure that if a k-letter subword is a preﬁx only and
not a suﬃx or an interior subword then it appears at the beginning of the word
only and hence any extension to the left is forbidden. Similarly, F3 forbids any
extension to the right of subwords which are suﬃxes only. If a k-letter subword
is not an interior subword, but it is both a preﬁx and a suﬃx, then simultaneous
extension on both sides is forbidden by F4. Construct:
F1 = {{u} | u ∈Ak \ (P ∪S ∪I)}
F2 = {{au} | u ∈P \ (I ∪S) and a ∈A}
F3 = {{ub} | u ∈S \ (I ∪P) and b ∈A}

268
D. Genova and H.J. Hoogeboom
F4 = {{aub} | u ∈(P ∩S) \ I and a, b ∈A}
We construct enforcing sets to ensure that interior subwords which are not
preﬁxes or suﬃxes are indeed interior and are being extended on both sides (E1).
Similarly, suﬃxes that are not preﬁxes must be extended to the left (E2) and
preﬁxes that are not suﬃxes must be extended to the right (E3).
E1 = {(x, {axb | a, b ∈A}) | x ∈I \ (P ∪S)}
E2 = {(x, {ax | a ∈A}) | x ∈S \ P}
E3 = {(x, {xb | b ∈A}) | x ∈P \ S}
Then, let F = 4
i=1 Fi and let E = 3
i=1 Ei. By the above construction,
L = L(F, E).
⊓⊔
Example 8 was used to illustrate the subword automaton. The same sets are
represented here using the construction in the above proof.
Example 9. Let the strictly locally testable language L be determined by P =
{aaa}, I = {aab, abb, baa, bba, bbb}, and S = {bab, bbb}. We construct an (F, E)
system which deﬁnes L.
Let F1 = {{aba}}, F2 = {{aaaa}, {baaa}}, F3 = {{baba}, {babb}}, and F4 = ∅.
Let E1 = {(aab, {aaaba, aaabb, baaba, baabb}), (abb, {aabba, aabbb, babba, babbb}),
(baa, {abaaa, abaab, bbaaa, bbaab}), (bba, {abbaa, abbab, bbbaa, bbbab})},
E2 = {(bab, {abab, bbab}), (bbb, {abbb, bbbb})}, and E3 = {(aaa, {aaaa, aaab})}.
Then, let F = 4
i=1 Fi and let E = 3
i=1 Ei.
We have presented two examples, so far, of fe-languages deﬁned by ﬁnite
systems, which are not strictly locally testable, Remark 1 and Example 7. Thus,
we conclude that the converse of the above theorem does not hold.
Theorem 8. There exists a language deﬁned by a ﬁnite fe-system that is not
strictly locally testable.
We conclude with a summary of our results.
Theorem 9. The class of fe-languages deﬁned by ﬁnite fe-systems is strictly
between the class of strictly locally testable languages and the class of locally
testable languages.
Proof. By Theorems 7 and 8, the class of strictly locally testable languages is
included strictly in the class of fe-languages deﬁned by ﬁnite fe-systems. Also,
by Theorems 4 and 5, languages deﬁned by ﬁnite fe-systems are strictly included
in the class of locally testable languages.
⊓⊔
Acknowledgement. This paper was started when the ﬁrst author was visiting Leiden
University, while on sabbatical from UNF. The authors thank both institutions for
making this possible.

Finite Language FE-Systems
269
References
1. Bonizzoni, P., Jonoska, N.: Existence of constants in regular splicing languages.
Inf. Comput. 242, 340–353 (2015)
2. Cavaliere, M., Jonoska, N.: Forbidding and enforcing in membrane computing. Nat.
Comput. 2, 215–228 (2003)
3. Ehrenfeucht, A., Haussler, D., Rozenberg, G.: On regularity of context-free lan-
guages. Theoret. Comput. Sci. 27, 311–332 (1983)
4. Ehrenfeucht, A., Hoogeboom, H.J., Rozenberg, G., van Vugt, N.: Forbidding and
enforcing, In: Winfree, E., Giﬀord, D.K. (eds.) DNA Based Computers V. AMS
DIMACS, Providence, RI, vol. 54, pp. 195–206 (2001)
5. Ehrenfeucht, A., Hoogeboom, H.J., Rozenberg, G., van Vugt, N.: Sequences of
languages in forbidding-enforcing families. Soft. Comput. 5(2), 121–125 (2001)
6. Ehrenfeucht, A., Rozenberg, G.: Forbidding-enforcing systems. Theoret. Comput.
Sci. 292, 611–638 (2003)
7. Ehrenfeucht, A., Rozenberg, G.: Reaction systems. Fundamenta Informaticae 76,
1–18 (2006)
8. Franco, G., Jonoska, N.: Forbidding and enforcing conditions in DNA self-assembly
of graphs. In: Chen, J., Jonoska, N., Rozenberg, G. (eds.) Nanotechnology: Sci-
ence and Computation, Part I. Natural Computing Series, pp. 105–118. Springer,
Heidelberg (2006)
9. Genova, D.: Deﬁning languages by forbidding-enforcing systems. In: L¨owe, B.,
Normann, D., Soskov, I., Soskova, A. (eds.) CiE 2011. LNCS, vol. 6735, pp. 92–101.
Springer, Heidelberg (2011). doi:10.1007/978-3-642-21875-0 10
10. Genova, D.: Forbidding sets and normal forms for language forbidding-enforcing
systems. In: Dediu, A.-H., Mart´ın-Vide, C. (eds.) LATA 2012. LNCS, vol. 7183,
pp. 289–300. Springer, Heidelberg (2012). doi:10.1007/978-3-642-28332-1 25
11. Genova, D.: Language forbidding-enforcing systems deﬁning DNA codewords. In:
Bonizzoni, P., Brattka, V., L¨owe, B. (eds.) CiE 2013. LNCS, vol. 7921, pp. 220–229.
Springer, Heidelberg (2013). doi:10.1007/978-3-642-39053-1 25
12. Genova, D., Jonoska, N.: Deﬁning structures through forbidding and enforcing
constraints. Phys. B Condens. Matter 394(2), 306–310 (2007)
13. Genova, D., Jonoska, N.: Forbidding and enforcing on graphs. Theoret. Comput.
Sci. 429, 108–117 (2012)
14. Head, T.: Formal language theory and DNA: an analysis of the generative capacity
of speciﬁc recombinant behaviors. Bull. Math. Biol. 49(6), 737–759 (1987)
15. P˘aun, G.: Membrane Computing. An Introduction. Springer, Berlin (2002)
16. Perrin, D.: Finite automata. In: van Leeuwen, J. (ed.) Handbook of Theoreti-
cal Computer Science, vol. B, Formal Models and Semantics, pp. 1–57. Elsevier,
Amsterdam (1990)
17. Rozenberg, G., B¨ack, T., Kok, J.N. (eds.): Handbook of Natural Computing, 3
vols. Springer, Heidelberg (2012)
18. Yu, S.: Regular languages. In: Rozenberg, G., Saloma, A. (eds.) Handbook of For-
mal Languages, vol. 1, pp. 41–110. Springer, Heidelberg (1997)

Surjective H-Colouring: New Hardness Results
Petr A. Golovach1, Matthew Johnson2, Barnaby Martin2, Dani¨el Paulusma2,
and Anthony Stewart2(B)
1 Department of Informatics, University of Bergen, Bergen, Norway
petr.golovach@ii.uib.no
2 School of Engineering and Computing Sciences,
Durham University, South Road, Durham DH1 3LE, U.K.
{matthew.johnson2,barnaby.d.martin,daniel.paulusma,a.g.stewart}@dur.ac.uk
Abstract. A homomorphism from a graph G to a graph H is a vertex
mapping f from the vertex set of G to the vertex set of H such that
there is an edge between vertices f(u) and f(v) of H whenever there is
an edge between vertices u and v of G. The H-Colouring problem is
to decide whether or not a graph G allows a homomorphism to a ﬁxed
graph H. We continue a study on a variant of this problem, namely the
Surjective H-Colouring problem, which imposes the homomorphism
to be vertex-surjective. We build upon previous results and show that this
problem is NP-complete for every connected graph H that has exactly
two vertices with a self-loop as long as these two vertices are not adjacent.
As a result, we can classify the computational complexity of Surjective
H-Colouring for every graph H on at most four vertices.
1
Introduction
The well-known Colouring problem is to decide whether or not the vertices of
a given graph can be properly coloured with at most k colours for some given
integer k. If we exclude k from the input and assume it is ﬁxed, we obtain
the k-Colouring problem. A homomorphism from a graph G = (VG, EG) to
a graph H = (VH, EH) is a vertex mapping f : VG →VH, such that there
is an edge between f(u) and f(v) in EH whenever there is an edge between
u and v in EG. We observe that k-Colouring is equivalent to the problem
of asking whether a graph allows a homomorphism to the complete graph Kk
on k vertices. Hence, a natural generalization of the k-Colouring problem is
the H-Colouring problem, which is to decide whether or not a graph allows
a homomorphism to an arbitrary ﬁxed graph H. We call this ﬁxed graph H
the target graph. Throughout the paper we consider undirected graphs with no
multiple edges. We assume that an input graph G contains no vertices with self-
loops (we call such vertices reﬂexive), whereas a target graph H may contain
such vertices. We call H reﬂexive if all its vertices are reﬂexive, and irreﬂexive
if all its vertices are irreﬂexive.
Supported by the Research Council of Norway via the project “CLASSIS” and the
Leverhulme Trust (RPG-2016-258).
c
⃝Springer International Publishing AG 2017
J. Kari et al. (Eds.): CiE 2017, LNCS 10307, pp. 270–281, 2017.
DOI: 10.1007/978-3-319-58741-7 26

Surjective H-Colouring: New Hardness Results
271
For a survey on graph homomorphisms we refer the reader to the textbook
of Hell and Neˇsetˇril [10]. Here, we will discuss the H-Colouring problem, a
number of its variants and their relations to each other. In particular, we will
focus on the surjective variant: a homomorphism f from a graph G to a graph H
is (vertex-)surjective if f is surjective, that is, if for every vertex x ∈VH there
exists at least one vertex u ∈VG with f(u) = x.
The computational complexity of H-Colouring has been determined com-
pletely. The problem is trivial if H contains a reﬂexive vertex u (we can map
each vertex of the input graph to u). If H has no reﬂexive vertices, then the
Hell-Neˇsetˇril dichotomy theorem [9] tells us that H-Colouring is solvable in poly-
nomial time if H is bipartite and that it is NP-complete otherwise.
The List H-Colouring problem takes as input a graph G and a function
L that assigns to each u ∈VG a list L(u) ⊆VH. The question is whether G
allows a homomorphism f to the target H with f(u) ∈L(u) for every u ∈VG.
Feder, Hell and Huang [2] proved that List H-Colouring is polynomial-time
solvable if H is a bi-arc graph and NP-complete otherwise (we refer to [2] for
the deﬁnition of a bi-arc graph). A homomorphism f from G to an induced sub-
graph H of G is a retraction if f(x) = x for every x ∈VH, and we say that G
retracts to H. A retraction from G to H can be viewed as a list-homomorphism:
choose L(u) = {u} if u ∈VH, and L(u) = VH if u ∈VG \ VH. The corresponding
decision problem is called H-Retraction. The computational complexity of
H-Retraction has not yet been classiﬁed. Feder et al. [3] determined the com-
plexity of the H-Retraction problem whenever H is a pseudo-forest (a graph
in which every connected component has at most one cycle). They also showed
that H-Retraction is NP-complete if H contains a connected component in
which the reﬂexive vertices induce a disconnected graph.
We impose a surjective condition on the graph homomorphism. An impor-
tant distinction is whether the surjectivity is with respect to vertices or edges.
Furthermore, the condition can be imposed locally or globally. If we require
a graph homomorphism f to be vertex-surjective when restricted to the open
neighbourhood of every vertex u of G, we say that f is an H-role assignment. The
corresponding decision problem is called H-Role Assignment and its compu-
tational complexity has been fully classiﬁed [6]. We refer to the survey of Fiala
and Kratochv´ıl [5] for further details on locally constrained homomorphisms and
from here on only consider global surjectivity.
It has been shown that deciding whether a given graph G allows a surjective
homomorphism to a given graph H is NP-complete even if G and H both belong
to one of the following graph classes: disjoint unions of paths; disjoint unions of
complete graphs; trees; connected cographs; connected proper interval graphs;
and connected split graphs [7]. Hence it is natural, just as before, to ﬁx H which
yields the following problem:
Surjective H-Colouring
Instance: a graph G.
Question: does there exist a surjective homomorphism from G to H?

272
P.A. Golovach et al.
We emphasize that being vertex-surjective is a diﬀerent condition than being
edge-surjective. A homomorphism from a graph G to a graph H is called edge-
surjective or a compaction if for any edge xy ∈EH with x ̸= y there exists an edge
uv ∈EG with f(u) = x and f(v) = y. Note that the edge-surjectivity condition
does not hold for any self-loops xx ∈EH. If f is a compaction from G to H,
we say that G compacts to H. The corresponding decision problem is known as
the H-Compaction problem. A full classiﬁcation of this problem is still wide
open. However partial results are known, for example when H is a reﬂexive
cycle, an irreﬂexive cycle, or a graph on at most four vertices [13–15], or when
G is restricted to some special graph class [16]. Vikas also showed that whenever
H-Retraction is polynomial-time solvable, then so is H-Compaction [14].
Whether the reverse implication holds is not known. A complete complexity
classiﬁcation of Surjective H-Colouring is also still open. Below we survey
the known results.
We ﬁrst consider irreﬂexive target graphs H. The Surjective H-
Colouring problem is NP-complete for every such graph H if H is non-
bipartite, as observed by Golovach et al. [8]. The straightforward reduction is
from the corresponding H-Colouring problem, which is NP-complete due to
the aforementioned Hell-Neˇsetˇril dichotomy theorem. However, the complexity
classiﬁcations of H-Colouring and Surjective H-Colouring do not coin-
cide: there exist bipartite graphs H for which Surjective H-Colouring is
NP-complete, for instance when H is the graph obtained from a 6-vertex cycle
to each of which vertices we add a path of length 3 [1].
We now consider target graphs with at least one reﬂexive vertex. Unlike the
H-Colouring problem, the presence of a reﬂexive vertex does not make the
Surjective H-Colouring problem trivial to solve. We call a connected graph
loop-connected if all its reﬂexive vertices induce a connected subgraph. Golovach,
Paulusma and Song [8] showed that if H is a tree (in this context, a connected
graph with no cycles of length at least 3) then Surjective H-Colouring is
polynomial-time solvable if H is loop-connected and NP-complete otherwise. As
such the following question is natural:
Is Surjective H-Colouring NP-complete for every connected graph H that is
not loop-connected?
The reverse statement is not true (if P̸= NP): Surjective H-Colouring is NP-
complete when H is the 4-vertex cycle C∗
4 with a self-loop in each of its vertices.
This result has been shown by Martin and Paulusma [11] and independently
by Vikas, as announced in [16]. Recall also that Surjective H-Colouring is
NP-complete if H is irreﬂexive (and thus loop-connected) and non-bipartite.
It is known that Surjective H-Colouring is polynomial-time solvable
whenever H-Compaction is [1]. Recall that H-Compaction is polynomial-
time solvable whenever H-Retraction is [14]. Hence, for instance, the afore-
mentioned result of Feder, Hell and Huang [2] implies that Surjective H-
Colouring is polynomial-time solvable if H is a bi-arc graph. We also recall
that H-Retraction is NP-complete whenever H is a connected graph that
is not loop-connected [3]. Hence, an aﬃrmative answer to the above question

Surjective H-Colouring: New Hardness Results
273
would mean that for these target graphs H the complexities of H-Retraction,
H-Compaction and Surjective H-Colouring coincide.
In Fig. 1 we display the relationships between the diﬀerent problems dis-
cussed. In particular, it is a major open problem whether the computational com-
plexities of H-Compaction, H-Retraction and Surjective H-Colouring
coincide for each target graph H. Even showing this for speciﬁc cases, such as
the case H = C∗
4, has been proven to be non-trivial. If it is true, it would relate
the Surjective H-Colouring problem to a well-known conjecture of Feder
and Vardi [4], which states that the H-Constraint Satisfaction problem has
a dichotomy when H is some ﬁxed ﬁnite target structure and which is equiva-
lent to conjecturing that H-Retraction has a dichotomy [4]. We refer to the
survey of Bodirsky, Kara and Martin [1] for more details on the Surjective
H-Colouring problem from a constraint satisfaction point of view.
List H-Colouring
H-Retraction
H-Compaction
Surj H-Colouring
H-Colouring
Fig. 1. Relations between Surjective H-Colouring and its variants. An arrow from
one problem to another indicates that the latter problem is polynomial-time solvable
for a target graph H whenever the former is polynomial-time solvable for H. Reverse
arrows do not hold for the leftmost and rightmost arrows, as witnessed by the reﬂexive
4-vertex cycle for the rightmost arrow and by any reﬂexive tree that is not a reﬂexive
interval graph for the leftmost arrow (Feder, Hell and Huang [2] showed that the only
reﬂexive bi-arc graphs are reﬂexive interval graphs). It is not known whether the reverse
direction holds for the two middle arrows.
1.1
Our Results
We present further progress on the research question of whether Surjective
H-Colouring is NP-complete for every connected graph H that is not loop-
connected. We ﬁrst consider the case where the target graph H is a connected
graph with exactly two reﬂexive vertices that are non-adjacent. In Sect. 2 we
prove that Surjective H-Colouring is indeed NP-complete for every such
target graph H. In the same section we slightly generalize this result by show-
ing that it holds even if the reﬂexive vertices of H can be partitioned into two
non-adjacent sets of twin vertices. This enables us to classify in Sect. 3 the com-
putational complexity of Surjective H-Colouring for every graph H on at
most four vertices, just as Vikas [15] did for the H-Compaction problem. A
classiﬁcation of Surjective H-Colouring for target graphs H on at most four
vertices has also been announced by Vikas in [16], and it is interesting to note
that NP-hardness proofs for H-Compaction of [15] may lift to NP-hardness for
Surjective H-Colouring. However, this is not true for the reﬂexive cycle C∗
4,
where a totally new proof was required.

274
P.A. Golovach et al.
1.2
Future Work
To conjecture a dichotomy of Surjective H-Colouring between P and NP-
complete seems still to be diﬃcult. Our ﬁrst goal is to prove that Surjec-
tive H-Colouring is NP-complete for every connected graph H that is not
loop-connected. However, doing this via using our current techniques does not
seem straightforward and we may need new hardness reductions. Another way
forward is to prove polynomial equivalence between the three problems Sur-
jective H-Colouring, H-Compaction and H-Retraction. However, com-
pletely achieving this goal also seems far from trivial. Our classiﬁcation for target
graphs H up to four vertices does show such an equivalence for these cases (see
Sect. 3).
2
Two Non-adjacent Reﬂexive Vertices
We say that a graph is 2-reﬂexive if it contains exactly 2 reﬂexive vertices that
are non-adjacent. In this section we will prove that Surjective H-Colouring
is NP-complete whenever H is connected and 2-reﬂexive. The problem is readily
seen to be in NP. Our NP-hardness reduction uses similar ingredients as the
reduction of Golovach, Paulusma and Song [8] for proving NP-hardness when H
is a tree that is not loop-connected. There are, however, a number of diﬀerences.
For instance, we will reduce from a factor cut problem instead of the less gen-
eral matching cut problem used in [8]. We will explain these two problems and
prove NP-hardness for the former one in Sect. 2.1. Then in Sect. 2.2 we give our
hardness reduction, and in Sect. 2.3 we extend our result to be valid for target
graphs H with more than two reﬂexive vertices as long as these reﬂexive vertices
can be partitioned into two non-adjacent sets of twin vertices.
2.1
Factor Cuts
Let G = (VG, EG) be a connected graph. For v ∈VG and E ⊆EG, let dE(v)
denote the number of edges of E incident with v. For a partition (V1, V2) of VG,
let EG(V1, V2) denote the set of edges between V1 and V2 in G.
Let i and j be positive integers, i ≤j. Let (V1, V2) be a partition of VG and
let M = EG(V1, V2). Then (V1, V2) is an (i, j)-factor cut of G if, for all v ∈V1,
dM(v) ≤i, and, for all v ∈V2, dM(v) ≤j. Observe that if a vertex v exists
with degree at most j, then there is a trivial (i, j)-factor cut (V \ {v}, {v}). Two
distinct vertices s and t in VG are (i, j)-factor roots of G if, for each (i, j)-factor
cut (V1, V2) of G, s and t belong to diﬀerent parts of the partition and, if i < j,
s ∈V1 and t ∈V2 (of course, if i = j, we do not require the latter condition as
(V2, V1) is also an (i, j)-factor cut). We note that when no (i, j)-factor cut exists,
every pair of vertices is a pair of (i, j)-factor roots. We deﬁne the following
decision problem.
(i, j)-Factor Cut with Roots
Instance: a connected graph G with (i, j)-factor roots s and t.
Question: does G have an (i, j)-factor cut?

Surjective H-Colouring: New Hardness Results
275
We emphasize that the (i, j)-factor roots are given as part of the input. That is,
the problem asks whether or not an (i, j)-factor cut (V1, V2) exists, but we know
already that if it does, then s and t belong to diﬀerent parts of the partition.
That is, we actually deﬁne (i, j)-Factor Cut with Roots to be a promise
problem in which we assume that if an (i, j)-factor cut exists then it has the
property that s and t belong to diﬀerent parts of the partition. The promise
class may not itself be polynomially recognizable but one may readily ﬁnd a
subclass of it that is polynomially recognizable and includes all the instances we
need for NP-hardness. In fact this will become clear when reading the proof of
Theorem 1 but we refer also to [8] where such a subclass is given for the case
(i, j) = (1, 1). A (1, 1)-factor cut (V1, V2) of G is also known as a matching cut,
as no two edges in EG(V1, V2) have a common end-vertex, that is, EG(V1, V2) is
a matching. Similarly (1, 1)-Factor Cut with Roots is known as Matching
Cut with Roots and was proved NP-complete by Golovach, Paulusma and
Song [8] (by making an observation about the proof of the result of Patrignani
and Pizzonia [12] that deciding whether or not any given graph has a matching
cut is NP-complete). The proof of Theorem 1 has been omitted.
Theorem 1. Let i and j be positive integers, i ≤j. Then (i, j)-Factor Cut
with Roots is NP-complete.
2.2
The Hardness Reduction
Let H be a connected 2-reﬂexive target graph. Let p and q be the two (non-
adjacent) reﬂexive vertices of H. The length of a path is its number of edges.
The distance between two vertices u and v in a graph G is the length of a
shortest path between them and is denoted distG(u, v). We deﬁne two induced
subgraphs H1 and H2 of H whose vertex sets partition VH. First H1 con-
tains those vertices of H that are closer to p than to q; and H2 contains
those vertices that are at least as close to q as to p (so contains any vertex
equidistant to p and q). That is, VH1 = {v ∈VH : distH(v, p) < distH(v, q)} and
VH2 = {v ∈VH : distH(v, q) ≤distH(v, p)}. See Fig. 2 for an example. The fol-
lowing lemma follows immediately from our assumption that H is connected.
Lemma 1. Both H1 and H2 are connected. Moreover, distH1(x, p) = distH(x, p)
for every x ∈VH1 and distH2(x, q) = distH(x, q) for every x ∈VH2.
A clique is a subset of vertices of G that are pairwise adjacent to each other.
Let ω denote the size of a largest clique in H.
From graphs H1 and H2 we construct graphs F1 and F2, respectively, in the
following way:
1. for each x /∈{p, q}, create a vertex t1
x;
2. for p, create ω vertices t1
p, . . . , tω
p ;
3. for q, create ω vertices t1
q, . . . , tω
q ;
4. for i = 1, 2, add an edge in Fi between any two vertices th
x and tj
y if and only
if xy is an edge of EHi.

276
P.A. Golovach et al.
p
q
H1
H2
Fig. 2. An example of the construction of graphs H1 and H2 from a connected 2-
reﬂexive target graph H with ω = 3.
We observe that since p and q are reﬂexive, there are edges pp and qq, hence
t1
p, . . . , tω
p and t1
q, . . . , tω
q form cliques of size ω. Note also that F1 is the graph
obtained by taking H1 and replacing p by a clique of size ω. Similarly, F2 is the
graph obtained by taking H2 and replacing q by a clique of size ω. We say that
t1
p, . . . , tω
p are the roots of F1 and that t1
q, . . . , tω
q are the roots of F2. Figure 3
shows an example of the graphs F1 and F2 obtained from the graph H in Fig. 2.
Fig. 3. The graphs F1 (left) and F2 (right) resulting from the graph H in Fig. 2.
Let ℓ= distH(p, q) ≥2 denote the distance between p and q. Let Np be the
set of neighbours of p that are each on some shortest path (thus of length ℓ)
from p to q in H. Let rp be the size of a largest clique in Np. We deﬁne Nq and
rq similarly. We will reduce from (rp, rq)-Factor Cut with Roots, which is
NP-complete due to Theorem 1. Hence, consider an instance (G, s, t) of (rp, rq)-
Factor Cut with Roots, where G is a connected graph and s and t form
the (ordered) pair of (rp, rq)-factor roots of G. Recall that we assume that G is
irreﬂexive.
We say that we identify two vertices u and v of a graph when we remove them
from the graph and replace them with a single vertex that we make adjacent to
every vertex that was adjacent to u or v. From F1, F2, and G we construct a
new graph G′ as follows:
1. For each edge e = uv ∈EG, we do as follows. We create four vertices, gr
u,e,
gb
u,e, gr
v,e and gb
v,e. We also create two paths P 1
e and P 2
e , each of length ℓ−2,
between gr
u,e and gb
v,e, and between gr
v,e and gb
u,e, respectively. If ℓ= 2 we
identify gr
u,e and gb
v,e and gr
v,e and gb
u,e to get paths of length 0.

Surjective H-Colouring: New Hardness Results
277
2. For each vertex u ∈VG, we do as follows. First we construct a clique Cu on ω
vertices. We denote these vertices by g1
u, . . . , gω
u. We then make every vertex
in Cu adjacent to both gr
u,e and gb
u,e for every edge e incident to u; we call
gr
u,e and gb
u,e a red and blue neighbour of Cu, respectively; if ℓ= 2, then the
vertex obtained by identifying two vertices gr
u,e and gb
v,e, or gr
v,e and gb
u,e is
simultaneously a red neighbour of one clique and a blue neighbour of another
one. Finally, for every two edges e and e′ incident to u, we make gr
u,e and gr
u,e′
adjacent, that is, the set of red neighbours of Cu form a clique, whereas the
set of blue neighbours form an independent sets.
3. We add F1 by identifying ti
p and gi
s for i = 1, . . . , ω, and we add F2 by
identifying ti
q and gi
t for i = 1, . . . , ω. We denote the vertices in F1 and F2 in
G′ by their label ti
x in F1 or F2.
See Fig. 4 for an example of a graph G′.
s
t
(a) An example of a graph G with
a (1, 2)-factor cut with (1, 2)-factor
roots s and t.
F2
F1
(b) The corresponding graph G′ where H is a
2-reﬂexive target graph with ℓ= 3 and ω = 3.
Fig. 4. An example of a graph G and the corresponding graph G′. (Color ﬁgure online)
The next lemma describes a straightforward property of graph homomor-
phisms that will prove useful.
Lemma 2. If there exists a homomorphism h : G′ →H then distG′(u, v) ≥
distH (h(u), h(v)) for every pair of vertices u, v ∈VG′.
Here is the key property of our construction (proof omitted).
Lemma 3. For every homomorphism h from G′ to H, there exists at least one
clique Ca with p ∈h(Ca) and at least one clique Cb with q ∈h(Cb).
Proof Sketch. Since for each u ∈VG and any edge e incident to u, every clique
Cu ∪{gr
u,e} in G′ is of size at least ω + 1, we ﬁnd that h must map at least two
of its vertices to a reﬂexive vertex, so either to p or q. Hence, for every u ∈VG,
we ﬁnd that h maps at least one vertex of Cu to either p or q.
We prove the lemma by contradiction. We will assume that h does not map
any vertex of any Cu to q, thus p ∈h(Cu) for all u ∈VG. We will note later
that if instead q ∈h(Cu) for all u ∈VG we can obtain a contradiction in the
same way.

278
P.A. Golovach et al.
We consider two vertices ti
p ∈F1 and tj
q ∈F2 such that h(ti
p) = h(tj
q) = p.
Without loss of generality let i = j = 1. We shall refer to these vertices as
tp and tq respectively. We now consider a vertex v ∈VF1∪VF2. By Lemma 2,
distG′(v, tp) ≥distH(h(v), p) and distG′(v, tq) ≥distH(h(v), p). In other words:
min (distG′(v, tp), distG′(v, tq)) ≥distH(h(v), p).
In fact by applying Lemma 2 we can generalize this further to any vertex mapped
to p by h:
min
w∈h−1(p) (distG′(v, w)) ≥distH(h(v), p).
(1)
For every v ∈VG′ we deﬁne a value D(v) as follows:
D(v) =
⎧
⎨
⎩
distF1(v, tp) if v ∈F1
distF2(v, tq) if v ∈F2
⌊ℓ/2⌋
otherwise
As h(tp) = h(tq) = p and any vertex not in F1 ∪F2 is either in a clique or on
a path of length ℓbetween two cliques, we can use inequality (1) to prove that
the following inequality holds for any distance d ≥ℓ:

t1
w ∈VF1∪VF2 : D(t1
w) ≥d
 ≥|{w ∈VH : distH(w, p) ≥d}| .
(2)
In the remainder we only present the intuition behind the ﬁnal part of the proof.
Consider the graphs F1, F2 and H in the example shown in Fig. 5. We recall that
every vertex v (other than p or q) has a single corresponding vertex tv in F1 or
F2. We may naturally want to map the vertices of F1 onto the vertices of H1,
p
q
q′
distH(p, v) = 1
distH(p, v) = 2
distH(p, v) = 3
distH(p, v) = 4
distH(p, v) = 5
H
t1
p
t1
q
t2
p
t2
q
tq′
D(tv) = 1
D(tv) = 2
D(tv) = 3
D(tv) = 4
D(tv) = 5
F1
F2
Fig. 5. An example of a graph H with corresponding graphs F1 and F2. Vertices in H
equidistant from p are plotted at the same vertical position and likewise vertices tv ∈F1
and tw ∈F2 with D(tv) = D(tw) are plotted at the same vertical position. The vertices
q′ ∈H and corresponding tq′ ∈F2 are highlighted.

Surjective H-Colouring: New Hardness Results
279
which is possible by deﬁnition of F1. However, when we try to map the vertices
of F2 onto the vertices of H2, with h(ti
q) = p (for some i), we will prove that
there is at least one vertex q′ in H2 which is further from p in H than it is from
q and that cannot be mapped to and thus violates the surjectivity constraint.
In Fig. 5 this vertex, which will play a special role in our proof, is shown in red.
In the example of this ﬁgure, ℓ= 3 and we observe that there are ten vertices
(including q′) in H with distH(p, v) ≥3 but only nine vertices (excluding q′) in
F1∪F2 with D(tv) ≥3 which could be mapped to these vertices. This contradicts
inequality (2).
⊓⊔
We are now ready to state and prove our main result.
Theorem 2. For every connected 2-reﬂexive graph H, the Surjective H-
Colouring problem is NP-complete.
Proof. Let H be a connected 2-reﬂexive graph with reﬂexive vertices p and q at
distance ℓ≥2 from each other. Let ω be the size of a largest clique in H. We
deﬁne the graphs H1, H2, F1 and F2 and values rp, rq as above. Recall that the
problem is readily seen to be in NP and that we reduce from (rp, rq)-Factor
Cut with Roots. From F1, F2 and an instance (G, s, t) of the latter problem
we construct the graph G′. We claim that G has an (rp, rq)-factor cut (V1, V2)
if and only if there exists a surjective homomorphism h from G′ to H.
First suppose that G has an (rp, rq)-factor cut (V1, V2). By deﬁnition, s ∈V1
and t ∈V2. We deﬁne a homomorphism h as follows. For every x ∈VF1 ∪VF2,
we let h map t1
x to x. This shows that h is surjective. It remains to deﬁne h on
the other vertices. For every u ∈VG, let h map all of Cu to p if u is in V1 and
let h map all of Cu to q if u is in V2 (note that this is consistent with how we
deﬁned h so far). For each uv ∈EG with u, v ∈V1, we map the vertices of the
paths P 1
e and P 2
e to p. For each uv ∈EG with u, v ∈V2, we map the vertices of
the paths P 1
e and P 2
e to q. We are left to show that the vertices of the remaining
paths P 1
e and P 2
e can be mapped to appropriate vertices of H.
Note that the red neighbours of each Cu form a clique (whereas all blue
vertices of each Cu form an independent set and inner vertices of paths P 1
e and
P 2
e have degree 2). However, as (V1, V2) is an (rp, rq)-factor cut of G, all but at
most rp vertices of these red cliques have been mapped to p already if u ∈V1
and all but at most rq vertices have been mapped to q already if u ∈V2. By
deﬁnition of rp and rq, this means that we can map the vertices of the paths P 1
e
and P 2
e with e = uv for u ∈V1 and v ∈V2 to vertices of appropriate shortest
paths between p and q in H, so that h is a homomorphism from G′ to H (recall
that we already showed surjectivity). In particular, the clique formed by the red
neighbours of each Cu is mapped to a clique in Np ∪{p} or Nq ∪{q}.
Now suppose that there exists a surjective homomorphism h from G′ to H.
For a clique Cu, we may choose any edge e incident to u, such that C′
u =
Cu ∪{gr
u,e} is a clique of size ω + 1. Since H contains no cliques larger than ω,
we ﬁnd that h maps each clique C′
u (which has size ω + 1) to a clique in H that
contains a reﬂexive vertex. Note that at least two vertices of C′
u are mapped
to a reﬂexive vertex. Hence we can deﬁne the following partition of VG. We let

280
P.A. Golovach et al.
V1 = {v ∈VG : p ∈h(Cv)} and V2 = VG \ V1 = {v ∈VG : q ∈h(Cv)}. Lemma 3
tells us that V1 ̸= ∅and V2 ̸= ∅. We deﬁne M = {uv ∈EG : u ∈V1, v ∈V2}.
Let e = uv be an arbitrary edge in M. By deﬁnition, h maps all of Cu to
a clique containing p and all of Cv to a clique containing q. Hence, the vertices
of the two paths P 1
e and P 2
e must be mapped to the vertices of a shortest path
between p and q. At most rp red neighbours of every Cu with u ∈V1 can be
mapped to a vertex other than p. This is because these red neighbours form a
clique. As such they must be mapped onto vertices that form a clique in H. As
such vertices lie on a shortest path from p to q, the clique in H has size at most
rp. Similarly, at most rq red neighbours of every Cu with u ∈V2 can be mapped
to a vertex other than q. As such, (V1, V2) is an (rp, rq)-factor cut in G.
⊓⊔
2.3
A Small Extension
Two vertices u and v in a graph G are true twins if they are adjacent to each other
and share the same neighbours in VG\{u, v}. Let H(i,j) be a graph obtained from
a connected 2-reﬂexive graph H with reﬂexive vertices p and q after introducing
i reﬂexive true twins of p and j reﬂexive true twins of q. In the graph G′ we
increase the cliques Cu to size ω + max(i, j). We call the resulting graph G′′.
Then it is readily seen that there exists a surjective homomorphism from G′
to H if and only if there exists a surjective homomorphism from G′′ to H(i,j).
Theorem 3. For every connected 2-reﬂexive graph H and integers i, j ≥0,
Surjective H(i,j)-Colouring is NP-complete.
3
Target Graphs of at Most Four Vertices
For proving Theorem 4 we use Theorem 3 combined with known results [11,15];
we omit the details. In Fig. 6, the three graphs C∗
4, D and paw∗are displayed.
Fig. 6. The graphs C∗
4, D and paw∗.
Theorem 4. Let H be a graph with |VH|
≤
4. Then Surjective H-
Colouring is NP-complete if some connected component of H is not loop-
connected or is an irreﬂexive complete graph on at least three vertices, or
H ∈{C∗
4, D, paw∗}. Otherwise Surjective H-Colouring is polynomial-time
solvable.

Surjective H-Colouring: New Hardness Results
281
Theorem 4 corresponds to Vikas’ complexity classiﬁcation of H-Compaction
for targets graphs H of at most four vertices. Vikas [15] showed that H-
Compaction and H-Retraction are polynomially equivalent for target
graphs H of at most four vertices. Thus, we obtain the following corollary.
Corollary 1. Let H be a graph on at most four vertices. Then the three prob-
lems Surjective H-Colouring, H-Compaction and H-Retraction are
polynomially equivalent.
References
1. Bodirsky, M., K´ara, J., Martin, B.: The complexity of surjective homomorphism
problems - a survey. Discrete Appl. Math. 160, 1680–1690 (2012)
2. Feder, T., Hell, P., Huang, J.: Bi-arc graphs and the complexity of list homomor-
phisms. J. Graph Theory 42, 61–80 (2003)
3. Feder, T., Hell, P., Jonsson, P., Krokhin, A., Nordh, G.: Retractions to pseudo-
forests. SIAM J. Discrete Math. 24, 101–112 (2010)
4. Feder, T., Vardi, M.Y.: The computational structure of monotone monadic SNP
and constraint satisfaction: a study through datalog and group theory. SIAM J.
Comput. 28, 57–104 (1998)
5. Fiala, J., Kratochv´ıl, J.: Locally constrained graph homomorphisms - structure,
complexity, and applications. Comput. Sci. Rev. 2, 97–111 (2008)
6. Fiala, J., Paulusma, D.: A complete complexity classiﬁcation of the role assignment
problem. Theoret. Comput. Sci. 349, 67–81 (2005)
7. Golovach, P.A., Lidick´y, B., Martin, B., Paulusma, D.: Finding vertex-surjective
graph homomorphisms. Acta Informatica 49, 381–394 (2012)
8. Golovach, P.A., Paulusma, D., Song, J.: Computing vertex-surjective homomor-
phisms to partially reﬂexive trees. Theoret. Comput. Sci. 457, 86–100 (2012)
9. Hell, P., Neˇsetˇril, J.: On the complexity of H-colouring. J. Comb. Theory Ser. B
48, 92–110 (1990)
10. Hell, P., Neˇsetˇril, J.: Graphs and Homomorphisms. Oxford University Press, Oxford
(2004)
11. Martin, B., Paulusma, D.: The computational complexity of disconnected cut and
2K2-partition. J. Comb. Theory Ser. B 111, 17–37 (2015)
12. Patrignani, M., Pizzonia, M.: The complexity of the matching-cut problem. In:
Brandst¨adt, A., Le, V.B. (eds.) WG 2001. LNCS, vol. 2204, pp. 284–295. Springer,
Heidelberg (2001). doi:10.1007/3-540-45477-2 26
13. Vikas, N.: Computational complexity of compaction to reﬂexive cycles. SIAM J.
Comput. 32, 253–280 (2002)
14. Vikas, N.: Compaction, retraction, and constraint satisfaction. SIAM J. Comput.
33, 761–782 (2004)
15. Vikas, N.: A complete and equal computational complexity classiﬁcation of com-
paction and retraction to all graphs with at most four vertices and some general
results. J. Comput. Syst. Sci. 71, 406–439 (2005)
16. Vikas, N.: Algorithms for partition of some class of graphs under compaction and
vertex-compaction. Algorithmica 67, 180–206 (2013)

On Higher Eﬀective Descriptive Set Theory
Margarita Korovina1(B) and Oleg Kudinov2
1 A.P. Ershov Institute of Informatics Systems, SbRAS, Novosibirsk, Russia
rita.korovina@gmail.com
2 Sobolev Institute of Mathematics, SbRAS, Novosibirsk, Russia
kud@math.nsc.ru
Abstract. In the framework of computable topology, we propose an
approach how to develop higher eﬀective descriptive set theory. We intro-
duce a wide class K of eﬀective T0-spaces admitting Borel point recover-
ing. For this class we propose the notion of an (α, m)-retractive morphism
that gives a great opportunity to extend classical results from EDST to
the class K. We illustrate this by several examples.
Keywords: Higher eﬀective descriptive set theory · Eﬀective topologi-
cal space · Eﬀective T0–space admitting Borel point recovering · (α, m)-
retractive morphism · Eﬀective Borel and Lusin hierarchies · Suslin-
Kleene Theorem · Uniformisation Theorem
1
Introduction
Having a long term history, classical descriptive set theory (DST) has been based
on the fundamental idea that all Polish spaces have common properties related
to deﬁnability of functions and sets as well as to the resulting Borel and Lusin
hierarchies [5,13]. The similar idea can be used for the computable Polish spaces
under consideration of eﬀective versions of the corresponding hierarchies. One of
the approaches to eﬀective descriptive set theory (EDST) has been proposed in
[10,12,14] and developed in [3,13,18] among others, where most of results have
been obtained for the computable Polish spaces. A comparison of concepts and
results from computable analysis and EDST has been presented in [4].
It is worth noting that in the non-eﬀective case a signiﬁcant progress has
been done in [2,17], where a big part of DST has been developed ﬁrst for ω-
continuous domains and then for the wider class of quasi-Polish spaces. Two
of the main problems that naturally arise in EDST are the following. The ﬁrst
one is to discover wide classes of eﬀective topological spaces for which the main
results of DST hold. Here the class of quasi-Polish spaces looks like a promising
candidate. The second problem is to discover wide classes of eﬀective topological
spaces admitting results of EDST related to higher levels of the eﬀective Lusin
hierarchy.
The research has been partially supported by the DFG grants CAVER BE 1267/14-1
and WERA MU 1801/5-1.
c
⃝Springer International Publishing AG 2017
J. Kari et al. (Eds.): CiE 2017, LNCS 10307, pp. 282–291, 2017.
DOI: 10.1007/978-3-319-58741-7 27

On Higher Eﬀective Descriptive Set Theory
283
The main results of our paper concern this second problem. Informally, in
the paper we consider a part of EDST that is nearly Δ1
1–level or above in the
eﬀective Lusin hierarchy and refer to this part as higher eﬀective descriptive set
theory (Higher EDST). In order to give a ﬂavor of Higher EDST it is worth
noting that an eﬀective version of the Hausdorﬀtheorem does not belong to
Higher EDST while the extended Suslin-Kleene theorem does.
The main contributions of the paper are the following. To attack the second
problem mentioned above we propose a wide class of eﬀective topological spaces
admitting eﬀective Borel point recovering which contains eﬀective quasi-Polish
spaces, weakly-eﬀective ω–continuous domains as proper subclasses. For this
class we provide a fruitful technique that allows us to eﬀectivise classical results
from DST. We illustrate this by the Suslin-Kleene Theorem, Uniformisation
Theorem.
2
Notations and Preliminaries
We refer the reader to [14,15] for basic deﬁnitions and fundamental concepts of
recursion theory, to [3,5,13] for basic deﬁnitions and fundamental concepts of
DST and EDST. We use bold Greek letters α, β, γ, . . . to denote numberings
and light Greek letters to denote ordinals. We use only computable ordinals i.e.
that are less than ωCK
1 . We work with the Baire space N = (ωω, αN ), the Cantor
space C = (2ω, αC) with the standard topologies and numberings of the bases,
and the space P = (P(ω), β), where β is the standard numbering of the topology
base generated by all open sets of the type WD = {I ⊆ω | D ⊆I}, where D is
a ﬁnite subset of ω.
3
Eﬀective Topological Spaces and Hierarchies
Let (X, τ, α) be a topological space, where X is a non-empty set, Bτ ⊆2X is a
base of the topology τ and α : ω →Bτ is a numbering. In notations we skip τ
since it can be recovered by α. Further on we will often abbreviate (X, α) by X
if α is clear from a context.
Deﬁnition 1. A topological space (X, α) is eﬀective if the following condition
holds.
• There exists a computable function g : ω × ω × ω →ω such that
α(i)

α(j) =

n∈ω
α(g(i, j, n)).
Now we recall the notion of an eﬀectively enumerable topological space.
Deﬁnition 2. [8] An eﬀective topological space (X, α) is eﬀectively enumerable
if the following condition holds.
• The set {i | α(i)≠∅} is computably enumerable.

284
M. Korovina and O. Kudinov
It is worth noting that the similar concept of a weakly computable cb0–space
has been used in [18].
Deﬁnition 3. Let (X, α) be an eﬀective topological space. A set A ⊆X is eﬀec-
tively open if there exists a computably enumerable set V ⊆ω such that
A =

n∈V
α(n).
Let OX denote the set of all open subsets of X and Oe
X denote the set of all
eﬀectively open subsets of X. The set Oe
X is closed under intersection and union
since the class of eﬀectively enumerable sets is a lattice. The following proposition
is a natural corollary of the deﬁnition.
Proposition 1. [7] For every eﬀective topological space X there exists a prin-
cipal computable numbering αe
X of Oe
X.
In this paper we use the notation f : X →Y for a partial function unless the
word total is written.
Deﬁnition 4. Let X = (X, α) be an eﬀective topological space and Y = (Y, β)
be an eﬀective T0–space. A total function f : X →Y is called
computable if
there exists a computable function H : ω2 →ω such that
f −1(β(m)) =

i∈ω
α(H(m, i)).
We adopt the notion of the eﬀective Borel and Lusin hierarchies for com-
putable Polish spaces [13] to eﬀective T0–spaces. Put for ﬁnite ordinals
Σ0
1 = all eﬀecively open sets,
Σ0
n+1 = ∃ω(the set of ﬁnite boolean combinations of Σ0
n),
where ∃ω denotes the projection along ω,
Π0
n = ¬Σ0
n,
Δ0
n = Σ0
n

Π0
n.
Following [13], {(Σ0
n, Π0
n)}n<ω is called the Kleene hierarchy. Further on, for
R ⊆X and R ∈Σ0
n we write R ∈Σ0
n[X].
Remark 1. It is worth noting that the diﬀerence between our and Moschovakis’s
deﬁnitions of the Kleene hierarchy [13] is based on the following observation.
For the space P, Σ0
1[P] ⊈∃ωΠ0
1[P]. To show that it is suﬃcient to prove that
A = {x ⊆ω | 0 ∉x} ∉∀ωΣ0
1[P]. Assume contrary A ∈∀ωΣ0
1[P]. Then A = 
n ∈ω En,
where En are eﬀectively open sets. Therefore, for all n∈ω, En≠∅and, by the
properties of the topology on P, ω ∈En. So, ω ∈A. This contradicts the deﬁnition
of A. In fact this deﬁnition of the Kleene hierarchy has been proposed in [18].

On Higher Eﬀective Descriptive Set Theory
285
One way to introduce the eﬀective Borel hierarchy {(Σ0
ξ, Π0
ξ )}ξ<ωCK
1
considered
in [10] is to use eﬀective Borel coding [5,13], i.e., for any B such that B = Bα
for some computable α ∈N, ξ(B) = inf {ξ(α) | α is computable and B = Bα},
where ξ(α) is introduced in [5]. Another more direct way proposed in [14] for
N and in [3] for computable Polish Spaces can be adopted to eﬀective T0–
spaces [18]. In diﬀerent situations one of the approaches has its advantages. For
inductive considerations the second one is more preferable. In particular, in the
framework of the second approach the inclusions Σ0
α ⊆Σ0
α+1, Π0
α ⊆Σ0
α+1 are just
parts of the deﬁnition. Therefore, Σ0
α ∪Π0
α ⊆Δ0
α+1 = Σ0
α+1
 Π0
α+1.
In [3,18] the eﬀective Lusin hierarchy {(Σ1
n[X], Π1
n[X])}n<ω is deﬁned by
induction as follows:
Σ1
1[X] = {prN (B) | B ∈Π0
2[N × X]},
Σ1
n+1[X] = {prN (B) | B ∈Π1
n[N × X]},
Π1
n[X] = ¬Σ1
n[X],
Δ1
n[X] = Σ1
n[X]

Π1
n[X].
Some properties of the eﬀective Lusin hierarchy on particular spaces (e.g. perfect
computable Polish spaces, computable reﬂective ω-algebraic domains) can be
found in [18].
Lemma 1.
For an eﬀective T0–space X, {(x, y) | x = y} ∈Π0
2[X × X].
4
The Class K
Deﬁnition 5. An eﬀective T0–space (X, α) is said to admit eﬀective Borel point
recovering if the following condition holds.
• The set {Ax | x ∈X} is a Δ1
1-subset of P(ω), where Ax = {n | x ∈α(n)}. Here
P(ω) is considered as the Cantor space C.
We denote this class of eﬀective T0–spaces admitting Borel point recovering
by K. Now we show the correspondence between spaces from K and Δ1
1-subsets
of P.
Proposition 2. Δ1
1[C] = Δ1
1[P].
Proof. The inclusion Δ1
1[C]⊇Δ1
1[P] follows from the fact that C has more Π0
2-
subsets than P. Now us take id : (P, β) →(C, αC). Since id−1(αC(n)) =
β(h(n))	β(t(n)), where h and t are computable functions, Π0
2[C] ⊆Π0
3[P]. There-
fore, Δ1
1[C] ⊆Δ1
1[P].
⊓⊔
Deﬁnition 6. We write (X0, β0) < (X, β) if
1. X0 is a subset of X,
2. β0(n) = β(n)  X for any n ∈ω.

286
M. Korovina and O. Kudinov
Theorem 1. For any eﬀective (eﬀectively enumerable) T0–space (X, α) the fol-
lowing assertions are equivalent.
1. (X, α) ∈K.
2. (X, α) is computably homeomorphic to some (X0, β0) < (P, β) with
X0 ∈Δ1
1[P].
Proof. (2 →1). Assume X ∈Δ1
1[P]. Consider (X, α), where α is induced by β. It
is easy to see that {Px | x ∈P} ∈Δ0
2[C], where Px = {n | x ∈β(n)}. In particular,
P ∈K. Let Ay = {n | y ∈α(n)}. Then
J ∈{Ay | y ∈X} ↔
J ∈{Py | y ∈P} ∧(∃y ∈X)J = Py ↔
J ∈{Py | y ∈P} ∧(∃y ∈X)(∀n ∈ω)

y ∈β(n) ↔n ∈J

.
This is a Σ1
1-condition on C.
J ∉{Ay | y ∈X} ↔
J ∉{Py | y ∈P} ∨(∃y ∈P)

J = Py ∧y ∉X

.
This is also a Σ1
1-condition on C. Therefore, {Ay | y ∈X} ∈Δ1
1[C].
(1 →2). Assume now that {Ax | x ∈X} ∈Δ1
1[C], where Ax = {n | x ∈α(n)}. We
take the function F : X
1−1
−−→P deﬁned by the rule F(x) = Ax. It is clear that
F is eﬀectively continuous, i.e. computable. Indeed, F −1(WD) = 
m∈D α(m).
Let X0 = F(X) and β0(m) = WDm
 X0. By deﬁnition, (X0, β0) is a sub-
space of P. In order to prove that (X0, β0) is computably homeomorphic to
(X, α) we show that F −1 : (X0, β0) →(X, α) is computable. For that we
check F(α(m)) = W{m}
 X0. The inclusion F(α(m)) ⊆W{m}
 X0 is trivial.
Let us show the inclusion F(α(m))⊇W{m}
 X0. Let I ∈W{m}
 X0, i.e., m ∈I
and I ∈X0. Since I ∈X0, by deﬁnition, there exists x ∈X that F(x) = I, so
I = Ax. Since m ∈Ax, x ∈α(m), so I ∈F(α(m)).
Now we show that X0 ∈Δ1
1[P]. Since (X0, β0) is computably homeomorphic
to (X, α), {Px | x ∈X0} ∈Δ1
1[C] = Δ1
1[P]. For x ∈P, we have
x ∈X0 ↔
(∃I ∈{Py | y ∈X0}) I = Px ↔
(∃I ∈{Py | y ∈P}) (∀n ∈ω)

x ∈β(n) ↔n ∈I

and
x ∉X0 ↔
(∃I ∈{Py | y ∈P})

I = Px ∧I ∉{Py | y ∈X0}

.
Therefore X0 ∈Δ1
1[C] = Δ1
1[P].
⊓⊔

On Higher Eﬀective Descriptive Set Theory
287
Taking into account results from [2], where the class of quasi-Polish spaces has
been introduced, we deﬁne in a natural way the notion of a computable quasi-
Polish space.
Deﬁnition 7. The space (X, α) is called computable quasi-Polish if it is com-
putably homeomorphic to some (X0, β0) < (P, β) with
X0 ∈Π0
2[P].
Now we show that there exists X ∈K that is not computable quasi-Polish.
Proposition 3. Let (X, α) be a computable quasi-Polish space. Then
{Ax | x ∈X} ∈Π0
3[C]

Π0
4[P].
Proof. It is suﬃcient to consider (X0, β0) < (P, β). Let us recall AI = {n |
Dn ⊆I}, where I ∈X0 and Dn is ﬁnite. Assume that X0 ∈Π0
2[P]. This means that
X0 = 
n∈ω En, where {En}n∈ω is an eﬀective sequence of boolean combinations
of eﬀectively open sets in P. Let us observe that if we denote An ⇌{Ax | x ∈En}
then A ⇌{Ax | x ∈X} = 
n∈ω An. Therefore, it is suﬃcient to understand the
level of {Ax | x ∈β(i)}. Since Bi ⇌{Ax | x ∈β(i)} = {{n | Dn ⊆x} | x ⊇Di}, by
a routine computation it can be shown that {Bi}i∈ω is a computable sequence
of Π0
1[C]–sets (Π0
2[P]–sets). Finally, An is a boolean combination of Σ0
2[C]–sets
(Π0
3[P]–sets). Therefore A ∈Π0
3[C] (A ∈Π0
4[P]).
⊓⊔
Theorem 2. 1. There exists a space from the class K which is not computable
quasi-Polish.
2. There exists a perfect space from the class K which is not computable quasi-
Polish.
Proof. We use the notations from the proposition above.
1. Let us consider (X0, β0) < (P, β) such that X0 ∈Δ1
1[C]	Π0
4[C]. Such space
exist since eﬀective hierarchies on C are strict. We take the function F : P
1−1
−−→P
deﬁned by the rule F(x) = Ax. The function F is eﬀectively continuous, i.e.
computable. Therefore this function is continuous and computable from C to P.
It is clear that if I ∈Π0
4[P] then F −1(I) ∈Π0
4[C]. Now if we assume that X0 is
quasi-Polish then by Proposition 3 {Ax | x ∈X0} ∈Π0
4[P]. So X0 = F −1({Ax |
x ∈X0}) ∈Π0
4[C]. This leads to a contradiction.
2. In order to construct a perfect space we consider
˜
X0 = {2 · I | I ∈X0}.
Take X∗
0 = {I ⊕J | I ∈X0, J ⊆ω}. It is easy to see that X∗
0 is computably
homeomorphic to ˜
X0 × P(2 · ω + 1). So X∗
0 ∈K is perfect but not computable
quasi-Polish.
⊓⊔
5
(α, m)–Retractive Morphisms
In this section we assume that all our spaces belong to the class K. We introduce
a useful tool that provides a fruitful technique to get eﬀective versions of classical
theorems from DST that hold for all spaces from K.

288
M. Korovina and O. Kudinov
Deﬁnition 8. Let f : X →Y and g : Y →X, where (X, α) ∈K and (Y, γ) ∈K.
The pair (f, g) is called a (α, m)–retractive morphism from X to Y (denoted by
X
f⇀
↩
g
Y ) if the following conditions hold.
1. f ◦g = idY ,
2. dom(f) ∈Σ0
α[X],
3. f −1(γ(m)) = 
i∈Im α(i)  dom(f), where Im is a computable sequence of c.e.
sets,
4. For On = αe
X(n), {g−1(On)}n∈ω is a computable sequence of elements of
Σ0
m+1[X], i.e., 
n∈ω{n} × g−1(On) ∈Σ0
m+1[ω × X].
Remark 2. The mappings f and g are eﬀective Borel functions, i.e., their preim-
ages of eﬀectively open sets are eﬀective Borel sets [13,18]. From the ﬁrst condi-
tion it follows that the function f is onto and the function g is a total injection
the third condition corresponds to the eﬀective continuity of f.
Remark 3. The notion of a computable sequence of elements of Σ0
m[X] can be
deﬁned in terms of good parametrisations for Σ0
m[X] (see e.g. [13]).
Lemma 2. Let X
f1
⇀
↩
g1
X1
f2
⇀
↩
g2
X2, where (f1, g1) is an (α, n)–retractive morphism
from X to X1 and (f2, g2) is a (β, m)–retractive morphism from X1 to X2 then
there exist ordinals γ < ωCK1 and k < ω such that (f2 ◦f1, g1 ◦g2) is a (γ, k)–
retractive morphism from X to X2. The ordinal k can be chosen as n + m.
Lemma 3. Let X
f1
⇀
↩
g1
Y0
ϕ−1
⇀
↩
ϕ
Y, where Y0 ⊆P is a computable homeomorphic
copy of Y under ϕ, (f, g) is an (α, n)-retractive morphism between X and Y .
Then (ϕ−1 ◦f, g ◦ϕ) is an (α, n)-retractive morphism between X and Y .
Theorem 3. For any space Y ∈K there exists an (α, 1)–retractive morphism
from N to Y for some ordinal α < ωCK
1 .
Proof. By Theorem 1 and Lemma 3, without loss of generality we assume that
Y ∈Δ1
1[P]. A required (α, 1)–retractive morphism from N to Y is the composition
of the following (α, 1)–retractive morphisms:
N
f1
⇀
↩
g1
C
f2
⇀
↩
g2
P
f3
⇀
↩
g3
Y,
where the functions are deﬁned as follows.
1. The function f1 and g1 are standard well known computable mappings:
f(χ)(n) = χ(n) mod 2 and g = id.
2. Put f2 = id and g2 = id.
3. Put f3 =

x, x ∈Y
↑, x ∉Y
and g3 = id.

On Higher Eﬀective Descriptive Set Theory
289
The functions satisfy the requirements of Deﬁnition 8. Let us show non-trivial
parts. It is easy to see that
g−1
2 (αC(n)) = {f | (∀j ∈D2)f(j) = 1}	{f | (∀i ∈D1)f(i) = 1},
where αC(n) = {f : ω →{0, 1} | (∀i ∈D1)f(i) = 0 ∧(∀j ∈D2)f(j) = 1} for some
ﬁnite sets D1 and D2 such that D1
 D2 = ∅. Therefore, g−1
2 (αC(n)) ∈Δ0
2[P]
uniformly in n. Since Y ∈Δ1
1[P] = Δ1
1[C] and the Suslin-Kleene Theorem holds
for all perfect computable Polish spaces (see e.g. [18]), Y ∈Σ0
α[C]. So, Y ∈Σ0
α′[P]
for some α′ ≥α.
⊓⊔
Proposition 4. Let Y ∈K and N
f⇀
↩
g
Y be an (α, 1)–retractive morphism from
N to Y . For any A ∈Π1
1[Y ], g(A) ∈Π1
1[N].
Proof. By the deﬁnition of (f, g), g(A) = f −1(A)  g(Y ). Let us denote Y0 =
g(Y ) and assume A ∈Π1
1[Y ]. Since f is an eﬀective Borel function, f −1(A) ∈
Π1
1[N]. It is easy to see that since {(x, y) | x = y} ∈Π0
2[X × X], Y0 = {x ∈N |
g(f(x)) = x} ∈Π0
α′ for some α′ ≥α, Therefore, g(A) ∈Π1
1[N].
⊓⊔
Proposition 5. Let X ∈K and B ∈Δ1
1[X × X]. Then A = prX(B) ∈Σ1
1[X].
Proof. Let us ﬁx an (α, 1)–retractive morphism N
f⇀
↩
g
X. Put B′ = {(x, y) ∈X ×
N | B(x, f(y))}. It is clear that B ∈Σ0
α[X × N] for some α < ωCK
1 . Let us show
that x ∈A ↔(∃y ∈N)B′(x, y).
(→). Assume B(x, z) for some z ∈X. Put y = g(z). By deﬁnition, f(y) = z. We
have B(x, f(y)), i.e. B′(x, y).
(←). Assume B′(x, y), i.e. B(x, f(y)) for some y ∈N. Put z = f(y). Then B(x, z),
i.e. x ∈A. So, the projections of Σ1
1–sets along X are again Σ1
1–sets.
⊓⊔
6
Transferring EDST Theorems
In this section we show how (α, m)–retractive morphisms can be used to make
an eﬀectivisation of classical results from DST that hold on the spaces from this
class K. The following proposition is an extension of the classical Suslin-Kleene
Theorem.
Theorem 4. For any Y ∈K,
Δ1
1[Y ] =

α<ωCK
1
Σ0
α[Y ].
Proof. The inclusion Δ1
1⊇
α<ωCK
1 Σ0
α follows from the observation that Σ1
1[Y ] is
closed under eﬀective inﬁnite unions, intersections. In order to show the inclu-
sion Δ1
1 ⊆
α<ωCK
1 Σ0
α let us ﬁx an (α, 1)–retractive morphism N
f⇀
↩
g
Y. Let us

290
M. Korovina and O. Kudinov
denote Y0 = g(Y ) and assume A ∈Δ1
1[Y ]. Since f is an eﬀective Borel func-
tion, f −1(A) ∈Δ1
1[N]. By the Suslin-Kleene Theorem for N there exists a com-
putable ordinal α such that f −1(A) ∈Δ0
α[N]. Since f −1(A)  g(Y ) = g(A),
{(x, y) | x = y} ∈Π0
2[X × X], Y0 = {x ∈N | g(f(x)) = x} ∈Π0
α′[N] for some
ordinal α′ ≥α, Therefore, f −1(A)  g(Y ) ∈Σ0
β[N] for some β ≥α. Finally,
g−1(f −1(A)  g(Y )) = A. Therefore, A ∈Σ0
γ[X] for some γ < ωCK
1 .
⊓⊔
The following proposition is an extension of the classical Novikov-Kondo-
Addison Uniformisation Theorem.
Theorem 5 (Uniformisation). Let X ∈K. If Y ∈Π1
1[X × X] then there exists
a function F : X →X such that
1. The graph ΓF of the function F is a subset of Y.
2. δ(F) = δ(Y ) = {x | (∃y ∈X) (x, y) ∈Y },
3. ΓF ∈Π1
1[X × X].
Proof. Let us ﬁx an (α, 1)–retractive morphism N
f⇀
↩
g
Y. Let Y ∈Π1
1[X]. By
Proposition 4, g(Y ) ∈Π1
1[N]. From the Novikov-Kondo-Addison Theorem for N
it follows that there exists G that is a Π1
1–uniformisation of g(Y ). Put F =
g−1(G). Since g is an eﬀective Borel function and a bijection between Y and
g(Y ), ΓF ∈Π1
1[X] and F is a required function.
⊓⊔
References
1. Becher, V., Heiber, P., Slaman, T.A.: Normal numbers and the Borel hierarchy.
Fundamenta Mathematicae 22, 63–77 (2014)
2. de Brecht, M.: Quasi-Polish spaces. Ann. Pure Appl. Logic 164, 356–381 (2013)
3. Gao, S.: Invariant Descriptive Set Theory. CRC Press, New York (2009)
4. Gregoriades, V., Kispeter, T., Pauly, A.: A comparison of concepts from com-
putable analysis and eﬀective descriptive set theory. Math. Struct. Comput. Sci.
1–23 (2016). https://doi.org/10.1017/S0960129516000128. (Published online: 23
June 2016)
5. Kechris, A.S.: Classical Descriptive Set Theory. Springer, New York (1995)
6. Korovina, M., Kudinov, O.: Complexity for partial computable functions over
computable Polish spaces. Math. Struct. Comput. Sci. (2016). doi:10.1017/
S0960129516000438. (Published online: 19 December 2016)
7. Korovina, M., Kudinov, O.: Index sets as a measure of continuous constraint com-
plexity. In: Voronkov, A., Virbitskaite, I. (eds.) PSI 2014. LNCS, vol. 8974, pp.
201–215. Springer, Heidelberg (2015). doi:10.1007/978-3-662-46823-4 17
8. Korovina, M., Kudinov, O.: Towards computability over eﬀectively enumerable
topological spaces. Electr. Notes Theor. Comput. Sci. 221, 115–125 (2008)
9. Korovina, M., Kudinov, O.: Towards computability of higher type continuous data.
In: Cooper, S.B., L¨owe, B., Torenvliet, L. (eds.) CiE 2005. LNCS, vol. 3526, pp.
235–241. Springer, Heidelberg (2005). doi:10.1007/11494645 30
10. Louveau, A.: Recursivity and compactness. In: M¨uller, G.H., Scott, D.S. (eds.)
Higher Set Theory. LNM, vol. 669, pp. 303–337. Springer, Heidelberg (1978).
doi:10.1007/BFb0103106

On Higher Eﬀective Descriptive Set Theory
291
11. Montalban, A., Nies, A.: Borel structures: a brief survey. Lect. Notes Logic 41,
124–134 (2013)
12. Moschovakis, Y.N.: Descriptive Set Theory. Studies in Logic Series. North Holland,
Amsterdam (1980)
13. Moschovakis, Y.N.: Descriptive Set Theory, 2nd edn. North-Holland, Amsterdam
(2009)
14. Rogers, H.: Theory of Recursive Functions and Eﬀective Computability. McGraw-
Hill, New York (1967)
15. Soare, R.I.: Recursively Enumerable Sets and Degrees: A Study of Computable
Functions and Computably Generated Sets. Springer Science and Business Media,
Heidelberg (1987)
16. Spreen, D.: On eﬀective topological spaces. J. Symb. Log. 63(1), 185–221 (1998)
17. Selivanov, V.L.: Towards a descriptive set theory for domain-like structures. Theor.
Comput. Sci. 365(3), 258–282 (2006)
18. Selivanov, V.: Towards the eﬀective descriptive set theory. In: Beckmann, A.,
Mitrana, V., Soskova, M. (eds.) CiE 2015. LNCS, vol. 9136, pp. 324–333. Springer,
Cham (2015). doi:10.1007/978-3-319-20028-6 33
19. Weihrauch, K.: Computable Analysis. Springer, Heidelberg (2000)

Σμ
2 is decidable for Πμ
2
Karoliina Lehtinen1,3(B) and Sandra Quickert2,3
1 University of Kiel, Kiel, Germany
kleh@informatik.uni-kiel.de
2 University of St. Andrews, St. Andrews, UK
sq21@st-andrews.ac.uk
3 University of Edinburgh, Edinburgh, UK
Abstract. Given a Πµ
2 formula of the modal μ calculus, it is decidable
whether it is equivalent to a Σµ
2 formula.
1
Introduction
The modal μ calculus, Lμ, is a well-established veriﬁcation logic describing prop-
erties of labelled transition systems. It consists of a simple modal logic, aug-
mented with the least ﬁxpoint μ and its dual, the greatest ﬁxpoint ν. Alternations
between μ and ν are key for measuring complexity: the fewer alternations, the
easier a formula is to model check. We call this the formula’s index. For any ﬁxed
index, the model-checking problem is in P. However, no ﬁxed index is suﬃcient
to capture all properties expressible in Lμ [1,3,14], and it is notoriously diﬃcult
to decide whether a formula can be simpliﬁed. So far only properties expressible
without ﬁxpoints [21], or with only one type of ﬁxpoint [10] are known to be
decidable.
In automata theory, the corresponding index problem is to decide the simplest
acceptance condition suﬃcient to express a property with a speciﬁed type of
automata. This is often referred to as the Mostowski-Rabin index of a language.
Given a deterministic automaton on labelled binary trees, the minimal index
of equivalent deterministic [18], non-deterministic [20,24], and alternating [19]
automata are all known to be decidable. In [7] these results were extended
to show that the non-deterministic and alternating index problems are also
decidable for languages of labelled binary trees recognised by game-automata, a
slightly more general model than deterministic automata.
For the case of non-deterministic automata, the index problem reduces to the
uniform universality of distance parity automata [5]. In [4] it was shown that
given a B¨uchi deﬁnable language L, it is decidable whether it can be described
by an alternating co-B¨uchi automaton. Skrzypczak and Walukiewicz [23] give an
alternative proof of the same result and add a topological characterisation of the
recognised languages. A B¨uchi deﬁnable language which is co-B¨uchi is said to
be weakly deﬁnable: it is deﬁnable in weak monadic second order logic [22], and
equivalently, by an alternating automaton which is simultaneously both B¨uchi
and co-B¨uchi. In Lμ terms, this result corresponds to deciding whether a formula
in the class Πμ
2 is equivalent on binary trees to a formula in the class Σμ
2 .
c
⃝Springer International Publishing AG 2017
J. Kari et al. (Eds.): CiE 2017, LNCS 10307, pp. 292–303, 2017.
DOI: 10.1007/978-3-319-58741-7 28

Σµ
2 is decidable for Πµ
2
293
This paper provides a novel proof of the same result extended to arbitrary
structures: given a Πμ
2 formula, it is decidable whether it is equivalent to a Σμ
2
formula. The proof deﬁnes an n-parametrised game such that the decidability of
Σμ
2 reduces to deciding whether for some n this is the model-checking game for
a formula. From this game, we derive a family Ψ n of Σμ
2 formulas, such that an
input formula Ψ is equivalent to a Σμ
2 formula if and only if it is equivalent to
some formula in this family. To decide the parameter n for Πμ
2 input formulas,
we simply argue that the game construction in [23], designed for binary trees,
extends to the case of labelled transition systems.
We consider the most interesting contributions of this paper to be the reduc-
tion of the decidability of Σμ
2 to ﬁnding the parameter n such that Ψ is equivalent
to Ψ n. With this result, ﬁnding a way to generalise the game construction from
[23] to arbitrary inputs would suﬃce to decide Σμ
2 .
All the proofs omitted here can be found in the technical report [13].
2
Preliminaries
2.1
Lµ
Let us ﬁx, once and for all a ﬁnite set of actions Act = {a, b, ...}, a countably
inﬁnite set of propositional variables Prop = {P, Q, ...}, and ﬁxpoint variables
Var = {X, Y, ...}. A literal is either P or ¬P for P ∈Prop.
Deﬁnition 1 (Labelled transition tree). A labelled transition tree is a structure
T = (V, vr, E, L, P) where V is a set of states, vr is the root, the only node with-
out predecessor, E ⊂V × V is an edge relation, L : E →Act labels edges with
actions and P : V →2Prop labels vertices with propositional variables. Further-
more, for each v ∈V the set of ancestors {w ∈V | ∃w1 . . . wk. wEw1E . . . wkEv}
is ﬁnite and well-ordered with respect to the transitive closure of E; the set of
successors {w ∈V | vEw} is also ﬁnite.
We can represent repetition in an inﬁnite tree with back edges. Note that we
allow more than one successor per label.
Deﬁnition 2 (Modal μ). The syntax of Lμ is given by:
φ := P / X / ¬P / φ ∧φ / φ ∨φ / ⟨a⟩φ / [a]φ / μX.φ / νX.φ / ⊥/ ⊤
The order of operator precedence is [a], ⟨a⟩, ∧, ∨, μ and ν.
The operators ⟨a⟩and [a] are called modalities, and formulas ⟨a⟩φ and [a]φ
are called modal formulas. If ψ = μX.φ or ψ = νX.φ, we call the formula φ
the binding formula of X within ψ and denote it by φX. We say that φ′ is an
immediate subformula of φ if either φ is built from φ′ in one step using the syntax
rules above, or, in a slight abuse of notation, if φ = X and φ′ its binding formula.
Hence φ is an immediate subformula of the formulas φ ∨ψ, ⟨a⟩φ, μX.φ and also
of X in νX.φ. A formula is guarded if every ﬁxpoint variable is in the scope
of a modality within its binding. Without loss of expressivity [9,15], we restrict

294
K. Lehtinen and S. Quickert
ourselves to Lμ in guarded positive form. We will also assume throughout the
paper that all ﬁxpoint variables within a formula have distinct names.
The semantics of Lμ are standard, see for example [2]. We now deﬁne the
priority assignment and index of a formula, following Niwi´nski’s notion of alter-
nation in [17].
Deﬁnition 3 (Priority assignment, index and alternation classes). A priority
assignment Ω is a function assigning an integer value to each ﬁxpoint variable
in a formula such that: (a) μ-bound variables receive odd priorities and ν-bound
variables receive even priorities, and (b) if X is free in φY , the binding formula
of Y , then Ω(X) ≥Ω(Y ). A formula has index {q, ..., i} where i ∈{0, 1} if it
has a priority assignment with co-domain {q, ..., i}.
Formulas without ﬁxpoints form the modal fragment of Lμ. Formulas with one
type of ﬁxpoint have index {0} or {1}, corresponding to the alternation classes
Πμ
1 and Σμ
1 , respectively. Then the class Πμ
i and Σμ
i for even i correspond to
formulas with indices {i, ..., 1} and {i −1, ..., 0}, respectively, while for odd i
they correspond formulas with indices {i −1, ..., 0} and {i, ..., 1}, respectively. A
formula has semantic alternation class C if it is equivalent to a formula in C.
Example 1. The formula μX.νY.□Y ∧μZ.□(X ∨Z) accepts the priority assign-
ment Ω(X) = 1, Ω(Y ) = 0 and Ω(Z) = 1, so it has index {1, 0} and is in the
class Σμ
2 . However, it is equivalent to μX.□X which holds in structures without
inﬁnite paths, and is therefore semantically in Σμ
1 .
In this paper we present a new proof that Σμ
2 is decidable for formulas in
Πμ
2 : given an arbitrary Lμ formula Ψ with index {2, 1}, it is decidable whether
Ψ is equivalent to a formula with index {1, 0}.
2.2
Parity Games
The semantics of Lμ formulas (like that of alternating parity automata) can be
described in terms of winning regions of parity games.
Deﬁnition 4. A parity game G = (V, vi, E, Ω) consists of a set of vertices V
partitioned into those belonging to Even, Ve, and those belonging to Odd, Vo, an
initial position vi ∈V , and a set of edges E ∈V × V . A priority assignment Ω
assigns a priority to every vertex.
At each turn, the player who owns the current position v chooses a successor
position from the successors of v via E. A play is a potentially inﬁnite sequence
of positions starting at the initial position vi. A ﬁnite play is winning for Even
if the ﬁnal position has even priority, and for Odd otherwise. An inﬁnite play is
winning for the player of the parity of the highest priority seen inﬁnitely often.
Parity games are known to be determined and we can restrict ourselves to
positional winning strategies [6,16]. It is a standard result that given a structure
M and a formula Ψ, there is a model-checking parity game M × Ψ such that
Even wins if and only if M satisﬁes Ψ [26].

Σµ
2 is decidable for Πµ
2
295
Deﬁnition 5 (The model-checking game M×Ψ ). The parity game M×Ψ has
for states s × φ where s is a state of M and φ is a subformula of Ψ. There is an
edge from s×ψ to s×φ if φ is an immediate subformula of a non-modal formula
ψ; there is an edge from s×⟨a⟩φ and s×[a]φ to s′ ×φ for s′ an a-successor of s.
Positions s × φ where φ is a disjunction or starting with an existential modality
⟨a⟩belong to Even while those where φ is a conjunction or universal modality
[a] belong to Odd. Positions with a single successor are given to Even, although
the game is deterministic at those. The priority assignment is inherited from
the priority assignment ΩΨ on Ψ: a ﬁxpoint variable X receives priority ΩΨ(X)
while other nodes receive the minimal priority in the co-domain of ΩΨ.
2.3
Disjunctive Form
Disjunctive Lμ is a fragment restricting conjunctions in a way reminiscent of
non-deterministic automata [25]. Its use is key to several of our proofs.
Deﬁnition 6 (Disjunctive formulas). The set of disjunctive form formulas of
Lμ is the smallest set F satisfying:
– ⊤,⊥, ﬁxpoint variables and ﬁnite sets (conjunctions) of literals are in F;
– If ψ ∈F and φ ∈F, then ψ ∨φ ∈F;
– If for each a in Act the set Ba ⊆F is a ﬁnite set of formulas, and if A is
a ﬁnite set of literals, then A ∧
a∈Act
a−→Ba ∈F where
a−→Ba is short for
(
ψ∈Ba⟨a⟩ψ)∧[a] 
ψ∈Ba ψ – that is to say, every formula in Ba holds at least
one successor and at every successor at least one of the formulas in Ba holds;
– μX.ψ and νX.ψ are in F as long as ψ ∈F.
Every formula is known to be equivalent to an eﬀectively computable formula
in disjunctive form [25]. The transformation preserves guardedness.
Given an Lμ formula with unrestricted conjunctions, the model-checking par-
ity game requires Even to have a strategy to verify both conjuncts. A strategy
for Even will agree with the plays corresponding to each of Odd’s choices, lead-
ing potentially to several plays on some branches. In contrast, disjunctive form
restricts conjunctions, and the only branching in Even’s strategies is at a posi-
tion where the formula is of the form A∧
a∈Act
a−→Ba ∈F, called an Odd-choice
formula.
Disjunctive form guarantees that Even can use strategies which only agree
with one play per branch. For further details, see [12].
Lemma 1. [12] Given a disjunctive formula Ψ, for any structure M and strat-
egy σ in M × Ψ, there is a structure M′ bisimilar to M such that a strategy σ′
in M′ × Ψ induced from σ only agrees with one play per branch. We then say
that M′ and σ′ are well-behaved.
Lemma 2. Given a Πμ
2 formula, the transformation into disjunctive form as
presented in [25] yields a disjunctive Πμ
2 formula.

296
K. Lehtinen and S. Quickert
This can be proved using the concepts of tableau, tableau equivalence, and
traces from [25]. The crux of the argument is that the tableau of a disjunctive
formula not in Πμ
2 must have an even cycle nested in an odd cycle which in turn
implies the existence of a trace on which a μ-ﬁxpoint dominates a ν ﬁxpoint in
any equivalent tableau. The proof can be found in the technical report [13].
Note that the dual is not true: a Σμ
2 formula may yield a formula of arbitrarily
large alternation depth when turned into disjunctive form [11]. This is in line
with alternating B¨uchi automata being equivalent to non-deterministic B¨uchi
automata while the same is not necessarily true for co-B¨uchi automata.
2.4
Automata and Lµ
The relationship between Lμ and automata theory is based on the fact that the
automata model that Lμ formulas correspond to is, when restricted to binary
trees1, equivalent to alternating automata with a parity condition [8]. The model-
checking problems in these two settings are equivalent: Model-checking a formula
ψ on a structure M reduces to checking an automaton A(ψ) on a binary tree
encoding of M. Model checking disjunctive Lμ similarly reduces to model check-
ing non-deterministic automata, albeit one of potentially higher index. For the
index problem, the comparison is not as simple and to the best of our knowl-
edge there is no known reduction from the (disjunctive) Lμ index problem to
the (non-deterministic) automata index problem. Part of the diﬃculty is that
only considering binary trees aﬀects the semantic complexity of formulas: for
example, the formula ⟨a⟩ψ ∧⟨a⟩¯ψ (where ¯ψ is the negation of ψ) is semantically
trivial when interpreted on trees with only one a-successor while in the general
case its index depends on ψ. Furthermore, non-deterministic parity automata
are weaker than disjunctive Lμ in the sense that some properties of binary trees
can be expressed with a lower index using disjunctive form.
3
Deciding Σµ
2 Reduces to a Bounding Problem
The ﬁrst part of the proof of our main result deﬁnes a parametrised n-challenge
game on a parity game arena. For each ﬁnite n, the n-challenge game is described
by a Σμ
2 formula Ψ n which holds in M if and only if Even wins the n-challenge
game on M × Ψ. We then show that a disjunctive formula Ψ is equivalent to a
(not necessarily disjunctive) formula in Σμ
2 if and only if there is some n such
that Ψ is equivalent to Ψ n. As any formula can be turned into disjunctive form,
this reduces the decidability of Σμ
2 to bounding the parameter n. For the main
result of this paper, we will only use this construction for Πμ
2 input formulas
to determine equivalence to a Σμ
2 formula. However, using this more general
construction, a generalisation of the second part of our proof beyond Πμ
2 would
suﬃce to decide Σμ
2 entirely.
1 assuming |Act| = 2; otherwise trees with one successor per label.

Σµ
2 is decidable for Πµ
2
297
When restricted to automata on binary trees and two priorities, this con-
struction is equivalent to those found for example in [4,23].
We ﬁx a disjunctive formula Ψ with index {q, ..., 0}. Let I = {q, ..., 0} if the
maximal priority q is even and {q + 1, q, ..., 0} otherwise. Write Ie for the even
priorities in I. The n-challenge game consists of a normal parity game augmented
with a set of challenges, one for each even priority i. A challenge can either be
open or met and has a counter ci attached to it. Each counter is initialised to n,
and decremented when the corresponding challenge is opened. The Odd player
can at any point open challenges of which the counter is non-zero, but he must
do so in decreasing order: an i-challenge can only be opened if every j-challenge
for j > i is opened. When a play encounters a priority greater or equal to j while
the j-challenge is open, the challenge is said to be met. All i-challenges for i < j
are reset. This means that the counters ci are set back to n.
A play of this game is a play in a parity game, augmented with the challenge
and counter conﬁguration at each step. A play with dominant priority d is win-
ning for Even if either d is even or if every opened d + 1 challenge is eventually
met or reset.
Example 2. The formula νY.μX.(A ∧♦X) ∨(B ∧♦Y ) is true if on some path B
always eventually holds. This formula does not hold in this structure:
A
start
B
A
B
A
However, Even wins the 1- and 2-challenge games: her strategy is to loop
in the current state until Odd opens a 2-challenge, then meet the challenge by
moving to the next state, as seeing a B corresponds to seeing 2. Odd will run out
of challenges before reaching the last state. Although Odd wins the 3-challenge
game in this structure, for any n it is easy to construct a similar structure in
which he loses the n-challenge game but wins the parity game. This section
argues that this is suﬃcient to show that νY.μX.(A ∧♦X) ∨(B ∧♦Y ) is not
equivalent to any Σμ
2 formula.
In contrast, in the formula νY.μX.(A ∧□X) ∨(B ∧♦Y ), Odd wins the 1-
challenge game whenever he wins the parity game: he can open the challenge
when his strategy in the parity game reaches the point at which he can avoid
B. This formula is therefore equivalent to a Σμ
2 formula, namely the alternation
free formulas νY.((A ∧□Y ) ∨(B ∧♦Y )) ∧μX.(A ∧□X) ∨B).
Deﬁnition 7. A conﬁguration (v, p, ¯c, r) of the n-challenge game on a parity
game G of index {q, ..., 0} where q is even consists of:
– a position v in the parity game;

298
K. Lehtinen and S. Quickert
– an even priority p indicating the least signiﬁcant priority on which a challenge
is open or p = q + 2 if all challenges are currently met;
– ¯c = (c0, c2, . . . , cq) a collection of counter values ci for each even priority i.
– r ∈{0, 1} indicating the round of the game: 1 for Odd’s turn to open chal-
lenges, 0 for a turn in the parity game.
At a conﬁguration (v, p, ¯c, 1), corresponding to Odd’s turn, he can open chal-
lenges up to any p′ ≤p, as long as c[i] > 0 for each i such that p′ ≤i < p. Then
the conﬁguration becomes (v, p′, ¯c′, 0) where c′[i] = c[i] −1 for all newly opened
challenges i, that is to say i such that p′ ≤i < p and c′[i] = c[i] for all other i.
At the conﬁguration (v, p, ¯c, 0), the player whose turn it is in the parity
game decides the successor position v′ of v and the conﬁguration is updated
to (v′, p′, ¯c′, 1) according to the priority i of v′ as follows:
– If i ≥p then p′ = i + 2 if i is even, p′ = i + 1 otherwise. This indicates which
challenges have been met. Note that if all challenges are met, p = q + 2.
– For each j < i, the counter value cj is reset to n.
– If i is even and ci = 0, then the game ends immediately with a win for Even.
A play is a potentially inﬁnite sequence of conﬁgurations starting at the ini-
tial conﬁguration (vι, q + 2, (n, ..., n), 1), where vι is the initial position of the
parity game. An inﬁnite play is winning for Even if the dominant priority on
the sequence of parity game positions is d but the game reaches inﬁnitely many
conﬁgurations (v, p, ¯c, 0) where p > d + 1. This is the case if d is even or if all
d + 1 challenges set by Odd are either met or reset.
A strategy for Odd in a challenge game consists of two parts: a strategy which
dictates when to open challenges, and a regular parity-game strategy which dic-
tates his moves in the underlying parity game. Even only has a parity game
strategy. Both players’ strategies may of course depend on the challenge conﬁgu-
ration as well as the parity game conﬁguration. Given a challenge-game strategy
for even σ, a challenging strategy γ for Odd induces a normal parity game strat-
egy σγ for Even which does not depend on the challenge conﬁguration.
We ﬁrst establish that the winning regions of the n-challenge games for Ψ
can be described by a Σμ
2 formula Ψ n.
Lemma 3. For all Ψ and ﬁnite n, there is a formula Ψ n ∈Σμ
2 which holds in
M if and only if Even wins the n-challenge game on M × Ψ.
This lemma can be proven by describing explicitly an alternating parity
automaton computing winning regions of the above mentioned n-challenge game.
The automaton can be deﬁned in a way that it only uses priorities 0 and 1, and
therefore corresponds to a formula in Σμ
2 which is the formula Ψ n as required.
The proof can be found in the technical report [13].
Next we prove our core theorem, reducing the decidability of Σμ
2 to a bound-
edness criterion.
Theorem 1. If a disjunctive formula Ψ is semantically in Σμ
2 , then there is a
ﬁnite n such that Ψ ⇔Ψ n.

Σµ
2 is decidable for Πµ
2
299
Proof. Assume that Ψ is semantically in Σμ
2 , i.e. equivalent to some Φ of index
{1, 0}, and that for all n, Ψ ⇎Ψ n. Fix n to be larger than 2|Ψ|+|Φ|. There is a
structure M, such that Odd wins the parity game M × Ψ but Even wins the n-
challenge game on M×Ψ. W.l.o.g, take M to be ﬁnitely branching. The overall
structure of this proof is to ﬁrst use a winning strategy τ for Odd in M × Φ to
deﬁne a challenging strategy γ for him in the n-challenge game on M × Ψ (Part
I). We then use Even’s winning strategy σ to add back edges to M (Part II),
turning it into a new structure M′ which preserves Odd’s winning strategy τ
in M′ × Φ while turning σγ into a winning strategy in M′ × Ψ (Part III). This
contradicts the equivalence of Φ and Ψ.
Part I. Let τ be Odd’s winning strategy in M×Φ. Since M is ﬁnitely branching,
for any node v reachable via τ, there is a ﬁnite bound i such that any play that
agrees with τ sees 1 within i modal steps of any position v × α that it reaches
(K¨onig’s Lemma). For a branch b of M, on which τ reaches a node v, indicate
by next(b, v) the ith node on b from v. This node has the property that any play
on the branch b agreeing with τ must see a 1 between v and next(b, v).
If τ does not agree with any plays on the branch b, then let next(b, v) be a
node on b which τ does not reach.
Now consider the n-challenge game on M×Ψ. Let Odd’s challenging strategy
γ be: to open all challenges at the start of the game, and whenever its counter is
reset; if a challenge for a priority i is met at v, and its counter ci is not at 0, to
open the next challenge when the play reaches a node next(b, v) for any branch
b, unless the counter is reset before then (i.e. a higher priority is seen).
Part II. Even wins the n-challenge game on M × Ψ, so let σ be her winning
strategy. Recall that σγ is an Even’s strategy for Ψ up to the point where an nth
challenge in the original challenge game is met, and undeﬁned thereafter. Since
Ψ is disjunctive, we can adjust M into a bisimilar structure in which the pure
parity game strategy σγ is well-behaved wherever it is deﬁned – it reaches each
position of M at either one subformula, or none.
The strategy σγ is winning in the challenge game against any strategy for
Odd which uses the challenging strategy γ. Since Odd always eventually opens
the next challenge, the only way for him to lose is that the play either reaches a
position that is winning for Even in the parity game, or a position of priority p
when cp = 0. Thus, every play is ﬁnite.
Since σγ is well-behaved, each branch carries at most one play. For every
branch b the ﬁnite play it may carry must end either in an immediate win for
Even, or in a long streak in which the highest priority seen is some even p, and
it is seen at least n times, corresponding to every instance of Even meeting a
p-challenge. As long as n is suﬃciently large, on every such branch there are two
nodes v and its descendant w, at which Odd opens challenges on p, which agree
on the set of subformulas that σγ reaches there in M × Ψ and that τ reaches
there in M × Φ. We now consider the structure M′, which is as M except that
the predecessor of each w-node has an edge to v instead. The strategies σγ and
τ transfer in the obvious way to M′.

300
K. Lehtinen and S. Quickert
Part III. We now claim that τ is winning in M′ × Φ and that σγ is winning in
M′ ×Ψ. Starting with σγ, ﬁrst consider plays that do not go through back edges
inﬁnitely often. These are the ones that end in positions immediately winning
for Even. Any play in M × Ψ that agrees with σγ which sees both v and w is
dominated by an even priority between v and w. Then, as the w and v agree on
which subformula σγ reaches them at, an even priority dominates any play that
goes through back edges in M′ × Ψ inﬁnitely many times. The strategy σγ is
therefore winning in M′ × Ψ.
Now onto τ in M′ ×Φ. If a branch is unchanged by the transformation, then
any play on it is still winning for τ, because such a play would be consistent
with τ in the original game. If a branch that τ plays on has been changed, then
consider in M the two nodes v and w at which the transformation is done. These
both are nodes at which Odd opens challenges according to γ, therefore, from
the deﬁnition of next and γ, the highest priority seen between them by any play
agreeing with τ is 1. Since v and w agree on which subformulas τ reaches them
at, any play in M′ × Φ which goes through a back-edge inﬁnitely often sees 1
inﬁnitely often and is therefore winning for Odd.
This contradicts the equivalence of Ψ and Φ. Therefore, if Ψ is semantically
in Σμ
2 , then for all structures M the n-challenge game and the parity game on
M × Ψ have the same winner for n > 2|Φ|+|Ψ|.
Theorem 2. Let Ψ ∈Lμ, and Ψd a disjunctive formula equivalent to Ψ. Then
Ψ is semantically in Σμ
2 if and only if there is some ﬁnite n such that Ψ ⇔Ψ n
d .
4
Deciding Σµ
2 for Πµ
2
To complete the proof of the namesake result, it suﬃces to show that the para-
meter n from Theorem 2 can be bounded. If we restrict ourselves to disjunctive
Ψ ∈Πμ
2 , we argue that the tree-building game F from [23] extends to arbitrary
labelled transition systems and delivers such a bound.
Since the F game is already well-exposed in [23], and the adjustments to
cater for disjunctive Lμ and labelled transition systems are relatively straight-
forward but verbose, we omit the proof of the following theorem. The proof can
be found in the technical report [13].
Theorem 3. Let Ψ ∈Πμ
2 be disjunctive. Then there is a constant K0 com-
putable from Ψ such that the following statements are equivalent:
(a) There is some n such that Ψ ⇔Ψ n.
(b) Ψ ⇔Ψ K0
Placing everything together, we obtain our ﬁnal result.
Theorem 4. It is eﬀectively decidable whether any given Πμ
2 formula is equiv-
alent to a Σμ
2 formula. By duality, it is also eﬀectively decidable whether any
given Σμ
2 formula is equivalent to a Πμ
2 formula.

Σµ
2 is decidable for Πµ
2
301
Proof. Given any Πμ
2 formula Ψ, it can be eﬀectively turned into a disjunctive
formula Ψd also in Πμ
2 (Lemma 2). Then, Theorem 2 yields that Ψd is semantically
in Σμ
2 if and only if it is equivalent to Ψ n
d for some n. From Theorem 3, Ψd ⇔Ψ n
d
if and only if Ψd ⇔Ψ K0
d
where K0 is computable from Ψ via Ψd. Thus, Ψ is
semantically in Σμ
2 if and only if Ψ ⇔Ψ K0
d
if and only if Ψd ⇔Ψ K0
d
.
Given any Σμ
2 formula, it can also be decided whether it is equivalent to a
Πμ
2 formula, via checking whether its negation is equivalent to a Σμ
2 formula.
5
Discussion
We have shown that given any Lμ formula in Πμ
2 , it can be eﬀectively decided
whether it is equivalent to a Σμ
2 formula. This result is the Lμ-theoretic counter-
part of the decidability of weak deﬁnability of B¨uchi deﬁnable languages [4,23].
The core contribution is the reduction of the decidability of Σμ
2 for arbitrary Lμ
formulas to deciding whether the n-challenge game is equivalent to the model-
checking parity game of a formula for any n. We obtain a family of parameterised
Σμ
2 formulas Ψ n such that Ψ is in Σμ
2 if an only if Ψ is equivalent to Ψ n for some
n. Unfortunately, the second part of our proof, based on [23], is less general and
only admits input formulas in Πμ
2 . If this could also be generalised to arbitrary
formulas, this would yield a decidability proof for Σμ
2 .
The challenge game can be extended to constructions described by more com-
plex Lμ formulas – this may turn out to be the right way to characterize higher
alternation classes. However, for Theorem 1, if there are more than two priorities
at play, the diﬀerent plays along one branch become less manageable and it is
not clear how they can inform a challenging strategy. Even when restricted to
disjunctive formulas, a new technique seems to be required. However, the result
of [5] which achieves this for non-deterministic automata on binary trees justiﬁes
cautious optimism for the disjunctive case.
Achnowledgements. We thank the anonymous reviewers for their thoughtful com-
ments and corrections. The work presented here has been supported by an EPSRC
doctoral studentship at the University of Edinburgh.
References
1. Arnold, A.: The μ-calculus alternation-depth hierarchy is strict on binary trees.
RAIRO - Theoretical Informatics and Applications - Informatique Th´eorique et
Applications 33(4–5), 329–339 (1999)
2. Bradﬁeld, J.C., Stirling, C.: Modal mu-calculi. Handbook of modal logic 3, 721–756
(2007)
3. Bradﬁeld, J.C.: The modal mu-calculus alternation hierarchy is strict. In:
Montanari, U., Sassone, V. (eds.) CONCUR 1996. LNCS, vol. 1119, pp. 233–246.
Springer, Heidelberg (1996). doi:10.1007/3-540-61604-7 58
4. Colcombet, T., Kuperberg, D., L¨oding, C., Vanden Boom, M.: Deciding the weak
deﬁnability of B¨uchi deﬁnable tree languages. In: LIPIcs-Leibniz International Pro-
ceedings in Informatics, vol. 23. Schloss Dagstuhl-Leibniz-Zentrum fuer Informatik
(2013)

302
K. Lehtinen and S. Quickert
5. Colcombet, T., L¨oding, C.: The non-deterministic mostowski hierarchy and
distance-parity automata. In: Aceto, L., Damg˚ard, I., Goldberg, L.A., Halld´orsson,
M.M., Ing´olfsd´ottir, A., Walukiewicz, I. (eds.) ICALP 2008. LNCS, vol. 5126,
pp. 398–409. Springer, Heidelberg (2008). doi:10.1007/978-3-540-70583-3 33
6. Emerson, E.A., Jutla, C.S.: Tree automata, mu-calculus and determinacy. In: Pro-
ceedings of the 32nd Annual Symposium on Foundations of Computer Science,
FoCS 1991, pp. 368–377. IEEE Computer Society Press (1991)
7. Facchini, A., Murlak, F., Skrzypczak, M.: Rabin-mostowski index problem: a
step beyond deterministic automata. In: Proceedings of the 2013 28th Annual
ACM/IEEE Symposium on Logic in Computer Science, pp. 499–508. IEEE Com-
puter Society (2013)
8. Janin, D., Walukiewicz, I.: Automata for the modal μ-calculus and related results.
In: Wiedermann, J., H´ajek, P. (eds.) MFCS 1995. LNCS, vol. 969, pp. 552–562.
Springer, Heidelberg (1995). doi:10.1007/3-540-60246-1 160
9. Kupferman, O., Vardi, M.Y., Wolper, P.: An automata-theoretic approach to
branching-time model checking. J. ACM (JACM) 47(2), 312–360 (2000)
10. K¨usters, R., Wilke, T.: Deciding the ﬁrst level of the μ-calculus alternation hierar-
chy. In: Agrawal, M., Seth, A. (eds.) FSTTCS 2002. LNCS, vol. 2556, pp. 241–252.
Springer, Heidelberg (2002). doi:10.1007/3-540-36206-1 22
11. Lehtinen, K.: Disjunctive form and the modal μ alternation hierarchy. In: FICS
2015 The 10th International Workshop on Fixed Points in Computer Science,
EPTCS 191, p. 117 (2015)
12. Lehtinen, K., Quickert, S.: Deciding the ﬁrst levels of the modal mu alternation
hierarchy by formula construction. In: LIPIcs-Leibniz International Proceedings in
Informatics, vol. 1. Schloss Dagstuhl-Leibniz-Zentrum fuer Informatik (2015)
13. Lehtinen, M.K., Quickert, S.: Σµ
2 is decidable for Πµ
2 (extended version). Technical
report. arXiv:1703.03239
14. Lenzi, G.: A hierarchy theorem for the μ-calculus. In: Meyer, F., Monien, B. (eds.)
ICALP 1996. LNCS, vol. 1099, pp. 87–97. Springer, Heidelberg (1996). doi:10.
1007/3-540-61440-0 119
15. Mateescu, R.: Local model-checking of modal mu-calculus on acyclic labeled tran-
sition systems. In: Katoen, J.-P., Stevens, P. (eds.) TACAS 2002. LNCS, vol. 2280,
pp. 281–295. Springer, Heidelberg (2002). doi:10.1007/3-540-46002-0 20
16. Mostowski, A.W.: Games with forbidden sequences and ﬁnite machines. Technical
report 78, Instytut Matematyki, Uniwersytet Gda´nski, Poland (1991)
17. Niwi´nski, D.: On ﬁxed-point clones. In: Kott, L. (ed.) ICALP 1986. LNCS,
vol. 226, pp. 464–473. Springer, Heidelberg (1986). doi:10.1007/3-540-16761-7 96
18. Niwi´nski, D., Walukiewicz, I.: Relating hierarchies of word and tree automata.
In: Morvan, M., Meinel, C., Krob, D. (eds.) STACS 1998. LNCS, vol. 1373,
pp. 320–331. Springer, Heidelberg (1998). doi:10.1007/BFb0028571
19. Niwi´nski, D., Walukiewicz, I.: A gap property of deterministic tree languages.
Theor. Comput. Sci. 303(1), 215–231 (2003)
20. Niwi´nski, D., Walukiewicz, I.: Deciding nondeterministic hierarchy of deterministic
tree automata. Electron. Notes Theor. Comput. Sci. 123, 195–208 (2005)
21. Otto, M.: Eliminating recursion in the μ-calculus. In: Meinel, C., Tison, S. (eds.)
STACS 1999. LNCS, vol. 1563, pp. 531–540. Springer, Heidelberg (1999). doi:10.
1007/3-540-49116-3 50
22. Rabin, M.O.: Weakly deﬁnable relations and special automata. In: Bar-Hillel, Y.
(ed.) Mathematical Logic and Foundations of Set Theory, pp. 1–23 (1970)

Σµ
2 is decidable for Πµ
2
303
23. Skrzypczak, M., Walukiewicz, I.: Deciding the topological complexity of b¨uchi
languages. In: Rabani, Y., Chatzigiannakis, I., Mitzenmacher, M., Sangiorgi, D.
(eds.) 43rd International Colloquium on Automata, Languages, and Programming
(ICALP 2016), vol. 55, Leibniz International Proceedings in Informatics (LIPIcs),
pp. 99:1–99:13. Dagstuhl, Germany (2016). Schloss Dagstuhl-Leibniz-Zentrum fuer
Informatik
24. Urba´nski, T.F.: On deciding if deterministic rabin language is in b¨uchi class. In:
Montanari, U., Rolim, J.D.P., Welzl, E. (eds.) ICALP 2000. LNCS, vol. 1853,
pp. 663–674. Springer, Heidelberg (2000). doi:10.1007/3-540-45022-X 56
25. Walukiewicz, I.: Completeness of Kozen’s axiomatisation of the propositional μ-
calculus. Inf. Comput. 157(1–2), 142–182 (2000)
26. Wilke, T.: Alternating tree automata, parity games, and modal m-calculus. Bull.
Belg. Math. Soc. Simon Stevin 8(2), 359 (2001)

Dimension Spectra of Lines
Neil Lutz1 and D.M. Stull2(B)
1 Department of Computer Science, Rutgers University, Piscataway, NJ 08854, USA
njlutz@rutgers.edu
2 Department of Computer Science, Iowa State University, Ames, IA 50011, USA
dstull@iastate.edu
Abstract. This paper investigates the algorithmic dimension spectra of
lines in the Euclidean plane. Given any line L with slope a and vertical
intercept b, the dimension spectrum sp(L) is the set of all eﬀective Haus-
dorﬀdimensions of individual points on L. We draw on Kolmogorov com-
plexity and geometrical arguments to show that if the eﬀective Hausdorﬀ
dimension dim(a, b) is equal to the eﬀective packing dimension Dim(a, b),
then sp(L) contains a unit interval. We also show that, if the dimension
dim(a, b) is at least one, then sp(L) is inﬁnite. Together with previous
work, this implies that the dimension spectrum of any line is inﬁnite.
1
Introduction
Algorithmic dimensions reﬁne notions of algorithmic randomness to quantify
the density of algorithmic information of individual points in continuous spaces.
The most well-studied algorithmic dimensions for a point x ∈Rn are the eﬀec-
tive Hausdorﬀdimension, dim(x), and its dual, the eﬀective packing dimen-
sion, Dim(x) [1,7]. These dimensions are both algorithmically and geometrically
meaningful [3]. In particular, the quantities supx∈E dim(x) and supx∈E Dim(x)
are closely related to classical Hausdorﬀand packing dimensions of a set
E ⊆Rn [5,8], and this relationship has been used to prove nontrivial results
in classical fractal geometry using algorithmic information theory [8,10,12].
Given the pointwise nature of eﬀective Hausdorﬀdimension, it is natural
to investigate not only the supremum supx∈E dim(x) but the entire (eﬀective
Hausdorﬀ) dimension spectrum of a set E ⊆Rn, i.e., the set
sp(E) = {dim(x) : x ∈E} .
The dimension spectra of several classes of sets have been previously investigated.
Gu et al. studied the dimension spectra of randomly selected subfractals of self-
similar fractals [4]. Dougherty, et al. focused on the dimension spectra of random
N. Lutz—Research supported in part by National Science Foundation Grant
1445755.
D.M. Stull—Research supported in part by National Science Foundation Grants
1247051 and 1545028.
c
⃝Springer International Publishing AG 2017
J. Kari et al. (Eds.): CiE 2017, LNCS 10307, pp. 304–314, 2017.
DOI: 10.1007/978-3-319-58741-7 29

Dimension Spectra of Lines
305
translations of Cantor sets [2]. In the context of symbolic dynamics, Westrick
has studied the dimension spectra of subshifts [14].
This work concerns the dimension spectra of lines in the Euclidean plane R2.
Given a line La,b with slope a and vertical intercept b, we ask what sp(La,b)
might be. It was shown by Turetsky that, for every n ≥2, the set of all points
in Rn with eﬀective Hausdorﬀ1 is connected, guaranteeing that 1 ∈sp(La,b). In
recent work [10], we showed that the dimension spectrum of a line in R2 cannot
be a singleton. By proving a general lower bound on dim(x, ax + b), which is
presented as Theorem 5 here, we demonstrated that
min{1, dim(a, b)} + 1 ∈sp(La,b) .
Together with the fact that dim(a, b) = dim(a, a2 + b) ∈sp(La,b) and Turetsky’s
result, this implies that the dimension spectrum of La,b contains both endpoints
of the unit interval [min{1, dim(a, b)}, min{1, dim(a, b)} + 1].
Here we build on that work with two main theorems on the dimension spec-
trum of a line. Our ﬁrst theorem gives conditions under which the entire unit
interval must be contained in the spectrum. We reﬁne the techniques of [10] to
show in our main theorem (Theorem 8) that, whenever dim(a, b) = Dim(a, b),
we have
[min{1, dim(a, b)}, min{1, dim(a, b)} + 1] ⊆sp(La,b) .
Given any value s ∈[0, 1], we construct, by padding a random binary sequence,
a value x ∈R such that dim(x, ax+b) = s+min{dim(a, b), 1}. Our second main
theorem shows that the dimension spectrum sp(La,b) is inﬁnite for every line
such that dim(a, b) is at least one. Together with Theorem 5, this shows that the
dimension spectrum of any line has inﬁnite cardinality.
We begin by reviewing deﬁnitions and properties of algorithmic information
in Euclidean spaces in Sect. 2. In Sect. 3, we sketch our technical approach and
state our main technical lemmas. In Sect. 4 we prove our ﬁrst main theorem and
state our second main theorem. We conclude in Sect. 5 with a brief discussion of
future directions.
2
Preliminaries
2.1
Kolmogorov Complexity in Discrete Domains
The conditional Kolmogorov complexity of binary string σ ∈{0, 1}∗given a
binary string τ ∈{0, 1}∗is the length of the shortest program π that will output
σ given τ as input. Formally, it is
K(σ|τ) =
min
π∈{0,1}∗{ℓ(π) : U(π, τ) = σ} ,
where U is a ﬁxed universal preﬁx-free Turing machine and ℓ(π) is the length of
π. Any π that achieves this minimum is said to testify to, or be a witness to, the
value K(σ|τ). The Kolmogorov complexity of a binary string σ is K(σ) = K(σ|λ),
where λ is the empty string. These deﬁnitions extend naturally to other ﬁnite
data objects, e.g., vectors in Qn, via standard binary encodings; see [6] for details.

306
N. Lutz and D.M. Stull
2.2
Kolmogorov Complexity in Euclidean Spaces
The above deﬁnitions can also be extended to Euclidean spaces, as we now
describe. The Kolmogorov complexity of a point x ∈Rm at precision r ∈N is
the length of the shortest program π that outputs a precision-r rational estimate
for x. Formally, it is
Kr(x) = min {K(p) : p ∈B2−r(x) ∩Qm} ,
where Bε(x) denotes the open ball of radius ε centered on x. The conditional
Kolmogorov complexity of x at precision r given y ∈Rn at precision s ∈Rn is
Kr,s(x|y) = max

min{Kr(p|q) : p ∈B2−r(x) ∩Qm} : q ∈B2−s(y) ∩Qn
.
When the precisions r and s are equal, we abbreviate Kr,r(x|y) by Kr(x|y).
As the following lemma shows, these quantities obey a chain rule and are only
linearly sensitive to their precision parameters.
Lemma 1 (J. Lutz and N. Lutz [8], N. Lutz and Stull [10]). Let x ∈Rm
and y ∈Rn. For all r, s ∈N with r ≥s,
1. Kr(x, y) = Kr(x|y) + Kr(y) + O(log r).
2. Kr(x) = Kr,s(x|x) + Ks(x) + O(log r).
As a matter of notational convenience, if we are given a nonintegral positive
real as a precision parameter, we will always round up to the next integer. For
example, Kr(x) denotes K⌈r⌉(x) whenever r ∈(0, ∞).
2.3
Eﬀective Hausdorﬀand Packing Dimensions
J. Lutz initiated the study of algorithmic dimensions by eﬀectivizing Hausdorﬀ
dimension using betting strategies called gales, which generalize martingales.
Subsequently, Athreya, et al., deﬁned eﬀective packing dimension, also using
gales [1]. Mayordomo showed that eﬀective Hausdorﬀdimension can be charac-
terized using Kolmogorov complexity [11], and Mayordomo and J. Lutz showed
that eﬀective packing dimension can also be characterized in this way [9]. In
this paper, we use these characterizations as deﬁnitions. The eﬀective Hausdorﬀ
dimension and eﬀective packing dimension of a point x ∈Rn are
dim(x) = lim inf
r→∞
Kr(x)
r
and
Dim(x) = lim sup
r→∞
Kr(x)
r
.
Intuitively, these dimensions measure the density of algorithmic information in
the point x. Guided by the information-theoretic nature of these characteriza-
tions, J. Lutz and N. Lutz [8] deﬁned the lower and upper conditional dimension
of x ∈Rm given y ∈Rn as
dim(x|y) = lim inf
r→∞
Kr(x|y)
r
and
Dim(x|y) = lim sup
r→∞
Kr(x|y)
r
.

Dimension Spectra of Lines
307
2.4
Relative Complexity and Dimensions
By letting the underlying ﬁxed preﬁx-free Turing machine U be a universal oracle
machine, we may relativize the deﬁnition in this section to an arbitrary oracle set
A ⊆N. The deﬁnitions of KA(σ|τ), KA(σ), KA
r (x), KA
r (x|y), dimA(x), DimA(x)
dimA(x|y), and DimA(x|y) are then all identical to their unrelativized versions,
except that U is given oracle access to A.
We will frequently consider the complexity of a point x ∈Rn relative to a
point y ∈Rm, i.e., relative to a set Ay that encodes the binary expansion of y is
a standard way. We then write Ky
r (x) for KAy
r (x). J. Lutz and N. Lutz showed
that Ky
r (x) ≤Kr,t(x|y) + K(t) + O(1) [8].
3
Background and Approach
In this section we describe the basic ideas behind our investigation of dimension
spectra of lines. We brieﬂy discuss some of our earlier work on this subject, and
we present two technical lemmas needed for the proof our main theorems.
The dimension of a point on a line in R2 has the following trivial bound.
Observation 2. For all a, b, x ∈R, dim(x, ax + b) ≤dim(x, a, b).
In this work, our goal is to ﬁnd values of x for which the approximate converse
dim(x, ax + b) ≥dima,b(x) + dim(a, b)
(1)
holds. There exist oracles, at least, relative to which (1) does not always hold.
This follows from the point-to-set principle of J. Lutz and N. Lutz [8] and the
existence of Furstenberg sets with parameter α and Hausdorﬀdimension less
than 1 + α (attributed by Wolﬀ[15] to Furstenberg and Katznelson “in all
probability”). The argument is simple and very similar to our proof in [10] of a
lower bound on the dimension of generalized Furstenberg sets.
Speciﬁcally, for every s ∈[0, 1], we want to ﬁnd an x of eﬀective Hausdorﬀ
dimension s such that (1) holds. Note that equality in Observation 2 implies (1).
Observation 3. Suppose ax + b = ux + v and u ̸= a. Then
dim(u, v) ≥dima,b(u, v) ≥dima,b
 b −v
u −a

= dima,b(x) .
This observation suggests an approach, whenever dima,b(x) > dim(a, b), for
showing that dim(x, ax+b) ≥dim(x, a, b). Since (a, b) is, in this case, the unique
low-dimensional pair such that (x, ax + b) lies on La,b, one might na¨ıvely hope
to use this fact to derive an estimate of (x, a, b) from an estimate of (x, ax + b).
Unfortunately, the dimension of a point is not even semicomputable, so algorith-
mically distinguishing (a, b) requires a more reﬁned statement.

308
N. Lutz and D.M. Stull
3.1
Previous Work
The following lemma, which is essentially geometrical, is such a statement.
Lemma 4 (N. Lutz and Stull [10]). Let a, b, x ∈R. For all (u, v) ∈R2 such
that ux + v = ax + b and t = −log ∥(a, b) −(u, v)∥∈(0, r],
Kr(u, v) ≥Kt(a, b) + Ka,b
r−t(x) −O(log r) .
Roughly, if dim(a, b) < dima,b(x), then Lemma 4 tells us that Kr(u, v) >
Kr(a, b) unless (u, v) is very close to (a, b). As Kr(u, v) is upper semicomputable,
this is algorithmically useful: We can enumerate all pairs (u, v) whose precision-r
complexity falls below a certain threshold. If one of these pairs satisﬁes, approx-
imately, ux + v = ax + b, then we know that (u, v) is close to (a, b). Thus, an
estimate for (x, ax + b) algorithmically yields an estimate for (x, a, b).
In our previous work [10], we used an argument of this type to prove a general
lower bound on the dimension of points on lines in R2:
Theorem 5 (N. Lutz and Stull [10]). For all a, b, x ∈R,
dim(x, ax + b) ≥dima,b(x) + min{dim(a, b), dima,b(x)} .
The strategy in that work is to use oracles to artiﬁcially lower Kr(a, b) when
necessary, to essentially force dim(a, b) < dima,b(x). This enables the above
argument structure to be used, but lowering the complexity of (a, b) also weakens
the conclusion, leading to the minimum in Theorem 5.
3.2
Technical Lemmas
In the present work, we circumvent this limitation and achieve inequality (1)
by controlling the choice of x and placing a condition on (a, b). Adapting the
above argument to the case where dim(a, b) > dima,b(x) requires reﬁning the
techniques of [10]. In particular, we use the following two technical lemmas, which
strengthen results from that work. Lemma 6 weakens the conditions needed to
compute an estimate of (x, a, b) from an estimate of (x, ax + b).
Lemma 6. Let a, b, x ∈R, k ∈N, and r0 = 1. Suppose that r1, . . . , rk ∈N,
δ ∈R+, and ε, η ∈Q+ satisfy the following conditions for every 1 ≤i ≤k.
1. ri ≥log(2|a| + |x| + 6) + ri−1.
2. Kri(a, b) ≤(η + ε) ri.
3. For every (u, v) ∈R2 such that t = −log ∥(a, b) −(u, v)∥∈(ri−1, ri] and
ux + v = ax + b, Kri(u, v) ≥(η −ε) ri + δ · (ri −t).
Then for every oracle set A ⊆N,
KA
rk(a, b, x | x, ax + b) ≤2k

K(ε) + K(η) + 4ε
δ rk + O(log rk)

.

Dimension Spectra of Lines
309
Lemma 7 strengthens the oracle construction of [10], allowing us to control com-
plexity at multiple levels of precision.
Lemma 7. Let z ∈Rn, η ∈Q ∩[0, dim(z)], and k ∈N. For all r1, . . . , rk ∈N,
there is an oracle D = D(r1, . . . , rk, z, η) such that
1. For every t ≤r1, KD
t (z) = min{ηr1, Kt(z)} + O(log rk)
2. For every 1 ≤i ≤k,
KD
ri (z) = ηr1 +
i

j=2
min{η(rj −rj−1), Krj,rj−1(z | z)} + O(log rk) .
3. For every t ∈N and x ∈R, Kz,D
t
(x) = Kz
t (x) + O(log rk).
4
Main Theorems
We are now prepared to prove our two main theorems. We ﬁrst show that, for
lines La,b such that dim(a, b) = Dim(a, b), the dimension spectrum sp(La,b)
contains the unit interval.
Theorem 8. Let a, b ∈R satisfy dim(a, b) = Dim(a, b). Then for every s ∈[0, 1]
there is a point x ∈R such that dim(x, ax + b) = s + min{dim(a, b), 1}.
Proof. Every line contains a point of eﬀective Hausdorﬀdimension 1 [13], and by
the preservation of eﬀective dimensions under computable bi-Lipschitz functions,
dim(a, a2 + b) = dim(a, b), so the theorem holds for s = 0. For s = 1, we may
choose an x ∈R that is random relative to (a, b). That is, there is some constant
c ∈N such that for all r ∈N, Ka,b
r (x) ≥r −c. By Theorem 5,
dim(x, ax + b) ≥dima,b(x) + min{dim(a, b), 1}
= min{dim(a, b), 1} + lim inf
r→∞
Kr(x)
r
= min{dim(a, b), 1} + 1,
and the conclusion holds.
Now let s ∈(0, 1) and d = dim(a, b) = Dim(a, b). Let y ∈R be random
relative to (a, b). Deﬁne the sequence of natural numbers {hj}j∈N inductively as
follows. Deﬁne h0 = 1. For every j > 0, let
hj = min

h ≥2hj−1 : Kh(a, b) ≤

d + 1
j

h

.
Note that hj always exists. For every r ∈N, let
x[r] =
	
0
if
r
hj ∈(s, 1] for some j ∈N
y[r]
otherwise

310
N. Lutz and D.M. Stull
where x[r] is the rth bit of x. Deﬁne x ∈R to be the real number with this
binary expansion. Then Kshj(x) = shj + O(log shj).
We ﬁrst show that dim(x, ax + b) ≤s + min{d, 1}. For every j ∈N,
Khj(x, ax + b) = Khj(x) + Khj(ax + b | x) + O(log hj)
= Kshj(x) + Khj(ax + b | x) + O(log hj)
= Kshj(y) + Khj(ax + b | x) + O(log hj)
≤shj + min{d, 1} · hj + o(hj) .
Therefore,
dim(x, ax + b) = lim inf
r→∞
Kr(x, ax + b)
r
≤lim inf
j→∞
Khj(x, ax + b)
hj
≤lim inf
j→∞
shj + min{d, 1}hj + o(hj)
hj
= s + min{d, 1} .
If 1 > s ≥d, then by Theorem 5 we also have
dim(x, ax + b) ≥dima,b(x) + dim(a, b)
= dim(x) + d
= lim inf
r→∞
Kr(x)
r
+ d
= lim inf
j→∞
Khj(x)
hj
+ d
= s + min{d, 1} .
Hence, we may assume that s < d.
Let H = Q ∩(s, min{d, 1}). Let η ∈H, δ = 1 −η > 0, and ε ∈Q+. We now
show that dim(x, ax + b) ≥s + η −αε
δ , where α is some constant independent of
η and ε. Let j ∈N and m = s−1
η−1. We ﬁrst show that
Kr(x, ax + b) ≥Kr(x) + ηr −cε
δ r −o(r) ,
(2)
for every r ∈(shj, mhj]. Let r ∈(shj, mhj]. Set k =
r
shj , and deﬁne ri = ishj
for all 1 ≤i ≤k. Note that k is bounded by a constant depending only on s
and η. Therefore a o(rk) = o(ri) for all ri. Let Dr = D(r1, . . . , rk, (a, b), η) be
the oracle deﬁned in Lemma 7. We ﬁrst note that, since dim(a, b) = Dim(a, b),
Kri,ri−1(a, b | a, b) = Kri(a, b) −Kri−1(a, b) −O(log ri)
= dim(a, b)ri −o(ri) −dim(a, b)ri−1 −o(ri−1) −O(log ri)
= dim(a, b)(ri −ri−1) −o(ri)
≥η(ri −ri−1) −o(ri).

Dimension Spectra of Lines
311
Hence, by property 2 of Lemma 7, for every 1 ≤i ≤k,
|KDr
ri (a, b) −ηri| ≤o(rk).
(3)
We now show that the conditions of Lemma 6 are satisﬁed. By inequality (3),
for every 1 ≤i ≤k,
KDr
ri (a, b) ≤ηri + o(rk) ,
and so KDr
ri (a, b) ≤(η + ε)ri, for suﬃciently large j. Hence, condition 2 of
Lemma 6 is satisﬁed.
To see that condition 3 is satisﬁed for i = 1, let (u, v) ∈B1(a, b) such that
ux + v = ax + b and t = −log ∥(a, b) −(u, v)∥≤r1. Then, by Lemmas 4 and 7,
and our construction of x,
KDr
r1 (u, v) ≥KDr
t
(a, b) + KDr
r1−t,r1(x|a, b) −O(log r1)
≥min{ηr1, Kt(a, b)} + Kr1−t(x) −o(rk)
≥min{ηr1, dt −o(t)} + (η + δ)(r1 −t) −o(rk)
≥min{ηr1, ηt −o(t)} + (η + δ)(r1 −t) −o(rk)
≥ηt −o(t) + (η + δ)(r1 −t) −o(rk) .
We conclude that KDr
r1 (u, v) ≥(η −ε)r1 + δ(r1 −t), for all suﬃciently large j.
To see that that condition 3 is satisﬁed for 1 < i ≤k, let (u, v) ∈B2−ri−1(a, b)
such that ux + v = ax + b and t = −log ∥(a, b) −(u, v)∥≤ri. Since (u, v) ∈
B2−ri−1(a, b),
ri −t ≤ri −ri−1 = ishj −(i −1)shj ≤shj + 1 ≤r1 + 1 .
Therefore, by Lemma 4, inequality (3), and our construction of x,
KDr
ri (u, v) ≥KDr
t
(a, b) + KDr
ri−t,ri(x|a, b) −O(log ri)
≥min{ηri, Kt(a, b)} + Kri−t(x) −o(ri)
≥min{ηri, dt −o(t)} + (η + δ)(ri −t) −o(ri)
≥min{ηri, ηt −o(t)} + (η + δ)(ri −t) −o(ri)
≥ηt −o(t) + (η + δ)(ri −t) −o(ri) .
We conclude that KDr
ri (u, v) ≥(η −ε)ri + δ(ri −t), for all suﬃciently large j.
Hence the conditions of Lemma 6 are satisﬁed, and we have
Kr(x, ax + b) ≥KDr
r
(x, ax + b) −O(1)
≥KDr
r
(a, b, x) −2k

K(ε) + K(η) + 4ε
δ r + O(log r)

= KDr
r
(a, b) + KDr
r
(x | a, b)
−2k

K(ε) + K(η) + 4ε
δ r + O(log r)

≥sr + ηr −2k

K(ε) + K(η) + 4ε
δ r + O(log r)

.

312
N. Lutz and D.M. Stull
Thus, for every r ∈(shj, mhj],
Kr(x, ax + b) ≥sr + ηr −αε
δ r −o(r) ,
where α is a ﬁxed constant, not depending on η and ε.
To complete the proof, we show that (2) holds for every r ∈[mhj, shj+1).
By Lemma 1 and our construction of x,
Kr(x) = Kr,hj(x | x) + Khj(x) + o(r)
= r −hj + shj + o(r)
≥ηr + o(r) .
The proof of Theorem 5 gives Kr(x, ax + b) ≥Kr(x) + dim(x)r −o(r), and so
Kr(x, ax + b) ≥r(s + η).
Therefore, equation (2) holds for every r ∈[shj, shj+1), for all suﬃciently
large j. Hence,
dim(x, ax + b) = lim inf
r→∞
Kr(x, ax + b)
r
≥lim inf
r→∞
Kr(x) + ηr −αε
δ r −o(r)
r
≥lim inf
r→∞
Kr(x)
r
+ η −αε
δ
= s + η −αε
δ .
Since η and ε were chosen arbitrarily, the conclusion follows.
⊓⊔
Theorem 9. Let a, b ∈R such that dim(a, b) ≥1. Then for every s ∈[ 1
2, 1]
there is a point x ∈R such that dim(x, ax + b) ∈

 3
2 + s −1
2s, s + 1

.
Corollary 10. Let La,b be any line in R2. Then the dimension spectrum sp(La,b)
is inﬁnite.
Proof. Let (a, b) ∈R2. If dim(a, b) < 1, then by Theorem 5 and Observa-
tion 2, the spectrum sp(La,b) contains the interval [dim(a, b), 1]. Assume that
dim(a, b) ≥1. By Theorem 9, for every s ∈[ 1
2, 1], there is a point x such that
dim(x, ax+b) ∈[ 3
2 +s−1
2s, s+1]. Since these intervals are disjoint for sn = 2n−1
2n ,
the dimension spectrum sp(La,b) is inﬁnite.
5
Future Directions
We have made progress in the broader program of describing the dimension
spectra of lines in Euclidean spaces. We highlight three speciﬁc directions for
further progress. First, it is natural to ask whether the condition on (a, b) may
be dropped from the statement our main theorem: Does Theorem 8 hold for
arbitrary a, b ∈R?

Dimension Spectra of Lines
313
Second, the dimension spectrum of a line La,b ⊆R2 may properly contain the
unit interval described in our main theorem, even when dim(a, b) = Dim(a, b).
If a ∈R is random and b = 0, for example, then sp(La,b) = {0} ∪[1, 2]. It is less
clear whether this set of “exceptional values” in sp(La,b) might itself contain an
interval, or even be inﬁnite. How large (in the sense of cardinality, dimension,
or measure) may sp(La,b) ∩

0, min{1, dim(a, b)}

be?
Finally, any non-trivial statement about the dimension spectra of lines in
higher-dimensional Euclidean spaces would be very interesting. Indeed, an n-
dimensional version of Theorem 5 (i.e., one in which a, b ∈Rn−1, for all n ≥2)
would, via the point-to-set principle for Hausdorﬀdimension [8], aﬃrm the
famous Kakeya conjecture and is therefore likely diﬃcult. The additional hypoth-
esis of Theorem 8 might make it more conducive to such an extension.
References
1. Athreya, K.B., Hitchcock, J.M., Lutz, J.H., Mayordomo, E.: Eﬀective strong
dimension in algorithmic information and computational complexity. SIAM J.
Comput. 37(3), 671–705 (2007)
2. Dougherty, R., Lutz, J., Mauldin, R.D., Teutsch, J.: Translating the Cantor set by
a random real. Trans. Am. Math. Soc. 366(6), 3027–3041 (2014)
3. Downey, R., Hirschfeldt, D.: Algorithmic Randomness and Complexity. Springer,
New York (2010)
4. Xiaoyang, G., Lutz, J.H., Mayordomo, E., Moser, P.: Dimension spectra of ran-
dom subfractals of self-similar fractals. Ann. Pure Appl. Logic 165(11), 1707–1726
(2014)
5. Hitchcock, J.M.: Correspondence principles for eﬀective dimensions. Theory Com-
put. Syst. 38(5), 559–571 (2005)
6. Li, M., Vit´anyi, P.M.B.: An Introduction to Kolmogorov Complexity and Its Appli-
cations, 3rd edn. Springer, New York (2008)
7. Lutz, J.H.: The dimensions of individual strings and sequences. Inf. Comput.
187(1), 49–79 (2003)
8. Lutz, J.H., Lutz, N.: Algorithmic information, plane Kakeya sets, and condi-
tional dimension. In: Vollmer, H., Vallee, B. (eds.) 34th Symposium on Theoretical
Aspects of Computer Science (STACS 2017), Leibniz International Proceedings in
Informatics (LIPIcs), vol. 66, pp. 53:1–53:13. Schloss Dagstuhl–Leibniz-Zentrum
fuer Informatik, Germany (2017)
9. Lutz, J.H., Mayordomo, E.: Dimensions of points in self-similar fractals. SIAM J.
Comput. 38(3), 1080–1112 (2008)
10. Lutz, N., Stull, D.M.: Bounding the dimension of points on a line. In: Gopal, T.V.,
J¨ager, G., Steila, S. (eds.) TAMC 2017. LNCS, vol. 10185, pp. 425–439. Springer,
Cham (2017). doi:10.1007/978-3-319-55911-7 31
11. Mayordomo, E.: A Kolmogorov complexity characterization of constructive Haus-
dorﬀdimension. Inf. Process. Lett. 84(1), 1–3 (2002)
12. Reimann, J.: Eﬀectively closed classes of measures and randomness. Ann. Pure
Appl. Logic 156(1), 170–182 (2008)
13. Turetsky, D.: Connectedness properties of dimension level sets. Theor. Comput.
Sci. 412(29), 3598–3603 (2011)

314
N. Lutz and D.M. Stull
14. Westrick, L.B.: Computability in ordinal ranks and symbolic dynamics. Ph.D. the-
sis, University of California, Berkeley (2014)
15. Wolﬀ, T.: Recent work connected with the Kakeya problem. In: Prospects in Math-
ematics, pp. 129–162 (1999)

A Universal Oracle for Signal Machines
Thierry Monteil(B)
CNRS – LIPN – Universit´e Paris 13, Villetaneuse, France
thierry.monteil@lipn.univ-paris13.fr
http://monteil.perso.math.cnrs.fr
Abstract. We construct two universal oracles for signal machines, one
via the binary expansion of irrational numbers, another via their contin-
ued fraction expansion, settling a conjecture of Durand-Lose in CiE 2013.
This latter is optimal in the number of speeds and irrational parameters
involved in the construction (three and one respectively).
Keywords: Signal machine · Geometric computation · Oracle · Linear
Blum Shub Smale model · Binary expansion · Continued fractions
1
Introduction: Signal Machines
Signal machines were introduced in [DL03] as a geometric model of computation
featuring discrete and deterministic interactions of signals within a continuous
space and time. More precisely, a meta-signal (c, s) is characterized by its color
c ∈C and speed s ∈R, where C is a ﬁnite set. A signal (c, s, p) is a meta-signal
together with a position p ∈R. A signal machine is given by:
– a ﬁnite set of meta-signals M,
– an initial conﬁguration, i.e. a ﬁnite set of signals I ⊂M × R,
– a set of deterministic collision rules, i.e. a map R : 2M →2M whose restriction
to sets of meta-signals with the same speed is the identity.
Note that two signals with the same position and speed, but diﬀerent col-
ors can be superposed. This allows some ﬂexibility in deﬁning signal machines
without having to artiﬁcially consider products of colors. The condition on meta-
signals with the same speed ensures that the non-trivial collisions are discrete (in
particular, no collision appears along a single signal). In this paper, by conven-
tion, when a collision rule is only partially deﬁned, it is extended by the identity,
so that when signals meet in an undeﬁned way, they ignore each other.
The execution of a signal machine could be deﬁned from its initial conﬁgura-
tion, then considering that signals move along the real line with constant speed,
until signals with diﬀerent speeds meet, in which case the corresponding collision
rule is applied, leading to the substitution of collided signals into their images by
R. Since a picture is worth a thousand words, let us describe a simple example
which will be used in the next section: a signal machine that computes the mid-
dle of two positions. The middle machine has ﬁve meta-signals on three colors:
c
⃝Springer International Publishing AG 2017
J. Kari et al. (Eds.): CiE 2017, LNCS 10307, pp. 315–326, 2017.
DOI: 10.1007/978-3-319-58741-7 30

316
T. Monteil
C = {black, red, green} M = {(black, 0), (green, 0), (red, 1), (red, 3), (red, −3)}.
Initial conﬁguration (with two parameters x1 and x2), collision rules and exe-
cution are described in Figs. 1, 2, 3, respectively. The representations show the
space (R) horizontally, and the time (R+) vertically, from bottom up.
While the initial condition could be understood as the input of a signal
machine and the collision rules could be understood as the transition function,
there is purposely no formal deﬁnition for the output of a signal machine. Indeed,
depending on the situation, some outputs could be the positions of signals of
given colors, or distances between such pairs of signals, some Boolean output
for decision problems could depend on the apparition of a given color during an
execution, or even on the existence of accumulations of collisions in the execution.
1
x1
0
0
x2
3
I = {(black, 0, x1), (black, 0, x2), (red, 1, x1), (red, 3, x1)}
•
•
Fig. 1. Middle machine: initial conﬁguration. (Color ﬁgure online)
1
−3
0
•
R({(red, 1), (red, −3)}) = {(green, 0)}
0
0
3
−3
R({(red, 3), (black, 0)}) = {(red, −3), (black, 0)}
•
Fig. 2. Middle machine: collision rules (other collisions lead to no signal). (Color ﬁgure
online)
x1
x2
x1+x2
2
•
•
•
Fig. 3. Middle machine: execution. (Color ﬁgure online)

A Universal Oracle for Signal Machines
317
In the present article, a non-trivial oracle never stops, and reacts to queries from
a Turing machine, leading to a on demand sequence of outputs.
There are diﬀerent ways to deal with accumulations of collisions. Allow-
ing accumulations to output some information leads to a stronger model (see
[DL09]). In the present article, we consider machines without accumulations,
i.e. the computation is aborted when an accumulation occurs. It was proved in
[DL07] that such an accumulation-free model is equivalent to the linear Blum,
Shub and Smale model (denoted Linear-BSS) [BSS89], which can be seen as a
Turing machine which can handle real numbers, and where allowed operations
on them are addition, comparison, multiplication by constants (in particular it
is less powerful than the classical Blum, Shub and Smale model where multipli-
cation between variables is allowed).
2
An Oracle Based on Binary Expansion
A usual way to deﬁne the interaction between a Turing machine and an oracle
representing a language L ⊆{0, 1}∗is as follows: the Turing machine queries
the oracle about a word w ∈{0, 1}∗and gets an answer 0 or 1 depending on
whether the word w belongs to L. Here, our oracle provides an inﬁnite sequence
S of bits, whose values can be consulted one after another. Those two versions are
equivalent. Indeed, since there exists a computable enumeration e : {0, 1}∗→N,
the sequence can S represent the language L if S ◦e is the characteristic function
of L. Since a Turing machine has unbounded caching capabilities, it can store all
the bits it gets from the oracle. To know if a word w belongs to L, it computes
n = e(w), and looks at the nth obtained bit if it was received already, or asks
for enough new bits until it gets the nth bit.
In the Turing model of computation, an oracle is a black box whose inter-
nals are unspeciﬁed. In order to understand the computational power of signal
machines, we want to see if any oracle can be produced from a concrete signal
machine.
The aim of this paper is to construct a universal oracle for signal machines,
that is, a single explicit signal machine O which depends on an input p, such that
every inﬁnite sequence (xn) ∈{0, 1}N can be produced by O(p) for some p ∈R.
First, let us describe how the simulation of a Turing machine by a signal
machine as described in [DL03] can query an oracle. It should be noticed that the
Turing machine simulation uses a bounded space. The oracles we will construct
will run in space bounded by 1, and the duration of the computation of one term
of the sequence by those oracles will be bounded by 1. In particular, we can con-
catenate their conﬁguration with the Turing machine on the left and the oracle on
the right (see Fig. 4). To avoid possible interference between the Turing machine
and the oracle, we add a static signal in-between that blocks any lost signal that is
not a query nor an answer (another possibility would be to ensure that the query
and answers are the only common colors between the two devices). The oracle
computes one term of the sequence and waits for a query with a zero-speed sig-
nal whose color (say green for 0 and blue for 1) corresponds to that term. When

318
T. Monteil
Fig. 4. Communication between a Turing machine and an oracle in the signal machine
model. (Color ﬁgure online)
the Turing machine needs a value from the oracle, it sends an orange signal going
to the right (with speed s > 0). Once this signal meets the waiting one from the
oracle, the answer is returned to the Turing machine as a green or blue signal of
speed −s. If the execution zones of the Turing machine and the oracle are sepa-
rated by a distance at least 1/s, we are sure that the orange query will reach the
oracle after this latter ﬁnishes the computation of the term.
Since ﬁnite and periodic sequences can easily be produced by the (simu-
lated) Turing machine itself, interesting oracles are the ones that produce uncom-
putable sequences, in particular inﬁnite non-periodic sequences, and we might
skip details regarding few ﬁnite or periodic sequences if those lead to additional
technicalities regarding non-generic collisions.
It is pretty easy to describe such a universal oracle in the Linear-BSS model:
given an inﬁnite sequence (xn) of 0 and 1 which is not ultimately constant, we can
construct the real number whose binary representation is p = 0.x0x1x2x3 · · · and
let a Turing machine extract its digits one by one by multiplication by 2 (which
corresponds to shifting the sequence) and taking the leading digit. A simple
implementation of such a generator could be (using Python syntax as a pseudo-
code):
def
binary oracle (p ) :
while True :
i f p < 1/2:
yield 0
p = 2∗p
e l i f
1/2 < p :

A Universal Oracle for Signal Machines
319
yield 1
p = 2∗p−1
else :
return
Hence, it is possible to simulate such an algorithm with a signal machine,
by translating this algorithm into a Linear-BSS machine, and then into a signal
machine following the construction of [DL07].
However, such a construction will lose all the geometrical features of the
signal-machine model, while we can beneﬁt from it easily. Indeed, constructing
the middle of two points is pretty easy in that framework, as we saw in Sect. 1.
Let us roughly implement it as a signal machine as follows:
The point p ∈(0, 1) is a static (zero speed) signal. We proceed by dichotomy
of the unit interval, the last middle is the active signal and knows (from its color)
on which side is the point p. When a query from the Turing machine reaches the
last middle, the previous result is returned and a new step of the dichotomy is
computed for the next query. To this end, two red signals create the next middle,
the one which meets the point p gives the right color to the next middle, which
knows on which side is p (See Figs. 5, 6, 7).
0
1
3
0
0
p
0
1
•
•
•
Fig. 5. Binary machine: initial conﬁguration. (Color ﬁgure online)
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
Fig. 6. Binary machine: collision rules. (Color ﬁgure online)

320
T. Monteil
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
p
0
1
Fig. 7. Binary machine: an execution for some 3/8 < p < 1/2, answering two queries
as 0, 1 and ready to answer the third as 1. (Color ﬁgure online)
3
An Optimal Oracle Based on Continued Fractions
As could be easily deduced from [DL13], signal machines involving two speeds
(and any number of irrational parameters) can only produce ﬁnite sequences;
signal machines involving three speeds and rational parameters can only produce
periodic sequences. Hence, an universal oracle would require at least three speeds
and one irrational parameter. Is this bound sharp?
The dichotomy method we saw in the previous section uses the multiplication
by constant 1/2, which itself uses four speeds.
Another famous way to produce inﬁnite sequences from real numbers is the
continued fraction algorithm, which can be described as follows:
def
c o n t i n u e d f r a c t i o n s o r a c l e (p ) :
a , b = p,1−p
while True :
i f
a < b :
yield 0
a , b = b−a , a
e l i f b < a :
yield 1
a , b = b , a−b
else :
return

A Universal Oracle for Signal Machines
321
Actually, this algorithm is a slight variant of the classical continued fraction
algorithm which iteratively sends (a, b) to (a, b −a) if a < b and (a, b) to (b, a) if
b < a and stops when a = b (see, e.g. [KE64]). While sharing the features of the
classical continued fraction algorithm (see Theorem 1), it is easier to implement
geometrically by avoiding swapping values.
One advantage over the dichotomy algorithm is that it performs only sub-
tractions and comparisons. Let us ﬁrst construct a machine that performs a
single step of the algorithm (see Figs. 8, 9, 10).
Let us now turn the subtraction machine into a universal oracle with three
speed and a single irrational parameter. We have to log the result of the com-
parison by specializing the gray color into gray when the comparison is not done
yet, green when a < b and blue when b < a. When a query arrives from the
Turing machine, we have to release this color to the Turing machine, and start
a new subtraction for the next round. This leads to the following signal machine
O(p) with parameter p ∈[0, 1] (see Figs. 11, 12, 13).
Note that the speed s of queries and answers is arbitrary and was set to a
high value to avoid signal superposition in the pictures, but it could be set to 1,
therefore not artiﬁcially adding additional speeds.
The continued fraction machine simulates the continued fractions oracle
algorithm.
0
0
1
−1
0
a
b
•
•
•
Fig. 8. Subtraction machine: initial conﬁguration with parameters a and b. (Color
ﬁgure online)
0
0
1
−1
•
0
0
−1
1
•
0
1
−1
•
0
1
−1
•
0
1
1
0
•
0
−1
−1
0
•
Fig. 9. Subtraction machine: collision rules. (Color ﬁgure online)

322
T. Monteil
a
b
b
a −b
•
•
•
•
•
•
•
•
a
b
a
b −a
•
•
•
•
•
•
•
•
Fig. 10. Subtraction machine: two possible executions depending on whether a < b or
b < a. (Color ﬁgure online)
0
0
1
−1
0
p
0
1
•
•
•
Fig. 11. Continued fraction machine: initial conﬁguration. (Color ﬁgure online)
0
0
1
−1
•
0
0
−1
1
•
0
1
−1
•
0
1
−1
•
0
1
1
0
•
0
−1
−1
0
•
0
0
−1
1
s
−s
•
0
0
−1
1
s
−s
•
(two parallel billiard computations)
(the ﬁrst to cross the gray line wins)
(the winner decides next answer)
(answer query + start new computation)
Fig. 12. Continued fraction machine: collision rules. (Color ﬁgure online)

A Universal Oracle for Signal Machines
323
p
0
1
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
Fig. 13. Continued fraction machine: execution with some parameter 2/3 < p < 5/7
answering three queries as 1, 0, 0 and ready to answer the fourth as 1. Note that the
speed of queries and answers can be set to ±1 so that the machine has only 3 speeds.
(Color ﬁgure online)

324
T. Monteil
Theorem 1. Let (xn) ∈{0, 1}N be a non-ultimately alternating sequence ( i.e.
a sequence not ending with 010101 · · · , corresponding to rational inputs).
Then, there exists p ∈[0, 1] such that the machine O(p) generates the
sequence (xn).
Proof. Let us ﬁrst look at the forward execution of the continued fraction
machine. When, a < b, the subtraction algorithm maps

a
b

to S0

a
b

, and
when b < a, it maps
a
b

to S1
a
b

, where S0 :=
−1 1
1 0

and S1 :=

0 1
1 −1

. Hence, after n iterations of the continued fractions oracle algo-
rithm, we have
an
bn

= SxnSxn−1 · · · Sx2Sx1Sx0

p
1 −p

, where x0, x1, . . . , xn is
the sequence returned by the algorithm.
Now, given an inﬁnite sequence (xn) ∈{0, 1}N, we have to go backward
to construct a number p ∈[0, 1] such that the continued fractions oracle
algorithm produces the sequence (xn). Let us deﬁne M0 := S−1
0
=

0 1
1 1

and
M1 := S−1
1
=

1 1
1 0

. As with the classical continued fraction algorithm, the
sequence of cones Cn := Mx0Mx1Mx2 · · · Mxn−1MxnR2
+ is decreasing for the
inclusion and converges to a half line L ⊆R2
+. There exists a (unique) normalized
vector
p
q

∈R2
+ such that p + q = 1 and L = R+
p
q

.
Note that the sequence (xn) being ultimately alternating corresponds to p
being rational and the machine will lead to a collision we did not consider yet:
both red signals reach the gray line simultaneously, a speciﬁc answer can be
returned, see Fig. 14.
In the other (irrational) cases, the inequalities are always strict during the
comparisons, and the forward execution of the continued fraction machine with
parameter p leads to the sequence (xn).
⊓⊔
0
1
0
−1
•
0
s
−s
•
Fig. 14. Possible additional collision rule for the continued fraction machine: sending
an “end of computation” signal (purple color) to the Turing machine when an = bn
(p ∈(0, 1) ∩Q). (Color ﬁgure online)

A Universal Oracle for Signal Machines
325
As an illustration of the method, the set of parameters for which (xn) starts
with 1001 is (2/3, 5/7) (see Fig. 13). Indeed, M1M0M0M1

0
1

=

2
1

and M1
M0M0M1
1
0

=
5
2

, so the normalization leads to the endpoints 2/(2 + 1) =
2/3 and 5/(5 + 2) = 5/7 respectively.
Three Speeds and One Irrational Parameter for the Whole System
The Turing machine described in [DL13] also works with 3 speeds and a sin-
gle irrational ratio. The speeds can be chosen identical for the Turing machine
and the continued fraction oracle. However, for the Turing machine, the irra-
tional parameter is the golden ratio, which allows to create cells accumulating
on a single side. Here, the positions of the vertical strips which are created is
not increasing, but oscillating in a way that depends on the continued fraction
expansion of the irrational parameter. However, it is possible, still using only 3
speeds, to add some rules to the continued fraction machine that swap a and b
before each subtraction step when a > b, so that each new vertical strips becomes
larger than the previous one. In particular, a single irrational parameter can be
ﬁrst duplicated and used to construct both the oracle (as described in this paper)
and the creation of cells for the Turing machine.
4
Conclusion: Further Work
In this paper, we answered a little part of one of the main questions about signal
machines: “what can they compute?”. We will see in a further paper how signal
machines can semi-decide the algebraicity of real numbers, without accumula-
tions, while this is not doable in the Linear-BSS model. We will also propose
a new kind of signal whose resulting signal machine model is equivalent to the
(classical) BSS model. We will also see how signal machines which are allowed
to deal with accumulations can go far beyond BSS: they can compute arbitrary
analytic functions, or even draw any compact subset of the unit interval.
References
[BSS89] Blum, L., Shub, M., Smale, S.: On a theory of computation and complex-
ity over the real numbers: NP-completeness, recursive functions and universal
machines. Bull. Am. Math. Soc. New Ser. 21(1), 1–46 (1989)
[DL03] Durand-Lose, J.: Calculer g´eom´etriquement sur le plan - machines `a sig-
naux. Habilitation `a Diriger des Recherches, ´Ecole Doctorale STIC, Universit´e de
Nice-Sophia Antipolis (2003) (In French)
[DL07] Durand-Lose, J.: Abstract geometrical computation and the linear Blum, Shub
and Smale model. In: Cooper, S.B., L¨owe, B., Sorbi, A. (eds.) CiE 2007. LNCS, vol.
4497, pp. 238–247. Springer, Heidelberg (2007). doi:10.1007/978-3-540-73001-9 25
[DL09] Durand-Lose, J.: Abstract geometrical computation 3: black holes for classical
and analog computing. Nat. Comput. 8(3), 455–472 (2009)

326
T. Monteil
[DL13] Durand-Lose, J.: Irrationality is needed to compute with signal machines
with only three speeds. In: Bonizzoni, P., Brattka, V., L¨owe, B. (eds.) CiE
2013. LNCS, vol. 7921, pp. 108–119. Springer, Heidelberg (2013). doi:10.1007/
978-3-642-39053-1 12
[KE64] Khinchin,
A.I.A.,
Eagle,
H.:
Continued
Fractions.
Dover
Books
on
Mathematics. Dover Publications, New York (1964)

Game Characterizations and Lower Cones
in the Weihrauch Degrees
Hugo Nobrega1(B) and Arno Pauly2
1 Institute for Logic, Language, and Computation,
University of Amsterdam, Amsterdam, The Netherlands
h.nobrega@uva.nl
2 D´epartement D’informatique, Universit´e Libre de Bruxelles, Brussels, Belgium
Arno.M.Pauly@gmail.com
Abstract. We introduce generalized Wadge games and show that each
lower cone in the Weihrauch degrees is characterized by such a game.
These generalized Wadge games subsume (a variant of) the original
Wadge game, the eraser and backtrack games as well as Semmes’s tree
games. In particular, we propose that the lower cones in the Weihrauch
degrees are the answer to Andretta’s question on which classes of func-
tions admit game characterizations. We then discuss some applications
of such generalized Wadge games.
1
Introduction
The use of games in set theory has a well-established tradition, going back to
work by Banach, Borel, Zermelo, K˝onig, and others (see [16, Sect. 27] for a
thorough historical account of the subject). In particular, games which go on
for inﬁnitely many rounds have taken a prominent role in the ﬁeld especially
since the work of Gale and Stewart on the determinacy of certain types of such
games [12].
In this paper, we will focus on inﬁnite games which have been used to charac-
terize classes of functions in descriptive set theory. Interest in this particular area
began with a re-reading of the seminal work of Wadge [40], who introduced a
game in order to analyze a notion of reducibility—Wadge reducibility—between
subsets of Baire space. In the variant—which by a slight abuse we call the Wadge
game—two players, I and II, are given a partial function f :⊆NN →NN and
play with perfect information for ω rounds. In each run of this game, at each
round player I ﬁrst picks a natural number and player II responds by either
This research was partially done whilst the authors were visiting fellows at the Isaac
Newton Institute for Mathematical Sciences in the programme ‘Mathematical, Foun-
dational and Computational Aspects of the Higher Inﬁnite’. The research beneﬁted
from the Royal Society International Exchange Grant Inﬁnite games in logic and
Weihrauch degrees. The ﬁrst author was partially supported by a CAPES Science
Without Borders grant (9625/13-5), and the second author was partially supported
by the ERC inVEST (279499) project.
c
⃝Springer International Publishing AG 2017
J. Kari et al. (Eds.): CiE 2017, LNCS 10307, pp. 327–337, 2017.
DOI: 10.1007/978-3-319-58741-7 31

328
H. Nobrega and A. Pauly
picking a natural number or passing, although she must pick natural numbers
at inﬁnitely many rounds. Thus, in the long run I and II build elements x ∈NN
and y ∈NN, respectively, and II wins the run if and only if x ̸∈dom(f) or
f(x) = y. It can be considered a folklore result, also implicit in Wadge’s work,
that this game characterizes the continuous functions in the following sense.
Theorem 1. A partial function f : NN →NN is relatively continuous iﬀplayer
II has a winning strategy in the Wadge game for f.
By adding new possibilities for player II at each round, one can obtain
games characterizing larger classes of functions. For example, in the eraser game
(implicit in [11]) characterizing the Baire class 1 functions, player II is allowed
to erase past moves, the rule being that she is only allowed to erase each posi-
tion of her output sequence ﬁnitely often. In the backtrack game (implicit in [44])
characterizing the functions which preserve the class of Σ0
2 sets under preimages,
player II is allowed to erase all of her past moves at any given round, the rule
in this case being that she only do this ﬁnitely many times.
In his PhD thesis [39], Semmes introduced the tree game characterizing the
class of Borel functions in Baire space. Player I plays as in the Wadge game and
therefore builds some x ∈NN in the long run, but at each round n player II now
plays a ﬁnite labeled tree, i.e., a pair (Tn, φn) consisting of a ﬁnite tree Tn ⊆N<N
and a function φn : Tn∖{⟨⟩} →N, where ⟨⟩denotes the empty sequence. The
rules are that Tn ⊆Tn+1 and φn ⊆φn+1 must hold for each n, and that the
ﬁnal labeled tree (T, φ) = (
n∈N Tn, 
n∈N φn) must be an inﬁnite tree with a
unique inﬁnite branch. Player II then wins if the sequence of labels along this
inﬁnite branch is exactly f(x). By providing suitable extra requirements on the
structure of the ﬁnal tree, Semmes was able to obtain a game characterizing
the Baire class 2 functions, and although this is not done explicitly in [39], it
is not diﬃcult to see that restrictions of the tree game also give his multitape
game characterizing the classes of functions which preserve Σ0
3 under preimages
and the multitape eraser game characterizing the class of functions for which the
preimage of any Σ0
2 set is a Σ0
3 set.
As examples of applications of these games, Semmes found a new proof of a
theorem of Jayne and Rogers characterizing the class of functions which preserve
Σ0
2 under preimages and extended this theorem to the classes characterized by
the multitape and multitape eraser games, by performing a detailed analysis of
the corresponding game in each case.
Given the success of such game characterizations, in [1] Andretta raised the
question of which classes of functions admit a characterization by a suitable
game. Signiﬁcant progress towards an answer was made by Motto Ros in [23]:
Starting from a general deﬁnition of a reduction game, he shows how to construct
new games from existing ones in ways that mirror the typical constructions of
classes of functions (e.g., piecewise deﬁnitions, composition, pointwise limits). In
particular, Motto Ros’s results show that all the usual subclasses of the Borel
functions studied in descriptive set theory admit game characterizations.
In order to arrive at a full characterization of the classes of functions char-
acterizable by a game, we need to ﬁnd the appropriate language to formulate

Game Characterizations and Lower Cones in the Weihrauch Degrees
329
such a result. Weihrauch reducibility (in its modern form) was introduced by
Gherardi and Marcone [13] and Brattka and Gherardi [2,3] based on earlier work
by Weihrauch on a reducibility between sets of functions analogous to Wadge
reducibility [41,42].
We will show that game characterizations and Weihrauch degrees correspond
closely to each other. We can thus employ the results and techniques developed
for Weihrauch reducibility to study function classes in descriptive set theory,
and vice versa. In particular, we can use the algebraic structure available for
Weihrauch degrees [6,15] to obtain game characterizations for derived classes
of functions from game characterizations for the original classes, similar to the
constructions found by Motto Ros [23]. As a further feature of our work, we
should point out that our results apply to the eﬀective setting ﬁrsthand, and
are then lifted to the continuous setting via relativization. They thus follow the
recipe laid out by Moschovakis in [21].
While the traditional scope of descriptive set theory is restricted to Polish
spaces, their subsets, and functions between them, these restrictions are immate-
rial for the approach presented here. Our results naturally hold for multivalued
functions between represented spaces. As such, this work is part of a larger
development to extend descriptive set theory to a more general setting, cf., e.g.,
[7,18,29,33,35].
We shall freely use standard concepts and notation from descriptive set the-
ory, referring to [17] for an introduction.
2
Preliminaries on Represented Spaces and Weihrauch
Reducibility
Represented spaces and continuous/computable maps between them form the
setting for computable analysis [43]. For a comprehensive modern introduction
we refer to [31].
A represented space X = (X, δX) is given by a set X and a partial surjection
δX :⊆NN →X. A (multivalued) function between represented spaces is just a
(multivalued) function on the underlying sets. We say that a partial function
F :⊆NN →NN is a realizer for a multivalued function f :⊆X ⇒Y (in symbols:
F ⊢f) if δY(F(p)) ∈f(δX(p)) for all p ∈dom(fδX). We call f computable
(continuous), if it admits some computable (continuous) realizer.
Represented spaces and continuous functions (in the sense just deﬁned) do
indeed generalize Polish spaces and continuous functions (in the usual sense).
Indeed, let (X, τ) be some Polish space, and ﬁx a countable dense sequence
(ai)i∈N and a compatible metric d. Now deﬁne δX by δX(p) = x iﬀd(ap(i), x) <
2−i holds for all i ∈N. In other words, we represent a point by a sequence of
basic points converging to it with a prescribed speed. It is a foundational result
in computable analysis that the notion of continuity for the represented space
(X, δX) coincides with that for the Polish space (X, τ).
Deﬁnition 2. Let f and g be partial multivalued functions between represented
spaces. We say that f is Weihrauch reducible to g, in symbols f ≤W g, if there

330
H. Nobrega and A. Pauly
are computable functions K :⊆NN →NN and H :⊆NN × NN →NN such that
whenever G ⊢g, the function F := (p 
→H(p, G(K(p)))) is a realizer for f.
If there are computable functions K, H :⊆NN →NN such that whenever
G ⊢g then HGK ⊢f, then we say that f is strongly Weihrauch reducible to g
(f ≤sW f). We write f ≤c
W g and f ≤c
sW g for the variations where computable
is replaced with continuous.
A multivalued function f tightens g, denoted by f ⪯g, if dom(g) ⊆dom(f)
and f(x) ⊆g(x) whenever x ∈dom(g), cf. [30,34].
Proposition 3 (cf., e.g., [28, Chapter 4]). Let f :⊆A ⇒B and g :⊆C ⇒
D. We have
1. f ≤sW g (f ≤c
sW g) iﬀthere exist computable (continuous) k :⊆A ⇒C and
h :⊆D ⇒B such that hgk ⪯f; and
2. f ≤W g (f ≤c
W g) iﬀthere exist computable (continuous) k :⊆A ⇒NN × C
and h :⊆NN × D ⇒B such that h(idNN × g)k ⪯f.
Although there are plenty of interesting operations deﬁned on Weihrauch
degrees (cf., e.g., the introduction of [4] for a recent overview), here we only
require the sequential composition operator ⋆from [5,6]. Rather than deﬁning
it explicitly as in [6], we will make use of the following characterization:
Theorem 4 (Brattka and Pauly [6]). f ⋆g ≡W max
≤W {f ′ ◦g′ ; f ′ ≤W f ∧
g′ ≤W g}
3
Transparent Cylinders
We call f :⊆X ⇒Y a cylinder if idNN × f ≤sW f. Note that f is a cylinder iﬀ
g ≤W f and g ≤sW f are equivalent for all g. This notion is from [3].
Deﬁnition 5. Call T :⊆X ⇒Y transparent iﬀfor any computable or contin-
uous g :⊆Y ⇒Y there is a computable or continuous, respectively, f :⊆X ⇒X
such that T ◦f ⪯g ◦T.
The transparent (singlevalued) functions on Baire space were studied by de
Brecht under the name jump operator in [8]. One of the reasons for their relevance
is that they induce endofunctors on the category of represented spaces, which
in turn can characterize function classes in DST [32]. The term transparent was
coined in [5]. Our extension of the concept to multivalued functions between
represented spaces is rather straightforward, but requires the use of the notion
of tightening. Note that if T :⊆X ⇒Y is transparent, then for every y ∈Y
there is some x ∈dom(T) with T(x) = {y}, i.e., T is slim in the terminology of
[5, Deﬁnition 2.7].
Given p ∈NN, recall that for each n ∈N we can deﬁne (p)n ∈NN by
(p)n(k) = p(⌜n, k⌝), where ⌜·, ·⌝is some standard pairing function on nat-
ural numbers. Two examples of transparent cylinders which will be relevant

Game Characterizations and Lower Cones in the Weihrauch Degrees
331
in what follows are the functions lim, limΔ :⊆NN →NN deﬁned by letting
lim(p) = limn∈N(p)n with dom(lim) = {p ∈NN ; limn∈N(p)n exists} and letting
limΔ(p) be the restriction of lim to the domain {p ∈NN ; ∃n ∈N∀k ≥n((p)k =
(p)n)}.
To see an example relating to Semmes’s tree game characterizing the Borel
functions, one ﬁrst needs to deﬁne the appropriate represented space of labeled
trees. For this, it is best to work in a quotient space of labeled trees under the
equivalence relation of bisimilarity (see [27] for the details, which we omit). The
resulting quotient space can be seen as the space of labeled trees in which the
order of the subtrees rooted at the children of a node, and possible repetitions
among these subtrees, are abstracted away. Then the function Prune, which
removes from (any representative of the equivalence class of) a labeled tree
which has one inﬁnite branch all of the nodes which are not part of that inﬁnite
branch, is a transparent cylinder.
Theorem 6 (Brattka and Pauly [6]). For every multivalued function g there
is a multivalued function gt ≡W g which is a transparent cylinder.
Proposition 7. Let T :⊆X ⇒Y and S :⊆Y ⇒Z be cylinders. If T is
transparent then S ◦T is a cylinder and S ◦T ≡W S ⋆T. Furthermore, if S is
also transparent then so is S ◦T.
4
Generalized Wadge Games
In order to deﬁne our generalization of the Wadge game, ﬁrst we need the follow-
ing notion, which is just the dual notion to being an admissible representation
as in the approach taken by Schr¨oder in [36].
Deﬁnition 8. A probe for Y is a computable partial function ζ :⊆Y →NN
such that for every computable or continuous f :⊆Y ⇒NN there is a computable
or continuous, respectively, e :⊆Y ⇒Y such that ζe ⪯f.
Note that a probe is always transparent.
The following deﬁnition generalizes the deﬁnition of a reduction game from
[23, Subsect. 3.1], which is recovered as the special case in which all involved
spaces are NN, the map ζ is the identity on NN, and T is a singlevalued function.
Deﬁnition 9. Let ζ :⊆Y →NN be a probe, T :⊆X ⇒Y and f :⊆A ⇒B.
The (ζ, T)-Wadge game for f is played by two players, I and II, who take turns
in inﬁnitely many rounds. At each round of a run of the game, player I ﬁrst plays
a natural number and player II then either plays a natural number or passes,
as long as she plays natural numbers inﬁnitely often. Therefore, in the long run
player I builds x ∈NN and II builds y ∈NN, and player II wins the run of the
game if x ̸∈dom(fδA), or y ∈dom(δBζTδX) and δBζTδX(y) ⊆fδA(x).

332
H. Nobrega and A. Pauly
It is easy to see that the Wadge game is the (id, id)-Wadge game, the eraser
game is the (id, lim)-Wadge game, and the backtrack game is the (id, limΔ)-
Wadge game. Semmes’s tree game for the Borel functions is the (Label, Prune)-
Wadge game, where Label is the probe extracting the inﬁnite sequence of labels
from (any representative of the equivalence class of) a pruned labeled tree con-
sisting of exactly one inﬁnite branch.
Theorem 10. Let T be a transparent cylinder. Then player II has a (com-
putable) winning strategy in the (ζ, T)-Wadge game for f iﬀf ≤c
W T (f ≤W T).
Proof. (⇒) Any (computable) strategy for player II gives rise to a continu-
ous (computable) function k :⊆NN →NN. If the strategy is winning, then
δBζTδXk ⪯fδA, which implies δBζTδXkδ−1
A ⪯fδAδ−1
A = f. Thus the continu-
ous (computable) maps δB ◦ζ and δXkδ−1
A witness that f ≤c
sW T (f ≤sW T).
(⇐) As T is a cylinder, if f ≤c
W T (f ≤W T), then already f ≤c
sW T
(f ≤sW T). Thus, there are continuous (computable) h, k with h ◦T ◦k ⪯f. As
δB ◦δ−1
B = idB, we ﬁnd that δB ◦δ−1
B ◦h ◦T ◦k ⪯f. Now δ−1
B ◦h :⊆Y ⇒NN is
continuous (computable), so by deﬁnition of a probe, there is some continuous
(computable) e :⊆Y ⇒Y with δB ◦ζ ◦e ◦T ◦k ⪯f. As T is transparent, there
is some continuous (computable) g with e ◦T ⪰T ◦g, thus δB ◦ζ ◦T ◦g ◦k ⪯f.
As (g ◦k) :⊆A ⇒X is continuous (computable), it has some (continuous)
computable realizer K :⊆NN →NN. By Theorem 1, player II has a winning
strategy in the Wadge game for K, and it is easy to see that this strategy also
wins the (ζ, T)-Wadge game for f for her.
Corollary 11. Let T and S be transparent cylinders. If the (ζ, T)-Wadge game
characterizes the class Γ
 and the (ζ′, S)-Wadge game characterizes the class
Γ

′, then the (ζ′, S ◦T)-Wadge game characterizes the class Γ

′ ◦Γ
 := {f ◦
g ; f ∈Γ

′ ∧g ∈Γ
 }.
We thus get game characterizations of many classes of functions, including,
e.g., ones not covered by Motto Ros’s constructions in [23]. For example, con-
sider the function Sort : {0, 1}N →{0, 1}N given by Sort(p) = 0n1N if p contains
exactly n occurrences of 0 and Sort(p) = 0N otherwise. This map was intro-
duced and studied in [26]. From their results it follows that the class Γ
 of total
functions on NN which are Weihrauch-reducible to Sort is neither the class of
pointwise limits of functions in some other class, nor the class of X-measurable
functions for any boldface pointclass X of subsets of NN closed under countable
unions and ﬁnite intersections. By Theorem 6, Sort is Weihrauch-equivalent to a
a transparent cylinder Sortt
NN. Thus, by Theorem 10, Γ
 is characterized by the
(id, Sortt
NN)-Wadge game.
The converse of Theorem 10 is almost true, as well:
Proposition 12. If the (ζ, T)-Wadge game characterizes a lower cone in the
Weihrauch degrees, then it is the lower cone of ζ ◦T, and ζ ◦T is a transparent
cylinder.

Game Characterizations and Lower Cones in the Weihrauch Degrees
333
5
Using Game Characterizations
One main advantage of having game characterizations of some properties is
realized together with determinacy: either by choosing our set-theoretic axioms
accordingly, or by restricting to simple cases and invoking, e.g., Borel determi-
nacy [20], we can conclude that if the property is false, i.e., player II has no
winning strategy, then player I has a winning strategy. Thus, player I’s win-
ning strategies serve as explicit witnesses of the failure of a property. Applying
this line of reasoning to our generalized Wadge games, we obtain the following
corollaries of Theorem 10:
Corollary 13 (ZFC). Let T be a transparent cylinder and ζ a probe such that
ζ ◦T is single-valued and dom(ζ ◦T) is Borel. Then for any f : A ⇒B such
that dom(δA) and f(x) are Borel for any x ∈A, we ﬁnd that f ≰c
W T iﬀplayer
I has a winning strategy in the (ζ, T)-Wadge game for f.
Corollary 14 ZF + DC+ AD). Let T be a transparent cylinder and ζ a
probe. Then f ≰c
W T iﬀplayer I has a winning strategy in the (ζ, T)-Wadge
game for f.
Unfortunately, as determinacy fails in a computable setting (cf., e.g., [10,19]),
we do not retain the computable counterparts. More generally, we are lacking
a clear understanding of how these winning strategies of player I might look
like. As pointed out to the authors by Carroy and Louveau, this holds even for
the original Wadge game, i.e., the (id, id)-Wadge game. Here, we already have
a notion of explicit witnesses for discontinuity: points of discontinuity. We can
thus inquire about their relation:
Question 15. Let a point of discontinuity of a function f : NN →NN be given
as a sequence (an)n∈N, a point a ∈NN, and a word w ∈N<N with w ⊑f(a) such
that ∀n d(an, a) < 2−n ∧w ̸⊑f(an). Let Point be the multivalued map that takes
as input a winning strategy for player I in the (id, id)-Wadge game for some
function f : NN →NN, and outputs a point of discontinuity for that function. Is
Point computable? More generally, what is the Weihrauch degree of Point?
We can somewhat restrict the range of potential answers for the preceding
question:
Theorem 16 (1).
Let player I have a computable winning strategy in the
(id, id)-Wadge game for f : NN →NN. Then f has a computable point of
discontinuity.
A more convenient way of exploiting determinacy of the (ζ, T)-Wadge games
could perhaps be achieved if a more symmetric version were found. In this, we
could hope for a dual principle S, where for any f either f ≤c
W T or S ≤c
W f
holds. More generally, we hope that a better understanding of the (ζ, T)-Wadge
games would lead to structural results about the Weihrauch lattice, similar to
the results obtained by Carroy on the strong Weihrauch reducibility [9].
1 A key lemma for the proof of this theorem goes back to helpful comments by Takayuki
Kihara.

334
H. Nobrega and A. Pauly
6
Generalized Wadge Reductions
As mentioned in the introduction, the Wadge game was introduced not to charac-
terize continuous functions, but in order to reason about a reducibility between
sets. Given A, B ⊆NN, we say that A is Wadge-reducible to B, in symbols
A ≤w B, if there exists a continuous F : NN →NN such that F −1[B] = A.
Equivalently, we could consider the multivalued function B
A : NN ⇒NN deﬁned
by B
A(x) = B if x ∈A and B
A(x) = (NN∖B) if x /∈A. Now, A ≤w B iﬀB
A
is continuous. A famous structural result following from the determinacy of the
corresponding Wadge game is that for any Borel A, B ⊆NN, either A ≤w B or
NN∖B ≤w A. In particular, the Wadge hierarchy on the Borel sets is a strict
weak order of width 2.
Both deﬁnitions immediately generalize to the case where A ⊆X and B ⊆Y
for represented spaces X, Y. However, they yield diﬀerent notions, for not every
continuous multivalued function has a continuous choice function. As noted, e.g.,
by Hertling [14], extending the former deﬁnition to the reals already introduces
inﬁnite antichains in the resulting degree structure. The second generalization
was proposed by Pequignot [35] as an alternative.2
It is a natural variation to replace continuous in the deﬁnition of Wadge
reducibility by some other class of functions (ideally one closed under composi-
tion). Motto Ros has shown that for the typical candidates of more restrictive
classes of functions, the resulting degree structures will not share the nice proper-
ties of the standard Wadge degrees (they are bad) [24]. Larger classes of functions
as reduction witnesses have been explored by Motto Ros, Schlicht, and Selivanov
[25] in the setting of quasi-Polish spaces—using the generalization of the ﬁrst
deﬁnition of the reduction.
Deﬁnition 17. Let T be a Weihrauch degree. We deﬁne a relation ⪯T on sub-
sets of represented spaces as follows: For A ⊆X, B ⊆Y let A ⪯T B hold iﬀ
B
A ≤c
W T.
Observation 18. If T ⋆T ≡W T, then ⪯T is a quasiorder.
The following partially generalizes [23, Theorem 6.10]:
Theorem 19. Let A ⊆X and B ⊆Y, let T : U ⇒V be a transparent cylinder,
and let ζ :⊆Y →NN be a probe such that the (ζ, T)-Wadge game for
B
A is
determined. Then either A ⪯T B or B ≤w NN∖A.
Proof. If player II has a winning strategy in the (ζ, T)-Wadge game for B
A, then
by Theorem 10, we ﬁnd that B
A ≤c
W T, hence A ⪯T B.
Otherwise, player I has a winning strategy. This winning strategy induces
a continuous function s : NN →NN, such that if player II plays y ∈NN, then
2 While Pequignot only introduces the notion for second countable T0 spaces, the
extension to all represented spaces is immediate. Note that one needs to take into
account that for general represented spaces, the Borel sets can show unfamiliar
properties, e.g., even singletons can fail to be Borel (cf. also [37,38]).

Game Characterizations and Lower Cones in the Weihrauch Degrees
335
player I plays s(y) ∈NN. As T is a transparent cylinder and ζ a probe, there is
a continuous function t : NN →NN such that (ζ ◦T ◦δU ◦t) = idNN. Now we
consider s ◦t : NN →NN. If δX(x) ∈A, then if player II plays t(x), player I
needs to play some s(t(x)) such that δY(s(t(x))) /∈B. Likewise, if δX(x) /∈A,
then for player I to win, it needs to be the case that δY(s(t(x))) ∈B. Thus, s◦t
is a continuous realizer of
B
NN∖A, and B ≤w NN∖A follows.
Corollary 20 (ZF + DC + AD). Suppose T ⋆T ≡W T. Then ≺T is strict
weak order of width at most 2.
In [22], Motto Ros has identiﬁed suﬃcient conditions on a generalized reduc-
tion (although in a diﬀerent formalism) to ensure that its degree structure is
equivalent to the Wadge degrees. We leave for future work the task of deter-
mining precisely for which T the degree structure of ≺T (restricted to subsets
of NN) is equivalent to the Wadge degrees, and which other structure types are
realizable.
Acknowledgments. We are grateful to Benedikt L¨owe, Luca Motto Ros, Takayuki
Kihara and Rapha¨el Carroy for helpful and inspiring discussions. We would also like
to thank the anonymous referees for the many corrections which have signiﬁcantly
improved the paper.
References
1. Andretta, A.: The SLO principle and the Wadge hierarchy. In: Bold, S., L¨owe, B.,
R¨asch, T., van Benthem, J. (eds.) Foundations of the Formal Sciences V: Inﬁnite
Games, pp. 1–38. College Publications (2007)
2. Brattka, V., Gherardi, G.: Eﬀective choice and boundedness principles in com-
putable analysis. Bull. Symbolic Log. 1, 73–117 (2011). arXiv:0905.4685
3. Brattka, V., Gherardi, G.: Weihrauch degrees, omniscience principles and weak
computability. J. Symbolic Log. 76, 143–176 (2011). arXiv:0905.4679
4. Brattka,
V.,
Gherardi,
G.,
H¨olzl,
R.:
Probabilistic
com-
putability
and
choice.
Inf.
Comput.
242,
249–286
(2015).
http://www.sciencedirect.com/science/article/pii/S0890540115000206,
arXiv:1312.7305
5. Brattka, V., Gherardi, G., Marcone, A.: The Bolzano-Weierstrass theorem is the
jump of weak K¨onig’s lemma. Ann. Pure Appl. Log. 163(6), 623–625 (2012)
6. Brattka, V., Pauly, A.: On the algebraic structure of Weihrauch degrees (2016).
arXiv 1604.08348, http://arxiv.org/abs/1604.08348
7. de Brecht, M.: Quasi-Polish spaces. Ann. Pure Appl. Log. 164(3), 354–381 (2013)
8. de Brecht, M.: Levels of discontinuity, limit-computability, and jump operators.
In: Brattka, V., Diener, H., Spreen, D. (eds.) Logic, Computation, Hierarchies, pp.
79–108 (2014). de Gruyter, arXiv:1312.0697
9. Carroy, R.: A quasi-order on continuous functions. J. Symbolic Log. 78(2), 633–648
(2013)
10. Cenzer, D., Remmel, J.: Recursively presented games and strategies. Math. Soc.
Sci. 24(2–3), 117–139 (1992)

336
H. Nobrega and A. Pauly
11. Duparc,
J.:
Wadge
hierarchy
and
Veblen
hierarchy
part
I:
Borel
sets
of
ﬁnite
rank.
J.
Symbolic
Log.
66(1),
56–86
(2001).
http://projecteuclid.org/euclid.jsl/1183746360
12. Gale, D., Stewart, F.M.: Inﬁnite games with perfect information. In: Kuhn, H.W.,
Tucker, A.W. (eds.) Contributions to the Theory of Games, vol. 2, pp. 245–266.
Princeton University Press (1953)
13. Gherardi, G., Marcone, A.: How incomputable is the separable Hahn-Banach the-
orem? Notre Dame J. Formal Log. 50(4), 393–425 (2009)
14. Hertling, P.: Unstetigkeitsgrade von Funktionen in der eﬀektiven Analysis. Ph.D.
thesis, Fernuniversit¨at, Gesamthochschule in Hagen (Oktober 1996)
15. Higuchi, K., Pauly, A.: The degree-structure of Weihrauch-reducibility. Log. Meth-
ods Comput. Sci. 9(2), 1–17 (2013)
16. Kanamori, A.: The Higher Inﬁnite: Large Cardinals in Set Theory from their Begin-
nings. Springer Monographs in Mathematics, 2nd edn. Springer, Heidelberg (2005)
17. Kechris, A.S.: Classical Descriptive Set Theory. Graduate Texts in Mathematics,
vol. 156. Springer, Heidelberg (1995)
18. Kihara, T., Pauly, A.: Point degree spectra of represented spaces (2014).
arXiv:1405.6866
19. Le Roux, S., Pauly, A.: Weihrauch degrees of ﬁnding equilibria in sequential games.
In: Beckmann, A., Mitrana, V., Soskova, M. (eds.) CiE 2015. LNCS, vol. 9136, pp.
246–257. Springer, Cham (2015). doi:10.1007/978-3-319-20028-6 25
20. Martin, D.A.: Borel determinacy. Ann. Math. 102(2), 363–371 (1975)
21. Moschovakis, Y.N.: Classical descriptive set theory as a reﬁnement of eﬀective
descriptive set theory. Ann. Pure Appl. Log. 162, 243–255 (2010)
22. Ros, L.M.: Borel-amenable reducibilities for sets of reals. J. Symbolic Log. 74(1),
27–49 (2009). http://dx.doi.org/10.2178/jsl/1231082301
23. Ros, L.M.: Game representations of classes of piecewise deﬁnable functions. Math.
Log. Q. 57(1), 95–112 (2011)
24. Ros, L.M.: Bad Wadge-like reducibilities on the baire space. Fundam. Math.
224(1), 67–95 (2014)
25. Ros, L.M., Schlicht, P., Selivanov, V.: Wadge-like reducibilities on arbitrary quasi-
Polish spaces. Mathematical Structures in Computer Science pp. 1–50 (2014).
http://journals.cambridge.org/article S0960129513000339, arXiv:1204.5338
26. Neumann, E., Pauly, A.: A topological view on algebraic computation models
(2016). arXiv:1602.08004
27. Nobrega, H., Pauly, A.: Game characterizations and lower cones in the Weihrauch
degrees (2015). arXiv:1511.03693
28. Pauly, A.: Computable Metamathematics and its Application to Game Theory.
Ph.D. thesis, University of Cambridge (2012)
29. Pauly, A.: The descriptive theory of represented spaces (2014). arXiv:1408.5329
30. Pauly, A.: Many-one reductions and the category of multivalued functions. Math-
ematical Structures in Computer Science (2015). arXiv:1102.3151
31. Pauly, A.: On the topological aspects of the theory of represented spaces. Com-
putability 5(2), 159–180 (2016). http://arxiv.org/abs/1204.3763
32. Pauly, A., de Brecht, M.: Towards synthetic descriptive set theory: An instantiation
with represented spaces (2013). http://arxiv.org/abs/1307.1850
33. Pauly, A., de Brecht, M.: Descriptive set theory in the category of represented
spaces. In: 30th Annual ACM/IEEE Symposium on Logic in Computer Science
(LICS), pp. 438–449 (2015)
34. Pauly, A., Ziegler, M.: Relative computability and uniform continuity of relations.
J. Log. Anal. 5, 1–39 (2013)

Game Characterizations and Lower Cones in the Weihrauch Degrees
337
35. Pequignot, Y.: A Wadge hierarchy for second countable spaces. Arch. Math. Log.
54(5), 1–25 (2015). http://dx.doi.org/10.1007/s00153-015-0434-y
36. Schr¨oder, M.: Extended admissibility. Theoret. Comput. Sci. 284(2), 519–538
(2002)
37. Schr¨oder, M., Selivanov, V.: Hyperprojective hierarchy of QCB0-spaces (2014).
arXiv:1404.0297, http://arxiv.org/abs/1404.0297
38. Schr¨oder, M., Selivanov, V.L.: Some hierarchies of QCB0-spaces. Math. Struct.
Comput. Sci. 25(8), 1–25 (2014). arXiv:1304.1647
39. Semmes, B.: A game for the Borel functions. Ph.D. thesis, University of Amsterdam
(2009)
40. Wadge, W.W.: Reducibility and determinateness on the Baire space. Ph.D. thesis,
University of California, Berkeley (1983)
41. Weihrauch, K.: The degrees of discontinuity of some translators between repre-
sentations of the real numbers. Informatik Berichte 129, FernUniversit¨at Hagen,
Hagen, July 1992
42. Weihrauch, K.: The TTE-interpretation of three hierarchies of omniscience princi-
ples. Informatik Berichte 130, FernUniversit¨at Hagen, Hagen, September 1992
43. Weihrauch, K.: Computable Analysis. Springer, Heidelberg (2000)
44. Wesep,
R.:
Wadge
degrees
and
descriptive
set
theory.
In:
Kechris,
A.S.,
Moschovakis, Y.N. (eds.) Cabal Seminar 76–77. LNM, vol. 689, pp. 151–170.
Springer, Heidelberg (1978). doi:10.1007/BFb0069298

Randomness Deﬁciencies
Gleb Novikov(B)
Lomonosov Moscow State University, Moscow, Russia
novikov.g.e@gmail.com
Abstract. The
notion
of
random
sequence
was
introduced
by
Martin-L¨of in [3]. In the same article he deﬁned the so-called random-
ness deﬁciency function that shows how close are random sequences to
non-random (in some natural sense). Other deﬁciency functions can be
obtained from the Levin-Schnorr theorem, that describes randomness in
terms of Kolmogorov complexity. The diﬀerence between all of these deﬁ-
ciencies is bounded by a logarithmic term (Proposition 1). In this paper
we show (Theorems 1 and 2) that the diﬀerence between some deﬁciencies
can be as large as possible.
1
Introduction
Classical probability theory cannot deal with individual random objects, such as
binary sequences or points on the real line: each sequence or point has measure
zero (with respect to the uniform measure). However, our intuition says that the
sequence of zeros (and any other computable sequence) is not random, while the
result of tossing a coin is. Martin-L¨of in [3] tried to formalize this statement. He
used an algorithmic approach to deﬁne random binary sequences.
Martin-L¨of random sequences have many nice properties: adding, deleting or
changing ﬁnitely many bits doesn’t change randomness; random sequences sat-
isfy the law of large numbers; computable permutations preserve randomness.
So if the sequence ω is random, the sequence ω′ = 01000000000ω (billion of zeros
concatenated with ω) is also random. But intuitively ω′ is “less random”. We
can make this argument formal using a randomness deﬁciency function d: this
function is ﬁnite on random sequences and inﬁnite on non-random sequences. If
d(ω′) ≥d(ω) we say that ω′ is less random than ω. It turns out that there are
some natural types of deﬁciency functions that have similar properties to the
so-called ﬁnite deﬁciency (the diﬀerence between the length of the string and its
Kolmogorov complexity). For example, adding n zeros to the sequence increases
randomness deﬁciency by n+O(log n). Using this fact one can reformulate state-
ments about random sequences in terms of the deﬁciency functions to look for
the connections between algorithmic randomness and Kolmogorov complexity
theories.
In this paper we consider several deﬁciency functions: the ﬁrst was intro-
duced by Martin-L¨of (Deﬁnition 3), the others appear from the Levin-Schnorr’s
criterion of randomness in terms of diﬀerent types of Kolmogorov complexity:
the preﬁx-free complexity and the a priori complexity. The diﬀerence between all
c
⃝Springer International Publishing AG 2017
J. Kari et al. (Eds.): CiE 2017, LNCS 10307, pp. 338–350, 2017.
DOI: 10.1007/978-3-319-58741-7 32

Randomness Deﬁciencies
339
of the deﬁciencies is not greater than (1+ε) log d (up to a constant, for all ε > 0)
(Proposition 1), where d is one of the deﬁciency functions. We show that the dif-
ference between some of the deﬁciencies can be greater than log d. For example,
some of the deﬁciency functions (given in exponential scale) are integrable, while
the others are not and that is the reason of the diﬀerence (Theorem 1). To diﬀer
the non-integrable deﬁciencies we construct a special rareﬁed set of intervals in
the Cantor space (Theorem 2).
1.1
Notation
The set of all inﬁnite binary sequences is called the Cantor space and is denoted
by Ω. An interval in the Cantor space is a set of extensions of some string x, it
is denoted by [x].
The set of all binary strings is denoted by B∗. The length of the string x is
denoted by |x|. We write y ≺x if y is a preﬁx of x.
IS is the indicator function of the set S.
In this paper, log means binary logarithm.
Notation f <+ g (f <∗g) means that there exists a constant c such that
for all x , f(x) < c + g(x) (f(x) < cg(x)).
2
Preliminaries
One can ﬁnd all of the notions and statements of this section in [1,2].
Deﬁnition 1. A measure μ over Ω is called computable, if there exists a Turing
machine that from each string x and rational ε > 0 returns an ε-approximation
of the value μ([x]).
The collection of intervals in the Cantor space forms a base for its standard
topology. We will talk about closed and open sets relative to this topology.
Deﬁnition 2. Let μ be a computable measure. A nested sequence of open sets
{Vn} is called a Martin-L¨of test with respect to μ if:
(1) {Vn} is uniformly eﬀectively open, that is there exists a Turing machine
that for each input k enumerates the set Vk.
(2) μ(Vn) ≤2−n for each n.
Deﬁnition 3. Let {Vn} be a Martin-L¨of test with respect to a computable mea-
sure μ. Function dμ;{Vn}(ω) = max{k : ω ∈Vk} is called a randomness deﬁciency
of ω with respect to the test {Vn}.
Lemma 1. For every computable measure μ there exists a Martin-L¨of test {Un}
with respect to μ such that for any Martin-L¨of test {Vn} with respect to μ there
exist a constant c such that for all sequences ω
dμ;{Un}(ω) ≥dμ;{Vn}(ω) −c
(1)

340
G. Novikov
The deﬁciency function dμ was deﬁned by Martin-L¨of in [3]. In the same article
he introduced the following notion of randomness:
Deﬁnition 4. Let μ be a computable measure. A sequence ω ∈Ω is called
Martin-L¨of random with respect to μ if dμ(ω) < ∞.
There are some other types of deﬁciency functions. To show the relations between
them, we need to reformulate the deﬁnition of dμ. First we deﬁne the so-called
lower semicomputable functions.
Deﬁnition 5. A function t : Ω →R is called lower semicomputable if there
exists a machine that given a rational r enumerates the set of intervals {ω :
t(ω) > r} (so this set should be open).
Let’s note the following property of dμ: the function tμ = 2dµ is probability
bounded, that is
μ{tμ(ω) > c} ≤1
c
(2)
for rational numbers c. Moreover, tμ is the largest (up to a multiplicative con-
stant) among all lower semicomputable probability bounded functions (the sets
Vn = {t(ω) > 2n} form a Martin-L¨of test). Therefore we can deﬁne the func-
tion dμ as logarithm of the largest lower semicomputable probability bounded
function and from now we denote this function as dP
μ (and tμ as tP
μ ).
To deﬁne other deﬁciency functions we need the following notion:
Deﬁnition 6. Function f : Ω →Q is called basic if its value on every sequence
ω is determined by some ﬁnite preﬁx of ω.
By compactness of Ω there exist ﬁnitely many intervals where basic function
is constant, and the union of these intervals is Ω. Therefore basic functions
are constructive objects and we can consider computable sequences of basic
functions.
The following lemma gives the equivalent deﬁnition of lower semicomputable
functions.
Lemma 2. Function t : Ω →R is lower semicomputable iﬀit is a limit of
increasing computable sequence of basic functions.
If the function is integrable and its integral is less than 1 it is probability bounded
(by Markov’s inequality). We call these functions expectation bounded. There
exists maximal (up to a multiplicative constant) lower semicomputable expecta-
tion bounded function tE
μ : we can enumerate all probability bounded functions
(with respect to μ); the integral of such function is a limit of integrals of basic
functions, so if it is greater than 1 we always know it after ﬁnitely many steps
of computation. If the integral is greater than 1, we decrease the values of basic
functions to make it less than 1. The sum of these new functions with weights
2−n is the maximal lower semicomputable expectation bounded function.

Randomness Deﬁciencies
341
Deﬁnition 7. Let μ be a computable measure. The expectation bounded
deﬁciency is the function
dE
μ (ω) = log tE
μ (ω)
(3)
The following proposition shows that the diﬀerence between dp
μ and dE
μ is not
large.
Proposition 1. Let μ be a computable measure and ε > 0. Then
dE
μ ≤+ dP
μ ≤+ dE
μ + (1 + ε) log dE
μ
(4)
Proof. The ﬁrst part follows from Markov’s inequality. To prove the second part,
let’s consider a function tP
μ log−1−ε tP
μ . Its integral does not exceed

n

An
tP
μ (ω) log−1−ε tP
μ (ω)dμ(ω) ≤

n
2n−1−ε
(5)
where An = {2n ≤tP
μ < 2n+1}, so this integral is ﬁnite. Therefore
dP
μ ≤+ dE
μ + (1 + ε) log dP
μ ≤+ dE
μ + (1 + ε) log dE
μ
(6)
⊓⊔
The deﬁciency function dE
μ can be described in terms of preﬁx-free Kolmogorov
complexity (see, for example, [2]). We will brieﬂy describe this construction.
At ﬁrst we deﬁne the discrete analogues of basic and lower semicomputable
functions.
Deﬁnition 8. Function f : B∗→Q is called basic if its support is ﬁnite.
Deﬁnition 9. Function f : B∗→R is called lower semicomputable if it is a
limit of a computable sequence of increasing basic functions.
Deﬁnition 10. A lower semicomputable function m : B∗→[0, ∞) such that

x m(x) ≤1 is called a discrete lower semicomputable semimeasure.
Let’s denote the preﬁx-free Kolmogorov complexity of a string x as K(x). The
function m(x) = 2−K(x) is called the discrete a priori probability. The famous
coding theorem (see, for example, [2]) states that this function is the largest
(up to a multiplicative constant) among all discrete lower semicomputable semi-
measures.
It can be shown (see, for example, [1]) that
tE
μ (ω) =∗
n
m(ω1...n)
μ([ω1...n]) =∗sup
n
m(ω1...n)
μ([ω1...n])
(7)
In logarithmic scale:
dE
μ (ω) =+ sup
n {−log μ([ω1...n]) −K(ω1...n)}
(8)

342
G. Novikov
This result is due to Gacs (see [4]). The value in the right part of 8 is ﬁnite iﬀthe
sequence is random. It was ﬁrst shown by Schnorr and Levin independently in
[5,6]. Informally, the sequence is random iﬀits initial segments are incompress-
ible. The Eq. 8 also shows that if one adds n zeros to the sequence then the ran-
domness deﬁciency (probability or expectation bounded) increases by at most
n + O(log n).
The Schnorr-Levin theorem can be formulated in terms of the so-called a pri-
ori complexity. To deﬁne it we need the notion of continuous a priori probability.
Deﬁnition 11. A lower semicomputable function a : B∗→[0, ∞) such that

x∈S a(x) ≤1 for every preﬁx-free set S is called a continuous lower semicom-
putable semimeasure.
We can enumerate all continuous lower semicomputable semimeasures and con-
sider a semimeasure a(x) = 
j aj(x)2−j. This semimeasure is also continuous
and lower semicomputable, and it is the largest (up to a multiplicative con-
stant) in this class of semimeasures. We will call a(x) the continuous a priori
probability.
Deﬁnition 12. The value KM(x) = −log a(x) is called the a priori complexity
of x.
The Schnorr-Levin theorem for the a priori complexity states that the sequence ω
is random iﬀsupn{−log μ([ω1...n])−KM(ω1...n)} is ﬁnite. Moreover, supremum
can be replaced by lim sup or lim inf. Using this theorem we can deﬁne other
types of deﬁciency functions.
Deﬁnition 13. Let μ be a computable measure. We will consider functions
dM
μ (ω) = sup
n {−log μ([ω1...n]) −KM(ω1...n)}
(9)
dlim sup M
μ
(ω) = lim sup
n
{−log μ([ω1...n]) −KM(ω1...n)}
(10)
dlim inf M
μ
(ω) = lim inf
n
{−log μ([ω1...n]) −KM(ω1...n)}
(11)
and call them a priori randomness deﬁciencies.
Each continuous lower semicomputable semimeasure can be represented as a
probability distribution on the initial segments of outputs of some probabilistic
machine that prints bits one after another and does not have to stop (see, for
example, [2]). That is for each a(x) there exists a machine A such that
a(x) = P{the output of A begins on the string x}
(12)
Informally, the Schnorr–Levin theorem states that the sequence ω is random
iﬀthe probability of getting the initial segments ω1...n using a probabilistic
machine cannot be much greater than getting it from a random generator (with
the distribution μ). The deﬁciency functions from the Deﬁnition 13 show the
diﬀerence between logarithms of these probabilities.
One can use supermartingales to deﬁne the deﬁciencies dM
μ , dlim sup M
μ
(ω),
dlim inf M
μ
(ω).

Randomness Deﬁciencies
343
Deﬁnition 14. Let μ be a measure on Ω and let M be a function of binary
strings.
If μ([x])M(x) = μ([x0])M(x0) + μ([x1])M(x1) the function M is called a
martingale.
If μ([x])M(x) ≥μ([x0])M(x0) + μ([x1])M(x1) the function M is called a
supermartingale.
If μ([x])M(x) ≤μ([x0])M(x0) + μ([x1])M(x1) the function M is called a
submartingale.
If martingale (or sub/supermartingale) is not bounded on the initial segments
of the sequence ω we say that it wins on ω.
If μ is computable, the supermartingale M(x) =
a(x)
μ([x]) is the largest (up to
a multiplicative constant) among all lower semicomputable supermartingales.
Supermartingale M(x) wins on all non-random sequences and does not win on
random sequences.
The deﬁciency dM
μ (ω) is a supremum of M(ω1...n), the deﬁciencies
dlim sup M
μ
(ω) and dlim inf M
μ
(ω) are respectively limsup and liminf of M(ω1...n).
Now we are going to show the relations between the deﬁciencies.
Proposition 2.
dE
μ ≤+ dlim inf M
μ
(13)
Proof. We need to construct some continuous lower semicomputable semimea-
sure a. Once the approximation to m(x) increases by ε we do the following:
(1) Increase the value of a by ε on preﬁxes of x
(2) Increase the value of a by εμ([y])/μ([x]) on the extensions y of x.
If dE
μ = R there exists a string x such that
−log μ([x]) −K(x) =+ R
(14)
and ω is the extension of x. If n > |x|, the logarithm of a is:
log a(ω1...n) ≥−K(x) + log μ([ω1...n]) −log μ([x])
(15)
Therefore
dlim inf M
μ
(ω) ≥+ lim inf
n
{−log μ([ω1...n]) + log a(ω1...n)} ≥
≥lim inf
n
{−log μ([x]) −K(x)} = −log μ([x]) −K(x) =+ dE
μ
(16)
The case dE
μ = ∞can be considered in the same way.
⊓⊔
Proposition 3.
dM
μ ≤+ dP
μ
(17)

344
G. Novikov
Proof. It is suﬃcient to show that μ{2dM
µ (ω) > 2c} ≤2−c for all rational c. Let’s
ﬁx c and consider a set of strings
S = {x : a(x)
μ([x]) > 2c, ∀y ≺x
a(y)
μ([y]) ≤2c}
(18)
It is evident that ω ∈∪x∈S[x] iﬀdM
μ (ω) > c. The set S is preﬁx-free, so
μ{2dM
µ (ω) > 2c} =

x∈S
μ([x]) <

x∈S
a(x)
2c
≤2−c
(19)
⊓⊔
Combining the results of Propositions 1, 2 and 3 we can write down the following
chain of inequalities:
dE
μ ≤+ dlim inf M
μ
≤+ dlim sup M
μ
≤+ dM
μ ≤+ dP
μ ≤+ dE
μ + (1 + ε) log dE
μ
(20)
The natural question is about the diﬀerence between these deﬁciencies. To
show the diﬀerence between some of them we will need the following lemma from
calculus:
Lemma 3. If ck ≥0 and ∞
k=1 ck < ∞and Rk := ∞
n=k+1 cn > 0, then
∞

k=1
ck
Rk log
1
RK
= ∞
(21)
Proof. At ﬁrst we will prove that the series ∞
k=1
ck
Rk does not converge. Denote
zk = ck
Rk . It is evident that
zk = Rk−1 −Rk
Rk
= Rk−1
Rk
−1 =⇒
1
Rk
= 1
R0
k

n=1
(1 + zn)
(22)
If we take the logarithm from both parts, we get
log 1
Rk
= log 1
R0
+
k

n=1
log(1 + zn) ≤∗
k

n=1
zn
(23)
The left part tends to inﬁnity, so the sum ∞
n=1 zn is inﬁnite. To prove the
lemma we need to show that ∞
k=1
zk
log
1
Rk
= ∞. Using 23 we get:
∞

k=1
zk
log
1
Rk
≥∗
∞

k=1
zk
k
n=1 zn
(24)
Denote Sk = k
n=1 zn and bk =
zk
Sk . It is suﬃcient to show that if the series
∞
n=1 zn does not converge then the series ∞
n=1 bn also does not converge. We
will do it in the same way as the ﬁrst part of the proof of the lemma:
bk = Sk+1 −Sk
Sk
= Sk+1
Sk
−1 =⇒Sk+1 = S1
k

n=1
(1 + bn)
(25)

Randomness Deﬁciencies
345
If we take the logarithm from both parts we get
log Sk = log S1 +
k

n=1
log(1 + bn) ≤∗
k

n=1
bn
(26)
The left part tends to inﬁnity, so the sum ∞
n=1 bn is inﬁnite.
⊓⊔
3
New Results
Now we are going to show the relations between deﬁciency functions.
Proposition 4 is an eﬀective version of Doob’s martingale convergence theorem
(see, for example, [7]) and can be easily obtained from it. Theorems 1 and 2
require Lemma 3.
Deﬁnition 15. If the sequence ω is random relative to the oracle 0′ it is called
2-random.
Proposition 4. Let μ be a computable measure. If ω is 2-random (with respect
to μ), then dlim sup M
μ
(ω) = dlim inf M
μ
(ω).
Proof. Given rational numbers β > α > 0 we can construct a 0′-computable
supermartingale M β
α that wins on sequences ω such that the supermartingale M
inﬁnitely many times becomes smaller than α and greater than β on the initial
segments of ω. Using the oracle we compute the values of M and if M(x) < α the
values M β
α(z) are equal to M(z) on extensions z of x such that M(z) ≤β. When
we ﬁnd extension y such that M(y) > β we just save the capital (M β
α(yw) =
M β
α(y)) until we ﬁnd some new string x with small M(x). On the segments from
x to y the value of M β
α increases by β
α times. The sum of all M β
α with weights
m(α, β) is a 0′-lower semicomputable supermartingale, so it is ﬁnite on 2-random
sequences.
⊓⊔
Corollary 1. Let μ be a computable measure. Then 2dlim sup M
µ
is the integrable
function with respect to μ.
Proof. By Fatou’s lemma:

Ω
lim inf
n
M(ω1...n)dμ(ω) ≤lim inf
n

Ω
M(ω1...n)dμ(ω) = lim inf
n

|x|=n
a(x) ≤1
(27)
dlim sup M
μ
= dlim inf M
μ
almost everywhere, therefore 2dlim sup M
µ
is integrable.
⊓⊔
The greater deﬁciencies are not integrable (in exponential scale). To show that
2dM
µ is not integrable we need Lemma 3.
Recall the deﬁnition of atomic measures.
Deﬁnition 16. If the measure μ on Ω is positive on some sequence, we will say
that μ is an atomic measure.

346
G. Novikov
The following theorems show that the diﬀerence between dM
μ and other deﬁcien-
cies may be greater then log dμ (here we write dμ without index because diﬀer-
ence between logarithms of all of the deﬁciencies is bounded by some constant).
Theorem 1. Let μ be a computable non-atomic measure. For all c there exists
ω such that
dlim sup M
μ
(ω) < dM
μ (ω) −log dM
μ (ω) −c
(28)
Proof. It is suﬃcient to prove that the function q = 2dM
µ −log dM
µ is not integrable
with respect to μ. We will construct some deterministic (but formally probabilis-
tic) machine f. At each step, after f has printed the string of bits x of length k,
f computes measures of [x0] and [x1], and then prints a bit b if μ[xb] > 1
3μ[x] (if
the both bits are suitable, let f print 0). Denote the interval [xb] = Bk if at the
k-th step f prints a bit b, and Ck = Bk−1 \ Bk. The measure μ is non-atomic,
hence
μBk =
∞

n=k+1
μCn
(29)
The intervals Ck are disjoint, so 
k Ck ≤1. By Lemma 3
∞

k=1
μCk
μBk log
1
μBk
= ∞
(30)
Let’s denote
tf(ω) = sup
n
P{the output of f begins on the string ω1...n}
μ([ω1...n])
(31)
The function
x
log x is monotone for large enough x, therefore by the universality
q ≥∗
tf
log tf
(32)
It is easy to see that
tf
log tf
(ω) =
∞

k=1
ICk+1(ω)
μBk log
1
μBk
(33)
Recall that μBk ≥μBk+1 > 1
3μBk

Ω
q(ω)dω ≥∗

Ω
tf
log tf
(ω)dω ≥
∞

k=1
μCk+1
μBk log
1
μBk
> 1
3
∞

k=1
μCk+1
μBk+1 log
1
μBk+1
= ∞
(34)
⊓⊔
The following theorem requires some technical constructions in general case, so
at ﬁrst we will prove it in the case of the uniform measure to show the idea.

Randomness Deﬁciencies
347
Theorem 2. Let μ be a computable non-atomic measure. For all c there exists
ω such that
dM
μ (ω) < dP
μ (ω) −log dP
μ (ω) −c
(35)
Proof (Uniform case). The main idea is that one cannot win 50$ after 5 tosses of
a coin if he starts with 1$. Let’s consider a function g = 
k 22k−1I[0k1k](ω). It is
a lower semicomputable probability bounded function. Let’s prove the theorem
by contradiction. Assume that there exists a constant c such that for all ω
tM
μ (ω) ≥2−c
g
log g (ω)
(36)
That means that there exists a preﬁx-free set of binary strings wk
l such that
∪l[wk
l ] ⊃0k1k and
a(wk
l )2|wk
l | ≥2−c 22k−1
2k −1
(37)
For k large enough
|wk
l | ≥−c −log(2k −1) + 2k −1 + KM(wk
l ) > k + 1
(38)
So [wk
l ] ⊂[0k1]. Hence the set {wk
l }k,l is preﬁx-free. Consider the following chain
of inequalities:
1 ≥

k

l
a(wk
l ) ≥

k

l
2−c−|wk
l | 22k−1
2k −1 ≥∗
≥∗
k
2−|0k1k| 22k−1
2k −1 =

k
1
2(2k −1) = ∞
(39)
This contradiction proves the theorem.
⊓⊔
Proof (General case). Now we replace the intervals [0k1] and [0k1k] by Ck and
Dk (see below) respectively. We cannot make the measures of Dk very small,
because it decreases g, but they also cannot be large, because g should be prob-
ability bounded. We will ﬁnd suitable sets {Ck} and {Dk} that satisfy all of the
conditions.
Let’s consider the intervals Bk and Ck from Theorem 1. The series  μ(Ck)
computably converges, hence for every computable sequence of positive rational
numbers εk that tends to 0, the one-to-one function τ : N →N such that
μ(Cτ(k)) ≥(1 −εk)μ(Cm) for all m /∈{τ(1), . . . , τ(k −1)} is also computable.
We will choose suitable sequence εk later. Denote Cτ(k) = Ck and consider
zk = −
3
log μCk . The sequence Sk = 1 + 
j≤k zj is computable. Let’s show that
Sk →∞:
Recall that

k
μCk+1
μBk log
1
μBk
= ∞
(40)

348
G. Novikov
The function
x
log x is monotone for large enough x, therefore

k
zk =

k
3
log
1
μCk
= 3

k
μCk
μCk log
1
μCk
≥3

k
μCk+1
μBk log
1
μBk
= ∞
(41)
If μ(Ck) ̸= 0, then k = τ(j) for some j, so 
k zk = 
k
3
log
1
µCk
.
For all Ck, we can construct an interval Dk ⊂Ck with such property:
1
3(μCk)Sk < μDk < (μCk)Sk
(42)
Let xk be a string such that [xk] = Ck. We compute μ([xk0]) and μ([xk1])
and choose the next bit b if μ[xkb] > 1
3μ[xk] (if the both bits are suitable, let’s
choose 0). After that we repeat this procedure with a string xkb and so on. We
stop when the condition 42 holds for the interval Dk (the set of the extensions
of the latest string). It always happens, because the measure is non-atomic (so
μ[xkb1 . . . bm] tends to 0), and μ[xkb1 . . . bm−1] < 3μ[xkb1 . . . bm].
Consider a function
g(ω) =

k
IDk(ω)
2μDk
(43)
It is lower semicomputable. To prove that it is probability bounded it is suﬃcient
to show that
μDj ≥

i:μDi<μDj
μDi
(44)
Indeed, consider the set {g(ω) > C}:
μ{g(ω) > C} =

i:μDi< 1
2C
μDi ≤2 max{μDi : μDi < 1
2C } < 1
C
(45)
The sequence μCSj
j
is exponentially decreasing:
μCSj
j
μCSj+1
j+1
≥(1 −εj)SjμCSj−Sj+1
j+1
= (1 −εj)1+ zjμC−zj+1
j+1
≥
≥(1 −εj)Mj2−zj+1 log Cj+1 ≥3
48 = 6
(46)
Where M = −
3
log 2
3 ≥max zk. Here one can see how to choose the sequence εk:
(1 −εj)Mj should be not less than 3
4. This inequality shows that

i:μDi<μDj
μDi =

i>j
μDi ≤

k≥1
(1
2)−kμDj ≤μDj
(47)
Therefore the function g is probability bounded.

Randomness Deﬁciencies
349
Assume that there exists a constant c such that for all ω
tM
μ (ω) ≥2−c
g
log g (ω)
(48)
Where tM
μ = 2dM
µ (ω). If ω ∈Dk, then for this k there exists a preﬁx-free set of
strings wk
l such that ∪l[wk
l ] ⊃Dk and
a(wk
l )
μ([wk
l ]) ≥2−c
1
2μDk log
1
μDk
(49)
Using the Property 42 for large enough k we get:
μ([wk
l ]) ≤2c+1a(wk
l )μDk log
1
μDk
<

μDk < μCk
(50)
Therefore wk
l ⊂Ck and the set {wk
l }k,l is preﬁx-free.
Consider the following chain of inequalities:
1 ≥

k,l
a(wk
l ) ≥

k,l
μ([wk
l ])2−c−1
1
μDk log
1
μDk
≥∗
≥∗
k
μDk
1
μDk log
1
μDk
=

k
1
log
1
μDk
=∗
k
1
Sk log
1
μCk
(51)
In the proof of Lemma 3 we showed that if the series 
n zn does not converge,
then the series zn
Sn where Sn = 
k≤n zk does not converge either, so the right
part of the chain of inequalities is ∞.
⊓⊔
Now we can rewrite the chain of inequalities 20 as follows:
dE
μ ≤+ dlim inf M
μ
a.e.
== dlim sup M
μ
≪dM
μ
≪dP
μ ≤+ dE
μ + (1 + ε) log dE
μ
(52)
where the symbol ≪means that the diﬀerence may be greater than log dμ.
Acknowledgements. This research was supported in part by RaCAF ANR-15-CE40-
0016-01. The author thanks Alexander Shen and Mikhail Andreev for their help.
References
1. Bienvenu, L., Gacs, P., Hoyrup, M., Rojas, C., Shen, A.: Algorithmic tests and
randomness with respect to a class of measures. Proc. Steklov Inst. Math. 274,
41–102 (2011)
2. Uspensky, V.A., Vereshchagin, N.K., Shen, A.: Kolmogorov complexity and algo-
rithmic randomness, MCCME (2013) (in Russian)
3. Martin-Lof, P.: The deﬁnition of random sequences. Inf. Control 9, 602–619 (1966)
4. Gacs, P.: Exact expressions for some randomness tests. Z. Math. Log. Grdl. M. 26,
385–394 (1980). Short version: Springer. Lecture Notes in Computer Science, vo.
67, pp. 124–131 (1979)

350
G. Novikov
5. Schnorr, C.P.: Process complexity and eﬀective random tests. J. Comput. Syst. Sci.
7(4), 376–388 (1973). Conference version: STOC 1972, pp. 168–176
6. Levin, L.A.: On the notion of a random sequence. Sov. Math. Dokl. 14(5), 1413–1416
(1973)
7. Williams, D.: Probability with Martingales. Cambridge University Press, Cambridge
(1991)

McShane-Whitney Pairs
Iosif Petrakis(B)
University of Munich, Munich, Germany
petrakis@math.lmu.de
Abstract. We present a constructive version of the classical McShane-
Whitney theorem on the extendability of real-valued Lipschitz functions
deﬁned on a subset of a metric space. Through the introduced notion of a
McShane-Whitney pair we study some abstract properties of this exten-
sion theorem showing how the behavior of a Lipschitz function deﬁned
on the subspace of the pair aﬀect its McShane-Whitney extensions on
the space of the pair. As a consequence, a Lipschitz version of the theory
around the Hahn-Banach theorem is formed. We work within Bishop’s
informal system of constructive mathematics BISH.
1
Introduction
According to the classical extension theorem of McShane and Whitney that ﬁrst
appeared in [12,19], a real-valued Lipschitz function deﬁned on any subset A of
a metric space X is extended to a Lipschitz function deﬁned on X. To determine
metric spaces X and Y such that a similar extension theorem for Y -valued Lip-
schitz functions deﬁned on a subset A of X holds is a non-trivial problem under
active current study (see [1,4,14]). Although the McShane-Whitney theorem
has a highly ineﬀective proof similar to the proof of the Hahn-Banach theorem
(see [17], pp.16–17), it also admits a proof based on an explicit deﬁnition of two
such extension functions. This deﬁnition, which involves the notions of inﬁmum
and supremum of a bounded subset of reals, can be carried out constructively
only if we restrict to certain subsets A of a metric space X.
We deﬁne a McShane-Whitney subset A of a metric space X in order to
constructively realize the McShane-Whitney explicit deﬁnition of the extension
functions. A pair (X, A), where X is a metric space and A is a subset of X on
which the McShane-Whitney explicit deﬁnition is carried out constructively is
called here a McShane-Whitney pair. The importance of the McShane-Whitney
extension lies in the possibility to relate properties of a given Lipschitz function
on A to properties of its extension functions on X in such a way that a Lipschitz-
version of the theory around the Hahn-Banach theorem is formed. We present
here the ﬁrst basic results in this direction. We work within Bishop’s informal
system of constructive mathematics BISH (see [2,3,6]). The constructive recon-
struction of the general theory of Lipschitz functions is quite underdeveloped.
Some ﬁrst results on constructive Lipschitz analysis are found in [8,10,13]. All
proofs that are not included here due to space restrictions are left to the reader.
c
⃝Springer International Publishing AG 2017
J. Kari et al. (Eds.): CiE 2017, LNCS 10307, pp. 351–363, 2017.
DOI: 10.1007/978-3-319-58741-7 33

352
I. Petrakis
2
Basic Notions and Facts
Deﬁnition 1. Let A ⊆R and b, l, λ, m, μ ∈R. If A is bounded above, we deﬁne
b ≥A :↔∀a∈A(b ≥a), [A) := {b ∈R | b ≥A}, l = sup A :↔l ≥A ∧
∀ϵ>0∃a∈A(a > l −ϵ), and λ = lubA :↔λ ≥A ∧∀b∈[A)(b ≥λ). If A is bounded
below, b ≤A, (A], m = inf A, and μ = glbA are deﬁned in a dual way.
In [11], pp. 24–25, Mandelkern gave a necessary and suﬃcient condition for
the existence of lubA and glbA and proved the following remark: If A ⊆R
bounded and glbA exists, then sup(A] exists and sup(A] = glbA, while if lubA
exists, then inf[A) exists and inf[A) = lubA.
Deﬁnition 2. We denote by F(X, Y ) the set of functions of type X →Y and
by F(X) the set of functions of type X →R. If a ∈R, then aX denotes the
constant map in F(X) with value a, and Const(X) is the set of constant maps. If
(X, d), (Y, ρ) are metric spaces, then Cu(X, Y) denotes the uniformly continuous
functions from X to Y , and Cu(X) denotes the uniformly continuous functions
from X to R, where R is equipped with its standard metric. The metric dx0
at the point x0 ∈X is deﬁned by dx0(x) := d(x0, x), for every x ∈X, and
U0(X) := {dx0 | x0 ∈X}. The set X0 of the d-distinct pairs of X is deﬁned by
X0 := {(x, y) ∈X × X | d(x, y) > 0}.
Deﬁnition 3. If A is a subset of a metric space X, x ∈X, and Δ(x, A) :=
{d(x, a) | a ∈A}, A is located if d(x, A) := inf Δ(x, A) exists, for every x ∈X,
and A is colocated, if δ(x, A) := sup Δ(x, A) exists, for every x ∈X.
If A is inhabited and colocated, then A is bounded; if a0 inhabits A, then
d(a, b) ≤d(a, a0) + d(a0, b) ≤2δ(a0, A), for every a, b ∈A. Unless otherwise
stated, for the rest X and Y are equipped with metrics d and ρ, respectively.
Deﬁnition 4. The set of Lipschitz functions Lip(X, Y ) from X to Y is
Lip(X, Y ) :=

σ≥0
Lip(X, Y, σ),
Lip(X, Y, σ) := {f ∈F(X, Y ) | ∀x,y∈X(ρ(f(x), f(y)) ≤σd(x, y))}.
If Y = R, we use the notations Lip(X) and Lip(X, σ), respectively.
Clearly, Lip(X, Y ) ⊆Cu(X, Y). If A ⊆X and f ∈Lip(X, σ), for some σ ≥0,
then f|A ∈Lip(A, σ). An element of Lip(X, Y ) sends a bounded subset of X to
a bounded subset of Y , which is not generally the case for elements of Cu(X, Y);
the identity function id : N →R, where N is equipped with the discrete metric,
is in Cu(N)\Lip(N) and id(N) = N is unbounded in R. In [13], p. 370, it is shown
constructively that if X is totally bounded, then Lip(X) is uniformly dense in
Cu(X).
Proposition 1. The set Lip(X) includes the sets U0(X), Const(X), and it is
closed under addition and multiplication by reals. If every element of Cu(X) is
a bounded function, then Lip(X) is closed under multiplication.

McShane-Whitney Pairs
353
Deﬁnition 5. If f ∈F(X, Y ), we deﬁne the following sets:
Λ(f) := {σ ≥0 | ∀x,y∈X(ρ(f(x), f(y)) ≤σd(x, y))},
Ξ(f) := {σ ≥0 | ∀x,y∈X(ρ(f(x), f(y)) ≥σd(x, y))},
M0(f) := {σx,y(f) | (x, y) ∈X0},
σx,y(f) := ρ(f(x), f(y))
d(x, y)
.
Proposition 2. If f ∈F(X, Y ), then Λ(f) = [M0(f)) and Ξ(f) = (M0(f)].
Classically one can prove that if f ∈Lip(X, Y ) such that inf Λ(f) exists,
then sup M0(f) exists and sup M0(f) = inf Λ(f). The classical argument in that
proof is avoided, if sup M0(f) exists.
Proposition 3. Let f ∈Lip(X, Y ).
(i) If sup M0(f) exists, then inf Λ(f) exists and inf Λ(f) = min Λ(f) =
sup M0(f).
(ii) If inf Λ(f) exists, then lubM0(f) exists and lubM0(f) = inf Λ(f).
(iii) If lubM0(f) exists, then inf Λ(f) exists and inf Λ(f) = lubM0(f).
In constructive analysis one usually works with the stronger notions of inﬁma
or suprema of sets and not with greatest lower bounds or least upper bounds
of sets. An important exception is found in the work of Mandelkern (see his
comment in [11], p. 24). Here we also ﬁnd useful to keep both notions at work.
Deﬁnition 6. Let f ∈Lip(X, Y ). We call f L-pseudo-normable, if sup M0(f)
exists, and we write L(f) := sup M0(f). We call f weakly L-pseudo-normable,
or L∗-pseudo-normable, if lubM0(f) = inf Λ(f) exists, and L∗(f) := lubM0(f).
In general a Lipschitz function need not be L-pseudo-normable. Note that in
the case of a linear function f between normed spaces X and Y the boundedness
condition is equivalent to the Lipschitz condition and the existence of its norm
||f|| is equivalent to the existence of L(f). If f is L-pseudo-normable, and since
L(f) ≥M0(f), by Proposition 2 we get ∀x,y∈X(ρ(f(x), f(y)) ≤L(f)d(x, y)), or
f ∈Lip(X, Y, L(f)). If f is L∗-pseudo-normable, we work similarly.
Proposition 4. Let A ⊆X and f ∈Lip(A, Y ) such that
∃g∈F(X,Y )(g|A = f ∧∀σ≥0(f ∈Lip(A, Y, σ) →g ∈Lip(X, Y, σ))).
(i) If f is L-pseudo-normable, g is L-pseudo-normable and L(g) = L(f).
(ii) If f is L∗-pseudo-normable, g is L∗-pseudo-normable and L∗(g) = L∗(f).
Note that if f
∈Lip(A, Y ), g ∈Lip(X, Y ) such that L(f), L(g) exist
and L(f) = L(g), then it is immediate that ∀σ≥0(f ∈Lip(A, Y, σ) →g ∈
Lip(X, Y, σ)). Next follows the Lipschitz-version of the extendability of a uni-
formly continuous function deﬁned on a dense subset of a metric space with
values in a complete metric space.

354
I. Petrakis
Proposition 5. Let D ⊆X be dense in X, Y complete, and f ∈Lip(D, Y ).
(i) ∃!g∈F(X,Y )(g|A = f ∧∀σ≥0(f ∈Lip(D, Y, σ) →g ∈Lip(X, Y, σ))).
(ii) If f is L-pseudo-normable, then g is L-pseudo-normable and L(g) = L(f).
(iii) If f is L∗-pseudo-normable, g is L∗-pseudo-normable and L∗(g) = L∗(f).
Corollary 1. Let D ⊆X be dense in X, let Y be complete, and g ∈Lip(X, Y ).
If g is L∗-pseudo-normable, f = g|D is L∗-pseudo-normable and L∗(f) = L∗(g).
3
McShane-Whitney Subsets and Pairs
We formulate a property on the subsets of a metric space so that the McShane-
Whitney extension can be carried out on them constructively.
Deﬁnition 7. If A ⊆X is inhabited, x ∈X, λ ∈R, and g ∈Lip(A), the set
MWg(A, λ, x) is deﬁned by
MWg(A, λ, x) := {g(a) + λd(x, a) | a ∈A}.
The set A is called a McShane-Whitney subset of X, if for every σ > 0, g ∈
Lip(A) and x ∈X the inf MWg(A, σ, x) exists.
A McShane-Whitney subset A of X is located, colocated and bounded. Since
{d(x, a) | a ∈A} = MW0X(A, 1, x), A is located. Since MW−2dx(A, 1, x) =
{−2d(x, a) + d(x, a) | a ∈A} = {−d(x, a) | a ∈A} = −Δ(x, A), we get1
δ(x, A) = sup[−(−Δ(x, A))] = −inf(−Δ(x, A)) = −inf MW−2dx(A, 1, x) i.e., A
is colocated, and since A is inhabited, A is also bounded.
Proposition 6. A is a McShane-Whitney subset of X if and only if for every
σ > 0, g ∈Lip(A) and x ∈X the sup MWg(A, −σ, x) exists.
Proof. If σ > 0, g ∈Lip(A) and x ∈X, then MWg(A, −σ, x) = {g(a)−σd(x, a) |
a ∈A} = {−(−g(a) + σd(x, a)) | a ∈A} = −{(−g)(a) + σd(x, a) | a ∈
A} = −MW−g(A, σ, x). Since −g ∈Lip(A), we get sup MWg(A, −σ, x) =
sup(−MW−g(A, σ, x)) = −inf MW−g(A, σ, x). For the converse implication we
use the equality inf(−B) = −sup B, where B ⊆R such that sup B exists,
and the similarly shown equality MWg(A, σ, x) = −MW−g(A, −σ, x). Hence
inf MWg(A, σ, x) = inf(−MW−g(A, −σ, x)) = −sup MW−g(A, −σ, x).
1 If B ⊆R is bounded and inf B exists, then sup(−B) exists and sup(−B) = −inf B;
if m = inf B, then by deﬁnition m is a lower bound of B and ∀ϵ>0∃b∈B(b < m + ϵ),
therefore −m is an upper bound of −B and ∀ϵ>0∃−b∈−B(−b > −m−ϵ). The following
constructively provable properties are used in this paper: if A, B ⊆R are inhabited
and bounded such that sup A, inf A, sup B, inf B exist, then sup(A + B) exists and
sup(A + B) = sup A + sup B, inf(A + B) exists and inf(A + B) = inf A + inf B,
if λ > 0, then sup(λA), inf(λA) exist and sup(λA) = λ sup A, inf(λA) = λ inf A, if
λ < 0, then sup(λA), inf(λA) exist and sup(λA) = λ inf A, and inf(λA) = λ sup A.

McShane-Whitney Pairs
355
The next proposition provides examples of McShane-Whitney subsets. A
locally compact (totally bounded) metric space X is one every bounded sub-
set of which is included in a compact (totally bounded) subset of X (see [5],
p. 46).
Proposition 7. Let A ⊆X be inhabited.
(i) If A is totally bounded, then A is a McShane-Whitney subset of X.
(ii) If X is totally bounded and A is located, then A is a McShane-Whitney
subset of X.
(iii) If X is locally compact (totally bounded), then A is a McShane-Whitney
subset of X if and only if A is bounded and located.
(iv) If X = Rn, then A is a McShane-Whitney subset of Rn if and only if A is
totally bounded.
Proof
(i) If σ > 0, g ∈Lip(A) and x ∈X, then g + σdx ∈Lip(A) ⊆Cu(A), and
inf MWg(σ, x) exists, since A is totally bounded (see [3], Corollary 4.3,
p. 94).
(ii) A located subset of X is also totally bounded (see [3], p. 95), and we
use (i).
(iii) If A is bounded and located, there is compact (totally bounded) K ⊆X
such that A ⊆K. Since A is located in X, it is a located in K, hence A
is totally bounded, and we use (i). For the converse see our remark after
Deﬁnition 7.
(iv) A is totally bounded if and only if it is located and bounded (see [3], p. 95),
and Rn is locally compact as a ﬁnite product of R (see [3], p. 111). The
required equivalence follows from (iii).
Deﬁnition 8. Let A ⊆X. We call (X, A) a McShane-Whitney pair, if for all
σ > 0 and g ∈Lip(A, σ) the functions g∗, ∗g : X →R, the smallest and largest
McShane-Whitney extension of g, deﬁned by
g∗(x) = inf Mg(A, σ, x), ∗g(x) = sup Mg(A, −σ, x),
for every x ∈X, are well-deﬁned and satisfy the following properties:
(i) g∗, ∗g ∈Lip(X, σ).
(ii) g∗
|A = (∗g)|A = g.
(iii) ∀f∈Lip(A,σ)(f|A = g →g∗≤f ≤∗g).
The extensions g∗, ∗g of g are unique. Let h∗, ∗h satisfy conditions (i)-(iii) of
Deﬁnition 8. Since h∗|A = (∗h)|A = g, g∗≤h∗≤∗g and g∗≤∗h ≤∗g. Since
g∗
|A = (∗g)|A = g, h∗≤g∗≤∗h and h∗≤∗g ≤∗h, hence h∗= g∗and ∗h = ∗g.
Theorem 1 (McShane-Whitney). If A is a McShane-Whitney subset of X,
then (X, A) is a McShane-Whitney pair.

356
I. Petrakis
Proof. By Proposition 6, the functions ∗g, g∗are well-deﬁned. First we show
that ∗g extends g. If a0 ∈A, then ∗g(a0) = inf{g(a) + σd(a0, a) | a ∈A} ≤
g(a0)+σd(a0, a0) = g(a0). If a ∈A, then g(a0)−g(a) ≤|g(a0)−g(a)| ≤σd(a0, a),
hence g(a) + σd(a0, a) ≥g(a0). Since a is arbitrary, ∗g(a0) ≥g(a0). To show
∗g ∈Lip(X, σ) let x1, x2 ∈X and a ∈A. Then d(x1, a) ≤d(x2, a) + d(x2, x1)
and σd(x1, a) ≤σd(x2, a) + σd(x1, x2), therefore
g(a) + σd(x1, a) ≤(g(a) + σd(x2, a)) + σd(x1, x2) →
∗g(x1) ≤(g(a) + σd(x2, a)) + σd(x1, x2) →
∗g(x1) −σd(x1, x2) ≤g(a) + σd(x2, a) →
∗g(x1) −σd(x1, x2) ≤∗g(x2) →
∗g(x1) −∗g(x2) ≤σd(x1, x2).
If we start from the inequality d(x2, a) ≤d(x1, a)+d(x2, x1) and work as above,
we get ∗g(x2) −∗g(x1) ≤σd(x1, x2), therefore |∗g(x1) −∗g(x2)| ≤σd(x1, x2).
Working similarly we get that g∗is an extension of g which is in Lip(X, σ). If
f ∈Lip(X, σ) such that f|A = g, x ∈X and a ∈A we have that
f(x) −g(a) = f(x) −f(a) ≤|f(x) −f(a)| ≤σd(x, a) →
f(x) ≤g(a) + σd(a, x) →
f(x) ≤∗g(x),
g(a) −f(x) = f(a) −f(x) ≤|f(a) −f(x)| ≤σd(x, a) →
g(a) −σd(a, x) ≤f(x) →
g∗(x) ≤f(x).
Proposition 8. Let (X, A) be a McShane-Whitney pair and g ∈Lip(A, σ).
(i) The set A is located.
(ii) If inf g and sup g exist, then inf ∗g, sup g∗exist and
inf
x∈X
∗g = inf
a∈A g,
sup
x∈X
g∗= sup
a∈A
g.
Proof
(i) Let r ∈R and σ > 0. Since rA ∈Lip(A, σ), by hypothesis ∗rA is well-
deﬁned, where ∗rA(x) = inf{r + σd(x, a) | a ∈A}, for every x ∈X. If
x ∈X and a ∈A, then d(x, a) =
1
σ(r + σd(x, a) −r), and Δ(x, A) =
{ 1
σ(r + σd(x, a) −r) | a ∈A}. Hence d(x, A) = inf{ 1
σ(r + σd(x, a) −r) | a ∈
A} = 1
σ(inf{r + σd(x, a) | a ∈A} −r) = 1
σ(∗rA(x) −r).
(ii) We show that m := inf{g(a) | a ∈A} satisﬁes the properties of inf{∗g(x) |
x ∈X}. It suﬃces to show that m ≤∗g(X), since the other deﬁnitional
condition of inf follows immediately; if ϵ > 0, then there exists a ∈A ⊆X
such that g(a) = ∗g(a) < m + ϵ. If x ∈A, then m ≤g(x) = ∗g(x), since
m = inf g. Since A is located, the set −A := {x ∈X | d(x, A) > 0} is
well-deﬁned. If x ∈−A, then d(x, a) ≥d(x, A) > 0, for every a ∈A. Hence
g(a) + σd(x, a) > g(a) ≥inf
a∈A g →inf
a∈A(g(a) + σd(x, a)) ≥inf
a∈A g ↔∗g(x) ≥m.

McShane-Whitney Pairs
357
Since A is located, the set A ∪(−A) is dense in X (see [3], p.88). If x ∈X, there
is some sequence (dn)n∈N ⊆A∪(−A) such that dn
n→x. By the continuity of ∗g
we have that ∗g(dn)
n→∗g(x). Suppose that ∗g(x) < m. Since ∗g(dn) ≥m, for
every n ∈N, if ϵ := (m−∗g(x)) > 0, there is some n0 such that for every n ≥n0
we have that |∗g(dn) −∗g(x)| = ∗g(dn) −∗g(x) < m −∗g(x) ↔∗g(dn) < m,
which is a contradiction. Hence ∗g(x) ≥m. For the existence of sup g∗and the
equality supx∈X g∗= supa∈A g we work similarly.
If g = rA and σ > 0, then r∗
A = rA−σdA and ∗rA = rA+σdA. If g ∈Lip(A, 0),
it is immediate that g = rA, for some r ∈R, and ∗g = g∗= rX. If D is dense
in X and (X, D) is a McShane-Whitney pair, then by Proposition 5 there is a
unique σ-Lipschitz extension on X of some g ∈Lip(D), hence ∗g = g∗, a fact
which is also shown by the deﬁnition of ∗g and g∗. A weaker property on A
that suﬃces for the McShane-Whitney extension is that for every σ > 0, g ∈
Lip(A, σ) and x ∈X the inf MWg(A, σ, x) exists, but since all our examples of
McShane-Whitney subsets satisfy the stronger property of Deﬁnition 7, we avoid
it. The next proposition expresses a “step-invariance” of the McShane-Whitney
extension. If A ⊆B ⊆X such that (X, A), (X, B), (B, A) are McShane-Whitney
pairs and g ∈Lip(A), then g∗X is the (A−X) extension of g, g∗B∗X is the (B−X)
extension of the (A −B) extension g∗B of g, and similarly for ∗Xg and ∗X∗Bg.
Proposition 9. If A ⊆B ⊆X such that (X, A), (X, B), (B, A) are McShane-
Whitney pairs and g ∈Lip(A, σ), for some σ > 0, then
g∗X = g∗B∗X,
∗Xg = ∗X∗Bg.
Proof. We show only the ﬁrst equality and for the second we work similarly. By
deﬁnition g∗B : B →R ∈Lip(B, σ) and g∗B(b) = sup{g(a) −σd(b, a) | a ∈A},
for every b ∈B. Moreover, g∗B∗X : X →R ∈Lip(X, σ) and g∗B∗X(x) =
sup{g∗B(b)−σd(x, b) | b ∈B}, for every x ∈X. For the (A−X) extension of g we
have that g∗X : X →R ∈Lip(X, σ) and g∗X(x) = sup{g(a) −σd(x, a) | a ∈A},
for every x ∈X. Since (g∗B∗X)|B = g∗B, we have that (g∗B∗X)|A = (g∗B)|A = g.
Therefore g∗X ≤g∗B∗X ≤∗Xg, and (g∗X)|B ≤(g∗B∗X)|B = g∗B ≤(∗Xg)|B.
Since (g∗X)|A = g, we get that ((g∗X)|B)|A = g, therefore g∗B ≤((g∗X)|B) ≤
∗Bg. Since (g∗X)|B ≤g∗B and g∗B ≤(g∗X)|B, we get (g∗X)|B = g∗B. Hence
g∗B∗X ≤g∗X ≤∗X∗Bg i.e., we have shown both g∗X ≤g∗B∗X and g∗B∗X ≤g∗X.
Proposition 10. Let (X, A) be a McShane-Whitney pair and g ∈Lip(A) such
that L(g) exists.
(i) g ∈Lip(A, L(g)).
(ii) If f is an L(g)-Lipschitz extension of g, then L(f) exists and L(f) = L(g).
(iii) L(∗g), L(g∗) exist and L(∗g) = L(g) = L(g∗).
Proof
(i) Since L(g) = sup M0(g), we have that L(g) ≥M0(g) and by Proposition 2
we get L(g) ∈Λ(g), therefore g ∈Lip(A, L(g)).

358
I. Petrakis
(ii) Since f ∈Lip(X, L(g)), we get L(g) ∈Λ(f) and L(g) ≥M0(f). Let ϵ > 0.
Since L(g) = sup M0(g), there exists (a, b) ∈A0 ⊆X0 such that σa,b(g) >
L(g) −ϵ. Since f extends g, σa,b(g) = σa,b(f).
(iii) By deﬁnition ∗g, g∗∈Lip(X, L(g)) and they extend g. Hence we use (ii).
Deﬁnition 9. Let (X, ||.||) be a normed space. A subset C of X is called convex,
if ∀x,y∈C∀λ∈(0,1)(λx + (1 −λ)y ∈C). If C ⊆X is convex, a function g : C →R
is called convex, if ∀x,y∈C∀λ∈(0,1)(g(λx + (1 −λ)y) ≤λg(x) + (1 −λ)g(y)), and
g is called concave, if ∀x,y∈C∀λ∈(0,1)(g(λx + (1 −λ)y) ≥λg(x) + (1 −λ)g(y)).
A function f : X →R is called sublinear if it is subadditive and positive homo-
geneous i.e., if f(x + y) ≤f(x) + f(y), and f(λx) = λf(x), for every x, y ∈X
and λ > 0, respectively. Similarly, f is called superlinear, if it is superadditive
i.e., if f(x + y) ≥f(x) + f(y), for every x, y ∈X, and positive homogeneous.
Proposition 11. Let (X, ||.||) be a normed space, C ⊆X convex and inhabited,
(X, C) a McShane-Whitney pair, and g ∈Lip(C, σ), for some σ > 0.
(i) If g is convex, then ∗g is convex.
(ii) If g is concave, then g∗is concave.
Proof. We show only (i), and for (ii) we work similarly. Let x, y ∈X, and
λ ∈(0, 1). If we consider the sets Cx = {λ(g(c) + σ||x −c||) | c ∈C} and
Cy = {(1 −λ)(g(c) + σ||y −c||) | c ∈C}, an element of Cx + Cy has the form
λ(g(c) + σ||x −c||) + (1 −λ)(g(d) + σ||y −d||), for some c, d ∈C. We show that
∗g(λx+(1−λ)y) ≤λ(g(c)+σ||x−c||)+(1−λ)(g(d)+σ||y−d||), where c, d ∈C.
Since C is convex, c′ := λc + (1 −λ)d ∈C, and by the convexity of g we get
∗g(λx + (1 −λ)y) ≤g(c′) + σ||λx + (1 −λ)y −c′||
≤λg(c) + (1 −λ)g(d) + λσ||x −c|| + (1 −λ)σ||y −d||
= λ(g(c) + σ||x −c||) + (1 −λ)(g(d) + σ||y −d||).
Since the element of Cx + Cy considered is arbitrary, we get that ∗g(λx + (1 −
λ)y) ≤inf(Cx + Cy) = inf Cx + inf Cy = λ∗g(x) + (1 −λ)∗g(y).
Proposition 12. Let (X, A) be McShane-Whitney pair, g1 ∈Lip(A, σ1), g2 ∈
Lip(A, σ2) and g ∈Lip(A, σ), for some σ1, σ2, σ > 0.
(i) (g1 + g2)∗≤g∗
1 + g∗
2 and ∗(g1 + g2) ≥∗g1 + ∗g2.
(ii) If λ > 0, then (λg)∗= λg∗and ∗(λg) = λ∗g.
(iii) If λ < 0, then (λg)∗= λ∗g and ∗(λg) = λg∗.
Proof. In each case we show only one of the two facts.
(i) We have that g1 + g2 ∈Lip(A, σ1 + σ2) and
(g1 + g2)∗(x) = sup{g1(a) + g2(a) −(σ1 + σ2)d(x, a) | a ∈A}
= sup{(g1(a) −σ1d(x, a)) + (g2(a) −σ2d(x, a)) | a ∈A}
≤sup{g1(a) −σ1d(x, a) | a ∈A} + sup{g2(a) −σ2d(x, a) | a ∈A}
= g∗
1(x) + g∗
2(x).

McShane-Whitney Pairs
359
(ii) If λ ∈R, then λg ∈Lip(A, |λ|σ) and if λ > 0, then
(λg)∗(x) = sup{λg(a) −|λ|σd(x, a) | a ∈A}
= λ sup{g(a) −σd(x, a) | a ∈A}
= λg∗(x).
(iii) If λ < 0, then
(λg)∗(x) = sup{λg(a) −|λ|σd(x, a) | a ∈A}
= sup{λg(a) −(−λ)σd(x, a) | a ∈A}
= sup{λ(g(a) + σd(x, a)) | a ∈A}
= λ inf{g(a) + σd(x, a) | a ∈A}
= λ∗g(x).
Proposition 13. Let (X, ||.||) be a normed space, A a non-trivial subspace of
X such that (X, A) is a McShane-Whitney pair, and let g ∈Lip(A, σ), for some
σ > 0, be linear. Moreover, let x1, x2, x ∈X and λ ∈R.
(i) g∗(x1 + x2) ≥g∗(x1) + g∗(x2) and ∗g(x1 + x2) ≤∗g(x1) + ∗g(x2).
(ii) If λ > 0, then g∗(λx) = λg∗(x) and ∗g(λx) = λ∗g(x).
(iii) If λ < 0, then g∗(λx) = λ∗g(x) and ∗g(λx) = λg∗(x).
Proof. In each case we show only one of the two facts.
(i) If a1, a2 ∈A, then
∗g(x1 + x2) = inf{g(a) + σ||(x1 + x2) −a|| | a ∈A}
≤g(a1 + a2) + σ||x1 + x2 −(a1 + a2)||
≤g(a1) + σ||x1 −a1|| + g(a2) + σ||x2 −a2||,
therefore
∗g(x1 + x2) ≤inf{g(a1) + σ||x1 −a1|| + g(a2) + σ||x2 −a2|| | a1, a2 ∈A}
= inf{g(a1) + σ||x1 −a1|| | a1 ∈A} + inf{g(a2) + σ||x2 −a2|| | a2 ∈A}
= ∗g(x1) + ∗g(x2).
(ii) First we show that ∗g(λx) ≤λ∗g(x). If a ∈A, then
∗g(λx) = inf{g(a) + σ||λx −a|| | a ∈A}
≤g(λa) + σ||λx −λa||
= λg(a) + |λ|σ||x −a||
= λ(g(a) + σ||x −a||),
therefore
∗g(λx) ≤inf{λ(g(a) + σ||x −a||) | a ∈A}
= λ inf{g(a) + σ||x −a|| | a ∈A}
= λ∗g(x).

360
I. Petrakis
For the inclusion ∗g(λx) ≥λ∗g(x) we work as follows.
λ∗g(x) = λ inf{g(a) + σ||x −a|| | a ∈A}
≤λ(g( 1
λa) + σ||x −1
λa||)
= g(a) + σ|λ|||x −1
λa||
= g(a) + σ||λ(x −1
λa)||
= g(a) + σ||λx −a||,
therefore
λ∗g(x) ≤inf{g(a) + σ||λx −a|| | a ∈A} = ∗g(λx).
(iii) First we show that ∗g(λx) ≤λg∗(x). If a ∈A, then
∗g(λx) = inf{g(a) + σ||λx −a|| | a ∈A}
≤g(λa) + σ||λx −λa||
= λg(a) + |λ|σ||x −a||
= λ(g(a) −σ||x −a||),
therefore
∗g(λx) ≤inf{λ(g(a) −σ||x −a||) | a ∈A}
= λ sup{g(a) −σ||x −a|| | a ∈A}
= λg∗(x).
For the inclusion ∗g(λx) ≥λg∗(x) we work as follows. Since
g∗(x) = sup{g(a) −σ||x −a|| | a ∈A}
≥g( 1
λa) −σ||x −1
λa||
and λ < 0, we get
λg∗(x) ≤λ(g( 1
λa) −σ||x −1
λa||)
= g(a) −λσ||x −1
λa||
= g(a) + σ|λ|||x −1
λa||
= g(a) + σ||λ(x −1
λa)||
= g(a) + σ||λx −a||,
therefore
λg∗(x) ≤inf{g(a) + σ||λx −a|| | a ∈A} = ∗g(λx).

McShane-Whitney Pairs
361
Proposition 13 says that ∗g is sublinear and g∗is superlinear. If X is a normed
space and x0 ∈X, then it is not generally the case that Rx0 := {λx0 | λ ∈R} is
a located subset of X. If X = R, this is equivalent to LPO, the limited principle
of omniscience2 (see [3], p. 122). Things change, if ||x0|| > 0. In this case Rx0
is a 1-dimensional subspace of X i.e., a closed and located linear subset of X
of dimension one (see [3], p. 307). Of course, Rx0 is a convex subset of X. A
standard corollary of the classical Hahn-Banach theorem is that if x0 ̸= 0, there
is a bounded linear functional u on X such that ||u|| = 1 and u(x0) = ||x0||. Its
proof is based on the extension of the obvious linear map on Rx0 to X through
the Hahn-Banach theorem. Next follows a ﬁrst approach to the translation of
this corollary in Lipschitz analysis. First we need a simple lemma.
Lemma 1. If (X, ||.||) is a normed space and x0 ∈X such that ||x0|| > 0, then
Ix0 := {λx0 | λ ∈[−1, 1]} is a compact subset of X.
Proposition 14. If (X, ||.||) is a normed space and x0 ∈X such that ||x0|| > 0,
there exists f ∈Lip(X) such that f(x0) = ||x0|| and L(f) = 1.
Proof. The function g : Ix0 →R, deﬁned by g(λx0) = λ||x0||, for every λ ∈
[−1, 1], is in Lip(Ix0) and L(g) = 1; if λ, μ ∈[−1, 1], then |g(λx0) −g(μx0)| =
|λ||x0|| −μ||x0||| = |λ −μ|||x0|| = ||(λ −μ)x0|| = ||λx0 −μx0||, and since
M0(g) = {σλx0,μx0(g) = |g(λx0) −g(μx0)|
||λx0 −μx0||
= 1 | (λ, μ) ∈[−1, 1]0},
we get that L(g) = sup M0(g) = 1. Since Ix0 is inhabited and totally bounded,
since by Lemma 1 it is compact, by Proposition 7(i) and Theorem 1 the extension
∗g of g is in Lip(X), while by Proposition 10 we have that L(∗g) = L(g) = 1.
Theorem 2. Let (X, ||.||) be a normed space and x0 ∈X such that ||x0|| > 0. If
(X, Rx0) is a McShane-Whitney pair, there exist a sublinear Lipschitz function f
on X such that f(x0) = ||x0|| and L(f) = 1, and a superlinear Lipschitz function
h on X such that h(x0) = ||x0|| and L(h) = 1.
Proof. As in the proof of Proposition 14 the function g : Rx0 →R, deﬁned by
g(λx0) = λ||x0||, for every λ ∈R, is in Lip(Rx0) and L(g) = 1. Since (X, Rx0)
is a McShane-Whitney pair, the extension ∗g of g is a Lipschitz function, and
by Proposition 10 L(∗g) = L(g) = 1. Since g is linear, by Proposition 13 we get
that ∗g is sublinear. Similarly, the extension g∗of g is a Lipschitz function, and
by Proposition 10 L(g∗) = L(g) = 1. Since g is linear, by Proposition 13 we get
that g∗is superlinear.
2 From this we can explain why it is not constructively acceptable that any pair (X, A)
is McShane-Whitney. If x0 ∈R and (R, Rx0) is a McShane-Whitney pair, then by
Proposition 8(i) we have that Rx0 is located, which implies LPO.

362
I. Petrakis
4
Concluding Remarks
Similarly to Theorem 1, one can prove an extension theorem for H¨older contin-
uous functions, or for functions which are continuous with respect to a given
modulus of continuity λ i.e., a function of type [0, +∞) →[0, +∞), which is
subadditive, strictly increasing, uniformly continuous on every bounded sub-
set of [0, +∞), and λ(0) = 0 (see also [3], p. 102). Note that one could have
deﬁned a McShane-Whitney pair such that the functions g∗and ∗g are given
by g∗(x) = glbMg(A, σ, x) and ∗g(x) = lubMg(A, −σ, x), for every x ∈X,
respectively, since only the properties of glb and lub are used in the proof of
Theorem 1.
Some open problems related to the material presented here are the following:
a. To ﬁnd necessary and suﬃcient conditions on X, Y and f ∈Lip(X, Y ) for
the L-pseudo-normability of f.
b. To ﬁnd conditions on (X, ||.||) under which one can show constructively that
(X, Rx0) is a McShane-Whitney pair, if ||x0|| > 0. A similar attitude is taken
by Ishihara in his constructive proof of the Hahn-Banach theorem, where the
property of Gˆateaux diﬀerentiability of the norm is added (see [5,7], p.126).
c. To elaborate the Lipschitz version of the theory of the Hahn-Banach theorem.
d. If (Rn, A) is a McShane-Whitney pair and g ∈Lip(A, Rm, σ), then by
Theorem 1 there are extensions g∗and
∗g of g in Lip(Rn, Rm, √mσ).
According to the classical Kirszbraun theorem there is an extension of g in
Lip(Rn, Rm, σ) (see [9,15,16,18]). The constructive study of the Kirszbraun
theorem is a non-trivial enterprise.
References
1. Benyamini, Y., Lindenstrauss, J.: Geometric nonlinear functional analysis, vol. 1,
American Mathematical Society Colloquium Publications, 48. American Mathe-
matical Society, Providence, RI (2000)
2. Bishop, E.: Foundations of Constructive Analysis. McGraw-Hill, New York (1967)
3. Bishop, E., Bridges, D.: Constructive Analysis, Grundlehren der mathematischen
Wissenschaften. 279. Springer, Heidelberg (1985)
4. Brudnyi, A., Brudnyi, Y.: Methods of geometric analysis in extension and trace
problems, Volume 1. Monographs in Mathematics, vol. 102. Birkh¨auser/Springer,
Basel (2012)
5. Bridges, D.S., Vˆıt¸˘a, L.S.: Techniques of Constructive Analysis. Universitext.
Springer, New York (2006)
6. Bridges, D.S., Richman, F.: Varieties of Constructive Mathematics. Cambridge
University Press, Cambridge (1987)
7. Ishihara, H.: On the constructive Hahn-Banach theorem. Bull. London. Math. Soc.
21, 79–81 (1989)
8. Julian, W., Philips, K.: Constructive bounded sequences and lipschitz functions.
J. London Math. Soc. s2–31(3), 385–392 (1985)
9. Kirszbraun, M.D.: ¨Uber die zusammenziehende und Lipschitzsche Transformatio-
nen. Fundam. Math. 22, 77–108 (1934)

McShane-Whitney Pairs
363
10. Loeb, I.: Lipschitz functions in constructive reverse mathematics. Logic J. IGPL
21(1), 28–43 (2013). (special issue on Non-Classical Mathematics)
11. Mandelkern, M.: Constructive continuity, Mem. Amer. Math. Soc. 277 (1983)
12. McShane, E.J.: Extension of range of functions. Bull. Amer. Math. Soc. 40(12),
837–842 (1934)
13. Petrakis, Iosif: A direct constructive proof of a stone-weierstrass theorem for
metric spaces. In: Beckmann, Arnold, Bienvenu, Laurent, Jonoska, Nataˇsa (eds.)
CiE 2016. LNCS, vol. 9709, pp. 364–374. Springer, Cham (2016). doi:10.1007/
978-3-319-40189-8 37
14. Tuominen, H.: Analysis in Metric Spaces, Lecture notes (2014)
15. Valentine, F.A.: On the extension of a vector function so as to preserve a Lipschitz
condition. Bull. Amer. Math. Soc. 49(2), 100–108 (1943)
16. Valentine, F.A.: A Lipschitz condition preserving extension for a vector function.
Amer. J. Math. 67, 83–93 (1945)
17. Weaver, N.: Lipschitz Algebras. World Scientiﬁc, Singapore (1999)
18. Wells, J.H., Williams, L.R.: Embeddings and Extensions in Analysis. Springer,
Heidelberg (1975)
19. Whitney, H.: Analytic extensions of diﬀerentiable functions deﬁned in closed sets.
Trans. Amer. Math. Soc. 36(1), 63–89 (1934)

Total Nondeterministic Turing Machines
and a p-optimal Proof System for SAT
Zenon Sadowski(B)
Institute of Informatics, University of Bialystok,
ul. Ciolkowskiego 1 M, 15-245 Bialystok, Poland
sadowski@math.uwb.edu.pl
Abstract. We show that the open problem of the existence of a p-
optimal proof system for SAT can be characterized in terms of total non-
deterministic Turing machines. We prove that there exists a p-optimal
proof system for SAT if and only if there exists a proof system h for
SAT such that for any total nondeterministic Turing machine working
in polynomial time its totality is provable with short proofs in h and
these proofs can be eﬃciently constructed. We prove that the standard
proof system for SAT (a satisfying truth assignment is a proof of a sat-
isﬁable propositional formula) is p-optimal if and only if for any total
nondeterministic Turing machine working in polynomial time its totality
is provable with short proofs in the standard proof system for SAT and
these proofs can be eﬃciently constructed.
Additionally we show that the problem of the existence of an optimal
proof system for TAUT can be characterized in terms of pairs of nonde-
terministic Turing machines which are disjoint (do not accept the same
strings). We prove that there exists an optimal proof system for TAUT
if and only if there exists a proof system f for TAUT such that for any
pair of disjoint nondeterministic Turing machines working in polynomial
time their disjointness is provable in f with short proofs.
Keywords: p-optimal proof system for SAT · An optimal propositional
proof system · Total Turing machines · Disjoint NP-pairs
1
Introduction
Stephen Cook and Robert Reckhow were the ﬁrst to precisely answer the ques-
tion of what exactly is a propositional proof system. They introduced the notion
of an abstract propositional proof system (see [7]) as a function f mapping
in polynomial time the set of all strings over a certain ﬁxed ﬁnite alphabet
(“proofs”) onto TAUT (the set of all propositional tautologies). All proposi-
tional proof systems from logic textbooks fall under the concept of an abstract
propositional proof system (a proof system for TAUT)
There are two tools for comparing the eﬃciency of proof systems for TAUT:
the notion of p-simulation and its nondeterministic counterpart the notion of
c
⃝Springer International Publishing AG 2017
J. Kari et al. (Eds.): CiE 2017, LNCS 10307, pp. 364–374, 2017.
DOI: 10.1007/978-3-319-58741-7 34

Total Nondeterministic Turing Machines and a p-optimal Proof System
365
simulation. A proof system for TAUT is optimal (p-optimal) if and only if it
simulates (p-simulates) any other proof system for TAUT.
The notion of an abstract proof system can be considered not only for TAUT,
but also for any language L, in particular for SAT (the set of all satisﬁable
boolean formulas). To compare diﬀerent proof systems for SAT we can use the
notion of p-simulation introduced by Stephen Cook and Robert Reckhow (see
[7]). Intuitively a proof system h for SAT p-simulates a second proof system g
for SAT if there is a polynomial-time computable function t translating proofs
in g into proofs in h. A proof system for SAT is p-optimal if and only if it p-
simulates any other proof system for SAT. There are two main open problems
concerning proof systems for SAT: the problem of the existence of a p-optimal
proof system for SAT posed by Johannes K¨obler and Jochen Messner (see [4,9,
10]) and the problem of whether the standard proof system for SAT (a satisfying
truth assignment is a proof of a formula α) is p-optimal, posed by Pavel Pudl´ak
(see [4,13]).
Both these problems were intensively studied and it seems impossible that
we can prove or disprove them with the currently available means. In such a
situation new characterizations of these problems can make some progress in
understanding them.
A disjoint NP-pair is a pair of nonempty disjoint sets both belonging to
the complexity class NP (see [14]). Olaf Beyersdorﬀproposed to express the
disjointness of any disjoint NP-pair on a propositional level, as a sequence of
propositional tautologies (see [2]). Any such a sequence he called a propositional
representation of this disjoint NP-pair. Any disjoint NP-pair has many proposi-
tional representations. In this setting Olaf Beyersdorﬀformulated an unexpected
characterization of the problem of the existence of an optimal proof system for
TAUT. He proved that the existence of an optimal proof system for TAUT is
equivalent to the existence of a proof system for TAUT which proves with short
proofs the disjointness of any disjoint NP-pair with respect to all representations
(see [2,3]). This result was a starting point to our research.
In this paper we characterize the problem of the existence of a p-optimal
proof system for SAT, the problem of whether the standard proof system for
SAT (a satisfying truth assignment is a proof of a satisﬁable boolean formula) is
p-optimal, and the problem of the existence of an optimal proof system for TAUT
in a similar, but slightly modiﬁed, manner. We provide the new characterization
of the problem of the existence of a p-optimal proof system for SAT and the
new characterization of the problem of whether the standard proof system for
SAT is p-optimal. We also reformulate Olaf Beyersdorﬀ’s characterization of the
problem of the existence of an optimal proof system for TAUT. The last section
of the paper is devoted to this issue.
Our characterizations of these problems are in terms of nondeterministic
polynomial-time Turing machines which obey special conditions, so called pro-
mises (see [5]). In case of a p-optimal proof system for SAT this promise
is the totality of a nondeterministic polynomial-time Turing machine. This
promise can be expressed on a propositional level in a nonuniform manner as
a sequence of satisﬁable boolean formulas. A nondeterministic polynomial-time

366
Z. Sadowski
Turing machine is total if and only if it accepts the set of all strings over a certain
ﬁxed ﬁnite alphabet. The crucial observation is that deterministic polynomial-
time transducers computing proof systems for SAT correspond to certain total
nondeterministic polynomial-time Turing machines.
For a given nondeterministic polynomial-time Turing machine we construct,
using the methods from the proof of Cook’s Theorem (see [6]), the family of
propositional formulas which in sum express the totality of this machine. Namely,
all formulas from this family are satisﬁable if and only if the machine is total.
Having such a family of propositional formulas we use proof systems for SAT
to verify that a given nondeterministic polynomial-time Turing machine is total.
For a given proof system h for SAT and for a total nondeterministic polynomial-
time Turing machine N we say that the totality of N is strongly representable
in h if and only if formulas expressing the totality of N are provable with short
proofs in h and these proofs can be eﬃciently constructed. We prove that there
exists a p-optimal proof system for SAT if and only if there exists a proof system
for SAT such that the totality of any total nondeterministic polynomial-time
Turing machine is strongly representable in it.
The hypothesis that in polynomial time one can ﬁnd accepting computa-
tions of total nondeterministic polynomial-time Turing machines is on the list of
propositions proved to be equivalent by Steven Fenner, Lance Fortnow, Ashish
Naik and John Rogers (see [8]). They used the notation Q to represent the prop-
erty that any or all of the hypotheses from this list are true. Olaf Beyersdorﬀ,
Johannes K¨obler and Jochen Messner [4] proved that Q is equivalent to the
p-optimality of the standard proof system for SAT.
In this paper we prove that the standard proof system for SAT is p-optimal
if and only if the totality of any total nondeterministic polynomial-time Turing
machine is strongly representable in it, so we add one more proposition to the
list of Q-hypotheses.
2
Preliminaries
We assume some familiarity with basic complexity theory and refer the reader
to [1] for standard notions and for deﬁnitions of complexity classes appearing in
the paper.
The symbol Σ denotes a certain ﬁxed ﬁnite alphabet throughout the paper.
The set of all strings over Σ is denoted by Σ⋆. For a string x, |x| denotes the
length of x.
We use Turing machines (acceptors and transducers) as our basic compu-
tational model. We will not distinguish between a machine and its code. For a
Turing machine M the symbol L(M) denotes the language accepted by M.
We consider deterministic polynomial-time clocked Turing transducers with
uniformly attached standard clocks that stop their computations in polynomial
time (see [1]). We impose some restrictions on our encoding of these machines.
From the code of any polynomial-time clocked Turing machine N we can easily
detect (in polynomial time) the polynomial pN which is its polynomial-time
bound.

Total Nondeterministic Turing Machines and a p-optimal Proof System
367
We consider only languages over the alphabet Σ (this means that, for exam-
ple, boolean formulas have to be suitably encoded). The symbol TAUT denotes
the set (of encodings) of all propositional tautologies over a ﬁxed adequate set
of connectives, SAT denotes the set of all satisﬁable boolean (propositional)
formulas. Finally, ⟨., . . . , .⟩denotes some standard polynomial-time computable
tupling function.
3
Propositional Proof Systems
The concept of an abstract propositional proof system, subsuming all proposi-
tional proof systems used in practice, was introduced by S. Cook and R. Reckhow
[7] in the following way:
Deﬁnition 1. A proof system for TAUT is a polynomial-time computable func-
tion f : Σ⋆onto
−→TAUT.
A string w such that f(w) = α we call an f-proof of a formula α. We write
f ⊢∗αn if and only if {αn: n ≥1} is a sequence of tautologies with polynomial-
size f-proofs. A polynomially bounded proof system for TAUT (which allows
short proofs to all tautologies) exists if and only if NP = co-NP (see [7]).
Proof systems are compared according to their strength using the notion of
simulation and the presumably stronger notion of p-simulation.
Deﬁnition 2 (Kraj´ıˇcek, Pudl´ak). Let f, f ′ be two proof systems for TAUT.
We say that f simulates f ′ if there exists a polynomial p such that for any
α ∈TAUT, if α has a proof of length n in f ′, then α has a proof of length
≤p(n) in f.
The notions of an optimal proof system for TAUT and a p-optimal proof
system for TAUT were introduced by J. Kraj´ıˇcek and P. Pudl´ak [11].
Deﬁnition 3. A proof system for TAUT is optimal (p-optimal) if and only if
it simulates (p-simulates) any proof system for TAUT.
The notion of a proof system can be considered not only for TAUT, but also
for any language L, in particular for SAT.
Deﬁnition 4. A proof system for SAT is a polynomial-time computable func-
tion h : Σ⋆onto
−→SAT.
It follows from the above deﬁnition that for any proof system h for SAT
there exists a polynomial-time clocked transducer Mh which computes h. To
classify proof system for SAT we can use the notion of p-simulation introduced
by Stephen Cook and Robert Reckhow (see [7]).
Deﬁnition 5 (Cook, Reckhow). Let h, h′ be two proof systems for SAT. We
say that h p-simulates h′ if there exists a polynomial-time computable function
γ : Σ⋆−→Σ⋆such that for every α ∈SAT and every w ∈Σ⋆, if w is a proof
of α in h′, then γ(w) is a proof of α in h.

368
Z. Sadowski
In other words, γ translates h′-proofs into h-proofs of the same formula.
Deﬁnition 6. A proof system for SAT is p-optimal if and only if it p-simulates
any proof system for SAT.
We will study the problem of the existence of an p-optimal proof system for
SAT and the problem of the existence of an optimal proof system for TAUT
from a computational-complexity perspective.
Proving our characterization of the problem of the existence of a p-optimal
proof system for SAT we will use the following theorem proved by Jochen Mess-
ner (see [12], Proposition 16). It says that a p-optimal proof system for SAT is
polynomial-time invertible on any easy (polynomial-time recognizable) subset of
SAT.
Theorem 1 (Jochen Messner). Let S ⊂SAT and S ∈P. If f is a p-optimal
proof system for SAT then there exists a polynomial-time algorithm AS such
that for any α ∈S this algorithm produces an f −proof of α.
4
Formulas Expressing the Totality of Nondeterministic
Turing Machines
Let N be a nondeterministic Turing machine.
Deﬁnition 7. We say that N is total if and only if N accepts Σ⋆.
To any nondeterministic polynomial-time Turing machine N and any x ∈Σ⋆
we shall assign the boolean formula βN
x which will be used for verifying that N
accepts x. The formula βN
x will satisfy the following condition: βN
x is satisﬁable
if and only if there exists an accepting computation N on input x. In sum, {βN
x :
x ∈Σ⋆} is a set of satisﬁable boolean formulas if and only if N is total.
Our construction of the formula βN
x
comes from Cook’s proof that SAT
is NP-complete (see [6]). The formula βN
x is just Cook’s formula for the pair
⟨N, x⟩. It follows from this construction that our formulas possess the following
property.
Local uniformity property.
Let M be a ﬁxed nondeterministic polynomial-time Turing machine. There
exists a polynomial-time computable function fM such that for any x ∈Σ⋆
fM(x) = βM
x .
5
Properties of Nondeterministic Turing Machines
Representable in Proof Systems
Considering the problem of the existence of a p-optimal proof system for SAT we
are concerned with the property of nondeterministic Turing machines called the
totality. Using the expressibility of the property of being total as a sequence of
satisﬁable boolean formulas we can verify that a given nondeterministic Turing

Total Nondeterministic Turing Machines and a p-optimal Proof System
369
machine is total with the help of short proofs in some proof system for SAT.
This leads to the following concept:
Let h be a proof system for SAT and let N be a polynomial-time nondeter-
ministic Turing machine which is total.
Deﬁnition 8. We say that the totality of N is strongly representable in h if
and only if there exists a polynomial-time algorithm that on input x produces an
h-proof of βN
x for any string x.
The key thing in this deﬁnition is the possibility to construct in polynomial
time the proofs of the formulas stating that deﬁnite input strings are acceptable.
6
A New Characterization of the Problem of the
Existence of a p-optimal Proof System for SAT
Polynomial-time clocked transducers producing all satisﬁable boolean formulas
(completeness) and only satisﬁable boolean formulas (correctness) are machines
computing proof systems for SAT. The polynomial-time clocked transducers pro-
ducing only satisﬁable boolean formulas correspond in a natural way to total non-
deterministic Turing machines working in polynomial time. It can be explained
in the following way:
Deﬁnition 9. We say that a polynomial-time clocked deterministic transducer
M behaves well on input x if and only if M on x outputs a satisﬁable boolean
formula.
Let S be a ﬁxed nondeterministic Turing machine working in polynomial
time and accepting SAT. Let M be a polynomial-time clocked transducer. By
M ◦S we denote the nondeterministic Turing machine which on any input x
runs M and then runs S on the output produced by M. We can see that M ◦S
accepts input string x if and only if M on input x outputs a satisﬁable boolean
formula, so M behaves well on any input if and only if M ◦S is total.
Now we can formulate our characterization of the problem of the existence
of a p-optimal proof system for SAT.
Theorem 2. Statements (i) – (ii) are equivalent:
(i) There exists a p-optimal proof system for SAT.
(ii) There exists a proof system for SAT such that the totality of any total non-
deterministic Turing machine working in polynomial time is strongly repre-
sentable in it.
Proof. (i) →(ii)
Let Opt be a p-optimal proof system for SAT and let M be a total nondeter-
ministic Turing machine working in polynomial-time. Let us deﬁne AM = {βM
x :
x ∈Σ⋆}. We have AM ⊂SAT because M is total. From the structure of Cook’s
reduction (as βM
x clearly displays M and x) it follows that AM ∈P.

370
Z. Sadowski
According to Theorem 1, there exists a polynomial-time algorithm that on
input βM
x
produces an Opt-proof of βM
x
for any βM
x ∈AM. From this and from
the local uniformity property of βM
x
formulas we conclude that there exists a
polynomial-time algorithm that on input x produces an Opt-proof of βM
x
for
any x ∈Σ⋆, so the totality of the machine M is strongly representable in Opt.
(ii) →(i)
Let h be a proof system for SAT such that the totality of any total nonde-
terministic Turing machine working in polynomial time is strongly representable
in it. We say that a string v ∈Σ⋆is in good form if and only if
v = ⟨M, x, Proof −βM◦S
x
, 0pM (|x|)⟩
where M is a polynomial-time clocked transducer with pM time bound, x ∈Σ⋆,
Proof −βM◦S
x
is an h-proof of the formula βM◦S
x
expressing the fact that the
machine M ◦S accepts x, 0pM (|x|) is the sequence of zeros (padding).
Let us notice that if v is in good form, then M on input x produces a
satisﬁable boolean formula. We can prove it as follows. The formula βM◦S
x
is
satisﬁable as a formula possessing an h-proof. From this it follows that there
is an accepting computation of M ◦S on input x. From the deﬁnition of the
machine M ◦S we conclude that M on input x produces a satisﬁable boolean
formula.
Let α0 be a certain satisﬁable boolean formula. We deﬁne Opt : Σ⋆onto
−→SAT
in the following way: Opt(v) = α if v is in good form and α is a satisﬁable
boolean formula produced by M on input x, otherwise Opt(v) = α0. Clearly
Opt : Σ⋆onto
−→SAT. Padding appearing in the deﬁnition of a string in a good
form assures that Opt can be computed in polynomial time.
To prove the p-optimality of Opt, let g be a proof system for SAT computed
by a polynomial-time clocked transducer K with time bound pk. Since K ◦S
is a total nondeterministic polynomial-time Turing machine it follows that the
totality of K ◦S is strongly representable in h and in consequence there exists a
polynomial-time algorithm that on input x produces an h-proof of βK◦S
x
for any
x. The following polynomial-time computable function t : Σ⋆−→Σ⋆deﬁned by
t(x) = ⟨K, x, Proof −βK◦S
x
, 0pK(|x|)⟩
translates g-proofs into Opt-proofs. The symbol Proof −βK◦S
x
denotes an h-
proof of the formula βK◦S
x
. This completes the proof that Opt is a p-optimal
proof system for SAT.
7
A New Characterization of the Problem of Whether
the Standard Proof System for SAT Is p-optimal
By the standard proof system for SAT we mean the proof system for SAT in
which the satisfying assignment is a proof of any satisﬁable boolean formula α
(see [4]).

Total Nondeterministic Turing Machines and a p-optimal Proof System
371
The following hypothesis is on the list of equivalent complexity-theoretic
conjectures presented by Stephen Fenner, Lance Fortnow, Ashish Naik and John
Rogers in [8]:
For any total nondeterministic polynomial-time Turing machine N there
exists a polynomial-time computable function gN such that for all x, gN out-
puts an accepting computation of N on x. We name this hypothesis as the main
hypothesis on the list of Q-hypotheses.
Olaf Beyersdorﬀ, Johannes K¨obler and Jochen Messner proved that the p-
optimality of the standard proof system for SAT is equivalent to the assertion
Q, so in other words, the p-optimality of the standard proof system for SAT is
equivalent to any of the Q-hypotheses from the list in [8]. Speciﬁcally, it concerns
the main hypothesis on the list of Q-hypotheses.
Theorem 3 (Olaf Beyersdorﬀ, Johannes K¨obler, Jochen Messner). Statements
(i) – (ii) are equivalent:
(i) The standard proof system for SAT is p-optimal.
(ii) For any total nondeterministic polynomial-time Turing machine N there
exists a polynomial-time computable function gN such that for all x, gN(x)
outputs an accepting computation of N on x.
The following theorem presents our characterization of the problem of
whether the standard proof system for SAT is p-optimal.
Theorem 4. Statements (i) – (ii) are equivalent:
(i) The standard proof system for SAT is p-optimal.
(ii) The totality of any total nondeterministic polynomial-time Turing machine
is strongly representable in the standard proof system for SAT.
Proof. From Theorem 3 it follows that it is suﬃcient to show that (ii) is equiva-
lent to the main hypothesis on the list of Q-hypotheses.
For the proof of the forward implication ((ii) →Q) observe, recalling the
proof of Cook’s theorem, that βN
x
is a propositional formula that encodes a
computation of N on x, so given a satisfying assignment to βN
x , some accepting
computation of N on x can be reconstructed from it in polynomial time.
For the converse implication, observe, again recalling the proof of Cook’s
theorem that if there exists a polynomial-time computable function gN such
that for all x, gN(x) outputs an accepting computation of N on x, the satisfying
assignment of βN
x can be easily produced from this accepting computation.
Note that we have actually proved that the statement (ii) from the last
theorem can be added to the list of Q-hypotheses.
8
A Characterization of the Problem of the Existence
of an Optimal Proof System for TAUT
O. Beyersdorﬀaddressed the problem of the existence of an optimal proof sys-
tem for TAUT from a completely logic oriented perspective. Deﬁning proposi-
tional representations of NP-sets he has not referred to nondeterministic Turing

372
Z. Sadowski
machines accepting this sets. We reformulate his characterization of the problem
of the existence of an optimal proof system for TAUT. Our characterization of
this problem is in terms of pairs of disjoint nondeterministic Turing machines
working in polynomial time, so the disjointness is the promise that, in our charac-
terization, pairs of nondeterministic Turing machines should obey. This promise
can be expressed on a propositional level as a sequence of propositional tau-
tologies. Using nondeterministic Turing machines we replaced a logic-oriented
perspective connected with Olaf Beyersdorﬀ’s characterization with a complex-
ity theoretic-perspective.
Let (M, N) be a pair of nondeterministic polynomial-time Turing machines.
Deﬁnition 10. We say that the machines M and N are disjoint if and only if
there does not exist any input that is accepted by both machines M and N.
Any pair of disjoint nondeterministic polynomial-time Turing machines
accepts a disjoint NP-pair. So we can say that pairs of disjoint nondeterministic
polynomial-time Turing machines is the machine model of the promise complex-
ity class Disjoint NP-Pairs.
Deﬁnition 11. Let (M, N) be a pair of nondeterministic polynomial-time Tur-
ing machines and let n be a natural number. We say that the machines M and N
are n-disjoint if and only if for any input x of length n there does not exist simul-
taneously a computation of M accepting x and a computation of N accepting x.
To any pair (M, N) of nondeterministic polynomial-time Turing machines
and any n natural we shall assign the boolean formula DisjM,N
n
satisfying the
following condition: DisjM,N
n
is a propositional tautology if and only if the pair
(M, N) is n-disjoint.
Adapting the methods from the proof of Cook’s Theorem we can construct
the propositional formula αM
n which satisﬁes the condition: αM
n is satisﬁable if
and only if there exists a string w of length n such that M accepts w. Similarly,
we can construct the propositional formula αN
n which is satisﬁable if and only
if there exists a string w of length n such that N accepts w. Let Gn
0 be the
propositional formula satisfying the condition: Gn
0 is satisﬁable if and only if
at the ﬁrst step of the computation of M, the ﬁrst n cells of the tape of this
machine contain the same symbols as the respective cells of the machine N at
the ﬁrst step of its computation. We deﬁne DisjM,N
n
⇐⇒¬(Gn
0 ∧αM
n ∧αN
n ). For
details of the construction of these formulas see [15]. In sum {DisjM,N
n
: n ∈N}
is a set of propositional tautologies if and only if the machines M and N are
disjoint.
Using the expressibility of the property of being disjoint as a sequence of
propositional tautologies we can verify that a pair of nondeterministic machines
is disjoint with the help of short proofs in some proof system for TAUT. This
leads to the following deﬁnition:
Deﬁnition 12. Let f be a proof system for TAUT and let (M, N) be a pair
of disjoint nondeterministic polynomial-time Turing machines. We say that the
disjointness of M and N is representable in f if and only if f ⊢∗DisjM,N
n
.

Total Nondeterministic Turing Machines and a p-optimal Proof System
373
Our reformulation of Olaf Beyersdorﬀ’s characterization of the problem of
the existence of an optimal proof system for TAUT is as follows:
Theorem 5. Statements (i) – (ii) are equivalent:
(i) There exists an optimal proof system for TAUT.
(ii) There exists a proof system for TAUT such that the disjointness of any
pair of disjoint nondeterministic polynomial-time Turing machines is repre-
sentable in it.
It seems that this characterization corresponds to Kraj´ıˇcek - Pudl´ak’s charac-
terization of the problem of the existence of an optimal proof system for TAUT
in terms of ﬁnitistic consistency statements (see [11]).
Acknowledgements. I would like to thank the anonymous referees for all their help-
ful comments on how to improve the paper.
References
1. Balcazar, J., D´ıaz, J., Gabarr´o, J.: Structural Complexity I. Springer, Heidelberg
(1995)
2. Beyersdorﬀ, O.: Classes of representable disjoint NP-pairs. Theoret. Comput. Sci.
377, 93–109 (2007)
3. Beyersdorﬀ, O.: Tuples of disjoint NP-sets. Theory Comput. Syst. 43(2), 118–135
(2008)
4. Beyersdorﬀ, O., K¨obler, J., Messner, J.: Nondeterministic functions and the exis-
tence of optimal proof systems. Theoret. Comput. Sci. 410, 3839–3855 (2009)
5. Beyersdorﬀ, O., Sadowski, Z.: Do there exist complete sets for promise classes?
Math. Logic Q. 57(6), 535–550 (2011)
6. Cook, S.: The complexity of theorem proving procedures. In: Proceedings of the
3rd ACM Symposium on Theory of Computing, pp. 151–158 (1971)
7. Cook, S., Reckhow, R.: The relative eﬃciency of propositional proof systems. J.
Symbolic Logic 44, 36–50 (1979)
8. Fenner, S., Fortnow, L., Naik, A., Rogers, J.: Inverting onto functions. Inf. Comput.
186, 90–103 (2003)
9. K¨obler, J., Messner, J.: Complete problems for promise classes by optimal proof
systems for test sets. In: Proceedings of the 13th IEEE Conference on Computa-
tional Complexity CCC 1998, pp. 132–140 (1998)
10. K¨obler, J., Messner, J., Tor´an, J.: Optimal proof systems imply complete sets for
promise classes. Inf. Comput. 184(1), 71–92 (2003)
11. Kraj´ıˇcek, J., Pudl´ak, P.: Propositional proof systems, the consistency of ﬁrst order
theories and the complexity of computations. J. Symbolic Logic 54, 1063–1079
(1989)
12. Messner, J.: On optimal algorithms and optimal proof systems. In: Meinel, C.,
Tison, S. (eds.) STACS 1999. LNCS, vol. 1563, pp. 541–550. Springer, Heidelberg
(1999). doi:10.1007/3-540-49116-3 51
13. Pudl´ak, P.: Incompleteness in the ﬁnite domain. The Czech Academy of Science,
Institute of Mathematics, Preprint No. 5–2016, Praha (2016)

374
Z. Sadowski
14. Razborov, A.: On provably disjoint NP-pairs. Technical report 94–006, ECCC
(1994)
15. Sadowski, Z.: On an optimal quantiﬁed propositional proof system and a complete
language for NP ∩co-NP. In: Chlebus, B.S., Czaja, L. (eds.) FCT 1997. LNCS,
vol. 1279, pp. 423–428. Springer, Heidelberg (1997). doi:10.1007/BFb0036203

A One-Dimensional Physically Universal
Cellular Automaton
Ville Salo and Ilkka T¨orm¨a(B)
Department of Matematics and Statistics,
University of Turku, Turku, Finland
{vosalo,iatorm}@utu.fi
Abstract. Physical universality of a cellular automaton was deﬁned
by Janzing in 2010 as the ability to implement an arbitrary transfor-
mation of spatial patterns. In 2014, Schaeﬀer gave a construction of a
two-dimensional physically universal cellular automaton. We construct
a one-dimensional version of the automaton and a reversibly universal
automaton.
Keywords: Cellular automaton · Physical universality · Reversibility
1
Introduction
A cellular automaton (CA) is a ﬁnite or inﬁnite lattice of deterministic ﬁnite
state machines with identical interaction rules, which, at discrete time steps,
update their states simultaneously based on those of their neighbors. They are an
idealized model of massively parallel computation. From another point of view,
the local updates can be seen as particle interactions, and the CA is then a kind
of physical law, or dynamics, governing the universe of all state conﬁgurations.
We study the notion of physical universality of cellular automata, introduced
by Janzing in [4], which combines the two viewpoints in a novel and interesting
way. Intuitively, a cellular automaton is physically universal if, given a ﬁnite
subset D of the lattice and a function h on the shape-D patterns over the states
of the CA, one can build a ‘machine’ in the universe of the CA that, under the
dynamics of the CA, decomposes any given pattern P and replaces it by h(P).
A crucial point in this deﬁnition is that we need to perform arbitrary compu-
tation on all patterns, not only carefully constructed ones. This has quite serious
implications: The machine M that takes apart an arbitrary pattern of shape D
and replaces it by its image under an arbitrary function h is not in any way
special, and in particular we are not allowed to have separate ‘machine states’
and ‘data states’ with the former operating on the latter. Instead, we can also
think of M as a pattern, and must be able to construct a larger machine M ′
that takes M apart and reassembles it in an arbitrary way.
Research supported by the Academy of Finland Grant 131558.
V. Salo was partially supported by CONICYT Proyecto Anillo ACT 1103.
c
⃝Springer International Publishing AG 2017
J. Kari et al. (Eds.): CiE 2017, LNCS 10307, pp. 375–386, 2017.
DOI: 10.1007/978-3-319-58741-7 35

376
V. Salo and I. T¨orm¨a
This notion diﬀers essentially from most existing notions of universality for
CA such as intrinsic universality [7], universality in terms of traces as discussed
by Delvenne et al. in [3], and the several diﬀerent versions of computational
universality [2,6]. In these notions, one can usually implement the computations
and simulations in a well-behaved subset of conﬁgurations. Physical universality
bears more resemblance to the universal constructor machines of Von Neumann
[12], which construct copies of themselves under the dynamics of a particular
cellular automaton, and were the initial motivation for the deﬁnition of CA.
Another property of CA with a similar ﬂavor is universal pattern generation as
discussed in [5], meaning the property of generating all ﬁnite patterns from a
given simple initial conﬁguration.
In Janzing’s work [4] some results were already proved about physically uni-
versal CA, but it was left open whether such an object actually exists. A two-
dimensional physically universal CA was constructed by Schaeﬀer in [8] (see
also [9,10]), but it was left open whether this CA can be made one-dimensional.
We construct such a CA, solving the question in the positive. We also outline
the construction of a reversibly physically universal CA, solving another open
problem of [8].
2
Deﬁnitions
We now deﬁne the terms and notation used in this article. Let A be a ﬁnite
set, called the state set, and Zd a d-dimensional grid; we will mostly restrict our
attention to the case d = 1. We call AZd the d-dimensional full shift over A,
whose elements are conﬁgurations.
A cellular automaton (CA for short) is a map f : AZd →AZd deﬁned by a
ﬁnite neighborhood {n1, . . . , nk} ⊂Zd and a local function F : Ak →A, so that
f(x)v = F(xv+n1, . . . , xv+nk) holds for all x ∈AZd and v ∈Zd. It is reversible
if there is another CA g : AZd →AZd such that f ◦g = g ◦f = id. An example
of a reversible CA is the shift by n ∈Zd, deﬁned by σn(x)v = xv+n.
Other examples of reversible CA can be constructed as follows. Let the state
set A be a Cartesian product k
i=1 Ai with projection maps πi : A →Ai, let
n1, . . . , nk ∈Zd be arbitrary vectors, and let γ : A →A be a bijection. Then the
CA f deﬁned by f(x)v = γ(π1(xv+n1), . . . , πk(xv+nk)) is reversible. We call f a
partitioned CA. The components Ai are called the tracks of f, and the numbers
ni are shifts associated to the tracks. In the CA, the tracks are ﬁrst shifted
individually by the vectors ni, and then the bijection γ is applied to every cell.
A CA f is physically universal if the following condition holds. For all ﬁnite
domains D, E ⊂Zd, and all functions h : AD →AE, there exists a partial
conﬁguration x ∈AZd\D and a time step t ∈N such that for all P ∈AD, we
have f t(x∪P)E = h(P). We think of the partial conﬁguration x as a ‘gadget’ that
implements the function h: if any pattern P ∈AD is placed in the unspeciﬁed
part of x and the CA f is applied exactly t times, the image h(P) appears on
the domain E. We say f is eﬃciently physically universal if t is polynomial
in the diameter of D ∪E and the computational complexity of h according to

A One-Dimensional Physically Universal Cellular Automaton
377
some ‘reasonable’ complexity measure. In this article, we use circuit complexity,
or more precisely, the number of binary NAND gates needed to implement h.
One could reasonably require also that the conﬁguration x is computed eﬃciently
from the circuit presentation of the function h, which can be seen as a uniformity
condition in the sense of circuit complexity. Our proof gives a polynomial time
algorithm for this. See Sect. 9 for a discussion.
3
The Cellular Automaton
Our physically universal automaton is a partitioned CA f deﬁned as follows.
– The state set is A = {0, 1}4.
– The shifts are 2, 1, −1 and −2, and we denote S = {2, 1, −1, −2}.
– For each a, b ∈{0, 1} bijection γ maps the state (1, a, b, 1) to (1, b, a, 1), and
(a, 1, 1, b) to (b, 1, 1, a). Everything else is mapped to itself.
Alternatively, f is the CA with neighborhood {−2, −1, 1, 2} and local rule
(a, b, c, d) →
⎧
⎨
⎩
(π4(d), 1, 1, π1(a)),
if π2(b) = π3(c) = 1,
(1, π3(c), π2(b), 1),
if π1(a) = π4(d) = 1,
(π1(a), π2(b), π3(c), π4(d)), otherwise
where a, b, c, d ∈A are length-4 Boolean vectors.
Intuitively, in the CA f there are four kinds of particles, which are represented
by 1-symbols on the four tracks: fast right (track 1, speed 2), slow right (track 2,
speed 1), slow left (track 3, speed −1) and fast left (track 4, speed −2). At most
one particle of each kind can be present in a cell. On each step, every particle
jumps from its position n ∈Z to n + s, where s ∈S is its speed. After that,
if two fast or two slow particles are present in the same cell, then the direction
of every particle of the other speed is reversed. Such interactions are depicted
in Fig. 1. This resembles the two-dimensional CA of Schaeﬀer, where particles
move in four directions (NE, NW, SE, SW) with speed one, and the head-on
collision of two particles causes other particles in the same cell to make a u-turn.
4
The Logical Cellular Automaton
For the proof of physical universality, we deﬁne another CA on an inﬁnite state
set. Denote the ternary conditional operator by p(a, b, c) = (a ∧b) ∨(¬a ∧c) for
a, b, c ∈{0, 1}. That is, p(a, b, c) is equal to b if a = 1, and to c otherwise. In
many programming languages, p(a, b, c) is denoted by a ? b : c.
Deﬁnition 1. Let V = {α1, α2, . . .} be an inﬁnite set of variables, and denote
by F the set of Boolean functions over ﬁnitely many variables of V. The logical
extension of f is the CA-like function ˆf : ˆAZ →ˆAZ on the inﬁnite state set
ˆA = F4, where the four tracks are ﬁrst shifted as in f, and then the function
(a, b, c, d) →(p(b ∧c, d, a), p(a ∧d, c, b), p(a ∧d, b, c), p(b ∧c, a, d))
is applied to each coordinate. A valuation is a function v : V →{0, 1}. It extends
to F and then into a function v : ˆAZ →AZ in the natural way.

378
V. Salo and I. T¨orm¨a
Fig. 1. A sample spacetime diagram of f showing diﬀerent particle interactions, and
a schematic version below it. Time increases upward. Particles are represented by
arrowed bullets. For example, a bullet with arrows to the east, northeast and northwest
represents three particles moving at speeds 2, 1 and −1, respectively.
The logical extension simulates multiple spacetime diagrams of f: one can
see that the deﬁnition of ˆf is equal to that of f, except that each particle is
replaced by a Boolean formula that corresponds to the conditional presence or
absence of a particle. We think of A as a subset of ˆA containing the constant
0 or constant 1 function in each track. Note that ˆf is also reversible, and we
denote by ˆf −1 its inverse function. See Fig. 2 for a spacetime diagram of ˆf.
The following result holds basically by construction.
Lemma 1. Let x ∈ˆAZ be a conﬁguration, and let v : V →{0, 1} be a valuation,
so that v(x) ∈AZ. Then for all t ∈Z we have f t(v(x)) = v( ˆf t(x)).
The idea of the proof of physical universality of f using this new CA is the
following. We may assume that D = E = [0, n −1] in the deﬁnition of physical
universality, for some n ∈N. Then, we construct a spacetime diagram of ˆf with
the following properties. First, in the initial conﬁguration x ∈ˆAZ, the cells of the
interval [0, n−1] contain 4n distinct variables from V. All other cells of x contain
either 0 or 1. There also exists t > 0 such that ˆf t(x)[0,n−1] contains the Boolean
functions computing the function h in the deﬁnition of physical universality. In
the course of the construction, we deﬁne which cells of x contain a 1.
The construction proceeds in ﬁve stages, which are depicted in Fig. 3:
– Diﬀusion Stage, where the Boolean particles in the input area D disperse
into the environment. This stage does not require any auxiliary particles, as
Lemma 2 in Sect. 5 will show.

A One-Dimensional Physically Universal Cellular Automaton
379
α
β
¬β
β
β
β
β
α ∧β
α ∧¬β
Fig. 2. A schematic spacetime diagram of ˆf, where α, β ∈F. Particles are represented
by solid lines, and Boolean particles by dotted lines. Note that Boolean particles can
be created, even though f itself conserves the number of particles.
– Collection Stage, where the dispersed particles are rerouted to travel in the
same direction at the same speed. This stage is implemented in Sect. 6.2.
– Computation Stage, where the NAND-gates of the circuit representing h are
applied one by one to the travelling Boolean particles. This stage is imple-
mented in Sect. 6.3.
– Assembly Stage, where the Boolean particles resulting from the computation
are rerouted again toward the output area E.
– Reverse Diﬀusion Stage, where the particles converge on the output area and
produce the desired pattern encoding h exactly at time t.
Deﬁnition 2. We introduce the following terminology for the construction.
– The conﬁguration of interest, denoted by x ∈ˆAZ, initially contains the ‘fully
general’ state (α4i, α4i+1, α4i+2, α4i+3) in every cell i ∈[0, n−1], and 0 every-
where else. During the construction, we change the cells of x from 0 to 1, but
keep referring to it as x, so some of the deﬁnitions below depend on the stage
of the proof. The spacetime diagram of interest is deﬁned similarly.
– A (spacetime) position is an element of Z × S (Z × Z × S, respectively),
representing a (spacetime) point that may contain a particle of certain speed.
Note that time is bi-inﬁnite, since our cellular automata are reversible.
– There is a Boolean particle at spacetime position (i, t, s) if πs( ˆf t(x)i) is not
the constant 0 function, and a particle if it is the constant 1 function.
– There is a collision at coordinate (i, t) ∈Z×Z if ˆf t(x)i contains at least three
Boolean particles, and a crossing if there are at least two Boolean particles.
– The input is the pattern x[0,n−1] ∈ˆAn.
– The gadget is the contents of x outside [0, n −1], an element of AZ\[0,n−1].

380
V. Salo and I. T¨orm¨a
Diﬀusion
Collection
Computation
Assembly
Reverse
Diﬀusion
Fig. 3. A schematic diagram of the construction, not drawn to scale.
– A line is a subset of Z × N of the form L = L(i, t, s) = {(i + st, t) | t ∈N} for
some speed s ∈S and i ∈Z. It is occupied (in a time interval I ⊂Z) if one of
its coordinates (in the region Z × I) contains a crossing or a Boolean particle
of speed s. We denote L(t) = i + st and Lt = (L(t), t, s). The set of occupied
lines in the spacetime diagram of interest is denoted Locc.
For example, there are three crossings in Fig. 2, two of which are collisions.
The highest intersection of two dashed lines is not a crossing, as it does not take
place at an actual coordinate (one of the white circles). Every line segment in
the ﬁgure deﬁnes an inﬁnite occupied line.
5
The Diﬀusion Lemma
As stated above, we initialize the gadget to the all-0 partial conﬁguration, in
which situation we have the following lemma. It states that any ﬁnite set of
particles in the CA f eventually stop interacting and scatter to inﬁnity. The cor-
responding result is proved for the physically universal CA of [8] by considering
an abstract CA over the state set {0, 1
2, 1}, with the interpretation that 1
2 can be
either 0 or 1, and this lack of information is suitably propagated in collisions. In
our version, the role the new state 1
2 is played by Boolean particles.

A One-Dimensional Physically Universal Cellular Automaton
381
Lemma 2 (Diﬀusion Lemma).
Let x ∈
ˆAZ be such that xi = 0 for all
i /∈[0, n −1]. Then there are O(n2) crossings in the two-directional spacetime
diagram of x under ˆf that all happen in a time window of length O(n). For
all other times t ∈Z, there are O(n) Boolean particles in ˆf t(x), and they are
contained in the interval [−2|t|, n + 2|t|].
Proof. We prove the claim in the positive direction of time. By induction, one
sees that after any t ≥0 steps, there can be no right-going Boolean particles in
the cells (−∞, t−1], and no left-going particles in the cells [n−t, ∞). After these
sets intersect at time ⌈n/2⌉, there are no collisions, so no new Boolean particles
are created. Thus the number of Boolean particles is at most 6n, that is, twice the
length of the segment of ˆf ⌈n/2⌉(x) that may contain Boolean particles. We may
also have O(n2) crossings between Boolean particles going in the same direction
with diﬀerent speeds. Thus there are O(n2) crossings in total (Fig. 4).
⊓⊔
x
Fig. 4. An illustration of Lemma 2. The dashed line is the conﬁguration x, and the
thick segment is the interval [0, n−1]. All collisions take place in the dark gray area, and
Boolean particles may occur in the light gray area. The eight horizontal line segments
are the scattering Boolean particles, grouped by speed.
At this point, in the conﬁguration of interest, we have an empty gadget,
and the spacetime diagram contains O(n) Boolean particles at any given time.
Since the CA ˆf is reversible, the values of the corresponding Boolean expressions
determine the values of the original variables.
6
Manipulating the Spacetime Diagram
6.1
Controlled Modiﬁcations
In this section, we introduce new particles in the gadget that will collide with
the existing Boolean particles and create new ones. This is called scheduling

382
V. Salo and I. T¨orm¨a
collisions. We never schedule a collision on an occupied line, and never add
a Boolean particle on an existing crossing. This is formalized in the following
deﬁnition.
Deﬁnition 3. We say a modiﬁcation of the gadget is (m, n, L, T , t, I)-controlled
for numbers m, n ∈N, sets of lines L and T , time t ∈Z, and interval I ⊂Z, if
the following conditions hold:
1. the modiﬁcation consists of adding at most m particles to the gadget,
2. at most m new occupied lines and n new crossings are introduced,
3. no existing crossings become collisions,
4. no line in L ∪Locc is occupied by a new Boolean particle or a new crossing,
5. no spacetime position in the set
F(T , t, I) = {(i, t, s′) | i ∈I, s′ ∈D} \ T t
(1)
gets a new Boolean particle, and
6. no line in T gets a collision after time t.
If the conditions hold in the time interval (−∞, t] (in particular, condition 6 need
not hold at all), then the modiﬁcation is weakly (m, n, L, T , t, I)-controlled.
In practice, a controlled modiﬁcation is one where we add to the gadget
a ﬁnite number of particles that aﬀect the spacetime diagram of interest only
where we want it to be aﬀected: the spacetime positions in T t. The numbers m
and n control the amount of new objects added to the diagram (recall that our
goal is the keep its size polynomial). An existing crossings should not become
a collision, since that could aﬀect the labels of the crossing Boolean particles,
which may store information about the input pattern. The lines in L ∪Locc and
the positions near T , that is, those in F(T , t, I), are ‘protected’ from accidentally
obtaining any auxiliary Boolean particles created in the modiﬁcation. The role
of L and I is to guarantee an empty area in the spacetime diagram where we
may reroute more Boolean particles at a later stage of the construction.
The notion of controlled modiﬁcations allows us to prove simple lemmas that
aﬀect one Boolean particle at a time, and use them repeatedly as ‘black boxes’
to perform more complex modiﬁcations without explicitly specifying the path
of every particle in the spacetime diagram. This makes our proof more ﬂexible,
but also somewhat technical.
Deﬁnition 4. Let j, t ∈Z. The positive cone rooted at (j, t) is the set of space-
time coordinates C(j, t) = {(j + j′, t + t′) | t′ ∈N, j′ ∈[−t′, t′]}.
The following lemmas are parametrized by the numbers mi for i = 1, 2, 3, 4.
They denote, intuitively, the number of existing crossings, the number of occu-
pied lines, the size of the additional ‘forbidden area,’ and the number of particles
involved, respectively. Also, the expression ‘if t′ = Ω(N(m1, m2, m3, m4)) is large
enough, then P(t′) holds’ for t′ ∈N, a function N : N4 →N and a property
P means that there exists a number T ≤K · N(m1, m2, m3, m4) + K′, where
K, K′ > 0 are constants independent of the mi, such that P(t′) holds for all
t′ ≥T.

A One-Dimensional Physically Universal Cellular Automaton
383
6.2
Moving the Boolean Particles
We now prove that we can add a ﬁnite number of particles to the gadget, so that
after some number of steps, a collection of Boolean particles is ‘moved’ onto any
desired lines, at the same time. We do this one particle at a time, and without
interfering with the trajectories of any other existing particles. The statements
of the following lemmas refer to labels of spacetime positions instead of Boolean
particles, since we want to also handle ‘Boolean particles’ whose label happens
to be 0. However, in the intuitive explanations we still refer to Boolean particles.
Lemma 3. Suppose we have a spacetime diagram of interest with m1 crossings
and m2 occupied lines, let Lp be a line that contains no collisions after time t,
and let β ∈F be the label of the spacetime position Lt
p. Let L be a collection
of m3 lines not containing Lp. Let L /∈L be an unoccupied line that passes
through some spacetime coordinate (j′, t′) ∈C(j, t) with t′ > t. Let T be a set of
O(m3) lines containing L, and let I ⊂Z be an interval of length O(m3). If t′ =
t + Ω(m1 + m2 + m3) is large enough, then there is an (O(1), O(m2), L, T , t′, I)-
controlled modiﬁcation after which the spacetime position Lt′ has label β. The
same holds if the line L is unoccupied only in the time interval (−∞, t′], but the
modiﬁcation is weakly controlled.
The lemma intuitively states that we can almost completely freely change
the position and direction of a Boolean particle by introducing a constant num-
ber of auxiliary particles, while preserving the already constructed gadget and
introducing relatively few new crossings. The point of the set of forbidden lines
L and positions I is that we can in fact move an arbitrary number of Boolean
particles at the same time. The idea is that we move them by applying Lemma 3
repeatedly to one Boolean particle at a time, always adding the target lines of
the remaining ones into the protected set L. This guarantees that the lines are
not accidentally occupied too early.
Corollary 1. Suppose we have a spacetime diagram of interest with m1 cross-
ings and m2 occupied lines, and for each k = 1, . . . , m4, a line Lpk that contains
no collisions after time t such that the spacetime position Lt
pk has label βk ∈F.
Let L be a collection of m3 lines not containing any of the Lpk. Let Lk /∈L be
unoccupied and mutually disjoint lines that pass through some spacetime coordi-
nates (j′
k, t′) ∈C(L(t)
pk , t) with t′ > t. Denote T = {L1, . . . , Lm4}, and let I ⊂Z
be an interval of length O(m3). If t′ = t + Ω(m1 + m3 + m4(m2 + m4)) is large
enough, then there is an (O(m4), O(m4(m2 + m4)), L, T , t′, I)-controlled modiﬁ-
cation after which each spacetime position Lt′
k has label βk. The same holds if the
lines Lk are unoccupied only in the time interval (−∞, t′], but the modiﬁcation
is weakly controlled.
6.3
Computing with the Boolean Particles
Next, we will do some computation with the Boolean particles. Namely, we show
that the NAND of two Boolean particles can be computed nondestructively in

384
V. Salo and I. T¨orm¨a
any spacetime position, as long as we have enough time, and the target line is
in the intersection of the cones rooted at the input particles.
Lemma 4. Suppose we have a spacetime diagram of interest with m1 crossings
and m2 occupied lines, and two distinct lines L1 and L2 of direction 1 contain-
ing no collisions after time t such that the spacetime coordinates Lt
1, Lt
2 have
labels β1, β2 ∈F. Let L be a set of m3 lines not containing L1 and L2, and
let L /∈L be an unoccupied line of slope 1 to the left of L1 and L2 that passes
through some spacetime coordinate (j′, t′) ∈C(L(t)
1 , t) ∩C(L(t)
2 , t) with t′ > t.
Let T = {L1, L2, L}. If t′ = t + Ω(m1 + m2 + m3) is large enough, then there
is an (O(1), O(m2), L, T , t′, ∅)-controlled modiﬁcation after which the spacetime
positions Lt′
1 , Lt′
2 and Lt′ have labels β1, β2 and ¬(β1 ∧β2), respectively.
Similarly to the fact that any number of particles can be moved, we can now
compute an arbitrary Boolean function, given enough time and space.
Corollary 2. Suppose we have a spacetime diagram of interest with m1 col-
lisions and m2 occupied lines. Let j ∈Z, and for every k = 1, . . . , m4, let
βk ∈F be the label of the spacetime position pk = (j + k −1, t, 1). Suppose
further that the lines Lpk passing through the pk do not contain collisions after
time t. Let H : {0, 1}m4 →{0, 1}m with m = O(m4) be a Boolean function
realizable with C NAND-gates. Let L be a set of m3 lines not containing the
Lpk, let L1, . . . , LC+m /∈L be unoccupied lines of slope 1 that pass through
the spacetime coordinates (j −1, t), . . . , (j −C −m, t), and let t′ > t. Let also
T = {LC, . . . , LC+m}. If
t′ = t + Ω((C + m4)(C2 + m1 + m3 + (C + m4)(m2 + m4)))
is large enough, there is an (O(C + m4), O((C + m2 + m4)(C + m4)), L, T , t′, ∅)-
controlled modiﬁcation after which the spacetime positions Lt′
C+ℓhave labels
H(β1, . . . , βm)ℓ.
7
Physical Universality
Combining the lemmas of the previous section, we obtain our main result, the
eﬃcient physical universality of f.
Theorem 1. The cellular automaton f is eﬃciently physically universal.
8
A Reversibly Physically Universal CA
In [8], other open questions were also posed, and here we answer one of them.
Call a CA f : AZd →AZd reversibly physically universal, if for any ﬁnite
domain D ⊂Zd and any bijection θ : AD →AD, there exist partial conﬁgu-
rations x, y ∈AZd\D and a time t such that for all patterns P ∈AD we have

A One-Dimensional Physically Universal Cellular Automaton
385
f t(x ∪P) = y ∪θ(P). In other words, the input cannot permanently aﬀect the
gadget during the computation.
The intuition behind this alternative notion is that after the CA has produced
the pattern θ(P), the state of the ‘computational machinery’ should not depend
on P: the entropy present in P does not permanently leak out of the domain D.
It was conjectured by Schaeﬀer in [8] that a two-dimensional reversibly universal
CA exists; we construct a one-dimensional one.
Our reversibly physically universal CA is based on the same idea as the phys-
ically universal one, but computation must be performed with reversible gates
[11]. This, together with additional collision rules for modifying the speeds of
particles, allows us to prevent information from spreading beyond the computa-
tion zone.
Theorem 2. There exists a one-dimensional reversibly physically universal CA.
9
Final Remarks
Our proof of the physical universality of f can be turned into a polynomial time
algorithm that, given a circuit computing the function h : AD →AE in the
deﬁnition of physical universality, computes the corresponding gadget and the
polynomially bounded number t. The main issue with this is that occupied lines
and crossings cannot be enumerated in polynomial time unless P = NP, since
it requires checking whether an arbitrary NAND-expression is satisﬁable. This
issue can be avoided by keeping track of a set of lines Locc+ that contains at
least all occupied lines, as well as a set of coordinates X ⊂Z2 that contains at
least all crossings. When invoking Lemmas 3 and 4 to modify the conﬁguration
of interest, we add to the protected set L all lines in Locc+ and all lines that pass
through a coordinate in X. The set Locc+ is then amended with those lines that
‘locally’ appear to be occupied based on the added particles, and similarly for
X. It can be veriﬁed that this approach does not change the asymptotic bounds
in the construction, so the resulting conﬁguration is polynomial in size.
The above algorithm will need polynomial space, as it compares the new
positions of auxiliary particles to all existing ones. To construct the gadget in
logarithmic space, it might be necessary to ﬁx particular choices of where the
auxiliary particles are put. We have chosen the more abstract route in the hope
that our methods generalize more directly to a larger class of CA.
The existence of a physically universal CA was asked in [4] without ﬁxing the
number of states. Our CA has 16 states and radius 2. It would be interesting to
ﬁnd the minimal number of states and the minimal radii for physically universal
CA. Of course, one can make any physically universal CA have radius 1 by
passing to a blocking presentation, but this increases the number of states. From
our CA, one obtains a physically universal radius-1 CA with 256 states.
Question 1. Are there physically universal CA on two states? Which combina-
tions of state set and radius allow physical universality?

386
V. Salo and I. T¨orm¨a
A long list of open questions about physical universality is also given in [8].
Finally, it would be interesting to explore the connections between physical uni-
versality and the other types of universalities mentioned in Sect. 1. For example,
a reversible cellular automaton is not intrinsically universal, since it cannot sim-
ulate a non-reversible automaton, but could a physically universal CA be able
to simulate all reversible automata?
Acknowledgments. We are thankful to Charalampos Zinoviadis for introducing this
problem to us, and for many fruitful discussions on the proof, and Luke Schaeﬀer for
his Golly implementation of our physically universal CA. We would also like to thank
Scott Aaronson for popularizing the concept in his blog [1].
References
1. Aaronson, S.: Shtetl-Optimized - the blog of Scott Aaronson. http://www.
scottaaronson.com/blog/?p=1896. Accessed 17 Sept 2014
2. Cook, M.: Universality in elementary cellular automata. Complex Syst. 15(1), 1–40
(2004)
3. Delvenne, J.-C., Kurka, P., Blondel, V.D.: Decidability and universality in symbolic
dynamical systems. Fundam. Inform. 74(4), 463–490 (2006)
4. Janzing, D.: Is there a physically universal cellular automaton or Hamiltonian?
ArXiv e-prints, September 2010
5. Kari, J.: Universal pattern generation by cellular automata. Theor. Comput. Sci.
429, 180–184 (2012). Magic in Science
6. Neary, T., Woods, D.: P-completeness of cellular automaton Rule 110. In: Bugliesi,
M., Preneel, B., Sassone, V., Wegener, I. (eds.) ICALP 2006. LNCS, vol. 4051, pp.
132–143. Springer, Heidelberg (2006). doi:10.1007/11786986 13
7. Ollinger, N.: The intrinsic universality problem of one-dimensional cellular
automata. In: Alt, H., Habib, M. (eds.) STACS 2003. LNCS, vol. 2607, pp. 632–641.
Springer, Heidelberg (2003). doi:10.1007/3-540-36494-3 55
8. Schaeﬀer, L.: A physically universal cellular automaton. In: Electronic Colloquium
on Computational Complexity (ECCC), vol. 21, p. 84 (2014)
9. Schaeﬀer,
L.:
A
physically
universal
cellular
automaton.
In:
ITCS
2015–
Proceedings of the 6th Innovations in Theoretical Computer Science, pp. 237–246
(2015)
10. Schaeﬀer, L.: A physically universal quantum cellular automaton. In: Kari, J.
(ed.) AUTOMATA 2015. LNCS, vol. 9099, pp. 46–58. Springer, Heidelberg (2015).
doi:10.1007/978-3-662-47221-7 4
11. Toﬀoli, T.: Reversible computing. In: de Bakker, J., van Leeuwen, J. (eds.)
ICALP 1980. LNCS, vol. 85, pp. 632–644. Springer, Heidelberg (1980). doi:10.
1007/3-540-10003-2 104
12. von Neumann, J.: Theory of Self-Reproducing Automata. University of Illinois
Press, Champaign (1966)

Extending Wadge Theory to k-Partitions
Victor L. Selivanov1,2(B)
1 A.P. Ershov Institute of Informatics Systems SB RAS, Novosibirsk, Russia
vseliv@iis.nsk.su
2 Kazan (Volga Region) Federal University, Kazan, Russia
Abstract. We extend some results about Wadge degrees of Borel sub-
sets of Baire space to ﬁnite partitions of Baire space. A typical new
result is the characterization up to isomorphism of the Wadge degrees of
k-partitions with Δ0
3-components.
Keywords: Baire space · Wadge reducibility · Lipschitz reducibility ·
Backtrack reducibility · k-partition · h-preorder · Well preorder · Inﬁnite
game
1
Introduction
For subsets A, B of the Baire space N = ωω, A is Wadge reducible to B (A ≤W
B), if A = f −1(B) for some continuous function f on N. The quotient-poset
of the preorder (P(N); ≤W ) under the induced equivalence relation ≡W on the
power-set of N is called the structure of Wadge degrees in N. W. Wadge [15,16]
characterized the Wadge degrees of Borel sets up to isomorphism, in particular
this poset is well-founded and has no 3 pairwise incomparable elements.
Let 2 ≤k < ω. By a k-partition of N we mean a function A : N →
k = {0, . . . , k −1} often identiﬁed with the sequence (A0, . . . , Ak−1) where
Ai = A−1(i) are the components of A. Obviously, 2-partitions of N can be
identiﬁed with the subsets of N using the characteristic functions. The set of
all k-partitions of N is denoted kN , thus 2N = P(N). The Wadge reducibility
on subsets of N is naturally extended to k-partitions: for A, B ∈kN , A ≤W B
means that A = B ◦f for some continuous function f on N. In this way, we
obtain the preorder (kN ; ≤W ). For any pointclass Γ ⊆P(N), let Γ(kN ) be the
set of k-partitions of N with components in Γ.
In contrast with the Wadge degrees of sets, the structure (Δ1
1(kN ); ≤W )
for k > 2 has antichains of any ﬁnite size. Nevertheless, a basic property of
the Wadge degrees of sets may be lifted to k-partitions, as the following very
particular case of Theorem 3.2 in [4] shows:
Proposition 1. For any 2 ≤k < ω, the structure (Δ1
1(kN ); ≤W ) is a well
preorder, i.e. it has neither inﬁnite descending chains nor inﬁnite antichains.
Although this result gives an important information about the Wadge degrees
of Borel k-partitions, it is far from a characterization. Our aim is to obtain
c
⃝Springer International Publishing AG 2017
J. Kari et al. (Eds.): CiE 2017, LNCS 10307, pp. 387–399, 2017.
DOI: 10.1007/978-3-319-58741-7 36

388
V.L. Selivanov
such a characterization, continuing a series of earlier partial results (see e.g.
[5,11,12,14]). Our approach is to characterize the initial segments (Δ0
α(kN );
≤W ) for bigger and bigger ordinals 2 ≤α < ω1. In [11] we have done this for
α = 2, here we treat the case α = 3 (a ﬁnitary version of this case was considered
in [12]), a general case was outlined in Sect. 5 of [14]. Our original contribution is
the discovery of useful properties of natural operations on the k-partitions and
of the structures of labeled forests.
Let 
i Ai be the disjoint union of a sequence of elements A0, A1, . . . of kN .
Let N + := {1, 2, . . .}ω and for x ∈N + let x−:= λi.x(i) −1, so x−∈N. Deﬁne
the binary operation + on kN as follows: (A + B)(x) := A(x−) if x ∈N +,
otherwise (A + B)(x) := B(y) where y is the unique element of N such that
x = σ0y for a unique ﬁnite sequence σ of positive integers. For any i < k,
deﬁne a unary operation pi on kN by pi(A) := i + A where i := λx.i are
the constant k-partitions (which are precisely the distinct minimal elements of
(kN ; ≤W )). For any i < k, deﬁne a unary operation qi on kN (for k = 2, q0
and q1 coincide with the Wadge’s operations ♯and ♭from Sect. III.E of [16]) as
follows: qi(A)(x) := i if x has inﬁnitely many zeroes, qi(A)(x) := A(x−) if x has
no zeroes, and qi(A)(x) := A(y−) otherwise where y is the unique element of
N + such that x = σ0y for a string σ of non-negative integers. The introduced
operations are correctly deﬁned on Wadge degrees.
Our ﬁrst result, which is proved with a heavy use of Proposition 1, character-
izes some subalgebras of the Wadge degrees generated from the minimal degrees
{0}, . . . , {k −1}. The item (1) below follows from results in [11] but the proof
here is slightly diﬀerent and easier to generalize.
Theorem 1
(1) The
quotient-poset
of
(Δ0
2(kN ); ≤W )
is
generated
from
the
degrees
{0}, . . . , {k −1} by the operations , p0, . . . , pk−1.
(2) The quotient-poset of (Δ0
3(kN ); ≤W ) is generated from {0}, . . . , {k −1} by
the operations , +, q0, . . . , qk−1.
Our second result characterizes the structures above in terms of the homo-
morphism preorder on labeled forests [11,12,14]. Let (Q; ≤) be a preorder. A Q-
poset is a triple (P, ≤, c) consisting of a countable nonempty poset (P; ≤) with-
out inﬁnite chains, and a labeling c : P →Q. A morphism f : (P, ≤, c) →
(P ′, ≤′, c′) of Q-posets is a monotone function f : (P; ≤) →(P ′; ≤′) satisfying
∀x ∈P(c(x) ≤c′(f(x))). Let FQ and TQ denote the sets of all countable Q-
forests and Q-trees without inﬁnite chains, respectively. The h-preorder ≤h on
FQ is deﬁned as follows: P ≤h P ′, if there is a morphism from P to P ′. If Q = ¯k
of the antichain with k elements 0, . . . , k −1, we obtain the Q-preorders denoted
by Fk and Tk, respectively. We also need the preorder F 
Tk.
Theorem 2
(1) The quotient-posets of (Δ0
2(kN ); ≤W ) and of ( Fk; ≤h) are isomorphic.
(2) The quotient-posets of (Δ0
3(kN ); ≤W ) and of ( F 
Tk; ≤h) are isomorphic.

Extending Wadge Theory to k-Partitions
389
Again, item (1) above was established in [11] and is now extended to (2)
(a “ﬁnitary” version of (2) is described in [12]). The proof of Theorem 2 gen-
eralizes those in [11,12]. It takes the h-quasiorders as natural naming systems
for the subalgebras in Theorem 1, providing natural homomorphisms from the
forest structures onto the corresponding degree structures. From the properties
of the operations in Theorem 1 it follows by induction on the rank of the forests
that these homomorphisms are in fact isomorphisms. Because of space bounds,
we omit some proofs having published versions for the case of sets.
We do believe that the results above maybe extended to larger segments
(Δ0
α(kN ); ≤W ), 4 ≤α < ω1. Using the Kuratowski relativization technique
[2,8,16], we can deﬁne for any 1 ≤β < ω1 the binary operation +β on kN
such that +1 coincides with + and, for any 2 ≤α < ω1, the quotient-poset
of (Δ0
α(kN ); ≤W ) is generated from {0}, . . . , {k −1} by the operations  and
+β for all 1 ≤β < α. The extension of Theorem 2 is obtained by deﬁning
suitable iterated versions of the h-quasiorder in the spirit of [14]. Since Δ1
1(kN ) =

α<ω1 Δ0
α(kN ), we obtain the characterization of Wadge degrees of Borel k-
partitions. Note that in [9] we considered a classiﬁcation of hyperarithmetical
k-partitions of ω modulo m-reducibility which is in a precise sense the eﬀective
version of the Wadge degrees of k-partitions. Our “algebraic” approach to Wadge
theory was motivated by the similar approach in [9].
2
Preliminaries
We use the standard set-theoretic notation. We identify the set of natural num-
bers with the ﬁrst inﬁnite ordinal ω. The ﬁrst uncountable ordinal is denoted
by ω1. Let N = ωω be the set of all inﬁnite sequences of natural numbers (i.e.,
of functions x: ω →ω). Let ω∗be the set of ﬁnite sequences of elements of ω,
including the empty sequence ε. For σ, τ ∈ω∗and x ∈N, we write σ ⊑τ (resp.
σ ⊑x) to denote that σ is an initial segment of τ (resp. of x). By σx = σ · x we
denote the concatenation of σ and x, and by σ · N the set of all extensions of σ
in N. For x ∈N, we write x = x(0)x(1) · · · where x(i) ∈ω for each i < ω. For
x ∈N and n < ω, x[n] = x(0) . . . x(n −1) is the initial segment of x of length n.
By endowing N with the product of the discrete topologies on ω, we obtain
the so-called Baire space. The product topology coincides with the topology
generated by the collection of sets of the form σ · N for σ ∈ω∗. We recall the
well-known (see e.g. [6]) relation of closed subsets of N to trees. A tree is a
non-empty set T ⊆ω∗which is closed downwards under ⊑. A leaf of T is a
maximal element of (T; ⊑). By ∂(T) we denote the set of minimal elements in
(ω∗\ T; ⊑). A pruned tree is a tree without leafs. A path through a tree T is an
element x ∈N such that x[n] ∈T for each n ∈ω. For any tree T, the set [T] of
paths through T is closed in N. For any non-empty closed set A ⊆N there is a
unique pruned tree T with A = [T] and, moreover, there is a Lipschitz surjection
t : N →A which is constant on A (such a surjection is called a retraction onto A).
Therefore, there is a bijection between the pruned trees and the non-empty closed

390
V.L. Selivanov
sets. Note that the well founded trees T (i.e., trees with [T] = ∅) and non-empty
well founded forests of the form F := T \ {ε} are suﬃcient for deﬁning the
h-preorders in the Introduction.
We mention some reducibilities on the k-partitions of Baire space. Since
these are many-one reducibilities, they are closely related to classes of functions
F on Baire space that are closed under composition and contain the identity
function. Any such a class F induces a “reducibility” (i.e., a preorder) ≤F on
kN : A ≤F B, if A = B ◦f for some f ∈F. If F is the class of continuous
functions we obtain Wadge reducibility. If F is the class of Lipschitz functions
we obtain Lipschitz reducibility which is denoted ≤L and plays an important role
in the Wadge theory. Recall that a Lipschitz function (resp. a strong Lipschitz
function) may be deﬁned as a function f on N satisfying f(x)(n) = φ(x[n + 1])
(resp. f(x)(n) = φ(x[n])), for some φ : ω∗→ω. Every strong Lipschitz function
is Lipschitz and every Lipschitz function is continuous, so ≤L is contained in
≤W (but not vice versa). For a Lipschitz function f and a string σ, f(σ) denotes
the obvious initial segment of f(x) for each x ⊒σ.
For any pointclass Γ ⊆P(N), by Γ-function we mean a function f on
N such that f −1(A) ∈Γ for each A ∈Γ. Since the Γ-functions are closed
under composition and contain the identity function, we obtain the correspond-
ing Γ-reducibility ≤Γ. Among such reducibilities are Δ0
α-reducibilities, for each
non-zero countable ordinal α. Note that Δ0
α-reducibility coincides with Σ0
α-
reducibility and Δ0
1-reducibility coincides with Wadge reducibility. We usually
shorten the notation ≤Δ0
α to ≤α, so ≤1 coincides with ≤W . Note that the rela-
tion ≤α is contained in ≤β for all 1 ≤α < β < ω1. The Δ0
α-functions and
Δ0
α-reducibilities were investigated in [1,2,8]. By Jayne-Rogers theorem, the
Δ0
2-functions coincide with the functions f on N for which there is a partition
{An} of N to closed sets An such that f|An is continuous for each n < ω.
Many reducibilities are closely related to inﬁnite games. Relate to any A, B ∈
kN the Lipschitz game GL(A, B) for players I and II as follows. Player I chooses
a natural number x(0), Player II responses with his number y(0), I responses
with x(1), and so on; every player knows all moves of the opponent. After ω
steps, I has produced some x ∈N while II has produced some y ∈N; we say
that II won this round if A(x) = B(y), otherwise I won the round. A winning
strategy for II (resp. for I) in the game GL(A, B) is identiﬁed with a Lipschitz
function f (resp. a strong Lipschitz function g) such that A(x) = B(f(x)) for
each x ∈N (resp. A(g(y)) ̸= B(y) for each y ∈N). It is easy to see that II has a
winning strategy in GL(A, B) iﬀA ≤L B. As it follows from Martin determinacy
theorem, for any Borel A, B the game GL(A, B) is determined, i.e. one of the
players has a winning strategy. Versions of this fact are crucial for applications of
inﬁnite games to Wadge theory. In particular, deﬁne the Wadge game GW (A, B)
as the modiﬁcation of GL(A, B) in which Player II is allowed to pass (i.e., not
choose a number) at any step. Player II wins a given round if he responses with
inﬁnitely many numbers during this round (thus producing some y ∈N) and
A(x) = B(y). Then II has a winning strategy in GW (A, B) iﬀA ≤W B.

Extending Wadge Theory to k-Partitions
391
There are many other ingenious modiﬁcations of GL(A, B) of which we men-
tion one introduced by R. Van Wesep. The backtrack game Gbt(A, B) is the mod-
iﬁcation of GW (A, B) by giving to Player II the additional ability to backtrack
(i.e., delete all his previous moves and start the construction of y from scratch)
at any step. Player II wins a given round if he makes only ﬁnitely many back-
tracks during this round (thus producing again some y ∈N) and A(x) = B(y).
The winning strategies for II in the backtrack games are known as the backtrack
functions. As shown in Theorem 21 of [1], the backtrack functions coincide with
the Δ0
2-functions, so II has a winning strategy in Gbt(A, B) iﬀA ≤2 B.
3
Operations on k-partitions
We use some obvious properties of the ω-ary operation  on SN (S is a non-
empty set) deﬁned by 
n An(i · x) := Ai(x). For any 2 ≤m < ω, deﬁne the
m-ary operation on SN by B0⊕· · ·⊕Bm−1 := 
n An where Amq+r := Br for all
q ≥0, 0 ≤r < m. For any σ ∈ω∗, A ∈SN , deﬁne Aσ ∈SN by Aσ(x) := A(σx).
The next result is a straightforward extension to k-partitions of some prop-
erties of + established in Sect. III.C of [16] for sets.
Proposition 2
(1) If A ≤1 A′ and B ≤1 B′ then A + B ≤1 A′ + B′.
(2) (A + B) + C ≡1 A + (B + C).
(3) (
n An) + B ≡1

n(An + B).
(4) A + B ≡2 A ⊕B.
(5) For any 2 ≤α < ω1, the set Δ0
α(kN ) is closed under +.
The next result is known (see Theorem 7.6 from [11] and references therein).
Proposition 3. The structure (kN ; , ≤1, p0, . . . , pk−1) is a σ-semilattice with
discrete closures which by deﬁnition means that any pi is a closure operation
(i.e., A ≤1 pi(A), A ≤1 B implies pi(A) ≤1 pi(B), and pi(pi(A)) ≤1 pi(A)),
pi(A) ≤1

n Bn implies that pi(A) ≤1 Bn for some n < ω, and pi(A) ≤1 pj(B),
i ̸= j imply that pi(A) ≤1 B.
Relate to any k-partition A the tree T(A) := {σ ∈ω∗| A ≤1 Aσ} which
is known to be closely related to the Wadge theory, in particular the following
relation to the operations p0, . . . , pk−1 is straightforward (for related facts on
sets see e.g. Sect. 2 of [1]):
Proposition 4
(1) If x ∈[T(A)] then pA(x)(A) ≤1 A.
(2) For any i < k, pi(A) ≤1 A iﬀi = A(x) for some x ∈[T(A)].

392
V.L. Selivanov
A k-partition A is α-irreducible (a more precise but more complicated term
would be σ-join-irreducible w.r.t. ≤α, cf. [11]) if there do not exist k-partitions
An <α A, n < ω, with A ≡α

n An. If A is not α-irreducible then we call it
α-reducible. We collect some characterizations of 1-irreducible k-partitions. For
the last one see e.g. [3,7] (where the k-partitions A with the property from item
(8) are called non-self-dual), the others are rather straightforward.
Proposition 5. For any A ∈Δ1
1(kN ), the following are equivalent:
(1) The k-partition A is 1-irreducible.
(2) There is no Δ0
1-partitions {Dn} of N with A ◦dn <1 A where dn is a
continuous retraction from N onto Dn.
(3) There are no 1-irreducible k-partitions An <1 A with A ≡1

n An.
(4) If A ≤1

n Bn then A ≤1 Bn for some n < ω.
(5) The tree T(A) is not well founded.
(6) The tree T(A) is pruned.
(7) There is i < k with pi(A) ≤1 A.
(8) Any continuous function f on N has an A-ﬁxed point (i.e., A(x) = A(f(x))
for some x ∈N).
We state a corollary of (8) which extends to k-partitions a well known prop-
erty of Wadge degrees (in the proof we use the idea of Lemma 29 in [7]).
Proposition 6. Let A, B ∈Δ1
1(kN ) and A be 1-irreducible. Then B ≤W A
implies B ≤L A, A ≤W B implies A ≤L B, and B ≡W A implies B ≡L A.
Proof. The third assertion follows from the ﬁrst two. Let B ≤W A via f. Con-
sider the game Gdiag(A, B) where players I and II construct x, y as in the
Lipschitz game and II wins iﬀA(x) ̸= B(y). Player II does not have a win-
ning strategy in this game since if s were such a strategy then A(x) ̸= B(s(x)) =
Af(s(x)) for all x ∈N, contradicting Proposition 5(8). Thus, player I has a
winning strategy t satisfying ∀yA(t(y)) = B(y). Since t is Lipschitz, B ≤L A.
Let now A ≤W B via f. Then player II does not have a winning strategy in
Gdiag(B, A) since if s were such a strategy then A(x) = B(f(x)) ̸= As(f(x)) for
all x ∈N, contradicting Proposition 5(8). Thus, player I has a winning strategy
t satisfying B(t(y)) = A(y) for all y ∈N. Since t is Lipschitz, A ≤L B.
2
Relate to any 1-irreducible A ∈kN the k-partitions A′ ∈kN and ˜A ∈kN ∪{⊥}
(here ⊥is a new element strictly ≤1-below any k-partition) as follows: A′ = A ◦t
where t : N →[T(A)] is a Lipschitz retraction onto [T(A)] (modulo ≡1, A′ does
not depend on the choice of t), and ˜A = {Aσ | σ ∈∂(T(A))} (modulo ≡1, ˜A does
not depend on the choice of a numbering of ∂(T(A)) if the last set is non-empty,
and if it is empty we set ˜A = ⊥).
Proposition 7. For all 1-irreducible A, B ∈kN we have:
(1) ˜A = ⊥iﬀT(A) = ω∗;
(2) A′ ≤1 A, ˜A <1 A and A ≡1 A′ + ˜A;

Extending Wadge Theory to k-Partitions
393
(3) If A ≡1 B then A′ ≡1 B′ (but, in general, ˜A ̸≡1 ˜B);
(4) T(A′) = ω∗.
Proof. Item (1) obvious. The ﬁrst assertion in (2) is obvious, the second follows
from 1-irreducibility of A, the third is straightforward.
(3) Let A ≡1 B. By symmetry, it suﬃces to show that A◦t ≤1 B◦tB where tB
is a continuous retraction onto [T(B)]. Let f witness A ≤1 B, then f(x) ∈[T(B)]
for each x ∈[T(A)]. (Suppose not, then τ ⊑f(x) for a unique τ ∈∂(T(B)).
By continuity of f, f(σ · N) ⊆τ · N for some σ ⊑x, hence Aσ ≤1 Bτ. Since
σ ∈T(A), we have B ≤1 A ≤1 Aσ ≤1 Bτ, so τ ∈T(B). A contradiction.) Since
tB is a retraction, f ◦t = tB ◦f ◦t, so A ◦t = B ◦f ◦t = (B ◦tB) ◦(f ◦t), hence
A ◦t ≤1 B ◦tB via f ◦t.
(4) Let σ ∈ω∗and B := At(σ). Since t(σ) ∈T(A), A ≡1 B. Note that
T(B) = {τ ∈ω∗| t(σ) · τ ∈T(A)}. Since t is a Lipschitz retraction onto T(A),
B′ ≡1 A′σ. Since A ≡1 B, by (3) we get A′ ≡1 B′. Therefore, A′ ≡1 A′σ,
σ ∈T(A′) and T(A′) = ω∗.
2
The next properties of the operations +, q0, . . . , qk−1 are straightforward:
Proposition 8
(1) For 3 ≤α < ω1, Δ0
α(kN ) is closed under q0, . . . , qk−1.
(2) Structure (kN ; , ≤2, q0, . . . , qk−1) is a σ-semilattice with discrete closures.
(3) For all A ∈kN and i < k, B →qi(A)+B is a closure operator on (kN ; ≤1).
(4) For all A, A1, B, B1 ∈kN and i, j < k, if qi(A) + B ≤1 qj(A1) + B1 and
qi(A) ̸≤1 qj(A1) then qi(A) + B ≤1 B1.
We proceed with some characterizations of 2-irreducible k-partitions.
Proposition 9. For any A ∈Δ1
1(kN ), the following are equivalent:
(1) The k-partition A is 2-irreducible.
(2) There is no Π0
1-partition {Dn} of N with A ◦dn <2 A where dn is a con-
tinuous retraction from N onto Dn.
(3) There are no 2-irreducible k-partitions An <2 A with A ≡2

n An.
(4) If A ≤2

n Bn then A ≤2 Bn for some n < ω.
(5) Any Δ0
2-function f on N has an A-ﬁxed point.
(6) There is B ≡2 A with T(B) = ω∗.
(7) There is i < k with qi(A) ≤1 A.
Proof. The equivalence of (1)–(4) is rather straightforward.
(5)→(1) Let A be 2 reducible, so A ≡2

n An for some An <2 A. We have
to ﬁnd a Δ0
2-function without A-ﬁxed points. Clearly, it suﬃces to ﬁnd such
a function without 
n An-ﬁxed points. For any n < ω, choose n′ < ω with
An′ ̸≤2 An, then Player II does not win Gbt(An′, An), hence Player I wins via a
strategy sn, so An′(sn(y)) ̸= An(y) for each y ∈N. Deﬁne a Lipschitz function
f by f(n · y) := n′ · sn(y). Then f has no 
n An-ﬁxed points.

394
V.L. Selivanov
(2)→(5) Suppose for a contradiction that A satisﬁes (2) but some Δ0
2-
function has no A-ﬁxed points. Then the following version of Claim 5.3.1 in [8]
holds: for any closed set D and any continuous retraction d onto D, if A ≡2 A◦d
then there is a Δ0
2-function g : N →D without (A ◦d)-ﬁxed points. Indeed,
since A ≡2 A◦d, there is a Δ0
2-function f : N →N without (A◦d)-ﬁxed points.
Since d is a retraction, we can take g = d ◦f. With this version at hand, we can
repeat (with A ∩D replaced by A ◦d) the proof of Theorem 5.3 in [8] (which is
based on the proof of Theorem 16 in [2]) and obtain a contradiction.
(5)→(6) Consider the representation A ≡1 A′ + ˜A from Proposition 7. By
this proposition, A ≡2 A′ ⊕˜A. Repeating the proof of Proposition 6 (with ≤W
replaced by ≤2) we obtain that if any Δ0
2-function has an A-ﬁxed point then the
Δ0
2-degree of A coincides with the Lipshitz degree of A. Therefore, A ≡1 A′ ⊕˜A.
By (5), 2-irreducibility implies 1-irreducibility. Thus, A is 1-irreducible, hence
A ≤1 A′ or A ≤1 ˜A. But A ̸≤1 ˜A, hence A ≡1 A′ and we can take B = A′.
(6)→(7). It suﬃces to show that if T(A) = ω∗then qi(A) ≤1 A for some
i ∈rng(A). By Proposition 6, for any σ ∈ω∗there is a strong Lipschitz function
fσ with A = Aσ ◦fσ. To simplify notation a bit, we consider the particular case
rng(A) = {0, 1, 2}, it will be clear that the proof works for the general case.
Towards a contradiction, suppose that qi(A) ̸≤1 A for each i < 3, then there are
strong Lipschitz functions si such that qi(A)(si(z)) ̸= A(z) for all i < 3, z ∈N.
We construct y ∈N as follows.
Let x0 be the ﬁrst number in the sequence s0(y) (it does not depend on y
because s0 is strong Lipschitz). If x0 > 0, we set y(0) = x0 −1, ﬁnd the second
number x1 in the sequence s0(y) and set y(1) = x1−1 if x1 > 0, and continue this
process until we ﬁnd the ﬁrst zero in s0(y). Such a zero exists because otherwise
we would get y = s0(y)−, hence A(y) = A(s0(y)−) = q0(A)(s0(y)), contradicting
the property of s0. Thus, we have τ00 ⊑s0(y) for a unique string τ0 without
zeroes. We proceed to construct y by concatenating the consecutive numbers of
the sequence fσ0((x0 −1)(x1 −1) · · · ) to σ0 := τ −
0 where this time x0, x1, . . . are
the consecutive non-zero numbers in the sequence s1(y); we continue until the
ﬁrst 0 in the last sequence is discovered. This 0 exists because otherwise we get
y = σ0fσ0(s1(y)−), hence A(y) = Aσ0fσ0(s1(y)−) = A(s1(y)−) = q1(A)(s1(y)),
contradicting the property of s1. Thus, we have τ10 ⊑s1(y) for a unique string
τ1 without zeroes. We proceed to construct y by concatenating the consecutive
numbers of the sequence fσ1((x0 −1)(x1 −1) · · · ) to σ1 := σ0fσ0(τ −
1 ) where
this time x0, x1, . . . are the consecutive non-zero numbers in the sequence s2(y).
Again we will ﬁnd the ﬁrst zero in s2(y) and the corresponding τ2 and σ2. Note
that σ0 < σ1 < σ2 because we work with the strong Lipschitz functions.
At this point, we proceed to construct y by concatenating the consecutive
numbers of the sequence fσ2((x0−1)(x1−1) · · · ) to σ2 where this time x0, x1, . . .
are the consecutive non-zero numbers in the unique sequence z0 ∈N satisfying
s0(y) = τ00z0; we continue until the ﬁrst 0 in the sequence z0 is discovered. This
0 exists because otherwise we get y = σ2fσ2(z−
0 ), hence A(y) = Aσ2fσ2(z−
0 ) =
A(z−
0 ) = qi(A)(s0(y)), contradicting the property of s0. Next we work in the
same way with s1(y) = τ10z1, s2(y) = τ20z2, and so on.

Extending Wadge Theory to k-Partitions
395
By the construction, we obtain an inﬁnite sequence σ0 < σ1 < σ2 < · · ·
with y = 
n σn, and any of s0(y), s1(y), s2(y) has inﬁnitely many zeroes. Let
i := A(y), i < 3. By the deﬁnition of qi(A) we have qi(A)(si(y)) = i = A(y),
contradicting the property of si.
(7)→(6) Take B = qi(A). By the deﬁnition of qi(A), T(B) = ω∗.
(6)→(4) Choose B ≡2 A with T(B) = ω∗. First we show that B ≤2 C
implies B ≤1 C. Let B ≤2 C via f such that for some Π0
1-partition {Dn} of N
the function f is continuous on Dn for each n < ω. By Baire category theorem,
σ · N ⊆Dn for some n. Thus, Bσ ≤1 C via λx.f(σx). Since σ ∈T(B), B ≤1 Bσ
and therefore B ≤1 C.
Let now A ≤2

n Bn, hence B ≤2

n Bn and therefore B ≤1

n Bn.
Since T(B) = ω∗, B is 1-irreducible by Proposition 5(6), hence B ≤1 Bn for
some n < ω. Therefore, A ≤2 Bn and A is 2-irreducible.
2
4
Generating Degree Structures
The next proposition coincides with item (1) of Theorem 1.
Proposition 10. The quotient-poset of (Δ0
2(kN ); ≤W ) is generated from the
minimal degrees {0}, . . . , {k −1} by the operations , p0, . . . , pk−1 (and also
by the operations , +).
Proof. Let S (resp. S1) be the subalgebra of (kN ; , p0, . . . , pk−1) (resp. of
(kN ; , +)) generated by the set {0, . . . , k −1}, then S ⊆S1 ⊆Δ0
2(kN ) by
Proposition 2(5). It remains to show that any A ∈Δ0
2(kN ) is Wadge equivalent
to some B ∈S. This is checked by the rank rk(A) of A in the well founded
preorder (Δ0
2(kN ); ≤W ). If rk(A) = 0 then A ∈{0, . . . , k −1} and there is noth-
ing to prove, so let A be non-constant. If A is 1-reducible then A ≡1

n An
for some An <1 A. By induction, An ≡1 Bn for some Bn ∈S, n ∈ω. Then
A ≡1

n Bn ∈S, as desired.
Finally, let A be 1-irreducible. Consider the representation A ≡1 A′ + ˜A from
Proposition 7. Then A′ is constant. (Otherwise, i, j ∈rng(A′) for some distinct
i, j, hence pi(A) ≡1 pj(A) ≡1 A by Proposition 7(4). Since the Wadge degrees of
Δ0
2-sets are generated by , p0, p1 from {∅}, {N} (see Sect. III.C of [16]), any
such degree is Wadge reducible to Ai, hence A ̸∈Δ0
2(kN ). A contradiction.) If
˜A = ⊥then A ≡1 A′ is constant and we are done. Finally, let ˜A ̸= ⊥. Since
˜A <1 A, by induction ˜A ≡1 B for some B ∈S. Then A ≡1 pi(B) ∈S for some
i < k, as desired.
2
The next proposition is interesting in its own right.
Proposition 11. The quotient-poset of (Δ0
3(kN ); ≤2) is generated from the
minimal degrees {0}, . . . , {k −1} by the operations , q0, . . . , qk−1.
Proof. Let S be the subalgebra of (kN ; , q0, . . . , qk−1) generated by the set
{0, . . . , k −1}, then S ⊆Δ0
3(kN ) by Proposition 8(1). It remains to show

396
V.L. Selivanov
that any A ∈Δ0
3(kN ) is 2-equivalent to some B ∈S. This is checked by the
rank rk(A) of A in the well founded preorder (Δ0
3(kN ); ≤2). If rk(A) = 0 then
A ∈{0, . . . , k −1} and there is nothing to prove, so let A be non-constant. If A
is 2-reducible then A ≡2

n An for some An <2 A. By induction, An ≡2 Bn for
some Bn ∈S, n ∈ω. Then A ≡2

n Bn ∈S, as desired.
Finally, let A be 2-irreducible. By Proposition 9(7), qi(A) ≡2 A for some
i < k. Such i is in fact unique. (Otherwise, qi(A) ≡1 qj(A) ≡1 A for some distinct
i, j. Since any Δ0
3-set is Wadge reducible to a set generated by , q0 = ♯, q1 = ♭
from {∅}, {N} by Sect. III.E of [16], any Δ0
3-set is Wadge reducible to Ai, hence
A ̸∈Δ0
3(kN ). A contradiction.) Moreover, A ≡2 qi( ˜A) for some ˜A <2 A as it
follows from the structure of the diﬀerence hierarchy of k-partitions over Σ0
2 [14]
(A will be Wadge complete in a non-self-dual level of this hierarchy similarly
to Sect. 7 of [11], with pi replaced by qi; in fact, the set of Δ0
2-degrees strictly
below A is at most countable, hence we can take ˜A as the disjoint union of all
such degrees, then the Δ0
2-degree of ˜A is the largest Δ0
2-degree strictly below
A). Since ˜A <2 A, by induction ˜A ≡2 B for some B ∈S. Then A ≡2 qi(B) ∈S,
as desired.
2
The next proposition coincides with item (2) of Theorem 1.
Proposition 12. The quotient-poset of (Δ0
3(kN ); ≤W ) is generated from the
minimal degrees {0},. . . ,{k −1} by the operations , +, q0, . . . , qk−1.
Proof. Let S be the subalgebra of (kN ; , +, q0, . . . , qk−1) generated by the set
{0, . . . , k −1}, then S ⊆Δ0
3(kN ) by Propositions 2(5) and 8. It remains to show
that any A ∈Δ0
3(kN ) is Wadge equivalent to some B ∈S. This is checked by the
rank rk(A) of A in the well founded preorder (Δ0
3(kN ); ≤W ). If rk(A) = 0 then
A ∈{0, . . . , k −1} and there is nothing to prove, so let A be non-constant. If A
is 1-reducible then A ≡1

n An for some An <1 A. By induction, An ≡1 Bn for
some Bn ∈S, n ∈ω. Then A ≡1

n Bn ∈S, as desired.
Finally, let A be 1-irreducible. Consider the representation A ≡1 A′ + ˜A from
Proposition 7. Since T(A′) = ω∗, A′ is 2-irreducible by Proposition 9(6). By
Proposition 11, A′ ≡2 C for some C ∈S, hence also A′ ≡1 C by the proof
of (6)→(4) in Proposition 9. If ˜A = ⊥then A ≡1 C ∈S and we are done.
Finally, let ˜A ̸= ⊥. Since ˜A <1 A, by induction ˜A ≡1 B for some B ∈S. Then
A ≡1 C + B ∈S, as desired.
2
5
Operations on Labeled Forests
Let us brieﬂy recall from [12–14] some operations of labeled forests and col-
lect their properties used in the sequel (all these operations respect the h-
equivalence). Recall that our labeled trees (T; c) in Tk (resp. in T 
Tk) consist
of a well founded tree T and a labeling c : T →k (resp. c : T →Tk). The non-
empty labeled forests in F 
Tk are obtained from such trees by removing the root
ε. The ω-ary operation  of disjoint union on F 
Tk is deﬁned in the obvious way.

Extending Wadge Theory to k-Partitions
397
For any i < k and F ∈F 
Tk, let pi(F) be the tree in T 
Tk obtained from F by
adjoining the empty string labeled by i. Note that the set Fk is closed under the
operation pi (we may think that Fk ⊆F 
Tk by identifying labels i < k with the
singleton tree i carrying the label i). Deﬁne the binary operation + on F 
Tk as
follows: F +G is obtained by adjoining a copy of G below any leaf of F. One easily
checks that i + F ≡h pi(F), F ≤h F + G, G ≤h F + G, F ≤h F1 →F + G ≤h
F1 + G, G ≤h G1 →F + G ≤h F + G1, (F + G) + H ≡h F + (G + H). Note that
the set 
Fk is closed under the operation +. Deﬁne the function s : Tk →T 
Tk as
follows: s(F) is the singleton tree carrying the label F. Note that s(i) = i for
each i < k, and T ≤h S iﬀs(T) ≤h s(S), for all S, T ∈Tk. One easily checks the
following properties:
Proposition 13
(1) ( Fk; , ≤h, p0, . . . , pk−1) and ( F 
Tk; , ≤h, p0, . . . , pk−1) are σ-semilattices
with discrete closures.
(2) For any T ∈Tk, F →s(T) + F is a closure operator on F 
Tk.
(3) For all T, T1 ∈Tk and F, F1 ∈F 
Tk, if s(T) + F ≤h s(T1) + F1 and T ̸≤h T1
then s(T) + F ≤h F1.
6
Characterizing Degree Structures
The next proposition coincides with item (1) of Theorem 2.
Proposition 14. The quotient-posets of (Δ0
2(kN ); ≤W ) and of ( Fk; ≤h) are iso-
morphic.
Proof. Let (T; c) ∈Tk. Relate to any node σ ∈T the k-partition μT (σ) by
induction on the rank rk(σ) of σ in (T; ⊒) as follows: if rk(σ) = 0, i.e. σ is a leaf
of T then μT (σ) := i where i = c(σ); otherwise, μT (σ) := pi({μT (σn) | n <
ω, σn ∈T}).
Now we deﬁne a function μ : Tk →kN by μ(T) := μT (ε). Then T ≤h S iﬀ
μ(T) ≤W μ(S), for all T, S ∈Tk. This is checked using Propositions 13(1) and 3
by induction on (rkT (ε), rkS(ε)) in the lexicographic order of pairs of countable
ordinals (for details see the proof of Theorem 5.1 in [10], although the induction
there was not on the tree ranks of T, S but rather on their ranks in the well
poset (Tk; ≤h)).
Next we extend μ to Fk by μ(F) := {μT (n) | n < ω, (n) ∈T} where
T := {ε} ∪F. Again, it is easy to see that F ≤h G iﬀμ(F) ≤W μ(G), for all
F, G ∈Fk.
Repeating the proof of Proposition 10, we check by induction on rk(A) that
for each A ∈Δ0
2(kN ) there is F ∈Fk with μ(F) ≡W A. Thus, the function μ
induces the desired isomorphism of quotient-posets.
2
The next proposition is interesting in its own right.

398
V.L. Selivanov
Proposition 15. The quotient-posets of (Δ0
3(kN ); ≤2) and of ( Fk; ≤h) are iso-
morphic.
Proof. The proof is a minor modiﬁcation of the previous one. For any (T; c) ∈Tk,
deﬁne νT : T →kN as follows: if rk(σ) = 0 then νT (σ) := i where i = c(σ),
otherwise νT (σ) := qi({νT (σn) | n < ω, σn ∈T}). Deﬁne ν : Tk →kN by
ν(T) := νT (ε). Then T ≤h S iﬀν(T) ≤2 ν(S), for all T, S ∈Tk, because the
operations qi have the same algebraic properties as pi. Finally, extend ν to Fk
by ν(F) := {νT (n) | n < ω, (n) ∈T} where T := {ε} ∪F. Again, it is easy to
see that F ≤h G iﬀν(F) ≤2 ν(G), for all F, G ∈Fk.
Repeating the proof of Proposition 11, we check by induction on rk(A) that
for each A ∈Δ0
3(kN ) there is F ∈Fk with ν(F) ≡2 A. Thus, the function ν
induces the desired isomorphism of quotient-posets.
2
The next proposition coincides with item (2) of Theorem 2.
Proposition 16. The quotient-posets of (Δ0
3(kN ); ≤W ) and of ( F 
Tk; ≤h) are
isomorphic.
Proof. Let (T; c) ∈T 
Tk. Relate to any node σ ∈T the k-partition ρT (σ) by
induction on the rank rk(σ) of σ in (T; ⊒) as follows: if rk(σ) = 0 then ρT (σ) :=
ν(Q) where Q = c(σ) ∈Tk; otherwise, ρT (σ) := ν(Q) + ({ρT (σn) | n <
ω, σn ∈T}). Now deﬁne a function ρ : T 
Tk →kN by ρ(T) := ρT (ε). Then
T ≤h S iﬀρ(T) ≤W ρ(S), for all T, S ∈T 
Tk. This is checked using Propositions
13(2,3) and 2 by induction on (rkT (ε), rkS(ε)). Next we extend ρ to F 
Tk by
ρ(F) := {ρT (n) | n < ω, (n) ∈T} where T := {ε} ∪F. Again, it is easy to see
that F ≤h G iﬀρ(F) ≤W ρ(G), for all F, G ∈F 
Tk.
Repeating the proof of Proposition 12, we check by induction on rk(A) that
for each A ∈Δ0
3(kN ) there is F ∈F 
Tk with ρ(F) ≡W A. Thus, the function ρ
induces the desired isomorphism of quotient-posets.
2
References
1. Andretta, A.: More on Wadge determinacy. Ann. Pure Appl. Logic 144(1–3), 2–32
(2006)
2. Andretta, A., Martin, D.A.: Borel-Wadge degrees. Fund. Math. 177(2), 175–192
(2003)
3. Block, A.C.: Operations on a Wadge-type hierarchy of ordinal-valued functions.
Masters thesis, Universiteit van Amsterdam (2014)
4. van Engelen, F., Miller, A., Steel, J.: Rigid Borel sets and better quasiorder theory.
Contemp. Math. 65, 199–222 (1987)
5. Hertling, P.: Topologische Komplexit¨atsgrade von Funktionen mit endlichem Bild.
Informatik-Berichte 152, Fernuniversit¨at Hagen (1993)
6. Kechris, A.S.: Classical Descriptive Set Theory. Springer, New York (1995)
7. Kihara, T., Montalban, A.: The uniform Martin’s conjecture for many-one degrees.
arXiv:1608.05065v1 [Math.LO], 17 August 2016

Extending Wadge Theory to k-Partitions
399
8. Motto Ros, L.: Borel-amenable reducibilities for sets of reals. J. Symbolic Logic
74(1), 27–49 (2009)
9. Selivanov, V.L.: Hierarchies of hyperarithmetical sets and functions. Algebra Logic
22, 473–491 (1983)
10. Selivanov, V.L.: The quotient algebra of labeled forests modulo h-equivalence. Alge-
bra Logic 46, 120–133 (2007)
11. Selivanov, V.L.: Hierarchies of Δ0
2-measurable k-partitions. Math. Logic Q. 53,
446–461 (2007)
12. Selivanov, V.: A ﬁne hierarchy of ω-regular k-partitions. In: L¨owe, B., Normann,
D., Soskov, I., Soskova, A. (eds.) CiE 2011. LNCS, vol. 6735, pp. 260–269. Springer,
Heidelberg (2011). doi:10.1007/978-3-642-21875-0 28
13. Selivanov, V.L.: Fine hierarchies via Priestley duality. Ann. Pure Appl. Logic 163,
1075–1107 (2012)
14. Selivanov, V.L.: Towards a descriptive theory of cb0-spaces. Mathematical Struc-
tures in Computer Science, September 2014. doi:10.1017/S0960129516000177. Ear-
lier version in: arXiv:1406.3942v1 [Math.GN], 16 June 2016
15. Van Wesep, R.: Wadge degrees and descriptive set theory. In: Kechris, A.S.,
Moschovakis, Y.N. (eds.) Cabal Seminar 76–77. LNM, vol. 689, pp. 151–170.
Springer, Heidelberg (1978). doi:10.1007/BFb0069298
16. Wadge, W.: Reducibility and determinateness in the Baire space. Ph.D. thesis,
University of California, Berkely (1984)

Erratum to: Counting Substrate Cycles
in Topologically Restricted Metabolic
Networks
Robert D. Barish(&) and Akira Suyama
Graduate School of Arts and Sciences, University of Tokyo,
Meguro-ku Komaba 3-8-1, Tokyo 153-8902, Japan
rbarish@genta.c.u-tokyo.ac.jp
Erratum to:
Chapter “Counting Substrate Cycles in Topologically
Restricted Metabolic Networks” in: J. Kari et al. (Eds.),
Unveiling Dynamics and Complexity, LNCS 10307,
DOI: 10.1007/978-3-319-58741-7_14
The original version of the book was inadvertently published with the terms “undir-
ected” and “graph” in full capitalization in Chapter 14. The erratum chapter and the
book has been updated with the change.
The updated online version of this chapter can be found at
http://dx.doi.org/10.1007/978-3-319-58741-7_14
© Springer International Publishing AG 2017
J. Kari et al. (Eds.): CiE 2017, LNCS 10307, p. E1, 2017.
DOI: 10.1007/978-3-319-58741-7_37

Author Index
Arnold, Stefan
119
Barish, Robert D.
129
Bazhenov, Nikolay A.
152
Bazhenov, Nikolay
141
Belazzougui, Djamal
162
Carl, Merlin
175, 187, 198
Carlucci, Lorenzo
210
Cunial, Fabio
162
Defrain, Oscar
221
Delacourt, Martin
234
Della Vedova, Gianluca
3
Durand, Bruno
175, 221
Gagie, Travis
162
Galeotti, Lorenzo
246
Genova, Daniela
258
Golovach, Petr A.
270
Hernández-Espinosa, Alberto
14
Hernández-Quiroz, Francisco
14
Holub, Štěpán
24
Hoogeboom, Hendrik Jan
258
Johnson, Matthew
270
Jones, Cliff B.
32
Kennedy, Juliette
42
Klau, Gunnar W.
50
Kołodziejczyk, Leszek Aleksander
210
Korovina, Margarita
64, 282
Kudinov, Oleg
64, 282
Laﬁtte, Grégory
175, 221
Lehtinen, Karoliina
292
Lepore, Francesco
210
Löwe, Benedikt
187
Lutz, Neil
304
Marschall, Tobias
50
Martin, Barnaby
270
Melnikov, Alexander G.
77
Miller, Russell
88
Monteil, Thierry
315
Nobrega, Hugo
246, 327
Novikov, Gleb
338
Ollinger, Nicolas
234
Ouazzani, Sabrina
175
Patterson, Murray
3
Paulusma, Daniël
270
Pauly, Arno
327
Petrakis, Iosif
351
Prezza, Nicola
162
Quickert, Sandra
292
Rafﬁnot, Mathieu
162
Rampersad, Narad
98
Rin, Benjamin G.
187
Rizzi, Raffaella
3
Sadowski, Zenon
364
Salo, Ville
375
Schlicht, Philipp
198
Selivanov, Victor L.
387
Shen, Alexander
101
Soto, Mauricio
3
Stewart, Anthony
270
Stull, D.M.
304
Suyama, Akira
129
Torán, Jacobo
119
Törmä, Ilkka
375
Veroff, Robert
24
Visconti, Ivan
112
Yamaleev, Mars M.
152
Zdanowski, Konrad
210
Zenil, Héctor
14

