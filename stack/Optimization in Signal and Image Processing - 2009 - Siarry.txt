Optimization in Signal and Image Processing 

Optimization in Signal 
and Image Processing 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Edited by 
Patrick Siarry 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 

 
 
 
 
 
 
 
First published in France in 2007 by Hermes Science/Lavoisier entitled Optimisation en traitement du 
signal et de l’image © LAVOISIER, 2007 
First published in Great Britain and the United States in 2009 by ISTE Ltd and John Wiley & Sons, Inc. 
 
Apart from any fair dealing for the purposes of research or private study, or criticism or review, as 
permitted under the Copyright, Designs and Patents Act 1988, this publication may only be reproduced, 
stored or transmitted, in any form or by any means, with the prior permission in writing of the publishers, 
or in the case of reprographic reproduction in accordance with the terms and licenses issued by the CLA. 
Enquiries concerning reproduction outside these terms should be sent to the publishers at the 
undermentioned address: 
 
ISTE Ltd  
John Wiley & Sons, Inc.  
27-37 St George’s Road  
111 River Street 
London SW 19 4EU  
Hoboken, NJ 07030 
UK  
USA  
www.iste.co.uk  
www.wiley.com 
 
© ISTE Ltd, 2009 
 
The rights of Patrick Siarry to be identified as the author of this work have been asserted by him in 
accordance with the Copyright, Designs and Patents Act 1988. 
Library of Congress Cataloging-in-Publication Data 
 
Optimisation en traitement du signal et de l'image. English. 
  Optimization in signal and image processing / edited by Patrick Siarry. 
       p. cm. 
  Includes bibliographical references and index. 
  ISBN 978-1-84821-044-8 
 1.  Signal processing. 2.  Image processing.  I. Siarry, Patrick. II. Title.  
  TK5102.9.O6813 2009 
  621.382'2--dc22 
           2009017635 
 
British Library Cataloguing-in-Publication Data 
A CIP record for this book is available from the British Library  
ISBN: 978-1-84821-044-8 
Printed and bound in Great Britain by CPI/Antony Rowe, Chippenham and Eastbourne. 
 

Table of Contents 
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  xiii 
Chapter 1. Modeling and Optimization in Image Analysis . . . . . . . . . .  
 1 
Jean LOUCHET 
1.1. Modeling at the source of image analysis and synthesis . . . . . . . . .  
 1 
1.2. From image synthesis to analysis . . . . . . . . . . . . . . . . . . . . . .  
 2 
1.3. Scene geometric modeling and image synthesis . . . . . . . . . . . . . .  
 3 
1.4. Direct model inversion and the Hough transform . . . . . . . . . . . . .  
 4 
1.4.1. The deterministic Hough transform . . . . . . . . . . . . . . . . . . .  
 4 
1.4.2. Stochastic exploration of parameters: evolutionary Hough . . . . .  
 5 
1.4.3. Examples of generalization . . . . . . . . . . . . . . . . . . . . . . . .  
 7 
1.5. Optimization and physical modeling . . . . . . . . . . . . . . . . . . . .  
 9 
1.5.1. Photometric modeling . . . . . . . . . . . . . . . . . . . . . . . . . . .  
 9 
1.5.2. Motion modeling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   10 
1.6. Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   12 
1.7. Acknowledgements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   13 
1.8. Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   13 
Chapter 2. Artificial Evolution and the Parisian Approach. Applications 
in the Processing of Signals and Images . . . . . . . . . . . . . . . . . . . . . .   15 
Pierre COLLET and Jean LOUCHET 
2.1. Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   15 
2.2. The Parisian approach for evolutionary algorithms . . . . . . . . . . . .   15 
2.3. Applying the Parisian approach to inverse IFS problems . . . . . . . .   17 
2.3.1. Choosing individuals for the evaluation process . . . . . . . . . . .   18 
2.3.2. Retribution of individuals . . . . . . . . . . . . . . . . . . . . . . . . .   18 

vi     Optimization in Signal and Image Processing 
 
2.4. Results obtained on the inverse problems of IFS . . . . . . . . . . . . .   20 
2.5. Conclusion on the usage of the Parisian approach for inverse IFS 
problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   22 
2.6. Collective representation: the Parisian approach and  
the Fly algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   23 
2.6.1. The principles . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   23 
2.6.2. Results on real images . . . . . . . . . . . . . . . . . . . . . . . . . . .   27 
2.6.3. Application to robotics: fly-based robot planning . . . . . . . . . .   30 
2.6.4. Sensor fusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   34 
2.6.5. Artificial evolution and real time . . . . . . . . . . . . . . . . . . . .   37 
2.6.6. Conclusion about the fly algorithm . . . . . . . . . . . . . . . . . . .   39 
2.7. Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   40 
2.8. Acknowledgements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   41 
2.9.Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   41 
Chapter 3. Wavelets and Fractals for  Signal and Image Analysis. . . . . .  
45 
Abdeldjalil OUAHABI and Djedjiga AIT AOUIT 
3.1. Introduction. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  
45 
3.2. Some general points on fractals . . . . . . . . . . . . . . . . . . . . . . . .  
46 
3.2.1. Fractals and paradox . . . . . . . . . . . . . . . . . . . . . . . . . . . .  
46 
3.2.2. Fractal sets and self-similarity . . . . . . . . . . . . . . . . . . . . . .  
47 
3.2.3. Fractal dimension. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  
49 
3.3. Multifractal analysis of signals . . . . . . . . . . . . . . . . . . . . . . . .  
54 
3.3.1. Regularity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  
54 
3.3.2. Multifractal spectrum . . . . . . . . . . . . . . . . . . . . . . . . . . .  
58 
3.4. Distribution of singularities based on wavelets. . . . . . . . . . . . . . .  
60 
3.4.1. Qualitative approach . . . . . . . . . . . . . . . . . . . . . . . . . . . .  
60 
3.4.2. A rough guide to the world of wavelet . . . . . . . . . . . . . . . . .  
60 
3.4.3. Wavelet Transform Modulus Maxima (WTMM) method . . . . . .  
63 
3.4.4. Spectrum of singularities and wavelets . . . . . . . . . . . . . . . . .  
66 
3.4.5. WTMM and some didactic signals. . . . . . . . . . . . . . . . . . . .  
68 
3.5. Experiments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  
70 
3.5.1. Fractal analysis of structures in images: applications in  
microbiology . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  
70 
3.5.2. Using WTMM for the classification of textures – application in  
the field of medical imagery . . . . . . . . . . . . . . . . . . . . . . . . . . .  
72 
3.6. Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  
76 
3.7. Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  
76 

Table of Contents     vii 
Chapter 4. Information Criteria: Examples of Applications in Signal and Image 
Processing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  
79 
Christian OLIVIER and Olivier ALATA 
4.1. Introduction and context . . . . . . . . . . . . . . . . . . . . . . . . . . . .  
79 
4.2. Overview of the different criteria . . . . . . . . . . . . . . . . . . . . . . .  
81 
4.3. The case of auto-regressive (AR) models . . . . . . . . . . . . . . . . . .  
83 
4.3.1. Origin, written form and performance of different criteria  
on simulated examples. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  
84 
4.3.2. AR and the segmentation of images: a first approach. . . . . . . . .  
87 
4.3.3. Extension to 2D AR and application to the  
modeling of textures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  
89 
4.3.4. AR and the segmentation of images: second approach  
using 2D AR . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  
92 
4.4. Applying the process to unsupervised clustering. . . . . . . . . . . . . .  
95 
4.5. Law approximation with the help of histograms . . . . . . . . . . . . . .  
98 
4.5.1. Theoretical aspects . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  
98 
4.5.2. Two applications used for encoding images . . . . . . . . . . . . . .  
99 
4.6. Other applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  103 
4.6.1. Estimation of the order of Markov models . . . . . . . . . . . . . . .  103 
4.6.2. Data fusion. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  104 
4.7. Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  106 
4.8. Appendix . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  106 
4.8.1. Kullback (-Leibler) information . . . . . . . . . . . . . . . . . . . . . .  106 
4.8.2. Nishii’s convergence criteria . . . . . . . . . . . . . . . . . . . . . . . .  107 
4.9. Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  107 
Chapter 5. Quadratic Programming and Machine Learning – Large Scale 
Problems and Sparsity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   111 
Gaëlle LOOSLI, Stéphane CANU 
5.1. Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   111 
5.2. Learning processes and optimization . . . . . . . . . . . . . . . . . . . .   112 
5.2.1. General framework . . . . . . . . . . . . . . . . . . . . . . . . . . . .   112 
5.2.2. Functional framework . . . . . . . . . . . . . . . . . . . . . . . . . . .   114 
5.2.3. Cost and regularization . . . . . . . . . . . . . . . . . . . . . . . . . .   115 
5.2.4. The aims of realistic learning processes . . . . . . . . . . . . . . . .   116 
5.3. From learning methods to quadratic programming . . . . . . . . . . . .   117 
5.3.1. Primal and dual forms . . . . . . . . . . . . . . . . . . . . . . . . . . .   117 
5.4. Methods and resolution . . . . . . . . . . . . . . . . . . . . . . . . . . . .   119 
5.4.1. Properties to be used: sparsity . . . . . . . . . . . . . . . . . . . . . .   120 
5.4.2. Tools to be used . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  120 
5.4.3. Structures of resolution algorithms . . . . . . . . . . . . . . . . . . .   121 
5.4.4. Decomposition methods . . . . . . . . . . . . . . . . . . . . . . . . .   121 

viii     Optimization in Signal and Image Processing 
 
5.4.5. Solving quadratic problems . . . . . . . . . . . . . . . . . . . . . . .   123 
5.4.6. Online and non-optimized methods . . . . . . . . . . . . . . . . . . .   126 
5.4.7. Comparisons . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   127 
5.5. Experiments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   128 
5.5.1. Comparison of empirical complexity . . . . . . . . . . . . . . . . . .   128 
5.5.2. Very large databases . . . . . . . . . . . . . . . . . . . . . . . . . . . .   130 
5.6. Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   132 
5.7. Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   133 
Chapter 6. Probabilistic Modeling of Policies and Application to Optimal 
Sensor Management . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   137 
Frédéric DAMBREVILLE, Francis CELESTE and Cécile SIMONIN 
6.1. Continuum, a path toward oblivion . . . . . . . . . . . . . . . . . . . . .   137 
6.2. The cross-entropy (CE) method . . . . . . . . . . . . . . . . . . . . . . .   138 
6.2.1. Probability of rare events . . . . . . . . . . . . . . . . . . . . . . . . .   139 
6.2.2.CE applied to optimization . . . . . . . . . . . . . . . . . . . . . . . .   143 
6.3. Examples of implementation of CE for surveillance . . . . . . . . . . .   146 
6.3.1. Introducing the problem . . . . . . . . . . . . . . . . . . . . . . . . .   147 
6.3.2. Optimizing the distribution of resources . . . . . . . . . . . . . . . .   149 
6.3.3. Allocating sensors to zones . . . . . . . . . . . . . . . . . . . . . . . .   150 
6.3.4. Implementation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   151 
6.4. Example of implementation of CE for exploration . . . . . . . . . . . .   153 
6.4.1. Definition of the problem . . . . . . . . . . . . . . . . . . . . . . . . .   153 
6.4.2. Applying the CE . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  156 
6.4.3. Analyzing a simple example . . . . . . . . . . . . . . . . . . . . . . .   157 
6.5. Optimal control under partial observation . . . . . . . . . . . . . . . . .   158 
6.5.1. Decision-making in partially observed environments . . . . . . . .   159 
6.5.2. Implementing CE . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   162 
6.5.3. Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   163 
6.6. Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   166 
6.7. Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   166 
Chapter 7. Optimizing Emissions for Tracking and Pursuit of Mobile 
Targets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   169 
Jean-Pierre LE CADRE 
7.1. Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   169 
7.2. Elementary modeling of the problem (deterministic case) . . . . . . . .   170 
7.2.1. Estimability measurement of the problem . . . . . . . . . . . . . . .   170 
7.2.2. Framework for computing exterior products . . . . . . . . . . . . .   173 
7.3. Application to the optimization of emissions (deterministic case) . . .   175 
7.3.1. The case of a maneuvering target . . . . . . . . . . . . . . . . . . . .   180 
7.4. The case of a target with a Markov trajectory . . . . . . . . . . . . . . . .   181 

Table of Contents     ix 
7.5. Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   189 
7.6. Appendix: monotonous functional matrices . . . . . . . . . . . . . . . .   189 
7.7. Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   192 
Chapter 8. Bayesian Inference and Markov Models . . . . . . . . . . . . . .   195 
Christophe COLLET 
8.1. Introduction and application framework . . . . . . . . . . . . . . . . . .   195 
8.2. Detection, segmentation and classification . . . . . . . . . . . . . . . . .   196 
8.3. General modeling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   199 
8.3.1. Markov modeling . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   199 
8.3.2. Bayesian inference . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   200 
8.4. Segmentation using the causal-in-scale Markov model . . . . . . . . . .   201 
8.5. Segmentation into three classes . . . . . . . . . . . . . . . . . . . . . . . .   203 
8.6. The classification of objects . . . . . . . . . . . . . . . . . . . . . . . . . .   206 
8.7. The classification of seabeds . . . . . . . . . . . . . . . . . . . . . . . . .   212 
8.8. Conclusion and perspectives . . . . . . . . . . . . . . . . . . . . . . . . .   214 
8.9. Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   215 
Chapter 9. The Use of Hidden Markov Models for Image Recognition: 
Learning with Artificial Ants, Genetic Algorithms and Particle Swarm 
Optimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   219 
Sébastien AUPETIT, Nicolas MONMARCHÉ and Mohamed SLIMANE 
9.1. Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   219 
9.2. Hidden Markov models (HMMs) . . . . . . . . . . . . . . . . . . . . . .   220 
9.2.1. Definition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   220 
9.2.2. The criteria used in programming hidden Markov models . . . . .   221 
9.3. Using metaheuristics to learn HMMs . . . . . . . . . . . . . . . . . . . .   223 
9.3.1. The different types of solution spaces used for the  
training of HMMs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  223 
9.3.2. The metaheuristics used for the training of the HMMs . . . . . . .   225 
9.4. Description, parameter setting and evaluation of the six approaches that 
are used to train HMMs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   226 
9.4.1. Genetic algorithms . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   226 
9.4.2. The API algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   228 
9.4.3. Particle swarm optimization . . . . . . . . . . . . . . . . . . . . . . .   230 
9.4.4. A behavioral comparison of the metaheuristics . . . . . . . . . . . .   233 
9.4.5. Parameter setting of the algorithms . . . . . . . . . . . . . . . . . . .   234 
9.4.6. Comparing the algorithms’ performances . . . . . . . . . . . . . . .   237 
9.5. Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   240 
9.6. Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   240 

x     Optimization in Signal and Image Processing 
 
Chapter 10. Biological Metaheuristics for Road Sign Detection . . . . . . .   245 
Guillaume DUTILLEUX and Pierre CHARBONNIER 
10.1. Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   245 
10.2. Relationship to existing works . . . . . . . . . . . . . . . . . . . . . . .   246 
10.3. Template and deformations . . . . . . . . . . . . . . . . . . . . . . . . .   248 
10.4. Estimation problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   248 
10.4.1. A priori energy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   248 
10.4.2. Image energy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   249 
10.5. Three biological metaheuristics . . . . . . . . . . . . . . . . . . . . . . .   252 
10.5.1. Evolution strategies . . . . . . . . . . . . . . . . . . . . . . . . . . .   252 
10.5.2. Clonal selection (CS) . . . . . . . . . . . . . . . . . . . . . . . . . .   255 
10.5.3. Particle swarm optimization . . . . . . . . . . . . . . . . . . . . . .   259 
10.6. Experimental results . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   259 
10.6.1. Preliminaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   259 
10.6.2. Evaluation on the CD3 sequence . . . . . . . . . . . . . . . . . . . .   261 
10.7. Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  265 
10.8. Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   266 
Chapter 11. Metaheuristics for Continuous Variables. The Registration of 
Retinal Angiogram Images . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   269 
Johann DRÉO, Jean-Claude NUNES and Patrick SIARRY 
11.1. Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   269 
11.2. Metaheuristics for difficult optimization problems . . . . . . . . . . .   270 
11.2.1. Difficult optimization . . . . . . . . . . . . . . . . . . . . . . . . . .   270 
11.2.2. Optimization algorithms . . . . . . . . . . . . . . . . . . . . . . . . .   272 
11.3. Image registration of retinal angiograms . . . . . . . . . . . . . . . . .   275 
11.3.1. Existing methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   275 
11.3.2. A possible optimization method for image registration . . . . . .   277 
11.4. Optimizing the image registration process . . . . . . . . . . . . . . . .   279 
11.4.1. The objective function . . . . . . . . . . . . . . . . . . . . . . . . . .   280 
11.4.2. The Nelder-Mead algorithm . . . . . . . . . . . . . . . . . . . . . .   281 
11.4.3. The hybrid continuous interacting ant colony (HCIAC) . . . . . .   283 
11.4.4. The continuous hybrid estimation of distribution  
algorithm. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   285 
11.4.5. Algorithm settings . . . . . . . . . . . . . . . . . . . . . . . . . . . .   288 
11.5. Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   288 
11.5.1. Preliminary tests . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   288 
11.5.2. Accuracy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   291 
11.5.3. Typical cases . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   291 
11.5.4. Additional problems . . . . . . . . . . . . . . . . . . . . . . . . . . .   293 
11.6. Analysis of the results . . . . . . . . . . . . . . . . . . . . . . . . . . . .   295 
11.7. Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   296 

Table of Contents     xi 
11.8. Acknowledgements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   296 
11.9. Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   296 
Chapter 12. Joint Estimation of the Dynamics and Shape of Physiological 
Signals  through Genetic Algorithms . . . . . . . . . . . . . . . . . . . . . . . .  301 
Amine NAÏT-ALI and Patrick SIARRY 
12.1. Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  301 
12.2. Brainstem Auditory Evoked Potentials (BAEPs) . . . . . . . . . . . .  302 
12.2.1. BAEP generation and their acquisition . . . . . . . . . . . . . . . .  303 
12.3. Processing BAEPs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  303 
12.4. Genetic algorithms. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  305 
12.5. BAEP dynamics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  307 
12.5.1. Validation of the simulated signal approach . . . . . . . . . . . . .  313 
12.5.2. Validating the approach on real signals . . . . . . . . . . . . . . . .  320 
12.5.3. Acceleration of the GA’s convergence time . . . . . . . . . . . . .  321 
12.6. The non-stationarity of the shape of the BAEPs . . . . . . . . . . . . .  324 
12.7. Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  327 
12.8. Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  327 
Chapter 13. Using Interactive Evolutionary Algorithms to Help Fit 
Cochlear Implants . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  329 
Pierre COLLET, Pierrick LEGRAND, Claire BOURGEOIS-RÉPUBLIQUE, Vincent PÉAN 
and Bruno FRACHET 
13.1. Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  329 
13.1.1. Finding good parameters for the processor . . . . . . . . . . . . . .  330 
13.1.2. Interacting with the patient . . . . . . . . . . . . . . . . . . . . . . .  331 
13.2. Choosing an optimization algorithm . . . . . . . . . . . . . . . . . . . .  333 
13.3. Adapting an evolutionary algorithm to the interactive fitting of cochlear 
implants. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  335 
13.3.1. Population size and the number of children per generation . . . .  336 
13.3.2. Initialization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  336 
13.3.3. Parent selection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  336 
13.3.4. Crossover. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  337 
13.3.5. Mutation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  337 
13.3.6. Replacement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  337 
13.4. Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  338 
13.5. Experiments. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  339 
13.5.1. The first experiment with patient A . . . . . . . . . . . . . . . . . .  339 
13.5.2. Analyzing the results . . . . . . . . . . . . . . . . . . . . . . . . . . .  343 
13.5.3. Second set of experiments: verifying the hypotheses . . . . . . . .  345 
13.5.4. Third set of experiments with other patients . . . . . . . . . . . . .  349 
13.6. Medical issues which were raised during the experiments . . . . . . .  350 

xii     Optimization in Signal and Image Processing 
 
13.7. Algorithmic conclusions for patient A . . . . . . . . . . . . . . . . . . .  352 
13.8. Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  354 
13.9. Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  354 
List of Authors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  357 
 
Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  359 

Introduction 
Engineers constantly encounter technological problems which are becoming 
increasingly complex. These problems may be encountered in different domains 
such as transport, telecommunications, genomics, technology for the healthcare 
sector and electronics. The given problem can often be expressed as one which 
could be solved by optimization. Within this process of optimization, one or several 
“objective functions” are defined. The aim of this process is to minimize the 
“objective function” in relation to all parameters concerned. Apart from problems of 
optimization, i.e. the problem’s objective function which is part of this topic (e.g. 
improving the shape of a ship, reducing polluting emissions, obtaining a maximum 
profit), a large number of other situations of indirect optimization can be 
encountered (e.g. identification of a model or the learning process of a new 
cognitive system). When looking at this issue from the angle of available methods 
used to resolve a given problem, a large variety of methods can be considered. On 
the one hand, there are “classic methods” that rely purely on mathematics, but 
impose strict application conditions. On the other hand, digital methods that could 
be referred to as “heuristic” do not try to find an ideal solution but try to obtain a 
solution in a given time available for the calculation. Part of the latter group of 
methods is “metaheuristics”, which emerged in the 1980s. Metaheuristics has many 
similarities with physics, biology or even ethology. “Metaheuristics” can be applied 
to a large variety of problems. Success can, however, not be guaranteed. The domain 
of optimization is also very interesting when it comes to its functions within the field 
of application. In the domain of optimization, the processing of signals and images 
is especially varied, which is due to its large number of different applications as well 
as the fact that it gave rise to specific theoretical approaches such as the Markov 
fields, to name just one example. 
These ideas have influenced the title of this book Optimization in Signal and 
Image Processing. This book has been written for researchers, university lecturers 

xiv     Optimization in Signal and Image Processing  
 
and engineers working at research laboratories, universities or in the private sector. 
This book is also destined to be used in the education and training of PhD students 
as well as postgraduate and undergraduate students studying signal processing, 
applied mathematics and computer science. It studies some theoretical tools that are 
used in this field: artificial evolution and the Parisian approach, wavelets and 
fractals, information criteria, learning and quadratic programming, Bayesian 
formalism, probabilistic modeling, the Markovian approach, hidden Markov models 
and metaheuristics (genetic algorithms, ant colony algorithms, cross-entropy, 
particle swarm optimization, estimation of distribution algorithms (EDA) and 
artificial immune systems). Theoretical approaches are illustrated by varied 
applications that are relevant to signals or images. Some examples include: analysis 
of 3D scenarios in robotics, detection of different aggregates in mammographic 
images, processing of hand-written numbers, tuning of sensors used in surveillance 
or exploration, underwater acoustic imagery, face recognition systems, detection of 
traffic signs, image registration of retinal angiography, estimation of physiological 
signals and tuning cochlear implants. 
Because of the wide variety of different subjects, as well as their 
interdependence, it is impossible to structure this book – which contains 13 chapters 
– into distinct divisions, which might, for example, separate traditional methods and 
metaheuristics, or create a distinction between methods dealing with signals or with 
imagery. However, it is possible to split these chapters into three main groups:  
– the first group (Chapters 1 to 5) illustrates several general optimization tools 
related to signals and images; 
– the second group (Chapters 6 to 10) consists of probabilistic, Markovian or 
Bayesian approaches; 
– the third group (Chapters 11 to 13) describes applications that are relevant for 
engineering in the healthcare sector, which are dealt with here through the use of 
metaheuristics.  
Chapter 1 deals with the benefits of modelization and optimization in the 
analysis of images. After the introduction of modelization techniques for complex 
scenes, the analysis of images has become much more accurate. In particular, 
traditional means of image analysis, such as the segmentation of an image, need to 
be revised. Jean Louchet creates a link between two domains that have been 
developing independently. These are the synthesis and the analysis of images. The 
synthesis of images relies on a wide range of different modelization techniques 
which are based on geometrics, depiction and movement. The author shows that 
some of these techniques can also be used for the analysis of images, which would 
broaden the possible applications of these techniques. Jean Louchet also shows how 
artificial evolution can lead to a better exploitation of models, create new methods of 

Introduction     xv      
 
analysis and push back the limits of Hough transform using a stochastical 
exploration of the model’s parameter space. 
In Chapter 2 Pierre Collet and Jean Louchet present the so-called “Parisian” 
approach of evolutionary algorithms and how these algorithms are used in 
applications when processing signals and images. Evolutionary algorithms are 
reputed to take a long time to perform calculations. The authors, however, show that 
it is possible to improve the performance of these algorithms by – if possible – 
splitting the problem into smaller sub-problems. When using the “Parisian” 
approach to analyze a scene, the objects which have been modified by genetic 
operators are not the vectors of the parameters that determine a complete model of 
an image. These objects are elementary entities which only make sense when 
merged together as a representative model of the scene that will be studied. In other 
words, a problem cannot be represented by a single individual but by several 
individuals, or even the entire population. The “Parisian” approach is successfully 
used in the field of robotics when analyzing 3D scenes via stereovision. The so-
called “Fly algorithm” allows for the detection of obstacles in real time and much 
more quickly than when using traditional approaches. Other visual applications 
based on models can be processed by evolutionary methods. Here, the authors 
discuss the identification of models of mechanical systems based on sequences of 
images.  
Chapter 3 deals with the use of wavelets and fractals when analyzing signals or 
images. The application of these techniques is becoming increasingly frequent in 
natural science as well as in the study and research carried out in the scientific fields 
of engineering and economics. Abdeljalil Ouahabi and Djedjiga Ait Aouit show that 
multifractal analysis and the exploitation of techniques of multiresolution based on 
the concept of wavelets lead to a local as well as global description of the signal’s 
singularities. On a local level, the criterion of punctual regularity (rugosity) based on 
Hölder’s inequality can be characterized by the decrease of the wavelets’ 
coefficients of the analyzed signal. On a global level, the distribution of a signal’s 
singularities can be estimated by global measures when using the auto-similarity of 
multifractals. In other words, the spectrum of singularities is obtained when 
localizating the maxima of the module of the wavelet transform of a signal. The 
authors give two examples of the aims and applications of this formalism. One 
example in the healthcare sector is a multifractal analysis which allows for the 
detection of different aggregates in mammographic images. The second example is 
fracture mechanics. In this field the formalism described above is used to study the 
resistance of materials.  
Chapter 4 deals with the information criteria and their applications when 
processing signals and images. Here, the model of a random signal should be 
optimized. An information criterion is a description or formulation of an objective 

xvi     Optimization in Signal and Image Processing  
 
function that should be minimized. The information criteria are an improvement on 
the traditional technique of the maximum likelihood. This improvement is due to the 
focus being shifted towards simultaneous research on the optimal number of free 
parameters in the model as well as the ideal values for these parameters. Christian 
Olivier and Olivier Alata first give a general overview of the main information 
criteria as well as the relevant literature. The majority of the criteria were introduced 
for research using 1D auto-regressive (1D AR) models. In Chapter 4, this case is 
illustrated by an application that involves the segmentation of natural images. The 
information criteria were then transferred to the 2D AR model. Two applications 
resulted from this. These are the modelization of the image’s texture and the 
unsupervised segmentation of textured images. The authors then look at the 
extension of the information criteria to other models based on parameters. These are 
a mix of Gauss’s laws n-D, which are here applied to unsupervised classification as 
well as Markov’s modes. Last but not least, this chapter deals with the application of 
information criteria in the case of non-parametrical problems, such as the estimation 
of distribution via histograms or the search for antiderivatives that carry a maximum 
amount of information depending on the form of the information. The information 
criteria finally offer a means to justify the choice of parameters which are linked to a 
large number of problems when processing signals or images. The information 
criterion deals with a high number of observations. This is why the time required to 
carry out the calculation might be high (particularly in an unsupervised context). 
Dynamic algorithms, however, are able to reduce the number of operations that need 
to be carried out.  
Chapter 5, written by Gaëlle Loosli and Stéphane Canu, deals with an aspect of 
optimization that can currently be encountered within signals and images, for 
example in shape recognition, i.e. learning processes. More precisely, the chapter 
focuses on the formulation of learning as a problem in convex quadratic 
programmation on a large scale (several million variables and constraints). This 
formulation was obtained by the “nucleus methods”, which emerged about a decade 
after neural networks. Its main aim is linked to the fact that the solution in question 
is often “parsimonious”, i.e more than 99% of all unknown variables are zero. Using 
this specific feature enables learning algorithms to solve large scale quadratic 
programming problems within a reasonable amount of time. The best-performing 
methods, known as “active constraints”, work “off-line”. In other words, they are 
able to determine the exact solution of a given problem if they are provided with all 
the data that is used in the learning process. To carry out an “online” learning 
process, a method of iterative stochastic optimization is used, which allows us to 
obtain an approximate solution. This chapter describes one of the methods which is 
part of the “support vector machine” (SVM) type. The efficiency of this technique is 
illustrated by results of experiments which focused on the problem of recognizing 
handwritten numbers.  

Introduction     xvii      
 
Chapter 6 deals with the problem of planning within time and space the use of 
sensors with the aim of optimizing the exploration and surveillance of a specific 
zone; given the rather low number of available sensors as well as their capacity, this 
zone is large. Due to the problem being rather extensive, exact methods cannot be 
used. An approximate solution can, however, be obtained with the help of 
metaheuristics. In this case, Frédéric Dambreville, Francis Celeste and Cécile 
Simonin, the authors of this chapter, recommend the use of “cross-entropy”. This 
method was initially created to evaluate the probability of rare events and has been 
adapted to “difficult optimization” problems (many local minima need to be 
considered). The solution is obtained with the help of a probability law that 
continually approaches the global optimum. This method is applied to the problem 
of planning sensors via a priori modeling mainly under the form of different groups 
of probability laws, of possible planning policies. In this chapter, three examples are 
explained in detail. The first example looks at how to ideally array search units in 
the context of military operations. The aim is to maximize the probability of locating 
the target which does not move but is hidden. In the second example, cross-entropy 
is used for an exploratory mission. The movement of the vehicle needs to be planned 
based on maps that show the environment. The third example is the problem of 
optimal control in an environment where only certain parts of the environment can 
be observed. Cross-entropy is particularly useful when dealing with data that are 
very difficult to formalize. Optimization via cross-entropy therefore means to 
“learn” an optimal strategy.  
The topic of Chapter 7 is linked to that of the previous chapter. Chapter 7 deals 
with a surveillance system such as a maritime patrol aircraft that needs to locate a 
moving target. In order to do this, all resources, i.e. passive as well as active sensors 
(e.g. a radar), need to be used. Passive measures do not involve any cost. However, 
they only determine the direction of the target. Active measures provide much more 
information since they can evaluate the distance to the target. These measures, 
however, need to be used sparsely because of their cost (emitting a wave) and with 
discretion. The author of this chapter, Jean-Pierre Le Cadre, gives a general outline 
of the problem of optimal and temporal repartition when using active measures. He 
futhermore describes the general mathematical tools (e.g. multilinear algebra) that 
allow for the analysis of this problem. The study focuses on the explicit calculation 
of objective functions while expressing the quality of the estimation (or tracking) of 
the trajectory’s location by using non-linear observations of state. First of all, this 
chapter examines the case of targets that contain a determined trajectory. Their 
movement is rectilinear and uniform, or in other words the target is “maneuvering”. 
When dealing with certain types of approximations, the problem of convex 
optimization comes into play. This problem can easily be resolved. The author also 
looks at the stochastic evaluation of this case. He shows that it is possible to directly 
calculate the objective function of a target of Markovian trajectory without having to 
use simulations.  

xviii     Optimization in Signal and Image Processing  
 
Chapter 8 deals with segmentation methods of images which exploit both the 
Markovian modeling of images and the Bayesian formalism. For every image under 
observation there is an infinite number of combinations of objects that can be 
associated with it. These combinations of objects represent, or in other words create 
,the image. To reduce the number of possible solutions that should be integrated in 
the stage of segmentation, prior local or global knowledge is required. The aim of 
Markovian modeling lies precisely in its capacity to locally describe global 
properties. Due to the equivalence between Markov’s field and Gibbs’s distribution, 
the optimal segmentation can be obtained by the minimization of a function linked 
to energy. Christophe Collet, the author of this chapter, applies this formalism to the 
context of underwater acoustic imagery. To detect small objects on the seabed, the 
author exploits images that have been taken by a lateral multibeam sonar. The 
images that were obtained were distorted by noise. A segmentation of good quality 
therefore requires the nature of noise to be taken into consideration during the 
process of image modeling. This chapter shows different examples of application. 
These are the segmentation of sonar images into two different groups (shadow, 
reflections of the seabed) or segmentation into three different groups (shadow, 
seabed and echo). Due to the third group, echo, physics, which forms the basis of the 
creation of sonar images, is also taken into consideration. Two other examples are 
the differentiation between manufactured and natural objects, as well as the 
subdivision of the seabed into different regions (sand, mid-ocean ridges, dunes, 
stones and rocks). All tasks linked to detection and classification are first of all 
united in the fact that the function of energy, which integrates the prior knowledge 
required to obtain a solution, needs to be minimized. The technique used for this 
optimization is a deterministic method or a genetic algorithm, depending on whether 
an initial good quality solution is available or not. 
Chapter 9 was written by Sébastien Aupetit, Nicolas Monmarché and Mohamed 
Slimane and describes the use of hidden Markov models (HMM) for the recognition 
of images. Hidden Markov models are statistical tools which allow for the 
modelization of stochastic phenomena. This type of phenomenon may, for example, 
consist of several sequences of images. Images of the same sequence are taken from 
different angles but show the same scene, e.g. a person’s face. After a learning 
phase, HMM is prepared for the process of recognition. During this learning phase 
several sequences of images, let us say four sequences of four photographs each 
showing the faces of four different people are processed. When confronted with a 
new photograph of a face, HMM is able to distinguish which person is shown in the 
picture from the four previous pictures. At the same time, the risk of HMM making 
a mistake is minimized. More precisely, a discrete HMM corresponds to the 
modeling of two stochastic processes. The first process is hidden and perfectly 
modeled by a discrete Markov chain while the second observed process is dependent 
on the state of the first process, i.e. the hidden process. This chapter focuses on 
learning processes, a crucial aspect of HMM. It provides an overview of the main 

Introduction     xix      
 
criteria of existing learning processes and the possible solutions for HMM learning 
processes. Furthermore, the principles of three metaheuristics inspired by biology 
and population-based are also addressed by the authors and analyzed in light of 
HMM learning processes. These three metaheuristics are a genetic algorithm, ant 
colony algorithm and particle swarm optimization (PSO). Several versions of these 
types of metaheuristics (which are different to one another because of the 
mechanisms which are implemented, or simply due to the settings of the respective 
methods) are examined and tested in great detail. These tests are carried out on a set 
of test images as well as samples of literature. The chapter emphasizes the fact that 
results can be improved if metaheuristics used for learning processes are combined 
with a method dedicated to local optimization. 
In Chapter 10 Guillaume Dutilleux and Pierre Charbonnier use different 
metaheuristics inspired by biology for the automatic detection of traffic signs. The 
aim is to make an inventory of road signs currently used in the French secondary 
road network. The data used are images that have been collected by vehicles 
inspecting the roads that are part of the respective network. The application does not 
face any real time constraint. However, the application needs to be robust when 
faced with changes in the conditions under which the images are collected. Problems 
might occur due to differences in light, backlighting, worn out or partially hidden 
traffic signs. The method that has been proven to be successful includes the 
technique of “deformable models”. This technique consists of a mathematical 
model, a prototype of which the object research is carried out upon. This model’s 
shape can be manipulated and changed to such an extent that it is adapted to the 
respective image that should be analyzed. The quality of this adjustment and to what 
extent manipulation can be accepted are, in the case of Bayesian formalism, 
respectively measured by a likelihood and an a priori. The problem of localizing an 
object therefore comes down to the problem of optimization in the sense of a 
maximum a posteriori. The residual value of a minimized objective function gives 
an indication of the effective presence of the object in the scene which is to be 
analyzed. In practice, the presence of numerous local minima justifies the use of 
metaheuristics. The authors have carried out experiments with three different 
techniques in the field of metaheuristics. These are an evolutionary strategy, PSO 
and a method of clone selection (the latter is relevant to a more general field of 
“artificial immune systems”). The performance of automatic detection is compared 
to a number of different algorithms when dealing with a sequence of traffic signs. 
(For these test images the real data had already been obtained manually.)  
The majority of metaheuristics were initially created for the processing of 
problems that arise when dealing with discrete optimization. Chapter 11, written by 
Johann Dréo, Jean-Claude Nunes and Patrick Siarry, looks at their adaptation to 
applications with continuous variables, which are encountered frequently, especially 
in the field of signals and images. The techniques suggested in the literature for this 

xx     Optimization in Signal and Image Processing  
 
adaptation are linked to each specific form of metaheuristics. These techniques 
cannot be generalized, i.e. it is not possible to apply these techniques to another 
application. Furthermore, no metaheuristic, whether it is continuous or discrete, is 
the ideal technique, i.e. most efficient, for all possible sorts of problems. This is why 
hybrid methods, which combine different forms of metaheuristics or metaheuristics 
with downhill simplex techniques, often need to be used. This chapter describes two 
“continuous metaheuristics”. These are an ant colony algorithm and EDA. 
Furthermore, a local technique, which is frequently used in continuous cases to 
refine the search within a “promising valley” of solutions, is Nelder and Mead’s 
downhill simplex method. These methods are used for image registration in the field 
of retinal angiography. Before a doctor can actually interpret a sequence of images, 
the problem of inevitable eye movement during the procedure needs to be dealt with. 
In the example given in this chapter, image registration is carried out by using only 
translatory motions between different images. Metaheuristics were found to be 
particularly appropriate for image registration in angiography with a high resolution. 
The time required for calculations only increases a little when increasing the 
resolution of images.  
Chapter 12, written by Amine Naït-Ali and Patrick Siarry, describes the 
introduction of a genetic algorithm used for the estimation of physiological signals, 
the Brainstem Auditory Evoked Potentials (BAEP). BAEP is an electric signal 
which is generated by the auditory system as a response to acoustic stimulation. 
Studying this signal allows for the detection of pathologies such as acoustic 
neuroma. Measuring BAEP is, however, a problem as this signal is of a very low 
energy and covered by electric noise that stems from spontaneous electric activity of 
the cerebral cortex (these signals can be measured using electroencephalograms 
(EEG)). To identify a patient’s effective BAEP, several hundred signals need to be 
exploited. These signals are obtained as a result of acoustic stimulation. They also 
have to be synchronized before being simply added to one another in order to 
eliminate the noise. The synchronization process is expressed in the form of an 
optimization problem in which unknown variables are the random delays of 
different signals. Here, the problem is solved with the help of a genetic algorithm. 
The authors show that a significant acceleration of this technique can be obtained 
when creating a model for the variation law of these delays. This can, for example, 
be performed using a set of sinusoids.  
Chapter 13, written by Pierre Collet, Pierrick Legrand, Claire Bourgeois-
République, Vincent Péan and Bruno Frachet, presents an evolutionary algorithm 
that allows for the adjustment of parameters for a cochlear implant. This adjustment 
is carried out in interaction with the patient using the device. This type of implant 
enables deaf people, whose cochlear plate is still intact, to hear. The device works as 
follows: a group of electrodes is implanted into the patient’s cochlear plate. These 
electrodes stimulate the auditory nerve. The electrodes are connected to a digital 

Introduction     xxi      
 
signal processor (DSP) that receives the sound as signals through a microphone 
situated next to the patient’s ear. The parameters of DSP need to be adjusted in a 
way that reconstructs the patient’s auditory ability to a point that he/she might even 
be able to understand spoken language. Adjusting these parameters is usually 
undertaken by a human and becomes increasingly complicated as technology 
progresses. A current implant consists of 20 electrodes and several hundred 
parameters. The effort for adjusting these parameters is dependent on the patient’s 
ability to understand spoken language. This is why this study looks at the 
performance of an interactive evolutionary algorithm which should take over the 
task of adjusting the parameters of a cochlear implant. There are a large number of 
difficulties that lie within this application. These are the subjective evaluation of 
every single patient, the quality of every single solution produced by the algorithm, 
the necessity of a rapid convergence of the algorithm in order to strictly limit the 
amount of solutions to be evaluated by the patient (as every evaluation takes a few 
minutes) as well as the fact that the search space is very broad. This chapter presents 
experiments undertaken by the authors with the help of a small number of patients 
following a methodical protocol. The first results are promising. They show the 
disadvantages of manual adjustment in cochlear implants which is increasing 
because the number of available electrodes is currently increasing. 

Chapter 1
Modeling and Optimization in Image Analysis
1.1. Modeling at the source of image analysis and synthesis
From its ﬁrst days, image analysis has been facing the problem of modeling.
Pioneering works on contour detection led their authors to refer to explicit models
of edges and noise [PET 91], which they used as a conceptual basis in order to build
their algorithms. With an opposite approach to these phenomenological models, a
physical model of light diffusion on surfaces has been used as the basis for Horn’s
works [HOR 75] on shape from shading. More generally, a phenomenological model
aims at describing a directly computable property of the geometric conﬁgurations of
gray levels on an image; the physical model then tries to use the knowledge corpus
of physics, or even sometimes to create an ad-hoc conceptual system, as we will see
later. Between these two extremes, there is a large number of approaches to modeling.
Here, we shall try to illustrate them using some examples.
It is important to ﬁrst show the links between image analysis and synthesis. For
a number of years, these two domains have been undergoing largely independent
development processes. In spite of their conceptual similarity, they have been dealt
with by two separate scientiﬁc communities, with different origins and centers of
interest, which did not address the same applications. Robotics is one of the few
ﬁelds of application that has played an important role in moving them closer to one
another. Image synthesis addresses another large panel of approaches to modeling,
in particular in the ﬁelds of geometry, rendering and motion modeling – to such an
extent that there are important international communities, journals and conferences
that specialize in each of these approaches to modeling. One of the beneﬁts of
Chapter written by Jean LOUCHET.
Optimization in Signal and Image Processing 
Edited by Patrick Siarry 
Copyright 0 
2009, ISTE Ltd 

2
Optimization in Signal and Image Processing
connecting image analysis and image synthesis comes from the fact these two
domains often use common modeling techniques which they use as bridges to their
constructive interaction.
1.2. From image synthesis to analysis
One of the difﬁcult points in image analysis and machine vision is algorithm
validation methods. In most cases it is not possible to access the “ground truth”
that corresponds to the image or the image sequence on which we want to evaluate
the quality of the analysis process. A frequent compromise consists of evaluating an
algorithm by referring to another algorithm, which is seldom acceptable. The ideal,
straightforward solution would consists of creating a synthesis tool – and therefore a
model – able to build dependable test data from any ground truth.
Once the effort of building such a model has been carried out, we naturally arrive
at the idea of incorporating into the image analysis algorithm, the knowledge of the
physical world and its rules, following an “artiﬁcial intelligence” approach. This can
be done implicitly (using the same knowledge corpus and coding it in a way suitable
to the analysis algorithm) or alternatively by explicitly incorporating the model into
the analysis process. Of course, this raises the delicate ethical question of mutually
validating two algorithms running the same model, and therefore susceptible to
containing the same errors or clumsy simpliﬁcations. In any case, this is, when
pushed to its extreme, the basis of the so-called “analysis by synthesis” approaches
where rather than the model (whether photometric, geometric, kinematic or physical),
it is the whole image synthesis process that is embedded into the analysis algorithm.
Between merely using general physical knowledge in the analysis process, and at
the other end, embedding a complete synthesis process into the analysis algorithm,
it appears that the image analysis techniques explicitly exploiting a model are
undergoing an important development, particularly thanks to modern optimization
techniques, as we will see in several examples.
First, we will examine the classical approaches to image segmentation and show
how they have built their organization, often implicitly, after the way scene models
used in image synthesis are naturally organized.
In the next section, we will revisit the Hough transform [HOU 62], which is
probably the best known example of image analysis and model inversion, through
deterministic, exhaustive search in a parameter space; the model used here is
phenomenological (visual alignment). We show the Hough transform and its
generalizations may be rewritten into an evolutionary optimization version; as a
stochastic exploration of a parameter space, here each point represents a particular
instance of a model. This considerably widens the ﬁeld of potential applications of
the original Hough transform.

Modeling and Optimization in Image Analysis
3
The following part will quickly examine the contribution of physical models to
image analysis. This is a promising yet little known topic we will discover through
two examples using photometric and dynamic models.
In some applications, the model underlying the analysis technique may be taken
apart into elementary objects whose collective behavior actually represents the
object to be modeled. A speciﬁc evolutionary optimization method, called “Parisian
Evolution”, can then be implemented. This is a change in the semantics of the evolved
population but a classical evolutionary process is still applied to the elementary
objects. This will be the subject of Chapter 2.
1.3. Scene geometric modeling and image synthesis
As discussed earlier, image contour segmentation took its foundations from
hypotheses about image signals, resulting into a wide use of differential operators
as main analysis tools. Region segmentation, which was developed later, probably
because of its greater need for computational power, brought more evidence of the
strong link between the structures of a 3D scene and the image entities directly
accessible to calculation. It is therefore tempting to revisit the notion of image
segmentation [COC 95, GON 92] through its possible interpretations in terms of
scene models.
Seen from this point of view, segmentation into regions could be deﬁned as any
image partitioning technique such that each region entity it extracts is a good candidate
image projection of a 3D or space-time varying physical object in the scene.
Similarly, it is possible to give a new deﬁnition of contour segmentation: it
describes any image line extraction technique such that each line extracted is likely to
be the image projection of an edge of a physical object present in the scene.
With each level of primitives in the polyhedral model (vertex, edge, facet, etc.) it
is possible to associate a probable local property of the image, such as the contrast
along a line, the homogenity of a region, etc., and a corresponding calculation
technique. Classical segmentation techniques are often a decisive step in the process
of instantiating the model as efﬁcient model exploration heuristics; contours usually
are the projection of the subset of the scene where the probability of ﬁnding an
edge is highest, thus the knowledge of contours contributes to the efﬁciency of the
exploration of the space of parameters which describe the possible positions of edges.
Similarly, interest points give useful hints on where to look for polyhedron vertices,
and so on.
One of the consequences is that the pertinence of a segmentation technique
on a class of images essentially depends on whether it actually corresponds to an
observable characteristic of the model underlying the class of scenes and how the

4
Optimization in Signal and Image Processing
images have been captured, An illustration of this is given by ﬂuid ﬂow imaging,
where polyhedral models are irrelevant and classical contour or region segmentation
techniques are just as irrelevant. Segmentation techniques are the translation of the
scene-speciﬁc description language.
The primary role of image analysis is to instantiate or identify the parameters
of a general scene model. If we consider scenes made from opaque objects, which
is not too bad in most familiar scenes, the most widely used modeling language in
image analysis, as in synthesis, is based on polyhedral objects. The ultimate goal
of image segmentation should ideally be to provide a description of the scene using
the same primitives and language as in image synthesis: a geometrical description
(polyhedra, facets, edges, vertices), completed (if useful to the application) with a
photometric description (light sources, radiance factors, diffusion coefﬁcients, etc.).
In the case of time-dependent sequences, it will be necessary to include object motion
and deformations, and the analysis may even include the building of a description of
the scene in terms of agents, individual behaviors and physical interaction [LUC 91].
In all these cases, “informing the model” means optimizing the likeness between
real data and data synthesized from the scene model, and therefore will generally
involve the optimization of a cost or resemblance function.
1.4. Direct model inversion and the Hough transform
1.4.1. The deterministic Hough transform
One of the main motivations of the development of image segmentation techniques
is the difﬁculty of directly resolving the problem of optimizing a scene model using
classical methods. However, a well known exception to the rule is given by the Hough
transform [HOU 62, BAL 82], which may be described as a direct parameter space
exploration technique. It consists of ﬁlling in the space of model parameters (also
known as the Hough accumulator) using a vote technique, where each locally detected
primitive in the image results in incrementing a sub-variety of the parameter space.
The parameter vector that will be eventually elected is the one which has received the
greatest number of votes, and therefore is likely to represent the best possible model,
i.e. the most satisfying a priori global explanation of all the primitives that have been
previously extracted from the image.
In
spite
of
a
reasonable
success
story,
the
Hough
transform
and
its
priority-to-image philosophy imply that for each image primitive considered to be
relevant, the accumulation process will go into the n-dimensional parameter space
to modify the values of all the points belonging to a variety with dimension n −1
(within the limits of the search space). The heuristics that have been found in order
to improve the algorithm’s speed have a limited effect and the generalized Hough
transform becomes unusable when the dimension of the search space becomes greater

Modeling and Optimization in Image Analysis
5
than 3 or 4, mainly due to available memory space, memory access time and the
complexity of the dual space incrementation task.
1.4.2. Stochastic exploration of parameters: evolutionary Hough
If we consider the Hough technique, which involves calculating voting scores
throughout the parameter space then exhaustively exploring this space in order to
ﬁnd the best optima, it becomes an attempt to directly explore the search space
[ROT 92, LUT 94]. Evolutionary programming provides us with very welcome
exploration techniques which, in our case, allow us only to calculate the values in the
dual space where individuals of the evolving population actually are, rather than on
all of the dual space.
According to the general principles of artiﬁcial evolution (also known as
evolutionary programming), a function to be optimized is given, though not explicitly.
We then consider an arbitrary set of individuals (“population”) which belong to
the space where this function is deﬁned. This population is then evolved, in a
way reminiscent of biological evolution, using genetic operators such as mutation
crossover and selection. The selection criterion is the individual’s performance
(“cost” or “ﬁtness”) as given by the function to be optimized. The expression
“evolutionary strategy” [REC 94, BÄC 95] refers to the artiﬁcial evolution algorithm,
where gene coding is performed using real numbers as variables, unlike genetic
algorithms which, strictly speaking, use Boolean variables.
Thus it is possible to deﬁne an evolutionary version of the Hough transform:
– the population is a ﬁnite subset of the parameter space;
– for each individual in the population, the ﬁtness function gives a measurement
of the pertinence of the corresponding image pattern;
– classical selection operator (tournament);
– barycentric crossover;
– mutation: Gaussian noise.
The ﬁtness function used in the evolutionary version of the Hough transform
is calculated according to the same criterion as in the classical versions of Hough;
for example, if the criterion for a point to participate into the incrementation of
the accumulator is that its contrast is greater than a given threshold, then in the
evolutionary version the ﬁtness of an individual (representing e.g. a straight line) will
be the number of points on this line with a contrast higher than the same threshold.
In the case of the classical Hough transform, there is no very clear advantage to
either approach. Indeed, the classical Hough method in which each image point (x, y)
votes for the set of points (θ, ρ) in the dual space, such that ρ = x cos θ + y sin θ,
is relatively fast and needs a reasonable memory allocation (Figures 1.1 and 1.2); on

6
Optimization in Signal and Image Processing
Figure 1.1. Result of the classical Hough transform (image 288×352)
Figure 1.2. The (θ, ρ) Hough accumulator corresponding to the same image (image 628×300)
the other hand, the evolutionary process which, thanks to the sharing operator, is able
to ﬁnd several different solutions (Figure 1.3), suffers from not having a canonically
deﬁned ending: it is therefore difﬁcult to compare processing times. In practice, the
number of generations needed to ensure convergence results in similar calculation
times.

Modeling and Optimization in Image Analysis
7
Figure 1.3. Result of the evolutionary version of Hough
However, when the dimension of the parameter space becomes higher, dual space
storage and exploration soon become prohibitive, while the evolutionary version is
much less greedy in terms of memory and computing time. The evolutionary version
of the Hough transform really becomes interesting when considering more complex
parametric optimization problems as shown in the following examples, where a
classical Hough approach would fail.
1.4.3. Examples of generalization
The following example1 consists of detecting circles with unknown diameters (a
moving ball) in an image sequence. The individuals are triples (a, b, r) which deﬁne
circles with equation (x−a)2 +(y −b)2 = r2. The ﬁtness of a particular individual is
deﬁned as the average gradient norm taken on 40 points randomly distributed on the
circle. The algorithm parameters are:
population size
100
selection
2-tournament
mutation rate (%)
15
r mutation amplitude
10
a, b mutation amplitude
40
barycentric crossover rate (%)
5
number of generations per frame
init. 800 then 240
1. These results were produced by A. Ekman, a PhD student at KTH Stockholm in October
2004.

8
Optimization in Signal and Image Processing
Figure 1.4. Four original images from the “tennis ball” sequence (top) and results of the
“evolutionary Hough” detection of circles with unknown radius (bottom)
It is worth noting an interesting property of this approach: if motion is small
enough between two consecutive frames, the evolutionary algorithm is able to track
the object’s motion, unlike its deterministic counterpart which has to resume its
calculations from the very beginning, even with a tiny image change, whatever the
degree of redundancy in their information contents. In other words, in spite of the
fact artiﬁcial evolution is often regarded as slow, the evolutionary version of the
Hough transform possesses true real time properties that its deterministic version
does not have.
Figure 1.5. Image of the galaxy AM 0644-741 taken by the Hubble telescope (left) and the
result of the evolutionary Hough ellipse detection algorithm (right)
Another example (Figure 1.5) consists of detecting a conical section (ellipse) in
an image, using the same method and the same adjustment of genetic parameters as
with the circle detection, but with a 5-parameter genome corresponding to the ellipse
parametric equation:
x = a + rx cos α cos θ + ry sin α sin θ
y = b −rx cos α sin θ + ry sin α cos θ

Modeling and Optimization in Image Analysis
9
It is not easy to compare the theoretical performance of classical (ﬁlling up
parameter spaces) Hough methods to their evolutionary versions, as strictly speaking
the number of generations required for convergence depends on analytical properties
of the ﬁtness function, which is image-dependent. However, let us re-examine the
practical examples given above. With a square N × N image and an accumulator
(parameter space) with dimension n, where each parameter can take P different
values, the classical Hough transform needs a memory with size P n, and roughly
N 2 × P n−1 calculations to ﬁll the accumulator. The evolutionary version does not
require large memory resources, and it needs G × E × N calculations, where G is
the number of generations and E the population size. In the case of ellipse detection
(n = 5), the images (213 × 161 pixels) correspond to N ≈200 and the precision
of quantization to P
= 200; the classical Hough method would use a 300 GB
accumulator and about 6 × 1012 calculations, against about 5 × 106 calculations
with the evolutionary method, which gives a gain factor about 106. In the simpler
case of circles (3 parameters) the computing time ratio falls to about 100, with a
Hough accumulator size about 10 MB. From these examples it is safe to say that with
three parameters, the evolutionary method is more efﬁcient than the classical Hough
method, but with 4 or more parameters, the only realistic method is the evolutionary
version. This gives quite an important extension to the ﬁeld of potential applications
of the Hough transform.
1.5. Optimization and physical modeling
In the discussion above, we considered image analysis as the instantiation of a
scene model. This leads us to wonder whether all the aspects of modeling used in
image synthesis and computer graphics are still relevant in image analysis. While it
still looks premature to give an exhaustive answer, we will examine two aspects of this
question: the photometric models and the motion models.
1.5.1. Photometric modeling
Photometric modeling is essential to image synthesis. Rather surprisingly,
photometry is not yet in wide use in image analysis. The main explicit application of
photometry to image analysis is shape from shading, which consists of building the
shape of a surface from the variations of the luminance. In his pioneering works,
Horn [HOR 75] showed that it is possible, through the resolution of differential
systems initialized on local luminance extrema, to recover the 3D shape of a surface,
under relatively strong hypotheses: the surfaces are assumed to have Lambertian
scattering properties, the light sources to be at inﬁnity, etc. Practical applications
have been limited by these constraints and the ill-conditioning of the problem. We
may however note that recent research by Prados [PRA 04] showed that taking into
account the distance-dependent reduction of lighting (light source at a ﬁnite distance)
allows us to obtain a well-conditioned problem and become free of some of the usage
restrictions.

10
Optimization in Signal and Image Processing
Another example has been given by G. Maurin [MAU 94] with the 3D location
of a light source. In this preliminary study, the author exploits one of the images
from a stereo pair of an interior scene which has previously been analyzed in three
dimensions; thanks to homogenity hypotheses concerning the regions detected, he
calculates the position of the (single) light source in a room.
Another original example of how to exploit a simple photometric model in image
analysis was given by J.B. Hayet [HAY 98] with the Robocop project (obstacle
location through observation and calculation of shadows). In this application, rather
than using a second camera, one or several computer-controlled light sources are set
on the robot: detecting the shadow edges in each lighting conﬁguration enables a
cheap and fast 3D analysis of the scene and an elementary obstacle detection.
1.5.2. Motion modeling
1.5.2.1. Kinematic modeling
Motion modeling is the heart of image animation. Motion can be modeled at
several levels, the kinematic level being the simplest and the most widely used. It
consists in analyzing, in a purely geometric way, the motion of an object in the
scene. It may be analyzed as a planar motion (e.g. for a pure translation, through
the exploitation of the apparent motion constraints equation [HOR 81]); concerning
more general planar movements, it is possible to exploit an equation which delivers
the instantaneous planar rotation centers [LOU 96a]; 3D movements can also be
analyzed directly [HUA 83].
However, this is not all about motion analysis and modeling. To each possible
level of motion modeling, there is a corresponding image sequence analysis technique.
Classical motion analysis (resulting in optical ﬂow data) corresponds to a purely
kinematic modeling of motion; similarly, physical or behavioral modeling approaches
may be matched to a corresponding semantic level of image sequence analysis.
1.5.2.2. Physical modeling
Here, we will examine how physical modeling of motion may be used in image
sequence analysis, using the mass-link modeling paradigm as it was developed by
the Acroe team in Grenoble, France [LUC 91]. The CORDIS-ANIMA model and
system were created in the 1970s with the main application objective of multi-modal
man-machine interfacing, incorporating acoustical visual and gestural modalities.
In addition to specialized peripherals such as their retroactive gestural transducer,
the conceptual heart of the system is a physical modeling language based on two
primitives: the mass (ﬁtted at each instant, with a position and a velocity) and the
link (between two visco-elastic and generally non-linear masses). An important
conceptual, theoretical and experimental construction has allowed us to demonstrate
the power of this approach through its applications in particular to the interactive

Modeling and Optimization in Image Analysis
11
synthesis of sounds and images. One of the problems to have been addressed around
this project is the inverse problem which consists of building a physical model able
to reproduce as accurately as possible the given motion, deformation and interaction
of an object. This problem has been partially resolved through a decomposition of
the mass-link structures and a multi-objective evolutionary strategy to optimize the
model [LOU 94, STA 02] using individual cost functions associated with each of the
masses.
Figure 1.6. Reconstruction of an image sequence of a cloth: original synthetic sequence (ﬁrst
line) and reconstructed sequence (second line) using cloth physical parameters identiﬁed
from the original image data (modeling and images: X. Provost)
One of the applications consisted of identifying the internal mechanical
parameters of a cloth from an image sequence of a hanging cloth sample, then
from these parameters re-synthesizing images of cloth from the same fabric (Figure
1.6) in more complex conﬁgurations [LOU 95]. In a similar way, from an image
sequence representing a compressible viscous ﬂuid ﬂow, Jiang Li showed [LOU 96b]
it is possible to identify the Cordis-Anima parameters that characterize the ﬂuid’s
viscosity and compressibility and re-synthesize other ﬂows from the same ﬂuid
(Figure 1.7).
Figure 1.7. Four successive synthesized images of the turbulent meeting
of two compressible ﬂuids (images: L. Jiang)

12
Optimization in Signal and Image Processing
Another application in the same spirit, consisted of detecting heart stroke scar
zones from X-ray scanner image sequences. The heart is modeled as a mass-link
system where the internal parameters are then identiﬁed using image sequence data.
Anomalous values of the internal parameters of viscous-elastic links indicate a high
probability of having a scar zone in the corresponding region (Figure 1.8).
Figure 1.8. Heart X-ray image sequence analysis: the gray zone represents the necrosed area,
the crosses are calibration points. Dotted lines show where the algorithm found high stiffness
using a planar model based on a single slice of the 3D data. Continuous lines represent links
with high stiffness in a 3D model based on all the slices
1.6. Conclusion
In this chapter, we revisited some classical approaches to image processing
in the light of implicit or explicit scene modeling. This allowed us to outline a
rarely described logical organization of the existing methods in image processing,
setting some light into certain research directions still little exploited and sometimes
promising. It looks like many modeling techniques developed by researchers in
other communities, in particular by the image synthesis community, have potential
applications to the domains of image or image sequence analysis. In a way, the
challenge of modeling is not so much adding a speciﬁc technique to the existing
panoply of image processing, but rather reconsidering the extension of the semantic
ﬁeld of what is commonly called “image processing” and “machine vision”.

Modeling and Optimization in Image Analysis
13
1.7. Acknowledgements
Thank you to Pierre Collet, Anders Ekman, Jean-Loup Florens, André
Gagalowicz, Jiang Li, Annie Luciani, Evelyne Lutton, Xavier Provot, Georges
Stamon, Bogdan Stanciulescu and all the colleagues who contributed the ideas,
algorithms and results described or quoted in this chapter.
1.8. Bibliography
[BÄC 95] BÄCK T. and SCHWEFEL H.-P., “Evolution Strategies I: variants and their
computational implementation”, Genetic Algorithms in Engineering and Computer Science,
John Wiley & Sons, 1995.
[BAL 82] BALLARD D.H. and BROWN C.M., Computer Vision, Prentice Hall, 1982.
[CAD 94] CADOZ C., Les réalités virtuelles, Dominos/Flammarion, 1994.
[COC 95] COCQUEREZ J.-P., PHILIPP S. et al., Analyse d’images: ﬁltrage et segmentation,
Masson, 1995.
[COL 00] COLLET P., LUTTON E., RAYNAL F. and SCHOENAUER M., “Polar IFS + Parisian
Genetic Programming = Efﬁcient IFS inverse problem solving”, Genetic Programming and
Evolvable Machines, vol. 1, pp. 339–361, 2000.
[DEL 93] DELNONDEDIEU Y., LUCIANI A. and CADOZ C., “Physical elementary component
for modelling the sensory-motricity: the primary muscle”, 4th Eurographics Workshop on
Animation and Simulation, pp. 193–207, Barcelona, September 1993.
[GON 92] GONZALEZ R.C. and WOODS R.E., Digital Image Processing, John Wiley & Sons,
1992.
[HAR 80] HARALICK R.M., “Using perspective transformations in scene analysis”, Computer
Graphics and Image Processing, vol. 13, pp. 191–221, 1980.
[HAY 98] HAYET J.-B. and TADJADIT M., Projet ROBOCOP: repérage d’obstacles par
observation et calcul des ombres portées, rapport de stage ENSTA, PPL 99/11, 1998.
[HOR 75] HORN B.K.P., “Obtaining shape from shading information”, The Psychology of
Computer Vision, McGraw-Hill, 1975.
[HOR 81] HORN B. and SCHUNCK B., “Determining optical ﬂow”, Artif. Intell., vol. 17,
pp. 185–203, 1981.
[HOU 62] HOUGH P.V.C., Method and Means of Recognising Complex Patterns, U.S. Patent
no. 3 069 654, 18 December 1962.
[HOU 92] HOUSE D.H., BREEN D.E., GETTO P.H., “On the dynamic simulation of
physically-based particle-system models”, Proceedings of EuroGraphics’92 Workshop on
Animation and Simulation, Cambridge England, 5-6 September 1992.
[HUA 83] HUANG T.S., Image Sequence Processing and Dynamic Scene Analysis, Springer
Verlag, Berlin, 1983.
[LOU 94] LOUCHET J., “An evolutionary algorithm for physical motion analysis”, British
Machine Vision Conference, York, BMVA Press, pp. 701–710, September 1994.

14
Optimization in Signal and Image Processing
[LOU 95] LOUCHET J., PROVOT X. and CROCHEMORE D., “Evolutionary identiﬁcation
of cloth animation models”, Computer Animation and Simulation ’95, Proc of the
Eurographics Workshop, Maastricht, Springer, pp. 44–54, September 1995.
[LOU 96a] LOUCHET J. and BOCCARA M., CROCHEMORE D. and PROVOT X., “Building
new tools for synthetic image animation using evolutionary techniques”, Evolution
Artiﬁcielle/Artiﬁcial Evolution 95, Brest, September 1995, Springer Verlag, 1996.
[LOU 96b] LOUCHET J. and JIANG L., “An identiﬁcation tool to build physical models for
virtual reality”, IWSIP Manchester, UK, November 1996.
[LUC 91] LUCIANI A., JIMENEZ S., CADOZ C., FLORENS J.-L. and RAOULT O.,
“Computational physics: a modeler-simulator for animated physical objects”, EuroGraphics
’91 Conference, Vienna, Elsevier Science Ed., 1991.
[LUT 94] LUTTON E. and MARTINEZ P., “A genetic algorithm for the detection of 3D
geometric primitives in images”, 12th ICPR, Jerusalem, Israel, October 9-13, 1994/INRIA
technical report # 2210.
[MAU 94] MAURIN G. and GAGALOWICZ A., Localisation 3-D de sources de lumière
par utilisation des variations lentes d’illumination dans les images, rapport de stage
INRIA/ENSTA, EPR, 1994.
[PRA 04] PRADOS E. and FAUGERAS O., “Unifying approaches and removing unrealistic
assumptions in shape from shading: mathematics can help”, Proc. ECCV04, 2004.
[PET 91] PETROU M. and KITTLER J., “Optimal edge detector for ramp edges”, IEEE Pattern
Analysis and Machine Intelligence, vol. 13, no. 5, pp. 1483–1491, 1991.
[REC 94] RECHENBERG I., “Evolution strategy”, in ZURADA J.M., MARKS R.J. and
ROBINSON
C.J.
(Eds.),
Computational
Intelligence
Imitating
Life,
IEEE
Press,
pp. 147–159, 1994.
[ROU 81] O’ROURKE J., “Motion detection using Hough technique”, IEEE Conference on
Pattern Recognition and Image Processing, Dallas, pp. 82–87, 1981.
[REY 87] REYNOLDS C., “Flocks, herds and schools: a distributed behavioural model”,
Computer Graphics (Siggraph), vol. 21, no. 4, pp. 25–34, 1987.
[REE 83] REEVES W.T., “Particle systems – a technique for modelling a class of fuzzy
objects”, Computer Graphics (Siggraph), vol. 17 no. 3, pp. 359–376, 1983.
[ROT 92] ROTH G. and LEVINE M.D., “Geometric primitive extraction using a genetic
algorithm”, IEEE CVPR Conference, pp. 640–644, 1992.
[SER 99] SER P.K., CLIFFORD S., CHOY T. and SIU W.C., “Genetic algorithm for the
extraction of nonanalytic objects from multiple dimensional parameter space”, Computer
Vision and Image Understanding, vol. 73, no. 1, pp. 1–13, 1999.
[STA 02] STANCIULESCU B., Modèles particulaires actifs pour la synthèse d’images animées,
PhD Thesis, Joseph Fourier University, Grenoble, 2002.

Chapter 2
Artiﬁcial Evolution and the Parisian Approach.
Applications in the Processing of Signals
and Images
2.1. Introduction
This chapter aims to present the so-called Parisian approach and one of its
applications in the ﬁeld of signal and image processing. Modeling, particularly in the
ﬁelds of geometry and physics, has already been covered in Chapter 1. However,
this may also come into play in image processing applications. Optimization through
artiﬁcial evolution also plays a role in efﬁciently instantiating these models. In certain
cases, it might be better to decompose the model into its elementary entities as they
are easier to manipulate. Objects that have been manipulated by genetic operators
are no longer vectors of parameters that describe a complete model of a scene. The
elementary entities, however, take on a similar role. They only come together as a
whole when the representative model of the scene is being studied.
2.2. The Parisian approach for evolutionary algorithms
In traditional evolutionary algorithms, the aim is to ﬁnd the best possible solution
for a given problem. However, certain problems (NP-complete, or not) can turn out to
be extremely complex, especially if the search space is very large. To conceptualize
the problem the evolutionary algorithm is confronted with, it makes sense to look
at some examples. Let us assume that, for instance, we want to segment (isolate)
Chapter written by Pierre COLLET and Jean LOUCHET.
Optimization in Signal and Image Processing 
Edited by Patrick Siarry 
Copyright 0 
2009, ISTE Ltd 

16
Optimization in Signal and Image Processing
the different objects of an interior scene using a standard evolutionary algorithm.
Assuming a contour extraction algorithm is available, and that the genome of an
individual contains a representation of the set of objects to be segmented, the ﬁrst
problem to solve is to determine how many genes should be present in the genome
(i.e. how many objects the individual should ﬁnd in the scene). Assuming the number
of genes is ﬁxed at 10 and that all objects of the scene are simple mathematical ﬁgures
(straight line, ellipsis, triangle, trapezoid), a simple algorithm could randomly take 10
different shapes among these and choose their orientations, sizes, positions at random,
in order to create an individual.
The task of the evolutionary algorithm is then to evolve a population of such
individuals in order to maximize the intersection between the shapes encoded by
an individual and the outlines that have been provided by the contour extraction
algorithm. The search space is very large as for every gene of an individual (who
possesses 10 genes in total) four different shapes can be chosen. These shapes can be
centered on any of the 786,432 pixels of a 1024 × 768, and orientated on 360 degrees
(if orientation is discretized into degrees), with a homothetic factor that we may
choose to be an integer between 1 and 1,000. Even with such extreme simpliﬁcations
and discretizations, there are already 11 × 1012 possibilities, which do not even take
into account the basic dimensions of all considered shapes!
With this algorithm, the chances of ﬁnding an individual whose genes represent
the outlines of the scene in reasonable time are therefore extremely slim.
We might therefore wonder whether the problem has been expressed correctly.
Indeed, the search space is very large if every individual is supposed to ﬁnd a solution
for the entire scene. Would it therefore not be possible to introduce the old concept of
divide and conquer?
Conventional evolutionary algorithms follow a Pittsburgh approach similar to what
is used in classiﬁer systems [SMI 80] (in which every individual encodes all rules). In
the Michigan approach, however [HOL 78], an individual only encodes one single
rule. The Parisian approach of evolutionary algorithms suggests doing the same, by
encoding the solution with the help of a group of individuals.1 Similar to the Michigan
approach, the Parisian approach needs a complex retribution. If the problem ﬁts this
approach, beneﬁts can be signiﬁcant because principles apply which can be found in
data-level parallelism, emergence and in optimization paradigms such as ant colony
optimization (ACO) or particle swarm optimization (PSO).
1. This is a type of co-evolution. The term co-evolution, however, was marked by strong
connotations which made it impossible for the term to be used. The approach has therefore
been named after its “place of origin” similar to the approaches from Pittsburgh and Michigan.

Artiﬁcial Evolution and the Parisian Approach
17
We should note that in a recent article [WAL 06], Julian Miller and his team make a
connection between the Parisian approach and polyploid representations of individuals
where several alleles are used to encode a gene. In this article the results and the
acceleration that have been obtained due to a polyploid presentation are comparable
to those obtained by the Parisian approach. A possible conclusion might be that the
two approaches are in fact very similar.
For a detailed explanation of the Parisian approach concept, the example of the
original paper will be brieﬂy recalled, before showing how the algorithm ﬁnds other
developments in the ﬁeld of image and signal processing.
2.3. Applying the Parisian approach to inverse IFS problems
Iterated functions systems (IFS) [BAR 85, HAR 85, HUT 81] allow us to deﬁne
a fractal attractor (see Figure 2.1) if the starting point is situated within the attractor
deﬁned by the set of functions and if all functions of the set are contractant (i.e. the
distance between the image of point x of the attractor by any of the functions and the
central point of the attractor – known as the ﬁxed point – needs to be lower than the
distance between x and the ﬁxed point).
Figure 2.1. Examples of IFS attractors
Let us take a system of three functions f1, f2, f3 that take a point on the plan as a
parameter and a starting point P0(x0, y0) situated within in the attractor of the system
(f1, f2, f3), the construction of the attractor can then be carried out by the so-called
toss-coin algorithm:
P=P0
While (true) {
Choose f randomly among f1, f2, f3 // here is the toss-coin operation
P=f(P)
display P
}
The inverse problems for IFS consists of ﬁnding which system of functions has a
pre-determined target image as an attractor. This inverse problem has many important
applications in the ﬁeld of fractal compression.

18
Optimization in Signal and Image Processing
The standard evolutionary approach uses genetic programming, where individual
genomes consist of n trees (one per function). Now, the attractor is in fact a collage of
several attractors represented by each function [VRS 91]. It might now be interesting
to ﬁnd out if this complex inverse problem could be decomposed into a series of
subproblems that would individually be much easier to solve. If the problem is
subdivided into 10 subproblems that are each 1,000 times easier to solve than the
original problem, we obtain a 100x speedup.
In the case of IFS, rather than evolving individuals that contain several functions
that are supposed to encode the complete problem, we have tried in [COL 00] to evolve
a population of individuals that would each contain a single function, even if this
meant that several individuals (a sub-population) are needed for the evaluation of a
complete solution.
Several problems therefore need to be solved:
– which individuals should be chosen when evaluating the complete IFS?
– how can each individual be rewarded correctly depending on whether it has
participated in the complete IFS or not?
2.3.1. Choosing individuals for the evaluation process
Using the Parisian approach requires a sharing strategy; a way to preserve
diversity. In the case of IFS, the ﬁnal attractor being a collage of different attractors
that are deﬁned by all the functions that make up the system, the attractors need
to be distributed as efﬁciently as possible in the target. The dynamic niche sharing
technique [MIL 96] allows for the distribution of the population into different
ecological niches, based on a distance between the individuals and a maximum
number of niches. The distance can be calculated on the genotype or phenotype. In
the case of polar representation, IFS used in [COL 00] each function (i.e. individual)
has a ﬁxed point in the center of the attractor that it determines. The coordinates of
the ﬁxed point can be used to determine the minimal distance between the individuals
(radius around the ﬁxed point of individuals). The maximum number of niches
established by dynamic niche sharing was ﬁxed at n/2 (with n being the number of
individuals in a population) and the ﬁttest individual is selected by the best found
niche.
2.3.2. Retribution of individuals
In the Parisian approach, a number of n individuals cooperate to obtain a potential
solution to be evaluated. To the standard individual ﬁtness retribution, we must add
(for the individuals that have been chosen to form a complete IFS) a retribution on the
quality of the obtained attractor. IFS are remarkably well adapted to the evaluation of
every individual before producing a complete IFS. The IFS’s contracting properties

Artiﬁcial Evolution and the Parisian Approach
19
ensure that the image of a point in an attractor refers to another point of the attractor
and is convergent towards the center of the attractor. Therefore, if the IFS exactly
represents the target, the image of any point within the target must lie inside the target.
This property is present in each of the functions that are part of the IFS. It is therefore
possible to evaluate the beneﬁt of each (individual) function by checking if the target’s
image of points inside the target remains inside the target or not. The relationship
between these two forms of distribution (global and individual) is of course highly
empirical.
2.3.2.1. Individual retribution
In the standard retribution in evolutionary algorithms, where every individual is
evaluated separately, the individual retribution [COL 00] is calculated by function:
Rloc

wi

= F1

wi

+ F2

wi

+

1 −si

where wi is the function/individual of an IFS. F1(wi) is a ratio between the number
of pixels (#) inside target A and the number of pixels outside the target:
F1

wi

=
#

wi(A)  A

#

wi(A)  A

+ #

wi(A)\A

with a maximum of 1.
F2(wi) rewards the wi individual increasingly with the size of surface wi(A)  A
with a maximum of 1:
F2

wi

= #

wi(A)  A

#[A]
Finally, si is the estimated contraction factor of wi. (1 −si) is antagonist of
F2(wi), in order to avoid obtaining an identity function (which would maximize
F2(wi) without being of any interest).
Each individual now being rewarded by its contribution to the target, we must now
reward the team as a whole for the obtained attractor.
2.3.2.2. Global retribution
Once all individuals have been evaluated, an IFS Ω will be constructed made of
the N ﬁttest individuals of all niches. The attractor AΩ of this IFS is evaluated with
the help of the following two values:
InsideΩ = #[AΩ
 A]
#[A]
proportions of points of AΩ inside the target A
OutsideΩ = #[AΩ\A]
number of points of AΩ outside A

20
Optimization in Signal and Image Processing
Again the recipe of retribution is highly empirical. Rather than giving as a global
reward an absolute value determined by the quality of the attractor, the evaluation is a
comparison between the created attractor and that of the previous generation:
Rglob(n) =

InsideΩ(n) −InsideΩ(n−1)

−

OutsideΩ(n) −OutsideΩ(n−1)

+ α

Nb_functions

Ω(n)

−Nb_functions

Ω(n −1)

In the next step, the global retribution for every individual wi is calculated as:
Fitness

wi

= Rloc

wi

+ Rglob(n)
– If wi is already part of Ω(n −1), then:
Fitness

wi

= Rloc

wi

+ Rglob(n) + Rglob(n −1)
2
×
1
[age

wi

]2
where age(wi) represents the number of generations for which wi was part of the IFS.
– If wi has just been removed from the IFS (i.e. has participated to the IFS until
Ω(n −1) but does not participate in Ω(n)):
Fitness

wi

= Rloc

wi

−Rglob(n)
– If wi does not belong to the IFS:
Fitness

wi

= Rloc

wi

+ Rglob(n −1)
2
(the global reward added to each individual decreases throughout the generations).
In other words, the quality of the created IFS is redistributed to the entire
population. This process of redistribution considers the past of the individuals as well
as the number of generations in which this individual has been selected.
2.4. Results obtained on the inverse problems of IFS
Until [COL 00], the best solutions obtained by a standard approach were obtained
by [LUT 95] (see Figure 2.2). In order to compare the computational effort with
the Parisian approach (where every individual represents a function) it makes more
sense to count the number of evaluated functions. The standard GP algorithm uses a
generational replacement with a population of 30 individuals (30 children are created
per generation). Since 1,500 generations were required to obtain the best individual of
Figure 2.2, and since each individual had to encode ﬁve functions, this individual
necessitated the evaluation of 30 individuals ×5 functions ×1, 500 generations =
225,000 in order to be found.

Artiﬁcial Evolution and the Parisian Approach
21
Figure 2.2. Optimization of a 64×64 square with mixed IFS using standard Genetic
Programming. From left to right, we can see the target (full 64×64 square) and then,
the best individuals from generations 10, 100, 300 and 1,500. Size of the population:
30 individuals containing 5 functions each. The best individual on the right ﬁlls the
target by 91%. 4% of the pixels are out of the target
On the same problem and to obtain a similar result (Figure 2.3 left) the Parisian
approach of [COL 00] required only 49 generations and 60 individuals. In terms of the
number of evaluations, since a (60+30, i.e. 60 parents and 30 children per generation)
replacement strategy (borrowed from Evolutionary Strategies [BÄC 97]) was used, the
necessary number of function (individual) evaluations was 60 + 49 × 30 = 1, 530 to
which 49 evaluations of complete IFS must be added.
Figure 2.3. Left: optimization of the same 64×64 square with polar IFS, by genetic
programming using the Parisian approach. The best IFS contains 14 individuals and is
obtained after 49 generations of only 60 individuals. It ﬁlls in 85% of the target and 0 pixels
are outside the target. Right: the dolphin (a more complex form) needed 400 generations of 60
individuals and is composed of 13 individuals. The dolphin is ﬁlled in up to 60% and 0.36% of
the pixels are outside the target
Given that on average 50% of the individuals participated in the IFS (which is
overestimated, as the best IFS of the 49th generation only required 14 individuals)
these 49 IFS evaluations amounted to another 49 × 30 = 1470 evaluations (i.e. nearly
as many evaluations as for the personal evaluation of each individual).
Overall the Parisian approach required around 3,000 evaluations, compared to the
225,000 evaluations of the standard approach, which is a difference of nearly two
orders of magnitude.
This allows us to envisage an approximation of more complex shapes with a
reasonable level of precision (e.g. dolphin in Figure 2.3 right) that would not be
obtainable with a traditional algorithm.

22
Optimization in Signal and Image Processing
Figure 2.4. Optimization of a 64×64 square with a genetic algorithm that was
used to optimize 24 real parameters for 4 functions. This result was obtained after
evaluating 800,000 functions (20 individuals encoding 4 functions for 10,000 generations).
The square is ﬁlled by 88.4% and 17% of the pixels are located outside the target
2.5. Conclusion on the usage of the Parisian approach for inverse IFS problems
Two main obstacles arise if a standard method is to be used on the inverse IFS
problem:
– the search space is very large, as the individuals must ﬁnd a complete solution to
the problem;
– there is no easy way of ﬁnding out how many functions an individual will need.
For the square, a simple solution exists with four individuals. Even though this
solution is known, it is very difﬁcult to obtain with a genetic algorithm [GOE 94] (see
Figure 2.4). Five functions were empirically chosen for the standard GP approach of
Figure 2.2. As the problem is well adapted to the Parisian approach, this approach
allows us to decompose the problem into subproblems that can be solved much
more easily than the original problem. Furthermore, the number of functions used is
obtained dynamically and automatically.
However, the price to be paid is an even higher complexity of the algorithm with:
– two evaluation functions (a local and a global function) that must be skillfully
intertwined;
– a strategy that maintains the diversity and sharing of ecological niches;
– a (μ + λ) replacement, borrowed from evolutionary strategies, that preserves a
large number of parents in the following generation. These parents could also be kept
due to a strong elitist strategy (see the ﬂy algorithm later on in this chapter).
Despite these disadvantages, the results obtained with the Parisian approach are
worthwhile.
According to Julian Miller et al. [WAL 06] this approach is very similar to the
polyploid approach (every gene is represented by several alleles that are or are not
all considered in the production of the phenotype). Many living beings (humans

Artiﬁcial Evolution and the Parisian Approach
23
included) have diploid chromosomes. This phenomenon is very common amongst
plants. Many of them are even triploid (bananas, apples), tetraploid (coffee, cotton),
hexaploid (wheat), etc.
From an evolutionary point of view, the real advantage that polyploidy has
over haploidy is unknown (otherwise it would be used even more often in artiﬁcial
evolution). In a recent PhD on this topic [TOU 04], it is observed that in two
comparable haploid and diploid contexts for a form of yeast, the mutation rate was
18 times higher in the haploid context. This may show that the diploid phase would
allow for fewer modiﬁcations even though it allows for more variety in the nature of
these modiﬁcations. The two last sentences of this thesis are the following
This thesis has shown among other issues that the diploid phase allows for both
a large genomic ﬂexibility that would favor the creativity that is essential for
the evolutionary process, while ensuring enough stability to avoid a too large
mutation rate that would be disruptive for the species. Evolution is therefore the
result of a fair equilibrium between creativity and stability.
The Parisian approach was developed in order to divide a complex problem into
independent subproblems that would be easier to solve. If this approach proves to be
very similar to a polyploid approach, this would shed new light on the advantage of
using polyploidy.
2.6. Collective representation: the Parisian approach and the Fly algorithm
In the introduction, we saw an example of how the principles of evolutionary
computation may give new life to older image processing techniques based on model
optimization methods. In the following sections, we will get a look at how the
Parisian approach may also be applied to image processing, through the example
given by the Fly algorithm. While in many cases the image or image sequence
to be processed can be viewed as a simple addition of separate entities, each one
corresponding to a particular point in the model’s parameter space, there are many
cases where this is untrue. It may then be more efﬁcient to exploit the model’s rather
than the image’s separability, and describe the image as the result of the combination
of a subset of suitable parameter space. This is the basic idea of the Parisian approach
in evolutionary computation: using evolutionary methods the normal way with
the usual tools, but with a major change in their semantics. Each individual in the
parameter space now only represents a small part of the problem to be solved: rather
than looking after one particular point in the parameter space, we are now interested
in the resulting population as a whole.
2.6.1. The principles
Stereovision is deﬁned as the construction of a 3D model of a scene, using the
images delivered by two cameras with well known geometric characteristics. Most

24
Optimization in Signal and Image Processing
classical stereovision methods are based on image segmentation, primitive extraction
and matching. They may provide detailed accurate scene descriptions but at a high
computational cost. Voting methods described in Chapter 1 are generally not relevant
due to the complexity of the image primitives involved. Moreover, the accuracy they
are capable of is seldom a requirement in robotics applications – in particular in the
ﬁeld of mobile robotics where obstacle avoidance and trajectory planning rarely need
such a high precision in scene primitive location.
The main idea here is to represent the scene using a population of 3D points and
evolve them in such a way that they are likely to concentrate on the visible surfaces
of the objects present in the scene. Here, using the Parisian approach means that
the algorithm’s result be expressed as a large set of simple primitives: points in the
3D space, rather than a smaller set of more complex primitives. This principle of
simplicity2 is followed even into the ﬁtness function – which has a major contribution
to the total computation load.
Basically, the method consists in creating a population of points (the “ﬂies”)
randomly spread over the common ﬁeld of vision of the cameras, then evolve this
population so that the points tend to locate themselves on the surfaces of the objects
we are trying to locate spatially. To this end, all the cameras’ geometric parameters
being known, the algorithm will calculate for each ﬂy in the population, a ﬁtness
value which estimates the degree of similarity between the ﬂy’s calculated projections
into each camera image.
A ﬂy is deﬁned as a point in space, with coordinates (x, y, z). As we are using
(at least) two cameras, each ﬂy will project onto the left camera image as a point
with coordinates (xL, yL) and similarly as (xR, yR) into the right camera. Using
the cameras’ calibration parameters, it is an easy task to calculate xL, yL, xR, yR
according to x, y, z using the projective geometry formulas:
⎛
⎝
xL
yL
1
⎞
⎠≡FL
⎛
⎜
⎜
⎝
x
y
z
1
⎞
⎟
⎟
⎠,
⎛
⎝
xR
yR
1
⎞
⎠≡FR
⎛
⎜
⎜
⎝
x
y
z
1
⎞
⎟
⎟
⎠
where FL and FR are the (3, 4) projective matrices of the left and right cameras.
If a ﬂy is located at the surface of an object, then the image pixels where it projects
into each camera image will usually have similar attributes: gray level, color, local
2. Eberhart’s particle swarms [EBE 95] are another optimization tool inspired by the “artiﬁcial
life” techniques, which also exploits the separability of the optimization problem in a similar
way as the Fly algorithm.

Artiﬁcial Evolution and the Parisian Approach
25
texture, etc.3 Conversely, if the ﬂy is not on a visible object surface, how much its
projections will look like one another will randomly depend on the textural properties
of the ﬁrst objects aligned with the ﬂy and each camera’s focal point. The fundamental
idea of the algorithm is to translate this principle into a ﬁtness function able to control
the ﬂy population’s evolution process successfully.
Figure 2.5. Pixels b1 and b2, projections of ﬂy B, have identical gray levels. Pixels
a1 and a2, projections of ﬂy A, generally have different gray levels, because they
correspond to two different points of the visible surface of the object
The ﬁtness function should be chosen in order to efﬁciently recognize the degree
of similarity of the ﬂies’ projections and if possible use some neighborhood-related
properties (contrast, texture) not to be fooled by apparently similar pixel gray values.
For example, a ﬁtness function only based on the identity of the projections’ gray
levels, would give undesirable high ﬁtness values to ﬂies located in front of a uniform
object, even if far from its surface. To get around this, the ﬁtness function includes a
normalization term at its numerator:
ﬁtness(indiv) =
G

(i,j)∈N

L

xL + i, yL + j

−R

xR + i, yR + j
2
where
– L(xL + i, yL + j) is the gray level of the left image at pixel (xL + i, yL + j);
– N is a small neighborhood used to calculate the ﬂy’s projections’ likeness;
– usual techniques are used to avoid division by zero.
3. Specular reﬂections and, more generally, any important discrepancy between the real
photometric properties of the object’s surface and the default Lambertian reﬂectance model,
which is the basis of the assumption that a given point in the scene will appear with the same
gray level independently of the point of view, may perturb this criterion and alter the algorithm’s
performance; however this is equally true with most surface-based stereovision algorithms.

26
Optimization in Signal and Image Processing
The denominator evaluates the square deviation between the pixel conﬁgurations
around the two projections of the ﬂy. Thus, a ﬂy whose projections are similar will
give rise to a small denominator value and a high ﬁtness value.
The normalization term G gives a measurement of the contrast around the current
pixel of the reference image; it has to achieve a good balance between giving too high
a ﬁtness value to ﬂies in front of a uniform object, or only giving a high ﬁtness value
to ﬂies in front of a contrasted contour. It has been experimentally determined that a
good trade-off is obtained with:
G =
 
(i,j)∈N

L

xL + i, yL + j

−L

xL, yL
2
Moreover, the evaluation function includes a correction term to eliminate the
constant by subtracting a local average gray level.
Figure 2.6. The ﬂy population is initialized inside the
truncated intersection of the camera vision cones
Let us now examine the evolution operators for the (x, y, z) genome.
The initial population is created inside the intersection of the vision cones of
the two cameras, with optional maximum and minimum clipping distances (see
Figure 2.6). An individual’s chromosome is the triplet (x, y, z) of its coordinates, Oz
corresponding to the left camera’s (used as the reference camera) axis. The ﬂies are
given a uniform distribution in z−1 beyond the minimal clipping distance, which
gives an initial density which decreases with depth.

Artiﬁcial Evolution and the Parisian Approach
27
As the calibration parameters of the cameras are known, the coordinates of each
ﬂy’s projection pixels are calculated and the ﬁtness is evaluated. The main genetic
operators are the standard ones found in evolution strategies: Gaussian mutation
and barycentric crossover. In the following examples, the selection process is a
2-tournament. As signiﬁcant populations are normally used, somewhat to compensate
for the simplicity of the individuals, an interesting speed improvement is obtained
by calculating a percentile on a random sample of the population and using it as a
threshold, without any measurable loss of performance.
A 2D sharing function is use to reduce the ﬁtness values of ﬂies that project into
crowded areas in the images [BOU 01]. A 2D ﬂy projection density is calculated and
used into the calculation of a sharing penalty.
2.6.2. Results on real images
2.6.2.1. Classical stereovision
The 760 × 560 stereo pair used in the following examples was obtained using a
monochrome camera with a sideways motion. The genetic parameters are similar to
the preceding ones: 5,000 individuals, 100 generations 40% mutation probability, 10%
crossover, sharing radius 2, sharing coefﬁcient 0.3.
On the results image, it is possible to see the two sides of the chest, a part of the
wall on the right and the front half of the round stool.
Figure 2.7. Left and right images
Genetic algorithms and evolution strategies are often seen as slow processes,
unable to cope with real-time applications. In reality, things are much more subtle:
– “real time” may not be reduced to a question of execution speed. It would
be more realistic to see it as the ability of an algorithm to exploit the ﬂow of
input data and adapt itself to the response time needed by the ﬁnal user. Rather
interestingly, evolutionary strategies are capable of adaptation, and may work on a
problem described by a ﬁtness function and accept the ﬁtness function being modiﬁed
and updated during execution [SAL 97]; this is far from being a common property
among optimization methods.

28
Optimization in Signal and Image Processing
Figure 2.8. Result, seen from above (384×288 image)
Figure 2.9. Average ﬁtness of a population of 5,000 individuals depending on
the number of generations, for three combinations of growth and mutation rates
(60%/0%; 50%/10% and 40%/20%)
– the execution speed of an evolution strategy depends to a large extent on the
computational complexity of the ﬁtness function – which is quite simple in this case.
This is why we worked at extending the algorithm to the processing of stereo image
sequences, with a special interest in sequences taken by moving cameras, as it is the
case in mobile robotics. The results show that if motion is slow enough, convergence is
signiﬁcantly speeded up if at each new image pair, the population of ﬂies is initialized
using the result – the old positions of ﬂies – obtained at the previous step rather than
using purely random initial positions.

Artiﬁcial Evolution and the Parisian Approach
29
In order to cope with slightly faster motion, we experimented with an extension of
the ﬂies’ chromosomes, introducing three velocity parameters into each ﬂy’s genome.
This allows each ﬂy, now with 6 parameters, to keep a memory of its relative speed in
the robot’s coordinate system, in a similar way to a Markov process. This technique,
called the “dynamic ﬂies” technique, does not overload the ﬁtness calculation process,
as the three extra genes are not expressed in the ﬁtness, but are only used to update
each ﬂy’s position between successive frames more efﬁciently. On the other hand, the
genetic operators become more complex, with more variables to manipulate, which
results in a non-negligible “administrative overhead” in the algorithm. The interest
of dynamic ﬂies is very much dependent on the particular problem to be solved, in
particular the robot’s velocity and the computer’s speed, as the beneﬁts of convergence
in a smaller number of generations may be worse than annihilated by the extra cost
of running the operators – which suggests a sad metaphor in management sciences.
These methods are described in detail in [LOU 02].
In the next section, we will show some results of the ﬂy algorithm running in real
time on a basic laptop computer aboard a car equipped with two cameras4. This is an
application of the ﬂies to a project aimed at developing driving assistance systems, in
a framework of cooperation between the IMARA and COMPLEX teams in INRIA,
France. With each ﬂy is associated an “alarm value”, which is higher when the ﬂy’s
ﬁtness is high. The ﬂy is close to the collision trajectory and the ﬂy’s distance is low.
The alarm function depends on multiple adjustment parameters, e.g. such as the car’s
width. The sum of alert values is used to trigger an emergency braking command.
Figure 2.10. Real-time evolutionary image processing on a highway
(the image comes from a monochrome camera)
4. Images obtained by O. Pauplin within the framework of an INRIA project.

30
Optimization in Signal and Image Processing
Figure 2.11. A pedestrian
Figure 2.12. Image of alarm values (pedestrian)
2.6.3. Application to robotics: ﬂy-based robot planning
Classical navigation and obstacle avoidance methods used in robotics use as input
data, scene descriptions built by the stereo analysis process, usually 3D structures such
as polygons or facets. Here, the stereovision algorithm produces ﬂies. It has therefore
been objected that the task of converting the ﬂies into a more classical representation
usable as input data to existing navigation systems would cost more time than the
time saved thanks to the simplicity of the ﬂy algorithm. This is why we decided not to
reinvent the wheel, but to write new navigation algorithms with the same spirit as what
had already been developed, in particular concerning the resolution of robot blockage

Artiﬁcial Evolution and the Parisian Approach
31
situations, but re-think them so that they can directly use the ﬂies as input data.5
Boumaza integrated the complete algorithmic construction (ﬂy-based stereovision and
navigation) into an ad hoc robot simulator, aiming at the simulation of the complete
robot’s perception-action loop (Figures 2.13 and 2.14), containing:
– a double camera simulator (image synthesis);
– stereovision (the ﬂy algorithm);
– ﬂy-based planning algorithm;
– a simple robot platform kinematic simulator.
Figure 2.13. A synthetic image of the scene, as seen by the robot
As could be predicted, running the simulator showed that the robot frequently
encounters blockage situations where the controlling force (which acts on the robot’s
steering) oscillates around zero when the robot becomes trapped in a local potential
minimum.
To get around this difﬁculty, A. Boumaza adapted and implemented three classical
heuristic methods [ZEL 98, KOR 91] allowing us to generate a new steering strategy
which drives the robot out of the local minimum: the random walk method, the wall
following method and the harmonic function method.
5. The results presented in this section result from the PhD Thesis work of A. Boumaza at
INRIA/René Descartes University, Paris.

32
Optimization in Signal and Image Processing
Figure 2.14. The robot is facing a wall and a door. The bright
points represent the ﬂies found during the preceding steps
In the random walk method, secondary targets are created at random places
whenever a blockage situation is diagnosed. Then the robot uses what it knows about
obstacles to choose the secondary target with the smallest number of obstacles, ﬁrst
between itself and the robot, and then between itself and the main target [BOU 01].
This secondary target plays for a short time the role of the primary target (see Figures
2.15 and 2.16).
Figure 2.15. Getting around a wall obstacle and through a door using secondary targets

Artiﬁcial Evolution and the Parisian Approach
33
Figure 2.16. Direct trajectory without secondary targets
The wall following method only uses a change in the attraction vector, modiﬁed
so that the new resulting force be roughly parallel to the direction of the obstacle.
The harmonic function method iteratively builds a harmonic attraction function
with a Laplacian equal to zero except at the singularities given as initial conditions:
the target (where the function value is −1) and the regions with a high density of ﬂies
with a high ﬁtness (ﬁtness valued at +1). The robot uses the gradient of this constantly
updated function to control its direction along the steepest gradient lines (Figures 2.17
and 2.18).
Figure 2.17. Harmonic function used for obstacle avoidance

34
Optimization in Signal and Image Processing
Figure 2.18. Obstacle avoidance using the harmonic function
2.6.4. Sensor fusion
One type of sensor is generally unable to provide a mobile robot with enough
reliability in variable environments. Simultaneous use of different sensors, e.g. based
on different physical principles (cameras sensitive to different wavelengths, acoustic
sensors, odometers, etc.) requires us to be able to fuse different information sources.
Sensor fusion is a key element in a robot’s perception system. Many classical
approaches use statistical sensor fusion based on Bayes’ theorem; this technique
cannot be used here, as the ﬂies do not provide any probabilistic information. We
have to follow another line.
Here, we will make the classical distinction between exteroceptive sensors (giving
the robot information about the external world) and proprioceptive sensors (giving the
robot information about its own state and position). We will show how it is possible
to fuse exteroceptive and proprioceptive information by introducing them into the ﬂy
evolution strategy itself.
2.6.4.1. Exteroceptive sensor fusion: a multisensor ﬁtness
We created an extended ﬁtness function which now integrates the exteroceptive
sensors. In the example taken in this simulation, the exteroceptive sensors are a set of
six short-range ultrasonic sonars, with a ﬁeld angle of 15 degrees. In the simulator,
the sonar simulation simply uses the data from the Z-buffer taken out of the image
synthesis program to calculate the distances to obstacles. The smallest value inside the
detection angle is then disturbed by noise and returned as the simulated sonar’s output.
As discussed above, the lack of a probabilistic interpretation of the ﬂy data prevents
any strong mathematical justiﬁcation of a ﬁtness function which would integrate all

Artiﬁcial Evolution and the Parisian Approach
35
the exteroceptive sensors. However, the idea is to increase the ﬁtness of any ﬂy whose
position has been conﬁrmed by one or several extra sensors. Conversely, if a ﬂy has
been attributed a good ﬁtness by the vision process alone and has not been “seen”
by the ultrasonic sensors, then it would be hazardous to reduce its ﬁtness – it may
come e.g. from an obstacle covered with an acoustically absorbent material. Therefore
we deﬁne the multisensor ﬁtness function the following way: if a ﬂy has not been
conﬁrmed by any extra sensor, its ﬁtness will be left unchanged as given by the main
sensor (here the stereo cameras); if a ﬂy lies within the ﬁeld of vision of an extra
sensor and its properties (depth) are consistent with the sensor’s data, then its ﬁtness
will be increased by a given percentage B:
newﬁtness = oldﬁtness(1 + B)
Here, we take into account the poor angular resolution of acoustic sensors: it is
safer not to give a high ﬁtness value to a ﬂy which did not obtain a good enough
ﬁtness value from the vision sensor in the ﬁrst place.
In parallel to this inclusion of sonar sensor information into the ﬁtness function,
we also introduced an immigration operator, which creates new ﬂies in space with a
bias in favor of the sonars’ suggestions.
This method allows us to integrate an arbitrary number of exteroceptive sensors,
but is not suitable for proprioceptive sensors.
2.6.4.2. Proprioceptive sensor fusion
Proprioceptive sensors provide the robot with information about its own state, in
particular its position. If this information is missing, when the robot moves slowly
enough, the quasi-continuous ﬂy optimization process will still be able to follow the
scene’s relative motion. If the robot moves faster, even an approximate knowledge of
the robot’s position enables us to continuously update the ﬂies’ positions and speed
up the algorithm’s convergence signiﬁcantly.
The robot simulator thus integrates an odometric sensor simulation module. In the
real world, the robot trajectory planner would control the wheel rotation angles, which
are therefore perfectly known by the robot, but the actual robot’s trajectory differs from
the theoretical one due to external factors such as tire deformation, ground irregularity
and gliding. Thus, to simulate the robot’s trajectory we add a Gaussian noise to the
trajectory command given by the planner, but the sensor fusion algorithm only receives
the robot’s internal odometric information as given by the trajectory controller to the
robot motors. The fusion of odometric information is performed when updating the
ﬂies’ 3D coordinates. Our experiments showed the convergence of ﬂies, otherwise
achieved after about 10 generations, now only requires 2 or 3 generations when the
ﬂies’ position are updated, despite the poor precision of odometric information.

36
Optimization in Signal and Image Processing
In the following example, the robot in open loop mode was turning 1 degree
per frame, with only one algorithm generation being executed at each new frame.
Without proprioceptive fusion (Figure 2.19) there is a delay in the detection of the
close obstacle as the ﬂies tend to stay on the remote wall already detected with the
previous images. When introducing proprioceptive fusion (Figure 2.20), updating the
ﬂies’ positions allows faster convergence and a better detection of the closest obstacle.
Figure 2.19. Images N and N+5, without proprioceptive fusion
Figure 2.20. Images N an N+5, with proprioceptive fusion.
The ﬂies become stabilized on close obstacles

Artiﬁcial Evolution and the Parisian Approach
37
2.6.5. Artiﬁcial evolution and real time
It is a common belief that artiﬁcial evolution, in spite of its robustness, suffers
from poor speed and performance. It would be possible to analyze the reasons for this
reputation, but let us re-examine this question in light of the ﬂy algorithm.
The ﬁrst important characteristic of the ﬂy algorithm is that rather than reading
pixels sequentially as in most conventional image processing algorithms, the pixel
reading sequence is a random sequence of neighborhood readings. It is interesting to
note that the CMOS cameras now commercially available, allow an asynchronous,
random pixel reading from the photosensitive detectors6 and seem to be well adapted
to the execution of algorithms similar to the ﬂy algorithm in embedded applications.
In particular, it should be possible to get rid of the otherwise incompressible delay
before the next synchronization signal, as image data are permanently available and
updated by the incoming photon ﬂux.
camera
image storage
pixels
vision system
scene model
scene
data
trajectory 
planner
control 
signal
Figure 2.21. Classical architecture of a vision-trajectory planning system. If T is the image
renewal period, a classical vision algorithm synchronized to the camera will use input data
with a delay up to 2T from the real world events, and (independently of its speed) the vision’s
output is a scene model which has to be completed before the planner is able to use it to
calculate control signals. The resulting delay is therefore at least equal to 3T
Second, unlike in the classical scene analysis approaches (see Figure 2.21), where
a conventional vision algorithm would ﬁrst end its work and then give the results to
the trajectory planner (ideally, exactly at the new frame synchro which enables it to
process the next frame7), here the ﬂy algorithm permanently maintains its results ﬁle
which the planner may read whenever it needs them, without having to wait until a
new synchronization signal. This is a typical application of the concept of “anytime
algorithms”.
6. This is generally done by transferring blocks of image data corresponding to pixel
neighborhoods, typically 8 × 8 pixel blocks. Sadly, most commercial camera-computer
interfaces do not allow this random access mode, probably due to the absence of algorithms
needing it, due to the absence of camera interfaces allowing it.
7. This delicate problem of synchronization may still be worsened by the conventional
decomposition of the vision module itself into low-level (ﬁltering and primary segmentation)
and high-level processes (3D vision and scene analysis).

38
Optimization in Signal and Image Processing
Moreover, the convergence of the ﬂy algorithm is progressive, which means the
results of the calculation are usable at any stage of their development. The calculation
results are not lost when the scene undergoes a slight modiﬁcation or upon the delivery
of a new frame. This property is even enhanced by the use of proprioceptive data into
the quasi-continuous updating of the ﬂies’ positions.
For all the reasons above, the Parisian approach in image analysis should enable us
to be freed of the usual synchronization constraints, which otherwise result in delays
at best equal to three periods of image acquisition. Here, image processing is done
through requests to the camera and requires no digital ﬁltering or image segmentation.
Similarly, the navigation system associated with the ﬂy algorithm uses asynchronous
requests to the vision system and thus exploits the anytime properties of the algorithm.
The beneﬁts that can be anticipated are:
– fast execution without any delay resulting from a clocked vision system;
– programming ﬂexibility in the framework of a given algorithmic architecture;
– progressive adaptation of the process to the apparent velocities of objects in the
scene;
– direct data fusion from other sensors (odometric, acoustic, etc.);
– optimal exploitation of the intrinsic asynchronism of CMOS imagers, which is
not achievable with classical “data ﬂow” algorithms.
It seems therefore that artiﬁcial evolution algorithms may provide convenient and
powerful solutions to some real-time applications:
– Evolutionary algorithms can accept modiﬁcations of the ﬁtness function even
while the algorithm is running. This is precisely what “real time” refers to: the ability
of a system to exploit data as soon as they are available, and permanently keep fresh,
updated results at the user’s disposal, in a quasi-continuous way.
– Conventional image processing and stereovision algorithms, based on image
segmentation, need a complete image scan before they are able to begin to sequentially
process the image and eventually deliver a result. Here, segmentation-free image
processing is compliant with continuous input data refreshing during its execution
and always uses fresh data. This is particularly interesting with CMOS cameras which
allow asynchronous access to pixels.
– The results of the ﬂy algorithm are continuously updated (at the fast pace of
generations), which allows the user (which can be e.g. a robot trajectory planner) to
react faster to new events.
– Usually with evolutionary algorithms, the heaviest part of calculation is the
calculation of the ﬁtness function. Here, the Parisian approach allows us to split up
the representation into many extremely simple primitives, which results in a simple
ﬁtness function and a globally fast algorithm.

Artiﬁcial Evolution and the Parisian Approach
39
The usual way to write an image processing algorithm is to custom design
an arrangement of existing operators, in a speciﬁc way to the application. Here,
the algorithm’s structure is essentially independent from the application, most
of the problem-speciﬁc knowledge is concentrated in its representation in the
ﬁtness function; apart from the ﬁtness function, there is not much to modify if the
algorithm code has to be transferred to another image processing application. Rather
interestingly in our case, while general metaknowledge is classically built into the
evolutionary resolution engine and on the other side, the image processing-speciﬁc
knowledge is written into a ﬁtness function, some of the intermediate, “robotics”
knowledge about proprioceptive sensor fusion or a priori knowledge about the
environment8 is coded at a third place, into the genetic operators. This can be
summarized in the following table.
CCD + conventional algorithm
CMOS + Parisian approach
Image sensor
Delay between acquisition
and restitution.
Asynchronous pixel
access.
Image processing
(input)
Segmentation requires a
complete image and must wait
until the end of the next cycle.
Reads pixels whenever
it is needed.
Image processing
(output)
Cannot deliver any result
before end of cycle.
Results available at
any time.
Planner
Must wait until end of the
current image processing cycle.
Saves two acquisition
cycles.
Table 2.1. Comparison of the classical vision and the Parisian approach
2.6.6. Conclusion about the ﬂy algorithm
The principles of the Parisian approach described in the beginning of this chapter
allowed us to build an evolutionary strategy able to provide a rough 3D description of
a scene from stereo image pairs. Unlike conventional approaches to stereovision, no
preliminary segmentation is required, and the precision of output results continuously
improves, which is of interest to roboticians as it provides a welcome ﬂexibility in the
trade-off between speed and accuracy.
In Chapter 1, we showed how the Hough transform, where each pixel or image
segment votes for a subspace of a parameter space, could be revisited in the light
of evolutionary computation. Here, it is an evolving population that explores this
8. We showed that the optimal crossover rate essentially depends on the nature of the physical
environment and is higher in the presence of manmade objects with planar surfaces.

40
Optimization in Signal and Image Processing
parameter space, each individual testing a pixel-level predicate. There is no obvious,
general rule to say which approach would be the most efﬁcient in all cases, but in
the example of ﬂies where each individual is represented by a chromosome with only
three parameters, a vote approach would obviously be way more costly. The main
advantages over the vote approach are:
– fast processing9 thanks to the non-exhaustive search;
– no preliminary segmentation required – this allows us to use the algorithm on
poorly structured scenes;
– progressive accumulation of knowledge about the scene, allowing exploitation
of results at any stage and an open trade-off between speed and precision, without any
intervention on the algorithm;
– real-time compliance as the ﬁtness function that contains all the useful
information about the scene can be updated at any time while the algorithm is running.
2.7. Conclusion
Thanks to its ability to speed up optimization by several orders of magnitude, the
Parisian approach opens the door to evolutionary computation into domains already
considered as solved using more conventional methods, as we saw it in the example
of obstacle detection.
Moreover, the Parisian approach may be a ﬁrst step to echo the presence of
polyploid chromosomes in natural life: these composite chromosomes might allow
greater variety in the possible reconﬁgurations, but also allow us to decompose
problems into subproblems that are easier to solve, in the way the Parisian approach
does.
In the case of image processing, the radically innovative nature of the evolutionary
approach allows us to anticipate several interesting research avenues: extending
the traditional application ﬁeld of traditional parametric approaches as we saw in
Chapter 1 with the Hough transform and its extensions, or through the introduction
of a frankly different programming style in image processing. The intrinsically
asynchronous character of artiﬁcial evolution opens up possibilities of real-time
applications which have been little explored as yet. Another interesting aspect
of evolutionary image processing is the explicit reference to a model, in a way
reminiscent of knowledge-based systems. This allows us to override some of the
traditional image processing gear (segmentation operators) and open the way to new
applications and new techniques using more general (and sometimes more efﬁcient)
tools.
9. Processing time depends on the population size rather than the image size.

Artiﬁcial Evolution and the Parisian Approach
41
In addition to this, we could address other applications in computer vision using
evolutionary approaches. In particular, identifying mechanical (physically-based)
animation models from image sequences, an operation reminiscent of reverse
engineering, is a highly complex problem which could only be solved using
multi-objective evolution strategies. These techniques allowed us to infer the
mechanical internal parameters of animated objects from image data only: passive
mechanical structures [LOU 95, LOU 96a], turbulent ﬂuid ﬂows [LOU 96b] and
motion-controlled mechanical structures (“muscle models”) [STA 02, STA 03].
Now, the asset is no so much to ﬁnd some (marginal or not) improvement to the
performance of computer vision algorithms, but actually to question the limits of the
semantic domain of what is usually called “image analysis” or “computer vision”.
2.8. Acknowledgements
We express our special thanks to Amine Boumaza, Baudoin Coppieters de Gibson,
Anders Ekman, Jean-Loup Florens, Maud Guyon, Marie-Jeanne Lesot, Annie Luciani,
Evelyne Lutton, Olivier Pauplin, Marc Schoenauer and Bogdan Stanciulescu, who
contributed the ideas, algorithms and results described and quoted in this chapter.
2.9. Bibliography
[BÄC 97] BÄCK T., HAMMEL U. and SCHWEFEL H.-P., “Evolutionary computation:
comments on the history and current state”, Transactions on Evolutionary Computation,
vol. 1, no. 1, pp. 3–17, 1997.
[BAR 85] BARNSLEY M. and DEMKO S., “Iterated function system and the global
construction of fractals”, Proceedings of the Royal Society, vol. A-399, pp. 243–245, 1985.
[BOU 01] BOUMAZA A. and LOUCHET J., “Using real-time evolution in robotics”,
EVOIASP2001, Applications of Evolutionary Computing, Como, Italy, vol. Springer LNCS
2037, pp. 288–297, 2001.
[COL 99] COLLET P., LUTTON E., RAYNAL F. and SCHOENAUER M., “Individual GP: an
alternative viewpoint for the resolution of complex problems”, in BANZHAF W., DAIDA
J., EIBEN A.E., GARZON M.H., HONAVAR V., JAKIELA M. and SMITH R.E. (Eds.),
Proceedings of the Genetic and Evolutionary Computation Conference (GECCO-1999),
Morgan Kaufmann, pp. 974–981, 1999.
[COL 00] COLLET P., LUTTON E., RAYNAL F. and SCHOENAUER M., “Polar IFS + Parisian
Genetic Programming = Efﬁcient IFS inverse problem solving”, Genetic Programming and
Evolvable Machines, vol. 1, pp. 339–361, 2000.
[EBE 95] EBERHART R.C. and KENNEDY J., “A new optimiser using particles swarm
theory”, Proc. 6th Int. Symposium on Micro Machine and Human Science, Nagoya, Japon,
IEEE service Centre, Piscataway, NJ, pp. 39–43, 1995.
[GOE 94] GOERTZEL B., “Fractal image compression with genetic algorithms”, Complexity
International, vol. 1, 1994.

42
Optimization in Signal and Image Processing
[HAR 85] HARDIN D.P., Hyperbolic iterated function systems and applications, PhD Thesis,
1985.
[HOL 78] HOLLAND J. and REITMAN J., “Cognitive systems based on adaptive algorithms”,
Pattern-Directed Inference Systems, Academic Press, 1978.
[HUT 81] HUTCHINSON J., “Fractals and self-similarity”, Indiana University Journal of
Mathematics, vol. 30, no. 5, pp. 713–747, 1981.
[KOR 91] KOREN Y. and BORENSTEIN J., “Potential ﬁeld methods and their inherent
limitations for mobile robot navigation”, Proc. of the IEEE Conf. on Robotics and
Automation ICRA91, pp. 1398–1404, April 1991.
[LOU 95] LOUCHET J., PROVOT X. and CROCHEMORE D., “Evolutionary identiﬁcation
of cloth animation models”, Computer Animation and Simulation ’95, Proc. of the
Eurographics Workshop, Maastricht, Netherlands, Springer, pp. 44–54, September 1995.
[LOU 96a] LOUCHET J., BOCCARA M., CROCHEMORE D. and PROVOT X., “Building new
tools for synthetic image animation using evolutionary techniques”, Evolution Artiﬁcielle
95, Brest, France, Springer, September 1996.
[LOU 96b] LOUCHET J. and JIANG L., “An identiﬁcation tool to build physical models for
virtual reality”, Proc. IWISP96 International Workshop on Image and Signal Processing,
Manchester, UK, Elsevier, pp. 669–672, 1996.
[LOU 02] LOUCHET J., GUYON M., LESOT M.-J. and BOUMAZA A., “L’algorithme des
mouches: apprendre une forme par évolution artiﬁcielle. Application en vision robotique”,
Extraction des Connaissances et Apprentissage, Hermes, January 2002.
[LUT 95] LUTTON E., VÉHEL J.L., CRETIN G., GLEVAREC P. and ROLL C., “Mixed IFS:
resolution of the inverse problem using genetic programming”, Complex Systems, vol. 9,
pp. 375–398, 1995.
[MIL 96] MILLER B.L. and SHAW M.J., “Genetic algorithms with dynamic niche
sharing for multimodal function optimization”, International Conference on Evolutionary
Computation, pp. 786–791, 1996.
[SAL 97] SALOMON R. and EGGENBERGER P., “Adaptation on the evolutionary time scale:
a working hypothesis and basic experiments”, EA’97, Nîmes, France, vol. Springer LNCS
1363, pp. 251–262, 1997.
[SMI 80] SMITH S.F., A learning system based on genetic adaptive algorithms, PhD Thesis,
University of Pittsburgh, 1980.
[STA 02] STANCIULESCU B., Identiﬁcation de modèles physiques et de contrôleurs en
animation, PhD Thesis, INPG, June 2002.
[STA 03] STANCIULESCU B., FLORENS J.-L., LUCIANI A. and LOUCHET J., “Physical
modeling framework for robotics applications”, IEEE Systems, Man and Cybernetics
Conference, Washington DC, October 2003.
[TOU 04] TOURRETTE Y., Sélection et analyse de remaniements chromosomiques chez
Saccharomyces cerevisiae en contexte diploïde: origine des délétions et des translocations
réciproques, PhD Thesis, Louis Pasteur University, 2004.

Artiﬁcial Evolution and the Parisian Approach
43
[VRS 91] VRSCAY E.R., “Moment and collage methods for the inverse problem of fractal
construction with iterated function systems”, in PEITGEN H.-O., HENRIQUES J.M. and
PENEDO L.F. (Eds.), Fractal 90 Conference, Fractals in the Fundamental and Applied
Sciences, North Holland, pp. 271–289, 1991.
[WAL 06] WALKER J., MILLER J. and CAVILL R., “A multi-chromosome approach to
standard and embedded cartesian genetic programming”, Gecco’06, Seattle, 2006.
[ZEL 98] ZELEK J.S., “Complete real-time path planning during sensor-based discovery”,
IEEE RSJ Int. Conf. on Intelligent Robots and Systems, 1998.

 
 
Chapter 3 
Wavelets and Fractals for  
Signal and Image Analysis 
3.1. Introduction  
The determination of singularities and of scaling laws by multifractal analysis 
(which uses multiresolution techniques based on the concept of wavelets) can be 
found in more and more applications in the fields of natural science, engineering and 
economics.  
In this chapter we highlight the different multifractal methods by analyzing 1D 
and 2D generic signals; the self-similarity of fractals using wavelet transform 
modulus maxima has allowed scientists to determine the distribution of the 
singularities of the very different complex signals which can be found in the 
domains of material physics, biology and medicine. 
The different themes in the chapter have been chosen for their relevance in 
relation to the further improvements and advances in scientific know-how as well as 
for the improvement in the quality of results that have been obtained during 
scientific experiments. The aim of including these themes is to help the reader better 
understand and apply certain purely mathematical theories which are normally 
difficult to carry out. 
                              
Chapter written by Abdeldjalil OUAHABI and Djedjiga AIT AOUIT. 
Optimization in Signal and Image Processing 
Edited by Patrick Siarry 
Copyright 0 
2009, ISTE Ltd 

46     Optimization in Signal and Image Processing 
3.2. Some general points on fractals  
They exist everywhere around us. These luminous, unusual, beautiful shapes are 
known as fractals. 
3.2.1. Fractals and paradox 
It is not easy to give a correct definition of fractals. Nevertheless, in terms of 
etymology the word fractal leads us to the idea of fractus meaning irregular or 
broken shape [MAN 82]. 
The analysis of unusual mathematical objects such as curves of infinite length, 
which possess a finite area, or non-derivable continuous functions, has considerably 
developed thanks to the work carried out by Mandelbrot, the founder of fractal 
geometry. 
We can see fractal geometry around us in our everyday lives, in nature, in 
biology or in physics. Generally speaking, the term fractal is used for mathematical 
objects whose shape and complexity are governed by the inherent omnipresence of 
irregularities. 
The scale invariance and the self-similarity of an object or signal must be taken 
into consideration in order to facilitate the exploration of fractals. An object is said 
to be scale-invariant when it is left unchanged following expansion; it is thus 
symmetric for this transformation process. Consequently, this property means that 
the change in the observation scale does not change the statistics which have been 
calculated from the signal. In other words, the general shape of the object remains 
the same regardless of the change in scale. 
Unlike a Euclidean geometric figure, a fractal does not possess any scale or any 
characteristic of size. Each portion of the fractal reproduces the general shape of the 
signal regardless of the scale enlargement: this is the property known as self-
similarity. This idea means that the information which comes from observation of 
the fractal is independent of the resolution at which the fractal’s measurement is 
taken.  
Fractal analysis was borne from the need to have a tool which could be adapted 
to the study of complex and irregular natural or artificial phenomena. 
For the most part, the recent success of (multi)fractal analysis in the optimization 
of signal and image processing does not stem from the fact that the signals which are 
studied are fractal. In reality, and with some rare exceptions, the signals do not 
possess any self-similarity nor any attributes which are normally associated with 

Wavelets and Fractals for Signal and Image Analysis    47 
fractal objects (except the idea of irregularity on all scales). The development of the 
methods used in fractal analysis enables scientists to describe the structure of the 
singularity of complex structures in fine detail. The development of these methods 
has also enabled scientists to study models which are the result of fractal analysis 
and which have led to significant progress in areas such as turbulence, growth 
models, finance, vibration phenomena, material rupture, biomedical signals, satellite 
images, earthquakes, etc. 
3.2.2. Fractal sets and self-similarity 
A set 
R
A
n

is said to be self-similar if the combination of unrelated sub-sets 
k
A
A ,...
1
can be obtained from A by expansion, translation and rotation. This notion 
of self-similarity often implies an infinite multiplication of points, which leads to the 
creation of irregular structures. The Von Koch curve and Cantor’s triadic set are 
simple examples of these irregular structures. 
DEFINITION 3.1.– Let f be a signal with compact support A. A signal f is self-similar 
if unrelated sub-sets
k
A
A ,...
1
exist, so that the restriction of the graph of f to each 
point 
iA is an affine transformation of f. Thus a scale of
1
!
is
, a translation 
iu , a 
weight
ip and a constant ic exist, so that  

)
(
)
(
       
,
     
i
i
i
i
i
u
t
s
f
p
c
t
f
A
t


 


 
It is assumed that f is constant when it is outside these sets.  
Figures 3.2 and 3.4 illustrate that if f is self-similar then its wavelet 
transformation is also self-similar. 
3.2.2.1. The Von Koch snowflake  
The Von Koch curve was published in an article in 1904 which was entitled: “On 
a continuous curve without tangents, constructible from elementary geometry”, 
[VON 04]. The Von Koch curve is a fractal set which is obtained by recursively 
dividing a segment of length l into four segments of length l/3 as can be seen in 
Figure 3.1. The length of each subdivision is then multiplied by 4/3. The limit of this 
process of subdivision thus results in a curve with infinite length. 

48     Optimization in Signal and Image Processing 
Initiator  
l=1 
A 
B 
l =1/3 
N = 4
Generator 
1/3 
1/3 
1/3
1/3
l =1/81 
N =256 
The Von Koch curve after four iterations
. 
. 
. 
 
Figure 3.1. Some iterations of a subdivision of Von Koch curve. The Von Koch curve is a 
fractal which is the result of an infinite number of subdivisions 
 
 
Figure 3.2. The analysis of the Von Koch curve by wavelet transformation with
'
T
\

 
 
where T is a Gaussian function shows self-similarity 
Wavelet analysis detects the singularities of the signal and shows the initial 
pattern of the signal on a fine scale. This initial pattern is identically reproduced 
over and over again.  

Wavelets and Fractals for Signal and Image Analysis    49 
3.2.2.2. Cantor’s set  
The triadic set, introduced by Georg Cantor in 1884 [CAN 84], is created by 
recursively dividing intervals of size l into two intervals l/3 and a central hole, as can 
be seen in Figure 3.3. The triadic set which is the result of the limit of the 
subdivisions of the intervals is a set of points known as Cantor’s set. 
 
Stage 1 
 
Stage 2 
 
Stage 3 
 
Figure 3.3. Three iterations using Cantor’s set 
 
Figure 3.4. The analysis of the Cantor set signal  by wavelet transformation with
'
T
\

 
 
where T is a Gaussian function shows self-similarity 
3.2.3. Fractal dimension 
Determining the dimension is to establish the relationship between the way in 
which an object uses its space, and its scale variation. 
We tend to attribute whole dimensions to Euclidean geometric shapes: straight 
lines, circles, cubes, etc. 
Fractals possess complex topological properties, for example the Von Koch 
snowflake, which is of infinite length but which resides in a finitely sized square. 
Faced with these difficulties, Hausdorff came up with a new definition of dimension, 
which was based on the variations of the size of the sets during the change in scale. 

50     Optimization in Signal and Image Processing 
This idea became the basis of his fundamental work in 1919 [HAU 19], which was 
developed further in 1935 by Besicovitch [BES 35].  
3.2.3.1. Some definitions  
The fractal dimension (sometimes called the capacity dimension) can be defined 
as follows. 
DEFINITION 3.2.– Let A be a bounded part of Rn and N(s) the minimum number of 
balls of radius s which are necessary to cover A, then the fractal dimension can be 
defined as follows: 
s
s
N
d
s
log
)
(
log
inf
lim
0

 
o
 . 
The measurement of A is
d
s
s
s
N
M
)
(
sup
lim
0
o
 
. The measurement of A can be 
either finite or infinite. 
 
With this formula it is possible to identify the idea of the box-counting 
dimension which is very useful in certain applications (see Figure 3.6). 
Another definition which can be attributed to Hausdorff-Besicovitch gives a new 
perspective on the Hausdorff-Besicovitch dimension 
DEFINITION 3.3.– The Hausdorff-Besicovitch dimension dH-B is defined as the 
logarithmic quotient of the number of internal homothetic transformations N of an 
object, by the inverse proportion of this homothety (1/s): 
)
/
1
log(
)
log(
s
N
d
B
H
 

 
 
EXAMPLES 3.1  
 For a point: 
1
natural
with 
,0
)
log(
)1
log(
!
 
 

n
n
d
B
H
 
 For a segment, it is possible to establish two internal homothetic 
transformations of ratio 1:2:  
 

Wavelets and Fractals for Signal and Image Analysis    51 
log(2)
log(2)
1
1
log(2)
log 1/ 2
H
B
d
 



¬­

­

­

®
 
 For the Von Koch snowflake: 
At each iteration and from each side, four new similar sides are generated in a 
homothetic ratio of 1:3. 
log(4)
log(4)
1.2619
1
log(3)
log 1/ 3
H
B
d
 



¬­

­

­

®
 
 For Cantor’s triadic set 
At each iteration the current intervals are divided into two smaller intervals and a 
central hole in a homothetic ratio of 1:3. 
log(2)
log(2)
0.6309
1
log(3)
log 1/ 3
H
B
d
 



¬­

­

­

®
. 
 
 For the following fractal curve: 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 3.5. Calculation of the Hausdorff-Besicovitch dimension from any given fractal 
Generator: 
- homothetic ratio: r = 1:4 
- 8 affine transformations applied  
to the new segment => N= 8 segments 
 
 
 
log(8)
1.5
1
log(
)
1/ 4
H
B
d
 

 
. 
. 
. 
l=1 
Initiator  
A 
B 
l=1/4 

52     Optimization in Signal and Image Processing 
NOTE 3.1.– The fractal dimension of the Von Koch curve is not equal to its unit size 
as is the case for all traditional linear geometric shapes. In the case of Cantor’s set, 
the limit of its subdivisions is a set of points in an interval [0,1]. Therefore, the 
Euclidean dimension of a point is zero whilst the fractal dimension of this set is 
0.63. 
As a consequence, the fractal dimension is greater than the topological or 
Euclidean dimension. 
EXAMPLE 3.2.– The following application gives some insight into the principal use 
of the box-counting method by using linear regression to calculate the fractal 
dimension of a curve which represents a given physical phenomenon: 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 3.6. Calculation of the fractal dimension by linear regression. (a) Paving followed by 
the covering of the function by N boxes of size s; (b) evolution of log (N) vs log (1/s) 
EXAMPLE 3.3.– Estimation of the fractal dimension from rupture profile using the 
Fraclab toolbox. 
  
a) 
-0.69 
(s=2) 
-4.15  
( s=64) 
867
.0
15
.4
69
.0
1
4
 



 
 slope
d f
log 1/s
1 
2 
3 
log N 
o 
o 
 small s  
large s  
4 
b) 

Wavelets and Fractals for Signal and Image Analysis    53 
 
Figure 3.7. Rupture profile1 
 
Figure 3.8. Estimation of the fractal dimension using box-counting method df = 1.0082 
Some software for calculating the fractal dimension: 
1. Matlab FRACLAB toolbox (free); 
2. FDC (Fractal Dimension Calculator);  
3. HarFA (Harmonic and Fractal image Analyzer); 
4. BENOIT Fractal Analysis System; 
5. 
FRACTALYSE. 
                              
1. After a number of stress cycles due to strains, a material ends up breaking and two rupture surfaces (or 
rupture faces) are recovered. 
 Log s 

54     Optimization in Signal and Image Processing 
3.3. Multifractal analysis of signals 
The objective of multifractal analysis is to describe and analyze phenomena 
whose regularity, which is measured by a particular indicator (the Hölder exponent), 
can vary from one point to another. Thus, multifractal analysis provides both a local 
and global description of a signal’s singularity; a local description is obtained using 
the Hölder exponent, and the global description is obtained thanks to multifractal 
spectra. The multifractal spectra geometrically and statistically characterize the 
distribution of singularities which are present on the signal’s support. 
3.3.1. Regularity 
EXAMPLE 3.4.– The Weierstrass function: self-similarity and singularities  
 
 
 
 
 
 
 
 
 
 
Figure 3.9. A signal generated by the Weierstrass function where D= 0.9 and ȕ = 0.3: (a) the 
complete signal; (b) an extraction from a part of this signal; (c) its WT modulus 
The signal
¦
 
 
10
1
)
2
cos(
)
(
k
k
k
t
t
f
SE
D
, in which D , and E  are real numbers 
and E is odd (under the condition
DE
D



1
0
), is a continuous signal which is 
non-derivable. Its Hölder function is constant. Figure 3.9(b) shows the self-
similarity of the signal; the shape of the signal remains the same regardless of the 
scale of the representation used. Figure 3.9(c) represents the wavelet transform 
a) 
b) 
c) 

Wavelets and Fractals for Signal and Image Analysis    55 
modulus of f(t) which is calculated from a wavelet which has been derived from a 
Gaussian style wavelet: in other words confirming this notion of self-similarity on 
all scales and also confirming the detection of singularities (presence of impulses). 
3.3.1.1. The roughness exponent (Hurst exponent )  
Rough surfaces, which can be the result of a rupture, may lead to invariance 
through anisotropic transformation (self-affinity). In this case the surfaces are 
described by a local roughness exponent or by the Hurst exponent which verifies 
that: 
2
R
)
,
(
x
   

 

y
x
in a neighborhood of
0
x , 
R

H
 such that, for all values 
of
0
!
O
: 
 
)]
,
(
)
,
(
[
~
)
,
(
)
,
(
0
0
0
0
0
0
0
0
y
x
f
y
y
x
x
f
y
x
f
y
y
x
x
f
H






O
O
O
G
 
In the case of a random phenomenon the symbol ~ signifies equality in terms of 
the laws of probability.  
 The Hurst exponent always has a value between zero and one and characterizes 
the fluctuations of height in a given surface. The analyzed surface might possess 
some properties of self-affinity meaning that it possesses properties of isotropic 
scale invariance if G =1 or of anisotropic scale invariance if G  1. 
3.3.1.2. Local regularity (Hölder exponent )  
Local regularity is introduced with the aim of describing the signals that show 
signs of local fluctuations, in this case, the Hurst exponent is insufficient when it 
comes to determining the regularity of the signals. A signal is said to be regular if it 
can be approached locally by a polynomial. 
A signal is said to be a regular Hölder signal h(x0)  0 if there is the presence of a 
polynomial 
0x
P
 of degree
¬
¼)
( 0
x
h
n  
 and a constant C > 0, so that: 
)
(
0
0
0
)
(
)
(
x
h
x
x
x
C
x
P
x
f

d

 
If f can be differentiated n times in the neighborhood x0, then 
0x
P
is equal to the 
Taylor series of f at x0. 
If 
1
0

d D
, then the regular part of 
)
(x
f
is reduced to
)
(
)
(
0
0
x
f
x
Px
 
and 
therefore
)
(
0
0
0
)
(
)
(
x
h
x
x
C
x
f
x
f

d

. 

56     Optimization in Signal and Image Processing 
The Hölder exponent provides a measurement of the rugosity of f(x): the closer 
the value of f(x) is to one then the softer its trajectory will be. The closer the value of 
f(x) is to zero, then the more variability the trajectory or the surface will possess. 
This increased variability corresponds to an increased level of rugosity. Singularities 
play a fundamental role in the study of signals and they often carry essential and 
relevant information. In the case of an image, its contours correspond to 
discontinuities or sudden variations in grayscale. These discontinuities or sudden 
variations in grayscale are the pieces of information that are recorded by a 
singularity of scale h. 
EXAMPLE 3.5.– The calculation of the Hölder exponent of the profile of a rupture 
surface of an elastomeric material: characteristics of rugosity. 
 
Figure 3.10. A 3D representation of one of the rupture surfaces of an elastomeric material 
 
Figure 3.11. Example of a rupture profile 

Wavelets and Fractals for Signal and Image Analysis    57 
 
Figure 3.12. The values of the local Hölder exponent calculated for each point of the profile 
INTERPRETATION 3.1. Our signal describes a profile (Figure 3.11) which has been 
extracted from a rupture surface of an elastomeric material that can be seen as a 3D 
representation in Figure 3.10. The calculation of the local Hölder exponent of this 
signal was created with the help of the Fraclab toolbox.  
Figure 3.12 shows that the majority of the values of the local exponent are 
between zero and one, with some peak values above one, reaching a maximum of 
1.3. The most notable point of this graph peaks at an amplitude of 1.3 for an abscissa 
of 552. This value of 1.3 is characterized by a sharp increase in h (the Hölder 
exponent) and is followed by much smaller values of 0.3. The most singular points 
of the entire profile, i.e. those with the smallest exponent, can be found straight after 
the maximum value of 1.3. The value of the exponent is approximately 0.25 for an 
abscissa of between 555 and 570; in other words this means that there is a strong 
level of rugosity of the rupture’s surface. This interval relates to the breaking point 
of the material and can correspond to a default or inclusion in the surface of the 
rupture.  
Our analysis remains basic and our objective is to trace the causes of the 
ruptures, for example by carrying out research into the defects which cause the 
material to break, or by looking at the poor physical and chemical design of the 
material. This study shows that the evolution of the local Hölder exponent provides 
clear and relevant information during the propagation analysis of cracks in a given 
material.   

58     Optimization in Signal and Image Processing 
3.3.2. Multifractal spectrum  
It is important to determine the distribution of the singularities of a multifractal 
in order to analyze its properties. The singularity spectrum (noted as D(h) and 
defined as the Hausdorff dimension of points where the Hölder exponent carries a 
particular value (iso-Hölder sets)) provides a geometric description of the 
singularities and measures the global distribution of the different Hölder exponents.  
Mathematically, this can be defined as follows [MAL 98]. 
DEFINITION 3.4.– Let Ah be the set of all the points where the punctual regular 
Hölder signal of a multifractal is worth h. The singularity spectrum D(h) of a 
multifractal is the fractal dimension (the Hausdorff dimension) of Ah. The support of 
D(h)is the entire sets of h for which Ah is not empty. 
Consequently, according to the definition of the fractal dimension given in 
section 3.2, covering the support of a multifractal by unconnected intervals of size s 
gives the number of intervals which intersects Ah: 
)
(s
N h
~
)
(h
D
s 
  
The singularity spectrum thus expresses the proportion of singularities h which 
appear on a given scale s. The singularity spectrum of multifractals can easily be 
measured from the wavelet transform modulus which will be introduced in section 
3.4.4.  
NOTE 3.2.– A multifractal is said to be homogenous if all of its singularities have the 
same Hölder exponent
0
D
 
h
, the support of D(h) therefore becomes punctual 
^
`
0
D
.  
 The multifractal approach of 2D signals enables scientists to consider light 
intensity as a measurement of local information held by the image [LEV 00, LEV 
97, LEV 94, LEV 92, BER 94]. 
A Hölder exponent is attributed to each point x on the image
(x)
h
h  
according 
to the following equation: 
H
H
H
log
(x)
)
(x
log
lim
(x)
0
f
f
h


 
o
 
This equation provides information on the local regularity of the image in a 
neighborhood of x. Once this simulation has been carried out on the entire image it 

Wavelets and Fractals for Signal and Image Analysis    59 
is then possible to construct sets of regularities by grouping together the points of 
the image which have the most similar Hölder exponent values in order to measure 
the Hausdorff dimension of these sets, noted as dH. The pair (h, dH), which is then 
obtained, can be used as an important piece of information in different applications: 
 detection of contours; the contours of an image are identified with the 
component that is linked to the strongest singularities; 
 measurement of the rugosity of a texture; 
 denoising.  
A large part of the noise (pixels of isolated singularities which do not correspond 
to any contour) can be eliminated by carrying out threshold techniques which are 
based on the notion of dimension.  
Figure 3.13 shows an example of the multifractal spectrum of a rupture surface 
image as well as the corresponding contours.  
 
Hausdorff spectrum
Hausdorff exponent
 
Figure 3.13. Estimation of the exponents of the singularities of the rupture surface. On the 
left: the original image of the face. Center: distribution of the values of the image’s 
singularity exponents. On the right: grayscale representation of the singularity exponents: the 
clearer the pixel, the weaker the exponent of the pixel 
Despite the complexity of the texture of the image, this method ensures the 
detection of very fine contours.   

60     Optimization in Signal and Image Processing 
3.4. Distribution of singularities based on wavelets  
3.4.1. Qualitative approach 
Singularities and irregular structures of a signal carry relevant information. It is 
very important to detect and characterize the discontinuities in the intensity of pixels 
which describes an image. This intensity also defines the contours of a scene (Figure 
3.13) or the transient of a pathological electro-encephalogram. 
In order to characterize singular structures, it is necessary to quantify the 
regularity of the signal f(t). The Hölder exponent (sometimes also referred to as the 
Lipchitz exponent) provides the measurements for uniform regularity of intervals as 
well as for any given point v . If f is singular, i.e. non-derivable, its behavior is 
described by the Hölder exponent. 
The decrease of the wavelet transform modulus according to the respective scale 
is linked to the global and punctual regularity of the signal. Measuring this 
asymptotic decrease can be compared to “zooming” into the structures of a signal 
with a scale that tends towards zero. 
3.4.2. A rough guide to the world of wavelet 
In the case of an image, the “time-scale” or “space-scale” analysis is based on 
the use of a very extensive range of scales used to analyze a signal. This type of 
analysis is often referred to as a multiresolution analysis. Multiresolution analysis is 
based on a variety of different behaviors in terms of the laws that define the scales 
(e.g. rather large to very fine scales). The different scales are used to “zoom” into 
the structure of the signal and obtain increasingly precise representations of the 
signal that is being analyzed. A function 
)
(t
\
or a localized and oscillating wave 
known as “mother-wavelet” are needed for the operation named above. 
The condition of localization implies a rapid decrease when t  increases 
indefinitely and the oscillation suggests that 
)
(t
\
 vibrates just as a wave does and 
that 
)
(t
\
’s average and its n moments equal zero: 
( )
( )
0   for  0  
k
t dt
t
t dt
k
n
Z
Z
d
d
d
d



b b
¨
¨
"
 

Wavelets and Fractals for Signal and Image Analysis    61 
This property (n vanishing moments) is important in order to analyze the local 
regularity of a signal. Indeed, the Hölder regularity index increases with increasing 
the number of vanishing wavelet moments. Furthermore, the wavelet is (a zero 
average function) centered around zero with a finite energy. 
The mother-wavelet 
)
(t
\
 whose scale, based on a convention, is 1  generates 
other wavelets 
)
(
,
t
s
u
\
, 
R
 ,0

!
u
s
. This generation of other wavelets is based on 
the changes of the scale s as well as on temporal translation u: 
¸
¹
·
¨
©
§ 
 
s
u
t
s
t
s
u
\
\
1
)
(
,
  
)
(
,
t
s
u
\
 is therefore centered around u. 
 The wavelet transform of f, expressed by 
)
,
(
s
u
Wf
, for the scale s and the 
position u, is calculated by correlating f with the corresponding wavelet: 
dt
s
u
t
s
t
f
s
u
Wf
¸
¹
·
¨
©
§ 
 ³
f
f

*
1
)
(
)
,
(
\
  
where 
s
u,
*
\
 describes the complex conjugate of 
s
u,
\
. 
In a way, this transformation measures the fluctuations in a signal f(t) around a 
specific point u and for the scale provided by 
0
!
s
. This type of property has 
interesting applications and allows for the detection of transients and analysis of 
fractals. These transients are detected when zooming all along the scales and fractal 
analysis in determining the distribution of singularities. 
It is possible to compare the time-scale analysis (u, s) to a time-frequency 
representation (u, Ș/s) where
s
u,
\
 is symbolically represented by rectangles whose 
dimensions vary according to s. Their surface, however, remains the same (Figure 
3.14). This idea therefore also represents the Heisenberg uncertainty principle:  
2
1
t
Z
V
Vt
  or   
t
V    and   
Z
V
  
respectively represents the temporal resolution (or standard deviation) and the 
frequency resolution.  

62     Optimization in Signal and Image Processing 
 
Ș/s 
Ȧ 
ıȦ/
s
ȥ u, s 
ȥu0, s0 
u 
u0
s0ıt 
t
ıȦ0/s0 
^
`
s
u
ȥ ,
TF
 
Ș/s0 
^
`
0
0,
TF
s
u
ȥ
 
 
Figure 3.14. Process of wavelet analysis and the illustration of  
the Heisenberg uncertainty principle 
Figure 3.14 shows that if s decreases, the frequency support increases and shifts 
towards higher frequencies. As a result the temporal resolution improves. 
Figures 3.15(a) and (b) show some examples of wavelets that are very useful in 
the analysis of signals.  
 
 
 
 
 
Figure 3.15. Wavelets generated from a Gaussian functionT ;  
(a) Morlet: T modulated; (b) Mexican hat: -
''
T
 
a) 
b) 
0 
 
 
0 
 
 

Wavelets and Fractals for Signal and Image Analysis    63 
3.4.3. Wavelet Transform Modulus Maxima (WTMM) method  
Wavelet \  is assumed to have n moments equal to zero. This wavelet is also 
Cn with the derivates of a rapid decrease. This means that for every 0
k
n
b
b
 and 
m  / , there is 
m
C  such that: 
 
( )( )
1
R,    
m
m
C
k
t
t
t
 
\
d

 
Jaffard’s necessary and sufficient condition [JAF 91] on wavelet transform, used 
in order to estimate the Hölder (or Lipchitz) punctual regularity of f at a point v, can 
be expressed as follows: 
if f 
2
L (R)

is Hölder2 
n
d
D
, there exists A such that: 
( , )
R 
R
u s



u
 ,   
¸¸
¸
¹
·
¨¨
¨
©
§



d
D
D
s
v
u
As
s
u
Wf
1
2
/
1
)
,
(
 
  
[3.1] 
Based on what has been discussed above, the Hölder local regularity of f at v 
depends on the decrease of 
)
,
(
s
u
Wf
 at fine scales in the neighborhood of v. The 
decrease of 
)
,
(
s
u
Wf
 can indeed be controlled by the values of its local maxima. 
Modulus maximum describes any point 

0
0, s
u
 such that 
)
,
(
0
0 s
u
Wf
 is locally 
maximum at 
0
u
u  
[OUA 02]. This implies: 
0
)
,
(
0
0
 
w
w
u
s
u
Wf
 
NOTE 3.3.– The singularities are detected by searching the abscissa where the 
wavelet modulus maxima converge at fine scales. Indeed, if \  has exactly n 
moments equal to zero and a compact support, there is T  with a compact support 
such that 
( )
( 1)n
n
Z
R
 
 with
( )
0
t dt
R
d
d
v
¨
. The wavelet transform can be expressed 
                              
2. In order to conform with the written form used by Jaffard and Mallat [MAL 98], the Hölder 
(or Lipchitz) exponent will, in the meantime, be expressed as D  instead of h. 

64     Optimization in Signal and Image Processing 
as a multiscale differential operator of order n: 
	

( , )
( )
n
n
s
n
d
Wf u s
s
f
u
du
R


 with 
1
( )
s
t
t
s
s
R
R
¬­


 ­

­­

® . 
If the wavelet has only one moment which equals zero, wavelet modulus maxima 
are the maxima of the first order derivate of f smoothened by
s
T . These multiscale 
modulus maxima are used for the location of discontinuities as well as when 
analyzing the contours of an image. If the wavelet has two moments that equal zero, 
the modulus maxima correspond to large curvatures.  
NOTE 3.4.– A contrario, if 
)
,
(
s
u
Wf
does not have a local maximum on the level of 
fine scales, then f is regular in that local area. 
 NOTE 3.5.– In general nothing guarantees that a modulus maxima is situated at 


0
0, s
u
 nor that this modulus is part of a line of maxima that propagates finer 
scales. However, in the case of T  being a Gaussian function, the modulus maxima 
of 
)
,
(
s
u
Wf
 belong to the related curves that are never interrupted when the scale 
decreases.  
NOTE 3.6.– In the case of an image, the points of the contours are distributed on 
curves that often correspond to the boundaries of the main structures. The modulus 
of individual maximum wavelets are linked to form a curve of maxima that follows 
the outline. For an image, partial derivates of wavelets linked to 
1x  and 
2
x of a 
smoothing function T  are also taken into consideration. 
1
2
1
2
       and         
x
x
R
R
Z
Z
s
s


s
s
 
Function T is assumed to be localized around 1
2
0
x
x

  and isotropic (does not 
depend on x ). The Gaussian function 
2
2
2
1
2
x /2
(
)/2
x
x
e
e



 and the Mexican hat 
wavelet 	

2
2
x /2
2
x
e

are wavelets that meet these requirements. The 
corresponding wavelets transform is as follows:  
\
^
2
2
1
x
u
( , )
(x)
x
(u)
* s
Wf u s
f
d
f
s
s
R
R
£
²

¬
¦
¦

¦
¦
­



 
­
¤
»

­­

¦
¦

®
¦
¦
¥
¼
¨
 
where * describes the operator of the convolution product.  

Wavelets and Fractals for Signal and Image Analysis    65 
This transformation can equally be expressed by its modulus 
(u, )
Wf
s and its 
argument
\
^
(u, )
Arg Wf
s
. 
This signifies that the 2D-wavelet transform defines the gradient field of 
)
x
(
f
smoothened byT . Note that the gradient 
^
`)
u
(
s
f T


 indicates the direction 
of the largest variation of f for a smoothened scale s and that the orthogonal 
direction is often referred to as the direction of maximum regularity.  
Furthermore, in the sense of Canny’s detection of the contours, wavelet modulus 
maxima are defined by the respective points u where 
)
,u
(
s
Wf
 is a local maximum 
that tends towards the direction of the given gradient described by the 
angle
^
`)
,u
(
s
Wf
Arg
. Its points create a chain that is referred to as the maxima 
chain. They might also be referred to as a gradient vector that indicates the local 
direction in which the signal varies the most when compared to the smoothened 
scale s.  
The skeleton of wavelet transformation consists of two lines of maxima that are 
convergent up to the point of plane 	

1
2
,
x x
 in the limits of 
0
s l
. This skeleton 
carries out the positioning of the space-scale that contains all information 
concerning the fluctuations of the local regularity of f. 
 
Figure 3.16. (a) Signal f(t )shows its singularities; (b) the wavelet modulus  
maxima and the lines of maxima of this modulus 
a) 
b) 

66     Optimization in Signal and Image Processing 
 Figure 3.16 can be accessed on the website http://cas.ensmp.fr/~chaplais/ and 
shows that the singularities create coefficients of great amplitude in their cone of 
influence. WTMMs detect the singularities well and allow us to estimate graphically 
the order of singularity of f (t) at all times in representing the WTMM linked to the 
function of the scale s. The gradient (based on the hypothesis of linearity) of the 
curve, e.g. log-log, obtained at a specific point in time, provides an estimation of the 
Hölder coefficient.  
NOTE 3.7.– Numerical aspects. It is well known that derivatives of Gaussians are 
used to guarantee that all maxima lines propagate up to the finest scales.However, 
the process of chaining maxima must be performed with caution due to the 
apparition of artefacts in areas where the wavelet transform is close to zero.  
Moreover, the finest scale of the wavelet transform is limited by the resolution of 
data. Then, the sampling period must be sufficiently small so thatҏ B ҏis measured 
precisely.
3.4.4. Spectrum of singularities and wavelets  
The singularities of multifractals vary from one point to another. It is important 
to establish the distribution of these singularities to analyze their properties. In 
practice, the distribution of singularities is estimated by global measurements which 
use self-similarities of multifractals. In this way, the fractal dimension of the points 
with the same Hölder regularity is calculated. The function used for this calculation 
is a function based on global partition calculated on the basis of the WTMM. The 
self-similarity of the wavelet transform modulus leads to the positions of the values 
of wavelet transform modulus maxima being equally self-similar.  
In practice, the spectrum of singularities written as 
( )
D B  or 
( )
D h  for 
multifractals is measured based on the local maxima of the wavelet transformation.  
Let\  be a wavelet with n vanishing moments. If f has pointwise Hölder 
regularity 
0
n
B 
at v, the wavelet transform 
)
,
(
s
u
Wf
 possesses a set of modulus 
maxima that are convergent towards v at fine scales.  
All maxima at the scale s can be interpreted as a recovery of the singular support 
of f by wavelets of scale s. For its maxima, the following applies: 
)
5.0
(
0
~
)
,
(

D
s
s
u
Wf
 

Wavelets and Fractals for Signal and Image Analysis    67 
 Let^
`
Z
)
(

p
p s
u
 represent the positions of all local maxima of 
)
,
(
s
u
Wf
 on a 
fixed scale s, >
@
max
min,D
D
 is the support of 
)
(D
D
, and \  a wavelet with 
max
D
!
n
moments equal to zero. The calculation of the spectrum 
)
(D
D
for a self-
similar signal f is carried out as follows: 
 calculation of maxima; determine 
)
,
(
s
u
Wf
and its modulus maxima for each 
scale s; create chains of the wavelets’ maxima across scales; 
 calculation of the function of partition (measurement of the sum of power q for 
these wavelet modulus maxima) 
q
p
p s
u
Wf
s
q
Z
¦
 
)
,
(
)
,
(
; 
 determination of the scaling exponent 
)
(q
W
by linear regression of 
)
,
(
log2
q
s
Z
 
as function of 
s
2
log
 
0
       
log
)
(
~
)
,
(
log
2
2
o
s
s
q
q
s
Z
W
. 
Note that the Hölder exponent D  and the spectrum of singularities 
)
(D
D
are 
conjugated variables of q  and
)
(q
W
. This means that 
)
(D
D
 can be obtained by 
inverting the Legendre transform of 
)
(q
W
 under the hypothesis that 
)
(D
D
is convex; 
 determination of the spectrum 
 ¸¸
¹
·
¨¨
©
§

¸¸
¹
·
¨¨
©
§

 

q
q
D
q
W
D
D
2
1
min
)
(
R
. 
NOTE 3.8 – The monofractals or the homogenous fractals are characterized by a 
single Hölder exponent h (or D ) = H (the Hurst exponent) of a spectrum
q
W  which is 
linear and whose gradient is given by 
H
q
h
 
w
w
 
W
. On the other hand, a non-linear 
behavior of
q
W indicates a multifractal for which the Hölder exponent 
)
x
(
h
 is a 
variable. 

68     Optimization in Signal and Image Processing 
3.4.5. WTMM and some didactic signals  
Highly oscillatory signals  
a) 
b) 
c) 
 
Figure 3.17. (a) Signal

t
a
t
f
/
sin
)
(
 
; (b) the modulus of its wavelet transform calculated 
with 
'
T
\

 
where T is a Gaussian function; (c ) the lines of maxima for this modulus  
Figure 3.17 shows the analysis of a generic signal 
¸¹
·
¨©
§
 
t
a
t
f
sin
)
(
which is highly 
oscillatory and discontinuous at 
0
 
t
. If (u, s) is in the cone of influence of 0, 
condition [3.1] is verified for
2
 
 h
D
. However, Figure 3.17 shows that there are 
coefficients for wavelets of high energy outside the cone of influence centered at 0. 
The instantaneous frequency of f(t) is 
2
t
a

, and if u varies, the set of points (u, 
s(u)) describes a parabolic curve situated outside the cone of influence centered 
around 0. The WTTMs confirm that large amplitudes are situated outside the cone of 
influence.  

Wavelets and Fractals for Signal and Image Analysis    69 
A signal with a finite number of discontinuities  
 
a) 
b) 
c) 
 
Figure 3.18. (a) signal f(t) with a finite number of discontinuities;  
(b ) its wavelet transform modulus calculated with
''
T
\

 
where  
T is a Gaussian; (c) the lines of maxima for this modulus  
Figure 3.18 represents the analysis of a generic signal which shows singularities 
that are marked by discontinuities and non-derivabilities. The WTTMs are 
calculated with the help of a wavelet which is a second derivative of a Gaussian. The 
decrease of 
)
,
(
s
u
Wf
 described by s  is expressed throughout several curves of 
maxima. These curves correspond to the smoothened and non-smoothened 
singularities.  

70     Optimization in Signal and Image Processing 
3.5. Experiments 
3.5.1. Fractal analysis of structures in images: applications in microbiology  
Fractal analysis can be used in microbiology when determining the number of 
yeast cells in a digitized image [VES 01]. 
 
Figure 3.19. Image of a microbiological sample 
Figure 3.19 comes from an acquisition system that is composed of an SM-6 
optical microscope and a digital camera that can be operated with the help of a 
computer.  
The optical level of the microscope and the resolution of the digital camera 
provide the link between the size of the image and the size of the sample (10 ȝm/48 
pixels) to be studied.  
The number of cells can be determined by bearing the following characteristics 
in mind: 
 the cells have a round shape;  
 the cells are of a similar size; 
 the cells differ from the background in their color and intensity.  
The process of determining the number of cells works as follows:  
1. Application of a mask to adjust the color: white (W) for the cells and black (B) 
for the background.  
2. Determining the fractal dimension and the fractal measurement (see definition 
3.2) of the masked image comprising the interface of the background (KWBW, dWBW) 
as well as the interface of the cells (KBW, dBW) is done with the help of the following 
equations that are directly based on the definition of the fractal:  

Wavelets and Fractals for Signal and Image Analysis    71 
BW
d
BW
BW
s
K
s
N

 
)
(
( )
( )
( )
WBW
d
WBW
W
BW
WBW
N
s
N
s
N
s
K
s



 
[3.2] 
NW  and NBW  respectively represent the number of entirely white boxes as well as the 
number of partially black boxes.  
dBW and dWBW are the fractal dimensions obtained with the help of the box-
counting method (see section 3.2.3.1), KBW and KWBW are fractal measurements.  
To determine the number of cells nc as well as their radius r, the following 
equations are used: 
2
2
(2
)
2
~
,
BW
c
c
WBW
c
r
r
r
N
n
n
N
n
s
s
s
Q
F
Q
Q



 
[3.3] 
From equations [3.2] and [3.3], the following equation is inferred: 
BW
WBW
WBW
BW
d
d
m
WBW
BW
d
m
WBW
d
m
BW
c
s
K
K
s
K
s
K
n
2
2
2
2
4
4



 
 
S
S
 
 sm is the size of the box corresponding to the maximum fractal dimension. For a 
radius of r = 38 pixels, the fractal analysis estimates the number of cells which is 
equal to nc= 100 cells. This is shown in Figure 3.20. 
0              1              2               3              4             5               6              7  
                                    log s     
120 
100 
80 
60 
40 
20 
0 
0
 
Figure 3.20. On the left: model of cellular structure, nc= 100 cells of the radius  
r = 38 pixels. On the right: Determination of the number of cells n and their  
radius by fractal analysis (log s = 2 provides nc = 100 and r = 38 pixels) 

72     Optimization in Signal and Image Processing 
 0              1              2             3              4             5              6              7 
                                    log  s
120 
100 
80 
60 
40 
20 
0 
 
Figure 3.21. On the left: model of cellular structure nc = 100 cells whose size  
is distributed according to a Gaussian law on the average radius r = 38 pixels  
of the standard deviation = 4. On the right: fractal analysis of the number of cells n  
and their radius r (log s = 2 provides nc = 82 and r = 43 pixels) 
Note that unless the structures are of a certain size a bias is introduced in the 
estimation process (Figure 3.21), the number of cells that has been calculated is 
always lower than the number of cells in reality. The size of the cells is therefore 
underestimated.  
Determining the number and the size of cells with the help of a fractal analysis is 
therefore only valid if the structures contain cells that are of a similar size.  
This experiment shows that fractal analysis is a promising tool when it comes to 
counting and measuring objects in a digital image.  
3.5.2. Using WTMM for the classification of textures – application in the field of 
medical imagery  
Numerous works in image processing and pattern recognition are directed to two 
complex tasks: detection and automated classification of aggregates that might 
indicate the beginning of breast cancer.  
This study, related to medical issues, is based on the application of the WTMM 
2D method described in section 3.4.3. The aim of the segmentation of aggregates 
referred to as accumulation is to dip objects into the rough texture at a specific 
moment in time, shown in Figure 3.24. 
As far as methodology is concerned, this technique is pertinent in discriminating 
against the groups of singularities that have been sufficiently characterized by the 
Hölder exponent.  

Wavelets and Fractals for Signal and Image Analysis    73 
Furthermore, the WTMM method is used to measure the properties of the 
invariance of the scale of mammography in order to distinguish dense tissue and 
adipose tissue with the help of the Hurst exponent.  
In particular, the invariance of the observed scale is of a monofractal type in 
which two different groups of tissue are respectively characterized by the Hurst 
exponent H=0.3±0.05 and H=0.65±0.05. This type of result can be interpreted as an 
adipose feature of nature (fat) or as conjunctive (dense) tissue. The properties of 
invariance of a scale are associated with two groups of tissue that allow for the 
segmentation of the image of a breast. This procedure is based on the Hurst 
exponent of a square size of 256×256 pixels per analysis of around 50 images (see 
Figure 3.23). 
This discrimination of monofractal behavior between adipose and dense tissue is 
also proven by the calculation of spectra for singularities D(h) (see Figure 3.22). 
 
 
 
 
 
 
Figure 3.22. Spectrum of singularities of 49 juxtaposed images (512×512)  
on the level of scales 21 s  112 
These spectra are made up of around 50 images and can be reduced to one single 
point h=H=0.30 for adipose tissue and h=H=0.65 for dense tissue. This is the proof 
that the texture represented in the mammogram is of a monofractal nature 
throughout the entire image. This is why it is possible to distinguish adipose from 
dense tissue.  
For more information and more details on these concepts, please see Kestener’s 
thesis [ KES 03] . 
2 
0 
0 
0.30 
1 
0.65 
h

74     Optimization in Signal and Image Processing 
Adipose
Dense 
 
Figure 3.23. Analysis based on WTMM of two mammograms: (a-d) breast with dense tissue 
and (e-h) breast with adipose tissue. The wavelet used in the analysis is an isotropic wavelet 
of the order 1 (derivate of a Gaussian function.) (a) and (e) represent the original 
mammogram; (b) and (f) represent their respective growth (zoom on the central part: 
256×256 pixels); (c) and (g) show the WT modulus and the maxima chains  at the level of  
s = 39 pixels; (d) and (h) show the chains of local maxima as well as their positions 

Wavelets and Fractals for Signal and Image Analysis    75 
Furthermore, this method is used to locate microcalcifications and characterize 
their disposition in a possible accumulation. In order to do this, the fractal dimension 
of all objects classed as “microcalcifications” are analyzed. 
 
 
Figure 3.24. On the left: a mammogram showing microcalcifications. On the right: close-up 
on the area containing the cluster of microcalcifications 
If the accumulation or cluster is of a linear disposition, the fractal dimension is 
equal to its Euclidean dimension df = 1, if a finite surface is filled df = 2 can be 
expected. However, if the cluster is of an arborescent structure, the fractal dimension 
is fractioned 1 < df < 2, which reflects the local complexity of mammary canals as 
well as the dissemination of the microcalcifications within these canals. An example 
of detecting microcalcifications in an accumulation or a cluster is shown in Figure 
3.25. These images show that it is possible to clearly distinguish the areas of 
microcalcifications. Consequently, WTMM allows for an analysis and a 
characterization which still have to prove their effectiveness in clinical tests.  
 
 
 
 
 
Figure 3.25. Detection of microcalcifications in a cluster (df = 2±0.05).  
(a) original mammogram. (b) and (c) Chains of maxima that indicate the  
microcalcifications for the scales s = 14 pixels and s = 24 pixels 
(a) 
(b) 
(c) 

76     Optimization in Signal and Image Processing 
In this study, the WTMM method confirms the interest in a fractal approach and 
shows that the Hölder exponent (or the Hurst exponent) can be used as an indicator 
of microcalcifications in the breast (probability of early stages of breast cancer) and, 
last but not least, this method also establishes the geometric shape of the cluster. 
This type of information could be used in combination with medical diagnosis and 
as an automatic system that helps medical staff with the diagnosis.  
3.6. Conclusion 
This chapter provides a pragmatic approach to the analysis of signals whose 
regularity varies from one point to another.  
The concepts that have been used show multifractal analysis and wavelet 
analysis. In practice, the distribution of singularities is estimated by global measures 
using self-similarity or invariance on the scale of multifractals. The criterion of local 
regularity based on the Hölder exponent can be characterized as a decrease in the 
wavelet coefficients in the signal that is being analyzed. Furthermore, the spectrum 
of singularities of the multifractals to be studied is measured by local maxima of 
wavelet transform.  
In the framework of this study, the formalism that was used has been validated in 
the field of health technology for the detection and characterization of images. 
Furthermore, the field of mechanical engineering looks at the process in terms of 
material fatigue.  
This promising formalism is currently undergoing a fusion of ideas on its very 
basic level as well as in the area that aims at developing analysis tools. 
3.7. Bibliography  
[BEN 00] BENASSI A., COHEN S., DEGUY S., ISTAS J., “Self-similarity and intermittency”, in 
Wavelets and Time-frequency Signal Analysis, EPH, Cairo, Egypt, 2000. 
[BER 94] BERAN J., Statistics for Long–Memory Process, Chapman and Hall, New York, 
1994. 
[BER 94] BERROIR J., Analyse multifractale d’images. Thesis , Paris University IX, 1994. 
[BES 35] BESICOVITCH A.S. , Mathematische Annalen 110, 1935. 
[CAN 84] CANTOR G., “On the power of perfect sets of points”, Acta Mathematica 2, 1884. 
[GRA 03] GRAZZINI J., Analyse multiéchelle et multifractale d’images météorologiques: 
application à la détection de zones précipitantes. Thesis, Marne-La-Vallée University, 
2003. 

Wavelets and Fractals for Signal and Image Analysis    77 
[HAU 19] HAUSDORFF F., Mathematische Annalen 79, 157, 1919. 
[JAF 91] JAFFARD S., “Pointwise smoothness, two-microlocalization and wavelet 
coefficients”, Publicaciones Matematiques, vol. 35, p. 155-168, 1991. 
[KES 03] KESTENER P., Analyse multifractale 2D et 3D à l’aide de la transformation en 
ondelettes: application en mammographie et en turbulence développée. Thesis, Bordeaux 
University I, 2003. 
[LEV 00] LEVY VEHEL J., “Analyse fractale: une nouvelle génération d’outils pour le 
traitement du signal-enjeux, tendances et évolution”, TSI 19 (1-2-3), pp. 335-350, 2000. 
[LEV 97] LEVY VEHEL J., LUTTON E., TRICOT C., Fractal in Engineering. Springer Verlag, 
1997. 
[LEV 94] LEVY VEHEL J., MIGNOT P., “Multifractale segmentation of images”, Fractlas 2(3), 
pp. 371-377, 1994. 
 [LEV 92] LEVY VEHEL J., MIGNOT P., BERROIR J., “Multifractals, texture and image analysis”, 
In: Proc of Computer Vision and Pattern Recognition, CVPR’92, p. 661-664, 1992. 
[MAN 82] MANDELBROT B.B., The Fractal Geometry of Nature, Freeman and Company, San 
Francisco,1982. 
[MAL 98] MALLAT F., A Wavelet Tour of Signal Processing, Academic Press, San Diego, 
1998. 
[OUA 02] OUAHABI A., LOPEZ A., BENDERBOUS S., “A wavelet-based method for 
compression, improving signal-to-noise and contrast in MR Images”, Proc. of the 2nd. 
IEEE International Conference on Systems, Man & Cybernetics, Hammamet, Tunisia, 6-9 
October 2002. 
[SAM 94] SAMORODNITSKY G., TAQQU M.S., Stable Non-Gaussian Random Processes, 
Chapmann and Hall, 1994. 
 [VES 01] VESLA M., ZMESKAL O., VESELAY M., NEZADAL M., “Fractal analysis of image 
structures for microbiologic application”, HarFa, p. 9-10, 2001. 
 [VON 04] VON KOCH H., “Sur une courbe continue sans tangente, obtenue par une 
construction géometrique élémentaire”, Arkiv for Matematik 1, p. 681-704, 1904. 
 
 

 
Chapter 4  
Information Criteria: Examples of 
Applications in Signal and Image Processing 
4.1. Introduction and context 
In this chapter we will focus on the sequence of N observations 


N
N
x
x
x
,
,
1 "
 
 
on a stationary and random process consisting of a family of random variables 
^
`
Z

 
n
n
X
X
 distributed according to the same unknown law T.  A model Tk based 
on k free parameters will represent this process X.  Determining the optimal 
estimation 
k
Tˆ  of Tk in the maximum likelihood (ML) sense enables us to find 
k
Tˆ  
which maximizes 
(
 
 )
N
k
f x
T
 where f represents the conditional density probability 
of the observations xN when choosing the model 
k
T . Finding 
k
Tˆ  which will minimize 
(
)
log
(
  
)
N
k
k
L
f x
T
 
T
 and therefore 
)
(
min
arg
ˆ
k
k
L
k
T
T
T
 
 has the same effect.  
Even though this criterion of estimation is expressed by a fixed number k, it 
might be tempting to use this criterion to carry out a simultaneous estimation of the 
model’s parameters and its number of free parameters, which in a written form can 
be expressed as follows: 
)
(
min
arg
ˆ
,
,1
,
k
K
k
k
L
k
T
T
T
"
 
 
, where K represents the maximum 
number of free parameters. 
                              
 Chapter written by Christian OLIVIER and Olivier ALATA. 
Optimization in Signal and Image Processing 
Edited by Patrick Siarry 
Copyright 0 
2009, ISTE Ltd 

80     Optimization of Image and Signal Processing  
As a general rule this criterion does not converge; this would lead to an 
overestimation of the number of free parameters. For sufficient proof see Figure 4.1. 
Information criteria (IC) will be referred to as penalized log-likelihood criteria 
where the penalized term depends on the number k of free parameters in the model 
Tk and/or the number of observations N. In some criteria, a third term appears. This 
term contains Fisher information which is often forgotten about and not very 
influential in the research focusing on model Tk. Furthermore, these criteria can be 
written in a generalized form: 
	 
	

	 
ˆ
2log
N
k
IC k
f x
kC N
R
 

 
[4.1] 
with 
k
Tˆ  as the parametric model which minimizes 
(
)
k
L R  and C(N) as an increasing 
function of N. The “best” model ˆkR  is the one that minimizes IC(k).  In the case 
where the hypothesis of independence is issued we could also write:  
	 
	

	 
1
ˆ
2
log
N
i
k
i
IC k
f x
kC N
R

 


 
[4.1’] 
where 
	

ˆ
i
k
f x R
, i = 1, …, N, describes the conditional probability density of 
observation xi while choosing model 
ˆkR . Assuming that  
1
ˆ
(
)
k
N L R
 tends 
asymptotically to 
ˆ
( log
(
))
k
E
f X

T
 when 
f

o
N
, the link between information 
criterion and entropy is created and the reason for the occasional designation of 
penalized entropic criteria is given to the IC. 
Numbers from these criteria are proved or proposed without proof in the context 
of researches about 1D auto-regressive (AR) models (sections 4.3.1 and 4.3.2). 
These criteria were then applied to other parameter-based models such as ARMA, 
2D AR models (section 4.3.3), mixtures of n-D Gauss’s laws (section 4.4) and 
Markov models (section 4.6.1). They were also taken into consideration for non-
parametrical problems such as the approximation of distribution via histograms 
(section 4.5) and research on features containing a maximum of information about 
one particular pattern (section 4.6.2). 
All of the applications presented in this chapter are, of course, not exhaustive as 
a large number of recent articles, like those on the processing of images, show.  

Information Criteria     81 
4.2. Overview of the different criteria  
The most common and also the oldest information criterion is Akaike’s 
information criterion (AIC) [AKA 73]. Even though this criterion improves ML 
estimation, it leads to an over-parameterization in the order of models [SHI 76]. This 
behavior will be analyzed in the examples which follow. AIC is in itself an 
improvement of the FPE (Final Prediction Error) criterion which was also created by 
Akaike (1969). FPE is still used occasionally. FPE is based on the minimization of 
the Kullback-Leibler (K-L) information between  
T.
f
 and 

k
f T
.
 (see Appendix, 
section 4.8.1). Through asymptotic approximation of this measure for large N, and 
leaving out terms that do not specifically depend on the model, the following 
criterion has been obtained:  
ˆ
( )
2log
(
)
2
N
k
AIC k
f x
k
 
T

 
[4.2] 
Even though this criterion has often been criticized and even contested, it still 
represents major progress in the field of approximation.  
Hannan and Quinn [HAN 79] improved this criterion by writing it in the 
following form:  
ˆ
( )
2log
(
)
loglog
N
k
k
f x
k
N
)
 
T

 
[4.3] 
This criterion is weakly consistent (convergence only in probability 
when
f
o
N
; see Appendix, section 4.8.2 for the types of convergence used). 
To overcome the inconsistency of AIC, Schwarz [SCH 78] suggested the widely-
known BIC criterion based on the Bayesian justification of choosing an order for the 
AR:  
ˆ
( )
2log
(
)
log
N
k
BIC k
f x
k
N
 
T

 
[4.4] 
A different approach was introduced by Rissanen [RIS 78]. This approach 
suggested using the minimization of the length of a code. This code is required to 
encode observations xN of the process stated in the number of bits as a criterion of 
optimization. This criterion is referred to as MDL (minimum description length)  
and can be compared to BIC, even though different terms were added to the  
penalty (Fisher information was added in [BAR 98], the estimated mean entropy in 
[BIE 00], etc.)  

82     Optimization of Image and Signal Processing  
The BIC and MDL criteria are almost surely convergent (there is a strong 
consistency) and penalized the term of likelihood more than )and AIC. As these 
two criteria are written in a very similar way, they will no longer be distinguished in 
the rest of this chapter. A complete theoretical study on MDL can be found in [GRU 
04]. 
Another criterion, referred to as 
E
)
, suggested and explored by El Matouat and 
Hallin [ELM 96], is a generalization of Rissanen’s work on stochastic complexity 
[RIS 89].  It is written in the following form: 
ˆ
( )
2log
(
)
loglog
N
k
k
f x
kN
N
E
E
)
 
T

 
[4.5] 
with the following condition being required: 0 < E < 1. This criterion is strongly 
consistent (see Appendix, section 4.8.2) and can be presented as a compromise 
between ) and BIC/MDL. It has been shown in [JOU 00] with refined conditions: 
1
log
log
log
1
log
log
log
0


d
d

N
N
N
N
E
, which allows for Eto be adjusted according to the 
number of observations N. From now on, 
N
N
log
log
log
min  
E
 and 
min
max
1
E
E

 
 will be 
referred to as the two bounds regulating E  data. 
On the basis of the 
E
)
 penalty it is possible to calculate the penalty of the BIC 
or AIC criterion. It is sufficient to apply the following values to E : 
N
N
N
log
log
log
log
log
log
BIC

 
E
 and 
N
N
log
log
log
log
2
log
AIC

 
E
.  Based on these formulae 
we can observe that 
1
0
BIC 
 E
, for N > 4, even though 
0
AIC 
E
 for N >1619, which 
is coherent with the non-convergence stated in AIC.  We can also observe that once 
N 
> 
15, 
even 
though 
1
max
min
BIC
AIC




E
E
E
E
 
and 
also 
max
min
BIC
AIC
ˆ
ˆ
ˆ
ˆ
k
k
k
k
t
t
t
, where
IC
ˆk
 represents the estimated number of free 
parameters  with a given IC.  
[EM 96] also suggested the AIC* criterion. In this case C(N) is written as 
follows: C(N) = 2 + logN. 
There are also other criteria which are not justified, such as the AICD criteria 
with penalty Dk, D > 2 [BHA 77]. The penalty 3k is part of the AICD criteria and 
features a mixture of laws [BOZ 94] (see section 4.4.1).  
Others are similar to the criteria shown above, e.g. the Kashyap criterion [KAS 
89], which is a BIC criterion and expressed for the case of an 2D AR model (see 

Information Criteria     83 
section 4.3.3); CAICF (consistent AIC Fisher) by Bozdogan [BOZ 94] is equivalent 
to MDL. Others are specified according to the chosen model and more often an AR 
model (see section 4.3.1). 
As a general rule, acceptable penalties kC(N) need to verify the conditions given 
in [NIS 88] (see Appendix, section 4.8.2 and Table 4.1) to ensure either almost sure 
convergence (strong consistency) or only convergence in probability (weak 
consistency).  
Apart from these criteria, there are also other “ICs” such as DIC (deviance IC) 
[SPI 02] or the GLRT (generalized likelihood ratio test) [STO 04], etc. They are 
used in the estimation of models or in the selection process of models. They will not 
be discussed further in this chapter as they cannot be classed as a generic form [4.1]. 
Table 4.1. Overview of the main criteria 
4.3. The case of auto-regressive (AR) models  
We know there is a real interest in using AR models for the modeling of real 
signals, for example medical signals (ECG, EEG, etc.) or speech signals (encoding 
by PARCOR (partial correlation) coefficients for example).  This fact justifies the 
criterion 
author(s) 
year 
penalty kC(N) 
cost 
consistency 
AIC 
Akaike 
1973 
2k 
K-L 
none 
)
Hannan and 
Quinn 
1978 
kloglogN 
 
weak 
BIC 
Schwarz 
1978 
klogN 
Bayes 
strong 
E
)

El Matouat 
and Hallin 
1994-96 
kNEloglogN 
1
0

 E
 
Stochasitical 
complexity 
 + K-L 
strong 
MDL 
Rissanen 
1978-87 
klogN  
+ (k+2)log(k+2) 
Stochasitical 
complexity 
 
strong 
CAICF 
Bozdogan 
1987-94 
k(2+logN)  
+ log
k
I Tˆ
(
 
K-L 
strong 
AIC* 
El Matouat et 
al. 
1987-94 
k(2+logN) 
K-L + Hellinger 
strong 
AICD
Bhansali et al. 
1977 
Dk 
 
none 

84     Optimization of Image and Signal Processing  
existence and development of IC. So, after an overview of the application of IC to 
an AR model, two applications linked to the analysis of images will be examined in 
this part.  
4.3.1. Origin, written form and performance of different criteria on simulated 
examples 
Many of the previous criteria (AIC, BIC, )) were initially suggested for research 
on the order of an 1D auto-regressive (AR) model. Many studies (e.g. [VAN 86], 
[DIC 94]) have compared these criteria when they are applied within the framework 
mentioned above. 
Note that a random process 
^
`
Z

 
n
n
X
X
 can be modeled by an AR of the order 
k if: 






°
¯
°
®
­

 
 



 ¦
 

2
,
2
1
Z
,
,
et
0
Z
,
m
n
E
E
E
E
E
n
E
X
a
X
m
n
e
m
n
n
n
k
i
i
n
i
n
G
V
 
[4.6] 
where 
m
n,
G
 is the Kronecker symbol and 
^
`
Z

 
n
n
E
E
 is white noise. Using the 
previous annotations and the Gaussian hypothesis, Tk is therefore the model with the 
following (k+1) parameters: ^
`
e
k
a
a
V
),
,...,
(
1
 with 
e
V  being the standard deviation 
of error. It is widely known that the log-likelihood term can be expressed as follows: 
2
ˆ
log
2
e
N
V

, where 
e
Vˆ  is the estimation in the ML sense of 
e
V , and the criteria have 
the following form: 
)
(
ˆ
log
2
)
(
N
kC
N
k
IC
e 
 
V
 
[4.7] 
The chosen order kˆ  and the parameters which have been calculated with the help 
of methods such as Yule-Walker, Levinson, Burg or lattice, therefore have to verify:  
)
(
min
arg
ˆ
k
IC
k
k
 
 
 
 
 
 
 
[4.8] 
In Figure 4.1 the behavior of AIC, BIC/MDL, ), )E, ML, is shown for two 
standard tests:  
– a first  AR of order 2 with a1 = 0.55 and a2 = 0.05; 

Information Criteria     85 
– a second AR of order 15 with a1 = 0.50, a2 = 0.06, a3 = 0 = …. = a14, a15 = 0.45. 
The research on the respective order is based on 100 experiments and the order is 
varied from 0 to 20. The number of observations is N = 1000 and Ve = 1.  The curves 
shown below give an average value of the IC for the 100 experiments. The )E 
criterion has been calculated for values of E equal to 0.1, 0.2, 0.3 and 0.4. The 
criteria BIC/MDL and )E (for E = 0.1, 0.2 or 0.3) give an adequate order. However, 
if ) under-parameterizes because the penalty is too high, even though AIC and ) 
are visually confused when it comes to the curves (because loglog1000 = 1.93 ~ 2) 
and over-parameterize (see Tables 4.2a and 4.2b). The ML criterion therefore 
systematically over-parameterizes. 
Now note the existence of bounds on the value E. For N = 1000, Emin = 0.28,  
Emax = 0.72, EBIC = 0.184 and EAIC = 0.005 (see section 4.2). These values explain the 
placement of the curve associated with BIC between the curves associated with ) 
and ). The curve ) provides the approximate behavior of 
min
E
)
. 
  
Figure 4.1. Curves of average values of ICs for the order k for an AR model  
of order 15 (left) and  for an AR model of order 2 (right) 
Tables 4.2 show the performances of the criteria under a different form:  
– Tables 4.2a show the influence of N more precisely. This is carried out for the 
case of an AR order 15, for AIC, BIC/MDL, ), ). It provides the number of times 
a value k is estimated. This, of course, applies to the 100 experiments named above 
(%). The results will have the same orientation as the convergences given in section 

86     Optimization of Image and Signal Processing  
4.2. Criterion )is not shown as it systematically under-parameterizes. Note that 
for N = 10,000, there is Emin = 0.241, Emax = 0.759, EBIC = 0.154 and EAIC = -0.011. 
These values explain the poor results of AIC AIC has the tendency to over-
parameterize in comparison to ) which corresponds to ) 
– Tables 4.2b give a detailed outline of the results that correspond to an AR 
order 2. The penalty of ) applies to this case even though this criterion 
systematically under-parameterizes. However, even BIC and ) give very 
contrasting results if the number of observations is insufficient. 
 
Tables 4.2a. Influence of the number of observations on the  
behavior of criteriafor an AR order 15 
 
order 
AIC 
BIC 
)
)
)
 
order 
AIC 
BIC 
)
)
)
0 
0 
0 
0 
0 
0 
 
0 
0 
0 
0 
0 
0 
1 
47 
90 
41 
91 
100 
 
1 
0 
1 
0 
9 
100 
2 
35 
10 
34 
9 
0 
 
2 
74 
99 
80 
91 
0 
3 
8 
0 
10 
0 
0 
 
3 
7 
0 
7 
0 
0 
4 
5 
0 
5 
0 
0 
 
4 
2 
0 
2 
0 
0 
>4 
5 
0 
10 
0 
0 
 
>4 
17 
0 
11 
0 
0 
N = 1,000 
 
N = 10,000 
Tables 4.2b. Influence of the number of observations on the  
behavior of criteria for an AR order 2 
order 
AIC 
BIC 
)
)
 
order
AIC 
BIC 
)
)
0 
0 
0 
0 
0 
 
0 
0 
0 
0 
0 
1 
0 
0 
0 
0 
 
1 
0 
0 
0 
0 
… 
 
 
 
 
 
… 
 
 
 
 
 15 
50 
82 
49 
84 
 
15 
65 
100 
74 
100 
16 
9 
5 
9 
3 
 
16 
13 
0 
11 
0 
17 
9 
7 
7 
7 
 
17 
7 
0 
6 
0 
18 
12 
3 
14 
4 
 
18 
6 
0 
5 
0 
19 
14 
3 
15 
2 
 
19 
2 
0 
1 
0 
>19 
6 
0 
6 
0 
 
>19 
7 
0 
3 
0 
order 
AIC 
BIC 
)
)
 
order
AIC 
BIC 
)
)
1 
 
1 

Information Criteria     87 
Also note that if the number of observations N is insufficient in comparison to 
the previously established order of the model (e.g. the order of the AR model is 
greater than 10
N ), Broersen [BRO1 00] suggests two criteria referred to as FSIC and 
CIC. These criteria compensate for the weaknesses of the log-likelihood and the bias 
of the criteria. CIC has also been used for a vectorial extension of ARs, as described 
in [WAE 03]. Other authors such as [SEG 03] base their research on a criterion 
which stems from the Kullback divergence, abbreviated as KIC (for Kullback IC 
[CAV 99]), to make up for the insufficient data.   
Lastly, for the case of ARMA models, different articles such as [KAS 82] or 
[BRO2 00] discuss the different approaches in the use of ICs. These articles 
provide further information. The forms of the criteria are similar to the one 
given in formula [4.7] but with the order k replaced by (p+q), where (p,q) is the 
order of the ARMA model.   
4.3.2. AR and the segmentation of images: a first approach  
In the given hypothesis only one line of images of different gray levels is a 
c
Tˆ  mixture of the AR models. Therefore: 
1 1
1
ˆ
ˆ
(
)
(
,
,
/
)
i
i
c
N
c
n
n
i
i
f x
f x
x
R
R
 


"
 
[4.9] 
where c is the number of AR models (referred to as 
iTˆ , i = 1, …, c), of the 
mixture model 
\ ^
1,...,
ˆ
ˆ
c
i i
c
R
R


. The positions ni, i = 1,…, c-1, correspond to the 
changes in the models (n0 = 0, nc = N) and can be estimated by using a dynamic 
programming algorithm. It is suggested that on every segment [ni-1+1, ni] 
iTˆ  is 
an AR model with order ki and therefore the parameters are the ki coefficients 
and the standard deviation of error. Finally, the retained mixture of AR models 
which minimizes the IC depends on positions ni, on their respective number and 
on the (ki + 1) parameters of AR models on every segment [JOU 98]. To 
subdivide a line of images into c AR models there are 
	 
1
1
c
i
i
c
k
c
B


¬­

­

­

 

­

­

­­

®

 free 
parameters and the IC criteria take the following written form (see [BOU 91] but 
only with the AIC criterion and models with fixed order): 
	 
	 
	 
 	 
ˆ
2
c
IC c
L
c C N
R
B


. 
[4.10] 

88     Optimization of Image and Signal Processing  
First of all, the results obtained from a sequence of synthetic images will be 
given (Figures 4.2). 
A better readability for the order is obtained with the help of the )Eand BIC 
criteria. However, it is clear that in this type of example the interval of validity 
for E is uncertain as it depends on the variable number N of observations per 
model that is taken into account.  
Figures 4.2.  Synthetic image (a) with the behavior of the ICs (c) 
 on the indicated line (b) 
On a natural image (see Figure 4.3a), the diverse changes obtained according 
to the criterion are addressed with the help of a dynamic programming algorithm 
suggested in [THU 97]. Every “white” point corresponds to a change in the 
model of the respective line. The result of the segmentation is shown using BIC 
and )Ewith E = 0.3; E = 0.3 corresponds to the best result. 

Information Criteria     89 
A comparison with the usual techniques of detecting the edges, such as 
Canny-Derriche or Sobel, shows the high quality of these criteria. However, the 
computation needs high complexity. Using an 2D AR could refine the 
segmentation of images even more (see section 4.3.4). 
 
 
 
 
 
Figures 4.3.  (a) Natural image (heart slice); (b) comparison with the  
criteria AIC; (c) BIC/MDL  and (d) )0.3  
4.3.3. Extension to 2D AR and application to the modeling of textures 
In this section, the focus will lie on the BIC criteria (or Kashyap criteria [KAS 
82]) and )Eto characterize textures from the basis of an a priori hypothesis that 
they can be represented by a 2D AR. This extension is not only a simple rewriting 
process of the 1D case since this choice of a support from the “past” is very 
important. Details on this subject can be found in [ALA 03].  
The 2D AR model that has been examined is of a support type D, i.e. a Quarter 
Plane (QP) or a Non-Symmetric Half Plane (NSHP) (Figure 4.4). The model for a 
process 
^
`

2
2
1
2
1
,
,
Z
n
n
n
n
X
X

 
 is written as follows:  
2
1
2
2
1
1
2
1
2
1
2
1
,
,
)
,
(
,
,
n
n
m
n
m
n
D
m
m
m
m
n
n
E
X
a
X


 



¦
 
[4.11] 

90     Optimization of Image and Signal Processing  
where 
^
`

2
2
1
2
1
,
,
Z
n
n
n
n
E
E

 
 is a white noise with variance 
2
e
V . 
  
 
Figure 4.4.  Causal supports QP and NSHP of the order (k1,k2) 
In this configuration the IC criteria are written as follows: 


)
(
1
)
,
(
ˆ
log
2
)
,
(
2
2
1
2
2
1
N
C
k
k
D
N
k
k
IC
e


 
V
 
[4.12] 
where NuN  is here the size of the image and |D(k1,k2)|  is chosen to be the cardinal 
number of D(k1,k2), i.e. the number of elements in the support of the order (k1,k2).  
For a  QP  support, |D(k1,k2)| = (k1+1)(k2+1) - 1, and for an NSHP support, 
|D(k1,k2)| = (2k1+1) k2+k1. 
First of all )E will be tested on synthetic textures which are modeled by 2D AR s 
of the order (i,j) (Figure 4.5). E is still equal to the minimum boundary of the double 
inequality given in section 4.2, i.e. Emin. QP is chosen as a support. For every texture, 
100 images of the different sizes NuN (1st column of Table 4.3) are synthesized and 
the rate of correct order estimation is given as a percentage. 
The results are very satisfying, regardless of the order or size of the images. 
However, the results have proven to be very different from BIC/MDL [ALA 03], as 
this criterion over-parameterizes in comparison to 
min
E
)
 according to section 4.2. 
 
k1 
k2 
k1 
k2 

Information Criteria     91 
 
 
 
(1,1) 
   (2,2) 
   (3,3) 
 
 
(1,3) 
   (5,2) 
Figure 4.5. Different synthetic textures and their corresponding orders  
 
 
 
 
 
 
 
 
 
 
Table 4.3. Behavior of the  
min
E
)
 criterion in comparison to the size NuN of images. 
The textures can be identified due to their respective order  
For natural textures the problem of comparison and validity of the criteria is far 
more complex. To judge the BIC/MDL criteria and 
min
E
)
for these textures the 
initial textures Ti are compared to synthetic textures Ts.  Ts are generated with a 2D 
AR model obtained by the two ICs. The comparison measure is the Kullback 
divergence (see [BAS 96]): 
 
(1,1) (2,2) (3,3) (1,3) (5,2)
45x45
99 
100 
100 
100 
100 
55x55
100 
100 
100 
100 
100 
64x64
100 
99 
100 
100 
100 
80x80
99 
100 
100 
100 
100 
90x90
99 
100 
100 
100 
100 

92     Optimization of Image and Signal Processing  




>
@ 121
)
(
)
(
)
(
)
(
2
1
)
,
(
1
1


 


i
s
s
i
s
i
T
R
T
R
tr
T
R
T
R
tr
T
T
J
 
[4.13] 
R(T) is thus the matrix of the covariance associated with the texture T that has 
been obtained from the QP support of the order (10,10), i.e. R(T) of the size 
121u121. “tr” describes the trace of a squared matrix.    
Figure 4.6a shows Brodatz’s four textures which were tested. Figure 4.6b 
represents the variations of the Kullback divergence, amongst the four textures 
shown in 4.6a, according to the size NuN  of the squared images, for BIC/MDL and 
min
E
)
criteria These are average values of calculated divergences for the different 
sizes of images given in Table 4.3. 
The two criteria are asymptotically comparable. The divergence decreases if N 
increases. Ts, which stems from 
min
E
)
, is however closer to Ti.  
 
 
 
 
D 19 
D 29 
D 38 
D 92 
Figure 4.6a. Brodatz’s textures which were tested 
4.3.4. AR and the segmentation of images: second approach using 2D AR 
In section 4.3.2, the use of AR in the framework of segmentation of natural 
images using simple 1D AR models was shown. In section 4.3.3 it was proven that it 
is possible to obtain a causal 2D AR model associated with a texture which is 
optimal in the sense of information criteria. This section will show how ICs can be 
exploited for an unsupervised segmentation of textured images based on a 2D AR  
model. In order to do this, the order of the associated models of different textures, as 
well as the number of different textures each image contains, need to be estimated. 
A parameter-based model needs to be estimated, 
^ `
K
k
k
,
,1 "
 
 T
T
, where K is the 
number of textures in an image and 
k
T  the AR model with Dk support. 

Information Criteria     93 
 
Figure 4.6b. Values of the Kullback divergence on textures given Figure 4.6a, in 
comparison to the size NuN of images. The QP support is used. As a line: 
min
E
)
;  
as a line of dots: BIC/MDL 
The solution to the problem presented here [ALA 05] is based on an article 
written by Bouman and Liu [BOU 91]. Bouman and Liu have used the AIC criteria 
to estimate K and fixed the orders of the models AR QP associated to different 
textures of the image equal to (1,1). Note that in the majority of articles that have  
been published on unsupervised segmentation, the number of textures within 
textured images is estimated, while the number of parameters of models has been 
fixed beforehand. The optimal orders of the models linked to the respective textures 
and obtained with ICs (section 4.3.3) show to what extent it is insufficient to only 
use a model with (1,1) order. 
The segmentation method can be divided into two steps. The first step consists of 
estimating the parameter-based model of the textured image. The second step 
describes the estimation of the segmented image which takes place in a supervised 
framework. During the first step information criteria come into play. The second 
step is carried out with the help of a simulated annealing (SA) algorithm based on 
Gibbs’ sampler that optimizes a maximum a posteriori (MAP) criterion; the 
segmented image is modeled by a hidden Markov field. 

94     Optimization of Image and Signal Processing  
The first step of the estimation of the parameters of the model associated with 
the textured image works as follows. 
The image is cut into squared blocks (e.g. of the size 8×8 or 16×16) that are 
assumed to be independent of one another1. The distribution of the categories of 
textures into blocks is supposed to follow a multinomial distribution of unknown 
parameters
^
`
K
k
k
,
,1 "
 
 U
U
. If now Ak, k = 1,…, K, describes all blocks that stem 
from the texture k, and if 
k
k
A
W
 
 describes the number of blocks in Ak, such as 
1
K
k
k
W
W



, with W representing the total number of blocks, it is possible to show 
that:  






1
1
,
,
,
,
exp
log
log
k
K
K
A
k
k
k
k
p x A
A
f
x
W
 
T U  

T

U

"
 
[4.14] 
where S is the set of sites of the image, 
^
`
S
s
x
x
s

 
,
 is the textured image, 
^
`
k
s
A
A
s
x
x
k

 
,
 and 

k
Ak
x
f
T
 is the conditional probability law of 
k
A
x
 subject 
to the parameter-based model 
k
T . 
It has been established (section 4.3.2) that [BOU 91] suggests a criterion for the 
estimation of parameters (K,^
`
U
T ,
) and the distribution of the textures to the 
blocks. Here it has been given with a nondescript penalty ([ALA 05]): 


  
1
,
,
,
,
log
2
1
1


u


¦  
K
S
C
A
A
x
p
K
k
k
K
T
U
T
"
 
[4.15] 
The written form of this criterion is analog to formula [4.10] in which the 
number of free parameters is established D(K).  The optimization of this criterion is 
carried out by successive minimization of (K, ^
`
U
T ,
) and the distribution of K 
textures to the blocks. The two other base qualities remain fixed. Note that, for 
k
A
x
the estimation of the order of model 
k
T  is carried out according to formula 
[4.12]. 
Based on the size 256u256 of an image with synthetized textures (Figure 4.7a),  
the “block” segmentation with the help of the )E criterion, used with E = Emin, has 
been obtained (Figure 4.7b). Comparisons were also carried out with the AIC and 
BIC criteria, with mediocre results.  
                              
1. This first division is necessary because the AR hypothesis implies the use of a correlated 
process, as opposed to a mixture of independently and infinitely distributed Gaussian 
processes that implies independence between all elements of the process.  

Information Criteria     95 
Another example of block segmentation is given in Figure 4.8a. However, this 
example shows an image that contains natural textures. Figure 4.8b shows that an 
additional category of texture on the boundaries has been obtained (six categories 
can be detected). The final segmentation after using SA can give results similar to 
the type given in Figure 4.8c, which shows how an undesired category of texture has 
been removed from Figure 4.8b. 
 
Figures 4.7. Image which contains synthetic textures  
 
 
 
 
(a) Observed image 
(b) Image segmented into 
blocks  
(c) Correction with help of 
Simulated Annealing  
Figures 4.8. Image which contains natural textures 
4.4. Applying the process to unsupervised clustering 
An application of ICs as presented here is, in fact, very similar to what has 
already been explained in sections 4.3.2 and 4.3.4. The difference is that the 
chosen parameter-based models are no longer ARs but n-D parameter-based 
laws.  
Different authors have dealt with this unsupervised clustering problem (the 
number of classes or categories or clusters is undefined) such as [BOZ 94] (with 
 
 
(a) Observed image 
(b) Image segmented into blocks  

96     Optimization of Image and Signal Processing  
C(N) = 3), [SAR 96] (dealt with the initial choice of the number of clusters), 
[LEE 00] (with non-Gaussian laws and the estimation based on ML), etc., to 
name just a few authors.  
Here the focus lies on the choice of the number and form of the components 
for a Gaussian mixture model. The estimation method used is the EM algorithm 
which optimizes the function of log-likelihood for a given number of components 
under the hypothesis of observations xN being independent of one another. 
 
Table 4.4. Parameters of the three 2D Gaussian distributions used in Figure 4.9 
If c is the number of components (number of Gaussian laws in the mixture) 
and n is the dimension of space of observations (
,
1,
,
n
x
i
N
i 
 
"
IR
), the 
number of free parameters D(c) is equal to (according to [JOU 00]) 
2
)
2
)(
1
(
)
(


 
n
n
c
c
D
. The optimal number of components still needs to verify 
(see formula and written form [4.10]): ˆ
argmin
( )
c
IC c

.  
As a first example there is n = 2 and the parameters of the three components 
of the Gaussian mixture are given in Table 4.4 and represented in Figure 4.9a 
with N = 900 samples subdivided into three clusters.  
Figures 4.9b to 4.9e show the evolution of different clusters estimated by the 
EM following the number c = 1,…,4. Every ellipsis represents a curve of 
isodensity for every estimated Gaussian component. Figure 4.9f shows a good 
readability of )0.3 (Emin = 0.282). 
 
 
Population 
 Expectation vector 
Covariance matrix  
 
n1 = 300 
P = 
»¼
º
«¬
ª
0
5
 
6 
»¼
º
«¬
ª
1
0
0
1

 
n2 = 300 
P = 
»¼
º
«¬
ª
0
0
 
6 
»¼
º
«¬
ª
3
2
2
5

 
n3 = 300 
P = 
»¼
º
«¬
ª
0
5
 
6 
»¼
º
«¬
ª
1
0
0
1


Information Criteria     97 
              
           
      
 
 
(a) 
 
 
 
 
(b) 
      
           
      
(c)   
 
 
 
 
(d)  
    
    
 
 
 
    (e)  
 
 
 
 
(f) 
Figures 4.9. (a) Original model (c = 3); (b) to (e) Gaussian mixture models identified for 
different values of c; (f) number of components c identified by different ICs.  
The AIC3 criterion for the penalty C(N) = 3 
Figure 4.10 shows an example of realistic uses of ICs [COU 98] in the case 
where the space of observations is IR, and therefore with n = 1. This sample is part 
of an envelope with 256 gray levels (Figure 4.10a), and the localization of the 
threshold (changes of Gauss laws) on the histogram of gray levels is shown (Figure 
4.10b) as well as, last but not least, the image which represents the threshold of three 
different grayscales  (Figure 4.10c). The IC criterion is used as a variant of BIC 
written AIC* (section 4.2) [EM 96]. The threshold T1 is the result obtained with  
c = 2 components. T21 and T22 correspond to c = 3 components that minimize AIC*. 

98     Optimization of Image and Signal Processing  
The use of ICs in this example appears to be an improvement of Kittler’s work and 
the work of the founders of histogram segmentation ([KIT 86], [KUR 92], [WAN 
94], etc.). Some authors have also shown to what extent traditional penalties such as 
AIC or BIC/MDL are insufficient for this type of application. They have therefore 
suggested empirical values for C(N) of a type that has been mentioned in section 4.2 
([LIA 92] or [THU 97]). 
To end this part dealing with unsupervised clustering, problems with the 
detection of sources that are linked to the ICs can also be mentioned as [FIS 00], 
where the number of signals which fall in an observation process is estimated using 
MDL, and the limits which therefore become possible due to the ICs’ method [CHE 
04].  In [BIE 00], the authors are interested in the number of models that represent a 
population per integrated completed likelihood (ICL) criterion. ICL should be more 
robust than BIC/MDL. 
   
   
 
 
  
 
       T21    T1   T22 
(a)  
 
 
 
(b) 
 
 
(c) 
Figures 4.10. (a) Initial image; (b) histogram of gray levels and the localization of the 
threshold; (c) image obtained after thresholding 
4.5. Law approximation with the help of histograms 
4.5.1. Theoretical aspects  
The use of ICs was linked to research on the number of classes in a histogram 
that represents an approximation of a theoretical law T followed by a random 
process X. X is given by N observations xN and this process is strictly stationary. The 
aim is to find the histogram that best summarizes the law, i.e. the number and the 
size of intervals or classes that make up this particular histogram. Note that this no 
longer deals with the research of parameter-based models. Obtaining the criteria is 
therefore different. [OLI 94] shows an extension of the AIC criteria to histograms, 
justified by Hellinger’s distance, and demonstrates the AIC* criterion, which has 
already been mentioned, in the histogram case. 

Information Criteria     99 
Note ^
`
k
r
Br
,...,
1
,  
 which defines the k intervals of the histogram. In this case 
the IC criteria defining the number of intervals are written in the following form:  
ˆ (
)
(
)
1
ˆ
( )
(1
(
))
2
(
)log
k
r
r
k
B
k
r
B
r
IC k
k
C N
N
B
R
N

 
¯



R
¡
°
¡
°
¢
±

 
[4.16] 
where 
k
Tˆ  is the estimation of the law Tin the ML sense, P is an a priori law 
according to which T  is absolutely continuous with respect to P. 
 It is shown that: ˆ (
)
number of values x in Br
i
Br
k
N
R

. The desired partition with k 
intervals is the one that minimizes the IC. 
The penalty therefore differs from previous formulae because k is the number of 
intervals and not the number of free parameters.  The k Br can be obtained using the 
maximum likelihood. Note that [RIS 92] suggests the method of histogram density 
estimation based on the MDL principle with Br intervals of the same size.  
4.5.2. Two applications used for encoding images  
Rissanen’s MDL criterion has its origins in the research on the minimal 
description that is needed to encode a message or information. More precisely, this 
technique is more refined than the simple entropic encoding of information. This 
technique consists of arithmetic encoding which does not encode individual symbols 
that contain information, but instead encodes a sequence of symbols. For more 
information interested readers can see [GUI 02] or take a look at the texts published 
on the encoding of fixed images with different gray levels or different colors [HAN 
00], [MAD 04], or with video sequences [PAT 98], and references to MPEG 4 and 
H264 standards. 
The two examples that will be given in this section do not deal with binary 
encoding processes. They are examined with respect to the ICs having a direct 
impact on the encoding of pixels or the quantization phase.  
The first is an encoding problem relating to the different gray levels in an image 
[COU 98], [COQ 07]. Distribution (Figure 4.11b) of the 256 gray levels of the Lena 
image with N = 512u512 pixels (Figure 4.11a) will be presented below. Figure 4.11c 
shows a histogram that has been obtained with the help of the AIC* (k = 40) and the 
effect (Figure 4.11d) on the Lena image, which is then encoded in 40 gray levels. 
With 
min
E
)
, we obtain k = 39. The result can be interesting in terms of compression 
of the image and satisfactory in terms of visual quality. Note that PSNR (peak signal 

100     Optimization of Image and Signal Processing  
to noise ratio) is equal to 38.52 dB with k = 39 and using
min
E
)
. The result becomes 
even more interesting if the image is made up of homogenous areas of gray levels, 
which improves the compressing levels after the image has been transformed using 
discrete cosine transformation (DCT) or discrete wavelet transforms (DWT).  
Figures 4.11. (a)Lena image; (b) distribution of the 256 gray levels; (c) histogram obtained 
by IC (k = 40 intervals); (d) Lena image encoded on 40 different gray levels 
The second example shows a possible application of ICs in a schema of encoding 
/quantization of a line of code and transmission (encoding source). DCT is used 
here, even though the wavelets (DWT) can enter the schema following subband 
quantization. 
Without going into too much detail, it is important to bear in mind that the initial 
image has been transmitted and split up into blocks of the size 8 u 8 of DCT 
coefficients which are decorrelated overall. The first term is called DC and 

Information Criteria     101 
corresponds to the null frequency. Its value is usually high. The 63 other coefficients 
referred to as AC can be close to zero where such a transformation is of interest.  
The distribution of AC values takes place with the position n within the 63 
possible positions. For an image of 512 u 512 there is N = 4,096 DCT coefficients 
for each of the 63 distributions. The given problem is a problem of non-uniform 
scalar quantization. Its aim is to determine the threshold of a zone referred to as 
“dead zone”, i.e. the value under which the coefficient AC will be zero. Other 
coefficients are quantified by other methods that guarantee the minimization of rate-
distortion (e.g. RD-OPT method) [RAT 00]. 
Figure 4.12a shows a test image entitled “boat” and Figure 4.12b shows a 
distribution of the AC coefficients for the position n, as well as the histogram 
obtained with 
min
E
)
The coefficients in the “zero” class will be put to zero. Figure 
4.13 compares the standard JPEG method, 
min
E
)
 linked to RD-OPT method 
(referred to as IC + RD-OPT) [OUL 03] and the RD-OPT method on its own in 
terms of PSNR. To judge the issue of introducing ICs into the quantization module 
in an impartial manner, our team has developed a new technique (written down next 
to the figure as “theory + RD-OPT”). This new technique is based on a quantization 
that stems from the a priori law of coefficients (the law PRf formula [4.16]) which 
was suggested to be a Laplacian law. In abscissa there is the measured rate of the 
number of bits per pixel (bpp). 
The result is satisfying (gain of several dB) when compared to the JPEG standard 
at a low rate. This method out-performs RD-OPT by between 0.25 bpp and 0.6 bpp. 
These results were observed for the entire sequence of tests and reached up to 0.5 
bpp. This technique is weaker than the method entitled “theory + RD-OPT” but the 
IC-based method does not require any parameters to be established beforehand, 
which is not the case for the other two methods. The explanation of this weakness is 
that adjacent classes of a similar number, i.e. of AC with high values (the 
“extremities” of Laplacian law in Figure 4.12b) are merged, contrary to the aim of 
this research. Indeed, if the rate is increasing (above to 0.7 bpp) the IC method is no 
longer of any interest.   

102     Optimization of Image and Signal Processing  
       
 
(a)                                                              (b) 
Figures 4.12. (a) Test image: boat; (b) distribution of an AC coefficient (n = 37) and merging 
of the intervals by 
min
E
)
 on image (a) 
 
Figure 4.13. Behavior of the IC-based method compared to other techniques 
Note that when using ICs for high frequency subbands of wavelet-based 
compression methods (JPEG2000), the a priori law of formula [4.16] works in the 
same way as a generalized Gaussian distribution.  
In conclusion, IC for the creation of histograms can be interesting due to the 
unsupervised choice of parameters which determine quantization. These parameters 
determine the number of intervals in the quantization process and the length of the 
intervals. As for the use of ICs on the arithmetic encoding (MDL), it has been 
mentioned in the introduction of this section.   

Information Criteria     103 
4.6. Other applications 
4.6.1. Estimation of the order of Markov chains 
For a homogenous and ergodic Markov chain with M states and length N, the 
order k is to be found.  
Noting 
i
i
i
k
n
,
,...,
1
 as the number of occurrences of (k + 1) in successive states (i1, 
…, ik, i) observed in the chain. In the sense of maximum likelihood the following 
applies: 
¦
 
 
 
 


i
i
i
i
i
i
i
ML
k
t
k
t
t
k
k
n
n
i
X
i
X
i
X
P
,
,...,
,
,...,
1
1
1
1
)
,...,
/
(
,  
and the criteria are written in the usual from: 
)
(
)1
(
log
2
)
(
,
,...,
,
,...,
,
,...,
1
1
,
,...,
1
1
N
C
M
M
n
n
n
k
IC
k
i
i
i
i
i
i
i
i
i
i
k
k
i
ki
i
k



 
¦
¦
 
[4.17] 
To validate this method, a binary chain is simulated with M = 2, order k = 2, N = 
10,000, with Mk+1 parameters which are the following probabilities:  
P(1/11) = 0.3; P(1/01) = 0.4; P(1/10) = 0.8; P(1/00) = 0.1; 
P(0/11) = 0.7; P(0/01) = 0.6; P(0/10) = 0.2; P(0/00) = 0.9. 
When ignoring the initial probabilities, we observe 4 free parameters can be 
obtained: Mk+1 – Mk = Mk(M-1) = 4. These free parameters are represented in factor 
C(N) in formula [4.17]. 
Table 4.5 is based on the results of principal criteria indicated as a percentage. 
This example confirms the information on types of convergence and predictable 
orders of a model according to the chosen criterion stated in section 4.2.  
  

104     Optimization of Image and Signal Processing  
 
 
 
 
 
 
 
Table 4.5. Searching for the order of a Markov model 
[OLI 97] describes an application of these criteria in the context of the 
handwritten information on checks. All words in the dictionary make up a Markov 
model. The aim is to obtain the optimal order k of this Markov model MM(k) to 
determine the handwritten amount on the check by reading the words (e.g. 35 
dollars/euros).  
A tool is available in the form of an alphabet of M = 15 states (known as 
graphemes), which represents letters or parts of letters. In this case, we dispose of  
N = 63,000 observations for a learning process of the model parameters, such as 
probabilities of initial states or the probability matrix for transition of order k. Only 
ICs of the order 0 (independent states) up to order 3 have been tested – for reasons 
of complexity and validity of the calculation of different parameters.  
These tests have shown that the obtained order (k = 2) and the associated Markov 
model MM(2) effectively correspond to the best rate when it comes to identifying 
the words written on a check.   
The application of ICs to Markov fields where the parameters (choosing 
potentials, choosing the environment) could be optimized seems natural. To our 
knowledge, this task has yet to be carried out successfully due to the challenge of 
determining the number of free parameters and obtaining different laws in the ML 
sense in a learning process.  
4.6.2. Data fusion 
Last but not least, two applications which have been tested in the field of 
pattern recognition will be presented. 
order 
AIC 
BIC/MDL )

min
E
)
 
0 
0 
0 
0 
0 
1 
0 
0 
0 
0 
2 
85 
100 
91 
100 
3 
12 
0 
9 
0 
>3 
3 
0 
0 
0 

Information Criteria     105 
1 – The choice of attributes or features as well as deciding on how many of those 
should be used in an identification process is a widely recorded issue. In a book 
published in 1986, Sakamoto [SAK 86] showed how the AIC criterion could be 
applied to the selection process of the most informative features within a respective 
population. This idea was taken up once more [OLI 96] for the identification of 
handwritten Arabic numbers (basis of N = 10,000 samples per number) with the help 
of Hu’s seven invariant moments. The results can be questioned, again due to the 
complexity of the calculation. Despite the low number of attributes, the quantity of 
models to be tested has been high due to the possible combination of moments (in 
this case 126 combinations). These combinations have to undergo a significant 
learning process, which is, however, impossible for the case of 10,000 samples per 
number.   
2 – A theoretical study in [LEF 00] has integrated AIC into an algorithm aiming 
at the fusion of information taken from a set of features. The criteria applied to 
histograms allow for a more “realistic” calculation of reliability coefficients could 
be assigned to every primitive. They also refined a Dempster-type operator of 
fusion. We have applied  the method by [LEF 00] to the identification process of 
inner walls situated very close to one another by taking 
min
E
)
as a criterion instead 
of AIC. The context is the learning process in an indoor environment for wireless 
communication.  These inner walls should be recognized according to their different 
radio-electric qualities that stem from differences in their surface. Three geometric 
and frequential measures are chosen [XIA 04] as features. We study two types of 
roughness (Figure 4.14) using these three measurements, which are at least 
considered to be decorrelated. Two primitives are badly processed (reliability 
coefficients not connected to 1 – see Dempster-Shaffer theory). The tests are carried 
out on 108 samples size 64u64 of every texture. As a decision-making tool, pignistic 
probability is used [LEF 00]. This method delivers the best result if the tool is of a 
square measure weighted by inversing the variances (subject to the hypothesis of 
effective decorrelation of attribute measures (otherwise see Mahalanobis or 
Kullback-Leibler measures)). 
These two simple examples confirm that the use of ICs in a large number of 
applications aimed at the pattern recognition is not only possible, but could also help 
to make algorithms used in these processes less complex while increasing their 
significance. 

106     Optimization of Image and Signal Processing  
 
 
Figure 4.14. Examples of the coating on indoor walls which are to be identified 
4.7. Conclusion 
Finally, and without going back to the applications mentioned in this chapter, 
information criteria have the advantage of providing justification of the choice of 
parameters in several problems linked to the processing of signals and images. They 
require a high amount of observations similar to stochastic approaches, if these 
statistics are to make sense. However, as has been mentioned for the case of ARs, 
penalties can eventually be adapted if there is a low number of observations. The 
complexity of the calculation might be very high, especially in an unsupervised 
context, but dynamic programming algorithms can reduce the level of complexity 
for certain applications. 
4.8. Appendix 
4.8.1. Kullback (-Leibler) information 
Kullback (-Leibler) information between two probability laws f(./T) and f(./O) is 
defined as follows:  




(
)
( ,
)
(
) log
log
log
(
)
f
X
K
f
X
dX
E
f
X
E
f
X
f
X
T
T
T
ª
º
ª
º
T O
 
T
 
T

O
¬
¼
¬
¼
O
³
 
The Shannon entropy can be observed in the first term of the difference as well 
as mutual information in the second term.  
Kullback divergence, which is symmetric, is equal to: K(T,O) + K(O,T). 

Information Criteria     107 
4.8.2. Nishii’s convergence criteria [NIS 88] 
Nishii’s convergence criteria set up the conditions under which the IC(k) criteria 
are consistent, i.e. respectively strongly or weakly. Therefore the following applies:  
if: 
0
)
(
lim
 
f

N
N
C
 and  
f
 
f

N
N
C
log
log
)
(
lim
 so 
ˆ
lim k k
f
  (almost sure convergence); 
if: 
0
)
(
lim
 
f

N
N
C
 and 
f
 
f

)
(
lim
N
C
 so 
1
)
ˆ
(
lim
 
 
f

k
k
P
 (convergence in probability). 
4.9. Bibliography 
[AKA 73] AKAIKE H., “Information theory and an extension of the maximum likelihood 
principle”, 2nd Int. Symposium on Information Theory , Budapest, p. 267-281, 1973. 
[ALA 03] ALATA O., OLIVIER C., “Choice of a 2D causal AR Texture Model using 
Information Criteria”, Pattern Recognition Letters, 24, no.9-10, p. 1191-1201, 2003. 
[ALA 05] ALATA O., RAMANANJARASOA C., “Unsupervised Texture Image Segmentation 
using 2-D Quarter Plane Autoregressive Model with Four Prediction Supports”, Pattern 
Recognition Letters, 26, p. 1069-1081, 2005. 
[BAR 98] BARRON A., RISSANEN J., YU B., “The MDL Principle in Coding and Modeling”,  
IEEE Trans. On Information Theory, 44, no.6, p. 2743-2760, October 1998. 
[BAS 96] BASSEVILLE M., “Information: entropies, divergences et moyennes” Publication 
Interne IRISA, no.1020, May 1996. 
[BHA 77] BHANSALI R., DOWHAM D., “Some properties of the order of an AR Model 
selected by a Generalization of Akaike’s FPE Criterion”, Biometrika, 64, p. 547-551, 1977. 
[BIE 00] BIERNACKI C., CELEUX G., GOVAERT G., “Assessing a mixture Model for Clustering 
with the integrated completed Likelihood”, IEEE Trans. on PAMI, 22, no.7, p. 719-725, 
July 2000. 
[BOU 91] BOUMAN C.A., LIU B., “Multiple resolution segmentation of textured images”, 
IEEE Trans. on PAMI, vol. PAMI-13, no. 2, p. 99-113, February 1991. 
[BOZ 94] BOZDOGAN H., “Mixture-Model cluster analysis using model selection criteria and 
a new informational measure of complexity”, Proc. of the First US/Japan Conf. on the 
Frontiers of Statistical Modeling: An Informational Approach,  Kluwer Academic 
Publishers, p. 69-113, 1994. 
[BRO1 00] BROERSEN P.M., “Finite sample Criteria for AR order Selection”, IEEE Trans. on 
Signal Processing, 48, no.12, p. 3550-3558, December 2000. 
[BRO2 00] BROERSEN P.M., “AR Model Order for Durbin’s MA and ARMA Estimators”, 
IEEE Trans. on Signal Processing, 48, no.8, p. 2454-2457, August 2000. 

108     Optimization of Image and Signal Processing  
[CAV 99] CAVANAUGH J.E., “The Kullback Information Criterion”, Statistics and Probability 
Letters, 42, p. 333-343, 1999. 
[COQ 07] COQ G., OLIVIER C., ALATA O., ARNAUDON M., “Information criteria and 
arithmetic codings: an illustration on raw images”, 15th EUSIPCO – EURASIP, Poznan 
(Poland), pp 634-638, September 2007. 
[COU 98] COURTELLEMONT P., OLIVIER C., JOUZEL F., “Information criteria for histogram 
thresholding techniques”, EUSIPCO’98, Signal Processing IX, Rhodes (Greece), 4, p. 
2509-2512, September 1998. 
[DIC 94] DICKIE J., NANDI A., “A comparative Study of AR-order selection methods”, Signal 
Processing, 40, no.2, p. 239-256, 1994. 
[ELM 96] EL MATOUAT A., HALLIN M., “Order selection, stochastic complexity and 
Kullback-Leibler information”, Springer Verlag, Time Series Analysis, 2, p. 291-299, 
New York, 1996. 
[FIS 96] FISCHLER E., MESSER H., “On the use of order statistics for improved detection of 
signal by the MDL criterion”, IEEE Trans. on Signal Processing, 48, no.8, p. 2242-2247, 
August 2000. 
[GRU 04] GRÜNWALD P., “A tutorial introduction to the minimum description length 
principle”, Advances in Minimum Description Length: Theory and Applications, MITT 
Press, 2004. 
[GUI 02] GUILLEMOT C., PATHEUX S., “Eléments de théorie de l'information et de 
communication”, Compression  et codage des images et des vidéos, ed. M. Barlaud and C. 
Labit, Hermes, p. 22-43, 2002.  
[HAN 79] HANNAN E.J., QUINN B.G., “The determination of the order of an  
autoregression”, Journal of the Royal Statistic Society, 41, no.2, p. 190-195, 1979. 
[HAN 00] HANSEN M., BIN Y., “Wavelet thresholding via MDL for natural images”, IEEE 
Trans. on Information Theory, 46, no.5, p. 1178-1188, August 2000. 
[JOU 98] JOUZEL F., OLIVIER C., EL MATOUAT A., “Information criteria based edge  
detection”, EUSIPCO’98, Signal Processing IX, Rhodes (Greece), 2, p. 997-1000, September 
1998. 
[JOU 00] JOUZEL F., OLIVIER C., EL MATOUAT A., “Choix du nombre de composantes d’un 
modèle de mélange gaussien par critères d’information”, 12ème Congrès RFIA, Paris 
(France), 1, p. 149-156 , Feburary 2000. 
[KAS 82] KASHYAP R., “Optimal choice of AR and MA parts in autoregressive moving 
average models”, IEEE Trans. on PAMI, 4, p. 99-104, 1982. 
[KAS 83] KASHYAP R., CHELAPPA R., “Estimation and choice of neighbors in spatial-
interaction models of images” , IEEE Trans. on Information Theory, 29, no.1, p. 60-71, 
1983. 

Information Criteria     109 
[KIT 86] KITTLER J., ILLINGWORTH J., “Minimum error thresholding”, Pattern Recognition, 
19, p. 41-47, 1986. 
[KUN 91] KUNDU A. HE Y., “On optimal order in modeling sequence of letters in words of 
common language as a Markov chain”, Pattern Recognition, 22, no.7, p. 603-608, 1991. 
[KUR 92] KURITA T., OTSU N., ABDELMALEK N., “Maximum likelihood thresholding based 
on population mixture models”, Pattern Recognition, 25, no.10, p. 1231-1340, 1992. 
[LEE 00] LEE T., LEWICKI M., SEJNOWSKI T., “ICA mixture models for unsupervised 
classification of non-Gaussian classes and automatic context switching in blind signal 
separation”, IEEE Trans. on PAMI, 22, no.10, p. 1078-1089, Octobre 2000. 
[LEF 00] LEFEBVRE E., COLOT O., VANNOONRENBERGHE P.,  “Contribution des mesures 
d’information à la modélisation crédibiliste de connaissance”, Traitement du Signal, 17, 
no.2, p. 87-97, 2000. 
[LIA 92] LIANG Z., JASZACK J., COLEMAN R., “Parameter estimation of finite mixture using 
the EM algorithm and IC with  application to medical image processing”, IEEE Trans. on 
Nuc. Science, 39, no.4, p. 1126-1131, 1992. 
[MAD 04] MADIMAN M., HARRISON M., KONTOYIANNIS I., “MDL vs maximun likelihood in 
lossy data compression “, IEEE-Int. Symposium on Information Theory, 461, July 2004. 
[NIS 88] NISHII R., “Maximum likelihood principle and model selection when the true model 
is unspecified”, Journal of Multivariate Analysis, 27, p. 392-403, 1988. 
[OLI 94] OLIVIER C., COURTELLEMONT P., COLOT O., DE BRUCQ D., EL MATOUAT A.,  
“Comparison of histograms: a tool of detection”, European Journal of Diagnosis  and 
safety in Automation, 4, no.3, p. 335-355, 1994. 
[OLI 96] OLIVIER C., COURTELLEMONT P., LECOURTIER Y., “Histogrammes et critères 
d’information en reconnaissance de formes”, 10ème Congrès RFIA, Rennes (France), 2, p. 
1033-1042, January 1996. 
[OLI 97] OLIVIER C., PAQUET T., AVILA M., LECOURTIER Y., “Optimal order of Markov 
models applied to bank checks” Int. Journal of Pattern Recognition and Artificial  
Intelligence, 11, no.8, p. 789-800, 1997. 
[OUL 01] OULED-ZAÏD A., OLIVIER C., ALATA O., MARMOITON F.,  “Optimisation du codage 
d’images par les critères d’information”, 18ème GRETSI, paper # 316 – Toulouse (France), 
September 2001. 
[OUL 03] OULED-ZAÏD A., OLIVIER C., ALATA O., MARMOITON F., “Transform image coding 
with global thresholding: application to baseline JPEG”, Pattern Recognition Letters, 24, 
no.3, p. 959-964, April 2003. 
[PAT 98] PATEUX S., Segmentation spatio-temporelle et codage orienté-régions de séquences 
vidéo basés sur le formalisme MDL, PhD thesis, University of Rennes 1, September 1998. 
[RAT 00] RATNAKAR V., LIVNY M., “An efficient algorithm for optimizing DCT 
quantization”, IEEE Trans. Image Processing, 9, no.2, p. 267-270, Feburary 2000. 

110     Optimization of Image and Signal Processing  
[RIS 78] RISSANEN J., “Modeling by shortest data description”, Automatica, 14, p. 465-471, 
1978. 
[RIS 89] RISSANEN J., Stochastic Complexity in Statistical Inquiry, World Scientific ed., New 
Jersey, 1989. 
[RIS 92] RISSANEN J., SPEED T.P., YU B., “Density estimation by stochastic complexity”, 
IEEE Trans. on Information Theory, 38, no.2, p. 315-323, March 1992. 
[SAK 86] SAKAMOTO Y., ISHIGURO M., KITAGAWA G., AIC in Statistics Mathematics and 
Applications, KTK Scientific Publishers, Tokyo, 1986. 
[SAR 96] SARDO L., KITTLER J., “Minimum complexity PDF estimation for correlated data”, 
ICPR'96, p. 750-754, 1996. 
[SCH 78] SCHWARZ G., “Estimating the dimension of a model”, The Annals of Statistics, 6, p. 
461-464, 1978. 
[SHI 76] SHIBATA R., “Selection of the order of an AR model by AIC”, Biometrika, 63, p. 
117-126, 1976. 
[SEG 03] SEGHOUANE A.K., BEKARA M., FLEURY G., “A small sample model selection 
criterion based on Kullback symmetric divergence”, IEEE-ICASSP'03, Hong-Kong, 6, p. 
145-148, April 2003. 
[SPI 02] SPIEGELHALTER J., BEST N.G., CARLIN B.P., VAN DER LINDE A., “Bayesian 
measures of model complexity and fit”, Journal of the Royal Statistic Society, Series B, 
64, p. 583-640, 2002. 
[STO 04] STOICA P., SELEN Y., LI J., “On IC and the GLRT of model order selection”, IEEE 
Signal Processing Letters, 11, no.10, pp 794-797, October 2004. 
[THU 97] THUNE M., OLSTAD B., THUNE N., “Edge detection in noisy data using finite 
mixture distribution analysis”, Pattern Recognition, 3, no.5, p. 685-699, 1997. 
[VAN 86] VAN ECK, “On objective AR model testing”, Signal Processing, 10, p. 185-191, 
1986. 
[WAE 03] DE WAELE S, BROERSEN P.M., “Order selection for vector autoregressive  
Models”, IEEE Trans. on Signal Processing, 51, no.2, p. 427-433, Feburary 2003. 
[WAN 94] WANG Y., LEI T., MORRIS J.M., “Detection of the number of image regions by 
minimum bias variance criterion”, SPIE-VCIP’94, 2308, Chicago, p. 2020-2029, 
September 1994. 
[XIA 04] XIA F., OLIVIER C., KHOUDEIR M., “Utilisation d’une modélisation crédibiliste pour 
une aide à la décision dans un environnement indoor”, SETIT'04, CD-ROM, Vol. Image, 
Sousse (Tunisia), March 2004. 
 
 
 

Chapter 5
Quadratic Programming and Machine
Learning – Large Scale Problems and Sparsity
5.1. Introduction
For a child, learning is a complex process that consists of acquiring or developing
certain competencies on the basis of multiple experiences. For a machine, this
learning process can be reduced to examples or observations that are used to improve
performance. Machine learning can be seen as the optimization of criteria deﬁned on
examples. The higher the number of examples, the better the learning process. In
terms of optimization, this learning process includes several speciﬁc problems. How
are the criteria to be optimized deﬁned? How can we manage large amounts of data?
Which algorithm is efﬁcient in this context?
When dealing with those problems, neural network approaches suggest the usage
of non-convex criteria associated with gradient descent methods. This procedure
leads to several difﬁculties linked to the non-convex criteria. The key to the success
of kernel-based methods (obtained about a decade after the introduction of neural
networks) is their capacity to express the learning problem as a large scale quadratic
programming problem (convex). Kernel-based methods often lead to sparse solutions,
i.e. a large number of their components equal zero. Based on this particularity,
learning algorithms can solve large scale problems in a reasonable time. Solving
this type of problem currently takes about one day of calculating when using a
mono-processor for 8 million unknowns. Among these 8 million unknowns only 8,000
to 20,000 variables do not equal zero depending on the complexity of the problem.
Chapter written by Gaëlle LOOSLI and Stéphane CANU.
Optimization in Signal and Image Processing 
Edited by Patrick Siarry 
Copyright 0 
2009, ISTE Ltd 

112
Optimization in Signal and Image Processing
This chapter deals with quadratic programming for machine learning. In the
general case of quadratic programming, “interior points” methods are the most
efﬁcient. On the other hand, when it comes to quadratic programming for machine
learning, “active set” or “active constraint” methods are of a higher performance.
This is due to the fact that “active set” methods take advantage of the geometric
particularities of the problem and have sparse solutions.
Algorithms which are based on “active sets” have to know all training points in
advance to provide the exact solution to a problem. This functioning is known as
“off-line” or “batch”. Not all machine learning problems, however, are covered by
this type of algorithm. It may occur that data are revealed during learning. This type
of learning process is referred to as “on-line”. On-line learning processes must also be
used if the database is too large for all examples to be processed simultaneously. This
even applies if all examples are known right at the beginning. The on-line framework
has led to iterative stochastic optimization methods that are adapted to large scale
and sparse problems. It is widely accepted that no method of polynomial convergence
(especially quadratic programming) can be used to solve problems of large dimensions
[NEM 05]. However, if this is true when looking for precise solutions, it is possible
to develop methods that provide non-optimal solutions (which can be neglected given
the incertitude of examples), but much faster. An on-line stochastic approach will be
presented that can both solve large scale and/or on-line problems and thus outperform
off-line methods.
This chapter is organized as follows. First the general framework of learning
processes and tools for convex quadratic programming will be explained. Secondly
“active sets” and their usage of geometrics and sparsity will be shown. A very
efﬁcient method of iterative stochastic optimization, LASVM, will also be explained.
Last but not least, some results of experiments will underline the possibilities offered
by the method described above.
5.2. Learning processes and optimization
Statistical learning based on data use form vectors x of dimension d. For
supervised learning, every individual x comes with its label y. This label characterizes
the individual (its group, value, structure etc.). The aim of learning is to enable a
machine to ﬁnd the label of a speciﬁc piece of data.
5.2.1. General framework
Deﬁne the family P, of all laws on (Rd × {−1, 1}). Training points are generated
from a unknown probability law P(x, y). Within this framework the result of the
learning process is deﬁned as the function f (for more information on this function see
section 5.2.2) which for all P ∈P is able to classify well (on average) points drawn
from P with a high probability, depending on the sample.

Quadratic Programming and Machine Learning
113
DEFINITION 5.1. The training set {X d
n, Yn} contains all known examples drawn from
the underlying law of P(x, y) ∈P. The size of this database is n and every example
(or individual) is xi, with i ∈[1, n]. The examples lie in a space of dimension d
(usually Rd). The labels associated with each example are mainly scalars. The most
frequent cases are yi ∈R for regression and yi ∈{−1, 1} for discrimination.
DEFINITION 5.2. The test set {X d
t , Yt} represents a group of unseen examples
generated by the same law P(x, y) ∈P.
An algorithm is efﬁcient if it is able to provide similar results (in terms of errors)
for the training set as well as the test set. This type of performance is referred to as the
ability to generalize.
DEFINITION 5.3. The empirical risk measures the algorithm’s efﬁciency on the
training set depending on a given cost function C.
Remp[f] = 1
n
n

i=1
C(f, xi, yi)
with, for example
C

f, xi, yi

= 1
2
f

xi

−yi
.
The empirical risk is to be minimized during the learning process.
Nothing guarantees that if the function f provides low empirical risks, it also
obtains good results for unknown data. Generalization has to be checked and the risk
has to be taken into account during the learning process.
DEFINITION 5.4. The risk is a similar idea to the empirical risk but concerns test
data. As this type of data is unknown, P(x, y) is required to express the risk:
R[f] = E

C(f, X, Y )

=

C(f, x, y)dP(x, y).
In order to do this, the empirical risk and a quantity that controls generalization
error are minimized together. The statistical theory of learning (see [VAP 95, SCH 02]
for more details) uses the notion of capacity to express this type of quantity.
DEFINITION 5.5. The capacity of an algorithm is deﬁned as the cardinal of the
space of hypothesis. In the case of inﬁnite dimension, the capacity is deﬁned by
VC-dimension.
VC-dimension provides a notion of capacity for a group of functions.
VC-dimension is deﬁned by the number of points that can be separated in every
possible manner by the functions of this group. On the basis of VC-dimension, the
Vapnik-Chervonenkis theory provides bounds on the risk. The risk can therefore be

114
Optimization in Signal and Image Processing
bounded in terms of the empirical risk, the capacity of functions to be used (their
VC-dimension h) and the number of training examples with a probability 1 −η for
C = 1
2|f(xi) −yi|, [BUR 98, equation 3, page 3]:
R[f] ≤Remp[f] +

h

log(2n/h) + 1

−log(η/4)
n
.
The idea consists of obtaining sufﬁciently ﬂexible functions to be able to learn data
but also sufﬁciently regular to generalize well. The learning process is therefore seen
as an optimization problem of two criteria. These criteria are ﬁnding the function of
the weakest capacity and minimizing the empirical risk.
5.2.2. Functional framework
A learning algorithm chooses the best solution from all hypotheses H depending
on the training set and the two criteria to be optimized. Kernel-based methods build
the pool of hypotheses H using the kernel. When it comes to classifying the points,
it makes sense to know which objects are close to each other or are similar to each
other. If it is possible to establish the distance between two objects, no matter what
their form is, this information is sufﬁcient to carry out the process of discrimination.
The kernel is deﬁned on the basis of this idea.
DEFINITION 5.6. A kernel is a symmetric function with two variables that returns a
scalar to express the distance between two variables. If s, t ∈Rd, k is deﬁned as:
k : Rd × Rd −→R
s, t −→k(s, t)
On the basis of the kernel (if it positive deﬁnite1) the space of hypothesis can be
constructed via the pre-Hilbertian space.
DEFINITION 5.7 (Pre-Hilbertian space). Let k be a positive deﬁnite kernel. H0 is
deﬁned as the vector space based on the linear combinations of the kernel:
H0 =

f : Rd −→R | ℓ< ∞,

αi
ℓ
1 ∈R,

si
ℓ
1 ∈Rd, f(x) =
ℓ

i=1
αik

si, x


1. Only cases for which the kernel is positive deﬁnite will be taken into consideration, i.e.
∀ℓ< ∞, ∀αi ∈R, ∀xi ∈Rd, i = 1 . . . ℓ; 
i

j αiαjk(xi, xj) ≥0.

Quadratic Programming and Machine Learning
115
This space is provided with a scalar product deﬁned as a bilinear form such that for
all f, g ∈H0, f(x) = ℓ
i=1 αik(si, x) and g(x) = m
j=1 βjk(tj, x),

f, g

H0 =
ℓ

i=1
m

j=1
αiβjk

si, tj

If the kernel is positive, this also guarantees that the scalar product is positive and
deﬁnite. The induced space with this scalar product is a pre-Hilbertian space.
Completing the pre-Hilbertian space H0 according to the norms introduced by the
scalar product turns it into a Hilbert space H = H0.
PROPERTIES. The norm induced in this space equals ∥f∥2
H = ⟨f, f⟩H. Also note that:

f(·), k(·, x)

H =

ℓ

i=1
αik

si, ·

, k(·, x)

H
= f(x)
This is the property of reproduction. The space H is thus a Reproducing Kernel
Hilbert.
Due to the usage of this property of reproduction, the problem of ﬁnding a general
solution f in the space of functions H comes down to the problem of ﬁnding a
vector α ∈Rn for which n describes the number of available examples for the
learning process. The link between the function f and the vector α is provided by
the representer theorem ([SCH 02, Theorem 4.2, page 90]):
f(x) =
n

i=1
αik

xi, x

.
5.2.3. Cost and regularization
Now all hypotheses have been deﬁned, the two criteria to be minimized during
the learning process will be explained in detail. These are the empirical risk and
the capacity. They are referred to as the minimization of regularized cost. The
regularization is a form of capacity control. The penalization term is to be used. This
term grows if the decision function increases in complexity. For an exact solution to
the problem, at least one of the two criteria has to be of the type L1 (as opposed to
the cost type L2) [NIK 00]2.
2. See the article “When does sparsity occur?” on O. Bousquet’s blog http://ml.typepad.com/
machine_learning_thoughts/.

116
Optimization in Signal and Image Processing
DEFINITION 5.8 (Cost of the type L2). The cost is known as type L2 if it takes a
quadratic form.
For example, this is the case for the cost C2 = (f(xi) −yi)2 used for regression,
the quadratic hinge cost C2
h = max(0, yi(f(xi) + b −1))2 used for discrimination
and terms of quadratic penalization type Ω2 = ∥f∥2
H. The cost linked to logistical
regression Cℓ= yi log f(xi) + (1 −yi) log(1 −f(xi)) does not strictly refer to a cost
type L2 but possesses the following characteristics: regularity and convexity.
Costs of the type L1 are more difﬁcult to deﬁne formally. This type of costs leads
to sparsity. These are often built on the basis of absolute values and are singular
at origin [NIK 00]. For example, this is the case of cost C1 = |f(xi) −yi| and
C1(ε) = max(0, |f(xi) −yi| −ε) used for the regression, for the cost Ch =
max(0, yi(f(xi) + b −1)) used as a form of discrimination, and the terms of
penalization type Ω1 = n
i=1 |αi| when the solution f we are looking for veriﬁes
f(x) = n
i=1 αik(xi, x).
The choice of cost functions and regularization leads to different types of
algorithms (see Table 5.1 for examples). These algorithms minimize the cost L2.
They are of a Gaussian type and very popular due to their properties of derivation
and their simple calculations. Algorithms that minimize the term L1 are also often
used due to their capacity to provide sparse solutions. On the other hand, the usage
in terms of L1 implies rather slow solutions (see simplex). In [POR 97] the authors
show how the L1 method may compete with the L2 method in terms of algorithms.
This chapter will show how, in practice, it makes more sense to beneﬁt from sparsity.
Cost
Ω
Discrimination
Regression
L1
L1
LP SVM [MAN 98]
LP SVR: C1(ε) and Ω1
L2
L1
HLAR: C2
h and Ω1 [KEE 05]
LARS: C2 and Ω1 [EFR 04]
L1
L2
SVM: Ch and Ω2
SVR: C1(ε) and Ω2
L2
L2
Logistical K-regression: Cℓand Ω2
Lagrangian SVM: C2
h and Ω2 [MAN 01]
Splines: C2 and Ω2
Table 5.1. Overview of different learning algorithms according to
the nature of objective functions
5.2.4. The aims of realistic learning processes
Learning processes have to be a tool for the processing of data taken from the real
world. Particularly when processing signals there is a large amount of signals which
are affected by ambient noise and variables. The challenge in learning processes does
therefore not only affect development of high performing methods and their primary

Quadratic Programming and Machine Learning
117
tasks (classiﬁcation, regression, etc.), but also has an impact on the available amount
of computer storage. This is why on-line algorithms and those of a lower complexity
(less than O(n2)) are likely to be used in the development of realistic applications.
5.3. From learning methods to quadratic programming
One of the most widely used algorithms that requires a quadratic program is
probably the SVM (Support Vector Machine) as well as a variety of declinations. This
chapter will show how a binary SVM, or one class SVM or SVM for regression (SVR
– Support Vector Regression machine) may use identical forms for problem solving.
Several algorithms will be shown as well as their capacity to solve a particular
system.
5.3.1. Primal and dual forms
5.3.1.1. Binary classiﬁcation: SVMs
For a problem of discriminating two classes, the separating functions have to be
found between the examples of each class. This separation is based on a RKHS
known as H. The decision function is D(x) = sign(f(x) + b). The primal expression
of a binary SVM is as follows:
⎧
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎩
min
f∈H,ξ,b
1
2∥f∥2
H + C
n

i=1
ξi
yi

f

xi

+ b

≥1 −ξi
i ∈[1, . . . , n]
ξi ≥0
i ∈[1, . . . , n].
[5.1]
This system ﬁnds the function of H of the smallest norm L2 (regularization). This
function correctly subdivides the learning points into different classes. The constraints
of correct classiﬁcation (the cost, here described as L1) are linked to a margin of 1 that
obliges the separating function to be situated far from training points. Furthermore, it
is possible to infringe the constraints of correct classiﬁcation (i.e. loosen up those
limits) due to variables ξi. C represents the maximum inﬂuence of a point within this
solution. Solving this kind of system is based on the usage of a Lagrangian:
L(f, ξ, b) = 1
2∥f∥2
H + C
n

i=1
ξi
−
n

i=1
αi

yi

f

xi

+ b

−1 + ξi

−
n

i=1
βiξi
[5.2]

118
Optimization in Signal and Image Processing
with i ∈[1, . . . , n], ξi ≥0, αi ≥0 and βi ≥0. Minimizing [5.1] comes down to
canceling the derivatives of L in combination with every variable:
⎧
⎪
⎪
⎨
⎪
⎪
⎩
Δf(L) = 0
Δξ(L) = 0
Δb(L) = 0
⇐⇒
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎩
f(·) =
n

i=1
αiyik

xi, ·

C −βi −αi = 0
n

i=1
yiαi = 0
[5.3]
When replacing these two relations in [5.2] a dual problem can be obtained which has
been described in a matrix form:
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
max
α∈Rn −1
2α⊤Gα + e⊤α
y⊤α = 0
0 ≤αi ≤C
i ∈[1, . . . , n].
[5.4]
e is a vector of ones and G describes the kernel matrix weighted by the labels of the
points such as Gij = yiK(xi, xj)yj. This dual system consists of convex quadratic
programming with the particularity that it is confronted with a problem of n unknowns
with 2n + 1 constraints. Furthermore, G is a positive, semi-deﬁnite matrix.
5.3.1.2. One class classiﬁcation: OC-SVM
For a problem of one class classiﬁcation, the border line around the training class
has to be found. Primal expression of one class SVM is expressed as:
⎧
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎩
min
f∈H,b,ξ
1
2∥f∥2
H + C
n

i=1
ξi −b
f

xi

≥b −ξi
i ∈[1, . . . , n]
ξi ≥0
i ∈[1, . . . , n]
[5.5]
As for binary cases, the Lagrangian is also applied and the following dual expression
can be obtained:
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
max
α∈Rn −1
2α⊤Kα
e⊤α = 0
0 ≤αi ≤C
i ∈[1, . . . , n]
[5.6]
This system is also a convex quadratic form of programming.

Quadratic Programming and Machine Learning
119
5.3.1.3. Regression: SVR
When dealing with the problem of regression, expected outputs are reals. Here the
data is not to be separated but the aim is to obtain a function that represents the best
of the training points. The idea is for the solution to ﬁt in a tube of the size 2ϵ based
on training examples. The primal formula of this problem is expressed as follows:
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎩
min
f∈H,ξ,ξ∗,b
1
2∥f∥2
H + C

n

i=1
ξ∗
i +
n

i=1
ξi

yi −f(xi) −b ≤ϵ + ξi
i ∈[1, . . . , n]
−yi + f(xi) + b ≤ϵ + ξ∗
i
i ∈[1, . . . , n]
ξ∗
i ≥0
i ∈[1, . . . , n]
ξi ≥0
i ∈[1, . . . , n]
[5.7]
According to the same method, a Lagrangian is always used for dual formulae:
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎩
max
α∈Rn −1
2

α∗⊤Kα∗−α∗⊤Gα −α⊤Gα∗+ α⊤Gα

−ϵe⊤α −ϵe⊤α∗−y⊤α + y⊤α∗
e⊤α = e⊤α∗
0 ≤αi ≤C
i ∈[1, . . . , n]
0 ≤α∗
i ≤C
i ∈[1, . . . , n]
[5.8]
This formula is similar to convex quadratic programming and it is sufﬁcient to adapt
the data as follows:
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
max
β∈R2n −1
2β⊤Gβ + c⊤β
u⊤β = 0
0 ≤βi ≤C
i ∈[1, . . . , 2n]
[5.9]
G describes the matrix which consists of four kernel matrices G = [K, −K; −K, K].
β is a vector that contains both α and α∗, i.e. β = [α, α∗]. c is the vector which
represents [−y −ϵ, y −ϵ], while the vector u represents [e, −e].
5.4. Methods and resolution
A certain number of problems in learning processes can be expressed in a convex
quadratic program. This part of the chapter will show how to efﬁciently obtain a
solution for minimization under “box” constraints.

120
Optimization in Signal and Image Processing
5.4.1. Properties to be used: sparsity
First of all note that the formula to be optimized is convex and only produces a
single optimal solution. Also note that the constraints are linear and of a ﬁnite number.
The best solution α is veriﬁed for each of its components αi according to the Karuch
Kuhn Tucker (KKT) conditions, i.e.
αi = 0 −→f

xi

yi > 1
0 < αi < C −→f

xi

yi = 1
αi = C −→f

xi

yi < 1.
[5.10]
The general principle of methods used for subdivision and/or active sets is based on the
observation that only the points that are not affected by the constraints in the solution
require a calculation of their coefﬁcient. This general principle is known as sparsity.
Other methods have ﬁxed values as coefﬁcients for each particular problem. They are
bounded (by 0 and C for the case of SVM for example). Based on this statement,
it is sufﬁcient to know the distribution of points in three groups (constrained at 0,
constrained at C, not constrained) for the solution of the problem. These groups will
from now on be referred to as I0, IC and Iw, for the respective points of 0, C or not
constrained. This statement promotes different techniques of distribution and different
algorithms that will be explained after presenting some tools that are shared by several
methods.
5.4.2. Tools to be used
ADMISSIBLE DIRECTIONS. The geometry of a dual and convex quadratic problem
is explained in Figure 5.1. The box constraints 0 ≤αi ≤C limit the solution to a
hypercube of the dimension n. The equality constraint  yiαi = 0 also limits the
solution to a polytope F of dimension n −1. Let us consider an admissible point
α ∈F and a straight line containing this point. This line indicates the admissible
direction if its intersection with the polytope contains other points apart from α.
An algorithm of admissible direction updates the position of the admissible point
αt in an iterative way. First of all a direction ut has to be chosen. The algorithm then
follows this direction and searches for an admissible point αt+1 which maximizes
the cost function. The optimum is reached once improvements are no longer possible
[ZOU 60]. There are two possible conﬁgurations when searching for an admissible
point. The quadratic cost function is limited to the direction and reaches its maximum
either inside or outside the polytope.
SHRINKING. Shrinking [JOA 99] is a form of heuristics that determines, while the
algorithm is being carried out, which points are excluded from the solution or are

Quadratic Programming and Machine Learning
121
Eequality constraints
Cost 
function
Admissible 
solutions
Box constraints
Figure 5.1. The geometry of a dual and quadratic problem. The box constraints 0 ≤αi ≤C
limit the solution to a hypercube of the dimension n. The equality constraint  yiαi = 0
also limits the solution to a polytope of the dimension n −1. The function for quadratic
cost is limited to the line that is being searched for. This line has its maximum at
the inside or at the outside of the constraint box
bounded. The value of these points is therefore known without having to calculate
their coefﬁcient α. This is why the points can no longer be taken into consideration
and the size of the problem is reduced mechanically so that the problem can be solved.
As this type of heuristic might lead to errors, it is sufﬁcient to check the algorithm once
it has stopped and verify whether the points to be excluded are in group I0 or group
IC. An optimization step might be required at this point.
5.4.3. Structures of resolution algorithms
Iterative algorithms for resolution share a common structure (Algorithm 5.1). The
methods are distinguished by their method of distributing the points and the way in
which they calculate α.
5.4.4. Decomposition methods
As their name indicates, the decomposition methods use a sub-group of the training
database at every stage of problem solving. The action of problem solving is therefore
subdivided into smaller dimensions. The results of these sub-problems are combined
in order to obtain the best global solution.

122
Optimization in Signal and Image Processing
Initialization
While (current solution is not optimal) do
update groups
compute the coefﬁcients αi which correspond to the changes
done
Algorithm 5.1. General schema showing algorithms of an iterative resolution
CHUNKING. The method known as chunking [VAP 82] eliminates the points for
which α becomes equal to 0 in the course of the algorithm. The main idea is to solve
the QP problem for a sub-group of points. This sub-group is made up out of support
vectors of the previous solution and M points in the database. These points infringe
KKT more than any other point. Moving from one sub-group to the next ensures
that the problem is eventually solved. The limit of this method is the size of the ﬁnal
solution when the entire kernel matrix cannot be stored in the memory.
DECOMPOSITION. The technique of decomposition [OSU 97] is similar to the
principle of chunking. In this approach the size of the sub-groups remains the same
and allows for vector points to be removed. This is how all quadratic problems can be
solved regardless of their size.
SMO (sequential minimal optimization). The extreme case only considers two points
in every stage. This method is referred to as SMO [PLA 99]. The main advantage is
that every quadratic sub-problem of a limited size can be solved analytically. Digital
resolution, which is often very cost intensive, can therefore be avoided.
SMO only considers admissible solutions that modify only two coefﬁcients αi and
αj on the basis of opposed values. The most widely used version of SMO is based
on the ﬁrst order criteria which are used to select the pairs (i, j) which deﬁne the
following directions:
i =
arg max
{s|αs<max(0,ysC)}
∂W
∂αs
j =
arg min
{s|αs>min(0,ysC)}
∂W
∂αs
.
[5.11]
Furthermore, the majority of SMO implementations (iterative schema of
Algorithm 5.2) use the shrinking technique in order to limit the space of searching
α. New criteria based on second order information have been published recently
[FAN 05]. These criteria ensure that the results can be used in theory and practice for
a better convergence.

Quadratic Programming and Machine Learning
123
chose two initial points i and j
calculate their coefﬁcients αi and αj
While (the current solution is not optimal) do
select two new points
calculate the associated coefﬁcients
done
Algorithm 5.2. Iterative schema of an SMO algorithm
The use of SMO does not require the usage of QP resolving tools. For other
decomposition methods every sub-problem has to be solved in the form of a quadratic
problem.
5.4.5. Solving quadratic problems
5.4.5.1. Methods based on interior points
Methods based on interior points, suggested by [KAR 84], solve linear
programming in a polynomial amount of time. Their derivation for semi-deﬁnite,
positive and non-linear programming has led to algorithms such as LOQO and OOQP
[VAN 99, GER 01]. Even though these methods are very efﬁcient when it comes to
optimization, they have been outperformed by methods that will be presented later
on. The methods of interior points work on the complete training set. Thus, they are
not dedicated to large databases whatever the efﬁciency of the algorithm. The main
challenge in learning processes is sparsity. This property is the key to solving large
quadratic problems. Even when working on a sub-group of points taken from the
learning process’s database, as is the case for decomposition methods, it still saves
time and effort to use methods which rely on sparsity and reduce complexity.
5.4.5.2. Active constraint methods
The principle of these methods is an efﬁcient distribution of the points into three
groups I0, IC and Iw. These groups obtain the values of αi, i ∈Iw by solving a linear
system. For SVM, the algorithm known as SimpleSVM [VIS 03] (it can, however,
be applied to all convex quadratic problems with box constraints) distributes points
iteratively into three groups.
At every stage the minimization is solved on group Iw without constraints. If one
of the values represented in α violates the constraints (i.e. the solution is situated
outside the box), α is projected into the admissible space (i.e. in practice the indicated
point changes group via the value that infringes the constraints.). This procedure will
be explained in detail.

124
Optimization in Signal and Image Processing
The iterative schema of this type of algorithms works as follows:
choose initial distribution
calculate initial solution
While (the current solution is not the best one) do
update the distribution into groups
calculate the associated coefﬁcients for group Iw
done
Algorithm 5.3. Iterative schema of a SimpleSVM
The choice of a particular distribution into groups, calculating coefﬁcients and the
evaluation of performances for a solution still have to be deﬁned.
SOLVING A DUAL PROBLEM. The problem to be solved: if the points with coefﬁcients
equal to zero are removed in equation [5.4], the system can be expressed as follows:
⎧
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎩
max
αw∈R|Iw| −1
2α⊤
wGwwαw + e⊤
wαw −Ce⊤
c Gcwαw
y⊤
wαw = −Cy⊤
CeC
max
αw∈R|Iw| 0 < αi < C
i ∈Iw
[5.12]
Gww describes the kernel between the points of Iw and Gcw between IC and
Iw. The Lagrangian is used to obtain the solution with the multipliers λ. With
ev = ew −CGwcec, αw = G−1
ww(ev −λyw) can be obtained. With N = G−1
wwewc
and M = G−1
wwyw,
αw = N −λM.
[5.13]
Given the constraints in problem [5.12], the following relationship can be obtained:
y⊤
w(N −λM)
=
−Cy⊤
c eC. The values of the Lagrange multipliers (which
correspond, in the primal, to the bias indicated as b in different primal expressions) is
deduced:
λ = y⊤
wN + Cy⊤
c ec
y⊤
wM
.
[5.14]
For a given distribution of data between the three groups of points, the coefﬁcients of
the decision function are calculated. It the distribution is correct, all elements of αw
are between 0 and C.

Quadratic Programming and Machine Learning
125
DISTRIBUTION OF GROUPS OF POINTS. In order to attribute every point to a group
the corresponding values of α will be used. The straightforward (but not very delicate)
strategy is to place the entire training set into the group Iw at the ﬁrst step. After
solving the quadratic program in Iw once, (all negative multipliers send their point to
group I0 and all multipliers larger than C send their points to group IC) The problem
of this method is the machine aspect, since solving the entire system directly from a
large database is very cost intensive in terms of time and computer storage. However,
this notion is used when producing an iterative version. Let’s have another look at the
iterative schema given for Algorithm 5.3.
choose initial distribution: (random)
calculate initial solution: eq. [5.13] and [5.14]
While (the current solution is not optimal: there are violated constraints) do
update groups:
If (one of the calculated α is negative or higher than C) then
Transfer this point to I0 or IC
else
If (constraints in the primal is violated by a point from IC or I0) then
Transfer this point to Iw
else
no constraints are violated anymore
end If
end If
calculate associated coefﬁcients for group Iw: eq. [5.13] and [5.14]
done
Algorithm 5.4. Detailed SimpleSVM algorithm
Initialization can be carried out randomly (making a good choice for the ﬁrst point
can accelerate the convergence of the algorithm). Checking whether a solution actually
is the best one is carried out in two stages. The box’s constraints have to be checked
(0 < α < C) as well as the classiﬁcation constraints (or regression, or aim of the
algorithm) given by the primal expression. These constraints also have to be respected.
SOLVING
LINEAR
SYSTEMS. Calculating Lagrange multiplications α requires
solving a linear equation. This is usually a complex operation O(n3). This
operation is very cost intensive and one of the main issues in the algorithm. It
therefore makes sense to take a more detailed look at this topic. To solve the
equation αw = G−1
w (ewc −λyw), the inverse of the matrix does not have to be
calculated. Generally Gw is subdivided. When doing so, Gw’s properties (symmetric,
semi-deﬁned and positive) play an important role and can be used when subdividing

126
Optimization in Signal and Image Processing
QR. Q is an orthogonal matrix and R a triangular matrix. This subdivision
(Gw = QR) leads to QRαw = ewc −λyw ⇔Rαw = Q⊤(ew −λyw) ⇔αw =
R−1(Q⊤(ewc −λyw)). The latter operation is less cost intensive as R is triangular.
Subdividing a matrix, no matter whether this is done on the basis of QR or other
methods, is complex O(n3) and is therefore the most cost intensive operation in the
solving process. However, for every iteration one single point is transferred from one
group to another. First range updating techniques can be used for different methods of
subdividing matrixes. Every iteration is therefore linked to a complex O(n2). There
are techniques to prove convergence for SMO [KEE 02] and SimpleSVM [LOO 05].
5.4.6. Online and non-optimized methods
Online methods are very interesting as they allow for realistic applications. Their
aim is to combine performance of results with SVM type methods. This type of usage
can be adapted to different contexts and used on a large scale. LASVM is an algorithm
that combines the advantages of SMO and SimpleSVM to reach this aim.
LASVM [BOR 05] is an online SVM that increases incrementally with respect
to the dual objective. LASVM maintains a vector of current coefﬁcients α and the
indexes for support vectors that correspond to Iv (here, Iv is made up out of Iw and
Ic). Every iteration of LASVM receives a new example from I0 and updates the vector
of coefﬁcients α by using two stages of SMO referred to as process and reprocess:
– Process means searching for an admissible point. The direction is deﬁned by a
pair of points created with the index of the current example σ and another example
chosen from Iv by using the criterion of the ﬁrst order (equation [5.11]). This operation
provides a new vector for the coefﬁcients α′
t and can insert σ into all corresponding
Iv.
– Reprocess also means searching for an admissible point. The direction is,
however, deﬁned by a pair of points (i, j) both taken from Iv by using a criterion of
the ﬁrst order (e.g. equation [5.11]). This operation provides new vector coefﬁcients
α and may delete i, j from the group of indexes Iv.
Repeating the LASVM operations (Algorithm 5.5) on a random choice of
examples leads to the convergence of SVM solutions with an arbitrary level of
precision. However, depending on the size of n, the experiment shows that LASVM
also provides good results after a single presentation of every example. After
every example has been presented, the ﬁnal coefﬁcients are reﬁned and carry out a
reprocess up to the convergence of the dual function.
Every iteration of an online LAVSM randomly chooses examples for the learning
process (xσ(t), yσ(t)). The most sophisticated strategies of choosing examples lead to
a better performance on the level of a scale. There are four strategies in total:
– random selection: randomly choose an example;

Quadratic Programming and Machine Learning
127
Initialize
While (there are points which still have to be covered) do
select point which has to change group
optimize α of Iv
done
ﬁnalize
Algorithm 5.5. Schema of the LASVM algorithm for online functioning
– gradient-based selection: choose the example with the lowest classiﬁcation
(lowest value for ykf(xk)) amongst the points which have not been dealt with before.
This criterion is close to what happens during a SimpleSVM;
– active selection: choose an example that is close to the limitations of
decision-making, i.e. the smallest value of |f(xk)| amongst a random group of points.
This criterion automatically chooses the example without considering its label;
– self-active selection: choose from 100 points which have not been dealt with
before but stop as soon as ﬁve of them are outside the margin. From those ﬁve, this
type of selection chooses the closest one to the limits of decision making.
There is empirical proof that the active or self-active selection leads to similar or
better performances if the number of support vectors to be used is limited. This fact is
based on the linear increase of the number of support vectors as every example which
has been wrongly classiﬁed is automatically a support vector in the traditional form
of SVM. Choosing the points purely on the basis of which one is close to the limit
excludes a high number of points from a possible solution.
On the basis of the structure, LAVSM exploits large databases. Of course, a
problem for the learning process is not automatically a problem of optimization.
It does not make any sense to optimize the function of the primal objective with a
higher precision than when working with a ﬁnite number of examples. Formal results
exist for the online learning process and use an estimation of the stochastic gradient.
These algorithms have been designed for online functioning and are much faster than
direct optimization of a function with a primal objective [BOT 04]. This type of
algorithm does not optimize the function as precisely as traditional optimization, but
leads to the same number or errors in tests. A speciﬁc stage is also reached more
rapidly by this algorithm than by traditional methods.
5.4.7. Comparisons
For a better illustration of the links between SimpleSVM, SMO and LASVM, the
essential functions of these algorithms will be shown below:
– initialize: correspond to what has to be done before entering the iterative phase;

128
Optimization in Signal and Image Processing
– select: choose points to be moved from one group to another;
– optimize: calculate the Lagrange multipliers;
– ﬁnalize: guarantee local and global optima.
Table 5.2 compares these different stages to one another. If these three algorithms
are similar, the major difference takes place during the optimization stage α.
SimpleSVM maintains the same group of coefﬁcients at optimized values throughout
the entire process, while LASVM and SMO update those values. Due to its online
functioning LASVM is faster than SMO.
General
SimpleSVM [VIS 03]
LASVM [BOR 05]
SMO [PLA 99]
Selection
Search groups I0 and
IC
for a point that
violate constraints
Choose one point from
the following points
Search for a point in Iw and
a point in the entire database
according to SMO’s heuristics
Optimization
Carries out a complete
optimization for Iw
Two stages of SMO, one
between the new point
and the point of Iw
(Process) and one stage
between two points of
Iw (Reprocess)
One SMO stage between two
chosen points (optimizes the
two α correspondents)
Final
Stops if constraints are
no longer violated
Stops when all points
have been dealt with and
carries out a complete
optimization for Iw
Stops if constraints are no
longer violated
Table 5.2. Comparison between the different functions used by SimpleSVM, LASVM and SMO
Amongst non-optimized methods, processing large dimensions also note (even
though this method will not be explained in detail here) that the CVM (core virtual
machines [TSA 05]) use statistical properties for the selection of the candidates
and therefore decrease the time required for the learning process at relatively high
efﬁciency in terms of performance. A rather small quantity of points guarantees to
95% that 95% of the points are distributed correctly.
5.5. Experiments
In order to illustrate the capacities of the methods which have been presented,
some results of experiments will be shown. First of all a problem whose size can be
changed will be used to show the empirical complexity, sparsity and efﬁciency of
different algorithms. Now an experiment will be explained which shows the behavior
of LASVM for a database with up to 8 million points.
5.5.1. Comparison of empirical complexity
For a problem of separable complexity it is important to be familiar with a 4 × 4
draughtsboard (Figure 5.2) as it shows developments in terms of time required for
calculations and number of points used in the learning process.

Quadratic Programming and Machine Learning
129
−1
−1
−1
−1
−1
−1
−1
−1
−1
−1
−1
−1
−1
−1
−1
−1
−1
−1
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
x1
x2
Damier
−2
−1.5
−1
−0.5
0
0.5
1
1.5
2
−2
−1.5
−1
−0.5
0
0.5
1
1.5
2
Figure 5.2. Example of a draughtsboard and an SVM associated solution. Note sparsity
of the result (round points in the ﬁgure). The other points are not used in the solution
The draughtsboard is an example of sparsity of the solution. No matter the
rate of ﬁlling the squares, only the points on the border lines are useful for the
decision-making process. In an extreme case, a point on every angle of a square
is sufﬁcient to obtain the correct border lines, i.e. 54 points are sufﬁcient. Support
vector points might, of course, be amongst those points but sparsity of the solution
shows the efﬁciency of the methods presented earlier.
With the implementation of SMO, libSVM [CHA 01] is used in version 2.7 and
version 2.81. Version 2.7 uses ﬁrst order criteria for the selection of points and version
2.81 uses criteria of the second order. For second order criteria, versions are also
compared to each other with or without shrinking. For SimpleSVM the tool box is
used [LOO 04]. For LASVM the code is derived from this tool box and obtains a
Matlab implementation. The code for CVM is a variation of libSVM 2.7.
Figure 5.3 shows the exact methods which provide the level of acknowledgement.
Empirical complexity is given by the gradient of the straight lines obtained for the
period of the learning process (above); the bias of these straight lines partially depends
on the language used during implementation (C is compiled, Matlab interpreted). An
improvement can be observed in terms of the time required for calculations due to
the shrinking heuristics and the superiority of second order criteria above those of the
ﬁrst order for SMO. In terms of sparsity, the two non-optimized methods retain fewer
points than the other methods. Increasing sparsity means that the time required for
calculations can be reduced. However, care needs to be taken in order not to deteriorate
the quality of the solution. If LASVM is convergent to similar solutions compared to
that obtained by optimized methods, CVM loses some of its quality.

130
Optimization in Signal and Image Processing
10
3
10
4
10
5
0
5
10
15
Error rate (%)
Size of database (log)
10
3
10
4
10
5
10
1
10
2
10
3
Number of SV (log)
Size of database (log)
10
3
10
4
10
5
10
0
10
2
10
4
Time required for the learning process (log)
Size of database (log)
CVM (C)
LibSVM 2.7 shrinking (C)
SimpleSVM (Matlab)
LibSVM 2.8 shrinking (C)
LibSVM 2.8 no shrinking (C)
LASVM (Matlab)
Figure 5.3. Comparison of different algorithms on the draughtsboard problem. The ﬁrst
ﬁgure shows the development in terms of learning process. The ﬁgure in the middle
shows the number of support vectors. The ﬁgure below indicates the error rate
5.5.2. Very large databases
For further illustration of the online method, an experiment on recognizing
handwritten characters (numbers 0 to 9) will be shown. MNIST [LEC 98] is the
database which is being used and which has been created on the basis of invariance
[LOO 06]. Without going into any detail on the generation of the points, the
experiment and its results will be presented. The main idea is to solve the problem
of invariance (enable the algorithm to recognize numbers independently from
transitions, rotations, or minor deformations). In order to do this, a database with a
virtually inﬁnite number of examples, different from the original, has been created.
It is sufﬁcient to use a generic parameter-based formula to create an example which

Quadratic Programming and Machine Learning
131
does not take the same shape. As soon as a new example is required the parameters
are chosen randomly and calculate a virtual example. An online algorithm is adapted
to increasing levels of demand. The more the examples are out of shape, the more
robust the algorithm is when it comes to variations, but this also increases the size of
the problem to be solved. If an off-line method is used (e.g. SMO or SimpleSVM)
the entire database has to be available at the beginning. This limits the possibility of
introducing a new invariance.
MNIST contains 60,000 training examples of 10 classes. The test database
contains 10,000 examples. The dimension of an example is 784 (an image of 28 × 28
pixels of shades of gray). During the learning process up to 130 changes in shape
were generated for every example. These changes in shape make up to 8 million
points per classiﬁer (every classiﬁer has a binary learning process of one class against
all other classes, i.e. 9 against 1).
Number of processed points
Number of support vectors (log)
Size of solution per classifier for MNIST with invariance, 1 against all
Figure 5.4. Development of the size of solution per classiﬁer during the learning process.
These results were obtained during preliminary studies of up to 6 million points
In this example LASVM shows its capacity to process large databases. These
results were obtained after eight days of learning and testing carried out by one single
machine for all 10 classiﬁers. The number of support vectors retained by the classiﬁer
varies between 8,000 and 20,000 (see Figure 5.4). This variation depends on how
complex the task is (distinguishing 1 from other ﬁgures is easier than distinguishing
3, 5 and 8. Fewer examples are therefore needed when distinguishing 1). These
results were obtained due to the combination of two essential elements. These are

132
Optimization in Signal and Image Processing
sparsity and the online mode. Sparsity allows for a high number of examples to be
considered and the online mode ensures that every point is dealt with only once. In
terms of performance, this learning process has an error rate of 0.67%, which is the
best possible result for kernel-based methods that use invariance and do not modify
the examples used in tests.
5.6. Conclusion
This chapter has shown the link between learning processes and convex quadratic
programming. One of the major challenges for the learning process is the capacity to
process large databases. An overview on the best methods of resolution has been given,
as well as an explanation on how to increase development towards non-optimized
methods which are more efﬁcient.
Deﬁning the learning process as a problem in convex quadratic programming has
improved efﬁciency and reliability. The currently available algorithms are able to
solve very large problems (8 million variables and 16 million constraints) within a
reasonable timescale. This is linked to a particular problem in the learning process the
level of sparsity within the solution. If in the general case of quadratic programming
the methods of an interior point are more efﬁcient, this no longer applies to the
speciﬁc problem of a learning process. The methods of active constraints beneﬁt from
the problem’s particularities. The result given by these programs is reliable as the
problem has a unique solution and because of the convergence of these algorithms.
These methods are very robust to small disturbances of data that lead to changes in the
solution. These solutions then move on to a high number of operational systems which
are able to recognize previously learnt forms. In the near future it will be possible to
integrate these algorithms into independent systems in order to provide them with the
capacity to learn.
This chapter has focused on support vector algorithms. There are, however, other
interesting approaches. For regression, the LAR (least angle regression [EFR 04])
algorithm suggests a very efﬁcient method of quadratic programming for problems
with a penalization lower than L1 (i.e. sparsity). One of the main advantages of this
method (apart from its efﬁciency) is how regularization is carried out on the basis of
minimization. This method therefore has not just one, but of a group of potentially
useful solutions. Finding the right algorithms is based on regularizations and the main
challenge when optimizing learning processes. This method is a sophisticated way of
studying optimization problems of two or three criteria for a solution.
When it comes to the learning process, the limits of algorithms presented above
are linked to their own strengths. Once an algorithm has chosen many points (up to
10,000 in the example which has been presented) a mechanism is required to compile
this solution, i.e. ﬁnd an equivalent form which is, however, more economical when
using resources. This can currently only be done via non-convex approaches such as

Quadratic Programming and Machine Learning
133
neural networks. These solutions are, however, not very satisfactory. Choosing the
right algorithms according to the size and the complexity of the problem is important.
If needed, the algorithm may also be changed during learning.
5.7. Bibliography
[BOR 05] BORDES A., ERTEKIN S., WESTON J. and BOTTOU L., “Fast kernel classiﬁers with
online and active learning”, Journal of Machine Learning Research, vol. 6, pp. 1579–1619,
2005.
[BOT 04] BOTTOU L. and LECUN Y., “Large scale online learning”, in THRUN S., SAUL
L. and SCHÖLKOPF B. (Eds.), Advances in Neural Information Processing Systems 16,
Cambridge, MA, MIT Press, 2004.
[BOY 02] BOYD
S.
and
VANDENBERGHE
L.,
“Advances
in
convex
optimization:
interior-point methods, cone programming and applications”, IEEE Conference on Decision
and Control, 2002.
[BUR 98] BURGES C.J.C., “A tutorial on support vector machines for pattern recognition”,
Data Mining and Knowledge Discovery, vol. 2, no. 2, pp. 121–167, 1998.
[CHA 01] CHANG C.-C. and LIN C.-J., LIBSVM: a Library for Support Vector Machines,
2001 (software available at http://www.csie.ntu.edu.tw/∼cjlin/libsvm/).
[EFR 04] EFRON B., HASTIE T., JOHNSTONE I. and TIBSHIRANI R., “Least angle
regression”, Annals of Statistics, vol. 32, no. 2, pp. 407–499, 2004.
[FAN 05] FAN R.-E., CHEN P.-H. and LIN C.-J., “Working set selection using second order
information for training support vector machines”, Journal of Machine Learning Research,
vol. 6, pp. 1889–1918, 2005.
[GER 01] GERTZ M. and WRIGHT S., Object-oriented Software for Quadratic Programming,
2001 (http://pages.cs.wisc.edu/∼swright/ooqp/ooqp-paper.pdf), ACM Transactions on
Mathematical Software, vol. 29, pp. 58–81, 2003.
[JOA 99] JOACHIMS T., “Making large-scale SVM learning practical”, in SCHOLKOPF B.,
BURGES C. and SMOLA A. (Eds.), Advanced in Kernel Methods – Support Vector
Learning, MIT Press, pp. 169–184, 1999.
[KAR 84] KARMARKAR N.K., “A new polynomial-time algorithm for linear programming”,
Combinatorica, vol. 4, pp. 373–395, 1984.
[KAU 99] KAUFMAN L., “Solving the quadratic programming problem arising in support
vector classiﬁcation”, Advances in Kernel Methods: Support Vector Learning, pp. 147–167,
MIT Press, 1999.
[KEE 02] KEERTHI S. S., GILBERT E.G., “Convergence of a generalized SMO algorithm for
SVMClassiﬁer design”, Machine Learning, vol. 46, no. 1-3, pp. 351–360, 2002.
[KEE 05] KEERTHI S. S., “Generalized LARS as an effective feature selection tool for text
classiﬁcation with SVMs”, ICML’05: Proceedings of the 22nd International Conference on
Machine learning, New York, NY, USA, ACM Press, pp. 417–424, 2005.

134
Optimization in Signal and Image Processing
[LEC 98] LECUN Y., BOTTOU L., BENGIO Y. and HAFFNER P., “Gradient-based learning
applied to document recognition”, Proceedings of the IEEE, vol. 86, no. 11, pp. 2278–2324,
1998, http://yann.lecun.com/exdb/mnist/.
[LOO 04] LOOSLI G., “Fast SVM Toolbox in Matlab based on SimpleSVM algorithm”, 2004,
http://asi.insa-rouen.fr/~gloosli/simpleSVM.html.
[LOO 05] LOOSLI G., CANU S., VISHWANATHAN S., SMOLA A.J. and CHATTOPADHYAY
M., “Boîte à outils SVM simple et rapide”, Revue d’Intelligence Artiﬁcielle, vol. 19,
pp. 741–767, 2005.
[LOO 06] LOOSLI G., BOTTOU L. and CANU S., Training Invariant SupportVectorMachines
using Selective Sampling, Rapport, LITIS – NEC Laboratories of America, 2006.
[MAN 98] MANGASARIAN O., “Generalized support vector machines”, NIPS Workshop on
Large Margin Classiﬁers, 1998.
[MAN 01] MANGASARIAN O.L., MUSICANT D.R., “Lagrangian support vector machines”,
Journal of Machine Learning Research, vol. 1, pp. 161–177, 2001.
[NEM 05] NEMIROVSKI A., “Introduction to convex programming, interior point methods,
and semi-deﬁnite programming”, Machine Learning, Support Vector Machines, and
Large-Scale Optimization Pascal Workshop, March 2005.
[NIK 00] NIKOLOVA M., “Local strong homogeneity of a regularized estimator”, SIAM
Journal on Applied Mathematics, vol. 61, no. 2, pp. 633–658, 2000.
[OSB 05] OSBORNE M.R., “Polyhedral function constrained optimization problems”, in
MAY R., ROBERTS A.J. (Eds.), Proc. of 12th Computational Techniques and Applications
Conference CTAC-2004, vol. 46, pp. C196–C209, April 2005, http://anziamj.austms.org.au/
V46/CTAC2004/Osbo [April 22, 2005].
[OSU 97] OSUNA E., FREUND R. and GIROSI F., “An improved training algorithm of Support
Vector Machines”, in PRINCIPE J., GILE L., MORGAN N. and WILSON E. (Eds.), Neural
Networks for Signal Processing VII – Proceedings of the 1997 IEEEWorkshop, pp. 276–285,
1997.
[PLA 99] PLATT J., “Fast training of support vector machines using sequential minimal
optimization”, in SCHOLKOPF B., BURGES C. and SMOLA A. (Eds.), Advanced in Kernel
Methods – Support Vector Learning, MIT Press, pp. 185–208, 1999.
[POR 97] PORTNOY S. and KOENKER R., “The Gaussian hare and the Laplacian tortoise:
computability of squared-error versus absolute-error estimators”, Statistical Sciences, 1997.
[SCH 02] SCHÖLKOPF B. and SMOLA A.J., Learning with Kernels, MIT Press, 2002.
[TSA 05] TSANG I.W., KWOK J.T. and CHEUNG P.-M., “Core vector machines: fast
SVM training on very large data sets”, Journal of Machine Learning Research, vol. 6,
pp. 363–392, 2005.
[VAN 99] VANDERBEI R.J., “LOQO: an interior point code for quadratic programming”,
Optimization Methods and Software, vol. 11, pp. 451–484, 1999.
[VAP 82] VAPNIK
V.N.,
Estimation
of
Dependences
Based
on
Empirical
Data,
Springer-Verlag, 1982.

Quadratic Programming and Machine Learning
135
[VAP 95] VAPNIK V., The Nature of Statistical Learning Theory, Springer, NY, 1995.
[VIS 03] VISHWANATHAN S.V.N., SMOLA A.J. and MURTY M.N., “SimpleSVM”,
Proceedings of the Twentieth International Conference on Machine Learning, 2003.
[ZOU 60] ZOUTENDIJK G., Methods of Feasible Directions, Elsevier, 1960.

Chapter 6
Probabilistic Modeling of Policies and
Application to Optimal Sensor Management
6.1. Continuum, a path toward oblivion
In the domain of operational research several practical questions often lead
on to combinatorial issues. This chapter covers planning and exploring problems.
Generally speaking, this chapter will deal with the path planning or placement of
sensors. Speciﬁc tasks like the detection of intrusion or surveillance are possible
applications. For such a task, large scale planning is often required and/or different
levels of decision making are considered. For some applications, an uncertain area
might be explored by mobile sensors. In such cases, the observations are involved in
the whole planning process, and feedback on the sensors orientations is necessary.
For such problems, the optimal planning of the complete mission is very difﬁcult to
solve and various simpliﬁcation techniques are addressed by the literature.
Main difﬁculties in optimization arise when manipulating discrete data. Even
for continuous non-convex optimization, the implication of discrete data is implicit
and associated to local minima. The combinatorics implied by integer data not only
impact the optimization but also have logical implications (e.g. calculability and
logical complexity). Various approaches have been investigated in order to reduce the
combinatorics. Systematic enumeration methods like Branch and Bound can be used
in combination with the computation of branching bounds of the enumeration tree.
The point here is to approximate the combinatorics using a relaxed problem, and, on
this basis, to explore the interesting branches of the combinatorial tree. Typically,
integer linear programs could be solved by relaxing to a linear program. Now, even
Chapter written by Frédéric DAMBREVILLE, Francis CELESTE and Cécile SIMONIN.
Optimization in Signal and Image Processing 
Edited by Patrick Siarry 
Copyright 0 
2009, ISTE Ltd 

138
Optimization in Signal and Image Processing
a Branch and Bround approach cannot apply when the combinatorics become too
complex. In practice, obtaining solutions which are close to the optimum is sufﬁcient.
Deterministic approaches could provide near-optimal solutions.
However,
stochastic
methods
and
metaheuristics
offer
better
versatility.
Metaheuristics share two principles: exploring the optimization space by generating
solution proposals and focusing gradually toward the best or promising proposals.
This focus corresponds to a degressive relaxation in the optimization process. In the
case of simulated annealing, high initial temperatures enable the particles to make
big jumps, which somehow is equivalent to smoothing down the functional to be
optimized. In the case of cross-entropy (CE) the solutions are approximated using
a family of parametric probabilistic laws, which gradually sharpen toward the best
populations. These methods imply a progressive migration from a continuous and
weak informational content toward a sharp and strong informational content.
This chapter introduces the CE method [DEB 03, RUB 04], a metaheuristic based
on rare events simulation, and its applications to some optimal exploration problems.
The method relies on a relaxed modeling of the policies to be optimized by means of a
family of probabilistic laws. It is underlined here that the capability of probability for
logical representation is not only instrumental and necessary, but it also endows the
CE method with a powerful asset. Practically, the choice for the modeling family is
implied by the logical properties of the optimization problem. Throughout this chapter,
different kinds of probabilistic models are considered in accordance with the nature of
the problems to be solved.
Even though metaheuristics can provide near-optimal solutions for complex
combinatorics, there are cases where the solution itself cannot be formalized in a
simple way. In the case of dynamic control under partial observation, the global
solution is a huge decision tree, which depends on all potentially earned observations.
Such huge dimension variables cannot be manipulated. Under some conditions,
dynamic programming answers this problem theoretically by providing a recursive
construction of the optimal solution. In practice, this method takes far too much
time and computer storage; approximation strategies are necessary. The ﬁnal section
of this chapter investigates the approximation of control strategies under partial
observation by means of a cross-entropic approach. As has already been mentioned,
an exact modeling of the decision trees is intractable. The decision tree itself will
be approximated by means of a family of probabilistic laws. The chapter will show
that a double-approximation, i.e. using the metaheuristics and the modeling, still
leads to acceptable solutions. These solutions are stochastic processes with bounded
memories and constitute continuous approximations of the optimal decision tree.
6.2. The cross-entropy (CE) method
The CE method was developed by Reuven Rubinstein [DEB 03] and was initially
intended for rare event simulation. A rare event is an event of weak probability. The

Probabilistic Modeling of Policies
139
need for evaluating the probability of rare events arises when analyzing reliability,
e.g. what is the probability of a breakdown? A mathematical expression of such weak
probabilities is not always possible. In the worst case scenario, the only possible way
to evaluate a rare event is by simulation. However, simulating the rare event directly
using the law under study will not work: too many samples are necessary to accurately
evaluate the probability of the rare event. Importance sampling is a method usually
implemented in order to overcome this difﬁculty. Its principle consists of changing
the law so as to favor the sampling around the rare event. However, adjusting the
parameters for this change in laws is generally difﬁcult. The CE method provides an
iterative estimation of these parameters. Subsequently, the CE method for rare event
simulation is introduced at ﬁrst.
Then, it is explained how this method could be adapted to optimization tasks.
Since an event maximizing a function is typically a rare event, such usage of CE
is a corollary. This section of the chapter is very succinct. Please see [RUB 04] or
the tutorial [DEB 03] for an improved introduction. Furthermore, a large amount of
documentation is available at http://www.cemethod.org.
Notations:
– [Kronecker] Given a logical proposition A, the quantity δ[A] has to be 1 if A is
true and requires 0 in the opposite case.
– The quantity Epf(x) =
 
X f(x)p(x) dx describes the expectancy of the value
f(x) relative to the density of probability p of the variable x ∈X.
– Given the measurable sub-set Y ⊂X and a density of probability p over X, the
quantity Pp(Y ) = Pp(x ∈Y ) = Epδ[x ∈Y ] =
 
Y p(x) dx is the probability of the
event x ∈Y .
– Given the ﬁnite set E, the quantity ♯E is the number of elements, i.e. the
cardinality, of this set.
– The object N(μ, Σ) refers to the Gaussian distribution with mean μ and
covariance matrix Σ.
6.2.1. Probability of rare events
Let us assume a measurable space X with density of probability p and a real-valued
measurable mapping f over X. We have to evaluate the probability that function f
exceeds a certain threshold γ ∈R. This event Fγ = {x ∈X/f(x) ≥γ} is a rare
event, when its probability is very weak, typically when f shows the malfunctioning
of a system.

140
Optimization in Signal and Image Processing
6.2.1.1. Sampling methods
Monte-Carlo. Let x1, . . . , xN be samples of the variable x, generated according to
the law p. The probability Pγ = Pp(f(x) ≥γ) = Pp(Fγ) can be estimated by the
empirical average:
ˆPγ = 1
N
N

n=1
δ

f

xn

≥γ

.
The variance in this unbiased estimate is given by:
Ep
 ˆPγ −Pγ
2 = 1
N Pγ

1 −Pγ

.
In the case where Pγ is very weak, the variance is not the correct criterion for
evaluating this estimate. The relative standard deviation would be more appropriate:
σγ
Pγ
=

1 −Pγ
NPγ
.
Note that this standard deviation is inversely proportional to
!
NPγ. Thus, the
empirical averaging cannot be used to estimate a rare event Fγ.
Importance sampling. The law p being inadequate for an estimation of Pγ, an
alternative approach consists of using an auxiliary sampling law q, with a sampling
scope focused around the rare event. Let x1, . . . , xN be samples of the variable
x, generated according to the law q. Then, the probability Pγ is estimated by the
weighted empirical average:
ˆPγ = 1
N
N

n=1
δ

f

xn

≥γ
p

xn

q

xn
.
The variance for this estimate is:
Eq
 ˆPγ −Pγ
2 = Ep

δ

f(x) ≥γ

p(x)q(x)−1
−P 2
γ
N
.
This
variance
is
zeroed
for
an
optimal
probabilistic
density
q∗(x)
=
δ[f(x) ≥γ]p(x)P −1
γ . Unfortunately the law q∗is inaccessible, since the probability
Pγ is unknown. Actually, a wise deﬁnition of a sampling law q is not easy. The
method explained subsequently consists of choosing the sampling law from a
family of laws π(·; λ) | λ ∈Λ. The objective is to optimize the parameter λ in
order to minimize the distance D(q∗, π(·; λ)) with the optimal sampling law. As a
criterion for distance between two probabilities, the Kullback-Leibler divergence is

Probabilistic Modeling of Policies
141
considered. This divergence is the CE between the laws diminished by the entropy of
the reference law:
D(q, p) = Eq ln q(x)
p(x) =

X
q(x) ln q(x) dx −

X
q(x) ln p(x) dx.
Sampling by means of a family of laws. Now, the sampling law is optimized within
the family of laws π(·; λ) | λ ∈Λ. Minimizing the divergence D(q∗, π(·; λ)) means
maximizing the CE
 
X q∗(x) ln π(x; λ) dx. Taking into consideration the deﬁnition of
q∗, the following optimization is implied:
λ∗∈arg max
λ∈Λ Ep

δ

f(x) ≥γ

ln π(x; λ)

.
At this stage, a rare event estimation is again instrumental. The calculation of the
optimal parameter λ∗thus requires an importance sampling, say by the law q:
λ∗∈arg max
λ∈Λ Eq
"
δ

f(x) ≥γ
p(x)
q(x) ln π(x; λ)
#
.
Let x1, . . . , xN be samples of the variable x generated according to law q. The optimal
parameter λ∗is approximated by the estimation ˆλ∗deﬁned as:
ˆλ∗∈arg max
λ∈Λ
N

n=1

δ

f

xn

≥γ
p

xn

q

xn
 ln π

xn; λ


.
[6.1]
The family of law π(·; λ) | λ ∈Λ has been chosen in order to guarantee a solution for
this maximization. This chapter will show that there is no problem in doing so. The
family of natural exponential laws is used in this case [RUB 04].
Now, the estimation of λ∗based on formula [6.1] is still not satisfactory. This
estimation process is based on an importance sampling, in which law q remains
unknown. Indeed, estimating λ∗is the basis for creating such a law. This is a typical
framework, where a ﬁxed-point process may be used; by the way, such an iterative
approach is the essence of the CE method.
6.2.1.2. CE-based sampling
The previous section showed us how to optimize a parameterized law in
order to address the importance sampling. However, estimating this parameter
via equation [6.1] also requires an importance sampling. To avoid this problem,
Rubinstein suggests an iterative method on the basis of a degressive relaxation of the
rare event.
For the sake of simplicity, we assume the existence of parameter λ0 ∈Λ such that
π(·; λ0) = p.

142
Optimization in Signal and Image Processing
Basic principle. Let (γt | t ≥1) be a sequence such that:
– event f(x) ≥γ1 is not rare;
– event f(x) ≥γt+1 is not rare in regards to the law π(·; λt);
– limt→∞γt = γ.
Then, a sequence of parameters (λt | t ∈N), with π(·; λ0) = p, may be constructed
on the basis of an iteration of estimation process [6.1]:
– generate x1, . . . , xN according to law π(·; λt);
– choose λt+1 ∈arg maxλ∈Λ
N
n=1(δ[f(xn) ≥γt+1]
p(xn)
π(xn;λt) ln π(xn; λ)).
Rubinstein proposed an adaptive algorithm for constructing sequence (γt | t ≥1).
Adaptive construction of the bounds sequence.
The construction process
introduced now implies the use of a selection parameter ρ ∈]0, 1[. This parameter
impacts the convergence speed of the sequence (γt | t ≥1). Speciﬁcally, the bound
γt is deﬁned as the (1 −ρ) quantile of f(x) for the law π(·; λt−1). More precisely,
when x1, . . . , xN are samples generated by π(·; λt−1) and are ordered so that
f(xn) ≤f(xn+1) for 1 ≤n < N, then γt is deﬁned by γt = min{γ, f(x⌈(1−ρ)N⌉)}.
Parameter ρ has to be large enough, so as to provide a fair estimation of the
probability of event f(x) ≥γt for the law π(·; λt−1). Note that the sequence
(γt | t ≥1) increases except for the noise. When combining the constructions of
(λt | t ∈N) and (γt | t ≥1), the CE algorithm, as described in [DEB 03], is then
deﬁned.
Integrated algorithms. Let ρ ∈]0, 1[. The CE algorithm for simulating rare events
is expressed as follows:
1) choose λ0 ∈Λ such that π(·; λ0) = p. Set t = 1;
2) generate N samples x1, . . . , xN by the law π(·; λt−1). Put these samples into
an increasing order according to f. Calculate the (1 −ρ) quantile γt:
γt = min

γ, f

x⌈(1−ρ)N⌉

,
[6.2]
3) compute λt by the maximization:
λt ∈arg max
λ∈Λ
N

n=1

δ

f

xn

≥γt

p

xn

π

xn; λt−1
 ln π

xn; λ


;
[6.3]
4) if γt < γ, iterate from stage 2) again, while setting t ←t + 1;
5) estimate the probability Pγ for rare events by:
ˆPγ = 1
N
N

n=1
δ

f

xn

≥γ

p

xn

π

xn; λt
.
[6.4]

Probabilistic Modeling of Policies
143
Note. There are different evolutions of the CE method. In particular parameter ρ
itself may be adaptive. Theoretical convergence results [HOM 04, MAR 04] have been
based on hypotheses of adaptive ρ.
6.2.2. CE applied to optimization
It was quickly noticed that the CE-based sampling process could be adapted and
applied to optimization. This idea makes sense, since parameters which optimize
an objective are hard to ﬁnd, and actually constitute a rare event. Let us have a
more detailed look at the algorithm presented in section 6.2.1.2. This algorithm
is based on the construction of a sequence of bounds (γt | t ≥1), which might
be considered as increasing except for the noise. These bounds deﬁne the events
Fγt = {x ∈X/f(x) ≥γt} which become increasingly rare. During the process
of construction, (γt | t ≥1) is truncated by γ, the parameter of the rare event
to be evaluated. However, it is possible to carry on with the process. This leads
to a sequence of increasingly rare events, which converge towards the event
Fγ∞= {x ∈X/f(x) ≥maxy∈X f(y)}. This event is almost empty in general. If
the process works long enough, it leads to the construction of a parameter λ, such
that law π(·; λ) is very close to Fγ∞. This is a way to reach the optimum of f.
While not subsequently addressed in detail, certain implied difﬁculties have to be
discussed since they inﬂuence the convergence of the method:
– choosing the selection parameter ρ, or its evolution throughout the process;
– deﬁning a criteria that stops the convergence;
– choosing a family of laws π well adapted to the optimization problem.
As previously discussed, some theoretical results answer the ﬁrst two points
[HOM 04]. It is not the purpose of this chapter to investigate these theoretical aspects.
In addition, empirical criteria are sufﬁcient and functional for our applications. The
latter point is not easy to formalize; it is mostly driven by the experiments. However,
the examples show that the laws naturally follow from the structure of the problem.
The next section presents the CE algorithm for optimization in the initial version
and in its smoothed version.
6.2.2.1. Algorithms
f is a real-valued function of the variables x ∈X. Variable x has to be optimized
with f(x). A family of laws (π(·; λ) | λ ∈Λ) is deﬁned over X.
Original algorithm. Let us take a selection parameter ρ ∈]0, 1[. The CE algorithm
for optimization works as follows:
1) initialize λ0 ∈Λ; This parameter is generally chosen so that π(·; λ0) is close to
the uniform law. Set t = 1;

144
Optimization in Signal and Image Processing
2) generate a set Et of N samples, according to the law π(·; λt−1). Select the
⌊ρN⌋best samples in regards to the function f. Let St ⊂Et be the subset of samples
such that:
♯St = ⌊ρN⌋
and
∀x ∈St, ∀y ∈Et \ St, f(x) ≥f(y);
3) compute λt by the maximization:
λt ∈arg max
λ∈Λ

x∈St
ln π(x; λ);
[6.5]
4) repeat from stage 2) while setting t ←t + 1 until the stop criteria is achieved;
5) the ﬁnal stage being at t = tf, an optimal solution for f can be sampled by the
law π(·; λtf ).
A simple stop criterion could be obtained by evaluating the stationarity of
γt = infx∈St f(x).
Notes. Since the aim of the algorithm is no longer to evaluate a probability, some
simpliﬁcations appear in the sampling algorithm. In particular, the update equation
[6.5] no longer contains the term of correction
p(x)
π(x;λt−1).
When the variable x is discrete, update [6.5] may cancel the probability of some
states: as a result, theses states become inaccessible. An exponential smoothing of the
update avoids this problem.
Smoothed algorithm. In addition to the selection parameter ρ ∈]0, 1[, a smoothing
parameter α is deﬁned. The set of law parameters Λ is assumed to be convex (this
is often the case in practice). The smoothed algorithm differs from the previous
algorithm at its update stage:
3) compute κt by the maximization:
κt ∈arg max
κ∈Λ

x∈St
ln π(x; κ),
[Smoothed update] Then, set λt = ακt + (1 −α)λt−1.
The CE algorithm for optimization is now applied to a simple example: the
traveling salesman.
6.2.2.2. A simple example
A salesman has to visit n cities and then come back to the starting point. The
distance between city i and city j is described by the value d(i, j) = d(j, i). The aim

Probabilistic Modeling of Policies
145
is to optimize the travel by the deﬁnition of a cycle (v1, v2, . . . , vn, v1), in which all
cities are visited only once, and which minimizes the distance to be traveled, i.e.:
f

v1, v2, . . . , vn

= d

vn, v1

+
n−1

k=1
d

vk, vk+1

.
The CE method is applied to this problem. It is assumed without loss of generality
that v1 = 1.
While applying the CE method, the ﬁrst stage is the deﬁnition of a family of
laws which is adapted to the problem. This preliminary stage is fundamental, as all
other stages take place automatically. For this problem, Markov chain laws are elected
[RUB 04]. Within a Markov chain, each new destination is sampled relatively to the
current location of the salesman1. This choice is not at all random, but is led by
the cinematic nature of the problem. Somehow, it locates certain difﬁculties of the
optimization: it is likely that the cities close to the current position would be favored
by the best solution.
These laws have to be formalized now. Let p(v) denote the law for sampling a
circuit v. Then, the construction of p(v) is that of a Markov chain:
p(v) = p

v2 | 1

n
$
k=2
p

vk+1 | vk

.
As a consequence, the law p is characterized by the parameters p(j | i), that is the
probability of moving form city i to city j. The following constraints are applied to
p(j | i):
p(j | i) ≥0,
n

j=1
p(j | i) = 1
and
p(i | i) = 0 (non-stationarity).
[6.6]
Note that the Markov chain does not comply with the circuit constraint n = 1.
Some additional adaptation of the sampling process will be implemented.
Family of laws. Let P = (p(j | i))ij denote the matrix of components p(j | i). The
laws family, π, is naturally deﬁned as follows:
– Λ is the set of matrices P compliant with constraint [6.6]; note that Λ is convex;
– π(v; P) = p(v2 | 1) %n
k=2 p(vk+1 | vk), for all P ∈Λ.
1. Another possibility would have been to map each city at a travel stage. However, such a law
is insufﬁcient for reasons explained hereafter.

146
Optimization in Signal and Image Processing
As previously discussed, the Markov chain does not always generate samples for
valid circuits. Actually, the following constraints are not managed by the laws:
vn+1 = 1
and
vi ̸= vj for all i, j ≤n such that i ̸= j.
[6.7]
It is shown at the very end of this section, how to handle this difﬁculty. However,
before that, updating stage [6.5] is now expressed in detail.
Update. The update of a parameter P ∈Λ is performed by maximizing:
max
P

v∈St
n

k=1
ln p

vk+1 | vk

,
under constraint [6.6]. This problem is convex and separable. It is easily solved by the
Kuhn-Tucker conditions. The following formula is valid for i ̸= j:
p(j | i) = ♯

(v, k)/v ∈St, 1 ≤k ≤n, vk = i and vk+1 = j

♯

(v, k)/v ∈St, 1 ≤k ≤n and vk = i

.
[6.8]
Constraints on the itinerary. Constraints [6.7] are generally unsatisﬁed by the
sampled circuits. Then, the approach in use consists of sampling with rejection. The
sampling process is thus repeated until the quota (i.e. N) of valid samples has been
reached. Samples which have not been validated by [6.7] are simply rejected. This
procedure attributes implicitly the evaluation −∞to invalid samples and adapts the
coefﬁcient of the selection rate ρ so as to remove systematically the invalid cases.
Now, a literal implementation of the sampling with rejection is intrinsically inefﬁcient,
since the probability of rejection is very high. The rejections have to be simulated, by
reprocessing the law π(·; P) along the circuit:
– after each Markovian choice for a city, remove this choice from matrix P, by
canceling the column of P linked to that city; renormalize all lines of P,
– always choose 1 for the last transition.
This selection method is equivalent to π(·; P) with rejection, and remains compatible
with updating formula [6.8].
The results of detailed experiments are available in the tutorial on CE [DEB 03].
CE is of a high performance for these problems.
6.3. Examples of implementation of CE for surveillance
The suggested example is inspired by the research carried out on behalf of
intelligence services working for military institutions. The aim is to ﬁnd clues in the
theater of operations with the help of different tools. The territory to be explored is
often very large in comparison to the capacities of surveillance sensors. It is therefore
necessary to place the sensors in a way which maximizes the chances of ﬁnding the
clue. Two main levels of optimization have been considered:

Probabilistic Modeling of Policies
147
– a global level which decides upon the distribution of sensors to subdivisions of
the territory;
– a local level: the search efforts are optimized within each subdivisions of the
territory.
The levels of optimization are mutually dependent. In particular, the global
distribution of the sensors is subject to the results of local optimizations of the search
efforts. The CE method is used for the global optimization.
6.3.1. Introducing the problem
The probability of detecting a hidden target in a space has to be maximized. The
target is non-moving and some prior information is known by means of a localization
probability. The sensors are characterized by their detection capability and by their
autonomy; their operation radii are limited.
The space to be searched is denoted E and divided into zones Ez, z ∈{1, . . . , Z}.
These zones are limited areas and have been chosen so as to take into account the
autonomy of the sensors. A sensor will investigate one zone. Each zone z is split up
into cells Unitzu, u ∈{1, . . . , Uz}. These cells are homogenous, i.e. all points in one
cell have the same characteristics (same surface, same kind of vegetation etc. refer to
Figure 6.1). These subdivisions are subject to the following constraints:
E =
Z
&
z=1
Ez
with: Ez ∩Ez′ = ∅for z ̸= z′,
Ez =
Uz
&
u=1
Unitzu
with: Unitzu ∩Unitzu′ = ∅for u ̸= u′.
The target is positioned somewhere in this space. The presence of the target
is characterized by the probabilistic prior α. Typically, α(Unitzu) is the prior
probability that the target is in the cell Unitzu. The target may be detected by sensors
s, s ∈{1, . . . , S}. These sensors only deal with one zone and their autonomy is
limited. This limited autonomy is characterized by an available amount of resources
Φs Exploring a cell Unitzu requires a certain amount of resources ϕs(Unitzu). The
optimization problem thus has to respect the following constraint:
Uz

u=1
ϕs

Unitzu

≤Φs.
The chances of detecting a target located in cell Unitzu depends on the quantity of
resources that are being used (e.g. time used to explore the cell). These probabilities

148
Optimization in Signal and Image Processing
also depend on the performance of the sensor within the cell Unitzu. Classically, an
exponential function of detection is employed [DEG 61, KOO 57]. Thus
Ps

ϕs

= exp

−ws
zuϕs

Unitzu

represents the conditional probability that sensor s will not detect a target hidden in
Unitzu, taking into account the search effort provided ϕs(Unitzu). Coefﬁcient −ws
zu
characterizes the visibility of the Sensors in cell Unitzu.
zone to be searched
cell to be searched
lake
street
woods
Figure 6.1. Space to be searched
In addition to the search functions ϕ, a mapping m : s →z is deﬁned, which
allocates each sensor to a zone. The aim is to optimize ϕ and m conjointly, so as to
maximize the chances of detecting the target:
F(m, ϕ) =
Z

z=1
Uz

u=1
α

Unitzu

$
s∈m−1(z)
Ps

ϕs

Unitzu

.
The entire problem is therefore expressed as follows:
min
ϕ,m F(m, ϕ), under the constraints:
Uz

u=1
ϕs

Unitzu

≤Φs and ϕ ≥0.
[6.9]
This problem is subdivided into two mutually dependent levels:
– ﬁnd the best possible allocation of the sensors to the zones;
– ﬁnd the best possible distribution of resources to the sensors.
The problem of allocating the sensors to the respective zones can be solved with
the help of the CE method. The underlying problem is, however, convex and therefore
needs to be optimized by more traditional methods [DEG 61].

Probabilistic Modeling of Policies
149
Note that the sensor allocation can be solved by linear programming (LP) when the
mapping m is one-to-one. A comparative study between CE and LP has been carried
out. Well adjusted parameters in CE enable us to provide optimal solutions. When LP
is a possible approach, it provides optimal solutions to this allocation problem much
more quickly.
However, in most cases m is not one-to-one and cannot be optimized by LP. When
LP-based optimization is no longer possible, integer programming could be employed.
Optimizing the allocation of sensors to search zones by integer programming is,
however, impossible for large dimensions (combinatorics). CE, on the other hand, is
often able to ﬁnd the optimal solution in a reasonable time. The following sections
present the CE method for the optimization of the sensor allocation.
6.3.2. Optimizing the distribution of resources
This section will show how to optimize the distribution of sensor resources.
When only one sensor s is allocated to zone z, the distribution of the resources is
solved as follows:
min
ϕs
Uz

u=1
α

Unitzu

exp

−ws
zuϕs

Celzu

under the constraints:
Uz

u=1
ϕs

Unitzu

≤Φs and ϕ ≥0.
This is a de Guenin problem [DEG 61], solved by Kuhn and Tucker:
ϕs

Unitzu

= max
⎧
⎪
⎨
⎪
⎩
0, −
ln
'
λ
wszuα

Unitzu

(
wszu
⎫
⎪
⎬
⎪
⎭
,
[6.10]
where the parameter λ is a dual variable to be adjusted. As the objective function is
convex, λ is obtained by dichotomy in ]0, maxu(ws
zuα(Unitzu))] so as to fulﬁll the
condition Uz
u=1 ϕs(Unitzu) = Φs.
When no assumption is made about the mapping m, the set of sensors m−1(z) is
affected to zone z. A recursive method is employed in order to optimize the usage of
the sensors of m−1(z), based on the de Guenin optimization scheme. Optimization
of the variables ϕs takes place recursively in the form of a cycle (all other variables
remain unchanged).

150
Optimization in Signal and Image Processing
Algorithm. 1) Initialize ϕs(Unitzu) = 0 for each sensor s ∈m−1(z),
2) Compute the probability p1 of not detecting the target in zone Ez, denoted p1
3) Carry out the following operations for each sensor s ∈m−1(z):
- compute the best distribution of resources according to the optimization of de
Guenin for the sensor s in concern (for every other sensor i, ϕi is kept unchanged),
- memorize the distribution ϕs, previously computed.
4) Compute the new probability p2 of not detecting the target,
5) If p1 ≈p2 then stop; otherwise, set p1 := p2 and reiterate from step 3).
Figure 6.2 provides a simple illustration of this algorithm.
For the sensor in question the consumption
of resources for every cell in the zone has 
to be updated
Sensor 1
Sensor 2
Sensor 3
Figure 6.2. Optimizing the distribution of resources for several sensors
6.3.3. Allocating sensors to zones
An exhaustive research of the best possible allocation of sensors to zones requires
the computation of the best resource distribution for each sensor conﬁguration in
each zone. For a given zone z, this means that ϕ is optimized for any possible
choice of m−1(z) ⊂[[1, S]]. The total number of sub-problems to be solved by local
optimization is Z × 2S. This is, of course, impossible. CE on the other hand, which is
adaptive with the data, does well with this problem. Subsequently, a family of laws
for sampling the allocation functions m is deﬁned.
optimizing the
distribution
of resources
optimizing the allocation
of sensors to zones
sensors
zones
Figure 6.3. Allocating sensors

Probabilistic Modeling of Policies
151
Family of laws. A discrete probabilistic law p(· | s) is associated with each sensor
s and is intended for sampling the allocation of sensor s to a particular zone z. The
matrix P = (p(j | i))ij is constructed from the components p(z | s). On the basis of
P, it is possible to deﬁne a sample prototype for the allocation functions m:
π(m; P) =
S
$
s=1
p

m(s) | s

.
The construction of a family of laws π for the CE is naturally implied:
– Λ is the set of matrices P which satisfy p(j | i) ≥0 and Z
j=1 p(j | i) = 1,
– π(m; P) = %S
s=1 p(m(s) | s), for P ∈Λ.
The update of P is similar to section 6.2.2.2:
p(j | i) = ♯

m/m ∈St, m(i) = j

♯S
.
[6.11]
Injective allocation. The previous sampling method will generate any possible
sensor-to-zone mapping. In general, such mapping is not injective. In order to
provide one-to-one mapping, a sampling with a reject will be implemented as
shown in section 6.2.2.2. Thus, the sampling process is iterated until N injective
maps are obtained. The remaining non-injective maps are simply rejected. As in
section 6.2.2.2, this process is accelerated by making the rejections virtual. This can
be carried out via a normalization process.
In the case of injective maps, a computation of the best resource allocation is
possible for all conﬁgurations. Only Z × S cases have to be taken into consideration.
In such a case, LP is a better approach.
6.3.4. Implementation
This section will focus on optimizing the allocation of sensors to zones in a general
case (i.e. several sensors can be allotted to the same zone). In order to do so, an
example (for an easy example, see Figure 6.4) of a territory divided into 20 zones
of research is used. Every zone is made up of 25 cells. 10 sensors are available for the
exploration of the territory.
Parameters of the CE algorithm. For each iteration of the algorithm, N = 500
samples are generated and evaluated. The coefﬁcient of the selection rate is ρ = 0.05.
The smoothing parameter α is adaptive, depending on the number nb of elapsed
iterations:
- For nb ≤4,
α = 0.1
- For nb > 4,
α =
"
1 −
1
4√
nb
#
.

152
Optimization in Signal and Image Processing
Probability of the target being present
Every line
corresponds
to a zone
light color
=
high probability
high visibility
more resources
,,,,,,,,,,,,,-
Visibility of sensors; sensors 1 to 10
Allocation of sensors/distribution of resources; sensors 1 to 10
Figure 6.4. Example
Result and analysis. The optimal solution for this example is obtained after
30 iterations of the CE algorithm. Each sensor is specialized in the exploration of one
single zone (except sensor 3). The algorithm allocates a sensor to a zone in which
this particular sensor obtains an improved visibility. Sensor 3 can be allocated to two
zones, which zone 1 and zone 11. The chances that the target is hidden in zone 1 are

Probabilistic Modeling of Policies
153
lower than in zone 11. Two sensors are therefore allocated to zone 11, sensor 2 and
sensor 3. The sensors focus their research on the cells with the best visibility.
6.4. Example of implementation of CE for exploration
Throughout this section, it has been shown how CE could be applied to a path
planning problem for a map-based mobile localization. It is assumed that the
environment covers a territory D ⊂R2. The objective is to choose the trajectories
from an initial position si ∈D to a ﬁnal position sf ∈D, which provide the best
localizations of the mobile during the mission execution. The process of localization
[DEL 99] consists of an incremental estimation of the position of the target by means
of the information provided by the sensors. The estimation process is usually based on
ﬁltering methods, for instance the Kalman ﬁlter. The measurements which have been
obtained are correlated to the embedded map, thus allowing for a global localization.
The posterior Cramér-Rao Bound can be used to evaluate the performance of the
ﬁlter. It is a lower bound for the covariance matrix of the state estimate.
6.4.1. Deﬁnition of the problem
The problem to be solved is based on two main stochastic equations. The ﬁrst
equation is known as the state equation, which provides the evolution of the mobile
state between two successive time periods. The second equation is known as the
observation equation, which links measurements to a particular state and prior
knowledge of the map. The following notations are used:
– Xk ≜(xk, yk) ∈D the position of the mobile sensor at time k.
– Ak ≜(ax, ay) the control given to the mobile sensor at time k. The controls
taken into consideration are (ax, ay) ∈{−d, 0, +d} × {−d, 0, +d} with d ∈R+.
– Zk is the vector of measurements at time k.
– M is the map in which the mobile is moving. It is built from speciﬁc
features extracted from the environment and made up of Nf geometric objects.
mi = (xi, yi) ∈D, i ∈{1, . . . , Nf} provide the positions of these objects considered
as points of the map. These objects represent real elements that will be observed during
the execution of the trajectory.
– Iv(k) ⊂{1, . . . , Nf} is the subset of indexes describing the objects of the map
that can be seen by the mobile at time period k. Indeed, the sensor provides a local
perception of the position of the mobile. Furthermore, we assume that all observations
provided by the sensors originate from one and only one object of the map. There is
therefore no problem in associating objects with the respective measurements.
The equation of the mobile is deﬁned as follows:
X0 ∼π0 ≜N

si, P0

,
Xk+1 = Xk + Ak + wk,
wk ∼N

0, Qk

,

154
Optimization in Signal and Image Processing
where {wk}k≥1 is a sequence of mutually independent Gaussian noises with average
zero and respective covariance matrix Qk.
For each visible object and each time period k, the mobile sensor has
measurements describing the distance to visible objects and the angle between the
axis of the sensor and the axis of the object. The horizontal axis is based on the map.
The observation vector uniﬁes all individual observations. The equation describing
the observations works as follows:
Zk =

zk(j)

j∈Iv(k),
with ∀j ∈Iv(k):
zk(j) ≜
⎧
⎪
⎪
⎨
⎪
⎪
⎩
zk
r (j) =
.
xk −xj
2 +

yk −yj
2 + γk
r (j),
zk
β(j) = arctan
" yj −yk
xj −xk
#
+ γk
β(j).
Variables {γk
r (j)} and {γk
β(j)} are random Gaussian noises with average zero and
respective standard deviations σr and σβ.
In order to address the optimization of the exploration, the map M is discretized
to a grid of Nx × Ny. cells. A state s ∈{1, . . . , Ns} with Ns = N×Ny is linked
to each cell. Owing to the nature of the action space, there are Na = 8 possible
decisions in association with states s (with a notable exception at the border of the
map – Figure 6.5), which control the move to eight possible neighbors. A trajectory
between si and sf is thus deﬁned by the sequence of actions V Ka = (a1, a2, . . . , aK)
or the sequence of states V K+1s = (si, s2, . . . , sK, sf). The problem of optimal
planning consists of determining the sequence V ∗a which minimizes the cost function
of the mission. From now on, ℑsisf denotes the trajectories which start from si and
end at sf.
The posterior Cramér-Rao bound as a criterion for optimization. The posterior
Cramér-Rao bound is used when a random parameter is estimated from random
measurements. If ˆX(Z) provides a non-biased estimation of a random vector X ∈Rr
on the basis of random measurements Z, the posterior Cramér-Rao bound is deﬁned
as the inverse of the information matrix [VAN 68] established by Fisher J:
E
/ ˆX(Z) −X
 ˆX(Z) −X
T 0
⪰J−1(X, Z),
[6.12]
where J is given by:
Jij = E
1
−∂2 ln p(Z, X)
∂Xi∂Xj
2
i, j = 1, . . . , r
[6.13]

Probabilistic Modeling of Policies
155
0.5
1
1.5
2
2.5
3
3.5
4
4.5
5
5.5
0.5
1
1.5
2
2.5
3
3.5
4
4.5
5
5.5
a=8
a=1
a=2
a=3
a=4
a=5
a=6
a=7
s=13 
s=1 
s=2 
m1 
m2 
m3 
m4 
Figure 6.5. This image shows the states s (+), the eight
actions a (arrows) and the objects mi (o)
and p(Z, X) is the joint probability for the variables X and Z. If X is of dimension r,
then J has the size r × r. In the context of a ﬁltering, that is an iterative estimation of
the position Xk by means of the measurements Zk, there is a recurrent link between
the matrices Jk and Jk+1 [TIC 98]. For this application the following relationship
applies:
J0 = P −1
0
,
[6.14]
Jk+1 = Πk +

Jk + Qk
−1,
[6.15]
where Πk represents the information obtained from the observation process. This
relationship is derived by differentiating the law p(Zk|Xk) with the variable Xk. This
chapter will not provide details about this calculation. However, note that a Monte
Carlo simulation is used for computing the expectation because of the non-linear
observation equation [PAR 02].
The optimization criterion in use is a function of matrices Jk along the trajectories.
Speciﬁcally, this criterion is related to the area of the ellipsis that describes the
uncertainty of the estimation. In the case of a trajectory V K+1
s
= (si, s2, . . . , sK, sf),
the objective function to be minimized is expressed as follows:
φ

V K+1
s

∝
K

k=0
αk det

J−1
k

,
αk ∈R+.
This function depends on the determinant of Jk. It is shown that a method such as
dynamic programming cannot solve the best trajectory for this criterion [LEC 97].
The CE method will be used in this case.

156
Optimization in Signal and Image Processing
6.4.2. Applying the CE
In order to implement the CE algorithm, it is ﬁrst necessary to deﬁne the random
processes which will generate our samples. These samples are deﬁned by a family of
laws π(·; λ) | λ ∈Λ, which have to be chosen in accordance with the structure of the
problem. Now, let τ be an element of ℑsisf , the set of valid trajectory. This trajectory
is characterized by a sequence of actions which has been decided for each state within
τ. The idea will be to decide for an action conditionally to a state. As a consequence,
each state s is associated with a density of discrete probability fs which deﬁnes the
probability of the event “choose action a”:
fs

i, ps
= P(A = i) = ps
i,
i = 1, . . . , 8 with
8

i=1
ps
i = 1.
[6.16]
The family adapted to this problem is thus (fs(·, ps))s≤1≤Ns | ps ∈[0, 1]8. Moreover,
the density will be chosen uniform for the initial stage of the algorithm.
Generating trajectories. At iteration n of the CE algorithm, and assuming that the
density of probability is (fs(·, ps
n))s≤1≤Ns, the generation of a trajectory of length T
in ℑsisf is carried out according to the procedure shown in Table 6.1.
j = 0
while (j < N) do:
t = 0, st = si
generate aj
0 according to fsi(·, psi
n )
apply action aj
0 and update st.
repeat until st = sf:
- generate action aj
t according to fst(·, pst
n )
- apply action aj
t and update st.
- set t = t + 1.
return τ(j) = (si, aj
0, sj
1, aj
1, . . . , sj
i−1, aj
i−1, . . . , sj
T −2, aj
T −2, sf)
set j = j + 1
Table 6.1. Generating N trajectories at iteration n
Updates. At iteration n of the CE algorithm, γn+1 is estimated as the ρ-quantile
for the sample evaluations (φ(τ(j)))1≤j≤N. Denote Sn+1
=
{j
∈
[[1, N]]/
φ(τ(j)) ≤γn+1}. As the density of probability is discrete (fs(·, ps
n))s≤1≤Ns, an
estimation of the parameters ps
n+1 is achieved using the formula [RUB 04]:
ps
i,n+1 =

j∈Sn+1 δ

φ

τ(j)

∈χsi


j∈Sn+1 δ

φ

τ(j)

∈χs

s ∈1, . . . , Ns, i = 1, . . . , 8
[6.17]

Probabilistic Modeling of Policies
157
where {φ(τ(j)) ∈χsi} is the event “the trajectory φ(τ(j)) is going through state s
where action i is decided” and {φ(τ(j)) ∈χs} is the event “the trajectory φ(τ(j)) is
going through state s”.
6.4.3. Analyzing a simple example
This section presents an application of the algorithm to a simpliﬁed example. The
map M has the size [1, 10] × [1, 10] and contains seven objects. The grid contains
Ns = 10 × 10 states. The initial and the ﬁnal positions are situated on the grid at
(3; 2) and (9; 9). The dynamic model is characterized by the following uncertainty:
P0 = σ2 · I22,
Qk = σ2 · I22, ∀k ≥1
where I22 is the identity matrix of size 2 × 2 and σ2 = 1, 6 · 10−3. Furthermore, the
observation equation is characterized by σ2
a = 10−4, σ2
β = 10−8 for all objects. The
CE algorithm has been run during 30 iterations, with 4,000 samples of trajectories
generated at each iteration. The selection parameter was ρ = 0.2.
1
2
3
4
5
6
7
8
9
10
1
2
3
4
5
6
7
8
9
10
s i 
s f 
Figure 6.6. Best possible trajectory obtained after 30 iterations of the CE algorithm
Figure 6.6 shows the best possible trajectory which has been determined in the
last iteration of the algorithm. The algorithm’s behavior is coherent. The best obtained
trajectory is the one that favors passages through the neighborhood of the objects of
the map. Figure 6.7 presents the evolution of parameter γ and the minimal cost φmin
for all generated trajectories. Figure 6.8 presents the evolution of density fsi(., psi
k )
at the initial point. Figure 6.7 shows the decrease of parameter γ as well as the fast
convergence of the algorithm. We should note the concentration of the sampling laws
around the best previous samples. Furthermore, analyzing the density of probability
(Figure 6.8) for the initial position si shows the persistence of two chosen actions. The
probability is, however, higher for action 8.

158
Optimization in Signal and Image Processing
0
5
10
15
20
25
30
1
1.5
2
2.5
3
3.5
4
4.5
5
iteration
Figure 6.7. Evolution of γ (circles) and of the minimum φ
among the samples (crosses)
Figure 6.8. Evolution of fsi(·, psi
k )
6.5. Optimal control under partial observation
In previous sections, sensor planning has been addressed without taking
into account observation feedback. Such prior planning is satisfactory when the
exploration space is not excessively random. Otherwise, a dynamic planning
approach should be considered. However, dynamic planning of the sensors leads to
major difﬁculties in optimization.

Probabilistic Modeling of Policies
159
Let us consider a very easy example. A moving target has to be intercepted within
a delimited territory. This target is moving according to a random model and reacts
by escaping the near trackers. Moving in the space is easy for the trackers but the
observation of the target is difﬁcult. Now, it is assumed to be a hill in the middle
of the territory. Climbing up that hill is difﬁcult but allows a good view from the
top. Which strategy should be chosen under these conditions? Should the interception
take place on the territory only, i.e. fast movement but bad observation of the target,
or does it makes sense to climb to the top of the hill, which means loosing time at
the beginning but allowing for a good observation and subsequently a better tracking
policy. When evaluating both strategies an optimal usage of the available information
has to be guaranteed. For this reason, dynamic problems are very complex from a
mathematical point of view.
In the literature, some hypotheses are expressed generally. First of all, the law of
evolution of the environment is assumed to be Markov. Secondly, the optimization
criterion is simple enough, that is, additive over the course of time. The problem can
therefore be solved theoretically [SON 71, CAS 98] by a dynamic programming
approach. The solution, however, takes up too much time and space in computer
storage and is therefore inaccessible, without pruning strategies. Another classical
approach will approximate the decision strategy on the basis of a reinforcement
learning process [BAK 04]. Even though this method is limited by the computer
storage of the decision grid, there are notable progresses using hierarchical
approaches.
In this section, the CE method will be applied to the learning process of optimal
strategies for planning under partial observation. The aim is to describe the possible
operating policies of control for each group of generic laws (typically hidden Markov
models). The parameters of the law are optimized by CE. This method does not require
a Markov evolution of the states nor the additive hypothesis on the objective function.
The approach avoids the restrictions in term of the dimension of the observation space.
On the other hand, the performance of the strategies is balanced by the complexity of
the implemented models.
6.5.1. Decision-making in partially observed environments
This section explains a short theoretical background of control under partial
observation; a simulated experiment is provided in section 6.5.3.
It is assumed that a subject has to carry out a mission in a given environment.
This subject interacts with the environment. It consumes observations and produces
actions. The control policy of the subject is to be optimized in order to accomplish the
mission.
The environment. The environment is described by a hidden state x which evolves
with time. In the example of section 6.5.3, this state is made up of the positions

160
Optimization in Signal and Image Processing
of the target and two patrols. The time t is discretized and ﬂows from period 1
to the ﬁnal period T. A temporal evolution of the state is represented by vector
x = x1:T = x1, . . . , xt, . . . , xT . In the course of the mission the subject produces
the decisions d = d1:T which has an impact on the evolution of the environment.
In the example, d is the move decision for the patrols. The subject perceives partial
and noisy observations of the environment, which are expressed as y = y1:T . In
the example, this observation is a poor estimation of the position of the target. The
environment is then characterized by a law of the hidden state dynamic and a law of
the observations, which are conditional of the decisions. This probabilistic law is
subsequently denoted P:
The hidden state xt and the observation yt are known on the basis of the
conditional law P(xt, yt | x1:t−1, y1:t−1, d1:t−1), which depends on the states,
observations and past decisions. Notice that dt itself is generated by the subject
after receiving the measure yt.
In this chapter, there is no Markov hypothesis carried out concerning P. On the
other hand, it is assumed that the law P(xt, yt | x1:t−1, d1:t−1) is simulated very
quickly. The law for x, y | d is illustrated in Figure 6.9. The outgoing arrows represent
the data produced by the environment, i.e. observations. The incoming arrows are the
data consumed by the environment, i.e. decisions made by the subject. The variables
are written in chronological order: yt appears before dt, since decision dt is made
after receiving yt. The notation P(x, y|d) is used to describe the law for the entire
environment:
P(x, y | d) =
T
$
t=1
P

xt, yt | x1:t−1, y1:t−1, d1:t−1

.
hidden state x
y1
y2
y3
yt
yt +1
d1
d2
d3
dt
dt +1
Figure 6.9. The environment
Evaluation and optimal planning. Evaluation and optimal planning. The mission to
be accomplished will now be described and formalized. The time which is available
to accomplish the mission is limited. T therefore represents the maximum length of
time for this mission. The mission is evaluated by means of an objective function
V (d, y, x) which evaluates the trajectories d, y, x obtained after mission. Typically,
function V can be used to compute the time required for the accomplishment of a
mission. There is no assumption made about function V , except that the computation
of V (d, y, x) is fast.

Probabilistic Modeling of Policies
161
Our purpose is to construct an optimal decision tree y →(dt(y1:t)|T
t=1), that
depends on past observations, in order to maximize the average evaluation:
d∗∈arg max
d

y

x
P
'
x, y |
'
dt

y1:t
T
t=1
((
V
''
dt

y1:t
T
t=1
(
, y, x
(
.
[6.18]
A schema for this optimization process is shown in Figure 6.10. The double arrows
⇒characterize the variables to be optimized. These arrows describe the ﬂow of
information between the observations and actions. The cells described as ∞produce
decisions and transmit all received and generated information to their next neighbor.
This architecture illustrates a non-ﬁnite-memory problem: the decision depends on all
past observations. When the evaluation V is additive and the Markovian environment
applies, it is possible to build a recursive optimal solution on the principles of
dynamic programming. However, note that this recursive construction involves the
manipulation of the posterior probabilistic law of the hidden state as a parameter of
the DP. It is difﬁcult to handle such continuous parameters. A discrete approximation
of the solution is necessary but difﬁcult. The approach is different here: it is the
probabilistic model approximating the control policy, which is optimized.
Figure 6.10. Optimal planing
Direct estimation of the decision tree. In equation [6.18], the value to be optimized
d∗is a deterministic object. A probabilistic approach is possible. Indeed, it is an
equivalent problem to ﬁnd π(d | y), a law of the decisions conditionally to the past
observations, that maximizes the average beneﬁt:
V (π) =

d

y

x
T
$
t=1
π

dt | d1:t−1, y1:t

P(x, y | d)V (d, y, x).
This problem is still illustrated in Figure 6.10. But now, the double arrow describes
the structure of the dynamic Bayesian network for law π. Actually, there is not
a true difference between the probabilistic case and the deterministic case: if the

162
Optimization in Signal and Image Processing
Figure 6.11. Planning on the basis of a ﬁnite memory
solution d∗is unique the optimal law π∗is a Dirac function around d∗. On the other
hand, the probabilities become interesting in a case where π∗is just approximated,
since probabilistic models are continuous, and thus better suited to approximation.
Furthermore, an approximation of the optimal decision laws follows naturally, by just
replacing the inﬁnite memory ∞with a ﬁnite memory m; see Figures 6.10 and 6.11.
In fact, by limiting the hidden memory, the decision law π becomes a hidden Markov
model. These models are easily optimized using CE.
Deﬁning a family of laws for the approximation. Let M be a ﬁnite set of states
that characterizes the memory of the laws. Deﬁne the variables mt ∈M, the memory
state at time-period t. For this choice of memory M, the hidden Markov models h are
deﬁned as follows:
h(d | y) =

m∈M T
h(d, m | y)
with
h(d, m | y) =
T
$
t=1

hd

dt | mt

hm

mt | yt, mt−1

.
It is assumed that the conditional laws hd and hm are invariant in time. Of course,
there are many possible choices for h, given M. These choices are characterized by
the deﬁnition of hd and hm. Now, let H denote the set of all such laws h.
6.5.2. Implementing CE
Our aim is to choose MMC h ∈H so as to attain an optimal strategy π∗:
π∗≃h∗∈arg max
h∈H V (h).

Probabilistic Modeling of Policies
163
From now on, P[h] refers to the law of the complete system, which combines both the
environment and planning components:
P[h](d, y, x, m) = P(x, y | d)h(d, m | y).
The estimation of π∗by the means of h corresponds to the following problem:
h∗∈arg max
h∈H

d

y

x

m
P[h](d, y, x, m)V (d, y, x).
Optimizing h∗means adjusting the parameter h ∈H in order to narrow the probability
P[h] around the optimal value V . This is exactly what CE does. The original algorithm
(without smoothing) has been used in this application. By choosing the selection rate
ρ ∈]0, 1[ CE optimization takes the form:
1) initialize h by choosing hd and hm to be uniform;
2) generate N samples θn = (dn, yn, xn, mn) by the law P[h];
3) deﬁne S as the set of the ⌊ρN⌋best samples in regards to the objective
V (d, y, x);
4) update h by:
h ∈arg max
h∈H

n∈S
ln P[h]

θn
,
[6.19]
5) reiterate from stage 2) until convergence is reached.
Maximization [6.19] does not create any difﬁculties. Markov properties are
particularly instrumental here: ln P[h] is divided into a sum of basic logarithms
and the optimization is reduced to several small and independent sub-problems.
The resolution is completed by Khun and Tucker and leads to the following update
formulae:
⎧
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎩
hd(A | B) = ♯

(n, t) ∈S × [[1, T]]/A = dn
t and B = mn
t

♯

(n, t) ∈S × [[1, T]]/B = mn
t

,
hm(A | B, C) = ♯

(n, t) ∈S × [[1, T]]/A = mn
t , B = yn
t and C = mn
t−1

♯

(n, t) ∈S × [[1, T]]/B = yn
t and C = mn
t−1

.
6.5.3. Example
6.5.3.1. Deﬁnition
A target R moves in a territory of 20 × 20 cells, i.e. [[0, 19]]2. R is tracked by two
patrols B and C, which are controlled by the subject. The coordinates of R, B and
C at moment t are expressed as follows: (it
R, jt
R), (it
B, jt
B) and (it
C, jt
C). B and C
receive a very limited amount of information on the position of the target and move
slowly:

164
Optimization in Signal and Image Processing
– moving B (or C) is done with the following orders: turn left, turn right, go
forward, do nothing. there are 16 different possibilities;
– the patrols are initially positioned in the down corners of the territory, i.e.
i1
B = 0, j1
B = 19 and i1
C = 19, j1
C = 19, and are directed downward;
– At each measurement scan, patrol B (respectively C) is informed whether the
target is situated in their front plane or not. For example, if B is directed upward, it
will detect whether jR < jB or not. There are therefore four possible observations.
Initially the target is localized randomly in the upper half of the lattice. This
positioning is based on a uniform law. The target moves in all directions (also
diagonally) and no more than just one cell. This movement is probabilistic and favors
escape:
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
P

Rt+1 | Rt
= 0
if
it+1
R
−it
R
 > 1 or
jt+1
R
−jt
R
 > 1,
P

Rt+1 | Rt

∝

it+1
R
−it
B
2 +

jt+1
R
−jt
B
2
+

it+1
R
−it
C
2 +

jt+1
R
−jt
C
2
otherwise.
Note that a short distance is neglected in the sum in comparison to longer distances.
In other words, a patrol that is far away might hide a patrol that is very close to the
target. This modeling error is deliberate, since it will be illustrative of the algorithm’s
capacity to generate original strategies.
The mission objective is to maintain the target in proximity of at least one patrol
at each time period (i.e. a distance less than 3). The evaluation function V consists of
counting the number of such hits in the course of the mission:
⎧
⎪
⎨
⎪
⎩
V0 = 0;
Vt = Vt−1 + 1
if d

Bt, Rt
≤3 or d

Ct, Rt
≤3;
Vt = Vt−1
otherwise.
The entire duration of the mission is T = 100.
6.5.3.2. Results
Global behavior of the algorithm. The implemented algorithm is based on a low
selection rate ρ = 0.5 and on a high number of samples N = 10, 000. Note that this
choice of parameters has not been optimized at all, and may be improved. Moreover,
the CE smoothing was not implemented at the time of the experiment. However, the
risk of degeneration has been avoided by a adding a tiny noise at the law updating
stage.

Probabilistic Modeling of Policies
165
Convergence. At the very initial step, the strategies are mostly irrelevant. For this
particular problem the initial evaluation was 5% of the optimal value. The convergence
speed was also relatively low at the beginning. This speed increases as well as the
improvement of the population, until a new stable stage has been reached. At this
stage about 75% of the optimal value is obtained. Swapping between stages of slow
and rapid convergence has been observed several times. However, the speed usually
decreases gradually.
Near-optimal policies. 69 is the best average number of hits. This number has been
obtained by running the CE during a couple of days. Moreover, several instances of
the run have been tested, and a large hidden Markov model ♯M = 256 has been used.
Two different typical behaviors have been observed within the optimal policy:
– the patrols cooperate in order to track the target; see Figure 6.12;
– when the target is close to the borderline one patrol goes along the opposite
borderline while the other patrol continues tracking the target. This behavior is a
consequence of the blindness of the target to a close patrol when the other one is far
away.
Other tests have been carried out, for which the observations have been deleted.
The average number of hits was 32. In addition, in the case where memory transitions
are deleted within h, the average number of hits is 55 (usage of the previous
observation only).
Figure 6.12. A control sequence

166
Optimization in Signal and Image Processing
Intermediary tests. For the subsequent results in the table, the algorithm was
stopped after 10,000 iterations. This fact corresponds to a strong convergence.
On the currently available machines (PCs at 1 Ghz), this was several hours of
processing. The table below shows the percentage that has been reached relatively to
the estimated maximum, which is 69 hits. These percentages have been obtained for
several memory size, #M.
♯M
16
32
64
256
Evaluation
94%
96%
97%
97%
The solutions which have been obtained are close to the best estimated solution.
Moreover, it seems that a quite limited memory is sufﬁcient for a reasonable
performance.
6.6. Conclusion
The CE method for optimization is a very elegant metaheuristic which is based
on the principle of importance sampling. As a simulation process, CE adapts itself to
data that cannot be easily formalized. From this point of view, CE optimization is a
learning approach for optimizing a strategy.
Good implementations of CE require a well adapted modeling of the sampling
family in use. For dynamic problems, Markov models are favored. When observations
are involved, memory-based models, like hidden Markov models, are preferred.
With CE, the problem of optimization turns into a modeling problem. Speciﬁcally,
the CE method beneﬁts from the modeling strength of probabilities. Some recent
works have investigated the combination of cross-entropy with Bayesian networks.
Such approaches have been used in order to reduce the combinatorics by the means of
hierarchical operating policies [DAM 06].
6.7. Bibliography
[BAK 04] BAKKER B. and SCHMIDHUBER J., “Hierarchical Reinforcement Learning Based
on Subgoal Discovery and Subpolicy Specialization”, 8th Conference on Intelligent
Autonomous Systems, Amsterdam, The Netherlands, pp. 438–445, 2004.
[CAS 98] CASSANDRA A.R., Exact and approximate algorithms for partially observable
Markov decision processes, PhD Thesis, Brown University, Rhode Island, Providence, May
1998.
[DAM 06] DAMBREVILLE F., “Cross-entropic learning of a machine for the decision in a
partially observable universe”, Submitted to European Journal of Operational Research,
http://fr.arxiv.org/abs/math.OC/0605498, 2006.
[DEG 61]
DE GUENIN J., “Optimum distribution of effort: an extension of the Koopman
theory”, Operations Research, 1961.

Probabilistic Modeling of Policies
167
[DEB 03]
DE BOER P.T., KROESE D.P., MANNOR S. and RUBINSTEIN R.Y., “A tutorial on
the cross-entropy method”, Technique et Science Informatiques, http://iew3.technion.ac.il/
CE/tutor.php, 2003.
[DEL 99] DELLAERT F., FOX D., BURGARD W. and THRUN S., “Monte Carlo localization
for mobile robots”, IEEE Intl. Conf. on Robotics and Automation, 1999.
[HOM 04] HOMEM-DE-MELLO T. and RUBINSTEIN R.Y., “Rare event estimation for static
models via cross-entropy and importance sampling”, http://users.iems.nwu.edu/∼tito/
list.htm, 2004.
[KOO 57] KOOPMAN B.O., “The theory of search: III. The optimum distribution of searching
effort”, Operations Research, vol. 5, pp. 613–626, 1957.
[LEC 97] LE CADRE J.-P. and TREMOIS O., “The matrix dynamic programming property
and its implications”, SIAM Journal on Matrix Analysis, vol. 18, no. 2, pp. 818–826, 1997.
[MAR 04] MARGOLIN L., “On the convergence of the cross-entropy method”, Annals of
Operations Research, 2004.
[PAR 02] PARIS S. and LE CADRE J.-P., “Planning for terrain-aided navigation”, Conference
Fusion 2002, Annapolis, USA, pp. 1007–1014, 2002.
[RUB 04] RUBINSTEIN R. and KROESE D.P., The Cross-Entropy method. An uniﬁed
approach to Combinatorial Optimization, Monte-Carlo Simulation, and Machine Learning,
Springer, information science & statistics edition, 2004.
[SON 71] SONDIK E.J., The optimal control of partially observable Markov processes, PhD
Thesis, Stanford University, Stanford, California, 1971.
[TIC 98] TICHAVSKY P., MURAVCHIK C. and NEHORAI A., “Posterior Cramer-Rao bounds
for discrete-time nonlinear ﬁltering”, IEEE Transactions on Signal Processing, vol. 46,
no. 5, pp. 1386–1396, 1998.
[VAN 68] VAN TREES H.L., Detection, Estimation and Modulation Theory, Wiley, New York,
1968.

Chapter 7
Optimizing Emissions for Tracking
and Pursuit of Mobile Targets
7.1. Introduction
Increasingly intricate problems and a variety of available sensors based on quite
different physical principles have led to the increasing necessity of optimizing the
usage of resources. It is assumed here that the sensors are collocated but differ in
their essential characteristics such as the type of observations, detection performance,
geographical coverage and the cost of usage. This chapter only deals with tracking
problems.
The problems addressed here are rather simply formalized. The system has
passive as well as active measurements. Passive measurements do not include the
estimation of the target’s complete state and typically are limited to the estimation
of the target’s direction (if partially observed). Passive measurements thus imply
(1D) non-linear functions with a noisy state. On the other hand, the system is able to
emit (active measurements). These measurements provide a direct estimation of the
distance to the target, but generate cost. This cost is limited by a global budget. The
global budget covers different factors such as the surveillance capacity of the entire
system, risks, etc. Several practical examples could illustrate this type of problem.
For example, an aeroplane used for maritime patrol has active and passive sensors in
order to accomplish its mission. Passive sensors are, for example, electronic support
measurements (ESM) and an active sensor is, for example, radar. In order to maintain
discretion, the emissions rely on the “less is more” concept. There are even sonar
Chapter written by Jean-Pierre LE CADRE.
Optimization in Signal and Image Processing 
Edited by Patrick Siarry 
Copyright 0 
2009, ISTE Ltd 

170
Optimization in Signal and Image Processing
systems which combine active and passive features of systems such as radar or
infrared (IR).
Optimal measurement scheduling is thus an important tool which has been used
for many different approaches. Mehra [MEH 76] has investigated different norms of
the Fischer matrix. Van Keuk et al. [VAN 93] have also examined this problem in
terms of optimizing the distribution of resources for maximizing the maintenance of
existing radars tacks. Avitzour and Rogers [AVI 90] have worked on an important
extension of this problem. They tried to optimize the distribution of active measures
when estimating a random variable x, given that 1) the global budget has been
ﬁxed, 2) the cost for each (active) measurement is proportional to the reduction of
variances for ˆy and 3) the function of autocorrelation for the quantity to be measured
{x(i) : i = 1, . . . , N}, as well as the correlations between {x(i) : i = 1, . . . , N} and
y, are known. These results were then used by Shakeri et al. [SHA 95] for a discrete
time and vector-based system. However, note that the general framework for the
analysis is linear here.
In the case analyzed in this chapter, however, the framework is non-linear. After
a general presentation of the problem (section 7.2), general tools necessary for the
analysis are presented in section 7.2. It is possible to examine the general formulation
for the optimal distribution of active measures. This is, ﬁrst of all, done for the
deterministic case (section 7.3) and then for the stochastic case (section 7.4).
7.2. Elementary modeling of the problem (deterministic case)
For this deterministic case, the trajectory of the target is assumed to be
deterministic. First, a measurement of the estimability of the target trajectory
parameters is introduced. Then, tools based on multi-linear algebra are deﬁned for
approximating this measure. These tools are basic enough to drastically simplify the
problems of optimization related to the optimal measurement scheduling.
7.2.1. Estimability measurement of the problem
Our study is ﬁrst limited to rectilinear and uniform movement. The equation which
describes the movement is deﬁned below [NAR 81]:
r(t) = r(0) + tv(0) −
 t
0
(t −τ)a0(τ)dτ
[7.1]
where:
– the reference time is 0;
– r and v are the (relative) vector position and vector speed of the target;
– a0 represents the maneuver of the observer.

Optimizing Emissions
171
For passive sensors, the measurements are frequently angular bearings, deﬁned by
the following equation:
β(t) = tan−1 
rx(t)/ry(t)

.
[7.2]
For active measures (e.g. radar, active sonar), the distance r(t) is also provided:
r(t) =

r2
x(t) + r2
y(t)
1/2.
[7.3]
The passive measurements ˆβk are available at all times (and are not cost intensive).
Active measurements ˆrk on the other hand are only available during emission. For
every active measurement there is a cost ck, which depends on the operational context.
The noises wβ,k (passive measures) and wr,k (active measures) are modeled by a
Gaussian white noise. Associated variances σ2 depend on the position of the target
relative to the system and the level of emissions.
Figure 7.1. The target-observer scenario: rx and ry are Cartesian coordinates.
Dotted line: trajectory of the observer; straight line: trajectory of the target

172
Optimization in Signal and Image Processing
Fischer information matrix
When estimating a deterministic parameter θ, the variance of the errors is bounded
by the Cramér-Rao bound:
E(ˆθ −θ) ≥E
1∂ln p(Z | θ)
∂θ
2
2

= −E
1∂2 ln p(Z | θ)
∂θ2
2
.
[7.4]
In the case of vector based parameters Θ, this inequality is replaced by a
matrix-based inequality:
E(ˆΘ −Θ) ⪰E
1∂ln p(Z | Θ)
∂Θ
23
∂ln p(Z | Θ)
∂Θ
T 4
= −E
3
∂2 ln p(Z | θ)
∂θiθj
242
.
[7.5]
The matrix E
'5
∂ln p(Z|Θ)
∂Θ
65
∂ln p(Z|Θ)
∂Θ
T 6(
is based on the dyadic product of the
gradient vectors. This matrix is semi-deﬁned and positive. It represents the average
curvature of the likelihood on Θ. In the following, this matrix will be referred to as
the Fischer information matrix (FIM).
The vectors ∇Θ ln p(Z
|
Θ) are calculated for Θ, which are the target’s
parameters (or states). Here Θ = (rx, ry, vx, vy)T and vector Z represent the
observation vectors (active and/or passive). Elementary calculations provide the
vectors Mk or Nk, which are instrumental for computing the FIM. These vectors
are gradient vectors of observations equations: {βk} for passive and {rk} for active
cases, relatively to the state of the target:
⎧
⎪
⎨
⎪
⎩
Mk = 1
rk

cos βk, −sin βk, k cos βk, −k sin βk
T ,
Nk =

sin βk, cos βk, k sin βk, k cos βk
T .
[7.6]
Note that the two vectors are orthogonal. Given that angular measurements and
distance are independent of one another, the calculation of the FIM is a standard
operation.
FIM =

k
" 1
σ2
β,k
MkMT
k + δr,k
σ2
r,k
NkNT
k
#
.
[7.7]
In [7.7], δr,k equals 1 in case of active measurements at time k, and 0 otherwise.

Optimizing Emissions
173
In this context the “measurements” of estimability might be a function based on
the FIM. The determinant which represents the volume of uncertainty associated with
state X is a possible measurement of this estimability. The difﬁculty is largely based
on the fact that our objective is global optimization. The sequence of controls (time
steps when emission takes place) that optimizes the global cost has to be found.
Unfortunately, it was proved [LEC 97] that the only functions based on the FIM, that
allow a dynamic programming approach, are nearly linear functions, i.e. functions
that can be expressed as linear functions by a simple, real and monotonous function.1
However, such functions are useless, since the trace of the information matrix is
trivially computed (see equation [7.7]) and not informative. As a consequence, the
calculation of the function to be optimized has to undergo as much mathematical
development as possible.
7.2.2. Framework for computing exterior products
First at all, exterior products are introduced into the vector space V. Let V be
an n-dimensional vector space on R so that Λ2V is made of all formal summations

i αi(Ui∧Vj). For these summations, the symbol U∧V is a bilinear and alternative
function. This implies that the exterior product can only be deﬁned by the following
rules:
⎧
⎪
⎪
⎨
⎪
⎪
⎩

α1U1 + α2U2

∧V −α1

U1 ∧V

−α2

U2 ∧V

= 0,
U ∧

β1V1 + β2V2

−β1

U ∧V1

−β2

U ∧V2

= 0,
U ∧U = 0 and: U ∧V + V ∧U = 0.
[7.8]
It has been proven that the space Λ2V , deﬁned below, is a vector space on R, with
basis:

Ui ∧Uj

1 ≤i < j ≤n,
[7.9]
where {U1, U2, . . . , Un} is a basis V. Then, it is deduced that dim Λ2V = n(n−1)
2
=
n
2

. More generally, ΛpV (2 ≤p ≤n) can be created on the same principle. This
space is made up out of all formal calculations (p-vectors):

α

U1 ∧U2 · · · ∧Up

,
[7.10]
with the rules below:
⎧
⎪
⎪
⎨
⎪
⎪
⎩

α1U1
1+α2U2
1

∧U2 · · · ∧Up =α1

U1
1 ∧· · · ∧Up

+α2

U2
1 ∧· · · ∧Up

,
U1 ∧U2 ∧Up = 0 if: ∃(i, j) such that: i ̸= j and: Ui = Uj,
U1 ∧· · · ∧Up changes its sign when two Ui are interchanged.
1. This result is important for this problem. An overview of this result is given in the Appendix
(section 7.6).

174
Optimization in Signal and Image Processing
In a similar way, it is easy to prove that if {U1, U2, . . . , Un} is a basis of V, then
{Ui1 ∧Ui2 ∧· · · ∧Uip} (1 ≤i1 < i2 · · · < ip ≤n) is a basis for the vector space
ΛpV of dimension
n
p

. Note that dim(ΛnV) = 1. The determinants are linked to the
exterior product in the following way. If A is a linear application of V, the associated
mapping gA from Vn to ΛnV is deﬁned as follows:
gA

U1, . . . , Un

≜A

U1

∧· · · ∧A

Un

.
[7.11]
Furthermore, since gA is deﬁned by equation [7.11] and is multi-linear and
alternative, there is a linear function fA (ΛnV →ΛnV) that meets the following rule:
gA

U1, . . . , Un

= fa

U1 ∧· · · Un

.
However, dim(ΛnV)
=
1, so that this linear application is just a scalar
multiplication by det(A). As a consequence,
A

U1

∧· · · A

Un

= det(A)

U1 ∧· · · Un

.
[7.12]
It is therefore easy to prove that there is a natural deﬁnition of the exterior
multiplication (also referred to as wedge product) such that ΛpV ∧ΛqV = Λp+qV.
This exterior multiplication is simply deﬁned by:

U1 ∧· · · ∧Up

∧

V1 ∧· · · ∧Vp

= U1 ∧· · · ∧Up ∧V1 ∧· · · ∧Vp.
[7.13]
The basic properties of the exterior product are as follows:
(1) u ∧v is distributive

u ∈Λp(V), v ∈Λq(V)

,
(2) u ∧

v ∧w

=

u ∧v

∧w associative,
(3) v ∧u = (−1)pqu ∧v alternated.
[7.14]
All these results are very basic and are widely used in this chapter. The
formalism has the advantage of making the calculations simpler. The Binet-Cauchy
formula is constantly used in order to obtain explicit formulae. More precisely, let
{U1, . . . , UN} be a set of N vectors of V (N ≥n). Then
det
5
U1, . . . , UN

⊗

U1, . . . , UN
T 6
=

1≤i1<i2<···<in≤T

det

Ui1, Ui2, . . . , Uin
2.
[7.15]
Consequently, it is sufﬁcient to use an explicit description for the determinants
det(Ui1, Ui2, . . . , Uin) in order to obtain an explicit expression for the determinant
of det[(U1, . . . , UN) ⊗(U1, . . . , UN)T ].

Optimizing Emissions
175
7.3. Application to the optimization of emissions (deterministic case)
Now the formalism, which has previously been established, will be used to
analyze the effect of distributing active measurements in the case of the deterministic
target. First of all, this is done on the basis of a uniform and rectilinear movement.
The deterministic case has the advantage of being simple enough to obtain explicit
and signiﬁcant results. If the observer does not carry out any maneuvers, the passive
problem of trajectories cannot be observed. If, however, multiple modalities are
observed (e.g. active and passive measurements) it is also possible to observe
problems [TRE 96]. In the case of multimodal measurements (active and passive)
the scalar observation z(t) is replaced by a vector-based form of observation
z(t) = (z1(t), z2(t))T . The statistical structure of the problem, however, remains
unchanged. Passive measurements are available at all times (at zero cost) while
active measurements are relatively rare and of a high cost. Given the constraints of a
budget, optimizing the distribution of active measurements makes sense. Note that
the matrices M and N consist of gradient vectors associated with passive or active
measurements.
det(FIM) = c(k) det

MMT + NN T 
,
= c(k) det
1
(M, N)
"
MT
N T
# 2
.
[7.16]
Matrices M and N are calculated on the basis of all gradient vectors (column
vectors) (see equation [7.6]), i.e.
⎧
⎨
⎩
M =

M0, . . . , Mk, . . . , MT −1

, k = 1 −→T −1,
N =

N0, Nj1, . . . , Nj#a−1

,
[7.17]
where M and N are the gradients associated with passive or active measurements.
This modelization corresponds to active emissions at the following points in time
{0, j1, . . . , j#a−1} ∈{0, . . . , T −1}. In this context, the matrices M and N are 4×T
and 4 × (#a) respectively. Despite each elementary FIM being deﬁned in equation
[7.16] being 4 × 4, a direct calculation of its determinant cannot be established if a
direct approach is used. To avoid this problem the Binet-Cauchy formula can be used.
Note that {i1, . . . , ik} is a (temporary)2 multi-index. According to the Binet-Cauchy
formula (see equation [7.15]) the following applies:
2. ik (resp. jl) are the indexes of measures associated with passive or active measures. It is
assumed the order k < l ⇒ik < il.

176
Optimization in Signal and Image Processing
det(FIM) =

i1,i2;j1,j2

Mi1 ∧Mi2

∧

Nj1 ∧Nj2
2
+

i1;j1,j2,j3

Mi1

∧

Nj1 ∧Nj2 ∧Nj3
2,
+

i1,i2,i3;j1

Mi1 ∧Mi2 ∧Mi3

∧

Nj1
2 + other terms.
[7.18]
The “other terms” correspond to the terms: 
i1,i2,i3,i4[Mi1 ∧Mi2 ∧Mi3 ∧Mi4]2
and 
i1,i2,i3,i4[Ni1 ∧Ni2 ∧Ni3 ∧Ni4]2.
These two terms correspond to the zero determinants (bearings only or distances
only) and associated problems cannot be observed. Calculating terms of the type
(Mi1 ∧Mi2) ∧(Nj1 ∧Nj2)3 can easily be carried out with the properties of exterior
algebra. This is why exterior algebra is dealt with by Λ2R4. The space of dimensions
is
4
2

. If e1, . . . , e4 is the canonical basis of R4 then the basis of Λ2R4 is

e1 ∧e2, e1 ∧e3, e1 ∧e4, e2 ∧e4, e2 ∧e3, e3 ∧e4

,
denote by {α1, . . . , α6} and {γ1, . . . , γ6} the components of Nj1 ∧Nj2 and
Mi1 ∧Mi2 in the canonical basis Λ2R4. The elementary properties of multi-linearity
therefore imply:

rσrσβ
2
Nj1 ∧Nj2 ∧Mi1 ∧Mi2

= α1γ6 −α2γ4 + α3γ5 −α4γ2 + α5γ3.
[7.19]
Without lost of generality, Nj1 corresponds to active measurements carried out
at time 0 (associated bearing: β0) while Nj2 is associated with active measurements
carried out at τ (0 < τ ≤(T −1)) with the associated bearing of β0 + δ (δ = τ ˙β).
Furthermore, the gradient vectors M1 and M2 correspond to purely passive
measurements associated in the times t and t′ (associated bearing βt and βt′). This
leads to:
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎩
σrNj1 =

sin β0, cos β0, 0, 0
T ,
σrNj2 =

sin

β0 + δ

, cos

β0 + δ

, τ sin

β0 + δ

, τ cos

β0 + δ
T ,
rσβMi1 =

cos βt, −sin βt, t cos βt, −t sin βt
T ,
rσβMi2 =

cos βt′, −sin βt′, t′ cos βt′, −t′ sin βt′T .
[7.20]
3. Also equal to det(Mi1, Mi2, Nj1, Nj2).

Optimizing Emissions
177
Now the components of Nj1∧Nj2 (written as: α1, . . . , α6) and Mi1∧Mi2 (written
as: γ1, . . . , γ6) are computed in the canonical basis of Λ2R4. Basic derivations lead to
the following inequalities:
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎩
α1 = −sin δ
γ1 = −cos βt sin βt′ + sin βt cos βt′,
α2 = τ sin β0 sin

β0 + δ

γ2 = (t′ −t) cos βt cos βt′,
α3 = τ sin β0 cos

β0 + δ

γ3 = t cos βt′ sin βt −t′ sin βt′ cos βt,
α4 = τ cos β0 cos

β0 + δ

γ4 = (t′ −t) sin βt sin βt′,
α5 = τ cos β0 sin

β0 + δ

γ5 = t cos βt sin βt′ −t′ sin βt cos βt′,
α6 = 0
γ6 = tt′
cos βt′ sin βt −sin βt′ cos βt

.
[7.21]
so that:
det(FIM) =
1
r4σ4rσ4
β

α1γ6 −α2γ4 + α3γ5 −α4γ2 + α5γ3

.
Until now the calculations have been exact. Adequate estimations will now be
considered. Through a regressive linear approximation of the bearing (i.e. δ = τ ˙β,
βt = β0 + t ˙β and βt′ = β0 + t′ ˙β) the following estimation is deducted from
det(FIMτ,2β,2r):
PROPOSITION 7.1. Let det(FIMτ,T,β,r) be the determinant of the FIM, which
is associated with two active measurements (separated from τ) and T passive
measurements (bearing). Then:
det

FIMτ,T

≃
τ 2

rσrσβ
4

0≤t<t′≤T
(t −t′)2
2 −˙β2(t′ + t −τ)22.
[7.22]
For a general case the Binet-Cauchy theorem ensures that it is sufﬁcient to consider
the following cases:
– 1 active measurement, T passive measurements;
– 2 active measurement, T passive measurements;
– 3 active measurement, T passive measurements.
For three active measurements the following result is obtained:
PROPOSITION 7.2. Let three active measurements (at 0, τ1 and τ2) be given, as well
as T passive measurements. Then:
det

FIMτ1,τ2,T

≃
T
r2σ2
βσ6r

0<τ1<τ2≤T

τ1τ2

τ1 −τ2
 ˙β
2.
[7.23]

178
Optimization in Signal and Image Processing
Proof. The active measurements are considered in Λ3R4 (canonical basis: {e1 ∧e2 ∧
e3, e1 ∧e2 ∧e4, e1 ∧e3 ∧e4, e2 ∧e3 ∧e4}). The gradient vectors N0, Nj1 and
Nj2, are associated with the emissions. Denote {ai}4
i=1, {bi}4
i=1 and {ci}4
i=1 their
components in this (canonical) basis. Then:
σ3
rN0 ∧Nj1 ∧Nj2 = α1

e1 ∧e2 ∧e3

+ α2

e1 ∧e2 ∧e4

+ α3

e1 ∧e3 ∧e4

+ α4

e2 ∧e3 ∧e4

,
[7.24]
where
⎧
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎩
α1 = a1b2c3 −a1b3c2 −a2b1c3 + a2b3c1,
α2 = a1b2c4 −a2b1c4 −a1b4c2 + a2b4c1,
α3 = a1b3c4 −a1b4c3,
α4 = a2b3c4 −a2b4c3.
The passive measurements are represented by vector Mt =
1
rσβ (cos βte1 −
sin βte2 + t cos βte3 −t sin βte4) where

rσβσ3
r

N0 ∧Nj1 ∧Nj2 ∧M4

= −α1t sin βt −α2t cos βt −α3 sin βt −α4 cos βt.
[7.25]
The proof of equation [7.23] is achieved by using the linear approximation βt ≜
β0 + t ˙β.
Now, let us consider the case of a unique active measurement. The following result
is obtained.
PROPOSITION 7.3. It is assumed that there is only one active measurement and T
passive measurements. Then:
det(FIM)T ≃
1
r6σ2rσ6
β

0≤t1<t2<t3≤T

t3 −t1

t2 −t1

t3 −t2
 ˙β
2.
[7.26]
Proof. The gradient vectors for three passive measurements are written Mt1, Mt2 and
Mt3 while the only emission takes place at 0. Then N0 = sin(β0)e1 + cos(β0)e2,
which implies that it is sufﬁcient to compute the components (denoted α2 and α1) of
the vector Mt1 ∧Mt2 ∧Mt3 in the basis e1∧e3∧e4 and e2∧e3∧e4. The computation
leads to:

α1 = −t1t2 sin βt2 cos βt1 cos βt3 + t3t1 sin βt3 cos βt1 cos βt2,
α2 = t1t2 sin βt2 cos βt1 sin βt3 −t3t1 sin βt3 cos βt1 sin βt2,
[7.27]
so that det(N0, Mt1, Mt2, Mt3) = −α1 cos β0 + α2 sin β0.

Optimizing Emissions
179
Here it makes sense to recall the deﬁnition of ˙β, i.e. ˙β =
 v
r

sin θ, where θ is
the angle between r and v, which represent the position and the speed (∥v∥= v,
∥r∥= r). Now a summary of all results mentioned above is given.
active measures
det(FIM)
simpliﬁed form
1 mes. (à 0)
1
r6σ2rσ6
β

0≤t1<t2<t3≤T

t3 −t1

t2 −t1

t3 −t2
 ˙β
2
1
r6σ2rσ6
β
˙β2P1(T)
2 mes. (à 0 and τ)
τ 2

rσrσβ
4

0≤t<t′≤T
(t −t′)2
2 −˙β2(t′ + t −τ)22
3 mes. (0, τ1, τ2)
T
r2σ2
βσ6r

0<τ1<τ2≤T

τ1τ2

τ1 −τ2
 ˙β
2
Any number of active measurements is available now. These measurements belong
to the discrete group E, with a ﬁxed cardinal number (Card(E) = N) and their index
is the time. Due to the Binet-Cauchy formula and previous results, it is now possible
to provide a general expression of the determinants for the FIM.
PROPOSITION 7.4. Assume active measurements belonging to the set E (Card(E) =
N) and T passive measurements. Denote FIME the related FIM. Then:
det(FIM)E = N · det(FIM)T +

τ∈E
det

FIMτ,T

+

τ1,τ2∈E
det

FIMτ1,τ2,T

, [7.28]
where det(FIM)T , det(FIMτ,T ) and det(FIMτ1,τ2,T ) are determined by equations
[7.26], [7.22] and [7.23].
Now, let us consider the same number of active and passive measurements. A direct
calculation of det(FIM) is impossible due to the high number of sub-cases. However,
Proposition 7.4 leads to the following result.
PROPOSITION 7.5. The same number of active and passive measurements is available
(that is T). Then:
det

FIMT,T

∝T 16
"
1
r4σ4
βσ4r
+
4 ˙β2
r2σ2
βσ6r
+
4 ˙β2
r6σ6
βσ2r
#
.
[7.29]
Previous results have been used in the analysis of information gain induced by
active measurements. This gain of information is quite high. In order to verify this
statement, it is sufﬁcient to take a look at the respective vectors Mi (passive) and
Ni (active). These vectors are orthogonal and det(FIM) is the parallelotope volume

180
Optimization in Signal and Image Processing
generated by these vectors. This volume is considerably increased by the inclusion of
orthogonal vectors.
Optimizing the distribution of measurements requires additional considerations.
The results that have been obtained above provide explicit expressions which are
functions of essential parameters. Then, it is easy to prove that the term det(FIMτ,T ) is
generally predominant in the global expression (see Binet-Cauchy) of det(FIM). This
is due to the following fact: the spaces generated by the gradient vectors (M1, M2)
and (N1, N2) are (approximately) orthogonal sub-spaces of same dimension.
Distance r is assumed to be constant, as well as σβ and σr. In this case, ﬁnding the
best possible distribution is equivalent to the problem:
PROBLEM 7.1. Determine τ by maximizing:
τ 2

0≤t<t′≤T
(t −t′)2
1 + ˙β2
−tt′ + τ(t + t′)
2.
In general, ˙β is an available parameter (on the basis of passive measurements). It is
therefore possible to replace ˙β with an estimate. Now, apart from very long scenarios,
the term ˙β2(−t t′ + τ(t + t′)) is found to be less than 1. The optimization problem
is therefore simpliﬁed and can be reduced to τ 2 
0≤t<t′≤T (t −t′)2. The general
conclusion is that det(FIMτ,T ) (as well as det(FIM)) reaches its maximum when τ
reaches its maximum. The best possible distribution of measurements comes down to
concentrating the active measurements around two suprema (beginning and end). This
conclusion is, of course, valid for a deterministic mobile target.
Also note that the hypotheses have been simpliﬁed (σβ, σr, r are constant).
However, the previous results are easily extended when the parameters (i.e. σβ, σr, r)
vary over the course of time.
7.3.1. The case of a maneuvering target
A mobile target is now considered, whose trajectory contains two legs. Then the
state vector of the target, X, is of dimension 6 (X=(rx,0, ry,0, vx,1, vy,1, vx,2, vy,2)T ).
If the time of maneuver is known (tm), the gradient vector takes the following form:
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
rtσb∇Xβt =

cos βt, −sin βt, t cos βt, −t sin βt, 0, 0
T ,
for t ≤tm,
rtσb∇Xβt =

cos βt, −sin βt, tm cos βt, −tm sin βt,

t −tm

cos βt, −

t −tm

sin βt
T ,
for t > tm.
[7.30]

Optimizing Emissions
181
There is a similar formula for active measurements. Now, let us consider the
maximization of the parallelotope hull of the ellipsoid of uncertainty. It is possible
to prove that the predominant term in det(FIM) is associated with exterior products
(M1 ∧M2 ∧M3) ∧(N1 ∧N2 ∧N3) (Mi →passive measurements Ni →active
measurements). Let (t1, t2), (t3, t4) and (t5, t6) be respectively the time associated
with (M1, N1), (M2, N2) and (M3, N3). Then:
det(FIM) ≈c

t1,...,t6

t1 −t2

t3 −t4

t5 −t6
2/
2 t2 cos

2β0

−2

t2−2tm+t2 sin 2β0

, −2 t2 ˙β

t2−t1+

t1+t2

cos 2β0+sin 2β0

,
+ ˙β2
t1 −t2
2
t2 −2 tm

−t2

t1 + t2
2
cos 2β0 −sin 2β0

,
−

t3 + t4 −t5 −t6
2
−t2 + 2 tm + t2

cos 2β0 −sin 2β0
02
.
At ﬁrst glance this formula seems to be complex and inapplicable. However, it
is easy to prove that the term which is predominant inside the {
} in the previous
equation is simply 2 t2 cos(2β0−2(t2−2tm+t2 sin 2β0)). Again, optimal distribution
of measurements is focused on active measurements around the suprema of the legs.
Let us now take a look at the general case of a trajectory which disposes of many legs
(legs of identical length, expressed as j). The FIM takes the following form:
FIM1,nj = FIM1,j + · · · + FIM(n−1)j,nj,
=
n

m=1
mj

(m−1)j+1

dm−1,n+1(k) dT
m−1,n+1(k)

⊗Ωk,
where
dT
p,q(k) =

1, j, . . . , j, (k −pj), 0, . . . , 0

,
Ωk =

cos2 βk
cos βk sin βk
−cos βk sin βk
cos2 βk

.
The previous analysis thus applies to the general case.
7.4. The case of a target with a Markov trajectory
When it comes to problems in the ﬁeld of tracking, a diffusion model is preferred,
which extends the deterministic model. This model is deﬁned as shown below
(Cartesian coordinates):

182
Optimization in Signal and Image Processing

Xt+1 = AXt + HUt + σVt,
for which: Vt ∼N(0, Q),
A = Id4 + δtB
with: B =
1
0
1
0
0
2
⊗Id2,
HUt: commands,
Q = Σ ⊗Id2
with Σ =
1α3
α2
α2
α1
2
,
observations: Zt = arctan
"rx(t)
ry(t)
#
+ Wt.
[7.31]
The term of diffusion is represented by a noise (here σVt) which expresses
the uncertainty of future evolutions of the target. Even if Cartesian models plays
an important role, another type of parameter is useful, i.e. the one introduced by
Hammel and Aidala [HAM 85], the MPC (modiﬁed polar coordinates).
1
βt
˙βt
˙rt
rt
1
rt
2T
.
[7.32]
This coordinate system is signiﬁcant since it separates the observable information
(

βt
˙βt
˙rt
rt
T ) from the unobservable information ( 1
rt ). A system with slightly
modiﬁed coordinates (called LPC4) was introduced by [BRE 06], and is deﬁned as
follows:
Yt =
1
βt
ln rt
˙βt
˙rt
rt
2T
.
[7.33]
This system has the signiﬁcant advantage that it calculates the FIM exactly. There
are bijective transformations that move Cartesian coordinates to LPC and vice versa
[BRE 06]. In the system of LPC coordinates the state equation is no longer linear and
has to be deducted from equation [7.31], i.e.:
Yt+1 =
⎧
⎨
⎩
f lp
c

Af c
lp(Yt) + HUt + σWt

if ry(t) > 0,
f lp
c

−Af c
lp(Yt) + HUt + σWt

if ry(t) < 0.
Zt = βt + Vt.
[7.34]
Now the notions of estimate lower bound (and FIM) are deﬁned for a Bayesian
problem. This means that there is a prior uncertainty for the state to be estimated.
4. Logarithmic polar coordinates.

Optimizing Emissions
183
DEFINITION 7.1 (FIM). The problem of ﬁltering deﬁned previously, based on FIM
(FIM), is denoted Jt and expressed by:
Jt = E

∇Yt ln p

Z1:t, Y0:t

∇T
Yt ln p

Z1:t, Y0:t

,
[7.35]
where p(Z1:t, Y0:t) is the density related to the sequence of observations Z1:t as well
as the sequence of state Y0:t. This leads to EQMt ≽J−1
t
.
EQMt ≜E
 ˆY0:t

Z1,t

−Y0:t
2
Actually, the extension of FIM to the Bayesian case (random state) is obtained by
means of an elementary lemma of matrix calculus summarized below.
LEMMA 7.1 (Cauchy-Schwarz matrix). Let S be a block matrix that has been
partitioned as follows:
S =
1 A
C
CT
B
2
,
(A, B ⪰0)
Then: S ⪰0 implies (A −CB−1CT ) ⪰0.
Furthermore, for a vector of parameter Φ, it is obtained (integration by parts):
E
"∂2
ln

p(Z, Φ)

∂θi∂θj
#
i,j

= −E

∇Φ ln p(Z, Φ)∇T
Φ ln p(Z, Φ)

,
[7.36]
and:
LEMMA 7.2 (C = Id).
FIM =
⎡
⎢⎢⎢⎢⎢⎢⎣
E
/:Φ(Z) −Φ
:Φ(Z) −Φ
T 0
;
<=
>
A
E
/:Φ(Z) −Φ

∇T
Φ

ln p(Z, Φ)
0
;
<=
>
C
E
/
∇Φ

ln p(Z, Φ)
:Φ(Z) −Φ
T 0
;
<=
>
CT
E
/
∇Φ

ln p(Y, Φ)

∇T
Φ

ln p(Z, Φ)
0
;
<=
>
B=J(Z,Φ)
⎤
⎥⎥⎥⎥⎥⎥⎦
[7.37]
Then, under reasonable hypothesis, C = Id.
Non-linear generic systems, e.g.

Xt = Ft

Xt−1, Vt

,
Zt = Ht

Xt, Wt

,

184
Optimization in Signal and Image Processing
will be analyzed now. It happens that the FIM Jt is of increasing size (i.e. 4 × t).
A direct approach is impossible as soon as t reaches reasonable values in terms of
tracking. The essential idea of Tichavsky et al. was the usage of structures separated
into blocks of matrices associated with the FIM.
LEMMA 7.3. p(X0:t+1, Z0:t+1) = pt p(Xt+1 | Xt)p(Zt+1 | Xt+1), and therefore:
J

Φ0:t+1

=
⎡
⎢⎢⎢⎣
JΦ0:t−1
Φ0:t−1

pt+1

JΦt
Φ0:t−1

pt+1

JΦt+1
Φ0:t−1

pt+1

JΦ0:t−1
Φt

pt+1

JΦt
Φt

pt+1

JΦt+1
Φt

pt+1

JΦ0:t−1
Φt+1

pt+1

JΦt
Φt+1

pt+1

JΦt+1
Φt+1

pt+1

⎤
⎥⎥⎥⎦
[7.38]
The following relations between the fundamental structures of J(Φ0:t+1) and
J(Φ0:t) are very important.
J

Φ0:t

=
3
At
Bt
BT
t
Ct
4
and
J

Φ0:t+1

=
⎡
⎢⎣
At
Bt
0
BT
t
Ct + D11
t
D12
t
0
D21
t
D22
t
⎤
⎥⎦
[7.39]
Now J−1
Φt+1 is the lower block of J−1(Φ0:t+1). Using twice the lemma of matrix
inversion on a matrix that has been subdivided into blocks, the following result is
obtained:
J−1
Φt+1 = D22
t −
0
D21
t

3
At
Bt
BT
t
Ct + D11
t
4−1 3
0
D12
t
4
= D22
t −D21
t

Ct + D11
t −BT
t A−1
t Bt
−1D12
t ,
= D22
t −D21
t

J−1
Φt + D11
t
−1D12
t .
[7.40]
The following proposition is fundamental for the FIM.
PROPOSITION 7.6 (formula by Tichavský et al.). For a ﬁltering problem, the right
bottom block of the FIM, denoted J−1
t
, is subject to the following recursive formula:
J−1
t+1 = D22
t + D33
t −D21
t

J−1
t
+ D11
t
−1D12
t ,
[7.41]

Optimizing Emissions
185
where D11
t , D12
t , D21
t , D22
t , D33
t
are matrices deﬁned by:
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎩
D11
t
= E

∇Yt ln p

Yt+1 | Yt

∇T
Yt ln p

Yt+1 | Yt

,
D21
t
= E

∇Yt+1 ln p

Yt+1 | Yt

∇T
Yt ln p

Yt+1 | Yt

,
D12
t
= E

∇Yt ln p

Yt+1 | Yt

∇T
Yt+1 ln p

Yt+1 | Yt

,
D22
t
= E

∇Yt+1 ln p

Yt+1 | Yt

∇T
Yt+1 ln p

Yt+1 | Yt

,
D33
t
= E

∇Yt+1 ln p

Zt+1 | Yt+1

∇T
Yt+1 ln p

Zt+1 | Yt+1

.
When it comes to applying the above recursive formula, the matrices Dij
t , of
course, still have to be calculated or estimated. This is usually done with the help
of simulation methods. The trajectories of the target are simulated on the basis of a
distribution equation as well as the corresponding observations. This simulation comes
at a relatively high cost. However, it has been shown that it is possible to obtain explicit
expression of matrix Dij
t in accordance with the following table.
Cartesian
MDP
LPC
D11
t
yes
no
yes
D12
t
yes
no
yes
D21
t
yes
no
yes
D22
t
yes
no
yes
D33
t
no
yes
yes
Table 7.1. Data used for explicit expression of matrix Dij
t
At this point of the chapter there will be a brief explanation of the reasons why
the LPC system is a system of coordinates which expresses the matrices Dij
t . All
calculations are relatively long and only an overview will be provided in this chapter.
Please see the original article for more detail [BRE 06].
PROPOSITION 7.7 (fundamental property [BRE 06]). In the LPC system, the gradients
∇Yt ln p(Xt+1 | Xt) and ∇Yt+1 ln p(Xt+1 | Xt) only rely on quadratic forms of the
variables Xt, Xt+1. This leads to:
⎧
⎨
⎩
∇T
Yt ln p

Xt+1 | Xt

=

Xt+1−AXt−HUt
T Q−1A∇Yt

Xt

,
∇T
Yt+1 ln p

Xt+1 | Xt

=

Xt+1−AXt−HUt
T Q−1∇Yt+1

Xt+1

,
[7.42]

186
Optimization in Signal and Image Processing
and
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎩
∇Yt{Xt} =
⎡
⎢⎢⎢⎢⎣
ry(t)
−rx(t)
0
0
rx(t)
ry(t)
0
0
vy(t)
−vx(t)
ry(t)
−rx(t)
vx(t)
vy(t)
rx(t)
ry(t)
⎤
⎥⎥⎥⎥⎦
,
∇Yt+1{Xt+1} =
⎡
⎢⎢⎢⎢⎣
ry(t + 1)
−rx(t + 1)
0
0
rx(t + 1)
ry(t + 1)
0
0
vy(t + 1)
−vx(t + 1)
ry(t + 1)
−rx(t + 1)
vx(t + 1)
vy(t + 1)
rx(t + 1)
ry(t + 1)
⎤
⎥⎥⎥⎥⎦
,
[7.43]
so that ∇Yt{Xt} and ∇Yt+1{Xt+1} are linear operators on Xt, Xt+1.
On the basis of these results, [BRE 06] has shown that it is possible to obtain an
analytical formula for the terms Dij
t . Detailed information on these calculations is
available in [BRE 06]. First, it is necessary to introduce auxiliary matrices (denoted
Γt). These matrices are themselves computed recursively (temporal recursion). The
matrices Dij
t
are blocks which are extracted from Γt. The main advantage is that
simulations are no longer needed. It is therefore possible to take optimal distribution
and active measurement problems into consideration.
The following problem is now considered:
PROBLEM 7.2. Is it possible to allocate active measurements U0:t, such as:
EQMln rl < s
∀l ∈{1, . . . , T}.
PROBLEM 7.2a. Is it possible to allocate active measurements U0:t, such as:
J−1
ln rl < s
∀l ∈{1, . . . , T}.
The algorithm for optimizing the distribution of measurements is presented below.
For t = 1 to T:
1) compute ˜J−1
t
with a passive measurement at t;
2) if ˜J−1
ln rl > s, then Ut = 1 and re-compute J−1
t
if measurements are active and
passive;
3) if ˜J−1
ln rl < s, then Ut = 0 and J−1
t
= ˜J−1
t
.

Optimizing Emissions
187
Results
Here the results for a representative scenario are presented. The parameters for the
scenario are described in Table 7.2.
Parameter scenario
duration
6000 s
robs
x (0)
3, 5 km
robs
y (0)
0 km
vobs
x (0)
10 ms−1
vobs
y
(0)
−2 ms−1
rcib
x (0)
0 km
rcib
y (0)
3, 5 km
vcib
x (0)
6 ms−1
vcib
y (0)
3 ms−1
δt
6 s
σ
0.05 ms−1
σβ
0.05 rad (≃3 deg.)
σr0
2 km
σv0
1 ms−1
σβ0
0.05 rad (≃3 deg.)
Table 7.2. Parameters of the scenario
Figure 7.2 shows an example of the target trajectory. Note that this trajectory is just
a realization of the target diffusion law. The target is moving away from the observer
quite rapidly. This leads to a uniform rectilinear movement. Active measurements are
required so as to maintain the FIM criterion below a certain value. Here only the
estimation of parameter ln(rt) is required, which means that only the corresponding
term J−1
ln rt is being analyzed.
Figure 7.3 shows the results for this scenario. These results apply for the passive
mode only. PCRB depends on ln(rt) and decreases rapidly and then stabilizes at a
certain point. The horizontal line shows the values of the order and the value which
cannot be exceeded.

188
Optimization in Signal and Image Processing
Figure 7.2. Scenario: (a) example of the target trajectory (straight line)
and the observer (dotted line) (b)
Figure 7.3. Calculation of PCRB in relation to ln rt with optimized active measurements
(straight line) versus passive measurements only (dotted line)

Optimizing Emissions
189
If the limit is infringed (without activation), an active measurement is emitted.
This guideline has been respected very well (see Figure 7.3). The optimal sequencing
of emissions is shown below. In Figure 7.4 the emissions are relatively frequent at the
beginning of the scenario but become less frequent later on.
Figure 7.4. Optimal sequencing of emissions
7.5. Conclusion
Different problems related to the optimal sequencing of emissions have been
investigated in this chapter. This chapter only deals with objective functions based on
the quality of estimation (or tracking) of the target in a non-linear framework. The
main difﬁculties of emission planning have been covered by this chapter. The explicit
calculation of functional objectives has been detailed. In the case of a deterministic
target trajectory, this result is applied to the evaluation of the importance of the
impacting factors. This approach also reduces the problems to simple optimizations
and avoids the difﬁculties related to the non-convexity of the functional objectives.
For a Markovian target, the importance of a direct calculation of the functional
objective has been shown (i.e. no simulation).
7.6. Appendix: monotonous functional matrices
Function f, mapping from Sn (the vector space of symmetric matrices) towards R,
satisﬁes the monotony property of matrices (MPM) if it meets the following condition.

190
Optimization in Signal and Image Processing
DEFINITION 7.2.
– f is of the class C2,
– let A and B be two matrices of Sn, such that: f(B) > f(A); then
f(B + C) > f(A + C),
for any matrix C ∈Sn.
The dynamic programming recursion makes inequalities of the form:
min f
 
j∈S

Ci,j(d) + Fπ∗
1 (k + 1, j)

pi,j(d)

≤f
 
j∈S

Ci,j(d) + Fπ1(k + 1, j)

pi,j(d)

,
necessary, which have to be valid so that the optimal strategy π∗
1 until time k remains
optimal at time k + 1. Now the question is to characterize functions f which meet the
requirements of MPM. An answer to this question is given now.
PROPOSITION 7.8. A matrix-valued function f, which applies for MPM, veriﬁes:
f(A) = g

tr(AR)

,
where g is any real-valued and increasing function and R is a ﬁxed matrix.
Proof. Function f is of class C2 and a ﬁrst order approximation5 of f around A is
possible:
f(A + ρC)
1= f(A) + ρ tr

∇T f(A)C

+ 0(ρ),
ρ scalar.
[7.44]
In the previous formula, ∇f(A) describes the gradient of f on A. The notation
tr[∇T f(A)C] replaces the expression [POL 85, CAR 67] of the derivative of f, i.e.
DfA(C), and corresponds to:
DfA(C) = tr

∇T f(A)C

.
[7.45]
Assume now that the gradients ∇f(A) are not always collinear. There are (at least)
two matrices A and B for which the following applies ∇f(A) ̸= ∇f(B). Assume
5. The symbol
1= means a ﬁrst order approximation.

Optimizing Emissions
191
that F ⊥denotes the orthogonal subspace of F (for the scalar product of the matrix
[GRE 76]). Then:

P1


∇f(A)
⊥̸=

∇f(B)
⊥.
[7.46]
At this point matrices A and B satisfy (P1) and can be chosen mutually as close
as possible (for the Frobenius norm related to the scalar product [HOR 85]). A
consequence of (P1) is the existence of a matrix C such as:
tr

∇T f(A)C

̸= 0
and
tr

∇T f(B)C

= 0.
[7.47]
Since tr[∇T f(A)C] < 0, implies tr[∇T f(A)(−C)] > 0, it is ensured without
lost of generality that:
tr

∇T f(A)C

> 0
and
tr

∇T f(B)C

= 0.
[7.48]
Now, deﬁne the function g(ρ) by:
g(ρ) ≜f(B + ρC) −f(A + ρC),
its ﬁrst order approximation around 0 is:
g(ρ)
1= f(B) −f(A) −ρ tr

∇T f(A)C

+ 0(ρ).
[7.49]
Since function f is continuous on Sn, it is possible to deﬁne a couple (A, B) such
that:
f(B) −f(A) = ρ
2 tr

∇T f(A)C

,
as a consequence, the following applies:
f(B + ρC) −f(A + ρC)
= −ρ
2 tr

∇T f(A)C

+ 0(ρ)

tr

∇T f(A)C

> 0

.
[7.50]
The equality above implies that f does not apply for the MPM. As a consequence,
if f applies for the MPM, then all gradients are collinear and are therefore proportional
to a single vector, denoted G. Then:
∇f(A) = λ(A)G
∀A ∈Sn

λ(A) scalar

.
[7.51]

192
Optimization in Signal and Image Processing
Owing to the intermediate value theorem and the rule of derivation of composite
functions [CAR 67], the following result is obtained:
∇g

h(A)

= g′
h(A)

∇h(A),

g : R −→R, h : Sn −→R

.
[7.52]
Then f is the composition of a monotonic scalar function g with a linear form h. A
linear form deﬁned on Sn may always be written as h(A) = tr(AR), where R is any
matrix (ﬁxed and independent of A).
Conversely, it is easy to prove that f(A) = g(tr(AR)), where g is an increasing
function, veriﬁes the MPM.
7.7. Bibliography
[AVI 90] AVITZOUR D. and ROGERS S., “Optimal measurement scheduling for prediction
and estimation”, IEEE Trans. on Acoustis, Speech and Signal Processing, vol. 38, no. 10,
pp. 1733–1739, 1990.
[BAR 88] BARAM Y. and KAILATH T., “Estimability and regulability of linear systems”, IEEE
Trans. on Automatic Control, vol. 33, no. 12, pp. 1116–1121, 1988.
[BOG 88] BOGUSLAVSKIJ I.A., Filtering and Control, Optimization Software, NY, 1988.
[BRE 06] BRÉHARD T. and LE CADRE J.-P., “Closed-form posterior Cramér-Rao bounds for
bearings-only tracking”, IEEE Trans. on Aerospace and Electronic Systems, vol. 42, no. 4,
pp. 1198–1223, 2006.
[CAR 67] CARTAN H., Calcul Différentiel, Hermann, 1967.
[DAR 94] DARLING R.W.R., Differential Forms and Connections, Cambridge University
Press, Cambridge, UK, 1994.
[GRE 76] GREUB W.H., Linear Algebra, 4th edition, Springer, 1976.
[HAM 85] HAMMEL
S.E.
and
AIDALA
V.J.,
“Observability
requirements
for
three-dimensional tracking via angle measurements”, IEEE Trans. on Aerospace and
Electronic Systems, vol. 21, no. 2, pp. 200–207, 1985.
[HOR 85] HORN R.A. and JOHNSON C.R., Matrix Analysis, Cambridge University Press,
1985.
[KER 94] KERSHAW D.J. and EVANS R.J., “Optimal waveform selection for tracking
systems”, IEEE Trans. on Information Theory, vol. 40, no. 5, pp. 1536–1550, 1994.
[LEC 98] LE CADRE J.-P., “Properties of estimability criteria for target motion analysis”, IEE
Proc. Radar, Sonar & Navigation, vol. 145, no. 2, pp. 92–99, 1998.
[LEC 97] LE CADRE J.-P. and TREMOIS O., “The matrix dynamic programming property and
its implications”, SIAM Journal Matrix Anal. Appl., vol. 18, no. 4, pp. 818–826, 1997.
[MEH 76] MEHRA K.K., “Optimization of measurement schedules and sensor design for
linear dynamic systems”, IEEE Trans. on Automatic Control, vol. 21, no. 1, pp. 55–64,
1976.

Optimizing Emissions
193
[NAR 81] NARDONE S.C. and AIDALA V.J., “Observability criteria for bearings-only target
motion analysis”, IEEE Trans. on Aerospace and Electronic Systems, vol. 17, no. 2,
pp. 162–166, 1981.
[NAR 84] NARDONE S.C., LINDGREN A.G. and GONG K.F., “Fundamental properties and
performance of conventional bearings-only target motion analysis”, IEEE Trans. on
Automatic Control, vol. 29, no. 9, pp. 775–787, 1984.
[POL 85] POLLOCK D.S.G., “Tensor products and matrix differential calculus”, Linear
Algebra and its Applications, vol. 67, pp. 169–193, 1985.
[POT 67] POTTER J.E. and FRASER D.C., “A formula for updating the determinant of the
covariance matrix”, AIAA Journal, vol. 5, no. 7, pp. 1352–1354, 1967.
[SHA 95] SHAKERI M., PATTIPATI K.R. and KLEINMAN D.I., “Optimal measurement
scheduling for estimation”, IEEE Trans. on Aerospace and Electronic Systems, vol. 31,
no. 2, pp. 716–729, 1995.
[TRE 96] TRÉMOIS O. and LE CADRE J.-P., “Target motion analysis with multiple arrays:
performance analysis”, IEEE Trans. on Aerospace and Electronic Systems, vol. 32, no. 3,
pp. 1030–1045, 1996.
[VAN 93]
VAN KEUK G. and BLACKMAN S.C., “On phased array tracking and parameter
control”, IEEE Trans. on Aerospace and Electronic Systems, vol. 29, no. 1, pp. 186–194,
1993.
[YOK 92] YOKONUMA T., Tensor Spaces and Exterior Algebra, Transl. of Math. Monographs,
vol. 108, Amer. Math. Soc., Providence, RI, 1992.

Chapter 8
Bayesian Inference and Markov Models
8.1. Introduction and application framework
Marine sciences rely on the use of different methods and different tools to be
able to carry out research on what the seabed is made up of: this includes the use of
geotechnical tools (isolated well-logging, on site samples) as well as side-scan sonar
devices and multi-beam sounding systems which transform the characteristics of the
seabed interface into images.
Investigation systems which are used and which are based on a high resolution
sonar imaging system are tools that provide a solution to the problems linked to the
detection of small objects that can be found on the seabed. After the emission of a
sonar wave, the detection of these small objects can be carried out in one of two
ways: ﬁrst of all, it is possible to detect the behavior of a signal which is reﬂected
by the object, and secondly there is a certain level of interference that is generated
by the presence of this object (in the case of objects which are slightly buried in the
sediment of the sea bed). It is therefore necessary that the dimensions and the location
of such objects be compatible with the sonar’s ability to detect them. In the case of
an anechoic object, it is the formation of the acoustic shadow which makes it possible
to detect and then classify the object. In this chapter we will not deal with the issues
that arise during the design of a sonar system, nor will we deal with the issues which
led to the development of specialized sonar devices that are used for speciﬁc tasks,
such as sonar sensors which detect the presence of an object, sonar classiﬁers, which
are used to analyze an object, but which possess a lower detection range, and acoustic
cameras, which make it possible to recognize the object from a very short distance.
Chapter written by Christophe COLLET.
Optimization in Signal and Image Processing 
Edited by Patrick Siarry 
Copyright 0 
2009, ISTE Ltd 

196
Optimization in Signal and Image Processing
The differences that exist between these sonar devices can be identiﬁed through the
following aspects: the frequency of emission and reception of each device (in other
words the size of their antennae), the visualization mode which is used to detect and
classify the object such as sectional vision, panoramic vision and lateral vision, and
ﬁnally the structure of the investigation systems. The investigation systems can either
be towed [THO 96], found under the body of a moving vessel [DUG 96], or on board
an autonomous sensor (remote operated vehicle).
The sensors, which are used in sonar antennae, measure different pressure
variations. They are thus normally used to carry out investigations on the complex
amplitude module that is emitted by a signal [BUR 78] and not on the signal’s
intensity as is the case with radar imagery. The principle of image formation is based
on dividing a region of the seabed into smaller sectors (or resolution cells). A pathway
in a particular direction is formed and this makes it possible to explore the region of
the seabed that is to be examined. Once the pathway has been formed, a sample of
the signal which is reﬂected from the seabed is taken. It then becomes possible to
work out the amplitude of the signal in relation to its distance from the seabed. If a
large number of these paths are created electronically it therefore becomes possible
to explore an entire region of the seabed that is to be analyzed, sector by sector. One
solution that can be used to explore an individual sector involves creating a small
number of pathways, and then moving the sonar in a direction that is perpendicular
to the source of emission which comes from the signal. This solution is used in
side-scan sonar devices (Figure 8.1a). The images produced by such devices are also
analyzed in this chapter.
It is quite difﬁcult to actually see the presence of any small objects or the edges
of small objects in the images due to the granularity of the objects [COL 98]. This
poor quality can be associated with the use of sonar systems as well as with the use
of any coherent emission system. This poor quality due to the presence of speckle
noise (multiplicative noise) can be modeled using either Rayleigh’s [COL 98] or
Weibull’s [MIG 98] probability density functions (pdf). In certain cases it is possible
to model this speckle noise by using more complex pdfs requiring a larger number
of parameters; an example of such a probability distribution is the K law. During the
modeling step and particularly when complex pdfs are used, it is vital to correctly
integrate the nature of the noise, because in doing so, it means that it becomes
possible to segment images that have been strongly corrupted.
8.2. Detection, segmentation and classiﬁcation
The sonar images can be divided into three generic classes: shadow, reverberation
and echo. The echo class is, however, not present all of the time. This idea of
segmentation has been the subject of different Markov models which are used with
the aim of coding a piece of a priori information [THO 96, MIG 98]. There is in fact
no mathematical relationship between the images where the information is coded in

Bayesian Inference and Markov Models
197
direction of moving
sonar
antenna
object
shadow 
(a)
shadow
Nr
t(s)
echo
reverberation 
of the sea bed
reverberation 
o
of the sea bed
(b)
Figure 8.1. The process of image formation using a sonar device: (a) a cylindrical object and
its shadow corresponding to the region of the seabed which is acoustically hidden, (b) a
diagram which shows the evolution of the signal over time. First of all we can see a weak level
of volume reverberation corresponding to the microelements which are present in the column
of water. We can then see the acoustic wave which is reﬂected by the seabed (reverberation) as
well as the presence of an object which is sometimes represented by a strong reﬂection of the
acoustic wave (the echo). Immediately after the object has been detected, a signal with a very
low amplitude level is received (the shadow). The term shadow is used because it corresponds
to the hidden zone of the seabed
grayscale and the representation of the observed objects. It is possible to associate an
inﬁnite number of combinations of objects with an image which has been observed.
All of these different combinations of objects are able to produce the same image.
This is why it is useful to integrate a priori knowledge during the segmentation phase.
The aim of this is to statistically reduce the number of solutions that are possible
for creating the image. This a priori knowledge is partly made up of information
which is relevant to the image which has been observed, and is also made up of more
generic information. This a priori knowledge can be divided into both local and
global knowledge. Markov modeling allows us to locally describe global properties

198
Optimization in Signal and Image Processing
and is useful to constrain the solution (i.e. the segmentation map) through the use
of optimization algorithms (section 8.3). There are substantial beneﬁts to be gained
from using hierarchical approaches such as those mentioned in [THO 96, MIG 98]
in terms of the quality of the solutions that are obtained as well as in relation to the
speed at which modern algorithms can converge in comparison to the traditional
algorithms that were once used.
In section 8.4 a description of the hierarchical Markov segmentation algorithm
is given. The use of this algorithm makes it possible to segment the images into
two different classes (shadow and reverberation). In section 8.5 we introduce another
Markov algorithm allowing us to detect the third label which is the echo class. This
class takes into consideration the physical formation of the sonar images. We also
illustrate, using two concrete examples, the generality of these approaches as well as
the variety of optimization algorithms which can be used on the segmentation map
previously obtained.
The ﬁrst example (section 8.6) deals with the detection and classiﬁcation of
cylindrical or spherical shape manufactured objects which are investigated by a high
resolution sonar system. The high quality of an echo rarely leads to the classiﬁcation
of such manufactured objects and this is due to the stealth technology that is used
to identify such objects (such as underwater mines). Nevertheless, it is possible to
use the shape of the shadow produced by the object lying on the seabed thanks to
signals sent by the acoustic wave. Whilst observing the shape of the shadows that
are produced by such manufactured objects, we noticed that their shadows’ shapes
are regular and that they can be described by using simple geometric descriptors.
The shapes of the shadows have an almost afﬁne transformation and exist within
a particular Markov energy function whose energy needs to be minimized (cf.
section 8.6). This regularity of the shadows of such manufactured objects is the
opposite of the shapes of the shadows which are produced by stones of a similar size;
the shadows of these stones vary and are very irregular. These different properties will
be used to classify the different objects which can be found lying on the seabed. The
optimization algorithm that we have developed, and which minimizes the Markov
energy function, is in this case a genetic algorithm.
The second example (section 8.7) deals with the classiﬁcation of seabeds in
relation to the segmentation process (shadow/reverberation). The goal consists of
being able to recognize different textured shapes and this can sometimes pose a
problem. The different parameters which are extracted during the segmentation
process lead to a fuzzy classiﬁcation of the seabeds. A Markov ﬁeld model is then
applied to this classiﬁcation process which reﬁnes the classiﬁcation of the seabeds
even further because the use of this ﬁeld model enforces the spatial homogenity of the
classes which are associated with the segmented map (i.e. shadow, reverberation and
echo labels). The optimization algorithm used in this case is the iterated conditional

Bayesian Inference and Markov Models
199
model (ICM) algorithm [BES 86]. This algorithm is preferred to a simulated
annealing algorithm because of processing times.
8.3. General modeling
Markov ﬁelds were ﬁrst used in the area of image processing in the 1980s
[GEM 84]. This framework, which is used for modeling, experienced a rapid growth
and success thanks to its ﬂexibility, its ability to represent contextual information in
probabilistic terms, as well as illustrating the well known Bayes theorem with which
the Markov ﬁelds are associated. Within the Markov approaches that are used in
image processing the observations (variables which can be observed and which rely
on the analysis of the image) and the labels (information which cannot be observed
and that have to be extracted from the observations) are assumed to be random
ﬁeld variables that we will note as Y (the observation ﬁeld) and X (the label ﬁeld)
respectively. These ﬁelds are deﬁned on a rectangular grid S: Y = {Ys, s ∈S} and
X = {Xs, s ∈S} where s represents a point on the grid. Let y = {ys, s ∈S}
and x = {xs, s ∈S} be two realizations of random ﬁelds. The labels Xs take
their values (either discrete or continuous) from the set of values Λlabel. The set of
all the possible conﬁgurations of Y is deﬁned as follows: Ωobs = Λ#S
obs , where #S
represents the cardinal numbers of S and Λobs represents the brightness values which
can be observed. The set of all the possible combinations of X is Ωlabel = Λ#S
label. This
set makes up all of the label ﬁelds which are possible in the solution space. This set is
huge and there is no way of exploring it in an exhaustive manner.
8.3.1. Markov modeling
The Markov hypothesis can be expressed by a set of solutions X which are deﬁned
on a regular grid S. Markov modeling makes it possible to specify the properties of the
random X ﬁeld (or label ﬁeld) in relation to neighboring system V = {vs, s ∈S},
which is deﬁned on a set of sites {s ∈S} (a system V = {Vs ⊂S | s ∈S},
is a neighboring system of S if, and only if, ∀s ∈S, s /∈Vs and ∀(s, r) ∈S2,
r ∈Vs ⇔s ∈Vr). The neighboring system, which is thus deﬁned, leads to the
generation of a set C of cliques c on S. These cliques c correspond to the set of
possible conﬁgurations generated by the adopted neighboring system. The statistical
relationship which links the observation ﬁeld (Y ) with the label ﬁeld (X) in the
neighboring system (V ) can be explained by the equations which follow in the next
few sentences. The X ﬁeld is said to be Markovian and stationary in relation to
a neighboring system V , so that V
= {vs, s ∈S}. The X ﬁeld is therefore a
Markov ﬁeld if for all x conﬁgurations of X the following is true: PX(x) > 0
and ∀s ∈S, PXs|Xr(xs | xr, r ∈S −{s}) = PXs|Xr(xs | xr, r ∈vs). The
importance of Markov modeling lies in the ability to locally specify a model which
is in fact a global model. The Hammersley-Clifford theorem shows the equivalence
that exists between Gibbs distribution and the Markov ﬁelds [BES 74]. In this way it

200
Optimization in Signal and Image Processing
is possible to describe a Markov ﬁeld by looking at its total probability distribution
in the following way: ∀x ∈Ωlabel, PX(x) =
1
Z exp{−U2(x)} with the function
U2(x) which is known as the energy function and which can be decomposed into
a smaller number of local functions Vc. These local functions are known as functions
of potential and are deﬁned by the cliques of c ∈C. These cliques are generated by
the neighboring system V : U2(x) = 
c∈C Vc(x). Vc is only a function of the labels
for the points c ∈C. Z is a normalization constant, otherwise known as a partition
function and can be deﬁned as Z = 
x∈Ωlabel exp{−U2(x)}. The conditional laws
PXs|Xt(Xs = xs | Xt = xt, t ∈vs) can also be calculated and a link can therefore be
established between the geometric shape of the neighborhood (V ) and the energy term
U2(x). It is also possible to simulate such Markov ﬁeld in terms of PX(x) by using
Gibbs sampling algorithms and Metropolis-Hastings algorithms [BES 86, DUB 89].
8.3.2. Bayesian inference
Bayesian inference is about modeling the labels and the observations jointly
through the modeling of a coupled random ﬁeld (X, Y ). This ﬁeld is deﬁned by the
joint distribution of PXY (x, y) which needs to be developed. Bayes’ theorem states
that PXY (x, y) = PY |X(y | x) × PX(x). The probability PY |X(y | x) translates
the likelihood between observations and labels. This probability is deﬁned by a
knowledge of probability laws that are linked to noise (in the case of sonar imagery
this noise would be the speckle noise), whilst PX(x) makes it possible to introduce a
priori knowledge onto the labels. If we assume the Morkovianity of the ﬁelds then
the joint distribution of PXY (x, y) is a Gibbs distribution with an energy value of
U(x, y):
PXY (x, y) = 1
Z exp

−U(x, y)

[8.1]
where the energy is divided into the sum of the two following terms: U(x, y) =
U1(x, y) + U2(x).
– U1(x, y), which stems from the observation likelihood, constitutes the
data-driven term and characterizes the balance that exists between the labels and the
observations;
– U2(x), which comes from the Markov ﬁeld modeling, constitutes the a priori
contextual term which introduces a regularizing effect into the label ﬁeld.
The criterion which is often used to estimate label ﬁeld is the MAP criterion
(maximum a posteriori otherwise known as posterior mode). The search for the
optimal label ﬁeld ˆxopt using this criterion can also be seen as the minimization
of the function U(x, y). It is possible to process this optimal label ﬁeld using a
simulated annealing algorithm. Due to reasons associated with processing time and
depending on the individual cases, we preferred using mono- or multi-scale ICM
algorithms [BES 86] or genetic algorithms. Parameter estimation will be carried out

Bayesian Inference and Markov Models
201
using estimation algorithms such as EM [DEM 76], SEM [CEL 86] or ECI [PIE 92]
depending on the model we will take into account.
8.4. Segmentation using the causal-in-scale Markov model
In this multi-scale model, the pyramid structure is made up of a hierarchy
(xL, . . . , x0) of label ﬁelds with variable resolutions, where xl is deﬁned in a grid Sl
which corresponds to an isotropic subsample of S of factor 2l (S0 ≡S and x0 ≡x).
Y = {Ys, s ∈S} corresponds to the observation ﬁeld which can also be found on
the same grid but at a much ﬁner resolution of S. The grid is made up of N sites of
s (these sites are linked to N pixels of the sonar image), and X = {Xs, s ∈S}
represents the label ﬁeld with the ﬁnest resolution where (X0 ≡X). Each label
Xs is developed further in {e0 = shadow, e1 = reverberation}. The segmentation
of sonar images into two classes is seen as a problem of global Bayesian
inference which involves the search for xl, the label with a resolution of l so that
ˆxL = arg maxxL{PXL/Y (xL/y)} and ∀l = (L −1), . . . , 0
ˆxl = arg max
xl

PXl/Y,Xl+1(xl/y, ˆxl+1)

[8.2]
= arg max
xl

exp −U l(xl, y, ˆxl+1)

[8.3]
= arg min
xl U l(xl, y, ˆxl+1).
[8.4]
Level 0 a posteriori distribution, which appears in equation [8.2], can be written as
PX/Y,X1(x/y, ˆx1) ∝PX/X1(x/x1)PY/X(y/x). In this expression PX/X1(x/ˆx1)
models the a priori distribution, and PY/X(y/x) under conditionally independent
assumption is factorized into ΠsPYs/Xs(ys/xs), with PYs/Xs(ys/xs) being
the probability density which is associated with each region (i.e. shadow and
reverberation) of the sonar image. As far as the ﬁnest resolution is concerned the
global energy function which is to be minimized can be written as follows:
U(x, y, ˆx1) = −

s∈S
ln PYs/Xs

ys/xs

;
<=
>
U1(x,y)
+

<s,t>⊂S
βst

1 −δ

xs, xt

;
<=
>
U2(x)
+

s∈S
β5

1 −δ

xs, ˆx1
father(s)

;
<=
>
U3

x,ˆx1
δ(·) represents the Kronecker function and βst = β1, β2, β3 or β4 depend only on
the orientation of the spatial binary clique, while β5 is the inter-scale parameter that
is associated with the causal-in-scale link. U1 measures the balance between the
observation and the label, U2 measures the energy of the a priori spatial model and

202
Optimization in Signal and Image Processing
U3 measures the causal energy which symbolizes the in-scale relationship that exists
with the segmentation process at the coarsest level. It is possible to successfully
create a multi-grid model which is deﬁned at every resolution level l and which can be
deﬁned as follows [HEI 94]: U l(xl, y, xl+1) ≜U(Ψl
0(xl), y, Ψl+1
1
(xl+1)), where Ψl
k
is the duplication operator of Sl on Sk (for k < l). At the coarsest level, the multi-grid
model can be deﬁned as follows: U L(xL, y) = U1(ΨL
0 (xL), y) + U2(ΨL(xL)).
parent
S
labels
observations
(a)
(l+1)
etc ...
l
duplication
relaxation
(b)
Figure 8.2. (a) Multi-scale structure using spatial interactions of an 8-connexity
neighborhood system which is causal in scale. The aim of this causal-in-scale link
is to make the two segmentation classes (shadow and reverberation) much robust;
(b) coarse to ﬁne minimization strategy
The energy of this model is described by U2 and U3 (named as SCM or scale
causal multi-grid), and can be seen in Figure 8.2a. The amount of energy that this
model possesses depends on the parameter vector Φx = (β1, . . . , β5) while the
noise U1 is deﬁned by a second vector Φy. In the case of sonar images, a Weibull
density model is used [MIG 99]. It is possible to estimate all the parameters in an
unsupervised way, by using the iterative conditional estimation (ICE) algorithm
[MIG 99] to simultaneously estimate two parameter vectors. The ICM optimization
algorithm carries out the minimization process, which can be seen in equation [8.4].
The ﬁnal estimation ˆxl+1 which is obtained at scale l + 1 is interpoled by Ψl+1
l
(ˆxl+1)
with the aim of initializing the relaxation process at the ﬁnest scale of l (Figure 8.2b).

Bayesian Inference and Markov Models
203
(a)
(b)
(c)
(d)
Figure 8.3. (a) and (c) A sonar image of a bed of sand on which there is a cylindrical shaped
manufactured object (a and c) plus a stone (c); (b) and (d) the result of segmenting the image
into the two classes (reverberation and shadow) using the proposed SCM algorithm
This multi-scale minimization strategy is a rapid process which is less sensitive
to local minima than standard mono-scale relaxation algorithms. The strategy is also
well adapted to sonar images which have been noised with a strong specular noise and
which are modeled by one of Weibull’s density models [THO 96, MIG 98]. Figure 8.3
shows the results obtained for an image which has been segmented into two classes
and for which the unsupervised SCM algorithm has been used.
8.5. Segmentation into three classes
Whenever an echo is present, it must be detected in spite of specular noise. One
possible approach requires the use of a priori information we possess relating to the
echo formation. In sonar imagery the object which lies on the seabed creates a possible
echo which is then automatically followed by the creation of a shadow. This property
can easily be integrated into a Markov model which is now going to be explained.
Let ˆx[1] be the label ﬁeld that is obtained after an image has been segmented into two
classes by using the SCM algorithm which was mentioned earlier in this chapter. The
label ˆx[1]
s belongs to {e0, e1}. In taking x[1], we now consider the subset of pixels S′
(S′ ⊂S) so that S′ = {s ∈S : ˆx[1]
s
= e1 = reverberation}. It is this set which
then needs to be segmented into two classes in order to extract the echo from the
reverberation class. Let X[2] be the following random binary process: ∀s ∈S′, X[2]
s
takes it values from {e1 = reverberation, e2 = echo}. The segmentation process will
then be carried out on the restricted set of data y[1] = {ys, s ∈S′}. The distribution
of (X[2]/Y [1] = y[1], X[1] = ˆx[1]) is then deﬁned. This deﬁnition is made up of
two terms: PX[2]/X[1](x[2]/ˆx[1]) which is the distribution of X[2] that we assume to
be stationary and de Markov, and by the data attachment term PY [1]
s
/X[2]
s (y[1]
s /x[2]
s )

204
Optimization in Signal and Image Processing
according to the label x[2]
s . In the case of a label which is reﬂected from the seabed e1:
PY [1]
s
/X[2]
s

y[1]
s /e1

= Wb

ys, α, β, min

[8.5]
= β
α
"ys −min
α
#β−1
exp

−
"ys −min
α
#β
[8.6]
where α and β are the parameters of scale and shape respectively, which are positive
deﬁned according to Weibull’s law (Figure 8.4(a)). The data attachment term for the
echo label e2 is written as follows:
PY [1]
s
/X[2]
s

y[1]
s /e2

= 2
γ Λ

ys −ymax

U

ymax −ys

[8.7]
where U is the Heaviside step function and Λ is a triangle function. ymax corresponds
to the maximum brightness of the sonar image while 2
γ is a normalization constant
(see Figure 8.4(b)). This model is justiﬁed due to the fact that for raw data the echo
corresponds to a saturation of hydrophones.
0
0.2
0.4
0.6
0.8
1
1.2
1.4
0
0.5
1
1.5
2
2.5
3
3.5
W(y)
y
The laws of Weibull
Rayleigh’s law
Exponential law
c=1
c=1.5
c=2
c=3
(a)
0
0.005
0.01
0.015
0.02
0
50
100
150
200
250
Probability density
brightness
The echo law
Probability density 
of the echo
(b)
Primary potential field
–5
0
5
-5
0
5
0
0.5
1
1.5
2
2.5
(c)
Figure 8.4. (a) A graph showing Weibull’s law for the different parameters of β = c; (b) the
echo law; (c) the primary potential ﬁeld which has been generated into a shadow labeled site

Bayesian Inference and Markov Models
205
We are therefore looking for x[2] so that [MIG 99]:
ˆx[2] = arg max
x[2] PX[2]/X[1],Y [1]
'
x[2]/ˆx[1], y[1](
[8.8]
= arg max
x[2] PY [1]/X[1],X[2]
'
y[1]/ˆx[1], x[2](
PX[2]/X[1]
'
x[2]/ˆx[1](
[8.9]
= arg min
x[2]
/
U1
'
y[1], x[2], ˆx[1](
+ U2
'
x[2], ˆx[1](0
[8.10]
where U1 highlights the balance that exists between the observations and the
labels {e1, e2}, while U2 is the energy term which corresponds to the a priori
model described in PX[2]/X[1](x[2]/ˆx[1]). The parameters of the energy term which
determine the likelihood of U1 can be estimated thanks to a procedure deﬁned in
[MIG 99]. U2 expresses the constraints on the desired solution. In our case, once
again we use a spatial 8-connexity neighborhood system (Figure 8.5) where β1,
β2, β3, β4 represent the a priori parameters which are associated with horizontal,
vertical, diagonal, left and right binary cliques respectively. β0 corresponds to the
singleton clique.
v1 u2 v2
u1
v4 u4 v3
u3
xs
β1
β3
β2
β4
Figure 8.5. An 8-connexity neighborhood system and the sites ui, vi, which are associated
with that neighborhood. The four binary cliques of the 8-connexity neighborhood system
and their associated βk parameters which correspond to the Ising model
The Potts model is used in order to favor the use of homogenous regions. The Potts
model associates the binary clique ⟨s, t⟩with a variable potential β(1 −δ(x[2]
s , x[2]
t )),
where β = β1 = β2 = β3 = β4.
The dependency of the echo class on the shadow class consists of favoring an
echo label within a site s which is located not too far from a shadow region. To
express such constraint, a potential associated with the singleton clique is used:
−β0 ln Ψˆx[1](s)δ(x[2]
s , e2). In this equation Ψˆx[1](s) is a ﬁeld of potentials which can
be deﬁned as follows:
Ψˆx[1](t) = inf


s∈S:ˆx[1]
s =e0
1
d(s, t) exp
"
−d(s, t)
σ
#
;
<=
>
φs

d(s,t)

, 1

[8.11]

206
Optimization in Signal and Image Processing
with d(s, t) being the geometric distance that exists between the pixels s and t. σ is
a parameter that controls the maximum distance at which it is possible for the echo
and shadow regions to interact with one another (Figure 8.4(c) represents the function
φs(d(s, t))). The total energy that needs to be minimized can be deﬁned as follows:
U

x[2], ˆx[1], y[1]
= −

s∈S′
ln PY [1]
s
/X[2]
s

y[1]
s /x[2]
s

;
<=
>
U1(y[1],x[2],ˆx[1])
+

<s,t>⊂S′
β

1 −δ

x[2]
s , x[2]
t

;
<=
>
U21(x[2],ˆx[1])
+

s∈S′
−β0 ln Ψˆx[1](s) · δ

x[2]
s , e2

;
<=
>
U22(x[1],x[2],ˆx[1])
.
Once the actual modeling process has been deﬁned, a traditional ICM type
optimization algorithm is used [BES 86]. The initialization is made by a maximum
likelihood algorithm.
In practice, on one hand due to the extremely low number of locations that
are associated with an echo label, on the other hand due to the good label map
initialization given by ML (maximum likelihood) algorithm, it is possible to segment
the image to a single resolution level with the ICM algorithm without having to
use a multi-grid strategy. Figures 8.6 and 8.7 show two examples of three-class
segmentation which have been carried out on synthetic and real images. We also show
(for different Markov models we deﬁned) that it is possible for the objects to free
themselves from strong specular noise and to integrate within a regularization scheme
based on a Markov model, some a priori information related to image formation.
8.6. The classiﬁcation of objects
In this section we will deal with another aspect of sonar image analysis: the
classiﬁcation of manufactured and natural objects which can be found lying on the
seabed. This phase of low-level semantic classiﬁcation (which is of great importance
for the application in real life) also relies on the use of a Markov regularization
approach which formalizes the a priori knowledge that we already possess. Contrary
to the natural objects that can be found lying on the seabed, the manufactured objects
are normally made up of simple and regular geometric shapes. The shadow of a
cylindrical shaped object (such as a mine) is the shape of a perfect parallelogram. The
a priori knowledge that we possess in relation to the object and its shadow can be
represented by a prototype shape, which in our case is a parallelogram with its four

Bayesian Inference and Markov Models
207
            
(a)
            
(b)
            
(c)
            
(d)
            
(e)
            
(f)
Figure 8.6. Synthetic shapes which are similar to the shape of a circle such as a tire (a) and a
sphere (d). These shapes are obtained by using a ray tracing algorithm. (b and e) are synthetic
sonar images which have been artiﬁcially sounded with a speckle noise, the objects are
assumed to be placed on a bed of sand. (c and f) are the resulting three-class segmentations
sides [MIG 00a]. In other cases it might be necessary to detect ellipses corresponding
to spherical shaped objects which are lying on the seabed: the shadow associated
with any object can in fact be deﬁned by m manually selected points or by m points
which are evenly spread on the shadow’s outline. A representation using a cubic
B-spline on m control points is therefore possible. The shape of this object’s shadow
(or of any other object) can be created thanks to the use of a ray tracing algorithm
(Figure 8.6a, d).
Let γ0 be the prototype shape of a class of objects we are looking for. We have to
deﬁne a set of linear transformations that can be carried out on γ0 in order to consider
the variability of the class of objects: different point of view, unknown a priori location
of the object in the image, etc. Let γθ be a distorted version of the original γ0 which
is made possible by carrying out an afﬁne transformation on the original and whose
parameters form the vector θ. In the case of a cylindrical shape these transformations
can take the form of any combination of the following functions: translation (the exact
location of the object in the image is unknown), scale-factor (the exact distance of
the object from the sonar device is unknown), rotation (the angle of the object from

208
Optimization in Signal and Image Processing
(a)
(b)
(c)
(d)
(e)
            
(f)
Figure 8.7. (a) (c) (e) Real sonar images taken from manufactured objects lying on a bed of
sand (two cylinders and a trolley lying on its side, it is possible to distinguish the two wheels
of the trolley); (b) (d) (f) the resulting three-class segmentation
the sonar device is unknown), slicing and stretching (with the aim of modeling the
artifact during the formation of the sonar image). All of these different functions can
be seen in Figure 8.8a. In the case of a spherical shaped object, the symmetry of the
object in relation to the direction of the sonar beam makes it possible to limit these
transformation functions to only translation, homothetic transformation and stretching
(Figure 8.8b).
The detection of an object is based on an objective function ϵ which measures the
balance between a prototype shape γθ and the two-class segmented image x. Using
the Gibbs distribution, ϵ(θ, x) statistically deﬁnes a joint model [MIG 00a]:
PΘ,X(θ, x) = 1
Z exp

−ϵ(θ, x)

[8.12]
where Θ is a random parameter vector and where Z is a normalization constant. The
energy function ϵ(θ, x) is made up of two terms:
ϵ(θ, x) = −ln

1
Nγθ

s∈γθ
ΦS′(s)

;
<=
>
ϵc(θ,x)
−ln

1
Nγ•
θ

s∈γ•
θ
δ

xs, e0


;
<=
>
ϵr(θ,x)
[8.13]

Bayesian Inference and Markov Models
209
Original prototype Scale
Elongation
Rotation
Cutting
Set of transformations
(a)
Elongation
Set of transformations
Original prototype
Scale
(b)
Figure 8.8. Linear transformations which are considered in the case of a prototype
shape which is associated with (a) the shadow of a manufactured cylindrical object
and (b) the shadow of a spherical object
with ϵc being the edge energy. ϵc forces the deformable prototype into positioning
itself onto the edges of each object: ΦS′ is a ﬁeld of potentials which is generated by
the outlines of an object and whose equation can be seen in [8.11]. This equation is the
sum of the set of edge pixels which is associated with objects that have been detected
after the process of two-class segmentation (this was dealt with in section 8.4). This
ﬁeld of potentials makes it possible to smooth the outlines of an image so that a site
that is located near such an edge can possess a value of potential which is close to
one. The sum of the set of edge points is taken from all of the points of Nγθ from the
distorted prototype shape γθ. ϵr is an energy term which uses a region-based approach,
and which aim at placing the major part of the pixels from the deformable prototype
into the shadow labeled class which is created after the image has been segmented.
γ•
θ and Nγ•
θ represent the set of pixels and the number of pixels that can be found
within a region deﬁned by γθ. This detection problem has been formalized as an
optimization problem that can be taken into account as a MAP (or maximum posterior
mode) estimation of θ:
ˆθMAP = arg max
θ

PΘ/X(θ/x)

= arg max
θ
B 1
Zx
exp

−ϵ(θ, x)
C
[8.14]
= arg min
θ
ϵ(θ, x)
[8.15]
where Zx is the partition function which depends only on x. ϵ is the total energy
function that needs to be minimized. This function is minimal whenever the
deformable prototype ﬁt exactly with the shape coming from the map created
after 2-classes labeling process (section 8.4). The interior of the object exclusively

210
Optimization in Signal and Image Processing
contains sites which stem from the shadow class. As far as the classiﬁcation phase
is concerned, the value of energy which is obtained, ϵ(ˆθMAP, x), is used to measure
the membership function of the prototype shape that forms part of the region of the
seabed that we want to investigate. ϵ(ˆθMAP, x) is also used to decide whether or not
the extracted object belongs to the class of objects of interest. If ϵ(ˆθMAP, x) is smaller
than the value of a given ﬁxed threshold then we assume that the estimated prototype
shape object ﬁts with the object we have to detect: it is also possible to know where
the object can be found in the image thanks to the translation functions contained
in ˆθMAP. If this is not the case, then it is believed that such an object is not present
in the image. Due to the detection and classiﬁcation strategies that are used, it is
not possible to use traditional relaxation techniques (such as the gradient descent
method) for minimizing the energy function. If such a method were to be used we
need to make sure that initialization is properly made, close to the object we are
trying to detect. However, this is not possible in practice since the aim of using such
a method is to try and ﬁnd the prototype shape of the shadow in the image without
any previous knowledge of the prototype shape’s position, angle, distance, slicing or
stretching in relation to the object’s shadow.
The stochastic optimization method which is based on simulated annealing
algorithm [GEM 84] is the best way, nevertheless such methods require huge
computing time to minimize the energy functions; even if this method does not
require any speciﬁc initialization to converge toward the right solution.
These different characteristics which are mentioned above come at a high price
since temperature decreasing diagrams end up with extremely long convergence times
which sometimes can prevent the simulated annealing algorithm from being used for
what it was intended [MIG 99, KER 96]. An alternative approach which has been
adopted here consists of estimating the parameters of the energy functions through the
use of a genetic algorithm [MIG 99]. This optimization procedure, which simulates
the process of natural selection in the living world [GOL 89], can also be used for
minimizing a continuous function of dimension L (L = 6 or L = 4 depending on the
symmetry of the object that is being researched). A global minimum is obtained by
carrying out successive mutations and crosses on the genes which code the different
parameters of the afﬁne transformation that is associated with each prototype of the
population. PΘ,X(θ, x) from equation [8.12] corresponds to the adaptation function
that we adopt to move from one generation to the next. If such an adaptation function
is used, the convergence is reached 25 times faster than for other sub-optimal versions
of the simulated annealing algorithm used (sub-optimal decrease of temperature law).
Figures 8.9, 8.10 and 8.11 show some examples of the results of typical classiﬁcations
which are obtained on our image base. It should be pointed out that a threshold of
0.2 was obtained after different tests on the different images were carried out. It
should also be pointed out that the geometric shapes (i.e. manufactured objects) were
correctly detected as follows: the correct part of a wreck (Figure 8.9e), the correct

Bayesian Inference and Markov Models
211
(a)
(b)
(c)
(d)
(e)
            
(f)
Figure 8.9. The parallelogram prototype and the low values which are obtained thanks to the
use of a genetic algorithm (ϵ < 0.2) enable us to identify the shadows as being shadows which
are produced by cylindrical shaped manufactured objects: (a), (b) and (c) different cylindrical
objects: ϵ = 0.17, ϵ = 0.15, and ϵ = 0.14 respectively; (d) a pipeline: ϵ = 0.12; (e) a wreck:
ϵ = 0.15; (f) a trolley: ϵ = 0.2
            
(a)
            
(b)
            
(c)
Figure 8.10. The prototype deﬁned by a cubic B-spline and the low values which are obtained
thanks to the use of a genetic algorithm for ϵ (ϵ < 0.2) make it possible to identify the presence
of spherical objects: (a) ϵ = 0.04; (b) ϵ = 0.15; (c) ϵ = 0.19. Here the shadow has been
added artiﬁcially to a real image
part of a pipe line (Figure 8.9d), a trolley (Figure 8.9f) and various other cylindrical
objects (Figure 8.9a, Figure 8.9b and Figure 8.9c). The robustness toward occlusion
phenomenon is illustrated for spherical objects in Figure 8.10. Figure 8.11 shows some
natural objects and their corresponding values for the objective function ϵ.

212
Optimization in Signal and Image Processing
            
(a)
(b)
(c)
            
(d)
(e)
(f)
            
(g)
(h)
(i)
Figure 8.11. The values ϵ (>0.2) (obtained through genetic exploration) for each prototype
can reject the hypothesis of a spherical or cylindrical object being in the image: (a), (b), (c) 2
class Markov segmentation of the sonar images; (d) ϵ = 0.40; (e) ϵ = 0.41; (f) ϵ = 0.24; (g)
ϵ = 0.55; (h) ϵ = 0.57; (i) ϵ = 0.38
8.7. The classiﬁcation of seabeds
Another application which uses the two-class segmentation maps of a sonar image
(see section 8.4) is the automatic segmentation-classiﬁcation process which is now
proposed to segment and classify seabeds. The aim of segmenting the seabeds is
to divide the acoustic images into regions according to the regions’ acoustic and
geological characteristics (Λ = {w0 = sand, w1 = ripples, w2 = dunes, w3 =
pebbles, w4 = stones}).
We recommend adopting a pattern recognition-based method for such a task.
Indeed, such an approach is based on the identiﬁcation of the detected shadows

Bayesian Inference and Markov Models
213
which are produced by the different types of seabed. To this end the two classes
which result from the segmentation of a sonar image are ﬁltered with the aim of
extracting the edges of an object’s shadow (high-pass ﬁlter). The resulting image is
divided into sub-images from which a characteristic vector is extracted. For each
small image, the characteristic vector includes information relating to the density,
directivity, elongation and maximum size of the shadow [MIG 00b]. Once each of
these four parameters has been extracted they form a characteristic vector v, which
provides information to a fuzzy classiﬁcation tool which models the fuzzy a priori
knowledge that we possess on the shadows that are produced by the different types
of seabed. This model of a priori knowledge simply models the following facts in a
simple fashion: the shadows of objects which are found on a seabed that is made
up of ripples or of dunes are geometrically in place and are parallel to one another.
The shadows of objects which are found on a seabed that is composed of pebbles
or of stones produce shapes with a random geometry and tend to possess random
orientations. This notion of fuzziness means that each parameter vector vk that is
calculated on every kth small image can associate itself with a particular degree
of membership μwi(vk) (0 ≤μwi(.) ≤1) for each class of wi. This degree of
membership will then later be used to model the data-driven term; in other words it
will be used to model the link that exists between the seabed class and the data which
has been observed.
In order to create an accurate segmentation-classiﬁcation process, the contextual
information (i.e. the spatial relationship that exists between the characteristic vectors
which are extracted from neighboring windows) is modeled another time with the help
of a Markov ﬁeld. This makes it possible to simultaneously consider the results that
are obtained from the fuzzy classiﬁcation process as well as considering the constraint
of spatial homogenity which is enforced upon the desired solution. We consider a
couple of random ﬁelds (V, W) with V = {Vs, s ∈S} being the observation ﬁeld
(where vs corresponds to the characteristic vector which is estimated on the sub-image
s considered as being created from Vs), and W = {Ws, s ∈S} is the label ﬁeld which
is deﬁned on a grid S of N small images. Each Ws takes values in Λ. The distribution
of W, PW (w) is assumed to be stationary and Markovian. In this way, the distribution
of W, PW (w), leads to the issue of spatial regularization. The segmentation process
leading to w is processed as a statistical segmentation problem that is resolved thanks
to the use of the Bayesian formula under a MAP criterion:
ˆw = arg max
w
PW/V (w/v) = arg max
w

PW (w) PV/W (v/w)

[8.16]
= arg min
w U1(w, v) + U2(w)
[8.17]
where U1(w, v) represents the data-driven term which measures the balance that exists
between observation ﬁeld and the label map, while U2(w) is an energy term which
models the a priori information that we possess on the solution that we are looking
for. The label which is used for each small image is the result of a compromise

214
Optimization in Signal and Image Processing
between these two equations, i.e. it is the result of the minimization of the global
energy function. The neighboring model and the potential functions are the same as
those mentioned in section 8.4. The characteristic-driven term U1(w, v) is deﬁned
as being: U1(w, v) = −
s∈S γ(ws, vs) with γ(·) a value that equals μws(vs) if
ws = arg maxwj(μwj(·)) (0 ≤j ≤4) and zero if this is not the case [MIG 00b]. The
global energy function which is to be minimized can be expressed as follows:
U(w, v) = −

s∈S
γ

ws, vs

;
<=
>
U1(w,v)
+

<s,t>
βst

1 −δ

ws, wt

;
<=
>
U2(w)
The use of an ICM relaxation algorithm efﬁciently solves this optimization
problem. The initialization process is carried out thanks to the classiﬁcation process
obtained by the fuzzy classiﬁcation tool. It is not worthwhile developing a multi-grid
strategy because the images which have been segmented are of a very high quality.
Figure 8.12 shows two images of seabeds and the classiﬁcations that the images
have been placed into in relation to our classiﬁcation system: the class is superimposed
onto each image.
(a)
            
(b)
Figure 8.12. (a), (b) Images received by a towed side-scan sonar device from an area
of a seabed made up of sand (by default), of sand dunes (parallel lines in image a),
of pebbles (small squares at the bottom right of image b) or of stones (large
squares in image b). The classiﬁcation results show that the individual
classiﬁcation classes have been correctly detected
8.8. Conclusion and perspectives
This chapter illustrates different methods of image processing which are made
possible thanks to the use of a towed side-scan sonar device. These different methods

Bayesian Inference and Markov Models
215
are all based on the notion of Bayesian inference within a Markov framework, which
underlines the strength and the widespread acceptance of this type of modeling. High
resolution sonar imagery is an interesting branch of imagery to work in because
all of the data is noised by a strong speckle effect which makes the analysis of the
data a delicate process. First of all a deﬁnition of the causal-in-scale segmentation
model was given (section 8.4), which is known as the scale causal multi-grid (SCM)
algorithm. The SCM links a Markov ﬁeld with a causal-in-scale term with the
aim of segmenting an image into two classes, shadow and reverberation. A priori
information can be expressed by using both local and global a priori models. The
local a priori model can be managed at pixel level (two-class segmentation) as well
as at the regional level (detection of the echo class, detection of prototype shapes
with an almost linear transformation as well as the classiﬁcation of different types of
seabeds). The data-driven model uses either the brightness of the image by estimating
the parameters of a noise model (such as those developed by Rayleigh and Weibull)
or uses the two-class segmentation map (detection of the echo, classiﬁcation of
objects or of seabeds). The tasks of detection and classiﬁcation come down to the
minimization of an energy function which integrates the a priori model within the
desired solution that we want to use in order to successfully detect and classify
objects. Different optimization strategies have also been developed depending on the
energy landscape in which they are used. For reasons linked to processing times, the
simulated annealing algorithm is not used and has been replaced by other determinist
methods such as the mono-scale ICM algorithm and the multi-scale ICM algorithm
whenever access to a good initialization algorithm is possible. It is also possible
to use an original stochastic optimization method based on genetic algorithms in
cases where there is no access to a good initialization algorithm. It should also be
pointed out that each of the four algorithms that are used is in fact an unsupervised
algorithm and that they have been used and validated in a signiﬁcant number of real
sonar images. Their robustness and their ﬂexibility make it possible to process large
quantities of data. Recently, however, new Markov models have been developed such
as the quad tree [LAF 00, PRO 03], the Markov chain and the pair-wise and triplet
Markov ﬁelds [PIE 03]. These new models make it possible to generalize the analysis
of multi-dimensional data such as multi-wavelengths and multi-resolutions, or to
analyze the non-stationarity of images. These new models are also opening the way
for a whole generation of new a priori type models such as the probabilistic atlas of
the brain which can be obtained from segmenting magnetic resonance imaging (MRI)
images [BRI 06, BRI 08, LEC 08].
8.9. Bibliography
[BES 74] BESAG J., “Spatial interaction and the statistical analysis of lattice systems”, Journal
of the Royal Statistical Society, vol. 36, pp. 192–236, 1974.
[BES 86] BESAG J., “On the statistical analysis of dirty pictures”, Journal of the Royal
Statistical Society, vol. B-48, pp. 259–302, 1986.

216
Optimization in Signal and Image Processing
[BRI 06] BRICQ S., COLLET C. and ARMSPACH J.-P., “Triplet Markov chain for 3D MRI
brain segmentation using a probabilistic atlas”, IEEE Int. Symposium on Biomedical
Imaging: from Nano to Macro, Virginia, USA, 6–9 April 2006.
[BRI 08] BRICQ S., COLLET C. and ARMSPACH J.-P., “Unifying framework for multimodal
brain MRI segmentation based on hidden Markov chain”, Medical Image Analysis, vol. 16,
no. 6, pp. 639–652, 2008.
[BUR 78] BURCKHARDT C.B., “Speckle in ultrasound B-mode scans”, IEEE Transactions on
Sonics and Ultrasonics, vol. SU-25, no. 1, pp. 1–6, 1978.
[CEL 86] CELEUX G. and DIEBOLT J., “L’algorithme SEM: un algorithme d’apprentissage
probabiliste pour la reconnaissance de mélanges de densités”, Journal of Applied Statistics,
vol. 34, no. 2, 1986.
[COL 98] COLLET C., THOUREL P., MIGNOTTE M., BOUTHEMY P. and PÉREZ P.,
“Une nouvelle approche en traitement d’images sonar haute résolution: la segmentation
markovienne hiérarchique multimodèle”, Traitement du Signal, vol. 15, no. 3, pp. 231–250,
1998.
[DEM 76] DEMPSTER A., LAIRD N. and RUBIN D., “Maximum likelihood from incomplete
data via the EM algorithm”, Royal Statistical Society, pp. 1–38, 1976.
[DUB 89] DUBES R.C. and JAIN A.K., “Random ﬁeld models in image analysis”, Journal of
Applied Statistics, vol. 16, no. 2, pp. 131–163, 1989.
[DUG 96] DUGELAY S., GRAFFIGNE C. and AUGUSTIN J., “Deep seaﬂoor characterization
with multibeam echosounders by image segmentation using angular acoustic variations”,
SPIE’96 International Symposium on Optical Science, Engineering and Instrumentation,
vol. 2847, 1996.
[GEM 84] GEMAN S. and GEMAN D., “Stochastic relaxation, Gibbs distributions and the
Bayesian restoration of images”, IEEE Transactions on Pattern Analysis and Machine
Intelligence, vol. PAMI-6, no. 6, pp. 721–741, November 1984.
[GOL 89] GOLDBERG D., Genetic Algorithm, Addison Wesley, 1989.
[HEI 94] HEITZ F., PÉREZ P. and BOUTHEMY P., “Multiscale minimisation of global energy
functions in some visual recovery problems”, CVGIP: Image Understanding, vol. 59, no. 1,
pp. 125–134, 1994.
[KER 96] KERVRANN C. and HEITZ F., “Statistical model-based segmentation of deformable
motion”, Proc. International Conference on Image Processing, Lausanne, pp. 937–940,
1996.
[LAF 00] LAFERTÉ J.-M., PÉREZ P. and HEITZ F., “Discrete Markov image modeling
and inference on the quadtree”, IEEE Transactions on Image Processing, vol. 9, no. 3,
pp. 390–404, 2000.
[LEC 08] LE CAM S., SALZENSTEIN F. and COLLET C., “Fuzzy pairwise Markov chain to
segment correlated noisy data”, Signal Processing, vol. 88, no. 10, pp. 2526–2541, 2008.
[MAU 05] MAUSSANG F., Traitement d’images et fusion de données pour la détection d’objets
enfouis en acoustique sous-marine, PhD Thesis, LIS – UMR CNRS 5083, Joseph Fourier
University, Grenoble, November 2005.

Bayesian Inference and Markov Models
217
[MIG 98] MIGNOTTE
M.,
Segmentation
d’images
sonar
par
approche
markovienne
hiérarchique non supervisée et classiﬁcation d’ombres portées par modèles statistiques, PhD
Thesis, University of West Brittany – GTS Laboratory, July 1998.
[MIG 99] MIGNOTTE M., COLLET C., PÉREZ P. and BOUTHEMY P., “Three-class Markovian
segmentation of high resolution sonar images”, Journal of Computer Vision and Image
Understanding, vol. 76, no. 3, pp. 191–204, 1999.
[MIG 00a] MIGNOTTE M., COLLET C., PÉREZ P. and BOUTHEMY P., “Hybrid genetic
optimization and statistical model-based approach for the classiﬁcation of shadow shapes in
sonar imagery”, IEEE Trans. on Pattern Analysis and Machine Intelligence, vol. 22, no. 2,
pp. 129–141, 2000.
[MIG 00b] MIGNOTTE M., COLLET C., PÉREZ P. and BOUTHEMY P., “Markov random
ﬁeld and fuzzy logic modeling in sonar imagery: application to the classiﬁcation of
underwater-ﬂoor”, Journal of Computer Vision and Image Understanding CVIU, vol. 79,
pp. 4–24, 2000.
[MIG 00c] MIGNOTTE M., COLLET C., PÉREZ P. and BOUTHEMY P., “Sonar image
segmentation using an unsupervised hierarchical MRF model”, IEEE Trans. on Image
Processing, vol. 9, no. 7, pp. 1–17, 2000.
[PIE 92] PIECZYNSKI W., “Statistical image segmentation”, Machine Graphics and Vision,
vol. 1, no. 2, pp. 261–268, 1992.
[PIE 03] PIECZYNSKI W., “Pairwise Markov chains”, IEEE Transactions on Pattern Analysis
and Machine Intelligence, vol. 25, no. 5, pp. 634–639, 2003.
[PRO 03] PROVOST J., COLLET C., ROSTAING P., PÉREZ P. and BOUTHEMY P.,
“Hierarchical Markovian segmentation of multispectral images for the reconstruction of
water depth maps”, Computer Vision and Image Understanding, vol. 93, no. 2, pp. 155–174,
2003.
[THO 96] THOUREL P., Segmentation d’images sonar par modélisation Markovienne
hiérarchique et analyse multirésolution, PhD Thesis, University of West Brittany – GTS
Laboratory, July 1996.

Chapter 9
The Use of Hidden Markov Models for Image
Recognition: Learning with Artiﬁcial Ants,
Genetic Algorithms and Particle Swarm
Optimization
9.1. Introduction
Hidden Markov models (HMMs) are statistical tools which are used to model
stochastic processes. These models are used in several different scientiﬁc domains
[CAP 01] such as speech recognition, biology and bioinformatics, image recognition,
document organization and indexing as well as the prediction of time series, etc. In
order to use these HMMs efﬁciently, it is necessary to train them to be able to carry
out a speciﬁc task. In this chapter we will show how this problem of training an
HMM to carry out a speciﬁc task can be resolved with the help of several different
population-based metaheuristics.
In order to explain what HMMs are, we will introduce the principles, notations
and main algorithms which make up the theory of hidden Markov models. We will
then continue this chapter by introducing the different metaheuristics which have been
considered to train HMMs: an evolutionary method, an artiﬁcial ant algorithm and a
particle swarm technique. We will ﬁnish the chapter by analyzing and evaluating six
different adaptations of the above metaheuristics that enable us to learn HMMs from
data which comes from the images.
Chapter written by Sébastien AUPETIT, Nicolas MONMARCHÉ and Mohamed SLIMANE.
Optimization in Signal and Image Processing 
Edited by Patrick Siarry 
Copyright 0 
2009, ISTE Ltd 

220
Optimization in Signal and Image Processing
9.2. Hidden Markov models (HMMs)
HMMs have existed for a long time. They were deﬁned in 1913 when A. A.
Markov ﬁrst designed what we know as Markov chains [MAR 13]. The ﬁrst efﬁcient
HMM algorithms and the key principles of HMMs only appeared during the 1960s
and 1970s [BAU 67, VIT 67, BAU 72, FOR 73]. Since then, several variants of the
original HMMs have been created and a number of HMM applications have been a
success. In order to give precise deﬁnitions, we need to deﬁne what we consider to be
a discrete hidden Markov model throughout this chapter.
9.2.1. Deﬁnition
A discrete hidden Markov model corresponds to the modeling of two stochastic
processes. The ﬁrst process corresponds to a hidden process which is modeled by
a discrete Markov chain and the second corresponds to an observed process which
depends on the states of the hidden process.
DEFINITION 9.1. Let S={s1, . . . , sN} be the set of N hidden states of the system and
let S =(S1, . . . , ST ) be a tuple of T random variables deﬁned on S. Let V = {v1, . . . ,
vM} be the set of the M symbols which can be emitted by the system and let V =
(V1, . . . , VT ) be a tuple of T random variables deﬁned on V. It is therefore possible to
deﬁne a ﬁrst order discrete hidden Markov model by using the following probabilities:
– the initialization probability of hidden states: P(S1 = si),
– the transition probability between hidden states: P(St = sj | St−1 = si),
– the emission probability of the symbols for each hidden state: P(Vt = vj |
St = si).
If the hidden Markov model is stationary then the transition probability between
hidden states and the emission probability of the symbols for each hidden state
are independent of the time t > 1. For every value of t > 1, we can deﬁne
A = (ai,j)1≤i,j≤N with ai,j = P(St = sj | St−1 = si), B = (bi(j))1≤i≤N, 1≤j≤M
with bi(j) = P(Vt = vj | St = si) and Π = (π1, . . . , πN)′ with πi = P(S1 = si).
A ﬁrst order stationary hidden Markov model denoted by λ is therefore deﬁned by
the triplet (A, B, Π). Throughout this chapter we will continue to use the notation
λ and we will use the term hidden Markov models (HMM) for the ﬁrst order
stationary HMMs. Let Q = (q1, . . . , qT ) ∈ST be a sequence of hidden states and
let O = (o1, . . . , oT ) ∈VT be a sequence of observed symbols. The probability of
producing a sequence of hidden states Q and of producing a sequence of observations
O according to the HMM λ is written as follows:1
P

V = O, S = Q | A, B, Π

= P

V = O, S = Q | λ)
1. Strictly, we should consider the hidden Markov model λ as the realization of a random
variable and note P(V = O, S = Q | l = λ). However, to simplify the notations, we
have chosen to leave out the random variable which refers to the model.

The Use of Hidden Markov Models for Image Recognition
221
The conditional probabilities lead to:
P

V = O, S = Q | λ

= P

V = O | S = Q, λ

P

S = Q | λ

=
 T
$
t=1
bqt

ot


·

πq1
T −1
$
t=1
aqt,qt+1

From an HMM λ, a sequence of hidden states Q and a sequence of observations
O, it is possible to calculate the balance between the model λ and the sequences
Q and O. In order to be able to do this, we only need to calculate the probability
P(V = O, S = Q | λ). This probability corresponds to the probability of a sequence
of observations O being produced by the model λ after a sequence of hidden states Q
has been produced.
Whenever the sequence of states is unknown, it is possible to evaluate the
likelihood of a sequence of observations O according to the model λ. The likelihood
of a sequence of observations corresponds to the probability P(V = O|λ) that the
sequence of observations has been produced by the model when considering all the
possible sequences of hidden states. The following formula is therefore validated:
P

V = O | λ

=

Q∈ST
P

V = O, S = Q | λ

Whenever HMMs are used, three fundamental issues need to be resolved (for the
model λ):
– evaluating the likelihood of P(V = O|λ) for a sequence of observations O
according to the model λ. This probability is calculated using the forward or backward
algorithm with a complexity level of O(N 2T) [RAB 89];
– determining the sequence of hidden states Q∗which has most likely been
monitored with the aim of producing the sequence of observations O: the sequence of
hidden states Q∗, which is deﬁned by the equation below, is determined by Viterbi’s
algorithm with a complexity level of O(N 2T) [VIT 67];
Q∗= arg max
Q∈ST P

V = O, S = Q | λ

– training/learning one or several HMMs from one or several sequences of
observations whenever the exact number of hidden states of the HMMs is known.
Training the HMMs can be seen as a maximization problem of a criterion with the
fact that the matrices A, B and Π are stochastics. A number of different criteria exist
which can be used.
9.2.2. The criteria used in programming hidden Markov models
In the following, an optimal model for a given criterion is noted as λ∗and is used
to represent the set of HMMs that exist for a given number of hidden states N and a

222
Optimization in Signal and Image Processing
given number of symbols M. O is the sequence of observations that is to be learned.
During our research, we found that ﬁve different types of training criteria exist:
– the ﬁrst type of criteria is the maximization of the likelihood. The aim of these
criteria is to ﬁnd the HMM λ∗which validates the equation:
λ∗= arg max
λ∈Λ P(V = O|λ)
However, no speciﬁc or general methods exist for this type of criteria. Nevertheless,
the Baum-Welch (BW) algorithm [BAU 67] and the gradient descent algorithm
[KAP 98, GAN 99] make it possible, from an initial HMM, to improve it according
to the criterion. These algorithms converge and lead to the creation of local optima of
the criterion;
– the second type of criteria is the maximization of a posteriori probabilities. The
aim of these criteria is to determine the HMM λ∗which validates the equation:
λ∗= arg max
λ∈Λ P(λ|V = O)
This type of criteria, which is associated with the Bayesian decision theory [BER 98],
can be divided into a number of smaller criteria depending on the aspects of the
decision theory that are being investigated. The simplest forms of this criterion lead
to maximum likelihood problems. However, the more complex forms of this criterion
do not allow for this possibility. For the more complex forms it is possible to use a
gradient descent algorithm in order to investigate such issues. In all cases, the resulting
models are local optima of the criteria;
– The third type of criteria is the maximization of mutual information. The aim of
these criteria is to simultaneously optimize several HMMs with the aim of maximizing
the discrimination power of each HMM. This type of criteria has been used on several
occasions in several different forms [RAB 89, SCH 97, GIU 02, VER 04]. One of the
solutions that is available and which can be used to maximize these criteria is the use
of a gradient descent algorithm. Once again the results which are obtained are local
optima of the criteria.
– The fourth type of criteria is the minimization of classiﬁcation errors of the
observation sequences. Several forms of these criteria have been used [LJO 90,
GAN 99, SAU 00]. In the three previous types of criteria, the criteria are non-derivable
and they are also not continuous. In order to maximize the three previous types
of criteria, the criteria are usually approximated with derivable functions. Gradient
descent techniques are then used.
– The ﬁfth and ﬁnal type of criteria is segmental k-means criteria. The aim of these
criteria is to determine the HMM λ∗which validates the equation:
λ∗= arg max
λ∈Λ P

V = O, S = Q∗
λ | λ


The Use of Hidden Markov Models for Image Recognition
223
Q∗
λ is the sequence of hidden states which is obtained after the Viterbi algorithm
[VIT 67] has been applied to the HMM λ. As far as segmental k-means is concerned,
the aim is to ﬁnd the HMM which possesses the sequence of hidden states which
has been monitored the most. One of the main characteristics of this criterion is
that it is neither derivable nor continuous. One solution consists of approximating
the criterion by applying a derivable or at least a continuous function to it; however
developing such a solution for the moment is a difﬁcult task. It is possible, however,
to use the segmental k-means algorithm [JUA 90] to partially maximize this criterion.
The way in which this algorithm functions is similar to the way in which the
Baum-Welch algorithm functions for maximum likelihood. The segmental k-means
algorithm iteratively improves an original HMM and also makes it possible to ﬁnd a
local optimum of the criterion.
We have noticed that numerous criteria can be considered when it comes to training
HMM. The criteria which have been described in this section are not the only criteria
that can be used but they are the ones that are used the most often. For the majority of
these criteria there is at least one corresponding algorithm that exists and which can
be used in order to maximize the criteria. These algorithms, which are applied to an
initial model, lead to the creation of a new model which in turn improves the value
of the said criterion. This approach makes it possible to calculate a local optimum of
the criterion in question, but not a global optimum. In certain cases, a local optimum
is sufﬁcient, but this is not always the case. It is therefore necessary to be able to
ﬁnd optimal models, or at least ﬁnd models which resemble, from the point of view
of the criterion t an optimal solution of a criterion. One possibility consists of using
metaheuristics [DRE 03] with the aim of investigating and exploring HMMs.
9.3. Using metaheuristics to learn HMMs
The aim of this section is to describe the principal metaheuristics that are used to
train HMMs. Before we introduce the different metaheuristics, we believe that it is a
good idea to introduce the three different types of solution spaces which have been
used up until now.
9.3.1. The different types of solution spaces used for the training of HMMs
It is possible to consider three types of solution spaces which can be used to train
HMMs [AUP 05a]: Λ, ST and Ω. In order to describe the different solution spaces,
we consider HMMs possessing N hidden states and M symbols, and sequences of
observations O with a length of T.
9.3.1.1. Λ solution space
The Λ solution space is the solution space which is the most commonly used for
training HMMs. This type of solution space corresponds to the set of stochastic matrix

224
Optimization in Signal and Image Processing
triplets (A, B, Π) which deﬁne a HMM. Λ is therefore isomorphic to the Cartesian
product GN × (GN)N × (GM)N where GK is the set of all stochastic vectors with K
dimensions. GK possesses the fundamental property of being convex which implies
that Λ is also convex.
9.3.1.2. ST solution space
The ST solution space corresponds to the set of hidden state sequences where each
sequence is of length T. The fundamental properties of this type of solution space
are that it is discrete, ﬁnite and is composed of N T elements. An HMM is deﬁned
by its triplet of stochastic matrices, then any given solution of ST cannot be directly
used as an HMM. Instead, a labeled learning algorithm is used in order to transform
the hidden state sequence into an HMM. The labeled learning algorithm estimates
probabilities by computing frequencies. γ(Q) is the model which is created after the
labeled learning algorithm has been applied to the sequence of observations O and
to the sequence of states Q ∈ST . The set γ(ST ) = {γ(Q) | Q ∈ST } is a ﬁnite
subset of Λ. The function γ is neither injective, nor surjective and as a consequence it
is not possible to use an algorithm such as the Baum-Welch algorithm with this type
of solution.
9.3.1.3. Ω solution space
The Ω solution space was initially deﬁned with the aim of providing a vector space
structure for the training of HMMs [AUP 05a]. With this in mind, we consider the set
GK of stochastic vectors with K dimensions. We deﬁne G∗
K as a subset of stochastic
vectors with dimension K. None of the components of this subset have a value of zero,
in other words G∗
K = {x ∈GK | ∀i = 1 . . . K, xi > 0}. Therefore rK : RK →RK
is a regularization function which is deﬁned on RK by the following equation:
rK(x)i = xi −max
j=1...K xj
where rK(x)i is the ith component of the vector rK(x).
We deﬁne ΩK = rK(RK) = {x ∈RK | rK(x) = x} and three symmetric
operators ⊕K : ΩK × ΩK →ΩK, ⊙K : R × ΩK →ΩK and ⊖K : ΩK × ΩK →ΩK
so that for all values (x, y) ∈(ΩK)2 and c ∈R:
x ⊕K y = y ⊕K x = rK(x + y)
c ⊙K x = x ⊙K c = rK(c · x)
x ⊖K y = y ⊖K x = rK(x −y) = x ⊕

−1 ⊙K y

.
Then (ΩK, ⊕K, ⊙K) is a vector space. Let ψK : G∗
K →ΩK and φK : ΩK →
G∗
K two operators. These operators can transform the elements of G∗
K into elements

The Use of Hidden Markov Models for Image Recognition
225
of ΩK, and vice-versa with the help of the equations below (for all values of x ∈G∗
K
and for all values y ∈ΩK):
ψK(x)i = ln xi −max
j=1...K ln xj,
φK(y)i =
exp yi
K
j=1 exp yj
.
We deﬁne Ω as Ω = ΩN × (ΩN)N × (ΩM)N and Λ∗as G∗
N × (G∗
N)N × (G∗
M)N.
By generalizing the operators ⊕K, ⊙K, ⊖K, ψK and φK to the Cartesian products Ω
and Λ∗, and by removing the K index, we can prove that (Ω, ⊕, ⊙) is a vector space,
and that ψ(Λ∗) = Ω and φ(Ω) = Λ∗. It is also important to note that Λ∗⊂Λ.
9.3.2. The metaheuristics used for the training of the HMMs
The six main types of metaheuristics that have been adapted to the HMM
training problem are: simulated annealing [KIR 83], Tabu search [GLO 86,
GLO 89a, GLO 89b, HER 92, GLO 97], genetic algorithms [HOL 75, GOL 89],
population-based
incremental
learning
[BUL 94,
BUL 95],
ant-colony-based
optimization algorithms such as the API algorithm (API) [MON 00a, MON 00b] and
particle swarm optimization (PSO) [KEN 95, CLE 05].
As mentioned earlier in this chapter numerous metaheuristics have been used to
train HMMs. When some of the metaheuristics were applied to the HMMs it led
to the creation of several adaptations of these metaheuristics (see Table 9.1). These
adaptations were not all created with the aim of maximizing the same criterion2 and
they do not explore nor investigate the same solution space (see Table 9.1).
Algorithm/solution
Λ
ST
(Ω, ⊕, ⊙)
Simulated annealing
[PAU 85]
[HAM 96]
Tabu search
[CHE 04]
Genetic algorithm
[SLI 99, THO 02] [AUP 05a]
Incremental population-based learning
[MAX 99]
API
[MON 00a]
[AUP 05a] [AUP 05c]
Particle swarm optimization
[RAS 03]
[AUP 05b]
Table 9.1. Adaptations of the metaheuristics in relation to the three different
solution spaces used for training HMM
2. The criterion of maximum likelihood is, nevertheless, the criterion that is used the most.

226
Optimization in Signal and Image Processing
The use of these metaheuristics raises the issue of size: we do not know which
metaheuristic is the most efﬁcient. The metaheuristics have not been compared and
no normalized data set has been created which would make it possible to compare
the results of performance studies. Even if the data sets were normalized we would
still have to deal with the issue of understanding exactly how the algorithms are
parameterized. The parameters of the algorithms often correspond to a default choice
(or to an empirical choice) rather than corresponding to the best parameters that could
make up the algorithm, or at least to the parameters which guarantee a high quality
solution. In the next section we will go into more detail about the six adaptations of
the generic metaheuristics as well as setting them and ﬁnally comparing them with
the aim of overcoming some of the problems mentioned in this section. In order to
make this possible, we will take the criterion of maximum likelihood as well as the
data which comes from the images into consideration.
9.4. Description, parameter setting and evaluation of the six approaches that are
used to train HMMs
The algorithms which have been used in this study all consider the maximum
likelihood criterion. The six different approaches are the result of the adaptation to
the problem of the genetic algorithms, of the API algorithm and of the particle swarm
optimization algorithm.
9.4.1. Genetic algorithms
The genetic algorithm [HOL 75, GOL 89] which we have considered in this study
is the one that has also been described in [AUP 05a] and can also be seen in Figure 9.1.
This algorithm is the result of adding an additional mutation and/or optimization phase
of the parents to the GHOSP algorithm which is described in [SLI 99]. For the purpose
of our study we have taken two different adaptations of the genetic algorithm into
consideration.
The ﬁrst adaptation of the genetic algorithm uses solutions in Λ. We have called
this adaptation of the genetic algorithm AG-A. The chromosome which corresponds
to the λ = (A, B, Π) HMM is the matrix (Π A B) which is obtained by the
concatenation of the three stochastic matrices that describe the HMM. The selection
operator is an elitist selection operator. The crossover operator is a classical one
point (1X) crossover. It randomly chooses a horizontal breaking point within the
model (see Figure 9.2). The mutation operator is applied to each coefﬁcient with a
probability of pmut. Whenever the mutation operator is applied to a coefﬁcient h, the
mutation operator replaces the coefﬁcient h with the value (1 −θ)h and also adds the
quantity θh to another coefﬁcient. This other coefﬁcient is chosen at random and
can be found on the same line in the same stochastic matrix. For each mutation the
coefﬁcient θ is a number which is uniformly chosen from the interval [0; 1]. The
optimization operator then takes NBW iterations from the Baum-Welch algorithm and
applies them to the individual (person or child) that needs to be optimized.

The Use of Hidden Markov Models for Image Recognition
227
Total 
population
Selection
Parents
Parents
Children
(after optimization)
Children
(after mutation)
Children
(after breeding)
Crossover
Optimization
grouping together of parents and 
children populations and selection  
of the best individuals
Mutation
Mutation
Parents after 
a possible 
mutation phase
Parents after 
a possible 
optimization phase
Parent 
population
Figure 9.1. The principle of the genetic algorithm used in programming the HMMs
Parents
Horizontal breaking
point
Horizontal breaking
point
Children
Figure 9.2. The principle of the crossover operator (1X) which can be found
in the AG-A adaptation of the genetic algorithm
The second adaptation of the genetic algorithm uses the ST solution space in order
to ﬁnd an HMM. We have called this adaptation of the genetic algorithm AG-B. The
individuals are represented by a sequence of hidden states which label the sequence of
observations that need to be learned. The corresponding HMM is found thanks to the
use of a labeled learning algorithm (for the statistic estimation of the probabilities).
The selection operator which is used is once again the elitist selection operator. The

228
Optimization in Signal and Image Processing
crossover operator corresponds to the classical 1X operator of genetic algorithms that
use binary representation. The mutation operator modiﬁes each element from the
sequence of states with a probability of pmut. The modiﬁcation of an element from
the sequence involves replacing a state in the solution. The process of optimizing the
parents and the children is not carried out because of the non-bijectivity of the labeled
learning operator.
The parameters of the two algorithms are as follows: N (the size of the
population), pmut (the probability of mutation), MutateParents (do we apply the
mutation operator to the parent population?), OptimizeParents (do we apply the
optimization operator to the parent population?), and NBW (the number of iterations
which is taken from the Baum-Welch algorithm).
9.4.2. The API algorithm
The API algorithm [MON 00a, MON 00b] is an optimization metaheuristic which
was inspired by the way in which a population of primitive ants (Pachycondyla
apicalis) feed. Whenever the ants’ prey is discovered, this species of ant has the
ability to memorize the site at which the prey has been found (the hunting site). The
next time the ants leave the nest, they go back to the last site they visited as this is
the last one they remember. If, after a number of several different attempts (named as
local patience), the ants are unable to ﬁnd any new prey on the site they give up on the
site and do not use it in the future. From time to time the nest is moved to a hunting
site. The result of adapting these principles to the global optimization problem has
been called the API algorithm (see Algorithm 9.1).
The experiments described in [AUP 05a] show that factors such as the size of the
ant colony and the memory capacity of the ants are anti-correlated. As a result of this,
we assume that the size of the ant’s memory capacity is one.
In this chapter we deal with three adaptations of the API algorithm. In order to
specify the three different adaptations of the algorithm a deﬁnition of the initialization
operator which refers to the initial position of the nest has been given and we also
deﬁne the exploration operator.
The ﬁrst adaptation [MON 00a] of the API algorithm is known as API-A, and the
aim of this adaptation of the algorithm is to explore the Λ solution space. The choice
of the initial position of the nest is obtained by randomly choosing an HMM within the
set Λ. The exploration operator from an existing solution depends on one particular
parameter: the amplitude. If we take A as the amplitude, then the exploration operator
applies the function AMA to the coefﬁcients of the model:
AMA(x) =
⎧
⎪
⎨
⎪
⎩
−v
if v < 0
2 −v
if v > 1
v
if not
and v = x + A ·

2U

[0, 1[

−1


The Use of Hidden Markov Models for Image Recognition
229
Randomly choose the initial position of the nest
The memory of the ants is assumed as being empty
While there are still iterations that need to be executed do
For each of the ants do
If the ant has not chosen all of its hunting sites Then
The ant creates a new hunting site
If not
If the previous solution is unsuccessful Then
Randomly choose a new site to explore
If not
Choose the last site that was explored
End if
Find a solution around a new site to explore
If the new solution is better than the hunting site Then
Replace the hunting site with this solution
If not
If too many unsuccessful attempts Then
Forget about the hunting site
End if
End if
End if
End for
If it is time that the nest should be moved Then
Move the next to the best solution that has been found
Empty the memory of the ants
End if
End while
Algorithm 9.1. The API algorithm
U(X) is a random number which is chosen in the set X. NBW is the number of
iterations taken from the Baum-Welch algorithm. It is possible to apply these iterations
to the HMMs which are discovered by the exploration operator.
The second adaptation [AUP 05a] of the API algorithm is known as API-B, and
the aim is to explore the ST solution space. The selection operator, which chooses the
initial position of the nest, uniformly chooses each of the T states of the sequence
that exist in S. The local exploration operator which is associated with a solution
x, and which has an amplitude of A ∈[0; 1] modiﬁes the number of states L that
exist in the sequence x. The number of states L is calculated in the following way:

230
Optimization in Signal and Image Processing
L = min{A · T · U([0; 1]), 1}. The states to modify are uniformly chosen in the
sequence and their values are generated in S. The different positions (a.k.a. models)
explored are not optimized due to the non-bijectivity of the labeled learning operator.
The third adaptation [AUP 05a] of the API algorithm is called API-C and the aim
of this adaptation of the algorithm is to explore the Ω solution space. The generation
operator chooses the nest’s initial position uniformly in Λ∗. The exploration operator
for a solution x ∈Ω, and for an amplitude A chooses a solution with y = ψ(U(Λ∗))
by computing:
x ⊕

−ln U

]A; 1[

∥y∥max
⊙y

Note that ∥· ∥max is the traditional maximum distance (maxi |xi|).
The parameters of the algorithms are as follows: N (the size of the ant colony),
Ai
site (the amplitude of exploration around the nest in order to choose a hunting site),
Ai
local (the amplitude of exploration around a hunting site), TMovement (the number
of iterations that exists between two movements of the nest), emax (the number of
consecutive, unsuccessful attempts to ﬁnd a hunting site before giving up) and NBW
(the number of iterations taken from the Baum-Welch algorithm). Two different types
of amplitude parameters are also taken into consideration: a set of parameters which
is common to all of the ants (known as a homogenous parameters), and a set of
parameters which is speciﬁc to each ant (known as a heterogenous parameters). As
far as the heterogenous parameters are concerned, the following equations are used
for the ants i = 1 . . . N:
Ai
site = 0.01
" 1
0.01
i
N #
Ai
local = Ai
site/10.
9.4.3. Particle swarm optimization
Particle swarm optimization (PSO) [KEN 95, CLE 05] is a technique that is used
to make N particles move towards a particular set of solutions. At each instant of t,
each particle possesses an exact location which is noted as xi(t), as well as possessing
an exact speed of movement which is noted as vi(t). x+
i (t) is used to refer to the best
position that is ever found by the particle i for a given instant of t. Vi(t) is used to
refer to the set of particles which can be found in the neighborhood of the particle i.
ˆxi(t) is used to refer to the position of the best particle of Vi(t), in other words:
ˆxi(t) = arg max
xj∈Vi(t) f

ˆxj(t −1)

.

The Use of Hidden Markov Models for Image Recognition
231
Nest exit
(path towards a hunting site)
Hunting sites
Explored solutions
Hunting
perimeter
Perimeter for exploration 
around a hunting site
Nest
Figure 9.3. The principle of the exploration techniques of an ant used in the API algorithm
This equation refers to the maximization of the criterion f. Traditional PSO is
controlled by three different coefﬁcients which are ω, c1 and c2. These different
coefﬁcients all play a role in the equations which refer to the movement of the
particles. ω controls the movement’s inertia, c1 controls the cognitive component of
the equations and c2 controls the social component of the equations.
The adaptation of PSO algorithm which we have used in our study aims at ﬁnding
a HMM model within the Ω solution space. The corresponding algorithm is shown in
Algorithm 9.2.
The parameters of the algorithms are as follows: N (number of particles), ω
(parameter of inertia), c1 (cognitive parameter), c2 (social parameter), V (size of the
particles’ neighborhood) and NBW (number of iterations taken from the Baum-Welch
algorithm). The neighborhood of a particular particle can be compared to a social
neighborhood that is divided into rings. Whenever the size of the neighborhood is V
for a particular instant of t, the ith particle’s neighborhood Vi(t) is said to be constant
and equal to Vi. Whenever the particles form a circular shape then Vi is made up of
the V/2 particles which precede the particle itself and of the V/2 particles which
come after the particle. Figure 9.4 shows what a size two neighborhood looks like for
particles one and ﬁve.

232
Optimization in Signal and Image Processing
For all particles of i do
xi(0) = U(ψ(Λ))
vi(0) = U(ψ(Λ))
x+
i (0) = xi(0)
End for
While there remains any iterations that need to be carried out do
// Movement of particles
For each particle do
x′ = xi(t −1) ⊕vi(t −1)
// movement
xi(t) = ψ(BW(φ(x′)))
// optimization
vi(t) = xi(t) ⊖xi(t −1)
// effective movement calculation
If P

V = O | φ(xi(t))

> P

V = O | φ

x+
i (t −1)

Then
x+
i (t) = xi(t)
If not
x+
i (t) = x+
i (t −1)
End if
End for
// update speeds
For each particle do
Calculate neighborhood Vi(t) with time t
ˆxi(t) = xj(t)+ with j = arg maxk∈Vi(t) P(V = O|φ(x+
k (t)))
vi(t) = ω ⊙vi(t −1)
⊕

c1 · U([0, 1])

⊙

x+
i (t) ⊖xi(t)

⊕

c2 · U([0, 1])

⊙
ˆxi(t) ⊖xi(t)

End for
End while
Algorithm 9.2. Adaptation of the PSO algorithm
Figure 9.4. An example of a circular neighborhood used in PSO

The Use of Hidden Markov Models for Image Recognition
233
9.4.4. A behavioral comparison of the metaheuristics
The algorithms that have been mentioned in this section are based on
metaheuristics which use other techniques that are used to explore different solution
space. These metaheuristics are made up of a population of agents which interact with
one another with the aim of being able to ﬁnd the best solution possible. These agents
interact with one another using different methods and different individuals and they
do this at different times. The interactions which take place within a genetic algorithm
are carried out by crossing the best quality solutions with one another and this is
made possible by exchanging and sharing the genes of the solutions at each iteration
of the algorithm. With this in mind, and if the codes of the adapted genes are present,
it becomes possible for each iteration that occurs within the algorithm to transfer the
best characteristics from the parent solutions to the child. In PSO the interaction of
the different agents takes place at each iteration of the algorithm thanks to the updates
of the velocity vectors. However, it is not possible to transfer the best characteristics
of the particles such as the position of the particle. Instead of this, PSO looks for the
best particles that exist within a particle’s neighborhood. The API algorithm uses
an extremely different approach: the agents only interact with each other whenever
the nest is moved. This type of interaction can be referred to as a direct interaction
in the sense that the nest is a solution which is made available to each of the ants.
Each of these approaches has its advantages and disadvantages. Interacting with each
of the iterations, as is the case for the genetic algorithm and for the PSO algorithm,
makes it possible to ﬁnd the correct solutions in the quickest time possible. However,
this frequency of interaction runs the risk of all of the agents moving in the same
direction, which in turn reduces the diversity of the exploration process. In addition,
if the agents ﬁnd several similar solutions as far as the criterion of optimization
is concerned, it becomes highly possible that poles of attraction will be created.
This in turn means that the agents will only move between these poles and that any
explorations that were carried out before the creation of these poles will be lost.
However, it is sometimes necessary to concentrate the exploration efforts on several
poles in order to guarantee the creation of an optimal or almost optimal solution.
On the other hand, rare interactions can also occur and this is the case with the API
algorithm. Such interactions can reduce the effectiveness of the search for an optimal
solution since the research that is carried out is blind research, with no knowledge of
the remaining solutions that are available. However, this rarity of interactions can
also turn out to be advantageous because these rare interactions reduce the number
of iterations that the agents need to consider before making a decision as to what
pole they will move towards. The decision is made as soon as the nest is moved. This
type of quick decision making can also turn out to be damaging in certain cases. In
all of the examples that have been mentioned in this section, the moment when a
decision is made (the interaction) can be an advantage or a disadvantage depending
on the characteristics of the type of solutions involved. Hesitating between several
solutions is better when we want to ﬁnd the maximum optimal solution but this idea
of hesitating between several solutions can reduce the speed at which the algorithm

234
Optimization in Signal and Image Processing
converges. The search for an optimal solution is carried out for each of the algorithms
by a process of guided random research. In the case of the genetic algorithm, this
search for the optimal solution is carried out by the mutation operator and in the
case of the API algorithm it is carried out by the local exploration operator. These
two different operators play similar roles. In the PSO algorithm the search for an
optimal solution is carried out thanks to random contributions which come from the
individual components of the algorithm whenever the velocity vectors are updated. In
the genetic algorithm the search for an optimum solution is carried out by statistically
reinforcing the zones that we are interested in exploring thanks to the use of the
elitist selection operator. Each individual solution is part of the sample which is
taken around the zone that we are interested in exploring. In the PSO algorithm the
solutions are exploited by analyzing the spatial density of the particles which exist
around the correct solutions. The exploitation of the solutions in the API algorithm is
carried out by using two pieces of information: the position of the nest and the way
in which the ants forage for food around a hunting site. These two mechanisms can
be seen as a hierarchical reinforcement around the zones which we are interested
in exploring. The nest determines the focal point around the zone, and around
which the ants establish their hunting sites. The hunting site of an ant determines
the zone in which it will search for its prey. The API algorithm has the capacity to
do something which the other two algorithms are incapable of doing, which is that
the API algorithm is able to forget about the exploration sites which proved to be
unsuccessful. This is possible thanks to the API’s patience on the exploration sites
and to its patience on waiting for the nest to be moved. The ability to do this is a
huge advantage for the API algorithm since it can abandon a non-proﬁtable zone and
concentrate on another zone with the aim of not wasting any effort.
9.4.5. Parameter setting of the algorithms
The explanation of the experimental study that was carried out in relation to how
these six approaches can be used to train a HMM is divided into two phases. The ﬁrst
phase involves carrying out a search for parameters on a reduced set of data. After
this is complete, we will use the conﬁgurations of these parameters to evaluate the
performance of the algorithms when they are applied to a bigger set of data.
DEFINITION 9.2. Let fA,X be the probability distribution of the random variable
which measures the performance of the algorithm A for a ﬁxed conﬁguration of X
parameters. Let be Δv=x = (∗, . . . , ∗, v = x, ∗, . . . , ∗) the set of conﬁgurations of
parameters for which the parameter v has a value x. The probability distribution
fA,Δv=x is deﬁned as:
fA,Δv=x =
1
Δv=x


X∈Δv=x
fA,X

The Use of Hidden Markov Models for Image Recognition
235
A conﬁguration X = (x1, . . . , xK) of parameters for a stochastic algorithm A is said
to be strong, if for every value xi, the probability distribution fA,Δvi=xi has a high
mean and a reduced standard deviation.
Let EG = {(e1, g1), . . . , (eL, gL)} be a set of samples so that ei is a conﬁguration
of Δv=x parameters and gi is the measurement of the conﬁguration’s performance.
The probability distribution fA,Δv=x can be approximated by the following probability
distribution:
1
|EG|

(e,g)∈EG
N(g, σ)
where N(m, s) is the normal distribution of mean m and of standard-deviation s and
considering the following equation:
σ = 0.1 ·
"
max
(e,g)∈EG g −
min
(e,g)∈EG g
#
Figure 9.5 shows the probability distributions which are the result of ﬁve different
mutation rates which have been applied to the ﬁrst image which can be seen in
Figure 9.7 by using the AG-B algorithm.
 0
 0.0001
 0.0002
 0.0003
 0.0004
 0.0005
 0.0006
 0.0007
−1500
−1400
−1300
−1200
−1100
−1000
−900
−800
−700
 P(V=O|λ)
0
0.01
0.1
0.3
0.5
Mutation rate:
Approximate probability of appearance
Logarithm of
Figure 9.5. Approximate distributions showing the probabilities of certain performances
appearing, taking into consideration ﬁve different mutation rates for the AG-B algorithm

236
Optimization in Signal and Image Processing
In order to determine the conﬁgurations of the strong parameters, we only need to
compare the probability distributions. With the aim of carrying out a fair comparison
of the algorithms, we have considered the conﬁgurations of parameters which provide
the same opportunities to all the algorithms. Whenever the Baum-Welch algorithm
is not used, the algorithms are able to evaluate approximately 30,000 HMMs (i.e.
30,000 uses of the forward algorithm). Whenever the Baum-Welch algorithm is used,
the algorithms are able to carry out approximately 1,000 iterations of the Baum-Welch
algorithm (2 or 5 iterations are carried out for each explored solution). The data that
we have used for these experiments was obtained from images of faces taken from
the ORL database [SAM 94]. The four faces which can be seen in Figure 9.7 are the
faces that were used. These images are in 256 gray-level. We have recoded them into
32 gray-level and they have been linearized into gray-level sequences (see Figure 9.6).
K
K
K
Figure 9.6. The principle of coding an image into a sequence
of observations with blocks of 10×10 pixels
Figure 9.7. The ﬁrst faces of the ﬁrst four people from the ORL image database [SAM 94]
Several different parameter settings have been taken into consideration for all
of the conditions that have been mentioned above. The parameter settings that we
obtained from the four images in Figure 9.7 are given in Table 9.2.

The Use of Hidden Markov Models for Image Recognition
237
Genetic Algorithms
NBW
N
pmut
MutateParents
OptimizeParents
AG-A1
0
5
0.01
No
No
AG-A2
2
5
0.3
Yes
Yes
AG-A3
2
20
0.3
No
Yes
AG-A4
5
20
0.5
Yes
Yes
AG-A5
5
5
0.5
No
Yes
AG-B
N/A
5
0.01
No
N/A
API Algorithm
NBW
N
Ai
local
Ai
site
emax
Tmovement
Type of parameter
API-A1
0
50
0.1
0.1
1
15
Homogenous
API-A2
2
5
0.1
0.1
4
15
Homogenous
API-A3
5
20
0.1
0.1
4
15
Homogenous
API-A4
0
2
N/A
N/A
5
10
Heterogenous
API-A5
2
5
N/A
N/A
4
15
Heterogenous
API-A6
5
5
N/A
N/A
3
5
Heterogenous
API-B1
0
2
0.2
0.1
1
5
Homogenous
API-B2
0
2
N/A
N/A
1
5
Heterogenous
API-C1
0
2
0.9
0.8
1
5
Homogenous
API-C2
2
20
0.1
0.2
4
5
Homogenous
API-C3
5
50
0.1
0.2
4
15
Homogenous
API-C4
0
2
N/A
N/A
5
4
Heterogenous
API-C5
2
20
N/A
N/A
2
5
Heterogenous
API-C6
5
50
N/A
N/A
1
20
Heterogenous
PSO
NBW
N
ω
c1
c2
V
OEP1
0
20
0.8
1.5
2.5
9
OEP2
2
20
0.8
1.5
0
N/C
OEP3
5
50
0.4
0
0.5
6
N/A means non-applicable. N/C means uncharacteristic.
Table 9.2. The conﬁgurations of the parameters
9.4.6. Comparing the algorithms’ performances
In order to compare the algorithms with the conﬁgurations of the parameters, we
decided to use four sets of images with each set of images being made up of between
four and ten images. The characteristics of the sets of the images that were used can
be seen in Table 9.3.

238
Optimization in Signal and Image Processing
Database
Content
Dimension (in pixels)
Grey level
[TCD 06]
Flowers
110 × 125
32
[TEX 06]
Patterns
100 × 100
2
[AGA 04]
Countryside
100 × 40
8
[AGA 04]
Cars
[120; 266] × [73; 176]
8
Table 9.3. Characteristics of the images used for programming the HMMs
In order to compare the effectiveness of the metaheuristics with a traditional
approach we used algorithms Random0, Random2 and Random5. 30,000 HMMs
were randomly chosen in the Λ solution space for algorithm Random0. The result of
this algorithm is the best model that has been explored. For algorithms Random2
and Random5 we explored between 500 and 200 random HMMs. We then applied
two or ﬁve iterations from the Baum-Welch algorithm to each random HMMs. We
considered HMMs which had 10 and 40 hidden states.
Each image is transformed into a sequence by following the same principles that
are used for setting the algorithms. The images are learned several times and the mean
likelihood logarithm is computed. m(I, A) is the mean for an image I and for an
algorithm A. If we note A as the set of algorithms that must be compared, then e(I, A)
can be deﬁned as follows:
e(I, A) =
m(I, A) −minX∈A m(I, X)
maxX∈A m(I, X) −minX∈A m(I, X)
The number e(I, A) measures the efﬁciency of algorithm A on a scale from zero
to one for the image I. The most effective algorithm leads to e(I, A) = 1 and the least
effective algorithm leads to e(I, A) = 0. In order to compare all of the algorithms
with one another we suggest that the measurement ¯e(A) is used. Let I be the set of
images that are used. Then, we deﬁne:
¯e(A) = 1
|I|

I∈I
e(I, A).
Table 9.4 shows the results of the experiment. As we can see, the algorithms are
divided into three groups. The ﬁrst group is made up mainly of those algorithms which
do not use the Baum-Welch algorithm. These algorithms tend not to perform as well
as those algorithms which do use the Baum-Welch algorithm. We can also note that
algorithm API-A1 provides worse statistics than if we were to carry out purely random
research. It would seem that there is less chance of ﬁnding a good model by carrying
out a poorly guided exploration of the different types of solutions than if a completely
random exploration of the solutions were to be carried out. This example shows that

The Use of Hidden Markov Models for Image Recognition
239
it is necessary to carry out a comparative study of the metaheuristics if they are to be
used to train the HMMs. The second group of algorithms contains those algorithms
which have an average performance level (from 44.31% to 85.94%). The ﬁnal group of
algorithms contains the highest performing and the most effective algorithms. As we
can see, these algorithms use two or ﬁve iterations from the Baum-Welch algorithm
(but not all in the same way), and they search for HMMs in the Λ and Ω solution
spaces. We can also see that as the performance of the algorithms increases and the
lower the variability: their standard deviation decreases.
algorithm A
¯e(A) average
Standard deviation
NBW
Solution space
API-A1
0.13%
0.53%
0
Λ
Random0
10.86%
5.07%
0
Λ
API-B1
13.07%
9.77%
0
ST
AG-B
16.48%
12.16%
0
ST
API-B2
19.05%
12.43%
0
ST
API-A4
20.38%
7.97%
0
Λ
OEP1
44.31%
12.65%
0
Ω
Random2
66.60%
7.07%
2
Λ
API-C4
78.39%
3.72%
0
Ω
API-A2
82.17%
9.95%
2
Λ
Random5
82.29%
7.03%
5
Λ
API-C1
85.68%
5.60%
0
Ω
AG-A1
89.80%
6.84%
0
Λ
API-A3
90.13%
9.21%
5
Λ
AG-A2
93.84%
5.11%
2
Λ
AG-A4
95.94%
3.77%
5
Λ
AG-A5
97.66%
2.11%
5
Λ
API-C6
98.32%
1.37%
5
Ω
API-C3
98.38%
1.62%
5
Ω
API-C5
98.50%
1.48%
2
Ω
OEP3
98.71%
1.70%
5
Ω
AG-A3
98.72%
1.45%
2
Λ
API-C2
98.88%
1.14%
2
Ω
API-A5
98.89%
1.02%
2
Λ
OEP2
99.34%
0.87%
2
Ω
API-A6
99.74%
0.32%
5
Λ
Table 9.4. A measurement of the algorithms’ efﬁciency

240
Optimization in Signal and Image Processing
9.5. Conclusion
In this chapter we have discussed the problem of learning HMMs using
metaheuristics. First of all, we introduced the HMMs and the traditional criteria
that were used to train them. We also introduced the different types of solution
spaces which are available nowadays, and which can be used to train the HMMs.
The fact that there are different types of solution spaces available is a fact that
is too often forgotten. The three types of search spaces that we investigated are
complementary representations and include: a discrete representation (ST ), a
continuous representation (Λ) and a vector-space representation (Ω).
Our experiments have shown that there is less chance of ﬁnding a good HMM in
the ST solution space in comparison to the two other types of solution spaces, Λ and
Ω; or at least this is the case with the search methods we used.
The use of metaheuristics for training HMMs has already been investigated and
many encouraging results were found. In this chapter we introduced a comparative
study which was inspired by three biologically-inspired approaches. Each approach
focuses on a particular population of solutions. We have concentrated our comparison
on one critical point, a point which can easily be analyzed and critiqued, i.e. the choice
of parameters. We have tried to conﬁgure our algorithms in as fair a way as possible.
However, we must bear in mind that the results and conclusions that we have obtained
depend on the particular area of study that we chose to investigate, in other words, the
training of sequences created from images whilst considering the maximum likelihood
as the training criterion.
Our ﬁndings have also shown that a moderate use of a local optimization method
(which in our case is the Baum-Welch algorithm) is in fact able to improve the
performance of the metaheuristics that we chose to investigate.
The conclusions which can be drawn from this experimental study have led to new
questions that need to be answered: is it possible to apply the results that we have
found to other domains of study? Is it possible to apply the results to other criteria and
to other metaheuristics? We strongly believe that it is best to act carefully when trying
to answer such questions and to avoid too much generalization. We hope that this
study can act as a framework for any future and more rigorous comparative studies.
9.6. Bibliography
[AGA 04] AGARWAL S., AWAN A. and ROTH D., “Learning to detect objects in images via
a sparse, part-based representation”, IEEE Transactions on Pattern Analysis and Machine
Intelligence, vol. 26, no. 11, pp. 1475–1490, 2004.

The Use of Hidden Markov Models for Image Recognition
241
[AUP 05a] AUPETIT S., Contributions aux modèles de Markov cachés: métaheuristiques
d’apprentissage, nouveaux modèles et visualisation de dissimilarité, PhD Thesis,
Department of Information Technology, University of Tours, Tours, France, 30th November
2005.
[AUP 05b] AUPETIT S., MONMARCHÉ N. and SLIMANE M., “Apprentissage de modèles
de Markov cachés par essaim particulaire”, BILLAUT J.-C. and ESSWEIN C. (Eds.),
ROADEF’05: 6th Conference of the French Society of Operational Research and Decision
Theory, vol. 1, pp. 375–391, François Rabelais University Press, Tours, France, 2005.
[AUP 05c] AUPETIT S., MONMARCHÉ N., SLIMANE M. and LIARDET S., “An exponential
representation in the API algorithm for hidden Markov models training”, Proceedings of the
7th International Conference on Artiﬁcial Evolution (EA’05), Lille, France, October 2005,
CD-Rom.
[BAU 67] BAUM L.E. and EAGON J.A., “An inequality with applications to statistical
estimation for probabilistic functions of Markov processes to a model for ecology”, Bull
American Mathematical Society, vol. 73, pp. 360–363, 1967.
[BAU 72] BAUM L.E., “An inequality and associated maximisation technique in statistical
estimation for probabilistic functions of Markov processes”, Inequalities, vol. 3, pp. 1–8,
1972.
[BER 98] BERTHOLD M. and HAND D.J. (Eds.), Intelligent Data Analysis: An Introduction,
Springer-Verlag, 1998.
[BUL 94] BULAJA S., Population-based incremental learning: a method for integrating genetic
search based function optimization and competitive learning, Report no. CMU-CS-94-163,
Carnegie Mellon University, 1994.
[BUL 95] BULAJA S. and CARUANA R., “Removing the genetics from the standard genetic
algorithm”, in PRIEDITIS A. and RUSSEL S. (Eds.), The International Conference on
Machine Learning (ML’95), San Mateo, CA, Morgan Kaufman Publishers, pp. 38–46, 1995.
[CAP 01] CAPPÉ O., “Ten years of HMMs”, http://www.tsi.enst.fr/cappe/docs/hmmbib.html,
March 2001.
[CHE 04] CHEN T.-Y., MEI X.-D., PAN J.-S. and SUN S.-H., “Optimization of HMM by
the Tabu search algorithm”, Journal Information Science and Engineering, vol. 20, no. 5,
pp. 949–957, 2004.
[CLE 05] CLERC M., L’optimisation par Essaims Particulaires: Versions Paramétriques et
Adaptatives, Hermes Science, Paris, 2005.
[DRE 03] DREO J., PETROWSKI A., SIARRY P. and TAILLARD E., Métaheuristiques pour
l’Optimisation Difﬁcile, Eyrolles, Paris, 2003.
[DUG 96] DUGAD R. and DESAI U.B., A tutorial on hidden Markov models, Report
no. SPANN-96.1, Indian Institute of Technology, Bombay, India, May 1996.
[FOR 73] FORNEY JR. G.D., “The Viterbi algorithm”, Proceedings of IEEE, vol. 61,
pp. 268–278, March 1973.
[GAN 99] GANAPATHIRAJU A., “Discriminative techniques in hidden Markov models”,
Course paper, 1999.

242
Optimization in Signal and Image Processing
[GIU 02] GIURGIU M., “Maximization of mutual information for training hidden Markov
models in speech recognition”, 3rd COST #276 Workshop, Budapest, Hungary, pp. 96–101,
October 2002.
[GLO 86] GLOVER F., “Future paths for integer programming and links to artiﬁcial
intelligence”, Computers and Operations Research, vol. 13, pp. 533–549, 1986.
[GLO 89a] GLOVER F., “Tabu search – part I”, ORSA Journal on Computing, vol. 1, no. 3,
pp. 190–206, 1989.
[GLO 89b] GLOVER F., “Tabu search – part II”, ORSA Journal on Computing, vol. 2, no. 1,
pp. 4–32, 1989.
[GLO 97] GLOVER F. and LAGUNA M., Tabu Search, Kluwer Academic Publishers, 1997.
[GOL 89] GOLDBERG D.E., Genetic Algorithms in Search, Optimization and Machine
Learning, Addison-Wesley, 1989.
[HAM 96] HAMAM Y. and AL ANI T., “Simulated annealing approach for Hidden Markov
Models”, 4th WG-7.6 Working Conference on Optimization-Based Computer-Aided
Modeling and Design, ESIEE, France, May 1996.
[HER 92] HERTZ A., TAILLARD E. and DE WERRA D., “A Tutorial on tabu search”,
Proceedings of Giornate di Lavoro AIRO’95 (Enterprise Systems: Management of
Technological and Organizational Changes), pp. 13–24, 1992.
[HOL 75] HOLLAND J.H., Adaptation in Natural and Artiﬁcial Systems, University of
Michigan Press: Ann Arbor, MI, 1975.
[JUA 90] JUANG B.-H. and RABINER L.R., “The segmental k-means algorithm for
estimating parameters of hidden Markov models”, IEEE Transactions on Acoustics, Speech
and Signal Processing, vol. 38, no. 9, pp. 1639–1641, 1990.
[KAP 98] KAPADIA S., Discriminative training of hidden Markov models, PhD Thesis,
Downing College, University of Cambridge, 18 March 1998.
[KEN 95] KENNEDY J. and EBERHART R., “Particle swarm optimization”, Proceedings of
the IEEE International Joint Conference on Neural Networks, vol. 4, IEEE, pp. 1942–1948,
1995.
[KIR 83] KIRKPATRICK S., GELATT C.D. and VECCHI M.P., “Optimizing by simulated
annealing”, Science, vol. 220, no. 4598, pp. 671–680, 13 May 1983.
[LJO 90] LJOLJE A., EPHRAIM Y. and RABINER L.R., “Estimation of hidden Markov
model parameters by minimizing empirical error rate”, IEEE International Conference on
Acoustic, Speech, Signal Processing, Albuquerque, pp. 709–712, April 1990.
[MAR 13] MARKOV A.A., “An example of statistical investigation in the text of “Eugene
Onyegin” illustrating coupling of “tests” in chains”, Proceedings of Academic Scienctiﬁc
St. Petersburg, VI, pp. 153–162, 1913.
[MAX 99] MAXWELL B. and ANDERSON S., “Training hidden Markov models using
population-based learning”, BANZHAF W., DAIDA J., EIBEN A.E., GARZON M.H.,
HONAVAR V., JAKIELA M. and SMITH R.E. (Eds.), Proceedings of the Genetic and
Evolutionary Computation Conference (GECCO’99), vol. 1, Orlando, Florida, USA,
Morgan Kaufmann, p. 944, 1999.

The Use of Hidden Markov Models for Image Recognition
243
[MON 00a] MONMARCHÉ N., Algorithmes de fourmis artiﬁcielles: applications à la
classiﬁcation et à l’optimisation, PhD Thesis, Department of Information Technology,
University of Tours, 20th December 2000.
[MON 00b] MONMARCHÉ N., VENTURINI G. and SLIMANE M., “On how Pachycondyla
apicalis ants suggest a new search algorithm”, Future Generation Computer Systems,
vol. 16, no. 8, pp. 937–946, 2000.
[PAU 85] PAUL D.B., “Training of HMM recognizers by simulated annealing”, Proceedings
of IEEE International Conference on Acoustics, Speech and Signal Processing, pp. 13–16,
1985.
[RAB 89] RABINER L.R., “A tutorial on hidden Markov models and selected applications in
speech recognition”, Proceedings of the IEEE, vol. 77, no. 2, pp. 257–286, 1989.
[RAS 03] RASMUSSEN T.K. and KRINK T., “Improved hidden Markov model training for
multiple sequence alignment by a particle swarm optimization – evolutionary algorithm
hybrid”, BioSystems, vol. 72, pp. 5–17, 2003.
[SAM 94] SAMARIA F. and HARTER A., “Parameterisation of a stochastic model for
human face identiﬁcation”, IEEE Workshop on Applications of Computer Vision, Florida,
December 1994.
[SAU 00] SAUL L. and RAHIM M., “Maximum likelihood and minimum classiﬁcation error
factor analysis for automatic speech recognition”, IEEE Transactions on Speech and Audio
Processing, vol. 8, no. 2, pp. 115–125, 2000.
[SCH 97] SCHLUTER R., MACHEREY W., KANTHAK S., NEY H. and WELLING L.,
“Comparison of optimization methods for discriminative training criteria”, EUROSPEECH
’97, 5th European Conference on Speech Communication and Technology, Rhodes, Greece,
pp. 15–18, September 1997.
[SLI 99] SLIMANE M., BROUARD T., VENTURINI G. and ASSELIN DE BEAUVILLE J.-P.,
“Apprentissage non-supervisé d’images par hybridation génétique d’une chaîne de Markov
cachée”, Signal Processing, vol. 16, no. 6, pp. 461–475, 1999.
[TCD 06] “T.C. Design, Free Background Textures, Flowers”, http://www.tcdesign.net/
free_textures_ﬂowers.htm, January 2006.
[TEX 06] “Textures
Unlimited:
Black
&
white
textures”,
http://www.geocities.com/
texturesunlimited/blackwhite.html, January 2006.
[THO 02] THOMSEN R., “Evolving the topology of hidden Markov models using evolutionary
algorithms”, Proceedings of Parallel Problem Solving from Nature VII (PPSN-2002),
pp. 861–870, 2002.
[VER 04] VERTANEN K., An overview of discriminative training for speech recognition,
Report, University of Cambridge, 2004.
[VIT 67] VITERBI A.J., “Error bounds for convolutionnal codes and asymptotically optimum
decoding algorithm”, IEEE Transactions on Information Theory, vol. 13, pp. 260–269,
1967.

Chapter 10
Biological Metaheuristics for Road
Sign Detection
10.1. Introduction
The automatic detection and recognition of trafﬁc signs in road scenes has
received particular attention for the past two decades, especially in the context of
driver assistance systems design. Aimed at performing in real time, the methods
which have been developed until now generally combine a segmentation phase based
on color or shape and a classiﬁcation phase. Despite the excellent performances
asserted by certain authors, these algorithms remain sensitive to occultation by other
components of the road scene. Moreover, color information is highly dependent on
the wear and tear of trafﬁc signs, as well as on the illumination conditions. With
this in mind, it is difﬁcult to ensure that the results of the segmentation phase are
completely reliable [GAV 99]. Characteristics linked to the gradient of the images are
also sensitive to image perturbations. Any error at this stage is indeed comparable to
a partial occultation of the sought object: the characteristics of the segmented objects
are distorted and the classiﬁcation process becomes much more difﬁcult.
In this chapter, we consider a different application, namely trafﬁc sign inventory
from large road scene databases. Such image databases are created by inspection
vehicles driving around the French road network. The images are taken by standard
numerical cameras under natural illumination conditions. The main area of interest
of these inventories is the French secondary road network, the longest network. On
the one hand, difﬁcult situations such as illumination variations, backlights, worn-out
Chapter written by Guillaume DUTILLEUX and Pierre CHARBONNIER.
Optimization in Signal and Image Processing 
Edited by Patrick Siarry 
Copyright 0 
2009, ISTE Ltd 

246
Optimization in Signal and Image Processing
or occulted signs occur more frequently in this context than on the French national
road network or on French motorways. On the other hand, the images may be
processed off-line, hence the real-time constraint can be relaxed and a more robust
technique, belonging to the family of deformable models [GRE 89, AMI 91] can be
used. The principle of the method consists of using a mathematical model, which is a
prototype of the sought object, and distorting and translating it until it ﬁts the sought
object in the analyzed image. The quality of adjustment and the acceptability of the
necessary deformation are measured, in the Bayesian framework, by a likelihood and
a prior value, respectively. Localizing a particular object of interest then becomes an
optimization problem in the maximum a posteriori (MAP) framework. The residual
value of the optimized function gives an indication of whether the object is present in
the image which has been analyzed, or not.
In practice it is quite difﬁcult to deal with such an optimization problem
which is characterized by the presence of numerous local minima. Therefore, the
optimization should not be dealt with by using traditional numerical methods, such
as the conjugate gradient or the simplex method. In this chapter we propose to use
biological metaheuristics, i.e. methods inspired from biological mechanisms.
The following sections deal ﬁrst with the state of the art of automatic road sign
detection. The components of the functional to be minimized are deﬁned in the
following section. The third section gives a brief introduction to algorithms which
have not been dealt with elsewhere in this book. The ﬁnal section of the chapter
proposes a systematic evaluation of the method over a representative image sequence.
The individual performances of the different algorithms are also compared.
10.2. Relationship to existing works
In this section, we propose a brief overview of vertical road sign detection
algorithms. Generally speaking, it is possible to distinguish between three different
categories of methods. The ﬁrst uses the appearance of the road sign, i.e. the values of
the pixels, without any initial segmentation. For example, in [BET 95] a transformed
image is obtained by applying an anisotropic scaling and a rotation to a gray-level
prototype image, and by translating it onto the analyzed image. A simulated annealing
maximizes the normalized correlation between the deformed prototype and the
analyzed image, with respect to the ﬁve parameters of the geometric transformation.
Since the research undertaken by Moghaddam and Pentland [MOG 97], active
appearance models have turned out to be quite successful when it comes to detecting
and recognizing faces or objects. The reasons for their success are that they make
it possible to represent classes of objects and that they also allow us to take into
account different variations of the shape, orientation or illumination. In addition, the
similarity measures involved in appearance-based methods can be made robust to
partial occultation [DAH 04]. However, such methods require a relatively signiﬁcant
amount of processing time.

Biological Metaheuristics for Road Sign Detection
247
The second type of methods, possibly the most widespread one, combines a
segmentation phase with a classiﬁcation phase, according to a traditional framework
in pattern recognition. A great variety of methods have been proposed. For further
information about these methods, the reader should see [LAL 95] and more recent
states of the art in e.g. [ESC 04] or [LOY 04]. It is possible to distinguish between
two sub-categories of approaches. Approaches which are based on color use, most
of the time, color representations that do not depend on the luminance to tackle
the problem of illumination variation. Approaches which are based on contour
information use either a traditional detection-closing-analysis scheme, or Hough’s
transform (or one of its variants). Other voting techniques such as Loy’s Fast Radial
Symmetry Transform [LOY 02] and its extension to the analysis of polygonal objects
[LOY 04] have started to be used more recently. A major disadvantage of all of these
methods which depend heavily on the quality of segmentation, is that they are very
sensitive to occultation as well as to appearance variations.
The third type of methods is the deformable model method, which in some way is
an intermediate category between the above-mentioned two families. The principle of
deformable models it to adjust a prototype onto the image, as is the case with the ﬁrst
type of methods mentioned above. The object representation involved in deformable
models however is simpler; most of the time, only the outline of the object is used.
As is the case with the second type of methods, the image which is analyzed is a
simpliﬁed version of the original image obtained by a rough segmentation process,
also called pre-segmentation, whose purpose is to extract characteristics that allow
shape adjustment. These characteristics may be contaminated by noise or can be
incomplete, which is counterbalanced by the use of a model. In [GAV 99] a distance
transform [BOR 88] is calculated from the contours extracted from the image. This
distance map is then matched with the same representation calculated beforehand
within a hierarchy of shape prototypes. The algorithm applies a multi-scale strategy
with the aim of reducing the processing time of the segmentation. In [AOY 96] the
pre-segmentation phase leads to the creation of an edge map by Laplacian ﬁltering
and thresholding. A genetic algorithm is then used to detect speed limit road signs
by adjusting a circular prototype. Deformable models were also used to classify
silhouettes of vehicles [JOL 96]. The pre-segmentation process consists of computing
image gradients and a rough motion analysis from successive images. A functional
is deﬁned in a Bayesian framework, which combines an a priori on admissible
deformations and a likelihood term computed from the pre-segmentation maps. The
optimization is carried out using a global algorithm, namely, a simulated annealing.
In a similar philosophy, a hybrid method combining a genetic algorithm with a local
gradient descent was used to successfully detect shadows in sonar images [MIG 00].
Our research has been inspired from the work produced by [JOL 96, MIG 00] as
well as the contemporary work carried out on the recognition of road signs led by
De La Escalera et al., whose work is also based on the use of genetic algorithms or
simulated annealing [ESC 03, ESC 04].

248
Optimization in Signal and Image Processing
Figure 10.1. Template and integration domains
10.3. Template and deformations
The template is tailored to the end application. As far as the detection of danger
road signs is concerned, the prototype is created from two nested triangles (see
Figure 10.1). The prototype can be deformed and placed onto the image by using
linear transformations like in [MIG 00]:
"x′
y′
#
=
"cos α
−sin α
sin α
cos α
# "1
h
0
1
# "s1
0
0
s2
# "x
y
#
+
"tx
ty
#
[10.1]
The transformation parameters are grouped together in a vector and from here on
will be referred to as Θ. This model can easily be adapted to other polygonal or elliptic
shapes so that it is possible to segment the different types of road signs.
10.4. Estimation problem
Following [JOL 96], we express the road sign segmentation task from a given
image I in the Bayesian framework as an estimation problem in the sense of maximum
a posteriori (MAP):
ˆΘ = arg max
Θ
P(Θ | I).
[10.2]
Using the Bayes theorem, P(Θ | I) is proportional to the product of an a priori
probability of the parameter values Pp(Θ), and a likelihood level Pv(I, Θ), which
measures the adequacy of the prototype to the image. These two different distributions
are both exponential distributions. Hence, P(Θ | I) can be expressed as a Gibbs
distribution with energy E(I, Θ) = Uv(I, Θ) + Up(Θ). A more detailed description
of each of these two terms will now be given.
10.4.1. A priori energy
The a priori energy on shape makes it possible to deﬁne a relevance level of a
conﬁguration which is created from a particular instance of the vector Θ. Measuring
such energy is based on the following three criteria:

Biological Metaheuristics for Road Sign Detection
249
– the usual position of the road signs in the image (normally on the right-hand side
of the road scene),
– the different sizes that are possible for a particular road sign,
– the usual orientation of the road sign.
Each criterion of parameter θ is supposed to be located in a relevance interval
[θmin, θmax] and is represented by a V-shaped penalty function:
θ < θmin,
g(θ) = a

θmin −θ

θmin ≤θ ≤θmax,
g(θ) = 0
θ > θmax,
g(θ) = b

θ −θmax

.
[10.3]
The limits of the relevance interval can be considered as data derived from a
“ground truth”, i.e. a manual analysis that was carried out on a representative set of
image sequences. The slopes a and b are modeled empirically. The global a priori
term Up(Θ) is the sum of the different penalty terms.
10.4.2. Image energy
It is possible to distinguish vertical road signs from their environment by
analyzing their color and shape. Therefore, the image energy function Uv(I, Θ)
is made up of two elements: an edge-oriented term Uc(I, Θ), which is based on
gradient information, and a region-oriented term Ur(I, Θ), which is based on color
information.
10.4.2.1. Using gradient information
As is the case with a lot of manufactured objects, vertical road signs possess
straight and aligned edges (see Figure 10.2). The edge-oriented element [JOL 96]
simultaneously uses the direction of the gradient and its magnitude. To be more
speciﬁc, on every edge of the polygon the edge-oriented element integrates the
product of the magnitude of the gradient ∥∇I∥with a function of the scalar product
of the direction vector of the segment −→
S and the local direction of the gradient of the
image −→
∇I:
Uc(I, Θ) = 1 −
 
δ(Θ) ∥∇I∥× h(−→
S · −→
∇I)
. 
δ(Θ) ∥∇I∥2
. 
δ(Θ) h2(−→s · −→
∇I)
[10.4]
where h(x) = max(0, 1 −|x|). The value of the criterion which is deﬁned is close to
zero when the model is aligned with the edges of a particular object of interest, and is
close to one in the opposite case. This criterion is evaluated along the exterior triangle
of the prototype.

250
Optimization in Signal and Image Processing
Figure 10.2. Image, magnitude (reversed grayscales) and angle of the gradient
With the aim of making the likelihood term more “attractive” it is possible to
alter its value in the following way. An edge map is calculated by extracting the
local maxima of the gradient which exceed a certain threshold level (see left image
in Figure 10.3). With the help of the fast marching algorithm [SET 96] it is possible to
determine the distance d(x, y) that exists between each point (x, y) of the image grid
and the closest edge point. In practice, however, this distance is propagated only up to
a certain maximum threshold level dmax. The map dmax −d(x, y) (see right image in
Figure 10.3) is introduced into the edge energy function Uc in place of the magnitude
of the gradient.
Figure 10.3. Edge map and associated distance transform, dmax −d
(histogram drawn to scale in order to improve the view of the image)
10.4.2.2. Exploiting color information
Warning road signs are characterized by their red color. In order to identify the
pixels which exhibit a predominant red color rapidly, the red green blue (RGB) color
model is used. The pre-detector assumes a pixel to be red if its components respect
the following two conditions:
R > α(G + B)
R −max(G, B) > β

max(G, B) −min(G, B)

.
[10.5]

Biological Metaheuristics for Road Sign Detection
251
The ﬁrst criterion involves placing a constraint on the normalized red component
R/(R + G + B), which must be dominant. The normalization of the red component
makes the pre-detector robust to illumination variations. The second criterion checks
that the pixel does not tend towards yellow nor towards magenta. In practice β = 2α is
suitable in most cases, which then only leaves parameter α to be tuned. The same value
of a parameter can be used for an entire image sequence. Usual values range from 0.5
to 0.75. The pre-detector introduced here performs as well as the one proposed by De
La Escalera et al. [ESC 04], and this is without having to change the color model,
which, in turn, reduces the computational cost of the pre-detection phase.
An incorrect white balance is, unfortunately, quite a common occurrence in such
image sequences that are to be processed. Since the images to be analyzed always
contain a part of the road which can act as a reference zone, a type of “gray-world”
balancing [BUC 80] can be automatically carried out in most cases. Figure 10.4 shows
an example of a red dominance map which illustrates the robustness of the method
against luminance variations.
Figure 10.4. Pre-detection of the color red on an RGB image with backlight
For a shape Θ the region-oriented term is calculated from the red dominance map.
More speciﬁcally, it is made up of two terms which are linked to two zones of the
chosen model: the external crown ∂Ω and the interior of the small triangle Ω (see
Figure 10.1):
Ue(I, Θ) =
  
∂Ω(Θ) I(x)dx
  
∂Ω(Θ) dx
and
Ui(I, Θ) =
  
Ω(Θ) I(x)dx
  
Ω(Θ) dx
[10.6]
The global region-oriented element is ﬁnally written as follows:
Ur(I, Θ) = min

1, 1 + Ue(I, Θ) −Ui(I, Θ)

.
[10.7]

252
Optimization in Signal and Image Processing
When Θ is perfectly adjusted, the value of Ur is zero. On the other hand, Ur(I, Θ)
has a value of one whenever Θ is in a zone of the image which is either completely
“red” or “not red”.
We have written the problem of road sign detection as the minimization of a cost
function E(I, Θ) whose different terms have just been described. The question is now
to ﬁnd an algorithm which is capable of efﬁciently minimizing E. This will be dealt
with in the next section.
10.5. Three biological metaheuristics
The non-convex nature of E over the set of possible transformations Θ, means
that an adapted algorithm must be used for the recognition of road signs. Due to the
fact that the value of E does not possess any interesting mathematical properties
it is difﬁcult to choose a priori an algorithm that can be used. This means that an
experimental comparison of certain algorithms must be carried out. We decided
to compare three different algorithms inspired from the world of biology. Each of
these algorithms has very different characteristics. One of the algorithms is evolution
strategy (ES), another is particle swarm optimization (PSO) and the ﬁnal one is clonal
selection (CS). The three algorithms have been implemented by the authors in Scilab
language.
10.5.1. Evolution strategies
ES will be considered as a reference algorithm in this experimental comparison
because it has been used by the authors since the beginning of the development of
a road sign detection tool. If we consider a particular optimization problem and
link it to a particular species in its own environment, it is possible to create an
analogy between the population of organisms of this particular species and the set of
solutions of the optimization problem. It is also possible to create an analogy between
the performance of these organisms and the cost-function value. The operators of
crossover and mutation which are used to produce new candidate solutions are
inspired by the main genetic mechanisms involved in the evolution of a species
with sexual reproduction. This analogy has led to the creation of algorithms usually
classiﬁed as evolutionary algorithms. A member of the evolutionary algorithms class
conforms to the diagram which can be seen in Figure 10.5. Genetic algorithms are
the most famous member of this class. ESs and evolution programs [BÄC 96] are
also found in this class. It must be pointed out that evolution programs are seldom
used. Since we address a continuous variable optimization problem, we have decided
to focus only on ES, which will be introduced in the next section.
10.5.1.1. Algorithm
10.5.1.1.1. Gaussian representation
ES, which was designed for numerical optimization, does not go into as much
depth as a genetic algorithm when it comes to the analogy with living beings, since it

Biological Metaheuristics for Road Sign Detection
253
Figure 10.5. Flow-chart of an evolutionary algorithm
operates only on the phenotype1 of the living object. It is therefore not necessary to
encode the variables that need to be optimized. In ESs the individuals are represented
by Gaussian random vectors, which are noted as ⃗N(Θ, C). The average vector is
the vector Θ which contains n variables of the optimization problem. Vector ⃗N also
contains the covariance matrix C which is divided into two vectors ⃗σ and ⃗α. Vector ⃗σ
contains the variances, and ⃗α the out-of-diagonal terms of C, or rotations. Even though
it is possible to introduce dependencies between different variables, this is in fact very
seldom carried out. Therefore, C is usually diagonal.
10.5.1.1.2. Initialization
The initial population of the average vector Θ can come from a priori information
on the expected position of the minimum. It can also be randomly sampled from
a uniform distribution, properly scaled and centered. The values of the covariance
matrix are ﬁxed non-zero arbitrary values.
10.5.1.1.3. Operators
In order to make the population evolve, ES uses traditional mutation, crossover
and selection operators in succession. The ﬁrst two operators are applied to all of the
1. An organism’s full hereditary information, even though it may not be seen, is known as the
genotype, while the phenotype refers to only the information which can be observed.

254
Optimization in Signal and Image Processing
components of the organism, i.e. average, as well as variances and strict covariances.
In the next part of this chapter we assume that the problem is made up of n variables.
N(a, b) refers to the selection of a Gaussian random variable with an average a, and a
standard deviation b.
The crossover operator relies on the phenotype of two organisms S and T, in the
same way as the breeding operator relies on the genotype for GA:
(Θ′,⃗σ′, ⃗α′) = R

(ΘS,⃗σS, ⃗αS), (ΘT ,⃗σT , ⃗αT )

.
[10.8]
Bäck describes six detailed formulae, which deal with the recombination of the
initial vectors’ components [BÄC 96]. Referring to the literature, he points out that it is
better to use two different formulae depending on whether we consider the variables of
the optimization problem or the covariances. For the variables, he recommends using
the process of discrete recombination; for the covariances, he recommends using a
process of recombination known as pan-mictic recombination:
Θ′
i = ΘS,i | ΘT,i,
∀i ∈{1, . . . , n}
σ′
i = σS,i + 1
2

σT,i −σS,i

,
∀i ∈{1, . . . , n}
α′
i = αS,i + 1
2

αT,i −αS,i

,
∀i ∈

1, . . . , n(n −1)/2

.
[10.9]
where | refers to the random choice operation between two values. The mutation
operator is applied to the descendant, which results from randomly choosing one of
the two values. The mutation operator is also applied to the variances and rotations,
and then to the variables as follows:
σ′
i = σieτ ′N(0,1)+τNi(0,1)
∀i ∈{1, n}
α′
i = αi + βeNi(0,1)
∀i ∈

1, n(n −1)/2

Θ′ = Θ + ⃗N(⃗0,⃗σ′, ⃗α′)
[10.10]
With these equations in mind we recognize a process which is similar to the cooling
schedule of the simulated annealing. The internal parameters of ES evolve through the
iterations. The factors τ, τ ′ and β have been established as follows in literature:
τ ∝
".
2√n
#−1
τ ′ ∝
√
2n
−1
β ≈0.0873
[10.11]

Biological Metaheuristics for Road Sign Detection
255
The cost-function value is calculated for each of the λ organisms of the offspring.
The organisms are ranked and then a number of μ organisms are chosen. The notation
which is used for this demographic scheme is (μ, λ)-ES. The other form of notation
which can be used is (μ + λ)-ES. This latter form corresponds to the selection among
parents and offspring organisms. This scheme is said to be elitist. Unlike genetic
algorithms, the selection of organisms is carried out strictly according to the ranking
of the organism. The lowest ranked organisms have no chance of survival.
10.5.1.2. Theory and convergence
The probabilistic framework in which the ESs have been deﬁned has made it
possible to obtain theoretical results somewhat stronger than for the other algorithms
presented in this chapter. For example, an analytical expression of the probability of
the speed of convergence has been established for (μ, λ)-ES. Nevertheless, it is still
quite difﬁcult to use this expression for parent populations whose size is larger than
one [BÄC 96, Chapter 2.1.7]. In addition, a certain number of results are available for
academic test functions, such as the sphere or the corridor. The rule for adjusting
the standard deviation of the model which has been presented above comes from
theoretical investigations. Bäck compares the ESs and the genetic algorithms for ﬁve
different academic functions, exhibiting different topologies. ES turns out to be the
best algorithm to use, by far [BÄC 96].
10.5.1.3. Practice
The theory behind ESs does not mention anything about the size of the parent
population to be dealt with. It seems that the parent population can be somewhat
smaller than is the case for GA, without having a negative effect on the ES. A size of
parent population that is equal to the size of the number of variables can typically be
used. For example, a parent population with less than four individuals strongly limits
which organisms the recombination operator can choose from. If there happens to be
a lot of variables, it is possible to deal with a much smaller number of organisms than
the total number of variables. The rule is to produce seven times as many descendants
as there are parents. Elitist ESs are not recommended, thus a (μ, λ)-ES is preferable.
10.5.1.4. Applying the ES to the issue of detection
After carrying out a parametric study on μ, a (4, 28)-ES was chosen. The
components of ⃗σ were tuned to a size of 1/100 of the range of each parameter. Since
no information on dependencies between the parameters is available, we take ⃗α = ⃗0.
10.5.2. Clonal selection
Clonal selection (CS) was chosen after a series of tests using several different
algorithms was carried out on a set of classical test functions by one of the authors.
It turns out that CS was the best performing algorithm of all of the algorithms

256
Optimization in Signal and Image Processing
that were tested and that its results on several optimizations showed a very low
standard-deviation.
10.5.2.1. Some information about the immune system
In this section we provide a brief description of the immune system of vertebrates
which acts as the basis for CS. For more detailed information on how the immune
system functions, see more specialized literature on the topic, such as [ALB 02] or
[JAN 04]. A perfectly functioning vertebrate immune system ensures the protection
and speciﬁc defense of the organism against pathogens, which continually try to
attack the organism. Speciﬁc defense refers to the immune system ﬁghting against a
particular type of pathogen. These pathogens, which we will refer to as antigens, can
be present in many different shapes or forms such as heavy metals, synthetic organic
compounds, bacteria etc.
The immune system secretes a particular type of protein known as an antibody
which in turn neutralizes and destroys the antigens. The production of an antibody is
partly coded by the immunity genes. This notion of coding leads to the creation of
a certain number of basic protein building blocks, which work together in order to
create an antibody. The process which leads to the creation of functional antibodies
by producing and arranging these building blocks into a sequence is known as
somatic recombination. The diversity of molecules which is produced by the process
of somatic recombination is staggering. It is estimated that there are 1011 different
antibodies which are present within the human body at any given moment. This is
one of the amazing aspects of the immune system.
When the immune system intercepts an antigen, it is assumed that there is an
antibody that possesses a certain afﬁnity, or complementarity with the antigen. A
part of the immune system’s response is to modulate the multiplication of the cells
which produce the antibodies in relation to their afﬁnity with the antigen. These
cells which produce antibodies are known as B lymphocyte cells. This process is
illustrated in Figure 10.6. A B lymphocyte cell only produces one type of antibody.
The multiplication of the B lymphocyte cells is carried out by a process of cloning. The
clones which are produced have two functions. They either produce new antibodies
with the aim of neutralizing other occurrences of the antigen, or they act as a memory
in case of a further attack carried out by the antigen. In the case of any further attack
carried out by the antigen, the immune system’s response becomes more intense, in
other words more antibodies are produced and they are produced at a quicker rate. The
lifespan of a memory B lymphocyte ranges from several months to several years.
This very brief and crude introduction results in the creation of an analogy
between the afﬁnity of the antigen/antibody, and the optimization process. As far as
the optimization process is concerned, the immune system of vertebrates possesses
two valuable characteristics.

Biological Metaheuristics for Road Sign Detection
257
Figure 10.6. The principle of clonal selection
On one hand, the immune system is capable of producing a large range of possible
solutions to help with the issue of optimization. On the other hand, it possesses a
learning mechanism. De Castro and von Zuben developed CS [CAS 02] after studying
the controlled multiplication of B lymphocytes. This algorithm is introduced in the
next part of this section. Other authors have used the immune network as their basis
for CS. By relying on the immune network it is possible to provide an explanation of
the long-term memory of past immune responses, with a moderate cost for the living
host organism. These aspects of the immune system which have just been mentioned
are not the only aspects which can be used in analyzing engineering issues, and the
optimization process is not the only process which can be used as well. Another
possibly more straightforward application is pattern recognition. For an overview of
all of the different applications of the artiﬁcial immune system that are available,
see [DAS 98].
10.5.2.2. An introduction to CS
The ﬂow chart of clonal selection adapted to optimization can be seen in
Figure 10.7.
The algorithm manipulates a population of antibodies. Each antibody contains a
set of data for the parameters which are to be optimized. It is possible to create the
initial population of N antibodies by random selection. For the next iterations, this
population of antibodies is made up of N −d antibodies resulting from previous
iterations and d new randomly generated antibodies. The population is then evaluated
with respect to the cost function. The population is then ranked according to merit

258
Optimization in Signal and Image Processing
Figure 10.7. Flow-chart of the clonal selection
in descending order. Ranking the antibodies like this makes it possible to choose the
n ≤N best individuals, which will then undergo a cloning phase. The total number
of clones Nc can be written as follows:
Nc =
N

i=1
arrondi
" βN
g(i)
#
.
[10.12]
where g is a function which can either be dependent on the afﬁnity between the
antibody and the antigen, or can be a constant value and β is a multiplicative factor.
According to de Castro and von Zuben the ﬁrst rule is suitable whenever it is a global
minimum that is being looked for – global form of the algorithm. The second rule is
used whenever several good quality minima are being looked for – local form of the
algorithm. The aim of the maturation phase is to introduce variations into the clones
that have been created. [CAS 02] does not go into a lot of details on the maturation
phase but does state that the mutation rate m should decrease when the afﬁnity of the
organism f increases, in our case, when the value of the cost function E decreases.
De Castro and von Zuben suggest deﬁning m by m = exp(−ρf), where ρ is a control
parameter. After the maturation phase, the Nc clones are evaluated and the best N −d
clones are retained before the entire cycle is restarted up until the stopping condition
is met.
10.5.2.3. Performance and convergence
Clonal selection is a recent algorithm and the underlying theory is less developed
than is the case for the other algorithms which have been introduced in this chapter.

Biological Metaheuristics for Road Sign Detection
259
There is no information about the algorithm’s probability of convergence or the
algorithm’s speed of convergence. The effects of the internal parameters were only
studied in an empirical way for multimodal functions. Remarkably, the complexity
of the CS is O(Nc), where Nc is the number of clones, while the complexity of an
evolutionary algorithm is O(N 2), where N refers to the size of the population. An
empirical evaluation over a large number of test functions which was carried out
by the Regional Ponts-et-Chaussées Laboratory in Strasbourg, France, highlights
the excellent performances of this algorithm. It was indeed the best algorithm over
(all but one) studied functions. Another point which needs to be mentioned is the
low scattering of results obtained for the CS, which is not the case for the other
algorithms. For the choice of parameters, N = 10, β = 1 are general purpose values.
The optimal value of ρ may vary. It is best not to have a value of d larger than two,
for fear of seeing the optimization process transform into Brownian motion. The
optimization of these last two parameters does not lead to the same values, depending
on whether the local or the global form of the algorithm is used.
10.5.2.4. Applying the CS to the optimization problem
We placed the value g(i) = 1/i into equation [10.12], N = n = 10, β = 1,
and ρ = 2. In the absence of a more precise deﬁnition of the mutation operator in
[CAS 02], we used a similar operator to the operator that is used in the canonic genetic
algorithm.
10.5.3. Particle swarm optimization
Particle swarm optimization (PSO) which was developed by Kennedy and Eberhart
[KEN 95, KEN 01] has already been described in Chapter 9. Due to this fact it is not
relevant to describe this algorithm again in this chapter. PSO combines a very simple
formulation with a high level of efﬁciency. The PSO which has been implemented here
is the “variant 1 with constriction” PSO proposed in [CLE 02] by Clerc and Kennedy.
The size of the population is 20 particles. According to Kennedy and Clerc, the value
of χ is calculated by having κ = 0.8 and having Φmax = 4.5.
10.6. Experimental results
10.6.1. Preliminaries
10.6.1.1. Additional information on the road sign detectors
Even if the algorithms can achieve global optimization, it is best to provide
them with an initial population as close as possible to the regions of interest. The
ﬁrst population uses, when possible, connected components extracted from the red
dominance maps supplied by the pre-segmentation stage (see section 10.4.2.2). The
bounding box of each sufﬁciently large connected component is calculated. Then, the
Θ transformation that yields the largest triangle inside the bounding box is calculated.

260
Optimization in Signal and Image Processing
The size of the resulting population is, in general, too small and it is necessary
to generate more individuals. This is done by randomly sampling over a uniform
distribution, properly scaled and centered (the resulting Θ transformations must lead
to the creation of patterns which respect the a priori criterion that has been described
in section 10.4.1).
On the other hand, local optimization is not completely missing in the detector. It
can happen that the initialization from the connected components gives an individual
that almost ﬁts the road sign. Therefore, before carrying out the optimization process,
whilst using one of the three metaheuristics that were mentioned in section 10.5, a
gradient descent is systematically applied to all individuals which have been created
from the connected components. In this way, a certain number of the road signs
can be localized at a low computational cost. Moreover, if the algorithm is stopped
because the likelihood energy becomes very small, applying a gradient descent makes
it possible to reﬁne the convergence without extending the overall computation time.
10.6.1.2. Establishing the ground-truth
It is necessary to have a reference sequence, whose properties are known, in order
to assess the performance of the detector. In this sequence, all the images with danger
road signs are identiﬁed and the coordinates of the vertices of these signs are stored.
The result of this survey will be referred to as the “ground truth” in the remainder of
this chapter. It can only be made by a human operator. For this purpose, a graphical
interface that makes it possible to navigate along image sequences was designed at the
Regional Ponts-et-Chaussées Laboratory in Strasbourg, France. Of course, the ground
truth depends on the human operator who made it. In order to avoid any possible
bias in our experiment, the ground truth was made by six different people from the
chosen image sequence. So, the real ground truth on which the different detectors
are compared in the following is an average ground truth i.e. the arithmetic mean of
coordinates. The ground truth was prepared for a sequence of images called CD3. The
images were taken along the French secondary road called RN74, in the department
of the Vosges (88). With CD3, the maximum standard deviation on each coordinate
of the center-of-mass in a given image is 1.85 pixels. The sampling rate of the image
sequence is 5 m. Thus, it is not uncommon to see a road sign appear several times
within consecutive images, with different sizes. Since the aim was to identify all of
the danger road signs along a given route and not to identify all of the appearances of
danger road signs in the image sequence, a chaining process was carried by one of the
operators. The idea of this chaining process is to group all of the images that contain
a view of the same road sign.
10.6.1.3. Deﬁnition of receiver operating characteristic (ROC) curves
With the aim of evaluating the different road sign detectors, we plotted a ROC
curve for each of them, in relation to the average ground truth. Such curves represent
the correct detection rate vs. the false positive rate, as a function of a threshold on

Biological Metaheuristics for Road Sign Detection
261
the value of the cost function. In the present case, there is no absolute deﬁnition of
a ROC curve. Hence, we chose to measure the distance (in terms of center-of-mass)
between the average ground truth and the result of the optimization algorithm. We
consider that a maximum distance of 4 pixels between these two points is acceptable.
The expressions of the false positive rate and the correct detection rate are as follows:
tF A(c, D) = nF A(c, D)
NF A(D)
[10.13]
tBD(c, D) = nBD(c, D)
NBD(D)
[10.14]
where FA means False Alarm, BD is the (French) acronym for “correct detection”,
c is the value of the threshold which is set for the cost-function. In other words, only
shapes whose cost is less than c are taken into account in the calculation of tF A and
tBD. In [10.13] and [10.14], D refers to the distance threshold. For the purpose of
our experiment we decided to use Euclidean distance, but it is possible to use any
other type of distance. A correct detection occurs if a shape satisﬁes the condition
on c and if its center-of-mass is located less than 4 pixels away from the average
ground truth. If only the ﬁrst of these conditions is met then this is a false alarm. The
other possibility for a false alarm is when the condition on c is met, while there is no
road sign in the image. This second possibility never occurs in our case because the
optimization process is applied to images that belong to the ground truth, i.e. which
contain at least one road sign, by deﬁnition. NF A is the maximum possible number
of false detections. For a ﬁxed image size, this number only depends on the distance
threshold. More speciﬁcally, NF A = lh −S, where l (respectively, h) is the width
(respectively the height) of the image in pixels, and S is the number of pixels in the
detection zone. NBD is the number of road signs to be found. The calculation of tBD
is carried out by only using the correct detections of distinct road signs.
In addition to the ROC curves, we also drew histograms of the distance (in terms
of center-of-mass) between the optimal solution and the average ground-truth. These
statistics are only calculated for road signs which meet the cost-function criterion.
10.6.2. Evaluation on the CD3 sequence
This section focuses on the results that were obtained from the CD3 sequence
by the six different detectors that can be devised, since there are two possible
contour-based terms and three optimization algorithms.
With an edge-oriented term based on the magnitude of the gradient (see
equation [10.4]), ES and PSO detect the presence of all of the road signs. CS,
however, is not perfect as can be seen in Figure 10.8.

262
Optimization in Signal and Image Processing
 
0
 0.2
 0.4
 0.6
 0.8
 
1
 1e−007
 1e−006
 1e−005
 0.0001
Rate of correct detections
Rate of false detections (log)
ES
CS
PSO
 
0
 0.05
 0.1
 0.15
 0.2
 0.25
 0.3
 0.35
 0.4
 
0
 
5
 10
 15
 20
 25
 30
 35
 40
Frequency
Distance
Figure 10.8. ROC curves and a typical distance histogram of a detector
that uses an edge-oriented term based on the magnitude of the gradient
The residual likelihood value after optimization is never equal to zero, which
explains why the ROC curve does not begin at zero. If the threshold value c is too
small then none of the images will be considered. If this threshold is increased then all
of the correct detections of the images are considered. Further increasing the threshold
level does not enhance the number of correct detections; it actually increases the
number of false alarms. The histogram of distances to the ground truth conﬁrms this
interpretation (see e.g. the ES histogram on the lower part of Figure 10.8). It reveals
that there is a class of individuals with a center of gravity that is very close to the center
of gravity of the ground truth. Classes of distance immediately higher are empty. We
have to signiﬁcantly increase the distance to ﬁnd other individuals, which are false
alarms.
With the edge-oriented term based on the distance map only PSO produces a
straight line ROC (see Figure 10.10). The number of correctly identiﬁed road signs
increases in steps whenever the other two algorithms are used. ES, just like PSO,
reaches the maximum rate of correctly identiﬁed road signs, whereas CS has a success
rate of less than 1.

Biological Metaheuristics for Road Sign Detection
263
Figure 10.9. Examples of detections with an edge-oriented term based on the distance map.
The original image is on the left and the best individual can be seen on the right

264
Optimization in Signal and Image Processing
 
0
 0.2
 0.4
 0.6
 0.8
 
1
 1e−007
 1e−006
 1e−005
 0.0001
Rate of correct dstections
Rate of false detections (log)
ES
CS
PSO
Figure 10.10. The detector’s ROC curve which is created from
the edge oriented term that is based on the distance map
A close examination of the distance histograms conﬁrms that PSO is the best
algorithm to use for detecting road signs and this can be seen in Figure 10.11. The
correctly identiﬁed road signs can be found at a distance which is at most 2 pixels
from the center of the ground truth, while for CS and ESs the ﬁtting is less precise.
 
0
 0.1
 0.2
 0.3
 0.4
 0.5
 0.6
 0.7
 0
 
5
 10  15  20  25  30  35  40
Frequency
Distance
 
0
 0.01
 0.02
 0.03
 0.04
 0.05
 0.06
 0.07
 
0
 
5
 10  15  20  25  30  35  40
Frequency
Distance
Figure 10.11. Distance histograms showing the distance of the detector from the road
signs. The PSO is on the left, and the CS is on the right. The edge-oriented element
is based on the distance map
The almost binary nature of the ROC curves suggests that the detector is well
conﬁgured since an increase in the number of correct identiﬁcations of road signs
does not necessarily mean that the number of false detections will also increase. We
can, therefore, rely on the likelihood value to judge the success or failure of the road
sign detection process. As a result of this it is quite easy to automate the detector.

Biological Metaheuristics for Road Sign Detection
265
Some examples of road signs which have been detected by PSO can be seen in
Figure 10.9. The left column shows the original image. The right column shows the
best individual after the optimization process. These optimized individuals are shown
superimposed either on the gradient’s magnitude map (lines one, three and four in
Figure 10.9), or on the red color map (line two in Figure 10.9). The top image on
the right hand side of Figure 10.9 shows a partly occulted road sign. The image on
the second row is an example of noisy red color map. This image also shows the
presence of a different number of potential lures (roof tiles and cars in particular). The
combination of the a priori information and the template make it possible to avoid
them. The other two images highlight the detector’s ability to locate several objects
within the same road scene, on two successive images. It is necessary to develop a
tool which can be used to detect several objects in one image if such a detector is to
be used on a large scale.
10.7. Conclusion
After introducing the state of the art in road sign detection, we described
an off-line detector dedicated to automatic road sign surveys. The associated
optimization problem has been dealt with using three different algorithms: evolution
strategy (ES), clonal selection and particle swarm optimization (PSO).
Judging from a test on a sequence of 48 typical road scene images, it can be said
that PSO, combined with an edge-oriented energy that is based on the distance map,
is the best algorithm. It achieves a true-positive rate of 100% with respect to a ground
truth made by several human operators. The 18 road signs in the sequence were all
correctly located, within a maximum distance of 2 pixels. The use of PSO combined
with an edge-oriented energy that is based on the gradient’s magnitude as well as the
use of ES with the same energy also led to a 100% true detection rate. However, the
distances to the ground truth are somewhat more signiﬁcant with the latter detectors.
The use of ES combined with an edge-oriented energy that is based on the distance
map is also capable of detecting all of the road signs of the sequence, but at the price
of a higher false alarm rate.
Between the two terms proposed to take into account edge-oriented information,
the distance map is the one which leads to the most efﬁcient detector. The ROC curves
and the associated histograms show that the problem is relatively well deﬁned, i.e
a low likelihood level corresponds to the correct identiﬁcation of a road sign. This
therefore makes it possible to deﬁne a stopping criterion for the optimization algorithm
based on the likelihood level. It is therefore possible to automate the detection process.
If we want to use the detector on a more operational level, it must be possible
to process sequences of several thousand images in a reasonable time lapse. The
percentage of road images which contain road signs is quite low. For example, CD3
contains 3,000 images for a total of 48 different views of 18 danger road signs. The

266
Optimization in Signal and Image Processing
analysis of the connected components which are calculated from red color maps makes
it possible to decide whether a road sign is present in an image or not. It is then quite
easy to isolate the images that need to be processed. A good detector must be able
to locate several road signs within an image. This can be carried out in a sequential
fashion. In this case the areas that have been successfully explored must be avoided.
One solution involves deleting, from the images, road signs which have been located.
Another solution involves modifying the likelihood energy each time a road sign is
identiﬁed. These two approaches have been tested by the authors with quite positive
results. Finally, and this is probably an interesting optimization problem, it is possible
to carry out a parallel search on the existing road signs in an image, provided that there
are algorithms that can localize several high quality minima. This is the case of the
local form of clonal selection.
10.8. Bibliography
[ALB 02] ALBERTS B., “The adaptive immune system”, chapter in Molecular Biology of the
Cell, pp. 1363–1421, Garland Science, 2002.
[AMI 91] AMIT Y., GRENANDER U. and PICCIONI M., “Structural image restoration through
deformable templates”, Journal of the American Statistical Association, vol. 86, no. 414,
pp. 367–387, 1991.
[AOY 96] AOYAGI Y. and ASAKURA T., “A study on trafﬁc sign recognition in scene image
using genetic algorithms and neural networks”, Proceedings of the 1996 IEEE 22nd
International Conference on Industrial Electronics, Control, and Instrumentation (IECON),
vol. 3, pp. 1838–1843, 1996.
[BÄC 96] BÄCK T., Evolutionary Algorithms in Theory and Practice, Oxford University Press,
1996.
[BET 95] BETKE M. and MAKRIS N.C., “Fast object recognition in noisy images using
simulated annealing”, Proceedings of the Fifth International Conference on Computer
Vision, Washington, DC, USA, IEEE Computer Society, pp. 523–530, 1995.
[BOR 88] BORGEFORS G., “Hierarchical chamfer matching: a parametric edge matching
algorithm”, IEEE Trans. Pattern Anal. Mach. Intell., vol. 10, no. 6, pp. 849–865, IEEE
Computer Society, 1988.
[BUC 80] BUCHSBAUM G., “A spatial processor model for object colour perception”, Journal
of the Franklin Institute, no. 310, pp. 1–26, 1980.
[CAS 02]
DE CASTRO L. and VON ZUBEN F., “Learning and optimization using the clonal
selection principle”, IEEE Transactions on Evolutionary Computation, vol. 6, no. 3,
pp. 239–251, 2002.
[CLE 02] CLERC M., KENNEDY J., “The particle swarm – explosion, stability, and
convergence in a multidimensional complex space”, IEEE Transactions on Evolutionary
Computation, vol. 6, no. 1, pp. 386–396, IEEE Press, 2002.

Biological Metaheuristics for Road Sign Detection
267
[DAH 04] DAHYOT R., CHARBONNIER P. and HEITZ F., “A Bayesian approach to object
detection using probabilistic appearance-based models”, Pattern Analysis and Applications,
vol. 7, no. 3, pp. 317–332, 2004.
[DAS 98] DASGUPTA D., Artiﬁcial Immune Systems and their Applications, Springer Verlag,
1998.
[ESC 03]
DE LA ESCALERA A., ARMINGOL J.M. and MATA M., “Trafﬁc sign recognition
and analysis for intelligent vehicles”, Image Vision Comput., vol. 21, no. 3, pp. 247–258,
2003.
[ESC 04]
DE LA ESCALERA A., ARMINGOL J., PASTOR J. and RODRIGUEZ F., “Visual sign
information extraction and identiﬁcation by deformable models for intelligent vehicles”,
IEEE Trans. on Intelligent Transportation Systems, vol. 5, no. 2, pp. 57–68, 2004.
[GAV 99] GAVRILA D.M., “Trafﬁc sign recognition revisited”, Proc. of the 21st DAGM
Symposium für Mustererkennung, Bonn, Germany, Springer Verlag, pp. 86–93, 1999.
[GRE 89] GRENANDER U. and KEENAN D.M., “Towards automated image understanding”,
Journal of Applied Statistics, vol. 16, no. 2, pp. 207–221, 1989.
[JAN 04] JANEWAY C., TRAVERS P., WALPORT M. and SHLOMCHIK M., Immunobiology –
the Immune System in Health and Disease, Garland Science, 2004.
[JOL 96] JOLLY M.D., LAKSHMANAN S. and JAIN A., “Vehicle segmentation and
classiﬁcation using deformable templates”, IEEE Trans. on Pattern Analysis and Machine
Intelligence, vol. 18, no. 3, pp. 293–308, 1996.
[KEN 95] KENNEDY J. and EBERHART R.C., “Particle swarm optimization”, IEEE
International Conference on Neural Networks, IEEE, pp. 1942–1948, 1995.
[KEN 01] KENNEDY J., C.EBERHART R. and SHI Y., Swarm Intelligence, Morgan Kaufmann
Publishers, 2001.
[LAL 95] LALONDE M. and LI Y., Road Sign Recognition, Survey of the State of the Art for
Sub-Project 2.4, Report no. CRIM-IIT-95/09-35, Information Technology Research Center
in Montreal, 1995.
[LOY 02] LOY G. and ZELINSKY A., “A fast radial symmetry transform for detecting
points of interest”, ECCV’02: Proceedings of the 7th European Conference on Computer
Vision-Part I, London, UK, Springer-Verlag, pp. 358–368, 2002.
[LOY 04] LOY G. and BARNES N., “Fast shape-based road sign detection for a driver
assistance system”, Proc. IEEE/RSJ International Conference on Intelligent Robots and
Systems (IROS2004), Sendai, Japan, pp. 86–93, 2004.
[MIG 00] MIGNOTTE M., COLLET C., PEREZ P. and BOUTHEMY P., “Hybrid genetic
optimization and statistical model-based approach for the classiﬁcation of shadow shapes in
sonar imagery”, IEEE Trans. On Pattern Analysis and Machine Intelligence, vol. 22, no. 2,
pp. 129–141, 2000.

268
Optimization in Signal and Image Processing
[MOG 97] MOGHADDAM B. and PENTLAND A., “Probabilistic visual learning for object
representation”, IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 19,
no. 7, pp. 696–710, 1997.
[REC 94] RECHENBERG I., Evolutionsstrategie’94, Frommann-Holzboog, 1994.
[SET 96] SETHIAN J., “A fast marching level set method for monotonically advancing fronts”,
Proceedings of the National Academy of Sciences, vol. 93, no. 4, pp. 1591–1595, 1996.

Chapter 11
Metaheuristics for Continuous Variables.
The Registration of Retinal Angiogram Images
11.1. Introduction
Image registration is an important tool that is used to resolve any problems
that may arise during the analysis of medical images. In the past, scientists have
tried to apply traditional minimization strategies to the ﬁeld of image registration.
Such traditional minimization strategies include exhaustive search, gradient descent
algorithm, simplex optimization method, simulated annealing algorithm, genetic
algorithms and Powell’s search [RIT 99, JEN 01].
In most cases image registration is carried out in two phases: image processing and
then optimization of a similarity criterion. The aim of the image processing phase is to
improve the quality of the image and to extract the relevant information which can be
used to improve the optimization phase. The aim of the optimization phase is to ﬁnd
optimal modiﬁcations of the image, in accordance with a particular objective function
which describes the quality of the image registration. The optimization phase is often
carried out by using speciﬁc optimization methods. The methods used tend to be local
searches, that are unable to ﬁnd any global optimum.
Since the image processing phase and the calculation of the objective function
requires a lot of time, global optimization methods such as metaheuristics (which
require a high number of evaluations) are avoided and local optimization methods
are used instead since they are quicker and more effective at ﬁnding local optima.
Chapter written by Johann DRÉO, Jean-Claude NUNES and Patrick SIARRY.
Optimization in Signal and Image Processing 
Edited by Patrick Siarry 
Copyright 0 
2009, ISTE Ltd 

270
Optimization in Signal and Image Processing
However, if the case arises that local optima exists, then it may be interesting to use
global optimization methods [JEN 01].
The combination of images taken over a certain period of time or of different
modalities is frequently used to help doctors diagnose certain diseases. When a set of
retinal angiogram images is being taken, it is inevitable that the eyes of the patient will
move. Before any quantitative analysis can be carried out on the images, the problems
that are associated with any involuntary eye movement must be resolved. The methods
used in image registration today means that it is possible to calculate a distortion ﬁeld
which reﬂects the transformation of structures that are present in any given image.
Metaheuristics are part of a family of algorithms whose main objective is to
resolve difﬁcult optimization problems. Metaheuristics are generally used as generic
optimization methods which are able to optimize a wide range of different problems,
without having to make any signiﬁcant changes to the algorithm being used.
This chapter introduces the registration of retinal angiograms with the help of
metaheuristics. The chapter is divided into six parts. It introduces the framework
that is used to solve difﬁcult optimization problems. In this chapter we also look
at the problems of image registration and image processing as well as introducing
the optimization tools to be used in order to resolve such issues. The results of the
experiments carried out in this chapter can be seen in section 11.5, and an analysis of
the results is given in section 11.6. The chapter ends in section 11.7 with a conclusion
on our results.
11.2. Metaheuristics for difﬁcult optimization problems
11.2.1. Difﬁcult optimization
11.2.1.1. Optimization problems
The general meaning of the term “optimization problem” can be deﬁned by a
set of possible solutions S, whose quality can be described by an objective function
f. The aim is therefore to ﬁnd the best s∗solution with the best f(s∗) quality.
After this has been achieved, the aim is then to minimize or maximize f(s). Such
optimization problems can also lead to other problems if f(s) changes with time or
if it is multi-objective, in other words if there are several objective functions which
need to optimized.
Deterministic methods, also known as exact methods, are used to resolve
such problems as those mentioned in the previous section in a ﬁnite time period.
These methods generally need to possess a certain number of characteristics of the
objective function, such as the objective function’s strict convexity, continuity or

Metaheuristics for Continuous Variables
271
its derivability. Examples of such deterministic methods include linear, quadratic
or dynamic programming, as well as the gradient method or Newton’s optimization
method, etc.
11.2.1.2. Difﬁcult optimization
It is not possible, however, to solve all optimization problems by using
deterministic methods which have been mentioned in the previous section. In
some cases it can be problematic for such methods to acquire the characteristics of
the objective function, for example there may be a lack of strict convexity. Other
problems such as the existence of discontinuities, multi-modality, a non-derivable
function and the presence of noise, etc. may exist.
In such cases the optimization problem is said to be difﬁcult due to the fact that
none of the exact methods is able to solve the problem within a reasonable time
scale in one session. In such cases, it is therefore necessary to rely on the use of
approach-based optimization heuristics.
The problems associated with difﬁcult optimization include two types of problems:
discrete problems and continuous problems. Discrete problems include NP-complete
type issues such as the issue of the traveling salesman. An NP problem is said to
be complete if it is possible to describe the problem with the aid of a polynomial
algorithm which is present in the form of a sub-set of instances. It is relatively easy to
describe a solution to such a problem, but the number of solutions that are necessary
to solve the issue increases exponentially with the size of the instance. Up until now,
the theory of not being able to solve NP-complete problems by using a polynomial
algorithm has neither been proven, nor has it been dismissed. No polynomial algorithm
has been developed which can resolve such issues. The use of optimization algorithms
makes it possible to ﬁnd an approach-based solution which can be used within a
reasonable time scale.
As far as the continuous problems are concerned, the variables associated with
each optimization problem are said to be continuous. This is true for problems
associated with identiﬁcation. In this case the aim is to minimize the errors that
exist between a system’s model and the experimental observations stemming from
the model. There is not a lot of research that has been carried out into this type of
problem, but it seems that a certain number of well-known difﬁculties do exist. Such
difﬁculties include: the existence of numerous variables which lead to the creation
of unidentiﬁed correlations; the presence of noise or more generally, the presence
of an objective function which can only be accessed through a simulation process.
More realistically, however, certain problems associated with difﬁcult optimization
are made up of both discrete and continuous variables.

272
Optimization in Signal and Image Processing
11.2.2. Optimization algorithms
11.2.2.1. Heuristics
An optimization heuristic is an approach-based method which is simple, quick, and
one which can be adapted to any given problem. Its ability to optimize a problem with
a minimum amount of information is counter-balanced by the fact that such heuristics
do not provide any guarantee about the quality of optimality of the best solution which
is found.
From an operational research point of view, this slight ﬂaw is not always a problem.
This is particularly true in cases when only an approximation of the optimal solution
is being researched.
11.2.2.2. Metaheuristics
Amongst the heuristics that exist, some of them can be adapted to a large number
of different problems without having to make any signiﬁcant changes to the algorithm
itself. When this occurs we use the term metaheuristics. The majority of heuristics and
metaheuristics use random processes as ways to gather information and to deal with
problems such as combinatorial explosion. In addition to this, metaheuristics are, for
the most part, iterative methods. In other words, the same research algorithm is applied
several times during the optimization process. This means that the metaheuristics do
not use the additional information such as the gradient of the objective function. As
far as the metaheuristics are concerned, we are interested in their ability to avoid local
optima, and this is made possible by either accepting a degradation of the objective
function or by using a population of candidate solutions as a research method. If such a
research method is used, it further distances the metaheuristics from the local descent
heuristic.
Metaheuristics are generally designed to resolve discrete problems, however, they
can also be adapted to resolve continuous problems.
Due to the fact that they can be used to deal with a large number of problems,
metaheuristics can also be extended to the following areas:
– Multi-objective optimization (also known as multi-criteria optimization)
[COL 02]. In multi-objective optimization it is necessary to optimize several
contradictory objectives. The aim of this research is not only to ﬁnd a global optimum,
but also a set of optima according to the rules of Pareto optimality.
– Multi-modal optimization. In multi-modal optimization the aim of the research
is to ﬁnd the best global and/or local optima possible.
– Optimization of sounded problems. Here there is a certain level of uncertainty
as far as the objective function is concerned. This uncertainty needs to be taken into
consideration when it comes to carrying out research in order to ﬁnd the global and/or
local optimum.

Metaheuristics for Continuous Variables
273
– Dynamic optimization. Here the objective function varies according to time. It is
therefore necessary to have an optimum value which is as close as possible to the best
optimum value for each step of the phase.
– Parallelization. With parallelization, the aim is to increase the rate of the
optimization process by dividing the information that needs to be processed into
different units which work together. The problem which arises here is that of trying to
adapt the metaheuristics so that they can be distributed evenly amongst the individual
units.
– Hybridization. The aim of hybridization is to combine all of the advantages of
all the different metaheuristics together.
It should not be forgotten that one of the major advantages of metaheuristics is the
way in which they can be easily used to deal with concrete problems. Users of such
metaheuristics often want to use effective optimization methods which means that
it is possible for them to ﬁnd a global and/or local optimum with relative precision
and within a reasonable time period. One of the problems with metaheuristics is that
because there are so many of them, their potential users are unable to make a quick
decision in relation to which one should be adopted. Once a particular metaheuristic
has been chosen, how is it then possible to simplify its image registration so that it can
be easily adapted to a given problem?
11.2.2.3. Ant colony optimization algorithms
In operational research, and in the ﬁeld of difﬁcult optimization, the majority of
methods that are used have been inspired by systems that exist in real life, and from
the world of biology in particular. The fact that the ﬁeld of biology often studies the
composition and behavior of systems known as intelligent systems means that it is
possible to model such systems and then use these systems in real-life computational
problems. Such approaches are also referred to as bio-inspired artiﬁcial intelligence.
Within biology it has been the ﬁeld of ethology (the study of the behavior of
animals) which has recently led to several signiﬁcant advances as far as optimization
is concerned. Such advances include the development of artiﬁcial ant systems. These
systems are often studied in robotics, in the classiﬁcation of living objects and in
optimization. The term swarm intelligence is often used to describe these systems,
where the intelligence of the entire system is greater than the intelligence of all of the
individual parts of the system combined [DOR 03].
As far as optimization processes are concerned, using artiﬁcial intelligence has led
to the creation of new metaheuristics. The algorithms that are used in optimization
form a particular class of metaheuristic which has recently been developed to try and
resolve the issues associated with discrete difﬁcult optimization. These algorithms
have been inspired by the collective behavior of ants in their colonies. A simple colony
of agents (ants) communicate indirectly with one another through changes that are

274
Optimization in Signal and Image Processing
made to their environment (pheromones). By relying on their collective experience,
the ants (who communicate with one another) are able to ﬁnd a solution to a problem
that they may have to deal with.
The metaheuristic which has been inspired by the ant colony is currently being
formalized. The information that is used to describe this metaheuristic is well known
and is as follows: a candidate solution is created (by adding different components to
the ant colony algorithm), an indirect memory and a structure (both of which can
be compared to the memory and structure of a self-organizing system) are used.
Different ideas resulting from research have shown that there is a lot of support for
the use of the ant colony algorithm. This metaheuristic could also be described as a
distributed system where the interactions between the basic components are carried
out by stigmergic processes. Using such processes makes it possible for the algorithm
to be used globally which, in turn, makes the algorithm capable of solving difﬁcult
optimization problems [DRE 03].
Ant colony algorithms have successfully been applied to several different
combinatorial problems and are starting to be adapted to continuous optimization
problems [DRE 04]. We would also like to highlight the importance of choosing the
correct local research method when it comes to developing algorithms which can be
used as an alternative to older, often more specialized, metaheuristics.
11.2.2.4. Estimation of distribution algorithms
Estimation of distribution algorithms (EDAs) were originally developed as
a variant to evolutionary algorithms [MUH 96]. However, in EDAs there are no
breeding or mutation operators. In fact, the population of new individuals is chosen
at random according to an estimated probability density function. The information
relating to the new population comes from the preceding one. In evolutionary
algorithms the relationship that exists between the different variables is implicit,
whereas with EDAs such relationships are explicitly estimated. These relationships
are worked out by estimating the probability distribution for a selected organism that
makes up the population of the best individuals.
The main difﬁculty encountered when using EDAs is linked to the estimation of the
probability distribution, which can be difﬁcult, depending on the model used. Several
different models have been developed to solve both continuous and combinatorial
optimization problems. It should be pointed out that the distribution model is often
based on the normal distribution [LAR 02].
General frameworks, into which these algorithms can be integrated, also exist.
An example of such a general framework is the IDEA approach [BOS 99, BOS 00a,
BOS 00b]. Ant colony optimization algorithms are also generally seen as being
distribution and sampling optimization methods [DRE 04].

Metaheuristics for Continuous Variables
275
11.3. Image registration of retinal angiograms
11.3.1. Existing methods
Experiments
have
shown
that
one
of
the
methods,
based
on
a
local
research method, and which is mentioned in [NUN 04a], is not powerful
enough to deal with strong inter-image variations. In the majority of scientiﬁc
publications that deal with the automatic registration of retinal images, such as
[BER 99, CAN 99, HAM 00, MUK 01, PIN 98, RIT 99, SIM 01, ZAN 99], it is
often said that it is necessary to detect the vascular structures of the eyes before the
retinal images can be registered. A retinal image is characterized by a low-level local
contrast, however, during the late phase of the angiogram (the phase in which the
radio contrast disappears). The particular optimization method that is mentioned in
[NUN 04a] is able to overcome such problems that are associated with the detection
of vascular structures.
11.3.1.1. Images of retinal angiograms
A series of images taken of the back of the eye is obtained by using one of two
methods: either by using a ﬂuorescein angiogram or an indocyanine green (ICG)
algorithm. These are both useful techniques which are used to evaluate retinal and
choroidal circulation. They are also used to diagnose and treat several retinal diseases,
such as macular degeneration which is linked to ageing, cytomegalovirus retinitis and
diabetic retinopathy [RIC 98].
The two techniques mentioned in the previous section involve injecting a radio
contrast into a cubital vein in the arm. The radio contrast which is injected into the
cubital vein in the arm is either ﬂuorescein or ICG, depending on the technique that
is being used for the angiogram. Once the radio contrast has been added, a close
observation of how it spreads over the retinal vessels (for a given amount of time) is
made. A retinal angiogram (which is a sequence of 36 images taken as soon as the
radio contrast is injected into the arm up until ﬁve minutes after) is generally divided
into three phases: early, average and late. With the aid of a retinal angiogram it is
possible to see the vascular tree or choroidal structures of the eye. It is also possible
to detect any existing diseases that may be present within the eye.
The process of image registration is necessary if doctors want to be able to detect
and quantify any retinal diseases that may be present (diseases which may affect the
fovea, the optic nerve and the vascular structures of the eye). Such areas of the eye are
analyzed by ophthalmologists.
The retinal vessels are the only signiﬁcant visible structure [RIC 98] which is
present in all of the images that are used in retinal angiograms. However, local
variations of intensity can lead to the creation of several problems such as: the

276
Optimization in Signal and Image Processing
creation of a non-uniform image background; a low-level contrast; eye movements;
several types of noise; as well as the presence of blood vessels which possess
different variations of light in comparison to the background of the image.
Figure 11.1 shows two examples of three successive images which were taken by
a ﬂuorescein and by an ICG angiogram. As the images are heavily sounded it means
that the actual process of image registration requires a further phase of ﬁltering that
must be applied to the vascular tree.
(a) ﬂuorescein image before
injection
(b) arterial ﬂuorescein image
(c) venous ﬂuorescein image
(d) ICG image before injection
(e) arterial ICG image
(f) venous ICG image
Figure 11.1. Successive images of angiograms taken from the back of the eye. Top row:
images from a ﬂuorescein angiogram. Bottom row: images from an ICG angiogram
11.3.1.2. Pre-processing
The original images of the eye possess a certain number of characteristics which
can disrupt the image registration process. It is therefore necessary to carry out some
type of pre-processing on the images with the aim of isolating and maintaining the
relevant information that is contained in the images.

Metaheuristics for Continuous Variables
277
The ﬁltering phase (or reduction of noise) makes it possible to register the images
more effectively. This ﬁlter is based on local statistics which are estimated from a
neighborhood of 5×5 pixels for each pixel. The main advantage of the ﬁltering phase
is that the edges of the vascular structure of the eye are not lost.
During the angiogram, there are generally different variations in intensity, and this
is particularly true for the background of an image. Calculating the morphological
gradient of the images becomes a necessary process in order to overcome any
problems that are associated with the different variations in intensity that arise. The
morphological gradient of an image is deﬁned as being the difference between the
dilated image and the eroded image.
It is possible to use an additional ﬁltering phase in order to smoothen the gradient
image. This phase, known as median ﬁltering, replaces the value of each pixel with
the median value of the adjacent pixels in a neighborhood of 3 × 3 pixels.
More information about the ﬁlters which are used can be found in [NUN 03,
NUN 04b]. Figure 11.2 shows the pre-processing process that is used.
11.3.1.3. Traditional image registration methods
The majority of traditional methods have been used in analyzing eye movement
and image registration problems. Such traditional methods can be found in
[BAN 96, HAR 94, IRA 94, KIM 01, ODO 94, ZHA 01]. One method which tends
to be the most commonly used is the application of multi-resolution methods
[ODO 94, ZHA 01]. Such methods are based on optical ﬂow, which calculates
the displacement ﬁeld that exists between two images [NUN 04a]. In the case of
multi-resolution methods, all of the research is carried out at increasing resolutions
of the images. As far as registering retinal images is concerned, only relevant
characteristics from an image are taken [BER 99]. The presence of noise and
low-level local contrasts make it difﬁcult to detect the vascular structure of the eye.
Images which have been generated by an ICG angiogram have only recently been
analyzed by a technique that is based on optical ﬂow.
Several state-of-the-art image registration algorithms can be found in [BRO 92,
MAI 98, HIL 01].
11.3.2. A possible optimization method for image registration
As part of our study we decided to only work on the translation of the images,
a phase that is involved in the image registration process. We decided to focus only
on this phase since it is the most important phase of the image registration process
and is also the most difﬁcult phase to carry out as far as images of retinal angiograms
are concerned. Image registration involves obtaining the best displacement that exists
between two images from the sequence of angiogram images.

278
Optimization in Signal and Image Processing
(a) original image
(b) ﬁltered image
(c) gradient image
(d) ﬁltered gradient image
Figure 11.2. Pre-processing phase before image registration
11.3.2.1. More about the suggested algorithm
The algorithm is made up of the following phases:
– Wiener ﬁltering of the original images;
– calculating the morphological gradient of the images;
– median ﬁltering (optional phase);
– optimization, this is made up of two parts. First of all the similarity criterion (the
sum of the differences of intensity) between two images for the current transformation
is calculated. A search is then carried out in order to ﬁnd the best solution.

Metaheuristics for Continuous Variables
279
11.3.2.2. The similarity criterion
Over the past few years, optimization methods based on the intensity of images,
and which do not possess any preliminary detection phase, have been used to resolve
a large number of image registration problems. Such optimization methods are
technically known as iconic methods.
The similarity criterion is the calculation that is used to judge the quality of image
registration of two images. In [ROC 99] Roche et al. have shown which theories in
the ﬁeld of image registration correspond to a large number of similarity criteria. The
aim of this is to be able to understand the uses of such similarity criteria and to be
able to choose which particular method can be used to deal with a certain problem.
The sum of squared differences [BRO 92], the sum of absolute differences [YU 89],
inter-correlation [CID 92], and entropy, etc., are all easy to calculate and do not lead
to the creation of complex minimization problems. A lot of algorithms use the sum
of squared differences as a measurement of similarity for couplets of images. This
measurement is calculated as follows:
Precision =
(length,width)
(i,j)=(1,1)
I1(i, j) −I2(i, j)
2
(length · width)
[11.1]
where I1 and I2 are two images that need to be registered.
These traditional measurements have different levels of efﬁciency and precision.
However, none of them is really capable of dealing with the relative changes in
intensity that occur when moving from one image to another. One of the problems
with these measurements is that images (which might be considered as being
registered correctly) can still possess errors that are linked to their alignment
[ROC 99]. Such alignment errors occur due to the changes in intensity mentioned in
the previous sentence. For the purposes of our study, the sum of squared differences
is a valid metric since it is calculated from ﬁltered gradient images.
11.4. Optimizing the image registration process
For the purposes of our investigation, the objective function must describe any
given registered image in the best way possible. With this in mind, we decided
to choose a similarity function as our objective function. The search space to
be investigated is the entire range of possible movements associated with image
registration.
It is possible to use several optimization techniques in order to carry out the
research. As far as our study is concerned, we tested two different methods: a local
research method, i.e. the Nelder-Mead Search (NMS) method [NEL 65]; and our own
algorithms, the HCIAC and CHEDA algorithms.

280
Optimization in Signal and Image Processing
11.4.1. The objective function
The objective function (deﬁned in section 11.3.2.2) is deﬁned as f : N →R and
must be minimized. Figure 11.3 shows the globally convex aspect of a simple image
registration problem.
-10
-5
 0
 5
 10
dX
-10
-5
 0
 5
 10
dY
 10
 12
 14
 16
 18
 20
(a) low resolution
-100
-80
-60
-40
-20
 0
 20
 40
 60
 80  100
dX
-100-80-60-40-20 0  20 40 60 80 100
dY
 5
 6
 7
 8
 9
 10
 11
 12
 13
(b) high resolution
Figure 11.3. Sample from the objective function for a simple image registration problem
(described in section 11.5.1)
If the image registration problem is deﬁned on a set of whole variables then the
methods used to solve registration problems need to be adapted so that they can deal
with this particular case. In our investigation we simply used a vector curve of the
required solution for a particular moment in time. Our tests tended to show that the
way in which an algorithm works does not change if the structure of the objective
function does not possess any additional information about the structure of the search
method that is used. In Figure 11.3 we can see that a simple image registration problem

Metaheuristics for Continuous Variables
281
leads to the creation of plateaus for low resolution images. Such plateaus, however, do
not change the structure of the objective function which remains globally convex.
11.4.2. The Nelder-Mead algorithm
Many algorithms which use a population are not very good at ﬁnding local optima
in a short time period. Such algorithms are, however, able to localize the regions
which contain local optima. Ant colony optimization algorithms are effective when
they are used as an additional local research tool. Such a technique is used in the area
of discrete optimization with the aim of making all of the algorithms which can be
used in this ﬁeld more competitive with one another [BON 99].
x3
xr
x2
xb
(a) Reﬂection
x3
xe
x2
xb
(b) Expansion
x3
x'c
xc
x2
xb
(c) Contraction (xc internal, x′
c
external)
x3
x'
3
x2
xh
x'
2
x'
h
xb
(d) Multi-contractions
Figure 11.4. Examples of modiﬁcations made to the Nelder-Mead simplex method for
a two dimensional problem: reﬂection, expansion, internal and external contraction
and multi-contractions. xb is the highest point of the minimum value and xh
is the highest point of the maximum value
The Nelder-Mead algorithm [NEL 65] is an effective and simple local research
method which has the advantage of not having to rely on derivative values. The
algorithm uses a small population of candidate solutions which are present in
the form of a non-degenerated simplex. A simplex is a geometric ﬁgure with a
non-zero volume of n dimensions, which is a convex envelope or convex hull of
n + 1 dimensions. The Nelder-Mead method consists of modifying the simplex in
four different ways: reﬂection (co-efﬁcient ρ), expansion (γ), contraction (χ) and
shortening (δ) (see Figure 11.4 above). These four types of alterations have been
developed so that the Nelder-Mead algorithm follows the gradient of the objective
function (see Algorithm 11.1).

282
Optimization in Signal and Image Processing
Initialize a simplex and calculate the values of the function at the simplex’s vertices
Repeat the iterations t, t ≥0 until the stop criterion is reached
Organize the vertices xt
0, xt
1, . . . , xt
n so that
f

xt
0

≤f

xt
1

≤· · · ≤f

xt
n

Calculate the center of gravity
¯xt = 1
n ·
n−1

i=0
xt
i
Reﬂection calculate the point of reﬂection from the equation:
xt
r = ¯xt + ρ

¯xt −xt
n

If f(xt
0) ≤f(xt
r) < f(xt
n−1) then xt
n ←xt
r, next iteration
Expansion if f(xt
r) < f(xt
0), calculate the point of expansion:
xt
e = ¯xt + χ

xt
r −¯xt
If f(xt
e) < f(xt
r) then xt
n ←xt
e, next iteration
If not xt
n ←xt
r, next iteration
Contraction
Exterior If f(xt
n−1) ≤f(xt
r) < f(xt
n), carry out process of exterior contraction:
xt
oc = ¯xt + γ

xt
r −¯xt
If f(xt
oc) ≤f(xt
r) then xt
n ←xt
oc, next iteration
If not go to the shortening phase
Interior If f(xt
n−1) ≤f(xt
r) ≥f(xt
n), carry out process of interior contraction:
xt
ic = ¯xt + γ

xt
n −¯xt
If f(xt
ic) ≤f(xt
n) then xt
n ←xt
ic, next iteration
If not go to the shortening phase
Shorten the simplex method around xt
0:
xt
i ←−ˆxt
i = xt
i + 1
2

xt
0 −xt
i

,
i = 1, . . . , n
End
Algorithm 11.1. The Nelder-Mead simplex method

Metaheuristics for Continuous Variables
283
11.4.3. The hybrid continuous interacting ant colony (HCIAC)
The HCIAC algorithm is explained in more detail in Figure 11.5.
Evaporation
To the centers of gravity of
the visible spots
yes
yes
no
no
yes
Initialisation
Choice according 
to threshold
Choice according to level
of motivation
Detection of spots
Waiting messages
To the message
Addition of noise
Choice according to1-level
of motivation
Local research 
Re-reinforcement
Zero motivation
Random Movement within
Increase level 
of motivation
Send message
Visible spot
New spot
Reduction of visible zone
the visible zone
no
Figure 11.5. The HCIAC algorithm
The ﬁrst stage of the algorithm involves placing η ants in a particular research area
following a uniform distribution. The ﬁrst stage also involves initializing all of the
parameters of the ants.
Pheromone spots (marks which can be seen in the research area) are removed when
the value τj,t+1 of each spot j at a time t + 1, is calculated according to the following
equation:
τj,t+1 = ρ · τj,t
where ρ represents a persistence parameter.

284
Optimization in Signal and Image Processing
 0
 0.5
 1
 0
 0.5
 1
Probability
Stimulus
(a)
 0
 0.5
 1
 0
 0.5
 1
Probability
Stimulus
(b)
Figure 11.6. Stimulus/response functions: (a) progressive choice, (b) binary choice
A decision is then made in accordance with a stimulus/response function
(Figure 11.6) and is carried out as follows. An ant chooses a method that it can use
to communicate with another ant. Such a communication method is referred to as a
channel of communication. Two parameters which are part of the choice function
are labeled χτ for the threshold level, and χρ for the power of the choice function.
These parameters are applied to the entire population of ants. Each individual ant,
i, has its own set of individual parameters, χi. These individual parameters are
initialized during the ﬁrst phase of the HCIAC algorithm, in accordance with the
normal distribution Nχm,χd.
If an ant chooses the “trail” channel of communication (which is created by placing
pheromone spots in the search space) then the ant will look for a spot within its visible
zone πi. The visible zone is created as part of the ﬁrst phase of the HCIAC algorithm,
in accordance with Nπm,πd. If spots do exist, the ant will move towards the center
of gravity of the visible spots. If no spots exist then the ant will move on to the
decision-making phase.
On the other hand, if an ant chooses the "direct" channel of communication
(which consists of sending a message) then the ant will inspect a stack of messages.
If messages are available then the ant will move towards the point that is indicated
by a message and will then add some noise to the place it has just moved to (in other
words, the ant moves randomly within its visible zone). If no messages are available
then the ant will move on to the decision-making phase.
If there is no spot nor any message, the ant will make a decision based on its
own motivation level ω. The ant makes it decision based on the following aspects
which are all initialized for the entire population of ants in the ﬁrst phase of the
HCIAC algorithm: a stimulus/response function, the threshold of motivation ωρ and

Metaheuristics for Continuous Variables
285
the ant’s strength ωτ. The stimulus ωi is set to zero during the ﬁrst phase of the HCIAC
algorithm.
The ﬁrst choice made by the ant leads directly to the use of the “direct” channel
of communication and therefore to the management of messages. During this phase
another decision is made. This additional decision is taken when a stimulus/response
function possesses the same parameters that it had in the previous phase of the
algorithm. The exception to this rule is when the stimulus has the value (1 −ωi). If
an ant decides to disrupt the stack of messages, then a message will be sent to another
ant (which is chosen at random) and the overall motivation level will be increased by
a small amount ωδ. If the ant’s second choice is to ignore the messages, then the ant
will move in any random direction.
If a decision to be made involves a local search, then a Nelder-Mead research
method is launched. When such a method is launched the position of the ant is used
as the starting point and the radius of the ant’s visible zone is taken as the length of
the initial phase. The local search is limited to ν evaluations of the objective function.
Once the local search has come to an end the ant then looks for visible spots. If there
is a spot, it is reinforced in the following way:
τj,t+1 = τj,t + τj,t
2 .
The radius of the ant’s visible zone is reduced to the distance of the furthest visible
spot that can be seen by the ant, from the actual location of the ant itself. If there are
no spots then the ant will place new ones in its visible zone. The number of spots that
an ant will place in its visible zone is equivalent to the value of the objective function
for that speciﬁc area. Once the trail channel of communication has come to an end,
the motivation level of the ant is set to zero once again.
The ﬁnal possible phase involves the ant moving randomly within the visible
zone. The HCIAC algorithm will stop if it is unable to ﬁnd the best optimum after
θ evaluations of the objective function.
11.4.4. The continuous hybrid estimation of distribution algorithm
The IDEA approach determines the general framework of an estimation of
distribution algorithm (EDA). Such an algorithm describes three key phases:
1) diversiﬁcation: this involves randomly choosing a sample. This choice depends
on the particular probability distribution that is considered;
2) memory: this involves choosing a probability distribution which best describes
the sampled solutions;
3) intensiﬁcation: selection of the best solutions.

286
Optimization in Signal and Image Processing
As part of our study and in order to improve the intensiﬁcation of the IDEA
approach, we decided to combine an IDEA type algorithm [BOS 99] with a
Nelder-Mead local research method [NEL 65]. This combined algorithm is known as
a continuous hybrid estimation of distribution algorithm (CHEDA).
By adopting the IDEA approach, it is possible to use a large number of probability
density functions. As far as our study is concerned, we decided to use a multi-variate
normal distribution as a basis. Indeed, it is not possible to take any of the dependencies
that exist between variables into consideration when a mono-variate distribution is
used (see Figure 11.7). Such dependencies are often present in continuous problems
which arise in the ﬁeld of engineering. It is a lot easier to distribute the population of
candidate solutions whenever a multi-variate normal distribution is used.
-4
-2
 0
 2
 4
-4
-2
 0
 2
 4
(a) the sum of two monovariate normal distributions
-4
-2
 0
 2
 4
-4
-2
 0
 2
 4
(b) a bivariate normal distribution
Figure 11.7. The difference between the sum of two mono-variate normal distributions and
a multi-variate normal distribution. The bi-variate normal distribution makes it possible
to consider a correlation that might exist between two variables which are represented in
the form of co-variances. The graphs above show the 2D distribution of 10,000 points,
with a vector possessing a zero average, a variance of one and a covariance of 1
2
The chosen EDA method can be seen in Algorithm 11.2, where Nm,V is the
multi-normal distribution, m is the average vector and V is the variance/co-variance
matrix. The distribution method that is used becomes truncated, depending on what
the boundaries of the search area are.
Three different versions of CHEDA exist, each version having a slightly different
intensiﬁcation phase from the others; the intensiﬁcation phases are classed as follows:
intensiﬁcation by selection, intensiﬁcation by local research, as well as intensiﬁcation
by local research and selection. Figure 11.8 shows the differences that exist between
the three different intensiﬁcation phases.

Metaheuristics for Continuous Variables
287
Initialize a population P0 of π points in Uxmin,xmax
Until the stop criterion
Estimate the m and V parameters of the sample Pi−1
Take a population Pi of π points in Nm,V
Evaluate Pi
Intensify from Pi
End
Algorithm 11.2. The EDA algorithm used
sampling
(a) CHEDAs
sampling
(b) CHEDAn
sampling
(c) CHEDAsn
Figure 11.8. Variates used for the CHEDA methods. The combination of the three phases
forms an iteration of the algorithm. This iteration of the algorithm is repeated several
times during the optimization process
Due to the fact that three different intensiﬁcation phases exist, it means that each
version has its own parameters that need to be regulated:
π the number of points of the sample (CHEDAs, CHEDAn and CHEDAsn);
β the proportion of candidate solutions to be chosen from Pi (CHEDAs,
CHEDAn and CHEDAs n);
ν the maximum number of modiﬁcations that can be made to the Nelder-Mead
algorithm, as soon as the selection phase has started (CHEDAn and CHEDAsn).

288
Optimization in Signal and Image Processing
11.4.5. Algorithm settings
The HCIAC algorithm is used with the following default settings: ρ = 0.5,
χm = 0.5, χd = 0.2, πm = 0.8, πd = 0.5, ωδ = 0.1, χτ = ωτ = 0.5, χρ = ωρ = 10.
The crucial parameters, which include the number of ants and the number of
iterations of the algorithm, are initialized when ν = 3, and when η = 10 respectively.
These values correspond to a fast-working algorithm (i.e. there is a low number of
evaluations). As far as our study is concerned, the maximum number of evaluations
possible is ﬁxed at 200 evaluations of the objective function.
XXXXXXXXXX
Algorithm
RX
0.1
0.5
1.0
min
max
min
max
min
max
Optic Flow
7
43∗
124
1090∗
704
4531∗
HCIAC
13
30
86
195
367
826
Table 11.1. A comparison of the total processing times (in seconds) for the two different
optimization methods (indicated as Algorithm in Table 11.1) according to resolution (indicated
as RX in the same table). The values are marked with a ∗when the algorithm has been unable
to ﬁnd any optimum. For the HCIAC algorithm the times which have been noted include the
time required for evaluating both the optimization algorithm and for the calculation of
the objective function (the evaluation time of the objective function is proportional
to the resolution)
The CHEDA algorithm is used with the following settings: π = 20, β = 30%
and ν = 10. The algorithm will stop after a maximum of 200 evaluations have been
carried out.
The NMS algorithm uses its own default settings. The algorithm will stop if the
size of the simplex method is less than 10−8, or if it has reached its maximum limit of
200 evaluations.
11.5. Results
11.5.1. Preliminary tests
All of the angiograms mentioned in this study have been digitized by a video signal
with a resolution of 1,024 × 1,024 pixels and a grayscale of eight bits per pixel. The
different algorithms have been tested using different resolutions, ranging from 10% up
to 100% of the size of the original image. The algorithms have also been tested with
and without the additional phase of median ﬁltering which is applied to the gradient
image.

Metaheuristics for Continuous Variables
289
In order to describe how the optimization algorithm functions and to test its
effectiveness, we decided to use a typical registration problem where the global
optimum is known (see Figure 11.9).
(a) ﬁrst ICG image
(b) 2 non-registered images
(c) ICG registered images
Figure 11.9. A typical registration problem which is used to test the accuracy of the algorithms
In this section we have only mentioned the results of the tests that were carried
out on the HCIAC algorithm, in an attempt to avoid overloading the reader with
information. We drew the same conclusions for the results that were obtained for the
CHEDA algorithm, and these results are explained in more detail in section 11.5.3.

290
Optimization in Signal and Image Processing
Traditional optimization techniques require much less processing time for
low resolution image registration problems. However, for high resolution image
registration problems, the processing time can increase dramatically (as can be
seen in Table 11.1 and Figure 11.10). The processing time, as far as metaheuristics
are concerned, stays practically the same (regardless of the resolution level; see
Figure 11.11).
 0
 500
 1000
 1500
 2000
 2500
 3000
 3500
 4000
 4500
 5000
 0.1
 0.2
 0.3
 0.4
 0.5
 0.6
 0.7
 0.8
 0.9
 1
Processing time (in seconds)
Resolution
    optic flow 
HCIAC
Figure 11.10. A comparison of the processing times (in seconds) for the two optimization
methods: optic ﬂow (indicated by a +) and the HCIAC algorithm (indicated by a ∗).
The minimum and maximum processing times for the HCIAC algorithm
are illustrated by the dotted lines
 0
 50
 100
 150
 200
 0.1
 0.2
 0.3
 0.4
 0.5
 0.6
 0.7
 0.8
 0.9
 1
Average number of evaluations
Resolution
Figure 11.11. The number of evaluations of the objective function
which are necessary for the HCIAC algorithm

Metaheuristics for Continuous Variables
291
11.5.2. Accuracy
In order to test the accuracy of the optimization methods we decided to carry
out 50 different tests on the same image registration problem. For the traditional
local optimization methods that were used with a low-level resolution, we tested how
the level of resolution affected the accuracy of the metaheuristics. The aim of this
particular test was to estimate the importance of the additional information which
is supplied by a higher resolution level. Furthermore, additional median ﬁltering is
often used to improve the optimization phase. However, since processing time is an
extremely important factor in resolving image registration problems, we tested how
the phase of additional ﬁltering affected the optimization process. In order to carry out
this test we used the HCIAC algorithm.
Figure 11.12 shows that the phase of additional ﬁltering is important for
high-level resolutions. Standard deviation is an accurate measurement of the accuracy
of the algorithm, since the standard deviation indicates the number of images which
have been properly registered. The larger the standard deviation, the more often the
algorithm will fail to determine how an image should be properly registered.
 4
 6
 8
 10
 12
 14
 0  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9  1  1.1
Similarity average
Resolution
with filtrage
without filtrage
(a) average and standard deviation
 0
 0.5
 1
 1.5
 2
 2.5
 3
 0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9
 1
Similarity standard deviation
Resolution
with filtrage
without filtrage
(b) standard deviation only
Figure 11.12. A comparison of the averages and standard deviations
of the similarities depending on the level of resolution
Figure 11.13 shows that when the NMS algorithm is used on its own it is able
to ﬁnd an optimal registered image. This, however, is at the expense of the standard
deviation which is proportional to the resolution level of the image. The resolution
level of the image has little impact on the accuracy of the HCIAC algorithm.
11.5.3. Typical cases
As far as the accuracy of the results is concerned, we tested the metaheuristics
on a high-level resolution image (100% the size of the original image) without any

292
Optimization in Signal and Image Processing
 0
 10
 20
 30
 40
 50
 60
 0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9
 1
dX average
Resolution
NMS
HCIAC
(a) horizontal movement
 0
 10
 20
 30
 40
 50
 60
 0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9
 1
dY average
Resolution
NMS
HCIAC
(b) vertical movement
Figure 11.13. Standard deviations according to optimal image registration,
without median ﬁltering
additional median ﬁltering. We used eight couples of angiogram images and carried
out 50 optimizations on each image.
As can be seen in Figure 11.14, the HCIAC is unable to accurately determine the
global optimum for each try. In fact, if the HCIAC algorithm always ﬁnds a value that
is close to the value of the perfectly registered image then the algorithm will produce
an inaccurate ﬁnding. The two variants of the CHEDA algorithm, however, produce
fewer errors and are more accurate in their ﬁndings. The variant CHEDAsn is either
equivalent to, or better than CHEDAs.
 0
 1
 2
 3
 4
 5
 0
 1
 2
 3
 4
 5
 6
 7
 8
Average similarity error
Image
(a) HCIAC
 0
 0.2
 0.4
 0.6
 0.8
 1
 0
 1
 2
 3
 4
 5
 6
Average similarity error
Image
CHEDAs
CHEDAsn
(b) CHEDA
Figure 11.14. Averages and standard deviations of similarities for the different test images
Figure 11.15 shows that the HCIAC algorithm is more accurate than the NMS
algorithm when it is used alone. The CHEDA variants produce a lower standard
deviation.

Metaheuristics for Continuous Variables
293
 0
 1
 2
 3
 4
 5
 0
 1
 2
 3
 4
 5
 6
 7
 8
Similarity standard deviation
Image
NMS
HCIAC
(a) HCIAC and NMS
 0
 0.2
 0.4
 0.6
 0.8
 1
 0
 1
 2
 3
 4
 5
 6
Similarity standard deviation
Image
CHEDAs
CHEDAsn
(b) CHEDA
Figure 11.15. Standard deviation of similarities for different images
using the HCIAC, NMS and CHEDA algorithms
11.5.4. Additional problems
11.5.4.1. Peripheral image registration
Some problems that are associated with exact image registration may remain,
and to solve such problems a simple translation of an image is not enough to
represent a real transformation of the image. Figure 11.16 shows that even if a perfect
registration of the image has been obtained, certain errors in the periphery of the
registered angiogram image may still exist. It is sometimes better to proceed to the
ﬁnal registration of the image by using an elastic method [NUN 04a]. The fact that
the most difﬁcult problem (rigid image registration) is dealt with by metaheuristics
means that it is possible to use the optic ﬂow optimization method on the registered
image. Our tests have shown that only one transition from the optic ﬂow onto the
residual image is required in order to overcome the problems linked with errors that
exist in the periphery of the image.
11.5.4.2. Afﬁne image registration
In some cases, a rotation transformation and a zoom transformation can be added
to the translation transformation. Even though these transformations are generally of
a poor quality as far as retinal angiograms are concerned, they can be improved upon
by adopting one of the following two approaches:
1) introduce the rotation and zoom transformations as additional parameters
of the optimized problem (the problem which has been optimized by one of the
metaheuristics);
2) let the ﬁnal optic ﬂow resolve any additional transformations.
Our tests have shown that if the ﬁrst approach is adopted, it is possible to carry
out large-scale transformations. However, if this approach is used it will dramatically

294
Optimization in Signal and Image Processing
(a) non registered
(b) registered
0
1
2
3
4
5
6
7
8
9
10
1
2
3
4
5
6
7
8
9
10
11
(c) translation
Figure 11.16. An example of poor peripheral image registration
increase the complexity of the problem. It is therefore necessary to increase the
number of points to be tested, which in turn increases the processing time that is
required. On the other hand, if the second approach is adopted, it is possible to
carry out transformations without having to increase an algorithm’s processing time.
However, this method can only be used to resolve small-scale transformation issues.
In the case of retinal angiograms, the rotation and zoom transformations are
generally small-scale, in comparison to the translations which are caused by the
movement of the eye. It is therefore best to use the optic ﬂow algorithm.

Metaheuristics for Continuous Variables
295
11.6. Analysis of the results
Our results have shown that the use of metaheuristics during the optimization
phase of the registration of an angiogram image can be particularly useful as far
as high resolution images are concerned. The main advantage of the optimization
methods which have been introduced in this chapter is their processing time which
is constant, regardless of the resolution of the images. With traditional algorithms,
such as the optic ﬂow algorithm, processing time increases as the resolution of the
images increases, whereas with the methods introduced in this chapter the processing
time remains almost constant. This advantage comes from the fact that metaheuristics
use samples from the objective function. Such samples do not rely on the resolution of
the image that is to be registered. The processing time for each algorithm is therefore
a function of the processing time that is required to ﬁnd a solution to a problem.
However, processing time is one of the major constraints faced by the algorithms.
Our results have shown that, for high resolutions, using additional ﬁltering is not
advantageous because it decreases the accuracy of the algorithm and increases its
processing time by adding an additional phase to the optimization process. It is
therefore necessary to avoid adding additional ﬁltering phases since they are capable
of removing any relevant information that can be used by the metaheuristics and thus
reduce their ability to ﬁnd a global optimum.
The Nelder-Mead local research method has the same advantages as the
metaheuristics in terms of processing time. However, our results have shown that
the accuracy of this local research method decreases when it is used to resolve
high-resolution problems. This is due to the fact that local optima are present, and as
a result the research method is tricked into believing that these optima are in fact
global, not local. This problem occurs quite often when optimization methods are
used to resolve image registration issues and one solution that can be used involves
adopting a multi-resolution approach. Such approaches require large amounts of
processing time. The use of metaheuristics, however, solves the problem linked to the
presence of local optima without dramatically increasing the algorithm’s processing
time.
The CHEDAsn method seems to be the most effective optimization method,
closely followed by the CHEDAs method. The HCIAC algorithm has a relatively
poor level of accuracy. A large part of the CHEDA’s efﬁciency is undoubtedly due to
the use of a normal distribution, which has a form that is very similar to that of the
objective function.
The problems linked to peripheral errors or afﬁne transformations are much less
serious than the problems linked to searching for the perfect translation transformation
of a retinal angiogram. This problem can only be resolved by using a rigid approach.
An elastic image registration method can be used to carry out a residual transformation
of a retinal angiogram.

296
Optimization in Signal and Image Processing
11.7. Conclusion
Image registration is an important concept for several applications which deal
with the analysis of medical images, such as the correction of eye movements or
multi-modal forms.
Due to the movements that are made by the eyes when a retinal angiogram
is being taken, an image registration phase is required in order to improve the
quantitative analysis of retinal diseases. The image registration process makes it
possible to compare an image with the one that was taken directly before. Image
registration also makes it possible to analyze how much a particular retinal disease
has progressed over time.
However, the data that comes from a retinal angiogram varies considerably in
terms of intensity. Is a pre-processing really necessary to overcome this problem
and the problem that is linked to the presence of noise? Wiener ﬁltering, as well as
the calculation of the image’s gradient, are essential, whereas median ﬁltering is not
necessary.
The optimization techniques which have been presented in this chapter have been
adapted so that they can be used to work with high resolution images. The HCIAC
algorithm is more accurate than the Nelder-Mead research method. The CHEDA
algorithm is the most accurate, as it leads to the creation of the highest quality
registered images.
One possible way to improve the image registration process as it stands at the
moment would be to remove the co-variances from the CHEDA algorithm. This would
mean that the vertical and horizontal movements of the eye would not be in correlation
with one another, and a sum of the uni-variant distributions would lead to similar
results, with a shorter processing time. Another possible improvement would be to
use other objective functions that provide a better representation of the problems
associated with image registration. An example of such an objective function would
be the use of mutual information.
11.8. Acknowledgements
We would like to thank the Intercommunal Hospital in Créteil, France, for
supplying us with the images of the retinal angiograms.
11.9. Bibliography
[BAN 96] BANGHAM J.A., HARVEY R. and LING P.D., “Morphological scale-space
preserving transforms in many dimensions”, J. Electronic Imaging, vol. 5, pp. 283–299,
1996.

Metaheuristics for Continuous Variables
297
[BER 99] BERGER J.W., LEVENTON M.E., HATA N., WELLS W. and KINIKIS R., “Design
considerations for a computer-vision-enabled ophtalmic augmented reality environment”,
Lectures Notes in Computer Science, vol. 1205, pp. 399–410, 1999.
[BON 99] BONABEAU E., DORIGO M. and THERAULAZ G., Swarm Intelligence, From
Natural to Artiﬁcial Systems, Oxford University Press, 1999.
[BOS 99] BOSMAN P.A.N. and THIERENS D., An algorithmic framework for density
estimation based evolutionary algorithm, Report no. UU-CS-1999-46, Utrecht University,
1999.
[BOS 00a] BOSMAN
P. and THIERENS
D., “Continuous iterated density estimation
evolutionary algorithms within the IDEA framework”, in MUEHLENBEIN M. and
RODRIGUEZ A. (Eds.), Proceedings of the Optimization by Building and Using
Probabilistic Models OBUPM Workshop at the Genetic and Evolutionary Computation
Conference GECCO-2000, San Francisco, California, Morgan Kauffmann, pp. 197–200,
2000.
[BOS 00b] BOSMAN P. and THIERENS D., IDEAs based on the normal kernels probability
density function, Report no. UU-CS-2000-11, Utrecht University, 2000.
[BRO 92] BROWN L.G., “A survey of image registration techniques”, ACM Comput. Surveys,
vol. 24, pp. 325–376, 1992.
[CAN 99] CAN A. and STEWART C.V., “Robust hierarchical algorithm for constructing a
mosaic from images of the curved human retina”, IEEE Conf. on Computer Vision and
Pattern Recognition, vol. 22, 1999.
[CID 92] CIDECIYAN A.V., JACOBSON S.G., KEMP C.M., KNIGHTON R.W. and NAGEL
J.H., “Registration of high resolution images of the retina”, SPIE: Medical Imaging VI:
Image Processing, vol. 1652, pp. 310–322, 1992.
[COL 02] COLLETTE Y. and SIARRY P., Optimisation Multiobjectif, Eyrolles, 2002.
[DOR 03] DORIGO M. and STÜTZLE T., “The ant colony optimization metaheuristics:
algorithms, applications, and advances”, Handbook of Metaheuristics, vol. 57 of
International Series in Operations Research and Management Science, Kluwer Academic
Publishers, Boston Hardbound, January 2003.
[DRE 03] DREO J. and SIARRY P., “Colonies de fourmis et optimisation continue. De l’utilité
de l’optimisation en général et des colonies de fourmis en particulier, quand l’éthologie et
l’informatique se croisent”, Research seminar by the ISBSP, Créteil, University of Paris 12,
2003.
[DRE 04] DREO J., Adaptation de la méthode des colonies de fourmis pour l’optimisation en
variables continues. Application en génie biomédical, PhD Thesis, University of Paris 12,
2004.
[HAM 00] HAMPSON F.J. and PESQUET J.C., “Motion estimation in the presence of
illumination variations”, Signal Processing: Image Communication, vol. 16, pp. 373–381,
2000.
[HAR 94] HART
W.E.
and
GOLDBAUM
M.H.,
“Registering
retinal
images
using
automatically selected control point pairs”, IEEE International Conference on Image
Processing, 1994.

298
Optimization in Signal and Image Processing
[HIL 01] HILL D.L.G., BATCHELOR P.G., HOLDEN M. and HAWKES D.J., “Medical Image
Registration”, Physics in Medicine and Biology, vol. 46, pp. 1–45, 2001.
[IRA 94] IRANI M., ROUSSO B. and PELEG S., “Computing occluding and transparent
motion”, IJCV, vol. 12, pp. 5–16, 1994.
[JEN 01] JENKINSON M. and SMITH S., “A global optimisation method for robust afﬁne
registration of brain images”, Medical Image Analysis, vol. 5, pp. 143–156, 2001.
[KIM 01] KIM M., JEON J.C., KWAK J.S., LEE M.H. and AHN C., “Moving object
segmentation in video sequences by user interaction and automatic object tracking”, Image
and Vision Computing, vol. 19, pp. 245–260, 2001.
[LAR 02] LARRAÑAGA P. and LOZANO J., Estimation of Distribution Algorithms, A New
Tool for Evolutionary Computation, Genetic Algorithms and Evolutionary Computation,
Kluwer Academic Publishers, 2002.
[MAI 98] MAINTZ J.B.A. and VIERGERVER M.A., “A survey of medical image registration”,
Med. Image Anal., vol. 2, pp. 1–36, 1998.
[MUH 96] MUHLENBEIN H. and PAASS G., “From recombination of genes to the estimation
of distributions I. Binary parameters”, Lecture Notes in Computer Science 1411: Parallel
Problem Solving from Nature, vol. PPSN IV, pp. 178–187, 1996.
[MUK 01] MUKHOPADHYAY S. and CHANDA B., “Fusion of 2D grayscale images using
multiscale morphology”, Pattern Recognition, vol. 34, pp. 606–619, 2001.
[NEL 65] NELDER J.A. and MEAD R., “A simplex method for function minimization”,
Computer Journal, vol. 7, pp. 308–313, 1965.
[NUN 03] NUNES J.-C., Analyse multiéchelle d’image. Application à l’angiographie
rétinienne et à la DMLA, PhD Thesis, University of Paris 12, December 2003.
[NUN 04a] NUNES J.C., BOUAOUNE Y., DELÉCHELLE E. and BUNEL P., “A multiscale
elastic registration scheme for retinal angiograms”, Computer Vision and Images
Understanding, vol. 95, no. 2, pp. 129–149, 2004.
[NUN 04b] NUNES J.-C., DREO J. and SIARRY P., “Rigid registration of retinal angiograms
through Nelder-Mead optimization”, International Workshop on Electronics and System
Analysis, IWESA’04, 2004.
[ODO 94] ODOBEZ J.M. and BOUTHEMY P., Robust multi-resolution estimation of
parametric motion models applied to complex scenes, Report no. 788, IRISA, 1994.
[PIN 98] PINZ A., BERNÖGGER S., DATLINGER P. and KRUGER A., “Mapping the human
retina”, IEEE Trans. on Medical Imaging, vol. 17, pp. 606–619, 1998.
[RIC 98] RICHARD G., SOUBRANE G. and YANNUZZI L.A., “Fluorescein and ICG
angiography”, Thieme, 1998.
[RIT 99] RITTER N., OWENS R., COOPER J., EIKELBOOM R.H. and SAARLOOS P.P.V.,
“Registration of stereo and temporal images of the retina”, IEEE Trans. On Medical
Imaging, vol. 18, pp. 404–418, 1999.
[ROC 99] ROCHE A., MALANDAIN G., AYACHE N. and PRIMA S., “Towards a better
comprehension of similarity measures used in medical image registration”, MICCAI, 1999.

Metaheuristics for Continuous Variables
299
[SIM 01] SIMO A. and DE VES E., “Segmentation of macular ﬂuorescein angiographies, a
statistical approach”, Pattern Recognition, vol. 34, pp. 795–809, 2001.
[TAL 02] TALBI E.-G., “A Taxonomy of Hybrid Metaheuristics”, Journal of Heuristics,
vol. 8, no. 5, pp. 541–564, 2002.
[YU 89] YU J.J.-H., HUNG B.-N. and LIOU C.-L., “Fast algorithm for digital retinal
image alignment”, IEEE Ann. Int. Conf. Engineering Medicine Biology Society, Images
Twenty-First Century, vol. 2, pp. 374–375, 1989.
[ZAN 99] ZANA F. and KLEIN J.C., “A multimodal registration algorithm of eye fundus
images using vessels detection and Hough transform”, IEEE Trans. on Medical Imaging,
vol. 18, pp. 419–458, 1999.
[ZHA 01] ZHANG Z. and BLUM R.S., “A hybrid image registration technique for a digital
camera image fusion application”, Information Fusion, vol. 2, pp. 135–149, 2001.

 
Chapter 12  
Joint Estimation of the Dynamics  
and Shape of Physiological Signals  
through Genetic Algorithms  
12.1. Introduction 
The aim of this chapter is to introduce an optimization technique which is 
based on genetic algorithms (GA). This optimization technique will be used in 
order to estimate brainstem auditory evoked potentials (BAEPs). We must point 
out that in certain abnormalities these physiological signals are generally highly 
non-stationary and are also corrupted by heavy noise, basically due to the 
electroencephalogram activity (EEG).  
Estimating the BAEPs relies on several models, relative to both their 
dynamics and their shape. In this chapter, a definition of BAEPs will be given as 
well as an explanation on the way they are generated. An insight into the 
techniques used in estimating the BAEPs will then be introduced in section 12.3. 
The principle of GAs will be reviewed in section 12.4. The use of such 
algorithms to deal with the problems related to BAEP non-stationarity is 
described in sections 12.5 and 12.6.  
 
 
                              
 Chapter written by AMINE NAÏT-ALI  and PATRICK SIARRY. 
Optimization in Signal and Image Processing 
Edited by Patrick Siarry 
Copyright 0 
2009, ISTE Ltd 

302    Optimization in Signal and Image Processing 
 
12.2. Brainstem auditory evoked potentials 
BAEPs are low energy electrical signals, generated when stimulating the 
auditory system by acoustical impulses. They are mainly used to ensure the 
earliest possible diagnosis of acoustic neuromas.  
An acoustic neuroma is in fact a benign tumor which might lead, in some 
cases, to the death of a patient. One of the first signs of this disease in patients is 
single-sided deafness. Figure 12.1 shows this type of tumor, which can clearly 
be seen on a nuclear magnetic resonance (NMR) image. Although this  imaging 
modality provides precise and detailed information on the location and features 
of the tumor, the study of BAEPs remains a non-invasive and inexpensive test. 
Therefore, the use of BAEPs is not only limited to the detection of acoustic 
neuromas, they can also be used to confirm the integrity of the auditory 
pathways or, if need be, to diagnose certain disorders (such as multiple 
sclerosis).  
In some other clinical applications, the BAEPs are used for the purpose  of 
clinical monitoring; for instance, to study the effects of certain substances on the 
auditory system, and also to help surgeons to preserve the auditory pathways 
during surgery.  
Generally speaking, the aim of the clinician during a BAEP recording 
consists of analyzing the BAEP by trying to reduce any possible error. An 
efficient BAEP analysis regarding a clinical sense depends on the quality of the 
BAEP recognition parameters, usually provided by an expert system. This expert 
system uses a set of extraction algorithms, recognition algorithms and decision 
algorithms. In fact, an accurate clinical interpretation of the BEAP is achieved 
only if its estimation is properly performed. For this purpose, prior useful signal 
features related to BAEPs and to other noise signals such as EEG, EMG, are 
required.  
This information then allows the scientists to model this type of 
physiological phenomena.  
As can be seen in Figure 12.2, a BAEP is characterized by five major waves 
which are denoted by I, II, III, IV/V.  

Estimating Physiological Signals     303 
 
 
0  
1
2
3
4
5
6
7
8
9
10
 
 
Temps (ms)
I
II
III
IV/V
 
Figure 12.1. An image of the brain, 
obtained by ultrasound imaging, 
showing an acoustic neuroma 
(Photo: Baylor College of Medicine) 
Figure 12.2. A real BAEP 
12.2.1. BAEP generation and their acquisition  
The acquisition of a BAEP is carried out as follows: the auditory system is 
excited by a set of acoustic impulses at a frequency which is generally less than 
30 clicks per second. For higher frequencies, the BAEPs might be distorted due 
to the superposition of late evoked potentials. Therefore, some useful techniques 
using a kind of aperiodic stimulations have been proposed in the literature.  
The responses to the stimulations, which can be sampled at a frequency of  
10 kHz, are naturally corrupted by the EEG. Generally, each response is 
recorded over less than 10 ms by using some electrodes which are properly 
located on the vertex and on the mastoid (see Figure 12.3). After the denoising 
process, BAEP wave recognition is then performed. As is well known, the 
different noises corrupting the BAEPs are essentially physiological (e.g. EEG or 
EMG).  
 12.3. Processing BAEPs 
The traditional methods used in estimating the BAEPs consist of averaging 
the recorded responses. The signal-to-noise ratio can reach record values from  
-20 to -30 dB. In practice, it is generally impossible to observe a BAEP directly 
from only a single response, even after the filtering process. As is known, the 
traditional averaging technique is based on the stationarity hypothesis. In other 
words, it is assumed that the BAEP (i.e. useful signal) in each response is time-
invariant and that the noise (i.e. the EEG) is a zero-mean stationary signal. 

304    Optimization in Signal and Image Processing 
 
Therefore, even if this technique seems to be simple, it can achieve excellent 
results in some cases, namely, when the subject is healthy and the recordings are 
carried out under appropriate conditions. In this case, among 800 and 1,000 
responses are generally required to extract an averaged BAEP. This procedure 
assumes that during the acquisition phase, the patient is somehow relaxed. 
However, if the subject is pathological and if the recordings are not carried out 
under appropriate conditions then a larger number of responses is required in 
order to reduce the energy related to the noise in comparison to the energy 
related to the BAEP. Moreover, it is important to mention that the EEG may 
change its spectral and statistical characteristics over recording time, and that 
the EMG can be added to recordings during patient’s muscular contractions. In 
some pathological cases, even if it is possible to reduce the effect of the noise 
during the averaging process, the BAEP non-stationarity regarding both its 
dynamics and its shape leads to an unrecognizable smoothed average signal. In 
this case, an objective analysis becomes a critical task, in particular for latency 
measurement (i.e. the time taken between the moment of stimulation and 
reaching the maximum value of a BAEP wave) or the measurement of 
conduction times (i.e. duration I-III, duration I-IV). 
 
Figure 12.3. The acquisition of BAEPs 
Several signal processing techniques dedicated to extracting BAEPs have 
been suggested in the relevant scientific literature. For example, some 
techniques are based on the weighted averaging principle [DAV 97] or on 
adaptive filtering [YU 94a] and [YU 94b]. These techniques generally use 
information based on the characteristics of noise and do not focus enough on the 
dynamics of the BAEP. The main reason for this is due to the fact that a direct 
BAEP observation from a given recorded response is almost impossible, as has 
been explained previously. 

Estimating Physiological Signals     305 
The approach that has been developed in this chapter is mainly based on 
modeling the non-stationarity (i.e. the dynamics) of the BAEPs, by taking into 
account the fact that the energy of the noise may be reduced during the 
averaging process. The parameters of the models that have been studied will be 
determined by using GAs. The reader can also refer to [NAI 02], [CHE 05] and 
[NAI 06] in which thesimulated annealing (SA) approach has been used as an 
optimization technique.  
The use of this metaheuristic can be justified by the fact that models may be 
dynamic and complex (due to the non-convexity of the criteria to be optimized). 
In terms of computing, only a single code is required for the whole set of 
models. The advantage here consists of avoiding an increasing number of 
algorithms and also means that it is possible to considerably reduce the memory 
space required for storing code. It should also be pointed out that GAs can be 
easily adapted for use on multiprocessor platforms.  
In the following section, the principle of a GA is introduced. It will be used 
throughout this chapter to deal with the problem of estimating BAEPs.  
12.4. Genetic algorithms 
GAs were developed in 1979 by J. Holland and his colleagues at the 
University of Michigan. The basic idea of GAs was inspired by the theories of 
natural selection and genetics. In order to understand how GAs work, it seems 
important to be aware of some of their basic principles which will then be 
applied to the problem that we are facing in relation to estimating the BAEPs 
(see Table 12.1).  
Let us assume that a population is made up of N individuals. In terms of 
genetics, each individual is characterized by a chromosome. At a lower level, 
the chromosome is made up of genes. The first generation is considered as a first 
generation able to evolve in a given environment in order to produce other 
generations by following the rules of reproduction, crossover and mutation. In 
other words, certain individuals will disappear from one generation to the next, 
(i.e. the weakest will disappear). The strongest will be able to reproduce with no 
modifications: the child is the clone of his parent. On the other hand, certain 
individuals from the same generation will be able to crossover so that the future 
generation can have similar characteristics. Certain genes of certain individuals 
can be changed and replaced by genes from the search space. 
 

306    Optimization in Signal and Image Processing 
 
Population 
A set of potential solutions in a generation (m).  
(
)
(
)
(
)
1
2
,
,...
m
m
m
K
d
d
d
 
(
)
m
id
is a vector with M parameters to be determined. 
Chromosome 
or individual  
A potential solution 
(
)
m
id
 : 
(
)
(
)
(
)
(
)
,0
,1
,
1
...
t
m
m
m
m
i
i
i
i M
d
d
d

ª
º
 ¬
¼
d
 
Gene 
An element of a potential solution. For example: 
(
)
,
m
i n
d
 , n=0,…M-1. 
Reproduction A potential solution in a generation (m-1) is maintained in the next 
generation (m). 
Breeding 
Two potential solutions of a given generation (m-1) are combined to  
generate two other solutions for the future generation (m). 
Example: 
(
1)
m
i

d
 and 
(
1)
m
j

d
 can produce
(
)
m
id
 and 
(
)
m
j
d
  : 
(
1)
(
1)
(
1)
(
1)
(
1)
(
1)
(
1)
(
)
,0
,1
,
2
,
1
(
1)
(
1)
(
)
,0
,1
... ...
...
 
 
 
 
 
 
 
 
d
 
 
 
 
d
 
m
m
i
j
m
j
m
m
m
m
m
i
i
i
j M
j M
Elements of d
Elements of d
m
m
m
j
j
j
Elements of d
d
d
d
d
d
d











 
¯
¡
°
¡
°
 ¡
°
¡
°
¡
°
¢
±

	
 	
	

(
1)
(
1)
(
1)
,
2
,
1
...
 
 
 
 
 
m
i
m
m
i M
i M
Elements of d
d
d





 
¯
¡
°
¡
°
¡
°
¡
°
¡
°
¢
±
	

 
Mutation 
If 
(
1)
m
i

d
is a potential solution in a generation, the mutation can occur 
in the following generation in order to generate 
(
)
m
id
by modifying one  
of its elements: 
Example: 
(
1)
(
1)
(
1)
(
1)
,0
,1
,
1
...
t
m
m
m
m
i
i
i
i M
d
d
d





ª
º
 ¬
¼
d
 
(
)
(
)
(
)
(
)
,0
,1
,
1
...
t
m
m
m
m
i
i
i
i M
d
s
d

ª
º
 ¬
¼
d
 
The element 
(
)
,1
m
id
 has been replaced by
(
)
,1
m
is
. 
Table 12.1. The principle of GAs 

Estimating Physiological Signals     307 
12.5. BAEP dynamics 
In this study we consider that the BAEPs vary over the time from one 
response to another according to random delays. This problem, known as “jitter”  
(i.e. desynchronization of the signals), which can be due to a physical or 
physiological origin, is not new in terms of signal processing. There are many 
different methods of dealing with similar problems, such as the techniques that 
are used to solve some problems related to radar detection, or even in some 
specific biomedical engineering applications. Unfortunately, these methods 
cannot be adapted to our problem, especially because the recording conditions 
are particularly poor (i.e. very low SNR). We must point out that BAEP 
desynchronization in each single response is only an assumption. However, if 
such an assumption turns out to be true, a phenomenon known as smoothing, 
which occurs during the averaging process, will be unavoidable. The distortion 
which is caused by smoothing can lead to quite serious consequences depending 
on the nature of desynchronization (distribution, variance). In such situations, as 
mentioned above, two distinct waves from a BAEP may be transformed into one 
single wave.  
In order to describe this phenomenon according to a mathematical formula, 
we assume that at each 
th
i
 stimulation, a signal
	 
ix n , is recorded. This signal 
can be explained as follows: 
 


 
i
i
i
x n
s n
d
b n
 


 
[12.1] 
where: 
s(n)  is the useful signal (BAEP) that we want to estimate; 
	 
ib n  is the noise, corrupted by the EEG during the th
i
acquisition; 
id  represents the time delay of each signal s(n) (in relation to the moment of 
stimulation). 
For M stimulations, averaging leads to:  
 


 
1
1
0
0
1
1
     +
M
M
i
i
i
i
A
B
x n
s n
d
b n
M
M


 
 
 

¦
¦
	
	
 
[12.2] 

308    Optimization in Signal and Image Processing 
 
From equation [12.2], it is clear that term B (which is related to the noise) 
can be neglected if the statistical average of the noise is zero or close to zero 
(
>
@
( )
0
E b n
|
). If the noise is not a zero-mean process, several situations can 
arise: 
1. 
The noise is a 1st order stationary process: in this case, the averaging 
provides an offset and a pre-filtering is necessary. Therefore, whatever the energy of 
this component is, its influence will be completely eliminated. 
2. 
The noise is stationary but its statistical average moves towards a low 
energy signal. 
3. 
The residual noise signal provided by the averaging process is not 
correlated to the useful signal (i.e. the BAEP). In such cases, a simple filtering over 
the BAEP bandwidth is necessary. 
4. 
The components of the averaged noise overlap with the BAEP components. 
Pre-filtering can only reduce the noise’s influence. 
What happens in real situations? The EEG signal is a cortical activity and is 
considered as a major noise source in BAEP clinical routines. It should also be 
pointed out that this signal has been largely studied in specialized scientific 
literature. It has been studied from different points of view according to pre-
defined objectives and under certain conditions. The different characterizations 
and models that have been suggested in the literature cannot be directly applied 
to the context in which we are working.  
In order to show how the EEG influences the estimation of BAEPS (i.e. in 
terms of averaging) we take the example of a small experiment which consists of 
averaging 800 acquisitions from an actual EEG. In this experiment we consider 
that BAEPs are totally absent in each acquisition. In Figure 12.4 we have 
superimposed several BAEP realizations in order to provide an idea of the 
energy produced by each of these realizations in comparison with the energy of 
the signal that is obtained through the averaging process (see Figure 12.5). The 
first comment that can be made when comparing the energy produced is that, 
after averaging, the energy has been reduced by 400% (which tends to greatly 
reduce the influence of noise on the averaged signal). This example was chosen 
randomly; other similar examples could also be illustrated to show that the noise 
average decreases according to a non-linear manner. Of course, this decrease 
depends on the nature of the EEG, which depends on the recording conditions 
that are relative to a given patient.  

Estimating Physiological Signals     309 
It is widely known that the properties of the EEG tend to vary whenever the 
patient passes from one state to another (i.e. tense patient, relaxed patient, 
patient who is asleep). Furthermore, movements such as eyes blinking and 
muscular contractions also contribute to the slowing down of the rate at which 
the EEG is attenuated by the averaging process.  
Now that we are sure that the influence of the noise during the averaging 
process is almost negligible for a given number of responses, a possible 
distortion of the BAEP signal can only occur due to its unstable feature. 
Consequently, in these conditions the characterization of the EEG is not 
important when it comes to estimating the BAEPs.  
 
 
Figure 12.4. The superposition of  
several creations 
Figure 12.5. Averaging of 800 creations 
It should also be pointed out that if it is possible to identify the way in which 
the BAEPs vary throughout time, it would probably make it possible: 
1. to estimate the BAEP that corresponds to each stimulation; 
2. to determine the dynamics of the BAEPs. 
 
The second point mentioned above could also be used as an indicator in some 
techniques of functional exploration.  
Under these conditions the averaged signal can be explained as follows: 
 


1
0
1
M
i
i
x n
s n
d
M

 
 

¦
 
[12.3] 

310    Optimization in Signal and Image Processing 
 
 
Figure 12.6. A model of a BAEP used in simulations 
The issue that now arises is the following: how is it possible to estimate the 
delay parameters di ? If we want to find the best solution for a given criterion, 
then the use of an optimization algorithm is necessary. 
If the recorded M signals and their direct averages are already known, then 
the issue of optimization can be dealt with as follows: find the best set of 
parameters di, which maximizes the energy of the averaged signal.  
This condition is only validated if the BAEPs are aligned. In mathematical 
terms this can lead to maximizing the following energy equation:  
2
1
1
0
0
1
(
)
N
M
i
i
n
i
f
x n
d
M


 
 
§
·
 

¨
¸
©
¹
¦
¦
d
 
[12.4] 
where:  
d=[
0
1
2
1
,
,
,.....,
M
d
d d
d
 ] represents the vector of the delay parameters,  
N is the number of samples in each response.  
The optimization problem can thus lead to the minimization of the following 
equation: 
 


2
1
1
0
0
1
N
M
i
i
n
i
J
x n
d
M


 
 
§
·
 

¨
¸
©
¹
¦
¦
d
 
[12.5] 

Estimating Physiological Signals     311 
It is clear that equation [12.5] is neither quadratic nor convex. If we adapt the 
problem to two dimensions (i.e. estimation of two delays d0 and d1), the 
objective function will introduce an aspect which is similar to that which can be 
seen in Figure 12.7 (simulations obtained from the BAEP which can be seen in 
Figure 12.6). 
 
 
Figure 12.7. The estimation of two delay parameters 
However, we can see that the global optimum of this objective function is not 
unique. The reason for this is that the BAEPs can be synchronized at distinct 
moments. 
In order to guarantee the uniqueness of the solution it is important to keep 
the signals still. An example is illustrated in Figure 12.8 which shows a two-
dimensional problem (M=2). The first BAEP is fixed while the second is 
moving. At each point the sum of the two signals is recalculated.   
 

312    Optimization in Signal and Image Processing 
 
 
Figure 12.8. The estimation of two delay parameters by fixing  
one in relation to the other 
In this case, the objective function is only one minimum point (the alignment 
of the two signals). This problem can be extended to the case M=3 when 
determining the first signal. The resulting objective function from this analysis 
shows several local minima and only one global maximum, the latter 
corresponding to the moment when the set of signals is synchronized. This can 
be seen in Figure 12.9.  
 
Figure 12.9. The estimation of two delay parameters which are calculated in relation to 
the first signal, used as a reference 

Estimating Physiological Signals     313 
The generalization of the problem with M dimensions also requires that one 
of the responses be considered as a reference signal, for example the first 
response. After the convergence of the optimization algorithm, the set of BAEPs 
will be systematically aligned with the first signal.  
12.5.1. Validation of the simulated signal approach 
This phase of simulation is fundamental. It enables us to validate the 
proposed algorithm (summarized in Table 12.2) when the acquisition conditions 
have been verified, and it also makes it possible to check the convergence of a 
signal towards a global minimum. All of the simulations are created from a 
model of the BAEP, which is corrupted by an 8th order autoregressive (AR) 
noise. The AR model is often used to model the EEG. In terms of energy, the 
effect of the AR model becomes negligible after the averaging process, in 
relation to the energy of the useful signal (BAEP). First of all, Gaussian random 
perturbations are considered; then some non-Gaussian cases are analyzed. 
 
  
1. 
Choose, at random, K vectors which represent potential solutions. Each solution is 
made up of M delays which correspond to M responses, 
2. 
Reproduction stage: generate K other potential solutions with the help of 
crossover and mutation operators, 
3. 
Evaluate the objective function in each of the potential solutions, 
4. 
Selection stage: take the best K solutions amongst the K+k solutions so that the 
following generation can be produced, 
5. 
Save the best solution, 
6. 
If the number of maximal generations is not reached, go back to 2, 
7. 
Solution = best point found, stop the program. 
 
Table 12.2. The genetic algorithm applied to the estimation of BAEP delays 
12.5.1.1. Random Gaussian distribution desynchronization 
Simulations are carried out on 200, 400 and 800 responses. Each BAEP is 
randomly moved according to Gaussian distribution and is then corrupted with 
an AR noise. As has been previously mentioned, the phenomenon of Gaussian 
desynchronization systematically leads to a smoothing of the waves during 
averaging. Figure 12.10 shows that the two waves II and III, as well as the 
complex IV/V, have been overlapped (test carried out on 200 responses). The 
problem which is then raised by the clinician is the difficulty in extracting the 

314    Optimization in Signal and Image Processing 
 
clinical parameters (latencies and conduction time) from such a signal, which 
makes any analysis and interpretation of such parameters extremely difficult to 
carry out. Figure 12.11 shows that it is possible to restore the shape of the BAEP 
after the synchronization of the responses using the solutions which result from 
the optimization of equation [12.1]. The waves go back to their original shape, 
as well as to their original amplitudes and original latencies.  
 
 
Figure 12.10. Averaged signal based on 200 
acquisitions 
Figure 12.11. Signal obtained after 
synchronization 
Such a result would not have been possible with basic techniques such as 
adapted filtering. In fact, adapted filtering can only be used if the signal-to-noise 
ratio is favorable. 
Figure 12.12 shows the set of BAEPs to be synchronized in the shape of an 
evolutionary surface. For illustrative reasons, we will not show the noise that 
corrupts each response. The objective is to highlight the alignment that is 
obtained after synchronization (see Figure 12.13).  
We are now going to analyze the delay vector which disturbs the BAEPs and 
then compare it with the optimal solution provided by the GA which minimized 
in equation [12.3].  
To analyze and use the results it must be pointed out that the solution 
required for the synchronization of the BAEPs is the opposite value of the delay 
vector. When analyzing and using the results, the analysis can be compared to a 
physical system that has been unbalanced by a force in one direction; then the 
system is rebalanced by applying a second force in the opposite direction. Figure 
12.14 compares the unbalancing vector with the (inversed) solution after the 

Estimating Physiological Signals     315 
convergence of the GA. Figure 12.15 represents the convergence of the GA in 
relation to 500 generations.   
 
Figure 12.12. 2D representation of BAEPs before synchronization 
 
Figure 12.13. 2D representation of the signals after synchronization 

316    Optimization in Signal and Image Processing 
 
When it comes to experiments with 400 and 800 responses, processing time 
clearly becomes more significant and is characterized by non-linear growth. This 
behavior is essentially due to the stochastic nature of the algorithm.  
 
 
Figure 12.14. 
[- ] Original delay signal, [...] estimated 
signal, used for the synchronization of 200 
BAEPs 
Figure 12.15.  
Convergence curve on 500 generations 
It is clear that the convergence time is not the only criterion used for 
evaluating the performances of the optimization algorithm. Other parameters, 
such as variance as well as the bias of the averaged signal after synchronization, 
can be taken into consideration. Tests on the same set of signals that were 
initially used can be carried out by using these other parameters. The fact that 
the GA is of a stochastic nature means that the results will undoubtedly be 
different from one test to another.  
By superimposing the estimated signals from each test, as shown in Figure 
12.16, we can gather some information about the variance of the estimator. This 
illustration clearly shows that the dispersion of the solutions is minimal.  The 
bias can be evaluated by simply calculating the average of the results from the 
different tests and by comparing the average with the ideal solution (which is 
represented by the BAEP model in Figure 12.17). With a very low variance and 
an almost zero bias, it is possible to consider the estimator as consistent.  

Estimating Physiological Signals     317 
 
 
Figure 12.16. Analysis of the  
estimator’s variance 
Figure 12.17. Analysis of the  
estimator’s average 
12.5.1.2. Non-Gaussian desynchronization  
Now that we have studied the general case of Gaussian randomization of the 
BAEPs, we are going to have a look at some unusual cases.  
Let us consider that the shape described by the delays does not emanate from 
a Gaussian distribution as was the case previously, but could describe any shape 
(an example is given in Figure 12.18). In this shape we consider that the set of 
BAEPs are delayed in only two stages. Everything occurs as if a normal 
acquisition was taking place without the BAEPs being delayed at the beginning; 
suddenly, the BAEPs move in one direction (with a continual delay), then move 
in the other direction before going back to their initial state. This sudden 
movement might occur in certain surgical procedures, in particular when the 
surgeon is working on auditory pathways. 
Two-dimensional illustrations of the BAEPs are shown in Figure 12.19 
(signals before synchronization) and in Figure 12.20 (signals after 
synchronization). 
We have seen that when it comes to Gaussian desynchronization, the 
averaging process leads to a smooth signal. This phenomenon cannot occur 
when randomization is commonplace. Averaging in such situations can lead to 
the generation of false supplementary waves.  

318    Optimization in Signal and Image Processing 
 
 
Figure 12.18. [-] Delay signal, [...] estimated synchronization signal 
 
Figure 12.19. 2D representation of the BAEPs before synchronization 

Estimating Physiological Signals     319 
 
Figure 12.20. Representation of the BAEPs after synchronization 
 
 
As far as tackling the problem of desynchronization is concerned, we have 
illustrated other atypical cases in Figures 12.21 and 12.22. The objective is to 
establish that the algorithm that is used ensures the convergence towards the 
global minimum, whatever the nature of the delay. The only difference is that 
the number of generations required by the GA is variable. This variability in the 
number of generations required by the GA leads to problems associated with the 
stop criterion.  
 
 
Figure 12.21. 
[-] Desynchronization signal in the  
form saw teeth, [...] estimated 
 synchronization signal 
Figure 12.22. 
[-] Desynchronization signal in the  
form of rugged saw teeth, [...]  
estimated synchronization signal. 

320    Optimization in Signal and Image Processing 
 
12.5.2. Validating the approach on real signals 
Simulations have shown that the approach that we have just mentioned 
allows for convergence towards the optimal solution regardless of the nature and 
the dynamics of the BAEP. The use of this approach on real signals can only be 
efficient if the hypotheses and recording conditions are verified. The problem 
that then arises in the case of real signals is that the type of non-stationarity of 
the BAEPs is unknown. It is impossible to confirm that the BAEP signals are 
desynchronized. The BAEPs cannot be observed in one given acquisition due to 
the energy coming from the EEG. As a consequence, when this approach is 
applied to real signals, it is initially assumed that the signals are delays. The 
reliability of this hypothesis is then checked afterwards.  
Two different cases arise: 
1. Traditional (or direct) averaging leads to an BAEP with an unrecognizable 
shape, while corrected averaging leads to the formation of a normal-shaped 
BAEP (which can be identified by its five waves). In this case we can confirm 
that the BAEP dynamics is a “delay”. Under no circumstances should the 
clinicians settle for only the corrected signal because if they do they run the risk 
of overlooking information that is linked to a particular disease; this information 
is introduced in the delay vectors which are used to correct the average signal. 
This vector could therefore be used as an indicator of a potential disease.    
2. The BAEP signal that has been averaged by the traditional method is 
unrecognizable. This case may occur due to one of the following two reasons: 
a. the BAEP dynamics is not a delay signal: in this case, we should modify 
the dynamic model of the BAEP; 
b. the number of M acquisitions is not sufficient to reduce the energy of the 
averaged noise: it is therefore necessary to increase the number of acquisitions, 
which also means an increase in processing time.  
Figures 12.23 and 12.24 illustrate a case that corresponds to a real recording.  
The patient is 70 years old and is stimulated at an intensity of 90 dB. The 
only clinical information that we have shows that this patient suffers from 
vertigo and from a loss in hearing. At this stage, the clinical information we 
have is poor and does not allow us to establish an objective correlation between 
the shape of the signal and the patient’s illness. An ideal situation would be to 
be able to identify the disease by simply looking at the shape of the BAEP. 
Unfortunately, we are still quite far from reaching this goal and in order to do 
so, a radical review in the way BAEPs are recorded is needed. Nevertheless, the 
results that have been obtained from real signals have been encouraging as our 

Estimating Physiological Signals     321 
objective was to have access to hidden information. This hidden information 
provides information relating to the movement of the BAEPs. With this 
objective in mind, it will enable future studies to be carried out in a more 
determined rather than statistical manner. As we can see in Figure 12.23, wave 
II seems to have been smoothened with wave III when only traditional averaging 
is used. The separation of these two waves is clearly visible after the 
synchronization process (see Figure 12.24). 
 
 
 
 
Figure 12.23. Signal obtained by 
averaging 800 acquisitions 
Figure 12.24. Corrected signal (separation  
of waves II and III) 
12.5.3. Acceleration of the GA’s convergence time 
In the method that has been described up to this point, the number of 
parameters (delays) to be estimated corresponds exactly to M responses that are 
used to extract the BAEP.  
The question that can now be asked is the following: is it possible to estimate 
M delays by using fewer parameters? It is possible, but on the condition that we 
can parametrically model the curve that is described by the delays.  
Let us take the example in which the delays vary according to a sinusoidal 
curve. In this case, it is possible to use a total of three parameters (instead of 
800). It is a question of the frequency of the sinusoid, its amplitude and its 
phase. If the curve that is described by the delays is slightly more complex than 
the sinusoid, then we can think of using a larger scale sinusoid, (i.e. two, three, 
… k sinusoids).  

322    Optimization in Signal and Image Processing 
 
Generally speaking, a delay-curve modeled by k sinusoids needs 3.k 
parameters that have to be identified. This approach is seen by some as 
following the principle of the Fourier transform approach. It is clear that a 
compromise in relation to processing time must be taken into consideration. This 
approach can only be efficient if 3.k<M.  
What has just been mentioned can be described in what follows below.  
The delay corresponding to the ith acquisition can be expressed by:    


 
 sin 2
      
1
                           
K
d
A
f i
k
k
i
k
k
 

¦
 
S
I
 
[12.6] 
where: 
k
A   is the amplitude of the kth sinusoid, 
kf   is the frequency of the kth sinusoid, 
k
I   is the phase of the kth sinusoid, 
 K is the number of sinusoids. 
The problem once again comes back to estimating the set of parameters Ak , 
fk  and k
I  in relation to equations [12.5] and [12.6]. In this case, by inserting 
the model of equation [12.6] within equation [12.5] we obtain the following: 


2
1
1
0
0
1
sin 2
 
1
N
M
i
n
i
J
x
n
M
K
A
f i
k
k
k
k
S
I


 
 
§
·
§
·
¨
¸
¨
¸
 

¨
¸
¨
¸
¨
¸
©
¹
©
¹

¦
 
¦
¦
d
 
[12.7] 
The introduction of the delay model means that the optimization algorithm 
must be adapted because here the optimization problem is not completely 
combinatory. This is because the search space depends on the nature of the 
parameters to be identified: 
 The values of the amplitudes Ak  are limited by the frequency of the 
samples, as well as by the duration of the ith acquisition, which leads to the 
creation of a combinatory case. 

Estimating Physiological Signals     323 
 The frequencies fk  are positive and are able to take any value in 

 . The 
problem is therefore continuous. 
One possible adaptation is to discretize the search space depending on the 
precision that is desired, even if the desired precision has the negative effect of 
increasing processing time.  
Other optimization techniques could also be used, such as ant colonies [DOR 
96], [DOR 97], [DRE 02] or the particle swarm optimization technique which 
tends to be used the most [KEN 97]. 
 
Figure 12.25. An example of a sinusoidal delay model which  
leads to a distortion of the BAEP 
Figure 12.25 illustrates an example in which the BAEPs are delayed by 
following a sinusoidal curve. Does this occur in practice? Perhaps the curve is 
not exactly sinusoidal but BAEPs with a low frequency are subject to possible 
movements. 
In certain clinical tests when analyzing the movement of wave V over time, it 
is also possible to study the fatigue of the auditory system following stimulation 
that has gone on for several hours. 

324    Optimization in Signal and Image Processing 
 
In certain studies it is also possible to analyze the effect that certain 
substances have on the auditory system, such as sodium chloride or Amikacin, 
in the shape of a BAEP.  
Generally speaking, this approach seems appropriate in such situations and in 
particular when tens of thousands of responses are used. For a given protocol, 
this approach, in fact, does not depend on the number of acquisitions. 
The results which come from the simulations on delay models of order 2 (i.e. 
two sinusoids) and order 5 (i.e. five sinusoids) are shown in Figures 12.26 and 
12.27 respectively.  
 
Figure 12.26. Delays according to two 
sinusoids, [-] original signal.[... ] signal 
estimated by the model 
Figure 12.27. Delays according to five 
sinusoids, [-] original signal, [...] signal 
estimated by the model 
12.6. The non-stationarity of the shape of the BAEPs 
It has been noticed that in certain BAEP clinical examinations, and in 
particular when it comes to retro-cochlear diseases, the shape of the BAEPs is 
unusual and sometimes completely unrecognizable. BAEPs tend to change shape 
quite randomly over time. During this transformation, the notion of the 
compression and dilation of the shape of the BAEP over time should be taken 
into consideration. As a consequence, the traditional averaging of the responses 
could lead to an overall deformation of the BAEP, thus making it impossible to 
work with. This deformation is not strictly related to the smoothness of the 
waves as was mentioned when describing the previous type of non-stationarity. 
However, deformation could lead to the production of other virtual waves, 
which in turn may lead to a false clinical interpretation. 

Estimating Physiological Signals     325 
In basing our judgment on equation [12.8], we assume that the BAEP is 
compressed or dilated according to a factor known as 
ia , which is a random 
factor with an unknown distribution. When 
ia  is greater than 1, the BAEP tends 
to be compressed and when 
ia  is less than 1 the BAEP becomes longer. The 
factor 
ia  varies over time and plots an uncharacteristic two-dimensional surface 
as can be seen in Figure 12.28.  
The signal that results from the average of these BAEPs leads to a disordered 
BAEP (Figures 12.29 and 12.30). 
 


 
.
i
i
i
x n
s a n
b n
 

 
[12.8] 
 
Figure 12.28. Two-dimensional surface which is obtained from uncharacteristic  
non-stationarity due to the compression and dilation of the BAEPs 
Our aim is to invert the function that leads to the creation of such a signal. 
This inversion must ensure the synchronization of the set of BAEPs so that they 
can converge to become one single shape. The solution involves dilating or 
compressing the M responses in such a way that the energy of the averaged 
signal is at its maximum. Once again we experience another optimization 
problem, a problem that we wanted to resolve through the use of GAs. The 

326    Optimization in Signal and Image Processing 
 
objective function requires polyphase-type filters. The dilation of each 
acquisition must be ensured by the principle of interpolation, whilst compression 
is ensured by sub-sampling. In each iteration of the GA, several combinations of 
polyphase filters are applied. The equation to be minimized is as follows:  


2
1
1
0
0
1
d
N
M
i
i
n
i
J
x
a n
M


 
 
§
·
 
¨
¸
¨
¸
©
¹
¦
¦
 
[12.9] 
It is clear that clinicians are unable to make any objective diagnosis by solely 
basing their judgment on the averaged and corrected signal. The curve that 
describes the evolution of the compression/dilation parameters represents an 
important indicator that the clinician can use to quantify the changes that a 
BAEP can experience from one stimulation to another.  
 
 
Figure 12.29. Comparative analysis, 
[...]BAEP obtained by averaging, 
[-]BAEP obtained after correction 
Figure 12.30. Evolution of the parameters 
of compression/dilation, [-] curve used for 
the deformation of the BAEPs, [...] curve 
estimated by the GA 
The two dynamics of BAEP mentioned before this point have dealt with the 
process of desynchronization, and the idea of compression and dilation.  
These two characteristics can be joined together in the same equation, as can 
be seen in equation [12.10]. A possible generalization of these two 
characteristics can be made and this can be seen in equation [12.11]. In equation 
[12.11] each recorded BAEP is considered to be deformed by a non-linear 
system which varies over time according to one operator (which is not strictly 
linear), and which is noted as ; . 

Estimating Physiological Signals     327 
 


 
.
i
i
i
i
x
n
s k n
d
b n
 


 
[12.10]  
 
 
 
( )
i
i
i
x n
s n
h n
b n
 
;

 
[12.11] 
Without being too optimistic, we believe that the increasing processing 
power of computers will make it easy to explore these types of models.  
12.7. Conclusion 
Metaheuristics often use a lot of computer processing time; but their 
efficiency in terms of optimizing non-linear equations provides a considerable 
advantage. As we have seen in this chapter, only one algorithm is needed and is 
efficient for solving several types of non-stationarity of the BAEPs. In certain 
situations, and in particular when the signals are characterized by a slow 
dynamics, we have shown that the convergence towards a global optimum can 
be effectively accelerated. The results could be further improved by introducing 
further degrees of freedom in the criteria that need to be optimized.  
12.8. Bibliography 
 [CHE 05] CHERRID N., NAIT-ALI A., SIARRY P., “Fast simulated annealing algorithm for 
BAEP time delay estimation using a reduced order dynamic model”, Med. Eng. and 
Phys., vol. 27, Issue 8, pp.  705-711, 2005. 
[DAV 92] DAVILA C., MOBIN M., “Weighted averaging of evoked potentials”, IEEE Trans. 
Biomed. Eng., vol. 39, pp. 338-45, 1992. 
[DOR 96] DORIGO M.,  MANIEZZO V., COLORNI A., “The ant system: optimization by a colony 
of cooperating agents”, IEEE Trans. Syst. Man Cybern, vol. 26, pp. 29-41, 1996. 
[DOR 97] DORIGO M., GAMBARDELLA L., “Ant colony system: a cooperative learning 
approach to the travelling salesman problem”, IEEE Trans. Evol. Comp., vol. 1, pp. 53-
66, 1997. 
[DRE 02]  DRÉO J., SIARRY P., “A new ant colony algorithm using the heterarchical concept 
aimed at optimization of multiminima Continuous Functions”, Proceedings of the Third 
International Workshop on Ant Algorithms (ANTS”2002), vol. 2463, pp. 216-221, 
Brussels, 2002. 
[KEN 95] KENNEDY J., EBERHART R., “Particle swarm optimization”, in Proc. IEEE Int’l. 
Conf. on neural networks, pp. 1942-1948, 1995. Piscataway, NJ. 
[NAI 02] NAIT-ALI A., SIARRY P., “Application of simulated annealing for estimating BAEPs 
in some pathological cases”, Med. Eng. and Phys., vol. 24, pp. 385-392, 2002. 

328    Optimization in Signal and Image Processing 
 
[NAI 06] NAIT-ALI A., SIARRY P., “A new vision on the averaging technique for the 
estimation of non-stationary brainstem auditory evoked potentials: application of a 
metaheuristic method” , Comp. in Biol. and Med., vol. 36, pp. 574-584, 2006. 
 
[QIU 94] QIU W., CHAN F., LAM F.,  POON P., “An enhanced approach to adaptive processing 
of the brainstem auditory evoked potential”, Australas. Phys. Eng. Sci. Med., vol. 17, pp. 
131-5, 1994. 
[YU 94a] YU X., “Time-varying adaptive filters for evoked potential estimation”, IEEE Trans. 
Biomed. Eng., vol. 41, pp. 1062-71, 1994. 
[YU 94b] YU X., ZHANG Y., HE Z., “Peak component latency-corrected average method for 
evoked potential waveform estimation”,  IEEE Trans Biomed. Eng., pp. 1072-82, vol. 41, 
1994. 
 
 
 
 

 
Chapter 13 
Using Interactive Evolutionary Algorithms  
to Help Fit Cochlear Implants 
13.1. Introduction 
The surgical technique which enables profoundly deaf people with a fully 
functional cochlea to hear again was developed some 40 years ago [LOI 98]. During 
the surgical procedure, the surgeon inserts a very thin silicon filament which bears 
several electrode inserts, into the cochlea of the patients. The aim of this procedure 
is to stimulate the auditory nerve. The electrodes are connected to an antenna which 
is surgically placed under the skin, just behind the patient’s ear (see Figure 13.1).  
In order to activate the electrodes, the patient wears a small apparatus called a 
BTE (for behind the ear) which looks like a hearing aid. The BTE is made up of two 
microphones that are connected to a digital signal processor (DSP) which transforms 
the received signal into electric pulses which are sent to the electrodes. The BTE is 
connected to a second exterior inductive antenna which works in collaboration with 
the antenna that is implanted under the patient’s skin, thanks to the use of a powerful 
magnet. The impulses that are emitted by the DSP are transmitted to the electrodes 
which have been implanted by the two inductive antennae (see Figure 13.1).  
The objective of the interface that is created is to stimulate the auditory nerve 
with the aim of restoring the patient’s hearing to a certain level so that they are able 
to understand spoken language. The question of how to stimulate the auditory nerve 
is very important. It is tackled by adjusting the parameters of the DSP. 
                                                      
Chapter written by Pierre COLLET, Pierrick LEGRAND, Claire BOURGEOIS- RÉPUBLIQUE, 
Vincent PÉAN and Bruno FRACHET. 
Optimization in Signal and Image Processing 
Edited by Patrick Siarry 
Copyright 0 
2009, ISTE Ltd 

330     Optimization in Signal and Image Processing 
 
Figure 13.1. Principle of a cochlear implant: 1) microphone; 2) processor; 3) external 
antenna (fixed and centered by a magnet); 4) internal antenna inserted under the skin and 
containing a magnet; 5) electrodes inserted into the cochlea; 6) auditory nerve 
The main problem is linked to the large number of parameters that need to be 
tuned, given that there are many causes for loss of hearing; for example, congenital 
deafness, traumatic deafness (due to an accident) or deafness due to illness. Other 
factors, such as the age of the patient, the number of years between the beginning of 
deafness and the implantation, the depth of insertion of the electrodes inside the 
cochlea, also add to this problem, making it very difficult to solve. The experience 
of the practitioners often leads to excellent results, such as patients who are able to 
follow a telephone conversation and enjoy listening to music. However, in some 
cases, no good results can be achieved for some unknown reason. 
In this chapter, an interactive evolutionary algorithm is used to optimize the 
parameters of the DSP for patients for whom implantation is a failure. 
This research was the doctoral thesis of Claire Bourgeois-République [BOU 04]. 
Further research has been carried out on her original research as part of the French 
Ministry of Health’s RNTS project known as HÉVÉA. This work was carried out at 
the ear, nose and throat department of Bobigny University Hospital in France.  
13.1.1. Finding good parameters for the processor 
The aim of adjusting the DSP’s parameters is to get the implant to fit the patient, 
and eventually enable him/her to distinguish between relevant information that is 
heard in speech in order to improve understanding. All of this should be possible 
without causing any discomfort to the patient, in other words it should be at an 
acceptable auditory level [LOI 00]. Originally, cochlear implants were only made up 
of one or two electrodes. In some cases this led to a vast and surprising improvement 
in the hearing of certain patients, despite the small number of electrodes. Thanks to 
the minimization process that exists nowadays, the designers of cochlear implants 
have been able to develop cochlear implants with 9, 15, 16, 20, 22 and even 24 

Using Interactive Evolutionary Algorithms to Help Fit Cochlear Implants     331 
electrodes [COC, MED, AB, MXM]. Results have been better than ever, but the 
number of parameters to be tuned has increased accordingly, along with the 
increased power of the embedded microprocessor.  
The principal parameters which are available include the following: 
 for each electrode: 
- a range of sound frequencies which will activate the electrode, 
- the minimum intensity threshold under which the patient will not be able to 
feel any sound sensation (referred to as T for threshold), 
- the maximum intensity threshold which the patient can endure for a long 
period of time (referred to as C for comfort level); 
 the number of electrodes which are activated simultaneously; 
 the gain in hearing for each sound frequency; 
 the sensitivity of the patient for each sound frequency; 
 the use of one or two microcomputers; 
 the type of stimulation chosen, etc. 
In an implant which has 20 electrodes, there are easily hundreds of different 
parameters that need to be tuned, and that can have an important role when it comes 
to enabling the patient to understand everyday conversation.  
13.1.2. Interacting with the patient 
One important aspect that needs to be taken into consideration is the subjective 
nature of the interactions that take place with the patients. Evaluating the different 
parameters of the DSP and the cochlear implant depends on the patient being able to 
recognize different feelings, which can sometimes be quite difficult to express. 
Furthermore, evaluating the success of a cochlear implant can be quite biased. This 
is known as the Pygmalion effect, which means that patients tend to place surgeons 
and experts, who have years of experience in adjusting the fittings of the cochlear 
implants and DSP, on a pedestal because it is these people who enabled the patient 
to hear. As a result, the patients imagine that any adjustments made to the 
parameters of the DSP will be beneficial. 
Then, there are often several sets of parameters which are available on the 
processor and which can be selected by a micro-switch that is located on the BTE 
worn behind the ear. It is common practice to refer to the current fitting as P1 and 
the previous fitting as P2 in case the most recently tested parameters are rejected by 

332     Optimization in Signal and Image Processing 
the patient (due to tiredness or lack of comfort, etc.). The possibility of moving from 
the old set of parameters to the new set also enables the patient to compare the two 
sets of parameters.  
Currently, adjusting the parameters of the DSP and the cochlear implant takes 
place in the following way: 
1) The fitting expert asks the patient if the last fitting was better or worse than 
the one carried out before that. The practitioner will then use the best recorded 
fitting as a basis from which he can start to work. 
2) The expert then loads the fitting that needs to be improved (P1 or P2) into 
proprietary software to tune the implant. 
3) The expert tries to find the problematic parameters, by carrying out a series of 
tests with the patient to check if the patient can recognize consonants, vowels and 
syllables. 
4) Thanks to his experience, the expert then changes certain parameters and 
carries out the same tests to see if the adjustment which has been made has led to 
any improvement. This is where the Pygmalion effect usually comes in; if the 
adjustment has not worked or has had a negative effect on the patient’s hearing, the 
patient will often find it difficult to say so, mainly because he does not want to 
disappoint the expert. Another factor should also be taken into consideration: 
patients may have difficulties in communicating, since, after all, it should not be 
forgotten that these patients are profoundly deaf. The age of the patients also varies. 
5) The previous point is repeated until the expert and the patient are both 
satisfied with the adjustments that have been made. 
6) The previous best fitting is loaded into the P2 memory and the new fitting to 
be tested is loaded into the P1 memory. 
It takes between 45 mins and 1 hour to find new satisfactory parameters. Then, 
the patient has to evaluate the new fittings over a period of several weeks in order to 
take neuro-plasticity into consideration. If the patient is not satisfied with the new 
fitting after this period of several weeks, another appointment will be made so that 
the fitting can be adjusted again. In some cases, evaluating the patient’s ability to 
understand spoken language is carried out by speech therapists in hospital. If this is 
the case, evaluation normally takes longer than 1 hour.  
 
Computer scientists who are specialized in optimization will see a problem in the 
protocol which has been described above: the optimization which is carried out is a 
type of local research. The expert who adjusts the fittings of the cochlear implants 
tries to improve on the best fitting that has been found to date. The expert will use 

Using Interactive Evolutionary Algorithms to Help Fit Cochlear Implants     333 
this best fitting as his basis and will only change some of the parameters in order to 
improve them. This means that the new fitting will be very similar to the previous 
one. If the problem is multimodal, then the expert runs the risk of becoming trapped 
by a local optimum and the patient’s hearing will never get better.  
13.2. Choosing an optimization algorithm 
The process that was described in the previous section is long and does not look 
like it can be optimized with an algorithm. 
However, an actual discussion with a patient led to the possibility of such an 
optimization taking place. The patient said that he was capable of immediately 
detecting if the new fitting was good or not. However, we still cannot count on 
thousands of evaluations to find the best possible fitting, so a deterministic 
algorithm could not be used. Among stochastic algorithms, we must find one that 
will not be much affected by local optima, but that is still able to converge quite 
rapidly in order to improve obtained results within a limited number of evaluations. 
 
 
Figure 13.2. The evolutionary loop 
Evolutionary algorithms (see Figure 13.2) have experienced a significant 
development and growth since their revival at the beginning of the 1990s: 
1) An initial population is created and then evaluated (by a user in the case of an 
interactive algorithm) with the aim of creating a population of parents.  

334     Optimization in Signal and Image Processing 
2) If we are not satisfied (non-verified stopping criterion), then n parents are 
selected (from the best parents) to create m children with the help of genetic 
operators. 
3) The new individuals who are created are then evaluated. 
4) Finally, the weakest individuals are eliminated thanks to the use of a 
replacement operator. This phase makes it possible to reduce the size of the 
population to its initial size. The loop is restarted at point two with a new generation 
of parents.  
The use of evolutionary algorithms has become increasingly widespread in many 
different domains and their increased use towards the end of the 1990s means that 
they are much better understood now. As a result, it has become possible to use 
them to solve different interactive problems [COL 04], as can be seen in the work 
published by Takagi [TAK 98, TAK 99, TAK 01] and by [HER 97, BIL 94 DUR 
02]. Rwo approaches can be used to reduce the number of evaluations: the Parisian 
approach [COL 00] (described in Chapter 2 and which dramatically reduces the 
number of evaluations) or Krishnakumar’s micro-GAs [KRI 89] that use populations 
of a few individuals only. In his tutorials on evolution strategies, Thomas Bäck 
shows that it is possible for evolution strategies to produce better results than human 
experts for a number of evaluations of the same order than the number of real 
parameters that need to be optimized [BAE 05]. 
These recent results have shown that the theories which suggested that 
evolutionary algorithms were to be used when all else failed, and required tens of 
thousands of evaluations in order to produce an average result, are no longer valid. 
A well designed evolutionary algorithm can now find interesting solutions with a 
reduced number of evaluations. Evolutionary algorithms seem to be more suited to 
solving multimodal problems than other stochastic methods such as simulated 
annealing, even if there are only a few individuals in the population. In the next 
sections of this chapter it is assumed that the reader possesses some knowledge of 
standard evolutionary algorithms (for an introduction to this topic it is recommended 
that the reader looks at [DEJ 05]). The descriptions that are given for this type of 
algorithm will also highlight any changes that have been made to them when they 
are to be used interactively.  
13.3. Adapting an evolutionary algorithm to the interactive fitting of cochlear 
implants 
In an interactive evolutionary algorithm it is the human user who evaluates each 
individual that is suggested by the algorithm. As far as the optimization of the 
parameters of a cochlear implant is concerned, it is the patient who evaluates the 

Using Interactive Evolutionary Algorithms to Help Fit Cochlear Implants     335 
fitting of the implant based on a particular series of words or syllables. It is therefore 
not possible to rely on a large number of evaluations, because in a domain like this 
fatigue, as well as the physiological and physical behavior of the patient, can also 
influence the results.  
According to Thomas Bäck’s results [BAE 05], an evolutionary algorithm should 
perform as well as, if not better, than a human expert on a number of evaluations 
equivalent in size to the number of real parameters that need to be optimized. 
Therefore, 100 evaluations would allow an EA to perform better than a human on a 
problem with 100 real parameters. If it is possible to reduce the evaluation time for 
each parameter from 45 minutes down to only 5 minutes, then it would take 8 hours 
to complete the evaluation of the 100 parameters, which is not unreasonable over 
two days. Knowing that the presented work only optimizes 30 parameters, we can 
hope to do better than a human expert during a two day fitting session. 
It is also necessary to take certain psychological aspects into consideration. For 
example, if the convergence speed of the algorithm is correctly tuned for the 100 
evaluations, (i.e. 8 hours to carry out the fitting), then the patient could be 
disheartened by this because over 8 hours progression would be very slow. The idea 
is then to break the experiment into several partial optimizations and have some 
“restarts” [JAN 02].  
Doing this also brings another advantage: all optimization algorithms (including 
Eas) have a strong tendency to converge prematurely on local optimae, meaning that 
optimizers usually implement many techniques to delay the convergence of the 
algorithm. If several restarts are used, convergence is, on the contrary, no longer a 
problem. In interactive evolution, we want an algorithm to converge very quickly, so 
that the patient sees an improvement over the very few evaluations of one run, and 
keeps up his spirit. After several restarts, we can use the best individuals of the 
previous runs (which will hopefully have converged on different solutions) as the 
initial population of afinal fitting session. 
So, rather than fighting against premature convergence, this work will encourage 
it (by using a micro-GA, for instance). 
13.3.1.Population size and the number of children per generation 
There are two possibilities which arise on a fixed number of evaluations: either 
we choose to create many children per generation over a few generations, or we 
create a few children per generation over many generations. 

336     Optimization in Signal and Image Processing 
Of these two possibilities, the latter will most favor convergence. This means 
that a steady-state type of replacement will be used (or a (ȝ + Ȝ) replacement 
strategy, with a heavily reduced Ȝ (number of children) [BAE 95]). Then, in order to 
avoid using too many evaluations in the initial population, the population size can be 
reduced as in micro-GAs [KRI 89].  
Now, as far as the optimization of cochlear implants is concerned, there are too 
many parameters to hope to optimize them all. Fitting experts have recommended 
starting with the optimization of the minimal T and maximum C thresholds for each 
electrode, meaning two variables per electrode. For MXM cochlear implants which 
have 15 electrodes, this means that 30 real variables need to be optimized over 100 
evaluations, giving good chances of performing better than a human expert.  
13.3.2. Initialization 
There is one major constraint that needs to be respected: the maximum value for 
the stimulation of each electrode (C value) must never be exceeded, so as not to 
damage the patient’s auditory neurons. For each new patient, the first appointment 
with the fitting expert consists of a “psychophysical” test in order to determine this 
maximum level for each electrode. A minimum intensity level (T value) is also 
determined because if an electrode is stimulated under this intensity level it means 
that a patient would be unable to hear anything. 
Then, the initialization of each individual is carried out by taking two random 
values within the predetermined [T, C] interval for each electrode. 
13.3.3. Parent selection 
Parent selection is different from parent replacement (see section 13.3.5) in that a 
parent can be selected several times. 
A 0.9 stochastic tournament [BLI 95] is used, that chooses 2 parents at random, 
and returns the better of the two with a 90% probability. This selection is preferred 
to a proportional selection that would rely on the fitness landscape of the problem 
(which is unknown here).  
13.3.4. Crossover 
The genome is made up of real values, which means that it could have been 
possible to use some type of barycentric crossover. However, since the aim is to 

Using Interactive Evolutionary Algorithms to Help Fit Cochlear Implants     337 
make the intervals evolve, adopting this style of crossover would actually have 
progressively reduced the width of the intervals. 
Therefore, the method used for crossovers comes from binary genetic 
algorithms. Genes are exchanged between parents after a particular crossover point 
(the locus, chosen at random) has been reached. A single-point crossover is used 
because according to experts, we can expect a high level of epistasis between the 
different electrodes. Using multi-point crossover points would therefore have been 
disruptive and would have turned the crossover into some kind of macro-mutation.  
Determining the locus is carried out electrode by electrode in the hope of not 
breaking any good combinations of genes that exist, meaning that T and C values are 
not separated. Since the evolutionary algorithm is a (ȝ + Ȝ) type of algorithm, with a 
number of children that is smaller than the population size (see Figure 13.2., 
crossover is therefore used for the creation of each child (100% probability). 
13.3.5. Mutation 
Mutation is also used with a 100% probability level on each child that has been 
produced by the crossover process. In the evolutionary algorithm, each gene has a 
10% probability of being mutated. Since there are 30 genes, each child will undergo 
three mutations on average. These figures may seem high but due to the high level 
of epistasis that exists, modifying one threshold on a genome would have a limited 
effect on the general evaluation process. This high rate of mutation lets the 
algorithm keep some kind of exploratory character, despite the low number of 
evaluations that take place.  
13.3.6. Replacement 
A steady-state like replacement is used, in order to promote fast convergence. 
However, where a strict steady-state would create only one child that would replace 
the worst of the parents, several children will be created, turning this replacement 
operator into a kind of (ȝ + Ȝ) replacement, even though the number of children is 
very small. 
13.4. Evaluation 
Until now, evaluating a patient’s ability to understand speech has been the test 
for a new fitting. The first method involved sending the patient back home with the 
new fitting stored in the P1 memory and the previous fittings stored in the P2 
memory. This meant that the patient was able to compare the two different fittings in 

338     Optimization in Signal and Image Processing 
his own environment. The other method involved a speech therapist who carried out 
an evaluation on the patient using intensive tests taking over one hour to complete.  
However, it was impossible to apply an interactive evolutionary algorithm with 
any of these two methods since the evaluation time was much too long. A new 
evaluation protocol was developed using calibrated sentences taken from Professor 
Lafon’s cochlear lists [LAF 64] that contain syllables that are both representative of 
the French language and supposed to be discriminant cochlear-wise. Ten sentences 
(a total of 78 words) were chosen to evaluate a patient’s understanding of the French 
spoken language. Here are the sentences (with their translation, even though their 
meaning is clearly secondary): 
 
Se réveiller chaque matin peut être un plaisir. 
 
(Waking up each day can be a pleasure) 
 
La cravate garde encore du prestige pour certains. 
 
(The tie still retains prestige for some people) 
 
Il ne restait que de l’eau à boire. 
 
(There was only water left to drink) 
 
Il s’est fait aider pour porter ses bagages. 
 
(He got someone to help him carry his luggage) 
 
Les chiens gardent les villas contre les voleurs. 
 
(Dogs protect villas against thieves) 
 
Il existe des perles fines et des perles de culture. 
 
(There exist both natural and cultured pearls) 
 
L’enfant appelait sa mère parce qu’il avait peur. 
 
(The child called his mother because he was frightened) 
 
On aspire et expire par la bouche. 
 
(We breathe in and out through our mouth) 
 
L’intelligence permet à l’homme de comprendre. 
 
(Intelligence enables man to understand) 
 
Les parfums doivent avoir une odeur agréable. 
 
(Perfumes should have a nice smell) 
Maximizing the understanding of a patient is, of course, one of the main 
objectives of the evaluation process but it must also be comfortable enough for 
patients to use in their everyday life.  
The overall evaluation is therefore the weighted mean of the comfort level of the 
cochlear implant (marked over 10) and of the patient’s understanding. For the tests 
which are described in the next section, the comfort mark is multiplied by 2.2 which 
means the overall comfort mark is out of 22. The total number of words that were 
recognized (out of 78) is added to this mark in order to get a total overall mark of 

Using Interactive Evolutionary Algorithms to Help Fit Cochlear Implants     339 
100. This total mark out of 100 will be used as the patient’s evaluation for the 
evolutionary algorithm. Understanding has the predominant mark, while comfort is 
not totally ignored. 
The evaluation procedure typically lasts about four minutes. Four minutes is 
clearly not long enough to obtain a precise evaluation of a patient’s ability to 
hear/understand speech, but it enables us to carry out 100 tests in 6h40', or 1h20' per 
run, if the 100 evaluations are divided into 5 runs. The aim of this reduced 
evaluation protocol is different from the complete evaluation protocol which is 
carried out by experts. Since experts cannot test as many configurations as 
evolutionary algorithms (patients may only have as many as ten appointments in one 
year) they need to work on as precise as possible evaluation of their patient’s 
hearing. 
Evolutionary algorithms work in a different way. They are stochastic processes 
that test many different fittings. They do not need very precise evaluations of the 
results, but need to be roughly guided towards a good solution. In fact, getting only a 
rough estimation of the patient’s hearing may improve the efficiency of the 
algorithm, as it may help to skip over local optima. 
13.5. Experiments 
A certain number of experiments were carried out, which led to surprising results 
in many respects. The first set of experiments described in the next part of this 
section was carried out by Claire Bourgeois-République as part of her doctoral thesis 
at the University of Bourgogne and was published in several articles [BOU 04, BOU 
05a, BOU 05b]. Other, more recent, tests were carried out as part of the RNTS 
HÉVÉA project which was supported by the French Ministry of Health. 
13.5.1. The first experiment with patient A 
The first experiment using the algorithm mentioned in the previous section was 
carried out with a patient whose hearing became progressively worse until the 
patient became totally deaf in 1983. In 1991 the patient was first implanted with a 
one-electrode implant in the right ear. This implant was later replaced with a  
15-electrode MXM implant, which was activated by an external processor the size 
of a walkman that clipped to the belt. The MXM implant with 15 electrodes led to 
average results. In 2003, the same patient then bought a behind the ear (BTE) 
miniaturized processor. As its name suggests, this miniaturized processor is worn 
behind the ear. However, the results were not as good as the results of the walkman-
style processor, so the patient decided to stop using the BTE processor. 

340     Optimization in Signal and Image Processing 
13.5.1.1. Psychophysical test 
The psychophysical test (which is used to determine the CT and C thresholds for 
each electrode) was performed by an expert practitioner (see Table 13.1). Electrodes 
10, 11 and 12 were not functional (the patient was unable to hear anything 
regardless of the power of the stimulation) and therefore not activated. 
 
Electrode 
1 
2 
3 
4 
5 
6 
7 
8 
9 
10 
11 
12 
13 
14 
15 
T 
6 
6.5 
6.5 
9 
9 
9 
8 
8 
8 
0 
0 
0 
7 
6 
5 
C 
9.5 
13 
13 
18 
20 
21.5 21.5
18 
16.5
0 
0 
0 
12 
10 
9 
  
Table 13.1. The set of T and C parameters 
13.5.1.2. Evaluation of the expert’s fitting with the BTE and the hearing aid 
Before the experiments were started, the best fittings previously obtained by the 
expert after 10 years on the walkman processor and BTE processor were tested 
against the 4-minute evaluation function that will be used for the evolutionary 
algorithm. 
As a reference point, the weighted mark for the walkman processor is 53/100, 
whereas the weighted mark for the BTE is 48.5/100. These marks confirm the 
patient’s observation: the BTE performs worse than the walkman-size processor. 
All the experiments below are done with the BTE processor. 
13.5.1.3. Experiment 1 and results 
The aim of this first set of experiments was not to actually obtain good results, 
but to tune the parameters of the algorithm (determining the optimal size of the 
population, the number of children per generation, the selection pressure, etc.. 
Successive tests were then carried out on the algorithm with the aim of varying these 
parameters.  
The first test uses a population of three individuals, with three children produced 
per generation. This test also uses a stochastic tournament selection with a 
probability of 0.8. The mutation rate of each parameter is fixed at 0.1 and the 
crossover rate of each parameter is fixed at 1.  
During this first experiment, 12 different fittings were evaluated by the patient. 
Evaluating one fitting (preparation and evaluation) lasts a little less than four 
minutes. The results which were obtained for this experiment can be seen in Table 
13.2. 

Using Interactive Evolutionary Algorithms to Help Fit Cochlear Implants     341 
 
Fitting 
1 
2 
3 
4 
5 
6 
7 
8 
9 
10 
11 
12 
Mark 
44.2 
21.2 
9.2 
31.4 
55.6 
46.4 
74.8 
74.8 
58.4 
81 
81 
79.8 
 
Table 13.2. Results of experiment 1 
The first line refers to the number of particular fittings to be evaluated and the 
second line refers to the fitting’s weighted mark. There are three fittings per 
generation, so fittings 1 to 3 refer to the first generation, fittings 4 to 6 to the second 
generation, and so on.  
The first three evaluations correspond to the individuals which were part of the 
initial population and which were created randomly. The process of artificial 
evolution begins at fitting 4. Fitting 5 has a mark that is higher than the expert’s best 
fitting. Fittings 7 and 8 have almost identical parameters and have identical marks. 
The algorithm seems to converge from the fitting 10 onwards with a very good mark 
of 81. The patient is happy and appreciates the speed of the evaluation procedure. 
13.5.1.4. Experiment 2 and results 
For this second experiment, the number of individuals of the population and the 
number of children per generation are doubled with the aim of delaying the 
premature convergence that was observed in experiment 1. The initial population is 
therefore increased to six individuals and four children are produced per generation.  
Fitting 
1 
2 
3 
4 
5 
6 
7 
8 
9 
10 
Mark 
24 
17 
30 
19 
53.2 
37.4 
22.6 
24 
33.4 
32 
 
Fitting 
11 
12 
13 
14 
15 
16 
17 
- 
- 
- 
Mark 
9 
27.4 
34 
34.5 
12 
27 
32 
- 
- 
- 
 
Table 13.3. Results of experiment 2 
The marks of the first six individuals are generally low. However, what is rather 
surprising is that one of the six random individuals (i.e. one of the first six fittings) 
has a mark which is higher than the mark obtained by the expert (53 vs 48.5). As can 
be seen in Table 13.3, the genetic operators are unable to find any suitable 
individuals. This is why the algorithm is stopped voluntarily after fitting 17, for the 
well-being of the patient. Results are not as good and the patient becomes 
increasingly tired. 

342     Optimization in Signal and Image Processing 
13.5.1.5. Experiment 3 and results 
During this experiment the population is reduced again to three individuals and 
only two children are produced per generation. In order to prevent any premature 
convergence (as was the case during experiment 1), mutation rate is increased to 0.6. 
A roulette-wheel type of selection is then tested. This type of selection is tested as it 
may have a stronger selection pressure on a problem where fitness varies a lot 
between individuals.  
Fitting 
1 
2 
3 
4 
5 
6 
7 
8 
9 
10 
11 
Mark 
54 
33 
26.5 
48 
52 
51.6 
54.6 
62.8 
59.6 
65.6 
60.1 
 
Fitting 
12 
13 
14 
15 
16 
17 
18 
19 
20 
21 
22 
Mark 
60 
72 
69.4 
53.4 
73 
67 
50.1 
62 
68.3 
67.3 
65 
 
Table 13.4. Results of experiment 3 
From the first three individuals that were created randomly (fittings 1 to 3), the 
first shows once again a mark that is slightly higher than the mark obtained by the 
expert. Table 13.4 shows that the marks of the individuals steadily increase. From 
the fitting 5 onwards, all of the marks are higher than 50. The best individual is the 
fitting 16 which has a mark of 73.  
13.5.1.6. Experiment 4 and results  
For the fourth experiment, the size of the population is four individuals and four 
children are produced per generation. The mutation rate is 0.1 and the selection 
mode used for choosing the parents is once again tournament selection. 
Fitting 
1 
2 
3 
4 
5 
6 
7 
8 
9 
10 
11 
12 
Mark 
59.4 
62.2 
57.3 
58.9 
57 
62.3 
65 
73 
75.3 
65.2 
83.1 
68 
 
Fitting 
13 
14 
15 
 
 
 
 
 
 
 
 
 
Mark 
75.4 
91 
91.5 
 
 
 
 
 
 
 
 
 
 
Table 13.5. Results of experiment 4 
Table 13.5 shows that the individuals that were randomly chosen from the 
population (fittings 1 to 4) achieve an average mark of 59.5 (this mark is much 
higher than the mark of 48.5 that was achieved for the BTE by the expert, even after 
many years). All the other values are above 56.5. The best marks from this 
experiment and from all of the experiments are 91 and 91.5, and were achieved by 
the 14th and 15th individuals respectively (in other words more than 90% of the 

Using Interactive Evolutionary Algorithms to Help Fit Cochlear Implants     343 
words from Professor Lafon’s list were understood). The patient is extremely happy 
and is astonished by such good results.  
13.5.1.7 Experiment 5 and its results 
The size of the population is fixed at five individuals and two children are 
produced per generation. The selection mode which is used to choose the parents is, 
once again, a tournament selection and the mutation rate is 0.1.  
Table 13.6 shows that two out of the five individuals which make up the initial 
population (fittings 1 to 5) achieve marks above 70. However, because of the 
evolution of the algorithm, it is impossible to find one particular individual which is 
better than the rest. The algorithm is stopped during the evaluation of the 23rd fitting.  
Fitting 
1 
2 
3 
4 
5 
6 
7 
8 
9 
10 
11 
 
Mark 
18.6 
53 
70.1 
9 
71.9 
58.4 
60.3 
58 
51 
57.3 
48.2 
 
 
Fitting 
12 
13 
14 
15 
16 
17 
18 
19 
20 
21 
22 
23 
Mark 
36 
36.2 
50 
29 
33.5 
50.3 
40.2 
44.5 
48.3 
49.3 
45.2 
50 
 
Table 13.6. Results of experiment 5 
13.5.2. Analyzing the results 
Figure 13.3 shows how the value of the best individual evolves during the 
evaluation process, which takes place in each experiment. As far as evolution is 
concerned, experiments 1, 3 and 4 led to the best results (there was an increase in the 
marks obtained by each individual). The good number of individuals to have in a 
population seems to be 3 or 4. The good number of children to have per population 
is quite low (2 or 3). These values validate the hypotheses that were made earlier in 
this section.  
 
Figure 13.3. Evolution of the best individual during the evaluation processes  
which were carried out for each experiment 

344     Optimization in Signal and Image Processing 
Medically speaking, it seems rather strange that the random fittings (the initial 
population) would yield better results than the results obtained by the expert 
practitioner. Some explanation is given below on this particular point. 
The T and C values of the best and worst individuals have been plotted for each 
electrode in Figure 13.4. The dark lines refer to the minimum and maximum values 
given by the psychophysical test (see section 13.5.1.1). The dotted curve refers to 
the T and C values of the worst fitting, and the thin lines refer to the best fitting 
(with a mark of 91.5). 
 
Figure 13.4. T and C values of the best and worst fittings 
The medical team, and in particular the experts who specialize in cochlear 
implants, were surprised that this particular fitting was the best because of the small 
[T,C] intervals observed for electrodes 3, 4, 5, 6, 12, 14 and 15 (0; 0.5 and 1). 
Usually, the expert generally tries to feed the auditory nerve with maximum 
information, and therefore tries to maximize the [T,C] interval for each electrode. 
This means that the expert usually sets the T and C values to the same values as 
those that are determined during the psychophysical test. The expert might 
sometimes reduce these values if he has the feeling that too much information may 
saturate the auditory nerve, but this happens rarely. In this case, the interactive 
evolutionary algorithm minimized the values of C-T for practically all the electrodes 
except 1, 7, (8) and 9, which does not make much sense. Nevertheless, doing this 
enabled us to obtain better results than if all the C-T values had been maximized (the 
expert’s fittings). 
Several issues therefore arise: 
 is minimizing the [T,C] interval equivalent to de-selecting an electrode? 
 would there be a problem of interference between the electrodes (diaphony)? 

Using Interactive Evolutionary Algorithms to Help Fit Cochlear Implants     345 
 would the problem be combinatorial (i.e. would certain combinations of 
electrode work better than others)? 
13.5.3. Second set of experiments: verifying the hypotheses 
A second set of experiments was then carried out, with fittings that were not 
created by the interactive evolutionary algorithm, but were created in order to 
validate certain hypotheses. The tests were carried out with the same patient and 
with the same evaluation protocol.  
It should be pointed out that a period of one month elapsed between the two 
tests. During this one month break, the patient went back to using his old walkman-
style processor, meaning that he was therefore unable to physiologically adapt to 
any new fittings (neuroplasticity). This means that the evaluations of the two 
experiments can therefore be compared with one another. In the next part of this 
section the first set of experiments will be referred to as C1 and the second set of 
experiments will be referred to as C2. 
13.5.3.1. Experiment 7: is the minimization of C-T equivalent to de-selecting an 
electrode? 
For this experiment all of the electrodes apart from electrodes 1, 7 and 9 are 
reduced to intensities which are much lower than the liminary intensities (T). This 
means that the patient will not hear anything from these electrodes. 
However, the differences between T and C have been maximized for electrodes 
1, 7 and 9 (see Figure 13.5). 
 
Figure 13.5. Experiment 7 
 

346     Optimization in Signal and Image Processing 
The resulting weighted mark of this fitting is 82, with a level of understanding of 
90%. In other words, the patient was able to understand 90% of the words from 
Professor Lafon’s sentences. This fact alone seems to confirm three points: 
1) Minimizing the difference of C-T is equivalent to de-selecting electrodes, 
since similar results were obtained as for the best individual. 
2) This fitting (which can be compared to the best fitting that was evaluated a 
month earlier) still produces a good result. 
3) All of the electrodes, apart from electrodes 1, 7 and 9 (which were 
maximized) have been minimized in order to produce a good result. The problem 
thus seems to be quite binary (even if the values of each interval were refined, it 
would only lead to a slight improvement as far as the quality of the result is 
concerned). 
13.5.3.2. Experiment 8: a study of electrode 8 and its influence on the fitting 
In the C1 set of experiments, the evolutionary algorithm set a medium interval 
on electrode 8. In this test, electrode 8 was maximized along with electrodes 1, 7 and 
9, using the values from the psychophysical test. 
The resulting weighted mark of this fitting is 81. The patient finds that the fitting 
is slightly less comfortable than the previous fitting, although the level of 
understanding is exactly the same. Electrode 8 seems to play a rather neutral role as 
far as understanding spoken language is concerned. 
13.5.3.3. Experiment 9: is there any diaphony between the electrodes? 
In order to investigate this hypothesis, the even-numbered electrodes are de-
activated (both T and C are set to a value below the T liminary intensity) and the 
odd-numbered electrodes are maximized (by using the values from the 
psychophysical test). The aim of this action is to increase the spacing between active 
electrodes (see Figure 13.6). 
 
Figure 13.6. Experiment 9 
 

Using Interactive Evolutionary Algorithms to Help Fit Cochlear Implants     347 
The resulted weighted mark of this fitting is 78.8. The patient stated that this 
fitting was less comfortable than the others. This result is obviously not as good as 
the results that were obtained for experiments 7 and 8. Adding other electrodes to 
electrodes 1, 7 and 9 does not seem to improve the fitting. The result, however, is 
still better than the expert’s result of 48.5 that was obtained for the BTE. 
13.5.3.4. Experiment 10: a wider spacing of the electrodes 
In order to further decrease the risk of interference, in this experiment we 
decided to activate one in every three electrodes instead of every two electrodes. 
Electrodes 7 and 9 remained activated and the maximized electrodes are now 
electrodes 1, 4, 7, 9, and 15 (electrodes 10 to 12 are non-functional); see Figure 
13.7. 
The result is astonishing. The fitting is not very comfortable and the weighted 
mark for this fitting is only 58.5. First of all, these facts refute the idea that 
interference between the different electrodes could exist, but above all, if maximized 
electrodes are compared with those of experiment 7 (where only electrodes 1, 7 and 
9 were activated), the difference being the addition of electrodes 4 and 15. 
This information suggests that this binary problem is combinatorial. In other 
words, there are certain combinations of electrodes that work better than others. 
Another conclusion which can be drawn from these facts is that the activation of 
certain electrodes has a negative effect on a patient’s understanding of spoken 
language (adding electrodes 4 and 15 degraded speech understanding). 
 
Figure 13.7. Experiment 10 

348     Optimization in Signal and Image Processing 
13.5.3.5. Experiment 11: evaluation of the best individual from C1 
Experiment 11 investigates the reliability and accuracy of the evaluation 
protocol.  
The parameters of the best fitting from the C1 set of experiments (with a mark of 
91.5), which were carried out a month earlier, are tested once again. 
The result of the vocal test is once again very good (94% of the words are 
understood), and even slightly better than one month earlier, but the fitting is 
evaluated as slightly less comfortable, which accounts for a weighted mark of only 
86.2. This mark is slightly lower than the previous weighted mark of 91.5, but it is 
still the best fitting that was found during the C2 set of experiments. 
13.5.3.6. Experiment 12: an evaluation of the expert’s fitting 
For this experiment the original expert’s best fitting (in which more or less all of 
the electrodes were maximized, and which obtained a mark of 48.5 during the C1 set 
of experiments) is uploaded into the BTE. 
The result of the vocal test is poor (only 33% of the words were understood), and 
the comfort mark, which was given by the patient, was only 4/10. This means that 
the weighted mark this time was only 41.8, a mark which is much worse than that 
obtained during the C1 set of experiments. 
In the period of one month, the best fitting generated by the interactive 
evolutionary algorithm went from a mark of 91.5 to 86.2, and the expert’s fittings 
went from a mark of 48.5 to 41.8. The absolute values have decreased between C1 
and C2, but the difference remains about the same (43 against 44.4). Repeating these 
two fittings showed that the quick evaluation procedure is pretty reliable, because 
results are reproducible after one month, during which the patient used his old 
processor (and therefore could not adapt to other settings).  
13.5.3.7. Other experiments 
In order to check whether the evolutionary algorithm actually added some value, 
other tests were performed with randomly chosen values for T and C. Results were 
average to poor (but often higher than 41.8, the expert’s best fitting) and comfort 
was often criticized by the patients. The fact that many random fittings obtained 
better results than the expert’s fitting may be explained by the fact that by 
maximizing the [T,C] interval of all electrodes, the expert also maximizes the 
influence of detrimental electrodes such as electrode 4 for the tested patient. By 
doing so, if there is only one detrimental electrode for a patient, the expert is sure to 
obtain a relatively bad speech understanding result, while a random fitting that 
would skip detrimental electrodes would very likely perform better. 

Using Interactive Evolutionary Algorithms to Help Fit Cochlear Implants     349 
13.5.4. Third set of experiments with other patients 
One thing stands out from the previous results: in several cases the random 
values for the T and C parameters gave a result which was equal to or better than the 
expert’s best fitting (who understandably was trying to maximize the [T,C] interval 
for all of the electrodes). 
A new series of tests was then started with four other patients in order to confirm 
or refute this observation. Unlike the previous experiments (where the evaluation 
process was a very short process with only ten sentences taken from the Lafon 
corpus), auditory speech evaluation (ASE) tests and vowel consonant vowel (VCV) 
recognition tests were used. The test is longer, but it makes it possible to determine a 
patient’s hearing ability in a much more detailed manner. 
It would take too long to provide a complete summary of the tests in this chapter. 
The results of the tests are shown as percentages of recognized VCVs in Table 3.7. 
Patient 
Mark for expert’s 
fitting 
Best random fitting 
Number of tests 
A 
31% 
33% 
3 
B 
43% 
50% 
3 
C 
16% 
25% 
3 
C 
20% 
27% 
9 
A 
33% 
31% 
3 
A 
33% 
27% 
3 
D 
20.5/22 
21/22 
3 
 
Table 13.7. Results of tests shown as percentages of recognized VCVs 
In almost all cases, if three random fittings are tested, it is nearly always possible 
to find a result that is equal to or better than the expert’s fitting. 
In the final case (patient D), another marking system was used. This marking 
system was based on the ASE test. For this patient the best fitting that was obtained 
by the expert can be seen in Figure 13.8. The mark corresponds to the 
psychophysical test in which the intervals for each electrode are maximized. 
In this experiment the evolutionary algorithm was briefly tested (only six 
evaluations due to the time that was required to complete the evaluations) and the 
best individual obtained an ASE mark of 22/22 (in comparison to a mark of 20.5/22 
for the fitting which was set by the expert). Once again there were some astonishing 
values that were recorded for the electrodes (see Figure 13.9). 

350     Optimization in Signal and Image Processing 
Given the very low number of evaluations, it is not possible to consider the 
algorithm as having played an important role in achieving such a result. However, 
analyzing the results is quite interesting because the intervals for all of the electrodes 
are quite small. Some of the electrodes were deselected and these included 
electrodes 5, 8, 11, 12 and 13. This goes against the recommendations of the experts 
and the developers of cochlear implants, who have been working in this field since 
the development of cochlear implants first took place over 40 years ago. However, 
once such electrodes have been removed, this supports the observation made by the 
first patient who had a better understanding of spoken language when only 3 out of 
the 12 electrodes were activated.  
 
Figure 13.8. The best fitting obtained by the expert for patient D: each rectangle represents 
the [T, C] interval for each electrode 
 
Figure 13.9. The best individual for patient D: each rectangle represents  
the [T, C] interval for each electrode 
13.6. Medical issues which were raised during the experiments 
It should be pointed out that our study does not focus on a wide range of 
different cases and because of this the results cannot be used on a more general 
level. However, throughout our study certain issues have been raised and we think it 

Using Interactive Evolutionary Algorithms to Help Fit Cochlear Implants     351 
would be interesting to try and find a solution to such issues. As far as the first set of 
experiments is concerned, they were all carried out on only one patient.  
1) In studying the graphs which show the progression of the different 
evolutionary tests, and which also show the results produced from the second set of 
tests, it is possible to evaluate a patient’s hearing (with the help of an optimization 
algorithm) in less than four minutes. This fact alone goes against the 
recommendations made by speech therapists. Speech therapists believe that it is 
impossible to evaluate a patient’s hearing in less than 20 minutes. 
The speech therapists are, of course, correct. They are correct in the sense that a 
four minute evaluation will not lead to the same quality of conclusions as a one-hour 
evaluation. However, in pragmatic terms, an evaluation procedure must be used in 
relation to the quality of the optimization algorithm that is also used. An 
evolutionary algorithm does not benefit from any of the experience or intelligence 
that an expert has. The quality of a very refined evaluation process (and therefore 
long evaluation) would be wasted if such a rough algorithm were to be used.  
Therefore, for such algorithms, it is better to have more evaluations than more 
precise evaluations. A more refined and longer evaluation process would benefit a 
human expert who works in this field, since the expert is able to provide a better 
interpretation of the results from the tests and therefore provide a better evaluation 
of a patient’s hearing.  
2) Patient D seems to be able to evaluate a new fitting within seconds. However, 
experts say that a patient can only give a true evaluation of any new fitting at least 
one or two weeks after the new fitting has been installed (this is probably due to 
neuroplasticity).  
Once again, the experts are more than likely correct if the aim is to carry out a 
more detailed evaluation of the patient’s hearing. As far as a rough evaluation is 
concerned (which is fine for an evolutionary algorithm) it is not problematic to 
evaluate the fitting only seconds after it was uploaded in the processor (but one 
example may not be enough to generalize this conclusion). 
3) With patient D it was possible to carry out 89 tests with different parameters, 
in a period of one and a half days, with results that were good enough to guide an 
interactive evolutionary algorithm where speech therapists and other experts 
working in this field believe that after a period of two hours any evaluations that are 
carried out are no longer relevant, due to patient fatigue. The same comments as 
above may apply here. 

352     Optimization in Signal and Image Processing 
4) With two patients, it has been possible to obtain a similar or higher level of 
understanding of spoken language when some of the electrodes were either 
minimized or deselected where experts, as well as cochlear implant manufacturers, 
believe that it would make more sense to maximize the number of activated 
electrodes and to maximize their range of stimulation. 
This point still remains a mystery and requires further investigation in order to 
provide a more accurate explanation. 
On a less general note, it seems that for patient A the problem is combinatorial, 
i.e. certain combinations of electrodes work better than others. This can be seen in 
the example where two electrodes (electrodes 4 and 15) were added to a set of 
electrodes (1, 7 and 9). With this particular combination of electrodes, the patient’s 
understanding of the spoken language actually got worse. If this hypothesis were 
proved, it would lead to a big problem, because: 
a) the problem would face a combinatorial explosion. With nine electrodes, the 
number of possible combinations is 29 = 512. With 15 electrodes, the number of 
possible combinations is 215 = 32,768, and with 22 electrodes, the number of 
possible combinations is a massive 222 = 4,194,304; 
b) since the expert has no way to determine which electrode will have a 
positive or negative effect on speech understanding this means that, in theory, it 
would be necessary to test all electrode combinations in order to find the best 
combination. This, however, is impossible in practice. 
As far as the third set of tests is concerned, it seems that one in every three 
random parameters taken from the T and C thresholds leads to a result that is equal 
to, if not better than the result which is obtained by the expert (who maximizes the 
[T,C] intervals). This point alone suggests that there are numerous fittings that are 
satisfactory for the patient.  
13.7. Algorithmic conclusions for patient A  
To start with, the contribution of the implemented evolutionary algorithm seems 
to be real, looking at Figure 13.3, even though it might seem surprising to achieve 
such good results in such a short period of time. However, if the problem is 
combinatorial (where certain combinations of electrodes enable a patient to 
understand spoken language better), then the chances of finding a good combination 
whilst using an interactive evolutionary algorithm for 100 evaluations are far from 
being zero: 

Using Interactive Evolutionary Algorithms to Help Fit Cochlear Implants     353 
1) in the case of patient A, three electrodes out of 15 were non-functional. This 
means that out of the remaining 12 activated electrodes, there were a total of 212 = 
4.096 different combinations of electrodes; 
2) if we assume that there are over 100 random evaluations, then the chances of 
finding the correct combination is one in 40; 
3) as is suggested in the random tests carried out during the third set of 
experiments, it is possible for different combinations of electrodes to carry out a 
good evaluation. If there are ten satisfactory combinations, then 100 random 
evaluations would have one chance in 4 of finding one of these ten good 
combinations; 
4) it should not be forgotten that having one chance in 4 of finding a good 
combination (using 100 evaluations) is obtained solely by random research.  
If it is assumed that an evolutionary algorithm can perform better than a random 
search, the probability of finding a good fitting suddenly comes closer to 1. 
However, all of this is only possible if the algorithm is capable of carrying out many 
evaluations in a short period of time.  
Finally, there is one final element that changes the probability of finding a good 
fitting from “very probable” to “extremely probable”: the interactive evaluation 
given by the patient may be of very high quality, and this is very important because 
evaluation is what guides the evolutionary algorithm. During the 15th French 
evolutionary workshop (JET) organized by the French Society for Artificial 
Evolution, a competition was organized with the aim of solving the famous 
MasterMind board game. This was a very difficult task to complete because the 
problem was a 13 x 13 size problem (13 positions, 13 colors), meaning that it was 
necessary to find a good combination from among 3.1014, i.e. approximately 300 
thousand billion. On 1,000 games, the best evolutionary algorithm was able to find 
the correct combination in an average of only 19.5 evaluations.  
This feat was only possible because the information given by the MasterMind 
game’s evaluation function is very rich (number of correct colored pegs in the 
correct place, and number of correct colored pegs in incorrect places), and that the 
evolutionary algorithm found a way to exploit it correctly. 
As far as cochlear implants are concerned, if the interactive evaluation that is 
given by the patient is of high quality, then this could significantly simplify the 
problem. All works on interactive evolutionary algorithms seem to support this idea 
[TAK 05].  
Furthermore, micro-population evolutionary algorithms have also proved to be 
efficient [KRI 89], and the number of variables to optimize was lower than the 

354     Optimization in Signal and Image Processing 
number of available evaluations. This set of hypotheses seems to reinforce the idea 
that the good results were not obtained through chance.  
The only way it is possible to confirm this would be to carry out a significant 
number of complete tests with new patients.  
13.8. Conclusion 
Fitting a cochlear implant is a problem for which it is very difficult, if not 
impossible to find a suitable solution deterministically within a limited time period 
for at least two reasons: 
 the objective function cannot be modeled and can vary a lot due to the fact that 
it is dependent on the patient and linked to the subjective evaluation of his 
sensations; 
 the search space is large enough to eliminate any guarantee of optimality.  
The work and the findings that are presented in this chapter describe a way to 
help the expert practitioner by using a micro-population interactive evolutionary 
algorithm. The first tests are very promising and the results raised several issues 
related to the current evaluation protocol that is used by experts in the field. The 
results also seem to question the seemingly evident idea that more electrodes would 
allow the patient to understand better, and that maximizing the [T,C] interval of all 
electrodes may not be a good idea, if for a patient some electrodes are detrimental to 
speech understanding. 
However, it goes without saying that this work is only the beginning. It is now 
necessary to build on this research by carrying out numerous clinical experiments. 
13.9. Bibliography 
[AB] Advanced Bionics: http://www.cochlearimplant.com 
[BAE 95] BAECK T., Evolutionary Algorithms in Theory and Practice, New-York, Oxford 
University Press, 1995. 
[BAE 05] BAECK T., “Tutorial on evolution strategies”, Genetic and Evolutionary 
Computation Conference Gecco’05, 2005. 
[BIL 94] BILES J., “GenJam: a genetic algorithm for generating jazz solos”, Proceedings of 
the International Computer Music Conference, San Francisco, 1994. 

Using Interactive Evolutionary Algorithms to Help Fit Cochlear Implants     355 
[BLI 95] BLICKLE T., THIELE L., “A mathematical analysis of tournament selection”, 
ESHELMAN L. J., (Ed.), Proceedings of the 6th International Conference on Genetic 
Algorithms, Morgan Kauffmann, p.9-16, 1995. 
[BOU 04] BOURGEOIS-RÉPUBLIQUE C., Plateforme de réglage automatique et adaptatif 
d’implant cochléaire par algorithme évolutionnaire interactif, PhD Thesis, University of 
Bourgogne, France, 2004. 
[BOU 05a] BOURGEOIS-RÉPUBLIQUE C., FRACHET B., COLLET P., “Using an 
interactive evolutionary algorithm to help with the fitting of a cochlear implant”, 
MEDGEC (GECCO), 2005. 
[BOU 05b] BOURGEOIS-RÉPUBLIQUE C., VALIGIANI G., COLLET P., “An interactive 
evolutionary algorithm for cochlear implant fitting: first results”, SAC, p. 231-235, 2005. 
[COC] Cochlear: http://www.cochlear.com 
[COL 00] COLLET P., LUTTON E., RAYNAL F., SCHOENAUER M., “Polar IFS + 
Parisian GP = efficient inverse IFS problem solving”, Genetic Programming and 
Evolvable Machines, vol. 1, number 4, p. 339-361, 2000. 
[COL 04] COLLET P., Vers une évolution interactive, from his thesis and Habilitation à 
Diriger des Recherches, June 2004, University of the Littoral Côte d’Opale. 
[DEJ 05] DEJONG K., Evolutionary Computation: a Unified Approach, MIT Press, 2005. 
[DUR 02] DURANT E. A., Hearing aid fitting with genetic algorithms, PhD Thesis, 
University of Michigan, USA, 2002.  
[EA] The Association for Artificial Evolution: http://ea.inria.fr. 
[HER 97] HERDY M., “Evolutionary optimization based on subjective selection – evolving 
blends of coffee”, Proceedings of the 5th European Congress on Intelligent Techniques 
and soft Computing, EUFIT’97, 1997. 
[JAN 02] JANSEN T., “On the analysis of dynamic restart strategies for evolutionary 
algorithms”, Parallel Problem Solving from Nature, p. 33-43, 2002. 
[KRI 89] KRISHNAKUMAR K., “Micro-genetic algorithms for stationary and non-stationary 
function optimization”, SPIE: Intelligent Control and Adaptive Systems, vol. 1196, 
Philadelphia, PA, 1989. 
[LAF 64] LAFON J., “Le test phonétique et la mesure de l’audition”, Ed. Centrex, 
Eindhoven, 1964. 
[LOI 98] LOIZOU P., “Introduction to cochlear implants”, IEEE Signal Processing 
Magazine, p. 101-130, 1998. 

356     Optimization in Signal and Image Processing 
[LOI 00] LOIZOU P., POROY O., DORMAN M., “The effect of parametric variations of 
cochlear implant processors on speech understanding”, Journal of Acoustical Society of 
America, p. 790-802, 2000. 
[MED] MEDEL, http://www.medel.com 
[MM] Mastermind competition: http://tniyurl.com/gaa7y 
[MXM] MXM Labs: http://www.mxmlabs.com 
[TAK 98] TAKAGI H., “Interactive evolutionary computation: system optimization based on 
human subjective evaluation”, Proceedings of the IEEE Intelligent Engineering Systems 
(INES’98), Vienna, Austria, 1998. 
[TAK 99] TAKAGI H., OHSAKI M., “IEC-based hearing aid fitting”, Proceedings of the 
IEEE Conference on Systems volume 3, 1999. 
[TAK 01] TAKAGI H., “Interactive evolutionary computation: fusion of the capabilities of 
EC optimization and human evaluation”, Proceedings of the IEEE, Vol.89, number 9, 
2001. 
[TAK 05] TAKAGI H., “Tutorial on interactive evolutionary algorithms”, 2005. 
 
  

List of Authors 
 
Djedjiga AÏT AOUIT 
Ecole Polytechnique of Tours  
France 
Olivier ALATA 
Signal, Image and Communications 
Laboratory 
University of Poitiers 
France 
Sébastien AUPETIT 
Computer Science Laboratory 
University François Rabelais 
Ecole Polytechnique of Tours  
France 
Claire BOURGEOIS-RÉPUBLIQUE 
LE2I  
University of Bourgogne 
France 
Stéphane CANU 
INSA  Rouen 
France 
Francis CELESTE 
DGA  
CEP  
Arcueil 
France 
Pierre CHARBONNIER 
LRPC 
Strasbourg 
France 
Christophe COLLET 
National College of Physics  
Strasbourg 
France 
Pierre COLLET 
Computer Science Laboratory  
University of Littoral Côte d’Opale  
Calais 
France 
Frédéric DAMBREVILLE 
DGA  
CEP  
Arcueil 
France 
Johann DRÉO 
Laboratory of Imagery, Signals and 
Intelligent Systems 
University of Paris 12 
Créteil 
France 
Optimization in Signal and Image Processing 
Edited by Patrick Siarry 
Copyright 0 
2009, ISTE Ltd 

358     Optimization in Signal and Image Processing 
Guillaume DUTILLEUX 
LRPC  
Strasbourg 
France 
Bruno FRACHET 
Avicenne Hospital 
Bobigny 
France 
Jean-Pierre LE CADRE 
French Research Institute in 
Computing and Risk Systems 
Rennes 
France  
Pierrick LEGRAND 
Computer Science Laboratory  
University of Littoral Côte d’Opale  
Calais 
France 
Gaëlle LOOSLI 
INSA  Rouen  
France 
Jean LOUCHET 
INRIA  
Rocquencourt  
France 
Nicolas MONMARCHÉ 
Computer Science Laboratory 
University François Rabelais 
Ecole Polytechnique de Tours  
France 
Amine NAÏT-ALI 
Laboratory of Imagery, Signals and 
Intelligent Systems 
University of Paris 12 
Créteil 
France 
Jean-Claude NUNES 
Laboratory of Signal and Image 
Processing 
University of Rennes 1 
France 
Christian OLIVIER 
Signal, Image and Communications 
Laboratory 
University of Poitiers 
France 
Abdeljalil OUAHABI 
Ecole Polytechnique de Tours  
France 
Vincent PÉAN 
Center of Technological Resources 
Innotech 
Bobigny 
France 
Patrick SIARRY 
Laboratory of Imagery, Signals and 
Intelligent Systems 
University of Paris 12 
Créteil 
France 
Cécile SIMONIN 
DGA  
CEP  
Arcueil 
France 
Mohamed SLIMANE 
Computer Science Laboratory 
University François Rabelais 
Ecole Polytechnique de Tours  
France 
 

 
Index
A 
A priori, 247-252, 260, 265 
Acceleration, 17 
Active sets, 112, 120, 123, 132 
AIC (Akaike Information Criterion), 
3-11, 15, 16, 19-21, 26, 27, 32 
Ant colony, 273, 274, 281, 283, 297 
API algorithm, 225-241 
Autoregressive (AR) models, 2 
 
B 
Bayesian network, 161, 166 
BIC (Bayesian Information 
Criterion), 3-20, 26 
B-spline, 207, 211 
 
C 
Capacity, 111-117, 131, 132,  
Chromosome, 305 
Clonal selection (CS), 252, 255-258, 
265, 266 
Cloning, 256, 258 
CMOS cameras, 37, 38 
Compressible fluid, 11 
Consistency, 4, 5 
Contour segmentation, 3  
Convergence speed, 335 
Cost, 113-126,  
Cramér-Rao bound, 153, 154, 
Criterion, 1-27 
Cross-entropy, 138, 166, 167 
 
D 
Deformable models, 246, 247, 267 
Deformable prototype, 209 
Detecting obstacles, 32, 34 
Detecting, 246, 264-267 
Diaphony, 344, 346 
Distance map, 247, 262-265 
 
E 
Echo, 198, 203-206, 215 
Electrodes, 329-331, 336, 337, 340, 
344-354 
Electroencephalography (EEG), 301-
303, 307-309, 313, 320 
Electromyography (EMG), 302-304 
Entropy, 2, 3, 28 
Estimation EM, 201 
Evolutionary algorithms, 252, 266 
Evolutionary strategies (ES), 252-
255, 261, 262, 264, 265 
 
F 
Filter, 153,  
Filtering, 153, 155, 167 
Optimization in Signal and Image Processing 
Edited by Patrick Siarry 
Copyright 0 
2009, ISTE Ltd 

360     Optimization in Signal and Image Processing 
Fitness, 18, 20, 24-40 
function, 24-28, 34, 35, 38-40 
Fly algorithm, 22-24, 29 
 
G 
Genetic algorithms, 337 
Gibbs sampling, 200 
Global algorithm, 247 
Gradient descent, 247, 260 
Ground truth, 249, 260-265 
 
H 
HÉVÉA, 330, 339 
Hidden Markov models, 159, 162, 
166 
Hierarchical models, 159, 166 
Hilbert space, 115 
Histograms, 2, 20, 24, 27, 31 
Hough transform, 2, 4-9, 13, 14 
 
I 
ICM algorithm, 199, 200, 206, 215,  
Image energy, 249  
Image registration, 290-299  
Interactive evolutionary algorithms, 
353 
Iterated functions system (IFS), 17-
22, 41, 42 
 
J 
Jitter, 307 
 
K 
Kinematic modeling, 2, 10, 
Kullback-Leibler divergence, 140 
 
L 
Large scale, 111, 112, 126, 133, 134 
Learning, 159, 166, 167 
Likelihood, 246-250, 260-266 
Local optimization, 260 
M 
Markov algorithm, 198 
Mass-link models, 10, 11, 12 
Maturation, 258 
Maximum a posteriori, 246, 248 
Maximum likelihood (ML), 1, 3, 6, 7, 
18, 21, 26 
MDL (minimum description length), 
3-7, 11-15, 20, 21, 24, 26, 29-31 
Metaheuristics, 138 
Metropolis-Hastings algorithm, 200 
Michigan approach, 16 
Micro-GA, 335 
Micro-population, 353, 354 
Modeling, 305 
Multiscale minimization, 216 
Mutation, 252-254, 258, 259, 305, 
306, 313 
 
N 
Navigation, 30, 31, 38, 42 
Nelder-Mead, 279, 281, 282, 285-
287, 295, 296, 298 
Non-stationary, 301, 328 
 
O 
One class SVM, 117, 118 
Online learning, 127, 133 
Optic flow, 288, 290, 293-295 
Optimal control under partial 
observation, 158 
Optimal control, 158, 167 
 
P 
Partial observation, 138, 158, 159 
Particle swarm, 219, 225, 226, 230, 
242, 243 
optimization (PSO), 252, 259, 
261, 262, 264, 265 
Photometric models, 2, 3, 9, 10 
Physical modeling of motion, 9, 10,  

Index    361 
Pittsburgh approach, 16 
Planning of sensors, 137, 158,  
Planning, 137, 153, 154, 158-163, 
167  
Population, 252, 253, 255, 257, 259, 
260 
Potts model, 205 
Psychophysical, 340 
 
R 
Random delays, 307 
Rare event, 139-143, 167 
Rayleigh, 196, 204, 215 
Real time, 8, 27, 29, 37, 38, 40-43 
Region segmentation, 3, 4,  
Regions, 259 
Retina, 277, 293-299 
Risk, 113-115 
Robotics, 24, 28, 30, 39, 41, 42 
 
S 
Segmentation, 9-11, 14-17, 20, 29 
Selection, 252-258, 265, 266 
Sensors fusion, 34, 35, 39 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Shape prototype, 247 
Side-scan sonar, 195, 196, 214 
Simulation of rare events, 138, 139 
Simulation, 138, 139, 155, 166, 167 
Solutions, 222, 226, 230, 231, 233, 
234, 238, 240 
Sonar, 195-217 
Stereovision, 23-31, 38, 39 
Subdivision, 120, 126 
SVR, 116-119 
Synthesis of images, 11 
 
T 
Texture (modeling textures), 12, 14, 
16, 17, 27 
Toss-coin algorithm, 17 
Trajectories, 153-160 
 
W 
Weibull, 196, 202-204, 215 

